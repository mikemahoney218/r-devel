From ggrothendieck at gmail.com  Sun Jan  1 14:47:02 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sun, 1 Jan 2006 08:47:02 -0500
Subject: [Rd] Wish list
Message-ID: <971536df0601010547m488319c9h62a74a8a1b4ad4ad@mail.gmail.com>

This is my New Year wishlist for R features.  One
common thread is that I find I sometimes use languages
other than R including javascript, Windows batch and
gawk.  Others have mentioned other languages too.  It
would be nice if, in those cases I could use R
simplifying development into a single environment
(viz. R).

The following are not in any order.

1. Self Contained Executables

Make it possible to create self contained R
executables.  Something like tcl starkits
	  http://www.equi4.com/starkit.html
or Python py2exe
	  http://starship.python.net/crew/theller/py2exe
is what I am thinking of.  Its ok if they
are interpreted as long as its all transparent.

2. R as a Filter

Support using R as a filter analogously to
awk/gawk.  e.g.

    echo a x 3 | R -f myprog.R | findstr /i answer
    echo a x 3 | R -e "chartr('x', 'X', readLines(STDIN()))" | findstr /i X

This would allow replacement of certain awk/gawk
filters with R.  In the above STDIN or some
would refer to the echo output, not to further
input from the script.  I think /dev/stdin
can already be used in UNIX but not in Windows.

3. Microsoft Active Scripting Language

Make R into a Microsoft Active Scripting
language.  Nearly every other major scripting
language including perl, python, ruby, tcl,
oorexx, vbscript, jscript and others have
Microsoft Active Scripting support.  This would
allow R to be used like javascript in HTML files
in Microsoft environments and also in any other
software that supports Microsoft's active
scripting interface.

4. Extend Clipboard Support to Non-Text Objects on
Windows

If one selects and copies a table in Internet
Explorer (IE) one can then paste it into Excel and
it comes out as expected with one Excel cell per
IE table cell.  However, R does not currently
support this level of integration. (Current
workaround is to paste it into Excel and then copy
it back out of Excel.  Excel will add tabs to the
text that is so copied.)

I understand that this feature may be in R 2.3.0
but am mentioning it for completeness.

5. Handhelds

Version(s) of R for handheld computers such as
Palm, Windows Mobile, Symbian, Blackberry, etc.
UNIX-based handhelds would likely be simplest
but the others would likely be useful to a wider
audience.

6. Issue Tracking in Packages

Standard method of tracking issues in CRAN
packages.  Provide svn and Trac support or
equivalent to CRAN package authors or at least
have a common change log mechanism.  There is
currently no uniform way of finding out what has
changed in a package.

7. system

The arguments of "system(...)" should be extended
in various operating systems so that a consistent
set is available across them.  Right now it works
differently under Windows and UNIX.

8. Extend Grid to Base Graphics

Rework base graphics so that they use grid
graphics underneath to the extent possible or else
leave them as is but have a version or package
that emulate them using grid graphics.

9. Eliminate Perl

Get rid of all use of perl within R.  The parts
of R that use perl have not changed much probably
because its too onerous to have to deal with a
complex multilanguage setup.  Eliminating perl might
speed up improvements in those areas.  This mostly
affects the package buildin gprocess which could
then be rehosted within R as a package building
package.

10. Event Loop

Add an event loop mechanism to facilitate GUI
programming in R and also to facilitate the development
of facilities to allow higher levels of interaction
within grid graphics.


From murdoch at stats.uwo.ca  Sun Jan  1 15:36:10 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sun, 01 Jan 2006 09:36:10 -0500
Subject: [Rd] Wish list
In-Reply-To: <971536df0601010547m488319c9h62a74a8a1b4ad4ad@mail.gmail.com>
References: <971536df0601010547m488319c9h62a74a8a1b4ad4ad@mail.gmail.com>
Message-ID: <43B7E8DA.4090603@stats.uwo.ca>

On 1/1/2006 8:47 AM, Gabor Grothendieck wrote:
> This is my New Year wishlist for R features.  One
> common thread is that I find I sometimes use languages
> other than R including javascript, Windows batch and
> gawk.  Others have mentioned other languages too.  It
> would be nice if, in those cases I could use R
> simplifying development into a single environment
> (viz. R).
> 
> The following are not in any order.
> 
> 1. Self Contained Executables
> 
> Make it possible to create self contained R
> executables.  Something like tcl starkits
> 	  http://www.equi4.com/starkit.html
> or Python py2exe
> 	  http://starship.python.net/crew/theller/py2exe
> is what I am thinking of.  Its ok if they
> are interpreted as long as its all transparent.

How self-contained?  It would be relatively easy to create small 
executables that could make use of the DLLs in R_HOME.  But that's 
probably not useful if better support for your next suggestion was 
there. If you want something that would run on a machine with no R 
installed, that probably involves changing the linking scheme (at least 
in Windows), and would not be so simple.

> 2. R as a Filter
> 
> Support using R as a filter analogously to
> awk/gawk.  e.g.
> 
>     echo a x 3 | R -f myprog.R | findstr /i answer
>     echo a x 3 | R -e "chartr('x', 'X', readLines(STDIN()))" | findstr /i X
> 
> This would allow replacement of certain awk/gawk
> filters with R.  In the above STDIN or some
> would refer to the echo output, not to further
> input from the script.  I think /dev/stdin
> can already be used in UNIX but not in Windows.
> 
> 3. Microsoft Active Scripting Language
> 
> Make R into a Microsoft Active Scripting
> language.  Nearly every other major scripting
> language including perl, python, ruby, tcl,
> oorexx, vbscript, jscript and others have
> Microsoft Active Scripting support.  This would
> allow R to be used like javascript in HTML files
> in Microsoft environments and also in any other
> software that supports Microsoft's active
> scripting interface.

R is not designed to be secure.  I think this would be a very risky 
thing to do.

> 
> 4. Extend Clipboard Support to Non-Text Objects on
> Windows
> 
> If one selects and copies a table in Internet
> Explorer (IE) one can then paste it into Excel and
> it comes out as expected with one Excel cell per
> IE table cell.  However, R does not currently
> support this level of integration. (Current
> workaround is to paste it into Excel and then copy
> it back out of Excel.  Excel will add tabs to the
> text that is so copied.)
> 
> I understand that this feature may be in R 2.3.0
> but am mentioning it for completeness.

Yes, I wrote some functions to do some of this, but I haven't committed 
them to the trunk.  I didn't like the user interface much:  using 
clipboard support depends heavily on being able to handle the various 
clipboard format constants (CF_BITMAP, etc.), and R doesn't handle 
constants well.  I'll take another look at them and see if I get any 
inspiration on how to make them palatable.

> 5. Handhelds
> 
> Version(s) of R for handheld computers such as
> Palm, Windows Mobile, Symbian, Blackberry, etc.
> UNIX-based handhelds would likely be simplest
> but the others would likely be useful to a wider
> audience.

All this needs is someone who wants to gather/create the tools and start 
building the binaries.

> 6. Issue Tracking in Packages
> 
> Standard method of tracking issues in CRAN
> packages.  Provide svn and Trac support or
> equivalent to CRAN package authors or at least
> have a common change log mechanism.  There is
> currently no uniform way of finding out what has
> changed in a package.
> 
> 7. system
> 
> The arguments of "system(...)" should be extended
> in various operating systems so that a consistent
> set is available across them.  Right now it works
> differently under Windows and UNIX.
> 
> 8. Extend Grid to Base Graphics
> 
> Rework base graphics so that they use grid
> graphics underneath to the extent possible or else
> leave them as is but have a version or package
> that emulate them using grid graphics.

This sounds like the gridBase package.

> 9. Eliminate Perl
> 
> Get rid of all use of perl within R.  The parts
> of R that use perl have not changed much probably
> because its too onerous to have to deal with a
> complex multilanguage setup.  Eliminating perl might
> speed up improvements in those areas.  This mostly
> affects the package buildin gprocess which could
> then be rehosted within R as a package building
> package.

> 10. Event Loop
> 
> Add an event loop mechanism to facilitate GUI
> programming in R and also to facilitate the development
> of facilities to allow higher levels of interaction
> within grid graphics.

There is such a thing now:  see the Writing R Extensions manual.  It 
still needs work, but people using it and suggesting improvements will help.

Duncan Murdoch


From ggrothendieck at gmail.com  Sun Jan  1 16:14:10 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sun, 1 Jan 2006 10:14:10 -0500
Subject: [Rd] Wish list
In-Reply-To: <43B7E8DA.4090603@stats.uwo.ca>
References: <971536df0601010547m488319c9h62a74a8a1b4ad4ad@mail.gmail.com>
	<43B7E8DA.4090603@stats.uwo.ca>
Message-ID: <971536df0601010714x6d24ce75l95d0be1a33f28d6a@mail.gmail.com>

On 1/1/06, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> On 1/1/2006 8:47 AM, Gabor Grothendieck wrote:
> > This is my New Year wishlist for R features.  One
> > common thread is that I find I sometimes use languages
> > other than R including javascript, Windows batch and
> > gawk.  Others have mentioned other languages too.  It
> > would be nice if, in those cases I could use R
> > simplifying development into a single environment
> > (viz. R).
> >
> > The following are not in any order.
> >
> > 1. Self Contained Executables
> >
> > Make it possible to create self contained R
> > executables.  Something like tcl starkits
> >         http://www.equi4.com/starkit.html
> > or Python py2exe
> >         http://starship.python.net/crew/theller/py2exe
> > is what I am thinking of.  Its ok if they
> > are interpreted as long as its all transparent.
>
> How self-contained?  It would be relatively easy to create small

Similar to tcl starkits and pyexe.  You can just send someone
an .exe and they can run it.  They don't have to have any software
or files other than that.  Or suppose I want to write an R configuration
facility and don't know which version of R is on the machine or even
if R is on the machine.  Currently I use batch files or javascript to
do this (see http://cran.r-project.org/contrib/extra/batchfiles/) since
one does not want to have configure the configurer.  I would actually
prefer to leverage my knowledge of R and not have to go to the
lengths of using a different language.

> executables that could make use of the DLLs in R_HOME.  But that's
> probably not useful if better support for your next suggestion was
> there. If you want something that would run on a machine with no R
> installed, that probably involves changing the linking scheme (at least
> in Windows), and would not be so simple.
>
> > 2. R as a Filter
> >
> > Support using R as a filter analogously to
> > awk/gawk.  e.g.
> >
> >     echo a x 3 | R -f myprog.R | findstr /i answer
> >     echo a x 3 | R -e "chartr('x', 'X', readLines(STDIN()))" | findstr /i X
> >
> > This would allow replacement of certain awk/gawk
> > filters with R.  In the above STDIN or some
> > would refer to the echo output, not to further
> > input from the script.  I think /dev/stdin
> > can already be used in UNIX but not in Windows.
> >
> > 3. Microsoft Active Scripting Language
> >
> > Make R into a Microsoft Active Scripting
> > language.  Nearly every other major scripting
> > language including perl, python, ruby, tcl,
> > oorexx, vbscript, jscript and others have
> > Microsoft Active Scripting support.  This would
> > allow R to be used like javascript in HTML files
> > in Microsoft environments and also in any other
> > software that supports Microsoft's active
> > scripting interface.
>
> R is not designed to be secure.  I think this would be a very risky
> thing to do.

Some alternatives are:

- restrict execution to .hta's (which are html files that are restricted to
run locally -- they can't be run from a browser).

- do the work to separate out the OS dependent items into libraries
so that access can be restricted similarly to what vscript and jscript
have done with wsh.

- perhaps there is some way for the user to accept or reject such
applications as trusted or not?

> >
> > 8. Extend Grid to Base Graphics
> >
> > Rework base graphics so that they use grid
> > graphics underneath to the extent possible or else
> > leave them as is but have a version or package
> > that emulate them using grid graphics.
>
> This sounds like the gridBase package.

Correct me if I am mistaken here but
my understanding is that this makes it possible to use
grid and standard graphics together but does not produce
grobs for all the elements of a graphic like doing it from
the bottom up would.


From duncan at wald.ucdavis.edu  Sun Jan  1 16:36:18 2006
From: duncan at wald.ucdavis.edu (Duncan Temple Lang)
Date: Sun, 01 Jan 2006 07:36:18 -0800
Subject: [Rd] Wish list
In-Reply-To: <971536df0601010547m488319c9h62a74a8a1b4ad4ad@mail.gmail.com>
References: <971536df0601010547m488319c9h62a74a8a1b4ad4ad@mail.gmail.com>
Message-ID: <43B7F6F2.6080401@wald.ucdavis.edu>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1



Gabor Grothendieck wrote:
> This is my New Year wishlist for R features.  One
> common thread is that I find I sometimes use languages
> other than R including javascript, Windows batch and
> gawk.  Others have mentioned other languages too.  It
> would be nice if, in those cases I could use R
> simplifying development into a single environment
> (viz. R).
> 
> The following are not in any order.
> 
> 1. Self Contained Executables
> 
> Make it possible to create self contained R
> executables.  Something like tcl starkits
> 	  http://www.equi4.com/starkit.html
> or Python py2exe
> 	  http://starship.python.net/crew/theller/py2exe
> is what I am thinking of.  Its ok if they
> are interpreted as long as its all transparent.
> 

We have been thinking of this, for me in the context
of putting R on small sensor network nodes.

> 2. R as a Filter
> 
> Support using R as a filter analogously to
> awk/gawk.  e.g.
> 
>     echo a x 3 | R -f myprog.R | findstr /i answer
>     echo a x 3 | R -e "chartr('x', 'X', readLines(STDIN()))" | findstr /i X
> 
> This would allow replacement of certain awk/gawk
> filters with R.  In the above STDIN or some
> would refer to the echo output, not to further
> input from the script.  I think /dev/stdin
> can already be used in UNIX but not in Windows.
> 

This has been in the works for a long time and I still dislike two
small pieces of the solution that make it limited.


> 3. Microsoft Active Scripting Language
> 
> Make R into a Microsoft Active Scripting
> language.  Nearly every other major scripting
> language including perl, python, ruby, tcl,
> oorexx, vbscript, jscript and others have
> Microsoft Active Scripting support.  This would
> allow R to be used like javascript in HTML files
> in Microsoft environments and also in any other
> software that supports Microsoft's active
> scripting interface.

Yes not that hard to do given the work in other interfaces,
but I wish the Windows users would contribute it.

> 
> 4. Extend Clipboard Support to Non-Text Objects on
> Windows
> 
> If one selects and copies a table in Internet
> Explorer (IE) one can then paste it into Excel and
> it comes out as expected with one Excel cell per
> IE table cell.  However, R does not currently
> support this level of integration. (Current
> workaround is to paste it into Excel and then copy
> it back out of Excel.  Excel will add tabs to the
> text that is so copied.)
> 
> I understand that this feature may be in R 2.3.0
> but am mentioning it for completeness.
> 
> 5. Handhelds
> 
> Version(s) of R for handheld computers such as
> Palm, Windows Mobile, Symbian, Blackberry, etc.
> UNIX-based handhelds would likely be simplest
> but the others would likely be useful to a wider
> audience.
> 
> 6. Issue Tracking in Packages
> 
> Standard method of tracking issues in CRAN
> packages.  Provide svn and Trac support or
> equivalent to CRAN package authors or at least
> have a common change log mechanism.  There is
> currently no uniform way of finding out what has
> changed in a package.
> 
> 7. system
> 
> The arguments of "system(...)" should be extended
> in various operating systems so that a consistent
> set is available across them.  Right now it works
> differently under Windows and UNIX.
> 
> 8. Extend Grid to Base Graphics
> 
> Rework base graphics so that they use grid
> graphics underneath to the extent possible or else
> leave them as is but have a version or package
> that emulate them using grid graphics.
> 
> 9. Eliminate Perl
> 
> Get rid of all use of perl within R.  The parts
> of R that use perl have not changed much probably
> because its too onerous to have to deal with a
> complex multilanguage setup.  Eliminating perl might
> speed up improvements in those areas.  This mostly
> affects the package buildin gprocess which could
> then be rehosted within R as a package building
> package.

There is some work in progress on an extensible, R-based
package mechanism.

> 
> 10. Event Loop
> 
> Add an event loop mechanism to facilitate GUI
> programming in R and also to facilitate the development
> of facilities to allow higher levels of interaction
> within grid graphics.
> 

Well, there has been work on this that people couldn't agree on.


And while we are on the topic of wishlists...
Generally (i.e. not directed specifically to Gabor),
the suggestions are very welcome, but so are contributions.
And for issues such as making the existing R available on handhelds,
that is a programming task. And I draw a large distinction between
programming and creative research which is based on new concepts and
paradigms.  The pool of people working in statistical computing research
is very small. And to a large extent, their time is consumed with
programming - making the same thing work on multiple platforms,
correcting documentation, etc. which are good things, but
not obviously the best use of available research ability and time.
There are many more topics that are in progress that represent
changes to what we can do  rather than just to how we do the same thing.

One of the reasons S (R and S-Plus) is where it is now
is because in Bell Labs, the idea was to be thinking
5 years ahead and both meeting and directing the needs for the future.
Because of R's popularity (somewhat related to it being free), there is
an aspect of development that focuses more on software for statisticians
to use "right now".
Obviously, th development is a mixture of both the current and the
future, but there is less of the future and certainly less of the
longer term directions that is sacrificed by the need to maintain an
existing system and be backward-compatible.
If statistics is to fulfill its potential in this modern IT, we need new
ideas and research into those new ideas. If we focus on basic
programming tasks (however complex) and demand usability above concepts,
we risk losing those whose primary focus is in statistical computing
research from the field.

While R provides statisticians and stat. comp. researchers with a
terrific vehicle for doing their respective work, it also acts as
a constraint for doing anything even moderately new. But much (not all)
of R is based on innovations from the 1970's, 80's and 90's.   And
as IT evolves at a terrific pace, to keep up with it, we need to be
forward looking.


I'll leave it there - for the moment - and go fight off the ants
that are invading my desk!  While I wrote this down relatively
rapidly, the ideas have been brewing for a long time. If anyone
wishes to comment on the theme, I hope they will take a few minutes
to think about the broad set of issues and tradeoffs.


  D.


> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

- --
Duncan Temple Lang                    duncan at wald.ucdavis.edu
Department of Statistics              work:  (530) 752-4782
4210 Mathematical Sciences Building   fax:   (530) 752-7099
One Shields Ave.
University of California at Davis
Davis,
CA 95616,
USA
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.2 (Darwin)

iD8DBQFDt/by9p/Jzwa2QP4RAr6UAJ4mT9C1JcGwlFFJRFVDteyetDrAjACfax7B
0MpswqQE442j23WzJjqUADA=
=Aq8t
-----END PGP SIGNATURE-----


From murdoch at stats.uwo.ca  Sun Jan  1 18:26:23 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sun, 01 Jan 2006 12:26:23 -0500
Subject: [Rd] Enhancement request: anonymous connections
In-Reply-To: <m2ek3xcm32.fsf@fhcrc.org>
References: <m2mzimc9zj.fsf@fhcrc.org> <43B1EE08.4090003@stats.uwo.ca>
	<m2ek3xcm32.fsf@fhcrc.org>
Message-ID: <43B810BF.8080309@stats.uwo.ca>

On 12/28/2005 9:50 AM, Seth Falcon wrote:
> On 27 Dec 2005, murdoch at stats.uwo.ca wrote:
> 
>>This is a bug in load, isn't it?  load() opens the connection but
>>doesn't close it.
> 
> 
> Well, it may be that load needs a small fix, but that doesn't fix
> anonymous connections in general, IMO.

No it doesn't.  However, I've committed the small fix.
> 
> The loop could easily have been:
> 
> for (i in 1:50) {
>     print(load(url(testUrl, open="r")))
> }
> 
> And it doesn't need to be related to url or load:
> 
> cat("a line of text\n", file="another-example.txt")
> z <- NULL
> for (i in 1:50) {
>     z <- c(z, readLines(file("another-example.txt", open="r")))
> }
> 
> Also, connections are "in use" even if they are closed:
> 
> for (i in 1:50) {
>     if (isOpen(file("another-example.txt")))
>         stop("you will not get here")
> }

I think the general problem is that R doesn't have references (or at 
least, they aren't in a final, documented state).  If the garbage 
collector closed a connection, then things would go wrong when there 
were two copies of it:  the second one would be messed up when the first 
was destroyed.  If we had references, then opening a connection could 
create a connection object and a reference to it; the connection object 
would remain as long as there were any references to it, and could be 
destroyed (and automatically closed) after the last reference was gone.

Duncan Murdoch


From ripley at stats.ox.ac.uk  Sun Jan  1 19:05:40 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 1 Jan 2006 18:05:40 +0000 (GMT)
Subject: [Rd] Enhancement request: anonymous connections
In-Reply-To: <43B810BF.8080309@stats.uwo.ca>
References: <m2mzimc9zj.fsf@fhcrc.org> <43B1EE08.4090003@stats.uwo.ca>
	<m2ek3xcm32.fsf@fhcrc.org> <43B810BF.8080309@stats.uwo.ca>
Message-ID: <Pine.LNX.4.61.0601011752100.29194@gannet.stats>

On Sun, 1 Jan 2006, Duncan Murdoch wrote:

> On 12/28/2005 9:50 AM, Seth Falcon wrote:
>> On 27 Dec 2005, murdoch at stats.uwo.ca wrote:
>>
>>> This is a bug in load, isn't it?  load() opens the connection but
>>> doesn't close it.
>>
>>
>> Well, it may be that load needs a small fix, but that doesn't fix
>> anonymous connections in general, IMO.
>
> No it doesn't.  However, I've committed the small fix.

It was not even a bug in load: close() and open() are not pairs.  (I 
didn't pick the names!) Your `fix' destroys a connection, which is 
not the documented behaviour and far more dangerous than leaving it open.

The lifecycle of a connection is  (see e.g. my R-news article)

 	create->open->close->destroy

and close() does both of the last two.  Please revert this change. 
Ideally we would close and not destroy if the connection was opened, but 
that needs a better C-level interface in place of this R-level one.

>> The loop could easily have been:
>>
>> for (i in 1:50) {
>>     print(load(url(testUrl, open="r")))
>> }
>>
>> And it doesn't need to be related to url or load:
>>
>> cat("a line of text\n", file="another-example.txt")
>> z <- NULL
>> for (i in 1:50) {
>>     z <- c(z, readLines(file("another-example.txt", open="r")))
>> }
>>
>> Also, connections are "in use" even if they are closed:
>>
>> for (i in 1:50) {
>>     if (isOpen(file("another-example.txt")))
>>         stop("you will not get here")
>> }
>
> I think the general problem is that R doesn't have references (or at
> least, they aren't in a final, documented state).  If the garbage
> collector closed a connection, then things would go wrong when there
> were two copies of it:  the second one would be messed up when the first
> was destroyed.  If we had references, then opening a connection could
> create a connection object and a reference to it; the connection object
> would remain as long as there were any references to it, and could be
> destroyed (and automatically closed) after the last reference was gone.

However, that just isn't how connections are documented in the Green Book 
(referenced on all the relevant help pages, so required reading) and 
getConnection() allows you to create an R object pointing to a connection 
that previously had none.  The OP has never told us what `anonymous 
connections' are, but it is quite possible that his unstated ideas are 
incompatible with the documentation.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From murdoch at stats.uwo.ca  Sun Jan  1 19:20:31 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sun, 01 Jan 2006 13:20:31 -0500
Subject: [Rd] Enhancement request: anonymous connections
In-Reply-To: <Pine.LNX.4.61.0601011752100.29194@gannet.stats>
References: <m2mzimc9zj.fsf@fhcrc.org> <43B1EE08.4090003@stats.uwo.ca>
	<m2ek3xcm32.fsf@fhcrc.org> <43B810BF.8080309@stats.uwo.ca>
	<Pine.LNX.4.61.0601011752100.29194@gannet.stats>
Message-ID: <43B81D6F.5000409@stats.uwo.ca>

On 1/1/2006 1:05 PM, Prof Brian Ripley wrote:
> On Sun, 1 Jan 2006, Duncan Murdoch wrote:
> 
> 
>>On 12/28/2005 9:50 AM, Seth Falcon wrote:
>>
>>>On 27 Dec 2005, murdoch at stats.uwo.ca wrote:
>>>
>>>
>>>>This is a bug in load, isn't it?  load() opens the connection but
>>>>doesn't close it.
>>>
>>>
>>>Well, it may be that load needs a small fix, but that doesn't fix
>>>anonymous connections in general, IMO.
>>
>>No it doesn't.  However, I've committed the small fix.
> 
> 
> It was not even a bug in load: close() and open() are not pairs.  (I 
> didn't pick the names!) Your `fix' destroys a connection, which is 
> not the documented behaviour and far more dangerous than leaving it open.
> 
> The lifecycle of a connection is  (see e.g. my R-news article)
> 
>  	create->open->close->destroy
> 
> and close() does both of the last two.  Please revert this change. 
> Ideally we would close and not destroy if the connection was opened, but 
> that needs a better C-level interface in place of this R-level one.

Sorry about that.  I've done the reversion.

Is it worth putting that C-level interface in place to make load() more 
compatible with ?connections which says,

      'open' opens a connection.  In general functions using connections
      will open them if they are not open, but then close them again, so
      to leave a connection open call 'open' explicitly.

?  I suppose a natural way to do it would be to add a "destroy=TRUE"
argument to close(), and then have load() do

  on.exit(close(con, destroy=FALSE))

but maybe it would be better to add a separate function to do this, for 
better green book compatibility.

Duncan Murdoch
> 
> 
>>>The loop could easily have been:
>>>
>>>for (i in 1:50) {
>>>    print(load(url(testUrl, open="r")))
>>>}
>>>
>>>And it doesn't need to be related to url or load:
>>>
>>>cat("a line of text\n", file="another-example.txt")
>>>z <- NULL
>>>for (i in 1:50) {
>>>    z <- c(z, readLines(file("another-example.txt", open="r")))
>>>}
>>>
>>>Also, connections are "in use" even if they are closed:
>>>
>>>for (i in 1:50) {
>>>    if (isOpen(file("another-example.txt")))
>>>        stop("you will not get here")
>>>}
>>
>>I think the general problem is that R doesn't have references (or at
>>least, they aren't in a final, documented state).  If the garbage
>>collector closed a connection, then things would go wrong when there
>>were two copies of it:  the second one would be messed up when the first
>>was destroyed.  If we had references, then opening a connection could
>>create a connection object and a reference to it; the connection object
>>would remain as long as there were any references to it, and could be
>>destroyed (and automatically closed) after the last reference was gone.
> 
> 
> However, that just isn't how connections are documented in the Green Book 
> (referenced on all the relevant help pages, so required reading) and 
> getConnection() allows you to create an R object pointing to a connection 
> that previously had none.  The OP has never told us what `anonymous 
> connections' are, but it is quite possible that his unstated ideas are 
> incompatible with the documentation.
>


From znmeb at cesmail.net  Sun Jan  1 20:08:42 2006
From: znmeb at cesmail.net (M. Edward (Ed) Borasky)
Date: Sun, 01 Jan 2006 11:08:42 -0800
Subject: [Rd] Wish list
In-Reply-To: <43B7F6F2.6080401@wald.ucdavis.edu>
References: <971536df0601010547m488319c9h62a74a8a1b4ad4ad@mail.gmail.com>
	<43B7F6F2.6080401@wald.ucdavis.edu>
Message-ID: <43B828BA.7010905@cesmail.net>

Duncan Temple Lang wrote:

>And while we are on the topic of wishlists...
>Generally (i.e. not directed specifically to Gabor),
>the suggestions are very welcome, but so are contributions.
>And for issues such as making the existing R available on handhelds,
>that is a programming task.
>
Hasn't someone ported R to the Sharp Zaurus, for which both the Linux 
kernel and a more or less complete GNU toolchain exist, plus at least 
two GUI builders? I've forgotten what the compiler version is -- it 
might be back around 2.95.

In any event, one of the Lisps and Maxima have been ported to the 
Zaurus. I'm not sure how well a number crunching application like R 
would run on the Zaurus processor, though -- IIRC the floating point is 
emulated in software. Isn't the same true for Palms and Windows CE PDAs?

>And I draw a large distinction between
>programming and creative research which is based on new concepts and
>paradigms.  The pool of people working in statistical computing research
>is very small. And to a large extent, their time is consumed with
>programming - making the same thing work on multiple platforms,
>correcting documentation, etc. which are good things, but
>not obviously the best use of available research ability and time.
>There are many more topics that are in progress that represent
>changes to what we can do  rather than just to how we do the same thing.
>  
>
I'd much rather have changes to what we can do rather than how we do the 
same thing! As the Perl folks say, "There's more than one way to do it!" 
So keep R and its contributed packages focused on making the first few 
ways to do something new!

>One of the reasons S (R and S-Plus) is where it is now
>is because in Bell Labs, the idea was to be thinking
>5 years ahead and both meeting and directing the needs for the future.
>Because of R's popularity (somewhat related to it being free), there is
>an aspect of development that focuses more on software for statisticians
>to use "right now".
>Obviously, th development is a mixture of both the current and the
>future, but there is less of the future and certainly less of the
>longer term directions that is sacrificed by the need to maintain an
>existing system and be backward-compatible.
>If statistics is to fulfill its potential in this modern IT, we need new
>ideas and research into those new ideas. If we focus on basic
>programming tasks (however complex) and demand usability above concepts,
>we risk losing those whose primary focus is in statistical computing
>research from the field.
>  
>
Amen! Please don't turn R into Perl! The Perl community has statistical 
libraries for the basics. If that's all you want to do, just learn how 
to do it in Perl. The same goes for Python and Ruby. All the scripting 
languages can be used for basic statistical and numeric processing, and 
their communities are adding libraries for more advanced functionality 
all the time.

But no other language/community has the breadth of advanced statistical 
processing that R and its contributed packages have, and no other 
language has the right core semantics to make this kind of computing 
easy, with the possible exception of the newest dialects of Fortran. I 
*could* write a web ecommerce site in R if I wanted to, but why would I? 
I'd do that in PHP or the new Ruby on Rails, because that's what those 
languages were designed to do well!

>While R provides statisticians and stat. comp. researchers with a
>terrific vehicle for doing their respective work, it also acts as
>a constraint for doing anything even moderately new. But much (not all)
>of R is based on innovations from the 1970's, 80's and 90's.   And
>as IT evolves at a terrific pace, to keep up with it, we need to be
>forward looking.
>  
>
Could you elaborate on the nature of the constraints R imposes? 
Obviously there are *time* constraints made necessary by the programming 
tasks and finite number of community members, but are there limits to 
the kinds of scientific/statistical computing thoughts one can think if 
one only uses R and its contributed packages?

>I'll leave it there - for the moment - and go fight off the ants
>that are invading my desk!  While I wrote this down relatively
>rapidly, the ideas have been brewing for a long time. If anyone
>wishes to comment on the theme, I hope they will take a few minutes
>to think about the broad set of issues and tradeoffs.
>  
>
I've been thinking about related issues over the holiday break, mostly 
triggered by Paul Graham's essay on a programming language that would 
last 100 years. The essay will appear on my blog in the near future. 
Meanwhile, I'll add my wish list (and list of things I'd work on in my 
spare time if I had any :) ) for R.

1. An integrated symbolic math capability. I think packaging GiNaC 
(http://freshmeat.net/projects/ginac/) is the logical way to do this. 
GiNaC is a C++ library, and I suspect it could be easily packaged, but I 
haven't tried it yet. If someone is ahead of me on this, I'd like to 
know about it before I attempt it.

2. A good solid discrete time and continuous time Markov chain analyzer 
for use in computer performance analysis. There are quite a few good 
toolsets out there, some with GUIs and some without, but nearly all of 
them have licenses that are not free as in speech. They're freely 
obtainable in the academic community, but not for "commercial use". 
There is one exception, and if I followed the path of integrating an 
existing package, I'd go with Prism (http://www.cs.bham.ac.uk/~dxp/prism/).

3. Along the lines of 2, more "out-of-core" solver capabilities. I don't 
think it's going to be much longer before a "typical scientific 
researcher" in a domain like bioinformatics or computer performance 
analysis will have available a two (physical 64-bit) processor 4GB 
workstation with a terabyte of local disk, plus, of course, access to a 
grid for the "big problems." :) At the moment, I don't have any computer 
performance analysis problems with enough states to require an efficient 
out-of-core solver, but it's bound to happen.
-- 

M. Edward (Ed) Borasky

http://borasky-research.blogspot.com


From Mark.Bravington at csiro.au  Sun Jan  1 22:48:51 2006
From: Mark.Bravington at csiro.au (Mark.Bravington@csiro.au)
Date: Mon, 2 Jan 2006 08:48:51 +1100
Subject: [Rd] sealed namespaces and lockEnvironment
Message-ID: <D79013E40FEF254AAF0D72DFC94F274803D989@extas4-hba.tas.csiro.au>

Dear R-devel

I'm experimenting with easy-to-use ways for a package maintainer to modify a"live" package-- i.e. while it's loaded & in use. One difficulty is that packages with namespaces are usually sealed with 'lockEnvironment', which means you can't add/remove objects. After some effort, I've managed to bypass the sealing step, and the live-editing seems to be working pretty well.

However, there are reasons for sealing (e.g. in Luke Tierney's article in R-news 3/1). Which disasters am I really courting by not sealing the namespace?

NB 1: non-sealing only happens during development by the package maintainer, so some rough edges are tolerable.

and 2: the only alternative I can think of-- and it's less satisfactory anyway-- involves changing the namespace's parent environment using 'parent.env<-', which comes with even more dire warnings...

thanks

Mark Bravington


From A.Robinson at ms.unimelb.edu.au  Mon Jan  2 00:29:21 2006
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Mon, 2 Jan 2006 10:29:21 +1100
Subject: [Rd] R on Zaurus (was: Wish list)
In-Reply-To: <43B828BA.7010905@cesmail.net>
References: <971536df0601010547m488319c9h62a74a8a1b4ad4ad@mail.gmail.com>
	<43B7F6F2.6080401@wald.ucdavis.edu> <43B828BA.7010905@cesmail.net>
Message-ID: <20060101232921.GH88067@ms.unimelb.edu.au>

On Sun, Jan 01, 2006 at 11:08:42AM -0800, M. Edward (Ed) Borasky wrote:
> 
> Hasn't someone ported R to the Sharp Zaurus, 

Yes, Simon Pickering did this.  I ran his version of R on a Zaurus two
years ago.  His site implies that development is still underway.  

http://people.bath.ac.uk/enpsgp/Zaurus/index.html

> I'm not sure how well a number crunching application like R would
> run on the Zaurus processor, though -- IIRC the floating point is
> emulated in software.

It was slow :).  Also I never got it to work with X, but in fairness I
didn't really try hard.  Simon's site implies that improvements are
being implemented.

Cheers

Andrew
-- 
Andrew Robinson
Senior Lecturer in Statistics                       Tel: +61-3-8344-9763
Department of Mathematics and Statistics            Fax: +61-3-8344-4599
University of Melbourne, VIC 3010 Australia
Email: a.robinson at ms.unimelb.edu.au    Website: http://www.ms.unimelb.edu.au


From ellis at stat.harvard.edu  Mon Jan  2 09:07:58 2006
From: ellis at stat.harvard.edu (Byron Ellis)
Date: Mon, 2 Jan 2006 00:07:58 -0800
Subject: [Rd] Wish list
In-Reply-To: <43B7F6F2.6080401@wald.ucdavis.edu>
References: <971536df0601010547m488319c9h62a74a8a1b4ad4ad@mail.gmail.com>
	<43B7F6F2.6080401@wald.ucdavis.edu>
Message-ID: <B38CD70A-002F-4FE4-8D72-9629294A3F01@stat.harvard.edu>


On Jan 1, 2006, at 7:36 AM, Duncan Temple Lang wrote:

> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
>
>
>
> Gabor Grothendieck wrote:
>> This is my New Year wishlist for R features.  One
>> common thread is that I find I sometimes use languages
>> other than R including javascript, Windows batch and
>> gawk.  Others have mentioned other languages too.  It
>> would be nice if, in those cases I could use R
>> simplifying development into a single environment
>> (viz. R).
>>
>> The following are not in any order.
>>
>> 1. Self Contained Executables
>>
>> Make it possible to create self contained R
>> executables.  Something like tcl starkits
>> 	  http://www.equi4.com/starkit.html
>> or Python py2exe
>> 	  http://starship.python.net/crew/theller/py2exe
>> is what I am thinking of.  Its ok if they
>> are interpreted as long as its all transparent.
>>
>
> We have been thinking of this, for me in the context
> of putting R on small sensor network nodes.

This was recently done with CLISP by, essentially cat'ing the image  
onto the end of the CLISP executable. You could probably do the same  
with an Rda and a startup script (since R isn't truly image based) on  
a small custom front end that links the DLL. You'd need to patch save  
and load, but you'd be able to deliver executable apps (assuming base  
and everything is installed). For a completely self-contained  
executable (i.e. not requiring an installer) you'd probably want to  
build a "minimal" R that you can just source in or load as an image  
(or we could just go to images in general.... R's been sort of  
meandering in that direction for the last couple of years ;-) )


>
>> 2. R as a Filter
>>
>> Support using R as a filter analogously to
>> awk/gawk.  e.g.
>>
>>     echo a x 3 | R -f myprog.R | findstr /i answer
>>     echo a x 3 | R -e "chartr('x', 'X', readLines(STDIN()))" |  
>> findstr /i X
>>
>> This would allow replacement of certain awk/gawk
>> filters with R.  In the above STDIN or some
>> would refer to the echo output, not to further
>> input from the script.  I think /dev/stdin
>> can already be used in UNIX but not in Windows.
>>
>
> This has been in the works for a long time and I still dislike two
> small pieces of the solution that make it limited.
>
>
>> 3. Microsoft Active Scripting Language
>>
>> Make R into a Microsoft Active Scripting
>> language.  Nearly every other major scripting
>> language including perl, python, ruby, tcl,
>> oorexx, vbscript, jscript and others have
>> Microsoft Active Scripting support.  This would
>> allow R to be used like javascript in HTML files
>> in Microsoft environments and also in any other
>> software that supports Microsoft's active
>> scripting interface.
>
> Yes not that hard to do given the work in other interfaces,
> but I wish the Windows users would contribute it.

No, with the DCOM stuff it should be pretty straightforward these  
days. We actually did a bit of this with I think it was R 1.1 or so  
before the Bioconductor project got started. Security was an issue as  
Duncan M. pointed out as I recall. You could basically remotely trash  
someone's drive, no good. In the end, I think you can do what you  
need to do with the DCOM interface and everything else you can do  
with a front-end. Being able to hook into .Net/Mono would be useful I  
think. On the Very Cool list would be a "managed" version of R, but  
that falls into the Things That Don't Result In Degrees so its on  
indefinite hold (it does give Naras and I something to talk about at  
coffee though).

>
>>
>> 4. Extend Clipboard Support to Non-Text Objects on
>> Windows
>>
>> If one selects and copies a table in Internet
>> Explorer (IE) one can then paste it into Excel and
>> it comes out as expected with one Excel cell per
>> IE table cell.  However, R does not currently
>> support this level of integration. (Current
>> workaround is to paste it into Excel and then copy
>> it back out of Excel.  Excel will add tabs to the
>> text that is so copied.)
>>
>> I understand that this feature may be in R 2.3.0
>> but am mentioning it for completeness.
>>
>> 5. Handhelds
>>
>> Version(s) of R for handheld computers such as
>> Palm, Windows Mobile, Symbian, Blackberry, etc.
>> UNIX-based handhelds would likely be simplest
>> but the others would likely be useful to a wider
>> audience.

Many handhelds are simply too limited. Those that aren't are usually  
Linux based and its just a matter of cross-compiling. Unfortunately a  
lot of the chips are not really suitable for floating point work.  
Additionally, a lot of the very limited PDAs (e.g. Coldfire-based  
PDAs) don't have an MMU.

>>
>> 6. Issue Tracking in Packages
>>
>> Standard method of tracking issues in CRAN
>> packages.  Provide svn and Trac support or
>> equivalent to CRAN package authors or at least
>> have a common change log mechanism.  There is
>> currently no uniform way of finding out what has
>> changed in a package.
>>
>> 7. system
>>
>> The arguments of "system(...)" should be extended
>> in various operating systems so that a consistent
>> set is available across them.  Right now it works
>> differently under Windows and UNIX.
>>
>> 8. Extend Grid to Base Graphics
>>
>> Rework base graphics so that they use grid
>> graphics underneath to the extent possible or else
>> leave them as is but have a version or package
>> that emulate them using grid graphics.
>>
>> 9. Eliminate Perl
>>
>> Get rid of all use of perl within R.  The parts
>> of R that use perl have not changed much probably
>> because its too onerous to have to deal with a
>> complex multilanguage setup.  Eliminating perl might
>> speed up improvements in those areas.  This mostly
>> affects the package buildin gprocess which could
>> then be rehosted within R as a package building
>> package.
>
> There is some work in progress on an extensible, R-based
> package mechanism.
>
>>
>> 10. Event Loop
>>
>> Add an event loop mechanism to facilitate GUI
>> programming in R and also to facilitate the development
>> of facilities to allow higher levels of interaction
>> within grid graphics.
>>
>
> Well, there has been work on this that people couldn't agree on.
>
>
> And while we are on the topic of wishlists...
> Generally (i.e. not directed specifically to Gabor),
> the suggestions are very welcome, but so are contributions.
> And for issues such as making the existing R available on handhelds,
> that is a programming task. And I draw a large distinction between
> programming and creative research which is based on new concepts and
> paradigms.  The pool of people working in statistical computing  
> research
> is very small. And to a large extent, their time is consumed with
> programming - making the same thing work on multiple platforms,
> correcting documentation, etc. which are good things, but
> not obviously the best use of available research ability and time.
> There are many more topics that are in progress that represent
> changes to what we can do  rather than just to how we do the same  
> thing.
>
> One of the reasons S (R and S-Plus) is where it is now
> is because in Bell Labs, the idea was to be thinking
> 5 years ahead and both meeting and directing the needs for the future.
> Because of R's popularity (somewhat related to it being free),  
> there is
> an aspect of development that focuses more on software for  
> statisticians
> to use "right now".
> Obviously, th development is a mixture of both the current and the
> future, but there is less of the future and certainly less of the
> longer term directions that is sacrificed by the need to maintain an
> existing system and be backward-compatible.
> If statistics is to fulfill its potential in this modern IT, we  
> need new
> ideas and research into those new ideas. If we focus on basic
> programming tasks (however complex) and demand usability above  
> concepts,
> we risk losing those whose primary focus is in statistical computing
> research from the field.
>
> While R provides statisticians and stat. comp. researchers with a
> terrific vehicle for doing their respective work, it also acts as
> a constraint for doing anything even moderately new. But much (not  
> all)
> of R is based on innovations from the 1970's, 80's and 90's.   And
> as IT evolves at a terrific pace, to keep up with it, we need to be
> forward looking.
>
>
> I'll leave it there - for the moment - and go fight off the ants
> that are invading my desk!  While I wrote this down relatively

Yes, Winter (such as it is around here) has arrived hasn't it? :-)

> rapidly, the ideas have been brewing for a long time. If anyone
> wishes to comment on the theme, I hope they will take a few minutes
> to think about the broad set of issues and tradeoffs.
>
>
>   D.
>
>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> - --
> Duncan Temple Lang                    duncan at wald.ucdavis.edu
> Department of Statistics              work:  (530) 752-4782
> 4210 Mathematical Sciences Building   fax:   (530) 752-7099
> One Shields Ave.
> University of California at Davis
> Davis,
> CA 95616,
> USA
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v1.4.2 (Darwin)
>
> iD8DBQFDt/by9p/Jzwa2QP4RAr6UAJ4mT9C1JcGwlFFJRFVDteyetDrAjACfax7B
> 0MpswqQE442j23WzJjqUADA=
> =Aq8t
> -----END PGP SIGNATURE-----
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

---
Byron Ellis (ellis at stat.harvard.edu)
"Oook" -- The Librarian


From olefc at daimi.au.dk  Mon Jan  2 14:05:43 2006
From: olefc at daimi.au.dk (Ole F. Christensen)
Date: Mon, 02 Jan 2006 14:05:43 +0100
Subject: [Rd] R crash with complex matrix algebra when using EISPACK=TRUE
Message-ID: <43B92527.4040003@daimi.au.dk>


Dear subscribers of R-devel

I am experiencing that R crashes (further details are given below) in
some complex matrix calculations when EISPACK=TRUE has been specified in 
eigen().
I discovered the behaviour some months ago just after the
release of R-2.2.0, and it has been lying on my desk since.
I apologise for not having nailed the problem down to a simple function 
call, but I thought I should better report the problem now
instead of waiting.
My hope is that someone will either spot the cause
of the crash in a minute, or otherwise provide some help for me to
investigate further. 


## The code :


source("http://www.daimi.au.dk/~olefc/TEST/fct.R")
source("http://www.daimi.au.dk/~olefc/TEST/parm.crash.R")

for(l.v in 1:4){
  for(r.v in 1:4){
    for(l.x in 1:4){
      for(r.x in 1:4){
        hvad <- 
inhomoWmat.complex(subst.ratematrix(parm.same.str.sym$Gamma[,,l.v,r.v]),subst.ratematrix(parm.same.str.sym$Gamma[,,l.x,r.x]), 
EISPACK=TRUE)
        print(c(l.v,r.v,l.x,r.x))
      }
    }
  }
}


## gives

[1] 1 1 1 1
[1] 1 1 1 2
[1] 1 1 1 3
[1] 1 1 1 4
[1] 1 1 2 1
Segmentation fault



### whereas the code seems to work fine when EISPACK=FALSE :


source("http://www.daimi.au.dk/~olefc/TEST/fct.R")
source("http://www.daimi.au.dk/~olefc/TEST/parm.crash.R")

for(l.v in 1:4){
  for(r.v in 1:4){
    for(l.x in 1:4){
      for(r.x in 1:4){
        hvad <- 
inhomoWmat.complex(subst.ratematrix(parm.same.str.sym$Gamma[,,l.v,r.v]),subst.ratematrix(parm.same.str.sym$Gamma[,,l.x,r.x]), 
EISPACK=FALSE)
        print(c(l.v,r.v,l.x,r.x))
      }
    }
  }
}

## works fine.


## There is some randomness in how and when the crash happens.
## The crash is either :

Segmentation fault

#

*** glibc detected *** double free or corruption (!prev): 0x08aa7298
    ***

# or

*** glibc detected *** free(): invalid pointer: 0x082bfd20 ***



## Seen on R-2.2-1 and  R-2.2-0 .
## Not seen in R-2.1.1 !
## I haven't investiated whether it happens on Windows also.


### A few details on the matrix calculations :
The eigenvalue decomposition is done on 4 * 4 matrices where the rows 
sum to 0.
The matrices may be on the edge of not being complex diagonalizable.


version
         _
platform i686-pc-linux-gnu
arch     i686
os       linux-gnu
system   i686, linux-gnu
status
major    2
minor    2.1
year     2005
month    12
day      20
svn rev  36812
language R


Thanks in advance of any help.

Ole Christensen

-- 
Ole F. Christensen
BiRC - Bioinformatics Research Center
University of Aarhus


From jmc at r-project.org  Mon Jan  2 17:46:30 2006
From: jmc at r-project.org (John Chambers)
Date: Mon, 02 Jan 2006 08:46:30 -0800
Subject: [Rd] Wish list
In-Reply-To: <43B7F6F2.6080401@wald.ucdavis.edu>
References: <971536df0601010547m488319c9h62a74a8a1b4ad4ad@mail.gmail.com>
	<43B7F6F2.6080401@wald.ucdavis.edu>
Message-ID: <43B958E6.3030500@r-project.org>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20060102/c2c42389/attachment.pl

From maechler at stat.math.ethz.ch  Mon Jan  2 18:00:15 2006
From: maechler at stat.math.ethz.ch (maechler@stat.math.ethz.ch)
Date: Mon,  2 Jan 2006 18:00:15 +0100 (CET)
Subject: [Rd] all.equal() improvements (PR#8191)
Message-ID: <20060102170015.E09C5CD22@slim.kubism.ku.dk>

I've now finally finalized my work on a subset of Andy's
propositions, and committed it to R-devel.

The current change doesn't show in our own checks and examples,
but may well in other people's package checks.
For this reason, I've also added a line to the
'USER-VISIBLE CHANGES' part of the NEWS file.

Martin


From ripley at stats.ox.ac.uk  Mon Jan  2 19:11:56 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 2 Jan 2006 18:11:56 +0000 (GMT)
Subject: [Rd] R crash with complex matrix algebra when using EISPACK=TRUE
In-Reply-To: <43B92527.4040003@daimi.au.dk>
References: <43B92527.4040003@daimi.au.dk>
Message-ID: <Pine.LNX.4.61.0601021810440.19500@gannet.stats>

Try valgrind.  That is reporting use outside arrays in rg, that is the 
non-complex case of eigen().

Otherwise, using gctorture(TRUE) will help precipitate the error.

On Mon, 2 Jan 2006, Ole F. Christensen wrote:

>
> Dear subscribers of R-devel
>
> I am experiencing that R crashes (further details are given below) in
> some complex matrix calculations when EISPACK=TRUE has been specified in
> eigen().
> I discovered the behaviour some months ago just after the
> release of R-2.2.0, and it has been lying on my desk since.
> I apologise for not having nailed the problem down to a simple function
> call, but I thought I should better report the problem now
> instead of waiting.
> My hope is that someone will either spot the cause
> of the crash in a minute, or otherwise provide some help for me to
> investigate further.
>
>
> ## The code :
>
>
> source("http://www.daimi.au.dk/~olefc/TEST/fct.R")
> source("http://www.daimi.au.dk/~olefc/TEST/parm.crash.R")
>
> for(l.v in 1:4){
>  for(r.v in 1:4){
>    for(l.x in 1:4){
>      for(r.x in 1:4){
>        hvad <-
> inhomoWmat.complex(subst.ratematrix(parm.same.str.sym$Gamma[,,l.v,r.v]),subst.ratematrix(parm.same.str.sym$Gamma[,,l.x,r.x]),
> EISPACK=TRUE)
>        print(c(l.v,r.v,l.x,r.x))
>      }
>    }
>  }
> }
>
>
> ## gives
>
> [1] 1 1 1 1
> [1] 1 1 1 2
> [1] 1 1 1 3
> [1] 1 1 1 4
> [1] 1 1 2 1
> Segmentation fault
>
>
>
> ### whereas the code seems to work fine when EISPACK=FALSE :
>
>
> source("http://www.daimi.au.dk/~olefc/TEST/fct.R")
> source("http://www.daimi.au.dk/~olefc/TEST/parm.crash.R")
>
> for(l.v in 1:4){
>  for(r.v in 1:4){
>    for(l.x in 1:4){
>      for(r.x in 1:4){
>        hvad <-
> inhomoWmat.complex(subst.ratematrix(parm.same.str.sym$Gamma[,,l.v,r.v]),subst.ratematrix(parm.same.str.sym$Gamma[,,l.x,r.x]),
> EISPACK=FALSE)
>        print(c(l.v,r.v,l.x,r.x))
>      }
>    }
>  }
> }
>
> ## works fine.
>
>
> ## There is some randomness in how and when the crash happens.
> ## The crash is either :
>
> Segmentation fault
>
> #
>
> *** glibc detected *** double free or corruption (!prev): 0x08aa7298
>    ***
>
> # or
>
> *** glibc detected *** free(): invalid pointer: 0x082bfd20 ***
>
>
>
> ## Seen on R-2.2-1 and  R-2.2-0 .
> ## Not seen in R-2.1.1 !
> ## I haven't investiated whether it happens on Windows also.
>
>
> ### A few details on the matrix calculations :
> The eigenvalue decomposition is done on 4 * 4 matrices where the rows
> sum to 0.
> The matrices may be on the edge of not being complex diagonalizable.
>
>
> version
>         _
> platform i686-pc-linux-gnu
> arch     i686
> os       linux-gnu
> system   i686, linux-gnu
> status
> major    2
> minor    2.1
> year     2005
> month    12
> day      20
> svn rev  36812
> language R
>
>
> Thanks in advance of any help.
>
> Ole Christensen
>
> -- 
> Ole F. Christensen
> BiRC - Bioinformatics Research Center
> University of Aarhus
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From maechler at stat.math.ethz.ch  Mon Jan  2 20:16:17 2006
From: maechler at stat.math.ethz.ch (maechler@stat.math.ethz.ch)
Date: Mon,  2 Jan 2006 20:16:17 +0100 (CET)
Subject: [Rd] all.equal() improvements (PR#8191)
Message-ID: <20060102191617.9C2A5CD24@slim.kubism.ku.dk>

I'm "happy" to have found the first problem myself:

'Matrix' doesn't pass R CMD check  anymore with the change I had
committed:

Basically because of this:

  > all.equal(cbind(1:5), matrix(1:5, 5,1, dimnames=list(NULL,NULL)))
  [1] "Attributes: < Names: Lengths (1, 2) differ (string compare on first 1) >"
  [2] "Attributes: < Length mismatch: comparison on first 1 components >"       

This new behavior is "S-compatible" insofar as S-plus 6.1 also
returns non-TRUE.

Is this what we want?
{we'll see soon how many other CRAN packages are having problems for it}

In my intuition, I'd have liked all.equal()  to return TRUE for the above,
since in principle,  dimnames = NULL  or dimnames = list(NULL,NULL) 
is a trivial difference.
OTOH, it will need "special case" code to assure this, and I
wonder if that's worth it.

Please comment!
Martin

>>>>> "MM" == Martin Maechler <maechler at stat.math.ethz.ch>
>>>>>     on Mon,  2 Jan 2006 18:00:15 +0100 (CET) writes:

    MM> I've now finally finalized my work on a subset of Andy's
    MM> propositions, and committed it to R-devel.

    MM> The current change doesn't show in our own checks and
    MM> examples, but may well in other people's package checks.
    MM> For this reason, I've also added a line to the
    MM> 'USER-VISIBLE CHANGES' part of the NEWS file.

    MM> Martin

    MM> ______________________________________________
    MM> R-devel at r-project.org mailing list
    MM> https://stat.ethz.ch/mailman/listinfo/r-devel


From ripley at stats.ox.ac.uk  Mon Jan  2 21:39:18 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 2 Jan 2006 20:39:18 +0000 (GMT)
Subject: [Rd] all.equal() improvements (PR#8191)
In-Reply-To: <20060102191617.9C2A5CD24@slim.kubism.ku.dk>
References: <20060102191617.9C2A5CD24@slim.kubism.ku.dk>
Message-ID: <Pine.LNX.4.61.0601022021140.5813@gannet.stats>

Martin,

I have some tests running over CRAN now (RUnit has also failed), but have 
already noticed things like

> swiss[, 1] -> x
> names(x) <- rownames(swiss)
> all.equal(x, x[1:10])
[1] "Names: Lengths (47, 10) differ (string compare on first 10)"
[2] "Numeric: lengths (47, 10) differ"

which is telling me the obvious, with the result that the reports from 
e.g. rpart are cluttered to the detriment of legibility.

I think we need to think harder about what should be reported when the
objects differ in mode or length.

Brian

On Mon, 2 Jan 2006 maechler at stat.math.ethz.ch wrote:

> I'm "happy" to have found the first problem myself:
>
> 'Matrix' doesn't pass R CMD check  anymore with the change I had
> committed:

I am seeing a problem in setGeneric which stops it being installed.

>
> Basically because of this:
>
>  > all.equal(cbind(1:5), matrix(1:5, 5,1, dimnames=list(NULL,NULL)))
>  [1] "Attributes: < Names: Lengths (1, 2) differ (string compare on first 1) >"
>  [2] "Attributes: < Length mismatch: comparison on first 1 components >"
>
> This new behavior is "S-compatible" insofar as S-plus 6.1 also
> returns non-TRUE.
>
> Is this what we want?
> {we'll see soon how many other CRAN packages are having problems for it}
>
> In my intuition, I'd have liked all.equal()  to return TRUE for the above,
> since in principle,  dimnames = NULL  or dimnames = list(NULL,NULL)
> is a trivial difference.
> OTOH, it will need "special case" code to assure this, and I
> wonder if that's worth it.
>
> Please comment!
> Martin
>
>>>>>> "MM" == Martin Maechler <maechler at stat.math.ethz.ch>
>>>>>>     on Mon,  2 Jan 2006 18:00:15 +0100 (CET) writes:
>
>    MM> I've now finally finalized my work on a subset of Andy's
>    MM> propositions, and committed it to R-devel.
>
>    MM> The current change doesn't show in our own checks and
>    MM> examples, but may well in other people's package checks.
>    MM> For this reason, I've also added a line to the
>    MM> 'USER-VISIBLE CHANGES' part of the NEWS file.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From maechler at stat.math.ethz.ch  Mon Jan  2 22:38:21 2006
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 2 Jan 2006 22:38:21 +0100
Subject: [Rd] all.equal() improvements (PR#8191)
In-Reply-To: <Pine.LNX.4.61.0601022021140.5813@gannet.stats>
References: <20060102191617.9C2A5CD24@slim.kubism.ku.dk>
	<Pine.LNX.4.61.0601022021140.5813@gannet.stats>
Message-ID: <17337.40269.219873.711052@stat.math.ethz.ch>

>>>>> "BDR" == Prof Brian Ripley <ripley at stats.ox.ac.uk>
>>>>>     on Mon, 2 Jan 2006 20:39:18 +0000 (GMT) writes:

    BDR> Martin,
    BDR> I have some tests running over CRAN now (RUnit has also failed), 

thank you, Brian, for the feedback

    BDR> but have  already noticed things like

    >> swiss[, 1] -> x
    >> names(x) <- rownames(swiss)
    >> all.equal(x, x[1:10])
    BDR> [1] "Names: Lengths (47, 10) differ (string compare on first 10)"
    BDR> [2] "Numeric: lengths (47, 10) differ"

    BDR> which is telling me the obvious, with the result that the reports from 
    BDR> e.g. rpart are cluttered to the detriment of legibility.

    BDR> I think we need to think harder about what should be reported when the
    BDR> objects differ in mode or length.

I agree;  the above is good example.
[OTOH, I don't think the above behavior to be a complete show
 stopper; since it's somewhat close to the way S-plus does things]

    BDR> Brian

    BDR> On Mon, 2 Jan 2006 maechler at stat.math.ethz.ch wrote:

    >> I'm "happy" to have found the first problem myself:
    >> 
    >> 'Matrix' doesn't pass R CMD check  anymore with the change I had
    >> committed:

    BDR> I am seeing a problem in setGeneric which stops it being installed.

{ah yes;  for R-devel you need the "next" version of Matrix
 the important part of which I'll commit shortly to R-packages;  it
 will take another day before I'll upload it to CRAN}


    >> Basically because of this:
    >> 
    >> > all.equal(cbind(1:5), matrix(1:5, 5,1, dimnames=list(NULL,NULL)))
    >> [1] "Attributes: < Names: Lengths (1, 2) differ (string compare on first 1) >"
    >> [2] "Attributes: < Length mismatch: comparison on first 1 components >"
    >> 
    >> This new behavior is "S-compatible" insofar as S-plus 6.1 also
    >> returns non-TRUE.
    >> 
    >> Is this what we want?
    >> {we'll see soon how many other CRAN packages are having problems for it}
    >> 
    >> In my intuition, I'd have liked all.equal()  to return TRUE for the above,
    >> since in principle,  dimnames = NULL  or dimnames = list(NULL,NULL)
    >> is a trivial difference.
    >> OTOH, it will need "special case" code to assure this, and I
    >> wonder if that's worth it.
    >> 
    >> Please comment!
    >> Martin
    >> 
    >>>>>>> "MM" == Martin Maechler <maechler at stat.math.ethz.ch>
    >>>>>>> on Mon,  2 Jan 2006 18:00:15 +0100 (CET) writes:
    >> 
    MM> I've now finally finalized my work on a subset of Andy's
    MM> propositions, and committed it to R-devel.
    >> 
    MM> The current change doesn't show in our own checks and
    MM> examples, but may well in other people's package checks.
    MM> For this reason, I've also added a line to the
    MM> 'USER-VISIBLE CHANGES' part of the NEWS file.

    BDR> -- 
    BDR> Brian D. Ripley,                  ripley at stats.ox.ac.uk
    BDR> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
    BDR> University of Oxford,             Tel:  +44 1865 272861 (self)
    BDR> 1 South Parks Road,                     +44 1865 272866 (PA)
    BDR> Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ross at biostat.ucsf.edu  Mon Jan  2 23:40:18 2006
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Mon, 02 Jan 2006 14:40:18 -0800
Subject: [Rd] checkpointing
Message-ID: <1136241618.5636.10.camel@iron.psg.net>

I would like to checkpoint some of my calculations in R, specifically
those using optim.  As far as I can tell, R doesn't have this facility,
and there seems to have been little discussion of it.

checkpointing is saving enough of the current state so that work can
resume where things were left off if, to take my own example, the system
crashes after 8 days of calculation.

My thought is that this could be added as an option to optim as one of
the control parameters.

I thought I'd check here to see if anyone is aware of any work in this
area or has any thoughts about how to proceed.  In particular, is save a
reasonable way to save a few variables to disk?  I could also make the
code available when/if I get it working.
-- 
Ross Boylan                                      wk:  (415) 514-8146
185 Berry St #5700                               ross at biostat.ucsf.edu
Dept of Epidemiology and Biostatistics           fax: (415) 514-8150
University of California, San Francisco
San Francisco, CA 94107-1739                     hm:  (415) 550-1062


From murdoch at stats.uwo.ca  Tue Jan  3 01:29:15 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Mon, 02 Jan 2006 19:29:15 -0500
Subject: [Rd] xy.coords
In-Reply-To: <971536df0512311309v1d39103am90f10759932e509c@mail.gmail.com>
References: <971536df0512301910k1e98e8e9pd4aa00149fedf1af@mail.gmail.com>	<43B68554.9030505@stats.uwo.ca>	<971536df0512310557l1e3ea702ic9f4444b7583f4a7@mail.gmail.com>	<43B6B983.1060408@stats.uwo.ca>	<971536df0512310921g43f340e6ufec047b7c07f53da@mail.gmail.com>	<43B6C44A.10103@stats.uwo.ca>	<971536df0512310957y750d8eb7oa23f38aa39db647c@mail.gmail.com>	<43B6CD5B.4040307@stats.uwo.ca>	<971536df0512311226r1b9817a1q206bbe1a72a7d800@mail.gmail.com>	<43B6EC80.7080202@stats.uwo.ca>
	<971536df0512311309v1d39103am90f10759932e509c@mail.gmail.com>
Message-ID: <43B9C55B.1050708@stats.uwo.ca>

On 12/31/2005 4:09 PM, Gabor Grothendieck wrote:
> On 12/31/05, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> 
>>On 12/31/2005 3:26 PM, Gabor Grothendieck wrote:
>>
>>>I think this is just playng with words.
>>
>>I'm starting to be convinced of that by the fact that you haven't posted
>>any sample code where using a single parameter would be desirable.
> 
> 
> Loose coupling is a general principle that should be followed as a matter
> of course and does not need case by case justification.  If there were
> a performance issue, say, one might justify circumventing
> otherwise desirable principles but there is no conflicting tradeoff here.

Generally I agree, but I've just committed the doc change only, for 
these reasons:

  - xy.coords is likely to be used by high-level plot functions that 
have  inputs like plot.default; if they follow its pattern closely, then 
they'll never need a one-parameter call.  This will encourage consistency.

  - the interface to those functions has been unchanged for years, and I 
don't like changing old interfaces without strong reasons.

This was really a borderline case, but the fact that I couldn't think of 
a situation where it would be good to use a one parameter call to 
xy.coords tipped the balance in my mind.

Duncan Murdoch


> 
> 
> 
>>The fact that its always been
>>
>>>like that is not sufficient and is not related to consistency.
>>>xyz.coords also does not work in accordance with the help file
>>>so the fact that the error extends to it just means they are both
>>>in error.
>>
>>>Modularity means loose coupling -- i.e. a function should be
>>>as independent as possible from its surroundings.  The fact
>>>that the second argument is not missing in uses within R base
>>>is not a valid argument for appropriate attention to this principle.
>>>
>>>Furthermore, its clear that the current way it works is not even
>>>the intended way -- the intended and better way is as documented
>>>and the software, not the documentation, ought to be changed.
>>
>>Take a look at the examples.  It's pretty clear that it is working as
>>intended, and the documentation incorrectly says "missing" where it
>>means "NULL".
>>
>>Duncan Murdoch
>>
>>>
>>>On 12/31/05, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
>>>
>>>
>>>>On 12/31/2005 12:57 PM, Gabor Grothendieck wrote:
>>>>
>>>>
>>>>>It does not achieve design consistency.
>>>>
>>>>It's consistent with the way it has been for at least 7 years, and is
>>>>consistent with xyz.coords().
>>>>
>>>>One would have to
>>>>
>>>>
>>>>>specify NULL but that should not really be necessary.
>>>>
>>>>In fact, one almost never needs to specify NULL there.  It's the default
>>>>value for y in the high level functions that call xy.coords, so it is
>>>>put there automatically.
>>>>
>>>>Duncan Murdoch
>>>>
>>>>
>>>>
>>>>>On 12/31/05, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
>>>>>
>>>>>
>>>>>
>>>>>>On 12/31/2005 12:21 PM, Gabor Grothendieck wrote:
>>>>>>
>>>>>>
>>>>>>
>>>>>>>I think the point is that (1) it does not work as documented and (2) in
>>>>>>>most functions one can omit unnecessary args without having
>>>>>>>to specify NULL so its behvaior seems inconsistent from a design
>>>>>>>viewpoint.  By allowing either missing or NULL it will work as documented,
>>>>>>>and probably intended, yet continue to be backward compatible with
>>>>>>>existing usages.
>>>>>>
>>>>>>But a simpler change is to change the documentation, and it achieves all
>>>>>>of those objectives.
>>>>>>
>>>>>>Duncan Murdoch
>>>>>>
>>>>>>
>>>>>>
>>>>>>>On 12/31/05, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>>On 12/31/2005 8:57 AM, Gabor Grothendieck wrote:
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>>>It could be changed to missing(y) || is.null(y) and the docs amended.
>>>>>>>>>That way existing code will continue to work and code that otherwise
>>>>>>>>>gives an error currently, but should have worked, will now work too.
>>>>>>>>
>>>>>>>>Can you give an example where you would want to use xy.coords(y ~ x)?
>>>>>>>>Normally xy.coords() is used in other functions, and they can default y
>>>>>>>>to NULL (see plot.default, for example).
>>>>>>>>
>>>>>>>>Duncan Murdoch
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>>>On 12/31/05, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>>On 12/30/2005 10:10 PM, Gabor Grothendieck wrote:
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>>>In ?xy.coords it says:
>>>>>>>>>>>
>>>>>>>>>>> If 'y' is missing and 'x' is a
>>>>>>>>>>>
>>>>>>>>>>> formula: of the form 'yvar ~ xvar'. 'xvar' and 'yvar' are used as
>>>>>>>>>>>      x and y variables.
>>>>>>>>>>>
>>>>>>>>>>> list: containing components 'x' and 'y', these are used to define
>>>>>>>>>>>      plotting coordinates.
>>>>>>>>>>>
>>>>>>>>>>> time series: the x values are taken to be 'time(x)' and the y
>>>>>>>>>>>      values to be the time series.
>>>>>>>>>>>
>>>>>>>>>>> matrix with two columns: the first is assumed to contain the x
>>>>>>>>>>>      values and the second the y values.
>>>>>>>>>>>
>>>>>>>>>>>however, in fact, if y is missing an error is given. e.g.
>>>>>>>>>>>
>>>>>>>>>>>x <- 1:3
>>>>>>>>>>>y <- 4:6
>>>>>>>>>>>xy.coords(y ~ x) # error
>>>>>>>>>>>xy.coords(cbind(x, y)) # error
>>>>>>>>>>>xy.coords(ts(y)) # error
>>>>>>>>>>>
>>>>>>>>>>>Looking at the code, is.null(y) in the first line of the
>>>>>>>>>>>body should be missing(y) .
>>>>>>>>>>
>>>>>>>>>>It would be better to change the docs to say "if 'y' is NULL ...".  The
>>>>>>>>>>code has been the way it is for years and years, and is widely used.
>>>>>>>>>>
>>>>>>>>>>Changing the test to missing(y) would mean all existing uses that put a
>>>>>>>>>>NULL there would need to be changed.
>>>>>>>>>>
>>>>>>>>>>Adding a default value of NULL to y would have less impact, but I'd
>>>>>>>>>>still be worried about it having long-range bad effects.
>>>>>>>>>>
>>>>>>>>>>Duncan Murdoch
>>>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>______________________________________________
>>>>>R-devel at r-project.org mailing list
>>>>>https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>
>>>>
>>>______________________________________________
>>>R-devel at r-project.org mailing list
>>>https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From mark.bravington at csiro.au  Tue Jan  3 03:07:26 2006
From: mark.bravington at csiro.au (mark.bravington@csiro.au)
Date: Tue,  3 Jan 2006 03:07:26 +0100 (CET)
Subject: [Rd] load, environment[[, and attr<-/attributes<- (PR#8457)
Message-ID: <20060103020726.88AE0CD1B@slim.kubism.ku.dk>

Full_Name: Mark Bravington
Version: 2.2.1
OS: Windows XP
Submission from: (NULL) (203.132.243.69)


#       r-bugs at r-project.org

There is a bug to do with 'load', environment access via '[[', and 'attr<-' or
'attributes<-'. Modifying the attributes of a *copy* of an object can modify the
original too, under certain conditions:

 - the copy needs to be created using env[[ not by env$ nor just by name
 - the original object must have been 'load'ed and not subsequently
read-accessed before the copy was created
 
The script below might clarify this. BTW the problem is not only for
.GlobalEnv.

It's intriguing that 'load' doesn't seem to be "fully creating" the object-- is
it just creating a promise or something like that?

Mark Bravington
mark.bravington at csiro.au

a <- 1
attr( a, 'thing') <- 99
  
tf <- tempfile()
save( a, file=tf)

load( tf)
y <- .GlobalEnv[[ 'a']]
attr( y, 'thing') <- NULL
a # attr gone!

load( tf)
y <- .GlobalEnv$a
attr( y, 'thing') <- NULL
a # OK

load( tf)
a # to force access
y <- .GlobalEnv[[ 'a']]
attr( y, 'thing') <- NULL
a # OK

unlink( tf)



--please do not edit the information below--

Version:
 platform = i386-pc-mingw32
 arch = i386
 os = mingw32
 system = i386, mingw32
 status = 
 major = 2
 minor = 2.1
 year = 2005
 month = 12
 day = 20
 svn rev = 36812
 language = R

Windows XP Professional (build 2600) Service Pack 1.0

Locale:
LC_COLLATE=English_Australia.1252;LC_CTYPE=English_Australia.1252;LC_MONETARY=English_Australia.1252;LC_NUMERIC=C;LC_TIME=English_Australia.1252

Search Path:
 .GlobalEnv, package:methods, package:stats, package:graphics,
package:grDevices, package:utils, package:datasets, Autoloads, package:base


From ripley at stats.ox.ac.uk  Tue Jan  3 09:36:21 2006
From: ripley at stats.ox.ac.uk (Brian D Ripley)
Date: Tue, 3 Jan 2006 08:36:21 +0000 (GMT)
Subject: [Rd] checkpointing
In-Reply-To: <1136241618.5636.10.camel@iron.psg.net>
Message-ID: <Pine.GSO.4.31.0601030832230.5822-100000@markov.stats>

I use save.image() or save(), which seem exactly what you are asking for.

On Mon, 2 Jan 2006, Ross Boylan wrote:

> I would like to checkpoint some of my calculations in R, specifically
> those using optim.  As far as I can tell, R doesn't have this facility,
> and there seems to have been little discussion of it.
>
> checkpointing is saving enough of the current state so that work can
> resume where things were left off if, to take my own example, the system
> crashes after 8 days of calculation.
>
> My thought is that this could be added as an option to optim as one of
> the control parameters.
>
> I thought I'd check here to see if anyone is aware of any work in this
> area or has any thoughts about how to proceed.  In particular, is save a
> reasonable way to save a few variables to disk?  I could also make the
> code available when/if I get it working.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From olefc at daimi.au.dk  Tue Jan  3 11:32:24 2006
From: olefc at daimi.au.dk (Ole F. Christensen)
Date: Tue, 03 Jan 2006 11:32:24 +0100
Subject: [Rd] R crash with complex matrix algebra when using EISPACK=TRUE
In-Reply-To: <Pine.LNX.4.61.0601021810440.19500@gannet.stats>
References: <43B92527.4040003@daimi.au.dk>
	<Pine.LNX.4.61.0601021810440.19500@gannet.stats>
Message-ID: <43BA52B8.4000407@daimi.au.dk>

Brain, Thank you very much for your help.
Using gctorture I was able to produce a simple function call showing the 
problem.


Gm <- rbind(c(-0.3194373786, 0.2444066686, 0.0428108831,  3.221983e-02),
                     c(0.0002071301, -0.0003282719,  0.0001211418,  
5.128830e-12),
                     c(0.0621332005,  0.0545850010, -0.2098487035,  
9.313050e-02),
                     c(0.0280936142,  0.0586642184,  0.1658310277, 
-2.525889e-01)
)
print(Gm)
temp <- eigen(Gm)
print(temp)
gctorture(TRUE)
temp <- eigen(Gm, EISPACK = TRUE)



###
# On my computer I get :
##

 > gctorture(TRUE)
 >
 > source("http://www.daimi.au.dk/~olefc/TEST/Gm.R")
 > print(Gm)
              [,1]          [,2]          [,3]          [,4]
[1,] -0.3194373786  0.2444066686  0.0428108831  3.221983e-02
[2,]  0.0002071301 -0.0003282719  0.0001211418  5.128830e-12
[3,]  0.0621332005  0.0545850010 -0.2098487035  9.313050e-02
[4,]  0.0280936142  0.0586642184  0.1658310277 -2.525889e-01
 >
 > temp <- eigen(Gm)
 > print(temp)
$values
[1] -3.464342e-01+1.3161e-03i -3.464342e-01-1.3161e-03i
[3] -8.933476e-02+0.0000e+00i  9.052031e-19+0.0000e+00i

$vectors
                          [,1]                      [,2]            [,3]
[1,] -0.3419128709-0.03748199i -0.3419128709+0.03748199i -0.222056433+0i
[2,]  0.0003508445+0.00001921i  0.0003508445-0.00001921i  0.001421758+0i
[3,] -0.4179745717+0.01301547i -0.4179745717-0.01301547i -0.664932225+0i
[4,]  0.8407249376+0.00000000i  0.8407249376+0.00000000i -0.713129761+0i
        [,4]
[1,] -0.5+0i
[2,] -0.5+0i
[3,] -0.5+0i
[4,] -0.5+0i

 > temp <- eigen(Gm, EISPACK = TRUE)
*** glibc detected *** free(): invalid pointer: 0x08c4e778 ***
Aborted



# Should I submit this as a bug report also ?


Best

Ole



Prof Brian Ripley wrote:

> Try valgrind.  That is reporting use outside arrays in rg, that is the 
> non-complex case of eigen().
>
> Otherwise, using gctorture(TRUE) will help precipitate the error.
>
> On Mon, 2 Jan 2006, Ole F. Christensen wrote:
>
>>
>> Dear subscribers of R-devel
>>
>> I am experiencing that R crashes (further details are given below) in
>> some complex matrix calculations when EISPACK=TRUE has been specified in
>> eigen().
>> I discovered the behaviour some months ago just after the
>> release of R-2.2.0, and it has been lying on my desk since.
>> I apologise for not having nailed the problem down to a simple function
>> call, but I thought I should better report the problem now
>> instead of waiting.
>> My hope is that someone will either spot the cause
>> of the crash in a minute, or otherwise provide some help for me to
>> investigate further.
>>
>>
>> ## The code :
>>
>>
>> source("http://www.daimi.au.dk/~olefc/TEST/fct.R")
>> source("http://www.daimi.au.dk/~olefc/TEST/parm.crash.R")
>>
>> for(l.v in 1:4){
>>  for(r.v in 1:4){
>>    for(l.x in 1:4){
>>      for(r.x in 1:4){
>>        hvad <-
>> inhomoWmat.complex(subst.ratematrix(parm.same.str.sym$Gamma[,,l.v,r.v]),subst.ratematrix(parm.same.str.sym$Gamma[,,l.x,r.x]), 
>>
>> EISPACK=TRUE)
>>        print(c(l.v,r.v,l.x,r.x))
>>      }
>>    }
>>  }
>> }
>>
>>
>> ## gives
>>
>> [1] 1 1 1 1
>> [1] 1 1 1 2
>> [1] 1 1 1 3
>> [1] 1 1 1 4
>> [1] 1 1 2 1
>> Segmentation fault
>>
>>
>>
>> ### whereas the code seems to work fine when EISPACK=FALSE :
>>
>>
>> source("http://www.daimi.au.dk/~olefc/TEST/fct.R")
>> source("http://www.daimi.au.dk/~olefc/TEST/parm.crash.R")
>>
>> for(l.v in 1:4){
>>  for(r.v in 1:4){
>>    for(l.x in 1:4){
>>      for(r.x in 1:4){
>>        hvad <-
>> inhomoWmat.complex(subst.ratematrix(parm.same.str.sym$Gamma[,,l.v,r.v]),subst.ratematrix(parm.same.str.sym$Gamma[,,l.x,r.x]), 
>>
>> EISPACK=FALSE)
>>        print(c(l.v,r.v,l.x,r.x))
>>      }
>>    }
>>  }
>> }
>>
>> ## works fine.
>>
>>
>> ## There is some randomness in how and when the crash happens.
>> ## The crash is either :
>>
>> Segmentation fault
>>
>> #
>>
>> *** glibc detected *** double free or corruption (!prev): 0x08aa7298
>>    ***
>>
>> # or
>>
>> *** glibc detected *** free(): invalid pointer: 0x082bfd20 ***
>>
>>
>>
>> ## Seen on R-2.2-1 and  R-2.2-0 .
>> ## Not seen in R-2.1.1 !
>> ## I haven't investiated whether it happens on Windows also.
>>
>>
>> ### A few details on the matrix calculations :
>> The eigenvalue decomposition is done on 4 * 4 matrices where the rows
>> sum to 0.
>> The matrices may be on the edge of not being complex diagonalizable.
>>
>>
>> version
>>         _
>> platform i686-pc-linux-gnu
>> arch     i686
>> os       linux-gnu
>> system   i686, linux-gnu
>> status
>> major    2
>> minor    2.1
>> year     2005
>> month    12
>> day      20
>> svn rev  36812
>> language R
>>
>>
>> Thanks in advance of any help.
>>
>> Ole Christensen
>>
>> -- 
>> Ole F. Christensen
>> BiRC - Bioinformatics Research Center
>> University of Aarhus
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>

-- 
Ole F. Christensen
BiRC - Bioinformatics Research Center
University of Aarhus


From ripley at stats.ox.ac.uk  Tue Jan  3 12:56:18 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 3 Jan 2006 11:56:18 +0000 (GMT)
Subject: [Rd] R crash with complex matrix algebra when using EISPACK=TRUE
In-Reply-To: <43BA52B8.4000407@daimi.au.dk>
References: <43B92527.4040003@daimi.au.dk>
	<Pine.LNX.4.61.0601021810440.19500@gannet.stats>
	<43BA52B8.4000407@daimi.au.dk>
Message-ID: <Pine.LNX.4.61.0601031154330.4622@gannet.stats>

Well, valgrind helps a lot more here: it points at lines 2131 and 2135-6 
of eigen.f, and using gdb shows those are called with NA = 0.

So it is a bug in EISPACK, and easy enough to fix -- now done.

On Tue, 3 Jan 2006, Ole F. Christensen wrote:

> Brain, Thank you very much for your help.
> Using gctorture I was able to produce a simple function call showing the
> problem.
>
>
> Gm <- rbind(c(-0.3194373786, 0.2444066686, 0.0428108831,  3.221983e-02),
>                     c(0.0002071301, -0.0003282719,  0.0001211418,
> 5.128830e-12),
>                     c(0.0621332005,  0.0545850010, -0.2098487035,
> 9.313050e-02),
>                     c(0.0280936142,  0.0586642184,  0.1658310277,
> -2.525889e-01)
> )
> print(Gm)
> temp <- eigen(Gm)
> print(temp)
> gctorture(TRUE)
> temp <- eigen(Gm, EISPACK = TRUE)
>
>
>
> ###
> # On my computer I get :
> ##
>
> > gctorture(TRUE)
> >
> > source("http://www.daimi.au.dk/~olefc/TEST/Gm.R")
> > print(Gm)
>              [,1]          [,2]          [,3]          [,4]
> [1,] -0.3194373786  0.2444066686  0.0428108831  3.221983e-02
> [2,]  0.0002071301 -0.0003282719  0.0001211418  5.128830e-12
> [3,]  0.0621332005  0.0545850010 -0.2098487035  9.313050e-02
> [4,]  0.0280936142  0.0586642184  0.1658310277 -2.525889e-01
> >
> > temp <- eigen(Gm)
> > print(temp)
> $values
> [1] -3.464342e-01+1.3161e-03i -3.464342e-01-1.3161e-03i
> [3] -8.933476e-02+0.0000e+00i  9.052031e-19+0.0000e+00i
>
> $vectors
>                          [,1]                      [,2]            [,3]
> [1,] -0.3419128709-0.03748199i -0.3419128709+0.03748199i -0.222056433+0i
> [2,]  0.0003508445+0.00001921i  0.0003508445-0.00001921i  0.001421758+0i
> [3,] -0.4179745717+0.01301547i -0.4179745717-0.01301547i -0.664932225+0i
> [4,]  0.8407249376+0.00000000i  0.8407249376+0.00000000i -0.713129761+0i
>        [,4]
> [1,] -0.5+0i
> [2,] -0.5+0i
> [3,] -0.5+0i
> [4,] -0.5+0i
>
> > temp <- eigen(Gm, EISPACK = TRUE)
> *** glibc detected *** free(): invalid pointer: 0x08c4e778 ***
> Aborted
>
>
>
> # Should I submit this as a bug report also ?
>
>
> Best
>
> Ole
>
>
>
> Prof Brian Ripley wrote:
>
>> Try valgrind.  That is reporting use outside arrays in rg, that is the
>> non-complex case of eigen().
>>
>> Otherwise, using gctorture(TRUE) will help precipitate the error.
>>
>> On Mon, 2 Jan 2006, Ole F. Christensen wrote:
>>
>>>
>>> Dear subscribers of R-devel
>>>
>>> I am experiencing that R crashes (further details are given below) in
>>> some complex matrix calculations when EISPACK=TRUE has been specified in
>>> eigen().
>>> I discovered the behaviour some months ago just after the
>>> release of R-2.2.0, and it has been lying on my desk since.
>>> I apologise for not having nailed the problem down to a simple function
>>> call, but I thought I should better report the problem now
>>> instead of waiting.
>>> My hope is that someone will either spot the cause
>>> of the crash in a minute, or otherwise provide some help for me to
>>> investigate further.
>>>
>>>
>>> ## The code :
>>>
>>>
>>> source("http://www.daimi.au.dk/~olefc/TEST/fct.R")
>>> source("http://www.daimi.au.dk/~olefc/TEST/parm.crash.R")
>>>
>>> for(l.v in 1:4){
>>>  for(r.v in 1:4){
>>>    for(l.x in 1:4){
>>>      for(r.x in 1:4){
>>>        hvad <-
>>> inhomoWmat.complex(subst.ratematrix(parm.same.str.sym$Gamma[,,l.v,r.v]),subst.ratematrix(parm.same.str.sym$Gamma[,,l.x,r.x]),
>>>
>>> EISPACK=TRUE)
>>>        print(c(l.v,r.v,l.x,r.x))
>>>      }
>>>    }
>>>  }
>>> }
>>>
>>>
>>> ## gives
>>>
>>> [1] 1 1 1 1
>>> [1] 1 1 1 2
>>> [1] 1 1 1 3
>>> [1] 1 1 1 4
>>> [1] 1 1 2 1
>>> Segmentation fault
>>>
>>>
>>>
>>> ### whereas the code seems to work fine when EISPACK=FALSE :
>>>
>>>
>>> source("http://www.daimi.au.dk/~olefc/TEST/fct.R")
>>> source("http://www.daimi.au.dk/~olefc/TEST/parm.crash.R")
>>>
>>> for(l.v in 1:4){
>>>  for(r.v in 1:4){
>>>    for(l.x in 1:4){
>>>      for(r.x in 1:4){
>>>        hvad <-
>>> inhomoWmat.complex(subst.ratematrix(parm.same.str.sym$Gamma[,,l.v,r.v]),subst.ratematrix(parm.same.str.sym$Gamma[,,l.x,r.x]),
>>>
>>> EISPACK=FALSE)
>>>        print(c(l.v,r.v,l.x,r.x))
>>>      }
>>>    }
>>>  }
>>> }
>>>
>>> ## works fine.
>>>
>>>
>>> ## There is some randomness in how and when the crash happens.
>>> ## The crash is either :
>>>
>>> Segmentation fault
>>>
>>> #
>>>
>>> *** glibc detected *** double free or corruption (!prev): 0x08aa7298
>>>    ***
>>>
>>> # or
>>>
>>> *** glibc detected *** free(): invalid pointer: 0x082bfd20 ***
>>>
>>>
>>>
>>> ## Seen on R-2.2-1 and  R-2.2-0 .
>>> ## Not seen in R-2.1.1 !
>>> ## I haven't investiated whether it happens on Windows also.
>>>
>>>
>>> ### A few details on the matrix calculations :
>>> The eigenvalue decomposition is done on 4 * 4 matrices where the rows
>>> sum to 0.
>>> The matrices may be on the edge of not being complex diagonalizable.
>>>
>>>
>>> version
>>>         _
>>> platform i686-pc-linux-gnu
>>> arch     i686
>>> os       linux-gnu
>>> system   i686, linux-gnu
>>> status
>>> major    2
>>> minor    2.1
>>> year     2005
>>> month    12
>>> day      20
>>> svn rev  36812
>>> language R
>>>
>>>
>>> Thanks in advance of any help.
>>>
>>> Ole Christensen
>>>
>>> --
>>> Ole F. Christensen
>>> BiRC - Bioinformatics Research Center
>>> University of Aarhus
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>>
>>
>
> -- 
> Ole F. Christensen
> BiRC - Bioinformatics Research Center
> University of Aarhus
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From p.dalgaard at biostat.ku.dk  Tue Jan  3 13:35:49 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 03 Jan 2006 13:35:49 +0100
Subject: [Rd] R crash with complex matrix algebra when using EISPACK=TRUE
In-Reply-To: <43BA52B8.4000407@daimi.au.dk>
References: <43B92527.4040003@daimi.au.dk>
	<Pine.LNX.4.61.0601021810440.19500@gannet.stats>
	<43BA52B8.4000407@daimi.au.dk>
Message-ID: <x2bqyth4ka.fsf@viggo.kubism.ku.dk>

"Ole F. Christensen" <olefc at daimi.au.dk> writes:

> Brain, Thank you very much for your help.
  *****

You seem to be using call-by-value semantics rather than
call-by-name... 


-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From khansen at stat.Berkeley.EDU  Tue Jan  3 14:14:00 2006
From: khansen at stat.Berkeley.EDU (Kasper Daniel Hansen)
Date: Tue, 3 Jan 2006 14:14:00 +0100
Subject: [Rd] checkpointing
In-Reply-To: <Pine.GSO.4.31.0601030832230.5822-100000@markov.stats>
References: <Pine.GSO.4.31.0601030832230.5822-100000@markov.stats>
Message-ID: <BCA2993F-D89F-4054-BB33-495B2EA8B74F@stat.berkeley.edu>

On Jan 3, 2006, at 9:36 AM, Brian D Ripley wrote:

> I use save.image() or save(), which seem exactly what you are  
> asking for.

I have the (perhaps unsupported) impression that Ross wanted to save  
the progress during the optim run. Since it spends most of its time  
in the .Internal(optim(***)) call, save/save.image would not work.

/Kasper

> On Mon, 2 Jan 2006, Ross Boylan wrote:
>
>> I would like to checkpoint some of my calculations in R, specifically
>> those using optim.  As far as I can tell, R doesn't have this  
>> facility,
>> and there seems to have been little discussion of it.
>>
>> checkpointing is saving enough of the current state so that work can
>> resume where things were left off if, to take my own example, the  
>> system
>> crashes after 8 days of calculation.
>>
>> My thought is that this could be added as an option to optim as  
>> one of
>> the control parameters.
>>
>> I thought I'd check here to see if anyone is aware of any work in  
>> this
>> area or has any thoughts about how to proceed.  In particular, is  
>> save a
>> reasonable way to save a few variables to disk?  I could also make  
>> the
>> code available when/if I get it working.
>
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From ggrothendieck at gmail.com  Tue Jan  3 14:21:08 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 3 Jan 2006 08:21:08 -0500
Subject: [Rd] checkpointing
In-Reply-To: <BCA2993F-D89F-4054-BB33-495B2EA8B74F@stat.berkeley.edu>
References: <Pine.GSO.4.31.0601030832230.5822-100000@markov.stats>
	<BCA2993F-D89F-4054-BB33-495B2EA8B74F@stat.berkeley.edu>
Message-ID: <971536df0601030521u4377de72jfbd1ff4499e7deed@mail.gmail.com>

One possibility for overcoming this problem might be to divide the
variables being optimized over into two sets using a grid over one
set (which should probably consist of only one or two variables) and then
fixing the gridded variables use optim over the rest.  In many problems its
really just one or two variables that cause all the problems and if that
were the case, each of the many runs of optim would be fast
and one could save its state upon completion.

Of course it would be even more convenient if there were some
builtin facility as the poster stated but this might work depending
on the particulars of the problem.

On 1/3/06, Kasper Daniel Hansen <khansen at stat.berkeley.edu> wrote:
> On Jan 3, 2006, at 9:36 AM, Brian D Ripley wrote:
>
> > I use save.image() or save(), which seem exactly what you are
> > asking for.
>
> I have the (perhaps unsupported) impression that Ross wanted to save
> the progress during the optim run. Since it spends most of its time
> in the .Internal(optim(***)) call, save/save.image would not work.
>
> /Kasper
>
> > On Mon, 2 Jan 2006, Ross Boylan wrote:
> >
> >> I would like to checkpoint some of my calculations in R, specifically
> >> those using optim.  As far as I can tell, R doesn't have this
> >> facility,
> >> and there seems to have been little discussion of it.
> >>
> >> checkpointing is saving enough of the current state so that work can
> >> resume where things were left off if, to take my own example, the
> >> system
> >> crashes after 8 days of calculation.
> >>
> >> My thought is that this could be added as an option to optim as
> >> one of
> >> the control parameters.
> >>
> >> I thought I'd check here to see if anyone is aware of any work in
> >> this
> >> area or has any thoughts about how to proceed.  In particular, is
> >> save a
> >> reasonable way to save a few variables to disk?  I could also make
> >> the
> >> code available when/if I get it working.
> >
> > --
> > Brian D. Ripley,                  ripley at stats.ox.ac.uk
> > Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> > University of Oxford,             Tel:  +44 1865 272861 (self)
> > 1 South Parks Road,                     +44 1865 272866 (PA)
> > Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From ripley at stats.ox.ac.uk  Tue Jan  3 14:26:39 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 3 Jan 2006 13:26:39 +0000 (GMT)
Subject: [Rd] checkpointing
In-Reply-To: <BCA2993F-D89F-4054-BB33-495B2EA8B74F@stat.berkeley.edu>
References: <Pine.GSO.4.31.0601030832230.5822-100000@markov.stats>
	<BCA2993F-D89F-4054-BB33-495B2EA8B74F@stat.berkeley.edu>
Message-ID: <Pine.LNX.4.61.0601031320220.13843@gannet.stats>

On Tue, 3 Jan 2006, Kasper Daniel Hansen wrote:

> On Jan 3, 2006, at 9:36 AM, Brian D Ripley wrote:
>
>> I use save.image() or save(), which seem exactly what you are asking for.
>
> I have the (perhaps unsupported) impression that Ross wanted to save the 
> progress during the optim run. Since it spends most of its time in the 
> .Internal(optim(***)) call, save/save.image would not work.

It certainly does not!  It is most likely spending time in the callbacks 
to evaluate the function/gradient.  We have used save() to save the 
current information (e.g. current parameter values) from inside optim so a 
restart could be done, but then I have only once encountered someone 
running a single optimization for over a week: there normally are ways to 
speed things up.

> /Kasper
>
>> On Mon, 2 Jan 2006, Ross Boylan wrote:
>> 
>>> I would like to checkpoint some of my calculations in R, specifically
>>> those using optim.  As far as I can tell, R doesn't have this facility,
>>> and there seems to have been little discussion of it.
>>> 
>>> checkpointing is saving enough of the current state so that work can
>>> resume where things were left off if, to take my own example, the system
>>> crashes after 8 days of calculation.
>>> 
>>> My thought is that this could be added as an option to optim as one of
>>> the control parameters.
>>> 
>>> I thought I'd check here to see if anyone is aware of any work in this
>>> area or has any thoughts about how to proceed.  In particular, is save a
>>> reasonable way to save a few variables to disk?  I could also make the
>>> code available when/if I get it working.
>> 
>> -- 
>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>> University of Oxford,             Tel:  +44 1865 272861 (self)
>> 1 South Parks Road,                     +44 1865 272866 (PA)
>> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From rpeng at jhsph.edu  Tue Jan  3 14:30:54 2006
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Tue, 03 Jan 2006 08:30:54 -0500
Subject: [Rd] checkpointing
In-Reply-To: <1136241618.5636.10.camel@iron.psg.net>
References: <1136241618.5636.10.camel@iron.psg.net>
Message-ID: <43BA7C8E.5020109@jhsph.edu>

One possibility is to write in some checkpointing into your objective function, 
such as saving the current parameter values via 'save()' or 'dput()'.

-roger

Ross Boylan wrote:
> I would like to checkpoint some of my calculations in R, specifically
> those using optim.  As far as I can tell, R doesn't have this facility,
> and there seems to have been little discussion of it.
> 
> checkpointing is saving enough of the current state so that work can
> resume where things were left off if, to take my own example, the system
> crashes after 8 days of calculation.
> 
> My thought is that this could be added as an option to optim as one of
> the control parameters.
> 
> I thought I'd check here to see if anyone is aware of any work in this
> area or has any thoughts about how to proceed.  In particular, is save a
> reasonable way to save a few variables to disk?  I could also make the
> code available when/if I get it working.

-- 
Roger D. Peng  |  http://www.biostat.jhsph.edu/~rpeng/


From B.Rowlingson at lancaster.ac.uk  Tue Jan  3 14:38:06 2006
From: B.Rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Tue, 03 Jan 2006 13:38:06 +0000
Subject: [Rd] checkpointing
In-Reply-To: <43BA7C8E.5020109@jhsph.edu>
References: <1136241618.5636.10.camel@iron.psg.net>
	<43BA7C8E.5020109@jhsph.edu>
Message-ID: <43BA7E3E.1030306@lancaster.ac.uk>

Roger D. Peng wrote:
> One possibility is to write in some checkpointing into your objective function, 
> such as saving the current parameter values via 'save()' or 'dput()'.

  Has anyone successfully checkpointed and restarted R using any of the 
linux process checkpointing solutions I find when I google for 'linux 
process checkpointing'? I cant see why you'd bother implementing 
checkpointing within optim() if you can do it at the process level and 
hence in the middle of anything.

  Unless you're running Windows.

An example and some links here:

  http://www.cise.ufl.edu/~mfoster/research/uclik/uclik.htm

Barry


From khansen at stat.Berkeley.EDU  Tue Jan  3 15:09:14 2006
From: khansen at stat.Berkeley.EDU (Kasper Daniel Hansen)
Date: Tue, 3 Jan 2006 15:09:14 +0100
Subject: [Rd] checkpointing
In-Reply-To: <Pine.LNX.4.61.0601031320220.13843@gannet.stats>
References: <Pine.GSO.4.31.0601030832230.5822-100000@markov.stats>
	<BCA2993F-D89F-4054-BB33-495B2EA8B74F@stat.berkeley.edu>
	<Pine.LNX.4.61.0601031320220.13843@gannet.stats>
Message-ID: <A5AC3A50-281C-457F-8B31-02B3F6DE9FF6@stat.Berkeley.EDU>


On Jan 3, 2006, at 2:26 PM, Prof Brian Ripley wrote:

> On Tue, 3 Jan 2006, Kasper Daniel Hansen wrote:
>
>> On Jan 3, 2006, at 9:36 AM, Brian D Ripley wrote:
>>
>>> I use save.image() or save(), which seem exactly what you are  
>>> asking for.
>>
>> I have the (perhaps unsupported) impression that Ross wanted to  
>> save the progress during the optim run. Since it spends most of  
>> its time in the .Internal(optim(***)) call, save/save.image would  
>> not work.
>
> It certainly does not!  It is most likely spending time in the  
> callbacks to evaluate the function/gradient.  We have used save()  
> to save the current information (e.g. current parameter values)  
> from inside optim so a restart could be done, but then I have only  
> once encountered someone running a single optimization for over a  
> week: there normally are ways to speed things up.

I stand corrected. Actually I should have thought of this.
.
/Kasper


>> /Kasper
>>
>>> On Mon, 2 Jan 2006, Ross Boylan wrote:
>>>> I would like to checkpoint some of my calculations in R,  
>>>> specifically
>>>> those using optim.  As far as I can tell, R doesn't have this  
>>>> facility,
>>>> and there seems to have been little discussion of it.
>>>> checkpointing is saving enough of the current state so that work  
>>>> can
>>>> resume where things were left off if, to take my own example,  
>>>> the system
>>>> crashes after 8 days of calculation.
>>>> My thought is that this could be added as an option to optim as  
>>>> one of
>>>> the control parameters.
>>>> I thought I'd check here to see if anyone is aware of any work  
>>>> in this
>>>> area or has any thoughts about how to proceed.  In particular,  
>>>> is save a
>>>> reasonable way to save a few variables to disk?  I could also  
>>>> make the
>>>> code available when/if I get it working.
>>> -- 
>>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>>> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>>> University of Oxford,             Tel:  +44 1865 272861 (self)
>>> 1 South Parks Road,                     +44 1865 272866 (PA)
>>> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From marcelodamasceno at gmail.com  Tue Jan  3 16:45:58 2006
From: marcelodamasceno at gmail.com (Marcelo Damasceno)
Date: Tue, 3 Jan 2006 13:45:58 -0200
Subject: [Rd] Problems with calloc function.
In-Reply-To: <Pine.LNX.4.61.0512291524370.31762@gannet.stats>
References: <a55593730512290649w497ffc10p75c5fd7f71af402b@mail.gmail.com>
	<Pine.LNX.4.61.0512291524370.31762@gannet.stats>
Message-ID: <a55593730601030745k1b7439d4v4ff58051b240cd0d@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20060103/6110bc45/attachment.pl

From sfalcon at fhcrc.org  Tue Jan  3 16:53:00 2006
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Tue, 03 Jan 2006 07:53:00 -0800
Subject: [Rd] S4 default initialization: unwanted NULL
Message-ID: <m2bqytfgv7.fsf@ziti.local>

The default initialization for slots of class "factor" and
"data.frame" gives NULL.  This seems odd, since those slots can't ever
be set to NULL by the user.  I would expect zero-length instances of
factor and data.frame.

Here is an example:

setClass("FOO", representation(a="factor", b="data.frame", c="numeric"))
[1] "FOO"
> ff <- new("FOO")
> ff
An object of class "FOO"
Slot "a":
NULL

Slot "b":
NULL

Slot "c":
numeric(0)


sessionInfo()
R version 2.3.0, 2005-12-26, powerpc-apple-darwin8.3.0 

attached base packages:
[1] "tools"     "methods"   "stats"     "graphics"  "grDevices" "utils"    
[7] "datasets"  "base"     


Slot c is initialized as I was expecting.

+ seth


From ross at biostat.ucsf.edu  Tue Jan  3 17:39:27 2006
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Tue, 3 Jan 2006 08:39:27 -0800
Subject: [Rd] checkpointing
In-Reply-To: <Pine.LNX.4.61.0601031320220.13843@gannet.stats>
References: <Pine.GSO.4.31.0601030832230.5822-100000@markov.stats>
	<BCA2993F-D89F-4054-BB33-495B2EA8B74F@stat.berkeley.edu>
	<Pine.LNX.4.61.0601031320220.13843@gannet.stats>
Message-ID: <20060103163927.GO7714@wheat.betterworld.us>

On Tue, Jan 03, 2006 at 01:26:39PM +0000, Prof Brian Ripley wrote:
> On Tue, 3 Jan 2006, Kasper Daniel Hansen wrote:
> 
> >On Jan 3, 2006, at 9:36 AM, Brian D Ripley wrote:
> >
> >>I use save.image() or save(), which seem exactly what you are asking for.
> >
> >I have the (perhaps unsupported) impression that Ross wanted to save the 
> >progress during the optim run. Since it spends most of its time in the 
> >.Internal(optim(***)) call, save/save.image would not work.
> 
> It certainly does not!  
I'm having trouble following; does that sentence mean the preceding
one is wrong, or that save won't work.

> It is most likely spending time in the callbacks 
> to evaluate the function/gradient.  
Yes.
> We have used save() to save the 
> current information (e.g. current parameter values) from inside optim so a 
> restart could be done, 
Did you do this by
* using an existing feature of optim I don't know about;
* modifying the code for optim
* writing an objective function that saved the parameters with which
  it was called (which, now that I think of it, might be the simplest
  approach)?

My guess was that optim keeps its state in local variables that would
not be captured by a save.image.  Are you saying the relevant
variables are saved and can be fished out if needed?

It would also probably save some time if the estimated matrix of 2nd
derivatives were saved too (I supply only the objective function, not
derivatives), but that's minor compared to having the parameter
values.

> but then I have only once encountered someone 
> running a single optimization for over a week: there normally are ways to 
> speed things up.

I certainly hope so.  However, the problem size is likely to remain
large.

In answer to the other question about using OS checkpointing
facilities, I haven't tried them since the application will be running
on a cluster.  More precisely, the optimization will be driven from a
single machine, but the calculation of the objective function will be
distributed.  So checkpointing at the level of the optimization
function is a good fit to my needs.  There are some cluster OS's that
provide a kind of unified process space across the processors (scyld,
mosix), but we're not using them and checkpointing them is an unsolved
problem.  At least, it was unsolved a couple of years ago when I
looked into it.

Ross


From Matthias.Kohl at stamats.de  Tue Jan  3 18:06:30 2006
From: Matthias.Kohl at stamats.de (Matthias Kohl)
Date: Tue, 03 Jan 2006 18:06:30 +0100
Subject: [Rd] S4 default initialization: unwanted NULL
In-Reply-To: <m2bqytfgv7.fsf@ziti.local>
References: <m2bqytfgv7.fsf@ziti.local>
Message-ID: <43BAAF16.7030204@stamats.de>

you might need a call to "setOldClass"; see Section "Register or 
Convert?" of the corresponding help page.

Matthias

Seth Falcon schrieb:

>The default initialization for slots of class "factor" and
>"data.frame" gives NULL.  This seems odd, since those slots can't ever
>be set to NULL by the user.  I would expect zero-length instances of
>factor and data.frame.
>
>Here is an example:
>
>setClass("FOO", representation(a="factor", b="data.frame", c="numeric"))
>[1] "FOO"
>  
>
>>ff <- new("FOO")
>>ff
>>    
>>
>An object of class "FOO"
>Slot "a":
>NULL
>
>Slot "b":
>NULL
>
>Slot "c":
>numeric(0)
>
>
>sessionInfo()
>R version 2.3.0, 2005-12-26, powerpc-apple-darwin8.3.0 
>
>attached base packages:
>[1] "tools"     "methods"   "stats"     "graphics"  "grDevices" "utils"    
>[7] "datasets"  "base"     
>
>
>Slot c is initialized as I was expecting.
>
>+ seth
>
>______________________________________________
>R-devel at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-devel
>  
>


-- 
StaMatS - Statistik + Mathematik Service
Dipl.Math.(Univ.) Matthias Kohl
Gottlieb-Keim-Stra?e 60
95448 Bayreuth
Phone: +49 921 50736 457
E-Mail: matthias.kohl at stamats.de
www.stamats.de


From jmc at r-project.org  Tue Jan  3 19:12:43 2006
From: jmc at r-project.org (John Chambers)
Date: Tue, 03 Jan 2006 10:12:43 -0800
Subject: [Rd] S4 default initialization: unwanted NULL
In-Reply-To: <43BAAF16.7030204@stamats.de>
References: <m2bqytfgv7.fsf@ziti.local> <43BAAF16.7030204@stamats.de>
Message-ID: <43BABE9B.4000901@r-project.org>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20060103/21dfe8e0/attachment.pl

From sfalcon at fhcrc.org  Tue Jan  3 19:17:50 2006
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Tue, 03 Jan 2006 10:17:50 -0800
Subject: [Rd] S4 default initialization: unwanted NULL
In-Reply-To: <43BAAF16.7030204@stamats.de> (Matthias Kohl's message of "Tue,
	03 Jan 2006 18:06:30 +0100")
References: <m2bqytfgv7.fsf@ziti.local> <43BAAF16.7030204@stamats.de>
Message-ID: <m2zmmddvld.fsf@ziti.local>

On  3 Jan 2006, Matthias.Kohl at stamats.de wrote:

> you might need a call to "setOldClass"; see Section "Register or
> Convert?" of the corresponding help page.

That doesn't seem to make a difference.  Note that other non-S4 slots
like "matrix" initialize in an appropriate (non-NULL) fashion.


From sfalcon at fhcrc.org  Tue Jan  3 19:39:13 2006
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Tue, 03 Jan 2006 10:39:13 -0800
Subject: [Rd] S4 default initialization: unwanted NULL
In-Reply-To: <43BABE9B.4000901@r-project.org> (John Chambers's message of "Tue,
	03 Jan 2006 10:12:43 -0800")
References: <m2bqytfgv7.fsf@ziti.local> <43BAAF16.7030204@stamats.de>
	<43BABE9B.4000901@r-project.org>
Message-ID: <m2vex1dulq.fsf@ziti.local>

On  3 Jan 2006, jmc at r-project.org wrote:
> It's legal to have virtual classes as slots, but yes, the slot is
> NULL in the prototype for the new class, unless the user specifies a
> value.  In your case, providing a non-null prototype for the
> data.frame slot might be the desired solution.

Yes, that's a workaround.  

> There is no S4 "initialization" for S3 classes; in fact, it's
> generally an error to use new() on them (or on other virtual
> classes).

The "basic vector classes" (see man page for new) can be created
with new().  From my perspective it would be more consistent if
data.frame and factor behaved similarly.  

I admit that I don't understand why data.frame and factor are virtual
classes and don't know what would be involved to have new() work for
data.frame and factor.

+ seth


From mtmorgan at fhcrc.org  Tue Jan  3 20:08:24 2006
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Tue, 03 Jan 2006 11:08:24 -0800
Subject: [Rd] can someone help me understand LAM/MPI and Rmpi for use on
 a cluster
In-Reply-To: <CE0E73903DB53F43B4B0938747F34F8A01242D08@nihexchange7.nih.gov>
	(Grant Izmirlian's message of "Fri, 23 Dec 2005 13:31:04 -0500")
References: <CE0E73903DB53F43B4B0938747F34F8A01242D08@nihexchange7.nih.gov>
Message-ID: <6ph3bk5yvrr.fsf@gopher3.fhcrc.org>

Here's my slow response; if there were other off-list replies it would
be great to have a summary.

Not exactly sure what you're looking for. You might adopt a parallel
program so that the 'master' node does something like

myprog.c:

  MPI_Init(...)

  /* parallel computations, e.g., of pi */
  
  if (myid == 0) {
    MPI_Comm_get_parent(&parent);
    MPI_Send( &pi, 1, MPI_DOUBLE, 0, 0, parent );
  }

  MPI_Finalize()

then in R

  library(Rmpi)
  mpi.comm.spawn("myprog", ...)
  mpi.recv(...)

This launches myprog as a child of the R process, and retrieves the
result via the send/receive exchange between the spawned program and
R. An extension of this would move the mpi.comm.spawn call into a C
function you'd invoked from R with .Call(...).

This could also be developed into a kind of 'shell' package
initializing MPI and then providing parallelized functions and a
light-weight mechanism for their dispatch.

Hope that's helpful and not too misleading.

Martin


"Izmirlian, Grant (NIH/NCI) [E]" <izmirlig at mail.nih.gov> writes:

> I'm fairly astute at C and R but new to parallelization. Would someone
> be willing to provide help in the form of a simple example that parallelizes
> an R function from the inside of a C routine?
>
> If so, write me back at izmirlig at mail.nih.gov
>
> Thanks!
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From jmc at r-project.org  Tue Jan  3 20:20:16 2006
From: jmc at r-project.org (John Chambers)
Date: Tue, 03 Jan 2006 11:20:16 -0800
Subject: [Rd] S4 default initialization: unwanted NULL
In-Reply-To: <m2vex1dulq.fsf@ziti.local>
References: <m2bqytfgv7.fsf@ziti.local> <43BAAF16.7030204@stamats.de>
	<43BABE9B.4000901@r-project.org> <m2vex1dulq.fsf@ziti.local>
Message-ID: <43BACE70.20904@r-project.org>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20060103/bd74800e/attachment.pl

From sfalcon at fhcrc.org  Tue Jan  3 21:51:18 2006
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Tue, 03 Jan 2006 12:51:18 -0800
Subject: [Rd] Enhancement request: anonymous connections
In-Reply-To: <Pine.LNX.4.61.0601011752100.29194@gannet.stats> (Brian Ripley's
	message of "Sun, 1 Jan 2006 18:05:40 +0000 (GMT)")
References: <m2mzimc9zj.fsf@fhcrc.org> <43B1EE08.4090003@stats.uwo.ca>
	<m2ek3xcm32.fsf@fhcrc.org> <43B810BF.8080309@stats.uwo.ca>
	<Pine.LNX.4.61.0601011752100.29194@gannet.stats>
Message-ID: <m264p1dohl.fsf@ziti.local>

On  1 Jan 2006, ripley at stats.ox.ac.uk wrote:
> However, that just isn't how connections are documented in the Green
> Book (referenced on all the relevant help pages, so required
> reading) and getConnection() allows you to create an R object
> pointing to a connection that previously had none.  

Yes, p. 384 of my copy of the Green Book explains:

    Once a connection has been opened, the evaluation manager keeps it
    open until it is explicitly closed, or the session ends, even if
    no corresponding S connection object exists.

What are some advantages of this design choice?  

> The OP has never told us what anonymous connections' are, but it is
> quite possible that his unstated ideas are incompatible with the
> documentation.

Yep.  The current behavior is as documented in the Green Book and yes,
the enhancement I would like is incompatible with that documentation.

What is an anonymous connection?  Well, really what I want is for the
evaluation manager to clean up connections that have no corresponding
S connection objects referring to them.  Then the code examples that
are part of this thread would work.


+ seth


From p.dalgaard at biostat.ku.dk  Wed Jan  4 18:34:24 2006
From: p.dalgaard at biostat.ku.dk (p.dalgaard@biostat.ku.dk)
Date: Wed,  4 Jan 2006 18:34:24 +0100 (CET)
Subject: [Rd] update.formula gotcha (PR#8462)
Message-ID: <20060104173424.B5A0419FE8@slim.kubism.ku.dk>


(Reported by S?ren H?jsgaard)

Looks like update.formula is stripping of parentheses in cases where
they shouldn't be

> update.formula (Reaction ~ Days + (Days | Subject), . ~ . + I(Days^2))
Reaction ~ Days + Days | Subject + I(Days^2)

Notice that the right hand side is interpreted with the bar at the root
of the parse tree, as in
(Days + Days) | (Subject + I(Days^2)):

> f <- update.formula (Reaction ~ Days + (Days | Subject), . ~ . + I(Days^2))
> f[[3]]
Days + Days | Subject + I(Days^2)
> f[[3]][[1]]
`|`

This confuses lmer() rather badly:

library(lme4)
example(lmer)
update(fm1,formula = . ~ . + I(Days^2))

   ------>

Error in x[[2]] : object is not subsettable
Error in model.matrix(eval(substitute(~T, list(T = x[[2]]))), frm) :
        unable to find the argument 'object' in selecting a method for function 'model.matrix'


-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From sfalcon at fhcrc.org  Wed Jan  4 18:36:30 2006
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Wed, 04 Jan 2006 09:36:30 -0800
Subject: [Rd] ANN: Advanced R programming course, Seattle, Jan 18-20
Message-ID: <m28xtvc2u9.fsf@ziti.local>

Spots are still available for an advanced R programming course to be
held Jan 18-20 in Seattle.

Instructors: Robert Gentleman
             Seth Falcon

Topics: 
    Lexical scope
    Vectorization
    S3 and S4 OOP
    R packages
    Database connectivity
    Interfacing to C via .C and .Call

Details:

    January 18-20, 2006 
    Fred Hutchinson Cancer Research Center
    Seattle, WA, USA

    http://bioconductor.org/rforbioc/


From B.Rowlingson at lancaster.ac.uk  Wed Jan  4 19:06:32 2006
From: B.Rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Wed, 04 Jan 2006 18:06:32 +0000
Subject: [Rd] R on Thin Client with Win 2003
Message-ID: <43BC0EA8.3070404@lancaster.ac.uk>

I'm having some fun with R on a Windows 2003 Server talking to a Wyse 
Winterm running Thinstation Linux. The Winterm boots Linux from the 
network and then runs rdesktop to a Dell 1750 server (dual 3G Xeon or 
somesuch).

The first problem I noticed was that R (and the terminal) ground to a 
near halt during demo(graphics). Further investigation showed that it 
seemed to be due to having par(ask=TRUE) set. So:

  par(ask=TRUE);plot(1:10);plot(1:10)

would cause the Windows session to become unresponsive. Usually it would 
recover, but sometimes not.

  This was odd, because I have had a similar setup servicing a lab for 
over a year without problems. Similar, except this old lab has R 1.9.1 
installed and not shiny new 2.2.1. So I installed R 1.9.1 on the new 
server - and then there's no problem with par(ask=TRUE) stuff.

  Further R installs show the problem manifests itself in 2.1.1 and not 
2.0.1, coincidental with a change in the prompt from "Hit <Return> to 
see next plot" (2.0.1) to "Click or hit ENTER for next page" (2.1.1). 
Curious...

  Running rdesktop from my desktop Linux box and connecting to the same 
server doesn't show any of these problems. So I can't blame the network.

  Possible reasons for the change:

  * Difference in rdesktop versions (1.4.1 on Wyse, 1.3 on my machine)

  * Difference in X version (Xorg 6.9.0 on Wyse, XFree86 4.2.1 on mine)

I think the next thing to try is to put R 2.2.1 on the old lab and see 
how that copes. Has anyone else any experience running R from Win2003 
servers or on Wyse Winterm X-terminals or using Thinstation Linux?

Barry


From hpages at fhcrc.org  Thu Jan  5 02:29:35 2006
From: hpages at fhcrc.org (Herve Pages)
Date: Wed, 04 Jan 2006 17:29:35 -0800
Subject: [Rd] Pb with agrep()
Message-ID: <43BC767F.4060405@fhcrc.org>

Happy new year everybody,


I'm getting the following while trying to use the agrep() function:

 > pattern <- "XXX"
 > subject <- c("oooooo", "oooXooo", "oooXXooo", "oooXXXooo")
 > max <- list(ins=0, del=0, sub=0) # I want exact matches only
 > agrep(pattern, subject, max=max)
[1] 4

OK

 > max$sub <- 1 # One allowed substitution
 > agrep(pattern, subject, max=max)
[1] 3 4

OK

 > max$sub <- 2 # Two allowed substitutions
 > agrep(pattern, subject, max=max)
[1] 3 4

Wrong!

 > sessionInfo()
R version 2.3.0, 2005-12-22, x86_64-unknown-linux-gnu
 
attached base packages:
[1] "methods"   "stats"     "graphics"  "grDevices" "utils"     "datasets"
[7] "base"
 
other attached packages:
Biostrings
   "1.5.6"

Cheers,


Herv?


-- 
------------------------
Herv? Pag?s
E-mail: hpages at fhcrc.org
Phone: (206) 667-5791
Fax: (206) 667-1319


From blindglobe at gmail.com  Thu Jan  5 03:03:48 2006
From: blindglobe at gmail.com (A.J. Rossini)
Date: Thu, 5 Jan 2006 03:03:48 +0100
Subject: [Rd] R-devel Digest, Vol 35, Issue 4
In-Reply-To: <mailman.8.1136372401.22906.r-devel@r-project.org>
References: <mailman.8.1136372401.22906.r-devel@r-project.org>
Message-ID: <1abe3fa90601041803s6bc61a26sa1415298b70da4e2@mail.gmail.com>

> From: Ross Boylan <ross at biostat.ucsf.edu>

>
> In answer to the other question about using OS checkpointing
> facilities, I haven't tried them since the application will be running
> on a cluster.  More precisely, the optimization will be driven from a
> single machine, but the calculation of the objective function will be
> distributed.  So checkpointing at the level of the optimization
> function is a good fit to my needs.  There are some cluster OS's that
> provide a kind of unified process space across the processors (scyld,
> mosix), but we're not using them and checkpointing them is an unsolved
> problem.  At least, it was unsolved a couple of years ago when I
> looked into it.
>

A few years ago, Condor, yet another job queuing tool, had some
checkpointing features.  Jun Yan had a presentation on his WWW site at
that time about it (but not necessarily about testing the
checkpointing feature).

I'd think that checkpointing would be best in system-space, not
user-space; however, for optimization, it should be just a matter of
saving state and possibly history, if you are doing memoization.

best,
-tony

blindglobe at gmail.com
Muttenz, Switzerland.
"Commit early,commit often, and commit in a repository from which we can easily
roll-back your mistakes" (AJR, 4Jan05).


From finle014 at umn.edu  Thu Jan  5 03:22:28 2006
From: finle014 at umn.edu (Andrew Finley)
Date: Wed, 04 Jan 2006 20:22:28 CST
Subject: [Rd] Using STL containers in R/C++
Message-ID: <200601050222.k052MSss030085@saturn.software.umn.edu>

Hi All,
I am in the process of writing an R extension in c++ and am using several
STL containers  (e.g., vector<double>, map<int, double>, multimap<int,
double>).  I make sure to clear all these containers at the end of the
.Call.   Everything compiles and runs just fine, but I'm a bit worried
since I haven't found any other packages that use STL.

So, my question: is it OK to use the STL containers in my code?  Will the
use of this library somehow limit portability of this package? Or cause
memory management problems?

Thanks-
Andy


Andrew Finley, Research Fellow
Department of Forest Resources
College of Natural Resources
University of Minnesota
305 Green Hall
1530 Cleveland Avenue N.
St. Paul, MN 55108

Ph 612-624-1714 office
http://blue.fr.umn.edu/home
www.cnr.umn.edu/FR/people/facstaff/finley/index.html


From ripley at stats.ox.ac.uk  Thu Jan  5 05:21:05 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 5 Jan 2006 04:21:05 +0000 (GMT)
Subject: [Rd] Using STL containers in R/C++
In-Reply-To: <200601050222.k052MSss030085@saturn.software.umn.edu>
References: <200601050222.k052MSss030085@saturn.software.umn.edu>
Message-ID: <Pine.LNX.4.61.0601050415570.27406@gannet.stats>

Using C++ will reduce portability of your code.  Using C++'s STL (not R's 
stl, so it is a good idea to spell out jargon) will reduce the 
portability further.

R itself does not use C++, and although a C++ compiler is found, it is 
only very mininally tested (and in particular its headers and libraries 
are not checked).  Some of us have only rather old C++ compilers on 
commercial Unixen.

On Wed, 4 Jan 2006, Andrew Finley wrote:

> Hi All,
> I am in the process of writing an R extension in c++ and am using several
> STL containers  (e.g., vector<double>, map<int, double>, multimap<int,
> double>).  I make sure to clear all these containers at the end of the
> .Call.   Everything compiles and runs just fine, but I'm a bit worried
> since I haven't found any other packages that use STL.
>
> So, my question: is it OK to use the STL containers in my code?  Will the
> use of this library somehow limit portability of this package? Or cause
> memory management problems?
>
> Thanks-
> Andy
>
>
> Andrew Finley, Research Fellow
> Department of Forest Resources
> College of Natural Resources
> University of Minnesota
> 305 Green Hall
> 1530 Cleveland Avenue N.
> St. Paul, MN 55108
>
> Ph 612-624-1714 office
> http://blue.fr.umn.edu/home
> www.cnr.umn.edu/FR/people/facstaff/finley/index.html
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ggrothendieck at gmail.com  Thu Jan  5 05:47:20 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Wed, 4 Jan 2006 23:47:20 -0500
Subject: [Rd] defining a print method
Message-ID: <971536df0601042047p24519c59nce098ab8e134b4e2@mail.gmail.com>

In the following session we define an xx class and a print method
for it.  If I invoke it with print then it prints as expected but if
we just type xx at the R prompt then we get nothing back.  How
do we define the print method so that it works in the latter
case too?

> xx <- structure("abc", class = "xx")
> print.xx <- function(x, ...) shQuote(x)
> print(xx) # ok
[1] "\"abc\""
> xx # no output ????
>
> sessionInfo()
R version 2.2.1, 2005-12-20, i386-pc-mingw32

attached base packages:
[1] "methods"   "stats"     "graphics"  "grDevices" "utils"     "datasets"
[7] "base"
>


From deepayan.sarkar at gmail.com  Thu Jan  5 06:01:13 2006
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Wed, 4 Jan 2006 23:01:13 -0600
Subject: [Rd] defining a print method
In-Reply-To: <971536df0601042047p24519c59nce098ab8e134b4e2@mail.gmail.com>
References: <971536df0601042047p24519c59nce098ab8e134b4e2@mail.gmail.com>
Message-ID: <eb555e660601042101n5b90dd99i278fc67a8b0752f5@mail.gmail.com>

On 1/4/06, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
> In the following session we define an xx class and a print method
> for it.  If I invoke it with print then it prints as expected but if
> we just type xx at the R prompt then we get nothing back.  How
> do we define the print method so that it works in the latter
> case too?
>
> > xx <- structure("abc", class = "xx")
> > print.xx <- function(x, ...) shQuote(x)

shQuote doesn't print anything, you probably want

print.xx <- function(x, ...) print(shQuote(x))

-Deepayan

> > print(xx) # ok
> [1] "\"abc\""
> > xx # no output ????
> >
> > sessionInfo()
> R version 2.2.1, 2005-12-20, i386-pc-mingw32
>
> attached base packages:
> [1] "methods"   "stats"     "graphics"  "grDevices" "utils"     "datasets"
> [7] "base"


From maechler at stat.math.ethz.ch  Thu Jan  5 10:02:21 2006
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 5 Jan 2006 10:02:21 +0100
Subject: [Rd] Pb with agrep()
In-Reply-To: <43BC767F.4060405@fhcrc.org>
References: <43BC767F.4060405@fhcrc.org>
Message-ID: <17340.57501.191566.727447@stat.math.ethz.ch>

>>>>> "Herve" == Herve Pages <hpages at fhcrc.org>
>>>>>     on Wed, 04 Jan 2006 17:29:35 -0800 writes:

    Herve> Happy new year everybody,
    Herve> I'm getting the following while trying to use the agrep() function:

    >> pattern <- "XXX"
    >> subject <- c("oooooo", "oooXooo", "oooXXooo", "oooXXXooo")
    >> max <- list(ins=0, del=0, sub=0) # I want exact matches only
    >> agrep(pattern, subject, max=max)
    Herve> [1] 4

    Herve> OK

    >> max$sub <- 1 # One allowed substitution
    >> agrep(pattern, subject, max=max)
    Herve> [1] 3 4

    Herve> OK

    >> max$sub <- 2 # Two allowed substitutions
    >> agrep(pattern, subject, max=max)
    Herve> [1] 3 4

    Herve> Wrong!

No. 
You have overlooked the fact that 'max.distance = 0.1' (10%) 
*remains* the default, even when 'max.distance' is specified as
a list as in your example [from  "?agrep" ] :

>> max.distance: Maximum distance allowed for a match.  Expressed either
>>           as integer, or as a fraction of the pattern length (will be
>>           replaced by the smallest integer not less than the
>>           corresponding fraction), or a list with possible components
>> 
>>           'all': maximal (overall) distance
>> 
>>           'insertions': maximum number/fraction of insertions
>> 
>>           'deletions': maximum number/fraction of deletions
>> 
>>           'substitutions': maximum number/fraction of substitutions
>> 
>>>>>>       If 'all' is missing, it is set to 10%, the other components
>>>>>>       default to 'all'.  The component names can be abbreviated. 

If you specify max$all as "100%", i.e, as 0.9999  ('< 1' !)  everything works
as you expect it:

agrep(pattern, subject, max = list(ins=0, del=0, sub= 2, all = 0.9999))
## --> 2 3 4


Martin Maechler, ETH Zurich


From ripley at stats.ox.ac.uk  Thu Jan  5 14:36:15 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 5 Jan 2006 13:36:15 +0000 (GMT)
Subject: [Rd] Using gcc4 visibility features
Message-ID: <Pine.LNX.4.61.0601051003360.9143@gannet.stats>

R-devel now makes use of gcc4's visibility features: for an in-depth 
account see

http://people.redhat.com/drepper/dsohowto.pdf

(and note there are older versions of that document around).

Consider for example stats.so.  On a gcc4 Linux system this has just three
entry points

gannet% nm -g stats.so | grep " T "
00002720 T R_init_stats
0004a544 T _fini
00001f28 T _init

since the only entry point we need is the symbol registration.  This 
results in a smaller DSO and a faster load.  It is only worth doing for
shared objects with many entry points, but this one had 262.

It also gives another reason for the registration of symbols, as this is 
the only way I know to hide Fortran entry points (except to hide them all, 
which will hide them from .Fortran).  Until recently registration was used 
in the standard packages and a handful of others (not including any 
recommended packages).  You can copy the way it is done in package stats 
(see PKG_* in Makefile.in and init.c).

The next step will be to prune libR.so down to something close to the 
documented API (it currently has 1816 exported symbols).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From edd at debian.org  Thu Jan  5 15:52:13 2006
From: edd at debian.org (Dirk Eddelbuettel)
Date: Thu, 5 Jan 2006 14:52:13 +0000 (UTC)
Subject: [Rd] Using STL containers in R/C++
References: <200601050222.k052MSss030085@saturn.software.umn.edu>
Message-ID: <loom.20060105T154400-143@post.gmane.org>

Andrew Finley <finle014 <at> umn.edu> writes:
> I am in the process of writing an R extension in c++ and am using several
> STL containers  (e.g., vector<double>, map<int, double>, multimap<int,
> double>).  I make sure to clear all these containers at the end of the
> .Call.   Everything compiles and runs just fine, but I'm a bit worried
> since I haven't found any other packages that use STL.

RQuantLib, a wrapper to the QuantLib libraries, has indirect exposure to Boost.
[ QuantLib uses Boost smart pointers, and unit testing. ]  However, I have kept 
the actual R-to-QuantLib interface very 'plain C' to keep it simple and sane. 

Dominick Samperi wrote a Rcpp.{hpp,cpp} class for C++ to R interface that is 
used in RQuantLib. Dominick was musing about releasing this stand-alone to CRAN
as well, but I don't think it has happened.

> So, my question: is it OK to use the STL containers in my code?  Will the

In my book, yes.  It would be nice to have a few nice, and documented, examples.

> use of this library somehow limit portability of this package? 

I don't see why. Effectively, R goes where gcc/g++ go so if you make sure you 
stay within the bounds of g++. It will create an external dependency, as those
do confuse users from time to time (c.f. the r-help archives).

> Or cause memory management problems?

If you have a bug, yes. If you don't, you don't. The R Extensions manual has a 
few tips on the matter.

Cheers, Dirk


From elw at stderr.org  Thu Jan  5 16:13:15 2006
From: elw at stderr.org (elijah wright)
Date: Thu, 5 Jan 2006 09:13:15 -0600 (CST)
Subject: [Rd] Using gcc4 visibility features
In-Reply-To: <Pine.LNX.4.61.0601051003360.9143@gannet.stats>
References: <Pine.LNX.4.61.0601051003360.9143@gannet.stats>
Message-ID: <Pine.LNX.4.64.0601050912290.19025@illuminati.stderr.org>


> Subject: [Rd] Using gcc4 visibility features
> 
> R-devel now makes use of gcc4's visibility features: for an in-depth 
> account see
>
> http://people.redhat.com/drepper/dsohowto.pdf


does this mean that we now have a dependency on gcc4, or just that it 
"can" use the feature of gcc4?

clarification, please.

thanks,

--elijah


From sfalcon at fhcrc.org  Thu Jan  5 16:40:43 2006
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Thu, 05 Jan 2006 07:40:43 -0800
Subject: [Rd] Using STL containers in R/C++
In-Reply-To: <200601050222.k052MSss030085@saturn.software.umn.edu> (Andrew
	Finley's message of "Wed, 04 Jan 2006 20:22:28 CST")
References: <200601050222.k052MSss030085@saturn.software.umn.edu>
Message-ID: <m2vewy65tw.fsf@ziti.local>

You might want to take a look at the Bioconductor package RBGL which
provides an R interface to the BGL which is C++ STL heavy, I believe.

+ seth


From hin-tak.leung at cimr.cam.ac.uk  Thu Jan  5 17:05:54 2006
From: hin-tak.leung at cimr.cam.ac.uk (Hin-Tak Leung)
Date: Thu, 05 Jan 2006 16:05:54 +0000
Subject: [Rd] Problems with calloc function.
In-Reply-To: <a55593730601030745k1b7439d4v4ff58051b240cd0d@mail.gmail.com>
References: <a55593730512290649w497ffc10p75c5fd7f71af402b@mail.gmail.com>	<Pine.LNX.4.61.0512291524370.31762@gannet.stats>
	<a55593730601030745k1b7439d4v4ff58051b240cd0d@mail.gmail.com>
Message-ID: <43BD43E2.2000208@cimr.cam.ac.uk>

Hi Marcelo,

You need to read the R extension manual more carefully...
Basically you haven't deference thed pointers. You think you
were allocating say, col=2, but instead you were allocating &col
in int's, the address of col, which is a large number since
user-land memory address starts at a large offset (0x40000000? =
1/2 GB or 0x80000000 = 1GB?),
so after 4 large allocations, you run out of memory.

Everything through the C interface is passed by pointer, in the
fortran convention.

BTW, you should use Rprintf() instead of printf(). Details below.

Hin-Tak Leung

Marcelo Damasceno wrote:
> Hello all and Prof. Brian Ripley ,
> 
> Sorry about my incautiousness, I use the tips, but is happen same problems.
> Below the R code.
> ################################################################
> rspcplot <- function(file1="dg_01.lab.txt"){
>   if(is.null(n))
>     stop("You need first run the function cluster")
>     file<-"dg_01.lab.txt"
>     aux<-file1
>     file1<-pmatch(file1,file)
>   if(is.na(file1)){
>       matrix=loadMatrix(file,n)
>   }
>   else{
>       matrix=loadMatrix(aux,n)
>   }
>   matrixc<-correct(matrix)
>   #merge2(matrixc)
>   nrow=nrow(matrixc)
>   ncol=ncol(matrixc)
>   ntemp=getTemp()
>   out <- .C("merge2",matrixc,nrow, ncol,ntemp,outMerge=as.integer
> (0),outHeight=as.integer(0),PACKAGE="rspc")
> ##########################################################################
> Below the C code.
> ##########################################################################
> void merge2(int *nmat,int nrow,int ncol, int *ntemp,int ntam, int *out, int
> *height){

Here, you should have "*ncol" instead of "ncol". (I am only correcting 
this one - you can change the others) like this:

	void merge2(int *nmat,int nrow,int *ncol, int *ntemp,int ntam,      int 
*out, int *height){

>     int row,col,*temp,i,j,k,n3,tam,x,aux2,n1;
>     row = nrow;
>     col = ncol;

You should use here:

	int col = *ncol;

> 
>     int *temp1,*temp2,*temp3,*temp4;
> 
>     temp1 = (int*)Calloc(col,int);


inserting here:

	Rprintf("I am trying to allocate col = %d\n", col);

would have told you what's wrong with your code...

>     printf("OK1 \n");


>     temp2 = (int*)Calloc(col,int);
>     printf("OK2 \n");
>     temp3 = (int *)Calloc(col,int);
>     printf("OK3 \n");
>     temp4 = (int *)Calloc(col,int);
>     if(temp4 == NULL){
>         printf("\n\n No Memory4!");
>         exit(1);
>     }
>     printf("OK4\n");
>     int *cvector;
>     cvector = (int *)Calloc(col,int);
>     if(cvector == NULL){
>         printf("\n\n No Memory5!");
>         exit(1);
>     }
>     printf("OK5\n");
>     tam=ntam;
> #######################################################################
> Output of Work Space:
> 
> 
>>rspcplot()
> 
> Read 525 items
> Read 101 items
> OK1
> OK2
> OK3
> OK4
> Error in rspcplot() : Calloc could not allocate (145869080 of 4) memory
> 
> 
> Using the Ruspini data, the values of variables col = 2 and row = 75. I was
> thinking that the number of pointers and space of memory are too big.
> 
> 
> Thanks All !
<earlier posts snipped>


From tibshirani at gmail.com  Thu Jan  5 17:44:59 2006
From: tibshirani at gmail.com (Tib)
Date: Thu, 5 Jan 2006 11:44:59 -0500
Subject: [Rd] random seed question
Message-ID: <58618a620601050844m5b7da38tb46f49488786122c@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20060105/e9ecd8a9/attachment.pl

From andy_liaw at merck.com  Thu Jan  5 18:10:48 2006
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 5 Jan 2006 12:10:48 -0500
Subject: [Rd] random seed question
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED6C4@usctmx1106.merck.com>

Just one call to each that enclose the RNG calls will do, I believe.

Andy

From: Tib
> 
> Greetings,
> 
> I am trying to write a C++ subroutine of my random number 
> generator. Based
> on tutorial in Writing R Extensions, one should call 
> GetRNGstate() before
> and PutRNGstate() after calling  R's random variate 
> generation routines. Now
> suppose my function would generate n(n>1) numbers by a loop, 
> do I need to
> call these two functions at each iteration? This certainly increases
> computation burden (although indiscernible in my case). But 
> if I only call
> them once (outside the loop), will the quality of my random numbers be
> reduced because of serial correlations in RNG algorithms? I 
> do comparisons
> between two methods, no significant difference is found. How 
> do you guys
> write RNG functions? Any other specific reasons? Thanks,
> 
> --
> I am Tib, not Rob.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
>


From maechler at stat.math.ethz.ch  Thu Jan  5 18:38:49 2006
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 5 Jan 2006 18:38:49 +0100
Subject: [Rd] Using gcc4 visibility features
In-Reply-To: <Pine.LNX.4.64.0601050912290.19025@illuminati.stderr.org>
References: <Pine.LNX.4.61.0601051003360.9143@gannet.stats>
	<Pine.LNX.4.64.0601050912290.19025@illuminati.stderr.org>
Message-ID: <17341.22953.84021.273803@stat.math.ethz.ch>

>>>>> "elijah" == elijah wright <elw at stderr.org>
>>>>>     on Thu, 5 Jan 2006 09:13:15 -0600 (CST) writes:

    >> Subject: [Rd] Using gcc4 visibility features
    >> 
    >> R-devel now makes use of gcc4's visibility features: for
    >> an in-depth account see
    >> 
    >> http://people.redhat.com/drepper/dsohowto.pdf


    elijah> does this mean that we now have a dependency on
    elijah> gcc4, or just that it "can" use the feature of gcc4?

the latter (of course!)

    elijah> clarification, please.


From roebuck at mdanderson.org  Thu Jan  5 18:46:54 2006
From: roebuck at mdanderson.org (Paul Roebuck)
Date: Thu, 5 Jan 2006 11:46:54 -0600 (CST)
Subject: [Rd] Problems with calloc function.
In-Reply-To: <a55593730601030745k1b7439d4v4ff58051b240cd0d@mail.gmail.com>
References: <a55593730512290649w497ffc10p75c5fd7f71af402b@mail.gmail.com>
	<Pine.LNX.4.61.0512291524370.31762@gannet.stats>
	<a55593730601030745k1b7439d4v4ff58051b240cd0d@mail.gmail.com>
Message-ID: <Pine.OSF.4.58.0601051145500.332031@wotan.mdacc.tmc.edu>

On Tue, 3 Jan 2006, Marcelo Damasceno wrote:

> Sorry about my incautiousness, I use the tips, but is
> happen same problems.

Not really. You definitely skipped over the most important
one - don't terminate the host process.

>     if(temp4 == NULL){
>         printf("\n\n No Memory4!");
>         exit(1);
>     }

    if (temp4 == NULL) {
        error("memory allocation failed for 'temp4'");
        /*NOTREACHED*/
    }

----------------------------------------------------------
SIGSIG -- signature too long (core dumped)


From elw at stderr.org  Thu Jan  5 19:11:32 2006
From: elw at stderr.org (elijah wright)
Date: Thu, 5 Jan 2006 12:11:32 -0600 (CST)
Subject: [Rd] Using gcc4 visibility features
In-Reply-To: <17341.22953.84021.273803@stat.math.ethz.ch>
References: <Pine.LNX.4.61.0601051003360.9143@gannet.stats>
	<Pine.LNX.4.64.0601050912290.19025@illuminati.stderr.org>
	<17341.22953.84021.273803@stat.math.ethz.ch>
Message-ID: <Pine.LNX.4.64.0601051211130.28761@illuminati.stderr.org>


>    >> R-devel now makes use of gcc4's visibility features: for
>    >> an in-depth account see
>
>    elijah> does this mean that we now have a dependency on
>    elijah> gcc4, or just that it "can" use the feature of gcc4?
>
> the latter (of course!)


that's what i expected, i was just checking :)

--elijah


From deepayan.sarkar at gmail.com  Thu Jan  5 19:21:50 2006
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Thu, 5 Jan 2006 12:21:50 -0600
Subject: [Rd] extending lattice to S4 classes
In-Reply-To: <43575CA0.9060807@ipimar.pt>
References: <434F88B9.1020600@ipimar.pt> <434FD8C2.205@ipimar.pt>
	<Pine.LNX.4.61.0510150758480.27345@gannet.stats>
	<4354D388.9000209@ipimar.pt>
	<eb555e660510191045s5de87a89p714e5fa8929a053b@mail.gmail.com>
	<43575CA0.9060807@ipimar.pt>
Message-ID: <eb555e660601051021w30ea1754ge3b9763af7c570f4@mail.gmail.com>

On 10/20/05, ernesto <ernesto at ipimar.pt> wrote:

[...]

> Hi Deepayan,
>
> I see that there are alternatives, I found one my self that works and
> it's transparent for the user.
>
> I don't want to implement solutions that force the user to use lattice
> methods differently from your implementation.
>
> The cleanest solution as you say is to add a data argument to xyplot but
> I can't do it so I would not propose it.

FYI, I have added the 'data' argument to high level generics in
lattice_0.13-1, available for r-devel (of course this causes the
current version of FLCore to fail).

Deepayan
--
http://www.stat.wisc.edu/~deepayan/


From murdoch at stats.uwo.ca  Thu Jan  5 19:58:59 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 05 Jan 2006 13:58:59 -0500
Subject: [Rd] random seed question
In-Reply-To: <58618a620601050844m5b7da38tb46f49488786122c@mail.gmail.com>
References: <58618a620601050844m5b7da38tb46f49488786122c@mail.gmail.com>
Message-ID: <43BD6C73.7080007@stats.uwo.ca>

On 1/5/2006 11:44 AM, Tib wrote:
> Greetings,
> 
> I am trying to write a C++ subroutine of my random number generator. Based
> on tutorial in Writing R Extensions, one should call GetRNGstate() before
> and PutRNGstate() after calling  R's random variate generation routines. Now
> suppose my function would generate n(n>1) numbers by a loop, do I need to
> call these two functions at each iteration? This certainly increases
> computation burden (although indiscernible in my case). But if I only call
> them once (outside the loop), will the quality of my random numbers be
> reduced because of serial correlations in RNG algorithms? I do comparisons
> between two methods, no significant difference is found. How do you guys
> write RNG functions? Any other specific reasons? Thanks,

Call them once, outside the loop.

What they do is move the RNG state between the R workspace and a place 
where the C functions can use it.  Wrapping each call in the loop in 
those calls will just generate a lot of unnecessary moves.  Not doing 
the calls, or not pairing them up properly, is the dangerous thing that 
would lead to damage to the RNG algorithms, because the state would not 
be updated properly.

Duncan Murdoch


From Karen.Green at sanofi-aventis.com  Thu Jan  5 23:18:38 2006
From: Karen.Green at sanofi-aventis.com (Karen.Green@sanofi-aventis.com)
Date: Thu, 5 Jan 2006 17:18:38 -0500
Subject: [Rd] Q: R 2.2.1:  Memory Management Issues?
Message-ID: <3CB6B0EE6816B142859B24E77724A8B8F87DDD@sccsmxsusr05.pharma.aventis.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20060105/e3eab45e/attachment.pl

From dsamperi at DecisionSynergy.com  Fri Jan  6 00:01:46 2006
From: dsamperi at DecisionSynergy.com (Dominick Samperi)
Date: Thu, 05 Jan 2006 18:01:46 -0500
Subject: [Rd] Using STL containers in R/C++
In-Reply-To: <loom.20060105T154400-143@post.gmane.org>
References: <200601050222.k052MSss030085@saturn.software.umn.edu>
	<loom.20060105T154400-143@post.gmane.org>
Message-ID: <43BDA55A.7050502@DecisionSynergy.com>

Dirk Eddelbuettel wrote:
> Dominick Samperi wrote a Rcpp.{hpp,cpp} class for C++ to R interface that is 
> used in RQuantLib. Dominick was musing about releasing this stand-alone to CRAN
> as well, but I don't think it has happened.
>   
It just happened. I uploaded Rcpp to CRAN today. The package contains a 
PDF file
Rcpp.pdf that describes the package and the class library.

Dominick


From simon.urbanek at r-project.org  Fri Jan  6 01:12:33 2006
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Thu, 5 Jan 2006 19:12:33 -0500
Subject: [Rd] Q: R 2.2.1:  Memory Management Issues?
In-Reply-To: <3CB6B0EE6816B142859B24E77724A8B8F87DDD@sccsmxsusr05.pharma.aventis.com>
References: <3CB6B0EE6816B142859B24E77724A8B8F87DDD@sccsmxsusr05.pharma.aventis.com>
Message-ID: <7BB23955-EC08-43D3-9465-AD12540C17A3@r-project.org>

Karen,

On Jan 5, 2006, at 5:18 PM, <Karen.Green at sanofi-aventis.com>  
<Karen.Green at sanofi-aventis.com> wrote:

> I am trying to run a R script which makes use of the MCLUST package.
> The script can successfully read in the approximately 17000 data  
> points ok, but then throws an error:
> --------------------------------------------------------
> Error:  cannot allocate vector of size 1115070Kb

This is 1.1GB of RAM to allocate alone for one vector(!). As you  
stated yourself the total upper limit is 2GB, so you cannot even fit  
two of those in memory anyway - not much you can do with it even if  
it is allocated.

> summary(EMclust(y),y)

I suspect that memory is your least problem. Did you even try to run  
EMclust on a small subsample? I suspect that if you did, you would  
figure out that what you are trying to do is not likely to terminate  
within days...

> (1) I had initially thought that Windows 2000 should be able to  
> allocate up to about 2 GB memory.  So, why is there a problem to  
> allocate a little over 1GB on a defragmented disk with over 15 GB  
> free?  (Is this a pagefile size issue?)

Because that is not the only 1GB vector that is allocated. Your "15GB/ 
defragmented" are irrelevant - if at all, look how much virtual  
memory is set up in you system's preferences.

> (2) Do you think the origin of the problem is
>     (a) the R environment, or
>     (b) the function in the MCLUST package using an in-memory  
> instead of an on-disk approach?

Well, a toy example of 17000x2 needs 2.3GB and it's unlikely to  
terminate anytime soon, so I'd rather call it shooting with the wrong  
gun. Maybe you should consider different approach to your problem -  
possibly ask at the BioConductor list, because people there have more  
experience with large data and this is not really a technical  
question about R, but rather how to apply statistical methods.

> (3)
>     (a) If the problem originates in the R environment, would  
> switching to the Linux version of R solve the problem?

Any reasonable unix will do - technically (64-bit versions  
preferably, but in your case even 32-bit would do). Again, I don't  
think memory is your only problem here, though.

Cheers,
Simon


From Karen.Green at sanofi-aventis.com  Fri Jan  6 01:33:58 2006
From: Karen.Green at sanofi-aventis.com (Karen.Green@sanofi-aventis.com)
Date: Thu, 5 Jan 2006 19:33:58 -0500
Subject: [Rd] Q: R 2.2.1:  Memory Management Issues?
Message-ID: <3CB6B0EE6816B142859B24E77724A8B8F87DDE@sccsmxsusr05.pharma.aventis.com>

Dear Simon,

Thank you for taking time to address my questions.

>> summary(EMclust(y),y)
>
>I suspect that memory is your least problem. Did you even try to run  
>EMclust on a small subsample? I suspect that if you did, you would  
>figure out that what you are trying to do is not likely to terminate  
>within days...

The empirically derived limit on my machine (under R 1.9.1) was approximately 7500 data points.
I have been able to successfully run the script that uses package MCLUST on several hundred smaller data sets.

I even had written a work-around for the case of greater than 9600 data points.  My work-around first orders the
points by their value then takes a sample (e.g. every other point or 1 point every n points) in order to bring the number under 9600.  No problems with the computations were observed, but you are correct that a deconvolution on that larger dataset of 9600 takes almost 30 minutes.  However, for our purposes, we do not have many datasets over 9600 so the time is not a major constraint.

Unfortunately, my management does not like using a work-around and really wants to operate on the larger data sets.
I was told to find a way to make it operate on the larger data sets or avoid using R and find another solution.  

>From previous programming projects in a different scientific field long ago, I recall making a trade-off of using temp files instead of holding data in memory in order to make working with larger data sets possible.  I am wondering if something like that would be possible for this situation, but I don't have enough knowledge at this moment to make this decision.

Karen
---
Karen M. Green, Ph.D.
Karen.Green at sanofi-aventis.com
Research Investigator
Drug Design Group
Sanofi Aventis Pharmaceuticals
Tucson, AZ  85737

-----Original Message-----
From: Simon Urbanek [mailto:simon.urbanek at r-project.org]
Sent: Thursday, January 05, 2006 5:13 PM
To: Green, Karen M. PH/US
Cc: R-devel at stat.math.ethz.ch
Subject: Re: [Rd] Q: R 2.2.1: Memory Management Issues?
Importance: High


Karen,

On Jan 5, 2006, at 5:18 PM, <Karen.Green at sanofi-aventis.com>  
<Karen.Green at sanofi-aventis.com> wrote:

> I am trying to run a R script which makes use of the MCLUST package.
> The script can successfully read in the approximately 17000 data  
> points ok, but then throws an error:
> --------------------------------------------------------
> Error:  cannot allocate vector of size 1115070Kb

This is 1.1GB of RAM to allocate alone for one vector(!). As you  
stated yourself the total upper limit is 2GB, so you cannot even fit  
two of those in memory anyway - not much you can do with it even if  
it is allocated.

> summary(EMclust(y),y)

I suspect that memory is your least problem. Did you even try to run  
EMclust on a small subsample? I suspect that if you did, you would  
figure out that what you are trying to do is not likely to terminate  
within days...

> (1) I had initially thought that Windows 2000 should be able to  
> allocate up to about 2 GB memory.  So, why is there a problem to  
> allocate a little over 1GB on a defragmented disk with over 15 GB  
> free?  (Is this a pagefile size issue?)

Because that is not the only 1GB vector that is allocated. Your "15GB/ 
defragmented" are irrelevant - if at all, look how much virtual  
memory is set up in you system's preferences.

> (2) Do you think the origin of the problem is
>     (a) the R environment, or
>     (b) the function in the MCLUST package using an in-memory  
> instead of an on-disk approach?

Well, a toy example of 17000x2 needs 2.3GB and it's unlikely to  
terminate anytime soon, so I'd rather call it shooting with the wrong  
gun. Maybe you should consider different approach to your problem -  
possibly ask at the BioConductor list, because people there have more  
experience with large data and this is not really a technical  
question about R, but rather how to apply statistical methods.

> (3)
>     (a) If the problem originates in the R environment, would  
> switching to the Linux version of R solve the problem?

Any reasonable unix will do - technically (64-bit versions  
preferably, but in your case even 32-bit would do). Again, I don't  
think memory is your only problem here, though.

Cheers,
Simon


From Karen.Green at sanofi-aventis.com  Fri Jan  6 01:36:42 2006
From: Karen.Green at sanofi-aventis.com (Karen.Green@sanofi-aventis.com)
Date: Thu, 5 Jan 2006 19:36:42 -0500
Subject: [Rd] Q: R 2.2.1:  Memory Management Issues?
Message-ID: <3CB6B0EE6816B142859B24E77724A8B80128D2F9@sccsmxsusr05.pharma.aventis.com>

Dear Simon,

Thank you for taking time to address my questions.

>> summary(EMclust(y),y)
>
>I suspect that memory is your least problem. Did you even try to run  
>EMclust on a small subsample? I suspect that if you did, you would  
>figure out that what you are trying to do is not likely to terminate  
>within days...

The empirically derived limit on my machine (under R 1.9.1) was approximately 7500 data points.
I have been able to successfully run the script that uses package MCLUST on several hundred smaller data sets.

I even had written a work-around for the case of greater than 9600 data points (the limit when using R 2.2.1).  My work-around first orders the points by their value then takes a sample (e.g. every other point or 1 point every n points) in order to bring the number under 9600.  No problems with the computations were observed, but you are correct that a deconvolution on that larger dataset of 9600 takes almost 30 minutes.  However, for our purposes, we do not have many datasets over 9600 so the time is not a major constraint.

Unfortunately, my management does not like using a work-around and really wants to operate on the larger data sets.
I was told to find a way to make it operate on the larger data sets or avoid using R and find another solution.  

>From previous programming projects in a different scientific field long ago, I recall making a trade-off of using temp files instead of holding data in memory in order to make working with larger data sets possible.  I am wondering if something like that would be possible for this situation, but I don't have enough knowledge at this moment to make this decision.

Karen
---
Karen M. Green, Ph.D.
Karen.Green at sanofi-aventis.com
Research Investigator
Drug Design Group
Sanofi Aventis Pharmaceuticals
Tucson, AZ  85737

-----Original Message-----
From: Simon Urbanek [mailto:simon.urbanek at r-project.org]
Sent: Thursday, January 05, 2006 5:13 PM
To: Green, Karen M. PH/US
Cc: R-devel at stat.math.ethz.ch
Subject: Re: [Rd] Q: R 2.2.1: Memory Management Issues?
Importance: High


Karen,

On Jan 5, 2006, at 5:18 PM, <Karen.Green at sanofi-aventis.com>  
<Karen.Green at sanofi-aventis.com> wrote:

> I am trying to run a R script which makes use of the MCLUST package.
> The script can successfully read in the approximately 17000 data  
> points ok, but then throws an error:
> --------------------------------------------------------
> Error:  cannot allocate vector of size 1115070Kb

This is 1.1GB of RAM to allocate alone for one vector(!). As you  
stated yourself the total upper limit is 2GB, so you cannot even fit  
two of those in memory anyway - not much you can do with it even if  
it is allocated.

> summary(EMclust(y),y)

I suspect that memory is your least problem. Did you even try to run  
EMclust on a small subsample? I suspect that if you did, you would  
figure out that what you are trying to do is not likely to terminate  
within days...

> (1) I had initially thought that Windows 2000 should be able to  
> allocate up to about 2 GB memory.  So, why is there a problem to  
> allocate a little over 1GB on a defragmented disk with over 15 GB  
> free?  (Is this a pagefile size issue?)

Because that is not the only 1GB vector that is allocated. Your "15GB/ 
defragmented" are irrelevant - if at all, look how much virtual  
memory is set up in you system's preferences.

> (2) Do you think the origin of the problem is
>     (a) the R environment, or
>     (b) the function in the MCLUST package using an in-memory  
> instead of an on-disk approach?

Well, a toy example of 17000x2 needs 2.3GB and it's unlikely to  
terminate anytime soon, so I'd rather call it shooting with the wrong  
gun. Maybe you should consider different approach to your problem -  
possibly ask at the BioConductor list, because people there have more  
experience with large data and this is not really a technical  
question about R, but rather how to apply statistical methods.

> (3)
>     (a) If the problem originates in the R environment, would  
> switching to the Linux version of R solve the problem?

Any reasonable unix will do - technically (64-bit versions  
preferably, but in your case even 32-bit would do). Again, I don't  
think memory is your only problem here, though.

Cheers,
Simon


From simon.urbanek at r-project.org  Fri Jan  6 02:38:31 2006
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Thu, 5 Jan 2006 20:38:31 -0500
Subject: [Rd] Q: R 2.2.1:  Memory Management Issues?
In-Reply-To: <3CB6B0EE6816B142859B24E77724A8B8F87DDE@sccsmxsusr05.pharma.aventis.com>
References: <3CB6B0EE6816B142859B24E77724A8B8F87DDE@sccsmxsusr05.pharma.aventis.com>
Message-ID: <E4275319-FE4E-44AC-9695-980D0090C5BA@r-project.org>

On Jan 5, 2006, at 7:33 PM, <Karen.Green at sanofi-aventis.com>  
<Karen.Green at sanofi-aventis.com> wrote:

> The empirically derived limit on my machine (under R 1.9.1) was  
> approximately 7500 data points.
> I have been able to successfully run the script that uses package  
> MCLUST on several hundred smaller data sets.
>
> I even had written a work-around for the case of greater than 9600  
> data points.  My work-around first orders the
> points by their value then takes a sample (e.g. every other point  
> or 1 point every n points) in order to bring the number under  
> 9600.  No problems with the computations were observed, but you are  
> correct that a deconvolution on that larger dataset of 9600 takes  
> almost 30 minutes.  However, for our purposes, we do not have many  
> datasets over 9600 so the time is not a major constraint.
>
> Unfortunately, my management does not like using a work-around and  
> really wants to operate on the larger data sets.
> I was told to find a way to make it operate on the larger data sets  
> or avoid using R and find another solution.

Well, sure, if your only concern is the memory then moving to unix  
will give you several hundred more data points you can use. I would  
recommend a  64-bit unix preferably, because then there is  
practically no software limit on the size of virtual memory.  
Nevertheless there is still a limit of ca. 4GB for a single vector,  
so that should give you around 32500 rows that mclust can handle as- 
is (I don't want to see the runtime, though ;)). For anything else  
you'll really have to think about another approach..

Cheers,
Simon


From hpages at fhcrc.org  Fri Jan  6 02:41:42 2006
From: hpages at fhcrc.org (Herve Pages)
Date: Thu, 05 Jan 2006 17:41:42 -0800
Subject: [Rd] Pb with agrep()
In-Reply-To: <17340.57501.191566.727447@stat.math.ethz.ch>
References: <43BC767F.4060405@fhcrc.org>
	<17340.57501.191566.727447@stat.math.ethz.ch>
Message-ID: <43BDCAD6.1040808@fhcrc.org>

Martin Maechler wrote:

>If you specify max$all as "100%", i.e, as 0.9999  ('< 1' !)  everything works
>as you expect it:
>
>agrep(pattern, subject, max = list(ins=0, del=0, sub= 2, all = 0.9999))
>## --> 2 3 4
>  
>
OK I got it! Thanks for the explanation.
Cheers,

Herv?

-- 
------------------------
Herv? Pag?s
E-mail: hpages at fhcrc.org
 Phone: (206) 667-5791
   Fax: (206) 667-1319


From ripley at stats.ox.ac.uk  Fri Jan  6 09:44:28 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 6 Jan 2006 08:44:28 +0000 (GMT)
Subject: [Rd] Q: R 2.2.1:  Memory Management Issues?
In-Reply-To: <7BB23955-EC08-43D3-9465-AD12540C17A3@r-project.org>
References: <3CB6B0EE6816B142859B24E77724A8B8F87DDD@sccsmxsusr05.pharma.aventis.com>
	<7BB23955-EC08-43D3-9465-AD12540C17A3@r-project.org>
Message-ID: <Pine.LNX.4.61.0601060834460.18569@gannet.stats>

On Thu, 5 Jan 2006, Simon Urbanek wrote:

> Karen,
>
> On Jan 5, 2006, at 5:18 PM, <Karen.Green at sanofi-aventis.com>
> <Karen.Green at sanofi-aventis.com> wrote:
>
>> I am trying to run a R script which makes use of the MCLUST package.
>> The script can successfully read in the approximately 17000 data
>> points ok, but then throws an error:
>> --------------------------------------------------------
>> Error:  cannot allocate vector of size 1115070Kb
>
> This is 1.1GB of RAM to allocate alone for one vector(!). As you
> stated yourself the total upper limit is 2GB, so you cannot even fit
> two of those in memory anyway - not much you can do with it even if
> it is allocated.

Just in case people missed this (Simon as a MacOS user has no reason to 
know this), the Windows limit is in fact 3Gb if you tell your OS to allow 
it.  (How is in the quoted rw-FAQ, Q2.9, and from 2.2.1 R will 
automatically notice this whereas earlier versions needed to be told.)

However, there is another problem with a 32-bit OS:  you can only fit 2 
1.1Gb objects in a 3Gb address space if they are in specific positions, 
and fragmentation is often a big problem.

I believe a 64-bit OS with 4Gb of RAM would handle such problems much 
more comfortably.  The alternative is to find (or write) more efficient 
mixture-fitting software than mclust.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ernesto at ipimar.pt  Fri Jan  6 11:28:25 2006
From: ernesto at ipimar.pt (ernesto)
Date: Fri, 06 Jan 2006 10:28:25 +0000
Subject: [Rd] extending lattice to S4 classes
In-Reply-To: <eb555e660601051021w30ea1754ge3b9763af7c570f4@mail.gmail.com>
References: <434F88B9.1020600@ipimar.pt> <434FD8C2.205@ipimar.pt>	
	<Pine.LNX.4.61.0510150758480.27345@gannet.stats>	
	<4354D388.9000209@ipimar.pt>	
	<eb555e660510191045s5de87a89p714e5fa8929a053b@mail.gmail.com>	
	<43575CA0.9060807@ipimar.pt>
	<eb555e660601051021w30ea1754ge3b9763af7c570f4@mail.gmail.com>
Message-ID: <43BE4649.6080307@ipimar.pt>

Deepayan Sarkar wrote:

>On 10/20/05, ernesto <ernesto at ipimar.pt> wrote:
>
>[...]
>
>  
>
>>Hi Deepayan,
>>
>>I see that there are alternatives, I found one my self that works and
>>it's transparent for the user.
>>
>>I don't want to implement solutions that force the user to use lattice
>>methods differently from your implementation.
>>
>>The cleanest solution as you say is to add a data argument to xyplot but
>>I can't do it so I would not propose it.
>>    
>>
>
>FYI, I have added the 'data' argument to high level generics in
>lattice_0.13-1, available for r-devel (of course this causes the
>current version of FLCore to fail).
>
>Deepayan
>--
>http://www.stat.wisc.edu/~deepayan/
>  
>
Hi,

Thanks for your help. I'll deal with it asap.

Regards

EJ


From roebuck at mdanderson.org  Fri Jan  6 15:38:29 2006
From: roebuck at mdanderson.org (Paul Roebuck)
Date: Fri, 6 Jan 2006 08:38:29 -0600 (CST)
Subject: [Rd] Using STL containers in R/C++
In-Reply-To: <43BDA55A.7050502@DecisionSynergy.com>
References: <200601050222.k052MSss030085@saturn.software.umn.edu>
	<loom.20060105T154400-143@post.gmane.org>
	<43BDA55A.7050502@DecisionSynergy.com>
Message-ID: <Pine.OSF.4.58.0601060802070.394412@wotan.mdacc.tmc.edu>

On Thu, 5 Jan 2006, Dominick Samperi wrote:

> Dirk Eddelbuettel wrote:
>
>> Dominick Samperi wrote a Rcpp.{hpp,cpp} class for
>> C++ to R interface that is used in RQuantLib. Dominick
>> was musing about releasing this stand-alone to CRAN
>> as well, but I don't think it has happened.
>
> It just happened. I uploaded Rcpp to CRAN today. The
> package contains a  PDF file Rcpp.pdf that describes
> the package and the class library.

It seems to me from looking at page 4 of your PDF that
your error handling is still incomplete. Calling error()
from within the catch handler will invoke a setjmp() and
the exception object's memory will not be reclaimed.

The code I wrote for C++ was basically similar except
that it copied the exception string into R temporary memory
allocated in the catch handler. Thus the exception object
will have been destroyed prior to invocation of error()
and R's garbage collection will take care of the rest
after the error message is printed.


SEXP do_something(SEXP vntObj1, SEXP vntObj2, SEXP vntObj3)
{
    unsigned n = 0;
    // Do PROTECT() stuff, incrementing n after each

    // Extract protected object info to C/C++ pointer variables

    bool fError = false;
    char* szDetail = NULL;

    try
    {
        // Make C++ calls that perform procedure logic
    }
    catch (const std::exception& e)
    {
        const char* const szMsg = e.what();
        void* rheap = R_alloc(std::strlen(szMsg)+1, sizeof(char));
        szDetail = static_cast<char*>(rheap);
        std::strcpy(szDetail, szMsg);
        fError = true;
    }
    catch (...)
    {
        const char* const szMsg = "unhandled exception";
        void* rheap = R_alloc(std::strlen(szMsg)+1, sizeof(char));
        szDetail = static_cast<char*>(rheap);
        std::strcpy(szDetail, szMsg);
        fError = true;
    }

    if (fError)
    {
        Rf_error(szDetail);
        /*NOTREACHED*/
    }

    UNPROTECT(n);

    return NULL_USER_OBJECT;
}


----------------------------------------------------------
SIGSIG -- signature too long (core dumped)


From casella at stat.ufl.edu  Fri Jan  6 15:43:45 2006
From: casella at stat.ufl.edu (casella@stat.ufl.edu)
Date: Fri,  6 Jan 2006 15:43:45 +0100 (CET)
Subject: [Rd] Multiplication (PR#8466)
Message-ID: <20060106144345.5682219AC0@slim.kubism.ku.dk>

hi - in version 2.1 the command

 >-2^2

gives

-4

as the answer.  (-2)^2 is evaluated correctly.

Cheers,

George Casella


-- 
George Casella                  	Phone: (352) 392-1941 Ext. 204
Distinguished Professor and Chair	Cell:  (352) 682-7210
Department of Statistics  		Fax:   (352) 392-5175
University of Florida           	Email: casella at stat.ufl.edu
P.O. Box 118545
Gainesville, FL 32611-8545


From tlumley at u.washington.edu  Fri Jan  6 16:15:40 2006
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Fri, 6 Jan 2006 07:15:40 -0800 (PST)
Subject: [Rd] Multiplication (PR#8466)
In-Reply-To: <20060106144345.5682219AC0@slim.kubism.ku.dk>
References: <20060106144345.5682219AC0@slim.kubism.ku.dk>
Message-ID: <Pine.LNX.4.64.0601060712540.7293@homer24.u.washington.edu>

On Fri, 6 Jan 2006, casella at stat.ufl.edu wrote:

> hi - in version 2.1 the command
>
> >-2^2
>
> gives
>
> -4
>
> as the answer.  (-2)^2 is evaluated correctly.

So is -2^2.  The precedence of ^ is higher than that of unary minus. It 
may be surprising, but it *is* documented and has been in S for a long 
time.


 	-thomas

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle


From ggrothendieck at gmail.com  Fri Jan  6 16:33:05 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 6 Jan 2006 10:33:05 -0500
Subject: [Rd] Multiplication (PR#8466)
In-Reply-To: <Pine.LNX.4.64.0601060712540.7293@homer24.u.washington.edu>
References: <20060106144345.5682219AC0@slim.kubism.ku.dk>
	<Pine.LNX.4.64.0601060712540.7293@homer24.u.washington.edu>
Message-ID: <971536df0601060733y432c989avf033983bd5ffeae3@mail.gmail.com>

On 1/6/06, Thomas Lumley <tlumley at u.washington.edu> wrote:
> On Fri, 6 Jan 2006, casella at stat.ufl.edu wrote:
>
> > hi - in version 2.1 the command
> >
> > >-2^2
> >
> > gives
> >
> > -4
> >
> > as the answer.  (-2)^2 is evaluated correctly.
>
> So is -2^2.  The precedence of ^ is higher than that of unary minus. It
> may be surprising, but it *is* documented and has been in S for a long
> time.

See ?Syntax


From ggrothendieck at gmail.com  Fri Jan  6 16:33:17 2006
From: ggrothendieck at gmail.com (ggrothendieck@gmail.com)
Date: Fri,  6 Jan 2006 16:33:17 +0100 (CET)
Subject: [Rd] Multiplication (PR#8466)
Message-ID: <20060106153317.0D12BE7B9@slim.kubism.ku.dk>

On 1/6/06, Thomas Lumley <tlumley at u.washington.edu> wrote:
> On Fri, 6 Jan 2006, casella at stat.ufl.edu wrote:
>
> > hi - in version 2.1 the command
> >
> > >-2^2
> >
> > gives
> >
> > -4
> >
> > as the answer.  (-2)^2 is evaluated correctly.
>
> So is -2^2.  The precedence of ^ is higher than that of unary minus. It
> may be surprising, but it *is* documented and has been in S for a long
> time.

See ?Syntax


From roger.bos at gmail.com  Fri Jan  6 16:56:48 2006
From: roger.bos at gmail.com (roger bos)
Date: Fri, 6 Jan 2006 10:56:48 -0500
Subject: [Rd] Multiplication (PR#8466)
In-Reply-To: <20060106153317.0D12BE7B9@slim.kubism.ku.dk>
References: <20060106153317.0D12BE7B9@slim.kubism.ku.dk>
Message-ID: <1db726800601060756i49b0c12ar93b72ad43a028901@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20060106/c5b5193b/attachment.pl

From ggrothendieck at gmail.com  Fri Jan  6 17:09:10 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 6 Jan 2006 11:09:10 -0500
Subject: [Rd] Multiplication (PR#8466)
In-Reply-To: <1db726800601060756i49b0c12ar93b72ad43a028901@mail.gmail.com>
References: <20060106153317.0D12BE7B9@slim.kubism.ku.dk>
	<1db726800601060756i49b0c12ar93b72ad43a028901@mail.gmail.com>
Message-ID: <971536df0601060809t147f2095l7bf6ef38f42851a1@mail.gmail.com>

Precedence rules are tricky, in general, and the usual
advice with most programming languages is to liberally use
parentheses when in doubt.  Its actually not that surprising
in this case but consider 0-1:3 and -1:3 which give different
results since one uses binary minus and the other uses
unary minus and the order of precedence from highest to
lowest is unary minus, : and binary minus.  If one used
parentheses in these cases it would be clear even without
detailed knowledge of the precedence rules (which likely
no one can remember anyways).

On 1/6/06, roger bos <roger.bos at gmail.com> wrote:
> How do people even notice stuff like this.  You would never hard-coding
> (-2)^2 or -2^2 anyway. The part being squared would be a variable, in which
> case it works correctly:
>
> > a<- -2
> > a
> [1] -2
> > a^2
> [1] 4
>
> Sometimes it seems that people go looking for bugs... and therefore see bugs
> all around them.
>
> On 1/6/06, ggrothendieck at gmail.com <ggrothendieck at gmail.com> wrote:
> >
> > On 1/6/06, Thomas Lumley <tlumley at u.washington.edu> wrote:
> > > On Fri, 6 Jan 2006, casella at stat.ufl.edu wrote:
> > >
> > > > hi - in version 2.1 the command
> > > >
> > > > >-2^2
> > > >
> > > > gives
> > > >
> > > > -4
> > > >
> > > > as the answer.  (-2)^2 is evaluated correctly.
> > >
> > > So is -2^2.  The precedence of ^ is higher than that of unary minus. It
> > > may be surprising, but it *is* documented and has been in S for a long
> > > time.
> >
> > See ?Syntax
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
>
>        [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From p.dalgaard at biostat.ku.dk  Fri Jan  6 17:26:19 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 06 Jan 2006 17:26:19 +0100
Subject: [Rd] Multiplication (PR#8466)
In-Reply-To: <Pine.LNX.4.64.0601060712540.7293@homer24.u.washington.edu>
References: <20060106144345.5682219AC0@slim.kubism.ku.dk>
	<Pine.LNX.4.64.0601060712540.7293@homer24.u.washington.edu>
Message-ID: <x27j9dtj9w.fsf@viggo.kubism.ku.dk>

Thomas Lumley <tlumley at u.washington.edu> writes:

> On Fri, 6 Jan 2006, casella at stat.ufl.edu wrote:
> 
> > hi - in version 2.1 the command
> >
> > >-2^2
> >
> > gives
> >
> > -4
> >
> > as the answer.  (-2)^2 is evaluated correctly.
> 
> So is -2^2.  The precedence of ^ is higher than that of unary minus. It 
> may be surprising, but it *is* documented and has been in S for a long 
> time.

Pretty much standard too, for languages that have an exponentiation
operator. AFAICS Fortran, Perl, SAS all have ** at higher precedence
than unary minus (or equal, but evaluate right to left). Stata seems
like it might be the exception.

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From p.dalgaard at biostat.ku.dk  Fri Jan  6 17:26:25 2006
From: p.dalgaard at biostat.ku.dk (p.dalgaard@biostat.ku.dk)
Date: Fri,  6 Jan 2006 17:26:25 +0100 (CET)
Subject: [Rd] Multiplication (PR#8466)
Message-ID: <20060106162625.35A6D17544@slim.kubism.ku.dk>

Thomas Lumley <tlumley at u.washington.edu> writes:

> On Fri, 6 Jan 2006, casella at stat.ufl.edu wrote:
> 
> > hi - in version 2.1 the command
> >
> > >-2^2
> >
> > gives
> >
> > -4
> >
> > as the answer.  (-2)^2 is evaluated correctly.
> 
> So is -2^2.  The precedence of ^ is higher than that of unary minus. It 
> may be surprising, but it *is* documented and has been in S for a long 
> time.

Pretty much standard too, for languages that have an exponentiation
operator. AFAICS Fortran, Perl, SAS all have ** at higher precedence
than unary minus (or equal, but evaluate right to left). Stata seems
like it might be the exception.

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From hpages at fhcrc.org  Fri Jan  6 21:05:20 2006
From: hpages at fhcrc.org (Herve Pages)
Date: Fri, 06 Jan 2006 12:05:20 -0800
Subject: [Rd] 'cannot create directory' bug fixed
Message-ID: <43BECD80.1030105@fhcrc.org>

Hi everybody,


I'd like to report that the 'cannot create directory' bug that we used 
to have with
'R CMD build' on Windows (and sometimes on Linux too) seems to have 
disappeared.
It's really nice because, thanks to this fix, for the first time we have 
a reliable
automated build system for the Bioconductor packages (they are currently 
166 and we
use R-devel r36823).

So thanks to whoever fixed the bug!


Herv?


PS: R CMD build still doesn't clean after itself though but this is less 
of a problem...


-- 
------------------------
Herv? Pag?s
E-mail: hpages at fhcrc.org
Phone: (206) 667-5791
Fax: (206) 667-1319


From David.Brahm at geodecapital.com  Fri Jan  6 21:48:09 2006
From: David.Brahm at geodecapital.com (Brahm, David)
Date: Fri, 6 Jan 2006 15:48:09 -0500
Subject: [Rd] Multiplication (PR#8466)
Message-ID: <4DD6F8B8782D584FABF50BF3A32B03D801A2BCDC@MSGBOSCLF2WIN.DMN1.FMR.COM>

While we're swapping precedence tales, can you guess what this gives:

> q <- TRUE
> 2 + !q + 3

It's "2", not "5".  Bit me in the arse just the other day :-)

-- David Brahm (brahm at alum.mit.edu)


From hpages at fhcrc.org  Sat Jan  7 00:29:11 2006
From: hpages at fhcrc.org (Herve Pages)
Date: Fri, 06 Jan 2006 15:29:11 -0800
Subject: [Rd] Multiplication (PR#8466)
In-Reply-To: <Pine.LNX.4.64.0601060712540.7293@homer24.u.washington.edu>
References: <20060106144345.5682219AC0@slim.kubism.ku.dk>
	<Pine.LNX.4.64.0601060712540.7293@homer24.u.washington.edu>
Message-ID: <43BEFD47.1010605@fhcrc.org>

Thomas Lumley wrote:

>On Fri, 6 Jan 2006, casella at stat.ufl.edu wrote:
>
>  
>
>>hi - in version 2.1 the command
>>
>>    
>>
>>>-2^2
>>>      
>>>
>>gives
>>
>>-4
>>
>>as the answer.  (-2)^2 is evaluated correctly.
>>    
>>
>
>So is -2^2.  The precedence of ^ is higher than that of unary minus. It 
>may be surprising, but it *is* documented and has been in S for a long 
>time.
>
>
> 	-thomas
>  
>
No, it's not surprising. At least to me...
In the country where I grew up, I've been teached that -x^2 means -(x^2)
not (-x)^2 ;-)

H.

-- 
------------------------
Herv? Pag?s
E-mail: hpages at fhcrc.org
 Phone: (206) 667-5791
   Fax: (206) 667-1319


From hpages at fhcrc.org  Sat Jan  7 00:29:30 2006
From: hpages at fhcrc.org (hpages@fhcrc.org)
Date: Sat,  7 Jan 2006 00:29:30 +0100 (CET)
Subject: [Rd] Multiplication (PR#8466)
Message-ID: <20060106232930.3498215ABB@slim.kubism.ku.dk>

Thomas Lumley wrote:

>On Fri, 6 Jan 2006, casella at stat.ufl.edu wrote:
>
>  
>
>>hi - in version 2.1 the command
>>
>>    
>>
>>>-2^2
>>>      
>>>
>>gives
>>
>>-4
>>
>>as the answer.  (-2)^2 is evaluated correctly.
>>    
>>
>
>So is -2^2.  The precedence of ^ is higher than that of unary minus. It 
>may be surprising, but it *is* documented and has been in S for a long 
>time.
>
>
> 	-thomas
>  
>
No, it's not surprising. At least to me...
In the country where I grew up, I've been teached that -x^2 means -(x^2)
not (-x)^2 ;-)

H.

-- 
------------------------
Herv? Pag?s
E-mail: hpages at fhcrc.org
 Phone: (206) 667-5791
   Fax: (206) 667-1319


From ross at biostat.ucsf.edu  Sat Jan  7 02:44:22 2006
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Fri, 06 Jan 2006 17:44:22 -0800
Subject: [Rd] checkpointing
In-Reply-To: <971536df0601030521u4377de72jfbd1ff4499e7deed@mail.gmail.com>
References: <Pine.GSO.4.31.0601030832230.5822-100000@markov.stats>
	<BCA2993F-D89F-4054-BB33-495B2EA8B74F@stat.berkeley.edu>
	<971536df0601030521u4377de72jfbd1ff4499e7deed@mail.gmail.com>
Message-ID: <1136598262.5639.202.camel@iron.psg.net>

Here's some code I put together for checkpointing a function being
optimized. Hooking directly into optim would require modifying its C
code, so this seemed the easiest route.  I've wanted more information on
the iterations than is currently provided, so this stuff some info back
in the calling environment (by default).

# wrapper to do checkpointing

# Ross Boylan ross at biostat.ucsf.edu
# 06-Jan-2006
# (C) 2006 Regents of University of California
# Distributed under the Gnu Public License v2 or later at your option

# If you want to checkpoint the optimization of a function f
# Use checkpoint(f) instead.  See below for other possible arguments.

# default operation for checkpoint(fnfoo) is to record the iterations
# in fnfoo.trace in the calling environment

# WARNING: Any existing variable with name in argument name
# will be deleted from the indicated frame
checkpoint <- function(f,
                       name = paste(substitute(f), ".trace", sep=""),
                       fileName = substitute(f),
                       nCalls = 1,
                       nTime = 60*15,
                       frame = parent.frame()) {
  # f is the objective function
  # frame is where to put the variable name
  # name will be a data.frame with rows containing
  #   iteration, time, value, parameters
  # fileName is the stem of the name to save for checkpointing
  #  saving will alternate between files with 0 and 1 appended
  # Saving to disk will happen every nCalls or nTime seconds,
  # whichever comes first
  if (exists(name, where=frame))
      rm(list=name, pos=frame)
  ckpt.lastSave <- 0 # alternate 0/1 for file to write to
  ckpt.lastTime <- Sys.time()  # last time saved
  function(params, ...) {
    p <- as.list(params)
    names(p) <- seq(length(params))
    if (exists(name, where=frame, inherits=FALSE)) {
      progress <- get(name, pos=frame)
      progress <- rbind(progress,
                        data.frame(row.names=dim(progress)[1]+1,
time=Sys.time(),
                        val=NA, p), deparse.level=0)
    } else
        progress <- data.frame(row.names=1, time=Sys.time(), val=NA, p)
    n <- dim(progress)[1]
    # write to disk
    if (n%%nCalls == 0 || progress[n, 1]- ckpt.lastTime > nTime) {
      ckpt.lastSave <<- (ckpt.lastSave+1) %% 2
      save(progress, file=paste(fileName, ckpt.lastSave, sep=""))
      ckpt.lastTime <<- progress[n, 1]
    }
    v <- f(params, ...)
    progress[n, 2] <- v
    assign(name, progress, pos=frame)
    v
  }
}


From casella at stat.ufl.edu  Sat Jan  7 13:47:07 2006
From: casella at stat.ufl.edu (George Casella)
Date: Sat, 07 Jan 2006 07:47:07 -0500
Subject: [Rd] Multiplication (PR#8466)
In-Reply-To: <43BEFD47.1010605@fhcrc.org>
References: <20060106144345.5682219AC0@slim.kubism.ku.dk>
	<Pine.LNX.4.64.0601060712540.7293@homer24.u.washington.edu>
	<43BEFD47.1010605@fhcrc.org>
Message-ID: <43BFB84B.30001@stat.ufl.edu>

Thanks

Herve Pages wrote:

> Thomas Lumley wrote:
> 
>> On Fri, 6 Jan 2006, casella at stat.ufl.edu wrote:
>>
>>  
>>
>>> hi - in version 2.1 the command
>>>
>>>   
>>>
>>>> -2^2
>>>>     
>>>
>>> gives
>>>
>>> -4
>>>
>>> as the answer.  (-2)^2 is evaluated correctly.
>>>   
>>
>>
>> So is -2^2.  The precedence of ^ is higher than that of unary minus. 
>> It may be surprising, but it *is* documented and has been in S for a 
>> long time.
>>
>>
>>     -thomas
>>  
>>
> No, it's not surprising. At least to me...
> In the country where I grew up, I've been teached that -x^2 means -(x^2)
> not (-x)^2 ;-)
> 
> H.
> 

-- 
George Casella                  	Phone: (352) 392-1941 Ext. 204
Distinguished Professor and Chair	Cell:  (352) 682-7210
Department of Statistics  		Fax:   (352) 392-5175
University of Florida           	Email: casella at stat.ufl.edu
P.O. Box 118545
Gainesville, FL 32611-8545


From casella at stat.ufl.edu  Sat Jan  7 13:47:09 2006
From: casella at stat.ufl.edu (casella@stat.ufl.edu)
Date: Sat,  7 Jan 2006 13:47:09 +0100 (CET)
Subject: [Rd] Multiplication (PR#8466)
Message-ID: <20060107124709.8111819FEF@slim.kubism.ku.dk>

Thanks

Herve Pages wrote:

> Thomas Lumley wrote:
> 
>> On Fri, 6 Jan 2006, casella at stat.ufl.edu wrote:
>>
>>  
>>
>>> hi - in version 2.1 the command
>>>
>>>   
>>>
>>>> -2^2
>>>>     
>>>
>>> gives
>>>
>>> -4
>>>
>>> as the answer.  (-2)^2 is evaluated correctly.
>>>   
>>
>>
>> So is -2^2.  The precedence of ^ is higher than that of unary minus. 
>> It may be surprising, but it *is* documented and has been in S for a 
>> long time.
>>
>>
>>     -thomas
>>  
>>
> No, it's not surprising. At least to me...
> In the country where I grew up, I've been teached that -x^2 means -(x^2)
> not (-x)^2 ;-)
> 
> H.
> 

-- 
George Casella                  	Phone: (352) 392-1941 Ext. 204
Distinguished Professor and Chair	Cell:  (352) 682-7210
Department of Statistics  		Fax:   (352) 392-5175
University of Florida           	Email: casella at stat.ufl.edu
P.O. Box 118545
Gainesville, FL 32611-8545


From ch-r-devel at bobobeach.com  Sat Jan  7 19:41:24 2006
From: ch-r-devel at bobobeach.com (Cyrus Harmon)
Date: Sat, 7 Jan 2006 10:41:24 -0800
Subject: [Rd] minor build problem
Message-ID: <B6EA82F9-98BE-4899-90AE-CE455AF3F391@bobobeach.com>

I'm trying to build from the latest SVN sources on Mac OS X 10.4.3  
and I seem to be having a problem making the documentation.

When I do make install, i get the following:

(sly at gigondas):~/src/R/r-devel/build-f95$ make install
make[1]: Nothing to be done for `front-matter'.
SVN-REVISION is unchanged
make[1]: Nothing to be done for `install'.
make[1]: Nothing to be done for `install'.
installing doc ...
/sw/bin/install: cannot stat `R.1': No such file or directory
make[1]: *** [install-man] Error 1
make: *** [install] Error 1

which is due to the fact that R.1 doesn't exist. When I try to make R. 
1 by going into docs and doing make svnonly, I get:

(sly at gigondas):~/src/R/r-devel/build-f95/doc$ make svnonly
make[1]: `R.fe' is up to date.
help2man: can't get `--version' info from ../src/scripts/R.fe


When I try to run help2man manually I get:

(sly at gigondas):~/src/R/r-devel/build-f95/doc$ perl  ../../R/tools/ 
help2man.pl --include=../../R/doc/R.aux --no-info --output=R.1 -- 
name="a language for data analysis and graphics" ../src/scripts/R.fe
help2man: can't get `--version' info from ../src/scripts/R.fe


If I try to get the version info from ../src/scripts/R.fe directly, I  
get:

(sly at gigondas):~/src/R/r-devel/build-f95/doc$ ../src/scripts/R.fe -- 
version
Version 2.3.0 Under development (unstable) (2006-01-07 r37011)
Copyright (C) 2006 R Development Core Team

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under the terms of the
GNU General Public License.  For more information about
these matters, see http://www.gnu.org/copyleft/gpl.html.


So that seems to work. There must be some problem parsing this  
output. Does have an idea why help2man is failing here?

Thanks,

Cyrus


From ripley at stats.ox.ac.uk  Sat Jan  7 19:53:04 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 7 Jan 2006 18:53:04 +0000 (GMT)
Subject: [Rd] minor build problem
In-Reply-To: <B6EA82F9-98BE-4899-90AE-CE455AF3F391@bobobeach.com>
References: <B6EA82F9-98BE-4899-90AE-CE455AF3F391@bobobeach.com>
Message-ID: <Pine.LNX.4.61.0601071850460.2075@gannet.stats>

We know: this is due to a change in where the version is stored that 
someone did not check the consequences of. It will be fixed shortly (I am 
testing a fix right now).  Meanwhile,

make; make; make install

works.

On Sat, 7 Jan 2006, Cyrus Harmon wrote:

> I'm trying to build from the latest SVN sources on Mac OS X 10.4.3
> and I seem to be having a problem making the documentation.
>
> When I do make install, i get the following:
>
> (sly at gigondas):~/src/R/r-devel/build-f95$ make install
> make[1]: Nothing to be done for `front-matter'.
> SVN-REVISION is unchanged
> make[1]: Nothing to be done for `install'.
> make[1]: Nothing to be done for `install'.
> installing doc ...
> /sw/bin/install: cannot stat `R.1': No such file or directory
> make[1]: *** [install-man] Error 1
> make: *** [install] Error 1
>
> which is due to the fact that R.1 doesn't exist. When I try to make R.
> 1 by going into docs and doing make svnonly, I get:
>
> (sly at gigondas):~/src/R/r-devel/build-f95/doc$ make svnonly
> make[1]: `R.fe' is up to date.
> help2man: can't get `--version' info from ../src/scripts/R.fe
>
>
> When I try to run help2man manually I get:
>
> (sly at gigondas):~/src/R/r-devel/build-f95/doc$ perl  ../../R/tools/
> help2man.pl --include=../../R/doc/R.aux --no-info --output=R.1 --
> name="a language for data analysis and graphics" ../src/scripts/R.fe
> help2man: can't get `--version' info from ../src/scripts/R.fe
>
>
> If I try to get the version info from ../src/scripts/R.fe directly, I
> get:
>
> (sly at gigondas):~/src/R/r-devel/build-f95/doc$ ../src/scripts/R.fe --
> version
> Version 2.3.0 Under development (unstable) (2006-01-07 r37011)
> Copyright (C) 2006 R Development Core Team
>
> R is free software and comes with ABSOLUTELY NO WARRANTY.
> You are welcome to redistribute it under the terms of the
> GNU General Public License.  For more information about
> these matters, see http://www.gnu.org/copyleft/gpl.html.
>
>
> So that seems to work. There must be some problem parsing this
> output. Does have an idea why help2man is failing here?
>
> Thanks,
>
> Cyrus
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From simon.urbanek at r-project.org  Sat Jan  7 19:54:49 2006
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Sat, 7 Jan 2006 13:54:49 -0500
Subject: [Rd] minor build problem
In-Reply-To: <B6EA82F9-98BE-4899-90AE-CE455AF3F391@bobobeach.com>
References: <B6EA82F9-98BE-4899-90AE-CE455AF3F391@bobobeach.com>
Message-ID: <1D0DAFC2-4F38-4A3C-9CE4-9B6C202625F5@r-project.org>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20060107/0bee8e3b/attachment.pl

From bolker at zoo.ufl.edu  Sun Jan  8 01:22:45 2006
From: bolker at zoo.ufl.edu (Ben Bolker)
Date: Sat, 07 Jan 2006 19:22:45 -0500
Subject: [Rd] confint/nls
Message-ID: <43C05B55.3040508@zoo.ufl.edu>


   I have found some "issues" (bugs?) with nls confidence intervals ...
some with the relatively new "port" algorithm, others more general
(but possibly in the "well, don't do that" category).  I have
corresponded some with Prof. Ripley about them, but I thought I
would just report how far I've gotten in case anyone else has
thoughts.  (I'm finding the code in stats/nls.R and stats/nle-profile.R
quite dense & scary ...)
   All of this has been done with R-devel from 3 Jan 2006; the changes
that Prof. Ripley already made to allow confint.nls not to crash
when algorithm="port" are in R-devel, not R-patched.

   a synopsis of the problems with confint():

with a 1-parameter model (is confint not appropriate for 1-parameter
models? it doesn't say so in the docs [by the way, "normality" is
misspelled as "nornality" in ?confint]):

    algorithm=default or plinear: get a complaint from qr.qty ('qr' and 
'y' must have the same number of rows)
    port: "cannot allocate vector of size [large]" [caused by C code
looking for dims when they aren't there]

   2-parameter models:
    default OK
    port "cannot allocate vector"
    plinear 	"Error in xy.coords"

3-parameter models are OK

   I can fix the 2-parameter port case by adding drop=FALSE in
appropriate places, but I wanted to check in just in case
there are better/more efficient ways than my slogging through
one case at a time ...

   apologies for the long message, but I am temporarily cut
off from any way to post these files to the web.

   cheers
     Ben Bolker

code that tests various combinations of numbers of parameters
and algorithms:
-----------
resmat = array(dim=c(3,2,3),
dimnames=list(npar=1:3,c("fit","confint"),c("default","plinear","port")))
resmat.fix <- resmat
## sim. values
npts=1000
set.seed(1001)
x = runif(npts)
b = 0.7
y = x^b+rnorm(npts,sd=0.05)
a =0.5
y2 = a*x^b+rnorm(npts,sd=0.05)
c = 1.0
y3 = a*(x+c)^b+rnorm(npts,sd=0.05)
d = 0.5
y4 = a*(x^d+c)^b+rnorm(npts,sd=0.05)

testfit <- function(model,start,alg) {
   tryfit <- try(fit <- 
nls(model,start=start,algorithm=alg,control=list(maxiter=200)))
   if (class(tryfit)!="try-error") {
     fitcode="OK"
     tryci <- try(confint(fit))
     if (class(tryci)!="try-error") {
       cicode="OK"
     } else cicode = as.character(tryci)
   } else {
     fitcode = as.character(tryfit)
     cicode="?"
   }
   c(fitcode,cicode)
}

m1 = c(y~x^b,y2~a*x^b,y3~a*(x+exp(logc))^b)
m2 = c(y2~x^b,y3~(x+exp(logc))^b,y4~(x^d+exp(logc))^b)
s1 = list(c(b=1),c(a=1,b=1),c(a=1,b=1,logc=0))
s2 = list(c(b=1),c(b=1,logc=0),c(b=1,logc=0,d=0.5))

for (p in 1:3) {
   resmat[p,,"default"] <- testfit(m1[[p]],start=s1[[p]],alg=NULL)
   resmat[p,,"port"] <- testfit(m1[[p]],start=s1[[p]],alg="port")
}

for (p in 1:3) {
   resmat[p,,"plinear"] <- testfit(m2[[p]],start=s2[[p]],alg="plinear")
}

print(resmat)
set.seed(1002)
example(nls,local=TRUE)

diffs:
--
*** /usr/local/src/R/R-devel/src/library/stats/R/nls.R  2006-01-07 
10:57:08.000000000 -0500
--- nlsnew.R    2006-01-07 19:18:53.000000000 -0500
***************
*** 266,277 ****
       gradSetArgs[[1]] <- (~attr(ans, "gradient"))[[2]]
       gradCall <-
           switch(length(gradSetArgs) - 1,
!                call("[", gradSetArgs[[1]], gradSetArgs[[2]]),
!                call("[", gradSetArgs[[1]], gradSetArgs[[2]], 
gradSetArgs[[2]]),
                  call("[", gradSetArgs[[1]], gradSetArgs[[2]], 
gradSetArgs[[2]],
!                     gradSetArgs[[3]]),
                  call("[", gradSetArgs[[1]], gradSetArgs[[2]], 
gradSetArgs[[2]],
!                     gradSetArgs[[3]], gradSetArgs[[4]]))
       getRHS.varying <- function()
       {
           ans <- getRHS.noVarying()
--- 266,277 ----
       gradSetArgs[[1]] <- (~attr(ans, "gradient"))[[2]]
       gradCall <-
           switch(length(gradSetArgs) - 1,
!                call("[", gradSetArgs[[1]], gradSetArgs[[2]],drop=FALSE),
!                call("[", gradSetArgs[[1]], gradSetArgs[[2]], 
gradSetArgs[[2]],drop=FALSE),
                  call("[", gradSetArgs[[1]], gradSetArgs[[2]], 
gradSetArgs[[2]],
!                     gradSetArgs[[3]],drop=FALSE),
                  call("[", gradSetArgs[[1]], gradSetArgs[[2]], 
gradSetArgs[[2]],
!                     gradSetArgs[[3]], gradSetArgs[[4]],drop=FALSE))
       getRHS.varying <- function()
       {
           ans <- getRHS.noVarying()
***************
*** 331,337 ****
                       else {
                           vary
                       }, envir = thisEnv)
!              gradCall[[length(gradCall)]] <<- useParams
                if(all(useParams)) {
                    assign("setPars", setPars.noVarying, envir = thisEnv)
                    assign("getPars", getPars.noVarying, envir = thisEnv)
--- 331,337 ----
                       else {
                           vary
                       }, envir = thisEnv)
!              gradCall[[length(gradCall)-1]] <<- useParams
                if(all(useParams)) {
                    assign("setPars", setPars.noVarying, envir = thisEnv)
                    assign("getPars", getPars.noVarying, envir = thisEnv)


From bolker at zoo.ufl.edu  Mon Jan  9 03:24:51 2006
From: bolker at zoo.ufl.edu (Ben Bolker)
Date: Sun, 08 Jan 2006 21:24:51 -0500
Subject: [Rd] prod(numeric(0)) surprise
Message-ID: <43C1C973.8080702@zoo.ufl.edu>


   It surprised me that prod(numeric(0)) is 1.
I guess if you say (operation(nothing) == identity
element) this makes sense, but ??

    Looking in the code, this makes sense:
basically (s=1; for i=0 to length(x),
multiply s by x[i]) -- which comes out to 1.

   What *should* prod(numeric(0)) produce?
I couldn't find the answer documented anywhere.

   (And how about sum(numeric(0))==0,
which for some reason makes more intuitive sense
to me, but is really exactly the same thing --
consider exp(sum(log(numeric(0)))) ... ?)

   cheers
     Ben Bolker

-- 
620B Bartram Hall                            bolker at zoo.ufl.edu
Zoology Department, University of Florida    http://www.zoo.ufl.edu/bolker
Box 118525                                   (ph)  352-392-5697
Gainesville, FL 32611-8525                   (fax) 352-392-3704


From murdoch at stats.uwo.ca  Mon Jan  9 03:34:33 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sun, 08 Jan 2006 21:34:33 -0500
Subject: [Rd] prod(numeric(0)) surprise
In-Reply-To: <43C1C973.8080702@zoo.ufl.edu>
References: <43C1C973.8080702@zoo.ufl.edu>
Message-ID: <43C1CBB9.7090307@stats.uwo.ca>

On 1/8/2006 9:24 PM, Ben Bolker wrote:
>    It surprised me that prod(numeric(0)) is 1.
> I guess if you say (operation(nothing) == identity
> element) this makes sense, but ??

What value were you expecting, or were you expecting an error?  I can't 
think how any other value could be justified, and throwing an error 
would make a lot of formulas more complicated.

> 
>     Looking in the code, this makes sense:
> basically (s=1; for i=0 to length(x),
> multiply s by x[i]) -- which comes out to 1.
> 
>    What *should* prod(numeric(0)) produce?
> I couldn't find the answer documented anywhere.
> 
>    (And how about sum(numeric(0))==0,
> which for some reason makes more intuitive sense
> to me, but is really exactly the same thing --
> consider exp(sum(log(numeric(0)))) ... ?)

That's a fairly standard mathematical convention, which is presumably 
why sum and prod work that way.

Duncan Murdoch


From bolker at zoo.ufl.edu  Mon Jan  9 03:40:05 2006
From: bolker at zoo.ufl.edu (Ben Bolker)
Date: Sun, 08 Jan 2006 21:40:05 -0500
Subject: [Rd] prod(numeric(0)) surprise
In-Reply-To: <43C1CBB9.7090307@stats.uwo.ca>
References: <43C1C973.8080702@zoo.ufl.edu> <43C1CBB9.7090307@stats.uwo.ca>
Message-ID: <43C1CD05.2030504@zoo.ufl.edu>

Duncan Murdoch wrote:
> On 1/8/2006 9:24 PM, Ben Bolker wrote:
> 
>>    It surprised me that prod(numeric(0)) is 1.
>> I guess if you say (operation(nothing) == identity
>> element) this makes sense, but ??
> 
> 
> What value were you expecting, or were you expecting an error?  I can't 
> think how any other value could be justified, and throwing an error 
> would make a lot of formulas more complicated.
> 
>>
> 
> 
> That's a fairly standard mathematical convention, which is presumably 
> why sum and prod work that way.
> 
> Duncan Murdoch

   OK.  I guess I was expecting NaN/NA (as opposed to an error),
but I take the "this makes everything else more complicated" point.
Should this be documented or is it just too obvious ... ?
(Funny -- I'm willing to take gamma(1)==1 without any argument
or suggestion that it should be documented ...)


   cheers
     Ben


-- 
620B Bartram Hall                            bolker at zoo.ufl.edu
Zoology Department, University of Florida    http://www.zoo.ufl.edu/bolker
Box 118525                                   (ph)  352-392-5697
Gainesville, FL 32611-8525                   (fax) 352-392-3704


From Mark.Bravington at csiro.au  Mon Jan  9 07:48:25 2006
From: Mark.Bravington at csiro.au (Mark.Bravington@csiro.au)
Date: Mon, 9 Jan 2006 17:48:25 +1100
Subject: [Rd] Problem installing from source: no CONTENTS files
Message-ID: <D79013E40FEF254AAF0D72DFC94F274803D997@extas4-hba.tas.csiro.au>

I've just had the error below while trying to install a package from
source under R2.2.1 and Windows XP. I recall encountering this
sporadically in the past. It is a pretty confusing message and took me
quite some time to figure out; I've seen queries about it on the R site
search, but couldn't find a reply. There's an attempted diagnosis and
suggested cure below.

D:\r2.0\debug>rcmd INSTALL --library=d:/rpackages/r2.2.1 --docs=normal
debug

---------- Making package debug ------------
<<snipped>>
installing indices
cat: C:/R/RW2021/library/*/CONTENTS: No such file or directory

What I think is happening is this. Because I installed R from binary
*without* HTML help, no CONTENTS files are created for the packages.
When running RCMD INSTALL, this causes an error in the MakePkg file (in
src/gnuwin32 on my machine), in the "indices" section at the line
starting @$(CAT) below. Commenting out the CAT line seems to work fine,
in that installation proceeds OK, and regular non-HTML help and
help.search are available for the package. The comment two lines up
suggests that the behaviour is a bug; maybe a TRY-style wrapper could be
used? If not, a different error message would be handy. I don't
understand enough about makefiles to suggest a patch, unfortunately. 

indices:
	@$(ECHO) "  installing indices"
	@$(ECHO) "invisible(.libPaths(c(.Library,\"$(RLIB)\",
.libPaths()))); tools:::.install_package_indices('.', '"$(DPKG)"')" | \
	  R_DEFAULT_PACKAGES=NULL LC_COLLATE=C R_OSTYPE=windows $(REXE)
> /dev/null
# need not have HTML installed when building packages
	@$(MKDIR) -p $(RHOME)/doc/html/search
	@$(CAT) $(RHOME)/library/*/CONTENTS >
$(RHOME)/doc/html/search/index.txt


Mark Bravington
CSIRO Mathematical & Information Sciences
Marine Laboratory
Castray Esplanade
Hobart 7001
TAS

ph (+61) 3 6232 5118
fax (+61) 3 6232 5012
mob (+61) 438 315 623


From maechler at stat.math.ethz.ch  Mon Jan  9 08:56:47 2006
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 9 Jan 2006 08:56:47 +0100
Subject: [Rd] prod(numeric(0)) surprise
In-Reply-To: <43C1CD05.2030504@zoo.ufl.edu>
References: <43C1C973.8080702@zoo.ufl.edu> <43C1CBB9.7090307@stats.uwo.ca>
	<43C1CD05.2030504@zoo.ufl.edu>
Message-ID: <17346.5951.435355.767827@stat.math.ethz.ch>

>>>>> "Ben" == Ben Bolker <bolker at zoo.ufl.edu>
>>>>>     on Sun, 08 Jan 2006 21:40:05 -0500 writes:

    Ben> Duncan Murdoch wrote:
    >> On 1/8/2006 9:24 PM, Ben Bolker wrote:
    >> 
    >>> It surprised me that prod(numeric(0)) is 1.  I guess if
    >>> you say (operation(nothing) == identity element) this
    >>> makes sense, but ??
    >> 
    >> 
    >> What value were you expecting, or were you expecting an
    >> error?  I can't think how any other value could be
    >> justified, and throwing an error would make a lot of
    >> formulas more complicated.
    >> 
    >>>
    >> 
    >> 
    >> That's a fairly standard mathematical convention, which
    >> is presumably why sum and prod work that way.
    >> 
    >> Duncan Murdoch

    Ben>    OK.  I guess I was expecting NaN/NA (as opposed to
    Ben> an error), but I take the "this makes everything else
    Ben> more complicated" point.  Should this be documented or
    Ben> is it just too obvious ... ?  (Funny -- I'm willing to
    Ben> take gamma(1)==1 without any argument or suggestion
    Ben> that it should be documented ...)

see?  so it looks to me as if you have finally convinced
yourself that '1' is the most reasonable result.. ;-)

Anyway, I've added a sentence to help(prod)  {which matches
the sentence in help(sum), BTW}.

Martin


From ripley at stats.ox.ac.uk  Mon Jan  9 10:22:29 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 9 Jan 2006 09:22:29 +0000 (GMT)
Subject: [Rd] Problem installing from source: no CONTENTS files
In-Reply-To: <D79013E40FEF254AAF0D72DFC94F274803D997@extas4-hba.tas.csiro.au>
References: <D79013E40FEF254AAF0D72DFC94F274803D997@extas4-hba.tas.csiro.au>
Message-ID: <Pine.LNX.4.61.0601090839460.8365@gannet.stats>

This will only happen if you installed R without HTML help and then 
install a package *with* HTML help *and* do so into a non-standard 
directory.  That seems an arcane thing to do: why do you want HTML help 
for some packages and not others?  You will end up with a partially 
functional system.

The fix is simple: put '-' at the beginning of that line (after the tab) 
in MakePkg.  I've put a more complete solution in R-devel.

On Mon, 9 Jan 2006 Mark.Bravington at csiro.au wrote:

> I've just had the error below while trying to install a package from
> source under R2.2.1 and Windows XP. I recall encountering this
> sporadically in the past. It is a pretty confusing message and took me
> quite some time to figure out; I've seen queries about it on the R site
> search, but couldn't find a reply.

I don't believe those are the same thing.

> There's an attempted diagnosis and
> suggested cure below.
>
> D:\r2.0\debug>rcmd INSTALL --library=d:/rpackages/r2.2.1 --docs=normal
> debug
>
> ---------- Making package debug ------------
> <<snipped>>
> installing indices
> cat: C:/R/RW2021/library/*/CONTENTS: No such file or directory
>
> What I think is happening is this. Because I installed R from binary
> *without* HTML help, no CONTENTS files are created for the packages.
> When running RCMD INSTALL, this causes an error in the MakePkg file (in
> src/gnuwin32 on my machine), in the "indices" section at the line
> starting @$(CAT) below. Commenting out the CAT line seems to work fine,
> in that installation proceeds OK, and regular non-HTML help and
> help.search are available for the package. The comment two lines up
> suggests that the behaviour is a bug; maybe a TRY-style wrapper could be
> used? If not, a different error message would be handy.

The error message is completely informative: why would you want to change 
it?

> I don't understand enough about makefiles to suggest a patch, 
> unfortunately.

A good learning project for you?


>
> indices:
> 	@$(ECHO) "  installing indices"
> 	@$(ECHO) "invisible(.libPaths(c(.Library,\"$(RLIB)\",
> .libPaths()))); tools:::.install_package_indices('.', '"$(DPKG)"')" | \
> 	  R_DEFAULT_PACKAGES=NULL LC_COLLATE=C R_OSTYPE=windows $(REXE)
>> /dev/null
> # need not have HTML installed when building packages
> 	@$(MKDIR) -p $(RHOME)/doc/html/search
> 	@$(CAT) $(RHOME)/library/*/CONTENTS >
> $(RHOME)/doc/html/search/index.txt
>
>
> Mark Bravington
> CSIRO Mathematical & Information Sciences
> Marine Laboratory
> Castray Esplanade
> Hobart 7001
> TAS
>
> ph (+61) 3 6232 5118
> fax (+61) 3 6232 5012
> mob (+61) 438 315 623
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ben.bob at gmail.com  Mon Jan  9 15:29:16 2006
From: ben.bob at gmail.com (Bo Peng)
Date: Mon, 9 Jan 2006 08:29:16 -0600
Subject: [Rd] R plot display problem under windows when using python rpy
	module.
Message-ID: <6ea7b5430601090629u6c3a6ed4r41d096e61c2579e7@mail.gmail.com>

Dear list,

Rpy is a python module that provides python interface to R. The
following simple commands

>>> from rpy import *
>>> r.plot(0)

is supposed to create a window that displays the result of plot(0).

However, we observe that
1. Under *nix, rpy+R+python  work as expected
2. Under windows, python + pythonWin32 (a python GUI provided by the
pywin32 module), work as expected
3. Under windows, if we run the commands from command line or IDLE (a
simple python IDE), a window will be created, but the figure will not
be drawn. Then, if we run r.plot(2), the result of plot(0) will be
drawn. plot(2) will be displayed when the next drawing command is
executed.

Since R works well in most cases, I do not think this is a R problem.
However, can anyone tell me what *might* block the figures from being
displayed? In other word, what might PythonWin have provided to enable
correct rendering of the figures? If I have to trace to the sources,
what portion of the R code should I have a look at? (It is good that
python/R/rpy are all open source).

Many thanks in advance.
Bo


From ripley at stats.ox.ac.uk  Mon Jan  9 15:52:18 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 9 Jan 2006 14:52:18 +0000 (GMT)
Subject: [Rd] R plot display problem under windows when using python rpy
 module.
In-Reply-To: <6ea7b5430601090629u6c3a6ed4r41d096e61c2579e7@mail.gmail.com>
References: <6ea7b5430601090629u6c3a6ed4r41d096e61c2579e7@mail.gmail.com>
Message-ID: <Pine.LNX.4.61.0601091446430.13067@gannet.stats>

How is Rpy calling R?  Presumably R is running single-threaded, and the 
problem is likely to be that Rpy is using blocking I/O on the R process 
and hence blocking the GUI callbacks that drive the window.

The not-so-simple answer is not to do it that way.  It might be well
sufficient to turn windows() buffering off -- see its help page.

On Mon, 9 Jan 2006, Bo Peng wrote:

> Dear list,
>
> Rpy is a python module that provides python interface to R. The
> following simple commands
>
>>>> from rpy import *
>>>> r.plot(0)
>
> is supposed to create a window that displays the result of plot(0).
>
> However, we observe that
> 1. Under *nix, rpy+R+python  work as expected
> 2. Under windows, python + pythonWin32 (a python GUI provided by the
> pywin32 module), work as expected
> 3. Under windows, if we run the commands from command line or IDLE (a
> simple python IDE), a window will be created, but the figure will not
> be drawn. Then, if we run r.plot(2), the result of plot(0) will be
> drawn. plot(2) will be displayed when the next drawing command is
> executed.
>
> Since R works well in most cases, I do not think this is a R problem.
> However, can anyone tell me what *might* block the figures from being
> displayed? In other word, what might PythonWin have provided to enable
> correct rendering of the figures? If I have to trace to the sources,
> what portion of the R code should I have a look at? (It is good that
> python/R/rpy are all open source).
>
> Many thanks in advance.
> Bo
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ben.bob at gmail.com  Mon Jan  9 16:48:28 2006
From: ben.bob at gmail.com (Bo Peng)
Date: Mon, 9 Jan 2006 09:48:28 -0600
Subject: [Rd] R plot display problem under windows when using python rpy
	module.
In-Reply-To: <Pine.LNX.4.61.0601091446430.13067@gannet.stats>
References: <6ea7b5430601090629u6c3a6ed4r41d096e61c2579e7@mail.gmail.com>
	<Pine.LNX.4.61.0601091446430.13067@gannet.stats>
Message-ID: <6ea7b5430601090748m4c232e2ercb54f792018982a@mail.gmail.com>

On 1/9/06, Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
> How is Rpy calling R?  Presumably R is running single-threaded, and the
> problem is likely to be that Rpy is using blocking I/O on the R process
> and hence blocking the GUI callbacks that drive the window.
>
> The not-so-simple answer is not to do it that way.  It might be well
> sufficient to turn windows() buffering off -- see its help page.

Using
>>> from rpy import *
>>> r.options(windowsBuffered=False)
>>> r.plot(0)
solves the problem.

Thank you very much! I will suggest that rpy developers address this problem.

Bo


From hin-tak.leung at cimr.cam.ac.uk  Mon Jan  9 16:49:44 2006
From: hin-tak.leung at cimr.cam.ac.uk (Hin-Tak Leung)
Date: Mon, 09 Jan 2006 15:49:44 +0000
Subject: [Rd] R plot display problem under windows when using python rpy
 module.
In-Reply-To: <6ea7b5430601090629u6c3a6ed4r41d096e61c2579e7@mail.gmail.com>
References: <6ea7b5430601090629u6c3a6ed4r41d096e61c2579e7@mail.gmail.com>
Message-ID: <43C28618.8060601@cimr.cam.ac.uk>

Hi,
(off topic slightly, and a slight flame-bait...).
I don't have an answer or clue to your question, but I have played with
PSPython briefly and it did work somewhat for me (and I have not heard 
of rpy until reading this through r-devel), and I was wondering
what is the difference between rpy and RSPython. According to the rpy page:
=============
  This code is inspired by RSPython from the Omegahat project. The main 
goals of RPy are:

     * to have a very robust interface for using R from Python
     * the interface should be as transparent and easy to use as possible
     * it should be usable for real scientific and statistical computations
=============

But "a very robust interface" is self-proclaimed and unsubstantiated; 
"transparent", "easy to use", "usable for real scientific..." are 
subjective, so what it amounts to is a case of "not-invented-here" 
symptom (i.e. wheels...). This might be flame-bait... but since I
have used PSPython very very briefly and I don't think it suffers
from the above 3 (and even if it does, it is open-source, one can
always add/modify/patch without starting new), I do wonder...

So I have a question for you - why rpy instead of RSPython? Have you 
tried both, and can you give a comparison of pros and cons?

In fact, the most obvious superficial difference I can see is that 
RSPython is written by an R-biased person (it uses "R CMD build"), where
as rpy is written by a Python-biased person (it builds with
"python setup.py ...")... there is nothing wrong with having a bias,
but the goals listed imply that it might be "better" in those areas... 
which may or may not be true.

(To answer one question you might have, I was trying to invoke Python 
code from inside R and was doing it the opposite direction from you).

HTL

Bo Peng wrote:
> Dear list,
> 
> Rpy is a python module that provides python interface to R. The
> following simple commands
> 
> 
>>>>from rpy import *
>>>>r.plot(0)
> 
> 
> is supposed to create a window that displays the result of plot(0).
> 
> However, we observe that
> 1. Under *nix, rpy+R+python  work as expected
> 2. Under windows, python + pythonWin32 (a python GUI provided by the
> pywin32 module), work as expected
> 3. Under windows, if we run the commands from command line or IDLE (a
> simple python IDE), a window will be created, but the figure will not
> be drawn. Then, if we run r.plot(2), the result of plot(0) will be
> drawn. plot(2) will be displayed when the next drawing command is
> executed.
> 
> Since R works well in most cases, I do not think this is a R problem.
> However, can anyone tell me what *might* block the figures from being
> displayed? In other word, what might PythonWin have provided to enable
> correct rendering of the figures? If I have to trace to the sources,
> what portion of the R code should I have a look at? (It is good that
> python/R/rpy are all open source).
> 
> Many thanks in advance.
> Bo
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From ben.bob at gmail.com  Mon Jan  9 17:36:37 2006
From: ben.bob at gmail.com (Bo Peng)
Date: Mon, 9 Jan 2006 10:36:37 -0600
Subject: [Rd] R plot display problem under windows when using python rpy
	module.
In-Reply-To: <43C28618.8060601@cimr.cam.ac.uk>
References: <6ea7b5430601090629u6c3a6ed4r41d096e61c2579e7@mail.gmail.com>
	<43C28618.8060601@cimr.cam.ac.uk>
Message-ID: <6ea7b5430601090836k76c9a331t4834bcd5a7a1bbca@mail.gmail.com>

> I was wondering
> what is the difference between rpy and RSPython.

The main difference is that rpy does one-way communication, is simpler
than RSPython, than is easier to use.

> So I have a question for you - why rpy instead of RSPython? Have you
> tried both, and can you give a comparison of pros and cons?

I am not an expert on RSPython. I tried RSPython and rpy and chose rpy
for the following reasons:

1. rpy is in active maintenance. As you can see from rpy webpage, rpy
supports all versions of R till 2.2.1, python 2.4 and provides binary
installers like rpy-0.4.6-R-2.0.0-to-2.2.1-xxxx.xxx . On the contrary,
a windows installer for RSPython is for R-1.4.0, python 2.2.0.

2. RSPython uses mainly its RS.call function. This is troublesome and
is the main reason why I use rpy. For example,

in RSPython:
  RS.call('rnorn', 10)
in rpy:
  r.rnorm(10)

RSPython does provide similar usage now (maybe after I became a rpy user) but
RSPython:
  from RS import R
  R.rnorm(10)   # works
  R.dev.off()     # does not work

Rpy solves this problem by (and the mechanism is clearly described in
the rpy manual):
  from rpy import *
  r.rnorm(10)
  r.dev_off()

rpy also provides
  r('''arbitrary R piece of code''')
which is immensely useful to run big trunk of R code.

rpy also claims that the performance of rpy is better but I have no
comparison data here.

>  there is nothing wrong with having a bias,
> but the goals listed imply that it might be "better" in those areas...
> which may or may not be true.

I agree.

> (To answer one question you might have, I was trying to invoke Python
> code from inside R and was doing it the opposite direction from you).

Exactly. We are doing different things so while you have to use
RSPython, I have a choice between RSPython and rpy. In my case, all
the real computations are done in C/C++, wrapped by Python. I could
have wrapped my C/C++ code in R but R is not good at wrapping C++
class hierarchy because of the different OOP mechanisms. When I need
the statistical analysis and plotting capacity of R, I use rpy.

As a matter of fact, since Python is a powerful programming language
than can handle string, text file etc better than R, I usually prepare
my data in python  and pass them to R using rpy.

Cheers,
Bo


From hin-tak.leung at cimr.cam.ac.uk  Mon Jan  9 18:33:08 2006
From: hin-tak.leung at cimr.cam.ac.uk (Hin-Tak Leung)
Date: Mon, 09 Jan 2006 17:33:08 +0000
Subject: [Rd] R plot display problem under windows when using python rpy
 module.
In-Reply-To: <6ea7b5430601090836k76c9a331t4834bcd5a7a1bbca@mail.gmail.com>
References: <6ea7b5430601090629u6c3a6ed4r41d096e61c2579e7@mail.gmail.com>	
	<43C28618.8060601@cimr.cam.ac.uk>
	<6ea7b5430601090836k76c9a331t4834bcd5a7a1bbca@mail.gmail.com>
Message-ID: <43C29E54.9080505@cimr.cam.ac.uk>

Thanks a lot for the comment and discussion. A few of mine below.

Bo Peng wrote:
<snipped older inserts>
> The main difference is that rpy does one-way communication, is simpler
> than RSPython, than is easier to use.
> 
<snipped older inserts>
> 
> I am not an expert on RSPython. I tried RSPython and rpy and chose rpy
> for the following reasons:
> 
> 1. rpy is in active maintenance. As you can see from rpy webpage, rpy
> supports all versions of R till 2.2.1, python 2.4 and provides binary
> installers like rpy-0.4.6-R-2.0.0-to-2.2.1-xxxx.xxx . On the contrary,
> a windows installer for RSPython is for R-1.4.0, python 2.2.0.

I think my original comment regarding not-invented-here still applies -
it is a shame that much of the omegahat project is defunc, but it 
doesn't mean that somebody interested in a particular orphaned project 
can't take it over or fork it or enhance on top. I suspect a small part
of simpler/easier comes from it being smaller and younger, which is 
exactly why one should think carefully about the "wheel"...

> 
> 2. RSPython uses mainly its RS.call function. This is troublesome and
> is the main reason why I use rpy. For example,
> 
> in RSPython:
>   RS.call('rnorn', 10)
> in rpy:
>   r.rnorm(10)
> 
> RSPython does provide similar usage now (maybe after I became a rpy user) but
> RSPython:
>   from RS import R
>   R.rnorm(10)   # works
>   R.dev.off()     # does not work

Maybe " R.dev("off") " ? Wild-guess here.

> 
> Rpy solves this problem by (and the mechanism is clearly described in
> the rpy manual):
>   from rpy import *
>   r.rnorm(10)
>   r.dev_off()
> 
> rpy also provides
>   r('''arbitrary R piece of code''')
> which is immensely useful to run big trunk of R code.

It might be RS.eval("...")? Again wild-guess here.

The "RS.call('routine', parameter)" syntax is actually how interpreted R 
code interacts with compiled C routines in much of R itself.

I think this difference is very much about which language one is more at 
home with.

(My background is actually somewhat stronger with Python than R, and
I was trying to learn R's C interfaces by looking at how R
interacts with more familiar languages like Perl/Python/Java)

<snipped>
> 
> Exactly. We are doing different things so while you have to use
> RSPython, I have a choice between RSPython and rpy. In my case, all
> the real computations are done in C/C++, wrapped by Python. I could
> have wrapped my C/C++ code in R but R is not good at wrapping C++
> class hierarchy because of the different OOP mechanisms. When I need
> the statistical analysis and plotting capacity of R, I use rpy.

That's correct - C++ together with R is quite painful, and I can imagine 
C++/Python being easier. (C++/R I have a little 1st hand experience
with, and I don't for C++/Python).

> As a matter of fact, since Python is a powerful programming language
> than can handle string, text file etc better than R, I usually prepare
> my data in python  and pass them to R using rpy.

Thanks. That's useful to know.

HTL


From mtmorgan at fhcrc.org  Mon Jan  9 18:40:43 2006
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Mon, 09 Jan 2006 09:40:43 -0800
Subject: [Rd] prod(numeric(0)) surprise
In-Reply-To: <17346.5951.435355.767827@stat.math.ethz.ch> (Martin Maechler's
	message of "Mon, 9 Jan 2006 08:56:47 +0100")
References: <43C1C973.8080702@zoo.ufl.edu> <43C1CBB9.7090307@stats.uwo.ca>
	<43C1CD05.2030504@zoo.ufl.edu>
	<17346.5951.435355.767827@stat.math.ethz.ch>
Message-ID: <6phslrxz4dg.fsf@gopher3.fhcrc.org>

I'm a little confused. I understand that numeric(0) means an empty
numeric vector, not the number 0 expressed as numeric. As it is now,
prod(numeric(0)) generates something -- a vector of length 1
containing the number 1 -- from nothing. I would have expected

prod(numeric(0)) ==> numeric(0)

this is consistent with

numeric(0) ==> numeric(0)
numeric(0) * 1 ==> numeric(0)
cumprod(numeric(0)) ==> numeric(0)

and, because concatenation occus before function evaluation,

prod(c(numeric(0),1)) ==> prod( c(1) ) ==> 1

I would expect sum() to behave the same way, e.g., sum(numeric(0)) ==>
numeric(0). From below,

>     >>>> consider exp(sum(log(numeric(0)))) ... ?)
>     >> 
>     >> That's a fairly standard mathematical convention, which
>     >> is presumably why sum and prod work that way.
>     >> 
>     >> Duncan Murdoch

I would have expected numeric(0) as the result (numeric(0) is the
result from log(numeric(0)), etc).

Martin (Morgan)


Martin Maechler <maechler at stat.math.ethz.ch> writes:

>>>>>> "Ben" == Ben Bolker <bolker at zoo.ufl.edu>
>>>>>>     on Sun, 08 Jan 2006 21:40:05 -0500 writes:
>
>     Ben> Duncan Murdoch wrote:
>     >> On 1/8/2006 9:24 PM, Ben Bolker wrote:
>     >> 
>     >>> It surprised me that prod(numeric(0)) is 1.  I guess if
>     >>> you say (operation(nothing) == identity element) this
>     >>> makes sense, but ??
>     >> 
>     >> 
>     >> What value were you expecting, or were you expecting an
>     >> error?  I can't think how any other value could be
>     >> justified, and throwing an error would make a lot of
>     >> formulas more complicated.
>     >> 
>     >>>
>     >> 
>     >>>> consider exp(sum(log(numeric(0)))) ... ?)
>     >> 
>     >> That's a fairly standard mathematical convention, which
>     >> is presumably why sum and prod work that way.
>     >> 
>     >> Duncan Murdoch
>
>     Ben>    OK.  I guess I was expecting NaN/NA (as opposed to
>     Ben> an error), but I take the "this makes everything else
>     Ben> more complicated" point.  Should this be documented or
>     Ben> is it just too obvious ... ?  (Funny -- I'm willing to
>     Ben> take gamma(1)==1 without any argument or suggestion
>     Ben> that it should be documented ...)
>
> see?  so it looks to me as if you have finally convinced
> yourself that '1' is the most reasonable result.. ;-)
>
> Anyway, I've added a sentence to help(prod)  {which matches
> the sentence in help(sum), BTW}.
>
> Martin
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From murdoch at stats.uwo.ca  Mon Jan  9 18:45:45 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Mon, 09 Jan 2006 12:45:45 -0500
Subject: [Rd] prod(numeric(0)) surprise
In-Reply-To: <6phslrxz4dg.fsf@gopher3.fhcrc.org>
References: <43C1C973.8080702@zoo.ufl.edu>
	<43C1CBB9.7090307@stats.uwo.ca>	<43C1CD05.2030504@zoo.ufl.edu>	<17346.5951.435355.767827@stat.math.ethz.ch>
	<6phslrxz4dg.fsf@gopher3.fhcrc.org>
Message-ID: <43C2A149.5030903@stats.uwo.ca>

On 1/9/2006 12:40 PM, Martin Morgan wrote:
> I'm a little confused. I understand that numeric(0) means an empty
> numeric vector, not the number 0 expressed as numeric. As it is now,
> prod(numeric(0)) generates something -- a vector of length 1
> containing the number 1 -- from nothing. I would have expected
> 
> prod(numeric(0)) ==> numeric(0)
> 
> this is consistent with
> 
> numeric(0) ==> numeric(0)
> numeric(0) * 1 ==> numeric(0)
> cumprod(numeric(0)) ==> numeric(0)
> 
> and, because concatenation occus before function evaluation,
> 
> prod(c(numeric(0),1)) ==> prod( c(1) ) ==> 1
> 
> I would expect sum() to behave the same way, e.g., sum(numeric(0)) ==>
> numeric(0). From below,
>

I think the code below works as I'd expect.  Would you really like the 
last answer to be numeric(0)?

 > x <- 1:10
 > sum(x)
[1] 55
 > sum(x[x>5])
[1] 40
 > sum(x[x>10])
[1] 0

Duncan Murdoch

>>     >>>> consider exp(sum(log(numeric(0)))) ... ?)
>>     >> 
>>     >> That's a fairly standard mathematical convention, which
>>     >> is presumably why sum and prod work that way.
>>     >> 
>>     >> Duncan Murdoch
> 
> I would have expected numeric(0) as the result (numeric(0) is the
> result from log(numeric(0)), etc).
> 
> Martin (Morgan)
> 
> 
> Martin Maechler <maechler at stat.math.ethz.ch> writes:
> 
>>>>>>> "Ben" == Ben Bolker <bolker at zoo.ufl.edu>
>>>>>>>     on Sun, 08 Jan 2006 21:40:05 -0500 writes:
>>
>>     Ben> Duncan Murdoch wrote:
>>     >> On 1/8/2006 9:24 PM, Ben Bolker wrote:
>>     >> 
>>     >>> It surprised me that prod(numeric(0)) is 1.  I guess if
>>     >>> you say (operation(nothing) == identity element) this
>>     >>> makes sense, but ??
>>     >> 
>>     >> 
>>     >> What value were you expecting, or were you expecting an
>>     >> error?  I can't think how any other value could be
>>     >> justified, and throwing an error would make a lot of
>>     >> formulas more complicated.
>>     >> 
>>     >>>
>>     >> 
>>     >>>> consider exp(sum(log(numeric(0)))) ... ?)
>>     >> 
>>     >> That's a fairly standard mathematical convention, which
>>     >> is presumably why sum and prod work that way.
>>     >> 
>>     >> Duncan Murdoch
>>
>>     Ben>    OK.  I guess I was expecting NaN/NA (as opposed to
>>     Ben> an error), but I take the "this makes everything else
>>     Ben> more complicated" point.  Should this be documented or
>>     Ben> is it just too obvious ... ?  (Funny -- I'm willing to
>>     Ben> take gamma(1)==1 without any argument or suggestion
>>     Ben> that it should be documented ...)
>>
>> see?  so it looks to me as if you have finally convinced
>> yourself that '1' is the most reasonable result.. ;-)
>>
>> Anyway, I've added a sentence to help(prod)  {which matches
>> the sentence in help(sum), BTW}.
>>
>> Martin
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel


From ggrothendieck at gmail.com  Mon Jan  9 18:53:36 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 9 Jan 2006 12:53:36 -0500
Subject: [Rd] prod(numeric(0)) surprise
In-Reply-To: <6phslrxz4dg.fsf@gopher3.fhcrc.org>
References: <43C1C973.8080702@zoo.ufl.edu> <43C1CBB9.7090307@stats.uwo.ca>
	<43C1CD05.2030504@zoo.ufl.edu>
	<17346.5951.435355.767827@stat.math.ethz.ch>
	<6phslrxz4dg.fsf@gopher3.fhcrc.org>
Message-ID: <971536df0601090953v1aaaa905n97c5654e582a89b0@mail.gmail.com>

The way to think about it is:

   prod(rep(x,n)) == x^n

and that works for n=0 too.

On 1/9/06, Martin Morgan <mtmorgan at fhcrc.org> wrote:
> I'm a little confused. I understand that numeric(0) means an empty
> numeric vector, not the number 0 expressed as numeric. As it is now,
> prod(numeric(0)) generates something -- a vector of length 1
> containing the number 1 -- from nothing. I would have expected
>
> prod(numeric(0)) ==> numeric(0)
>
> this is consistent with
>
> numeric(0) ==> numeric(0)
> numeric(0) * 1 ==> numeric(0)
> cumprod(numeric(0)) ==> numeric(0)
>
> and, because concatenation occus before function evaluation,
>
> prod(c(numeric(0),1)) ==> prod( c(1) ) ==> 1
>
> I would expect sum() to behave the same way, e.g., sum(numeric(0)) ==>
> numeric(0). From below,
>
> >     >>>> consider exp(sum(log(numeric(0)))) ... ?)
> >     >>
> >     >> That's a fairly standard mathematical convention, which
> >     >> is presumably why sum and prod work that way.
> >     >>
> >     >> Duncan Murdoch
>
> I would have expected numeric(0) as the result (numeric(0) is the
> result from log(numeric(0)), etc).
>
> Martin (Morgan)
>
>
> Martin Maechler <maechler at stat.math.ethz.ch> writes:
>
> >>>>>> "Ben" == Ben Bolker <bolker at zoo.ufl.edu>
> >>>>>>     on Sun, 08 Jan 2006 21:40:05 -0500 writes:
> >
> >     Ben> Duncan Murdoch wrote:
> >     >> On 1/8/2006 9:24 PM, Ben Bolker wrote:
> >     >>
> >     >>> It surprised me that prod(numeric(0)) is 1.  I guess if
> >     >>> you say (operation(nothing) == identity element) this
> >     >>> makes sense, but ??
> >     >>
> >     >>
> >     >> What value were you expecting, or were you expecting an
> >     >> error?  I can't think how any other value could be
> >     >> justified, and throwing an error would make a lot of
> >     >> formulas more complicated.
> >     >>
> >     >>>
> >     >>
> >     >>>> consider exp(sum(log(numeric(0)))) ... ?)
> >     >>
> >     >> That's a fairly standard mathematical convention, which
> >     >> is presumably why sum and prod work that way.
> >     >>
> >     >> Duncan Murdoch
> >
> >     Ben>    OK.  I guess I was expecting NaN/NA (as opposed to
> >     Ben> an error), but I take the "this makes everything else
> >     Ben> more complicated" point.  Should this be documented or
> >     Ben> is it just too obvious ... ?  (Funny -- I'm willing to
> >     Ben> take gamma(1)==1 without any argument or suggestion
> >     Ben> that it should be documented ...)
> >
> > see?  so it looks to me as if you have finally convinced
> > yourself that '1' is the most reasonable result.. ;-)
> >
> > Anyway, I've added a sentence to help(prod)  {which matches
> > the sentence in help(sum), BTW}.
> >
> > Martin
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From mtmorgan at fhcrc.org  Mon Jan  9 19:16:41 2006
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Mon, 09 Jan 2006 10:16:41 -0800
Subject: [Rd] prod(numeric(0)) surprise
In-Reply-To: <43C2A149.5030903@stats.uwo.ca> (Duncan Murdoch's message of
	"Mon, 09 Jan 2006 12:45:45 -0500")
References: <43C1C973.8080702@zoo.ufl.edu> <43C1CBB9.7090307@stats.uwo.ca>
	<43C1CD05.2030504@zoo.ufl.edu>
	<17346.5951.435355.767827@stat.math.ethz.ch>
	<6phslrxz4dg.fsf@gopher3.fhcrc.org> <43C2A149.5030903@stats.uwo.ca>
Message-ID: <6phirstz2pi.fsf@gopher3.fhcrc.org>

I guess I have to say yes, I'd exepct

x <- 1:10
sum(x[x>10]) ==> numeric(0)

this would be reinforced by recongnizing that numeric(0) is not zero,
but nothing. I guess the summation over an empty set is an empty set,
rather than a set containing the number 0. Certainly these

exp(x[x>10]) ==> numeric(0)
numeric(0) + 1 ==> numeric(0)

would give me pause.


Gabor Grothendieck <ggrothendieck at gmail.com> writes:

> The way to think about it is:
>
>    prod(rep(x,n)) == x^n
>
> and that works for n=0 too.

Hmm, Not sure what to put in for x and n? do you mean x == numeric(0),
n == 0 (0 copies of an empty set), x == ANY n == numeric(0) (an empty
set of ANYthing), x == numeric(0), n == numeric(0) ? For all of these,
x^n evaluates to numeric(0).

Martin (Morgan)

Duncan Murdoch <murdoch at stats.uwo.ca> writes:

> On 1/9/2006 12:40 PM, Martin Morgan wrote:
>> I'm a little confused. I understand that numeric(0) means an empty
>> numeric vector, not the number 0 expressed as numeric. As it is now,
>> prod(numeric(0)) generates something -- a vector of length 1
>> containing the number 1 -- from nothing. I would have expected
>> prod(numeric(0)) ==> numeric(0)
>> this is consistent with
>> numeric(0) ==> numeric(0)
>> numeric(0) * 1 ==> numeric(0)
>> cumprod(numeric(0)) ==> numeric(0)
>> and, because concatenation occus before function evaluation,
>> prod(c(numeric(0),1)) ==> prod( c(1) ) ==> 1
>> I would expect sum() to behave the same way, e.g., sum(numeric(0))
>> ==>
>> numeric(0). From below,
>>
>
> I think the code below works as I'd expect.  Would you really like the
> last answer to be numeric(0)?
>
>  > x <- 1:10
>  > sum(x)
> [1] 55
>  > sum(x[x>5])
> [1] 40
>  > sum(x[x>10])
> [1] 0
>
> Duncan Murdoch
>
>>>     >>>> consider exp(sum(log(numeric(0)))) ... ?)
>>>     >>     >> That's a fairly standard mathematical convention,
>>> which
>>>     >> is presumably why sum and prod work that way.
>>>     >>     >> Duncan Murdoch
>> I would have expected numeric(0) as the result (numeric(0) is the
>> result from log(numeric(0)), etc).
>> Martin (Morgan)
>> Martin Maechler <maechler at stat.math.ethz.ch> writes:
>>
>>>>>>>> "Ben" == Ben Bolker <bolker at zoo.ufl.edu>
>>>>>>>>     on Sun, 08 Jan 2006 21:40:05 -0500 writes:
>>>
>>>     Ben> Duncan Murdoch wrote:
>>>     >> On 1/8/2006 9:24 PM, Ben Bolker wrote:
>>>     >>     >>> It surprised me that prod(numeric(0)) is 1.  I guess
>>> if
>>>     >>> you say (operation(nothing) == identity element) this
>>>     >>> makes sense, but ??
>>>     >>     >>     >> What value were you expecting, or were you
>>> expecting an
>>>     >> error?  I can't think how any other value could be
>>>     >> justified, and throwing an error would make a lot of
>>>     >> formulas more complicated.
>>>     >>     >>>
>>>     >>     >>>> consider exp(sum(log(numeric(0)))) ... ?)
>>>     >>     >> That's a fairly standard mathematical convention,
>>> which
>>>     >> is presumably why sum and prod work that way.
>>>     >>     >> Duncan Murdoch
>>>
>>>     Ben>    OK.  I guess I was expecting NaN/NA (as opposed to
>>>     Ben> an error), but I take the "this makes everything else
>>>     Ben> more complicated" point.  Should this be documented or
>>>     Ben> is it just too obvious ... ?  (Funny -- I'm willing to
>>>     Ben> take gamma(1)==1 without any argument or suggestion
>>>     Ben> that it should be documented ...)
>>>
>>> see?  so it looks to me as if you have finally convinced
>>> yourself that '1' is the most reasonable result.. ;-)
>>>
>>> Anyway, I've added a sentence to help(prod)  {which matches
>>> the sentence in help(sum), BTW}.
>>>
>>> Martin
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel


From andy_liaw at merck.com  Mon Jan  9 19:27:41 2006
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 9 Jan 2006 13:27:41 -0500
Subject: [Rd] prod(numeric(0)) surprise
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED6D2@usctmx1106.merck.com>

If you haven't seen this in your math courses, perhaps this would help:

http://en.wikipedia.org/wiki/Empty_set

which says, in part:

Operations on the empty set

Operations performed on the empty set (as a set of things to be operated
upon) can also be confusing. (Such operations are nullary operations.) For
example, the sum of the elements of the empty set is zero, but the product
of the elements of the empty set is one (see empty product). This may seem
odd, since there are no elements of the empty set, so how could it matter
whether they are added or multiplied (since "they" do not exist)?
Ultimately, the results of these operations say more about the operation in
question than about the empty set. For instance, notice that zero is the
identity element for addition, and one is the identity element for
multiplication.


Andy


From: Martin Morgan
> 
> I guess I have to say yes, I'd exepct
> 
> x <- 1:10
> sum(x[x>10]) ==> numeric(0)
> 
> this would be reinforced by recongnizing that numeric(0) is not zero,
> but nothing. I guess the summation over an empty set is an empty set,
> rather than a set containing the number 0. Certainly these
> 
> exp(x[x>10]) ==> numeric(0)
> numeric(0) + 1 ==> numeric(0)
> 
> would give me pause.
> 
> 
> Gabor Grothendieck <ggrothendieck at gmail.com> writes:
> 
> > The way to think about it is:
> >
> >    prod(rep(x,n)) == x^n
> >
> > and that works for n=0 too.
> 
> Hmm, Not sure what to put in for x and n? do you mean x == numeric(0),
> n == 0 (0 copies of an empty set), x == ANY n == numeric(0) (an empty
> set of ANYthing), x == numeric(0), n == numeric(0) ? For all of these,
> x^n evaluates to numeric(0).
> 
> Martin (Morgan)
> 
> Duncan Murdoch <murdoch at stats.uwo.ca> writes:
> 
> > On 1/9/2006 12:40 PM, Martin Morgan wrote:
> >> I'm a little confused. I understand that numeric(0) means an empty
> >> numeric vector, not the number 0 expressed as numeric. As 
> it is now,
> >> prod(numeric(0)) generates something -- a vector of length 1
> >> containing the number 1 -- from nothing. I would have expected
> >> prod(numeric(0)) ==> numeric(0)
> >> this is consistent with
> >> numeric(0) ==> numeric(0)
> >> numeric(0) * 1 ==> numeric(0)
> >> cumprod(numeric(0)) ==> numeric(0)
> >> and, because concatenation occus before function evaluation,
> >> prod(c(numeric(0),1)) ==> prod( c(1) ) ==> 1
> >> I would expect sum() to behave the same way, e.g., sum(numeric(0))
> >> ==>
> >> numeric(0). From below,
> >>
> >
> > I think the code below works as I'd expect.  Would you 
> really like the
> > last answer to be numeric(0)?
> >
> >  > x <- 1:10
> >  > sum(x)
> > [1] 55
> >  > sum(x[x>5])
> > [1] 40
> >  > sum(x[x>10])
> > [1] 0
> >
> > Duncan Murdoch
> >
> >>>     >>>> consider exp(sum(log(numeric(0)))) ... ?)
> >>>     >>     >> That's a fairly standard mathematical convention,
> >>> which
> >>>     >> is presumably why sum and prod work that way.
> >>>     >>     >> Duncan Murdoch
> >> I would have expected numeric(0) as the result (numeric(0) is the
> >> result from log(numeric(0)), etc).
> >> Martin (Morgan)
> >> Martin Maechler <maechler at stat.math.ethz.ch> writes:
> >>
> >>>>>>>> "Ben" == Ben Bolker <bolker at zoo.ufl.edu>
> >>>>>>>>     on Sun, 08 Jan 2006 21:40:05 -0500 writes:
> >>>
> >>>     Ben> Duncan Murdoch wrote:
> >>>     >> On 1/8/2006 9:24 PM, Ben Bolker wrote:
> >>>     >>     >>> It surprised me that prod(numeric(0)) is 
> 1.  I guess
> >>> if
> >>>     >>> you say (operation(nothing) == identity element) this
> >>>     >>> makes sense, but ??
> >>>     >>     >>     >> What value were you expecting, or were you
> >>> expecting an
> >>>     >> error?  I can't think how any other value could be
> >>>     >> justified, and throwing an error would make a lot of
> >>>     >> formulas more complicated.
> >>>     >>     >>>
> >>>     >>     >>>> consider exp(sum(log(numeric(0)))) ... ?)
> >>>     >>     >> That's a fairly standard mathematical convention,
> >>> which
> >>>     >> is presumably why sum and prod work that way.
> >>>     >>     >> Duncan Murdoch
> >>>
> >>>     Ben>    OK.  I guess I was expecting NaN/NA (as opposed to
> >>>     Ben> an error), but I take the "this makes everything else
> >>>     Ben> more complicated" point.  Should this be documented or
> >>>     Ben> is it just too obvious ... ?  (Funny -- I'm willing to
> >>>     Ben> take gamma(1)==1 without any argument or suggestion
> >>>     Ben> that it should be documented ...)
> >>>
> >>> see?  so it looks to me as if you have finally convinced
> >>> yourself that '1' is the most reasonable result.. ;-)
> >>>
> >>> Anyway, I've added a sentence to help(prod)  {which matches
> >>> the sentence in help(sum), BTW}.
> >>>
> >>> Martin
> >>>
> >>> ______________________________________________
> >>> R-devel at r-project.org mailing list
> >>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
>


From murdoch at stats.uwo.ca  Mon Jan  9 19:35:03 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Mon, 09 Jan 2006 13:35:03 -0500
Subject: [Rd] prod(numeric(0)) surprise
In-Reply-To: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED6D2@usctmx1106.merck.com>
References: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED6D2@usctmx1106.merck.com>
Message-ID: <43C2ACD7.3050902@stats.uwo.ca>

On 1/9/2006 1:27 PM, Liaw, Andy wrote:
> If you haven't seen this in your math courses, perhaps this would help:
> 
> http://en.wikipedia.org/wiki/Empty_set
>

This is what is so great about Wikipedia:  it gives certainty where I'd 
only call it a fairly standard convention.  ;-)

Duncan Murdoch


> which says, in part:
> 
> Operations on the empty set
> 
> Operations performed on the empty set (as a set of things to be operated
> upon) can also be confusing. (Such operations are nullary operations.) For
> example, the sum of the elements of the empty set is zero, but the product
> of the elements of the empty set is one (see empty product). This may seem
> odd, since there are no elements of the empty set, so how could it matter
> whether they are added or multiplied (since "they" do not exist)?
> Ultimately, the results of these operations say more about the operation in
> question than about the empty set. For instance, notice that zero is the
> identity element for addition, and one is the identity element for
> multiplication.
> 
> 
> Andy
> 
> 
> From: Martin Morgan
>> 
>> I guess I have to say yes, I'd exepct
>> 
>> x <- 1:10
>> sum(x[x>10]) ==> numeric(0)
>> 
>> this would be reinforced by recongnizing that numeric(0) is not zero,
>> but nothing. I guess the summation over an empty set is an empty set,
>> rather than a set containing the number 0. Certainly these
>> 
>> exp(x[x>10]) ==> numeric(0)
>> numeric(0) + 1 ==> numeric(0)
>> 
>> would give me pause.
>> 
>> 
>> Gabor Grothendieck <ggrothendieck at gmail.com> writes:
>> 
>> > The way to think about it is:
>> >
>> >    prod(rep(x,n)) == x^n
>> >
>> > and that works for n=0 too.
>> 
>> Hmm, Not sure what to put in for x and n? do you mean x == numeric(0),
>> n == 0 (0 copies of an empty set), x == ANY n == numeric(0) (an empty
>> set of ANYthing), x == numeric(0), n == numeric(0) ? For all of these,
>> x^n evaluates to numeric(0).
>> 
>> Martin (Morgan)
>> 
>> Duncan Murdoch <murdoch at stats.uwo.ca> writes:
>> 
>> > On 1/9/2006 12:40 PM, Martin Morgan wrote:
>> >> I'm a little confused. I understand that numeric(0) means an empty
>> >> numeric vector, not the number 0 expressed as numeric. As 
>> it is now,
>> >> prod(numeric(0)) generates something -- a vector of length 1
>> >> containing the number 1 -- from nothing. I would have expected
>> >> prod(numeric(0)) ==> numeric(0)
>> >> this is consistent with
>> >> numeric(0) ==> numeric(0)
>> >> numeric(0) * 1 ==> numeric(0)
>> >> cumprod(numeric(0)) ==> numeric(0)
>> >> and, because concatenation occus before function evaluation,
>> >> prod(c(numeric(0),1)) ==> prod( c(1) ) ==> 1
>> >> I would expect sum() to behave the same way, e.g., sum(numeric(0))
>> >> ==>
>> >> numeric(0). From below,
>> >>
>> >
>> > I think the code below works as I'd expect.  Would you 
>> really like the
>> > last answer to be numeric(0)?
>> >
>> >  > x <- 1:10
>> >  > sum(x)
>> > [1] 55
>> >  > sum(x[x>5])
>> > [1] 40
>> >  > sum(x[x>10])
>> > [1] 0
>> >
>> > Duncan Murdoch
>> >
>> >>>     >>>> consider exp(sum(log(numeric(0)))) ... ?)
>> >>>     >>     >> That's a fairly standard mathematical convention,
>> >>> which
>> >>>     >> is presumably why sum and prod work that way.
>> >>>     >>     >> Duncan Murdoch
>> >> I would have expected numeric(0) as the result (numeric(0) is the
>> >> result from log(numeric(0)), etc).
>> >> Martin (Morgan)
>> >> Martin Maechler <maechler at stat.math.ethz.ch> writes:
>> >>
>> >>>>>>>> "Ben" == Ben Bolker <bolker at zoo.ufl.edu>
>> >>>>>>>>     on Sun, 08 Jan 2006 21:40:05 -0500 writes:
>> >>>
>> >>>     Ben> Duncan Murdoch wrote:
>> >>>     >> On 1/8/2006 9:24 PM, Ben Bolker wrote:
>> >>>     >>     >>> It surprised me that prod(numeric(0)) is 
>> 1.  I guess
>> >>> if
>> >>>     >>> you say (operation(nothing) == identity element) this
>> >>>     >>> makes sense, but ??
>> >>>     >>     >>     >> What value were you expecting, or were you
>> >>> expecting an
>> >>>     >> error?  I can't think how any other value could be
>> >>>     >> justified, and throwing an error would make a lot of
>> >>>     >> formulas more complicated.
>> >>>     >>     >>>
>> >>>     >>     >>>> consider exp(sum(log(numeric(0)))) ... ?)
>> >>>     >>     >> That's a fairly standard mathematical convention,
>> >>> which
>> >>>     >> is presumably why sum and prod work that way.
>> >>>     >>     >> Duncan Murdoch
>> >>>
>> >>>     Ben>    OK.  I guess I was expecting NaN/NA (as opposed to
>> >>>     Ben> an error), but I take the "this makes everything else
>> >>>     Ben> more complicated" point.  Should this be documented or
>> >>>     Ben> is it just too obvious ... ?  (Funny -- I'm willing to
>> >>>     Ben> take gamma(1)==1 without any argument or suggestion
>> >>>     Ben> that it should be documented ...)
>> >>>
>> >>> see?  so it looks to me as if you have finally convinced
>> >>> yourself that '1' is the most reasonable result.. ;-)
>> >>>
>> >>> Anyway, I've added a sentence to help(prod)  {which matches
>> >>> the sentence in help(sum), BTW}.
>> >>>
>> >>> Martin
>> >>>
>> >>> ______________________________________________
>> >>> R-devel at r-project.org mailing list
>> >>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> 
>> 
> 
> 
> ------------------------------------------------------------------------------
> Notice:  This e-mail message, together with any attachment...{{dropped}}


From mtmorgan at fhcrc.org  Mon Jan  9 19:44:58 2006
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Mon, 09 Jan 2006 10:44:58 -0800
Subject: [Rd] prod(numeric(0)) surprise
In-Reply-To: <43C2ACD7.3050902@stats.uwo.ca> (Duncan Murdoch's message of
	"Mon, 09 Jan 2006 13:35:03 -0500")
References: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED6D2@usctmx1106.merck.com>
	<43C2ACD7.3050902@stats.uwo.ca>
Message-ID: <6phek3hz1ed.fsf@gopher3.fhcrc.org>

Duncan Murdoch <murdoch at stats.uwo.ca> writes:

> On 1/9/2006 1:27 PM, Liaw, Andy wrote:
>> If you haven't seen this in your math courses, perhaps this would help:
>> http://en.wikipedia.org/wiki/Empty_set
>>
>
> This is what is so great about Wikipedia:  it gives certainty where
> I'd only call it a fairly standard convention.  ;-)
>
> Duncan Murdoch

Yes, thanks for the refresher and sorry for the noise. Martin

>> which says, in part:
>> Operations on the empty set
>> Operations performed on the empty set (as a set of things to be
>> operated
>> upon) can also be confusing. (Such operations are nullary operations.) For
>> example, the sum of the elements of the empty set is zero, but the product
>> of the elements of the empty set is one (see empty product). This may seem
>> odd, since there are no elements of the empty set, so how could it matter
>> whether they are added or multiplied (since "they" do not exist)?
>> Ultimately, the results of these operations say more about the operation in
>> question than about the empty set. For instance, notice that zero is the
>> identity element for addition, and one is the identity element for
>> multiplication.
>> Andy
>> From: Martin Morgan
>>> I guess I have to say yes, I'd exepct
>>> x <- 1:10
>>> sum(x[x>10]) ==> numeric(0)
>>> this would be reinforced by recongnizing that numeric(0) is not
>>> zero,
>>> but nothing. I guess the summation over an empty set is an empty set,
>>> rather than a set containing the number 0. Certainly these
>>> exp(x[x>10]) ==> numeric(0)
>>> numeric(0) + 1 ==> numeric(0)
>>> would give me pause.
>>> Gabor Grothendieck <ggrothendieck at gmail.com> writes:
>>> > The way to think about it is:
>>> >
>>> >    prod(rep(x,n)) == x^n
>>> >
>>> > and that works for n=0 too.
>>> Hmm, Not sure what to put in for x and n? do you mean x ==
>>> numeric(0),
>>> n == 0 (0 copies of an empty set), x == ANY n == numeric(0) (an empty
>>> set of ANYthing), x == numeric(0), n == numeric(0) ? For all of these,
>>> x^n evaluates to numeric(0).
>>> Martin (Morgan)
>>> Duncan Murdoch <murdoch at stats.uwo.ca> writes:
>>> > On 1/9/2006 12:40 PM, Martin Morgan wrote:
>>> >> I'm a little confused. I understand that numeric(0) means an empty
>>> >> numeric vector, not the number 0 expressed as numeric. As it is
>>> now,
>>> >> prod(numeric(0)) generates something -- a vector of length 1
>>> >> containing the number 1 -- from nothing. I would have expected
>>> >> prod(numeric(0)) ==> numeric(0)
>>> >> this is consistent with
>>> >> numeric(0) ==> numeric(0)
>>> >> numeric(0) * 1 ==> numeric(0)
>>> >> cumprod(numeric(0)) ==> numeric(0)
>>> >> and, because concatenation occus before function evaluation,
>>> >> prod(c(numeric(0),1)) ==> prod( c(1) ) ==> 1
>>> >> I would expect sum() to behave the same way, e.g., sum(numeric(0))
>>> >> ==>
>>> >> numeric(0). From below,
>>> >>
>>> >
>>> > I think the code below works as I'd expect.  Would you really
>>> like the
>>> > last answer to be numeric(0)?
>>> >
>>> >  > x <- 1:10
>>> >  > sum(x)
>>> > [1] 55
>>> >  > sum(x[x>5])
>>> > [1] 40
>>> >  > sum(x[x>10])
>>> > [1] 0
>>> >
>>> > Duncan Murdoch
>>> >
>>> >>>     >>>> consider exp(sum(log(numeric(0)))) ... ?)
>>> >>>     >>     >> That's a fairly standard mathematical convention,
>>> >>> which
>>> >>>     >> is presumably why sum and prod work that way.
>>> >>>     >>     >> Duncan Murdoch
>>> >> I would have expected numeric(0) as the result (numeric(0) is the
>>> >> result from log(numeric(0)), etc).
>>> >> Martin (Morgan)
>>> >> Martin Maechler <maechler at stat.math.ethz.ch> writes:
>>> >>
>>> >>>>>>>> "Ben" == Ben Bolker <bolker at zoo.ufl.edu>
>>> >>>>>>>>     on Sun, 08 Jan 2006 21:40:05 -0500 writes:
>>> >>>
>>> >>>     Ben> Duncan Murdoch wrote:
>>> >>>     >> On 1/8/2006 9:24 PM, Ben Bolker wrote:
>>> >>>     >>     >>> It surprised me that prod(numeric(0)) is 1.  I
>>> guess
>>> >>> if
>>> >>>     >>> you say (operation(nothing) == identity element) this
>>> >>>     >>> makes sense, but ??
>>> >>>     >>     >>     >> What value were you expecting, or were you
>>> >>> expecting an
>>> >>>     >> error?  I can't think how any other value could be
>>> >>>     >> justified, and throwing an error would make a lot of
>>> >>>     >> formulas more complicated.
>>> >>>     >>     >>>
>>> >>>     >>     >>>> consider exp(sum(log(numeric(0)))) ... ?)
>>> >>>     >>     >> That's a fairly standard mathematical convention,
>>> >>> which
>>> >>>     >> is presumably why sum and prod work that way.
>>> >>>     >>     >> Duncan Murdoch
>>> >>>
>>> >>>     Ben>    OK.  I guess I was expecting NaN/NA (as opposed to
>>> >>>     Ben> an error), but I take the "this makes everything else
>>> >>>     Ben> more complicated" point.  Should this be documented or
>>> >>>     Ben> is it just too obvious ... ?  (Funny -- I'm willing to
>>> >>>     Ben> take gamma(1)==1 without any argument or suggestion
>>> >>>     Ben> that it should be documented ...)
>>> >>>
>>> >>> see?  so it looks to me as if you have finally convinced
>>> >>> yourself that '1' is the most reasonable result.. ;-)
>>> >>>
>>> >>> Anyway, I've added a sentence to help(prod)  {which matches
>>> >>> the sentence in help(sum), BTW}.
>>> >>>
>>> >>> Martin
>>> >>>
>>> >>> ______________________________________________
>>> >>> R-devel at r-project.org mailing list
>>> >>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>> ------------------------------------------------------------------------------
>> Notice:  This e-mail message, together with any attachments, contains information of Merck & Co., Inc. (One Merck Drive, Whitehouse Station, New Jersey, USA 08889), and/or its affiliates (which may be known outside the United States as Merck Frosst, Merck Sharp & Dohme or MSD and in Japan, as Banyu) that may be confidential, proprietary copyrighted and/or legally privileged. It is intended solely for the use of the individual or entity named on this message.  If you are not the intended recipient, and have received this message in error, please notify us immediately by reply e-mail and then delete it from your system.
>> ------------------------------------------------------------------------------


From ripley at stats.ox.ac.uk  Mon Jan  9 20:19:48 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 9 Jan 2006 19:19:48 +0000 (GMT)
Subject: [Rd] confint/nls
In-Reply-To: <43C05B55.3040508@zoo.ufl.edu>
References: <43C05B55.3040508@zoo.ufl.edu>
Message-ID: <Pine.LNX.4.61.0601091843560.7651@gannet.stats>

These are all solved, except those for "plinear", where you cannot profile 
linear parameters and so you must specify parms (or call 
confint(profile(fm)).  And the third plinear model does not converge, so 
isn't a useful test.

On Sat, 7 Jan 2006, Ben Bolker wrote:

>
>   I have found some "issues" (bugs?) with nls confidence intervals ...
> some with the relatively new "port" algorithm, others more general
> (but possibly in the "well, don't do that" category).  I have
> corresponded some with Prof. Ripley about them, but I thought I
> would just report how far I've gotten in case anyone else has
> thoughts.  (I'm finding the code in stats/nls.R and stats/nle-profile.R
> quite dense & scary ...)
>   All of this has been done with R-devel from 3 Jan 2006; the changes
> that Prof. Ripley already made to allow confint.nls not to crash
> when algorithm="port" are in R-devel, not R-patched.
>
>   a synopsis of the problems with confint():
>
> with a 1-parameter model (is confint not appropriate for 1-parameter
> models? it doesn't say so in the docs [by the way, "normality" is
> misspelled as "nornality" in ?confint]):
>
>    algorithm=default or plinear: get a complaint from qr.qty ('qr' and
> 'y' must have the same number of rows)
>    port: "cannot allocate vector of size [large]" [caused by C code
> looking for dims when they aren't there]
>
>   2-parameter models:
>    default OK
>    port "cannot allocate vector"
>    plinear 	"Error in xy.coords"
>
> 3-parameter models are OK
>
>   I can fix the 2-parameter port case by adding drop=FALSE in
> appropriate places, but I wanted to check in just in case
> there are better/more efficient ways than my slogging through
> one case at a time ...
>
>   apologies for the long message, but I am temporarily cut
> off from any way to post these files to the web.
>
>   cheers
>     Ben Bolker
>
> code that tests various combinations of numbers of parameters
> and algorithms:
> -----------
> resmat = array(dim=c(3,2,3),
> dimnames=list(npar=1:3,c("fit","confint"),c("default","plinear","port")))
> resmat.fix <- resmat
> ## sim. values
> npts=1000
> set.seed(1001)
> x = runif(npts)
> b = 0.7
> y = x^b+rnorm(npts,sd=0.05)
> a =0.5
> y2 = a*x^b+rnorm(npts,sd=0.05)
> c = 1.0
> y3 = a*(x+c)^b+rnorm(npts,sd=0.05)
> d = 0.5
> y4 = a*(x^d+c)^b+rnorm(npts,sd=0.05)
>
> testfit <- function(model,start,alg) {
>   tryfit <- try(fit <-
> nls(model,start=start,algorithm=alg,control=list(maxiter=200)))
>   if (class(tryfit)!="try-error") {
>     fitcode="OK"
>     tryci <- try(confint(fit))
>     if (class(tryci)!="try-error") {
>       cicode="OK"
>     } else cicode = as.character(tryci)
>   } else {
>     fitcode = as.character(tryfit)
>     cicode="?"
>   }
>   c(fitcode,cicode)
> }
>
> m1 = c(y~x^b,y2~a*x^b,y3~a*(x+exp(logc))^b)
> m2 = c(y2~x^b,y3~(x+exp(logc))^b,y4~(x^d+exp(logc))^b)
> s1 = list(c(b=1),c(a=1,b=1),c(a=1,b=1,logc=0))
> s2 = list(c(b=1),c(b=1,logc=0),c(b=1,logc=0,d=0.5))
>
> for (p in 1:3) {
>   resmat[p,,"default"] <- testfit(m1[[p]],start=s1[[p]],alg=NULL)
>   resmat[p,,"port"] <- testfit(m1[[p]],start=s1[[p]],alg="port")
> }
>
> for (p in 1:3) {
>   resmat[p,,"plinear"] <- testfit(m2[[p]],start=s2[[p]],alg="plinear")
> }
>
> print(resmat)
> set.seed(1002)
> example(nls,local=TRUE)
>
> diffs:
> --
> *** /usr/local/src/R/R-devel/src/library/stats/R/nls.R  2006-01-07
> 10:57:08.000000000 -0500
> --- nlsnew.R    2006-01-07 19:18:53.000000000 -0500
> ***************
> *** 266,277 ****
>       gradSetArgs[[1]] <- (~attr(ans, "gradient"))[[2]]
>       gradCall <-
>           switch(length(gradSetArgs) - 1,
> !                call("[", gradSetArgs[[1]], gradSetArgs[[2]]),
> !                call("[", gradSetArgs[[1]], gradSetArgs[[2]],
> gradSetArgs[[2]]),
>                  call("[", gradSetArgs[[1]], gradSetArgs[[2]],
> gradSetArgs[[2]],
> !                     gradSetArgs[[3]]),
>                  call("[", gradSetArgs[[1]], gradSetArgs[[2]],
> gradSetArgs[[2]],
> !                     gradSetArgs[[3]], gradSetArgs[[4]]))
>       getRHS.varying <- function()
>       {
>           ans <- getRHS.noVarying()
> --- 266,277 ----
>       gradSetArgs[[1]] <- (~attr(ans, "gradient"))[[2]]
>       gradCall <-
>           switch(length(gradSetArgs) - 1,
> !                call("[", gradSetArgs[[1]], gradSetArgs[[2]],drop=FALSE),
> !                call("[", gradSetArgs[[1]], gradSetArgs[[2]],
> gradSetArgs[[2]],drop=FALSE),
>                  call("[", gradSetArgs[[1]], gradSetArgs[[2]],
> gradSetArgs[[2]],
> !                     gradSetArgs[[3]],drop=FALSE),
>                  call("[", gradSetArgs[[1]], gradSetArgs[[2]],
> gradSetArgs[[2]],
> !                     gradSetArgs[[3]], gradSetArgs[[4]],drop=FALSE))
>       getRHS.varying <- function()
>       {
>           ans <- getRHS.noVarying()
> ***************
> *** 331,337 ****
>                       else {
>                           vary
>                       }, envir = thisEnv)
> !              gradCall[[length(gradCall)]] <<- useParams
>                if(all(useParams)) {
>                    assign("setPars", setPars.noVarying, envir = thisEnv)
>                    assign("getPars", getPars.noVarying, envir = thisEnv)
> --- 331,337 ----
>                       else {
>                           vary
>                       }, envir = thisEnv)
> !              gradCall[[length(gradCall)-1]] <<- useParams
>                if(all(useParams)) {
>                    assign("setPars", setPars.noVarying, envir = thisEnv)
>                    assign("getPars", getPars.noVarying, envir = thisEnv)
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From tlumley at u.washington.edu  Mon Jan  9 20:54:31 2006
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon, 9 Jan 2006 11:54:31 -0800 (PST)
Subject: [Rd] prod(numeric(0)) surprise
In-Reply-To: <6phirstz2pi.fsf@gopher3.fhcrc.org>
References: <43C1C973.8080702@zoo.ufl.edu> <43C1CBB9.7090307@stats.uwo.ca>
	<43C1CD05.2030504@zoo.ufl.edu>
	<17346.5951.435355.767827@stat.math.ethz.ch>
	<6phslrxz4dg.fsf@gopher3.fhcrc.org> <43C2A149.5030903@stats.uwo.ca>
	<6phirstz2pi.fsf@gopher3.fhcrc.org>
Message-ID: <Pine.LNX.4.64.0601091046090.29697@homer23.u.washington.edu>

On Mon, 9 Jan 2006, Martin Morgan wrote:

> I guess I have to say yes, I'd exepct
>
> x <- 1:10
> sum(x[x>10]) ==> numeric(0)
>
> this would be reinforced by recongnizing that numeric(0) is not zero,
> but nothing. I guess the summation over an empty set is an empty set,
> rather than a set containing the number 0. Certainly these
>
> exp(x[x>10]) ==> numeric(0)
> numeric(0) + 1 ==> numeric(0)
>

There are some fairly simple rules in how R does it.  You do need to 
distinguish between functions (binary operators) that map two vectors of 
length n to a vector of length n and functions such as prod and sum that 
map a vector of length n to a vector of length 1.

The output of sum and prod is always of length 1, so sum(numeric(0)) and 
prod(numeric(0)) should be of length 1 (or give an error).  It is 
convenient that sum(c(x,y)) is equal to sum(x)+sum(y) and that 
prod(c(x,y)) is equal to prod(x)*prod(y), which motivates making 
sum(numeric(0)) give 0 and prod(numeric(0)) give 1.

Single argument functions such as exp(numeric(0)) seem fairly obvious: you 
have no numbers and you exponentiate them so you still have no numbers. 
You could also argue based on c() and exp() commuting.

The rules for binary operators are a little less tidy [my fault]. They 
come from the idea that x+1 should always add 1 to each element of x.  If 
you add 1 to each element of numeric(0) you get numeric(0).  The usual 
recycling rule says that the shorter vector should be repeated to make it 
the same length as the longer vector, so this is a wart.  On the other 
hand, you can't recycle a vector of length 0 to have length 1, so the 
usual recycling rule can't be applied here. This also makes matrix 
operations work, at least in the sense of getting 
matrices of the right dimension.

 	-thomas


From sdavis2 at mail.nih.gov  Mon Jan  9 20:54:53 2006
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Mon, 09 Jan 2006 14:54:53 -0500
Subject: [Rd] Interfacing R and C++
Message-ID: <BFE829BD.3534%sdavis2@mail.nih.gov>

I have a single c++ file that contains a class and a "wrapper" function that
has C-like syntax for interacting with the Class.  Basically, this wrapper
function just makes an instance of the class and then organizes the data for
return to R.  

#include <math.h>

void myFunc(double *data, int *n, double *prm, double* intervals, int* max,
double *plot) {
...
}

myClass::myclass(...) {
...
}

My question is simple:  what goes inside the extern "C" {} block.  Should it
include only the #includes, those and the "wrapper" function, or the entire
.cc file?  The answer wasn't clear to me from the Writing R extensions
manual (probably due to my c++ ignorance--using someone else's code).

> sessionInfo()
R version 2.2.0, 2005-08-11, powerpc-apple-darwin7.9.0

attached base packages:
[1] "methods"   "stats"     "graphics"  "grDevices" "utils"     "datasets"
[7] "base"

I'm trying to use the .C interface and getting segmentation faults--probably
a bug in the code, but just wanted to make sure that it wasn't a simple
issue with the extern block.

Thanks,
Sean


From ripley at stats.ox.ac.uk  Mon Jan  9 21:20:23 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 9 Jan 2006 20:20:23 +0000 (GMT)
Subject: [Rd] Interfacing R and C++
In-Reply-To: <BFE829BD.3534%sdavis2@mail.nih.gov>
References: <BFE829BD.3534%sdavis2@mail.nih.gov>
Message-ID: <Pine.LNX.4.61.0601092016380.21148@gannet.stats>

The wrapper function must be in extern "C" {} since you want to give it a 
C name (and not a mangled C++ one).  These days, the headers probably do 
not need to be, but in theory if they are C headers they should be in any 
C++ code.

I think R-exts is quite clear on this:

   To use with @R{}, the only thing we have to do is writing a wrapper
   function and ensuring that the function is enclosed in
                              ^^^^^^^^^^^^^^^^^^^^^^^^



On Mon, 9 Jan 2006, Sean Davis wrote:

> I have a single c++ file that contains a class and a "wrapper" function that
> has C-like syntax for interacting with the Class.  Basically, this wrapper
> function just makes an instance of the class and then organizes the data for
> return to R.
>
> #include <math.h>
>
> void myFunc(double *data, int *n, double *prm, double* intervals, int* max,
> double *plot) {
> ...
> }
>
> myClass::myclass(...) {
> ...
> }
>
> My question is simple:  what goes inside the extern "C" {} block.  Should it
> include only the #includes, those and the "wrapper" function, or the entire
> .cc file?  The answer wasn't clear to me from the Writing R extensions
> manual (probably due to my c++ ignorance--using someone else's code).
>
>> sessionInfo()
> R version 2.2.0, 2005-08-11, powerpc-apple-darwin7.9.0
>
> attached base packages:
> [1] "methods"   "stats"     "graphics"  "grDevices" "utils"     "datasets"
> [7] "base"
>
> I'm trying to use the .C interface and getting segmentation faults--probably
> a bug in the code, but just wanted to make sure that it wasn't a simple
> issue with the extern block.
>
> Thanks,
> Sean
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Mon Jan  9 21:22:53 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 9 Jan 2006 20:22:53 +0000 (GMT)
Subject: [Rd] prod(numeric(0)) surprise
Message-ID: <Pine.LNX.4.61.0601092021260.21148@gannet.stats>

On Mon, 9 Jan 2006, Thomas Lumley wrote:

> On Mon, 9 Jan 2006, Martin Morgan wrote:
> 
>> I guess I have to say yes, I'd exepct
>> 
>> x <- 1:10
>> sum(x[x>10]) ==> numeric(0)
>> 
>> this would be reinforced by recongnizing that numeric(0) is not zero,
>> but nothing. I guess the summation over an empty set is an empty set,
>> rather than a set containing the number 0. Certainly these
>> 
>> exp(x[x>10]) ==> numeric(0)
>> numeric(0) + 1 ==> numeric(0)
>> 
> 
> There are some fairly simple rules in how R does it.  You do need to
> distinguish between functions (binary operators) that map two vectors of
> length n to a vector of length n and functions such as prod and sum that
> map a vector of length n to a vector of length 1.
> 
> The output of sum and prod is always of length 1, so sum(numeric(0)) and
> prod(numeric(0)) should be of length 1 (or give an error).  It is
> convenient that sum(c(x,y)) is equal to sum(x)+sum(y) and that
> prod(c(x,y)) is equal to prod(x)*prod(y), which motivates making
> sum(numeric(0)) give 0 and prod(numeric(0)) give 1.
> 
> Single argument functions such as exp(numeric(0)) seem fairly obvious: you
> have no numbers and you exponentiate them so you still have no numbers.
> You could also argue based on c() and exp() commuting.
> 
> The rules for binary operators are a little less tidy [my fault]. They
> come from the idea that x+1 should always add 1 to each element of x.  If
> you add 1 to each element of numeric(0) you get numeric(0).  The usual
> recycling rule says that the shorter vector should be repeated to make it
> the same length as the longer vector, so this is a wart.  On the other
> hand, you can't recycle a vector of length 0 to have length 1, so the
> usual recycling rule can't be applied here. This also makes matrix
> operations work, at least in the sense of getting
> matrices of the right dimension.

There is an Svr4 addendum to the original S recycling rule which R 
implements: any vector/array expression with a length-0 component has a 
length-0 result. (Note the qualifier in there.)  See `S Programming' pp. 
17,27 for more details.  So the `wart' is part of a general rule.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From sdavis2 at mail.nih.gov  Mon Jan  9 21:27:28 2006
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Mon, 09 Jan 2006 15:27:28 -0500
Subject: [Rd] Interfacing R and C++
In-Reply-To: <Pine.LNX.4.61.0601092016380.21148@gannet.stats>
Message-ID: <BFE83160.3551%sdavis2@mail.nih.gov>




On 1/9/06 3:20 PM, "Prof Brian Ripley" <ripley at stats.ox.ac.uk> wrote:

> The wrapper function must be in extern "C" {} since you want to give it a
> C name (and not a mangled C++ one).  These days, the headers probably do
> not need to be, but in theory if they are C headers they should be in any
> C++ code.
> 
> I think R-exts is quite clear on this:
> 
>    To use with @R{}, the only thing we have to do is writing a wrapper
>    function and ensuring that the function is enclosed in
>                               ^^^^^^^^^^^^^^^^^^^^^^^^

Yes, the documentation is clear, provided one knows what name-mangling is
and why it is important, which I now understand better.

Thanks,
Sean


From pgilbert at bank-banque-canada.ca  Mon Jan  9 21:27:12 2006
From: pgilbert at bank-banque-canada.ca (Paul Gilbert)
Date: Mon, 09 Jan 2006 15:27:12 -0500
Subject: [Rd] [R] ouml in an .Rd
In-Reply-To: <Pine.LNX.4.61.0601062105570.11196@gannet.stats>
References: <43BED712.2030705@bank-banque-canada.ca>
	<Pine.LNX.4.61.0601062105570.11196@gannet.stats>
Message-ID: <43C2C720.2020507@bank-banque-canada.ca>

(moved from r-help)

Ok, UTF-8 works on some of my machines and latin1 on others. If I use 
one I get failure or spurious characters when I build on the wrong 
machine. Are .Rd files suppose to work on different platforms when there 
are special characters, or is this a known limitation?

Paul

Prof Brian Ripley wrote:

> It means what it says: you need to put the actual character in the file, 
> and specify the encoding for the file via \encoding.  (For you, UTF-8 or 
> latin1, I would guess.)
> 
> It's not a question of trying variations, rather of following instructions.
> 
> On Fri, 6 Jan 2006, Paul Gilbert wrote:
> 
>> I am trying to put an ouml in an .Rd file with no success. Writing R
>> Extensions suggests:
>>
>> Text which might need to be represented differently in different
>> encodings should be marked by |\enc|, e.g. |\enc{J?reskog}{Joreskog}|
>> where the first argument will be used where encodings are allowed and
>> the second should be ASCII (and is used for e.g. the text conversion).
>>
>> (Above may get mangled by the mail.) I have tried variations
>>
>>   \enc{J"oreskog}{Joreskog}
>>   \enc{J\"oreskog}{Joreskog}
>>   \enc{Jo\"reskog}{Joreskog}
>>   \enc{Jo\"reskog}{Joreskog}
>>   \enc{J\"{o}reskog}{Joreskog}
>>   \enc{J\\"{o}reskog}{Joreskog}
>>   \enc{J&ouml;oreskog}{Joreskog}
>>
>> all with no effect on the generated pdf file.  Suggestions would be
>> appreciated.
>>
>> Thanks,
>> Paul Gilbert
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! 
>> http://www.R-project.org/posting-guide.html
>>
>


From kjetilbrinchmannhalvorsen at gmail.com  Mon Jan  9 21:35:17 2006
From: kjetilbrinchmannhalvorsen at gmail.com (Kjetil Halvorsen)
Date: Mon, 9 Jan 2006 21:35:17 +0100
Subject: [Rd] prod(numeric(0)) surprise
In-Reply-To: <43C2A149.5030903@stats.uwo.ca>
References: <43C1C973.8080702@zoo.ufl.edu> <43C1CBB9.7090307@stats.uwo.ca>
	<43C1CD05.2030504@zoo.ufl.edu>
	<17346.5951.435355.767827@stat.math.ethz.ch>
	<6phslrxz4dg.fsf@gopher3.fhcrc.org> <43C2A149.5030903@stats.uwo.ca>
Message-ID: <556e90a80601091235r19bab40au330337b22ec6da42@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20060109/2f6e161f/attachment.pl

From simon.urbanek at r-project.org  Mon Jan  9 22:04:06 2006
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Mon, 9 Jan 2006 16:04:06 -0500
Subject: [Rd] prod(numeric(0)) surprise
In-Reply-To: <556e90a80601091235r19bab40au330337b22ec6da42@mail.gmail.com>
References: <43C1C973.8080702@zoo.ufl.edu> <43C1CBB9.7090307@stats.uwo.ca>
	<43C1CD05.2030504@zoo.ufl.edu>
	<17346.5951.435355.767827@stat.math.ethz.ch>
	<6phslrxz4dg.fsf@gopher3.fhcrc.org> <43C2A149.5030903@stats.uwo.ca>
	<556e90a80601091235r19bab40au330337b22ec6da42@mail.gmail.com>
Message-ID: <79E1B788-0E53-4D00-AD50-F12E18DCA37D@r-project.org>

On Jan 9, 2006, at 3:35 PM, Kjetil Halvorsen wrote:

> But this thread seems to have pointed to some inconsistencies:
>
>> cumprod( numeric(0) )
> numeric(0)
>> cumsum( numeric(0) )
> numeric(0)
>
> shouldn't this give the same as prod() and sum() in this case?

No - as Thomas explained very nicely they are a different kind of  
functions. cumXXX are n-to-n length vector functions, whereas prod/ 
sum are n to 1 vector length functions. So R is in fact very  
consistent and Thomas did exactly describe the rules.

Cheers,
Simon


From tplate at acm.org  Mon Jan  9 23:03:33 2006
From: tplate at acm.org (Tony Plate)
Date: Mon, 09 Jan 2006 15:03:33 -0700
Subject: [Rd] prod(numeric(0)) surprise
In-Reply-To: <43C2ACD7.3050902@stats.uwo.ca>
References: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED6D2@usctmx1106.merck.com>
	<43C2ACD7.3050902@stats.uwo.ca>
Message-ID: <43C2DDB5.9070600@acm.org>

Since the virtue and reliability of Wikis was brought up, I created a R 
Wiki page for this at 
http://www.sciviews.org/_rgui/wiki/doku.php?id=beginners:surprises:emptysetfuncs
:-)

Anyone: please correct errors and improve it!

Tony Plate

Duncan Murdoch wrote:
> On 1/9/2006 1:27 PM, Liaw, Andy wrote:
> 
>>If you haven't seen this in your math courses, perhaps this would help:
>>
>>http://en.wikipedia.org/wiki/Empty_set
>>
> 
> 
> This is what is so great about Wikipedia:  it gives certainty where I'd 
> only call it a fairly standard convention.  ;-)
> 
> Duncan Murdoch
> 
> 
> 
>>which says, in part:
>>
>>Operations on the empty set
>>
>>Operations performed on the empty set (as a set of things to be operated
>>upon) can also be confusing. (Such operations are nullary operations.) For
>>example, the sum of the elements of the empty set is zero, but the product
>>of the elements of the empty set is one (see empty product). This may seem
>>odd, since there are no elements of the empty set, so how could it matter
>>whether they are added or multiplied (since "they" do not exist)?
>>Ultimately, the results of these operations say more about the operation in
>>question than about the empty set. For instance, notice that zero is the
>>identity element for addition, and one is the identity element for
>>multiplication.
>>
>>
>>Andy
>>
>>
>>From: Martin Morgan
>>
>>>I guess I have to say yes, I'd exepct
>>>
>>>x <- 1:10
>>>sum(x[x>10]) ==> numeric(0)
>>>
>>>this would be reinforced by recongnizing that numeric(0) is not zero,
>>>but nothing. I guess the summation over an empty set is an empty set,
>>>rather than a set containing the number 0. Certainly these
>>>
>>>exp(x[x>10]) ==> numeric(0)
>>>numeric(0) + 1 ==> numeric(0)
>>>
>>>would give me pause.
>>>
>>>
>>>Gabor Grothendieck <ggrothendieck at gmail.com> writes:
>>>
>>>
>>>>The way to think about it is:
>>>>
>>>>   prod(rep(x,n)) == x^n
>>>>
>>>>and that works for n=0 too.
>>>
>>>Hmm, Not sure what to put in for x and n? do you mean x == numeric(0),
>>>n == 0 (0 copies of an empty set), x == ANY n == numeric(0) (an empty
>>>set of ANYthing), x == numeric(0), n == numeric(0) ? For all of these,
>>>x^n evaluates to numeric(0).
>>>
>>>Martin (Morgan)
>>>
>>>Duncan Murdoch <murdoch at stats.uwo.ca> writes:
>>>
>>>
>>>>On 1/9/2006 12:40 PM, Martin Morgan wrote:
>>>>
>>>>>I'm a little confused. I understand that numeric(0) means an empty
>>>>>numeric vector, not the number 0 expressed as numeric. As 
>>>
>>>it is now,
>>>
>>>>>prod(numeric(0)) generates something -- a vector of length 1
>>>>>containing the number 1 -- from nothing. I would have expected
>>>>>prod(numeric(0)) ==> numeric(0)
>>>>>this is consistent with
>>>>>numeric(0) ==> numeric(0)
>>>>>numeric(0) * 1 ==> numeric(0)
>>>>>cumprod(numeric(0)) ==> numeric(0)
>>>>>and, because concatenation occus before function evaluation,
>>>>>prod(c(numeric(0),1)) ==> prod( c(1) ) ==> 1
>>>>>I would expect sum() to behave the same way, e.g., sum(numeric(0))
>>>>>==>
>>>>>numeric(0). From below,
>>>>>
>>>>
>>>>I think the code below works as I'd expect.  Would you 
>>>
>>>really like the
>>>
>>>>last answer to be numeric(0)?
>>>>
>>>> > x <- 1:10
>>>> > sum(x)
>>>>[1] 55
>>>> > sum(x[x>5])
>>>>[1] 40
>>>> > sum(x[x>10])
>>>>[1] 0
>>>>
>>>>Duncan Murdoch
>>>>
>>>>
>>>>>>    >>>> consider exp(sum(log(numeric(0)))) ... ?)
>>>>>>    >>     >> That's a fairly standard mathematical convention,
>>>>>>which
>>>>>>    >> is presumably why sum and prod work that way.
>>>>>>    >>     >> Duncan Murdoch
>>>>>
>>>>>I would have expected numeric(0) as the result (numeric(0) is the
>>>>>result from log(numeric(0)), etc).
>>>>>Martin (Morgan)
>>>>>Martin Maechler <maechler at stat.math.ethz.ch> writes:
>>>>>
>>>>>
>>>>>>>>>>>"Ben" == Ben Bolker <bolker at zoo.ufl.edu>
>>>>>>>>>>>    on Sun, 08 Jan 2006 21:40:05 -0500 writes:
>>>>>>
>>>>>>    Ben> Duncan Murdoch wrote:
>>>>>>    >> On 1/8/2006 9:24 PM, Ben Bolker wrote:
>>>>>>    >>     >>> It surprised me that prod(numeric(0)) is 
>>>
>>>1.  I guess
>>>
>>>>>>if
>>>>>>    >>> you say (operation(nothing) == identity element) this
>>>>>>    >>> makes sense, but ??
>>>>>>    >>     >>     >> What value were you expecting, or were you
>>>>>>expecting an
>>>>>>    >> error?  I can't think how any other value could be
>>>>>>    >> justified, and throwing an error would make a lot of
>>>>>>    >> formulas more complicated.
>>>>>>    >>     >>>
>>>>>>    >>     >>>> consider exp(sum(log(numeric(0)))) ... ?)
>>>>>>    >>     >> That's a fairly standard mathematical convention,
>>>>>>which
>>>>>>    >> is presumably why sum and prod work that way.
>>>>>>    >>     >> Duncan Murdoch
>>>>>>
>>>>>>    Ben>    OK.  I guess I was expecting NaN/NA (as opposed to
>>>>>>    Ben> an error), but I take the "this makes everything else
>>>>>>    Ben> more complicated" point.  Should this be documented or
>>>>>>    Ben> is it just too obvious ... ?  (Funny -- I'm willing to
>>>>>>    Ben> take gamma(1)==1 without any argument or suggestion
>>>>>>    Ben> that it should be documented ...)
>>>>>>
>>>>>>see?  so it looks to me as if you have finally convinced
>>>>>>yourself that '1' is the most reasonable result.. ;-)
>>>>>>
>>>>>>Anyway, I've added a sentence to help(prod)  {which matches
>>>>>>the sentence in help(sum), BTW}.
>>>>>>
>>>>>>Martin
>>>>>>
>>>>>>______________________________________________
>>>>>>R-devel at r-project.org mailing list
>>>>>>https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>>______________________________________________
>>>R-devel at r-project.org mailing list
>>>https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>>
>>
>>
>>------------------------------------------------------------------------------
>>Notice:  This e-mail message, together with any attachment...{{dropped}}
> 
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From bolker at zoo.ufl.edu  Tue Jan 10 01:26:22 2006
From: bolker at zoo.ufl.edu (Ben Bolker)
Date: Mon, 09 Jan 2006 19:26:22 -0500
Subject: [Rd] Wikis (was about prod(numeric(0)))
Message-ID: <43C2FF2E.5060601@zoo.ufl.edu>


Tony Plate <tplate <at> acm.org> writes:

 >
 > Since the virtue and reliability of Wikis was brought up, I created a R
 > Wiki page for this at
 > 
http://www.sciviews.org/_rgui/wiki/doku.php?id=beginners:surprises:emptysetfuncs
 >
 >
 > Anyone: please correct errors and improve it!
 >
 > Tony Plate
 >

   OK, now I have another question:
I see a wiki at
http://fawn.unibw-hamburg.de/cgi-bin/Rwiki.pl?RwikiHome
administered by Detlef Steuer
   I see another at http://www.sciviews.org/_rgui/wiki/doku.php
(Phillippe Grosjean)
which is nominally geared toward beginners/GUI interfaces.

  I'm not saying I could do any better, but both of these look
as though they'd be pretty hard to get into if you were really
a beginner or intermediate R user looking for info ... Paul
John's Rtips (http://www.ku.edu/~pauljohn/R/Rtips.html) is actually
about the best example about there -- the flat hierarchy might not
work too well for a really big wiki, but having at least
a good first-level hierarchy set up (and making sure that
what new users see is not a lot of detail about how to extend
the wiki) seems really important.

   Sorry to criticize, but I am happy to start working
on populating a wiki -- but only if the structure is there
so that I can figure out where to put stuff and hope that
someone who needs it will ever be able to find it ...

-- 
620B Bartram Hall                            bolker at zoo.ufl.edu
Zoology Department, University of Florida    http://www.zoo.ufl.edu/bolker
Box 118525                                   (ph)  352-392-5697
Gainesville, FL 32611-8525                   (fax) 352-392-3704


From tplate at blackmesacapital.com  Tue Jan 10 01:56:38 2006
From: tplate at blackmesacapital.com (Tony Plate)
Date: Mon, 09 Jan 2006 17:56:38 -0700
Subject: [Rd] Wikis (was about prod(numeric(0)))
In-Reply-To: <43C2FF2E.5060601@zoo.ufl.edu>
References: <43C2FF2E.5060601@zoo.ufl.edu>
Message-ID: <43C30646.4030900@blackmesacapital.com>

I agree with everything you say about the structure and organization of 
the Wiki (needs top-level R-related structure, the 
Wiki-administration/editing stuff dominates, etc.)  But, it's also 
possible to spend so much time talking about how to do it, that it never 
gets done...

Still, it really does look like it would be worth putting some effort 
into the top level structure early on, because from the material I saw 
about maintaining the wiki, it looks like a bit of a chore to impose a 
new top-level structure (requires scripts, admittedly simple, that 
rename files and change links within files -- so, presumably, can only 
be done by the Wiki administrator.)

Also, I had a little difficulty figuring out exactly how to create new 
pages, and my attempts were not clean -- I seemed to have left two items 
with the same name at the same level in the index.

Everything is an experiment!

Maybe when Phillippe Grosjean returns to his work he can put some more 
R-related top-level structure on his wiki?

In the meantime, anyone else can go in there and start proposing some 
structure...

-- Tony Plate

PS. Detlef Steuer did say that he would be happy to shut down his wiki 
and let the sciviews one be "the" R Wiki.  I had previously put some 
material on Detlef's Wiki, but this time on put it on the sciviews Wiki.

Ben Bolker wrote:
> Tony Plate <tplate <at> acm.org> writes:
> 
>  >
>  > Since the virtue and reliability of Wikis was brought up, I created a R
>  > Wiki page for this at
>  > 
> http://www.sciviews.org/_rgui/wiki/doku.php?id=beginners:surprises:emptysetfuncs
>  >
>  >
>  > Anyone: please correct errors and improve it!
>  >
>  > Tony Plate
>  >
> 
>    OK, now I have another question:
> I see a wiki at
> http://fawn.unibw-hamburg.de/cgi-bin/Rwiki.pl?RwikiHome
> administered by Detlef Steuer
>    I see another at http://www.sciviews.org/_rgui/wiki/doku.php
> (Phillippe Grosjean)
> which is nominally geared toward beginners/GUI interfaces.
> 
>   I'm not saying I could do any better, but both of these look
> as though they'd be pretty hard to get into if you were really
> a beginner or intermediate R user looking for info ... Paul
> John's Rtips (http://www.ku.edu/~pauljohn/R/Rtips.html) is actually
> about the best example about there -- the flat hierarchy might not
> work too well for a really big wiki, but having at least
> a good first-level hierarchy set up (and making sure that
> what new users see is not a lot of detail about how to extend
> the wiki) seems really important.
> 
>    Sorry to criticize, but I am happy to start working
> on populating a wiki -- but only if the structure is there
> so that I can figure out where to put stuff and hope that
> someone who needs it will ever be able to find it ...
>


From Mark.Bravington at csiro.au  Tue Jan 10 03:26:45 2006
From: Mark.Bravington at csiro.au (Mark.Bravington@csiro.au)
Date: Tue, 10 Jan 2006 13:26:45 +1100
Subject: [Rd] Problem installing from source: no CONTENTS files
Message-ID: <D79013E40FEF254AAF0D72DFC94F274803D998@extas4-hba.tas.csiro.au>

> Brian D. Ripley,                  ripley at stats.ox.ac.uk

> This will only happen if you installed R without HTML help 
> and then install a package *with* HTML help *and* do so into 
> a non-standard directory.  That seems an arcane thing to do: 
> why do you want HTML help for some packages and not others?  
> You will end up with a partially functional system.
> 
> The fix is simple: put '-' at the beginning of that line 
> (after the tab) in MakePkg.  I've put a more complete 
> solution in R-devel.

Thanks for the fix. I think the message is more general, though. What I
want to do is install the package just with "vanilla help"-- the stuff
that comes up in the pager. According to "RCMD INSTALL --help" the only
options are "doc=none/normal/chtml/all"-- there's no "vanilla" or
equivalent. If I do "doc=none" I don't get vanilla help. So "doc=normal"
is required, and this tries to do HTML which I don't need. A
vanilla-only option would be ideal, I guess.

> 
> On Mon, 9 Jan 2006 Mark.Bravington at csiro.au wrote:
> 
> > I've just had the error below while trying to install a 
> package from 
> > source under R2.2.1 and Windows XP. I recall encountering this 
> > sporadically in the past. It is a pretty confusing message 
> and took me 
> > quite some time to figure out; I've seen queries about it on the R 

<<snipped>>

> > ---------- Making package debug ------------ <<snipped>> installing 
> > indices
> > cat: C:/R/RW2021/library/*/CONTENTS: No such file or directory

<<snipped>>

> > be used? If not, a different error message would be handy.
> 
> The error message is completely informative: why would you 
> want to change it?

I should have said "an additional error message" instead of "a
different...". It's pretty difficult for a user to track down where &
why it is occurring and whether it matters-- accurate, yes, but not
informative! Anyway, maybe otiose now (the more complete solution hasn't
made it to the R-devel I got this morning, so I can't check yet).

> 
> > I don't understand enough about makefiles to suggest a patch, 
> > unfortunately.
> 
> A good learning project for you?

true no doubt-- but just one out of so many ... :(

Thanks
Mark

> >
> > Mark Bravington
> > CSIRO Mathematical & Information Sciences Marine Laboratory Castray 
> > Esplanade Hobart 7001 TAS
> >
> > ph (+61) 3 6232 5118
> > fax (+61) 3 6232 5012
> > mob (+61) 438 315 623
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
> >
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 
>


From maechler at stat.math.ethz.ch  Tue Jan 10 12:27:29 2006
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 10 Jan 2006 12:27:29 +0100
Subject: [Rd] [R] ouml in an .Rd
In-Reply-To: <43C2C720.2020507@bank-banque-canada.ca>
References: <43BED712.2030705@bank-banque-canada.ca>
	<Pine.LNX.4.61.0601062105570.11196@gannet.stats>
	<43C2C720.2020507@bank-banque-canada.ca>
Message-ID: <17347.39457.39808.947779@stat.math.ethz.ch>

>>>>> "PaulG" == Paul Gilbert <pgilbert at bank-banque-canada.ca>
>>>>>     on Mon, 09 Jan 2006 15:27:12 -0500 writes:

    PaulG> (moved from r-help) Ok, UTF-8 works on some of my
    PaulG> machines and latin1 on others. If I use one I get
    PaulG> failure or spurious characters when I build on the
    PaulG> wrong machine. Are .Rd files suppose to work on
    PaulG> different platforms when there are special
    PaulG> characters, 

yes, they are. That's why we have \encoding{} and \enc{}
nowadays, and the "Writing R Extensions" manual has been
documenting this for a while, currently [an excerpt:]

 >> 2.10 Encoding
 >> =============
 >> 
 >> `Rd' files  are text files  and so it  is impossible to  deduce the
 >> encoding they are written in: ASCII, UTF-8, Latin-1, Latin-9 _etc_.  So
 >> the  `\encoding{}' directive  must  be  used  to specify  the
 >> encoding: if not present the processing to HTML assumes that the file is
 >> in Latin-1 (ISO-8859-1).   This is used when creating  the header of the
 >> HTML conversion  and to make a  comment in the examples  file.  It is
 >> also used to indicate to LaTeX how to process the file (see below).
 >> 
 >>    Wherever possible, avoid non-ASCII chars in `Rd' files.
 >> 
 >>    For convenience, encoding names `latin1' and `latin2' are always
 >> recognized: these and `UTF-8' are likely to work fairly widely.

 >> ............................
 >> ............................


I'm a bit surprised that you haven't succeeded finding this
information in the extension manual.  
After all, it's  *the*  R manual for package writers.

Martin

    PaulG> or is this a known limitation?

(not at all)

    PaulG> Paul

    PaulG> Prof Brian Ripley wrote:

    >> It means what it says: you need to put the actual
    >> character in the file, and specify the encoding for the
    >> file via \encoding.  (For you, UTF-8 or latin1, I would
    >> guess.)
    >> 
    >> It's not a question of trying variations, rather of
    >> following instructions.
    >> 
    >> On Fri, 6 Jan 2006, Paul Gilbert wrote:
    >> 
    >>> I am trying to put an ouml in an .Rd file with no
    >>> success. Writing R Extensions suggests:
    >>> 
    >>> Text which might need to be represented differently in
    >>> different encodings should be marked by |\enc|,
    >>> e.g. |\enc{J?reskog}{Joreskog}| where the first argument
    >>> will be used where encodings are allowed and the second
    >>> should be ASCII (and is used for e.g. the text
    >>> conversion).
    >>> 
    >>> (Above may get mangled by the mail.) I have tried
    >>> variations
    >>> 
    >>> \enc{J"oreskog}{Joreskog} \enc{J\"oreskog}{Joreskog}
    >>> \enc{Jo\"reskog}{Joreskog} \enc{Jo\"reskog}{Joreskog}
    >>> \enc{J\"{o}reskog}{Joreskog}
    >>> \enc{J\\"{o}reskog}{Joreskog}
    >>> \enc{J&ouml;oreskog}{Joreskog}
    >>> 
    >>> all with no effect on the generated pdf file.
    >>> Suggestions would be appreciated.
    >>> 
    >>> Thanks, Paul Gilbert
    >>> 
    >>> ______________________________________________
    >>> R-help at stat.math.ethz.ch mailing list
    >>> https://stat.ethz.ch/mailman/listinfo/r-help PLEASE do
    >>> read the posting guide!
    >>> http://www.R-project.org/posting-guide.html
    >>> 
    >>

    PaulG> ______________________________________________
    PaulG> R-devel at r-project.org mailing list
    PaulG> https://stat.ethz.ch/mailman/listinfo/r-devel


From r.hankin at noc.soton.ac.uk  Tue Jan 10 13:53:44 2006
From: r.hankin at noc.soton.ac.uk (Robin Hankin)
Date: Tue, 10 Jan 2006 12:53:44 +0000
Subject: [Rd] eigen()
Message-ID: <3B7754B8-4982-49BE-B424-A0D9CFC6F056@soc.soton.ac.uk>

Hi

I am having difficulty with eigen() on   R-devel_2006-01-05.tar.gz

Specifically,  in R-2.2.0 I get expected behaviour:


 > eigen(matrix(1:100,10,10),FALSE,TRUE)$values
[1]  5.208398e+02+0.000000e+00i -1.583980e+01+0.000000e+00i
[3] -4.805412e-15+0.000000e+00i  1.347691e-15+4.487511e-15i
[5]  1.347691e-15-4.487511e-15i -4.269863e-16+0.000000e+00i
[7]  1.364748e-16+0.000000e+00i -1.269735e-16+0.000000e+00i
[9] -1.878758e-18+5.031259e-17i -1.878758e-18-5.031259e-17i
 >


The same command gives different results in the development version:


 > eigen(matrix(1:100,10,10),FALSE,TRUE)$values
[1]  3.903094e-118 -3.903094e-118 -2.610848e-312 -2.995687e-313  
-2.748516e-313
[6] -1.073138e-314 -1.061000e-314 -1.060998e-314  4.940656e-324    
0.000000e+00
 > R.version()
Error: attempt to apply non-function
 > R.version
                _
platform       powerpc-apple-darwin8.3.0
arch           powerpc
os             darwin8.3.0
system         powerpc, darwin8.3.0
status         Under development (unstable)
major          2
minor          3.0
year           2006
month          01
day            04
svn rev        36984
language       R
version.string Version 2.3.0 Under development (unstable) (2006-01-04  
r36984)
 >


Note the strange magnitude of the output.

[
I need this to work because one of my packages fails under R-devel
]


--
Robin Hankin
Uncertainty Analyst
National Oceanography Centre, Southampton
European Way, Southampton SO14 3ZH, UK
  tel  023-8059-7743


From p.dalgaard at biostat.ku.dk  Tue Jan 10 14:16:00 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 10 Jan 2006 14:16:00 +0100
Subject: [Rd] eigen()
In-Reply-To: <3B7754B8-4982-49BE-B424-A0D9CFC6F056@soc.soton.ac.uk>
References: <3B7754B8-4982-49BE-B424-A0D9CFC6F056@soc.soton.ac.uk>
Message-ID: <x2zmm49qb3.fsf@viggo.kubism.ku.dk>

Robin Hankin <r.hankin at noc.soton.ac.uk> writes:

> Hi
> 
> I am having difficulty with eigen() on   R-devel_2006-01-05.tar.gz
> 
> Specifically,  in R-2.2.0 I get expected behaviour:
> 
> 
>  > eigen(matrix(1:100,10,10),FALSE,TRUE)$values
> [1]  5.208398e+02+0.000000e+00i -1.583980e+01+0.000000e+00i
> [3] -4.805412e-15+0.000000e+00i  1.347691e-15+4.487511e-15i
> [5]  1.347691e-15-4.487511e-15i -4.269863e-16+0.000000e+00i
> [7]  1.364748e-16+0.000000e+00i -1.269735e-16+0.000000e+00i
> [9] -1.878758e-18+5.031259e-17i -1.878758e-18-5.031259e-17i
>  >
> 
> 
> The same command gives different results in the development version:
> 
> 
>  > eigen(matrix(1:100,10,10),FALSE,TRUE)$values
> [1]  3.903094e-118 -3.903094e-118 -2.610848e-312 -2.995687e-313  
> -2.748516e-313
> [6] -1.073138e-314 -1.061000e-314 -1.060998e-314  4.940656e-324    
> 0.000000e+00
>  > R.version()
> Error: attempt to apply non-function
>  > R.version

Strange and semi-random results on SuSE 9.3 as well:

>  eigen(matrix(1:100,10,10))$values
 [1] -5.393552e+194   3.512001e-68   0.000000e+00   0.000000e+00   0.000000e+00
 [6]   0.000000e+00   0.000000e+00   0.000000e+00   0.000000e+00   0.000000e+00
>  eigen(matrix(1:100,10,10))$values
 [1]  1.526259e-311 -1.041529e-311  1.181720e-313   0.000000e+00   0.000000e+00
 [6]   0.000000e+00   0.000000e+00   0.000000e+00   0.000000e+00   0.000000e+00
>  eigen(matrix(1:100,10,10))$values
 [1] -9.338774e+93  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00
 [6]  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00
>  eigen(matrix(1:100,10,10))$values
 [1]  5.4e-311+ 0.0e+00i -2.5e-311+3.7e-311i -2.5e-311-3.7e-311i
 [4]  2.5e-312+ 0.0e+00i -2.4e-312+ 0.0e+00i  3.2e-317+ 0.0e+00i
 [7]   0.0e+00+ 0.0e+00i   0.0e+00+ 0.0e+00i   0.0e+00+ 0.0e+00i
[10]   0.0e+00+ 0.0e+00i



-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From Heather.Turner at warwick.ac.uk  Tue Jan 10 14:30:23 2006
From: Heather.Turner at warwick.ac.uk (Heather.Turner@warwick.ac.uk)
Date: Tue, 10 Jan 2006 14:30:23 +0100 (CET)
Subject: [Rd] standardized residuals (rstandard & plot.lm) (PR#8468)
Message-ID: <20060110133023.3AA8D20631@slim.kubism.ku.dk>

This bug is not quite fixed - the example from my original report now =
works using R-2.2.1, but

plot(Uniform, 6)

does not. The bug is due to
 if (show[6]) {
        ymx <- max(cook, na.rm =3D TRUE) * 1.025
        g <- hatval/(1 - hatval) # Potential division by zero here #
        plot(g, cook, xlim =3D c(0, max(g)), ylim =3D c(0, ymx),=20
            main =3D main, xlab =3D "Leverage", ylab =3D "Cook's distance",=
=20
            xaxt =3D "n", type =3D "n", ...)
...

All other values of 'which' seem to work fine. Sorry not to have checked =
this in the beta version,

Heather

>>> Prof Brian Ripley <ripley at stats.ox.ac.uk> 12/06/05 04:10pm >>>
Curiously, I was just looking at that, since I believe the answer =
should=20
be NaN, and some optimizing compilers/fast BLASes are not giving that.
(There's an example in reg-test-3.R.)  So I think we need to return NaN=20
when hat is within rounding error of 1.

My take is that plot.lm should handle this: you will see most but not =
all=20
cases have na.rm=3DTRUE in calculating ylim, but as Inf is theoretically
impossible it has not been considered.

Note that plot.lm does not use rstandard and so needs a separate fix.

Thanks for the report

On Tue, 6 Dec 2005 Heather.Turner at warwick.ac.uk wrote:

> Full_Name: Heather Turner
> Version: 2.2.0
> OS: Windows XP
> Submission from: (NULL) (137.205.240.44)
>
>
> Standardized residuals as calculated by rstandard.lm, rstandard.glm and =
plot.lm
> are Inf/NaN rather than zero when the un-standardized residuals are =
zero. This
> causes plot.lm to break when calculating 'ylim' for any of the plots of
> standardized residuals. Example:
>
> "occupationalStatus" <-
>    structure(as.integer(c(50, 16, 12, 11, 2, 12, 0, 0, 19, 40, 35,
>                           20, 8, 28, 6, 3, 26, 34, 65, 58, 12, 102, 19, =
14, 8,
>                           18, 66, 110, 23, 162, 40, 32, 7, 11, 35, 40, =
25, 90,
>                           21, 15, 11, 20, 88, 183, 46, 554, 158, 126, 6, =
8,
> 23,
>                           64, 28, 230, 143, 91, 2, 3, 21, 32, 12, 177, =
71,
> 106)
>                         ), .Dim =3D as.integer(c(8, 8)), .Dimnames =3D
>              structure(list(origin =3D c("1", "2", "3", "4", "5", "6", =
"7",
> "8"),
>                             destination =3D c("1", "2", "3", "4", "5", =
"6", "7",
>                             "8")), .Names =3D c("origin", "destination"))=
,
>              class =3D "table")
> Diag <- as.factor(diag(1:8))
> Rscore <- scale(as.numeric(row(occupationalStatus)), scale =3D FALSE)
> Cscore <- scale(as.numeric(col(occupationalStatus)), scale =3D FALSE)
> Uniform <- glm(Freq ~ origin + destination + Diag +
>               Rscore:Cscore, family =3D poisson, data =3D occupationalSta=
tus)
> residuals(Uniform)[as.logical(diag(8))] #zero/near-zero
> rstandard(Uniform)[as.logical(diag(8))] #mostly Inf/NaN
> plot(Uniform) #breaks on qqnorm plot (or any 'which' > 1)
>
> This could be fixed by replacing standardized residuals with zero where =
the hat
> value is one, e.g.
> rstandard.glm <- function (model,
>                            infl =3D lm.influence(model, do.coef =3D =
FALSE),
>                            ...) {
>     res <- infl$wt.res
>     hat <- infl$hat
>     ifelse(hat =3D=3D 1, 0, res/sqrt(summary(model)$dispersion * (1 -
> infl$hat)))
> }
> etc.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel=20
>
>

--=20
Brian D. Ripley,                  ripley at stats.ox.ac.uk=20
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/=20
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From p.dalgaard at biostat.ku.dk  Tue Jan 10 14:34:10 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 10 Jan 2006 14:34:10 +0100
Subject: [Rd] eigen()
In-Reply-To: <x2zmm49qb3.fsf@viggo.kubism.ku.dk>
References: <3B7754B8-4982-49BE-B424-A0D9CFC6F056@soc.soton.ac.uk>
	<x2zmm49qb3.fsf@viggo.kubism.ku.dk>
Message-ID: <x2vews9pgt.fsf@viggo.kubism.ku.dk>

Peter Dalgaard <p.dalgaard at biostat.ku.dk> writes:

> Robin Hankin <r.hankin at noc.soton.ac.uk> writes:
> 
> > Hi
> > 
> > I am having difficulty with eigen() on   R-devel_2006-01-05.tar.gz
> > 
> > Specifically,  in R-2.2.0 I get expected behaviour:
> > 
> > 
> >  > eigen(matrix(1:100,10,10),FALSE,TRUE)$values
> > [1]  5.208398e+02+0.000000e+00i -1.583980e+01+0.000000e+00i
> > [3] -4.805412e-15+0.000000e+00i  1.347691e-15+4.487511e-15i
> > [5]  1.347691e-15-4.487511e-15i -4.269863e-16+0.000000e+00i
> > [7]  1.364748e-16+0.000000e+00i -1.269735e-16+0.000000e+00i
> > [9] -1.878758e-18+5.031259e-17i -1.878758e-18-5.031259e-17i
> >  >
> > 
> > 
> > The same command gives different results in the development version:
> > 
> > 
> >  > eigen(matrix(1:100,10,10),FALSE,TRUE)$values
> > [1]  3.903094e-118 -3.903094e-118 -2.610848e-312 -2.995687e-313  
> > -2.748516e-313
> > [6] -1.073138e-314 -1.061000e-314 -1.060998e-314  4.940656e-324    
> > 0.000000e+00
> >  > R.version()
> > Error: attempt to apply non-function
> >  > R.version
> 
> Strange and semi-random results on SuSE 9.3 as well:
> 
> >  eigen(matrix(1:100,10,10))$values
>  [1] -5.393552e+194   3.512001e-68   0.000000e+00   0.000000e+00   0.000000e+00
>  [6]   0.000000e+00   0.000000e+00   0.000000e+00   0.000000e+00   0.000000e+00
> >  eigen(matrix(1:100,10,10))$values
>  [1]  1.526259e-311 -1.041529e-311  1.181720e-313   0.000000e+00   0.000000e+00
>  [6]   0.000000e+00   0.000000e+00   0.000000e+00   0.000000e+00   0.000000e+00
> >  eigen(matrix(1:100,10,10))$values
>  [1] -9.338774e+93  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00
>  [6]  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00
> >  eigen(matrix(1:100,10,10))$values
>  [1]  5.4e-311+ 0.0e+00i -2.5e-311+3.7e-311i -2.5e-311-3.7e-311i
>  [4]  2.5e-312+ 0.0e+00i -2.4e-312+ 0.0e+00i  3.2e-317+ 0.0e+00i
>  [7]   0.0e+00+ 0.0e+00i   0.0e+00+ 0.0e+00i   0.0e+00+ 0.0e+00i
> [10]   0.0e+00+ 0.0e+00i


On closer inspection:

> eigen(matrix(as.numeric(1:100),10),FALSE,TRUE)
$values
 [1]  5.208398e+02+0.000000e+00i -1.583980e+01+0.000000e+00i
 [3]  9.895951e-15+3.370683e-15i  9.895951e-15-3.370683e-15i
 [5] -7.018984e-15+2.881924e-15i -7.018984e-15-2.881924e-15i
 [7] -7.978136e-16+2.629350e-15i -7.978136e-16-2.629350e-15i
 [9]  1.818143e-16+6.007106e-16i  1.818143e-16-6.007106e-16i

$vectors
NULL


I.e. there's a bug in that eigen() doesn't check the storage mode, but
there's also a simple workaround.

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From hin-tak.leung at cimr.cam.ac.uk  Tue Jan 10 14:42:55 2006
From: hin-tak.leung at cimr.cam.ac.uk (Hin-Tak Leung)
Date: Tue, 10 Jan 2006 13:42:55 +0000
Subject: [Rd] eigen()
In-Reply-To: <x2zmm49qb3.fsf@viggo.kubism.ku.dk>
References: <3B7754B8-4982-49BE-B424-A0D9CFC6F056@soc.soton.ac.uk>
	<x2zmm49qb3.fsf@viggo.kubism.ku.dk>
Message-ID: <43C3B9DF.1090803@cimr.cam.ac.uk>

Peter Dalgaard wrote:
> Robin Hankin <r.hankin at noc.soton.ac.uk> writes:
> 
> 
>>Hi
>>
>>I am having difficulty with eigen() on   R-devel_2006-01-05.tar.gz
>>
>>Specifically,  in R-2.2.0 I get expected behaviour:
>>
>>
>> > eigen(matrix(1:100,10,10),FALSE,TRUE)$values
>>[1]  5.208398e+02+0.000000e+00i -1.583980e+01+0.000000e+00i
>>[3] -4.805412e-15+0.000000e+00i  1.347691e-15+4.487511e-15i
>>[5]  1.347691e-15-4.487511e-15i -4.269863e-16+0.000000e+00i
>>[7]  1.364748e-16+0.000000e+00i -1.269735e-16+0.000000e+00i
>>[9] -1.878758e-18+5.031259e-17i -1.878758e-18-5.031259e-17i
>> >
>>
>>
>>The same command gives different results in the development version:
>>
>>
>> > eigen(matrix(1:100,10,10),FALSE,TRUE)$values
>>[1]  3.903094e-118 -3.903094e-118 -2.610848e-312 -2.995687e-313  
>>-2.748516e-313
>>[6] -1.073138e-314 -1.061000e-314 -1.060998e-314  4.940656e-324    
>>0.000000e+00
>> > R.version()
>>Error: attempt to apply non-function
>> > R.version
> 
> 
> Strange and semi-random results on SuSE 9.3 as well:
> 
> 
>> eigen(matrix(1:100,10,10))$values
> 
>  [1] -5.393552e+194   3.512001e-68   0.000000e+00   0.000000e+00   0.000000e+00
>  [6]   0.000000e+00   0.000000e+00   0.000000e+00   0.000000e+00   0.000000e+00
> 
>> eigen(matrix(1:100,10,10))$values
> 
>  [1]  1.526259e-311 -1.041529e-311  1.181720e-313   0.000000e+00   0.000000e+00
>  [6]   0.000000e+00   0.000000e+00   0.000000e+00   0.000000e+00   0.000000e+00
> 
>> eigen(matrix(1:100,10,10))$values
> 
>  [1] -9.338774e+93  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00
>  [6]  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00
> 
>> eigen(matrix(1:100,10,10))$values
> 
>  [1]  5.4e-311+ 0.0e+00i -2.5e-311+3.7e-311i -2.5e-311-3.7e-311i
>  [4]  2.5e-312+ 0.0e+00i -2.4e-312+ 0.0e+00i  3.2e-317+ 0.0e+00i
>  [7]   0.0e+00+ 0.0e+00i   0.0e+00+ 0.0e+00i   0.0e+00+ 0.0e+00i
> [10]   0.0e+00+ 0.0e+00i
> 
> 
> 

Mine is closer to Robin's, but not the same (EL4 x86).

 > eigen(matrix(1:100,10,10))$values
  [1]  5.208398e+02+0.000000e+00i -1.583980e+01+0.000000e+00i
  [3]  6.292457e-16+2.785369e-15i  6.292457e-16-2.785369e-15i
  [5] -1.055022e-15+0.000000e+00i  3.629676e-16+0.000000e+00i
  [7]  1.356222e-16+2.682405e-16i  1.356222e-16-2.682405e-16i
  [9]  1.029077e-16+0.000000e+00i -1.269181e-17+0.000000e+00i
 >

But surely, my matrix algebra is a bit rusty, I think this matrix is
solveable analytically? Most of the eigenvalues shown are almost
exactly zero, except the first two, actually, which is about 521
and -16 to the closest integer.

I think the difference between mine and Robin's are rounding errors
(the matrix is simple enough I expect the solution to be simple integers
or easily expressible analystical expressions, so 8 e-values being zero
is fine). Peter's number seems to be all 10 e-values are zero or one 
being a huge number! So Peter's is odd... and Peter's machine also seems
to be of a different archtecture (64-bit machine)?

HTL


From p.dalgaard at biostat.ku.dk  Tue Jan 10 15:14:44 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 10 Jan 2006 15:14:44 +0100
Subject: [Rd] eigen()
In-Reply-To: <43C3B9DF.1090803@cimr.cam.ac.uk>
References: <3B7754B8-4982-49BE-B424-A0D9CFC6F056@soc.soton.ac.uk>
	<x2zmm49qb3.fsf@viggo.kubism.ku.dk> <43C3B9DF.1090803@cimr.cam.ac.uk>
Message-ID: <x2mzi49nl7.fsf@viggo.kubism.ku.dk>

Hin-Tak Leung <hin-tak.leung at cimr.cam.ac.uk> writes:

> Peter Dalgaard wrote:
> > Robin Hankin <r.hankin at noc.soton.ac.uk> writes:
> >
> >>Hi
> >>
> >>I am having difficulty with eigen() on   R-devel_2006-01-05.tar.gz
> >>
> >>Specifically,  in R-2.2.0 I get expected behaviour:
> >>
> >>
> >> > eigen(matrix(1:100,10,10),FALSE,TRUE)$values
> >>[1]  5.208398e+02+0.000000e+00i -1.583980e+01+0.000000e+00i
> >>[3] -4.805412e-15+0.000000e+00i  1.347691e-15+4.487511e-15i
> >>[5]  1.347691e-15-4.487511e-15i -4.269863e-16+0.000000e+00i
> >>[7]  1.364748e-16+0.000000e+00i -1.269735e-16+0.000000e+00i
> >>[9] -1.878758e-18+5.031259e-17i -1.878758e-18-5.031259e-17i
> >> >
> >>
> >>
> >>The same command gives different results in the development version:
> >>
> >>
> >> > eigen(matrix(1:100,10,10),FALSE,TRUE)$values
> >> [1]  3.903094e-118 -3.903094e-118 -2.610848e-312 -2.995687e-313
> >> -2.748516e-313
> >> [6] -1.073138e-314 -1.061000e-314 -1.060998e-314  4.940656e-324
> >> 0.000000e+00
> >> > R.version()
> >>Error: attempt to apply non-function
> >> > R.version
> > Strange and semi-random results on SuSE 9.3 as well:
> >
> >> eigen(matrix(1:100,10,10))$values
> >  [1] -5.393552e+194   3.512001e-68   0.000000e+00   0.000000e+00
> > 0.000000e+00
> >  [6]   0.000000e+00   0.000000e+00   0.000000e+00   0.000000e+00   0.000000e+00
> >
> >> eigen(matrix(1:100,10,10))$values
> >  [1]  1.526259e-311 -1.041529e-311  1.181720e-313   0.000000e+00
> > 0.000000e+00
> >  [6]   0.000000e+00   0.000000e+00   0.000000e+00   0.000000e+00   0.000000e+00
> >
> >> eigen(matrix(1:100,10,10))$values
> >  [1] -9.338774e+93  0.000000e+00  0.000000e+00  0.000000e+00
> > 0.000000e+00
> >  [6]  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00
> >
> >> eigen(matrix(1:100,10,10))$values
> >  [1]  5.4e-311+ 0.0e+00i -2.5e-311+3.7e-311i -2.5e-311-3.7e-311i
> >  [4]  2.5e-312+ 0.0e+00i -2.4e-312+ 0.0e+00i  3.2e-317+ 0.0e+00i
> >  [7]   0.0e+00+ 0.0e+00i   0.0e+00+ 0.0e+00i   0.0e+00+ 0.0e+00i
> > [10]   0.0e+00+ 0.0e+00i
> >
> 
> Mine is closer to Robin's, but not the same (EL4 x86).
> 
>  > eigen(matrix(1:100,10,10))$values
>   [1]  5.208398e+02+0.000000e+00i -1.583980e+01+0.000000e+00i
>   [3]  6.292457e-16+2.785369e-15i  6.292457e-16-2.785369e-15i
>   [5] -1.055022e-15+0.000000e+00i  3.629676e-16+0.000000e+00i
>   [7]  1.356222e-16+2.682405e-16i  1.356222e-16-2.682405e-16i
>   [9]  1.029077e-16+0.000000e+00i -1.269181e-17+0.000000e+00i
>  >
> 
> But surely, my matrix algebra is a bit rusty, I think this matrix is
> solveable analytically? Most of the eigenvalues shown are almost
> exactly zero, except the first two, actually, which is about 521
> and -16 to the closest integer.
> 
> I think the difference between mine and Robin's are rounding errors
> (the matrix is simple enough I expect the solution to be simple integers
> or easily expressible analystical expressions, so 8 e-values being zero
> is fine). Peter's number seems to be all 10 e-values are zero or one
> being a huge number! So Peter's is odd... and Peter's machine also
> seems
> to be of a different archtecture (64-bit machine)?
> 
> HTL

Notice that Robin got something completely different in _R-devel_
which is where I did my check too.  In R 2.2.1 I get the expected two
non-zero eigenvalues. 

I'm not sure whether (and how) you can work out the eigenvalues
analytically, but since all columns are linear progressions, it is
at least obvious that the matrix must have column rank two.

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From r.hankin at noc.soton.ac.uk  Tue Jan 10 15:39:07 2006
From: r.hankin at noc.soton.ac.uk (Robin Hankin)
Date: Tue, 10 Jan 2006 14:39:07 +0000
Subject: [Rd] eigen()
In-Reply-To: <x2mzi49nl7.fsf@viggo.kubism.ku.dk>
References: <3B7754B8-4982-49BE-B424-A0D9CFC6F056@soc.soton.ac.uk>
	<x2zmm49qb3.fsf@viggo.kubism.ku.dk>
	<43C3B9DF.1090803@cimr.cam.ac.uk>
	<x2mzi49nl7.fsf@viggo.kubism.ku.dk>
Message-ID: <70356E1A-618F-4610-8E17-ABCB10485282@soc.soton.ac.uk>



On 10 Jan 2006, at 14:14, Peter Dalgaard wrote:
>


>>> Strange and semi-random results on SuSE 9.3 as well:
>>>
>>>
>>>> eigen(matrix(1:100,10,10))$values
>>>  [1]  5.4e-311+ 0.0e+00i -2.5e-311+3.7e-311i -2.5e-311-3.7e-311i
>>>  [4]  2.5e-312+ 0.0e+00i -2.4e-312+ 0.0e+00i  3.2e-317+ 0.0e+00i
>>>  [7]   0.0e+00+ 0.0e+00i   0.0e+00+ 0.0e+00i   0.0e+00+ 0.0e+00i
>>> [10]   0.0e+00+ 0.0e+00i
>>>
>>
>> Mine is closer to Robin's, but not the same (EL4 x86).
>>
>>> eigen(matrix(1:100,10,10))$values
>>   [1]  5.208398e+02+0.000000e+00i -1.583980e+01+0.000000e+00i
>>   [3]  6.292457e-16+2.785369e-15i  6.292457e-16-2.785369e-15i
>>   [5] -1.055022e-15+0.000000e+00i  3.629676e-16+0.000000e+00i
>>   [7]  1.356222e-16+2.682405e-16i  1.356222e-16-2.682405e-16i
>>   [9]  1.029077e-16+0.000000e+00i -1.269181e-17+0.000000e+00i
>>>
>>
>> But surely, my matrix algebra is a bit rusty, I think this matrix is
>> solveable analytically? Most of the eigenvalues shown are almost
>> exactly zero, except the first two, actually, which is about 521
>> and -16 to the closest integer.
>>
>> I think the difference between mine and Robin's are rounding errors
>> (the matrix is simple enough I expect the solution to be simple  
>> integers
>> or easily expressible analystical expressions, so 8 e-values being  
>> zero
>> is fine). Peter's number seems to be all 10 e-values are zero or one
>> being a huge number! So Peter's is odd... and Peter's machine also
>> seems
>> to be of a different archtecture (64-bit machine)?
>>
>> HTL
>
> Notice that Robin got something completely different in _R-devel_
> which is where I did my check too.  In R 2.2.1 I get the expected two
> non-zero eigenvalues.
>
> I'm not sure whether (and how) you can work out the eigenvalues
> analytically, but since all columns are linear progressions, it is
> at least obvious that the matrix must have column rank two.
>




For everyone's entertainment, here's an example where the analytic  
solution
is known.

fact 1:  the first eigenvalue of a magic square is equal to its constant
fact 2: the sum of the other eigenvalues of a magic square is zero
fact 3: the constant of a magic square of order 10 is 505.

R-2.2.0:

 > library(magic)
 > round(Re(eigen(magic(10),F,T)$values))
[1]  505  170 -170 -105  105   -3    3    0    0    0
 >

answers as expected.


R-devel:



 > a <- structure(c(68, 66, 92, 90, 16, 14, 37, 38, 41, 43, 65, 67, 89,
91, 13, 15, 40, 39, 44, 42, 96, 94, 20, 18, 24, 22, 45, 46, 69,
71, 93, 95, 17, 19, 21, 23, 48, 47, 72, 70, 4, 2, 28, 26, 49,
50, 76, 74, 97, 99, 1, 3, 25, 27, 52, 51, 73, 75, 100, 98, 32,
30, 56, 54, 80, 78, 81, 82, 5, 7, 29, 31, 53, 55, 77, 79, 84,
83, 8, 6, 60, 58, 64, 62, 88, 86, 9, 10, 33, 35, 57, 59, 61,
63, 85, 87, 12, 11, 36, 34), .Dim = c(10, 10))

[no magic package!  it fails R CMD check !]

 > round(Re(eigen(magic(10),F,T)$values))
[1] 7.544456e+165  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e 
+00
[6]  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e 
+00
 >


not as expected.



--
Robin Hankin
Uncertainty Analyst
National Oceanography Centre, Southampton
European Way, Southampton SO14 3ZH, UK
  tel  023-8059-7743


From maechler at stat.math.ethz.ch  Tue Jan 10 15:58:55 2006
From: maechler at stat.math.ethz.ch (maechler@stat.math.ethz.ch)
Date: Tue, 10 Jan 2006 15:58:55 +0100 (CET)
Subject: [Rd] standardized residuals (rstandard & plot.lm) (PR#8468)
Message-ID: <20060110145855.C141D2069D@slim.kubism.ku.dk>

>>>>> "Heather" == Heather Turner <Heather.Turner at warwick.ac.uk>
>>>>>     on Tue, 10 Jan 2006 14:30:23 +0100 (CET) writes:

    Heather> This bug is not quite fixed - the example from my
    Heather> original report now = works using R-2.2.1, but

    Heather> plot(Uniform, 6)

    Heather> does not. The bug is due

    .........
     g <- hatval/(1 - hatval) # Potential division by zero here 

     plot(g, cook, xlim = c(0, max(g)), ylim = c(0, ymx),
     ..........

    Heather> All other values of 'which' seem to work
    Heather> fine. Sorry not to have checked this in the beta
    Heather> version,

(indeed; that would have been useful)


Hmm, it's not clear what *should* be drawn in such a
case. Leaving away all the observations with  h_ii = 1
seems a particularly bad idea, since these are the ones that
you'd definitely should remark.
OTOH, for h_ii = 1, the cook distance is 'NaN' 
(or should that be changed; to  "very large" instead ???)
and plot number 6 doesn't seem to make any sense to me

When 'which = 6' was proposed 
[ on R-devel as well, last April,
  http://tolstoy.newcastle.edu.au/R/devel/05/04/0595.html
  ah, I see, by David Firth, from your place, so, Heather, can you
  make sure he sees this e-mail ?
]
I actually had wondered a bit about it's general usefulness,..

---

But the example is useful anyway; I think that also plot
number 5, (R_i vs h_ii) does the wrong thing currently by just
leaving away all points for which h_ii = 1.
These really should be shown one or the other way!

Martin


From ripley at stats.ox.ac.uk  Tue Jan 10 16:01:00 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 10 Jan 2006 15:01:00 +0000 (GMT)
Subject: [Rd] eigen()
In-Reply-To: <70356E1A-618F-4610-8E17-ABCB10485282@soc.soton.ac.uk>
References: <3B7754B8-4982-49BE-B424-A0D9CFC6F056@soc.soton.ac.uk>
	<x2zmm49qb3.fsf@viggo.kubism.ku.dk> <43C3B9DF.1090803@cimr.cam.ac.uk>
	<x2mzi49nl7.fsf@viggo.kubism.ku.dk>
	<70356E1A-618F-4610-8E17-ABCB10485282@soc.soton.ac.uk>
Message-ID: <Pine.LNX.4.61.0601101451540.4195@gannet.stats>

I haven't seen most of this thread, but this is a classic case of passing 
integers instead of doubles.  And indeed

     else if(is.numeric(x)) {
 	storage.mode(x) <- "double"

has been removed from eigen.R in R-devel in r36952.  So that's the 
culprit.

[BTW, x86 is not 64-bit, which is x86_64.  I'd take x86 to be ix86, what 
Intel calls ia32 (and AMD does call x86, given what 'i' stands for here).]

On Tue, 10 Jan 2006, Robin Hankin wrote:

>
>
> On 10 Jan 2006, at 14:14, Peter Dalgaard wrote:
>>
>
>
>>>> Strange and semi-random results on SuSE 9.3 as well:
>>>>
>>>>
>>>>> eigen(matrix(1:100,10,10))$values
>>>>  [1]  5.4e-311+ 0.0e+00i -2.5e-311+3.7e-311i -2.5e-311-3.7e-311i
>>>>  [4]  2.5e-312+ 0.0e+00i -2.4e-312+ 0.0e+00i  3.2e-317+ 0.0e+00i
>>>>  [7]   0.0e+00+ 0.0e+00i   0.0e+00+ 0.0e+00i   0.0e+00+ 0.0e+00i
>>>> [10]   0.0e+00+ 0.0e+00i
>>>>
>>>
>>> Mine is closer to Robin's, but not the same (EL4 x86).
>>>
>>>> eigen(matrix(1:100,10,10))$values
>>>   [1]  5.208398e+02+0.000000e+00i -1.583980e+01+0.000000e+00i
>>>   [3]  6.292457e-16+2.785369e-15i  6.292457e-16-2.785369e-15i
>>>   [5] -1.055022e-15+0.000000e+00i  3.629676e-16+0.000000e+00i
>>>   [7]  1.356222e-16+2.682405e-16i  1.356222e-16-2.682405e-16i
>>>   [9]  1.029077e-16+0.000000e+00i -1.269181e-17+0.000000e+00i
>>>>
>>>
>>> But surely, my matrix algebra is a bit rusty, I think this matrix is
>>> solveable analytically? Most of the eigenvalues shown are almost
>>> exactly zero, except the first two, actually, which is about 521
>>> and -16 to the closest integer.
>>>
>>> I think the difference between mine and Robin's are rounding errors
>>> (the matrix is simple enough I expect the solution to be simple
>>> integers
>>> or easily expressible analystical expressions, so 8 e-values being
>>> zero
>>> is fine). Peter's number seems to be all 10 e-values are zero or one
>>> being a huge number! So Peter's is odd... and Peter's machine also
>>> seems
>>> to be of a different archtecture (64-bit machine)?
>>>
>>> HTL
>>
>> Notice that Robin got something completely different in _R-devel_
>> which is where I did my check too.  In R 2.2.1 I get the expected two
>> non-zero eigenvalues.
>>
>> I'm not sure whether (and how) you can work out the eigenvalues
>> analytically, but since all columns are linear progressions, it is
>> at least obvious that the matrix must have column rank two.
>>
>
>
>
>
> For everyone's entertainment, here's an example where the analytic
> solution
> is known.
>
> fact 1:  the first eigenvalue of a magic square is equal to its constant
> fact 2: the sum of the other eigenvalues of a magic square is zero
> fact 3: the constant of a magic square of order 10 is 505.
>
> R-2.2.0:
>
> > library(magic)
> > round(Re(eigen(magic(10),F,T)$values))
> [1]  505  170 -170 -105  105   -3    3    0    0    0
> >
>
> answers as expected.
>
>
> R-devel:
>
>
>
> > a <- structure(c(68, 66, 92, 90, 16, 14, 37, 38, 41, 43, 65, 67, 89,
> 91, 13, 15, 40, 39, 44, 42, 96, 94, 20, 18, 24, 22, 45, 46, 69,
> 71, 93, 95, 17, 19, 21, 23, 48, 47, 72, 70, 4, 2, 28, 26, 49,
> 50, 76, 74, 97, 99, 1, 3, 25, 27, 52, 51, 73, 75, 100, 98, 32,
> 30, 56, 54, 80, 78, 81, 82, 5, 7, 29, 31, 53, 55, 77, 79, 84,
> 83, 8, 6, 60, 58, 64, 62, 88, 86, 9, 10, 33, 35, 57, 59, 61,
> 63, 85, 87, 12, 11, 36, 34), .Dim = c(10, 10))
>
> [no magic package!  it fails R CMD check !]
>
> > round(Re(eigen(magic(10),F,T)$values))
> [1] 7.544456e+165  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e
> +00
> [6]  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e
> +00
> >
>
>
> not as expected.
>
>
>
> --
> Robin Hankin
> Uncertainty Analyst
> National Oceanography Centre, Southampton
> European Way, Southampton SO14 3ZH, UK
>  tel  023-8059-7743
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From p.dalgaard at biostat.ku.dk  Tue Jan 10 16:18:27 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 10 Jan 2006 16:18:27 +0100
Subject: [Rd] eigen()
In-Reply-To: <Pine.LNX.4.61.0601101451540.4195@gannet.stats>
References: <3B7754B8-4982-49BE-B424-A0D9CFC6F056@soc.soton.ac.uk>
	<x2zmm49qb3.fsf@viggo.kubism.ku.dk> <43C3B9DF.1090803@cimr.cam.ac.uk>
	<x2mzi49nl7.fsf@viggo.kubism.ku.dk>
	<70356E1A-618F-4610-8E17-ABCB10485282@soc.soton.ac.uk>
	<Pine.LNX.4.61.0601101451540.4195@gannet.stats>
Message-ID: <x2irss9kn0.fsf@viggo.kubism.ku.dk>

Prof Brian Ripley <ripley at stats.ox.ac.uk> writes:

> I haven't seen most of this thread, but this is a classic case of
> passing integers instead of doubles.  And indeed
> 
>      else if(is.numeric(x)) {
>  	storage.mode(x) <- "double"
> 
> has been removed from eigen.R in R-devel in r36952.  So that's the
> culprit.

Thought as much...
 
> [BTW, x86 is not 64-bit, which is x86_64.  I'd take x86 to be ix86,
> what Intel calls ia32 (and AMD does call x86, given what 'i' stands
> for here).]

Actually, I have

> version
               _
platform       x86_64-unknown-linux-gnu
arch           x86_64
os             linux-gnu
system         x86_64, linux-gnu
status         Under development (unstable)
major          2
minor          3.0
year           2006
month          01
day            10
svn rev        37041
language       R
version.string Version 2.3.0 Under development (unstable) (2006-01-10 r37041)

Which is in fact Pentium 4 EMT (not to be confused with ia64 which is
Itanium, AFAIR).

I don't see how anyone could figure that out from the information
given, though...
   
        -p

> On Tue, 10 Jan 2006, Robin Hankin wrote:
> 
> >
> >
> > On 10 Jan 2006, at 14:14, Peter Dalgaard wrote:
> >>
> >
> >
> >>>> Strange and semi-random results on SuSE 9.3 as well:
> >>>>
> >>>>
> >>>>> eigen(matrix(1:100,10,10))$values
> >>>>  [1]  5.4e-311+ 0.0e+00i -2.5e-311+3.7e-311i -2.5e-311-3.7e-311i
> >>>>  [4]  2.5e-312+ 0.0e+00i -2.4e-312+ 0.0e+00i  3.2e-317+ 0.0e+00i
> >>>>  [7]   0.0e+00+ 0.0e+00i   0.0e+00+ 0.0e+00i   0.0e+00+ 0.0e+00i
> >>>> [10]   0.0e+00+ 0.0e+00i
> >>>>
> >>>
> >>> Mine is closer to Robin's, but not the same (EL4 x86).
> >>>
> >>>> eigen(matrix(1:100,10,10))$values
> >>>   [1]  5.208398e+02+0.000000e+00i -1.583980e+01+0.000000e+00i
> >>>   [3]  6.292457e-16+2.785369e-15i  6.292457e-16-2.785369e-15i
> >>>   [5] -1.055022e-15+0.000000e+00i  3.629676e-16+0.000000e+00i
> >>>   [7]  1.356222e-16+2.682405e-16i  1.356222e-16-2.682405e-16i
> >>>   [9]  1.029077e-16+0.000000e+00i -1.269181e-17+0.000000e+00i
> >>>>
> >>>
> >>> But surely, my matrix algebra is a bit rusty, I think this matrix is
> >>> solveable analytically? Most of the eigenvalues shown are almost
> >>> exactly zero, except the first two, actually, which is about 521
> >>> and -16 to the closest integer.
> >>>
> >>> I think the difference between mine and Robin's are rounding errors
> >>> (the matrix is simple enough I expect the solution to be simple
> >>> integers
> >>> or easily expressible analystical expressions, so 8 e-values being
> >>> zero
> >>> is fine). Peter's number seems to be all 10 e-values are zero or one
> >>> being a huge number! So Peter's is odd... and Peter's machine also
> >>> seems
> >>> to be of a different archtecture (64-bit machine)?
> >>>
> >>> HTL
> >>
> >> Notice that Robin got something completely different in _R-devel_
> >> which is where I did my check too.  In R 2.2.1 I get the expected two
> >> non-zero eigenvalues.
> >>
> >> I'm not sure whether (and how) you can work out the eigenvalues
> >> analytically, but since all columns are linear progressions, it is
> >> at least obvious that the matrix must have column rank two.
> >>
> >
> >
> >
> >
> > For everyone's entertainment, here's an example where the analytic
> > solution
> > is known.
> >
> > fact 1:  the first eigenvalue of a magic square is equal to its constant
> > fact 2: the sum of the other eigenvalues of a magic square is zero
> > fact 3: the constant of a magic square of order 10 is 505.
> >
> > R-2.2.0:
> >
> > > library(magic)
> > > round(Re(eigen(magic(10),F,T)$values))
> > [1]  505  170 -170 -105  105   -3    3    0    0    0
> > >
> >
> > answers as expected.
> >
> >
> > R-devel:
> >
> >
> >
> > > a <- structure(c(68, 66, 92, 90, 16, 14, 37, 38, 41, 43, 65, 67, 89,
> > 91, 13, 15, 40, 39, 44, 42, 96, 94, 20, 18, 24, 22, 45, 46, 69,
> > 71, 93, 95, 17, 19, 21, 23, 48, 47, 72, 70, 4, 2, 28, 26, 49,
> > 50, 76, 74, 97, 99, 1, 3, 25, 27, 52, 51, 73, 75, 100, 98, 32,
> > 30, 56, 54, 80, 78, 81, 82, 5, 7, 29, 31, 53, 55, 77, 79, 84,
> > 83, 8, 6, 60, 58, 64, 62, 88, 86, 9, 10, 33, 35, 57, 59, 61,
> > 63, 85, 87, 12, 11, 36, 34), .Dim = c(10, 10))
> >
> > [no magic package!  it fails R CMD check !]
> >
> > > round(Re(eigen(magic(10),F,T)$values))
> > [1] 7.544456e+165  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e
> > +00
> > [6]  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e
> > +00
> > >
> >
> >
> > not as expected.
> >
> >
> >
> > --
> > Robin Hankin
> > Uncertainty Analyst
> > National Oceanography Centre, Southampton
> > European Way, Southampton SO14 3ZH, UK
> >  tel  023-8059-7743
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
> >
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From ripley at stats.ox.ac.uk  Tue Jan 10 16:19:20 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 10 Jan 2006 15:19:20 +0000 (GMT)
Subject: [Rd] standardized residuals (rstandard & plot.lm) (PR#8468)
In-Reply-To: <20060110145855.C141D2069D@slim.kubism.ku.dk>
References: <20060110145855.C141D2069D@slim.kubism.ku.dk>
Message-ID: <Pine.LNX.4.61.0601101513511.4195@gannet.stats>

Martin,

I tend to think that points with hii = 1 are best omitted, as in almost 
all cases you already know about them.  I've yet to hear of a better 
compromise.

Incidentally, this is neither a case of the subject nor of 8367 which that 
subject line refers to.  So 8367 was fixed.

Brian


On Tue, 10 Jan 2006 maechler at stat.math.ethz.ch wrote:

>>>>>> "Heather" == Heather Turner <Heather.Turner at warwick.ac.uk>
>>>>>>     on Tue, 10 Jan 2006 14:30:23 +0100 (CET) writes:
>
>    Heather> This bug is not quite fixed - the example from my
>    Heather> original report now = works using R-2.2.1, but
>
>    Heather> plot(Uniform, 6)
>
>    Heather> does not. The bug is due
>
>    .........
>     g <- hatval/(1 - hatval) # Potential division by zero here
>
>     plot(g, cook, xlim = c(0, max(g)), ylim = c(0, ymx),
>     ..........
>
>    Heather> All other values of 'which' seem to work
>    Heather> fine. Sorry not to have checked this in the beta
>    Heather> version,
>
> (indeed; that would have been useful)
>
>
> Hmm, it's not clear what *should* be drawn in such a
> case. Leaving away all the observations with  h_ii = 1
> seems a particularly bad idea, since these are the ones that
> you'd definitely should remark.
> OTOH, for h_ii = 1, the cook distance is 'NaN'
> (or should that be changed; to  "very large" instead ???)
> and plot number 6 doesn't seem to make any sense to me
>
> When 'which = 6' was proposed
> [ on R-devel as well, last April,
>  http://tolstoy.newcastle.edu.au/R/devel/05/04/0595.html
>  ah, I see, by David Firth, from your place, so, Heather, can you
>  make sure he sees this e-mail ?
> ]
> I actually had wondered a bit about it's general usefulness,..
>
> ---
>
> But the example is useful anyway; I think that also plot
> number 5, (R_i vs h_ii) does the wrong thing currently by just
> leaving away all points for which h_ii = 1.
> These really should be shown one or the other way!
>
> Martin
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From maechler at stat.math.ethz.ch  Tue Jan 10 16:55:39 2006
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 10 Jan 2006 16:55:39 +0100
Subject: [Rd] eigen()
In-Reply-To: <Pine.LNX.4.61.0601101451540.4195@gannet.stats>
References: <3B7754B8-4982-49BE-B424-A0D9CFC6F056@soc.soton.ac.uk>
	<x2zmm49qb3.fsf@viggo.kubism.ku.dk>
	<43C3B9DF.1090803@cimr.cam.ac.uk>
	<x2mzi49nl7.fsf@viggo.kubism.ku.dk>
	<70356E1A-618F-4610-8E17-ABCB10485282@soc.soton.ac.uk>
	<Pine.LNX.4.61.0601101451540.4195@gannet.stats>
Message-ID: <17347.55547.595680.514608@stat.math.ethz.ch>

>>>>> "BDR" == Prof Brian Ripley <ripley at stats.ox.ac.uk>
>>>>>     on Tue, 10 Jan 2006 15:01:00 +0000 (GMT) writes:

    BDR> I haven't seen most of this thread, but this is a classic case of passing 
    BDR> integers instead of doubles.  And indeed

    BDR> else if(is.numeric(x)) {
    BDR> storage.mode(x) <- "double"

    BDR> has been removed from eigen.R in R-devel in r36952.  So that's the 
    BDR> culprit.

and I am the culprit of that revision.  I'll fix this ASAP.
Martin


From sdavis2 at mail.nih.gov  Tue Jan 10 19:13:52 2006
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Tue, 10 Jan 2006 13:13:52 -0500
Subject: [Rd] Issue with c++ .C call
Message-ID: <BFE96390.3659%sdavis2@mail.nih.gov>

I am still having some difficulties with connecting R to a C++ function.  I
am able to call the function as expected after compiling the shared library
and such.  However, the call to the function is via .C; parameters from the
.C call are not being passed correctly to the function.  As an example, I
have attached a GDB run of the code.  I set a breakpoint on entry to the
function I am calling from R.  What is bothering me (and probably causing
the segmentation faults I am seeing) is that the parameter
prm=as.double(c(3.2,1.1)) is not 3.2,1.1 IMMEDIATELY after the call to .C.
I am sure I am missing something very basic.

Thanks,
Sean


> sessionInfo()
R version 2.2.0, 2005-08-11, powerpc-apple-darwin7.9.0

attached base packages:
[1] "methods"   "stats"     "graphics"  "grDevices" "utils"     "datasets"
[7] "base"     




holmes:~/Mercury/projects/R/StepGram sdavis$ R -d gdb
GNU gdb 6.1-20040303 (Apple version gdb-413) (Wed May 18 10:17:02 GMT 2005)
Copyright 2004 Free Software Foundation, Inc.
GDB is free software, covered by the GNU General Public License, and you are
welcome to change it and/or distribute copies of it under certain
conditions.
Type "show copying" to see the conditions.
There is absolutely no warranty for GDB.  Type "show warranty" for details.
This GDB was configured as "powerpc-apple-darwin"...Reading symbols for
shared libraries ... done

(gdb) r
Starting program: 
/Users/sdavis/R-devel2/R.framework/Versions/2.2.0/Resources/bin/exec/R
Reading symbols for shared libraries ...........+ done

R : Copyright 2005, The R Foundation for Statistical Computing
Version 2.2.0 Under development (unstable) (2005-08-11 r35256)
ISBN 3-900051-07-0

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for a HTML browser interface to help.
Type 'q()' to quit R.

Reading symbols for shared libraries
............................................................. done
Reading symbols for shared libraries . done
Reading symbols for shared libraries . done
> dyn.load('StepGram/src/Stepgram.so')
Reading symbols for shared libraries .. done
> mySG <- function(dat1,thresh,noise) {
  vec <- c(thresh,noise)
  .C('calcStepgram',
     data=as.double(dat1),
     prm=as.double(vec),
     intervals=double(10000*3+1),
     max=as.integer(10000),
     n=as.integer(length(dat1)),
     plot=double(length(dat1)))}
> dat <- c(0.01,0.1,-0.2, 0.1,-0.1,-1000,3.2,3.5,-1.3,3.1,
3.2,3.1,-0.1,0.2,0.15,-0.05,-0.1,0.2,0.1,-0.1)
> 
Program received signal SIGINT, Interrupt.
0x9001f208 in select ()
(gdb) break calcStepgram
Breakpoint 1 at 0x10bb418: file Stepgram.cpp, line 22.
(gdb) c
Continuing.
> mySG(dat1=dat,thresh=3.2,noise=1.1)

Breakpoint 1, calcStepgram (data=0x1137048, prm=0x1c81eb0,
intervals=0xbfffd7e0, max=0x2954840, n=0xbfffd6c0, plot=0x180d574) at
Stepgram.cpp:22
(gdb) print prm[0]
$1 = 1.7716149411915527e-303    <<<<<------This should be 3.2!
Current language:  auto; currently c++


From dsamperi at DecisionSynergy.com  Tue Jan 10 19:41:47 2006
From: dsamperi at DecisionSynergy.com (Dominick Samperi)
Date: Tue, 10 Jan 2006 13:41:47 -0500
Subject: [Rd] Issue with c++ .C call
In-Reply-To: <BFE96390.3659%sdavis2@mail.nih.gov>
References: <BFE96390.3659%sdavis2@mail.nih.gov>
Message-ID: <43C3FFEB.3010506@DecisionSynergy.com>

Sean,

prm in your function calcStepgram is NOT a vector of doubles, it is of type
SEXP, and you need to use R macros to fetch the value(s). This is done
automatically in the Rcpp package, and if you want to see how this is
done look at the definition of the class RcppVector in Rcpp.cpp

Dominick

Sean Davis wrote:
> I am still having some difficulties with connecting R to a C++ function.  I
> am able to call the function as expected after compiling the shared library
> and such.  However, the call to the function is via .C; parameters from the
> .C call are not being passed correctly to the function.  As an example, I
> have attached a GDB run of the code.  I set a breakpoint on entry to the
> function I am calling from R.  What is bothering me (and probably causing
> the segmentation faults I am seeing) is that the parameter
> prm=as.double(c(3.2,1.1)) is not 3.2,1.1 IMMEDIATELY after the call to .C.
> I am sure I am missing something very basic.
>
> Thanks,
> Sean
>
>
>   
>> sessionInfo()
>>     
> R version 2.2.0, 2005-08-11, powerpc-apple-darwin7.9.0
>
> attached base packages:
> [1] "methods"   "stats"     "graphics"  "grDevices" "utils"     "datasets"
> [7] "base"     
>
>
>
>
> holmes:~/Mercury/projects/R/StepGram sdavis$ R -d gdb
> GNU gdb 6.1-20040303 (Apple version gdb-413) (Wed May 18 10:17:02 GMT 2005)
> Copyright 2004 Free Software Foundation, Inc.
> GDB is free software, covered by the GNU General Public License, and you are
> welcome to change it and/or distribute copies of it under certain
> conditions.
> Type "show copying" to see the conditions.
> There is absolutely no warranty for GDB.  Type "show warranty" for details.
> This GDB was configured as "powerpc-apple-darwin"...Reading symbols for
> shared libraries ... done
>
> (gdb) r
> Starting program: 
> /Users/sdavis/R-devel2/R.framework/Versions/2.2.0/Resources/bin/exec/R
> Reading symbols for shared libraries ...........+ done
>
> R : Copyright 2005, The R Foundation for Statistical Computing
> Version 2.2.0 Under development (unstable) (2005-08-11 r35256)
> ISBN 3-900051-07-0
>
> R is free software and comes with ABSOLUTELY NO WARRANTY.
> You are welcome to redistribute it under certain conditions.
> Type 'license()' or 'licence()' for distribution details.
>
> R is a collaborative project with many contributors.
> Type 'contributors()' for more information and
> 'citation()' on how to cite R or R packages in publications.
>
> Type 'demo()' for some demos, 'help()' for on-line help, or
> 'help.start()' for a HTML browser interface to help.
> Type 'q()' to quit R.
>
> Reading symbols for shared libraries
> ............................................................. done
> Reading symbols for shared libraries . done
> Reading symbols for shared libraries . done
>   
>> dyn.load('StepGram/src/Stepgram.so')
>>     
> Reading symbols for shared libraries .. done
>   
>> mySG <- function(dat1,thresh,noise) {
>>     
>   vec <- c(thresh,noise)
>   .C('calcStepgram',
>      data=as.double(dat1),
>      prm=as.double(vec),
>      intervals=double(10000*3+1),
>      max=as.integer(10000),
>      n=as.integer(length(dat1)),
>      plot=double(length(dat1)))}
>   
>> dat <- c(0.01,0.1,-0.2, 0.1,-0.1,-1000,3.2,3.5,-1.3,3.1,
>>     
> 3.2,3.1,-0.1,0.2,0.15,-0.05,-0.1,0.2,0.1,-0.1)
>   
> Program received signal SIGINT, Interrupt.
> 0x9001f208 in select ()
> (gdb) break calcStepgram
> Breakpoint 1 at 0x10bb418: file Stepgram.cpp, line 22.
> (gdb) c
> Continuing.
>   
>> mySG(dat1=dat,thresh=3.2,noise=1.1)
>>     
>
> Breakpoint 1, calcStepgram (data=0x1137048, prm=0x1c81eb0,
> intervals=0xbfffd7e0, max=0x2954840, n=0xbfffd6c0, plot=0x180d574) at
> Stepgram.cpp:22
> (gdb) print prm[0]
> $1 = 1.7716149411915527e-303    <<<<<------This should be 3.2!
> Current language:  auto; currently c++
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From sdavis2 at mail.nih.gov  Tue Jan 10 19:45:12 2006
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Tue, 10 Jan 2006 13:45:12 -0500
Subject: [Rd] Issue with c++ .C call
In-Reply-To: <Pine.LNX.4.61.0601101831140.18059@gannet.stats>
Message-ID: <BFE96AE8.3668%sdavis2@mail.nih.gov>




On 1/10/06 1:33 PM, "Prof Brian Ripley" <ripley at stats.ox.ac.uk> wrote:

> Looks like a type mismatch in the call: you have not shown us the C++
> code.

extern "C" void calcStepgram(double *data,  double *prm, double *intervals,
int *max, int *n,double *plot) {
 ....
}


> On Tue, 10 Jan 2006, Sean Davis wrote:
> 
>> I am still having some difficulties with connecting R to a C++ function.  I
>> am able to call the function as expected after compiling the shared library
>> and such.  However, the call to the function is via .C; parameters from the
>> .C call are not being passed correctly to the function.  As an example, I
>> have attached a GDB run of the code.  I set a breakpoint on entry to the
>> function I am calling from R.  What is bothering me (and probably causing
>> the segmentation faults I am seeing) is that the parameter
>> prm=as.double(c(3.2,1.1)) is not 3.2,1.1 IMMEDIATELY after the call to .C.
>> I am sure I am missing something very basic.
>> 
>> Thanks,
>> Sean
>> 
>> 
>>> sessionInfo()
>> R version 2.2.0, 2005-08-11, powerpc-apple-darwin7.9.0
>> 
>> attached base packages:
>> [1] "methods"   "stats"     "graphics"  "grDevices" "utils"     "datasets"
>> [7] "base"
>> 
>> 
>> 
>> 
>> holmes:~/Mercury/projects/R/StepGram sdavis$ R -d gdb
>> GNU gdb 6.1-20040303 (Apple version gdb-413) (Wed May 18 10:17:02 GMT 2005)
>> Copyright 2004 Free Software Foundation, Inc.
>> GDB is free software, covered by the GNU General Public License, and you are
>> welcome to change it and/or distribute copies of it under certain
>> conditions.
>> Type "show copying" to see the conditions.
>> There is absolutely no warranty for GDB.  Type "show warranty" for details.
>> This GDB was configured as "powerpc-apple-darwin"...Reading symbols for
>> shared libraries ... done
>> 
>> (gdb) r
>> Starting program:
>> /Users/sdavis/R-devel2/R.framework/Versions/2.2.0/Resources/bin/exec/R
>> Reading symbols for shared libraries ...........+ done
>> 
>> R : Copyright 2005, The R Foundation for Statistical Computing
>> Version 2.2.0 Under development (unstable) (2005-08-11 r35256)
>> ISBN 3-900051-07-0
>> 
>> R is free software and comes with ABSOLUTELY NO WARRANTY.
>> You are welcome to redistribute it under certain conditions.
>> Type 'license()' or 'licence()' for distribution details.
>> 
>> R is a collaborative project with many contributors.
>> Type 'contributors()' for more information and
>> 'citation()' on how to cite R or R packages in publications.
>> 
>> Type 'demo()' for some demos, 'help()' for on-line help, or
>> 'help.start()' for a HTML browser interface to help.
>> Type 'q()' to quit R.
>> 
>> Reading symbols for shared libraries
>> ............................................................. done
>> Reading symbols for shared libraries . done
>> Reading symbols for shared libraries . done
>>> dyn.load('StepGram/src/Stepgram.so')
>> Reading symbols for shared libraries .. done
>>> mySG <- function(dat1,thresh,noise) {
>>  vec <- c(thresh,noise)
>>  .C('calcStepgram',
>>     data=as.double(dat1),
>>     prm=as.double(vec),
>>     intervals=double(10000*3+1),
>>     max=as.integer(10000),
>>     n=as.integer(length(dat1)),
>>     plot=double(length(dat1)))}
>>> dat <- c(0.01,0.1,-0.2, 0.1,-0.1,-1000,3.2,3.5,-1.3,3.1,
>> 3.2,3.1,-0.1,0.2,0.15,-0.05,-0.1,0.2,0.1,-0.1)
>>> 
>> Program received signal SIGINT, Interrupt.
>> 0x9001f208 in select ()
>> (gdb) break calcStepgram
>> Breakpoint 1 at 0x10bb418: file Stepgram.cpp, line 22.
>> (gdb) c
>> Continuing.
>>> mySG(dat1=dat,thresh=3.2,noise=1.1)
>> 
>> Breakpoint 1, calcStepgram (data=0x1137048, prm=0x1c81eb0,
>> intervals=0xbfffd7e0, max=0x2954840, n=0xbfffd6c0, plot=0x180d574) at
>> Stepgram.cpp:22
>> (gdb) print prm[0]
>> $1 = 1.7716149411915527e-303    <<<<<------This should be 3.2!
>> Current language:  auto; currently c++


From tlumley at u.washington.edu  Tue Jan 10 20:15:20 2006
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 10 Jan 2006 11:15:20 -0800 (PST)
Subject: [Rd] Issue with c++ .C call
In-Reply-To: <43C3FFEB.3010506@DecisionSynergy.com>
References: <BFE96390.3659%sdavis2@mail.nih.gov>
	<43C3FFEB.3010506@DecisionSynergy.com>
Message-ID: <Pine.LNX.4.64.0601101114200.25401@homer24.u.washington.edu>

On Tue, 10 Jan 2006, Dominick Samperi wrote:

> Sean,
>
> prm in your function calcStepgram is NOT a vector of doubles, it is of type
> SEXP, and you need to use R macros to fetch the value(s). This is done
> automatically in the Rcpp package, and if you want to see how this is
> done look at the definition of the class RcppVector in Rcpp.cpp

Not at all.  He is using .C, which passes a double * to the C function. 
You may be thinking of .Call

 	-thomas


> Dominick
>
> Sean Davis wrote:
>> I am still having some difficulties with connecting R to a C++ function.  I
>> am able to call the function as expected after compiling the shared library
>> and such.  However, the call to the function is via .C; parameters from the
>> .C call are not being passed correctly to the function.  As an example, I
>> have attached a GDB run of the code.  I set a breakpoint on entry to the
>> function I am calling from R.  What is bothering me (and probably causing
>> the segmentation faults I am seeing) is that the parameter
>> prm=as.double(c(3.2,1.1)) is not 3.2,1.1 IMMEDIATELY after the call to .C.
>> I am sure I am missing something very basic.
>>
>> Thanks,
>> Sean
>>
>>
>>
>>> sessionInfo()
>>>
>> R version 2.2.0, 2005-08-11, powerpc-apple-darwin7.9.0
>>
>> attached base packages:
>> [1] "methods"   "stats"     "graphics"  "grDevices" "utils"     "datasets"
>> [7] "base"
>>
>>
>>
>>
>> holmes:~/Mercury/projects/R/StepGram sdavis$ R -d gdb
>> GNU gdb 6.1-20040303 (Apple version gdb-413) (Wed May 18 10:17:02 GMT 2005)
>> Copyright 2004 Free Software Foundation, Inc.
>> GDB is free software, covered by the GNU General Public License, and you are
>> welcome to change it and/or distribute copies of it under certain
>> conditions.
>> Type "show copying" to see the conditions.
>> There is absolutely no warranty for GDB.  Type "show warranty" for details.
>> This GDB was configured as "powerpc-apple-darwin"...Reading symbols for
>> shared libraries ... done
>>
>> (gdb) r
>> Starting program:
>> /Users/sdavis/R-devel2/R.framework/Versions/2.2.0/Resources/bin/exec/R
>> Reading symbols for shared libraries ...........+ done
>>
>> R : Copyright 2005, The R Foundation for Statistical Computing
>> Version 2.2.0 Under development (unstable) (2005-08-11 r35256)
>> ISBN 3-900051-07-0
>>
>> R is free software and comes with ABSOLUTELY NO WARRANTY.
>> You are welcome to redistribute it under certain conditions.
>> Type 'license()' or 'licence()' for distribution details.
>>
>> R is a collaborative project with many contributors.
>> Type 'contributors()' for more information and
>> 'citation()' on how to cite R or R packages in publications.
>>
>> Type 'demo()' for some demos, 'help()' for on-line help, or
>> 'help.start()' for a HTML browser interface to help.
>> Type 'q()' to quit R.
>>
>> Reading symbols for shared libraries
>> ............................................................. done
>> Reading symbols for shared libraries . done
>> Reading symbols for shared libraries . done
>>
>>> dyn.load('StepGram/src/Stepgram.so')
>>>
>> Reading symbols for shared libraries .. done
>>
>>> mySG <- function(dat1,thresh,noise) {
>>>
>>   vec <- c(thresh,noise)
>>   .C('calcStepgram',
>>      data=as.double(dat1),
>>      prm=as.double(vec),
>>      intervals=double(10000*3+1),
>>      max=as.integer(10000),
>>      n=as.integer(length(dat1)),
>>      plot=double(length(dat1)))}
>>
>>> dat <- c(0.01,0.1,-0.2, 0.1,-0.1,-1000,3.2,3.5,-1.3,3.1,
>>>
>> 3.2,3.1,-0.1,0.2,0.15,-0.05,-0.1,0.2,0.1,-0.1)
>>
>> Program received signal SIGINT, Interrupt.
>> 0x9001f208 in select ()
>> (gdb) break calcStepgram
>> Breakpoint 1 at 0x10bb418: file Stepgram.cpp, line 22.
>> (gdb) c
>> Continuing.
>>
>>> mySG(dat1=dat,thresh=3.2,noise=1.1)
>>>
>>
>> Breakpoint 1, calcStepgram (data=0x1137048, prm=0x1c81eb0,
>> intervals=0xbfffd7e0, max=0x2954840, n=0xbfffd6c0, plot=0x180d574) at
>> Stepgram.cpp:22
>> (gdb) print prm[0]
>> $1 = 1.7716149411915527e-303    <<<<<------This should be 3.2!
>> Current language:  auto; currently c++
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle


From sdavis2 at mail.nih.gov  Tue Jan 10 20:18:18 2006
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Tue, 10 Jan 2006 14:18:18 -0500
Subject: [Rd] Issue with c++ .C call
In-Reply-To: <43C3FFEB.3010506@DecisionSynergy.com>
Message-ID: <BFE972AA.3677%sdavis2@mail.nih.gov>




On 1/10/06 1:41 PM, "Dominick Samperi" <dsamperi at DecisionSynergy.com> wrote:

> Sean,
> 
> prm in your function calcStepgram is NOT a vector of doubles, it is of type
> SEXP, and you need to use R macros to fetch the value(s). This is done
> automatically in the Rcpp package, and if you want to see how this is
> done look at the definition of the class RcppVector in Rcpp.cpp

I'm not sure why the prm parameter is not a vector; I thought this was the
standard way to create a vector of doubles....  So to confuse myself even
more, I have added a simple C function that looks simply calls my C++
function like this:

extern "C" {
  void mymain(double *data,double *prm, double* intervals, int* max, int *n,
double *plot) {
    calcStepgram(data,prm,intervals,max,n,plot);
  }
}

Then, I call this function using .C('mymain',...) as before.  Note the
change in parameter memory locations from the call to mymain and the call to
calcStepgram.  Why does this happen?

> dyn.load('StepGram/src/Stepgram.so')
> mySG <- function(dat1,thresh,noise) {
  vec <- c(thresh,noise)
  .C('mymain',
     data=as.double(dat1),
     prm=as.double(vec),
     intervals=double(10000*3+1),
     max=as.integer(10000),
     n=as.integer(length(dat1)),
     plot=double(length(dat1)))}
> dat <- c(0.01,0.1,-0.2,0.1,-0.1,-1000,3.2,3.5,-1.3,
3.1,3.2,3.1,-0.1,0.2,0.15,-0.05,-0.1,0.2,0.1,-0.1)

....

(gdb) break mymain
Breakpoint 1 at 0x10c13f0: file Stepgram.cpp, line 23.
(gdb) c
Continuing.
> mySG(dat1=dat,thresh=3,noise=1)

Breakpoint 1, mymain (data=0x1137148, prm=0x195cd30, intervals=0x1386018,
max=0x1b208e0, n=0x1b20900, plot=0x1137208) at Stepgram.cpp:23
23          calcStepgram(data,prm,intervals,max,n,plot);
(gdb) print prm[0]
$1 = 3
Current language:  auto; currently c++
(gdb) print prm[1]
$2 = 1
(gdb) print max[0]
$3 = 10000
(gdb) s       
calcStepgram (data=0x1137148, prm=0x180da24, intervals=0x195cd68,
max=0x1999d6c, n=0xbfffd6e0, plot=0x0) at Stepgram.cpp:29
29          Stepgram* sg=new Stepgram(data, *n);
(gdb) print prm[0]
$4 = 2.0002441518028817
(gdb)


From tlumley at u.washington.edu  Tue Jan 10 20:27:09 2006
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 10 Jan 2006 11:27:09 -0800 (PST)
Subject: [Rd] Issue with c++ .C call
In-Reply-To: <BFE96390.3659%sdavis2@mail.nih.gov>
References: <BFE96390.3659%sdavis2@mail.nih.gov>
Message-ID: <Pine.LNX.4.64.0601101115500.25401@homer24.u.washington.edu>

On Tue, 10 Jan 2006, Sean Davis wrote:
> and such.  However, the call to the function is via .C; parameters from the
> .C call are not being passed correctly to the function.  As an example, I
> have attached a GDB run of the code.  I set a breakpoint on entry to the
> function I am calling from R.  What is bothering me (and probably causing
> the segmentation faults I am seeing) is that the parameter
> prm=as.double(c(3.2,1.1)) is not 3.2,1.1 IMMEDIATELY after the call to .C.

Is this compiled with optimization? If so, you can't conclude much from 
the gdb info as the code can be executed in a different order from how 
it's written.

When I use this example

extern "C" void calcStepgram(double *data,  double *prm, double *intervals,
int *max, int *n,double *plot) {

  prm[0]=data[0];
  return;
}

if I compile with -g -02 (the default) it looks as though there are 
problems with initialization like the ones you report, but in fact the 
function works correctly.  If I compile without optimization the 
initialization looks fine.

 	-thomas


From sdavis2 at mail.nih.gov  Tue Jan 10 22:17:41 2006
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Tue, 10 Jan 2006 16:17:41 -0500
Subject: [Rd] Issue with c++ .C call
In-Reply-To: <Pine.LNX.4.64.0601101115500.25401@homer24.u.washington.edu>
Message-ID: <BFE98EA5.36AA%sdavis2@mail.nih.gov>




On 1/10/06 2:27 PM, "Thomas Lumley" <tlumley at u.washington.edu> wrote:

> On Tue, 10 Jan 2006, Sean Davis wrote:
>> and such.  However, the call to the function is via .C; parameters from the
>> .C call are not being passed correctly to the function.  As an example, I
>> have attached a GDB run of the code.  I set a breakpoint on entry to the
>> function I am calling from R.  What is bothering me (and probably causing
>> the segmentation faults I am seeing) is that the parameter
>> prm=as.double(c(3.2,1.1)) is not 3.2,1.1 IMMEDIATELY after the call to .C.
> 
> Is this compiled with optimization? If so, you can't conclude much from
> the gdb info as the code can be executed in a different order from how
> it's written.
> 
> When I use this example
> 
> extern "C" void calcStepgram(double *data,  double *prm, double *intervals,
> int *max, int *n,double *plot) {
> 
>   prm[0]=data[0];
>   return;
> }
> 
> if I compile with -g -02 (the default) it looks as though there are
> problems with initialization like the ones you report, but in fact the
> function works correctly.  If I compile without optimization the
> initialization looks fine.

Thanks, Thomas.  That did fix the initialization issue (or apparent one).
Unfortunately, the reason that I started debugging was for segmentation
faults, which have not gone away.  However, it now looks like the problem is
internal to the C++ code and not with the way the arguments were being
passed.  

Back to gdb....

Sean


From Augusto.Sanabria at ga.gov.au  Tue Jan 10 22:34:29 2006
From: Augusto.Sanabria at ga.gov.au (Augusto.Sanabria@ga.gov.au)
Date: Wed, 11 Jan 2006 08:34:29 +1100
Subject: [Rd] Interfacing with user in R
Message-ID: <9707EBA615A57747A0668CECD4638A3081E2EF@mail.agso.gov.au>


Good day everyone,

I am new in R programming (my question may sound
trivial to you): is there any way to ask the user
to enter a string within an R process, say a filename, 
make R to recognise it and open the given file? 
It is a simple exercise in other languages. 
I am using R2.1.1 in a LINUX machine.

Thanks for your help.

Augusto

--------------------------------------------
Augusto Sanabria. MSc, PhD.
Mathematical Modeller
Risk Research Group
Geospatial & Earth Monitoring Division
Geoscience Australia (www.ga.gov.au)
Cnr. Jerrabomberra Av. & Hindmarsh Dr.
Symonston ACT 2609
Ph. (02) 6249-9155


From simon.urbanek at r-project.org  Tue Jan 10 22:43:21 2006
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Tue, 10 Jan 2006 16:43:21 -0500
Subject: [Rd] Interfacing with user in R
In-Reply-To: <9707EBA615A57747A0668CECD4638A3081E2EF@mail.agso.gov.au>
References: <9707EBA615A57747A0668CECD4638A3081E2EF@mail.agso.gov.au>
Message-ID: <1689A0EA-C51D-48E5-BE0F-E32863244077@r-project.org>

On Jan 10, 2006, at 4:34 PM, <Augusto.Sanabria at ga.gov.au>  
<Augusto.Sanabria at ga.gov.au> wrote:

> I am new in R programming (my question may sound trivial to you):  
> is there any way to ask the user to enter a string within an R  
> process, say a filename, make R to recognise it and open the given  
> file?

Sure, for reading you can use readLines. I have no idea what you mean  
by "recognise", but let's say if you wanted to use read.table, it  
would be
read.table(readLines(n=1))

Of course, in R there is an even more convenient method far that ;)
read.table(file.choose())

Cheers,
Simon


From tlumley at u.washington.edu  Wed Jan 11 00:50:48 2006
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 10 Jan 2006 15:50:48 -0800 (PST)
Subject: [Rd] Issue with c++ .C call
In-Reply-To: <BFE98EA5.36AA%sdavis2@mail.nih.gov>
References: <BFE98EA5.36AA%sdavis2@mail.nih.gov>
Message-ID: <Pine.LNX.4.64.0601101549120.25401@homer24.u.washington.edu>

On Tue, 10 Jan 2006, Sean Davis wrote:

>
> Thanks, Thomas.  That did fix the initialization issue (or apparent one).
> Unfortunately, the reason that I started debugging was for segmentation
> faults, which have not gone away.  However, it now looks like the problem is
> internal to the C++ code and not with the way the arguments were being
> passed.

If you can get access to a Linux machine then it's worth trying Valgrind, 
which is very helpful for this sort of thing.

 	-thomas


From christian.hoffmann at wsl.ch  Wed Jan 11 09:30:52 2006
From: christian.hoffmann at wsl.ch (christian.hoffmann@wsl.ch)
Date: Wed, 11 Jan 2006 09:30:52 +0100 (CET)
Subject: [Rd] Browser problem,
	Misrepresentation of .html in Solaris Firefox (PR#8471)
Message-ID: <20060111083052.E9C1120709@slim.kubism.ku.dk>

Hi there

I hope that I am in the right forum.

I am working on Win2000 PC connected via Exceed 6.0.1.0 to a

SunOS fluke 5.9 Generic_118558-11 sun4u sparc SUNW,Sun-Fire-480R

There I am using Mozilla Firefox 1.0.7 as a browser.

I am having
difficulties viewing .html files. Their first pages are displayed
normally, black on white, links in blue. When I scoll down, the pages
appear black throughout, only links are sticking out. The rest of the
text can only be viewed by selecting it with the mouse, making it
appear white on blue. This makes scrolling and following links *very* 
combersome.

Files affected:
- R-intro.html
- R-exts.html,
- R-lang.html
- R-admin.html
- R-FAQ.html

Files not affected:
- R-data.html
- packages.html
- SearchEngine.html
- License
- Thanks

Thanks for help
Christian
-- 
Dr. Christian W. Hoffmann,
Swiss Federal Research Institute WSL
Mathematics + Statistical Computing
Zuercherstrasse 111
CH-8903 Birmensdorf, Switzerland

Tel +41-44-7392-277  (office)   -111(exchange)
Fax +41-44-7392-215  (fax)
christian.hoffmann at wsl.ch
http://www.wsl.ch/staff/christian.hoffmann

International Conference 5.-7.6.2006 Ekaterinburg Russia
"Climate changes and their impact on boreal and temperate forests"
http://ecoinf.uran.ru/conference/


From p.dalgaard at biostat.ku.dk  Wed Jan 11 12:18:25 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 11 Jan 2006 12:18:25 +0100
Subject: [Rd] Browser problem,
	Misrepresentation of .html in Solaris Firefox (PR#8471)
In-Reply-To: <20060111083052.E9C1120709@slim.kubism.ku.dk>
References: <20060111083052.E9C1120709@slim.kubism.ku.dk>
Message-ID: <x2y81nko72.fsf@viggo.kubism.ku.dk>

christian.hoffmann at wsl.ch writes:

> Hi there
> 
> I hope that I am in the right forum.
> 
> I am working on Win2000 PC connected via Exceed 6.0.1.0 to a
> 
> SunOS fluke 5.9 Generic_118558-11 sun4u sparc SUNW,Sun-Fire-480R
> 
> There I am using Mozilla Firefox 1.0.7 as a browser.
> 
> I am having
> difficulties viewing .html files. Their first pages are displayed
> normally, black on white, links in blue. When I scoll down, the pages
> appear black throughout, only links are sticking out. The rest of the
> text can only be viewed by selecting it with the mouse, making it
> appear white on blue. This makes scrolling and following links *very* 
> combersome.
> 
> Files affected:
> - R-intro.html
> - R-exts.html,
> - R-lang.html
> - R-admin.html
> - R-FAQ.html
> 
> Files not affected:
> - R-data.html
> - packages.html
> - SearchEngine.html
> - License
> - Thanks
> 
> Thanks for help
> Christian

Not happening here with Firefox 1.0.7, SuSE 9.3 and e.g.
http://cran.r-project.org/doc/manuals/R-intro.html. Not happening with
locally built version of R-intro.html either.

I suspect this is particular to your setup (X terminal emulators can
be notoriously flaky) and not a problem with the html files themselves.
I.e., not a bug that we can do anything about.


-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From ripley at stats.ox.ac.uk  Wed Jan 11 12:24:47 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 11 Jan 2006 11:24:47 +0000 (GMT)
Subject: [Rd] (PR#8471) Browser problem,
 Misrepresentation of .html in Solaris Firefox
In-Reply-To: <20060111083052.E9C1120709@slim.kubism.ku.dk>
References: <20060111083052.E9C1120709@slim.kubism.ku.dk>
Message-ID: <Pine.LNX.4.61.0601111116470.31462@gannet.stats>

In what sense is this a bug in R?

It is either an Exceed or Firefox bug: R is not involved in any way in 
scrolling the pages.

That is an exceedingly old version of Exceed: I have version 10 on my 
machine, and I think there is a `2006' version now.  I have seen a lot of 
bugs in earlier versions of Exceed (8.x and 9.x, not way back to 6.0).

On Wed, 11 Jan 2006 christian.hoffmann at wsl.ch wrote:

> Hi there
>
> I hope that I am in the right forum.
>
> I am working on Win2000 PC connected via Exceed 6.0.1.0 to a
>
> SunOS fluke 5.9 Generic_118558-11 sun4u sparc SUNW,Sun-Fire-480R
>
> There I am using Mozilla Firefox 1.0.7 as a browser.
>
> I am having
> difficulties viewing .html files. Their first pages are displayed
> normally, black on white, links in blue. When I scoll down, the pages
> appear black throughout, only links are sticking out. The rest of the
> text can only be viewed by selecting it with the mouse, making it
> appear white on blue. This makes scrolling and following links *very*
> combersome.
>
> Files affected:
> - R-intro.html
> - R-exts.html,
> - R-lang.html
> - R-admin.html
> - R-FAQ.html
>
> Files not affected:
> - R-data.html
> - packages.html
> - SearchEngine.html
> - License
> - Thanks
>
> Thanks for help
> Christian
> -- 
> Dr. Christian W. Hoffmann,
> Swiss Federal Research Institute WSL
> Mathematics + Statistical Computing
> Zuercherstrasse 111
> CH-8903 Birmensdorf, Switzerland
>
> Tel +41-44-7392-277  (office)   -111(exchange)
> Fax +41-44-7392-215  (fax)
> christian.hoffmann at wsl.ch
> http://www.wsl.ch/staff/christian.hoffmann
>
> International Conference 5.-7.6.2006 Ekaterinburg Russia
> "Climate changes and their impact on boreal and temperate forests"
> http://ecoinf.uran.ru/conference/
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From sdavis2 at mail.nih.gov  Wed Jan 11 12:37:30 2006
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Wed, 11 Jan 2006 06:37:30 -0500
Subject: [Rd] Issue with c++ .C call
In-Reply-To: <Pine.LNX.4.64.0601101549120.25401@homer24.u.washington.edu>
Message-ID: <BFEA582A.3717%sdavis2@mail.nih.gov>




On 1/10/06 6:50 PM, "Thomas Lumley" <tlumley at u.washington.edu> wrote:

> On Tue, 10 Jan 2006, Sean Davis wrote:
> 
>> 
>> Thanks, Thomas.  That did fix the initialization issue (or apparent one).
>> Unfortunately, the reason that I started debugging was for segmentation
>> faults, which have not gone away.  However, it now looks like the problem is
>> internal to the C++ code and not with the way the arguments were being
>> passed.
> 
> If you can get access to a Linux machine then it's worth trying Valgrind,
> which is very helpful for this sort of thing.

I'm going to improve my access, just for this sort of thing.

The problem turned out to be a commented out line in the original C++ code
that wasn't manifesting itself all the time in the standalone code, but was
under R.  So, while the error was hard to find, it was easy to fix.

Thanks to Thomas, Robert Gentleman, Dominick Samperi, and Brian Ripley for
their patient help.

Sean


From jason at cs.jhu.edu  Wed Jan 11 12:43:08 2006
From: jason at cs.jhu.edu (jason@cs.jhu.edu)
Date: Wed, 11 Jan 2006 12:43:08 +0100 (CET)
Subject: [Rd] problem with replicate and "..." (PR#8472)
Message-ID: <20060111114308.0FF342073F@slim.kubism.ku.dk>

I am using R version 2.0.0 (2004-10-04) on Fedora Core 2.

This works correctly:

> foo <- function(x=1,y=2) { c(x,y) }
> bar <- function(n,...) c(n,foo(...))
> bar(10,3)
[1] 10  3  2

But it goes wrong if I replace "c" in bar with "replicate":

> foo <- function(x=1,y=2) { c(x,y) }
> bar <- function(n,...) replicate(n,foo(...))
> bar(10,3)
     [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]
[1,]    0    0    0    0    0    0    0    0    0     0
[2,]    2    2    2    2    2    2    2    2    2     2

It is mysterious why x was bound to the apparently arbitrary
value 0 while y was left at its default.

The ... arguments to bar seems to be ignored altogether.
bar(10), bar(10,x=3), and bar(10,3,4) give the same result.
Furthermore, bar(10,extra=3) does not give an error.

Perhaps this mysterious behavior is unavoidable because of 
the kind of hack replicate is?

Thanks ...


From jason at cs.jhu.edu  Wed Jan 11 12:50:23 2006
From: jason at cs.jhu.edu (jason@cs.jhu.edu)
Date: Wed, 11 Jan 2006 12:50:23 +0100 (CET)
Subject: [Rd] problem with replicate and "..." (PR#8473)
Message-ID: <20060111115023.15174206ED@slim.kubism.ku.dk>

p.s. Note that one workaround is

> bar <- function(n,...) { f <- function() foo(...); 
+                          replicate(n,f()) }
> bar(10,3)
     [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]
[1,]    3    3    3    3    3    3    3    3    3     3
[2,]    2    2    2    2    2    2    2    2    2     2

A little while ago, Jason Eisner wrote:

> I am using R version 2.0.0 (2004-10-04) on Fedora Core 2.
>
> This works correctly:
>
>> foo <- function(x=1,y=2) { c(x,y) }
>> bar <- function(n,...) c(n,foo(...))
>> bar(10,3)
> [1] 10  3  2
>
> But it goes wrong if I replace "c" in bar with "replicate":
>
>> foo <- function(x=1,y=2) { c(x,y) }
>> bar <- function(n,...) replicate(n,foo(...))
>> bar(10,3)
>      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]
> [1,]    0    0    0    0    0    0    0    0    0     0
> [2,]    2    2    2    2    2    2    2    2    2     2
>
> It is mysterious why x was bound to the apparently arbitrary
> value 0 while y was left at its default.
>
> The ... arguments to bar seems to be ignored altogether.
> bar(10), bar(10,x=3), and bar(10,3,4) give the same result.
> Furthermore, bar(10,extra=3) does not give an error.
>
> Perhaps this mysterious behavior is unavoidable because of 
> the kind of hack replicate is?
>
> Thanks ...


From d.firth at warwick.ac.uk  Wed Jan 11 12:56:38 2006
From: d.firth at warwick.ac.uk (David Firth)
Date: Wed, 11 Jan 2006 11:56:38 +0000
Subject: [Rd] standardized residuals (rstandard & plot.lm) (PR#8468)
In-Reply-To: <20060110145855.C141D2069D@slim.kubism.ku.dk>
References: <20060110145855.C141D2069D@slim.kubism.ku.dk>
Message-ID: <681a42f2071447e7f62c4c0a49a3b854@warwick.ac.uk>

On 10 Jan, 2006, at 14:58, maechler at stat.math.ethz.ch wrote:

>>>>>> "Heather" == Heather Turner <Heather.Turner at warwick.ac.uk>
>>>>>>     on Tue, 10 Jan 2006 14:30:23 +0100 (CET) writes:
>
>     Heather> This bug is not quite fixed - the example from my
>     Heather> original report now = works using R-2.2.1, but
>
>     Heather> plot(Uniform, 6)
>
>     Heather> does not. The bug is due
>
>     .........
>      g <- hatval/(1 - hatval) # Potential division by zero here
>
>      plot(g, cook, xlim = c(0, max(g)), ylim = c(0, ymx),
>      ..........
>
>     Heather> All other values of 'which' seem to work
>     Heather> fine. Sorry not to have checked this in the beta
>     Heather> version,
>
> (indeed; that would have been useful)
>
>
> Hmm, it's not clear what *should* be drawn in such a
> case. Leaving away all the observations with  h_ii = 1
> seems a particularly bad idea, since these are the ones that
> you'd definitely should remark.
> OTOH, for h_ii = 1, the cook distance is 'NaN'
> (or should that be changed; to  "very large" instead ???)
> and plot number 6 doesn't seem to make any sense to me
>
> When 'which = 6' was proposed
> [ on R-devel as well, last April,
>   http://tolstoy.newcastle.edu.au/R/devel/05/04/0595.html
>   ah, I see, by David Firth, from your place, so, Heather, can you
>   make sure he sees this e-mail ?
> ]
> I actually had wondered a bit about it's general usefulness,..

Yes, I remember that there was some discussion of this last year, and 
my recollection is that it was mostly luke-warm at best in regard to 
including this plot.

The "h_ii = 1" problem can of course be taken care of by leaving out 
such points if they can be reliably detected, but I share Martin's 
unease about this.  We should also worry about for example h_ii = (1 - 
epsilon), with epsilon small, as plotting such a point would 
effectively make the rest of the graph useless.

Maybe it would be safest to remove the which=6 option?

David


From d.firth at warwick.ac.uk  Wed Jan 11 12:56:56 2006
From: d.firth at warwick.ac.uk (d.firth@warwick.ac.uk)
Date: Wed, 11 Jan 2006 12:56:56 +0100 (CET)
Subject: [Rd] standardized residuals (rstandard & plot.lm) (PR#8468)
Message-ID: <20060111115656.AFC2B2070D@slim.kubism.ku.dk>

On 10 Jan, 2006, at 14:58, maechler at stat.math.ethz.ch wrote:

>>>>>> "Heather" == Heather Turner <Heather.Turner at warwick.ac.uk>
>>>>>>     on Tue, 10 Jan 2006 14:30:23 +0100 (CET) writes:
>
>     Heather> This bug is not quite fixed - the example from my
>     Heather> original report now = works using R-2.2.1, but
>
>     Heather> plot(Uniform, 6)
>
>     Heather> does not. The bug is due
>
>     .........
>      g <- hatval/(1 - hatval) # Potential division by zero here
>
>      plot(g, cook, xlim = c(0, max(g)), ylim = c(0, ymx),
>      ..........
>
>     Heather> All other values of 'which' seem to work
>     Heather> fine. Sorry not to have checked this in the beta
>     Heather> version,
>
> (indeed; that would have been useful)
>
>
> Hmm, it's not clear what *should* be drawn in such a
> case. Leaving away all the observations with  h_ii = 1
> seems a particularly bad idea, since these are the ones that
> you'd definitely should remark.
> OTOH, for h_ii = 1, the cook distance is 'NaN'
> (or should that be changed; to  "very large" instead ???)
> and plot number 6 doesn't seem to make any sense to me
>
> When 'which = 6' was proposed
> [ on R-devel as well, last April,
>   http://tolstoy.newcastle.edu.au/R/devel/05/04/0595.html
>   ah, I see, by David Firth, from your place, so, Heather, can you
>   make sure he sees this e-mail ?
> ]
> I actually had wondered a bit about it's general usefulness,..

Yes, I remember that there was some discussion of this last year, and 
my recollection is that it was mostly luke-warm at best in regard to 
including this plot.

The "h_ii = 1" problem can of course be taken care of by leaving out 
such points if they can be reliably detected, but I share Martin's 
unease about this.  We should also worry about for example h_ii = (1 - 
epsilon), with epsilon small, as plotting such a point would 
effectively make the rest of the graph useless.

Maybe it would be safest to remove the which=6 option?

David


From ripley at stats.ox.ac.uk  Wed Jan 11 15:00:19 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 11 Jan 2006 14:00:19 +0000 (GMT)
Subject: [Rd] Updates for building R-devel for Windows
Message-ID: <Pine.LNX.4.61.0601111125100.31564@gannet.stats>

If you are building R (especially R-devel) for Windows, you will need to 
update your tools.

First, we now require binutils-2.16.91-20050827 (and even 2.2.1 
effectively did).  There is a patched ld.exe for that available from the 
Rtools site, which should be used if you intend to distribute compiled 
packages.  (It overcomes a bug only seen on NT4: the patched version is 
being used for the pre-compiled packages Uwe Ligges makes.)

Second, the recommended gcc 3.4.4 compilers have been replaced by 3.4.5 
ones.  As the 3.4.4 builds are not longer available, we recommend you do 
use the currently available 3.4.5.

Third, I have updated my cross-compiler suite to binutils-2.16.91-20050827 
(with the patched ld.exe), mingw-runtime-3.9 and w32api-3.5, and the 
updated suite is required to build R-devel or R-patched.  After a 
considerable struggle I have managed to cross-build all of gcc-3.4.5, so 
full C++ support is available again.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From p.dalgaard at biostat.ku.dk  Wed Jan 11 15:25:27 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 11 Jan 2006 15:25:27 +0100
Subject: [Rd] problem with replicate and "..." (PR#8472)
In-Reply-To: <20060111114308.0FF342073F@slim.kubism.ku.dk>
References: <20060111114308.0FF342073F@slim.kubism.ku.dk>
Message-ID: <x2psmylu3s.fsf@viggo.kubism.ku.dk>

jason at cs.jhu.edu writes:

> I am using R version 2.0.0 (2004-10-04) on Fedora Core 2.
> 
> This works correctly:
> 
> > foo <- function(x=1,y=2) { c(x,y) }
> > bar <- function(n,...) c(n,foo(...))
> > bar(10,3)
> [1] 10  3  2
> 
> But it goes wrong if I replace "c" in bar with "replicate":
> 
> > foo <- function(x=1,y=2) { c(x,y) }
> > bar <- function(n,...) replicate(n,foo(...))
> > bar(10,3)
>      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]
> [1,]    0    0    0    0    0    0    0    0    0     0
> [2,]    2    2    2    2    2    2    2    2    2     2
> 
> It is mysterious why x was bound to the apparently arbitrary
> value 0 while y was left at its default.
> 
> The ... arguments to bar seems to be ignored altogether.
> bar(10), bar(10,x=3), and bar(10,3,4) give the same result.
> Furthermore, bar(10,extra=3) does not give an error.
> 
> Perhaps this mysterious behavior is unavoidable because of 
> the kind of hack replicate is?

Yes. It is really a wrapper for

sapply(integer(n), eval.parent(substitute(function(...) expr))

Now, integer(n) is n zeroes, and the function that is passed to sapply
is

Browse[1]> FUN
function (...)
foo(...)
<environment: 0xd82338>

Now, this gets called as FUN(0) and in turn foo(0) which is c(0,2).

So, the short answer is "don't do that", and the long answer is "don't
do that". If you're adventurous, you could try experimenting with a
different definition, possibly

sapply(integer(n), eval.parent(substitute(function(...) eval.parent(expr)))

but I'm far from sure that it works...

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From pgilbert at bank-banque-canada.ca  Wed Jan 11 16:07:58 2006
From: pgilbert at bank-banque-canada.ca (Paul Gilbert)
Date: Wed, 11 Jan 2006 10:07:58 -0500
Subject: [Rd] typo in factanal.Rd
Message-ID: <43C51F4E.8000902@bank-banque-canada.ca>

In the file factanal.Rd the line

    then the first fit is started at the value suggested by J\uffffreskog

should be

    then the first fit is started at the value suggested by
     \enc{J\uffffreskog}{Joreskog}

or whatever that translates to on a system that does not mangle cut and 
paste of special characters.

Paul


From sfalcon at fhcrc.org  Wed Jan 11 16:18:25 2006
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Wed, 11 Jan 2006 07:18:25 -0800
Subject: [Rd] problem with replicate and "..." (PR#8473)
In-Reply-To: <20060111115023.15174206ED@slim.kubism.ku.dk> (jason@cs.jhu.edu's
	message of "Wed, 11 Jan 2006 12:50:23 +0100 (CET)")
References: <20060111115023.15174206ED@slim.kubism.ku.dk>
Message-ID: <m27j96n67y.fsf@fhcrc.org>

On 11 Jan 2006, jason at cs.jhu.edu wrote:

> p.s. Note that one workaround is
>
>> bar <- function(n,...) { f <- function() foo(...); 
> +                          replicate(n,f()) }

Another appears to be:

bar <- function(n, ...) {
    args <- list(...)
    replicate(n, do.call("foo", args))
}

+ seth


From mschaff at bu.edu  Wed Jan 11 22:49:12 2006
From: mschaff at bu.edu (Mike Schaffer)
Date: Wed, 11 Jan 2006 16:49:12 -0500
Subject: [Rd] Fixed plot height question
Message-ID: <75ABA294-FD90-4CC8-995B-17F35BF55A71@bu.edu>

I've tried many things, so it's time to call on the gurus.  I'm  
trying to make a plot that will conform to the width of the plot  
device but have a fixed height (say one inch regardless of the plot  
device height setting -- unless obviously it's less than the plot  
device).

Is this possible?

Additionally, I'd like to be able to plot something immediately after  
this plot and have it right below.  Would this require a par(mfrow=c 
()) command? Can anyone help?

Thanks.


From ripley at stats.ox.ac.uk  Wed Jan 11 23:00:46 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 11 Jan 2006 22:00:46 +0000 (GMT)
Subject: [Rd] Fixed plot height question
In-Reply-To: <75ABA294-FD90-4CC8-995B-17F35BF55A71@bu.edu>
References: <75ABA294-FD90-4CC8-995B-17F35BF55A71@bu.edu>
Message-ID: <Pine.LNX.4.61.0601112155550.27354@gannet.stats>

On Wed, 11 Jan 2006, Mike Schaffer wrote:

> I've tried many things, so it's time to call on the gurus.  I'm
> trying to make a plot that will conform to the width of the plot
> device but have a fixed height (say one inch regardless of the plot
> device height setting -- unless obviously it's less than the plot
> device).
>
> Is this possible?

Yes.  Set par(pin=c(par("pin")[1], 1)).

Warning: you may not have meant the plot height, rather the figure height.
See R-Intro for the differences.

> Additionally, I'd like to be able to plot something immediately after
> this plot and have it right below.  Would this require a par(mfrow=c
> ()) command? Can anyone help?

Using par(plt=) will do this for you.  Or look into grid, layout or 
split.screen.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From danlipsitt at gmail.com  Wed Jan 11 23:26:09 2006
From: danlipsitt at gmail.com (Dan Lipsitt)
Date: Wed, 11 Jan 2006 17:26:09 -0500
Subject: [Rd] R 2.2.2-1 RPM build problem and solution on RH AS 4 x86_64
Message-ID: <b3a7efa90601111426p555bb45ag90193daac00f9862@mail.gmail.com>

I have a dual Xeon x86_64 system running Red Hat AS 4. There are no
x86_64 rpms in http://cran.us.r-project.org/bin/linux/redhat/el4/ (the
i386 ones are a point release behind anyway) , and the fc4 rpms have a
whole web of dependencies I don't want to pull in. So I decided to
build http://cran.us.r-project.org/bin/linux/redhat/SRPMS/R-2.2.1-1.fc3.src.rpm
.

When I ran rpmbuild. one of the make-check tests failed.

from /BUILD/R-2.2.1/tests/p-r-random-tests.Rout.fail:
> dkwtest("weibull",shape = 1)
weibull(shape = 1) FAILED
Error in dkwtest("weibull", shape = 1) : dkwtest failed
Execution halted

I was able to build the rpm after removing "--enable-r-shlib" from the
spec file.

http://cran.us.r-project.org/bin/linux/redhat/SRPMS/ReadMe says:
"The new SRPM for R 2.1.1 builds the shared library version of R. This is,
unfortunately, slower than the version without the shared library."

It doesn't say why, if it's slower, it builds it that way. Can anyone
shed some light on the subject?

Dan


From ripley at stats.ox.ac.uk  Wed Jan 11 23:44:25 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 11 Jan 2006 22:44:25 +0000 (GMT)
Subject: [Rd] R 2.2.2-1 RPM build problem and solution on RH AS 4 x86_64
In-Reply-To: <b3a7efa90601111426p555bb45ag90193daac00f9862@mail.gmail.com>
References: <b3a7efa90601111426p555bb45ag90193daac00f9862@mail.gmail.com>
Message-ID: <Pine.LNX.4.61.0601112235380.7495@gannet.stats>

On Wed, 11 Jan 2006, Dan Lipsitt wrote:

> I have a dual Xeon x86_64 system running Red Hat AS 4. There are no
> x86_64 rpms in http://cran.us.r-project.org/bin/linux/redhat/el4/ (the
> i386 ones are a point release behind anyway) , and the fc4 rpms have a
> whole web of dependencies I don't want to pull in. So I decided to
> build http://cran.us.r-project.org/bin/linux/redhat/SRPMS/R-2.2.1-1.fc3.src.rpm
> .

You might consider the fc3 RPMS: is RHEL4 not closer to FC3 than FC4?
(They may not have made your mirror yet, but they are en route.)

> When I ran rpmbuild. one of the make-check tests failed.

That test is documented to be random and fail sometimes.  Please try it
again.

> from /BUILD/R-2.2.1/tests/p-r-random-tests.Rout.fail:
>> dkwtest("weibull",shape = 1)
> weibull(shape = 1) FAILED
> Error in dkwtest("weibull", shape = 1) : dkwtest failed
> Execution halted
>
> I was able to build the rpm after removing "--enable-r-shlib" from the
> spec file.
>
> http://cran.us.r-project.org/bin/linux/redhat/SRPMS/ReadMe says:
> "The new SRPM for R 2.1.1 builds the shared library version of R. This is,
> unfortunately, slower than the version without the shared library."
>
> It doesn't say why, if it's slower, it builds it that way. Can anyone
> shed some light on the subject?

This _is_ discussed in the the R-admin manual, to which the INSTALL file 
refers you.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ggrothendieck at gmail.com  Wed Jan 11 23:45:10 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Wed, 11 Jan 2006 17:45:10 -0500
Subject: [Rd] natural sorting
Message-ID: <971536df0601111445w10b5dce2se8e52e962ccfd1e5@mail.gmail.com>

It would be nifty to incorporate this into R or into an R package:

http://sourcefrog.net/projects/natsort/


From sims at Princeton.EDU  Thu Jan 12 03:47:35 2006
From: sims at Princeton.EDU (sims@Princeton.EDU)
Date: Thu, 12 Jan 2006 03:47:35 +0100 (CET)
Subject: [Rd] bug in qr.coef() and (therefore) in qr.solve (PR#8476)
Message-ID: <20060112024735.47F8820772@slim.kubism.ku.dk>

This is a multi-part message in MIME format.
--------------050206000203080003040803
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit

[I thought I'd submitted this bug report some time ago, but it's never showed up on the bug tracking system, so I'm submitting again.]

qr.solve() gives incorrect results when dealing with complex matrices or with qr objects that have been computed with LAPACK=TRUE, whenever the b argument has more than one column.  This bug flows from qr.coef(), which has a similar problem.  I believe the problem is the line

  coef[qr$pivot, ] <- .Call("qr_coef_cmplx", qr, y, PACKAGE = "base")[1:p]

and the similar line in the LAPACK section of the qr.coef() code.  As far as I can see, this line should read

	coef <- .Call("qr_coef_cmplx", qr, y, PACKAGE = "base")[qr$pivot,]

With this change, qr.coef() gives correct results for my examples.  In the examples, the qr.coeffCS() function is my version of qr.coef, with the two lines
in question changed as above (and no other modifications).

Examples:

> A <- matrix(rnorm(9),3,3)
> B <- matrix(rnorm(9),3,3)
> solve(A+1i*B,A+1i*B)
                            [,1]                        [,2] [,3]
[1,]  1.000000e+00+0.000000e+00i -1.853360e-17-1.199306e-17i 0+0i
[2,]  2.338819e-17-1.192988e-19i  1.000000e+00+1.155338e-20i 0+0i
[3,] -6.940188e-18+1.120842e-17i  5.188659e-17-3.226848e-17i 1+0i
> qr.solve(A+1i*B,A+1i*B)
                            [,1]                        [,2]
[1,]  1.000000e-00-2.583088e-16i  1.000000e-00-2.583088e-16i
[2,] -1.045057e-16+1.979352e-16i -1.045057e-16+1.979352e-16i
[3,]  3.966684e-16+7.360601e-16i  3.966684e-16+7.360601e-16i
                            [,3]
[1,]  1.000000e-00-2.583088e-16i
[2,] -1.045057e-16+1.979352e-16i
[3,]  3.966684e-16+7.360601e-16i
## Note:  all columns the same, matrix should be the identity

> qr.coef(qr(A+1i*B),A+1i*B)
                            [,1]                        [,2]
[1,]  1.000000e-00-2.583088e-16i  1.000000e-00-2.583088e-16i
[2,] -1.045057e-16+1.979352e-16i -1.045057e-16+1.979352e-16i
[3,]  3.966684e-16+7.360601e-16i  3.966684e-16+7.360601e-16i
                            [,3]
[1,]  1.000000e-00-2.583088e-16i
[2,] -1.045057e-16+1.979352e-16i
[3,]  3.966684e-16+7.360601e-16i
> qr.coeffCS(qr(A+1i*B),A+1i*B)
                            [,1]                        [,2]
[1,]  1.000000e-00-2.583088e-16i -6.306738e-17-8.893088e-17i
[2,] -1.045057e-16+1.979352e-16i  1.000000e-00-1.921467e-17i
[3,]  3.966684e-16+7.360601e-16i  4.149193e-17-1.149122e-16i
                            [,3]
[1,] -7.350360e-17-6.340421e-17i
[2,] -2.685509e-17+3.225516e-17i
[3,]  1.000000e+00-8.587603e-18i
## Note:  correct results from the function with two modified lines, whether
## LAPACK=TRUE or not and whether complex or not.

> qr.coeffCS(qr(A,LAPACK=TRUE),A)
              [,1]         [,2] [,3]
[1,]  1.000000e+00 0.000000e+00    0
[2,]  1.267908e-15 1.000000e+00    0
[3,] -1.889451e-15 4.074224e-17    1
> qr.coef(qr(A,LAPACK=TRUE),A)
              [,1]          [,2]          [,3]
[1,]  1.000000e+00  1.000000e+00  1.000000e+00
[2,]  1.267908e-15  1.267908e-15  1.267908e-15
[3,] -1.889451e-15 -1.889451e-15 -1.889451e-15
> qr.solve(qr(A,LAPACK=TRUE),A)
              [,1]          [,2]          [,3]
[1,]  1.000000e+00  1.000000e+00  1.000000e+00
[2,]  1.267908e-15  1.267908e-15  1.267908e-15
[3,] -1.889451e-15 -1.889451e-15 -1.889451e-15
> solve(A,A)
             [,1]          [,2] [,3]
[1,] 1.000000e+00  2.628787e-17    0
[2,] 1.899954e-17  1.000000e+00    0
[3,] 2.851722e-16 -6.860465e-17    1
> C <- solve(A,B)
> qr.solve(A,B)-C
              [,1]          [,2]          [,3]
[1,] -8.881784e-16  1.332268e-15  4.440892e-16
[2,] -1.387779e-15  2.220446e-15  8.881784e-16
[3,]  2.664535e-15 -3.552714e-15 -1.110223e-15
## qr.solve() matches solve() with real, non-LAPACK argument

> qr.coef(qr(A),B)-C
              [,1]          [,2]          [,3]
[1,] -8.881784e-16  1.332268e-15  4.440892e-16
[2,] -1.387779e-15  2.220446e-15  8.881784e-16
[3,]  2.664535e-15 -3.552714e-15 -1.110223e-15
> qr.coef(qr(A,LAPACK=TRUE),B)-C
              [,1]      [,2]       [,3]
[1,]  1.110223e-15  3.380377  1.4697337
[2,]  2.164935e-15  1.812489  0.9821958
[3,] -3.552714e-15 -9.280706 -6.3293155
## qr.coef() gives different results with LAPACK=TRUE 

> qr.coeffCS(qr(A,LAPACK=TRUE),B)-C
              [,1]          [,2]          [,3]
[1,]  1.110223e-15 -1.776357e-15 -3.330669e-16
[2,]  2.164935e-15 -3.996803e-15 -6.661338e-16
[3,] -3.552714e-15  7.105427e-15  1.221245e-15
## the modified function gives the same results for LAPACK=TRUE as does
## qr.coef() in the LAPACK=FALSE case.

## lines below just show that qr.coeffCS() works in non-square cases and
## that the problem is there in ths same form in these cases for the original
## qr.coef()

> X <- matrix(rnorm(36),12,3)
> y <- matrix(rnorm(24),12,2)
> b <- qr.coef(qr(X),y)
> qr.coef(qr(X,LAPACK=TRUE),y)-b
              [,1]      [,2]
[1,] -5.551115e-17 0.2509164
[2,]  1.110223e-16 0.1846802
[3,]  0.000000e+00 1.0224349
> qr.coef(qr(X+0i),y)-b
                 [,1]         [,2]
[1,] -5.551115e-17+0i 0.2509164+0i
[2,]  1.110223e-16+0i 0.1846802+0i
[3,]  0.000000e+00+0i 1.0224349+0i
> qr.coeffCS(qr(X+0i),y)-b
                 [,1]            [,2]
[1,] -5.551115e-17+0i 2.775558e-17+0i
[2,]  1.110223e-16+0i 1.110223e-16+0i
[3,]  0.000000e+00+0i 5.551115e-17+0i


--------------050206000203080003040803
Content-Type: text/x-vcard; charset=utf-8;
 name="sims.vcf"
Content-Transfer-Encoding: 7bit
Content-Disposition: attachment;
 filename="sims.vcf"

begin:vcard
fn:Chris Sims
n:Sims;Chris
org:Princeton University;Department of Economics
adr:;;Fisher Hall;Princeton;NJ;08544-1021;USA
email;internet:sims at princeton.edu
tel;work:609 258 4033
tel;fax:609 258 6419
x-mozilla-html:FALSE
url:http://www.princeton.edu/~sims
version:2.1
end:vcard


--------------050206000203080003040803--


From dominik.heier at uni-bielefeld.de  Thu Jan 12 11:27:48 2006
From: dominik.heier at uni-bielefeld.de (Dominik)
Date: Thu, 12 Jan 2006 11:27:48 +0100
Subject: [Rd] naiveBayes.plot does not accept ask=FALSE (needed for use with
	tkrplot)
Message-ID: <43C62F24.1000105@uni-bielefeld.de>

Dear mailing list members,

I am writing a tiny tcltk interface for a few basic classification 
methods which should also include plotting density curves with 
naiveBayes.plot() and tkrplot(). I try to replot the curve using the 
next input variable of the NaiveBayes by clicking a button in the 
tkrplot window. Well, it kind of works but:
Now I want to make R stop asking me to "Hit <Return> to see next plot"
The plot function does not accept the parameter "ask=FALSE". Warning: 
parameter "ask" could not be set in high-level plot() function.
If I precede par(ask=FALSE), nothing changes. Well, I am really not 
shure wether I use "par()" correctly. (please see function plotfun() 
below) What do I have to do to run R completley in batch-mode?

thank you in advance
any hint would be greatly appreciated

Dominik Heier
--------------------------------------------------------
#my codelooks like this:

require(tcltk)
require(tkrplot)
require(klaR)
doBayes<-function() {
    ## selected by former widget . For instance:
    DATA<-as.data.frame(iris)
    Output_var="Species"
    ##
    AnzahlZeilen<-nrow(DATA)
    form<-as.formula(paste(Output_var,"~."))
   
    bays<-NaiveBayes(form,data=DATA,usekernel=TRUE)
  
    bbb<-tktoplevel()
    tkwm.title(bbb,"Bayes-Plot")
    inVars<-names(DATA)[names(DATA)!=Output_var]

    varcount<-1

    plotfun<-function() {
        #par(ask=FALSE)
        plot(bays,inVars[varcount],legendplot = TRUE,ask=FALSE)
        ## I tried to set ask=FALSE but got following warning:
        ## parameter "ask" could not be set in high-level plot() function
    }
    bplot<-tkrplot(bbb,plotfun)
   
    plotNextVariable <- function() {
        if (varcount==length(inVars)) {
            varcount<<-1
        } else {
            varcount<<-(varcount+1)
        }
        tkrreplot(bplot,function() plot(bays,inVars[varcount],legendplot 
= TRUE))
    }
    next.but <- tkbutton(bbb,text="Next input 
variable",command=plotNextVariable)
    tkpack(bplot,next.but)
}
doBayes()


From wb at arb-phys.uni-dortmund.de  Thu Jan 12 11:50:56 2006
From: wb at arb-phys.uni-dortmund.de (wb@arb-phys.uni-dortmund.de)
Date: Thu, 12 Jan 2006 11:50:56 +0100 (CET)
Subject: [Rd] strange lme errors (PR#8477)
Message-ID: <20060112105056.3894920755@slim.kubism.ku.dk>

Full_Name: Wilhelm Bernhard Kloke
Version: R-2.2.1
OS: FreeBSD-5.3-i386
Submission from: (NULL) (195.253.22.63)


Since 2.2.0 I am getting strange lme errors like

> lme(ampl ~ gapf * bl,hframe2,~1|VP)
Fehler in lme.formula(ampl ~ gapf * bl, hframe2, ~1 | VP) : 
        See PORT documentation.  Code (27)

I have no clue how to understand this. The specification worked well until
2.1.0.
I tried a second dataset with the same error message.

At least the said "PORT documentation" should be included in the R distribution,
just in case.


From A.Robinson at ms.unimelb.edu.au  Thu Jan 12 12:59:35 2006
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Thu, 12 Jan 2006 22:59:35 +1100
Subject: [Rd] strange lme errors (PR#8477)
In-Reply-To: <20060112105056.3894920755@slim.kubism.ku.dk>
References: <20060112105056.3894920755@slim.kubism.ku.dk>
Message-ID: <20060112115935.GY75255@ms.unimelb.edu.au>

I have seen this error before. I think that you need to upgrade gcc.
See

http://tolstoy.newcastle.edu.au/R/help/05/08/10820.html

I hope that this helps.

Andrew

On Thu, Jan 12, 2006 at 11:50:56AM +0100, wb at arb-phys.uni-dortmund.de wrote:
> Full_Name: Wilhelm Bernhard Kloke
> Version: R-2.2.1
> OS: FreeBSD-5.3-i386
> Submission from: (NULL) (195.253.22.63)
> 
> 
> Since 2.2.0 I am getting strange lme errors like
> 
> > lme(ampl ~ gapf * bl,hframe2,~1|VP)
> Fehler in lme.formula(ampl ~ gapf * bl, hframe2, ~1 | VP) : 
>         See PORT documentation.  Code (27)
> 
> I have no clue how to understand this. The specification worked well until
> 2.1.0.
> I tried a second dataset with the same error message.
> 
> At least the said "PORT documentation" should be included in the R distribution,
> just in case.
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Andrew Robinson  
Department of Mathematics and Statistics            Tel: +61-3-8344-9763
University of Melbourne, VIC 3010 Australia         Fax: +61-3-8344-4599
Email: a.robinson at ms.unimelb.edu.au         http://www.ms.unimelb.edu.au


From jason at cs.jhu.edu  Thu Jan 12 14:27:17 2006
From: jason at cs.jhu.edu (Jason Eisner)
Date: Thu, 12 Jan 2006 08:27:17 -0500
Subject: [Rd] problem with replicate and "..." (PR#8472)
In-Reply-To: <x2psmylu3s.fsf@viggo.kubism.ku.dk>
	(Peter Dalgaard's message of "11 Jan 2006 15:25:27 +0100")
References: <20060111114308.0FF342073F@slim.kubism.ku.dk>
	<x2psmylu3s.fsf@viggo.kubism.ku.dk>
Message-ID: <m3bqyh60ga.fsf@tree.cs.jhu.edu>

Yesterday morning, Peter Dalgaard wrote:

> jason at cs.jhu.edu writes:
>
>> I am using R version 2.0.0 (2004-10-04) on Fedora Core 2.
>> 
>> This works correctly:
>> 
>> > foo <- function(x=1,y=2) { c(x,y) }
>> > bar <- function(n,...) c(n,foo(...))
>> > bar(10,3)
>> [1] 10  3  2
>> 
>> But it goes wrong if I replace "c" in bar with "replicate":
>> 
>> > foo <- function(x=1,y=2) { c(x,y) }
>> > bar <- function(n,...) replicate(n,foo(...))
>> > bar(10,3)
>>      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]
>> [1,]    0    0    0    0    0    0    0    0    0     0
>> [2,]    2    2    2    2    2    2    2    2    2     2
>> 
>> It is mysterious why x was bound to the apparently arbitrary
>> value 0 while y was left at its default.
>> 
>> The ... arguments to bar seems to be ignored altogether.
>> bar(10), bar(10,x=3), and bar(10,3,4) give the same result.
>> Furthermore, bar(10,extra=3) does not give an error.
>> 
>> Perhaps this mysterious behavior is unavoidable because of 
>> the kind of hack replicate is?
>
> Yes. It is really a wrapper for
>
> sapply(integer(n), eval.parent(substitute(function(...) expr))
>
> Now, integer(n) is n zeroes, and the function that is passed to sapply
> is
>
> Browse[1]> FUN
> function (...)
> foo(...)
> <environment: 0xd82338>
>
> Now, this gets called as FUN(0) and in turn foo(0) which is c(0,2).
>
> So, the short answer is "don't do that", and the long answer is "don't
> do that". If you're adventurous, you could try experimenting with a
> different definition, possibly
>
> sapply(integer(n), eval.parent(substitute(function(...) eval.parent(expr)))
>
> but I'm far from sure that it works...

Peter: thanks for the good explanation.

Perhaps the OFFICIAL replicate function can be fixed as you suggest
above, or by somehow incorporating this workaround:

   bar <- function(n,...) { f <- function() foo(...); 
                            replicate(n,f()) }


If not, then may I suggest that help("replicate") should document the
limitation, and perhaps the workaround as well?  

(The help page does mention that replicate is just a convenience
wrapper, but without a BUGS or LIMITATIONS section as on Unix
manpages, a user might be forgiven for assuming that it actually works
in all cases.  Obviously, a user shouldn't have to understand how a
function is implemented in order to avoid nasty special cases.)

Thanks!  -jason


From martyn.plummer at r-project.org  Thu Jan 12 15:12:19 2006
From: martyn.plummer at r-project.org (Martyn Plummer)
Date: Thu, 12 Jan 2006 15:12:19 +0100
Subject: [Rd] R 2.2.2-1 RPM build problem and solution on RH AS 4 x86_64
In-Reply-To: <b3a7efa90601111426p555bb45ag90193daac00f9862@mail.gmail.com>
References: <b3a7efa90601111426p555bb45ag90193daac00f9862@mail.gmail.com>
Message-ID: <1137075139.3047.4.camel@seurat.iarc.fr>

On Wed, 2006-01-11 at 17:26 -0500, Dan Lipsitt wrote:
> I have a dual Xeon x86_64 system running Red Hat AS 4. There are no
> x86_64 rpms in http://cran.us.r-project.org/bin/linux/redhat/el4/ (the
> i386 ones are a point release behind anyway) , and the fc4 rpms have a
> whole web of dependencies I don't want to pull in. So I decided to
> build http://cran.us.r-project.org/bin/linux/redhat/SRPMS/R-2.2.1-1.fc3.src.rpm
> .
> 
> When I ran rpmbuild. one of the make-check tests failed.
> 
> from /BUILD/R-2.2.1/tests/p-r-random-tests.Rout.fail:
> > dkwtest("weibull",shape = 1)
> weibull(shape = 1) FAILED
> Error in dkwtest("weibull", shape = 1) : dkwtest failed
> Execution halted
> 
> I was able to build the rpm after removing "--enable-r-shlib" from the
> spec file.
> 
> http://cran.us.r-project.org/bin/linux/redhat/SRPMS/ReadMe says:
> "The new SRPM for R 2.1.1 builds the shared library version of R. This is,
> unfortunately, slower than the version without the shared library."
> 
> It doesn't say why, if it's slower, it builds it that way. Can anyone
> shed some light on the subject?

Well, I did it because people were asking for it. You need the shared
library to use embedded R or use a GUI. I considered that most people
using R on the command line would pay the speed penalty (or not notice)
and that people who really need the speed could always compile their
own. The penalty is not so bad (~10%) on x86_64 anyway.

Martyn



-----------------------------------------------------------------------
This message and its attachments are strictly confidential. ...{{dropped}}


From ripley at stats.ox.ac.uk  Thu Jan 12 15:14:11 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 12 Jan 2006 14:14:11 +0000 (GMT)
Subject: [Rd] strange lme errors (PR#8477)
In-Reply-To: <20060112105056.3894920755@slim.kubism.ku.dk>
References: <20060112105056.3894920755@slim.kubism.ku.dk>
Message-ID: <Pine.LNX.4.61.0601121301150.16533@gannet.stats>

lme is not part of R, but of the contributed package nlme.  So if you 
thought this is an lme error, you reported it in the wrong place.  See the 
BUGS section in the FAQ.

On Thu, 12 Jan 2006 wb at arb-phys.uni-dortmund.de wrote:

> Full_Name: Wilhelm Bernhard Kloke
> Version: R-2.2.1
> OS: FreeBSD-5.3-i386
> Submission from: (NULL) (195.253.22.63)
>
>
> Since 2.2.0 I am getting strange lme errors like
>
>> lme(ampl ~ gapf * bl,hframe2,~1|VP)
> Fehler in lme.formula(ampl ~ gapf * bl, hframe2, ~1 | VP) :
>        See PORT documentation.  Code (27)
>
> I have no clue how to understand this. The specification worked well until
> 2.1.0.
> I tried a second dataset with the same error message.

Try traceback().  It will probably tell you the message comes from nlminb, 
in which case try ?nlminb.  The problem here is the change in lme from 
optim to nlminb which seems to have broken many examples.

Searching for that message would have lead you to suggestions that it 
comes from a bug in your compiler.  RSiteSearch() lead me to

http://finzi.psych.upenn.edu/R/Rhelp02a/archive/60118.html

And googling showed that your OS has gcc 3.4.2 with its broken Fortran 
compiler.  So it seems this is not a bug in lme nor in R but in your OS.

> At least the said "PORT documentation" should be included in the R 
> distribution, just in case.

The reference is!  More specifically the URL given points you to
http://netlib.bell-labs.com/cm/cs/cstr/153.pdf
section 3.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From atp at piskorski.com  Thu Jan 12 16:39:35 2006
From: atp at piskorski.com (Andrew Piskorski)
Date: Thu, 12 Jan 2006 10:39:35 -0500
Subject: [Rd] natural sorting
In-Reply-To: <971536df0601111445w10b5dce2se8e52e962ccfd1e5@mail.gmail.com>
References: <971536df0601111445w10b5dce2se8e52e962ccfd1e5@mail.gmail.com>
Message-ID: <20060112153934.GB79318@tehun.pair.com>

On Wed, Jan 11, 2006 at 05:45:10PM -0500, Gabor Grothendieck wrote:
> It would be nifty to incorporate this into R or into an R package:
> 
> http://sourcefrog.net/projects/natsort/

Btw, I haven't looked at the implementation, but Tcl also contains
equivalent functionality, they call it dictionary sort:

  http://tcl.activestate.com/man/tcl8.4/TclCmd/lsort.htm

-- 
Andrew Piskorski <atp at piskorski.com>
http://www.piskorski.com/


From francoisromain at free.fr  Thu Jan 12 16:46:14 2006
From: francoisromain at free.fr (Romain Francois)
Date: Thu, 12 Jan 2006 16:46:14 +0100
Subject: [Rd] hello World problem
Message-ID: <43C679C6.7050709@free.fr>

Hi,

I'm trying to build a simple R package 'helloWorld' with just one 
function that prints 'hello World' on the C side.
I agree that it is completely useless, but I just start mixing R and C.

My C file is as follows :

#include <stdio.h>
void helloWorld() {
  printf("hello world !\n") ;
}

When I call it from R, here is what happens :
R> .C("helloWorld", PACKAGE = "helloWorld")
hello world !
list()

is it normal that 'list()' is printed ?

Thanks.

Romain

-- 
visit the R Graph Gallery : http://addictedtor.free.fr/graphiques
mixmod 1.7 is released : http://www-math.univ-fcomte.fr/mixmod/index.php
+---------------------------------------------------------------+
| Romain FRANCOIS - http://francoisromain.free.fr               |
| Doctorant INRIA Futurs / EDF                                  |
+---------------------------------------------------------------+


From sims at Princeton.EDU  Thu Jan 12 16:45:20 2006
From: sims at Princeton.EDU (sims@Princeton.EDU)
Date: Thu, 12 Jan 2006 16:45:20 +0100 (CET)
Subject: [Rd] follow-up on qr.coef bug (PR#8478)
Message-ID: <20060112154520.EA32720799@slim.kubism.ku.dk>

This is a multi-part message in MIME format.
--------------090308090600080800090200
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit

The bug I submitted yesterday (It's not entered in the bug data base, so 
I have no ID for it) included a suggested fix that
is not correct.  It worked for the examples I gave because there was no 
pivoting in fact, or only pivot permutations that were
idempotent.   A correction that works in general on the examples I gave 
makes these two changes in qr.coef():

        ## coef[qr$pivot, ] <- .Call("qr_coef_cmplx", qr, y, PACKAGE = 
"base")[1:p]
        coef[qr$pivot,] <- .Call("qr_coef_cmplx", qr, y, PACKAGE = 
"base")[1:p,]

        ##coef[qr$pivot,] <- .Call("qr_coef_real", qr, y, PACKAGE = 
"base")[1:p]
        coef[qr$pivot,] <- .Call("qr_coef_real", qr, y, PACKAGE = 
"base")[1:p,]

I'm not sure why the [1:p,] on the right is needed.  For my examples, it 
works without this extraction operation, but maybe there is some case in 
which the output of qr_coef_real or qr_coef_cmplx could have more than p 
rows.



--------------090308090600080800090200
Content-Type: text/x-vcard; charset=utf-8;
 name="sims.vcf"
Content-Transfer-Encoding: 7bit
Content-Disposition: attachment;
 filename="sims.vcf"

begin:vcard
fn:Chris Sims
n:Sims;Chris
org:Princeton University;Department of Economics
adr:;;Fisher Hall;Princeton;NJ;08544-1021;USA
email;internet:sims at princeton.edu
tel;work:609 258 4033
tel;fax:609 258 6419
x-mozilla-html:FALSE
url:http://www.princeton.edu/~sims
version:2.1
end:vcard


--------------090308090600080800090200--


From andy_liaw at merck.com  Thu Jan 12 16:49:34 2006
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 12 Jan 2006 10:49:34 -0500
Subject: [Rd] hello World problem
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED6F2@usctmx1106.merck.com>

See the `Value' section of ?.C.  Also, it's better to use the i/o provided
by the R API; i.e., something like:

#include "R.h"
void helloworld() {
    Rprintf("Hello world!\n");
}

Andy



From: Romain Francois
> 
> Hi,
> 
> I'm trying to build a simple R package 'helloWorld' with just one 
> function that prints 'hello World' on the C side.
> I agree that it is completely useless, but I just start 
> mixing R and C.
> 
> My C file is as follows :
> 
> #include <stdio.h>
> void helloWorld() {
>   printf("hello world !\n") ;
> }
> 
> When I call it from R, here is what happens :
> R> .C("helloWorld", PACKAGE = "helloWorld")
> hello world !
> list()
> 
> is it normal that 'list()' is printed ?
> 
> Thanks.
> 
> Romain
> 
> -- 
> visit the R Graph Gallery : http://addictedtor.free.fr/graphiques
> mixmod 1.7 is released : 
> http://www-math.univ-> fcomte.fr/mixmod/index.php
> 
> 
> +---------------------------------------------------------------+
> | Romain FRANCOIS - http://francoisromain.free.fr               |
> | Doctorant INRIA Futurs / EDF                                  |
> +---------------------------------------------------------------+
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
>


From ripley at stats.ox.ac.uk  Thu Jan 12 16:50:39 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 12 Jan 2006 15:50:39 +0000 (GMT)
Subject: [Rd] hello World problem
In-Reply-To: <43C679C6.7050709@free.fr>
References: <43C679C6.7050709@free.fr>
Message-ID: <Pine.LNX.4.61.0601121549040.436@gannet.stats>

On Thu, 12 Jan 2006, Romain Francois wrote:

> Hi,
>
> I'm trying to build a simple R package 'helloWorld' with just one
> function that prints 'hello World' on the C side.
> I agree that it is completely useless, but I just start mixing R and C.
>
> My C file is as follows :
>
> #include <stdio.h>
> void helloWorld() {
>  printf("hello world !\n") ;
> }
>
> When I call it from R, here is what happens :
> R> .C("helloWorld", PACKAGE = "helloWorld")
> hello world !
> list()
>
> is it normal that 'list()' is printed ?

Yes.  That is the return value of .C().  (It is not normal to call .C() at 
the toplevel, rather as part of a function.)  The value section of the 
help page says

      The functions '.C' and '.Fortran' return a list similar to the
      '...' list of arguments passed in, but reflecting any changes made
      by the C or Fortran code.

You have no ... args, so get an empty list.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From murdoch at stats.uwo.ca  Thu Jan 12 16:52:03 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 12 Jan 2006 10:52:03 -0500
Subject: [Rd] hello World problem
In-Reply-To: <43C679C6.7050709@free.fr>
References: <43C679C6.7050709@free.fr>
Message-ID: <43C67B23.3000705@stats.uwo.ca>

On 1/12/2006 10:46 AM, Romain Francois wrote:
> Hi,
> 
> I'm trying to build a simple R package 'helloWorld' with just one 
> function that prints 'hello World' on the C side.
> I agree that it is completely useless, but I just start mixing R and C.
> 
> My C file is as follows :
> 
> #include <stdio.h>
> void helloWorld() {
>   printf("hello world !\n") ;
> }
> 
> When I call it from R, here is what happens :
> R> .C("helloWorld", PACKAGE = "helloWorld")
> hello world !
> list()
> 
> is it normal that 'list()' is printed ?

Yes, because that is the return value from .C.  If you don't want to 
print it, you could call

invisible(.C( ... ))

or, more likely, you'd embed this call in a function that produced its 
own return value after calling .C().

By the way, you should call Rprintf() rather than printf(), if you want 
your function to work in environments like Windows Rgui.  See the 
Writing R Extensions manual for the details.

Duncan Murdoch


From ripley at stats.ox.ac.uk  Thu Jan 12 17:21:38 2006
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Thu, 12 Jan 2006 17:21:38 +0100 (CET)
Subject: [Rd] follow-up on qr.coef bug (PR#8478)
Message-ID: <20060112162138.8E4572079A@slim.kubism.ku.dk>

It certainly _was_ there, in incoming as PR#8476, and also in the R-devel 
archives.

BTW, you have not given the minimal information required, e.g. the R 
version.  The pivot logic _is_ correct (your patch was broken), but there 
was a problem with multiple RHSs, now fixed.


On Thu, 12 Jan 2006 sims at princeton.edu wrote:

> This is a multi-part message in MIME format.
> --------------090308090600080800090200
> Content-Type: text/plain; charset=ISO-8859-1; format=flowed
> Content-Transfer-Encoding: 7bit
>
> The bug I submitted yesterday (It's not entered in the bug data base, so
> I have no ID for it) included a suggested fix that
> is not correct.  It worked for the examples I gave because there was no
> pivoting in fact, or only pivot permutations that were
> idempotent.   A correction that works in general on the examples I gave
> makes these two changes in qr.coef():
>
>        ## coef[qr$pivot, ] <- .Call("qr_coef_cmplx", qr, y, PACKAGE =
> "base")[1:p]
>        coef[qr$pivot,] <- .Call("qr_coef_cmplx", qr, y, PACKAGE =
> "base")[1:p,]
>
>        ##coef[qr$pivot,] <- .Call("qr_coef_real", qr, y, PACKAGE =
> "base")[1:p]
>        coef[qr$pivot,] <- .Call("qr_coef_real", qr, y, PACKAGE =
> "base")[1:p,]
>
> I'm not sure why the [1:p,] on the right is needed.  For my examples, it
> works without this extraction operation, but maybe there is some case in
> which the output of qr_coef_real or qr_coef_cmplx could have more than p
> rows.

Read the C code: B is a copy of Bin (y) and so no, it cannot happen any 
more (it could in an earlier version).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From dsamperi at DecisionSynergy.com  Thu Jan 12 17:40:07 2006
From: dsamperi at DecisionSynergy.com (Dominick Samperi)
Date: Thu, 12 Jan 2006 11:40:07 -0500
Subject: [Rd] Rcpp 1.1: R/C++ interface class library update
Message-ID: <43C68667.7030801@DecisionSynergy.com>

Hello,

Based on feedback from this list I have updated the Rcpp R/C++ interface
class library and uploaded the new version to CRAN.

Just as the .C
interface can be viewed as a C programmer-friendly version of the
more demanding .Call interface, Rcpp essentially provides a
C++ programmer-friendly version of the .Call interface, with
automatic type checking and error reporting via a try/catch
protocol. Rcpp also eliminates the need to work with the
low-level SEXP macros.

The API documentation is in RHOME/library/Rcpp/doc/RcppAPI.pdf.

If there is interest in providing a supported C++ API for R, then
Rcpp might be a useful starting point.

The RQuantLib package has also been updated to use the new
version of Rcpp.

Dominick


From Robert.McGehee at geodecapital.com  Thu Jan 12 21:34:37 2006
From: Robert.McGehee at geodecapital.com (McGehee, Robert)
Date: Thu, 12 Jan 2006 15:34:37 -0500
Subject: [Rd] .leap.seconds
Message-ID: <67DCA285A2D7754280D3B8E88EB548020C94674E@MSGBOSCLB2WIN.DMN1.FMR.COM>

I glanced at the .leap.seconds object and noticed that it has not been
updated for the most recent leap second that occurred 2005 December 31,
23h 59m 60s. See the IERS bulletin here:
http://hpiers.obspm.fr/iers/bul/bulc/bulletinc.dat

Moreover, after a more careful glance at the .leap.seconds object, I
noticed that there are two incorrect entries. First, there was not a
leap second on 1986 June 30, and second there was a leap second that was
omitted on 1982 June 30.

For a list of past offsets see this IERS table:
http://www.iers.org/MainDisp.csl?pid=95-106

Best, 
Robert

> version
platform i686-pc-linux-gnu
arch     i686             
os       linux-gnu        
system   i686, linux-gnu  
status   Patched          
major    2                
minor    2.1              
year     2006             
month    01               
day      07               
svn rev  37024            
language R                

Robert McGehee
Quantitative Analyst
Geode Capital Management, LLC
53 State Street, 5th Floor | Boston, MA | 02109
Tel: 617/392-8396    Fax:617/476-6389
mailto:robert.mcgehee at geodecapital.com



This e-mail, and any attachments hereto, are intended for us...{{dropped}}


From Augusto.Sanabria at ga.gov.au  Fri Jan 13 01:02:12 2006
From: Augusto.Sanabria at ga.gov.au (Augusto.Sanabria@ga.gov.au)
Date: Fri, 13 Jan 2006 11:02:12 +1100
Subject: [Rd] Saving a plot in R-LINUX
Message-ID: <9707EBA615A57747A0668CECD4638A3009BBA8@mail.agso.gov.au>


Good day,

Is there any way to save a plot produced by
R in a LINUX (Debian) machine?

The window opened by R to put the plot in,
does not give any option to save it (there
are options to move, close, minimise it, etc.
but not to save it). How do you do that?

Thanks,

Augusto



--------------------------------------------
Augusto Sanabria. MSc, PhD.
Mathematical Modeller
Risk Research Group
Geospatial & Earth Monitoring Division
Geoscience Australia (www.ga.gov.au)
Cnr. Jerrabomberra Av. & Hindmarsh Dr.
Symonston ACT 2609
Ph. (02) 6249-9155


From edd at debian.org  Fri Jan 13 02:02:42 2006
From: edd at debian.org (Dirk Eddelbuettel)
Date: Thu, 12 Jan 2006 19:02:42 -0600
Subject: [Rd] Saving a plot in R-LINUX
In-Reply-To: <9707EBA615A57747A0668CECD4638A3009BBA8@mail.agso.gov.au>
References: <9707EBA615A57747A0668CECD4638A3009BBA8@mail.agso.gov.au>
Message-ID: <17350.64562.286742.136147@basebud.nulle.part>


On 13 January 2006 at 11:02, Augusto.Sanabria at ga.gov.au wrote:
| Is there any way to save a plot produced by
| R in a LINUX (Debian) machine?

It is the same on every platform and ...

| The window opened by R to put the plot in,
| does not give any option to save it (there
| are options to move, close, minimise it, etc.
| but not to save it). How do you do that?

... explained in section 12.6 of the fine 'R Introduction' manual available
in Debian in each one of the packages

	r-doc-info
	r-doc-html
	r-doc-pdf

for your choice of format to read.

Short form:

> pdf("/tmp/foo.pdf")
> plot(x, y)
> dev.off()

Don't forget the dev.off(). And do read the manual, section 12.6, also on the
web at eg http://cran.r-project.org/doc/manuals/R-intro.html#Graphics

Dirk

-- 
Hell, there are no rules here - we're trying to accomplish something. 
                                                  -- Thomas A. Edison


From Augusto.Sanabria at ga.gov.au  Fri Jan 13 03:03:27 2006
From: Augusto.Sanabria at ga.gov.au (Augusto.Sanabria@ga.gov.au)
Date: Fri, 13 Jan 2006 13:03:27 +1100
Subject: [Rd] Saving a plot from R-LINUX(2)
Message-ID: <9707EBA615A57747A0668CECD4638A3009BBA9@mail.agso.gov.au>

Dirk,

Thanks a lot for taking the time to reply.

Please have a look at my comments below:


On 13 January 2006 at 11:02, Augusto.Sanabria at ga.gov.au wrote:
| Is there any way to save a plot produced by
| R in a LINUX (Debian) machine?

(Dirk)It is the same on every platform and ...

(Augusto) No, I can see an option to save my plot from  the plot window
in MS Windows. That option does not exist in the LINUX window,
does it? (maybe there is something wrong with my LINUX config.)

say, I have an arbitrary set of data x,y (not a pdf).
I can plot the data using plot(x,y) and I can see the plot
in a plot window in LINUX.

The problem is: how can I save that plot into an external
file? I expect to find a command like:

save_a_displayed_plot("myplot1","jpeg","/mnt/store")

Then, I expect to find the file myplot1.jpeg in "store".

I have read the documentation, sect. 1.6, and found no reference
to this problem.

Again, thank you for your reply.

Augusto


From ripley at stats.ox.ac.uk  Fri Jan 13 03:10:01 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 13 Jan 2006 02:10:01 +0000 (GMT)
Subject: [Rd] Saving a plot in R-LINUX
In-Reply-To: <17350.64562.286742.136147@basebud.nulle.part>
References: <9707EBA615A57747A0668CECD4638A3009BBA8@mail.agso.gov.au>
	<17350.64562.286742.136147@basebud.nulle.part>
Message-ID: <Pine.LNX.4.61.0601130146310.6845@gannet.stats>

That does not save the current plot though, and dev.copy() and 
dev.print() can do so.  They _are_ in the manual Dirk pointed you at.

Windows versions of R have other options, e.g. savePlot() and menu items 
to save the plot, and my guess is that is what 
'Augusto.Sanabria at ga.gov.au' has seen.

I don't see what this has to do with this list rather than R-help, though.

On Thu, 12 Jan 2006, Dirk Eddelbuettel wrote:

>
> On 13 January 2006 at 11:02, Augusto.Sanabria at ga.gov.au wrote:
> | Is there any way to save a plot produced by
> | R in a LINUX (Debian) machine?
>
> It is the same on every platform and ...
>
> | The window opened by R to put the plot in,
> | does not give any option to save it (there
> | are options to move, close, minimise it, etc.

Those `options' are from your X11 Window Manager, not from R.

> | but not to save it). How do you do that?
>
> ... explained in section 12.6 of the fine 'R Introduction' manual available
> in Debian in each one of the packages
>
> 	r-doc-info
> 	r-doc-html
> 	r-doc-pdf
>
> for your choice of format to read.
>
> Short form:
>
>> pdf("/tmp/foo.pdf")
>> plot(x, y)
>> dev.off()
>
> Don't forget the dev.off(). And do read the manual, section 12.6, also on the
> web at eg http://cran.r-project.org/doc/manuals/R-intro.html#Graphics
>
> Dirk
>
> -- 
> Hell, there are no rules here - we're trying to accomplish something.
>                                                  -- Thomas A. Edison
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Fri Jan 13 03:15:28 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 13 Jan 2006 02:15:28 +0000 (GMT)
Subject: [Rd] Saving a plot from R-LINUX(2)
In-Reply-To: <9707EBA615A57747A0668CECD4638A3009BBA9@mail.agso.gov.au>
References: <9707EBA615A57747A0668CECD4638A3009BBA9@mail.agso.gov.au>
Message-ID: <Pine.LNX.4.61.0601130215190.6845@gannet.stats>

For jpeg see ?dev2bitmap as well as my earlier reply.

On Fri, 13 Jan 2006 Augusto.Sanabria at ga.gov.au wrote:

> Dirk,
>
> Thanks a lot for taking the time to reply.
>
> Please have a look at my comments below:
>
>
> On 13 January 2006 at 11:02, Augusto.Sanabria at ga.gov.au wrote:
> | Is there any way to save a plot produced by
> | R in a LINUX (Debian) machine?
>
> (Dirk)It is the same on every platform and ...
>
> (Augusto) No, I can see an option to save my plot from  the plot window
> in MS Windows. That option does not exist in the LINUX window,
> does it? (maybe there is something wrong with my LINUX config.)
>
> say, I have an arbitrary set of data x,y (not a pdf).
> I can plot the data using plot(x,y) and I can see the plot
> in a plot window in LINUX.
>
> The problem is: how can I save that plot into an external
> file? I expect to find a command like:
>
> save_a_displayed_plot("myplot1","jpeg","/mnt/store")
>
> Then, I expect to find the file myplot1.jpeg in "store".
>
> I have read the documentation, sect. 1.6, and found no reference
> to this problem.
>
> Again, thank you for your reply.
>
> Augusto
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Fri Jan 13 04:26:43 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 13 Jan 2006 03:26:43 +0000 (GMT)
Subject: [Rd] .leap.seconds
In-Reply-To: <67DCA285A2D7754280D3B8E88EB548020C94674E@MSGBOSCLB2WIN.DMN1.FMR.COM>
References: <67DCA285A2D7754280D3B8E88EB548020C94674E@MSGBOSCLB2WIN.DMN1.FMR.COM>
Message-ID: <Pine.LNX.4.61.0601130310001.8120@gannet.stats>

You don't seriously expect R 2.2.1 to know about events after its release 
do you?  And as the new leap second is not a bug, it will not go into a 
patched version.

I have been looking into this for R-devel, but there is a lot more to it. 
We really need consistency with the OS, and as this leap second was not 
even announced until 2005-07-04, probably most R platforms will not know 
about it.  Some systems count leapseconds in their clock time, but most do 
not: see ?DateTimeClasses.  So we need to find out if the OS knows about 
this leap second when we make internal adjustments, and even that is 
tricky as e.g. FC3 as originally shipped does not but the latest patched 
glibc does.  I am not convinced I have a good enough solution as yet.


On Thu, 12 Jan 2006, McGehee, Robert wrote:

> I glanced at the .leap.seconds object and noticed that it has not been
> updated for the most recent leap second that occurred 2005 December 31,
> 23h 59m 60s. See the IERS bulletin here:
> http://hpiers.obspm.fr/iers/bul/bulc/bulletinc.dat
>
> Moreover, after a more careful glance at the .leap.seconds object, I
> noticed that there are two incorrect entries. First, there was not a
> leap second on 1986 June 30, and second there was a leap second that was
> omitted on 1982 June 30.

A (harmless) typo.

> For a list of past offsets see this IERS table:
> http://www.iers.org/MainDisp.csl?pid=95-106
>
> Best,
> Robert
>
>> version
> platform i686-pc-linux-gnu
> arch     i686
> os       linux-gnu
> system   i686, linux-gnu
> status   Patched
> major    2
> minor    2.1
> year     2006
> month    01
> day      07
> svn rev  37024
> language R
>
> Robert McGehee
> Quantitative Analyst
> Geode Capital Management, LLC
> 53 State Street, 5th Floor | Boston, MA | 02109
> Tel: 617/392-8396    Fax:617/476-6389
> mailto:robert.mcgehee at geodecapital.com
>
>
>
> This e-mail, and any attachments hereto, are intended for us...{{dropped}}
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From maechler at stat.math.ethz.ch  Fri Jan 13 12:42:34 2006
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 13 Jan 2006 12:42:34 +0100
Subject: [Rd] [R] "infinite recursion" in do.call when lme4 loaded only
In-Reply-To: <17351.36355.296014.525531@stat.math.ethz.ch>
References: <LPEJLJACLINDNMBMFAFIGEOBCBAA.dieter.menne@menne-biomed.de>
	<x2psmxuzkw.fsf@viggo.kubism.ku.dk>
	<loom.20060112T191150-51@post.gmane.org>
	<17351.36355.296014.525531@stat.math.ethz.ch>
Message-ID: <17351.37418.31624.869070@stat.math.ethz.ch>

>>>>> "MM" == Martin Maechler <maechler at stat.math.ethz.ch>
>>>>>     on Fri, 13 Jan 2006 12:24:51 +0100 writes:

>>>>> "Dieter" == Dieter Menne <dieter.menne at menne-biomed.de>
>>>>>     on Thu, 12 Jan 2006 18:14:32 +0000 (UTC) writes:

    Dieter> Peter Dalgaard <p.dalgaard <at> biostat.ku.dk> writes:
    >>> > A larg program which worked with lme4/R about a year ago failed when I
    >>> > re-run it today. I reproduced the problem with the program below.

    >>> > -- When lme4 is loaded (but never used), the do.call fails
    >>> >    with infinite recursion after 60 seconds. Memory used increases
    >>> >    beyond bonds in task manager.
    >>> 
    >>> However, it surely has to do with methods dispatch:
    >>> 
    >>> > system.time(do.call("rbind.data.frame",caScore))
    >>> [1] 0.99 0.00 0.99 0.00 0.00
    >>> 
    >>> which provides you with another workaround.

    Dieter> Peter, I had increased the optional value already, but I still don't understand 
    Dieter> what this recursion overflow has to do with the lm4 loading.

    MM> Aahh, you've hit a secret ;-)  no, but a semi-hidden feature:
    MM> lme4 loads Matrix and Matrix  activates versions of rbind() and
    MM> cbind() which use rbind2/cbind2 which are S4 generics and
    MM> default methods that are slightly different than then the
    MM> original base rbind() and cbind(). 
    MM> This was a necessity since the original rbind(), cbind() have
    MM> first argument "...", i.e. an invalid signature for S4 method
    MM> dispatch.

    MM> This was in NEWS for R 2.2.0 :

    MM> o	Experimental versions of cbind() and rbind() in methods package,
    MM> based on new generic function cbind2(x,y) and rbind2().	 This will
    MM> allow the equivalent of S4 methods for cbind() and rbind() ---
    MM> currently only after an explicit activation call, see ?cbind2.

    MM> And 'Matrix' uses the activation call in its .OnLoad hook.
    MM> This is now getting much too technical to explain for R-help, so
    MM> if we want to go there, we should move this topic to R-devel,
    MM> and I'd like to do so, and will be glad if you can provide more
    MM> details on how exactly you're using rbind.

One thing -- very useful for you -- I forgot to add:

You can easily quickly revert the  "other cbind/rbind
activation" by using

    methods:::bind_activation(FALSE)

so you don't need to unload lme4 or Matrix,  and you can
reactivate them again after your special computation by

    methods:::bind_activation(on = TRUE)

Martin


From mpiktas at gmail.com  Fri Jan 13 14:09:36 2006
From: mpiktas at gmail.com (Vaidotas Zemlys)
Date: Fri, 13 Jan 2006 15:09:36 +0200
Subject: [Rd] Saving a plot in R-LINUX
In-Reply-To: <17350.64562.286742.136147@basebud.nulle.part>
References: <9707EBA615A57747A0668CECD4638A3009BBA8@mail.agso.gov.au>
	<17350.64562.286742.136147@basebud.nulle.part>
Message-ID: <e47808320601130509mad192b8ye540b35cad0d4b88@mail.gmail.com>

On 1/13/06, Dirk Eddelbuettel <edd at debian.org> wrote:
>
> On 13 January 2006 at 11:02, Augusto.Sanabria at ga.gov.au wrote:
> | Is there any way to save a plot produced by
> | R in a LINUX (Debian) machine?
>
> It is the same on every platform and ...
>
> | The window opened by R to put the plot in,
> | does not give any option to save it (there
> | are options to move, close, minimise it, etc.
> | but not to save it). How do you do that?
>

What about using dev.copy? Or am I missing something? In windows there
is a context menu when you click with the right mouse button, which
lets you choose how do you want to save the plot. On linux I came up
with such function, which albeit not perfectly but does the job:

d2b <- function(file="Rplot%d.bmp",height=4,width=4,res=150,which=dev.cur(),...)
{
    if(which!=dev.cur()) {
        cur <- dev.cur()
        dev.set(which)
    }
    else cur <- NULL

    dev.copy(device=bitmap,file=file,height=height,width=width,point=8,res=res,...)
    dev.off()
    if(!is.null(cur))dev.set(cur)
    else dev.set(which)
}

It copies told device (current by default) to bitmap file. This
function could be easily adapted for copying to other formats.

Since the answer was too easy, probably I did not understand question
correctly. In that case please ignore this message.

Vaidotas Zemlys
--
Doctorate student, http://www.mif.vu.lt/katedros/eka/katedra/zemlys.php
Vilnius University


From acasseb at ufpa.br  Thu Jan 12 21:39:38 2006
From: acasseb at ufpa.br (acasseb@ufpa.br)
Date: Thu, 12 Jan 2006 17:39:38 -0300
Subject: [Rd] Bug by libreadline.so.5
Message-ID: <20060112173938.fr8mark5nos00g4s@correio.ufpa.br>

		 [was sent to R-bugs and caught in "R-bugs-spam"; 
                  manual FWD to R-devel, since it's not a bug in R.  MM ]
Dear friend,

I need same help about "libreadline.so.5". My OS: Conectiva Linux 10 
(Brazilian distribution). The prompt show this messenger:

"/usr/lib/R/bin/exec/R:error while loading shared libraries: 
/lib/libreadline.so.5: undefined symbol : BC"

Please Help! Thanks!





-----------------------------------------------------------
Esta mensagem foi enviada atraves da pagina Correio.UFPA.BR


From ripley at stats.ox.ac.uk  Fri Jan 13 15:23:26 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 13 Jan 2006 14:23:26 +0000 (GMT)
Subject: [Rd] Bug by libreadline.so.5
In-Reply-To: <20060112173938.fr8mark5nos00g4s@correio.ufpa.br>
References: <20060112173938.fr8mark5nos00g4s@correio.ufpa.br>
Message-ID: <Pine.LNX.4.61.0601131419390.19143@gannet.stats>

On Thu, 12 Jan 2006 acasseb at ufpa.br wrote:

> 		 [was sent to R-bugs and caught in "R-bugs-spam";
>                  manual FWD to R-devel, since it's not a bug in R.  MM ]
> Dear friend,
>
> I need same help about "libreadline.so.5". My OS: Conectiva Linux 10
> (Brazilian distribution). The prompt show this messenger:
>
> "/usr/lib/R/bin/exec/R:error while loading shared libraries:
> /lib/libreadline.so.5: undefined symbol : BC"

It's an OS-specific problem: try compiling R from sources on the actual 
machine you are using.  You are probably missing a compatible ncurses 
library (as discussed in the R-admin manual), and we've seen missing 
dependencies in (the closely related) Mandriva before.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From p.dalgaard at biostat.ku.dk  Fri Jan 13 16:17:08 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 13 Jan 2006 16:17:08 +0100
Subject: [Rd] Bug by libreadline.so.5
In-Reply-To: <Pine.LNX.4.61.0601131419390.19143@gannet.stats>
References: <20060112173938.fr8mark5nos00g4s@correio.ufpa.br>
	<Pine.LNX.4.61.0601131419390.19143@gannet.stats>
Message-ID: <x2irso6tu3.fsf@turmalin.kubism.ku.dk>

Prof Brian Ripley <ripley at stats.ox.ac.uk> writes:

> On Thu, 12 Jan 2006 acasseb at ufpa.br wrote:
> 
> > 		 [was sent to R-bugs and caught in "R-bugs-spam";
> >                  manual FWD to R-devel, since it's not a bug in R.  MM ]
> > Dear friend,
> >
> > I need same help about "libreadline.so.5". My OS: Conectiva Linux 10
> > (Brazilian distribution). The prompt show this messenger:
> >
> > "/usr/lib/R/bin/exec/R:error while loading shared libraries:
> > /lib/libreadline.so.5: undefined symbol : BC"
> 
> It's an OS-specific problem: try compiling R from sources on the actual 
> machine you are using.  You are probably missing a compatible ncurses 
> library (as discussed in the R-admin manual), and we've seen missing 
> dependencies in (the closely related) Mandriva before.

I think that something similar got solved just by installing ncurses
on some other Linux distro, so that should probably be the first thing
to try.

Ideally this sort of thing should be handled via RPM dependencies, but
not all packagers are equally good at keeping track of them.

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From rjohnsto at sfu.ca  Sat Jan 14 00:59:22 2006
From: rjohnsto at sfu.ca (Robert W. Johnstone)
Date: Fri, 13 Jan 2006 15:59:22 -0800 (PST)
Subject: [Rd] Palette functions in grDevices
Message-ID: <4070.199.60.7.247.1137196762.squirrel@webmail.fas.sfu.ca>

Hello,

1) I would like to add three function to the file colorstuff.R in the
grDevices package.  These functions would be:

   red.colors <- function(n, start = 0.3, end = 0.9, gamma = 2.2)
   green.colors <- function(n, start = 0.3, end = 0.9, gamma = 2.2)
   blue.colors <- function(n, start = 0.3, end = 0.9, gamma = 2.2)

As you can see, these are simply analogs of the function grey.colors, and
would be useful for image processing code done in R.  This would be a
simple change, with little impact on existing code.

Documentation for the three new functions would be added to gray.colors.Rd.

I could make the necessary changes, and would volunteer to make the
changes, but don't have SVN access.

2) Can someone explain the origin of the naming system for these
functions?  I would have thought function names such as palette.terrain,
palette.gray, palette.heat, etc. would be more obvious to users.

A change such as this would obviously be more intrusive, but could be
easily accomplished over a transition period.  The old function names
could be depreciated, while still pointing to the correct code.

Thank-you,

----------------------------------------
Robert Johnstone
Simon Fraser University
http://www.sfu.ca/~rjohnsto/


From greg.kochanski at phon.ox.ac.uk  Sat Jan 14 17:26:09 2006
From: greg.kochanski at phon.ox.ac.uk (greg.kochanski@phon.ox.ac.uk)
Date: Sat, 14 Jan 2006 17:26:09 +0100 (CET)
Subject: [Rd] help.start() and Debian packaging (PR#8483)
Message-ID: <20060114162609.E69D71A005@slim.kubism.ku.dk>

Full_Name: Greg Kochanski
Version: 2.2.0
OS: Debian Linux on i686
Submission from: (NULL) (212.159.16.190)


Debian packages the R documentation separately from the R core code.
Consequently, it is possible for people to have R without
the HTML documentation.   (In fact, the docs are not installed by default,
so it's very likely.)


Thus, help.start() cannot depend on the HTML documentation being there.
It should check for one (or a few) files and produce some reasonable
error message if it is not there.   Maybe something like
"Warning: the HTML documentation is not installed."

Alternatively, help.start() could produce references to some on-line
HTML documentation, instead of local documentation.



A related bug is that if one calls
help.start()  when the HTML documentation does not exist,
all future calls to help() will lead to errors.


From greg.kochanski at phon.ox.ac.uk  Sat Jan 14 17:33:49 2006
From: greg.kochanski at phon.ox.ac.uk (greg.kochanski@phon.ox.ac.uk)
Date: Sat, 14 Jan 2006 17:33:49 +0100 (CET)
Subject: [Rd] Section 7.1 HML documentation (PR#8484)
Message-ID: <20060114163349.7A9931A001@slim.kubism.ku.dk>

Full_Name: Greg Kochanski
Version: 2.2.0
OS: Debian Linux i686
Submission from: (NULL) (212.159.16.190)


In /usr/share/doc/r-doc-html/manual/R-data.html (at least that's where
it is on Debian...) the documentation is unclear.   Comments below.


The paragraph has unclear references, and I have no idea what
it actually means.

>> Base R comes with some facilities to communicate via BSD sockets on systems
that support them (...). One potential problem....
>> For new projects it is suggested that socket connections are used instead.

"Used instead"?   Instead of what?

>>The earlier low-level interface is given by functions make.socket,
read.socket, write.socket and close.socket. 

What does "earlier" mean?   Earlier than what?


From greg.kochanski at phon.ox.ac.uk  Sat Jan 14 17:45:15 2006
From: greg.kochanski at phon.ox.ac.uk (greg.kochanski@phon.ox.ac.uk)
Date: Sat, 14 Jan 2006 17:45:15 +0100 (CET)
Subject: [Rd] Minor: bad label in "faithful" dataset (PR#8485)
Message-ID: <20060114164515.538FF1A001@slim.kubism.ku.dk>

Full_Name: Greg Kochanski
Version: 2.2.0
OS: Debian Linux i686
Submission from: (NULL) (212.159.16.190)


The data set for "faithful" appears to be (column 1) the duration
of the eruptions, and (column 2) the interval between eruptions.
(See http://stat.ethz.ch/R-manual/R-patched/library/datasets/html/faithful.html).

The label of column 1 is wrong, and should be "eruption duration"
not just "eruptions", which implies a count of eruptions not a duration.


From ripley at stats.ox.ac.uk  Sat Jan 14 19:32:06 2006
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Sat, 14 Jan 2006 19:32:06 +0100 (CET)
Subject: [Rd] help.start() and Debian packaging (PR#8483)
Message-ID: <20060114183206.265CC2070B@slim.kubism.ku.dk>

This is all based on a false premise: that a partial install of Debian
files is 'R'.

R's own scripts do always install the HTML documentation, so help.start() 
is entitled to assume that it is present.  (That is under Unix-alikes: R 
for Windows allows Compiled HTML rather than HTML, and so help.start makes 
appropriate tests).

Note that your version of 'R' is not current.

If there is a bug here, it is in the Debian re-packaging.  I trust the 
Debian packages do contain a bug reporting address other than this one: 
please use the correct one.  (The other binary distributions that I am 
aware of, e.g. RPMs, do seem to include all of R.)

On Sat, 14 Jan 2006 greg.kochanski at phonetics.oxford.ac.uk wrote:

> Full_Name: Greg Kochanski
> Version: 2.2.0
> OS: Debian Linux on i686
> Submission from: (NULL) (212.159.16.190)
>
>
> Debian packages the R documentation separately from the R core code.
> Consequently, it is possible for people to have R without
> the HTML documentation.   (In fact, the docs are not installed by default,
> so it's very likely.)
>
>
> Thus, help.start() cannot depend on the HTML documentation being there.
> It should check for one (or a few) files and produce some reasonable
> error message if it is not there.   Maybe something like
> "Warning: the HTML documentation is not installed."
>
> Alternatively, help.start() could produce references to some on-line
> HTML documentation, instead of local documentation.
>
>
>
> A related bug is that if one calls
> help.start()  when the HTML documentation does not exist,
> all future calls to help() will lead to errors.

Working as documented is not a bug.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From taccioli.1 at osu.edu  Sun Jan 15 23:00:48 2006
From: taccioli.1 at osu.edu (taccioli.1@osu.edu)
Date: Sun, 15 Jan 2006 23:00:48 +0100 (CET)
Subject: [Rd] Linux proxy problem (PR#8487)
Message-ID: <20060115220048.69BA81E5F8@slim.kubism.ku.dk>

Full_Name: cristian taccioli
Version: 2.2.1
OS: Linux Debian
Submission from: (NULL) (140.254.45.199)


Dear R staff
I'm a osu Ph.D.
I have a problem with Linux.
I usually start R on Windows OS by dos shell:      
c:\Program Files\R\R-2.2.1\bin\Rgui.exe --internet2
With no script --internet2 i can't connect to
bioconductor to download bioconductor packages.
A real problem is that I can't do this with Linux:    R --internet2   command
doesn't work.
My system administrator doesn't know Linux.
Can you help me?
Regards
Cristian


From taccioli.1 at osu.edu  Sun Jan 15 23:03:39 2006
From: taccioli.1 at osu.edu (taccioli.1@osu.edu)
Date: Sun, 15 Jan 2006 23:03:39 +0100 (CET)
Subject: [Rd] Linux and proxy problem (PR#8488)
Message-ID: <20060115220339.253901E5F8@slim.kubism.ku.dk>

Dear R staff
I'm a osu Ph.D.
I have a problem with Linux.
I usually start R on Windows OS by dos shell:      
c:\Program Files\R\R-2.2.1\bin\Rgui.exe --internet2
With no script --internet2 i can't connect to
bioconductor to download bioconductor packages.
A real problem is that I can't do this with Linux:    R --internet2   command doesn't work.
My system administrator doesn't know Linux.
Can you help me?
Regards
Cristian


From jh910 at juno.com  Mon Jan 16 00:02:21 2006
From: jh910 at juno.com (J. Hosking)
Date: Sun, 15 Jan 2006 18:02:21 -0500
Subject: [Rd] tempdir() in R-2.2.1 under Windows
Message-ID: <dqek9t$24m$1@sea.gmane.org>

The documentation for tempdir() and tempfile() on R-2.2.1 for Windows
says that "Both will use backslash as the path separator", but in
practice I see a forward slash:

  > tempdir()
  [1] "C:\\DOCUME~1\\ADMINI~1\\LOCALS~1\\Temp/RtmpGqB7ob"
  > tempfile()
  [1] "C:\\DOCUME~1\\ADMINI~1\\LOCALS~1\\Temp/RtmpGqB7ob\\file6df11649"

This causes problems when the string is passed as a parameter to a
Windows program that accepts only backslash as a path separator.
For example, fix() appears to pass the tempfile() string to the
editor program and my preferred editor (KEDIT) does not accept it:
I get an error message "Invalid fileid" from KEDIT and a warning from
fix() "Warning message: editor ran but returned error status in:
edit(name, file, title, editor)".  I can work around this with
fix(object,file=normalizePath(tempfile())), but I would rather have
tempfile() return a normalized path in the first place.

 > R.version
          _
platform i386-pc-mingw32
arch     i386
os       mingw32
system   i386, mingw32
status
major    2
minor    2.1
year     2005
month    12
day      20
svn rev  36812
language R


J. R. M. Hosking


From khansen at stat.Berkeley.EDU  Mon Jan 16 02:44:15 2006
From: khansen at stat.Berkeley.EDU (Kasper Daniel Hansen)
Date: Sun, 15 Jan 2006 17:44:15 -0800
Subject: [Rd] Linux and proxy problem (PR#8488)
In-Reply-To: <20060115220339.253901E5F8@slim.kubism.ku.dk>
References: <20060115220339.253901E5F8@slim.kubism.ku.dk>
Message-ID: <D08318DD-85CF-4690-8C6D-B57A51A03923@stat.berkeley.edu>

Christian

1. This is not a bug, please read the posting rules.
2. You have submitted two bug reports

This means a member of R-core has to spend valuable time cleaning up  
after you. Behavior like this is not going to help you getting an  
answer.

Nevertheless, I will try: you are probably behind a firewall. Your  
system administrator needs to allow R to access the internet. This  
has nothing to do with R and everything to do with how your network  
is configured. This is something your system administrator should be  
able to help you with. Can you access the internet at all from your  
linux box?

/Kasper




On Jan 15, 2006, at 2:03 PM, taccioli.1 at osu.edu wrote:

> Dear R staff
> I'm a osu Ph.D.
> I have a problem with Linux.
> I usually start R on Windows OS by dos shell:
> c:\Program Files\R\R-2.2.1\bin\Rgui.exe --internet2
> With no script --internet2 i can't connect to
> bioconductor to download bioconductor packages.
> A real problem is that I can't do this with Linux:    R -- 
> internet2   command doesn't work.
> My system administrator doesn't know Linux.
> Can you help me?
> Regards
> Cristian
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From Augusto.Sanabria at ga.gov.au  Mon Jan 16 04:10:38 2006
From: Augusto.Sanabria at ga.gov.au (Augusto.Sanabria@ga.gov.au)
Date: Mon, 16 Jan 2006 14:10:38 +1100
Subject: [Rd] Saving a plot in R-LINUX
Message-ID: <9707EBA615A57747A0668CECD4638A3009BBAB@mail.agso.gov.au>

Vaidotas,

The command 'dev2bitmap(plotname, type="jpeg")'
does the trick too.

Thanks to all those who sent helpful tips. It seems that I
am posting these questions to the wrong list, my apologies!

Regards,

Augusto


--------------------------------------------
Augusto Sanabria. MSc, PhD.
Mathematical Modeller
Risk Research Group
Geospatial & Earth Monitoring Division
Geoscience Australia (www.ga.gov.au)
Cnr. Jerrabomberra Av. & Hindmarsh Dr.
Symonston ACT 2609
Ph. (02) 6249-9155
 
 


-----Original Message-----
From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org] On
Behalf Of Vaidotas Zemlys
Sent: Saturday, 14 January 2006 12:10 AM
To: r-devel at r-project.org
Subject: Re: [Rd] Saving a plot in R-LINUX


On 1/13/06, Dirk Eddelbuettel <edd at debian.org> wrote:
>
> On 13 January 2006 at 11:02, Augusto.Sanabria at ga.gov.au wrote:
> | Is there any way to save a plot produced by
> | R in a LINUX (Debian) machine?
>
> It is the same on every platform and ...
>
> | The window opened by R to put the plot in,
> | does not give any option to save it (there
> | are options to move, close, minimise it, etc.
> | but not to save it). How do you do that?
>

What about using dev.copy? Or am I missing something? In windows there is a
context menu when you click with the right mouse button, which lets you
choose how do you want to save the plot. On linux I came up with such
function, which albeit not perfectly but does the job:

d2b <-
function(file="Rplot%d.bmp",height=4,width=4,res=150,which=dev.cur(),...)
{
    if(which!=dev.cur()) {
        cur <- dev.cur()
        dev.set(which)
    }
    else cur <- NULL

 
dev.copy(device=bitmap,file=file,height=height,width=width,point=8,res=res,..
.)
    dev.off()
    if(!is.null(cur))dev.set(cur)
    else dev.set(which)
}

It copies told device (current by default) to bitmap file. This function
could be easily adapted for copying to other formats.

Since the answer was too easy, probably I did not understand question
correctly. In that case please ignore this message.

Vaidotas Zemlys
--
Doctorate student, http://www.mif.vu.lt/katedros/eka/katedra/zemlys.php
Vilnius University

______________________________________________
R-devel at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-devel


From ben.bob at gmail.com  Mon Jan 16 05:21:10 2006
From: ben.bob at gmail.com (Bo Peng)
Date: Sun, 15 Jan 2006 22:21:10 -0600
Subject: [Rd] Provide both shlib and standard versions of R?
Message-ID: <6ea7b5430601152021y2a54089bj9f8b122b91d007b3@mail.gmail.com>

Dear list,

To operate R from python via a Python package rpy, R has to be
compiled with --enable-R-shlib.  This is troublesome since none of the
binary distributions (except for windows?) is built with this option
so rpy users have to build R from source. This can be quite a
challenge, especially on platforms like macOSX.

Is it possible to provide both standard and shlib version of R by
default? This may not be too hard for R (link twice? I am not quite
sure.) but will benefit all applications that embed R.

Cheers,
Bo


From simon.urbanek at r-project.org  Mon Jan 16 06:48:18 2006
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Mon, 16 Jan 2006 00:48:18 -0500
Subject: [Rd] Provide both shlib and standard versions of R?
In-Reply-To: <6ea7b5430601152021y2a54089bj9f8b122b91d007b3@mail.gmail.com>
References: <6ea7b5430601152021y2a54089bj9f8b122b91d007b3@mail.gmail.com>
Message-ID: <5AC56224-204C-4FFF-881A-994A5C01A11C@r-project.org>


On Jan 15, 2006, at 11:21 PM, Bo Peng wrote:

> To operate R from python via a Python package rpy, R has to be  
> compiled with --enable-R-shlib.  This is troublesome since none of  
> the binary distributions (except for windows?) is built with this  
> option


That is not true, almost all binaries come with R as shared library -  
it is in fact the default on Mac OS X and Windows. Most Linux  
distributions provide a shared library binary as well.

>  so rpy users have to build R from source. This can be quite a  
> challenge, especially on platforms like macOSX.
>

I guess you didn't even try it, because on OS X it *is* the default!

Simon


From ben.bob at gmail.com  Mon Jan 16 07:03:06 2006
From: ben.bob at gmail.com (Bo Peng)
Date: Mon, 16 Jan 2006 00:03:06 -0600
Subject: [Rd] Provide both shlib and standard versions of R?
In-Reply-To: <5AC56224-204C-4FFF-881A-994A5C01A11C@r-project.org>
References: <6ea7b5430601152021y2a54089bj9f8b122b91d007b3@mail.gmail.com>
	<5AC56224-204C-4FFF-881A-994A5C01A11C@r-project.org>
Message-ID: <6ea7b5430601152203o5d1ff963vdb0323d21c1b4ff2@mail.gmail.com>

> That is not true, almost all binaries come with R as shared library -
> it is in fact the default on Mac OS X and Windows. Most Linux
> distributions provide a shared library binary as well.

This would be good news. But at least, under linux,

./configure --help
  --enable-R-shlib        build the shared/dynamic library 'libR' [no]

This option is not enabled by default.

Bo


From elw at stderr.org  Mon Jan 16 08:10:01 2006
From: elw at stderr.org (elijah wright)
Date: Mon, 16 Jan 2006 01:10:01 -0600 (CST)
Subject: [Rd] Provide both shlib and standard versions of R?
In-Reply-To: <6ea7b5430601152203o5d1ff963vdb0323d21c1b4ff2@mail.gmail.com>
References: <6ea7b5430601152021y2a54089bj9f8b122b91d007b3@mail.gmail.com>
	<5AC56224-204C-4FFF-881A-994A5C01A11C@r-project.org>
	<6ea7b5430601152203o5d1ff963vdb0323d21c1b4ff2@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0601160108290.19320@illuminati.stderr.org>


>> That is not true, almost all binaries come with R as shared library - 
>> it is in fact the default on Mac OS X and Windows. Most Linux 
>> distributions provide a shared library binary as well.
>
> This would be good news. But at least, under linux,
>
> ./configure --help
>  --enable-R-shlib        build the shared/dynamic library 'libR' [no]
>
> This option is not enabled by default.

then either build your own with correct options or talk to your 
distribution's packaging team.

on debian:

elw at illuminati:/usr/lib/R/lib$ ls -al /usr/lib/R/lib
total 2900
drwxr-xr-x  2 root root    4096 Jan 10 20:54 .
drwxr-xr-x 11 root root    4096 Jan 10 20:54 ..
-rw-r--r--  1 root root 1810072 Jan  7 20:44 libR.so
-rw-r--r--  1 root root 1139796 Jan  7 20:44 libRlapack.so
lrwxrwxrwx  1 root root      27 Jun  8  2005 libggobi.so -> ../../ggobi/lib/libggobi.so
lrwxrwxrwx  1 root root      28 Jun  8  2005 libgtkext.so -> ../../ggobi/lib/libgtkext.so


as you can see - there's clearly a nice libR.so sitting here.

--elijah


From ben.bob at gmail.com  Mon Jan 16 07:45:52 2006
From: ben.bob at gmail.com (Bo Peng)
Date: Mon, 16 Jan 2006 00:45:52 -0600
Subject: [Rd] Provide both shlib and standard versions of R?
In-Reply-To: <Pine.LNX.4.64.0601160108290.19320@illuminati.stderr.org>
References: <6ea7b5430601152021y2a54089bj9f8b122b91d007b3@mail.gmail.com>
	<5AC56224-204C-4FFF-881A-994A5C01A11C@r-project.org>
	<6ea7b5430601152203o5d1ff963vdb0323d21c1b4ff2@mail.gmail.com>
	<Pine.LNX.4.64.0601160108290.19320@illuminati.stderr.org>
Message-ID: <6ea7b5430601152245w3629a110w586b62f17f35e116@mail.gmail.com>

> then either build your own with correct options or talk to your
> distribution's packaging team.

It seems that my knowledge about this option is outdated.  When I
first encountered this problem two years ago, the R/rpm distribution
came with no libR.so. I was told that --enable-R-shlib would lead to
10% - 20% performance loss, and I had to re-compile R if I need to
embed it.

So I guess performance is no longer an issue and shared libraries are
provided as default on all platforms now? I certainly welcome this
change and I apologize for my unfounded accusation to R.

BTW, shouldn't --enable-R-shlib be yes by default during ./configure?.

Cheers,
Bo


From Bill.Venables at csiro.au  Sun Jan 15 00:28:50 2006
From: Bill.Venables at csiro.au (Bill.Venables@csiro.au)
Date: Sun, 15 Jan 2006 00:28:50 +0100 (CET)
Subject: [Rd] initialize expression in 'quasi' (PR#8486)
Message-ID: <20060114232850.D0FE719FFF@slim.kubism.ku.dk>

This is a multi-part message in MIME format.

------_=_NextPart_001_01C61962.212F35AB
Content-Type: text/plain;
	charset="us-ascii"
Content-Transfer-Encoding: quoted-printable

This is not so much a bug as an infelicity in the code that can easily
be fixed.

The initialize expression in the quasi family function is, (uniformly
for all links and all variance functions):


    initialize <- expression({
        n <- rep.int(1, nobs)
        mustart <- y + 0.1 * (y =3D=3D 0)
    })

This is inappropriate (and often fails) for variance function
"mu(1-mu)".  Here is a short demo to show it:
#################################################

set.seed(666)
dat <- data.frame(x =3D rep((-10):10, each =3D 5), w =3D rep(1:5, 21))
dat <- transform(dat, y =3D rbinom(x, size =3D w, prob =3D pcauchy(1 + =
2*x)))

modFit <- glm(y/w ~ x, quasi(link =3D cauchit, variance =3D "mu(1-mu)"),
              dat, weights =3D w, trace =3D T)

Deviance =3D 309.2785 Iterations - 1=20
Deviance =3D 3257.501 Iterations - 2=20
Deviance =3D 1043.455 Iterations - 3=20
..
Deviance =3D 1733.824 Iterations - 24=20
Deviance =3D 1665.487 Iterations - 25=20
Warning message:
algorithm did not converge in: glm.fit(x =3D X, ...
#################################################

A comprehensive fix would involve tying the initialize expression to
both the link and the variance function, but that would involve changing
make.link(), which is probably not a good idea for other reasons (though
ultimately that might be the way to go).  There are at least three
possible work-arounds:

1) use quasibinomial for this kind of model (but that's not possible
here and an unnecessary complication if you are transferring S-PLUS
code, which is how I found the problem) but quasibinomial could be
extended to take this link as well, of course.

2) warn people in the help information that with quasi() they should
always give the algorithm a bit more help and supply an appropriate
mustart.   This works fine (even if the coefficient estimates are a bit
ropey!):

#################################################
modFit <- glm(y/w ~ x, quasi(link =3D cauchit, variance =3D "mu(1-mu)"),
  dat, weights =3D w, trace =3D T, mustart =3D pmax(0.001, pmin(0.999, =
y/w)))

Deviance =3D 218.9552 Iterations - 1=20
Deviance =3D 123.2773 Iterations - 2=20
Deviance =3D 86.13804 Iterations - 3=20
Deviance =3D 74.23746 Iterations - 4=20
Deviance =3D 72.03787 Iterations - 5=20
Deviance =3D 71.89566 Iterations - 6=20
Deviance =3D 71.89395 Iterations - 7=20
Deviance =3D 71.89395 Iterations - 8=20
Deviance =3D 71.89395 Iterations - 9=20
>=20
#################################################

3) change quasi() slightly to cover this case, at least, in a better
way.

I have included a minimally modified version of quasi that I think
achieves this and the demo shown above.=20

With the changed version the performance, in this case, is identical to
what you get above when mustart is supplied.  The changes cannot affect
performance with any other variance functions and with this variance
function should only make things better, but it just _might_ make things
work worse in extreme and unusual cases.  I have not found one, though.

Bill Venables.=20



--please do not edit the information below--

Version:
 platform =3D i386-pc-mingw32
 arch =3D i386
 os =3D mingw32
 system =3D i386, mingw32
 status =3D=20
 major =3D 2
 minor =3D 2.1
 year =3D 2005
 month =3D 12
 day =3D 20
 svn rev =3D 36812
 language =3D R

Windows XP Professional (build 2600) Service Pack 2.0

Locale:
LC_COLLATE=3DEnglish_Australia.1252;LC_CTYPE=3DEnglish_Australia.1252;LC_=
MON
ETARY=3DEnglish_Australia.1252;LC_NUMERIC=3DC;LC_TIME=3DEnglish_Australia=
.1252

Search Path:
 .GlobalEnv, package:mgcv, package:AusNew, package:MASS, package:RODBC,
package:lattice, package:splines, package:methods, package:stats,
package:graphics, package:grDevices, package:datasets, package:RBigData,
package:mvbutils, mvb.session.info, package:tools, package:utils,
package:RBigData, package:RUtilities, package:RBigLibrary,
package:g.data, Autoloads, package:base

Bill Venables,=20
CMIS, CSIRO Laboratories,=20
PO Box 120, Cleveland, Qld. 4163=20
AUSTRALIA=20
Office Phone (email preferred): +61 7 3826 7251=20
Fax (if absolutely necessary):    +61 7 3826 7304=20
Mobile (rarely used):                +61 4 1963 4642=20
Home Phone:                          +61 7 3286 7700=20
mailto:Bill.Venables at csiro.au=20
http://www.cmis.csiro.au/bill.venables/=20



------_=_NextPart_001_01C61962.212F35AB
Content-Type: application/octet-stream;
	name="_quasi.R"
Content-Transfer-Encoding: base64
Content-Description: _quasi.R
Content-Disposition: attachment;
	filename="_quasi.R"
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------_=_NextPart_001_01C61962.212F35AB
Content-Type: application/octet-stream;
	name="demo_quasi.R"
Content-Transfer-Encoding: base64
Content-Description: demo_quasi.R
Content-Disposition: attachment;
	filename="demo_quasi.R"

c2V0LnNlZWQoNjY2KQ0KZGF0IDwtIGRhdGEuZnJhbWUoeCA9IHJlcCgoLTEwKToxMCwgZWFjaCA9
IDUpLCB3ID0gcmVwKDE6NSwgMjEpKQ0KZGF0IDwtIHRyYW5zZm9ybShkYXQsIHkgPSByYmlub20o
eCwgc2l6ZSA9IHcsIHByb2IgPSBwY2F1Y2h5KDEgKyAyKngpKSkNCg0KbW9kRml0IDwtIGdsbSh5
L3cgfiB4LCBxdWFzaShsaW5rID0gY2F1Y2hpdCwgdmFyaWFuY2UgPSAibXUoMS1tdSkiKSwNCiAg
ICAgICAgICAgICAgZGF0LCB3ZWlnaHRzID0gdywgdHJhY2UgPSBUKQ0KDQptb2RGaXQgPC0gZ2xt
KHkvdyB+IHgsIHF1YXNpKGxpbmsgPSBjYXVjaGl0LCB2YXJpYW5jZSA9ICJtdSgxLW11KSIpLA0K
ICAgICAgICAgICAgICBkYXQsIHdlaWdodHMgPSB3LCB0cmFjZSA9IFQsIG11c3RhcnQgPSBwbWF4
KDAuMDAxLCBwbWluKDAuOTk5LCB5L3cpKSkNCiMgcXVhc2kgPC0gcXVhc2kubmV3DQoNCg0KbW9k
Rml0IDwtIGdsbSh5L3cgfiB4LCBxdWFzaShsaW5rID0gY2F1Y2hpdCwgdmFyaWFuY2UgPSAibXUo
MS1tdSkiKSwNCiAgICAgICAgICAgICAgZGF0LCB3ZWlnaHRzID0gdywgdHJhY2UgPSBUKQ0K

------_=_NextPart_001_01C61962.212F35AB--


From ripley at stats.ox.ac.uk  Mon Jan 16 09:08:16 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 16 Jan 2006 08:08:16 +0000 (GMT)
Subject: [Rd] Provide both shlib and standard versions of R?
In-Reply-To: <6ea7b5430601152245w3629a110w586b62f17f35e116@mail.gmail.com>
References: <6ea7b5430601152021y2a54089bj9f8b122b91d007b3@mail.gmail.com>
	<5AC56224-204C-4FFF-881A-994A5C01A11C@r-project.org>
	<6ea7b5430601152203o5d1ff963vdb0323d21c1b4ff2@mail.gmail.com>
	<Pine.LNX.4.64.0601160108290.19320@illuminati.stderr.org>
	<6ea7b5430601152245w3629a110w586b62f17f35e116@mail.gmail.com>
Message-ID: <Pine.LNX.4.61.0601160725460.2921@gannet.stats>

On Mon, 16 Jan 2006, Bo Peng wrote:

>> then either build your own with correct options or talk to your
>> distribution's packaging team.
>
> It seems that my knowledge about this option is outdated.  When I
> first encountered this problem two years ago, the R/rpm distribution
> came with no libR.so. I was told that --enable-R-shlib would lead to
> 10% - 20% performance loss, and I had to re-compile R if I need to
> embed it.
>
> So I guess performance is no longer an issue and shared libraries are
> provided as default on all platforms now? I certainly welcome this
> change and I apologize for my unfounded accusation to R.

Why guess?  There are accurate statements in the R-admin manual, and the 
RH RPM change was discussed on this list in 2006:

https://stat.ethz.ch/pipermail/r-devel/2006-January/036118.html

> BTW, shouldn't --enable-R-shlib be yes by default during ./configure?.

No, for the reasons given in the R-admin manual.  They include that there 
are platforms on which --enable-R-shlib cannot be used.

We have been working (in R-devel) on changes which are designed to reduce 
the overhead of the shlib version of R: they do, but it is still over 10% 
on the platforms checked.  (The figures given earlier are optimistic in 
the sense that they include time spent in compiled code in packages such 
as stats in a typical R session: worst-case scenarios have up to double 
that.)

Please do think hard before you tell other people what they `should' do 
for you.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Mon Jan 16 09:28:19 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 16 Jan 2006 08:28:19 +0000 (GMT)
Subject: [Rd] initialize expression in 'quasi' (PR#8486)
In-Reply-To: <20060114232850.D0FE719FFF@slim.kubism.ku.dk>
References: <20060114232850.D0FE719FFF@slim.kubism.ku.dk>
Message-ID: <Pine.LNX.4.61.0601160814140.2921@gannet.stats>

Bill,

As you see, R-bugs does not work with encoded (binary) attachments. 
Could you please send this again to R-devel with (if possible) text 
attachments?

The source code says

# 0.1 fudge here matches poisson: S has 1/6.
     initialize <- expression({ n <- rep.int(1, nobs); mustart <- y + 0.1 * (y == 0)})

although I believe S-PLUS has diverged here.

Brian

On Sun, 15 Jan 2006 Bill.Venables at csiro.au wrote:

> This is a multi-part message in MIME format.
>
> ------_=_NextPart_001_01C61962.212F35AB
> Content-Type: text/plain;
> 	charset="us-ascii"
> Content-Transfer-Encoding: quoted-printable
>
> This is not so much a bug as an infelicity in the code that can easily
> be fixed.
>
> The initialize expression in the quasi family function is, (uniformly
> for all links and all variance functions):
>
>
>    initialize <- expression({
>        n <- rep.int(1, nobs)
>        mustart <- y + 0.1 * (y =3D=3D 0)
>    })
>
> This is inappropriate (and often fails) for variance function
> "mu(1-mu)".  Here is a short demo to show it:
> #################################################
>
> set.seed(666)
> dat <- data.frame(x =3D rep((-10):10, each =3D 5), w =3D rep(1:5, 21))
> dat <- transform(dat, y =3D rbinom(x, size =3D w, prob =3D pcauchy(1 + =
> 2*x)))
>
> modFit <- glm(y/w ~ x, quasi(link =3D cauchit, variance =3D "mu(1-mu)"),
>              dat, weights =3D w, trace =3D T)
>
> Deviance =3D 309.2785 Iterations - 1=20
> Deviance =3D 3257.501 Iterations - 2=20
> Deviance =3D 1043.455 Iterations - 3=20
> ..
> Deviance =3D 1733.824 Iterations - 24=20
> Deviance =3D 1665.487 Iterations - 25=20
> Warning message:
> algorithm did not converge in: glm.fit(x =3D X, ...
> #################################################
>
> A comprehensive fix would involve tying the initialize expression to
> both the link and the variance function, but that would involve changing
> make.link(), which is probably not a good idea for other reasons (though
> ultimately that might be the way to go).  There are at least three
> possible work-arounds:
>
> 1) use quasibinomial for this kind of model (but that's not possible
> here and an unnecessary complication if you are transferring S-PLUS
> code, which is how I found the problem) but quasibinomial could be
> extended to take this link as well, of course.
>
> 2) warn people in the help information that with quasi() they should
> always give the algorithm a bit more help and supply an appropriate
> mustart.   This works fine (even if the coefficient estimates are a bit
> ropey!):
>
> #################################################
> modFit <- glm(y/w ~ x, quasi(link =3D cauchit, variance =3D "mu(1-mu)"),
>  dat, weights =3D w, trace =3D T, mustart =3D pmax(0.001, pmin(0.999, =
> y/w)))
>
> Deviance =3D 218.9552 Iterations - 1=20
> Deviance =3D 123.2773 Iterations - 2=20
> Deviance =3D 86.13804 Iterations - 3=20
> Deviance =3D 74.23746 Iterations - 4=20
> Deviance =3D 72.03787 Iterations - 5=20
> Deviance =3D 71.89566 Iterations - 6=20
> Deviance =3D 71.89395 Iterations - 7=20
> Deviance =3D 71.89395 Iterations - 8=20
> Deviance =3D 71.89395 Iterations - 9=20
>> =20
> #################################################
>
> 3) change quasi() slightly to cover this case, at least, in a better
> way.
>
> I have included a minimally modified version of quasi that I think
> achieves this and the demo shown above.=20
>
> With the changed version the performance, in this case, is identical to
> what you get above when mustart is supplied.  The changes cannot affect
> performance with any other variance functions and with this variance
> function should only make things better, but it just _might_ make things
> work worse in extreme and unusual cases.  I have not found one, though.
>
> Bill Venables.=20
>
>
>
> --please do not edit the information below--
>
> Version:
> platform =3D i386-pc-mingw32
> arch =3D i386
> os =3D mingw32
> system =3D i386, mingw32
> status =3D=20
> major =3D 2
> minor =3D 2.1
> year =3D 2005
> month =3D 12
> day =3D 20
> svn rev =3D 36812
> language =3D R
>
> Windows XP Professional (build 2600) Service Pack 2.0
>
> Locale:
> LC_COLLATE=3DEnglish_Australia.1252;LC_CTYPE=3DEnglish_Australia.1252;LC_=
> MON
> ETARY=3DEnglish_Australia.1252;LC_NUMERIC=3DC;LC_TIME=3DEnglish_Australia=
> .1252
>
> Search Path:
> .GlobalEnv, package:mgcv, package:AusNew, package:MASS, package:RODBC,
> package:lattice, package:splines, package:methods, package:stats,
> package:graphics, package:grDevices, package:datasets, package:RBigData,
> package:mvbutils, mvb.session.info, package:tools, package:utils,
> package:RBigData, package:RUtilities, package:RBigLibrary,
> package:g.data, Autoloads, package:base
>
> Bill Venables,=20
> CMIS, CSIRO Laboratories,=20
> PO Box 120, Cleveland, Qld. 4163=20
> AUSTRALIA=20
> Office Phone (email preferred): +61 7 3826 7251=20
> Fax (if absolutely necessary):    +61 7 3826 7304=20
> Mobile (rarely used):                +61 4 1963 4642=20
> Home Phone:                          +61 7 3286 7700=20
> mailto:Bill.Venables at csiro.au=20
> http://www.cmis.csiro.au/bill.venables/=20
>
>
>
> ------_=_NextPart_001_01C61962.212F35AB
> Content-Type: application/octet-stream;
> 	name="_quasi.R"
> Content-Transfer-Encoding: base64
> Content-Description: _quasi.R
> Content-Disposition: attachment;
> 	filename="_quasi.R"
>
> InF1YXNpIiA8LQ0KZnVuY3Rpb24gKGxpbmsgPSAiaWRlbnRpdHkiLCB2YXJpYW5jZSA9ICJjb25z
> dGFudCIpIA0Kew0KICAgIGxpbmt0ZW1wIDwtIHN1YnN0aXR1dGUobGluaykNCiAgICBpZiAoaXMu
> ZXhwcmVzc2lvbihsaW5rdGVtcCkgfHwgaXMuY2FsbChsaW5rdGVtcCkpIA0KICAgICAgICBsaW5r
> dGVtcCA8LSBsaW5rDQogICAgZWxzZSBpZiAoIWlzLmNoYXJhY3RlcihsaW5rdGVtcCkpIA0KICAg
> ICAgICBsaW5rdGVtcCA8LSBkZXBhcnNlKGxpbmt0ZW1wKQ0KICAgIGlmIChpcy5jaGFyYWN0ZXIo
> bGlua3RlbXApKSANCiAgICAgICAgc3RhdHMgPC0gbWFrZS5saW5rKGxpbmt0ZW1wKQ0KICAgIGVs
> c2Ugc3RhdHMgPC0gbGlua3RlbXANCiAgICB2YXJpYW5jZXRlbXAgPC0gc3Vic3RpdHV0ZSh2YXJp
> YW5jZSkNCiAgICBpZiAoIWlzLmNoYXJhY3Rlcih2YXJpYW5jZXRlbXApKSB7DQogICAgICAgIHZh
> cmlhbmNldGVtcCA8LSBkZXBhcnNlKHZhcmlhbmNldGVtcCkNCiAgICAgICAgaWYgKGxpbmt0ZW1w
> ID09ICJ2YXJpYW5jZSIpIA0KICAgICAgICAgICAgdmFyaWFuY2V0ZW1wIDwtIGV2YWwodmFyaWFu
> Y2UpDQogICAgfQ0KICAgIGluaXRpYWxpemUgPC0gTlVMTCAgICAgICAgICAgICAgICAgICAgICAg
> ICAgICAgICAgICAgICAgICAgICAgICAgIyMjIyBjaGFuZ2UNCiAgICBzd2l0Y2godmFyaWFuY2V0
> ZW1wLCBjb25zdGFudCA9IHsNCiAgICAgICAgdmFyaWFuY2UgPC0gZnVuY3Rpb24obXUpIHJlcC5p
> bnQoMSwgbGVuZ3RoKG11KSkNCiAgICAgICAgZGV2LnJlc2lkcyA8LSBmdW5jdGlvbih5LCBtdSwg
> d3QpIHd0ICogKCh5IC0gbXUpXjIpDQogICAgICAgIHZhbGlkbXUgPC0gZnVuY3Rpb24obXUpIFRS
> VUUNCiAgICB9LCAibXUoMS1tdSkiID0gew0KICAgICAgICB2YXJpYW5jZSA8LSBmdW5jdGlvbiht
> dSkgbXUgKiAoMSAtIG11KQ0KICAgICAgICB2YWxpZG11IDwtIGZ1bmN0aW9uKG11KSBhbGwobXUg
> PiAwKSAmJiBhbGwobXUgPCAxKQ0KICAgICAgICBkZXYucmVzaWRzIDwtIGZ1bmN0aW9uKHksIG11
> LCB3dCkgMiAqIHd0ICogKHkgKiBsb2coaWZlbHNlKHkgPT0gDQogICAgICAgICAgICAwLCAxLCB5
> L211KSkgKyAoMSAtIHkpICogbG9nKGlmZWxzZSh5ID09IDEsIDEsICgxIC0gDQogICAgICAgICAg
> ICB5KS8oMSAtIG11KSkpKQ0KICAgICAgICBpbml0aWFsaXplIDwtIGV4cHJlc3Npb24oeyAgICAg
> ICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIyMjIyBjaGFuZ2UNCiAgICAgICAgICBuIDwt
> IHJlcC5pbnQoMSwgbm9icykgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICMj
> IyMgY2hhbmdlDQogICAgICAgICAgbXVzdGFydCA8LSBwbWF4KDAuMDAxLCBwbWluKDAuOTk5LCB5
> KSkgICAgICAgICAgICAgICAgICAgICAjIyMjIGNoYW5nZQ0KICAgICAgICB9KSAgICAgICAgICAg
> ICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIyMjIyBjaGFu
> Z2UNCiAgICB9LCBtdSA9IHsNCiAgICAgICAgdmFyaWFuY2UgPC0gZnVuY3Rpb24obXUpIG11DQog
> ICAgICAgIHZhbGlkbXUgPC0gZnVuY3Rpb24obXUpIGFsbChtdSA+IDApDQogICAgICAgIGRldi5y
> ZXNpZHMgPC0gZnVuY3Rpb24oeSwgbXUsIHd0KSAyICogd3QgKiAoeSAqIGxvZyhpZmVsc2UoeSA9
> PSANCiAgICAgICAgICAgIDAsIDEsIHkvbXUpKSAtICh5IC0gbXUpKQ0KICAgIH0sICJtdV4yIiA9
> IHsNCiAgICAgICAgdmFyaWFuY2UgPC0gZnVuY3Rpb24obXUpIG11XjINCiAgICAgICAgdmFsaWRt
> dSA8LSBmdW5jdGlvbihtdSkgYWxsKG11ID4gMCkNCiAgICAgICAgZGV2LnJlc2lkcyA8LSBmdW5j
> dGlvbih5LCBtdSwgd3QpIHBtYXgoLTIgKiB3dCAqIChsb2coaWZlbHNlKHkgPT0gDQogICAgICAg
> ICAgICAwLCAxLCB5KS9tdSkgLSAoeSAtIG11KS9tdSksIDApDQogICAgfSwgIm11XjMiID0gew0K
> ICAgICAgICB2YXJpYW5jZSA8LSBmdW5jdGlvbihtdSkgbXVeMw0KICAgICAgICB2YWxpZG11IDwt
> IGZ1bmN0aW9uKG11KSBhbGwobXUgPiAwKQ0KICAgICAgICBkZXYucmVzaWRzIDwtIGZ1bmN0aW9u
> KHksIG11LCB3dCkgd3QgKiAoKHkgLSBtdSleMikvKHkgKiANCiAgICAgICAgICAgIG11XjIpDQog
> ICAgfSwgc3RvcChnZXR0ZXh0ZigiJ3ZhcmlhbmNlJyBcIiVzXCIgaXMgaW52YWxpZDogcG9zc2li
> bGUgdmFsdWVzIGFyZSBcIm11KDEtbXUpXCIsIFwibXVcIiwgXCJtdV4yXCIsIFwibXVeM1wiIGFu
> ZCBcImNvbnN0YW50XCIiLCANCiAgICAgICAgdmFyaWFuY2V0ZW1wKSwgZG9tYWluID0gTkEpKQ0K
> ICAgIGlmKGlzLm51bGwoaW5pdGlhbGl6ZSkpICAgICAgICAgICAgICAgICAgICAgICAgICAgICAg
> ICAgICAgICAgICAgIyMjIyBjaGFuZ2UNCiAgICBpbml0aWFsaXplIDwtIGV4cHJlc3Npb24oew0K
> ICAgICAgICBuIDwtIHJlcC5pbnQoMSwgbm9icykNCiAgICAgICAgbXVzdGFydCA8LSB5ICsgMC4x
> ICogKHkgPT0gMCkNCiAgICB9KQ0KICAgIGFpYyA8LSBmdW5jdGlvbih5LCBuLCBtdSwgd3QsIGRl
> dikgTkENCiAgICBzdHJ1Y3R1cmUobGlzdChmYW1pbHkgPSAicXVhc2kiLCBsaW5rID0gbGlua3Rl
> bXAsIGxpbmtmdW4gPSBzdGF0cyRsaW5rZnVuLCANCiAgICAgICAgbGlua2ludiA9IHN0YXRzJGxp
> bmtpbnYsIHZhcmlhbmNlID0gdmFyaWFuY2UsIGRldi5yZXNpZHMgPSBkZXYucmVzaWRzLCANCiAg
> ICAgICAgYWljID0gYWljLCBtdS5ldGEgPSBzdGF0cyRtdS5ldGEsIGluaXRpYWxpemUgPSBpbml0
> aWFsaXplLCANCiAgICAgICAgdmFsaWRtdSA9IHZhbGlkbXUsIHZhbGlkZXRhID0gc3RhdHMkdmFs
> aWRldGEsIHZhcmZ1biA9IHZhcmlhbmNldGVtcCksIA0KICAgICAgICBjbGFzcyA9ICJmYW1pbHki
> KQ0KfQ0K
>
> ------_=_NextPart_001_01C61962.212F35AB
> Content-Type: application/octet-stream;
> 	name="demo_quasi.R"
> Content-Transfer-Encoding: base64
> Content-Description: demo_quasi.R
> Content-Disposition: attachment;
> 	filename="demo_quasi.R"
>
> c2V0LnNlZWQoNjY2KQ0KZGF0IDwtIGRhdGEuZnJhbWUoeCA9IHJlcCgoLTEwKToxMCwgZWFjaCA9
> IDUpLCB3ID0gcmVwKDE6NSwgMjEpKQ0KZGF0IDwtIHRyYW5zZm9ybShkYXQsIHkgPSByYmlub20o
> eCwgc2l6ZSA9IHcsIHByb2IgPSBwY2F1Y2h5KDEgKyAyKngpKSkNCg0KbW9kRml0IDwtIGdsbSh5
> L3cgfiB4LCBxdWFzaShsaW5rID0gY2F1Y2hpdCwgdmFyaWFuY2UgPSAibXUoMS1tdSkiKSwNCiAg
> ICAgICAgICAgICAgZGF0LCB3ZWlnaHRzID0gdywgdHJhY2UgPSBUKQ0KDQptb2RGaXQgPC0gZ2xt
> KHkvdyB+IHgsIHF1YXNpKGxpbmsgPSBjYXVjaGl0LCB2YXJpYW5jZSA9ICJtdSgxLW11KSIpLA0K
> ICAgICAgICAgICAgICBkYXQsIHdlaWdodHMgPSB3LCB0cmFjZSA9IFQsIG11c3RhcnQgPSBwbWF4
> KDAuMDAxLCBwbWluKDAuOTk5LCB5L3cpKSkNCiMgcXVhc2kgPC0gcXVhc2kubmV3DQoNCg0KbW9k
> Rml0IDwtIGdsbSh5L3cgfiB4LCBxdWFzaShsaW5rID0gY2F1Y2hpdCwgdmFyaWFuY2UgPSAibXUo
> MS1tdSkiKSwNCiAgICAgICAgICAgICAgZGF0LCB3ZWlnaHRzID0gdywgdHJhY2UgPSBUKQ0K
>
> ------_=_NextPart_001_01C61962.212F35AB--
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From greg.kochanski at phonetics.oxford.ac.uk  Mon Jan 16 10:31:31 2006
From: greg.kochanski at phonetics.oxford.ac.uk (greg.kochanski@phonetics.oxford.ac.uk)
Date: Mon, 16 Jan 2006 10:31:31 +0100 (CET)
Subject: [Rd] help.start() and Debian packaging (PR#8483)
Message-ID: <20060116093131.4F3BC1E5F8@slim.kubism.ku.dk>

While I agree with you, I find that the Debian packager does not.
I already reported the problem to Debian, and they said that
enough people want light-weight installations that they will
continue splitting R into several parts.
The package maintainer is  Dirk Eddelbuettel <edd at debian.org>,
and the relevant bug report is 348051.

His response was this:
| > Ok, that confirms that all you need to do is to install r-doc-html. 
No bug,
| > it is designed this way.


Consequently, I can only appeal to your humanity and
to good programming practice.

It is good programming practice to protect the user from
his/her own mistakes, even if those mistakes are made
easier/encouraged by Debian.   It is also good programming
practice to provide appropriate error messages when something
goes wrong, even if it "shouldn't" ever go wrong.

So, yeah, you can make an argument that you don't have to
do it, but R will be a better piece of software if you make
the change.


Prof Brian Ripley wrote:
> This is all based on a false premise: that a partial install of Debian
> files is 'R'.
> 
> R's own scripts do always install the HTML documentation, so 
> help.start() is entitled to assume that it is present. ...
> 
> Note that your version of 'R' is not current.
> 
> If there is a bug here, it is in the Debian re-packaging.  I trust the 
> Debian packages do contain a bug reporting address other than this one: 
> please use the correct one.  (The other binary distributions that I am 
> aware of, e.g. RPMs, do seem to include all of R.)
> 
> On Sat, 14 Jan 2006 greg.kochanski at phonetics.oxford.ac.uk wrote:
> 
>> Full_Name: Greg Kochanski
>> Version: 2.2.0
>> OS: Debian Linux on i686
>> Submission from: (NULL) (212.159.16.190)
>>
>>
>> Debian packages the R documentation separately from the R core code.
>> Consequently, it is possible for people to have R without
>> the HTML documentation.   (In fact, the docs are not installed by 
>> default,
>> so it's very likely.)
>>
>>
>> Thus, help.start() cannot depend on the HTML documentation being there.
>> It should check for one (or a few) files and produce some reasonable
>> error message if it is not there.   Maybe something like
>> "Warning: the HTML documentation is not installed."
>>
>> Alternatively, help.start() could produce references to some on-line
>> HTML documentation, instead of local documentation.
>>
>>
>>
>> A related bug is that if one calls
>> help.start()  when the HTML documentation does not exist,
>> all future calls to help() will lead to errors.
> 
> 
> Working as documented is not a bug.
>


From ewellm at cox.net  Mon Jan 16 14:20:21 2006
From: ewellm at cox.net (ewellm@cox.net)
Date: Mon, 16 Jan 2006 14:20:21 +0100 (CET)
Subject: [Rd] _pei386_runtime_relocator ? (PR#8491)
Message-ID: <20060116132021.8E30C20805@slim.kubism.ku.dk>

Hi,

The problem arises when I try to use /bin/Rcmd shlib to create a DLL for 
external fortran code to do numerical integration from Dr. Alan Genz's 
website.  I tried this yesterday after downloading R-tools, activePerl, 
mingw and cygwin and reinstalling R.

I used the following command

c:\"program files"\R\rw2010\bin\Rcmd shlib ranrth.f

I got the following error message:

In function 
'DllMainCRTStartup':  d:/src/mingw/build/runtime/../..runtime/dllcrt1.c:67: 
  undefined reference to '_pei386_runtime_relocator'

I am a new user, but I searched the R web-site first, and couldn't find 
this error message.  A google search confirmed that it is a cygwin error 
message, but it was in an exchange between two cygwin developers, and I 
couldn't figure out what the message means.  The only google hits were on 
the cygwin web-site. The cygwin web-site also said that they would flame 
any new users who asked stupid questions, and I am hoping you guys are more 
tolerant.

thanks warmly,

Marian Ewell


From ben.bob at gmail.com  Mon Jan 16 15:35:15 2006
From: ben.bob at gmail.com (Bo Peng)
Date: Mon, 16 Jan 2006 08:35:15 -0600
Subject: [Rd] Provide both shlib and standard versions of R?
In-Reply-To: <Pine.LNX.4.61.0601160725460.2921@gannet.stats>
References: <6ea7b5430601152021y2a54089bj9f8b122b91d007b3@mail.gmail.com>
	<5AC56224-204C-4FFF-881A-994A5C01A11C@r-project.org>
	<6ea7b5430601152203o5d1ff963vdb0323d21c1b4ff2@mail.gmail.com>
	<Pine.LNX.4.64.0601160108290.19320@illuminati.stderr.org>
	<6ea7b5430601152245w3629a110w586b62f17f35e116@mail.gmail.com>
	<Pine.LNX.4.61.0601160725460.2921@gannet.stats>
Message-ID: <6ea7b5430601160635qcf1f980qea3384576a04f077@mail.gmail.com>

> Why guess?  There are accurate statements in the R-admin manual,

I read the manual 2 years ago, and the info I got was still correct.

> and the RH RPM change was discussed on this list in 2006:
> https://stat.ethz.ch/pipermail/r-devel/2006-January/036118.html

I simply do not know RPMs have been built with this option on, and
there is no definite place/word I can be assured about this.

> No, for the reasons given in the R-admin manual.

Even the reason I gave in my first email was not up to date (most
binary distributions are compiled with this option), my suggest is
still valid: why not provide two binaries? Most users can use standard
R without sacrificing performance  and embedding applications use
libR.so and, if needed, a separate binary R_embed.

Cheers,
Bo


From plummer at iarc.fr  Mon Jan 16 17:50:31 2006
From: plummer at iarc.fr (Martyn Plummer)
Date: Mon, 16 Jan 2006 17:50:31 +0100
Subject: [Rd] Provide both shlib and standard versions of R?
In-Reply-To: <6ea7b5430601152245w3629a110w586b62f17f35e116@mail.gmail.com>
References: <6ea7b5430601152021y2a54089bj9f8b122b91d007b3@mail.gmail.com>
	<5AC56224-204C-4FFF-881A-994A5C01A11C@r-project.org>
	<6ea7b5430601152203o5d1ff963vdb0323d21c1b4ff2@mail.gmail.com>
	<Pine.LNX.4.64.0601160108290.19320@illuminati.stderr.org>
	<6ea7b5430601152245w3629a110w586b62f17f35e116@mail.gmail.com>
Message-ID: <1137430231.2938.48.camel@seurat.iarc.fr>

On Mon, 2006-01-16 at 00:45 -0600, Bo Peng wrote:
> > then either build your own with correct options or talk to your
> > distribution's packaging team.
> 
> It seems that my knowledge about this option is outdated.  When I
> first encountered this problem two years ago, the R/rpm distribution
> came with no libR.so. I was told that --enable-R-shlib would lead to
> 10% - 20% performance loss, and I had to re-compile R if I need to
> embed it.
> 
> So I guess performance is no longer an issue and shared libraries are
> provided as default on all platforms now? I certainly welcome this
> change and I apologize for my unfounded accusation to R.

What changed was that a sufficient number of people asked me to create
an RPM with the shared library and I changed my mind.  The aim of the
precompiled binaries is to satisfy most of the people most of the time,
and when I get repeated requests for the same feature, I have to bear
that in mind. People who require optimal performance can still compile
their own.

As for the idea of compiling two distinct binaries packages for R, I am
not especially keen, and not just out of laziness. The problem is that R
packages depend on libR.so, when it exists, so if you uninstall R with a
shared library and then install R without the shared library you get a
broken system.

You can look at the CAPABILITIES file in the same directory as the RPM
to see how it was compiled.

Martyn

> BTW, shouldn't --enable-R-shlib be yes by default during ./configure?.
> 
> Cheers,
> Bo
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-----------------------------------------------------------------------
This message and its attachments are strictly confidential. ...{{dropped}}


From sls at usc.edu  Mon Jan 16 18:57:14 2006
From: sls at usc.edu (sls@usc.edu)
Date: Mon, 16 Jan 2006 18:57:14 +0100 (CET)
Subject: [Rd] problem unpacking R sources (PR#8492)
Message-ID: <20060116175714.206A219FF2@slim.kubism.ku.dk>

Full_Name: Steven L. Scott
Version: 2.2.1
OS: Windows-Cygwin
Submission from: (NULL) (128.125.60.50)


I've had problems unpacking the R source coded downloaded from 
   http://lib.stat.cmu.edu/R/CRAN/src/base/R-2/R-2.2.1.tar.gz

Version info for tar and gunzip provided below (GNU legalese edited out), along
with the error messages I get.
Thanks.
Steve 

/notcygwin[506] gunzip --version
gunzip 1.3.5
(2002-09-30)
Copyright 2002 Free Software Foundation
Copyright 1992-1993 Jean-loup Gailly
Compilation options:
DIRENT UTIME STDC_HEADERS HAVE_UNISTD_H HAVE_MEMORY_H HAVE_STRING_H HAVE_LSTAT
ASMV 
Written by Jean-loup Gailly.

/notcygwin[507] tar --version
tar (GNU tar) 1.13.25
Copyright (C) 2001 Free Software Foundation, Inc.
Written by John Gilmore and Jay Fenlason.

/notcygwin[508] gunzip R-2.2.1.tar.gz 
R-2.2.1.tar.gz:   0.2% -- replaced with R-2.2.1.tar

/notcygwin[509] tar xf R-2.2.1.tar 
tar: This does not look like a tar archive
tar: Skipping to next header
tar: Archive contains obsolescent base-64 headers
tar: Error exit delayed from previous errors


From ligges at statistik.uni-dortmund.de  Mon Jan 16 19:27:00 2006
From: ligges at statistik.uni-dortmund.de (ligges@statistik.uni-dortmund.de)
Date: Mon, 16 Jan 2006 19:27:00 +0100 (CET)
Subject: [Rd] problem unpacking R sources (PR#8492)
Message-ID: <20060116182700.6721319A41@slim.kubism.ku.dk>

sls at usc.edu wrote:

> Full_Name: Steven L. Scott
> Version: 2.2.1
> OS: Windows-Cygwin
> Submission from: (NULL) (128.125.60.50)
> 
> 
> I've had problems unpacking the R source coded downloaded from 
>    http://lib.stat.cmu.edu/R/CRAN/src/base/R-2/R-2.2.1.tar.gz


This is not a bug in R!!!

The Statlib mirror is known to be broken.
Please download from another mirror.

Please check the archives before submitting a bug report!

Uwe Ligges

> Version info for tar and gunzip provided below (GNU legalese edited out), along
> with the error messages I get.
> Thanks.
> Steve 
> 
> /notcygwin[506] gunzip --version
> gunzip 1.3.5
> (2002-09-30)
> Copyright 2002 Free Software Foundation
> Copyright 1992-1993 Jean-loup Gailly
> Compilation options:
> DIRENT UTIME STDC_HEADERS HAVE_UNISTD_H HAVE_MEMORY_H HAVE_STRING_H HAVE_LSTAT
> ASMV 
> Written by Jean-loup Gailly.
> 
> /notcygwin[507] tar --version
> tar (GNU tar) 1.13.25
> Copyright (C) 2001 Free Software Foundation, Inc.
> Written by John Gilmore and Jay Fenlason.
> 
> /notcygwin[508] gunzip R-2.2.1.tar.gz 
> R-2.2.1.tar.gz:   0.2% -- replaced with R-2.2.1.tar
> 
> /notcygwin[509] tar xf R-2.2.1.tar 
> tar: This does not look like a tar archive
> tar: Skipping to next header
> tar: Archive contains obsolescent base-64 headers
> tar: Error exit delayed from previous errors
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From Bill.Venables at csiro.au  Mon Jan 16 23:55:08 2006
From: Bill.Venables at csiro.au (Bill.Venables@csiro.au)
Date: Tue, 17 Jan 2006 09:55:08 +1100
Subject: [Rd] initialize expression in 'quasi' (PR#8486)
Message-ID: <B998A44C8986644EA8029CFE6396A924546897@exqld2-bne.qld.csiro.au>

My apologies, I thought it was going as a text attachement.  Looks like
Microsoft second guessing me again.

The problem is the 'mustart' value (if you are going to base it on the
variance structure and not the link as well) should not allow values to
touch the point 
where the variance becomes zero.  The fudge that is in there now obeys
this
'rule' for all but the mu(1-mu).  It is a bit too strong for the
'constant'
case, but I guess we are stuck with that now for back compatibility
reasons.


Here is my suggestion:

##############(cut
here)##################################################

quasi <- function (link = "identity", variance = "constant")  {
    linktemp <- substitute(link)
    if (is.expression(linktemp) || is.call(linktemp)) 
        linktemp <- link
    else if (!is.character(linktemp)) 
        linktemp <- deparse(linktemp)
    if (is.character(linktemp)) 
        stats <- make.link(linktemp)
    else stats <- linktemp
    variancetemp <- substitute(variance)
    if (!is.character(variancetemp)) {
        variancetemp <- deparse(variancetemp)
        if (linktemp == "variance") 
            variancetemp <- eval(variance)
    }
    initialize <- NULL
#######change
    switch(variancetemp,
    constant = {
        variance <- function(mu) rep.int(1, length(mu))
        dev.resids <- function(y, mu, wt) wt * ((y - mu)^2)
        validmu <- function(mu) TRUE
    },
    "mu(1-mu)" = {
        variance <- function(mu) mu * (1 - mu)
        validmu <- function(mu) all(mu > 0) && all(mu < 1)
        dev.resids <- function(y, mu, wt) 2 * wt * (y * log(ifelse(y == 
            0, 1, y/mu)) + (1 - y) * log(ifelse(y == 1, 1, (1 - 
            y)/(1 - mu))))
        initialize <- expression({
#######change
          n <- rep.int(1, nobs)
#######change
          mustart <- pmax(0.001, pmin(0.999, y))	#######change
        })
#######change
    },
    mu = {
        variance <- function(mu) mu
        validmu <- function(mu) all(mu > 0)
        dev.resids <- function(y, mu, wt) 2 * wt * (y * log(ifelse(y == 
            0, 1, y/mu)) - (y - mu))
    },
    "mu^2" = {
        variance <- function(mu) mu^2
        validmu <- function(mu) all(mu > 0)
        dev.resids <- function(y, mu, wt) pmax(-2 * wt * (log(ifelse(y
== 
            0, 1, y)/mu) - (y - mu)/mu), 0)
    },
    "mu^3" = {
        variance <- function(mu) mu^3
        validmu <- function(mu) all(mu > 0)
        dev.resids <- function(y, mu, wt) wt * ((y - mu)^2)/(y * 
            mu^2)
    },
    stop(gettextf("'variance' \"%s\" is invalid: possible values are
\"mu(1-mu)\", \"mu\", \"mu^2\", \"mu^3\" and \"constant\"",
        variancetemp), domain = NA))
    if(is.null(initialize))
#######change
    initialize <- expression({
        n <- rep.int(1, nobs)
        mustart <- y + 0.1 * (y == 0)
    })
    aic <- function(y, n, mu, wt, dev) NA
    structure(list(family = "quasi", link = linktemp, linkfun =
stats$linkfun, 
        linkinv = stats$linkinv, variance = variance, dev.resids =
dev.resids, 
        aic = aic, mu.eta = stats$mu.eta, initialize = initialize, 
        validmu = validmu, valideta = stats$valideta, varfun =
variancetemp), 
        class = "family")
}

###############(cut here)##############################

Bill Venables, 
CMIS, CSIRO Laboratories, 
PO Box 120, Cleveland, Qld. 4163 
AUSTRALIA 
Office Phone (email preferred): +61 7 3826 7251 
Fax (if absolutely necessary):    +61 7 3826 7304 
Mobile (rarely used):                +61 4 1963 4642 
Home Phone:                          +61 7 3286 7700 
mailto:Bill.Venables at csiro.au 
http://www.cmis.csiro.au/bill.venables/ 



-----Original Message-----
From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk] 
Sent: Monday, 16 January 2006 6:28 PM
To: Venables, Bill (CMIS, Cleveland)
Cc: r-devel at stat.math.ethz.ch
Subject: Re: [Rd] initialize expression in 'quasi' (PR#8486)


Bill,

As you see, R-bugs does not work with encoded (binary) attachments. 
Could you please send this again to R-devel with (if possible) text 
attachments?

The source code says

# 0.1 fudge here matches poisson: S has 1/6.
     initialize <- expression({ n <- rep.int(1, nobs); mustart <- y +
0.1 * (y == 0)})

although I believe S-PLUS has diverged here.

Brian

On Sun, 15 Jan 2006 Bill.Venables at csiro.au wrote:

> This is a multi-part message in MIME format.
>
> ------_=_NextPart_001_01C61962.212F35AB
> Content-Type: text/plain;
> 	charset="us-ascii"
> Content-Transfer-Encoding: quoted-printable
>
> This is not so much a bug as an infelicity in the code that can easily
> be fixed.
>
> The initialize expression in the quasi family function is, (uniformly
> for all links and all variance functions):
>
>
>    initialize <- expression({
>        n <- rep.int(1, nobs)
>        mustart <- y + 0.1 * (y =3D=3D 0)
>    })
>
> This is inappropriate (and often fails) for variance function
> "mu(1-mu)".  Here is a short demo to show it:
> #################################################
>
> set.seed(666)
> dat <- data.frame(x =3D rep((-10):10, each =3D 5), w =3D rep(1:5, 21))
> dat <- transform(dat, y =3D rbinom(x, size =3D w, prob =3D pcauchy(1 +
=
> 2*x)))
>
> modFit <- glm(y/w ~ x, quasi(link =3D cauchit, variance =3D
"mu(1-mu)"),
>              dat, weights =3D w, trace =3D T)
>
> Deviance =3D 309.2785 Iterations - 1=20
> Deviance =3D 3257.501 Iterations - 2=20
> Deviance =3D 1043.455 Iterations - 3=20
> ..
> Deviance =3D 1733.824 Iterations - 24=20
> Deviance =3D 1665.487 Iterations - 25=20
> Warning message:
> algorithm did not converge in: glm.fit(x =3D X, ...
> #################################################
>
> A comprehensive fix would involve tying the initialize expression to
> both the link and the variance function, but that would involve
changing
> make.link(), which is probably not a good idea for other reasons
(though
> ultimately that might be the way to go).  There are at least three
> possible work-arounds:
>
> 1) use quasibinomial for this kind of model (but that's not possible
> here and an unnecessary complication if you are transferring S-PLUS
> code, which is how I found the problem) but quasibinomial could be
> extended to take this link as well, of course.
>
> 2) warn people in the help information that with quasi() they should
> always give the algorithm a bit more help and supply an appropriate
> mustart.   This works fine (even if the coefficient estimates are a
bit
> ropey!):
>
> #################################################
> modFit <- glm(y/w ~ x, quasi(link =3D cauchit, variance =3D
"mu(1-mu)"),
>  dat, weights =3D w, trace =3D T, mustart =3D pmax(0.001, pmin(0.999,
=
> y/w)))
>
> Deviance =3D 218.9552 Iterations - 1=20
> Deviance =3D 123.2773 Iterations - 2=20
> Deviance =3D 86.13804 Iterations - 3=20
> Deviance =3D 74.23746 Iterations - 4=20
> Deviance =3D 72.03787 Iterations - 5=20
> Deviance =3D 71.89566 Iterations - 6=20
> Deviance =3D 71.89395 Iterations - 7=20
> Deviance =3D 71.89395 Iterations - 8=20
> Deviance =3D 71.89395 Iterations - 9=20
>> =20
> #################################################
>
> 3) change quasi() slightly to cover this case, at least, in a better
> way.
>
> I have included a minimally modified version of quasi that I think
> achieves this and the demo shown above.=20
>
> With the changed version the performance, in this case, is identical
to
> what you get above when mustart is supplied.  The changes cannot
affect
> performance with any other variance functions and with this variance
> function should only make things better, but it just _might_ make
things
> work worse in extreme and unusual cases.  I have not found one,
though.
>
> Bill Venables.=20
>
>
>
> --please do not edit the information below--
>
> Version:
> platform =3D i386-pc-mingw32
> arch =3D i386
> os =3D mingw32
> system =3D i386, mingw32
> status =3D=20
> major =3D 2
> minor =3D 2.1
> year =3D 2005
> month =3D 12
> day =3D 20
> svn rev =3D 36812
> language =3D R
>
> Windows XP Professional (build 2600) Service Pack 2.0
>
> Locale:
>
LC_COLLATE=3DEnglish_Australia.1252;LC_CTYPE=3DEnglish_Australia.1252;LC
_=
> MON
>
ETARY=3DEnglish_Australia.1252;LC_NUMERIC=3DC;LC_TIME=3DEnglish_Australi
a=
> .1252
>
> Search Path:
> .GlobalEnv, package:mgcv, package:AusNew, package:MASS, package:RODBC,
> package:lattice, package:splines, package:methods, package:stats,
> package:graphics, package:grDevices, package:datasets,
package:RBigData,
> package:mvbutils, mvb.session.info, package:tools, package:utils,
> package:RBigData, package:RUtilities, package:RBigLibrary,
> package:g.data, Autoloads, package:base
>
> Bill Venables,=20
> CMIS, CSIRO Laboratories,=20
> PO Box 120, Cleveland, Qld. 4163=20
> AUSTRALIA=20
> Office Phone (email preferred): +61 7 3826 7251=20
> Fax (if absolutely necessary):    +61 7 3826 7304=20
> Mobile (rarely used):                +61 4 1963 4642=20
> Home Phone:                          +61 7 3286 7700=20
> mailto:Bill.Venables at csiro.au=20
> http://www.cmis.csiro.au/bill.venables/=20
>
>
>
> ------_=_NextPart_001_01C61962.212F35AB
> Content-Type: application/octet-stream;
> 	name="_quasi.R"
> Content-Transfer-Encoding: base64
> Content-Description: _quasi.R
> Content-Disposition: attachment;
> 	filename="_quasi.R"
>
>
InF1YXNpIiA8LQ0KZnVuY3Rpb24gKGxpbmsgPSAiaWRlbnRpdHkiLCB2YXJpYW5jZSA9ICJj
b25z
>
dGFudCIpIA0Kew0KICAgIGxpbmt0ZW1wIDwtIHN1YnN0aXR1dGUobGluaykNCiAgICBpZiAo
aXMu
>
ZXhwcmVzc2lvbihsaW5rdGVtcCkgfHwgaXMuY2FsbChsaW5rdGVtcCkpIA0KICAgICAgICBs
aW5r
>
dGVtcCA8LSBsaW5rDQogICAgZWxzZSBpZiAoIWlzLmNoYXJhY3RlcihsaW5rdGVtcCkpIA0K
ICAg
>
ICAgICBsaW5rdGVtcCA8LSBkZXBhcnNlKGxpbmt0ZW1wKQ0KICAgIGlmIChpcy5jaGFyYWN0
ZXIo
>
bGlua3RlbXApKSANCiAgICAgICAgc3RhdHMgPC0gbWFrZS5saW5rKGxpbmt0ZW1wKQ0KICAg
IGVs
>
c2Ugc3RhdHMgPC0gbGlua3RlbXANCiAgICB2YXJpYW5jZXRlbXAgPC0gc3Vic3RpdHV0ZSh2
YXJp
>
YW5jZSkNCiAgICBpZiAoIWlzLmNoYXJhY3Rlcih2YXJpYW5jZXRlbXApKSB7DQogICAgICAg
IHZh
>
cmlhbmNldGVtcCA8LSBkZXBhcnNlKHZhcmlhbmNldGVtcCkNCiAgICAgICAgaWYgKGxpbmt0
ZW1w
>
ID09ICJ2YXJpYW5jZSIpIA0KICAgICAgICAgICAgdmFyaWFuY2V0ZW1wIDwtIGV2YWwodmFy
aWFu
>
Y2UpDQogICAgfQ0KICAgIGluaXRpYWxpemUgPC0gTlVMTCAgICAgICAgICAgICAgICAgICAg
ICAg
>
ICAgICAgICAgICAgICAgICAgICAgICAgIyMjIyBjaGFuZ2UNCiAgICBzd2l0Y2godmFyaWFu
Y2V0
>
ZW1wLCBjb25zdGFudCA9IHsNCiAgICAgICAgdmFyaWFuY2UgPC0gZnVuY3Rpb24obXUpIHJl
cC5p
>
bnQoMSwgbGVuZ3RoKG11KSkNCiAgICAgICAgZGV2LnJlc2lkcyA8LSBmdW5jdGlvbih5LCBt
dSwg
>
d3QpIHd0ICogKCh5IC0gbXUpXjIpDQogICAgICAgIHZhbGlkbXUgPC0gZnVuY3Rpb24obXUp
IFRS
>
VUUNCiAgICB9LCAibXUoMS1tdSkiID0gew0KICAgICAgICB2YXJpYW5jZSA8LSBmdW5jdGlv
biht
>
dSkgbXUgKiAoMSAtIG11KQ0KICAgICAgICB2YWxpZG11IDwtIGZ1bmN0aW9uKG11KSBhbGwo
bXUg
>
PiAwKSAmJiBhbGwobXUgPCAxKQ0KICAgICAgICBkZXYucmVzaWRzIDwtIGZ1bmN0aW9uKHks
IG11
>
LCB3dCkgMiAqIHd0ICogKHkgKiBsb2coaWZlbHNlKHkgPT0gDQogICAgICAgICAgICAwLCAx
LCB5
>
L211KSkgKyAoMSAtIHkpICogbG9nKGlmZWxzZSh5ID09IDEsIDEsICgxIC0gDQogICAgICAg
ICAg
>
ICB5KS8oMSAtIG11KSkpKQ0KICAgICAgICBpbml0aWFsaXplIDwtIGV4cHJlc3Npb24oeyAg
ICAg
>
ICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIyMjIyBjaGFuZ2UNCiAgICAgICAgICBu
IDwt
>
IHJlcC5pbnQoMSwgbm9icykgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAg
ICMj
>
IyMgY2hhbmdlDQogICAgICAgICAgbXVzdGFydCA8LSBwbWF4KDAuMDAxLCBwbWluKDAuOTk5
LCB5
>
KSkgICAgICAgICAgICAgICAgICAgICAjIyMjIGNoYW5nZQ0KICAgICAgICB9KSAgICAgICAg
ICAg
>
ICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIyMjIyBj
aGFu
>
Z2UNCiAgICB9LCBtdSA9IHsNCiAgICAgICAgdmFyaWFuY2UgPC0gZnVuY3Rpb24obXUpIG11
DQog
>
ICAgICAgIHZhbGlkbXUgPC0gZnVuY3Rpb24obXUpIGFsbChtdSA+IDApDQogICAgICAgIGRl
di5y
>
ZXNpZHMgPC0gZnVuY3Rpb24oeSwgbXUsIHd0KSAyICogd3QgKiAoeSAqIGxvZyhpZmVsc2Uo
eSA9
>
PSANCiAgICAgICAgICAgIDAsIDEsIHkvbXUpKSAtICh5IC0gbXUpKQ0KICAgIH0sICJtdV4y
IiA9
>
IHsNCiAgICAgICAgdmFyaWFuY2UgPC0gZnVuY3Rpb24obXUpIG11XjINCiAgICAgICAgdmFs
aWRt
>
dSA8LSBmdW5jdGlvbihtdSkgYWxsKG11ID4gMCkNCiAgICAgICAgZGV2LnJlc2lkcyA8LSBm
dW5j
>
dGlvbih5LCBtdSwgd3QpIHBtYXgoLTIgKiB3dCAqIChsb2coaWZlbHNlKHkgPT0gDQogICAg
ICAg
>
ICAgICAwLCAxLCB5KS9tdSkgLSAoeSAtIG11KS9tdSksIDApDQogICAgfSwgIm11XjMiID0g
ew0K
>
ICAgICAgICB2YXJpYW5jZSA8LSBmdW5jdGlvbihtdSkgbXVeMw0KICAgICAgICB2YWxpZG11
IDwt
>
IGZ1bmN0aW9uKG11KSBhbGwobXUgPiAwKQ0KICAgICAgICBkZXYucmVzaWRzIDwtIGZ1bmN0
aW9u
>
KHksIG11LCB3dCkgd3QgKiAoKHkgLSBtdSleMikvKHkgKiANCiAgICAgICAgICAgIG11XjIp
DQog
>
ICAgfSwgc3RvcChnZXR0ZXh0ZigiJ3ZhcmlhbmNlJyBcIiVzXCIgaXMgaW52YWxpZDogcG9z
c2li
>
bGUgdmFsdWVzIGFyZSBcIm11KDEtbXUpXCIsIFwibXVcIiwgXCJtdV4yXCIsIFwibXVeM1wi
IGFu
>
ZCBcImNvbnN0YW50XCIiLCANCiAgICAgICAgdmFyaWFuY2V0ZW1wKSwgZG9tYWluID0gTkEp
KQ0K
>
ICAgIGlmKGlzLm51bGwoaW5pdGlhbGl6ZSkpICAgICAgICAgICAgICAgICAgICAgICAgICAg
ICAg
>
ICAgICAgICAgICAgIyMjIyBjaGFuZ2UNCiAgICBpbml0aWFsaXplIDwtIGV4cHJlc3Npb24o
ew0K
>
ICAgICAgICBuIDwtIHJlcC5pbnQoMSwgbm9icykNCiAgICAgICAgbXVzdGFydCA8LSB5ICsg
MC4x
>
ICogKHkgPT0gMCkNCiAgICB9KQ0KICAgIGFpYyA8LSBmdW5jdGlvbih5LCBuLCBtdSwgd3Qs
IGRl
>
dikgTkENCiAgICBzdHJ1Y3R1cmUobGlzdChmYW1pbHkgPSAicXVhc2kiLCBsaW5rID0gbGlu
a3Rl
>
bXAsIGxpbmtmdW4gPSBzdGF0cyRsaW5rZnVuLCANCiAgICAgICAgbGlua2ludiA9IHN0YXRz
JGxp
>
bmtpbnYsIHZhcmlhbmNlID0gdmFyaWFuY2UsIGRldi5yZXNpZHMgPSBkZXYucmVzaWRzLCAN
CiAg
>
ICAgICAgYWljID0gYWljLCBtdS5ldGEgPSBzdGF0cyRtdS5ldGEsIGluaXRpYWxpemUgPSBp
bml0
>
aWFsaXplLCANCiAgICAgICAgdmFsaWRtdSA9IHZhbGlkbXUsIHZhbGlkZXRhID0gc3RhdHMk
dmFs
>
aWRldGEsIHZhcmZ1biA9IHZhcmlhbmNldGVtcCksIA0KICAgICAgICBjbGFzcyA9ICJmYW1p
bHki
> KQ0KfQ0K
>
> ------_=_NextPart_001_01C61962.212F35AB
> Content-Type: application/octet-stream;
> 	name="demo_quasi.R"
> Content-Transfer-Encoding: base64
> Content-Description: demo_quasi.R
> Content-Disposition: attachment;
> 	filename="demo_quasi.R"
>
>
c2V0LnNlZWQoNjY2KQ0KZGF0IDwtIGRhdGEuZnJhbWUoeCA9IHJlcCgoLTEwKToxMCwgZWFj
aCA9
>
IDUpLCB3ID0gcmVwKDE6NSwgMjEpKQ0KZGF0IDwtIHRyYW5zZm9ybShkYXQsIHkgPSByYmlu
b20o
>
eCwgc2l6ZSA9IHcsIHByb2IgPSBwY2F1Y2h5KDEgKyAyKngpKSkNCg0KbW9kRml0IDwtIGds
bSh5
>
L3cgfiB4LCBxdWFzaShsaW5rID0gY2F1Y2hpdCwgdmFyaWFuY2UgPSAibXUoMS1tdSkiKSwN
CiAg
>
ICAgICAgICAgICAgZGF0LCB3ZWlnaHRzID0gdywgdHJhY2UgPSBUKQ0KDQptb2RGaXQgPC0g
Z2xt
>
KHkvdyB+IHgsIHF1YXNpKGxpbmsgPSBjYXVjaGl0LCB2YXJpYW5jZSA9ICJtdSgxLW11KSIp
LA0K
>
ICAgICAgICAgICAgICBkYXQsIHdlaWdodHMgPSB3LCB0cmFjZSA9IFQsIG11c3RhcnQgPSBw
bWF4
>
KDAuMDAxLCBwbWluKDAuOTk5LCB5L3cpKSkNCiMgcXVhc2kgPC0gcXVhc2kubmV3DQoNCg0K
bW9k
>
Rml0IDwtIGdsbSh5L3cgfiB4LCBxdWFzaShsaW5rID0gY2F1Y2hpdCwgdmFyaWFuY2UgPSAi
bXUo
>
MS1tdSkiKSwNCiAgICAgICAgICAgICAgZGF0LCB3ZWlnaHRzID0gdywgdHJhY2UgPSBUKQ0K
>
> ------_=_NextPart_001_01C61962.212F35AB--
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From epurdom at stanford.edu  Tue Jan 17 03:38:32 2006
From: epurdom at stanford.edu (epurdom@stanford.edu)
Date: Tue, 17 Jan 2006 03:38:32 +0100 (CET)
Subject: [Rd] Error handling in solve.default (PR#8494)
Message-ID: <20060117023832.C12D519FF2@slim.kubism.ku.dk>

Hi, this is a minor problem in solve.default but I didn't see anyone 
mention it. The function does not give "correct" error-handling if given 
non-square matrix, LINPACK=F, and matrix has names attributes (either 
row or column names).

Demo:
##"correct" error handling of non-square matrix
 > temp<-diag(1,5)[,1:4]
 > solve(temp,LINPACK=F)
Error in solve.default(diag(1, 5)[, 1:4], LINPACK = F) :
        'A' (5 x 4) must be square

#indeciferable error handling when same matrix is given names attributes
 > temp<-diag(1,5)[,1:4]
 > rownames(temp)<-as.character(1:5)
 > colnames(temp)<-as.character(1:4)
 > solve(temp,LINPACK=F)
Error in "rownames<-"(`*tmp*`, value = c("1", "2", "3", "4")) :
        length of 'dimnames' [1] not equal to array extent

I think the problem is that if LINPACK=F, then the error handling of the 
argument "a" is not done until after creating a matrix "b", when none 
was given. Then, the function creates a square identity matrix for "b", 
to which it tries to assign row and column names of "a". Of course, 
since "a" is not square, they are not of the correct length.

Best,
Elizabeth


From jonathan.swinton at astrazeneca.com  Tue Jan 17 12:07:59 2006
From: jonathan.swinton at astrazeneca.com (jonathan.swinton@astrazeneca.com)
Date: Tue, 17 Jan 2006 12:07:59 +0100 (CET)
Subject: [Rd] data.matrix returns mode logical for zero rows (PR#8496)
Message-ID: <20060117110759.B161B2074E@slim.kubism.ku.dk>

Full_Name: Jonathan Swinton
Version: 2.2.1
OS: Windows
Submission from: (NULL) (193.132.159.169)


#The first line of description for data.matrix says that it will
#	'Return the matrix obtained by converting all the variables in a
#    data frame to numeric mode and then binding them together as the
#     columns of a matrix.'

#However when called with a data.frame with zero rows, data.matrix returns a
matrix 
#of mode logical rather than numeric. This conflicts with the documentation
#and is not what seems sensible.

# One underlying reason for this is that when a zero-length column of a matrix
of mode logical is 
# asserted to be numeric the matrix is not actually cast to numeric. I wonder if
that too is a bug?

> R.version.string
[1] "R version 2.2.1, 2005-12-20"
> df <- data.frame(matrix(1:2,nrow=2))
> mode(data.matrix(df)[,1])
[1] "numeric"
> mode(data.matrix(df[FALSE,])[,1])
[1] "numeric"
> 
> # Underlying cause
> x <- matrix(nr = 2,nc = 1 )
> mode(x)
[1] "logical"
> x[, 1] <-   c(1,2)
> mode(x)
[1] "numeric"
> 
> x0 <- matrix(nr = 0, nc = 1)
> x0[, 1] <-   numeric(0)
> mode(x0)
[1] "logical"
> mode(x0[,1])
[1] "logical"


From hin-tak.leung at cimr.cam.ac.uk  Tue Jan 17 16:39:17 2006
From: hin-tak.leung at cimr.cam.ac.uk (Hin-Tak Leung)
Date: Tue, 17 Jan 2006 15:39:17 +0000
Subject: [Rd] Section 7.1 HML documentation (PR#8484)
In-Reply-To: <20060114163349.7A9931A001@slim.kubism.ku.dk>
References: <20060114163349.7A9931A001@slim.kubism.ku.dk>
Message-ID: <43CD0FA5.7010208@cimr.cam.ac.uk>

greg.kochanski at phon.ox.ac.uk wrote:
> Full_Name: Greg Kochanski
> Version: 2.2.0
> OS: Debian Linux i686
> Submission from: (NULL) (212.159.16.190)
> 
> 
> In /usr/share/doc/r-doc-html/manual/R-data.html (at least that's where
> it is on Debian...) the documentation is unclear.   Comments below.

The documentation is, I believe, correct and precise as it stands.
What it doesn't emphasize and mention is the difference between
"BSD socket" and "socket connection", or an "R connection of the socket 
type". And it is recommended that you
use "socket connection" instead of "BSD socket".

The earlier "BSD socket" is created, read, write with 
"make.socket"/"read.socket"/"write socket"/"close socket".

The newer "socket connection" is created by creating a new connection 
object like this:
      con <- socketConnection(port = 79, blocking = TRUE)
and invoking the open/write/read method of the "connection"
object. type "?connection" in an R prompt for details.

"BSD socket" is a unix concept, "socket connection" is an R object.
The paragraph should have put "BSD socket" and "socket connection"
in quote or italics. Make more sense?

Somebody please fix the paragraph... :-).

> The paragraph has unclear references, and I have no idea what
> it actually means.
> 
> 
>>>Base R comes with some facilities to communicate via BSD sockets on systems
> 
> that support them (...). One potential problem....
> 
>>>For new projects it is suggested that socket connections are used instead.
> 
> 
> "Used instead"?   Instead of what?
> 
> 
>>>The earlier low-level interface is given by functions make.socket,
> 
> read.socket, write.socket and close.socket. 
> 
> What does "earlier" mean?   Earlier than what?
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From greg.kochanski at phonetics.oxford.ac.uk  Tue Jan 17 17:45:06 2006
From: greg.kochanski at phonetics.oxford.ac.uk (Greg Kochanski)
Date: Tue, 17 Jan 2006 16:45:06 +0000
Subject: [Rd] Section 7.1 HML documentation (PR#8484)
In-Reply-To: <43CD0FA5.7010208@cimr.cam.ac.uk>
References: <20060114163349.7A9931A001@slim.kubism.ku.dk>
	<43CD0FA5.7010208@cimr.cam.ac.uk>
Message-ID: <43CD1F12.80506@phon.ox.ac.uk>

Well, I don't know how it can be precise
and correct when it has dangling antecedents.
Gramatically speaking, that's the equivalent of
an uninitialized pointer.

However, I agree with you that it probably just
needs a minor bit of fiddling to make sure it
answers "Instead of what?" and "Earlier than what?"


Hin-Tak Leung wrote:
> greg.kochanski at phon.ox.ac.uk wrote:
> 
>> Full_Name: Greg Kochanski
>> Version: 2.2.0
>> OS: Debian Linux i686
>> Submission from: (NULL) (212.159.16.190)
>>
>>
>> In /usr/share/doc/r-doc-html/manual/R-data.html (at least that's where
>> it is on Debian...) the documentation is unclear.   Comments below.
> 
> 
> The documentation is, I believe, correct and precise as it stands.
> What it doesn't emphasize and mention is the difference between
> "BSD socket" and "socket connection", or an "R connection of the socket 
> type". And it is recommended that you
> use "socket connection" instead of "BSD socket".
> 
> The earlier "BSD socket" is created, read, write with 
> "make.socket"/"read.socket"/"write socket"/"close socket".
> 
> The newer "socket connection" is created by creating a new connection 
> object like this:
>      con <- socketConnection(port = 79, blocking = TRUE)
> and invoking the open/write/read method of the "connection"
> object. type "?connection" in an R prompt for details.
> 
> "BSD socket" is a unix concept, "socket connection" is an R object.
> The paragraph should have put "BSD socket" and "socket connection"
> in quote or italics. Make more sense?
> 
> Somebody please fix the paragraph... :-).
> 
>> The paragraph has unclear references, and I have no idea what
>> it actually means.
>>
>>
>>>> Base R comes with some facilities to communicate via BSD sockets on 
>>>> systems
>>
>>
>> that support them (...). One potential problem....
>>
>>>> For new projects it is suggested that socket connections are used 
>>>> instead.
>>
>>
>>
>> "Used instead"?   Instead of what?
>>
>>
>>>> The earlier low-level interface is given by functions make.socket,
>>
>>
>> read.socket, write.socket and close.socket.
>> What does "earlier" mean?   Earlier than what?
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 
> 
>


From Friedrich.Leisch at tuwien.ac.at  Tue Jan 17 18:33:35 2006
From: Friedrich.Leisch at tuwien.ac.at (Friedrich.Leisch@tuwien.ac.at)
Date: Tue, 17 Jan 2006 18:33:35 +0100
Subject: [Rd] CRAN mirror at StatLib
Message-ID: <17357.10863.714194.577278@galadriel.ci.tuwien.ac.at>

Dear Pantelis,

there have been numerous reports on the R mailing lists that the
StatLib mirror of CRAN is not up to date, and I also have written
several emails to you asking about the nature of the problems. E.g.,

	http://lib.stat.cmu.edu/R/CRAN/bin/windows/contrib/

shows an old listing, and

	http://lib.stat.cmu.edu/R/CRAN/bin/windows/contrib/r-release/

points to the wrong directory giving packages for the development
version of R rather then the released version (on the master it is a
link to 2.2, on your copy it seems to be a link to 2.3).

If the problems persist and cannot be fixed it is perhaps the easiest
solution if you stop mirroring CRAN, as download problems from StatLib
get reported to us as "bugs in R".

With best regards,
Fritz Leisch

-- 
-------------------------------------------------------------------
                        Friedrich Leisch 
Institut f?r Statistik                     Tel: (+43 1) 58801 10715
Technische Universit?t Wien                Fax: (+43 1) 58801 10798
Wiedner Hauptstra?e 8-10/1071
A-1040 Wien, Austria             http://www.ci.tuwien.ac.at/~leisch


From tlumley at u.washington.edu  Tue Jan 17 20:13:41 2006
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 17 Jan 2006 11:13:41 -0800 (PST)
Subject: [Rd] [OT] GPL3 draft
Message-ID: <Pine.LNX.4.43.0601171113410.7252@hymn06.u.washington.edu>



Since someone is bound to point this out soon I will note that

a) A discussion draft of the proposed GPL version 3 is up at 
http://gplv3.fsf.org/


b) If you have comments on the draft, send them to the FSF rather than to r-devel


      -thomas

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle


From gregory.r.warnes at pfizer.com  Tue Jan 17 20:48:46 2006
From: gregory.r.warnes at pfizer.com (Warnes, Gregory R)
Date: Tue, 17 Jan 2006 14:48:46 -0500
Subject: [Rd] natural sorting
Message-ID: <915D2D65A9986440A277AC5C98AA466F018637D8@groamrexm02.amer.pfizer.com>

The 'mixedsort' function in the 'gtools' package does this.  It is probably slower than the c version you point to, but it is already working in R.

-G

> -----Original Message-----
> From: r-devel-bounces at r-project.org
> [mailto:r-devel-bounces at r-project.org]On Behalf Of Andrew Piskorski
> Sent: Thursday, January 12, 2006 10:40 AM
> To: R Development Mailing List
> Subject: Re: [Rd] natural sorting
> 
> 
> On Wed, Jan 11, 2006 at 05:45:10PM -0500, Gabor Grothendieck wrote:
> > It would be nifty to incorporate this into R or into an R package:
> > 
> > http://sourcefrog.net/projects/natsort/
> 
> Btw, I haven't looked at the implementation, but Tcl also contains
> equivalent functionality, they call it dictionary sort:
> 
>   http://tcl.activestate.com/man/tcl8.4/TclCmd/lsort.htm
> 
> -- 
> Andrew Piskorski <atp at piskorski.com>
> http://www.piskorski.com/
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
----------------------------------------------------------------------
LEGAL NOTICE\ Unless expressly stated otherwise, this messag...{{dropped}}


From bolker at zoo.ufl.edu  Wed Jan 18 00:02:09 2006
From: bolker at zoo.ufl.edu (Ben Bolker)
Date: Tue, 17 Jan 2006 18:02:09 -0500
Subject: [Rd] nls profile with port/constraints
Message-ID: <43CD7771.60506@zoo.ufl.edu>


   Sorry to report further difficulties with
nls and profiling and constraints ... the problem
this time (which I didn't check for in my last
round of testing) is that the nls profiler doesn't
seem to respect constraints that have been
set when using the port algorithm.
   See test code below ...
   If I can I will try to hack the code, but I will
probably start by redefining my function with
some workarounds to make the fit quadratically "bad" (but well-defined)
when the parameters are negative ...
    As always, please don't hesitate to correct me
if I'm being an idiot ...

   cheers
     Ben Bolker

-----------------------
rm(list=ls())

npts=10
set.seed(1001)

a =2
b =0.5
x= runif(npts)
y = a*x/(1+a*b*x)+rnorm(npts,sd=0.2)

gfun <- function(a,b,x) {
   if (a<0 || b<0) stop("bounds violated")
   a*x/(1+a*b*x)
}

m1 = nls(y~gfun(a,b,x),algorithm="port",
   lower=c(0,0),start=c(a=1,b=1))

try(confint(m1))
----------------


for what it's worth, the logic appears to be OK in mle in the stats4
library:
--------------
library(stats4)

mfun <- function(a,b,s) {
   if (a<0 || b<0 || s<0) stop("bounds violated")
   -sum(dnorm(y,a*x/(1+a*b*x),sd=s,log=TRUE))
}

m2 = mle(minuslogl=mfun,
   start=list(a=1,b=1,s=0.1),
   method="L-BFGS-B",lower=c(0.002,0.002,0.002))

confint(m2)


m2b = mle(minuslogl=mfun,
   fixed=list(b=0),start=list(a=1,s=0.1),
   method="L-BFGS-B",lower=c(0.002,0.002,0.002))
## set boundary slightly above zero to avoid
## boundary cases

dev <- 2*(-logLik(m2b)+logLik(m2))
as.numeric(pchisq(dev,lower.tail=FALSE,df=1))


-- 
620B Bartram Hall                            bolker at zoo.ufl.edu
Zoology Department, University of Florida    http://www.zoo.ufl.edu/bolker
Box 118525                                   (ph)  352-392-5697
Gainesville, FL 32611-8525                   (fax) 352-392-3704


From maechler at stat.math.ethz.ch  Wed Jan 18 09:54:47 2006
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 18 Jan 2006 09:54:47 +0100
Subject: [Rd] symbols function -- possible enhancements
In-Reply-To: <Pine.LNX.4.61.0601172306550.32358@gannet.stats>
References: <Pine.LNX.4.43.0601171337360.7252@hymn06.u.washington.edu>
	<Pine.LNX.4.61.0601172306550.32358@gannet.stats>
Message-ID: <17358.599.749665.458231@stat.math.ethz.ch>

Hi Jean,

now that you've been told  `the truth' ..  :

If you'd like to carefully look at symbols() and its help page and see
which arguments ('axes' but maybe more) would be useful to pass
to plot.default and if you provide enhanced versions of the two files
     https://svn.r-project.org/R/trunk/src/library/graphics/R/symbols.R
and  https://svn.r-project.org/R/trunk/src/library/graphics/man/symbols.Rd

I'll gladly look at them and incorporate them for R 2.3.0
(unless they break something)

Best regards,
Martin Maechler


>>>>> "BDR" == Prof Brian Ripley <ripley at stats.ox.ac.uk>
>>>>>     on Tue, 17 Jan 2006 23:15:19 +0000 (GMT) writes:

    BDR> On Tue, 17 Jan 2006, Thomas Lumley wrote:
    >> On Tue, 17 Jan 2006, Jean Eid wrote:
    >> 
    >>> Hi
    >>> 
    >>> I do not get why the symbols function produces warnings when axes=F is
    >>> added. The following example illustrate this
    >>> 
    >>>> symbols(0,10, inches=T, circles=1, axes=F, xlab="", ylab="")
    >>> Warning message:
    >>> parameter "axes" could not be set in high-level plot() function
    >>> 
    >>> 
    >>> I augmented symbols and added the axes=F argument to the plot function
    >>> inside the original symbols function. It works as expected, no warning
    >>> message. I am just lost as to why the extra arguments in symbols (...)
    >>> are not behaving as expected.
    >>> 
    >> 
    >> The ... argument is also passed to .Internal, and presumably the code 
    >> there gives the warning.

    BDR> Indeed.  axes=F is not in the allowed list

    BDR> ...: graphics parameters can also be passed to this function, as
    BDR> can the plot aspect ratio 'asp' (see 'plot.window').

    BDR> People confuse 'axes' with the graphics parameters, but it is in fact an 
    BDR> argument to plot.default.  (The corresponding graphics parameters
    BDR> xaxt and yaxt do work.)  R-devel gives a more informative message:

    >> attach(trees)
    >> symbols(Height, Volume, circles = Girth/24, inches = FALSE, axes=F)
    BDR> Warning message:
    BDR> "axes" is not a graphical parameter in: symbols(x, y, type, data, inches, 
    BDR> bg, fg, ...)

    BDR> We do ask people to read the help pages before posting for a good reason: 
    BDR> the information is usually there in a more complete and accurate form than 
    BDR> people remember.

    BDR> -- 
    BDR> Brian D. Ripley,                  ripley at stats.ox.ac.uk
    BDR> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
    BDR> University of Oxford,             Tel:  +44 1865 272861 (self)
    BDR> 1 South Parks Road,                     +44 1865 272866 (PA)
    BDR> Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From maechler at stat.math.ethz.ch  Wed Jan 18 10:02:24 2006
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 18 Jan 2006 10:02:24 +0100
Subject: [Rd] natural sorting
In-Reply-To: <915D2D65A9986440A277AC5C98AA466F018637D8@groamrexm02.amer.pfizer.com>
References: <915D2D65A9986440A277AC5C98AA466F018637D8@groamrexm02.amer.pfizer.com>
Message-ID: <17358.1056.894105.125923@stat.math.ethz.ch>

>>>>> "Greg" == Warnes, Gregory R <gregory.r.warnes at pfizer.com>
>>>>>     on Tue, 17 Jan 2006 14:48:46 -0500 writes:

    Greg> The 'mixedsort' function in the 'gtools' package does
    Greg> this.  It is probably slower than the c version you
    Greg> point to, but it is already working in R.

Thank you, Greg.

BTW, given the thread, this is a typical example where it might
be very useful to add the following two concepts to the 
   mixedsort.Rd file in gtools :

\concept{natural sort}
\concept{dictionary sort}

so that mixedsort() will be quickly found by help.search("natural sort")
and possibly also via the java search from the HTML help interface?
(I never use it; I use help.search() {or then RSiteSearch()}
 exclusively.)

Martin


    >> -----Original Message-----
    >> From: r-devel-bounces at r-project.org
    >> [mailto:r-devel-bounces at r-project.org]On Behalf Of Andrew Piskorski
    >> Sent: Thursday, January 12, 2006 10:40 AM
    >> To: R Development Mailing List
    >> Subject: Re: [Rd] natural sorting
    >> 
    >> 
    >> On Wed, Jan 11, 2006 at 05:45:10PM -0500, Gabor Grothendieck wrote:
    >> > It would be nifty to incorporate this into R or into an R package:
    >> > 
    >> > http://sourcefrog.net/projects/natsort/
    >> 
    >> Btw, I haven't looked at the implementation, but Tcl also contains
    >> equivalent functionality, they call it dictionary sort:
    >> 
    >> http://tcl.activestate.com/man/tcl8.4/TclCmd/lsort.htm
    >> 
    >> -- 
    >> Andrew Piskorski <atp at piskorski.com>
    >> http://www.piskorski.com/


From hin-tak.leung at cimr.cam.ac.uk  Wed Jan 18 10:48:18 2006
From: hin-tak.leung at cimr.cam.ac.uk (Hin-Tak Leung)
Date: Wed, 18 Jan 2006 09:48:18 +0000
Subject: [Rd] Section 7.1 HML documentation (PR#8484)
In-Reply-To: <43CD1F12.80506@phon.ox.ac.uk>
References: <20060114163349.7A9931A001@slim.kubism.ku.dk>
	<43CD0FA5.7010208@cimr.cam.ac.uk> <43CD1F12.80506@phon.ox.ac.uk>
Message-ID: <43CE0EE2.5010207@cimr.cam.ac.uk>

Greg Kochanski wrote:
> Well, I don't know how it can be precise
> and correct when it has dangling antecedents.
> Gramatically speaking, that's the equivalent of
> an uninitialized pointer.

I don't think there is anything "dangling" there. What the paragraph 
assumes (and quite patently wrongly) is that the reader had encountered 
the concept of "R connection object of the socket type" elsewhere. 
Without that background, one tends to interprete the phrase "socket
connection" in the traditional unix sense (i.e. = "BSD socket"), and
hence one reads the paragraph as " XXX is older than XXX and XXX is
newer than XXX and there had been potential problems with XXX and
one should use XXX instead (of XXX)".

> However, I agree with you that it probably just
> needs a minor bit of fiddling to make sure it
> answers "Instead of what?" and "Earlier than what?"

I have re-read R-data and it seems the fault is yours. Because 
"Connection" is mentioned in quite a major way and is the entire subject
of chapter 6 and comes earlier than the paragraph you quoted in
chapter 7. So it seems to be your own fault of trying to
understand chapter 7 without noticing the header of chapter 6
nor reading it!

===============
6 Connections

"Connections" are used in R in the sense of Chambers (1998), a set of 
functions to replace the use
of file names by a flexible interface to file-like objects.

...

6.1 Types of connections

...
Sockets can also be used as connections via function socketConnection on 
platforms which
support Berkeley-like sockets (most Unix systems, Linux and Windows). 
Sockets can be written
to or read from, and both client and server sockets can be used.
...

7 Network interfaces
Some limited facilities are available to exchange data at a lower level 
across network connections.

7.1 Reading from sockets

...<the paragraph concerned>
=====================



> Hin-Tak Leung wrote:
> 
>> greg.kochanski at phon.ox.ac.uk wrote:
>>
>>> Full_Name: Greg Kochanski
>>> Version: 2.2.0
>>> OS: Debian Linux i686
>>> Submission from: (NULL) (212.159.16.190)
>>>
>>>
>>> In /usr/share/doc/r-doc-html/manual/R-data.html (at least that's where
>>> it is on Debian...) the documentation is unclear.   Comments below.
>>
>>
>>
>> The documentation is, I believe, correct and precise as it stands.
>> What it doesn't emphasize and mention is the difference between
>> "BSD socket" and "socket connection", or an "R connection of the 
>> socket type". And it is recommended that you
>> use "socket connection" instead of "BSD socket".
>>
>> The earlier "BSD socket" is created, read, write with 
>> "make.socket"/"read.socket"/"write socket"/"close socket".
>>
>> The newer "socket connection" is created by creating a new connection 
>> object like this:
>>      con <- socketConnection(port = 79, blocking = TRUE)
>> and invoking the open/write/read method of the "connection"
>> object. type "?connection" in an R prompt for details.
>>
>> "BSD socket" is a unix concept, "socket connection" is an R object.
>> The paragraph should have put "BSD socket" and "socket connection"
>> in quote or italics. Make more sense?
>>
>> Somebody please fix the paragraph... :-).
>>
>>> The paragraph has unclear references, and I have no idea what
>>> it actually means.
>>>
>>>
>>>>> Base R comes with some facilities to communicate via BSD sockets on 
>>>>> systems
>>>
>>>
>>>
>>> that support them (...). One potential problem....
>>>
>>>>> For new projects it is suggested that socket connections are used 
>>>>> instead.
>>>
>>>
>>>
>>>
>>> "Used instead"?   Instead of what?
>>>
>>>
>>>>> The earlier low-level interface is given by functions make.socket,
>>>
>>>
>>>
>>> read.socket, write.socket and close.socket.
>>> What does "earlier" mean?   Earlier than what?
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>>
>>
>>


From utz.pape at molgen.mpg.de  Wed Jan 18 10:55:07 2006
From: utz.pape at molgen.mpg.de (utz.pape@molgen.mpg.de)
Date: Wed, 18 Jan 2006 10:55:07 +0100 (CET)
Subject: [Rd] phyper returns 1 if x==k (PR#8499)
Message-ID: <20060118095507.D636728F9B@slim.kubism.ku.dk>

Full_Name: Utz J. Pape
Version: 2.2.0
OS: linux
Submission from: (NULL) (141.14.23.12)


If I use phyper and set parameter x equal to k (meaning that all balls I draw
are white) phyper returns 1 which is not (always) correct:

pape at xxx:~> R2.2.0 --vanilla

R : Copyright 2005, The R Foundation for Statistical Computing
Version 2.2.0  (2005-10-06 r35749)
ISBN 3-900051-07-0

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for a HTML browser interface to help.
Type 'q()' to quit R.

> x <- 10; m <- 20; n <- 5; k <- 10
> phyper(x,m,n,k)
[1] 1
> choose(m,x) * choose(n,k-x) / choose(m+n,k)
[1] 0.05652174
> version
         _                
platform i686-pc-linux-gnu
arch     i686             
os       linux-gnu        
system   i686, linux-gnu  
status                    
major    2                
minor    2.0              
year     2005             
month    10               
day      06               
svn rev  35749            
language R                
> sessionInfo()
R version 2.2.0, 2005-10-06, i686-pc-linux-gnu 

attached base packages:
[1] "methods"   "stats"     "graphics"  "grDevices" "utils"     "datasets" 
[7] "base"


From ripley at stats.ox.ac.uk  Wed Jan 18 11:01:24 2006
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Wed, 18 Jan 2006 11:01:24 +0100 (CET)
Subject: [Rd] phyper returns 1 if x==k (PR#8499)
Message-ID: <20060118100124.E668928F9D@slim.kubism.ku.dk>

On Wed, 18 Jan 2006 utz.pape at molgen.mpg.de wrote:

> Full_Name: Utz J. Pape
> Version: 2.2.0
> OS: linux
> Submission from: (NULL) (141.14.23.12)
>
>
> If I use phyper and set parameter x equal to k (meaning that all balls I draw
> are white) phyper returns 1 which is not (always) correct:

I think you are confusing this with dhyper.  How can you possibly get more 
white balls than exist in the urn?  That you cannot is what p = 1 is 
telling you.

We do quite specifically ask you not to report on obselete versions of R.
Of course, as this is NOT A BUG, it is the same in the current R.

>
> pape at xxx:~> R2.2.0 --vanilla
>
> R : Copyright 2005, The R Foundation for Statistical Computing
> Version 2.2.0  (2005-10-06 r35749)
> ISBN 3-900051-07-0
>
> R is free software and comes with ABSOLUTELY NO WARRANTY.
> You are welcome to redistribute it under certain conditions.
> Type 'license()' or 'licence()' for distribution details.
>
> R is a collaborative project with many contributors.
> Type 'contributors()' for more information and
> 'citation()' on how to cite R or R packages in publications.
>
> Type 'demo()' for some demos, 'help()' for on-line help, or
> 'help.start()' for a HTML browser interface to help.
> Type 'q()' to quit R.
>
>> x <- 10; m <- 20; n <- 5; k <- 10
>> phyper(x,m,n,k)
> [1] 1
>> choose(m,x) * choose(n,k-x) / choose(m+n,k)
> [1] 0.05652174
>> version
>         _
> platform i686-pc-linux-gnu
> arch     i686
> os       linux-gnu
> system   i686, linux-gnu
> status
> major    2
> minor    2.0
> year     2005
> month    10
> day      06
> svn rev  35749
> language R
>> sessionInfo()
> R version 2.2.0, 2005-10-06, i686-pc-linux-gnu
>
> attached base packages:
> [1] "methods"   "stats"     "graphics"  "grDevices" "utils"     "datasets"
> [7] "base"
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From greg.kochanski at phonetics.oxford.ac.uk  Wed Jan 18 11:25:52 2006
From: greg.kochanski at phonetics.oxford.ac.uk (Greg Kochanski)
Date: Wed, 18 Jan 2006 10:25:52 +0000
Subject: [Rd] Section 7.1 HML documentation (PR#8484)
In-Reply-To: <43CE0EE2.5010207@cimr.cam.ac.uk>
References: <20060114163349.7A9931A001@slim.kubism.ku.dk>
	<43CD0FA5.7010208@cimr.cam.ac.uk> <43CD1F12.80506@phon.ox.ac.uk>
	<43CE0EE2.5010207@cimr.cam.ac.uk>
Message-ID: <43CE17B0.1010509@phon.ox.ac.uk>

Well, you make two very strong assumptions.

First, that your readers start in the beginning and read to the
end.
Second, that your readers are sufficiently dedicated to learn
your terminology.

The first is false:  I got to that page via Google.
The second is only true in varying degrees,
and I wouldn't depend on it too strongly.

When writing documentation, you really have to write for
the case of someone who has a specific problem and wants
to understand that problem as quickly as possible.
That means the manuals should have "local support" --
most of what you need to know should be in one place, and
everything else should be referenced or hyperlinked.

Speaking almost professionally (since I'm almost a linguist),
the word "instead" is normally used in the form "instead of X",
and you can only delete the "of X" when X is clear and obvious.

For instance, one wouldn't just write

"I go to work instead."

because your readers won't know the
alternative to work.
Likewise, with "earlier":  the underlying form is
"earlier than Y", and you can only delete "than Y" when your
readers are quite clear what you are comparing to.

That's what I meant by "dangling": that X and Y were not clear.

Hin-Tak Leung wrote:
> Greg Kochanski wrote:
> 
>> Well, I don't know how it can be precise
>> and correct when it has dangling antecedents.
>> Gramatically speaking, that's the equivalent of
>> an uninitialized pointer.
> 
> 
> I don't think there is anything "dangling" there. What the paragraph 
> assumes (and quite patently wrongly) is that the reader had encountered 
> the concept of "R connection object of the socket type" elsewhere. 
> Without that background, one tends to interprete the phrase "socket
> connection" in the traditional unix sense (i.e. = "BSD socket"), and
> hence one reads the paragraph as " XXX is older than XXX and XXX is
> newer than XXX and there had been potential problems with XXX and
> one should use XXX instead (of XXX)".

Yep.


> 
>> However, I agree with you that it probably just
>> needs a minor bit of fiddling to make sure it
>> answers "Instead of what?" and "Earlier than what?"
> 
> 
> I have re-read R-data and it seems the fault is yours. Because 
> "Connection" is mentioned in quite a major way and is the entire subject
> of chapter 6 and comes earlier than the paragraph you quoted in
> chapter 7. So it seems to be your own fault of trying to
> understand chapter 7 without noticing the header of chapter 6
> nor reading it!

That may be so, but it is irrelevant.   The object of this
exercise is not to assign blame, but to make the software
more useful for the next user.

Consequently, you might want to fix it (even if it is my fault),
so long as it is likely to help the next guy (even if it is his fault).
And, I contend that a lot more people Google into the middle
of the documentation than read it from beginning to end.  QED.


From greg.kochanski at phonetics.oxford.ac.uk  Wed Jan 18 11:26:09 2006
From: greg.kochanski at phonetics.oxford.ac.uk (greg.kochanski@phonetics.oxford.ac.uk)
Date: Wed, 18 Jan 2006 11:26:09 +0100 (CET)
Subject: [Rd] Section 7.1 HML documentation (PR#8484)
Message-ID: <20060118102609.3B9E128FB0@slim.kubism.ku.dk>

Well, you make two very strong assumptions.

First, that your readers start in the beginning and read to the
end.
Second, that your readers are sufficiently dedicated to learn
your terminology.

The first is false:  I got to that page via Google.
The second is only true in varying degrees,
and I wouldn't depend on it too strongly.

When writing documentation, you really have to write for
the case of someone who has a specific problem and wants
to understand that problem as quickly as possible.
That means the manuals should have "local support" --
most of what you need to know should be in one place, and
everything else should be referenced or hyperlinked.

Speaking almost professionally (since I'm almost a linguist),
the word "instead" is normally used in the form "instead of X",
and you can only delete the "of X" when X is clear and obvious.

For instance, one wouldn't just write

"I go to work instead."

because your readers won't know the
alternative to work.
Likewise, with "earlier":  the underlying form is
"earlier than Y", and you can only delete "than Y" when your
readers are quite clear what you are comparing to.

That's what I meant by "dangling": that X and Y were not clear.

Hin-Tak Leung wrote:
> Greg Kochanski wrote:
> 
>> Well, I don't know how it can be precise
>> and correct when it has dangling antecedents.
>> Gramatically speaking, that's the equivalent of
>> an uninitialized pointer.
> 
> 
> I don't think there is anything "dangling" there. What the paragraph 
> assumes (and quite patently wrongly) is that the reader had encountered 
> the concept of "R connection object of the socket type" elsewhere. 
> Without that background, one tends to interprete the phrase "socket
> connection" in the traditional unix sense (i.e. = "BSD socket"), and
> hence one reads the paragraph as " XXX is older than XXX and XXX is
> newer than XXX and there had been potential problems with XXX and
> one should use XXX instead (of XXX)".

Yep.


> 
>> However, I agree with you that it probably just
>> needs a minor bit of fiddling to make sure it
>> answers "Instead of what?" and "Earlier than what?"
> 
> 
> I have re-read R-data and it seems the fault is yours. Because 
> "Connection" is mentioned in quite a major way and is the entire subject
> of chapter 6 and comes earlier than the paragraph you quoted in
> chapter 7. So it seems to be your own fault of trying to
> understand chapter 7 without noticing the header of chapter 6
> nor reading it!

That may be so, but it is irrelevant.   The object of this
exercise is not to assign blame, but to make the software
more useful for the next user.

Consequently, you might want to fix it (even if it is my fault),
so long as it is likely to help the next guy (even if it is his fault).
And, I contend that a lot more people Google into the middle
of the documentation than read it from beginning to end.  QED.


From ripley at stats.ox.ac.uk  Wed Jan 18 12:55:16 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 18 Jan 2006 11:55:16 +0000 (GMT)
Subject: [Rd] Minumum memory requirements to run R.
Message-ID: <Pine.LNX.4.61.0601181149400.9400@gannet.stats>

Quite a while back we set the goal of running R in 16Mb RAM, as people (I 
think Kjetil) had teaching labs that small.

Since then R has grown, and we has recently started to optimize R for 
speed rather than size.  I recently tested R-devel on my ancient Win98 
notebook with 64Mb RAM -- it ran but startup was rather slow on what I 
think is a 233MHz processor and very slow disc.

R still runs in 16Mb, but that is getting tight.  Does anyone have any 
need to run on a smaller machine than my 64Mb notebook?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From Heather.Turner at warwick.ac.uk  Wed Jan 18 13:09:16 2006
From: Heather.Turner at warwick.ac.uk (Heather Turner)
Date: Wed, 18 Jan 2006 12:09:16 +0000
Subject: [Rd] Loading of namespace on load of .Rdata (was strange
	behaviour	of load)
Message-ID: <s3ce2ffa.094@liberator.csv.warwick.ac.uk>

Last week Giovanni Parrinello posted a message asking why various packages were loaded when he loaded an .Rdata file. Brian Ripley replied saying he thought it was because the saved workspace contained a reference to the namespace of ipred. (Correspondence copied below).

This begs the question: how did the reference to the namespace of ipred come to be in the .Rdata file? Brian did say it is likely to be because the workspace contained object(s) saved with environment the namespace of ipred - but how would this come about?

In this case I think is because the .Rdata file contained an object whose *parent* environment was the namespace of ipred. Take the following example from ?bagging (having loaded ipred):

> data(BreastCancer)
> 
> mod <- bagging(Class ~ Cl.thickness + Cell.size
+                 + Cell.shape + Marg.adhesion   
+                 + Epith.c.size + Bare.nuclei   
+                 + Bl.cromatin + Normal.nucleoli
+                 + Mitoses, data=BreastCancer, coob=TRUE)
>
> environment(mod$mtrees[[1]]$btree$terms)
<environment: 024E8138>
>
> parent.env(environment(mod$mtrees[[1]]$btree$terms))
<environment: namespace:ipred>

This occurs because the terms object is taken from the model frame which was evaluated within the environment of a function from the ipred package (here ipred:::irpart).

Therefore I think the behaviour observed by Giovanni will only occur in unusual circumstances: when the workspace contains a formula object, a terms object, a function, or some other object with a non-NULL environment, which has been created in the environment of a packaged function. In particular, this would not always occur with a packaged model fitting function, e.g. (from ?loglm in MASS)

> library(MASS)
> minn38a <- array(0, c(3,4,7,2), lapply(minn38[, -5], levels))
> minn38a[data.matrix(minn38[,-5])] <- minn38$f
> fm <- loglm(~1 + 2 + 3 + 4, minn38a)  
> environment(fm$terms)
<environment: R_GlobalEnv>

in this case because the terms component is obtained from the formula, whose environment is .GlobalEnv.

So, I have two points on this (more for R-devel than R-help now)

1. There is a more general situation where it would be useful to load the namespace of a package after loading a saved workspace: when the workspace contains objects of a class for which special methods are required. E.g. if 'fm' from the example above were saved in a workspace, the namespace of MASS would not be loaded when the workspace was loaded into R. Thus unless MASS was loaded by the user, default methods would be used by summary(), print() etc rather than the specialised methods for objects of class "loglm".

Of course the user should quickly realise this, but there may be cases where the default method gives a convincing but incorrect or unhelpful result. An alternative would be to add an attribute to objects of class "loglm" (say), e.g. attr(loglmObject, ".Environment") <- environment(MASS)
so that the namespace would automatically be loaded when it is required. [In fact alternatives such as environment(loglmObject) <- environment(MASS) or loglmObject$anyoldthing <- environment(MASS) would work just as well, but perhaps the first suggestion is neatest.].

What do others think of this idea? Should it (or an equivalent idea) be encouraged amongst package writers?

2. In the case highlighted by Giovanni, the namespace of ipred was loaded, but the package was not. This would be fine, except that the packages on which ipred depends *were* loaded. This seems inconsistent. I guess as long as there are packages without namespaces though, this is the only way to proceed. Perhaps in the meantime, package authors should be encouraged to use importFrom() rather than import()? Or perhaps where packages do have namespaces, only the namespace should be loaded in such a case.

Heather

> From: Prof Brian Ripley <ripley at stats.ox.ac.uk>
> Date: 12 January 2006 08:21:35 GMT
> To: giovanni parrinello <parrinel at med.unibs.it>
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] Strange behaviour of load
>
> On Wed, 11 Jan 2006, giovanni parrinello wrote:
>
>> Dear All,
>> simetimes when I load an Rdata I get this message
>>
>> #######
>> Code:
>>
>> load('bladder1.RData')
>> Carico il pacchetto richiesto: rpart ( Bad traslastion: Load required 
>> package-...)
>> Carico il pacchetto richiesto: MASS
>> Carico il pacchetto richiesto: mlbench
>> Carico il pacchetto richiesto: survival
>> Carico il pacchetto richiesto: splines
>>
>> Carico il pacchetto richiesto: 'survival'
>>
>>
>>        The following object(s) are masked from package:Hmisc :
>>
>>         untangle.specials
>>
>> Carico il pacchetto richiesto: class
>> Carico il pacchetto richiesto: nnet
>> #########
>>
>> So  I have many unrequired packages loaded.
>> Any idea?
>
> They are required!  My guess is that you have object(s) saved with
> environment the namespace of some package, and loading that namespace 
> is
> pulling these in.  The only CRAN package which requires mlbench 
> appears to
> be ipred, and that requires all of those except splines, required by
> survival.
>
> So I believe you have been using ipred and have saved a reference to 
> its
> namespace.
>
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html

Dr H Turner
Research Assistant
Dept. of Statistics
The University of Warwick
Coventry
CV4 7AL

Tel: 024 76575870
Url: www.warwick.ac.uk/go/heatherturner


From ripley at stats.ox.ac.uk  Wed Jan 18 14:31:08 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 18 Jan 2006 13:31:08 +0000 (GMT)
Subject: [Rd] Loading of namespace on load of .Rdata (was strange
 behaviour of load)
In-Reply-To: <s3ce2ffa.094@liberator.csv.warwick.ac.uk>
References: <s3ce2ffa.094@liberator.csv.warwick.ac.uk>
Message-ID: <Pine.LNX.4.61.0601181308390.17452@gannet.stats>

On Wed, 18 Jan 2006, Heather Turner wrote:

[Lines wrapped for legibility and R-help removed as it is not an 
appropriate list.]

> Last week Giovanni Parrinello posted a message asking why various 
> packages were loaded when he loaded an .Rdata file. Brian Ripley replied 
> saying he thought it was because the saved workspace contained a 
> reference to the namespace of ipred. (Correspondence copied below).
>
> This begs the question: how did the reference to the namespace of ipred 
> come to be in the .Rdata file? Brian did say it is likely to be because 
> the workspace contained object(s) saved with environment the namespace 
> of ipred - but how would this come about?
>
> In this case I think is because the .Rdata file contained an object 
> whose *parent* environment was the namespace of ipred. Take the 
> following example from ?bagging (having loaded ipred):

Excuse me: environments do not have parents but enclosures according to 
?environment.

Of course, the environment of mod is itself an object, and so my statement 
holds true.  Saving a workspace saves all the objects (possibly as 
references) whether named or not.  I was fully aware that the namespace 
was likely to be up the environment tree of a named object when I chose my 
words carefully.

>> data(BreastCancer)
>>
>> mod <- bagging(Class ~ Cl.thickness + Cell.size
> +                 + Cell.shape + Marg.adhesion
> +                 + Epith.c.size + Bare.nuclei
> +                 + Bl.cromatin + Normal.nucleoli
> +                 + Mitoses, data=BreastCancer, coob=TRUE)
>>
>> environment(mod$mtrees[[1]]$btree$terms)
> <environment: 024E8138>
>>
>> parent.env(environment(mod$mtrees[[1]]$btree$terms))
> <environment: namespace:ipred>

parent.env is a very confusing name.  To quote the draft R language 
definition:

 	`The parent.env function may be used to access the enclosure
 	of an environment.'

[...]


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From maechler at stat.math.ethz.ch  Wed Jan 18 15:02:14 2006
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 18 Jan 2006 15:02:14 +0100
Subject: [Rd] R: ecdf - linear
In-Reply-To: <680F0EB5-D84F-4A45-AE5E-72377A43418E@warthmann.com>
References: <680F0EB5-D84F-4A45-AE5E-72377A43418E@warthmann.com>
Message-ID: <17358.19046.242740.946478@stat.math.ethz.ch>

I'm replying to R-devel, the mailing list which should be used
to discuss R feature enhancements.

>>>>> "Norman" == Norman Warthmann <norman at warthmann.com>
>>>>>     on Wed, 18 Jan 2006 11:33:22 +0100 writes:

    Norman> .......... 

    Norman> Is there a specific reason why in the ecdf-function
    Norman> the variable method="constant" is hard-coded?
yes, see below

    Norman> I would like to use method="linear" and I have created
    Norman> a new function based on yours just changing this and
    Norman> it seems to work. I am now wondering whether you did
    Norman> that on purpose? Maybe because there is problems
    Norman> that are not obvious? If there aren't I would like
    Norman> to put in a feature request to include the "method"-
    Norman> argument into ecdf.

It can't be the way you did it:

The class "ecdf" inherits from class "stepfun" which is defined
to be "Step functions" and a step function *is* piecewise
constant (also every definition of ecdf in math/statistics
only uses a piecewise constant function).

Of course, it does make sense in some contexts to linearly
(or even "smoothly") interpolate an ecdf, one important context
being versions of "smoothed bootstrap", but the result is not a
proper ecdf anymore. 

I think you should rather define a function that takes an ecdf
(of class "ecdf" from R) as input
and returns a piecewise linear function {resulting from
approxfun() as in your example below}. However that result  may
*NOT* inherit from "ecdf" (nor "stepfun").

And for that reason {returning a different class}, this
extension should NOT become part of ecdf() itself.

If you write such a "ecdf -> interpolated_ecdf" transforming
function, it might be useful to include in the ecdf() help page
later, so "keep us posted".

Regards,
Martin Maechler, ETH Zurich



    Norman> my changed function:

    N>>   ecdf_linear<-function (x)
    N>>   {
    N>>        x <- sort(x)
    N>>        n <- length(x)
    N>>        if (n < 1)
    N>> 	   stop("'x' must have 1 or more non-missing values")
    N>>        vals <- sort(unique(x))
    N>>        rval <- approxfun(vals, cumsum(tabulate(match(x,vals)))/n,  
    N>>   method = "linear", yleft = 0, yright = 1, f = 0,ties = "ordered")
    N>>        class(rval) <- c("ecdf", "stepfun", class(rval))
    N>>        attr(rval, "call") <- sys.call()
    N>>        rval
    N>>   }

    N>>   test<-c(1,2,7,8,9,10,10,10,12,13,13,13,14)
    N>>   constant<-ecdf(test)
    N>>   linear<- ecdf_linear(test)
    N>>   plot(constant(1:14),type="b")
    N>>   points(linear(1:14),type="b",col="red")


From donahue at skepsis.com  Wed Jan 18 15:04:26 2006
From: donahue at skepsis.com (donahue@skepsis.com)
Date: Wed, 18 Jan 2006 15:04:26 +0100 (CET)
Subject: [Rd] standard install on OS 10.3.9 crashes on start without useful
	diagnostics (PR#8500)
Message-ID: <20060118140426.E85A01E5F8@slim.kubism.ku.dk>

Full_Name: Bob Donahue
Version: 2.2
OS: Mac OS 10.3.9
Submission from: (NULL) (204.152.13.26)


That's pretty much it.  I did the most basic install possible, tried running the
package through the GUI and on the command line, it crashed hard, immediately,
with absolutely NO useful information as to WHY it crashed.

To reproduce:
1) get the installer for OS X
2) install in the default places
3) run
4) watch it crash with no useful diagnostics


From Heather.Turner at warwick.ac.uk  Wed Jan 18 14:58:15 2006
From: Heather.Turner at warwick.ac.uk (Heather Turner)
Date: Wed, 18 Jan 2006 13:58:15 +0000
Subject: [Rd] Loading of namespace on load of .Rdata (was
	strange	behaviourof load)
Message-ID: <s3ce4988.063@liberator.csv.warwick.ac.uk>

Apologies - I was not trying to correct you Brian, but to explore how the situation could arise. I'm sure you had a good idea why the namespace (or a reference to it) had been saved, but this was not clear to me and I thought, possibly not to others either.

Thanks for putting me right over parent environments vs. enclosures - again I was not trying to correct you with the point I made there, but to trace back where the reference to the namespace might have come from in Giovanni's case.

I think the issues raised are still of interest...

Heather


>>> Prof Brian Ripley <ripley at stats.ox.ac.uk> 01/18/06 01:31pm >>>
On Wed, 18 Jan 2006, Heather Turner wrote:

[Lines wrapped for legibility and R-help removed as it is not an 
appropriate list.]

> Last week Giovanni Parrinello posted a message asking why various 
> packages were loaded when he loaded an .Rdata file. Brian Ripley replied 
> saying he thought it was because the saved workspace contained a 
> reference to the namespace of ipred. (Correspondence copied below).
>
> This begs the question: how did the reference to the namespace of ipred 
> come to be in the .Rdata file? Brian did say it is likely to be because 
> the workspace contained object(s) saved with environment the namespace 
> of ipred - but how would this come about?
>
> In this case I think is because the .Rdata file contained an object 
> whose *parent* environment was the namespace of ipred. Take the 
> following example from ?bagging (having loaded ipred):

Excuse me: environments do not have parents but enclosures according to 
?environment.

Of course, the environment of mod is itself an object, and so my statement 
holds true.  Saving a workspace saves all the objects (possibly as 
references) whether named or not.  I was fully aware that the namespace 
was likely to be up the environment tree of a named object when I chose my 
words carefully.

>> data(BreastCancer)
>>
>> mod <- bagging(Class ~ Cl.thickness + Cell.size
> +                 + Cell.shape + Marg.adhesion
> +                 + Epith.c.size + Bare.nuclei
> +                 + Bl.cromatin + Normal.nucleoli
> +                 + Mitoses, data=BreastCancer, coob=TRUE)
>>
>> environment(mod$mtrees[[1]]$btree$terms)
> <environment: 024E8138>
>>
>> parent.env(environment(mod$mtrees[[1]]$btree$terms))
> <environment: namespace:ipred>

parent.env is a very confusing name.  To quote the draft R language 
definition:

 	`The parent.env function may be used to access the enclosure
 	of an environment.'

[...]


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk 
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/ 
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Wed Jan 18 16:05:25 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 18 Jan 2006 15:05:25 +0000 (GMT)
Subject: [Rd] symbols function -- possible enhancements
In-Reply-To: <17358.599.749665.458231@stat.math.ethz.ch>
References: <Pine.LNX.4.43.0601171337360.7252@hymn06.u.washington.edu>
	<Pine.LNX.4.61.0601172306550.32358@gannet.stats>
	<17358.599.749665.458231@stat.math.ethz.ch>
Message-ID: <Pine.LNX.4.61.0601180932580.7771@gannet.stats>

On Wed, 18 Jan 2006, Martin Maechler wrote:

> Hi Jean,
>
> now that you've been told  `the truth' ..  :
>
> If you'd like to carefully look at symbols() and its help page and see
> which arguments ('axes' but maybe more) would be useful to pass
> to plot.default and if you provide enhanced versions of the two files
>     https://svn.r-project.org/R/trunk/src/library/graphics/R/symbols.R
> and  https://svn.r-project.org/R/trunk/src/library/graphics/man/symbols.Rd
>
> I'll gladly look at them and incorporate them for R 2.3.0
> (unless they break something)

I am not at all sure this is a good idea.  We have a standard way (x/yaxt) 
to suppress axes.  Let's not propagate the myth that axes=FALSE is 
standard, as then people will expect it in all plot() methods.  (We have 
been here several times before when people have made that incorrect 
assumption.)

symbols() is just one of a range of high-level graphics functions such as 
(the default methods of) barplot, boxplot, contour, coplot, dotchart, 
image, hist, pairs, stars, sunflowerplot.  A few do have an 'axes' 
argument and others accept one (and most were wrongly documented) and 
others do not.  In general the S originals do not have an axes or ... 
argument, and R has added them rather inconsistently.  My preference would 
be that ... is used only for graphics parameters, but clearly we cannot 
get from here to there.

>
> Best regards,
> Martin Maechler
>
>
>>>>>> "BDR" == Prof Brian Ripley <ripley at stats.ox.ac.uk>
>>>>>>     on Tue, 17 Jan 2006 23:15:19 +0000 (GMT) writes:
>
>    BDR> On Tue, 17 Jan 2006, Thomas Lumley wrote:
>    >> On Tue, 17 Jan 2006, Jean Eid wrote:
>    >>
>    >>> Hi
>    >>>
>    >>> I do not get why the symbols function produces warnings when axes=F is
>    >>> added. The following example illustrate this
>    >>>
>    >>>> symbols(0,10, inches=T, circles=1, axes=F, xlab="", ylab="")
>    >>> Warning message:
>    >>> parameter "axes" could not be set in high-level plot() function
>    >>>
>    >>>
>    >>> I augmented symbols and added the axes=F argument to the plot function
>    >>> inside the original symbols function. It works as expected, no warning
>    >>> message. I am just lost as to why the extra arguments in symbols (...)
>    >>> are not behaving as expected.
>    >>>
>    >>
>    >> The ... argument is also passed to .Internal, and presumably the code
>    >> there gives the warning.
>
>    BDR> Indeed.  axes=F is not in the allowed list
>
>    BDR> ...: graphics parameters can also be passed to this function, as
>    BDR> can the plot aspect ratio 'asp' (see 'plot.window').
>
>    BDR> People confuse 'axes' with the graphics parameters, but it is in fact an
>    BDR> argument to plot.default.  (The corresponding graphics parameters
>    BDR> xaxt and yaxt do work.)  R-devel gives a more informative message:
>
>    >> attach(trees)
>    >> symbols(Height, Volume, circles = Girth/24, inches = FALSE, axes=F)
>    BDR> Warning message:
>    BDR> "axes" is not a graphical parameter in: symbols(x, y, type, data, inches,
>    BDR> bg, fg, ...)
>
>    BDR> We do ask people to read the help pages before posting for a good reason:
>    BDR> the information is usually there in a more complete and accurate form than
>    BDR> people remember.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From tlumley at u.washington.edu  Wed Jan 18 16:25:43 2006
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Wed, 18 Jan 2006 07:25:43 -0800 (PST)
Subject: [Rd] (PR#8500) standard install on OS 10.3.9 crashes on start
 without useful diagnostics (PR#8500)
In-Reply-To: <20060118140426.E85A01E5F8@slim.kubism.ku.dk>
References: <20060118140426.E85A01E5F8@slim.kubism.ku.dk>
Message-ID: <Pine.LNX.4.64.0601180723320.26064@homer21.u.washington.edu>


This won't actually help you at all, but I used the standard install on OS 
10.3.9 (Powerbook G4) just last week without any problems.

On the other hand, my install was on a machine that had previously had 
other versions of R.

 	-thomas

On Wed, 18 Jan 2006, donahue at skepsis.com wrote:

> Full_Name: Bob Donahue
> Version: 2.2
> OS: Mac OS 10.3.9
> Submission from: (NULL) (204.152.13.26)
>
>
> That's pretty much it.  I did the most basic install possible, tried running the
> package through the GUI and on the command line, it crashed hard, immediately,
> with absolutely NO useful information as to WHY it crashed.
>
> To reproduce:
> 1) get the installer for OS X
> 2) install in the default places
> 3) run
> 4) watch it crash with no useful diagnostics
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle


From gregory.r.warnes at pfizer.com  Wed Jan 18 17:29:10 2006
From: gregory.r.warnes at pfizer.com (Warnes, Gregory R)
Date: Wed, 18 Jan 2006 11:29:10 -0500
Subject: [Rd] natural sorting
Message-ID: <915D2D65A9986440A277AC5C98AA466F018637E5@groamrexm02.amer.pfizer.com>

Good idea. Done.

-G

> -----Original Message-----
> From: Martin Maechler [mailto:maechler at stat.math.ethz.ch]
> Sent: Wednesday, January 18, 2006 4:02 AM
> To: Warnes, Gregory R
> Cc: Andrew Piskorski; R Development Mailing List
> Subject: Re: [Rd] natural sorting
> 
> 
> >>>>> "Greg" == Warnes, Gregory R <gregory.r.warnes at pfizer.com>
> >>>>>     on Tue, 17 Jan 2006 14:48:46 -0500 writes:
> 
>     Greg> The 'mixedsort' function in the 'gtools' package does
>     Greg> this.  It is probably slower than the c version you
>     Greg> point to, but it is already working in R.
> 
> Thank you, Greg.
> 
> BTW, given the thread, this is a typical example where it might
> be very useful to add the following two concepts to the 
>    mixedsort.Rd file in gtools :
> 
> \concept{natural sort}
> \concept{dictionary sort}
> 
> so that mixedsort() will be quickly found by 
> help.search("natural sort")
> and possibly also via the java search from the HTML help interface?
> (I never use it; I use help.search() {or then RSiteSearch()}
>  exclusively.)
> 
> Martin
> 
> 
>     >> -----Original Message-----
>     >> From: r-devel-bounces at r-project.org
>     >> [mailto:r-devel-bounces at r-project.org]On Behalf Of 
> Andrew Piskorski
>     >> Sent: Thursday, January 12, 2006 10:40 AM
>     >> To: R Development Mailing List
>     >> Subject: Re: [Rd] natural sorting
>     >> 
>     >> 
>     >> On Wed, Jan 11, 2006 at 05:45:10PM -0500, Gabor 
> Grothendieck wrote:
>     >> > It would be nifty to incorporate this into R or into 
> an R package:
>     >> > 
>     >> > http://sourcefrog.net/projects/natsort/
>     >> 
>     >> Btw, I haven't looked at the implementation, but Tcl 
> also contains
>     >> equivalent functionality, they call it dictionary sort:
>     >> 
>     >> http://tcl.activestate.com/man/tcl8.4/TclCmd/lsort.htm
>     >> 
>     >> -- 
>     >> Andrew Piskorski <atp at piskorski.com>
>     >> http://www.piskorski.com/
> 
> 
----------------------------------------------------------------------
LEGAL NOTICE\ Unless expressly stated otherwise, this messag...{{dropped}}


From mike.prager at noaa.gov  Wed Jan 18 17:30:09 2006
From: mike.prager at noaa.gov (mike.prager@noaa.gov)
Date: Wed, 18 Jan 2006 17:30:09 +0100 (CET)
Subject: [Rd] Suboptimal EPS output (PR#8502)
Message-ID: <20060118163009.B417B20703@slim.kubism.ku.dk>

Full_Name: Mike Prager
Version: 2.2.1
OS: Windows XP with SP2
Submission from: (NULL) (205.156.36.17)


When several EPS files are made with one invocation of postscript(), only the
first displays correctly in gsview. Examination of the generated eps files with
a diff utility reveals that subsequent eps files lack the encoding vector
definition and report page numbers higher than one. This causes (e.g.) gsview to
fail when trying to display the subsequent files.

My copy of the EPS specification does not prohibit %%Pages DSC comments higher
than one, but since an EPS file is not allowed to have multiple pages, it seems
inconsistent at least for the R-generated file to claim to be page 2 or that it
contains more than one page.

The lack of encoding vector definition causes font loading to fail when it the
file later specifies WinAnsiEncoding (as it does by default).

Therefore, it would be desirable for each generated eps file to include the
encoding vector and to state that it is page 1 of 1 and that the number of pages
is 1.

(This can be worked around by closing the device between plots, thus making sure
each EPS file is the first file.)

The following example generates two files, the second of which is incompatible
with gsview on Windows as described:

######################################################################
# epstest.r
# M. H. Prager
# Demonstrate (1) possible wrapper function for postscript() and
#             (2) problems with current EPS output
# January 17, 2006
######################################################################
eps <- function (...)
{
    postscript(height = 5, width = 7, onefile = FALSE, horizontal = FALSE, 
        paper = "special", file = "Rplot%03d.eps", ...)
}

eps()
plot(1:5, rnorm(5))
plot(1:6, rnorm(6))
dev.off()
# END OF EXAMPLE
######################################################################

In addition, although it is NOT a bug, I would like to request that a wrapper
function like eps() above be included with the R distribution. This would save
R-help readers from answering the same questions over and over. It would also
make it easier for newcomers to use R for generating eps files. Consideration by
the R Core Team would be appreciated.

Thanks,
...Mike Prager


From Mike.Prager at noaa.gov  Wed Jan 18 17:40:30 2006
From: Mike.Prager at noaa.gov (Mike.Prager@noaa.gov)
Date: Wed, 18 Jan 2006 17:40:30 +0100 (CET)
Subject: [Rd] (PR#8502) comment
Message-ID: <20060118164030.53E4C20703@slim.kubism.ku.dk>

In my example, I should have included the defaults to the wrapper 
function in its definition, rather than in the call to postscript().  
That of course does NOT affect the validity of my bug report nor the 
ability of my example to demonstrate it.

MHP


From jago at mclink.it  Wed Jan 18 18:15:55 2006
From: jago at mclink.it (stefano iacus)
Date: Wed, 18 Jan 2006 18:15:55 +0100
Subject: [Rd] (PR#8500) standard install on OS 10.3.9 crashes on start
	without useful diagnostics (PR#8500)
In-Reply-To: <Pine.LNX.4.64.0601180723320.26064@homer21.u.washington.edu>
References: <20060118140426.E85A01E5F8@slim.kubism.ku.dk>
	<Pine.LNX.4.64.0601180723320.26064@homer21.u.washington.edu>
Message-ID: <73A74BA6-3C19-4BFF-B7AC-C9CADF0C4B06@mclink.it>

Let me add that you should probably have a crash report on your  
system. See Console.app inside "Utilities" and search for R.app or R  
crash report. Check if date/time of the log is the right one and send  
it to us.
Did you have a previous version of R.app installed? An old one?
Because the problem could be in the preference file sometimes.

thanks

stefano

Il giorno 18/gen/06, alle ore 16:25, Thomas Lumley ha scritto:

>
> This won't actually help you at all, but I used the standard  
> install on OS
> 10.3.9 (Powerbook G4) just last week without any problems.
>
> On the other hand, my install was on a machine that had previously had
> other versions of R.
>
>  	-thomas
>
> On Wed, 18 Jan 2006, donahue at skepsis.com wrote:
>
>> Full_Name: Bob Donahue
>> Version: 2.2
>> OS: Mac OS 10.3.9
>> Submission from: (NULL) (204.152.13.26)
>>
>>
>> That's pretty much it.  I did the most basic install possible,  
>> tried running the
>> package through the GUI and on the command line, it crashed hard,  
>> immediately,
>> with absolutely NO useful information as to WHY it crashed.
>>
>> To reproduce:
>> 1) get the installer for OS X
>> 2) install in the default places
>> 3) run
>> 4) watch it crash with no useful diagnostics
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
> Thomas Lumley			Assoc. Professor, Biostatistics
> tlumley at u.washington.edu	University of Washington, Seattle
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From ripley at stats.ox.ac.uk  Wed Jan 18 20:04:24 2006
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Wed, 18 Jan 2006 20:04:24 +0100 (CET)
Subject: [Rd] data.matrix returns mode logical for zero rows (PR#8496)
Message-ID: <20060118190424.DEBA5CCEE@slim.kubism.ku.dk>

On Tue, 17 Jan 2006 jonathan.swinton at astrazeneca.com wrote:

> Full_Name: Jonathan Swinton
> Version: 2.2.1
> OS: Windows
> Submission from: (NULL) (193.132.159.169)
>
>
> #The first line of description for data.matrix says that it will
> #	'Return the matrix obtained by converting all the variables in a
> #    data frame to numeric mode and then binding them together as the
> #     columns of a matrix.'
>
> #However when called with a data.frame with zero rows, data.matrix returns a
> matrix
> #of mode logical rather than numeric. This conflicts with the documentation
> #and is not what seems sensible.

You don't show us an example of a data frame with zero rows, nor do you 
show an example of data.matrix returning logical, so this report was very 
confusing.  Please do give a reproducible example as the posting guide and 
FAQ ask.

df[FALSE,] is not a data frame, so I don't know why you expect data.matrix 
to be applicable (it is the same as as.matrix in such cases).

Here is an actual reproducible example:

DF <- data.frame(x=c("a", "b"), y=2:3)[FALSE,]
typeof(data.matrix(DF))


> One underlying reason for this is that when a zero-length column of a 
> matrix of mode logical is asserted to be numeric the matrix is not 
> actually cast to numeric. I wonder if that too is a bug?

No, but there is a bug in your description as you are describing 
replacement indexing, not `assertion'.  Coercion in replacement indexing 
is done to accommodate the new values, and there are none in your example.
(That is how S has always done it in my experience, although the Blue 
Book p.359 says otherwise.)

If you want to assert that an object be numeric, use mode(x) <- "numeric".

>> R.version.string
> [1] "R version 2.2.1, 2005-12-20"
>> df <- data.frame(matrix(1:2,nrow=2))
>> mode(data.matrix(df)[,1])
> [1] "numeric"
>> mode(data.matrix(df[FALSE,])[,1])
> [1] "numeric"
>>
>> # Underlying cause
>> x <- matrix(nr = 2,nc = 1 )
>> mode(x)
> [1] "logical"
>> x[, 1] <-   c(1,2)
>> mode(x)
> [1] "numeric"
>>
>> x0 <- matrix(nr = 0, nc = 1)
>> x0[, 1] <-   numeric(0)
>> mode(x0)
> [1] "logical"
>> mode(x0[,1])
> [1] "logical"

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From Vincent.Labbe.AEREX at drdc-rddc.gc.ca  Wed Jan 18 20:12:54 2006
From: Vincent.Labbe.AEREX at drdc-rddc.gc.ca (Labbe, Vincent (AEREX))
Date: Wed, 18 Jan 2006 14:12:54 -0500
Subject: [Rd] Display an Image on a Plane
Message-ID: <85F883EB8B41D61181C80002A541DB960627544F@valcartierex.drdc-rddc.gc.ca>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20060118/9d0ae792/attachment.pl

From Pierre.Legendre at umontreal.ca  Wed Jan 18 23:25:59 2006
From: Pierre.Legendre at umontreal.ca (Pierre.Legendre@umontreal.ca)
Date: Wed, 18 Jan 2006 23:25:59 +0100 (CET)
Subject: [Rd] function 'eigen' (PR#8503)
Message-ID: <20060118222559.0FBAE1A000@slim.kubism.ku.dk>

Full_Name: Pierre Legendre
Version: 2.1.1
OS: Mac OSX 10.4.3
Submission from: (NULL) (132.204.120.81)


I am reporting the mis-behaviour of the function 'eigen' in 'base', for the
following input matrix:

A <- matrix(c(2,3,4,-1,3,1,1,-2,0),3,3)
eigen(A)

I obtain the following results, which are incorrect for eigenvalues and
eigenvectors 2 and 3 (incorrect imaginary portions):
$values
[1] 3+0.000000e+00i 1+1.869518e-08i 1-1.869518e-08i

$vectors
              [,1]                       [,2]                       [,3]
[1,] -0.5345225+0i 4.720910e-17+2.643897e-09i 4.720910e-17-2.643897e-09i
[2,] -0.2672612+0i 7.071068e-01+0.000000e+00i 7.071068e-01+0.000000e+00i
[3,] -0.8017837+0i 7.071068e-01-2.643897e-09i 7.071068e-01+2.643897e-09i

The eigenvalues of matrix A are 3, 1, and 1. The eigenvectors are real (not
complex). Eigenvectors 2 and 3 of matrix A are identical.

With R version 2.2.1 on a PC, 'eigen' produces the following (correct) results:
Results obtained on a PC (WIndows) using R version 2.2.1:

eigen(A)
$values
[1] 3 1 1

$vectors
           [,1]          [,2]          [,3]
[1,] -0.5345225 -3.563430e-09 -3.563431e-09
[2,] -0.2672612 -7.071068e-01  7.071068e-01
[3,] -0.8017837 -7.071068e-01  7.071068e-01

I obtained the  following results using R version 2.2.1 on a PowerMac G5 under
Mac OSX 10.4.4:

eigen(A)
$values
[1] 3+0i 1+0i 1-0i   # OK results, although there is no need to show the
imaginary portion which is 0

$vectors
              [,1]                       [,2]                       [,3]
[1,] -0.5345225+0i 4.720910e-17+2.643897e-09i 4.720910e-17-2.643897e-09i
[2,] -0.2672612+0i 7.071068e-01+0.000000e+00i 7.071068e-01+0.000000e+00i
[3,] -0.8017837+0i 7.071068e-01-2.643897e-09i 7.071068e-01+2.643897e-09i

Incorrect imaginary portions, again, in eigenvectors 2 and 3.


From Friedrich.Leisch at tuwien.ac.at  Thu Jan 19 08:08:34 2006
From: Friedrich.Leisch at tuwien.ac.at (Friedrich.Leisch@tuwien.ac.at)
Date: Thu, 19 Jan 2006 08:08:34 +0100
Subject: [Rd] StatLib mirror now OK
Message-ID: <17359.15090.473651.51098@galadriel.ci.tuwien.ac.at>


Pantelis Vlachos (the StatLib admin) and I figured out what the
problems with the CRAN mirror on StatLib were and he seems to have
fixed all problems in the mirroring process. 

Please let us know if you still observe problems with the StatLib
mirror.

Best,

-- 
-------------------------------------------------------------------
                        Friedrich Leisch 
Institut f?r Statistik                     Tel: (+43 1) 58801 10715
Technische Universit?t Wien                Fax: (+43 1) 58801 10798
Wiedner Hauptstra?e 8-10/1071
A-1040 Wien, Austria             http://www.ci.tuwien.ac.at/~leisch


From ripley at stats.ox.ac.uk  Thu Jan 19 11:49:07 2006
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Thu, 19 Jan 2006 11:49:07 +0100 (CET)
Subject: [Rd] function 'eigen' (PR#8503)
Message-ID: <20060119104907.2B96826BC5@slim.kubism.ku.dk>

> I am reporting the mis-behaviour of the function 'eigen' in 'base', for the
> following input matrix:

All you can report is that the results do not accord with your
expectations, and I am afraid the problem is the latter.  However, I am 
not going be as impolite as to call that your `mis-behaviour'.

I am going to assume (because you did not tell us) that you are using a 
pre-built version of R for MacOS X linked against veclib.  We do ask you 
not to report issues with obselete versions of R, and 2.2.1 is current, 
not 2.1.1.  I believe that you will see different printed results on 2.2.1 
because of the NEWS item

     o	The printing of complex numbers has changed, handling numbers
 	as a whole rather than in two parts.  So both real and
 	imaginary parts are shown to the same accuracy, with the
 	'digits' parameter referring to the accuracy of the larger
 	component, and both components are shown in fixed or
 	scientific notation (unless one is entirely zero when it is
 	always shown in fixed notation).

J. F. Wilkinson wrote a large tome on the numerical analysis of the 
eigenproblem.  An over-simple precis is that all one can expect on a 
real-world computer is a solution to a problem somewhat close to the 
original one.  Since asymmetric matrices do not in general have a solution 
to the eigenproblem in the real domain, the analysis has to be conducted 
in the complex domain (where there is a solution, possibly degenerate). 
That is what you are seeing here: in particular for a theoretical solution 
with repeated eigenvalues the computed solution will almost certainly have 
close but not identical ones.  In general software makes internal 
decisions about whether to report repeated eigenvalues or not depending 
how close the computed values are.

The different results on MacOS 10.4.3/4 would reflect different versions 
of the OS services, in this case veclib. It looks as if Apple have already 
corrected one of their minor bugs.

eigen() for an asymmetric real matrix reports complex eigenvalues and 
eigenvectors whenever the computed eigenvalues are actually complex (that 
is, not all imaginary parts are identically zero).  So what you are seeing 
as '3+0i' probably does not have a zero imaginary part, but an imaginary 
part small compared to the modulus given that you asked for the result to 
7 significant figures.  Please distinguish between internal and printed 
representations of numbers.  (One could argue that the test should have a 
tolerance, but it is hard to know what it should be and I suspect it would 
be lower than your machine is giving.)

The problems you are seeing (on an obselete version of R) seem to indicate 
that Apple's OS services are less accurate than the LAPACK used by R on 
Windows, and indeed other LAPACKs I tried.  (My guess is that internally 
veclib is using some single-precision calculations for speed.)  If so, you 
need to adjust your expectations further to allow for the limited accuracy 
of your particular OS.


On Wed, 18 Jan 2006 Pierre.Legendre at umontreal.ca wrote:

> Full_Name: Pierre Legendre
> Version: 2.1.1
> OS: Mac OSX 10.4.3
> Submission from: (NULL) (132.204.120.81)
>
>
> I am reporting the mis-behaviour of the function 'eigen' in 'base', for the
> following input matrix:
>
> A <- matrix(c(2,3,4,-1,3,1,1,-2,0),3,3)
> eigen(A)
>
> I obtain the following results, which are incorrect for eigenvalues and
> eigenvectors 2 and 3 (incorrect imaginary portions):
> $values
> [1] 3+0.000000e+00i 1+1.869518e-08i 1-1.869518e-08i
>
> $vectors
>              [,1]                       [,2]                       [,3]
> [1,] -0.5345225+0i 4.720910e-17+2.643897e-09i 4.720910e-17-2.643897e-09i
> [2,] -0.2672612+0i 7.071068e-01+0.000000e+00i 7.071068e-01+0.000000e+00i
> [3,] -0.8017837+0i 7.071068e-01-2.643897e-09i 7.071068e-01+2.643897e-09i
>
> The eigenvalues of matrix A are 3, 1, and 1. The eigenvectors are real (not
> complex). Eigenvectors 2 and 3 of matrix A are identical.

More accurately, the geometric multiplicity of the repeated eigenvalue is 
1, so the eigenvectors span a one-dimensional space.  (This is one of 
those degenerate cases I mentioned earlier.)

> With R version 2.2.1 on a PC, 'eigen' produces the following (correct) results:
> Results obtained on a PC (WIndows) using R version 2.2.1:
>
> eigen(A)
> $values
> [1] 3 1 1
>
> $vectors
>           [,1]          [,2]          [,3]
> [1,] -0.5345225 -3.563430e-09 -3.563431e-09
> [2,] -0.2672612 -7.071068e-01  7.071068e-01
> [3,] -0.8017837 -7.071068e-01  7.071068e-01
>
> I obtained the  following results using R version 2.2.1 on a PowerMac G5 under
> Mac OSX 10.4.4:
>
> eigen(A)
> $values
> [1] 3+0i 1+0i 1-0i   # OK results, although there is no need to show the
> imaginary portion which is 0
>
> $vectors
>              [,1]                       [,2]                       [,3]
> [1,] -0.5345225+0i 4.720910e-17+2.643897e-09i 4.720910e-17-2.643897e-09i
> [2,] -0.2672612+0i 7.071068e-01+0.000000e+00i 7.071068e-01+0.000000e+00i
> [3,] -0.8017837+0i 7.071068e-01-2.643897e-09i 7.071068e-01+2.643897e-09i
>
> Incorrect imaginary portions, again, in eigenvectors 2 and 3.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Thu Jan 19 16:34:17 2006
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Thu, 19 Jan 2006 16:34:17 +0100 (CET)
Subject: [Rd] Suboptimal EPS output (PR#8502)
Message-ID: <20060119153417.7CFEA19FF2@slim.kubism.ku.dk>

I am unable to reproduce the claimed bug here in R-devel (although I can 
in 2.2.1), and the files are all readable in GSView/gs.

We do ask you to consult the appropriate files and test the current 
versions to see if this has been changed.  As the FAQ says

   If a bug has already been reported or fixed, please do not submit
   further bug reports on it.


I am not sure that the page numbering is inappropriate but it is 
easy to change (pdf() works the way you desire) and I have done so.

On Wed, 18 Jan 2006 mike.prager at noaa.gov wrote:

> Full_Name: Mike Prager
> Version: 2.2.1
> OS: Windows XP with SP2
> Submission from: (NULL) (205.156.36.17)
>
>
> When several EPS files are made with one invocation of postscript(), only the
> first displays correctly in gsview. Examination of the generated eps files with
> a diff utility reveals that subsequent eps files lack the encoding vector
> definition and report page numbers higher than one. This causes (e.g.) gsview to
> fail when trying to display the subsequent files.
>
> My copy of the EPS specification does not prohibit %%Pages DSC comments higher
> than one, but since an EPS file is not allowed to have multiple pages, it seems
> inconsistent at least for the R-generated file to claim to be page 2 or that it
> contains more than one page.

Not for it to claim to be page 2: it does not say it is page 2 in that 
file.

> The lack of encoding vector definition causes font loading to fail when it the
> file later specifies WinAnsiEncoding (as it does by default).
>
> Therefore, it would be desirable for each generated eps file to include the
> encoding vector and to state that it is page 1 of 1 and that the number of pages
> is 1.
>
> (This can be worked around by closing the device between plots, thus making sure
> each EPS file is the first file.)
>
> The following example generates two files, the second of which is incompatible
> with gsview on Windows as described:
>
> ######################################################################
> # epstest.r
> # M. H. Prager
> # Demonstrate (1) possible wrapper function for postscript() and
> #             (2) problems with current EPS output
> # January 17, 2006
> ######################################################################
> eps <- function (...)
> {
>    postscript(height = 5, width = 7, onefile = FALSE, horizontal = FALSE,
>        paper = "special", file = "Rplot%03d.eps", ...)
> }
>
> eps()
> plot(1:5, rnorm(5))
> plot(1:6, rnorm(6))
> dev.off()
> # END OF EXAMPLE
> ######################################################################
>
> In addition, although it is NOT a bug, I would like to request that a wrapper
> function like eps() above be included with the R distribution. This would save
> R-help readers from answering the same questions over and over. It would also
> make it easier for newcomers to use R for generating eps files. Consideration by
> the R Core Team would be appreciated.

The people who do not read the help page also do not do what is suggested 
to them on R-help, so how would this help?  If you really think this is 
an FAQ (as distinct from being asked over and over again by a single 
person), you should submit an FAQ entry on it.

We already provide many simple ways, including menu items, for saving to 
EPS.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From deepayan.sarkar at gmail.com  Thu Jan 19 20:47:29 2006
From: deepayan.sarkar at gmail.com (deepayan.sarkar@gmail.com)
Date: Thu, 19 Jan 2006 20:47:29 +0100 (CET)
Subject: [Rd] bug in rbind.data.frame: wrong rownames (PR#8506)
Message-ID: <20060119194729.2CF1F28F8C@slim.kubism.ku.dk>

Hi,

there is a bug in the calculation of row names in rbind.data.frame.
When one of the arguments has 0 rows but is named in the call, this
mistakenly contributes an element in the "row.names" attribute of the
result, e.g.:

> foo <- data.frame(x = 1:10, y = rnorm(10))
> bar1 <- rbind.data.frame(foo[1:5,], foo[numeric(0),])
> dim(bar1)
[1] 5 2
> bar2 <- rbind.data.frame(a = foo[1:5,], b = foo[numeric(0),])
> dim(bar2)
[1] 6 2
> sessionInfo()
Version 2.3.0 Under development (unstable) (2006-01-17 r37109)
i686-pc-linux-gnu

attached base packages:
[1] "methods"   "stats"     "graphics"  "grDevices" "utils"     "datasets"
[7] "base"

This happens because

> rownames(bar1)
[1] "1" "2" "3" "4" "5"
> rownames(bar2)
[1] "a.1" "a.2" "a.3" "a.4" "a.5" "b"

I think the following patch (to the 'Make.row.names' function defined
inside rbind.data.frame) fixes this:

-Deepayan

Index: src/library/base/R/dataframe.R
===================================================================
--- src/library/base/R/dataframe.R      (revision 37109)
+++ src/library/base/R/dataframe.R      (working copy)
@@ -886,7 +886,7 @@
        if(nchar(nmi) > 0) {
            if(ni > 1)
                paste(nmi, ri, sep = ".")
-           else nmi
+           else nmi[ri]
        }
        else if(nrow > 0 && identical(ri, 1:ni))
            seq(from = nrow + 1, length = ni)


From spector at stat.Berkeley.EDU  Thu Jan 19 21:29:02 2006
From: spector at stat.Berkeley.EDU (spector@stat.Berkeley.EDU)
Date: Thu, 19 Jan 2006 21:29:02 +0100 (CET)
Subject: [Rd] chron library: format.times, parse.format and h:m (PR#8507)
Message-ID: <20060119202902.9382428FB5@slim.kubism.ku.dk>

Due to the following lines in parse.format:


else if (nf == 3) {
        sep <- ""
        fmt <- substring(format, first = 1:3, last = 1:3)
    }

If a format code has 3 characters, it will not use a separator:

> library(chron)
> mytime = times('7:15:00')
> format(mytime,'h:m')
[1] "0715"
                                       - Phil Spector
					 Statistical Computing Facility
					 Department of Statistics
					 UC Berkeley
					 spector at stat.berkeley.edu




--please do not edit the information below--

Version:
 platform = x86_64-pc-linux-gnu
 arch = x86_64
 os = linux-gnu
 system = x86_64, linux-gnu
 status = 
 major = 2
 minor = 1.1
 year = 2005
 month = 06
 day = 20
 language = R

Locale:
C

Search Path:
 .GlobalEnv, package:chron, package:methods, package:stats, package:graphics, package:grDevices, package:utils, package:datasets, Autoloads, package:base


From bolker at zoo.ufl.edu  Thu Jan 19 21:50:40 2006
From: bolker at zoo.ufl.edu (bolker@zoo.ufl.edu)
Date: Thu, 19 Jan 2006 21:50:40 +0100 (CET)
Subject: [Rd] nls profiling with algorithm="port" may violate bounds
	(PR#8508)
Message-ID: <20060119205040.3F5DD206FA@slim.kubism.ku.dk>

  [posted to R-devel, no discussion:
resubmitting it as a bug, just so it gets
logged appropriately]

   Sorry to report further difficulties with
nls and profiling and constraints ... the problem
this time (which I didn't check for in my last
round of testing) is that the nls profiler doesn't
seem to respect constraints that have been
set when using the port algorithm.
    See test code below ...
    If I can I will try to hack the code, but I will
probably start by redefining my function with
some workarounds to make the fit quadratically "bad" (but well-defined)
when the parameters are negative ...
     As always, please don't hesitate to correct me
if I'm being an idiot ...

    cheers
      Ben Bolker

-----------------------
rm(list=ls())

npts=10
set.seed(1001)

a =2
b =0.5
x= runif(npts)
y = a*x/(1+a*b*x)+rnorm(npts,sd=0.2)

gfun <- function(a,b,x) {
    if (a<0 || b<0) stop("bounds violated")
    a*x/(1+a*b*x)
}

m1 = nls(y~gfun(a,b,x),algorithm="port",
    lower=c(0,0),start=c(a=1,b=1))

try(confint(m1))
----------------

for what it's worth, the logic appears to be OK in mle in the stats4
library:
--------------
library(stats4)

mfun <- function(a,b,s) {
    if (a<0 || b<0 || s<0) stop("bounds violated")
    -sum(dnorm(y,a*x/(1+a*b*x),sd=s,log=TRUE))
}

m2 = mle(minuslogl=mfun,
    start=list(a=1,b=1,s=0.1),
    method="L-BFGS-B",lower=c(0.002,0.002,0.002))

confint(m2)

m2b = mle(minuslogl=mfun,
    fixed=list(b=0),start=list(a=1,s=0.1),
    method="L-BFGS-B",lower=c(0.002,0.002,0.002))
## set boundary slightly above zero to avoid
## boundary cases

dev <- 2*(-logLik(m2b)+logLik(m2))
as.numeric(pchisq(dev,lower.tail=FALSE,df=1))


From bolker at ufl.edu  Thu Jan 19 21:57:36 2006
From: bolker at ufl.edu (Ben Bolker)
Date: Thu, 19 Jan 2006 20:57:36 +0000 (UTC)
Subject: [Rd] Display an Image on a Plane
References: <85F883EB8B41D61181C80002A541DB960627544F@valcartierex.drdc-rddc.gc.ca>
Message-ID: <loom.20060119T215128-758@post.gmane.org>

Labbe, Vincent (AEREX <Vincent.Labbe.AEREX <at> drdc-rddc.gc.ca> writes:

> 
> Hi,
> 
> I am new to R and I would like to display an image on a plane in a 3D plot,
> i.e. I would like to be able to specify a theta and a phi parameters like in
> the function persp to display a 2D image on an inclined plane.
> 
> Regards,
> 
> vincent
> 

   can't think of an easy way to do this: what do you mean by "image"
exactly?  A bitmapped image from a file?  Or something like the
output of image()?  If the latter, you may be able to cobble together something
using the trans3d() function (i.e., manually recreating an image()
by drawing colored squares, but transforming each of the to the 3D
perspective).  If the former, you might be able to do something with
the pixmap package ...

  Ben Bolker


From sfalcon at fhcrc.org  Fri Jan 20 01:52:12 2006
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Thu, 19 Jan 2006 16:52:12 -0800
Subject: [Rd] R CMD check, NAMESPACE, import: bad error?
Message-ID: <m24q3zbu0z.fsf@fhcrc.org>

I'm seeing errors with R CMD check that I don't understand when
checking a package that uses a NAMESPACE file with an import
directive.  The imported package is listed in the DESCRIPTION file in
the Imports field.

DESCRIPTION contains:

   Imports: arules

NAMESPACE contains:

   import(arules)

The package builds without warnings and installs and loads just fine.
But check has this to say:

$ R CMD check DNAhelperseth_1.0.tar.gz 
[snip]
* using Version 2.3.0 Under development (unstable) (2006-01-15 r37092) 
* checking for file 'DNAhelperseth/DESCRIPTION' ... OK
[snip]
* checking R files for library.dynam ... OK
* checking S3 generic/method consistency ... WARNING
Error: package/namespace load failed for 'DNAhelperseth'
Call sequence:
2: stop(gettextf("package/namespace load failed for '%s'", libraryPkgName(package)),        call. = FALSE, domain = NA)
1: library(package, lib.loc = lib.loc, character.only = TRUE, verbose = FALSE)
Execution halted
See section 'Generic functions and methods' of the 'Writing R Extensions'
manual.
* checking replacement functions ... WARNING
Error: package/namespace load failed for 'DNAhelperseth'
Call sequence:
2: stop(gettextf("package/namespace load failed for '%s'", libraryPkgName(package)),        call. = FALSE, domain = NA)
1: library(package, lib.loc = lib.loc, character.only = TRUE, verbose = FALSE)
Execution halted
In R, the argument of a replacement function which corresponds to the right
hand side must be named 'value'.
* checking foreign function calls ... WARNING
Error: package/namespace load failed for 'DNAhelperseth'
Call sequence:
2: stop(gettextf("package/namespace load failed for '%s'", libraryPkgName(package)),        call. = FALSE, domain = NA)
1: library(package, lib.loc = lib.loc, character.only = TRUE, verbose = FALSE)
Execution halted
See section 'System and foreign language interfaces' of the 'Writing R
Extensions' manual.
* checking Rd files ... OK
* checking for missing documentation entries ... ERROR
Error: package/namespace load failed for 'DNAhelperseth'


From berwin at maths.uwa.edu.au  Fri Jan 20 05:47:42 2006
From: berwin at maths.uwa.edu.au (Berwin A Turlach)
Date: Fri, 20 Jan 2006 12:47:42 +0800
Subject: [Rd] R CMD check, NAMESPACE, import: bad error?
In-Reply-To: <m24q3zbu0z.fsf@fhcrc.org>
References: <m24q3zbu0z.fsf@fhcrc.org>
Message-ID: <17360.27502.365586.740869@bossiaea.maths.uwa.edu.au>

G'day Seth,

>>>>> "SF" == Seth Falcon <sfalcon at fhcrc.org> writes:

    SF> I'm seeing errors with R CMD check that I don't understand
    SF> when checking a package that uses a NAMESPACE file with an
    SF> import directive.
I came sometime ago across a similar problem and it took me some time
to figure it out.  In my case it was that a .Fortran() call didn't
have a "package=" argument.  My advise would be to check all .C() and
.Fortran() calls in your package and add the "package=" argument if it
is missing.

I also guess that if you temporarily remove the NAMESPACE file, the
following step in the checking process:

      * checking foreign function calls ... WARNING
      Error: package/namespace load failed for 'DNAhelperseth'
      Call sequence:
      2: stop(gettextf("package/namespace load failed for '%s'", libraryPkgName(package)),        call. = FALSE, domain = NA)
      1: library(package, lib.loc = lib.loc, character.only = TRUE, verbose = FALSE)
      Execution halted
      See section 'System and foreign language interfaces' of the 'Writing R
      Extensions' manual.

will tell you which call the culprit is.  

Cheers,

        Berwin


From ripley at stats.ox.ac.uk  Fri Jan 20 08:23:35 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 20 Jan 2006 07:23:35 +0000 (GMT)
Subject: [Rd] R CMD check, NAMESPACE, import: bad error?
In-Reply-To: <17360.27502.365586.740869@bossiaea.maths.uwa.edu.au>
References: <m24q3zbu0z.fsf@fhcrc.org>
	<17360.27502.365586.740869@bossiaea.maths.uwa.edu.au>
Message-ID: <Pine.LNX.4.61.0601200719490.25948@gannet.stats>

We do recommend you try INSTALLing and loading the package before R CMD 
check.  The most common problem I have found is that the DSO/DLL cannot be 
loaded, and there loading will give a more extensive error message.

On Fri, 20 Jan 2006, Berwin A Turlach wrote:

> G'day Seth,
>
>>>>>> "SF" == Seth Falcon <sfalcon at fhcrc.org> writes:
>
>    SF> I'm seeing errors with R CMD check that I don't understand
>    SF> when checking a package that uses a NAMESPACE file with an
>    SF> import directive.
> I came sometime ago across a similar problem and it took me some time
> to figure it out.  In my case it was that a .Fortran() call didn't
> have a "package=" argument.  My advise would be to check all .C() and
> .Fortran() calls in your package and add the "package=" argument if it
> is missing.

(It had better be PACKAGE= !)

> I also guess that if you temporarily remove the NAMESPACE file, the
> following step in the checking process:
>
>      * checking foreign function calls ... WARNING
>      Error: package/namespace load failed for 'DNAhelperseth'
>      Call sequence:
>      2: stop(gettextf("package/namespace load failed for '%s'", libraryPkgName(package)),        call. = FALSE, domain = NA)
>      1: library(package, lib.loc = lib.loc, character.only = TRUE, verbose = FALSE)
>      Execution halted
>      See section 'System and foreign language interfaces' of the 'Writing R
>      Extensions' manual.
>
> will tell you which call the culprit is.
>
> Cheers,
>
>        Berwin
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Fri Jan 20 08:47:36 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 20 Jan 2006 07:47:36 +0000 (GMT)
Subject: [Rd] par(mfg=) and postscript and pdf
Message-ID: <Pine.LNX.4.61.0601200727470.25948@gannet.stats>

This is related to the incorrect bug report PR#7820.  Marc Schwartz
pointed out in

https://stat.ethz.ch/pipermail/r-devel/2005-April/033016.html

an example of a real problem.  If you call par(mfg=) after par(mfrow) (or 
mfcol) and before you have done any plotting, NewPage is not called on the 
device at the start of the first page.  That causes the DSC comments to be 
incorrect on postscript() and much worse on pdf().

You would get the same effect by calling par(new=T) before plot.new() is 
called, except that is disallowed.  par(mfg=) does set new=T internally, 
and also sets the plot number to a valid one, both of which inhibit 
calling NewPage.  I've managed to overcome this by ensuring that
GNewPage always calls NewPage on an unused device (there is an internal 
'state' variable which records the latter).

This is safe in the sense that the worst it could do is to produce an 
unwanted new page.  I can't see how this could happen but the design of 
the internals of base graphics is very complicated and undocumented, so I 
am only putting the change in R-devel (along with fixes to the 
long-standing graphics bugs PR#1235 and PR#2630).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From peverlorenvanthemaat at amc.uva.nl  Fri Jan 20 11:47:24 2006
From: peverlorenvanthemaat at amc.uva.nl (peverlorenvanthemaat@amc.uva.nl)
Date: Fri, 20 Jan 2006 11:47:24 +0100 (CET)
Subject: [Rd] read.table with ":" in column names (PR#8511)
Message-ID: <20060120104724.966D4CD0D@slim.kubism.ku.dk>

Full_Name: emiel ver loren
Version: 2.2.0
OS: Windows XP
Submission from: (NULL) (145.117.31.248)


Dear R-community and developers,

I have been trying to read in a tab delimeted file where the column names and
the row names are of the form "GO:0000051" (gene ontology IDs). When using:

> gomat<-read.table("test.txt")
> colnames(gomat)[1]
[1] "GO.0000051"
> rownames(gomat)[1]
[1] "GO:0000002"

Which means that ":" is transformed into a "." !! This seems like Excel when it
is trying to guess what I am really ment (and turning 1/1/1 into 1-1-2001).

Furthermore, I found the following quite strange as well:

> gomat2<-read.delim2("test.txt",header=FALSE)
> gomat2[1,1:2]
          V1         V2
1 GO:0000051 GO:0000280
>  as.character(gomat2[1,1:2])
[1] "8" "2"
> as.character(gomat2[1,1])
[1] "GO:0000051"

I have found a way to work around it, but I am wandering what's happening....

The tab-delimited file look like:

GO:0000051	GO:0000280	GO:0000740	
GO:0000002	0	0	0
GO:0000004	0	0	0
GO:0000012	0	0	0
GO:0000014	0	0	0
GO:0000015	0	0	0
GO:0000018	0	0	0
GO:0000019	0	0	0

Thanks for helping, and 

Emiel


From ripley at stats.ox.ac.uk  Fri Jan 20 12:14:24 2006
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Fri, 20 Jan 2006 12:14:24 +0100 (CET)
Subject: [Rd] read.table with ":" in column names (PR#8511)
Message-ID: <20060120111424.3466E28FC3@slim.kubism.ku.dk>

Please do not report documented behaviour as a bug!
See the 'check.names' argument to read.table.

In your second example you are applying as.character to a data frame, and 
you seem not to realize that.  We specifically ask you NOT to use R-bugs 
to ask questions.  (What is happening is that you got the internal codes 
of the factor columns, which is not what you intended.  If you want 
character columns, read them as such.)

On Fri, 20 Jan 2006 peverlorenvanthemaat at amc.uva.nl wrote:

> Full_Name: emiel ver loren
> Version: 2.2.0

We do ask you not to send reports on obselete versions of R.

> OS: Windows XP
> Submission from: (NULL) (145.117.31.248)
>
>
> Dear R-community and developers,
>
> I have been trying to read in a tab delimeted file where the column names and
> the row names are of the form "GO:0000051" (gene ontology IDs). When using:
>
>> gomat<-read.table("test.txt")
>> colnames(gomat)[1]
> [1] "GO.0000051"
>> rownames(gomat)[1]
> [1] "GO:0000002"
>
> Which means that ":" is transformed into a "." !! This seems like Excel when it
> is trying to guess what I am really ment (and turning 1/1/1 into 1-1-2001).
>
> Furthermore, I found the following quite strange as well:
>
>> gomat2<-read.delim2("test.txt",header=FALSE)
>> gomat2[1,1:2]
>          V1         V2
> 1 GO:0000051 GO:0000280
>>  as.character(gomat2[1,1:2])
> [1] "8" "2"
>> as.character(gomat2[1,1])
> [1] "GO:0000051"
>
> I have found a way to work around it, but I am wandering what's happening....
>
> The tab-delimited file look like:
>
> GO:0000051	GO:0000280	GO:0000740
> GO:0000002	0	0	0
> GO:0000004	0	0	0
> GO:0000012	0	0	0
> GO:0000014	0	0	0
> GO:0000015	0	0	0
> GO:0000018	0	0	0
> GO:0000019	0	0	0
>
> Thanks for helping, and
>
> Emiel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From p.dalgaard at biostat.ku.dk  Fri Jan 20 12:22:53 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 20 Jan 2006 12:22:53 +0100
Subject: [Rd] read.table with ":" in column names (PR#8511)
In-Reply-To: <20060120104724.966D4CD0D@slim.kubism.ku.dk>
References: <20060120104724.966D4CD0D@slim.kubism.ku.dk>
Message-ID: <x2slrj9m9e.fsf@viggo.kubism.ku.dk>

peverlorenvanthemaat at amc.uva.nl writes:

> Full_Name: emiel ver loren
> Version: 2.2.0
> OS: Windows XP
> Submission from: (NULL) (145.117.31.248)
> 
> 
> Dear R-community and developers,
> 
> I have been trying to read in a tab delimeted file where the column names and
> the row names are of the form "GO:0000051" (gene ontology IDs). When using:
> 
> > gomat<-read.table("test.txt")
> > colnames(gomat)[1]
> [1] "GO.0000051"
> > rownames(gomat)[1]
> [1] "GO:0000002"
> 
> Which means that ":" is transformed into a "." !! This seems like Excel when it
> is trying to guess what I am really ment (and turning 1/1/1 into 1-1-2001).

This is what check.names=FALSE is for... (and NOT a bug, please don't
abuse the bug repository, use the mailing lists)
 
> Furthermore, I found the following quite strange as well:
> 
> > gomat2<-read.delim2("test.txt",header=FALSE)
> > gomat2[1,1:2]
>           V1         V2
> 1 GO:0000051 GO:0000280
> >  as.character(gomat2[1,1:2])
> [1] "8" "2"
> > as.character(gomat2[1,1])
> [1] "GO:0000051"
> 
> I have found a way to work around it, but I am wandering what's happening....

Yes, this is a bit nasty, but... What is happening is similar to this:

> d <- data.frame(a=factor(LETTERS), b=factor(letters))
> d[1,]
  a b
1 A a
> as.character(d[1,])
[1] "1" "1"
> as.character(d[1,1])
[1] "A"
> as.character(d[1,1,drop=F])
[1] "1"

or this:

> l <- list(a=factor("x"),b=factor("y"))
> l
$a
[1] x
Levels: x

$b
[1] y
Levels: y

> as.character(l)
[1] "1" "1"

The thing is that as.character on a list will first coerce factors to
numeric, then numeric to character. I'm not sure whether there could
be a rationale for it, but it isn't S-PLUS compatible (not 6.2.1
anyway, which is the most recent one that I have access to).


-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From Roger.Bivand at nhh.no  Fri Jan 20 12:47:46 2006
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 20 Jan 2006 12:47:46 +0100 (CET)
Subject: [Rd] read.table with ":" in column names (PR#8511)
In-Reply-To: <20060120104724.966D4CD0D@slim.kubism.ku.dk>
Message-ID: <Pine.LNX.4.44.0601201241520.635-100000@reclus.nhh.no>

On Fri, 20 Jan 2006 peverlorenvanthemaat at amc.uva.nl wrote:

> Full_Name: emiel ver loren
> Version: 2.2.0
> OS: Windows XP
> Submission from: (NULL) (145.117.31.248)
> 
> 
> Dear R-community and developers,
> 
> I have been trying to read in a tab delimeted file where the column names and
> the row names are of the form "GO:0000051" (gene ontology IDs). When using:
> 
> > gomat<-read.table("test.txt")
> > colnames(gomat)[1]
> [1] "GO.0000051"
> > rownames(gomat)[1]
> [1] "GO:0000002"
> 
> Which means that ":" is transformed into a "." !! This seems like Excel when it
> is trying to guess what I am really ment (and turning 1/1/1 into 1-1-2001).

Wrong. 

?read.table says with reference to the check.names = TRUE argument that:

"check.names: logical.  If 'TRUE' then the names of the variables in the
          data frame are checked to ensure that they are syntactically
          valid variable names.  If necessary they are adjusted (by
          'make.names') so that they are, and also to ensure that there
          are no duplicates."

> make.names("GO:0000051")
[1] "GO.0000051"

You can use "GO:0000051" as a column name if quoted, otherwise ":" is an 
operator, so the default value of the check.names argument is sound.

If you "ment" to do what you say, you should have set check.names=FALSE.

> 
> Furthermore, I found the following quite strange as well:
> 
> > gomat2<-read.delim2("test.txt",header=FALSE)
> > gomat2[1,1:2]
>           V1         V2
> 1 GO:0000051 GO:0000280
> >  as.character(gomat2[1,1:2])
> [1] "8" "2"
> > as.character(gomat2[1,1])
> [1] "GO:0000051"
> 
> I have found a way to work around it, but I am wandering what's happening....
> 
> The tab-delimited file look like:
> 
> GO:0000051	GO:0000280	GO:0000740	
> GO:0000002	0	0	0
> GO:0000004	0	0	0
> GO:0000012	0	0	0
> GO:0000014	0	0	0
> GO:0000015	0	0	0
> GO:0000018	0	0	0
> GO:0000019	0	0	0
> 
> Thanks for helping, and 
> 
> Emiel
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From p.dalgaard at biostat.ku.dk  Fri Jan 20 13:18:13 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 20 Jan 2006 13:18:13 +0100
Subject: [Rd] read.table with ":" in column names (PR#8511)
In-Reply-To: <20060120111424.3466E28FC3@slim.kubism.ku.dk>
References: <20060120111424.3466E28FC3@slim.kubism.ku.dk>
Message-ID: <x2oe279jp6.fsf@viggo.kubism.ku.dk>

ripley at stats.ox.ac.uk writes:

> On Fri, 20 Jan 2006 peverlorenvanthemaat at amc.uva.nl wrote:
> 
> > Full_Name: emiel ver loren
> > Version: 2.2.0
> 
> We do ask you not to send reports on obselete versions of R.

Well, we might forgive that (please at least check against the current
NEWS file), but

USING FAKE EMAIL ADDRESSES ON BUG REPORTS IS BLOODY UNFORGIVEABLE!!!!!

Grrrr....

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From ripley at stats.ox.ac.uk  Fri Jan 20 14:12:26 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 20 Jan 2006 13:12:26 +0000 (GMT)
Subject: [Rd] as.character on list (was read.table with ":" in column
 names)
In-Reply-To: <x2slrj9m9e.fsf@viggo.kubism.ku.dk>
References: <20060120104724.966D4CD0D@slim.kubism.ku.dk>
	<x2slrj9m9e.fsf@viggo.kubism.ku.dk>
Message-ID: <Pine.LNX.4.61.0601201238250.17045@gannet.stats>

On Fri, 20 Jan 2006, Peter Dalgaard wrote:

[...]

> Yes, this is a bit nasty, but... What is happening is similar to this:
>
>> d <- data.frame(a=factor(LETTERS), b=factor(letters))
>> d[1,]
>  a b
> 1 A a
>> as.character(d[1,])
> [1] "1" "1"
>> as.character(d[1,1])
> [1] "A"
>> as.character(d[1,1,drop=F])
> [1] "1"
>
> or this:
>
>> l <- list(a=factor("x"),b=factor("y"))
>> l
> $a
> [1] x
> Levels: x
>
> $b
> [1] y
> Levels: y
>
>> as.character(l)
> [1] "1" "1"
>
> The thing is that as.character on a list will first coerce factors to
> numeric, then numeric to character.

Nope.  It just coerces an INTSXP to a STRSXP.  as.character (and all other 
forms of coercion that I can think of quickly) ignores classes except when 
initially dispatching.

Note that these examples are special cases:

> as.character(d[1:2,])
[1] "c(1, 2)" "c(1, 2)"

may also be unexpected but follows from the general (undocumented, I 
dare say) rules.

> I'm not sure whether there could be a rationale for it, but it isn't 
> S-PLUS compatible (not 6.2.1 anyway, which is the most recent one that I 
> have access to).

My S-PLUS deparses:

> l <- list(a=factor("x"),b=factor("y"))
> as.character(l)
[1] "structure(.Data = 1, .Label = \"x\", class = \"factor\")"
[2] "structure(.Data = 1, .Label = \"y\", class = \"factor\")"

which seems no better (and probably worse).

The only other consistent option I can see is for all coercion methods to 
dispatch at each element of a recursive object, which I suspect introduces 
a considerable overhead for very little gain.

One could perhaps argue for a data.frame method, since coercion operations 
on dataframes are rare and that is a case where people get factors where 
they wanted character columns.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From p.dalgaard at biostat.ku.dk  Fri Jan 20 14:36:10 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 20 Jan 2006 14:36:10 +0100
Subject: [Rd] as.character on list (was read.table with ":" in column
	names)
In-Reply-To: <Pine.LNX.4.61.0601201238250.17045@gannet.stats>
References: <20060120104724.966D4CD0D@slim.kubism.ku.dk>
	<x2slrj9m9e.fsf@viggo.kubism.ku.dk>
	<Pine.LNX.4.61.0601201238250.17045@gannet.stats>
Message-ID: <x27j8v9g39.fsf@viggo.kubism.ku.dk>

Prof Brian Ripley <ripley at stats.ox.ac.uk> writes:


> > The thing is that as.character on a list will first coerce factors to
> > numeric, then numeric to character.
> 
> Nope.  It just coerces an INTSXP to a STRSXP.  as.character (and all
> other forms of coercion that I can think of quickly) ignores classes
> except when initially dispatching.

OK. I just meant that "de facto" it is like as.character(as.integer(f))
 
> Note that these examples are special cases:
> 
> > as.character(d[1:2,])
> [1] "c(1, 2)" "c(1, 2)"
> 
> may also be unexpected but follows from the general (undocumented, I
> dare say) rules.

and unlike as.character(as.integer(f)), so I do stand corrected....

> > I'm not sure whether there could be a rationale for it, but it isn't
> > S-PLUS compatible (not 6.2.1 anyway, which is the most recent one
> > that I have access to).
> 
> My S-PLUS deparses:
> 
> > l <- list(a=factor("x"),b=factor("y"))
> > as.character(l)
> [1] "structure(.Data = 1, .Label = \"x\", class = \"factor\")"
> [2] "structure(.Data = 1, .Label = \"y\", class = \"factor\")"
> 
> which seems no better (and probably worse).

Same here. Arguably, we deparse too, we just discard attributes first.
Both S-PLUS and R will do

> as.character(list(a=1:5,b=3))
[1] "c(1, 2, 3, 4, 5)" "3"


> The only other consistent option I can see is for all coercion methods
> to dispatch at each element of a recursive object, which I suspect
> introduces a considerable overhead for very little gain.

Then again maybe not, but it is one of those things which have the
potential to break things in unexpected places if you change it.
 
> One could perhaps argue for a data.frame method, since coercion
> operations on dataframes are rare and that is a case where people get
> factors where they wanted character columns.

Agreed.

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From MSchwartz at mn.rr.com  Fri Jan 20 14:48:59 2006
From: MSchwartz at mn.rr.com (Marc Schwartz)
Date: Fri, 20 Jan 2006 07:48:59 -0600
Subject: [Rd] par(mfg=) and postscript and pdf
In-Reply-To: <Pine.LNX.4.61.0601200727470.25948@gannet.stats>
References: <Pine.LNX.4.61.0601200727470.25948@gannet.stats>
Message-ID: <1137764939.4335.3.camel@localhost.localdomain>

On Fri, 2006-01-20 at 07:47 +0000, Prof Brian Ripley wrote:
> This is related to the incorrect bug report PR#7820.  Marc Schwartz
> pointed out in
> 
> https://stat.ethz.ch/pipermail/r-devel/2005-April/033016.html
> 
> an example of a real problem.  If you call par(mfg=) after par(mfrow) (or 
> mfcol) and before you have done any plotting, NewPage is not called on the 
> device at the start of the first page.  That causes the DSC comments to be 
> incorrect on postscript() and much worse on pdf().
> 
> You would get the same effect by calling par(new=T) before plot.new() is 
> called, except that is disallowed.  par(mfg=) does set new=T internally, 
> and also sets the plot number to a valid one, both of which inhibit 
> calling NewPage.  I've managed to overcome this by ensuring that
> GNewPage always calls NewPage on an unused device (there is an internal 
> 'state' variable which records the latter).
> 
> This is safe in the sense that the worst it could do is to produce an 
> unwanted new page.  I can't see how this could happen but the design of 
> the internals of base graphics is very complicated and undocumented, so I 
> am only putting the change in R-devel (along with fixes to the 
> long-standing graphics bugs PR#1235 and PR#2630).


Prof. Ripley,

Thanks for your follow up on this issue. Your efforts in resolution are
greatly appreciated.

Best regards,

Marc Schwartz


From j.van_den_hoff at fz-rossendorf.de  Fri Jan 20 15:11:07 2006
From: j.van_den_hoff at fz-rossendorf.de (Joerg van den Hoff)
Date: Fri, 20 Jan 2006 15:11:07 +0100
Subject: [Rd]  read.table with ":" in column names (PR#8511)
Message-ID: <43D0EF7B.7050609@fz-rossendorf.de>

in my view it's not always good to get this answer, but your "problem" 
is not too deeply hidden in the manpages, so simply read the 
documentation of read.table:

?read.table


(and look out for the "check.names" flag)

regards,
joerg


From sfalcon at fhcrc.org  Fri Jan 20 16:41:12 2006
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Fri, 20 Jan 2006 07:41:12 -0800
Subject: [Rd] R CMD check, NAMESPACE, import: bad error?
In-Reply-To: <Pine.LNX.4.61.0601200719490.25948@gannet.stats> (Brian Ripley's
	message of "Fri, 20 Jan 2006 07:23:35 +0000 (GMT)")
References: <m24q3zbu0z.fsf@fhcrc.org>
	<17360.27502.365586.740869@bossiaea.maths.uwa.edu.au>
	<Pine.LNX.4.61.0601200719490.25948@gannet.stats>
Message-ID: <m2fyniaovb.fsf@fhcrc.org>

On 19 Jan 2006, ripley at stats.ox.ac.uk wrote:

> We do recommend you try INSTALLing and loading the package before R
> CMD check.  The most common problem I have found is that the DSO/DLL
> cannot be loaded, and there loading will give a more extensive error
> message.

Yes, the package INSTALLs and loads just fine.

Actually, one sees the same error message for a package without a
DSO/DLL...

But DSO/DLL loading does seem to be related.  I'm only seeing the
issue when the package that is imported contains a DSO/DLL.

I've created two versions of a very simple 'hello world' package.  The
first imports RUnit and passes check.  The second imports Biobase
and does not pass check.


http://bioconductor.fhcrc.org/developers/examples/

Perhaps someone can see if they see the same thing and/or point out an
error in my package setup.


R.version
               _                                                             
platform       powerpc-apple-darwin8.4.0                                     
arch           powerpc                                                       
os             darwin8.4.0                                                   
system         powerpc, darwin8.4.0                                          
status         Under development (unstable)                                  
major          2                                                             
minor          3.0                                                           
year           2006                                                          
month          01                                                            
day            15                                                            
svn rev        37092                                                         
language       R                                                             
version.string Version 2.3.0 Under development (unstable) (2006-01-15 r37092)


From Ancelet at engref.fr  Fri Jan 20 16:45:01 2006
From: Ancelet at engref.fr (Sophie Ancelet)
Date: Fri, 20 Jan 2006 16:45:01 +0100
Subject: [Rd] Troubles with the function rmultinom.c of the R's Random
 Number Generator
Message-ID: <3.0.6.32.20060120164501.007c4c90@Tilia.engref.fr>


Hi,

I'm simulating a Markov chain in Fortran interfaced with R-2.2.1 in order
to generate data according to a Markov Random Field called the Potts model. 

R Version: 
platform i686-pc-linux-gnu
arch     i686
os       linux-gnu
system   i686, linux-gnu
status
major    2
minor    2.1
year     2005
month    12
day      20
svn rev  36812




Each loop of my Fortran calls the function rmultinom.c of the R's Random
Number Generator through the wrapper:

#include <R.h>
#include <Rmath.h>
void F77_SUB(sarmultinom)(int n,
                          double* prob,
                          int K,
                          int* rN){
 rmultinom(n, prob, K, rN);}



My fortran program is:

subroutine testsarmultinom(n,prob,K,rN)
implicit none
integer n,K,rN(K)
double precision prob(K)

call rndstart()
call sarmultinom(n,prob,K,rN)
call rndend()
end


In order to understand better how the function rmultinom.c works, I have
written an R code which calls this fortran subroutine as follows:

system("R CMD SHLIB test-multinom.f wrapper.c")
dyn.load("~/Package/test/test-multinom.so")

n=1
prob=c(0.6,0.1,0.3)
K=3
rN=c(1,0,0)
res<- .Fortran("testsarmultinom",
               as.integer(n),
               as.double(prob),
               as.integer(K),
               as.integer(rN))


Unfortunately, I have some trouble with the results. First, this command
always returns 0 values. In other words, I always get:

>res[[4]]
[1] 0 0 0


Moreover, if I run this R code a second time, an error message appears:
Segmentation fault.

Has somebody ever used rmultinom.c and encountered these problems? My code
must be wrong but I don't know where. In this case, what is the correct way
to call the C function rmultinom.c?

Thanks in advance,

Sophie.




Sophie Ancelet
ENGREF
Laboratoire Grese 
19 avenue du Maine
75 732 Paris Cedex 15 
France
tel: 33 1 45 49 89 27


From ripley at stats.ox.ac.uk  Fri Jan 20 18:06:27 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 20 Jan 2006 17:06:27 +0000 (GMT)
Subject: [Rd] Troubles with Fortran and C (was with the function
 rmultinom.c of the R's Random Number Generator)
In-Reply-To: <3.0.6.32.20060120164501.007c4c90@Tilia.engref.fr>
References: <3.0.6.32.20060120164501.007c4c90@Tilia.engref.fr>
Message-ID: <Pine.LNX.4.61.0601201653420.23380@gannet.stats>

All arguments to functions called from C by Fortran are pointers
(or should be: yours are not).  The error is within your own code.

You don't want to call rndstart and rndend around every call, only before 
the first and after the last.

This is not the list for advice om mixed Fortran/C programming, though.

On Fri, 20 Jan 2006, Sophie Ancelet wrote:

>
> Hi,
>
> I'm simulating a Markov chain in Fortran interfaced with R-2.2.1 in order
> to generate data according to a Markov Random Field called the Potts model.
>
> R Version:
> platform i686-pc-linux-gnu
> arch     i686
> os       linux-gnu
> system   i686, linux-gnu
> status
> major    2
> minor    2.1
> year     2005
> month    12
> day      20
> svn rev  36812
>
>
>
>
> Each loop of my Fortran calls the function rmultinom.c of the R's Random
> Number Generator through the wrapper:
>
> #include <R.h>
> #include <Rmath.h>
> void F77_SUB(sarmultinom)(int n,
>                          double* prob,
>                          int K,
>                          int* rN){
> rmultinom(n, prob, K, rN);}
>
>
>
> My fortran program is:
>
> subroutine testsarmultinom(n,prob,K,rN)
> implicit none
> integer n,K,rN(K)
> double precision prob(K)
>
> call rndstart()
> call sarmultinom(n,prob,K,rN)
> call rndend()
> end
>
>
> In order to understand better how the function rmultinom.c works, I have
> written an R code which calls this fortran subroutine as follows:
>
> system("R CMD SHLIB test-multinom.f wrapper.c")
> dyn.load("~/Package/test/test-multinom.so")
>
> n=1
> prob=c(0.6,0.1,0.3)
> K=3
> rN=c(1,0,0)
> res<- .Fortran("testsarmultinom",
>               as.integer(n),
>               as.double(prob),
>               as.integer(K),
>               as.integer(rN))
>
>
> Unfortunately, I have some trouble with the results. First, this command
> always returns 0 values. In other words, I always get:
>
>> res[[4]]
> [1] 0 0 0
>
>
> Moreover, if I run this R code a second time, an error message appears:
> Segmentation fault.
>
> Has somebody ever used rmultinom.c and encountered these problems? My code
> must be wrong but I don't know where. In this case, what is the correct way
> to call the C function rmultinom.c?
>
> Thanks in advance,
>
> Sophie.
>
>
>
>
> Sophie Ancelet
> ENGREF
> Laboratoire Grese
> 19 avenue du Maine
> 75 732 Paris Cedex 15
> France
> tel: 33 1 45 49 89 27
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Fri Jan 20 18:56:37 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 20 Jan 2006 17:56:37 +0000 (GMT)
Subject: [Rd] [R] cron job install/update problems: tcltk can't find
 display (installing e.g., pbatR)
In-Reply-To: <13e802630601200827i21003d99r2704b80a6f32420b@mail.gmail.com>
References: <13e802630601200827i21003d99r2704b80a6f32420b@mail.gmail.com>
Message-ID: <Pine.LNX.4.61.0601201749460.29805@gannet.stats>

This really is an R-devel question, so moved there.  (Just what would you 
use R-devel for?)

On Fri, 20 Jan 2006, Paul Johnson wrote:

> On Fedora Core Linux 4, I have a cron job that causes R to update all
> packages and install new ones.  Lately, I notice in the log that some
> packages fail to install.  These are ones that assume X is running.
> For example, the pbatR install requires tcltk to be loaded, and then
> the install fails because in a cron job, there is no DISPLAY
> environment.  I suppose the same happens if you try to install R
> packages in the console, without X running?

Yes.  At least for tcltk this is solved in R-devel, so it will start 
without X11.

Some of your `black list' will work if you update your gcc to the current 
version (4.0.2).

> Error output is pasted here.  I wonder if you can advise me whether
> this is the kind of thing that can be fixed in the cron job or not.

Yes, if you run an X server (e.g. Xvfb) to which a cron job has access.

> I've verified that pbatR does install interactively (because tcltk
> does start).  If you think this is a pbatR-specific problem, i will
> contact the author directly.  When I have the repos option set, the
> interactive install does not cause any tcltk widgets to pop up, so I
> wonder if it is really necessary.

It is unreasonable that some packages expect X11 to be running to be 
installed or checked.  So if the issue is not tcltk, please complain to 
the maintainer(s).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From Roger.Bivand at nhh.no  Fri Jan 20 19:41:20 2006
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 20 Jan 2006 19:41:20 +0100 (CET)
Subject: [Rd] Problem loading package with version, S4 classes and NAMESPACE
Message-ID: <Pine.LNX.4.44.0601201907290.1154-100000@reclus.nhh.no>

I've run into a problem that I hope has an obvious solution. The sp 
package uses S4 classes and has a NAMESPACE, and when installed without 
package versions, runs OK, passes R CMD check, and so on.

A user reported that he installed it  --with-package-versions, and that 
from then on it would fail at first use of a class defined in the package.

I've reconstructed the problem in a skeletal package:

http://reclus.nhh.no/R/etc/S4nswv_0.1-1.tar.gz

which when installed without versions works:

$ R CMD INSTALL S4nswv
$ R
...
> library(S4nswv)
> sessionInfo()
R version 2.2.1, 2005-12-20, i686-pc-linux-gnu 

attached base packages:
[1] "methods"   "stats"     "graphics"  "grDevices" "utils"     "datasets" 
[7] "base"     

other attached packages:
 S4nswv 
"0.1-1" 
> xyd <- new("xyloc", x=runif(20), y=runif(20))
> xyd
               x           y         res
 [1,] 0.01589694 0.935594239 -0.91969730
 [2,] 0.56974225 0.120906481  0.44883577
...

but fails after INSTALL --with-package-versions S4nswv

> library(S4nswv)
> sessionInfo()
R version 2.2.1, 2005-12-20, i686-pc-linux-gnu 

attached base packages:
[1] "methods"   "stats"     "graphics"  "grDevices" "utils"     
"datasets" 
[7] "base"     

other attached packages:
S4nswv_0.1-1 
     "0.1-1" 
> xyd <- new("xyloc", x=runif(20), y=runif(20))
Error in as.environment(pkg) : no item called "package:S4nswv" on the 
search list
Error in initialize(value, ...) : S language method selection got an error 
when called from internal dispatch for function 'initialize'
> traceback()
2: initialize(value, ...)
1: new("xyloc", x = runif(20), y = runif(20))

This suggests that "package:S4nswv" and its versioned equivalent are not 
being associated, and I'd be grateful for pointers about how to do this. 

Removing the NAMESPACE, and uncommenting .First.lib() in R/zzz.R removes 
the problem, that is the skeletal package works --with-package-versions, 
but this isn't an option.

At present, the methods package is invoked in DESCRIPTION in the Depends:  
field, by "import(methods)" in NAMESPACE, and by

.onLoad <- function(lib, pkg) require(methods)

in zzz.R, which feels like overkill, but removing them one-by-one doesn't 
seem to affect the problem.

(I don't think this is the same problem as Seth's)

Roger

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From Roger.Bivand at nhh.no  Fri Jan 20 21:23:28 2006
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 20 Jan 2006 21:23:28 +0100 (CET)
Subject: [Rd] Problem loading package with version,
 S4 classes and NAMESPACE
In-Reply-To: <Pine.LNX.4.44.0601201907290.1154-100000@reclus.nhh.no>
Message-ID: <Pine.LNX.4.44.0601202101540.1154-100000@reclus.nhh.no>

On Fri, 20 Jan 2006, Roger Bivand wrote:

> I've run into a problem that I hope has an obvious solution. The sp 
> package uses S4 classes and has a NAMESPACE, and when installed without 
> package versions, runs OK, passes R CMD check, and so on.
> 
> A user reported that he installed it  --with-package-versions, and that 
> from then on it would fail at first use of a class defined in the package.

Further to my question, hardcoding the package= argument to the versioned
package name string in setClass() removes the problem when installing with
versions (for that version), but creates the reverse problem if installed
(by default) without versions:

> library(S4nswv)
> xyd <- new("xyloc", x=runif(20), y=runif(20))
Loading required package: S4nswv_0.1-1
Error in .requirePackage(package) : unable to find required package 
'S4nswv_0.1-1'
In addition: Warning message:
there is no package called 'S4nswv', version 0.1-1 in: library(package, 
character.only = TRUE, logical = TRUE, warn.conflicts = warn.conflicts,  
Error in initialize(value, ...) : S language method selection got an error 
when called from internal dispatch for function 'initialize'

The default for the package argument is getPackageName(where), and where = 
topenv(parent.frame()). There are comments in methods/R/packageName.R 
suggesting that the hidden object .packageName is being made invisible by 
NAMESPACE.

It looks as though R_PACKAGE_NAME as a shell variable could be used to 
smuggle the correct string in, but I'm not sure what order things happen 
in.

> 
> I've reconstructed the problem in a skeletal package:
> 
> http://reclus.nhh.no/R/etc/S4nswv_0.1-1.tar.gz
> 
> which when installed without versions works:
> 
> $ R CMD INSTALL S4nswv
> $ R
> ...
> > library(S4nswv)
> > sessionInfo()
> R version 2.2.1, 2005-12-20, i686-pc-linux-gnu 
> 
> attached base packages:
> [1] "methods"   "stats"     "graphics"  "grDevices" "utils"     "datasets" 
> [7] "base"     
> 
> other attached packages:
>  S4nswv 
> "0.1-1" 
> > xyd <- new("xyloc", x=runif(20), y=runif(20))
> > xyd
>                x           y         res
>  [1,] 0.01589694 0.935594239 -0.91969730
>  [2,] 0.56974225 0.120906481  0.44883577
> ...
> 
> but fails after INSTALL --with-package-versions S4nswv
> 
> > library(S4nswv)
> > sessionInfo()
> R version 2.2.1, 2005-12-20, i686-pc-linux-gnu 
> 
> attached base packages:
> [1] "methods"   "stats"     "graphics"  "grDevices" "utils"     
> "datasets" 
> [7] "base"     
> 
> other attached packages:
> S4nswv_0.1-1 
>      "0.1-1" 
> > xyd <- new("xyloc", x=runif(20), y=runif(20))
> Error in as.environment(pkg) : no item called "package:S4nswv" on the 
> search list
> Error in initialize(value, ...) : S language method selection got an error 
> when called from internal dispatch for function 'initialize'
> > traceback()
> 2: initialize(value, ...)
> 1: new("xyloc", x = runif(20), y = runif(20))
> 
> This suggests that "package:S4nswv" and its versioned equivalent are not 
> being associated, and I'd be grateful for pointers about how to do this. 
> 
> Removing the NAMESPACE, and uncommenting .First.lib() in R/zzz.R removes 
> the problem, that is the skeletal package works --with-package-versions, 
> but this isn't an option.
> 
> At present, the methods package is invoked in DESCRIPTION in the Depends:  
> field, by "import(methods)" in NAMESPACE, and by
> 
> .onLoad <- function(lib, pkg) require(methods)
> 
> in zzz.R, which feels like overkill, but removing them one-by-one doesn't 
> seem to affect the problem.
> 
> (I don't think this is the same problem as Seth's)
> 
> Roger
> 
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From kjetilbrinchmannhalvorsen at gmail.com  Fri Jan 20 23:47:28 2006
From: kjetilbrinchmannhalvorsen at gmail.com (Kjetil Brinchmann Halvorsen)
Date: Fri, 20 Jan 2006 22:47:28 -0000
Subject: [Rd] Minumum memory requirements to run R.
In-Reply-To: <Pine.LNX.4.61.0601181149400.9400@gannet.stats>
References: <Pine.LNX.4.61.0601181149400.9400@gannet.stats>
Message-ID: <43FA4711.2010103@gmail.com>

Prof Brian Ripley wrote:
> Quite a while back we set the goal of running R in 16Mb RAM, as people (I 
> think Kjetil) had teaching labs that small.

It's a while since I actually har R used on such small machines, I think
64 MB is quite acceptable now.

Kjetil

> 
> Since then R has grown, and we has recently started to optimize R for 
> speed rather than size.  I recently tested R-devel on my ancient Win98 
> notebook with 64Mb RAM -- it ran but startup was rather slow on what I 
> think is a 233MHz processor and very slow disc.
> 
> R still runs in 16Mb, but that is getting tight.  Does anyone have any 
> need to run on a smaller machine than my 64Mb notebook?
>


From spencer.graves at pdf.com  Sat Jan 21 04:16:08 2006
From: spencer.graves at pdf.com (Spencer Graves)
Date: Fri, 20 Jan 2006 19:16:08 -0800
Subject: [Rd] nls profiling with algorithm="port" may violate
	bounds	(PR#8508)
In-Reply-To: <20060119205040.3F5DD206FA@slim.kubism.ku.dk>
References: <20060119205040.3F5DD206FA@slim.kubism.ku.dk>
Message-ID: <43D1A778.6010209@pdf.com>

Hi, Ben, et al.:

	  The issue Ben identified with confint(nls(... )) generates a hard 
failure for me.  Specifically the command "confint(m1)" in his script 
below under Rgui 2.2.1 first says, "Waiting for profiling to be done..." 
then forces a screen to pop up with heading "R for Windows GUI 
front-end" reading, "R for Windows GUI front-end has encountered a 
problem and needs to close.  We are sorry for the inconvenience.  If you 
were in the middle of something, the information you were working on 
might be lost... ."  When I try the same thing running R under XEmacs 
with ESS, I get essentially the same response, exceppt "R for Windows 
GUI" is replaced by "R for Windows terminal".  In both cases, it kills 
R.  In both cases, sessionInfo() before this command is as follows:

 > sessionInfo()
R version 2.2.1, 2005-12-20, i386-pc-mingw32

attached base packages:
[1] "stats4"    "methods"   "stats"     "graphics"  "grDevices" "utils"
[7] "datasets"  "base"

	  I'm running Windows XP professional version 5.1 on an IBM T30 
notebook computer.

	  Thanks to all of the R Core team for all your hard work to make R 
what it is today, with these kinds of unpleasant surprises to rare.

	  Best Wishes,
	  spencer graves	

bolker at zoo.ufl.edu wrote:

>   [posted to R-devel, no discussion:
> resubmitting it as a bug, just so it gets
> logged appropriately]
> 
>    Sorry to report further difficulties with
> nls and profiling and constraints ... the problem
> this time (which I didn't check for in my last
> round of testing) is that the nls profiler doesn't
> seem to respect constraints that have been
> set when using the port algorithm.
>     See test code below ...
>     If I can I will try to hack the code, but I will
> probably start by redefining my function with
> some workarounds to make the fit quadratically "bad" (but well-defined)
> when the parameters are negative ...
>      As always, please don't hesitate to correct me
> if I'm being an idiot ...
> 
>     cheers
>       Ben Bolker
> 
> -----------------------
> rm(list=ls())
> 
> npts=10
> set.seed(1001)
> 
> a =2
> b =0.5
> x= runif(npts)
> y = a*x/(1+a*b*x)+rnorm(npts,sd=0.2)
> 
> gfun <- function(a,b,x) {
>     if (a<0 || b<0) stop("bounds violated")
>     a*x/(1+a*b*x)
> }
> 
> m1 = nls(y~gfun(a,b,x),algorithm="port",
>     lower=c(0,0),start=c(a=1,b=1))
> 
> try(confint(m1))
> ----------------
> 
> for what it's worth, the logic appears to be OK in mle in the stats4
> library:
> --------------
> library(stats4)
> 
> mfun <- function(a,b,s) {
>     if (a<0 || b<0 || s<0) stop("bounds violated")
>     -sum(dnorm(y,a*x/(1+a*b*x),sd=s,log=TRUE))
> }
> 
> m2 = mle(minuslogl=mfun,
>     start=list(a=1,b=1,s=0.1),
>     method="L-BFGS-B",lower=c(0.002,0.002,0.002))
> 
> confint(m2)
> 
> m2b = mle(minuslogl=mfun,
>     fixed=list(b=0),start=list(a=1,s=0.1),
>     method="L-BFGS-B",lower=c(0.002,0.002,0.002))
> ## set boundary slightly above zero to avoid
> ## boundary cases
> 
> dev <- 2*(-logLik(m2b)+logLik(m2))
> as.numeric(pchisq(dev,lower.tail=FALSE,df=1))
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From andy_liaw at merck.com  Sat Jan 21 04:27:45 2006
From: andy_liaw at merck.com (Liaw, Andy)
Date: Fri, 20 Jan 2006 22:27:45 -0500
Subject: [Rd] Minumum memory requirements to run R.
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED732@usctmx1106.merck.com>

From: Kjetil Brinchmann Halvorsen
> 
> Prof Brian Ripley wrote:
> > Quite a while back we set the goal of running R in 16Mb 
> RAM, as people (I 
> > think Kjetil) had teaching labs that small.
> 
> It's a while since I actually har R used on such small 
> machines, I think
> 64 MB is quite acceptable now.
> 
> Kjetil
> 
> > 
> > Since then R has grown, and we has recently started to 
> optimize R for 
> > speed rather than size.  I recently tested R-devel on my 
> ancient Win98 
> > notebook with 64Mb RAM -- it ran but startup was rather 
> slow on what I 
> > think is a 233MHz processor and very slow disc.
> > 
> > R still runs in 16Mb, but that is getting tight.  Does 
> anyone have any 
> > need to run on a smaller machine than my 64Mb notebook?

I sure don't, but I wouldn't be surprised if one of these days someone
figures out how to get R to run on a video card...  (I recall that there was
a tutorial session at some datamining conference last year that showed
people how to use the GPU for numerical computation, so this may not be too
far fetched.)

Andy


From ligges at statistik.uni-dortmund.de  Sat Jan 21 12:20:01 2006
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sat, 21 Jan 2006 12:20:01 +0100
Subject: [Rd] Minumum memory requirements to run R.
In-Reply-To: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED732@usctmx1106.merck.com>
References: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED732@usctmx1106.merck.com>
Message-ID: <43D218E1.90300@statistik.uni-dortmund.de>

Liaw, Andy wrote:

> From: Kjetil Brinchmann Halvorsen
> 
>>Prof Brian Ripley wrote:
>>
>>>Quite a while back we set the goal of running R in 16Mb 
>>
>>RAM, as people (I 
>>
>>>think Kjetil) had teaching labs that small.
>>
>>It's a while since I actually har R used on such small 
>>machines, I think
>>64 MB is quite acceptable now.
>>
>>Kjetil
>>
>>
>>>Since then R has grown, and we has recently started to 
>>
>>optimize R for 
>>
>>>speed rather than size.  I recently tested R-devel on my 
>>
>>ancient Win98 
>>
>>>notebook with 64Mb RAM -- it ran but startup was rather 
>>
>>slow on what I 
>>
>>>think is a 233MHz processor and very slow disc.
>>>
>>>R still runs in 16Mb, but that is getting tight.  Does 
>>
>>anyone have any 
>>
>>>need to run on a smaller machine than my 64Mb notebook?
> 
> 
> I sure don't, but I wouldn't be surprised if one of these days someone
> figures out how to get R to run on a video card...  (I recall that there was
> a tutorial session at some datamining conference last year that showed
> people how to use the GPU for numerical computation, so this may not be too
> far fetched.)

If you want to run R on a videocard because of its enormous floating 
point speed, you have access to quite a lot of RAM (fast cards already 
have huge amounts of RAM). Well, my 20 EUR card has 32Mb only, but you 
certainly don't want to perform calculations on it... ;-)

Are there already PCIe cards that support fast writing to the main 
memory (not only fast reading)?

Uwe

> 
> Andy
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From rpeng at jhsph.edu  Sat Jan 21 17:24:54 2006
From: rpeng at jhsph.edu (Roger Peng)
Date: Sat, 21 Jan 2006 11:24:54 -0500
Subject: [Rd] Loading of namespace on load of .Rdata (was
 strange	behaviour of load)
In-Reply-To: <s3ce2ffa.094@liberator.csv.warwick.ac.uk>
References: <s3ce2ffa.094@liberator.csv.warwick.ac.uk>
Message-ID: <43D26056.3070800@jhsph.edu>

[R-help removed]

See below.

Heather Turner wrote:

<snip>
> 
> 1. There is a more general situation where it would be useful to load
> the namespace of a package after loading a saved workspace: when the
> workspace contains objects of a class for which special methods are
> required. E.g. if 'fm' from the example above were saved in a
> workspace, the namespace of MASS would not be loaded when the
> workspace was loaded into R. Thus unless MASS was loaded by the user,
> default methods would be used by summary(), print() etc rather than
> the specialised methods for objects of class "loglm".
> 
> Of course the user should quickly realise this, but there may be
> cases where the default method gives a convincing but incorrect or
> unhelpful result. An alternative would be to add an attribute to
> objects of class "loglm" (say), e.g. attr(loglmObject,
> ".Environment") <- environment(MASS) so that the namespace would
> automatically be loaded when it is required. [In fact alternatives
> such as environment(loglmObject) <- environment(MASS) or
> loglmObject$anyoldthing <- environment(MASS) would work just as well,
> but perhaps the first suggestion is neatest.].
> 
> What do others think of this idea? Should it (or an equivalent idea)
> be encouraged amongst package writers?

If I understand you correctly here, what you are talking about works 
with S4 classes.  For example, if I load an object 'x' (say, from a 
saved workspace) of class "foo" and it has a 'show()' method in package 
"bar", then

show(x)

will automatically load package "bar".  I this is accomplished because 
there is a "package" attribute that is part of the class of the object.

It's true, what you're talking about does not exist in S3, but since it 
does in S4, I'm not sure it's worth enhancing the older system.

> 
> 2. In the case highlighted by Giovanni, the namespace of ipred was
> loaded, but the package was not. This would be fine, except that the
> packages on which ipred depends *were* loaded. This seems
> inconsistent. I guess as long as there are packages without
> namespaces though, this is the only way to proceed. Perhaps in the
> meantime, package authors should be encouraged to use importFrom()
> rather than import()? Or perhaps where packages do have namespaces,
> only the namespace should be loaded in such a case.
> 
> Heather
> 
> 
>> From: Prof Brian Ripley <ripley at stats.ox.ac.uk> Date: 12 January
>> 2006 08:21:35 GMT To: giovanni parrinello <parrinel at med.unibs.it> 
>> Cc: r-help at stat.math.ethz.ch Subject: Re: [R] Strange behaviour of
>> load
>> 
>> On Wed, 11 Jan 2006, giovanni parrinello wrote:
>> 
>> 
>>> Dear All, simetimes when I load an Rdata I get this message
>>> 
>>> ####### Code:
>>> 
>>> load('bladder1.RData') Carico il pacchetto richiesto: rpart ( Bad
>>> traslastion: Load required package-...) Carico il pacchetto
>>> richiesto: MASS Carico il pacchetto richiesto: mlbench Carico il
>>> pacchetto richiesto: survival Carico il pacchetto richiesto:
>>> splines
>>> 
>>> Carico il pacchetto richiesto: 'survival'
>>> 
>>> 
>>> The following object(s) are masked from package:Hmisc :
>>> 
>>> untangle.specials
>>> 
>>> Carico il pacchetto richiesto: class Carico il pacchetto
>>> richiesto: nnet #########
>>> 
>>> So  I have many unrequired packages loaded. Any idea?
>> 
>> They are required!  My guess is that you have object(s) saved with 
>> environment the namespace of some package, and loading that
>> namespace is pulling these in.  The only CRAN package which
>> requires mlbench appears to be ipred, and that requires all of
>> those except splines, required by survival.
>> 
>> So I believe you have been using ipred and have saved a reference
>> to its namespace.
>> 
>> -- Brian D. Ripley,                  ripley at stats.ox.ac.uk 
>> Professor of Applied Statistics,
>> http://www.stats.ox.ac.uk/~ripley/ University of Oxford,
>> Tel:  +44 1865 272861 (self) 1 South Parks Road,
>> +44 1865 272866 (PA) Oxford OX1 3TG, UK                Fax:  +44
>> 1865 272595
>> 
>> ______________________________________________ 
>> R-help at stat.math.ethz.ch mailing list 
>> https://stat.ethz.ch/mailman/listinfo/r-help PLEASE do read the
>> posting guide! http://www.R-project.org/posting-guide.html
> 
> 
> Dr H Turner Research Assistant Dept. of Statistics The University of
> Warwick Coventry CV4 7AL
> 
> Tel: 024 76575870 Url: www.warwick.ac.uk/go/heatherturner
> 
> ______________________________________________ R-devel at r-project.org
> mailing list https://stat.ethz.ch/mailman/listinfo/r-devel
> 

-- 
Roger D. Peng  |  http://www.biostat.jhsph.edu/~rpeng/


From gavin.simpson at ucl.ac.uk  Sat Jan 21 19:05:19 2006
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Sat, 21 Jan 2006 18:05:19 +0000
Subject: [Rd] Bug in xy.coords() or documentation error?
Message-ID: <1137866719.2523.33.camel@dsl-217-155-166-107.zen.co.uk>

Hi,

I noticed the following problem with xy.coords() in R 2.2.1-patched
(version info at the foot of this email) and R 2.3.0 unstable
(subversion no: r37123):

> xy.coords(x = matrix(1:20, ncol = 2))
Error in xy.coords(x = matrix(1:20, ncol = 2)) :
        argument "y" is missing, with no default
> xy.coords(x = matrix(1:20, ncol = 2), y = NULL)
$x
 [1]  1  2  3  4  5  6  7  8  9 10

$y
 [1] 11 12 13 14 15 16 17 18 19 20

$xlab
[1] "[,1]"

$ylab
[1] "[,2]"

And:

> xy.coords(x = data.frame(x = 1:10, y = 1:10))
Error in xy.coords(x = data.frame(x = 1:10, y = 1:10)) :
        argument "y" is missing, with no default
> xy.coords(x = data.frame(x = 1:10, y = 1:10), y = NULL)
$x
 [1]  1  2  3  4  5  6  7  8  9 10

$y
 [1]  1  2  3  4  5  6  7  8  9 10

$xlab
[1] "x"

$ylab
[1] "y"

... for example.

?xy.coords states:

    x, y: the x and y coordinates of a set of points. Alternatively, a
          single argument 'x' can be provided.

Given that, I would have thought the above examples would have worked
without explicitly passing y = NULL to xy.coords(). However, ?xy,coords
later states:

    If 'y' is 'NULL' and 'x' is a

and the examples all illustrate the use of NULL passed as y.

Is this a documentation error and a single argument x is not allowed, or
is this a bug in the code? Either way, ?xy.coords contradicts itself as
one would expect to be able to pass only x given the statement above.

If this is a bug in the code, a potential workaround appears to be to
change the first line of xy.coords from:

   if (is.null(y)) {

to

   if (missing(y) || is.null(y)) {

but I haven't tested this on anything other than my two examples.

I will file a bug report if my observation is correct - but given all
the erroneous bug reports lately, I thought I'd try my luck here where
an error on my part would not cause the maintainers of the bug tracker
any extra work.

> version
         _
platform i686-pc-linux-gnu
arch     i686
os       linux-gnu
system   i686, linux-gnu
status   Patched
major    2
minor    2.1
year     2006
month    01
day      18
svn rev  37123
language R
> sessionInfo()
R version 2.2.1, 2006-01-18, i686-pc-linux-gnu

attached base packages:
[1] "methods"   "stats"     "graphics"  "grDevices"
[5] "utils"     "datasets"  "base"

All the best,

Gav

-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
Gavin Simpson                     [T] +44 (0)20 7679 5522
ENSIS Research Fellow             [F] +44 (0)20 7679 7565
ENSIS Ltd. & ECRC                 [E] gavin.simpsonATNOSPAMucl.ac.uk
UCL Department of Geography       [W] http://www.ucl.ac.uk/~ucfagls/cv/
26 Bedford Way                    [W] http://www.ucl.ac.uk/~ucfagls/
London.  WC1H 0AP.
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%


From ggrothendieck at gmail.com  Sat Jan 21 19:12:06 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 21 Jan 2006 13:12:06 -0500
Subject: [Rd] Bug in xy.coords() or documentation error?
In-Reply-To: <1137866719.2523.33.camel@dsl-217-155-166-107.zen.co.uk>
References: <1137866719.2523.33.camel@dsl-217-155-166-107.zen.co.uk>
Message-ID: <971536df0601211012t19e45314ieb573d8acf71a32b@mail.gmail.com>

This was discussed just recently.   This is a design
error but the maintainers claim there are no cases of
interest where it matters.


On 1/21/06, Gavin Simpson <gavin.simpson at ucl.ac.uk> wrote:
> Hi,
>
> I noticed the following problem with xy.coords() in R 2.2.1-patched
> (version info at the foot of this email) and R 2.3.0 unstable
> (subversion no: r37123):
>
> > xy.coords(x = matrix(1:20, ncol = 2))
> Error in xy.coords(x = matrix(1:20, ncol = 2)) :
>        argument "y" is missing, with no default
> > xy.coords(x = matrix(1:20, ncol = 2), y = NULL)
> $x
>  [1]  1  2  3  4  5  6  7  8  9 10
>
> $y
>  [1] 11 12 13 14 15 16 17 18 19 20
>
> $xlab
> [1] "[,1]"
>
> $ylab
> [1] "[,2]"
>
> And:
>
> > xy.coords(x = data.frame(x = 1:10, y = 1:10))
> Error in xy.coords(x = data.frame(x = 1:10, y = 1:10)) :
>        argument "y" is missing, with no default
> > xy.coords(x = data.frame(x = 1:10, y = 1:10), y = NULL)
> $x
>  [1]  1  2  3  4  5  6  7  8  9 10
>
> $y
>  [1]  1  2  3  4  5  6  7  8  9 10
>
> $xlab
> [1] "x"
>
> $ylab
> [1] "y"
>
> ... for example.
>
> ?xy.coords states:
>
>    x, y: the x and y coordinates of a set of points. Alternatively, a
>          single argument 'x' can be provided.
>
> Given that, I would have thought the above examples would have worked
> without explicitly passing y = NULL to xy.coords(). However, ?xy,coords
> later states:
>
>    If 'y' is 'NULL' and 'x' is a
>
> and the examples all illustrate the use of NULL passed as y.
>
> Is this a documentation error and a single argument x is not allowed, or
> is this a bug in the code? Either way, ?xy.coords contradicts itself as
> one would expect to be able to pass only x given the statement above.
>
> If this is a bug in the code, a potential workaround appears to be to
> change the first line of xy.coords from:
>
>   if (is.null(y)) {
>
> to
>
>   if (missing(y) || is.null(y)) {
>
> but I haven't tested this on anything other than my two examples.
>
> I will file a bug report if my observation is correct - but given all
> the erroneous bug reports lately, I thought I'd try my luck here where
> an error on my part would not cause the maintainers of the bug tracker
> any extra work.
>
> > version
>         _
> platform i686-pc-linux-gnu
> arch     i686
> os       linux-gnu
> system   i686, linux-gnu
> status   Patched
> major    2
> minor    2.1
> year     2006
> month    01
> day      18
> svn rev  37123
> language R
> > sessionInfo()
> R version 2.2.1, 2006-01-18, i686-pc-linux-gnu
>
> attached base packages:
> [1] "methods"   "stats"     "graphics"  "grDevices"
> [5] "utils"     "datasets"  "base"
>
> All the best,
>
> Gav
>
> --
> %~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
> Gavin Simpson                     [T] +44 (0)20 7679 5522
> ENSIS Research Fellow             [F] +44 (0)20 7679 7565
> ENSIS Ltd. & ECRC                 [E] gavin.simpsonATNOSPAMucl.ac.uk
> UCL Department of Geography       [W] http://www.ucl.ac.uk/~ucfagls/cv/
> 26 Bedford Way                    [W] http://www.ucl.ac.uk/~ucfagls/
> London.  WC1H 0AP.
> %~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From gavin.simpson at ucl.ac.uk  Sat Jan 21 19:21:52 2006
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Sat, 21 Jan 2006 18:21:52 +0000
Subject: [Rd] Bug in xy.coords() or documentation error?
In-Reply-To: <971536df0601211012t19e45314ieb573d8acf71a32b@mail.gmail.com>
References: <1137866719.2523.33.camel@dsl-217-155-166-107.zen.co.uk>
	<971536df0601211012t19e45314ieb573d8acf71a32b@mail.gmail.com>
Message-ID: <1137867712.2523.41.camel@dsl-217-155-166-107.zen.co.uk>

On Sat, 2006-01-21 at 13:12 -0500, Gabor Grothendieck wrote:
> This was discussed just recently.   This is a design
> error but the maintainers claim there are no cases of
> interest where it matters.

Thanks Gabor,

I must have missed that discussion whilst I was on vacation. If what you
say was the outcome of that discussion, it still means that the
documentation for xy.coords is in error, as you may *not* provide a
single argument 'x'.

If the intention is to keep the current behaviour - which is fine - then
the documentation should be changed, perhaps along the lines of:

    x, y: the x and y coordinates of a set of points. Alternatively, a
          single object 'x' can be provided if 'y = NULL' is also  
          supplied.

'object' might not be correct here - is a formula an 'object'?

Cheers,

Gav

> 
> On 1/21/06, Gavin Simpson <gavin.simpson at ucl.ac.uk> wrote:
> > Hi,
> >
> > I noticed the following problem with xy.coords() in R 2.2.1-patched
> > (version info at the foot of this email) and R 2.3.0 unstable
> > (subversion no: r37123):
> >
> > > xy.coords(x = matrix(1:20, ncol = 2))
> > Error in xy.coords(x = matrix(1:20, ncol = 2)) :
> >        argument "y" is missing, with no default
> > > xy.coords(x = matrix(1:20, ncol = 2), y = NULL)
> > $x
> >  [1]  1  2  3  4  5  6  7  8  9 10
> >
> > $y
> >  [1] 11 12 13 14 15 16 17 18 19 20
> >
> > $xlab
> > [1] "[,1]"
> >
> > $ylab
> > [1] "[,2]"
> >
> > And:
> >
> > > xy.coords(x = data.frame(x = 1:10, y = 1:10))
> > Error in xy.coords(x = data.frame(x = 1:10, y = 1:10)) :
> >        argument "y" is missing, with no default
> > > xy.coords(x = data.frame(x = 1:10, y = 1:10), y = NULL)
> > $x
> >  [1]  1  2  3  4  5  6  7  8  9 10
> >
> > $y
> >  [1]  1  2  3  4  5  6  7  8  9 10
> >
> > $xlab
> > [1] "x"
> >
> > $ylab
> > [1] "y"
> >
> > ... for example.
> >
> > ?xy.coords states:
> >
> >    x, y: the x and y coordinates of a set of points. Alternatively, a
> >          single argument 'x' can be provided.
> >
> > Given that, I would have thought the above examples would have worked
> > without explicitly passing y = NULL to xy.coords(). However, ?xy,coords
> > later states:
> >
> >    If 'y' is 'NULL' and 'x' is a
> >
> > and the examples all illustrate the use of NULL passed as y.
> >
> > Is this a documentation error and a single argument x is not allowed, or
> > is this a bug in the code? Either way, ?xy.coords contradicts itself as
> > one would expect to be able to pass only x given the statement above.
> >
> > If this is a bug in the code, a potential workaround appears to be to
> > change the first line of xy.coords from:
> >
> >   if (is.null(y)) {
> >
> > to
> >
> >   if (missing(y) || is.null(y)) {
> >
> > but I haven't tested this on anything other than my two examples.
> >
> > I will file a bug report if my observation is correct - but given all
> > the erroneous bug reports lately, I thought I'd try my luck here where
> > an error on my part would not cause the maintainers of the bug tracker
> > any extra work.
> >
> > > version
> >         _
> > platform i686-pc-linux-gnu
> > arch     i686
> > os       linux-gnu
> > system   i686, linux-gnu
> > status   Patched
> > major    2
> > minor    2.1
> > year     2006
> > month    01
> > day      18
> > svn rev  37123
> > language R
> > > sessionInfo()
> > R version 2.2.1, 2006-01-18, i686-pc-linux-gnu
> >
> > attached base packages:
> > [1] "methods"   "stats"     "graphics"  "grDevices"
> > [5] "utils"     "datasets"  "base"
> >
> > All the best,
> >
> > Gav
> >
> > --
> > %~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
> > Gavin Simpson                     [T] +44 (0)20 7679 5522
> > ENSIS Research Fellow             [F] +44 (0)20 7679 7565
> > ENSIS Ltd. & ECRC                 [E] gavin.simpsonATNOSPAMucl.ac.uk
> > UCL Department of Geography       [W] http://www.ucl.ac.uk/~ucfagls/cv/
> > 26 Bedford Way                    [W] http://www.ucl.ac.uk/~ucfagls/
> > London.  WC1H 0AP.
> > %~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
Gavin Simpson                     [T] +44 (0)20 7679 5522
ENSIS Research Fellow             [F] +44 (0)20 7679 7565
ENSIS Ltd. & ECRC                 [E] gavin.simpsonATNOSPAMucl.ac.uk
UCL Department of Geography       [W] http://www.ucl.ac.uk/~ucfagls/cv/
26 Bedford Way                    [W] http://www.ucl.ac.uk/~ucfagls/
London.  WC1H 0AP.
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%


From ggrothendieck at gmail.com  Sat Jan 21 19:39:02 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 21 Jan 2006 13:39:02 -0500
Subject: [Rd] Bug in xy.coords() or documentation error?
In-Reply-To: <1137867712.2523.41.camel@dsl-217-155-166-107.zen.co.uk>
References: <1137866719.2523.33.camel@dsl-217-155-166-107.zen.co.uk>
	<971536df0601211012t19e45314ieb573d8acf71a32b@mail.gmail.com>
	<1137867712.2523.41.camel@dsl-217-155-166-107.zen.co.uk>
Message-ID: <971536df0601211039h3d84cddei18c2c02a5eb5d3c3@mail.gmail.com>

I think the docs have been changed for the next vesion
of R.

On 1/21/06, Gavin Simpson <gavin.simpson at ucl.ac.uk> wrote:
> On Sat, 2006-01-21 at 13:12 -0500, Gabor Grothendieck wrote:
> > This was discussed just recently.   This is a design
> > error but the maintainers claim there are no cases of
> > interest where it matters.
>
> Thanks Gabor,
>
> I must have missed that discussion whilst I was on vacation. If what you
> say was the outcome of that discussion, it still means that the
> documentation for xy.coords is in error, as you may *not* provide a
> single argument 'x'.
>
> If the intention is to keep the current behaviour - which is fine - then
> the documentation should be changed, perhaps along the lines of:
>
>    x, y: the x and y coordinates of a set of points. Alternatively, a
>          single object 'x' can be provided if 'y = NULL' is also
>          supplied.
>
> 'object' might not be correct here - is a formula an 'object'?
>
> Cheers,
>
> Gav
>
> >
> > On 1/21/06, Gavin Simpson <gavin.simpson at ucl.ac.uk> wrote:
> > > Hi,
> > >
> > > I noticed the following problem with xy.coords() in R 2.2.1-patched
> > > (version info at the foot of this email) and R 2.3.0 unstable
> > > (subversion no: r37123):
> > >
> > > > xy.coords(x = matrix(1:20, ncol = 2))
> > > Error in xy.coords(x = matrix(1:20, ncol = 2)) :
> > >        argument "y" is missing, with no default
> > > > xy.coords(x = matrix(1:20, ncol = 2), y = NULL)
> > > $x
> > >  [1]  1  2  3  4  5  6  7  8  9 10
> > >
> > > $y
> > >  [1] 11 12 13 14 15 16 17 18 19 20
> > >
> > > $xlab
> > > [1] "[,1]"
> > >
> > > $ylab
> > > [1] "[,2]"
> > >
> > > And:
> > >
> > > > xy.coords(x = data.frame(x = 1:10, y = 1:10))
> > > Error in xy.coords(x = data.frame(x = 1:10, y = 1:10)) :
> > >        argument "y" is missing, with no default
> > > > xy.coords(x = data.frame(x = 1:10, y = 1:10), y = NULL)
> > > $x
> > >  [1]  1  2  3  4  5  6  7  8  9 10
> > >
> > > $y
> > >  [1]  1  2  3  4  5  6  7  8  9 10
> > >
> > > $xlab
> > > [1] "x"
> > >
> > > $ylab
> > > [1] "y"
> > >
> > > ... for example.
> > >
> > > ?xy.coords states:
> > >
> > >    x, y: the x and y coordinates of a set of points. Alternatively, a
> > >          single argument 'x' can be provided.
> > >
> > > Given that, I would have thought the above examples would have worked
> > > without explicitly passing y = NULL to xy.coords(). However, ?xy,coords
> > > later states:
> > >
> > >    If 'y' is 'NULL' and 'x' is a
> > >
> > > and the examples all illustrate the use of NULL passed as y.
> > >
> > > Is this a documentation error and a single argument x is not allowed, or
> > > is this a bug in the code? Either way, ?xy.coords contradicts itself as
> > > one would expect to be able to pass only x given the statement above.
> > >
> > > If this is a bug in the code, a potential workaround appears to be to
> > > change the first line of xy.coords from:
> > >
> > >   if (is.null(y)) {
> > >
> > > to
> > >
> > >   if (missing(y) || is.null(y)) {
> > >
> > > but I haven't tested this on anything other than my two examples.
> > >
> > > I will file a bug report if my observation is correct - but given all
> > > the erroneous bug reports lately, I thought I'd try my luck here where
> > > an error on my part would not cause the maintainers of the bug tracker
> > > any extra work.
> > >
> > > > version
> > >         _
> > > platform i686-pc-linux-gnu
> > > arch     i686
> > > os       linux-gnu
> > > system   i686, linux-gnu
> > > status   Patched
> > > major    2
> > > minor    2.1
> > > year     2006
> > > month    01
> > > day      18
> > > svn rev  37123
> > > language R
> > > > sessionInfo()
> > > R version 2.2.1, 2006-01-18, i686-pc-linux-gnu
> > >
> > > attached base packages:
> > > [1] "methods"   "stats"     "graphics"  "grDevices"
> > > [5] "utils"     "datasets"  "base"
> > >
> > > All the best,
> > >
> > > Gav
> > >
> > > --
> > > %~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
> > > Gavin Simpson                     [T] +44 (0)20 7679 5522
> > > ENSIS Research Fellow             [F] +44 (0)20 7679 7565
> > > ENSIS Ltd. & ECRC                 [E] gavin.simpsonATNOSPAMucl.ac.uk
> > > UCL Department of Geography       [W] http://www.ucl.ac.uk/~ucfagls/cv/
> > > 26 Bedford Way                    [W] http://www.ucl.ac.uk/~ucfagls/
> > > London.  WC1H 0AP.
> > > %~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
> > >
> > > ______________________________________________
> > > R-devel at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-devel
> > >
> --
> %~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
> Gavin Simpson                     [T] +44 (0)20 7679 5522
> ENSIS Research Fellow             [F] +44 (0)20 7679 7565
> ENSIS Ltd. & ECRC                 [E] gavin.simpsonATNOSPAMucl.ac.uk
> UCL Department of Geography       [W] http://www.ucl.ac.uk/~ucfagls/cv/
> 26 Bedford Way                    [W] http://www.ucl.ac.uk/~ucfagls/
> London.  WC1H 0AP.
> %~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
>
>


From gavin.simpson at ucl.ac.uk  Sat Jan 21 19:52:09 2006
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Sat, 21 Jan 2006 18:52:09 +0000
Subject: [Rd] Bug in xy.coords() or documentation error?
In-Reply-To: <971536df0601211039h3d84cddei18c2c02a5eb5d3c3@mail.gmail.com>
References: <1137866719.2523.33.camel@dsl-217-155-166-107.zen.co.uk>
	<971536df0601211012t19e45314ieb573d8acf71a32b@mail.gmail.com>
	<1137867712.2523.41.camel@dsl-217-155-166-107.zen.co.uk>
	<971536df0601211039h3d84cddei18c2c02a5eb5d3c3@mail.gmail.com>
Message-ID: <1137869529.2523.44.camel@dsl-217-155-166-107.zen.co.uk>

On Sat, 2006-01-21 at 13:39 -0500, Gabor Grothendieck wrote:
> I think the docs have been changed for the next vesion
> of R.

Not in R Version 2.3.0 Under development (unstable) (2006-01-18 r37123)
downloaded today.

G

> 
> On 1/21/06, Gavin Simpson <gavin.simpson at ucl.ac.uk> wrote:
> > On Sat, 2006-01-21 at 13:12 -0500, Gabor Grothendieck wrote:
> > > This was discussed just recently.   This is a design
> > > error but the maintainers claim there are no cases of
> > > interest where it matters.
> >
> > Thanks Gabor,
> >
> > I must have missed that discussion whilst I was on vacation. If what you
> > say was the outcome of that discussion, it still means that the
> > documentation for xy.coords is in error, as you may *not* provide a
> > single argument 'x'.
> >
> > If the intention is to keep the current behaviour - which is fine - then
> > the documentation should be changed, perhaps along the lines of:
> >
> >    x, y: the x and y coordinates of a set of points. Alternatively, a
> >          single object 'x' can be provided if 'y = NULL' is also
> >          supplied.
> >
> > 'object' might not be correct here - is a formula an 'object'?
> >
> > Cheers,
> >
> > Gav
> >
> > >
> > > On 1/21/06, Gavin Simpson <gavin.simpson at ucl.ac.uk> wrote:
> > > > Hi,
> > > >
> > > > I noticed the following problem with xy.coords() in R 2.2.1-patched
> > > > (version info at the foot of this email) and R 2.3.0 unstable
> > > > (subversion no: r37123):
> > > >
> > > > > xy.coords(x = matrix(1:20, ncol = 2))
> > > > Error in xy.coords(x = matrix(1:20, ncol = 2)) :
> > > >        argument "y" is missing, with no default
> > > > > xy.coords(x = matrix(1:20, ncol = 2), y = NULL)
> > > > $x
> > > >  [1]  1  2  3  4  5  6  7  8  9 10
> > > >
> > > > $y
> > > >  [1] 11 12 13 14 15 16 17 18 19 20
> > > >
> > > > $xlab
> > > > [1] "[,1]"
> > > >
> > > > $ylab
> > > > [1] "[,2]"
> > > >
> > > > And:
> > > >
> > > > > xy.coords(x = data.frame(x = 1:10, y = 1:10))
> > > > Error in xy.coords(x = data.frame(x = 1:10, y = 1:10)) :
> > > >        argument "y" is missing, with no default
> > > > > xy.coords(x = data.frame(x = 1:10, y = 1:10), y = NULL)
> > > > $x
> > > >  [1]  1  2  3  4  5  6  7  8  9 10
> > > >
> > > > $y
> > > >  [1]  1  2  3  4  5  6  7  8  9 10
> > > >
> > > > $xlab
> > > > [1] "x"
> > > >
> > > > $ylab
> > > > [1] "y"
> > > >
> > > > ... for example.
> > > >
> > > > ?xy.coords states:
> > > >
> > > >    x, y: the x and y coordinates of a set of points. Alternatively, a
> > > >          single argument 'x' can be provided.
> > > >
> > > > Given that, I would have thought the above examples would have worked
> > > > without explicitly passing y = NULL to xy.coords(). However, ?xy,coords
> > > > later states:
> > > >
> > > >    If 'y' is 'NULL' and 'x' is a
> > > >
> > > > and the examples all illustrate the use of NULL passed as y.
> > > >
> > > > Is this a documentation error and a single argument x is not allowed, or
> > > > is this a bug in the code? Either way, ?xy.coords contradicts itself as
> > > > one would expect to be able to pass only x given the statement above.
> > > >
> > > > If this is a bug in the code, a potential workaround appears to be to
> > > > change the first line of xy.coords from:
> > > >
> > > >   if (is.null(y)) {
> > > >
> > > > to
> > > >
> > > >   if (missing(y) || is.null(y)) {
> > > >
> > > > but I haven't tested this on anything other than my two examples.
> > > >
> > > > I will file a bug report if my observation is correct - but given all
> > > > the erroneous bug reports lately, I thought I'd try my luck here where
> > > > an error on my part would not cause the maintainers of the bug tracker
> > > > any extra work.
> > > >
> > > > > version
> > > >         _
> > > > platform i686-pc-linux-gnu
> > > > arch     i686
> > > > os       linux-gnu
> > > > system   i686, linux-gnu
> > > > status   Patched
> > > > major    2
> > > > minor    2.1
> > > > year     2006
> > > > month    01
> > > > day      18
> > > > svn rev  37123
> > > > language R
> > > > > sessionInfo()
> > > > R version 2.2.1, 2006-01-18, i686-pc-linux-gnu
> > > >
> > > > attached base packages:
> > > > [1] "methods"   "stats"     "graphics"  "grDevices"
> > > > [5] "utils"     "datasets"  "base"
> > > >
> > > > All the best,
> > > >
> > > > Gav
> > > >
> > > > --
> > > > %~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
> > > > Gavin Simpson                     [T] +44 (0)20 7679 5522
> > > > ENSIS Research Fellow             [F] +44 (0)20 7679 7565
> > > > ENSIS Ltd. & ECRC                 [E] gavin.simpsonATNOSPAMucl.ac.uk
> > > > UCL Department of Geography       [W] http://www.ucl.ac.uk/~ucfagls/cv/
> > > > 26 Bedford Way                    [W] http://www.ucl.ac.uk/~ucfagls/
> > > > London.  WC1H 0AP.
> > > > %~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
> > > >
> > > > ______________________________________________
> > > > R-devel at r-project.org mailing list
> > > > https://stat.ethz.ch/mailman/listinfo/r-devel
> > > >
> > --
> > %~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
> > Gavin Simpson                     [T] +44 (0)20 7679 5522
> > ENSIS Research Fellow             [F] +44 (0)20 7679 7565
> > ENSIS Ltd. & ECRC                 [E] gavin.simpsonATNOSPAMucl.ac.uk
> > UCL Department of Geography       [W] http://www.ucl.ac.uk/~ucfagls/cv/
> > 26 Bedford Way                    [W] http://www.ucl.ac.uk/~ucfagls/
> > London.  WC1H 0AP.
> > %~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
> >
> >
-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
Gavin Simpson                     [T] +44 (0)20 7679 5522
ENSIS Research Fellow             [F] +44 (0)20 7679 7565
ENSIS Ltd. & ECRC                 [E] gavin.simpsonATNOSPAMucl.ac.uk
UCL Department of Geography       [W] http://www.ucl.ac.uk/~ucfagls/cv/
26 Bedford Way                    [W] http://www.ucl.ac.uk/~ucfagls/
London.  WC1H 0AP.
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%


From denswei at bee.net  Sat Jan 21 19:55:51 2006
From: denswei at bee.net (denswei@bee.net)
Date: Sat, 21 Jan 2006 19:55:51 +0100 (CET)
Subject: [Rd] Quits immediately / missing files (PR#8515)
Message-ID: <20060121185551.CD9E528FD7@slim.kubism.ku.dk>

Full_Name: Dennis Sweitzer
Version: 1.14?  2.2.1?
OS: 10.3.5
Submission from: (NULL) (216.83.100.22)


I just downloaded R, performed the installation as instructed, but when I run
the program it immediately quits.

The system generates the following bug report to be sent to Apple.  After that
is a copy of the version information displayed at installation.

R.Frameworks is not in the library/frameworks directory, so it appears that it
is not being loaded.  However, the installation program reported that it
successfully loaded.  Installing the file R.Frameworks.pkg yields the same
results.

Sincerely,
Dennis Sweitzer
++++++++++++++++++++++++++++++++++++++++++++++++++

Date/Time:      2006-01-20 12:17:18 -0500
OS Version:     10.3.5 (Build 7P220)
Report Version: 2

Command: R
Path:    /Applications/R.app/Contents/MacOS/R
Version: 1.14 (2129)
PID:     450
Thread:  Unknown

Link (dyld) error:

dyld: /Applications/R.app/Contents/MacOS/R Undefined symbols:
/Library/Frameworks/R.framework/Resources/lib/libR.dylib undefined reference
to _cacos expected to be defined in /usr/lib/libSystem.B.dylib
/Library/Frameworks/R.framework/Resources/lib/libR.dylib undefined reference
to _cacosh expected to be defined in /usr/lib/libSystem.B.dylib
/Library/Frameworks/R.framework/Resources/lib/libR.dylib undefined reference
to _carg expected to be defined in /usr/lib/libSystem.B.dylib
/Library/Frameworks/R.framework/Resources/lib/libR.dylib undefined reference
to _casin expected to be defined in /usr/lib/libSystem.B.dylib
/Library/Frameworks/R.framework/Resources/lib/libR.dylib undefined reference
to _casinh expected to be defined in /usr/lib/libSystem.B.dylib
/Library/Frameworks/R.framework/Resources/lib/libR.dylib undefined reference
to _catan expected to be defined in /usr/lib/libSystem.B.dylib
/Library/Frameworks/R.framework/Resources/lib/libR.dylib undefined reference
to _catanh expected

++++++++++++++++
Package information from the installation:
R 2.2.1
Version 2.2.1 (2005-12-20)
for Mac OS X 10.3 (Panther) and higher

This multi-package contains following main components:
- R Framework 2.2.1
- R.app GUI 1.14
......

Requirements:
- Mac OS X 10.3 (Panther) or higher on a PowerPC Mac

The Cocoa GUI called R.app will be installed by default in your Applications
folder,  R framework will be installed in /Library/Frameworks. ......

+++++++++++++++++


From ggrothendieck at gmail.com  Sat Jan 21 20:05:50 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 21 Jan 2006 14:05:50 -0500
Subject: [Rd] Bug in xy.coords() or documentation error?
In-Reply-To: <1137869529.2523.44.camel@dsl-217-155-166-107.zen.co.uk>
References: <1137866719.2523.33.camel@dsl-217-155-166-107.zen.co.uk>
	<971536df0601211012t19e45314ieb573d8acf71a32b@mail.gmail.com>
	<1137867712.2523.41.camel@dsl-217-155-166-107.zen.co.uk>
	<971536df0601211039h3d84cddei18c2c02a5eb5d3c3@mail.gmail.com>
	<1137869529.2523.44.camel@dsl-217-155-166-107.zen.co.uk>
Message-ID: <971536df0601211105n72c280fcja67bdb91d817e31f@mail.gmail.com>

If the latest version does not have it then I guess it
was not done.  I do agree with you that there is
a problem and here and think that the code, not
just the docs, should be fixed.

On 1/21/06, Gavin Simpson <gavin.simpson at ucl.ac.uk> wrote:
> On Sat, 2006-01-21 at 13:39 -0500, Gabor Grothendieck wrote:
> > I think the docs have been changed for the next vesion
> > of R.
>
> Not in R Version 2.3.0 Under development (unstable) (2006-01-18 r37123)
> downloaded today.
>
> G
>
> >
> > On 1/21/06, Gavin Simpson <gavin.simpson at ucl.ac.uk> wrote:
> > > On Sat, 2006-01-21 at 13:12 -0500, Gabor Grothendieck wrote:
> > > > This was discussed just recently.   This is a design
> > > > error but the maintainers claim there are no cases of
> > > > interest where it matters.
> > >
> > > Thanks Gabor,
> > >
> > > I must have missed that discussion whilst I was on vacation. If what you
> > > say was the outcome of that discussion, it still means that the
> > > documentation for xy.coords is in error, as you may *not* provide a
> > > single argument 'x'.
> > >
> > > If the intention is to keep the current behaviour - which is fine - then
> > > the documentation should be changed, perhaps along the lines of:
> > >
> > >    x, y: the x and y coordinates of a set of points. Alternatively, a
> > >          single object 'x' can be provided if 'y = NULL' is also
> > >          supplied.
> > >
> > > 'object' might not be correct here - is a formula an 'object'?
> > >
> > > Cheers,
> > >
> > > Gav
> > >
> > > >
> > > > On 1/21/06, Gavin Simpson <gavin.simpson at ucl.ac.uk> wrote:
> > > > > Hi,
> > > > >
> > > > > I noticed the following problem with xy.coords() in R 2.2.1-patched
> > > > > (version info at the foot of this email) and R 2.3.0 unstable
> > > > > (subversion no: r37123):
> > > > >
> > > > > > xy.coords(x = matrix(1:20, ncol = 2))
> > > > > Error in xy.coords(x = matrix(1:20, ncol = 2)) :
> > > > >        argument "y" is missing, with no default
> > > > > > xy.coords(x = matrix(1:20, ncol = 2), y = NULL)
> > > > > $x
> > > > >  [1]  1  2  3  4  5  6  7  8  9 10
> > > > >
> > > > > $y
> > > > >  [1] 11 12 13 14 15 16 17 18 19 20
> > > > >
> > > > > $xlab
> > > > > [1] "[,1]"
> > > > >
> > > > > $ylab
> > > > > [1] "[,2]"
> > > > >
> > > > > And:
> > > > >
> > > > > > xy.coords(x = data.frame(x = 1:10, y = 1:10))
> > > > > Error in xy.coords(x = data.frame(x = 1:10, y = 1:10)) :
> > > > >        argument "y" is missing, with no default
> > > > > > xy.coords(x = data.frame(x = 1:10, y = 1:10), y = NULL)
> > > > > $x
> > > > >  [1]  1  2  3  4  5  6  7  8  9 10
> > > > >
> > > > > $y
> > > > >  [1]  1  2  3  4  5  6  7  8  9 10
> > > > >
> > > > > $xlab
> > > > > [1] "x"
> > > > >
> > > > > $ylab
> > > > > [1] "y"
> > > > >
> > > > > ... for example.
> > > > >
> > > > > ?xy.coords states:
> > > > >
> > > > >    x, y: the x and y coordinates of a set of points. Alternatively, a
> > > > >          single argument 'x' can be provided.
> > > > >
> > > > > Given that, I would have thought the above examples would have worked
> > > > > without explicitly passing y = NULL to xy.coords(). However, ?xy,coords
> > > > > later states:
> > > > >
> > > > >    If 'y' is 'NULL' and 'x' is a
> > > > >
> > > > > and the examples all illustrate the use of NULL passed as y.
> > > > >
> > > > > Is this a documentation error and a single argument x is not allowed, or
> > > > > is this a bug in the code? Either way, ?xy.coords contradicts itself as
> > > > > one would expect to be able to pass only x given the statement above.
> > > > >
> > > > > If this is a bug in the code, a potential workaround appears to be to
> > > > > change the first line of xy.coords from:
> > > > >
> > > > >   if (is.null(y)) {
> > > > >
> > > > > to
> > > > >
> > > > >   if (missing(y) || is.null(y)) {
> > > > >
> > > > > but I haven't tested this on anything other than my two examples.
> > > > >
> > > > > I will file a bug report if my observation is correct - but given all
> > > > > the erroneous bug reports lately, I thought I'd try my luck here where
> > > > > an error on my part would not cause the maintainers of the bug tracker
> > > > > any extra work.
> > > > >
> > > > > > version
> > > > >         _
> > > > > platform i686-pc-linux-gnu
> > > > > arch     i686
> > > > > os       linux-gnu
> > > > > system   i686, linux-gnu
> > > > > status   Patched
> > > > > major    2
> > > > > minor    2.1
> > > > > year     2006
> > > > > month    01
> > > > > day      18
> > > > > svn rev  37123
> > > > > language R
> > > > > > sessionInfo()
> > > > > R version 2.2.1, 2006-01-18, i686-pc-linux-gnu
> > > > >
> > > > > attached base packages:
> > > > > [1] "methods"   "stats"     "graphics"  "grDevices"
> > > > > [5] "utils"     "datasets"  "base"
> > > > >
> > > > > All the best,
> > > > >
> > > > > Gav
> > > > >
> > > > > --
> > > > > %~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
> > > > > Gavin Simpson                     [T] +44 (0)20 7679 5522
> > > > > ENSIS Research Fellow             [F] +44 (0)20 7679 7565
> > > > > ENSIS Ltd. & ECRC                 [E] gavin.simpsonATNOSPAMucl.ac.uk
> > > > > UCL Department of Geography       [W] http://www.ucl.ac.uk/~ucfagls/cv/
> > > > > 26 Bedford Way                    [W] http://www.ucl.ac.uk/~ucfagls/
> > > > > London.  WC1H 0AP.
> > > > > %~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
> > > > >
> > > > > ______________________________________________
> > > > > R-devel at r-project.org mailing list
> > > > > https://stat.ethz.ch/mailman/listinfo/r-devel
> > > > >
> > > --
> > > %~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
> > > Gavin Simpson                     [T] +44 (0)20 7679 5522
> > > ENSIS Research Fellow             [F] +44 (0)20 7679 7565
> > > ENSIS Ltd. & ECRC                 [E] gavin.simpsonATNOSPAMucl.ac.uk
> > > UCL Department of Geography       [W] http://www.ucl.ac.uk/~ucfagls/cv/
> > > 26 Bedford Way                    [W] http://www.ucl.ac.uk/~ucfagls/
> > > London.  WC1H 0AP.
> > > %~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
> > >
> > >
> --
> %~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
> Gavin Simpson                     [T] +44 (0)20 7679 5522
> ENSIS Research Fellow             [F] +44 (0)20 7679 7565
> ENSIS Ltd. & ECRC                 [E] gavin.simpsonATNOSPAMucl.ac.uk
> UCL Department of Geography       [W] http://www.ucl.ac.uk/~ucfagls/cv/
> 26 Bedford Way                    [W] http://www.ucl.ac.uk/~ucfagls/
> London.  WC1H 0AP.
> %~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
>
>


From murdoch at stats.uwo.ca  Sat Jan 21 20:07:20 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sat, 21 Jan 2006 14:07:20 -0500
Subject: [Rd] Bug in xy.coords() or documentation error?
In-Reply-To: <1137867712.2523.41.camel@dsl-217-155-166-107.zen.co.uk>
References: <1137866719.2523.33.camel@dsl-217-155-166-107.zen.co.uk>	<971536df0601211012t19e45314ieb573d8acf71a32b@mail.gmail.com>
	<1137867712.2523.41.camel@dsl-217-155-166-107.zen.co.uk>
Message-ID: <43D28668.1030805@stats.uwo.ca>

On 1/21/2006 1:21 PM, Gavin Simpson wrote:
> On Sat, 2006-01-21 at 13:12 -0500, Gabor Grothendieck wrote:
>> This was discussed just recently.   This is a design
>> error but the maintainers claim there are no cases of
>> interest where it matters.
> 
> Thanks Gabor,
> 
> I must have missed that discussion whilst I was on vacation. If what you
> say was the outcome of that discussion, it still means that the
> documentation for xy.coords is in error, as you may *not* provide a
> single argument 'x'.

You need to read the whole page.  You provide a single argument x by 
setting y to NULL, not by leaving it missing (as the docs said in 
earlier versions).

If you want to submit a patch to the docs, I'll take a look, but I don't 
like the one below.  It has basically the same flaw as the current docs: 
  you're providing two objects, not a single object.  Probably the 
clearest thing to do is just to say "see below" after the current 
wording, to point out that there are funny conventions here.

> If the intention is to keep the current behaviour - which is fine - then
> the documentation should be changed, perhaps along the lines of:
> 
>     x, y: the x and y coordinates of a set of points. Alternatively, a
>           single object 'x' can be provided if 'y = NULL' is also  
>           supplied.
> 
> 'object' might not be correct here - is a formula an 'object'?

Sure, why not?

Duncan Murdoch

> 
> Cheers,
> 
> Gav
> 
>> On 1/21/06, Gavin Simpson <gavin.simpson at ucl.ac.uk> wrote:
>>> Hi,
>>>
>>> I noticed the following problem with xy.coords() in R 2.2.1-patched
>>> (version info at the foot of this email) and R 2.3.0 unstable
>>> (subversion no: r37123):
>>>
>>>> xy.coords(x = matrix(1:20, ncol = 2))
>>> Error in xy.coords(x = matrix(1:20, ncol = 2)) :
>>>        argument "y" is missing, with no default
>>>> xy.coords(x = matrix(1:20, ncol = 2), y = NULL)
>>> $x
>>>  [1]  1  2  3  4  5  6  7  8  9 10
>>>
>>> $y
>>>  [1] 11 12 13 14 15 16 17 18 19 20
>>>
>>> $xlab
>>> [1] "[,1]"
>>>
>>> $ylab
>>> [1] "[,2]"
>>>
>>> And:
>>>
>>>> xy.coords(x = data.frame(x = 1:10, y = 1:10))
>>> Error in xy.coords(x = data.frame(x = 1:10, y = 1:10)) :
>>>        argument "y" is missing, with no default
>>>> xy.coords(x = data.frame(x = 1:10, y = 1:10), y = NULL)
>>> $x
>>>  [1]  1  2  3  4  5  6  7  8  9 10
>>>
>>> $y
>>>  [1]  1  2  3  4  5  6  7  8  9 10
>>>
>>> $xlab
>>> [1] "x"
>>>
>>> $ylab
>>> [1] "y"
>>>
>>> ... for example.
>>>
>>> ?xy.coords states:
>>>
>>>    x, y: the x and y coordinates of a set of points. Alternatively, a
>>>          single argument 'x' can be provided.
>>>
>>> Given that, I would have thought the above examples would have worked
>>> without explicitly passing y = NULL to xy.coords(). However, ?xy,coords
>>> later states:
>>>
>>>    If 'y' is 'NULL' and 'x' is a
>>>
>>> and the examples all illustrate the use of NULL passed as y.
>>>
>>> Is this a documentation error and a single argument x is not allowed, or
>>> is this a bug in the code? Either way, ?xy.coords contradicts itself as
>>> one would expect to be able to pass only x given the statement above.
>>>
>>> If this is a bug in the code, a potential workaround appears to be to
>>> change the first line of xy.coords from:
>>>
>>>   if (is.null(y)) {
>>>
>>> to
>>>
>>>   if (missing(y) || is.null(y)) {
>>>
>>> but I haven't tested this on anything other than my two examples.
>>>
>>> I will file a bug report if my observation is correct - but given all
>>> the erroneous bug reports lately, I thought I'd try my luck here where
>>> an error on my part would not cause the maintainers of the bug tracker
>>> any extra work.
>>>
>>>> version
>>>         _
>>> platform i686-pc-linux-gnu
>>> arch     i686
>>> os       linux-gnu
>>> system   i686, linux-gnu
>>> status   Patched
>>> major    2
>>> minor    2.1
>>> year     2006
>>> month    01
>>> day      18
>>> svn rev  37123
>>> language R
>>>> sessionInfo()
>>> R version 2.2.1, 2006-01-18, i686-pc-linux-gnu
>>>
>>> attached base packages:
>>> [1] "methods"   "stats"     "graphics"  "grDevices"
>>> [5] "utils"     "datasets"  "base"
>>>
>>> All the best,
>>>
>>> Gav
>>>
>>> --
>>> %~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
>>> Gavin Simpson                     [T] +44 (0)20 7679 5522
>>> ENSIS Research Fellow             [F] +44 (0)20 7679 7565
>>> ENSIS Ltd. & ECRC                 [E] gavin.simpsonATNOSPAMucl.ac.uk
>>> UCL Department of Geography       [W] http://www.ucl.ac.uk/~ucfagls/cv/
>>> 26 Bedford Way                    [W] http://www.ucl.ac.uk/~ucfagls/
>>> London.  WC1H 0AP.
>>> %~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>


From sfalcon at fhcrc.org  Sat Jan 21 20:20:53 2006
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Sat, 21 Jan 2006 11:20:53 -0800
Subject: [Rd] A patch for do_sample: check replace arg
Message-ID: <m2wtgt75gq.fsf@fhcrc.org>

A colleague sent me the following:

    If you specify probabilities in the 'sample' function and forget
    to type 'prob=...', then you get nonsense. E.g.
    
        sample(1:10,1,c(0,0,0,0,1,0,0,0,0,0)) 

    does not filter '5', while 
    
        sample(1:10,1,prob=c(0,0,0,0,1,0,0,0,0,0)) 

    does it correctly.  I wish this would return an error because the
    'replace' argument should only take logical args. Anyway, it is
    easy to make this mistake and having it produce an error would be
    nice.

Assuming there is not a use-case for specifying a logical vector for
the 'replace' argument, I like the idea of raising an error if replace
is not length one.  The following patch provides an implementation.

+ seth


Diff is against svn Revision: 37141
--- a/src/main/random.c Sat Jan 21 10:54:11 2006 -0800
+++ b/src/main/random.c Sat Jan 21 11:17:20 2006 -0800
@@ -453,15 +453,18 @@
 /* with/without replacement according to r. */
 SEXP attribute_hidden do_sample(SEXP call, SEXP op, SEXP args, SEXP rho)
 {
-    SEXP x, y, prob;
+    SEXP x, y, prob, sreplace;
     int k, n, replace;
     double *p;
 
     checkArity(op, args);
     n = asInteger(CAR(args)); args = CDR(args);
     k = asInteger(CAR(args)); args = CDR(args);
-    replace = asLogical(CAR(args)); args = CDR(args);
+    sreplace = CAR(args); args = CDR(args);
     prob = CAR(args);
+    if (length(sreplace) != 1)
+        errorcall(call, _("invalid '%s' argument"), "replace");
+    replace = asLogical(sreplace);
     if (replace == NA_LOGICAL)
        errorcall(call, _("invalid '%s' argument"), "replace");
     if (n == NA_INTEGER || n < 1)


From gavin.simpson at ucl.ac.uk  Sat Jan 21 20:28:09 2006
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Sat, 21 Jan 2006 19:28:09 +0000
Subject: [Rd] Bug in xy.coords() or documentation error?
In-Reply-To: <43D28668.1030805@stats.uwo.ca>
References: <1137866719.2523.33.camel@dsl-217-155-166-107.zen.co.uk>
	<971536df0601211012t19e45314ieb573d8acf71a32b@mail.gmail.com>
	<1137867712.2523.41.camel@dsl-217-155-166-107.zen.co.uk>
	<43D28668.1030805@stats.uwo.ca>
Message-ID: <1137871689.2523.56.camel@dsl-217-155-166-107.zen.co.uk>

On Sat, 2006-01-21 at 14:07 -0500, Duncan Murdoch wrote:
> On 1/21/2006 1:21 PM, Gavin Simpson wrote:
> > On Sat, 2006-01-21 at 13:12 -0500, Gabor Grothendieck wrote:
> >> This was discussed just recently.   This is a design
> >> error but the maintainers claim there are no cases of
> >> interest where it matters.
> > 
> > Thanks Gabor,
> > 
> > I must have missed that discussion whilst I was on vacation. If what you
> > say was the outcome of that discussion, it still means that the
> > documentation for xy.coords is in error, as you may *not* provide a
> > single argument 'x'.
> 
> You need to read the whole page.  You provide a single argument x by 
> setting y to NULL, not by leaving it missing (as the docs said in 
> earlier versions).
> 
> If you want to submit a patch to the docs, I'll take a look, but I don't 
> like the one below.  It has basically the same flaw as the current docs: 
>   you're providing two objects, not a single object.  Probably the 
> clearest thing to do is just to say "see below" after the current 
> wording, to point out that there are funny conventions here.

How about:

x, y: the x and y coordinates of a set of points. Alternatively, 'x' may
be a formula, list, time series or a matrix-like object with two
columns, in which case 'y' should be 'NULL', see Details below.

Or,

x, y: the x and y coordinates of a set of points. Alternatively, 'x' may
take different forms. If so, 'y' must be supplied as 'NULL'. See Details
below.

Or,

x, y: the x and y coordinates of a set of points. Alternatively, 'x' may
take different forms. See Details below.

I can provide you with a revised Rd file for xy.coords() if you think
any of the above are acceptable

All the best,

Gav

> 
> > If the intention is to keep the current behaviour - which is fine - then
> > the documentation should be changed, perhaps along the lines of:
> > 
> >     x, y: the x and y coordinates of a set of points. Alternatively, a
> >           single object 'x' can be provided if 'y = NULL' is also  
> >           supplied.
> > 
> > 'object' might not be correct here - is a formula an 'object'?
> 
> Sure, why not?
> 
> Duncan Murdoch
> 
> > 
> > Cheers,
> > 
> > Gav
> > 
> >> On 1/21/06, Gavin Simpson <gavin.simpson at ucl.ac.uk> wrote:
> >>> Hi,
> >>>
> >>> I noticed the following problem with xy.coords() in R 2.2.1-patched
> >>> (version info at the foot of this email) and R 2.3.0 unstable
> >>> (subversion no: r37123):
> >>>
> >>>> xy.coords(x = matrix(1:20, ncol = 2))
> >>> Error in xy.coords(x = matrix(1:20, ncol = 2)) :
> >>>        argument "y" is missing, with no default
> >>>> xy.coords(x = matrix(1:20, ncol = 2), y = NULL)
> >>> $x
> >>>  [1]  1  2  3  4  5  6  7  8  9 10
> >>>
> >>> $y
> >>>  [1] 11 12 13 14 15 16 17 18 19 20
> >>>
> >>> $xlab
> >>> [1] "[,1]"
> >>>
> >>> $ylab
> >>> [1] "[,2]"
> >>>
> >>> And:
> >>>
> >>>> xy.coords(x = data.frame(x = 1:10, y = 1:10))
> >>> Error in xy.coords(x = data.frame(x = 1:10, y = 1:10)) :
> >>>        argument "y" is missing, with no default
> >>>> xy.coords(x = data.frame(x = 1:10, y = 1:10), y = NULL)
> >>> $x
> >>>  [1]  1  2  3  4  5  6  7  8  9 10
> >>>
> >>> $y
> >>>  [1]  1  2  3  4  5  6  7  8  9 10
> >>>
> >>> $xlab
> >>> [1] "x"
> >>>
> >>> $ylab
> >>> [1] "y"
> >>>
> >>> ... for example.
> >>>
> >>> ?xy.coords states:
> >>>
> >>>    x, y: the x and y coordinates of a set of points. Alternatively, a
> >>>          single argument 'x' can be provided.
> >>>
> >>> Given that, I would have thought the above examples would have worked
> >>> without explicitly passing y = NULL to xy.coords(). However, ?xy,coords
> >>> later states:
> >>>
> >>>    If 'y' is 'NULL' and 'x' is a
> >>>
> >>> and the examples all illustrate the use of NULL passed as y.
> >>>
> >>> Is this a documentation error and a single argument x is not allowed, or
> >>> is this a bug in the code? Either way, ?xy.coords contradicts itself as
> >>> one would expect to be able to pass only x given the statement above.
> >>>
> >>> If this is a bug in the code, a potential workaround appears to be to
> >>> change the first line of xy.coords from:
> >>>
> >>>   if (is.null(y)) {
> >>>
> >>> to
> >>>
> >>>   if (missing(y) || is.null(y)) {
> >>>
> >>> but I haven't tested this on anything other than my two examples.
> >>>
> >>> I will file a bug report if my observation is correct - but given all
> >>> the erroneous bug reports lately, I thought I'd try my luck here where
> >>> an error on my part would not cause the maintainers of the bug tracker
> >>> any extra work.
> >>>
> >>>> version
> >>>         _
> >>> platform i686-pc-linux-gnu
> >>> arch     i686
> >>> os       linux-gnu
> >>> system   i686, linux-gnu
> >>> status   Patched
> >>> major    2
> >>> minor    2.1
> >>> year     2006
> >>> month    01
> >>> day      18
> >>> svn rev  37123
> >>> language R
> >>>> sessionInfo()
> >>> R version 2.2.1, 2006-01-18, i686-pc-linux-gnu
> >>>
> >>> attached base packages:
> >>> [1] "methods"   "stats"     "graphics"  "grDevices"
> >>> [5] "utils"     "datasets"  "base"
> >>>
> >>> All the best,
> >>>
> >>> Gav
> >>>
> >>> --
> >>> %~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
> >>> Gavin Simpson                     [T] +44 (0)20 7679 5522
> >>> ENSIS Research Fellow             [F] +44 (0)20 7679 7565
> >>> ENSIS Ltd. & ECRC                 [E] gavin.simpsonATNOSPAMucl.ac.uk
> >>> UCL Department of Geography       [W] http://www.ucl.ac.uk/~ucfagls/cv/
> >>> 26 Bedford Way                    [W] http://www.ucl.ac.uk/~ucfagls/
> >>> London.  WC1H 0AP.
> >>> %~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
> >>>
> >>> ______________________________________________
> >>> R-devel at r-project.org mailing list
> >>> https://stat.ethz.ch/mailman/listinfo/r-devel
> >>>
> 
-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
Gavin Simpson                     [T] +44 (0)20 7679 5522
ENSIS Research Fellow             [F] +44 (0)20 7679 7565
ENSIS Ltd. & ECRC                 [E] gavin.simpsonATNOSPAMucl.ac.uk
UCL Department of Geography       [W] http://www.ucl.ac.uk/~ucfagls/cv/
26 Bedford Way                    [W] http://www.ucl.ac.uk/~ucfagls/
London.  WC1H 0AP.
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%


From bolker at zoo.ufl.edu  Sat Jan 21 23:40:05 2006
From: bolker at zoo.ufl.edu (Ben Bolker)
Date: Sat, 21 Jan 2006 22:40:05 +0000 (UTC)
Subject: [Rd]
	=?utf-8?q?nls_profiling_with_algorithm=3D=22port=22_may_viol?=
	=?utf-8?b?YXRlCWJvdW5kcwkoUFIjODUwOCk=?=
References: <20060119205040.3F5DD206FA@slim.kubism.ku.dk>
	<43D1A778.6010209@pdf.com>
Message-ID: <loom.20060121T233708-691@post.gmane.org>

Spencer Graves <spencer.graves <at> pdf.com> writes:

> 
> Hi, Ben, et al.:
> 
> 	  The issue Ben identified with confint(nls(... )) generates a hard 
> failure for me.  

  "We" (being Brian Ripley and I) know about this already.
  I'm sorry I failed to specify enough info in my bug report,
but I was using R-devel/2.3.0 of (I think?) 11 January, under Linux.
Your problem is actually PR #8428, which is fixed enough to prevent
a crash in 2.2.1 patched and really fixed in 2.3.0, all thanks to
Brian Ripley.

  cheers
    Ben


From spencer.graves at pdf.com  Sun Jan 22 01:58:57 2006
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sat, 21 Jan 2006 16:58:57 -0800
Subject: [Rd] nls profiling with algorithm="port" may violate bounds
	(PR#8508)
In-Reply-To: <loom.20060121T233708-691@post.gmane.org>
References: <20060119205040.3F5DD206FA@slim.kubism.ku.dk>	<43D1A778.6010209@pdf.com>
	<loom.20060121T233708-691@post.gmane.org>
Message-ID: <43D2D8D1.1060702@pdf.com>

Dear Professors. Bolker & Ripley:

       Thank you both very much for all your creativity and hard work 
both in your generall contributions to human knowledge and specifically 
for helping make R the great thing it is today.  I had not seen a reply 
to that email in several days, so I made time to check it out.  When I 
replicated the error, I thought it my duty to report same.  I know 
that's more appropraite with "r-help" than with "r-devel", but I thought 
such a comment might help someone.  I certainly did NOT want to add to 
someones' workload a requirement to reply to my comment.

       Thanks again,
       spencer graves

Ben Bolker wrote:

> Spencer Graves <spencer.graves <at> pdf.com> writes:
> 
> 
>>Hi, Ben, et al.:
>>
>>	  The issue Ben identified with confint(nls(... )) generates a hard 
>>failure for me.  
> 
> 
>   "We" (being Brian Ripley and I) know about this already.
>   I'm sorry I failed to specify enough info in my bug report,
> but I was using R-devel/2.3.0 of (I think?) 11 January, under Linux.
> Your problem is actually PR #8428, which is fixed enough to prevent
> a crash in 2.2.1 patched and really fixed in 2.3.0, all thanks to
> Brian Ripley.
> 
>   cheers
>     Ben
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From jago at mclink.it  Sun Jan 22 10:09:22 2006
From: jago at mclink.it (stefano iacus)
Date: Sun, 22 Jan 2006 10:09:22 +0100
Subject: [Rd] Quits immediately / missing files (PR#8515)
In-Reply-To: <20060121185551.CD9E528FD7@slim.kubism.ku.dk>
References: <20060121185551.CD9E528FD7@slim.kubism.ku.dk>
Message-ID: <773F6A39-A354-4112-AF2E-F0D5A85C9175@mclink.it>

Please update your system to at least 10.3.9
stefano

Il giorno 21/gen/06, alle ore 19:55, denswei at bee.net ha scritto:

> Full_Name: Dennis Sweitzer
> Version: 1.14?  2.2.1?
> OS: 10.3.5
> Submission from: (NULL) (216.83.100.22)
>
>
> I just downloaded R, performed the installation as instructed, but  
> when I run
> the program it immediately quits.
>
> The system generates the following bug report to be sent to Apple.   
> After that
> is a copy of the version information displayed at installation.
>
> R.Frameworks is not in the library/frameworks directory, so it  
> appears that it
> is not being loaded.  However, the installation program reported  
> that it
> successfully loaded.  Installing the file R.Frameworks.pkg yields  
> the same
> results.
>
> Sincerely,
> Dennis Sweitzer
> ++++++++++++++++++++++++++++++++++++++++++++++++++
>
> Date/Time:      2006-01-20 12:17:18 -0500
> OS Version:     10.3.5 (Build 7P220)
> Report Version: 2
>
> Command: R
> Path:    /Applications/R.app/Contents/MacOS/R
> Version: 1.14 (2129)
> PID:     450
> Thread:  Unknown
>
> Link (dyld) error:
>
> dyld: /Applications/R.app/Contents/MacOS/R Undefined symbols:
> /Library/Frameworks/R.framework/Resources/lib/libR.dylib undefined  
> reference
> to _cacos expected to be defined in /usr/lib/libSystem.B.dylib
> /Library/Frameworks/R.framework/Resources/lib/libR.dylib undefined  
> reference
> to _cacosh expected to be defined in /usr/lib/libSystem.B.dylib
> /Library/Frameworks/R.framework/Resources/lib/libR.dylib undefined  
> reference
> to _carg expected to be defined in /usr/lib/libSystem.B.dylib
> /Library/Frameworks/R.framework/Resources/lib/libR.dylib undefined  
> reference
> to _casin expected to be defined in /usr/lib/libSystem.B.dylib
> /Library/Frameworks/R.framework/Resources/lib/libR.dylib undefined  
> reference
> to _casinh expected to be defined in /usr/lib/libSystem.B.dylib
> /Library/Frameworks/R.framework/Resources/lib/libR.dylib undefined  
> reference
> to _catan expected to be defined in /usr/lib/libSystem.B.dylib
> /Library/Frameworks/R.framework/Resources/lib/libR.dylib undefined  
> reference
> to _catanh expected
>
> ++++++++++++++++
> Package information from the installation:
> R 2.2.1
> Version 2.2.1 (2005-12-20)
> for Mac OS X 10.3 (Panther) and higher
>
> This multi-package contains following main components:
> - R Framework 2.2.1
> - R.app GUI 1.14
> ......
>
> Requirements:
> - Mac OS X 10.3 (Panther) or higher on a PowerPC Mac
>
> The Cocoa GUI called R.app will be installed by default in your  
> Applications
> folder,  R framework will be installed in /Library/Frameworks. ......
>
> +++++++++++++++++
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From berwin at maths.uwa.edu.au  Sun Jan 22 10:11:23 2006
From: berwin at maths.uwa.edu.au (Berwin A Turlach)
Date: Sun, 22 Jan 2006 17:11:23 +0800
Subject: [Rd] R CMD check, NAMESPACE, import: bad error?
In-Reply-To: <Pine.LNX.4.61.0601200719490.25948@gannet.stats>
References: <m24q3zbu0z.fsf@fhcrc.org>
	<17360.27502.365586.740869@bossiaea.maths.uwa.edu.au>
	<Pine.LNX.4.61.0601200719490.25948@gannet.stats>
Message-ID: <17363.19515.464525.105706@bossiaea.maths.uwa.edu.au>

G'day Brian,

>>>>> "BDR" == Prof Brian Ripley <ripley at stats.ox.ac.uk> writes:

    BDR> We do recommend you try INSTALLing and loading the package
    BDR> before R CMD check.
I have to rely on my memory, but if I remember correctly, installing
and loading the package worked.  It was only when it came to "R CMD
check" that the combination of having a NAMESPACE and no "PACKAGE="
argument in a .Fortran() call made "R CMD check" complain.  (With much
the same complaints that Seth reported).

But now I am utterly confused because I wanted to test if my memory is
correct.  So I went back to the package (called SCSS) with which I
experienced these problems (according to the dates of the files I was
putting that package together around 12 October 2005, which was just
after the release of R 2.2.0 and I believe I was using that version).

After removing the "PACKAGE=" arguments from the .Fortran() calls, the
package installs and loads fine.  But to my utter amazement, "R CMD
check" now works without a problem.  I tried this command with R
2.1.1, R 2.2.0, R 2.2.1 and R 2.3.0 (i.e. R-devel).

What surprised me most, was that all these versions said

* checking foreign function calls ... OK

I thought that this check is supposed to catch missing "PACKAGE="
arguments in .C(), .Fortran() &c calls???

The only explanation I have, is that my Debian linux system was some
time ago upgraded to gcc 4.0.3 and gfortran.  Indeed, running "R CMD
check" with R 2.3.0 produces a 00install.out file in the SCSS.Rcheck
directory that says:

* Installing *source* package 'SCSS' ...
** libs
make[2]: Entering directory `/home/berwin/lang/R/Develop/SCSS/src'
gfortran   -fpic  -g -O2 -c evsp.f -o evsp.o
gfortran   -fpic  -g -O2 -c evsp1d.f -o evsp1d.o
gfortran   -fpic  -g -O2 -c repar.f -o repar.o
gcc -shared -L/usr/local/lib -o SCSS.so evsp.o evsp1d.o repar.o  -lgfortran -lm -lgcc_s 

whereas R 2.1.1, R 2.2.0 and R 2.2.1 issue the following lines during
"R CMD check":

* Installing *source* package 'SCSS' ...
** libs
make[2]: Entering directory `/home/berwin/lang/R/Develop/SCSS/src'
g77   -fPIC  -g -O2 -c evsp.f -o evsp.o
g77   -fPIC  -g -O2 -c evsp1d.f -o evsp1d.o
g77   -fPIC  -g -O2 -c repar.f -o repar.o
gcc -shared -L/usr/local/lib -o SCSS.so evsp.o evsp1d.o repar.o  -L/usr/lib/gcc/i486-linux-gnu/3.4.5 -lg2c -lm -lgcc_s

since those versions of R where compiled and installed while I was
using gcc 3.4 on my machine.  

But on my machine I have now:

[bossiaea:Develop]$ file `which gcc`
/usr/bin/gcc: symbolic link to `gcc-4.0'

I redirected the link to point to gcc-3.4, but I still could not
reproduce the problems that I experienced last October (and which Seth
experienced right now).  Perhaps the problem only occurs with a very
specific version of the gcc compiler??

    >> [...]  My advise would be to check all .C() and .Fortran()
    >> calls in your package and add the "package=" argument if it is
    >> missing.
    BDR> (It had better be PACKAGE= !)
Of course, my bad.

Cheers,

        Berwin


From ripley at stats.ox.ac.uk  Sun Jan 22 10:35:18 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 22 Jan 2006 09:35:18 +0000 (GMT)
Subject: [Rd] R CMD check, NAMESPACE, import: bad error?
In-Reply-To: <17363.19515.464525.105706@bossiaea.maths.uwa.edu.au>
References: <m24q3zbu0z.fsf@fhcrc.org>
	<17360.27502.365586.740869@bossiaea.maths.uwa.edu.au>
	<Pine.LNX.4.61.0601200719490.25948@gannet.stats>
	<17363.19515.464525.105706@bossiaea.maths.uwa.edu.au>
Message-ID: <Pine.LNX.4.61.0601220930120.15663@gannet.stats>

On Sun, 22 Jan 2006, Berwin A Turlach wrote:

> G'day Brian,
>
>>>>>> "BDR" == Prof Brian Ripley <ripley at stats.ox.ac.uk> writes:
>
>    BDR> We do recommend you try INSTALLing and loading the package
>    BDR> before R CMD check.
> I have to rely on my memory, but if I remember correctly, installing
> and loading the package worked.  It was only when it came to "R CMD
> check" that the combination of having a NAMESPACE and no "PACKAGE="
> argument in a .Fortran() call made "R CMD check" complain.  (With much
> the same complaints that Seth reported).

I perhaps should have said that loading the R_DEFAULT_PACKAGES=NULL is 
sometimes also useful.

> But now I am utterly confused because I wanted to test if my memory is
> correct.  So I went back to the package (called SCSS) with which I
> experienced these problems (according to the dates of the files I was
> putting that package together around 12 October 2005, which was just
> after the release of R 2.2.0 and I believe I was using that version).
>
> After removing the "PACKAGE=" arguments from the .Fortran() calls, the
> package installs and loads fine.  But to my utter amazement, "R CMD
> check" now works without a problem.  I tried this command with R
> 2.1.1, R 2.2.0, R 2.2.1 and R 2.3.0 (i.e. R-devel).
>
> What surprised me most, was that all these versions said
>
> * checking foreign function calls ... OK
>
> I thought that this check is supposed to catch missing "PACKAGE="
> arguments in .C(), .Fortran() &c calls???

Not quite: `needed and missing'.  If R is able to work out the 
package from the NAMESPACE info, it is not reported.  That changed in 
2.2.0:

     o	checkFF() used by R CMD check has since R 2.0.0 not reported
 	missing PACKAGE arguments when testing installed packages with
 	namespaces.  It now

 	- treats installed and source packages in the same way.

 	- reports missing arguments unless they are in a function in
 	  the namespace with a useDynLib declaration (as the
 	  appropriate DLL for such calls can be searched for).

There is a further change in pre-2.3.0.


> The only explanation I have, is that my Debian linux system was some
> time ago upgraded to gcc 4.0.3 and gfortran.  Indeed, running "R CMD
> check" with R 2.3.0 produces a 00install.out file in the SCSS.Rcheck
> directory that says:
>
> * Installing *source* package 'SCSS' ...
> ** libs
> make[2]: Entering directory `/home/berwin/lang/R/Develop/SCSS/src'
> gfortran   -fpic  -g -O2 -c evsp.f -o evsp.o
> gfortran   -fpic  -g -O2 -c evsp1d.f -o evsp1d.o
> gfortran   -fpic  -g -O2 -c repar.f -o repar.o
> gcc -shared -L/usr/local/lib -o SCSS.so evsp.o evsp1d.o repar.o  -lgfortran -lm -lgcc_s
>
> whereas R 2.1.1, R 2.2.0 and R 2.2.1 issue the following lines during
> "R CMD check":
>
> * Installing *source* package 'SCSS' ...
> ** libs
> make[2]: Entering directory `/home/berwin/lang/R/Develop/SCSS/src'
> g77   -fPIC  -g -O2 -c evsp.f -o evsp.o
> g77   -fPIC  -g -O2 -c evsp1d.f -o evsp1d.o
> g77   -fPIC  -g -O2 -c repar.f -o repar.o
> gcc -shared -L/usr/local/lib -o SCSS.so evsp.o evsp1d.o repar.o  -L/usr/lib/gcc/i486-linux-gnu/3.4.5 -lg2c -lm -lgcc_s
>
> since those versions of R where compiled and installed while I was
> using gcc 3.4 on my machine.
>
> But on my machine I have now:
>
> [bossiaea:Develop]$ file `which gcc`
> /usr/bin/gcc: symbolic link to `gcc-4.0'
>
> I redirected the link to point to gcc-3.4, but I still could not
> reproduce the problems that I experienced last October (and which Seth
> experienced right now).  Perhaps the problem only occurs with a very
> specific version of the gcc compiler??
>
>    >> [...]  My advise would be to check all .C() and .Fortran()
>    >> calls in your package and add the "package=" argument if it is
>    >> missing.
>    BDR> (It had better be PACKAGE= !)
> Of course, my bad.
>
> Cheers,
>
>        Berwin
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From adsl665400 at tiscali.nl  Sun Jan 22 18:26:13 2006
From: adsl665400 at tiscali.nl (Marjo en Edwin)
Date: Sun, 22 Jan 2006 18:26:13 +0100
Subject: [Rd] including .svg vector graphics?
Message-ID: <000001c61f78$f1eac7b0$2101a8c0@DEEPTHOUGHT>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20060122/3b9ba393/attachment.pl

From edd at debian.org  Sun Jan 22 18:35:47 2006
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sun, 22 Jan 2006 11:35:47 -0600
Subject: [Rd] including .svg vector graphics?
In-Reply-To: <000001c61f78$f1eac7b0$2101a8c0@DEEPTHOUGHT>
References: <000001c61f78$f1eac7b0$2101a8c0@DEEPTHOUGHT>
Message-ID: <17363.49779.305308.353093@basebud.nulle.part>


On 22 January 2006 at 18:26, Marjo en Edwin wrote:
| I am wondering if there are any plans for incorporating the option to save
| graphs as ".svg" files. This would make it easy to postprocess figures in R
| with Inkscape, the open source vector graphics editor.

Had you run this search from within R:

	> RSiteSearch("svg")

you would have seen 67 hits, including seven to the RSvg package.

Dirk

-- 
Hell, there are no rules here - we're trying to accomplish something. 
                                                  -- Thomas A. Edison


From knoblauch at lyon.inserm.fr  Mon Jan 23 01:18:54 2006
From: knoblauch at lyon.inserm.fr (Ken Knoblauch)
Date: Sun, 22 Jan 2006 23:18:54 -0100 (CET)
Subject: [Rd] proposed pbirthday fix
Message-ID: <51940.82.231.93.240.1137968334.squirrel@webmail.lyon.inserm.fr>

Recent news articles concerning an article from The Lancet with fabricated
data indicate
that in the sample containing some 900 or so patients, more than 200 had
the same
birthday.  I was curious and tried out the p and q birthday functions but
pbirthday
could not handle 250 coincidences with n = 1000.  The calculation of upper
prior
to using uniroot produces NaN,

upper<-min(n^k/(c^(k-1)),1)

I was able to get it to work by using logs, however, as in the following
version

function(n, classes = 365, coincident = 2){
    k <- coincident
    c <- classes
    if (coincident < 2) return(1)
    if (coincident > n) return(0)
    if (n > classes * (coincident - 1)) return(1)
    eps <- 1e-14
    if (qbirthday(1 - eps, classes, coincident) <= n)
        return(1 - eps)
    f <- function(p) qbirthday(p, c, k) - n
    lower <- 0
    upper <- min( exp( k * log(n) - (k-1) * log(c) ), 1 )
    nmin <- uniroot(f, c(lower, upper), tol = eps)
    nmin$root
}

Ken


From murdoch at stats.uwo.ca  Mon Jan 23 01:38:33 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sun, 22 Jan 2006 19:38:33 -0500
Subject: [Rd] 2nd argument to substitute()
Message-ID: <43D42589.7070004@stats.uwo.ca>

The second argument to the substitute() function gives the frame in 
which to look for substitutions.  However, the documentation doesn't 
appear to match what happens exactly.

Could anyone who makes use of this tell me what they would expect to see 
from these calls?

substitute(expr) evaluated at top level
substitute(expr) evaluated within a function
substitute(expr, NULL)
substitute(expr, .GlobalEnv)

In C code:

substitute(expr, R_NilValue) (as used in bind.c)
substitute(expr, R_GlobalEnv) (not used currently, as far as I can see)

The reason I ask is that I'm trying to clean up the findVarInFrame3 
code, and currently substitute calls it with the environment set to 
NULL.  What is the expectation there?

Duncan Murdoch


From knoblauch at lyon.inserm.fr  Mon Jan 23 09:43:28 2006
From: knoblauch at lyon.inserm.fr (ken knoblauch)
Date: Mon, 23 Jan 2006 09:43:28 +0100
Subject: [Rd] proposed pbirthday fix
Message-ID: <389c92deb9f6dbbb6bff8ecaba94d297@lyon.inserm.fr>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20060123/ab5579d1/attachment.pl

From maechler at stat.math.ethz.ch  Mon Jan 23 11:52:55 2006
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 23 Jan 2006 11:52:55 +0100
Subject: [Rd] proposed pbirthday fix
In-Reply-To: <389c92deb9f6dbbb6bff8ecaba94d297@lyon.inserm.fr>
References: <389c92deb9f6dbbb6bff8ecaba94d297@lyon.inserm.fr>
Message-ID: <17364.46471.624799.196209@stat.math.ethz.ch>

>>>>> "ken" == ken knoblauch <knoblauch at lyon.inserm.fr>
>>>>>     on Mon, 23 Jan 2006 09:43:28 +0100 writes:

    ken> Actually, since NaN's are also detected in na.action
    ken> operations, a simpler fix might just be to use the
    ken> na.rm = TRUE option of min

    ken> upper <- min(n^k/(c^(k - 1)), 1, na.rm = TRUE)

Well, I liked your first fix better -- thank you for it! --
since it's always good practice to formulate such as to avoid
overflow when possible. 
All things considered, I think I'd go for

   upper <- min( exp(k * log(n) - (k-1) * log(c)), 1, na.rm = TRUE)

Martin 

    Ken> Recent news articles concerning an article from The
    Ken> Lancet with fabricated data indicate that in the sample
    Ken> containing some 900 or so patients, more than 200 had the
    Ken> same birthday.  I was curious and tried out the p and q
    Ken> birthday functions but pbirthday could not handle 250
    Ken> coincidences with n = 1000.  The calculation of upper
    Ken> prior to using uniroot produces NaN,

    Ken> upper<-min(n^k/(c^(k-1)),1)

    Ken> I was able to get it to work by using logs, however, as
    Ken> in the following version

    >> function(n, classes = 365, coincident = 2){
    >>     k <- coincident
    >>     c <- classes
    >>     if (coincident < 2) return(1)
    >>     if (coincident > n) return(0)
    >>     if (n > classes * (coincident - 1)) return(1)
    >>     eps <- 1e-14
    >>     if (qbirthday(1 - eps, classes, coincident) <= n)
    >>     return(1 - eps)
    >>     f <- function(p) qbirthday(p, c, k) - n
    >>     lower <- 0
    >>     upper <- min( exp( k * log(n) - (k-1) * log(c) ), 1 )
    >>     nmin <- uniroot(f, c(lower, upper), tol = eps)
    >>     nmin$root
    >> }


From hin-tak.leung at cimr.cam.ac.uk  Mon Jan 23 12:15:18 2006
From: hin-tak.leung at cimr.cam.ac.uk (Hin-Tak Leung)
Date: Mon, 23 Jan 2006 11:15:18 +0000
Subject: [Rd] Minumum memory requirements to run R.
In-Reply-To: <43FA4711.2010103@gmail.com>
References: <Pine.LNX.4.61.0601181149400.9400@gannet.stats>
	<43FA4711.2010103@gmail.com>
Message-ID: <43D4BAC6.2050904@cimr.cam.ac.uk>

Kjetil Brinchmann Halvorsen wrote:
> Prof Brian Ripley wrote:
> 
>>Quite a while back we set the goal of running R in 16Mb RAM, as people (I 
>>think Kjetil) had teaching labs that small.
> 
> It's a while since I actually har R used on such small machines, I think
> 64 MB is quite acceptable now.

May I add another note to this - I recently upgraded to 64-bits (AMD 
opteron) and noticed the memory foot print of R has shot up. Just 
starting R takes up 90+MB virtual. There are correponding increases with 
Python and Perl as well; I suspect R suffers a bit on 64-bit
platform due to extensive use of pointers internally. The fundamental
unit in R, SEXP, is 6 pointers + 1 int, (and another
pointer for itself). So I would probably say 64MB is questionable on 
64-bit, but then probably nobody is stupid enough to do that...

For those who want to investigate the equivalent in Perl, the equivalent 
perl headers corresponding to "R/include/Rinternals.h" is located at
the "-I" flags of the output of:

perl -MExtUtils::Embed -e ccopts

(no idea where python stores its stuff...)

Hin-Tak Leung

> 
> Kjetil
> 
> 
>>Since then R has grown, and we has recently started to optimize R for 
>>speed rather than size.  I recently tested R-devel on my ancient Win98 
>>notebook with 64Mb RAM -- it ran but startup was rather slow on what I 
>>think is a 233MHz processor and very slow disc.
>>
>>R still runs in 16Mb, but that is getting tight.  Does anyone have any 
>>need to run on a smaller machine than my 64Mb notebook?
>>
> 
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From ripley at stats.ox.ac.uk  Mon Jan 23 12:50:49 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 23 Jan 2006 11:50:49 +0000 (GMT)
Subject: [Rd] Minumum memory requirements to run R.
In-Reply-To: <43D4BAC6.2050904@cimr.cam.ac.uk>
References: <Pine.LNX.4.61.0601181149400.9400@gannet.stats>
	<43FA4711.2010103@gmail.com> <43D4BAC6.2050904@cimr.cam.ac.uk>
Message-ID: <Pine.LNX.4.61.0601231133410.12327@gannet.stats>

On Mon, 23 Jan 2006, Hin-Tak Leung wrote:

> Kjetil Brinchmann Halvorsen wrote:
>> Prof Brian Ripley wrote:
>> 
>>> Quite a while back we set the goal of running R in 16Mb RAM, as people (I 
>>> think Kjetil) had teaching labs that small.
>> 
>> It's a while since I actually har R used on such small machines, I think
>> 64 MB is quite acceptable now.
>
> May I add another note to this - I recently upgraded to 64-bits (AMD opteron) 
> and noticed the memory foot print of R has shot up. Just starting R takes up 
> 90+MB virtual.

That's a different question.  I said RAM, you quote virtual.  I am 
suprised at your figure though, as I am used to seeing 40-50Mb virtual at 
startup on an Opteron.

The distinction is important: even those small Windows machines had 100s 
of Mb of virtual memory available, it was RAM that was in short supply.

> There are correponding increases with Python and Perl as well; 
> I suspect R suffers a bit on 64-bit
> platform due to extensive use of pointers internally. The fundamental
> unit in R, SEXP, is 6 pointers + 1 int, (and another
> pointer for itself). So I would probably say 64MB is questionable on 64-bit, 
> but then probably nobody is stupid enough to do that...

We know: we even document it in the appropriate places.

Some of us were running 64-bit R last century on machines with 128Mb (and 
others with much more, of course).  When I tried in 1997, Solaris would 
not run in 64-bit mode with 64Mb RAM (which then cost ?1000 or so).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From sdavis2 at mail.nih.gov  Mon Jan 23 13:45:43 2006
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Mon, 23 Jan 2006 07:45:43 -0500
Subject: [Rd] Read.delim error in 2.3.0 devel, not in 2.2.0
Message-ID: <BFFA3A27.4298%sdavis2@mail.nih.gov>

I get this error in R-devel, but not in R-2.2.0.  Any insight is
appreciated.

Error in read.delim(txtcon, header = TRUE, sep = "\t", na.strings = "NULL")
: 
    recursive default argument reference


> sessionInfo()
Version 2.3.0 Under development (unstable) (2006-01-04 r36984)
powerpc-apple-darwin8.3.0

attached base packages:
[1] "methods"   "stats"     "graphics"  "grDevices" "utils"     "datasets"
[7] "base"     

other attached packages:
GEOquery 
 "1.5.3" 

Thanks,
Sean


From hin-tak.leung at cimr.cam.ac.uk  Mon Jan 23 16:18:29 2006
From: hin-tak.leung at cimr.cam.ac.uk (Hin-Tak Leung)
Date: Mon, 23 Jan 2006 15:18:29 +0000
Subject: [Rd] Minumum memory requirements to run R.
In-Reply-To: <Pine.LNX.4.61.0601231133410.12327@gannet.stats>
References: <Pine.LNX.4.61.0601181149400.9400@gannet.stats>
	<43FA4711.2010103@gmail.com> <43D4BAC6.2050904@cimr.cam.ac.uk>
	<Pine.LNX.4.61.0601231133410.12327@gannet.stats>
Message-ID: <43D4F3C5.6060005@cimr.cam.ac.uk>

Prof Brian Ripley wrote:
<snipped>
> That's a different question.  I said RAM, you quote virtual.  I am 
> suprised at your figure though, as I am used to seeing 40-50Mb virtual 
> at startup on an Opteron.

I am somewhat surprised by it as well. But there is nothing unusual 
about the build - it is just rebuilding the rpm on CRAN on a FC4 system
with everything as shipped, and should be quite reproducible.
I'll probably have a better look in time.

"R --vanilla" doesn't improve. Still 90+ MB virtual, 20+MB resident.

> The distinction is important: even those small Windows machines had 100s 
> of Mb of virtual memory available, it was RAM that was in short supply.

Yes and no. Virtual means it will possibly be used - and it is a big 
gray scale between unresponsible/intolerably-slow and slow.

>> There are correponding increases with Python and Perl as well; I 
>> suspect R suffers a bit on 64-bit
>> platform due to extensive use of pointers internally. The fundamental
>> unit in R, SEXP, is 6 pointers + 1 int, (and another
>> pointer for itself). So I would probably say 64MB is questionable on 
>> 64-bit, but then probably nobody is stupid enough to do that...
> 
> 
> We know: we even document it in the appropriate places.

I went and have a look - it is the last section of R-admin (and of 
course, for those who "read the source", R/include/Rinternals.h). It 
would be good to mention this in the FAQ (which it doesn't, or maybe I 
didn't look hard enough), or the beginning of R-admin?

> Some of us were running 64-bit R last century on machines with 128Mb 
> (and others with much more, of course).  When I tried in 1997, Solaris 
> would not run in 64-bit mode with 64Mb RAM (which then cost ?1000 or so).
>


From tlumley at u.washington.edu  Mon Jan 23 17:10:34 2006
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon, 23 Jan 2006 08:10:34 -0800 (PST)
Subject: [Rd] Minumum memory requirements to run R.
In-Reply-To: <43D4F3C5.6060005@cimr.cam.ac.uk>
References: <Pine.LNX.4.61.0601181149400.9400@gannet.stats>
	<43FA4711.2010103@gmail.com> <43D4BAC6.2050904@cimr.cam.ac.uk>
	<Pine.LNX.4.61.0601231133410.12327@gannet.stats>
	<43D4F3C5.6060005@cimr.cam.ac.uk>
Message-ID: <Pine.LNX.4.64.0601230804010.10033@homer24.u.washington.edu>

On Mon, 23 Jan 2006, Hin-Tak Leung wrote:

> Prof Brian Ripley wrote:
>> We know: we even document it in the appropriate places.
>
> I went and have a look - it is the last section of R-admin (and of
> course, for those who "read the source", R/include/Rinternals.h). It
> would be good to mention this in the FAQ (which it doesn't, or maybe I
> didn't look hard enough), or the beginning of R-admin?
>

It's not in the FAQ because it isn't a FAQ (yet).

If you use the PDF manual it is in the table of contents on page i.

In the HTML manual it is admittedly less clear: there isn't a table of 
contents and there is nothing obvious in the index. To some extent this is 
a problem with all the manuals. The structure in the .texi file isn't 
translated well to HTML form by the makeinfo tools.

 	-thomas


From ripley at stats.ox.ac.uk  Mon Jan 23 17:19:49 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 23 Jan 2006 16:19:49 +0000 (GMT)
Subject: [Rd] Minumum memory requirements to run R.
In-Reply-To: <Pine.LNX.4.64.0601230804010.10033@homer24.u.washington.edu>
References: <Pine.LNX.4.61.0601181149400.9400@gannet.stats>
	<43FA4711.2010103@gmail.com> <43D4BAC6.2050904@cimr.cam.ac.uk>
	<Pine.LNX.4.61.0601231133410.12327@gannet.stats>
	<43D4F3C5.6060005@cimr.cam.ac.uk>
	<Pine.LNX.4.64.0601230804010.10033@homer24.u.washington.edu>
Message-ID: <Pine.LNX.4.61.0601231613210.20503@gannet.stats>

On Mon, 23 Jan 2006, Thomas Lumley wrote:

> On Mon, 23 Jan 2006, Hin-Tak Leung wrote:
>
>> Prof Brian Ripley wrote:

[About Ncell sizes on 64-bit platforms.]

>>> We know: we even document it in the appropriate places.
>> 
>> I went and have a look - it is the last section of R-admin (and of
>> course, for those who "read the source", R/include/Rinternals.h). It
>> would be good to mention this in the FAQ (which it doesn't, or maybe I
>> didn't look hard enough), or the beginning of R-admin?
>> 
>
> It's not in the FAQ because it isn't a FAQ (yet).
>
> If you use the PDF manual it is in the table of contents on page i.
>
> In the HTML manual it is admittedly less clear: there isn't a table of 
> contents and there is nothing obvious in the index. To some extent this is a 
> problem with all the manuals. The structure in the .texi file isn't 
> translated well to HTML form by the makeinfo tools.

In my build there is a chapter in the HTML manual

 	Choosing between 32- and 64-bit builds

in the top-level contents, and the information is in there.

It is also in ?Memory (a fairly obvious place).  It may be elsewhere, but 
those are the most obvious places to me.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From hin-tak.leung at cimr.cam.ac.uk  Mon Jan 23 18:35:26 2006
From: hin-tak.leung at cimr.cam.ac.uk (Hin-Tak Leung)
Date: Mon, 23 Jan 2006 17:35:26 +0000
Subject: [Rd] Minumum memory requirements to run R.
In-Reply-To: <Pine.LNX.4.61.0601231613210.20503@gannet.stats>
References: <Pine.LNX.4.61.0601181149400.9400@gannet.stats>
	<43FA4711.2010103@gmail.com> <43D4BAC6.2050904@cimr.cam.ac.uk>
	<Pine.LNX.4.61.0601231133410.12327@gannet.stats>
	<43D4F3C5.6060005@cimr.cam.ac.uk>
	<Pine.LNX.4.64.0601230804010.10033@homer24.u.washington.edu>
	<Pine.LNX.4.61.0601231613210.20503@gannet.stats>
Message-ID: <43D513DE.4060106@cimr.cam.ac.uk>

Prof Brian Ripley wrote:
<snipped>
> [About Ncell sizes on 64-bit platforms.]
<snipped>
> In my build there is a chapter in the HTML manual
> 
>     Choosing between 32- and 64-bit builds
> 
> in the top-level contents, and the information is in there.

Maybe the one on CRAN needs fixing...
http://cran.r-project.org/doc/manuals/R-admin.html

> It is also in ?Memory (a fairly obvious place).  It may be elsewhere, 
> but those are the most obvious places to me.

I don't want to be argumentative, but the perpective of "obvious"
can often be quite different from one of the authors versus one of
the users...

The 32-bit/64-bit issue affects purchasing or upgrading decisions
- whether one wants to spend the money on buying cheaper
32-bit machines, versus more expensive 64-bit machines. That
decision would be based on information available while *not* having
an operational R installation...

Regards,
Hin-Tak Leung


From maechler at stat.math.ethz.ch  Mon Jan 23 19:01:25 2006
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 23 Jan 2006 19:01:25 +0100
Subject: [Rd] proposed pbirthday fix
In-Reply-To: <17364.46471.624799.196209@stat.math.ethz.ch>
References: <389c92deb9f6dbbb6bff8ecaba94d297@lyon.inserm.fr>
	<17364.46471.624799.196209@stat.math.ethz.ch>
Message-ID: <17365.6645.448913.320652@stat.math.ethz.ch>

>>>>> "MM" == Martin Maechler <maechler at stat.math.ethz.ch>
>>>>>     on Mon, 23 Jan 2006 11:52:55 +0100 writes:

>>>>> "ken" == ken knoblauch <knoblauch at lyon.inserm.fr>
>>>>>     on Mon, 23 Jan 2006 09:43:28 +0100 writes:

    ken> Actually, since NaN's are also detected in na.action
    ken> operations, a simpler fix might just be to use the
    ken> na.rm = TRUE option of min

    ken> upper <- min(n^k/(c^(k - 1)), 1, na.rm = TRUE)

    MM> Well, I liked your first fix better -- thank you for it! --
    MM> since it's always good practice to formulate such as to avoid
    MM> overflow when possible. 
    MM> All things considered, I think I'd go for

    MM> upper <- min( exp(k * log(n) - (k-1) * log(c)), 1, na.rm = TRUE)

    MM> Martin 

    Ken> Recent news articles concerning an article from The
    Ken> Lancet with fabricated data indicate that in the sample
    Ken> containing some 900 or so patients, more than 200 had the
    Ken> same birthday.  I was curious and tried out the p and q
    Ken> birthday functions but pbirthday could not handle 250
    Ken> coincidences with n = 1000.  The calculation of upper
    Ken> prior to using uniroot produces NaN,

    Ken> upper<-min(n^k/(c^(k-1)),1)

    Ken> I was able to get it to work by using logs, however, as
    Ken> in the following version

    >>> function(n, classes = 365, coincident = 2){
	..................

    >>> upper <- min( exp( k * log(n) - (k-1) * log(c) ), 1 )
    >>> nmin <- uniroot(f, c(lower, upper), tol = eps)
    >>> nmin$root
    >>> }

Well, now after inspection, I think ``get it to work''
is a bit of an exaggeration, at least for a purist like me
(some famous fortune teller once guessed it may be because I'm ... Swiss)
who doesn't like to lose precision in probability computations
unnecessarily. One can do much better:

The version of [pq]birthday() I've just committed to R-devel *) now gives

> sapply(c(20,50,100,200), function(k) pbirthday(1000, coincident= k))
[1]  8.596245e-08  9.252349e-41 2.395639e-112 1.758236e-285

whereas the 'na.rm=TRUE' fix  would simply give

[1] 8.596245e-08 0.000000e+00 0.000000e+00 0.000000e+00

--
Martin Maechler, ETH Zurich

*) peek at https://svn.r-project.org/R/trunk/src/library/stats/R/pbirthday.R


From tlumley at u.washington.edu  Mon Jan 23 19:48:04 2006
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon, 23 Jan 2006 10:48:04 -0800 (PST)
Subject: [Rd] Minumum memory requirements to run R.
In-Reply-To: <43D513DE.4060106@cimr.cam.ac.uk>
References: <Pine.LNX.4.61.0601181149400.9400@gannet.stats>
	<43FA4711.2010103@gmail.com> <43D4BAC6.2050904@cimr.cam.ac.uk>
	<Pine.LNX.4.61.0601231133410.12327@gannet.stats>
	<43D4F3C5.6060005@cimr.cam.ac.uk>
	<Pine.LNX.4.64.0601230804010.10033@homer24.u.washington.edu>
	<Pine.LNX.4.61.0601231613210.20503@gannet.stats>
	<43D513DE.4060106@cimr.cam.ac.uk>
Message-ID: <Pine.LNX.4.64.0601231046350.32205@homer22.u.washington.edu>

On Mon, 23 Jan 2006, Hin-Tak Leung wrote:
>
> The 32-bit/64-bit issue affects purchasing or upgrading decisions
> - whether one wants to spend the money on buying cheaper
> 32-bit machines, versus more expensive 64-bit machines. That
> decision would be based on information available while *not* having
> an operational R installation...
>

Not necessarily. It's perfectly feasible to use a 32-bit build on a 64-bit 
machine, as it says in the manual, which is available from 
http://www.r-project.org whether or not you have an R installation.

 	-thomas


From ripley at stats.ox.ac.uk  Mon Jan 23 20:03:40 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 23 Jan 2006 19:03:40 +0000 (GMT)
Subject: [Rd] Read.delim error in 2.3.0 devel, not in 2.2.0
In-Reply-To: <BFFA3A27.4298%sdavis2@mail.nih.gov>
References: <BFFA3A27.4298%sdavis2@mail.nih.gov>
Message-ID: <Pine.LNX.4.61.0601231354300.19018@gannet.stats>

On Mon, 23 Jan 2006, Sean Davis wrote:

> I get this error in R-devel, but not in R-2.2.0.  Any insight is
> appreciated.
>
> Error in read.delim(txtcon, header = TRUE, sep = "\t", na.strings = "NULL")
> :
>    recursive default argument reference

There is nothing we can reproduce here.  What is txtcon, for example?
I was unable to reproduce anything like this reading from a text 
connection.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From bolker at zoo.ufl.edu  Mon Jan 23 20:37:18 2006
From: bolker at zoo.ufl.edu (Ben Bolker)
Date: Mon, 23 Jan 2006 14:37:18 -0500
Subject: [Rd] too-large notches in boxplot (PR #7690)
Message-ID: <43D5306E.7020709@zoo.ufl.edu>


   PR #7690 points out that if the confidence intervals (+/-1.58 
IQR/sqrt(n)) in a boxplot with notch=TRUE are larger than the
hinges -- which is most likely to happen for small n and asymmetric
distributions -- the resulting plot is ugly, e.g.:

set.seed(1001)
npts <- 5
X <- rnorm(2*npts,rep(3:4,each=npts),sd=1)
f <- factor(rep(1:2,each=npts))
boxplot(X~f)
boxplot(X~f,notch=TRUE)

   I can imagine debate about what should be done in this case --
you could just say "don't do that", since the notches are based
on an asymptotic argument ... the diff below just truncates
the notches to the hinges, but produces a warning saying that the 
notches have been truncated.

   ?? what should the behavior be ??

  the diff is against the 11 Jan version of R 2.3.0



*** newboxplot.R        2006-01-23 14:32:12.000000000 -0500
--- oldboxplot.R        2006-01-23 14:29:29.000000000 -0500
***************
*** 84,98 ****
       bplt <- function(x, wid, stats, out, conf, notch, xlog, i)
       {
         ## Draw single box plot
-       conf.ok <- TRUE
-       if(!any(is.na(stats))) {
-           ## check for overlap of notches and hinges
-           if (notch && (stats[2]>conf[1] || stats[4]<conf[2])) {
-              conf.ok <- FALSE
-              conf[1] <- max(conf[1],stats[2])
-              conf[2] <- min(conf[2],stats[4])
-            }

             ## stats = +/- Inf: polygon & segments should handle

             ## Compute 'x + w' -- "correctly" in log-coord. case:
--- 84,91 ----
       bplt <- function(x, wid, stats, out, conf, notch, xlog, i)
       {
         ## Draw single box plot

+       if(!any(is.na(stats))) {
             ## stats = +/- Inf: polygon & segments should handle

             ## Compute 'x + w' -- "correctly" in log-coord. case:
***************
*** 148,154 ****
                           domain = NA)
             }
         }
-       return(conf.ok)
       } ## bplt

       if(!is.list(z) || 0 == (n <- length(z$n)))
--- 141,146 ----
***************
*** 239,252 ****
           xysegments <- segments
       }

-     conf.ok <- numeric(n)
       for(i in 1:n)
!       conf.ok[i] <- bplt(at[i], wid=width[i],
              stats= z$stats[,i],
              out  = z$out[z$group==i],
              conf = z$conf[,i],
              notch= notch, xlog = xlog, i = i)
!     if (any(!conf.ok)) warning("some confidence limits > hinges: 
notches truncated")
       axes <- is.null(pars$axes)
       if(!axes) { axes <- pars$axes; pars$axes <- NULL }
       if(axes) {
--- 231,243 ----
           xysegments <- segments
       }

       for(i in 1:n)
!       bplt(at[i], wid=width[i],
              stats= z$stats[,i],
              out  = z$out[z$group==i],
              conf = z$conf[,i],
              notch= notch, xlog = xlog, i = i)
!
       axes <- is.null(pars$axes)
       if(!axes) { axes <- pars$axes; pars$axes <- NULL }
       if(axes) {

-- 
620B Bartram Hall                            bolker at zoo.ufl.edu
Zoology Department, University of Florida    http://www.zoo.ufl.edu/bolker
Box 118525                                   (ph)  352-392-5697
Gainesville, FL 32611-8525                   (fax) 352-392-3704


From oliver at bic.mni.mcgill.ca  Mon Jan 23 21:24:37 2006
From: oliver at bic.mni.mcgill.ca (Oliver LYTTELTON)
Date: Mon, 23 Jan 2006 15:24:37 -0500
Subject: [Rd] Master's project to coerce linux nvidia drivers to run
 generalised linear models
Message-ID: <43D53B85.4060109@bic.mni.mcgill.ca>



Hi,

I am working with a friend on a master's project. Our laboratory does a 
lot of statistical analysis using the R stats package and we also have a 
lot of under-utilised nvidia cards sitting in the back of our networked 
linux machines. Our idea is to coerce the linux nvidia driver to run 
some of our statistical analysis for us. Our first thought was to 
specifically code up a version of glm() to run on the nvidia cards...

Thinking that this might be of use to the broader community we thought 
we might ask for feedback before starting?

Any ideas...

Thanks,

Olly


From mschwartz at mn.rr.com  Mon Jan 23 22:47:38 2006
From: mschwartz at mn.rr.com (Marc Schwartz (via MN))
Date: Mon, 23 Jan 2006 15:47:38 -0600
Subject: [Rd] Master's project to coerce linux nvidia drivers to
	run	generalised linear models
In-Reply-To: <43D53B85.4060109@bic.mni.mcgill.ca>
References: <43D53B85.4060109@bic.mni.mcgill.ca>
Message-ID: <1138052858.4314.100.camel@localhost.localdomain>

On Mon, 2006-01-23 at 15:24 -0500, Oliver LYTTELTON wrote:
> 
> Hi,
> 
> I am working with a friend on a master's project. Our laboratory does a 
> lot of statistical analysis using the R stats package and we also have a 
> lot of under-utilised nvidia cards sitting in the back of our networked 
> linux machines. Our idea is to coerce the linux nvidia driver to run 
> some of our statistical analysis for us. Our first thought was to 
> specifically code up a version of glm() to run on the nvidia cards...
> 
> Thinking that this might be of use to the broader community we thought 
> we might ask for feedback before starting?
> 
> Any ideas...
> 
> Thanks,
> 
> Olly


Well, I'll bite.

My first reaction to this was, why?


Then I did some Googling and found the following article:

http://www.apcmag.com/apc/v3.nsf/0/5F125BA4653309A3CA25705A0005AD27


And also noted the GPU Gems 2 site here:

http://developer.nvidia.com/object/gpu_gems_2_home.html


So, my new found perspective is, why not?


Best wishes for success, especially since I have a certain affinity for
McGill...

HTH,

Marc Schwartz


From ggrothendieck at gmail.com  Mon Jan 23 23:09:34 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 23 Jan 2006 17:09:34 -0500
Subject: [Rd] Master's project to coerce linux nvidia drivers to run
	generalised linear models
In-Reply-To: <43D53B85.4060109@bic.mni.mcgill.ca>
References: <43D53B85.4060109@bic.mni.mcgill.ca>
Message-ID: <971536df0601231409g17c34b74sbfc3e4828add2050@mail.gmail.com>

I wonder if it would make more sense to get a relatively
low level package to run on it so that all packages that
used that low level package would benefit.  The Matrix
package and the functions runmean and sum.exact in
package caTools are some things that come to mind.
Others may have other ideas along these lines.

On 1/23/06, Oliver LYTTELTON <oliver at bic.mni.mcgill.ca> wrote:
>
>
> Hi,
>
> I am working with a friend on a master's project. Our laboratory does a
> lot of statistical analysis using the R stats package and we also have a
> lot of under-utilised nvidia cards sitting in the back of our networked
> linux machines. Our idea is to coerce the linux nvidia driver to run
> some of our statistical analysis for us. Our first thought was to
> specifically code up a version of glm() to run on the nvidia cards...
>
> Thinking that this might be of use to the broader community we thought
> we might ask for feedback before starting?
>
> Any ideas...
>
> Thanks,
>
> Olly
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From greg.kochanski at phon.ox.ac.uk  Tue Jan 24 00:40:12 2006
From: greg.kochanski at phon.ox.ac.uk (greg.kochanski@phon.ox.ac.uk)
Date: Tue, 24 Jan 2006 00:40:12 +0100 (CET)
Subject: [Rd] --gui=Tk window does not stretch (PR#8520)
Message-ID: <20060123234012.2B3B0CD3F@slim.kubism.ku.dk>

Full_Name: Greg Kochanski
Version: 2.2.0
OS: Debian Linux
Submission from: (NULL) (212.159.16.190)


When you grab the corner of the Tk-R (R's console) window,
the window stretches, but the useable area does not.
It remains firmly fixed at the (rather small) value of
24 lines.

In fact, you end up with a grey border  of wasted pixels
around the active white area that contains the text.

(And, please don't tell me that it's not a bug because
it's been that way for 15 years, or because the S
documentation states that the terminal window is
24 lines high.   That would shatter my dreams
and illusions.)


From p.dalgaard at biostat.ku.dk  Tue Jan 24 01:26:21 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 24 Jan 2006 01:26:21 +0100
Subject: [Rd] --gui=Tk window does not stretch (PR#8520)
In-Reply-To: <20060123234012.2B3B0CD3F@slim.kubism.ku.dk>
References: <20060123234012.2B3B0CD3F@slim.kubism.ku.dk>
Message-ID: <x2psmieaj6.fsf@turmalin.kubism.ku.dk>

greg.kochanski at phon.ox.ac.uk writes:

> When you grab the corner of the Tk-R (R's console) window,
> the window stretches, but the useable area does not.
> It remains firmly fixed at the (rather small) value of
> 24 lines.
> 
> In fact, you end up with a grey border  of wasted pixels
> around the active white area that contains the text.
> 
> (And, please don't tell me that it's not a bug because
> it's been that way for 15 years, or because the S
> documentation states that the terminal window is
> 24 lines high.   That would shatter my dreams
> and illusions.)

It's not a bug, it's an unimplemented feature...

As you're bound to discover, the Tk console is mainly a
proof-of-concept with shortcomings in many other areas as well. It's
been largely undeveloped (as has the Gnome GUI) because we had very
little feedback to indicate that people were actually interested in
getting it to work better. Patches might be considered.

The particular issue is just a matter of sending suitable options to
the Tk geometry manager. This can be fixed in the console.tcl script,
and in fact also from within the running GUI using

with(.GUIenv, tkpack("configure", Term, expand=TRUE, fill="both"))


-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From francoisromain at free.fr  Tue Jan 24 11:33:24 2006
From: francoisromain at free.fr (Romain Francois)
Date: Tue, 24 Jan 2006 11:33:24 +0100
Subject: [Rd] generate Rd file from R file
Message-ID: <43D60274.5000808@free.fr>

Hi,

Is there something similar to javadoc or doxygen for R, ie ability to 
create a first draft of an Rd file reading the comments that are in a 
script file?

For example, for the weighted.mean function in base, one could write the 
source as :

weighted.mean <- function(
x,             #@ a numeric vector containing the values whose mean is to be computed. 
w,             #@ a vector of weights the same length as |x| giving the weights to use for each element of |x|.
na.rm = FALSE  #@ a logical value indicating whether |NA |values in |x| should be stripped before the computation proceeds.
)
#e wt <- c(5,  5,  4,  1)/15
#e x <- c(3.7,3.3,3.5,2.8)
#e xm <- weighted.mean(x,wt)


and get a draft file more full than what may be created with prompt.
Of course, I do not ask for a way to not write all the information in 
one file ... but some can be shared between R and Rd

Romain



-- 
visit the R Graph Gallery : http://addictedtor.free.fr/graphiques
mixmod 1.7 is released : http://www-math.univ-fcomte.fr/mixmod/index.php
+---------------------------------------------------------------+
| Romain FRANCOIS - http://francoisromain.free.fr               |
| Doctorant INRIA Futurs / EDF                                  |
+---------------------------------------------------------------+


From phgrosjean at sciviews.org  Tue Jan 24 11:55:12 2006
From: phgrosjean at sciviews.org (Philippe Grosjean)
Date: Tue, 24 Jan 2006 11:55:12 +0100
Subject: [Rd] generate Rd file from R file
In-Reply-To: <43D60274.5000808@free.fr>
References: <43D60274.5000808@free.fr>
Message-ID: <43D60790.8060508@sciviews.org>

Hi,
There is something like that (not so sophiscticated) defined in the 
green book, but it is not implemented in R. You should look at the 
mvbutils package, ?dochelp, ?flatdoc, ?doc3Rd, to get such features.
Best,

Philippe Grosjean


Romain Francois wrote:
> Hi,
> 
> Is there something similar to javadoc or doxygen for R, ie ability to 
> create a first draft of an Rd file reading the comments that are in a 
> script file?
> 
> For example, for the weighted.mean function in base, one could write the 
> source as :
> 
> weighted.mean <- function(
> x,             #@ a numeric vector containing the values whose mean is to be computed. 
> w,             #@ a vector of weights the same length as |x| giving the weights to use for each element of |x|.
> na.rm = FALSE  #@ a logical value indicating whether |NA |values in |x| should be stripped before the computation proceeds.
> )
> #e wt <- c(5,  5,  4,  1)/15
> #e x <- c(3.7,3.3,3.5,2.8)
> #e xm <- weighted.mean(x,wt)
> 
> 
> and get a draft file more full than what may be created with prompt.
> Of course, I do not ask for a way to not write all the information in 
> one file ... but some can be shared between R and Rd
> 
> Romain
> 
> 
>


From dmbates at gmail.com  Tue Jan 24 15:38:46 2006
From: dmbates at gmail.com (Douglas Bates)
Date: Tue, 24 Jan 2006 08:38:46 -0600
Subject: [Rd] Master's project to coerce linux nvidia drivers to run
	generalised linear models
In-Reply-To: <971536df0601231409g17c34b74sbfc3e4828add2050@mail.gmail.com>
References: <43D53B85.4060109@bic.mni.mcgill.ca>
	<971536df0601231409g17c34b74sbfc3e4828add2050@mail.gmail.com>
Message-ID: <40e66e0b0601240638l1c539e9dqa5ccedc8334d6968@mail.gmail.com>

On 1/23/06, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
> I wonder if it would make more sense to get a relatively
> low level package to run on it so that all packages that
> used that low level package would benefit.  The Matrix
> package and the functions runmean and sum.exact in
> package caTools are some things that come to mind.
> Others may have other ideas along these lines.

Martin and I are delighted to learn that the Matrix package is a
"relatively low-level" package :-)

We were of the opinion that the amount of code and design work that
went into it made it a little more sophisticated than that.

More seriously, the approach to speeding up model fitting that has
been most successful to date is to speed up the BLAS (Basic Linear
Algebra Subroutines), especially the Level-3 BLAS.  The bulk of the
computation in the Matrix package takes place in either Lapack (for
dense matrices) or CHOLMOD (for sparse matrices) code and those are
based on calls to the Levels 1, 2 and 3 BLAS.  The Atlas package and
K. Goto's BLAS are designed to obtain the highest level of performance
possible from the CPU on these routines.  I think the easiest way of
incorporating the power of the GPU into the model fitting process
would be to port the BLAS to the GPU.  I also imagine that someone
somewhere has already started on that.

>
> On 1/23/06, Oliver LYTTELTON <oliver at bic.mni.mcgill.ca> wrote:
> >
> >
> > Hi,
> >
> > I am working with a friend on a master's project. Our laboratory does a
> > lot of statistical analysis using the R stats package and we also have a
> > lot of under-utilised nvidia cards sitting in the back of our networked
> > linux machines. Our idea is to coerce the linux nvidia driver to run
> > some of our statistical analysis for us. Our first thought was to
> > specifically code up a version of glm() to run on the nvidia cards...
> >
> > Thinking that this might be of use to the broader community we thought
> > we might ask for feedback before starting?
> >
> > Any ideas...
> >
> > Thanks,
> >
> > Olly
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From ggrothendieck at gmail.com  Tue Jan 24 15:45:05 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 24 Jan 2006 09:45:05 -0500
Subject: [Rd] Master's project to coerce linux nvidia drivers to run
	generalised linear models
In-Reply-To: <40e66e0b0601240638l1c539e9dqa5ccedc8334d6968@mail.gmail.com>
References: <43D53B85.4060109@bic.mni.mcgill.ca>
	<971536df0601231409g17c34b74sbfc3e4828add2050@mail.gmail.com>
	<40e66e0b0601240638l1c539e9dqa5ccedc8334d6968@mail.gmail.com>
Message-ID: <971536df0601240645y7b37ad81mc4fa329f039097ed@mail.gmail.com>

On 1/24/06, Douglas Bates <dmbates at gmail.com> wrote:
> On 1/23/06, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
> > I wonder if it would make more sense to get a relatively
> > low level package to run on it so that all packages that
> > used that low level package would benefit.  The Matrix
> > package and the functions runmean and sum.exact in
> > package caTools are some things that come to mind.
> > Others may have other ideas along these lines.
>
> Martin and I are delighted to learn that the Matrix package is a
> "relatively low-level" package :-)
>
> We were of the opinion that the amount of code and design work that
> went into it made it a little more sophisticated than that.

Low level refers to a package that is typically used by other routines
rather than used directly although, of course, it could be.

This was not intended to be a comment on the breadth, sophistication
or internal complexity of the package.


From nali at umn.edu  Tue Jan 24 18:15:18 2006
From: nali at umn.edu (Na Li)
Date: Tue, 24 Jan 2006 11:15:18 -0600
Subject: [Rd] unexported symbols in libR.so of r-devel
Message-ID: <gj4q3ttumx.fsf@bass.biostat.umn.edu>


Thanks to Matthias Burger, I came to know that in r-devel, a lot of symbols
are no longer exported in libR.so, which breaks the package rpvm since it
calls these functions in serialize.c.

R_InitInPStream
R_InitOutPStream

Since the change is fairly recent (earlier this month), I guess the core team
will be making further changes.  In any case, please add these two to the
exported list.

Thanks,

Michael


From Torsten.Hothorn at rzmail.uni-erlangen.de  Tue Jan 24 18:26:05 2006
From: Torsten.Hothorn at rzmail.uni-erlangen.de (Torsten Hothorn)
Date: Tue, 24 Jan 2006 18:26:05 +0100 (CET)
Subject: [Rd] useR! 2006 - Submission Deadline 2006-02-28
Message-ID: <Pine.LNX.4.51.0601241825010.26623@artemis.imbe.med.uni-erlangen.de>



The submission deadline for `useR! 2006', the second R user conference to be
held in Vienna June 15-17 2006, is only four weeks ahead. Now is the perfect
time to submit abstracts for user-contributed sessions!

The sessions will be a platform to bring together R users, contributers,
package maintainers and developers in the S spirit that `users are developers'.
People from different fields will show us how they solve problems
with R in fascinating applications, including
  - Applied Statistics & Biostatistics
  - Bayesian Statistics
  - Bioinformatics
  - Econometrics & Finance
  - Machine Learning
  - Marketing
  - Robust Statistics
  - Spatial Statistics
  - Statistics in the Social and Political Sciences
  - Teaching
  - Visualization & Graphics
  - and many more.

We invite all R users to submit abstracts on topics presenting innovations or
exciting applications of R. A web page offering more information on the `useR!'
conference, abstract submission, registration and Vienna is available at

  http://www.R-project.org/useR-2006/

We will accept submissions until February 28, 2006.

Let the contributions roll in!


The organizing committee:

Torsten Hothorn, Achim Zeileis, David Meyer, Bettina Gruen,
Kurt Hornik and Friedrich Leisch


From rgentlem at fhcrc.org  Tue Jan 24 18:46:46 2006
From: rgentlem at fhcrc.org (Robert Gentleman)
Date: Tue, 24 Jan 2006 09:46:46 -0800
Subject: [Rd] A patch for do_sample: check replace arg
In-Reply-To: <m2wtgt75gq.fsf@fhcrc.org>
References: <m2wtgt75gq.fsf@fhcrc.org>
Message-ID: <43D66806.3030501@fhcrc.org>

should be there now

Seth Falcon wrote:
> A colleague sent me the following:
> 
>     If you specify probabilities in the 'sample' function and forget
>     to type 'prob=...', then you get nonsense. E.g.
>     
>         sample(1:10,1,c(0,0,0,0,1,0,0,0,0,0)) 
> 
>     does not filter '5', while 
>     
>         sample(1:10,1,prob=c(0,0,0,0,1,0,0,0,0,0)) 
> 
>     does it correctly.  I wish this would return an error because the
>     'replace' argument should only take logical args. Anyway, it is
>     easy to make this mistake and having it produce an error would be
>     nice.
> 
> Assuming there is not a use-case for specifying a logical vector for
> the 'replace' argument, I like the idea of raising an error if replace
> is not length one.  The following patch provides an implementation.
> 
> + seth
> 
> 
> Diff is against svn Revision: 37141
> --- a/src/main/random.c Sat Jan 21 10:54:11 2006 -0800
> +++ b/src/main/random.c Sat Jan 21 11:17:20 2006 -0800
> @@ -453,15 +453,18 @@
>  /* with/without replacement according to r. */
>  SEXP attribute_hidden do_sample(SEXP call, SEXP op, SEXP args, SEXP rho)
>  {
> -    SEXP x, y, prob;
> +    SEXP x, y, prob, sreplace;
>      int k, n, replace;
>      double *p;
>  
>      checkArity(op, args);
>      n = asInteger(CAR(args)); args = CDR(args);
>      k = asInteger(CAR(args)); args = CDR(args);
> -    replace = asLogical(CAR(args)); args = CDR(args);
> +    sreplace = CAR(args); args = CDR(args);
>      prob = CAR(args);
> +    if (length(sreplace) != 1)
> +        errorcall(call, _("invalid '%s' argument"), "replace");
> +    replace = asLogical(sreplace);
>      if (replace == NA_LOGICAL)
>         errorcall(call, _("invalid '%s' argument"), "replace");
>      if (n == NA_INTEGER || n < 1)
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 

-- 
Robert Gentleman, PhD
Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M2-B876
PO Box 19024
Seattle, Washington 98109-1024
206-667-7700
rgentlem at fhcrc.org


From ripley at stats.ox.ac.uk  Tue Jan 24 19:22:49 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 24 Jan 2006 18:22:49 +0000 (GMT)
Subject: [Rd] unexported symbols in libR.so of r-devel
In-Reply-To: <gj4q3ttumx.fsf@bass.biostat.umn.edu>
References: <gj4q3ttumx.fsf@bass.biostat.umn.edu>
Message-ID: <Pine.LNX.4.61.0601241818470.24056@gannet.stats>

On Tue, 24 Jan 2006, Na Li wrote:

>
> Thanks to Matthias Burger, I came to know that in r-devel, a lot of symbols
> are no longer exported in libR.so, which breaks the package rpvm since it
> calls these functions in serialize.c.

They are hidden.  Since they are in Rinternals.h, this was unintentional,
although they are not part of R's declared API and so are at risk (see 
Writing R Extensions).

Just remove 'attribute_hidden' (which I have done in the sources)

> R_InitInPStream
> R_InitOutPStream
>
> Since the change is fairly recent (earlier this month), I guess the core team
> will be making further changes.  In any case, please add these two to the
> exported list.

No more changes are planned.

> Thanks,
>
> Michael
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From roebuck at mdanderson.org  Tue Jan 24 20:43:55 2006
From: roebuck at mdanderson.org (Paul Roebuck)
Date: Tue, 24 Jan 2006 13:43:55 -0600 (CST)
Subject: [Rd] Generated HTML tags not all lowercase
Message-ID: <Pine.OSF.4.58.0601241320160.496508@wotan.mdacc.tmc.edu>

Noticed while fixing problem in my package documentation
that some Rd code referencing an environment variable
as \env{PATH} produced the HTML as <CODE>PATH</CODE>.

"<R-2.2.1>/share/perl/R/Rdconv.pm#785-800":
shows there are others as well.

Although R seems to currently target HTML 4.0 (or older)
and not the stricter XHTML standard, converting the
remaining HTML tags to lowercase would be
backward-compatible with the current standard.

----------------------------------------------------------
SIGSIG -- signature too long (core dumped)


From sfalcon at fhcrc.org  Wed Jan 25 20:55:28 2006
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Wed, 25 Jan 2006 11:55:28 -0800
Subject: [Rd] Using substitute from inside an S4 method
Message-ID: <m2ek2wkrpr.fsf@ziti.local>

Hi all,

I would like to access the name of a variable passed to an S4 method.
For a function, I would do this:

    f <- function(x) as.character(substitute(x))

This also works for a the examples I have tried for methods that do
not have extra, non-dispatch args:

    setGeneric("A", function(x, ...) standardGeneric("A"))

    setMethod("A", signature(x="character"),
              function(x) as.character(substitute(x)))

However, I'm seeing strange behavior if the method uses an extra
argument:

    setMethod("A", signature(x="numeric"),
              function(x, y) as.character(substitute(x)))

    num <- 1

    A(num)
    [1] "x"

    A(num, 2)
    [1] "x"

Is there a way to make this work?  I came up with one workaround that
uses a non-standard generic (see below).  

It seems that when a method uses extra args matching '...' in the
generic, an extra frame is used in the evaluation and so substitute()
isn't reaching the same place as without extra args.

Thanks in advance for pointers to doc or suggestions.


+ seth

## here is a non-standard generic that gives me the behavior I want

    setGeneric("B", function(x, ...) {
        x.name <- as.character(substitute(x))
        standardGeneric("B")
        })
    
    setMethod("B", signature(x="character"),
              function(x, y) {
                  penv <- sys.frames()
                  penv <- penv[[length(penv)-2]]
                  get("x.name", envir=penv)
              })

Observation: Without an extra arg in the method, the appropriate
environment would be penv[[length(penv) - 1]], but the presence of the
extra arg results in an extra environment in the evaluation, hence we
need -2.


From ggrothendieck at gmail.com  Wed Jan 25 21:11:00 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Wed, 25 Jan 2006 15:11:00 -0500
Subject: [Rd] Using substitute from inside an S4 method
In-Reply-To: <m2ek2wkrpr.fsf@ziti.local>
References: <m2ek2wkrpr.fsf@ziti.local>
Message-ID: <971536df0601251211g1368af64qa51175950df2d251@mail.gmail.com>

Try defining your method like this.  I don't know how generally this
works but it seems to work here.

setMethod("A", signature(x="numeric"),
              function(x, y) as.character(substitute(x, sys.frame(-1))))

On 1/25/06, Seth Falcon <sfalcon at fhcrc.org> wrote:
> Hi all,
>
> I would like to access the name of a variable passed to an S4 method.
> For a function, I would do this:
>
>    f <- function(x) as.character(substitute(x))
>
> This also works for a the examples I have tried for methods that do
> not have extra, non-dispatch args:
>
>    setGeneric("A", function(x, ...) standardGeneric("A"))
>
>    setMethod("A", signature(x="character"),
>              function(x) as.character(substitute(x)))
>
> However, I'm seeing strange behavior if the method uses an extra
> argument:
>
>    setMethod("A", signature(x="numeric"),
>              function(x, y) as.character(substitute(x)))
>
>    num <- 1
>
>    A(num)
>    [1] "x"
>
>    A(num, 2)
>    [1] "x"
>
> Is there a way to make this work?  I came up with one workaround that
> uses a non-standard generic (see below).
>
> It seems that when a method uses extra args matching '...' in the
> generic, an extra frame is used in the evaluation and so substitute()
> isn't reaching the same place as without extra args.
>
> Thanks in advance for pointers to doc or suggestions.
>
>
> + seth
>
> ## here is a non-standard generic that gives me the behavior I want
>
>    setGeneric("B", function(x, ...) {
>        x.name <- as.character(substitute(x))
>        standardGeneric("B")
>        })
>
>    setMethod("B", signature(x="character"),
>              function(x, y) {
>                  penv <- sys.frames()
>                  penv <- penv[[length(penv)-2]]
>                  get("x.name", envir=penv)
>              })
>
> Observation: Without an extra arg in the method, the appropriate
> environment would be penv[[length(penv) - 1]], but the presence of the
> extra arg results in an extra environment in the evaluation, hence we
> need -2.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From bill at insightful.com  Wed Jan 25 21:37:06 2006
From: bill at insightful.com (bill@insightful.com)
Date: Wed, 25 Jan 2006 12:37:06 -0800 (PST)
Subject: [Rd] Using substitute from inside an S4 method
In-Reply-To: <m2ek2wkrpr.fsf@ziti.local>
References: <m2ek2wkrpr.fsf@ziti.local>
Message-ID: <Pine.GSO.4.56.0601251221110.20987@durian.statsci.com>

On Wed, 25 Jan 2006, Seth Falcon wrote:

> I would like to access the name of a variable passed to an S4 method.
> For a function, I would do this:
>
>     f <- function(x) as.character(substitute(x))
>
> This also works for a the examples I have tried for methods that do
> not have extra, non-dispatch args:
>
>     setGeneric("A", function(x, ...) standardGeneric("A"))
>
>     setMethod("A", signature(x="character"),
>               function(x) as.character(substitute(x)))
>
> However, I'm seeing strange behavior if the method uses an extra
> argument:
>
>     setMethod("A", signature(x="numeric"),
>               function(x, y) as.character(substitute(x)))
>
>     num <- 1
>
>     A(num)
>     [1] "x"
>
>     A(num, 2)
>     [1] "x"
>
> Is there a way to make this work?  I came up with one workaround that
> uses a non-standard generic (see below).
>
> It seems that when a method uses extra args matching '...' in the
> generic, an extra frame is used in the evaluation and so substitute()
> isn't reaching the same place as without extra args.

The reason you get an extra frame is that when the method's
argument doesn't match the generic's, setMethod makes a function
with the generic's argument list that calls your method (renamed
".local") and makes that new function the real method.  E.g.,

   > setMethod("A",sig=signature(x="character"), function(x,n){
          if(nchar(x)>n) stop("nchar(x)>n")
          deparse(substitute(x))
     })
   [1] "A"
   > getMethod("A",sig=signature(x="character"))
   Method Definition:

   function (x, ...)
   {
       .local <- function (x, n)
       {
           if (nchar(x) > n)
               stop("nchar(x)>n")
           deparse(substitute(x))
       }
       .local(x, ...)
   }
   ...

This has 2 bothersome side effects.  One is yours:
   > A(paste("One","Two"), 10)
   [1] "x"
and the other is that the function mentioned in the
error report is misleading:
   > A("xyz", 1)
   Error in .local(x, ...) : nchar(x)>n
You can workaround both problems by making a method
that looks somewhat like the the one generated by
setMethod but gets some details right for your
function.  E.g.,

   > setMethod("A",sig=signature(x="character"),
          function(x, ...) {
             A.character <- function(x,n,x.name){
                 if(nchar(x)>n) stop("nchar(x)>n")
                 x.name
             }
             x.name <- deparse(substitute(x))
             A.character(x, ..., x.name=x.name)
          }
     )

This gives a suggestive function name in the error
message
   > A(paste("One","Two"), 3)
   Error in A.character(x, ..., x.name = x.name) :
        nchar(x)>n
and lets you use substitute:
   > A(paste("One","Two"), 10)
   [1] "paste(\"One\", \"Two\")"
Thus you don't have to guess how many frames or environments
lie between your method and the generic.

This works in R and Splus.

----------------------------------------------------------------------------
Bill Dunlap
Insightful Corporation
bill at insightful dot com
360-428-8146

 "All statements in this message represent the opinions of the author and do
 not necessarily reflect Insightful Corporation policy or position."


From jgvcqa at rit.edu  Fri Jan 27 06:20:49 2006
From: jgvcqa at rit.edu (jgvcqa@rit.edu)
Date: Fri, 27 Jan 2006 06:20:49 +0100 (CET)
Subject: [Rd] example in ?plot.window is incorrect (PR#8524)
Message-ID: <20060127052049.B17B4CD35@slim.kubism.ku.dk>

Full_Name: Joe Voelkel
Version: R 2.2.0
OS: Windows
Submission from: (NULL) (67.139.200.41)


In ?plot.window, the example includes the argument
   names(eurodist)

in the text function. The argument should be 
   attr(eurodist,"Labels")


From ripley at stats.ox.ac.uk  Fri Jan 27 08:21:45 2006
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Fri, 27 Jan 2006 08:21:45 +0100 (CET)
Subject: [Rd] (PR#8524) Report on obselete version of R (was example in
Message-ID: <20060127072145.939C019A9A@slim.kubism.ku.dk>

Please do not report on obselete versions of R. (See the section on Bugs 
in the FAQ, which specifically asks you not to.)

R 2.2.1 and later use the correct labels(eurodist)

On Fri, 27 Jan 2006 jgvcqa at rit.edu wrote:

> Full_Name: Joe Voelkel
> Version: R 2.2.0
> OS: Windows
> Submission from: (NULL) (67.139.200.41)
>
>
> In ?plot.window, the example includes the argument
>   names(eurodist)
>
> in the text function. The argument should be
>   attr(eurodist,"Labels")

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Fri Jan 27 08:35:03 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 27 Jan 2006 07:35:03 +0000 (GMT)
Subject: [Rd] [R] R compile on AIX 5.2
In-Reply-To: <E153C65077E0034E97A981C6CE26F1BD03814ACD@ENTWMAIL1A.harrahs.org>
References: <E153C65077E0034E97A981C6CE26F1BD03814ACD@ENTWMAIL1A.harrahs.org>
Message-ID: <Pine.LNX.4.61.0601270724290.7012@gannet.stats>

[Moved to a more appropriate list.]

This is a problem with your f2c.  R-2.2.1 (of which you used a beta from 
more than a month ago) has been compiled using f2c, and I just checked 
that my f2c (compiled from the current netlib sources) does not produce 
anything like that or near on line 296.

Why not use a real Fortran compiler?  (Your gcc is rather old, as well.)

On Thu, 26 Jan 2006, Matthew Beason wrote:

> Fellow R Enthusiasts..
>
> 	I'm trying to compile R on AIX 5.2 32bit with gcc 3.3.2-5. I've
> tried both the development bundle R-devel_2006-01-25.tar.gz and the
> R-beta.tar.gz from about a month ago. In each instance, I'm using the
> following options prior to running "./configure --prefix=/usr/local/R":
>
> 	OBJECT_MODE=32
> 	MAIN_LDFLAGS=-Wl,-brtl
> 	SHLIB_LDFLAGS=-Wl,-G
> 	F2C=/usr/local/bin/f2c

But R-devel_2006-01-25 does not support F2C, and its R-admin manual says 
so quite explicitly!

> 	The "R-beta" bundle successfully completes the "configure" stage
> but comes up with the following error during "make":
>
> gcc -Wl,-G -Wl,-bM:SRE -Wl,-H512 -Wl,-T512 -Wl,-bnoentry -Wl,-bexpall
> -Wl,-bI:../../../etc/R.exp -L/usr/local/lib -o internet.so  Rsock.lo
> internet.lo nanoftp.lo nanohttp.lo sock.lo sockconn.lo
> /home/mbeason/work/R-beta/src/modules/lapack
> making Lapack.d from Lapack.c
>        /usr/local/bin/f2c  < dlamc.f > c_dlamc.c
>   dlamch:
>   dlamc1:
> Error on line 296: p1_addr:  unknown uname_tag '537090960'
>   dlamc2:
>   dlamc3:
>   dlamc4:
>   dlamc5:
> make: The error code from the last command is 1.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From julien.gagneur at embl.de  Fri Jan 27 11:02:01 2006
From: julien.gagneur at embl.de (julien.gagneur@embl.de)
Date: Fri, 27 Jan 2006 11:02:01 +0100 (CET)
Subject: [Rd] e1071: using svm with sparse matrices (PR#8527)
Message-ID: <20060127100201.321B2103DC@slim.kubism.ku.dk>

Full_Name: Julien Gagneur
Version: 2.2.1
OS: Linux (Suse 9.3)
Submission from: (NULL) (194.94.44.4)


Using the SparseM library (SparseM_0.66)
and the e1071 library (e1071_1.5-12)


I fail using svm method with a sparse matrix. Here is a sample example.

I experienced the same problem under Windows.



> library(SparseM)
[1] "SparseM library loaded"
> library("e1071")
Loading required package: class
> data(iris)
> attach(iris)
> M=as.matrix(iris[,1:4])
> Msparse=as.matrix.csr(M)
> Species=iris[,5]
> mod=svm(Msparse,Species)
Error in svm.default(Msparse, Species) : object "nac" not found


From ripley at stats.ox.ac.uk  Fri Jan 27 14:31:55 2006
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Fri, 27 Jan 2006 14:31:55 +0100 (CET)
Subject: [Rd] pgamma - inadequate algorithm design and poor coding (PR#8528)
Message-ID: <20060127133155.2110B2070C@slim.kubism.ku.dk>

R versions 2.1.0 to present.

Examples shown were computed under Windows R-devel, current SVN, but ix86 
Linux shows similar behaviour (sometimes NaN or -Inf rather than Inf, 
depending on the compiler and optimization level used).


The replacement pgamma algorithm used from R 2.1.0 has an inadequate 
design and no supporting documentation whatsoever.  There is no reference 
given to support the algorithm, and it seems very desirable to use only 
algorithms with a published (and preferably refereed) analysis, or at 
least of impeccable provenance.

The following errors were found by investigating an example in the 
d-p-q-r-tests.R regression tests that gave NaN on a real system.

These errors were not present in R 2.0.0, which used a normal 
approximation in that region.  We could fix this by reverting where needed 
to a normal approximation, but that leaves the problem that we have no 
proof of the validity or accuracy of the rest of the algorithm (if indeed 
it is accurate).

?pgamma says

      As from R 2.1.0 'pgamma()' uses a new algorithm (mainly by Morten
      Welinder) which should be uniformly as accurate as AS 239.

Well, it 'should be' but it is not, and we should not be making statements 
like that.  Those in the email quoted in pgamma.c exhibit hubris.

There are also at least two examples of sloppy coding that lead to numeric 
overflow and complete loss of accuracy.


Consider

> pgamma(seq(0.75, 1.25, by=0.05)*1e100, shape = 1e100, log=T)
  [1] -3.768207e+98           NaN           NaN           NaN           NaN
  [6] -6.931472e-01           NaN           NaN           NaN           NaN
[11]  0.000000e+00
Warning message:
NaNs produced in: pgamma(q, shape, scale, lower.tail, log.p)
> pgamma(seq(0.75, 1.25, by=0.05)*1e100, shape = 1e100, log=T, lower=F)
  [1]  0.000000e+00           NaN           NaN           NaN           NaN
  [6] -6.931472e-01           Inf           Inf           Inf           Inf
[11] -2.685645e+98
Warning message:
NaNs produced in: pgamma(q, shape, scale, lower.tail, log.p)

> pgamma(c(1-1e-10, 1+1e-10)*1e100, shape = 1e100)
[1] NaN NaN

(shape=1e25 is enough to cause a breakdown in the first of these, and 
1e60 in the rest.)

The code has four branches

1) x <= 1

2) x <= alph - 1 && x < 0.8 * (alph + 50)).  This has the comment
/* incl. large alph */, but that is false.

3) if (alph - 1 < x && alph < 0.8 * (x + 50)).  This has the comment
/* incl. large x */, but again false.

4) The rest, which uses an asymptotic expansion in

pt_ = -x * (log(1 + (lambda-x)/x) - (lambda-x)/x)
= -x * log((lambda-x)/x) - (lambda-x)

and naively assumes that this is small enough to use a power series 
expansion in 1/x with coefficients as powers of pt_.  To make matters 
worse, consider

> pgamma(0.9*1e25, 1e25, log=T)
pgamma_raw(x=9e+024, alph=1e+025, low=1, log=1)
  using ppois_asymp()
pt_ = 5.3605156578263e+022
pp*_asymp(): f=-2.0803930924076e-013 np=-5.3605156578263e+022 
nd=-5.3605156578263e+022  f*nd=11151979746.284
[1] -Inf

Hmm, how did that manage to lose *all* the accuracy here?  Hubris again 
appears in the comments.

Here np and nd are on log scale and if they are large they will be almost 
equal (and negative), and f is not large (and if it were we could have 
computed log f).  So we can compute the log of np+f*nd accurately as

log(np*(1+f*nd/np)) = lnp + log(1+f*nd/np) = lnp + log1p(f*exp(lnd-lnp))


Almost all the mass of gamma(shape=1e100) is concentrated at the nearest 
representable value to 1e100:

> qgamma(c(1e-16, 1-1e-16), 1e100)-1e100
[1] 0 0

(if it can be believed, but this can be verified independently).  So being 
accurate in the middle of the range is pretty academic, but one can at 
least avoid returning the nonsense of non-monotone cdfs and NaN/infinite 
probabilities.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From hin-tak.leung at cimr.cam.ac.uk  Fri Jan 27 15:26:59 2006
From: hin-tak.leung at cimr.cam.ac.uk (hin-tak.leung@cimr.cam.ac.uk)
Date: Fri, 27 Jan 2006 15:26:59 +0100 (CET)
Subject: [Rd] rbind/cbind unimplemented for raw (RAWSXP) types. (PR#8529)
Message-ID: <20060127142659.8FC43CD16@slim.kubism.ku.dk>

Full_Name: Hin-Tak Leung
Version: R 2.2.1
OS: x86_64-redhat-linux-gnu
Submission from: (NULL) (131.111.186.92)


rbind/cbind is unimplemented for raw (RAWSXP) types.

I have a working patch implementing the functionality,
to follow.

--please do not edit the information below--

Version:
 platform = x86_64-redhat-linux-gnu
 arch = x86_64
 os = linux-gnu
 system = x86_64, linux-gnu
 status =
 major = 2
 minor = 2.1
 year = 2005
 month = 12
 day = 20
 svn rev = 36812
 language = R

Locale:
LC_CTYPE=en_US.UTF-8;LC_NUMERIC=C;LC_TIME=en_US.UTF-8;LC_COLLATE=en_US.UTF-8;LC_MONETARY=en_US.UTF-8;LC_MESSAGES=en_US.UTF-8;LC_PAPER=C;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=C;LC_IDENTIFICATION=C

Search Path:
 .GlobalEnv, package:methods, package:stats, package:graphics,
package:grDevices, package:utils, package:datasets, Autoloads, package:base


From hin-tak.leung at cimr.cam.ac.uk  Fri Jan 27 15:33:52 2006
From: hin-tak.leung at cimr.cam.ac.uk (hin-tak.leung@cimr.cam.ac.uk)
Date: Fri, 27 Jan 2006 15:33:52 +0100 (CET)
Subject: [Rd] sub* assgnment unimplemented for raw (RAWSXP) types. (PR#8530)
Message-ID: <20060127143352.736A2103DC@slim.kubism.ku.dk>

Full_Name: Hin-Tak Leung
Version: R 2.2.1
OS: x86_64-redhat-linux-gnu
Submission from: (NULL) (131.111.186.92)


Matrix subset assignment and [[<- assignment
are unimplemented for raw (RAWSXP) types.

I have a working patch implementing the functionality,
to follow.

--please do not edit the information below--

Version:
 platform = x86_64-redhat-linux-gnu
 arch = x86_64
 os = linux-gnu
 system = x86_64, linux-gnu
 status =
 major = 2
 minor = 2.1
 year = 2005
 month = 12
 day = 20
 svn rev = 36812
 language = R

Locale:
LC_CTYPE=en_US.UTF-8;LC_NUMERIC=C;LC_TIME=en_US.UTF-8;LC_COLLATE=en_US.UTF-8;LC_MONETARY=en_US.UTF-8;LC_MESSAGES=en_US.UTF-8;LC_PAPER=C;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=C;LC_IDENTIFICATION=C

Search Path:
 .GlobalEnv, package:methods, package:stats, package:graphics,
package:grDevices, package:utils, package:datasets, Autoloads, package:base


From hin-tak.leung at cimr.cam.ac.uk  Fri Jan 27 15:46:01 2006
From: hin-tak.leung at cimr.cam.ac.uk (Hin-Tak Leung)
Date: Fri, 27 Jan 2006 14:46:01 +0000
Subject: [Rd] rbind/cbind unimplemented for raw (RAWSXP) types. (PR#8529)
In-Reply-To: <20060127142659.8FC43CD16@slim.kubism.ku.dk>
References: <20060127142659.8FC43CD16@slim.kubism.ku.dk>
Message-ID: <43DA3229.6040209@cimr.cam.ac.uk>

hin-tak.leung at cimr.cam.ac.uk wrote:
> Full_Name: Hin-Tak Leung
> Version: R 2.2.1
> OS: x86_64-redhat-linux-gnu
> Submission from: (NULL) (131.111.186.92)
> 
> 
> rbind/cbind is unimplemented for raw (RAWSXP) types.
> 
> I have a working patch implementing the functionality,
> to follow.

Attached in ready-to-patch form and also insert (white spaces
will go wrong) here. Please review, comment and possibly commit,
and hope to see it in R 2.3.x

====================
--- src/main/bind.c.orig        2005-10-06 11:25:22.000000000 +0100
+++ src/main/bind.c     2006-01-27 11:55:32.000000000 +0000
@@ -997,6 +997,7 @@
      case CPLXSXP:
      case STRSXP:
      case VECSXP:
+    case RAWSXP:
         break;
         /* we don't handle expressions: we could, but coercion of a matrix
            to an expression is not ideal */
@@ -1164,6 +1165,18 @@
             }
         }
      }
+    else if (mode == RAWSXP) {
+       for (t = args; t != R_NilValue; t = CDR(t)) {
+           u = PRVALUE(CAR(t));
+           if (isMatrix(u) || length(u) >= lenmin) {
+               u = coerceVector(u, RAWSXP);
+               k = LENGTH(u);
+               idx = (!isMatrix(u)) ? rows : k;
+               for (i = 0; i < idx; i++)
+                   RAW(result)[n++] = RAW(u)[i % k];
+           }
+       }
+    }
      else {
         for (t = args; t != R_NilValue; t = CDR(t)) {
             u = PRVALUE(CAR(t));
@@ -1385,6 +1398,21 @@
             }
         }
      }
+    else if (mode == RAWSXP) {
+       for (t = args; t != R_NilValue; t = CDR(t)) {
+           u = PRVALUE(CAR(t));
+           if (isMatrix(u) || length(u) >= lenmin) {
+               u = coerceVector(u, RAWSXP);
+               k = LENGTH(u);
+               idx = (isMatrix(u)) ? nrows(u) : (k > 0);
+               for (i = 0; i < idx; i++)
+                   for (j = 0; j < cols; j++)
+                       RAW(result)[i + n + (j * rows)]
+                           = RAW(u)[(i + j * idx) % k];
+               n += idx;
+           }
+       }
+    }
      else {
         for (t = args; t != R_NilValue; t = CDR(t)) {
             u = PRVALUE(CAR(t));
================================

From hin-tak.leung at cimr.cam.ac.uk  Fri Jan 27 15:49:45 2006
From: hin-tak.leung at cimr.cam.ac.uk (Hin-Tak Leung)
Date: Fri, 27 Jan 2006 14:49:45 +0000
Subject: [Rd] sub* assgnment unimplemented for raw (RAWSXP) types.
	(PR#8530)
In-Reply-To: <20060127143352.736A2103DC@slim.kubism.ku.dk>
References: <20060127143352.736A2103DC@slim.kubism.ku.dk>
Message-ID: <43DA3309.50903@cimr.cam.ac.uk>

hin-tak.leung at cimr.cam.ac.uk wrote:
> Full_Name: Hin-Tak Leung
> Version: R 2.2.1
> OS: x86_64-redhat-linux-gnu
> Submission from: (NULL) (131.111.186.92)
> 
> 
> Matrix subset assignment and [[<- assignment
> are unimplemented for raw (RAWSXP) types.
> 
> I have a working patch implementing the functionality,
> to follow.

Same thing, sorry for two bug reports and two patches related
to RAWSXP, but they are independent issues.

Attached in ready-to-patch form and also insert (white spaces
will go wrong) here. Please review, comment and possibly commit,
and hope to see it in R 2.3.x.

======================
--- src/main/subassign.c.orig   2005-12-05 23:00:17.000000000 +0000
+++ src/main/subassign.c        2006-01-27 12:50:47.000000000 +0000
@@ -868,6 +868,23 @@
             }
         }
         break;
+    case 2424: /* raw   <- raw   */
+
+       for (j = 0; j < ncs; j++) {
+           jj = INTEGER(sc)[j];
+           if (jj == NA_INTEGER) continue;
+           jj = jj - 1;
+           for (i = 0; i < nrs; i++) {
+               ii = INTEGER(sr)[i];
+               if (ii == NA_INTEGER) continue;
+               ii = ii - 1;
+               ij = ii + jj * nr;
+               RAW(x)[ij] = RAW(y)[k];
+               k = (k + 1) % ny;
+           }
+       }
+       break;
+
      default:
         error(_("incompatible types (case %d) in matrix subset 
assignment"),
               which);
@@ -1611,6 +1628,11 @@
             SET_VECTOR_ELT(x, offset, y);
             break;

+       case 2424:      /* raw <- raw */
+
+           RAW(x)[offset] = RAW(y)[0];
+           break;
+
         default:
             error(_("incompatible types (%d) in [[ assignment"), which);
         }
===========================

From khansen at stat.Berkeley.EDU  Fri Jan 27 19:07:38 2006
From: khansen at stat.Berkeley.EDU (Kasper Daniel Hansen)
Date: Fri, 27 Jan 2006 10:07:38 -0800
Subject: [Rd] e1071: using svm with sparse matrices (PR#8527)
In-Reply-To: <20060127100201.321B2103DC@slim.kubism.ku.dk>
References: <20060127100201.321B2103DC@slim.kubism.ku.dk>
Message-ID: <0CB2E1CC-1EFF-4B8B-851F-198DEB6240A1@stat.berkeley.edu>

First: this is not a bug, more a feature request.

Secondly, even if it was a bug, it is _not_ a bug in R, please read  
the posting rules for bugs. Now a member of R-core has to use  
valuable time to clean up after your bug report.

Correspondence such as this such really be sent to the package  
maintainers (and - perhaps - a cc to R-devel).

Having said all of this, of course it would be nice if svn supported  
sparse matrices.

/Kasper


On Jan 27, 2006, at 2:02 AM, julien.gagneur at embl.de wrote:

> Full_Name: Julien Gagneur
> Version: 2.2.1
> OS: Linux (Suse 9.3)
> Submission from: (NULL) (194.94.44.4)
>
>
> Using the SparseM library (SparseM_0.66)
> and the e1071 library (e1071_1.5-12)
>
>
> I fail using svm method with a sparse matrix. Here is a sample  
> example.
>
> I experienced the same problem under Windows.
>
>
>
>> library(SparseM)
> [1] "SparseM library loaded"
>> library("e1071")
> Loading required package: class
>> data(iris)
>> attach(iris)
>> M=as.matrix(iris[,1:4])
>> Msparse=as.matrix.csr(M)
>> Species=iris[,5]
>> mod=svm(Msparse,Species)
> Error in svm.default(Msparse, Species) : object "nac" not found
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From andy_liaw at merck.com  Fri Jan 27 19:31:59 2006
From: andy_liaw at merck.com (Liaw, Andy)
Date: Fri, 27 Jan 2006 13:31:59 -0500
Subject: [Rd] e1071: using svm with sparse matrices (PR#8527)
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED774@usctmx1106.merck.com>

From: Kasper Daniel Hansen
> 
> First: this is not a bug, more a feature request.
> 
> Secondly, even if it was a bug, it is _not_ a bug in R, please read  
> the posting rules for bugs. Now a member of R-core has to use  
> valuable time to clean up after your bug report.
> 
> Correspondence such as this such really be sent to the package  
> maintainers (and - perhaps - a cc to R-devel).
> 
> Having said all of this, of course it would be nice if svn supported  
> sparse matrices.

Libsvm, the `engine' underneath svm() in `e1071', uses a sparse
representation of the data.  I vaguely recall seeing Chih-Jen Lin's code
that uses the SparseM package to pass sparse data to svm()...  David would
know best, of course.

Andy

 
> /Kasper
> 
> 
> On Jan 27, 2006, at 2:02 AM, julien.gagneur at embl.de wrote:
> 
> > Full_Name: Julien Gagneur
> > Version: 2.2.1
> > OS: Linux (Suse 9.3)
> > Submission from: (NULL) (194.94.44.4)
> >
> >
> > Using the SparseM library (SparseM_0.66)
> > and the e1071 library (e1071_1.5-12)
> >
> >
> > I fail using svm method with a sparse matrix. Here is a sample  
> > example.
> >
> > I experienced the same problem under Windows.
> >
> >
> >
> >> library(SparseM)
> > [1] "SparseM library loaded"
> >> library("e1071")
> > Loading required package: class
> >> data(iris)
> >> attach(iris)
> >> M=as.matrix(iris[,1:4])
> >> Msparse=as.matrix.csr(M)
> >> Species=iris[,5]
> >> mod=svm(Msparse,Species)
> > Error in svm.default(Msparse, Species) : object "nac" not found
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
>


From Weigand.Stephen at mayo.edu  Fri Jan 27 21:15:07 2006
From: Weigand.Stephen at mayo.edu (Stephen Weigand)
Date: Fri, 27 Jan 2006 14:15:07 -0600 (CST)
Subject: [Rd] Tiny typo in ?sprintf
Message-ID: <200601272015.k0RKF7k09101@muttley.mayo.edu>

Greetings,

Reading ?sprintf it seems like the word "be" was omitted:

--- ./src/library/base/man/sprintf.Rd   Tue Sep 20 19:48:55 2005
+++ /tmp/sprintf.Rd     Fri Jan 27 13:51:10 2006
@@ -78,7 +78,7 @@
   }
   Further, as from \R 2.1.0, immediately after \code{\%} may come
   \code{1$} to \code{99$} to refer to the numbered argument: this allows
-  arguments to referenced out of order and is mainly intended for
+  arguments to be referenced out of order and is mainly intended for
   translators of error messages.  If this is done it is best if all
   formats are numbered: if not the unnumbered ones process the arguments
   in order.  See the examples.

Thank you,

Stephen

::::::::::::::::::::::::::::::::::
Stephen Weigand
Division of Biostatistics
Mayo Clinic Rochester, Minn., USA
Phone (507) 266-1650, fax 284-9542


From cain at u.washington.edu  Sat Jan 28 02:03:35 2006
From: cain at u.washington.edu (cain@u.washington.edu)
Date: Sat, 28 Jan 2006 02:03:35 +0100 (CET)
Subject: [Rd] PR#1654
Message-ID: <20060128010335.323BECD13@slim.kubism.ku.dk>

Full_Name: Kevin Cain
Version: 2.2.1
OS: Windows XP
Submission from: (NULL) (128.95.124.144)


In the following command, R ignores the xaxp command - it places tick marks at
1, 1.5, 2.0, etc regardless of what the third argument is (I want them only at
integer values).

plot(x=c(min(time),max(time)),y=c(min(y-se),max(y+se)),type='n',xaxp=c(1,4,3),
  xlab='Measurement Time Point',
  ylab='Accelerometer Mean VMU/min')

A prior bug report says this problem has been fixed (Graphics-fixed/1654), but
it looks like that referred to the unix version.


From ripley at stats.ox.ac.uk  Sat Jan 28 08:29:36 2006
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Sat, 28 Jan 2006 08:29:36 +0100 (CET)
Subject: [Rd] Your false remark on PR#1654
Message-ID: <20060128072936.D4BD0103E9@slim.kubism.ku.dk>

The comment says

`Works in 2.3.0: BDR fixed inline [xy]axp'

and 2.2.1 is not 2.3.0.

Your example is not reproducible, so we cannot check.  If you get a copy 
of R-devel (as the FAQ and posting guide ask you to before posting) you 
can check for yourself.

Please do study the FAQ and avoid time-wasting.


On Sat, 28 Jan 2006 cain at u.washington.edu wrote:

> Full_Name: Kevin Cain
> Version: 2.2.1
> OS: Windows XP
> Submission from: (NULL) (128.95.124.144)
>
>
> In the following command, R ignores the xaxp command - it places tick marks at
> 1, 1.5, 2.0, etc regardless of what the third argument is (I want them only at
> integer values).
>
> plot(x=c(min(time),max(time)),y=c(min(y-se),max(y+se)),type='n',xaxp=c(1,4,3),
>  xlab='Measurement Time Point',
>  ylab='Accelerometer Mean VMU/min')
>
> A prior bug report says this problem has been fixed (Graphics-fixed/1654), but
> it looks like that referred to the unix version.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From IandJMSmith at aol.com  Sat Jan 28 09:43:51 2006
From: IandJMSmith at aol.com (IandJMSmith@aol.com)
Date: Sat, 28 Jan 2006 09:43:51 +0100 (CET)
Subject: [Rd] PR#8528
Message-ID: <20060128084351.090CD2070C@slim.kubism.ku.dk>

On 23/02/05 I suggested that given R had included TOMS 708 to correct for t=
he=20
poor performance of pbeta, TOMS 654 should be included to fix all the pgamm=
a=20
problems. I was slightly surprised to find Morten's code had been included=
=20
instead 2 days later. I noticed but did not worry that the reference to me =
had=20
been removed.=20

The derivation of the asymptotic expansion for the gamma distribution used =
by=20
Morten can be found at http://members.aol.com/iandjmsmith/PoissonApprox.htm=
=20
It is fairly easy to understand and find error bounds for and hence include=
=20
sensibly in an algorithm to calculate pgamma.

The basis and accuracy of the some of the algorithms I use is discussed in=
=20
http://members.aol.com/iandjmsmith/Accuracy.htm In this case, the absolute =
error=20
in the log of the probability gives a good indication of the accuracy of yo=
ur=20
answer. In the least extreme example you consider=20
(pgamma(0.9*1e25,1e25,log=3DT)the absolute error would be about 5360515 and=
 if you exponentiated the result=20
the relative error would be about 10 to the power 2328042. So the answer yo=
u=20
wish to calculate is K times 10 to the power -2.32804237034994E+22, where K=
 is=20
somewhere between 10 to the power plus or minus 2328042. In other words whe=
n=20
you make the changes to correct this problem, your calculation will still=
=20
return values with no real meaning but at least users might be aware of thi=
s which=20
would be no bad thing! For me this answer is possibly so meaningless that N=
an=20
would be preferable.

I did mention to Morten that I had updated my code but I believed that for=
=20
Gnumeric he was quite satisfied with what he had. If you look at the VBA co=
de at=20
http://members.aol.com/iandjmsmith/Examples.txt you can see the changes I=
=20
made to stop the overflow problems you seem to be worried about. My code fo=
r the=20
pdf of the gamma distribution still fails for shape parameters > 2e307 due =
to=20
multiplication of the shap parameter by 2pi. The code for dgamma will have =
the=20
same problem unless it is hidden by use of an 80 or more bit floating point=
=20
processor. The code for the asymptotic expansion for the gamma distribution=
=20
seems to be fine for any number, excluding silly ones like Nan and Inf. Ind=
eed it=20
takes the difference from the mean as a parameter and if you supply an=20
accurate value you get a sensible answer as mentioned in=20
http://members.aol.com/iandjmsmith/Accuracy.htm

I do not share your apparent sense of panic on this matter. I have no=20
problems with error signals like NaNs because it is obvious to the user tha=
t things=20
have gone wrong. Inaccurate answers when the user has no reason to expect t=
hem=20
are usually far more difficult to spot and in many cases the results are ju=
st=20
believed. That for me is a serious problem. I think you will find that the=
=20
pgamma code of 2.0.0 did not work for small shape parameters (similar to th=
e=20
problems exhibited by pbeta still for small parameters see PR#2894), was=20
inaccurate for large shape parameters (> 1e5) when it resorted to the norma=
l=20
approximation and was pretty slow in between. Indeed, the normal approximat=
ion was the=20
cause of PR#7307.


I don't understand your comments about=20
"pt_ =3D -x * (log(1 + (lambda-x)/x) - (lambda-x)/x) =3D -x * log((lambda-x=
)/x) -=20
(lambda-x)=20
and naively assumes that this is small enough to use a power series expansi=
on=20
in 1/x with coefficients as powers of pt_. To make matters worse, consider =
=E2=80=A6"
In the example you go on to discuss, |(lambda-x)/x| is 0.1 and I don't thin=
k=20
it can be bigger than 0.2. Calculating log(1+x)-x is done several ways. If =
|x|=20
< .01 it is evaluated by a power series, if x < -0.8 or x > 1 it uses=20
log1p(1+x)-x and for other values it uses a continued fraction which essent=
ially=20
evaluates more of the same series used when |x| < .01.

Your comments about replacing logspace_add with logspace_sub with simpler=
=20
code which works at first sight to be a very sensible improvement. However,=
 I=20
would be a bit nervous that lnd-lnp could be very large and the exp of it c=
ould=20
return infinity. I'm sure this can be accounted for in the code and lnp +=
=20
log1p(f*exp(lnd-lnp))evaluated as lnp or log(f)+lnd accordingly.

I am not responsible for the code for calculating the logs of probabilities=
=20
but I seem to remember that the extremely poor performance of the algorithm=
s in=20
R2.0.0 with logged probabilities was one of the reasons Morten became=20
interested in changing the pgamma code (see PR#7307). I have had a quick lo=
ok and=20
once the corections mentioned above are made it should be giving nonsense a=
nswers=20
with no difficulty.


Unfortunately there are still a few examples of sloppy coding and accuracy=
=20
errors remaining in R.

The non-central distribution functions have horrible 1- cancellation errors=
=20
associated with them (see PR#7099) and separate code is required for the tw=
o=20
tails of the distributions to get round the problem.

The fix for PR#8251 is a kludge and just moves the inaccuracies to examples=
=20
with higher non-centrality parameters.

pt(x,1) will overflow or return 0 for values < -2e154 for 64-bit=20
implementations. pcauchy works but I believe the pt function is also suppos=
ed to work for=20
non integral degrees of freedom so making it work one degree of freedom via=
=20
pcauchy is hardly much use.

qnbinom(1e-10,1e3,1e-7,TRUE,FALSE) is slow and by varying the parameters,=
=20
qnbinom can be made very slow indeed. I do not think there is anything wron=
g with=20
the Cornish-Fisher expansion. It just seems that it is not always very good=
=20
for the Negative Binomial distribution. In the example above, the initial=
=20
approximation is out by 2e6.

A slightly different problem which can cause qnbinom and qbinom to go into=
=20
infinite loops is when the q-value is too big. For example=20
qnbinom(1E-300,0.000002,10000000000) should return 4.99813787561159E+15 app=
rox but the code works=20
with values where one of the statements y :=3D y +1 or y =3D y - 1; is exec=
uted but=20
does not alter the value of y.

df(0,2,2,FALSE) should be 1 not 0
df(0,df,2,FALSE) should be infinity for df < 2 not 0
dbeta(1e-162,1e-162,1e-162,FALSE) should be 0.5 not 0

Presumably R also has similar problems with the pbeta function. As I recall=
=20
the TOMS 708 code was pretty much included without edits and therefore didn=
't=20
calculate logs of probabilities except by calculating the probability and t=
hen=20
logging it. I assumed this was why it was not used for small shape paramete=
rs=20
where the current code does not work, although it did not seem logical to m=
e.=20
Of course, my memory is not what it was but if that is the case and there a=
re=20
problems with modifying the TOMS code, you could try an asymptotic expansio=
n=20
based on http://members.aol.com/iandjmsmith/BinomialApprox.htm

This response has been very rushed. I do not write well when I have plenty =
of=20
time and I felt I had so many different things to say so I apologise if it =
is=20
all a bit of a jumble.=20

Ian Smith


	[[alternative HTML version deleted]]


From sigbert at wiwi.hu-berlin.de  Sun Jan 29 10:57:54 2006
From: sigbert at wiwi.hu-berlin.de (sigbert@wiwi.hu-berlin.de)
Date: Sun, 29 Jan 2006 10:57:54 +0100 (CET)
Subject: [Rd] R 2.1.1 installation fails under Suse 10.0 (PR#8533)
Message-ID: <20060129095754.70303CD27@slim.kubism.ku.dk>

Full_Name: Sigbert Klinke
Version: 2.1.1
OS: Suse Linux 10.0 (Full DVD)
Submission from: (NULL) (141.20.100.252)


Suse 10.0 installs only a Fortran 95 compiler with g77 compability mode. Using
this leads in "configure" to an abortion with problems about "FPICFLAGS".
Deinstalling g77 compatiblity mode, using f2c, compiles R. But after calling R()
the program shows its entrance message and then hangs up, using 100% of the
processor capacity.

What finally works on my computer was setting a softlink from /usr/bin/g77 to
gfortran such that the fortran 95 compiler was used directly during the R
compilation.


From ripley at stats.ox.ac.uk  Sun Jan 29 11:49:41 2006
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Sun, 29 Jan 2006 11:49:41 +0100 (CET)
Subject: [Rd] R 2.1.1 installation fails under Suse 10.0 (PR#8533)
Message-ID: <20060129104941.9A318CCEB@slim.kubism.ku.dk>

I am afraid

1) This is a message about an outdated version of R, and

2) The problem is most likely the compiler and the way it (mis)compiles 
src/modules/lapack/dlamc.f.  This is covered in the R-admin manual (which 
INSTALL asked you to read).  This said in 2.1.1

   It seems that @samp{gcc 3.4.x} and later on @samp{ix86} Linux defeat
   attempts by the LAPACK code to avoid computations entirely in
   extended-precision registers, so file @file{src/modules/lapack/dlamc.f}
   may need to be compiled without optimization.  If configure detects
   @acronym{GNU} Fortran it adds flag @option{-ffloat-store} which
   suffices, but it is possible that @file{src/modules/lapack/Makefile}
   will need to be edited to remove optimization on other platforms.

and the NEWS for 2.2.0 says

     o	src/modules/lapack/dlamc.f is now compiled with -ffloat-store
 	if f2c/gcc are used, as well as if g77 is used.


If the current version of R does not work for you, please ask a question 
on R-devel describing exactly what you are using (you have not mentioned 
your cpu type or your compilers, for example) and what the error messages 
are.


On Sun, 29 Jan 2006 sigbert at wiwi.hu-berlin.de wrote:

> Full_Name: Sigbert Klinke
> Version: 2.1.1
> OS: Suse Linux 10.0 (Full DVD)
> Submission from: (NULL) (141.20.100.252)
>
>
> Suse 10.0 installs only a Fortran 95 compiler

Which compiler is this?  According to its man page, gfortran is *not* a 
Fortran 95 compiler, and you have not mentioned what you think is.
(I don't believe there is a free F95 compiler for Linux.)

> with g77 compability mode. Using this leads in "configure" to an 
> abortion with problems about "FPICFLAGS".

Which were?  What happened when you set FPICFLAGS in config.site?


> Deinstalling g77 compatiblity 
> mode, using f2c, compiles R. But after calling R() the program shows its 
> entrance message and then hangs up, using 100% of the processor 
> capacity.
>
> What finally works on my computer was setting a softlink from /usr/bin/g77 to
> gfortran such that the fortran 95 compiler was used directly during the R
> compilation.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From p.dalgaard at biostat.ku.dk  Sun Jan 29 14:00:25 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 29 Jan 2006 14:00:25 +0100
Subject: [Rd] R 2.1.1 installation fails under Suse 10.0 (PR#8533)
In-Reply-To: <20060129095754.70303CD27@slim.kubism.ku.dk>
References: <20060129095754.70303CD27@slim.kubism.ku.dk>
Message-ID: <x2oe1vfaty.fsf@turmalin.kubism.ku.dk>

sigbert at wiwi.hu-berlin.de writes:

> Suse 10.0 installs only a Fortran 95 compiler with g77 compability mode. Using
> this leads in "configure" to an abortion with problems about "FPICFLAGS".
> Deinstalling g77 compatiblity mode, using f2c, compiles R. But after calling R()
> the program shows its entrance message and then hangs up, using 100% of the
> processor capacity.
> 
> What finally works on my computer was setting a softlink from /usr/bin/g77 to
> gfortran such that the fortran 95 compiler was used directly during the R
> compilation.

All alpha and beta versions, as well as the final release of 2.2.1
were done on (32bit) SuSE 10.0! 

Just remember to install *all* the tools, including the gcc-fortran
RPM. And install a recent R - older versions may need help to pick up
the right Fortran, and as you have noticed gcc4 and gcc3 does not mix
and match (so if you insist on using compat-g77, also use compat-gcc). 

And: It is not considered a bug that versions of R do not work/build
with OS releases which didn't exist at the time....

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From murdoch at stats.uwo.ca  Sun Jan 29 18:18:08 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sun, 29 Jan 2006 12:18:08 -0500
Subject: [Rd] [R] help with read.table() function
In-Reply-To: <x2d5ibf04m.fsf@turmalin.kubism.ku.dk>
References: <20060129152620.65089.qmail@web33210.mail.mud.yahoo.com>	<43DCE4A4.4090703@free.fr>
	<x2d5ibf04m.fsf@turmalin.kubism.ku.dk>
Message-ID: <43DCF8D0.8060105@stats.uwo.ca>

(Moved from R-help).

This comes up often enough that I'm starting to think most functions 
that take filename arguments should have file.choose() as the default 
value.  Then one could do

read.table()

and have a dialog box pop up in Windows, or some other prompt for a 
filename in other platforms.  Are there any obviously bad side effects 
from a change like this?

Duncan Murdoch

On 1/29/2006 11:51 AM, Peter Dalgaard wrote:
> Romain Francois <francoisromain at free.fr> writes:
> 
>> Le 29.01.2006 16:26, oliver wee a ?crit :
>>
>>> hello, I have just started using R for doing a project
>>> in time series...
>>>
>>> unfortunately, I am having trouble using the
>>> read.table function for use in reading my data set.
>>>
>>> This is what I'm getting:
>>> I inputted:
>>> data <-
>>> read.table("D:/Oliver/Professional/Studies/Time Series
>>> Analysis/spdc2693.data", header = TRUE)
>>>
>>> I got:
>>> Error in file(file, "r") : unable to open connection
>>> In addition: Warning message:
>>> cannot open file 'D:/Oliver/Professional/Studies/Time
>>> Series Analysis/spdc2693.data', reason 'No such file
>>> or directory'
>>>
>>> as I am just a novice programmer, I really would
>>> appreciate help from you guys. Is there a need to
>>> setpath in R, like in java or something like that...
>>>
>>> I am using the windows version btw. 
>>>
>>> I have also tried to put the file in the work
>>> directory of R, so that I only typed 
>>> data <- read.table("spdc2693.data", header = TRUE)
>>> Again, it won't work, with the same error message.
>>>
>>> I would appreciate any help. thanks again.
>>>  
>>>
>> Hi, try :
>>
>> read.table(file.choose(), header=TRUE)
>>
>> and go to your file.
>> Also, you can look a ?setwd, ?getwd
> 
> Right. Or just file.choose() and see what the OS thinks your file is
> really called. The most common causes for symptoms like that are
> 
> (A) The file is "spcd2693.data"
> (B) There's an extra extension which ever helpful Windows decided to
> hide, as in "spdc2693.data.txt".
> 
>


From charlie at stat.umn.edu  Sun Jan 29 18:23:18 2006
From: charlie at stat.umn.edu (Charles Geyer)
Date: Sun, 29 Jan 2006 11:23:18 -0600
Subject: [Rd] Bug in wilcox.test
In-Reply-To: <mailman.3.1138532401.23395.r-devel@r-project.org>
References: <mailman.3.1138532401.23395.r-devel@r-project.org>
Message-ID: <20060129172318.GA13110@stat.umn.edu>

There is a fairly new bug in wilcox.test in R-2.2.1 (stable).
It wasn't there when I last taught nonparametrics in fall 2003.

Line 86 of wilcox.test.R

    achieved.alpha<-2*psignrank(trunc(qu),n)

It should be

    achieved.alpha<-2*psignrank(trunc(qu)-1,n)

If you don't see why, decode the cookbook instructions p. 56 in
Hollander and Wolfe (2nd ed.) or see

    http://www.stat.umn.edu/geyer/5601/examp/signrank.html#conf

or just do a sanity check: does this to the right thing when the confidence
interval is the range of the data, case qu = 1?  No.

Of course, this error isn't very visible, because wilcox.test still
prints the ASKED FOR confidence level instead of the ACTUAL ACHIEVED
confidence level (which sucks IMHO, but never mind) except when
it incorrectly thinks that the level cannot be achieved, in which
case it prints the incorrect achieved level.  Just great.

To see the bug do

   X <- read.table(url("http://www.stat.umn.edu/geyer/5601/hwdata/t3-3.txt"),
       header = TRUE)
   attach(X)
   wilcox.test(y, x, paired = TRUE, conf.int = TRUE)

and compare with what you get when you change t3-1.txt to t3-3.txt in
the Rweb form in

    http://www.stat.umn.edu/geyer/5601/examp/signrank.html#conf

and submit.

Sorry to sound so grumpy about this, but I hate having my
homework solutions explain that R sucks (in this instance).

Better yet, NEVER use wilcox.test.  Always use wilcox.exact in exactRankTests
or fuzzy.signrank.ci in fuzzyRankTests.

   X <- read.table(url("http://www.stat.umn.edu/geyer/5601/hwdata/t3-3.txt"),
       header = TRUE)
   attach(X)
   library(fuzzyRankTests)
   fuzzy.signrank.ci(y - x)

prints

            Wilcoxon signed rank test

    data:  y - x
    95 percent confidence interval:

    Randomized confidence interval is mixture of two intervals

     probability lower end upper end
             0.9       -25       605
             0.1       -15       560

    Corresponding fuzzy confidence interval is one on the narrower
    interval, 0.9 elsewhere on the wider interval, and zero outside the
    wider interval, with values at jumps that are the average of the left
    and right limits

Sorry about the advert.  Couldn't resist the opportunity.

-- 
Charles Geyer
Professor, School of Statistics
University of Minnesota
charlie at stat.umn.edu


From greg.kochanski at phon.ox.ac.uk  Sun Jan 29 18:39:14 2006
From: greg.kochanski at phon.ox.ac.uk (greg.kochanski@phon.ox.ac.uk)
Date: Sun, 29 Jan 2006 18:39:14 +0100 (CET)
Subject: [Rd] dataentry() (PR#8535)
Message-ID: <20060129173914.60C9B19A41@slim.kubism.ku.dk>

Full_Name: Greg Kochanski
Version: 2.2.1
OS: Debian Linux (testing)
Submission from: (NULL) (212.159.16.190)


In writing class notes to teach people how to use R, I came across
a design failure of dataentry().

It seems that if you add a new value outside the bounds of an array,
dataentry() fills the intervening space with NA.     That's reasonable,
but what happens if you *accidentally* entered a value outside the
bounds?    There's no way to get rid of it.

Note that you are doomed once you type anyting beyond the end
of an array, even if you delete your typing before moving the
mouse out of the cell -- even then, that cell and others
between it and the end of the array will be filled with NA.

I would suggest that some mechanism be added to allow
arrays to be shortened in the data editor.     It would
be generally useful, even beyond fixing typing mistakes.

(I recognize that you can shorten an array with something
like x <- X[1:132], but it should still be possible in the
editor.)


From MSchwartz at mn.rr.com  Sun Jan 29 18:55:45 2006
From: MSchwartz at mn.rr.com (Marc Schwartz)
Date: Sun, 29 Jan 2006 11:55:45 -0600
Subject: [Rd] [R] help with read.table() function
In-Reply-To: <43DCF8D0.8060105@stats.uwo.ca>
References: <20060129152620.65089.qmail@web33210.mail.mud.yahoo.com>
	<43DCE4A4.4090703@free.fr> <x2d5ibf04m.fsf@turmalin.kubism.ku.dk>
	<43DCF8D0.8060105@stats.uwo.ca>
Message-ID: <1138557345.5518.249.camel@localhost.localdomain>

I would argue against this.

If this were the default, that is requiring user interaction, it would
break a fair amount of code that I (and I am sure a lot of others have)
where automation is critical.

A lot of the issues seem to be user errors, file permission errors,
hidden extensions as is pointed out below and related issues. If there
is a legitimate bug in R resulting in these issues, then let's patch
that. However, I don't think that I can recall reproducible situations
where a bug in R is the root cause of these problems.

Best regards,

Marc Schwartz

On Sun, 2006-01-29 at 12:18 -0500, Duncan Murdoch wrote:
> (Moved from R-help).
> 
> This comes up often enough that I'm starting to think most functions 
> that take filename arguments should have file.choose() as the default 
> value.  Then one could do
> 
> read.table()
> 
> and have a dialog box pop up in Windows, or some other prompt for a 
> filename in other platforms.  Are there any obviously bad side effects 
> from a change like this?
> 
> Duncan Murdoch
> 
> On 1/29/2006 11:51 AM, Peter Dalgaard wrote:
> > Romain Francois <francoisromain at free.fr> writes:
> > 
> >> Le 29.01.2006 16:26, oliver wee a ?crit :
> >>
> >>> hello, I have just started using R for doing a project
> >>> in time series...
> >>>
> >>> unfortunately, I am having trouble using the
> >>> read.table function for use in reading my data set.
> >>>
> >>> This is what I'm getting:
> >>> I inputted:
> >>> data <-
> >>> read.table("D:/Oliver/Professional/Studies/Time Series
> >>> Analysis/spdc2693.data", header = TRUE)
> >>>
> >>> I got:
> >>> Error in file(file, "r") : unable to open connection
> >>> In addition: Warning message:
> >>> cannot open file 'D:/Oliver/Professional/Studies/Time
> >>> Series Analysis/spdc2693.data', reason 'No such file
> >>> or directory'
> >>>
> >>> as I am just a novice programmer, I really would
> >>> appreciate help from you guys. Is there a need to
> >>> setpath in R, like in java or something like that...
> >>>
> >>> I am using the windows version btw. 
> >>>
> >>> I have also tried to put the file in the work
> >>> directory of R, so that I only typed 
> >>> data <- read.table("spdc2693.data", header = TRUE)
> >>> Again, it won't work, with the same error message.
> >>>
> >>> I would appreciate any help. thanks again.
> >>>  
> >>>
> >> Hi, try :
> >>
> >> read.table(file.choose(), header=TRUE)
> >>
> >> and go to your file.
> >> Also, you can look a ?setwd, ?getwd
> > 
> > Right. Or just file.choose() and see what the OS thinks your file is
> > really called. The most common causes for symptoms like that are
> > 
> > (A) The file is "spcd2693.data"
> > (B) There's an extra extension which ever helpful Windows decided to
> > hide, as in "spdc2693.data.txt".
> > 
> >
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From murdoch at stats.uwo.ca  Sun Jan 29 19:08:57 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sun, 29 Jan 2006 13:08:57 -0500
Subject: [Rd] [R] help with read.table() function
In-Reply-To: <1138557345.5518.249.camel@localhost.localdomain>
References: <20060129152620.65089.qmail@web33210.mail.mud.yahoo.com>	<43DCE4A4.4090703@free.fr>
	<x2d5ibf04m.fsf@turmalin.kubism.ku.dk>	<43DCF8D0.8060105@stats.uwo.ca>
	<1138557345.5518.249.camel@localhost.localdomain>
Message-ID: <43DD04B9.8040903@stats.uwo.ca>

On 1/29/2006 12:55 PM, Marc Schwartz wrote:
> I would argue against this.
> 
> If this were the default, that is requiring user interaction, it would
> break a fair amount of code that I (and I am sure a lot of others have)
> where automation is critical.

I don't see how this change could affect any code that currently works 
-- maybe you misunderstood the proposal?  I'm just suggesting that the 
args to functions that take input from files use file.choose() as a 
default.  For example, read.table's arg list would change from

function (file, header = FALSE, ...

to

function (file = file.choose(), header = FALSE, ...

Currently a call like read.table() dies with an error message:

 > read.table()
Error in read.table() : argument "file" is missing, with no default

With this change we wouldn't get an error here.

> 
> A lot of the issues seem to be user errors, file permission errors,
> hidden extensions as is pointed out below and related issues. If there
> is a legitimate bug in R resulting in these issues, then let's patch
> that. However, I don't think that I can recall reproducible situations
> where a bug in R is the root cause of these problems.

This isn't about fixing a bug, it's about making the user interface a 
bit less error-prone.

Duncan Murdoch

> 
> Best regards,
> 
> Marc Schwartz
> 
> On Sun, 2006-01-29 at 12:18 -0500, Duncan Murdoch wrote:
>> (Moved from R-help).
>>
>> This comes up often enough that I'm starting to think most functions 
>> that take filename arguments should have file.choose() as the default 
>> value.  Then one could do
>>
>> read.table()
>>
>> and have a dialog box pop up in Windows, or some other prompt for a 
>> filename in other platforms.  Are there any obviously bad side effects 
>> from a change like this?
>>
>> Duncan Murdoch
>>
>> On 1/29/2006 11:51 AM, Peter Dalgaard wrote:
>>> Romain Francois <francoisromain at free.fr> writes:
>>>
>>>> Le 29.01.2006 16:26, oliver wee a ?crit :
>>>>
>>>>> hello, I have just started using R for doing a project
>>>>> in time series...
>>>>>
>>>>> unfortunately, I am having trouble using the
>>>>> read.table function for use in reading my data set.
>>>>>
>>>>> This is what I'm getting:
>>>>> I inputted:
>>>>> data <-
>>>>> read.table("D:/Oliver/Professional/Studies/Time Series
>>>>> Analysis/spdc2693.data", header = TRUE)
>>>>>
>>>>> I got:
>>>>> Error in file(file, "r") : unable to open connection
>>>>> In addition: Warning message:
>>>>> cannot open file 'D:/Oliver/Professional/Studies/Time
>>>>> Series Analysis/spdc2693.data', reason 'No such file
>>>>> or directory'
>>>>>
>>>>> as I am just a novice programmer, I really would
>>>>> appreciate help from you guys. Is there a need to
>>>>> setpath in R, like in java or something like that...
>>>>>
>>>>> I am using the windows version btw. 
>>>>>
>>>>> I have also tried to put the file in the work
>>>>> directory of R, so that I only typed 
>>>>> data <- read.table("spdc2693.data", header = TRUE)
>>>>> Again, it won't work, with the same error message.
>>>>>
>>>>> I would appreciate any help. thanks again.
>>>>>  
>>>>>
>>>> Hi, try :
>>>>
>>>> read.table(file.choose(), header=TRUE)
>>>>
>>>> and go to your file.
>>>> Also, you can look a ?setwd, ?getwd
>>> Right. Or just file.choose() and see what the OS thinks your file is
>>> really called. The most common causes for symptoms like that are
>>>
>>> (A) The file is "spcd2693.data"
>>> (B) There's an extra extension which ever helpful Windows decided to
>>> hide, as in "spdc2693.data.txt".
>>>
>>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From greg.kochanski at phon.ox.ac.uk  Sun Jan 29 19:16:24 2006
From: greg.kochanski at phon.ox.ac.uk (greg.kochanski@phon.ox.ac.uk)
Date: Sun, 29 Jan 2006 19:16:24 +0100 (CET)
Subject: [Rd] mosaicplot() labels overlap (PR#8536)
Message-ID: <20060129181624.0A6A5C777@slim.kubism.ku.dk>

Full_Name: Greg Kochanski
Version: 2.2.1
OS: Debian Linux (testing)
Submission from: (NULL) (212.159.16.190)


This is really a feature request.

When you do mosaicplot() on a data set where the probability of
several nearby rows is small, then the labels for those
rows are plotted overlapping each other.

This situation can be improved by calling mosaicplot()
with a large value of "off", but sometimes, even off=50
(the largest allowable value) isn't sufficient,
especially if the labels are several characters long.

The problem exists even if the labels don't overlap,
because one needs space between the labels to avoid
confusion.   For instance, labels "L*H", "!H*", and
"L%" when too close together turn into
"L*H!H*L%" which is confusing to anyone.

The problem could be solved by breaking the assumption that
the label position need always be exactly matched to the
graphic.    This is OK, especially for rows because
(a) the graphical blocks that are part of a single row
aren't aligned with each other anyway, and
(b) if you can read the labels, you can generally
match things up by counting.

One way to do this in a fairly nice way is to position
the labels in such a way to minimize the
sum of the squared error between the label center
and the average position of the blocks on that row,
subject to the constraint that labels be
non-overlapping.

This problem is actually not too hard to solve:
it is essentially Kruskal's algorithm for finding
a best-fit monotonic sequence  (which probably exists in
CRAN already).

Neglecting edge effects, assume you have a
vector of desired positions z, and
a vector of minimum widths for each label w.
Then, you can compute the space used up by
the labels:  s[i] = -0.5*w[1] + sum(j<i of w[i]) + 0.5*w[i]
and compute y = M(z-s) + s
where M() gives the best-fit monotonically nondecreasing
fit to it's argument.   Y should then be the correct
place to put each label.

If there's a likelyhood of getting a patch accepted,
I could probably supply one.

(Given the opportunity, I'd think about shifting the blocks
up and down also, to do an overall alignment.)


From ripley at stats.ox.ac.uk  Sun Jan 29 19:29:30 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 29 Jan 2006 18:29:30 +0000 (GMT)
Subject: [Rd] [R] help with read.table() function
In-Reply-To: <1138557345.5518.249.camel@localhost.localdomain>
References: <20060129152620.65089.qmail@web33210.mail.mud.yahoo.com>
	<43DCE4A4.4090703@free.fr> <x2d5ibf04m.fsf@turmalin.kubism.ku.dk>
	<43DCF8D0.8060105@stats.uwo.ca>
	<1138557345.5518.249.camel@localhost.localdomain>
Message-ID: <Pine.LNX.4.61.0601291802280.25185@gannet.stats>

On Sun, 29 Jan 2006, Marc Schwartz wrote:

> I would argue against this.
>
> If this were the default, that is requiring user interaction, it would
> break a fair amount of code that I (and I am sure a lot of others have)
> where automation is critical.

I don't see how.  The current default is

> read.table()
Error in read.table() : argument "file" is missing, with no default

so the only change is that the default might do something useful.

Nor do I see the change would help, as the same people would still use a 
character string for 'file' and not omit the argument.  (It seems very 
unlikely that they would read any documentation that suggested things had 
changed.)

The same issue could be made over scan(), where the current default is 
useful.

> A lot of the issues seem to be user errors, file permission errors,
> hidden extensions as is pointed out below and related issues. If there
> is a legitimate bug in R resulting in these issues, then let's patch
> that. However, I don't think that I can recall reproducible situations
> where a bug in R is the root cause of these problems.

Nor I.

Note that file.choose does not protect you against file permission issues 
(actually, on a command-line Unix-alike it does nothing much useful at 
all):

> readLines(file.choose())
Enter file name: errs.txt
Error in file(con, "r") : unable to open connection
In addition: Warning message:
cannot open file 'errs.txt', reason 'Permission denied'

but

> file.show(file.choose())
says

NO FILE errs.txt

which is not a good idea (and I will improve).

So this would really only have any effect on GUI platforms, for people who 
read the documentation.


> Best regards,
>
> Marc Schwartz
>
> On Sun, 2006-01-29 at 12:18 -0500, Duncan Murdoch wrote:
>> (Moved from R-help).
>>
>> This comes up often enough that I'm starting to think most functions
>> that take filename arguments should have file.choose() as the default
>> value.  Then one could do
>>
>> read.table()
>>
>> and have a dialog box pop up in Windows, or some other prompt for a
>> filename in other platforms.  Are there any obviously bad side effects
>> from a change like this?
>>
>> Duncan Murdoch
>>
>> On 1/29/2006 11:51 AM, Peter Dalgaard wrote:
>>> Romain Francois <francoisromain at free.fr> writes:
>>>
>>>> Le 29.01.2006 16:26, oliver wee a ?crit :
>>>>
>>>>> hello, I have just started using R for doing a project
>>>>> in time series...
>>>>>
>>>>> unfortunately, I am having trouble using the
>>>>> read.table function for use in reading my data set.
>>>>>
>>>>> This is what I'm getting:
>>>>> I inputted:
>>>>> data <-
>>>>> read.table("D:/Oliver/Professional/Studies/Time Series
>>>>> Analysis/spdc2693.data", header = TRUE)
>>>>>
>>>>> I got:
>>>>> Error in file(file, "r") : unable to open connection
>>>>> In addition: Warning message:
>>>>> cannot open file 'D:/Oliver/Professional/Studies/Time
>>>>> Series Analysis/spdc2693.data', reason 'No such file
>>>>> or directory'
>>>>>
>>>>> as I am just a novice programmer, I really would
>>>>> appreciate help from you guys. Is there a need to
>>>>> setpath in R, like in java or something like that...
>>>>>
>>>>> I am using the windows version btw.
>>>>>
>>>>> I have also tried to put the file in the work
>>>>> directory of R, so that I only typed
>>>>> data <- read.table("spdc2693.data", header = TRUE)
>>>>> Again, it won't work, with the same error message.
>>>>>
>>>>> I would appreciate any help. thanks again.
>>>>>
>>>>>
>>>> Hi, try :
>>>>
>>>> read.table(file.choose(), header=TRUE)
>>>>
>>>> and go to your file.
>>>> Also, you can look a ?setwd, ?getwd
>>>
>>> Right. Or just file.choose() and see what the OS thinks your file is
>>> really called. The most common causes for symptoms like that are
>>>
>>> (A) The file is "spcd2693.data"
>>> (B) There's an extra extension which ever helpful Windows decided to
>>> hide, as in "spdc2693.data.txt".
>>>
>>>
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From greg.kochanski at phon.ox.ac.uk  Sun Jan 29 19:30:11 2006
From: greg.kochanski at phon.ox.ac.uk (greg.kochanski@phon.ox.ac.uk)
Date: Sun, 29 Jan 2006 19:30:11 +0100 (CET)
Subject: [Rd] Mosaicplot coloring (PR#8537)
Message-ID: <20060129183011.D2682C777@slim.kubism.ku.dk>

Full_Name: Greg Kochanski
Version: 2.2.1
OS: Debian Linux (testing)
Submission from: (NULL) (212.159.16.190)


mosaicplot(x, shade=TRUE) is intended to color the blocks
blue if they are more common than one might expect
and red if they are rarer than one might expect.

Unfortunately, if a block is much rarer than expected,
it is so narrow that one cannot see the red.    Thus,
a casual inspection of the mosaicplot will miss some
of the most statistically significant results.

This is partially an intrinsic problem and cannot be
entirely fixed, but it is made worse by the black outlines
around each block.    Blocks with very small probabilities
show as black, not red.   The broken outlines on the
red blocks help, but not quite enough.

I would suggest that there be an option to either turn off
the black outlines when for the colored blocks,
or an option to use colored outlines.

If those options are somehow hidden in the ... part of the
argument list for mosaicplot(), I apologize, but then this
bug report should be converted to a documentation bug.
Nowhere in help(mosaicplot) does it say what one can put into
the unspecified arguments (...).


From MSchwartz at mn.rr.com  Sun Jan 29 19:30:23 2006
From: MSchwartz at mn.rr.com (Marc Schwartz)
Date: Sun, 29 Jan 2006 12:30:23 -0600
Subject: [Rd] [R] help with read.table() function
In-Reply-To: <43DD04B9.8040903@stats.uwo.ca>
References: <20060129152620.65089.qmail@web33210.mail.mud.yahoo.com>
	<43DCE4A4.4090703@free.fr> <x2d5ibf04m.fsf@turmalin.kubism.ku.dk>
	<43DCF8D0.8060105@stats.uwo.ca>
	<1138557345.5518.249.camel@localhost.localdomain>
	<43DD04B9.8040903@stats.uwo.ca>
Message-ID: <1138559424.5518.255.camel@localhost.localdomain>

Duncan,

OK. I mis-understood the proposal. My error.

Thanks for the clarification.

Marc

On Sun, 2006-01-29 at 13:08 -0500, Duncan Murdoch wrote:
> On 1/29/2006 12:55 PM, Marc Schwartz wrote:
> > I would argue against this.
> > 
> > If this were the default, that is requiring user interaction, it would
> > break a fair amount of code that I (and I am sure a lot of others have)
> > where automation is critical.
> 
> I don't see how this change could affect any code that currently works 
> -- maybe you misunderstood the proposal?  I'm just suggesting that the 
> args to functions that take input from files use file.choose() as a 
> default.  For example, read.table's arg list would change from
> 
> function (file, header = FALSE, ...
> 
> to
> 
> function (file = file.choose(), header = FALSE, ...
> 
> Currently a call like read.table() dies with an error message:
> 
>  > read.table()
> Error in read.table() : argument "file" is missing, with no default
> 
> With this change we wouldn't get an error here.
> 
> > 
> > A lot of the issues seem to be user errors, file permission errors,
> > hidden extensions as is pointed out below and related issues. If there
> > is a legitimate bug in R resulting in these issues, then let's patch
> > that. However, I don't think that I can recall reproducible situations
> > where a bug in R is the root cause of these problems.
> 
> This isn't about fixing a bug, it's about making the user interface a 
> bit less error-prone.
> 
> Duncan Murdoch
> 
> > 
> > Best regards,
> > 
> > Marc Schwartz
> > 
> > On Sun, 2006-01-29 at 12:18 -0500, Duncan Murdoch wrote:
> >> (Moved from R-help).
> >>
> >> This comes up often enough that I'm starting to think most functions 
> >> that take filename arguments should have file.choose() as the default 
> >> value.  Then one could do
> >>
> >> read.table()
> >>
> >> and have a dialog box pop up in Windows, or some other prompt for a 
> >> filename in other platforms.  Are there any obviously bad side effects 
> >> from a change like this?
> >>
> >> Duncan Murdoch
> >>
> >> On 1/29/2006 11:51 AM, Peter Dalgaard wrote:
> >>> Romain Francois <francoisromain at free.fr> writes:
> >>>
> >>>> Le 29.01.2006 16:26, oliver wee a ?crit :
> >>>>
> >>>>> hello, I have just started using R for doing a project
> >>>>> in time series...
> >>>>>
> >>>>> unfortunately, I am having trouble using the
> >>>>> read.table function for use in reading my data set.
> >>>>>
> >>>>> This is what I'm getting:
> >>>>> I inputted:
> >>>>> data <-
> >>>>> read.table("D:/Oliver/Professional/Studies/Time Series
> >>>>> Analysis/spdc2693.data", header = TRUE)
> >>>>>
> >>>>> I got:
> >>>>> Error in file(file, "r") : unable to open connection
> >>>>> In addition: Warning message:
> >>>>> cannot open file 'D:/Oliver/Professional/Studies/Time
> >>>>> Series Analysis/spdc2693.data', reason 'No such file
> >>>>> or directory'
> >>>>>
> >>>>> as I am just a novice programmer, I really would
> >>>>> appreciate help from you guys. Is there a need to
> >>>>> setpath in R, like in java or something like that...
> >>>>>
> >>>>> I am using the windows version btw. 
> >>>>>
> >>>>> I have also tried to put the file in the work
> >>>>> directory of R, so that I only typed 
> >>>>> data <- read.table("spdc2693.data", header = TRUE)
> >>>>> Again, it won't work, with the same error message.
> >>>>>
> >>>>> I would appreciate any help. thanks again.
> >>>>>  
> >>>>>
> >>>> Hi, try :
> >>>>
> >>>> read.table(file.choose(), header=TRUE)
> >>>>
> >>>> and go to your file.
> >>>> Also, you can look a ?setwd, ?getwd
> >>> Right. Or just file.choose() and see what the OS thinks your file is
> >>> really called. The most common causes for symptoms like that are
> >>>
> >>> (A) The file is "spcd2693.data"
> >>> (B) There's an extra extension which ever helpful Windows decided to
> >>> hide, as in "spdc2693.data.txt".
> >>>
> >>>
> >> ______________________________________________
> >> R-devel at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-devel
> > 
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel


From murdoch at stats.uwo.ca  Sun Jan 29 22:35:50 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sun, 29 Jan 2006 16:35:50 -0500
Subject: [Rd] [R] help with read.table() function
In-Reply-To: <Pine.LNX.4.61.0601291802280.25185@gannet.stats>
References: <20060129152620.65089.qmail@web33210.mail.mud.yahoo.com>
	<43DCE4A4.4090703@free.fr> <x2d5ibf04m.fsf@turmalin.kubism.ku.dk>
	<43DCF8D0.8060105@stats.uwo.ca>
	<1138557345.5518.249.camel@localhost.localdomain>
	<Pine.LNX.4.61.0601291802280.25185@gannet.stats>
Message-ID: <43DD3536.1060004@stats.uwo.ca>

On 1/29/2006 1:29 PM, Prof Brian Ripley wrote:
> On Sun, 29 Jan 2006, Marc Schwartz wrote:
> 
>> I would argue against this.
>>
>> If this were the default, that is requiring user interaction, it would
>> break a fair amount of code that I (and I am sure a lot of others have)
>> where automation is critical.
> 
> I don't see how.  The current default is
> 
>> read.table()
> Error in read.table() : argument "file" is missing, with no default
> 
> so the only change is that the default might do something useful.
> 
> Nor do I see the change would help, as the same people would still use a 
> character string for 'file' and not omit the argument.  (It seems very 
> unlikely that they would read any documentation that suggested things had 
> changed.)

No, but people teaching new users (or answering R-help questions) would 
have a simpler answer:  just use read.table().

> The same issue could be made over scan(), where the current default is 
> useful.

scan() is very useful for small reads, and rarely needed for reading big 
formatted files, so I wouldn't propose to change it.  The inconsistency 
with read.table would be unfortunate, but no worse than the current one.

>> A lot of the issues seem to be user errors, file permission errors,
>> hidden extensions as is pointed out below and related issues. If there
>> is a legitimate bug in R resulting in these issues, then let's patch
>> that. However, I don't think that I can recall reproducible situations
>> where a bug in R is the root cause of these problems.
> 
> Nor I.
> 
> Note that file.choose does not protect you against file permission issues 
> (actually, on a command-line Unix-alike it does nothing much useful at 
> all):
> 
>> readLines(file.choose())
> Enter file name: errs.txt

No, it's not helpful here, but again it makes things no worse, and 
there's always the possibility that someone would improve file.choose().

Duncan Murdoch

> Error in file(con, "r") : unable to open connection
> In addition: Warning message:
> cannot open file 'errs.txt', reason 'Permission denied'
> 
> but
> 
>> file.show(file.choose())
> says
> 
> NO FILE errs.txt
> 
> which is not a good idea (and I will improve).
> 
> So this would really only have any effect on GUI platforms, for people who 
> read the documentation.
> 
> 
>> Best regards,
>>
>> Marc Schwartz
>>
>> On Sun, 2006-01-29 at 12:18 -0500, Duncan Murdoch wrote:
>>> (Moved from R-help).
>>>
>>> This comes up often enough that I'm starting to think most functions
>>> that take filename arguments should have file.choose() as the default
>>> value.  Then one could do
>>>
>>> read.table()
>>>
>>> and have a dialog box pop up in Windows, or some other prompt for a
>>> filename in other platforms.  Are there any obviously bad side effects
>>> from a change like this?
>>>
>>> Duncan Murdoch
>>>
>>> On 1/29/2006 11:51 AM, Peter Dalgaard wrote:
>>>> Romain Francois <francoisromain at free.fr> writes:
>>>>
>>>>> Le 29.01.2006 16:26, oliver wee a ?crit :
>>>>>
>>>>>> hello, I have just started using R for doing a project
>>>>>> in time series...
>>>>>>
>>>>>> unfortunately, I am having trouble using the
>>>>>> read.table function for use in reading my data set.
>>>>>>
>>>>>> This is what I'm getting:
>>>>>> I inputted:
>>>>>> data <-
>>>>>> read.table("D:/Oliver/Professional/Studies/Time Series
>>>>>> Analysis/spdc2693.data", header = TRUE)
>>>>>>
>>>>>> I got:
>>>>>> Error in file(file, "r") : unable to open connection
>>>>>> In addition: Warning message:
>>>>>> cannot open file 'D:/Oliver/Professional/Studies/Time
>>>>>> Series Analysis/spdc2693.data', reason 'No such file
>>>>>> or directory'
>>>>>>
>>>>>> as I am just a novice programmer, I really would
>>>>>> appreciate help from you guys. Is there a need to
>>>>>> setpath in R, like in java or something like that...
>>>>>>
>>>>>> I am using the windows version btw.
>>>>>>
>>>>>> I have also tried to put the file in the work
>>>>>> directory of R, so that I only typed
>>>>>> data <- read.table("spdc2693.data", header = TRUE)
>>>>>> Again, it won't work, with the same error message.
>>>>>>
>>>>>> I would appreciate any help. thanks again.
>>>>>>
>>>>>>
>>>>> Hi, try :
>>>>>
>>>>> read.table(file.choose(), header=TRUE)
>>>>>
>>>>> and go to your file.
>>>>> Also, you can look a ?setwd, ?getwd
>>>> Right. Or just file.choose() and see what the OS thinks your file is
>>>> really called. The most common causes for symptoms like that are
>>>>
>>>> (A) The file is "spcd2693.data"
>>>> (B) There's an extra extension which ever helpful Windows decided to
>>>> hide, as in "spdc2693.data.txt".
>>>>
>>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>


From murdoch at stats.uwo.ca  Sun Jan 29 23:11:01 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sun, 29 Jan 2006 17:11:01 -0500
Subject: [Rd] [R] help with read.table() function
In-Reply-To: <971536df0601291024n57113e97t3cc938a78a11f495@mail.gmail.com>
References: <20060129162850.73978.qmail@web33204.mail.mud.yahoo.com>	
	<43DCF7E8.2080900@stats.uwo.ca>
	<971536df0601291024n57113e97t3cc938a78a11f495@mail.gmail.com>
Message-ID: <43DD3D75.6010404@stats.uwo.ca>

On 1/29/2006 1:24 PM, Gabor Grothendieck wrote:
 > Normally one expects stdin to be the default on command line
 > programs and something like file.choose to be the default on GUI
 > programs and this would break that expectation.

We don't currently meet that expectation, so I don't think it would make 
things any worse.  As I mentioned to Brian, I wouldn't change the 
default for scan() (which is stdin everywhere).  I haven't done a 
complete survey yet, but after looking at a few, I think the rules I 
would use are these:

  - the function should use the filename argument to find an existing file
  - it should not already have a default
  - it should be something that would commonly be used interactively

Ones I would change which currently give an error with no filename:

read.table() and friends
dget()
read.dcf()
source()
read.ftable()
tkpager()
md5sum()
Rd_parse()

Ones I probably wouldn't touch:

unz()
file.create(), etc.
file() gives a temporary file for writing
dput(), write.dcf() write to the console
dev2bitmap(), bitmap()
file.show() - which might be called with an empty file list, which we 
should treat as a no-op

Ones I'm not sure about right now, because they're relatively obscure:

sys.source()
shell.exec()

Duncan Murdoch
 >
 > If there were a GUI version of read.table then that would reasonbly
 > have file.choose as the default.
 >
 > On 1/29/06, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
 >> On 1/29/2006 11:28 AM, oliver wee wrote:
 >>> hi,
 >>>
 >>> Sorry again to bother you, but I got the file.choose()
 >>> to work. Thanks for the help there.
 >>>
 >>> Unfortunately I encountered a new problem. After I
 >>> selected the data, I got this error message:
 >>>
 >>> Error in scan(file = file, what = what, sep = sep,
 >>> quote = quote, dec = dec,  :
 >>>         line 1 did not have 11 elements
 >>> In addition: Warning message:
 >>> incomplete final line found by readTableHeader on
 >>> 'D:\Oliver\Professional\Studies\Time Series
 >>> Analysis\spdc2693.data.txt'
 >>>
 >>> my time series data looks like this...
 >>>
 >>> ------------
 >>> Standard and Poor's 500 Index closing values from 1926
 >>> to 1993.
 >>>
 >>>   Date       Index
 >>>   260101     12.76
 >>>   260108     12.78
 >>>   260115     12.52
 >>>   260122     12.45
 >>>   260129     12.74
 >>>   260205     12.87
 >>>   260212     12.87
 >>>   260219     12.74
 >>>   260226     12.18
 >>>   260305     11.99
 >>>   260312     12.15
 >>>   260319     11.64
 >>>   260326     11.46
 >>> ...
 >>> (and so on)
 >>> ----------
 >>>
 >>> Should I insert additional attributes besides header =
 >>> TRUE?
 >> Yes, you need to tell it to skip over the lines of the comment at the
 >> start of the file.  That looks like 3 lines (including the blank line),
 >> so add skip=3 to your read.table call.
 >>
 >> Duncan Murdoch
 >>
 >>> thanks.
 >>>
 >>>
 >>> --- Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
 >>>
 >>>> On 1/29/2006 10:26 AM, oliver wee wrote:
 >>>>> hello, I have just started using R for doing a
 >>>> project
 >>>>> in time series...
 >>>>>
 >>>>> unfortunately, I am having trouble using the
 >>>>> read.table function for use in reading my data
 >>>> set.
 >>>>> This is what I'm getting:
 >>>>> I inputted:
 >>>>> data <-
 >>>>> read.table("D:/Oliver/Professional/Studies/Time
 >>>> Series
 >>>>> Analysis/spdc2693.data", header = TRUE)
 >>>> Generally it's easier to use the dialogs to specify
 >>>> the filename, e.g.
 >>>>
 >>>> read.table(file.choose(), header=TRUE)
 >>>>
 >>>> Then you shouldn't get the "no such file" message.
 >>>> If you do, you
 >>>> should check whether other programs (e.g. notepad)
 >>>> can open the file.
 >>>> Maybe you don't have read permission?
 >>>>
 >>>> Duncan Murdoch
 >>>>
 >>>>> I got:
 >>>>> Error in file(file, "r") : unable to open
 >>>> connection
 >>>>> In addition: Warning message:
 >>>>> cannot open file
 >>>> 'D:/Oliver/Professional/Studies/Time
 >>>>> Series Analysis/spdc2693.data', reason 'No such
 >>>> file
 >>>>> or directory'
 >>>>>
 >>>>> as I am just a novice programmer, I really would
 >>>>> appreciate help from you guys. Is there a need to
 >>>>> setpath in R, like in java or something like
 >>>> that...
 >>>>> I am using the windows version btw.
 >>>>>
 >>>>> I have also tried to put the file in the work
 >>>>> directory of R, so that I only typed
 >>>>> data <- read.table("spdc2693.data", header = TRUE)
 >>>>> Again, it won't work, with the same error message.
 >>>>>
 >>>>> I would appreciate any help. thanks again.
 >>>>>
 >>>>> ______________________________________________
 >>>>> R-help at stat.math.ethz.ch mailing list
 >>>>> https://stat.ethz.ch/mailman/listinfo/r-help
 >>>>> PLEASE do read the posting guide!
 >>>> http://www.R-project.org/posting-guide.html
 >>>>
 >>>>
 >>>
 >>> __________________________________________________
 >>> Do You Yahoo!?
 >>> Tired of spam?  Yahoo! Mail has the best spam protection around
 >>> http://mail.yahoo.com
 >> ______________________________________________
 >> R-help at stat.math.ethz.ch mailing list
 >> https://stat.ethz.ch/mailman/listinfo/r-help
 >> PLEASE do read the posting guide! 
http://www.R-project.org/posting-guide.html
 >>


From ggrothendieck at gmail.com  Sun Jan 29 23:20:59 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sun, 29 Jan 2006 17:20:59 -0500
Subject: [Rd] [R] help with read.table() function
In-Reply-To: <43DD3D75.6010404@stats.uwo.ca>
References: <20060129162850.73978.qmail@web33204.mail.mud.yahoo.com>
	<43DCF7E8.2080900@stats.uwo.ca>
	<971536df0601291024n57113e97t3cc938a78a11f495@mail.gmail.com>
	<43DD3D75.6010404@stats.uwo.ca>
Message-ID: <971536df0601291420g5dd9732dl2108a5661705d7e2@mail.gmail.com>

On 1/29/06, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> On 1/29/2006 1:24 PM, Gabor Grothendieck wrote:
>  > Normally one expects stdin to be the default on command line
>  > programs and something like file.choose to be the default on GUI
>  > programs and this would break that expectation.
>
> We don't currently meet that expectation, so I don't think it would make
> things any worse.  As I mentioned to Brian, I wouldn't change the

II don't think you understood my point.  This is how most software works,
IN GENERAL, so R should be expected to work that way
too.   I don't think not having a default is so bad but having the wrong
default that breaks the stereotype that one expects in all software
is bad.

What could be done is to add something about file.choose to the
error message that one gets when one does read.table("myfile")
and it can't find "myfile".


From murdoch at stats.uwo.ca  Mon Jan 30 00:03:34 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sun, 29 Jan 2006 18:03:34 -0500
Subject: [Rd] [R] help with read.table() function
In-Reply-To: <971536df0601291420g5dd9732dl2108a5661705d7e2@mail.gmail.com>
References: <20060129162850.73978.qmail@web33204.mail.mud.yahoo.com>	
	<43DCF7E8.2080900@stats.uwo.ca>	
	<971536df0601291024n57113e97t3cc938a78a11f495@mail.gmail.com>	
	<43DD3D75.6010404@stats.uwo.ca>
	<971536df0601291420g5dd9732dl2108a5661705d7e2@mail.gmail.com>
Message-ID: <43DD49C6.201@stats.uwo.ca>

On 1/29/2006 5:20 PM, Gabor Grothendieck wrote:
> On 1/29/06, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
>> On 1/29/2006 1:24 PM, Gabor Grothendieck wrote:
>>  > Normally one expects stdin to be the default on command line
>>  > programs and something like file.choose to be the default on GUI
>>  > programs and this would break that expectation.
>>
>> We don't currently meet that expectation, so I don't think it would make
>> things any worse.  As I mentioned to Brian, I wouldn't change the
> 
> II don't think you understood my point.  This is how most software works,
> IN GENERAL, so R should be expected to work that way
> too.   

I think I understood that, but my point is that R doesn't act that way 
now, and this change won't make the situation worse.

 >I don't think not having a default is so bad but having the wrong
> default that breaks the stereotype that one expects in all software
> is bad.

I don't follow your argument.  Why is it better to say

Error in read.table() : argument "file" is missing, with no default

than it would be to ask the user which file to read?  The first is 
unexpected in both of the situations you described, while the second is 
only unexpected in a command line program.

Consistency is a good thing, but there are a number of choices of what 
to be consistent with:

  - other similar functions in R (but they are inconsistent)
  - previous versions of R (which is why I wouldn't change scan())
  - other software a user would be familiar with (which is why 
file.choose() is a good idea in a GUI, but not in a command line program).

> What could be done is to add something about file.choose to the
> error message that one gets when one does read.table("myfile")
> and it can't find "myfile".

Currently our error messages explain what went wrong, they generally 
don't try to suggest alternative approaches (though a few do, e.g. 
help("dfdsfs")).  There are a lot of reasons read.table() could fail, 
and I think it would be very hard to get a good automatic rule on when 
file.choose() was the appropriate alternative.

Duncan Murdoch


From john.maindonald at anu.edu.au  Mon Jan 30 00:06:52 2006
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Mon, 30 Jan 2006 10:06:52 +1100 (EST)
Subject: [Rd] Citation of R packages
Message-ID: <1578.202.89.153.187.1138576012.squirrel@sqmail.anu.edu.au>

The bibtex citations provided by citation() do not
work all that well in cases where there is no printed
document to reference:
(1) A version field is needed, as the note field is
required for other purposes, currently trying to
sort out nuances that cannot be sorted out in the
author list (author, compiler, implementor of R version,
contributor, ...) and maybe giving a cross-reference
to a book or paper that is somehow relevant.
(2) Maybe the author field should be more nuanced, or
maybe ...
(3) In compiling a list of packages, name order seems
preferable, and one wants the title first (achieved by
relocating the format.title field in the manual FUNCTION
in the .bst file
(4) manual seems not an ideal name for the class, if
there is no manual.

Maybe what is needed is a package or suchlike class,
and several alternative .bst files that handle the needed
listings.

I know at least one other person who is wrestling with
this, and others on this list must be wrestling with it.

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Mathematical Sciences Institute, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.


From ggrothendieck at gmail.com  Mon Jan 30 01:28:50 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sun, 29 Jan 2006 19:28:50 -0500
Subject: [Rd] [R] help with read.table() function
In-Reply-To: <43DD49C6.201@stats.uwo.ca>
References: <20060129162850.73978.qmail@web33204.mail.mud.yahoo.com>
	<43DCF7E8.2080900@stats.uwo.ca>
	<971536df0601291024n57113e97t3cc938a78a11f495@mail.gmail.com>
	<43DD3D75.6010404@stats.uwo.ca>
	<971536df0601291420g5dd9732dl2108a5661705d7e2@mail.gmail.com>
	<43DD49C6.201@stats.uwo.ca>
Message-ID: <971536df0601291628u3baaa9f9pb50fadb444772a50@mail.gmail.com>

On 1/29/06, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> On 1/29/2006 5:20 PM, Gabor Grothendieck wrote:
> > On 1/29/06, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> >> On 1/29/2006 1:24 PM, Gabor Grothendieck wrote:
> >>  > Normally one expects stdin to be the default on command line
> >>  > programs and something like file.choose to be the default on GUI
> >>  > programs and this would break that expectation.
> >>
> >> We don't currently meet that expectation, so I don't think it would make
> >> things any worse.  As I mentioned to Brian, I wouldn't change the
> >
> > II don't think you understood my point.  This is how most software works,
> > IN GENERAL, so R should be expected to work that way
> > too.
>
> I think I understood that, but my point is that R doesn't act that way
> now, and this change won't make the situation worse.
>
>  >I don't think not having a default is so bad but having the wrong
> > default that breaks the stereotype that one expects in all software
> > is bad.
>
> I don't follow your argument.  Why is it better to say
>
> Error in read.table() : argument "file" is missing, with no default

Because that does not mix conventions.

>
> than it would be to ask the user which file to read?  The first is
> unexpected in both of the situations you described, while the second is
> only unexpected in a command line program.

Because its conventional that stdin is the default.  Even in R someone
must have realized that since that is the default for scan.


>
> Consistency is a good thing, but there are a number of choices of what
> to be consistent with:
>
>  - other similar functions in R (but they are inconsistent)
>  - previous versions of R (which is why I wouldn't change scan())
>  - other software a user would be familiar with (which is why
> file.choose() is a good idea in a GUI, but not in a command line program).
>
> > What could be done is to add something about file.choose to the
> > error message that one gets when one does read.table("myfile")
> > and it can't find "myfile".
>
> Currently our error messages explain what went wrong, they generally
> don't try to suggest alternative approaches (though a few do, e.g.
> help("dfdsfs")).  There are a lot of reasons read.table() could fail,
> and I think it would be very hard to get a good automatic rule on when
> file.choose() was the appropriate alternative.

I wasn't suggesting an automatic solution but I think it could be helpful
if the error message pointed out the existence of file.choose.


From karl.thomaseth at isib.cnr.it  Mon Jan 30 08:57:10 2006
From: karl.thomaseth at isib.cnr.it (karl.thomaseth@isib.cnr.it)
Date: Mon, 30 Jan 2006 08:57:10 +0100 (CET)
Subject: [Rd] colnames(tapply(...)) (PR#8539)
Message-ID: <20060130075710.C5DACCD13@slim.kubism.ku.dk>

I would like to bring to your attention the following error message
which didn't appear on previous versions (long time ago?)

Thanks for all your effort

Karl

Version 2.2.1 Patched (2006-01-21 r37153)

 > f <- rep(c(1,2),each=5)
 > x <- tapply(f,f,sum)
 > colnames(x)
Error in dn[[2]] : subscript out of bounds


-------------------------------
Karl Thomaseth, Ph.D.
Research Director
National Research Council
Institute of Biomedical Engineering ISIB-CNR
Corso Stati Uniti 4
35127 Padova, ITALY
http://www.isib.cnr.it/~karl/
tel.: (+39) 049 8295762,  fax:  (+39) 049 8295763


	[[alternative HTML version deleted]]


From Achim.Zeileis at wu-wien.ac.at  Mon Jan 30 09:38:43 2006
From: Achim.Zeileis at wu-wien.ac.at (Achim Zeileis)
Date: Mon, 30 Jan 2006 09:38:43 +0100 (CET)
Subject: [Rd] Mosaicplot coloring (PR#8537)
In-Reply-To: <20060129183011.D2682C777@slim.kubism.ku.dk>
References: <20060129183011.D2682C777@slim.kubism.ku.dk>
Message-ID: <Pine.LNX.4.58.0601300926120.2745@thorin.ci.tuwien.ac.at>

On Sun, 29 Jan 2006 greg.kochanski at phon.ox.ac.uk wrote:

> Full_Name: Greg Kochanski
> Version: 2.2.1
> OS: Debian Linux (testing)
> Submission from: (NULL) (212.159.16.190)
>
>
> mosaicplot(x, shade=TRUE) is intended to color the blocks
> blue if they are more common than one might expect
> and red if they are rarer than one might expect.
>
> Unfortunately, if a block is much rarer than expected,
> it is so narrow that one cannot see the red.

Where is the bug?? Please read Section 9 in
  http://CRAN.R-project.org/doc/manuals/R-FAQ.html
and also the posting guide at
  http://www.R-project.org/posting-guide.html

> Thus,
> a casual inspection of the mosaicplot will miss some
> of the most statistically significant results.

Note that with this shading you are using colored cells and statistically
significant results might not coincide.

> This is partially an intrinsic problem and cannot be
> entirely fixed, but it is made worse by the black outlines
> around each block.    Blocks with very small probabilities
> show as black, not red.   The broken outlines on the
> red blocks help, but not quite enough.
>
> I would suggest that there be an option to either turn off
> the black outlines when for the colored blocks,
> or an option to use colored outlines.

For an enhanced implementation of mosaic plots written in the grid
graphics system, see the package "vcd" and the functions mosaic() and
strucplot(). See the package vignettes for details on control of the
graphical appearance and also for combining shading and significance
testing. To overcome the problem of small cells, another approach is to
plot expected instead of observed frequencies.
Z

> If those options are somehow hidden in the ... part of the
> argument list for mosaicplot(), I apologize, but then this
> bug report should be converted to a documentation bug.
> Nowhere in help(mosaicplot) does it say what one can put into
> the unspecified arguments (...).
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From Achim.Zeileis at wu-wien.ac.at  Mon Jan 30 09:42:28 2006
From: Achim.Zeileis at wu-wien.ac.at (Achim Zeileis)
Date: Mon, 30 Jan 2006 09:42:28 +0100 (CET)
Subject: [Rd] mosaicplot() labels overlap (PR#8536)
In-Reply-To: <20060129181624.0A6A5C777@slim.kubism.ku.dk>
References: <20060129181624.0A6A5C777@slim.kubism.ku.dk>
Message-ID: <Pine.LNX.4.58.0601300938490.2745@thorin.ci.tuwien.ac.at>

On Sun, 29 Jan 2006 greg.kochanski at phon.ox.ac.uk wrote:

> Full_Name: Greg Kochanski
> Version: 2.2.1
> OS: Debian Linux (testing)
> Submission from: (NULL) (212.159.16.190)
>
>
> This is really a feature request.

Hence not a bug (just for the record).

A potential solution to your problem is to write your own labeling
function for strucplot() in vcd implementing the approach you suggest
below. Also check the available labeling functions whether they can be
used to produce acceptable results. One way which might work, depending on
your specific data, is to rotate the labels. Details can again be found in
the package vignettes.
Z

> When you do mosaicplot() on a data set where the probability of
> several nearby rows is small, then the labels for those
> rows are plotted overlapping each other.
>
> This situation can be improved by calling mosaicplot()
> with a large value of "off", but sometimes, even off=50
> (the largest allowable value) isn't sufficient,
> especially if the labels are several characters long.
>
> The problem exists even if the labels don't overlap,
> because one needs space between the labels to avoid
> confusion.   For instance, labels "L*H", "!H*", and
> "L%" when too close together turn into
> "L*H!H*L%" which is confusing to anyone.
>
> The problem could be solved by breaking the assumption that
> the label position need always be exactly matched to the
> graphic.    This is OK, especially for rows because
> (a) the graphical blocks that are part of a single row
> aren't aligned with each other anyway, and
> (b) if you can read the labels, you can generally
> match things up by counting.
>
> One way to do this in a fairly nice way is to position
> the labels in such a way to minimize the
> sum of the squared error between the label center
> and the average position of the blocks on that row,
> subject to the constraint that labels be
> non-overlapping.
>
> This problem is actually not too hard to solve:
> it is essentially Kruskal's algorithm for finding
> a best-fit monotonic sequence  (which probably exists in
> CRAN already).
>
> Neglecting edge effects, assume you have a
> vector of desired positions z, and
> a vector of minimum widths for each label w.
> Then, you can compute the space used up by
> the labels:  s[i] = -0.5*w[1] + sum(j<i of w[i]) + 0.5*w[i]
> and compute y = M(z-s) + s
> where M() gives the best-fit monotonically nondecreasing
> fit to it's argument.   Y should then be the correct
> place to put each label.
>
> If there's a likelyhood of getting a patch accepted,
> I could probably supply one.
>
> (Given the opportunity, I'd think about shifting the blocks
> up and down also, to do an overall alignment.)
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From ripley at stats.ox.ac.uk  Mon Jan 30 09:45:18 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 30 Jan 2006 08:45:18 +0000 (GMT)
Subject: [Rd] colnames(tapply(...)) (PR#8539)
In-Reply-To: <20060130075710.C5DACCD13@slim.kubism.ku.dk>
References: <20060130075710.C5DACCD13@slim.kubism.ku.dk>
Message-ID: <Pine.LNX.4.61.0601300839410.8938@gannet.stats>

On Mon, 30 Jan 2006 karl.thomaseth at isib.cnr.it wrote:

> I would like to bring to your attention the following error message
> which didn't appear on previous versions (long time ago?)
>
> Thanks for all your effort
>
> Karl
>
> Version 2.2.1 Patched (2006-01-21 r37153)
>
> > f <- rep(c(1,2),each=5)
> > x <- tapply(f,f,sum)
> > colnames(x)
> Error in dn[[2]] : subscript out of bounds

What is inappropriate about this?  x is a 1D array, so it does not have
column names (or columns).  Indeed, the help page says

        x: a matrix-like R object, with at least two dimensions for
           'colnames'.

The exact same message appears in 1.6.2, more than three years old (and 
the earliest version I still have running). If earlier versions did not 
have an error message, that was probably a bug.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From maechler at stat.math.ethz.ch  Mon Jan 30 10:16:41 2006
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 30 Jan 2006 10:16:41 +0100
Subject: [Rd] [R] help with read.table() function
In-Reply-To: <43DD3536.1060004@stats.uwo.ca>
References: <20060129152620.65089.qmail@web33210.mail.mud.yahoo.com>
	<43DCE4A4.4090703@free.fr> <x2d5ibf04m.fsf@turmalin.kubism.ku.dk>
	<43DCF8D0.8060105@stats.uwo.ca>
	<1138557345.5518.249.camel@localhost.localdomain>
	<Pine.LNX.4.61.0601291802280.25185@gannet.stats>
	<43DD3536.1060004@stats.uwo.ca>
Message-ID: <17373.55673.169110.838093@stat.math.ethz.ch>

>>>>> "Duncan" == Duncan Murdoch <murdoch at stats.uwo.ca>
>>>>>     on Sun, 29 Jan 2006 16:35:50 -0500 writes:

    Duncan> On 1/29/2006 1:29 PM, Prof Brian Ripley wrote:
    >> On Sun, 29 Jan 2006, Marc Schwartz wrote:
    >> 
    >>> I would argue against this.
    >>> 
    >>> If this were the default, that is requiring user
    >>> interaction, it would break a fair amount of code that I
    >>> (and I am sure a lot of others have) where automation is
    >>> critical.

    >>  I don't see how.  The current default is
    >> 
    >>> read.table()
    >> Error in read.table() : argument "file" is missing, with
    >> no default
    >> 
    >> so the only change is that the default might do something
    >> useful.
    >> 
    >> Nor do I see the change would help, as the same people
    >> would still use a character string for 'file' and not
    >> omit the argument.  (It seems very unlikely that they
    >> would read any documentation that suggested things had
    >> changed.)

    Duncan> No, but people teaching new users (or answering
    Duncan> R-help questions) would have a simpler answer: just
    Duncan> use read.table().

but I am not sure that people teaching R should advocate such a 
read.table;  
I they did, the new R users would get the concept that this is
the way how to use R.
I still think R should eventually be used for "Programming with Data"
rather than a GUI for ``clicking results together''.
Hence users should be taught (in the 2nd or 3rd part, not the
1st one of their introduction to R)
to work with R scripts, writing functions etc.

And similar to Marc, I would never want default behavior to
start up a GUI elements: It is also much more error-prone; just
consider the  "choose CRAN mirror" GUI that we had recently
introduced, and the many questions and "bug" reports it produced.

I know that I am biased in my views here;
but I strongly advocate the  "useRs becoming programmeRs" theme
and hence rather keep R consistent as a programming language,
partly agreeing with Gabor here.

    >> The same issue could be made over scan(), where the
    >> current default is useful.

    Duncan> scan() is very useful for small reads, and rarely
    Duncan> needed for reading big formatted files, 

{people might disagree with this; given scan() is more efficient
 for large files;  but that's not really the topic here.}

    Duncan> so I wouldn't propose to change it.  
good.

    Duncan> The inconsistency
    Duncan> with read.table would be unfortunate, but no worse
    Duncan> than the current one.


    >>> A lot of the issues seem to be user errors, file
    >>> permission errors, hidden extensions as is pointed out
    >>> below and related issues. If there is a legitimate bug
    >>> in R resulting in these issues, then let's patch
    >>> that. However, I don't think that I can recall
    >>> reproducible situations where a bug in R is the root
    >>> cause of these problems.

    >>  Nor I.
    >> 
    >> Note that file.choose does not protect you against file
    >> permission issues (actually, on a command-line Unix-alike
    >> it does nothing much useful at all):
    >> 
    >>> readLines(file.choose())
    >> Enter file name: errs.txt

    Duncan> No, it's not helpful here, but again it makes things
    Duncan> no worse, and there's always the possibility that
    Duncan> someone would improve file.choose().

I strongly prefer the current usage

  read.table(file.choose(), ....)

which implicitly ``explains'' how the file name is chosen to a
new default
  read.table( .....)

I'd like basic R functions not to call menu(), GUI... parts 
unless it's really the main task of that function.

Martin


   .............................
   .............................


From greg.kochanski at phonetics.oxford.ac.uk  Mon Jan 30 12:02:24 2006
From: greg.kochanski at phonetics.oxford.ac.uk (Greg Kochanski)
Date: Mon, 30 Jan 2006 11:02:24 +0000
Subject: [Rd] Mosaicplot coloring (PR#8537)
In-Reply-To: <Pine.LNX.4.58.0601300926120.2745@thorin.ci.tuwien.ac.at>
References: <20060129183011.D2682C777@slim.kubism.ku.dk>
	<Pine.LNX.4.58.0601300926120.2745@thorin.ci.tuwien.ac.at>
Message-ID: <43DDF240.8050901@phon.ox.ac.uk>



Achim Zeileis wrote:
> On Sun, 29 Jan 2006 greg.kochanski at phon.ox.ac.uk wrote:
> 
> 
>>Full_Name: Greg Kochanski
>>Version: 2.2.1
>>OS: Debian Linux (testing)
>>Submission from: (NULL) (212.159.16.190)
>>
>>
>>mosaicplot(x, shade=TRUE) is intended to color the blocks
>>blue if they are more common than one might expect
>>and red if they are rarer than one might expect.
>>
>>Unfortunately, if a block is much rarer than expected,
>>it is so narrow that one cannot see the red.
> 
> 
> Where is the bug?? Please read Section 9 in
>   http://CRAN.R-project.org/doc/manuals/R-FAQ.html
> and also the posting guide at
>   http://www.R-project.org/posting-guide.html
> 

The bug is that the software produces results that could
lead to the wrong conclusion in a research paper,
or could lead the readers of the research paper to
an erroneous belief.  That sounds like a
relevant definition of a bug to me.

 From section  9:
> Finally, a command's intended definition may not be best for
 > statistical analysis. This is a very important sort of problem,
 > but it is also a matter of judgment.
 > > ... The manual's job is to make everything clear.
 > It is just as important to report documentation bugs
 > as program bugs....

 From my reading of section 9, this is a documentation bug.

...
> For an enhanced implementation of mosaic plots written in the grid
> graphics system, see the package "vcd" and the functions mosaic() and
> strucplot(). See the package vignettes for details on control of the
> graphical appearance and also for combining shading and significance
> testing. To overcome the problem of small cells, another approach is to
> plot expected instead of observed frequencies.
> Z


You shouldn't be telling this to me,
you should be putting it in the documentation where
it might help more than one person.
Putting a "see also" note in help(mosaicplot) that points
to the "vcd" package, and "mosaic" and "strucplot" functions
might be a solution to the problem.


From Achim.Zeileis at wu-wien.ac.at  Mon Jan 30 12:26:37 2006
From: Achim.Zeileis at wu-wien.ac.at (Achim Zeileis)
Date: Mon, 30 Jan 2006 12:26:37 +0100 (CET)
Subject: [Rd] Mosaicplot coloring (PR#8537)
In-Reply-To: <43DDF240.8050901@phon.ox.ac.uk>
References: <20060129183011.D2682C777@slim.kubism.ku.dk>
	<Pine.LNX.4.58.0601300926120.2745@thorin.ci.tuwien.ac.at>
	<43DDF240.8050901@phon.ox.ac.uk>
Message-ID: <Pine.LNX.4.58.0601301212120.3488@thorin.ci.tuwien.ac.at>

On Mon, 30 Jan 2006, Greg Kochanski wrote:

> The bug is that the software produces results that could
> lead to the wrong conclusion in a research paper,
> or could lead the readers of the research paper to
> an erroneous belief.  That sounds like a
> relevant definition of a bug to me.

Maybe. However, it seems to be a bug in the way you interpret mosaic
displays, not in the way they are implemented/documented in R.

As I said before: This is a known issue with mosaic displays which is not
so hard to find out if you consult the references given in ?mosaiplot.

Another solution to your problem might be to use association plots
(assoplot() is referred to in ?mosaicplot, assoc() is again a more
flexible implementation in "vcd").

> > For an enhanced implementation of mosaic plots written in the grid
> > graphics system, see the package "vcd" and the functions mosaic() and
> > strucplot(). See the package vignettes for details on control of the
> > graphical appearance and also for combining shading and significance
> > testing. To overcome the problem of small cells, another approach is to
> > plot expected instead of observed frequencies.
>
> You shouldn't be telling this to me,

? If you don't want feedback, don't write to the lists.

> you should be putting it in the documentation where

Note that I'm neither the author of the mosaicplot() function nor
its manual page.

> it might help more than one person.
> Putting a "see also" note in help(mosaicplot) that points
> to the "vcd" package, and "mosaic" and "strucplot" functions
> might be a solution to the problem.

vcd is `only' a contributed package on CRAN, hence not referred to from
base packages.
Z


From greg.kochanski at phonetics.oxford.ac.uk  Mon Jan 30 13:53:30 2006
From: greg.kochanski at phonetics.oxford.ac.uk (Greg Kochanski)
Date: Mon, 30 Jan 2006 12:53:30 +0000
Subject: [Rd] Mosaicplot coloring (PR#8537)
In-Reply-To: <Pine.LNX.4.58.0601301212120.3488@thorin.ci.tuwien.ac.at>
References: <20060129183011.D2682C777@slim.kubism.ku.dk>
	<Pine.LNX.4.58.0601300926120.2745@thorin.ci.tuwien.ac.at>
	<43DDF240.8050901@phon.ox.ac.uk>
	<Pine.LNX.4.58.0601301212120.3488@thorin.ci.tuwien.ac.at>
Message-ID: <43DE0C4A.90101@phon.ox.ac.uk>



Achim Zeileis wrote:
> On Mon, 30 Jan 2006, Greg Kochanski wrote:
> 
> 
>>The bug is that the software produces results that could
>>lead to the wrong conclusion in a research paper,
>>or could lead the readers of the research paper to
>>an erroneous belief.  That sounds like a
>>relevant definition of a bug to me.
> 
> 
> Maybe. However, it seems to be a bug in the way you interpret mosaic
> displays, not in the way they are implemented/documented in R.

OK.  Call it that if you want, though I expect that I share
the bug with many other people.


> 
> As I said before: This is a known issue with mosaic displays which is not
> so hard to find out if you consult the references given in ?mosaiplot.

The problem I see is that you (as a representative for the r-project)
are the wrong person to judge the success or failure of the
documentation.    You presumably know the software in detail.
Documentation is (to at least some degree) intended for use by
people who _do_not_ know the software well.

Expecting a package's developer to judge documentation is
like asking a bald man to judge which comb is best.   He knows
what a comb is for, he may remember using one, but it's not
quite the same as actually needing and using one.



> 
> Another solution to your problem might be to use association plots
> (assoplot() is referred to in ?mosaicplot, assoc() is again a more
> flexible implementation in "vcd").

Thanks; that may help me; I appreciate the suggestion.
(I must point out, though, it doesn't help improve
mosaicplot().)


> 
> 
>>>For an enhanced implementation of mosaic plots...
>>You shouldn't be telling this to me,
>>you should be putting it in the documentation where
> 
> 
> Note that I'm neither the author of the mosaicplot() function nor
> its manual page.

Just out of curiosity,
why are you responding to bug reports that you don't
have the power to fix?


>>Putting a "see also" note in help(mosaicplot) that points
>>to the "vcd" package, ...
>>might be a solution to the problem.
> 
> vcd is `only' a contributed package on CRAN, hence not referred to from
> base packages.

But, if the contributed packages are better (as you seem to say)
than the base packages, perhaps they *should* be mentioned?


From Achim.Zeileis at wu-wien.ac.at  Mon Jan 30 14:33:22 2006
From: Achim.Zeileis at wu-wien.ac.at (Achim Zeileis)
Date: Mon, 30 Jan 2006 14:33:22 +0100
Subject: [Rd] Mosaicplot coloring (PR#8537)
In-Reply-To: <43DE0C4A.90101@phon.ox.ac.uk>
References: <20060129183011.D2682C777@slim.kubism.ku.dk>
	<Pine.LNX.4.58.0601300926120.2745@thorin.ci.tuwien.ac.at>
	<43DDF240.8050901@phon.ox.ac.uk>
	<Pine.LNX.4.58.0601301212120.3488@thorin.ci.tuwien.ac.at>
	<43DE0C4A.90101@phon.ox.ac.uk>
Message-ID: <20060130143322.3fd712c5.Achim.Zeileis@wu-wien.ac.at>

Greg:

> OK.  Call it that if you want, though I expect that I share
> the bug with many other people.

What I tried to say here was: Reports of user errors do not belong on
R-bugs. A request on R-help would have been more likely to generate a
useful, friendly and widely shared reply/discussion.

> The problem I see is that you (as a representative for the r-project)
> are the wrong person to judge the success or failure of the
> documentation.    You presumably know the software in detail.
> Documentation is (to at least some degree) intended for use by
> people who _do_not_ know the software well.

What I tried to say here was: The main problem is neither the software
nor the documentation, but the way you use it and interpret its results.
 
> Expecting a package's developer to judge documentation is
> like asking a bald man to judge which comb is best.  

I would never make recommendations about combs.

> > Note that I'm neither the author of the mosaicplot() function nor
> > its manual page.
> 
> Just out of curiosity,
> why are you responding to bug reports that you don't
> have the power to fix?

Because you did not report a bug. Furthermore, I thought I could
give you a helpful pointer to other solutions to your problem.

FYI: Meanwhile, R-core has signalled that they would add a cross
reference to vcd in this case. Hence, I'll suggest a documentation
patch to R-core.

Best regards,
Z


From andy_liaw at merck.com  Mon Jan 30 14:35:56 2006
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 30 Jan 2006 08:35:56 -0500
Subject: [Rd] Mosaicplot coloring (PR#8537)
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED785@usctmx1106.merck.com>

From: Greg Kochanski
> 
> Achim Zeileis wrote:
> > On Mon, 30 Jan 2006, Greg Kochanski wrote:
> > 
> > 
> >>The bug is that the software produces results that could
> >>lead to the wrong conclusion in a research paper,
> >>or could lead the readers of the research paper to
> >>an erroneous belief.  That sounds like a
> >>relevant definition of a bug to me.
> > 
> > 
> > Maybe. However, it seems to be a bug in the way you interpret mosaic
> > displays, not in the way they are implemented/documented in R.
> 
> OK.  Call it that if you want, though I expect that I share
> the bug with many other people.

Sorry for butting in...  I'm no expert in mosaic displays, and don't even
use them very often, but I think the problem you're referring as a bug in R
is more like a problem with the _method_ itself, (which will impact most, if
not all, implementation of mosaic displays, not just R's).  That's the
reason Achim points to the reference cited by the help page.  If that's the
case, I doubt it's fair to expect software documentation to point out all
possible (or known) problems with the methods it implements.  Instead, I'd
rather think that it's the user's responsibility to know what s/he is
getting into.

> > As I said before: This is a known issue with mosaic 
> displays which is not
> > so hard to find out if you consult the references given in 
> ?mosaiplot.
> 
> The problem I see is that you (as a representative for the r-project)
> are the wrong person to judge the success or failure of the
> documentation.    You presumably know the software in detail.
> Documentation is (to at least some degree) intended for use by
> people who _do_not_ know the software well.
> 
> Expecting a package's developer to judge documentation is
> like asking a bald man to judge which comb is best.   He knows
> what a comb is for, he may remember using one, but it's not
> quite the same as actually needing and using one.

R (and S) has the uncommon (if not unique) `feature' of turning users into
developers, so there's not a sharp distinction between users and developers.
Some of the package authors (including yours truly) really see themselves
more as users than developers, or at least that's how we started in this
wonderful environment.

Perhaps you do not understand why the documentations in base R do/can not
refer to contributed packages (as Achim stated).  There are several, but the
more obvious one is that contributed packages are not guanranteed to be
there:  Each package is required to have a maintainer, who is responsible
for making necessary updates to keep the package up-to-date with R versions.
A package not actively maintained is subject to removal from CRAN.  Can you
reasonably expect base R to cite contributed packages in such a setup?

Cheers,
Andy
 
> > Another solution to your problem might be to use association plots
> > (assoplot() is referred to in ?mosaicplot, assoc() is again a more
> > flexible implementation in "vcd").
> 
> Thanks; that may help me; I appreciate the suggestion.
> (I must point out, though, it doesn't help improve
> mosaicplot().)
> 
> 
> > 
> > 
> >>>For an enhanced implementation of mosaic plots...
> >>You shouldn't be telling this to me,
> >>you should be putting it in the documentation where
> > 
> > 
> > Note that I'm neither the author of the mosaicplot() function nor
> > its manual page.
> 
> Just out of curiosity,
> why are you responding to bug reports that you don't
> have the power to fix?
> 
> 
> >>Putting a "see also" note in help(mosaicplot) that points
> >>to the "vcd" package, ...
> >>might be a solution to the problem.
> > 
> > vcd is `only' a contributed package on CRAN, hence not 
> referred to from
> > base packages.
> 
> But, if the contributed packages are better (as you seem to say)
> than the base packages, perhaps they *should* be mentioned?
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
>


From greg.kochanski at phonetics.oxford.ac.uk  Mon Jan 30 14:43:47 2006
From: greg.kochanski at phonetics.oxford.ac.uk (Greg Kochanski)
Date: Mon, 30 Jan 2006 13:43:47 +0000
Subject: [Rd] --gui=Tk window does not stretch (PR#8520)
In-Reply-To: <x2psmieaj6.fsf@turmalin.kubism.ku.dk>
References: <20060123234012.2B3B0CD3F@slim.kubism.ku.dk>
	<x2psmieaj6.fsf@turmalin.kubism.ku.dk>
Message-ID: <43DE1813.6050400@phon.ox.ac.uk>



Peter Dalgaard wrote:

> 
> As you're bound to discover, the Tk console is mainly a
> proof-of-concept with shortcomings in many other areas as well. It's
> been largely undeveloped (as has the Gnome GUI) because we had very
> little feedback to indicate that people were actually interested in
> getting it to work better. Patches might be considered.

Does that mean "patches will be considered and accepted if they
meet reasonable criteria for simplicity and correctness."
or does it mean something less?


From ripley at stats.ox.ac.uk  Mon Jan 30 15:02:08 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 30 Jan 2006 14:02:08 +0000 (GMT)
Subject: [Rd] References to contributed packages (was Re: Mosaicplot
	coloring)
In-Reply-To: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED785@usctmx1106.merck.com>
References: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED785@usctmx1106.merck.com>
Message-ID: <Pine.LNX.4.61.0601301355040.11920@gannet.stats>

On Mon, 30 Jan 2006, Liaw, Andy wrote:

> Perhaps you do not understand why the documentations in base R do/can not
> refer to contributed packages (as Achim stated).  There are several, but the
> more obvious one is that contributed packages are not guanranteed to be
> there:  Each package is required to have a maintainer, who is responsible
> for making necessary updates to keep the package up-to-date with R versions.
> A package not actively maintained is subject to removal from CRAN.  Can you
> reasonably expect base R to cite contributed packages in such a setup?

As a general principle this is indeed so, but we do have some exceptions 
(look in the R Data Import/Export Manual for several), especially to the 
recommended packages.  Where there is enhanced methodology in a package 
and as a result there are no plans to enhance the main R version and the 
package is stable and has maintainers with a track record of being 
responsive, we do consider adding a cross-reference (and indeed a 
cross-ref from mosaicplot to vcd has been floated before).  And possibly 
under other circumstances too ....

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From greg.kochanski at phonetics.oxford.ac.uk  Mon Jan 30 15:21:59 2006
From: greg.kochanski at phonetics.oxford.ac.uk (Greg Kochanski)
Date: Mon, 30 Jan 2006 14:21:59 +0000
Subject: [Rd] Mosaicplot coloring (PR#8537)
In-Reply-To: <20060130143322.3fd712c5.Achim.Zeileis@wu-wien.ac.at>
References: <20060129183011.D2682C777@slim.kubism.ku.dk>	<Pine.LNX.4.58.0601300926120.2745@thorin.ci.tuwien.ac.at>	<43DDF240.8050901@phon.ox.ac.uk>	<Pine.LNX.4.58.0601301212120.3488@thorin.ci.tuwien.ac.at>	<43DE0C4A.90101@phon.ox.ac.uk>
	<20060130143322.3fd712c5.Achim.Zeileis@wu-wien.ac.at>
Message-ID: <43DE2107.4040607@phon.ox.ac.uk>



Achim Zeileis wrote:
> Greg:
> 
> 
>>OK.  Call it that if you want, though I expect that I share
>>the bug with many other people.
> 
> 
> What I tried to say here was: Reports of user errors do not belong on
> R-bugs. A request on R-help would have been more likely to generate a
> useful, friendly and widely shared reply/discussion.


And what I was trying to say is that any behaviour of a
program that makes user errors likely can reasonably
be considered a bug.    I'll grant you that an individual
user error is mere anecdotal evidence, but an individual's
report combined with a plausible argument that other people
will make the same mistake deserves some attention.

I would make an analogy to accident reports from aircraft accidents.
Most accidents are caused (at least in part) by user error,
and yet the reports recommend design changes to the
aircraft to minimize the probability of future errors.


> FYI: Meanwhile, R-core has signalled that they would add a cross
> reference to vcd in this case. Hence, I'll suggest a documentation
> patch to R-core.
> 

Thanks!


From murdoch at stats.uwo.ca  Mon Jan 30 15:58:23 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Mon, 30 Jan 2006 09:58:23 -0500
Subject: [Rd] [R] help with read.table() function
In-Reply-To: <17373.55673.169110.838093@stat.math.ethz.ch>
References: <20060129152620.65089.qmail@web33210.mail.mud.yahoo.com>	<43DCE4A4.4090703@free.fr>	<x2d5ibf04m.fsf@turmalin.kubism.ku.dk>	<43DCF8D0.8060105@stats.uwo.ca>	<1138557345.5518.249.camel@localhost.localdomain>	<Pine.LNX.4.61.0601291802280.25185@gannet.stats>	<43DD3536.1060004@stats.uwo.ca>
	<17373.55673.169110.838093@stat.math.ethz.ch>
Message-ID: <43DE298F.8040001@stats.uwo.ca>

On 1/30/2006 4:16 AM, Martin Maechler wrote:
>>>>>> "Duncan" == Duncan Murdoch <murdoch at stats.uwo.ca>
>>>>>>     on Sun, 29 Jan 2006 16:35:50 -0500 writes:
> 
>     Duncan> On 1/29/2006 1:29 PM, Prof Brian Ripley wrote:
>     >> On Sun, 29 Jan 2006, Marc Schwartz wrote:
>     >> 
>     >>> I would argue against this.
>     >>> 
>     >>> If this were the default, that is requiring user
>     >>> interaction, it would break a fair amount of code that I
>     >>> (and I am sure a lot of others have) where automation is
>     >>> critical.
> 
>     >>  I don't see how.  The current default is
>     >> 
>     >>> read.table()
>     >> Error in read.table() : argument "file" is missing, with
>     >> no default
>     >> 
>     >> so the only change is that the default might do something
>     >> useful.
>     >> 
>     >> Nor do I see the change would help, as the same people
>     >> would still use a character string for 'file' and not
>     >> omit the argument.  (It seems very unlikely that they
>     >> would read any documentation that suggested things had
>     >> changed.)
> 
>     Duncan> No, but people teaching new users (or answering
>     Duncan> R-help questions) would have a simpler answer: just
>     Duncan> use read.table().
> 
> but I am not sure that people teaching R should advocate such a 
> read.table;  
> I they did, the new R users would get the concept that this is
> the way how to use R.

I'd say "a way to use R", and I think teachers *should* present such a 
use.  It insulates users from uninteresting details, just as now it's 
probably good to advocate using file.choose() rather than explaining 
paths and escape characters before beginners can do anything with data.
Later on they'll need to learn those things, but not from the beginning.

> I still think R should eventually be used for "Programming with Data"
> rather than a GUI for ``clicking results together''.
> Hence users should be taught (in the 2nd or 3rd part, not the
> 1st one of their introduction to R)
> to work with R scripts, writing functions etc.

Right, I agree here too.  This would soften the shock of the 1st 
introduction, but as soon as the students are ready to look at functions 
and understand default parameters, they'd be able to see that the 
default value for the "file" argument is file.choose().   They might 
become curious about it and call it by itself and discover that it is 
possible to program GUI elements (assuming that file.choose() calls one).

> And similar to Marc, I would never want default behavior to
> start up a GUI elements: It is also much more error-prone; just
> consider the  "choose CRAN mirror" GUI that we had recently
> introduced, and the many questions and "bug" reports it produced.
> 
> I know that I am biased in my views here;
> but I strongly advocate the  "useRs becoming programmeRs" theme
> and hence rather keep R consistent as a programming language,
> partly agreeing with Gabor here.

I think I disagree with you because I think GUI programming is 
programming.  I don't want beginners to think that there are two kinds 
of programs:  command-line programs that they can write, and GUI 
programs that only Microsoft can write.  I want them to think that 
programming is programming.  Doing complex things is harder than doing 
easy things, but it's not qualitatively different.

Duncan Murdoch

>     >> The same issue could be made over scan(), where the
>     >> current default is useful.
> 
>     Duncan> scan() is very useful for small reads, and rarely
>     Duncan> needed for reading big formatted files, 
> 
> {people might disagree with this; given scan() is more efficient
>  for large files;  but that's not really the topic here.}
> 
>     Duncan> so I wouldn't propose to change it.  
> good.
> 
>     Duncan> The inconsistency
>     Duncan> with read.table would be unfortunate, but no worse
>     Duncan> than the current one.
> 
> 
>     >>> A lot of the issues seem to be user errors, file
>     >>> permission errors, hidden extensions as is pointed out
>     >>> below and related issues. If there is a legitimate bug
>     >>> in R resulting in these issues, then let's patch
>     >>> that. However, I don't think that I can recall
>     >>> reproducible situations where a bug in R is the root
>     >>> cause of these problems.
> 
>     >>  Nor I.
>     >> 
>     >> Note that file.choose does not protect you against file
>     >> permission issues (actually, on a command-line Unix-alike
>     >> it does nothing much useful at all):
>     >> 
>     >>> readLines(file.choose())
>     >> Enter file name: errs.txt
> 
>     Duncan> No, it's not helpful here, but again it makes things
>     Duncan> no worse, and there's always the possibility that
>     Duncan> someone would improve file.choose().
> 
> I strongly prefer the current usage
> 
>   read.table(file.choose(), ....)
> 
> which implicitly ``explains'' how the file name is chosen to a
> new default
>   read.table( .....)
> 
> I'd like basic R functions not to call menu(), GUI... parts 
> unless it's really the main task of that function.


From maechler at stat.math.ethz.ch  Mon Jan 30 16:38:54 2006
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 30 Jan 2006 16:38:54 +0100
Subject: [Rd] [R] help with read.table() function
In-Reply-To: <43DE298F.8040001@stats.uwo.ca>
References: <20060129152620.65089.qmail@web33210.mail.mud.yahoo.com>
	<43DCE4A4.4090703@free.fr> <x2d5ibf04m.fsf@turmalin.kubism.ku.dk>
	<43DCF8D0.8060105@stats.uwo.ca>
	<1138557345.5518.249.camel@localhost.localdomain>
	<Pine.LNX.4.61.0601291802280.25185@gannet.stats>
	<43DD3536.1060004@stats.uwo.ca>
	<17373.55673.169110.838093@stat.math.ethz.ch>
	<43DE298F.8040001@stats.uwo.ca>
Message-ID: <17374.13070.709724.132455@stat.math.ethz.ch>

>>>>> "Duncan" == Duncan Murdoch <murdoch at stats.uwo.ca>
>>>>>     on Mon, 30 Jan 2006 09:58:23 -0500 writes:

    Duncan> On 1/30/2006 4:16 AM, Martin Maechler wrote:
    >>>>>>> "Duncan" == Duncan Murdoch <murdoch at stats.uwo.ca> on
    >>>>>>> Sun, 29 Jan 2006 16:35:50 -0500 writes:
    >>
    Duncan> On 1/29/2006 1:29 PM, Prof Brian Ripley wrote:
    >> >> On Sun, 29 Jan 2006, Marc Schwartz wrote:
    >> >> 
    >> >>> I would argue against this.
    >> >>> 
    >> >>> If this were the default, that is requiring user >>>
    >> interaction, it would break a fair amount of code that I
    >> >>> (and I am sure a lot of others have) where automation
    >> is >>> critical.
    >> 
    >> >> I don't see how.  The current default is
    >> >> 
    >> >>> read.table() >> Error in read.table() : argument
    >> "file" is missing, with >> no default
    >> >> 
    >> >> so the only change is that the default might do
    >> something >> useful.
    >> >> 
    >> >> Nor do I see the change would help, as the same people
    >> >> would still use a character string for 'file' and not
    >> >> omit the argument.  (It seems very unlikely that they
    >> >> would read any documentation that suggested things had
    >> >> changed.)
    >> 
    Duncan> No, but people teaching new users (or answering
    Duncan> R-help questions) would have a simpler answer: just
    Duncan> use read.table().
    >>  but I am not sure that people teaching R should advocate
    >> such a read.table; I they did, the new R users would get
    >> the concept that this is the way how to use R.

    Duncan> I'd say "a way to use R", and I think teachers
    Duncan> *should* present such a use.  It insulates users
    Duncan> from uninteresting details, just as now it's
    Duncan> probably good to advocate using file.choose() rather
    Duncan> than explaining paths and escape characters before
    Duncan> beginners can do anything with data.  Later on
    Duncan> they'll need to learn those things, but not from the
    Duncan> beginning.

    >> I still think R should eventually be used for
    >> "Programming with Data" rather than a GUI for ``clicking
    >> results together''.  Hence users should be taught (in the
    >> 2nd or 3rd part, not the 1st one of their introduction to
    >> R) to work with R scripts, writing functions etc.

    Duncan> Right, I agree here too.  This would soften the
    Duncan> shock of the 1st introduction, but as soon as the
    Duncan> students are ready to look at functions and
    Duncan> understand default parameters, they'd be able to see
    Duncan> that the default value for the "file" argument is
    Duncan> file.choose().  They might become curious about it
    Duncan> and call it by itself and discover that it is
    Duncan> possible to program GUI elements (assuming that
    Duncan> file.choose() calls one).

    >> And similar to Marc, I would never want default behavior
    >> to start up a GUI elements: It is also much more
    >> error-prone; just consider the "choose CRAN mirror" GUI
    >> that we had recently introduced, and the many questions
    >> and "bug" reports it produced.
    >> 
    >> I know that I am biased in my views here; but I strongly
    >> advocate the "useRs becoming programmeRs" theme and hence
    >> rather keep R consistent as a programming language,
    >> partly agreeing with Gabor here.

    Duncan> I think I disagree with you because I think GUI
    Duncan> programming is programming.  I don't want beginners
    Duncan> to think that there are two kinds of programs:
    Duncan> command-line programs that they can write, and GUI
    Duncan> programs that only Microsoft can write.  I want them
    Duncan> to think that programming is programming.  Doing
    Duncan> complex things is harder than doing easy things, but
    Duncan> it's not qualitatively different.

Actually, I completely agree with what you said here.

However we disagree to some extent about the implications
(on teaching R, learning R, ..) of making GUI elements defaults
for basic R functions.  
Also the phrase  "consistent as a programming language"  was
about the fact that for some functions, the default file(name) would be
GUI-dispatching whereas for other functions it would not (and
you agreed it should not).

Martin

    Duncan> Duncan Murdoch

    >> >> The same issue could be made over scan(), where the >>
    >> current default is useful.
    >> 
    Duncan> scan() is very useful for small reads, and rarely
    Duncan> needed for reading big formatted files,
    >>  {people might disagree with this; given scan() is more
    >> efficient for large files; but that's not really the
    >> topic here.}
    >> 
    Duncan> so I wouldn't propose to change it.
    >> good.
    >> 
    Duncan> The inconsistency with read.table would be
    Duncan> unfortunate, but no worse than the current one.
    >> 
    >> 
    >> >>> A lot of the issues seem to be user errors, file >>>
    >> permission errors, hidden extensions as is pointed out
    >> >>> below and related issues. If there is a legitimate
    >> bug >>> in R resulting in these issues, then let's patch
    >> >>> that. However, I don't think that I can recall >>>
    >> reproducible situations where a bug in R is the root >>>
    >> cause of these problems.
    >> 
    >> >> Nor I.
    >> >> 
    >> >> Note that file.choose does not protect you against
    >> file >> permission issues (actually, on a command-line
    >> Unix-alike >> it does nothing much useful at all):
    >> >> 
    >> >>> readLines(file.choose()) >> Enter file name: errs.txt
    >> 
    Duncan> No, it's not helpful here, but again it makes things
    Duncan> no worse, and there's always the possibility that
    Duncan> someone would improve file.choose().
    >>  I strongly prefer the current usage
    >> 
    >> read.table(file.choose(), ....)
    >> 
    >> which implicitly ``explains'' how the file name is chosen
    >> to a new default read.table( .....)
    >> 
    >> I'd like basic R functions not to call menu(),
    >> GUI... parts unless it's really the main task of that
    >> function.


From matthias.burger at epigenomics.com  Mon Jan 30 16:59:18 2006
From: matthias.burger at epigenomics.com (Matthias Burger)
Date: 30 Jan 2006 16:59:18 +0100
Subject: [Rd] unexported symbols in libR.so of r-devel
In-Reply-To: <Pine.LNX.4.61.0601241818470.24056@gannet.stats>
References: <gj4q3ttumx.fsf@bass.biostat.umn.edu>
	<Pine.LNX.4.61.0601241818470.24056@gannet.stats>
Message-ID: <43DE37D6.8060408@epigenomics.com>


sorry for the late reply. I now had time to check again using
R devel  (2006-01-26 r37181)
and succeeded in loading package rpvm.

Thanks for your support.

Regards,

  Matthias


Prof Brian Ripley wrote:
> On Tue, 24 Jan 2006, Na Li wrote:
> 
>>
>> Thanks to Matthias Burger, I came to know that in r-devel, a lot of
>> symbols
>> are no longer exported in libR.so, which breaks the package rpvm since it
>> calls these functions in serialize.c.
> 
> 
> They are hidden.  Since they are in Rinternals.h, this was unintentional,
> although they are not part of R's declared API and so are at risk (see
> Writing R Extensions).
> 
> Just remove 'attribute_hidden' (which I have done in the sources)
> 
>> R_InitInPStream
>> R_InitOutPStream
>>
>> Since the change is fairly recent (earlier this month), I guess the
>> core team
>> will be making further changes.  In any case, please add these two to the
>> exported list.
> 
> 
> No more changes are planned.
> 
>> Thanks,
>>
>> Michael
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
> 

-- 
Matthias Burger                     Project Manager/ Biostatistician
Epigenomics AG    Kleine Praesidentenstr. 1    10178 Berlin, Germany
phone:+49-30-24345-371                          fax:+49-30-24345-555
http://www.epigenomics.com           matthias.burger at epigenomics.com


From David.Brahm at geodecapital.com  Mon Jan 30 18:39:05 2006
From: David.Brahm at geodecapital.com (David.Brahm@geodecapital.com)
Date: Mon, 30 Jan 2006 18:39:05 +0100 (CET)
Subject: [Rd] colnames(tapply(...)) (PR#8539)
Message-ID: <20060130173905.BD37F3EEAA@slim.kubism.ku.dk>

Wasn't there once a time when tapply(f,f,sum) (with "f" a vector)
returned a vector instead of a 1D array?  Then colnames(x) would just
give NULL instead of an error.  Sorry my memory isn't more precise.

-- David Brahm (brahm at alum.mit.edu)=20


-----Original Message-----
From: r-devel-bounces at r-project.org
[mailto:r-devel-bounces at r-project.org] On Behalf Of Prof Brian Ripley
Sent: Monday, January 30, 2006 3:45 AM
To: karl.thomaseth at isib.cnr.it
Cc: R-bugs at biostat.ku.dk; r-devel at stat.math.ethz.ch
Subject: Re: [Rd] colnames(tapply(...)) (PR#8539)


On Mon, 30 Jan 2006 karl.thomaseth at isib.cnr.it wrote:

> I would like to bring to your attention the following error message
> which didn't appear on previous versions (long time ago?)
>
> Thanks for all your effort
>
> Karl
>
> Version 2.2.1 Patched (2006-01-21 r37153)
>
> > f <- rep(c(1,2),each=3D5)
> > x <- tapply(f,f,sum)
> > colnames(x)
> Error in dn[[2]] : subscript out of bounds

What is inappropriate about this?  x is a 1D array, so it does not have
column names (or columns).  Indeed, the help page says

        x: a matrix-like R object, with at least two dimensions for
           'colnames'.

The exact same message appears in 1.6.2, more than three years old (and=20
the earliest version I still have running). If earlier versions did not=20
have an error message, that was probably a bug.

--=20
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

______________________________________________
R-devel at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-devel


From francoisromain at free.fr  Mon Jan 30 19:06:39 2006
From: francoisromain at free.fr (Romain Francois)
Date: Mon, 30 Jan 2006 19:06:39 +0100
Subject: [Rd]  What about a bib file
Message-ID: <43DE55AF.9050108@free.fr>

Hi,

Doing the following command on the freshest R-devel i get 223 entries :

$ grep  "The New S Language" */man/*.Rd | wc -l

Would it make sense to add a bib file (or another format) such that one 
could do something like :

\cite{blueBook}

or even :

\cite[base]{blueBook}

What do you think ?

Romain

-- 
visit the R Graph Gallery : http://addictedtor.free.fr/graphiques
mixmod 1.7 is released : http://www-math.univ-fcomte.fr/mixmod/index.php
+---------------------------------------------------------------+
| Romain FRANCOIS - http://francoisromain.free.fr               |
| Doctorant INRIA Futurs / EDF                                  |
+---------------------------------------------------------------+


From maechler at stat.math.ethz.ch  Mon Jan 30 19:06:27 2006
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 30 Jan 2006 19:06:27 +0100
Subject: [Rd] colnames(tapply(...)) (PR#8539)
In-Reply-To: <20060130173905.BD37F3EEAA@slim.kubism.ku.dk>
References: <20060130173905.BD37F3EEAA@slim.kubism.ku.dk>
Message-ID: <17374.21923.129387.459683@stat.math.ethz.ch>

>>>>> "DavidB" == David Brahm <David.Brahm at geodecapital.com>
>>>>>     on Mon, 30 Jan 2006 18:39:05 +0100 (CET) writes:

    DavidB> Wasn't there once a time when tapply(f,f,sum) (with "f" a vector)
    DavidB> returned a vector instead of a 1D array?  Then colnames(x) would just
    DavidB> give NULL instead of an error.  Sorry my memory isn't more precise.

well, it was very good...

R-0.16  had this 
R-0.63.3 (March 3, 1999)  already didn't anymore, i.e. it
already did return a 1D-array.

So, indeed Karl must have used a *very* old version of R.
Martin Maechler, ETH Zurich

    DavidB> -- David Brahm (brahm at alum.mit.edu)=20


    DavidB> -----Original Message-----
    DavidB> From: r-devel-bounces at r-project.org
    DavidB> [mailto:r-devel-bounces at r-project.org] On Behalf Of Prof Brian Ripley
    DavidB> Sent: Monday, January 30, 2006 3:45 AM
    DavidB> To: karl.thomaseth at isib.cnr.it
    DavidB> Cc: R-bugs at biostat.ku.dk; r-devel at stat.math.ethz.ch
    DavidB> Subject: Re: [Rd] colnames(tapply(...)) (PR#8539)


    DavidB> On Mon, 30 Jan 2006 karl.thomaseth at isib.cnr.it wrote:

    >> I would like to bring to your attention the following error message
    >> which didn't appear on previous versions (long time ago?)
    >> 
    >> Thanks for all your effort
    >> 
    >> Karl
    >> 
    >> Version 2.2.1 Patched (2006-01-21 r37153)
    >> 
    >> > f <- rep(c(1,2),each=3D5)
    >> > x <- tapply(f,f,sum)
    >> > colnames(x)
    >> Error in dn[[2]] : subscript out of bounds

    DavidB> What is inappropriate about this?  x is a 1D array, so it does not have
    DavidB> column names (or columns).  Indeed, the help page says

    DavidB> x: a matrix-like R object, with at least two dimensions for
    DavidB> 'colnames'.

    DavidB> The exact same message appears in 1.6.2, more than three years old (and=20
    DavidB> the earliest version I still have running). If earlier versions did not=20
    DavidB> have an error message, that was probably a bug.

    DavidB> --=20
    DavidB> Brian D. Ripley,                  ripley at stats.ox.ac.uk
    DavidB> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
    DavidB> University of Oxford,             Tel:  +44 1865 272861 (self)
    DavidB> 1 South Parks Road,                     +44 1865 272866 (PA)
    DavidB> Oxford OX1 3TG, UK                Fax:  +44 1865 272595

    DavidB> ______________________________________________
    DavidB> R-devel at r-project.org mailing list
    DavidB> https://stat.ethz.ch/mailman/listinfo/r-devel

    DavidB> ______________________________________________
    DavidB> R-devel at r-project.org mailing list
    DavidB> https://stat.ethz.ch/mailman/listinfo/r-devel


From murdoch at stats.uwo.ca  Mon Jan 30 19:50:16 2006
From: murdoch at stats.uwo.ca (murdoch@stats.uwo.ca)
Date: Mon, 30 Jan 2006 19:50:16 +0100 (CET)
Subject: [Rd] [R] Integer bit size and the modulus operator (PR#8541)
Message-ID: <20060130185016.81BD13EEAA@slim.kubism.ku.dk>

On 1/30/2006 1:39 PM, Ionut Florescu wrote:
> Thank you for the quick reply, I will look into the R packages.
> For crashing R try this:
> 
> generator.zp=function(x,p)
> {a=1:(p-1); b=x^a%%p;
> if(all(b[1:(p-2)]!=1)&&(b[p-1]==1)){return(x, " Good ")}
> else{return(x, " No Good, try another integer ")}
> }

Thanks, I can reproduce the crash using

for (x in 10:100) generator.zp(x, 41)

I'll see if I can track down what's going wrong.  By the way, you're not 
supposed to use two arguments to return():  that's not supposed to be 
allowed any more.  I'm somewhat surprised you don't get an error from 
it.  But that's not the cause of the crash.

Duncan Murdoch


> 
> This checks if element x is a generator of the group Z_p. If you try 
> this function for p = 41 and x various increasing values eventually it 
> will crash R. That is what I meant by random, at first I started x=2,3 
> so on, when I got to 8, R crashed. Now apparently I can get to 15. When 
> I tried again I got to 20.
> 
> Ionut Florescu
> 
> 
> Duncan Murdoch wrote:
>> On 1/30/2006 11:32 AM, Ionut Florescu wrote:
>>> I am a statistician and I come up to an interesting problem in 
>>> cryptography. I would like to use R since there are some statistical 
>>> procedures that I need to use.
>>> However, I run into a problem when using the modulus operator %%.
>>>
>>> I am using R 2.2.1 and when I calculate modulus for large numbers 
>>> (that I need with my problem) R gives me warnings. For instance if 
>>> one does:
>>> a=1:40;
>>> 8^a %% 41
>>> one obtains zeros which is not possible since 8 to any power is not a 
>>> multiple of 41.
>>> In addition when working with numbers larger that this and with the 
>>> mod operator R crashes randomly.
>>
>> Could you keep a record of the random crashes, and see if you can make 
>> any of them repeatable?  R shouldn't crash.  If you can find a 
>> repeatable way to make it crash, then that's a bug that needs to be 
>> fixed.  (If it crashes at random it should still be fixed, but it's so 
>> much harder to fix that it's unlikely to happen unless the cases are 
>> ones that look likely to come up in normal situations.)
>>
>>
>>>
>>> I believe this is because R stores large integers as real numbers 
>>> thus there may be lack of accuracy when applying the modulus operator 
>>> and converting back to integers.
>>>
>>> So my question is this: Is it possible to increase the size of memory 
>>> used for storing integers? Say from 32 bits to 512 bits (Typical size 
>>> of integers in cryptography).
>>
>> No, but there is at least one contributed package that does multiple 
>> precision integer arithmetic.  I can't remember the name of it right 
>> now, but Google should be able to find it for you...
>>
>> Duncan Murdoch
>>>
>>> Thank you, any help would be greatly appreciated.
>>> Ionut Florescu
>>>
>>> ______________________________________________
>>> R-help at stat.math.ethz.ch mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide! 
>>> http://www.R-project.org/posting-guide.html
>>
>>


From ripley at stats.ox.ac.uk  Mon Jan 30 20:26:47 2006
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Mon, 30 Jan 2006 20:26:47 +0100 (CET)
Subject: [Rd] [R] Integer bit size and the modulus operator (PR#8541)
Message-ID: <20060130192647.B21E23EFF3@slim.kubism.ku.dk>

On Mon, 30 Jan 2006 murdoch at stats.uwo.ca wrote:

> On 1/30/2006 1:39 PM, Ionut Florescu wrote:
>> Thank you for the quick reply, I will look into the R packages.
>> For crashing R try this:
>>
>> generator.zp=function(x,p)
>> {a=1:(p-1); b=x^a%%p;
>> if(all(b[1:(p-2)]!=1)&&(b[p-1]==1)){return(x, " Good ")}
>> else{return(x, " No Good, try another integer ")}
>> }
>
> Thanks, I can reproduce the crash using
>
> for (x in 10:100) generator.zp(x, 41)
>
> I'll see if I can track down what's going wrong.  By the way, you're not
> supposed to use two arguments to return():  that's not supposed to be
> allowed any more.  I'm somewhat surprised you don't get an error from
> it.  But that's not the cause of the crash.

You do get a warning, though.  It *is* allowed, see ?return.

One error is the following in real_binary:

     if (n1 > n2)
 	copyMostAttrib(s1, ans);
     else if (n1 == n2) {
 	copyMostAttrib(s2, ans);
 	copyMostAttrib(s1, ans);
     }
     else
 	copyMostAttrib(s2, ans);

Here ans is not PROTECTED.

The second is in the warning, which causes allocation when ans is not 
protected.

Fixed in R-devel and 2.2.1 patched.


> Duncan Murdoch
>
>
>>
>> This checks if element x is a generator of the group Z_p. If you try
>> this function for p = 41 and x various increasing values eventually it
>> will crash R. That is what I meant by random, at first I started x=2,3
>> so on, when I got to 8, R crashed. Now apparently I can get to 15. When
>> I tried again I got to 20.
>>
>> Ionut Florescu
>>
>>
>> Duncan Murdoch wrote:
>>> On 1/30/2006 11:32 AM, Ionut Florescu wrote:
>>>> I am a statistician and I come up to an interesting problem in
>>>> cryptography. I would like to use R since there are some statistical
>>>> procedures that I need to use.
>>>> However, I run into a problem when using the modulus operator %%.
>>>>
>>>> I am using R 2.2.1 and when I calculate modulus for large numbers
>>>> (that I need with my problem) R gives me warnings. For instance if
>>>> one does:
>>>> a=1:40;
>>>> 8^a %% 41
>>>> one obtains zeros which is not possible since 8 to any power is not a
>>>> multiple of 41.
>>>> In addition when working with numbers larger that this and with the
>>>> mod operator R crashes randomly.
>>>
>>> Could you keep a record of the random crashes, and see if you can make
>>> any of them repeatable?  R shouldn't crash.  If you can find a
>>> repeatable way to make it crash, then that's a bug that needs to be
>>> fixed.  (If it crashes at random it should still be fixed, but it's so
>>> much harder to fix that it's unlikely to happen unless the cases are
>>> ones that look likely to come up in normal situations.)
>>>
>>>
>>>>
>>>> I believe this is because R stores large integers as real numbers
>>>> thus there may be lack of accuracy when applying the modulus operator
>>>> and converting back to integers.
>>>>
>>>> So my question is this: Is it possible to increase the size of memory
>>>> used for storing integers? Say from 32 bits to 512 bits (Typical size
>>>> of integers in cryptography).
>>>
>>> No, but there is at least one contributed package that does multiple
>>> precision integer arithmetic.  I can't remember the name of it right
>>> now, but Google should be able to find it for you...
>>>
>>> Duncan Murdoch
>>>>
>>>> Thank you, any help would be greatly appreciated.
>>>> Ionut Florescu
>>>>
>>>> ______________________________________________
>>>> R-help at stat.math.ethz.ch mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide!
>>>> http://www.R-project.org/posting-guide.html
>>>
>>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Mon Jan 30 20:40:30 2006
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Mon, 30 Jan 2006 20:40:30 +0100 (CET)
Subject: [Rd] [R] Integer bit size and the modulus operator (PR#8541)
Message-ID: <20060130194030.1794B3EFF5@slim.kubism.ku.dk>

On Mon, 30 Jan 2006, Prof Brian Ripley wrote:

> On Mon, 30 Jan 2006 murdoch at stats.uwo.ca wrote:
>
>> On 1/30/2006 1:39 PM, Ionut Florescu wrote:
>>> Thank you for the quick reply, I will look into the R packages.
>>> For crashing R try this:
>>> 
>>> generator.zp=function(x,p)
>>> {a=1:(p-1); b=x^a%%p;
>>> if(all(b[1:(p-2)]!=1)&&(b[p-1]==1)){return(x, " Good ")}
>>> else{return(x, " No Good, try another integer ")}
>>> }
>> 
>> Thanks, I can reproduce the crash using
>> 
>> for (x in 10:100) generator.zp(x, 41)
>> 
>> I'll see if I can track down what's going wrong.  By the way, you're not
>> supposed to use two arguments to return():  that's not supposed to be
>> allowed any more.  I'm somewhat surprised you don't get an error from
>> it.  But that's not the cause of the crash.
>
> You do get a warning, though.  It *is* allowed, see ?return.
>
> One error is the following in real_binary:
>
>    if (n1 > n2)
> 	copyMostAttrib(s1, ans);
>    else if (n1 == n2) {
> 	copyMostAttrib(s2, ans);
> 	copyMostAttrib(s1, ans);
>    }
>    else
> 	copyMostAttrib(s2, ans);
>
> Here ans is not PROTECTED.

I think this one was a consequence of the other one.  I did get a valgrind 
error from there, but it looks as if copyMostAttrib does the necessary 
protection, if ans has not already been damaged.

> The second is in the warning, which causes allocation when ans is not 
> protected.
>
> Fixed in R-devel and 2.2.1 patched.
>
>
>> Duncan Murdoch
>> 
>> 
>>> 
>>> This checks if element x is a generator of the group Z_p. If you try
>>> this function for p = 41 and x various increasing values eventually it
>>> will crash R. That is what I meant by random, at first I started x=2,3
>>> so on, when I got to 8, R crashed. Now apparently I can get to 15. When
>>> I tried again I got to 20.
>>> 
>>> Ionut Florescu
>>> 
>>> 
>>> Duncan Murdoch wrote:
>>>> On 1/30/2006 11:32 AM, Ionut Florescu wrote:
>>>>> I am a statistician and I come up to an interesting problem in
>>>>> cryptography. I would like to use R since there are some statistical
>>>>> procedures that I need to use.
>>>>> However, I run into a problem when using the modulus operator %%.
>>>>> 
>>>>> I am using R 2.2.1 and when I calculate modulus for large numbers
>>>>> (that I need with my problem) R gives me warnings. For instance if
>>>>> one does:
>>>>> a=1:40;
>>>>> 8^a %% 41
>>>>> one obtains zeros which is not possible since 8 to any power is not a
>>>>> multiple of 41.
>>>>> In addition when working with numbers larger that this and with the
>>>>> mod operator R crashes randomly.
>>>> 
>>>> Could you keep a record of the random crashes, and see if you can make
>>>> any of them repeatable?  R shouldn't crash.  If you can find a
>>>> repeatable way to make it crash, then that's a bug that needs to be
>>>> fixed.  (If it crashes at random it should still be fixed, but it's so
>>>> much harder to fix that it's unlikely to happen unless the cases are
>>>> ones that look likely to come up in normal situations.)
>>>> 
>>>> 
>>>>> 
>>>>> I believe this is because R stores large integers as real numbers
>>>>> thus there may be lack of accuracy when applying the modulus operator
>>>>> and converting back to integers.
>>>>> 
>>>>> So my question is this: Is it possible to increase the size of memory
>>>>> used for storing integers? Say from 32 bits to 512 bits (Typical size
>>>>> of integers in cryptography).
>>>> 
>>>> No, but there is at least one contributed package that does multiple
>>>> precision integer arithmetic.  I can't remember the name of it right
>>>> now, but Google should be able to find it for you...
>>>> 
>>>> Duncan Murdoch
>>>>> 
>>>>> Thank you, any help would be greatly appreciated.
>>>>> Ionut Florescu
>>>>> 
>>>>> ______________________________________________
>>>>> R-help at stat.math.ethz.ch mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide!
>>>>> http://www.R-project.org/posting-guide.html
>>>> 
>>>> 
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> 
>> 
>
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From bolker at zoo.ufl.edu  Mon Jan 30 21:25:01 2006
From: bolker at zoo.ufl.edu (Ben Bolker)
Date: Mon, 30 Jan 2006 15:25:01 -0500
Subject: [Rd] R on the brain
Message-ID: <43DE761D.50704@zoo.ufl.edu>


   I was sitting in the coffee room at work listening to people complain
about a recent seminar about nanotechnology using the terms 
nanofluidics, nanofactory, nano-this, and nano-that ... I found myself 
thinking "well the speaker should just
have said
   with(nano,
      ...)

   Un(?)fortunately there's no-one here I can share that thought with.

-- 
620B Bartram Hall                            bolker at zoo.ufl.edu
Zoology Department, University of Florida    http://www.zoo.ufl.edu/bolker
Box 118525                                   (ph)  352-392-5697
Gainesville, FL 32611-8525                   (fax) 352-392-3704


From rpeng at jhsph.edu  Mon Jan 30 21:35:03 2006
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Mon, 30 Jan 2006 15:35:03 -0500
Subject: [Rd] R on the brain
In-Reply-To: <43DE761D.50704@zoo.ufl.edu>
References: <43DE761D.50704@zoo.ufl.edu>
Message-ID: <43DE7877.1080707@jhsph.edu>

Well shared! :)  Maybe better yet,

"Before I begin this talk, I'd like to 'attach("nano")'".

-roger

Ben Bolker wrote:
>    I was sitting in the coffee room at work listening to people complain
> about a recent seminar about nanotechnology using the terms 
> nanofluidics, nanofactory, nano-this, and nano-that ... I found myself 
> thinking "well the speaker should just
> have said
>    with(nano,
>       ...)
> 
>    Un(?)fortunately there's no-one here I can share that thought with.
> 

-- 
Roger D. Peng  |  http://www.biostat.jhsph.edu/~rpeng/


From Ted.Harding at nessie.mcc.ac.uk  Mon Jan 30 21:49:46 2006
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Mon, 30 Jan 2006 20:49:46 -0000 (GMT)
Subject: [Rd] R on the brain
In-Reply-To: <43DE7877.1080707@jhsph.edu>
Message-ID: <XFMail.060130204946.Ted.Harding@nessie.mcc.ac.uk>

On 30-Jan-06 Roger D. Peng wrote:
> Well shared! :)  Maybe better yet,
> 
> "Before I begin this talk, I'd like to 'attach("nano")'".
> 
> -roger

And, at the end of the talk:

   "Save workspace image? [y/n/c]: "

Ted.

> Ben Bolker wrote:
>>    I was sitting in the coffee room at work listening to people
>>    complain
>> about a recent seminar about nanotechnology using the terms 
>> nanofluidics, nanofactory, nano-this, and nano-that ... I found myself
>> thinking "well the speaker should just
>> have said
>>    with(nano,
>>       ...)
>> 
>>    Un(?)fortunately there's no-one here I can share that thought with.
>> 
> 
> -- 
> Roger D. Peng  |  http://www.biostat.jhsph.edu/~rpeng/
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 30-Jan-06                                       Time: 20:49:43
------------------------------ XFMail ------------------------------


From andy_liaw at merck.com  Mon Jan 30 22:24:40 2006
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 30 Jan 2006 16:24:40 -0500
Subject: [Rd] R on the brain
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED78C@usctmx1106.merck.com>

From: Ted.Harding at nessie.mcc.ac.uk
> 
> On 30-Jan-06 Roger D. Peng wrote:
> > Well shared! :)  Maybe better yet,
> > 
> > "Before I begin this talk, I'd like to 'attach("nano")'".
> > 
> > -roger
> 
> And, at the end of the talk:
> 
>    "Save workspace image? [y/n/c]: "

Nah!  Always use q("no") or start R with --no-save.  Source is master!

I suppose one can use sessionInfo() as the wrap-up summary...

Andy
 
> Ted.
> 
> > Ben Bolker wrote:
> >>    I was sitting in the coffee room at work listening to people
> >>    complain
> >> about a recent seminar about nanotechnology using the terms 
> >> nanofluidics, nanofactory, nano-this, and nano-that ... I 
> found myself
> >> thinking "well the speaker should just
> >> have said
> >>    with(nano,
> >>       ...)
> >> 
> >>    Un(?)fortunately there's no-one here I can share that 
> thought with.
> >> 
> > 
> > -- 
> > Roger D. Peng  |  http://www.biostat.jhsph.edu/~rpeng/
> > 
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> --------------------------------------------------------------------
> E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
> Fax-to-email: +44 (0)870 094 0861
> Date: 30-Jan-06                                       Time: 20:49:43
> ------------------------------ XFMail ------------------------------
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
>


From stvjc at channing.harvard.edu  Mon Jan 30 23:49:37 2006
From: stvjc at channing.harvard.edu (Vincent Carey 525-2265)
Date: Mon, 30 Jan 2006 17:49:37 -0500 (EST)
Subject: [Rd] What about a bib file
Message-ID: <Pine.GSO.4.58.0601301729090.20387@capecod.bwh.harvard.edu>

Romain Francois suggests that a central bibliographic database
(possibly in bibtex format) might be useful for reference inclusion
in R package man pages.  This has been discussed by a small
group, with one proposal presented for a package-specific bibtex database
placed in a dedicated package subdirectory.  Man page references would
then cite the sources enumerated in the database using their bibtex
tags.  This approach could encourage better annotation and should
confer greater accuracy on package:literature referencing.

This does not rule out a central archive that might include all the
references cited in base man pages.

We are doing some work on harvesting the bibliographic citations
in man pages in an R distribution, and converting them to a regular
format.  The \references section is free form, so the conversion
is not trivial, but progress has been made.

The infrastructure required to use this approach to propagate
(e.g., bibtex-formatted) bibliographic data into the man pages that
cite the sources is not yet available, but we hope to have some
prototypes in the next month.

[apologies if i mess up the threading on this topic; i did not receive
the original e-mail to r-devel]

Vince Carey
stvjc at channing.harvard.edu


From murdoch at stats.uwo.ca  Tue Jan 31 00:07:37 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Mon, 30 Jan 2006 18:07:37 -0500
Subject: [Rd] [R] Integer bit size and the modulus operator (PR#8541)
In-Reply-To: <20060130192647.B21E23EFF3@slim.kubism.ku.dk>
References: <20060130192647.B21E23EFF3@slim.kubism.ku.dk>
Message-ID: <43DE9C39.5030006@stats.uwo.ca>

On 1/30/2006 2:26 PM, ripley at stats.ox.ac.uk wrote:
> On Mon, 30 Jan 2006 murdoch at stats.uwo.ca wrote:
> 
>> On 1/30/2006 1:39 PM, Ionut Florescu wrote:
>>> Thank you for the quick reply, I will look into the R packages.
>>> For crashing R try this:
>>>
>>> generator.zp=function(x,p)
>>> {a=1:(p-1); b=x^a%%p;
>>> if(all(b[1:(p-2)]!=1)&&(b[p-1]==1)){return(x, " Good ")}
>>> else{return(x, " No Good, try another integer ")}
>>> }
>> Thanks, I can reproduce the crash using
>>
>> for (x in 10:100) generator.zp(x, 41)
>>
>> I'll see if I can track down what's going wrong.  By the way, you're not
>> supposed to use two arguments to return():  that's not supposed to be
>> allowed any more.  I'm somewhat surprised you don't get an error from
>> it.  But that's not the cause of the crash.
> 
> You do get a warning, though.  It *is* allowed, see ?return.
> 
> One error is the following in real_binary:
> 
>      if (n1 > n2)
>  	copyMostAttrib(s1, ans);
>      else if (n1 == n2) {
>  	copyMostAttrib(s2, ans);
>  	copyMostAttrib(s1, ans);
>      }
>      else
>  	copyMostAttrib(s2, ans);
> 
> Here ans is not PROTECTED.
> 
> The second is in the warning, which causes allocation when ans is not 
> protected.
> 
> Fixed in R-devel and 2.2.1 patched.

I don't see it now.  Thanks!

Duncan Murdoch
> 
> 
>> Duncan Murdoch
>>
>>
>>> This checks if element x is a generator of the group Z_p. If you try
>>> this function for p = 41 and x various increasing values eventually it
>>> will crash R. That is what I meant by random, at first I started x=2,3
>>> so on, when I got to 8, R crashed. Now apparently I can get to 15. When
>>> I tried again I got to 20.
>>>
>>> Ionut Florescu
>>>
>>>
>>> Duncan Murdoch wrote:
>>>> On 1/30/2006 11:32 AM, Ionut Florescu wrote:
>>>>> I am a statistician and I come up to an interesting problem in
>>>>> cryptography. I would like to use R since there are some statistical
>>>>> procedures that I need to use.
>>>>> However, I run into a problem when using the modulus operator %%.
>>>>>
>>>>> I am using R 2.2.1 and when I calculate modulus for large numbers
>>>>> (that I need with my problem) R gives me warnings. For instance if
>>>>> one does:
>>>>> a=1:40;
>>>>> 8^a %% 41
>>>>> one obtains zeros which is not possible since 8 to any power is not a
>>>>> multiple of 41.
>>>>> In addition when working with numbers larger that this and with the
>>>>> mod operator R crashes randomly.
>>>> Could you keep a record of the random crashes, and see if you can make
>>>> any of them repeatable?  R shouldn't crash.  If you can find a
>>>> repeatable way to make it crash, then that's a bug that needs to be
>>>> fixed.  (If it crashes at random it should still be fixed, but it's so
>>>> much harder to fix that it's unlikely to happen unless the cases are
>>>> ones that look likely to come up in normal situations.)
>>>>
>>>>
>>>>> I believe this is because R stores large integers as real numbers
>>>>> thus there may be lack of accuracy when applying the modulus operator
>>>>> and converting back to integers.
>>>>>
>>>>> So my question is this: Is it possible to increase the size of memory
>>>>> used for storing integers? Say from 32 bits to 512 bits (Typical size
>>>>> of integers in cryptography).
>>>> No, but there is at least one contributed package that does multiple
>>>> precision integer arithmetic.  I can't remember the name of it right
>>>> now, but Google should be able to find it for you...
>>>>
>>>> Duncan Murdoch
>>>>> Thank you, any help would be greatly appreciated.
>>>>> Ionut Florescu
>>>>>
>>>>> ______________________________________________
>>>>> R-help at stat.math.ethz.ch mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide!
>>>>> http://www.R-project.org/posting-guide.html
>>>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>


From maechler at stat.math.ethz.ch  Tue Jan 31 15:38:28 2006
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 31 Jan 2006 15:38:28 +0100
Subject: [Rd] What about a bib file
In-Reply-To: <Pine.GSO.4.58.0601301729090.20387@capecod.bwh.harvard.edu>
References: <Pine.GSO.4.58.0601301729090.20387@capecod.bwh.harvard.edu>
Message-ID: <17375.30308.435983.343593@stat.math.ethz.ch>

>>>>> "Vince" == Vincent Carey 525-2265 <stvjc at channing.harvard.edu>
>>>>>     on Mon, 30 Jan 2006 17:49:37 -0500 (EST) writes:

    Vince> Romain Francois suggests that a central bibliographic database
    Vince> (possibly in bibtex format) might be useful for reference inclusion
    Vince> in R package man pages.  This has been discussed by a small
    Vince> group, with one proposal presented for a package-specific bibtex database
    Vince> placed in a dedicated package subdirectory.  Man page references would
    Vince> then cite the sources enumerated in the database using their bibtex
    Vince> tags.  This approach could encourage better annotation and should
    Vince> confer greater accuracy on package:literature referencing.

a very good idea!
I've wished more than once that we had something like that in
place...

My intermediate workaround has been the following, e.g., in
package 'cluster', in man/fanny.Rd,  I have
   \seealso{
     \code{\link{agnes}} for background and references;
     ....
   }

and then no \references{.} in the fanny.Rd file;  but this
workaround is not very satisfactory,
and I am looking forward to your proposals.

Martin Maechler, ETH Zurich


    Vince> This does not rule out a central archive that might include all the
    Vince> references cited in base man pages.

    Vince> We are doing some work on harvesting the bibliographic citations
    Vince> in man pages in an R distribution, and converting them to a regular
    Vince> format.  The \references section is free form, so the conversion
    Vince> is not trivial, but progress has been made.

    Vince> The infrastructure required to use this approach to propagate
    Vince> (e.g., bibtex-formatted) bibliographic data into the man pages that
    Vince> cite the sources is not yet available, but we hope to have some
    Vince> prototypes in the next month.

    Vince> [apologies if i mess up the threading on this topic; i did not receive
    Vince> the original e-mail to r-devel]

    Vince> Vince Carey
    Vince> stvjc at channing.harvard.edu


From ggrothendieck at gmail.com  Tue Jan 31 22:55:25 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 31 Jan 2006 16:55:25 -0500
Subject: [Rd] [R] Help! What does this R command mean?
In-Reply-To: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED79A@usctmx1106.merck.com>
References: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED79A@usctmx1106.merck.com>
Message-ID: <971536df0601311355g7a4e9337iab7e356e533bcfee@mail.gmail.com>

I think that a pointer to ?formula needs to be added to ?":"


On 1/31/06, Liaw, Andy <andy_liaw at merck.com> wrote:
> ":" in a formula is not the same as ":" otherwise!
>
> Andy
>
> From: Ionut Florescu
> >
> > a:b means - all the element in the vector from a to b
> > a[,-1] means for the matrix a keep all the rows but not the last or
> > first -can't remember column.
> > When in doubt do what I do make a small matrix and apply the
> > command see
> > what it does.
> > After this:
> >  > a=matrix(c(1:9),3,3)
> >  > a[,-1]
> >      [,1] [,2]
> > [1,]    4    7
> > [2,]    5    8
> > [3,]    6    9
> >
> > you see that -1 eliminates the first column.
> > I found the R manual useless myself.
> > The only thing useful is the search function in the html
> > help. That has
> > examples.
> >
> > Ionut Florescu
> >
> > Michael wrote:
> > > Hi all,
> > >
> > > R is so difficult. I am so desperate.
> > >
> > > What does the ":" mean in the following statement?
> > >
> > > What does the "[, -1]" mean?
> > >
> > >
> > >> # Leaps takes a design matrix as argument: throw away the intercept
> > >> # column or leaps will complain
> > >>
> > >> X <- model.matrix(lm(V ~ I + D + W +G:I + P + N,
> > election.table))[,-1]
> > >>
> > >
> > > Thanks a lot!
> > >
> > >     [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide!
> > http://www.R-project.org/posting-guide.html
> > >
> > >
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> > http://www.R-project.org/posting-guide.html
> >
> >
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>


