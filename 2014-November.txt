From murdoch.duncan at gmail.com  Sat Nov  1 00:03:13 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 31 Oct 2014 19:03:13 -0400
Subject: [Rd] proposed: minor change to error message
In-Reply-To: <1482649333.479101.1414779779842.JavaMail.root@fredhutch.org>
References: <1482649333.479101.1414779779842.JavaMail.root@fredhutch.org>
Message-ID: <54541531.1040503@gmail.com>

On 31/10/2014, 2:22 PM, Dan Tenenbaum wrote:
> When checking a package (call it "A") that has "Enhances: B" in DESCRIPTION, I get the message:
> 
> Package which this enhances but not available for checking: ?B?
> 
> Can this be changed to:
> 
> Package which enhances this but not available for checking: ?B?
> 
> ?
> 
> Because really, B is not enhanced by A, B does not need A at all.
> 
> (Actually, for the same reason, Enhances should be EnhancedBy, but I am not suggesting changing that because I realize that is non-trivial.)

I think you've got it wrong.  Saying Enhances: B is explicitly a claim
that your package A does enhance B.  Read "Writing R Extensions".

Not all claims made in packages are true, but that's a different issue.

Duncan Murdoch


From csardi.gabor at gmail.com  Sat Nov  1 00:34:41 2014
From: csardi.gabor at gmail.com (=?UTF-8?B?R8OhYm9yIENzw6FyZGk=?=)
Date: Fri, 31 Oct 2014 19:34:41 -0400
Subject: [Rd] Options that are local to the package that sets them
Message-ID: <CABtg=KmCrX1G3K8BxdeJsHvMpMhwoscZ0ExY4_ga9614oYB=KQ@mail.gmail.com>

Dear All,

I am trying to do the following, and could use some hints.

Suppose I have a package called pkgA. pkgA exposes an API that
includes setting some options, e.g. pkgA works with color palettes,
and the user of the package can define new palettes. pkgA provides an
API to manipulate these palettes, including defining them.

pkgA is intended to be used in other packages, e.g. in pkgB1 and
pkgB2. Now suppose pkgB1 and pkgB2 both set new palettes using pkgA.
They might set palettes with the same name, of course, they do not
know about each other.

My question is, is there a straightforward way to implement pkgA's
API, such that pkgB1 and pkgB2 do not interfere? In other words, if
pkgB1 and pkgB2 both define a palette 'foo', but they define it
differently, each should see her own version of it.

I guess this requires that I put something (a function?) in both
pkgB1's and pkgB2's package namespace. As I see it, this can only
happen when pkgA's API is called from pkgB1 (and pkgB2).

So at this time I could just walk up the call tree and put the palette
definition in the first environment that is not pkgA's. This looks
somewhat messy, and I am probably missing some caveats.

Is there a better way? I have a feeling that this is already supported
somehow, I just can't find out how.

Thanks, Best Regards,
Gabor


From ggrothendieck at gmail.com  Sat Nov  1 01:10:56 2014
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 31 Oct 2014 20:10:56 -0400
Subject: [Rd] Options that are local to the package that sets them
In-Reply-To: <CABtg=KmCrX1G3K8BxdeJsHvMpMhwoscZ0ExY4_ga9614oYB=KQ@mail.gmail.com>
References: <CABtg=KmCrX1G3K8BxdeJsHvMpMhwoscZ0ExY4_ga9614oYB=KQ@mail.gmail.com>
Message-ID: <CAP01uR=gS6Zr_QxHjnzCkydRqyZgo2Faoin56ugDoNtPpu4ivA@mail.gmail.com>

On Fri, Oct 31, 2014 at 7:34 PM, G?bor Cs?rdi <csardi.gabor at gmail.com> wrote:
> Dear All,
>
> I am trying to do the following, and could use some hints.
>
> Suppose I have a package called pkgA. pkgA exposes an API that
> includes setting some options, e.g. pkgA works with color palettes,
> and the user of the package can define new palettes. pkgA provides an
> API to manipulate these palettes, including defining them.
>
> pkgA is intended to be used in other packages, e.g. in pkgB1 and
> pkgB2. Now suppose pkgB1 and pkgB2 both set new palettes using pkgA.
> They might set palettes with the same name, of course, they do not
> know about each other.
>
> My question is, is there a straightforward way to implement pkgA's
> API, such that pkgB1 and pkgB2 do not interfere? In other words, if
> pkgB1 and pkgB2 both define a palette 'foo', but they define it
> differently, each should see her own version of it.
>
> I guess this requires that I put something (a function?) in both
> pkgB1's and pkgB2's package namespace. As I see it, this can only
> happen when pkgA's API is called from pkgB1 (and pkgB2).
>
> So at this time I could just walk up the call tree and put the palette
> definition in the first environment that is not pkgA's. This looks
> somewhat messy, and I am probably missing some caveats.
>
> Is there a better way? I have a feeling that this is already supported
> somehow, I just can't find out how.
>

Try the settings package.


From wdunlap at tibco.com  Sat Nov  1 01:16:22 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 31 Oct 2014 17:16:22 -0700
Subject: [Rd] Options that are local to the package that sets them
In-Reply-To: <CABtg=KmCrX1G3K8BxdeJsHvMpMhwoscZ0ExY4_ga9614oYB=KQ@mail.gmail.com>
References: <CABtg=KmCrX1G3K8BxdeJsHvMpMhwoscZ0ExY4_ga9614oYB=KQ@mail.gmail.com>
Message-ID: <CAF8bMca9j3w2T7Uu1pDx97uK=k0aP4jva6qwCT_rhHS5KfayRg@mail.gmail.com>

You can put the following 3 objects, an environment and 2 functions
that access it, in any package that need some package-specific
storage (say your pkgB1 and pkgB2).
   .pkgLocalStorage <- new.env(parent = emptyenv())
   assignInPkgLocalStorage <- function(name, object) {
       .pkgLocalStorage[[name]] <- object
   }
   getFromPkgLocalStorage <- function(name, object) {
       .pkgLocalStorage[[name]]
   }
Leave the environment private and export the functions.  Then a user can
use them as
   pkgB1::assignInPkgLocalStorage("myPallete", makeAPallete(1,2,3))
   pkgB2::assignInPkgLocalStorage("myPallete", makeAPallete(5,6,7))
   pkgB1::getFromPkgLocalStorage("myPallete") # get the 1,2,3 pallete

If only one of pkgB1 and pkgB2 is loaded you can leave off the pkgBn::.

A package writer can always leave off the pkgBn:: as well.

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Fri, Oct 31, 2014 at 4:34 PM, G?bor Cs?rdi <csardi.gabor at gmail.com> wrote:
> Dear All,
>
> I am trying to do the following, and could use some hints.
>
> Suppose I have a package called pkgA. pkgA exposes an API that
> includes setting some options, e.g. pkgA works with color palettes,
> and the user of the package can define new palettes. pkgA provides an
> API to manipulate these palettes, including defining them.
>
> pkgA is intended to be used in other packages, e.g. in pkgB1 and
> pkgB2. Now suppose pkgB1 and pkgB2 both set new palettes using pkgA.
> They might set palettes with the same name, of course, they do not
> know about each other.
>
> My question is, is there a straightforward way to implement pkgA's
> API, such that pkgB1 and pkgB2 do not interfere? In other words, if
> pkgB1 and pkgB2 both define a palette 'foo', but they define it
> differently, each should see her own version of it.
>
> I guess this requires that I put something (a function?) in both
> pkgB1's and pkgB2's package namespace. As I see it, this can only
> happen when pkgA's API is called from pkgB1 (and pkgB2).
>
> So at this time I could just walk up the call tree and put the palette
> definition in the first environment that is not pkgA's. This looks
> somewhat messy, and I am probably missing some caveats.
>
> Is there a better way? I have a feeling that this is already supported
> somehow, I just can't find out how.
>
> Thanks, Best Regards,
> Gabor
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From csardi.gabor at gmail.com  Sat Nov  1 01:43:34 2014
From: csardi.gabor at gmail.com (=?UTF-8?B?R8OhYm9yIENzw6FyZGk=?=)
Date: Fri, 31 Oct 2014 20:43:34 -0400
Subject: [Rd] Options that are local to the package that sets them
In-Reply-To: <CAP01uR=gS6Zr_QxHjnzCkydRqyZgo2Faoin56ugDoNtPpu4ivA@mail.gmail.com>
References: <CABtg=KmCrX1G3K8BxdeJsHvMpMhwoscZ0ExY4_ga9614oYB=KQ@mail.gmail.com>
	<CAP01uR=gS6Zr_QxHjnzCkydRqyZgo2Faoin56ugDoNtPpu4ivA@mail.gmail.com>
Message-ID: <CABtg=Knpvsx5SSFaDyS+bDmSHpNqXn8Hj2zEWgz1-5UiRd-2bA@mail.gmail.com>

On Fri, Oct 31, 2014 at 8:10 PM, Gabor Grothendieck
<ggrothendieck at gmail.com> wrote:
[...]
>> Is there a better way? I have a feeling that this is already supported
>> somehow, I just can't find out how.
>>
>
> Try the settings package.

I could, but I don't see how it would solve my problem.
https://github.com/markvanderloo/settings/issues/1

Gabor


From csardi.gabor at gmail.com  Sat Nov  1 01:55:52 2014
From: csardi.gabor at gmail.com (=?UTF-8?B?R8OhYm9yIENzw6FyZGk=?=)
Date: Fri, 31 Oct 2014 20:55:52 -0400
Subject: [Rd] Options that are local to the package that sets them
In-Reply-To: <CAF8bMca9j3w2T7Uu1pDx97uK=k0aP4jva6qwCT_rhHS5KfayRg@mail.gmail.com>
References: <CABtg=KmCrX1G3K8BxdeJsHvMpMhwoscZ0ExY4_ga9614oYB=KQ@mail.gmail.com>
	<CAF8bMca9j3w2T7Uu1pDx97uK=k0aP4jva6qwCT_rhHS5KfayRg@mail.gmail.com>
Message-ID: <CABtg=Kk0D7UWkiLE3R38VSz3dk68t5DfRt=NqwPbTYQi2K0Wig@mail.gmail.com>

On Fri, Oct 31, 2014 at 8:16 PM, William Dunlap <wdunlap at tibco.com> wrote:
> You can put the following 3 objects, an environment and 2 functions
> that access it, in any package that need some package-specific
> storage (say your pkgB1 and pkgB2).
>    .pkgLocalStorage <- new.env(parent = emptyenv())
>    assignInPkgLocalStorage <- function(name, object) {
>        .pkgLocalStorage[[name]] <- object
>    }
>    getFromPkgLocalStorage <- function(name, object) {
>        .pkgLocalStorage[[name]]
>    }
> Leave the environment private and export the functions.  Then a user can
> use them as
>    pkgB1::assignInPkgLocalStorage("myPallete", makeAPallete(1,2,3))
>    pkgB2::assignInPkgLocalStorage("myPallete", makeAPallete(5,6,7))
>    pkgB1::getFromPkgLocalStorage("myPallete") # get the 1,2,3 pallete

I am trying to avoid requiring pkgBn to do this kind of magic. I just
want it to call function(s) from pkgA. But maybe something like this
would work. In pkgBn:

my_palettes <- pkgA::palette_factory()

and my_palettes is a function or an environment that has the API
functions to modify my_palettes itself (via closure if it is a
function), e.g.

my_palettes$add_palette(...)
my_palettes$get_palette(...)

or if it is a function, then

my_palettes(add(...), ...)
my_palettes(get(...), ...)

etc.

This would work, right? I'll try it in a minute.

Gabor


> If only one of pkgB1 and pkgB2 is loaded you can leave off the pkgBn::.
>
> A package writer can always leave off the pkgBn:: as well.
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
>
> On Fri, Oct 31, 2014 at 4:34 PM, G?bor Cs?rdi <csardi.gabor at gmail.com> wrote:
>> Dear All,
>>
>> I am trying to do the following, and could use some hints.
>>
>> Suppose I have a package called pkgA. pkgA exposes an API that
>> includes setting some options, e.g. pkgA works with color palettes,
>> and the user of the package can define new palettes. pkgA provides an
>> API to manipulate these palettes, including defining them.
>>
>> pkgA is intended to be used in other packages, e.g. in pkgB1 and
>> pkgB2. Now suppose pkgB1 and pkgB2 both set new palettes using pkgA.
>> They might set palettes with the same name, of course, they do not
>> know about each other.
>>
>> My question is, is there a straightforward way to implement pkgA's
>> API, such that pkgB1 and pkgB2 do not interfere? In other words, if
>> pkgB1 and pkgB2 both define a palette 'foo', but they define it
>> differently, each should see her own version of it.
>>
>> I guess this requires that I put something (a function?) in both
>> pkgB1's and pkgB2's package namespace. As I see it, this can only
>> happen when pkgA's API is called from pkgB1 (and pkgB2).
>>
>> So at this time I could just walk up the call tree and put the palette
>> definition in the first environment that is not pkgA's. This looks
>> somewhat messy, and I am probably missing some caveats.
>>
>> Is there a better way? I have a feeling that this is already supported
>> somehow, I just can't find out how.
>>
>> Thanks, Best Regards,
>> Gabor
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel


From brodie.gaslam at yahoo.com  Sat Nov  1 02:00:43 2014
From: brodie.gaslam at yahoo.com (brodie gaslam)
Date: Fri, 31 Oct 2014 18:00:43 -0700
Subject: [Rd] Appropriately Crediting Use of R Source Code in Package
Message-ID: <1414803643.57890.YahooMailNeo@web162204.mail.bf1.yahoo.com>

I'm developing packages that in some places use code that started off as a direct copy-paste from the R sources (this is C code).  The finished code is fairly different from what I started with, but clearly uses similar algorithms / tricks as the original code, and some lines here and there are still verbatim copies.

What is the correct way to credit the R developers in DESCRIPTION? As copyright holders?  As contributors / authors (though it almost seems presumptuous for me to associate them with my crappy package)?  If so, should I use "R Core Team" as seems to be the standard in base R packages for authors?

I've looked in Writing R extensions, the 6/2012 R Journal article, and other places and can't quite find an answer for my use case (I may be obtuse).
	[[alternative HTML version deleted]]


From edward.davignon at gmail.com  Sat Nov  1 02:00:54 2014
From: edward.davignon at gmail.com (Edward Davignon)
Date: Fri, 31 Oct 2014 21:00:54 -0400
Subject: [Rd] Trouble installing Rcpp on AIX - missing "execinfo.h"
In-Reply-To: <AA01911644A2F84FB4571C323FC45DD56A524FC7@TWIX.dataventures.local>
References: <AA01911644A2F84FB4571C323FC45DD56A524FC7@TWIX.dataventures.local>
Message-ID: <CACw-iSDaOSDp8kXr=deSfq+zWOBLaTnx9v_tcqu-kNtUMQ-RRA@mail.gmail.com>

Mike,

Perhaps this will help: http://cygwin.com/ml/cygwin/2012-04/msg00346.html

Regards,
Ed Davignon

On Thu, Oct 30, 2014 at 12:13 AM, Mike Beddo <Mike.Beddo at dataventures.com>
wrote:

> Greetings,
>
> When I try "install.packages('Rcpp')" it fails when compiling api.cpp
> (line 39). This is Rcpp 0.11.3. I searched my filesystem, and indeed I do
> not have execinfo.h anywhere. After some effort, I got R build on AIX. Now
> I am trying to build the packages I need. Rcpp is crucial.
>
> I first build R with the native IBM XL compilers, and Rcpp wouldn't build.
> That was because it wasn't a "GOOD COMPILER" (there's a directive in the
> Rcpp code that checks for various types of compilers). So I switched to
> building R with gcc/gfortran/g++ 4.8 and got past that point, but now
> blocked by the absence of "execinfo.h" header file.
>
> Any ideas?
>
> Thanks,
>
> Mike
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From ggrothendieck at gmail.com  Sat Nov  1 02:20:29 2014
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 31 Oct 2014 21:20:29 -0400
Subject: [Rd] Options that are local to the package that sets them
In-Reply-To: <CABtg=Knpvsx5SSFaDyS+bDmSHpNqXn8Hj2zEWgz1-5UiRd-2bA@mail.gmail.com>
References: <CABtg=KmCrX1G3K8BxdeJsHvMpMhwoscZ0ExY4_ga9614oYB=KQ@mail.gmail.com>
	<CAP01uR=gS6Zr_QxHjnzCkydRqyZgo2Faoin56ugDoNtPpu4ivA@mail.gmail.com>
	<CABtg=Knpvsx5SSFaDyS+bDmSHpNqXn8Hj2zEWgz1-5UiRd-2bA@mail.gmail.com>
Message-ID: <CAP01uRmKvVjtzbsL+Afn5bXm-uZ50vXHTZZ+yzE4OS1ooiJuuQ@mail.gmail.com>

On Fri, Oct 31, 2014 at 8:43 PM, G?bor Cs?rdi <csardi.gabor at gmail.com> wrote:
> On Fri, Oct 31, 2014 at 8:10 PM, Gabor Grothendieck
> <ggrothendieck at gmail.com> wrote:
> [...]
>>> Is there a better way? I have a feeling that this is already supported
>>> somehow, I just can't find out how.
>>>
>>
>> Try the settings package.
>
> I could, but I don't see how it would solve my problem.
> https://github.com/markvanderloo/settings/issues/1

Isn't your problem really just that you want multiple sets of
settings?  That's what settings provides.

pkgA would provide a class whose instances are created by the clients.
Assuming you wrap this in a function create:

inst1 <- create(a = 1, b = 2)

where create sets up a settings object and does anything else
returning the handle inst1.

When you want to do something you would pass the instance to the
function or method that actually carries it out.  This could be done
with any OO system in R without settings but if you are looking for an
options type interface which I thought you were then you might be able
to leverage that package.




-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From mtmorgan at fredhutch.org  Sat Nov  1 02:26:23 2014
From: mtmorgan at fredhutch.org (Martin Morgan)
Date: Fri, 31 Oct 2014 18:26:23 -0700
Subject: [Rd] Options that are local to the package that sets them
In-Reply-To: <CABtg=Kk0D7UWkiLE3R38VSz3dk68t5DfRt=NqwPbTYQi2K0Wig@mail.gmail.com>
References: <CABtg=KmCrX1G3K8BxdeJsHvMpMhwoscZ0ExY4_ga9614oYB=KQ@mail.gmail.com>	<CAF8bMca9j3w2T7Uu1pDx97uK=k0aP4jva6qwCT_rhHS5KfayRg@mail.gmail.com>
	<CABtg=Kk0D7UWkiLE3R38VSz3dk68t5DfRt=NqwPbTYQi2K0Wig@mail.gmail.com>
Message-ID: <545436BF.10006@fredhutch.org>

On 10/31/2014 05:55 PM, G?bor Cs?rdi wrote:
> On Fri, Oct 31, 2014 at 8:16 PM, William Dunlap <wdunlap at tibco.com> wrote:
>> You can put the following 3 objects, an environment and 2 functions
>> that access it, in any package that need some package-specific
>> storage (say your pkgB1 and pkgB2).
>>     .pkgLocalStorage <- new.env(parent = emptyenv())
>>     assignInPkgLocalStorage <- function(name, object) {
>>         .pkgLocalStorage[[name]] <- object
>>     }
>>     getFromPkgLocalStorage <- function(name, object) {
>>         .pkgLocalStorage[[name]]
>>     }
>> Leave the environment private and export the functions.  Then a user can
>> use them as
>>     pkgB1::assignInPkgLocalStorage("myPallete", makeAPallete(1,2,3))
>>     pkgB2::assignInPkgLocalStorage("myPallete", makeAPallete(5,6,7))
>>     pkgB1::getFromPkgLocalStorage("myPallete") # get the 1,2,3 pallete
>
> I am trying to avoid requiring pkgBn to do this kind of magic. I just
> want it to call function(s) from pkgA. But maybe something like this
> would work. In pkgBn:
>
> my_palettes <- pkgA::palette_factory()
>
> and my_palettes is a function or an environment that has the API
> functions to modify my_palettes itself (via closure if it is a
> function), e.g.
>
> my_palettes$add_palette(...)
> my_palettes$get_palette(...)
>
> or if it is a function, then
>
> my_palettes(add(...), ...)
> my_palettes(get(...), ...)
>
> etc.
>
> This would work, right? I'll try it in a minute.

You'll need pkgA to be able to know that pkgB1's invokation is to use pkgB1's 
parameters, so coupling state (parameters) with function, i.e., a class with 
methods. So a solution is to use an S4 or reference class and generator to 
encapsulate state and dispatch to appropriate functions, E.g.,

   .Plotter <- setRefClass("Plotter",
       fields=list(palette="character"),
       methods=list(
         update(palette) {
             .self$palette <- palette
         },
         plot=function(...) {
             graphics::plot(..., col=.self$palette)
         }))

   APlotter <- function(palette=c("red", "green", "blue"))
       .Plotter(palette=palette)

PkgB1, 2 would then

   plt = APlotter()
   plt$plot(mpg ~ disp, mtcars)
   plt$update(c("blue", "green"))
   plt$plot(mpg ~ disp, mtcars)

or

   .S4Plotter <- setClass("S4Plotter", representation(palette="character")
   S4Plotter <- function(palette=c("red", "blue", "green"))
   s4plot <- function(x, ...) graphics::plot(..., col=x at palette))

(make s4plot a generic with method for class S4Plotter to enforce type).

Seems like this interface could be generated automatically in .onLoad() of pkgA, 
especially if adopting a naming convention of some sort.

Martin

>
> Gabor
>
>
>> If only one of pkgB1 and pkgB2 is loaded you can leave off the pkgBn::.
>>
>> A package writer can always leave off the pkgBn:: as well.
>>
>> Bill Dunlap
>> TIBCO Software
>> wdunlap tibco.com
>>
>>
>> On Fri, Oct 31, 2014 at 4:34 PM, G?bor Cs?rdi <csardi.gabor at gmail.com> wrote:
>>> Dear All,
>>>
>>> I am trying to do the following, and could use some hints.
>>>
>>> Suppose I have a package called pkgA. pkgA exposes an API that
>>> includes setting some options, e.g. pkgA works with color palettes,
>>> and the user of the package can define new palettes. pkgA provides an
>>> API to manipulate these palettes, including defining them.
>>>
>>> pkgA is intended to be used in other packages, e.g. in pkgB1 and
>>> pkgB2. Now suppose pkgB1 and pkgB2 both set new palettes using pkgA.
>>> They might set palettes with the same name, of course, they do not
>>> know about each other.
>>>
>>> My question is, is there a straightforward way to implement pkgA's
>>> API, such that pkgB1 and pkgB2 do not interfere? In other words, if
>>> pkgB1 and pkgB2 both define a palette 'foo', but they define it
>>> differently, each should see her own version of it.
>>>
>>> I guess this requires that I put something (a function?) in both
>>> pkgB1's and pkgB2's package namespace. As I see it, this can only
>>> happen when pkgA's API is called from pkgB1 (and pkgB2).
>>>
>>> So at this time I could just walk up the call tree and put the palette
>>> definition in the first environment that is not pkgA's. This looks
>>> somewhat messy, and I am probably missing some caveats.
>>>
>>> Is there a better way? I have a feeling that this is already supported
>>> somehow, I just can't find out how.
>>>
>>> Thanks, Best Regards,
>>> Gabor
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


-- 
Computational Biology / Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N.
PO Box 19024 Seattle, WA 98109

Location: Arnold Building M1 B861
Phone: (206) 667-2793


From csardi.gabor at gmail.com  Sat Nov  1 02:46:09 2014
From: csardi.gabor at gmail.com (=?UTF-8?B?R8OhYm9yIENzw6FyZGk=?=)
Date: Fri, 31 Oct 2014 21:46:09 -0400
Subject: [Rd] Options that are local to the package that sets them
In-Reply-To: <CAP01uRmKvVjtzbsL+Afn5bXm-uZ50vXHTZZ+yzE4OS1ooiJuuQ@mail.gmail.com>
References: <CABtg=KmCrX1G3K8BxdeJsHvMpMhwoscZ0ExY4_ga9614oYB=KQ@mail.gmail.com>
	<CAP01uR=gS6Zr_QxHjnzCkydRqyZgo2Faoin56ugDoNtPpu4ivA@mail.gmail.com>
	<CABtg=Knpvsx5SSFaDyS+bDmSHpNqXn8Hj2zEWgz1-5UiRd-2bA@mail.gmail.com>
	<CAP01uRmKvVjtzbsL+Afn5bXm-uZ50vXHTZZ+yzE4OS1ooiJuuQ@mail.gmail.com>
Message-ID: <CABtg=K=tDuYRvqNP61-5g8mbapT3tFU8W=u39A+dzYP+2o_rQg@mail.gmail.com>

On Fri, Oct 31, 2014 at 9:20 PM, Gabor Grothendieck
<ggrothendieck at gmail.com> wrote:
[...]
> Isn't your problem really just that you want multiple sets of
> settings?  That's what settings provides.

Almost. Multiple sets of settings, set up by the same package. So
essentially I want pkgA to use different settings when called from
different packages.

E.g. imagine that my package igraph has an option that sets a color
plot plotting. Another package, qgraph sets this setting to something,
say "red". Now another package xgraph wants to set it to "green". What
I want is to use "red" when plotting through qgraph, and to use
"green" when plotting from xgraph.

igraph provides the API for setting this option, so if I just use
'settings' (or a similar technique) in igraph, then xgraph's setting
will overwrite qgraph's setting.

> pkgA would provide a class whose instances are created by the clients.
> Assuming you wrap this in a function create:
>
> inst1 <- create(a = 1, b = 2)
>
> where create sets up a settings object and does anything else
> returning the handle inst1.
>
> When you want to do something you would pass the instance to the
> function or method that actually carries it out.  This could be done
> with any OO system in R without settings but if you are looking for an
> options type interface which I thought you were then you might be able
> to leverage that package.

You are right, this should work. I would like to avoid passing the
settings object to each and every igraph function, though. (Would need
to update 500+ functions.) But that does not seem to be possible,
unless I start messing with the call stack.

G.


From csardi.gabor at gmail.com  Sat Nov  1 02:51:08 2014
From: csardi.gabor at gmail.com (=?UTF-8?B?R8OhYm9yIENzw6FyZGk=?=)
Date: Fri, 31 Oct 2014 21:51:08 -0400
Subject: [Rd] Options that are local to the package that sets them
In-Reply-To: <545436BF.10006@fredhutch.org>
References: <CABtg=KmCrX1G3K8BxdeJsHvMpMhwoscZ0ExY4_ga9614oYB=KQ@mail.gmail.com>
	<CAF8bMca9j3w2T7Uu1pDx97uK=k0aP4jva6qwCT_rhHS5KfayRg@mail.gmail.com>
	<CABtg=Kk0D7UWkiLE3R38VSz3dk68t5DfRt=NqwPbTYQi2K0Wig@mail.gmail.com>
	<545436BF.10006@fredhutch.org>
Message-ID: <CABtg=K=BxcJe5xrigwkQZD1H68wAcF2NqEOWCOQx=1We37Foaw@mail.gmail.com>

On Fri, Oct 31, 2014 at 9:26 PM, Martin Morgan <mtmorgan at fredhutch.org> wrote:
[...]
> You'll need pkgA to be able to know that pkgB1's invokation is to use
> pkgB1's parameters, so coupling state (parameters) with function, i.e., a
> class with methods. So a solution is to use an S4 or reference class and
> generator to encapsulate state and dispatch to appropriate functions, E.g.,
>
>   .Plotter <- setRefClass("Plotter",
>       fields=list(palette="character"),
>       methods=list(
>         update(palette) {
>             .self$palette <- palette
>         },
>         plot=function(...) {
>             graphics::plot(..., col=.self$palette)
>         }))
>
>   APlotter <- function(palette=c("red", "green", "blue"))
>       .Plotter(palette=palette)
>
> PkgB1, 2 would then
>
>   plt = APlotter()
>   plt$plot(mpg ~ disp, mtcars)
>   plt$update(c("blue", "green"))
>   plt$plot(mpg ~ disp, mtcars)
>
> or
>
>   .S4Plotter <- setClass("S4Plotter", representation(palette="character")
>   S4Plotter <- function(palette=c("red", "blue", "green"))
>   s4plot <- function(x, ...) graphics::plot(..., col=x at palette))
>
> (make s4plot a generic with method for class S4Plotter to enforce type).
>
> Seems like this interface could be generated automatically in .onLoad() of
> pkgA, especially if adopting a naming convention of some sort.

Yes, I think this works, and all three of us came to essentially the
same solution.
Unfortunately, this solution also requires putting the whole pkgA API
inside such a class, otherwise the pkgA functions will not find the
right settings.

Thanks again!
Gabor

[...]


From edd at debian.org  Sat Nov  1 03:31:52 2014
From: edd at debian.org (Dirk Eddelbuettel)
Date: Fri, 31 Oct 2014 21:31:52 -0500
Subject: [Rd] Trouble installing Rcpp on AIX - missing "execinfo.h"
In-Reply-To: <AA01911644A2F84FB4571C323FC45DD56A524FC7@TWIX.dataventures.local>
References: <AA01911644A2F84FB4571C323FC45DD56A524FC7@TWIX.dataventures.local>
Message-ID: <21588.17944.611417.254485@max.nulle.part>


On 30 October 2014 at 04:13, Mike Beddo wrote:
| Greetings,
| 
| When I try "install.packages('Rcpp')" it fails when compiling api.cpp (line 39). This is Rcpp 0.11.3. I searched my filesystem, and indeed I do not have execinfo.h anywhere. After some effort, I got R build on AIX. Now I am trying to build the packages I need. Rcpp is crucial.
| 
| I first build R with the native IBM XL compilers, and Rcpp wouldn't build. That was because it wasn't a "GOOD COMPILER" (there's a directive in the Rcpp code that checks for various types of compilers). So I switched to building R with gcc/gfortran/g++ 4.8 and got past that point, but now blocked by the absence of "execinfo.h" header file.
| 
| Any ideas?

I would have replied sooner if you had used the proper list -- which for
matters pertaining to Rcpp is the rcpp-devel list (and note that you need
subscribe first in order to post).

For systems we do not have access to -- like Solaris, Aix, or equally antique
and rarified Unix systems -- we do rely on those having access to run tests.
Worst case we can #ifdef some features away so that you can build with a
possibly sightly reduced feature set.  But you, or someone else on Aix, needs
to drive this as we can't.

Dirk

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From Mike.Beddo at dataventures.com  Sat Nov  1 05:06:52 2014
From: Mike.Beddo at dataventures.com (Mike Beddo)
Date: Sat, 1 Nov 2014 04:06:52 +0000
Subject: [Rd] Trouble installing Rcpp on AIX - missing "execinfo.h"
In-Reply-To: <21588.17944.611417.254485@max.nulle.part>
References: <AA01911644A2F84FB4571C323FC45DD56A524FC7@TWIX.dataventures.local>
	<21588.17944.611417.254485@max.nulle.part>
Message-ID: <AA01911644A2F84FB4571C323FC45DD56A526B86@TWIX.dataventures.local>

Dirk and Edward,

Thanks for the help.

I found for AIX that "execinfo.h" basically did nothing that I could tell. What I ended up doing was replacing the line in api.cpp "#include <execinfo.h>" with the following from gnulib:

int backtrace (void **buffer, int size)
{
    (void) buffer;
    (void) size;
    return 0;
}

char **backtrace_symbols (void *const *buffer, int size)
{
    (void) buffer;
    (void) size;
    return 0;
}

void backtrace_symbols_fd (void *const *buffer, int size, int fd)
{
    (void) buffer;
    (void) size;
    (void) fd;
}

So I've probably lost some functionality over other popular Unix systems, but the few examples that I ran from the Rcpp help pages, and for other packages that depend on Rcpp, seemed to indicate that what got built essentially works fine.

Up till now, at my work we've been moving data back and forth between AIX (data generation) and Windows (R analysis). I'm no fan of AIX, but we needed R on AIX so we can avoid all the data movement and be more productive.

I am going to have to learn more about Rcpp. This was really my first encounter with it - my co-worker depends on it so I was trying to build it on AIX for her.

I want to thank you both very much for the tips and help. If I can be of service to help with testing on AIX, please feel free to reach out to me. Building the base R system for AIX 7.1 was no small feat for me - I spent days back and forth between the IBM XL and GNU compilers, trying to find the flags that would work. The R Admin guide got me 80% of the way there, but I had to patch a system header file, etc. Once that was done, building the recommended packages went ok for the most part, but building Matrix gave lots of warnings but seems to work. AIX is no friend to non-IBM softwares.

I will subscribe to the rcpp-devel list, and probably buy the book.

Mike Beddo

-----Original Message-----
From: Dirk Eddelbuettel [mailto:edd at debian.org] 
Sent: Friday, October 31, 2014 8:32 PM
To: Mike Beddo
Cc: r-devel at r-project.org
Subject: Re: [Rd] Trouble installing Rcpp on AIX - missing "execinfo.h"


On 30 October 2014 at 04:13, Mike Beddo wrote:
| Greetings,
| 
| When I try "install.packages('Rcpp')" it fails when compiling api.cpp (line 39). This is Rcpp 0.11.3. I searched my filesystem, and indeed I do not have execinfo.h anywhere. After some effort, I got R build on AIX. Now I am trying to build the packages I need. Rcpp is crucial.
| 
| I first build R with the native IBM XL compilers, and Rcpp wouldn't build. That was because it wasn't a "GOOD COMPILER" (there's a directive in the Rcpp code that checks for various types of compilers). So I switched to building R with gcc/gfortran/g++ 4.8 and got past that point, but now blocked by the absence of "execinfo.h" header file.
| 
| Any ideas?

I would have replied sooner if you had used the proper list -- which for matters pertaining to Rcpp is the rcpp-devel list (and note that you need subscribe first in order to post).

For systems we do not have access to -- like Solaris, Aix, or equally antique and rarified Unix systems -- we do rely on those having access to run tests.
Worst case we can #ifdef some features away so that you can build with a possibly sightly reduced feature set.  But you, or someone else on Aix, needs to drive this as we can't.

Dirk

--
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From h.wickham at gmail.com  Sat Nov  1 06:08:27 2014
From: h.wickham at gmail.com (Hadley Wickham)
Date: Sat, 1 Nov 2014 00:08:27 -0500
Subject: [Rd] ScalarLogical and setAttrib
In-Reply-To: <CABFfbXvzf4QV6Tb5qi53ddJh_MEhJEDeb3aFwL=s-Nnnpe2okA@mail.gmail.com>
References: <CABFfbXvzf4QV6Tb5qi53ddJh_MEhJEDeb3aFwL=s-Nnnpe2okA@mail.gmail.com>
Message-ID: <CABdHhvFnLEbhK1NbAGY0gFc77G_dYDGSUXZROCA9RwZroLiRNg@mail.gmail.com>

I believe this is by design (and changed relatively recently). FALSE and
TRUE are singletons, like NULL.

Hadley.

On Friday, October 31, 2014, Jeroen Ooms <jeroen.ooms at stat.ucla.edu> wrote:

> Is it expected that attributes set on a LGLSXP created by
> ScalarLogical will apply to all future objects created by
> ScalarLogical as well? For example: the 'test1' function below returns
> FALSE and 'test2' returns FALSE with an attribute:
>
>   library(inline)
>   test1 <- cfunction(body = 'return ScalarLogical(0);')
>   test2 <- cfunction(body = '
>     SEXP success = PROTECT(ScalarLogical(0));
>     setAttrib(success, install("foo"), mkString("bar"));
>     UNPROTECT(1);
>     return success;
>   ')
>
> However after running test2(), then test1() will also return the attribute:
>
>   > test1()
>   [1] FALSE
>   > test2()
>   [1] FALSE
>   attr(,"foo")
>   [1] "bar"
>   > test1()
>   [1] FALSE
>   attr(,"foo")
>   [1] "bar"
>
> It seems like ScalarLogical returns a singleton object, which is not
> the case for ScalarInteger or ScalarReal. I am currently working
> around this using duplicate(ScalarLogical(0)), but was quite surprised
> by this behavior of ScalarLogical.
>
> ______________________________________________
> R-devel at r-project.org <javascript:;> mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


-- 
http://had.co.nz/

	[[alternative HTML version deleted]]


From hpages at fredhutch.org  Sat Nov  1 11:42:52 2014
From: hpages at fredhutch.org (=?windows-1252?Q?Herv=E9_Pag=E8s?=)
Date: Sat, 01 Nov 2014 03:42:52 -0700
Subject: [Rd] ScalarLogical and setAttrib
In-Reply-To: <CABFfbXvzf4QV6Tb5qi53ddJh_MEhJEDeb3aFwL=s-Nnnpe2okA@mail.gmail.com>
References: <CABFfbXvzf4QV6Tb5qi53ddJh_MEhJEDeb3aFwL=s-Nnnpe2okA@mail.gmail.com>
Message-ID: <5454B92C.7010501@fredhutch.org>

Hi,

The problem is better illustrated with:

   library(inline)
   test2 <- cfunction(body = '
     SEXP success = PROTECT(ScalarLogical(0));
     setAttrib(success, install("foo"), mkString("bar"));
     UNPROTECT(1);
     return success;
   ')
   test3 <- cfunction(body = '
     SEXP success = PROTECT(ScalarLogical(0));
     LOGICAL(success)[0] = 1;
     UNPROTECT(1);
     return success;
   ')

Then:

   > test2()
   [1] FALSE
   attr(,"foo")
   [1] "bar"

   > test3()
   [1] TRUE
   attr(,"foo")
   [1] "bar"

Looks like someone assumed that the SEXP returned by ScalarLogical()
would never be touched before being returned to R (which is probably
true 99% of the time but not 100%).

Cheers,
H.


On 10/31/2014 03:58 PM, Jeroen Ooms wrote:
> Is it expected that attributes set on a LGLSXP created by
> ScalarLogical will apply to all future objects created by
> ScalarLogical as well? For example: the 'test1' function below returns
> FALSE and 'test2' returns FALSE with an attribute:
>
>    library(inline)
>    test1 <- cfunction(body = 'return ScalarLogical(0);')
>    test2 <- cfunction(body = '
>      SEXP success = PROTECT(ScalarLogical(0));
>      setAttrib(success, install("foo"), mkString("bar"));
>      UNPROTECT(1);
>      return success;
>    ')
>
> However after running test2(), then test1() will also return the attribute:
>
>    > test1()
>    [1] FALSE
>    > test2()
>    [1] FALSE
>    attr(,"foo")
>    [1] "bar"
>    > test1()
>    [1] FALSE
>    attr(,"foo")
>    [1] "bar"
>
> It seems like ScalarLogical returns a singleton object, which is not
> the case for ScalarInteger or ScalarReal. I am currently working
> around this using duplicate(ScalarLogical(0)), but was quite surprised
> by this behavior of ScalarLogical.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fredhutch.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From hpages at fredhutch.org  Sat Nov  1 11:50:29 2014
From: hpages at fredhutch.org (=?windows-1252?Q?Herv=E9_Pag=E8s?=)
Date: Sat, 01 Nov 2014 03:50:29 -0700
Subject: [Rd] ScalarLogical and setAttrib
In-Reply-To: <CABFfbXvzf4QV6Tb5qi53ddJh_MEhJEDeb3aFwL=s-Nnnpe2okA@mail.gmail.com>
References: <CABFfbXvzf4QV6Tb5qi53ddJh_MEhJEDeb3aFwL=s-Nnnpe2okA@mail.gmail.com>
Message-ID: <5454BAF5.1040107@fredhutch.org>

Hi,

The problem is better illustrated with:

   library(inline)
   test2 <- cfunction(body = '
     SEXP success = PROTECT(ScalarLogical(0));
     setAttrib(success, install("foo"), mkString("bar"));
     UNPROTECT(1);
     return success;
   ')
   test3 <- cfunction(body = '
     SEXP success = PROTECT(ScalarLogical(0));
     LOGICAL(success)[0] = 1;
     UNPROTECT(1);
     return success;
   ')

Then:

   > test2()
   [1] FALSE
   attr(,"foo")
   [1] "bar"

   > test3()
   [1] TRUE
   attr(,"foo")
   [1] "bar"

Looks like someone assumed that the SEXP returned by ScalarLogical()
would never be touched before being returned to R (which is probably
true 99% of the time but not 100%).

Cheers,
H.


On 10/31/2014 03:58 PM, Jeroen Ooms wrote:
> Is it expected that attributes set on a LGLSXP created by
> ScalarLogical will apply to all future objects created by
> ScalarLogical as well? For example: the 'test1' function below returns
> FALSE and 'test2' returns FALSE with an attribute:
>
>    library(inline)
>    test1 <- cfunction(body = 'return ScalarLogical(0);')
>    test2 <- cfunction(body = '
>      SEXP success = PROTECT(ScalarLogical(0));
>      setAttrib(success, install("foo"), mkString("bar"));
>      UNPROTECT(1);
>      return success;
>    ')
>
> However after running test2(), then test1() will also return the attribute:
>
>    > test1()
>    [1] FALSE
>    > test2()
>    [1] FALSE
>    attr(,"foo")
>    [1] "bar"
>    > test1()
>    [1] FALSE
>    attr(,"foo")
>    [1] "bar"
>
> It seems like ScalarLogical returns a singleton object, which is not
> the case for ScalarInteger or ScalarReal. I am currently working
> around this using duplicate(ScalarLogical(0)), but was quite surprised
> by this behavior of ScalarLogical.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fredhutch.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From simons at cryp.to  Sat Nov  1 13:30:14 2014
From: simons at cryp.to (Peter Simons)
Date: Sat, 1 Nov 2014 13:30:14 +0100
Subject: [Rd] R 3.1.1 and 3.1.2 both fail their test suites
Message-ID: <87lhnvje7d.fsf@write-only.cryp.to>

Hi,

I maintain the R packages in the NixOS Linux distribution [1]. A while
ago, I attempted to update to version 3.1.1, but I ran into the
following test suite failure:

 | Testing examples for package 'tools'
 |   comparing 'tools-Ex.Rout' to 'tools-Ex.Rout.save' ...
 | 452c452
 | < character(0)
 | ---
 | > [1] "Matrix" "nlme"   "mgcv"
 | 856c856
 | < character(0)
 | ---
 | > [1] "lattice"
 | 865c865
 | < character(0)
 | ---
 | > [1] "R (>= 2.15.1)"
 | Testing examples for package 'utils'
 | Error: testing 'utils' failed

I reported that issue at [2], and waited for something to happen. Now,
version 3.1.2 comes out and I try to update again, but it has the exact
same error. Apparently, no-one cares about the problem we've run into?

Now, I wonder how to proceed. It doesn't look like this issue is going
to be fixed any time soon. So I guess I should disable the "make check"
phase in NixOS and ship software to our users that doesn't pass its own
self-test?

Best regards,
Peter


[1] http://nixos.org/
[2] https://bugs.r-project.org/bugzilla/show_bug.cgi?id=15975


From ligges at statistik.tu-dortmund.de  Sat Nov  1 15:49:10 2014
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sat, 1 Nov 2014 15:49:10 +0100
Subject: [Rd] R 3.1.1 and 3.1.2 both fail their test suites
In-Reply-To: <87lhnvje7d.fsf@write-only.cryp.to>
References: <87lhnvje7d.fsf@write-only.cryp.to>
Message-ID: <5454F2E6.9090301@statistik.tu-dortmund.de>

Nobody in R core runs NixOS and can reproduce this. This passes on most 
other platforms, apparently. If you can point us to a problem or send 
patches, we'd appreciate it.

Best,
Uwe Ligges


On 01.11.2014 13:30, Peter Simons wrote:
> Hi,
>
> I maintain the R packages in the NixOS Linux distribution [1]. A while
> ago, I attempted to update to version 3.1.1, but I ran into the
> following test suite failure:
>
>   | Testing examples for package 'tools'
>   |   comparing 'tools-Ex.Rout' to 'tools-Ex.Rout.save' ...
>   | 452c452
>   | < character(0)
>   | ---
>   | > [1] "Matrix" "nlme"   "mgcv"
>   | 856c856
>   | < character(0)
>   | ---
>   | > [1] "lattice"
>   | 865c865
>   | < character(0)
>   | ---
>   | > [1] "R (>= 2.15.1)"
>   | Testing examples for package 'utils'
>   | Error: testing 'utils' failed
>
> I reported that issue at [2], and waited for something to happen. Now,
> version 3.1.2 comes out and I try to update again, but it has the exact
> same error. Apparently, no-one cares about the problem we've run into?
>
> Now, I wonder how to proceed. It doesn't look like this issue is going
> to be fixed any time soon. So I guess I should disable the "make check"
> phase in NixOS and ship software to our users that doesn't pass its own
> self-test?
>
> Best regards,
> Peter
>
>
> [1] http://nixos.org/
> [2] https://bugs.r-project.org/bugzilla/show_bug.cgi?id=15975
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From radford at cs.toronto.edu  Sat Nov  1 16:03:23 2014
From: radford at cs.toronto.edu (Radford Neal)
Date: Sat, 1 Nov 2014 11:03:23 -0400
Subject: [Rd]  ScalarLogical and setAttrib
In-Reply-To: <mailman.19.1414839607.13132.r-devel@r-project.org>
References: <mailman.19.1414839607.13132.r-devel@r-project.org>
Message-ID: <20141101150323.GA25355@cs.toronto.edu>

> From: Jeroen Ooms <jeroen.ooms at stat.ucla.edu>
>
> It seems like ScalarLogical returns a singleton object, which is not
> the case for ScalarInteger or ScalarReal. I am currently working
> around this using duplicate(ScalarLogical(0)), but was quite surprised
> by this behavior of ScalarLogical.

> From: Hadley Wickham <h.wickham at gmail.com>
> 
> I believe this is by design (and changed relatively recently). FALSE and
> TRUE are singletons, like NULL.


No, TRUE and FALSE aren't like NULL.  There's only ever one NULL, but
there can be many TRUE and FALSE objects.  For example, see below,
done with R-3.1.2:

  > .Internal(inspect(TRUE))
  @2d84488 10 LGLSXP g0c1 [NAM(2)] (len=1, tl=0) 1
  > .Internal(inspect(TRUE|FALSE))
  @2d84308 10 LGLSXP g0c1 [] (len=1, tl=0) 1

The problem is a combination of not documenting exactly what
ScalarLogical is supposed to do, and then changing what it does.

I think it's pretty reasonable for people to have assumed they could
attach an attribute to the result of ScalarLogical, given the lack of
any explicit documentation.  Of course, paranoid users would have
checked NAMED on the result to see it they need to duplicate it, but
the documentation on that is less explicit than it might be as well.

This is why pqR still returns an unshared object for ScalarLogical.
Internally, pqR has a ScalarLogicalMaybeShared function that returns the
shared version, which is in read-only memory so that any attempt to change
it will cause an error.  (Similarly, there are ScalarRealMaybeShared, etc.)

   Radford Neal


From simons at cryp.to  Sat Nov  1 16:33:29 2014
From: simons at cryp.to (Peter Simons)
Date: Sat, 1 Nov 2014 16:33:29 +0100
Subject: [Rd] R 3.1.1 and 3.1.2 both fail their test suites
References: <87lhnvje7d.fsf@write-only.cryp.to>
	<5454F2E6.9090301@statistik.tu-dortmund.de>
Message-ID: <87ioizndfa.fsf@write-only.cryp.to>

Hi Uwe,

 > Nobody in R core runs NixOS and can reproduce this. This passes on most
 > other platforms, apparently. If you can point us to a problem or send
 > patches, we'd appreciate it.

have tried running the test suite in a build that's configured with
'--without-recommended-packages'? That's about the only unusual thing we
do when building with Nix. Other than that, our build runs on a
perfectly ordinary Linux -- and it used to succeed fine in earlier
versions of R.

Best regards,
Peter


From edd at debian.org  Sat Nov  1 17:36:12 2014
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sat, 1 Nov 2014 11:36:12 -0500
Subject: [Rd] Trouble installing Rcpp on AIX - missing "execinfo.h"
In-Reply-To: <AA01911644A2F84FB4571C323FC45DD56A526B86@TWIX.dataventures.local>
References: <AA01911644A2F84FB4571C323FC45DD56A524FC7@TWIX.dataventures.local>
	<21588.17944.611417.254485@max.nulle.part>
	<AA01911644A2F84FB4571C323FC45DD56A526B86@TWIX.dataventures.local>
Message-ID: <21589.3068.484673.618681@max.nulle.part>


Hi Mike,

Thanks for the follow-up -- if you glance at src/api.cpp you'll see that we
already conditionally exclude execinfo.h on a number of other platforms. I'll
look up the canonical define for Aix and will check back with you to test
this. I'm currently at a workshop so this may take a day or two.  But we will
get this sorted out in no time.

Cheers, Dirk

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From murdoch.duncan at gmail.com  Sat Nov  1 18:17:56 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 1 Nov 2014 13:17:56 -0400
Subject: [Rd] R 3.1.1 and 3.1.2 both fail their test suites
In-Reply-To: <87ioizndfa.fsf@write-only.cryp.to>
References: <87lhnvje7d.fsf@write-only.cryp.to>	<5454F2E6.9090301@statistik.tu-dortmund.de>
	<87ioizndfa.fsf@write-only.cryp.to>
Message-ID: <545515C4.2090900@gmail.com>

On 01/11/2014, 11:33 AM, Peter Simons wrote:
> Hi Uwe,
> 
>  > Nobody in R core runs NixOS and can reproduce this. This passes on most
>  > other platforms, apparently. If you can point us to a problem or send
>  > patches, we'd appreciate it.
> 
> have tried running the test suite in a build that's configured with
> '--without-recommended-packages'? That's about the only unusual thing we
> do when building with Nix. Other than that, our build runs on a
> perfectly ordinary Linux -- and it used to succeed fine in earlier
> versions of R.

The tests "make check-devel" and "make check-all" are documented to
require the recommended packages, and will fail without them.  On
Windows, "make check" also needs them, so this may be true on other
systems as well.

Duncan Murdoch


From ligges at statistik.tu-dortmund.de  Sat Nov  1 18:53:10 2014
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sat, 1 Nov 2014 18:53:10 +0100
Subject: [Rd] R 3.1.1 and 3.1.2 both fail their test suites
In-Reply-To: <87ioizndfa.fsf@write-only.cryp.to>
References: <87lhnvje7d.fsf@write-only.cryp.to>	<5454F2E6.9090301@statistik.tu-dortmund.de>
	<87ioizndfa.fsf@write-only.cryp.to>
Message-ID: <54551E06.8060605@statistik.tu-dortmund.de>



On 01.11.2014 16:33, Peter Simons wrote:
> Hi Uwe,
>
>   > Nobody in R core runs NixOS and can reproduce this. This passes on most
>   > other platforms, apparently. If you can point us to a problem or send
>   > patches, we'd appreciate it.
>
> have tried running the test suite in a build that's configured with
> '--without-recommended-packages'?

Of course this fails in the case when we check for the recommended packages:

   | < character(0)
   | ---
   | > [1] "Matrix" "nlme"   "mgcv"

If Matrix et al are not there, they can't be reported to be there, of 
course...

Best,
Uwe Ligges


> That's about the only unusual thing we
> do when building with Nix. Other than that, our build runs on a
> perfectly ordinary Linux -- and it used to succeed fine in earlier
> versions of R.
>
> Best regards,
> Peter
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From simons at cryp.to  Sat Nov  1 19:58:23 2014
From: simons at cryp.to (Peter Simons)
Date: Sat, 1 Nov 2014 19:58:23 +0100
Subject: [Rd] R 3.1.1 and 3.1.2 both fail their test suites
References: <87lhnvje7d.fsf@write-only.cryp.to>
	<5454F2E6.9090301@statistik.tu-dortmund.de>
	<87ioizndfa.fsf@write-only.cryp.to>
	<54551E06.8060605@statistik.tu-dortmund.de>
Message-ID: <87lhnuvjcg.fsf@write-only.cryp.to>

Hi Uwe,

 >> have tried running the test suite in a build that's configured with
 >> '--without-recommended-packages'?
 >
 > Of course this fails in the case when we check for the recommended packages:
 >
 >   | < character(0)
 >   | ---
 >   | > [1] "Matrix" "nlme"   "mgcv"
 >
 > If Matrix et al are not there, they can't be reported to be there, of
 > course...

maybe that test could be made a little bit smarter to deal with the
seemingly legit use-case of passing --without-recommended-packages?

Best regards,
Peter


From murdoch.duncan at gmail.com  Sun Nov  2 01:21:40 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 1 Nov 2014 20:21:40 -0400
Subject: [Rd] R 3.1.1 and 3.1.2 both fail their test suites
In-Reply-To: <87lhnuvjcg.fsf@write-only.cryp.to>
References: <87lhnvje7d.fsf@write-only.cryp.to>	<5454F2E6.9090301@statistik.tu-dortmund.de>	<87ioizndfa.fsf@write-only.cryp.to>	<54551E06.8060605@statistik.tu-dortmund.de>
	<87lhnuvjcg.fsf@write-only.cryp.to>
Message-ID: <54557914.7020309@gmail.com>

On 01/11/2014, 2:58 PM, Peter Simons wrote:
> Hi Uwe,
> 
>  >> have tried running the test suite in a build that's configured with
>  >> '--without-recommended-packages'?
>  >
>  > Of course this fails in the case when we check for the recommended packages:
>  >
>  >   | < character(0)
>  >   | ---
>  >   | > [1] "Matrix" "nlme"   "mgcv"
>  >
>  > If Matrix et al are not there, they can't be reported to be there, of
>  > course...
> 
> maybe that test could be made a little bit smarter to deal with the
> seemingly legit use-case of passing --without-recommended-packages?

The documentation is ambiguous, but certainly it would be easier to
clarify it than to change this.

Duncan Murdoch


From mtmorgan at fredhutch.org  Sun Nov  2 01:44:10 2014
From: mtmorgan at fredhutch.org (Martin Morgan)
Date: Sat, 01 Nov 2014 17:44:10 -0700
Subject: [Rd] package vignettes build in the same R process?
Message-ID: <54557E5A.7090800@fredhutch.org>

If I understand correctly, all vignettes in a package are built in the same R 
process. Global options, loaded packages, etc., in an earlier vignette persist 
in later vignettes. This can introduce user confusion (e.g., when a later 
vignette builds successfully because a package is require()'ed in an earlier 
vignette, but not the current one), difficult-to-identify bugs (e.g., when
a setting in an earlier vignette influences calculation in a latter vignette), 
and misleading information about reproducibility (e.g., when the sessionInfo() 
of a later vignette reflects packages used in earlier vignettes).

I believe the relevant code is at

src/library/tools/R/Vignettes.R:505

         output <- tryCatch({
             ## FIXME: run this in a separate process
             engine$weave(file, quiet = quiet)
             setwd(startdir)
             find_vignette_product(name, by = "weave", engine = engine)
         }, error = function(e) {
             stop(gettextf("processing vignette '%s' failed with diagnostics:\n%s",
                  file, conditionMessage(e)), domain = NA, call. = FALSE)
         })

Is building of each vignette in separate processes a reasonable feature request?

Martin
-- 
Computational Biology / Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N.
PO Box 19024 Seattle, WA 98109

Location: Arnold Building M1 B861
Phone: (206) 667-2793


From edd at debian.org  Sun Nov  2 02:15:38 2014
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sat, 1 Nov 2014 20:15:38 -0500
Subject: [Rd] Trouble installing Rcpp on AIX - missing "execinfo.h"
In-Reply-To: <21589.3068.484673.618681@max.nulle.part>
References: <AA01911644A2F84FB4571C323FC45DD56A524FC7@TWIX.dataventures.local>
	<21588.17944.611417.254485@max.nulle.part>
	<AA01911644A2F84FB4571C323FC45DD56A526B86@TWIX.dataventures.local>
	<21589.3068.484673.618681@max.nulle.part>
Message-ID: <21589.34234.836664.806059@max.nulle.part>


Mike,

On 1 November 2014 at 11:36, Dirk Eddelbuettel wrote:
| Thanks for the follow-up -- if you glance at src/api.cpp you'll see that we
| already conditionally exclude execinfo.h on a number of other platforms. I'll
| look up the canonical define for Aix and will check back with you to test
| this. I'm currently at a workshop so this may take a day or two.  But we will
| get this sorted out in no time.

I committed that, so you can now check again Rcpp as on GitHub.

Dirk

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From january.weiner at gmail.com  Sun Nov  2 12:20:19 2014
From: january.weiner at gmail.com (January Weiner)
Date: Sun, 2 Nov 2014 12:20:19 +0100
Subject: [Rd] =?utf-8?b?QnVpbGRpbmcgUiBwYWNrYWdlOiDigJxGb3VuZCAncmFuZCcs?=
	=?utf-8?q?_possibly_from_=27rand=27_=28C=29=E2=80=9D_NOTE_when_che?=
	=?utf-8?q?cking_package?=
Message-ID: <CA+A1kV4tt9JWMN0HjVjeDNMbdMS0UYkpPmDU189FHBmE_O6gTQ@mail.gmail.com>

I am building a package that makes a simple visualization. A part of
the code is in C++, and utilizes the functions srand() and rand() for
purposes not related to statistics (introducing random noise in the
visualization). The package compiles without problems on my
workstation(s), but when I submitted it to the winbuilder service, I
got the following weird message:

* checking compiled code ... NOTE
File 'tagcloud/libs/i386/tagcloud.dll':
  Found 'rand', possibly from 'rand' (C)
    Object: 'overlap.o'
  Found 'srand', possibly from 'srand' (C)
    Object: 'overlap.o'
File 'tagcloud/libs/x64/tagcloud.dll':
  Found 'rand', possibly from 'rand' (C)
    Object: 'overlap.o'
  Found 'srand', possibly from 'srand' (C)
    Object: 'overlap.o'

Compiled code should not call entry points which might terminate R nor
write to stdout/stderr instead of to the console, nor the C RNG.

To the best of my knowledge, I don't see where in the code I "call
entry points which might terminate R" or "write to stdout/stderr", but
then, if I remove the calls to rand/srand, this message disappears.

You can review the package here:
http://win-builder.r-project.org/toy6frr57aCU/

Kind regards,

January

-- 
-------- January Weiner --------------------------------------


From bhh at xs4all.nl  Sun Nov  2 12:40:14 2014
From: bhh at xs4all.nl (Berend Hasselman)
Date: Sun, 2 Nov 2014 12:40:14 +0100
Subject: [Rd]
 =?windows-1252?q?Building_R_package=3A_=93Found_=27rand=27?=
 =?windows-1252?q?=2C_possibly_from_=27rand=27_=28C=29=94_NOTE_when_checki?=
 =?windows-1252?q?ng_package?=
In-Reply-To: <CA+A1kV4tt9JWMN0HjVjeDNMbdMS0UYkpPmDU189FHBmE_O6gTQ@mail.gmail.com>
References: <CA+A1kV4tt9JWMN0HjVjeDNMbdMS0UYkpPmDU189FHBmE_O6gTQ@mail.gmail.com>
Message-ID: <3265701A-0465-4D10-8DD2-C5FF4D10F9E2@xs4all.nl>


On 02-11-2014, at 12:20, January Weiner <january.weiner at gmail.com> wrote:

> I am building a package that makes a simple visualization. A part of
> the code is in C++, and utilizes the functions srand() and rand() for
> purposes not related to statistics (introducing random noise in the
> visualization). The package compiles without problems on my
> workstation(s), but when I submitted it to the winbuilder service, I
> got the following weird message:
> 
> * checking compiled code ... NOTE
> File 'tagcloud/libs/i386/tagcloud.dll':
>  Found 'rand', possibly from 'rand' (C)
>    Object: 'overlap.o'
>  Found 'srand', possibly from 'srand' (C)
>    Object: 'overlap.o'
> File 'tagcloud/libs/x64/tagcloud.dll':
>  Found 'rand', possibly from 'rand' (C)
>    Object: 'overlap.o'
>  Found 'srand', possibly from 'srand' (C)
>    Object: 'overlap.o'
> 
> Compiled code should not call entry points which might terminate R nor
> write to stdout/stderr instead of to the console, nor the C RNG.
> 
> To the best of my knowledge, I don't see where in the code I "call
> entry points which might terminate R" or "write to stdout/stderr", but
> then, if I remove the calls to rand/srand, this message disappears.
> 

Which version of R on your workstation?
Your code should also not call the C RNG (rand and srand) as the message clearly states.

Berend

> You can review the package her:e
> http://win-builder.r-project.org/toy6frr57aCU/
> 
> Kind regards,
> 
> January
> 
> -- 
> -------- January Weiner --------------------------------------
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From ligges at statistik.tu-dortmund.de  Sun Nov  2 13:53:45 2014
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sun, 02 Nov 2014 13:53:45 +0100
Subject: [Rd]
 =?utf-8?b?QnVpbGRpbmcgUiBwYWNrYWdlOiDigJxGb3VuZCAncmFuZCcs?=
 =?utf-8?q?_possibly_from_=27rand=27_=28C=29=E2=80=9D_NOTE_when_checking_p?=
 =?utf-8?q?ackage?=
In-Reply-To: <3265701A-0465-4D10-8DD2-C5FF4D10F9E2@xs4all.nl>
References: <CA+A1kV4tt9JWMN0HjVjeDNMbdMS0UYkpPmDU189FHBmE_O6gTQ@mail.gmail.com>
	<3265701A-0465-4D10-8DD2-C5FF4D10F9E2@xs4all.nl>
Message-ID: <54562959.3000904@statistik.tu-dortmund.de>



On 02.11.2014 12:40, Berend Hasselman wrote:
>
> On 02-11-2014, at 12:20, January Weiner <january.weiner at gmail.com> wrote:
>
>> I am building a package that makes a simple visualization. A part of
>> the code is in C++, and utilizes the functions srand() and rand() for
>> purposes not related to statistics (introducing random noise in the
>> visualization). The package compiles without problems on my
>> workstation(s), but when I submitted it to the winbuilder service, I
>> got the following weird message:
>>
>> * checking compiled code ... NOTE
>> File 'tagcloud/libs/i386/tagcloud.dll':
>>   Found 'rand', possibly from 'rand' (C)
>>     Object: 'overlap.o'
>>   Found 'srand', possibly from 'srand' (C)
>>     Object: 'overlap.o'
>> File 'tagcloud/libs/x64/tagcloud.dll':
>>   Found 'rand', possibly from 'rand' (C)
>>     Object: 'overlap.o'
>>   Found 'srand', possibly from 'srand' (C)
>>     Object: 'overlap.o'
>>
>> Compiled code should not call entry points which might terminate R nor
>> write to stdout/stderr instead of to the console, nor the C RNG.
>>
>> To the best of my knowledge, I don't see where in the code I "call
>> entry points which might terminate R" or "write to stdout/stderr", but
>> then, if I remove the calls to rand/srand, this message disappears.
>>
>
> Which version of R on your workstation?
> Your code should also not call the C RNG (rand and srand) as the message clearly states.


Right: set.seed() only controls R'd RNG, hence use that one so that your 
users can conveniently reproduce their visualizations with your package.

Best,
Uwe Ligges


> Berend
>
>> You can review the package her:e
>> http://win-builder.r-project.org/toy6frr57aCU/
>>
>> Kind regards,
>>
>> January
>>
>> --
>> -------- January Weiner --------------------------------------
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From january.weiner at gmail.com  Sun Nov  2 14:15:34 2014
From: january.weiner at gmail.com (January Weiner)
Date: Sun, 2 Nov 2014 14:15:34 +0100
Subject: [Rd]
	=?utf-8?b?QnVpbGRpbmcgUiBwYWNrYWdlOiDigJxGb3VuZCAncmFuZCcs?=
	=?utf-8?q?_possibly_from_=27rand=27_=28C=29=E2=80=9D_NOTE_when_che?=
	=?utf-8?q?cking_package?=
In-Reply-To: <3265701A-0465-4D10-8DD2-C5FF4D10F9E2@xs4all.nl>
References: <CA+A1kV4tt9JWMN0HjVjeDNMbdMS0UYkpPmDU189FHBmE_O6gTQ@mail.gmail.com>
	<3265701A-0465-4D10-8DD2-C5FF4D10F9E2@xs4all.nl>
Message-ID: <CA+A1kV7807RXQpD0Uqgz2D-uis27jYf9B5h8U4cDUwzboK2T3Q@mail.gmail.com>

Dear Berend,

thank you for your kind response. You are right, and I am blind. I
will use the R RNG instead.

Kind regards,

j.


On 2 November 2014 12:40, Berend Hasselman <bhh at xs4all.nl> wrote:
>
> On 02-11-2014, at 12:20, January Weiner <january.weiner at gmail.com> wrote:
>
>> I am building a package that makes a simple visualization. A part of
>> the code is in C++, and utilizes the functions srand() and rand() for
>> purposes not related to statistics (introducing random noise in the
>> visualization). The package compiles without problems on my
>> workstation(s), but when I submitted it to the winbuilder service, I
>> got the following weird message:
>>
>> * checking compiled code ... NOTE
>> File 'tagcloud/libs/i386/tagcloud.dll':
>>  Found 'rand', possibly from 'rand' (C)
>>    Object: 'overlap.o'
>>  Found 'srand', possibly from 'srand' (C)
>>    Object: 'overlap.o'
>> File 'tagcloud/libs/x64/tagcloud.dll':
>>  Found 'rand', possibly from 'rand' (C)
>>    Object: 'overlap.o'
>>  Found 'srand', possibly from 'srand' (C)
>>    Object: 'overlap.o'
>>
>> Compiled code should not call entry points which might terminate R nor
>> write to stdout/stderr instead of to the console, nor the C RNG.
>>
>> To the best of my knowledge, I don't see where in the code I "call
>> entry points which might terminate R" or "write to stdout/stderr", but
>> then, if I remove the calls to rand/srand, this message disappears.
>>
>
> Which version of R on your workstation?
> Your code should also not call the C RNG (rand and srand) as the message clearly states.
>
> Berend
>
>> You can review the package her:e
>> http://win-builder.r-project.org/toy6frr57aCU/
>>
>> Kind regards,
>>
>> January
>>
>> --
>> -------- January Weiner --------------------------------------
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>



-- 
-------- January Weiner --------------------------------------


From murdoch.duncan at gmail.com  Sun Nov  2 16:10:05 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 02 Nov 2014 10:10:05 -0500
Subject: [Rd] package vignettes build in the same R process?
In-Reply-To: <54557E5A.7090800@fredhutch.org>
References: <54557E5A.7090800@fredhutch.org>
Message-ID: <5456494D.9020702@gmail.com>

On 01/11/2014, 8:44 PM, Martin Morgan wrote:
> If I understand correctly, all vignettes in a package are built in the same R 
> process. Global options, loaded packages, etc., in an earlier vignette persist 
> in later vignettes. This can introduce user confusion (e.g., when a later 
> vignette builds successfully because a package is require()'ed in an earlier 
> vignette, but not the current one), difficult-to-identify bugs (e.g., when
> a setting in an earlier vignette influences calculation in a latter vignette), 
> and misleading information about reproducibility (e.g., when the sessionInfo() 
> of a later vignette reflects packages used in earlier vignettes).
> 
> I believe the relevant code is at
> 
> src/library/tools/R/Vignettes.R:505
> 
>          output <- tryCatch({
>              ## FIXME: run this in a separate process
>              engine$weave(file, quiet = quiet)
>              setwd(startdir)
>              find_vignette_product(name, by = "weave", engine = engine)
>          }, error = function(e) {
>              stop(gettextf("processing vignette '%s' failed with diagnostics:\n%s",
>                   file, conditionMessage(e)), domain = NA, call. = FALSE)
>          })
> 
> Is building of each vignette in separate processes a reasonable feature request?

I'm not sure.  It's not perfect:  users may still see different output
than the package contains, because when they run the vignette it will
see their system state, but at least it gives them a way to get the
identical output.  On the other hand, they already have a way to do
that:  just build the whole package.  Overall I'd say it's probably a
good idea.

I would prefer a way to detect and warn when vignette output depends on
the state outside the vignette, but that looks hard to do.

Duncan Murdoch


From sleepingwell at gmail.com  Mon Nov  3 04:55:36 2014
From: sleepingwell at gmail.com (Simon Knapp)
Date: Mon, 3 Nov 2014 14:55:36 +1100
Subject: [Rd] Holding a large number of SEXPs in C++
In-Reply-To: <5E3A097A-6872-49C7-8B49-AD3F71D7947B@r-project.org>
References: <CAA+5f=1dGHT4EE51WAUg75x+MmimYBW0aWmdsXvtGRpHZ5_b=A@mail.gmail.com>
	<5E3A097A-6872-49C7-8B49-AD3F71D7947B@r-project.org>
Message-ID: <CAA+5f=0YXYPmiBCwUwwOdJnSmfkuNJyu66giWXLBiOgTKxy5hQ@mail.gmail.com>

Thanks Simon and sorry for taking so long to give this a go. I had thought
of pair lists but got confused about how to protect the top level object
only, as it seems that appending requires creating a new "top-level
object". The following example seems to work (full example at
https://gist.github.com/Sleepingwell/8588c5ee844ce0242d05). Is this the way
you would do it (or at least 'a correct' way)?



struct PolyHolder {
    PolyHolder(void) {
        PROTECT_WITH_INDEX(currentRegion = R_NilValue, &icr);
        PROTECT_WITH_INDEX(regions = R_NilValue, &ir);
    }

    ~PolyHolder(void) {
        UNPROTECT(2);
    }

    void notifyEndRegion(void) {
        REPROTECT(regions = CONS(makePolygonsFromPairList(currentRegion),
regions), ir);
        REPROTECT(currentRegion = R_NilValue, icr);
    }

    template<typename Iter>
    void addSubPolygon(Iter b, Iter e) {
        REPROTECT(currentRegion = CONS(makePolygon(b, e), currentRegion),
icr);
    }

    SEXP getPolygons(void) {
        return regions;
    }

private:
    PROTECT_INDEX
        ir,
        icr;

    SEXP
        currentRegion,
        regions;
};



Thanks again,
Simon Knapp



CONS(newPoly, creates a new object
On Sat, Oct 18, 2014 at 2:10 AM, Simon Urbanek <simon.urbanek at r-project.org>
wrote:

>
> On Oct 17, 2014, at 7:31 AM, Simon Knapp <sleepingwell at gmail.com> wrote:
>
> > Background:
> > I have an algorithm which produces a large number of small polygons (of
> the
> > spatial kind) which I would like to use within R using objects from sp. I
> > can't predict the exact number of polygons a-priori, the polygons will be
> > grouped into regions, and each region will be filled sequentially, so an
> > appropriate C++ 'framework' (for the point of illustration) might be:
> >
> > typedef std::pair<double, double> Point;
> > typedef std::vector<Point> Polygon;
> > typedef std::vector<Polygon> Polygons;
> > typedef std::vector<Polygons> Regions;
> >
> > struct Holder {
> >    void notifyNewRegion(void) const {
> >        regions.push_back(Polygons());
> >    }
> >
> >    template<typename Iter>
> >    void addSubPoly(Iter b, Iter e) {
> >        regions.back().push_back(Polygon(b, e));
> >    }
> >
> > private:
> >    Regions regions;
> > };
> >
> > where the reference_type of Iter is convertible to Point. In practice I
> use
> > pointers in a couple of places to avoid resizing in push_back becoming
> too
> > expensive.
> >
> > To construct the corresponding sp::Polygon, sp::Polygons and
> > sp::SpatialPolygons at the end of the algorithm, I iterate over the
> result
> > turning each Polygon into a two column matrix and calling the C functions
> > corresponding to the 'constructors' for these objects.
> >
> > This is all working fine, but I could cut my memory consumption in half
> if
> > I could construct the sp::Polygon objects in addSubPoly, and the
> > sp::Polygons objects in notifyNewRegion. My vector typedefs would then
> all
> > be:
> >
> > typedef std::vector<SEXP>
> >
> >
> >
> >
> > Question:
> > What I'm not sure about (and finally my question) is: I will have
> datasets
> > where I have more than 10,000 SEXPs in the Polygon and Polygons objects
> for
> > a single region, and possibly more than 10,000 regions, so how do I
> PROTECT
> > all those SEXPs (noting that the protection stack is limited to 10,000
> and
> > bearing in mind that I don't know how many there will be before I start)?
> >
> > I am also interested in this just out of general curiosity.
> >
> >
> >
> >
> > Thoughts:
> >
> > 1) I could create an environment and store the objects themselves in
> there
> > while keeping pointers in the vectors, but am not sure if this would be
> > that efficient (guidance would be appreciated), or
> >
> > 2) Just keep them in R vectors and grow these myself (as push_back is
> doing
> > for me in the above), but that sounds like a pain and I'm not sure if the
> > objects or just the pointers would be copied when I reassigned things
> > (guidance would be appreciated again). Bare in mind that I keep pointers
> in
> > the vectors, but omitted that for the sake of clarity.
> >
> >
> >
> >
> > Is there some other R type that would be suited to this, or a general
> > approach?
> >
>
> Lists in R (LISTSXP aka pairlists) are suited to appending (since that is
> fast and trivial) and sequential processing. The only issue is that
> pairlists are slow for random access. If you only want to load the polygons
> and finalize, then you can hold them in a pairlist and at the end copy to a
> generic vector (if random access is expected). DB applications typically
> use a hybrid approach -  allocate vector blocks and keep them in pairlists,
> but that's probably an overkill for your use (if you really cared about
> performance you wouldn't use sp objects for this ;))
>
> Note that you only have to protect the top-level object, so you don't need
> to protect the individual elements.
>
> Cheers,
> Simon
>
>
> > Cheers and thanks in advance,
> > Simon Knapp
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
>
>

	[[alternative HTML version deleted]]


From maechler at stat.math.ethz.ch  Mon Nov  3 10:17:17 2014
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 3 Nov 2014 10:17:17 +0100
Subject: [Rd] R 3.1.1 and 3.1.2 both fail their test suites
In-Reply-To: <545515C4.2090900@gmail.com>
References: <87lhnvje7d.fsf@write-only.cryp.to>
	<5454F2E6.9090301@statistik.tu-dortmund.de>
	<87ioizndfa.fsf@write-only.cryp.to> <545515C4.2090900@gmail.com>
Message-ID: <21591.18461.92369.277925@stat.math.ethz.ch>

>>>>> Duncan Murdoch <murdoch.duncan at gmail.com>
>>>>>     on Sat, 1 Nov 2014 13:17:56 -0400 writes:

    > On 01/11/2014, 11:33 AM, Peter Simons wrote:
    >> Hi Uwe,
    >> 
    >> > Nobody in R core runs NixOS and can reproduce
    >> this. This passes on most > other platforms,
    >> apparently. If you can point us to a problem or send >
    >> patches, we'd appreciate it.
    >> 
    >> have tried running the test suite in a build that's
    >> configured with '--without-recommended-packages'? That's
    >> about the only unusual thing we do when building with
    >> Nix. Other than that, our build runs on a perfectly
    >> ordinary Linux -- and it used to succeed fine in earlier
    >> versions of R.

    > The tests "make check-devel" and "make check-all" are
    > documented to require the recommended packages, and will
    > fail without them.  On Windows, "make check" also needs
    > them, so this may be true on other systems as well.

Thank you Duncan, for clarifying (above and later in the thread).

Would it be hard to strive for

    1)  'make check' should pass without-rec....
    2)  'make check-devel' etc do require the recommended packages.

That would be ideal I think - and correspond to the fact that
we call the recommended packages 'recommended' only.

OTOH, if '1)' is too much work for us, we could add this as a
      'wishlist' item  and wait for someone to send patches..

Martin


From murdoch.duncan at gmail.com  Mon Nov  3 12:28:19 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 3 Nov 2014 06:28:19 -0500
Subject: [Rd] R 3.1.1 and 3.1.2 both fail their test suites
In-Reply-To: <21591.18461.92369.277925@stat.math.ethz.ch>
References: <87lhnvje7d.fsf@write-only.cryp.to>	<5454F2E6.9090301@statistik.tu-dortmund.de>	<87ioizndfa.fsf@write-only.cryp.to>	<545515C4.2090900@gmail.com>
	<21591.18461.92369.277925@stat.math.ethz.ch>
Message-ID: <545766D3.9050809@gmail.com>

On 03/11/2014, 4:17 AM, Martin Maechler wrote:
>>>>>> Duncan Murdoch <murdoch.duncan at gmail.com>
>>>>>>     on Sat, 1 Nov 2014 13:17:56 -0400 writes:
> 
>     > On 01/11/2014, 11:33 AM, Peter Simons wrote:
>     >> Hi Uwe,
>     >> 
>     >> > Nobody in R core runs NixOS and can reproduce
>     >> this. This passes on most > other platforms,
>     >> apparently. If you can point us to a problem or send >
>     >> patches, we'd appreciate it.
>     >> 
>     >> have tried running the test suite in a build that's
>     >> configured with '--without-recommended-packages'? That's
>     >> about the only unusual thing we do when building with
>     >> Nix. Other than that, our build runs on a perfectly
>     >> ordinary Linux -- and it used to succeed fine in earlier
>     >> versions of R.
> 
>     > The tests "make check-devel" and "make check-all" are
>     > documented to require the recommended packages, and will
>     > fail without them.  On Windows, "make check" also needs
>     > them, so this may be true on other systems as well.
> 
> Thank you Duncan, for clarifying (above and later in the thread).
> 
> Would it be hard to strive for
> 
>     1)  'make check' should pass without-rec....
>     2)  'make check-devel' etc do require the recommended packages.
> 
> That would be ideal I think - and correspond to the fact that
> we call the recommended packages 'recommended' only.

I think we could avoid errors in make check, but not warnings.  People
need to understand what the tests are testing, and recognize that some
warnings are ignorable.

To do this, we'd need to make sure that no examples in base packages
require the use of recommended packages.  Currently the failure happens
in capture.output, because it runs the glm example which needs MASS.
(The glm example is marked not to need MASS during testing, but the
capture.output example runs everything.)  Fixing that one causes the
error to happen later.


> OTOH, if '1)' is too much work for us, we could add this as a
>       'wishlist' item  and wait for someone to send patches..

Alternatively, we could require the recommended packages for all tests.

Duncan Murdoch

Duncan Murdoch


From simon.urbanek at r-project.org  Mon Nov  3 14:47:56 2014
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Mon, 3 Nov 2014 08:47:56 -0500
Subject: [Rd] Holding a large number of SEXPs in C++
In-Reply-To: <CAA+5f=0YXYPmiBCwUwwOdJnSmfkuNJyu66giWXLBiOgTKxy5hQ@mail.gmail.com>
References: <CAA+5f=1dGHT4EE51WAUg75x+MmimYBW0aWmdsXvtGRpHZ5_b=A@mail.gmail.com>
	<5E3A097A-6872-49C7-8B49-AD3F71D7947B@r-project.org>
	<CAA+5f=0YXYPmiBCwUwwOdJnSmfkuNJyu66giWXLBiOgTKxy5hQ@mail.gmail.com>
Message-ID: <DE5D8D60-8B4B-4879-A283-B52971496A1B@r-project.org>


On Nov 2, 2014, at 10:55 PM, Simon Knapp <sleepingwell at gmail.com> wrote:

> Thanks Simon and sorry for taking so long to give this a go. I had thought of pair lists but got confused about how to protect the top level object only, as it seems that appending requires creating a new "top-level object". The following example seems to work (full example at https://gist.github.com/Sleepingwell/8588c5ee844ce0242d05). Is this the way you would do it (or at least 'a correct' way)?
> 

You can simply append to a pairlist, so you only need to protect the head. Also note that R_NilValue is a constant (in R sense, not C sense) so it doesn't need protection. I would write a generic pairlist builder something like that:

SEXP head = R_NilValue, tail;

void append(SEXP x) {
  if (head == R_NilValue)
	R_PreserveObject(head = tail = CONS(x, R_NilValue));
  else
	tail = SETCDR(tail, CONS(x, R_NilValue));
}

void destroy() {
   if (head != R_NilValue)
	R_ReleaseObject(head);
}      

Cheers,
Simon


> 
> 
> struct PolyHolder {
>     PolyHolder(void) {
>         PROTECT_WITH_INDEX(currentRegion = R_NilValue, &icr);
>         PROTECT_WITH_INDEX(regions = R_NilValue, &ir);
>     }
> 
>     ~PolyHolder(void) {
>         UNPROTECT(2);
>     }
> 
>     void notifyEndRegion(void) {
>         REPROTECT(regions = CONS(makePolygonsFromPairList(currentRegion), regions), ir);
>         REPROTECT(currentRegion = R_NilValue, icr);
>     }
> 
>     template<typename Iter>
>     void addSubPolygon(Iter b, Iter e) {
>         REPROTECT(currentRegion = CONS(makePolygon(b, e), currentRegion), icr);
>     }
> 
>     SEXP getPolygons(void) {
>         return regions;
>     }
> 
> private:
>     PROTECT_INDEX
>         ir,
>         icr;
> 
>     SEXP
>         currentRegion,
>         regions;
> };
> 
> 
> 
> Thanks again,
> Simon Knapp
> 
> 
> 
> CONS(newPoly, creates a new object 
> On Sat, Oct 18, 2014 at 2:10 AM, Simon Urbanek <simon.urbanek at r-project.org> wrote:
> 
> On Oct 17, 2014, at 7:31 AM, Simon Knapp <sleepingwell at gmail.com> wrote:
> 
> > Background:
> > I have an algorithm which produces a large number of small polygons (of the
> > spatial kind) which I would like to use within R using objects from sp. I
> > can't predict the exact number of polygons a-priori, the polygons will be
> > grouped into regions, and each region will be filled sequentially, so an
> > appropriate C++ 'framework' (for the point of illustration) might be:
> >
> > typedef std::pair<double, double> Point;
> > typedef std::vector<Point> Polygon;
> > typedef std::vector<Polygon> Polygons;
> > typedef std::vector<Polygons> Regions;
> >
> > struct Holder {
> >    void notifyNewRegion(void) const {
> >        regions.push_back(Polygons());
> >    }
> >
> >    template<typename Iter>
> >    void addSubPoly(Iter b, Iter e) {
> >        regions.back().push_back(Polygon(b, e));
> >    }
> >
> > private:
> >    Regions regions;
> > };
> >
> > where the reference_type of Iter is convertible to Point. In practice I use
> > pointers in a couple of places to avoid resizing in push_back becoming too
> > expensive.
> >
> > To construct the corresponding sp::Polygon, sp::Polygons and
> > sp::SpatialPolygons at the end of the algorithm, I iterate over the result
> > turning each Polygon into a two column matrix and calling the C functions
> > corresponding to the 'constructors' for these objects.
> >
> > This is all working fine, but I could cut my memory consumption in half if
> > I could construct the sp::Polygon objects in addSubPoly, and the
> > sp::Polygons objects in notifyNewRegion. My vector typedefs would then all
> > be:
> >
> > typedef std::vector<SEXP>
> >
> >
> >
> >
> > Question:
> > What I'm not sure about (and finally my question) is: I will have datasets
> > where I have more than 10,000 SEXPs in the Polygon and Polygons objects for
> > a single region, and possibly more than 10,000 regions, so how do I PROTECT
> > all those SEXPs (noting that the protection stack is limited to 10,000 and
> > bearing in mind that I don't know how many there will be before I start)?
> >
> > I am also interested in this just out of general curiosity.
> >
> >
> >
> >
> > Thoughts:
> >
> > 1) I could create an environment and store the objects themselves in there
> > while keeping pointers in the vectors, but am not sure if this would be
> > that efficient (guidance would be appreciated), or
> >
> > 2) Just keep them in R vectors and grow these myself (as push_back is doing
> > for me in the above), but that sounds like a pain and I'm not sure if the
> > objects or just the pointers would be copied when I reassigned things
> > (guidance would be appreciated again). Bare in mind that I keep pointers in
> > the vectors, but omitted that for the sake of clarity.
> >
> >
> >
> >
> > Is there some other R type that would be suited to this, or a general
> > approach?
> >
> 
> Lists in R (LISTSXP aka pairlists) are suited to appending (since that is fast and trivial) and sequential processing. The only issue is that pairlists are slow for random access. If you only want to load the polygons and finalize, then you can hold them in a pairlist and at the end copy to a generic vector (if random access is expected). DB applications typically use a hybrid approach -  allocate vector blocks and keep them in pairlists, but that's probably an overkill for your use (if you really cared about performance you wouldn't use sp objects for this ;))
> 
> Note that you only have to protect the top-level object, so you don't need to protect the individual elements.
> 
> Cheers,
> Simon
> 
> 
> > Cheers and thanks in advance,
> > Simon Knapp
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
> 
> 


From jorismeys at gmail.com  Mon Nov  3 16:07:43 2014
From: jorismeys at gmail.com (Joris Meys)
Date: Mon, 3 Nov 2014 16:07:43 +0100
Subject: [Rd] Unexplicable difference between 2 R installations regarding
	reading numbers
Message-ID: <CAO1zAVaszZavZc1X6ryLKSAb7s3z-vhrxNLCA7ahO+Oc=GxK0w@mail.gmail.com>

Dear all,

A colleague of mine reported a problem that I fail to understand
completely. He has a number of .csv files that look all very
straightforward, and they all read in perfectly well using read.csv() on
both his and my computer.

When we try the exact same R version on the university server however,
suddenly all numeric variables turn into factors. The problem is resolved
by deleting the last digits of every number in the .csv file.  Using
as.numeric() on the values works as well.

Anybody a clue as to what might cause this problem? If needed, I can send
an example of a .csv file.

Example output on server:

> X <- read.csv("Originelen/Originelen/heavymetals.csv")
> levels(X[[2]])
 [1] "11.140969600635804" "11.548972671055257" "11.98554898321271"
 [4] "16.317868213178677" "17.179218967921898" "18.596573461949852"
 [7] "18.786014405762298" "18.87978032658098"  "23.604106448719225"
[10] "26.75482955698816"  "27.33829851044687"  "29.26619704952923"
[13] "33.07842352705811"  "39.296270581233884" "4.8696848424212105"
[16] "5.5751725517655295" "6.0256909109049195" "9.117975845892804"
[19] "9.26944194868723"
> str(X)
'data.frame':   19 obs. of  18 variables:
 $ ID   : int  1 2 3 4 5 6 7 8 9 10 ...
 $ Cd5  : Factor w/ 19 levels "11.140969600635804",..: 3 8 6 12 11 10 2 5
14 13 ...
 $ Cd20 : Factor w/ 19 levels "10.160499999999999",..: 2 8 10 12 5 6 18 9
11 4 ...
 $ Cr5  : Factor w/ 19 levels "118.43421710855425",..: 6 11 10 17 16 15 7
13 19 18 ...
 $ Cr20 : Factor w/ 19 levels "100.48101898101898",..: 9 15 14 17 13 11 6
16 18 12 ...
 $ Cu5  : Factor w/ 19 levels "101.8005401620486",..: 8 17 16 15 14 12 9 18
19 1 ...
 $ Cu20 : Factor w/ 19 levels "103.67346938775509",..: 11 18 19 2 16 17 14
3 4 1 ...
 $ Fe5  : Factor w/ 19 levels "17239.349496158833",..: 3 8 10 9 12 14 7 16
19 18 ...
 $ Fe20 : Factor w/ 19 levels "17701.77893264042",..: 3 14 16 18 10 15 6 17
19 13 ...
 $ Mn5  : Factor w/ 19 levels "440.37211163349",..: 10 14 4 5 3 17 2 7 18 6
...
 $ Mn20 : Factor w/ 19 levels "375.19156134938805",..: 12 2 6 3 1 9 11 7 8
5 ...
 $ Ni5  : Factor w/ 19 levels "19.54255213010077",..: 4 12 8 10 11 16 6 14
19 18 ...
 $ Ni20 : Factor w/ 19 levels "21.295222866280234",..: 8 13 15 18 12 16 7
17 19 14 ...
 $ Pb5  : Factor w/ 19 levels "125.5616926977306",..: 1 11 14 9 13 8 5 12
15 16 ...
 $ Pb20 : Factor w/ 19 levels "106.96930306969303",..: 3 8 11 12 9 10 4 13
14 15 ...
 $ Zn5  : Factor w/ 19 levels "1024.909963985594",..: 17 4 7 5 8 3 18 6 9
10 ...
 $ Zn20 : Factor w/ 19 levels "1247.816195886593",..: 15 4 5 7 2 1 16 6 8 3
...
 $ river: int  1 1 1 1 1 1 1 1 1 1 ...

Using as.numeric(levels(X[[2]])) works perfectly fine though...

Session info both server and my own computer :

> sessionInfo()
R version 3.1.0 (2014-04-10)
Platform: x86_64-w64-mingw32/x64 (64-bit)

locale:
[1] LC_COLLATE=Dutch_Belgium.1252  LC_CTYPE=Dutch_Belgium.1252
[3] LC_MONETARY=Dutch_Belgium.1252 LC_NUMERIC=C
[5] LC_TIME=Dutch_Belgium.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] tools_3.1.0

-- 
Joris Meys
Statistical consultant

Ghent University
Faculty of Bioscience Engineering
Department of Mathematical Modelling, Statistics and Bio-Informatics

tel :  +32 (0)9 264 61 79
Joris.Meys at Ugent.be
-------------------------------
Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php

	[[alternative HTML version deleted]]


From simon.urbanek at r-project.org  Mon Nov  3 16:41:19 2014
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Mon, 3 Nov 2014 10:41:19 -0500
Subject: [Rd] Unexplicable difference between 2 R installations
	regarding reading numbers
In-Reply-To: <CAO1zAVaszZavZc1X6ryLKSAb7s3z-vhrxNLCA7ahO+Oc=GxK0w@mail.gmail.com>
References: <CAO1zAVaszZavZc1X6ryLKSAb7s3z-vhrxNLCA7ahO+Oc=GxK0w@mail.gmail.com>
Message-ID: <D1C9E11A-E50F-4D61-B64B-D7771B54176E@r-project.org>

R version.

NEWS for 3.1.0:

      type.convert() (and hence by default
      read.table() returns a character vector or factor when
      representing a numeric input as a double would lose accuracy.
      Similarly for complex inputs.

NEWS for 3.1.1:

      type.convert(), read.table() and similar
      read.*() functions get a new numerals argument,
      specifying how numeric input is converted when its conversion to
      double precision loses accuracy.  The default value,
      allow.loss allows accuracy loss, as in R versions before
      3.1.0.


On Nov 3, 2014, at 10:07 AM, Joris Meys <jorismeys at gmail.com> wrote:

> Dear all,
> 
> A colleague of mine reported a problem that I fail to understand
> completely. He has a number of .csv files that look all very
> straightforward, and they all read in perfectly well using read.csv() on
> both his and my computer.
> 
> When we try the exact same R version on the university server however,
> suddenly all numeric variables turn into factors. The problem is resolved
> by deleting the last digits of every number in the .csv file.  Using
> as.numeric() on the values works as well.
> 
> Anybody a clue as to what might cause this problem? If needed, I can send
> an example of a .csv file.
> 
> Example output on server:
> 
>> X <- read.csv("Originelen/Originelen/heavymetals.csv")
>> levels(X[[2]])
> [1] "11.140969600635804" "11.548972671055257" "11.98554898321271"
> [4] "16.317868213178677" "17.179218967921898" "18.596573461949852"
> [7] "18.786014405762298" "18.87978032658098"  "23.604106448719225"
> [10] "26.75482955698816"  "27.33829851044687"  "29.26619704952923"
> [13] "33.07842352705811"  "39.296270581233884" "4.8696848424212105"
> [16] "5.5751725517655295" "6.0256909109049195" "9.117975845892804"
> [19] "9.26944194868723"
>> str(X)
> 'data.frame':   19 obs. of  18 variables:
> $ ID   : int  1 2 3 4 5 6 7 8 9 10 ...
> $ Cd5  : Factor w/ 19 levels "11.140969600635804",..: 3 8 6 12 11 10 2 5
> 14 13 ...
> $ Cd20 : Factor w/ 19 levels "10.160499999999999",..: 2 8 10 12 5 6 18 9
> 11 4 ...
> $ Cr5  : Factor w/ 19 levels "118.43421710855425",..: 6 11 10 17 16 15 7
> 13 19 18 ...
> $ Cr20 : Factor w/ 19 levels "100.48101898101898",..: 9 15 14 17 13 11 6
> 16 18 12 ...
> $ Cu5  : Factor w/ 19 levels "101.8005401620486",..: 8 17 16 15 14 12 9 18
> 19 1 ...
> $ Cu20 : Factor w/ 19 levels "103.67346938775509",..: 11 18 19 2 16 17 14
> 3 4 1 ...
> $ Fe5  : Factor w/ 19 levels "17239.349496158833",..: 3 8 10 9 12 14 7 16
> 19 18 ...
> $ Fe20 : Factor w/ 19 levels "17701.77893264042",..: 3 14 16 18 10 15 6 17
> 19 13 ...
> $ Mn5  : Factor w/ 19 levels "440.37211163349",..: 10 14 4 5 3 17 2 7 18 6
> ...
> $ Mn20 : Factor w/ 19 levels "375.19156134938805",..: 12 2 6 3 1 9 11 7 8
> 5 ...
> $ Ni5  : Factor w/ 19 levels "19.54255213010077",..: 4 12 8 10 11 16 6 14
> 19 18 ...
> $ Ni20 : Factor w/ 19 levels "21.295222866280234",..: 8 13 15 18 12 16 7
> 17 19 14 ...
> $ Pb5  : Factor w/ 19 levels "125.5616926977306",..: 1 11 14 9 13 8 5 12
> 15 16 ...
> $ Pb20 : Factor w/ 19 levels "106.96930306969303",..: 3 8 11 12 9 10 4 13
> 14 15 ...
> $ Zn5  : Factor w/ 19 levels "1024.909963985594",..: 17 4 7 5 8 3 18 6 9
> 10 ...
> $ Zn20 : Factor w/ 19 levels "1247.816195886593",..: 15 4 5 7 2 1 16 6 8 3
> ...
> $ river: int  1 1 1 1 1 1 1 1 1 1 ...
> 
> Using as.numeric(levels(X[[2]])) works perfectly fine though...
> 
> Session info both server and my own computer :
> 
>> sessionInfo()
> R version 3.1.0 (2014-04-10)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> 
> locale:
> [1] LC_COLLATE=Dutch_Belgium.1252  LC_CTYPE=Dutch_Belgium.1252
> [3] LC_MONETARY=Dutch_Belgium.1252 LC_NUMERIC=C
> [5] LC_TIME=Dutch_Belgium.1252
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> loaded via a namespace (and not attached):
> [1] tools_3.1.0
> 
> -- 
> Joris Meys
> Statistical consultant
> 
> Ghent University
> Faculty of Bioscience Engineering
> Department of Mathematical Modelling, Statistics and Bio-Informatics
> 
> tel :  +32 (0)9 264 61 79
> Joris.Meys at Ugent.be
> -------------------------------
> Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From jorismeys at gmail.com  Mon Nov  3 17:06:40 2014
From: jorismeys at gmail.com (Joris Meys)
Date: Mon, 3 Nov 2014 17:06:40 +0100
Subject: [Rd] Unexplicable difference between 2 R installations
 regarding reading numbers
In-Reply-To: <D1C9E11A-E50F-4D61-B64B-D7771B54176E@r-project.org>
References: <CAO1zAVaszZavZc1X6ryLKSAb7s3z-vhrxNLCA7ahO+Oc=GxK0w@mail.gmail.com>
	<D1C9E11A-E50F-4D61-B64B-D7771B54176E@r-project.org>
Message-ID: <CAO1zAVYs4jebGVo4x8G=Pnm4ag4Htzmpbw5v7VrqW+DL6+VyBw@mail.gmail.com>

...and apparently I have 3.1.1 installed here, instead of 3.1.0 like on the
server. That illustrates very nicely the lack of coffee I experienced on
this monday.

Thank you!

On Mon, Nov 3, 2014 at 4:41 PM, Simon Urbanek <simon.urbanek at r-project.org>
wrote:

> R version.
>
> NEWS for 3.1.0:
>
>       type.convert() (and hence by default
>       read.table() returns a character vector or factor when
>       representing a numeric input as a double would lose accuracy.
>       Similarly for complex inputs.
>
> NEWS for 3.1.1:
>
>       type.convert(), read.table() and similar
>       read.*() functions get a new numerals argument,
>       specifying how numeric input is converted when its conversion to
>       double precision loses accuracy.  The default value,
>       allow.loss allows accuracy loss, as in R versions before
>       3.1.0.
>
>
> On Nov 3, 2014, at 10:07 AM, Joris Meys <jorismeys at gmail.com> wrote:
>
> > Dear all,
> >
> > A colleague of mine reported a problem that I fail to understand
> > completely. He has a number of .csv files that look all very
> > straightforward, and they all read in perfectly well using read.csv() on
> > both his and my computer.
> >
> > When we try the exact same R version on the university server however,
> > suddenly all numeric variables turn into factors. The problem is resolved
> > by deleting the last digits of every number in the .csv file.  Using
> > as.numeric() on the values works as well.
> >
> > Anybody a clue as to what might cause this problem? If needed, I can send
> > an example of a .csv file.
> >
> > Example output on server:
> >
> >> X <- read.csv("Originelen/Originelen/heavymetals.csv")
> >> levels(X[[2]])
> > [1] "11.140969600635804" "11.548972671055257" "11.98554898321271"
> > [4] "16.317868213178677" "17.179218967921898" "18.596573461949852"
> > [7] "18.786014405762298" "18.87978032658098"  "23.604106448719225"
> > [10] "26.75482955698816"  "27.33829851044687"  "29.26619704952923"
> > [13] "33.07842352705811"  "39.296270581233884" "4.8696848424212105"
> > [16] "5.5751725517655295" "6.0256909109049195" "9.117975845892804"
> > [19] "9.26944194868723"
> >> str(X)
> > 'data.frame':   19 obs. of  18 variables:
> > $ ID   : int  1 2 3 4 5 6 7 8 9 10 ...
> > $ Cd5  : Factor w/ 19 levels "11.140969600635804",..: 3 8 6 12 11 10 2 5
> > 14 13 ...
> > $ Cd20 : Factor w/ 19 levels "10.160499999999999",..: 2 8 10 12 5 6 18 9
> > 11 4 ...
> > $ Cr5  : Factor w/ 19 levels "118.43421710855425",..: 6 11 10 17 16 15 7
> > 13 19 18 ...
> > $ Cr20 : Factor w/ 19 levels "100.48101898101898",..: 9 15 14 17 13 11 6
> > 16 18 12 ...
> > $ Cu5  : Factor w/ 19 levels "101.8005401620486",..: 8 17 16 15 14 12 9
> 18
> > 19 1 ...
> > $ Cu20 : Factor w/ 19 levels "103.67346938775509",..: 11 18 19 2 16 17 14
> > 3 4 1 ...
> > $ Fe5  : Factor w/ 19 levels "17239.349496158833",..: 3 8 10 9 12 14 7 16
> > 19 18 ...
> > $ Fe20 : Factor w/ 19 levels "17701.77893264042",..: 3 14 16 18 10 15 6
> 17
> > 19 13 ...
> > $ Mn5  : Factor w/ 19 levels "440.37211163349",..: 10 14 4 5 3 17 2 7 18
> 6
> > ...
> > $ Mn20 : Factor w/ 19 levels "375.19156134938805",..: 12 2 6 3 1 9 11 7 8
> > 5 ...
> > $ Ni5  : Factor w/ 19 levels "19.54255213010077",..: 4 12 8 10 11 16 6 14
> > 19 18 ...
> > $ Ni20 : Factor w/ 19 levels "21.295222866280234",..: 8 13 15 18 12 16 7
> > 17 19 14 ...
> > $ Pb5  : Factor w/ 19 levels "125.5616926977306",..: 1 11 14 9 13 8 5 12
> > 15 16 ...
> > $ Pb20 : Factor w/ 19 levels "106.96930306969303",..: 3 8 11 12 9 10 4 13
> > 14 15 ...
> > $ Zn5  : Factor w/ 19 levels "1024.909963985594",..: 17 4 7 5 8 3 18 6 9
> > 10 ...
> > $ Zn20 : Factor w/ 19 levels "1247.816195886593",..: 15 4 5 7 2 1 16 6 8
> 3
> > ...
> > $ river: int  1 1 1 1 1 1 1 1 1 1 ...
> >
> > Using as.numeric(levels(X[[2]])) works perfectly fine though...
> >
> > Session info both server and my own computer :
> >
> >> sessionInfo()
> > R version 3.1.0 (2014-04-10)
> > Platform: x86_64-w64-mingw32/x64 (64-bit)
> >
> > locale:
> > [1] LC_COLLATE=Dutch_Belgium.1252  LC_CTYPE=Dutch_Belgium.1252
> > [3] LC_MONETARY=Dutch_Belgium.1252 LC_NUMERIC=C
> > [5] LC_TIME=Dutch_Belgium.1252
> >
> > attached base packages:
> > [1] stats     graphics  grDevices utils     datasets  methods   base
> >
> > loaded via a namespace (and not attached):
> > [1] tools_3.1.0
> >
> > --
> > Joris Meys
> > Statistical consultant
> >
> > Ghent University
> > Faculty of Bioscience Engineering
> > Department of Mathematical Modelling, Statistics and Bio-Informatics
> >
> > tel :  +32 (0)9 264 61 79
> > Joris.Meys at Ugent.be
> > -------------------------------
> > Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
>
>


-- 
Joris Meys
Statistical consultant

Ghent University
Faculty of Bioscience Engineering
Department of Mathematical Modelling, Statistics and Bio-Informatics

tel :  +32 (0)9 264 61 79
Joris.Meys at Ugent.be
-------------------------------
Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php

	[[alternative HTML version deleted]]


From rolandh at uni-muenster.de  Mon Nov  3 22:08:58 2014
From: rolandh at uni-muenster.de (rolandh at uni-muenster.de)
Date: Mon, 03 Nov 2014 22:08:58 +0100 (CET)
Subject: [Rd] Pkg creation: Sweave: multiple files vignette: Error in R CMD
	check
Message-ID: <permail-20141103210858fe5316b600004702-rolandh@message-id.uni-muenster.de>

Hello R-developers!

I am creating a package (using devtools and RStudio) and I would like to split
my vignette into multiple Rnw-files.

As an example I tried the code from:
https://support.rstudio.com/hc/en-us/articles/200486298
(--> Working with multiple Rnw files)

The Rnw-files work fine with "Complie pdf" in RStudio as well as with
Sweave("Master.Rnw").

But, if I try to check my package I get the following error:

...
* creating vignettes ... ERROR
Error in texi2dvi(file = file, pdf = TRUE, clean = clean, quiet = quiet,  :
  Ausf?hren von 'texi2dvi' f?r 'ChapterY.tex' fehlgeschlagen.
LaTeX errors:
! LaTeX Error: Missing \begin{document}.

See the LaTeX manual or LaTeX Companion for explanation.
Type  H <return>  for immediate help.
 ...
! Emergency stop.
<*> ...13 \let~\normaltilde  \input ./ChapterY.tex

*** (job aborted, no legal \end found)

!  ==> Fatal error occurred, no output PDF file produced!
Calls: <Anonymous> -> texi2pdf -> texi2dvi
Ausf?hrung angehalten
Fehler: Command failed (1)
Ausf?hrung angehalten

Exited with status 1.
###


So, it seems like that it is tried to make a tex-file from my child-Rnw-file
called "ChapterY.Rnw",
what of couse is not possible, because that file contains no praeambel.

As a workaround I tried to put my child-Rnw-file in a subfolder (ChapterY) and
calling this file by
\SweaveInput{ChapterY/ChapterY.Rnw}.
Again, "Complie pdf" as well as Sweave("Master.Rnw") works fine, but with
checking the package
I get the following error:

Error in SweaveReadFile(c(ifile, file), syntax, encoding = encoding) :
  no Sweave file with name ?./ChapterY/ChapterY.Rnw? found
ERROR: installing vignettes failed


By the way I tried that on different (L)ubuntu machines (12.04, 14) which the
latest version of
RStudio and R, and I also tried it after updating texlive to version 2012,
always getting the same error.

Moreover, if I just use one Rnw-file instaed of multiple files checking the
package finished fine without errors!

I do not know what to do anymore, and I did not find any solution in the www
...

Do someone has any idea how to solve this problem in any way?

Thank you very very much in advance!

Greetings!

Roland

###
R version 3.1.2 (2014-10-31)
Platform: i686-pc-linux-gnu (32-bit)

locale:
 [1] LC_CTYPE=de_DE.UTF-8       LC_NUMERIC=C               LC_TIME=de_DE.UTF-8
 LC_COLLATE=de_DE.UTF-8
 [5] LC_MONETARY=de_DE.UTF-8    LC_MESSAGES=de_DE.UTF-8
 LC_PAPER=de_DE.UTF-8       LC_NAME=C
 [9] LC_ADDRESS=C               LC_TELEPHONE=C
 LC_MEASUREMENT=de_DE.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] trajcoert01_0.1

loaded via a namespace (and not attached):
 [1] devtools_1.6       geosphere_1.3-8    grid_3.1.2         intervals_0.14.0
 lattice_0.20-29
 [6] move_1.2.475       raster_2.2-31      rgdal_0.8-16       rgeos_0.3-4
 sp_1.0-15
[11] spacetime_1.1-2    tools_3.1.2        trajectories_0.1-1 xts_0.9-7
zoo_1.7-11
###


From sleepingwell at gmail.com  Mon Nov  3 23:34:41 2014
From: sleepingwell at gmail.com (Simon Knapp)
Date: Tue, 4 Nov 2014 09:34:41 +1100
Subject: [Rd] Holding a large number of SEXPs in C++
In-Reply-To: <DE5D8D60-8B4B-4879-A283-B52971496A1B@r-project.org>
References: <CAA+5f=1dGHT4EE51WAUg75x+MmimYBW0aWmdsXvtGRpHZ5_b=A@mail.gmail.com>
	<5E3A097A-6872-49C7-8B49-AD3F71D7947B@r-project.org>
	<CAA+5f=0YXYPmiBCwUwwOdJnSmfkuNJyu66giWXLBiOgTKxy5hQ@mail.gmail.com>
	<DE5D8D60-8B4B-4879-A283-B52971496A1B@r-project.org>
Message-ID: <CAA+5f=1B7hvrFp9vmxp1+QZfLFLqiwnEE_781VVxu=ZVVqMAYg@mail.gmail.com>

Thanks again Simon. I had realised that R_NilValue didn't need
protection... I just thought it a clean way to make my initial call to
PROTECT_WITH_INDEX (which I can see now was not required since I didn't
need the calls to REPROTECT)... and I had not thought of appending to the
tail.

One final question (and hopefully I don't get to badly burnt) I cannot find
R_PreserveObject/R_ReleaseObject or SETCDR mentioned in "Writing R
Extensions". Is there anywhere for a novice like myself to find a
'complete' reference to Rs useful macros and functions, or do I just have
to read more source?

Thanks again for being so awesome,
Simon

On Tue, Nov 4, 2014 at 12:47 AM, Simon Urbanek <simon.urbanek at r-project.org>
wrote:

>
> On Nov 2, 2014, at 10:55 PM, Simon Knapp <sleepingwell at gmail.com> wrote:
>
> > Thanks Simon and sorry for taking so long to give this a go. I had
> thought of pair lists but got confused about how to protect the top level
> object only, as it seems that appending requires creating a new "top-level
> object". The following example seems to work (full example at
> https://gist.github.com/Sleepingwell/8588c5ee844ce0242d05). Is this the
> way you would do it (or at least 'a correct' way)?
> >
>
> You can simply append to a pairlist, so you only need to protect the head.
> Also note that R_NilValue is a constant (in R sense, not C sense) so it
> doesn't need protection. I would write a generic pairlist builder something
> like that:
>
> SEXP head = R_NilValue, tail;
>
> void append(SEXP x) {
>   if (head == R_NilValue)
>         R_PreserveObject(head = tail = CONS(x, R_NilValue));
>   else
>         tail = SETCDR(tail, CONS(x, R_NilValue));
> }
>
> void destroy() {
>    if (head != R_NilValue)
>         R_ReleaseObject(head);
> }
>
> Cheers,
> Simon
>
>
> >
> >
> > struct PolyHolder {
> >     PolyHolder(void) {
> >         PROTECT_WITH_INDEX(currentRegion = R_NilValue, &icr);
> >         PROTECT_WITH_INDEX(regions = R_NilValue, &ir);
> >     }
> >
> >     ~PolyHolder(void) {
> >         UNPROTECT(2);
> >     }
> >
> >     void notifyEndRegion(void) {
> >         REPROTECT(regions =
> CONS(makePolygonsFromPairList(currentRegion), regions), ir);
> >         REPROTECT(currentRegion = R_NilValue, icr);
> >     }
> >
> >     template<typename Iter>
> >     void addSubPolygon(Iter b, Iter e) {
> >         REPROTECT(currentRegion = CONS(makePolygon(b, e),
> currentRegion), icr);
> >     }
> >
> >     SEXP getPolygons(void) {
> >         return regions;
> >     }
> >
> > private:
> >     PROTECT_INDEX
> >         ir,
> >         icr;
> >
> >     SEXP
> >         currentRegion,
> >         regions;
> > };
> >
> >
> >
> > Thanks again,
> > Simon Knapp
> >
> >
> >
> > CONS(newPoly, creates a new object
> > On Sat, Oct 18, 2014 at 2:10 AM, Simon Urbanek <
> simon.urbanek at r-project.org> wrote:
> >
> > On Oct 17, 2014, at 7:31 AM, Simon Knapp <sleepingwell at gmail.com> wrote:
> >
> > > Background:
> > > I have an algorithm which produces a large number of small polygons
> (of the
> > > spatial kind) which I would like to use within R using objects from
> sp. I
> > > can't predict the exact number of polygons a-priori, the polygons will
> be
> > > grouped into regions, and each region will be filled sequentially, so
> an
> > > appropriate C++ 'framework' (for the point of illustration) might be:
> > >
> > > typedef std::pair<double, double> Point;
> > > typedef std::vector<Point> Polygon;
> > > typedef std::vector<Polygon> Polygons;
> > > typedef std::vector<Polygons> Regions;
> > >
> > > struct Holder {
> > >    void notifyNewRegion(void) const {
> > >        regions.push_back(Polygons());
> > >    }
> > >
> > >    template<typename Iter>
> > >    void addSubPoly(Iter b, Iter e) {
> > >        regions.back().push_back(Polygon(b, e));
> > >    }
> > >
> > > private:
> > >    Regions regions;
> > > };
> > >
> > > where the reference_type of Iter is convertible to Point. In practice
> I use
> > > pointers in a couple of places to avoid resizing in push_back becoming
> too
> > > expensive.
> > >
> > > To construct the corresponding sp::Polygon, sp::Polygons and
> > > sp::SpatialPolygons at the end of the algorithm, I iterate over the
> result
> > > turning each Polygon into a two column matrix and calling the C
> functions
> > > corresponding to the 'constructors' for these objects.
> > >
> > > This is all working fine, but I could cut my memory consumption in
> half if
> > > I could construct the sp::Polygon objects in addSubPoly, and the
> > > sp::Polygons objects in notifyNewRegion. My vector typedefs would then
> all
> > > be:
> > >
> > > typedef std::vector<SEXP>
> > >
> > >
> > >
> > >
> > > Question:
> > > What I'm not sure about (and finally my question) is: I will have
> datasets
> > > where I have more than 10,000 SEXPs in the Polygon and Polygons
> objects for
> > > a single region, and possibly more than 10,000 regions, so how do I
> PROTECT
> > > all those SEXPs (noting that the protection stack is limited to 10,000
> and
> > > bearing in mind that I don't know how many there will be before I
> start)?
> > >
> > > I am also interested in this just out of general curiosity.
> > >
> > >
> > >
> > >
> > > Thoughts:
> > >
> > > 1) I could create an environment and store the objects themselves in
> there
> > > while keeping pointers in the vectors, but am not sure if this would be
> > > that efficient (guidance would be appreciated), or
> > >
> > > 2) Just keep them in R vectors and grow these myself (as push_back is
> doing
> > > for me in the above), but that sounds like a pain and I'm not sure if
> the
> > > objects or just the pointers would be copied when I reassigned things
> > > (guidance would be appreciated again). Bare in mind that I keep
> pointers in
> > > the vectors, but omitted that for the sake of clarity.
> > >
> > >
> > >
> > >
> > > Is there some other R type that would be suited to this, or a general
> > > approach?
> > >
> >
> > Lists in R (LISTSXP aka pairlists) are suited to appending (since that
> is fast and trivial) and sequential processing. The only issue is that
> pairlists are slow for random access. If you only want to load the polygons
> and finalize, then you can hold them in a pairlist and at the end copy to a
> generic vector (if random access is expected). DB applications typically
> use a hybrid approach -  allocate vector blocks and keep them in pairlists,
> but that's probably an overkill for your use (if you really cared about
> performance you wouldn't use sp objects for this ;))
> >
> > Note that you only have to protect the top-level object, so you don't
> need to protect the individual elements.
> >
> > Cheers,
> > Simon
> >
> >
> > > Cheers and thanks in advance,
> > > Simon Knapp
> > >
> > >       [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-devel at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-devel
> > >
> >
> >
>
>

	[[alternative HTML version deleted]]


From simon.urbanek at r-project.org  Tue Nov  4 03:25:02 2014
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Mon, 3 Nov 2014 21:25:02 -0500
Subject: [Rd] Holding a large number of SEXPs in C++
In-Reply-To: <CAA+5f=1B7hvrFp9vmxp1+QZfLFLqiwnEE_781VVxu=ZVVqMAYg@mail.gmail.com>
References: <CAA+5f=1dGHT4EE51WAUg75x+MmimYBW0aWmdsXvtGRpHZ5_b=A@mail.gmail.com>
	<5E3A097A-6872-49C7-8B49-AD3F71D7947B@r-project.org>
	<CAA+5f=0YXYPmiBCwUwwOdJnSmfkuNJyu66giWXLBiOgTKxy5hQ@mail.gmail.com>
	<DE5D8D60-8B4B-4879-A283-B52971496A1B@r-project.org>
	<CAA+5f=1B7hvrFp9vmxp1+QZfLFLqiwnEE_781VVxu=ZVVqMAYg@mail.gmail.com>
Message-ID: <66DE46AB-EE00-4236-BBCC-165B8B659D81@r-project.org>


On Nov 3, 2014, at 5:34 PM, Simon Knapp <sleepingwell at gmail.com> wrote:

> Thanks again Simon. I had realised that R_NilValue didn't need protection... I just thought it a clean way to make my initial call to PROTECT_WITH_INDEX (which I can see now was not required since I didn't need the calls to REPROTECT)... and I had not thought of appending to the tail.
> 
> One final question (and hopefully I don't get to badly burnt) I cannot find R_PreserveObject/R_ReleaseObject or SETCDR mentioned in "Writing R Extensions". Is there anywhere for a novice like myself to find a 'complete' reference to Rs useful macros and functions, or do I just have to read more source?
> 

R_PreserveObject is mentioned in 5.9.1, but it's really just a fleeting mention. It's not used in typical packages, but it is used heavily whenever you're interfacing a foreign runtime system (language or library). What is or is not in the API can vary slightly depending on whom you ask, but the installed header files are essentially the candidate set.

Cheers,
Simon



> Thanks again for being so awesome,
> Simon
> 
> On Tue, Nov 4, 2014 at 12:47 AM, Simon Urbanek <simon.urbanek at r-project.org> wrote:
> 
> On Nov 2, 2014, at 10:55 PM, Simon Knapp <sleepingwell at gmail.com> wrote:
> 
> > Thanks Simon and sorry for taking so long to give this a go. I had thought of pair lists but got confused about how to protect the top level object only, as it seems that appending requires creating a new "top-level object". The following example seems to work (full example at https://gist.github.com/Sleepingwell/8588c5ee844ce0242d05). Is this the way you would do it (or at least 'a correct' way)?
> >
> 
> You can simply append to a pairlist, so you only need to protect the head. Also note that R_NilValue is a constant (in R sense, not C sense) so it doesn't need protection. I would write a generic pairlist builder something like that:
> 
> SEXP head = R_NilValue, tail;
> 
> void append(SEXP x) {
>   if (head == R_NilValue)
>         R_PreserveObject(head = tail = CONS(x, R_NilValue));
>   else
>         tail = SETCDR(tail, CONS(x, R_NilValue));
> }
> 
> void destroy() {
>    if (head != R_NilValue)
>         R_ReleaseObject(head);
> }
> 
> Cheers,
> Simon
> 
> 
> >
> >
> > struct PolyHolder {
> >     PolyHolder(void) {
> >         PROTECT_WITH_INDEX(currentRegion = R_NilValue, &icr);
> >         PROTECT_WITH_INDEX(regions = R_NilValue, &ir);
> >     }
> >
> >     ~PolyHolder(void) {
> >         UNPROTECT(2);
> >     }
> >
> >     void notifyEndRegion(void) {
> >         REPROTECT(regions = CONS(makePolygonsFromPairList(currentRegion), regions), ir);
> >         REPROTECT(currentRegion = R_NilValue, icr);
> >     }
> >
> >     template<typename Iter>
> >     void addSubPolygon(Iter b, Iter e) {
> >         REPROTECT(currentRegion = CONS(makePolygon(b, e), currentRegion), icr);
> >     }
> >
> >     SEXP getPolygons(void) {
> >         return regions;
> >     }
> >
> > private:
> >     PROTECT_INDEX
> >         ir,
> >         icr;
> >
> >     SEXP
> >         currentRegion,
> >         regions;
> > };
> >
> >
> >
> > Thanks again,
> > Simon Knapp
> >
> >
> >
> > CONS(newPoly, creates a new object
> > On Sat, Oct 18, 2014 at 2:10 AM, Simon Urbanek <simon.urbanek at r-project.org> wrote:
> >
> > On Oct 17, 2014, at 7:31 AM, Simon Knapp <sleepingwell at gmail.com> wrote:
> >
> > > Background:
> > > I have an algorithm which produces a large number of small polygons (of the
> > > spatial kind) which I would like to use within R using objects from sp. I
> > > can't predict the exact number of polygons a-priori, the polygons will be
> > > grouped into regions, and each region will be filled sequentially, so an
> > > appropriate C++ 'framework' (for the point of illustration) might be:
> > >
> > > typedef std::pair<double, double> Point;
> > > typedef std::vector<Point> Polygon;
> > > typedef std::vector<Polygon> Polygons;
> > > typedef std::vector<Polygons> Regions;
> > >
> > > struct Holder {
> > >    void notifyNewRegion(void) const {
> > >        regions.push_back(Polygons());
> > >    }
> > >
> > >    template<typename Iter>
> > >    void addSubPoly(Iter b, Iter e) {
> > >        regions.back().push_back(Polygon(b, e));
> > >    }
> > >
> > > private:
> > >    Regions regions;
> > > };
> > >
> > > where the reference_type of Iter is convertible to Point. In practice I use
> > > pointers in a couple of places to avoid resizing in push_back becoming too
> > > expensive.
> > >
> > > To construct the corresponding sp::Polygon, sp::Polygons and
> > > sp::SpatialPolygons at the end of the algorithm, I iterate over the result
> > > turning each Polygon into a two column matrix and calling the C functions
> > > corresponding to the 'constructors' for these objects.
> > >
> > > This is all working fine, but I could cut my memory consumption in half if
> > > I could construct the sp::Polygon objects in addSubPoly, and the
> > > sp::Polygons objects in notifyNewRegion. My vector typedefs would then all
> > > be:
> > >
> > > typedef std::vector<SEXP>
> > >
> > >
> > >
> > >
> > > Question:
> > > What I'm not sure about (and finally my question) is: I will have datasets
> > > where I have more than 10,000 SEXPs in the Polygon and Polygons objects for
> > > a single region, and possibly more than 10,000 regions, so how do I PROTECT
> > > all those SEXPs (noting that the protection stack is limited to 10,000 and
> > > bearing in mind that I don't know how many there will be before I start)?
> > >
> > > I am also interested in this just out of general curiosity.
> > >
> > >
> > >
> > >
> > > Thoughts:
> > >
> > > 1) I could create an environment and store the objects themselves in there
> > > while keeping pointers in the vectors, but am not sure if this would be
> > > that efficient (guidance would be appreciated), or
> > >
> > > 2) Just keep them in R vectors and grow these myself (as push_back is doing
> > > for me in the above), but that sounds like a pain and I'm not sure if the
> > > objects or just the pointers would be copied when I reassigned things
> > > (guidance would be appreciated again). Bare in mind that I keep pointers in
> > > the vectors, but omitted that for the sake of clarity.
> > >
> > >
> > >
> > >
> > > Is there some other R type that would be suited to this, or a general
> > > approach?
> > >
> >
> > Lists in R (LISTSXP aka pairlists) are suited to appending (since that is fast and trivial) and sequential processing. The only issue is that pairlists are slow for random access. If you only want to load the polygons and finalize, then you can hold them in a pairlist and at the end copy to a generic vector (if random access is expected). DB applications typically use a hybrid approach -  allocate vector blocks and keep them in pairlists, but that's probably an overkill for your use (if you really cared about performance you wouldn't use sp objects for this ;))
> >
> > Note that you only have to protect the top-level object, so you don't need to protect the individual elements.
> >
> > Cheers,
> > Simon
> >
> >
> > > Cheers and thanks in advance,
> > > Simon Knapp
> > >
> > >       [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-devel at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-devel
> > >
> >
> >
> 
> 


From sami.toppinen at kolumbus.fi  Tue Nov  4 09:44:36 2014
From: sami.toppinen at kolumbus.fi (Sami Toppinen)
Date: Tue, 4 Nov 2014 10:44:36 +0200 (EET)
Subject: [Rd] [R] Calculation of cross-correlation in ccf
Message-ID: <27647630.19060831415090677592.JavaMail.sami.toppinen@kolumbus.fi>

Dear All,

I am studying some process measurement time series in R and trying to identify time delays using cross-correlation function ccf. The results have however been bit confusing. I found a couple of years old message about this issue but unfortunately wasn't able to find it again for a reference.

For example, an obvious time shift is observed between the measurements y1 and y2 when the following test data is plotted:

x <- 1:121
y1 <- c(328.27, 328.27, 328.27, 328.27, 328.21, 328.14, 328.14, 328.01,
  328.07, 328.01, 327.87, 328.01, 328.07, 328.27, 328.27, 328.54, 328.61,
  328.74, 328.88, 329.01, 329.01, 329.21, 329.28, 329.35, 329.35, 329.42,
  329.35, 329.28, 329.28, 329.15, 329.08, 329.08, 328.95, 328.95, 328.95,
  328.95, 329.01, 329.15, 329.21, 329.28, 329.55, 329.62, 329.75, 329.82,
  329.89, 330.09, 330.09, 330.29, 330.29, 330.36, 330.42, 330.29, 330.15,
  330.22, 330.09, 329.95, 329.82, 329.75, 329.62, 329.55, 329.48, 329.55,
  329.68, 329.75, 329.82, 329.89, 330.09, 330.09, 330.15, 330.22, 330.42,
  330.42, 330.42, 330.36, 330.42, 330.22, 330.15, 330.09, 329.89, 329.75,
  329.55, 329.35, 329.35, 329.42, 329.48, 329.55, 329.75, 329.75, 329.82,
  330.09, 330.15, 330.42, 330.42, 330.62, 330.69, 330.69, 330.83, 330.83,
  330.76, 330.62, 330.62, 330.56, 330.42, 330.42, 330.29, 330.29, 330.29,
  330.29, 330.22, 330.49, 330.56, 330.62, 330.76, 331.03, 330.96, 331.16,
  331.23, 331.50, 331.63, 332.03, 332.03)
y2 <- c(329.68, 329.75, 329.82, 329.95, 330.02, 330.15, 330.22, 330.36,
  330.22, 330.29, 330.29, 330.29, 330.29, 330.15, 330.22, 330.22, 330.15,
  330.15, 330.15, 330.15, 330.15, 330.29, 330.49, 330.49, 330.62, 330.89,
  331.03, 331.09, 331.16, 331.30, 331.30, 331.36, 331.43, 331.43, 331.43,
  331.36, 331.36, 331.36, 331.36, 331.23, 331.23, 331.16, 331.16, 331.23,
  331.30, 331.23, 331.36, 331.56, 331.70, 331.83, 331.97, 331.97, 332.10,
  332.30, 332.44, 332.44, 332.51, 332.51, 332.57, 332.57, 332.51, 332.37,
  332.24, 332.24, 332.10, 331.97, 331.97, 331.90, 331.83, 331.97, 331.97,
  331.97, 332.03, 332.24, 332.30, 332.30, 332.37, 332.57, 332.57, 332.57,
  332.57, 332.57, 332.51, 332.37, 332.30, 332.17, 331.97, 331.83, 331.70,
  331.70, 331.63, 331.63, 331.70, 331.83, 331.90, 332.10, 332.24, 332.30,
  332.44, 332.57, 332.71, 332.84, 332.77, 332.91, 332.84, 332.84, 332.91,
  332.84, 332.77, 332.77, 332.64, 332.64, 332.57, 332.57, 332.57, 332.57,
  332.57, 332.71, 332.98, 333.24, 333.58)
matplot(cbind(y1, y2))

However, the cross-correlation function surprisingly gives the maximum correlation 0.83 at zero lag:

ccf(y1, y2)

Plotting of variables against each other with zero lag

plot(y1, y2)

shows that the correlation is not that good. Instead, a very nice correlation is obtained with a plot with shifted variables:

plot(y1[1:113], y2[1:113 + 8])

As a comparison I defined my own cross correlation function:

cross.cor <- function(x, y, k)
{
  n <- length(x) - abs(k)
  if (k >= 0)
    cor(x[1:n + k], y[1:n])
  else
    cor(x[1:n], y[1:n - k])
}

The new function cross.cor gives maximum correlation of 0.99 at lag -8, and the shape of the correlation function is very different from the one obtained with ccf (both methods give same value at zero lag):

plot(-15:15, sapply(-15:15, function(lag) cross.cor(y1, y2, lag)),
  ylim = c(0.3, 1))
points(-15:15, ccf(y1, y2, 15, plot = FALSE)$acf, col = "red")

In order to understand the reason for the differences, I looked at the program codes of ccf function. When the variables are compared with a nonzero lag, some the data points must be left out from the tails of the time series. It appears to me that ccf calculates (partly in R code, partly in C code) first the means and the standard deviations using the whole data, and then uses those values as constants in further calculations. The time series are truncated only in the summations for covariances.

That approach naturally speeds up the computations, but is it really correct? Is the approach used in ccf somehow statistically more correct? I suppose the strong increasing trend in my test data emphasizes this issue (leaving data points out from one end has big impact on the average).

Best regards,
Sami Toppinen
sami.toppinen at kolumbus.fi


From vakili.kaveh.email at gmail.com  Tue Nov  4 14:37:17 2014
From: vakili.kaveh.email at gmail.com (kaveh)
Date: Tue, 04 Nov 2014 14:37:17 +0100
Subject: [Rd] Linking to the BH package introduces CRAN warnings
Message-ID: <5458D68D.3070102@gmail.com>

Dear all,

I'm working on a project that links to the BH package
(http://cran.r-project.org/web/packages/BH/index.html).

My packages doesn't call entry points which might terminate R nor
write to stdout/stderr instead of to the console.

However, it seems some of the codes in the BH package
might. At any rate, when I include some boost headers such as
boost/math/distributions/ through BH, I get the following warnings
  when  submitting to the win-builder page:


   Found '_ZSt4cerr', possibly from 'std::cerr' (C++)

   Found 'abort', possibly from 'abort' (C), 'runtime' (Fortran)

   Found '_ZSt4cerr', possibly from 'std::cerr' (C++)

   Found 'abort', possibly from 'abort' (C), 'runtime' (Fortran)


  Furthermore, these warnings disappear when remove the boost
  headers and replace the call to boost functions by constants.

Looking at the CRAN-check diagnostics of some other packages that link to
BH, I do not see similar warnings, so I suppose it is possible to fix 
this issue.
Looking at their source code, it is not clear to me how these authors have
managed to do this, but this might be because I'm not that familiar with
boost to begin with. Can someone point me to some solution to this problem?

Thanks in advance,


From edd at debian.org  Tue Nov  4 15:42:08 2014
From: edd at debian.org (Dirk Eddelbuettel)
Date: Tue, 4 Nov 2014 08:42:08 -0600
Subject: [Rd] Linking to the BH package introduces CRAN warnings
In-Reply-To: <5458D68D.3070102@gmail.com>
References: <5458D68D.3070102@gmail.com>
Message-ID: <21592.58816.359652.109459@max.nulle.part>


On 4 November 2014 at 14:37, kaveh wrote:
| Dear all,
| 
| I'm working on a project that links to the BH package
| (http://cran.r-project.org/web/packages/BH/index.html).
| 
| My packages doesn't call entry points which might terminate R nor
| write to stdout/stderr instead of to the console.
| 
| However, it seems some of the codes in the BH package
| might. At any rate, when I include some boost headers such as
| boost/math/distributions/ through BH, I get the following warnings
|   when  submitting to the win-builder page:
| 
| 
|    Found '_ZSt4cerr', possibly from 'std::cerr' (C++)
| 
|    Found 'abort', possibly from 'abort' (C), 'runtime' (Fortran)
| 
|    Found '_ZSt4cerr', possibly from 'std::cerr' (C++)
| 
|    Found 'abort', possibly from 'abort' (C), 'runtime' (Fortran)
| 
| 
|   Furthermore, these warnings disappear when remove the boost
|   headers and replace the call to boost functions by constants.
| 
| Looking at the CRAN-check diagnostics of some other packages that link to
| BH, I do not see similar warnings, so I suppose it is possible to fix 
| this issue.
| Looking at their source code, it is not clear to me how these authors have
| managed to do this, but this might be because I'm not that familiar with
| boost to begin with. Can someone point me to some solution to this problem?

Briefly:

i) Your subject line is wrong.  You do not "link" to BH, you use it to
include headers at compile time. That may seem like a small difference, but
it is not. You generally want to avoid linking as much as you can, if only
for cross-OS portability,

ii) This the R-devel list for R question. You have a package question. You
are generally advised to contact __the package authors__ and/or the package
mailing list. And yes, BH has one in

    http://lists.r-forge.r-project.org/pipermail/boostheaders-devel/

though I grant you that it is not as well advertised as it should be. I just
opened a ticket at https://github.com/eddelbuettel/bh/issues/3 to remind
myself to improve that.

iii) As for your problem, only you and some careful bisections can help you
there as we do not have your sources.  I too have packages including BH
headers, but they do not pull in abort() or other things the CRAN gatekeepers
prohibit us from deploying.

Dirk
aka your friendly neighborhood BH maintainer

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From igauravsehrawat at gmail.com  Tue Nov  4 20:22:43 2014
From: igauravsehrawat at gmail.com (Gaurav Sehrawat)
Date: Wed, 5 Nov 2014 00:52:43 +0530
Subject: [Rd] Volunteers for Google Code-in mentor & co-admin/admin
Message-ID: <CAC2qNN4+bFPEwZ7uKM0AFGNAQ5qyBO=KM0J1txPDdNKPxO6wcA@mail.gmail.com>

Hello everyone ,

I would like to bring everyone's attention to this thread :
https://groups.google.com/forum/#!topic/gsoc-r/dtYY_5NBvyc .

R-project has been participating for Google Summer of Code since long time
. This R-project is planning for Google Code-in ,to introduce school kids
about the r-language .

If anyone is available to volunteer for the same , that would be great .

More about code-in is here :
http://www.google-melange.com/gci/homepage/google/gci2014

Thanks

Cheers

	[[alternative HTML version deleted]]


From romain at r-enthusiasts.com  Tue Nov  4 21:46:57 2014
From: romain at r-enthusiasts.com (=?utf-8?Q?Romain_Fran=C3=A7ois?=)
Date: Tue, 4 Nov 2014 21:46:57 +0100
Subject: [Rd] Linking to the BH package introduces CRAN warnings
In-Reply-To: <21592.58816.359652.109459@max.nulle.part>
References: <5458D68D.3070102@gmail.com>
	<21592.58816.359652.109459@max.nulle.part>
Message-ID: <0CDE01C7-C290-4CB8-A1ED-B2A8816CBA49@r-enthusiasts.com>


> Le 4 nov. 2014 ? 15:42, Dirk Eddelbuettel <edd at debian.org> a ?crit :
> 
> 
> On 4 November 2014 at 14:37, kaveh wrote:
> | Dear all,
> | 
> | I'm working on a project that links to the BH package
> | (http://cran.r-project.org/web/packages/BH/index.html).
> | 
> | My packages doesn't call entry points which might terminate R nor
> | write to stdout/stderr instead of to the console.
> | 
> | However, it seems some of the codes in the BH package
> | might. At any rate, when I include some boost headers such as
> | boost/math/distributions/ through BH, I get the following warnings
> |   when  submitting to the win-builder page:
> | 
> | 
> |    Found '_ZSt4cerr', possibly from 'std::cerr' (C++)
> | 
> |    Found 'abort', possibly from 'abort' (C), 'runtime' (Fortran)
> | 
> |    Found '_ZSt4cerr', possibly from 'std::cerr' (C++)
> | 
> |    Found 'abort', possibly from 'abort' (C), 'runtime' (Fortran)

You?re kind of out of luck. These functions are both:
 - used by the boost headers
 - forbidden by R, well at least forbidden by CRAN

> |   Furthermore, these warnings disappear when remove the boost
> |   headers and replace the call to boost functions by constants.
> | 
> | Looking at the CRAN-check diagnostics of some other packages that link to
> | BH, I do not see similar warnings, so I suppose it is possible to fix 
> | this issue.
> | Looking at their source code, it is not clear to me how these authors have
> | managed to do this, but this might be because I'm not that familiar with
> | boost to begin with. Can someone point me to some solution to this problem?
> 
> Briefly:
> 
> i) Your subject line is wrong.  You do not "link" to BH, you use it to
> include headers at compile time. That may seem like a small difference, but
> it is not. You generally want to avoid linking as much as you can, if only
> for cross-OS portability,

How would you not expect someone to be confused when ? not linking to ? BH requires the use of the `LinkingTo: BH` in the DESCRIPTION file. 

> ii) This the R-devel list for R question. You have a package question. You
> are generally advised to contact __the package authors__ and/or the package
> mailing list. And yes, BH has one in
> 
>    http://lists.r-forge.r-project.org/pipermail/boostheaders-devel/
> 
> though I grant you that it is not as well advertised as it should be. I just
> opened a ticket at https://github.com/eddelbuettel/bh/issues/3 to remind
> myself to improve that.
> 
> iii) As for your problem, only you and some careful bisections can help you
> there as we do not have your sources.  I too have packages including BH
> headers, but they do not pull in abort() or other things the CRAN gatekeepers
> prohibit us from deploying.
> 
> Dirk
> aka your friendly neighborhood BH maintainer
> 
> -- 
> http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From vakili.kaveh.email at gmail.com  Tue Nov  4 21:52:53 2014
From: vakili.kaveh.email at gmail.com (kaveh)
Date: Tue, 04 Nov 2014 21:52:53 +0100
Subject: [Rd] Linking to the BH package introduces CRAN warnings
In-Reply-To: <0CDE01C7-C290-4CB8-A1ED-B2A8816CBA49@r-enthusiasts.com>
References: <5458D68D.3070102@gmail.com>
	<21592.58816.359652.109459@max.nulle.part>
	<0CDE01C7-C290-4CB8-A1ED-B2A8816CBA49@r-enthusiasts.com>
Message-ID: <54593CA5.2030002@gmail.com>


Dear Romain,



                /You?re kind of out of luck. These functions are both:
                  - used by the boost headers
                  - forbidden by R, well at least forbidden by CRAN
                /

//

Thanks for conforming my earlier fears. Since I only use
this header and would like my package to eventually be
on CRAN, I was thinking of bypassing BH and just putting
these headers in the /inst directory and modifying them
to remove the offending calls. I was wondering what your
view on this is. Or perhaps there is a simpler alternative?

Thanks in advance,



On 2014-11-04 21:46, Romain Fran?ois wrote:
>> Le 4 nov. 2014 ? 15:42, Dirk Eddelbuettel <edd at debian.org> a ?crit :
>>
>>
>> On 4 November 2014 at 14:37, kaveh wrote:
>> | Dear all,
>> |
>> | I'm working on a project that links to the BH package
>> | (http://cran.r-project.org/web/packages/BH/index.html).
>> |
>> | My packages doesn't call entry points which might terminate R nor
>> | write to stdout/stderr instead of to the console.
>> |
>> | However, it seems some of the codes in the BH package
>> | might. At any rate, when I include some boost headers such as
>> | boost/math/distributions/ through BH, I get the following warnings
>> |   when  submitting to the win-builder page:
>> |
>> |
>> |    Found '_ZSt4cerr', possibly from 'std::cerr' (C++)
>> |
>> |    Found 'abort', possibly from 'abort' (C), 'runtime' (Fortran)
>> |
>> |    Found '_ZSt4cerr', possibly from 'std::cerr' (C++)
>> |
>> |    Found 'abort', possibly from 'abort' (C), 'runtime' (Fortran)
> You?re kind of out of luck. These functions are both:
>   - used by the boost headers
>   - forbidden by R, well at least forbidden by CRAN
>


	[[alternative HTML version deleted]]


From romain at r-enthusiasts.com  Tue Nov  4 22:01:31 2014
From: romain at r-enthusiasts.com (=?utf-8?Q?Romain_Fran=C3=A7ois?=)
Date: Tue, 4 Nov 2014 22:01:31 +0100
Subject: [Rd] Linking to the BH package introduces CRAN warnings
In-Reply-To: <54593CA5.2030002@gmail.com>
References: <5458D68D.3070102@gmail.com>
	<21592.58816.359652.109459@max.nulle.part>
	<0CDE01C7-C290-4CB8-A1ED-B2A8816CBA49@r-enthusiasts.com>
	<54593CA5.2030002@gmail.com>
Message-ID: <3C0BCB13-BD36-49FE-90E0-C71335B38258@r-enthusiasts.com>


> Le 4 nov. 2014 ? 21:52, kaveh <vakili.kaveh.email at gmail.com> a ?crit :
> 
> 
> Dear Romain, 
> 
> 
> 
> You?re kind of out of luck. These functions are both:
>  - used by the boost headers
>  - forbidden by R, well at least forbidden by CRAN
> 
> 
> Thanks for conforming my earlier fears. Since I only use 
> this header and would like my package to eventually be 
> on CRAN, I was thinking of bypassing BH and just putting 
> these headers in the /inst directory and modifying them 
> to remove the offending calls. I was wondering what your 
> view on this is. Or perhaps there is a simpler alternative?
> 
> Thanks in advance, 

If you go through the hoops of modifying these headers to fulfill R?s requirements, I?m sure it would be of interest to others if you contribute these back to BH. 

The danger obviously is that this gets out of sync with boost, which would create work for merging your changes to new boost files from the future. 

Some parts of boost (e.g. uBlas) have macros to control whether or not std::cerr is used at all. https://github.com/eddelbuettel/bh/blob/cb1427c27dc068c8328fd1d2f4b1b8a8da1957c2/inst/include/boost/numeric/ublas/exception.hpp#L215 <https://github.com/eddelbuettel/bh/blob/cb1427c27dc068c8328fd1d2f4b1b8a8da1957c2/inst/include/boost/numeric/ublas/exception.hpp#L215>

But I don?t think this is of any relevance to the files you want to use. 

Romain

> On 2014-11-04 21:46, Romain Fran?ois wrote:
>>> Le 4 nov. 2014 ? 15:42, Dirk Eddelbuettel <edd at debian.org> <mailto:edd at debian.org> a ?crit :
>>> 
>>> 
>>> On 4 November 2014 at 14:37, kaveh wrote:
>>> | Dear all,
>>> | 
>>> | I'm working on a project that links to the BH package
>>> | (http://cran.r-project.org/web/packages/BH/index.html <http://cran.r-project.org/web/packages/BH/index.html>).
>>> | 
>>> | My packages doesn't call entry points which might terminate R nor
>>> | write to stdout/stderr instead of to the console.
>>> | 
>>> | However, it seems some of the codes in the BH package
>>> | might. At any rate, when I include some boost headers such as
>>> | boost/math/distributions/ through BH, I get the following warnings
>>> |   when  submitting to the win-builder page:
>>> | 
>>> | 
>>> |    Found '_ZSt4cerr', possibly from 'std::cerr' (C++)
>>> | 
>>> |    Found 'abort', possibly from 'abort' (C), 'runtime' (Fortran)
>>> | 
>>> |    Found '_ZSt4cerr', possibly from 'std::cerr' (C++)
>>> | 
>>> |    Found 'abort', possibly from 'abort' (C), 'runtime' (Fortran)
>> You?re kind of out of luck. These functions are both:
>>  - used by the boost headers
>>  - forbidden by R, well at least forbidden by CRAN
>> 
> 


	[[alternative HTML version deleted]]


From vakili.kaveh.email at gmail.com  Tue Nov  4 22:03:24 2014
From: vakili.kaveh.email at gmail.com (kaveh)
Date: Tue, 04 Nov 2014 22:03:24 +0100
Subject: [Rd] Linking to the BH package introduces CRAN warnings
In-Reply-To: <3C0BCB13-BD36-49FE-90E0-C71335B38258@r-enthusiasts.com>
References: <5458D68D.3070102@gmail.com>
	<21592.58816.359652.109459@max.nulle.part>
	<0CDE01C7-C290-4CB8-A1ED-B2A8816CBA49@r-enthusiasts.com>
	<54593CA5.2030002@gmail.com>
	<3C0BCB13-BD36-49FE-90E0-C71335B38258@r-enthusiasts.com>
Message-ID: <54593F1C.3020107@gmail.com>

Dear Romain,


Thanks for all these info,


I will ponder this versus using
some of the alternatives in the R sources


Best regards,

On 2014-11-04 22:01, Romain Fran?ois wrote:
>
>> Le 4 nov. 2014 ? 21:52, kaveh <vakili.kaveh.email at gmail.com 
>> <mailto:vakili.kaveh.email at gmail.com>> a ?crit :
>>
>>
>> Dear Romain,
>>
>>
>>
>>                 /You?re kind of out of luck. These functions are both:
>>                   - used by the boost headers
>>                   - forbidden by R, well at least forbidden by CRAN
>>                 /
>>
>> //
>>
>> Thanks for conforming my earlier fears. Since I only use
>> this header and would like my package to eventually be
>> on CRAN, I was thinking of bypassing BH and just putting
>> these headers in the /inst directory and modifying them
>> to remove the offending calls. I was wondering what your
>> view on this is. Or perhaps there is a simpler alternative?
>>
>> Thanks in advance,
>
> If you go through the hoops of modifying these headers to fulfill R?s 
> requirements, I?m sure it would be of interest to others if you 
> contribute these back to BH.
>
> The danger obviously is that this gets out of sync with boost, which 
> would create work for merging your changes to new boost files from the 
> future.
>
> Some parts of boost (e.g. uBlas) have macros to control whether or not 
> std::cerr is used at all. 
> https://github.com/eddelbuettel/bh/blob/cb1427c27dc068c8328fd1d2f4b1b8a8da1957c2/inst/include/boost/numeric/ublas/exception.hpp#L215
>
> But I don?t think this is of any relevance to the files you want to use.
>
> Romain
>
>> On 2014-11-04 21:46, Romain Fran?ois wrote:
>>>> Le 4 nov. 2014 ? 15:42, Dirk Eddelbuettel<edd at debian.org>  a ?crit :
>>>>
>>>>
>>>> On 4 November 2014 at 14:37, kaveh wrote:
>>>> | Dear all,
>>>> |
>>>> | I'm working on a project that links to the BH package
>>>> | (http://cran.r-project.org/web/packages/BH/index.html).
>>>> |
>>>> | My packages doesn't call entry points which might terminate R nor
>>>> | write to stdout/stderr instead of to the console.
>>>> |
>>>> | However, it seems some of the codes in the BH package
>>>> | might. At any rate, when I include some boost headers such as
>>>> | boost/math/distributions/ through BH, I get the following warnings
>>>> |   when  submitting to the win-builder page:
>>>> |
>>>> |
>>>> |    Found '_ZSt4cerr', possibly from 'std::cerr' (C++)
>>>> |
>>>> |    Found 'abort', possibly from 'abort' (C), 'runtime' (Fortran)
>>>> |
>>>> |    Found '_ZSt4cerr', possibly from 'std::cerr' (C++)
>>>> |
>>>> |    Found 'abort', possibly from 'abort' (C), 'runtime' (Fortran)
>>> You?re kind of out of luck. These functions are both:
>>>   - used by the boost headers
>>>   - forbidden by R, well at least forbidden by CRAN
>>>
>>
>


	[[alternative HTML version deleted]]


From h.wickham at gmail.com  Tue Nov  4 23:32:51 2014
From: h.wickham at gmail.com (Hadley Wickham)
Date: Tue, 4 Nov 2014 16:32:51 -0600
Subject: [Rd] Linking to the BH package introduces CRAN warnings
In-Reply-To: <0CDE01C7-C290-4CB8-A1ED-B2A8816CBA49@r-enthusiasts.com>
References: <5458D68D.3070102@gmail.com>
	<21592.58816.359652.109459@max.nulle.part>
	<0CDE01C7-C290-4CB8-A1ED-B2A8816CBA49@r-enthusiasts.com>
Message-ID: <CABdHhvEiGiXAYymj4Fw2BTMw7Jq+BHBu0q=CR6kCRXYFph2VKw@mail.gmail.com>

>> | However, it seems some of the codes in the BH package
>> | might. At any rate, when I include some boost headers such as
>> | boost/math/distributions/ through BH, I get the following warnings
>> |   when  submitting to the win-builder page:
>> |
>> |
>> |    Found '_ZSt4cerr', possibly from 'std::cerr' (C++)
>> |
>> |    Found 'abort', possibly from 'abort' (C), 'runtime' (Fortran)
>> |
>> |    Found '_ZSt4cerr', possibly from 'std::cerr' (C++)
>> |
>> |    Found 'abort', possibly from 'abort' (C), 'runtime' (Fortran)
>
> You?re kind of out of luck. These functions are both:
>  - used by the boost headers
>  - forbidden by R, well at least forbidden by CRAN

Maaaaybe - I had this note in RSQLite, and CRAN seemed ok with my explanation:

* checking compiled code ... NOTE
  File ?/Users/hadley/Documents/databases/RSQLite.Rcheck/RSQLite/libs/RSQLite.so?:
    Found ?___stderrp?, possibly from ?stderr? (C)
      Object: ?sqlite-all.o?

  This is in C code from the embedded SQLite database.


Hadley

-- 
http://had.co.nz/


From vakili.kaveh.email at gmail.com  Tue Nov  4 23:36:54 2014
From: vakili.kaveh.email at gmail.com (kaveh)
Date: Tue, 04 Nov 2014 23:36:54 +0100
Subject: [Rd] Linking to the BH package introduces CRAN warnings
In-Reply-To: <CABdHhvEiGiXAYymj4Fw2BTMw7Jq+BHBu0q=CR6kCRXYFph2VKw@mail.gmail.com>
References: <5458D68D.3070102@gmail.com>
	<21592.58816.359652.109459@max.nulle.part>
	<0CDE01C7-C290-4CB8-A1ED-B2A8816CBA49@r-enthusiasts.com>
	<CABdHhvEiGiXAYymj4Fw2BTMw7Jq+BHBu0q=CR6kCRXYFph2VKw@mail.gmail.com>
Message-ID: <54595506.7000706@gmail.com>

Dear Hadley,

Thank you for this information, maybe the CRAN gods
will look favourably on this case too,


Best regards,

On 2014-11-04 23:32, Hadley Wickham wrote:
>>> | However, it seems some of the codes in the BH package
>>> | might. At any rate, when I include some boost headers such as
>>> | boost/math/distributions/ through BH, I get the following warnings
>>> |   when  submitting to the win-builder page:
>>> |
>>> |
>>> |    Found '_ZSt4cerr', possibly from 'std::cerr' (C++)
>>> |
>>> |    Found 'abort', possibly from 'abort' (C), 'runtime' (Fortran)
>>> |
>>> |    Found '_ZSt4cerr', possibly from 'std::cerr' (C++)
>>> |
>>> |    Found 'abort', possibly from 'abort' (C), 'runtime' (Fortran)
>> You?re kind of out of luck. These functions are both:
>>   - used by the boost headers
>>   - forbidden by R, well at least forbidden by CRAN
> Maaaaybe - I had this note in RSQLite, and CRAN seemed ok with my explanation:
>
> * checking compiled code ... NOTE
>    File ?/Users/hadley/Documents/databases/RSQLite.Rcheck/RSQLite/libs/RSQLite.so?:
>      Found ?___stderrp?, possibly from ?stderr? (C)
>        Object: ?sqlite-all.o?
>
>    This is in C code from the embedded SQLite database.
>
>
> Hadley
>


From edd at debian.org  Tue Nov  4 23:52:46 2014
From: edd at debian.org (Dirk Eddelbuettel)
Date: Tue, 4 Nov 2014 16:52:46 -0600
Subject: [Rd] Linking to the BH package introduces CRAN warnings
In-Reply-To: <54595506.7000706@gmail.com>
References: <5458D68D.3070102@gmail.com>
	<21592.58816.359652.109459@max.nulle.part>
	<0CDE01C7-C290-4CB8-A1ED-B2A8816CBA49@r-enthusiasts.com>
	<CABdHhvEiGiXAYymj4Fw2BTMw7Jq+BHBu0q=CR6kCRXYFph2VKw@mail.gmail.com>
	<54595506.7000706@gmail.com>
Message-ID: <21593.22718.944171.419082@max.nulle.part>


Gentlemen,

On 4 November 2014 at 23:36, kaveh wrote:
| Dear Hadley,
| 
| Thank you for this information, maybe the CRAN gods
| will look favourably on this case too,

You seemed to have missed a point my earlier email tried to stress: Inclusion
of BH does not lead to the warning.  

All this depends on WHICH headers are included, and the OP will need to sort
this out by modifying his code.

Dirk
 
| Best regards,
| 
| On 2014-11-04 23:32, Hadley Wickham wrote:
| >>> | However, it seems some of the codes in the BH package
| >>> | might. At any rate, when I include some boost headers such as
| >>> | boost/math/distributions/ through BH, I get the following warnings
| >>> |   when  submitting to the win-builder page:
| >>> |
| >>> |
| >>> |    Found '_ZSt4cerr', possibly from 'std::cerr' (C++)
| >>> |
| >>> |    Found 'abort', possibly from 'abort' (C), 'runtime' (Fortran)
| >>> |
| >>> |    Found '_ZSt4cerr', possibly from 'std::cerr' (C++)
| >>> |
| >>> |    Found 'abort', possibly from 'abort' (C), 'runtime' (Fortran)
| >> You?re kind of out of luck. These functions are both:
| >>   - used by the boost headers
| >>   - forbidden by R, well at least forbidden by CRAN
| > Maaaaybe - I had this note in RSQLite, and CRAN seemed ok with my explanation:
| >
| > * checking compiled code ... NOTE
| >    File ?/Users/hadley/Documents/databases/RSQLite.Rcheck/RSQLite/libs/RSQLite.so?:
| >      Found ?___stderrp?, possibly from ?stderr? (C)
| >        Object: ?sqlite-all.o?
| >
| >    This is in C code from the embedded SQLite database.
| >
| >
| > Hadley
| >
| 

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From vakili.kaveh.email at gmail.com  Wed Nov  5 00:15:11 2014
From: vakili.kaveh.email at gmail.com (kaveh)
Date: Wed, 05 Nov 2014 00:15:11 +0100
Subject: [Rd] Linking to the BH package introduces CRAN warnings
In-Reply-To: <21593.22718.944171.419082@max.nulle.part>
References: <5458D68D.3070102@gmail.com>	<21592.58816.359652.109459@max.nulle.part>	<0CDE01C7-C290-4CB8-A1ED-B2A8816CBA49@r-enthusiasts.com>	<CABdHhvEiGiXAYymj4Fw2BTMw7Jq+BHBu0q=CR6kCRXYFph2VKw@mail.gmail.com>	<54595506.7000706@gmail.com>
	<21593.22718.944171.419082@max.nulle.part>
Message-ID: <54595DFF.6080101@gmail.com>

Sire,

The header that is included is

boost/math/distributions/

If I remove it and replace the calls
to its members by plain constants,
the warning disappear (I just tried
this again on http://win-builder.r-project.org/).

This leads me to the suspicion that
the header is causing the error message.

I will post a simpler source code,
tomorrow on this list.

Best regards,


On 2014-11-04 23:52, Dirk Eddelbuettel wrote:
> Gentlemen,
>
> On 4 November 2014 at 23:36, kaveh wrote:
> | Dear Hadley,
> |
> | Thank you for this information, maybe the CRAN gods
> | will look favourably on this case too,
>
> You seemed to have missed a point my earlier email tried to stress: Inclusion
> of BH does not lead to the warning.
>
> All this depends on WHICH headers are included, and the OP will need to sort
> this out by modifying his code.
>
> Dirk
>   
> | Best regards,
> |
> | On 2014-11-04 23:32, Hadley Wickham wrote:
> | >>> | However, it seems some of the codes in the BH package
> | >>> | might. At any rate, when I include some boost headers such as
> | >>> | boost/math/distributions/ through BH, I get the following warnings
> | >>> |   when  submitting to the win-builder page:
> | >>> |
> | >>> |
> | >>> |    Found '_ZSt4cerr', possibly from 'std::cerr' (C++)
> | >>> |
> | >>> |    Found 'abort', possibly from 'abort' (C), 'runtime' (Fortran)
> | >>> |
> | >>> |    Found '_ZSt4cerr', possibly from 'std::cerr' (C++)
> | >>> |
> | >>> |    Found 'abort', possibly from 'abort' (C), 'runtime' (Fortran)
> | >> You?re kind of out of luck. These functions are both:
> | >>   - used by the boost headers
> | >>   - forbidden by R, well at least forbidden by CRAN
> | > Maaaaybe - I had this note in RSQLite, and CRAN seemed ok with my explanation:
> | >
> | > * checking compiled code ... NOTE
> | >    File ?/Users/hadley/Documents/databases/RSQLite.Rcheck/RSQLite/libs/RSQLite.so?:
> | >      Found ?___stderrp?, possibly from ?stderr? (C)
> | >        Object: ?sqlite-all.o?
> | >
> | >    This is in C code from the embedded SQLite database.
> | >
> | >
> | > Hadley
> | >
> |
>


From vakili.kaveh.email at gmail.com  Wed Nov  5 00:55:15 2014
From: vakili.kaveh.email at gmail.com (kaveh)
Date: Wed, 05 Nov 2014 00:55:15 +0100
Subject: [Rd] Linking to the BH package introduces CRAN warnings
In-Reply-To: <21593.22718.944171.419082@max.nulle.part>
References: <5458D68D.3070102@gmail.com>	<21592.58816.359652.109459@max.nulle.part>	<0CDE01C7-C290-4CB8-A1ED-B2A8816CBA49@r-enthusiasts.com>	<CABdHhvEiGiXAYymj4Fw2BTMw7Jq+BHBu0q=CR6kCRXYFph2VKw@mail.gmail.com>	<54595506.7000706@gmail.com>
	<21593.22718.944171.419082@max.nulle.part>
Message-ID: <54596763.3020700@gmail.com>

Dear all,


the simple code in below, when send to the
win-builder returns the following (and no other)
warning:


* checking compiled code ... WARNING
File 'quicky/libs/i386/quicky.dll':
   Found '_ZSt4cerr', possibly from 'std::cerr' (C++)
     Object: 'quicky.o'
   Found 'abort', possibly from 'abort' (C), 'runtime' (Fortran)
     Object: 'quicky.o'
File 'quicky/libs/x64/quicky.dll':
   Found '_ZSt4cerr', possibly from 'std::cerr' (C++)
     Object: 'quicky.o'
   Found 'abort', possibly from 'abort' (C), 'runtime' (Fortran)
     Object: 'quicky.o'

Compiled code should not call entry points which might terminate R nor
write to stdout/stderr instead of to the console, nor the C RNG.

See 'Writing portable packages' in the 'Writing R Extensions' manual.


Here is the source:

#include <algorithm>
#include <cstdlib>
#include <ctime>
#include <functional>
#include <fstream>
#include <iostream>
#include <math.h>
#include <time.h>
#include <stdio.h>
#include <stdlib.h>
#include <sstream>
#include <vector>
#include <random>

#include <boost/math/distributions/normal.hpp>
#include <boost/math/distributions/chi_squared.hpp>

#include <Eigen/Dense>

using namespace std;
using namespace Eigen;
using Eigen::MatrixXd;
using Eigen::VectorXd;
using Eigen::VectorXi;
using Eigen::RowVectorXd;


using boost::math::chi_squared;
using boost::math::quantile;
using boost::math::complement;
using boost::math::normal_distribution;
using namespace boost::math::policies;

typedef policy<
       promote_double<true>
       > my_policy_norm;
typedef policy<
       promote_double<true>
       > my_policy_chi2;

typedef boost::math::normal_distribution<double,my_policy_norm> my_norm;
typedef boost::math::chi_squared_distribution<double,my_policy_chi2> 
my_chi2;


VectorXd GetQs(const VectorXd& x){
     const int n=x.size();
     double mytol=1e-8;
     double the_max=x.maxCoeff();
     double the_min=x.minCoeff();
     double the_rag=(the_max-the_min);
     if(the_rag<mytol)    return(x);
     if(1.0-the_max<mytol)    return(x);
     if(the_min<mytol)    return(x);
     VectorXd y=x.array();
     for(int i=0;i<n;i++) 
y(i)=sqrt(quantile(complement(my_chi2(1.0),x(i))));
     return(y);
}
extern "C"{
     void quicky(int* rn,double* xi,double* yi){
         const int n=*rn;
         VectorXd x=Map<VectorXd>(xi,n);
         Map<VectorXd>(yi,n)=GetQs(x);
     }
}


So I guess, I should fill a bug report with the
BH maintainer?

Best regards,


On 2014-11-04 23:52, Dirk Eddelbuettel wrote:
> Gentlemen,
>
> On 4 November 2014 at 23:36, kaveh wrote:
> | Dear Hadley,
> |
> | Thank you for this information, maybe the CRAN gods
> | will look favourably on this case too,
>
> You seemed to have missed a point my earlier email tried to stress: Inclusion
> of BH does not lead to the warning.
>
> All this depends on WHICH headers are included, and the OP will need to sort
> this out by modifying his code.
>
> Dirk
>   
> | Best regards,
> |
> | On 2014-11-04 23:32, Hadley Wickham wrote:
> | >>> | However, it seems some of the codes in the BH package
> | >>> | might. At any rate, when I include some boost headers such as
> | >>> | boost/math/distributions/ through BH, I get the following warnings
> | >>> |   when  submitting to the win-builder page:
> | >>> |
> | >>> |
> | >>> |    Found '_ZSt4cerr', possibly from 'std::cerr' (C++)
> | >>> |
> | >>> |    Found 'abort', possibly from 'abort' (C), 'runtime' (Fortran)
> | >>> |
> | >>> |    Found '_ZSt4cerr', possibly from 'std::cerr' (C++)
> | >>> |
> | >>> |    Found 'abort', possibly from 'abort' (C), 'runtime' (Fortran)
> | >> You?re kind of out of luck. These functions are both:
> | >>   - used by the boost headers
> | >>   - forbidden by R, well at least forbidden by CRAN
> | > Maaaaybe - I had this note in RSQLite, and CRAN seemed ok with my explanation:
> | >
> | > * checking compiled code ... NOTE
> | >    File ?/Users/hadley/Documents/databases/RSQLite.Rcheck/RSQLite/libs/RSQLite.so?:
> | >      Found ?___stderrp?, possibly from ?stderr? (C)
> | >        Object: ?sqlite-all.o?
> | >
> | >    This is in C code from the embedded SQLite database.
> | >
> | >
> | > Hadley
> | >
> |
>


From csardi.gabor at gmail.com  Wed Nov  5 02:44:31 2014
From: csardi.gabor at gmail.com (=?UTF-8?B?R8OhYm9yIENzw6FyZGk=?=)
Date: Tue, 4 Nov 2014 20:44:31 -0500
Subject: [Rd] r-release, r-oldrel
Message-ID: <CABtg=Kn2fDXQedu=KaXpEx21hSLu=HqDB=aE_QthPvs8LCSzuw@mail.gmail.com>

Hi All,

quick question. How does one know which R versions r-release and
r-oldrel correspond to? Is there a prefered way to determine this
programmatically?

So far I could only find messy ways, like parsing the HTML of the
homepage, or (for r-release) checking the latest R-x-x-x tag in the
SVN. The SVN is actually not bad, but how about r-oldrel? Is that
always the previous release? Or the previous minor?

Thanks, Best,
Gabor


From plummerm at iarc.fr  Wed Nov  5 11:50:03 2014
From: plummerm at iarc.fr (Martyn Plummer)
Date: Wed, 5 Nov 2014 10:50:03 +0000
Subject: [Rd] [R] Calculation of cross-correlation in ccf
In-Reply-To: <27647630.19060831415090677592.JavaMail.sami.toppinen@kolumbus.fi>
References: <27647630.19060831415090677592.JavaMail.sami.toppinen@kolumbus.fi>
Message-ID: <31E214B6DF75104E942856C2F74953CB051F6BD9@exchange>

The acf and ccf functions assume that time series are stationary, but yours are not.

I think that your alternative function is not well founded. You take a separate mean for each sub-series, which implicitly allows the mean of the series to vary arbitrarily with time. However, you only have one instance of each time series so you can't have a non-parametric model for the means.

A parametric approach is to remove a linear trend from the series and then apply ccf:

e1 <- residuals(lm(y1 ~ x))
e2 <- residuals(lm(y1 ~ x))
ccf(e1, e2)

which does identify a lag of -8 as the best match, although the correlation is somewhat lower than what you found (0.87).

Martyn

________________________________________
From: r-devel-bounces at r-project.org [r-devel-bounces at r-project.org] on behalf of Sami Toppinen [sami.toppinen at kolumbus.fi]
Sent: 04 November 2014 09:44
To: r-devel at r-project.org
Subject: [Rd] [R] Calculation of cross-correlation in ccf

Dear All,

I am studying some process measurement time series in R and trying to identify time delays using cross-correlation function ccf. The results have however been bit confusing. I found a couple of years old message about this issue but unfortunately wasn't able to find it again for a reference.

For example, an obvious time shift is observed between the measurements y1 and y2 when the following test data is plotted:

x <- 1:121
y1 <- c(328.27, 328.27, 328.27, 328.27, 328.21, 328.14, 328.14, 328.01,
  328.07, 328.01, 327.87, 328.01, 328.07, 328.27, 328.27, 328.54, 328.61,
  328.74, 328.88, 329.01, 329.01, 329.21, 329.28, 329.35, 329.35, 329.42,
  329.35, 329.28, 329.28, 329.15, 329.08, 329.08, 328.95, 328.95, 328.95,
  328.95, 329.01, 329.15, 329.21, 329.28, 329.55, 329.62, 329.75, 329.82,
  329.89, 330.09, 330.09, 330.29, 330.29, 330.36, 330.42, 330.29, 330.15,
  330.22, 330.09, 329.95, 329.82, 329.75, 329.62, 329.55, 329.48, 329.55,
  329.68, 329.75, 329.82, 329.89, 330.09, 330.09, 330.15, 330.22, 330.42,
  330.42, 330.42, 330.36, 330.42, 330.22, 330.15, 330.09, 329.89, 329.75,
  329.55, 329.35, 329.35, 329.42, 329.48, 329.55, 329.75, 329.75, 329.82,
  330.09, 330.15, 330.42, 330.42, 330.62, 330.69, 330.69, 330.83, 330.83,
  330.76, 330.62, 330.62, 330.56, 330.42, 330.42, 330.29, 330.29, 330.29,
  330.29, 330.22, 330.49, 330.56, 330.62, 330.76, 331.03, 330.96, 331.16,
  331.23, 331.50, 331.63, 332.03, 332.03)
y2 <- c(329.68, 329.75, 329.82, 329.95, 330.02, 330.15, 330.22, 330.36,
  330.22, 330.29, 330.29, 330.29, 330.29, 330.15, 330.22, 330.22, 330.15,
  330.15, 330.15, 330.15, 330.15, 330.29, 330.49, 330.49, 330.62, 330.89,
  331.03, 331.09, 331.16, 331.30, 331.30, 331.36, 331.43, 331.43, 331.43,
  331.36, 331.36, 331.36, 331.36, 331.23, 331.23, 331.16, 331.16, 331.23,
  331.30, 331.23, 331.36, 331.56, 331.70, 331.83, 331.97, 331.97, 332.10,
  332.30, 332.44, 332.44, 332.51, 332.51, 332.57, 332.57, 332.51, 332.37,
  332.24, 332.24, 332.10, 331.97, 331.97, 331.90, 331.83, 331.97, 331.97,
  331.97, 332.03, 332.24, 332.30, 332.30, 332.37, 332.57, 332.57, 332.57,
  332.57, 332.57, 332.51, 332.37, 332.30, 332.17, 331.97, 331.83, 331.70,
  331.70, 331.63, 331.63, 331.70, 331.83, 331.90, 332.10, 332.24, 332.30,
  332.44, 332.57, 332.71, 332.84, 332.77, 332.91, 332.84, 332.84, 332.91,
  332.84, 332.77, 332.77, 332.64, 332.64, 332.57, 332.57, 332.57, 332.57,
  332.57, 332.71, 332.98, 333.24, 333.58)
matplot(cbind(y1, y2))

However, the cross-correlation function surprisingly gives the maximum correlation 0.83 at zero lag:

ccf(y1, y2)

Plotting of variables against each other with zero lag

plot(y1, y2)

shows that the correlation is not that good. Instead, a very nice correlation is obtained with a plot with shifted variables:

plot(y1[1:113], y2[1:113 + 8])

As a comparison I defined my own cross correlation function:

cross.cor <- function(x, y, k)
{
  n <- length(x) - abs(k)
  if (k >= 0)
    cor(x[1:n + k], y[1:n])
  else
    cor(x[1:n], y[1:n - k])
}

The new function cross.cor gives maximum correlation of 0.99 at lag -8, and the shape of the correlation function is very different from the one obtained with ccf (both methods give same value at zero lag):

plot(-15:15, sapply(-15:15, function(lag) cross.cor(y1, y2, lag)),
  ylim = c(0.3, 1))
points(-15:15, ccf(y1, y2, 15, plot = FALSE)$acf, col = "red")

In order to understand the reason for the differences, I looked at the program codes of ccf function. When the variables are compared with a nonzero lag, some the data points must be left out from the tails of the time series. It appears to me that ccf calculates (partly in R code, partly in C code) first the means and the standard deviations using the whole data, and then uses those values as constants in further calculations. The time series are truncated only in the summations for covariances.

That approach naturally speeds up the computations, but is it really correct? Is the approach used in ccf somehow statistically more correct? I suppose the strong increasing trend in my test data emphasizes this issue (leaving data points out from one end has big impact on the average).

Best regards,
Sami Toppinen
sami.toppinen at kolumbus.fi

______________________________________________
R-devel at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-devel-----------------------------------------------------------------------
This message and its attachments are strictly confidenti...{{dropped:8}}


From maechler at stat.math.ethz.ch  Wed Nov  5 12:48:37 2014
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 5 Nov 2014 12:48:37 +0100
Subject: [Rd] R 3.1.1 and 3.1.2 both fail their test suites
In-Reply-To: <545766D3.9050809@gmail.com>
References: <87lhnvje7d.fsf@write-only.cryp.to>
	<5454F2E6.9090301@statistik.tu-dortmund.de>
	<87ioizndfa.fsf@write-only.cryp.to> <545515C4.2090900@gmail.com>
	<21591.18461.92369.277925@stat.math.ethz.ch>
	<545766D3.9050809@gmail.com>
Message-ID: <21594.3733.779424.351379@stat.math.ethz.ch>

>>>>> Duncan Murdoch <murdoch.duncan at gmail.com>
>>>>>     on Mon, 3 Nov 2014 06:28:19 -0500 writes:

    > On 03/11/2014, 4:17 AM, Martin Maechler wrote:
    >>>>>>> Duncan Murdoch <murdoch.duncan at gmail.com>
    >>>>>>> on Sat, 1 Nov 2014 13:17:56 -0400 writes:
    >> 
    >> > On 01/11/2014, 11:33 AM, Peter Simons wrote:
    >> >> Hi Uwe,
    >> >> 
    >> >> > Nobody in R core runs NixOS and can reproduce
    >> >> this. This passes on most > other platforms,
    >> >> apparently. If you can point us to a problem or send >
    >> >> patches, we'd appreciate it.
    >> >> 
    >> >> have tried running the test suite in a build that's
    >> >> configured with '--without-recommended-packages'? That's
    >> >> about the only unusual thing we do when building with
    >> >> Nix. Other than that, our build runs on a perfectly
    >> >> ordinary Linux -- and it used to succeed fine in earlier
    >> >> versions of R.
    >> 
    >> > The tests "make check-devel" and "make check-all" are
    >> > documented to require the recommended packages, and will
    >> > fail without them.  On Windows, "make check" also needs
    >> > them, so this may be true on other systems as well.
    >> 
    >> Thank you Duncan, for clarifying (above and later in the thread).
    >> 
    >> Would it be hard to strive for
    >> 
    >> 1)  'make check' should pass without-rec....
    >> 2)  'make check-devel' etc do require the recommended packages.
    >> 
    >> That would be ideal I think - and correspond to the fact that
    >> we call the recommended packages 'recommended' only.

    > I think we could avoid errors in make check, but not warnings.  People
    > need to understand what the tests are testing, and recognize that some
    > warnings are ignorable.

    > To do this, we'd need to make sure that no examples in base packages
    > require the use of recommended packages.  Currently the failure happens
    > in capture.output, because it runs the glm example which needs MASS.
    > (The glm example is marked not to need MASS during testing, but the
    > capture.output example runs everything.)  

aah.. that's interesting in itself: Maybe  example() should also
get 'run.dontcheck' argument in addition to its  'run.dontrun'
and Rd2ex() a similar enhancement.... I'm looking into that.

    > Fixing that one causes the error to happen later.

"fascinating", as Kurt may say ..

    >> OTOH, if '1)' is too much work for us, we could add this as a
    >> 'wishlist' item  and wait for someone to send patches..

    > Alternatively, we could require the recommended packages for all tests.

    > Duncan Murdoch

which seems too extreme. If some people really only want to test
something like "the R base engine", they should be easily able
to do so, and I still think that 'make check' should do exactly that.
In the tests/Makefile.{common|in} this is even called 
"test-all-basics"

One thing to consider might remove 'Examples' from the "all-basics"
and use 'Examples' only in a new make target between "basics"
and "devel".
But personally, I'd strive for fixing the few (I hope) cases in
the Examples we currently have.
Using the \dontcheck{..}  tag should really help there.

Martin Maechler


From murdoch.duncan at gmail.com  Wed Nov  5 13:12:40 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 5 Nov 2014 07:12:40 -0500
Subject: [Rd] R 3.1.1 and 3.1.2 both fail their test suites
In-Reply-To: <21594.3733.779424.351379@stat.math.ethz.ch>
References: <87lhnvje7d.fsf@write-only.cryp.to>	<5454F2E6.9090301@statistik.tu-dortmund.de>	<87ioizndfa.fsf@write-only.cryp.to>	<545515C4.2090900@gmail.com>	<21591.18461.92369.277925@stat.math.ethz.ch>	<545766D3.9050809@gmail.com>
	<21594.3733.779424.351379@stat.math.ethz.ch>
Message-ID: <545A1438.3060405@gmail.com>

On 05/11/2014, 6:48 AM, Martin Maechler wrote:
>>>>>> Duncan Murdoch <murdoch.duncan at gmail.com>
>>>>>>     on Mon, 3 Nov 2014 06:28:19 -0500 writes:
> 
>     > On 03/11/2014, 4:17 AM, Martin Maechler wrote:
>     >>>>>>> Duncan Murdoch <murdoch.duncan at gmail.com>
>     >>>>>>> on Sat, 1 Nov 2014 13:17:56 -0400 writes:
>     >> 
>     >> > On 01/11/2014, 11:33 AM, Peter Simons wrote:
>     >> >> Hi Uwe,
>     >> >> 
>     >> >> > Nobody in R core runs NixOS and can reproduce
>     >> >> this. This passes on most > other platforms,
>     >> >> apparently. If you can point us to a problem or send >
>     >> >> patches, we'd appreciate it.
>     >> >> 
>     >> >> have tried running the test suite in a build that's
>     >> >> configured with '--without-recommended-packages'? That's
>     >> >> about the only unusual thing we do when building with
>     >> >> Nix. Other than that, our build runs on a perfectly
>     >> >> ordinary Linux -- and it used to succeed fine in earlier
>     >> >> versions of R.
>     >> 
>     >> > The tests "make check-devel" and "make check-all" are
>     >> > documented to require the recommended packages, and will
>     >> > fail without them.  On Windows, "make check" also needs
>     >> > them, so this may be true on other systems as well.
>     >> 
>     >> Thank you Duncan, for clarifying (above and later in the thread).
>     >> 
>     >> Would it be hard to strive for
>     >> 
>     >> 1)  'make check' should pass without-rec....
>     >> 2)  'make check-devel' etc do require the recommended packages.
>     >> 
>     >> That would be ideal I think - and correspond to the fact that
>     >> we call the recommended packages 'recommended' only.
> 
>     > I think we could avoid errors in make check, but not warnings.  People
>     > need to understand what the tests are testing, and recognize that some
>     > warnings are ignorable.
> 
>     > To do this, we'd need to make sure that no examples in base packages
>     > require the use of recommended packages.  Currently the failure happens
>     > in capture.output, because it runs the glm example which needs MASS.
>     > (The glm example is marked not to need MASS during testing, but the
>     > capture.output example runs everything.)  
> 
> aah.. that's interesting in itself: Maybe  example() should also
> get 'run.dontcheck' argument in addition to its  'run.dontrun'
> and Rd2ex() a similar enhancement.... I'm looking into that.
> 
>     > Fixing that one causes the error to happen later.
> 
> "fascinating", as Kurt may say ..
> 
>     >> OTOH, if '1)' is too much work for us, we could add this as a
>     >> 'wishlist' item  and wait for someone to send patches..
> 
>     > Alternatively, we could require the recommended packages for all tests.
> 
>     > Duncan Murdoch
> 
> which seems too extreme. If some people really only want to test
> something like "the R base engine", they should be easily able
> to do so, and I still think that 'make check' should do exactly that.
> In the tests/Makefile.{common|in} this is even called 
> "test-all-basics"
> 
> One thing to consider might remove 'Examples' from the "all-basics"
> and use 'Examples' only in a new make target between "basics"
> and "devel".
> But personally, I'd strive for fixing the few (I hope) cases in
> the Examples we currently have.
> Using the \dontcheck{..}  tag should really help there.

I don't think we should be removing tests for everybody to allow a few
people to test a build of R that none of us actually use.

The choice of name "recommended" is unfortunate, because it suggests
that these packages are not necessary in order to get R to run:  but a
build that doesn't contain them won't work properly.  The test is giving
correct results:  R "without-recommended" is broken.

We might be able to get it to pass "make check" by removing tests, but
example(capture.output) and example(glm) will still fail.

Duncan Murdoch


From edd at debian.org  Wed Nov  5 13:43:37 2014
From: edd at debian.org (Dirk Eddelbuettel)
Date: Wed, 5 Nov 2014 06:43:37 -0600
Subject: [Rd] Linking to the BH package introduces CRAN warnings
In-Reply-To: <54596763.3020700@gmail.com>
References: <5458D68D.3070102@gmail.com>
	<21592.58816.359652.109459@max.nulle.part>
	<0CDE01C7-C290-4CB8-A1ED-B2A8816CBA49@r-enthusiasts.com>
	<CABdHhvEiGiXAYymj4Fw2BTMw7Jq+BHBu0q=CR6kCRXYFph2VKw@mail.gmail.com>
	<54595506.7000706@gmail.com>
	<21593.22718.944171.419082@max.nulle.part>
	<54596763.3020700@gmail.com>
Message-ID: <21594.7033.486398.753912@max.nulle.part>


On 5 November 2014 at 00:55, kaveh wrote:
| Dear all,
| 
| 
| the simple code in below, when send to the
| win-builder returns the following (and no other)
| warning:
| 
| 
| * checking compiled code ... WARNING
| File 'quicky/libs/i386/quicky.dll':
|    Found '_ZSt4cerr', possibly from 'std::cerr' (C++)
|      Object: 'quicky.o'
|    Found 'abort', possibly from 'abort' (C), 'runtime' (Fortran)
|      Object: 'quicky.o'
| File 'quicky/libs/x64/quicky.dll':
|    Found '_ZSt4cerr', possibly from 'std::cerr' (C++)
|      Object: 'quicky.o'
|    Found 'abort', possibly from 'abort' (C), 'runtime' (Fortran)
|      Object: 'quicky.o'
| 
| Compiled code should not call entry points which might terminate R nor
| write to stdout/stderr instead of to the console, nor the C RNG.
| 
| See 'Writing portable packages' in the 'Writing R Extensions' manual.
| 
| 
| Here is the source:
| 
| #include <algorithm>
| #include <cstdlib>
| #include <ctime>
| #include <functional>
| #include <fstream>
| #include <iostream>
| #include <math.h>
| #include <time.h>
| #include <stdio.h>
| #include <stdlib.h>
| #include <sstream>
| #include <vector>
| #include <random>
| 
| #include <boost/math/distributions/normal.hpp>
| #include <boost/math/distributions/chi_squared.hpp>
| 
| #include <Eigen/Dense>
| 
| using namespace std;
| using namespace Eigen;
| using Eigen::MatrixXd;
| using Eigen::VectorXd;
| using Eigen::VectorXi;
| using Eigen::RowVectorXd;
| 
| 
| using boost::math::chi_squared;
| using boost::math::quantile;
| using boost::math::complement;
| using boost::math::normal_distribution;
| using namespace boost::math::policies;
| 
| typedef policy<
|        promote_double<true>
|        > my_policy_norm;
| typedef policy<
|        promote_double<true>
|        > my_policy_chi2;
| 
| typedef boost::math::normal_distribution<double,my_policy_norm> my_norm;
| typedef boost::math::chi_squared_distribution<double,my_policy_chi2> 
| my_chi2;
| 
| 
| VectorXd GetQs(const VectorXd& x){
|      const int n=x.size();
|      double mytol=1e-8;
|      double the_max=x.maxCoeff();
|      double the_min=x.minCoeff();
|      double the_rag=(the_max-the_min);
|      if(the_rag<mytol)    return(x);
|      if(1.0-the_max<mytol)    return(x);
|      if(the_min<mytol)    return(x);
|      VectorXd y=x.array();
|      for(int i=0;i<n;i++) 
| y(i)=sqrt(quantile(complement(my_chi2(1.0),x(i))));
|      return(y);
| }
| extern "C"{
|      void quicky(int* rn,double* xi,double* yi){
|          const int n=*rn;
|          VectorXd x=Map<VectorXd>(xi,n);
|          Map<VectorXd>(yi,n)=GetQs(x);
|      }
| }
| 
| 
| So I guess, I should fill a bug report with the
| BH maintainer?

Err, why? BH does nothing wrong. 

You are NOT forced or required to use the Boost distributions header __as R
comes with the equivalent functionality__ via the Rmath.h header file from R.
Which has functionality that Rcpp provides to you in scalar and vector form.

And there are probably several dozen examples of using the R distribution
functions from Rcpp.

So this is _precisely_ what I suggested several mails ago: do your homework,
identify which header is causing it.  And the obvious next step is then to
not use the header.

Dirk
 

| Best regards,
| 
| 
| On 2014-11-04 23:52, Dirk Eddelbuettel wrote:
| > Gentlemen,
| >
| > On 4 November 2014 at 23:36, kaveh wrote:
| > | Dear Hadley,
| > |
| > | Thank you for this information, maybe the CRAN gods
| > | will look favourably on this case too,
| >
| > You seemed to have missed a point my earlier email tried to stress: Inclusion
| > of BH does not lead to the warning.
| >
| > All this depends on WHICH headers are included, and the OP will need to sort
| > this out by modifying his code.
| >
| > Dirk
| >   
| > | Best regards,
| > |
| > | On 2014-11-04 23:32, Hadley Wickham wrote:
| > | >>> | However, it seems some of the codes in the BH package
| > | >>> | might. At any rate, when I include some boost headers such as
| > | >>> | boost/math/distributions/ through BH, I get the following warnings
| > | >>> |   when  submitting to the win-builder page:
| > | >>> |
| > | >>> |
| > | >>> |    Found '_ZSt4cerr', possibly from 'std::cerr' (C++)
| > | >>> |
| > | >>> |    Found 'abort', possibly from 'abort' (C), 'runtime' (Fortran)
| > | >>> |
| > | >>> |    Found '_ZSt4cerr', possibly from 'std::cerr' (C++)
| > | >>> |
| > | >>> |    Found 'abort', possibly from 'abort' (C), 'runtime' (Fortran)
| > | >> You?re kind of out of luck. These functions are both:
| > | >>   - used by the boost headers
| > | >>   - forbidden by R, well at least forbidden by CRAN
| > | > Maaaaybe - I had this note in RSQLite, and CRAN seemed ok with my explanation:
| > | >
| > | > * checking compiled code ... NOTE
| > | >    File ?/Users/hadley/Documents/databases/RSQLite.Rcheck/RSQLite/libs/RSQLite.so?:
| > | >      Found ?___stderrp?, possibly from ?stderr? (C)
| > | >        Object: ?sqlite-all.o?
| > | >
| > | >    This is in C code from the embedded SQLite database.
| > | >
| > | >
| > | > Hadley
| > | >
| > |
| >
| 

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From vakili.kaveh.email at gmail.com  Wed Nov  5 13:54:52 2014
From: vakili.kaveh.email at gmail.com (kaveh)
Date: Wed, 05 Nov 2014 13:54:52 +0100
Subject: [Rd] Linking to the BH package introduces CRAN warnings
In-Reply-To: <21594.7033.486398.753912@max.nulle.part>
References: <5458D68D.3070102@gmail.com>	<21592.58816.359652.109459@max.nulle.part>	<0CDE01C7-C290-4CB8-A1ED-B2A8816CBA49@r-enthusiasts.com>	<CABdHhvEiGiXAYymj4Fw2BTMw7Jq+BHBu0q=CR6kCRXYFph2VKw@mail.gmail.com>	<54595506.7000706@gmail.com>	<21593.22718.944171.419082@max.nulle.part>	<54596763.3020700@gmail.com>
	<21594.7033.486398.753912@max.nulle.part>
Message-ID: <545A1E1C.1030409@gmail.com>

Dear,

I was expecting this reaction.

Please do not get caught up in the details of the examples,
which I have tried to make as simple as possible for your
benefit.

The main point is that if you remove the lines associated
with

boost/math/distributions/


the warning disappears as well. Ergo,

boost/math/distributions/

is causing the warnings.

Best regards,


On 2014-11-05 13:43, Dirk Eddelbuettel wrote:
> On 5 November 2014 at 00:55, kaveh wrote:
> | Dear all,
> |
> |
> | the simple code in below, when send to the
> | win-builder returns the following (and no other)
> | warning:
> |
> |
> | * checking compiled code ... WARNING
> | File 'quicky/libs/i386/quicky.dll':
> |    Found '_ZSt4cerr', possibly from 'std::cerr' (C++)
> |      Object: 'quicky.o'
> |    Found 'abort', possibly from 'abort' (C), 'runtime' (Fortran)
> |      Object: 'quicky.o'
> | File 'quicky/libs/x64/quicky.dll':
> |    Found '_ZSt4cerr', possibly from 'std::cerr' (C++)
> |      Object: 'quicky.o'
> |    Found 'abort', possibly from 'abort' (C), 'runtime' (Fortran)
> |      Object: 'quicky.o'
> |
> | Compiled code should not call entry points which might terminate R nor
> | write to stdout/stderr instead of to the console, nor the C RNG.
> |
> | See 'Writing portable packages' in the 'Writing R Extensions' manual.
> |
> |
> | Here is the source:
> |
> | #include <algorithm>
> | #include <cstdlib>
> | #include <ctime>
> | #include <functional>
> | #include <fstream>
> | #include <iostream>
> | #include <math.h>
> | #include <time.h>
> | #include <stdio.h>
> | #include <stdlib.h>
> | #include <sstream>
> | #include <vector>
> | #include <random>
> |
> | #include <boost/math/distributions/normal.hpp>
> | #include <boost/math/distributions/chi_squared.hpp>
> |
> | #include <Eigen/Dense>
> |
> | using namespace std;
> | using namespace Eigen;
> | using Eigen::MatrixXd;
> | using Eigen::VectorXd;
> | using Eigen::VectorXi;
> | using Eigen::RowVectorXd;
> |
> |
> | using boost::math::chi_squared;
> | using boost::math::quantile;
> | using boost::math::complement;
> | using boost::math::normal_distribution;
> | using namespace boost::math::policies;
> |
> | typedef policy<
> |        promote_double<true>
> |        > my_policy_norm;
> | typedef policy<
> |        promote_double<true>
> |        > my_policy_chi2;
> |
> | typedef boost::math::normal_distribution<double,my_policy_norm> my_norm;
> | typedef boost::math::chi_squared_distribution<double,my_policy_chi2>
> | my_chi2;
> |
> |
> | VectorXd GetQs(const VectorXd& x){
> |      const int n=x.size();
> |      double mytol=1e-8;
> |      double the_max=x.maxCoeff();
> |      double the_min=x.minCoeff();
> |      double the_rag=(the_max-the_min);
> |      if(the_rag<mytol)    return(x);
> |      if(1.0-the_max<mytol)    return(x);
> |      if(the_min<mytol)    return(x);
> |      VectorXd y=x.array();
> |      for(int i=0;i<n;i++)
> | y(i)=sqrt(quantile(complement(my_chi2(1.0),x(i))));
> |      return(y);
> | }
> | extern "C"{
> |      void quicky(int* rn,double* xi,double* yi){
> |          const int n=*rn;
> |          VectorXd x=Map<VectorXd>(xi,n);
> |          Map<VectorXd>(yi,n)=GetQs(x);
> |      }
> | }
> |
> |
> | So I guess, I should fill a bug report with the
> | BH maintainer?
>
> Err, why? BH does nothing wrong.
>
> You are NOT forced or required to use the Boost distributions header __as R
> comes with the equivalent functionality__ via the Rmath.h header file from R.
> Which has functionality that Rcpp provides to you in scalar and vector form.
>
> And there are probably several dozen examples of using the R distribution
> functions from Rcpp.
>
> So this is _precisely_ what I suggested several mails ago: do your homework,
> identify which header is causing it.  And the obvious next step is then to
> not use the header.
>
> Dirk
>   
>
> | Best regards,
> |
> |
> | On 2014-11-04 23:52, Dirk Eddelbuettel wrote:
> | > Gentlemen,
> | >
> | > On 4 November 2014 at 23:36, kaveh wrote:
> | > | Dear Hadley,
> | > |
> | > | Thank you for this information, maybe the CRAN gods
> | > | will look favourably on this case too,
> | >
> | > You seemed to have missed a point my earlier email tried to stress: Inclusion
> | > of BH does not lead to the warning.
> | >
> | > All this depends on WHICH headers are included, and the OP will need to sort
> | > this out by modifying his code.
> | >
> | > Dirk
> | >
> | > | Best regards,
> | > |
> | > | On 2014-11-04 23:32, Hadley Wickham wrote:
> | > | >>> | However, it seems some of the codes in the BH package
> | > | >>> | might. At any rate, when I include some boost headers such as
> | > | >>> | boost/math/distributions/ through BH, I get the following warnings
> | > | >>> |   when  submitting to the win-builder page:
> | > | >>> |
> | > | >>> |
> | > | >>> |    Found '_ZSt4cerr', possibly from 'std::cerr' (C++)
> | > | >>> |
> | > | >>> |    Found 'abort', possibly from 'abort' (C), 'runtime' (Fortran)
> | > | >>> |
> | > | >>> |    Found '_ZSt4cerr', possibly from 'std::cerr' (C++)
> | > | >>> |
> | > | >>> |    Found 'abort', possibly from 'abort' (C), 'runtime' (Fortran)
> | > | >> You?re kind of out of luck. These functions are both:
> | > | >>   - used by the boost headers
> | > | >>   - forbidden by R, well at least forbidden by CRAN
> | > | > Maaaaybe - I had this note in RSQLite, and CRAN seemed ok with my explanation:
> | > | >
> | > | > * checking compiled code ... NOTE
> | > | >    File ?/Users/hadley/Documents/databases/RSQLite.Rcheck/RSQLite/libs/RSQLite.so?:
> | > | >      Found ?___stderrp?, possibly from ?stderr? (C)
> | > | >        Object: ?sqlite-all.o?
> | > | >
> | > | >    This is in C code from the embedded SQLite database.
> | > | >
> | > | >
> | > | > Hadley
> | > | >
> | > |
> | >
> |
>


From pdalgd at gmail.com  Wed Nov  5 13:56:25 2014
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 5 Nov 2014 13:56:25 +0100
Subject: [Rd] R 3.1.1 and 3.1.2 both fail their test suites
In-Reply-To: <545A1438.3060405@gmail.com>
References: <87lhnvje7d.fsf@write-only.cryp.to>	<5454F2E6.9090301@statistik.tu-dortmund.de>	<87ioizndfa.fsf@write-only.cryp.to>	<545515C4.2090900@gmail.com>	<21591.18461.92369.277925@stat.math.ethz.ch>	<545766D3.9050809@gmail.com>
	<21594.3733.779424.351379@stat.math.ethz.ch>
	<545A1438.3060405@gmail.com>
Message-ID: <F24266E7-2937-4F2B-9DBD-DDA0642E1299@gmail.com>


On 05 Nov 2014, at 13:12 , Duncan Murdoch <murdoch.duncan at gmail.com> wrote:

> 
> I don't think we should be removing tests for everybody to allow a few
> people to test a build of R that none of us actually use.

Yes. Having R pass "make check" while breaking recommended packages would be unfortunate. I wouldn't object to special variations like "make check-without-recommended" or "make check-core". Except, of course, if the dontrun/dontcheck logic gets even more convoluted than it already is...


-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From romain at r-enthusiasts.com  Wed Nov  5 14:11:54 2014
From: romain at r-enthusiasts.com (Romain Francois)
Date: Wed, 5 Nov 2014 14:11:54 +0100
Subject: [Rd] Linking to the BH package introduces CRAN warnings
In-Reply-To: <21594.7033.486398.753912@max.nulle.part>
References: <5458D68D.3070102@gmail.com>
	<21592.58816.359652.109459@max.nulle.part>
	<0CDE01C7-C290-4CB8-A1ED-B2A8816CBA49@r-enthusiasts.com>
	<CABdHhvEiGiXAYymj4Fw2BTMw7Jq+BHBu0q=CR6kCRXYFph2VKw@mail.gmail.com>
	<54595506.7000706@gmail.com>
	<21593.22718.944171.419082@max.nulle.part>
	<54596763.3020700@gmail.com>
	<21594.7033.486398.753912@max.nulle.part>
Message-ID: <19E725B6-AC86-41BA-B20F-9D26A3CFCFDB@r-enthusiasts.com>



Envoy? de mon iPhone

> Le 5 nov. 2014 ? 13:43, Dirk Eddelbuettel <edd at debian.org> a ?crit :
> 
> 
> On 5 November 2014 at 00:55, kaveh wrote:
> | Dear all,
> | 
> | 
> | the simple code in below, when send to the
> | win-builder returns the following (and no other)
> | warning:
> | 
> | 
> | * checking compiled code ... WARNING
> | File 'quicky/libs/i386/quicky.dll':
> |    Found '_ZSt4cerr', possibly from 'std::cerr' (C++)
> |      Object: 'quicky.o'
> |    Found 'abort', possibly from 'abort' (C), 'runtime' (Fortran)
> |      Object: 'quicky.o'
> | File 'quicky/libs/x64/quicky.dll':
> |    Found '_ZSt4cerr', possibly from 'std::cerr' (C++)
> |      Object: 'quicky.o'
> |    Found 'abort', possibly from 'abort' (C), 'runtime' (Fortran)
> |      Object: 'quicky.o'
> | 
> | Compiled code should not call entry points which might terminate R nor
> | write to stdout/stderr instead of to the console, nor the C RNG.
> | 
> | See 'Writing portable packages' in the 'Writing R Extensions' manual.
> | 
> | 
> | Here is the source:
> | 
> | #include <algorithm>
> | #include <cstdlib>
> | #include <ctime>
> | #include <functional>
> | #include <fstream>
> | #include <iostream>
> | #include <math.h>
> | #include <time.h>
> | #include <stdio.h>
> | #include <stdlib.h>
> | #include <sstream>
> | #include <vector>
> | #include <random>
> | 
> | #include <boost/math/distributions/normal.hpp>
> | #include <boost/math/distributions/chi_squared.hpp>
> | 
> | #include <Eigen/Dense>
> | 
> | using namespace std;
> | using namespace Eigen;
> | using Eigen::MatrixXd;
> | using Eigen::VectorXd;
> | using Eigen::VectorXi;
> | using Eigen::RowVectorXd;
> | 
> | 
> | using boost::math::chi_squared;
> | using boost::math::quantile;
> | using boost::math::complement;
> | using boost::math::normal_distribution;
> | using namespace boost::math::policies;
> | 
> | typedef policy<
> |        promote_double<true>
> |        > my_policy_norm;
> | typedef policy<
> |        promote_double<true>
> |        > my_policy_chi2;
> | 
> | typedef boost::math::normal_distribution<double,my_policy_norm> my_norm;
> | typedef boost::math::chi_squared_distribution<double,my_policy_chi2> 
> | my_chi2;
> | 
> | 
> | VectorXd GetQs(const VectorXd& x){
> |      const int n=x.size();
> |      double mytol=1e-8;
> |      double the_max=x.maxCoeff();
> |      double the_min=x.minCoeff();
> |      double the_rag=(the_max-the_min);
> |      if(the_rag<mytol)    return(x);
> |      if(1.0-the_max<mytol)    return(x);
> |      if(the_min<mytol)    return(x);
> |      VectorXd y=x.array();
> |      for(int i=0;i<n;i++) 
> | y(i)=sqrt(quantile(complement(my_chi2(1.0),x(i))));
> |      return(y);
> | }
> | extern "C"{
> |      void quicky(int* rn,double* xi,double* yi){
> |          const int n=*rn;
> |          VectorXd x=Map<VectorXd>(xi,n);
> |          Map<VectorXd>(yi,n)=GetQs(x);
> |      }
> | }
> | 
> | 
> | So I guess, I should fill a bug report with the
> | BH maintainer?
> 
> Err, why? BH does nothing wrong. 

Calls to these forbidden fruits come from the BH tree so ...

> You are NOT forced or required to use the Boost distributions header __as R
> comes with the equivalent functionality__ via the Rmath.h header file from R.
> Which has functionality that Rcpp provides to you in scalar and vector form.
> 
> And there are probably several dozen examples of using the R distribution
> functions from Rcpp.
> 
> So this is _precisely_ what I suggested several mails ago: do your homework,
> identify which header is causing it.  And the obvious next step is then to
> not use the header.

So why these headers are shipped with BH then. 

> Dirk
> 
> 
> | Best regards,
> | 
> | 
> | On 2014-11-04 23:52, Dirk Eddelbuettel wrote:
> | > Gentlemen,
> | >
> | > On 4 November 2014 at 23:36, kaveh wrote:
> | > | Dear Hadley,
> | > |
> | > | Thank you for this information, maybe the CRAN gods
> | > | will look favourably on this case too,
> | >
> | > You seemed to have missed a point my earlier email tried to stress: Inclusion
> | > of BH does not lead to the warning.
> | >
> | > All this depends on WHICH headers are included, and the OP will need to sort
> | > this out by modifying his code.
> | >
> | > Dirk
> | >   
> | > | Best regards,
> | > |
> | > | On 2014-11-04 23:32, Hadley Wickham wrote:
> | > | >>> | However, it seems some of the codes in the BH package
> | > | >>> | might. At any rate, when I include some boost headers such as
> | > | >>> | boost/math/distributions/ through BH, I get the following warnings
> | > | >>> |   when  submitting to the win-builder page:
> | > | >>> |
> | > | >>> |
> | > | >>> |    Found '_ZSt4cerr', possibly from 'std::cerr' (C++)
> | > | >>> |
> | > | >>> |    Found 'abort', possibly from 'abort' (C), 'runtime' (Fortran)
> | > | >>> |
> | > | >>> |    Found '_ZSt4cerr', possibly from 'std::cerr' (C++)
> | > | >>> |
> | > | >>> |    Found 'abort', possibly from 'abort' (C), 'runtime' (Fortran)
> | > | >> You?re kind of out of luck. These functions are both:
> | > | >>   - used by the boost headers
> | > | >>   - forbidden by R, well at least forbidden by CRAN
> | > | > Maaaaybe - I had this note in RSQLite, and CRAN seemed ok with my explanation:
> | > | >
> | > | > * checking compiled code ... NOTE
> | > | >    File ?/Users/hadley/Documents/databases/RSQLite.Rcheck/RSQLite/libs/RSQLite.so?:
> | > | >      Found ?___stderrp?, possibly from ?stderr? (C)
> | > | >        Object: ?sqlite-all.o?
> | > | >
> | > | >    This is in C code from the embedded SQLite database.
> | > | >
> | > | >
> | > | > Hadley
> | > | >
> | > |
> | >
> | 
> 
> -- 
> http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From edd at debian.org  Wed Nov  5 14:26:40 2014
From: edd at debian.org (Dirk Eddelbuettel)
Date: Wed, 5 Nov 2014 07:26:40 -0600
Subject: [Rd] Linking to the BH package introduces CRAN warnings
In-Reply-To: <545A1E1C.1030409@gmail.com>
References: <5458D68D.3070102@gmail.com>
	<21592.58816.359652.109459@max.nulle.part>
	<0CDE01C7-C290-4CB8-A1ED-B2A8816CBA49@r-enthusiasts.com>
	<CABdHhvEiGiXAYymj4Fw2BTMw7Jq+BHBu0q=CR6kCRXYFph2VKw@mail.gmail.com>
	<54595506.7000706@gmail.com>
	<21593.22718.944171.419082@max.nulle.part>
	<54596763.3020700@gmail.com>
	<21594.7033.486398.753912@max.nulle.part>
	<545A1E1C.1030409@gmail.com>
Message-ID: <21594.9616.917830.191167@max.nulle.part>


On 5 November 2014 at 13:54, kaveh wrote:
| Dear,
| 
| I was expecting this reaction.
| 
| Please do not get caught up in the details of the examples,
| which I have tried to make as simple as possible for your
| benefit.

Well, to be perfectly honst, there you failed. 

No need to carry RcppEigen for example.  "Minimally reproducible" is how
describe ideal examples.
 
| The main point is that if you remove the lines associated
| with
| 
| boost/math/distributions/
| 
| 
| the warning disappears as well. Ergo,
| 
| boost/math/distributions/
| 
| is causing the warnings.

Yes, and I suggested to you to remove these lines, and offered you an easy
alternative already provided by the R system in which you are trying to craft
your extension.

I mentioned in my first email that I thought your post was probably off-topic
for r-devel.  You have now posted six more times to this list.  I would urge
to consider if it really the most appropropriate venue for this.

Hope this helps,  Dirk

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From edd at debian.org  Wed Nov  5 14:45:02 2014
From: edd at debian.org (Dirk Eddelbuettel)
Date: Wed, 5 Nov 2014 07:45:02 -0600
Subject: [Rd] Linking to the BH package introduces CRAN warnings
In-Reply-To: <19E725B6-AC86-41BA-B20F-9D26A3CFCFDB@r-enthusiasts.com>
References: <5458D68D.3070102@gmail.com>
	<21592.58816.359652.109459@max.nulle.part>
	<0CDE01C7-C290-4CB8-A1ED-B2A8816CBA49@r-enthusiasts.com>
	<CABdHhvEiGiXAYymj4Fw2BTMw7Jq+BHBu0q=CR6kCRXYFph2VKw@mail.gmail.com>
	<54595506.7000706@gmail.com>
	<21593.22718.944171.419082@max.nulle.part>
	<54596763.3020700@gmail.com>
	<21594.7033.486398.753912@max.nulle.part>
	<19E725B6-AC86-41BA-B20F-9D26A3CFCFDB@r-enthusiasts.com>
Message-ID: <21594.10718.756844.417316@max.nulle.part>


On 5 November 2014 at 14:11, Romain Francois wrote:
| > Le 5 nov. 2014 ? 13:43, Dirk Eddelbuettel <edd at debian.org> a ?crit :
| > You are NOT forced or required to use the Boost distributions header __as R
| > comes with the equivalent functionality__ via the Rmath.h header file from R.
| > Which has functionality that Rcpp provides to you in scalar and vector form.
| > 
| > And there are probably several dozen examples of using the R distribution
| > functions from Rcpp.
| > 
| > So this is _precisely_ what I suggested several mails ago: do your homework,
| > identify which header is causing it.  And the obvious next step is then to
| > not use the header.
| 
| So why these headers are shipped with BH then. 

The BH "builder" (ie the script local/scripts/CreateBoost.sh in the repo)
actively selects a number of Boost libraries [1], and uses the Boost tool
'bcp' to copy these (header-only) libraries -- plus all their dependencies.
The set of "selected components" grew out of initial requirements, plus
requests received since the package was created.  [2]

Now, just because some files within a library tickle a warning does not seem
to imply that all use of said warning is impossible. By my count, over two
dozen CRAN packages currently depend on BH [3] indicating some usefulness of BH,
including to the dplyr package you work on.

Policies and requirements do of cause charge, but I am not aware of any of
the two dozen package tickling this issue -- their use case is just fine,
thank you, and their requirements lead to the inclusion of the header
currently comprised in the package.

I hope this answers your question. Should you have further questions
concerning the BH package, could you be so kind as to bringing them to
appropriate list [4] or filing a ticket on GH?

Thanks, Dirk

[1] "components" may be a better term so we avoid the association with "linking"
[2] Another one of these requests just came in this week asking for circular_buffer.
[3] http://cran.r-project.org/web/packages/BH/index.html
[4] http://lists.r-forge.r-project.org/cgi-bin/mailman/listinfo/boostheaders-devel

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From simons at cryp.to  Wed Nov  5 15:36:17 2014
From: simons at cryp.to (Peter Simons)
Date: Wed, 5 Nov 2014 15:36:17 +0100
Subject: [Rd] R 3.1.1 and 3.1.2 both fail their test suites
References: <87lhnvje7d.fsf@write-only.cryp.to>
	<5454F2E6.9090301@statistik.tu-dortmund.de>
	<87ioizndfa.fsf@write-only.cryp.to> <545515C4.2090900@gmail.com>
	<21591.18461.92369.277925@stat.math.ethz.ch>
	<545766D3.9050809@gmail.com>
	<21594.3733.779424.351379@stat.math.ethz.ch>
	<545A1438.3060405@gmail.com>
Message-ID: <878ujpemu6.fsf@write-only.cryp.to>

Hi Duncan,

 > I don't think we should be removing tests for everybody to allow a few
 > people to test a build of R that none of us actually use.

no tests need to be removed. All that needs to be done is to distinguish
tests that require the recommended packages from those that don't. Then
users can choose which test set they want to run.

It would be particularly nice if "make check" would do the right thing
automatically based on the choice of --with{,out}-recommended-packages
at ./configure time. Offering two separate "check" targets would be
equally good, though.

Best regards,
Peter


From romain at r-enthusiasts.com  Wed Nov  5 16:18:01 2014
From: romain at r-enthusiasts.com (=?windows-1252?Q?Romain_Fran=E7ois?=)
Date: Wed, 5 Nov 2014 16:18:01 +0100
Subject: [Rd] Linking to the BH package introduces CRAN warnings
In-Reply-To: <21594.10718.756844.417316@max.nulle.part>
References: <5458D68D.3070102@gmail.com>
	<21592.58816.359652.109459@max.nulle.part>
	<0CDE01C7-C290-4CB8-A1ED-B2A8816CBA49@r-enthusiasts.com>
	<CABdHhvEiGiXAYymj4Fw2BTMw7Jq+BHBu0q=CR6kCRXYFph2VKw@mail.gmail.com>
	<54595506.7000706@gmail.com>
	<21593.22718.944171.419082@max.nulle.part>
	<54596763.3020700@gmail.com>
	<21594.7033.486398.753912@max.nulle.part>
	<19E725B6-AC86-41BA-B20F-9D26A3CFCFDB@r-enthusiasts.com>
	<21594.10718.756844.417316@max.nulle.part>
Message-ID: <EF4209F6-2223-42A3-ABC0-80466360B917@r-enthusiasts.com>


> Le 5 nov. 2014 ? 14:45, Dirk Eddelbuettel <edd at debian.org> a ?crit :
> 
> 
> On 5 November 2014 at 14:11, Romain Francois wrote:
> | > Le 5 nov. 2014 ? 13:43, Dirk Eddelbuettel <edd at debian.org> a ?crit :
> | > You are NOT forced or required to use the Boost distributions header __as R
> | > comes with the equivalent functionality__ via the Rmath.h header file from R.
> | > Which has functionality that Rcpp provides to you in scalar and vector form.
> | > 
> | > And there are probably several dozen examples of using the R distribution
> | > functions from Rcpp.
> | > 
> | > So this is _precisely_ what I suggested several mails ago: do your homework,
> | > identify which header is causing it.  And the obvious next step is then to
> | > not use the header.
> | 
> | So why these headers are shipped with BH then. 
> 
> The BH "builder" (ie the script local/scripts/CreateBoost.sh in the repo)
> actively selects a number of Boost libraries [1], and uses the Boost tool
> 'bcp' to copy these (header-only) libraries -- plus all their dependencies.
> The set of "selected components" grew out of initial requirements, plus
> requests received since the package was created.  [2]
> 
> Now, just because some files within a library tickle a warning does not seem
> to imply that all use of said warning is impossible. By my count, over two
> dozen CRAN packages currently depend on BH [3] indicating some usefulness of BH,
> including to the dplyr package you work on.

Yeah so that?s like ? we?ll sell you horticultural bulbs, but only use them for indoor culture of tomatoes, ?cause you know it?s illegal to grow weed ? whatever. 

Believe me, I?d love for dplyr not to depend on BH, which we use for unordered_map. 

> Policies and requirements do of cause charge, but I am not aware of any of
> the two dozen package tickling this issue -- their use case is just fine,
> thank you, and their requirements lead to the inclusion of the header
> currently comprised in the package.
> 
> I hope this answers your question. Should you have further questions
> concerning the BH package, could you be so kind as to bringing them to
> appropriate list [4] or filing a ticket on GH?

This was not really a question, so yes I guess it answers it. Not your fault, just the user?s fault of using something that is shipped yet is unusable. You?re in the clear. 

> Thanks, Dirk
> 
> [1] "components" may be a better term so we avoid the association with "linking"
> [2] Another one of these requests just came in this week asking for circular_buffer.
> [3] http://cran.r-project.org/web/packages/BH/index.html
> [4] http://lists.r-forge.r-project.org/cgi-bin/mailman/listinfo/boostheaders-devel
> 
> -- 
> http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From murdoch.duncan at gmail.com  Wed Nov  5 16:22:09 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 5 Nov 2014 10:22:09 -0500
Subject: [Rd] R 3.1.1 and 3.1.2 both fail their test suites
In-Reply-To: <878ujpemu6.fsf@write-only.cryp.to>
References: <87lhnvje7d.fsf@write-only.cryp.to>	<5454F2E6.9090301@statistik.tu-dortmund.de>	<87ioizndfa.fsf@write-only.cryp.to>
	<545515C4.2090900@gmail.com>	<21591.18461.92369.277925@stat.math.ethz.ch>	<545766D3.9050809@gmail.com>	<21594.3733.779424.351379@stat.math.ethz.ch>	<545A1438.3060405@gmail.com>
	<878ujpemu6.fsf@write-only.cryp.to>
Message-ID: <545A40A1.4000500@gmail.com>

On 05/11/2014 9:36 AM, Peter Simons wrote:
> Hi Duncan,
>
>   > I don't think we should be removing tests for everybody to allow a few
>   > people to test a build of R that none of us actually use.
>
> no tests need to be removed.

My response was to Martin, who proposed exactly that.

>   All that needs to be done is to distinguish
> tests that require the recommended packages from those that don't. Then
> users can choose which test set they want to run.

Go ahead and submit a patch that does this, and I expect it would be 
accepted.

Duncan Murdoch

>
> It would be particularly nice if "make check" would do the right thing
> automatically based on the choice of --with{,out}-recommended-packages
> at ./configure time. Offering two separate "check" targets would be
> equally good, though.
>
> Best regards,
> Peter
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From retep.meissner at gmail.com  Thu Nov  6 11:57:52 2014
From: retep.meissner at gmail.com (Peter Meissner)
Date: Thu, 06 Nov 2014 11:57:52 +0100
Subject: [Rd] Citation if copying R base code
Message-ID: <545B5430.2030403@gmail.com>

Dear Listeners,

... also I read the CRAN policies and tried to solve those questions 
myself I feel very much in the need of good advise ...


I am currently finishing a package that -- to solve some nasty problems 
with dirty data -- uses its own as.Date() equivalent methods (i.e. its 
own generic and methods).

Thereby, I shamelessly copied code from the as.Date() methods from the 
base package and only made some minor adjustments.

For my main achievement was copy-pasting I feel obliged to cite the 
efforts made by base package authors - do I, should I? Currently I only 
use the help files to mention that the generic and its methods are 
basically the same as as.Date(), except this and that.

And if yes how to do it best? What is the standard procedure here? 
Should I include base package authors as contributors in DESCRIPTION???

Am I allowed to use MIT + file license with that or is it wrong to do so?


I appreciate any advise on these (I think important) but very confusing 
matters of referencing and licensing.


Best, Peter


PS:
- My current description:
https://github.com/petermeissner/wikipediatrend/blob/master/DESCRIPTION

- the package specific as.Date() implementation:
https://github.com/petermeissner/wikipediatrend/blob/master/R/wp_date.R


From murdoch.duncan at gmail.com  Thu Nov  6 12:36:42 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 06 Nov 2014 06:36:42 -0500
Subject: [Rd] Citation if copying R base code
In-Reply-To: <545B5430.2030403@gmail.com>
References: <545B5430.2030403@gmail.com>
Message-ID: <545B5D4A.1060105@gmail.com>

On 06/11/2014, 5:57 AM, Peter Meissner wrote:
> Dear Listeners,
> 
> ... also I read the CRAN policies and tried to solve those questions 
> myself I feel very much in the need of good advise ...
> 
> 
> I am currently finishing a package that -- to solve some nasty problems 
> with dirty data -- uses its own as.Date() equivalent methods (i.e. its 
> own generic and methods).
> 
> Thereby, I shamelessly copied code from the as.Date() methods from the 
> base package and only made some minor adjustments.

There's no problem doing that, as long as you respect the license.  That
includes keeping the copyright notices from the files where you found
the code:  see the GPL

> 
> For my main achievement was copy-pasting I feel obliged to cite the 
> efforts made by base package authors - do I, should I? Currently I only 
> use the help files to mention that the generic and its methods are 
> basically the same as as.Date(), except this and that.

In your package help file it would be polite to describe the
contributions from the R source code.  In the DESCRIPTION file, the rule
is that all "significant" contributors must be included.  You'll need to
judge that, but from your description, I'd guess this counts.

> And if yes how to do it best? What is the standard procedure here? 
> Should I include base package authors as contributors in DESCRIPTION???
> 
> Am I allowed to use MIT + file license with that or is it wrong to do so?

No, you must use the GPL, since the code you copied is licensed under
the GPL.  You can choose to use version 2 or 3 (or both).  You do not
have permission to re-license R code under a different license.

Duncan Murdoch

> 
> 
> I appreciate any advise on these (I think important) but very confusing 
> matters of referencing and licensing.
> 
> 
> Best, Peter
> 
> 
> PS:
> - My current description:
> https://github.com/petermeissner/wikipediatrend/blob/master/DESCRIPTION
> 
> - the package specific as.Date() implementation:
> https://github.com/petermeissner/wikipediatrend/blob/master/R/wp_date.R
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From hb at biostat.ucsf.edu  Thu Nov  6 15:19:04 2014
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Thu, 6 Nov 2014 06:19:04 -0800
Subject: [Rd] Citation if copying R base code
In-Reply-To: <545B5D4A.1060105@gmail.com>
References: <545B5430.2030403@gmail.com>
	<545B5D4A.1060105@gmail.com>
Message-ID: <CAFDcVCQL3Y0c7h47C4fwthgOw+xM4kYSB1+9=F-D4pT96ds=Qg@mail.gmail.com>

On Nov 6, 2014 3:36 AM, "Duncan Murdoch" <murdoch.duncan at gmail.com> wrote:
>
> On 06/11/2014, 5:57 AM, Peter Meissner wrote:
> > Dear Listeners,
> >
> > ... also I read the CRAN policies and tried to solve those questions
> > myself I feel very much in the need of good advise ...
> >
> >
> > I am currently finishing a package that -- to solve some nasty problems
> > with dirty data -- uses its own as.Date() equivalent methods (i.e. its
> > own generic and methods).
> >
> > Thereby, I shamelessly copied code from the as.Date() methods from the
> > base package and only made some minor adjustments.
>
> There's no problem doing that, as long as you respect the license.  That
> includes keeping the copyright notices from the files where you found
> the code:  see the GPL
>
> >
> > For my main achievement was copy-pasting I feel obliged to cite the
> > efforts made by base package authors - do I, should I? Currently I only
> > use the help files to mention that the generic and its methods are
> > basically the same as as.Date(), except this and that.
>
> In your package help file it would be polite to describe the
> contributions from the R source code.  In the DESCRIPTION file, the rule
> is that all "significant" contributors must be included.  You'll need to
> judge that, but from your description, I'd guess this counts.
>
> > And if yes how to do it best? What is the standard procedure here?
> > Should I include base package authors as contributors in DESCRIPTION???
> >
> > Am I allowed to use MIT + file license with that or is it wrong to do
so?
>
> No, you must use the GPL, since the code you copied is licensed under
> the GPL.  You can choose to use version 2 or 3 (or both).  You do not
> have permission to re-license R code under a different license.

Theoretically you could ask the copyright holder of that piece of code
whether he/she/it allows you to use a different license. This brings up
another question: who is formally the copyright holder of the R source code
(and documentation)? The R Foundation, the individual who contributed the
code in the first place, or someone else? You could certainly imagine a
case where a piece of code was donated to R by someone, e.g. the code
originates from a user-contributed package and has not been modified since.
It may even be that that code was licensed under another license at the
time.

Henrik

>
> Duncan Murdoch
>
> >
> >
> > I appreciate any advise on these (I think important) but very confusing
> > matters of referencing and licensing.
> >
> >
> > Best, Peter
> >
> >
> > PS:
> > - My current description:
> > https://github.com/petermeissner/wikipediatrend/blob/master/DESCRIPTION
> >
> > - the package specific as.Date() implementation:
> > https://github.com/petermeissner/wikipediatrend/blob/master/R/wp_date.R
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

	[[alternative HTML version deleted]]


From rolandh at uni-muenster.de  Thu Nov  6 15:44:10 2014
From: rolandh at uni-muenster.de (rolandh at uni-muenster.de)
Date: Thu, 06 Nov 2014 15:44:10 +0100 (CET)
Subject: [Rd] Pkg creation: Sweave: multiple files vignette: Error in R
 CMD check
In-Reply-To: <545815ED.8080302@gmail.com>
Message-ID: <permail-20141106144410fe5316b600000b3a-rolandh@message-id.uni-muenster.de>

Hello R-developers!

First I want to thank Duncan, Sean and Ben (off-list-communication) for your
comments and suggestions!


Unfortunetly the renaming of the child.Rnw file to e.g. child.sub and also the
usage of an other file type like child.txt did not solve the Problem.
I got an ERROR in the beginning of the check process:
###
...
** installing vignettes
   ?Master.Rnw? using ?UTF-8?
Error in SweaveReadFile(c(ifile, file), syntax, encoding = encoding) :
  no Sweave file with name ?./TitlePage.sub? found
ERROR: installing vignettes failed
* removing ?/tmp/Rtmp1iHmcw/Rinst1bc110488fde/trajaggr?
      -----------------------------------
ERROR: package installation failed
###


I found a workaround which passes the "installing vignettes" process. In this
workaround the child.Rnw file (here: TitlePage.Rnw) is placed in a subfolder
of the  vignettes folder and \SweaveInput{} in the Master.Rnw-file looks like
this:
...
\SweaveInput{../../../../../../../../home/harry/.../R/R_wd/myPkg/.../vignettes/TitlePage/TitlePage.Rnw}
..

(By the way I do not see the difference between this and the original approach
with \SweaveInput{TitlePage/TitlePage.Rnw})

Unfortunetly there is still an issue related to this workaround!
I got a NOTE related to "checking re-building of vignette outputs" in the end
of the check process:
###
* checking running R code from vignettes ...
   ?Master.Rnw? using ?UTF-8? ... OK
 OK
* checking re-building of vignette outputs ... NOTE
Error in re-building vignettes:
  ...
Fehler: Verarbeitung der Vignette 'Master.Rnw' mit folgender Diagnose
fehlgeschlagen:
no Sweave file with name
?./../../../../../../../../../home/harry/.../R/R_wd/myPkg/.../vignettes/TitlePage/TitlePage.Rnw?
found
###

[This workaround idea came from:
http://r.789695.n4.nabble.com/Sweave-absolute-path-versus-relative-path-td3950135.html]


I am a newbie related to package creation and I am confused why the Sweave
file now is found in the beginning (original problem) but not in the end (new
NOTE in R CMD check)?
It seems to be a path problem. Is the "checking re-building of vignette
outputs" done out of another origin/ folder, e.g. like out of a temporal
created package source and / or out of /inst/doc? If it is like that this NOTE
seems to be unsolvable!?!
Any suggestions what to do to solve this?

Thank you very much again!
Cheers!
Roland



Duncan Murdoch schrieb am 2014-11-04:
> On 03/11/2014, 4:08 PM, rolandh at uni-muenster.de wrote:
> > Hello R-developers!

> > I am creating a package (using devtools and RStudio) and I would
> > like to split
> > my vignette into multiple Rnw-files.

> > As an example I tried the code from:
> > https://support.rstudio.com/hc/en-us/articles/200486298
> > (--> Working with multiple Rnw files)

> > The Rnw-files work fine with "Complie pdf" in RStudio as well as
> > with
> > Sweave("Master.Rnw").

> > But, if I try to check my package I get the following error:

> > ...
> > * creating vignettes ... ERROR
> > Error in texi2dvi(file = file, pdf = TRUE, clean = clean, quiet =
> > quiet,  :
> >   Ausf?hren von 'texi2dvi' f?r 'ChapterY.tex' fehlgeschlagen.
> > LaTeX errors:
> > ! LaTeX Error: Missing \begin{document}.

> > See the LaTeX manual or LaTeX Companion for explanation.
> > Type  H <return>  for immediate help.
> >  ...
> > ! Emergency stop.
> > <*> ...13 \let~\normaltilde  \input ./ChapterY.tex

> > *** (job aborted, no legal \end found)

> > !  ==> Fatal error occurred, no output PDF file produced!
> > Calls: <Anonymous> -> texi2pdf -> texi2dvi
> > Ausf?hrung angehalten
> > Fehler: Command failed (1)
> > Ausf?hrung angehalten

> > Exited with status 1.
> > ###


> > So, it seems like that it is tried to make a tex-file from my
> > child-Rnw-file
> > called "ChapterY.Rnw",
> > what of couse is not possible, because that file contains no
> > praeambel.

> > As a workaround I tried to put my child-Rnw-file in a subfolder
> > (ChapterY) and
> > calling this file by
> > \SweaveInput{ChapterY/ChapterY.Rnw}.
> > Again, "Complie pdf" as well as Sweave("Master.Rnw") works fine,
> > but with
> > checking the package
> > I get the following error:

> > Error in SweaveReadFile(c(ifile, file), syntax, encoding =
> > encoding) :
> >   no Sweave file with name ?./ChapterY/ChapterY.Rnw? found
> > ERROR: installing vignettes failed


> > By the way I tried that on different (L)ubuntu machines (12.04, 14)
> > which the
> > latest version of
> > RStudio and R, and I also tried it after updating texlive to
> > version 2012,
> > always getting the same error.

> > Moreover, if I just use one Rnw-file instaed of multiple files
> > checking the
> > package finished fine without errors!

> > I do not know what to do anymore, and I did not find any solution
> > in the www
> > ...

> > Do someone has any idea how to solve this problem in any way?

> > Thank you very very much in advance!

> I suspect the problem is that the check code can't tell which is the
> main file, and which ones are the sub files.  Have you tried naming
> the
> sub files something else, e.g. chapter.sub?

> Duncan Murdoch


> > Greetings!

> > Roland

> > ###
> > R version 3.1.2 (2014-10-31)
> > Platform: i686-pc-linux-gnu (32-bit)

> > locale:
> >  [1] LC_CTYPE=de_DE.UTF-8       LC_NUMERIC=C
> >  LC_TIME=de_DE.UTF-8
> >  LC_COLLATE=de_DE.UTF-8
> >  [5] LC_MONETARY=de_DE.UTF-8    LC_MESSAGES=de_DE.UTF-8
> >  LC_PAPER=de_DE.UTF-8       LC_NAME=C
> >  [9] LC_ADDRESS=C               LC_TELEPHONE=C
> >  LC_MEASUREMENT=de_DE.UTF-8 LC_IDENTIFICATION=C

> > attached base packages:
> > [1] stats     graphics  grDevices utils     datasets  methods
> > base

> > other attached packages:
> > [1] trajcoert01_0.1

> > loaded via a namespace (and not attached):
> >  [1] devtools_1.6       geosphere_1.3-8    grid_3.1.2
> >  intervals_0.14.0
> >  lattice_0.20-29
> >  [6] move_1.2.475       raster_2.2-31      rgdal_0.8-16
> >  rgeos_0.3-4
> >  sp_1.0-15
> > [11] spacetime_1.1-2    tools_3.1.2        trajectories_0.1-1
> > xts_0.9-7
> > zoo_1.7-11
> > ###

> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel


From h.wickham at gmail.com  Thu Nov  6 15:46:43 2014
From: h.wickham at gmail.com (Hadley Wickham)
Date: Thu, 6 Nov 2014 08:46:43 -0600
Subject: [Rd] Citation if copying R base code
In-Reply-To: <545B5D4A.1060105@gmail.com>
References: <545B5430.2030403@gmail.com> <545B5D4A.1060105@gmail.com>
Message-ID: <CABdHhvEdsAxhtE7P6GcBa=C6FpxAAf8pHANavfytQk=vXuhfiQ@mail.gmail.com>

>> And if yes how to do it best? What is the standard procedure here?
>> Should I include base package authors as contributors in DESCRIPTION???
>>
>> Am I allowed to use MIT + file license with that or is it wrong to do so?
>
> No, you must use the GPL, since the code you copied is licensed under
> the GPL.  You can choose to use version 2 or 3 (or both).  You do not
> have permission to re-license R code under a different license.

I think it's slightly murkier than that - MIT is GPL compatible, so
you could license the code you've written as MIT, but the package as a
whole would need to be GPL-2/3.

Hadley

-- 
http://had.co.nz/


From h.wickham at gmail.com  Thu Nov  6 15:49:05 2014
From: h.wickham at gmail.com (Hadley Wickham)
Date: Thu, 6 Nov 2014 08:49:05 -0600
Subject: [Rd] Citation if copying R base code
In-Reply-To: <CAFDcVCQL3Y0c7h47C4fwthgOw+xM4kYSB1+9=F-D4pT96ds=Qg@mail.gmail.com>
References: <545B5430.2030403@gmail.com> <545B5D4A.1060105@gmail.com>
	<CAFDcVCQL3Y0c7h47C4fwthgOw+xM4kYSB1+9=F-D4pT96ds=Qg@mail.gmail.com>
Message-ID: <CABdHhvGOp2wkcQ7yLhoAS27YstU0mEURybN2cdi+L6X60tjwFQ@mail.gmail.com>

> Theoretically you could ask the copyright holder of that piece of code
> whether he/she/it allows you to use a different license. This brings up
> another question: who is formally the copyright holder of the R source code
> (and documentation)? The R Foundation, the individual who contributed the
> code in the first place, or someone else? You could certainly imagine a
> case where a piece of code was donated to R by someone, e.g. the code
> originates from a user-contributed package and has not been modified since.
> It may even be that that code was licensed under another license at the
> time.

Unless a contributor signs a contributor license agreement, the
copyright belongs to the original author.  I don't think that the
R-foundation is in the practice of requiring these, so the the
copyright of R itself will be a mismash of many different people. This
is can be seen as a good thing because it makes it impossible to
re-license code away from the GPL.

Hadley

-- 
http://had.co.nz/


From csardi.gabor at gmail.com  Thu Nov  6 15:55:28 2014
From: csardi.gabor at gmail.com (=?UTF-8?B?R8OhYm9yIENzw6FyZGk=?=)
Date: Thu, 6 Nov 2014 09:55:28 -0500
Subject: [Rd] Citation if copying R base code
In-Reply-To: <CABdHhvEdsAxhtE7P6GcBa=C6FpxAAf8pHANavfytQk=vXuhfiQ@mail.gmail.com>
References: <545B5430.2030403@gmail.com> <545B5D4A.1060105@gmail.com>
	<CABdHhvEdsAxhtE7P6GcBa=C6FpxAAf8pHANavfytQk=vXuhfiQ@mail.gmail.com>
Message-ID: <CABtg=KnJp2WM53N-tM3NSR0WqaqCDzS=hvU2sooABgCRecwhmA@mail.gmail.com>

On Thu, Nov 6, 2014 at 9:46 AM, Hadley Wickham <h.wickham at gmail.com> wrote:
>>> And if yes how to do it best? What is the standard procedure here?
>>> Should I include base package authors as contributors in DESCRIPTION???
>>>
>>> Am I allowed to use MIT + file license with that or is it wrong to do so?
>>
>> No, you must use the GPL, since the code you copied is licensed under
>> the GPL.  You can choose to use version 2 or 3 (or both).  You do not
>> have permission to re-license R code under a different license.
>
> I think it's slightly murkier than that - MIT is GPL compatible, so
> you could license the code you've written as MIT, but the package as a
> whole would need to be GPL-2/3.

The package can also be under AGPLv3 AFAIK, just for the sake of completeness.
Maybe something else as well.

Gabor

> Hadley
>
> --
> http://had.co.nz/
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From retep.meissner at gmail.com  Thu Nov  6 16:05:22 2014
From: retep.meissner at gmail.com (Peter Meissner)
Date: Thu, 06 Nov 2014 16:05:22 +0100
Subject: [Rd] Citation if copying R base code
In-Reply-To: <CABdHhvEdsAxhtE7P6GcBa=C6FpxAAf8pHANavfytQk=vXuhfiQ@mail.gmail.com>
References: <545B5430.2030403@gmail.com> <545B5D4A.1060105@gmail.com>
	<CABdHhvEdsAxhtE7P6GcBa=C6FpxAAf8pHANavfytQk=vXuhfiQ@mail.gmail.com>
Message-ID: <545B8E32.403@gmail.com>

But how might I do that?

Writing GPL in DESCRIPTION and putting my name in every R-file?




Am 2014-11-06 15:46, schrieb Hadley Wickham:
>>> And if yes how to do it best? What is the standard procedure here?
>>> Should I include base package authors as contributors in DESCRIPTION???
>>>
>>> Am I allowed to use MIT + file license with that or is it wrong to do so?
>>
>> No, you must use the GPL, since the code you copied is licensed under
>> the GPL.  You can choose to use version 2 or 3 (or both).  You do not
>> have permission to re-license R code under a different license.
>
> I think it's slightly murkier than that - MIT is GPL compatible, so
> you could license the code you've written as MIT, but the package as a
> whole would need to be GPL-2/3.
>
> Hadley
>


From murdoch.duncan at gmail.com  Thu Nov  6 16:05:48 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 06 Nov 2014 10:05:48 -0500
Subject: [Rd] Citation if copying R base code
In-Reply-To: <CABdHhvGOp2wkcQ7yLhoAS27YstU0mEURybN2cdi+L6X60tjwFQ@mail.gmail.com>
References: <545B5430.2030403@gmail.com> <545B5D4A.1060105@gmail.com>
	<CAFDcVCQL3Y0c7h47C4fwthgOw+xM4kYSB1+9=F-D4pT96ds=Qg@mail.gmail.com>
	<CABdHhvGOp2wkcQ7yLhoAS27YstU0mEURybN2cdi+L6X60tjwFQ@mail.gmail.com>
Message-ID: <545B8E4C.4050809@gmail.com>

On 06/11/2014 9:49 AM, Hadley Wickham wrote:
> > Theoretically you could ask the copyright holder of that piece of code
> > whether he/she/it allows you to use a different license. This brings up
> > another question: who is formally the copyright holder of the R source code
> > (and documentation)? The R Foundation, the individual who contributed the
> > code in the first place, or someone else? You could certainly imagine a
> > case where a piece of code was donated to R by someone, e.g. the code
> > originates from a user-contributed package and has not been modified since.
> > It may even be that that code was licensed under another license at the
> > time.
>
> Unless a contributor signs a contributor license agreement, the
> copyright belongs to the original author.  I don't think that the
> R-foundation is in the practice of requiring these, so the the
> copyright of R itself will be a mismash of many different people. This
> is can be seen as a good thing because it makes it impossible to
> re-license code away from the GPL.

Yes, that's right.  We often enter lines like

Copyright (C) 1997--2014  The R Core Team

into the sources, but I suspect that those don't legally imply a 
copyright transfer, at least where I live.

Duncan Murdoch


From csardi.gabor at gmail.com  Thu Nov  6 16:11:49 2014
From: csardi.gabor at gmail.com (=?UTF-8?B?R8OhYm9yIENzw6FyZGk=?=)
Date: Thu, 6 Nov 2014 10:11:49 -0500
Subject: [Rd] Citation if copying R base code
In-Reply-To: <545B8E32.403@gmail.com>
References: <545B5430.2030403@gmail.com> <545B5D4A.1060105@gmail.com>
	<CABdHhvEdsAxhtE7P6GcBa=C6FpxAAf8pHANavfytQk=vXuhfiQ@mail.gmail.com>
	<545B8E32.403@gmail.com>
Message-ID: <CABtg=K=JBRmjH0=mSHb5WpELJ4ZWt+G_asgbrBKA+mYstxeA+Q@mail.gmail.com>

On Thu, Nov 6, 2014 at 10:05 AM, Peter Meissner
<retep.meissner at gmail.com> wrote:
> But how might I do that?
>
> Writing GPL in DESCRIPTION and putting my name in every R-file?

Maybe see http://www.gnu.org/licenses/gpl-howto.html
It has some example header that you can put in each source file.

Gabor

>
>
>
> Am 2014-11-06 15:46, schrieb Hadley Wickham:
>>>>
>>>> And if yes how to do it best? What is the standard procedure here?
>>>> Should I include base package authors as contributors in DESCRIPTION???
>>>>
>>>> Am I allowed to use MIT + file license with that or is it wrong to do
>>>> so?
>>>
>>>
>>> No, you must use the GPL, since the code you copied is licensed under
>>> the GPL.  You can choose to use version 2 or 3 (or both).  You do not
>>> have permission to re-license R code under a different license.
>>
>>
>> I think it's slightly murkier than that - MIT is GPL compatible, so
>> you could license the code you've written as MIT, but the package as a
>> whole would need to be GPL-2/3.
>>
>> Hadley
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From h.wickham at gmail.com  Thu Nov  6 16:11:44 2014
From: h.wickham at gmail.com (Hadley Wickham)
Date: Thu, 6 Nov 2014 09:11:44 -0600
Subject: [Rd] Citation if copying R base code
In-Reply-To: <545B8E4C.4050809@gmail.com>
References: <545B5430.2030403@gmail.com> <545B5D4A.1060105@gmail.com>
	<CAFDcVCQL3Y0c7h47C4fwthgOw+xM4kYSB1+9=F-D4pT96ds=Qg@mail.gmail.com>
	<CABdHhvGOp2wkcQ7yLhoAS27YstU0mEURybN2cdi+L6X60tjwFQ@mail.gmail.com>
	<545B8E4C.4050809@gmail.com>
Message-ID: <CABdHhvHmAopUtSpRQiceLhR5O+X3YJ5ZORU0BbYdKf1eX=ritg@mail.gmail.com>

> Yes, that's right.  We often enter lines like
>
> Copyright (C) 1997--2014  The R Core Team
>
> into the sources, but I suspect that those don't legally imply a copyright
> transfer, at least where I live.

It's also not clear that R Core Team is a legal entity that can own copyright.

Hadley

-- 
http://had.co.nz/


From murdoch.duncan at gmail.com  Thu Nov  6 16:26:05 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 06 Nov 2014 10:26:05 -0500
Subject: [Rd] Citation if copying R base code
In-Reply-To: <545B8E32.403@gmail.com>
References: <545B5430.2030403@gmail.com> <545B5D4A.1060105@gmail.com>
	<CABdHhvEdsAxhtE7P6GcBa=C6FpxAAf8pHANavfytQk=vXuhfiQ@mail.gmail.com>
	<545B8E32.403@gmail.com>
Message-ID: <545B930D.8070204@gmail.com>

On 06/11/2014 10:05 AM, Peter Meissner wrote:
> But how might I do that?
>
> Writing GPL in DESCRIPTION and putting my name in every R-file?

You should probably choose a version to be unambiguous, e.g. use "GPL-2 
| GPL-3".  There's a section on this in "Writing R Extensions".

The files that you write can contain a copyright notice if you like, but 
it is not a requirement, just generally good practice.  The parts that 
are taken from R must contain copies of the copyright notices from the 
originals.  If you do include a copyright notice in your own code, then 
anyone using it will be required by the GPL to keep that one, as well as 
the R copyrights.


>
>
>
>
> Am 2014-11-06 15:46, schrieb Hadley Wickham:
> >>> And if yes how to do it best? What is the standard procedure here?
> >>> Should I include base package authors as contributors in DESCRIPTION???
> >>>
> >>> Am I allowed to use MIT + file license with that or is it wrong to do so?
> >>
> >> No, you must use the GPL, since the code you copied is licensed under
> >> the GPL.  You can choose to use version 2 or 3 (or both).  You do not
> >> have permission to re-license R code under a different license.
> >
> > I think it's slightly murkier than that - MIT is GPL compatible, so
> > you could license the code you've written as MIT, but the package as a
> > whole would need to be GPL-2/3.


Yes, it is complicated.  For files where you own the copyright, you can 
license them any way you like in addition to the GPL license. 
Effectively this means you can be more liberal (granting more rights), 
but you can't be more restrictive:  because you've included GPL code, 
you must give recipients of your whole package the rights that the GPL 
grants.

For files from R where you don't own the copyright, you are using them 
under the GPL, so you don't have the freedom to change the license.

Duncan Murdoch


From retep.meissner at gmail.com  Thu Nov  6 17:01:07 2014
From: retep.meissner at gmail.com (Peter Meissner)
Date: Thu, 06 Nov 2014 17:01:07 +0100
Subject: [Rd] Citation if copying R base code
In-Reply-To: <545B5D4A.1060105@gmail.com>
References: <545B5430.2030403@gmail.com> <545B5D4A.1060105@gmail.com>
Message-ID: <545B9B43.7070306@gmail.com>

Thank you all for your advise, comments and suggestions.


To keep it simple and play it fair and save, I choose to take the 
following actions:


Within DESCRIPTION

- the License now reads:
License: GPL (>= 2)

- the Authors are specified as
Authors at R: as.person(c(
     "Peter Meissner <retep.meissner at gmail.com> [aut, cre]",
     "R Core team [ctb] (wp_date() derived from base package as.Date())"
     ))


Also, the wp_date() help files mention where I copied and where I did 
rewrite code. I hope that's fine and good for everyone.



Puh. - That's it.

Best, Peter


From xie at yihui.name  Thu Nov  6 18:34:02 2014
From: xie at yihui.name (Yihui Xie)
Date: Thu, 6 Nov 2014 11:34:02 -0600
Subject: [Rd] Pkg creation: Sweave: multiple files vignette: Error in R
 CMD check
In-Reply-To: <permail-20141106144410fe5316b600000b3a-rolandh@message-id.uni-muenster.de>
References: <545815ED.8080302@gmail.com>
	<permail-20141106144410fe5316b600000b3a-rolandh@message-id.uni-muenster.de>
Message-ID: <CANROs4dhXA5Q1VFg_GRDGd=F8xOKdW+=Qr-WNW7Bh1o-H3JayA@mail.gmail.com>

My guess is that your child Rnw file was not copied to inst/doc during
R CMD build or check. You may read the section 1.4 of the R-exts
manual: http://cran.rstudio.com/doc/manuals/r-release/R-exts.html#Writing-package-vignettes

> When R CMD build builds the vignettes, it copies these and the vignette sources from directory vignettes to inst/doc. To install any other files from the vignettes directory, include a file vignettes/.install_extras which specifies these as Perl-like regular expressions on one or more lines. (See the description of the .Rinstignore file for full details.)

So it seems you will need a .install_extras file to make sure the
child Rnw file is copied along with the parent .Rnw. I do not think
you have to obfuscate the path of the child Rnw file like
../../whatever/... but you do have to change its file extension if and
only if you put it under the root directory vignettes/ (it should be
fine if it is under a sub directory).

Regards,
Yihui
--
Yihui Xie <xieyihui at gmail.com>
Web: http://yihui.name


On Thu, Nov 6, 2014 at 8:44 AM,  <rolandh at uni-muenster.de> wrote:
> Hello R-developers!
>
> First I want to thank Duncan, Sean and Ben (off-list-communication) for your
> comments and suggestions!
>
>
> Unfortunetly the renaming of the child.Rnw file to e.g. child.sub and also the
> usage of an other file type like child.txt did not solve the Problem.
> I got an ERROR in the beginning of the check process:
> ###
> ...
> ** installing vignettes
>    ?Master.Rnw? using ?UTF-8?
> Error in SweaveReadFile(c(ifile, file), syntax, encoding = encoding) :
>   no Sweave file with name ?./TitlePage.sub? found
> ERROR: installing vignettes failed
> * removing ?/tmp/Rtmp1iHmcw/Rinst1bc110488fde/trajaggr?
>       -----------------------------------
> ERROR: package installation failed
> ###
>
>
> I found a workaround which passes the "installing vignettes" process. In this
> workaround the child.Rnw file (here: TitlePage.Rnw) is placed in a subfolder
> of the  vignettes folder and \SweaveInput{} in the Master.Rnw-file looks like
> this:
> ...
> \SweaveInput{../../../../../../../../home/harry/.../R/R_wd/myPkg/.../vignettes/TitlePage/TitlePage.Rnw}
> ..
>
> (By the way I do not see the difference between this and the original approach
> with \SweaveInput{TitlePage/TitlePage.Rnw})
>
> Unfortunetly there is still an issue related to this workaround!
> I got a NOTE related to "checking re-building of vignette outputs" in the end
> of the check process:
> ###
> * checking running R code from vignettes ...
>    ?Master.Rnw? using ?UTF-8? ... OK
>  OK
> * checking re-building of vignette outputs ... NOTE
> Error in re-building vignettes:
>   ...
> Fehler: Verarbeitung der Vignette 'Master.Rnw' mit folgender Diagnose
> fehlgeschlagen:
> no Sweave file with name
> ?./../../../../../../../../../home/harry/.../R/R_wd/myPkg/.../vignettes/TitlePage/TitlePage.Rnw?
> found
> ###
>
> [This workaround idea came from:
> http://r.789695.n4.nabble.com/Sweave-absolute-path-versus-relative-path-td3950135.html]
>
>
> I am a newbie related to package creation and I am confused why the Sweave
> file now is found in the beginning (original problem) but not in the end (new
> NOTE in R CMD check)?
> It seems to be a path problem. Is the "checking re-building of vignette
> outputs" done out of another origin/ folder, e.g. like out of a temporal
> created package source and / or out of /inst/doc? If it is like that this NOTE
> seems to be unsolvable!?!
> Any suggestions what to do to solve this?
>
> Thank you very much again!
> Cheers!
> Roland
>
>
>
> Duncan Murdoch schrieb am 2014-11-04:
>> On 03/11/2014, 4:08 PM, rolandh at uni-muenster.de wrote:
>> > Hello R-developers!
>
>> > I am creating a package (using devtools and RStudio) and I would
>> > like to split
>> > my vignette into multiple Rnw-files.
>
>> > As an example I tried the code from:
>> > https://support.rstudio.com/hc/en-us/articles/200486298
>> > (--> Working with multiple Rnw files)
>
>> > The Rnw-files work fine with "Complie pdf" in RStudio as well as
>> > with
>> > Sweave("Master.Rnw").
>
>> > But, if I try to check my package I get the following error:
>
>> > ...
>> > * creating vignettes ... ERROR
>> > Error in texi2dvi(file = file, pdf = TRUE, clean = clean, quiet =
>> > quiet,  :
>> >   Ausf?hren von 'texi2dvi' f?r 'ChapterY.tex' fehlgeschlagen.
>> > LaTeX errors:
>> > ! LaTeX Error: Missing \begin{document}.
>
>> > See the LaTeX manual or LaTeX Companion for explanation.
>> > Type  H <return>  for immediate help.
>> >  ...
>> > ! Emergency stop.
>> > <*> ...13 \let~\normaltilde  \input ./ChapterY.tex
>
>> > *** (job aborted, no legal \end found)
>
>> > !  ==> Fatal error occurred, no output PDF file produced!
>> > Calls: <Anonymous> -> texi2pdf -> texi2dvi
>> > Ausf?hrung angehalten
>> > Fehler: Command failed (1)
>> > Ausf?hrung angehalten
>
>> > Exited with status 1.
>> > ###
>
>
>> > So, it seems like that it is tried to make a tex-file from my
>> > child-Rnw-file
>> > called "ChapterY.Rnw",
>> > what of couse is not possible, because that file contains no
>> > praeambel.
>
>> > As a workaround I tried to put my child-Rnw-file in a subfolder
>> > (ChapterY) and
>> > calling this file by
>> > \SweaveInput{ChapterY/ChapterY.Rnw}.
>> > Again, "Complie pdf" as well as Sweave("Master.Rnw") works fine,
>> > but with
>> > checking the package
>> > I get the following error:
>
>> > Error in SweaveReadFile(c(ifile, file), syntax, encoding =
>> > encoding) :
>> >   no Sweave file with name ?./ChapterY/ChapterY.Rnw? found
>> > ERROR: installing vignettes failed
>
>
>> > By the way I tried that on different (L)ubuntu machines (12.04, 14)
>> > which the
>> > latest version of
>> > RStudio and R, and I also tried it after updating texlive to
>> > version 2012,
>> > always getting the same error.
>
>> > Moreover, if I just use one Rnw-file instaed of multiple files
>> > checking the
>> > package finished fine without errors!
>
>> > I do not know what to do anymore, and I did not find any solution
>> > in the www
>> > ...
>
>> > Do someone has any idea how to solve this problem in any way?
>
>> > Thank you very very much in advance!
>
>> I suspect the problem is that the check code can't tell which is the
>> main file, and which ones are the sub files.  Have you tried naming
>> the
>> sub files something else, e.g. chapter.sub?
>
>> Duncan Murdoch
>
>
>> > Greetings!
>
>> > Roland
>
>> > ###
>> > R version 3.1.2 (2014-10-31)
>> > Platform: i686-pc-linux-gnu (32-bit)
>
>> > locale:
>> >  [1] LC_CTYPE=de_DE.UTF-8       LC_NUMERIC=C
>> >  LC_TIME=de_DE.UTF-8
>> >  LC_COLLATE=de_DE.UTF-8
>> >  [5] LC_MONETARY=de_DE.UTF-8    LC_MESSAGES=de_DE.UTF-8
>> >  LC_PAPER=de_DE.UTF-8       LC_NAME=C
>> >  [9] LC_ADDRESS=C               LC_TELEPHONE=C
>> >  LC_MEASUREMENT=de_DE.UTF-8 LC_IDENTIFICATION=C
>
>> > attached base packages:
>> > [1] stats     graphics  grDevices utils     datasets  methods
>> > base
>
>> > other attached packages:
>> > [1] trajcoert01_0.1
>
>> > loaded via a namespace (and not attached):
>> >  [1] devtools_1.6       geosphere_1.3-8    grid_3.1.2
>> >  intervals_0.14.0
>> >  lattice_0.20-29
>> >  [6] move_1.2.475       raster_2.2-31      rgdal_0.8-16
>> >  rgeos_0.3-4
>> >  sp_1.0-15
>> > [11] spacetime_1.1-2    tools_3.1.2        trajectories_0.1-1
>> > xts_0.9-7
>> > zoo_1.7-11
>> > ###
>
>> > ______________________________________________
>> > R-devel at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From ligges at statistik.tu-dortmund.de  Thu Nov  6 23:36:35 2014
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Thu, 06 Nov 2014 23:36:35 +0100
Subject: [Rd] r-release, r-oldrel
In-Reply-To: <CABtg=Kn2fDXQedu=KaXpEx21hSLu=HqDB=aE_QthPvs8LCSzuw@mail.gmail.com>
References: <CABtg=Kn2fDXQedu=KaXpEx21hSLu=HqDB=aE_QthPvs8LCSzuw@mail.gmail.com>
Message-ID: <545BF7F3.4000708@statistik.tu-dortmund.de>



On 05.11.2014 02:44, G?bor Cs?rdi wrote:
> Hi All,
>
> quick question. How does one know which R versions r-release

The latest official release, i.e. currently R-3.1.2.

> and r-oldrel

If R-x.y.z is recent, then r-oldrel corresponds to the latest "y-1" 
version, i.e. currently R-3.0.3.

Best,
Uwe Ligges





> correspond to? Is there a prefered way to determine this
> programmatically?
>
> So far I could only find messy ways, like parsing the HTML of the
> homepage, or (for r-release) checking the latest R-x-x-x tag in the
> SVN. The SVN is actually not bad, but how about r-oldrel? Is that
> always the previous release? Or the previous minor?
>
> Thanks, Best,
> Gabor
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From csardi.gabor at gmail.com  Thu Nov  6 23:41:34 2014
From: csardi.gabor at gmail.com (=?UTF-8?B?R8OhYm9yIENzw6FyZGk=?=)
Date: Thu, 6 Nov 2014 17:41:34 -0500
Subject: [Rd] r-release, r-oldrel
In-Reply-To: <545BF7F3.4000708@statistik.tu-dortmund.de>
References: <CABtg=Kn2fDXQedu=KaXpEx21hSLu=HqDB=aE_QthPvs8LCSzuw@mail.gmail.com>
	<545BF7F3.4000708@statistik.tu-dortmund.de>
Message-ID: <CABtg=Knonx3oAc+Xo0LN5Y4PYoSUKU-NRaKEusg6rMU1KO406Q@mail.gmail.com>

On Thu, Nov 6, 2014 at 5:36 PM, Uwe Ligges
<ligges at statistik.tu-dortmund.de> wrote:
[...]
>> quick question. How does one know which R versions r-release
>
>
> The latest official release, i.e. currently R-3.1.2.

Thanks!

How does one know what is the latest official release? Is parsing the
R homepage the best way to determine it? Or the latest tarball? Or can
I use the latest R-x-y-z tag from the SVN repository?

>> and r-oldrel
>
>
> If R-x.y.z is recent, then r-oldrel corresponds to the latest "y-1" version,
> i.e. currently R-3.0.3.

So this also means that when (say) R-3.0.2 was r-release, 2.15.3 was r-oldrel?

Thanks again,
Gabor

> Best,
> Uwe Ligges


From ligges at statistik.tu-dortmund.de  Thu Nov  6 23:45:46 2014
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Thu, 06 Nov 2014 23:45:46 +0100
Subject: [Rd] r-release, r-oldrel
In-Reply-To: <CABtg=Knonx3oAc+Xo0LN5Y4PYoSUKU-NRaKEusg6rMU1KO406Q@mail.gmail.com>
References: <CABtg=Kn2fDXQedu=KaXpEx21hSLu=HqDB=aE_QthPvs8LCSzuw@mail.gmail.com>	<545BF7F3.4000708@statistik.tu-dortmund.de>
	<CABtg=Knonx3oAc+Xo0LN5Y4PYoSUKU-NRaKEusg6rMU1KO406Q@mail.gmail.com>
Message-ID: <545BFA1A.2060008@statistik.tu-dortmund.de>



On 06.11.2014 23:41, G?bor Cs?rdi wrote:
> On Thu, Nov 6, 2014 at 5:36 PM, Uwe Ligges
> <ligges at statistik.tu-dortmund.de> wrote:
> [...]
>>> quick question. How does one know which R versions r-release
>>
>>
>> The latest official release, i.e. currently R-3.1.2.
>
> Thanks!
>
> How does one know what is the latest official release? Is parsing the
> R homepage the best way to determine it?

I'd say yes.

> Or the latest tarball? Or can
> I use the latest R-x-y-z tag from the SVN repository?

I assume that works.

>
>>> and r-oldrel
>>
>>
>> If R-x.y.z is recent, then r-oldrel corresponds to the latest "y-1" version,
>> i.e. currently R-3.0.3.
>
> So this also means that when (say) R-3.0.2 was r-release, 2.15.3 was r-oldrel?

Right.

Best,
Uwe

> Thanks again,
> Gabor
>
>> Best,
>> Uwe Ligges


From pdalgd at gmail.com  Fri Nov  7 12:09:48 2014
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 7 Nov 2014 12:09:48 +0100
Subject: [Rd] r-release, r-oldrel
In-Reply-To: <545BFA1A.2060008@statistik.tu-dortmund.de>
References: <CABtg=Kn2fDXQedu=KaXpEx21hSLu=HqDB=aE_QthPvs8LCSzuw@mail.gmail.com>	<545BF7F3.4000708@statistik.tu-dortmund.de>
	<CABtg=Knonx3oAc+Xo0LN5Y4PYoSUKU-NRaKEusg6rMU1KO406Q@mail.gmail.com>
	<545BFA1A.2060008@statistik.tu-dortmund.de>
Message-ID: <C6E7D4D9-4049-404F-846C-C50961DE0E1A@gmail.com>


On 06 Nov 2014, at 23:45 , Uwe Ligges <ligges at statistik.tu-dortmund.de> wrote:

> 
> 
> On 06.11.2014 23:41, G?bor Cs?rdi wrote:
>> On Thu, Nov 6, 2014 at 5:36 PM, Uwe Ligges
>> <ligges at statistik.tu-dortmund.de> wrote:
>> [...]
>>>> quick question. How does one know which R versions r-release
>>> 
>>> 
>>> The latest official release, i.e. currently R-3.1.2.
>> 
>> Thanks!
>> 
>> How does one know what is the latest official release? Is parsing the
>> R homepage the best way to determine it?
> 
> I'd say yes.
> 
>> Or the latest tarball? Or can
>> I use the latest R-x-y-z tag from the SVN repository?
> 
> I assume that works.

Also,

/pub/R/src/base on CRAN contains:

lrwxrwxrwx    1 1007     1001           18 Oct 31 09:11 R-latest.tar.gz -> R-3/R-3.1.2.tar.gz

which is auto-updated on release.

r-oldrel is trickier. I suppose that you are right: the most effective way is to parse the output of 

svn ls -v http://svn.r-project.org/R/tags

Now you got me curious... this seems to do the job of finding the last release of all major.minor series:

tb <- read.table(text=system("svn ls -v http://svn.r-project.org/R/tags", intern=TRUE))
names(tb) <- c("rev","au","m","d","y.or.time", "tag")
ix <- grep(x=tb$tag,pattern="^R-[0-9]+-[0-9]")
tb <- tb[ix,c("rev", "tag")]
v.str <- as.character(tb$tag)[order(tb$rev)]
versions <- data.frame(do.call(rbind,strsplit(v.str,"[-/]+"))[,-1],stringsAsFactors=FALSE)
names(versions) <- c("major","minor","patch")
maj.min <- paste(versions$major,versions$minor, sep=".")
maj.min <- factor(maj.min,levels=unique(maj.min))
unsplit(lapply(split(versions, maj.min),tail,1),unique(maj.min))

-pd


> 
>> 
>>>> and r-oldrel
>>> 
>>> 
>>> If R-x.y.z is recent, then r-oldrel corresponds to the latest "y-1" version,
>>> i.e. currently R-3.0.3.
>> 
>> So this also means that when (say) R-3.0.2 was r-release, 2.15.3 was r-oldrel?
> 
> Right.
> 
> Best,
> Uwe
> 
>> Thanks again,
>> Gabor
>> 
>>> Best,
>>> Uwe Ligges
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From whuber at embl.de  Sat Nov  8 09:29:49 2014
From: whuber at embl.de (Wolfgang Huber)
Date: Sat, 8 Nov 2014 09:29:49 +0100
Subject: [Rd] package vignettes build in the same R process?
In-Reply-To: <5456494D.9020702@gmail.com>
References: <54557E5A.7090800@fredhutch.org> <5456494D.9020702@gmail.com>
Message-ID: <07FD6E84-E72A-4D70-A191-6CAC9AA080A2@embl.de>

Il giorno Nov 2, 2014, alle ore 16:10 GMT+1, Duncan Murdoch <murdoch.duncan at gmail.com> ha scritto:

> On 01/11/2014, 8:44 PM, Martin Morgan wrote:
>> If I understand correctly, all vignettes in a package are built in the same R 
>> process. Global options, loaded packages, etc., in an earlier vignette persist 
>> in later vignettes. This can introduce user confusion (e.g., when a later 
>> vignette builds successfully because a package is require()'ed in an earlier 
>> vignette, but not the current one), difficult-to-identify bugs (e.g., when
>> a setting in an earlier vignette influences calculation in a latter vignette), 
>> and misleading information about reproducibility (e.g., when the sessionInfo() 
>> of a later vignette reflects packages used in earlier vignettes).
>> 
>> I believe the relevant code is at
>> 
>> src/library/tools/R/Vignettes.R:505
>> 
>>         output <- tryCatch({
>>             ## FIXME: run this in a separate process
>>             engine$weave(file, quiet = quiet)
>>             setwd(startdir)
>>             find_vignette_product(name, by = "weave", engine = engine)
>>         }, error = function(e) {
>>             stop(gettextf("processing vignette '%s' failed with diagnostics:\n%s",
>>                  file, conditionMessage(e)), domain = NA, call. = FALSE)
>>         })
>> 
>> Is building of each vignette in separate processes a reasonable feature request?
> 
> I'm not sure.  It's not perfect:  users may still see different output
> than the package contains, because when they run the vignette it will
> see their system state, but at least it gives them a way to get the
> identical output.  On the other hand, they already have a way to do
> that:  just build the whole package.  Overall I'd say it's probably a
> good idea.

Let the perfect be the enemy of the good?
Martin?s proposed improvement would eliminate unnecessary complexity and a lot of potential (and actual) confusion.

Wolfgang Huber

> 
> I would prefer a way to detect and warn when vignette output depends on
> the state outside the vignette, but that looks hard to do.
> 
> Duncan Murdoch
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From murdoch.duncan at gmail.com  Sat Nov  8 14:00:11 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 08 Nov 2014 08:00:11 -0500
Subject: [Rd] package vignettes build in the same R process?
In-Reply-To: <07FD6E84-E72A-4D70-A191-6CAC9AA080A2@embl.de>
References: <54557E5A.7090800@fredhutch.org> <5456494D.9020702@gmail.com>
	<07FD6E84-E72A-4D70-A191-6CAC9AA080A2@embl.de>
Message-ID: <545E13DB.30302@gmail.com>

On 08/11/2014, 3:29 AM, Wolfgang Huber wrote:
> Il giorno Nov 2, 2014, alle ore 16:10 GMT+1, Duncan Murdoch <murdoch.duncan at gmail.com> ha scritto:
> 
>> On 01/11/2014, 8:44 PM, Martin Morgan wrote:
>>> If I understand correctly, all vignettes in a package are built in the same R 
>>> process. Global options, loaded packages, etc., in an earlier vignette persist 
>>> in later vignettes. This can introduce user confusion (e.g., when a later 
>>> vignette builds successfully because a package is require()'ed in an earlier 
>>> vignette, but not the current one), difficult-to-identify bugs (e.g., when
>>> a setting in an earlier vignette influences calculation in a latter vignette), 
>>> and misleading information about reproducibility (e.g., when the sessionInfo() 
>>> of a later vignette reflects packages used in earlier vignettes).
>>>
>>> I believe the relevant code is at
>>>
>>> src/library/tools/R/Vignettes.R:505
>>>
>>>         output <- tryCatch({
>>>             ## FIXME: run this in a separate process
>>>             engine$weave(file, quiet = quiet)
>>>             setwd(startdir)
>>>             find_vignette_product(name, by = "weave", engine = engine)
>>>         }, error = function(e) {
>>>             stop(gettextf("processing vignette '%s' failed with diagnostics:\n%s",
>>>                  file, conditionMessage(e)), domain = NA, call. = FALSE)
>>>         })
>>>
>>> Is building of each vignette in separate processes a reasonable feature request?
>>
>> I'm not sure.  It's not perfect:  users may still see different output
>> than the package contains, because when they run the vignette it will
>> see their system state, but at least it gives them a way to get the
>> identical output.  On the other hand, they already have a way to do
>> that:  just build the whole package.  Overall I'd say it's probably a
>> good idea.
> 
> Let the perfect be the enemy of the good?
> Martin?s proposed improvement would eliminate unnecessary complexity and a lot of potential (and actual) confusion.

What are you talking about?  I didn't object to Martin making this
change, I was just pointing out that it is only a good idea, not a
perfect one.

Duncan Murdoch

> 
> Wolfgang Huber
> 
>>
>> I would prefer a way to detect and warn when vignette output depends on
>> the state outside the vignette, but that looks hard to do.
>>
>> Duncan Murdoch
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From hb at biostat.ucsf.edu  Sat Nov  8 18:01:46 2014
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Sat, 8 Nov 2014 09:01:46 -0800
Subject: [Rd] package vignettes build in the same R process?
In-Reply-To: <07FD6E84-E72A-4D70-A191-6CAC9AA080A2@embl.de>
References: <54557E5A.7090800@fredhutch.org> <5456494D.9020702@gmail.com>
	<07FD6E84-E72A-4D70-A191-6CAC9AA080A2@embl.de>
Message-ID: <CAFDcVCQCq=HLU02r9F94-rQh-XCpKRxnn5=rJs5ZydEtj9ofRA@mail.gmail.com>

On Sat, Nov 8, 2014 at 12:29 AM, Wolfgang Huber <whuber at embl.de> wrote:
> Il giorno Nov 2, 2014, alle ore 16:10 GMT+1, Duncan Murdoch <murdoch.duncan at gmail.com> ha scritto:
>
>> On 01/11/2014, 8:44 PM, Martin Morgan wrote:
>>> If I understand correctly, all vignettes in a package are built in the same R
>>> process. Global options, loaded packages, etc., in an earlier vignette persist
>>> in later vignettes. This can introduce user confusion (e.g., when a later
>>> vignette builds successfully because a package is require()'ed in an earlier
>>> vignette, but not the current one), difficult-to-identify bugs (e.g., when
>>> a setting in an earlier vignette influences calculation in a latter vignette),
>>> and misleading information about reproducibility (e.g., when the sessionInfo()
>>> of a later vignette reflects packages used in earlier vignettes).
>>>
>>> I believe the relevant code is at
>>>
>>> src/library/tools/R/Vignettes.R:505
>>>
>>>         output <- tryCatch({
>>>             ## FIXME: run this in a separate process
>>>             engine$weave(file, quiet = quiet)
>>>             setwd(startdir)
>>>             find_vignette_product(name, by = "weave", engine = engine)
>>>         }, error = function(e) {
>>>             stop(gettextf("processing vignette '%s' failed with diagnostics:\n%s",
>>>                  file, conditionMessage(e)), domain = NA, call. = FALSE)
>>>         })
>>>
>>> Is building of each vignette in separate processes a reasonable feature request?
>>
>> I'm not sure.  It's not perfect:  users may still see different output
>> than the package contains, because when they run the vignette it will
>> see their system state, but at least it gives them a way to get the
>> identical output.  On the other hand, they already have a way to do
>> that:  just build the whole package.  Overall I'd say it's probably a
>> good idea.
>
> Let the perfect be the enemy of the good?
> Martin?s proposed improvement would eliminate unnecessary complexity and a lot of potential (and actual) confusion.

I agree that this is likely a good move and will make the
reproducibility at bit more solid.   If changing, several things has
to be considered:

1. Make sure to run using the exact same R executable and architecture.
2. Make sure to use the exact same .libPaths(), which is particularly
important under R CMD check where it's composed of a minimum set of
temporary paths.
3. Preserve working directory.  ...or should also the working
directories be unique in order to bulkhead the vignettes from each
other?
4. What other settings needs to be set in order to replicate the state
of R CMD build/check?
5. How to deal with standard output and standard error?
6. How to propagate conditions such as warnings and errors?
7. Remember that buildVignette[s]() can be called manually too, not
only via R CMD build/check.
8. When you build a vignette manually via buildVignette(), should the
vignette change the state of R so it's available for
troubleshooting/debugging, inspecting variables and so on?
9. Maybe there is suite of vignettes that needs to be run sequentially
in order for them to work.  For instance, the first vignette
preprocesses the data and the second does EDA on it.  I don't think
this is currently supported, because I don't think the the order that
vignettes are processed is guaranteed (depends on locale), but maybe a
decision on supporting/not supporting this needs to be made.
10. Related to 9, when building vignettes in separate R processes, it
is tempting to also add support for parallel processing of vignettes.
If so, what decisions needs to be made already now in order to allow
for that?
11. What else?

So any change made needs to done with great care.  Adding a local=TRUE
to buildVignette[s]() could be a way to please both worlds and allow
us to move safely forward until success is proven.  Other things such
as cleaning up after the vignette engine, may be come easier when
running in a separate process, e.g. closing stray graphics devices.

BTW, an alternative to run in a separate process would be to have a
res <- sandbox({ ... }) that resets the state of R to the entry state
upon exit.  The major hurdle I see for achieving that is the fact that
packages cannot be unloaded properly.  One implementation of sandbox({
... }) would probably be to launch a separate R process.

/Henrik

>
> Wolfgang Huber
>
>>
>> I would prefer a way to detect and warn when vignette output depends on
>> the state outside the vignette, but that looks hard to do.
>>
>> Duncan Murdoch
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From francois.rousset at univ-montp2.fr  Sun Nov  9 12:25:55 2014
From: francois.rousset at univ-montp2.fr (Francois Rousset)
Date: Sun, 09 Nov 2014 12:25:55 +0100
Subject: [Rd] R CMD CHECK --run-donttest ignored
Message-ID: <545F4F43.5070401@univ-montp2.fr>

Dear R developers,

As far as I can see

R CMD CHECK --run-donttest

does not test the \donttest examples.
By contrast, --run-dontrun appears to run the \dontrun examples as expected.

I have prepared a minimal package archive for illustrating this bug, 
which I can send to anyone interested (but I am not sure it is 
appropriate to attach it to this mail).

I have formally tested this problem on
=============================

>sessionInfo()
R Under development (unstable) (2014-11-06 r66943)
Platform: x86_64-w64-mingw32/x64 (64-bit)

locale:
[1] LC_COLLATE=French_France.1252  LC_CTYPE=French_France.1252    LC_MONETARY=French_France.1252 LC_NUMERIC=C                   LC_TIME=French_France.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] tools_3.2.0

=============================


  F.R.

	[[alternative HTML version deleted]]


From steven.sagaert at gmail.com  Sun Nov  9 17:24:43 2014
From: steven.sagaert at gmail.com (Steven Sagaert)
Date: Sun, 9 Nov 2014 17:24:43 +0100
Subject: [Rd] organisation of packages & CRAN
Message-ID: <0D578E1F-CA3B-4991-8B25-24924D4DB9AA@gmail.com>

Hi,
I?ve been using R on and off for a couple of years. I think R is pretty great but one thing I?d like to see improved is the way packages are organised. Instead of CRAN being a long list of packages having a short & usually unintelligible name I ?d like to see packages organised in a hierarchical way with that path acting as a hierarchical namespace just like you have in many other languages like Java, C#,Scala,? The names of the (sub)packages should also be clear and unambiguous & packages should be organised according to their functionality and not just for example be code for a whole book thrown together and given a cryptic name. 

Next to that it would be nice to have extra metadata in the packages to allow for another more loose flat multi-class class-action like in tagging blog systems & other metadata to allow for for automatically generating something like task views.

Due to the large number of packages it?s hard to see the forest from the trees so a recommendation system for CRAN based on popularity (download statistics) , ratings & other data  like related packages from package metadata would be most welcome. 

Finally the number of packages in CRAN is exponentially growing but there is also a large partial overlap in functionality between packages & so many packages make it hard to find what you are looking for. So maybe there less is more and there should be a system of removing hardly used/low quality packages on a regular basis.

From csardi.gabor at gmail.com  Sun Nov  9 20:06:56 2014
From: csardi.gabor at gmail.com (=?UTF-8?B?R8OhYm9yIENzw6FyZGk=?=)
Date: Sun, 9 Nov 2014 14:06:56 -0500
Subject: [Rd] organisation of packages & CRAN
In-Reply-To: <0D578E1F-CA3B-4991-8B25-24924D4DB9AA@gmail.com>
References: <0D578E1F-CA3B-4991-8B25-24924D4DB9AA@gmail.com>
Message-ID: <CABtg=K=8szFqwwKMEHVF1-a49Zm1BQkeMCzmdbG4XFgs55hMzA@mail.gmail.com>

Hi,

I think much of this is simply impossible to do. CRAN packages are
written and maintained by thousands of people, how are you planning to
convince them to reorganize their packages? Or even just rename them?
This obviously won't happen.

Btw. did you see 'CRAN Task Views'? That is one organizations of
packages into topics.

Personally, I don't think organization is the solution here. It is too
costly (i.e. too much work) to maintain, impossible to enforce. I
think, however, that a good search engine would definitely help.

FWIW there is a simple search engine here: http://metacran.github.io/search/
This ranks packages according to the number of reverse dependencies
(among other things), i.e. packages more often used by other packages
will be higher up in the list.

Ranking them according to downloads is also possible, but AFAIK only
one CRAN mirror gives out statistics about downloads, so you don't
really have the complete numbers there.

Disclaimer: I built the search engine above. There are obviously other
alternatives as well, e.g. http://rdocumentation.org, and
http://mran.revolutionanalytics.com/packages/ are the two I know.

Gabor

On Sun, Nov 9, 2014 at 11:24 AM, Steven Sagaert
<steven.sagaert at gmail.com> wrote:
> Hi,
> I?ve been using R on and off for a couple of years. I think R is pretty great but one thing I?d like to see improved is the way packages are organised. Instead of CRAN being a long list of packages having a short & usually unintelligible name I ?d like to see packages organised in a hierarchical way with that path acting as a hierarchical namespace just like you have in many other languages like Java, C#,Scala,? The names of the (sub)packages should also be clear and unambiguous & packages should be organised according to their functionality and not just for example be code for a whole book thrown together and given a cryptic name.
>
> Next to that it would be nice to have extra metadata in the packages to allow for another more loose flat multi-class class-action like in tagging blog systems & other metadata to allow for for automatically generating something like task views.
>
> Due to the large number of packages it?s hard to see the forest from the trees so a recommendation system for CRAN based on popularity (download statistics) , ratings & other data  like related packages from package metadata would be most welcome.
>
> Finally the number of packages in CRAN is exponentially growing but there is also a large partial overlap in functionality between packages & so many packages make it hard to find what you are looking for. So maybe there less is more and there should be a system of removing hardly used/low quality packages on a regular basis.
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From bbolker at gmail.com  Sun Nov  9 21:26:49 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Sun, 9 Nov 2014 20:26:49 +0000
Subject: [Rd] organisation of packages & CRAN
References: <0D578E1F-CA3B-4991-8B25-24924D4DB9AA@gmail.com>
	<CABtg=K=8szFqwwKMEHVF1-a49Zm1BQkeMCzmdbG4XFgs55hMzA@mail.gmail.com>
Message-ID: <loom.20141109T210222-834@post.gmane.org>

G?bor Cs?rdi <csardi.gabor <at> gmail.com> writes:

> 
> Hi,
> 
> I think much of this is simply impossible to do. CRAN packages are
> written and maintained by thousands of people, how are you planning to
> convince them to reorganize their packages? Or even just rename them?
> This obviously won't happen.
> 
> Btw. did you see 'CRAN Task Views'? That is one organizations of
> packages into topics.
> 
> Personally, I don't think organization is the solution here. It is too
> costly (i.e. too much work) to maintain, impossible to enforce. I
> think, however, that a good search engine would definitely help.
> 
> FWIW there is a simple search engine here: http://metacran.github.io/search/
> This ranks packages according to the number of reverse dependencies
> (among other things), i.e. packages more often used by other packages
> will be higher up in the list.
> 
> Ranking them according to downloads is also possible, but AFAIK only
> one CRAN mirror gives out statistics about downloads, so you don't
> really have the complete numbers there.
> 
> Disclaimer: I built the search engine above. There are obviously other
> alternatives as well, e.g. http://rdocumentation.org, and
> http://mran.revolutionanalytics.com/packages/ are the two I know.
> 
> Gabor

  A few more thoughts:

* similar topics have been discussed _many_ times over the years on
the R mailing lists (sorry, I can't point you to any specific
threads). So far the R core/CRAN team have not indicated any interest
in making changes in the directions you suggest, so it's up to
the community to implement the things it would like to see.  There's
nothing stopping you from mirroring CRAN packages in any way you'd
like (e.g. see Revolution R's 'MRAN': http://mran.revolutionanalytics.com/ ,
which among other things allows you to sort packages by task view).

In addition to the Task Views pointed out by Gabor (you may enjoy
this version: http://www.maths.lancs.ac.uk/~rowlings/R/TaskViews/ ),
there have been a variety of individual/community attempts to provide
more package information:

* CRANberries http://dirk.eddelbuettel.com/cranberries/ gives a feed
about package changes
* CRANtastic http://crantastic.org/ attempted to set up a community
site for package rating/voting (never got a lot of traction though).
* download information _is_ available, unofficially, from some 
mirrors other than the RStudio mirror: see
http://www.rpubs.com/bbolker/3750

Questions:

* how would you propose to enforce package naming? (One of the
great things about packaging code R is the relatively *low*
barriers to entry ... but that has obvious disadvantages ...)
* who's going to enforce and curate the metadata?
* who's going to decide on the criteria for CRAN package removal
(i.e. how to determine quality, or how to decide on a threshold
for removal?) There's some filtering based on packages failing
their automated checks and being archived as R advances ...
 
> On Sun, Nov 9, 2014 at 11:24 AM, Steven Sagaert
> <steven.sagaert <at> gmail.com> wrote:
> > Hi,

> > I?ve been using R on and off for a couple of years. I think R is
> pretty great but one thing I?d like to see improved is the way
> packages are organised. Instead of CRAN being a long list of
> packages having a short & usually unintelligible name I ?d like to
> see packages organised in a hierarchical way with that path acting
> as a hierarchical namespace just like you have in many other
> languages like Java, C#,Scala,? The names of the (sub)packages
> should also be clear and unambiguous & packages should be organised
> according to their functionality and not just for example be code
> for a whole book thrown together and given a cryptic name.

> Next to that it would be nice to have extra metadata in the
> packages to allow for another more loose flat multi-class
> class-action like in tagging blog systems & other metadata to allow
> for for automatically generating something like task views.

> > Due to the large number of packages it?s hard to see the forest
> from the trees so a recommendation system for CRAN based on
> popularity (download statistics) , ratings & other data like related
> packages from package metadata would be most welcome.


>  Finally the number of packages in CRAN is exponentially growing but
> there is also a large partial overlap in functionality between
> packages & so many packages make it hard to find what you are
> looking for. So maybe there less is more and there should be a
> system of removing hardly used/low quality packages on a regular
> basis.


From murdoch.duncan at gmail.com  Sun Nov  9 22:37:05 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 9 Nov 2014 16:37:05 -0500
Subject: [Rd] organisation of packages & CRAN
In-Reply-To: <loom.20141109T210222-834@post.gmane.org>
References: <0D578E1F-CA3B-4991-8B25-24924D4DB9AA@gmail.com>	<CABtg=K=8szFqwwKMEHVF1-a49Zm1BQkeMCzmdbG4XFgs55hMzA@mail.gmail.com>
	<loom.20141109T210222-834@post.gmane.org>
Message-ID: <545FDE81.7020301@gmail.com>

Hi Ben.  I agree with most of your points and questions, but just wanted
to nitpick one little point, inline below:

On 09/11/2014, 3:26 PM, Ben Bolker wrote:
> G?bor Cs?rdi <csardi.gabor <at> gmail.com> writes:
> 
>>
>> Hi,
>>
>> I think much of this is simply impossible to do. CRAN packages are
>> written and maintained by thousands of people, how are you planning to
>> convince them to reorganize their packages? Or even just rename them?
>> This obviously won't happen.
>>
>> Btw. did you see 'CRAN Task Views'? That is one organizations of
>> packages into topics.
>>
>> Personally, I don't think organization is the solution here. It is too
>> costly (i.e. too much work) to maintain, impossible to enforce. I
>> think, however, that a good search engine would definitely help.
>>
>> FWIW there is a simple search engine here: http://metacran.github.io/search/
>> This ranks packages according to the number of reverse dependencies
>> (among other things), i.e. packages more often used by other packages
>> will be higher up in the list.
>>
>> Ranking them according to downloads is also possible, but AFAIK only
>> one CRAN mirror gives out statistics about downloads, so you don't
>> really have the complete numbers there.
>>
>> Disclaimer: I built the search engine above. There are obviously other
>> alternatives as well, e.g. http://rdocumentation.org, and
>> http://mran.revolutionanalytics.com/packages/ are the two I know.
>>
>> Gabor
> 
>   A few more thoughts:
> 
> * similar topics have been discussed _many_ times over the years on
> the R mailing lists (sorry, I can't point you to any specific
> threads). So far the R core/CRAN team have not indicated any interest

"team" should be plural here.  Though there is overlap in membership,
CRAN is a separate entity from the R Core team.

Duncan Murdoch

> in making changes in the directions you suggest, so it's up to
> the community to implement the things it would like to see.  There's
> nothing stopping you from mirroring CRAN packages in any way you'd
> like (e.g. see Revolution R's 'MRAN': http://mran.revolutionanalytics.com/ ,
> which among other things allows you to sort packages by task view).
> 
> In addition to the Task Views pointed out by Gabor (you may enjoy
> this version: http://www.maths.lancs.ac.uk/~rowlings/R/TaskViews/ ),
> there have been a variety of individual/community attempts to provide
> more package information:
> 
> * CRANberries http://dirk.eddelbuettel.com/cranberries/ gives a feed
> about package changes
> * CRANtastic http://crantastic.org/ attempted to set up a community
> site for package rating/voting (never got a lot of traction though).
> * download information _is_ available, unofficially, from some 
> mirrors other than the RStudio mirror: see
> http://www.rpubs.com/bbolker/3750
> 
> Questions:
> 
> * how would you propose to enforce package naming? (One of the
> great things about packaging code R is the relatively *low*
> barriers to entry ... but that has obvious disadvantages ...)
> * who's going to enforce and curate the metadata?
> * who's going to decide on the criteria for CRAN package removal
> (i.e. how to determine quality, or how to decide on a threshold
> for removal?) There's some filtering based on packages failing
> their automated checks and being archived as R advances ...
>  
>> On Sun, Nov 9, 2014 at 11:24 AM, Steven Sagaert
>> <steven.sagaert <at> gmail.com> wrote:
>>> Hi,
> 
>>> I?ve been using R on and off for a couple of years. I think R is
>> pretty great but one thing I?d like to see improved is the way
>> packages are organised. Instead of CRAN being a long list of
>> packages having a short & usually unintelligible name I ?d like to
>> see packages organised in a hierarchical way with that path acting
>> as a hierarchical namespace just like you have in many other
>> languages like Java, C#,Scala,? The names of the (sub)packages
>> should also be clear and unambiguous & packages should be organised
>> according to their functionality and not just for example be code
>> for a whole book thrown together and given a cryptic name.
> 
>> Next to that it would be nice to have extra metadata in the
>> packages to allow for another more loose flat multi-class
>> class-action like in tagging blog systems & other metadata to allow
>> for for automatically generating something like task views.
> 
>>> Due to the large number of packages it?s hard to see the forest
>> from the trees so a recommendation system for CRAN based on
>> popularity (download statistics) , ratings & other data like related
>> packages from package metadata would be most welcome.
> 
> 
>>  Finally the number of packages in CRAN is exponentially growing but
>> there is also a large partial overlap in functionality between
>> packages & so many packages make it hard to find what you are
>> looking for. So maybe there less is more and there should be a
>> system of removing hardly used/low quality packages on a regular
>> basis.
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From csardi.gabor at gmail.com  Sun Nov  9 22:40:29 2014
From: csardi.gabor at gmail.com (=?UTF-8?B?R8OhYm9yIENzw6FyZGk=?=)
Date: Sun, 9 Nov 2014 16:40:29 -0500
Subject: [Rd] organisation of packages & CRAN
In-Reply-To: <loom.20141109T210222-834@post.gmane.org>
References: <0D578E1F-CA3B-4991-8B25-24924D4DB9AA@gmail.com>
	<CABtg=K=8szFqwwKMEHVF1-a49Zm1BQkeMCzmdbG4XFgs55hMzA@mail.gmail.com>
	<loom.20141109T210222-834@post.gmane.org>
Message-ID: <CABtg=Knx_eonSy3BrTQysff0UtGXmOZFWMjw1wSzE_m-BQ5h-A@mail.gmail.com>

On Sun, Nov 9, 2014 at 3:26 PM, Ben Bolker <bbolker at gmail.com> wrote:
[...]
> * download information _is_ available, unofficially, from some
> mirrors other than the RStudio mirror: see
> http://www.rpubs.com/bbolker/3750

You mean the report_cran.html file? According to my quick check it is
indeed available on some mirrors, but it also seems to be the same
file, so it is probably mirrored from cran.r-project.org. Why does it
show the (almost) last 56 days, btw.? How often is it updated? Can you
have daily values? Older data? In general, do you know any
documentation about this?

G.

[...]


From bbolker at gmail.com  Sun Nov  9 22:50:20 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Sun, 9 Nov 2014 16:50:20 -0500
Subject: [Rd] organisation of packages & CRAN
In-Reply-To: <545FDE81.7020301@gmail.com>
References: <0D578E1F-CA3B-4991-8B25-24924D4DB9AA@gmail.com>
	<CABtg=K=8szFqwwKMEHVF1-a49Zm1BQkeMCzmdbG4XFgs55hMzA@mail.gmail.com>
	<loom.20141109T210222-834@post.gmane.org>
	<545FDE81.7020301@gmail.com>
Message-ID: <CABghstQ7F=2Kaw3ZXMztjvHpoBhHespHOQNDBLPAVq+=inJshA@mail.gmail.com>

On Sun, Nov 9, 2014 at 4:37 PM, Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> Hi Ben.  I agree with most of your points and questions, but just wanted
> to nitpick one little point, inline below:
>

  You're right -- I was being sloppy, that's worth clarifying.  I think I
originally meant
to write "R core/the CRAN team" (i.e. referring to "R core" and "the CRAN
team"
as separate entities), but my fingers slipped ...

   Ben


> On 09/11/2014, 3:26 PM, Ben Bolker wrote:
> > G?bor Cs?rdi <csardi.gabor <at> gmail.com> writes:
> >
> >>
> >> Hi,
> >>
> >> I think much of this is simply impossible to do. CRAN packages are
> >> written and maintained by thousands of people, how are you planning to
> >> convince them to reorganize their packages? Or even just rename them?
> >> This obviously won't happen.
> >>
> >> Btw. did you see 'CRAN Task Views'? That is one organizations of
> >> packages into topics.
> >>
> >> Personally, I don't think organization is the solution here. It is too
> >> costly (i.e. too much work) to maintain, impossible to enforce. I
> >> think, however, that a good search engine would definitely help.
> >>
> >> FWIW there is a simple search engine here:
> http://metacran.github.io/search/
> >> This ranks packages according to the number of reverse dependencies
> >> (among other things), i.e. packages more often used by other packages
> >> will be higher up in the list.
> >>
> >> Ranking them according to downloads is also possible, but AFAIK only
> >> one CRAN mirror gives out statistics about downloads, so you don't
> >> really have the complete numbers there.
> >>
> >> Disclaimer: I built the search engine above. There are obviously other
> >> alternatives as well, e.g. http://rdocumentation.org, and
> >> http://mran.revolutionanalytics.com/packages/ are the two I know.
> >>
> >> Gabor
> >
> >   A few more thoughts:
> >
> > * similar topics have been discussed _many_ times over the years on
> > the R mailing lists (sorry, I can't point you to any specific
> > threads). So far the R core/CRAN team have not indicated any interest
>
> "team" should be plural here.  Though there is overlap in membership,
> CRAN is a separate entity from the R Core team.
>
> Duncan Murdoch
>
> > in making changes in the directions you suggest, so it's up to
> > the community to implement the things it would like to see.  There's
> > nothing stopping you from mirroring CRAN packages in any way you'd
> > like (e.g. see Revolution R's 'MRAN':
> http://mran.revolutionanalytics.com/ ,
> > which among other things allows you to sort packages by task view).
> >
> > In addition to the Task Views pointed out by Gabor (you may enjoy
> > this version: http://www.maths.lancs.ac.uk/~rowlings/R/TaskViews/ ),
> > there have been a variety of individual/community attempts to provide
> > more package information:
> >
> > * CRANberries http://dirk.eddelbuettel.com/cranberries/ gives a feed
> > about package changes
> > * CRANtastic http://crantastic.org/ attempted to set up a community
> > site for package rating/voting (never got a lot of traction though).
> > * download information _is_ available, unofficially, from some
> > mirrors other than the RStudio mirror: see
> > http://www.rpubs.com/bbolker/3750
> >
> > Questions:
> >
> > * how would you propose to enforce package naming? (One of the
> > great things about packaging code R is the relatively *low*
> > barriers to entry ... but that has obvious disadvantages ...)
> > * who's going to enforce and curate the metadata?
> > * who's going to decide on the criteria for CRAN package removal
> > (i.e. how to determine quality, or how to decide on a threshold
> > for removal?) There's some filtering based on packages failing
> > their automated checks and being archived as R advances ...
> >
> >> On Sun, Nov 9, 2014 at 11:24 AM, Steven Sagaert
> >> <steven.sagaert <at> gmail.com> wrote:
> >>> Hi,
> >
> >>> I?ve been using R on and off for a couple of years. I think R is
> >> pretty great but one thing I?d like to see improved is the way
> >> packages are organised. Instead of CRAN being a long list of
> >> packages having a short & usually unintelligible name I ?d like to
> >> see packages organised in a hierarchical way with that path acting
> >> as a hierarchical namespace just like you have in many other
> >> languages like Java, C#,Scala,? The names of the (sub)packages
> >> should also be clear and unambiguous & packages should be organised
> >> according to their functionality and not just for example be code
> >> for a whole book thrown together and given a cryptic name.
> >
> >> Next to that it would be nice to have extra metadata in the
> >> packages to allow for another more loose flat multi-class
> >> class-action like in tagging blog systems & other metadata to allow
> >> for for automatically generating something like task views.
> >
> >>> Due to the large number of packages it?s hard to see the forest
> >> from the trees so a recommendation system for CRAN based on
> >> popularity (download statistics) , ratings & other data like related
> >> packages from package metadata would be most welcome.
> >
> >
> >>  Finally the number of packages in CRAN is exponentially growing but
> >> there is also a large partial overlap in functionality between
> >> packages & so many packages make it hard to find what you are
> >> looking for. So maybe there less is more and there should be a
> >> system of removing hardly used/low quality packages on a regular
> >> basis.
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
>
>

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Sun Nov  9 22:56:53 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Sun, 9 Nov 2014 16:56:53 -0500
Subject: [Rd] organisation of packages & CRAN
In-Reply-To: <CABtg=Knx_eonSy3BrTQysff0UtGXmOZFWMjw1wSzE_m-BQ5h-A@mail.gmail.com>
References: <0D578E1F-CA3B-4991-8B25-24924D4DB9AA@gmail.com>
	<CABtg=K=8szFqwwKMEHVF1-a49Zm1BQkeMCzmdbG4XFgs55hMzA@mail.gmail.com>
	<loom.20141109T210222-834@post.gmane.org>
	<CABtg=Knx_eonSy3BrTQysff0UtGXmOZFWMjw1wSzE_m-BQ5h-A@mail.gmail.com>
Message-ID: <CABghstReSXD2+Z430LQiwN3uCmOShrTFxAdjanZ+VgfuAb__fQ@mail.gmail.com>

  I"ve never looked to see if it differs among mirrors. I believe this is
just an internal log file that is produced according to the default Apache
(?) webserver configs on a Debian system -- I always
assumed it was generated separately for different servers, but it could
indeed be just a copy of the download stats for the central repository.  I
found about it when someone else pointed it out in some long-ago exchange
on an R mailing list.

   As far as I know it's essentially accidental that it exists and is
accessible -- if the CRAN maintainers decided to move it or cut off access
they could at any time.


On Sun, Nov 9, 2014 at 4:40 PM, G?bor Cs?rdi <csardi.gabor at gmail.com> wrote:

> On Sun, Nov 9, 2014 at 3:26 PM, Ben Bolker <bbolker at gmail.com> wrote:
> [...]
> > * download information _is_ available, unofficially, from some
> > mirrors other than the RStudio mirror: see
> > http://www.rpubs.com/bbolker/3750
>
> You mean the report_cran.html file? According to my quick check it is
> indeed available on some mirrors, but it also seems to be the same
> file, so it is probably mirrored from cran.r-project.org. Why does it
> show the (almost) last 56 days, btw.? How often is it updated? Can you
> have daily values? Older data? In general, do you know any
> documentation about this?
>
> G.
>
> [...]
>

	[[alternative HTML version deleted]]


From spencer.graves at prodsyse.com  Mon Nov 10 01:18:40 2014
From: spencer.graves at prodsyse.com (Spencer Graves)
Date: Sun, 09 Nov 2014 16:18:40 -0800
Subject: [Rd] organisation of packages & CRAN
In-Reply-To: <CABtg=K=8szFqwwKMEHVF1-a49Zm1BQkeMCzmdbG4XFgs55hMzA@mail.gmail.com>
References: <0D578E1F-CA3B-4991-8B25-24924D4DB9AA@gmail.com>
	<CABtg=K=8szFqwwKMEHVF1-a49Zm1BQkeMCzmdbG4XFgs55hMzA@mail.gmail.com>
Message-ID: <54600460.6090302@prodsyse.com>

       Might it be appropriate to add "http://metacran.github.io/search" 
and the "sos" package to the official list of R search capabilities at 
"www.r-project.org/search.html"?  [Disclaimer:  I'm the lead author of 
"sos".]


       Best Wishes,
       Spencer Graves


On 11/9/2014 11:06 AM, G?bor Cs?rdi wrote:
> Hi,
>
> I think much of this is simply impossible to do. CRAN packages are
> written and maintained by thousands of people, how are you planning to
> convince them to reorganize their packages? Or even just rename them?
> This obviously won't happen.
>
> Btw. did you see 'CRAN Task Views'? That is one organizations of
> packages into topics.
>
> Personally, I don't think organization is the solution here. It is too
> costly (i.e. too much work) to maintain, impossible to enforce. I
> think, however, that a good search engine would definitely help.
>
> FWIW there is a simple search engine here: http://metacran.github.io/search/
> This ranks packages according to the number of reverse dependencies
> (among other things), i.e. packages more often used by other packages
> will be higher up in the list.
>
> Ranking them according to downloads is also possible, but AFAIK only
> one CRAN mirror gives out statistics about downloads, so you don't
> really have the complete numbers there.
>
> Disclaimer: I built the search engine above. There are obviously other
> alternatives as well, e.g. http://rdocumentation.org, and
> http://mran.revolutionanalytics.com/packages/ are the two I know.
>
> Gabor
>
> On Sun, Nov 9, 2014 at 11:24 AM, Steven Sagaert
> <steven.sagaert at gmail.com> wrote:
>> Hi,
>> I?ve been using R on and off for a couple of years. I think R is pretty great but one thing I?d like to see improved is the way packages are organised. Instead of CRAN being a long list of packages having a short & usually unintelligible name I ?d like to see packages organised in a hierarchical way with that path acting as a hierarchical namespace just like you have in many other languages like Java, C#,Scala,? The names of the (sub)packages should also be clear and unambiguous & packages should be organised according to their functionality and not just for example be code for a whole book thrown together and given a cryptic name.
>>
>> Next to that it would be nice to have extra metadata in the packages to allow for another more loose flat multi-class class-action like in tagging blog systems & other metadata to allow for for automatically generating something like task views.
>>
>> Due to the large number of packages it?s hard to see the forest from the trees so a recommendation system for CRAN based on popularity (download statistics) , ratings & other data  like related packages from package metadata would be most welcome.
>>
>> Finally the number of packages in CRAN is exponentially growing but there is also a large partial overlap in functionality between packages & so many packages make it hard to find what you are looking for. So maybe there less is more and there should be a system of removing hardly used/low quality packages on a regular basis.
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel


From lawrence.michael at gene.com  Mon Nov 10 01:26:08 2014
From: lawrence.michael at gene.com (Michael Lawrence)
Date: Sun, 9 Nov 2014 16:26:08 -0800
Subject: [Rd] organisation of packages & CRAN
In-Reply-To: <0D578E1F-CA3B-4991-8B25-24924D4DB9AA@gmail.com>
References: <0D578E1F-CA3B-4991-8B25-24924D4DB9AA@gmail.com>
Message-ID: <CAOQ5NyfSuja-WiyvxnEHQU5gyORhBH+o88_Ee-hK8+Vbx+2c_g@mail.gmail.com>

On Sun, Nov 9, 2014 at 8:24 AM, Steven Sagaert <steven.sagaert at gmail.com>
wrote:

> Hi,
> I?ve been using R on and off for a couple of years. I think R is pretty
> great but one thing I?d like to see improved is the way packages are
> organised. Instead of CRAN being a long list of packages having a short &
> usually unintelligible name I ?d like to see packages organised in a
> hierarchical way with that path acting as a hierarchical namespace just
> like you have in many other languages like Java, C#,Scala,? The names of
> the (sub)packages should also be clear and unambiguous & packages should be
> organised according to their functionality and not just for example be code
> for a whole book thrown together and given a cryptic name.
>
> Next to that it would be nice to have extra metadata in the packages to
> allow for another more loose flat multi-class class-action like in tagging
> blog systems & other metadata to allow for for automatically generating
> something like task views.
>
>

Just wanted to point out that this extra metadata idea has been pursued by
the Bioconductor BiocViews feature.

http://www.bioconductor.org/packages/release/BiocViews.html



> Due to the large number of packages it?s hard to see the forest from the
> trees so a recommendation system for CRAN based on popularity (download
> statistics) , ratings & other data  like related packages from package
> metadata would be most welcome.
>
> Finally the number of packages in CRAN is exponentially growing but there
> is also a large partial overlap in functionality between packages & so many
> packages make it hard to find what you are looking for. So maybe there less
> is more and there should be a system of removing hardly used/low quality
> packages on a regular basis.
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Mon Nov 10 01:50:43 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 10 Nov 2014 00:50:43 +0000
Subject: [Rd] organisation of packages & CRAN
References: <0D578E1F-CA3B-4991-8B25-24924D4DB9AA@gmail.com>
	<CABtg=K=8szFqwwKMEHVF1-a49Zm1BQkeMCzmdbG4XFgs55hMzA@mail.gmail.com>
	<54600460.6090302@prodsyse.com>
Message-ID: <loom.20141110T014525-752@post.gmane.org>

Spencer Graves <spencer.graves <at> prodsyse.com> writes:

> 
>        Might it be appropriate to add "http://metacran.github.io/search" 
> and the "sos" package to the official list of R search capabilities at 
> "www.r-project.org/search.html"?  [Disclaimer:  I'm the lead author of 
> "sos".]
> 
>        Best Wishes,
>        Spencer Graves
> 

  I would go farther and nominate the sos package for inclusion as 
a recommended package (I don't have any conflict of interest in 
making the suggestion).  When I tell students about it many of them
are puzzled that it's not part of the core R framework. I understand
the arguments against migrating new functionality into core R, but
this functionality is super-useful especially for beginners, and
it seems worth it to lower the bar for finding help, at the cost
of not a huge amount of extra code to maintain.

  Ben Bolker


From spencer.graves at prodsyse.com  Mon Nov 10 03:36:21 2014
From: spencer.graves at prodsyse.com (Spencer Graves)
Date: Sun, 9 Nov 2014 18:36:21 -0800
Subject: [Rd] organisation of packages & CRAN
In-Reply-To: <loom.20141110T014525-752@post.gmane.org>
References: <0D578E1F-CA3B-4991-8B25-24924D4DB9AA@gmail.com>	<CABtg=K=8szFqwwKMEHVF1-a49Zm1BQkeMCzmdbG4XFgs55hMzA@mail.gmail.com>	<54600460.6090302@prodsyse.com>
	<loom.20141110T014525-752@post.gmane.org>
Message-ID: <546024A5.9040407@prodsyse.com>

On 11/9/2014 4:50 PM, Ben Bolker wrote:
> Spencer Graves <spencer.graves <at> prodsyse.com> writes:
>
>>         Might it be appropriate to add "http://metacran.github.io/search"
>> and the "sos" package to the official list of R search capabilities at
>> "www.r-project.org/search.html"?  [Disclaimer:  I'm the lead author of
>> "sos".]
>>
>>         Best Wishes,
>>         Spencer Graves
>>
>    I would go farther and nominate the sos package for inclusion as
> a recommended package (I don't have any conflict of interest in
> making the suggestion).  When I tell students about it many of them
> are puzzled that it's not part of the core R framework. I understand
> the arguments against migrating new functionality into core R, but
> this functionality is super-useful especially for beginners, and
> it seems worth it to lower the bar for finding help, at the cost
> of not a huge amount of extra code to maintain.


       Thanks.  For me, "sos" has provided the fastest literature search 
I've found for anything statistical (including using "installPackages" 
and "writeFindFn2xls", which could be overlooked by people using only 
"findFn").  Gone are the days when I'd puzzle for hours over a single 
line or page of mathematics.  If I don't understand something, I give 
examples to the code, and see what I get -- possibly using debug to 
trace what it does line by line.  If I don't find what I want with 
"sos", then I can look elsewhere.


       I only became aware of "http://metacran.github.io/search/", 
"http://www.rdocumentation.org/", and 
"http://www.bioconductor.org/packages/release/BiocViews.html" through 
responses earlier in this thread, so I can't compare "sos" to these 
other capabilities.


       Spencer Graves
>
>    Ben Bolker
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From csardi.gabor at gmail.com  Mon Nov 10 04:58:48 2014
From: csardi.gabor at gmail.com (=?UTF-8?B?R8OhYm9yIENzw6FyZGk=?=)
Date: Sun, 9 Nov 2014 22:58:48 -0500
Subject: [Rd] organisation of packages & CRAN
In-Reply-To: <54600460.6090302@prodsyse.com>
References: <0D578E1F-CA3B-4991-8B25-24924D4DB9AA@gmail.com>
	<CABtg=K=8szFqwwKMEHVF1-a49Zm1BQkeMCzmdbG4XFgs55hMzA@mail.gmail.com>
	<54600460.6090302@prodsyse.com>
Message-ID: <CABtg=KmqZPXtMP6SZ_hW0t3SXgGDLOZdJ+LOTOeVm2UWApFTNw@mail.gmail.com>

A little more details about the metacran search, to show how it (imo)
solves a different problem than sos, rseek, RSiteSearch, or
rdocumentation.org.

1. The most important difference is that it searches for _packages_.
The results are packages, not functions, vignettes, etc. E.g. if you
want to find all packages that interact with google apis, you can just
say (https://github.com/metacran/seer is the CLI version):

library(seer)
> see("google")
SAW "google" -------------------------------- 25 packages in 0.013 seconds ---
 #  # Title     # Package
 1  RgoogleMaps Overlays on Google map tiles in R
 2  ggmap       A package for spatial visualization with Google Maps and Ope...
 3  RGA         A Google Analytics API client for R
 4  plotKML     Visualization of spatial and spatio-temporal objects in Goog...
 5  googleVis   Interface between R and Google Charts
 6  scholar     Analyse citation data from Google Scholar
 7  translateR  Bindings for the Google and Microsoft Translation APIs
 8  plusser     A Google+ Interface for R
 9  gooJSON     Google JSON Data Interpreter for R
 10 translate   Bindings for the Google Translate API v2
> more()
SAW "google" -------------------------------- 25 packages in 0.012 seconds ---
 #  # Title          # Package
 11 ngramr           Retrieve and plot Google n-gram data
 12 RGoogleAnalytics R Wrapper for the Google Analytics API
 13 R2G2             Converting R CRAN outputs into Google Earth.
 14 plotGoogleMaps   Plot spatial or spatio-temporal data over Google Maps
 15 googlePublicData An R library to build Google's Public Data Explorer DSP...
 16 RWeather         R wrapper around the Yahoo! Weather, Google Weather and...
 17 sysfonts         Loading system fonts into R
 18 hashFunction     A collection of non-cryptographic hash functions
 19 rgauges          R wrapper to Gaug.es API
 20 splitstackshape  Stack and Reshape Datasets After Splitting Concatenated...

2. The second difference is that metacran ranks the search results
based on (among other things) the package dependency graph, so if you
search for 'graphics' lattice and ggplot2 come first.

3. Another difference is that metacran exposes a full search API of
the underlying ElasticSearch engine, so if someone wants to rank
results differently, or make more difficult complex queries, they can.

4. It does not search code and docs. I think rdocumentation.org does a
good job with docs, and http://github.com/cran is great for code, e.g.
if you want packages that call SET_SLOT in C:
https://github.com/search?l=c&q=SET_SLOT+user%3Acran&ref=searchresults&type=Code&utf8=%E2%9C%93

Gabor

On Sun, Nov 9, 2014 at 7:18 PM, Spencer Graves
<spencer.graves at prodsyse.com> wrote:
>       Might it be appropriate to add "http://metacran.github.io/search" and
> the "sos" package to the official list of R search capabilities at
> "www.r-project.org/search.html"?  [Disclaimer:  I'm the lead author of
> "sos".]
>
>
>       Best Wishes,
>       Spencer Graves
>
>
> On 11/9/2014 11:06 AM, G?bor Cs?rdi wrote:
>>
>> Hi,
>>
>> I think much of this is simply impossible to do. CRAN packages are
>> written and maintained by thousands of people, how are you planning to
>> convince them to reorganize their packages? Or even just rename them?
>> This obviously won't happen.
>>
>> Btw. did you see 'CRAN Task Views'? That is one organizations of
>> packages into topics.
>>
>> Personally, I don't think organization is the solution here. It is too
>> costly (i.e. too much work) to maintain, impossible to enforce. I
>> think, however, that a good search engine would definitely help.
>>
>> FWIW there is a simple search engine here:
>> http://metacran.github.io/search/
>> This ranks packages according to the number of reverse dependencies
>> (among other things), i.e. packages more often used by other packages
>> will be higher up in the list.
>>
>> Ranking them according to downloads is also possible, but AFAIK only
>> one CRAN mirror gives out statistics about downloads, so you don't
>> really have the complete numbers there.
>>
>> Disclaimer: I built the search engine above. There are obviously other
>> alternatives as well, e.g. http://rdocumentation.org, and
>> http://mran.revolutionanalytics.com/packages/ are the two I know.
>>
>> Gabor
>>
>> On Sun, Nov 9, 2014 at 11:24 AM, Steven Sagaert
>> <steven.sagaert at gmail.com> wrote:
>>>
>>> Hi,
>>> I?ve been using R on and off for a couple of years. I think R is pretty
>>> great but one thing I?d like to see improved is the way packages are
>>> organised. Instead of CRAN being a long list of packages having a short &
>>> usually unintelligible name I ?d like to see packages organised in a
>>> hierarchical way with that path acting as a hierarchical namespace just like
>>> you have in many other languages like Java, C#,Scala,? The names of the
>>> (sub)packages should also be clear and unambiguous & packages should be
>>> organised according to their functionality and not just for example be code
>>> for a whole book thrown together and given a cryptic name.
>>>
>>> Next to that it would be nice to have extra metadata in the packages to
>>> allow for another more loose flat multi-class class-action like in tagging
>>> blog systems & other metadata to allow for for automatically generating
>>> something like task views.
>>>
>>> Due to the large number of packages it?s hard to see the forest from the
>>> trees so a recommendation system for CRAN based on popularity (download
>>> statistics) , ratings & other data  like related packages from package
>>> metadata would be most welcome.
>>>
>>> Finally the number of packages in CRAN is exponentially growing but there
>>> is also a large partial overlap in functionality between packages & so many
>>> packages make it hard to find what you are looking for. So maybe there less
>>> is more and there should be a system of removing hardly used/low quality
>>> packages on a regular basis.
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel


From spencer.graves at structuremonitoring.com  Mon Nov 10 07:20:31 2014
From: spencer.graves at structuremonitoring.com (Spencer Graves)
Date: Sun, 09 Nov 2014 22:20:31 -0800
Subject: [Rd] organisation of packages & CRAN
In-Reply-To: <CABtg=KmqZPXtMP6SZ_hW0t3SXgGDLOZdJ+LOTOeVm2UWApFTNw@mail.gmail.com>
References: <0D578E1F-CA3B-4991-8B25-24924D4DB9AA@gmail.com>	<CABtg=K=8szFqwwKMEHVF1-a49Zm1BQkeMCzmdbG4XFgs55hMzA@mail.gmail.com>	<54600460.6090302@prodsyse.com>
	<CABtg=KmqZPXtMP6SZ_hW0t3SXgGDLOZdJ+LOTOeVm2UWApFTNw@mail.gmail.com>
Message-ID: <5460592F.7090607@structuremonitoring.com>

Hi, G?bor:


On 11/9/2014 7:58 PM, G?bor Cs?rdi wrote:
> A little more details about the metacran search, to show how it (imo)
> solves a different problem than sos, rseek, RSiteSearch, or
> rdocumentation.org.
>
> 1. The most important difference is that it searches for _packages_.
> The results are packages, not functions, vignettes, etc. E.g. if you
> want to find all packages that interact with google apis, you can just
> say (https://github.com/metacran/seer is the CLI version):
>
> library(seer)
>> see("google")
> SAW "google" -------------------------------- 25 packages in 0.013 seconds ---
>   #  # Title     # Package
>   1  RgoogleMaps Overlays on Google map tiles in R
>   2  ggmap       A package for spatial visualization with Google Maps and Ope...
>   3  RGA         A Google Analytics API client for R
>   4  plotKML     Visualization of spatial and spatio-temporal objects in Goog...
>   5  googleVis   Interface between R and Google Charts
>   6  scholar     Analyse citation data from Google Scholar
>   7  translateR  Bindings for the Google and Microsoft Translation APIs
>   8  plusser     A Google+ Interface for R
>   9  gooJSON     Google JSON Data Interpreter for R
>   10 translate   Bindings for the Google Translate API v2
>> more()
> SAW "google" -------------------------------- 25 packages in 0.012 seconds ---
>   #  # Title          # Package
>   11 ngramr           Retrieve and plot Google n-gram data
>   12 RGoogleAnalytics R Wrapper for the Google Analytics API
>   13 R2G2             Converting R CRAN outputs into Google Earth.
>   14 plotGoogleMaps   Plot spatial or spatio-temporal data over Google Maps
>   15 googlePublicData An R library to build Google's Public Data Explorer DSP...
>   16 RWeather         R wrapper around the Yahoo! Weather, Google Weather and...
>   17 sysfonts         Loading system fonts into R
>   18 hashFunction     A collection of non-cryptographic hash functions
>   19 rgauges          R wrapper to Gaug.es API
>   20 splitstackshape  Stack and Reshape Datasets After Splitting Concatenated...
>
> 2. The second difference is that metacran ranks the search results
> based on (among other things) the package dependency graph, so if you
> search for 'graphics' lattice and ggplot2 come first.
>
> 3. Another difference is that metacran exposes a full search API of
> the underlying ElasticSearch engine, so if someone wants to rank
> results differently, or make more difficult complex queries, they can.
>
> 4. It does not search code and docs. I think rdocumentation.org does a
> good job with docs, and http://github.com/cran is great for code, e.g.
> if you want packages that call SET_SLOT in C:
> https://github.com/search?l=c&q=SET_SLOT+user%3Acran&ref=searchresults&type=Code&utf8=%E2%9C%93


       Thanks for the explanation of metacran/seer.


       "sos" is also designed to identify packages, but it does it based 
on the number and rank of help pages matching the search term.  I often 
do "a|b" to obtain the union of two different searches then use 
"writeFindFn2xls" to output the result to an MS Excel file with 3 
sheets:  (1) a package summary,  (2) the raw search results of help 
pages sorted by package, and (3) info on the search terms used.  
"findFn" has a "sortBy" that allows a user to change the default sort 
order, but I've never used it.  Part of the information from the package 
summary is taken from installed packages and is missing for packages 
that are not installed.  "sos" includes "installPackages" to install the 
highest ranking packages, but that's a poor solution to the problem.  
I'd be happy to work with others who can potentially improve the 
selection of information to present and get it all without installing 
the packages first. Spencer

>
> Gabor
>
> On Sun, Nov 9, 2014 at 7:18 PM, Spencer Graves
> <spencer.graves at prodsyse.com> wrote:
>>        Might it be appropriate to add "http://metacran.github.io/search" and
>> the "sos" package to the official list of R search capabilities at
>> "www.r-project.org/search.html"?  [Disclaimer:  I'm the lead author of
>> "sos".]
>>
>>
>>        Best Wishes,
>>        Spencer Graves
>>
>>
>> On 11/9/2014 11:06 AM, G?bor Cs?rdi wrote:
>>> Hi,
>>>
>>> I think much of this is simply impossible to do. CRAN packages are
>>> written and maintained by thousands of people, how are you planning to
>>> convince them to reorganize their packages? Or even just rename them?
>>> This obviously won't happen.
>>>
>>> Btw. did you see 'CRAN Task Views'? That is one organizations of
>>> packages into topics.
>>>
>>> Personally, I don't think organization is the solution here. It is too
>>> costly (i.e. too much work) to maintain, impossible to enforce. I
>>> think, however, that a good search engine would definitely help.
>>>
>>> FWIW there is a simple search engine here:
>>> http://metacran.github.io/search/
>>> This ranks packages according to the number of reverse dependencies
>>> (among other things), i.e. packages more often used by other packages
>>> will be higher up in the list.
>>>
>>> Ranking them according to downloads is also possible, but AFAIK only
>>> one CRAN mirror gives out statistics about downloads, so you don't
>>> really have the complete numbers there.
>>>
>>> Disclaimer: I built the search engine above. There are obviously other
>>> alternatives as well, e.g. http://rdocumentation.org, and
>>> http://mran.revolutionanalytics.com/packages/ are the two I know.
>>>
>>> Gabor
>>>
>>> On Sun, Nov 9, 2014 at 11:24 AM, Steven Sagaert
>>> <steven.sagaert at gmail.com> wrote:
>>>> Hi,
>>>> I?ve been using R on and off for a couple of years. I think R is pretty
>>>> great but one thing I?d like to see improved is the way packages are
>>>> organised. Instead of CRAN being a long list of packages having a short &
>>>> usually unintelligible name I ?d like to see packages organised in a
>>>> hierarchical way with that path acting as a hierarchical namespace just like
>>>> you have in many other languages like Java, C#,Scala,? The names of the
>>>> (sub)packages should also be clear and unambiguous & packages should be
>>>> organised according to their functionality and not just for example be code
>>>> for a whole book thrown together and given a cryptic name.
>>>>
>>>> Next to that it would be nice to have extra metadata in the packages to
>>>> allow for another more loose flat multi-class class-action like in tagging
>>>> blog systems & other metadata to allow for for automatically generating
>>>> something like task views.
>>>>
>>>> Due to the large number of packages it?s hard to see the forest from the
>>>> trees so a recommendation system for CRAN based on popularity (download
>>>> statistics) , ratings & other data  like related packages from package
>>>> metadata would be most welcome.
>>>>
>>>> Finally the number of packages in CRAN is exponentially growing but there
>>>> is also a large partial overlap in functionality between packages & so many
>>>> packages make it hard to find what you are looking for. So maybe there less
>>>> is more and there should be a system of removing hardly used/low quality
>>>> packages on a regular basis.
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From georgi.boshnakov at manchester.ac.uk  Mon Nov 10 13:49:38 2014
From: georgi.boshnakov at manchester.ac.uk (Georgi Boshnakov)
Date: Mon, 10 Nov 2014 12:49:38 +0000
Subject: [Rd] ambiguity in the documented return value of Null() from
	package MASS
Message-ID: <438D2EC9EAFE5946B2D5864670EA468E0145C06617@MBXP01.ds.man.ac.uk>

Hi,
 
Function Null from package MASS seems to return a matrix with zero columns and the expected number of rows when
the null space of the argument contains only the zero vector, e.g. 

> library(MASS)
> diag(nrow=3)
     [,1] [,2] [,3]
[1,]    1    0    0
[2,]    0    1    0
[3,]    0    0    1

>  Null(diag(nrow=3))

[1,]
[2,]
[3,]

But the documentation of Null  seems to imply that the result is numeric(0):

-----------------------------------------------

Value: 

The matrix 'N' with the basis for the null space, or an empty
     vector if the matrix 'M' is square and of maximal rank.

-----------------------------------------------

(R version 3.1.1 Patched (2014-09-21 r66653) -- "Sock it to Me")

Georgi


From pdalgd at gmail.com  Mon Nov 10 14:47:16 2014
From: pdalgd at gmail.com (peter dalgaard)
Date: Mon, 10 Nov 2014 14:47:16 +0100
Subject: [Rd] ambiguity in the documented return value of Null() from
	package MASS
In-Reply-To: <438D2EC9EAFE5946B2D5864670EA468E0145C06617@MBXP01.ds.man.ac.uk>
References: <438D2EC9EAFE5946B2D5864670EA468E0145C06617@MBXP01.ds.man.ac.uk>
Message-ID: <7E647343-87CF-4DB2-969D-C4F7F4A76B28@gmail.com>

There is a maintainer for this contributed package...

However, a zero column vector _is_ numeric(0) -- with dimension attributes c(3,0). 

structure(numeric(0),dim=c(3,0))
c(Null(diag(3)))

I.e., the ambiguity is pretty slight. 

Presumably, the help file wording goes back to S-PLUS which (to my recollection) didn't allow zero-extent matrices. The actual behaviour is a clear improvement.

- Peter D.



On 10 Nov 2014, at 13:49 , Georgi Boshnakov <georgi.boshnakov at manchester.ac.uk> wrote:

> Hi,
> 
> Function Null from package MASS seems to return a matrix with zero columns and the expected number of rows when
> the null space of the argument contains only the zero vector, e.g. 
> 
>> library(MASS)
>> diag(nrow=3)
>     [,1] [,2] [,3]
> [1,]    1    0    0
> [2,]    0    1    0
> [3,]    0    0    1
> 
>> Null(diag(nrow=3))
> 
> [1,]
> [2,]
> [3,]
> 
> But the documentation of Null  seems to imply that the result is numeric(0):
> 
> -----------------------------------------------
> 
> Value: 
> 
> The matrix 'N' with the basis for the null space, or an empty
>     vector if the matrix 'M' is square and of maximal rank.
> 
> -----------------------------------------------
> 
> (R version 3.1.1 Patched (2014-09-21 r66653) -- "Sock it to Me")
> 
> Georgi
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From maechler at stat.math.ethz.ch  Mon Nov 10 15:12:43 2014
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 10 Nov 2014 15:12:43 +0100
Subject: [Rd] ambiguity in the documented return value of Null()
	from	package MASS
In-Reply-To: <7E647343-87CF-4DB2-969D-C4F7F4A76B28@gmail.com>
References: <438D2EC9EAFE5946B2D5864670EA468E0145C06617@MBXP01.ds.man.ac.uk>
	<7E647343-87CF-4DB2-969D-C4F7F4A76B28@gmail.com>
Message-ID: <21600.51163.598882.251181@stat.math.ethz.ch>

>>>>> peter dalgaard <pdalgd at gmail.com>
>>>>>     on Mon, 10 Nov 2014 14:47:16 +0100 writes:

    > There is a maintainer for this contributed package...
    > However, a zero column vector _is_ numeric(0) -- with
    > dimension attributes c(3,0).

    > structure(numeric(0),dim=c(3,0))
    > c(Null(diag(3)))

    > I.e., the ambiguity is pretty slight. 

    > Presumably, the help file wording goes back to S-PLUS
    > which (to my recollection) didn't allow zero-extent
    > matrices. The actual behaviour is a clear improvement.

    > - Peter D.

confirmed:

- S-PLUS aka S+ aka ...  did not have 0-extent matrices nor arrays
- R having them makes for much more consistent code in several places.
- one could argue that  matrix( , 3, 0) *is* a special case of
 an empty vector

Further confirmation [not for Peter, for other readers] :

> str(Null(diag(3)))
 num[1:3, 0 ] 
> identical(Null(diag(3)), matrix(pi, 3,0))
[1] TRUE
> 





    > On 10 Nov 2014, at 13:49 , Georgi Boshnakov <georgi.boshnakov at manchester.ac.uk> wrote:

    >> Hi,
    >> 
    >> Function Null from package MASS seems to return a matrix with zero columns and the expected number of rows when
    >> the null space of the argument contains only the zero vector, e.g. 
    >> 
    >>> library(MASS)
    >>> diag(nrow=3)
    >> [,1] [,2] [,3]
    >> [1,]    1    0    0
    >> [2,]    0    1    0
    >> [3,]    0    0    1
    >> 
    >>> Null(diag(nrow=3))
    >> 
    >> [1,]
    >> [2,]
    >> [3,]
    >> 
    >> But the documentation of Null  seems to imply that the result is numeric(0):
    >> 
    >> -----------------------------------------------
    >> 
    >> Value: 
    >> 
    >> The matrix 'N' with the basis for the null space, or an empty
    >> vector if the matrix 'M' is square and of maximal rank.
    >> 
    >> -----------------------------------------------
    >> 
    >> (R version 3.1.1 Patched (2014-09-21 r66653) -- "Sock it to Me")
    >> 
    >> Georgi
    >> 
    >> ______________________________________________
    >> R-devel at r-project.org mailing list
    >> https://stat.ethz.ch/mailman/listinfo/r-devel

    > -- 
    > Peter Dalgaard, Professor,
    > Center for Statistics, Copenhagen Business School
    > Solbjerg Plads 3, 2000 Frederiksberg, Denmark
    > Phone: (+45)38153501
    > Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com

    > ______________________________________________
    > R-devel at r-project.org mailing list
    > https://stat.ethz.ch/mailman/listinfo/r-devel


From kindlychung at gmail.com  Mon Nov 10 16:52:20 2014
From: kindlychung at gmail.com (Kaiyin Zhong (Victor Chung))
Date: Mon, 10 Nov 2014 15:52:20 +0000
Subject: [Rd] Cursor not behaving properly
Message-ID: <CAOHtMfUupQ2KSGwuoZcKZRJ3BAdQLzTxgV8-ucAMMoMpWzEYCg@mail.gmail.com>

I found a strange bug in R recently (version 3.1.2):

As you can see from the screenshots attached, when the cursor passes the
right edge of the console, instead of start on a new line, it goes back to
the beginning of the same line, and overwrites everything after it.

This happens every time the size of the terminal is changed, for example,
if you fit the terminal to the right half of the screen, start an R
session, exec some commands, maximize the terminal, and type a long command
into the session, then you will find the bug reproduced.

I am on Ubuntu 14.04, and I have tested this in konsole, guake and
gnome-terminal.
-------------- next part --------------
A non-text attachment was scrubbed...
Name: snapshot1.png
Type: image/png
Size: 1252 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20141110/81c0c08d/attachment.png>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: snapshot2.png
Type: image/png
Size: 1483 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20141110/81c0c08d/attachment-0001.png>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: snapshot3.png
Type: image/png
Size: 1637 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20141110/81c0c08d/attachment-0002.png>

From wdunlap at tibco.com  Mon Nov 10 17:40:39 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 10 Nov 2014 08:40:39 -0800
Subject: [Rd] ambiguity in the documented return value of Null() from
 package MASS
In-Reply-To: <7E647343-87CF-4DB2-969D-C4F7F4A76B28@gmail.com>
References: <438D2EC9EAFE5946B2D5864670EA468E0145C06617@MBXP01.ds.man.ac.uk>
	<7E647343-87CF-4DB2-969D-C4F7F4A76B28@gmail.com>
Message-ID: <CAF8bMcbrfUj0o+sK34mY+h=qnNc=K34b7GqnpOeEZWJDm+5MbA@mail.gmail.com>

> Presumably, the help file wording goes back to S-PLUS which
> (to my recollection) didn't allow zero-extent matrices.

Splus (and S) started having reasonable support for zero-extent
matrices in May 2001 (i.e., Splus 6.0, which I think corresponds
to S version 4-m of June 2, 1999),  Splus5.0 (Nov 20, 1998, corresponding
to S version 4-? of Oct 26, 1998) have very partial support for them.

  % Splus6.0
  S-PLUS : Copyright (c) 1988, 2001 Insightful Corp.
  S : Copyright Lucent Technologies, Inc.
  Version 6.0.1 Release 1 for Linux 2.2.12 : 2001
  Working data will be in .Data
  > library(MASS)
  > Null(diag(3))
  numeric matrix: 3 rows, 0 columns.
  > load.date()
  [1] "Fri May  4 01:09:06 PDT 2001"



Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Mon, Nov 10, 2014 at 5:47 AM, peter dalgaard <pdalgd at gmail.com> wrote:

> There is a maintainer for this contributed package...
>
> However, a zero column vector _is_ numeric(0) -- with dimension attributes
> c(3,0).
>
> structure(numeric(0),dim=c(3,0))
> c(Null(diag(3)))
>
> I.e., the ambiguity is pretty slight.
>
> Presumably, the help file wording goes back to S-PLUS which (to my
> recollection) didn't allow zero-extent matrices. The actual behaviour is a
> clear improvement.
>
> - Peter D.
>
>
>
> On 10 Nov 2014, at 13:49 , Georgi Boshnakov <
> georgi.boshnakov at manchester.ac.uk> wrote:
>
> > Hi,
> >
> > Function Null from package MASS seems to return a matrix with zero
> columns and the expected number of rows when
> > the null space of the argument contains only the zero vector, e.g.
> >
> >> library(MASS)
> >> diag(nrow=3)
> >     [,1] [,2] [,3]
> > [1,]    1    0    0
> > [2,]    0    1    0
> > [3,]    0    0    1
> >
> >> Null(diag(nrow=3))
> >
> > [1,]
> > [2,]
> > [3,]
> >
> > But the documentation of Null  seems to imply that the result is
> numeric(0):
> >
> > -----------------------------------------------
> >
> > Value:
> >
> > The matrix 'N' with the basis for the null space, or an empty
> >     vector if the matrix 'M' is square and of maximal rank.
> >
> > -----------------------------------------------
> >
> > (R version 3.1.1 Patched (2014-09-21 r66653) -- "Sock it to Me")
> >
> > Georgi
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
>
> --
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From maechler at stat.math.ethz.ch  Mon Nov 10 17:52:39 2014
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 10 Nov 2014 17:52:39 +0100
Subject: [Rd] R 3.1.1 and 3.1.2 both fail their test suites
In-Reply-To: <545A40A1.4000500@gmail.com>
References: <87lhnvje7d.fsf@write-only.cryp.to>
	<5454F2E6.9090301@statistik.tu-dortmund.de>
	<87ioizndfa.fsf@write-only.cryp.to> <545515C4.2090900@gmail.com>
	<21591.18461.92369.277925@stat.math.ethz.ch>
	<545766D3.9050809@gmail.com>
	<21594.3733.779424.351379@stat.math.ethz.ch>
	<545A1438.3060405@gmail.com> <878ujpemu6.fsf@write-only.cryp.to>
	<545A40A1.4000500@gmail.com>
Message-ID: <21600.60759.915093.547571@stat.math.ethz.ch>

>>>>> Duncan Murdoch <murdoch.duncan at gmail.com>
>>>>>     on Wed, 5 Nov 2014 10:22:09 -0500 writes:

    > On 05/11/2014 9:36 AM, Peter Simons wrote:
    >> Hi Duncan,
    >> 
    >> > I don't think we should be removing tests for everybody to allow a few
    >> > people to test a build of R that none of us actually use.
    >> 
    >> no tests need to be removed.

    > My response was to Martin, who proposed exactly that.

    >> All that needs to be done is to distinguish
    >> tests that require the recommended packages from those that don't. Then
    >> users can choose which test set they want to run.

    > Go ahead and submit a patch that does this, and I expect it would be 
    > accepted.
    > Duncan Murdoch

I have committed changes (svn 66943 and 66951) which more or
less achieves this.
Basic idea:  example() newly has an argument  'run.dontcheck = interactive()'
      whereas till now it implicitely had  'run.dontcheck = TRUE'
so using example(..) in our examples or strict tests should now
be safe(r).

So, in the current development version of R,
indeed  'make check' passes -- on one platform at least :-) --
even when R was configured to *not* install the recommended
packages alongside.

BTW: In one place, I've used

   base.and.rec <- .packages(all.available=TRUE, lib=.Library)
   example(glm, run.dontcheck = any("MASS" == base.and.rec))

for checking the presence of one (and by implication "all",
almost surely) recommended package.

Martin Maechler

    >> It would be particularly nice if "make check" would do the right thing
    >> automatically based on the choice of --with{,out}-recommended-packages
    >> at ./configure time. Offering two separate "check" targets would be
    >> equally good, though.
    >> 
    >> Best regards,
    >> Peter


From jefferis at mrc-lmb.cam.ac.uk  Mon Nov 10 19:35:18 2014
From: jefferis at mrc-lmb.cam.ac.uk (Dr Gregory Jefferis)
Date: Mon, 10 Nov 2014 18:35:18 +0000
Subject: [Rd] subscripting a data.frame (without changing row order) changes
 internal row.names
Message-ID: <E2D19D2D-FFB7-4A28-A6F1-2F72DA776C4A@mrc-lmb.cam.ac.uk>

Dear R-devel,

Can anyone help me to understand this? It seems that subscripting the 
rows of a data.frame without actually changing their order, somehow 
changes an internal representation of row.names that is revealed by e.g. 
dput/dump/serialize

I have read the docs and inspected the (R) code for data.frame, 
rownames, row.names and dput without enlightenment.

df=data.frame(a=1:10, b=1)
dput(df)
df2=df[1:nrow(df), ]
# R thinks they are equal (so do I!)
all.equal(df, df2)
dput(df2)

Looking at the output of the dputs

> dput(df)
structure(list(a = 1:10, b = c(1, 1, 1, 1, 1, 1, 1, 1, 1, 1)), .Names = 
c("a",
"b"), row.names = c(NA, -10L), class = "data.frame")
> dput(df2)
structure(list(a = 1:10, b = c(1, 1, 1, 1, 1, 1, 1, 1, 1, 1)), .Names = 
c("a",
"b"), row.names = c(NA, 10L), class = "data.frame")

we have row.names = c(NA, -10L) in the first case and row.names = c(NA, 
10L) in the second, so somehow these objects have a different 
representation

Can anyone explain why? This has come up because

> library(digest)
> digest(df)==digest(df2)
[1] FALSE

digest uses serialize under the hood, but serialize, dput and dump all 
show the same effect (I've pasted an example below using dump, md5sum 
from base R).

Many thanks for any enlightenment! More generally is there any way to 
calculate a digest of a data.frame that could get round this issue or is 
that not possible?

Best wishes,

Greg.


A digest using base R:

library(tools)
td=tempfile()
dir.create(td)
tempfiles=file.path(td,c("df", "df2"))
dump("df",tempfiles[1])
dump("df2",tempfiles[2])
md5sum(tempfiles)

# different md5sum

> sessionInfo() # for my laptop but also observed on R 3.1.2
R version 3.1.1 (2014-07-10)
Platform: x86_64-apple-darwin13.1.0 (64-bit)

locale:
[1] en_GB.UTF-8/en_GB.UTF-8/en_GB.UTF-8/C/en_GB.UTF-8/en_GB.UTF-8

attached base packages:
[1] tools     stats     graphics  grDevices utils     datasets  methods  
  base

other attached packages:
[1] nat_1.5.14      nat.utils_0.4.2 digest_0.6.4    Rvcg_0.9        
devtools_1.6.1  igraph_0.7.1
[7] testthat_0.9.1  rgl_0.93.1098

loaded via a namespace (and not attached):
  [1] codetools_0.2-9   filehash_2.2-2    nabor_0.4.3       
parallel_3.1.1    plyr_1.8.1
  [6] Rcpp_0.11.3       rstudio_0.98.1062 rstudioapi_0.1    XML_3.98-1.1 
      yaml_2.1.13

--
Gregory Jefferis, PhD
Division of Neurobiology
MRC Laboratory of Molecular Biology
Francis Crick Avenue
Cambridge Biomedical Campus
Cambridge, CB2 OQH, UK

http://www2.mrc-lmb.cam.ac.uk/group-leaders/h-to-m/g-jefferis
http://jefferislab.org
http://flybrain.stanford.edu


From josh.m.ulrich at gmail.com  Mon Nov 10 21:05:34 2014
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Mon, 10 Nov 2014 14:05:34 -0600
Subject: [Rd] subscripting a data.frame (without changing row order)
 changes internal row.names
In-Reply-To: <E2D19D2D-FFB7-4A28-A6F1-2F72DA776C4A@mrc-lmb.cam.ac.uk>
References: <E2D19D2D-FFB7-4A28-A6F1-2F72DA776C4A@mrc-lmb.cam.ac.uk>
Message-ID: <CAPPM_gRVgG78CNDfuqPZN0svHCgA5UHKvLcFUsOYsXhhYLKi3Q@mail.gmail.com>

On Mon, Nov 10, 2014 at 12:35 PM, Dr Gregory Jefferis
<jefferis at mrc-lmb.cam.ac.uk> wrote:
> Dear R-devel,
>
> Can anyone help me to understand this? It seems that subscripting the rows
> of a data.frame without actually changing their order, somehow changes an
> internal representation of row.names that is revealed by e.g.
> dput/dump/serialize
>
> I have read the docs and inspected the (R) code for data.frame, rownames,
> row.names and dput without enlightenment.
>
Look at ?.row_names_info (which is mentioned in the See Also section
of ?row.names) and its type argument.  Also see the discussion here:
http://stackoverflow.com/q/26468746/271616

> df=data.frame(a=1:10, b=1)
> dput(df)
> df2=df[1:nrow(df), ]
> # R thinks they are equal (so do I!)
> all.equal(df, df2)
> dput(df2)
>
> Looking at the output of the dputs
>
>> dput(df)
>
> structure(list(a = 1:10, b = c(1, 1, 1, 1, 1, 1, 1, 1, 1, 1)), .Names =
> c("a",
> "b"), row.names = c(NA, -10L), class = "data.frame")
>>
>> dput(df2)
>
> structure(list(a = 1:10, b = c(1, 1, 1, 1, 1, 1, 1, 1, 1, 1)), .Names =
> c("a",
> "b"), row.names = c(NA, 10L), class = "data.frame")
>
> we have row.names = c(NA, -10L) in the first case and row.names = c(NA, 10L)
> in the second, so somehow these objects have a different representation
>
> Can anyone explain why? This has come up because
>
The first are "automatic".  The second are a compact form of 1:10, as
mentioned in ?row.names.  I'm not certain of the root cause/reason,
but the second object will not have "automatic" rownames because you
have subset it with a non-missing 'i'.

>> library(digest)
>> digest(df)==digest(df2)
>
> [1] FALSE
>
> digest uses serialize under the hood, but serialize, dput and dump all show
> the same effect (I've pasted an example below using dump, md5sum from base
> R).
>
> Many thanks for any enlightenment! More generally is there any way to
> calculate a digest of a data.frame that could get round this issue or is
> that not possible?
>
> Best wishes,
>
> Greg.
>
>
> A digest using base R:
>
> library(tools)
> td=tempfile()
> dir.create(td)
> tempfiles=file.path(td,c("df", "df2"))
> dump("df",tempfiles[1])
> dump("df2",tempfiles[2])
> md5sum(tempfiles)
>
> # different md5sum
>
>> sessionInfo() # for my laptop but also observed on R 3.1.2
>
> R version 3.1.1 (2014-07-10)
> Platform: x86_64-apple-darwin13.1.0 (64-bit)
>
> locale:
> [1] en_GB.UTF-8/en_GB.UTF-8/en_GB.UTF-8/C/en_GB.UTF-8/en_GB.UTF-8
>
> attached base packages:
> [1] tools     stats     graphics  grDevices utils     datasets  methods
> base
>
> other attached packages:
> [1] nat_1.5.14      nat.utils_0.4.2 digest_0.6.4    Rvcg_0.9
> devtools_1.6.1  igraph_0.7.1
> [7] testthat_0.9.1  rgl_0.93.1098
>
> loaded via a namespace (and not attached):
>  [1] codetools_0.2-9   filehash_2.2-2    nabor_0.4.3       parallel_3.1.1
> plyr_1.8.1
>  [6] Rcpp_0.11.3       rstudio_0.98.1062 rstudioapi_0.1    XML_3.98-1.1
> yaml_2.1.13
>
> --
> Gregory Jefferis, PhD
> Division of Neurobiology
> MRC Laboratory of Molecular Biology
> Francis Crick Avenue
> Cambridge Biomedical Campus
> Cambridge, CB2 OQH, UK
>
> http://www2.mrc-lmb.cam.ac.uk/group-leaders/h-to-m/g-jefferis
> http://jefferislab.org
> http://flybrain.stanford.edu
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel



-- 
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com


From kevinushey at gmail.com  Mon Nov 10 23:21:57 2014
From: kevinushey at gmail.com (Kevin Ushey)
Date: Mon, 10 Nov 2014 14:21:57 -0800
Subject: [Rd] subscripting a data.frame (without changing row order)
 changes internal row.names
In-Reply-To: <CAPPM_gRVgG78CNDfuqPZN0svHCgA5UHKvLcFUsOYsXhhYLKi3Q@mail.gmail.com>
References: <E2D19D2D-FFB7-4A28-A6F1-2F72DA776C4A@mrc-lmb.cam.ac.uk>
	<CAPPM_gRVgG78CNDfuqPZN0svHCgA5UHKvLcFUsOYsXhhYLKi3Q@mail.gmail.com>
Message-ID: <CAJXgQP3kwH=dGF8+2PBB_5A5aN8K54EpeJNs5qPC5WGoMsEg7w@mail.gmail.com>

I believe the question here is related to the sign on the compact row
names representation: why is it sometimes `c(NA, <positive>)` and
sometimes `c(NA, <negative>)` -- why the difference in sign?

To the best of my knowledge, older versions of R used the signed-ness
of compact row.names to differentiate between different 'types' of
data.frames, but that should no longer be necessary. Unless there is
some reason not to, I believe R should standardize on one
representation, and consider it a bug if the other is seen.

Of course, I could be wrong, so I only offer my understanding only as
a way of invoking Cunningham's law...

Cheers,
Kevin

On Mon, Nov 10, 2014 at 12:05 PM, Joshua Ulrich <josh.m.ulrich at gmail.com> wrote:
> On Mon, Nov 10, 2014 at 12:35 PM, Dr Gregory Jefferis
> <jefferis at mrc-lmb.cam.ac.uk> wrote:
>> Dear R-devel,
>>
>> Can anyone help me to understand this? It seems that subscripting the rows
>> of a data.frame without actually changing their order, somehow changes an
>> internal representation of row.names that is revealed by e.g.
>> dput/dump/serialize
>>
>> I have read the docs and inspected the (R) code for data.frame, rownames,
>> row.names and dput without enlightenment.
>>
> Look at ?.row_names_info (which is mentioned in the See Also section
> of ?row.names) and its type argument.  Also see the discussion here:
> http://stackoverflow.com/q/26468746/271616
>
>> df=data.frame(a=1:10, b=1)
>> dput(df)
>> df2=df[1:nrow(df), ]
>> # R thinks they are equal (so do I!)
>> all.equal(df, df2)
>> dput(df2)
>>
>> Looking at the output of the dputs
>>
>>> dput(df)
>>
>> structure(list(a = 1:10, b = c(1, 1, 1, 1, 1, 1, 1, 1, 1, 1)), .Names =
>> c("a",
>> "b"), row.names = c(NA, -10L), class = "data.frame")
>>>
>>> dput(df2)
>>
>> structure(list(a = 1:10, b = c(1, 1, 1, 1, 1, 1, 1, 1, 1, 1)), .Names =
>> c("a",
>> "b"), row.names = c(NA, 10L), class = "data.frame")
>>
>> we have row.names = c(NA, -10L) in the first case and row.names = c(NA, 10L)
>> in the second, so somehow these objects have a different representation
>>
>> Can anyone explain why? This has come up because
>>
> The first are "automatic".  The second are a compact form of 1:10, as
> mentioned in ?row.names.  I'm not certain of the root cause/reason,
> but the second object will not have "automatic" rownames because you
> have subset it with a non-missing 'i'.
>
>>> library(digest)
>>> digest(df)==digest(df2)
>>
>> [1] FALSE
>>
>> digest uses serialize under the hood, but serialize, dput and dump all show
>> the same effect (I've pasted an example below using dump, md5sum from base
>> R).
>>
>> Many thanks for any enlightenment! More generally is there any way to
>> calculate a digest of a data.frame that could get round this issue or is
>> that not possible?
>>
>> Best wishes,
>>
>> Greg.
>>
>>
>> A digest using base R:
>>
>> library(tools)
>> td=tempfile()
>> dir.create(td)
>> tempfiles=file.path(td,c("df", "df2"))
>> dump("df",tempfiles[1])
>> dump("df2",tempfiles[2])
>> md5sum(tempfiles)
>>
>> # different md5sum
>>
>>> sessionInfo() # for my laptop but also observed on R 3.1.2
>>
>> R version 3.1.1 (2014-07-10)
>> Platform: x86_64-apple-darwin13.1.0 (64-bit)
>>
>> locale:
>> [1] en_GB.UTF-8/en_GB.UTF-8/en_GB.UTF-8/C/en_GB.UTF-8/en_GB.UTF-8
>>
>> attached base packages:
>> [1] tools     stats     graphics  grDevices utils     datasets  methods
>> base
>>
>> other attached packages:
>> [1] nat_1.5.14      nat.utils_0.4.2 digest_0.6.4    Rvcg_0.9
>> devtools_1.6.1  igraph_0.7.1
>> [7] testthat_0.9.1  rgl_0.93.1098
>>
>> loaded via a namespace (and not attached):
>>  [1] codetools_0.2-9   filehash_2.2-2    nabor_0.4.3       parallel_3.1.1
>> plyr_1.8.1
>>  [6] Rcpp_0.11.3       rstudio_0.98.1062 rstudioapi_0.1    XML_3.98-1.1
>> yaml_2.1.13
>>
>> --
>> Gregory Jefferis, PhD
>> Division of Neurobiology
>> MRC Laboratory of Molecular Biology
>> Francis Crick Avenue
>> Cambridge Biomedical Campus
>> Cambridge, CB2 OQH, UK
>>
>> http://www2.mrc-lmb.cam.ac.uk/group-leaders/h-to-m/g-jefferis
>> http://jefferislab.org
>> http://flybrain.stanford.edu
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>
>
> --
> Joshua Ulrich  |  about.me/joshuaulrich
> FOSS Trading  |  www.fosstrading.com
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From jefferis at mrc-lmb.cam.ac.uk  Tue Nov 11 00:27:22 2014
From: jefferis at mrc-lmb.cam.ac.uk (Dr Gregory Jefferis)
Date: Mon, 10 Nov 2014 23:27:22 +0000
Subject: [Rd] subscripting a data.frame (without changing row order)
 changes internal row.names
In-Reply-To: <CAJXgQP3kwH=dGF8+2PBB_5A5aN8K54EpeJNs5qPC5WGoMsEg7w@mail.gmail.com>
References: <E2D19D2D-FFB7-4A28-A6F1-2F72DA776C4A@mrc-lmb.cam.ac.uk>
	<CAPPM_gRVgG78CNDfuqPZN0svHCgA5UHKvLcFUsOYsXhhYLKi3Q@mail.gmail.com>
	<CAJXgQP3kwH=dGF8+2PBB_5A5aN8K54EpeJNs5qPC5WGoMsEg7w@mail.gmail.com>
Message-ID: <CBBA192D-F1B2-441D-A4B1-758C87A4A362@mrc-lmb.cam.ac.uk>

Hi Kevin, Joshua,

Many thanks for this additional information.

On 10 Nov 2014, at 22:21, Kevin Ushey wrote:

> I believe the question here is related to the sign on the compact row
> names representation: why is it sometimes `c(NA, <positive>)` and
> sometimes `c(NA, <negative>)` -- why the difference in sign?

It was indeed the difference in sign that Kevin highlights that was 
puzzling me

> To the best of my knowledge, older versions of R used the signed-ness
> of compact row.names to differentiate between different 'types' of
> data.frames, but that should no longer be necessary. Unless there is
> some reason not to, I believe R should standardize on one
> representation, and consider it a bug if the other is seen.

[snip, Joshua wrote ]

>> Look at ?.row_names_info (which is mentioned in the See Also section
>> of ?row.names) and its type argument.

>> The first are "automatic".  The second are a compact form of 1:10, as
>> mentioned in ?row.names.  I'm not certain of the root cause/reason,
>> but the second object will not have "automatic" rownames because you
>> have subset it with a non-missing 'i'.

Quoting ?.row_names_info for

> .row_names_info(x, type = 1L)

> Currently type = 0 returns the internal "row.names" attribute 
> (possibly NULL), type = 2 the number of rows implied by the attribute, 
> and type = 1 the latter with a negative sign for ?automatic? row 
> names.

> .row_names_info(df2)
[1] 10
> .row_names_info(df)
[1] -10

So indeed the first case is marked as automatic, the second not.

Thanks again,

Greg.

--
Gregory Jefferis, PhD                   Tel: 01223 267048
Division of Neurobiology
MRC Laboratory of Molecular Biology
Francis Crick Avenue
Cambridge Biomedical Campus
Cambridge, CB2 OQH, UK

http://www2.mrc-lmb.cam.ac.uk/group-leaders/h-to-m/g-jefferis
http://jefferislab.org
http://flybrain.stanford.edu


From brodie.gaslam at yahoo.com  Tue Nov 11 15:39:15 2014
From: brodie.gaslam at yahoo.com (brodie gaslam)
Date: Tue, 11 Nov 2014 06:39:15 -0800
Subject: [Rd] Should R Packages Unload Dynamic Libraries When They Unload?
Message-ID: <1415716755.66393.YahooMailNeo@web162202.mail.bf1.yahoo.com>



>From Hadley's C best practices (http://r-pkgs.had.co.nz/src.html#c-best-practices):

> Like with C++, whenever you use C code in your package, you should unload the DLL when the package is unloaded:

    .onUnload <- function (libpath) {
      library.dynam.unload("mypackage", libpath)
    }

Writing R Extensions on the other hand doesn't even mention this (AFAIK). I can see how it would be polite to unload the dlls, but doing so seems to cause some weird problems for me with packages that are loaded/unloaded/reloaded. Additionally, there are some mentions that suggest maybe unloading isn't required. From ?library.dynam:

> Note that whether or not it is possible to unload a DLL and then reload a revised version of the same file is OS-dependent: see the ?Value? section of the help for dyn.unload.

though this shouldn't affect objects that are not modified. Then there is this comment from Brian Ripley in R-devel (https://stat.ethz.ch/pipermail/r-devel/2010-November/059062.html):

> Having said all that, my experience is that unloading the DLL often does not help if you need to load it again (and that is why e.g. tcltk does not unload its DLL).

Is it acceptable for packages to leave the C libraries loaded when they are unloaded?


I'm on R 3.1.1 on a Mac OS X, though this question is not specific to my system.


I originally asked this on SO (http://stackoverflow.com/questions/26691878/must-r-packages-unload-dynamic-libraries-when-they-unload), but got crickets.
	[[alternative HTML version deleted]]


From vinhdizzo at gmail.com  Tue Nov 11 19:23:39 2014
From: vinhdizzo at gmail.com (Vinh Nguyen)
Date: Tue, 11 Nov 2014 10:23:39 -0800
Subject: [Rd] segfault with readDCF on R 3.1.2 on AIX 6.1 when using
	install.packages
Message-ID: <CA+2Dmwgowjk9+qKcVQOPXRaGpER5wu+UtqZ=pJrJmaNS1DDpdw@mail.gmail.com>

Dear list (re-posting from r-help as r-devel is probably more appropriate),

I was able to successfully compile R on our AIX box at work using the
GNU compilers following the instructions on the R Administration
guide.  The output can be seen at here
(https://gist.github.com/nguyenvinh/504321ea9c89d8919bef) and yields
no errors .

However, I get a segfault whenever I try to use the install.packages
function to install packages.  Using debug, I was able to trace it to
the readDCF function:

Browse[2]>
debug: if (!all) return(.Internal(readDCF(file, fields, keep.white)))
Browse[2]>
debug: return(.Internal(readDCF(file, fields, keep.white)))
Browse[2]>

 *** caught segfault ***
address 4, cause 'invalid permissions'

Possible actions:
1: abort (with core dump, if enabled)
2: normal R exit
3: exit R without saving workspace
4: exit R saving workspace
Selection:

Was curious if anyone has a clue on why such error exists or what I
could do to fix it?  I'm able to install packages via R CMD INSTALL,
but I would hate to have to manually determine dependencies, download
the source for each package, and install them "by hand" via R CMD
INSTALL.

I went back and compiled older versions of R to see if this error
exists.  On R 3.0.3, I get:

debug(available.packages)
install.packages('ggplot2', dep=TRUE, repo='http://cran.stat.ucla.edu')
...
Browse[2]>
debug: z <- res0 <- tryCatch(read.dcf(file = tmpf), error = identity)
Browse[2]>
Error: segfault from C stack overflow

On R 2.15.3, I do not see the error.

Would be great to get this resolved.  Thank you for your help.

-- Vinh


From zhengda1936 at gmail.com  Wed Nov 12 14:36:09 2014
From: zhengda1936 at gmail.com (Zheng Da)
Date: Wed, 12 Nov 2014 08:36:09 -0500
Subject: [Rd] How to maintain memory in R extension
Message-ID: <CAFLer80OKhvuH2BRuC3qdTFN-2Kg6MPzh0A24NNBs+JMbO-fvQ@mail.gmail.com>

Hello,

I wrote a system to perform data analysis in C++. Now I am integrating
it to R. I need to allocate memory for my own C++ data structures,
which can't be represented by any R data structures. I create a global
hashtable to keep a reference to the C++ data structures. Whenever I
allocate one, I register it in the hashtable and return its key to the
R code. So later on, the R code can access the C++ data structures
with their keys.

The problem is how to perform garbage collection on the C++ data
structures. Once an R object that contains the key is garbage
collected, the R code can no longer access the corresponding C++ data
structure, so I need to deallocate it. Is there any way that the C++
code can get notification when an R object gets garbage collected? If
not, what is the usual way to manage memory in R extensions?

Thanks,
Da


From csardi.gabor at gmail.com  Wed Nov 12 15:36:33 2014
From: csardi.gabor at gmail.com (=?UTF-8?B?R8OhYm9yIENzw6FyZGk=?=)
Date: Wed, 12 Nov 2014 09:36:33 -0500
Subject: [Rd] How to maintain memory in R extension
In-Reply-To: <CAFLer80OKhvuH2BRuC3qdTFN-2Kg6MPzh0A24NNBs+JMbO-fvQ@mail.gmail.com>
References: <CAFLer80OKhvuH2BRuC3qdTFN-2Kg6MPzh0A24NNBs+JMbO-fvQ@mail.gmail.com>
Message-ID: <CABtg=KkzuYuLtPEZzQMaZyZbgZ1FPqUGygUVKMvsWStBnRYPfg@mail.gmail.com>

Hi,

I think you need external pointers:
http://cran.r-project.org/doc/manuals/r-release/R-exts.html#External-pointers-and-weak-references
The docs also has an example.

See more examples from other R packages here:
https://github.com/search?q=R_MakeExternalPtr+user%3Acran&type=Code&utf8=%E2%9C%93

Gabor

On Wed, Nov 12, 2014 at 8:36 AM, Zheng Da <zhengda1936 at gmail.com> wrote:
> Hello,
>
> I wrote a system to perform data analysis in C++. Now I am integrating
> it to R. I need to allocate memory for my own C++ data structures,
> which can't be represented by any R data structures. I create a global
> hashtable to keep a reference to the C++ data structures. Whenever I
> allocate one, I register it in the hashtable and return its key to the
> R code. So later on, the R code can access the C++ data structures
> with their keys.
>
> The problem is how to perform garbage collection on the C++ data
> structures. Once an R object that contains the key is garbage
> collected, the R code can no longer access the corresponding C++ data
> structure, so I need to deallocate it. Is there any way that the C++
> code can get notification when an R object gets garbage collected? If
> not, what is the usual way to manage memory in R extensions?
>
> Thanks,
> Da
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From mtmorgan at fredhutch.org  Wed Nov 12 19:20:33 2014
From: mtmorgan at fredhutch.org (Martin Morgan)
Date: Wed, 12 Nov 2014 10:20:33 -0800
Subject: [Rd] How to maintain memory in R extension
In-Reply-To: <CAFLer80OKhvuH2BRuC3qdTFN-2Kg6MPzh0A24NNBs+JMbO-fvQ@mail.gmail.com>
References: <CAFLer80OKhvuH2BRuC3qdTFN-2Kg6MPzh0A24NNBs+JMbO-fvQ@mail.gmail.com>
Message-ID: <5463A4F1.3090008@fredhutch.org>

On 11/12/2014 05:36 AM, Zheng Da wrote:
> Hello,
>
> I wrote a system to perform data analysis in C++. Now I am integrating
> it to R. I need to allocate memory for my own C++ data structures,
> which can't be represented by any R data structures. I create a global
> hashtable to keep a reference to the C++ data structures. Whenever I
> allocate one, I register it in the hashtable and return its key to the
> R code. So later on, the R code can access the C++ data structures
> with their keys.
>
> The problem is how to perform garbage collection on the C++ data
> structures. Once an R object that contains the key is garbage
> collected, the R code can no longer access the corresponding C++ data
> structure, so I need to deallocate it. Is there any way that the C++
> code can get notification when an R object gets garbage collected? If
> not, what is the usual way to manage memory in R extensions?

register a finalizer that runs when there are no longer references to the R 
object, see ?reg.finalizer or the interface to R and C finalizers in 
Rinternals.h. If you return more than one reference to a key, then of course 
you'll have to manage these in your own C++ code.

Martin Morgan

>
> Thanks,
> Da
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


-- 
Computational Biology / Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N.
PO Box 19024 Seattle, WA 98109

Location: Arnold Building M1 B861
Phone: (206) 667-2793


From therneau at mayo.edu  Wed Nov 12 20:11:09 2014
From: therneau at mayo.edu (Therneau, Terry M., Ph.D.)
Date: Wed, 12 Nov 2014 13:11:09 -0600
Subject: [Rd] Problem with  build and check
Message-ID: <58e5f6$jk252p@ironport9.mayo.edu>

I am getting failure of build and check, for an Rd file that has a long argument list.
Guess diagnosis: a quoted string beyond a certain point in the argument list is fatal.

Example:  Use the function below, create an Rd file for it with prompt().  Move the .Rd 
file to the man directory (no need to edit it) and try building

dart.control <- function(server=c("production", "integration", "development",
                                   "http"),
                          out.poll.duration = 5,
                          out.poll.increase = 1.1,
                          out.poll.max = 30,
                          out.poll.timeout = 3600,
                          netrc.path,
                          netrc.server = "ldap",
                          rtype = c("xml", "json"),
                          dateformat= "%Y-%m-%d") {

     server <- match.arg(server)
     server
}

I created a package "dummy" with only this function, and get the following on my Linux box.

tmt-local2021% R CMD build dummy
* checking for file ?dummy/DESCRIPTION? ... OK
* preparing ?dummy?:
* checking DESCRIPTION meta-information ... OK
Warning: newline within quoted string at dart.control.Rd:11
Warning: /tmp/RtmpjPjz9V/Rbuild398d6e382572/dummy/man/dart.control.Rd:46: unexpected 
section header '\value'
Warning: newline within quoted string at dart.control.Rd:11
Error in parse_Rd("/tmp/RtmpjPjz9V/Rbuild398d6e382572/dummy/man/dart.control.Rd", :
   Unexpected end of input (in " quoted string opened at dart.control.Rd:88:16)
Execution halted

Session info for my version
 > sessionInfo()
R Under development (unstable) (2014-10-30 r66907)
Platform: i686-pc-linux-gnu (32-bit)

locale:
  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=C
  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
  [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods base


Terry T.


From pgilbert902 at gmail.com  Wed Nov 12 20:24:02 2014
From: pgilbert902 at gmail.com (Paul Gilbert)
Date: Wed, 12 Nov 2014 14:24:02 -0500
Subject: [Rd] Problem with  build and check
In-Reply-To: <58e5f6$jk252p@ironport9.mayo.edu>
References: <58e5f6$jk252p@ironport9.mayo.edu>
Message-ID: <5463B3D2.1060207@gmail.com>

I certainly have longer argument lists with no problem. More likely the 
Rd file needs special consideration for %.

Paul

On 11/12/2014 02:11 PM, Therneau, Terry M., Ph.D. wrote:
> I am getting failure of build and check, for an Rd file that has a long
> argument list.
> Guess diagnosis: a quoted string beyond a certain point in the argument
> list is fatal.
>
> Example:  Use the function below, create an Rd file for it with
> prompt().  Move the .Rd file to the man directory (no need to edit it)
> and try building
>
> dart.control <- function(server=c("production", "integration",
> "development",
>                                    "http"),
>                           out.poll.duration = 5,
>                           out.poll.increase = 1.1,
>                           out.poll.max = 30,
>                           out.poll.timeout = 3600,
>                           netrc.path,
>                           netrc.server = "ldap",
>                           rtype = c("xml", "json"),
>                           dateformat= "%Y-%m-%d") {
>
>      server <- match.arg(server)
>      server
> }
>
> I created a package "dummy" with only this function, and get the
> following on my Linux box.
>
> tmt-local2021% R CMD build dummy
> * checking for file ?dummy/DESCRIPTION? ... OK
> * preparing ?dummy?:
> * checking DESCRIPTION meta-information ... OK
> Warning: newline within quoted string at dart.control.Rd:11
> Warning:
> /tmp/RtmpjPjz9V/Rbuild398d6e382572/dummy/man/dart.control.Rd:46:
> unexpected section header '\value'
> Warning: newline within quoted string at dart.control.Rd:11
> Error in
> parse_Rd("/tmp/RtmpjPjz9V/Rbuild398d6e382572/dummy/man/dart.control.Rd", :
>    Unexpected end of input (in " quoted string opened at
> dart.control.Rd:88:16)
> Execution halted
>
> Session info for my version
>  > sessionInfo()
> R Under development (unstable) (2014-10-30 r66907)
> Platform: i686-pc-linux-gnu (32-bit)
>
> locale:
>   [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>   [3] LC_TIME=en_US.UTF-8        LC_COLLATE=C
>   [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>   [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>   [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods base
>
>
> Terry T.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From es at enricoschumann.net  Wed Nov 12 20:25:39 2014
From: es at enricoschumann.net (Enrico Schumann)
Date: Wed, 12 Nov 2014 20:25:39 +0100
Subject: [Rd] Problem with  build and check
In-Reply-To: <58e5f6$jk252p@ironport9.mayo.edu> (Terry M. Therneau's message
	of "Wed, 12 Nov 2014 13:11:09 -0600")
References: <58e5f6$jk252p@ironport9.mayo.edu>
Message-ID: <87ioikgr0s.fsf@enricoschumann.net>

On Wed, 12 Nov 2014, "Therneau, Terry M., Ph.D." <therneau at mayo.edu> writes:

> I am getting failure of build and check, for an Rd file that has a long argument list.
> Guess diagnosis: a quoted string beyond a certain point in the argument list is fatal.

Another guess: should you not escape the '%'?  That is, write
"\%Y-\%m-\%d"?  [Untested.]

> Example:  Use the function below, create an Rd file for it with
> prompt().  Move the .Rd file to the man directory (no need to edit it)
> and try building
>
> dart.control <- function(server=c("production", "integration", "development",
>                                   "http"),
>                          out.poll.duration = 5,
>                          out.poll.increase = 1.1,
>                          out.poll.max = 30,
>                          out.poll.timeout = 3600,
>                          netrc.path,
>                          netrc.server = "ldap",
>                          rtype = c("xml", "json"),
>                          dateformat= "%Y-%m-%d") {
>
>     server <- match.arg(server)
>     server
> }
>
> I created a package "dummy" with only this function, and get the following on my Linux box.
>
> tmt-local2021% R CMD build dummy
> * checking for file ?dummy/DESCRIPTION? ... OK
> * preparing ?dummy?:
> * checking DESCRIPTION meta-information ... OK
> Warning: newline within quoted string at dart.control.Rd:11
> Warning:
> /tmp/RtmpjPjz9V/Rbuild398d6e382572/dummy/man/dart.control.Rd:46:
> unexpected section header '\value'
> Warning: newline within quoted string at dart.control.Rd:11
> Error in parse_Rd("/tmp/RtmpjPjz9V/Rbuild398d6e382572/dummy/man/dart.control.Rd", :
>   Unexpected end of input (in " quoted string opened at dart.control.Rd:88:16)
> Execution halted
>
> Session info for my version
>> sessionInfo()
> R Under development (unstable) (2014-10-30 r66907)
> Platform: i686-pc-linux-gnu (32-bit)
>
> locale:
>  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=C
>  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods base
>
>
> Terry T.
>


-- 
Enrico Schumann
Lucerne, Switzerland
http://enricoschumann.net


From murdoch.duncan at gmail.com  Wed Nov 12 20:28:16 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 12 Nov 2014 14:28:16 -0500
Subject: [Rd] Problem with  build and check
In-Reply-To: <58e5f6$jk252p@ironport9.mayo.edu>
References: <58e5f6$jk252p@ironport9.mayo.edu>
Message-ID: <5463B4D0.1090109@gmail.com>

On 12/11/2014 2:11 PM, Therneau, Terry M., Ph.D. wrote:
> I am getting failure of build and check, for an Rd file that has a long argument list.
> Guess diagnosis: a quoted string beyond a certain point in the argument list is fatal.

No, the problem is that % is a comment marker in .Rd.  You need to 
escape those in the dateformat default.  Apparently
prompt() doesn't know this...

Duncan Murdoch
>
> Example:  Use the function below, create an Rd file for it with prompt().  Move the .Rd
> file to the man directory (no need to edit it) and try building
>
> dart.control <- function(server=c("production", "integration", "development",
>                                     "http"),
>                            out.poll.duration = 5,
>                            out.poll.increase = 1.1,
>                            out.poll.max = 30,
>                            out.poll.timeout = 3600,
>                            netrc.path,
>                            netrc.server = "ldap",
>                            rtype = c("xml", "json"),
>                            dateformat= "%Y-%m-%d") {
>
>       server <- match.arg(server)
>       server
> }
>
> I created a package "dummy" with only this function, and get the following on my Linux box.
>
> tmt-local2021% R CMD build dummy
> * checking for file ?dummy/DESCRIPTION? ... OK
> * preparing ?dummy?:
> * checking DESCRIPTION meta-information ... OK
> Warning: newline within quoted string at dart.control.Rd:11
> Warning: /tmp/RtmpjPjz9V/Rbuild398d6e382572/dummy/man/dart.control.Rd:46: unexpected
> section header '\value'
> Warning: newline within quoted string at dart.control.Rd:11
> Error in parse_Rd("/tmp/RtmpjPjz9V/Rbuild398d6e382572/dummy/man/dart.control.Rd", :
>     Unexpected end of input (in " quoted string opened at dart.control.Rd:88:16)
> Execution halted
>
> Session info for my version
>   > sessionInfo()
> R Under development (unstable) (2014-10-30 r66907)
> Platform: i686-pc-linux-gnu (32-bit)
>
> locale:
>    [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>    [3] LC_TIME=en_US.UTF-8        LC_COLLATE=C
>    [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>    [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>    [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods base
>
>
> Terry T.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From wdunlap at tibco.com  Wed Nov 12 20:34:02 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 12 Nov 2014 11:34:02 -0800
Subject: [Rd] Problem with build and check
In-Reply-To: <58e5f6$jk252p@ironport9.mayo.edu>
References: <58e5f6$jk252p@ironport9.mayo.edu>
Message-ID: <CAF8bMcaXYkk_H3d6Jq+oGdYWN4Xqnr6P5QRA7bL=Tbfp=dCGNA@mail.gmail.com>

'Writing R Extensions', section 2.1 Rd format, says"

Comments run from a percent symbol % to the end of the line in all types of
text (as on the first line of the load example).

Because backslashes, braces and percent symbols have special meaning, to
enter them into text sometimes requires escapes using a backslash. In
general balanced braces do not need to be escaped, but percent symbols
always do. For the complete list of macros and rules for escapes, see ?Parsing
Rd files? <http://developer.r-project.org/parseRd.pdf>.




Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Wed, Nov 12, 2014 at 11:11 AM, Therneau, Terry M., Ph.D. <
therneau at mayo.edu> wrote:

> I am getting failure of build and check, for an Rd file that has a long
> argument list.
> Guess diagnosis: a quoted string beyond a certain point in the argument
> list is fatal.
>
> Example:  Use the function below, create an Rd file for it with prompt().
> Move the .Rd file to the man directory (no need to edit it) and try building
>
> dart.control <- function(server=c("production", "integration",
> "development",
>                                   "http"),
>                          out.poll.duration = 5,
>                          out.poll.increase = 1.1,
>                          out.poll.max = 30,
>                          out.poll.timeout = 3600,
>                          netrc.path,
>                          netrc.server = "ldap",
>                          rtype = c("xml", "json"),
>                          dateformat= "%Y-%m-%d") {
>
>     server <- match.arg(server)
>     server
> }
>
> I created a package "dummy" with only this function, and get the following
> on my Linux box.
>
> tmt-local2021% R CMD build dummy
> * checking for file ?dummy/DESCRIPTION? ... OK
> * preparing ?dummy?:
> * checking DESCRIPTION meta-information ... OK
> Warning: newline within quoted string at dart.control.Rd:11
> Warning: /tmp/RtmpjPjz9V/Rbuild398d6e382572/dummy/man/dart.control.Rd:46:
> unexpected section header '\value'
> Warning: newline within quoted string at dart.control.Rd:11
> Error in parse_Rd("/tmp/RtmpjPjz9V/Rbuild398d6e382572/dummy/man/dart.control.Rd",
> :
>   Unexpected end of input (in " quoted string opened at
> dart.control.Rd:88:16)
> Execution halted
>
> Session info for my version
> > sessionInfo()
> R Under development (unstable) (2014-10-30 r66907)
> Platform: i686-pc-linux-gnu (32-bit)
>
> locale:
>  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=C
>  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods base
>
>
> Terry T.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From josh.m.ulrich at gmail.com  Wed Nov 12 20:36:37 2014
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Wed, 12 Nov 2014 13:36:37 -0600
Subject: [Rd] Problem with build and check
In-Reply-To: <5463B4D0.1090109@gmail.com>
References: <58e5f6$jk252p@ironport9.mayo.edu> <5463B4D0.1090109@gmail.com>
Message-ID: <CAPPM_gSjDtU6ayYy+uWJhiU8rR8D4YVeLdEtF1KRegzU9pvvRg@mail.gmail.com>

On Wed, Nov 12, 2014 at 1:28 PM, Duncan Murdoch
<murdoch.duncan at gmail.com> wrote:
> On 12/11/2014 2:11 PM, Therneau, Terry M., Ph.D. wrote:
>>
>> I am getting failure of build and check, for an Rd file that has a long
>> argument list.
>> Guess diagnosis: a quoted string beyond a certain point in the argument
>> list is fatal.
>
>
> No, the problem is that % is a comment marker in .Rd.  You need to escape
> those in the dateformat default.  Apparently
> prompt() doesn't know this...
>
> Duncan Murdoch
>
prompt.default does add the escapes for the example section, but not
for the usage section.

>>
>> Example:  Use the function below, create an Rd file for it with prompt().
>> Move the .Rd
>> file to the man directory (no need to edit it) and try building
>>
>> dart.control <- function(server=c("production", "integration",
>> "development",
>>                                     "http"),
>>                            out.poll.duration = 5,
>>                            out.poll.increase = 1.1,
>>                            out.poll.max = 30,
>>                            out.poll.timeout = 3600,
>>                            netrc.path,
>>                            netrc.server = "ldap",
>>                            rtype = c("xml", "json"),
>>                            dateformat= "%Y-%m-%d") {
>>
>>       server <- match.arg(server)
>>       server
>> }
>>
>> I created a package "dummy" with only this function, and get the following
>> on my Linux box.
>>
>> tmt-local2021% R CMD build dummy
>> * checking for file ?dummy/DESCRIPTION? ... OK
>> * preparing ?dummy?:
>> * checking DESCRIPTION meta-information ... OK
>> Warning: newline within quoted string at dart.control.Rd:11
>> Warning: /tmp/RtmpjPjz9V/Rbuild398d6e382572/dummy/man/dart.control.Rd:46:
>> unexpected
>> section header '\value'
>> Warning: newline within quoted string at dart.control.Rd:11
>> Error in
>> parse_Rd("/tmp/RtmpjPjz9V/Rbuild398d6e382572/dummy/man/dart.control.Rd", :
>>     Unexpected end of input (in " quoted string opened at
>> dart.control.Rd:88:16)
>> Execution halted
>>
>> Session info for my version
>>   > sessionInfo()
>> R Under development (unstable) (2014-10-30 r66907)
>> Platform: i686-pc-linux-gnu (32-bit)
>>
>> locale:
>>    [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>>    [3] LC_TIME=en_US.UTF-8        LC_COLLATE=C
>>    [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>>    [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>>    [9] LC_ADDRESS=C               LC_TELEPHONE=C
>> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods base
>>
>>
>> Terry T.
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel



-- 
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com


From zhengda1936 at gmail.com  Wed Nov 12 21:54:19 2014
From: zhengda1936 at gmail.com (Zheng Da)
Date: Wed, 12 Nov 2014 15:54:19 -0500
Subject: [Rd] How to maintain memory in R extension
In-Reply-To: <5463A4F1.3090008@fredhutch.org>
References: <CAFLer80OKhvuH2BRuC3qdTFN-2Kg6MPzh0A24NNBs+JMbO-fvQ@mail.gmail.com>
	<5463A4F1.3090008@fredhutch.org>
Message-ID: <CAFLer82eg+4ibjLmhuVhe0BMe4_A+LhB10rJRYzzf7ABQYxW3g@mail.gmail.com>

Thank you, Gabor and Martin. It helps a lot.

Da

On Wed, Nov 12, 2014 at 1:20 PM, Martin Morgan <mtmorgan at fredhutch.org> wrote:
> On 11/12/2014 05:36 AM, Zheng Da wrote:
>>
>> Hello,
>>
>> I wrote a system to perform data analysis in C++. Now I am integrating
>> it to R. I need to allocate memory for my own C++ data structures,
>> which can't be represented by any R data structures. I create a global
>> hashtable to keep a reference to the C++ data structures. Whenever I
>> allocate one, I register it in the hashtable and return its key to the
>> R code. So later on, the R code can access the C++ data structures
>> with their keys.
>>
>> The problem is how to perform garbage collection on the C++ data
>> structures. Once an R object that contains the key is garbage
>> collected, the R code can no longer access the corresponding C++ data
>> structure, so I need to deallocate it. Is there any way that the C++
>> code can get notification when an R object gets garbage collected? If
>> not, what is the usual way to manage memory in R extensions?
>
>
> register a finalizer that runs when there are no longer references to the R
> object, see ?reg.finalizer or the interface to R and C finalizers in
> Rinternals.h. If you return more than one reference to a key, then of course
> you'll have to manage these in your own C++ code.
>
> Martin Morgan
>
>
>>
>> Thanks,
>> Da
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
>
> --
> Computational Biology / Fred Hutchinson Cancer Research Center
> 1100 Fairview Ave. N.
> PO Box 19024 Seattle, WA 98109
>
> Location: Arnold Building M1 B861
> Phone: (206) 667-2793


From hb at biostat.ucsf.edu  Wed Nov 12 22:56:27 2014
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Wed, 12 Nov 2014 13:56:27 -0800
Subject: [Rd] How to maintain memory in R extension
In-Reply-To: <5463A4F1.3090008@fredhutch.org>
References: <CAFLer80OKhvuH2BRuC3qdTFN-2Kg6MPzh0A24NNBs+JMbO-fvQ@mail.gmail.com>
	<5463A4F1.3090008@fredhutch.org>
Message-ID: <CAFDcVCTqipH+-d_csjsagetMSpc388AKHu3aN1wC9+v8FHQ8hA@mail.gmail.com>

On Wed, Nov 12, 2014 at 10:20 AM, Martin Morgan <mtmorgan at fredhutch.org> wrote:
> On 11/12/2014 05:36 AM, Zheng Da wrote:
>>
>> Hello,
>>
>> I wrote a system to perform data analysis in C++. Now I am integrating
>> it to R. I need to allocate memory for my own C++ data structures,
>> which can't be represented by any R data structures. I create a global
>> hashtable to keep a reference to the C++ data structures. Whenever I
>> allocate one, I register it in the hashtable and return its key to the
>> R code. So later on, the R code can access the C++ data structures
>> with their keys.
>>
>> The problem is how to perform garbage collection on the C++ data
>> structures. Once an R object that contains the key is garbage
>> collected, the R code can no longer access the corresponding C++ data
>> structure, so I need to deallocate it. Is there any way that the C++
>> code can get notification when an R object gets garbage collected? If
>> not, what is the usual way to manage memory in R extensions?
>
>
> register a finalizer that runs when there are no longer references to the R
> object, see ?reg.finalizer or the interface to R and C finalizers in
> Rinternals.h. If you return more than one reference to a key, then of course
> you'll have to manage these in your own C++ code.

A small but important addition: Make sure your registered finalizer
also works, or at least don't core dump R, if your package (or one of
its dependencies) happens be unloaded by the time the garbage
collector runs.  This task seems easy but can be quite tricky, e.g.
should you reload you package temporarily and what are the side
effects from doing that?

/Henrik

>
> Martin Morgan
>
>>
>> Thanks,
>> Da
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
>
> --
> Computational Biology / Fred Hutchinson Cancer Research Center
> 1100 Fairview Ave. N.
> PO Box 19024 Seattle, WA 98109
>
> Location: Arnold Building M1 B861
> Phone: (206) 667-2793
>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From Ross.Boylan at ucsf.edu  Thu Nov 13 04:05:24 2014
From: Ross.Boylan at ucsf.edu (Boylan, Ross)
Date: Thu, 13 Nov 2014 03:05:24 +0000
Subject: [Rd] Non-webby links on Windows web page
Message-ID: <F1F13E14A610474196571953929C020963D23B@ex08.net.ucsf.edu>

On the Windows download page the second link is "Installation and other instructions" http://cran.cnr.berkeley.edu/bin/windows/base/README.R-3.1.2.  Clicking on this gets me a "download or open as" dialogue rather than a page of text.

I think something like this happened a few years ago, and the problem was the MIME type of the link.

It would be nice to fix.

Thanks.
Ross Boylan

P.S. I was using http://cran.cnr.berkeley.edu/ and FF 33.1 on Win 7.


From jeroenooms at gmail.com  Thu Nov 13 05:58:17 2014
From: jeroenooms at gmail.com (Jeroen Ooms)
Date: Wed, 12 Nov 2014 20:58:17 -0800
Subject: [Rd] Non-webby links on Windows web page
In-Reply-To: <F1F13E14A610474196571953929C020963D23B@ex08.net.ucsf.edu>
References: <F1F13E14A610474196571953929C020963D23B@ex08.net.ucsf.edu>
Message-ID: <CABFfbXsJj-nTH-a1d35Zi=njpqgaEveuQwT4J4wg2ExLAuhZnw@mail.gmail.com>

This caused by the Berkeley web server setting strange content-types.
It is probably more suitable to report this to the Berkeley mirror
admin or cran maintainers.

> library(httr)
> GET("http://cran.cnr.berkeley.edu/bin/windows/base/README.R-3.1.2")$headers["content-type"]
$`content-type`
[1] "application/x-troff-man"

> GET("http://cran.r-project.org/bin/windows/base/README.R-3.1.2")$headers["content-type"]
$`content-type`
[1] "text/plain"




On Wed, Nov 12, 2014 at 7:05 PM, Boylan, Ross <Ross.Boylan at ucsf.edu> wrote:
> On the Windows download page the second link is "Installation and other instructions" http://cran.cnr.berkeley.edu/bin/windows/base/README.R-3.1.2.  Clicking on this gets me a "download or open as" dialogue rather than a page of text.
>
> I think something like this happened a few years ago, and the problem was the MIME type of the link.
>
> It would be nice to fix.
>
> Thanks.
> Ross Boylan
>
> P.S. I was using http://cran.cnr.berkeley.edu/ and FF 33.1 on Win 7.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From january.weiner at gmail.com  Thu Nov 13 12:09:47 2014
From: january.weiner at gmail.com (January Weiner)
Date: Thu, 13 Nov 2014 12:09:47 +0100
Subject: [Rd] Changing style for the Sweave vignettes
Message-ID: <CA+A1kV4FSFtUMDPME0_MEMM_orCX+U9jgUZ9m1_rT0-ftRE4Fg@mail.gmail.com>

As a user, I am always annoyed beyond measure that Sweave vignettes
precede the code by a command line prompt. It makes running examples
by simple copying of the commands from the vignette to the console a
pain. I know the idea is that it is clear what is the command, and
what is the output, but I'd rather precede the output with some kind
of marking.

Is there any other solution possible / allowed in vignettes? I would
much prefer to make my vignettes easier to use for people like me.

Kind regards,

j.

-- 
-------- January Weiner --------------------------------------


From sorenh at math.aau.dk  Thu Nov 13 12:16:36 2014
From: sorenh at math.aau.dk (=?iso-8859-1?Q?S=F8ren_H=F8jsgaard?=)
Date: Thu, 13 Nov 2014 11:16:36 +0000
Subject: [Rd] Changing style for the Sweave vignettes
In-Reply-To: <CA+A1kV4FSFtUMDPME0_MEMM_orCX+U9jgUZ9m1_rT0-ftRE4Fg@mail.gmail.com>
References: <CA+A1kV4FSFtUMDPME0_MEMM_orCX+U9jgUZ9m1_rT0-ftRE4Fg@mail.gmail.com>
Message-ID: <7E8037094A0C2146AA3E6F94DAE621C3A166667C@AD-EXCHMBX2-1.aau.dk>

Not sure if this is the right list for your question, but

options("prompt"="")

should do it.

Regards
S?ren

|-----Original Message-----
|From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-
|project.org] On Behalf Of January Weiner
|Sent: 13. november 2014 12:10
|To: r-devel
|Subject: [Rd] Changing style for the Sweave vignettes
|
|As a user, I am always annoyed beyond measure that Sweave vignettes
|precede the code by a command line prompt. It makes running examples by
|simple copying of the commands from the vignette to the console a pain. I
|know the idea is that it is clear what is the command, and what is the
|output, but I'd rather precede the output with some kind of marking.
|
|Is there any other solution possible / allowed in vignettes? I would much
|prefer to make my vignettes easier to use for people like me.
|
|Kind regards,
|
|j.
|
|--
|-------- January Weiner --------------------------------------
|
|______________________________________________
|R-devel at r-project.org mailing list
|https://stat.ethz.ch/mailman/listinfo/r-devel


From brian at braverock.com  Thu Nov 13 12:36:55 2014
From: brian at braverock.com (Brian G. Peterson)
Date: Thu, 13 Nov 2014 05:36:55 -0600
Subject: [Rd] Changing style for the Sweave vignettes
In-Reply-To: <CA+A1kV4FSFtUMDPME0_MEMM_orCX+U9jgUZ9m1_rT0-ftRE4Fg@mail.gmail.com>
References: <CA+A1kV4FSFtUMDPME0_MEMM_orCX+U9jgUZ9m1_rT0-ftRE4Fg@mail.gmail.com>
Message-ID: <546497D7.50009@braverock.com>

On 11/13/2014 05:09 AM, January Weiner wrote:
> As a user, I am always annoyed beyond measure that Sweave vignettes
> precede the code by a command line prompt. It makes running examples
> by simple copying of the commands from the vignette to the console a
> pain. I know the idea is that it is clear what is the command, and
> what is the output, but I'd rather precede the output with some kind
> of marking.
>
> Is there any other solution possible / allowed in vignettes? I would
> much prefer to make my vignettes easier to use for people like me.

I agree with S?ren that this is not the right list, but to complete the 
thread...

See the examples in

?vignette

start just above

## Now let us have a closer look at the code

All vignette's are compiled.  You can trivially extract all the code 
used for any vignette in R, including any code not displayed in the text 
and hidden from the user, from within R, or saved out to an editor so 
you can source it line by line from Rstudio (or vim or emacs or...). 
That's the whole point.

Regards,

Brian

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From january.weiner at gmail.com  Thu Nov 13 12:56:02 2014
From: january.weiner at gmail.com (January Weiner)
Date: Thu, 13 Nov 2014 12:56:02 +0100
Subject: [Rd] Changing style for the Sweave vignettes
In-Reply-To: <546497D7.50009@braverock.com>
References: <CA+A1kV4FSFtUMDPME0_MEMM_orCX+U9jgUZ9m1_rT0-ftRE4Fg@mail.gmail.com>
	<546497D7.50009@braverock.com>
Message-ID: <CA+A1kV5CGck2ucp+sjb9U6vpB0WkEry8QCeVS6oMX6dzOd_1Xg@mail.gmail.com>

Thank you, S?ren and Brian for your answers.

Whether this is the right list -- well, I think it is, since I am
developing a package and would like to create a vignette which is
useful and convenient for my users. I know how to extract the vignette
code. However, most of my users don't.  Or if they do, they do not
bother, but copy the examples from the PDF while they are reading it.
At least that is my observation.

I'm sorry that my e-mail was unclear -- I started my e-mail with "as a
user, ...", but I did mention that it is my vignettes that I am
concerned with.

options(prompt=...) is an idea, though I'm still not sure as to the
second part of my question - whether a vignette without a command
prompt is acceptable in a package or not.

Kind regards,

j.


On 13 November 2014 12:36, Brian G. Peterson <brian at braverock.com> wrote:
> On 11/13/2014 05:09 AM, January Weiner wrote:
>>
>> As a user, I am always annoyed beyond measure that Sweave vignettes
>> precede the code by a command line prompt. It makes running examples
>> by simple copying of the commands from the vignette to the console a
>> pain. I know the idea is that it is clear what is the command, and
>> what is the output, but I'd rather precede the output with some kind
>> of marking.
>>
>> Is there any other solution possible / allowed in vignettes? I would
>> much prefer to make my vignettes easier to use for people like me.
>
>
> I agree with S?ren that this is not the right list, but to complete the
> thread...
>
> See the examples in
>
> ?vignette
>
> start just above
>
> ## Now let us have a closer look at the code
>
> All vignette's are compiled.  You can trivially extract all the code used
> for any vignette in R, including any code not displayed in the text and
> hidden from the user, from within R, or saved out to an editor so you can
> source it line by line from Rstudio (or vim or emacs or...). That's the
> whole point.
>
> Regards,
>
> Brian
>
> --
> Brian G. Peterson
> http://braverock.com/brian/
> Ph: 773-459-4973
> IM: bgpbraverock
>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel



-- 
-------- January Weiner --------------------------------------


From mtmorgan at fredhutch.org  Thu Nov 13 13:25:02 2014
From: mtmorgan at fredhutch.org (Martin Morgan)
Date: Thu, 13 Nov 2014 04:25:02 -0800
Subject: [Rd] Changing style for the Sweave vignettes
In-Reply-To: <CA+A1kV4FSFtUMDPME0_MEMM_orCX+U9jgUZ9m1_rT0-ftRE4Fg@mail.gmail.com>
References: <CA+A1kV4FSFtUMDPME0_MEMM_orCX+U9jgUZ9m1_rT0-ftRE4Fg@mail.gmail.com>
Message-ID: <5464A31E.2030608@fredhutch.org>

On 11/13/2014 03:09 AM, January Weiner wrote:
> As a user, I am always annoyed beyond measure that Sweave vignettes
> precede the code by a command line prompt. It makes running examples
> by simple copying of the commands from the vignette to the console a
> pain. I know the idea is that it is clear what is the command, and
> what is the output, but I'd rather precede the output with some kind
> of marking.
>
> Is there any other solution possible / allowed in vignettes? I would
> much prefer to make my vignettes easier to use for people like me.

Vignettes do not need to be generated by Sweave and to pdf documents. My current 
favorite (e.g., recent course material at 
http://bioconductor.org/help/course-materials/ which uses styling from the 
BiocStyle package 
http://bioconductor.org/packages/release/bioc/html/BiocStyle.html) uses the 
knitr package (see http://yihui.name/knitr/) to produce HTML vignettes (knitr 
will also process Rnw files to pdf with perhaps more appealing styling, see, 
e.g.,  http://bit.ly/117OLVl for an example of PDF output).

The mechanics are discussed in Writing R Extensions (RShowDoc('R-exts')), 
section 1.4.2 Non-Sweave vignettes. There are three steps involved: specifying a 
\VignetteEngine in the vignette itself, specifying VignetteBuilder: field in the 
DESCRIPTION file, and including the package providing the engine (knitr, in my 
case) in the Suggests: field of the DESCRIPTION file.

Brian mentioned processing the vignette to it's underlying code; see 
?browseVignettes and ?vignette for installed packages, and ?Stangle in R and R 
CMD Stangle for extracting the R code from stand-alone vignettes to .R files.

Martin Morgan

>
> Kind regards,
>
> j.
>


-- 
Computational Biology / Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N.
PO Box 19024 Seattle, WA 98109

Location: Arnold Building M1 B861
Phone: (206) 667-2793


From pgilbert902 at gmail.com  Thu Nov 13 15:35:27 2014
From: pgilbert902 at gmail.com (Paul Gilbert)
Date: Thu, 13 Nov 2014 09:35:27 -0500
Subject: [Rd] Changing style for the Sweave vignettes
In-Reply-To: <CA+A1kV5CGck2ucp+sjb9U6vpB0WkEry8QCeVS6oMX6dzOd_1Xg@mail.gmail.com>
References: <CA+A1kV4FSFtUMDPME0_MEMM_orCX+U9jgUZ9m1_rT0-ftRE4Fg@mail.gmail.com>	<546497D7.50009@braverock.com>
	<CA+A1kV5CGck2ucp+sjb9U6vpB0WkEry8QCeVS6oMX6dzOd_1Xg@mail.gmail.com>
Message-ID: <5464C1AF.1000401@gmail.com>

You might also consider starting your vignettes with

\begin{Scode}{echo=FALSE,results=hide}
  options(continue="  ")
\end{Scode}

Then you get one prompt but it is still easy to cut and paste. This has 
been in many of my packages for many years, so I think it would be fair 
to assume it is acceptable.

Paul

On 11/13/2014 06:56 AM, January Weiner wrote:
> Thank you, S?ren and Brian for your answers.
>
> Whether this is the right list -- well, I think it is, since I am
> developing a package and would like to create a vignette which is
> useful and convenient for my users. I know how to extract the vignette
> code. However, most of my users don't.  Or if they do, they do not
> bother, but copy the examples from the PDF while they are reading it.
> At least that is my observation.
>
> I'm sorry that my e-mail was unclear -- I started my e-mail with "as a
> user, ...", but I did mention that it is my vignettes that I am
> concerned with.
>
> options(prompt=...) is an idea, though I'm still not sure as to the
> second part of my question - whether a vignette without a command
> prompt is acceptable in a package or not.
>
> Kind regards,
>
> j.
>
>
> On 13 November 2014 12:36, Brian G. Peterson <brian at braverock.com> wrote:
>> On 11/13/2014 05:09 AM, January Weiner wrote:
>>>
>>> As a user, I am always annoyed beyond measure that Sweave vignettes
>>> precede the code by a command line prompt. It makes running examples
>>> by simple copying of the commands from the vignette to the console a
>>> pain. I know the idea is that it is clear what is the command, and
>>> what is the output, but I'd rather precede the output with some kind
>>> of marking.
>>>
>>> Is there any other solution possible / allowed in vignettes? I would
>>> much prefer to make my vignettes easier to use for people like me.
>>
>>
>> I agree with S?ren that this is not the right list, but to complete the
>> thread...
>>
>> See the examples in
>>
>> ?vignette
>>
>> start just above
>>
>> ## Now let us have a closer look at the code
>>
>> All vignette's are compiled.  You can trivially extract all the code used
>> for any vignette in R, including any code not displayed in the text and
>> hidden from the user, from within R, or saved out to an editor so you can
>> source it line by line from Rstudio (or vim or emacs or...). That's the
>> whole point.
>>
>> Regards,
>>
>> Brian
>>
>> --
>> Brian G. Peterson
>> http://braverock.com/brian/
>> Ph: 773-459-4973
>> IM: bgpbraverock
>>
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>
>


From murdoch.duncan at gmail.com  Thu Nov 13 15:46:03 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 13 Nov 2014 09:46:03 -0500
Subject: [Rd] Problem with build and check
In-Reply-To: <CAPPM_gSjDtU6ayYy+uWJhiU8rR8D4YVeLdEtF1KRegzU9pvvRg@mail.gmail.com>
References: <58e5f6$jk252p@ironport9.mayo.edu> <5463B4D0.1090109@gmail.com>
	<CAPPM_gSjDtU6ayYy+uWJhiU8rR8D4YVeLdEtF1KRegzU9pvvRg@mail.gmail.com>
Message-ID: <5464C42B.9050100@gmail.com>

On 12/11/2014 2:36 PM, Joshua Ulrich wrote:
> On Wed, Nov 12, 2014 at 1:28 PM, Duncan Murdoch
> <murdoch.duncan at gmail.com> wrote:
> > On 12/11/2014 2:11 PM, Therneau, Terry M., Ph.D. wrote:
> >>
> >> I am getting failure of build and check, for an Rd file that has a long
> >> argument list.
> >> Guess diagnosis: a quoted string beyond a certain point in the argument
> >> list is fatal.
> >
> >
> > No, the problem is that % is a comment marker in .Rd.  You need to escape
> > those in the dateformat default.  Apparently
> > prompt() doesn't know this...
> >
> > Duncan Murdoch
> >
> prompt.default does add the escapes for the example section, but not
> for the usage section.

Yes, that was the problem.  Now fixed in R-devel, soon in R-patched.

Duncan Murdoch
>
> >>
> >> Example:  Use the function below, create an Rd file for it with prompt().
> >> Move the .Rd
> >> file to the man directory (no need to edit it) and try building
> >>
> >> dart.control <- function(server=c("production", "integration",
> >> "development",
> >>                                     "http"),
> >>                            out.poll.duration = 5,
> >>                            out.poll.increase = 1.1,
> >>                            out.poll.max = 30,
> >>                            out.poll.timeout = 3600,
> >>                            netrc.path,
> >>                            netrc.server = "ldap",
> >>                            rtype = c("xml", "json"),
> >>                            dateformat= "%Y-%m-%d") {
> >>
> >>       server <- match.arg(server)
> >>       server
> >> }
> >>
> >> I created a package "dummy" with only this function, and get the following
> >> on my Linux box.
> >>
> >> tmt-local2021% R CMD build dummy
> >> * checking for file ?dummy/DESCRIPTION? ... OK
> >> * preparing ?dummy?:
> >> * checking DESCRIPTION meta-information ... OK
> >> Warning: newline within quoted string at dart.control.Rd:11
> >> Warning: /tmp/RtmpjPjz9V/Rbuild398d6e382572/dummy/man/dart.control.Rd:46:
> >> unexpected
> >> section header '\value'
> >> Warning: newline within quoted string at dart.control.Rd:11
> >> Error in
> >> parse_Rd("/tmp/RtmpjPjz9V/Rbuild398d6e382572/dummy/man/dart.control.Rd", :
> >>     Unexpected end of input (in " quoted string opened at
> >> dart.control.Rd:88:16)
> >> Execution halted
> >>
> >> Session info for my version
> >>   > sessionInfo()
> >> R Under development (unstable) (2014-10-30 r66907)
> >> Platform: i686-pc-linux-gnu (32-bit)
> >>
> >> locale:
> >>    [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
> >>    [3] LC_TIME=en_US.UTF-8        LC_COLLATE=C
> >>    [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
> >>    [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
> >>    [9] LC_ADDRESS=C               LC_TELEPHONE=C
> >> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
> >>
> >> attached base packages:
> >> [1] stats     graphics  grDevices utils     datasets  methods base
> >>
> >>
> >> Terry T.
> >>
> >> ______________________________________________
> >> R-devel at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-devel
> >
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
>
>
>


From january.weiner at gmail.com  Thu Nov 13 17:10:23 2014
From: january.weiner at gmail.com (January Weiner)
Date: Thu, 13 Nov 2014 17:10:23 +0100
Subject: [Rd] Changing style for the Sweave vignettes
In-Reply-To: <5464C1AF.1000401@gmail.com>
References: <CA+A1kV4FSFtUMDPME0_MEMM_orCX+U9jgUZ9m1_rT0-ftRE4Fg@mail.gmail.com>
	<546497D7.50009@braverock.com>
	<CA+A1kV5CGck2ucp+sjb9U6vpB0WkEry8QCeVS6oMX6dzOd_1Xg@mail.gmail.com>
	<5464C1AF.1000401@gmail.com>
Message-ID: <CA+A1kV5jtNnrQn2dNH8-OGBGNcqjMjkPY6OO0Bf+q2odkfWfmQ@mail.gmail.com>

Dear Paul and Martin,

thanks for the useful tips. I'll start with Paul's suggestion (getting
rid of these '+'-es will already be a boon!), and move from my old
Sweave vignettes when possible.

Thank you!
j.

On 13 November 2014 15:35, Paul Gilbert <pgilbert902 at gmail.com> wrote:
> You might also consider starting your vignettes with
>
> \begin{Scode}{echo=FALSE,results=hide}
>  options(continue="  ")
> \end{Scode}
>
> Then you get one prompt but it is still easy to cut and paste. This has been
> in many of my packages for many years, so I think it would be fair to assume
> it is acceptable.
>
> Paul
>
>
> On 11/13/2014 06:56 AM, January Weiner wrote:
>>
>> Thank you, S?ren and Brian for your answers.
>>
>> Whether this is the right list -- well, I think it is, since I am
>> developing a package and would like to create a vignette which is
>> useful and convenient for my users. I know how to extract the vignette
>> code. However, most of my users don't.  Or if they do, they do not
>> bother, but copy the examples from the PDF while they are reading it.
>> At least that is my observation.
>>
>> I'm sorry that my e-mail was unclear -- I started my e-mail with "as a
>> user, ...", but I did mention that it is my vignettes that I am
>> concerned with.
>>
>> options(prompt=...) is an idea, though I'm still not sure as to the
>> second part of my question - whether a vignette without a command
>> prompt is acceptable in a package or not.
>>
>> Kind regards,
>>
>> j.
>>
>>
>> On 13 November 2014 12:36, Brian G. Peterson <brian at braverock.com> wrote:
>>>
>>> On 11/13/2014 05:09 AM, January Weiner wrote:
>>>>
>>>>
>>>> As a user, I am always annoyed beyond measure that Sweave vignettes
>>>> precede the code by a command line prompt. It makes running examples
>>>> by simple copying of the commands from the vignette to the console a
>>>> pain. I know the idea is that it is clear what is the command, and
>>>> what is the output, but I'd rather precede the output with some kind
>>>> of marking.
>>>>
>>>> Is there any other solution possible / allowed in vignettes? I would
>>>> much prefer to make my vignettes easier to use for people like me.
>>>
>>>
>>>
>>> I agree with S?ren that this is not the right list, but to complete the
>>> thread...
>>>
>>> See the examples in
>>>
>>> ?vignette
>>>
>>> start just above
>>>
>>> ## Now let us have a closer look at the code
>>>
>>> All vignette's are compiled.  You can trivially extract all the code used
>>> for any vignette in R, including any code not displayed in the text and
>>> hidden from the user, from within R, or saved out to an editor so you can
>>> source it line by line from Rstudio (or vim or emacs or...). That's the
>>> whole point.
>>>
>>> Regards,
>>>
>>> Brian
>>>
>>> --
>>> Brian G. Peterson
>>> http://braverock.com/brian/
>>> Ph: 773-459-4973
>>> IM: bgpbraverock
>>>
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>>
>>
>



-- 
-------- January Weiner --------------------------------------


From xie at yihui.name  Thu Nov 13 17:58:20 2014
From: xie at yihui.name (Yihui Xie)
Date: Thu, 13 Nov 2014 10:58:20 -0600
Subject: [Rd] Changing style for the Sweave vignettes
In-Reply-To: <CA+A1kV5jtNnrQn2dNH8-OGBGNcqjMjkPY6OO0Bf+q2odkfWfmQ@mail.gmail.com>
References: <CA+A1kV4FSFtUMDPME0_MEMM_orCX+U9jgUZ9m1_rT0-ftRE4Fg@mail.gmail.com>
	<546497D7.50009@braverock.com>
	<CA+A1kV5CGck2ucp+sjb9U6vpB0WkEry8QCeVS6oMX6dzOd_1Xg@mail.gmail.com>
	<5464C1AF.1000401@gmail.com>
	<CA+A1kV5jtNnrQn2dNH8-OGBGNcqjMjkPY6OO0Bf+q2odkfWfmQ@mail.gmail.com>
Message-ID: <CANROs4fi+H_bHdSKtXOom59gsn=LVWzTNUsCgKjsfs_VK=BTEw@mail.gmail.com>

As someone who was also annoyed by command line prompts a couple of
years ago, I wrote knitr and removed prompts as well as the
continuation characters (+) by default (FAQ5:
https://github.com/yihui/knitr/blob/master/FAQ.md).

BTW, I do not always trust copying text from PDF. Perhaps it is fine
for code/text in verbatim environments (as Paul indicated above).
LaTeX users are probably aware of ligatures (e.g. for "ff") and the
fact that leading/trailing white spaces are often removed in the PDF
output, which will make "What You Copy is Not What You Get".
Personally I think HTML is more reliable in this respect (<pre></pre>
is more faithful), and this is one of the reasons that I'm in favor of
HTML vignettes instead of PDF when I do not care that much about
precise typesetting (which is not always the most important thing).

Regards,
Yihui
--
Yihui Xie <xieyihui at gmail.com>
Web: http://yihui.name


On Thu, Nov 13, 2014 at 10:10 AM, January Weiner
<january.weiner at gmail.com> wrote:
> Dear Paul and Martin,
>
> thanks for the useful tips. I'll start with Paul's suggestion (getting
> rid of these '+'-es will already be a boon!), and move from my old
> Sweave vignettes when possible.
>
> Thank you!
> j.
>
> On 13 November 2014 15:35, Paul Gilbert <pgilbert902 at gmail.com> wrote:
>> You might also consider starting your vignettes with
>>
>> \begin{Scode}{echo=FALSE,results=hide}
>>  options(continue="  ")
>> \end{Scode}
>>
>> Then you get one prompt but it is still easy to cut and paste. This has been
>> in many of my packages for many years, so I think it would be fair to assume
>> it is acceptable.
>>
>> Paul
>>
>>
>> On 11/13/2014 06:56 AM, January Weiner wrote:
>>>
>>> Thank you, S?ren and Brian for your answers.
>>>
>>> Whether this is the right list -- well, I think it is, since I am
>>> developing a package and would like to create a vignette which is
>>> useful and convenient for my users. I know how to extract the vignette
>>> code. However, most of my users don't.  Or if they do, they do not
>>> bother, but copy the examples from the PDF while they are reading it.
>>> At least that is my observation.
>>>
>>> I'm sorry that my e-mail was unclear -- I started my e-mail with "as a
>>> user, ...", but I did mention that it is my vignettes that I am
>>> concerned with.
>>>
>>> options(prompt=...) is an idea, though I'm still not sure as to the
>>> second part of my question - whether a vignette without a command
>>> prompt is acceptable in a package or not.
>>>
>>> Kind regards,
>>>
>>> j.
>>>
>>>
>>> On 13 November 2014 12:36, Brian G. Peterson <brian at braverock.com> wrote:
>>>>
>>>> On 11/13/2014 05:09 AM, January Weiner wrote:
>>>>>
>>>>>
>>>>> As a user, I am always annoyed beyond measure that Sweave vignettes
>>>>> precede the code by a command line prompt. It makes running examples
>>>>> by simple copying of the commands from the vignette to the console a
>>>>> pain. I know the idea is that it is clear what is the command, and
>>>>> what is the output, but I'd rather precede the output with some kind
>>>>> of marking.
>>>>>
>>>>> Is there any other solution possible / allowed in vignettes? I would
>>>>> much prefer to make my vignettes easier to use for people like me.
>>>>
>>>>
>>>>
>>>> I agree with S?ren that this is not the right list, but to complete the
>>>> thread...
>>>>
>>>> See the examples in
>>>>
>>>> ?vignette
>>>>
>>>> start just above
>>>>
>>>> ## Now let us have a closer look at the code
>>>>
>>>> All vignette's are compiled.  You can trivially extract all the code used
>>>> for any vignette in R, including any code not displayed in the text and
>>>> hidden from the user, from within R, or saved out to an editor so you can
>>>> source it line by line from Rstudio (or vim or emacs or...). That's the
>>>> whole point.
>>>>
>>>> Regards,
>>>>
>>>> Brian
>>>>
>>>> --
>>>> Brian G. Peterson
>>>> http://braverock.com/brian/
>>>> Ph: 773-459-4973
>>>> IM: bgpbraverock


From Ross.Boylan at ucsf.edu  Thu Nov 13 21:20:35 2014
From: Ross.Boylan at ucsf.edu (Boylan, Ross)
Date: Thu, 13 Nov 2014 20:20:35 +0000
Subject: [Rd] Non-webby links on Windows web page
In-Reply-To: <CABFfbXsJj-nTH-a1d35Zi=njpqgaEveuQwT4J4wg2ExLAuhZnw@mail.gmail.com>
References: <F1F13E14A610474196571953929C020963D23B@ex08.net.ucsf.edu>,
	<CABFfbXsJj-nTH-a1d35Zi=njpqgaEveuQwT4J4wg2ExLAuhZnw@mail.gmail.com>
Message-ID: <F1F13E14A610474196571953929C020963D6F1@ex08.net.ucsf.edu>

Thanks for the detective work.  I'm a little surprised all the mirrors aren't configured the same.

Maybe it should be a little easier to figure out how to contact the maintainers of a particular site.

At the bottom of the front page are links to 2 organization; picking the most specific led to a general welcome page.  It had a contact llink at the bottom, which led to a page that had an IT contact on it, cnrit at berkeley.edu. I'll try sending it there with a cc to cran at r-project.org, which I found chasing another set of links.

Ross
________________________________________
From: Jeroen Ooms [jeroenooms at gmail.com]
Sent: Wednesday, November 12, 2014 8:58 PM
To: Boylan, Ross
Cc: r-devel at r-project.org
Subject: Re: [Rd] Non-webby links on Windows web page

This caused by the Berkeley web server setting strange content-types.
It is probably more suitable to report this to the Berkeley mirror
admin or cran maintainers.

> library(httr)
> GET("http://cran.cnr.berkeley.edu/bin/windows/base/README.R-3.1.2")$headers["content-type"]
$`content-type`
[1] "application/x-troff-man"

> GET("http://cran.r-project.org/bin/windows/base/README.R-3.1.2")$headers["content-type"]
$`content-type`
[1] "text/plain"




On Wed, Nov 12, 2014 at 7:05 PM, Boylan, Ross <Ross.Boylan at ucsf.edu> wrote:
> On the Windows download page the second link is "Installation and other instructions" http://cran.cnr.berkeley.edu/bin/windows/base/README.R-3.1.2.  Clicking on this gets me a "download or open as" dialogue rather than a page of text.
>
> I think something like this happened a few years ago, and the problem was the MIME type of the link.
>
> It would be nice to fix.
>
> Thanks.
> Ross Boylan
>
> P.S. I was using http://cran.cnr.berkeley.edu/ and FF 33.1 on Win 7.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From winstonchang1 at gmail.com  Thu Nov 13 23:01:17 2014
From: winstonchang1 at gmail.com (Winston Chang)
Date: Thu, 13 Nov 2014 16:01:17 -0600
Subject: [Rd] Non-webby links on Windows web page
In-Reply-To: <F1F13E14A610474196571953929C020963D6F1@ex08.net.ucsf.edu>
References: <F1F13E14A610474196571953929C020963D23B@ex08.net.ucsf.edu>
	<CABFfbXsJj-nTH-a1d35Zi=njpqgaEveuQwT4J4wg2ExLAuhZnw@mail.gmail.com>
	<F1F13E14A610474196571953929C020963D6F1@ex08.net.ucsf.edu>
Message-ID: <CAFOpNVFdg4Gv6GisHm8CAQ9q=d9AovQq5EkiVstr_F1d7SSKXA@mail.gmail.com>

I agree that it would be nice to have mirrors configured the same.
Several weeks ago, there was a change to the .htaccess file at the top
level of the CRAN repository which brought down RStudio mirror, since
the .htaccess file used an Apache module that wasn't installed on the
RStudio mirror.

A really nice way to do this would be to have an official CRAN mirror
Docker image with the proper Linux distro + Apache configuration. Then
to set up a mirror, all you'd need to do is to set up rsyncing of the
contents of the central CRAN repo, and then do `docker pull` and then
`docker run` (with a few more command line arguments). Even the rsync
could be done within a docker container, so you'd run two containers
that share a volume: one container for syncing, and one container for
the web server.

-Winston

On Thu, Nov 13, 2014 at 2:20 PM, Boylan, Ross <Ross.Boylan at ucsf.edu> wrote:
> Thanks for the detective work.  I'm a little surprised all the mirrors aren't configured the same.
>
> Maybe it should be a little easier to figure out how to contact the maintainers of a particular site.
>
> At the bottom of the front page are links to 2 organization; picking the most specific led to a general welcome page.  It had a contact llink at the bottom, which led to a page that had an IT contact on it, cnrit at berkeley.edu. I'll try sending it there with a cc to cran at r-project.org, which I found chasing another set of links.
>
> Ross
> ________________________________________
> From: Jeroen Ooms [jeroenooms at gmail.com]
> Sent: Wednesday, November 12, 2014 8:58 PM
> To: Boylan, Ross
> Cc: r-devel at r-project.org
> Subject: Re: [Rd] Non-webby links on Windows web page
>
> This caused by the Berkeley web server setting strange content-types.
> It is probably more suitable to report this to the Berkeley mirror
> admin or cran maintainers.
>
>> library(httr)
>> GET("http://cran.cnr.berkeley.edu/bin/windows/base/README.R-3.1.2")$headers["content-type"]
> $`content-type`
> [1] "application/x-troff-man"
>
>> GET("http://cran.r-project.org/bin/windows/base/README.R-3.1.2")$headers["content-type"]
> $`content-type`
> [1] "text/plain"
>
>
>
>
> On Wed, Nov 12, 2014 at 7:05 PM, Boylan, Ross <Ross.Boylan at ucsf.edu> wrote:
>> On the Windows download page the second link is "Installation and other instructions" http://cran.cnr.berkeley.edu/bin/windows/base/README.R-3.1.2.  Clicking on this gets me a "download or open as" dialogue rather than a page of text.
>>
>> I think something like this happened a few years ago, and the problem was the MIME type of the link.
>>
>> It would be nice to fix.
>>
>> Thanks.
>> Ross Boylan
>>
>> P.S. I was using http://cran.cnr.berkeley.edu/ and FF 33.1 on Win 7.
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From john.maindonald at anu.edu.au  Fri Nov 14 00:13:37 2014
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Thu, 13 Nov 2014 23:13:37 +0000
Subject: [Rd] Correction in help(factanal)
Message-ID: <4B6A3570-97BB-4907-B5CE-A073CBA0DDE3@anu.edu.au>

<<<
Thus factor analysis is in essence a model for the correlation matrix of x,

? = ?'? + ?
>>>

This should surely be ? = ??' + ?

Also line 3 under ?Details? says
<<<
for a p?element row-vector x, ?
>>>

x is here surely a column vector, albeit the transpose of a row vector
from the data matrix.

cf page 322 of ?Modern Applied Statistics with S?, 4th edn.

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.



From pdalgd at gmail.com  Fri Nov 14 10:09:26 2014
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 14 Nov 2014 10:09:26 +0100
Subject: [Rd] Correction in help(factanal)
In-Reply-To: <4B6A3570-97BB-4907-B5CE-A073CBA0DDE3@anu.edu.au>
References: <4B6A3570-97BB-4907-B5CE-A073CBA0DDE3@anu.edu.au>
Message-ID: <78326C1D-3288-4E8C-9871-A77928579E84@gmail.com>

Right. (Well, I suppose that you could transpose x and Lambda, but then it would have to be  x = f Lambda + epsilon and all the dimensions would be wrong.)

I'll fix this in R-devel.

-pd

> On 14 Nov 2014, at 00:13 , John Maindonald <john.maindonald at anu.edu.au> wrote:
> 
> <<<
> Thus factor analysis is in essence a model for the correlation matrix of x,
> 
> ? = ?'? + ?
>>>> 
> 
> This should surely be ? = ??' + ?
> 
> Also line 3 under ?Details? says
> <<<
> for a p?element row-vector x, ?
>>>> 
> 
> x is here surely a column vector, albeit the transpose of a row vector
> from the data matrix.
> 
> cf page 322 of ?Modern Applied Statistics with S?, 4th edn.
> 
> John Maindonald             email: john.maindonald at anu.edu.au
> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
> Centre for Mathematics & Its Applications, Room 1194,
> John Dedman Mathematical Sciences Building (Building 27)
> Australian National University, Canberra ACT 0200.
> 
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From pdalgd at gmail.com  Fri Nov 14 11:55:43 2014
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 14 Nov 2014 11:55:43 +0100
Subject: [Rd] Correction in help(factanal)
In-Reply-To: <78326C1D-3288-4E8C-9871-A77928579E84@gmail.com>
References: <4B6A3570-97BB-4907-B5CE-A073CBA0DDE3@anu.edu.au>
	<78326C1D-3288-4E8C-9871-A77928579E84@gmail.com>
Message-ID: <749C55F7-DCDD-4978-ADFD-8EFB17E51C21@gmail.com>

Done. Actually, I just dropped the row-vector bit. Doesn't seem necessary and the "column vectors stored as matrix rows" issue is (a) well-known and (b) generic to multivariate methods. 

> On 14 Nov 2014, at 10:09 , peter dalgaard <pdalgd at gmail.com> wrote:
> 
> Right. (Well, I suppose that you could transpose x and Lambda, but then it would have to be  x = f Lambda + epsilon and all the dimensions would be wrong.)
> 
> I'll fix this in R-devel.
> 
> -pd
> 
>> On 14 Nov 2014, at 00:13 , John Maindonald <john.maindonald at anu.edu.au> wrote:
>> 
>> <<<
>> Thus factor analysis is in essence a model for the correlation matrix of x,
>> 
>> ? = ?'? + ?
>>>>> 
>> 
>> This should surely be ? = ??' + ?
>> 
>> Also line 3 under ?Details? says
>> <<<
>> for a p?element row-vector x, ?
>>>>> 
>> 
>> x is here surely a column vector, albeit the transpose of a row vector
>> from the data matrix.
>> 
>> cf page 322 of ?Modern Applied Statistics with S?, 4th edn.
>> 
>> John Maindonald             email: john.maindonald at anu.edu.au
>> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
>> Centre for Mathematics & Its Applications, Room 1194,
>> John Dedman Mathematical Sciences Building (Building 27)
>> Australian National University, Canberra ACT 0200.
>> 
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> -- 
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
> 
> 
> 
> 
> 
> 
> 
> 

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From smyth at wehi.EDU.AU  Fri Nov 14 12:26:40 2014
From: smyth at wehi.EDU.AU (Gordon K Smyth)
Date: Fri, 14 Nov 2014 22:26:40 +1100 (AUS Eastern Daylight Time)
Subject: [Rd] Changing style for the Sweave vignettes
In-Reply-To: <mailman.17.1415962806.473.r-devel@r-project.org>
References: <mailman.17.1415962806.473.r-devel@r-project.org>
Message-ID: <Pine.WNT.4.64.1411142211580.3564@PC975.wehi.edu.au>

> Date: Thu, 13 Nov 2014 12:09:47 +0100
> From: January Weiner <january.weiner at gmail.com>
> To: r-devel <r-devel at r-project.org>
> Subject: [Rd] Changing style for the Sweave vignettes
>
> As a user, I am always annoyed beyond measure that Sweave vignettes
> precede the code by a command line prompt. It makes running examples
> by simple copying of the commands from the vignette to the console a
> pain. I know the idea is that it is clear what is the command, and
> what is the output, but I'd rather precede the output with some kind
> of marking.
>
> Is there any other solution possible / allowed in vignettes? I would
> much prefer to make my vignettes easier to use for people like me.
>
> Kind regards,
> j.

There are different types of people, and some find the default Sweave 
format easier.

For a beginner, it is best that the code and output should look the same 
in the Sweave vignette as it would look on the screen during an actual 
session.

Windows users have access to "paste commands only".  For them the default 
Sweave vignette format is perfectly convenient -- one can easily cut and 
paste whole pages straight from pdf into the R session.

Perhaps a "paste commands only" app for Unix would keep everyone happy :)

Gordon

______________________________________________________________________
The information in this email is confidential and intend...{{dropped:4}}


From hb at biostat.ucsf.edu  Sat Nov 15 03:06:02 2014
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Fri, 14 Nov 2014 18:06:02 -0800
Subject: [Rd] Error "promise already under evaluation ..." with function(x,
	dim=dim(x))
Message-ID: <CAFDcVCQtz0HMknNVv16jYatLwk26EhtayKmE7-jzbt-sRyS6CA@mail.gmail.com>

I've meant to ask the following for several years now.  I understand why:

> foo <- function(x, dim=dim) { dim }
> foo(1)
Error in foo(1) :
  promise already under evaluation: recursive default argument
reference or earlier problems?

gives an error, but why wouldn't/couldn't the following work?

> foo <- function(x, dim=dim(x)) { dim }
> foo(1)
Error in foo(1) :
  promise already under evaluation: recursive default argument
reference or earlier problems?

As a workaround I also tried:

> foo <- function(x, dim) { if (missing(dim)) dim <- dim(x); dim }
> foo(1)
Error in foo(1) : argument "dim" is missing, with no default

which surprised me too.


For the first case, is the rationale related to:

> foo <- function(x, a=dim(x), dim) { a }
> foo(1)
Error in foo(1) : argument "dim" is missing, with no default

and

> foo <- function(x, a=dim(x), dim=a) { a }
> foo(1)
Error in foo(1) :
  promise already under evaluation: recursive default argument
reference or earlier problems?

[since here argument 'dim' could take a function, e.g. foo(1,
dim=length)], and that R treats

foo <- function(x, dim=dim(x)) { dim }

in a similar way?  That is, is R not "clever" enough to detect this as
a special case, but instead goes ahead and tries to evaluate the
default expression (=dim(x)) of argument 'dim' in order to get its
default value?  If so, is there anything preventing R from support
this "special case", e.g. by evaluating the default expression without
argument/symbol 'dim' itself being in the picture to avoid "it finds
itself"?  (Sorry if I'm using the incorrect words here).


Yes, I understand that I can do:

> foo <- function(x, dim=base::dim(x)) { dim }
> foo(1)
NULL

> foo <- function(x, dim=NULL) { if (is.null(dim)) dim <- dim(x); dim }
> foo(1)
NULL

or

> foo <- function(x, dim.=dim(x)) { dim. }
> foo(1)
NULL

but I would prefer not to have to turn those rather ad hoc solutions in my code.


Thanks,

Henrik


From hb at biostat.ucsf.edu  Sat Nov 15 03:57:48 2014
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Fri, 14 Nov 2014 18:57:48 -0800
Subject: [Rd] Code tools for identifying which package A functions package B
	use?
Message-ID: <CAFDcVCQeSbJ29+Ou7szGFj=b1WiOr6junuyarW3oF7z3L1uT9g@mail.gmail.com>

Hi,

I'd like to list all package PkgA functions that another package PkgB
use via Depends or Imports (ignoring Suggests for simplicity).  As
long as PkgB uses importFrom("PkgA", ...) it's just a matter of
parsing the NAMESPACE file or inspecting
asNamespace("PkgB")$.__NAMESPACE__.$imports.  However, what can be
done in case PkgB uses import("PkgA")?  Is there a function/package
already available for this?

Thanks,

Henrik


From kasperdanielhansen at gmail.com  Sat Nov 15 05:41:49 2014
From: kasperdanielhansen at gmail.com (Kasper Daniel Hansen)
Date: Fri, 14 Nov 2014 23:41:49 -0500
Subject: [Rd] Code tools for identifying which package A functions
 package B use?
In-Reply-To: <CAFDcVCQeSbJ29+Ou7szGFj=b1WiOr6junuyarW3oF7z3L1uT9g@mail.gmail.com>
References: <CAFDcVCQeSbJ29+Ou7szGFj=b1WiOr6junuyarW3oF7z3L1uT9g@mail.gmail.com>
Message-ID: <CAC2h7uutj2bg6676GXAX19j1-VrpRm5Zj76zjYOhXJ1iw4a9JA@mail.gmail.com>

The best thing I have found is codetoolsBioC in the Bioconductor subversion
repository.

Best,
Kasper

On Fri, Nov 14, 2014 at 9:57 PM, Henrik Bengtsson <hb at biostat.ucsf.edu>
wrote:

> Hi,
>
> I'd like to list all package PkgA functions that another package PkgB
> use via Depends or Imports (ignoring Suggests for simplicity).  As
> long as PkgB uses importFrom("PkgA", ...) it's just a matter of
> parsing the NAMESPACE file or inspecting
> asNamespace("PkgB")$.__NAMESPACE__.$imports.  However, what can be
> done in case PkgB uses import("PkgA")?  Is there a function/package
> already available for this?
>
> Thanks,
>
> Henrik
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From hb at biostat.ucsf.edu  Sat Nov 15 06:49:37 2014
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Fri, 14 Nov 2014 21:49:37 -0800
Subject: [Rd] Code tools for identifying which package A functions
 package B use?
In-Reply-To: <CAC2h7uutj2bg6676GXAX19j1-VrpRm5Zj76zjYOhXJ1iw4a9JA@mail.gmail.com>
References: <CAFDcVCQeSbJ29+Ou7szGFj=b1WiOr6junuyarW3oF7z3L1uT9g@mail.gmail.com>
	<CAC2h7uutj2bg6676GXAX19j1-VrpRm5Zj76zjYOhXJ1iw4a9JA@mail.gmail.com>
Message-ID: <CAFDcVCQRACa4cLaCJa=rDJy5gCbxA77Z_BRZGfvCztqp=dx9kQ@mail.gmail.com>

Thanks Kasper, that seems to do it:

$ url=https://hedgehog.fhcrc.org/bioconductor/trunk/madman/Rpacks/codetoolsBioC
$ svn checkout --username readonly --password readonly $url
$ R CMD build codetoolsBioC
$ R CMD INSTALL codetoolsBioC
$ R

> library("codetoolsBioC")
> deps <- findExternalDeps("MASS")
attaching required packages 'MASS'
Loading required package: MASS
> str(deps)
List of 4
 $ S4Classes: list()
 $ S4Methods:List of 1
  ..$ methods: chr "body<-"
 $ functions:List of 5
  ..$ base     : chr [1:248] "-" "!" "!=" "$" ...
  ..$ graphics : chr [1:16] "abline" "axis" "box" "frame" ...
  ..$ grDevices: chr [1:5] "dev.flush" "dev.hold" "nclass.FD" ...
  ..$ methods  : chr "new"
  ..$ stats    : chr [1:97] ".checkMFClasses" ".getXlevels" ...
 $ variables:List of 1
  ..$ base: chr [1:4] ".GlobalEnv" ".Machine" ".Options" "pi"
>

Great!

/Henrik

On Fri, Nov 14, 2014 at 8:41 PM, Kasper Daniel Hansen
<kasperdanielhansen at gmail.com> wrote:
> The best thing I have found is codetoolsBioC in the Bioconductor subversion
> repository.
>
> Best,
> Kasper
>
> On Fri, Nov 14, 2014 at 9:57 PM, Henrik Bengtsson <hb at biostat.ucsf.edu>
> wrote:
>>
>> Hi,
>>
>> I'd like to list all package PkgA functions that another package PkgB
>> use via Depends or Imports (ignoring Suggests for simplicity).  As
>> long as PkgB uses importFrom("PkgA", ...) it's just a matter of
>> parsing the NAMESPACE file or inspecting
>> asNamespace("PkgB")$.__NAMESPACE__.$imports.  However, what can be
>> done in case PkgB uses import("PkgA")?  Is there a function/package
>> already available for this?
>>
>> Thanks,
>>
>> Henrik
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From murdoch.duncan at gmail.com  Sat Nov 15 10:47:57 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 15 Nov 2014 04:47:57 -0500
Subject: [Rd] Error "promise already under evaluation ..." with
 function(x, dim=dim(x))
In-Reply-To: <CAFDcVCQtz0HMknNVv16jYatLwk26EhtayKmE7-jzbt-sRyS6CA@mail.gmail.com>
References: <CAFDcVCQtz0HMknNVv16jYatLwk26EhtayKmE7-jzbt-sRyS6CA@mail.gmail.com>
Message-ID: <5467214D.1060502@gmail.com>

On 14/11/2014, 9:06 PM, Henrik Bengtsson wrote:
> I've meant to ask the following for several years now.  I understand why:
> 
>> foo <- function(x, dim=dim) { dim }
>> foo(1)
> Error in foo(1) :
>   promise already under evaluation: recursive default argument
> reference or earlier problems?
> 
> gives an error, but why wouldn't/couldn't the following work?
> 
>> foo <- function(x, dim=dim(x)) { dim }
>> foo(1)
> Error in foo(1) :
>   promise already under evaluation: recursive default argument
> reference or earlier problems?

You refer to "dim".  There's a dim defined in the argument list, so R
uses that definition of it.

But you didn't supply any value, so it tries to evaluate the default
value.  Default expressions are always evaluated in the evaluation frame
of the function call, so it looks for a function named "dim" in the
local frame.

It finds the argument in the local frame, so it tries to figure out if
it is a function or a value.  It needs to evaluate it to do that, and
you get the recursion.

> 
> As a workaround I also tried:
> 
>> foo <- function(x, dim) { if (missing(dim)) dim <- dim(x); dim }
>> foo(1)
> Error in foo(1) : argument "dim" is missing, with no default
> 
> which surprised me too.
> 
> 
> For the first case, is the rationale related to:
> 
>> foo <- function(x, a=dim(x), dim) { a }
>> foo(1)
> Error in foo(1) : argument "dim" is missing, with no default
> 
> and
> 
>> foo <- function(x, a=dim(x), dim=a) { a }
>> foo(1)
> Error in foo(1) :
>   promise already under evaluation: recursive default argument
> reference or earlier problems?
> 
> [since here argument 'dim' could take a function, e.g. foo(1,
> dim=length)], and that R treats
> 
> foo <- function(x, dim=dim(x)) { dim }
> 
> in a similar way?  That is, is R not "clever" enough to detect this as
> a special case, but instead goes ahead and tries to evaluate the
> default expression (=dim(x)) of argument 'dim' in order to get its
> default value?  If so, is there anything preventing R from support
> this "special case", e.g. by evaluating the default expression without
> argument/symbol 'dim' itself being in the picture to avoid "it finds
> itself"?  (Sorry if I'm using the incorrect words here).

No, it shouldn't do that.  It should use consistent rules for evaluation
or there would be sure to be bugs.

> 
> Yes, I understand that I can do:
> 
>> foo <- function(x, dim=base::dim(x)) { dim }

This is what you should do.

>> foo(1)
> NULL
> 
>> foo <- function(x, dim=NULL) { if (is.null(dim)) dim <- dim(x); dim }

This works, because when R is looking up the function dim(), it can
evaluate the local argument dim and see it is not a function, so it
proceeds to the parent frame.

>> foo(1)
> NULL
> 
> or
> 
>> foo <- function(x, dim.=dim(x)) { dim. }
>> foo(1)
> NULL

This is another solution that works, but it has the ugly argument name
now, so you'll get warnings during package checks from calls like

foo(1, dim=2)

> 
> but I would prefer not to have to turn those rather ad hoc solutions in my code.

Nothing ad hoc about the first one.

Duncan Murdoch

> 
> 
> Thanks,
> 
> Henrik
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From mmuurr at gmail.com  Mon Nov 17 01:58:37 2014
From: mmuurr at gmail.com (Murat Tasan)
Date: Sun, 16 Nov 2014 17:58:37 -0700
Subject: [Rd] common base functions stripping S3 class
Message-ID: <CA+YV+Hx1qA_+JZ1QLo0D7Ckcc3A2sxa-ScAs5g44icfiO4DpnQ@mail.gmail.com>

Hi all --- this is less a specific question and more general regarding
S3 classes.
I've noticed that quite a few very common default implementations of
generic functions (e.g. `unique`, `[`, `as.data.frame`) strip away
class information.
In some cases, it appears conditionals have been created to re-assign
the class, but only for a few special types.
For example, in `unique.default`, if the argument inherits (_only_)
from "POSIXct" or "Date", the initial class is re-assigned to the
returned object.
But for any other custom S3 classes, it means we have to catch these
frequent cases and write a lot relatively plain wrappers, e.g.:

unique.MyClass <- function(x, incomparables = FALSE, ...) {
    structure(unique(unclass(x)), class = class(x))
}

It's certainly nice to be able to create a very simple wrapper class
on a base type, so that we can override common functions like plot(x).
(An example is a simple class attribute that dictates a particular
plot style for a vector of integers.)
But it would be even nicer to not have to detect and override all the
un-class events that occur when manipulating these objects with
everyday functions, e.g. when adding that 'classed' integer vector to
a data frame.

Apart from moving to S4 classes, how have most dealt with this?
Might there be a list of common functions for which the default
implementation strips class information?
(Such a list could be a handy "consider overriding _this_" guide for
implementors of any new classes.)

Cheers and thanks for any tips!

-murat


From murdoch.duncan at gmail.com  Mon Nov 17 02:14:02 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 16 Nov 2014 20:14:02 -0500
Subject: [Rd] common base functions stripping S3 class
In-Reply-To: <CA+YV+Hx1qA_+JZ1QLo0D7Ckcc3A2sxa-ScAs5g44icfiO4DpnQ@mail.gmail.com>
References: <CA+YV+Hx1qA_+JZ1QLo0D7Ckcc3A2sxa-ScAs5g44icfiO4DpnQ@mail.gmail.com>
Message-ID: <54694BDA.10102@gmail.com>

On 16/11/2014, 7:58 PM, Murat Tasan wrote:
> Hi all --- this is less a specific question and more general regarding
> S3 classes.
> I've noticed that quite a few very common default implementations of
> generic functions (e.g. `unique`, `[`, `as.data.frame`) strip away
> class information.
> In some cases, it appears conditionals have been created to re-assign
> the class, but only for a few special types.
> For example, in `unique.default`, if the argument inherits (_only_)
> from "POSIXct" or "Date", the initial class is re-assigned to the
> returned object.
> But for any other custom S3 classes, it means we have to catch these
> frequent cases and write a lot relatively plain wrappers, e.g.:
> 
> unique.MyClass <- function(x, incomparables = FALSE, ...) {
>     structure(unique(unclass(x)), class = class(x))
> }
> 
> It's certainly nice to be able to create a very simple wrapper class
> on a base type, so that we can override common functions like plot(x).
> (An example is a simple class attribute that dictates a particular
> plot style for a vector of integers.)
> But it would be even nicer to not have to detect and override all the
> un-class events that occur when manipulating these objects with
> everyday functions, e.g. when adding that 'classed' integer vector to
> a data frame.
> 
> Apart from moving to S4 classes, how have most dealt with this?
> Might there be a list of common functions for which the default
> implementation strips class information?
> (Such a list could be a handy "consider overriding _this_" guide for
> implementors of any new classes.)
> 
> Cheers and thanks for any tips!

I don't know of such a list.  If I define a class, I wouldn't assume
that any functions preserve it, unless I specifically write them to do so.

Generally the idea is that the class should be stripped because R has no
way of knowing if the new object, for example unique(obj), still has the
necessary properties to be considered to be of the same class as obj.
Only the author of the class knows that.  S4 would help a bit here, but
only structurally (it could detect when the object couldn't possibly be
of the right class), not semantically.

Duncan Murdoch


From h.wickham at gmail.com  Mon Nov 17 16:41:25 2014
From: h.wickham at gmail.com (Hadley Wickham)
Date: Mon, 17 Nov 2014 09:41:25 -0600
Subject: [Rd] common base functions stripping S3 class
In-Reply-To: <54694BDA.10102@gmail.com>
References: <CA+YV+Hx1qA_+JZ1QLo0D7Ckcc3A2sxa-ScAs5g44icfiO4DpnQ@mail.gmail.com>
	<54694BDA.10102@gmail.com>
Message-ID: <CABdHhvEo0OfXC0-rfSJmiyh9XJ57MqCnWDpa3Buwfr0OOzdh4w@mail.gmail.com>

> Generally the idea is that the class should be stripped because R has no
> way of knowing if the new object, for example unique(obj), still has the
> necessary properties to be considered to be of the same class as obj.
> Only the author of the class knows that.  S4 would help a bit here, but
> only structurally (it could detect when the object couldn't possibly be
> of the right class), not semantically.

There are two possible ways that S3 methods could handle subclasses:

* preserve by default (would also have preserve all attributes)
* drop by default

If you could really on either system consistently, I think you could
write correct code. It's very hard when the defaults vary.

(In other words, I agree with everything you said, except I think if
the default was to preserve you could still write correct code)

Hadley

-- 
http://had.co.nz/


From murdoch.duncan at gmail.com  Mon Nov 17 17:19:34 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 17 Nov 2014 11:19:34 -0500
Subject: [Rd] common base functions stripping S3 class
In-Reply-To: <CABdHhvEo0OfXC0-rfSJmiyh9XJ57MqCnWDpa3Buwfr0OOzdh4w@mail.gmail.com>
References: <CA+YV+Hx1qA_+JZ1QLo0D7Ckcc3A2sxa-ScAs5g44icfiO4DpnQ@mail.gmail.com>
	<54694BDA.10102@gmail.com>
	<CABdHhvEo0OfXC0-rfSJmiyh9XJ57MqCnWDpa3Buwfr0OOzdh4w@mail.gmail.com>
Message-ID: <546A2016.1020109@gmail.com>

On 17/11/2014 10:41 AM, Hadley Wickham wrote:
> > Generally the idea is that the class should be stripped because R has no
> > way of knowing if the new object, for example unique(obj), still has the
> > necessary properties to be considered to be of the same class as obj.
> > Only the author of the class knows that.  S4 would help a bit here, but
> > only structurally (it could detect when the object couldn't possibly be
> > of the right class), not semantically.
>
> There are two possible ways that S3 methods could handle subclasses:
>
> * preserve by default (would also have preserve all attributes)
> * drop by default
>
> If you could really on either system consistently, I think you could
> write correct code. It's very hard when the defaults vary.
>
> (In other words, I agree with everything you said, except I think if
> the default was to preserve you could still write correct code)

I don't see how default preserving could work.

For example, I might define a "SortedNumbers" class, which is a vector 
of numbers in non-decreasing order.  I could define min() and max() 
methods for it which would be really fast, because they only need to 
look at the first or last elements.  But a rev() method wouldn't make 
sense, so I wouldn't define one of those.

If the rev() default method left the class as "SortedNumbers", then my 
min() and max() calculations would end up broken.
So maybe I should have defined a rev() method that just stops with an 
error.  But classes don't own methods, so I'd have no way of knowing 
that someone else defined a new generic (e.g. shuffle()) that broke 
things.  I don't see any way around this within the S3 system.

In fact, some default methods do preserve the class, for example the 
replacement method `[<-`.  I could take a SortedNumbers vector of the 
numbers 1:10, and set element 1 to 11, and end up breaking min() and 
max().  This is a problem with the current design.

Probably we should do a better job of documenting which methods preserve 
the class and which ones don't.  (For example, `[` doesn't preserve the 
class, even though it would be fine to do so in this example.)  But 
there are a lot of things to do, and this is one thing that is pretty 
easy to figure out without documentation, so I'd say it's a low priority.

Duncan Murdoch


From murdoch.duncan at gmail.com  Tue Nov 18 14:15:32 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 18 Nov 2014 08:15:32 -0500
Subject: [Rd] common base functions stripping S3 class
In-Reply-To: <CA+YV+HwcnPbedCmwds_9P_gL_VMiK_Dv6TaJt1NMY7D4NXjNzQ@mail.gmail.com>
References: <CA+YV+Hx1qA_+JZ1QLo0D7Ckcc3A2sxa-ScAs5g44icfiO4DpnQ@mail.gmail.com>
	<54694BDA.10102@gmail.com>
	<CABdHhvEo0OfXC0-rfSJmiyh9XJ57MqCnWDpa3Buwfr0OOzdh4w@mail.gmail.com>
	<546A2016.1020109@gmail.com>
	<CA+YV+HwcnPbedCmwds_9P_gL_VMiK_Dv6TaJt1NMY7D4NXjNzQ@mail.gmail.com>
Message-ID: <546B4674.2050502@gmail.com>

On 17/11/2014, 4:23 PM, Murat Tasan wrote:
> Yeah, my biggest stumbling-point while starting to write S3 classes
> was the some-default-methods-preserve class, and
> some-default-methods-don't-preserve class dichotomy.
> But I'm not sure it's so "easy" to figure this out without more
> documentation... (though my experience is n = 1, and I might be
> particularly slow).

What I meant is that you can just try it.  If you think your users will
want to subset your object, then you can try it yourself, and you'll see
that you need to write a `[` method.

Duncan Murdoch

> 
> The most common motivating example for S3 classes (I've seen) is
> overriding plot().
> I imagine many people would want to take a base structure (e.g. a
> simple vector) and 'class-ify' it solely for the purposes of
> encapsulating domain-specific plotting commands:
> 
> MyClass <- function(x) structure(x, class = "MyClass")
> plot.MyClass <- function(...) ## large complicated plotting function here.
> 
> Those examples, however, basically never mention the need to then
> override/implement many other common methods, `c`, `[`, `unique`,
> `as.list`, `as.data.frame`, etc.
> I believe this is a _huge_ tripping point for new-comers to R
> programming (even if they are not new-comers to programming more
> generally).
> In my own experience, I had to work backwards by finding methods that
> dropped my class, then examine the source for those methods, find the
> underlying calls in those methods that dropped the class, and continue
> on down the (rabbit hole) call stack... this is hardly ideal for any
> programmer, I think, experienced or novice.
> 
> In the end, I completely understand your point (e.g. with the sorted
> numbers example), and I don't know how to resolve the issue, save
> perhaps for more explicit warnings when introducing S3 programming?
> 
> My own solution, by the way, is to define a single ancestor class that
> either (i) errors immediately if some assumptions fail, or (ii)
> dispatch to the default method while working to properly restore class
> attributes of the return object.
> Most of my 'useful' classes inherit from this 'dummy' ancestor class,
> just to save a lot of re-writing dispatch code.
> An example of where I error-out immediately is something like `c`,
> where I'll check to make sure all args are of the same class type...
> if they aren't, I could use R's coercion rules, but I've opted for the
> 'type-safe' approach of mixing variables when dealing with my own
> custom classes.
> An example of where I opt for preserving class is `[`.
> If I write a class where subsetting doesn't make sense, I'll have to
> write a fail-fast implementation of `[` for that specific class.
> The whole thing seems... inelegant (for lack of a better word), which
> is what prompted my post in the first place.
> 
> Cheers, and thanks for the discussion and points... they're definitely
> helpful in guiding development.
> 
> -murat
> 
> 
> On Mon, Nov 17, 2014 at 9:19 AM, Duncan Murdoch
> <murdoch.duncan at gmail.com> wrote:
>> On 17/11/2014 10:41 AM, Hadley Wickham wrote:
>>>
>>>> Generally the idea is that the class should be stripped because R has no
>>>> way of knowing if the new object, for example unique(obj), still has the
>>>> necessary properties to be considered to be of the same class as obj.
>>>> Only the author of the class knows that.  S4 would help a bit here, but
>>>> only structurally (it could detect when the object couldn't possibly be
>>>> of the right class), not semantically.
>>>
>>> There are two possible ways that S3 methods could handle subclasses:
>>>
>>> * preserve by default (would also have preserve all attributes)
>>> * drop by default
>>>
>>> If you could really on either system consistently, I think you could
>>> write correct code. It's very hard when the defaults vary.
>>>
>>> (In other words, I agree with everything you said, except I think if
>>> the default was to preserve you could still write correct code)
>>
>>
>> I don't see how default preserving could work.
>>
>> For example, I might define a "SortedNumbers" class, which is a vector of
>> numbers in non-decreasing order.  I could define min() and max() methods for
>> it which would be really fast, because they only need to look at the first
>> or last elements.  But a rev() method wouldn't make sense, so I wouldn't
>> define one of those.
>>
>> If the rev() default method left the class as "SortedNumbers", then my min()
>> and max() calculations would end up broken.
>> So maybe I should have defined a rev() method that just stops with an error.
>> But classes don't own methods, so I'd have no way of knowing that someone
>> else defined a new generic (e.g. shuffle()) that broke things.  I don't see
>> any way around this within the S3 system.
>>
>> In fact, some default methods do preserve the class, for example the
>> replacement method `[<-`.  I could take a SortedNumbers vector of the
>> numbers 1:10, and set element 1 to 11, and end up breaking min() and max().
>> This is a problem with the current design.
>>
>> Probably we should do a better job of documenting which methods preserve the
>> class and which ones don't.  (For example, `[` doesn't preserve the class,
>> even though it would be fine to do so in this example.)  But there are a lot
>> of things to do, and this is one thing that is pretty easy to figure out
>> without documentation, so I'd say it's a low priority.
>>
>> Duncan Murdoch
>>
>>


From MEC at stowers.org  Tue Nov 18 18:00:53 2014
From: MEC at stowers.org (Cook, Malcolm)
Date: Tue, 18 Nov 2014 17:00:53 +0000
Subject: [Rd] ShortRead::FastqStreamer and parallelization
Message-ID: <D4772401B9D976478C0895769BE3E7920F27A42C@MBSRV02.sgc.loc>

Hi,

I understand ShortRead::FastqStreamer will read chunks in parallel depending on the value of ShortRead:::.set_omp_threads

I see this discussed here:  https://stat.ethz.ch/pipermail/bioc-devel/2013-May/004355.html and nowhere else.

It probably should be documented in ShortRead.

Possibly this has already changed for I am using still R 3.1.0.   I thought I'd check.

Oh, and, in my hands/hardware, the value of this FastqStreamer's use of srapply's parallelization is negligible, at least if the consumer of successive yields is in the main process.  I see that the new bpiterate appears to take advantage of yielding in forked processes, which sounds promising.  Is that the idea?

Looking forward....

Malcolm Cook


From ripley at stats.ox.ac.uk  Tue Nov 18 18:35:38 2014
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 18 Nov 2014 17:35:38 +0000
Subject: [Rd] ShortRead::FastqStreamer and parallelization
In-Reply-To: <D4772401B9D976478C0895769BE3E7920F27A42C@MBSRV02.sgc.loc>
References: <D4772401B9D976478C0895769BE3E7920F27A42C@MBSRV02.sgc.loc>
Message-ID: <546B836A.1060008@stats.ox.ac.uk>

What does this have to do with this (or any R) list?

Bioconductor has its own support arrangements.

On 18/11/2014 17:00, Cook, Malcolm wrote:
> Hi,
>
> I understand ShortRead::FastqStreamer will read chunks in parallel depending on the value of ShortRead:::.set_omp_threads
>
> I see this discussed here:  https://stat.ethz.ch/pipermail/bioc-devel/2013-May/004355.html and nowhere else.
>
> It probably should be documented in ShortRead.
>
> Possibly this has already changed for I am using still R 3.1.0.   I thought I'd check.
>
> Oh, and, in my hands/hardware, the value of this FastqStreamer's use of srapply's parallelization is negligible, at least if the consumer of successive yields is in the main process.  I see that the new bpiterate appears to take advantage of yielding in forked processes, which sounds promising.  Is that the idea?
>
> Looking forward....
>
> Malcolm Cook
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From skostysh at princeton.edu  Wed Nov 19 03:50:17 2014
From: skostysh at princeton.edu (Scott Kostyshak)
Date: Tue, 18 Nov 2014 21:50:17 -0500
Subject: [Rd] Cursor not behaving properly
In-Reply-To: <CAOHtMfUupQ2KSGwuoZcKZRJ3BAdQLzTxgV8-ucAMMoMpWzEYCg@mail.gmail.com>
References: <CAOHtMfUupQ2KSGwuoZcKZRJ3BAdQLzTxgV8-ucAMMoMpWzEYCg@mail.gmail.com>
Message-ID: <CAE3=dmfRW8QTXm6G1469bJ_fzuQUpf7wdiqrZe9sqyckpYPOjw@mail.gmail.com>

On Mon, Nov 10, 2014 at 10:52 AM, Kaiyin Zhong (Victor Chung)
<kindlychung at gmail.com> wrote:
> I found a strange bug in R recently (version 3.1.2):
>
> As you can see from the screenshots attached, when the cursor passes the
> right edge of the console, instead of start on a new line, it goes back to
> the beginning of the same line, and overwrites everything after it.
>
> This happens every time the size of the terminal is changed, for example,
> if you fit the terminal to the right half of the screen, start an R
> session, exec some commands, maximize the terminal, and type a long command
> into the session, then you will find the bug reproduced.
>
> I am on Ubuntu 14.04, and I have tested this in konsole, guake and
> gnome-terminal.

I can reproduce this, also on Ubuntu 14.04, with gnome-terminal and
xterm. If you don't get any response here, please file a bug report at
bugs.r-project.org.

Scott


--
Scott Kostyshak
Economics PhD Candidate
Princeton University


From mark.vanderloo at gmail.com  Wed Nov 19 10:58:41 2014
From: mark.vanderloo at gmail.com (Mark van der Loo)
Date: Wed, 19 Nov 2014 10:58:41 +0100
Subject: [Rd] nchar reporting wrong width when zero-space character is
	present?
Message-ID: <CAOKDuOgXB9sLVSrLqyuaqx8i=whRBrf7xV9nyVurW-oFu0MZYA@mail.gmail.com>

Dear list,

If I include the zero-width non-breaking space (\ufeff) in a string,
nchar seems to compute the wrong number of columns used by 'cat'.

> x <- "f\ufeffoo"
> x
[1] "f?oo"
> nchar(x,type="width")
[1] 2

I would expect "3" here. Going through the documentation of 'Encoding'
and 'encodeString', I don't think this is expected behavior. Am I
missing something? If it is a bug I will file a report.

Secondly, the documentation of 'nchars' states that with type='chars'
(the default) it returns "the number of human-readable characters". I
get:

> nchar(x,type='chars')
[1] 4

I would hardly call the zero-width space human-readable. Also, since for example

> nchar("foo\r")
[1] 4

it is probably more accurate to say that the number of symbols
(abstract characters) are counted, noting that some of the symbols in
an alphabet represented by an encoding may be invisible (or hardly
visible).


Much thanks in advance,
Best, Mark


> sessionInfo()
R version 3.1.2 (2014-10-31)
Platform: x86_64-pc-linux-gnu (64-bit)

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
 [3] LC_TIME=nl_NL.UTF-8        LC_COLLATE=en_US.UTF-8
 [5] LC_MONETARY=nl_NL.UTF-8    LC_MESSAGES=en_US.UTF-8
 [7] LC_PAPER=nl_NL.UTF-8       LC_NAME=C
 [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=nl_NL.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] tools_3.1.2


From skostysh at princeton.edu  Wed Nov 19 22:14:38 2014
From: skostysh at princeton.edu (Scott Kostyshak)
Date: Wed, 19 Nov 2014 16:14:38 -0500
Subject: [Rd] Cursor not behaving properly
In-Reply-To: <CAE3=dmfRW8QTXm6G1469bJ_fzuQUpf7wdiqrZe9sqyckpYPOjw@mail.gmail.com>
References: <CAOHtMfUupQ2KSGwuoZcKZRJ3BAdQLzTxgV8-ucAMMoMpWzEYCg@mail.gmail.com>
	<CAE3=dmfRW8QTXm6G1469bJ_fzuQUpf7wdiqrZe9sqyckpYPOjw@mail.gmail.com>
Message-ID: <CAE3=dmeKHj0jOc62QcNY9g=nVbFJTgU6u3t1zfiwpUDC+4Fraw@mail.gmail.com>

On Tue, Nov 18, 2014 at 9:50 PM, Scott Kostyshak <skostysh at princeton.edu> wrote:
> On Mon, Nov 10, 2014 at 10:52 AM, Kaiyin Zhong (Victor Chung)
> <kindlychung at gmail.com> wrote:
>> I found a strange bug in R recently (version 3.1.2):
>>
>> As you can see from the screenshots attached, when the cursor passes the
>> right edge of the console, instead of start on a new line, it goes back to
>> the beginning of the same line, and overwrites everything after it.
>>
>> This happens every time the size of the terminal is changed, for example,
>> if you fit the terminal to the right half of the screen, start an R
>> session, exec some commands, maximize the terminal, and type a long command
>> into the session, then you will find the bug reproduced.
>>
>> I am on Ubuntu 14.04, and I have tested this in konsole, guake and
>> gnome-terminal.
>
> I can reproduce this, also on Ubuntu 14.04, with gnome-terminal and
> xterm. If you don't get any response here, please file a bug report at
> bugs.r-project.org.

For archival purposes, the OP reported the bug here:
https://bugs.r-project.org/bugzilla/show_bug.cgi?id=16077

Scott


--
Scott Kostyshak
Economics PhD Candidate
Princeton University


From hb at biostat.ucsf.edu  Wed Nov 19 23:20:40 2014
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Wed, 19 Nov 2014 14:20:40 -0800
Subject: [Rd] Cursor not behaving properly
In-Reply-To: <CAE3=dmeKHj0jOc62QcNY9g=nVbFJTgU6u3t1zfiwpUDC+4Fraw@mail.gmail.com>
References: <CAOHtMfUupQ2KSGwuoZcKZRJ3BAdQLzTxgV8-ucAMMoMpWzEYCg@mail.gmail.com>
	<CAE3=dmfRW8QTXm6G1469bJ_fzuQUpf7wdiqrZe9sqyckpYPOjw@mail.gmail.com>
	<CAE3=dmeKHj0jOc62QcNY9g=nVbFJTgU6u3t1zfiwpUDC+4Fraw@mail.gmail.com>
Message-ID: <CAFDcVCQmqDE09f_5NiNDb15S9DwT=7hVXfseZ6YRCc3L_1Scqg@mail.gmail.com>

FYI, it might be useful to check if the bug also appears on R-devel as
well as on earlier versions of R.  That might narrow down whether it
was introduced in a particular R version or not, which in turn would
be useful to whoever might try to tackle this problem.  It might not
even be an R problem in the end.

/Henrik

On Wed, Nov 19, 2014 at 1:14 PM, Scott Kostyshak <skostysh at princeton.edu> wrote:
> On Tue, Nov 18, 2014 at 9:50 PM, Scott Kostyshak <skostysh at princeton.edu> wrote:
>> On Mon, Nov 10, 2014 at 10:52 AM, Kaiyin Zhong (Victor Chung)
>> <kindlychung at gmail.com> wrote:
>>> I found a strange bug in R recently (version 3.1.2):
>>>
>>> As you can see from the screenshots attached, when the cursor passes the
>>> right edge of the console, instead of start on a new line, it goes back to
>>> the beginning of the same line, and overwrites everything after it.
>>>
>>> This happens every time the size of the terminal is changed, for example,
>>> if you fit the terminal to the right half of the screen, start an R
>>> session, exec some commands, maximize the terminal, and type a long command
>>> into the session, then you will find the bug reproduced.
>>>
>>> I am on Ubuntu 14.04, and I have tested this in konsole, guake and
>>> gnome-terminal.
>>
>> I can reproduce this, also on Ubuntu 14.04, with gnome-terminal and
>> xterm. If you don't get any response here, please file a bug report at
>> bugs.r-project.org.
>
> For archival purposes, the OP reported the bug here:
> https://bugs.r-project.org/bugzilla/show_bug.cgi?id=16077
>
> Scott
>
>
> --
> Scott Kostyshak
> Economics PhD Candidate
> Princeton University
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From larissahauer at googlemail.com  Thu Nov 20 10:27:28 2014
From: larissahauer at googlemail.com (Larissa Hauer)
Date: Thu, 20 Nov 2014 10:27:28 +0100
Subject: [Rd] Cursor not behaving properly
In-Reply-To: <CAFDcVCQmqDE09f_5NiNDb15S9DwT=7hVXfseZ6YRCc3L_1Scqg@mail.gmail.com>
References: <CAOHtMfUupQ2KSGwuoZcKZRJ3BAdQLzTxgV8-ucAMMoMpWzEYCg@mail.gmail.com>	<CAE3=dmfRW8QTXm6G1469bJ_fzuQUpf7wdiqrZe9sqyckpYPOjw@mail.gmail.com>	<CAE3=dmeKHj0jOc62QcNY9g=nVbFJTgU6u3t1zfiwpUDC+4Fraw@mail.gmail.com>
	<CAFDcVCQmqDE09f_5NiNDb15S9DwT=7hVXfseZ6YRCc3L_1Scqg@mail.gmail.com>
Message-ID: <546DB400.3040902@googlemail.com>


Hi,

regarding earlier versions: I can reproduce this bug with R 3.1.1 on 
Ubuntu 14.04, Gnome Terminal.

I could imagine this is an Ubuntu problem since I've had "ghost mice" 
and strange cursor behavior since I switched to 14.04.

Larissa

PS: If any Ubuntu user is interested, I was able to fix the problems 
(except for the R bug of course) by turning off the second screen as 
described here:

http://askubuntu.com/questions/365798/mouse-arrow-flash-and-ghost-in-ubuntu-13-10

On 19.11.2014 23:20, Henrik Bengtsson wrote:
> FYI, it might be useful to check if the bug also appears on R-devel as
> well as on earlier versions of R.  That might narrow down whether it
> was introduced in a particular R version or not, which in turn would
> be useful to whoever might try to tackle this problem.  It might not
> even be an R problem in the end.
>
> /Henrik
>
> On Wed, Nov 19, 2014 at 1:14 PM, Scott Kostyshak <skostysh at princeton.edu> wrote:
>> On Tue, Nov 18, 2014 at 9:50 PM, Scott Kostyshak <skostysh at princeton.edu> wrote:
>>> On Mon, Nov 10, 2014 at 10:52 AM, Kaiyin Zhong (Victor Chung)
>>> <kindlychung at gmail.com> wrote:
>>>> I found a strange bug in R recently (version 3.1.2):
>>>>
>>>> As you can see from the screenshots attached, when the cursor passes the
>>>> right edge of the console, instead of start on a new line, it goes back to
>>>> the beginning of the same line, and overwrites everything after it.
>>>>
>>>> This happens every time the size of the terminal is changed, for example,
>>>> if you fit the terminal to the right half of the screen, start an R
>>>> session, exec some commands, maximize the terminal, and type a long command
>>>> into the session, then you will find the bug reproduced.
>>>>
>>>> I am on Ubuntu 14.04, and I have tested this in konsole, guake and
>>>> gnome-terminal.
>>>
>>> I can reproduce this, also on Ubuntu 14.04, with gnome-terminal and
>>> xterm. If you don't get any response here, please file a bug report at
>>> bugs.r-project.org.
>>
>> For archival purposes, the OP reported the bug here:
>> https://bugs.r-project.org/bugzilla/show_bug.cgi?id=16077
>>
>> Scott
>>
>>
>> --
>> Scott Kostyshak
>> Economics PhD Candidate
>> Princeton University
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From plummerm at iarc.fr  Thu Nov 20 11:01:12 2014
From: plummerm at iarc.fr (Martyn Plummer)
Date: Thu, 20 Nov 2014 10:01:12 +0000
Subject: [Rd] Cursor not behaving properly
In-Reply-To: <546DB400.3040902@googlemail.com>
References: <CAOHtMfUupQ2KSGwuoZcKZRJ3BAdQLzTxgV8-ucAMMoMpWzEYCg@mail.gmail.com>
	<CAE3=dmfRW8QTXm6G1469bJ_fzuQUpf7wdiqrZe9sqyckpYPOjw@mail.gmail.com>
	<CAE3=dmeKHj0jOc62QcNY9g=nVbFJTgU6u3t1zfiwpUDC+4Fraw@mail.gmail.com>
	<CAFDcVCQmqDE09f_5NiNDb15S9DwT=7hVXfseZ6YRCc3L_1Scqg@mail.gmail.com>
	<546DB400.3040902@googlemail.com>
Message-ID: <1416477672.3093.236.camel@braque.iarc.fr>

I can't reproduce this on Fedora 20, so I think it is an Ubuntu bug.

If anyone not on Ubuntu can reproduce this then please add a comment in
the bug repository.

https://bugs.r-project.org/bugzilla/show_bug.cgi?id=16077

If not then I'll close it.
Martyn

On Thu, 2014-11-20 at 10:27 +0100, Larissa Hauer wrote:
> Hi,
> 
> regarding earlier versions: I can reproduce this bug with R 3.1.1 on 
> Ubuntu 14.04, Gnome Terminal.
> 
> I could imagine this is an Ubuntu problem since I've had "ghost mice" 
> and strange cursor behavior since I switched to 14.04.
> 
> Larissa
> 
> PS: If any Ubuntu user is interested, I was able to fix the problems 
> (except for the R bug of course) by turning off the second screen as 
> described here:
> 
> http://askubuntu.com/questions/365798/mouse-arrow-flash-and-ghost-in-ubuntu-13-10
> 
> On 19.11.2014 23:20, Henrik Bengtsson wrote:
> > FYI, it might be useful to check if the bug also appears on R-devel as
> > well as on earlier versions of R.  That might narrow down whether it
> > was introduced in a particular R version or not, which in turn would
> > be useful to whoever might try to tackle this problem.  It might not
> > even be an R problem in the end.
> >
> > /Henrik
> >
> > On Wed, Nov 19, 2014 at 1:14 PM, Scott Kostyshak <skostysh at princeton.edu> wrote:
> >> On Tue, Nov 18, 2014 at 9:50 PM, Scott Kostyshak <skostysh at princeton.edu> wrote:
> >>> On Mon, Nov 10, 2014 at 10:52 AM, Kaiyin Zhong (Victor Chung)
> >>> <kindlychung at gmail.com> wrote:
> >>>> I found a strange bug in R recently (version 3.1.2):
> >>>>
> >>>> As you can see from the screenshots attached, when the cursor passes the
> >>>> right edge of the console, instead of start on a new line, it goes back to
> >>>> the beginning of the same line, and overwrites everything after it.
> >>>>
> >>>> This happens every time the size of the terminal is changed, for example,
> >>>> if you fit the terminal to the right half of the screen, start an R
> >>>> session, exec some commands, maximize the terminal, and type a long command
> >>>> into the session, then you will find the bug reproduced.
> >>>>
> >>>> I am on Ubuntu 14.04, and I have tested this in konsole, guake and
> >>>> gnome-terminal.
> >>>
> >>> I can reproduce this, also on Ubuntu 14.04, with gnome-terminal and
> >>> xterm. If you don't get any response here, please file a bug report at
> >>> bugs.r-project.org.
> >>
> >> For archival purposes, the OP reported the bug here:
> >> https://bugs.r-project.org/bugzilla/show_bug.cgi?id=16077
> >>
> >> Scott
> >>
> >>
> >> --
> >> Scott Kostyshak
> >> Economics PhD Candidate
> >> Princeton University
> >>
> >> ______________________________________________
> >> R-devel at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-devel
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-----------------------------------------------------------------------
This message and its attachments are strictly confidenti...{{dropped:8}}


From csardi.gabor at gmail.com  Thu Nov 20 22:43:22 2014
From: csardi.gabor at gmail.com (=?UTF-8?B?R8OhYm9yIENzw6FyZGk=?=)
Date: Thu, 20 Nov 2014 16:43:22 -0500
Subject: [Rd] r-release, r-oldrel
In-Reply-To: <C6E7D4D9-4049-404F-846C-C50961DE0E1A@gmail.com>
References: <CABtg=Kn2fDXQedu=KaXpEx21hSLu=HqDB=aE_QthPvs8LCSzuw@mail.gmail.com>
	<545BF7F3.4000708@statistik.tu-dortmund.de>
	<CABtg=Knonx3oAc+Xo0LN5Y4PYoSUKU-NRaKEusg6rMU1KO406Q@mail.gmail.com>
	<545BFA1A.2060008@statistik.tu-dortmund.de>
	<C6E7D4D9-4049-404F-846C-C50961DE0E1A@gmail.com>
Message-ID: <CABtg=K=VZ7RZvtLqv=A0ai4nmjsqVc=iDA+UJwvAcE94QdJdAg@mail.gmail.com>

On Fri, Nov 7, 2014 at 6:09 AM, peter dalgaard <pdalgd at gmail.com> wrote:
[...]
> Now you got me curious... this seems to do the job of finding the last release of all major.minor series:
>
> tb <- read.table(text=system("svn ls -v http://svn.r-project.org/R/tags", intern=TRUE))
> names(tb) <- c("rev","au","m","d","y.or.time", "tag")
> ix <- grep(x=tb$tag,pattern="^R-[0-9]+-[0-9]")
> tb <- tb[ix,c("rev", "tag")]
> v.str <- as.character(tb$tag)[order(tb$rev)]
> versions <- data.frame(do.call(rbind,strsplit(v.str,"[-/]+"))[,-1],stringsAsFactors=FALSE)
> names(versions) <- c("major","minor","patch")
> maj.min <- paste(versions$major,versions$minor, sep=".")
> maj.min <- factor(maj.min,levels=unique(maj.min))
> unsplit(lapply(split(versions, maj.min),tail,1),unique(maj.min))

Thanks, awesome! As I needed something that does not call svn (might
not be installed), I went with querying the list via webdav. This is
my final solution, for the records. It is lengthy, though.

library(magrittr)
library(RCurl)
library(XML)

## Get the tag info from SVN
xtags <- getURLContent(
  "http://svn.r-project.org/R/tags/",
  customrequest = "PROPFIND",
  httpheader=c("Depth"="1")
) %>%
  xmlParse() %>%
  xmlRoot() %>%
  xmlChildren()

## Split a version number to major, minor, patch
split_versions <- function(x) {
  x %>%
    sub(pattern = "^([0-9]+-[0-9]+)$", replacement = "\\1-0") %>%
    strsplit(split = "-") %>%
    sapply(as.numeric)
}

## Sort version numbers
sort_tags <- function(x) {
  x_order <- x %>%
    split_versions() %>%
    apply(1, list) %>%
    lapply("[[", 1) %>%
    do.call(what = order)
  x [x_order]
}

## Extract versions numbers from XML and sort them
versions <- xtags %>%
  lapply(xpathApply, "*[local-name()='href']") %>%
  sapply("[[", 1) %>%
  sapply(xmlValue) %>%
  unname() %>%
  sub(pattern = "/R/tags/R-([^/]+)/", replacement = "\\1") %>%
  grep(pattern = "^[0-9]+-[0-9]+(-[0-9]+|)$", value = TRUE) %>%
  sort_tags()

## Relase is easy, most recent
release <- tail(versions, 1)

## Oldrel is latest from the previous minor
## (Careful with factors, they are ordered by default!)
oldrel <- versions %>%
  sub(pattern = "-[0-9]+$", replacement = "") %>%
  factor(levels = unique(.)) %>%
  tapply(X = versions, FUN = tail, 1) %>%
  tail(2) %>%
  head(1) %>%
  unname()

Thanks again,
Gabor


> -pd

[...]


From hanchen at hsph.harvard.edu  Sat Nov 22 09:34:19 2014
From: hanchen at hsph.harvard.edu (Chen, Han)
Date: Sat, 22 Nov 2014 08:34:19 +0000
Subject: [Rd] Large size shared library
Message-ID: <8D48472E9B593F468ACA358D876124DB4F04EE@ENTWEXMB0000008.university.harvard.edu>

Dear all,

I have an R package that I plan to submit to CRAN in the near future, but it gave me a note when I ran "R CMD check --as-cran" saying that my libs directory is 7.0Mb. I wrote some functions in C++ and my source code included several low-level C++ libraries as header files. When I compiled manually using g++ without the -g flag, my shared library (.so) was about 400Kb; but when I compiled with the -g flag, it was about 7.0Mb... I am assuming there was a lot of debugging information created when I turned on -g, possibly because the compiler had to look for a lot of classes and functions in low-level C++ libraries, but I am worried that the package would fail CRAN check due to the large size .so file created (it seems R has -g flag on by default when compiling C/C++ code according to ${R_HOME}/etc/Makeconf). Does anyone have any suggestions on how I could possibly make my shared library file smaller? Even though I can compile it manually without the -g flag, general users will use R default to install the package and it could take a lot of space. Thanks in advance!

Best,
Han

-----
Han Chen, Ph.D.
Postdoctoral Research Fellow
Department of Biostatistics
Harvard School of Public Health
http://www.hsph.harvard.edu/han-chen/


	[[alternative HTML version deleted]]


From ripley at stats.ox.ac.uk  Sat Nov 22 14:13:49 2014
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 22 Nov 2014 13:13:49 +0000
Subject: [Rd] Large size shared library
In-Reply-To: <8D48472E9B593F468ACA358D876124DB4F04EE@ENTWEXMB0000008.university.harvard.edu>
References: <8D48472E9B593F468ACA358D876124DB4F04EE@ENTWEXMB0000008.university.harvard.edu>
Message-ID: <54708C0D.5070408@stats.ox.ac.uk>

On 22/11/2014 08:34, Chen, Han wrote:
> Dear all,
>
> I have an R package that I plan to submit to CRAN in the near
> future,
but it gave me a note when I ran "R CMD check --as-cran" saying that my
libs directory is 7.0Mb. I wrote some functions in C++ and my source
code included several low-level C++ libraries as header files. When I
compiled manually using g++ without the -g flag, my shared library (.so)
was about 400Kb; but when I compiled with the -g flag, it was about
7.0Mb... I am assuming there was a lot of debugging information created
when I turned on -g, possibly because the compiler had to look for a lot
of classes and functions in low-level C++ libraries, but I am worried
that the package would fail CRAN check due to the large size .so file
created (it seems R has -g flag on by default when compiling C/C++ code
according to ${R_HOME}/etc/Makeconf). Does anyone have any suggestions
on how I could possibly make my shared library file smaller? Even though
I can compile it manually without the -g flag, general users will !
> use R default to install the package and it could take a lot of
> space.

Thanks in advance!

7MB is not 'a lot of space'.  There are CRAN packages which compiled 
with -g take ca 80MB.

> Best,
> Han
>
> -----
> Han Chen, Ph.D.
> Postdoctoral Research Fellow
> Department of Biostatistics
> Harvard School of Public Health
> http://www.hsph.harvard.edu/han-chen/
>
>
> 	[[alternative HTML version deleted]]

Please do follow the posting guide and not send HTML.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From sambler at linkedin.com  Sat Nov 22 20:59:48 2014
From: sambler at linkedin.com (Stuart Ambler)
Date: Sat, 22 Nov 2014 19:59:48 +0000
Subject: [Rd] R string comparisons may vary with platform (plain text)
Message-ID: <D0962B34.6441%sambler@linkedin.com>

A colleague?s R program behaved differently when I ran it, and we thought
we traced it probably to different results from string comparisons as
below, with different R versions.  However the platforms also differed.  A
friend ran it on a few machines and found that the comparison behavior
didn?t correlate with R version, but rather with platform.

I wonder if you?ve seen this.  If it?s not some setting I?m unaware of,
maybe someone should look into it.  Sorry I haven?t taken the time to read
the source code myself.

Thanks,
Stuart

R version 3.0.2 (2013-09-25) -- "Frisbee Sailing"
Platform: x86_64-unknown-linux-gnu (64-bit)
Sys.getlocale()
[1] 
"LC_CTYPE=en_US.UTF-8;LC_NUMERIC=C;LC_TIME=en_US.UTF-8;LC_COLLATE=en_US.UTF
-8;LC_MONETARY=en_US.UTF-8;LC_MESSAGES=en_US.UTF-8;LC_PAPER=en_US.UTF-8;LC_
NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=en_US.UTF-8;LC_IDENTIFICA
TION=C"

"-1" > "1"
[1] TRUE

"-1" <"1"
[1] FALSE

"1" < "-1"
[1] TRUE

"1" < "-"
[1] FALSE

Vs.

R version 3.1.1 (2014-07-10) ? ?Sock it to Me"
Platform: x86_64-redhat-linux-gnu (64-bit)
Sys.getlocale()
[1] 
"LC_CTYPE=en_US.utf8;LC_NUMERIC=C;LC_TIME=en_US.utf8;LC_COLLATE=en_US.utf8
;LC_MONETARY=en_US.utf8;LC_MESSAGES=en_US.utf8;LC_PAPER=en_US.utf8;LC_NAME
=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=en_US.utf8;LC_IDENTIFICATION
=C"

"-1" > "1"
[1] FALSE

"-1" <"1"
[1] TRUE

"1" < "-1"
[1] FALSE

"1" < "-"
[1] FALSE


From murdoch.duncan at gmail.com  Sat Nov 22 21:42:07 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 22 Nov 2014 15:42:07 -0500
Subject: [Rd] R string comparisons may vary with platform (plain text)
In-Reply-To: <D0962B34.6441%sambler@linkedin.com>
References: <D0962B34.6441%sambler@linkedin.com>
Message-ID: <5470F51F.1000802@gmail.com>

On 22/11/2014, 2:59 PM, Stuart Ambler wrote:
> A colleague?s R program behaved differently when I ran it, and we thought
> we traced it probably to different results from string comparisons as
> below, with different R versions.  However the platforms also differed.  A
> friend ran it on a few machines and found that the comparison behavior
> didn?t correlate with R version, but rather with platform.
> 
> I wonder if you?ve seen this.  If it?s not some setting I?m unaware of,
> maybe someone should look into it.  Sorry I haven?t taken the time to read
> the source code myself.

Looks like a collation order issue.  See ?Comparison.

Duncan Murdoch

> Thanks,
> Stuart
> 
> R version 3.0.2 (2013-09-25) -- "Frisbee Sailing"
> Platform: x86_64-unknown-linux-gnu (64-bit)
> Sys.getlocale()
> [1] 
> "LC_CTYPE=en_US.UTF-8;LC_NUMERIC=C;LC_TIME=en_US.UTF-8;LC_COLLATE=en_US.UTF
> -8;LC_MONETARY=en_US.UTF-8;LC_MESSAGES=en_US.UTF-8;LC_PAPER=en_US.UTF-8;LC_
> NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=en_US.UTF-8;LC_IDENTIFICA
> TION=C"
> 
> "-1" > "1"
> [1] TRUE
> 
> "-1" <"1"
> [1] FALSE
> 
> "1" < "-1"
> [1] TRUE
> 
> "1" < "-"
> [1] FALSE
> 
> Vs.
> 
> R version 3.1.1 (2014-07-10) ? ?Sock it to Me"
> Platform: x86_64-redhat-linux-gnu (64-bit)
> Sys.getlocale()
> [1] 
> "LC_CTYPE=en_US.utf8;LC_NUMERIC=C;LC_TIME=en_US.utf8;LC_COLLATE=en_US.utf8
> ;LC_MONETARY=en_US.utf8;LC_MESSAGES=en_US.utf8;LC_PAPER=en_US.utf8;LC_NAME
> =C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=en_US.utf8;LC_IDENTIFICATION
> =C"
> 
> "-1" > "1"
> [1] FALSE
> 
> "-1" <"1"
> [1] TRUE
> 
> "1" < "-1"
> [1] FALSE
> 
> "1" < "-"
> [1] FALSE
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From sambler at linkedin.com  Sat Nov 22 21:49:46 2014
From: sambler at linkedin.com (Stuart Ambler)
Date: Sat, 22 Nov 2014 20:49:46 +0000
Subject: [Rd] R string comparisons may vary with platform (plain text)
In-Reply-To: <5470F51F.1000802@gmail.com>
References: <D0962B34.6441%sambler@linkedin.com> <5470F51F.1000802@gmail.com>
Message-ID: <D0963606.647D%sambler@linkedin.com>

You mean where it says that some platforms may not respect the locale (I
assume, though don?t know, that en_US.UTF-8 and en_US.utf8 would be the
same)?  But I gather that the general problem has been looked into and is
difficult to solve; thanks.

On 11/22/14, 12:42 PM, "Duncan Murdoch" <murdoch.duncan at gmail.com> wrote:

>On 22/11/2014, 2:59 PM, Stuart Ambler wrote:
>> A colleague?s R program behaved differently when I ran it, and we
>>thought
>> we traced it probably to different results from string comparisons as
>> below, with different R versions.  However the platforms also differed.
>> A
>> friend ran it on a few machines and found that the comparison behavior
>> didn?t correlate with R version, but rather with platform.
>> 
>> I wonder if you?ve seen this.  If it?s not some setting I?m unaware of,
>> maybe someone should look into it.  Sorry I haven?t taken the time to
>>read
>> the source code myself.
>
>Looks like a collation order issue.  See ?Comparison.
>
>Duncan Murdoch
>
>> Thanks,
>> Stuart
>> 
>> R version 3.0.2 (2013-09-25) -- "Frisbee Sailing"
>> Platform: x86_64-unknown-linux-gnu (64-bit)
>> Sys.getlocale()
>> [1] 
>> 
>>"LC_CTYPE=en_US.UTF-8;LC_NUMERIC=C;LC_TIME=en_US.UTF-8;LC_COLLATE=en_US.U
>>TF
>> 
>>-8;LC_MONETARY=en_US.UTF-8;LC_MESSAGES=en_US.UTF-8;LC_PAPER=en_US.UTF-8;L
>>C_
>> 
>>NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=en_US.UTF-8;LC_IDENTIFI
>>CA
>> TION=C"
>> 
>> "-1" > "1"
>> [1] TRUE
>> 
>> "-1" <"1"
>> [1] FALSE
>> 
>> "1" < "-1"
>> [1] TRUE
>> 
>> "1" < "-"
>> [1] FALSE
>> 
>> Vs.
>> 
>> R version 3.1.1 (2014-07-10) ? ?Sock it to Me"
>> Platform: x86_64-redhat-linux-gnu (64-bit)
>> Sys.getlocale()
>> [1] 
>> 
>>"LC_CTYPE=en_US.utf8;LC_NUMERIC=C;LC_TIME=en_US.utf8;LC_COLLATE=en_US.utf
>>8
>> 
>>;LC_MONETARY=en_US.utf8;LC_MESSAGES=en_US.utf8;LC_PAPER=en_US.utf8;LC_NAM
>>E
>> 
>>=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=en_US.utf8;LC_IDENTIFICATIO
>>N
>> =C"
>> 
>> "-1" > "1"
>> [1] FALSE
>> 
>> "-1" <"1"
>> [1] TRUE
>> 
>> "1" < "-1"
>> [1] FALSE
>> 
>> "1" < "-"
>> [1] FALSE
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> 
>


From hb at biostat.ucsf.edu  Sun Nov 23 01:05:33 2014
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Sat, 22 Nov 2014 16:05:33 -0800
Subject: [Rd] R string comparisons may vary with platform (plain text)
In-Reply-To: <5470F51F.1000802@gmail.com>
References: <D0962B34.6441%sambler@linkedin.com> <5470F51F.1000802@gmail.com>
Message-ID: <CAFDcVCQeXKWL87wOzpa=7pX1nMe91b73VxOC5=3Fby9M8U+2Hg@mail.gmail.com>

On Sat, Nov 22, 2014 at 12:42 PM, Duncan Murdoch
<murdoch.duncan at gmail.com> wrote:
> On 22/11/2014, 2:59 PM, Stuart Ambler wrote:
>> A colleague?s R program behaved differently when I ran it, and we thought
>> we traced it probably to different results from string comparisons as
>> below, with different R versions.  However the platforms also differed.  A
>> friend ran it on a few machines and found that the comparison behavior
>> didn?t correlate with R version, but rather with platform.
>>
>> I wonder if you?ve seen this.  If it?s not some setting I?m unaware of,
>> maybe someone should look into it.  Sorry I haven?t taken the time to read
>> the source code myself.
>
> Looks like a collation order issue.  See ?Comparison.

With the oddity that both platforms use what look like similar locales:

LC_COLLATE=en_US.UTF-8
LC_COLLATE=en_US.utf8

/Henrik

>
> Duncan Murdoch
>
>> Thanks,
>> Stuart
>>
>> R version 3.0.2 (2013-09-25) -- "Frisbee Sailing"
>> Platform: x86_64-unknown-linux-gnu (64-bit)
>> Sys.getlocale()
>> [1]
>> "LC_CTYPE=en_US.UTF-8;LC_NUMERIC=C;LC_TIME=en_US.UTF-8;LC_COLLATE=en_US.UTF
>> -8;LC_MONETARY=en_US.UTF-8;LC_MESSAGES=en_US.UTF-8;LC_PAPER=en_US.UTF-8;LC_
>> NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=en_US.UTF-8;LC_IDENTIFICA
>> TION=C"
>>
>> "-1" > "1"
>> [1] TRUE
>>
>> "-1" <"1"
>> [1] FALSE
>>
>> "1" < "-1"
>> [1] TRUE
>>
>> "1" < "-"
>> [1] FALSE
>>
>> Vs.
>>
>> R version 3.1.1 (2014-07-10) ? ?Sock it to Me"
>> Platform: x86_64-redhat-linux-gnu (64-bit)
>> Sys.getlocale()
>> [1]
>> "LC_CTYPE=en_US.utf8;LC_NUMERIC=C;LC_TIME=en_US.utf8;LC_COLLATE=en_US.utf8
>> ;LC_MONETARY=en_US.utf8;LC_MESSAGES=en_US.utf8;LC_PAPER=en_US.utf8;LC_NAME
>> =C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=en_US.utf8;LC_IDENTIFICATION
>> =C"
>>
>> "-1" > "1"
>> [1] FALSE
>>
>> "-1" <"1"
>> [1] TRUE
>>
>> "1" < "-1"
>> [1] FALSE
>>
>> "1" < "-"
>> [1] FALSE
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From hb at biostat.ucsf.edu  Sun Nov 23 02:41:25 2014
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Sat, 22 Nov 2014 17:41:25 -0800
Subject: [Rd] Rprof(...,
	memory.profiling=TRUE) to profile C memory allocation?
Message-ID: <CAFDcVCSV1BXP53PBrU1TFANtLF5CXqpVG8W_P5kJrSg1u-cu-A@mail.gmail.com>

Could someone please confirm/refute that Rprof(...,
memory.profiling=TRUE) can also be used to profile memory allocation
done in a C function (src/*.c) that uses, e.g.

  allocVector(INTSXP, n)

but also allocations such as

 R_alloc(n, sizeof(int))

?

Modulo how R was built, does the answer depend on OS?  I'm interested
in all the major ones (Linux, OS X and Windows).

Thanks,

Henrik


From pdalgd at gmail.com  Sun Nov 23 10:39:09 2014
From: pdalgd at gmail.com (peter dalgaard)
Date: Sun, 23 Nov 2014 10:39:09 +0100
Subject: [Rd] R string comparisons may vary with platform (plain text)
In-Reply-To: <CAFDcVCQeXKWL87wOzpa=7pX1nMe91b73VxOC5=3Fby9M8U+2Hg@mail.gmail.com>
References: <D0962B34.6441%sambler@linkedin.com> <5470F51F.1000802@gmail.com>
	<CAFDcVCQeXKWL87wOzpa=7pX1nMe91b73VxOC5=3Fby9M8U+2Hg@mail.gmail.com>
Message-ID: <26A0DFF7-0E3C-4062-AE73-F7C0052E3380@gmail.com>


> On 23 Nov 2014, at 01:05 , Henrik Bengtsson <hb at biostat.ucsf.edu> wrote:
> 
> On Sat, Nov 22, 2014 at 12:42 PM, Duncan Murdoch
> <murdoch.duncan at gmail.com> wrote:
>> On 22/11/2014, 2:59 PM, Stuart Ambler wrote:
>>> A colleague?s R program behaved differently when I ran it, and we thought
>>> we traced it probably to different results from string comparisons as
>>> below, with different R versions.  However the platforms also differed.  A
>>> friend ran it on a few machines and found that the comparison behavior
>>> didn?t correlate with R version, but rather with platform.
>>> 
>>> I wonder if you?ve seen this.  If it?s not some setting I?m unaware of,
>>> maybe someone should look into it.  Sorry I haven?t taken the time to read
>>> the source code myself.
>> 
>> Looks like a collation order issue.  See ?Comparison.
> 
> With the oddity that both platforms use what look like similar locales:
> 
> LC_COLLATE=en_US.UTF-8
> LC_COLLATE=en_US.utf8

It's the sort of thing thay I've tried to wrap my mind around multiple times and failed, but have a look at

http://stackoverflow.com/questions/19967555/postgres-collation-differences-osx-v-ubuntu

which seems to be essentially the same issue, just for Postgres. If you have the stamina, also look into the python question that it links to.

As I understand it, there are two potential reasons: Either the two platforms are not using the same collation table for en_US, or at least one of them is not fully implementing the Unicode Collation Algorithm.

In general, collation is a minefield: Some languages have the same letters in different order (e.g. Estonian with Z between S and T); accented characters sort with the unaccented counterpart in some languages but as separate characters in others; some locales sort ABab, others AaBb, yet others aAbB; sometimes punctuation is ignored, sometimes not; sometimes multiple characters count as one, etc.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From ripley at stats.ox.ac.uk  Sun Nov 23 12:44:10 2014
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 23 Nov 2014 11:44:10 +0000
Subject: [Rd] R string comparisons may vary with platform (plain text)
In-Reply-To: <26A0DFF7-0E3C-4062-AE73-F7C0052E3380@gmail.com>
References: <D0962B34.6441%sambler@linkedin.com>
	<5470F51F.1000802@gmail.com>	<CAFDcVCQeXKWL87wOzpa=7pX1nMe91b73VxOC5=3Fby9M8U+2Hg@mail.gmail.com>
	<26A0DFF7-0E3C-4062-AE73-F7C0052E3380@gmail.com>
Message-ID: <5471C88A.10902@stats.ox.ac.uk>

On 23/11/2014 09:39, peter dalgaard wrote:
>
>> On 23 Nov 2014, at 01:05 , Henrik Bengtsson <hb at biostat.ucsf.edu> wrote:
>>
>> On Sat, Nov 22, 2014 at 12:42 PM, Duncan Murdoch
>> <murdoch.duncan at gmail.com> wrote:
>>> On 22/11/2014, 2:59 PM, Stuart Ambler wrote:
>>>> A colleague?s R program behaved differently when I ran it, and we thought
>>>> we traced it probably to different results from string comparisons as
>>>> below, with different R versions.  However the platforms also differed.  A
>>>> friend ran it on a few machines and found that the comparison behavior
>>>> didn?t correlate with R version, but rather with platform.
>>>>
>>>> I wonder if you?ve seen this.  If it?s not some setting I?m unaware of,
>>>> maybe someone should look into it.  Sorry I haven?t taken the time to read
>>>> the source code myself.
>>>
>>> Looks like a collation order issue.  See ?Comparison.
>>
>> With the oddity that both platforms use what look like similar locales:
>>
>> LC_COLLATE=en_US.UTF-8
>> LC_COLLATE=en_US.utf8
>
> It's the sort of thing thay I've tried to wrap my mind around multiple times and failed, but have a look at
>
> http://stackoverflow.com/questions/19967555/postgres-collation-differences-osx-v-ubuntu
>
> which seems to be essentially the same issue, just for Postgres. If you have the stamina, also look into the python question that it links to.
>
> As I understand it, there are two potential reasons: Either the two platforms are not using the same collation table for en_US, or at least one of them is not fully implementing the Unicode Collation Algorithm.

And I have seen both with R.  At the very least, check if ICU is being 
used (capabilities("ICU") in current R, maybe not in some of the 
obsolete versions seen in this thread).

As a further possibility, there are choices in the UCA (in R, see 
?icuSetCollate) and ICU can be compiled with different default choices. 
  It is not clear to me what (if any) difference ICU versions make, but 
in R-devel extSoftVersion() reports that.


> In general, collation is a minefield: Some languages have the same letters in different order (e.g. Estonian with Z between S and T); accented characters sort with the unaccented counterpart in some languages but as separate characters in others; some locales sort ABab, others AaBb, yet others aAbB; sometimes punctuation is ignored, sometimes not; sometimes multiple characters count as one, etc.
>
As ?Comparison has long said.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From mtmorgan at fredhutch.org  Sun Nov 23 17:15:27 2014
From: mtmorgan at fredhutch.org (Martin Morgan)
Date: Sun, 23 Nov 2014 08:15:27 -0800
Subject: [Rd] R string comparisons may vary with platform (plain text)
In-Reply-To: <5471C88A.10902@stats.ox.ac.uk>
References: <D0962B34.6441%sambler@linkedin.com>	<5470F51F.1000802@gmail.com>	<CAFDcVCQeXKWL87wOzpa=7pX1nMe91b73VxOC5=3Fby9M8U+2Hg@mail.gmail.com>	<26A0DFF7-0E3C-4062-AE73-F7C0052E3380@gmail.com>
	<5471C88A.10902@stats.ox.ac.uk>
Message-ID: <5472081F.7020702@fredhutch.org>


For many scientific applications one is really dealing with ASCII characters and 
LC_COLLATE="C", even if the user is running in non-C locales. What robust 
approaches (if any?) are available to write code that sorts in a 
locale-independent way? The Note in ?Sys.setlocale is not overly optimistic 
about setting the locale within a session.

Martin Morgan

On 11/23/2014 03:44 AM, Prof Brian Ripley wrote:
> On 23/11/2014 09:39, peter dalgaard wrote:
>>
>>> On 23 Nov 2014, at 01:05 , Henrik Bengtsson <hb at biostat.ucsf.edu> wrote:
>>>
>>> On Sat, Nov 22, 2014 at 12:42 PM, Duncan Murdoch
>>> <murdoch.duncan at gmail.com> wrote:
>>>> On 22/11/2014, 2:59 PM, Stuart Ambler wrote:
>>>>> A colleague?s R program behaved differently when I ran it, and we thought
>>>>> we traced it probably to different results from string comparisons as
>>>>> below, with different R versions.  However the platforms also differed.  A
>>>>> friend ran it on a few machines and found that the comparison behavior
>>>>> didn?t correlate with R version, but rather with platform.
>>>>>
>>>>> I wonder if you?ve seen this.  If it?s not some setting I?m unaware of,
>>>>> maybe someone should look into it.  Sorry I haven?t taken the time to read
>>>>> the source code myself.
>>>>
>>>> Looks like a collation order issue.  See ?Comparison.
>>>
>>> With the oddity that both platforms use what look like similar locales:
>>>
>>> LC_COLLATE=en_US.UTF-8
>>> LC_COLLATE=en_US.utf8
>>
>> It's the sort of thing thay I've tried to wrap my mind around multiple times
>> and failed, but have a look at
>>
>> http://stackoverflow.com/questions/19967555/postgres-collation-differences-osx-v-ubuntu
>>
>>
>> which seems to be essentially the same issue, just for Postgres. If you have
>> the stamina, also look into the python question that it links to.
>>
>> As I understand it, there are two potential reasons: Either the two platforms
>> are not using the same collation table for en_US, or at least one of them is
>> not fully implementing the Unicode Collation Algorithm.
>
> And I have seen both with R.  At the very least, check if ICU is being used
> (capabilities("ICU") in current R, maybe not in some of the obsolete versions
> seen in this thread).
>
> As a further possibility, there are choices in the UCA (in R, see
> ?icuSetCollate) and ICU can be compiled with different default choices.  It is
> not clear to me what (if any) difference ICU versions make, but in R-devel
> extSoftVersion() reports that.
>
>
>> In general, collation is a minefield: Some languages have the same letters in
>> different order (e.g. Estonian with Z between S and T); accented characters
>> sort with the unaccented counterpart in some languages but as separate
>> characters in others; some locales sort ABab, others AaBb, yet others aAbB;
>> sometimes punctuation is ignored, sometimes not; sometimes multiple characters
>> count as one, etc.
>>
> As ?Comparison has long said.
>
>


-- 
Computational Biology / Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N.
PO Box 19024 Seattle, WA 98109

Location: Arnold Building M1 B861
Phone: (206) 667-2793


From hb at biostat.ucsf.edu  Mon Nov 24 01:07:44 2014
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Sun, 23 Nov 2014 16:07:44 -0800
Subject: [Rd] Error "promise already under evaluation ..." with
 function(x, dim=dim(x))
In-Reply-To: <5467214D.1060502@gmail.com>
References: <CAFDcVCQtz0HMknNVv16jYatLwk26EhtayKmE7-jzbt-sRyS6CA@mail.gmail.com>
	<5467214D.1060502@gmail.com>
Message-ID: <CAFDcVCRHs2+YrssVzMFuSu9=QtJdN9XbG0xgXQVvb7Py5pAeTQ@mail.gmail.com>

On Sat, Nov 15, 2014 at 1:47 AM, Duncan Murdoch
<murdoch.duncan at gmail.com> wrote:
>
> On 14/11/2014, 9:06 PM, Henrik Bengtsson wrote:
> > I've meant to ask the following for several years now.  I understand why:
> >
> >> foo <- function(x, dim=dim) { dim }
> >> foo(1)
> > Error in foo(1) :
> >   promise already under evaluation: recursive default argument
> > reference or earlier problems?
> >
> > gives an error, but why wouldn't/couldn't the following work?
> >
> >> foo <- function(x, dim=dim(x)) { dim }
> >> foo(1)
> > Error in foo(1) :
> >   promise already under evaluation: recursive default argument
> > reference or earlier problems?
>
> You refer to "dim".  There's a dim defined in the argument list, so R
> uses that definition of it.
>
> But you didn't supply any value, so it tries to evaluate the default
> value.  Default expressions are always evaluated in the evaluation frame
> of the function call, so it looks for a function named "dim" in the
> local frame.
>
> It finds the argument in the local frame, so it tries to figure out if
> it is a function or a value.  It needs to evaluate it to do that, and
> you get the recursion.
>
> >
> > As a workaround I also tried:
> >
> >> foo <- function(x, dim) { if (missing(dim)) dim <- dim(x); dim }
> >> foo(1)
> > Error in foo(1) : argument "dim" is missing, with no default
> >
> > which surprised me too.
> >
> >
> > For the first case, is the rationale related to:
> >
> >> foo <- function(x, a=dim(x), dim) { a }
> >> foo(1)
> > Error in foo(1) : argument "dim" is missing, with no default
> >
> > and
> >
> >> foo <- function(x, a=dim(x), dim=a) { a }
> >> foo(1)
> > Error in foo(1) :
> >   promise already under evaluation: recursive default argument
> > reference or earlier problems?
> >
> > [since here argument 'dim' could take a function, e.g. foo(1,
> > dim=length)], and that R treats
> >
> > foo <- function(x, dim=dim(x)) { dim }
> >
> > in a similar way?  That is, is R not "clever" enough to detect this as
> > a special case, but instead goes ahead and tries to evaluate the
> > default expression (=dim(x)) of argument 'dim' in order to get its
> > default value?  If so, is there anything preventing R from support
> > this "special case", e.g. by evaluating the default expression without
> > argument/symbol 'dim' itself being in the picture to avoid "it finds
> > itself"?  (Sorry if I'm using the incorrect words here).
>
> No, it shouldn't do that.  It should use consistent rules for evaluation
> or there would be sure to be bugs.
>
> >
> > Yes, I understand that I can do:
> >
> >> foo <- function(x, dim=base::dim(x)) { dim }
>
> This is what you should do.
>
> >> foo(1)
> > NULL
> >
> >> foo <- function(x, dim=NULL) { if (is.null(dim)) dim <- dim(x); dim }
>
> This works, because when R is looking up the function dim(), it can
> evaluate the local argument dim and see it is not a function, so it
> proceeds to the parent frame.
>
> >> foo(1)
> > NULL
> >
> > or
> >
> >> foo <- function(x, dim.=dim(x)) { dim. }
> >> foo(1)
> > NULL
>
> This is another solution that works, but it has the ugly argument name
> now, so you'll get warnings during package checks from calls like
>
> foo(1, dim=2)
>
> >
> > but I would prefer not to have to turn those rather ad hoc solutions in my code.
>
> Nothing ad hoc about the first one.

Thanks for the feedback.  I agree that base::dim(x) is clean and
clear, but unfortunately there is a ~500 times overhead in using '::'.
Since I went through the effort of doing the benchmarking and find
faster solutions, I'm sharing the following:

> library("microbenchmark")

> x <- matrix(1:(80*80), nrow=80)

> # Not "legal", because it calls .Primitive().
> dim_illegal <- base::dim

> dim_R <- function(x) {
+   ns <- getNamespace("base")
+   dim <- get("dim", envir=ns, inherits=FALSE, mode="function")
+   dim(x)
+ }

> dim_R_memoized <- local({
+   dim <- NULL
+   function(x) {
+     if (is.null(dim)) {
+       dim <<- get("dim", envir=getNamespace("base"), inherits=FALSE,
mode="function")
+     }
+     dim(x)
+   }
+ })

> stats <- microbenchmark(
+   dim(x),
+   base::dim(x),
+   dim_R(x),
+   dim_R_memoized(x),
+   dim_illegal(x),
+   sum(x),
+   unit="ns",
+   times=10e3
+ )
Warning message:
In microbenchmark(dim(x), base::dim(x), dim_R(x), dim_R_memoized(x),  :
  Could not measure a positive execution time for 3859 evaluations.

> print(stats)
Unit: nanoseconds
              expr  min   lq       mean median    uq     max neval   cld
            dim(x)    0    0    25.2226      1     1   10780 10000 a
      base::dim(x) 6545 7700 10429.0165   8470 12897 2678155 10000     e
          dim_R(x) 3080 3851  5163.8612   4236  6545   55435 10000   c
 dim_R_memoized(x)  385  771  1238.8292   1156  1541   44656 10000  b
    dim_illegal(x)    0    1    51.4421      1     1    5775 10000 a
            sum(x) 8085 8470  9590.9570   8470 10395   49660 10000    d

Yes, yes, the extra cost of using base::dim(x) is only ~10 us, but if
you do, say, a million bootstrap samples calling this function, that's
an extra unnecessary 10 seconds of processing time.  As a comparison,
the overhead is roughly the same as summing 6400 integers.

For workarounds, I considered:

(a) dim_illegal
(b) dim_R
(c) dim_R_memoized

where,

(a) would be "good enough", but can immediately be discarded because
if used in a package, it will create a copy of base::dim and thereby
call .Primitive() immediately, which is unsafe.

(b) is a poor-mans version of try to cut the corners of '::', but
there is still a substantial overhead in each call, but still a 25-50%
speedup compared to '::'.

(c) is a smarter version of (b) that does the look up only ones, and
managed to reduce the overhead to 10% of '::'.  It's still 50 times
the overhead of a direct dim(x) call.

Since one can byte compile packages (ByteCompile: TRUE in
DESCRIPTION), I've also played around with compiler::cmpfun() and that
prunes off about 10% of the non-compiled ditto.  I was
somewhat/naively hoping that the compiler would be able to compile
base::dim into a "constant", but that doesn't seem to be the case.


BTW, is the following, which is ~2 times as fast as dim_R_memoized(),
valid in an R package?   Will it set the local 'dim' variable when the
package is loaded, which I assume is safe/legal, or before?  I didn't
include it above, because I wasn't sure it was safe/valid.

dim_R_memoized_2 <- local({
  dim_local <- base::dim
  function(x) dim_local(x)
})


Thanks,

/Henrik


>
> Duncan Murdoch
>
> >
> >
> > Thanks,
> >
> > Henrik
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
>


From hb at biostat.ucsf.edu  Mon Nov 24 01:42:35 2014
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Sun, 23 Nov 2014 16:42:35 -0800
Subject: [Rd] Error "promise already under evaluation ..." with
 function(x, dim=dim(x))
In-Reply-To: <CAFDcVCRHs2+YrssVzMFuSu9=QtJdN9XbG0xgXQVvb7Py5pAeTQ@mail.gmail.com>
References: <CAFDcVCQtz0HMknNVv16jYatLwk26EhtayKmE7-jzbt-sRyS6CA@mail.gmail.com>
	<5467214D.1060502@gmail.com>
	<CAFDcVCRHs2+YrssVzMFuSu9=QtJdN9XbG0xgXQVvb7Py5pAeTQ@mail.gmail.com>
Message-ID: <CAFDcVCSFGg9_Kme4sGX-_2y_r=PJU_cE+7V=evAT1dUkh4byHA@mail.gmail.com>

On Sun, Nov 23, 2014 at 4:07 PM, Henrik Bengtsson <hb at biostat.ucsf.edu> wrote:
> On Sat, Nov 15, 2014 at 1:47 AM, Duncan Murdoch
> <murdoch.duncan at gmail.com> wrote:
>>
>> On 14/11/2014, 9:06 PM, Henrik Bengtsson wrote:
>> > I've meant to ask the following for several years now.  I understand why:
>> >
>> >> foo <- function(x, dim=dim) { dim }
>> >> foo(1)
>> > Error in foo(1) :
>> >   promise already under evaluation: recursive default argument
>> > reference or earlier problems?
>> >
>> > gives an error, but why wouldn't/couldn't the following work?
>> >
>> >> foo <- function(x, dim=dim(x)) { dim }
>> >> foo(1)
>> > Error in foo(1) :
>> >   promise already under evaluation: recursive default argument
>> > reference or earlier problems?
>>
>> You refer to "dim".  There's a dim defined in the argument list, so R
>> uses that definition of it.
>>
>> But you didn't supply any value, so it tries to evaluate the default
>> value.  Default expressions are always evaluated in the evaluation frame
>> of the function call, so it looks for a function named "dim" in the
>> local frame.
>>
>> It finds the argument in the local frame, so it tries to figure out if
>> it is a function or a value.  It needs to evaluate it to do that, and
>> you get the recursion.
>>
>> >
>> > As a workaround I also tried:
>> >
>> >> foo <- function(x, dim) { if (missing(dim)) dim <- dim(x); dim }
>> >> foo(1)
>> > Error in foo(1) : argument "dim" is missing, with no default
>> >
>> > which surprised me too.
>> >
>> >
>> > For the first case, is the rationale related to:
>> >
>> >> foo <- function(x, a=dim(x), dim) { a }
>> >> foo(1)
>> > Error in foo(1) : argument "dim" is missing, with no default
>> >
>> > and
>> >
>> >> foo <- function(x, a=dim(x), dim=a) { a }
>> >> foo(1)
>> > Error in foo(1) :
>> >   promise already under evaluation: recursive default argument
>> > reference or earlier problems?
>> >
>> > [since here argument 'dim' could take a function, e.g. foo(1,
>> > dim=length)], and that R treats
>> >
>> > foo <- function(x, dim=dim(x)) { dim }
>> >
>> > in a similar way?  That is, is R not "clever" enough to detect this as
>> > a special case, but instead goes ahead and tries to evaluate the
>> > default expression (=dim(x)) of argument 'dim' in order to get its
>> > default value?  If so, is there anything preventing R from support
>> > this "special case", e.g. by evaluating the default expression without
>> > argument/symbol 'dim' itself being in the picture to avoid "it finds
>> > itself"?  (Sorry if I'm using the incorrect words here).
>>
>> No, it shouldn't do that.  It should use consistent rules for evaluation
>> or there would be sure to be bugs.
>>
>> >
>> > Yes, I understand that I can do:
>> >
>> >> foo <- function(x, dim=base::dim(x)) { dim }
>>
>> This is what you should do.
>>
>> >> foo(1)
>> > NULL
>> >
>> >> foo <- function(x, dim=NULL) { if (is.null(dim)) dim <- dim(x); dim }
>>
>> This works, because when R is looking up the function dim(), it can
>> evaluate the local argument dim and see it is not a function, so it
>> proceeds to the parent frame.
>>
>> >> foo(1)
>> > NULL
>> >
>> > or
>> >
>> >> foo <- function(x, dim.=dim(x)) { dim. }
>> >> foo(1)
>> > NULL
>>
>> This is another solution that works, but it has the ugly argument name
>> now, so you'll get warnings during package checks from calls like
>>
>> foo(1, dim=2)
>>
>> >
>> > but I would prefer not to have to turn those rather ad hoc solutions in my code.
>>
>> Nothing ad hoc about the first one.
>
> Thanks for the feedback.  I agree that base::dim(x) is clean and
> clear, but unfortunately there is a ~500 times overhead in using '::'.
> Since I went through the effort of doing the benchmarking and find
> faster solutions, I'm sharing the following:
>
>> library("microbenchmark")
>
>> x <- matrix(1:(80*80), nrow=80)
>
>> # Not "legal", because it calls .Primitive().
>> dim_illegal <- base::dim
>
>> dim_R <- function(x) {
> +   ns <- getNamespace("base")
> +   dim <- get("dim", envir=ns, inherits=FALSE, mode="function")
> +   dim(x)
> + }
>
>> dim_R_memoized <- local({
> +   dim <- NULL
> +   function(x) {
> +     if (is.null(dim)) {
> +       dim <<- get("dim", envir=getNamespace("base"), inherits=FALSE,
> mode="function")
> +     }
> +     dim(x)
> +   }
> + })
>
>> stats <- microbenchmark(
> +   dim(x),
> +   base::dim(x),
> +   dim_R(x),
> +   dim_R_memoized(x),
> +   dim_illegal(x),
> +   sum(x),
> +   unit="ns",
> +   times=10e3
> + )
> Warning message:
> In microbenchmark(dim(x), base::dim(x), dim_R(x), dim_R_memoized(x),  :
>   Could not measure a positive execution time for 3859 evaluations.
>
>> print(stats)
> Unit: nanoseconds
>               expr  min   lq       mean median    uq     max neval   cld
>             dim(x)    0    0    25.2226      1     1   10780 10000 a
>       base::dim(x) 6545 7700 10429.0165   8470 12897 2678155 10000     e
>           dim_R(x) 3080 3851  5163.8612   4236  6545   55435 10000   c
>  dim_R_memoized(x)  385  771  1238.8292   1156  1541   44656 10000  b
>     dim_illegal(x)    0    1    51.4421      1     1    5775 10000 a
>             sum(x) 8085 8470  9590.9570   8470 10395   49660 10000    d
>
> Yes, yes, the extra cost of using base::dim(x) is only ~10 us, but if
> you do, say, a million bootstrap samples calling this function, that's
> an extra unnecessary 10 seconds of processing time.  As a comparison,
> the overhead is roughly the same as summing 6400 integers.
>
> For workarounds, I considered:
>
> (a) dim_illegal
> (b) dim_R
> (c) dim_R_memoized
>
> where,
>
> (a) would be "good enough", but can immediately be discarded because
> if used in a package, it will create a copy of base::dim and thereby
> call .Primitive() immediately, which is unsafe.
>
> (b) is a poor-mans version of try to cut the corners of '::', but
> there is still a substantial overhead in each call, but still a 25-50%
> speedup compared to '::'.
>
> (c) is a smarter version of (b) that does the look up only ones, and
> managed to reduce the overhead to 10% of '::'.  It's still 50 times
> the overhead of a direct dim(x) call.
>
> Since one can byte compile packages (ByteCompile: TRUE in
> DESCRIPTION), I've also played around with compiler::cmpfun() and that
> prunes off about 10% of the non-compiled ditto.  I was
> somewhat/naively hoping that the compiler would be able to compile
> base::dim into a "constant", but that doesn't seem to be the case.
>
>
> BTW, is the following, which is ~2 times as fast as dim_R_memoized(),
> valid in an R package?   Will it set the local 'dim' variable when the
> package is loaded, which I assume is safe/legal, or before?  I didn't
> include it above, because I wasn't sure it was safe/valid.
>
> dim_R_memoized_2 <- local({
>   dim_local <- base::dim
>   function(x) dim_local(x)
> })

The above question still stands, but otherwise, I overlooked the most
obvious solution:

dim_1 <- function(x) dim(x)

which is favorable when benchmarked (~10 times slower than a direct
dim(x) call but otherwise the one of the fastest solutions):

Unit: nanoseconds
                  expr   min    lq      mean median    uq     max neval cld
                dim(x)     0     1    72.941      1     1    2696  1000 a
          base::dim(x) 11549 13474 15105.950  14245 15399   60824  1000   c
              dim_1(x)     1   771  2801.544    771  1156 1806225  1000 a
              dim_R(x)  5390  6930  8077.753   7315  8085  249069  1000  b
     dim_R_memoized(x)  1156  1926  2520.119   2310  2695   73528  1000 a
   dim_R_memoized_2(x)   385   771  1089.243    771  1156   20019  1000 a
        dim_illegal(x)     0     1   161.480      1   386    2311  1000 a
                sum(x) 10395 15784 16459.454  15785 16169  114333  1000   c


So, my best shot on the original problem would now be to either use:

dim2 <- function(x) dim(x)
foo <- function(x, dim=dim2(x)) { dim }

or simply avoid the name clash via:

foo <- function(x, dimx=dim(x)) { dimx }

/Henrik

>
>
> Thanks,
>
> /Henrik
>
>
>>
>> Duncan Murdoch
>>
>> >
>> >
>> > Thanks,
>> >
>> > Henrik
>> >
>> > ______________________________________________
>> > R-devel at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-devel
>> >
>>


From mark.vanderloo at gmail.com  Mon Nov 24 15:36:20 2014
From: mark.vanderloo at gmail.com (Mark van der Loo)
Date: Mon, 24 Nov 2014 15:36:20 +0100
Subject: [Rd] R string comparisons may vary with platform (plain text)
In-Reply-To: <5472081F.7020702@fredhutch.org>
References: <D0962B34.6441%sambler@linkedin.com> <5470F51F.1000802@gmail.com>
	<CAFDcVCQeXKWL87wOzpa=7pX1nMe91b73VxOC5=3Fby9M8U+2Hg@mail.gmail.com>
	<26A0DFF7-0E3C-4062-AE73-F7C0052E3380@gmail.com>
	<5471C88A.10902@stats.ox.ac.uk> <5472081F.7020702@fredhutch.org>
Message-ID: <CAOKDuOjfOhWH6siNX1wbk588W46b-t4f5bNeHAExks=Hp_eyJQ@mail.gmail.com>

The 'stringi' package claims robust cross-platform performance. It exports
much functionality of the ICU library and will attempt to install it when
not present.
The function 'stri_sort' accepts a collation argument that can be defined
with 'stri_opts_collator'.




On Sun, Nov 23, 2014 at 5:15 PM, Martin Morgan <mtmorgan at fredhutch.org>
wrote:

>
> For many scientific applications one is really dealing with ASCII
> characters and LC_COLLATE="C", even if the user is running in non-C
> locales. What robust approaches (if any?) are available to write code that
> sorts in a locale-independent way? The Note in ?Sys.setlocale is not overly
> optimistic about setting the locale within a session.
>
> Martin Morgan
>
>
> On 11/23/2014 03:44 AM, Prof Brian Ripley wrote:
>
>> On 23/11/2014 09:39, peter dalgaard wrote:
>>
>>>
>>>  On 23 Nov 2014, at 01:05 , Henrik Bengtsson <hb at biostat.ucsf.edu>
>>>> wrote:
>>>>
>>>> On Sat, Nov 22, 2014 at 12:42 PM, Duncan Murdoch
>>>> <murdoch.duncan at gmail.com> wrote:
>>>>
>>>>> On 22/11/2014, 2:59 PM, Stuart Ambler wrote:
>>>>>
>>>>>> A colleague?s R program behaved differently when I ran it, and we
>>>>>> thought
>>>>>> we traced it probably to different results from string comparisons as
>>>>>> below, with different R versions.  However the platforms also
>>>>>> differed.  A
>>>>>> friend ran it on a few machines and found that the comparison behavior
>>>>>> didn?t correlate with R version, but rather with platform.
>>>>>>
>>>>>> I wonder if you?ve seen this.  If it?s not some setting I?m unaware
>>>>>> of,
>>>>>> maybe someone should look into it.  Sorry I haven?t taken the time to
>>>>>> read
>>>>>> the source code myself.
>>>>>>
>>>>>
>>>>> Looks like a collation order issue.  See ?Comparison.
>>>>>
>>>>
>>>> With the oddity that both platforms use what look like similar locales:
>>>>
>>>> LC_COLLATE=en_US.UTF-8
>>>> LC_COLLATE=en_US.utf8
>>>>
>>>
>>> It's the sort of thing thay I've tried to wrap my mind around multiple
>>> times
>>> and failed, but have a look at
>>>
>>> http://stackoverflow.com/questions/19967555/postgres-
>>> collation-differences-osx-v-ubuntu
>>>
>>>
>>> which seems to be essentially the same issue, just for Postgres. If you
>>> have
>>> the stamina, also look into the python question that it links to.
>>>
>>> As I understand it, there are two potential reasons: Either the two
>>> platforms
>>> are not using the same collation table for en_US, or at least one of
>>> them is
>>> not fully implementing the Unicode Collation Algorithm.
>>>
>>
>> And I have seen both with R.  At the very least, check if ICU is being
>> used
>> (capabilities("ICU") in current R, maybe not in some of the obsolete
>> versions
>> seen in this thread).
>>
>> As a further possibility, there are choices in the UCA (in R, see
>> ?icuSetCollate) and ICU can be compiled with different default choices.
>> It is
>> not clear to me what (if any) difference ICU versions make, but in R-devel
>> extSoftVersion() reports that.
>>
>>
>>  In general, collation is a minefield: Some languages have the same
>>> letters in
>>> different order (e.g. Estonian with Z between S and T); accented
>>> characters
>>> sort with the unaccented counterpart in some languages but as separate
>>> characters in others; some locales sort ABab, others AaBb, yet others
>>> aAbB;
>>> sometimes punctuation is ignored, sometimes not; sometimes multiple
>>> characters
>>> count as one, etc.
>>>
>>>  As ?Comparison has long said.
>>
>>
>>
>
> --
> Computational Biology / Fred Hutchinson Cancer Research Center
> 1100 Fairview Ave. N.
> PO Box 19024 Seattle, WA 98109
>
> Location: Arnold Building M1 B861
> Phone: (206) 667-2793
>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From rich.r.maillist at gmail.com  Mon Nov 24 15:23:19 2014
From: rich.r.maillist at gmail.com (richard h)
Date: Mon, 24 Nov 2014 15:23:19 +0100
Subject: [Rd] tools::testInstalledBasic
Message-ID: <CACLL=1NSveCq_9v237pzSTK3fmfrJV7rkgx-o8eRagsR8FQnfQ@mail.gmail.com>

Dear users,

I have a problem when using the testInstalledBasic function in the tools
package on my windows 7 machine. I specified the environment variables as
stated in the Installation and administration manual (Sys.setenv(LC_COLLATE
= "C", LANGUAGE = "en")) and ran the function on an installation without
additional packages. However the test fails on the script "reg-tests-2.R".

I think that the problem is the fact that the local LC_ALL should be set to
"C" to correctly compare the results for read.csv("EmbeddedNuls.csv"). This
locale is set within the function however all test scripts are submitted
using CMD BATCH. Therefore setting the locale within the function seems to
have no effect. I tried setting the locale within Rprofile.site but within
CMD BATCH --vanilla is used. Are my assumptions correct and if so does
anybody know a solution for this problem?

Thank you,
Richard

sessionInfo:

R version 3.1.2 (2014-10-31)
Platform: i386-w64-mingw32/i386 (32-bit)

locale:
[1] LC_COLLATE=English_United States.1252
[2] LC_CTYPE=English_United States.1252
[3] LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C
[5] LC_TIME=English_United States.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

	[[alternative HTML version deleted]]


From radford at cs.toronto.edu  Mon Nov 24 19:46:02 2014
From: radford at cs.toronto.edu (Radford Neal)
Date: Mon, 24 Nov 2014 13:46:02 -0500
Subject: [Rd]  Error "promise already under evaluation ..."
In-Reply-To: <mailman.11.1416826806.27250.r-devel@r-project.org>
References: <mailman.11.1416826806.27250.r-devel@r-project.org>
Message-ID: <20141124184602.GA15277@cs.toronto.edu>

> The above question still stands, but otherwise, I overlooked the most
> obvious solution:
> 
> dim_1 <- function(x) dim(x)
> 
> Unit: nanoseconds
>                   expr   min    lq      mean median    uq     max neval cld
>                 dim(x)     0     1    72.941      1     1    2696  1000 a
>           base::dim(x) 11549 13474 15105.950  14245 15399   60824  1000   c
>               dim_1(x)     1   771  2801.544    771  1156 1806225  1000 a
>               dim_R(x)  5390  6930  8077.753   7315  8085  249069  1000  b
>      dim_R_memoized(x)  1156  1926  2520.119   2310  2695   73528  1000 a
>    dim_R_memoized_2(x)   385   771  1089.243    771  1156   20019  1000 a
>         dim_illegal(x)     0     1   161.480      1   386    2311  1000 a
>                 sum(x) 10395 15784 16459.454  15785 16169  114333  1000   c
> 
> So, my best shot on the original problem would now be to either use:
> 
> dim2 <- function(x) dim(x)
> foo <- function(x, dim=dim2(x)) { dim }
> 
> or simply avoid the name clash via:
> 
> foo <- function(x, dimx=dim(x)) { dimx }


I think you'll find that baseenv()$dim(x) and .BaseNamespaceEnv$dim(x)
are about 25 times faster than base::dim(x).  This doesn't seem like
it should be necessary...

   Radford


From spinuvit at gmail.com  Mon Nov 24 21:00:31 2014
From: spinuvit at gmail.com (Vitalie Spinu)
Date: Mon, 24 Nov 2014 12:00:31 -0800
Subject: [Rd] How to read variable nr of chars from a Server Socket?
Message-ID: <87d28ce5cw.fsf@gmail.com>



Hi,

I am trying to implement messaging protocol that doesn't pre-specify the
length of the message in the message header. In other words, I don't
know in advance when I will reach the end of the message.

I wrote C level parser for strings but when it came to reading from
connections I got stuck. API in Connections.h doesn't provide a pointer
to an existing connection and there seems to be absolutely no way to
read from connections at C level. Is that correct?


Alternatively I would be happy to accumulate the message into a string
at R level and then parse the message. Unfortunately `readChar` blocks
with *server* socket till all nchars have been received. For example:

   ss <- socketConnection(port = 4005, server = TRUE, open = "r+b")
   readChar(ss, 2000)

blocks on the second line till all 2000 chars were received.

The *client* connection doesn't block on read at all:

   cs <- socketConnection(port = 4005, server = FALSE, open = "r+b")
   readChar(ss, 2000)

quickly returns character(0) if there is nothing there.

So, can I make reading on server non-blocking as it is for client
connection?


Thanks,

   Vitalie


From georgi.boshnakov at manchester.ac.uk  Tue Nov 25 15:42:20 2014
From: georgi.boshnakov at manchester.ac.uk (Georgi Boshnakov)
Date: Tue, 25 Nov 2014 14:42:20 +0000
Subject: [Rd] problem with setGroupGeneric from package methods
Message-ID: <438D2EC9EAFE5946B2D5864670EA468E0157FAFE1D@MBXP01.ds.man.ac.uk>

Hi,

There seems to be a problem with setGroupGeneric() from package 'methods'. The symptoms are somewhat erratic, in the sense that small changes may lead to any of the following behaviours.

1.Package works without problems on Windows and installs on Linux but gives error when loaded with library().

2.Package installs on both systems and gives error when loaded on any of them.

3. Package builds but fails to install on both systems.

4.Package fails to build on both systems.

Other combinations, depending also on the R version occur, as well.
The package in question is a pure R package with no OS specific code.
The error message in all cases is:

Error in .setupMethodsTables(generic) :
  trying to get slot "group" from an object of a basic class ("NULL") with no slots
Error: package or namespace load failed for 'pctsData'


Similar problem has been  reported before at
http://stackoverflow.com/questions/12368439/defining-group-generic-functions-in-an-r-package
A solution given by Romain Francois was to enclose the offending code in evalqOnLoad() but this doesn't really solve the problem. 
The code in that question can serve as a minimal example and I have packed it in a package at 
http://www.maths.manchester.ac.uk/~gb/Rpackages/grgen_1.0.tar.gz
but that package gives the error at installation time and I do not know how to debug with the command line tools. 
The example below is with my local package which installs and gives the same error at attach time (I will make it available, together with its dependencies, if needed).

> sessionInfo()
R version 3.1.2 (2014-10-31)
Platform: x86_64-unknown-linux-gnu (64-bit)         (actually, Fedora)

locale:
 [1] LC_CTYPE=en_GB.UTF-8       LC_NUMERIC=C
 [3] LC_TIME=en_GB.UTF-8        LC_COLLATE=en_GB.UTF-8
 [5] LC_MONETARY=en_GB.UTF-8    LC_MESSAGES=en_GB.UTF-8
 [7] LC_PAPER=en_GB.UTF-8       LC_NAME=C
 [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_GB.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base



> library(pctsData)

In one of the cases when the package installs  the problem seems to appear after

cacheMetaData -> .updateMethodsInTable -> .updateMethodsInTable -> .setupMethodsTables 

in one of the recursive calls to updateMethodsInTable (the place is marked with !!! towards the end of the code below). 
At the time of the error in .setupMethodsTables(generic)   'generic' is  NULL and  generic at group fails. The calling stack shown by the recover facility is this:

===========================================
Enter a frame number, or 0 to exit

 1: library(pctsData)
 2: try({
    ns <- loadNamespace(package, c(which.lib.loc, lib.loc))
    env <-
 3: tryCatch(expr, error = function(e) {
    call <- conditionCall(e)
    if (!is
 4: tryCatchList(expr, classes, parentenv, handlers)
 5: tryCatchOne(expr, names, parentenv, handlers[[1]])
 6: doTryCatch(return(expr), name, parentenv, handler)
 7: loadNamespace(package, c(which.lib.loc, lib.loc))
 8: methods:::cacheMetaData(ns, TRUE, ns)
 9: .updateMethodsInTable(fdef, where, attach)
10: .updateMethodsInTable(getGeneric(g), where, attach)
11: .setupMethodsTables(generic)

==============================================

On a different Linux machine and R version (the standard faculty wide installation),  library(pctsData) completes fine but package "grgen" mentioned above still gives the error at installation time.
The session info for this case:

R version 3.0.2 (2013-09-25)
Platform: x86_64-redhat-linux-gnu (64-bit)

locale:
 [1] LC_CTYPE=en_GB.UTF-8       LC_NUMERIC=C              
 [3] LC_TIME=en_GB.UTF-8        LC_COLLATE=en_GB.UTF-8    
 [5] LC_MONETARY=en_GB.UTF-8    LC_MESSAGES=en_GB.UTF-8   
 [7] LC_PAPER=en_GB.UTF-8       LC_NAME=C                 
 [9] LC_ADDRESS=C               LC_TELEPHONE=C            
[11] LC_MEASUREMENT=en_GB.UTF-8 LC_IDENTIFICATION=C       

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] pctsData_0.0-3

loaded via a namespace

====================================================

Further details are after the signature below.

Georgi

--
Dr Georgi Boshnakov               tel: (+44) (0)161 306 3684
School of Mathematics             fax: (+44) (0)161 306 3669
Alan Turing Building 1.125
The University of Manchester      email: Georgi.Boshnakov at manchester.ac.uk
Oxford Road
Manchester M13 9PL
UK

====================================================

Here is the relevant code from my package code. 
When I narrowed down the cause of the problem to setGroupGeneric, I found the following commented out excerpt, probably the error was the same. A change in the syntax back then removed the problem.

## 2011-07-07 I was not able to compile pcts properly since R moved from 2.7.x to 2.8.x.
##            Today I finally investigated and discovered that the reason is something to do
##            with the group generic. I looked in the sources of package "methods" for the
##            way group generics are defined and switched to using argument "known members"
##            (see below) instead of the following commands.

## setGroupGeneric("pcfData", function(x) NULL)
## setGeneric("pc.nseasons"        , group="pcfData")  # ima setGeneric i pri pcSeason. Check!
## setGeneric("pc.nepochs"         , group="pcfData")
## setGeneric("pc.nvariables"      , group="pcfData")
## setGeneric("pc.namesofseasons"  , group="pcfData")
## setGeneric("pc.namesofvariables", group="pcfData")
## setGeneric("pc.data.matrix"     , group="pcfData")
## setGeneric("pc.data.vec"        , group="pcfData")
## setGeneric("pc.data.Vec"        , group="pcfData")
## setGeneric("pc.data.tsvec"      , group="pcfData")
## setGeneric("pc.data.tsVec"      , group="pcfData")
# setGeneric("",group="pcfData")

setGeneric("pc.nepochs"         )
setGeneric("pc.nvariables"      )
setGeneric("pc.namesofseasons"  )
setGeneric("pc.namesofvariables")
setGeneric("pc.data.matrix"     )
setGeneric("pc.data.vec"        )
setGeneric("pc.data.Vec"        )
setGeneric("pc.data.tsvec"      )
setGeneric("pc.data.tsVec"      )

## 2014-11-24 modifying since causes problems on Linux (cannot load the package).
##                     no luck.
## setGroupGeneric("pcfData", function(x) NULL
##                 , knownMembers = c("pc.nepochs"
##                                  , "pc.nvariables"
##                                  , "pc.namesofseasons"
##                                  , "pc.namesofvariables"
##                                  , "pc.data.matrix"
##                                  , "pc.data.vec"
##                                  , "pc.data.Vec"
##                                  , "pc.data.tsvec"
##                                  , "pc.data.tsVec"
##                 ))

pcfData <- function(x) NULL
setGeneric("pcfData")

setGroupGeneric("pcfData", # def = function(x) NULL,
                knownMembers = c("pc.nepochs"
                                  , "pc.nvariables"
                                  , "pc.namesofseasons"
                                  , "pc.namesofvariables"
                                  , "pc.data.matrix"
                                  , "pc.data.vec"
                                  , "pc.data.Vec"
                                  , "pc.data.tsvec"
                                  , "pc.data.tsVec"
                                 ),
                where = topenv()
                )


#########################################################
Related code from "methods" package:

cacheMetaData <-
    function(where, attach = TRUE, searchWhere = as.environment(where),
             doCheck = TRUE)
{
    ## a collection of actions performed on attach or detach
    ## to update class and method information.
    pkg <- getPackageName(where)
    classes <- getClasses(where)
    for(cl in classes) {
        cldef <- (if(attach) get(classMetaName(cl), where) # NOT getClassDef, it will use cache
                  else  getClassDef(cl, searchWhere))
        if(is(cldef, "classRepresentation")) {
            if(attach) {
                .cacheClass(cl, cldef, is(cldef, "ClassUnionRepresentation"), where)
            }
            else if(identical(cldef at package, pkg)) {
                .uncacheClass(cl, cldef)
                .removeSuperclassBackRefs(cl, cldef, searchWhere)
            }
        }
    }
    generics <- .getGenerics(where)
    packages <- attr(generics, "package")
    if(length(packages) <  length(generics))
        packages <- rep(packages, length.out = length(generics))
    if(attach && exists(".requireCachedGenerics", where, inherits = FALSE)) {
        others <- get(".requireCachedGenerics", where)
        generics <- c(generics, others)
        packages <- c(packages, attr(others, "package"))
    }
    ## check for duplicates
    dups <- duplicated(generics) & duplicated(packages)
    generics <- generics[!dups]
    for(i in seq_along(generics)) {
        f <- generics[[i]]
        fpkg <- packages[[i]]
        if(!identical(fpkg, pkg) && doCheck) {
            if(attach) {
                env <- as.environment(where)
                ## All instances of this generic in different attached packages must
                ## agree with the cached version of the generic for consistent
                ## method selection.
                if(exists(f, envir = env, inherits = FALSE)) {
                    def <- get(f, envir = env)
                    fdef <- .genericOrImplicit(f, fpkg, env)
                    if(is.function(def)) {
                        ## exclude a non-function of the same name as a primitive with methods (!)
                        if(identical(environment(def), environment(fdef)))
                            next        # the methods are identical
                        else if( is(fdef, "genericFunction")) {
                            .assignOverBinding(f, fdef,  env, FALSE)
                        }
                    }     # else, go ahead to update primitive methods
                }
                else          # either imported generic or a primitive
                    fdef <- getGeneric(f, FALSE, searchWhere, fpkg)
            }
            else
                fdef <- getGeneric(f, FALSE, searchWhere, fpkg)
        }
        else
            fdef <- getGeneric(f, FALSE, searchWhere, fpkg)
        if(!is(fdef, "genericFunction"))
            next ## silently ignores all generics not visible from searchWhere
        if(attach)
            .cacheGeneric(f, fdef)
        else
            .uncacheGeneric(f, fdef)
        methods <- .updateMethodsInTable(fdef, where, attach)          ### !!!
        cacheGenericsMetaData(f, fdef, attach, where, fdef at package, methods)
    }
    .doLoadActions(where, attach)
    invisible(NULL) ## as some people call this at the end of functions
}

###############

# add objects to the generic function's environment that allow
# table-based dispatch of methods
.setupMethodsTables <- function(generic,
		initialize = !exists(".MTable", envir = env, inherits = FALSE))
{
    env <- environment(generic)
    if(initialize || !exists(".SigLength", envir = env, inherits = FALSE)) {
        nsig <- 1
        ## check that groups of generics agree on .SigLength; otherwise
        ## labels won't match
        for(gp in generic at group) {          ### !!!
            gpDef <- getGeneric(gp)
            if(is(gpDef, "genericFunction")) {
                .getMethodsTable(gpDef) # force initialization
                nsig <- max(nsig, get(".SigLength", envir = environment(gpDef)))
            }
        }
        assign(".SigLength", nsig, envir = env)
    }
    argSyms <- lapply(generic at signature, as.name)
    assign(".SigArgs", argSyms, envir = env)
    if(initialize) {
        mlist <- generic at default # from 2.11.0: method, primitive or NULL, not MethodsList
        mtable <- .mlistAddToTable(generic, mlist) # by default, adds to an empty table
        assign(".MTable", mtable, envir = env)
    }
    else ## the current .MTable
        mtable <- getMethodsForDispatch(generic)
    .resetInheritedMethods(env, mtable)
    if(is(generic, "groupGenericFunction")) {
        for(gp in generic at groupMembers) {
            gpDef <- getGeneric(gp)
            if(is(gpDef, "genericFunction"))
                .getMethodsTable(gpDef) # force initialization w. group methods
        }
    }
    NULL
}

###############

.updateMethodsInTable <- function(generic, where, attach) {
  fenv <- environment(generic)
  reset <- identical(attach, "reset")
  if(!exists(".MTable", envir = fenv, inherits = FALSE))
    .setupMethodsTables(generic)              ### !!!
  mtable <- get(".MTable", envir = fenv)
  if(!reset) {
    env <- as.environment(where)
    tname <- .TableMetaName(generic at generic, generic at package)
    if(exists(tname, envir = env, inherits = FALSE)) {
      .mergeMethodsTable(generic, mtable, get(tname, envir = env), attach)
    }
    ## else used to warn, but the generic may be implicitly required
    ## by class inheritance, without any explicit methods in this package
  }
  if(length(generic at group)) {
      groups <- as.list(generic at group)
      generics <- vector("list", length(groups))
      for(i in seq_along(groups))
        generics[[i]] <- getGeneric(groups[[i]])
    .checkGroupSigLength(groups, generics)
  }
  if(is(generic, "groupGenericFunction")) {
      .checkGroupSigLength(list(generic at generic), list(generic))
      for(g in getGroupMembers(generic))
          .updateMethodsInTable(getGeneric(g), where, attach)   ### !!! 
  }
  .resetInheritedMethods(fenv, mtable)
  mtable
}


From pgilbert902 at gmail.com  Wed Nov 26 19:45:26 2014
From: pgilbert902 at gmail.com (Paul Gilbert)
Date: Wed, 26 Nov 2014 13:45:26 -0500
Subject: [Rd] testing dontrun  examples
Message-ID: <54761FC6.3090007@gmail.com>

Is there a good strategy for testing examples which should not be run by 
default? For instance, I have examples which get data from the Internet. 
If I wrap them in try() then they can be skipped if the Internet is not 
available, but may not be tested in cases when I would like to know 
about the failure. (Not to mention that the example syntax is ugly.)

If I mark them \dontrun or \donttest then they are not tested. I could 
mark them \dontrun and then use example() but for this, in addition to 
run.dontrun=TRUE, I would need to specify all topics for a package, and 
I don't see how to do this, missing topic does not work.

Wishlist: what I would really like is R CMD check --run-dontrun   pkg

Suggestions?

Thanks,
Paul


From spencer.graves at structuremonitoring.com  Wed Nov 26 20:09:52 2014
From: spencer.graves at structuremonitoring.com (Spencer Graves)
Date: Wed, 26 Nov 2014 11:09:52 -0800
Subject: [Rd] testing dontrun  examples
In-Reply-To: <54761FC6.3090007@gmail.com>
References: <54761FC6.3090007@gmail.com>
Message-ID: <54762580.50007@structuremonitoring.com>

Hi, Paul:


       "if(!fda::CRAN())" runs code except with "R CMD check ?as-cran".  
I use it so CRAN checks skip examples that (a) need the Internet or (b) 
take too long for CRAN.


        Hope this helps.


       Spencer


On 11/26/2014 10:45 AM, Paul Gilbert wrote:
> Is there a good strategy for testing examples which should not be run 
> by default? For instance, I have examples which get data from the 
> Internet. If I wrap them in try() then they can be skipped if the 
> Internet is not available, but may not be tested in cases when I would 
> like to know about the failure. (Not to mention that the example 
> syntax is ugly.)
>
> If I mark them \dontrun or \donttest then they are not tested. I could 
> mark them \dontrun and then use example() but for this, in addition to 
> run.dontrun=TRUE, I would need to specify all topics for a package, 
> and I don't see how to do this, missing topic does not work.
>
> Wishlist: what I would really like is R CMD check --run-dontrun pkg
>
> Suggestions?
>
> Thanks,
> Paul
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
Spencer Graves, PE, PhD
President and Chief Technology Officer
Structure Inspection and Monitoring, Inc.
751 Emerson Ct.
San Jos?, CA 95126
ph:  408-655-4567
web:  www.structuremonitoring.com


From pgilbert902 at gmail.com  Wed Nov 26 21:08:50 2014
From: pgilbert902 at gmail.com (Paul Gilbert)
Date: Wed, 26 Nov 2014 15:08:50 -0500
Subject: [Rd] testing dontrun  examples
In-Reply-To: <54762580.50007@structuremonitoring.com>
References: <54761FC6.3090007@gmail.com>
	<54762580.50007@structuremonitoring.com>
Message-ID: <54763352.90303@gmail.com>

On 14-11-26 02:09 PM, Spencer Graves wrote:
> Hi, Paul:
>
>
>        "if(!fda::CRAN())" runs code except with "R CMD check ?as-cran".
> I use it so CRAN checks skip examples that (a) need the Internet or (b)
> take too long for CRAN.

Spencer

fda::CRAN() gives TRUE on my home machine, I think because I use several 
variables like  _R_CHECK_HAVE_MYSQL_=TRUE to control whether some tests 
get run. (Not all CRAN test servers have all resources.)

But, more importantly, wouldn't this strategy prevent CRAN from 
automatically running more extensive testing of the examples if they 
decided to do that sometimes?

Paul

>
>
>         Hope this helps.
>
>
>        Spencer
>
>
> On 11/26/2014 10:45 AM, Paul Gilbert wrote:
>> Is there a good strategy for testing examples which should not be run
>> by default? For instance, I have examples which get data from the
>> Internet. If I wrap them in try() then they can be skipped if the
>> Internet is not available, but may not be tested in cases when I would
>> like to know about the failure. (Not to mention that the example
>> syntax is ugly.)
>>
>> If I mark them \dontrun or \donttest then they are not tested. I could
>> mark them \dontrun and then use example() but for this, in addition to
>> run.dontrun=TRUE, I would need to specify all topics for a package,
>> and I don't see how to do this, missing topic does not work.
>>
>> Wishlist: what I would really like is R CMD check --run-dontrun pkg
>>
>> Suggestions?
>>
>> Thanks,
>> Paul
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From h.wickham at gmail.com  Wed Nov 26 21:17:45 2014
From: h.wickham at gmail.com (Hadley Wickham)
Date: Wed, 26 Nov 2014 14:17:45 -0600
Subject: [Rd] testing dontrun examples
In-Reply-To: <54761FC6.3090007@gmail.com>
References: <54761FC6.3090007@gmail.com>
Message-ID: <CABdHhvEHxbf8KRjZNr5WcXfOASCb3nnh2HBVRELaFzJ_n870TQ@mail.gmail.com>

You can try devtools::run_examples(test = TRUE)  (assuming your
working directory is the top-level package directory)

Hadley

On Wed, Nov 26, 2014 at 12:45 PM, Paul Gilbert <pgilbert902 at gmail.com> wrote:
> Is there a good strategy for testing examples which should not be run by
> default? For instance, I have examples which get data from the Internet. If
> I wrap them in try() then they can be skipped if the Internet is not
> available, but may not be tested in cases when I would like to know about
> the failure. (Not to mention that the example syntax is ugly.)
>
> If I mark them \dontrun or \donttest then they are not tested. I could mark
> them \dontrun and then use example() but for this, in addition to
> run.dontrun=TRUE, I would need to specify all topics for a package, and I
> don't see how to do this, missing topic does not work.
>
> Wishlist: what I would really like is R CMD check --run-dontrun   pkg
>
> Suggestions?
>
> Thanks,
> Paul
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel



-- 
http://had.co.nz/


From tkeitt at utexas.edu  Wed Nov 26 22:13:48 2014
From: tkeitt at utexas.edu (Tim Keitt)
Date: Wed, 26 Nov 2014 15:13:48 -0600
Subject: [Rd] testing dontrun examples
In-Reply-To: <54761FC6.3090007@gmail.com>
References: <54761FC6.3090007@gmail.com>
Message-ID: <CANnL8gp290W9QV=R02jLWLV1DSB4sM5SQW0LVzqwqO955Bezhg@mail.gmail.com>

On Wed, Nov 26, 2014 at 12:45 PM, Paul Gilbert <pgilbert902 at gmail.com>
wrote:

> Is there a good strategy for testing examples which should not be run by
> default? For instance, I have examples which get data from the Internet. If
> I wrap them in try() then they can be skipped if the Internet is not
> available, but may not be tested in cases when I would like to know about
> the failure. (Not to mention that the example syntax is ugly.)
>
> If I mark them \dontrun or \donttest then they are not tested. I could
> mark them \dontrun and then use example() but for this, in addition to
> run.dontrun=TRUE, I would need to specify all topics for a package, and I
> don't see how to do this, missing topic does not work.
>
> Wishlist: what I would really like is R CMD check --run-dontrun   pkg
>

I agree that would be nice to have.

My solution was just to have a private function (pkg:::run_examples()) that
runs all the examples. It has to be manually updated when adding a new
example however.

The devtools solution has not always worked for me when there are external
dependencies (like internet download, etc.)

THK


>
> Suggestions?
>
> Thanks,
> Paul
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>



-- 
http://www.keittlab.org/

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Wed Nov 26 23:49:50 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 26 Nov 2014 17:49:50 -0500
Subject: [Rd] testing dontrun  examples
In-Reply-To: <54761FC6.3090007@gmail.com>
References: <54761FC6.3090007@gmail.com>
Message-ID: <5476590E.1040804@gmail.com>

On 26/11/2014, 1:45 PM, Paul Gilbert wrote:
> Is there a good strategy for testing examples which should not be run by 
> default? For instance, I have examples which get data from the Internet. 
> If I wrap them in try() then they can be skipped if the Internet is not 
> available, but may not be tested in cases when I would like to know 
> about the failure. (Not to mention that the example syntax is ugly.)
> 
> If I mark them \dontrun or \donttest then they are not tested. I could 
> mark them \dontrun and then use example() but for this, in addition to 
> run.dontrun=TRUE, I would need to specify all topics for a package, and 
> I don't see how to do this, missing topic does not work.
> 
> Wishlist: what I would really like is R CMD check --run-dontrun   pkg


We have that in R-devel, so everyone will have it next April, but there
will possibly be bugs unless people like you try it out now.

Duncan Murdoch


From geoff.lee99 at bigpond.com  Wed Nov 26 23:39:32 2014
From: geoff.lee99 at bigpond.com (Geoff Lee)
Date: Thu, 27 Nov 2014 09:39:32 +1100
Subject: [Rd] Problem understanding behaviour of versionCheck for
	loadNamespace (and when versions for Imports packages are checked)
Message-ID: <00ff01d009c9$db1446c0$913cd440$@bigpond.com>

Hi

 

I'm still exploring the R programming universe, so if this is being asked in
the wrong place, or in the wrong way (e.g. too verbose or lacking in crucial
detail or in the wrong format) please let me know

 

I am trying to understand when the version constraints for packages which
appear in the Imports field of a DESCRIPTION file are checked.

 

Along the way I've hit a snag understanding what loadNamespace with the
versionCheck argument set does.  The core of my query is 'am I doing
something wrong, or have I stumbled across a bug?'.  Probably the former,
but after several days I still can't figure it out, so any guidance, hints
or outright help would be much appreciated.

 

Thanks in advance

 

Geoff

 

What I've tried so far.

 

"Writing R extensions" section 1.1.3 says 

 

"The 'Imports' field lists packages whose namespaces are imported from (as
specified in the NAMESPACE file) but which do not need to be attached.  ...
shortened for brevity ... Packages declared in the 'Depends' field should
not also be in the 'Imports' field. Version requirements can be specified
and are checked when the namespace is loaded (since R >= 3.0.0). "

 

It is slightly ambiguous, but seems to mean that the version dependencies
for both Depends packages and Imports packages are checked when the package
(namespace?) is loaded.

 

The release notes for R3.0.0 are more direct.  They say

 

"loadNamespace() allows a version specification to be given, and this is
used to check version specifications given in the Imports field when a
namespace is loaded"

 

But some toy (locally built and loaded) examples seem to show that while the
Depends versions are checked, the Imports version constraints are not (on
Windows 64, running R3.1.2, see full session_info later).

 

My tests (package2 imports package1) use implicit loading (via the
package1::fun1() idiom) so I have worked back to try get a minimal example
of what's causing me problems. I have tried

 

loadNamespace('package2', versionCheck = list (op = ">=", version =
package_version('3.0')))

 

This should fail (package2 has version 0.3, not 3.0) but instead it seems to
load package2, version 0.3 OK.

 

Reading the code of loadNamespace, there is some code which says

 

if (length(z <- versionCheck) == 3L && !do.call(z$op, 

    list(as.numeric_version(version), z$version))) 

    stop(gettextf("namespace %s %s is being loaded, but %s %s is required", 

      sQuote(package), version, z$op, z$version), 

       domain = NA)

 

I think it is the length(z <- versionCheck) == 3L part of the if test that
is allowing the incorrect version be loaded.

 

The documentation for loadNamespace says that "versionCheck" is

"NULL or a version specification (a list with components op and version))."

 

If I add a third (nonsense) component to the versionCheck argument list,
then loadNamespace does what I expect.  Is there supposed to be a third
component in the list, and if so what should it be? Or is this a bug?

 

I've got this far and am now stumped, hence my query.

 

Some output from my tests.

 

d> devtools::session_info()

Session
info--------------------------------------------------------------------

  setting  value                       

version  R version 3.1.2 (2014-10-31)

system   x86_64, mingw32             

ui       RStudio (0.98.953)          

language (EN)                        

collate  English_Australia.1252      

tz       Australia/Sydney            

 

Packages--------------------------------------------------------------------
----

  package    * version date       source        

devtools     1.6.1   2014-10-07 CRAN (R 3.1.2)

rstudioapi   0.1     2014-03-27 CRAN (R 3.1.1)

 

d> # I think this should fail but it does not

d> loadNamespace('package2', versionCheck = list(op='>=', version =
package_version('3.0')))

<environment: namespace:package2>

  

  

  d> devtools::session_info()

Session
info--------------------------------------------------------------------

  setting  value                       

version  R version 3.1.2 (2014-10-31)

system   x86_64, mingw32             

ui       RStudio (0.98.953)          

language (EN)                        

collate  English_Australia.1252      

tz       Australia/Sydney            

 

Packages--------------------------------------------------------------------
----

  package    * version date       source        

devtools     1.6.1   2014-10-07 CRAN (R 3.1.2)

package2     0.3     2014-11-24 local         

rstudioapi   0.1     2014-03-27 CRAN (R 3.1.1)

 

d> #Try again with a third (nonsense) entry in the versionCheck list

d> unloadNamespace('package2')

d> loadNamespace('package2', versionCheck = list(op='>=', version =
package_version('3.0'), please = 'check it'))

Error in loadNamespace("package2", versionCheck = list(op = ">=", version =
package_version("3.0"),  : 

 namespace 'package2' 0.3 is being loaded, but >= 3.0 is required

 

 

 

d> devtools::session_info()

Session
info--------------------------------------------------------------------

setting  value                       

version  R version 3.1.2 (2014-10-31)

system   x86_64, mingw32             

ui       RStudio (0.98.953)          

language (EN)                        

collate  English_Australia.1252      

tz       Australia/Sydney            

 

Packages--------------------------------------------------------------------
----

package    * version date       source        

devtools     1.6.1   2014-10-07 CRAN (R 3.1.2)

rstudioapi   0.1     2014-03-27 CRAN (R 3.1.1)

d> loadNamespace('package2', versionCheck = list(op='>=', version =
package_version('0.3'), please = 'check it'))

<environment: namespace:package2>

d>


	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Thu Nov 27 00:57:29 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 26 Nov 2014 18:57:29 -0500
Subject: [Rd] Problem understanding behaviour of versionCheck for
 loadNamespace (and when versions for Imports packages are checked)
In-Reply-To: <00ff01d009c9$db1446c0$913cd440$@bigpond.com>
References: <00ff01d009c9$db1446c0$913cd440$@bigpond.com>
Message-ID: <547668E9.3050505@gmail.com>

Summary:  I think you've found a bug.

On 26/11/2014, 5:39 PM, Geoff Lee wrote:
> Hi
> 
>  
> 
> I'm still exploring the R programming universe, so if this is being asked in
> the wrong place, or in the wrong way (e.g. too verbose or lacking in crucial
> detail or in the wrong format) please let me know
> 
>  
> 
> I am trying to understand when the version constraints for packages which
> appear in the Imports field of a DESCRIPTION file are checked.

I would have assumed they are checked when you try to install the
package.  If you ask for version 3.0, and only have 0.3, the install
should fail.

But as you've found, the documents say something else...

> 
>  
> 
> Along the way I've hit a snag understanding what loadNamespace with the
> versionCheck argument set does.  The core of my query is 'am I doing
> something wrong, or have I stumbled across a bug?'.  Probably the former,
> but after several days I still can't figure it out, so any guidance, hints
> or outright help would be much appreciated.
> 
>  
> 
> Thanks in advance
> 
>  
> 
> Geoff
> 
>  
> 
> What I've tried so far.
> 
>  
> 
> "Writing R extensions" section 1.1.3 says 
> 
>  
> 
> "The 'Imports' field lists packages whose namespaces are imported from (as
> specified in the NAMESPACE file) but which do not need to be attached.  ...
> shortened for brevity ... Packages declared in the 'Depends' field should
> not also be in the 'Imports' field. Version requirements can be specified
> and are checked when the namespace is loaded (since R >= 3.0.0). "
> 
>  
> 
> It is slightly ambiguous, but seems to mean that the version dependencies
> for both Depends packages and Imports packages are checked when the package
> (namespace?) is loaded.
> 
>  
> 
> The release notes for R3.0.0 are more direct.  They say
> 
>  
> 
> "loadNamespace() allows a version specification to be given, and this is
> used to check version specifications given in the Imports field when a
> namespace is loaded"
> 
>  
> 
> But some toy (locally built and loaded) examples seem to show that while the
> Depends versions are checked, the Imports version constraints are not (on
> Windows 64, running R3.1.2, see full session_info later).
> 
>  
> 
> My tests (package2 imports package1) use implicit loading (via the
> package1::fun1() idiom) so I have worked back to try get a minimal example
> of what's causing me problems. I have tried

According to what you have written, that should have failed.  So it
looks like a bug.
> 
>  
> 
> loadNamespace('package2', versionCheck = list (op = ">=", version =
> package_version('3.0')))
> 
>  
> 
> This should fail (package2 has version 0.3, not 3.0) but instead it seems to
> load package2, version 0.3 OK.
> 
>  
> 
> Reading the code of loadNamespace, there is some code which says
> 
>  
> 
> if (length(z <- versionCheck) == 3L && !do.call(z$op, 
> 
>     list(as.numeric_version(version), z$version))) 
> 
>     stop(gettextf("namespace %s %s is being loaded, but %s %s is required", 
> 
>       sQuote(package), version, z$op, z$version), 
> 
>        domain = NA)
> 
>  
> 
> I think it is the length(z <- versionCheck) == 3L part of the if test that
> is allowing the incorrect version be loaded.

That does seem like a typo.

Duncan Murdoch

> 
>  
> 
> The documentation for loadNamespace says that "versionCheck" is
> 
> "NULL or a version specification (a list with components op and version))."
> 
>  
> 
> If I add a third (nonsense) component to the versionCheck argument list,
> then loadNamespace does what I expect.  Is there supposed to be a third
> component in the list, and if so what should it be? Or is this a bug?
> 
>  
> 
> I've got this far and am now stumped, hence my query.
> 
>  
> 
> Some output from my tests.
> 
>  
> 
> d> devtools::session_info()
> 
> Session
> info--------------------------------------------------------------------
> 
>   setting  value                       
> 
> version  R version 3.1.2 (2014-10-31)
> 
> system   x86_64, mingw32             
> 
> ui       RStudio (0.98.953)          
> 
> language (EN)                        
> 
> collate  English_Australia.1252      
> 
> tz       Australia/Sydney            
> 
>  
> 
> Packages--------------------------------------------------------------------
> ----
> 
>   package    * version date       source        
> 
> devtools     1.6.1   2014-10-07 CRAN (R 3.1.2)
> 
> rstudioapi   0.1     2014-03-27 CRAN (R 3.1.1)
> 
>  
> 
> d> # I think this should fail but it does not
> 
> d> loadNamespace('package2', versionCheck = list(op='>=', version =
> package_version('3.0')))
>
> <environment: namespace:package2>
> 
>   
> 
>   
> 
>   d> devtools::session_info()
> 
> Session
> info--------------------------------------------------------------------
> 
>   setting  value                       
> 
> version  R version 3.1.2 (2014-10-31)
> 
> system   x86_64, mingw32             
> 
> ui       RStudio (0.98.953)          
> 
> language (EN)                        
> 
> collate  English_Australia.1252      
> 
> tz       Australia/Sydney            
> 
>  
> 
> Packages--------------------------------------------------------------------
> ----
> 
>   package    * version date       source        
> 
> devtools     1.6.1   2014-10-07 CRAN (R 3.1.2)
> 
> package2     0.3     2014-11-24 local         
> 
> rstudioapi   0.1     2014-03-27 CRAN (R 3.1.1)
> 
>  
> 
> d> #Try again with a third (nonsense) entry in the versionCheck list
> 
> d> unloadNamespace('package2')
> 
> d> loadNamespace('package2', versionCheck = list(op='>=', version =
> package_version('3.0'), please = 'check it'))
> 
> Error in loadNamespace("package2", versionCheck = list(op = ">=", version =
> package_version("3.0"),  : 
> 
>  namespace 'package2' 0.3 is being loaded, but >= 3.0 is required
> 
>  
> 
>  
> 
>  
> 
> d> devtools::session_info()
> 
> Session
> info--------------------------------------------------------------------
> 
> setting  value                       
> 
> version  R version 3.1.2 (2014-10-31)
> 
> system   x86_64, mingw32             
> 
> ui       RStudio (0.98.953)          
> 
> language (EN)                        
> 
> collate  English_Australia.1252      
> 
> tz       Australia/Sydney            
> 
>  
> 
> Packages--------------------------------------------------------------------
> ----
> 
> package    * version date       source        
> 
> devtools     1.6.1   2014-10-07 CRAN (R 3.1.2)
> 
> rstudioapi   0.1     2014-03-27 CRAN (R 3.1.1)
> 
> d> loadNamespace('package2', versionCheck = list(op='>=', version =
> package_version('0.3'), please = 'check it'))
> 
> <environment: namespace:package2>
> 
> d>
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From murdoch.duncan at gmail.com  Thu Nov 27 01:43:17 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 26 Nov 2014 19:43:17 -0500
Subject: [Rd] Problem understanding behaviour of versionCheck for
 loadNamespace (and when versions for Imports packages are checked)
In-Reply-To: <00ff01d009c9$db1446c0$913cd440$@bigpond.com>
References: <00ff01d009c9$db1446c0$913cd440$@bigpond.com>
Message-ID: <547673A5.8080802@gmail.com>

On 26/11/2014, 5:39 PM, Geoff Lee wrote:
> Hi
> 
>  
> 
> I'm still exploring the R programming universe, so if this is being asked in
> the wrong place, or in the wrong way (e.g. too verbose or lacking in crucial
> detail or in the wrong format) please let me know
> 
>  
> 
> I am trying to understand when the version constraints for packages which
> appear in the Imports field of a DESCRIPTION file are checked.
> 
>  
> 
> Along the way I've hit a snag understanding what loadNamespace with the
> versionCheck argument set does.  The core of my query is 'am I doing
> something wrong, or have I stumbled across a bug?'.  Probably the former,
> but after several days I still can't figure it out, so any guidance, hints
> or outright help would be much appreciated.
> 
>  
> 
> Thanks in advance
> 
>  
> 
> Geoff
> 
>  
> 
> What I've tried so far.
> 
>  
> 
> "Writing R extensions" section 1.1.3 says 
> 
>  
> 
> "The 'Imports' field lists packages whose namespaces are imported from (as
> specified in the NAMESPACE file) but which do not need to be attached.  ...
> shortened for brevity ... Packages declared in the 'Depends' field should
> not also be in the 'Imports' field. Version requirements can be specified
> and are checked when the namespace is loaded (since R >= 3.0.0). "
> 
>  
> 
> It is slightly ambiguous, but seems to mean that the version dependencies
> for both Depends packages and Imports packages are checked when the package
> (namespace?) is loaded.
> 
>  
> 
> The release notes for R3.0.0 are more direct.  They say
> 
>  
> 
> "loadNamespace() allows a version specification to be given, and this is
> used to check version specifications given in the Imports field when a
> namespace is loaded"
> 
>  
> 
> But some toy (locally built and loaded) examples seem to show that while the
> Depends versions are checked, the Imports version constraints are not (on
> Windows 64, running R3.1.2, see full session_info later).
> 
>  
> 
> My tests (package2 imports package1) use implicit loading (via the
> package1::fun1() idiom) so I have worked back to try get a minimal example
> of what's causing me problems. I have tried
> 
>  
> 
> loadNamespace('package2', versionCheck = list (op = ">=", version =
> package_version('3.0')))

You need to look at how versionCheck is used in the existing code.  It
is used on items that were produced when the package was installed, and
in those, the length of the versionCheck entry really is 3.  For
example, the dplyr package imports "lazyeval (>= 0.1.8)".  That
specification becomes the list

 ..$ lazyeval  :List of 3
  .. ..$ name   : chr "lazyeval"
  .. ..$ op     : chr ">="
  .. ..$ version:Classes 'package_version', 'numeric_version'  hidden
list of 1
  .. .. ..$ : int [1:3] 0 1 8

So if you want to put one of these together, your versionCheck list
should be list(name = "package2", op = ">=", version =
package+version('3.0'))

Duncan Murdoch

> 
>  
> 
> This should fail (package2 has version 0.3, not 3.0) but instead it seems to
> load package2, version 0.3 OK.
> 
>  
> 
> Reading the code of loadNamespace, there is some code which says
> 
>  
> 
> if (length(z <- versionCheck) == 3L && !do.call(z$op, 
> 
>     list(as.numeric_version(version), z$version))) 
> 
>     stop(gettextf("namespace %s %s is being loaded, but %s %s is required", 
> 
>       sQuote(package), version, z$op, z$version), 
> 
>        domain = NA)
> 
>  
> 
> I think it is the length(z <- versionCheck) == 3L part of the if test that
> is allowing the incorrect version be loaded.
> 
>  
> 
> The documentation for loadNamespace says that "versionCheck" is
> 
> "NULL or a version specification (a list with components op and version))."
> 
>  
> 
> If I add a third (nonsense) component to the versionCheck argument list,
> then loadNamespace does what I expect.  Is there supposed to be a third
> component in the list, and if so what should it be? Or is this a bug?
> 
>  
> 
> I've got this far and am now stumped, hence my query.
> 
>  
> 
> Some output from my tests.
> 
>  
> 
> d> devtools::session_info()
> 
> Session
> info--------------------------------------------------------------------
> 
>   setting  value                       
> 
> version  R version 3.1.2 (2014-10-31)
> 
> system   x86_64, mingw32             
> 
> ui       RStudio (0.98.953)          
> 
> language (EN)                        
> 
> collate  English_Australia.1252      
> 
> tz       Australia/Sydney            
> 
>  
> 
> Packages--------------------------------------------------------------------
> ----
> 
>   package    * version date       source        
> 
> devtools     1.6.1   2014-10-07 CRAN (R 3.1.2)
> 
> rstudioapi   0.1     2014-03-27 CRAN (R 3.1.1)
> 
>  
> 
> d> # I think this should fail but it does not
> 
> d> loadNamespace('package2', versionCheck = list(op='>=', version =
> package_version('3.0')))
> 
> <environment: namespace:package2>
> 
>   
> 
>   
> 
>   d> devtools::session_info()
> 
> Session
> info--------------------------------------------------------------------
> 
>   setting  value                       
> 
> version  R version 3.1.2 (2014-10-31)
> 
> system   x86_64, mingw32             
> 
> ui       RStudio (0.98.953)          
> 
> language (EN)                        
> 
> collate  English_Australia.1252      
> 
> tz       Australia/Sydney            
> 
>  
> 
> Packages--------------------------------------------------------------------
> ----
> 
>   package    * version date       source        
> 
> devtools     1.6.1   2014-10-07 CRAN (R 3.1.2)
> 
> package2     0.3     2014-11-24 local         
> 
> rstudioapi   0.1     2014-03-27 CRAN (R 3.1.1)
> 
>  
> 
> d> #Try again with a third (nonsense) entry in the versionCheck list
> 
> d> unloadNamespace('package2')
> 
> d> loadNamespace('package2', versionCheck = list(op='>=', version =
> package_version('3.0'), please = 'check it'))
> 
> Error in loadNamespace("package2", versionCheck = list(op = ">=", version =
> package_version("3.0"),  : 
> 
>  namespace 'package2' 0.3 is being loaded, but >= 3.0 is required
> 
>  
> 
>  
> 
>  
> 
> d> devtools::session_info()
> 
> Session
> info--------------------------------------------------------------------
> 
> setting  value                       
> 
> version  R version 3.1.2 (2014-10-31)
> 
> system   x86_64, mingw32             
> 
> ui       RStudio (0.98.953)          
> 
> language (EN)                        
> 
> collate  English_Australia.1252      
> 
> tz       Australia/Sydney            
> 
>  
> 
> Packages--------------------------------------------------------------------
> ----
> 
> package    * version date       source        
> 
> devtools     1.6.1   2014-10-07 CRAN (R 3.1.2)
> 
> rstudioapi   0.1     2014-03-27 CRAN (R 3.1.1)
> 
> d> loadNamespace('package2', versionCheck = list(op='>=', version =
> package_version('0.3'), please = 'check it'))
> 
> <environment: namespace:package2>
> 
> d>
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From murdoch.duncan at gmail.com  Thu Nov 27 02:08:54 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 26 Nov 2014 20:08:54 -0500
Subject: [Rd] Problem understanding behaviour of versionCheck for
 loadNamespace (and when versions for Imports packages are checked)
In-Reply-To: <011301d009da$845492c0$8cfdb840$@gmail.com>
References: <00ff01d009c9$db1446c0$913cd440$@bigpond.com>
	<547668E9.3050505@gmail.com>
	<011301d009da$845492c0$8cfdb840$@gmail.com>
Message-ID: <547679A6.3000907@gmail.com>

On 26/11/2014, 7:38 PM, Geoff Lee wrote:
> Many thanks Duncan for the quick response. 

A little too quick, it seems...
> 
> A bug is a relief in a way. I've been digging my way deeper into this (and
> learning more as I go) for several days now - but it is a diversion from (a
> diversion from) my main goal :-(
> 
> Is there somewhere specific I should report or log the bug or will that
> happen from this mailing-list automatically? (I have seen the Bug Tracking
> link on the r-project page and followed that, but don't yet have a Bugzilla
> account, nor know the precise mechanics and protocols for notifying a bug)

If you can put together a simple set of steps to illustrate a bug, then
reporting on bugs.r-project.org is the way to get it recorded.
Reporting it on this list is really hit and miss.  But I think from your
previous description, something else is going on.  When I try to load a
namespace with a bad version number, I get an error:

loadNamespace("rgl", versionCheck=list(name="rgl", op=">",
version=package_version('3.0')))
Error in loadNamespace("rgl", versionCheck = list(name = "rgl", op =
">",  :
  namespace ?rgl? 0.95.1163 is being loaded, but > 3.0 is required

Duncan Murdoch

> 
> Geoff
> 
> PS Building package2 - via devtools::build('package2', binary = TRUE) does
> check and insist that I have an appropriate version of the 'to be imported'
> package1 installed in my .libPath().
> 
> It was only when I simulated a user who has and older version of the
> Imported package1 (by overwriting the later version of package 1 with an
> earlier version), then trying to load or attach package2 that the (failure
> of the version checking) at loadNamespace time for package1 became apparent
> (well apparentish after quite a bit of digging)
> 
> -----Original Message-----
> From: Duncan Murdoch [mailto:murdoch.duncan at gmail.com] 
> Sent: Thursday, 27 November 2014 10:57 AM
> To: Geoff Lee; r-devel at r-project.org
> Subject: Re: [Rd] Problem understanding behaviour of versionCheck for
> loadNamespace (and when versions for Imports packages are checked)
> 
> Summary:  I think you've found a bug.
> 
> On 26/11/2014, 5:39 PM, Geoff Lee wrote:
>> Hi
>>
>>  
>>
>> I'm still exploring the R programming universe, so if this is being 
>> asked in the wrong place, or in the wrong way (e.g. too verbose or 
>> lacking in crucial detail or in the wrong format) please let me know
>>
>>  
>>
>> I am trying to understand when the version constraints for packages 
>> which appear in the Imports field of a DESCRIPTION file are checked.
> 
> I would have assumed they are checked when you try to install the package.
> If you ask for version 3.0, and only have 0.3, the install should fail.
> 
> But as you've found, the documents say something else...
> 
>>
>>  
>>
>> Along the way I've hit a snag understanding what loadNamespace with 
>> the versionCheck argument set does.  The core of my query is 'am I 
>> doing something wrong, or have I stumbled across a bug?'.  Probably 
>> the former, but after several days I still can't figure it out, so any 
>> guidance, hints or outright help would be much appreciated.
>>
>>  
>>
>> Thanks in advance
>>
>>  
>>
>> Geoff
>>
>>  
>>
>> What I've tried so far.
>>
>>  
>>
>> "Writing R extensions" section 1.1.3 says
>>
>>  
>>
>> "The 'Imports' field lists packages whose namespaces are imported from 
>> (as specified in the NAMESPACE file) but which do not need to be attached.
> ...
>> shortened for brevity ... Packages declared in the 'Depends' field 
>> should not also be in the 'Imports' field. Version requirements can be 
>> specified and are checked when the namespace is loaded (since R >= 3.0.0).
> "
>>
>>  
>>
>> It is slightly ambiguous, but seems to mean that the version 
>> dependencies for both Depends packages and Imports packages are 
>> checked when the package
>> (namespace?) is loaded.
>>
>>  
>>
>> The release notes for R3.0.0 are more direct.  They say
>>
>>  
>>
>> "loadNamespace() allows a version specification to be given, and this 
>> is used to check version specifications given in the Imports field 
>> when a namespace is loaded"
>>
>>  
>>
>> But some toy (locally built and loaded) examples seem to show that 
>> while the Depends versions are checked, the Imports version 
>> constraints are not (on Windows 64, running R3.1.2, see full session_info
> later).
>>
>>  
>>
>> My tests (package2 imports package1) use implicit loading (via the
>> package1::fun1() idiom) so I have worked back to try get a minimal 
>> example of what's causing me problems. I have tried
> 
> According to what you have written, that should have failed.  So it looks
> like a bug.
>>
>>  
>>
>> loadNamespace('package2', versionCheck = list (op = ">=", version =
>> package_version('3.0')))
>>
>>  
>>
>> This should fail (package2 has version 0.3, not 3.0) but instead it 
>> seems to load package2, version 0.3 OK.
>>
>>  
>>
>> Reading the code of loadNamespace, there is some code which says
>>
>>  
>>
>> if (length(z <- versionCheck) == 3L && !do.call(z$op,
>>
>>     list(as.numeric_version(version), z$version)))
>>
>>     stop(gettextf("namespace %s %s is being loaded, but %s %s is 
>> required",
>>
>>       sQuote(package), version, z$op, z$version),
>>
>>        domain = NA)
>>
>>  
>>
>> I think it is the length(z <- versionCheck) == 3L part of the if test 
>> that is allowing the incorrect version be loaded.
> 
> That does seem like a typo.
> 
> Duncan Murdoch
> 
>>
>>  
>>
>> The documentation for loadNamespace says that "versionCheck" is
>>
>> "NULL or a version specification (a list with components op and
> version))."
>>
>>  
>>
>> If I add a third (nonsense) component to the versionCheck argument 
>> list, then loadNamespace does what I expect.  Is there supposed to be 
>> a third component in the list, and if so what should it be? Or is this a
> bug?
>>
>>  
>>
>> I've got this far and am now stumped, hence my query.
>>
>>  
>>
>> Some output from my tests.
>>
>>  
>>
>> d> devtools::session_info()
>>
>> Session
>> info------------------------------------------------------------------
>> --
>>
>>   setting  value                       
>>
>> version  R version 3.1.2 (2014-10-31)
>>
>> system   x86_64, mingw32             
>>
>> ui       RStudio (0.98.953)          
>>
>> language (EN)                        
>>
>> collate  English_Australia.1252      
>>
>> tz       Australia/Sydney            
>>
>>  
>>
>> Packages--------------------------------------------------------------
>> ------
>> ----
>>
>>   package    * version date       source        
>>
>> devtools     1.6.1   2014-10-07 CRAN (R 3.1.2)
>>
>> rstudioapi   0.1     2014-03-27 CRAN (R 3.1.1)
>>
>>  
>>
>> d> # I think this should fail but it does not
>>
>> d> loadNamespace('package2', versionCheck = list(op='>=', version =
>> package_version('3.0')))
>>
>> <environment: namespace:package2>
>>
>>   
>>
>>   
>>
>>   d> devtools::session_info()
>>
>> Session
>> info------------------------------------------------------------------
>> --
>>
>>   setting  value                       
>>
>> version  R version 3.1.2 (2014-10-31)
>>
>> system   x86_64, mingw32             
>>
>> ui       RStudio (0.98.953)          
>>
>> language (EN)                        
>>
>> collate  English_Australia.1252      
>>
>> tz       Australia/Sydney            
>>
>>  
>>
>> Packages--------------------------------------------------------------
>> ------
>> ----
>>
>>   package    * version date       source        
>>
>> devtools     1.6.1   2014-10-07 CRAN (R 3.1.2)
>>
>> package2     0.3     2014-11-24 local         
>>
>> rstudioapi   0.1     2014-03-27 CRAN (R 3.1.1)
>>
>>  
>>
>> d> #Try again with a third (nonsense) entry in the versionCheck list
>>
>> d> unloadNamespace('package2')
>>
>> d> loadNamespace('package2', versionCheck = list(op='>=', version =
>> package_version('3.0'), please = 'check it'))
>>
>> Error in loadNamespace("package2", versionCheck = list(op = ">=", 
>> version = package_version("3.0"),  :
>>
>>  namespace 'package2' 0.3 is being loaded, but >= 3.0 is required
>>
>>  
>>
>>  
>>
>>  
>>
>> d> devtools::session_info()
>>
>> Session
>> info------------------------------------------------------------------
>> --
>>
>> setting  value                       
>>
>> version  R version 3.1.2 (2014-10-31)
>>
>> system   x86_64, mingw32             
>>
>> ui       RStudio (0.98.953)          
>>
>> language (EN)                        
>>
>> collate  English_Australia.1252      
>>
>> tz       Australia/Sydney            
>>
>>  
>>
>> Packages--------------------------------------------------------------
>> ------
>> ----
>>
>> package    * version date       source        
>>
>> devtools     1.6.1   2014-10-07 CRAN (R 3.1.2)
>>
>> rstudioapi   0.1     2014-03-27 CRAN (R 3.1.1)
>>
>> d> loadNamespace('package2', versionCheck = list(op='>=', version =
>> package_version('0.3'), please = 'check it'))
>>
>> <environment: namespace:package2>
>>
>> d>
>>
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
> 
>


From geoff.lee99 at gmail.com  Thu Nov 27 01:38:43 2014
From: geoff.lee99 at gmail.com (Geoff Lee)
Date: Thu, 27 Nov 2014 11:38:43 +1100
Subject: [Rd] Problem understanding behaviour of versionCheck for
	loadNamespace (and when versions for Imports packages are checked)
In-Reply-To: <547668E9.3050505@gmail.com>
References: <00ff01d009c9$db1446c0$913cd440$@bigpond.com>
	<547668E9.3050505@gmail.com>
Message-ID: <011301d009da$845492c0$8cfdb840$@gmail.com>

Many thanks Duncan for the quick response. 

A bug is a relief in a way. I've been digging my way deeper into this (and
learning more as I go) for several days now - but it is a diversion from (a
diversion from) my main goal :-(

Is there somewhere specific I should report or log the bug or will that
happen from this mailing-list automatically? (I have seen the Bug Tracking
link on the r-project page and followed that, but don't yet have a Bugzilla
account, nor know the precise mechanics and protocols for notifying a bug)

Geoff

PS Building package2 - via devtools::build('package2', binary = TRUE) does
check and insist that I have an appropriate version of the 'to be imported'
package1 installed in my .libPath().

It was only when I simulated a user who has and older version of the
Imported package1 (by overwriting the later version of package 1 with an
earlier version), then trying to load or attach package2 that the (failure
of the version checking) at loadNamespace time for package1 became apparent
(well apparentish after quite a bit of digging)

-----Original Message-----
From: Duncan Murdoch [mailto:murdoch.duncan at gmail.com] 
Sent: Thursday, 27 November 2014 10:57 AM
To: Geoff Lee; r-devel at r-project.org
Subject: Re: [Rd] Problem understanding behaviour of versionCheck for
loadNamespace (and when versions for Imports packages are checked)

Summary:  I think you've found a bug.

On 26/11/2014, 5:39 PM, Geoff Lee wrote:
> Hi
> 
>  
> 
> I'm still exploring the R programming universe, so if this is being 
> asked in the wrong place, or in the wrong way (e.g. too verbose or 
> lacking in crucial detail or in the wrong format) please let me know
> 
>  
> 
> I am trying to understand when the version constraints for packages 
> which appear in the Imports field of a DESCRIPTION file are checked.

I would have assumed they are checked when you try to install the package.
If you ask for version 3.0, and only have 0.3, the install should fail.

But as you've found, the documents say something else...

> 
>  
> 
> Along the way I've hit a snag understanding what loadNamespace with 
> the versionCheck argument set does.  The core of my query is 'am I 
> doing something wrong, or have I stumbled across a bug?'.  Probably 
> the former, but after several days I still can't figure it out, so any 
> guidance, hints or outright help would be much appreciated.
> 
>  
> 
> Thanks in advance
> 
>  
> 
> Geoff
> 
>  
> 
> What I've tried so far.
> 
>  
> 
> "Writing R extensions" section 1.1.3 says
> 
>  
> 
> "The 'Imports' field lists packages whose namespaces are imported from 
> (as specified in the NAMESPACE file) but which do not need to be attached.
...
> shortened for brevity ... Packages declared in the 'Depends' field 
> should not also be in the 'Imports' field. Version requirements can be 
> specified and are checked when the namespace is loaded (since R >= 3.0.0).
"
> 
>  
> 
> It is slightly ambiguous, but seems to mean that the version 
> dependencies for both Depends packages and Imports packages are 
> checked when the package
> (namespace?) is loaded.
> 
>  
> 
> The release notes for R3.0.0 are more direct.  They say
> 
>  
> 
> "loadNamespace() allows a version specification to be given, and this 
> is used to check version specifications given in the Imports field 
> when a namespace is loaded"
> 
>  
> 
> But some toy (locally built and loaded) examples seem to show that 
> while the Depends versions are checked, the Imports version 
> constraints are not (on Windows 64, running R3.1.2, see full session_info
later).
> 
>  
> 
> My tests (package2 imports package1) use implicit loading (via the
> package1::fun1() idiom) so I have worked back to try get a minimal 
> example of what's causing me problems. I have tried

According to what you have written, that should have failed.  So it looks
like a bug.
> 
>  
> 
> loadNamespace('package2', versionCheck = list (op = ">=", version =
> package_version('3.0')))
> 
>  
> 
> This should fail (package2 has version 0.3, not 3.0) but instead it 
> seems to load package2, version 0.3 OK.
> 
>  
> 
> Reading the code of loadNamespace, there is some code which says
> 
>  
> 
> if (length(z <- versionCheck) == 3L && !do.call(z$op,
> 
>     list(as.numeric_version(version), z$version)))
> 
>     stop(gettextf("namespace %s %s is being loaded, but %s %s is 
> required",
> 
>       sQuote(package), version, z$op, z$version),
> 
>        domain = NA)
> 
>  
> 
> I think it is the length(z <- versionCheck) == 3L part of the if test 
> that is allowing the incorrect version be loaded.

That does seem like a typo.

Duncan Murdoch

> 
>  
> 
> The documentation for loadNamespace says that "versionCheck" is
> 
> "NULL or a version specification (a list with components op and
version))."
> 
>  
> 
> If I add a third (nonsense) component to the versionCheck argument 
> list, then loadNamespace does what I expect.  Is there supposed to be 
> a third component in the list, and if so what should it be? Or is this a
bug?
> 
>  
> 
> I've got this far and am now stumped, hence my query.
> 
>  
> 
> Some output from my tests.
> 
>  
> 
> d> devtools::session_info()
> 
> Session
> info------------------------------------------------------------------
> --
> 
>   setting  value                       
> 
> version  R version 3.1.2 (2014-10-31)
> 
> system   x86_64, mingw32             
> 
> ui       RStudio (0.98.953)          
> 
> language (EN)                        
> 
> collate  English_Australia.1252      
> 
> tz       Australia/Sydney            
> 
>  
> 
> Packages--------------------------------------------------------------
> ------
> ----
> 
>   package    * version date       source        
> 
> devtools     1.6.1   2014-10-07 CRAN (R 3.1.2)
> 
> rstudioapi   0.1     2014-03-27 CRAN (R 3.1.1)
> 
>  
> 
> d> # I think this should fail but it does not
> 
> d> loadNamespace('package2', versionCheck = list(op='>=', version =
> package_version('3.0')))
>
> <environment: namespace:package2>
> 
>   
> 
>   
> 
>   d> devtools::session_info()
> 
> Session
> info------------------------------------------------------------------
> --
> 
>   setting  value                       
> 
> version  R version 3.1.2 (2014-10-31)
> 
> system   x86_64, mingw32             
> 
> ui       RStudio (0.98.953)          
> 
> language (EN)                        
> 
> collate  English_Australia.1252      
> 
> tz       Australia/Sydney            
> 
>  
> 
> Packages--------------------------------------------------------------
> ------
> ----
> 
>   package    * version date       source        
> 
> devtools     1.6.1   2014-10-07 CRAN (R 3.1.2)
> 
> package2     0.3     2014-11-24 local         
> 
> rstudioapi   0.1     2014-03-27 CRAN (R 3.1.1)
> 
>  
> 
> d> #Try again with a third (nonsense) entry in the versionCheck list
> 
> d> unloadNamespace('package2')
> 
> d> loadNamespace('package2', versionCheck = list(op='>=', version =
> package_version('3.0'), please = 'check it'))
> 
> Error in loadNamespace("package2", versionCheck = list(op = ">=", 
> version = package_version("3.0"),  :
> 
>  namespace 'package2' 0.3 is being loaded, but >= 3.0 is required
> 
>  
> 
>  
> 
>  
> 
> d> devtools::session_info()
> 
> Session
> info------------------------------------------------------------------
> --
> 
> setting  value                       
> 
> version  R version 3.1.2 (2014-10-31)
> 
> system   x86_64, mingw32             
> 
> ui       RStudio (0.98.953)          
> 
> language (EN)                        
> 
> collate  English_Australia.1252      
> 
> tz       Australia/Sydney            
> 
>  
> 
> Packages--------------------------------------------------------------
> ------
> ----
> 
> package    * version date       source        
> 
> devtools     1.6.1   2014-10-07 CRAN (R 3.1.2)
> 
> rstudioapi   0.1     2014-03-27 CRAN (R 3.1.1)
> 
> d> loadNamespace('package2', versionCheck = list(op='>=', version =
> package_version('0.3'), please = 'check it'))
> 
> <environment: namespace:package2>
> 
> d>
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From geoff.lee99 at gmail.com  Thu Nov 27 02:29:49 2014
From: geoff.lee99 at gmail.com (Geoff Lee)
Date: Thu, 27 Nov 2014 12:29:49 +1100
Subject: [Rd] Problem understanding behaviour of versionCheck for
	loadNamespace (and when versions for Imports packages are checked)
In-Reply-To: <547679A6.3000907@gmail.com>
References: <00ff01d009c9$db1446c0$913cd440$@bigpond.com>
	<547668E9.3050505@gmail.com>
	<011301d009da$845492c0$8cfdb840$@gmail.com>
	<547679A6.3000907@gmail.com>
Message-ID: <011601d009e1$a7929f00$f6b7dd00$@gmail.com>

Hi Duncan

The difference is that in your call to loadNamespace, the versionCheck list
has 3 components (name, op and version), whereas the documentation only
mentions 2 (op and version).
loadNamespace 'works' for me provided I add a third component to the list
(even a nonsense one).

What I haven't yet had the fortitude to do is track down through the code to
see what the arguments are (ie how many elements there are in the
versionCheck list) to any calls to loadNamespace that are generated
internally when the Imports to package2 are being loaded (either because
they are explicitly mentioned in the NAMESPACE file, or because they are
invoked by a "importedpackage1::fun_from_imported_package1" line of code).

I'll put a bug report together later today, and include my toy packages etc.

Once again thanks for looking at this for me

Geoff

-----Original Message-----
From: Duncan Murdoch [mailto:murdoch.duncan at gmail.com] 
Sent: Thursday, 27 November 2014 12:09 PM
To: Geoff Lee; r-devel at r-project.org
Subject: Re: [Rd] Problem understanding behaviour of versionCheck for
loadNamespace (and when versions for Imports packages are checked)

On 26/11/2014, 7:38 PM, Geoff Lee wrote:
> Many thanks Duncan for the quick response. 

A little too quick, it seems...
> 
> A bug is a relief in a way. I've been digging my way deeper into this 
> (and learning more as I go) for several days now - but it is a 
> diversion from (a diversion from) my main goal :-(
> 
> Is there somewhere specific I should report or log the bug or will 
> that happen from this mailing-list automatically? (I have seen the Bug 
> Tracking link on the r-project page and followed that, but don't yet 
> have a Bugzilla account, nor know the precise mechanics and protocols 
> for notifying a bug)

If you can put together a simple set of steps to illustrate a bug, then
reporting on bugs.r-project.org is the way to get it recorded.
Reporting it on this list is really hit and miss.  But I think from your
previous description, something else is going on.  When I try to load a
namespace with a bad version number, I get an error:

loadNamespace("rgl", versionCheck=list(name="rgl", op=">",
version=package_version('3.0')))
Error in loadNamespace("rgl", versionCheck = list(name = "rgl", op = ">",  :
  namespace 'rgl' 0.95.1163 is being loaded, but > 3.0 is required

Duncan Murdoch

> 
> Geoff
> 
> PS Building package2 - via devtools::build('package2', binary = TRUE) 
> does check and insist that I have an appropriate version of the 'to be
imported'
> package1 installed in my .libPath().
> 
> It was only when I simulated a user who has and older version of the 
> Imported package1 (by overwriting the later version of package 1 with 
> an earlier version), then trying to load or attach package2 that the 
> (failure of the version checking) at loadNamespace time for package1 
> became apparent (well apparentish after quite a bit of digging)
> 
> -----Original Message-----
> From: Duncan Murdoch [mailto:murdoch.duncan at gmail.com]
> Sent: Thursday, 27 November 2014 10:57 AM
> To: Geoff Lee; r-devel at r-project.org
> Subject: Re: [Rd] Problem understanding behaviour of versionCheck for 
> loadNamespace (and when versions for Imports packages are checked)
> 
> Summary:  I think you've found a bug.
> 
> On 26/11/2014, 5:39 PM, Geoff Lee wrote:
>> Hi
>>
>>  
>>
>> I'm still exploring the R programming universe, so if this is being 
>> asked in the wrong place, or in the wrong way (e.g. too verbose or 
>> lacking in crucial detail or in the wrong format) please let me know
>>
>>  
>>
>> I am trying to understand when the version constraints for packages 
>> which appear in the Imports field of a DESCRIPTION file are checked.
> 
> I would have assumed they are checked when you try to install the package.
> If you ask for version 3.0, and only have 0.3, the install should fail.
> 
> But as you've found, the documents say something else...
> 
>>
>>  
>>
>> Along the way I've hit a snag understanding what loadNamespace with 
>> the versionCheck argument set does.  The core of my query is 'am I 
>> doing something wrong, or have I stumbled across a bug?'.  Probably 
>> the former, but after several days I still can't figure it out, so 
>> any guidance, hints or outright help would be much appreciated.
>>
>>  
>>
>> Thanks in advance
>>
>>  
>>
>> Geoff
>>
>>  
>>
>> What I've tried so far.
>>
>>  
>>
>> "Writing R extensions" section 1.1.3 says
>>
>>  
>>
>> "The 'Imports' field lists packages whose namespaces are imported 
>> from (as specified in the NAMESPACE file) but which do not need to be
attached.
> ...
>> shortened for brevity ... Packages declared in the 'Depends' field 
>> should not also be in the 'Imports' field. Version requirements can 
>> be specified and are checked when the namespace is loaded (since R >=
3.0.0).
> "
>>
>>  
>>
>> It is slightly ambiguous, but seems to mean that the version 
>> dependencies for both Depends packages and Imports packages are 
>> checked when the package
>> (namespace?) is loaded.
>>
>>  
>>
>> The release notes for R3.0.0 are more direct.  They say
>>
>>  
>>
>> "loadNamespace() allows a version specification to be given, and this 
>> is used to check version specifications given in the Imports field 
>> when a namespace is loaded"
>>
>>  
>>
>> But some toy (locally built and loaded) examples seem to show that 
>> while the Depends versions are checked, the Imports version 
>> constraints are not (on Windows 64, running R3.1.2, see full 
>> session_info
> later).
>>
>>  
>>
>> My tests (package2 imports package1) use implicit loading (via the
>> package1::fun1() idiom) so I have worked back to try get a minimal 
>> example of what's causing me problems. I have tried
> 
> According to what you have written, that should have failed.  So it 
> looks like a bug.
>>
>>  
>>
>> loadNamespace('package2', versionCheck = list (op = ">=", version =
>> package_version('3.0')))
>>
>>  
>>
>> This should fail (package2 has version 0.3, not 3.0) but instead it 
>> seems to load package2, version 0.3 OK.
>>
>>  
>>
>> Reading the code of loadNamespace, there is some code which says
>>
>>  
>>
>> if (length(z <- versionCheck) == 3L && !do.call(z$op,
>>
>>     list(as.numeric_version(version), z$version)))
>>
>>     stop(gettextf("namespace %s %s is being loaded, but %s %s is 
>> required",
>>
>>       sQuote(package), version, z$op, z$version),
>>
>>        domain = NA)
>>
>>  
>>
>> I think it is the length(z <- versionCheck) == 3L part of the if test 
>> that is allowing the incorrect version be loaded.
> 
> That does seem like a typo.
> 
> Duncan Murdoch
> 
>>
>>  
>>
>> The documentation for loadNamespace says that "versionCheck" is
>>
>> "NULL or a version specification (a list with components op and
> version))."
>>
>>  
>>
>> If I add a third (nonsense) component to the versionCheck argument 
>> list, then loadNamespace does what I expect.  Is there supposed to be 
>> a third component in the list, and if so what should it be? Or is 
>> this a
> bug?
>>
>>  
>>
>> I've got this far and am now stumped, hence my query.
>>
>>  
>>
>> Some output from my tests.
>>
>>  
>>
>> d> devtools::session_info()
>>
>> Session
>> info-----------------------------------------------------------------
>> -
>> --
>>
>>   setting  value                       
>>
>> version  R version 3.1.2 (2014-10-31)
>>
>> system   x86_64, mingw32             
>>
>> ui       RStudio (0.98.953)          
>>
>> language (EN)                        
>>
>> collate  English_Australia.1252      
>>
>> tz       Australia/Sydney            
>>
>>  
>>
>> Packages-------------------------------------------------------------
>> -
>> ------
>> ----
>>
>>   package    * version date       source        
>>
>> devtools     1.6.1   2014-10-07 CRAN (R 3.1.2)
>>
>> rstudioapi   0.1     2014-03-27 CRAN (R 3.1.1)
>>
>>  
>>
>> d> # I think this should fail but it does not
>>
>> d> loadNamespace('package2', versionCheck = list(op='>=', version =
>> package_version('3.0')))
>>
>> <environment: namespace:package2>
>>
>>   
>>
>>   
>>
>>   d> devtools::session_info()
>>
>> Session
>> info-----------------------------------------------------------------
>> -
>> --
>>
>>   setting  value                       
>>
>> version  R version 3.1.2 (2014-10-31)
>>
>> system   x86_64, mingw32             
>>
>> ui       RStudio (0.98.953)          
>>
>> language (EN)                        
>>
>> collate  English_Australia.1252      
>>
>> tz       Australia/Sydney            
>>
>>  
>>
>> Packages-------------------------------------------------------------
>> -
>> ------
>> ----
>>
>>   package    * version date       source        
>>
>> devtools     1.6.1   2014-10-07 CRAN (R 3.1.2)
>>
>> package2     0.3     2014-11-24 local         
>>
>> rstudioapi   0.1     2014-03-27 CRAN (R 3.1.1)
>>
>>  
>>
>> d> #Try again with a third (nonsense) entry in the versionCheck list
>>
>> d> unloadNamespace('package2')
>>
>> d> loadNamespace('package2', versionCheck = list(op='>=', version =
>> package_version('3.0'), please = 'check it'))
>>
>> Error in loadNamespace("package2", versionCheck = list(op = ">=", 
>> version = package_version("3.0"),  :
>>
>>  namespace 'package2' 0.3 is being loaded, but >= 3.0 is required
>>
>>  
>>
>>  
>>
>>  
>>
>> d> devtools::session_info()
>>
>> Session
>> info-----------------------------------------------------------------
>> -
>> --
>>
>> setting  value                       
>>
>> version  R version 3.1.2 (2014-10-31)
>>
>> system   x86_64, mingw32             
>>
>> ui       RStudio (0.98.953)          
>>
>> language (EN)                        
>>
>> collate  English_Australia.1252      
>>
>> tz       Australia/Sydney            
>>
>>  
>>
>> Packages-------------------------------------------------------------
>> -
>> ------
>> ----
>>
>> package    * version date       source        
>>
>> devtools     1.6.1   2014-10-07 CRAN (R 3.1.2)
>>
>> rstudioapi   0.1     2014-03-27 CRAN (R 3.1.1)
>>
>> d> loadNamespace('package2', versionCheck = list(op='>=', version =
>> package_version('0.3'), please = 'check it'))
>>
>> <environment: namespace:package2>
>>
>> d>
>>
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
> 
>


From johannes.rainer at eurac.edu  Thu Nov 27 08:37:21 2014
From: johannes.rainer at eurac.edu (Johannes Rainer)
Date: Thu, 27 Nov 2014 08:37:21 +0100
Subject: [Rd] p.adjust on a vector including NA values
Message-ID: <CF5AE231-B861-4863-B47F-F98A7C269B97@eurac.edu>

dear all,

I recently came across the following issue and I was not sure whether it is intentionally or not:
using p.adjust to adjust p-values for multiple hypothesis testing using the method from Benjamini and Hochberg removes all NA values from the input vector and does not account for them in the adjustment, i.e. in a vector of 23 p-values with 20 of them being NA it adjusts the 3 non-NA p-values as if there had only been 3 tests to adjust for (see example). I was not aware of that behaviour, and also implementations like the one in Bioconductor's multtest package handle NAs differently.
If this behaviour is intentionally I would appreciate if a related note could be added to the help page.

Example:

x <- c( 0.001, 0.01, 0.02, rep( NA, 20 ) )
p.adjust( x, method="BH" )

 [1] 0.003 0.015 0.020    NA    NA    NA    NA    NA    NA    NA    NA    NA
[13]    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA

p.adjust( x, method="BH", n=length( x ) )
 [1] 0.0230000 0.1150000 0.1533333        NA        NA        NA        NA
 [8]        NA        NA        NA        NA        NA        NA        NA
[15]        NA        NA        NA        NA        NA        NA        NA
[22]        NA        NA

in the default settings (without specifying n, i.e. n=length(p)) the value of n is determined after all NAs have been removed from the p-value vector p.

cheers, jo

my R:
> sessionInfo()
R version 3.1.2 (2014-10-31)
Platform: x86_64-apple-darwin14.0.0/x86_64 (64-bit)

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     
>


From murdoch.duncan at gmail.com  Thu Nov 27 11:20:33 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 27 Nov 2014 05:20:33 -0500
Subject: [Rd] Problem understanding behaviour of versionCheck for
 loadNamespace (and when versions for Imports packages are checked)
In-Reply-To: <011601d009e1$a7929f00$f6b7dd00$@gmail.com>
References: <00ff01d009c9$db1446c0$913cd440$@bigpond.com>
	<547668E9.3050505@gmail.com>
	<011301d009da$845492c0$8cfdb840$@gmail.com>
	<547679A6.3000907@gmail.com>
	<011601d009e1$a7929f00$f6b7dd00$@gmail.com>
Message-ID: <5476FAF1.8080702@gmail.com>

On 26/11/2014, 8:29 PM, Geoff Lee wrote:
> Hi Duncan
> 
> The difference is that in your call to loadNamespace, the versionCheck list
> has 3 components (name, op and version), whereas the documentation only
> mentions 2 (op and version).
> loadNamespace 'works' for me provided I add a third component to the list
> (even a nonsense one).
> 
> What I haven't yet had the fortitude to do is track down through the code to
> see what the arguments are (ie how many elements there are in the
> versionCheck list) to any calls to loadNamespace that are generated
> internally when the Imports to package2 are being loaded (either because
> they are explicitly mentioned in the NAMESPACE file, or because they are
> invoked by a "importedpackage1::fun_from_imported_package1" line of code).
> 
> I'll put a bug report together later today, and include my toy packages etc.

As mentioned in a different message, the internal code creates a list
with members "name", "op", "version".  As you've noticed, the "name"
part is never used in the loadNamespace code.  I'm going to change the
code so that the documentation is correct.

But you said somewhere or other that you had an example where the
implicit load failed to do the check.  I don't see why it would.  So
that's what you should put in your bug report.

Duncan Murdoch

> 
> Once again thanks for looking at this for me
> 
> Geoff
> 
> -----Original Message-----
> From: Duncan Murdoch [mailto:murdoch.duncan at gmail.com] 
> Sent: Thursday, 27 November 2014 12:09 PM
> To: Geoff Lee; r-devel at r-project.org
> Subject: Re: [Rd] Problem understanding behaviour of versionCheck for
> loadNamespace (and when versions for Imports packages are checked)
> 
> On 26/11/2014, 7:38 PM, Geoff Lee wrote:
>> Many thanks Duncan for the quick response. 
> 
> A little too quick, it seems...
>>
>> A bug is a relief in a way. I've been digging my way deeper into this 
>> (and learning more as I go) for several days now - but it is a 
>> diversion from (a diversion from) my main goal :-(
>>
>> Is there somewhere specific I should report or log the bug or will 
>> that happen from this mailing-list automatically? (I have seen the Bug 
>> Tracking link on the r-project page and followed that, but don't yet 
>> have a Bugzilla account, nor know the precise mechanics and protocols 
>> for notifying a bug)
> 
> If you can put together a simple set of steps to illustrate a bug, then
> reporting on bugs.r-project.org is the way to get it recorded.
> Reporting it on this list is really hit and miss.  But I think from your
> previous description, something else is going on.  When I try to load a
> namespace with a bad version number, I get an error:
> 
> loadNamespace("rgl", versionCheck=list(name="rgl", op=">",
> version=package_version('3.0')))
> Error in loadNamespace("rgl", versionCheck = list(name = "rgl", op = ">",  :
>   namespace 'rgl' 0.95.1163 is being loaded, but > 3.0 is required
> 
> Duncan Murdoch
> 
>>
>> Geoff
>>
>> PS Building package2 - via devtools::build('package2', binary = TRUE) 
>> does check and insist that I have an appropriate version of the 'to be
> imported'
>> package1 installed in my .libPath().
>>
>> It was only when I simulated a user who has and older version of the 
>> Imported package1 (by overwriting the later version of package 1 with 
>> an earlier version), then trying to load or attach package2 that the 
>> (failure of the version checking) at loadNamespace time for package1 
>> became apparent (well apparentish after quite a bit of digging)
>>
>> -----Original Message-----
>> From: Duncan Murdoch [mailto:murdoch.duncan at gmail.com]
>> Sent: Thursday, 27 November 2014 10:57 AM
>> To: Geoff Lee; r-devel at r-project.org
>> Subject: Re: [Rd] Problem understanding behaviour of versionCheck for 
>> loadNamespace (and when versions for Imports packages are checked)
>>
>> Summary:  I think you've found a bug.
>>
>> On 26/11/2014, 5:39 PM, Geoff Lee wrote:
>>> Hi
>>>
>>>  
>>>
>>> I'm still exploring the R programming universe, so if this is being 
>>> asked in the wrong place, or in the wrong way (e.g. too verbose or 
>>> lacking in crucial detail or in the wrong format) please let me know
>>>
>>>  
>>>
>>> I am trying to understand when the version constraints for packages 
>>> which appear in the Imports field of a DESCRIPTION file are checked.
>>
>> I would have assumed they are checked when you try to install the package.
>> If you ask for version 3.0, and only have 0.3, the install should fail.
>>
>> But as you've found, the documents say something else...
>>
>>>
>>>  
>>>
>>> Along the way I've hit a snag understanding what loadNamespace with 
>>> the versionCheck argument set does.  The core of my query is 'am I 
>>> doing something wrong, or have I stumbled across a bug?'.  Probably 
>>> the former, but after several days I still can't figure it out, so 
>>> any guidance, hints or outright help would be much appreciated.
>>>
>>>  
>>>
>>> Thanks in advance
>>>
>>>  
>>>
>>> Geoff
>>>
>>>  
>>>
>>> What I've tried so far.
>>>
>>>  
>>>
>>> "Writing R extensions" section 1.1.3 says
>>>
>>>  
>>>
>>> "The 'Imports' field lists packages whose namespaces are imported 
>>> from (as specified in the NAMESPACE file) but which do not need to be
> attached.
>> ...
>>> shortened for brevity ... Packages declared in the 'Depends' field 
>>> should not also be in the 'Imports' field. Version requirements can 
>>> be specified and are checked when the namespace is loaded (since R >=
> 3.0.0).
>> "
>>>
>>>  
>>>
>>> It is slightly ambiguous, but seems to mean that the version 
>>> dependencies for both Depends packages and Imports packages are 
>>> checked when the package
>>> (namespace?) is loaded.
>>>
>>>  
>>>
>>> The release notes for R3.0.0 are more direct.  They say
>>>
>>>  
>>>
>>> "loadNamespace() allows a version specification to be given, and this 
>>> is used to check version specifications given in the Imports field 
>>> when a namespace is loaded"
>>>
>>>  
>>>
>>> But some toy (locally built and loaded) examples seem to show that 
>>> while the Depends versions are checked, the Imports version 
>>> constraints are not (on Windows 64, running R3.1.2, see full 
>>> session_info
>> later).
>>>
>>>  
>>>
>>> My tests (package2 imports package1) use implicit loading (via the
>>> package1::fun1() idiom) so I have worked back to try get a minimal 
>>> example of what's causing me problems. I have tried
>>
>> According to what you have written, that should have failed.  So it 
>> looks like a bug.
>>>
>>>  
>>>
>>> loadNamespace('package2', versionCheck = list (op = ">=", version =
>>> package_version('3.0')))
>>>
>>>  
>>>
>>> This should fail (package2 has version 0.3, not 3.0) but instead it 
>>> seems to load package2, version 0.3 OK.
>>>
>>>  
>>>
>>> Reading the code of loadNamespace, there is some code which says
>>>
>>>  
>>>
>>> if (length(z <- versionCheck) == 3L && !do.call(z$op,
>>>
>>>     list(as.numeric_version(version), z$version)))
>>>
>>>     stop(gettextf("namespace %s %s is being loaded, but %s %s is 
>>> required",
>>>
>>>       sQuote(package), version, z$op, z$version),
>>>
>>>        domain = NA)
>>>
>>>  
>>>
>>> I think it is the length(z <- versionCheck) == 3L part of the if test 
>>> that is allowing the incorrect version be loaded.
>>
>> That does seem like a typo.
>>
>> Duncan Murdoch
>>
>>>
>>>  
>>>
>>> The documentation for loadNamespace says that "versionCheck" is
>>>
>>> "NULL or a version specification (a list with components op and
>> version))."
>>>
>>>  
>>>
>>> If I add a third (nonsense) component to the versionCheck argument 
>>> list, then loadNamespace does what I expect.  Is there supposed to be 
>>> a third component in the list, and if so what should it be? Or is 
>>> this a
>> bug?
>>>
>>>  
>>>
>>> I've got this far and am now stumped, hence my query.
>>>
>>>  
>>>
>>> Some output from my tests.
>>>
>>>  
>>>
>>> d> devtools::session_info()
>>>
>>> Session
>>> info-----------------------------------------------------------------
>>> -
>>> --
>>>
>>>   setting  value                       
>>>
>>> version  R version 3.1.2 (2014-10-31)
>>>
>>> system   x86_64, mingw32             
>>>
>>> ui       RStudio (0.98.953)          
>>>
>>> language (EN)                        
>>>
>>> collate  English_Australia.1252      
>>>
>>> tz       Australia/Sydney            
>>>
>>>  
>>>
>>> Packages-------------------------------------------------------------
>>> -
>>> ------
>>> ----
>>>
>>>   package    * version date       source        
>>>
>>> devtools     1.6.1   2014-10-07 CRAN (R 3.1.2)
>>>
>>> rstudioapi   0.1     2014-03-27 CRAN (R 3.1.1)
>>>
>>>  
>>>
>>> d> # I think this should fail but it does not
>>>
>>> d> loadNamespace('package2', versionCheck = list(op='>=', version =
>>> package_version('3.0')))
>>>
>>> <environment: namespace:package2>
>>>
>>>   
>>>
>>>   
>>>
>>>   d> devtools::session_info()
>>>
>>> Session
>>> info-----------------------------------------------------------------
>>> -
>>> --
>>>
>>>   setting  value                       
>>>
>>> version  R version 3.1.2 (2014-10-31)
>>>
>>> system   x86_64, mingw32             
>>>
>>> ui       RStudio (0.98.953)          
>>>
>>> language (EN)                        
>>>
>>> collate  English_Australia.1252      
>>>
>>> tz       Australia/Sydney            
>>>
>>>  
>>>
>>> Packages-------------------------------------------------------------
>>> -
>>> ------
>>> ----
>>>
>>>   package    * version date       source        
>>>
>>> devtools     1.6.1   2014-10-07 CRAN (R 3.1.2)
>>>
>>> package2     0.3     2014-11-24 local         
>>>
>>> rstudioapi   0.1     2014-03-27 CRAN (R 3.1.1)
>>>
>>>  
>>>
>>> d> #Try again with a third (nonsense) entry in the versionCheck list
>>>
>>> d> unloadNamespace('package2')
>>>
>>> d> loadNamespace('package2', versionCheck = list(op='>=', version =
>>> package_version('3.0'), please = 'check it'))
>>>
>>> Error in loadNamespace("package2", versionCheck = list(op = ">=", 
>>> version = package_version("3.0"),  :
>>>
>>>  namespace 'package2' 0.3 is being loaded, but >= 3.0 is required
>>>
>>>  
>>>
>>>  
>>>
>>>  
>>>
>>> d> devtools::session_info()
>>>
>>> Session
>>> info-----------------------------------------------------------------
>>> -
>>> --
>>>
>>> setting  value                       
>>>
>>> version  R version 3.1.2 (2014-10-31)
>>>
>>> system   x86_64, mingw32             
>>>
>>> ui       RStudio (0.98.953)          
>>>
>>> language (EN)                        
>>>
>>> collate  English_Australia.1252      
>>>
>>> tz       Australia/Sydney            
>>>
>>>  
>>>
>>> Packages-------------------------------------------------------------
>>> -
>>> ------
>>> ----
>>>
>>> package    * version date       source        
>>>
>>> devtools     1.6.1   2014-10-07 CRAN (R 3.1.2)
>>>
>>> rstudioapi   0.1     2014-03-27 CRAN (R 3.1.1)
>>>
>>> d> loadNamespace('package2', versionCheck = list(op='>=', version =
>>> package_version('0.3'), please = 'check it'))
>>>
>>> <environment: namespace:package2>
>>>
>>> d>
>>>
>>>
>>> 	[[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>
>>
> 
>


From pgilbert902 at gmail.com  Thu Nov 27 17:23:34 2014
From: pgilbert902 at gmail.com (Paul Gilbert)
Date: Thu, 27 Nov 2014 11:23:34 -0500
Subject: [Rd] testing dontrun  examples
In-Reply-To: <5476590E.1040804@gmail.com>
References: <54761FC6.3090007@gmail.com> <5476590E.1040804@gmail.com>
Message-ID: <54775006.5000101@gmail.com>



On 14-11-26 05:49 PM, Duncan Murdoch wrote:
> On 26/11/2014, 1:45 PM, Paul Gilbert wrote:
>> Is there a good strategy for testing examples which should not be run by
>> default? For instance, I have examples which get data from the Internet.
>> If I wrap them in try() then they can be skipped if the Internet is not
>> available, but may not be tested in cases when I would like to know
>> about the failure. (Not to mention that the example syntax is ugly.)
>>
>> If I mark them \dontrun or \donttest then they are not tested. I could
>> mark them \dontrun and then use example() but for this, in addition to
>> run.dontrun=TRUE, I would need to specify all topics for a package, and
>> I don't see how to do this, missing topic does not work.
>>
>> Wishlist: what I would really like is R CMD check --run-dontrun   pkg
>
>
> We have that in R-devel, so everyone will have it next April, but there
> will possibly be bugs unless people like you try it out now.

Are you anticipating my wishes now, or did you tell me this and it 
entered my subconscious? So far it works as advertised.

Thanks,
Paul
>
> Duncan Murdoch
>


From janko.thyson at gmail.com  Thu Nov 27 18:45:16 2014
From: janko.thyson at gmail.com (Janko Thyson)
Date: Thu, 27 Nov 2014 18:45:16 +0100
Subject: [Rd] Feature request: mixing `...` (three dots) with other formal
 arguments in S4 methods
Message-ID: <CAGmpuejTqw=_bfVaWN9idUukpKBJkfmd2G=+m0NCkkmieRkkTg@mail.gmail.com>

Dear List,

I'm currently investigating if the argument dispatch mechanism based on
`...` could somehow be "generalized" to scenarios that involve `r`
recipients located across `c` calling stack layers *and* combined with the
S4 method mechanism (for those interested see
http://stackoverflow.com/questions/26963900/generalizing-three-dots-argument-dispatch-s4-methods-for-argument-set-i
for an (conceptual) approach of how this could be realized).

AFAICT, this would require that `...` can be *mixed* with other signature
arguments, which is currently not supported as stated in `?dotsMethods`:

Quote {
Using "..." in a Signature

Beginning with version 2.8.0 of R, S4 methods can be dispatched (selected
and called) corresponding to the special argument ?...?. Currently, ?...?
cannot be mixed with other formal arguments: either the signature of the
generic function is ?...? only, or it does not contain ?...?. (This
restriction may be lifted in a future version.)
}

Would it be possible to consider lifting this limitation soon?

Thanks a lot to everyone maintaining R!!

Janko

	[[alternative HTML version deleted]]


From gmbecker at ucdavis.edu  Thu Nov 27 19:48:25 2014
From: gmbecker at ucdavis.edu (Gabriel Becker)
Date: Thu, 27 Nov 2014 10:48:25 -0800
Subject: [Rd] Feature request: mixing `...` (three dots) with other
 formal arguments in S4 methods
In-Reply-To: <CAGmpuejTqw=_bfVaWN9idUukpKBJkfmd2G=+m0NCkkmieRkkTg@mail.gmail.com>
References: <CAGmpuejTqw=_bfVaWN9idUukpKBJkfmd2G=+m0NCkkmieRkkTg@mail.gmail.com>
Message-ID: <CADwqtCPtsmn-xyBB1yq-EcUHvZpghmEDKCELMiJWiSTWJHWQag@mail.gmail.com>

Janko,

I'm not entirely sure I understand your proposal. Are you suggesting
methods be dispatched based on the *contents* of ... (ie which arguments
are in there)? This seems like it would be pretty different from how
dispatch behaves now, which is entirely class based.

Even the dispatching based on ... via dots methods is class based, having
nothing to do AFAIK with the argument names. From ?dotsMethods

A method selecting on ?...? is specified by a single class in the call to
setMethod <http://127.0.0.1:11942/library/methods/help/setMethod>. If all
the actual arguments corresponding to ?...? have this class, the
corresponding method is selected directly.

Otherwise, the class of each argument and that class' superclasses are
computed, beginning with the first ?...? argument. For the first argument,
eligible methods are those for any of the classes. For each succeeding
argument that introduces a class not considered previously, the eligible
methods are further restricted to those matching the argument's class or
superclasses. If no further eligible classes exist, the iteration breaks
out and the default method, if any, is selected.


No mention of argument name there.

~G

On Thu, Nov 27, 2014 at 9:45 AM, Janko Thyson <janko.thyson at gmail.com>
wrote:

> Dear List,
>
> I'm currently investigating if the argument dispatch mechanism based on
> `...` could somehow be "generalized" to scenarios that involve `r`
> recipients located across `c` calling stack layers *and* combined with the
> S4 method mechanism (for those interested see
>
> http://stackoverflow.com/questions/26963900/generalizing-three-dots-argument-dispatch-s4-methods-for-argument-set-i
> for an (conceptual) approach of how this could be realized).
>
> AFAICT, this would require that `...` can be *mixed* with other signature
> arguments, which is currently not supported as stated in `?dotsMethods`:
>
> Quote {
> Using "..." in a Signature
>
> Beginning with version 2.8.0 of R, S4 methods can be dispatched (selected
> and called) corresponding to the special argument ?...?. Currently, ?...?
> cannot be mixed with other formal arguments: either the signature of the
> generic function is ?...? only, or it does not contain ?...?. (This
> restriction may be lifted in a future version.)
> }
>
> Would it be possible to consider lifting this limitation soon?
>
> Thanks a lot to everyone maintaining R!!
>
> Janko
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>



-- 
Gabriel Becker
Graduate Student
Statistics Department
University of California, Davis

	[[alternative HTML version deleted]]


From edd at debian.org  Thu Nov 27 19:55:09 2014
From: edd at debian.org (Dirk Eddelbuettel)
Date: Thu, 27 Nov 2014 12:55:09 -0600
Subject: [Rd] testing dontrun  examples
In-Reply-To: <54775006.5000101@gmail.com>
References: <54761FC6.3090007@gmail.com> <5476590E.1040804@gmail.com>
	<54775006.5000101@gmail.com>
Message-ID: <21623.29581.953874.858216@max.nulle.part>


On 27 November 2014 at 11:23, Paul Gilbert wrote:
| On 14-11-26 05:49 PM, Duncan Murdoch wrote:
| > On 26/11/2014, 1:45 PM, Paul Gilbert wrote:
| >> Wishlist: what I would really like is R CMD check --run-dontrun   pkg
| >
| > We have that in R-devel, so everyone will have it next April, but there
| > will possibly be bugs unless people like you try it out now.
| 
| Are you anticipating my wishes now, or did you tell me this and it 
| entered my subconscious? So far it works as advertised.

AFAICR Duncan said so in the long recent thread on the issue.

It was also reported as a change in the NEWS.Rd file, and hence communicated
via the (very useful, I find) RSS feed reporting changes in NEWS.Rd:
     
    http://developer.r-project.org/blosxom.cgi/R-devel

Dirk

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From janko.thyson at gmail.com  Thu Nov 27 20:26:38 2014
From: janko.thyson at gmail.com (Janko Thyson)
Date: Thu, 27 Nov 2014 20:26:38 +0100
Subject: [Rd] Feature request: mixing `...` (three dots) with other
 formal arguments in S4 methods
In-Reply-To: <CADwqtCPtsmn-xyBB1yq-EcUHvZpghmEDKCELMiJWiSTWJHWQag@mail.gmail.com>
References: <CAGmpuejTqw=_bfVaWN9idUukpKBJkfmd2G=+m0NCkkmieRkkTg@mail.gmail.com>
	<CADwqtCPtsmn-xyBB1yq-EcUHvZpghmEDKCELMiJWiSTWJHWQag@mail.gmail.com>
Message-ID: <CAGmpueg=AhvJwhw9qFtWXxEJjdXw8gFhmAXvFwQ67+R01atEqQ@mail.gmail.com>

Hi Gabriel,

and thanks for answering. I'm basically just trying to find a way to use
the power of `...` in more complex scenarios and I'm well aware that this
might not be the best approach ;-)

Regarding your actual question:
"Are you suggesting methods be dispatched based on the *contents* of ...
[...]?"
Yes, I guess currently I kind of do - but not on the argument *names*

I'm not expecting functions to detect the argument *names*  from `...`, but
the relevant "argument containers" from which then the actual arguments
should be extracted and used:

I thought the *actual* arguments to be passed via `...` to subsequent
functions/methods could be put into an "arguments container" (as a list so
you could easily use them with `do.call(foo)`) that has a class that `foo`
expects for its `...` argument (e.g. `ThreedotsForFoo`). What I would like
to accomplish is that `foo` auto-detects those parts coming in via `...`
that are *relevant* for itself (e.g. instances of the argument container
`ThreedotsForFoo`), that it handles them in a proper way (i.e. extracting
the *actual* arguments from the container) and that it passes `...` along
to subsequently called functions.

That's why I would need methods that use mix of regular formal arguments
and `...`.

Best regards,
Janko


On Thu, Nov 27, 2014 at 7:48 PM, Gabriel Becker <gmbecker at ucdavis.edu>
wrote:

> Janko,
>
> I'm not entirely sure I understand your proposal. Are you suggesting
> methods be dispatched based on the *contents* of ... (ie which arguments
> are in there)? This seems like it would be pretty different from how
> dispatch behaves now, which is entirely class based.
>
> Even the dispatching based on ... via dots methods is class based, having
> nothing to do AFAIK with the argument names. From ?dotsMethods
>
> A method selecting on ?...? is specified by a single class in the call to
> setMethod <http://127.0.0.1:11942/library/methods/help/setMethod>. If all
> the actual arguments corresponding to ?...? have this class, the
> corresponding method is selected directly.
>
> Otherwise, the class of each argument and that class' superclasses are
> computed, beginning with the first ?...? argument. For the first argument,
> eligible methods are those for any of the classes. For each succeeding
> argument that introduces a class not considered previously, the eligible
> methods are further restricted to those matching the argument's class or
> superclasses. If no further eligible classes exist, the iteration breaks
> out and the default method, if any, is selected.
>
>
> No mention of argument name there.
>
> ~G
>
> On Thu, Nov 27, 2014 at 9:45 AM, Janko Thyson <janko.thyson at gmail.com>
> wrote:
>
>> Dear List,
>>
>> I'm currently investigating if the argument dispatch mechanism based on
>> `...` could somehow be "generalized" to scenarios that involve `r`
>> recipients located across `c` calling stack layers *and* combined with the
>> S4 method mechanism (for those interested see
>>
>> http://stackoverflow.com/questions/26963900/generalizing-three-dots-argument-dispatch-s4-methods-for-argument-set-i
>> for an (conceptual) approach of how this could be realized).
>>
>> AFAICT, this would require that `...` can be *mixed* with other signature
>> arguments, which is currently not supported as stated in `?dotsMethods`:
>>
>> Quote {
>> Using "..." in a Signature
>>
>> Beginning with version 2.8.0 of R, S4 methods can be dispatched (selected
>> and called) corresponding to the special argument ?...?. Currently, ?...?
>> cannot be mixed with other formal arguments: either the signature of the
>> generic function is ?...? only, or it does not contain ?...?. (This
>> restriction may be lifted in a future version.)
>> }
>>
>> Would it be possible to consider lifting this limitation soon?
>>
>> Thanks a lot to everyone maintaining R!!
>>
>> Janko
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
>
>
> --
> Gabriel Becker
> Graduate Student
> Statistics Department
> University of California, Davis
>

	[[alternative HTML version deleted]]


From geoff.lee99 at gmail.com  Thu Nov 27 22:12:28 2014
From: geoff.lee99 at gmail.com (Geoff Lee)
Date: Fri, 28 Nov 2014 08:12:28 +1100
Subject: [Rd] Problem understanding behaviour of versionCheck for
	loadNamespace (and when versions for Imports packages are checked)
In-Reply-To: <5476FAF1.8080702@gmail.com>
References: <00ff01d009c9$db1446c0$913cd440$@bigpond.com>
	<547668E9.3050505@gmail.com>
	<011301d009da$845492c0$8cfdb840$@gmail.com>
	<547679A6.3000907@gmail.com>
	<011601d009e1$a7929f00$f6b7dd00$@gmail.com>
	<5476FAF1.8080702@gmail.com>
Message-ID: <017401d00a86$df119030$9d34b090$@gmail.com>

Hi Duncan,

Many thanks (yet again).

With the hint given by your earlier email (viz that currently loadNamespace
expects a 3rd component called name in the list that is used for the
versionCheck argument) I had another look at what was going on with my toy
examples yesterday evening.  I'm still working on my issue, but thus far I
have:

1) Confirmed that internal calls to loadNamespace triggered by
import(somePackage) statements in the NAMESPACE file do create a
versionCheck argument that has 3 components in the list.  I deduce (but have
not worked my way through the specific lines of code insde loadNamespace)
that the name is needed while processing the 'import(somepackage)' NAMESPACE
directive at some stage (otherwise how do you know what installed
'somepackage' to import and find the version of!) but is *probably* not
needed in the versionCheck list argument itself when the loadNamespace call
is done (since by then the name 'somepackage' is used as the package
argument to the call).  I will (very very gratefully) leave to you the
resolution of the mismatch between the checkVersion documentation, and the
actual implementation - whether you change the documentation (easiest) or
the implementation (means tracking down and amending all the internally
generated calls) is not something I'm up to even contemplating at the
moment.

2) Discovered that the NAMESPACE file in my toy examples did not contain
correct import() or importfrom() statements. I'm still figuring out why (it
*appears* to be due to the way I have used devtools::create() and then
roxygen2 comments and then devtools::document() to generate my toy
examples.)  Once I figure out what is happening and have 'valid' toy
examples I will either a) 'shut up' (because I have found my own error) P
>.5; b)follow up the issue of how the NAMESPACE file was by devtools with
devtools itself  P ~ .3; or c)come back to this list since I am still
struggling P ~< .2

If the protocol is that I should record the complete resolution of my
question (for the benefit of future readers) pls let me know and I will do
that (once I get there!).

Geoff

PS Moral for me : Think twice before pulling on a loose piece of string.
I've learnt heaps - but I'm still not finished :-(  (At this stage the
benefits of the learning >> the pain of the journey, so I'll keep going)

-----Original Message-----
From: Duncan Murdoch [mailto:murdoch.duncan at gmail.com] 
Sent: Thursday, 27 November 2014 9:21 PM
To: Geoff Lee; r-devel at r-project.org
Subject: Re: [Rd] Problem understanding behaviour of versionCheck for
loadNamespace (and when versions for Imports packages are checked)

On 26/11/2014, 8:29 PM, Geoff Lee wrote:
> Hi Duncan
> 
> The difference is that in your call to loadNamespace, the versionCheck 
> list has 3 components (name, op and version), whereas the 
> documentation only mentions 2 (op and version).
> loadNamespace 'works' for me provided I add a third component to the 
> list (even a nonsense one).
> 
> What I haven't yet had the fortitude to do is track down through the 
> code to see what the arguments are (ie how many elements there are in 
> the versionCheck list) to any calls to loadNamespace that are 
> generated internally when the Imports to package2 are being loaded 
> (either because they are explicitly mentioned in the NAMESPACE file, 
> or because they are invoked by a
"importedpackage1::fun_from_imported_package1" line of code).
> 
> I'll put a bug report together later today, and include my toy packages
etc.

As mentioned in a different message, the internal code creates a list with
members "name", "op", "version".  As you've noticed, the "name"
part is never used in the loadNamespace code.  I'm going to change the code
so that the documentation is correct.

But you said somewhere or other that you had an example where the implicit
load failed to do the check.  I don't see why it would.  So that's what you
should put in your bug report.

Duncan Murdoch

> 
> Once again thanks for looking at this for me
> 
> Geoff
> 
> -----Original Message-----
> From: Duncan Murdoch [mailto:murdoch.duncan at gmail.com]
> Sent: Thursday, 27 November 2014 12:09 PM
> To: Geoff Lee; r-devel at r-project.org
> Subject: Re: [Rd] Problem understanding behaviour of versionCheck for 
> loadNamespace (and when versions for Imports packages are checked)
> 
> On 26/11/2014, 7:38 PM, Geoff Lee wrote:
>> Many thanks Duncan for the quick response. 
> 
> A little too quick, it seems...
>>
>> A bug is a relief in a way. I've been digging my way deeper into this 
>> (and learning more as I go) for several days now - but it is a 
>> diversion from (a diversion from) my main goal :-(
>>
>> Is there somewhere specific I should report or log the bug or will 
>> that happen from this mailing-list automatically? (I have seen the 
>> Bug Tracking link on the r-project page and followed that, but don't 
>> yet have a Bugzilla account, nor know the precise mechanics and 
>> protocols for notifying a bug)
> 
> If you can put together a simple set of steps to illustrate a bug, 
> then reporting on bugs.r-project.org is the way to get it recorded.
> Reporting it on this list is really hit and miss.  But I think from 
> your previous description, something else is going on.  When I try to 
> load a namespace with a bad version number, I get an error:
> 
> loadNamespace("rgl", versionCheck=list(name="rgl", op=">",
> version=package_version('3.0')))
> Error in loadNamespace("rgl", versionCheck = list(name = "rgl", op = ">",
:
>   namespace 'rgl' 0.95.1163 is being loaded, but > 3.0 is required
> 
> Duncan Murdoch
> 
>>
>> Geoff
>>
>> PS Building package2 - via devtools::build('package2', binary = TRUE) 
>> does check and insist that I have an appropriate version of the 'to 
>> be
> imported'
>> package1 installed in my .libPath().
>>
>> It was only when I simulated a user who has and older version of the 
>> Imported package1 (by overwriting the later version of package 1 with 
>> an earlier version), then trying to load or attach package2 that the 
>> (failure of the version checking) at loadNamespace time for package1 
>> became apparent (well apparentish after quite a bit of digging)
>>
>> -----Original Message-----
>> From: Duncan Murdoch [mailto:murdoch.duncan at gmail.com]
>> Sent: Thursday, 27 November 2014 10:57 AM
>> To: Geoff Lee; r-devel at r-project.org
>> Subject: Re: [Rd] Problem understanding behaviour of versionCheck for 
>> loadNamespace (and when versions for Imports packages are checked)
>>
>> Summary:  I think you've found a bug.
>>
>> On 26/11/2014, 5:39 PM, Geoff Lee wrote:
>>> Hi
>>>
>>>  
>>>
>>> I'm still exploring the R programming universe, so if this is being 
>>> asked in the wrong place, or in the wrong way (e.g. too verbose or 
>>> lacking in crucial detail or in the wrong format) please let me know
>>>
>>>  
>>>
>>> I am trying to understand when the version constraints for packages 
>>> which appear in the Imports field of a DESCRIPTION file are checked.
>>
>> I would have assumed they are checked when you try to install the
package.
>> If you ask for version 3.0, and only have 0.3, the install should fail.
>>
>> But as you've found, the documents say something else...
>>
>>>
>>>  
>>>
>>> Along the way I've hit a snag understanding what loadNamespace with 
>>> the versionCheck argument set does.  The core of my query is 'am I 
>>> doing something wrong, or have I stumbled across a bug?'.  Probably 
>>> the former, but after several days I still can't figure it out, so 
>>> any guidance, hints or outright help would be much appreciated.
>>>
>>>  
>>>
>>> Thanks in advance
>>>
>>>  
>>>
>>> Geoff
>>>
>>>  
>>>
>>> What I've tried so far.
>>>
>>>  
>>>
>>> "Writing R extensions" section 1.1.3 says
>>>
>>>  
>>>
>>> "The 'Imports' field lists packages whose namespaces are imported 
>>> from (as specified in the NAMESPACE file) but which do not need to 
>>> be
> attached.
>> ...
>>> shortened for brevity ... Packages declared in the 'Depends' field 
>>> should not also be in the 'Imports' field. Version requirements can 
>>> be specified and are checked when the namespace is loaded (since R 
>>> >=
> 3.0.0).
>> "
>>>
>>>  
>>>
>>> It is slightly ambiguous, but seems to mean that the version 
>>> dependencies for both Depends packages and Imports packages are 
>>> checked when the package
>>> (namespace?) is loaded.
>>>
>>>  
>>>
>>> The release notes for R3.0.0 are more direct.  They say
>>>
>>>  
>>>
>>> "loadNamespace() allows a version specification to be given, and 
>>> this is used to check version specifications given in the Imports 
>>> field when a namespace is loaded"
>>>
>>>  
>>>
>>> But some toy (locally built and loaded) examples seem to show that 
>>> while the Depends versions are checked, the Imports version 
>>> constraints are not (on Windows 64, running R3.1.2, see full 
>>> session_info
>> later).
>>>
>>>  
>>>
>>> My tests (package2 imports package1) use implicit loading (via the
>>> package1::fun1() idiom) so I have worked back to try get a minimal 
>>> example of what's causing me problems. I have tried
>>
>> According to what you have written, that should have failed.  So it 
>> looks like a bug.
>>>
>>>  
>>>
>>> loadNamespace('package2', versionCheck = list (op = ">=", version =
>>> package_version('3.0')))
>>>
>>>  
>>>
>>> This should fail (package2 has version 0.3, not 3.0) but instead it 
>>> seems to load package2, version 0.3 OK.
>>>
>>>  
>>>
>>> Reading the code of loadNamespace, there is some code which says
>>>
>>>  
>>>
>>> if (length(z <- versionCheck) == 3L && !do.call(z$op,
>>>
>>>     list(as.numeric_version(version), z$version)))
>>>
>>>     stop(gettextf("namespace %s %s is being loaded, but %s %s is 
>>> required",
>>>
>>>       sQuote(package), version, z$op, z$version),
>>>
>>>        domain = NA)
>>>
>>>  
>>>
>>> I think it is the length(z <- versionCheck) == 3L part of the if 
>>> test that is allowing the incorrect version be loaded.
>>
>> That does seem like a typo.
>>
>> Duncan Murdoch
>>
>>>
>>>  
>>>
>>> The documentation for loadNamespace says that "versionCheck" is
>>>
>>> "NULL or a version specification (a list with components op and
>> version))."
>>>
>>>  
>>>
>>> If I add a third (nonsense) component to the versionCheck argument 
>>> list, then loadNamespace does what I expect.  Is there supposed to 
>>> be a third component in the list, and if so what should it be? Or is 
>>> this a
>> bug?
>>>
>>>  
>>>
>>> I've got this far and am now stumped, hence my query.
>>>
>>>  
>>>
>>> Some output from my tests.
>>>
>>>  
>>>
>>> d> devtools::session_info()
>>>
>>> Session
>>> info----------------------------------------------------------------
>>> -
>>> -
>>> --
>>>
>>>   setting  value                       
>>>
>>> version  R version 3.1.2 (2014-10-31)
>>>
>>> system   x86_64, mingw32             
>>>
>>> ui       RStudio (0.98.953)          
>>>
>>> language (EN)                        
>>>
>>> collate  English_Australia.1252      
>>>
>>> tz       Australia/Sydney            
>>>
>>>  
>>>
>>> Packages------------------------------------------------------------
>>> -
>>> -
>>> ------
>>> ----
>>>
>>>   package    * version date       source        
>>>
>>> devtools     1.6.1   2014-10-07 CRAN (R 3.1.2)
>>>
>>> rstudioapi   0.1     2014-03-27 CRAN (R 3.1.1)
>>>
>>>  
>>>
>>> d> # I think this should fail but it does not
>>>
>>> d> loadNamespace('package2', versionCheck = list(op='>=', version =
>>> package_version('3.0')))
>>>
>>> <environment: namespace:package2>
>>>
>>>   
>>>
>>>   
>>>
>>>   d> devtools::session_info()
>>>
>>> Session
>>> info----------------------------------------------------------------
>>> -
>>> -
>>> --
>>>
>>>   setting  value                       
>>>
>>> version  R version 3.1.2 (2014-10-31)
>>>
>>> system   x86_64, mingw32             
>>>
>>> ui       RStudio (0.98.953)          
>>>
>>> language (EN)                        
>>>
>>> collate  English_Australia.1252      
>>>
>>> tz       Australia/Sydney            
>>>
>>>  
>>>
>>> Packages------------------------------------------------------------
>>> -
>>> -
>>> ------
>>> ----
>>>
>>>   package    * version date       source        
>>>
>>> devtools     1.6.1   2014-10-07 CRAN (R 3.1.2)
>>>
>>> package2     0.3     2014-11-24 local         
>>>
>>> rstudioapi   0.1     2014-03-27 CRAN (R 3.1.1)
>>>
>>>  
>>>
>>> d> #Try again with a third (nonsense) entry in the versionCheck list
>>>
>>> d> unloadNamespace('package2')
>>>
>>> d> loadNamespace('package2', versionCheck = list(op='>=', version =
>>> package_version('3.0'), please = 'check it'))
>>>
>>> Error in loadNamespace("package2", versionCheck = list(op = ">=", 
>>> version = package_version("3.0"),  :
>>>
>>>  namespace 'package2' 0.3 is being loaded, but >= 3.0 is required
>>>
>>>  
>>>
>>>  
>>>
>>>  
>>>
>>> d> devtools::session_info()
>>>
>>> Session
>>> info----------------------------------------------------------------
>>> -
>>> -
>>> --
>>>
>>> setting  value                       
>>>
>>> version  R version 3.1.2 (2014-10-31)
>>>
>>> system   x86_64, mingw32             
>>>
>>> ui       RStudio (0.98.953)          
>>>
>>> language (EN)                        
>>>
>>> collate  English_Australia.1252      
>>>
>>> tz       Australia/Sydney            
>>>
>>>  
>>>
>>> Packages------------------------------------------------------------
>>> -
>>> -
>>> ------
>>> ----
>>>
>>> package    * version date       source        
>>>
>>> devtools     1.6.1   2014-10-07 CRAN (R 3.1.2)
>>>
>>> rstudioapi   0.1     2014-03-27 CRAN (R 3.1.1)
>>>
>>> d> loadNamespace('package2', versionCheck = list(op='>=', version =
>>> package_version('0.3'), please = 'check it'))
>>>
>>> <environment: namespace:package2>
>>>
>>> d>
>>>
>>>
>>> 	[[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>
>>
> 
>


From gmbecker at ucdavis.edu  Fri Nov 28 02:40:52 2014
From: gmbecker at ucdavis.edu (Gabriel Becker)
Date: Thu, 27 Nov 2014 17:40:52 -0800
Subject: [Rd] Feature request: mixing `...` (three dots) with other
 formal arguments in S4 methods
In-Reply-To: <CAGmpueg=AhvJwhw9qFtWXxEJjdXw8gFhmAXvFwQ67+R01atEqQ@mail.gmail.com>
References: <CAGmpuejTqw=_bfVaWN9idUukpKBJkfmd2G=+m0NCkkmieRkkTg@mail.gmail.com>
	<CADwqtCPtsmn-xyBB1yq-EcUHvZpghmEDKCELMiJWiSTWJHWQag@mail.gmail.com>
	<CAGmpueg=AhvJwhw9qFtWXxEJjdXw8gFhmAXvFwQ67+R01atEqQ@mail.gmail.com>
Message-ID: <CADwqtCOXUmCJTr_wVycrAhzcvZ0Lc21Qj+P1Hi4=7Scm6Qfm-A@mail.gmail.com>

I think I understand what you're saying now, but I'm still kind of missing
the benefit from the approach.

As far as I can tell just giving foo formals for the arguments you want it
to catch gives you the end result you want, doesn't it?

And if the generic has ... in it, you can (if you're very careful) add
formals to specific methods that would capture arguments not meant for
other methods of the same generic.

~G

On Thu, Nov 27, 2014 at 11:26 AM, Janko Thyson <janko.thyson at gmail.com>
wrote:

> Hi Gabriel,
>
> and thanks for answering. I'm basically just trying to find a way to use
> the power of `...` in more complex scenarios and I'm well aware that this
> might not be the best approach ;-)
>
> Regarding your actual question:
> "Are you suggesting methods be dispatched based on the *contents* of ...
> [...]?"
> Yes, I guess currently I kind of do - but not on the argument *names*
>
> I'm not expecting functions to detect the argument *names*  from `...`,
> but the relevant "argument containers" from which then the actual arguments
> should be extracted and used:
>
> I thought the *actual* arguments to be passed via `...` to subsequent
> functions/methods could be put into an "arguments container" (as a list so
> you could easily use them with `do.call(foo)`) that has a class that `foo`
> expects for its `...` argument (e.g. `ThreedotsForFoo`). What I would like
> to accomplish is that `foo` auto-detects those parts coming in via `...`
> that are *relevant* for itself (e.g. instances of the argument container
> `ThreedotsForFoo`), that it handles them in a proper way (i.e. extracting
> the *actual* arguments from the container) and that it passes `...` along
> to subsequently called functions.
>
> That's why I would need methods that use mix of regular formal arguments
> and `...`.
>
> Best regards,
> Janko
>
>
> On Thu, Nov 27, 2014 at 7:48 PM, Gabriel Becker <gmbecker at ucdavis.edu>
> wrote:
>
>> Janko,
>>
>> I'm not entirely sure I understand your proposal. Are you suggesting
>> methods be dispatched based on the *contents* of ... (ie which arguments
>> are in there)? This seems like it would be pretty different from how
>> dispatch behaves now, which is entirely class based.
>>
>> Even the dispatching based on ... via dots methods is class based, having
>> nothing to do AFAIK with the argument names. From ?dotsMethods
>>
>> A method selecting on ?...? is specified by a single class in the call to
>> setMethod <http://127.0.0.1:11942/library/methods/help/setMethod>. If
>> all the actual arguments corresponding to ?...? have this class, the
>> corresponding method is selected directly.
>>
>> Otherwise, the class of each argument and that class' superclasses are
>> computed, beginning with the first ?...? argument. For the first argument,
>> eligible methods are those for any of the classes. For each succeeding
>> argument that introduces a class not considered previously, the eligible
>> methods are further restricted to those matching the argument's class or
>> superclasses. If no further eligible classes exist, the iteration breaks
>> out and the default method, if any, is selected.
>>
>>
>> No mention of argument name there.
>>
>> ~G
>>
>> On Thu, Nov 27, 2014 at 9:45 AM, Janko Thyson <janko.thyson at gmail.com>
>> wrote:
>>
>>> Dear List,
>>>
>>> I'm currently investigating if the argument dispatch mechanism based on
>>> `...` could somehow be "generalized" to scenarios that involve `r`
>>> recipients located across `c` calling stack layers *and* combined with
>>> the
>>> S4 method mechanism (for those interested see
>>>
>>> http://stackoverflow.com/questions/26963900/generalizing-three-dots-argument-dispatch-s4-methods-for-argument-set-i
>>> for an (conceptual) approach of how this could be realized).
>>>
>>> AFAICT, this would require that `...` can be *mixed* with other signature
>>> arguments, which is currently not supported as stated in `?dotsMethods`:
>>>
>>> Quote {
>>> Using "..." in a Signature
>>>
>>> Beginning with version 2.8.0 of R, S4 methods can be dispatched (selected
>>> and called) corresponding to the special argument ?...?. Currently, ?...?
>>> cannot be mixed with other formal arguments: either the signature of the
>>> generic function is ?...? only, or it does not contain ?...?. (This
>>> restriction may be lifted in a future version.)
>>> }
>>>
>>> Would it be possible to consider lifting this limitation soon?
>>>
>>> Thanks a lot to everyone maintaining R!!
>>>
>>> Janko
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>
>>
>>
>> --
>> Gabriel Becker
>> Graduate Student
>> Statistics Department
>> University of California, Davis
>>
>
>


-- 
Gabriel Becker
Graduate Student
Statistics Department
University of California, Davis

	[[alternative HTML version deleted]]


From janko.thyson at gmail.com  Fri Nov 28 03:53:39 2014
From: janko.thyson at gmail.com (Janko Thyson)
Date: Fri, 28 Nov 2014 03:53:39 +0100
Subject: [Rd] Feature request: mixing `...` (three dots) with other
 formal arguments in S4 methods
In-Reply-To: <CADwqtCOXUmCJTr_wVycrAhzcvZ0Lc21Qj+P1Hi4=7Scm6Qfm-A@mail.gmail.com>
References: <CAGmpuejTqw=_bfVaWN9idUukpKBJkfmd2G=+m0NCkkmieRkkTg@mail.gmail.com>
	<CADwqtCPtsmn-xyBB1yq-EcUHvZpghmEDKCELMiJWiSTWJHWQag@mail.gmail.com>
	<CAGmpueg=AhvJwhw9qFtWXxEJjdXw8gFhmAXvFwQ67+R01atEqQ@mail.gmail.com>
	<CADwqtCOXUmCJTr_wVycrAhzcvZ0Lc21Qj+P1Hi4=7Scm6Qfm-A@mail.gmail.com>
Message-ID: <CAGmpuehOb4HDA4N0vsgK2=k0qk0ucxvKumwicQj5uwm96LgqMg@mail.gmail.com>

Well, the benefit lies in the ability to pass along arguments via `...` to
more than one recipient that use *identical argument names* and/or when
these recipients are not necessarily located on the same calling stack
layer.

I'm *not* after a *general* change in the way arguments are
dispatched/functions are called as I'm actually a big friend of keepings
things quite explicit (thus declaring explicitly what's passed on to
subsequent functions by defining respective formal arguments).
Nevertheless, sometimes it's quite handy to use `...`.

Consider the implementation of `plot()`. It uses `...` quite extensively to
pass things along to `par()` which makes perfect sense: declaring formal
arguments for things that are merely passed along to `par()` in *all*
functions that depend on `par()` would probably be a developer's nightmare
w.r.t. refactoring should `par()` ever change.

But let's say that at one point in time, developers decide that `par()` can
also call something like `parShiny()` if `shiny = TRUE` in order
encapsulate shiny-specific graphical parameters in a own function (sorry, I
couldn't come up with a better example just now).  I'm using a simplified
example where `cex` is indeed a formal parameter (which is not the case in
the actual `par()`):

myPlot <- function(x, ...) {
  myPar(...)
}
myPar <- function (cex = 1.0, shiny = FALSE, ...) {
  if (!shiny) {
    message("myPar/cex:")
    print(cex)
  } else {
    parShiny(...)
  }
}
parShiny <- function (cex = 1.0) {
  message("parShiny/cex:")
  print(cex)
}
> myPlot(x = 10, cex = 1.25)
myPar/cex:
[1] 1.25

> myPlot(x = 10, cex = 1.25, shiny = TRUE)
parShiny/cex:
[1] 1

So: due to the fact that `myPar()` has a formal argument `cex`, `...` is
out of the question for passing along `cex` to `parShiny()`. You'd have to
change things to `parShiny(cex = cex)` in the implementation of `myPar()`
in order for this to work as expected - which you might or might not feel
is (too) cumbersome.

While it probably makes a lot of sense to pass things along explicitly in
95 % of cases, there might be situations where you'd prefer to being able
to use `...`.

But I don't want to overstress the (current) purpose/use case behind my
request. I just wondered if the limitation of not being able to mix `...`
with other formal arguments could be lifted soon as the possiblity is
already stated at `?dotsMethods` :-)

On Fri, Nov 28, 2014 at 2:40 AM, Gabriel Becker <gmbecker at ucdavis.edu>
wrote:

> I think I understand what you're saying now, but I'm still kind of missing
> the benefit from the approach.
>
> As far as I can tell just giving foo formals for the arguments you want it
> to catch gives you the end result you want, doesn't it?
>
> And if the generic has ... in it, you can (if you're very careful) add
> formals to specific methods that would capture arguments not meant for
> other methods of the same generic.
>
> ~G
>
> On Thu, Nov 27, 2014 at 11:26 AM, Janko Thyson <janko.thyson at gmail.com>
> wrote:
>
>> Hi Gabriel,
>>
>> and thanks for answering. I'm basically just trying to find a way to use
>> the power of `...` in more complex scenarios and I'm well aware that this
>> might not be the best approach ;-)
>>
>> Regarding your actual question:
>> "Are you suggesting methods be dispatched based on the *contents* of ...
>> [...]?"
>> Yes, I guess currently I kind of do - but not on the argument *names*
>>
>> I'm not expecting functions to detect the argument *names*  from `...`,
>> but the relevant "argument containers" from which then the actual arguments
>> should be extracted and used:
>>
>> I thought the *actual* arguments to be passed via `...` to subsequent
>> functions/methods could be put into an "arguments container" (as a list so
>> you could easily use them with `do.call(foo)`) that has a class that `foo`
>> expects for its `...` argument (e.g. `ThreedotsForFoo`). What I would like
>> to accomplish is that `foo` auto-detects those parts coming in via `...`
>> that are *relevant* for itself (e.g. instances of the argument container
>> `ThreedotsForFoo`), that it handles them in a proper way (i.e. extracting
>> the *actual* arguments from the container) and that it passes `...` along
>> to subsequently called functions.
>>
>> That's why I would need methods that use mix of regular formal arguments
>> and `...`.
>>
>> Best regards,
>> Janko
>>
>>
>> On Thu, Nov 27, 2014 at 7:48 PM, Gabriel Becker <gmbecker at ucdavis.edu>
>> wrote:
>>
>>> Janko,
>>>
>>> I'm not entirely sure I understand your proposal. Are you suggesting
>>> methods be dispatched based on the *contents* of ... (ie which arguments
>>> are in there)? This seems like it would be pretty different from how
>>> dispatch behaves now, which is entirely class based.
>>>
>>> Even the dispatching based on ... via dots methods is class based,
>>> having nothing to do AFAIK with the argument names. From ?dotsMethods
>>>
>>> A method selecting on ?...? is specified by a single class in the call
>>> to setMethod <http://127.0.0.1:11942/library/methods/help/setMethod>.
>>> If all the actual arguments corresponding to ?...? have this class, the
>>> corresponding method is selected directly.
>>>
>>> Otherwise, the class of each argument and that class' superclasses are
>>> computed, beginning with the first ?...? argument. For the first argument,
>>> eligible methods are those for any of the classes. For each succeeding
>>> argument that introduces a class not considered previously, the eligible
>>> methods are further restricted to those matching the argument's class or
>>> superclasses. If no further eligible classes exist, the iteration breaks
>>> out and the default method, if any, is selected.
>>>
>>>
>>> No mention of argument name there.
>>>
>>> ~G
>>>
>>> On Thu, Nov 27, 2014 at 9:45 AM, Janko Thyson <janko.thyson at gmail.com>
>>> wrote:
>>>
>>>> Dear List,
>>>>
>>>> I'm currently investigating if the argument dispatch mechanism based on
>>>> `...` could somehow be "generalized" to scenarios that involve `r`
>>>> recipients located across `c` calling stack layers *and* combined with
>>>> the
>>>> S4 method mechanism (for those interested see
>>>>
>>>> http://stackoverflow.com/questions/26963900/generalizing-three-dots-argument-dispatch-s4-methods-for-argument-set-i
>>>> for an (conceptual) approach of how this could be realized).
>>>>
>>>> AFAICT, this would require that `...` can be *mixed* with other
>>>> signature
>>>> arguments, which is currently not supported as stated in `?dotsMethods`:
>>>>
>>>> Quote {
>>>> Using "..." in a Signature
>>>>
>>>> Beginning with version 2.8.0 of R, S4 methods can be dispatched
>>>> (selected
>>>> and called) corresponding to the special argument ?...?. Currently,
>>>> ?...?
>>>> cannot be mixed with other formal arguments: either the signature of the
>>>> generic function is ?...? only, or it does not contain ?...?. (This
>>>> restriction may be lifted in a future version.)
>>>> }
>>>>
>>>> Would it be possible to consider lifting this limitation soon?
>>>>
>>>> Thanks a lot to everyone maintaining R!!
>>>>
>>>> Janko
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>
>>>
>>>
>>>
>>> --
>>> Gabriel Becker
>>> Graduate Student
>>> Statistics Department
>>> University of California, Davis
>>>
>>
>>
>
>
> --
> Gabriel Becker
> Graduate Student
> Statistics Department
> University of California, Davis
>

	[[alternative HTML version deleted]]


From geoff.lee99 at gmail.com  Sat Nov 29 02:25:02 2014
From: geoff.lee99 at gmail.com (Geoff Lee)
Date: Sat, 29 Nov 2014 12:25:02 +1100
Subject: [Rd] Problem understanding behaviour of versionCheck for
	loadNamespace (and when versions for Imports packages are checked)
In-Reply-To: <017401d00a86$df119030$9d34b090$@gmail.com>
References: <00ff01d009c9$db1446c0$913cd440$@bigpond.com>
	<547668E9.3050505@gmail.com>
	<011301d009da$845492c0$8cfdb840$@gmail.com>
	<547679A6.3000907@gmail.com>
	<011601d009e1$a7929f00$f6b7dd00$@gmail.com>
	<5476FAF1.8080702@gmail.com>
	<017401d00a86$df119030$9d34b090$@gmail.com>
Message-ID: <005001d00b73$51137a80$f33a6f80$@gmail.com>

Hi Duncan and others,

For the record I think I have pinned down what happens wrt checking the
version of an imported package.

In summary :

loadNamespace behaves as it ought to (once the discrepancy between the
documentation and reality of the versionCheck argument is taken into
account).

However (if packageA is the package to be imported) using the
"packageA::funA" idiom in packageB *instead* of using a NAMESPACE file with
either @import(package) or @importFrom(packageA, funA) seems to circumvent
the checking of whatever constraints on the version of packageA were given
in the packageB DESCRIPTION file.

I rather suspect this will fall into the category of "correct behaviour,
just not what I wanted) from the `::` function in this instance" rather than
a bug but I have recorded the behaviour, and made my toy examples available
as Bug 16094 on the R Bug reporting system.

Hoping this makes sense, and helps someone else later on down the track

Geoff

PS Along the way I had a problem with devtools and roxygen2 - it was my
error! I had a typo - a backtick ` when I should have had a single quote '
in a roxygen2 comment :-(

-----Original Message-----
From: Geoff Lee [mailto:geoff.lee99 at gmail.com] 
Sent: Friday, 28 November 2014 8:12 AM
To: 'Duncan Murdoch'; r-devel at r-project.org
Subject: RE: [Rd] Problem understanding behaviour of versionCheck for
loadNamespace (and when versions for Imports packages are checked)

Hi Duncan,

Many thanks (yet again).

With the hint given by your earlier email (viz that currently loadNamespace
expects a 3rd component called name in the list that is used for the
versionCheck argument) I had another look at what was going on with my toy
examples yesterday evening.  I'm still working on my issue, but thus far I
have:

1) Confirmed that internal calls to loadNamespace triggered by
import(somePackage) statements in the NAMESPACE file do create a
versionCheck argument that has 3 components in the list.  I deduce (but have
not worked my way through the specific lines of code insde loadNamespace)
that the name is needed while processing the 'import(somepackage)' NAMESPACE
directive at some stage (otherwise how do you know what installed
'somepackage' to import and find the version of!) but is *probably* not
needed in the versionCheck list argument itself when the loadNamespace call
is done (since by then the name 'somepackage' is used as the package
argument to the call).  I will (very very gratefully) leave to you the
resolution of the mismatch between the checkVersion documentation, and the
actual implementation - whether you change the documentation (easiest) or
the implementation (means tracking down and amending all the internally
generated calls) is not something I'm up to even contemplating at the
moment.

2) Discovered that the NAMESPACE file in my toy examples did not contain
correct import() or importfrom() statements. I'm still figuring out why (it
*appears* to be due to the way I have used devtools::create() and then
roxygen2 comments and then devtools::document() to generate my toy
examples.)  Once I figure out what is happening and have 'valid' toy
examples I will either a) 'shut up' (because I have found my own error) P
>.5; b)follow up the issue of how the NAMESPACE file was by devtools 
>with
devtools itself  P ~ .3; or c)come back to this list since I am still
struggling P ~< .2

If the protocol is that I should record the complete resolution of my
question (for the benefit of future readers) pls let me know and I will do
that (once I get there!).

Geoff

PS Moral for me : Think twice before pulling on a loose piece of string.
I've learnt heaps - but I'm still not finished :-(  (At this stage the
benefits of the learning >> the pain of the journey, so I'll keep going)

-----Original Message-----
From: Duncan Murdoch [mailto:murdoch.duncan at gmail.com]
Sent: Thursday, 27 November 2014 9:21 PM
To: Geoff Lee; r-devel at r-project.org
Subject: Re: [Rd] Problem understanding behaviour of versionCheck for
loadNamespace (and when versions for Imports packages are checked)

On 26/11/2014, 8:29 PM, Geoff Lee wrote:
> Hi Duncan
> 
> The difference is that in your call to loadNamespace, the versionCheck 
> list has 3 components (name, op and version), whereas the 
> documentation only mentions 2 (op and version).
> loadNamespace 'works' for me provided I add a third component to the 
> list (even a nonsense one).
> 
> What I haven't yet had the fortitude to do is track down through the 
> code to see what the arguments are (ie how many elements there are in 
> the versionCheck list) to any calls to loadNamespace that are 
> generated internally when the Imports to package2 are being loaded 
> (either because they are explicitly mentioned in the NAMESPACE file, 
> or because they are invoked by a
"importedpackage1::fun_from_imported_package1" line of code).
> 
> I'll put a bug report together later today, and include my toy 
> packages
etc.

As mentioned in a different message, the internal code creates a list with
members "name", "op", "version".  As you've noticed, the "name"
part is never used in the loadNamespace code.  I'm going to change the code
so that the documentation is correct.

But you said somewhere or other that you had an example where the implicit
load failed to do the check.  I don't see why it would.  So that's what you
should put in your bug report.

Duncan Murdoch

> 
> Once again thanks for looking at this for me
> 
> Geoff
> 
> -----Original Message-----
> From: Duncan Murdoch [mailto:murdoch.duncan at gmail.com]
> Sent: Thursday, 27 November 2014 12:09 PM
> To: Geoff Lee; r-devel at r-project.org
> Subject: Re: [Rd] Problem understanding behaviour of versionCheck for 
> loadNamespace (and when versions for Imports packages are checked)
> 
> On 26/11/2014, 7:38 PM, Geoff Lee wrote:
>> Many thanks Duncan for the quick response. 
> 
> A little too quick, it seems...
>>
>> A bug is a relief in a way. I've been digging my way deeper into this 
>> (and learning more as I go) for several days now - but it is a 
>> diversion from (a diversion from) my main goal :-(
>>
>> Is there somewhere specific I should report or log the bug or will 
>> that happen from this mailing-list automatically? (I have seen the 
>> Bug Tracking link on the r-project page and followed that, but don't 
>> yet have a Bugzilla account, nor know the precise mechanics and 
>> protocols for notifying a bug)
> 
> If you can put together a simple set of steps to illustrate a bug, 
> then reporting on bugs.r-project.org is the way to get it recorded.
> Reporting it on this list is really hit and miss.  But I think from 
> your previous description, something else is going on.  When I try to 
> load a namespace with a bad version number, I get an error:
> 
> loadNamespace("rgl", versionCheck=list(name="rgl", op=">",
> version=package_version('3.0')))
> Error in loadNamespace("rgl", versionCheck = list(name = "rgl", op = 
> ">",
:
>   namespace 'rgl' 0.95.1163 is being loaded, but > 3.0 is required
> 
> Duncan Murdoch
> 
>>
>> Geoff
>>
>> PS Building package2 - via devtools::build('package2', binary = TRUE) 
>> does check and insist that I have an appropriate version of the 'to 
>> be
> imported'
>> package1 installed in my .libPath().
>>
>> It was only when I simulated a user who has and older version of the 
>> Imported package1 (by overwriting the later version of package 1 with 
>> an earlier version), then trying to load or attach package2 that the 
>> (failure of the version checking) at loadNamespace time for package1 
>> became apparent (well apparentish after quite a bit of digging)
>>
>> -----Original Message-----
>> From: Duncan Murdoch [mailto:murdoch.duncan at gmail.com]
>> Sent: Thursday, 27 November 2014 10:57 AM
>> To: Geoff Lee; r-devel at r-project.org
>> Subject: Re: [Rd] Problem understanding behaviour of versionCheck for 
>> loadNamespace (and when versions for Imports packages are checked)
>>
>> Summary:  I think you've found a bug.
>>
>> On 26/11/2014, 5:39 PM, Geoff Lee wrote:
>>> Hi
>>>
>>>  
>>>
>>> I'm still exploring the R programming universe, so if this is being 
>>> asked in the wrong place, or in the wrong way (e.g. too verbose or 
>>> lacking in crucial detail or in the wrong format) please let me know
>>>
>>>  
>>>
>>> I am trying to understand when the version constraints for packages 
>>> which appear in the Imports field of a DESCRIPTION file are checked.
>>
>> I would have assumed they are checked when you try to install the
package.
>> If you ask for version 3.0, and only have 0.3, the install should fail.
>>
>> But as you've found, the documents say something else...
>>
>>>
>>>  
>>>
>>> Along the way I've hit a snag understanding what loadNamespace with 
>>> the versionCheck argument set does.  The core of my query is 'am I 
>>> doing something wrong, or have I stumbled across a bug?'.  Probably 
>>> the former, but after several days I still can't figure it out, so 
>>> any guidance, hints or outright help would be much appreciated.
>>>
>>>  
>>>
>>> Thanks in advance
>>>
>>>  
>>>
>>> Geoff
>>>
>>>  
>>>
>>> What I've tried so far.
>>>
>>>  
>>>
>>> "Writing R extensions" section 1.1.3 says
>>>
>>>  
>>>
>>> "The 'Imports' field lists packages whose namespaces are imported 
>>> from (as specified in the NAMESPACE file) but which do not need to 
>>> be
> attached.
>> ...
>>> shortened for brevity ... Packages declared in the 'Depends' field 
>>> should not also be in the 'Imports' field. Version requirements can 
>>> be specified and are checked when the namespace is loaded (since R
>>> >=
> 3.0.0).
>> "
>>>
>>>  
>>>
>>> It is slightly ambiguous, but seems to mean that the version 
>>> dependencies for both Depends packages and Imports packages are 
>>> checked when the package
>>> (namespace?) is loaded.
>>>
>>>  
>>>
>>> The release notes for R3.0.0 are more direct.  They say
>>>
>>>  
>>>
>>> "loadNamespace() allows a version specification to be given, and 
>>> this is used to check version specifications given in the Imports 
>>> field when a namespace is loaded"
>>>
>>>  
>>>
>>> But some toy (locally built and loaded) examples seem to show that 
>>> while the Depends versions are checked, the Imports version 
>>> constraints are not (on Windows 64, running R3.1.2, see full 
>>> session_info
>> later).
>>>
>>>  
>>>
>>> My tests (package2 imports package1) use implicit loading (via the
>>> package1::fun1() idiom) so I have worked back to try get a minimal 
>>> example of what's causing me problems. I have tried
>>
>> According to what you have written, that should have failed.  So it 
>> looks like a bug.
>>>
>>>  
>>>
>>> loadNamespace('package2', versionCheck = list (op = ">=", version =
>>> package_version('3.0')))
>>>
>>>  
>>>
>>> This should fail (package2 has version 0.3, not 3.0) but instead it 
>>> seems to load package2, version 0.3 OK.
>>>
>>>  
>>>
>>> Reading the code of loadNamespace, there is some code which says
>>>
>>>  
>>>
>>> if (length(z <- versionCheck) == 3L && !do.call(z$op,
>>>
>>>     list(as.numeric_version(version), z$version)))
>>>
>>>     stop(gettextf("namespace %s %s is being loaded, but %s %s is 
>>> required",
>>>
>>>       sQuote(package), version, z$op, z$version),
>>>
>>>        domain = NA)
>>>
>>>  
>>>
>>> I think it is the length(z <- versionCheck) == 3L part of the if 
>>> test that is allowing the incorrect version be loaded.
>>
>> That does seem like a typo.
>>
>> Duncan Murdoch
>>
>>>
>>>  
>>>
>>> The documentation for loadNamespace says that "versionCheck" is
>>>
>>> "NULL or a version specification (a list with components op and
>> version))."
>>>
>>>  
>>>
>>> If I add a third (nonsense) component to the versionCheck argument 
>>> list, then loadNamespace does what I expect.  Is there supposed to 
>>> be a third component in the list, and if so what should it be? Or is 
>>> this a
>> bug?
>>>
>>>  
>>>
>>> I've got this far and am now stumped, hence my query.
>>>
>>>  
>>>
>>> Some output from my tests.
>>>
>>>  
>>>
>>> d> devtools::session_info()
>>>
>>> Session
>>> info----------------------------------------------------------------
>>> -
>>> -
>>> --
>>>
>>>   setting  value                       
>>>
>>> version  R version 3.1.2 (2014-10-31)
>>>
>>> system   x86_64, mingw32             
>>>
>>> ui       RStudio (0.98.953)          
>>>
>>> language (EN)                        
>>>
>>> collate  English_Australia.1252      
>>>
>>> tz       Australia/Sydney            
>>>
>>>  
>>>
>>> Packages------------------------------------------------------------
>>> -
>>> -
>>> ------
>>> ----
>>>
>>>   package    * version date       source        
>>>
>>> devtools     1.6.1   2014-10-07 CRAN (R 3.1.2)
>>>
>>> rstudioapi   0.1     2014-03-27 CRAN (R 3.1.1)
>>>
>>>  
>>>
>>> d> # I think this should fail but it does not
>>>
>>> d> loadNamespace('package2', versionCheck = list(op='>=', version =
>>> package_version('3.0')))
>>>
>>> <environment: namespace:package2>
>>>
>>>   
>>>
>>>   
>>>
>>>   d> devtools::session_info()
>>>
>>> Session
>>> info----------------------------------------------------------------
>>> -
>>> -
>>> --
>>>
>>>   setting  value                       
>>>
>>> version  R version 3.1.2 (2014-10-31)
>>>
>>> system   x86_64, mingw32             
>>>
>>> ui       RStudio (0.98.953)          
>>>
>>> language (EN)                        
>>>
>>> collate  English_Australia.1252      
>>>
>>> tz       Australia/Sydney            
>>>
>>>  
>>>
>>> Packages------------------------------------------------------------
>>> -
>>> -
>>> ------
>>> ----
>>>
>>>   package    * version date       source        
>>>
>>> devtools     1.6.1   2014-10-07 CRAN (R 3.1.2)
>>>
>>> package2     0.3     2014-11-24 local         
>>>
>>> rstudioapi   0.1     2014-03-27 CRAN (R 3.1.1)
>>>
>>>  
>>>
>>> d> #Try again with a third (nonsense) entry in the versionCheck list
>>>
>>> d> unloadNamespace('package2')
>>>
>>> d> loadNamespace('package2', versionCheck = list(op='>=', version =
>>> package_version('3.0'), please = 'check it'))
>>>
>>> Error in loadNamespace("package2", versionCheck = list(op = ">=", 
>>> version = package_version("3.0"),  :
>>>
>>>  namespace 'package2' 0.3 is being loaded, but >= 3.0 is required
>>>
>>>  
>>>
>>>  
>>>
>>>  
>>>
>>> d> devtools::session_info()
>>>
>>> Session
>>> info----------------------------------------------------------------
>>> -
>>> -
>>> --
>>>
>>> setting  value                       
>>>
>>> version  R version 3.1.2 (2014-10-31)
>>>
>>> system   x86_64, mingw32             
>>>
>>> ui       RStudio (0.98.953)          
>>>
>>> language (EN)                        
>>>
>>> collate  English_Australia.1252      
>>>
>>> tz       Australia/Sydney            
>>>
>>>  
>>>
>>> Packages------------------------------------------------------------
>>> -
>>> -
>>> ------
>>> ----
>>>
>>> package    * version date       source        
>>>
>>> devtools     1.6.1   2014-10-07 CRAN (R 3.1.2)
>>>
>>> rstudioapi   0.1     2014-03-27 CRAN (R 3.1.1)
>>>
>>> d> loadNamespace('package2', versionCheck = list(op='>=', version =
>>> package_version('0.3'), please = 'check it'))
>>>
>>> <environment: namespace:package2>
>>>
>>> d>
>>>
>>>
>>> 	[[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>
>>
> 
>


From mhahsler at lyle.smu.edu  Sun Nov 30 07:46:59 2014
From: mhahsler at lyle.smu.edu (Michael Hahsler)
Date: Sun, 30 Nov 2014 00:46:59 -0600
Subject: [Rd] Using FPP preprocessor for Fortran Code
Message-ID: <547ABD63.9060606@lyle.smu.edu>

Dear R Developers,

For package seriation I use Fortran code. I recently got a request to add

#if defined(__ICC) || defined(__INTEL_COMPILER)
       USE IFPORT
#endif

to the code since the Intel Fortran compiler otherwise has problems with 
rand(). However, to enable the FPP preprocessor I have to either add a 
compiler flag (-cpp for gFortran) which is possibly not portable or 
change the extension to .F, .fpp, .FPP (and a few others) which 
automatically invokes the preprocessor (hopefully on all platforms). I 
tried .fpp and added the following to Makevars:

OBJECTS=arsa.o bburcg.o bbwrcg.o bea.o criterion.o dist.o fprintf.o 
greedy.o optimal.o stress.o

%.o: %.fpp
         $(F77) $(ALL_FFLAGS) -c $< -o $@

It seems to work (I tried Linux and Windows) but R CMD check gives me:

* checking if this is a source package ... WARNING
Subdirectory ?src? contains:
   arsa.fpp bburcg.fpp

Is there a different preferred method to do this? Is it possible to add 
support for Fortran with the fpp preprocessor (.fpp files) to the R 
package building process?

Thanks,
Michael

-- 
   Michael Hahsler, Assistant Professor
   Department of Engineering Management, Information, and Systems
   Department of Computer Science and Engineering (by courtesy)
   Bobby B. Lyle School of Engineering
   Southern Methodist University, Dallas, Texas

   office: Caruth Hall, suite 337, room 311
   email:  mhahsler at lyle.smu.edu
   web:    http://lyle.smu.edu/~mhahsler


