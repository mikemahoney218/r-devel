From ripley at stats.ox.ac.uk  Sat Jan  1 11:58:16 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 1 Jan 2011 10:58:16 +0000 (GMT)
Subject: [Rd] Want non-ASCII characters in data package
In-Reply-To: <4D1B65A1.1020203@gmail.com>
References: <4D1B65A1.1020203@gmail.com>
Message-ID: <alpine.LFD.2.00.1101011052240.23147@gannet.stats.ox.ac.uk>

On Wed, 29 Dec 2010, Kevin R. Coombes wrote:

> Hi,
>
> I have a data frame that includes several names that (if typeset correctly) 
> require accented characters not available in the ASCII character set.
>
> I'd like to include this data frame as example data in an R package.  I'd 
> also like the R CMD check warning about the use of non-ASCII characters to go 
> away, in part so I could submit the package somewhere that wouldn't balk at 
> the presence of the warning.  (I gather from older posts that there are 
> environment variables to skip this check.  Those will work for me personally 
> but will not necessarily appease the maintainers of sites like CRAN where I 
> might want to submit the package.)
>
> Is there any way to use the correctly accented characters by setting a 
> different character encoding or equivalent for the data frame? Or am I forced 
> to remove the offending accents in order to be ASCII-pure and thus leave 
> people and places with an incorrect representation of their names?

The latter is inevitable.  There is no encoding that will work 
correctly for everyone (see 'Writing R Extensions' ?1.7.1): e.g. 
Chinese Windows users have only ASCII and Chinese characters (and only 
one of two sets of Chinese characters).  Again, good practice and 
compromises are discussed in 'Writing R Extensions' -- these days 
using UTF-8 will do a good job for most R users.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From matteo at naufraghi.net  Mon Jan  3 11:26:09 2011
From: matteo at naufraghi.net (Matteo Bertini)
Date: Mon, 3 Jan 2011 11:26:09 +0100
Subject: [Rd] key-value mapping in C inside R?
In-Reply-To: <AANLkTinpt1Ssi2Cg4SRgtmkSPib9UGA4fggZmVM=tmuu@mail.gmail.com>
References: <4D1C8012.7050403@naufraghi.net>
	<AANLkTinpt1Ssi2Cg4SRgtmkSPib9UGA4fggZmVM=tmuu@mail.gmail.com>
Message-ID: <AANLkTikWZXgSFqpXEmsvWkPGEPrfeVOL0MFc20ZH9WWO@mail.gmail.com>

On Thu, Dec 30, 2010 at 9:34 PM, Hadley Wickham <hadley at rice.edu> wrote:
> Why not use a sparse Matrix package?
> Hadley

In the original arima.c code the matrix is represented as an array of double.
I'd like to add a minimal overhead/changes on the code.

I think I'll use a simple sorted linked list to store the key-value map.
It will be enough for testing and I'll use something better if needed.

Thanks,
Matteo Bertini


From maechler at stat.math.ethz.ch  Mon Jan  3 16:21:41 2011
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 3 Jan 2011 16:21:41 +0100
Subject: [Rd] RFC: sapply() limitation from vector to matrix,
	but not further
In-Reply-To: <AANLkTikeGUT5yCLrhg7kA-8=QQsWcr6B8s1w5weoEbvO@mail.gmail.com>
References: <19702.2469.739772.13707@lynne.math.ethz.ch>
	<AANLkTin6pbS_99RjSje12Zr7M9mwLy0oKNX7H8gz1Zgh@mail.gmail.com>
	<19738.1821.84824.284589@cmath-6.math.ethz.ch>
	<4D1A290C.8040205@acm.org>
	<AANLkTikeGUT5yCLrhg7kA-8=QQsWcr6B8s1w5weoEbvO@mail.gmail.com>
Message-ID: <19745.59781.225579.416547@lynne.math.ethz.ch>

>>>>> Martin Maechler <maechler at stat.math.ethz.ch>
>>>>>     on Tue, 28 Dec 2010 20:06:07 +0100 writes:

    > On Tue, Dec 28, 2010 at 19:14, Tony Plate <tplate at acm.org>
    > wrote:
    >> The abind() function from the abind package is an
    >> alternative here -- it can take a list argument, which
    >> makes it easy to use with the result of lapply(). ?It's
    >> also able take direction about which dimension to join
    >> on.
    >> 
    >>> x <- list(a=1,b=2,c=3) f <- function(v) matrix(v,
    >>> nrow=2, ncol=4) sapply(x, f)
    >> ? ? a b c [1,] 1 2 3 [2,] 1 2 3 [3,] 1 2 3 [4,] 1 2 3
    >> [5,] 1 2 3 [6,] 1 2 3 [7,] 1 2 3 [8,] 1 2 3
    >>> 
    >>> # The 'along=' argument to abind() determines on which
    >>> dimension # the list elements are joined. ?Use a
    >>> fractional value to put the new # dimension between
    >>> existing ones.
    >>> 
    >>> dim(abind(lapply(x, f), along=0))
    >> [1] 3 2 4
    >>> dim(abind(lapply(x, f), along=1.5))
    >> [1] 2 3 4
    >>> dim(abind(lapply(x, f), along=3))
    >> [1] 2 4 3
    >>> abind(lapply(x, f), along=3)
    >> , , a
    >> 
    >> ? ? [,1] [,2] [,3] [,4] [1,] ? ?1 ? ?1 ? ?1 ? ?1 [2,] ?
    >> ?1 ? ?1 ? ?1 ? ?1
    >> 
    >> , , b
    >> 
    >> ? ? [,1] [,2] [,3] [,4] [1,] ? ?2 ? ?2 ? ?2 ? ?2 [2,] ?
    >> ?2 ? ?2 ? ?2 ? ?2
    >> 
    >> , , c
    >> 
    >> ? ? [,1] [,2] [,3] [,4] [1,] ? ?3 ? ?3 ? ?3 ? ?3 [2,] ?
    >> ?3 ? ?3 ? ?3 ? ?3
    >> 

    > Thank you, Tony.
    > Indeed, yes, abind() is nice here (and in the good ol' APL
    > spirit !)

    > Wanting to keep things both simple *and* fast here, of
    > course, hence I currently contemplate the following code,
    > where the new simplify2array() is considerably simpler
    > than abind():

>     ##' "Simplify" a list of commonly structured components into an array.
>     ##'
>     ##' @title simplify list() to an array if the list elements are structurally equal
>     ##' @param x a list, typically resulting from lapply()
>     ##' @param higher logical indicating if an array() of "higher rank"
>     ##'  should be returned when appropriate, namely when all elements of
>     ##' \code{x} have the same \code{\link{dim}()}ension.
>     ##' @return x itself, or an array if the simplification "is sensible"
>     simplify2array <- function(x, higher = TRUE)
>     {
> 	if(length(common.len <- unique(unlist(lapply(x, length)))) > 1L)
> 	    return(x)
> 	if(common.len == 1L)
> 	    unlist(x, recursive = FALSE)
> 	else if(common.len > 1L) {
> 	    n <- length(x)
> 	    ## make sure that array(*) will not call rep() {e.g. for 'call's}:
> 	    r <- as.vector(unlist(x, recursive = FALSE))
> 	    if(higher && length(c.dim <- unique(lapply(x, dim))) == 1 &&
> 	       is.numeric(c.dim <- c.dim[[1L]]) &&
> 	       prod(d <- c(c.dim, n)) == length(r)) {

> 		iN1 <- is.null(n1 <- dimnames(x[[1L]]))
> 		n2 <- names(x)
> 		dnam <-
> 		    if(!(iN1 && is.null(n2)))
> 			c(if(iN1) rep.int(list(n1), length(c.dim)) else n1,
> 			  list(n2)) ## else NULL
> 		array(r, dim = d, dimnames = dnam)

> 	    } else if(prod(d <- c(common.len, n)) == length(r))
> 		array(r, dim = d,
> 		      dimnames= if(!(is.null(n1 <- names(x[[1L]])) &
> 		      is.null(n2 <- names(x)))) list(n1,n2))
> 	    else x
> 	}
> 	else x
>     }

>     sapply <- function(X, FUN, ..., simplify = TRUE, USE.NAMES = TRUE)
>     {
> 	FUN <- match.fun(FUN)
> 	answer <- lapply(X, FUN, ...)
> 	if(USE.NAMES && is.character(X) && is.null(names(answer)))
> 	    names(answer) <- X
> 	if(!identical(simplify, FALSE) && length(answer))
> 	    simplify2array(answer, higher = (simplify == "array"))
> 	else answer
>     }

As some may have noted, the above has been committed to R-devel
   (r53886 | maechler | 2010-12-29 10:36:01 +0100)

with the extra
------------------------------------------------------
NOTE: vapply() and replicate() doing that *by default*
------------------------------------------------------
which means that I've deared to let vapply() and replicate()
behave logically (in the above sense) by default, i.e.
*not* back compatibly.

If you want to remain bug-compatible (:-),
for replicate() you can explicitly ask for  'simplify=TRUE'
instead of the new default simplify="array".
For vapply(), the extra work of implementing such a back/bug
compatibility option did not seem worth; in particular, as
vapply() is very new and not used in many places (on CRAN)
anyway.

The new replicate() default behavior has lead to two CRAN
packages ('emoa', 'plsRglm' whose authors I'll address privately)
to fail 'R CMD check'; inspection however shows that in both cases, 

1) the check failure is from examples / test functions

2) the usage there being

	t(replicate(N, foobar()))

where foobar() returns a 1D array instead of a vector, so one
way to "fix" the problem would be to change the above to

	t(replicate(N, t(foobar())))

So, in summary, the changed behavior of replicate() seems indeed
more logical insofar as it revealed programming/usage glitches
in other parts of R code.

BTW: The above makes me considering --- once again -- extending the
     definition of  t(a) to arrays a of array-rank {:= length(dim(a))} >= 3,
     and there generalize t(.) to be the same as 
     aperm(., rev(seq_along(dim(.))))

     {.. in the APL tradition where t() and aperm() really where the same}

Martin


From kleiman at rohan.sdsu.edu  Tue Jan  4 01:01:07 2011
From: kleiman at rohan.sdsu.edu (Elliot Todd Kleiman)
Date: Mon, 3 Jan 2011 16:01:07 -0800 (PST)
Subject: [Rd] \VignetteKeywords{}, for KEYWORDS or for free-tagging?
In-Reply-To: <19745.52937.544928.604562@fangorn.hornik.net>
References: <Pine.GSO.4.64.1012282323310.9121@rohan.sdsu.edu>
	<19745.52937.544928.604562@fangorn.hornik.net>
Message-ID: <Pine.GSO.4.64.1101031553270.5098@rohan.sdsu.edu>

Hi Kurt,

Thank you for the info!

However, I would also like to ask:

* Since the user may use any words as 'keywords',
what is the purpose of this command and what are
the benefits of using it?

* Where is the documentation for the '\Vignette*'
commands?

Because other than the '\VignetteIndexEntry' command,
I could not find any mentioning of them in the R-exts
manual, http://cran.r-project.org/doc/manuals/R-exts.html.

Best,

+ Elliot

On Mon, 3 Jan 2011, Kurt Hornik wrote:

>>>>>> Elliot Todd Kleiman writes:
>
>> Hi R-devel,
>> [Question]:
>
>> * Is there a KEYWORDS file to lookup 'keywords' to supply
>> the vignette command, '\VignetteKeywords{}'?
>
>> -or, is the pkg writer free to tag the vignette using any
>> keywords he/she chooses? i.e., free-tagging.
>
> For vignette keywords, the latter.
>
> Best
> -k
>
>> Thank you,
>
>> + Elliot Kleiman
>> __________________________
>> San Diego State University
>> http://www.sdsu.edu/
>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From ral64 at cam.ac.uk  Tue Jan  4 17:41:06 2011
From: ral64 at cam.ac.uk (Robert Lowe)
Date: Tue, 4 Jan 2011 16:41:06 +0000
Subject: [Rd] C code hanging and printing everything at the end
References: <DA930DC9-8A65-422A-8668-491236CD4952@cam.ac.uk>
Message-ID: <64F9E9B1-2FF8-43FF-A1F8-4CB1E612A1A9@cam.ac.uk>

Hi,

I am currently writing an extension for R and have the need to include some C code. If I call the code with a large amount of data then it can take several minutes to complete.

The C code prints out after a certain iteration hence letting the user know it hasn't crashed.

When running in R this generally does not happen and all is printed out at the end once the program has completed successfully.

I am using Rprintf() to print out the required output.

e.g. Something simple which illustrates my point

for(int i=0; i<10000; i++){
	#Calculations
	if (i%1000==0){
		Rprintf("Step %d\n",i)
	}
}

All I get during the program is the OS X spinning wheel in R. Is there any way to print out as the program is running?

Thanks,
Rob

From simon.urbanek at r-project.org  Tue Jan  4 18:09:06 2011
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Tue, 4 Jan 2011 12:09:06 -0500
Subject: [Rd] C code hanging and printing everything at the end
In-Reply-To: <64F9E9B1-2FF8-43FF-A1F8-4CB1E612A1A9@cam.ac.uk>
References: <DA930DC9-8A65-422A-8668-491236CD4952@cam.ac.uk>
	<64F9E9B1-2FF8-43FF-A1F8-4CB1E612A1A9@cam.ac.uk>
Message-ID: <CE81461A-189D-459D-9BC1-EB0F54E3C363@r-project.org>


On Jan 4, 2011, at 11:41 AM, Robert Lowe wrote:

> Hi,
> 
> I am currently writing an extension for R and have the need to include some C code. If I call the code with a large amount of data then it can take several minutes to complete.
> 
> The C code prints out after a certain iteration hence letting the user know it hasn't crashed.
> 
> When running in R this generally does not happen and all is printed out at the end once the program has completed successfully.
> 
> I am using Rprintf() to print out the required output.
> 
> e.g. Something simple which illustrates my point
> 
> for(int i=0; i<10000; i++){
> 	#Calculations
> 	if (i%1000==0){
> 		Rprintf("Step %d\n",i)
> 	}
> }
> 
> All I get during the program is the OS X spinning wheel in R. Is there any way to print out as the program is running?
> 

You want to add R_CheckUserInterrupt(); so that the system has a chance to run the event loop and thus display the result. But the implication is that you may be interrupted so make sure R controls any memory allocations you have made.

Cheers,
Simon


From jfox at mcmaster.ca  Tue Jan  4 22:35:35 2011
From: jfox at mcmaster.ca (John Fox)
Date: Tue, 4 Jan 2011 16:35:35 -0500
Subject: [Rd] scoping/non-standard evaluation issue
Message-ID: <009b01cbac57$532a3b80$f97eb280$@ca>

Dear r-devel list members,

On a couple of occasions I've encountered the issue illustrated by the
following examples:

--------- snip -----------

> mod.1 <- lm(Employed ~ GNP.deflator + GNP + Unemployed + 
+         Armed.Forces + Population + Year, data=longley)

> mod.2 <- update(mod.1, . ~ . - Year + Year)

> all.equal(mod.1, mod.2)
[1] TRUE
> 
> f <- function(mod){
+     subs <- 1:10
+     update(mod, subset=subs)
+     }
    
> f(mod.1)

Call:
lm(formula = Employed ~ GNP.deflator + GNP + Unemployed + Armed.Forces + 
    Population + Year, data = longley, subset = subs)

Coefficients:
 (Intercept)  GNP.deflator           GNP    Unemployed  Armed.Forces  
   3.641e+03     8.394e-03     6.909e-02    -3.971e-03    -8.595e-03  
  Population          Year  
   1.164e+00    -1.911e+00  

> f(mod.2)
Error in eval(expr, envir, enclos) : object 'subs' not found

--------- snip -----------

I *almost* understand what's going -- that is, clearly mod.1 and mod.2, or
the formulas therein, are associated with different environments, but I
don't quite see why.

Anyway, here are two "solutions" that work, but neither is in my view
desirable:

--------- snip -----------

> f1 <- function(mod){
+     assign(".subs", 1:10, envir=.GlobalEnv)
+     on.exit(remove(".subs", envir=.GlobalEnv))
+     update(mod, subset=.subs)
+     }

> f1(mod.1)

Call:
lm(formula = Employed ~ GNP.deflator + GNP + Unemployed + Armed.Forces + 
    Population + Year, data = longley, subset = .subs)

Coefficients:
 (Intercept)  GNP.deflator           GNP    Unemployed  Armed.Forces  
   3.641e+03     8.394e-03     6.909e-02    -3.971e-03    -8.595e-03  
  Population          Year  
   1.164e+00    -1.911e+00  

> f1(mod.2)

Call:
lm(formula = Employed ~ GNP.deflator + GNP + Unemployed + Armed.Forces + 
    Population + Year, data = longley, subset = .subs)

Coefficients:
 (Intercept)  GNP.deflator           GNP    Unemployed  Armed.Forces  
   3.641e+03     8.394e-03     6.909e-02    -3.971e-03    -8.595e-03  
  Population          Year  
   1.164e+00    -1.911e+00  

> f2 <- function(mod){
+     env <- new.env(parent=.GlobalEnv)
+     attach(NULL)
+     on.exit(detach())
+     assign(".subs", 1:10, pos=2)
+     update(mod, subset=.subs)
+     }

> f2(mod.1)

Call:
lm(formula = Employed ~ GNP.deflator + GNP + Unemployed + Armed.Forces + 
    Population + Year, data = longley, subset = .subs)

Coefficients:
 (Intercept)  GNP.deflator           GNP    Unemployed  Armed.Forces  
   3.641e+03     8.394e-03     6.909e-02    -3.971e-03    -8.595e-03  
  Population          Year  
   1.164e+00    -1.911e+00  

> f2(mod.2)

Call:
lm(formula = Employed ~ GNP.deflator + GNP + Unemployed + Armed.Forces + 
    Population + Year, data = longley, subset = .subs)

Coefficients:
 (Intercept)  GNP.deflator           GNP    Unemployed  Armed.Forces  
   3.641e+03     8.394e-03     6.909e-02    -3.971e-03    -8.595e-03  
  Population          Year  
   1.164e+00    -1.911e+00  

--------- snip -----------

The problem with f1() is that it will clobber a variable named .subs in the
global environment; the problem with f2() is that .subs can be masked by a
variable in the global environment.

Is there a better approach?

Thanks,
 John

--------------------------------
John Fox
Senator William McMaster 
  Professor of Social Statistics
Department of Sociology
McMaster University
Hamilton, Ontario, Canada
web: socserv.mcmaster.ca/jfox


From jfox at mcmaster.ca  Tue Jan  4 22:55:47 2011
From: jfox at mcmaster.ca (John Fox)
Date: Tue, 4 Jan 2011 16:55:47 -0500
Subject: [Rd] scoping/non-standard evaluation issue
In-Reply-To: <12757_1294177082_p04Lblsd023207_009b01cbac57$532a3b80$f97eb280$@ca>
References: <12757_1294177082_p04Lblsd023207_009b01cbac57$532a3b80$f97eb280$@ca>
Message-ID: <00a401cbac5a$255ac190$701044b0$@ca>

Dear all,

A small correction: I had a stray line in my f2(),

	env <- new.env(parent=.GlobalEnv)

left over from yet another attempt; it can simply be removed.

Sorry for the confusion,
 John

--------------------------------
John Fox
Senator William McMaster 
  Professor of Social Statistics
Department of Sociology
McMaster University
Hamilton, Ontario, Canada
web: socserv.mcmaster.ca/jfox


> -----Original Message-----
> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org]
On
> Behalf Of John Fox
> Sent: January-04-11 4:36 PM
> To: r-devel at r-project.org
> Cc: 'Sanford Weisberg'
> Subject: [Rd] scoping/non-standard evaluation issue
> 
> Dear r-devel list members,
> 
> On a couple of occasions I've encountered the issue illustrated by the
> following examples:
> 
> --------- snip -----------
> 
> > mod.1 <- lm(Employed ~ GNP.deflator + GNP + Unemployed +
> +         Armed.Forces + Population + Year, data=longley)
> 
> > mod.2 <- update(mod.1, . ~ . - Year + Year)
> 
> > all.equal(mod.1, mod.2)
> [1] TRUE
> >
> > f <- function(mod){
> +     subs <- 1:10
> +     update(mod, subset=subs)
> +     }
> 
> > f(mod.1)
> 
> Call:
> lm(formula = Employed ~ GNP.deflator + GNP + Unemployed + Armed.Forces +
>     Population + Year, data = longley, subset = subs)
> 
> Coefficients:
>  (Intercept)  GNP.deflator           GNP    Unemployed  Armed.Forces
>    3.641e+03     8.394e-03     6.909e-02    -3.971e-03    -8.595e-03
>   Population          Year
>    1.164e+00    -1.911e+00
> 
> > f(mod.2)
> Error in eval(expr, envir, enclos) : object 'subs' not found
> 
> --------- snip -----------
> 
> I *almost* understand what's going -- that is, clearly mod.1 and mod.2, or
> the formulas therein, are associated with different environments, but I
> don't quite see why.
> 
> Anyway, here are two "solutions" that work, but neither is in my view
> desirable:
> 
> --------- snip -----------
> 
> > f1 <- function(mod){
> +     assign(".subs", 1:10, envir=.GlobalEnv)
> +     on.exit(remove(".subs", envir=.GlobalEnv))
> +     update(mod, subset=.subs)
> +     }
> 
> > f1(mod.1)
> 
> Call:
> lm(formula = Employed ~ GNP.deflator + GNP + Unemployed + Armed.Forces +
>     Population + Year, data = longley, subset = .subs)
> 
> Coefficients:
>  (Intercept)  GNP.deflator           GNP    Unemployed  Armed.Forces
>    3.641e+03     8.394e-03     6.909e-02    -3.971e-03    -8.595e-03
>   Population          Year
>    1.164e+00    -1.911e+00
> 
> > f1(mod.2)
> 
> Call:
> lm(formula = Employed ~ GNP.deflator + GNP + Unemployed + Armed.Forces +
>     Population + Year, data = longley, subset = .subs)
> 
> Coefficients:
>  (Intercept)  GNP.deflator           GNP    Unemployed  Armed.Forces
>    3.641e+03     8.394e-03     6.909e-02    -3.971e-03    -8.595e-03
>   Population          Year
>    1.164e+00    -1.911e+00
> 
> > f2 <- function(mod){
> +     env <- new.env(parent=.GlobalEnv)
> +     attach(NULL)
> +     on.exit(detach())
> +     assign(".subs", 1:10, pos=2)
> +     update(mod, subset=.subs)
> +     }
> 
> > f2(mod.1)
> 
> Call:
> lm(formula = Employed ~ GNP.deflator + GNP + Unemployed + Armed.Forces +
>     Population + Year, data = longley, subset = .subs)
> 
> Coefficients:
>  (Intercept)  GNP.deflator           GNP    Unemployed  Armed.Forces
>    3.641e+03     8.394e-03     6.909e-02    -3.971e-03    -8.595e-03
>   Population          Year
>    1.164e+00    -1.911e+00
> 
> > f2(mod.2)
> 
> Call:
> lm(formula = Employed ~ GNP.deflator + GNP + Unemployed + Armed.Forces +
>     Population + Year, data = longley, subset = .subs)
> 
> Coefficients:
>  (Intercept)  GNP.deflator           GNP    Unemployed  Armed.Forces
>    3.641e+03     8.394e-03     6.909e-02    -3.971e-03    -8.595e-03
>   Population          Year
>    1.164e+00    -1.911e+00
> 
> --------- snip -----------
> 
> The problem with f1() is that it will clobber a variable named .subs in
the
> global environment; the problem with f2() is that .subs can be masked by a
> variable in the global environment.
> 
> Is there a better approach?
> 
> Thanks,
>  John
> 
> --------------------------------
> John Fox
> Senator William McMaster
>   Professor of Social Statistics
> Department of Sociology
> McMaster University
> Hamilton, Ontario, Canada
> web: socserv.mcmaster.ca/jfox
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From charlie at stat.umn.edu  Tue Jan  4 23:46:04 2011
From: charlie at stat.umn.edu (Charles Geyer)
Date: Tue, 4 Jan 2011 16:46:04 -0600
Subject: [Rd] R CMD check bug or misfeature
Message-ID: <20110104224604.GA19577@stat.umn.edu>

This is a bug/misfeature report for R CMD check.  The function

    tools:::.check_packages_used_in_tests

Gives an apparently unintended error when checking the tests in the
contributed package rcdd_1.1-3.tar.gz as found on CRAN.
See the script below for details.

The actual error reported is totally mysterious.

* checking for unstated dependencies in tests ... NOTE
Error in as.character(function (description = "", open = "", blocking = TRUE,  : 
  cannot coerce type 'closure' to vector of type 'character'
Calls: <Anonymous> ... tryCatch -> tryCatchList -> tryCatchOne -> <Anonymous>
Execution halted

The error is apparently due to several of the test scripts using scan()
which reads stuff from the script itself until an empty line is reached.
This works fine (as one can see below, all the tests pass), but 

    tools:::.check_packages_used_in_tests

wants to parse each of the test scripts, and they don't parse.

First, is this a bug?  "Writing R Extensions" just says the contents of
the tests directory should be [a-zA-Z]*.R files.  It does not say they have
to parse.

Even if this is deemed a feature not a bug, it seems that
"Writing R Extensions" should warn about this issue.

Also

    tools:::.check_packages_used_in_tests

should give a sane report about the issue, not a totally mysterious crash.

Given the FIXME's and other comments in this function, it clearly needs more
work.  This issue should go on the todo list.

I have rewritten the tests in rcdd so that they do not give this error,
and will upload a new version when I get another bug resolved, but I think
this issue could bite someone else.  Hence should be fixed, somehow.

---------- here is a script showing the error -----------
---------- the system is openSuSE Linux 11.3  -----------
Script started on Tue 04 Jan 2011 04:08:53 PM CST
oak$ wget http://cran.r-project.org/src/contrib/rcdd_1.1-3.tar.gz
--2011-01-04 16:09:51--  http://cran.r-project.org/src/contrib/rcdd_1.1-3.tar.gz
Resolving cran.r-project.org... 137.208.57.37
Connecting to cran.r-project.org|137.208.57.37|:80... connected.
HTTP request sent, awaiting response... 200 OK
Length: 598019 (584K) [application/x-gzip]
Saving to: `rcdd_1.1-3.tar.gz'

 0% [                                       ] 0           --.-K/s               2% [                                       ] 12,726      53.8K/s               7% [==>                                    ] 47,478      92.4K/s              23% [========>                              ] 138,702      175K/s              52% [===================>                   ] 312,462      308K/s              100%[======================================>] 598,019      494K/s   in 1.2s    

2011-01-04 16:09:53 (494 KB/s) - `rcdd_1.1-3.tar.gz' saved [598019/598019]

oak$ tar zxf rcdd_1.1-3.tar.gz
oak$ R CMD check rcdd
* using log directory ?/HOME/faculty/charlie/tmp/Bugs/rcmdcheck/rcdd.Rcheck?
* using R version 2.12.1 (2010-12-16)
* using platform: x86_64-unknown-linux-gnu (64-bit)
* using session charset: UTF-8
* checking for file ?rcdd/DESCRIPTION? ... OK
* this is package ?rcdd? version ?1.1-3?
* checking package name space information ... OK
* checking package dependencies ... OK
* checking if this is a source package ... OK
* checking for executable files ... OK
* checking whether package ?rcdd? can be installed ... OK
* checking package directory ... OK
* checking for portable file names ... OK
* checking for sufficient/correct file permissions ... OK
* checking DESCRIPTION meta-information ... OK
* checking top-level files ... OK
* checking index information ... OK
* checking package subdirectories ... OK
* checking R files for non-ASCII characters ... OK
* checking R files for syntax errors ... OK
* checking whether the package can be loaded ... OK
* checking whether the package can be loaded with stated dependencies ... OK
* checking whether the package can be unloaded cleanly ... OK
* checking whether the name space can be loaded with stated dependencies ... OK
* checking whether the name space can be unloaded cleanly ... OK
* checking for unstated dependencies in R code ... OK
* checking S3 generic/method consistency ... OK
* checking replacement functions ... OK
* checking foreign function calls ... OK
* checking R code for possible problems ... OK
* checking Rd files ... OK
* checking Rd metadata ... OK
* checking Rd cross-references ... OK
* checking for missing documentation entries ... OK
* checking for code/documentation mismatches ... OK
* checking Rd \usage sections ... OK
* checking Rd contents ... OK
* checking for unstated dependencies in examples ... OK
* checking line endings in C/C++/Fortran sources/headers ... OK
* checking line endings in Makefiles ... OK
* checking for portable compilation flags in Makevars ... OK
* checking for portable use of $BLAS_LIBS ... OK
* checking examples ... OK
* checking for unstated dependencies in tests ... NOTE
Error in as.character(function (description = "", open = "", blocking = TRUE,  : 
  cannot coerce type 'closure' to vector of type 'character'
Calls: <Anonymous> ... tryCatch -> tryCatchList -> tryCatchOne -> <Anonymous>
Execution halted
* checking tests ...
  Running ?allfaces.R?
  Comparing ?allfaces.Rout? to ?allfaces.Rout.save? ... OK
  Running ?arith.R?
  Comparing ?arith.Rout? to ?arith.Rout.save? ... OK
  Running ?bar-gmp.R?
  Comparing ?bar-gmp.Rout? to ?bar-gmp.Rout.save? ... OK
  Running ?bar.R?
  Comparing ?bar.Rout? to ?bar.Rout.save? ... OK
  Running ?bug.R?
  Comparing ?bug.Rout? to ?bug.Rout.save? ... OK
  Running ?bug2.R?
  Comparing ?bug2.Rout? to ?bug2.Rout.save? ... OK
  Running ?chull.R?
  Comparing ?chull.Rout? to ?chull.Rout.save? ... OK
  Running ?chull2.R?
  Comparing ?chull2.Rout? to ?chull2.Rout.save? ... OK
  Running ?convert.R?
  Comparing ?convert.Rout? to ?convert.Rout.save? ... OK
  Running ?fred.R?
  Comparing ?fred.Rout? to ?fred.Rout.save? ... OK
  Running ?lpcdd.R?
  Comparing ?lpcdd.Rout? to ?lpcdd.Rout.save? ... OK
  Running ?oops.R?
  Comparing ?oops.Rout? to ?oops.Rout.save? ... OK
  Running ?qmatmult.R?
  Comparing ?qmatmult.Rout? to ?qmatmult.Rout.save? ... OK
  Running ?qux-gmp.R?
  Comparing ?qux-gmp.Rout? to ?qux-gmp.Rout.save? ... OK
  Running ?qux.R?
  Comparing ?qux.Rout? to ?qux.Rout.save? ... OK
  Running ?redund.R?
  Comparing ?redund.Rout? to ?redund.Rout.save? ... OK
  Running ?sammy.R?
  Comparing ?sammy.Rout? to ?sammy.Rout.save? ... OK
  Running ?subset.R?
  Comparing ?subset.Rout? to ?subset.Rout.save? ... OK
  Running ?zero.R?
  Comparing ?zero.Rout? to ?zero.Rout.save? ... OK
 OK
* checking package vignettes in ?inst/doc? ... OK
* checking PDF version of manual ... OK

oak$ ##### It checks o. k., but what about that NOTE ?????
oak$ R --vanilla

R version 2.12.1 (2010-12-16)
Copyright (C) 2010 The R Foundation for Statistical Computing
ISBN 3-900051-07-0
Platform: x86_64-unknown-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> library(tools)
> tools:::.check_packages_used_in_tests("rcdd")
Error in as.character(function (description = "", open = "", blocking = TRUE,  : 
  cannot coerce type 'closure' to vector of type 'character'
> traceback()
8: sprintf(gettext(fmt, domain = domain), ...)
7: gettextf("parse error in file '%s':\n%s", file, .massage_file_parse_error_message(conditionMessage(e)))
6: stop(gettextf("parse error in file '%s':\n%s", file, .massage_file_parse_error_message(conditionMessage(e))), 
       domain = NA, call. = FALSE)
5: value[[3L]](cond)
4: tryCatchOne(expr, names, parentenv, handlers[[1L]])
3: tryCatchList(expr, classes, parentenv, handlers)
2: tryCatch(parse(file = f, n = -1L), error = function(e) stop(gettextf("parse error in file '%s':\n%s", 
       file, .massage_file_parse_error_message(conditionMessage(e))), 
       domain = NA, call. = FALSE))
1: tools:::.check_packages_used_in_tests("rcdd")
> parse("rcdd/tests/bug2.R")
Error in parse("rcdd/tests/bug2.R") : 
  rcdd/tests/bug2.R:5:8: unexpected numeric constant
4:  A <- matrix(scan(), byrow = TRUE, nrow = 9)
5:     0  1.000
          ^
> q()
oak$ exit

Script done on Tue 04 Jan 2011 04:14:53 PM CST
-- 
Charles Geyer
Professor, School of Statistics
University of Minnesota
charlie at stat.umn.edu


From pdalgd at gmail.com  Wed Jan  5 00:04:55 2011
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 5 Jan 2011 00:04:55 +0100
Subject: [Rd] scoping/non-standard evaluation issue
In-Reply-To: <009b01cbac57$532a3b80$f97eb280$@ca>
References: <009b01cbac57$532a3b80$f97eb280$@ca>
Message-ID: <C94EAFD5-25C1-448D-8206-BF221F102A37@gmail.com>


On Jan 4, 2011, at 22:35 , John Fox wrote:

> Dear r-devel list members,
> 
> On a couple of occasions I've encountered the issue illustrated by the
> following examples:
> 
> --------- snip -----------
> 
>> mod.1 <- lm(Employed ~ GNP.deflator + GNP + Unemployed + 
> +         Armed.Forces + Population + Year, data=longley)
> 
>> mod.2 <- update(mod.1, . ~ . - Year + Year)
> 
>> all.equal(mod.1, mod.2)
> [1] TRUE
>> 
>> f <- function(mod){
> +     subs <- 1:10
> +     update(mod, subset=subs)
> +     }
> 
>> f(mod.1)
> 
> Call:
> lm(formula = Employed ~ GNP.deflator + GNP + Unemployed + Armed.Forces + 
>    Population + Year, data = longley, subset = subs)
> 
> Coefficients:
> (Intercept)  GNP.deflator           GNP    Unemployed  Armed.Forces  
>   3.641e+03     8.394e-03     6.909e-02    -3.971e-03    -8.595e-03  
>  Population          Year  
>   1.164e+00    -1.911e+00  
> 
>> f(mod.2)
> Error in eval(expr, envir, enclos) : object 'subs' not found
> 
> --------- snip -----------
> 
> I *almost* understand what's going -- that is, clearly mod.1 and mod.2, or
> the formulas therein, are associated with different environments, but I
> don't quite see why.
> 
> Anyway, here are two "solutions" that work, but neither is in my view
> desirable:
> 
> --------- snip -----------
> 
>> f1 <- function(mod){
> +     assign(".subs", 1:10, envir=.GlobalEnv)
> +     on.exit(remove(".subs", envir=.GlobalEnv))
> +     update(mod, subset=.subs)
> +     }
> 
>> f1(mod.1)
> 
> Call:
> lm(formula = Employed ~ GNP.deflator + GNP + Unemployed + Armed.Forces + 
>    Population + Year, data = longley, subset = .subs)
> 
> Coefficients:
> (Intercept)  GNP.deflator           GNP    Unemployed  Armed.Forces  
>   3.641e+03     8.394e-03     6.909e-02    -3.971e-03    -8.595e-03  
>  Population          Year  
>   1.164e+00    -1.911e+00  
> 
>> f1(mod.2)
> 
> Call:
> lm(formula = Employed ~ GNP.deflator + GNP + Unemployed + Armed.Forces + 
>    Population + Year, data = longley, subset = .subs)
> 
> Coefficients:
> (Intercept)  GNP.deflator           GNP    Unemployed  Armed.Forces  
>   3.641e+03     8.394e-03     6.909e-02    -3.971e-03    -8.595e-03  
>  Population          Year  
>   1.164e+00    -1.911e+00  
> 
>> f2 <- function(mod){
> +     env <- new.env(parent=.GlobalEnv)
> +     attach(NULL)
> +     on.exit(detach())
> +     assign(".subs", 1:10, pos=2)
> +     update(mod, subset=.subs)
> +     }
> 
>> f2(mod.1)
> 
> Call:
> lm(formula = Employed ~ GNP.deflator + GNP + Unemployed + Armed.Forces + 
>    Population + Year, data = longley, subset = .subs)
> 
> Coefficients:
> (Intercept)  GNP.deflator           GNP    Unemployed  Armed.Forces  
>   3.641e+03     8.394e-03     6.909e-02    -3.971e-03    -8.595e-03  
>  Population          Year  
>   1.164e+00    -1.911e+00  
> 
>> f2(mod.2)
> 
> Call:
> lm(formula = Employed ~ GNP.deflator + GNP + Unemployed + Armed.Forces + 
>    Population + Year, data = longley, subset = .subs)
> 
> Coefficients:
> (Intercept)  GNP.deflator           GNP    Unemployed  Armed.Forces  
>   3.641e+03     8.394e-03     6.909e-02    -3.971e-03    -8.595e-03  
>  Population          Year  
>   1.164e+00    -1.911e+00  
> 
> --------- snip -----------
> 
> The problem with f1() is that it will clobber a variable named .subs in the
> global environment; the problem with f2() is that .subs can be masked by a
> variable in the global environment.
> 
> Is there a better approach?

I think the best way would be to modify the environment of the formula. Something like the below, except that it doesn't actually work...

f3 <- function(mod) {
  f <- formula(mod)
  environment(f) <- e <-  new.env(parent=environment(f))
  mod <- update(mod, formula=f)
  evalq(.subs <- 1:10, e)
  update(mod, subset=.subs)
}

The catch is that it is not quite so easy to update the formula of a model. 

-- 
Peter Dalgaard
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From ggrothendieck at gmail.com  Wed Jan  5 00:56:08 2011
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 4 Jan 2011 18:56:08 -0500
Subject: [Rd] scoping/non-standard evaluation issue
In-Reply-To: <009b01cbac57$532a3b80$f97eb280$@ca>
References: <009b01cbac57$532a3b80$f97eb280$@ca>
Message-ID: <AANLkTi=uVQeJ1XTKoAMpMriFqc10ZkaEc1dtR805Pja8@mail.gmail.com>

On Tue, Jan 4, 2011 at 4:35 PM, John Fox <jfox at mcmaster.ca> wrote:
> Dear r-devel list members,
>
> On a couple of occasions I've encountered the issue illustrated by the
> following examples:
>
> --------- snip -----------
>
>> mod.1 <- lm(Employed ~ GNP.deflator + GNP + Unemployed +
> + ? ? ? ? Armed.Forces + Population + Year, data=longley)
>
>> mod.2 <- update(mod.1, . ~ . - Year + Year)
>
>> all.equal(mod.1, mod.2)
> [1] TRUE
>>
>> f <- function(mod){
> + ? ? subs <- 1:10
> + ? ? update(mod, subset=subs)
> + ? ? }
>
>> f(mod.1)
>
> Call:
> lm(formula = Employed ~ GNP.deflator + GNP + Unemployed + Armed.Forces +
> ? ?Population + Year, data = longley, subset = subs)
>
> Coefficients:
> ?(Intercept) ?GNP.deflator ? ? ? ? ? GNP ? ?Unemployed ?Armed.Forces
> ? 3.641e+03 ? ? 8.394e-03 ? ? 6.909e-02 ? ?-3.971e-03 ? ?-8.595e-03
> ?Population ? ? ? ? ?Year
> ? 1.164e+00 ? ?-1.911e+00
>
>> f(mod.2)
> Error in eval(expr, envir, enclos) : object 'subs' not found
>
> --------- snip -----------
>
> I *almost* understand what's going -- that is, clearly mod.1 and mod.2, or
> the formulas therein, are associated with different environments, but I
> don't quite see why.
>
> Anyway, here are two "solutions" that work, but neither is in my view
> desirable:
>
> --------- snip -----------
>
>> f1 <- function(mod){
> + ? ? assign(".subs", 1:10, envir=.GlobalEnv)
> + ? ? on.exit(remove(".subs", envir=.GlobalEnv))
> + ? ? update(mod, subset=.subs)
> + ? ? }
>
>> f1(mod.1)
>
> Call:
> lm(formula = Employed ~ GNP.deflator + GNP + Unemployed + Armed.Forces +
> ? ?Population + Year, data = longley, subset = .subs)
>
> Coefficients:
> ?(Intercept) ?GNP.deflator ? ? ? ? ? GNP ? ?Unemployed ?Armed.Forces
> ? 3.641e+03 ? ? 8.394e-03 ? ? 6.909e-02 ? ?-3.971e-03 ? ?-8.595e-03
> ?Population ? ? ? ? ?Year
> ? 1.164e+00 ? ?-1.911e+00
>
>> f1(mod.2)
>
> Call:
> lm(formula = Employed ~ GNP.deflator + GNP + Unemployed + Armed.Forces +
> ? ?Population + Year, data = longley, subset = .subs)
>
> Coefficients:
> ?(Intercept) ?GNP.deflator ? ? ? ? ? GNP ? ?Unemployed ?Armed.Forces
> ? 3.641e+03 ? ? 8.394e-03 ? ? 6.909e-02 ? ?-3.971e-03 ? ?-8.595e-03
> ?Population ? ? ? ? ?Year
> ? 1.164e+00 ? ?-1.911e+00
>
>> f2 <- function(mod){
> + ? ? env <- new.env(parent=.GlobalEnv)
> + ? ? attach(NULL)
> + ? ? on.exit(detach())
> + ? ? assign(".subs", 1:10, pos=2)
> + ? ? update(mod, subset=.subs)
> + ? ? }
>
>> f2(mod.1)
>
> Call:
> lm(formula = Employed ~ GNP.deflator + GNP + Unemployed + Armed.Forces +
> ? ?Population + Year, data = longley, subset = .subs)
>
> Coefficients:
> ?(Intercept) ?GNP.deflator ? ? ? ? ? GNP ? ?Unemployed ?Armed.Forces
> ? 3.641e+03 ? ? 8.394e-03 ? ? 6.909e-02 ? ?-3.971e-03 ? ?-8.595e-03
> ?Population ? ? ? ? ?Year
> ? 1.164e+00 ? ?-1.911e+00
>
>> f2(mod.2)
>
> Call:
> lm(formula = Employed ~ GNP.deflator + GNP + Unemployed + Armed.Forces +
> ? ?Population + Year, data = longley, subset = .subs)
>
> Coefficients:
> ?(Intercept) ?GNP.deflator ? ? ? ? ? GNP ? ?Unemployed ?Armed.Forces
> ? 3.641e+03 ? ? 8.394e-03 ? ? 6.909e-02 ? ?-3.971e-03 ? ?-8.595e-03
> ?Population ? ? ? ? ?Year
> ? 1.164e+00 ? ?-1.911e+00
>
> --------- snip -----------
>
> The problem with f1() is that it will clobber a variable named .subs in the
> global environment; the problem with f2() is that .subs can be masked by a
> variable in the global environment.
>
> Is there a better approach?
>

I think there is something wrong with R here since the formula in the
call component of mod.1 has a "call" class whereas the corresponding
call component of mod.2 has "formula" class:

> class(mod.1$call[[2]])
[1] "call"
> class(mod.2$call[[2]])
[1] "formula"

If we reset call[[2]] to have "call" class then it works:

> mod.2a <- mod.2
> mod.2a$call[[2]] <- as.call(as.list(mod.2a$call[[2]]))
> f(mod.2a)

Call:
lm(formula = Employed ~ GNP.deflator + GNP + Unemployed + Armed.Forces +
    Population + Year, data = longley, subset = subs)

Coefficients:
 (Intercept)  GNP.deflator           GNP    Unemployed  Armed.Forces
 Population          Year
   3.641e+03     8.394e-03     6.909e-02    -3.971e-03    -8.595e-03
  1.164e+00    -1.911e+00


-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From Thorn.Thaler at rdls.nestle.com  Wed Jan  5 11:20:47 2011
From: Thorn.Thaler at rdls.nestle.com (Thaler, Thorn, LAUSANNE,
	Applied Mathematics)
Date: Wed, 5 Jan 2011 11:20:47 +0100
Subject: [Rd] Minimum of an ordered factor
Message-ID: <F54EF8F1B477CF448729593FE421F6464A22AE@HQVEVE0032.nestle.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110105/665e29a0/attachment.pl>

From jfox at mcmaster.ca  Wed Jan  5 14:42:17 2011
From: jfox at mcmaster.ca (John Fox)
Date: Wed, 5 Jan 2011 08:42:17 -0500
Subject: [Rd] scoping/non-standard evaluation issue
In-Reply-To: <C94EAFD5-25C1-448D-8206-BF221F102A37@gmail.com>
References: <009b01cbac57$532a3b80$f97eb280$@ca>
	<C94EAFD5-25C1-448D-8206-BF221F102A37@gmail.com>
Message-ID: <003401cbacde$5ee7d540$1cb77fc0$@ca>

Dear Peter,

I played around a bit with your suggestion but wasn't able to get it to
work. 

Thanks for this.

John

--------------------------------
John Fox
Senator William McMaster 
  Professor of Social Statistics
Department of Sociology
McMaster University
Hamilton, Ontario, Canada
web: socserv.mcmaster.ca/jfox


> -----Original Message-----
> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org]
On
> Behalf Of peter dalgaard
> Sent: January-04-11 6:05 PM
> To: John Fox
> Cc: 'Sanford Weisberg'; r-devel at r-project.org
> Subject: Re: [Rd] scoping/non-standard evaluation issue
> 
> 
> On Jan 4, 2011, at 22:35 , John Fox wrote:
> 
> > Dear r-devel list members,
> >
> > On a couple of occasions I've encountered the issue illustrated by the
> > following examples:
> >
> > --------- snip -----------
> >
> >> mod.1 <- lm(Employed ~ GNP.deflator + GNP + Unemployed +
> > +         Armed.Forces + Population + Year, data=longley)
> >
> >> mod.2 <- update(mod.1, . ~ . - Year + Year)
> >
> >> all.equal(mod.1, mod.2)
> > [1] TRUE
> >>
> >> f <- function(mod){
> > +     subs <- 1:10
> > +     update(mod, subset=subs)
> > +     }
> >
> >> f(mod.1)
> >
> > Call:
> > lm(formula = Employed ~ GNP.deflator + GNP + Unemployed + Armed.Forces +
> >    Population + Year, data = longley, subset = subs)
> >
> > Coefficients:
> > (Intercept)  GNP.deflator           GNP    Unemployed  Armed.Forces
> >   3.641e+03     8.394e-03     6.909e-02    -3.971e-03    -8.595e-03
> >  Population          Year
> >   1.164e+00    -1.911e+00
> >
> >> f(mod.2)
> > Error in eval(expr, envir, enclos) : object 'subs' not found
> >
> > --------- snip -----------
> >
> > I *almost* understand what's going -- that is, clearly mod.1 and mod.2,
or
> > the formulas therein, are associated with different environments, but I
> > don't quite see why.
> >
> > Anyway, here are two "solutions" that work, but neither is in my view
> > desirable:
> >
> > --------- snip -----------
> >
> >> f1 <- function(mod){
> > +     assign(".subs", 1:10, envir=.GlobalEnv)
> > +     on.exit(remove(".subs", envir=.GlobalEnv))
> > +     update(mod, subset=.subs)
> > +     }
> >
> >> f1(mod.1)
> >
> > Call:
> > lm(formula = Employed ~ GNP.deflator + GNP + Unemployed + Armed.Forces +
> >    Population + Year, data = longley, subset = .subs)
> >
> > Coefficients:
> > (Intercept)  GNP.deflator           GNP    Unemployed  Armed.Forces
> >   3.641e+03     8.394e-03     6.909e-02    -3.971e-03    -8.595e-03
> >  Population          Year
> >   1.164e+00    -1.911e+00
> >
> >> f1(mod.2)
> >
> > Call:
> > lm(formula = Employed ~ GNP.deflator + GNP + Unemployed + Armed.Forces +
> >    Population + Year, data = longley, subset = .subs)
> >
> > Coefficients:
> > (Intercept)  GNP.deflator           GNP    Unemployed  Armed.Forces
> >   3.641e+03     8.394e-03     6.909e-02    -3.971e-03    -8.595e-03
> >  Population          Year
> >   1.164e+00    -1.911e+00
> >
> >> f2 <- function(mod){
> > +     env <- new.env(parent=.GlobalEnv)
> > +     attach(NULL)
> > +     on.exit(detach())
> > +     assign(".subs", 1:10, pos=2)
> > +     update(mod, subset=.subs)
> > +     }
> >
> >> f2(mod.1)
> >
> > Call:
> > lm(formula = Employed ~ GNP.deflator + GNP + Unemployed + Armed.Forces +
> >    Population + Year, data = longley, subset = .subs)
> >
> > Coefficients:
> > (Intercept)  GNP.deflator           GNP    Unemployed  Armed.Forces
> >   3.641e+03     8.394e-03     6.909e-02    -3.971e-03    -8.595e-03
> >  Population          Year
> >   1.164e+00    -1.911e+00
> >
> >> f2(mod.2)
> >
> > Call:
> > lm(formula = Employed ~ GNP.deflator + GNP + Unemployed + Armed.Forces +
> >    Population + Year, data = longley, subset = .subs)
> >
> > Coefficients:
> > (Intercept)  GNP.deflator           GNP    Unemployed  Armed.Forces
> >   3.641e+03     8.394e-03     6.909e-02    -3.971e-03    -8.595e-03
> >  Population          Year
> >   1.164e+00    -1.911e+00
> >
> > --------- snip -----------
> >
> > The problem with f1() is that it will clobber a variable named .subs in
the
> > global environment; the problem with f2() is that .subs can be masked by
a
> > variable in the global environment.
> >
> > Is there a better approach?
> 
> I think the best way would be to modify the environment of the formula.
> Something like the below, except that it doesn't actually work...
> 
> f3 <- function(mod) {
>   f <- formula(mod)
>   environment(f) <- e <-  new.env(parent=environment(f))
>   mod <- update(mod, formula=f)
>   evalq(.subs <- 1:10, e)
>   update(mod, subset=.subs)
> }
> 
> The catch is that it is not quite so easy to update the formula of a
model.
> 
> --
> Peter Dalgaard
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From jfox at mcmaster.ca  Wed Jan  5 14:44:18 2011
From: jfox at mcmaster.ca (John Fox)
Date: Wed, 5 Jan 2011 08:44:18 -0500
Subject: [Rd] scoping/non-standard evaluation issue
In-Reply-To: <AANLkTi=uVQeJ1XTKoAMpMriFqc10ZkaEc1dtR805Pja8@mail.gmail.com>
References: <009b01cbac57$532a3b80$f97eb280$@ca>
	<AANLkTi=uVQeJ1XTKoAMpMriFqc10ZkaEc1dtR805Pja8@mail.gmail.com>
Message-ID: <003501cbacde$a6d4eb40$f47ec1c0$@ca>

Dear Gabor,

I used str() to look at the two objects but missed the difference that you
found. What I didn't quite understand was why one model worked but not the
other when both were defined at the command prompt in the global
environment.

Thanks,
 John

--------------------------------
John Fox
Senator William McMaster 
  Professor of Social Statistics
Department of Sociology
McMaster University
Hamilton, Ontario, Canada
web: socserv.mcmaster.ca/jfox


> -----Original Message-----
> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org]
On
> Behalf Of Gabor Grothendieck
> Sent: January-04-11 6:56 PM
> To: John Fox
> Cc: Sanford Weisberg; r-devel at r-project.org
> Subject: Re: [Rd] scoping/non-standard evaluation issue
> 
> On Tue, Jan 4, 2011 at 4:35 PM, John Fox <jfox at mcmaster.ca> wrote:
> > Dear r-devel list members,
> >
> > On a couple of occasions I've encountered the issue illustrated by the
> > following examples:
> >
> > --------- snip -----------
> >
> >> mod.1 <- lm(Employed ~ GNP.deflator + GNP + Unemployed +
> > + ? ? ? ? Armed.Forces + Population + Year, data=longley)
> >
> >> mod.2 <- update(mod.1, . ~ . - Year + Year)
> >
> >> all.equal(mod.1, mod.2)
> > [1] TRUE
> >>
> >> f <- function(mod){
> > + ? ? subs <- 1:10
> > + ? ? update(mod, subset=subs)
> > + ? ? }
> >
> >> f(mod.1)
> >
> > Call:
> > lm(formula = Employed ~ GNP.deflator + GNP + Unemployed + Armed.Forces +
> > ? ?Population + Year, data = longley, subset = subs)
> >
> > Coefficients:
> > ?(Intercept) ?GNP.deflator ? ? ? ? ? GNP ? ?Unemployed ?Armed.Forces
> > ? 3.641e+03 ? ? 8.394e-03 ? ? 6.909e-02 ? ?-3.971e-03 ? ?-8.595e-03
> > ?Population ? ? ? ? ?Year
> > ? 1.164e+00 ? ?-1.911e+00
> >
> >> f(mod.2)
> > Error in eval(expr, envir, enclos) : object 'subs' not found
> >
> > --------- snip -----------
> >
> > I *almost* understand what's going -- that is, clearly mod.1 and mod.2,
or
> > the formulas therein, are associated with different environments, but I
> > don't quite see why.
> >
> > Anyway, here are two "solutions" that work, but neither is in my view
> > desirable:
> >
> > --------- snip -----------
> >
> >> f1 <- function(mod){
> > + ? ? assign(".subs", 1:10, envir=.GlobalEnv)
> > + ? ? on.exit(remove(".subs", envir=.GlobalEnv))
> > + ? ? update(mod, subset=.subs)
> > + ? ? }
> >
> >> f1(mod.1)
> >
> > Call:
> > lm(formula = Employed ~ GNP.deflator + GNP + Unemployed + Armed.Forces +
> > ? ?Population + Year, data = longley, subset = .subs)
> >
> > Coefficients:
> > ?(Intercept) ?GNP.deflator ? ? ? ? ? GNP ? ?Unemployed ?Armed.Forces
> > ? 3.641e+03 ? ? 8.394e-03 ? ? 6.909e-02 ? ?-3.971e-03 ? ?-8.595e-03
> > ?Population ? ? ? ? ?Year
> > ? 1.164e+00 ? ?-1.911e+00
> >
> >> f1(mod.2)
> >
> > Call:
> > lm(formula = Employed ~ GNP.deflator + GNP + Unemployed + Armed.Forces +
> > ? ?Population + Year, data = longley, subset = .subs)
> >
> > Coefficients:
> > ?(Intercept) ?GNP.deflator ? ? ? ? ? GNP ? ?Unemployed ?Armed.Forces
> > ? 3.641e+03 ? ? 8.394e-03 ? ? 6.909e-02 ? ?-3.971e-03 ? ?-8.595e-03
> > ?Population ? ? ? ? ?Year
> > ? 1.164e+00 ? ?-1.911e+00
> >
> >> f2 <- function(mod){
> > + ? ? env <- new.env(parent=.GlobalEnv)
> > + ? ? attach(NULL)
> > + ? ? on.exit(detach())
> > + ? ? assign(".subs", 1:10, pos=2)
> > + ? ? update(mod, subset=.subs)
> > + ? ? }
> >
> >> f2(mod.1)
> >
> > Call:
> > lm(formula = Employed ~ GNP.deflator + GNP + Unemployed + Armed.Forces +
> > ? ?Population + Year, data = longley, subset = .subs)
> >
> > Coefficients:
> > ?(Intercept) ?GNP.deflator ? ? ? ? ? GNP ? ?Unemployed ?Armed.Forces
> > ? 3.641e+03 ? ? 8.394e-03 ? ? 6.909e-02 ? ?-3.971e-03 ? ?-8.595e-03
> > ?Population ? ? ? ? ?Year
> > ? 1.164e+00 ? ?-1.911e+00
> >
> >> f2(mod.2)
> >
> > Call:
> > lm(formula = Employed ~ GNP.deflator + GNP + Unemployed + Armed.Forces +
> > ? ?Population + Year, data = longley, subset = .subs)
> >
> > Coefficients:
> > ?(Intercept) ?GNP.deflator ? ? ? ? ? GNP ? ?Unemployed ?Armed.Forces
> > ? 3.641e+03 ? ? 8.394e-03 ? ? 6.909e-02 ? ?-3.971e-03 ? ?-8.595e-03
> > ?Population ? ? ? ? ?Year
> > ? 1.164e+00 ? ?-1.911e+00
> >
> > --------- snip -----------
> >
> > The problem with f1() is that it will clobber a variable named .subs in
the
> > global environment; the problem with f2() is that .subs can be masked by
a
> > variable in the global environment.
> >
> > Is there a better approach?
> >
> 
> I think there is something wrong with R here since the formula in the
> call component of mod.1 has a "call" class whereas the corresponding
> call component of mod.2 has "formula" class:
> 
> > class(mod.1$call[[2]])
> [1] "call"
> > class(mod.2$call[[2]])
> [1] "formula"
> 
> If we reset call[[2]] to have "call" class then it works:
> 
> > mod.2a <- mod.2
> > mod.2a$call[[2]] <- as.call(as.list(mod.2a$call[[2]]))
> > f(mod.2a)
> 
> Call:
> lm(formula = Employed ~ GNP.deflator + GNP + Unemployed + Armed.Forces +
>     Population + Year, data = longley, subset = subs)
> 
> Coefficients:
>  (Intercept)  GNP.deflator           GNP    Unemployed  Armed.Forces
>  Population          Year
>    3.641e+03     8.394e-03     6.909e-02    -3.971e-03    -8.595e-03
>   1.164e+00    -1.911e+00
> 
> 
> --
> Statistics & Software Consulting
> GKX Group, GKX Associates Inc.
> tel: 1-877-GKX-GROUP
> email: ggrothendieck at gmail.com
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From maechler at stat.math.ethz.ch  Wed Jan  5 16:26:59 2011
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 5 Jan 2011 16:26:59 +0100
Subject: [Rd] Minimum of an ordered factor
In-Reply-To: <F54EF8F1B477CF448729593FE421F6464A22AE@HQVEVE0032.nestle.com>
References: <F54EF8F1B477CF448729593FE421F6464A22AE@HQVEVE0032.nestle.com>
Message-ID: <19748.36291.498450.670163@lynne.math.ethz.ch>

>>>>> Thaler, Thorn, LAUSANNE, Applied Mathematics <Thorn.Thaler at rdls.nestle.com>
>>>>>     on Wed, 5 Jan 2011 11:20:47 +0100 writes:

    > Hi everybody, Is there a particular reason, why this code
    > does not work as intended:

    > z <- factor(LETTERS[1:3], ordered = TRUE)
    > u <- 4:6
    > min(z[u > 4])

    > Error in Summary.factor(2:3, na.rm = FALSE) :
    >   min not meaningful for factors



    > I agree that min is indeed not meaningful for not ordered
    > factors, but it makes sense for ordered
    > factors. Especially since

    > z[3] < z[2]
    > sort(z)

    > _ARE_ defined and work as expected. 

I agree that it is natural then, to expect  min(), max() and
range() to work as well.

    > Of course I can do something like

    > sort(z[u>4])[1]

    > but this does not enhance readability of my code. Thus, I
    > overloaded Summary.ordered as follows:


 

    > Summary.ordered <- function(..., na.rm) {

    >   ok <- switch(.Generic, max = , min = , range = TRUE,
    > FALSE)

    >   if (!ok) {

    >     warning(sprintf("'%s' is not meaningful for ordered
    > factors", .Generic))

    >     return(NA)

    >   }

    >   args <- list(...)

    >   level.list <- lapply(args, levels)

    >   level.set <- Reduce(union, level.list)

    >   if (!all(sapply(args, is.ordered)) ||
    > !all(sapply(level.list, identical, y = level.set))) {

    >     stop(sprintf("'%s' is only meaningful for ordered
    > factors if all arguments are ordered factors with the same
    > level sets",

    >                  .Generic))

    >   }

 

    >   codes <- lapply(args, as.integer)

    >   ind <- do.call(.Generic, c(codes, na.rm = na.rm))

 

    >   factor(level.set[ind], levels = level.set, ordered =
    > TRUE)

    > }

(the above is now even more garbled than it was already by your
 use of HTML-ified e-mail ..)

But your code is fine, even nice, in most parts,
and I will add (most of) it (and some documentation) to R-devel
 
unless we get contradicting comments :

    > Any comments appreciated.
(still)


Thank you, Thorn!

With regards,
Martin Maechler, ETH Zurich


From pdalgd at gmail.com  Wed Jan  5 16:50:56 2011
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 5 Jan 2011 16:50:56 +0100
Subject: [Rd] scoping/non-standard evaluation issue
In-Reply-To: <003501cbacde$a6d4eb40$f47ec1c0$@ca>
References: <009b01cbac57$532a3b80$f97eb280$@ca>
	<AANLkTi=uVQeJ1XTKoAMpMriFqc10ZkaEc1dtR805Pja8@mail.gmail.com>
	<003501cbacde$a6d4eb40$f47ec1c0$@ca>
Message-ID: <ACC173DC-3256-42D5-8F14-061A6545DF77@gmail.com>


On Jan 5, 2011, at 14:44 , John Fox wrote:

> Dear Gabor,
> 
> I used str() to look at the two objects but missed the difference that you
> found. What I didn't quite understand was why one model worked but not the
> other when both were defined at the command prompt in the global
> environment.

I kind of suspect that the bug is that mod.1 works... I.e., I can vaguely make out the  contours of why mod.2 is not supposed to work and if that is true, neither should mod.1. However, if so, something clearly needs more work. Possibly, some of the people who worked on implement formula environments may want to chime in? (It's been a while, though.)

> 
> Thanks,
> John
> 
> --------------------------------
> John Fox
> Senator William McMaster 
>  Professor of Social Statistics
> Department of Sociology
> McMaster University
> Hamilton, Ontario, Canada
> web: socserv.mcmaster.ca/jfox
> 
> 
>> -----Original Message-----
>> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org]
> On
>> Behalf Of Gabor Grothendieck
>> Sent: January-04-11 6:56 PM
>> To: John Fox
>> Cc: Sanford Weisberg; r-devel at r-project.org
>> Subject: Re: [Rd] scoping/non-standard evaluation issue
>> 
>> On Tue, Jan 4, 2011 at 4:35 PM, John Fox <jfox at mcmaster.ca> wrote:
>>> Dear r-devel list members,
>>> 
>>> On a couple of occasions I've encountered the issue illustrated by the
>>> following examples:
>>> 
>>> --------- snip -----------
>>> 
>>>> mod.1 <- lm(Employed ~ GNP.deflator + GNP + Unemployed +
>>> +         Armed.Forces + Population + Year, data=longley)
>>> 
>>>> mod.2 <- update(mod.1, . ~ . - Year + Year)
>>> 
>>>> all.equal(mod.1, mod.2)
>>> [1] TRUE
>>>> 
>>>> f <- function(mod){
>>> +     subs <- 1:10
>>> +     update(mod, subset=subs)
>>> +     }
>>> 
>>>> f(mod.1)
>>> 
>>> Call:
>>> lm(formula = Employed ~ GNP.deflator + GNP + Unemployed + Armed.Forces +
>>>    Population + Year, data = longley, subset = subs)
>>> 
>>> Coefficients:
>>>  (Intercept)  GNP.deflator           GNP    Unemployed  Armed.Forces
>>>   3.641e+03     8.394e-03     6.909e-02    -3.971e-03    -8.595e-03
>>>  Population          Year
>>>   1.164e+00    -1.911e+00
>>> 
>>>> f(mod.2)
>>> Error in eval(expr, envir, enclos) : object 'subs' not found
>>> 
>>> --------- snip -----------
>>> 
>>> I *almost* understand what's going -- that is, clearly mod.1 and mod.2,
> or
>>> the formulas therein, are associated with different environments, but I
>>> don't quite see why.
>>> 
>>> Anyway, here are two "solutions" that work, but neither is in my view
>>> desirable:
>>> 
>>> --------- snip -----------
>>> 
>>>> f1 <- function(mod){
>>> +     assign(".subs", 1:10, envir=.GlobalEnv)
>>> +     on.exit(remove(".subs", envir=.GlobalEnv))
>>> +     update(mod, subset=.subs)
>>> +     }
>>> 
>>>> f1(mod.1)
>>> 
>>> Call:
>>> lm(formula = Employed ~ GNP.deflator + GNP + Unemployed + Armed.Forces +
>>>    Population + Year, data = longley, subset = .subs)
>>> 
>>> Coefficients:
>>>  (Intercept)  GNP.deflator           GNP    Unemployed  Armed.Forces
>>>   3.641e+03     8.394e-03     6.909e-02    -3.971e-03    -8.595e-03
>>>  Population          Year
>>>   1.164e+00    -1.911e+00
>>> 
>>>> f1(mod.2)
>>> 
>>> Call:
>>> lm(formula = Employed ~ GNP.deflator + GNP + Unemployed + Armed.Forces +
>>>    Population + Year, data = longley, subset = .subs)
>>> 
>>> Coefficients:
>>>  (Intercept)  GNP.deflator           GNP    Unemployed  Armed.Forces
>>>   3.641e+03     8.394e-03     6.909e-02    -3.971e-03    -8.595e-03
>>>  Population          Year
>>>   1.164e+00    -1.911e+00
>>> 
>>>> f2 <- function(mod){
>>> +     env <- new.env(parent=.GlobalEnv)
>>> +     attach(NULL)
>>> +     on.exit(detach())
>>> +     assign(".subs", 1:10, pos=2)
>>> +     update(mod, subset=.subs)
>>> +     }
>>> 
>>>> f2(mod.1)
>>> 
>>> Call:
>>> lm(formula = Employed ~ GNP.deflator + GNP + Unemployed + Armed.Forces +
>>>    Population + Year, data = longley, subset = .subs)
>>> 
>>> Coefficients:
>>>  (Intercept)  GNP.deflator           GNP    Unemployed  Armed.Forces
>>>   3.641e+03     8.394e-03     6.909e-02    -3.971e-03    -8.595e-03
>>>  Population          Year
>>>   1.164e+00    -1.911e+00
>>> 
>>>> f2(mod.2)
>>> 
>>> Call:
>>> lm(formula = Employed ~ GNP.deflator + GNP + Unemployed + Armed.Forces +
>>>    Population + Year, data = longley, subset = .subs)
>>> 
>>> Coefficients:
>>>  (Intercept)  GNP.deflator           GNP    Unemployed  Armed.Forces
>>>   3.641e+03     8.394e-03     6.909e-02    -3.971e-03    -8.595e-03
>>>  Population          Year
>>>   1.164e+00    -1.911e+00
>>> 
>>> --------- snip -----------
>>> 
>>> The problem with f1() is that it will clobber a variable named .subs in
> the
>>> global environment; the problem with f2() is that .subs can be masked by
> a
>>> variable in the global environment.
>>> 
>>> Is there a better approach?
>>> 
>> 
>> I think there is something wrong with R here since the formula in the
>> call component of mod.1 has a "call" class whereas the corresponding
>> call component of mod.2 has "formula" class:
>> 
>>> class(mod.1$call[[2]])
>> [1] "call"
>>> class(mod.2$call[[2]])
>> [1] "formula"
>> 
>> If we reset call[[2]] to have "call" class then it works:
>> 
>>> mod.2a <- mod.2
>>> mod.2a$call[[2]] <- as.call(as.list(mod.2a$call[[2]]))
>>> f(mod.2a)
>> 
>> Call:
>> lm(formula = Employed ~ GNP.deflator + GNP + Unemployed + Armed.Forces +
>>    Population + Year, data = longley, subset = subs)
>> 
>> Coefficients:
>> (Intercept)  GNP.deflator           GNP    Unemployed  Armed.Forces
>> Population          Year
>>   3.641e+03     8.394e-03     6.909e-02    -3.971e-03    -8.595e-03
>>  1.164e+00    -1.911e+00
>> 
>> 
>> --
>> Statistics & Software Consulting
>> GKX Group, GKX Associates Inc.
>> tel: 1-877-GKX-GROUP
>> email: ggrothendieck at gmail.com
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 

-- 
Peter Dalgaard
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From jfox at mcmaster.ca  Wed Jan  5 17:36:11 2011
From: jfox at mcmaster.ca (John Fox)
Date: Wed, 5 Jan 2011 11:36:11 -0500
Subject: [Rd] scoping/non-standard evaluation issue
In-Reply-To: <ACC173DC-3256-42D5-8F14-061A6545DF77@gmail.com>
References: <009b01cbac57$532a3b80$f97eb280$@ca>
	<AANLkTi=uVQeJ1XTKoAMpMriFqc10ZkaEc1dtR805Pja8@mail.gmail.com>
	<003501cbacde$a6d4eb40$f47ec1c0$@ca>
	<ACC173DC-3256-42D5-8F14-061A6545DF77@gmail.com>
Message-ID: <004701cbacf6$a9ffb170$fdff1450$@ca>

Dear Peter,

You hit the nail on the head: I didn't (and don't) understand why mod.1
works -- which I attributed to my imperfect understanding of non-standard
evaluation. Even if there's a bug allowing mod.1 to work, I wonder about the
consequences of fixing it. That might break a lot of code. It would seem
desirable, though, for mod.1 and mod.2 to behave the same.

Best,
 John


> -----Original Message-----
> From: peter dalgaard [mailto:pdalgd at gmail.com]
> Sent: January-05-11 10:51 AM
> To: John Fox
> Cc: 'Gabor Grothendieck'; 'Sanford Weisberg'; r-devel at r-project.org
> Subject: Re: [Rd] scoping/non-standard evaluation issue
> 
> 
> On Jan 5, 2011, at 14:44 , John Fox wrote:
> 
> > Dear Gabor,
> >
> > I used str() to look at the two objects but missed the difference that
you
> > found. What I didn't quite understand was why one model worked but not
the
> > other when both were defined at the command prompt in the global
> > environment.
> 
> I kind of suspect that the bug is that mod.1 works... I.e., I can vaguely
> make out the  contours of why mod.2 is not supposed to work and if that is
> true, neither should mod.1. However, if so, something clearly needs more
> work. Possibly, some of the people who worked on implement formula
> environments may want to chime in? (It's been a while, though.)
> 
> >
> > Thanks,
> > John
> >
> > --------------------------------
> > John Fox
> > Senator William McMaster
> >  Professor of Social Statistics
> > Department of Sociology
> > McMaster University
> > Hamilton, Ontario, Canada
> > web: socserv.mcmaster.ca/jfox
> >
> >
> >> -----Original Message-----
> >> From: r-devel-bounces at r-project.org
[mailto:r-devel-bounces at r-project.org]
> > On
> >> Behalf Of Gabor Grothendieck
> >> Sent: January-04-11 6:56 PM
> >> To: John Fox
> >> Cc: Sanford Weisberg; r-devel at r-project.org
> >> Subject: Re: [Rd] scoping/non-standard evaluation issue
> >>
> >> On Tue, Jan 4, 2011 at 4:35 PM, John Fox <jfox at mcmaster.ca> wrote:
> >>> Dear r-devel list members,
> >>>
> >>> On a couple of occasions I've encountered the issue illustrated by the
> >>> following examples:
> >>>
> >>> --------- snip -----------
> >>>
> >>>> mod.1 <- lm(Employed ~ GNP.deflator + GNP + Unemployed +
> >>> +         Armed.Forces + Population + Year, data=longley)
> >>>
> >>>> mod.2 <- update(mod.1, . ~ . - Year + Year)
> >>>
> >>>> all.equal(mod.1, mod.2)
> >>> [1] TRUE
> >>>>
> >>>> f <- function(mod){
> >>> +     subs <- 1:10
> >>> +     update(mod, subset=subs)
> >>> +     }
> >>>
> >>>> f(mod.1)
> >>>
> >>> Call:
> >>> lm(formula = Employed ~ GNP.deflator + GNP + Unemployed + Armed.Forces
+
> >>>    Population + Year, data = longley, subset = subs)
> >>>
> >>> Coefficients:
> >>>  (Intercept)  GNP.deflator           GNP    Unemployed  Armed.Forces
> >>>   3.641e+03     8.394e-03     6.909e-02    -3.971e-03    -8.595e-03
> >>>  Population          Year
> >>>   1.164e+00    -1.911e+00
> >>>
> >>>> f(mod.2)
> >>> Error in eval(expr, envir, enclos) : object 'subs' not found
> >>>
> >>> --------- snip -----------
> >>>
> >>> I *almost* understand what's going -- that is, clearly mod.1 and
mod.2,
> > or
> >>> the formulas therein, are associated with different environments, but
I
> >>> don't quite see why.
> >>>
> >>> Anyway, here are two "solutions" that work, but neither is in my view
> >>> desirable:
> >>>
> >>> --------- snip -----------
> >>>
> >>>> f1 <- function(mod){
> >>> +     assign(".subs", 1:10, envir=.GlobalEnv)
> >>> +     on.exit(remove(".subs", envir=.GlobalEnv))
> >>> +     update(mod, subset=.subs)
> >>> +     }
> >>>
> >>>> f1(mod.1)
> >>>
> >>> Call:
> >>> lm(formula = Employed ~ GNP.deflator + GNP + Unemployed + Armed.Forces
+
> >>>    Population + Year, data = longley, subset = .subs)
> >>>
> >>> Coefficients:
> >>>  (Intercept)  GNP.deflator           GNP    Unemployed  Armed.Forces
> >>>   3.641e+03     8.394e-03     6.909e-02    -3.971e-03    -8.595e-03
> >>>  Population          Year
> >>>   1.164e+00    -1.911e+00
> >>>
> >>>> f1(mod.2)
> >>>
> >>> Call:
> >>> lm(formula = Employed ~ GNP.deflator + GNP + Unemployed + Armed.Forces
+
> >>>    Population + Year, data = longley, subset = .subs)
> >>>
> >>> Coefficients:
> >>>  (Intercept)  GNP.deflator           GNP    Unemployed  Armed.Forces
> >>>   3.641e+03     8.394e-03     6.909e-02    -3.971e-03    -8.595e-03
> >>>  Population          Year
> >>>   1.164e+00    -1.911e+00
> >>>
> >>>> f2 <- function(mod){
> >>> +     env <- new.env(parent=.GlobalEnv)
> >>> +     attach(NULL)
> >>> +     on.exit(detach())
> >>> +     assign(".subs", 1:10, pos=2)
> >>> +     update(mod, subset=.subs)
> >>> +     }
> >>>
> >>>> f2(mod.1)
> >>>
> >>> Call:
> >>> lm(formula = Employed ~ GNP.deflator + GNP + Unemployed + Armed.Forces
+
> >>>    Population + Year, data = longley, subset = .subs)
> >>>
> >>> Coefficients:
> >>>  (Intercept)  GNP.deflator           GNP    Unemployed  Armed.Forces
> >>>   3.641e+03     8.394e-03     6.909e-02    -3.971e-03    -8.595e-03
> >>>  Population          Year
> >>>   1.164e+00    -1.911e+00
> >>>
> >>>> f2(mod.2)
> >>>
> >>> Call:
> >>> lm(formula = Employed ~ GNP.deflator + GNP + Unemployed + Armed.Forces
+
> >>>    Population + Year, data = longley, subset = .subs)
> >>>
> >>> Coefficients:
> >>>  (Intercept)  GNP.deflator           GNP    Unemployed  Armed.Forces
> >>>   3.641e+03     8.394e-03     6.909e-02    -3.971e-03    -8.595e-03
> >>>  Population          Year
> >>>   1.164e+00    -1.911e+00
> >>>
> >>> --------- snip -----------
> >>>
> >>> The problem with f1() is that it will clobber a variable named .subs
in
> > the
> >>> global environment; the problem with f2() is that .subs can be masked
by
> > a
> >>> variable in the global environment.
> >>>
> >>> Is there a better approach?
> >>>
> >>
> >> I think there is something wrong with R here since the formula in the
> >> call component of mod.1 has a "call" class whereas the corresponding
> >> call component of mod.2 has "formula" class:
> >>
> >>> class(mod.1$call[[2]])
> >> [1] "call"
> >>> class(mod.2$call[[2]])
> >> [1] "formula"
> >>
> >> If we reset call[[2]] to have "call" class then it works:
> >>
> >>> mod.2a <- mod.2
> >>> mod.2a$call[[2]] <- as.call(as.list(mod.2a$call[[2]]))
> >>> f(mod.2a)
> >>
> >> Call:
> >> lm(formula = Employed ~ GNP.deflator + GNP + Unemployed + Armed.Forces
+
> >>    Population + Year, data = longley, subset = subs)
> >>
> >> Coefficients:
> >> (Intercept)  GNP.deflator           GNP    Unemployed  Armed.Forces
> >> Population          Year
> >>   3.641e+03     8.394e-03     6.909e-02    -3.971e-03    -8.595e-03
> >>  1.164e+00    -1.911e+00
> >>
> >>
> >> --
> >> Statistics & Software Consulting
> >> GKX Group, GKX Associates Inc.
> >> tel: 1-877-GKX-GROUP
> >> email: ggrothendieck at gmail.com
> >>
> >> ______________________________________________
> >> R-devel at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-devel
> >
> 
> --
> Peter Dalgaard
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From kleiman at rohan.sdsu.edu  Wed Jan  5 23:53:58 2011
From: kleiman at rohan.sdsu.edu (Elliot Todd Kleiman)
Date: Wed, 5 Jan 2011 14:53:58 -0800 (PST)
Subject: [Rd] \VignetteKeywords{}, for KEYWORDS or for free-tagging?
In-Reply-To: <19748.4646.918513.719315@fangorn.hornik.net>
References: <Pine.GSO.4.64.1012282323310.9121@rohan.sdsu.edu>
	<19745.52937.544928.604562@fangorn.hornik.net>
	<Pine.GSO.4.64.1101031358480.28885@rohan.sdsu.edu>
	<19748.4646.918513.719315@fangorn.hornik.net>
Message-ID: <Pine.GSO.4.64.1101051444330.7085@rohan.sdsu.edu>

Hi Kurt,

Thank you very much for clarifying this.

I hope that some documentation may be
written about these commands and added
to one of the manuals in the future.

+ Elliot


On Wed, 5 Jan 2011, Kurt Hornik wrote:

>>>>>> Elliot Todd Kleiman writes:
>
>> Hi Kurt,
>> Thank you for the info!
>
>> However, I would also like to ask:
>
>> * Since the user may use any words as 'keywords',
>> what is the purpose of this command and what are
>> the benefits of using it?
>
>> * Where is the documentation for the '\Vignette*'
>> commands?
>
>> Because other than the '\VignetteIndexEntry' command,
>> I could not find any mentioning of them in the R-exts
>> manual, http://cran.r-project.org/doc/manuals/R-exts.html.
>
> I don't think that the vignette metadata are currently used "a lot".
> They make it into the vignette index but users don't get to play with
> this.  (There are long-standing plans to integrate vignettes into the
> help system [with help and help.search], though.)
>
> Best
> -k
>
>> Best,
>
>> + Elliot
>
>> On Mon, 3 Jan 2011, Kurt Horniks wrote:
>
>>>>>>>> Elliot Todd Kleiman writes:
>>>
>>>> Hi R-devel,
>>>> [Question]:
>>>
>>>> * Is there a KEYWORDS file to lookup 'keywords' to supply
>>>> the vignette command, '\VignetteKeywords{}'?
>>>
>>>> -or, is the pkg writer free to tag the vignette using any
>>>> keywords he/she chooses? i.e., free-tagging.
>>>
>>> For vignette keywords, the latter.
>>>
>>> Best
>>> -k
>>>
>>>> Thank you,
>>>
>>>> + Elliot Kleiman
>>>> __________________________
>>>> San Diego State University
>>>> http://www.sdsu.edu/
>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>>
>
>


From Kurt.Hornik at wu.ac.at  Thu Jan  6 10:52:17 2011
From: Kurt.Hornik at wu.ac.at (Kurt Hornik)
Date: Thu, 6 Jan 2011 10:52:17 +0100
Subject: [Rd] Minimum of an ordered factor
In-Reply-To: <19748.36291.498450.670163@lynne.math.ethz.ch>
References: <F54EF8F1B477CF448729593FE421F6464A22AE@HQVEVE0032.nestle.com>
	<19748.36291.498450.670163@lynne.math.ethz.ch>
Message-ID: <19749.37073.506112.61897@fangorn.hornik.net>

>>>>> Martin Maechler writes:

I have 3 comments:

>>>>> Thaler, Thorn, LAUSANNE, Applied Mathematics <Thorn.Thaler at rdls.nestle.com>
>>>>>     on Wed, 5 Jan 2011 11:20:47 +0100 writes:

>> Hi everybody, Is there a particular reason, why this code
>> does not work as intended:

>> z <- factor(LETTERS[1:3], ordered = TRUE)
>> u <- 4:6
>> min(z[u > 4])

>> Error in Summary.factor(2:3, na.rm = FALSE) :
>> min not meaningful for factors



>> I agree that min is indeed not meaningful for not ordered
>> factors, but it makes sense for ordered
>> factors. Especially since

>> z[3] < z[2]
>> sort(z)

>> _ARE_ defined and work as expected. 

> I agree that it is natural then, to expect  min(), max() and
> range() to work as well.

Same for me.

>> Of course I can do something like

>> sort(z[u>4])[1]

>> but this does not enhance readability of my code. Thus, I
>> overloaded Summary.ordered as follows:


 

>> Summary.ordered <- function(..., na.rm) {

>> ok <- switch(.Generic, max = , min = , range = TRUE,
>> FALSE)

>> if (!ok) {

>> warning(sprintf("'%s' is not meaningful for ordered
>> factors", .Generic))

>> return(NA)

>> }

>> args <- list(...)

>> level.list <- lapply(args, levels)

>> level.set <- Reduce(union, level.list)

>> if (!all(sapply(args, is.ordered)) ||
>> !all(sapply(level.list, identical, y = level.set))) {

I think it would be better to use something like

  ll <- lapply(args, levels)

  !all(sapply(ll, identical, ll[[1L]]))

[using union() is not quite right]  

>> stop(sprintf("'%s' is only meaningful for ordered
>> factors if all arguments are ordered factors with the same
>> level sets",

>> .Generic))

>> }

>> codes <- lapply(args, as.integer)

>> ind <- do.call(.Generic, c(codes, na.rm = na.rm))

>> factor(level.set[ind], levels = level.set, ordered =
>> TRUE)

>> }

> (the above is now even more garbled than it was already by your
>  use of HTML-ified e-mail ..)

> But your code is fine, even nice, in most parts,
> and I will add (most of) it (and some documentation) to R-devel
 
> unless we get contradicting comments :

>> Any comments appreciated.
> (still)

The general comment is that if we support this I don't see why we should
not also support c.ordered (and in fact also c.factor) with the same
restrictions (identical level sequences for ordered and level sets for
factors).  We already have Ops.factor and Ops.ordered using the same
principle afaic.

If we add c.ordered, we should be able to encapsulate the identity of
levels testing into this, and simply use

    x <- c(...)

and then call .Generic on the codes of x etc.

Best
-k


> Thank you, Thorn!

> With regards,
> Martin Maechler, ETH Zurich

> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From lebatsnok at gmail.com  Thu Jan  6 13:11:44 2011
From: lebatsnok at gmail.com (Kenn Konstabel)
Date: Thu, 6 Jan 2011 14:11:44 +0200
Subject: [Rd] scoping/non-standard evaluation issue
In-Reply-To: <009b01cbac57$532a3b80$f97eb280$@ca>
References: <009b01cbac57$532a3b80$f97eb280$@ca>
Message-ID: <AANLkTi=Hi=XN81xMNTGKsyw5oqU0VU+sRRBaBSPNVY_t@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110106/3470220c/attachment.pl>

From pdalgd at gmail.com  Thu Jan  6 13:31:06 2011
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 6 Jan 2011 13:31:06 +0100
Subject: [Rd] scoping/non-standard evaluation issue
In-Reply-To: <AANLkTi=Hi=XN81xMNTGKsyw5oqU0VU+sRRBaBSPNVY_t@mail.gmail.com>
References: <009b01cbac57$532a3b80$f97eb280$@ca>
	<AANLkTi=Hi=XN81xMNTGKsyw5oqU0VU+sRRBaBSPNVY_t@mail.gmail.com>
Message-ID: <9EE05E39-820F-4524-86FE-8146F856FA55@gmail.com>


On Jan 6, 2011, at 13:11 , Kenn Konstabel wrote:

> the following seems an easy solution:
> 
> f1 <- function(mod){
>     subs <- 1:10
>     toeval <- quote(update(mod, subset=subs))
>     toeval$subset<-subs
>     eval(toeval)
>     }
> 
> f1(mod.2)

Tere, Kenn!

Yes, enforcing pass-by-value by pre-evaluating the argument will certainly defeat the nonstandard evaluation issues. Another version of the same idea is

eval(bquote(update(mod, .(subs)))

The only thing is that if the argument is ever deparsed, you might get a messy display. E.g., try eval(bquote(plot(.(rnorm(20)))))


-pd

-- 
Peter Dalgaard
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From Thorn.Thaler at rdls.nestle.com  Thu Jan  6 15:37:01 2011
From: Thorn.Thaler at rdls.nestle.com (Thaler, Thorn, LAUSANNE,
	Applied Mathematics)
Date: Thu, 6 Jan 2011 15:37:01 +0100
Subject: [Rd] Minimum of an ordered factor
In-Reply-To: <19749.37073.506112.61897@fangorn.hornik.net>
References: <F54EF8F1B477CF448729593FE421F6464A22AE@HQVEVE0032.nestle.com><19748.36291.498450.670163@lynne.math.ethz.ch>
	<19749.37073.506112.61897@fangorn.hornik.net>
Message-ID: <F54EF8F1B477CF448729593FE421F6464A2377@HQVEVE0032.nestle.com>

Kurt Hornik writes
> >> if (!all(sapply(args, is.ordered)) ||
> >> !all(sapply(level.list, identical, y = level.set))) {
> 
> I think it would be better to use something like
> 
>   ll <- lapply(args, levels)
> 
>   !all(sapply(ll, identical, ll[[1L]]))
> 
> [using union() is not quite right]

Yes definitely. This line is in fact just a relic from a previous idea I
had.
 
> The general comment is that if we support this I don't see why we
> should
> not also support c.ordered (and in fact also c.factor) with the same
> restrictions (identical level sequences for ordered and level sets for
> factors).  We already have Ops.factor and Ops.ordered using the same
> principle afaic.
> 
> If we add c.ordered, we should be able to encapsulate the identity of
> levels testing into this, and simply use
> 
>     x <- c(...)
> 
> and then call .Generic on the codes of x etc.

Sounds reasonable. Ack.

BR Thorn


From bbolker at gmail.com  Thu Jan  6 22:30:06 2011
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 06 Jan 2011 16:30:06 -0500
Subject: [Rd] trivial typo in R language definition manual
Message-ID: <4D26345E.50900@gmail.com>


  on line 1714 of R-lang.texi (current SVN of R-devel, 53919)

 @code{x$aa} will match @code{x$aabb} if @code{x} does not a component

  should probably have "contain" or "have" inserted after "not"


From wdunlap at tibco.com  Fri Jan  7 02:29:42 2011
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 6 Jan 2011 17:29:42 -0800
Subject: [Rd] formula(model.frame(y~.^2,
	data=d)) does not return formula from terms attribute of the
	model.frame
Message-ID: <77EB52C6DD32BA4D87471DCD70C8D70003C2E52B@NA-PA-VBE03.na.tibco.com>

In R 2.12.0 I get
  > d <- data.frame(x=1:10, y=log(1:10), f3=LETTERS[rep(1:3,c(3,3,4))])
  > m <- model.frame(y~.^2, data=d)
  > formula(m)
  y ~ x + f3
In S+ formula(m) gives formula given to model.frame(),
but in R you have to do the following get that formula:
  > formula(attr(m, "terms"))
  y ~ (x + f3)^2

Would it break anything to add to the top of formula.data.frame
something like
  if (!is.null(tms <- attr(x, "terms"))) {
    return(formula(tms))
  }
so that formula() would retrieve the formula buried
in model.frame's output?

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com 


From dwinsemius at comcast.net  Fri Jan  7 06:08:29 2011
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 7 Jan 2011 00:08:29 -0500
Subject: [Rd] Indexing request
Message-ID: <6A5820A7-03B1-4995-A8B7-846850319312@comcast.net>


I just tried ?Constants at the console and was disappointed that the  
so-named base help page would not come up.

 > ?Constants
No documentation for 'Constants' in specified packages and libraries:
you could try '??Constants'

Seems like there should have been a match. I was looking for the month  
abbreviations, failing to hit the right name 4 times and then failing  
3 more times on variations of what I remembered to be the name of that  
page and finally ended up typing:

?letters

--

David Winsemius, MD
West Hartford, CT


From smckinney at bccrc.ca  Fri Jan  7 06:48:17 2011
From: smckinney at bccrc.ca (Steven McKinney)
Date: Thu, 6 Jan 2011 21:48:17 -0800
Subject: [Rd] Indexing request
In-Reply-To: <15312_1294376928_1294376928_6A5820A7-03B1-4995-A8B7-846850319312@comcast.net>
References: <15312_1294376928_1294376928_6A5820A7-03B1-4995-A8B7-846850319312@comcast.net>
Message-ID: <DCE81E14EB74504B971DAD4D2DB0356B08645685B1@crcmail4.BCCRC.CA>


Yes, odd that ?Constants doesn't work, given that there is a page labeled
 Constants {base}.

On a happier note, these all work now on my Mac R version 2.11.1 

> ?base
> ?stats
> ?utils

though Constants is not an entry in the index.

R help gurus - is it possible to have entries such as "Constants"
for such help pages that discuss multiple functions?

On further poking around I do see an index entry for "assignOps" 
for page assignOps {base} so the answer is obviously "yes".
I guess it's now a matter of providing a patch or convincing
an R developer to do so in his copious spare time :)

 


Steven McKinney

Statistician
Molecular Oncology and Breast Cancer Program
British Columbia Cancer Research Centre

________________________________________
From: r-devel-bounces at r-project.org [r-devel-bounces at r-project.org] On Behalf Of David Winsemius [dwinsemius at comcast.net]
Sent: January 6, 2011 9:08 PM
To: r-devel at stat.math.ethz.ch
Subject: [Rd] Indexing request

I just tried ?Constants at the console and was disappointed that the
so-named base help page would not come up.

 > ?Constants
No documentation for 'Constants' in specified packages and libraries:
you could try '??Constants'

Seems like there should have been a match. I was looking for the month
abbreviations, failing to hit the right name 4 times and then failing
3 more times on variations of what I remembered to be the name of that
page and finally ended up typing:

?letters

--

David Winsemius, MD
West Hartford, CT

______________________________________________
R-devel at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-devel


From murdoch.duncan at gmail.com  Fri Jan  7 11:09:47 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 07 Jan 2011 05:09:47 -0500
Subject: [Rd] Indexing request
In-Reply-To: <6A5820A7-03B1-4995-A8B7-846850319312@comcast.net>
References: <6A5820A7-03B1-4995-A8B7-846850319312@comcast.net>
Message-ID: <4D26E66B.8020905@gmail.com>

On 11-01-07 12:08 AM, David Winsemius wrote:
>
> I just tried ?Constants at the console and was disappointed that the
> so-named base help page would not come up.
>
>   >  ?Constants
> No documentation for 'Constants' in specified packages and libraries:
> you could try '??Constants'
>
> Seems like there should have been a match. I was looking for the month
> abbreviations, failing to hit the right name 4 times and then failing
> 3 more times on variations of what I remembered to be the name of that
> page and finally ended up typing:
>

I do see that page as the first hit if I follow the advice and type 
??Constants, though there seems to be a problem with the OSX help system 
and that particular page.

But I agree with you, and will add Constants to the index.

For future reference:  Every help page has:

  - a name (in this case "Constants"), which is what is displayed at the 
top of the help page.  It also determines the order in which pages are 
collated into the full manual, if you build one of those.
  - a title (which is a one-line explanation of the page); here it is 
"Built-in constants".  That is shown in the results from ??Constants.
  - a number of aliases, which are indexed.  Those are the things which 
work with a single ?.  In this case they are "LETTERS", "letters", 
"month.abb", "month.name", and "pi".
  - a filename (which you'll never see), in this case it's 
src/library/base/man/Constants.Rd.  That's the file to edit to make this 
change.

In most cases the name is repeated as an alias, but for some reason 
(flexibility?) that's not a requirement, and is not always the case, as 
here.  If I were designing the system I would say the name is 
automatically an alias, but perhaps there are cases where that would be 
undesirable.

I'll add it as an alias here.  I've passed on a message about the 
problem on that page, and it should eventually be fixed.

Duncan Murdoch


From ripley at stats.ox.ac.uk  Fri Jan  7 11:52:44 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 7 Jan 2011 10:52:44 +0000 (GMT)
Subject: [Rd] Indexing request
In-Reply-To: <4D26E66B.8020905@gmail.com>
References: <6A5820A7-03B1-4995-A8B7-846850319312@comcast.net>
	<4D26E66B.8020905@gmail.com>
Message-ID: <alpine.LFD.2.00.1101071027310.23134@toucan.stats.ox.ac.uk>

On Fri, 7 Jan 2011, Duncan Murdoch wrote:

> On 11-01-07 12:08 AM, David Winsemius wrote:
>> 
>> I just tried ?Constants at the console and was disappointed that the
>> so-named base help page would not come up.
>>
>>   >  ?Constants
>> No documentation for 'Constants' in specified packages and libraries:
>> you could try '??Constants'
>> 
>> Seems like there should have been a match. I was looking for the month
>> abbreviations, failing to hit the right name 4 times and then failing
>> 3 more times on variations of what I remembered to be the name of that
>> page and finally ended up typing:
>> 
>
> I do see that page as the first hit if I follow the advice and type 
> ??Constants, though there seems to be a problem with the OSX help system and 
> that particular page.
>
> But I agree with you, and will add Constants to the index.

I am not so sure: Constants seems rather to be a \concept entry, and 
those are (deliberately) not searched by help()/?.  (There is also the 
question of capitalization: help() looks for exact matches.)

> For future reference:  Every help page has:
>
> - a name (in this case "Constants"), which is what is displayed at the top 
> of the help page.  It also determines the order in which pages are collated 
> into the full manual, if you build one of those.
> - a title (which is a one-line explanation of the page); here it is 
> "Built-in constants".  That is shown in the results from ??Constants.
> - a number of aliases, which are indexed.  Those are the things which work 
> with a single ?.  In this case they are "LETTERS", "letters", "month.abb", 
> "month.name", and "pi".
> - a filename (which you'll never see), in this case it's 
> src/library/base/man/Constants.Rd.  That's the file to edit to make this 
> change.
>
> In most cases the name is repeated as an alias, but for some reason 
> (flexibility?) that's not a requirement, and is not always the case, as here. 
> If I were designing the system I would say the name is automatically an 
> alias, but perhaps there are cases where that would be undesirable.

That was the case a decade ago, and it was found to be undesirable for 
various reasons (one was the restrictions on the value for \name, 
which used to be more severe than they are now).  Another was that 
where there were multiple matches the user was only offered one, so a 
badly chosen \name in a contributed package could mask completely an 
\alias in the standard system.

> I'll add it as an alias here.  I've passed on a message about the problem on 
> that page, and it should eventually be fixed.
>
> Duncan Murdoch
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From maechler at stat.math.ethz.ch  Fri Jan  7 11:57:19 2011
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 7 Jan 2011 11:57:19 +0100
Subject: [Rd] Minimum of an ordered factor
In-Reply-To: <F54EF8F1B477CF448729593FE421F6464A2377@HQVEVE0032.nestle.com>
References: <F54EF8F1B477CF448729593FE421F6464A22AE@HQVEVE0032.nestle.com>
	<19748.36291.498450.670163@lynne.math.ethz.ch>
	<19749.37073.506112.61897@fangorn.hornik.net>
	<F54EF8F1B477CF448729593FE421F6464A2377@HQVEVE0032.nestle.com>
Message-ID: <19750.61839.60744.481983@lynne.math.ethz.ch>

>>>>> "TTLAM" == Thaler, Thorn, LAUSANNE, Applied Mathematics <Thorn.Thaler at rdls.nestle.com>
>>>>>     on Thu, 6 Jan 2011 15:37:01 +0100 writes:

    TTLAM> Kurt Hornik writes
    >> >> if (!all(sapply(args, is.ordered)) ||
    >> >> !all(sapply(level.list, identical, y = level.set))) {
    >> 
    >> I think it would be better to use something like
    >> 
    >> ll <- lapply(args, levels)
    >> 
    >> !all(sapply(ll, identical, ll[[1L]]))
    >> 
    >> [using union() is not quite right]

    TTLAM> Yes definitely. This line is in fact just a relic from a previous idea I
    TTLAM> had.
 
I have now committed the amended proposal (rev 53925);
thank you for the feedbacks..


    >> The general comment is that if we support this I don't see why we
    >> should
    >> not also support c.ordered (and in fact also c.factor) with the same
    >> restrictions (identical level sequences for ordered and level sets for
    >> factors).  We already have Ops.factor and Ops.ordered using the same
    >> principle afaic.

Yes, I think, too.

    >> If we add c.ordered, we should be able to encapsulate the identity of
    >> levels testing into this, and simply use
    >> 
    >> x <- c(...)
    >> 
    >> and then call .Generic on the codes of x etc.

    TTLAM> Sounds reasonable. Ack.

Yes, adding c.factor() and c.ordered() seems reasonable in
principle.
However, S and R now have a more than 20 year old history of
silently coercing factors to there integer codes with c(),
that I'm not yet sure we can do this without breaking too much
code [[and I am pretty sure this topic has been discusses before]].

I think we should start discussing the issue in a new thread
with proper Subject explicitly mention "c()" or "c.factor"/"c.ordered".
Martin



    TTLAM> BR Thorn

    TTLAM> ______________________________________________
    TTLAM> R-devel at r-project.org mailing list
    TTLAM> https://stat.ethz.ch/mailman/listinfo/r-devel


From Thorn.Thaler at rdls.nestle.com  Fri Jan  7 13:35:16 2011
From: Thorn.Thaler at rdls.nestle.com (Thaler, Thorn, LAUSANNE,
	Applied Mathematics)
Date: Fri, 7 Jan 2011 13:35:16 +0100
Subject: [Rd] Minimum of an ordered factor
In-Reply-To: <19750.61839.60744.481983@lynne.math.ethz.ch>
References: <F54EF8F1B477CF448729593FE421F6464A22AE@HQVEVE0032.nestle.com><19748.36291.498450.670163@lynne.math.ethz.ch><19749.37073.506112.61897@fangorn.hornik.net><F54EF8F1B477CF448729593FE421F6464A2377@HQVEVE0032.nestle.com>
	<19750.61839.60744.481983@lynne.math.ethz.ch>
Message-ID: <F54EF8F1B477CF448729593FE421F6464A23C6@HQVEVE0032.nestle.com>

> Martin Maechler writes
> I have now committed the amended proposal (rev 53925);
> thank you for the feedbacks..

I had a look at it and there is a typo:
	
stop(gettextf("'%s' not defined for \"difftime\" objects", .Generic),
domain = NA)

should rather be

stop(gettextf("'%s' not defined for ordered factors", .Generic), domain
= NA)

BR Thorn


From murdoch.duncan at gmail.com  Fri Jan  7 13:41:42 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 07 Jan 2011 07:41:42 -0500
Subject: [Rd] Indexing request
In-Reply-To: <alpine.LFD.2.00.1101071027310.23134@toucan.stats.ox.ac.uk>
References: <6A5820A7-03B1-4995-A8B7-846850319312@comcast.net>
	<4D26E66B.8020905@gmail.com>
	<alpine.LFD.2.00.1101071027310.23134@toucan.stats.ox.ac.uk>
Message-ID: <4D270A06.3020708@gmail.com>

On 11-01-07 5:52 AM, Prof Brian Ripley wrote:
> On Fri, 7 Jan 2011, Duncan Murdoch wrote:
>
>> On 11-01-07 12:08 AM, David Winsemius wrote:
>>>
>>> I just tried ?Constants at the console and was disappointed that the
>>> so-named base help page would not come up.
>>>
>>>    >   ?Constants
>>> No documentation for 'Constants' in specified packages and libraries:
>>> you could try '??Constants'
>>>
>>> Seems like there should have been a match. I was looking for the month
>>> abbreviations, failing to hit the right name 4 times and then failing
>>> 3 more times on variations of what I remembered to be the name of that
>>> page and finally ended up typing:
>>>
>>
>> I do see that page as the first hit if I follow the advice and type
>> ??Constants, though there seems to be a problem with the OSX help system and
>> that particular page.
>>
>> But I agree with you, and will add Constants to the index.
>
> I am not so sure: Constants seems rather to be a \concept entry, and
> those are (deliberately) not searched by help()/?.  (There is also the
> question of capitalization: help() looks for exact matches.)

I think David's argument convinced me:  he had an imperfect memory of 
the page, but it included the name (which is displayed prominently when 
you see it).  Pages where the name is not an alias are so uncommon that 
most people don't realize that the name is not searched by help().


>
>> For future reference:  Every help page has:
>>
>> - a name (in this case "Constants"), which is what is displayed at the top
>> of the help page.  It also determines the order in which pages are collated
>> into the full manual, if you build one of those.
>> - a title (which is a one-line explanation of the page); here it is
>> "Built-in constants".  That is shown in the results from ??Constants.
>> - a number of aliases, which are indexed.  Those are the things which work
>> with a single ?.  In this case they are "LETTERS", "letters", "month.abb",
>> "month.name", and "pi".
>> - a filename (which you'll never see), in this case it's
>> src/library/base/man/Constants.Rd.  That's the file to edit to make this
>> change.
>>
>> In most cases the name is repeated as an alias, but for some reason
>> (flexibility?) that's not a requirement, and is not always the case, as here.
>> If I were designing the system I would say the name is automatically an
>> alias, but perhaps there are cases where that would be undesirable.
>
> That was the case a decade ago, and it was found to be undesirable for
> various reasons (one was the restrictions on the value for \name,
> which used to be more severe than they are now).  Another was that
> where there were multiple matches the user was only offered one, so a
> badly chosen \name in a contributed package could mask completely an
> \alias in the standard system.

The help system can now handle duplicates, can't it?  Check will warn 
about duplicate aliases within a package, but alias conflicts across 
packages work fine.

Duncan

>
>> I'll add it as an alias here.  I've passed on a message about the problem on
>> that page, and it should eventually be fixed.
>>
>> Duncan Murdoch
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>


From cooch17 at verizon.net  Thu Jan  6 22:27:35 2011
From: cooch17 at verizon.net (egc)
Date: Thu, 06 Jan 2011 16:27:35 -0500
Subject: [Rd] steps for problems compiling a package
Message-ID: <4D2633C7.1070707@verizon.net>

Recently installed 2.12.1 on my CentOS 5.5 box. Install of R went 
without incident, and packages downloaded and compiled fine. With one 
exception -- my interest is somewhat in the problems with this 
particular package, but more in terms of 'what to do if/when a package' 
doesn't compile properly.

The offending package (in this instance) is rjags. When I try to install 
it using

install.packages("rjags",lib="/usr/local/lib64/R/library")

I get the following comiplation messages:

* installing *source* package "rjags? ...
checking for prefix by checking for jags... /usr/bin/jags
checking whether the C++ compiler works... yes
checking for C++ compiler default output file name... a.out
checking for suffix of executables...
checking whether we are cross compiling... no
checking for suffix of object files... o
checking whether we are using the GNU C++ compiler... yes
checking whether g++ accepts -g... yes
checking how to run the C++ preprocessor... g++ -E
checking for grep that handles long lines and -e... /bin/grep
checking for egrep... /bin/grep -E
checking for ANSI C header files... yes
checking for sys/types.h... yes
checking for sys/stat.h... yes
checking for stdlib.h... yes
checking for string.h... yes
checking for memory.h... yes
checking for strings.h... yes
checking for inttypes.h... yes
checking for stdint.h... yes
checking for unistd.h... yes
checking Console.h usability... no
checking Console.h presence... no
checking for Console.h... no

configure: error: in `/tmp/Rtmpb64Khr/R.INSTALL6524e7b4/rjags':
configure: error: "Problem with header file /usr/include/JAGS/Console.h "
See `config.log' for more details.
ERROR: configuration failed for package "rjags?
* removing ???/usr/local/lib64/R/library/rjags?

The downloaded packages are in
?/tmp/RtmpwAo4Qp/downloaded_packages?
Updating HTML index of packages in '.Library'
Warning message:
In install.packages("rjags", lib = "/usr/local/lib64/R/library") :
installation of package 'rjags' had non-zero exit status


So, my questions:

1. the error messages suggest looking at config.log for details. Will do 
-- if someone will tell me where to find config.log?

2. in cases (such as this) where an individual package throws errors on 
compilation, what is the recommended ("officially sanctified") approach 
to dealing with -- post question to r-devel, or to the package maintainer?

3. in this particular instance, the problem seems to be related to a 
header in /usr/include/JAGS No doubt this is because (in fact) 
/usr/includes/JAGS doesn't exist. Which I suppose brings me back to 
question (2).

Thanks in advance...


From ripley at stats.ox.ac.uk  Fri Jan  7 14:54:49 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 7 Jan 2011 13:54:49 +0000 (GMT)
Subject: [Rd] Indexing request
In-Reply-To: <4D270A06.3020708@gmail.com>
References: <6A5820A7-03B1-4995-A8B7-846850319312@comcast.net>
	<4D26E66B.8020905@gmail.com>
	<alpine.LFD.2.00.1101071027310.23134@toucan.stats.ox.ac.uk>
	<4D270A06.3020708@gmail.com>
Message-ID: <alpine.LFD.2.00.1101071351300.27561@toucan.stats.ox.ac.uk>

On Fri, 7 Jan 2011, Duncan Murdoch wrote:

> On 11-01-07 5:52 AM, Prof Brian Ripley wrote:
>> On Fri, 7 Jan 2011, Duncan Murdoch wrote:
>> 
>>> On 11-01-07 12:08 AM, David Winsemius wrote:
>>>> 
>>>> I just tried ?Constants at the console and was disappointed that the
>>>> so-named base help page would not come up.
>>>>
>>>>    >   ?Constants
>>>> No documentation for 'Constants' in specified packages and libraries:
>>>> you could try '??Constants'
>>>> 
>>>> Seems like there should have been a match. I was looking for the month
>>>> abbreviations, failing to hit the right name 4 times and then failing
>>>> 3 more times on variations of what I remembered to be the name of that
>>>> page and finally ended up typing:
>>>> 
>>> 
>>> I do see that page as the first hit if I follow the advice and type
>>> ??Constants, though there seems to be a problem with the OSX help system 
>>> and
>>> that particular page.
>>> 
>>> But I agree with you, and will add Constants to the index.
>> 
>> I am not so sure: Constants seems rather to be a \concept entry, and
>> those are (deliberately) not searched by help()/?.  (There is also the
>> question of capitalization: help() looks for exact matches.)
>
> I think David's argument convinced me:  he had an imperfect memory of the 
> page, but it included the name (which is displayed prominently when you see 
> it).  Pages where the name is not an alias are so uncommon that most people 
> don't realize that the name is not searched by help().
>
>
>> 
>>> For future reference:  Every help page has:
>>> 
>>> - a name (in this case "Constants"), which is what is displayed at the top
>>> of the help page.  It also determines the order in which pages are 
>>> collated
>>> into the full manual, if you build one of those.
>>> - a title (which is a one-line explanation of the page); here it is
>>> "Built-in constants".  That is shown in the results from ??Constants.
>>> - a number of aliases, which are indexed.  Those are the things which work
>>> with a single ?.  In this case they are "LETTERS", "letters", "month.abb",
>>> "month.name", and "pi".
>>> - a filename (which you'll never see), in this case it's
>>> src/library/base/man/Constants.Rd.  That's the file to edit to make this
>>> change.
>>> 
>>> In most cases the name is repeated as an alias, but for some reason
>>> (flexibility?) that's not a requirement, and is not always the case, as 
>>> here.
>>> If I were designing the system I would say the name is automatically an
>>> alias, but perhaps there are cases where that would be undesirable.
>> 
>> That was the case a decade ago, and it was found to be undesirable for
>> various reasons (one was the restrictions on the value for \name,
>> which used to be more severe than they are now).  Another was that
>> where there were multiple matches the user was only offered one, so a
>> badly chosen \name in a contributed package could mask completely an
>> \alias in the standard system.
>
> The help system can now handle duplicates, can't it?  Check will warn about 
> duplicate aliases within a package, but alias conflicts across packages work 
> fine.

Yes, it now offers a menu of choices when there are multiple exact 
matches.  But AFAIR that was not the case when \name was removed as an 
automatic alias.

>
> Duncan
>
>> 
>>> I'll add it as an alias here.  I've passed on a message about the problem 
>>> on
>>> that page, and it should eventually be fixed.
>>> 
>>> Duncan Murdoch
>>> 
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>> 
>> 
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From maechler at stat.math.ethz.ch  Fri Jan  7 15:38:14 2011
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 7 Jan 2011 15:38:14 +0100
Subject: [Rd] Minimum of an ordered factor
In-Reply-To: <F54EF8F1B477CF448729593FE421F6464A23C6@HQVEVE0032.nestle.com>
References: <F54EF8F1B477CF448729593FE421F6464A22AE@HQVEVE0032.nestle.com>
	<19748.36291.498450.670163@lynne.math.ethz.ch>
	<19749.37073.506112.61897@fangorn.hornik.net>
	<F54EF8F1B477CF448729593FE421F6464A2377@HQVEVE0032.nestle.com>
	<19750.61839.60744.481983@lynne.math.ethz.ch>
	<F54EF8F1B477CF448729593FE421F6464A23C6@HQVEVE0032.nestle.com>
Message-ID: <19751.9558.440289.247493@lynne.math.ethz.ch>

>>>>> Thaler,Thorn,LAUSANNE,Applied Mathematics <Thorn.Thaler at rdls.nestle.com>
>>>>>     on Fri, 7 Jan 2011 13:35:16 +0100 writes:

    >> Martin Maechler writes
    >> I have now committed the amended proposal (rev 53925);
    >> thank you for the feedbacks..

    > I had a look at it and there is a typo:
	
    > stop(gettextf("'%s' not defined for \"difftime\" objects", .Generic),
    > domain = NA)

    > should rather be

    > stop(gettextf("'%s' not defined for ordered factors", .Generic), domain
    TM> = NA)

aah.. blushshsh ! .... (and thanks).
Martin


From ripley at stats.ox.ac.uk  Fri Jan  7 16:18:56 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 7 Jan 2011 15:18:56 +0000 (GMT)
Subject: [Rd] steps for problems compiling a package
In-Reply-To: <4D2633C7.1070707@verizon.net>
References: <4D2633C7.1070707@verizon.net>
Message-ID: <alpine.LFD.2.00.1101071509380.10649@gannet.stats.ox.ac.uk>

On Thu, 6 Jan 2011, egc wrote:

> Recently installed 2.12.1 on my CentOS 5.5 box. Install of R went without 
> incident, and packages downloaded and compiled fine. With one exception -- my 
> interest is somewhat in the problems with this particular package, but more 
> in terms of 'what to do if/when a package' doesn't compile properly.

1) For a source package, download it and unpack the tarball.

2) Read the instructions: you missed the README file, which starts

   The rjags package is an interface to the JAGS library.  In order to
   build a binary package, or install from source, you must have a
   matching installation of the JAGS library.

You might also be unaware of 
http://www-fis.iarc.fr/~martyn/software/jags/

3) If you run

R CMD INSTALL rjags

then config.log will be in the rjags directory.  Which is one reason 
to download and unpack the tarball: it will be in a temporary 
directory if run from install.packages() or INSTALL on the tarball.

4) As for where to ask: see the posting guide!

>
> The offending package (in this instance) is rjags. When I try to install it 
> using
>
> install.packages("rjags",lib="/usr/local/lib64/R/library")
>
> I get the following comiplation messages:
>
> * installing *source* package "rjags? ...
> checking for prefix by checking for jags... /usr/bin/jags
> checking whether the C++ compiler works... yes
> checking for C++ compiler default output file name... a.out
> checking for suffix of executables...
> checking whether we are cross compiling... no
> checking for suffix of object files... o
> checking whether we are using the GNU C++ compiler... yes
> checking whether g++ accepts -g... yes
> checking how to run the C++ preprocessor... g++ -E
> checking for grep that handles long lines and -e... /bin/grep
> checking for egrep... /bin/grep -E
> checking for ANSI C header files... yes
> checking for sys/types.h... yes
> checking for sys/stat.h... yes
> checking for stdlib.h... yes
> checking for string.h... yes
> checking for memory.h... yes
> checking for strings.h... yes
> checking for inttypes.h... yes
> checking for stdint.h... yes
> checking for unistd.h... yes
> checking Console.h usability... no
> checking Console.h presence... no
> checking for Console.h... no
>
> configure: error: in `/tmp/Rtmpb64Khr/R.INSTALL6524e7b4/rjags':
> configure: error: "Problem with header file /usr/include/JAGS/Console.h "
> See `config.log' for more details.
> ERROR: configuration failed for package "rjags?
> * removing ???/usr/local/lib64/R/library/rjags?
>
> The downloaded packages are in
> ?/tmp/RtmpwAo4Qp/downloaded_packages?
> Updating HTML index of packages in '.Library'
> Warning message:
> In install.packages("rjags", lib = "/usr/local/lib64/R/library") :
> installation of package 'rjags' had non-zero exit status
>
>
> So, my questions:
>
> 1. the error messages suggest looking at config.log for details. Will do -- 
> if someone will tell me where to find config.log?
>
> 2. in cases (such as this) where an individual package throws errors on 
> compilation, what is the recommended ("officially sanctified") approach to 
> dealing with -- post question to r-devel, or to the package maintainer?
>
> 3. in this particular instance, the problem seems to be related to a header 
> in /usr/include/JAGS No doubt this is because (in fact) /usr/includes/JAGS 
> doesn't exist. Which I suppose brings me back to question (2).
>
> Thanks in advance...
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From Kurt.Hornik at wu.ac.at  Sat Jan  8 08:54:26 2011
From: Kurt.Hornik at wu.ac.at (Kurt Hornik)
Date: Sat, 8 Jan 2011 08:54:26 +0100
Subject: [Rd] Minimum of an ordered factor
In-Reply-To: <19750.61839.60744.481983@lynne.math.ethz.ch>
References: <F54EF8F1B477CF448729593FE421F6464A22AE@HQVEVE0032.nestle.com>
	<19748.36291.498450.670163@lynne.math.ethz.ch>
	<19749.37073.506112.61897@fangorn.hornik.net>
	<F54EF8F1B477CF448729593FE421F6464A2377@HQVEVE0032.nestle.com>
	<19750.61839.60744.481983@lynne.math.ethz.ch>
Message-ID: <19752.6194.611459.498155@fangorn.hornik.net>

>>>>> Martin Maechler writes:

>>>>> "TTLAM" == Thaler, Thorn, LAUSANNE, Applied Mathematics <Thorn.Thaler at rdls.nestle.com>
>>>>>     on Thu, 6 Jan 2011 15:37:01 +0100 writes:

TTLAM> Kurt Hornik writes
>>> >> if (!all(sapply(args, is.ordered)) ||
>>> >> !all(sapply(level.list, identical, y = level.set))) {
>>> 
>>> I think it would be better to use something like
>>> 
>>> ll <- lapply(args, levels)
>>> 
>>> !all(sapply(ll, identical, ll[[1L]]))
>>> 
>>> [using union() is not quite right]

TTLAM> Yes definitely. This line is in fact just a relic from a previous idea I
TTLAM> had.
 
> I have now committed the amended proposal (rev 53925);
> thank you for the feedbacks..


>>> The general comment is that if we support this I don't see why we
>>> should
>>> not also support c.ordered (and in fact also c.factor) with the same
>>> restrictions (identical level sequences for ordered and level sets for
>>> factors).  We already have Ops.factor and Ops.ordered using the same
>>> principle afaic.

> Yes, I think, too.

>>> If we add c.ordered, we should be able to encapsulate the identity of
>>> levels testing into this, and simply use
>>> 
>>> x <- c(...)
>>> 
>>> and then call .Generic on the codes of x etc.

TTLAM> Sounds reasonable. Ack.

> Yes, adding c.factor() and c.ordered() seems reasonable in
> principle.
> However, S and R now have a more than 20 year old history of
> silently coercing factors to there integer codes with c(),
> that I'm not yet sure we can do this without breaking too much
> code [[and I am pretty sure this topic has been discusses before]].

Yes, of course.  But then we just made another backwards incompatible
change, and

R> c(ordered(1 : 3), ordered(4 : 6))
[1] 1 2 3 1 2 3

seems more like a bug to me :-)

> I think we should start discussing the issue in a new thread
> with proper Subject explicitly mention "c()" or
> "c.factor"/"c.ordered".

Yes!

Best
-k

> Martin



TTLAM> BR Thorn

TTLAM> ______________________________________________
TTLAM> R-devel at r-project.org mailing list
TTLAM> https://stat.ethz.ch/mailman/listinfo/r-devel


From cooch17 at verizon.net  Fri Jan  7 16:52:58 2011
From: cooch17 at verizon.net (egc)
Date: Fri, 07 Jan 2011 10:52:58 -0500
Subject: [Rd] steps for problems compiling a package
In-Reply-To: <alpine.LFD.2.00.1101071509380.10649@gannet.stats.ox.ac.uk>
References: <4D2633C7.1070707@verizon.net>
	<alpine.LFD.2.00.1101071509380.10649@gannet.stats.ox.ac.uk>
Message-ID: <4D2736DA.2020604@verizon.net>



> 1) For a source package, download it and unpack the tarball.
>
> 2) Read the instructions: you missed the README file, which starts
>
>   The rjags package is an interface to the JAGS library.  In order to
>   build a binary package, or install from source, you must have a
>   matching installation of the JAGS library.

JAGS was/is already installed and functioning on the machine, so that 
wasn't the source of the problem.

>
> You might also be unaware of 
> http://www-fis.iarc.fr/~martyn/software/jags/
>
> 3) If you run
>
> R CMD INSTALL rjags
>
> then config.log will be in the rjags directory.  Which is one reason 
> to download and unpack the tarball: it will be in a temporary 
> directory if run from install.packages() or INSTALL on the tarball.

Thanks - will give that a try. Doing the direct install from CRAN led to 
the problems in the OP.

>
> 4) As for where to ask: see the posting guide!
>

I did, but often there is a substantial grey area defining some overlap 
between various lists. Some of my 'R friends' managed to make completely 
different recommendations as to which list was appropriate for this (and 
similar) question.


From lewin-koh.nicholas at gene.com  Fri Jan  7 17:25:46 2011
From: lewin-koh.nicholas at gene.com (Nicholas Lewin-Koh)
Date: Fri, 7 Jan 2011 08:25:46 -0800
Subject: [Rd] print.citation, small bug?
Message-ID: <AANLkTikWuMGpaVe3V=FYyY=O8B78mZ-N-OeqqsevKO_p@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110107/85a18db0/attachment.pl>

From Kurt.Hornik at wu.ac.at  Sat Jan  8 15:37:44 2011
From: Kurt.Hornik at wu.ac.at (Kurt Hornik)
Date: Sat, 8 Jan 2011 15:37:44 +0100
Subject: [Rd] print.citation, small bug?
In-Reply-To: <AANLkTikWuMGpaVe3V=FYyY=O8B78mZ-N-OeqqsevKO_p@mail.gmail.com>
References: <AANLkTikWuMGpaVe3V=FYyY=O8B78mZ-N-OeqqsevKO_p@mail.gmail.com>
Message-ID: <19752.30392.547095.678117@fangorn.hornik.net>

>>>>> Nicholas Lewin-Koh writes:

Thanks.  Changed in r-devel now.

Best
-k

> Hi,
> I use Sweave extensively in my consulting work. When submitting reports to
> the scientists I work
> with I like to use the citation function to reference any packages I use, to
> give proper acknowledgement.
> I noted in the documentation that a  citation inherits from bibentry, and
> indeed,
>> citr<- citation()
>> class(citr)
> [1] "citation" "bibentry"

> However, following this line I would assume citation should fully inherit
> the methods of bibentry. But that is not the case,
>> print(citr, style="latex")
> still gives style='citation'

>> utils:::print.citation
> function (x, ...)
> {
>     NextMethod("print", x, style = "citation")
>     invisible(x)
> }
> <environment: namespace:utils>

> The citation print style is hard coded. Of course a workaround is,
> class(citr) <- 'bibentry'
> but I think it would be better if print inherited all bibentry methods,
> something like

> print.citation <- function (x, style="citation" ...)
> {
>     NextMethod("print", x, style = style, ...)
>     invisible(x)
> }

> Then the default is still printing a citation, but other print methods are
> available.

> Thanks
> Nicholas

> -- 
> "The bear and the goat were married and lived together until the end of
> their days. Either the goat went mad or the bear became sane."

> Nicholas Lewin-Koh
> Genentech

> 	[[alternative HTML version deleted]]

> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From ripley at stats.ox.ac.uk  Mon Jan 10 13:52:16 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 10 Jan 2011 12:52:16 +0000 (GMT)
Subject: [Rd] Issues from GNU tar >= 1.24
In-Reply-To: <AANLkTi=D27CdQUNKHQmVZ1am_d_gRP5acH1DyTRebrgg@mail.gmail.com>
References: <AANLkTimYhB5ixTEejJftzuuXpEvpJAoOzF2T6vyk3zxy@mail.gmail.com>
	<AANLkTinOnCw8P8=U+SYyLWiegQC_ccB6xpNKCYk8Kv3Z@mail.gmail.com>
	<AANLkTikWCx=qGtoXfgT0mySheb+k03uQvOQYOAdmcu4X@mail.gmail.com>
	<alpine.LFD.2.00.1101061645180.654@gannet.stats.ox.ac.uk>
	<AANLkTi=D27CdQUNKHQmVZ1am_d_gRP5acH1DyTRebrgg@mail.gmail.com>
Message-ID: <alpine.LFD.2.00.1101081055290.14209@gannet.stats.ox.ac.uk>

[Moved from R-help with a new subject line.]

R CMD build used with GNU tar >= 1.24 (which is only a couple of 
months old and so not in widespread use) can create tarballs 
containing hard links if the package sources contain (symbolic or 
hard) links.  RGtk2_2.20.4.tar.gz was such a tarball.

I have added support for hard links in R-devel, so such tarballs will 
be unpacked with hard links (or if that fails file copies).

Hard links are supported on POSIX file systems and on NTFS on Windows. 
So this should work fine (and tests correctly) where such file systems 
are in use -- the main exception would be FAT file systems (which 
because of their OS-portability are widely used for external disks and 
USB drives), and those FAT systems tested[*] seem also to work.

The claim about other tars seems false: the other two commonly used 
tars (bsdtar from libarchive used in Mac OS 10.6 and FreeBSD, and AT&T 
Unix tar) deference symbolic links to ordinary files.

So the current position is:

If you have symbolic links in your package sources and use GNU tar >= 
1.24 and use R CMD build to make the package tarball:

- R < 2.11.0 relies on an external tar program
- 2.11.0 <= R <= 2.12.1 may not unpack the tarball correctly on a
   Unix-alike.
- Somewhat accidentally R <= 2.12.1 should unpack it correctly on
   Windows, expanding hard links to file copies.
- R-patched will unpack the tarball correctly, expanding hard links to
   file copies.
- R-devel will unpack the tarball correctly on file systems which
   support hard links, and on the FAT file systems tested.

It seems the best workarounds are

- Do not have links in your package sources (and that advice has been
    added to 'Writing R Extensions')
- If you encounter a tarball which contains links (which can be hard
   to detect: 'tar tvf' does not necessarily list them as such), try
   setting environment variable R_INSTALL_TAR to the path to a 'tar'
   program that handles such links.

[*] Linux, Mac OS X and Windows reported failures on file.link() and 
fell back to file copies.  However, Mac OS X (and not the others) 
seems to support symbolic links on FAT file systems.

On Thu, 6 Jan 2011, Michael Lawrence wrote:

> 
> 
> On Thu, Jan 6, 2011 at 8:53 AM, Prof Brian Ripley <ripley at stats.ox.ac.uk>
> wrote:
>       You need RGtk2 2.20.7 which is now on CRAN. ?Others have seen
>       this, but it has taken a while to track down the exact cause.
>
>       The diagnosis was that ML used a recent GNU tar which created a
>       tarball with hard links that R's untar was not prepared to deal
>       with. We consider that is a bug in GNU tar, but untar() has been
>       updated in R-patched to cope.
> 
> 
> After a lot of back and forth with the GNU tar guys, it turns out they do
> not consider this to be a bug. I had to refresh my knowledge of hard linking
> to understand. A hard link is from a file name to the actual inode in the
> file system. Typically every file has a single hard link (the name of the
> file). The -h option used to resolve a symbolic link differently, based on
> whether the hard link count of the target was 1 or >=2. This was practically
> useful in my mind, because symlinks to any files without any explicitly
> added hard links would become a regular file in the archive. They have now
> dropped this distinction, calling it an inconsistency (apparently other
> implementations of tar have never made such a distinction). So symlinks now
> become hard links in the archive (as long as the target is in the archive).
> We may need to keep the fix in untar() to handle this. Either way, RGtk2
> 2.20.7 should work now.
> 
> Thanks,
> Michael
> ?
>       If you have such a tarball, try setting the environment variable
>       R_INSTALL_TAR to 'tar' (or whatever GNU tar is called on your
>       system) when installing the tarball.
>
>       For those packaging source packages: in the unusual event that
>       your package sources contains symbolic (or even hard) links,
>       don't use GNU tar 1.24 or 1.25.
>
>       On Thu, 6 Jan 2011, Shige Song wrote:
>
>             Look forward to it.
>
>             Thanks.
>
>             Shige
>
>             On Sat, Jan 1, 2011 at 8:45 AM, Michael Lawrence
>             <lawrence.michael at gene.com> wrote:
>                   Please watch for 2.20.5 and let me know
>                   if it helps. Not really sure what is
>                   going on here, but someone else has
>                   reported the same issue.
>
>                   Thanks,
>                   Michael
>
>                   On Wed, Dec 29, 2010 at 6:44 AM, Shige
>                   Song <shigesong at gmail.com> wrote:
>
>                         Dear All,
>
>                         I am trying to
>                         compile&install the package
>                         "RGtk2" on my Ubuntu 10.04
>                         box. I did not have problem
>                         with earlier versions, but
>                         with the new
>                         version, I got the following
>                         error message :
> 
> 
> ...
> 
> --
> Brian D. Ripley, ? ? ? ? ? ? ? ? ?ripley at stats.ox.ac.uk
> Professor of Applied Statistics, ?http://www.stats.ox.ac.uk/~ripley/
> University of Oxford, ? ? ? ? ? ? Tel: ?+44 1865 272861 (self)
> 1 South Parks Road, ? ? ? ? ? ? ? ? ? ? +44 1865 272866 (PA)
> Oxford OX1 3TG, UK ? ? ? ? ? ? ? ?Fax: ?+44 1865 272595
> 
> 
> 
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From Richard.Cotton at hsl.gov.uk  Mon Jan 10 19:18:33 2011
From: Richard.Cotton at hsl.gov.uk (Richard.Cotton at hsl.gov.uk)
Date: Mon, 10 Jan 2011 18:18:33 +0000
Subject: [Rd] possible bug with log of complex zero
Message-ID: <OFAA17E0DE.60CFE4BD-ON80257814.00643817-80257814.0064A027@hsl.gov.uk>

Notice that 

> log(0i)
[1] -Inf+0i

but

> log(0i, )
[1] -Inf+NaNi

To me, it seems that these should be the same value.  I'll record this on 
the bug tracker if you agree; otherwise please can someone explain why 
this is the case.

Regards,
Richie.

Mathematical Sciences Unit
HSL
4D Pie Charts


------------------------------------------------------------------------
ATTENTION:

This message contains privileged and confidential inform...{{dropped:22}}


From georgi.boshnakov at manchester.ac.uk  Mon Jan 10 22:16:18 2011
From: georgi.boshnakov at manchester.ac.uk (Georgi Boshnakov)
Date: Mon, 10 Jan 2011 21:16:18 +0000
Subject: [Rd] overfilled signature lines in documentation shell for methods
Message-ID: <438D2EC9EAFE5946B2D5864670EA468E023954@MBXP01.ds.man.ac.uk>

The  documentation shells created by the utility functions for classes and methods
contain section "Methods". Due to a  slight difference in the layout and the underlying Rd code,
function signatures are wrapped on the following line (if necessary)  in the "methods" section in a class description (xxx-class.Rd)
but not in xxx.-methods.Rd. As a result long signatures may overfill lines or go off the page. 

For example, some entries for "[<-" are wrapped on two lines in 'Matrix-class.Rd' below and do not overfill the line, while in the second case they do. 

> library(Matrix)
> promptClass("Matrix")
A shell of class documentation has been written to the file
'Matrix-class.Rd'.

> promptMethods("[<-",file="proba.Rd")
A shell of methods documentation has been written to the file
'proba.Rd'. 


The syntax is very similar in both cases and uses \item{}{}, except that in the case of class the first argument is the function name (printed  in bold). The signature is put in the second argument together with the explanation of the method.

 In the "methods" case, the function name is redundant and not included, the signature is put in the first argument, and the explanation in the second. 

The first argument of \item is not justified but the second is, hence the difference.

A simple fix (if needed) for the methods case might be to leave the first argument empty and put everything in the second,
e.g. \item{}{signature(x = "numeric",y = character, ....): this method ...}.


Georgi


--
Dr Georgi Boshnakov               tel: (+44) (0)161 306 3684
School of Mathematics             fax: (+44) (0)161 306 3669
Alan Turing Building 1.125
The University of Manchester      email: Georgi.Boshnakov at manchester.ac.uk
Oxford Road
Manchester M13 9PL
UK



From romain at r-enthusiasts.com  Tue Jan 11 20:33:38 2011
From: romain at r-enthusiasts.com (Romain Francois)
Date: Tue, 11 Jan 2011 20:33:38 +0100
Subject: [Rd] as.environment.list provides inconsistent results under torture
Message-ID: <4D2CB092.6000303@r-enthusiasts.com>

Hello,

Using R-devel (rev 53950), I get inconsistent results with 
as.environment( VECSXP ) when gctorture is on.

Consider:

a <- list( aa = rnorm, bb = runif )
gctorture(TRUE)
as.environment( a )

The last line sometimes produces the correct environment, but sometimes 
I get errors. Here are the three situations:

# good
 > as.environment( a )
<environment: 0x100b1c978>

# not good
 > as.environment( a )
Erreur dans length(x) : 'x' est manquant

# not good either
 > as.environment( a )
Erreur dans list(NULL, list(aa = function (n, mean = 0, sd = 1)  :
   correspondance partielle de cha?nes de caract?res incorrecte


Is it because the call made by lang4 is not protected while evaluated in 
this line :

     case VECSXP: {
	/* implement as.environment.list() {isObject(.) is false for a list} */
	return(eval(lang4(install("list2env"), arg,
			  /*envir = */R_NilValue, /* parent = */R_EmptyEnv),
		    rho));
     }


(BTW, this was detected in a looooooooong Rcpp-devel thread. See 
http://comments.gmane.org/gmane.comp.lang.r.rcpp/1336)

Romain

-- 
Romain Francois
Professional R Enthusiast
+33(0) 6 28 91 30 30
http://romainfrancois.blog.free.fr
|- http://bit.ly/fT2rZM : highlight 0.2-5
|- http://bit.ly/gpCSpH : Evolution of Rcpp code size
`- http://bit.ly/hovakS : RcppGSL initial release


From djsamperi at gmail.com  Tue Jan 11 22:02:35 2011
From: djsamperi at gmail.com (Dominick Samperi)
Date: Tue, 11 Jan 2011 16:02:35 -0500
Subject: [Rd] [Rcpp-devel] Loading a package using Rcpp Modules results
 in memory corruption
In-Reply-To: <4D2CB270.7030107@r-enthusiasts.com>
References: <AANLkTimTL5FYT31VtKyzit62sTwxwSw_ezGZJYYV0fA3@mail.gmail.com>
	<AANLkTikPToku5yXbFycourGD1zEL14F1Fd2AvuY2Q262@mail.gmail.com>
	<19755.12115.728270.935136@max.nulle.part>
	<AANLkTinaL1P7O86S28OWPqfvQdm32c4wawtq3o+-b+sk@mail.gmail.com>
	<19755.15290.37679.774545@max.nulle.part>
	<AANLkTikHFLgtMeuY1jSJfcmEvf_=XwuKJuB1zwAkcsx1@mail.gmail.com>
	<19755.23027.775139.598013@max.nulle.part>
	<AANLkTikA74Sd4eaLddscnmuXOunnJpsKBMb16XHKgP2F@mail.gmail.com>
	<19755.27044.485634.465636@max.nulle.part>
	<AANLkTimdR2nW4ZFXvU45qJveDjhV5nztQ13WDc8oX2LA@mail.gmail.com>
	<19755.29469.617118.664190@max.nulle.part>
	<AANLkTikxfD+FME_kG5Hq-ggP9WkGGL7gEqrc3D_Gz70Z@mail.gmail.com>
	<19755.31830.324676.138847@max.nulle.part>
	<76B7C29D-B31F-43A1-951F-7E3FCB20961C@stat.ubc.ca>
	<4D2C9F6C.4010909@r-enthusiasts.com>
	<AANLkTi=C+mvCsxYOkyxkJ71pB10iq067zHLZriL_Q2=Z@mail.gmail.com>
	<AANLkTimTUgMNpHQwROfN9dM214PrOfVHM0rRWYecunFD@mail.gmail.com>
	<4D2CA80A.5070406@r-enthusiasts.com>
	<4D2CB270.7030107@r-enthusiasts.com>
Message-ID: <AANLkTimOMKfUeMbsOQgXu+ZxvLwXmhqEzBPjp7=t8P2A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110111/855abd76/attachment.pl>

From simon.urbanek at r-project.org  Tue Jan 11 23:15:37 2011
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Tue, 11 Jan 2011 17:15:37 -0500
Subject: [Rd] as.environment.list provides inconsistent results under
	torture
In-Reply-To: <4D2CB092.6000303@r-enthusiasts.com>
References: <4D2CB092.6000303@r-enthusiasts.com>
Message-ID: <792C6196-A236-44AC-B734-E38A09791CB4@r-project.org>

Interesting, I'd argue that the bug is in eval() not protecting its arguments since the usual convention is for functions to protect its arguments...

On Jan 11, 2011, at 2:33 PM, Romain Francois wrote:

> Hello,
> 
> Using R-devel (rev 53950), I get inconsistent results with as.environment( VECSXP ) when gctorture is on.
> 
> Consider:
> 
> a <- list( aa = rnorm, bb = runif )
> gctorture(TRUE)
> as.environment( a )
> 
> The last line sometimes produces the correct environment, but sometimes I get errors. Here are the three situations:
> 
> # good
> > as.environment( a )
> <environment: 0x100b1c978>
> 
> # not good
> > as.environment( a )
> Erreur dans length(x) : 'x' est manquant
> 
> # not good either
> > as.environment( a )
> Erreur dans list(NULL, list(aa = function (n, mean = 0, sd = 1)  :
>  correspondance partielle de cha?nes de caract?res incorrecte
> 
> 
> Is it because the call made by lang4 is not protected while evaluated in this line :
> 
>    case VECSXP: {
> 	/* implement as.environment.list() {isObject(.) is false for a list} */
> 	return(eval(lang4(install("list2env"), arg,
> 			  /*envir = */R_NilValue, /* parent = */R_EmptyEnv),
> 		    rho));
>    }
> 
> 
> (BTW, this was detected in a looooooooong Rcpp-devel thread. See http://comments.gmane.org/gmane.comp.lang.r.rcpp/1336)
> 
> Romain
> 
> -- 
> Romain Francois
> Professional R Enthusiast
> +33(0) 6 28 91 30 30
> http://romainfrancois.blog.free.fr
> |- http://bit.ly/fT2rZM : highlight 0.2-5
> |- http://bit.ly/gpCSpH : Evolution of Rcpp code size
> `- http://bit.ly/hovakS : RcppGSL initial release
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From luke-tierney at uiowa.edu  Wed Jan 12 00:55:52 2011
From: luke-tierney at uiowa.edu (luke-tierney at uiowa.edu)
Date: Tue, 11 Jan 2011 17:55:52 -0600
Subject: [Rd] as.environment.list provides inconsistent results under
 torture
In-Reply-To: <792C6196-A236-44AC-B734-E38A09791CB4@r-project.org>
References: <4D2CB092.6000303@r-enthusiasts.com>
	<792C6196-A236-44AC-B734-E38A09791CB4@r-project.org>
Message-ID: <alpine.DEB.2.00.1101111751380.1812@luke-inspiron>

No. Lots of internal functions expect their callers to protect their
arguments, for efficiency reasons. eval is called very often and
almost always with argument that are protected because they are in the
evaluation engine, so it would be wasteful and potentially very costly
if eval protected its arguments every time it is called. (I don't
tknow what the cost would be to do so in the current implementation
but it could be prohibitive if we moved to some different approaches,
so for now we whould continue to expect callers of eval to make sure
the argumetns are protected.)

Best,

luke

On Tue, 11 Jan 2011, Simon Urbanek wrote:

> Interesting, I'd argue that the bug is in eval() not protecting its arguments since the usual convention is for functions to protect its arguments...
>
> On Jan 11, 2011, at 2:33 PM, Romain Francois wrote:
>
>> Hello,
>>
>> Using R-devel (rev 53950), I get inconsistent results with as.environment( VECSXP ) when gctorture is on.
>>
>> Consider:
>>
>> a <- list( aa = rnorm, bb = runif )
>> gctorture(TRUE)
>> as.environment( a )
>>
>> The last line sometimes produces the correct environment, but sometimes I get errors. Here are the three situations:
>>
>> # good
>>> as.environment( a )
>> <environment: 0x100b1c978>
>>
>> # not good
>>> as.environment( a )
>> Erreur dans length(x) : 'x' est manquant
>>
>> # not good either
>>> as.environment( a )
>> Erreur dans list(NULL, list(aa = function (n, mean = 0, sd = 1)  :
>>  correspondance partielle de cha?nes de caract?res incorrecte
>>
>>
>> Is it because the call made by lang4 is not protected while evaluated in this line :
>>
>>    case VECSXP: {
>> 	/* implement as.environment.list() {isObject(.) is false for a list} */
>> 	return(eval(lang4(install("list2env"), arg,
>> 			  /*envir = */R_NilValue, /* parent = */R_EmptyEnv),
>> 		    rho));
>>    }
>>
>>
>> (BTW, this was detected in a looooooooong Rcpp-devel thread. See http://comments.gmane.org/gmane.comp.lang.r.rcpp/1336)
>>
>> Romain
>>
>> --
>> Romain Francois
>> Professional R Enthusiast
>> +33(0) 6 28 91 30 30
>> http://romainfrancois.blog.free.fr
>> |- http://bit.ly/fT2rZM : highlight 0.2-5
>> |- http://bit.ly/gpCSpH : Evolution of Rcpp code size
>> `- http://bit.ly/hovakS : RcppGSL initial release
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Luke Tierney
Statistics and Actuarial Science
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu

From simon.urbanek at r-project.org  Wed Jan 12 02:45:24 2011
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Tue, 11 Jan 2011 20:45:24 -0500
Subject: [Rd] as.environment.list provides inconsistent results under
	torture
In-Reply-To: <alpine.DEB.2.00.1101111751380.1812@luke-inspiron>
References: <4D2CB092.6000303@r-enthusiasts.com>
	<792C6196-A236-44AC-B734-E38A09791CB4@r-project.org>
	<alpine.DEB.2.00.1101111751380.1812@luke-inspiron>
Message-ID: <21D8CF42-9C05-4EC0-A6CD-0C697C81D69A@r-project.org>


On Jan 11, 2011, at 6:55 PM, <luke-tierney at uiowa.edu> <luke-tierney at uiowa.edu> wrote:

> No. Lots of internal functions expect their callers to protect their arguments, for efficiency reasons. eval is called very often and almost always with argument that are protected because they are in the evaluation engine, so it would be wasteful and potentially very costly if eval protected its arguments every time it is called. (I don't tknow what the cost would be to do so in the current implementation but it could be prohibitive if we moved to some different approaches, so for now we whould continue to expect callers of eval to make sure the argumetns are protected.)
> 


Fair enough. It would be nice if this was explicitly documented since eval() is part of the API and I see several packages on CRAN using eval(LCONS(..),..) and eval(listX(...),...) - and I don't blame them (partly because one of them is mine ;)). Unfortunately all the examples in R-ext use implicitly protected arguments (as function arguments or parts of larger already protected constructs) so it's not obvious from that, either.

Thanks,
Simon




> 
> 
> On Tue, 11 Jan 2011, Simon Urbanek wrote:
> 
>> Interesting, I'd argue that the bug is in eval() not protecting its arguments since the usual convention is for functions to protect its arguments...
>> 
>> On Jan 11, 2011, at 2:33 PM, Romain Francois wrote:
>> 
>>> Hello,
>>> 
>>> Using R-devel (rev 53950), I get inconsistent results with as.environment( VECSXP ) when gctorture is on.
>>> 
>>> Consider:
>>> 
>>> a <- list( aa = rnorm, bb = runif )
>>> gctorture(TRUE)
>>> as.environment( a )
>>> 
>>> The last line sometimes produces the correct environment, but sometimes I get errors. Here are the three situations:
>>> 
>>> # good
>>>> as.environment( a )
>>> <environment: 0x100b1c978>
>>> 
>>> # not good
>>>> as.environment( a )
>>> Erreur dans length(x) : 'x' est manquant
>>> 
>>> # not good either
>>>> as.environment( a )
>>> Erreur dans list(NULL, list(aa = function (n, mean = 0, sd = 1)  :
>>> correspondance partielle de cha?nes de caract?res incorrecte
>>> 
>>> 
>>> Is it because the call made by lang4 is not protected while evaluated in this line :
>>> 
>>>   case VECSXP: {
>>> 	/* implement as.environment.list() {isObject(.) is false for a list} */
>>> 	return(eval(lang4(install("list2env"), arg,
>>> 			  /*envir = */R_NilValue, /* parent = */R_EmptyEnv),
>>> 		    rho));
>>>   }
>>> 
>>> 
>>> (BTW, this was detected in a looooooooong Rcpp-devel thread. See http://comments.gmane.org/gmane.comp.lang.r.rcpp/1336)
>>> 
>>> Romain
>>> 
>>> --
>>> Romain Francois
>>> Professional R Enthusiast
>>> +33(0) 6 28 91 30 30
>>> http://romainfrancois.blog.free.fr
>>> |- http://bit.ly/fT2rZM : highlight 0.2-5
>>> |- http://bit.ly/gpCSpH : Evolution of Rcpp code size
>>> `- http://bit.ly/hovakS : RcppGSL initial release
>>> 
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>> 
>>> 
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> 
> 
> -- 
> Luke Tierney
> Statistics and Actuarial Science
> Ralph E. Wareham Professor of Mathematical Sciences
> University of Iowa                  Phone:             319-335-3386
> Department of Statistics and        Fax:               319-335-3017
>   Actuarial Science
> 241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
> Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From murdoch.duncan at gmail.com  Wed Jan 12 10:33:15 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 12 Jan 2011 04:33:15 -0500
Subject: [Rd] as.environment.list provides inconsistent results under
 torture
In-Reply-To: <alpine.DEB.2.00.1101111751380.1812@luke-inspiron>
References: <4D2CB092.6000303@r-enthusiasts.com>	<792C6196-A236-44AC-B734-E38A09791CB4@r-project.org>
	<alpine.DEB.2.00.1101111751380.1812@luke-inspiron>
Message-ID: <4D2D755B.1080007@gmail.com>

On 11-01-11 6:55 PM, luke-tierney at uiowa.edu wrote:
> No. Lots of internal functions expect their callers to protect their
> arguments, for efficiency reasons. eval is called very often and
> almost always with argument that are protected because they are in the
> evaluation engine, so it would be wasteful and potentially very costly
> if eval protected its arguments every time it is called. (I don't
> tknow what the cost would be to do so in the current implementation
> but it could be prohibitive if we moved to some different approaches,
> so for now we whould continue to expect callers of eval to make sure
> the argumetns are protected.)

Do we have an isProtected() function to use in debugging?  It should 
check if something is in the protection stack or is protected for some 
other reason, so it doesn't look trivial to write.

Duncan Murdoch


>
> Best,
>
> luke
>
> On Tue, 11 Jan 2011, Simon Urbanek wrote:
>
>> Interesting, I'd argue that the bug is in eval() not protecting its arguments since the usual convention is for functions to protect its arguments...
>>
>> On Jan 11, 2011, at 2:33 PM, Romain Francois wrote:
>>
>>> Hello,
>>>
>>> Using R-devel (rev 53950), I get inconsistent results with as.environment( VECSXP ) when gctorture is on.
>>>
>>> Consider:
>>>
>>> a<- list( aa = rnorm, bb = runif )
>>> gctorture(TRUE)
>>> as.environment( a )
>>>
>>> The last line sometimes produces the correct environment, but sometimes I get errors. Here are the three situations:
>>>
>>> # good
>>>> as.environment( a )
>>> <environment: 0x100b1c978>
>>>
>>> # not good
>>>> as.environment( a )
>>> Erreur dans length(x) : 'x' est manquant
>>>
>>> # not good either
>>>> as.environment( a )
>>> Erreur dans list(NULL, list(aa = function (n, mean = 0, sd = 1)  :
>>>   correspondance partielle de cha?nes de caract?res incorrecte
>>>
>>>
>>> Is it because the call made by lang4 is not protected while evaluated in this line :
>>>
>>>     case VECSXP: {
>>> 	/* implement as.environment.list() {isObject(.) is false for a list} */
>>> 	return(eval(lang4(install("list2env"), arg,
>>> 			  /*envir = */R_NilValue, /* parent = */R_EmptyEnv),
>>> 		    rho));
>>>     }
>>>
>>>
>>> (BTW, this was detected in a looooooooong Rcpp-devel thread. See http://comments.gmane.org/gmane.comp.lang.r.rcpp/1336)
>>>
>>> Romain
>>>
>>> --
>>> Romain Francois
>>> Professional R Enthusiast
>>> +33(0) 6 28 91 30 30
>>> http://romainfrancois.blog.free.fr
>>> |- http://bit.ly/fT2rZM : highlight 0.2-5
>>> |- http://bit.ly/gpCSpH : Evolution of Rcpp code size
>>> `- http://bit.ly/hovakS : RcppGSL initial release
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>>
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From luke-tierney at uiowa.edu  Wed Jan 12 14:18:19 2011
From: luke-tierney at uiowa.edu (luke-tierney at uiowa.edu)
Date: Wed, 12 Jan 2011 07:18:19 -0600
Subject: [Rd] as.environment.list provides inconsistent results under
 torture
In-Reply-To: <21D8CF42-9C05-4EC0-A6CD-0C697C81D69A@r-project.org>
References: <4D2CB092.6000303@r-enthusiasts.com>
	<792C6196-A236-44AC-B734-E38A09791CB4@r-project.org>
	<alpine.DEB.2.00.1101111751380.1812@luke-inspiron>
	<21D8CF42-9C05-4EC0-A6CD-0C697C81D69A@r-project.org>
Message-ID: <alpine.DEB.2.00.1101120638320.1812@luke-inspiron>

On Tue, 11 Jan 2011, Simon Urbanek wrote:

>
> On Jan 11, 2011, at 6:55 PM, <luke-tierney at uiowa.edu> <luke-tierney at uiowa.edu> wrote:
>
>> No. Lots of internal functions expect their callers to protect their arguments, for efficiency reasons. eval is called very often and almost always with argument that are protected because they are in the evaluation engine, so it would be wasteful and potentially very costly if eval protected its arguments every time it is called. (I don't tknow what the cost would be to do so in the current implementation but it could be prohibitive if we moved to some different approaches, so for now we whould continue to expect callers of eval to make sure the argumetns are protected.)
>>
>
>
> Fair enough. It would be nice if this was explicitly documented since eval() is part of the API and I see several packages on CRAN using eval(LCONS(..),..) and eval(listX(...),...) - and I don't blame them (partly because one of them is mine ;)).

There are lots of functions in the internals, API or not, that do not
protect their arguments. I would argue that the right way to think
about this is: unless a function is explicitly documented to protect
its arguments you have to assume it either does not now or might not
in the future.

In any case, with functions of more than one SEXP argument, like eval,
protecting the arguments might give inexperienced programmers a false
sense of security: if f, g, and h all allocate and f protects its
arguments they might then be tempted to write

      f(g(), h())

But that would be wrong since one of the values of g() or h() would be
unprotected while the other one is computed and before f() has a
chance to do its protecting (which one is unprotected depends on the
argument evaluation order the C compiler chooses for the expression).

One of the few lower level functions that protects its arguments is
CONS (and some of its cousins like LCONS) both because it is cheap to
do so because of the integration with the GC and because it makes
certain kinds of code a bit more readable. But again if you want to
take advantage of this only one of the arguments can allocate. For
example, in the first case below there is

     LCONS(install("library"),CONS(install("grDevices"),R_NilValue))

Both LCONS and CONS protect their arguments, but one of the two
arguments to LCONS is unprotected while the other is being
computed. (Of course the install calls only allocate if the symbols
are not in the symbol table and even then those allocations are
protected by being put in the symbol table, and as library will be
there once base is loaded this is safe for all practical purposes, but
it would still be better to write it as

     lang2(install("library"), install("grDevices"))

or

      SEXP librarySymbol = install("library");
      SEXP grDevicesSymbol = install("grDevices");
      ...
      lang2(librarySymbol, grDevicesSymbol)

or something like that.)

I suppose we could have more warnings about this sort of thing in the
extensions manual.

I did do a quick scan of R-devel for this issue with eval and found these:

     ./unix/aqua.c:	     eval(LCONS(install("library"),CONS(install("grDevices"),R_NilValue)),R_GlobalEnv);
     ./unix/sys-std.c:    infile = PROTECT(eval(lang1(RComp_getFileCompSym), rcompgen_rho));
     ./modules/X11/dataentry.c:       newval <- eval(parse(text=newval))
     ./main/envir.c:			 return(eval(lang4(install("list2env"), arg,
     ./gnuwin32/dataentry.c:       newval <- eval(parse(text=newval))

I'll fix them in the next couple of days if no one else gets there
first (but I'm not set up to test the aqua or gnuwin32 ones).

Best,

luke

> Unfortunately all the examples in R-ext use implicitly protected arguments (as function arguments or parts of larger already protected constructs) so it's not obvious from that, either.
>
> Thanks,
> Simon
>
>
>
>
>>
>>
>> On Tue, 11 Jan 2011, Simon Urbanek wrote:
>>
>>> Interesting, I'd argue that the bug is in eval() not protecting its arguments since the usual convention is for functions to protect its arguments...
>>>
>>> On Jan 11, 2011, at 2:33 PM, Romain Francois wrote:
>>>
>>>> Hello,
>>>>
>>>> Using R-devel (rev 53950), I get inconsistent results with as.environment( VECSXP ) when gctorture is on.
>>>>
>>>> Consider:
>>>>
>>>> a <- list( aa = rnorm, bb = runif )
>>>> gctorture(TRUE)
>>>> as.environment( a )
>>>>
>>>> The last line sometimes produces the correct environment, but sometimes I get errors. Here are the three situations:
>>>>
>>>> # good
>>>>> as.environment( a )
>>>> <environment: 0x100b1c978>
>>>>
>>>> # not good
>>>>> as.environment( a )
>>>> Erreur dans length(x) : 'x' est manquant
>>>>
>>>> # not good either
>>>>> as.environment( a )
>>>> Erreur dans list(NULL, list(aa = function (n, mean = 0, sd = 1)  :
>>>> correspondance partielle de cha?nes de caract?res incorrecte
>>>>
>>>>
>>>> Is it because the call made by lang4 is not protected while evaluated in this line :
>>>>
>>>>   case VECSXP: {
>>>> 	/* implement as.environment.list() {isObject(.) is false for a list} */
>>>> 	return(eval(lang4(install("list2env"), arg,
>>>> 			  /*envir = */R_NilValue, /* parent = */R_EmptyEnv),
>>>> 		    rho));
>>>>   }
>>>>
>>>>
>>>> (BTW, this was detected in a looooooooong Rcpp-devel thread. See http://comments.gmane.org/gmane.comp.lang.r.rcpp/1336)
>>>>
>>>> Romain
>>>>
>>>> --
>>>> Romain Francois
>>>> Professional R Enthusiast
>>>> +33(0) 6 28 91 30 30
>>>> http://romainfrancois.blog.free.fr
>>>> |- http://bit.ly/fT2rZM : highlight 0.2-5
>>>> |- http://bit.ly/gpCSpH : Evolution of Rcpp code size
>>>> `- http://bit.ly/hovakS : RcppGSL initial release
>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>
>>>>
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>
>> --
>> Luke Tierney
>> Statistics and Actuarial Science
>> Ralph E. Wareham Professor of Mathematical Sciences
>> University of Iowa                  Phone:             319-335-3386
>> Department of Statistics and        Fax:               319-335-3017
>>   Actuarial Science
>> 241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
>> Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu
>
>

-- 
Luke Tierney
Statistics and Actuarial Science
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu

From pdalgd at gmail.com  Wed Jan 12 15:03:48 2011
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 12 Jan 2011 15:03:48 +0100
Subject: [Rd] as.environment.list provides inconsistent results under
	torture
In-Reply-To: <alpine.DEB.2.00.1101120638320.1812@luke-inspiron>
References: <4D2CB092.6000303@r-enthusiasts.com>
	<792C6196-A236-44AC-B734-E38A09791CB4@r-project.org>
	<alpine.DEB.2.00.1101111751380.1812@luke-inspiron>
	<21D8CF42-9C05-4EC0-A6CD-0C697C81D69A@r-project.org>
	<alpine.DEB.2.00.1101120638320.1812@luke-inspiron>
Message-ID: <80481BA7-58C3-4C01-8A1A-C2C65EA38F80@gmail.com>


On Jan 12, 2011, at 14:18 , <luke-tierney at uiowa.edu> <luke-tierney at uiowa.edu> wrote:
> 
> I did do a quick scan of R-devel for this issue with eval and found these:
> 
>    ./unix/aqua.c:	     eval(LCONS(install("library"),CONS(install("grDevices"),R_NilValue)),R_GlobalEnv);
>    ./unix/sys-std.c:    infile = PROTECT(eval(lang1(RComp_getFileCompSym), rcompgen_rho));
>    ./modules/X11/dataentry.c:       newval <- eval(parse(text=newval))
>    ./main/envir.c:			 return(eval(lang4(install("list2env"), arg,
>    ./gnuwin32/dataentry.c:       newval <- eval(parse(text=newval))
> 
> I'll fix them in the next couple of days if no one else gets there
> first (but I'm not set up to test the aqua or gnuwin32 ones).
> 

You had me perplexed there for a while: "<-" assignment in C code??? However, those lines occur inside comments, so at least gnuwin32 is not to worry about.

As you look around those parts, you might also find some superfluous PROTECTs inserted by me some time in the last century while trying to chase down the mysterious crashes that we had. (They eventually turned out to be caused by parser lookahead breaking protection stack discipline, fixed by UNPROTECT_PTR() etc.). I lost track a bit in the frenzy and I never got around to backing out everything. 

-- 
Peter Dalgaard
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From luke-tierney at uiowa.edu  Wed Jan 12 15:45:33 2011
From: luke-tierney at uiowa.edu (luke-tierney at uiowa.edu)
Date: Wed, 12 Jan 2011 08:45:33 -0600
Subject: [Rd] as.environment.list provides inconsistent results under
 torture
In-Reply-To: <80481BA7-58C3-4C01-8A1A-C2C65EA38F80@gmail.com>
References: <4D2CB092.6000303@r-enthusiasts.com>
	<792C6196-A236-44AC-B734-E38A09791CB4@r-project.org>
	<alpine.DEB.2.00.1101111751380.1812@luke-inspiron>
	<21D8CF42-9C05-4EC0-A6CD-0C697C81D69A@r-project.org>
	<alpine.DEB.2.00.1101120638320.1812@luke-inspiron>
	<80481BA7-58C3-4C01-8A1A-C2C65EA38F80@gmail.com>
Message-ID: <alpine.DEB.2.00.1101120843110.1812@luke-inspiron>

On Wed, 12 Jan 2011, peter dalgaard wrote:

>
> On Jan 12, 2011, at 14:18 , <luke-tierney at uiowa.edu> <luke-tierney at uiowa.edu> wrote:
>>
>> I did do a quick scan of R-devel for this issue with eval and found these:
>>
>>    ./unix/aqua.c:	     eval(LCONS(install("library"),CONS(install("grDevices"),R_NilValue)),R_GlobalEnv);
>>    ./unix/sys-std.c:    infile = PROTECT(eval(lang1(RComp_getFileCompSym), rcompgen_rho));
>>    ./modules/X11/dataentry.c:       newval <- eval(parse(text=newval))
>>    ./main/envir.c:			 return(eval(lang4(install("list2env"), arg,
>>    ./gnuwin32/dataentry.c:       newval <- eval(parse(text=newval))
>>
>> I'll fix them in the next couple of days if no one else gets there
>> first (but I'm not set up to test the aqua or gnuwin32 ones).
>>
>
> You had me perplexed there for a while: "<-" assignment in C code??? However, those lines occur inside comments, so at least gnuwin32 is not to worry about.

:-) I guess I would have noticed that when I started trying to fix things ...

>
> As you look around those parts, you might also find some superfluous PROTECTs inserted by me some time in the last century while trying to chase down the mysterious crashes that we had. (They eventually turned out to be caused by parser lookahead breaking protection stack discipline, fixed by UNPROTECT_PTR() etc.). I lost track a bit in the frenzy and I never got around to backing out everything.

I think for now the "if it ain't broke don't fix it" principle applies
to those, unless you have spare time on your hands ...

Best,

luke


-- 
Luke Tierney
Statistics and Actuarial Science
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From proebuck at mdanderson.org  Wed Jan 12 18:23:58 2011
From: proebuck at mdanderson.org (Roebuck,Paul L)
Date: Wed, 12 Jan 2011 11:23:58 -0600
Subject: [Rd] Access R Help Content From R
Message-ID: <C9533FCE.124B9%proebuck@mdanderson.org>

Have UI that simplifies running code from another (internal) package,
allowing user to set values on fields I basically grabbed from results
of calls to formals() for various functions. That works fine for the
most part. But it was requested to investigate some type of popup help
or something for each field.

Since I already wrote the information in the dot-Rd files for what
should be displayed, was wondering if (how) that information could
be accessed. For example, given formal argument 'x' to function 'foo',
I would like to grab the text associated with \item{x} in \arguments{}
section of manual page, preferably without scraping.


From wht_crl at yahoo.com  Wed Jan 12 22:08:13 2011
From: wht_crl at yahoo.com (carol white)
Date: Wed, 12 Jan 2011 13:08:13 -0800 (PST)
Subject: [Rd] problem reported in 00check.log-package not found
In-Reply-To: <4C94B40F.6040708@statistik.tu-dortmund.de>
References: <935784.92453.qm@web62004.mail.re1.yahoo.com>
	<4C94B40F.6040708@statistik.tu-dortmund.de>
Message-ID: <939864.75045.qm@web62005.mail.re1.yahoo.com>

I set 

setenv R_LIBS path_to_local_Rpackages

still I get the error message that a package not found

Warning in library(pkg, character.only = TRUE, logical.return = TRUE, lib.loc = 
lib.loc) :
  there is no package called 'prodlim'
Error : package 'prodlim' could not be loaded
ERROR: lazy loading failed for package ?prodlim?

What can be done?

Carol





From wht_crl at yahoo.com  Thu Jan 13 09:19:12 2011
From: wht_crl at yahoo.com (carol white)
Date: Thu, 13 Jan 2011 00:19:12 -0800 (PST)
Subject: [Rd] Fw:  problem reported in 00check.log-package not found-cont.
In-Reply-To: <4C94B40F.6040708@statistik.tu-dortmund.de>
References: <935784.92453.qm@web62004.mail.re1.yahoo.com>
	<4C94B40F.6040708@statistik.tu-dortmund.de>
Message-ID: <357426.88255.qm@web62004.mail.re1.yahoo.com>

Sorry, forgot to specified that I get this message error when running

R CMD check my_pkg_name



----- Forwarded Message ----
From: carol white <wht_crl at yahoo.com>
To: r-devel at r-project.org
Sent: Wed, January 12, 2011 10:08:13 PM
Subject: [Rd] problem reported in 00check.log-package not found

I set 

setenv R_LIBS path_to_local_Rpackages

still I get the error message that a package not found

Warning in library(pkg, character.only = TRUE, logical.return = TRUE, lib.loc = 
lib.loc) :
  there is no package called 'prodlim'
Error : package 'prodlim' could not be loaded
ERROR: lazy loading failed for package ?prodlim?

What can be done?

Carol




______________________________________________
R-devel at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-devel






From ripley at stats.ox.ac.uk  Thu Jan 13 11:24:47 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 13 Jan 2011 10:24:47 +0000 (GMT)
Subject: [Rd] Fw: problem reported in 00check.log-package not found-cont.
In-Reply-To: <357426.88255.qm@web62004.mail.re1.yahoo.com>
References: <935784.92453.qm@web62004.mail.re1.yahoo.com>
	<4C94B40F.6040708@statistik.tu-dortmund.de>
	<357426.88255.qm@web62004.mail.re1.yahoo.com>
Message-ID: <alpine.LFD.2.00.1101131020050.19028@gannet.stats.ox.ac.uk>

We simply don't have a reproducible example, nor the 'at a minimum' 
information required by the posting guide.

Is prodlim installed?

Is it in the library tree you set as R_LIBS?

Note the following from 'Writing R Extensions':

   Note: R CMD check and R CMD build run R with --vanilla, so none of the
   user's startup files are read. If you need R_LIBS set (to find
   packages in a non-standard library) you can set it in the environment:
   also as from R 2.12.0 you can use files ~/.R/check.Renviron and
   ~/.R/build.Renviron to set environment variables when using these
   utilities.

and we've seen non-reproucible reports that use of ~/.R/check.Renviron 
(rather than setting R_LIBS in the environment) was needed.  So please 
try that.

On Thu, 13 Jan 2011, carol white wrote:

> Sorry, forgot to specified that I get this message error when running
>
> R CMD check my_pkg_name
>
>
>
> ----- Forwarded Message ----
> From: carol white <wht_crl at yahoo.com>
> To: r-devel at r-project.org
> Sent: Wed, January 12, 2011 10:08:13 PM
> Subject: [Rd] problem reported in 00check.log-package not found
>
> I set
>
> setenv R_LIBS path_to_local_Rpackages
>
> still I get the error message that a package not found
>
> Warning in library(pkg, character.only = TRUE, logical.return = TRUE, lib.loc =
> lib.loc) :
>  there is no package called 'prodlim'
> Error : package 'prodlim' could not be loaded
> ERROR: lazy loading failed for package ?prodlim?
>
> What can be done?
>
> Carol
>
>
>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>
>
>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From georgi.boshnakov at manchester.ac.uk  Thu Jan 13 13:51:33 2011
From: georgi.boshnakov at manchester.ac.uk (Georgi Boshnakov)
Date: Thu, 13 Jan 2011 12:51:33 +0000
Subject: [Rd] Access R Help Content From R
Message-ID: <438D2EC9EAFE5946B2D5864670EA468E023E47@MBXP01.ds.man.ac.uk>

I have a small package with some functions for this, it can be downloaded from 

     http://www.maths.manchester.ac.uk/~gb/Rpackages/index.html

There is a nice package (fgui) which provides an easy way to make gui-style functions (using tcl//tk).
It seems that it has not been updated for the new help system, though.
(I am using a modified version of fgui locally but was not able to contact the author).

Georgi

--
Dr Georgi Boshnakov               tel: (+44) (0)161 306 3684
School of Mathematics             fax: (+44) (0)161 306 3669
Alan Turing Building 1.125
The University of Manchester      email: Georgi.Boshnakov at manchester.ac.uk
Oxford Road
Manchester M13 9PL
UK


________________________________________

Message: 4
Date: Wed, 12 Jan 2011 11:23:58 -0600
From: "Roebuck,Paul L" <proebuck at mdanderson.org>
To: R Develop Mailing List <r-devel at r-project.org>
Subject: [Rd] Access R Help Content From R
Message-ID: <C9533FCE.124B9%proebuck at mdanderson.org>
Content-Type: text/plain; charset="us-ascii"

Have UI that simplifies running code from another (internal) package,
allowing user to set values on fields I basically grabbed from results
of calls to formals() for various functions. That works fine for the
most part. But it was requested to investigate some type of popup help
or something for each field.

Since I already wrote the information in the dot-Rd files for what
should be displayed, was wondering if (how) that information could
be accessed. For example, given formal argument 'x' to function 'foo',
I would like to grab the text associated with \item{x} in \arguments{}
section of manual page, preferably without scraping.



------------------------------

Message: 5
Date: Wed, 12 Jan 2011 13:08:13 -0800 (PST)
From: carol white <wht_crl at yahoo.com>
To: r-devel at r-project.org
Subject: [Rd] problem reported in 00check.log-package not found
Message-ID: <939864.75045.qm at web62005.mail.re1.yahoo.com>
Content-Type: text/plain; charset=utf-8

I set

setenv R_LIBS path_to_local_Rpackages

still I get the error message that a package not found

Warning in library(pkg, character.only = TRUE, logical.return = TRUE, lib.loc =
lib.loc) :
  there is no package called 'prodlim'
Error : package 'prodlim' could not be loaded
ERROR: lazy loading failed for package ?prodlim?

What can be done?

Carol






------------------------------

Message: 6
Date: Thu, 13 Jan 2011 00:19:12 -0800 (PST)
From: carol white <wht_crl at yahoo.com>
To: r-devel at r-project.org
Subject: [Rd] Fw:  problem reported in 00check.log-package not
        found-cont.
Message-ID: <357426.88255.qm at web62004.mail.re1.yahoo.com>
Content-Type: text/plain; charset=utf-8

Sorry, forgot to specified that I get this message error when running

R CMD check my_pkg_name



----- Forwarded Message ----
From: carol white <wht_crl at yahoo.com>
To: r-devel at r-project.org
Sent: Wed, January 12, 2011 10:08:13 PM
Subject: [Rd] problem reported in 00check.log-package not found

I set

setenv R_LIBS path_to_local_Rpackages

still I get the error message that a package not found

Warning in library(pkg, character.only = TRUE, logical.return = TRUE, lib.loc =
lib.loc) :
  there is no package called 'prodlim'
Error : package 'prodlim' could not be loaded
ERROR: lazy loading failed for package ?prodlim?

What can be done?

Carol




______________________________________________
R-devel at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-devel







------------------------------

Message: 7
Date: Thu, 13 Jan 2011 10:24:47 +0000 (GMT)
From: Prof Brian Ripley <ripley at stats.ox.ac.uk>
To: carol white <wht_crl at yahoo.com>
Cc: r-devel at r-project.org
Subject: Re: [Rd] Fw: problem reported in 00check.log-package not
        found-cont.
Message-ID:
        <alpine.LFD.2.00.1101131020050.19028 at gannet.stats.ox.ac.uk>
Content-Type: text/plain; charset="utf-8"; Format="flowed"

We simply don't have a reproducible example, nor the 'at a minimum'
information required by the posting guide.

Is prodlim installed?

Is it in the library tree you set as R_LIBS?

Note the following from 'Writing R Extensions':

   Note: R CMD check and R CMD build run R with --vanilla, so none of the
   user's startup files are read. If you need R_LIBS set (to find
   packages in a non-standard library) you can set it in the environment:
   also as from R 2.12.0 you can use files ~/.R/check.Renviron and
   ~/.R/build.Renviron to set environment variables when using these
   utilities.

and we've seen non-reproucible reports that use of ~/.R/check.Renviron
(rather than setting R_LIBS in the environment) was needed.  So please
try that.

On Thu, 13 Jan 2011, carol white wrote:

> Sorry, forgot to specified that I get this message error when running
>
> R CMD check my_pkg_name
>
>
>
> ----- Forwarded Message ----
> From: carol white <wht_crl at yahoo.com>
> To: r-devel at r-project.org
> Sent: Wed, January 12, 2011 10:08:13 PM
> Subject: [Rd] problem reported in 00check.log-package not found
>
> I set
>
> setenv R_LIBS path_to_local_Rpackages
>
> still I get the error message that a package not found
>
> Warning in library(pkg, character.only = TRUE, logical.return = TRUE, lib.loc =
> lib.loc) :
>  there is no package called 'prodlim'
> Error : package 'prodlim' could not be loaded
> ERROR: lazy loading failed for package ?prodlim?
>
> What can be done?
>
> Carol
>
>
>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>
>
>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

--
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

------------------------------

_______________________________________________
R-devel at r-project.org mailing list  DIGESTED
https://stat.ethz.ch/mailman/listinfo/r-devel


End of R-devel Digest, Vol 95, Issue 11
***************************************


From wht_crl at yahoo.com  Thu Jan 13 16:03:10 2011
From: wht_crl at yahoo.com (carol white)
Date: Thu, 13 Jan 2011 07:03:10 -0800 (PST)
Subject: [Rd] Fw: problem reported in 00check.log-package not found-cont.
In-Reply-To: <alpine.LFD.2.00.1101131020050.19028@gannet.stats.ox.ac.uk>
References: <935784.92453.qm@web62004.mail.re1.yahoo.com>
	<4C94B40F.6040708@statistik.tu-dortmund.de>
	<357426.88255.qm@web62004.mail.re1.yahoo.com>
	<alpine.LFD.2.00.1101131020050.19028@gannet.stats.ox.ac.uk>
Message-ID: <458640.20337.qm@web62004.mail.re1.yahoo.com>

Yes, the packages are already installed and their path is given correctly

I have noticed that if I run the R version lower ( < 2.10.0) than the version 
with which the packages were installed (2.10.0) I don't get such error message. 
But if I run the equal or greater version (>= 2.10.0), I get the error message:
 
content of 00check.log file

* install options are ' --no-html'

* installing *source* package ?my_package? ...
** R
** preparing package for lazy loading
Loading required package: splines
Warning in library(pkg, character.only = TRUE, logical.return = TRUE, lib.loc = 
lib.loc) :
  there is no package called 'prodlim'
Error : package 'prodlim' could not be loaded
ERROR: lazy loading failed for package ?my_package?




----- Original Message ----
From: Prof Brian Ripley <ripley at stats.ox.ac.uk>
To: carol white <wht_crl at yahoo.com>
Cc: r-devel at r-project.org
Sent: Thu, January 13, 2011 11:24:47 AM
Subject: Re: [Rd] Fw:  problem reported in 00check.log-package not found-cont.

We simply don't have a reproducible example, nor the 'at a minimum' 
information required by the posting guide.

Is prodlim installed?

Is it in the library tree you set as R_LIBS?

Note the following from 'Writing R Extensions':

   Note: R CMD check and R CMD build run R with --vanilla, so none of the
   user's startup files are read. If you need R_LIBS set (to find
   packages in a non-standard library) you can set it in the environment:
   also as from R 2.12.0 you can use files ~/.R/check.Renviron and
   ~/.R/build.Renviron to set environment variables when using these
   utilities.

and we've seen non-reproucible reports that use of ~/.R/check.Renviron 
(rather than setting R_LIBS in the environment) was needed.  So please 
try that.

On Thu, 13 Jan 2011, carol white wrote:

> Sorry, forgot to specified that I get this message error when running
>
> R CMD check my_pkg_name
>
>
>
> ----- Forwarded Message ----
> From: carol white <wht_crl at yahoo.com>
> To: r-devel at r-project.org
> Sent: Wed, January 12, 2011 10:08:13 PM
> Subject: [Rd] problem reported in 00check.log-package not found
>
> I set
>
> setenv R_LIBS path_to_local_Rpackages
>
> still I get the error message that a package not found
>
> Warning in library(pkg, character.only = TRUE, logical.return = TRUE, lib.loc 
=
> lib.loc) :
>  there is no package called 'prodlim'
> Error : package 'prodlim' could not be loaded
> ERROR: lazy loading failed for package ?prodlim?
>
> What can be done?
>
> Carol
>
>
>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>
>
>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595





From dhinds at sonic.net  Thu Jan 13 20:34:04 2011
From: dhinds at sonic.net (dhinds at sonic.net)
Date: Thu, 13 Jan 2011 19:34:04 +0000 (UTC)
Subject: [Rd] Commenting conventions
Message-ID: <ignk3b$1d9$1@dough.gmane.org>

This might be a dumb question, but I couldn't figure out how to find
the answer: why is it that comments in R documentation files (i.e. in
examples) typically start with a double hash (##) instead of a single
hash?

-- Dave


From eriki at ccbr.umn.edu  Thu Jan 13 21:16:14 2011
From: eriki at ccbr.umn.edu (Erik Iverson)
Date: Thu, 13 Jan 2011 14:16:14 -0600
Subject: [Rd] Commenting conventions
In-Reply-To: <ignk3b$1d9$1@dough.gmane.org>
References: <ignk3b$1d9$1@dough.gmane.org>
Message-ID: <4D2F5D8E.9070005@ccbr.umn.edu>



dhinds at sonic.net wrote:
> This might be a dumb question, but I couldn't figure out how to find
> the answer: why is it that comments in R documentation files (i.e. in
> examples) typically start with a double hash (##) instead of a single
> hash?

See the second paragraph in section 7.5 for the likely answer.

http://ess.r-project.org/Manual/ess.html#Indenting


From hadley at rice.edu  Thu Jan 13 21:46:08 2011
From: hadley at rice.edu (Hadley Wickham)
Date: Thu, 13 Jan 2011 14:46:08 -0600
Subject: [Rd] Access R Help Content From R
In-Reply-To: <C9533FCE.124B9%proebuck@mdanderson.org>
References: <C9533FCE.124B9%proebuck@mdanderson.org>
Message-ID: <AANLkTi=K7esDfCDPxSnxReyoY8tpik+Dtq6pDBEQj4ao@mail.gmail.com>

You might want to take a look at the helpr package,
https://github.com/hadley/helpr, which provides a lot of functions
that do exactly that.  The key idea is to use tools::parse_Rd to parse
the Rd files into R data structures.

Hadley

On Wed, Jan 12, 2011 at 11:23 AM, Roebuck,Paul L
<proebuck at mdanderson.org> wrote:
> Have UI that simplifies running code from another (internal) package,
> allowing user to set values on fields I basically grabbed from results
> of calls to formals() for various functions. That works fine for the
> most part. But it was requested to investigate some type of popup help
> or something for each field.
>
> Since I already wrote the information in the dot-Rd files for what
> should be displayed, was wondering if (how) that information could
> be accessed. For example, given formal argument 'x' to function 'foo',
> I would like to grab the text associated with \item{x} in \arguments{}
> section of manual page, preferably without scraping.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>



-- 
Assistant Professor / Dobelman Family Junior Chair
Department of Statistics / Rice University
http://had.co.nz/


From luke-tierney at uiowa.edu  Thu Jan 13 23:14:18 2011
From: luke-tierney at uiowa.edu (luke-tierney at uiowa.edu)
Date: Thu, 13 Jan 2011 16:14:18 -0600
Subject: [Rd] as.environment.list provides inconsistent results under
 torture
In-Reply-To: <alpine.DEB.2.00.1101120638320.1812@luke-inspiron>
References: <4D2CB092.6000303@r-enthusiasts.com>
	<792C6196-A236-44AC-B734-E38A09791CB4@r-project.org>
	<alpine.DEB.2.00.1101111751380.1812@luke-inspiron>
	<21D8CF42-9C05-4EC0-A6CD-0C697C81D69A@r-project.org>
	<alpine.DEB.2.00.1101120638320.1812@luke-inspiron>
Message-ID: <alpine.DEB.2.00.1101131613530.1812@luke-inspiron>

The fixes are committed as 53967.

luke

On Wed, 12 Jan 2011, luke-tierney at uiowa.edu wrote:

> On Tue, 11 Jan 2011, Simon Urbanek wrote:
>
>> 
>> On Jan 11, 2011, at 6:55 PM, <luke-tierney at uiowa.edu> 
>> <luke-tierney at uiowa.edu> wrote:
>> 
>>> No. Lots of internal functions expect their callers to protect their 
>>> arguments, for efficiency reasons. eval is called very often and almost 
>>> always with argument that are protected because they are in the evaluation 
>>> engine, so it would be wasteful and potentially very costly if eval 
>>> protected its arguments every time it is called. (I don't tknow what the 
>>> cost would be to do so in the current implementation but it could be 
>>> prohibitive if we moved to some different approaches, so for now we whould 
>>> continue to expect callers of eval to make sure the argumetns are 
>>> protected.)
>>> 
>> 
>> 
>> Fair enough. It would be nice if this was explicitly documented since 
>> eval() is part of the API and I see several packages on CRAN using 
>> eval(LCONS(..),..) and eval(listX(...),...) - and I don't blame them 
>> (partly because one of them is mine ;)).
>
> There are lots of functions in the internals, API or not, that do not
> protect their arguments. I would argue that the right way to think
> about this is: unless a function is explicitly documented to protect
> its arguments you have to assume it either does not now or might not
> in the future.
>
> In any case, with functions of more than one SEXP argument, like eval,
> protecting the arguments might give inexperienced programmers a false
> sense of security: if f, g, and h all allocate and f protects its
> arguments they might then be tempted to write
>
>     f(g(), h())
>
> But that would be wrong since one of the values of g() or h() would be
> unprotected while the other one is computed and before f() has a
> chance to do its protecting (which one is unprotected depends on the
> argument evaluation order the C compiler chooses for the expression).
>
> One of the few lower level functions that protects its arguments is
> CONS (and some of its cousins like LCONS) both because it is cheap to
> do so because of the integration with the GC and because it makes
> certain kinds of code a bit more readable. But again if you want to
> take advantage of this only one of the arguments can allocate. For
> example, in the first case below there is
>
>    LCONS(install("library"),CONS(install("grDevices"),R_NilValue))
>
> Both LCONS and CONS protect their arguments, but one of the two
> arguments to LCONS is unprotected while the other is being
> computed. (Of course the install calls only allocate if the symbols
> are not in the symbol table and even then those allocations are
> protected by being put in the symbol table, and as library will be
> there once base is loaded this is safe for all practical purposes, but
> it would still be better to write it as
>
>    lang2(install("library"), install("grDevices"))
>
> or
>
>     SEXP librarySymbol = install("library");
>     SEXP grDevicesSymbol = install("grDevices");
>     ...
>     lang2(librarySymbol, grDevicesSymbol)
>
> or something like that.)
>
> I suppose we could have more warnings about this sort of thing in the
> extensions manual.
>
> I did do a quick scan of R-devel for this issue with eval and found these:
>
>    ./unix/aqua.c: 
> eval(LCONS(install("library"),CONS(install("grDevices"),R_NilValue)),R_GlobalEnv);
>    ./unix/sys-std.c:    infile = PROTECT(eval(lang1(RComp_getFileCompSym), 
> rcompgen_rho));
>    ./modules/X11/dataentry.c:       newval <- eval(parse(text=newval))
>    ./main/envir.c: 
> return(eval(lang4(install("list2env"), arg,
>    ./gnuwin32/dataentry.c:       newval <- eval(parse(text=newval))
>
> I'll fix them in the next couple of days if no one else gets there
> first (but I'm not set up to test the aqua or gnuwin32 ones).
>
> Best,
>
> luke
>
>> Unfortunately all the examples in R-ext use implicitly protected arguments 
>> (as function arguments or parts of larger already protected constructs) so 
>> it's not obvious from that, either.
>> 
>> Thanks,
>> Simon
>> 
>> 
>> 
>> 
>>> 
>>> 
>>> On Tue, 11 Jan 2011, Simon Urbanek wrote:
>>> 
>>>> Interesting, I'd argue that the bug is in eval() not protecting its 
>>>> arguments since the usual convention is for functions to protect its 
>>>> arguments...
>>>> 
>>>> On Jan 11, 2011, at 2:33 PM, Romain Francois wrote:
>>>> 
>>>>> Hello,
>>>>> 
>>>>> Using R-devel (rev 53950), I get inconsistent results with 
>>>>> as.environment( VECSXP ) when gctorture is on.
>>>>> 
>>>>> Consider:
>>>>> 
>>>>> a <- list( aa = rnorm, bb = runif )
>>>>> gctorture(TRUE)
>>>>> as.environment( a )
>>>>> 
>>>>> The last line sometimes produces the correct environment, but sometimes 
>>>>> I get errors. Here are the three situations:
>>>>> 
>>>>> # good
>>>>>> as.environment( a )
>>>>> <environment: 0x100b1c978>
>>>>> 
>>>>> # not good
>>>>>> as.environment( a )
>>>>> Erreur dans length(x) : 'x' est manquant
>>>>> 
>>>>> # not good either
>>>>>> as.environment( a )
>>>>> Erreur dans list(NULL, list(aa = function (n, mean = 0, sd = 1)  :
>>>>> correspondance partielle de cha?nes de caract?res incorrecte
>>>>> 
>>>>> 
>>>>> Is it because the call made by lang4 is not protected while evaluated in 
>>>>> this line :
>>>>>
>>>>>   case VECSXP: {
>>>>> 	/* implement as.environment.list() {isObject(.) is false for a list} 
>>>>> */
>>>>> 	return(eval(lang4(install("list2env"), arg,
>>>>> 			  /*envir = */R_NilValue, /* parent = */R_EmptyEnv),
>>>>> 		    rho));
>>>>>   }
>>>>> 
>>>>> 
>>>>> (BTW, this was detected in a looooooooong Rcpp-devel thread. See 
>>>>> http://comments.gmane.org/gmane.comp.lang.r.rcpp/1336)
>>>>> 
>>>>> Romain
>>>>> 
>>>>> --
>>>>> Romain Francois
>>>>> Professional R Enthusiast
>>>>> +33(0) 6 28 91 30 30
>>>>> http://romainfrancois.blog.free.fr
>>>>> |- http://bit.ly/fT2rZM : highlight 0.2-5
>>>>> |- http://bit.ly/gpCSpH : Evolution of Rcpp code size
>>>>> `- http://bit.ly/hovakS : RcppGSL initial release
>>>>> 
>>>>> ______________________________________________
>>>>> R-devel at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>> 
>>>>> 
>>>> 
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>> 
>>> 
>>> --
>>> Luke Tierney
>>> Statistics and Actuarial Science
>>> Ralph E. Wareham Professor of Mathematical Sciences
>>> University of Iowa                  Phone:             319-335-3386
>>> Department of Statistics and        Fax:               319-335-3017
>>>   Actuarial Science
>>> 241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
>>> Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu
>> 
>> 
>
>

-- 
Luke Tierney
Statistics and Actuarial Science
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu

From wdunlap at tibco.com  Fri Jan 14 02:14:05 2011
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 13 Jan 2011 17:14:05 -0800
Subject: [Rd] why is class externalptr considered recursive?
Message-ID: <77EB52C6DD32BA4D87471DCD70C8D70003CDFEE4@NA-PA-VBE03.na.tibco.com>

I have a function to search through R code
and look for certain language constructs.
It uses the idiom
    if (is.recursive(object)) {
        object <- as.list(object)
        for(element in object) {
            Recall(element) # recurse further into object
        }
    }
and I was surprised that this fails in as.list
on objects of class "externalptr" because they
are considered recursive but cannot be turned
into lists (nor are they subsettable). 
  > p <- stats:::R_smart[[2]]
  > str(p)
  <externalptr> 
  > class(p)
  [1] "externalptr"
  > is.recursive(p)
  [1] TRUE
  > length(p)
  [1] 1
  > as.list(p)
  Error in as.vector(x, "list") : 
    cannot coerce type 'externalptr' to vector of type 'list'
  > p[[1]]
  Error in p[[1]] : object of type 'externalptr' is not subsettable

I can work around the issue but was wondering what the
rationale for this was.

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com 


From oyvfos at yahoo.no  Fri Jan 14 09:09:51 2011
From: oyvfos at yahoo.no (oyvfos)
Date: Fri, 14 Jan 2011 00:09:51 -0800 (PST)
Subject: [Rd] matrix multiplication speed R
Message-ID: <1294992591724-3217257.post@n4.nabble.com>


Hi,
A quick bench-mark of an R matrix muliplication 500by500 X 500by10000, all
random variates, with matlab reveals a huge difference in speed (5 times at
least). Is there anything that can be done in R to speed up the
multiplication?
Kind regards,  Oyvind
-- 
View this message in context: http://r.789695.n4.nabble.com/matrix-multiplication-speed-R-tp3217257p3217257.html
Sent from the R devel mailing list archive at Nabble.com.


From jorismeys at gmail.com  Fri Jan 14 11:38:20 2011
From: jorismeys at gmail.com (Joris Meys)
Date: Fri, 14 Jan 2011 11:38:20 +0100
Subject: [Rd] matrix multiplication speed R
In-Reply-To: <1294992591724-3217257.post@n4.nabble.com>
References: <1294992591724-3217257.post@n4.nabble.com>
Message-ID: <AANLkTinaCO61x_fWzqFFawWrnBN+LZ_APLpsaBZYAw-j@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110114/58283ce7/attachment.pl>

From ligges at statistik.tu-dortmund.de  Fri Jan 14 12:04:47 2011
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Fri, 14 Jan 2011 12:04:47 +0100
Subject: [Rd] matrix multiplication speed R
In-Reply-To: <AANLkTinaCO61x_fWzqFFawWrnBN+LZ_APLpsaBZYAw-j@mail.gmail.com>
References: <1294992591724-3217257.post@n4.nabble.com>
	<AANLkTinaCO61x_fWzqFFawWrnBN+LZ_APLpsaBZYAw-j@mail.gmail.com>
Message-ID: <4D302DCF.1020003@statistik.tu-dortmund.de>



On 14.01.2011 11:38, Joris Meys wrote:
> Please give the code you used for the matrix multiplication. 5 times is a
> bit much.

No, it is reasonable for matrix multiplication:

Matlab ships with optimized BLAS for various CPU types. In R, you have 
to get an optimized BLAS yourself.

How to link against optimized BLAS versions or how to substitute the 
BLAS is mentioned in the R INstallation and Administration manual.

Best,
Uwe Ligges



>
> On Fri, Jan 14, 2011 at 9:09 AM, oyvfos<oyvfos at yahoo.no>  wrote:
>
>>
>> Hi,
>> A quick bench-mark of an R matrix muliplication 500by500 X 500by10000, all
>> random variates, with matlab reveals a huge difference in speed (5 times at
>> least). Is there anything that can be done in R to speed up the
>> multiplication?
>> Kind regards,  Oyvind
>> --
>> View this message in context:
>> http://r.789695.n4.nabble.com/matrix-multiplication-speed-R-tp3217257p3217257.html
>> Sent from the R devel mailing list archive at Nabble.com.
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
>
>


From s.wood at bath.ac.uk  Fri Jan 14 15:52:09 2011
From: s.wood at bath.ac.uk (Simon Wood)
Date: Fri, 14 Jan 2011 14:52:09 +0000
Subject: [Rd] naresid.exclude query
Message-ID: <201101141452.09977.s.wood@bath.ac.uk>

  x <- NA
  na.act <- na.action(na.exclude(x))
  y <- rep(0,0)
  naresid(na.act,y)

... currently produces the result...
  numeric(0)

... whereas the documentation might lead you to expect
  NA

The behaviour is caused by the line 
  if (length(x) == 0L) return(x)

in `stats:::naresid.exclude'. Removing this line results in the behaviour I'd 
expected in the above example (and in a test example where `x' is a zero row 
matrix). 

Is the coded behaviour necessary for some reason? Could it be changed (so that 
my example produces NA)? The reason I ask is that I use `napredict' in 
mgcv:predict.gam, and someone complained that if he predicts using newdata 
that is all NA, then he doesn't get what he expected (he has a pretty good 
reason for doing this). Part of the problem with predict.gam in this case was 
my code, but once I fixed that I ran up against the above problem.  

Actually, I just checked the source code and the line of naresid.exclude that 
causes the problem already has this comment after it....
  # << FIXME? -- reconstructing all NA object
... so I guess I'm really asking if there is any chance of fixing this soon, 
or whether I should just code up a work-around for predict.gam?

Simon

-- 
> Simon Wood, Mathematical Sciences, University of Bath, Bath, BA2 7AY UK
> +44 1225 386603  www.maths.bath.ac.uk/~sw283


From oyvfos at yahoo.no  Fri Jan 14 13:15:21 2011
From: oyvfos at yahoo.no (oyvfos)
Date: Fri, 14 Jan 2011 04:15:21 -0800 (PST)
Subject: [Rd] matrix multiplication speed R
In-Reply-To: <4D302DCF.1020003@statistik.tu-dortmund.de>
References: <1294992591724-3217257.post@n4.nabble.com>
	<AANLkTinaCO61x_fWzqFFawWrnBN+LZ_APLpsaBZYAw-j@mail.gmail.com>
	<4D302DCF.1020003@statistik.tu-dortmund.de>
Message-ID: <1295007321497-3217539.post@n4.nabble.com>


Thanks very much, Uwe. The calculation time is now comparable with matlab.
Oyvind
-- 
View this message in context: http://r.789695.n4.nabble.com/matrix-multiplication-speed-R-tp3217257p3217539.html
Sent from the R devel mailing list archive at Nabble.com.


From helixed2 at yahoo.com  Fri Jan 14 19:12:55 2011
From: helixed2 at yahoo.com (Jeremy Koster)
Date: Fri, 14 Jan 2011 10:12:55 -0800 (PST)
Subject: [Rd] How to point R toward Ghostscript on a Windows XP system
Message-ID: <249211.68732.qm@web161805.mail.bf1.yahoo.com>

A colleague designed a script for a bar plot, which I'd like to export to my directory via the barplot command:

bitmap(file="barplot.tif", type="tifflzw", height=4, width=6.5, res=1250)

Unfortunately, this command produces the following error message: 

Error in system(paste(gsexe, "-help"), intern = TRUE, invisible = TRUE) : 
  'gswin32c.exe' not found

>From consulting the archives and the help file, I deduced that I needed to install Ghostscript, which I did.  Subsequent messages in the archives suggest directing R toward Ghostscript using an environmental variable, specifically R_GSCMD.

Unfortunately, I haven't figured out how to use this command.  Can anyone provide assistance?

This is for R version 2.12.0 using Windows XP on a Dell laptop.  The path for ghostscript in my program files folder is:
C:\Program Files\gs

Many thanks,
Jeremy
UC Anthropology


From dhinds at sonic.net  Fri Jan 14 19:53:12 2011
From: dhinds at sonic.net (dhinds at sonic.net)
Date: Fri, 14 Jan 2011 18:53:12 +0000 (UTC)
Subject: [Rd] Commenting conventions
References: <ignk3b$1d9$1@dough.gmane.org> <4D2F5D8E.9070005@ccbr.umn.edu>
Message-ID: <igq62o$vmq$1@dough.gmane.org>

Erik Iverson <eriki at ccbr.umn.edu> wrote:

> dhinds at sonic.net wrote:
> > This might be a dumb question, but I couldn't figure out how to find
> > the answer: why is it that comments in R documentation files (i.e. in
> > examples) typically start with a double hash (##) instead of a single
> > hash?

> See the second paragraph in section 7.5 for the likely answer.

> http://ess.r-project.org/Manual/ess.html#Indenting

Ahh.  I'd forgotten the (setq ess-fancy-comments nil) in my .emacs
file!  I thought the explanation would turn up in an R coding
standards document and/or in Writing R Documentation Files, and it
isn't an easy thing to google.

-- Dave


From ripley at stats.ox.ac.uk  Sat Jan 15 08:59:24 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 15 Jan 2011 07:59:24 +0000 (GMT)
Subject: [Rd] How to point R toward Ghostscript on a Windows XP system
In-Reply-To: <249211.68732.qm@web161805.mail.bf1.yahoo.com>
References: <249211.68732.qm@web161805.mail.bf1.yahoo.com>
Message-ID: <alpine.LFD.2.00.1101150749170.3738@gannet.stats.ox.ac.uk>

On Fri, 14 Jan 2011, Jeremy Koster wrote:

> A colleague designed a script for a bar plot, which I'd like to 
> export to my directory via the barplot command:
>
> bitmap(file="barplot.tif", type="tifflzw", height=4, width=6.5, res=1250)
>
> Unfortunately, this command produces the following error message:
>
> Error in system(paste(gsexe, "-help"), intern = TRUE, invisible = TRUE) :
>  'gswin32c.exe' not found
>
>> From consulting the archives and the help file, I deduced that I 
>> needed to install Ghostscript, which I did.  Subsequent messages in 
>> the archives suggest directing R toward Ghostscript using an 
>> environmental variable, specifically R_GSCMD.

Please do read the help page.  You didn't tell us if you added 
Ghostscript to your path: if you had done so this would not be needed 
(as the help page says).

> Unfortunately, I haven't figured out how to use this command.  Can 
> anyone provide assistance?

Sys.setenv(GS_CMD="C:/Program Files/gs/gswin32c.exe")
if what you say below is correct, but
Sys.setenv(GS_CMD="C:/Program Files/gs/bin/gswin32c.exe")
would be more standard for recent versions of Ghostscript.

> This is for R version 2.12.0 using Windows XP on a Dell laptop.

OK, but next time please consult the posting guide and give us the 
'at a minimum' information asked for there (we need to know if this is 
32- or 64-bit Windows on a 32- or 64-bit OS -- and although rare, 
64-bit Windows XP does exist).

> The path for ghostscript in my program files folder is: C:\Program 
> Files\gs
>
> Many thanks,
> Jeremy
> UC Anthropology

BTW, asking how to set environment variables is covered in the rw-FAQ 
and is not an R-devel topic.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From guxiaobo1982 at gmail.com  Sat Jan 15 03:34:55 2011
From: guxiaobo1982 at gmail.com (Xiaobo Gu)
Date: Sat, 15 Jan 2011 10:34:55 +0800
Subject: [Rd] RPostgreSQL 0.1.7 for Windows 64 causes R.2.12.1 Win64 crash
Message-ID: <AANLkTinvoub-z_Le1GVPYswnqTsW1P6MZzLZsztois9K@mail.gmail.com>

Hi,
I build the binary package file of RPostgreSQL 0.1.7 for Windows 2003
Server R2 64 bit SP2, the software environments are as following:
         R 2.12.1 for Win64
         RTools212 for Win64
         DBI 0.2.5
         RPostgreSQL 0.1.7
         Postgresql related binaries shipped with
postgresql-9.0.2-1-windows_x64.exe from EnterpriseDB

The package can be loaded, and driver can be created, but the
dbConnect function causes the whole RGui crashes,

driver <- dbDriver("PostgreSQL")
con <- dbConnect(driver, dbname="demo", host="192.168.8.1",
user="postgres", password="postgres", port=5432)


From guxiaobo1982 at gmail.com  Sun Jan 16 16:00:41 2011
From: guxiaobo1982 at gmail.com (Xiaobo Gu)
Date: Sun, 16 Jan 2011 23:00:41 +0800
Subject: [Rd] RPostgreSQL 0.1.7 for Windows 64 causes R.2.12.1 Win64
	crash
In-Reply-To: <AANLkTinvoub-z_Le1GVPYswnqTsW1P6MZzLZsztois9K@mail.gmail.com>
References: <AANLkTinvoub-z_Le1GVPYswnqTsW1P6MZzLZsztois9K@mail.gmail.com>
Message-ID: <AANLkTimfKn+qAMP8q2W8nJFvxVdoOM8gYYWZtZU_Jk9w@mail.gmail.com>

Is it because of compiler campsites between R and PostgreSQL, R is
compiled by GCC, while PostgreSQL from Enterprise DB is compiled by
Microsoft Visual C ++.

Xiaobo Gu

On Sat, Jan 15, 2011 at 10:34 AM, Xiaobo Gu <guxiaobo1982 at gmail.com> wrote:
> Hi,
> I build the binary package file of RPostgreSQL 0.1.7 for Windows 2003
> Server R2 64 bit SP2, the software environments are as following:
> ? ? ? ? R 2.12.1 for Win64
> ? ? ? ? RTools212 for Win64
> ? ? ? ? DBI 0.2.5
> ? ? ? ? RPostgreSQL 0.1.7
> ? ? ? ? Postgresql related binaries shipped with
> postgresql-9.0.2-1-windows_x64.exe from EnterpriseDB
>
> The package can be loaded, and driver can be created, but the
> dbConnect function causes the whole RGui crashes,
>
> driver <- dbDriver("PostgreSQL")
> con <- dbConnect(driver, dbname="demo", host="192.168.8.1",
> user="postgres", password="postgres", port=5432)
>


From Simon.Wotherspoon at utas.edu.au  Mon Jan 17 04:41:22 2011
From: Simon.Wotherspoon at utas.edu.au (Simon Wotherspoon)
Date: Mon, 17 Jan 2011 14:41:22 +1100
Subject: [Rd] isoreg memory leak?
Message-ID: <4D33BA62.7010902@utas.edu.au>


I believe there is a memory leak in isoreg in the current version of R, 
as I believe the following shows

 > gc()
          used (Mb) gc trigger (Mb) max used (Mb)
Ncells 120405  3.3     350000  9.4   350000  9.4
Vcells  78639  0.6     786432  6.0   392463  3.0
 > for(k in 1:100) {
+
+   y <- runif(10000)
+   isoreg(x,y)
+ }
 > rm(x)
 > rm(y)
 > gc()
          used (Mb) gc trigger (Mb) max used (Mb)
Ncells 121637  3.3     350000  9.4   350000  9.4
Vcells 578615  4.5    1300721 10.0  1300642 10.0
                ^^^


Looking at the C code, I believe the problem arises as a consequence of 
using SETLENGTH to resize the result near the very end of isoreg.c,
and the solution is to make a copy of iKnots.


SEXP R_isoreg(SEXP y)
{
     int n = LENGTH(y), i, ip, known, n_ip;
     double tmp, slope;
     SEXP yc, yf, iKnots, ans;
     const char *anms[] = {"y", "yc", "yf", "iKnots", ""};

     /* unneeded: y = coerceVector(y, REALSXP); */

     PROTECT(ans = mkNamed(VECSXP, anms));

     SET_VECTOR_ELT(ans, 0, y = y);
     SET_VECTOR_ELT(ans, 1, yc = allocVector(REALSXP, n+1));
     SET_VECTOR_ELT(ans, 2, yf = allocVector(REALSXP, n));
     SET_VECTOR_ELT(ans, 3, iKnots= allocVector(INTSXP, n));

... calculation ...

     SETLENGTH(iKnots, n_ip);
     UNPROTECT(1);
     return(ans);
}


But if this is the problem, I am at a bit of a loss as to what SETLENGTH 
is actually for in general.

Clearly my understanding of how allocation/gc works is a bit off here, 
but I can't see how else the leak may occur.  Hope this is more use than 
nuisance.

Simon.


From edd at debian.org  Mon Jan 17 15:10:57 2011
From: edd at debian.org (Dirk Eddelbuettel)
Date: Mon, 17 Jan 2011 08:10:57 -0600
Subject: [Rd] RPostgreSQL 0.1.7 for Windows 64 causes R.2.12.1
	Win64	crash
In-Reply-To: <AANLkTimfKn+qAMP8q2W8nJFvxVdoOM8gYYWZtZU_Jk9w@mail.gmail.com>
References: <AANLkTinvoub-z_Le1GVPYswnqTsW1P6MZzLZsztois9K@mail.gmail.com>
	<AANLkTimfKn+qAMP8q2W8nJFvxVdoOM8gYYWZtZU_Jk9w@mail.gmail.com>
Message-ID: <19764.19953.237115.864920@max.nulle.part>


On 16 January 2011 at 23:00, Xiaobo Gu wrote:
| Is it because of compiler campsites between R and PostgreSQL, R is
| compiled by GCC, while PostgreSQL from Enterprise DB is compiled by
| Microsoft Visual C ++.

So the usual recommendation is to build the matching library (here libpq)
with the same compiler, or get the commercial support you are paying for to
do it for you.  

For what it is worth, I deal with one vendor at work where I made that
requirement and they had no issue complying / helping me with a MinGW /
Rtools-compatible library.  One of several reasons I like working with that
vendor.

Dirk
 
| Xiaobo Gu
| 
| On Sat, Jan 15, 2011 at 10:34 AM, Xiaobo Gu <guxiaobo1982 at gmail.com> wrote:
| > Hi,
| > I build the binary package file of RPostgreSQL 0.1.7 for Windows 2003
| > Server R2 64 bit SP2, the software environments are as following:
| > ? ? ? ? R 2.12.1 for Win64
| > ? ? ? ? RTools212 for Win64
| > ? ? ? ? DBI 0.2.5
| > ? ? ? ? RPostgreSQL 0.1.7
| > ? ? ? ? Postgresql related binaries shipped with
| > postgresql-9.0.2-1-windows_x64.exe from EnterpriseDB
| >
| > The package can be loaded, and driver can be created, but the
| > dbConnect function causes the whole RGui crashes,
| >
| > driver <- dbDriver("PostgreSQL")
| > con <- dbConnect(driver, dbname="demo", host="192.168.8.1",
| > user="postgres", password="postgres", port=5432)
| >
| 
| ______________________________________________
| R-devel at r-project.org mailing list
| https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com


From simon.urbanek at r-project.org  Mon Jan 17 16:22:07 2011
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Mon, 17 Jan 2011 10:22:07 -0500
Subject: [Rd] isoreg memory leak?
In-Reply-To: <4D33BA62.7010902@utas.edu.au>
References: <4D33BA62.7010902@utas.edu.au>
Message-ID: <334171D4-0548-49D5-A4B9-ECEE6D8D4C03@r-project.org>


On Jan 16, 2011, at 10:41 PM, Simon Wotherspoon wrote:

> 
> I believe there is a memory leak in isoreg in the current version of R, as I believe the following shows
> 
> > gc()
>         used (Mb) gc trigger (Mb) max used (Mb)
> Ncells 120405  3.3     350000  9.4   350000  9.4
> Vcells  78639  0.6     786432  6.0   392463  3.0
> > for(k in 1:100) {
> +
> +   y <- runif(10000)
> +   isoreg(x,y)
> + }
> > rm(x)
> > rm(y)
> > gc()
>         used (Mb) gc trigger (Mb) max used (Mb)
> Ncells 121637  3.3     350000  9.4   350000  9.4
> Vcells 578615  4.5    1300721 10.0  1300642 10.0
>               ^^^
> 
> 
> Looking at the C code, I believe the problem arises as a consequence of using SETLENGTH to resize the result near the very end of isoreg.c,
> and the solution is to make a copy of iKnots.
> 

AFAICS this is more of a reporting issue than a memory leak - ReleaseLargeFreeVectors() uses LENGTH() to determine the number by which to reduce R_LargeVallocSize - and it will be smaller than the actually released memory if SETLENGTH was used. I'm not sure how to fix it, because AFAICS the real size is not recorded anywhere (unless we use truelength for that but I'm not sure I know the implications). The good news is that it's not really a memory leak - the bad news is that the memory usage stats are rather an upper bound of the reality ;).

Cheers,
Simon



> 
> SEXP R_isoreg(SEXP y)
> {
>    int n = LENGTH(y), i, ip, known, n_ip;
>    double tmp, slope;
>    SEXP yc, yf, iKnots, ans;
>    const char *anms[] = {"y", "yc", "yf", "iKnots", ""};
> 
>    /* unneeded: y = coerceVector(y, REALSXP); */
> 
>    PROTECT(ans = mkNamed(VECSXP, anms));
> 
>    SET_VECTOR_ELT(ans, 0, y = y);
>    SET_VECTOR_ELT(ans, 1, yc = allocVector(REALSXP, n+1));
>    SET_VECTOR_ELT(ans, 2, yf = allocVector(REALSXP, n));
>    SET_VECTOR_ELT(ans, 3, iKnots= allocVector(INTSXP, n));
> 
> ... calculation ...
> 
>    SETLENGTH(iKnots, n_ip);
>    UNPROTECT(1);
>    return(ans);
> }
> 
> 
> But if this is the problem, I am at a bit of a loss as to what SETLENGTH is actually for in general.
> 
> Clearly my understanding of how allocation/gc works is a bit off here, but I can't see how else the leak may occur.  Hope this is more use than nuisance.
> 
> Simon.
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From ngkbr8es at gmail.com  Mon Jan 17 18:13:36 2011
From: ngkbr8es at gmail.com (Patrick Leyshock)
Date: Mon, 17 Jan 2011 09:13:36 -0800
Subject: [Rd] R vs. C
Message-ID: <AANLkTikbHjP7JvwfWjSaWds7fa4Ek=8LEo14h-Rm5igq@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110117/be037da8/attachment.pl>

From ripley at stats.ox.ac.uk  Mon Jan 17 18:22:01 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 17 Jan 2011 17:22:01 +0000 (GMT)
Subject: [Rd] RPostgreSQL 0.1.7 for Windows 64 causes R.2.12.1 Win64
 crash
In-Reply-To: <19764.19953.237115.864920@max.nulle.part>
References: <AANLkTinvoub-z_Le1GVPYswnqTsW1P6MZzLZsztois9K@mail.gmail.com>
	<AANLkTimfKn+qAMP8q2W8nJFvxVdoOM8gYYWZtZU_Jk9w@mail.gmail.com>
	<19764.19953.237115.864920@max.nulle.part>
Message-ID: <alpine.LFD.2.00.1101171711170.2906@toucan.stats.ox.ac.uk>

On Mon, 17 Jan 2011, Dirk Eddelbuettel wrote:

>
> On 16 January 2011 at 23:00, Xiaobo Gu wrote:
> | Is it because of compiler campsites between R and PostgreSQL, R is
> | compiled by GCC, while PostgreSQL from Enterprise DB is compiled by
> | Microsoft Visual C ++.
>
> So the usual recommendation is to build the matching library (here libpq)
> with the same compiler, or get the commercial support you are paying for to
> do it for you.
>
> For what it is worth, I deal with one vendor at work where I made that
> requirement and they had no issue complying / helping me with a MinGW /
> Rtools-compatible library.  One of several reasons I like working with that
> vendor.

And also for what it is worth, RPostgreSQL works for me on x64 Windows 
7 compiled with the Rtools compilers and linked against the initial 
PostgreSQL 9.0 Windows x64 distribution (I've not tried the one you 
mentioned).

Where C (and not C++) is involved it should be possible to mix DLLs 
compiled by MinGW-w64 and MSVC, and this has been done extensively 
(after all a lot of Windows' own DLLs are compiled with MSVC, as are 
the Tcl/Tk binaries which are distributed with R).

>
> Dirk
>
> | Xiaobo Gu
> |
> | On Sat, Jan 15, 2011 at 10:34 AM, Xiaobo Gu <guxiaobo1982 at gmail.com> wrote:
> | > Hi,
> | > I build the binary package file of RPostgreSQL 0.1.7 for Windows 2003
> | > Server R2 64 bit SP2, the software environments are as following:
> | > ? ? ? ? R 2.12.1 for Win64
> | > ? ? ? ? RTools212 for Win64
> | > ? ? ? ? DBI 0.2.5
> | > ? ? ? ? RPostgreSQL 0.1.7
> | > ? ? ? ? Postgresql related binaries shipped with
> | > postgresql-9.0.2-1-windows_x64.exe from EnterpriseDB
> | >
> | > The package can be loaded, and driver can be created, but the
> | > dbConnect function causes the whole RGui crashes,
> | >
> | > driver <- dbDriver("PostgreSQL")
> | > con <- dbConnect(driver, dbname="demo", host="192.168.8.1",
> | > user="postgres", password="postgres", port=5432)
> | >
> |
> | ______________________________________________
> | R-devel at r-project.org mailing list
> | https://stat.ethz.ch/mailman/listinfo/r-devel
>
> -- 
> Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From pburns at pburns.seanet.com  Mon Jan 17 18:41:45 2011
From: pburns at pburns.seanet.com (Patrick Burns)
Date: Mon, 17 Jan 2011 17:41:45 +0000
Subject: [Rd] R vs. C
In-Reply-To: <AANLkTikbHjP7JvwfWjSaWds7fa4Ek=8LEo14h-Rm5igq@mail.gmail.com>
References: <AANLkTikbHjP7JvwfWjSaWds7fa4Ek=8LEo14h-Rm5igq@mail.gmail.com>
Message-ID: <4D347F59.5060100@pburns.seanet.com>

Everyone has their own utility
function.  Mine is if the boredom
of waiting for the pure R function
to finish is going to out-weight the
boredom of writing the C code.

Another issue is that adding C code
increases the hassle of users who might
want the code to run on different
architectures.

On 17/01/2011 17:13, Patrick Leyshock wrote:
> A question, please about development of R packages:
>
> Are there any guidelines or best practices for deciding when and why to
> implement an operation in R, vs. implementing it in C?  The "Writing R
> Extensions" recommends "working in interpreted R code . . . this is normally
> the best option."  But we do write C-functions and access them in R - the
> question is, when/why is this justified, and when/why is it NOT justified?
>
> While I have identified helpful documents on R coding standards, I have not
> seen notes/discussions on when/why to implement in R, vs. when to implement
> in C.
>
> Thanks, Patrick
>
> On Sun, Jan 16, 2011 at 3:00 AM,<r-devel-request at r-project.org>  wrote:
>
>> Send R-devel mailing list submissions to
>>         r-devel at r-project.org
>>
>> To subscribe or unsubscribe via the World Wide Web, visit
>>         https://stat.ethz.ch/mailman/listinfo/r-devel
>> or, via email, send a message with subject or body 'help' to
>>         r-devel-request at r-project.org
>>
>> You can reach the person managing the list at
>>         r-devel-owner at r-project.org
>>
>> When replying, please edit your Subject line so it is more specific
>> than "Re: Contents of R-devel digest..."
>>
>>
>> Today's Topics:
>>
>>    1. RPostgreSQL 0.1.7 for Windows 64 causes R.2.12.1 Win64 crash
>>       (Xiaobo Gu)
>>
>>
>> ----------------------------------------------------------------------
>>
>> Message: 1
>> Date: Sat, 15 Jan 2011 10:34:55 +0800
>> From: Xiaobo Gu<guxiaobo1982 at gmail.com>
>> To: r-devel at r-project.org
>> Subject: [Rd] RPostgreSQL 0.1.7 for Windows 64 causes R.2.12.1 Win64
>>         crash
>> Message-ID:
>>         <AANLkTinvoub-z_Le1GVPYswnqTsW1P6MZzLZsztois9K at mail.gmail.com>
>> Content-Type: text/plain; charset=ISO-8859-1
>>
>> Hi,
>> I build the binary package file of RPostgreSQL 0.1.7 for Windows 2003
>> Server R2 64 bit SP2, the software environments are as following:
>>          R 2.12.1 for Win64
>>          RTools212 for Win64
>>          DBI 0.2.5
>>          RPostgreSQL 0.1.7
>>          Postgresql related binaries shipped with
>> postgresql-9.0.2-1-windows_x64.exe from EnterpriseDB
>>
>> The package can be loaded, and driver can be created, but the
>> dbConnect function causes the whole RGui crashes,
>>
>> driver<- dbDriver("PostgreSQL")
>> con<- dbConnect(driver, dbname="demo", host="192.168.8.1",
>> user="postgres", password="postgres", port=5432)
>>
>>
>>
>> ------------------------------
>>
>> _______________________________________________
>> R-devel at r-project.org mailing list  DIGESTED
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>> End of R-devel Digest, Vol 95, Issue 14
>> ***************************************
>>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Patrick Burns
pburns at pburns.seanet.com
twitter: @portfolioprobe
http://www.portfolioprobe.com/blog
http://www.burns-stat.com
(home of 'Some hints for the R beginner'
and 'The R Inferno')


From murdoch.duncan at gmail.com  Mon Jan 17 18:53:58 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 17 Jan 2011 12:53:58 -0500
Subject: [Rd] R vs. C
In-Reply-To: <4D347F59.5060100@pburns.seanet.com>
References: <AANLkTikbHjP7JvwfWjSaWds7fa4Ek=8LEo14h-Rm5igq@mail.gmail.com>
	<4D347F59.5060100@pburns.seanet.com>
Message-ID: <4D348236.6060701@gmail.com>

On 17/01/2011 12:41 PM, Patrick Burns wrote:
> Everyone has their own utility
> function.  Mine is if the boredom
> of waiting for the pure R function
> to finish is going to out-weight the
> boredom of writing the C code.
>
> Another issue is that adding C code
> increases the hassle of users who might
> want the code to run on different
> architectures.

... and also makes it harder for you and your users to tweak your code 
for different uses.

It is not uncommon for C code to run 100 times faster than R code (but 
it is also not uncommon to see very little speedup, if the R code is 
well vectorized).  So if you have something that's really slow, think 
about the fundamental operations, and write those in C, then use R code 
to glue them together.  But if it is fast enough without doing that, 
then leave it all in R.

Duncan Murdoch

> On 17/01/2011 17:13, Patrick Leyshock wrote:
> >  A question, please about development of R packages:
> >
> >  Are there any guidelines or best practices for deciding when and why to
> >  implement an operation in R, vs. implementing it in C?  The "Writing R
> >  Extensions" recommends "working in interpreted R code . . . this is normally
> >  the best option."  But we do write C-functions and access them in R - the
> >  question is, when/why is this justified, and when/why is it NOT justified?
> >
> >  While I have identified helpful documents on R coding standards, I have not
> >  seen notes/discussions on when/why to implement in R, vs. when to implement
> >  in C.
> >
> >  Thanks, Patrick
> >
> >  On Sun, Jan 16, 2011 at 3:00 AM,<r-devel-request at r-project.org>   wrote:
> >
> >>  Send R-devel mailing list submissions to
> >>          r-devel at r-project.org
> >>
> >>  To subscribe or unsubscribe via the World Wide Web, visit
> >>          https://stat.ethz.ch/mailman/listinfo/r-devel
> >>  or, via email, send a message with subject or body 'help' to
> >>          r-devel-request at r-project.org
> >>
> >>  You can reach the person managing the list at
> >>          r-devel-owner at r-project.org
> >>
> >>  When replying, please edit your Subject line so it is more specific
> >>  than "Re: Contents of R-devel digest..."
> >>
> >>
> >>  Today's Topics:
> >>
> >>     1. RPostgreSQL 0.1.7 for Windows 64 causes R.2.12.1 Win64 crash
> >>        (Xiaobo Gu)
> >>
> >>
> >>  ----------------------------------------------------------------------
> >>
> >>  Message: 1
> >>  Date: Sat, 15 Jan 2011 10:34:55 +0800
> >>  From: Xiaobo Gu<guxiaobo1982 at gmail.com>
> >>  To: r-devel at r-project.org
> >>  Subject: [Rd] RPostgreSQL 0.1.7 for Windows 64 causes R.2.12.1 Win64
> >>          crash
> >>  Message-ID:
> >>          <AANLkTinvoub-z_Le1GVPYswnqTsW1P6MZzLZsztois9K at mail.gmail.com>
> >>  Content-Type: text/plain; charset=ISO-8859-1
> >>
> >>  Hi,
> >>  I build the binary package file of RPostgreSQL 0.1.7 for Windows 2003
> >>  Server R2 64 bit SP2, the software environments are as following:
> >>           R 2.12.1 for Win64
> >>           RTools212 for Win64
> >>           DBI 0.2.5
> >>           RPostgreSQL 0.1.7
> >>           Postgresql related binaries shipped with
> >>  postgresql-9.0.2-1-windows_x64.exe from EnterpriseDB
> >>
> >>  The package can be loaded, and driver can be created, but the
> >>  dbConnect function causes the whole RGui crashes,
> >>
> >>  driver<- dbDriver("PostgreSQL")
> >>  con<- dbConnect(driver, dbname="demo", host="192.168.8.1",
> >>  user="postgres", password="postgres", port=5432)
> >>
> >>
> >>
> >>  ------------------------------
> >>
> >>  _______________________________________________
> >>  R-devel at r-project.org mailing list  DIGESTED
> >>  https://stat.ethz.ch/mailman/listinfo/r-devel
> >>
> >>
> >>  End of R-devel Digest, Vol 95, Issue 14
> >>  ***************************************
> >>
> >
> >  	[[alternative HTML version deleted]]
> >
> >  ______________________________________________
> >  R-devel at r-project.org mailing list
> >  https://stat.ethz.ch/mailman/listinfo/r-devel
> >
>


From edd at debian.org  Mon Jan 17 19:13:36 2011
From: edd at debian.org (Dirk Eddelbuettel)
Date: Mon, 17 Jan 2011 12:13:36 -0600
Subject: [Rd] R vs. C
In-Reply-To: <AANLkTikbHjP7JvwfWjSaWds7fa4Ek=8LEo14h-Rm5igq@mail.gmail.com>
References: <AANLkTikbHjP7JvwfWjSaWds7fa4Ek=8LEo14h-Rm5igq@mail.gmail.com>
Message-ID: <19764.34512.640668.433147@max.nulle.part>


On 17 January 2011 at 09:13, Patrick Leyshock wrote:
| A question, please about development of R packages:
| 
| Are there any guidelines or best practices for deciding when and why to
| implement an operation in R, vs. implementing it in C?  The "Writing R
| Extensions" recommends "working in interpreted R code . . . this is normally
| the best option."  But we do write C-functions and access them in R - the
| question is, when/why is this justified, and when/why is it NOT justified?
| 
| While I have identified helpful documents on R coding standards, I have not
| seen notes/discussions on when/why to implement in R, vs. when to implement
| in C.

The (still fairly recent) book 'Software for Data Analysis: Programming with
R' by John Chambers (Springer, 2008) has a lot to say about this.  John also
gave a talk in November which stressed 'multilanguage' approaches; see e.g.
http://blog.revolutionanalytics.com/2010/11/john-chambers-on-r-and-multilingualism.html

In short, it all depends, and it is unlikely that you will get a coherent
answer that is valid for all circumstances.  We all love R for how expressive
and powerful it is, yet there are times when something else is called for.
Exactly when that time is depends on a great many things and you have not
mentioned a single metric in your question.  So I'd start with John's book.

Hope this helps, Dirk

-- 
Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com


From dnadavewa at yahoo.com  Mon Jan 17 19:57:32 2011
From: dnadavewa at yahoo.com (David Henderson)
Date: Mon, 17 Jan 2011 10:57:32 -0800 (PST)
Subject: [Rd] R vs. C
In-Reply-To: <19764.34512.640668.433147@max.nulle.part>
References: <AANLkTikbHjP7JvwfWjSaWds7fa4Ek=8LEo14h-Rm5igq@mail.gmail.com>
	<19764.34512.640668.433147@max.nulle.part>
Message-ID: <891858.34031.qm@web113714.mail.gq1.yahoo.com>

I think we're also forgetting something, namely testing.  If you write your 
routine in C, you have placed additional burden upon yourself to test your C 
code through unit tests, etc.  If you write your code in R, you still need the 
unit tests, but you can rely on the well tested nature of R to allow you to 
reduce the number of tests of your algorithm.  I routinely tell people at Sage 
Bionetworks where I am working now that your new C code needs to experience at 
least one order of magnitude increase in performance to warrant the effort of 
moving from R to C.

But, then again, I am working with scientists who are not primarily, or even 
secondarily, coders...

Dave H



----- Original Message ----
From: Dirk Eddelbuettel <edd at debian.org>
To: Patrick Leyshock <ngkbr8es at gmail.com>
Cc: r-devel at r-project.org
Sent: Mon, January 17, 2011 10:13:36 AM
Subject: Re: [Rd] R vs. C


On 17 January 2011 at 09:13, Patrick Leyshock wrote:
| A question, please about development of R packages:
| 
| Are there any guidelines or best practices for deciding when and why to
| implement an operation in R, vs. implementing it in C?  The "Writing R
| Extensions" recommends "working in interpreted R code . . . this is normally
| the best option."  But we do write C-functions and access them in R - the
| question is, when/why is this justified, and when/why is it NOT justified?
| 
| While I have identified helpful documents on R coding standards, I have not
| seen notes/discussions on when/why to implement in R, vs. when to implement
| in C.

The (still fairly recent) book 'Software for Data Analysis: Programming with
R' by John Chambers (Springer, 2008) has a lot to say about this.  John also
gave a talk in November which stressed 'multilanguage' approaches; see e.g.
http://blog.revolutionanalytics.com/2010/11/john-chambers-on-r-and-multilingualism.html


In short, it all depends, and it is unlikely that you will get a coherent
answer that is valid for all circumstances.  We all love R for how expressive
and powerful it is, yet there are times when something else is called for.
Exactly when that time is depends on a great many things and you have not
mentioned a single metric in your question.  So I'd start with John's book.

Hope this helps, Dirk

-- 
Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com

______________________________________________
R-devel at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-devel


From spencer.graves at structuremonitoring.com  Mon Jan 17 20:08:34 2011
From: spencer.graves at structuremonitoring.com (Spencer Graves)
Date: Mon, 17 Jan 2011 11:08:34 -0800
Subject: [Rd] R vs. C
In-Reply-To: <891858.34031.qm@web113714.mail.gq1.yahoo.com>
References: <AANLkTikbHjP7JvwfWjSaWds7fa4Ek=8LEo14h-Rm5igq@mail.gmail.com>	<19764.34512.640668.433147@max.nulle.part>
	<891858.34031.qm@web113714.mail.gq1.yahoo.com>
Message-ID: <4D3493B2.2070907@structuremonitoring.com>

       Another point I have not yet seen mentioned:  If your code is 
painfully slow, that can often be fixed without leaving R by 
experimenting with different ways of doing the same thing -- often after 
using profiling your code to find the slowest part as described in 
chapter 3 of "Writing R Extensions".


       If I'm given code already written in C (or some other language), 
unless it's really simple, I may link to it rather than recode it in R.  
However, the problems with portability, maintainability, transparency to 
others who may not be very facile with C, etc., all suggest that it's 
well worth some effort experimenting with alternate ways of doing the 
same thing in R before jumping to C or something else.


       Hope this helps.
       Spencer


On 1/17/2011 10:57 AM, David Henderson wrote:
> I think we're also forgetting something, namely testing.  If you write your
> routine in C, you have placed additional burden upon yourself to test your C
> code through unit tests, etc.  If you write your code in R, you still need the
> unit tests, but you can rely on the well tested nature of R to allow you to
> reduce the number of tests of your algorithm.  I routinely tell people at Sage
> Bionetworks where I am working now that your new C code needs to experience at
> least one order of magnitude increase in performance to warrant the effort of
> moving from R to C.
>
> But, then again, I am working with scientists who are not primarily, or even
> secondarily, coders...
>
> Dave H
>
>
>
> ----- Original Message ----
> From: Dirk Eddelbuettel<edd at debian.org>
> To: Patrick Leyshock<ngkbr8es at gmail.com>
> Cc: r-devel at r-project.org
> Sent: Mon, January 17, 2011 10:13:36 AM
> Subject: Re: [Rd] R vs. C
>
>
> On 17 January 2011 at 09:13, Patrick Leyshock wrote:
> | A question, please about development of R packages:
> |
> | Are there any guidelines or best practices for deciding when and why to
> | implement an operation in R, vs. implementing it in C?  The "Writing R
> | Extensions" recommends "working in interpreted R code . . . this is normally
> | the best option."  But we do write C-functions and access them in R - the
> | question is, when/why is this justified, and when/why is it NOT justified?
> |
> | While I have identified helpful documents on R coding standards, I have not
> | seen notes/discussions on when/why to implement in R, vs. when to implement
> | in C.
>
> The (still fairly recent) book 'Software for Data Analysis: Programming with
> R' by John Chambers (Springer, 2008) has a lot to say about this.  John also
> gave a talk in November which stressed 'multilanguage' approaches; see e.g.
> http://blog.revolutionanalytics.com/2010/11/john-chambers-on-r-and-multilingualism.html
>
>
> In short, it all depends, and it is unlikely that you will get a coherent
> answer that is valid for all circumstances.  We all love R for how expressive
> and powerful it is, yet there are times when something else is called for.
> Exactly when that time is depends on a great many things and you have not
> mentioned a single metric in your question.  So I'd start with John's book.
>
> Hope this helps, Dirk


From b.rowlingson at lancaster.ac.uk  Mon Jan 17 20:16:31 2011
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Mon, 17 Jan 2011 19:16:31 +0000
Subject: [Rd] R vs. C
In-Reply-To: <891858.34031.qm@web113714.mail.gq1.yahoo.com>
References: <AANLkTikbHjP7JvwfWjSaWds7fa4Ek=8LEo14h-Rm5igq@mail.gmail.com>
	<19764.34512.640668.433147@max.nulle.part>
	<891858.34031.qm@web113714.mail.gq1.yahoo.com>
Message-ID: <AANLkTi=7EwptjwsrqyR_OKYXCNP2Gn5uR-RMFdmNUpzC@mail.gmail.com>

On Mon, Jan 17, 2011 at 6:57 PM, David Henderson <dnadavewa at yahoo.com> wrote:
> I think we're also forgetting something, namely testing. ?If you write your
> routine in C, you have placed additional burden upon yourself to test your C
> code through unit tests, etc. ?If you write your code in R, you still need the
> unit tests, but you can rely on the well tested nature of R to allow you to
> reduce the number of tests of your algorithm. ?I routinely tell people at Sage
> Bionetworks where I am working now that your new C code needs to experience at
> least one order of magnitude increase in performance to warrant the effort of
> moving from R to C.
>
> But, then again, I am working with scientists who are not primarily, or even
> secondarily, coders...

If you write your code in C but interface to it in R, you can use the
same R test harness system. I recently coded something up in R, tested
it on small data, discovered it was waaay too slow on the real data,
rewrote the likelihood calculation in C, and then used the same test
set to make sure it was giving the same answers as the R code. It
wasn't. So I fixed that bug until it was. If I'd written the thing in
C to start with I might not have spotted it.

 Sometimes writing a prototype in R is a useful testing tool even when
you know it'll be too slow - as an interpreted language R gives you a
rapid development cycle and handy interactive debugging possibilities.
Things that do exist in C but require compilation....

Barry


From djsamperi at gmail.com  Mon Jan 17 20:38:30 2011
From: djsamperi at gmail.com (Dominick Samperi)
Date: Mon, 17 Jan 2011 14:38:30 -0500
Subject: [Rd] R vs. C
In-Reply-To: <4D3493B2.2070907@structuremonitoring.com>
References: <AANLkTikbHjP7JvwfWjSaWds7fa4Ek=8LEo14h-Rm5igq@mail.gmail.com>
	<19764.34512.640668.433147@max.nulle.part>
	<891858.34031.qm@web113714.mail.gq1.yahoo.com>
	<4D3493B2.2070907@structuremonitoring.com>
Message-ID: <AANLkTim1jCxVaPLoES_7JZ+0OxeGtAGGReHNFLSOFaPU@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110117/85e36f4e/attachment.pl>

From spencer.graves at structuremonitoring.com  Mon Jan 17 21:57:54 2011
From: spencer.graves at structuremonitoring.com (Spencer Graves)
Date: Mon, 17 Jan 2011 12:57:54 -0800
Subject: [Rd] R vs. C
In-Reply-To: <AANLkTim1jCxVaPLoES_7JZ+0OxeGtAGGReHNFLSOFaPU@mail.gmail.com>
References: <AANLkTikbHjP7JvwfWjSaWds7fa4Ek=8LEo14h-Rm5igq@mail.gmail.com>	<19764.34512.640668.433147@max.nulle.part>	<891858.34031.qm@web113714.mail.gq1.yahoo.com>	<4D3493B2.2070907@structuremonitoring.com>
	<AANLkTim1jCxVaPLoES_7JZ+0OxeGtAGGReHNFLSOFaPU@mail.gmail.com>
Message-ID: <4D34AD52.20704@structuremonitoring.com>

       For me, a major strength of R is the package development 
process.  I've found this so valuable that I created a Wikipedia entry 
by that name and made additions to a Wikipedia entry on "software 
repository", noting that this process encourages good software 
development practices that I have not seen standardized for other 
languages.  I encourage people to review this material and make 
additions or corrections as they like (or sent me suggestions for me to 
make appropriate changes).


       While R has other capabilities for unit and regression testing, I 
often include unit tests in the "examples" section of documentation 
files.  To keep from cluttering the examples with unnecessary material, 
I often include something like the following:


A1 <- myfunc() # to test myfunc

A0 <- ("manual generation of the correct  answer for A1")

\dontshow{stopifnot(} # so the user doesn't see "stopifnot("
all.equal(A1, A0) # compare myfunc output with the correct answer
\dontshow{)} # close paren on "stopifnot(".


       This may not be as good in some ways as a full suite of unit 
tests, which could be provided separately.  However, this has the 
distinct advantage of including unit tests with the documentation in a 
way that should help users understand "myfunc".  (Unit tests too 
detailed to show users could be completely enclosed in "\dontshow".


       Spencer


On 1/17/2011 11:38 AM, Dominick Samperi wrote:
> On Mon, Jan 17, 2011 at 2:08 PM, Spencer Graves<
> spencer.graves at structuremonitoring.com>  wrote:
>
>>       Another point I have not yet seen mentioned:  If your code is
>> painfully slow, that can often be fixed without leaving R by experimenting
>> with different ways of doing the same thing -- often after using profiling
>> your code to find the slowest part as described in chapter 3 of "Writing R
>> Extensions".
>>
>>
>>       If I'm given code already written in C (or some other language),
>> unless it's really simple, I may link to it rather than recode it in R.
>>   However, the problems with portability, maintainability, transparency to
>> others who may not be very facile with C, etc., all suggest that it's well
>> worth some effort experimenting with alternate ways of doing the same thing
>> in R before jumping to C or something else.
>>
>>       Hope this helps.
>>       Spencer
>>
>>
>>
>> On 1/17/2011 10:57 AM, David Henderson wrote:
>>
>>> I think we're also forgetting something, namely testing.  If you write
>>> your
>>> routine in C, you have placed additional burden upon yourself to test your
>>> C
>>> code through unit tests, etc.  If you write your code in R, you still need
>>> the
>>> unit tests, but you can rely on the well tested nature of R to allow you
>>> to
>>> reduce the number of tests of your algorithm.  I routinely tell people at
>>> Sage
>>> Bionetworks where I am working now that your new C code needs to
>>> experience at
>>> least one order of magnitude increase in performance to warrant the effort
>>> of
>>> moving from R to C.
>>>
>>> But, then again, I am working with scientists who are not primarily, or
>>> even
>>> secondarily, coders...
>>>
>>> Dave H
>>>
>>>
> This makes sense, but I have seem some very transparent algorithms turned
> into vectorized R code
> that is difficult to read (and thus to maintain or to change). These chunks
> of optimized R code are like
> embedded assembly, in the sense that nobody is likely to want to mess with
> it. This could be addressed
> by including pseudo code for the original (more transparent) algorithm as a
> comment, but I have never
> seen this done in practice (perhaps it could be enforced by R CMD check?!).
>
> On the other hand, in principle a well-documented piece of C/C++ code could
> be much easier to understand,
> without paying a performance penalty...but "coders" are not likely to place
> this high on their
> list of priorities.
>
> The bottom like is that R is an adaptor ("glue") language like Lisp that
> makes it easy to mix and
> match functions (using classes and generic functions), many of which are
> written in C (or C++
> or Fortran) for performance reasons. Like any object-based system there can
> be a lot of
> object copying, and like any functional programming system, there can be a
> lot of function
> calls, resulting in poor performance for some applications.
>
> If you can vectorize your R code then you have effectively found a way to
> benefit from
> somebody else's C code, thus saving yourself some time. For operations other
> than pure
> vector calculations you will have to do the C/C++ programming yourself (or
> call a library
> that somebody else has written).
>
> Dominick
>
>
>
>>> ----- Original Message ----
>>> From: Dirk Eddelbuettel<edd at debian.org>
>>> To: Patrick Leyshock<ngkbr8es at gmail.com>
>>> Cc: r-devel at r-project.org
>>> Sent: Mon, January 17, 2011 10:13:36 AM
>>> Subject: Re: [Rd] R vs. C
>>>
>>>
>>> On 17 January 2011 at 09:13, Patrick Leyshock wrote:
>>> | A question, please about development of R packages:
>>> |
>>> | Are there any guidelines or best practices for deciding when and why to
>>> | implement an operation in R, vs. implementing it in C?  The "Writing R
>>> | Extensions" recommends "working in interpreted R code . . . this is
>>> normally
>>> | the best option."  But we do write C-functions and access them in R -
>>> the
>>> | question is, when/why is this justified, and when/why is it NOT
>>> justified?
>>> |
>>> | While I have identified helpful documents on R coding standards, I have
>>> not
>>> | seen notes/discussions on when/why to implement in R, vs. when to
>>> implement
>>> | in C.
>>>
>>> The (still fairly recent) book 'Software for Data Analysis: Programming
>>> with
>>> R' by John Chambers (Springer, 2008) has a lot to say about this.  John
>>> also
>>> gave a talk in November which stressed 'multilanguage' approaches; see
>>> e.g.
>>>
>>> http://blog.revolutionanalytics.com/2010/11/john-chambers-on-r-and-multilingualism.html
>>>
>>>
>>> In short, it all depends, and it is unlikely that you will get a coherent
>>> answer that is valid for all circumstances.  We all love R for how
>>> expressive
>>> and powerful it is, yet there are times when something else is called for.
>>> Exactly when that time is depends on a great many things and you have not
>>> mentioned a single metric in your question.  So I'd start with John's
>>> book.
>>>
>>> Hope this helps, Dirk
>>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel


From djsamperi at gmail.com  Mon Jan 17 22:32:22 2011
From: djsamperi at gmail.com (Dominick Samperi)
Date: Mon, 17 Jan 2011 16:32:22 -0500
Subject: [Rd] R vs. C
In-Reply-To: <4D34AD52.20704@structuremonitoring.com>
References: <AANLkTikbHjP7JvwfWjSaWds7fa4Ek=8LEo14h-Rm5igq@mail.gmail.com>
	<19764.34512.640668.433147@max.nulle.part>
	<891858.34031.qm@web113714.mail.gq1.yahoo.com>
	<4D3493B2.2070907@structuremonitoring.com>
	<AANLkTim1jCxVaPLoES_7JZ+0OxeGtAGGReHNFLSOFaPU@mail.gmail.com>
	<4D34AD52.20704@structuremonitoring.com>
Message-ID: <AANLkTik4KinrsoE0BO0MswhZNBiWns3_UY9SbtLAt_nN@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110117/8dbeb719/attachment.pl>

From pgilbert at bank-banque-canada.ca  Mon Jan 17 22:52:30 2011
From: pgilbert at bank-banque-canada.ca (Paul Gilbert)
Date: Mon, 17 Jan 2011 21:52:30 +0000
Subject: [Rd] R vs. C
In-Reply-To: <4D34AD52.20704@structuremonitoring.com>
References: <AANLkTikbHjP7JvwfWjSaWds7fa4Ek=8LEo14h-Rm5igq@mail.gmail.com>
	<19764.34512.640668.433147@max.nulle.part>
	<891858.34031.qm@web113714.mail.gq1.yahoo.com>
	<4D3493B2.2070907@structuremonitoring.com>
	<AANLkTim1jCxVaPLoES_7JZ+0OxeGtAGGReHNFLSOFaPU@mail.gmail.com>
	<4D34AD52.20704@structuremonitoring.com>
Message-ID: <6441154A9FF1CD4386AF4ABF141A056D2150F03C@WMEXOSCD2-N2.bocad.bank-banque-canada.ca>

Spencer

Would it not be easier to include this kind of test in a small file in the tests/ directory?

Paul

-----Original Message-----
From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org] On Behalf Of Spencer Graves
Sent: January 17, 2011 3:58 PM
To: Dominick Samperi
Cc: Patrick Leyshock; r-devel at r-project.org; Dirk Eddelbuettel
Subject: Re: [Rd] R vs. C


       For me, a major strength of R is the package development 
process.  I've found this so valuable that I created a Wikipedia entry 
by that name and made additions to a Wikipedia entry on "software 
repository", noting that this process encourages good software 
development practices that I have not seen standardized for other 
languages.  I encourage people to review this material and make 
additions or corrections as they like (or sent me suggestions for me to 
make appropriate changes).


       While R has other capabilities for unit and regression testing, I 
often include unit tests in the "examples" section of documentation 
files.  To keep from cluttering the examples with unnecessary material, 
I often include something like the following:


A1 <- myfunc() # to test myfunc

A0 <- ("manual generation of the correct  answer for A1")

\dontshow{stopifnot(} # so the user doesn't see "stopifnot("
all.equal(A1, A0) # compare myfunc output with the correct answer
\dontshow{)} # close paren on "stopifnot(".


       This may not be as good in some ways as a full suite of unit 
tests, which could be provided separately.  However, this has the 
distinct advantage of including unit tests with the documentation in a 
way that should help users understand "myfunc".  (Unit tests too 
detailed to show users could be completely enclosed in "\dontshow".


       Spencer


On 1/17/2011 11:38 AM, Dominick Samperi wrote:
> On Mon, Jan 17, 2011 at 2:08 PM, Spencer Graves<
> spencer.graves at structuremonitoring.com>  wrote:
>
>>       Another point I have not yet seen mentioned:  If your code is
>> painfully slow, that can often be fixed without leaving R by experimenting
>> with different ways of doing the same thing -- often after using profiling
>> your code to find the slowest part as described in chapter 3 of "Writing R
>> Extensions".
>>
>>
>>       If I'm given code already written in C (or some other language),
>> unless it's really simple, I may link to it rather than recode it in R.
>>   However, the problems with portability, maintainability, transparency to
>> others who may not be very facile with C, etc., all suggest that it's well
>> worth some effort experimenting with alternate ways of doing the same thing
>> in R before jumping to C or something else.
>>
>>       Hope this helps.
>>       Spencer
>>
>>
>>
>> On 1/17/2011 10:57 AM, David Henderson wrote:
>>
>>> I think we're also forgetting something, namely testing.  If you write
>>> your
>>> routine in C, you have placed additional burden upon yourself to test your
>>> C
>>> code through unit tests, etc.  If you write your code in R, you still need
>>> the
>>> unit tests, but you can rely on the well tested nature of R to allow you
>>> to
>>> reduce the number of tests of your algorithm.  I routinely tell people at
>>> Sage
>>> Bionetworks where I am working now that your new C code needs to
>>> experience at
>>> least one order of magnitude increase in performance to warrant the effort
>>> of
>>> moving from R to C.
>>>
>>> But, then again, I am working with scientists who are not primarily, or
>>> even
>>> secondarily, coders...
>>>
>>> Dave H
>>>
>>>
> This makes sense, but I have seem some very transparent algorithms turned
> into vectorized R code
> that is difficult to read (and thus to maintain or to change). These chunks
> of optimized R code are like
> embedded assembly, in the sense that nobody is likely to want to mess with
> it. This could be addressed
> by including pseudo code for the original (more transparent) algorithm as a
> comment, but I have never
> seen this done in practice (perhaps it could be enforced by R CMD check?!).
>
> On the other hand, in principle a well-documented piece of C/C++ code could
> be much easier to understand,
> without paying a performance penalty...but "coders" are not likely to place
> this high on their
> list of priorities.
>
> The bottom like is that R is an adaptor ("glue") language like Lisp that
> makes it easy to mix and
> match functions (using classes and generic functions), many of which are
> written in C (or C++
> or Fortran) for performance reasons. Like any object-based system there can
> be a lot of
> object copying, and like any functional programming system, there can be a
> lot of function
> calls, resulting in poor performance for some applications.
>
> If you can vectorize your R code then you have effectively found a way to
> benefit from
> somebody else's C code, thus saving yourself some time. For operations other
> than pure
> vector calculations you will have to do the C/C++ programming yourself (or
> call a library
> that somebody else has written).
>
> Dominick
>
>
>
>>> ----- Original Message ----
>>> From: Dirk Eddelbuettel<edd at debian.org>
>>> To: Patrick Leyshock<ngkbr8es at gmail.com>
>>> Cc: r-devel at r-project.org
>>> Sent: Mon, January 17, 2011 10:13:36 AM
>>> Subject: Re: [Rd] R vs. C
>>>
>>>
>>> On 17 January 2011 at 09:13, Patrick Leyshock wrote:
>>> | A question, please about development of R packages:
>>> |
>>> | Are there any guidelines or best practices for deciding when and why to
>>> | implement an operation in R, vs. implementing it in C?  The "Writing R
>>> | Extensions" recommends "working in interpreted R code . . . this is
>>> normally
>>> | the best option."  But we do write C-functions and access them in R -
>>> the
>>> | question is, when/why is this justified, and when/why is it NOT
>>> justified?
>>> |
>>> | While I have identified helpful documents on R coding standards, I have
>>> not
>>> | seen notes/discussions on when/why to implement in R, vs. when to
>>> implement
>>> | in C.
>>>
>>> The (still fairly recent) book 'Software for Data Analysis: Programming
>>> with
>>> R' by John Chambers (Springer, 2008) has a lot to say about this.  John
>>> also
>>> gave a talk in November which stressed 'multilanguage' approaches; see
>>> e.g.
>>>
>>> http://blog.revolutionanalytics.com/2010/11/john-chambers-on-r-and-multilingualism.html
>>>
>>>
>>> In short, it all depends, and it is unlikely that you will get a coherent
>>> answer that is valid for all circumstances.  We all love R for how
>>> expressive
>>> and powerful it is, yet there are times when something else is called for.
>>> Exactly when that time is depends on a great many things and you have not
>>> mentioned a single metric in your question.  So I'd start with John's
>>> book.
>>>
>>> Hope this helps, Dirk
>>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel

______________________________________________
R-devel at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-devel
====================================================================================

La version fran?aise suit le texte anglais.

------------------------------------------------------------------------------------

This email may contain privileged and/or confidential information, and the Bank of
Canada does not waive any related rights. Any distribution, use, or copying of this
email or the information it contains by other than the intended recipient is
unauthorized. If you received this email in error please delete it immediately from
your system and notify the sender promptly by email that you have done so. 

------------------------------------------------------------------------------------

Le pr?sent courriel peut contenir de l'information privil?gi?e ou confidentielle.
La Banque du Canada ne renonce pas aux droits qui s'y rapportent. Toute diffusion,
utilisation ou copie de ce courriel ou des renseignements qu'il contient par une
personne autre que le ou les destinataires d?sign?s est interdite. Si vous recevez
ce courriel par erreur, veuillez le supprimer imm?diatement et envoyer sans d?lai ?
l'exp?diteur un message ?lectronique pour l'aviser que vous avez ?limin? de votre
ordinateur toute copie du courriel re?u.

From luke-tierney at uiowa.edu  Mon Jan 17 22:53:53 2011
From: luke-tierney at uiowa.edu (luke-tierney at uiowa.edu)
Date: Mon, 17 Jan 2011 15:53:53 -0600
Subject: [Rd] isoreg memory leak?
In-Reply-To: <334171D4-0548-49D5-A4B9-ECEE6D8D4C03@r-project.org>
References: <4D33BA62.7010902@utas.edu.au>
	<334171D4-0548-49D5-A4B9-ECEE6D8D4C03@r-project.org>
Message-ID: <alpine.DEB.2.00.1101171551130.3628@luke-inspiron>

On Mon, 17 Jan 2011, Simon Urbanek wrote:

>
> On Jan 16, 2011, at 10:41 PM, Simon Wotherspoon wrote:
>
>>
>> I believe there is a memory leak in isoreg in the current version of R, as I believe the following shows
>>
>>> gc()
>>         used (Mb) gc trigger (Mb) max used (Mb)
>> Ncells 120405  3.3     350000  9.4   350000  9.4
>> Vcells  78639  0.6     786432  6.0   392463  3.0
>>> for(k in 1:100) {
>> +
>> +   y <- runif(10000)
>> +   isoreg(x,y)
>> + }
>>> rm(x)
>>> rm(y)
>>> gc()
>>         used (Mb) gc trigger (Mb) max used (Mb)
>> Ncells 121637  3.3     350000  9.4   350000  9.4
>> Vcells 578615  4.5    1300721 10.0  1300642 10.0
>>               ^^^
>>
>>
>> Looking at the C code, I believe the problem arises as a consequence of using SETLENGTH to resize the result near the very end of isoreg.c,
>> and the solution is to make a copy of iKnots.

Using SETLENGTH in this way is definitely not intended -- only code in
memory.c should use it (and for now in envir.c).  We should fix shis
use, and one other strange one in grevents.c, and probably should get
rid of it SETLENGTH altogether outside of memory.c.

Best,

luke

>>
>
> AFAICS this is more of a reporting issue than a memory leak - ReleaseLargeFreeVectors() uses LENGTH() to determine the number by which to reduce R_LargeVallocSize - and it will be smaller than the actually released memory if SETLENGTH was used. I'm not sure how to fix it, because AFAICS the real size is not recorded anywhere (unless we use truelength for that but I'm not sure I know the implications). The good news is that it's not really a memory leak - the bad news is that the memory usage stats are rather an upper bound of the reality ;).
>
> Cheers,
> Simon
>
>
>
>>
>> SEXP R_isoreg(SEXP y)
>> {
>>    int n = LENGTH(y), i, ip, known, n_ip;
>>    double tmp, slope;
>>    SEXP yc, yf, iKnots, ans;
>>    const char *anms[] = {"y", "yc", "yf", "iKnots", ""};
>>
>>    /* unneeded: y = coerceVector(y, REALSXP); */
>>
>>    PROTECT(ans = mkNamed(VECSXP, anms));
>>
>>    SET_VECTOR_ELT(ans, 0, y = y);
>>    SET_VECTOR_ELT(ans, 1, yc = allocVector(REALSXP, n+1));
>>    SET_VECTOR_ELT(ans, 2, yf = allocVector(REALSXP, n));
>>    SET_VECTOR_ELT(ans, 3, iKnots= allocVector(INTSXP, n));
>>
>> ... calculation ...
>>
>>    SETLENGTH(iKnots, n_ip);
>>    UNPROTECT(1);
>>    return(ans);
>> }
>>
>>
>> But if this is the problem, I am at a bit of a loss as to what SETLENGTH is actually for in general.
>>
>> Clearly my understanding of how allocation/gc works is a bit off here, but I can't see how else the leak may occur.  Hope this is more use than nuisance.
>>
>> Simon.
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Luke Tierney
Statistics and Actuarial Science
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From spencer.graves at structuremonitoring.com  Mon Jan 17 23:15:20 2011
From: spencer.graves at structuremonitoring.com (Spencer Graves)
Date: Mon, 17 Jan 2011 14:15:20 -0800
Subject: [Rd] R vs. C
In-Reply-To: <6441154A9FF1CD4386AF4ABF141A056D2150F03C@WMEXOSCD2-N2.bocad.bank-banque-canada.ca>
References: <AANLkTikbHjP7JvwfWjSaWds7fa4Ek=8LEo14h-Rm5igq@mail.gmail.com>	<19764.34512.640668.433147@max.nulle.part>	<891858.34031.qm@web113714.mail.gq1.yahoo.com>	<4D3493B2.2070907@structuremonitoring.com>	<AANLkTim1jCxVaPLoES_7JZ+0OxeGtAGGReHNFLSOFaPU@mail.gmail.com>
	<4D34AD52.20704@structuremonitoring.com>
	<6441154A9FF1CD4386AF4ABF141A056D2150F03C@WMEXOSCD2-N2.bocad.bank-banque-canada.ca>
Message-ID: <4D34BF78.7040301@structuremonitoring.com>

Hi, Paul:


       The "Writing R Extensions" manual says that *.R code in a "tests" 
directory is run during "R CMD check".  I suspect that many R 
programmers do this routinely.  I probably should do that also.  
However, for me, it's simpler to have everything in the "examples" 
section of *.Rd files.  I think the examples with independently 
developed answers provides useful documentation.


       Spencer


On 1/17/2011 1:52 PM, Paul Gilbert wrote:
> Spencer
>
> Would it not be easier to include this kind of test in a small file in the tests/ directory?
>
> Paul
>
> -----Original Message-----
> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org] On Behalf Of Spencer Graves
> Sent: January 17, 2011 3:58 PM
> To: Dominick Samperi
> Cc: Patrick Leyshock; r-devel at r-project.org; Dirk Eddelbuettel
> Subject: Re: [Rd] R vs. C
>
>
>         For me, a major strength of R is the package development
> process.  I've found this so valuable that I created a Wikipedia entry
> by that name and made additions to a Wikipedia entry on "software
> repository", noting that this process encourages good software
> development practices that I have not seen standardized for other
> languages.  I encourage people to review this material and make
> additions or corrections as they like (or sent me suggestions for me to
> make appropriate changes).
>
>
>         While R has other capabilities for unit and regression testing, I
> often include unit tests in the "examples" section of documentation
> files.  To keep from cluttering the examples with unnecessary material,
> I often include something like the following:
>
>
> A1<- myfunc() # to test myfunc
>
> A0<- ("manual generation of the correct  answer for A1")
>
> \dontshow{stopifnot(} # so the user doesn't see "stopifnot("
> all.equal(A1, A0) # compare myfunc output with the correct answer
> \dontshow{)} # close paren on "stopifnot(".
>
>
>         This may not be as good in some ways as a full suite of unit
> tests, which could be provided separately.  However, this has the
> distinct advantage of including unit tests with the documentation in a
> way that should help users understand "myfunc".  (Unit tests too
> detailed to show users could be completely enclosed in "\dontshow".
>
>
>         Spencer
>
>
> On 1/17/2011 11:38 AM, Dominick Samperi wrote:
>> On Mon, Jan 17, 2011 at 2:08 PM, Spencer Graves<
>> spencer.graves at structuremonitoring.com>   wrote:
>>
>>>        Another point I have not yet seen mentioned:  If your code is
>>> painfully slow, that can often be fixed without leaving R by experimenting
>>> with different ways of doing the same thing -- often after using profiling
>>> your code to find the slowest part as described in chapter 3 of "Writing R
>>> Extensions".
>>>
>>>
>>>        If I'm given code already written in C (or some other language),
>>> unless it's really simple, I may link to it rather than recode it in R.
>>>    However, the problems with portability, maintainability, transparency to
>>> others who may not be very facile with C, etc., all suggest that it's well
>>> worth some effort experimenting with alternate ways of doing the same thing
>>> in R before jumping to C or something else.
>>>
>>>        Hope this helps.
>>>        Spencer
>>>
>>>
>>>
>>> On 1/17/2011 10:57 AM, David Henderson wrote:
>>>
>>>> I think we're also forgetting something, namely testing.  If you write
>>>> your
>>>> routine in C, you have placed additional burden upon yourself to test your
>>>> C
>>>> code through unit tests, etc.  If you write your code in R, you still need
>>>> the
>>>> unit tests, but you can rely on the well tested nature of R to allow you
>>>> to
>>>> reduce the number of tests of your algorithm.  I routinely tell people at
>>>> Sage
>>>> Bionetworks where I am working now that your new C code needs to
>>>> experience at
>>>> least one order of magnitude increase in performance to warrant the effort
>>>> of
>>>> moving from R to C.
>>>>
>>>> But, then again, I am working with scientists who are not primarily, or
>>>> even
>>>> secondarily, coders...
>>>>
>>>> Dave H
>>>>
>>>>
>> This makes sense, but I have seem some very transparent algorithms turned
>> into vectorized R code
>> that is difficult to read (and thus to maintain or to change). These chunks
>> of optimized R code are like
>> embedded assembly, in the sense that nobody is likely to want to mess with
>> it. This could be addressed
>> by including pseudo code for the original (more transparent) algorithm as a
>> comment, but I have never
>> seen this done in practice (perhaps it could be enforced by R CMD check?!).
>>
>> On the other hand, in principle a well-documented piece of C/C++ code could
>> be much easier to understand,
>> without paying a performance penalty...but "coders" are not likely to place
>> this high on their
>> list of priorities.
>>
>> The bottom like is that R is an adaptor ("glue") language like Lisp that
>> makes it easy to mix and
>> match functions (using classes and generic functions), many of which are
>> written in C (or C++
>> or Fortran) for performance reasons. Like any object-based system there can
>> be a lot of
>> object copying, and like any functional programming system, there can be a
>> lot of function
>> calls, resulting in poor performance for some applications.
>>
>> If you can vectorize your R code then you have effectively found a way to
>> benefit from
>> somebody else's C code, thus saving yourself some time. For operations other
>> than pure
>> vector calculations you will have to do the C/C++ programming yourself (or
>> call a library
>> that somebody else has written).
>>
>> Dominick
>>
>>
>>
>>>> ----- Original Message ----
>>>> From: Dirk Eddelbuettel<edd at debian.org>
>>>> To: Patrick Leyshock<ngkbr8es at gmail.com>
>>>> Cc: r-devel at r-project.org
>>>> Sent: Mon, January 17, 2011 10:13:36 AM
>>>> Subject: Re: [Rd] R vs. C
>>>>
>>>>
>>>> On 17 January 2011 at 09:13, Patrick Leyshock wrote:
>>>> | A question, please about development of R packages:
>>>> |
>>>> | Are there any guidelines or best practices for deciding when and why to
>>>> | implement an operation in R, vs. implementing it in C?  The "Writing R
>>>> | Extensions" recommends "working in interpreted R code . . . this is
>>>> normally
>>>> | the best option."  But we do write C-functions and access them in R -
>>>> the
>>>> | question is, when/why is this justified, and when/why is it NOT
>>>> justified?
>>>> |
>>>> | While I have identified helpful documents on R coding standards, I have
>>>> not
>>>> | seen notes/discussions on when/why to implement in R, vs. when to
>>>> implement
>>>> | in C.
>>>>
>>>> The (still fairly recent) book 'Software for Data Analysis: Programming
>>>> with
>>>> R' by John Chambers (Springer, 2008) has a lot to say about this.  John
>>>> also
>>>> gave a talk in November which stressed 'multilanguage' approaches; see
>>>> e.g.
>>>>
>>>> http://blog.revolutionanalytics.com/2010/11/john-chambers-on-r-and-multilingualism.html
>>>>
>>>>
>>>> In short, it all depends, and it is unlikely that you will get a coherent
>>>> answer that is valid for all circumstances.  We all love R for how
>>>> expressive
>>>> and powerful it is, yet there are times when something else is called for.
>>>> Exactly when that time is depends on a great many things and you have not
>>>> mentioned a single metric in your question.  So I'd start with John's
>>>> book.
>>>>
>>>> Hope this helps, Dirk
>>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> ====================================================================================
>
> La version fran?aise suit le texte anglais.
>
> ------------------------------------------------------------------------------------
>
> This email may contain privileged and/or confidential ...{{dropped:25}}


From djsamperi at gmail.com  Tue Jan 18 00:27:15 2011
From: djsamperi at gmail.com (Dominick Samperi)
Date: Mon, 17 Jan 2011 18:27:15 -0500
Subject: [Rd] R vs. C
In-Reply-To: <4D34BF78.7040301@structuremonitoring.com>
References: <AANLkTikbHjP7JvwfWjSaWds7fa4Ek=8LEo14h-Rm5igq@mail.gmail.com>
	<19764.34512.640668.433147@max.nulle.part>
	<891858.34031.qm@web113714.mail.gq1.yahoo.com>
	<4D3493B2.2070907@structuremonitoring.com>
	<AANLkTim1jCxVaPLoES_7JZ+0OxeGtAGGReHNFLSOFaPU@mail.gmail.com>
	<4D34AD52.20704@structuremonitoring.com>
	<6441154A9FF1CD4386AF4ABF141A056D2150F03C@WMEXOSCD2-N2.bocad.bank-banque-canada.ca>
	<4D34BF78.7040301@structuremonitoring.com>
Message-ID: <AANLkTi=c961At6WL16g1kBmPgzpfGcPGabWdPG2=bhP9@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110117/52e35df8/attachment.pl>

From spencer.graves at structuremonitoring.com  Tue Jan 18 01:00:07 2011
From: spencer.graves at structuremonitoring.com (Spencer Graves)
Date: Mon, 17 Jan 2011 16:00:07 -0800
Subject: [Rd] R vs. C
In-Reply-To: <AANLkTi=c961At6WL16g1kBmPgzpfGcPGabWdPG2=bhP9@mail.gmail.com>
References: <AANLkTikbHjP7JvwfWjSaWds7fa4Ek=8LEo14h-Rm5igq@mail.gmail.com>	<19764.34512.640668.433147@max.nulle.part>	<891858.34031.qm@web113714.mail.gq1.yahoo.com>	<4D3493B2.2070907@structuremonitoring.com>	<AANLkTim1jCxVaPLoES_7JZ+0OxeGtAGGReHNFLSOFaPU@mail.gmail.com>	<4D34AD52.20704@structuremonitoring.com>	<6441154A9FF1CD4386AF4ABF141A056D2150F03C@WMEXOSCD2-N2.bocad.bank-banque-canada.ca>	<4D34BF78.7040301@structuremonitoring.com>
	<AANLkTi=c961At6WL16g1kBmPgzpfGcPGabWdPG2=bhP9@mail.gmail.com>
Message-ID: <4D34D807.4020004@structuremonitoring.com>

Hi, Dominick, et al.:


       Demanding complete unit test suites with all software contributed 
to CRAN would likely cut contributions by a factor of 10 or 100.  For 
me, the R package creation process is close to perfection in providing a 
standard process for documentation with places for examples and test 
suites of various kinds.  I mention "perfection", because it makes 
developing "trustworthy software" (Chamber's "prime directive") 
relatively easy without forcing people to do things they don't feel 
comfortable doing.


       If you need more confidence in the software you use, you can 
build your own test suites -- maybe in packages you write yourself -- or 
pay someone else to develop test suites to your specifications.  For 
example, Revolution Analytics offers "Package validation, development 
and support".


        Spencer


On 1/17/2011 3:27 PM, Dominick Samperi wrote:
> On Mon, Jan 17, 2011 at 5:15 PM, Spencer Graves<
> spencer.graves at structuremonitoring.com>  wrote:
>
>> Hi, Paul:
>>
>>
>>       The "Writing R Extensions" manual says that *.R code in a "tests"
>> directory is run during "R CMD check".  I suspect that many R programmers do
>> this routinely.  I probably should do that also.  However, for me, it's
>> simpler to have everything in the "examples" section of *.Rd files.  I think
>> the examples with independently developed answers provides useful
>> documentation.
>>
> This is a unit test function, and I think it would be better if there was a
> way to unit test packages *before* they
> are released to CRAN. Otherwise, this is not really a "release," it is test
> or "beta" version. This is currently
> possible under Windows using http://win-builder.r-project.org/, for example.
>
> My earlier remark about the release process was more about documentation
> than about unit testing, more
> about the gentle "nudging" that the R release process does to help insure
> consistent documentation and
> organization, and about how this nudging might be extended to the C/C++ part
> of a package.
>
> Dominick
>
>
>>       Spencer
>>
>>
>>
>> On 1/17/2011 1:52 PM, Paul Gilbert wrote:
>>
>>> Spencer
>>>
>>> Would it not be easier to include this kind of test in a small file in the
>>> tests/ directory?
>>>
>>> Paul
>>>
>>> -----Original Message-----
>>> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org]
>>> On Behalf Of Spencer Graves
>>> Sent: January 17, 2011 3:58 PM
>>> To: Dominick Samperi
>>> Cc: Patrick Leyshock; r-devel at r-project.org; Dirk Eddelbuettel
>>> Subject: Re: [Rd] R vs. C
>>>
>>>
>>>         For me, a major strength of R is the package development
>>> process.  I've found this so valuable that I created a Wikipedia entry
>>> by that name and made additions to a Wikipedia entry on "software
>>> repository", noting that this process encourages good software
>>> development practices that I have not seen standardized for other
>>> languages.  I encourage people to review this material and make
>>> additions or corrections as they like (or sent me suggestions for me to
>>> make appropriate changes).
>>>
>>>
>>>         While R has other capabilities for unit and regression testing, I
>>> often include unit tests in the "examples" section of documentation
>>> files.  To keep from cluttering the examples with unnecessary material,
>>> I often include something like the following:
>>>
>>>
>>> A1<- myfunc() # to test myfunc
>>>
>>> A0<- ("manual generation of the correct  answer for A1")
>>>
>>> \dontshow{stopifnot(} # so the user doesn't see "stopifnot("
>>> all.equal(A1, A0) # compare myfunc output with the correct answer
>>> \dontshow{)} # close paren on "stopifnot(".
>>>
>>>
>>>         This may not be as good in some ways as a full suite of unit
>>> tests, which could be provided separately.  However, this has the
>>> distinct advantage of including unit tests with the documentation in a
>>> way that should help users understand "myfunc".  (Unit tests too
>>> detailed to show users could be completely enclosed in "\dontshow".
>>>
>>>
>>>         Spencer
>>>
>>>
>>> On 1/17/2011 11:38 AM, Dominick Samperi wrote:
>>>
>>>> On Mon, Jan 17, 2011 at 2:08 PM, Spencer Graves<
>>>> spencer.graves at structuremonitoring.com>    wrote:
>>>>
>>>>         Another point I have not yet seen mentioned:  If your code is
>>>>> painfully slow, that can often be fixed without leaving R by
>>>>> experimenting
>>>>> with different ways of doing the same thing -- often after using
>>>>> profiling
>>>>> your code to find the slowest part as described in chapter 3 of "Writing
>>>>> R
>>>>> Extensions".
>>>>>
>>>>>
>>>>>        If I'm given code already written in C (or some other language),
>>>>> unless it's really simple, I may link to it rather than recode it in R.
>>>>>    However, the problems with portability, maintainability, transparency
>>>>> to
>>>>> others who may not be very facile with C, etc., all suggest that it's
>>>>> well
>>>>> worth some effort experimenting with alternate ways of doing the same
>>>>> thing
>>>>> in R before jumping to C or something else.
>>>>>
>>>>>        Hope this helps.
>>>>>        Spencer
>>>>>
>>>>>
>>>>>
>>>>> On 1/17/2011 10:57 AM, David Henderson wrote:
>>>>>
>>>>>   I think we're also forgetting something, namely testing.  If you write
>>>>>> your
>>>>>> routine in C, you have placed additional burden upon yourself to test
>>>>>> your
>>>>>> C
>>>>>> code through unit tests, etc.  If you write your code in R, you still
>>>>>> need
>>>>>> the
>>>>>> unit tests, but you can rely on the well tested nature of R to allow
>>>>>> you
>>>>>> to
>>>>>> reduce the number of tests of your algorithm.  I routinely tell people
>>>>>> at
>>>>>> Sage
>>>>>> Bionetworks where I am working now that your new C code needs to
>>>>>> experience at
>>>>>> least one order of magnitude increase in performance to warrant the
>>>>>> effort
>>>>>> of
>>>>>> moving from R to C.
>>>>>>
>>>>>> But, then again, I am working with scientists who are not primarily, or
>>>>>> even
>>>>>> secondarily, coders...
>>>>>>
>>>>>> Dave H
>>>>>>
>>>>>>
>>>>>>   This makes sense, but I have seem some very transparent algorithms
>>>> turned
>>>> into vectorized R code
>>>> that is difficult to read (and thus to maintain or to change). These
>>>> chunks
>>>> of optimized R code are like
>>>> embedded assembly, in the sense that nobody is likely to want to mess
>>>> with
>>>> it. This could be addressed
>>>> by including pseudo code for the original (more transparent) algorithm as
>>>> a
>>>> comment, but I have never
>>>> seen this done in practice (perhaps it could be enforced by R CMD
>>>> check?!).
>>>>
>>>> On the other hand, in principle a well-documented piece of C/C++ code
>>>> could
>>>> be much easier to understand,
>>>> without paying a performance penalty...but "coders" are not likely to
>>>> place
>>>> this high on their
>>>> list of priorities.
>>>>
>>>> The bottom like is that R is an adaptor ("glue") language like Lisp that
>>>> makes it easy to mix and
>>>> match functions (using classes and generic functions), many of which are
>>>> written in C (or C++
>>>> or Fortran) for performance reasons. Like any object-based system there
>>>> can
>>>> be a lot of
>>>> object copying, and like any functional programming system, there can be
>>>> a
>>>> lot of function
>>>> calls, resulting in poor performance for some applications.
>>>>
>>>> If you can vectorize your R code then you have effectively found a way to
>>>> benefit from
>>>> somebody else's C code, thus saving yourself some time. For operations
>>>> other
>>>> than pure
>>>> vector calculations you will have to do the C/C++ programming yourself
>>>> (or
>>>> call a library
>>>> that somebody else has written).
>>>>
>>>> Dominick
>>>>
>>>>
>>>>
>>>>   ----- Original Message ----
>>>>>> From: Dirk Eddelbuettel<edd at debian.org>
>>>>>> To: Patrick Leyshock<ngkbr8es at gmail.com>
>>>>>> Cc: r-devel at r-project.org
>>>>>> Sent: Mon, January 17, 2011 10:13:36 AM
>>>>>> Subject: Re: [Rd] R vs. C
>>>>>>
>>>>>>
>>>>>> On 17 January 2011 at 09:13, Patrick Leyshock wrote:
>>>>>> | A question, please about development of R packages:
>>>>>> |
>>>>>> | Are there any guidelines or best practices for deciding when and why
>>>>>> to
>>>>>> | implement an operation in R, vs. implementing it in C?  The "Writing
>>>>>> R
>>>>>> | Extensions" recommends "working in interpreted R code . . . this is
>>>>>> normally
>>>>>> | the best option."  But we do write C-functions and access them in R -
>>>>>> the
>>>>>> | question is, when/why is this justified, and when/why is it NOT
>>>>>> justified?
>>>>>> |
>>>>>> | While I have identified helpful documents on R coding standards, I
>>>>>> have
>>>>>> not
>>>>>> | seen notes/discussions on when/why to implement in R, vs. when to
>>>>>> implement
>>>>>> | in C.
>>>>>>
>>>>>> The (still fairly recent) book 'Software for Data Analysis: Programming
>>>>>> with
>>>>>> R' by John Chambers (Springer, 2008) has a lot to say about this.  John
>>>>>> also
>>>>>> gave a talk in November which stressed 'multilanguage' approaches; see
>>>>>> e.g.
>>>>>>
>>>>>>
>>>>>> http://blog.revolutionanalytics.com/2010/11/john-chambers-on-r-and-multilingualism.html
>>>>>>
>>>>>>
>>>>>> In short, it all depends, and it is unlikely that you will get a
>>>>>> coherent
>>>>>> answer that is valid for all circumstances.  We all love R for how
>>>>>> expressive
>>>>>> and powerful it is, yet there are times when something else is called
>>>>>> for.
>>>>>> Exactly when that time is depends on a great many things and you have
>>>>>> not
>>>>>> mentioned a single metric in your question.  So I'd start with John's
>>>>>> book.
>>>>>>
>>>>>> Hope this helps, Dirk
>>>>>>
>>>>>>   ______________________________________________
>>>>> R-devel at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>>
>>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>> ====================================================================================
>>>
>>> La version fran?aise suit le texte anglais.
>>>
>>>
>>> ------------------------------------------------------------------------------------
>>>
>>> This email may contain privileged and/or confidential information, and the
>>> Bank of
>>> Canada does not waive any related rights. Any distribution, use, or
>>> copying of this
>>> email or the information it contains by other than the intended recipient
>>> is
>>> unauthorized. If you received this email in error please delete it
>>> immediately from
>>> your system and notify the sender promptly by email that you have done so.
>>>
>>>
>>> ------------------------------------------------------------------------------------
>>>
>>> Le pr?sent courriel peut contenir de l'information privil?gi?e ou
>>> confidentielle.
>>> La Banque du Canada ne renonce pas aux droits qui s'y rapportent. Toute
>>> diffusion,
>>> utilisation ou copie de ce courriel ou des renseignements qu'il contient
>>> par une
>>> personne autre que le ou les destinataires d?sign?s est interdite. Si vous
>>> recevez
>>> ce courriel par erreur, veuillez le supprimer imm?diatement et envoyer
>>> sans d?lai ?
>>> l'exp?diteur un message ?lectronique pour l'aviser que vous avez ?limin?
>>> de votre
>>> ordinateur toute copie du courriel re?u.


From djsamperi at gmail.com  Tue Jan 18 01:13:35 2011
From: djsamperi at gmail.com (Dominick Samperi)
Date: Mon, 17 Jan 2011 19:13:35 -0500
Subject: [Rd] R vs. C
In-Reply-To: <4D34D807.4020004@structuremonitoring.com>
References: <AANLkTikbHjP7JvwfWjSaWds7fa4Ek=8LEo14h-Rm5igq@mail.gmail.com>
	<19764.34512.640668.433147@max.nulle.part>
	<891858.34031.qm@web113714.mail.gq1.yahoo.com>
	<4D3493B2.2070907@structuremonitoring.com>
	<AANLkTim1jCxVaPLoES_7JZ+0OxeGtAGGReHNFLSOFaPU@mail.gmail.com>
	<4D34AD52.20704@structuremonitoring.com>
	<6441154A9FF1CD4386AF4ABF141A056D2150F03C@WMEXOSCD2-N2.bocad.bank-banque-canada.ca>
	<4D34BF78.7040301@structuremonitoring.com>
	<AANLkTi=c961At6WL16g1kBmPgzpfGcPGabWdPG2=bhP9@mail.gmail.com>
	<4D34D807.4020004@structuremonitoring.com>
Message-ID: <AANLkTim=ZhYg-X-cvQX=W25c3nY3v5AtmjBFA5Ec8F8+@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110117/f6b92746/attachment.pl>

From cbeleites at units.it  Tue Jan 18 10:48:48 2011
From: cbeleites at units.it (Claudia Beleites)
Date: Tue, 18 Jan 2011 10:48:48 +0100
Subject: [Rd] R vs. C now rather: how to ease package checking
In-Reply-To: <AANLkTim=ZhYg-X-cvQX=W25c3nY3v5AtmjBFA5Ec8F8+@mail.gmail.com>
References: <AANLkTikbHjP7JvwfWjSaWds7fa4Ek=8LEo14h-Rm5igq@mail.gmail.com>	<19764.34512.640668.433147@max.nulle.part>	<891858.34031.qm@web113714.mail.gq1.yahoo.com>	<4D3493B2.2070907@structuremonitoring.com>	<AANLkTim1jCxVaPLoES_7JZ+0OxeGtAGGReHNFLSOFaPU@mail.gmail.com>	<4D34AD52.20704@structuremonitoring.com>	<6441154A9FF1CD4386AF4ABF141A056D2150F03C@WMEXOSCD2-N2.bocad.bank-banque-canada.ca>	<4D34BF78.7040301@structuremonitoring.com>	<AANLkTi=c961At6WL16g1kBmPgzpfGcPGabWdPG2=bhP9@mail.gmail.com>	<4D34D807.4020004@structuremonitoring.com>
	<AANLkTim=ZhYg-X-cvQX=W25c3nY3v5AtmjBFA5Ec8F8+@mail.gmail.com>
Message-ID: <4D356200.6060004@units.it>

On 01/18/2011 01:13 AM, Dominick Samperi wrote:
> On Mon, Jan 17, 2011 at 7:00 PM, Spencer Graves<
> spencer.graves at structuremonitoring.com>  wrote:
>
>> Hi, Dominick, et al.:
>>
>>
>>       Demanding complete unit test suites with all software contributed to
>> CRAN would likely cut contributions by a factor of 10 or 100.  For me, the R
>> package creation process is close to perfection in providing a standard
>> process for documentation with places for examples and test suites of
>> various kinds.  I mention "perfection", because it makes developing
>> "trustworthy software" (Chamber's "prime directive") relatively easy without
>> forcing people to do things they don't feel comfortable doing.
>>
>
> I don't think I made myself clear, sorry. I was not suggesting that package
> developers include a complete unit
> test suite. I was suggesting that unit testing should be done outside of the
> CRAN release process. Packages
> should be submitted for "release" to CRAN after they have been tested (the
> responsibility of the package
> developers). I understand that the main problem here is that package
> developers do not have access to
> all supported platforms, so the current process is not likely to change.

Regarding access to all platforms: But there's r-forge where building and checks 
are done nightly for Linux, Win, and Mac (though for some months now the check 
protocols are not available for 32 bit Linux and Windows - but I hope they'll be 
back soon).
I found it extremely easy to get an account & project space and building.
Many thanks to r-forge!

complete unit test suites:
To me, it seems nicer and better to favour packages that do it than mechanical 
enforcement. E.g. show icons that announce if a package comes with vignette, 
test suite (code coverage), and etc.

My 2 ct,

Claudia


>
> Dominick
>
>
>>
>>       If you need more confidence in the software you use, you can build
>> your own test suites -- maybe in packages you write yourself -- or pay
>> someone else to develop test suites to your specifications.  For example,
>> Revolution Analytics offers "Package validation, development and support".
>>
>>
>>        Spencer
>>
>>
>>
>> On 1/17/2011 3:27 PM, Dominick Samperi wrote:
>>
>>> On Mon, Jan 17, 2011 at 5:15 PM, Spencer Graves<
>>> spencer.graves at structuremonitoring.com>   wrote:
>>>
>>>   Hi, Paul:
>>>>
>>>>
>>>>       The "Writing R Extensions" manual says that *.R code in a "tests"
>>>> directory is run during "R CMD check".  I suspect that many R programmers
>>>> do
>>>> this routinely.  I probably should do that also.  However, for me, it's
>>>> simpler to have everything in the "examples" section of *.Rd files.  I
>>>> think
>>>> the examples with independently developed answers provides useful
>>>> documentation.
>>>>
>>>>   This is a unit test function, and I think it would be better if there
>>> was a
>>> way to unit test packages *before* they
>>> are released to CRAN. Otherwise, this is not really a "release," it is
>>> test
>>> or "beta" version. This is currently
>>> possible under Windows using http://win-builder.r-project.org/, for
>>> example.
>>>
>>> My earlier remark about the release process was more about documentation
>>> than about unit testing, more
>>> about the gentle "nudging" that the R release process does to help insure
>>> consistent documentation and
>>> organization, and about how this nudging might be extended to the C/C++
>>> part
>>> of a package.
>>>
>>> Dominick
>>>
>>>
>>>        Spencer
>>>>
>>>>
>>>>
>>>> On 1/17/2011 1:52 PM, Paul Gilbert wrote:
>>>>
>>>>   Spencer
>>>>>
>>>>> Would it not be easier to include this kind of test in a small file in
>>>>> the
>>>>> tests/ directory?
>>>>>
>>>>> Paul
>>>>>
>>>>> -----Original Message-----
>>>>> From: r-devel-bounces at r-project.org [mailto:
>>>>> r-devel-bounces at r-project.org]
>>>>> On Behalf Of Spencer Graves
>>>>> Sent: January 17, 2011 3:58 PM
>>>>> To: Dominick Samperi
>>>>> Cc: Patrick Leyshock; r-devel at r-project.org; Dirk Eddelbuettel
>>>>> Subject: Re: [Rd] R vs. C
>>>>>
>>>>>
>>>>>         For me, a major strength of R is the package development
>>>>> process.  I've found this so valuable that I created a Wikipedia entry
>>>>> by that name and made additions to a Wikipedia entry on "software
>>>>> repository", noting that this process encourages good software
>>>>> development practices that I have not seen standardized for other
>>>>> languages.  I encourage people to review this material and make
>>>>> additions or corrections as they like (or sent me suggestions for me to
>>>>> make appropriate changes).
>>>>>
>>>>>
>>>>>         While R has other capabilities for unit and regression testing, I
>>>>> often include unit tests in the "examples" section of documentation
>>>>> files.  To keep from cluttering the examples with unnecessary material,
>>>>> I often include something like the following:
>>>>>
>>>>>
>>>>> A1<- myfunc() # to test myfunc
>>>>>
>>>>> A0<- ("manual generation of the correct  answer for A1")
>>>>>
>>>>> \dontshow{stopifnot(} # so the user doesn't see "stopifnot("
>>>>> all.equal(A1, A0) # compare myfunc output with the correct answer
>>>>> \dontshow{)} # close paren on "stopifnot(".
>>>>>
>>>>>
>>>>>         This may not be as good in some ways as a full suite of unit
>>>>> tests, which could be provided separately.  However, this has the
>>>>> distinct advantage of including unit tests with the documentation in a
>>>>> way that should help users understand "myfunc".  (Unit tests too
>>>>> detailed to show users could be completely enclosed in "\dontshow".
>>>>>
>>>>>
>>>>>         Spencer
>>>>>
>>>>>
>>>>> On 1/17/2011 11:38 AM, Dominick Samperi wrote:
>>>>>
>>>>>   On Mon, Jan 17, 2011 at 2:08 PM, Spencer Graves<
>>>>>> spencer.graves at structuremonitoring.com>     wrote:
>>>>>>
>>>>>>         Another point I have not yet seen mentioned:  If your code is
>>>>>>
>>>>>>> painfully slow, that can often be fixed without leaving R by
>>>>>>> experimenting
>>>>>>> with different ways of doing the same thing -- often after using
>>>>>>> profiling
>>>>>>> your code to find the slowest part as described in chapter 3 of
>>>>>>> "Writing
>>>>>>> R
>>>>>>> Extensions".
>>>>>>>
>>>>>>>
>>>>>>>        If I'm given code already written in C (or some other language),
>>>>>>> unless it's really simple, I may link to it rather than recode it in
>>>>>>> R.
>>>>>>>    However, the problems with portability, maintainability,
>>>>>>> transparency
>>>>>>> to
>>>>>>> others who may not be very facile with C, etc., all suggest that it's
>>>>>>> well
>>>>>>> worth some effort experimenting with alternate ways of doing the same
>>>>>>> thing
>>>>>>> in R before jumping to C or something else.
>>>>>>>
>>>>>>>        Hope this helps.
>>>>>>>        Spencer
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>> On 1/17/2011 10:57 AM, David Henderson wrote:
>>>>>>>
>>>>>>>   I think we're also forgetting something, namely testing.  If you
>>>>>>> write
>>>>>>>
>>>>>>>> your
>>>>>>>> routine in C, you have placed additional burden upon yourself to test
>>>>>>>> your
>>>>>>>> C
>>>>>>>> code through unit tests, etc.  If you write your code in R, you still
>>>>>>>> need
>>>>>>>> the
>>>>>>>> unit tests, but you can rely on the well tested nature of R to allow
>>>>>>>> you
>>>>>>>> to
>>>>>>>> reduce the number of tests of your algorithm.  I routinely tell
>>>>>>>> people
>>>>>>>> at
>>>>>>>> Sage
>>>>>>>> Bionetworks where I am working now that your new C code needs to
>>>>>>>> experience at
>>>>>>>> least one order of magnitude increase in performance to warrant the
>>>>>>>> effort
>>>>>>>> of
>>>>>>>> moving from R to C.
>>>>>>>>
>>>>>>>> But, then again, I am working with scientists who are not primarily,
>>>>>>>> or
>>>>>>>> even
>>>>>>>> secondarily, coders...
>>>>>>>>
>>>>>>>> Dave H
>>>>>>>>
>>>>>>>>
>>>>>>>>   This makes sense, but I have seem some very transparent algorithms
>>>>>>>>
>>>>>>> turned
>>>>>> into vectorized R code
>>>>>> that is difficult to read (and thus to maintain or to change). These
>>>>>> chunks
>>>>>> of optimized R code are like
>>>>>> embedded assembly, in the sense that nobody is likely to want to mess
>>>>>> with
>>>>>> it. This could be addressed
>>>>>> by including pseudo code for the original (more transparent) algorithm
>>>>>> as
>>>>>> a
>>>>>> comment, but I have never
>>>>>> seen this done in practice (perhaps it could be enforced by R CMD
>>>>>> check?!).
>>>>>>
>>>>>> On the other hand, in principle a well-documented piece of C/C++ code
>>>>>> could
>>>>>> be much easier to understand,
>>>>>> without paying a performance penalty...but "coders" are not likely to
>>>>>> place
>>>>>> this high on their
>>>>>> list of priorities.
>>>>>>
>>>>>> The bottom like is that R is an adaptor ("glue") language like Lisp
>>>>>> that
>>>>>> makes it easy to mix and
>>>>>> match functions (using classes and generic functions), many of which
>>>>>> are
>>>>>> written in C (or C++
>>>>>> or Fortran) for performance reasons. Like any object-based system there
>>>>>> can
>>>>>> be a lot of
>>>>>> object copying, and like any functional programming system, there can
>>>>>> be
>>>>>> a
>>>>>> lot of function
>>>>>> calls, resulting in poor performance for some applications.
>>>>>>
>>>>>> If you can vectorize your R code then you have effectively found a way
>>>>>> to
>>>>>> benefit from
>>>>>> somebody else's C code, thus saving yourself some time. For operations
>>>>>> other
>>>>>> than pure
>>>>>> vector calculations you will have to do the C/C++ programming yourself
>>>>>> (or
>>>>>> call a library
>>>>>> that somebody else has written).
>>>>>>
>>>>>> Dominick
>>>>>>
>>>>>>
>>>>>>
>>>>>>   ----- Original Message ----
>>>>>>
>>>>>>> From: Dirk Eddelbuettel<edd at debian.org>
>>>>>>>> To: Patrick Leyshock<ngkbr8es at gmail.com>
>>>>>>>> Cc: r-devel at r-project.org
>>>>>>>> Sent: Mon, January 17, 2011 10:13:36 AM
>>>>>>>> Subject: Re: [Rd] R vs. C
>>>>>>>>
>>>>>>>>
>>>>>>>> On 17 January 2011 at 09:13, Patrick Leyshock wrote:
>>>>>>>> | A question, please about development of R packages:
>>>>>>>> |
>>>>>>>> | Are there any guidelines or best practices for deciding when and
>>>>>>>> why
>>>>>>>> to
>>>>>>>> | implement an operation in R, vs. implementing it in C?  The
>>>>>>>> "Writing
>>>>>>>> R
>>>>>>>> | Extensions" recommends "working in interpreted R code . . . this is
>>>>>>>> normally
>>>>>>>> | the best option."  But we do write C-functions and access them in R
>>>>>>>> -
>>>>>>>> the
>>>>>>>> | question is, when/why is this justified, and when/why is it NOT
>>>>>>>> justified?
>>>>>>>> |
>>>>>>>> | While I have identified helpful documents on R coding standards, I
>>>>>>>> have
>>>>>>>> not
>>>>>>>> | seen notes/discussions on when/why to implement in R, vs. when to
>>>>>>>> implement
>>>>>>>> | in C.
>>>>>>>>
>>>>>>>> The (still fairly recent) book 'Software for Data Analysis:
>>>>>>>> Programming
>>>>>>>> with
>>>>>>>> R' by John Chambers (Springer, 2008) has a lot to say about this.
>>>>>>>>   John
>>>>>>>> also
>>>>>>>> gave a talk in November which stressed 'multilanguage' approaches;
>>>>>>>> see
>>>>>>>> e.g.
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>> http://blog.revolutionanalytics.com/2010/11/john-chambers-on-r-and-multilingualism.html
>>>>>>>>
>>>>>>>>
>>>>>>>> In short, it all depends, and it is unlikely that you will get a
>>>>>>>> coherent
>>>>>>>> answer that is valid for all circumstances.  We all love R for how
>>>>>>>> expressive
>>>>>>>> and powerful it is, yet there are times when something else is called
>>>>>>>> for.
>>>>>>>> Exactly when that time is depends on a great many things and you have
>>>>>>>> not
>>>>>>>> mentioned a single metric in your question.  So I'd start with John's
>>>>>>>> book.
>>>>>>>>
>>>>>>>> Hope this helps, Dirk
>>>>>>>>
>>>>>>>>   ______________________________________________
>>>>>>>>
>>>>>>> R-devel at r-project.org mailing list
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>>>>
>>>>>>>   ______________________________________________
>>>>>>
>>>>> R-devel at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>>
>>>>>
>>>>> ====================================================================================
>>>>>
>>>>> La version fran?aise suit le texte anglais.
>>>>>
>>>>>
>>>>>
>>>>> ------------------------------------------------------------------------------------
>>>>>
>>>>> This email may contain privileged and/or confidential information, and
>>>>> the
>>>>> Bank of
>>>>> Canada does not waive any related rights. Any distribution, use, or
>>>>> copying of this
>>>>> email or the information it contains by other than the intended
>>>>> recipient
>>>>> is
>>>>> unauthorized. If you received this email in error please delete it
>>>>> immediately from
>>>>> your system and notify the sender promptly by email that you have done
>>>>> so.
>>>>>
>>>>>
>>>>>
>>>>> ------------------------------------------------------------------------------------
>>>>>
>>>>> Le pr?sent courriel peut contenir de l'information privil?gi?e ou
>>>>> confidentielle.
>>>>> La Banque du Canada ne renonce pas aux droits qui s'y rapportent. Toute
>>>>> diffusion,
>>>>> utilisation ou copie de ce courriel ou des renseignements qu'il contient
>>>>> par une
>>>>> personne autre que le ou les destinataires d?sign?s est interdite. Si
>>>>> vous
>>>>> recevez
>>>>> ce courriel par erreur, veuillez le supprimer imm?diatement et envoyer
>>>>> sans d?lai ?
>>>>> l'exp?diteur un message ?lectronique pour l'aviser que vous avez ?limin?
>>>>> de votre
>>>>> ordinateur toute copie du courriel re?u.
>>>>>
>>>>
>
> 	[[alternative HTML version deleted]]
>
>
>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
Claudia Beleites
Dipartimento dei Materiali e delle Risorse Naturali
Universit? degli Studi di Trieste
Via Alfonso Valerio 6/a
I-34127 Trieste

phone: +39 0 40 5 58-37 68
email: cbeleites at units.it


From pburns at pburns.seanet.com  Tue Jan 18 10:53:50 2011
From: pburns at pburns.seanet.com (Patrick Burns)
Date: Tue, 18 Jan 2011 09:53:50 +0000
Subject: [Rd] R vs. C
In-Reply-To: <4D34BF78.7040301@structuremonitoring.com>
References: <AANLkTikbHjP7JvwfWjSaWds7fa4Ek=8LEo14h-Rm5igq@mail.gmail.com>	<19764.34512.640668.433147@max.nulle.part>	<891858.34031.qm@web113714.mail.gq1.yahoo.com>	<4D3493B2.2070907@structuremonitoring.com>	<AANLkTim1jCxVaPLoES_7JZ+0OxeGtAGGReHNFLSOFaPU@mail.gmail.com>	<4D34AD52.20704@structuremonitoring.com>	<6441154A9FF1CD4386AF4ABF141A056D2150F03C@WMEXOSCD2-N2.bocad.bank-banque-canada.ca>
	<4D34BF78.7040301@structuremonitoring.com>
Message-ID: <4D35632E.8040405@pburns.seanet.com>

I'm not at all a fan of thinking
of the examples as being tests.

Examples should clarify the thinking
of potential users.  Tests should
clarify the space in which the code
is correct.  These two goals are
generally at odds.

On 17/01/2011 22:15, Spencer Graves wrote:
> Hi, Paul:
>
>
> The "Writing R Extensions" manual says that *.R code in a "tests"
> directory is run during "R CMD check". I suspect that many R programmers
> do this routinely. I probably should do that also. However, for me, it's
> simpler to have everything in the "examples" section of *.Rd files. I
> think the examples with independently developed answers provides useful
> documentation.
>
>
> Spencer
>
>
> On 1/17/2011 1:52 PM, Paul Gilbert wrote:
>> Spencer
>>
>> Would it not be easier to include this kind of test in a small file in
>> the tests/ directory?
>>
>> Paul
>>
>> -----Original Message-----
>> From: r-devel-bounces at r-project.org
>> [mailto:r-devel-bounces at r-project.org] On Behalf Of Spencer Graves
>> Sent: January 17, 2011 3:58 PM
>> To: Dominick Samperi
>> Cc: Patrick Leyshock; r-devel at r-project.org; Dirk Eddelbuettel
>> Subject: Re: [Rd] R vs. C
>>
>>
>> For me, a major strength of R is the package development
>> process. I've found this so valuable that I created a Wikipedia entry
>> by that name and made additions to a Wikipedia entry on "software
>> repository", noting that this process encourages good software
>> development practices that I have not seen standardized for other
>> languages. I encourage people to review this material and make
>> additions or corrections as they like (or sent me suggestions for me to
>> make appropriate changes).
>>
>>
>> While R has other capabilities for unit and regression testing, I
>> often include unit tests in the "examples" section of documentation
>> files. To keep from cluttering the examples with unnecessary material,
>> I often include something like the following:
>>
>>
>> A1<- myfunc() # to test myfunc
>>
>> A0<- ("manual generation of the correct answer for A1")
>>
>> \dontshow{stopifnot(} # so the user doesn't see "stopifnot("
>> all.equal(A1, A0) # compare myfunc output with the correct answer
>> \dontshow{)} # close paren on "stopifnot(".
>>
>>
>> This may not be as good in some ways as a full suite of unit
>> tests, which could be provided separately. However, this has the
>> distinct advantage of including unit tests with the documentation in a
>> way that should help users understand "myfunc". (Unit tests too
>> detailed to show users could be completely enclosed in "\dontshow".
>>
>>
>> Spencer
>>
>>
>> On 1/17/2011 11:38 AM, Dominick Samperi wrote:
>>> On Mon, Jan 17, 2011 at 2:08 PM, Spencer Graves<
>>> spencer.graves at structuremonitoring.com> wrote:
>>>
>>>> Another point I have not yet seen mentioned: If your code is
>>>> painfully slow, that can often be fixed without leaving R by
>>>> experimenting
>>>> with different ways of doing the same thing -- often after using
>>>> profiling
>>>> your code to find the slowest part as described in chapter 3 of
>>>> "Writing R
>>>> Extensions".
>>>>
>>>>
>>>> If I'm given code already written in C (or some other language),
>>>> unless it's really simple, I may link to it rather than recode it in R.
>>>> However, the problems with portability, maintainability,
>>>> transparency to
>>>> others who may not be very facile with C, etc., all suggest that
>>>> it's well
>>>> worth some effort experimenting with alternate ways of doing the
>>>> same thing
>>>> in R before jumping to C or something else.
>>>>
>>>> Hope this helps.
>>>> Spencer
>>>>
>>>>
>>>>
>>>> On 1/17/2011 10:57 AM, David Henderson wrote:
>>>>
>>>>> I think we're also forgetting something, namely testing. If you write
>>>>> your
>>>>> routine in C, you have placed additional burden upon yourself to
>>>>> test your
>>>>> C
>>>>> code through unit tests, etc. If you write your code in R, you
>>>>> still need
>>>>> the
>>>>> unit tests, but you can rely on the well tested nature of R to
>>>>> allow you
>>>>> to
>>>>> reduce the number of tests of your algorithm. I routinely tell
>>>>> people at
>>>>> Sage
>>>>> Bionetworks where I am working now that your new C code needs to
>>>>> experience at
>>>>> least one order of magnitude increase in performance to warrant the
>>>>> effort
>>>>> of
>>>>> moving from R to C.
>>>>>
>>>>> But, then again, I am working with scientists who are not
>>>>> primarily, or
>>>>> even
>>>>> secondarily, coders...
>>>>>
>>>>> Dave H
>>>>>
>>>>>
>>> This makes sense, but I have seem some very transparent algorithms
>>> turned
>>> into vectorized R code
>>> that is difficult to read (and thus to maintain or to change). These
>>> chunks
>>> of optimized R code are like
>>> embedded assembly, in the sense that nobody is likely to want to mess
>>> with
>>> it. This could be addressed
>>> by including pseudo code for the original (more transparent)
>>> algorithm as a
>>> comment, but I have never
>>> seen this done in practice (perhaps it could be enforced by R CMD
>>> check?!).
>>>
>>> On the other hand, in principle a well-documented piece of C/C++ code
>>> could
>>> be much easier to understand,
>>> without paying a performance penalty...but "coders" are not likely to
>>> place
>>> this high on their
>>> list of priorities.
>>>
>>> The bottom like is that R is an adaptor ("glue") language like Lisp that
>>> makes it easy to mix and
>>> match functions (using classes and generic functions), many of which are
>>> written in C (or C++
>>> or Fortran) for performance reasons. Like any object-based system
>>> there can
>>> be a lot of
>>> object copying, and like any functional programming system, there can
>>> be a
>>> lot of function
>>> calls, resulting in poor performance for some applications.
>>>
>>> If you can vectorize your R code then you have effectively found a
>>> way to
>>> benefit from
>>> somebody else's C code, thus saving yourself some time. For
>>> operations other
>>> than pure
>>> vector calculations you will have to do the C/C++ programming
>>> yourself (or
>>> call a library
>>> that somebody else has written).
>>>
>>> Dominick
>>>
>>>
>>>
>>>>> ----- Original Message ----
>>>>> From: Dirk Eddelbuettel<edd at debian.org>
>>>>> To: Patrick Leyshock<ngkbr8es at gmail.com>
>>>>> Cc: r-devel at r-project.org
>>>>> Sent: Mon, January 17, 2011 10:13:36 AM
>>>>> Subject: Re: [Rd] R vs. C
>>>>>
>>>>>
>>>>> On 17 January 2011 at 09:13, Patrick Leyshock wrote:
>>>>> | A question, please about development of R packages:
>>>>> |
>>>>> | Are there any guidelines or best practices for deciding when and
>>>>> why to
>>>>> | implement an operation in R, vs. implementing it in C? The
>>>>> "Writing R
>>>>> | Extensions" recommends "working in interpreted R code . . . this is
>>>>> normally
>>>>> | the best option." But we do write C-functions and access them in R -
>>>>> the
>>>>> | question is, when/why is this justified, and when/why is it NOT
>>>>> justified?
>>>>> |
>>>>> | While I have identified helpful documents on R coding standards,
>>>>> I have
>>>>> not
>>>>> | seen notes/discussions on when/why to implement in R, vs. when to
>>>>> implement
>>>>> | in C.
>>>>>
>>>>> The (still fairly recent) book 'Software for Data Analysis:
>>>>> Programming
>>>>> with
>>>>> R' by John Chambers (Springer, 2008) has a lot to say about this. John
>>>>> also
>>>>> gave a talk in November which stressed 'multilanguage' approaches; see
>>>>> e.g.
>>>>>
>>>>> http://blog.revolutionanalytics.com/2010/11/john-chambers-on-r-and-multilingualism.html
>>>>>
>>>>>
>>>>>
>>>>> In short, it all depends, and it is unlikely that you will get a
>>>>> coherent
>>>>> answer that is valid for all circumstances. We all love R for how
>>>>> expressive
>>>>> and powerful it is, yet there are times when something else is
>>>>> called for.
>>>>> Exactly when that time is depends on a great many things and you
>>>>> have not
>>>>> mentioned a single metric in your question. So I'd start with John's
>>>>> book.
>>>>>
>>>>> Hope this helps, Dirk
>>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> ====================================================================================
>>
>>
>> La version fran?aise suit le texte anglais.
>>
>> ------------------------------------------------------------------------------------
>>
>>
>> This email may contain privileged and/or confidential ...{{dropped:25}}
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Patrick Burns
pburns at pburns.seanet.com
twitter: @portfolioprobe
http://www.portfolioprobe.com/blog
http://www.burns-stat.com
(home of 'Some hints for the R beginner'
and 'The R Inferno')


From cbeleites at units.it  Tue Jan 18 12:36:48 2011
From: cbeleites at units.it (Claudia Beleites)
Date: Tue, 18 Jan 2011 12:36:48 +0100
Subject: [Rd] R vs. C
In-Reply-To: <4D35632E.8040405@pburns.seanet.com>
References: <AANLkTikbHjP7JvwfWjSaWds7fa4Ek=8LEo14h-Rm5igq@mail.gmail.com>	<19764.34512.640668.433147@max.nulle.part>	<891858.34031.qm@web113714.mail.gq1.yahoo.com>	<4D3493B2.2070907@structuremonitoring.com>	<AANLkTim1jCxVaPLoES_7JZ+0OxeGtAGGReHNFLSOFaPU@mail.gmail.com>	<4D34AD52.20704@structuremonitoring.com>	<6441154A9FF1CD4386AF4ABF141A056D2150F03C@WMEXOSCD2-N2.bocad.bank-banque-canada.ca>	<4D34BF78.7040301@structuremonitoring.com>
	<4D35632E.8040405@pburns.seanet.com>
Message-ID: <4D357B50.1050509@units.it>

On 01/18/2011 10:53 AM, Patrick Burns wrote:
> I'm not at all a fan of thinking
> of the examples as being tests.
>
> Examples should clarify the thinking
> of potential users. Tests should
> clarify the space in which the code
> is correct. These two goals are
> generally at odds.

Patrick, I completely agree with you that
- Tests should not clutter the documentation and go to their proper place.
- Examples are there for the user's benefit - and must be written accordingly.
- Often, test should cover far more situations than good examples.

Yet it seems to me that (part of the) examples are justly considered a (small) 
subset of the tests:
As a potential user, I reqest two things from good examples that have an 
implicit testing message/side effect:
- I like the examples to roughly outline the space in which the code works: they 
should tell me what I'm supposed to do.
- Depending on the function's purpose, I like to see a demonstration of the 
correctness for some example calculation.
(I don't want to see all further tests - I can look them up if I feel the need)

The fact that the very same line of example code serves a testing (side) purpose 
  doesn't mean that it should be copied into the tests, does it?

Thus, I think of the "public" part (the "preface") of the tests living in the 
examples.

My 2 ct,
Best regards,

Claudia



>
> On 17/01/2011 22:15, Spencer Graves wrote:
>> Hi, Paul:
>>
>>
>> The "Writing R Extensions" manual says that *.R code in a "tests"
>> directory is run during "R CMD check". I suspect that many R programmers
>> do this routinely. I probably should do that also. However, for me, it's
>> simpler to have everything in the "examples" section of *.Rd files. I
>> think the examples with independently developed answers provides useful
>> documentation.
>>
>>
>> Spencer
>>
>>
>> On 1/17/2011 1:52 PM, Paul Gilbert wrote:
>>> Spencer
>>>
>>> Would it not be easier to include this kind of test in a small file in
>>> the tests/ directory?
>>>
>>> Paul
>>>
>>> -----Original Message-----
>>> From: r-devel-bounces at r-project.org
>>> [mailto:r-devel-bounces at r-project.org] On Behalf Of Spencer Graves
>>> Sent: January 17, 2011 3:58 PM
>>> To: Dominick Samperi
>>> Cc: Patrick Leyshock; r-devel at r-project.org; Dirk Eddelbuettel
>>> Subject: Re: [Rd] R vs. C
>>>
>>>
>>> For me, a major strength of R is the package development
>>> process. I've found this so valuable that I created a Wikipedia entry
>>> by that name and made additions to a Wikipedia entry on "software
>>> repository", noting that this process encourages good software
>>> development practices that I have not seen standardized for other
>>> languages. I encourage people to review this material and make
>>> additions or corrections as they like (or sent me suggestions for me to
>>> make appropriate changes).
>>>
>>>
>>> While R has other capabilities for unit and regression testing, I
>>> often include unit tests in the "examples" section of documentation
>>> files. To keep from cluttering the examples with unnecessary material,
>>> I often include something like the following:
>>>
>>>
>>> A1<- myfunc() # to test myfunc
>>>
>>> A0<- ("manual generation of the correct answer for A1")
>>>
>>> \dontshow{stopifnot(} # so the user doesn't see "stopifnot("
>>> all.equal(A1, A0) # compare myfunc output with the correct answer
>>> \dontshow{)} # close paren on "stopifnot(".
>>>
>>>
>>> This may not be as good in some ways as a full suite of unit
>>> tests, which could be provided separately. However, this has the
>>> distinct advantage of including unit tests with the documentation in a
>>> way that should help users understand "myfunc". (Unit tests too
>>> detailed to show users could be completely enclosed in "\dontshow".
>>>
>>>
>>> Spencer
>>>
>>>
>>> On 1/17/2011 11:38 AM, Dominick Samperi wrote:
>>>> On Mon, Jan 17, 2011 at 2:08 PM, Spencer Graves<
>>>> spencer.graves at structuremonitoring.com> wrote:
>>>>
>>>>> Another point I have not yet seen mentioned: If your code is
>>>>> painfully slow, that can often be fixed without leaving R by
>>>>> experimenting
>>>>> with different ways of doing the same thing -- often after using
>>>>> profiling
>>>>> your code to find the slowest part as described in chapter 3 of
>>>>> "Writing R
>>>>> Extensions".
>>>>>
>>>>>
>>>>> If I'm given code already written in C (or some other language),
>>>>> unless it's really simple, I may link to it rather than recode it in R.
>>>>> However, the problems with portability, maintainability,
>>>>> transparency to
>>>>> others who may not be very facile with C, etc., all suggest that
>>>>> it's well
>>>>> worth some effort experimenting with alternate ways of doing the
>>>>> same thing
>>>>> in R before jumping to C or something else.
>>>>>
>>>>> Hope this helps.
>>>>> Spencer
>>>>>
>>>>>
>>>>>
>>>>> On 1/17/2011 10:57 AM, David Henderson wrote:
>>>>>
>>>>>> I think we're also forgetting something, namely testing. If you write
>>>>>> your
>>>>>> routine in C, you have placed additional burden upon yourself to
>>>>>> test your
>>>>>> C
>>>>>> code through unit tests, etc. If you write your code in R, you
>>>>>> still need
>>>>>> the
>>>>>> unit tests, but you can rely on the well tested nature of R to
>>>>>> allow you
>>>>>> to
>>>>>> reduce the number of tests of your algorithm. I routinely tell
>>>>>> people at
>>>>>> Sage
>>>>>> Bionetworks where I am working now that your new C code needs to
>>>>>> experience at
>>>>>> least one order of magnitude increase in performance to warrant the
>>>>>> effort
>>>>>> of
>>>>>> moving from R to C.
>>>>>>
>>>>>> But, then again, I am working with scientists who are not
>>>>>> primarily, or
>>>>>> even
>>>>>> secondarily, coders...
>>>>>>
>>>>>> Dave H
>>>>>>
>>>>>>
>>>> This makes sense, but I have seem some very transparent algorithms
>>>> turned
>>>> into vectorized R code
>>>> that is difficult to read (and thus to maintain or to change). These
>>>> chunks
>>>> of optimized R code are like
>>>> embedded assembly, in the sense that nobody is likely to want to mess
>>>> with
>>>> it. This could be addressed
>>>> by including pseudo code for the original (more transparent)
>>>> algorithm as a
>>>> comment, but I have never
>>>> seen this done in practice (perhaps it could be enforced by R CMD
>>>> check?!).
>>>>
>>>> On the other hand, in principle a well-documented piece of C/C++ code
>>>> could
>>>> be much easier to understand,
>>>> without paying a performance penalty...but "coders" are not likely to
>>>> place
>>>> this high on their
>>>> list of priorities.
>>>>
>>>> The bottom like is that R is an adaptor ("glue") language like Lisp that
>>>> makes it easy to mix and
>>>> match functions (using classes and generic functions), many of which are
>>>> written in C (or C++
>>>> or Fortran) for performance reasons. Like any object-based system
>>>> there can
>>>> be a lot of
>>>> object copying, and like any functional programming system, there can
>>>> be a
>>>> lot of function
>>>> calls, resulting in poor performance for some applications.
>>>>
>>>> If you can vectorize your R code then you have effectively found a
>>>> way to
>>>> benefit from
>>>> somebody else's C code, thus saving yourself some time. For
>>>> operations other
>>>> than pure
>>>> vector calculations you will have to do the C/C++ programming
>>>> yourself (or
>>>> call a library
>>>> that somebody else has written).
>>>>
>>>> Dominick
>>>>
>>>>
>>>>
>>>>>> ----- Original Message ----
>>>>>> From: Dirk Eddelbuettel<edd at debian.org>
>>>>>> To: Patrick Leyshock<ngkbr8es at gmail.com>
>>>>>> Cc: r-devel at r-project.org
>>>>>> Sent: Mon, January 17, 2011 10:13:36 AM
>>>>>> Subject: Re: [Rd] R vs. C
>>>>>>
>>>>>>
>>>>>> On 17 January 2011 at 09:13, Patrick Leyshock wrote:
>>>>>> | A question, please about development of R packages:
>>>>>> |
>>>>>> | Are there any guidelines or best practices for deciding when and
>>>>>> why to
>>>>>> | implement an operation in R, vs. implementing it in C? The
>>>>>> "Writing R
>>>>>> | Extensions" recommends "working in interpreted R code . . . this is
>>>>>> normally
>>>>>> | the best option." But we do write C-functions and access them in R -
>>>>>> the
>>>>>> | question is, when/why is this justified, and when/why is it NOT
>>>>>> justified?
>>>>>> |
>>>>>> | While I have identified helpful documents on R coding standards,
>>>>>> I have
>>>>>> not
>>>>>> | seen notes/discussions on when/why to implement in R, vs. when to
>>>>>> implement
>>>>>> | in C.
>>>>>>
>>>>>> The (still fairly recent) book 'Software for Data Analysis:
>>>>>> Programming
>>>>>> with
>>>>>> R' by John Chambers (Springer, 2008) has a lot to say about this. John
>>>>>> also
>>>>>> gave a talk in November which stressed 'multilanguage' approaches; see
>>>>>> e.g.
>>>>>>
>>>>>> http://blog.revolutionanalytics.com/2010/11/john-chambers-on-r-and-multilingualism.html
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>> In short, it all depends, and it is unlikely that you will get a
>>>>>> coherent
>>>>>> answer that is valid for all circumstances. We all love R for how
>>>>>> expressive
>>>>>> and powerful it is, yet there are times when something else is
>>>>>> called for.
>>>>>> Exactly when that time is depends on a great many things and you
>>>>>> have not
>>>>>> mentioned a single metric in your question. So I'd start with John's
>>>>>> book.
>>>>>>
>>>>>> Hope this helps, Dirk
>>>>>>
>>>>> ______________________________________________
>>>>> R-devel at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>> ====================================================================================
>>>
>>>
>>>
>>> La version fran?aise suit le texte anglais.
>>>
>>> ------------------------------------------------------------------------------------
>>>
>>>
>>>
>>> This email may contain privileged and/or confidential ...{{dropped:25}}
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>


-- 
Claudia Beleites
Dipartimento dei Materiali e delle Risorse Naturali
Universit? degli Studi di Trieste
Via Alfonso Valerio 6/a
I-34127 Trieste

phone: +39 0 40 5 58-37 68
email: cbeleites at units.it


From pburns at pburns.seanet.com  Tue Jan 18 12:54:39 2011
From: pburns at pburns.seanet.com (Patrick Burns)
Date: Tue, 18 Jan 2011 11:54:39 +0000
Subject: [Rd] R vs. C
In-Reply-To: <4D357B50.1050509@units.it>
References: <AANLkTikbHjP7JvwfWjSaWds7fa4Ek=8LEo14h-Rm5igq@mail.gmail.com>	<19764.34512.640668.433147@max.nulle.part>	<891858.34031.qm@web113714.mail.gq1.yahoo.com>	<4D3493B2.2070907@structuremonitoring.com>	<AANLkTim1jCxVaPLoES_7JZ+0OxeGtAGGReHNFLSOFaPU@mail.gmail.com>	<4D34AD52.20704@structuremonitoring.com>	<6441154A9FF1CD4386AF4ABF141A056D2150F03C@WMEXOSCD2-N2.bocad.bank-banque-canada.ca>	<4D34BF78.7040301@structuremonitoring.com>
	<4D35632E.8040405@pburns.seanet.com> <4D357B50.1050509@units.it>
Message-ID: <4D357F7F.6020808@pburns.seanet.com>

Claudia,

I think we agree.

Having the examples run in the
tests is a good thing, I think.
They might strengthen the tests
some (especially if there are
no other tests).  But mainly if
examples don't work, then it's
hard to have much faith in the
code.

On 18/01/2011 11:36, Claudia Beleites wrote:
> On 01/18/2011 10:53 AM, Patrick Burns wrote:
>> I'm not at all a fan of thinking
>> of the examples as being tests.
>>
>> Examples should clarify the thinking
>> of potential users. Tests should
>> clarify the space in which the code
>> is correct. These two goals are
>> generally at odds.
>
> Patrick, I completely agree with you that
> - Tests should not clutter the documentation and go to their proper place.
> - Examples are there for the user's benefit - and must be written
> accordingly.
> - Often, test should cover far more situations than good examples.
>
> Yet it seems to me that (part of the) examples are justly considered a
> (small) subset of the tests:
> As a potential user, I reqest two things from good examples that have an
> implicit testing message/side effect:
> - I like the examples to roughly outline the space in which the code
> works: they should tell me what I'm supposed to do.
> - Depending on the function's purpose, I like to see a demonstration of
> the correctness for some example calculation.
> (I don't want to see all further tests - I can look them up if I feel
> the need)
>
> The fact that the very same line of example code serves a testing (side)
> purpose doesn't mean that it should be copied into the tests, does it?
>
> Thus, I think of the "public" part (the "preface") of the tests living
> in the examples.
>
> My 2 ct,
> Best regards,
>
> Claudia
>
>
>
>>
>> On 17/01/2011 22:15, Spencer Graves wrote:
>>> Hi, Paul:
>>>
>>>
>>> The "Writing R Extensions" manual says that *.R code in a "tests"
>>> directory is run during "R CMD check". I suspect that many R programmers
>>> do this routinely. I probably should do that also. However, for me, it's
>>> simpler to have everything in the "examples" section of *.Rd files. I
>>> think the examples with independently developed answers provides useful
>>> documentation.
>>>
>>>
>>> Spencer
>>>
>>>
>>> On 1/17/2011 1:52 PM, Paul Gilbert wrote:
>>>> Spencer
>>>>
>>>> Would it not be easier to include this kind of test in a small file in
>>>> the tests/ directory?
>>>>
>>>> Paul
>>>>
>>>> -----Original Message-----
>>>> From: r-devel-bounces at r-project.org
>>>> [mailto:r-devel-bounces at r-project.org] On Behalf Of Spencer Graves
>>>> Sent: January 17, 2011 3:58 PM
>>>> To: Dominick Samperi
>>>> Cc: Patrick Leyshock; r-devel at r-project.org; Dirk Eddelbuettel
>>>> Subject: Re: [Rd] R vs. C
>>>>
>>>>
>>>> For me, a major strength of R is the package development
>>>> process. I've found this so valuable that I created a Wikipedia entry
>>>> by that name and made additions to a Wikipedia entry on "software
>>>> repository", noting that this process encourages good software
>>>> development practices that I have not seen standardized for other
>>>> languages. I encourage people to review this material and make
>>>> additions or corrections as they like (or sent me suggestions for me to
>>>> make appropriate changes).
>>>>
>>>>
>>>> While R has other capabilities for unit and regression testing, I
>>>> often include unit tests in the "examples" section of documentation
>>>> files. To keep from cluttering the examples with unnecessary material,
>>>> I often include something like the following:
>>>>
>>>>
>>>> A1<- myfunc() # to test myfunc
>>>>
>>>> A0<- ("manual generation of the correct answer for A1")
>>>>
>>>> \dontshow{stopifnot(} # so the user doesn't see "stopifnot("
>>>> all.equal(A1, A0) # compare myfunc output with the correct answer
>>>> \dontshow{)} # close paren on "stopifnot(".
>>>>
>>>>
>>>> This may not be as good in some ways as a full suite of unit
>>>> tests, which could be provided separately. However, this has the
>>>> distinct advantage of including unit tests with the documentation in a
>>>> way that should help users understand "myfunc". (Unit tests too
>>>> detailed to show users could be completely enclosed in "\dontshow".
>>>>
>>>>
>>>> Spencer
>>>>
>>>>
>>>> On 1/17/2011 11:38 AM, Dominick Samperi wrote:
>>>>> On Mon, Jan 17, 2011 at 2:08 PM, Spencer Graves<
>>>>> spencer.graves at structuremonitoring.com> wrote:
>>>>>
>>>>>> Another point I have not yet seen mentioned: If your code is
>>>>>> painfully slow, that can often be fixed without leaving R by
>>>>>> experimenting
>>>>>> with different ways of doing the same thing -- often after using
>>>>>> profiling
>>>>>> your code to find the slowest part as described in chapter 3 of
>>>>>> "Writing R
>>>>>> Extensions".
>>>>>>
>>>>>>
>>>>>> If I'm given code already written in C (or some other language),
>>>>>> unless it's really simple, I may link to it rather than recode it
>>>>>> in R.
>>>>>> However, the problems with portability, maintainability,
>>>>>> transparency to
>>>>>> others who may not be very facile with C, etc., all suggest that
>>>>>> it's well
>>>>>> worth some effort experimenting with alternate ways of doing the
>>>>>> same thing
>>>>>> in R before jumping to C or something else.
>>>>>>
>>>>>> Hope this helps.
>>>>>> Spencer
>>>>>>
>>>>>>
>>>>>>
>>>>>> On 1/17/2011 10:57 AM, David Henderson wrote:
>>>>>>
>>>>>>> I think we're also forgetting something, namely testing. If you
>>>>>>> write
>>>>>>> your
>>>>>>> routine in C, you have placed additional burden upon yourself to
>>>>>>> test your
>>>>>>> C
>>>>>>> code through unit tests, etc. If you write your code in R, you
>>>>>>> still need
>>>>>>> the
>>>>>>> unit tests, but you can rely on the well tested nature of R to
>>>>>>> allow you
>>>>>>> to
>>>>>>> reduce the number of tests of your algorithm. I routinely tell
>>>>>>> people at
>>>>>>> Sage
>>>>>>> Bionetworks where I am working now that your new C code needs to
>>>>>>> experience at
>>>>>>> least one order of magnitude increase in performance to warrant the
>>>>>>> effort
>>>>>>> of
>>>>>>> moving from R to C.
>>>>>>>
>>>>>>> But, then again, I am working with scientists who are not
>>>>>>> primarily, or
>>>>>>> even
>>>>>>> secondarily, coders...
>>>>>>>
>>>>>>> Dave H
>>>>>>>
>>>>>>>
>>>>> This makes sense, but I have seem some very transparent algorithms
>>>>> turned
>>>>> into vectorized R code
>>>>> that is difficult to read (and thus to maintain or to change). These
>>>>> chunks
>>>>> of optimized R code are like
>>>>> embedded assembly, in the sense that nobody is likely to want to mess
>>>>> with
>>>>> it. This could be addressed
>>>>> by including pseudo code for the original (more transparent)
>>>>> algorithm as a
>>>>> comment, but I have never
>>>>> seen this done in practice (perhaps it could be enforced by R CMD
>>>>> check?!).
>>>>>
>>>>> On the other hand, in principle a well-documented piece of C/C++ code
>>>>> could
>>>>> be much easier to understand,
>>>>> without paying a performance penalty...but "coders" are not likely to
>>>>> place
>>>>> this high on their
>>>>> list of priorities.
>>>>>
>>>>> The bottom like is that R is an adaptor ("glue") language like Lisp
>>>>> that
>>>>> makes it easy to mix and
>>>>> match functions (using classes and generic functions), many of
>>>>> which are
>>>>> written in C (or C++
>>>>> or Fortran) for performance reasons. Like any object-based system
>>>>> there can
>>>>> be a lot of
>>>>> object copying, and like any functional programming system, there can
>>>>> be a
>>>>> lot of function
>>>>> calls, resulting in poor performance for some applications.
>>>>>
>>>>> If you can vectorize your R code then you have effectively found a
>>>>> way to
>>>>> benefit from
>>>>> somebody else's C code, thus saving yourself some time. For
>>>>> operations other
>>>>> than pure
>>>>> vector calculations you will have to do the C/C++ programming
>>>>> yourself (or
>>>>> call a library
>>>>> that somebody else has written).
>>>>>
>>>>> Dominick
>>>>>
>>>>>
>>>>>
>>>>>>> ----- Original Message ----
>>>>>>> From: Dirk Eddelbuettel<edd at debian.org>
>>>>>>> To: Patrick Leyshock<ngkbr8es at gmail.com>
>>>>>>> Cc: r-devel at r-project.org
>>>>>>> Sent: Mon, January 17, 2011 10:13:36 AM
>>>>>>> Subject: Re: [Rd] R vs. C
>>>>>>>
>>>>>>>
>>>>>>> On 17 January 2011 at 09:13, Patrick Leyshock wrote:
>>>>>>> | A question, please about development of R packages:
>>>>>>> |
>>>>>>> | Are there any guidelines or best practices for deciding when and
>>>>>>> why to
>>>>>>> | implement an operation in R, vs. implementing it in C? The
>>>>>>> "Writing R
>>>>>>> | Extensions" recommends "working in interpreted R code . . .
>>>>>>> this is
>>>>>>> normally
>>>>>>> | the best option." But we do write C-functions and access them
>>>>>>> in R -
>>>>>>> the
>>>>>>> | question is, when/why is this justified, and when/why is it NOT
>>>>>>> justified?
>>>>>>> |
>>>>>>> | While I have identified helpful documents on R coding standards,
>>>>>>> I have
>>>>>>> not
>>>>>>> | seen notes/discussions on when/why to implement in R, vs. when to
>>>>>>> implement
>>>>>>> | in C.
>>>>>>>
>>>>>>> The (still fairly recent) book 'Software for Data Analysis:
>>>>>>> Programming
>>>>>>> with
>>>>>>> R' by John Chambers (Springer, 2008) has a lot to say about this.
>>>>>>> John
>>>>>>> also
>>>>>>> gave a talk in November which stressed 'multilanguage'
>>>>>>> approaches; see
>>>>>>> e.g.
>>>>>>>
>>>>>>> http://blog.revolutionanalytics.com/2010/11/john-chambers-on-r-and-multilingualism.html
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>> In short, it all depends, and it is unlikely that you will get a
>>>>>>> coherent
>>>>>>> answer that is valid for all circumstances. We all love R for how
>>>>>>> expressive
>>>>>>> and powerful it is, yet there are times when something else is
>>>>>>> called for.
>>>>>>> Exactly when that time is depends on a great many things and you
>>>>>>> have not
>>>>>>> mentioned a single metric in your question. So I'd start with John's
>>>>>>> book.
>>>>>>>
>>>>>>> Hope this helps, Dirk
>>>>>>>
>>>>>> ______________________________________________
>>>>>> R-devel at r-project.org mailing list
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>> ====================================================================================
>>>>
>>>>
>>>>
>>>>
>>>> La version fran?aise suit le texte anglais.
>>>>
>>>> ------------------------------------------------------------------------------------
>>>>
>>>>
>>>>
>>>>
>>>> This email may contain privileged and/or confidential ...{{dropped:25}}
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
>

-- 
Patrick Burns
pburns at pburns.seanet.com
twitter: @portfolioprobe
http://www.portfolioprobe.com/blog
http://www.burns-stat.com
(home of 'Some hints for the R beginner'
and 'The R Inferno')


From plfjohnson at emory.edu  Mon Jan 17 23:06:02 2011
From: plfjohnson at emory.edu (Philip Johnson)
Date: Mon, 17 Jan 2011 17:06:02 -0500
Subject: [Rd] format scientific + plotmath potential bug
Message-ID: <4D34BD4A.8030503@emory.edu>

I have run into a potential bug somewhere between format (specifically 
scientific notation) and plotmath that results in displaying:
	$1e+01^{2e+00}$
instead of
	$10^2$

Reproduce by:
	plot.new()
	a=format(10, scientific=TRUE)
	mtext(expression(10^2), line=1) # looks like $1e+01^{2e+00}$
	10 # this fixes the problem on the next line
	mtext(expression(10^2), line=2) # looks like $10^2$

I can narrow the trigger somewhat further by replacing the "a=..." line 
with:
	a=.Internal(format(10, FALSE, NULL, 0L, NULL, 3L, TRUE, TRUE))
Tracing this call into the C started giving me a headache, so I'm hoping 
that one of the R core gurus can confirm & file a bug report if necessary.

I ran into this on Ubuntu / Lucid using R version 2.10.1 (2009-12-14).
I confirmed it still exists in R 2.12.1 (2010-12-16) on a fresh install 
of Ubuntu / Maverick.

Thanks,
Philip


From murdoch.duncan at gmail.com  Tue Jan 18 14:24:48 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 18 Jan 2011 08:24:48 -0500
Subject: [Rd] format scientific + plotmath potential bug
In-Reply-To: <4D34BD4A.8030503@emory.edu>
References: <4D34BD4A.8030503@emory.edu>
Message-ID: <4D3594A0.3040205@gmail.com>

On 17/01/2011 5:06 PM, Philip Johnson wrote:
> I have run into a potential bug somewhere between format (specifically
> scientific notation) and plotmath that results in displaying:
> 	$1e+01^{2e+00}$
> instead of
> 	$10^2$
>
> Reproduce by:
> 	plot.new()
> 	a=format(10, scientific=TRUE)
> 	mtext(expression(10^2), line=1) # looks like $1e+01^{2e+00}$
> 	10 # this fixes the problem on the next line
> 	mtext(expression(10^2), line=2) # looks like $10^2$
>
> I can narrow the trigger somewhat further by replacing the "a=..." line
> with:
> 	a=.Internal(format(10, FALSE, NULL, 0L, NULL, 3L, TRUE, TRUE))
> Tracing this call into the C started giving me a headache, so I'm hoping
> that one of the R core gurus can confirm&  file a bug report if necessary.
>
> I ran into this on Ubuntu / Lucid using R version 2.10.1 (2009-12-14).
> I confirmed it still exists in R 2.12.1 (2010-12-16) on a fresh install
> of Ubuntu / Maverick.

Yes, I see this too in R-devel and 2.12.1.  Definitely a bug, and I've 
submitted it to the bug system:

https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=14477

If you want to be kept up to date about fixes you can add yourself to 
the CC list there.

Duncan Murdoch


From guxiaobo1982 at gmail.com  Tue Jan 18 15:42:05 2011
From: guxiaobo1982 at gmail.com (Xiaobo Gu)
Date: Tue, 18 Jan 2011 22:42:05 +0800
Subject: [Rd] RPostgreSQL 0.1.7 for Windows 64 causes R.2.12.1 Win64
	crash
In-Reply-To: <alpine.LFD.2.00.1101171711170.2906@toucan.stats.ox.ac.uk>
References: <AANLkTinvoub-z_Le1GVPYswnqTsW1P6MZzLZsztois9K@mail.gmail.com>
	<AANLkTimfKn+qAMP8q2W8nJFvxVdoOM8gYYWZtZU_Jk9w@mail.gmail.com>
	<19764.19953.237115.864920@max.nulle.part>
	<alpine.LFD.2.00.1101171711170.2906@toucan.stats.ox.ac.uk>
Message-ID: <AANLkTi=hX+JF9zPJRzmSi63bpzcVxt4XcHfFOsUhAvFS@mail.gmail.com>

Hi Professor Brian :

I buy a new  64bit Win7 Home basic notebook for working with 64bit R
and PostgreSQL :)

but still now I can't get postgresql-9.0.2-1-windows_x64 installed.

Which version of Win 7 and postgres do you use, can you share the
download URL for 9.0.0.1 of 64bit PostgreSQL, I can't find it form
EnterpriseDB now.

Thanks.

Xiaobo Gu


On Tue, Jan 18, 2011 at 1:22 AM, Prof Brian Ripley
<ripley at stats.ox.ac.uk> wrote:
> On Mon, 17 Jan 2011, Dirk Eddelbuettel wrote:
>
>>
>> On 16 January 2011 at 23:00, Xiaobo Gu wrote:
>> | Is it because of compiler campsites between R and PostgreSQL, R is
>> | compiled by GCC, while PostgreSQL from Enterprise DB is compiled by
>> | Microsoft Visual C ++.
>>
>> So the usual recommendation is to build the matching library (here libpq)
>> with the same compiler, or get the commercial support you are paying for
>> to
>> do it for you.
>>
>> For what it is worth, I deal with one vendor at work where I made that
>> requirement and they had no issue complying / helping me with a MinGW /
>> Rtools-compatible library. ?One of several reasons I like working with
>> that
>> vendor.
>
> And also for what it is worth, RPostgreSQL works for me on x64 Windows 7
> compiled with the Rtools compilers and linked against the initial PostgreSQL
> 9.0 Windows x64 distribution (I've not tried the one you mentioned).
>
> Where C (and not C++) is involved it should be possible to mix DLLs compiled
> by MinGW-w64 and MSVC, and this has been done extensively (after all a lot
> of Windows' own DLLs are compiled with MSVC, as are the Tcl/Tk binaries
> which are distributed with R).
>
>>
>> Dirk
>>
>> | Xiaobo Gu
>> |
>> | On Sat, Jan 15, 2011 at 10:34 AM, Xiaobo Gu <guxiaobo1982 at gmail.com>
>> wrote:
>> | > Hi,
>> | > I build the binary package file of RPostgreSQL 0.1.7 for Windows 2003
>> | > Server R2 64 bit SP2, the software environments are as following:
>> | > ? ? ? ? R 2.12.1 for Win64
>> | > ? ? ? ? RTools212 for Win64
>> | > ? ? ? ? DBI 0.2.5
>> | > ? ? ? ? RPostgreSQL 0.1.7
>> | > ? ? ? ? Postgresql related binaries shipped with
>> | > postgresql-9.0.2-1-windows_x64.exe from EnterpriseDB
>> | >
>> | > The package can be loaded, and driver can be created, but the
>> | > dbConnect function causes the whole RGui crashes,
>> | >
>> | > driver <- dbDriver("PostgreSQL")
>> | > con <- dbConnect(driver, dbname="demo", host="192.168.8.1",
>> | > user="postgres", password="postgres", port=5432)
>> | >
>> |
>> | ______________________________________________
>> | R-devel at r-project.org mailing list
>> | https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>> --
>> Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
> --
> Brian D. Ripley, ? ? ? ? ? ? ? ? ?ripley at stats.ox.ac.uk
> Professor of Applied Statistics, ?http://www.stats.ox.ac.uk/~ripley/
> University of Oxford, ? ? ? ? ? ? Tel: ?+44 1865 272861 (self)
> 1 South Parks Road, ? ? ? ? ? ? ? ? ? ? +44 1865 272866 (PA)
> Oxford OX1 3TG, UK ? ? ? ? ? ? ? ?Fax: ?+44 1865 272595


From djsamperi at gmail.com  Tue Jan 18 17:44:41 2011
From: djsamperi at gmail.com (Dominick Samperi)
Date: Tue, 18 Jan 2011 11:44:41 -0500
Subject: [Rd] R vs. C now rather: how to ease package checking
In-Reply-To: <4D356200.6060004@units.it>
References: <AANLkTikbHjP7JvwfWjSaWds7fa4Ek=8LEo14h-Rm5igq@mail.gmail.com>
	<19764.34512.640668.433147@max.nulle.part>
	<891858.34031.qm@web113714.mail.gq1.yahoo.com>
	<4D3493B2.2070907@structuremonitoring.com>
	<AANLkTim1jCxVaPLoES_7JZ+0OxeGtAGGReHNFLSOFaPU@mail.gmail.com>
	<4D34AD52.20704@structuremonitoring.com>
	<6441154A9FF1CD4386AF4ABF141A056D2150F03C@WMEXOSCD2-N2.bocad.bank-banque-canada.ca>
	<4D34BF78.7040301@structuremonitoring.com>
	<AANLkTi=c961At6WL16g1kBmPgzpfGcPGabWdPG2=bhP9@mail.gmail.com>
	<4D34D807.4020004@structuremonitoring.com>
	<AANLkTim=ZhYg-X-cvQX=W25c3nY3v5AtmjBFA5Ec8F8+@mail.gmail.com>
	<4D356200.6060004@units.it>
Message-ID: <AANLkTi=SHHMr7pRc7zQOfX95d19+nCfhPqwjL1GNF7Oi@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110118/21428072/attachment.pl>

From ripley at stats.ox.ac.uk  Tue Jan 18 17:52:33 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 18 Jan 2011 16:52:33 +0000 (GMT)
Subject: [Rd] format scientific + plotmath potential bug
In-Reply-To: <4D3594A0.3040205@gmail.com>
References: <4D34BD4A.8030503@emory.edu> <4D3594A0.3040205@gmail.com>
Message-ID: <alpine.LFD.2.00.1101181651260.10449@gannet.stats.ox.ac.uk>

I already had a solution under test, so the bug is now fixed and 
closed.

On Tue, 18 Jan 2011, Duncan Murdoch wrote:

> On 17/01/2011 5:06 PM, Philip Johnson wrote:
>> I have run into a potential bug somewhere between format (specifically
>> scientific notation) and plotmath that results in displaying:
>> 	$1e+01^{2e+00}$
>> instead of
>> 	$10^2$
>> 
>> Reproduce by:
>> 	plot.new()
>> 	a=format(10, scientific=TRUE)
>> 	mtext(expression(10^2), line=1) # looks like $1e+01^{2e+00}$
>> 	10 # this fixes the problem on the next line
>> 	mtext(expression(10^2), line=2) # looks like $10^2$
>> 
>> I can narrow the trigger somewhat further by replacing the "a=..." line
>> with:
>> 	a=.Internal(format(10, FALSE, NULL, 0L, NULL, 3L, TRUE, TRUE))
>> Tracing this call into the C started giving me a headache, so I'm hoping
>> that one of the R core gurus can confirm&  file a bug report if necessary.
>> 
>> I ran into this on Ubuntu / Lucid using R version 2.10.1 (2009-12-14).
>> I confirmed it still exists in R 2.12.1 (2010-12-16) on a fresh install
>> of Ubuntu / Maverick.
>
> Yes, I see this too in R-devel and 2.12.1.  Definitely a bug, and I've 
> submitted it to the bug system:
>
> https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=14477
>
> If you want to be kept up to date about fixes you can add yourself to the CC 
> list there.
>
> Duncan Murdoch
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From spencer.graves at structuremonitoring.com  Tue Jan 18 18:13:52 2011
From: spencer.graves at structuremonitoring.com (Spencer Graves)
Date: Tue, 18 Jan 2011 09:13:52 -0800
Subject: [Rd] R vs. C now rather: how to ease package checking
In-Reply-To: <AANLkTi=SHHMr7pRc7zQOfX95d19+nCfhPqwjL1GNF7Oi@mail.gmail.com>
References: <AANLkTikbHjP7JvwfWjSaWds7fa4Ek=8LEo14h-Rm5igq@mail.gmail.com>	<19764.34512.640668.433147@max.nulle.part>	<891858.34031.qm@web113714.mail.gq1.yahoo.com>	<4D3493B2.2070907@structuremonitoring.com>	<AANLkTim1jCxVaPLoES_7JZ+0OxeGtAGGReHNFLSOFaPU@mail.gmail.com>	<4D34AD52.20704@structuremonitoring.com>	<6441154A9FF1CD4386AF4ABF141A056D2150F03C@WMEXOSCD2-N2.bocad.bank-banque-canada.ca>	<4D34BF78.7040301@structuremonitoring.com>	<AANLkTi=c961At6WL16g1kBmPgzpfGcPGabWdPG2=bhP9@mail.gmail.com>	<4D34D807.4020004@structuremonitoring.com>	<AANLkTim=ZhYg-X-cvQX=W25c3nY3v5AtmjBFA5Ec8F8+@mail.gmail.com>	<4D356200.6060004@units.it>
	<AANLkTi=SHHMr7pRc7zQOfX95d19+nCfhPqwjL1GNF7Oi@mail.gmail.com>
Message-ID: <4D35CA50.1070709@structuremonitoring.com>

On 1/18/2011 8:44 AM, Dominick Samperi wrote:
> On Tue, Jan 18, 2011 at 4:48 AM, Claudia Beleites<cbeleites at units.it>wrote:
>
>> On 01/18/2011 01:13 AM, Dominick Samperi wrote:
>>
>>> On Mon, Jan 17, 2011 at 7:00 PM, Spencer Graves<
>>> spencer.graves at structuremonitoring.com>   wrote:
>>>
>>>   Hi, Dominick, et al.:
>>>>
>>>>       Demanding complete unit test suites with all software contributed to
>>>> CRAN would likely cut contributions by a factor of 10 or 100.  For me,
>>>> the R
>>>> package creation process is close to perfection in providing a standard
>>>> process for documentation with places for examples and test suites of
>>>> various kinds.  I mention "perfection", because it makes developing
>>>> "trustworthy software" (Chamber's "prime directive") relatively easy
>>>> without
>>>> forcing people to do things they don't feel comfortable doing.
>>>>
>>>>
>>> I don't think I made myself clear, sorry. I was not suggesting that
>>> package
>>> developers include a complete unit
>>> test suite. I was suggesting that unit testing should be done outside of
>>> the
>>> CRAN release process. Packages
>>> should be submitted for "release" to CRAN after they have been tested (the
>>> responsibility of the package
>>> developers). I understand that the main problem here is that package
>>> developers do not have access to
>>> all supported platforms, so the current process is not likely to change.
>>>
>> Regarding access to all platforms: But there's r-forge where building and
>> checks are done nightly for Linux, Win, and Mac (though for some months now
>> the check protocols are not available for 32 bit Linux and Windows - but I
>> hope they'll be back soon).
>> I found it extremely easy to get an account&  project space and building.
>> Many thanks to r-forge!
>>
> Good point Claudia,
>
> There are packages released to CRAN that
> do not build on some platforms because the unit tests fail. It seems to me
> that this kind of issue could be ironed out with the help of r-forge before
> release, in which case there is no need to run the unit tests for released
> packages.
>
> Dominick

CRAN also runs "R CMD check" on its contributed packages.  I've found 
problems (and fixed) that I couldn't replicate by reviewing the repeated 
checks on both R-Forge and CRAN.


Spencer

> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


-- 
Spencer Graves, PE, PhD
President and Chief Operating Officer
Structure Inspection and Monitoring, Inc.
751 Emerson Ct.
San Jos?, CA 95126
ph:  408-655-4567


From dnadavewa at yahoo.com  Tue Jan 18 18:50:40 2011
From: dnadavewa at yahoo.com (David Henderson)
Date: Tue, 18 Jan 2011 09:50:40 -0800 (PST)
Subject: [Rd] R vs. C
Message-ID: <419620.44772.qm@web113714.mail.gq1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110118/b33c8547/attachment.pl>

From ripley at stats.ox.ac.uk  Wed Jan 19 13:06:52 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 19 Jan 2011 12:06:52 +0000 (GMT)
Subject: [Rd] naresid.exclude query
In-Reply-To: <201101141452.09977.s.wood@bath.ac.uk>
References: <201101141452.09977.s.wood@bath.ac.uk>
Message-ID: <alpine.LFD.2.00.1101191132540.4595@gannet.stats.ox.ac.uk>

There was a reason for that line, as running 'make check' with your 
modification would have shown you.  Sometimes naresid() is called with 
x=NULL.   AFAICS replacing the test with is.null(x) suffices, and I'm 
testing that in R-devel.  If nothing else comes up I will port it to 
R-patched later.

Note that R's own code does not AFAIR call these functions when 
predicting with 'newdata', and a fit with all cases omitted would not 
be very interesting so it is unsurprising no one noticed for >8 years.

On Fri, 14 Jan 2011, Simon Wood wrote:

>  x <- NA
>  na.act <- na.action(na.exclude(x))
>  y <- rep(0,0)
>  naresid(na.act,y)
>
> ... currently produces the result...
>  numeric(0)
>
> ... whereas the documentation might lead you to expect
>  NA
>
> The behaviour is caused by the line
>  if (length(x) == 0L) return(x)
>
> in `stats:::naresid.exclude'. Removing this line results in the behaviour I'd
> expected in the above example (and in a test example where `x' is a zero row
> matrix).
>
> Is the coded behaviour necessary for some reason? Could it be changed (so that
> my example produces NA)? The reason I ask is that I use `napredict' in
> mgcv:predict.gam, and someone complained that if he predicts using newdata
> that is all NA, then he doesn't get what he expected (he has a pretty good
> reason for doing this). Part of the problem with predict.gam in this case was
> my code, but once I fixed that I ran up against the above problem.
>
> Actually, I just checked the source code and the line of naresid.exclude that
> causes the problem already has this comment after it....
>  # << FIXME? -- reconstructing all NA object
> ... so I guess I'm really asking if there is any chance of fixing this soon,
> or whether I should just code up a work-around for predict.gam?
>
> Simon
>
> -- 
>> Simon Wood, Mathematical Sciences, University of Bath, Bath, BA2 7AY UK
>> +44 1225 386603  www.maths.bath.ac.uk/~sw283
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From janko.thyson at ku-eichstaett.de  Wed Jan 19 11:45:49 2011
From: janko.thyson at ku-eichstaett.de (Janko Thyson)
Date: Wed, 19 Jan 2011 11:45:49 +0100
Subject: [Rd] Possible bug in stats::arima (arima.c)
Message-ID: <004d01cbb7c6$08f4f530$1adedf90$@thyson@ku-eichstaett.de>

Dear list,

 

We think we found a bug in the ?arima.c? file of the stats package with
respect to the estimation of SARIMA model coefficients (wrong sign). Please
see the attached PDF file for more details.

 

It?d be great if someone could verify if this is a bug or not.

 

Regards,

Ulrich K?sters and Janko Thyson

-------------- next part --------------
A non-text attachment was scrubbed...
Name: arima_bug.pdf
Type: application/pdf
Size: 146406 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110119/94727d7e/attachment.pdf>

From ripley at stats.ox.ac.uk  Wed Jan 19 15:50:01 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 19 Jan 2011 14:50:01 +0000 (GMT)
Subject: [Rd] formula(model.frame(y~.^2,
 data=d)) does not return formula from terms attribute of the
 model.frame
In-Reply-To: <77EB52C6DD32BA4D87471DCD70C8D70003C2E52B@NA-PA-VBE03.na.tibco.com>
References: <77EB52C6DD32BA4D87471DCD70C8D70003C2E52B@NA-PA-VBE03.na.tibco.com>
Message-ID: <alpine.LFD.2.00.1101191429310.1083@gannet.stats.ox.ac.uk>

On Thu, 6 Jan 2011, William Dunlap wrote:

> In R 2.12.0 I get
>  > d <- data.frame(x=1:10, y=log(1:10), f3=LETTERS[rep(1:3,c(3,3,4))])
>  > m <- model.frame(y~.^2, data=d)
>  > formula(m)
>  y ~ x + f3
> In S+ formula(m) gives formula given to model.frame(),
> but in R you have to do the following get that formula:
>  > formula(attr(m, "terms"))
>  y ~ (x + f3)^2

But that has the advantage that you almost certainly have a model 
frame and hence that is what you intend.  With 6-6 (or 20-20 in 
Imperial units) hindsight it would have been better to give model 
frames a class inheriting from "data frame", but it seems that the 
presence of attr(, "terms") is the most common test.

> Would it break anything to add to the top of

Unfortunately, that is rather hard to tell!

> formula.data.frame
> something like
>  if (!is.null(tms <- attr(x, "terms"))) {
>    return(formula(tms))
>  }
> so that formula() would retrieve the formula buried
> in model.frame's output?

I looked (not hard, but without success) for examples of calling 
formula() on a data frame.  I did see that model.frame.default() calls 
as.formula() on a data frame, but only after checking for the absence 
of a "terms" attribute.

Can you explain where it would help?  I think we need to see examples 
to see if a change in meaning would be clearly beneficial.  I can 
envisage cases in which 'x' was a data frame that just happened to 
have been constructed as a model frame and where the currently 
documented meaning was intended.

> Bill Dunlap
> Spotfire, TIBCO Software
> wdunlap tibco.com

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From wdunlap at tibco.com  Wed Jan 19 23:58:36 2011
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 19 Jan 2011 14:58:36 -0800
Subject: [Rd] buglet in weighted.residuals(mlmObject)
Message-ID: <77EB52C6DD32BA4D87471DCD70C8D70003D65407@NA-PA-VBE03.na.tibco.com>

When weighted.residuals() is given a fitted model
object with several responses (class mlm) and some
zero weights it returns a vector instead of a matrix.
It looks like it is doing
   resids[ weights != 0 ]
instead of
   resids[ weights != 0, , drop=FALSE] 
in the multi-response case.

E.g.,

> d4 <- data.frame(y1=1:4, y2=2^(0:3), wt=log(1:4),
fac=LETTERS[c(1,1,2,2)])
> fit <- lm(data=d4, cbind(y1,y2)~fac, weights=wt)
> weighted.residuals(fit) # expect 3x2 matrix
[1]  1.407294e-16 -5.847465e-01  5.205496e-01  5.950102e-16
-2.338986e+00
[6]  2.082198e+00
> weighted.residuals(fit, drop0=FALSE)
             y1            y2
1  0.000000e+00  0.000000e+00
2  1.407294e-16  5.950102e-16
3 -5.847465e-01 -2.338986e+00
4  5.205496e-01  2.082198e+00

This is in R 2.12.0.  I haven't upgraded yet.

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com 


From wdunlap at tibco.com  Thu Jan 20 00:43:22 2011
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 19 Jan 2011 15:43:22 -0800
Subject: [Rd] formula(model.frame(y~.^2,
	data=d)) does not return formula from terms attribute of the
	model.frame
In-Reply-To: <alpine.LFD.2.00.1101191429310.1083@gannet.stats.ox.ac.uk>
References: <77EB52C6DD32BA4D87471DCD70C8D70003C2E52B@NA-PA-VBE03.na.tibco.com>
	<alpine.LFD.2.00.1101191429310.1083@gannet.stats.ox.ac.uk>
Message-ID: <77EB52C6DD32BA4D87471DCD70C8D70003D65438@NA-PA-VBE03.na.tibco.com>

It is not terribly important, but I had a model.frame
which I forgot was a model.frame and was surprised that
   lm(modelFrame)
gave me a result based on the different formula than
   formula(modelFrame)
showed.

S+'s formula() makes those consistent (and it also
makes model.frame's output have class "model.frame"
instead of just "data.frame").  That is inherited
from S version 3.  R has formula methods (especially
in package:nlme) to extract the formula from lots
of other kinds of objects, but not for model.frames.

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com  

> -----Original Message-----
> From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk] 
> Sent: Wednesday, January 19, 2011 6:50 AM
> To: William Dunlap
> Cc: r-devel at r-project.org
> Subject: Re: [Rd] formula(model.frame(y~.^2, data=d)) does 
> not return formula from terms attribute of the model.frame
> 
> On Thu, 6 Jan 2011, William Dunlap wrote:
> 
> > In R 2.12.0 I get
> >  > d <- data.frame(x=1:10, y=log(1:10), 
> f3=LETTERS[rep(1:3,c(3,3,4))])
> >  > m <- model.frame(y~.^2, data=d)
> >  > formula(m)
> >  y ~ x + f3
> > In S+ formula(m) gives formula given to model.frame(),
> > but in R you have to do the following get that formula:
> >  > formula(attr(m, "terms"))
> >  y ~ (x + f3)^2
> 
> But that has the advantage that you almost certainly have a model 
> frame and hence that is what you intend.  With 6-6 (or 20-20 in 
> Imperial units) hindsight it would have been better to give model 
> frames a class inheriting from "data frame", but it seems that the 
> presence of attr(, "terms") is the most common test.
> 
> > Would it break anything to add to the top of
> 
> Unfortunately, that is rather hard to tell!
> 
> > formula.data.frame
> > something like
> >  if (!is.null(tms <- attr(x, "terms"))) {
> >    return(formula(tms))
> >  }
> > so that formula() would retrieve the formula buried
> > in model.frame's output?
> 
> I looked (not hard, but without success) for examples of calling 
> formula() on a data frame.  I did see that 
> model.frame.default() calls 
> as.formula() on a data frame, but only after checking for the absence 
> of a "terms" attribute.
> 
> Can you explain where it would help?  I think we need to see examples 
> to see if a change in meaning would be clearly beneficial.  I can 
> envisage cases in which 'x' was a data frame that just happened to 
> have been constructed as a model frame and where the currently 
> documented meaning was intended.
> 
> > Bill Dunlap
> > Spotfire, TIBCO Software
> > wdunlap tibco.com
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 


From ripley at stats.ox.ac.uk  Thu Jan 20 08:29:19 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 20 Jan 2011 07:29:19 +0000 (GMT)
Subject: [Rd] buglet in weighted.residuals(mlmObject)
In-Reply-To: <77EB52C6DD32BA4D87471DCD70C8D70003D65407@NA-PA-VBE03.na.tibco.com>
References: <77EB52C6DD32BA4D87471DCD70C8D70003D65407@NA-PA-VBE03.na.tibco.com>
Message-ID: <alpine.LFD.2.00.1101200729060.27434@gannet.stats.ox.ac.uk>

Thanks: changed in R-patched.

On Wed, 19 Jan 2011, William Dunlap wrote:

> When weighted.residuals() is given a fitted model
> object with several responses (class mlm) and some
> zero weights it returns a vector instead of a matrix.
> It looks like it is doing
>   resids[ weights != 0 ]
> instead of
>   resids[ weights != 0, , drop=FALSE]
> in the multi-response case.
>
> E.g.,
>
>> d4 <- data.frame(y1=1:4, y2=2^(0:3), wt=log(1:4),
> fac=LETTERS[c(1,1,2,2)])
>> fit <- lm(data=d4, cbind(y1,y2)~fac, weights=wt)
>> weighted.residuals(fit) # expect 3x2 matrix
> [1]  1.407294e-16 -5.847465e-01  5.205496e-01  5.950102e-16
> -2.338986e+00
> [6]  2.082198e+00
>> weighted.residuals(fit, drop0=FALSE)
>             y1            y2
> 1  0.000000e+00  0.000000e+00
> 2  1.407294e-16  5.950102e-16
> 3 -5.847465e-01 -2.338986e+00
> 4  5.205496e-01  2.082198e+00
>
> This is in R 2.12.0.  I haven't upgraded yet.
>
> Bill Dunlap
> Spotfire, TIBCO Software
> wdunlap tibco.com
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From cbeleites at units.it  Thu Jan 20 14:05:41 2011
From: cbeleites at units.it (Claudia Beleites)
Date: Thu, 20 Jan 2011 14:05:41 +0100
Subject: [Rd] plotmath indices: suggested addition to help file
Message-ID: <4D383325.5060604@units.it>

Dear all,

I just stumbled over the fact that subsetting by square bracket will only output 
the first given index. I guess the rest is thrown away by the CADDR in RenderSub 
(plotmath.c l. 1399).
Maybe changing this could be considered as "low-priority desired" (would be nice 
if the output works for ?

However, I suggest to announce the fact that only the first parameter is printed 
in plotmath.Rd.

E.g. in the table l. 72
\code{x[i]}   \tab x subscript i; escape further indices (\code{x ["i, j"]})\cr

Claudia

-- 
Claudia Beleites
Dipartimento dei Materiali e delle Risorse Naturali
Universit? degli Studi di Trieste
Via Alfonso Valerio 6/a
I-34127 Trieste

phone: +39 0 40 5 58-37 68
email: cbeleites at units.it


From jhibschman at gmail.com  Thu Jan 20 16:24:50 2011
From: jhibschman at gmail.com (Johann Hibschman)
Date: Thu, 20 Jan 2011 09:24:50 -0600
Subject: [Rd] setGeneric for residuals, etc
Message-ID: <u1ok4hzfvi5.fsf@lx-chrateresearch01.citadelgroup.com>

I'm experimenting with a few model-fitting classes of my own.  I'm
leaning towards using S4 for my classes, but the R functions I'd want to
override (residuals, predict, etc.) are all S3 methods.

As I understand it, I could do setGeneric("residuals"), then add S4
specializations to it.  However, I don't understand the full
consequences of doing this.  Are there any drawbacks?  Is there some
code that will not run properly if I do this?  It feels like I'm
reaching in and modifying a core R function, which makes me nervous.

To put it another way, if it's completely transparent and causes no
problems, why isn't it done by default?

(If it matters, I'm still on 2.10.1, but I can take it up with global
architecture if there are compelling changes in later versions.)

Thanks,
Johann


From hadley at rice.edu  Thu Jan 20 18:26:05 2011
From: hadley at rice.edu (Hadley Wickham)
Date: Thu, 20 Jan 2011 09:26:05 -0800
Subject: [Rd] [OT] DSC?
Message-ID: <AANLkTik7=PdQRB8rwLJagBPCH60OGe-s8e0aUY82svi3@mail.gmail.com>

Hi all,

This is a bit off topic, but is there another DSC planned for the near
future?  I thought it was biannual and the last one was in 2009...

Hadley

-- 
Assistant Professor / Dobelman Family Junior Chair
Department of Statistics / Rice University
http://had.co.nz/


From maechler at stat.math.ethz.ch  Fri Jan 21 11:27:36 2011
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 21 Jan 2011 11:27:36 +0100
Subject: [Rd] plotmath indices: suggested addition to help file
In-Reply-To: <4D383325.5060604@units.it>
References: <4D383325.5060604@units.it>
Message-ID: <19769.24472.996333.510972@stat.math.ethz.ch>

Thank you, Claudia,

>>>>> "CB" == Claudia Beleites <cbeleites at units.it>
>>>>>     on Thu, 20 Jan 2011 14:05:41 +0100 writes:

    CB> Dear all, I just stumbled over the fact that subsetting
    CB> by square bracket will only output the first given
    CB> index. I guess the rest is thrown away by the CADDR in
    CB> RenderSub (plotmath.c l. 1399).  Maybe changing this
    CB> could be considered as "low-priority desired" (would be
    CB> nice if the output works for ?

I agree this is a  ``missing feature'' and well worth wish list item.

    CB> However, I suggest to announce the fact that only the
    CB> first parameter is printed in plotmath.Rd.

    CB> E.g. in the table l. 72
    CB>  \code{x[i]} \tab x subscript i;  escape further indices (\code{x ["i, j"]})\cr

How would get the equivalent of  LaTeX  x_{i_1, j_2}  ?
Not by making it a string (that's not  escape, I'd say),
but by something like

    plot(0, axes=FALSE, main= expression(paste(x[i[1]],{}[j[2]])))

which works +-  
but of course is unnecessarily ugly, compared to the desired

    plot(0, axes=FALSE, main= expression(      x[i[1], j[2]]))

Martin

    CB> Claudia


From janko.thyson.rstuff at googlemail.com  Fri Jan 21 13:08:48 2011
From: janko.thyson.rstuff at googlemail.com (Janko Thyson)
Date: Fri, 21 Jan 2011 13:08:48 +0100
Subject: [Rd] setGeneric for residuals, etc
In-Reply-To: <u1ok4hzfvi5.fsf@lx-chrateresearch01.citadelgroup.com>
References: <u1ok4hzfvi5.fsf@lx-chrateresearch01.citadelgroup.com>
Message-ID: <4d39774c.825bdf0a.5ca4.ffffa40a@mx.google.com>

> -----Urspr?ngliche Nachricht-----
> Von: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-
> project.org] Im Auftrag von Johann Hibschman
> Gesendet: Donnerstag, 20. Januar 2011 16:25
> An: r-devel at stat.math.ethz.ch
> Betreff: [Rd] setGeneric for residuals, etc
> 
> I'm experimenting with a few model-fitting classes of my own.  I'm
> leaning towards using S4 for my classes, but the R functions I'd want
> to
> override (residuals, predict, etc.) are all S3 methods.
> 
> As I understand it, I could do setGeneric("residuals"), then add S4
> specializations to it.  However, I don't understand the full
> consequences of doing this.  Are there any drawbacks?  Is there some
> code that will not run properly if I do this?  It feels like I'm
> reaching in and modifying a core R function, which makes me nervous.
> 
> To put it another way, if it's completely transparent and causes no
> problems, why isn't it done by default?
> 
> (If it matters, I'm still on 2.10.1, but I can take it up with global
> architecture if there are compelling changes in later versions.)
> 
> Thanks,
> Johann
> 

Well, one "drawback" with S4 is that you need to write more explicit code
than in a pure S3 world, but it makes your code also a lot more robust
(method dispatch, validation etc.). As far as I understand it, working with
customized S4 objects would imply that you need to specify methods for all
those S3 functions already out there that you want to work with your
objects. For example, inside your method for 'residuals()', you will
probably just get some data out of a slot of your object and run the S3
function 'residuals(your.slot.data)'. So there's nothing that should make
you nervous in that respect, you're not overwriting anything with your
method. Setting a generic for an existing function is just a necessary step
in order to specify S4 methods for it. 

However, you could also write a couple methods that coerce your custom
object into those S3 objects that the already implemented functions expect
(e.g. 'residuals()'). Another drawback might be efficiency depending on how
complex your S4 objects are (e.g. how many nested function calls are
required to get to actual data).

HTH,
Janko

> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From karl at huftis.org  Fri Jan 21 10:47:56 2011
From: karl at huftis.org (Karl Ove Hufthammer)
Date: Fri, 21 Jan 2011 10:47:56 +0100
Subject: [Rd] match function causing bad performance when using table
	function on factors with multibyte characters on Windows
Message-ID: <ihbko3$efs$1@dough.gmane.org>

[I originally posted this on the R-help mailing list, and it was suggested that R-devel would be a better
place to dicuss it.]

Running ?table? on a factor with levels containing non-ASCII characters
seems to result in extremely bad performance on Windows. Here?s a simple
example with benchmark results (I?ve reduced the number of replications to
make the function finish within reasonable time):

  library(rbenchmark)
  x.num=sample(1:2, 10^5, replace=TRUE)
  x.fac.ascii=factor(x.num, levels=1:2, labels=c("A","B"))
  x.fac.nascii=factor(x.num, levels=1:2, labels=c("?","?"))
  benchmark( table(x.num), table(x.fac.ascii), table(x.fac.nascii), table(unclass(x.fac.nascii)), replications=20 )
  
                            test replications elapsed   relative user.self sys.self user.child sys.child
  4 table(unclass(x.fac.nascii))           20    1.53   4.636364      1.51     0.01         NA        NA
  2           table(x.fac.ascii)           20    0.33   1.000000      0.33     0.00         NA        NA
  3          table(x.fac.nascii)           20  146.67 444.454545     38.52    81.74         NA        NA
  1                 table(x.num)           20    1.55   4.696970      1.53     0.01         NA        NA
  
  sessionInfo()
  R version 2.12.1 (2010-12-16)
  Platform: i386-pc-mingw32/i386 (32-bit)
  
  locale:
  [1] LC_COLLATE=Norwegian-Nynorsk_Norway.1252  LC_CTYPE=Norwegian-Nynorsk_Norway.1252    LC_MONETARY=Norwegian-Nynorsk_Norway.1252
  [4] LC_NUMERIC=C                              LC_TIME=Norwegian-Nynorsk_Norway.1252   
  
  attached base packages:
  [1] stats     graphics  grDevices datasets  utils     methods   base    
  
  other attached packages:
  [1] rbenchmark_0.3

The timings are from R 2.12.1, but I also get comparable results
on the latest prelease (R 2.13.0 2011-01-18 r54032).

Running the same test (100 replications) on a Linux system with
R.12.1 Patched results in essentially no difference between the
performance on ASCII factors and non-ASCII factors:

                            test replications elapsed relative user.self sys.self user.child sys.child
  4 table(unclass(x.fac.nascii))          100   4.607 3.096102     4.455    0.092          0         0
  2           table(x.fac.ascii)          100   1.488 1.000000     1.459    0.028          0         0
  3          table(x.fac.nascii)          100   1.616 1.086022     1.560    0.051          0         0
  1                 table(x.num)          100   4.504 3.026882     4.403    0.079          0         0

  sessionInfo()
  R version 2.12.1 Patched (2011-01-18 r54033)
  Platform: i686-pc-linux-gnu (32-bit)
  
  locale:
   [1] LC_CTYPE=nn_NO.UTF-8       LC_NUMERIC=C               LC_TIME=nn_NO.UTF-8       
   [4] LC_COLLATE=nn_NO.UTF-8     LC_MONETARY=C              LC_MESSAGES=nn_NO.UTF-8   
   [7] LC_PAPER=nn_NO.UTF-8       LC_NAME=C                  LC_ADDRESS=C              
  [10] LC_TELEPHONE=C             LC_MEASUREMENT=nn_NO.UTF-8 LC_IDENTIFICATION=C   
  
  attached base packages:
  [1] stats     graphics  grDevices utils     datasets  methods   base     

  other attached packages:
  [1] rbenchmark_0.3

Profiling the ?table? function indicates almost all the time if spent in
the ?match? function, which is used when ?factor? is used on a ?factor?
inside ?table?. Indeed, ?x.fac.nascii = factor(x.fac.nascii)? by itself
is extremely slow.

Is there any theoretical reason ?factor? on ?factor? with non-ASCII
characters must be so slow? And why doesn?t this happen on Linux?

Perhaps a fix for ?table? might be calculating the ?table? statistics
*including* all levels (not using the ?factor? function anywhere),
and then removing the ?exclude? levels in the end. For example,
something along these lines:

res = table.modified.to.not.use.factor(...)
ind = lapply(dimnames(res), function(x) !(x %in% exclude))
do.call("[", c(list(res), ind, drop=FALSE))

(I haven?t tested this very much, so there may be issues with this
way of doing things.)

-- 
Karl Ove Hufthammer


From xiaoch.sun at gmail.com  Thu Jan 20 22:05:05 2011
From: xiaoch.sun at gmail.com (mtck1982)
Date: Thu, 20 Jan 2011 13:05:05 -0800 (PST)
Subject: [Rd] Calling C++ from R
Message-ID: <1295557505204-3228490.post@n4.nabble.com>


Hi All,

I am new to this area and use Rcpp to call C++ from R and try to build the
package under Windows 7. I use Rtools and R 2.10.1 32bit. Everything works
fine with me, except using R functions like "rnorm" or "runif" in the C++
code. When I use "R CMD check" the package, it always return error 

** libs
  making DLL ...
g++ -I"c:/PROGRA~2/R/R-210~1.1/include"  
-I"c:/PROGRA~2/R/R-210~1.1/library/Rcpp/include"     -O2 -Wall  -c func.cpp
-o func.o
func.cpp: In function 'SEXPREC* myfunction(SEXPREC*, SEXPREC*)':
func.cpp:220: error: 'rgamma' was not declared in this scope
func.cpp:225: error: 'rnorm' was not declared in this scope
func.cpp:244: error: 'runif' was not declared in this scope
func.cpp:274: error: 'rbeta' was not declared in this scope
make: *** [func.o] Error 1
  ... done

although I already put <Rmath.h>, <R.h> and <math.h> in the header file.
//////////////////////////////////////////////////
The func.cpp file has the following structure 

#include "func.h"
SEXP myfunction(SEXP a, SEXP b) {
}
//////////////////////////////////////////////
The  header file "func.h" has the following content

#include <cstdio>
#include <Rcpp.h>
#include <math.h>
#include <R.h>
#include <Rmath.h>
RcppExport SEXP myfunction(SEXP a, SEXP b);
/////////////////////////////////////////
What could the problem be?

Many thanks, 
Xiaochun
-- 
View this message in context: http://r.789695.n4.nabble.com/Calling-C-from-R-tp3228490p3228490.html
Sent from the R devel mailing list archive at Nabble.com.


From karl at huftis.org  Fri Jan 21 11:30:58 2011
From: karl at huftis.org (Karl Ove Hufthammer)
Date: Fri, 21 Jan 2011 11:30:58 +0100
Subject: [Rd] table on numeric vector with exclude argument containing value
	missing from vector causes warning + "NaN" levels incorrectly
	removed from factors
Message-ID: <ihbn8q$rgp$1@dough.gmane.org>

I *think* the following may be considered a bug or two, but would appreciate 
any comments before (not) filing an official bug report.

Possible bug 1: ?table? on numeric vector with ?exclude? argument containing 
value missing from vector causes warning
Possible bug 2: ?table? incorrectly tries to remove "NaN" levels

The help page for ?table? says the the first argument is ?one or more 
objects which can be interpreted as factors (including character strings) 
[?]?. Does this include numeric vectors? Numeric vectors seems to work fine. 
Example:

  x = sample(1:3, 100, replace=TRUE)
  table(x)

The ?exclude? argument explicitly mentions factor levels, but seems to work 
fine for other objects too. Example:

  table(x, exclude=2)

It?s actually not clear from the help page what is meant by ?levels to 
remove from all factors in ...?, but it seems like a character vector is 
expected. And indeed the following also works:

  table(x, exclude="2")

However, setting the ?exclude? argument to a value not contained in 
the vector to be tabulated,

  table(x, exclude="foo")

causes the following warning:

  In as.vector(exclude, typeof(x)) : NAs introduced by coercion?:

The correct results is produced, though. Note that all of the following does 
*not* cause any warning:

  table(x, exclude=NA)
  table(x, exclude=NaN)
  table(factor(x), exclude="foo")
  table(as.character(x), exclude="foo")

I also wonder about the inclusion of ?NaN? in the definition of ?table?:

table(..., exclude = if (useNA == "no") c(NA, NaN), useNA = c("no", 
    "ifany", "always"), dnn = list.names(...), deparse.level = 1) 

A factor can?t include a NaN level, as the levels values are always
strings or NA. And having the above definition causes "NaN" (string)
levels to mysteriously disappear when run through ?table?. Example:

  table(factor(c("NA",NA,"NcN","NbN", "NaN")))

Result:

   NA NbN NcN 
    1   1   1

(The missing NA is not a bug; it?s caused by useNA="no".)



sessionInfo()
R version 2.12.1 Patched (2011-01-20 r54056)
Platform: i686-pc-linux-gnu (32-bit)

locale:
[1] C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base   

-- 
Karl Ove Hufthammer


From bates at stat.wisc.edu  Fri Jan 21 13:44:13 2011
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 21 Jan 2011 06:44:13 -0600
Subject: [Rd] Calling C++ from R
In-Reply-To: <1295557505204-3228490.post@n4.nabble.com>
References: <1295557505204-3228490.post@n4.nabble.com>
Message-ID: <AANLkTi=tcJKD4Qv5er6pLJF1JrEXRMSVQ+wWDaHnbndK@mail.gmail.com>

It is more effective to send such inquiries to the Rcpp-devel mailing
list which I am cc'ing on this reply.

On Thu, Jan 20, 2011 at 3:05 PM, mtck1982 <xiaoch.sun at gmail.com> wrote:
>
> Hi All,
>
> I am new to this area and use Rcpp to call C++ from R and try to build the
> package under Windows 7. I use Rtools and R 2.10.1 32bit. Everything works
> fine with me, except using R functions like "rnorm" or "runif" in the C++
> code. When I use "R CMD check" the package, it always return error
>
> ** libs
> ?making DLL ...
> g++ -I"c:/PROGRA~2/R/R-210~1.1/include"
> -I"c:/PROGRA~2/R/R-210~1.1/library/Rcpp/include" ? ? -O2 -Wall ?-c func.cpp
> -o func.o
> func.cpp: In function 'SEXPREC* myfunction(SEXPREC*, SEXPREC*)':
> func.cpp:220: error: 'rgamma' was not declared in this scope
> func.cpp:225: error: 'rnorm' was not declared in this scope
> func.cpp:244: error: 'runif' was not declared in this scope
> func.cpp:274: error: 'rbeta' was not declared in this scope
> make: *** [func.o] Error 1
> ?... don

It is not clear if you are trying to use the Rcpp "sugar"
constructions, which can apply to entire vectors, of if you are using
the functions in the R API.  If the latter then you will need to
preface the name with Rf_, as in Rf_runif. Those are the actual names
of the functions.  The Rinternals.h file defines a number of aliases,
such as runif, but in Rcpp those aliases are turned off, so as to
avoid name clashes.

You should note that when calling random number generator functions
the programmer is responsible for getting and restoring the seed
structure.  I can't remember the details right now and I am on a
Windows system without the sources so I will rely on someone else to
fill in the details.

> although I already put <Rmath.h>, <R.h> and <math.h> in the header file.
> //////////////////////////////////////////////////
> The func.cpp file has the following structure
>
> #include "func.h"
> SEXP myfunction(SEXP a, SEXP b) {
> }
> //////////////////////////////////////////////
> The ?header file "func.h" has the following content
>
> #include <cstdio>
> #include <Rcpp.h>
> #include <math.h>
> #include <R.h>
> #include <Rmath.h>
> RcppExport SEXP myfunction(SEXP a, SEXP b);
> /////////////////////////////////////////
> What could the problem be?
>
> Many thanks,
> Xiaochun
> --
> View this message in context: http://r.789695.n4.nabble.com/Calling-C-from-R-tp3228490p3228490.html
> Sent from the R devel mailing list archive at Nabble.com.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From edd at debian.org  Fri Jan 21 14:38:25 2011
From: edd at debian.org (Dirk Eddelbuettel)
Date: Fri, 21 Jan 2011 07:38:25 -0600
Subject: [Rd] [Rcpp-devel]  Calling C++ from R
In-Reply-To: <AANLkTi=tcJKD4Qv5er6pLJF1JrEXRMSVQ+wWDaHnbndK@mail.gmail.com>
References: <1295557505204-3228490.post@n4.nabble.com>
	<AANLkTi=tcJKD4Qv5er6pLJF1JrEXRMSVQ+wWDaHnbndK@mail.gmail.com>
Message-ID: <19769.35921.695036.563489@max.nulle.part>


On 21 January 2011 at 06:44, Douglas Bates wrote:
| It is more effective to send such inquiries to the Rcpp-devel mailing
| list which I am cc'ing on this reply.

Correct. 
 
| On Thu, Jan 20, 2011 at 3:05 PM, mtck1982 <xiaoch.sun at gmail.com> wrote:
| >
| > Hi All,
| >
| > I am new to this area and use Rcpp to call C++ from R and try to build the
| > package under Windows 7. I use Rtools and R 2.10.1 32bit. Everything works
| > fine with me, except using R functions like "rnorm" or "runif" in the C++
| > code. When I use "R CMD check" the package, it always return error
| >
| > ** libs
| > ?making DLL ...
| > g++ -I"c:/PROGRA~2/R/R-210~1.1/include"
| > -I"c:/PROGRA~2/R/R-210~1.1/library/Rcpp/include" ? ? -O2 -Wall ?-c func.cpp
| > -o func.o
| > func.cpp: In function 'SEXPREC* myfunction(SEXPREC*, SEXPREC*)':
| > func.cpp:220: error: 'rgamma' was not declared in this scope
| > func.cpp:225: error: 'rnorm' was not declared in this scope
| > func.cpp:244: error: 'runif' was not declared in this scope
| > func.cpp:274: error: 'rbeta' was not declared in this scope
| > make: *** [func.o] Error 1
| > ?... don
| 
| It is not clear if you are trying to use the Rcpp "sugar"
| constructions, which can apply to entire vectors, of if you are using
| the functions in the R API.  If the latter then you will need to
| preface the name with Rf_, as in Rf_runif. Those are the actual names
| of the functions.  The Rinternals.h file defines a number of aliases,
| such as runif, but in Rcpp those aliases are turned off, so as to
| avoid name clashes.
| 
| You should note that when calling random number generator functions
| the programmer is responsible for getting and restoring the seed
| structure.  I can't remember the details right now and I am on a
| Windows system without the sources so I will rely on someone else to
| fill in the details.

The easiest is to just declared a variable of type 

    Rcpp::RNGScope

which saves state when entering the local scope (ie "set of curly braces")
and restores it when leaving, thanks to what one can do with C++. Here is
an example Romain wrote to the rcpp-devel list in October:

   In addition, we have the RNGScope class, whose constructor calls=20
   GetRNGstate and destruvctor calls PutRNGstate, so that you can do :

   fx <- cxxfunction( , '
           RNGScope scope ;
           NumericVector x = rgamma( 10, 1, 1 ) ;
           return x ;
   ', plugin="Rcpp" )

   fx()

That's self-contained example for inline, using the rgamma sugar function.
You need the Rcpp:: prefix or a 'using namespace Rcpp;' when you use that in
your own source code.

Dirk

-- 
Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com


From ehlers at ucalgary.ca  Fri Jan 21 15:17:20 2011
From: ehlers at ucalgary.ca (Peter Ehlers)
Date: Fri, 21 Jan 2011 06:17:20 -0800
Subject: [Rd] plotmath indices: suggested addition to help file
In-Reply-To: <19769.24472.996333.510972@stat.math.ethz.ch>
References: <4D383325.5060604@units.it>
	<19769.24472.996333.510972@stat.math.ethz.ch>
Message-ID: <4D399570.7010600@ucalgary.ca>

On 2011-01-21 02:27, Martin Maechler wrote:
> Thank you, Claudia,
>
>>>>>> "CB" == Claudia Beleites<cbeleites at units.it>
>>>>>>      on Thu, 20 Jan 2011 14:05:41 +0100 writes:
>
>      CB>  Dear all, I just stumbled over the fact that subsetting
>      CB>  by square bracket will only output the first given
>      CB>  index. I guess the rest is thrown away by the CADDR in
>      CB>  RenderSub (plotmath.c l. 1399).  Maybe changing this
>      CB>  could be considered as "low-priority desired" (would be
>      CB>  nice if the output works for ?
>
> I agree this is a  ``missing feature'' and well worth wish list item.
>
>      CB>  However, I suggest to announce the fact that only the
>      CB>  first parameter is printed in plotmath.Rd.
>
>      CB>  E.g. in the table l. 72
>      CB>   \code{x[i]} \tab x subscript i;  escape further indices (\code{x ["i, j"]})\cr
>
> How would get the equivalent of  LaTeX  x_{i_1, j_2}  ?
> Not by making it a string (that's not  escape, I'd say),
> but by something like
>
>      plot(0, axes=FALSE, main= expression(paste(x[i[1]],{}[j[2]])))
>
> which works +-
> but of course is unnecessarily ugly, compared to the desired
>
>      plot(0, axes=FALSE, main= expression(      x[i[1], j[2]]))
>

I don't know if I've ever disagreed with Martin's advice but,
unless I'm missing something, Claudia wants something done about
the second index in x[i, j] while Martin is talking about the
case of cascading subscripts in 'x_sub_i_sub_1' (as shown in his
LaTeX expression).

Both situations are nicely handled with the 'list()' and '[]'
constructs in plotmath:

   plot(0, axes=FALSE, main= expression( x[ list( i[1], j[2] ) ] ) )

To handle Claudia's wish, it might be desirable to have plotmath.c
automatically recognize such cases but I would consider that to
be (as Claudia says) in the 'nice if' category. Claudia's suggestion
for the help page could be handled by adding another example. Then
again, plotmath (not surprisingly) is like LaTeX in that, the more
you use it, the more you become familiar with the special constructs
needed to get the output you want. I still find myself scurrying to
?plotmath and scanning the Syntax/Meaning table quite frequently.

Peter Ehlers

> Martin
>
>      CB>  Claudia
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From maechler at stat.math.ethz.ch  Fri Jan 21 15:32:14 2011
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 21 Jan 2011 15:32:14 +0100
Subject: [Rd] plotmath indices: suggested addition to help file
In-Reply-To: <4D399570.7010600@ucalgary.ca>
References: <4D383325.5060604@units.it>
	<19769.24472.996333.510972@stat.math.ethz.ch>
	<4D399570.7010600@ucalgary.ca>
Message-ID: <19769.39150.275431.631915@stat.math.ethz.ch>

>>>>> "PE" == Peter Ehlers <ehlers at ucalgary.ca>
>>>>>     on Fri, 21 Jan 2011 06:17:20 -0800 writes:

    PE> On 2011-01-21 02:27, Martin Maechler wrote:
    >> Thank you, Claudia,
    >> 
    >>>>>>> "CB" == Claudia Beleites<cbeleites at units.it> on Thu,
    >>>>>>> 20 Jan 2011 14:05:41 +0100 writes:
    >> 
    CB> Dear all, I just stumbled over the fact that subsetting
    CB> by square bracket will only output the first given
    CB> index. I guess the rest is thrown away by the CADDR in
    CB> RenderSub (plotmath.c l. 1399).  Maybe changing this
    CB> could be considered as "low-priority desired" (would be
    CB> nice if the output works for ?
    >> 
    >> I agree this is a ``missing feature'' and well worth wish
    >> list item.
    >> 
    CB> However, I suggest to announce the fact that only the
    CB> first parameter is printed in plotmath.Rd.
    >> 
    CB> E.g. in the table l. 72 \code{x[i]} \tab x subscript i;
    CB> escape further indices (\code{x ["i, j"]})\cr
    >> 
    >> How would get the equivalent of LaTeX x_{i_1, j_2} ?  Not
    >> by making it a string (that's not escape, I'd say), but
    >> by something like
    >> 
    >> plot(0, axes=FALSE, main=
    >> expression(paste(x[i[1]],{}[j[2]])))
    >> 
    >> which works +- but of course is unnecessarily ugly,
    >> compared to the desired
    >> 
    >> plot(0, axes=FALSE, main= expression( x[i[1], j[2]]))
    >> 

    PE> I don't know if I've ever disagreed with Martin's advice but,
:-)

    PE> unless I'm missing something, Claudia wants something
    PE> done about the second index in x[i, j] while Martin is
    PE> talking about the case of cascading subscripts in
    PE> 'x_sub_i_sub_1' (as shown in his LaTeX expression).

Well, that was a misunderstanding.
I've use "cascaded" subscripts as an example of subscripts that
are themselves expressions, and so using a string,
as Claudia's suggestion (on R-devel!) was, is not enough.

Only afterwards, I saw the related thread on R-help,
which included the proposals you give here

    PE> Both situations are nicely handled with the 'list()' and '[]'
    PE> constructs in plotmath:

    PE> plot(0, axes=FALSE, main= expression( x[ list( i[1], j[2] ) ] ) )

    PE> To handle Claudia's wish, it might be desirable to have plotmath.c
    PE> automatically recognize such cases but I would consider that to
    PE> be (as Claudia says) in the 'nice if' category. Claudia's suggestion
    PE> for the help page could be handled by adding another example. Then
    PE> again, plotmath (not surprisingly) is like LaTeX in that, the more
    PE> you use it, the more you become familiar with the special constructs
    PE> needed to get the output you want. I still find myself scurrying to
    PE> ?plotmath and scanning the Syntax/Meaning table quite frequently.

okay.
Indeed, the following code snippet shows what I deem a summary
of the proposals seen.


Txt <- function(y, exp) {
    y <- y/16 # to allow integer arguments on input
    x0 <- par("xaxp")[1]
    text(y, exp, adj = 0, cex = 5)
    text(y, deparse(substitute(exp)), adj = 1.1, cex=1.2)
}
plot(0, axes=FALSE,ann=FALSE, asp=1, type="n")
## These show no "," between the two indices:
Txt( 0, expression(x[paste(i[1],j[2])]))
Txt( 2, expression(x[i[1]][j[2]])) ## <-- clearly nicest
## This one does .. that's what Claudia wanted:
Txt(-3, expression(x[list(i[1],j[2])]))
## and this one uses extra space
Txt(-5, expression(x[list(~i[1],j[2])]))
g <- seq(-1.6,1, .2)/4; abline(v=g+1, h=g, col=adjustcolor(1, .2))


Notably the distinction between (LaTeX)   
   x_{i,j}  or  x_{i_1, j_2}
and
   x_{ij}   or   x_{i_1 i_2}

is something that the useR will want to be able to specify with
plotmath as well.
So Claudia's (and my) wish that   x[i,j]  (or x[i[1], j[2]] )
also work automatically in R's plotmath
would still have to say if we want the version with "," or
without.

Martin

    PE> Peter Ehlers

    >> Martin
    >> 
    CB> Claudia


From pdalgd at gmail.com  Fri Jan 21 16:14:45 2011
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 21 Jan 2011 16:14:45 +0100
Subject: [Rd] Windows script editor and locale
Message-ID: <1B00FAE3-0417-46E5-94E6-B496A2538116@gmail.com>

Maybe I'm just overlooking something, but I can't figure out how to set/change the locale of a file loaded into the built-in script editor on Windows.

The generic issue is that if I make a teaching script on a Mac, save it to a USB stick, and open it in the script editor in a classroom, then special Danish characters in the comments come out as two-byte sequences, which are pretty unsightly. I know that I can convert the file with iconv (or iconv()), but then I'd have to maintain two copies of the same file for the two operating systems, if I want the students to access it. Would be nice if there was something like a set-coding-system to call up via a menu item.

Any pointers?

-- 
Peter Dalgaard
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From ripley at stats.ox.ac.uk  Fri Jan 21 16:57:45 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 21 Jan 2011 15:57:45 +0000 (GMT)
Subject: [Rd] Windows script editor and locale
In-Reply-To: <1B00FAE3-0417-46E5-94E6-B496A2538116@gmail.com>
References: <1B00FAE3-0417-46E5-94E6-B496A2538116@gmail.com>
Message-ID: <alpine.LFD.2.00.1101211531210.27188@gannet.stats.ox.ac.uk>

There is no support for files in alternative encodings in RGui's 
menus: not to source files nor to load into a pager or the script 
editor.  (I believe all of those long predate any support for 
encodings in R.)

Such provision is rather rare on Windows: files are almost everywhere 
assumed to be in the current Windows codepage (or sometimes WinANSI, 
as in the 'Command prompt' terminal) or in so-called Unicode (usually 
UCS-2LE, possibly UTF-16LE, with a BOM).

I think you could equally ask the same question in reverse: AFAICS the 
R.app GUI has no support for Latin-1 nor UCS-2LE files.  At least in 
our UK experience, the proportion of non-Windows users is so low that 
it is those (including this instructor) who expect to adjust.

What might make some sense is for file.edit() to gain a 'fileEncoding' 
argument so this could at least be done from the command-line.

On Fri, 21 Jan 2011, peter dalgaard wrote:

> Maybe I'm just overlooking something, but I can't figure out how to 
> set/change the locale of a file loaded into the built-in script 
> editor on Windows.
>
> The generic issue is that if I make a teaching script on a Mac, save 
> it to a USB stick, and open it in the script editor in a classroom, 
> then special Danish characters in the comments come out as two-byte 
> sequences, which are pretty unsightly. I know that I can convert the 
> file with iconv (or iconv()), but then I'd have to maintain two 
> copies of the same file for the two operating systems, if I want the 
> students to access it. Would be nice if there was something like a 
> set-coding-system to call up via a menu item.
>
> Any pointers?
>
> -- 
> Peter Dalgaard
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From cbeleites at units.it  Fri Jan 21 19:25:48 2011
From: cbeleites at units.it (Claudia Beleites)
Date: Fri, 21 Jan 2011 19:25:48 +0100
Subject: [Rd] plotmath indices: suggested addition to help file
In-Reply-To: <19769.39150.275431.631915@stat.math.ethz.ch>
References: <4D383325.5060604@units.it>	<19769.24472.996333.510972@stat.math.ethz.ch>	<4D399570.7010600@ucalgary.ca>
	<19769.39150.275431.631915@stat.math.ethz.ch>
Message-ID: <4D39CFAC.1090502@units.it>

Dear all,

after realizing yesterday that my suggestion was not yet quite "ripe" as the 
character version is very limited, I decided to wait a bit before summarizing 
the outcome to a better proposition instead of creating too much fuss.

Martin, thanks for your support & systematic table :-)

My main point is that somehow I didn't at all expect plotmath to throw away 
everything after the i of expression (x [i,j]). I think this "trap" deserves 
either change (nice to have; I now believe that this may be quite easy, see 
below) or at least an announcement.

I agree that one needs to learn dealing with plotmath. On the other hand, it is 
nice if plotmath's output corresponds to the R meaning of the expression.

I guess the underlying problem is that we have three different possibilities 
with indexing:

              R ---> how I'd write down the R meaning
(a)   x [i, j]  ---> x_{i, j} or x_{i j} (not x_{ij})
(b)   x [i [j]] ---> x_i_j
(c)   x [i][j]  ---> (x_i)_j

(b) works as expected, though a tiny little bit more default space would be 
excellent.
(a) produces plotmath output x_i which is _very_ unexpected, and
(c) produces output that looks very similar to my expectation for (a) and can 
thus be used to cheat around unexpected behaviour of (a).
I'd say the behaviour of (c) is fine, and it is up to me to write (x [i])[j].
Note that writing (x [i]) [j] does not change the R meaning of the expression.

BTW: I prefer a comma for (a) because i couldn't distinguish the output of
expression (x [i][j])
from
expression (x [ij])
.
I also vote for a comma for the future behaviour of (a) - even with some space 
it's easier to distinguish two indices if they are separated by a comma (and no 
comma can still be obtained by x[i][j]). Plus, it may be easier to implement it 
that way.

I tried:
CDDR instead CADDR in RenderSub (plotmath.c) yields all indices given in the 
square bracket. Now I prepended install ("list") by LCONS, and it seems to work:
plot (1,1, type = "n"); text (1, 1, expression (x [i[a,b,c],j,k]*f(x)), cex = 3)
now looks as I expect.

Disclaimer: This is the first time ever I tried to do something with the R C 
interface, and I didn't even properly read the maual and SoDa chapters. So I 
have no idea whether I did something that will cause trouble.

Best regards & have a nice weekend

Claudia

cb at cb:~/r-devel$ svn diff src/main/plotmath.c
Index: src/main/plotmath.c
===================================================================
--- src/main/plotmath.c	(revision 54062)
+++ src/main/plotmath.c	(working copy)
@@ -898,6 +898,7 @@
  				mathContext*, pGEcontext , pGEDevDesc);
  static BBOX RenderExpression(SEXP, int, mathContext*, pGEcontext , pGEDevDesc);
  static BBOX RenderSymbolChar(int, int, mathContext*, pGEcontext , pGEDevDesc);
+static BBOX RenderCommaList(SEXP, int, mathContext *, pGEcontext, pGEDevDesc);


  /*  Code to Generate Bounding Boxes and Draw Formulae.	*/
@@ -1396,7 +1397,8 @@
  {
      BBOX bodyBBox, subBBox;
      SEXP body = CADR(expr);
-    SEXP sub = CADDR(expr);
+    SEXP sub = CDDR(expr);
+    SEXP list = install ("list");
      STYLE style = GetStyle(mc);
      double savedX = mc->CurrentX;
      double savedY = mc->CurrentY;
@@ -1407,6 +1409,7 @@
      s5 = TeX(sigma5, gc, dd);
      s16 = TeX(sigma16, gc, dd);
      SetSubStyle(style, mc, gc);
+    sub = LCONS (list, sub);
      subBBox = RenderElement(sub, 0, mc, gc, dd);
      v = max(max(v, s16), bboxHeight(subBBox) - 0.8 * sigma5);
      subBBox = RenderOffsetElement(sub, 0, -v, draw, mc, gc, dd);

-- 
Claudia Beleites
Dipartimento dei Materiali e delle Risorse Naturali
Universit? degli Studi di Trieste
Via Alfonso Valerio 6/a
I-34127 Trieste

phone: +39 0 40 5 58-37 68
email: cbeleites at units.it


From azege at yahoo.com  Sat Jan 22 03:43:58 2011
From: azege at yahoo.com (Andre Zege)
Date: Fri, 21 Jan 2011 18:43:58 -0800 (PST)
Subject: [Rd] libRblas.so: undefined reference to `xerbla_' ?
Message-ID: <290192.85031.qm@web39301.mail.mud.yahoo.com>

Hi all, i am trying to compile a test, calling from C code  R Lapack  shared 
libraries. In particular, i am calling simple LAPACK driver 

dposv for solving linear equation  system A*x=B  with positive definite A. My 
code looks like the following in 


solve.c 
========================== 
#include<stdio.h> 
#include <R_ext/BLAS.h> 
#include <R_ext/Lapack.h> 


int main(){ 
  double A[4]={1,0.5,0.5,1}; 
  double B[2]={3,4}; 
  char uplo='U'; 
  int n = 2, nrhs=1, lda=2, ldb=2, info, i; 
  F77_CALL(dposv)(&uplo,&n, &nrhs, A, &lda, B, &ldb, &info); 
  for(i=0; i<2; i++){ 
    printf("%f\n", B[i]); 
  } 
  return info; 

} 
========================== 
When I am trying to link to BLAS/LAPACK using 

gcc -std=gnu99 solve.c -o test -I$R_HOME/include -L$R_HOME/lib -lRblas -lRlapack 
-lgfortran 


linker generates an error message 
$RHOME/lib/libRblas.so: undefined reference to `xerbla_' 

Dumping symbol table shows that indeed libRblas.so has undefined  xerbla_ symbol 
and so does libRlapack. Confusingly, documentation says  that xerbla is error 
checking routine for BLAS, but it is not found in  the library libRblas. 


I did find out that xerbla is defined in libR.so and when i link  to R library, 
everything seems to go fine. However, i have a nagging  feeling i am doing 
something wrong. It doesn't make sense to me that i  cannot compile code that 
doesn't use R without linking to R. Also, one  would want to switch 
transparently between different implementations of  BLAS for example for testing 
purposes and not modify linking  instructions. Would appreciate if someone with 
better understanding of R  commented on how to properly link to  BLAS and LAPACK 
libraries  included with R.


From sun54 at illinois.edu  Fri Jan 21 18:32:57 2011
From: sun54 at illinois.edu (Xiaochun Sun)
Date: Fri, 21 Jan 2011 11:32:57 -0600
Subject: [Rd] [Rcpp-devel]  Calling C++ from R
In-Reply-To: <19769.35921.695036.563489@max.nulle.part>
References: <1295557505204-3228490.post@n4.nabble.com>
	<AANLkTi=tcJKD4Qv5er6pLJF1JrEXRMSVQ+wWDaHnbndK@mail.gmail.com>
	<19769.35921.695036.563489@max.nulle.part>
Message-ID: <AANLkTinia7ooCQVzHKsGFeokrLUQBgWN_dooiFaEqA+x@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110121/f5b975ef/attachment.pl>

From anders at embl.de  Fri Jan 21 19:13:45 2011
From: anders at embl.de (Simon Anders)
Date: Fri, 21 Jan 2011 19:13:45 +0100
Subject: [Rd] Possible bug in Spearman correlation with
	use="pairwise.complete.obs"
Message-ID: <4D39CCD9.9030409@embl.de>

Hi,

I have just encountered a strange behaviour from 'cor' with regards to 
the treatment of NAs when calculating Spearman correlations. I guess it 
is a subtle bug.

If I understand the help page correctly, the two modes 'complete.obs' 
and 'pairwise.complete.obs' specify how to deal with correlation 
coefficients when calculating a correlation _matrix_. When calculating a 
single (scalar) correlation coefficient for two data vectors x and y, 
both should give the same result.

For Pearson correlation, this is in fact the case:

> x <- runif( 10 )
> y <- runif( 10 )
> y[5] <- NA

> cor( x, y, use="complete.obs" )
[1] 0.407858
> cor( x, y, use="pairwise.complete.obs" )
[1] 0.407858

For Spearman correlation, we do NOT get the same results

> cor( x, y, method="spearman", use="complete.obs" )
[1] 0.3416009
> cor( x, y, method="spearman", use="pairwise.complete.obs" )
[1] 0.3333333

To see the likely reason for this possible bug, observe:

> goodobs <- !is.na(x) & !is.na(y)

> cor( rank(x)[goodobs], rank(y)[goodobs] )
[1] 0.3416009
> cor( rank(x[goodobs]), rank(y[goodobs]) )
[1] 0.3333333

I would claim that only the calculation resulting in 0.3333 is a proper 
Spearman correlation, while the line resulting in 0.3416 is not. After 
all, the following is not a complete set of ranks because there are 9 
observations, numbered from 1 to 10, skipping the 3:

> rank(x)[goodobs]
[1] 10  6  8  7  4  5  1  9  2

Would you hence agree that 'method="spearman"' with 
'use="pairwise.complete.obs"' is incorrect?

Cheers
   Simon


> sessionInfo()
R version 2.12.0 (2010-10-15)
Platform: x86_64-unknown-linux-gnu (64-bit)

locale:
  [1] LC_CTYPE=en_US.utf8       LC_NUMERIC=C
  [3] LC_TIME=en_US.utf8        LC_COLLATE=en_US.utf8
  [5] LC_MONETARY=C             LC_MESSAGES=en_US.utf8
  [7] LC_PAPER=en_US.utf8       LC_NAME=C
  [9] LC_ADDRESS=C              LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.utf8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] pspearman_0.2-5 SuppDists_1.1-8

loaded via a namespace (and not attached):
[1] tools_2.12.0




+---
| Dr. Simon Anders, Dipl.-Phys.
| European Molecular Biology Laboratory (EMBL), Heidelberg
| office phone +49-6221-387-8632
| preferred (permanent) e-mail: sanders at fs.tum.de


From therneau at mayo.edu  Sat Jan 22 16:58:40 2011
From: therneau at mayo.edu (Terry Therneau)
Date: Sat, 22 Jan 2011 09:58:40 -0600
Subject: [Rd] news.Rd format
Message-ID: <201101221558.p0MFweE3007920@punchbuggy.mayo.edu>

  I'm converting the "Changelog" files that I have used in the survival package
(since the 1980s) to the inst/NEWS.Rd format and a couple of things are not 
clear from the help page.
  1. What should I use for the name: NEWS or survival?
  2. My section headers look like
    \section{Changes in version 2.36-3}{
      \itemize{  
  etc
and I get "cannot extract version info from the following section titles" for all of them.  I must be missing something simple.

  Perhaps these two points could be clarified further in the manual page.

Terry Therneau


From therneau at mayo.edu  Sat Jan 22 17:04:11 2011
From: therneau at mayo.edu (Terry Therneau)
Date: Sat, 22 Jan 2011 10:04:11 -0600
Subject: [Rd] news.Rd format -- further info
Message-ID: <201101221604.p0MG4BAx008045@punchbuggy.mayo.edu>

 I forgot to state the version of R in my last message.

R version 2.12.1 (2010-12-16)
Copyright (C) 2010 The R Foundation for Statistical Computing
ISBN 3-900051-07-0
Platform: i686-pc-linux-gnu (32-bit)

Survival version 2.36-3 (not yet on CRAN).


From edd at debian.org  Sat Jan 22 20:21:57 2011
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sat, 22 Jan 2011 13:21:57 -0600
Subject: [Rd] [Rcpp-devel]  Calling C++ from R
In-Reply-To: <AANLkTinia7ooCQVzHKsGFeokrLUQBgWN_dooiFaEqA+x@mail.gmail.com>
References: <1295557505204-3228490.post@n4.nabble.com>
	<AANLkTi=tcJKD4Qv5er6pLJF1JrEXRMSVQ+wWDaHnbndK@mail.gmail.com>
	<19769.35921.695036.563489@max.nulle.part>
	<AANLkTinia7ooCQVzHKsGFeokrLUQBgWN_dooiFaEqA+x@mail.gmail.com>
Message-ID: <19771.11861.742324.700435@max.nulle.part>


On 21 January 2011 at 11:32, Xiaochun Sun wrote:
| Many thanks for your reply. Rf_rnorm works very good with me.

Glad to hear it helped, and let us know if you have other questions.

Cheers, Dirk

-- 
Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com


From spinuvit.list at gmail.com  Sat Jan 22 21:08:46 2011
From: spinuvit.list at gmail.com (Vitalie S.)
Date: Sat, 22 Jan 2011 21:08:46 +0100
Subject: [Rd] "+" operator on characters revisited
Message-ID: <878vycd7ld.fsf@gmail.com>


Hello everyone!

Motivated by the recent post on SO
http://stackoverflow.com/questions/4730551/making-a-string-concatenation-operator-in-r

I wonder what is the current state of argument on making "+" to
concatenate character vectors. The "+" method is still sealed for
signature("character", "character") in the current version of R.

The 4 years old R-devel thread
https://www.stat.math.ethz.ch/pipermail/r-devel/2006-August/038991.html
on the same topic, stopped without reaching any definite conclusion.

The only definite argument occurred in the thread against "+" operator
was the lack of commutativity (as if one have to prove algebraic
theorems in R).

Yet another useful suggestion of introducing cat0() and paste0(), for
the common use of cat and paste with sep="" was not absorbed by the
core R either.

Thanks,
Vitalie


From ggrothendieck at gmail.com  Sat Jan 22 21:56:15 2011
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 22 Jan 2011 15:56:15 -0500
Subject: [Rd] "+" operator on characters revisited
In-Reply-To: <878vycd7ld.fsf@gmail.com>
References: <878vycd7ld.fsf@gmail.com>
Message-ID: <AANLkTin_=MtMYZOjprLme53-H4XVOD7y_d9DpH+OiEb_@mail.gmail.com>

On Sat, Jan 22, 2011 at 3:08 PM, Vitalie S. <spinuvit.list at gmail.com> wrote:
>
> Hello everyone!
>
> Motivated by the recent post on SO
> http://stackoverflow.com/questions/4730551/making-a-string-concatenation-operator-in-r
>
> I wonder what is the current state of argument on making "+" to
> concatenate character vectors. The "+" method is still sealed for
> signature("character", "character") in the current version of R.
>
> The 4 years old R-devel thread
> https://www.stat.math.ethz.ch/pipermail/r-devel/2006-August/038991.html
> on the same topic, stopped without reaching any definite conclusion.
>
> The only definite argument occurred in the thread against "+" operator
> was the lack of commutativity (as if one have to prove algebraic
> theorems in R).
>
> Yet another useful suggestion of introducing cat0() and paste0(), for
> the common use of cat and paste with sep="" was not absorbed by the
> core R either.

The gsubfn package has always had a paste0 function and I would be
happy to remove it if the core adds it.

Also the gsubfn supports quasi perl style string interpolation that
can sometimes be used to avoid the use of paste in the first place.
Just preface the function in question by fn$ like this:

library(gsubfn)
fn$cat("pi = $pi\n")

-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From spinuvit.list at gmail.com  Sun Jan 23 12:56:50 2011
From: spinuvit.list at gmail.com (Vitalie S.)
Date: Sun, 23 Jan 2011 12:56:50 +0100
Subject: [Rd] "+" operator on characters revisited
References: <878vycd7ld.fsf@gmail.com>
	<AANLkTin_=MtMYZOjprLme53-H4XVOD7y_d9DpH+OiEb_@mail.gmail.com>
Message-ID: <cpnei83q1dp.fsf@gmail.com>

Gabor Grothendieck <ggrothendieck at gmail.com> writes:

> On Sat, Jan 22, 2011 at 3:08 PM, Vitalie S. <spinuvit.list at gmail.com> wrote:
>>
>> Hello everyone!
>>
>> Motivated by the recent post on SO
>>
> http://stackoverflow.com/questions/4730551/making-a-string-concatenation-operator-in-r>
>> I wonder what is the current state of argument on making "+" to
>> concatenate character vectors. The "+" method is still sealed for
>> signature("character", "character") in the current version of R.
>>
>> The 4 years old R-devel thread
>> https://www.stat.math.ethz.ch/pipermail/r-devel/2006-August/038991.html>
>> on the same topic, stopped without reaching any definite conclusion.
>>
>> The only definite argument occurred in the thread against "+" operator
>> was the lack of commutativity (as if one have to prove algebraic
>> theorems in R).
>>
>> Yet another useful suggestion of introducing cat0() and paste0(), for
>> the common use of cat and paste with sep="" was not absorbed by the
>> core R either.
>
> The gsubfn package has always had a paste0 function and I would be
> happy to remove it if the core adds it.
>
> Also the gsubfn supports quasi perl style string interpolation that
> can sometimes be used to avoid the use of paste in the first place.
> Just preface the function in question by fn$ like this:
>
> library(gsubfn)
> fn$cat("pi = $pi\n")

Thanks for the tip. Not bad indeed.
Almost as readable as

cat("pi = " + pi + "\n")


From ggrothendieck at gmail.com  Sun Jan 23 13:34:07 2011
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sun, 23 Jan 2011 07:34:07 -0500
Subject: [Rd] "+" operator on characters revisited
In-Reply-To: <cpnei83q1dp.fsf@gmail.com>
References: <878vycd7ld.fsf@gmail.com>
	<AANLkTin_=MtMYZOjprLme53-H4XVOD7y_d9DpH+OiEb_@mail.gmail.com>
	<cpnei83q1dp.fsf@gmail.com>
Message-ID: <AANLkTikZ8M38vX1eGs76EK-FwMoOFJBuJHbF2_Jdj0St@mail.gmail.com>

On Sun, Jan 23, 2011 at 6:56 AM, Vitalie S. <spinuvit.list at gmail.com> wrote:
> Gabor Grothendieck <ggrothendieck at gmail.com> writes:
>
>> On Sat, Jan 22, 2011 at 3:08 PM, Vitalie S. <spinuvit.list at gmail.com> wrote:
>>>
>>> Hello everyone!
>>>
>>> Motivated by the recent post on SO
>>>
>> http://stackoverflow.com/questions/4730551/making-a-string-concatenation-operator-in-r>
>>> I wonder what is the current state of argument on making "+" to
>>> concatenate character vectors. The "+" method is still sealed for
>>> signature("character", "character") in the current version of R.
>>>
>>> The 4 years old R-devel thread
>>> https://www.stat.math.ethz.ch/pipermail/r-devel/2006-August/038991.html>
>>> on the same topic, stopped without reaching any definite conclusion.
>>>
>>> The only definite argument occurred in the thread against "+" operator
>>> was the lack of commutativity (as if one have to prove algebraic
>>> theorems in R).
>>>
>>> Yet another useful suggestion of introducing cat0() and paste0(), for
>>> the common use of cat and paste with sep="" was not absorbed by the
>>> core R either.
>>
>> The gsubfn package has always had a paste0 function and I would be
>> happy to remove it if the core adds it.
>>
>> Also the gsubfn supports quasi perl style string interpolation that
>> can sometimes be used to avoid the use of paste in the first place.
>> Just preface the function in question by fn$ like this:
>>
>> library(gsubfn)
>> fn$cat("pi = $pi\n")
>
> Thanks for the tip. Not bad indeed.
> Almost as readable as
>
> cat("pi = " + pi + "\n")

To me the + can be substantially less readable.  The need to
repeatedly quote everything makes it just as bad as paste.  Compare
the following and try to figure out if there is an error in quoting in
the + and paste solutions.  Trying to distinguish the single and
double quotes is pretty difficult but simple in the fn$ and sprintf
solutions.  Even if there were no quotes the constant need to
interpose quotes makes it hard to read.

library(sqldf) # also pulls in gsubfn which has fn$ and paste0
plant <- "Qn1"
treatment <- "nonchilled"

# using +
# sqldf("select * from CO2 where Plant = '" + plant + "' and Treatment
= '" + treatment + "' limit 10")

# using paste0, also from gsubfn
sqldf(paste0("select * from CO2 where Plant = '", plant, "' and
Treatment = '", treatment, "' limit 10"))

# using paste, almost the same as last one
sqldf(paste("select * from CO2 where Plant = '", plant, "' and
Treatment = '", treatment, "' limit 10", sep = ""))

# With the perl-like interpolation you don't need the repeated quoting
in the first place so its much clearer.

# using perl-like interpolation from gsubfn
fn$sqldf("select * from CO2 where Plant = '$plant' and Treatment =
'$treatment' limit 10")

# sprintf is nearly as good as the perl-like interpolation except you
have to match up % codes and arguments which is a bit of nuisance #
and there are more parentheses.  On the other hand it does have the
advantage that there is the facility for fancier formatting codes
# (though this example does not illustrate that aspect):

# using sprintf
sqldf(sprintf("select * from CO2 where Plant = '%s' and Treatment =
'%s' limit 10", plant, treatment))

-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From tplate at acm.org  Sun Jan 23 16:44:21 2011
From: tplate at acm.org (Tony Plate)
Date: Sun, 23 Jan 2011 10:44:21 -0500
Subject: [Rd] feature request: additional hook in plot.new()
Message-ID: <4D3C4CD5.30104@acm.org>

Request: An additional hook in plot.new() that is called prior to the call to .Internal(plot.new()).
Reason: To allow the hook to set up or modify a graphics device that the new plot will appear in.

The code change needed for this is simple - just 4 new lines of R code in src/library/graphics/R/plot.R:plot.new()

Current definition of plot.new() in src/library/graphics/R/plot.R:

plot.new <- function()
{
     .Internal(plot.new())
     for(fun in getHook("plot.new")) {
         if(is.character(fun)) fun <- get(fun)
         try(fun())
     }
     invisible()
}

New definition of plot.new() in src/library/graphics/R/plot.R:

plot.new <- function()
{
     for(fun in getHook("plot.prenew")) {
         if(is.character(fun)) fun <- get(fun)
         try(fun())
     }
     .Internal(plot.new())
     for(fun in getHook("plot.new")) {
         if(is.character(fun)) fun <- get(fun)
         try(fun())
     }
     invisible()
}

In src/library/graphics/man/frame.Rd after the existing sentence beginning "There is a hook..." in the DETAILS section, the following sentence could be added:

"There is another hook called \code{"plot.prenew"} which is called before advancing the frame.  This hook can be used to create a new plot "

The name of the hook is not very important -- I've suggested "plot.prenew" here.  Another possibility could be "plot.new0".

More detail on the reason:

In a tabbed graphics widget (https://r-forge.r-project.org/projects/tabbedplots/ ), having this hook would enable it to operate in a mode where a new tab is automatically created for each new plot.

thanks for your consideration,

Tony Plate


From hadley at rice.edu  Sun Jan 23 17:09:26 2011
From: hadley at rice.edu (Hadley Wickham)
Date: Sun, 23 Jan 2011 16:09:26 +0000
Subject: [Rd] "+" operator on characters revisited
In-Reply-To: <878vycd7ld.fsf@gmail.com>
References: <878vycd7ld.fsf@gmail.com>
Message-ID: <AANLkTinHarTQc60hN3yX5PJMy-d6TZneTYg7019YSRU=@mail.gmail.com>

> Yet another useful suggestion of introducing cat0() and paste0(), for
> the common use of cat and paste with sep="" was not absorbed by the
> core R either.

stringr has str_c which is a replacement for paste with sep = "" and
automatic removal of length 0 inputs.

Hadley


-- 
Assistant Professor / Dobelman Family Junior Chair
Department of Statistics / Rice University
http://had.co.nz/


From pdalgd at gmail.com  Sun Jan 23 17:50:03 2011
From: pdalgd at gmail.com (peter dalgaard)
Date: Sun, 23 Jan 2011 17:50:03 +0100
Subject: [Rd] "+" operator on characters revisited
In-Reply-To: <878vycd7ld.fsf@gmail.com>
References: <878vycd7ld.fsf@gmail.com>
Message-ID: <E410A01D-653A-434F-B971-9EAC08324AC8@gmail.com>


On Jan 22, 2011, at 21:08 , Vitalie S. wrote:

> The only definite argument occurred in the thread against "+" operator
> was the lack of commutativity (as if one have to prove algebraic
> theorems in R).

I think the real killer was associativity, combined with coercion rules: 

Is "x"+1+2 supposed to be equal to "x12" or "x3"?

-- 
Peter Dalgaard
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From spencer.graves at structuremonitoring.com  Sun Jan 23 17:55:03 2011
From: spencer.graves at structuremonitoring.com (Spencer Graves)
Date: Sun, 23 Jan 2011 08:55:03 -0800
Subject: [Rd] "+" operator on characters revisited
In-Reply-To: <AANLkTinHarTQc60hN3yX5PJMy-d6TZneTYg7019YSRU=@mail.gmail.com>
References: <878vycd7ld.fsf@gmail.com>
	<AANLkTinHarTQc60hN3yX5PJMy-d6TZneTYg7019YSRU=@mail.gmail.com>
Message-ID: <4D3C5D67.9010101@structuremonitoring.com>

Consider the following from Python 2.6.5:


 >>> 'abc'+ 2

Traceback (most recent call last):
   File "<pyshell#0>", line 1, in <module>
     'abc'+ 2
TypeError: cannot concatenate 'str' and 'int' objects
 >>> 'abc'+'2'
'abc2'
 >>>


       Spencer


On 1/23/2011 8:09 AM, Hadley Wickham wrote:
>> Yet another useful suggestion of introducing cat0() and paste0(), for
>> the common use of cat and paste with sep="" was not absorbed by the
>> core R either.
> stringr has str_c which is a replacement for paste with sep = "" and
> automatic removal of length 0 inputs.
>
> Hadley
>
>


-- 
Spencer Graves, PE, PhD
President and Chief Operating Officer
Structure Inspection and Monitoring, Inc.
751 Emerson Ct.
San Jos?, CA 95126
ph:  408-655-4567


From spencer.graves at structuremonitoring.com  Sun Jan 23 18:10:39 2011
From: spencer.graves at structuremonitoring.com (Spencer Graves)
Date: Sun, 23 Jan 2011 09:10:39 -0800
Subject: [Rd] "+" operator on characters revisited
In-Reply-To: <E410A01D-653A-434F-B971-9EAC08324AC8@gmail.com>
References: <878vycd7ld.fsf@gmail.com>
	<E410A01D-653A-434F-B971-9EAC08324AC8@gmail.com>
Message-ID: <4D3C610F.4000005@structuremonitoring.com>

On 1/23/2011 8:50 AM, peter dalgaard wrote:
> On Jan 22, 2011, at 21:08 , Vitalie S. wrote:
>
>> The only definite argument occurred in the thread against "+" operator
>> was the lack of commutativity (as if one have to prove algebraic
>> theorems in R).
> I think the real killer was associativity, combined with coercion rules:
>
> Is "x"+1+2 supposed to be equal to "x12" or "x3"?
>
       Excellent:  This seems like a good reason to follow Python:  
Allow "a+b" with a character vector "a" only if "b" is also a character 
vector (or factor?).


       This example raises another question:  If we allow "a+b" for "a" 
and "b" both character vectors (and give an error if one is numeric), 
what do we do with factors?  If "a" is a factor, return a factor?


       Spencer


From murdoch.duncan at gmail.com  Sun Jan 23 18:38:47 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 23 Jan 2011 12:38:47 -0500
Subject: [Rd] "+" operator on characters revisited
In-Reply-To: <E410A01D-653A-434F-B971-9EAC08324AC8@gmail.com>
References: <878vycd7ld.fsf@gmail.com>
	<E410A01D-653A-434F-B971-9EAC08324AC8@gmail.com>
Message-ID: <4D3C67A7.4040101@gmail.com>

On 23/01/2011 11:50 AM, peter dalgaard wrote:
>
> On Jan 22, 2011, at 21:08 , Vitalie S. wrote:
>
>> The only definite argument occurred in the thread against "+" operator
>> was the lack of commutativity (as if one have to prove algebraic
>> theorems in R).
>
> I think the real killer was associativity, combined with coercion rules:
>
> Is "x"+1+2 supposed to be equal to "x12" or "x3"?
>

As I pointed out at the time, we don't even have associativity for 
integer addition.  For example in

-1L + .Machine$integer.max + 1L

the two possibilities

(-1L + .Machine$integer.max) + 1L

and

-1L + (.Machine$integer.max + 1L)

give different results.  When I try it now without parentheses, I get 
the same answer as the first one, but I don't believe we guarantee that 
that will always be so.

Duncan Murdoch


From thomas.friedrichsmeier at ruhr-uni-bochum.de  Sun Jan 23 20:06:09 2011
From: thomas.friedrichsmeier at ruhr-uni-bochum.de (Thomas Friedrichsmeier)
Date: 23 Jan 2011 20:06:09 +0100
Subject: [Rd] feature request: additional hook in plot.new()
In-Reply-To: <4D3C4CD5.30104@acm.org>
References: <4D3C4CD5.30104@acm.org>
Message-ID: <201101232006.16256.thomas.friedrichsmeier@ruhr-uni-bochum.de>

Hi Tony,

On Sunday 23 January 2011, you wrote:
> Request: An additional hook in plot.new() that is called prior to the call
> to .Internal(plot.new()). Reason: To allow the hook to set up or modify a
> graphics device that the new plot will appear in.

for what it's worth, you can work around the lack of this hook by modifying 
plot.new(). Here's what we do in RKWard (in order to add a plot history 
feature):

"plot.new" <- function () 
{
	# [your code goes here]

	eval (body (.rk.plot.new.default))
}
formals (plot.new) <- formals (graphics::plot.new)
.rk.plot.new.default <- graphics::plot.new

# Note: This needs to be called *after* the package has been loaded
assignInNamespace ("plot.new", plot.new, envir=as.environment 
("package:graphics"))

Note that at least persp() also sets up a new plot, _without_ calling 
plot.new(). So you'll want to catch that as well.

In RKWard we use this technique at a number of places to insert "hooks" where 
there are none, regularly.

Regards
Thomas
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 198 bytes
Desc: This is a digitally signed message part.
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110123/bc417e9d/attachment.bin>

From simon.urbanek at r-project.org  Sun Jan 23 21:18:20 2011
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Sun, 23 Jan 2011 15:18:20 -0500
Subject: [Rd] Windows script editor and locale
In-Reply-To: <alpine.LFD.2.00.1101211531210.27188@gannet.stats.ox.ac.uk>
References: <1B00FAE3-0417-46E5-94E6-B496A2538116@gmail.com>
	<alpine.LFD.2.00.1101211531210.27188@gannet.stats.ox.ac.uk>
Message-ID: <65B3147B-1944-4154-A5BD-761BB631DC11@r-project.org>

On Jan 21, 2011, at 10:57 AM, Prof Brian Ripley wrote:

> There is no support for files in alternative encodings in RGui's menus: not to source files nor to load into a pager or the script editor.  (I believe all of those long predate any support for encodings in R.)
> 
> Such provision is rather rare on Windows: files are almost everywhere assumed to be in the current Windows codepage (or sometimes WinANSI, as in the 'Command prompt' terminal) or in so-called Unicode (usually UCS-2LE, possibly UTF-16LE, with a BOM).
> 
> I think you could equally ask the same question in reverse: AFAICS the R.app GUI has no support for Latin-1 nor UCS-2LE files.  At least in our UK experience, the proportion of non-Windows users is so low that it is those (including this instructor) who expect to adjust.
> 

I have added a) encoding choice to the Save panel so you can save a file in a wide range of encodings and b) auto-detection of Unicode files (UTF-16LE with BOM) so they will be handled transparently. Note that R is always run in a UTF-8 locale so this only affects the read/save operations of R documents. There are a few loose ends I want to tackle later next week and document re-interpretation code is included but without a GUI yet (the idea is that if you fall-back to MacRoman you can re-interpret it in any other of the 8-bit character encodings like latin1 if you wish).

Cheers,
Simon


> What might make some sense is for file.edit() to gain a 'fileEncoding' argument so this could at least be done from the command-line.
> 
> On Fri, 21 Jan 2011, peter dalgaard wrote:
> 
>> Maybe I'm just overlooking something, but I can't figure out how to set/change the locale of a file loaded into the built-in script editor on Windows.
>> 
>> The generic issue is that if I make a teaching script on a Mac, save it to a USB stick, and open it in the script editor in a classroom, then special Danish characters in the comments come out as two-byte sequences, which are pretty unsightly. I know that I can convert the file with iconv (or iconv()), but then I'd have to maintain two copies of the same file for the two operating systems, if I want the students to access it. Would be nice if there was something like a set-coding-system to call up via a menu item.
>> 
>> Any pointers?
>> 
>> -- 
>> Peter Dalgaard
>> Center for Statistics, Copenhagen Business School
>> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
>> Phone: (+45)38153501
>> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> 
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From janko.thyson.rstuff at googlemail.com  Sun Jan 23 21:21:25 2011
From: janko.thyson.rstuff at googlemail.com (Janko Thyson)
Date: Sun, 23 Jan 2011 21:21:25 +0100
Subject: [Rd] "Simulate" package namespace at development stage
Message-ID: <4d3c8dbd.194cdf0a.1454.ffffe59d@mx.google.com>

Dear list,

I was wondering if it is possible to create and use a package namespace at
the development stage of a package. To clarify, I would like to make sure
that my package functions (and not some other functions that happen to have
identical names) are called by prepending function names appropriately (e.g.
my.package::foo()). Is that possible before a package is actually build and
loaded? If so, could you tell me how to do it?

Thanks a lot!
Janko


From simon.urbanek at r-project.org  Sun Jan 23 21:23:23 2011
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Sun, 23 Jan 2011 15:23:23 -0500
Subject: [Rd] feature request: additional hook in plot.new()
In-Reply-To: <4D3C4CD5.30104@acm.org>
References: <4D3C4CD5.30104@acm.org>
Message-ID: <570CC602-46B1-47A3-A419-CF43E8DD2996@r-project.org>


On Jan 23, 2011, at 10:44 AM, Tony Plate wrote:

> Request: An additional hook in plot.new() that is called prior to the call to .Internal(plot.new()).
> Reason: To allow the hook to set up or modify a graphics device that the new plot will appear in.
> 
> The code change needed for this is simple - just 4 new lines of R code in src/library/graphics/R/plot.R:plot.new()
> 
> Current definition of plot.new() in src/library/graphics/R/plot.R:
> 
> plot.new <- function()
> {
>    .Internal(plot.new())
>    for(fun in getHook("plot.new")) {
>        if(is.character(fun)) fun <- get(fun)
>        try(fun())
>    }
>    invisible()
> }
> 
> New definition of plot.new() in src/library/graphics/R/plot.R:
> 
> plot.new <- function()
> {
>    for(fun in getHook("plot.prenew")) {
>        if(is.character(fun)) fun <- get(fun)
>        try(fun())
>    }
>    .Internal(plot.new())
>    for(fun in getHook("plot.new")) {
>        if(is.character(fun)) fun <- get(fun)
>        try(fun())
>    }
>    invisible()
> }
> 
> In src/library/graphics/man/frame.Rd after the existing sentence beginning "There is a hook..." in the DETAILS section, the following sentence could be added:
> 
> "There is another hook called \code{"plot.prenew"} which is called before advancing the frame.  This hook can be used to create a new plot "
> 
> The name of the hook is not very important -- I've suggested "plot.prenew" here.  Another possibility could be "plot.new0".
> 
> More detail on the reason:
> 
> In a tabbed graphics widget (https://r-forge.r-project.org/projects/tabbedplots/ ), having this hook would enable it to operate in a mode where a new tab is automatically created for each new plot.
> 

Just note on the latter: I would expect this to be usually better handled by the device/UI as you will be in conflict with things like plot history, already supported tabbed devices etc. Do you have a use case where the above has any benefits over separate devices in tabs? (The website has little detail so I'm just guessing what you're up to ..).

Cheers,
Simon


From spinuvit.list at gmail.com  Sun Jan 23 21:15:59 2011
From: spinuvit.list at gmail.com (Vitalie S.)
Date: Sun, 23 Jan 2011 21:15:59 +0100
Subject: [Rd] "+" operator on characters revisited
References: <878vycd7ld.fsf@gmail.com>
	<E410A01D-653A-434F-B971-9EAC08324AC8@gmail.com>
	<4D3C610F.4000005@structuremonitoring.com>
Message-ID: <87vd1fbclc.fsf@gmail.com>

Spencer Graves <spencer.graves at structuremonitoring.com> writes:

> On 1/23/2011 8:50 AM, peter dalgaard wrote:
>> On Jan 22, 2011, at 21:08 , Vitalie S. wrote:
>>
>>> The only definite argument occurred in the thread against "+" operator
>>> was the lack of commutativity (as if one have to prove algebraic
>>> theorems in R).
>> I think the real killer was associativity, combined with coercion rules:
>>
>> Is "x"+1+2 supposed to be equal to "x12" or "x3"?
>>
>       Excellent:  This seems like a good reason to follow Python:  Allow "a+b" with a character vector "a" only if
> "b" is also a character vector (or factor?).
>
>       This example raises another question:  If we allow "a+b" for "a" and "b" both character vectors (and give an
> error if one is numeric), what do we do with factors?  If "a" is a factor,
> return a factor?

If we define custom %+% as:

    `%+%` <- function(a, b){
        if(is.character(a) || is.character(b))
            paste(as.character(a), as.character(b), sep="")
        else
            a + b
    }

because of higher precedence of %any% operators over binary + we have:

    "a" %+% 1 %+% 2
    ## [1] "a12"

and

   str("a" %+% factor(1:2))
   ## chr [1:2] "a1" "a2"

so if + on characters would behave "as if" having slightly higher priority than
other + operators that might solve reasonably the problem. 

Vitalie.


From spencer.graves at structuremonitoring.com  Sun Jan 23 23:30:01 2011
From: spencer.graves at structuremonitoring.com (Spencer Graves)
Date: Sun, 23 Jan 2011 14:30:01 -0800
Subject: [Rd] "+" operator on characters revisited
In-Reply-To: <87vd1fbclc.fsf@gmail.com>
References: <878vycd7ld.fsf@gmail.com>	<E410A01D-653A-434F-B971-9EAC08324AC8@gmail.com>	<4D3C610F.4000005@structuremonitoring.com>
	<87vd1fbclc.fsf@gmail.com>
Message-ID: <4D3CABE9.6020208@structuremonitoring.com>



On 1/23/2011 12:15 PM, Vitalie S. wrote:
> Spencer Graves<spencer.graves at structuremonitoring.com>  writes:
>
>> On 1/23/2011 8:50 AM, peter dalgaard wrote:
>>> On Jan 22, 2011, at 21:08 , Vitalie S. wrote:
>>>
>>>> The only definite argument occurred in the thread against "+" operator
>>>> was the lack of commutativity (as if one have to prove algebraic
>>>> theorems in R).
>>> I think the real killer was associativity, combined with coercion rules:
>>>
>>> Is "x"+1+2 supposed to be equal to "x12" or "x3"?
>>>
>>        Excellent:  This seems like a good reason to follow Python:  Allow "a+b" with a character vector "a" only if
>> "b" is also a character vector (or factor?).
>>
>>        This example raises another question:  If we allow "a+b" for "a" and "b" both character vectors (and give an
>> error if one is numeric), what do we do with factors?  If "a" is a factor,
>> return a factor?
> If we define custom %+% as:
>
>      `%+%`<- function(a, b){
>          if(is.character(a) || is.character(b))
>              paste(as.character(a), as.character(b), sep="")
>          else
>              a + b
>      }
>
> because of higher precedence of %any% operators over binary + we have:
>
>      "a" %+% 1 %+% 2
>      ## [1] "a12"
>
> and
>
>     str("a" %+% factor(1:2))
>     ## chr [1:2] "a1" "a2"
>
> so if + on characters would behave "as if" having slightly higher priority than
> other + operators that might solve reasonably the problem.
>
> Vitalie.

No:  'a' %+% (1 %+%2)  != ('a' %+% 1) %+% 2, as Peter Dalgaard noted:  
'a3' != 'a12'.


> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From olafm at statistik.tu-dortmund.de  Mon Jan 24 09:15:54 2011
From: olafm at statistik.tu-dortmund.de (Olaf Mersmann)
Date: Mon, 24 Jan 2011 09:15:54 +0100
Subject: [Rd] Possible bug in R parser
Message-ID: <AANLkTimQVCHSFXHRaLtJXY_NpTxRHsZcdyNQ9h+UT4jA@mail.gmail.com>

Dear R developers,

A recent typo led me to discover, that R is happy to accept

  > 20x2
  [1] 20

as input. This appears to be related to the parsing of hexadecimal
constants, since there must be a zero before the 'x' (i.e. 2x2 or
02x02 gives the expected error). All this is under R 2.12.1 on both OS
X and Linux. Is this expected behavior?

Cheers,
Olaf Mersmann


From ligges at statistik.tu-dortmund.de  Mon Jan 24 11:47:47 2011
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Mon, 24 Jan 2011 11:47:47 +0100
Subject: [Rd] "Simulate" package namespace at development stage
In-Reply-To: <4d3c8dbd.194cdf0a.1454.ffffe59d@mx.google.com>
References: <4d3c8dbd.194cdf0a.1454.ffffe59d@mx.google.com>
Message-ID: <4D3D58D3.3050809@statistik.tu-dortmund.de>



On 23.01.2011 21:21, Janko Thyson wrote:
> Dear list,
>
> I was wondering if it is possible to create and use a package namespace at
> the development stage of a package. To clarify, I would like to make sure
> that my package functions (and not some other functions that happen to have
> identical names) are called by prepending function names appropriately (e.g.
> my.package::foo()). Is that possible before a package is actually build and
> loaded? If so, could you tell me how to do it?

No, unless you work around by assigning the stuff in certain 
environments, which would be less convenient than just 
building/installing/testing the package.

Uwe Ligges


> Thanks a lot!
> Janko
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From jhibschman at gmail.com  Mon Jan 24 17:01:18 2011
From: jhibschman at gmail.com (Johann Hibschman)
Date: Mon, 24 Jan 2011 10:01:18 -0600
Subject: [Rd] setGeneric for residuals, etc
References: <u1ok4hzfvi5.fsf@lx-chrateresearch01.citadelgroup.com>
	<4d39774c.825bdf0a.5ca4.ffffa40a@mx.google.com>
Message-ID: <u1ozkqqqoj5.fsf@lx-chrateresearch01.citadelgroup.com>

"Janko Thyson" <janko.thyson.rstuff at googlemail.com> writes:

>> I'm experimenting with a few model-fitting classes of my own.  I'm
>> leaning towards using S4 for my classes, but the R functions I'd want
>> to override (residuals, predict, etc.) are all S3 methods.

> For example, inside your method for 'residuals()', you will
> probably just get some data out of a slot of your object and run the S3
> function 'residuals(your.slot.data)'. So there's nothing that should make
> you nervous in that respect, you're not overwriting anything with your
> method. Setting a generic for an existing function is just a necessary step
> in order to specify S4 methods for it. 

Yes, I understand that it's a necessary step in R, but I'm still puzzled
as to why it's necessary.  (And by "why", I don't mean the technical
point that 'residuals' is not an S4 generic function; I mean why isn't
it a S4 generic function already?)

In principle, R could be shipped with all S3 functions replaced by S4
functions that default to the S3 implementation.  That would be a
benefit to everyone writing S4 objects.  The fact that it's not been
done seems to imply it would have a cost to people writing S3 objects,
so I'm trying to understand what that cost is.

Perhaps I'm seeing an implied risk where I really should be seeing a
loose federation of developers with disparate interests, and the slow
pace of "global" change that implies.

Thanks,
Johann


From kasperdanielhansen at gmail.com  Mon Jan 24 17:37:23 2011
From: kasperdanielhansen at gmail.com (Kasper Daniel Hansen)
Date: Mon, 24 Jan 2011 11:37:23 -0500
Subject: [Rd] setGeneric for residuals, etc
In-Reply-To: <u1ozkqqqoj5.fsf@lx-chrateresearch01.citadelgroup.com>
References: <u1ok4hzfvi5.fsf@lx-chrateresearch01.citadelgroup.com>
	<4d39774c.825bdf0a.5ca4.ffffa40a@mx.google.com>
	<u1ozkqqqoj5.fsf@lx-chrateresearch01.citadelgroup.com>
Message-ID: <AANLkTin9T2P1LBRRwOSxVc9HG72J37evh5+zv5kEK6zU@mail.gmail.com>

Johann,

whether S4 is "better" than S3 is a heated subject.  No-one (I think)
disputes that S4 is in some sense more flexible (for some suitable
definition of flexible), but it does incur some performance overhead
(how much is debatable) and some would argue that it also makes code
more complicated and harder to debug.

But take a look at stats4.

Kasper

On Mon, Jan 24, 2011 at 11:01 AM, Johann Hibschman <jhibschman at gmail.com> wrote:
> "Janko Thyson" <janko.thyson.rstuff at googlemail.com> writes:
>
>>> I'm experimenting with a few model-fitting classes of my own. ?I'm
>>> leaning towards using S4 for my classes, but the R functions I'd want
>>> to override (residuals, predict, etc.) are all S3 methods.
>
>> For example, inside your method for 'residuals()', you will
>> probably just get some data out of a slot of your object and run the S3
>> function 'residuals(your.slot.data)'. So there's nothing that should make
>> you nervous in that respect, you're not overwriting anything with your
>> method. Setting a generic for an existing function is just a necessary step
>> in order to specify S4 methods for it.
>
> Yes, I understand that it's a necessary step in R, but I'm still puzzled
> as to why it's necessary. ?(And by "why", I don't mean the technical
> point that 'residuals' is not an S4 generic function; I mean why isn't
> it a S4 generic function already?)
>
> In principle, R could be shipped with all S3 functions replaced by S4
> functions that default to the S3 implementation. ?That would be a
> benefit to everyone writing S4 objects. ?The fact that it's not been
> done seems to imply it would have a cost to people writing S3 objects,
> so I'm trying to understand what that cost is.
>
> Perhaps I'm seeing an implied risk where I really should be seeing a
> loose federation of developers with disparate interests, and the slow
> pace of "global" change that implies.
>
> Thanks,
> Johann
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From karthi_subramanian at yahoo.ca  Mon Jan 24 18:05:45 2011
From: karthi_subramanian at yahoo.ca (Karthi Subramanian)
Date: Mon, 24 Jan 2011 09:05:45 -0800 (PST)
Subject: [Rd] normality and equal variance testing
Message-ID: <86509.71814.qm@web161703.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110124/74696a06/attachment.pl>

From mtmorgan at fhcrc.org  Mon Jan 24 18:13:36 2011
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Mon, 24 Jan 2011 09:13:36 -0800
Subject: [Rd] setGeneric for residuals, etc
In-Reply-To: <AANLkTin9T2P1LBRRwOSxVc9HG72J37evh5+zv5kEK6zU@mail.gmail.com>
References: <u1ok4hzfvi5.fsf@lx-chrateresearch01.citadelgroup.com>	<4d39774c.825bdf0a.5ca4.ffffa40a@mx.google.com>	<u1ozkqqqoj5.fsf@lx-chrateresearch01.citadelgroup.com>
	<AANLkTin9T2P1LBRRwOSxVc9HG72J37evh5+zv5kEK6zU@mail.gmail.com>
Message-ID: <4D3DB340.4090207@fhcrc.org>

On 01/24/2011 08:37 AM, Kasper Daniel Hansen wrote:
> Johann,
> 
> whether S4 is "better" than S3 is a heated subject.  No-one (I think)
> disputes that S4 is in some sense more flexible (for some suitable
> definition of flexible), but it does incur some performance overhead
> (how much is debatable) and some would argue that it also makes code
> more complicated and harder to debug.
> 
> But take a look at stats4.
> 
> Kasper
> 
> On Mon, Jan 24, 2011 at 11:01 AM, Johann Hibschman <jhibschman at gmail.com> wrote:
>> "Janko Thyson" <janko.thyson.rstuff at googlemail.com> writes:
>>
>>>> I'm experimenting with a few model-fitting classes of my own.  I'm
>>>> leaning towards using S4 for my classes, but the R functions I'd want
>>>> to override (residuals, predict, etc.) are all S3 methods.
>>
>>> For example, inside your method for 'residuals()', you will
>>> probably just get some data out of a slot of your object and run the S3
>>> function 'residuals(your.slot.data)'. So there's nothing that should make
>>> you nervous in that respect, you're not overwriting anything with your
>>> method. Setting a generic for an existing function is just a necessary step
>>> in order to specify S4 methods for it.
>>
>> Yes, I understand that it's a necessary step in R, but I'm still puzzled
>> as to why it's necessary.  (And by "why", I don't mean the technical
>> point that 'residuals' is not an S4 generic function; I mean why isn't
>> it a S4 generic function already?)
>>
>> In principle, R could be shipped with all S3 functions replaced by S4
>> functions that default to the S3 implementation.  That would be a
>> benefit to everyone writing S4 objects.  The fact that it's not been
>> done seems to imply it would have a cost to people writing S3 objects,
>> so I'm trying to understand what that cost is.

As Kasper mentioned the current S4 implementation has costs in terms of
performance and usability that I suppose make it unappealing as a
'built-in' feature of R.

The current situation, where individual package developers promote a
function to an S4 generic, can lead to many issues. Some of these
represent bugs in the implementation of S4, e.g., incorrect dispatch
with complicated class hierarchies and package dependencies, that are
very challenging for the average developer (me, for instance) to fathom.
There are also more conceptual issues, e.g., two packages can each
create generics that are exported from separate package name spaces,
with the usual rules of the R search path determining which generic is
discovered. This is very confusing to the user, who has been told that
they are using a 'generic'. Documentation is also very confusing, as the
generic is documented in several different places.

These issues become increasingly important as package hierarchies
required for analysis become complicated; the average CRAN package has
relatively few dependencies and for many there will be no problem. The
class hierarchy and collection of packages for a typical Bioconductor
analysis can be quite large and complicated, leading to subtle problems.

Martin

>>
>> Perhaps I'm seeing an implied risk where I really should be seeing a
>> loose federation of developers with disparate interests, and the slow
>> pace of "global" change that implies.
>>
>> Thanks,
>> Johann
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
Computational Biology
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N. PO Box 19024 Seattle, WA 98109

Location: M1-B861
Telephone: 206 667-2793


From mdowle at mdowle.plus.com  Mon Jan 24 18:30:38 2011
From: mdowle at mdowle.plus.com (Matthew Dowle)
Date: Mon, 24 Jan 2011 17:30:38 -0000
Subject: [Rd] match function causing bad performance when using
	tablefunction on factors with multibyte characters on Windows
References: <ihbko3$efs$1@dough.gmane.org>
Message-ID: <ihkd01$bem$1@dough.gmane.org>


I'm not sure, but note the difference in locale between
Linux (UTF-8) and Windows (non UTF-8). As far as I
understand it R much prefers UTF-8, which Windows doesn't
natively support. Otherwise you could just change your
Windows locale to a UTF-8 locale to make R happier.

My stab in the dark would be that the poor performance on
Windows in this case may be down to many calls to
translateCharUTF8 internally.

There was a change in R 2.12.0 in this area. Running your
test in R 2.11.1 on Windows shows the same problem though
so it doesn't look like that change caused this problem.

>From NEWS 2.12.0 :
o  unique() and match() are now faster on character vectors
    where all elements are in the global CHARSXP cache and
    have unmarked encoding (ASCII). Thanks to Matthew
    Dowle for suggesting improvements to the way the hash
    code is generated in 'unique.c'

If anybody knows a way to trick R on Linux into thinking it has
an encoding similar to Windows then I may be able to take a
look if I can reproduce the problem in Linux.

Matthew


"Karl Ove Hufthammer" <karl at huftis.org> wrote in message 
news:ihbko3$efs$1 at dough.gmane.org...
> [I originally posted this on the R-help mailing list, and it was suggested 
> that R-devel would be a better
> place to dicuss it.]
>
> Running 'table' on a factor with levels containing non-ASCII characters
> seems to result in extremely bad performance on Windows. Here's a simple
> example with benchmark results (I've reduced the number of replications to
> make the function finish within reasonable time):
>
>  library(rbenchmark)
>  x.num=sample(1:2, 10^5, replace=TRUE)
>  x.fac.ascii=factor(x.num, levels=1:2, labels=c("A","B"))
>  x.fac.nascii=factor(x.num, levels=1:2, labels=c("?","?"))
>  benchmark( table(x.num), table(x.fac.ascii), table(x.fac.nascii), 
> table(unclass(x.fac.nascii)), replications=20 )
>
>                            test replications elapsed   relative user.self 
> sys.self user.child sys.child
>  4 table(unclass(x.fac.nascii))           20    1.53   4.636364      1.51 
> 0.01         NA        NA
>  2           table(x.fac.ascii)           20    0.33   1.000000      0.33 
> 0.00         NA        NA
>  3          table(x.fac.nascii)           20  146.67 444.454545     38.52 
> 81.74         NA        NA
>  1                 table(x.num)           20    1.55   4.696970      1.53 
> 0.01         NA        NA
>
>  sessionInfo()
>  R version 2.12.1 (2010-12-16)
>  Platform: i386-pc-mingw32/i386 (32-bit)
>
>  locale:
>  [1] LC_COLLATE=Norwegian-Nynorsk_Norway.1252 
> LC_CTYPE=Norwegian-Nynorsk_Norway.1252 
> LC_MONETARY=Norwegian-Nynorsk_Norway.1252
>  [4] LC_NUMERIC=C 
> LC_TIME=Norwegian-Nynorsk_Norway.1252
>
>  attached base packages:
>  [1] stats     graphics  grDevices datasets  utils     methods   base
>
>  other attached packages:
>  [1] rbenchmark_0.3
>
> The timings are from R 2.12.1, but I also get comparable results
> on the latest prelease (R 2.13.0 2011-01-18 r54032).
>
> Running the same test (100 replications) on a Linux system with
> R.12.1 Patched results in essentially no difference between the
> performance on ASCII factors and non-ASCII factors:
>
>                            test replications elapsed relative user.self 
> sys.self user.child sys.child
>  4 table(unclass(x.fac.nascii))          100   4.607 3.096102     4.455 
> 0.092          0         0
>  2           table(x.fac.ascii)          100   1.488 1.000000     1.459 
> 0.028          0         0
>  3          table(x.fac.nascii)          100   1.616 1.086022     1.560 
> 0.051          0         0
>  1                 table(x.num)          100   4.504 3.026882     4.403 
> 0.079          0         0
>
>  sessionInfo()
>  R version 2.12.1 Patched (2011-01-18 r54033)
>  Platform: i686-pc-linux-gnu (32-bit)
>
>  locale:
>   [1] LC_CTYPE=nn_NO.UTF-8       LC_NUMERIC=C 
> LC_TIME=nn_NO.UTF-8
>   [4] LC_COLLATE=nn_NO.UTF-8     LC_MONETARY=C 
> LC_MESSAGES=nn_NO.UTF-8
>   [7] LC_PAPER=nn_NO.UTF-8       LC_NAME=C                  LC_ADDRESS=C
>  [10] LC_TELEPHONE=C             LC_MEASUREMENT=nn_NO.UTF-8 
> LC_IDENTIFICATION=C
>
>  attached base packages:
>  [1] stats     graphics  grDevices utils     datasets  methods   base
>
>  other attached packages:
>  [1] rbenchmark_0.3
>
> Profiling the 'table' function indicates almost all the time if spent in
> the 'match' function, which is used when 'factor' is used on a 'factor'
> inside 'table'. Indeed, 'x.fac.nascii = factor(x.fac.nascii)' by itself
> is extremely slow.
>
> Is there any theoretical reason 'factor' on 'factor' with non-ASCII
> characters must be so slow? And why doesn't this happen on Linux?
>
> Perhaps a fix for 'table' might be calculating the 'table' statistics
> *including* all levels (not using the 'factor' function anywhere),
> and then removing the 'exclude' levels in the end. For example,
> something along these lines:
>
> res = table.modified.to.not.use.factor(...)
> ind = lapply(dimnames(res), function(x) !(x %in% exclude))
> do.call("[", c(list(res), ind, drop=FALSE))
>
> (I haven't tested this very much, so there may be issues with this
> way of doing things.)
>
> -- 
> Karl Ove Hufthammer
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From cubranic at stat.ubc.ca  Mon Jan 24 20:15:29 2011
From: cubranic at stat.ubc.ca (Davor Cubranic)
Date: Mon, 24 Jan 2011 11:15:29 -0800
Subject: [Rd] "+" operator on characters revisited
In-Reply-To: <AANLkTikZ8M38vX1eGs76EK-FwMoOFJBuJHbF2_Jdj0St@mail.gmail.com>
References: <878vycd7ld.fsf@gmail.com>
	<AANLkTin_=MtMYZOjprLme53-H4XVOD7y_d9DpH+OiEb_@mail.gmail.com>
	<cpnei83q1dp.fsf@gmail.com>
	<AANLkTikZ8M38vX1eGs76EK-FwMoOFJBuJHbF2_Jdj0St@mail.gmail.com>
Message-ID: <6C93669D-6B58-45B6-86DC-2A77984C7CC3@stat.ubc.ca>

On 2011-01-23, at 4:34 AM, Gabor Grothendieck wrote:

> On Sun, Jan 23, 2011 at 6:56 AM, Vitalie S. <spinuvit.list at gmail.com> wrote:
>> Gabor Grothendieck <ggrothendieck at gmail.com> writes:
>> 
>>> Also the gsubfn supports quasi perl style string interpolation that
>>> can sometimes be used to avoid the use of paste in the first place.
>>> Just preface the function in question by fn$ like this:
>>> 
>>> library(gsubfn)
>>> fn$cat("pi = $pi\n")
>> 
>> Thanks for the tip. Not bad indeed.
>> Almost as readable as
>> 
>> cat("pi = " + pi + "\n")
> 
> To me the + can be substantially less readable.  The need to
> repeatedly quote everything makes it just as bad as paste.  Compare
> the following and try to figure out if there is an error in quoting in
> the + and paste solutions.  Trying to distinguish the single and
> double quotes is pretty difficult but simple in the fn$ and sprintf
> solutions.  Even if there were no quotes the constant need to
> interpose quotes makes it hard to read.

That may be a matter of taste, but FWIW it seems that shell-style string interpolation (using the dollar prefix) has going out of style in recent scripting languages. Ruby uses the expression substitution construct ("#{expr}"), while Python has "str.format", both allowing arbitrary expressions.

And most editors have syntax highlighting that distinguishes strings from other program elements. This makes quoting errors pretty obvious.

Davor

From ggrothendieck at gmail.com  Mon Jan 24 20:30:29 2011
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 24 Jan 2011 14:30:29 -0500
Subject: [Rd] "+" operator on characters revisited
In-Reply-To: <6C93669D-6B58-45B6-86DC-2A77984C7CC3@stat.ubc.ca>
References: <878vycd7ld.fsf@gmail.com>
	<AANLkTin_=MtMYZOjprLme53-H4XVOD7y_d9DpH+OiEb_@mail.gmail.com>
	<cpnei83q1dp.fsf@gmail.com>
	<AANLkTikZ8M38vX1eGs76EK-FwMoOFJBuJHbF2_Jdj0St@mail.gmail.com>
	<6C93669D-6B58-45B6-86DC-2A77984C7CC3@stat.ubc.ca>
Message-ID: <AANLkTikrk29EpzreB-QZ5a+z-kvW_5sWp+pq1ASA7jyR@mail.gmail.com>

On Mon, Jan 24, 2011 at 2:15 PM, Davor Cubranic <cubranic at stat.ubc.ca> wrote:
> On 2011-01-23, at 4:34 AM, Gabor Grothendieck wrote:
>
>> On Sun, Jan 23, 2011 at 6:56 AM, Vitalie S. <spinuvit.list at gmail.com> wrote:
>>> Gabor Grothendieck <ggrothendieck at gmail.com> writes:
>>>
>>>> Also the gsubfn supports quasi perl style string interpolation that
>>>> can sometimes be used to avoid the use of paste in the first place.
>>>> Just preface the function in question by fn$ like this:
>>>>
>>>> library(gsubfn)
>>>> fn$cat("pi = $pi\n")
>>>
>>> Thanks for the tip. Not bad indeed.
>>> Almost as readable as
>>>
>>> cat("pi = " + pi + "\n")
>>
>> To me the + can be substantially less readable. ?The need to
>> repeatedly quote everything makes it just as bad as paste. ?Compare
>> the following and try to figure out if there is an error in quoting in
>> the + and paste solutions. ?Trying to distinguish the single and
>> double quotes is pretty difficult but simple in the fn$ and sprintf
>> solutions. ?Even if there were no quotes the constant need to
>> interpose quotes makes it hard to read.
>
> That may be a matter of taste, but FWIW it seems that shell-style string interpolation (using the dollar prefix) has going out of style in recent scripting languages. Ruby uses the expression substitution construct ("#{expr}"), while Python has "str.format", both allowing arbitrary expressions.
>

fn$ supports that too using `...`

> library(sqldf)
> fn$sqldf("select * from BOD where demand > `mean(BOD$demand)` limit 2")
  Time demand
1    3     19
2    4     16


> And most editors have syntax highlighting that distinguishes strings from other program elements. This makes quoting errors pretty obvious.
>

That only makes it slightly easier to handle the mess.  Its better to
get rid of the quotes in the first place.

-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From bbolker at gmail.com  Mon Jan 24 22:01:30 2011
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 24 Jan 2011 21:01:30 +0000 (UTC)
Subject: [Rd] normality and equal variance testing
References: <86509.71814.qm@web161703.mail.bf1.yahoo.com>
Message-ID: <loom.20110124T215645-21@post.gmane.org>

Karthi Subramanian <karthi_subramanian <at> yahoo.ca> writes:

> 
> I currently have a program that automates 2-way ANOVA on a series of
> endpoints, but before the ANOVA is carried out I want the code to
> test the assumptions of normality and equal variance and report along
>  with each anova result in the 
> output file.? How can I do this? 
> 
 [snip]

  I think this is the wrong list for this question; please see
<http://www.r-project.org/posting-guide.html#which_list>

  See ?shapiro.test, ?fligner.test, nortest package ...

also library(sos); findFn("{normality test}"), etc.


From Greg.Snow at imail.org  Mon Jan 24 22:02:49 2011
From: Greg.Snow at imail.org (Greg Snow)
Date: Mon, 24 Jan 2011 14:02:49 -0700
Subject: [Rd] normality and equal variance testing
In-Reply-To: <86509.71814.qm@web161703.mail.bf1.yahoo.com>
References: <86509.71814.qm@web161703.mail.bf1.yahoo.com>
Message-ID: <B37C0A15B8FB3C468B5BC7EBC7DA14CC634247A051@LP-EXMBVS10.CO.IHC.COM>

Why do you want to test for normality and equal variances?

If those are really a concern then you should use a method up front that is robust against those.  Those tests are usually testing a hypothesis that is different from what you are actually interested in and generally have low power to guide further tests.

-- 
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at imail.org
801.408.8111


> -----Original Message-----
> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-
> project.org] On Behalf Of Karthi Subramanian
> Sent: Monday, January 24, 2011 10:06 AM
> To: R-devel at r-project.org
> Subject: [Rd] normality and equal variance testing
> 
> I currently have a program that automates 2-way ANOVA on a series of
> endpoints,
> but before the ANOVA is carried out I want the code to test the
> assumptions of
> normality and equal variance and report along with each anova result in
> the
> output file.? How can I do this?
> 
> 
> I have pasted below the code that I currently use.
> 
> 
> library(car)
> numFiles = x # <--<--<--<--<--<--<--<--<--<--<-- supply the number of
> files
> containing the source data here
> for (iIndx in 1:numFiles) {
> ?????? sinkFilePath = paste("C:/AnovaData/2WayAnovaForProteins_Set",
> iIndx,
> ".txt", sep="")
> ?sink(sinkFilePath)
> ?sourceFilePath = paste("C:/AnovaData/ProteinsFor2WayAnova_Set", iIndx,
> ".txt",
> sep="")
> ?dataSet = read.delim(sourceFilePath)
> ?numProteins = ncol(dataSet)
> ?nameProteins = colnames(dataSet)
> ?for (i in 3:numProteins) {
> ??fla = as.formula(paste(nameProteins[i],"~","Trt*Dose"))
> ??mod = lm(fla, data = dataSet , contrasts = list(Trt = contr.sum, Dose
> =
> contr.sum))
> ??ano = Anova(mod, type = "III")
> ??print.noquote("")
> ??print.noquote("")
> ??print.noquote("--------------------------------------------")
> ??print.noquote(paste("--------- Analysis of Spot:
> ",nameProteins[i],"------------"))
> ??print.noquote("--------------------------------------------")
> ??print(ano)
> ?}
> }
> 
> 
> Thanks in advance.
> Karthi
> 
> 
> 	[[alternative HTML version deleted]]


From beniltoncarvalho at gmail.com  Mon Jan 24 23:07:28 2011
From: beniltoncarvalho at gmail.com (Benilton Carvalho)
Date: Mon, 24 Jan 2011 22:07:28 +0000
Subject: [Rd] news.Rd format
In-Reply-To: <201101221558.p0MFweE3007920@punchbuggy.mayo.edu>
References: <201101221558.p0MFweE3007920@punchbuggy.mayo.edu>
Message-ID: <AANLkTikg5ZfOeXTbwZxHc0Hgu-KaWs5-KKGpv+sNnDy8@mail.gmail.com>

the version format should be x.y

'Changes in version 2.36' should work...

benilton

On 22 January 2011 15:58, Terry Therneau <therneau at mayo.edu> wrote:
> ?I'm converting the "Changelog" files that I have used in the survival package
> (since the 1980s) to the inst/NEWS.Rd format and a couple of things are not
> clear from the help page.
> ?1. What should I use for the name: NEWS or survival?
> ?2. My section headers look like
> ? ?\section{Changes in version 2.36-3}{
> ? ? ?\itemize{
> ?etc
> and I get "cannot extract version info from the following section titles" for all of them. ?I must be missing something simple.
>
> ?Perhaps these two points could be clarified further in the manual page.
>
> Terry Therneau
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From ripley at stats.ox.ac.uk  Tue Jan 25 08:22:12 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 25 Jan 2011 07:22:12 +0000 (GMT)
Subject: [Rd] Possible bug in R parser
In-Reply-To: <AANLkTimQVCHSFXHRaLtJXY_NpTxRHsZcdyNQ9h+UT4jA@mail.gmail.com>
References: <AANLkTimQVCHSFXHRaLtJXY_NpTxRHsZcdyNQ9h+UT4jA@mail.gmail.com>
Message-ID: <alpine.LFD.2.00.1101250650220.27617@gannet.stats.ox.ac.uk>

On Mon, 24 Jan 2011, Olaf Mersmann wrote:

> Dear R developers,
>
> A recent typo led me to discover, that R is happy to accept
>
>  > 20x2
>  [1] 20
>
> as input. This appears to be related to the parsing of hexadecimal
> constants, since there must be a zero before the 'x' (i.e. 2x2 or
> 02x02 gives the expected error). All this is under R 2.12.1 on both OS
> X and Linux. Is this expected behavior?

Only 'expected' in so far as we don't expect the parser to always 
detect incorrect numeric constants (since we've seen other instances, 
and it does not use a grammar for numeric constants).

I'll change the rules to detect this one -- thanks for the report and 
example.

> Cheers,
> Olaf Mersmann

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From renaud at mancala.cbio.uct.ac.za  Tue Jan 25 10:27:47 2011
From: renaud at mancala.cbio.uct.ac.za (Renaud Gaujoux)
Date: Tue, 25 Jan 2011 11:27:47 +0200
Subject: [Rd] Missing argument vs. empty argument
Message-ID: <4D3E9793.6040309@cbio.uct.ac.za>

Hi,

is there an easy, robust, and/or recommended way to distinguish a 
missing argument from an empty argument as in:

foo <- function(i, j){
     print(missing(j))
     print(nargs())
}

foo(i)  # TRUE, 1
foo(i,) # TRUE, 2

I know I can work around with nargs, the list of arguments and the names 
of the passed arguments, but I wish there is something already in place 
for this.
This is specially important for '['-like methods where x[i,] is not the 
same as x[i].
What I am looking for is a function that tells me if an argument has 
actually been passed empty:

foo <- function(i, j, k){
     print( empty.arg(j) )
     print(nargs())
}

would result in:

foo(i) # FALSE, 1
foo(i, ) # TRUE, 2
foo(i, j) # FALSE, 2
foo(i, k=2) # FALSE, 2
foo(i, k=2, ) # TRUE, 3

Thank you for any help or pointer.

Bests,
Renaud


 

###
UNIVERSITY OF CAPE TOWN 

This e-mail is subject to the UCT ICT policies and e-mai...{{dropped:5}}


From karl.forner at gmail.com  Tue Jan 25 11:27:14 2011
From: karl.forner at gmail.com (Karl Forner)
Date: Tue, 25 Jan 2011 11:27:14 +0100
Subject: [Rd] dendrogram plot does not draw long labels ?
Message-ID: <AANLkTikuvd7q4xbyzEdfp+G_k1CsEM_db7zxZXpiQcWg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110125/1e74f341/attachment.pl>

From ripley at stats.ox.ac.uk  Tue Jan 25 11:53:19 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 25 Jan 2011 10:53:19 +0000 (GMT)
Subject: [Rd] Missing argument vs. empty argument
In-Reply-To: <4D3E9793.6040309@cbio.uct.ac.za>
References: <4D3E9793.6040309@cbio.uct.ac.za>
Message-ID: <alpine.LFD.2.00.1101251039330.19721@toucan.stats.ox.ac.uk>

On Tue, 25 Jan 2011, Renaud Gaujoux wrote:

> Hi,
>
> is there an easy, robust, and/or recommended way to distinguish a missing 
> argument from an empty argument as in:

An empty argument is a missing argument when argument matching is 
done, e.g.

> foo <- function(i,j) match.call()
> foo(i)
foo(i = i)
> foo(i,)
foo(i = i)
> foo(,j)
foo(j = j)

It is rather against the spirit of R to use the actual call rather 
than the matched call.  Unless you are doing this to write a '[' 
method I would suggest you find a different convention, e.g. 
distinguish f(i) and f(i, NULL).  For the exception, look at 
`[.data.frame`, which does use nargs().

(NB: what I have said does not apply to primitives like '[' itself, 
which do not do standard argument matching.)


>
> foo <- function(i, j){
>    print(missing(j))
>    print(nargs())
> }
>
> foo(i)  # TRUE, 1
> foo(i,) # TRUE, 2
>
> I know I can work around with nargs, the list of arguments and the names of 
> the passed arguments, but I wish there is something already in place for 
> this.
> This is specially important for '['-like methods where x[i,] is not the same 
> as x[i].
> What I am looking for is a function that tells me if an argument has actually 
> been passed empty:
>
> foo <- function(i, j, k){
>    print( empty.arg(j) )
>    print(nargs())
> }
>
> would result in:
>
> foo(i) # FALSE, 1
> foo(i, ) # TRUE, 2
> foo(i, j) # FALSE, 2
> foo(i, k=2) # FALSE, 2
> foo(i, k=2, ) # TRUE, 3
>
> Thank you for any help or pointer.
>
> Bests,
> Renaud
>
>
>
>
> ###
> UNIVERSITY OF CAPE TOWN 
> This e-mail is subject to the UCT ICT policies and e-mai...{{dropped:5}}
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From renaud at mancala.cbio.uct.ac.za  Tue Jan 25 12:01:38 2011
From: renaud at mancala.cbio.uct.ac.za (Renaud Gaujoux)
Date: Tue, 25 Jan 2011 13:01:38 +0200
Subject: [Rd] Missing argument vs. empty argument
In-Reply-To: <alpine.LFD.2.00.1101251039330.19721@toucan.stats.ox.ac.uk>
References: <4D3E9793.6040309@cbio.uct.ac.za>
	<alpine.LFD.2.00.1101251039330.19721@toucan.stats.ox.ac.uk>
Message-ID: <4D3EAD92.5020108@cbio.uct.ac.za>

My purpose is indeed to write a '[' method.
I will go for the `[.data.frame` solution then.
Thank you.


On 25/01/2011 12:53, Prof Brian Ripley wrote:
> On Tue, 25 Jan 2011, Renaud Gaujoux wrote:
>
>> Hi,
>>
>> is there an easy, robust, and/or recommended way to distinguish a 
>> missing argument from an empty argument as in:
>
> An empty argument is a missing argument when argument matching is 
> done, e.g.
>
>> foo <- function(i,j) match.call()
>> foo(i)
> foo(i = i)
>> foo(i,)
> foo(i = i)
>> foo(,j)
> foo(j = j)
>
> It is rather against the spirit of R to use the actual call rather 
> than the matched call.  Unless you are doing this to write a '[' 
> method I would suggest you find a different convention, e.g. 
> distinguish f(i) and f(i, NULL).  For the exception, look at 
> `[.data.frame`, which does use nargs().
>
> (NB: what I have said does not apply to primitives like '[' itself, 
> which do not do standard argument matching.)
>
>
>>
>> foo <- function(i, j){
>>    print(missing(j))
>>    print(nargs())
>> }
>>
>> foo(i)  # TRUE, 1
>> foo(i,) # TRUE, 2
>>
>> I know I can work around with nargs, the list of arguments and the 
>> names of the passed arguments, but I wish there is something already 
>> in place for this.
>> This is specially important for '['-like methods where x[i,] is not 
>> the same as x[i].
>> What I am looking for is a function that tells me if an argument has 
>> actually been passed empty:
>>
>> foo <- function(i, j, k){
>>    print( empty.arg(j) )
>>    print(nargs())
>> }
>>
>> would result in:
>>
>> foo(i) # FALSE, 1
>> foo(i, ) # TRUE, 2
>> foo(i, j) # FALSE, 2
>> foo(i, k=2) # FALSE, 2
>> foo(i, k=2, ) # TRUE, 3
>>
>> Thank you for any help or pointer.
>>
>> Bests,
>> Renaud
>>
>>
>>
>>
>> ###
>> UNIVERSITY OF CAPE TOWN This e-mail is subject to the UCT ICT 
>> policies and e-mai...{{dropped:5}}
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>

 

###
UNIVERSITY OF CAPE TOWN 

This e-mail is subject to the UCT ICT policies and e-mai...{{dropped:5}}


From tobias.verbeke at openanalytics.eu  Tue Jan 25 12:17:27 2011
From: tobias.verbeke at openanalytics.eu (Tobias Verbeke)
Date: Tue, 25 Jan 2011 12:17:27 +0100
Subject: [Rd] dendrogram plot does not draw long labels ?
In-Reply-To: <AANLkTikuvd7q4xbyzEdfp+G_k1CsEM_db7zxZXpiQcWg@mail.gmail.com>
References: <AANLkTikuvd7q4xbyzEdfp+G_k1CsEM_db7zxZXpiQcWg@mail.gmail.com>
Message-ID: <4D3EB147.8000906@openanalytics.eu>

Hi Karl,

On 01/25/2011 11:27 AM, Karl Forner wrote:

> It seems that the plot function for dendrograms does not draw labels when
> they are too long.
>
>> hc<- hclust(dist(USArrests), "ave")
>> dend1<- as.dendrogram(hc)
>> dend2<- cut(dend1, h=70)
>> dd<- dend2$lower[[1]]
>> plot(dd) # first label is drawn
>> attr(dd[[1]], "label")<- "aaaaaaaaaaaaaaaaaa"
>> plot(dd) # first label is NOT drawn
>
> Is this expected ?

Reading the code of stats:::plotNode, yes.

Clipping to the figure region is hard-coded.

You can see it is clipping to the figure region as follows:

hc <- hclust(dist(USArrests), "ave")
dend1 <- as.dendrogram(hc)
dend2 <- cut(dend1, h=70)
dd <- dend2$lower[[1]]
op <- par(oma = c(8,4,4,2)+0.1, xpd = NA)
plot(dd) # first label is drawn
attr(dd[[1]], "label") <- "abcdefghijklmnopqrstuvwxyz"
plot(dd) # first label is NOT drawn
box(which = "figure")
par(op)

> Is it possible to force the drawing ?

These are (from very quick reading -- not verified)
the culprit lines in plotNode, I think:

text(xBot, yBot + vln, nodeText, xpd = TRUE, # <- clipping hard-coded
                   cex = lab.cex, col = lab.col, font = lab.font)

Best,
Tobias


From karl at huftis.org  Tue Jan 25 11:49:11 2011
From: karl at huftis.org (Karl Ove Hufthammer)
Date: Tue, 25 Jan 2011 11:49:11 +0100
Subject: [Rd] match function causing bad performance when using
	tablefunction on factors with multibyte characters on Windows
References: <ihbko3$efs$1@dough.gmane.org> <ihkd01$bem$1@dough.gmane.org>
Message-ID: <ihm9qq$9ej$1@dough.gmane.org>

Matthew Dowle wrote:

> I'm not sure, but note the difference in locale between
> Linux (UTF-8) and Windows (non UTF-8). As far as I
> understand it R much prefers UTF-8, which Windows doesn't
> natively support. Otherwise you could just change your
> Windows locale to a UTF-8 locale to make R happier.
> 
[...]
> 
> If anybody knows a way to trick R on Linux into thinking it has
> an encoding similar to Windows then I may be able to take a
> look if I can reproduce the problem in Linux.

Changing the locale to an ISO 8859-1 locale, i.e.:

export LC_ALL="en_US.ISO-8859-1"
export LANG="en_US.ISO-8859-1"

I could *not* reproduce it; that is, ?table? is as fast on the non-ASCII 
factor as it is on the ASCII factor.

-- 
Karl Ove Hufthammer


From rksh1 at cam.ac.uk  Tue Jan 25 16:34:38 2011
From: rksh1 at cam.ac.uk (Robin Hankin)
Date: Tue, 25 Jan 2011 15:34:38 +0000
Subject: [Rd] NA printing
Message-ID: <4D3EED8E.7050400@cam.ac.uk>

Hi.

I'm writing a print method for an object that includes a numeric matrix
for which
the lower diagonal elements are not meaningful.  So I make the lower
diagonal of my matrix NA and print it.

But my co-author does not like NA there and wants a dash.

I have tried coercing the matrix to character, essentially by
M[is.na(M)] <- "-" but this interferes with the pleasing
column alignment for numerical matrices.

How do I make R print "-" instead of "NA"  for NA entries in a numeric
matrix, without altering the vertical alignment?  Is there such a command
as

options(NA_string = "-")

available?

best wishes

Robin Hankin


From karl.forner at gmail.com  Tue Jan 25 16:34:41 2011
From: karl.forner at gmail.com (Karl Forner)
Date: Tue, 25 Jan 2011 16:34:41 +0100
Subject: [Rd] dendrogram plot does not draw long labels ?
In-Reply-To: <4D3EB147.8000906@openanalytics.eu>
References: <AANLkTikuvd7q4xbyzEdfp+G_k1CsEM_db7zxZXpiQcWg@mail.gmail.com>
	<4D3EB147.8000906@openanalytics.eu>
Message-ID: <AANLkTi=3rXNF5RQRbcQwonUqA-0Q1XBT--p4hyfNQ9VZ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110125/58207327/attachment.pl>

From marc_schwartz at me.com  Tue Jan 25 17:08:45 2011
From: marc_schwartz at me.com (Marc Schwartz)
Date: Tue, 25 Jan 2011 10:08:45 -0600
Subject: [Rd] NA printing
In-Reply-To: <4D3EED8E.7050400@cam.ac.uk>
References: <4D3EED8E.7050400@cam.ac.uk>
Message-ID: <379224E8-43E1-4B2A-AD8A-EC255653982D@me.com>

On Jan 25, 2011, at 9:34 AM, Robin Hankin wrote:

> Hi.
> 
> I'm writing a print method for an object that includes a numeric matrix
> for which
> the lower diagonal elements are not meaningful.  So I make the lower
> diagonal of my matrix NA and print it.
> 
> But my co-author does not like NA there and wants a dash.
> 
> I have tried coercing the matrix to character, essentially by
> M[is.na(M)] <- "-" but this interferes with the pleasing
> column alignment for numerical matrices.
> 
> How do I make R print "-" instead of "NA"  for NA entries in a numeric
> matrix, without altering the vertical alignment?  Is there such a command
> as
> 
> options(NA_string = "-")
> 
> available?
> 
> best wishes
> 
> Robin Hankin


Robin,

How about this:

set.seed(1)

mat <- matrix(rnorm(16), 4, 4, )

> mat
           [,1]       [,2]       [,3]        [,4]
[1,] -0.6264538  0.3295078  0.5757814 -0.62124058
[2,]  0.1836433 -0.8204684 -0.3053884 -2.21469989
[3,] -0.8356286  0.4874291  1.5117812  1.12493092
[4,]  1.5952808  0.7383247  0.3898432 -0.04493361

mat[lower.tri(mat, diag = TRUE)] <- NA

> mat
     [,1]      [,2]       [,3]       [,4]
[1,]   NA 0.3295078  0.5757814 -0.6212406
[2,]   NA        NA -0.3053884 -2.2146999
[3,]   NA        NA         NA  1.1249309
[4,]   NA        NA         NA         NA

> print.table(mat, na.print = "-")
     [,1] [,2]       [,3]       [,4]      
[1,]    -  0.3295078  0.5757814 -0.6212406
[2,]    -          - -0.3053884 -2.2146999
[3,]    -          -          -  1.1249309
[4,]    -          -          -          -


See the 'na.print' argument in ?print.table

HTH,

Marc Schwartz


From mdowle at mdowle.plus.com  Tue Jan 25 18:31:03 2011
From: mdowle at mdowle.plus.com (Matthew Dowle)
Date: Tue, 25 Jan 2011 17:31:03 -0000
Subject: [Rd] match function causing bad performance when
	usingtablefunction on factors with multibyte characters on Windows
References: <ihbko3$efs$1@dough.gmane.org> <ihkd01$bem$1@dough.gmane.org>
	<ihm9qq$9ej$1@dough.gmane.org>
Message-ID: <ihn1cq$h2k$1@dough.gmane.org>


I don't know if that's enough to flip the UTF8 switches
internally in R. If it is enough, then this result may show
I'm barking up the wrong tree. Hopefully someone from
core is watching who knows. Is it feasible that you run
R using an alias, and for some reason the alias is not
picking up your shell variables. Best to rule that out now
by running sessionInfo() at the R prompt.

Otherwise do you know profiling tools sufficiently to trace the
problem at the C level as it runs on Windows?

Matthew

"Karl Ove Hufthammer" <karl at huftis.org> wrote in message 
news:ihm9qq$9ej$1 at dough.gmane.org...
> Matthew Dowle wrote:
>
>> I'm not sure, but note the difference in locale between
>> Linux (UTF-8) and Windows (non UTF-8). As far as I
>> understand it R much prefers UTF-8, which Windows doesn't
>> natively support. Otherwise you could just change your
>> Windows locale to a UTF-8 locale to make R happier.
>>
> [...]
>>
>> If anybody knows a way to trick R on Linux into thinking it has
>> an encoding similar to Windows then I may be able to take a
>> look if I can reproduce the problem in Linux.
>
> Changing the locale to an ISO 8859-1 locale, i.e.:
>
> export LC_ALL="en_US.ISO-8859-1"
> export LANG="en_US.ISO-8859-1"
>
> I could *not* reproduce it; that is, 'table' is as fast on the non-ASCII
> factor as it is on the ASCII factor.
>
> -- 
> Karl Ove Hufthammer
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From hpages at fhcrc.org  Tue Jan 25 19:13:11 2011
From: hpages at fhcrc.org (=?ISO-8859-1?Q?Herv=E9_Pag=E8s?=)
Date: Tue, 25 Jan 2011 10:13:11 -0800
Subject: [Rd] Regression in error handling with R >= 2.12
Message-ID: <4D3F12B7.9060809@fhcrc.org>

Hi list,

When nesting 2 function calls, if an exception occurs during the inner 
call, the error message will display properly:

   bar <- function() stop("bar() is broken")
   foo <- function(x) {x * (x - 2)}

   > foo(bar())
   Error in bar() : bar() is broken

However, starting with R 2.12, if foo() is a generic function, we only
get the following not-so-informative message:

   setMethod("foo", "numeric", function(x) {x * (x - 2)})

   > foo(bar())
   Error in foo(bar()) :
     error in evaluating the argument 'x' in selecting a method for 
function 'foo'

With versions prior to R 2.12, we were getting the full story:

   > foo(bar())
   Error in bar() : bar() is broken
   Error in foo(bar()) :
     error in evaluating the argument 'x' in selecting a method for 
function 'foo'

Could this behavior be restored?

Thanks,
H.

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M2-B876
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fhcrc.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From simon.urbanek at r-project.org  Tue Jan 25 20:14:56 2011
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Tue, 25 Jan 2011 14:14:56 -0500
Subject: [Rd] match function causing bad performance when using
	tablefunction on factors with multibyte characters on Windows
In-Reply-To: <ihm9qq$9ej$1@dough.gmane.org>
References: <ihbko3$efs$1@dough.gmane.org> <ihkd01$bem$1@dough.gmane.org>
	<ihm9qq$9ej$1@dough.gmane.org>
Message-ID: <96D7BCDC-2FCF-4FB6-BDE6-0A55DAB57DA5@r-project.org>


On Jan 25, 2011, at 5:49 AM, Karl Ove Hufthammer wrote:

> Matthew Dowle wrote:
> 
>> I'm not sure, but note the difference in locale between
>> Linux (UTF-8) and Windows (non UTF-8). As far as I
>> understand it R much prefers UTF-8, which Windows doesn't
>> natively support. Otherwise you could just change your
>> Windows locale to a UTF-8 locale to make R happier.
>> 
> [...]
>> 
>> If anybody knows a way to trick R on Linux into thinking it has
>> an encoding similar to Windows then I may be able to take a
>> look if I can reproduce the problem in Linux.
> 
> Changing the locale to an ISO 8859-1 locale, i.e.:
> 
> export LC_ALL="en_US.ISO-8859-1"
> export LANG="en_US.ISO-8859-1"
> 
> I could *not* reproduce it; that is, ?table? is as fast on the non-ASCII 
> factor as it is on the ASCII factor.
> 

Strange - are you sure you get the right locale names? Make sure it's listed in locale -a. The above works on my Mac but on my Linux system I have to use LANG=en_US.iso88591 and is *is* replicable albeit with a much smaller hit:

> benchmark( table(x.num), table(x.fac.ascii), table(x.fac.nascii), table(unclass(x.fac.nascii)), replications=20 )
                          test replications elapsed relative user.self sys.self user.child sys.child
4 table(unclass(x.fac.nascii))           20   1.028 2.269316     1.020    0.004          0         0
2           table(x.fac.ascii)           20   0.453 1.000000     0.452    0.004          0         0
3          table(x.fac.nascii)           20   2.683 5.922737     2.684    0.000          0         0
1                 table(x.num)           20   1.028 2.269316     1.020    0.008          0         0

The main reason is that table() calls factor() which does as.character() which means 10^5 character conversions - a bad idea in that case. Why the penalty is so much higher on Windows that I can't answer at the moment as I'm not on a machine with Windows VM.

FWIW if you care about speed you should use tabulate() instead - it's much faster and incurs no penalty:

>  benchmark( tabulate(x.num), tabulate(x.fac.ascii), tabulate(x.fac.nascii), tabulate(unclass(x.fac.nascii)), replications=20 )
                             test replications elapsed relative user.self sys.self user.child sys.child
4 tabulate(unclass(x.fac.nascii))           20   0.027 1.421053     0.024        0          0         0
2           tabulate(x.fac.ascii)           20   0.023 1.210526     0.024        0          0         0
3          tabulate(x.fac.nascii)           20   0.024 1.263158     0.020        0          0         0
1                 tabulate(x.num)           20   0.019 1.000000     0.020        0          0         0

Cheers,
Simon


From tobias.verbeke at openanalytics.eu  Tue Jan 25 21:27:41 2011
From: tobias.verbeke at openanalytics.eu (Tobias Verbeke)
Date: Tue, 25 Jan 2011 21:27:41 +0100
Subject: [Rd] patch dendrogram.R from stats [was: Re: dendrogram plot does
 not draw long labels ?]
In-Reply-To: <AANLkTi=3rXNF5RQRbcQwonUqA-0Q1XBT--p4hyfNQ9VZ@mail.gmail.com>
References: <AANLkTikuvd7q4xbyzEdfp+G_k1CsEM_db7zxZXpiQcWg@mail.gmail.com>	<4D3EB147.8000906@openanalytics.eu>
	<AANLkTi=3rXNF5RQRbcQwonUqA-0Q1XBT--p4hyfNQ9VZ@mail.gmail.com>
Message-ID: <4D3F323D.2090803@openanalytics.eu>

L.S.

Please find below a patch for dendrogram.R (stats package)
against revision r54107 which allows one to pass the xpd
parameter as a component of the nodePar list (to be
passed to plot.dendrogram).

I hope I did not overlook anything.

Best,
Tobias

378a379
 >     lab.xpd <- Xtract("xpd", nPar, default = c(TRUE, TRUE), i)
391c392
< 	    text(X, Y, nodeText, xpd = TRUE, srt = srt, adj = adj,
---
 > 	    text(X, Y, nodeText, xpd = lab.xpd, srt = srt, adj = adj,
436c437
< 		text(xBot, yBot + vln, nodeText, xpd = TRUE,
---
 > 		text(xBot, yBot + vln, nodeText, xpd = lab.xpd,



On 01/25/2011 04:34 PM, Karl Forner wrote:
> Hi Tobias and thank you for your reply,
>
> Using your insight I managed to work-around the issue (with some help)
> by increasing
> the "mai" option of par().
> For example a "mai" with first coordinate (bottom) set to 5 allows to
> display ~ 42 letters.
>
> We tried to change the xpd value in the text() call that you mentioned,
> but it did not seem to fix the problem.
>
> But I think this is very annoying: the dendrogram plot is meant to be
> the common unique plotting for all clustering stuff
> and suddenly if your labels are just too long, nothing get displayed,
> without even a warning.
> I suppose that the margins should be dynamically set based on the max
> label text drawn length...
>
> The hclust plot seemed to handle very nicely these long labels, but I
> need to display colored labels and the only way I found is to use the
> plot.dendrogram for this.
>
> Best,
>
> Karl
>
> On Tue, Jan 25, 2011 at 12:17 PM, Tobias Verbeke
> <tobias.verbeke at openanalytics.eu
> <mailto:tobias.verbeke at openanalytics.eu>> wrote:
>
>     Hi Karl,
>
>
>     On 01/25/2011 11:27 AM, Karl Forner wrote:
>
>         It seems that the plot function for dendrograms does not draw
>         labels when
>         they are too long.
>
>             hc<- hclust(dist(USArrests), "ave")
>             dend1<- as.dendrogram(hc)
>             dend2<- cut(dend1, h=70)
>             dd<- dend2$lower[[1]]
>             plot(dd) # first label is drawn
>             attr(dd[[1]], "label")<- "aaaaaaaaaaaaaaaaaa"
>             plot(dd) # first label is NOT drawn
>
>
>         Is this expected ?
>
>
>     Reading the code of stats:::plotNode, yes.
>
>     Clipping to the figure region is hard-coded.
>
>     You can see it is clipping to the figure region as follows:
>
>
>     hc <- hclust(dist(USArrests), "ave")
>     dend1 <- as.dendrogram(hc)
>     dend2 <- cut(dend1, h=70)
>     dd <- dend2$lower[[1]]
>     op <- par(oma = c(8,4,4,2)+0.1, xpd = NA)
>
>     plot(dd) # first label is drawn
>     attr(dd[[1]], "label") <- "abcdefghijklmnopqrstuvwxyz"
>
>     plot(dd) # first label is NOT drawn
>     box(which = "figure")
>     par(op)
>
>
>         Is it possible to force the drawing ?
>
>
>     These are (from very quick reading -- not verified)
>     the culprit lines in plotNode, I think:
>
>     text(xBot, yBot + vln, nodeText, xpd = TRUE, # <- clipping hard-coded
>                       cex = lab.cex, col = lab.col, font = lab.font)
>
>     Best,
>     Tobias
>
>


From mdowle at mdowle.plus.com  Wed Jan 26 00:30:07 2011
From: mdowle at mdowle.plus.com (Matthew Dowle)
Date: Tue, 25 Jan 2011 15:30:07 -0800 (PST)
Subject: [Rd] match function causing bad performance when using
 tablefunction on factors with multibyte characters on Windows
In-Reply-To: <96D7BCDC-2FCF-4FB6-BDE6-0A55DAB57DA5@r-project.org>
References: <ihbko3$efs$1@dough.gmane.org> <ihkd01$bem$1@dough.gmane.org>
	<ihm9qq$9ej$1@dough.gmane.org>
	<96D7BCDC-2FCF-4FB6-BDE6-0A55DAB57DA5@r-project.org>
Message-ID: <1295998207120-3237228.post@n4.nabble.com>


Thanks Simon!  I can reproduce this on Linux now, too.
locale -a didn't show en_US.iso88591 for me so I needed
'sudo locale-gen en_US' first.
Then running R with 
$ LANG="en_US.ISO-8859-1" R
is enough to reproduce the problem.

Karl - can you use tabulate instead as Simon suggests?

Matthew

-- 
View this message in context: http://r.789695.n4.nabble.com/match-function-causing-bad-performance-when-using-table-function-on-factors-with-multibyte-characters-tp3229526p3237228.html
Sent from the R devel mailing list archive at Nabble.com.


From karl at huftis.org  Wed Jan 26 09:31:43 2011
From: karl at huftis.org (Karl Ove Hufthammer)
Date: Wed, 26 Jan 2011 09:31:43 +0100
Subject: [Rd] match function causing bad performance when using
	tablefunction on factors with multibyte characters on Windows
References: <ihbko3$efs$1@dough.gmane.org> <ihkd01$bem$1@dough.gmane.org>
	<ihm9qq$9ej$1@dough.gmane.org>
	<96D7BCDC-2FCF-4FB6-BDE6-0A55DAB57DA5@r-project.org>
Message-ID: <ihom50$312$1@dough.gmane.org>

Simon Urbanek wrote:

>> I could *not* reproduce it; that is, ?table? is as fast on the non-ASCII
>> factor as it is on the ASCII factor.
> 
> Strange - are you sure you get the right locale names? Make sure it's
> listed in locale -a.

Yes, I managed to reproduce it now, using a locale listed in ?locale -a?.
There is a performance hit, though *much* smaller than on Windows.

> FWIW if you care about speed you should use tabulate() instead - it's much
> faster and incurs no penalty:

Yes, that the solution I ended up using:

res = tabulate(x, nbins=nlevels(x)) # nbins needed for levels that don?t occur
names(res) = levels(x)
res

(Though I?m not sure it?s *guaranteed* that factors are internally stored in a
way that make this works, i.e., as the numbers 1, 2, ... for level 1, 2 ...)

Anyway, do you think it?s worth trying to change the ?table? function the way I
outlined in my first post?? This should eliminate the performance hit on all
platforms. However, it will introduce a performance hit (CPU and memory use)
if the elements of ?exclude? make up a large part of the factor(s).

? http://permalink.gmane.org/gmane.comp.lang.r.devel/26576

-- 
Karl Ove Hufthammer


From karl at huftis.org  Wed Jan 26 14:37:08 2011
From: karl at huftis.org (Karl Ove Hufthammer)
Date: Wed, 26 Jan 2011 14:37:08 +0100
Subject: [Rd] match function causing bad performance when using
	tablefunction on factors with multibyte characters on Windows
References: <ihbko3$efs$1@dough.gmane.org> <ihkd01$bem$1@dough.gmane.org>
	<ihm9qq$9ej$1@dough.gmane.org>
	<96D7BCDC-2FCF-4FB6-BDE6-0A55DAB57DA5@r-project.org>
	<ihom50$312$1@dough.gmane.org>
Message-ID: <ihp81l$ucj$1@dough.gmane.org>

Karl Ove Hufthammer wrote:

> Anyway, do you think it?s worth trying to change the ?table? function the
> way I outlined in my first post?? This should eliminate the performance
> hit on all platforms.

Some additional notes: ?table? uses ?factor? directly, but also indirectly, 
in ?addNA?. The definition of ?addNA? ends with:

    if (!any(is.na(ll))) 
        ll <- c(ll, NA)
    factor(x, levels = ll, exclude = NULL)

Which is slow for non-ASCII levels. One *could* fix this by changing the 
last line to

  attr(x, "levels")=ll

But one soon ends up changing every function that uses ?factor? in this way, 
which seems like the wrong approach. The problems lies inside ?factor?,
and that?s where it should be fixed, if feasible.

BTW, the defintion of ?addNA? looks suboptimal in a different way. The last 
line is always executed, even if the factor *does* contain NA values (and of 
course NA levels). For this case, basically it?s doing nothing, just taking 
a very long time doing it (at least on Windows). Moving the last line inside 
the ?if? clause, and adding a ?else return(x)? would fix this (correct me if 
I?m wrong).

-- 
Karl Ove Hufthammer


From pdbailey at umd.edu  Wed Jan 26 20:04:14 2011
From: pdbailey at umd.edu (Paul Bailey)
Date: Wed, 26 Jan 2011 14:04:14 -0500
Subject: [Rd] aggregate(as.formula("some formula"), data,
	function) error when called from in a function
Message-ID: <99034C83-582C-481B-A91F-60004971AFFB@umd.edu>

I'm having a problem with aggregate.formula when I call it in a function and the function is converted from a string in the funtion

I think my problem may also only occur when the left hand side of the formula is cbind(...)

Here is example code that generates a dataset and then the error. 

The first function "agg2" fails

> agg2(FALSE)
do agg 2
Error in m[[2L]][[2L]] : object of type 'symbol' is not subsettable

but, if I run it have it return what it is going to pass to aggregate and pass it myself, it works. I can use this for a workaround (agg3) where one function does this itself.

I'm confused by the behavior. Is there some way to not have to use a separate function to make the call ?


======================
# start R code
# idea: in a function, count the number of instances
# of some factor (y) associated with another
# factor (x). aggregate.formula appears to be
# able to do this... but I have a problem if all of the following:
# (1) It is called in a function
# (2) the formula is created using as.formula(character)
# calling aggregate with the same formula (created with as.formula)
# outside the function works fine.
agg2 <- function(test=FALSE) {
  # create a factor y
  dat <- data.frame(y=sample(LETTERS[1:3],100,replace=TRUE))
  # create a factor x
  dat$x <- sample(letters[1:4],100,replace=TRUE)
  # make a column of 1s and zeros
  # 1 when that row has that level of y
  # 0 otherwise
  lvls <- levels(dat$y)
  dat$ya <- 1*(dat[,1] == lvls[1])
  dat$yb <- 1*(dat[,1] == lvls[2])
  dat$yc <- 1*(dat[,1] == lvls[3])
  # this works fine if you give the exact function
  agg1 <- aggregate(cbind(ya,yb,yc)~x,data=dat,sum)
  # and fine if you accept
  fo <- as.formula("cbind(ya,yb,yc)~x")
  if(test) {
  	return(list(fo=fo,data=dat))
  }
  cat("do agg 2\n")
  agg2 <- aggregate(fo,data=dat,sum)
  list(agg1,agg2)
}
agg2(FALSE)
ag <- agg2(TRUE)
ag$fo
aggregate(ag$fo,ag$data,sum)


agg3 <- function() {
  ag <- agg2(TRUE)
  ag$fo
  aggregate(ag$fo,ag$data,sum)
}
agg3()

# end R code
==============
Paul Bailey
University of Maryland

From ggrothendieck at gmail.com  Wed Jan 26 20:31:56 2011
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Wed, 26 Jan 2011 14:31:56 -0500
Subject: [Rd] aggregate(as.formula("some formula"), data,
 function) error when called from in a function
In-Reply-To: <99034C83-582C-481B-A91F-60004971AFFB@umd.edu>
References: <99034C83-582C-481B-A91F-60004971AFFB@umd.edu>
Message-ID: <AANLkTimysHdZQZiKeTPpCQFQ5Uxs_VOWsSLTjcANRADJ@mail.gmail.com>

On Wed, Jan 26, 2011 at 2:04 PM, Paul Bailey <pdbailey at umd.edu> wrote:
> I'm having a problem with aggregate.formula when I call it in a function and the function is converted from a string in the funtion
>
> I think my problem may also only occur when the left hand side of the formula is cbind(...)
>
> Here is example code that generates a dataset and then the error.
>
> The first function "agg2" fails
>
>> agg2(FALSE)
> do agg 2
> Error in m[[2L]][[2L]] : object of type 'symbol' is not subsettable
>
> but, if I run it have it return what it is going to pass to aggregate and pass it myself, it works. I can use this for a workaround (agg3) where one function does this itself.
>
> I'm confused by the behavior. Is there some way to not have to use a separate function to make the call ?
>
>
> ======================
> # start R code
> # idea: in a function, count the number of instances
> # of some factor (y) associated with another
> # factor (x). aggregate.formula appears to be
> # able to do this... but I have a problem if all of the following:
> # (1) It is called in a function
> # (2) the formula is created using as.formula(character)
> # calling aggregate with the same formula (created with as.formula)
> # outside the function works fine.
> agg2 <- function(test=FALSE) {
> ?# create a factor y
> ?dat <- data.frame(y=sample(LETTERS[1:3],100,replace=TRUE))
> ?# create a factor x
> ?dat$x <- sample(letters[1:4],100,replace=TRUE)
> ?# make a column of 1s and zeros
> ?# 1 when that row has that level of y
> ?# 0 otherwise
> ?lvls <- levels(dat$y)
> ?dat$ya <- 1*(dat[,1] == lvls[1])
> ?dat$yb <- 1*(dat[,1] == lvls[2])
> ?dat$yc <- 1*(dat[,1] == lvls[3])
> ?# this works fine if you give the exact function
> ?agg1 <- aggregate(cbind(ya,yb,yc)~x,data=dat,sum)
> ?# and fine if you accept
> ?fo <- as.formula("cbind(ya,yb,yc)~x")
> ?if(test) {
> ? ? ? ?return(list(fo=fo,data=dat))
> ?}
> ?cat("do agg 2\n")
> ?agg2 <- aggregate(fo,data=dat,sum)
> ?list(agg1,agg2)
> }
> agg2(FALSE)
> ag <- agg2(TRUE)
> ag$fo
> aggregate(ag$fo,ag$data,sum)
>
>
> agg3 <- function() {
> ?ag <- agg2(TRUE)
> ?ag$fo
> ?aggregate(ag$fo,ag$data,sum)
> }
> agg3()
>
> # end R code
> ==============
> Paul Bailey
> University of Maryland

The problem is that the aggregate statement:

agg2 <- aggregate(fo, data = dat, sum)

is using non-standard evaluation and is literally looking at fo rather
than fo's value.  This may be a bug in aggregate.formula but at any
rate you could try replacing that statement with the following to
force fo to be evaluated:

agg2 <- do.call(aggregate, list(fo, data = dat, FUN = sum))

-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From janko.thyson.rstuff at googlemail.com  Wed Jan 26 20:34:02 2011
From: janko.thyson.rstuff at googlemail.com (Janko Thyson)
Date: Wed, 26 Jan 2011 20:34:02 +0100
Subject: [Rd] Error handling with frozen RCurl function calls +
	Identification of frozen R processes
Message-ID: <4d407719.4310df0a.16d9.ffff875d@mx.google.com>

Dear list,

I'm tackling an empiric research problem that requires me to address a whole
bunch of conceptual and/or technical details at the same time which cuts
time short for all the nitty-gritty details of the "components" involved.
Having said this, I'm lacking the time at the moment to deeply dive into
parallel computing and HTTP requests via RCurl and I hope you can help me
out with one or two imminent issues of my crawler/scraper:

Once a day, I'm running 'RCurl::getURIAsynchronous(x=URL.frontier.sub,
multiHandle=my.multi.handle)' within an lapply()-construct in order to read
chunks of deterministically composed URLs from a host. There are courtesy
time delays implemented between the individual http requests (5 times the
time the last request from this host took) so that I'm not clogging the
host. I'm causing about 15 minutes of traffic per day. The problem is, that
'getURIAsynchronous()' simply freezes sometimes and I don't have a clue why
so. I also can't reproduce the error as it's totally erratic. 

I tried to put the function inside a try() or tryCatch() construct to no
avail. Also, I've experimented with a couple of timeout options of Curl, but
honestly didn't really understand all the implications. None worked so far.
It simply seems that upon an error 'getURIAsynchronous()' simply does not
give control back to the R process. Additionally, due to a lack of profound
knowledge in parallel computing, the program is scripted to run a bunch of R
processes independently. "Communication" between them takes place via
variables they read from and write to disc in order to have some sort of
"shared environment" (horrible, I know ;-)). 

So here are my specific questions:
1) Is it possible to catch connection or timeout errors in RCurl functions
that allow me to implement my customized error handling? If so, could you
guide me to some examples, please?
2) Can I somehow identify "frozen" Rterm or Rscript processes (e.g. via
using Sys.getpid()?) in order to shut them down and reinitialize them? 

You'll find my session info below.

Thanks for any hints or advice! 
Janko

> sessionInfo()
R version 2.12.1 (2010-12-16)
Platform: i386-pc-mingw32/i386 (32-bit)

locale:
[1] LC_COLLATE=German_Germany.1252  LC_CTYPE=German_Germany.1252   
[3] LC_MONETARY=German_Germany.1252 LC_NUMERIC=C                   
[5] LC_TIME=German_Germany.1252    

attached base packages:
[1] tcltk     tools     stats     graphics  grDevices utils     datasets 
[8] methods   base     

other attached packages:
 [1] RCurl_1.5-0.1    bitops_1.0-4.1   XML_3.2-0.2      RMySQL_0.7-5    
 [5] filehash_2.1-1   hash_2.0.1       timeDate_2130.91 RODBC_1.3-2     
 [9] MiscPsycho_1.6   statmod_1.4.8    debug_1.2.4      mvbutils_2.5.4  
[13] DBI_0.2-5        cwhmisc_2.1      lattice_0.19-13 

loaded via a namespace (and not attached):
[1] grid_2.12.1


From janko.thyson.rstuff at googlemail.com  Wed Jan 26 23:31:28 2011
From: janko.thyson.rstuff at googlemail.com (Janko Thyson)
Date: Wed, 26 Jan 2011 23:31:28 +0100
Subject: [Rd] Error handling with frozen RCurl function calls +
	Identification of frozen R processes
Message-ID: <4d40a0ae.c151df0a.3d63.ffff96a5@mx.google.com>

Dear list,

I'm tackling an empiric research problem that requires me to address a whole
bunch of conceptual and/or technical details at the same time which cuts
time short for all the nitty-gritty details of the "components" involved.
Having said this, I'm lacking the time at the moment to deeply dive into
parallel computing and HTTP requests via RCurl and I hope you can help me
out with one or two imminent issues of my crawler/scraper:

Once a day, I'm running 'RCurl::getURIAsynchronous(x=URL.frontier.sub,
multiHandle=my.multi.handle)' within an lapply()-construct in order to read
chunks of deterministically composed URLs from a host. There are courtesy
time delays implemented between the individual http requests (5 times the
time the last request from this host took) so that I'm not clogging the
host. I'm causing about 15 minutes of traffic per day. The problem is, that
'getURIAsynchronous()' simply freezes sometimes and I don't have a clue why
so. I also can't reproduce the error as it's totally erratic. 

I tried to put the function inside a try() or tryCatch() construct to no
avail. Also, I've experimented with a couple of timeout options of Curl, but
honestly didn't really understand all the implications. None worked so far.
It simply seems that upon an error 'getURIAsynchronous()' simply does not
give control back to the R process. Additionally, due to a lack of profound
knowledge in parallel computing, the program is scripted to run a bunch of R
processes independently. "Communication" between them takes place via
variables they read from and write to disc in order to have some sort of
"shared environment" (horrible, I know ;-)). 

So here are my specific questions:
1) Is it possible to catch connection or timeout errors in RCurl functions
that allow me to implement my customized error handling? If so, could you
guide me to some examples, please?
2) Can I somehow identify "frozen" Rterm or Rscript processes (e.g. via
using Sys.getpid()?) in order to shut them down and reinitialize them? 

You'll find my session info below.

Thanks for any hints or advice! 
Janko

> sessionInfo()
R version 2.12.1 (2010-12-16)
Platform: i386-pc-mingw32/i386 (32-bit)

locale:
[1] LC_COLLATE=German_Germany.1252  LC_CTYPE=German_Germany.1252   
[3] LC_MONETARY=German_Germany.1252 LC_NUMERIC=C                   
[5] LC_TIME=German_Germany.1252    

attached base packages:
[1] tcltk     tools     stats     graphics  grDevices utils     datasets 
[8] methods   base     

other attached packages:
 [1] RCurl_1.5-0.1    bitops_1.0-4.1   XML_3.2-0.2      RMySQL_0.7-5    
 [5] filehash_2.1-1   hash_2.0.1       timeDate_2130.91 RODBC_1.3-2     
 [9] MiscPsycho_1.6   statmod_1.4.8    debug_1.2.4      mvbutils_2.5.4  
[13] DBI_0.2-5        cwhmisc_2.1      lattice_0.19-13 

loaded via a namespace (and not attached):
[1] grid_2.12.1


From Wayne.Zhang at barclayscapital.com  Wed Jan 26 23:56:32 2011
From: Wayne.Zhang at barclayscapital.com (Wayne.Zhang at barclayscapital.com)
Date: Wed, 26 Jan 2011 17:56:32 -0500
Subject: [Rd] Dealing with R list objects in C/C++
Message-ID: <A02FE3A5690A624994A6A0BC0DEEA920072898926A@NYKPCMMGMB05.INTRANET.BARCAPINT.COM>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110126/0b11da81/attachment.pl>

From edd at debian.org  Thu Jan 27 03:07:01 2011
From: edd at debian.org (Dirk Eddelbuettel)
Date: Wed, 26 Jan 2011 20:07:01 -0600
Subject: [Rd] Dealing with R list objects in C/C++
In-Reply-To: <A02FE3A5690A624994A6A0BC0DEEA920072898926A@NYKPCMMGMB05.INTRANET.BARCAPINT.COM>
References: <A02FE3A5690A624994A6A0BC0DEEA920072898926A@NYKPCMMGMB05.INTRANET.BARCAPINT.COM>
Message-ID: <19776.54085.632636.289766@max.nulle.part>


Hi Wayne,

On 26 January 2011 at 17:56, Wayne.Zhang at barclayscapital.com wrote:
| Hi,
| 
| I'd like to construct an R list object in C++, fill it with relevant data, and pass it to an R function which will return a different list object back.  I have browsed through all the R manuals, and examples under tests/Embedding, but can't figure out the correct way.  Below is my code snippet:
| 
|     #include <Rinternals.h>
| // Rf_initEmbeddedR and other setups already performed
| 
|     SEXP arg, ret;
| 
|     // this actually creates a pairlist.  I can't find any API that creates a list
| PROTECT(arg = allocList(3));
| 
| // I want the first element to be type integer, second double, and third a vector.
|     INTEGER(arg)[0]  = 1;            // <- runtime exception: "INTEGER() can only be applied to a 'integer', not a 'pairlist'
|     REAL(arg)[1] = 2.5;               // control never reached here
| 
|     VECTOR_PTR(arg)[2] = allocVector(REALSXP, 4);
|     REAL(VECTOR_PTR(arg)[2])[0] = 10.0;
|     REAL(VECTOR_PTR(arg)[2])[1] = 11.0;
|     REAL(VECTOR_PTR(arg)[2])[2] = 12.0;
|     REAL(VECTOR_PTR(arg)[2])[3] = 13.0;
| 
|     PROTECT(call = lang2(install(entryPoint.c_str()), arg));
| 
| ret = R_tryEval(call, R_GlobalEnv, &errorOccurred);
| 
| 
| I'll be grateful if you can point me to any online docs/samples.

This is a non-trivial problem when the use the C API provided by R. It is all
documented, but you need to study the 'Writing R Extensions' in some detail,
as well as maybe 'R Programming' by Gentleman and/or 'Software for Data
Analysis' by Chambers.

But there is another API you can use. It is provided by RInside (to embed R
inside C++) which uses Rcpp (for R and C++ integration).  Install those two
packages from CRAN, and then drop the few lines below as a file, say,
wayne.cpp in the examples/standard/ directory of RInside. Saying 'make wayne'
will build an executable, using proper flags and linker options, and you can
run that:

edd at max:~/svn/rinside/pkg/inst/examples/standard$ make wayne
g++ -I/usr/share/R/include -I/usr/local/lib/R/site-library/Rcpp/include -I"/usr/local/lib/R/site-library/RInside/include" -O3 -pipe -g -Wall    wayne.cpp  -L/usr/lib64/R/lib -lR  -lblas -llapack -L/usr/local/lib/R/site-library/Rcpp/lib -lRcpp -Wl,-rpath,/usr/local/lib/R/site-library/Rcpp/lib -L/usr/local/lib/R/site-library/RInside/lib -lRInside -Wl,-rpath,/usr/local/lib/R/site-library/RInside/lib -o wayne
edd at max:~/svn/rinside/pkg/inst/examples/standard$ ./wayne 
Showing list content:
L[0] 1
L[1] 2.5
L[2][0] 10
L[2][1] 11
Showing list content:
L[0] 42
L[1] 42
L[2][0] 10
L[2][1] 42
edd at max:~/svn/rinside/pkg/inst/examples/standard$ 

The code a list as you spec'ed with int, double and vector. The list is shown
on stdout, then passed to R, transformed by R and shown again at the C++ level.

Questions on RInside and Rcpp are welcome on the rcpp-devel list.

Hope this helps,  Dirk

-----------------------------------------------------------------------------
#include <RInside.h>                    // for the embedded R via RInside

void show(const Rcpp::List & L) {
    // this function is cumbersome as we haven't defined << operators
    std::cout << "Showing list content:\n";
    std::cout << "L[0] " << Rcpp::as<int>(L[0]) << std::endl;
    std::cout << "L[1] " << Rcpp::as<double>(L[1]) << std::endl;
    Rcpp::IntegerVector v = Rcpp::as<Rcpp::IntegerVector>(L[2]);
    std::cout << "L[2][0] " << v[0] << std::endl;
    std::cout << "L[2][1] " << v[1] << std::endl;
}

int main(int argc, char *argv[]) {

    // create an embedded R instance
    RInside R(argc, argv);               

    Rcpp::List mylist(3);
    mylist[0] = 1;
    mylist[1] = 2.5;
    Rcpp::IntegerVector v(2); v[0] = 10; v[1] = 11; // with C++0x we could assign directly
    mylist[2] = v;
    show(mylist);

    R["myRlist"] = mylist;
    std::string r_code = "myRlist[[1]] = 42; myRlist[[2]] = 42.0; myRlist[[3]][2] = 42; myRlist";
    
    Rcpp::List reslist = R.parseEval(r_code);
    show(reslist);

    exit(0);
}
-----------------------------------------------------------------------------


-- 
Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com


From mtmorgan at fhcrc.org  Thu Jan 27 04:03:38 2011
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Wed, 26 Jan 2011 19:03:38 -0800
Subject: [Rd] Dealing with R list objects in C/C++
In-Reply-To: <A02FE3A5690A624994A6A0BC0DEEA920072898926A@NYKPCMMGMB05.INTRANET.BARCAPINT.COM>
References: <A02FE3A5690A624994A6A0BC0DEEA920072898926A@NYKPCMMGMB05.INTRANET.BARCAPINT.COM>
Message-ID: <4D40E08A.6070100@fhcrc.org>

On 01/26/2011 02:56 PM, Wayne.Zhang at barclayscapital.com wrote:
> Hi,
> 
> I'd like to construct an R list object in C++, fill it with relevant data, and pass it to an R function which will return a different list object back.  I have browsed through all the R manuals, and examples under tests/Embedding, but can't figure out the correct way.  Below is my code snippet:
> 
>     #include <Rinternals.h>
> // Rf_initEmbeddedR and other setups already performed
> 
>     SEXP arg, ret;
> 
>     // this actually creates a pairlist.  I can't find any API that creates a list
> PROTECT(arg = allocList(3));

Allocate a list of length 3 via SEXPTYPE VECSXP

      PROTECT(arg = allocVector(VECSXP, 3));

> 
> // I want the first element to be type integer, second double, and third a vector.
>     INTEGER(arg)[0]  = 1;            // <- runtime exception: "INTEGER() can only be applied to a 'integer', not a 'pairlist'

set the first element of the list to an integer vector of length 1, and
assign a value

      SET_VECTOR_ELT(arg, 0, allocVector(INTSXP, 1));
      INTEGER(VECTOR_ELT(arg, 0))[0] = 1

or more succinctly

      SET_VECTOR_ELT(arg, 0, ScalarInteger(1));

>     REAL(arg)[1] = 2.5;               // control never reached here

and the second element

      SET_VECTOR_ELT(arg, 1, ScalarReal(2.5));

>     VECTOR_PTR(arg)[2] = allocVector(REALSXP, 4);

and for the third allocate a REALSXP and then fill

      SET_VECTOR_ELT(arg, 2, allocVector(REALSXP, 4));

next lines should be ok as REAL(VECTOR_ELT(arg, 2))[0] = 10.0; or with
less typing as

      double *x = REAL(VECTOR_ETL(arg, 2));
      x[0] = 10.0; x[1] = 11.0; x[2] = 12.0; x[3] = 13.0;

>     REAL(VECTOR_PTR(arg)[2])[0] = 10.0;
>     REAL(VECTOR_PTR(arg)[2])[1] = 11.0;
>     REAL(VECTOR_PTR(arg)[2])[2] = 12.0;
>     REAL(VECTOR_PTR(arg)[2])[3] = 13.0;
> 
>     PROTECT(call = lang2(install(entryPoint.c_str()), arg));

not sure where entryPoint.c_str() is coming from, but

     PROTECT(call = lang2(install("fun"), arg));

with some debate about whether install("fun") should be PROTECT'ed.

> 
> ret = R_tryEval(call, R_GlobalEnv, &errorOccurred);

likely PROTECT(ret = ...) while checking errorOccurred, etc.

Hope that helps,

Martin

> 
> 
> I'll be grateful if you can point me to any online docs/samples.
> 
> Thanks in advance,
> Wayne
> 
> _______________________________________________
> 
> 
i!
>  ce at 1 Churchill Place, London, E14 5HP.  This email may relate to or be sent from other members of the Barclays Group.
> _______________________________________________
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
Computational Biology
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N. PO Box 19024 Seattle, WA 98109

Location: M1-B861
Telephone: 206 667-2793


From gavin.simpson at ucl.ac.uk  Thu Jan 27 15:47:34 2011
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Thu, 27 Jan 2011 14:47:34 +0000
Subject: [Rd] Minor typo in influence.measures.Rd ?
Message-ID: <1296139654.9389.76.camel@prometheus.geog.ucl.ac.uk>

Dear list,

There is, I believe, a minor typo in the example section of
influence.measures.Rd. In the final example the word `does` appears
where I suspect `dose` is required:

I couldn't remember exactly what format patches should be in, so here is
one as diff would produce:

Index: devel/src/library/stats/man/influence.measures.Rd
===================================================================
198c198
< yi <- c(0,2,14,19,30) # number of mice responding to does xi
---
> yi <- c(0,2,14,19,30) # number of mice responding to dose xi

#######
and this version is provided by svn diff:

Index: devel/src/library/stats/man/influence.measures.Rd
===================================================================
--- devel/src/library/stats/man/influence.measures.Rd	(revision 54122)
+++ devel/src/library/stats/man/influence.measures.Rd	(working copy)
@@ -195,7 +195,7 @@
 
 ## Irwin's data [Williams 1987]
 xi <- 1:5
-yi <- c(0,2,14,19,30) # number of mice responding to does xi
+yi <- c(0,2,14,19,30) # number of mice responding to dose xi
 mi <- rep(40, 5)      # number of mice exposed
 summary(lmI <- glm(cbind(yi, mi -yi) ~ xi, family = binomial))
 signif(cooks.distance(lmI), 3)# ~= Ci in Table 3, p.184

#######
Both are against the R svn trunk, r54122, and are attached, but may not
make it through the mailing list filters.

All the best,

Gavin
-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
 Dr. Gavin Simpson             [t] +44 (0)20 7679 0522
 ECRC, UCL Geography,          [f] +44 (0)20 7679 0565
 Pearson Building,             [e] gavin.simpsonATNOSPAMucl.ac.uk
 Gower Street, London          [w] http://www.ucl.ac.uk/~ucfagls/
 UK. WC1E 6BT.                 [w] http://www.freshwaters.org.uk
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
-------------- next part --------------
A non-text attachment was scrubbed...
Name: influence.measures.Rd.diff-patched
Type: text/x-patch
Size: 263 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110127/cb594ac5/attachment.bin>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: influence.measures.Rd.patched
Type: text/x-patch
Size: 624 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110127/cb594ac5/attachment-0001.bin>

From cbeleites at units.it  Thu Jan 27 15:48:01 2011
From: cbeleites at units.it (Claudia Beleites)
Date: Thu, 27 Jan 2011 15:48:01 +0100
Subject: [Rd] Google Summer of Code 2011
Message-ID: <4D4185A1.2070203@units.it>

Dear all,

I just saw that Google Summer of Code 2011 is announced:
http://www.google-melange.com/

Claudia

-- 
Claudia Beleites
Dipartimento dei Materiali e delle Risorse Naturali
Universit? degli Studi di Trieste
Via Alfonso Valerio 6/a
I-34127 Trieste

phone: +39 0 40 5 58-37 68
email: cbeleites at units.it


From ripley at stats.ox.ac.uk  Thu Jan 27 19:09:12 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 27 Jan 2011 18:09:12 +0000 (GMT)
Subject: [Rd] Minor typo in influence.measures.Rd ?
In-Reply-To: <1296139654.9389.76.camel@prometheus.geog.ucl.ac.uk>
References: <1296139654.9389.76.camel@prometheus.geog.ucl.ac.uk>
Message-ID: <alpine.LFD.2.02.1101271805560.25557@gannet.stats.ox.ac.uk>

The preferred form is a diff -u as a text attachment.  svn diff is 
basically diff -u, but has the advantage of telling us exactly what 
version was diff-ed against.

But for something as simple as this, inline is fine, thanks.

[The main reason for wanting an attachment is that once lines get 
wrapped or tabs expanded, the noise can far exceed the signal.]

On Thu, 27 Jan 2011, Gavin Simpson wrote:

> Dear list,
>
> There is, I believe, a minor typo in the example section of
> influence.measures.Rd. In the final example the word `does` appears
> where I suspect `dose` is required:
>
> I couldn't remember exactly what format patches should be in, so here is
> one as diff would produce:
>
> Index: devel/src/library/stats/man/influence.measures.Rd
> ===================================================================
> 198c198
> < yi <- c(0,2,14,19,30) # number of mice responding to does xi
> ---
>> yi <- c(0,2,14,19,30) # number of mice responding to dose xi
>
> #######
> and this version is provided by svn diff:
>
> Index: devel/src/library/stats/man/influence.measures.Rd
> ===================================================================
> --- devel/src/library/stats/man/influence.measures.Rd	(revision 54122)
> +++ devel/src/library/stats/man/influence.measures.Rd	(working copy)
> @@ -195,7 +195,7 @@
>
> ## Irwin's data [Williams 1987]
> xi <- 1:5
> -yi <- c(0,2,14,19,30) # number of mice responding to does xi
> +yi <- c(0,2,14,19,30) # number of mice responding to dose xi
> mi <- rep(40, 5)      # number of mice exposed
> summary(lmI <- glm(cbind(yi, mi -yi) ~ xi, family = binomial))
> signif(cooks.distance(lmI), 3)# ~= Ci in Table 3, p.184
>
> #######
> Both are against the R svn trunk, r54122, and are attached, but may not
> make it through the mailing list filters.
>
> All the best,
>
> Gavin
> -- 
> %~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
> Dr. Gavin Simpson             [t] +44 (0)20 7679 0522
> ECRC, UCL Geography,          [f] +44 (0)20 7679 0565
> Pearson Building,             [e] gavin.simpsonATNOSPAMucl.ac.uk
> Gower Street, London          [w] http://www.ucl.ac.uk/~ucfagls/
> UK. WC1E 6BT.                 [w] http://www.freshwaters.org.uk
> %~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From kevin.r.coombes at gmail.com  Thu Jan 27 21:22:40 2011
From: kevin.r.coombes at gmail.com (Kevin R. Coombes)
Date: Thu, 27 Jan 2011 14:22:40 -0600
Subject: [Rd] use of depends, suggests, etc
Message-ID: <4D41D410.9040106@gmail.com>

Hi,

I'm putting together an R package.  In explaining how it works (in the 
Rd files), I want to refer to another package.  The other package is not 
used anywhere in the actual code nor in the examples. So, there is no 
reason to include the other package in the Depends, Suggests, or Imports 
lines of the DESCRIPTION file.  People will be able to use my package 
without actually installing the other package.

However, "R CMD check" warns about "Missing link(s)" when it is checking 
the cross references in the Rd files.

What is the preferred way to make this warning go away?

Thanks in advance,
     Kevin


From Wayne.Zhang at barclayscapital.com  Thu Jan 27 22:03:11 2011
From: Wayne.Zhang at barclayscapital.com (Wayne.Zhang at barclayscapital.com)
Date: Thu, 27 Jan 2011 16:03:11 -0500
Subject: [Rd] Dealing with R list objects in C/C++
In-Reply-To: <4D40E08A.6070100@fhcrc.org>
References: <A02FE3A5690A624994A6A0BC0DEEA920072898926A@NYKPCMMGMB05.INTRANET.BARCAPINT.COM>
	<4D40E08A.6070100@fhcrc.org>
Message-ID: <A02FE3A5690A624994A6A0BC0DEEA9200728989271@NYKPCMMGMB05.INTRANET.BARCAPINT.COM>

Many thanks for the quick reply Martin, your code works as expected.  Next I'd like to retrieve heterogeneous data from an SEXP object (let's just pretend it's the same type as the one what I'm constructing).  I'm sure the relevant APIs are defined in Rinternals.h, do we have API documentations for this header file somewhere?  

@Dirk: thanks for your help too.  I'm doing something very simple at the moment, so I prefer not to bring in Rinside/Rcpp if possible.

Thanks again,
Wayne 


-----Original Message-----
From: Martin Morgan [mailto:mtmorgan at fhcrc.org] 
Sent: Wednesday, January 26, 2011 10:04 PM
To: Zhang, Wayne: IT (NYK)
Cc: r-devel at r-project.org
Subject: Re: [Rd] Dealing with R list objects in C/C++

On 01/26/2011 02:56 PM, Wayne.Zhang at barclayscapital.com wrote:
> Hi,
> 
> I'd like to construct an R list object in C++, fill it with relevant data, and pass it to an R function which will return a different list object back.  I have browsed through all the R manuals, and examples under tests/Embedding, but can't figure out the correct way.  Below is my code snippet:
> 
>     #include <Rinternals.h>
> // Rf_initEmbeddedR and other setups already performed
> 
>     SEXP arg, ret;
> 
>     // this actually creates a pairlist.  I can't find any API that creates a list
> PROTECT(arg = allocList(3));

Allocate a list of length 3 via SEXPTYPE VECSXP

      PROTECT(arg = allocVector(VECSXP, 3));

> 
> // I want the first element to be type integer, second double, and third a vector.
>     INTEGER(arg)[0]  = 1;            // <- runtime exception: "INTEGER() can only be applied to a 'integer', not a 'pairlist'

set the first element of the list to an integer vector of length 1, and
assign a value

      SET_VECTOR_ELT(arg, 0, allocVector(INTSXP, 1));
      INTEGER(VECTOR_ELT(arg, 0))[0] = 1

or more succinctly

      SET_VECTOR_ELT(arg, 0, ScalarInteger(1));

>     REAL(arg)[1] = 2.5;               // control never reached here

and the second element

      SET_VECTOR_ELT(arg, 1, ScalarReal(2.5));

>     VECTOR_PTR(arg)[2] = allocVector(REALSXP, 4);

and for the third allocate a REALSXP and then fill

      SET_VECTOR_ELT(arg, 2, allocVector(REALSXP, 4));

next lines should be ok as REAL(VECTOR_ELT(arg, 2))[0] = 10.0; or with
less typing as

      double *x = REAL(VECTOR_ETL(arg, 2));
      x[0] = 10.0; x[1] = 11.0; x[2] = 12.0; x[3] = 13.0;

>     REAL(VECTOR_PTR(arg)[2])[0] = 10.0;
>     REAL(VECTOR_PTR(arg)[2])[1] = 11.0;
>     REAL(VECTOR_PTR(arg)[2])[2] = 12.0;
>     REAL(VECTOR_PTR(arg)[2])[3] = 13.0;
> 
>     PROTECT(call = lang2(install(entryPoint.c_str()), arg));

not sure where entryPoint.c_str() is coming from, but

     PROTECT(call = lang2(install("fun"), arg));

with some debate about whether install("fun") should be PROTECT'ed.

> 
> ret = R_tryEval(call, R_GlobalEnv, &errorOccurred);

likely PROTECT(ret = ...) while checking errorOccurred, etc.

Hope that helps,

Martin

> 
> 
> I'll be grateful if you can point me to any online docs/samples.
> 
> Thanks in advance,
> Wayne
> 
> _______________________________________________
> 
> This e-mail may contain information that is confidential, privileged or otherwise protected from disclosure. If you are not an intended recipient of this e-mail, do not duplicate or redistribute it by any means. Please delete it and any attachments and notify the sender that you have received it in error. Unless specifically indicated, this e-mail is not an offer to buy or sell or a solicitation to buy or sell any securities, investment products or other financial product or service, an official confirmation of any transaction, or an official statement of Barclays. Any views or opinions presented are solely those of the author and do not necessarily represent those of Barclays. This e-mail is subject to terms available at the following link: www.barcap.com/emaildisclaimer. By messaging with Barclays you consent to the foregoing.  Barclays Capital is the investment banking division of Barclays Bank PLC, a company registered in England (number 1026167) with its registered off
i!
>  ce at 1 Churchill Place, London, E14 5HP.  This email may relate to or be sent from other members of the Barclays Group.
> _______________________________________________
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
Computational Biology
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N. PO Box 19024 Seattle, WA 98109

Location: M1-B861
Telephone: 206 667-2793


From mtmorgan at fhcrc.org  Thu Jan 27 22:16:51 2011
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Thu, 27 Jan 2011 13:16:51 -0800
Subject: [Rd] Dealing with R list objects in C/C++
In-Reply-To: <A02FE3A5690A624994A6A0BC0DEEA9200728989271@NYKPCMMGMB05.INTRANET.BARCAPINT.COM>
References: <A02FE3A5690A624994A6A0BC0DEEA920072898926A@NYKPCMMGMB05.INTRANET.BARCAPINT.COM>
	<4D40E08A.6070100@fhcrc.org>
	<A02FE3A5690A624994A6A0BC0DEEA9200728989271@NYKPCMMGMB05.INTRANET.BARCAPINT.COM>
Message-ID: <4D41E0C3.5070902@fhcrc.org>

On 1/27/2011 1:03 PM, Wayne.Zhang at barclayscapital.com wrote:
> Many thanks for the quick reply Martin, your code works as expected.  Next I'd like to retrieve heterogeneous data from an SEXP object (let's just pretend it's the same type as the one what I'm constructing).  I'm sure the relevant APIs are defined in Rinternals.h, do we have API documentations for this header file somewhere?
Hi Wayne -- Your best bet might be sections 5 and 6 of

     RShowDoc("R-exts")

or the books Dirk mentioned; see also Rdefines.h. Martin
> @Dirk: thanks for your help too.  I'm doing something very simple at the moment, so I prefer not to bring in Rinside/Rcpp if possible.
>
> Thanks again,
> Wayne
>
>
> -----Original Message-----
> From: Martin Morgan [mailto:mtmorgan at fhcrc.org]
> Sent: Wednesday, January 26, 2011 10:04 PM
> To: Zhang, Wayne: IT (NYK)
> Cc: r-devel at r-project.org
> Subject: Re: [Rd] Dealing with R list objects in C/C++
>
> On 01/26/2011 02:56 PM, Wayne.Zhang at barclayscapital.com wrote:
>> Hi,
>>
>> I'd like to construct an R list object in C++, fill it with relevant data, and pass it to an R function which will return a different list object back.  I have browsed through all the R manuals, and examples under tests/Embedding, but can't figure out the correct way.  Below is my code snippet:
>>
>>      #include<Rinternals.h>
>> // Rf_initEmbeddedR and other setups already performed
>>
>>      SEXP arg, ret;
>>
>>      // this actually creates a pairlist.  I can't find any API that creates a list
>> PROTECT(arg = allocList(3));
> Allocate a list of length 3 via SEXPTYPE VECSXP
>
>        PROTECT(arg = allocVector(VECSXP, 3));
>
>> // I want the first element to be type integer, second double, and third a vector.
>>      INTEGER(arg)[0]  = 1;            //<- runtime exception: "INTEGER() can only be applied to a 'integer', not a 'pairlist'
> set the first element of the list to an integer vector of length 1, and
> assign a value
>
>        SET_VECTOR_ELT(arg, 0, allocVector(INTSXP, 1));
>        INTEGER(VECTOR_ELT(arg, 0))[0] = 1
>
> or more succinctly
>
>        SET_VECTOR_ELT(arg, 0, ScalarInteger(1));
>
>>      REAL(arg)[1] = 2.5;               // control never reached here
> and the second element
>
>        SET_VECTOR_ELT(arg, 1, ScalarReal(2.5));
>
>>      VECTOR_PTR(arg)[2] = allocVector(REALSXP, 4);
> and for the third allocate a REALSXP and then fill
>
>        SET_VECTOR_ELT(arg, 2, allocVector(REALSXP, 4));
>
> next lines should be ok as REAL(VECTOR_ELT(arg, 2))[0] = 10.0; or with
> less typing as
>
>        double *x = REAL(VECTOR_ETL(arg, 2));
>        x[0] = 10.0; x[1] = 11.0; x[2] = 12.0; x[3] = 13.0;
>
>>      REAL(VECTOR_PTR(arg)[2])[0] = 10.0;
>>      REAL(VECTOR_PTR(arg)[2])[1] = 11.0;
>>      REAL(VECTOR_PTR(arg)[2])[2] = 12.0;
>>      REAL(VECTOR_PTR(arg)[2])[3] = 13.0;
>>
>>      PROTECT(call = lang2(install(entryPoint.c_str()), arg));
> not sure where entryPoint.c_str() is coming from, but
>
>       PROTECT(call = lang2(install("fun"), arg));
>
> with some debate about whether install("fun") should be PROTECT'ed.
>
>> ret = R_tryEval(call, R_GlobalEnv,&errorOccurred);
> likely PROTECT(ret = ...) while checking errorOccurred, etc.
>
> Hope that helps,
>
> Martin
>
>>
>> I'll be grateful if you can point me to any online docs/samples.
>>
>> Thanks in advance,
>> Wayne
>>
>> _______________________________________________
>>
>> This e-mail may contain information that is confidential, privileged or otherwise protected from disclosure. If you are not an intended recipient of this e-mail, do not duplicate or redistribute it by any means. Please delete it and any attachments and notify the sender that you have received it in error. Unless specifically indicated, this e-mail is not an offer to buy or sell or a solicitation to buy or sell any securities, investment products or other financial product or service, an official confirmation of any transaction, or an official statement of Barclays. Any views or opinions presented are solely those of the author and do not necessarily represent those of Barclays. This e-mail is subject to terms available at the following link: www.barcap.com/emaildisclaimer. By messaging with Barclays you consent to the foregoing.  Barclays Capital is the investment banking division of Barclays Bank PLC, a company registered in England (number 1026167) with its registered off
> i!
>>   ce at 1 Churchill Place, London, E14 5HP.  This email may relate to or be sent from other members of the Barclays Group.
>> _______________________________________________
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>


-- 
Dr. Martin Morgan, PhD
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N.
PO Box 19024 Seattle, WA 98109


From ripley at stats.ox.ac.uk  Thu Jan 27 23:12:08 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 27 Jan 2011 22:12:08 +0000 (GMT)
Subject: [Rd] use of depends, suggests, etc
In-Reply-To: <4D41D410.9040106@gmail.com>
References: <4D41D410.9040106@gmail.com>
Message-ID: <alpine.LFD.2.02.1101272203470.3466@gannet.stats.ox.ac.uk>

On Thu, 27 Jan 2011, Kevin R. Coombes wrote:

> Hi,
>
> I'm putting together an R package.  In explaining how it works (in the Rd 
> files), I want to refer to another package.  The other package is not used 
> anywhere in the actual code nor in the examples. So, there is no reason to 
> include the other package in the Depends, Suggests, or Imports lines of the 
> DESCRIPTION file.  People will be able to use my package without actually 
> installing the other package.
>
> However, "R CMD check" warns about "Missing link(s)" when it is checking the 
> cross references in the Rd files.
>
> What is the preferred way to make this warning go away?

Follow the 'Writing R Extensions' manual.  There is a 3-item bullet 
point in ?1.1.1 following

     'The general rules are'

and your claims contradict the third point.

>
> Thanks in advance,
>    Kevin
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From Ken.Williams at thomsonreuters.com  Thu Jan 27 23:31:32 2011
From: Ken.Williams at thomsonreuters.com (Ken.Williams at thomsonreuters.com)
Date: Thu, 27 Jan 2011 16:31:32 -0600
Subject: [Rd] use of depends, suggests, etc
In-Reply-To: <alpine.LFD.2.02.1101272203470.3466@gannet.stats.ox.ac.uk>
Message-ID: <C9674B00.201BA%ken.williams@thomsonreuters.com>

But suppose I want to write something like: "this package is 10 million
times better than my other package [Foo] because that one will eat your
children" - or "in contrast to the package [Bar], this package is for
continuous data, while that one is for discrete data, so they don't
interoperate".

It wouldn't make sense to Depend or Suggest or Import the [Foo] or [Bar]
package, but if I didn't, the doc-building process will (apparently - I
haven't tried it myself) warn about the link being broken.

I can think of several different ways to address this if there isn't an
existing way (e.g. create a generic SeeAlso dependency field; use a
different syntax for citing packages that aren't dependencies of one sort
or another, etc.), but obviously they'd need the blessing of the people
maintaining the tools & specs.

--
Ken Williams
Senior Research Scientist
Thomson Reuters
Phone: 651-848-7712
ken.williams at thomsonreuters.com
http://labs.thomsonreuters.com





On 1/27/11 4:12 PM, "Prof Brian Ripley" <ripley at stats.ox.ac.uk> wrote:

>On Thu, 27 Jan 2011, Kevin R. Coombes wrote:
>
>> Hi,
>>
>> I'm putting together an R package.  In explaining how it works (in the
>>Rd 
>> files), I want to refer to another package.  The other package is not
>>used 
>> anywhere in the actual code nor in the examples. So, there is no reason
>>to 
>> include the other package in the Depends, Suggests, or Imports lines of
>>the 
>> DESCRIPTION file.  People will be able to use my package without
>>actually 
>> installing the other package.
>>
>> However, "R CMD check" warns about "Missing link(s)" when it is
>>checking the 
>> cross references in the Rd files.
>>
>> What is the preferred way to make this warning go away?
>
>Follow the 'Writing R Extensions' manual.  There is a 3-item bullet
>point in ?1.1.1 following
>
>     'The general rules are'
>
>and your claims contradict the third point.
>
>>
>> Thanks in advance,
>>    Kevin
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
>-- 
>Brian D. Ripley,                  ripley at stats.ox.ac.uk
>Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>University of Oxford,             Tel:  +44 1865 272861 (self)
>1 South Parks Road,                     +44 1865 272866 (PA)
>Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From smckinney at bccrc.ca  Thu Jan 27 23:34:06 2011
From: smckinney at bccrc.ca (Steven McKinney)
Date: Thu, 27 Jan 2011 14:34:06 -0800
Subject: [Rd] use of depends, suggests, etc
In-Reply-To: <5448_1296166343_1296166343_alpine.LFD.2.02.1101272203470.3466@gannet.stats.ox.ac.uk>
References: <4D41D410.9040106@gmail.com>,
	<5448_1296166343_1296166343_alpine.LFD.2.02.1101272203470.3466@gannet.stats.ox.ac.uk>
Message-ID: <DCE81E14EB74504B971DAD4D2DB0356B08645685F9@crcmail4.BCCRC.CA>

If you add the other package to Suggests, what problems do you see?
Adding the other package to Suggests seems most appropriate, your
use case seems very similar to packages discussed in a vignette.

Steven McKinney

________________________________________
From: r-devel-bounces at r-project.org [r-devel-bounces at r-project.org] On Behalf Of Prof Brian Ripley [ripley at stats.ox.ac.uk]
Sent: January 27, 2011 2:12 PM
To: Kevin R. Coombes
Cc: r-devel at r-project.org
Subject: Re: [Rd] use of depends, suggests, etc

On Thu, 27 Jan 2011, Kevin R. Coombes wrote:

> Hi,
>
> I'm putting together an R package.  In explaining how it works (in the Rd
> files), I want to refer to another package.  The other package is not used
> anywhere in the actual code nor in the examples. So, there is no reason to
> include the other package in the Depends, Suggests, or Imports lines of the
> DESCRIPTION file.  People will be able to use my package without actually
> installing the other package.
>
> However, "R CMD check" warns about "Missing link(s)" when it is checking the
> cross references in the Rd files.
>
> What is the preferred way to make this warning go away?

Follow the 'Writing R Extensions' manual.  There is a 3-item bullet
point in ?1.1.1 following

     'The general rules are'

and your claims contradict the third point.

>
> Thanks in advance,
>    Kevin
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

--
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From pdbailey at umd.edu  Fri Jan 28 05:51:21 2011
From: pdbailey at umd.edu (Paul Bailey)
Date: Thu, 27 Jan 2011 23:51:21 -0500
Subject: [Rd] help with S4 objects: trying to use a "link-glm" as a class in
	an object definition
Message-ID: <CCB342DD-FD6F-45EA-9977-8779844535B6@umd.edu>

Hi,

I'm trying to make a new S4 object with a slot for a "link-glm" object. R doesn't like me have a slot of class "link-glm"

> class(make.link("probit"))
[1] "link-glm"
> setClass("a",representation(item="link-glm"))
[1] "a"
Warning message:
undefined slot classes in definition of "a": item(class "link-glm") 
> fa <- function() {
+   new("a",item=make.link("probit"))
+ }> 
> fa()
Error in validObject(.Object) : 
  invalid class "a" object: undefined class for slot "item" ("link-glm")

# and a link-glm looks like a list to me, so I thought I would tell R it is a list and see what happens

> setClass("b",representation(item="list"))
[1] "b"
> fb <- function() {
+   new("b",item=make.link("probit"))
+ }
> fb()
Error in validObject(.Object) : 
  invalid class "b" object: invalid object for slot "item" in class "b": got class "link-glm", should be or extend class "list"

Any advice?

Regards,
Paul Bailey
Ph.D. candidate
Department of Economics
University of Maryland

###### raw code #####
setClass("a",representation(item="link-glm"))
fa <- function() {
  new("a",item=make.link("probit"))
}
fa()
setClass("b",representation(item="list"))
fb <- function() {
  new("b",item=make.link("probit"))
}
fb()
###########

From i.aoultchenko at erasmusmc.nl  Fri Jan 28 07:35:23 2011
From: i.aoultchenko at erasmusmc.nl (016750)
Date: Fri, 28 Jan 2011 07:35:23 +0100
Subject: [Rd] generating HTML help pages
Message-ID: <ad4dfacdb33eb9107f09750cf5a4ca8b@mbox.erasmusmc.nl>

 Dear All,

 I need to convert all Rd help pages for my package to HTML format in 
 order to serve these on our web-server. Ideally, I would like to do that 
 as "all docs in single page" and also index page + one html page per Rd 
 file.

 Looking through documentation the only clues I could find were

 * R CMD Rdconv --type=html FILE, which does not produce cross-links, 
 does not process multiple files, and does not produce index file

 and

 * 
 tools::Rd2HTML("pathtopackage/file.Rd",Links=findHTMLlinks("pathtopackage")); 
 this will do a better job by producing cross-links, but again, no 
 multiple files processing, and no index

 This is not a big deal to make a loop over all files in my "man", and I 
 can copy "00Index.html" from library/package/html after install, but I 
 wonder if there is a more straightforward way to achieve my aim? Also, 
 any suggestions as for generating a single HTML with all help pages of a 
 package?

 with best regards, and sorry if I am off-topic,
 Yurii


From ripley at stats.ox.ac.uk  Fri Jan 28 08:46:22 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 28 Jan 2011 07:46:22 +0000 (GMT)
Subject: [Rd] generating HTML help pages
In-Reply-To: <ad4dfacdb33eb9107f09750cf5a4ca8b@mbox.erasmusmc.nl>
References: <ad4dfacdb33eb9107f09750cf5a4ca8b@mbox.erasmusmc.nl>
Message-ID: <alpine.LFD.2.02.1101280741190.28640@gannet.stats.ox.ac.uk>

Installing your package with 'R CMD INSTALL --html' gives you an 
'html' directory with an index and all the static HTML help files.
(That is in the R-admin manual, under 'Help options'.)

For a single page, you will need to write your own code -- but since R 
is Open Source you have lots of examples to go from.

On Fri, 28 Jan 2011, 016750 wrote:

> Dear All,
>
> I need to convert all Rd help pages for my package to HTML format in order to 
> serve these on our web-server. Ideally, I would like to do that as "all docs 
> in single page" and also index page + one html page per Rd file.
>
> Looking through documentation the only clues I could find were
>
> * R CMD Rdconv --type=html FILE, which does not produce cross-links, does not 
> process multiple files, and does not produce index file
>
> and
>
> * 
> tools::Rd2HTML("pathtopackage/file.Rd",Links=findHTMLlinks("pathtopackage")); 
> this will do a better job by producing cross-links, but again, no multiple 
> files processing, and no index
>
> This is not a big deal to make a loop over all files in my "man", and I can 
> copy "00Index.html" from library/package/html after install, but I wonder if 
> there is a more straightforward way to achieve my aim? Also, any suggestions 
> as for generating a single HTML with all help pages of a package?
>
> with best regards, and sorry if I am off-topic,
> Yurii
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From karl.forner at gmail.com  Fri Jan 28 12:54:20 2011
From: karl.forner at gmail.com (Karl Forner)
Date: Fri, 28 Jan 2011 12:54:20 +0100
Subject: [Rd] Possible bug in cut.dendrogram when there are only 2 leaves in
 the tree ?
Message-ID: <AANLkTinf1VtBsO+DVEdDF=qvXsqZeaUnSyZiDixLOcKu@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110128/ca1aed57/attachment.pl>

From mayr.andreas at gmail.com  Fri Jan 28 09:47:12 2011
From: mayr.andreas at gmail.com (Andreas Mayr)
Date: Fri, 28 Jan 2011 09:47:12 +0100
Subject: [Rd] trojan at current development version?
Message-ID: <AANLkTinnPcOZ-pdx-JAd+9L_kJQyD554TwU0VpGDnv8A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110128/012bbb7d/attachment.pl>

From pdalgd at gmail.com  Fri Jan 28 13:49:48 2011
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 28 Jan 2011 13:49:48 +0100
Subject: [Rd] trojan at current development version?
In-Reply-To: <AANLkTinnPcOZ-pdx-JAd+9L_kJQyD554TwU0VpGDnv8A@mail.gmail.com>
References: <AANLkTinnPcOZ-pdx-JAd+9L_kJQyD554TwU0VpGDnv8A@mail.gmail.com>
Message-ID: <928542C1-0002-48D7-9938-085597CD6614@gmail.com>


On Jan 28, 2011, at 09:47 , Andreas Mayr wrote:

> Hi,
> 
> is it possible, that the current development version  for Windows (
> http://cran.at.r-project.org/bin/windows/base/R-2.13.0dev-win.exe) is
> infected by a trojan/virus. My antivir-program (www.avira.com) seems to find
> a trojan in open.exe at bin\i386.

We have seen false positives before (accidental mismatch between virus signatures and legitimate programs). But presumably, the Windows maintainers will double-check, just in case.


-- 
Peter Dalgaard
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From ligges at statistik.tu-dortmund.de  Fri Jan 28 14:31:22 2011
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Fri, 28 Jan 2011 14:31:22 +0100
Subject: [Rd] trojan at current development version?
In-Reply-To: <928542C1-0002-48D7-9938-085597CD6614@gmail.com>
References: <AANLkTinnPcOZ-pdx-JAd+9L_kJQyD554TwU0VpGDnv8A@mail.gmail.com>
	<928542C1-0002-48D7-9938-085597CD6614@gmail.com>
Message-ID: <4D42C52A.4020801@statistik.tu-dortmund.de>



On 28.01.2011 13:49, peter dalgaard wrote:
>
> On Jan 28, 2011, at 09:47 , Andreas Mayr wrote:
>
>> Hi,
>>
>> is it possible, that the current development version  for Windows (
>> http://cran.at.r-project.org/bin/windows/base/R-2.13.0dev-win.exe) is
>> infected by a trojan/virus. My antivir-program (www.avira.com) seems to find
>> a trojan in open.exe at bin\i386.
>
> We have seen false positives before (accidental mismatch between virus signatures and legitimate programs). But presumably, the Windows maintainers will double-check, just in case.

Oh yes, we got such reports before. People reported to Avira and it went 
away. Now it is there again. Hopeless, I assume.

Duncan: Perhaps we can add at the download page that Avira reports 
open.exe to be infected from time to time.

Best wishes,
Uwe



>
>


From mtmorgan at fhcrc.org  Fri Jan 28 14:58:49 2011
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Fri, 28 Jan 2011 05:58:49 -0800
Subject: [Rd] help with S4 objects: trying to use a "link-glm" as a
 class in	an object definition
In-Reply-To: <CCB342DD-FD6F-45EA-9977-8779844535B6@umd.edu>
References: <CCB342DD-FD6F-45EA-9977-8779844535B6@umd.edu>
Message-ID: <4D42CB99.9090801@fhcrc.org>

On 01/27/2011 08:51 PM, Paul Bailey wrote:
> Hi,
> 
> I'm trying to make a new S4 object with a slot for a "link-glm" object. R doesn't like me have a slot of class "link-glm"
> 
>> class(make.link("probit"))
> [1] "link-glm"

Tell the S4 system that you'd like to use this 'old' class

setOldClass("link-glm")

and things should be ok. Martin

>> setClass("a",representation(item="link-glm"))
> [1] "a"
> Warning message:
> undefined slot classes in definition of "a": item(class "link-glm") 
>> fa <- function() {
> +   new("a",item=make.link("probit"))
> + }> 
>> fa()
> Error in validObject(.Object) : 
>   invalid class "a" object: undefined class for slot "item" ("link-glm")
> 
> # and a link-glm looks like a list to me, so I thought I would tell R it is a list and see what happens
> 
>> setClass("b",representation(item="list"))
> [1] "b"
>> fb <- function() {
> +   new("b",item=make.link("probit"))
> + }
>> fb()
> Error in validObject(.Object) : 
>   invalid class "b" object: invalid object for slot "item" in class "b": got class "link-glm", should be or extend class "list"
> 
> Any advice?
> 
> Regards,
> Paul Bailey
> Ph.D. candidate
> Department of Economics
> University of Maryland
> 
> ###### raw code #####
> setClass("a",representation(item="link-glm"))
> fa <- function() {
>   new("a",item=make.link("probit"))
> }
> fa()
> setClass("b",representation(item="list"))
> fb <- function() {
>   new("b",item=make.link("probit"))
> }
> fb()
> ###########
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
Computational Biology
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N. PO Box 19024 Seattle, WA 98109

Location: M1-B861
Telephone: 206 667-2793


From bbolker at gmail.com  Fri Jan 28 15:17:11 2011
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 28 Jan 2011 14:17:11 +0000 (UTC)
Subject: [Rd] trojan at current development version?
References: <AANLkTinnPcOZ-pdx-JAd+9L_kJQyD554TwU0VpGDnv8A@mail.gmail.com>
	<928542C1-0002-48D7-9938-085597CD6614@gmail.com>
	<4D42C52A.4020801@statistik.tu-dortmund.de>
Message-ID: <loom.20110128T151400-760@post.gmane.org>

Uwe Ligges <ligges <at> statistik.tu-dortmund.de> writes:

> 
> 
> On 28.01.2011 13:49, peter dalgaard wrote:
> >
> > On Jan 28, 2011, at 09:47 , Andreas Mayr wrote:
> >
> >> Hi,
> >>
> >> is it possible, that the current development version  for Windows (
> >> http://cran.at.r-project.org/bin/windows/base/R-2.13.0dev-win.exe) is
> >> infected by a trojan/virus. My antivir-program (www.avira.com) seems to find
> >> a trojan in open.exe at bin\i386.
> >
> > We have seen false positives before (accidental mismatch between virus
signatures and legitimate
> programs). But presumably, the Windows maintainers will double-check, just in
case.
> 
> Oh yes, we got such reports before. People reported to Avira and it went 
> away. Now it is there again. Hopeless, I assume.
> 
> Duncan: Perhaps we can add at the download page that Avira reports 
> open.exe to be infected from time to time.
> 
> Best wishes,
> Uwe
> 
 
  Another note for the paranoid is that the MD5 sum for the binary
is posted, so you can at least check consistency.  On the  other hand,
if someone managed to compromise an entire CRAN mirror, they could
also post MD5 sums for their nastified version ...  you could always
go check the MD5 sums on another CRAN mirror (or on the main page),
which would make the attacker work much harder ...


From kevin.r.coombes at gmail.com  Fri Jan 28 18:18:02 2011
From: kevin.r.coombes at gmail.com (Kevin R. Coombes)
Date: Fri, 28 Jan 2011 11:18:02 -0600
Subject: [Rd] use of depends, suggests, etc
In-Reply-To: <C9674B00.201BA%ken.williams@thomsonreuters.com>
References: <C9674B00.201BA%ken.williams@thomsonreuters.com>
Message-ID: <4D42FA4A.7000709@gmail.com>

The situation I am talking about is essentially the one in your example.

If package [Bar] is not installed on the machine where R CMD chedk is 
running, then putting
     Suggests: Bar
in the DESCRIPTION file causes R CMD check to fail, with the error message
     * checking package dependencies ... ERROR
     Package required but not available: Bar
Thus, for purposes of running R CMD check, anything listed in Depends, 
Suggest, or Imports is required to be installed.

However, I'd like to be able to talk about the package in the Rd file 
(even if it is not installed locally), and have a link generated (which 
will only work if the package is installed), but not actually use or 
require package Bar for anything in my own package.

     Kevin

On 1/27/2011 4:31 PM, Ken.Williams at thomsonreuters.com wrote:
> But suppose I want to write something like: "this package is 10 million
> times better than my other package [Foo] because that one will eat your
> children" - or "in contrast to the package [Bar], this package is for
> continuous data, while that one is for discrete data, so they don't
> interoperate".
>
> It wouldn't make sense to Depend or Suggest or Import the [Foo] or [Bar]
> package, but if I didn't, the doc-building process will (apparently - I
> haven't tried it myself) warn about the link being broken.
>
> I can think of several different ways to address this if there isn't an
> existing way (e.g. create a generic SeeAlso dependency field; use a
> different syntax for citing packages that aren't dependencies of one sort
> or another, etc.), but obviously they'd need the blessing of the people
> maintaining the tools&  specs.
>
> --
> Ken Williams
> Senior Research Scientist
> Thomson Reuters
> Phone: 651-848-7712
> ken.williams at thomsonreuters.com
> http://labs.thomsonreuters.com
>
>
>
>
>
> On 1/27/11 4:12 PM, "Prof Brian Ripley"<ripley at stats.ox.ac.uk>  wrote:
>
>> On Thu, 27 Jan 2011, Kevin R. Coombes wrote:
>>
>>> Hi,
>>>
>>> I'm putting together an R package.  In explaining how it works (in the
>>> Rd
>>> files), I want to refer to another package.  The other package is not
>>> used
>>> anywhere in the actual code nor in the examples. So, there is no reason
>>> to
>>> include the other package in the Depends, Suggests, or Imports lines of
>>> the
>>> DESCRIPTION file.  People will be able to use my package without
>>> actually
>>> installing the other package.
>>>
>>> However, "R CMD check" warns about "Missing link(s)" when it is
>>> checking the
>>> cross references in the Rd files.
>>>
>>> What is the preferred way to make this warning go away?
>> Follow the 'Writing R Extensions' manual.  There is a 3-item bullet
>> point in ?1.1.1 following
>>
>>      'The general rules are'
>>
>> and your claims contradict the third point.
>>
>>> Thanks in advance,
>>>     Kevin
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>> -- 
>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>> University of Oxford,             Tel:  +44 1865 272861 (self)
>> 1 South Parks Road,                     +44 1865 272866 (PA)
>> Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From marc.carpentier at ymail.com  Fri Jan 28 20:01:43 2011
From: marc.carpentier at ymail.com (Marc Carpentier)
Date: Fri, 28 Jan 2011 19:01:43 +0000 (GMT)
Subject: [Rd] ReferenceClasses examples {method}
Message-ID: <750123.43782.qm@web28204.mail.ukl.yahoo.com>

Dear r-devel-list, dear John Chambers,

I'm trying to learn OOP-possibilities in R and I was going through the 
documentation 'ReferenceClasses {methods}' (great work, by the way...).
Reading associated Examples, something bothers me : it seems to me that there 
are errors in 'edit' and 'undo' methods. I think that :
- 'undo' should update 'edits' field with :
length(edits) <<- length(edits) - 1 #(and not - 2)
- and for coherence, 'edit' should store modifications in an 'append'-style :
edits <<- c(edits,list(backup)) #as opposed to c(list(backup),edits)

I hope I'm not wrong and this hasn't been previously reported (I didn't find 
anything about it)
Best regards.

PS: I first posted this message on help-list. David Winsemius suggested  me 
devel-list would probably be more appropriate and was right about that. Sorry if 
you read it  again.
PPS: please associate my address when responding because I didn't subscribe to 
r-devel-list (I'm still far from being able to follow all its discussions...)






From jmc at r-project.org  Sat Jan 29 00:09:36 2011
From: jmc at r-project.org (John Chambers)
Date: Fri, 28 Jan 2011 15:09:36 -0800
Subject: [Rd] ReferenceClasses examples {method}
In-Reply-To: <750123.43782.qm@web28204.mail.ukl.yahoo.com>
References: <750123.43782.qm@web28204.mail.ukl.yahoo.com>
Message-ID: <4D434CB0.3070004@r-project.org>

Hi Marc,

Sort of one out of two, but very helpful.

On 1/28/11 11:01 AM, Marc Carpentier wrote:
> Dear r-devel-list, dear John Chambers,
>
> I'm trying to learn OOP-possibilities in R and I was going through the
> documentation 'ReferenceClasses {methods}' (great work, by the way...).
> Reading associated Examples, something bothers me : it seems to me that there
> are errors in 'edit' and 'undo' methods. I think that :
> - 'undo' should update 'edits' field with :
> length(edits)<<- length(edits) - 1 #(and not - 2)

Nope.  There are actually two logical choices here, but that is not 
either of them.

Notice that the line before that is:
   edit(prev[[1]], prev[[2]], prev[[3]])
which invokes the $edit() method to effect the undo, _and_ which adds 
that edit to the $edits list.

One could just leave things that way, but we decide to hide our undo 
from Wikileaks by removing both the edits.

> - and for coherence, 'edit' should store modifications in an 'append'-style :
> edits<<- c(edits,list(backup)) #as opposed to c(list(backup),edits)

Well, that's a bit debatable, but it does expose a bug, for sure.  The 
current order might be acceptable, but $undo() is then removing the 
wrong end of the $edits list, as would have been obvious if the example 
had done two edits and then removed one.  In the current version the 
first backup is the most recent edit (and indeed is used to reset the 
data), but then the wrong elements of $edits are removed.

Given that, I agree that the opposite order of keeping the backup list 
is better.  Less copying, for one thing.

Attached is a corrected and slightly expanded version of that part of 
the example.  Anyone is encouraged to try it out; if no further problems 
arise, I'll commit its essentials.

>
> I hope I'm not wrong and this hasn't been previously reported (I didn't find
> anything about it)
> Best regards.
>
> PS: I first posted this message on help-list. David Winsemius suggested  me
> devel-list would probably be more appropriate and was right about that. Sorry if
> you read it  again.

And indeed r-devel was the right place.  Thanks

John

> PPS: please associate my address when responding because I didn't subscribe to
> r-devel-list (I'm still far from being able to follow all its discussions...)
>
>
>
>
>

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: test.R
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110128/ce5eee6c/attachment.pl>

From guxiaobo1982 at gmail.com  Sat Jan 29 10:07:05 2011
From: guxiaobo1982 at gmail.com (Xiaobo Gu)
Date: Sat, 29 Jan 2011 17:07:05 +0800
Subject: [Rd] RPostgreSQL 0.1.7 for Windows 64 causes R.2.12.1 Win64
	crash
In-Reply-To: <alpine.LFD.2.00.1101171711170.2906@toucan.stats.ox.ac.uk>
References: <AANLkTinvoub-z_Le1GVPYswnqTsW1P6MZzLZsztois9K@mail.gmail.com>
	<AANLkTimfKn+qAMP8q2W8nJFvxVdoOM8gYYWZtZU_Jk9w@mail.gmail.com>
	<19764.19953.237115.864920@max.nulle.part>
	<alpine.LFD.2.00.1101171711170.2906@toucan.stats.ox.ac.uk>
Message-ID: <AANLkTinEeqX_3w8qb4_jhfx9Wkmz3GpYZYvVrgZivwG5@mail.gmail.com>

On Tue, Jan 18, 2011 at 1:22 AM, Prof Brian Ripley
<ripley at stats.ox.ac.uk> wrote:
> On Mon, 17 Jan 2011, Dirk Eddelbuettel wrote:
>
>>
>> On 16 January 2011 at 23:00, Xiaobo Gu wrote:
>> | Is it because of compiler campsites between R and PostgreSQL, R is
>> | compiled by GCC, while PostgreSQL from Enterprise DB is compiled by
>> | Microsoft Visual C ++.
>>
>> So the usual recommendation is to build the matching library (here libpq)
>> with the same compiler, or get the commercial support you are paying for
>> to
>> do it for you.
>>
>> For what it is worth, I deal with one vendor at work where I made that
>> requirement and they had no issue complying / helping me with a MinGW /
>> Rtools-compatible library. ?One of several reasons I like working with
>> that
>> vendor.
>
> And also for what it is worth, RPostgreSQL works for me on x64 Windows 7
> compiled with the Rtools compilers and linked against the initial PostgreSQL
> 9.0 Windows x64 distribution (I've not tried the one you mentioned).

PostgreSQL 9.0.2 source code with a Win64 patch now can be built using
MinGW64 1.0 (GCC 4.5.2), and the RPostgreSQL package works well now
against the corresponding libpq.dll libraries.

By the way, I found MinGW64 with MSYS is much more convenient.

Xiaobo Gu


From marc.carpentier at ymail.com  Sat Jan 29 11:49:15 2011
From: marc.carpentier at ymail.com (Marc Carpentier)
Date: Sat, 29 Jan 2011 10:49:15 +0000 (GMT)
Subject: [Rd] Re : ReferenceClasses examples {method}
In-Reply-To: <4D434CB0.3070004@r-project.org>
References: <750123.43782.qm@web28204.mail.ukl.yahoo.com>
	<4D434CB0.3070004@r-project.org>
Message-ID: <587595.92086.qm@web28201.mail.ukl.yahoo.com>

Hi,
Thank you for this pedagocical response. Obviously, I hadn't consider the 
$edit() call from $undo() itself...

Which made me think of a more vicious (!) example... with the possibility to 
undo what's been undone...
Viciousness isn't the point, so in this modified example :
- edits is used as an history list of 'edit actions' (i, j, oldvalue AND 
newvalue)
- a new field is used to point current position in this history list (coerced as 
integer)
- this is the opportunity to demonstrate a very simple initialize() method to 
set editspointer to 0 (because of the first call of edit() and 'length(edits) 
<<- editspointer')
- a default argument is used for the edit() method, to consider specific calls 
by undo() or unundo()
- controls and stops are maintained...
It seems to run correctly... I don't know if it's worth to share ; please use it 
freely.

Marc



----- Message d'origine ----
De : John Chambers <jmc at r-project.org>
? : Marc Carpentier <marc.carpentier at ymail.com>
Cc : r-devel at r-project.org
Envoy? le : Sam 29 janvier 2011, 0h 09min 36s
Objet : Re: ReferenceClasses examples {method}

Hi Marc,

Sort of one out of two, but very helpful.

On 1/28/11 11:01 AM, Marc Carpentier wrote:
> Dear r-devel-list, dear John Chambers,
> 
> I'm trying to learn OOP-possibilities in R and I was going through the
> documentation 'ReferenceClasses {methods}' (great work, by the way...).
> Reading associated Examples, something bothers me : it seems to me that there
> are errors in 'edit' and 'undo' methods. I think that :
> - 'undo' should update 'edits' field with :
> length(edits)<<- length(edits) - 1 #(and not - 2)

Nope.  There are actually two logical choices here, but that is not either of 
them.

Notice that the line before that is:
  edit(prev[[1]], prev[[2]], prev[[3]])
which invokes the $edit() method to effect the undo, _and_ which adds that edit 
to the $edits list.

One could just leave things that way, but we decide to hide our undo from 
Wikileaks by removing both the edits.

> - and for coherence, 'edit' should store modifications in an 'append'-style :
> edits<<- c(edits,list(backup)) #as opposed to c(list(backup),edits)

Well, that's a bit debatable, but it does expose a bug, for sure.  The current 
order might be acceptable, but $undo() is then removing the wrong end of the 
$edits list, as would have been obvious if the example had done two edits and 
then removed one.  In the current version the first backup is the most recent 
edit (and indeed is used to reset the data), but then the wrong elements of 
$edits are removed.

Given that, I agree that the opposite order of keeping the backup list is 
better.  Less copying, for one thing.

Attached is a corrected and slightly expanded version of that part of the 
example.  Anyone is encouraged to try it out; if no further problems arise, I'll 
commit its essentials.

> 
> I hope I'm not wrong and this hasn't been previously reported (I didn't find
> anything about it)
> Best regards.
> 
> PS: I first posted this message on help-list. David Winsemius suggested  me
> devel-list would probably be more appropriate and was right about that. Sorry 
>if
> you read it  again.

And indeed r-devel was the right place.  Thanks

John

> PPS: please associate my address when responding because I didn't subscribe to
> r-devel-list (I'm still far from being able to follow all its discussions...)
> 
> 
> 
> 
> 


      

From maechler at stat.math.ethz.ch  Sat Jan 29 21:49:38 2011
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Sat, 29 Jan 2011 21:49:38 +0100
Subject: [Rd] help with S4 objects: trying to use a "link-glm" as a
	class in	an object definition
In-Reply-To: <CCB342DD-FD6F-45EA-9977-8779844535B6@umd.edu>
References: <CCB342DD-FD6F-45EA-9977-8779844535B6@umd.edu>
Message-ID: <19780.32098.662708.522582@stat.math.ethz.ch>

>>>>> Paul Bailey <pdbailey at umd.edu>
>>>>>     on Thu, 27 Jan 2011 23:51:21 -0500 writes:

    > Hi, I'm trying to make a new S4 object with a slot for a
    > "link-glm" object. R doesn't like me have a slot of class
    > "link-glm"

    >> class(make.link("probit"))
    > [1] "link-glm"
    >> setClass("a",representation(item="link-glm"))
    > [1] "a" Warning message: undefined slot classes in
    > definition of "a": item(class "link-glm")

you need a 

 setOldClass("link-glm")

before the the setClass() above and then things "work".

> setOldClass("link-glm")
> setClass("a",representation(item="link-glm"))
[1] "a"
> fa <- function() { new("a",item=make.link("probit"))  }
> b <- fa()
> b
An object of class "a"
Slot "item":
$linkfun
function (mu) 
....
....

Martin Maechler, ETH Zurich

    >> fa <- function() {
    > + new("a",item=make.link("probit")) + }>
    >> fa()
    > Error in validObject(.Object) : invalid class "a" object:
    > undefined class for slot "item" ("link-glm")

    > # and a link-glm looks like a list to me, so I thought I
    > would tell R it is a list and see what happens

    >> setClass("b",representation(item="list"))
    > [1] "b"
    >> fb <- function() {
    > + new("b",item=make.link("probit")) + }
    >> fb()
    > Error in validObject(.Object) : invalid class "b" object:
    > invalid object for slot "item" in class "b": got class
    > "link-glm", should be or extend class "list"

    > Any advice?

    > Regards, Paul Bailey Ph.D. candidate Department of
    > Economics University of Maryland

    > ###### raw code #####
    > setClass("a",representation(item="link-glm")) fa <-
    > function() { new("a",item=make.link("probit")) } fa()
    > setClass("b",representation(item="list")) fb <- function()
    > { new("b",item=make.link("probit")) } fb()
    > ###########
    > ______________________________________________
    > R-devel at r-project.org mailing list
    > https://stat.ethz.ch/mailman/listinfo/r-devel


From murdoch.duncan at gmail.com  Sat Jan 29 21:57:54 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 29 Jan 2011 15:57:54 -0500
Subject: [Rd] use of depends, suggests, etc
In-Reply-To: <4D42FA4A.7000709@gmail.com>
References: <C9674B00.201BA%ken.williams@thomsonreuters.com>
	<4D42FA4A.7000709@gmail.com>
Message-ID: <4D447F52.5060908@gmail.com>

On 11-01-28 12:18 PM, Kevin R. Coombes wrote:
> The situation I am talking about is essentially the one in your example.
>
> If package [Bar] is not installed on the machine where R CMD chedk is
> running, then putting
>       Suggests: Bar
> in the DESCRIPTION file causes R CMD check to fail, with the error message
>       * checking package dependencies ... ERROR
>       Package required but not available: Bar
> Thus, for purposes of running R CMD check, anything listed in Depends,
> Suggest, or Imports is required to be installed.
>
> However, I'd like to be able to talk about the package in the Rd file
> (even if it is not installed locally), and have a link generated (which
> will only work if the package is installed), but not actually use or
> require package Bar for anything in my own package.

You can probably avoid the check problems by using a link generated
at display time by \Sexpr, with code that generates a link if the target 
is installed, and plain text if not.  Seems like it would be overkill, 
but you must have good reasons to want to link to packages that don't 
exist on the test machines, so maybe it's worth doing.

Duncan Murdoch

>
>       Kevin
>
> On 1/27/2011 4:31 PM, Ken.Williams at thomsonreuters.com wrote:
>> But suppose I want to write something like: "this package is 10 million
>> times better than my other package [Foo] because that one will eat your
>> children" - or "in contrast to the package [Bar], this package is for
>> continuous data, while that one is for discrete data, so they don't
>> interoperate".
>>
>> It wouldn't make sense to Depend or Suggest or Import the [Foo] or [Bar]
>> package, but if I didn't, the doc-building process will (apparently - I
>> haven't tried it myself) warn about the link being broken.
>>
>> I can think of several different ways to address this if there isn't an
>> existing way (e.g. create a generic SeeAlso dependency field; use a
>> different syntax for citing packages that aren't dependencies of one sort
>> or another, etc.), but obviously they'd need the blessing of the people
>> maintaining the tools&   specs.
>>
>> --
>> Ken Williams
>> Senior Research Scientist
>> Thomson Reuters
>> Phone: 651-848-7712
>> ken.williams at thomsonreuters.com
>> http://labs.thomsonreuters.com
>>
>>
>>
>>
>>
>> On 1/27/11 4:12 PM, "Prof Brian Ripley"<ripley at stats.ox.ac.uk>   wrote:
>>
>>> On Thu, 27 Jan 2011, Kevin R. Coombes wrote:
>>>
>>>> Hi,
>>>>
>>>> I'm putting together an R package.  In explaining how it works (in the
>>>> Rd
>>>> files), I want to refer to another package.  The other package is not
>>>> used
>>>> anywhere in the actual code nor in the examples. So, there is no reason
>>>> to
>>>> include the other package in the Depends, Suggests, or Imports lines of
>>>> the
>>>> DESCRIPTION file.  People will be able to use my package without
>>>> actually
>>>> installing the other package.
>>>>
>>>> However, "R CMD check" warns about "Missing link(s)" when it is
>>>> checking the
>>>> cross references in the Rd files.
>>>>
>>>> What is the preferred way to make this warning go away?
>>> Follow the 'Writing R Extensions' manual.  There is a 3-item bullet
>>> point in ?1.1.1 following
>>>
>>>       'The general rules are'
>>>
>>> and your claims contradict the third point.
>>>
>>>> Thanks in advance,
>>>>      Kevin
>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>
>>> --
>>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>>> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>>> University of Oxford,             Tel:  +44 1865 272861 (self)
>>> 1 South Parks Road,                     +44 1865 272866 (PA)
>>> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From maechler at stat.math.ethz.ch  Sat Jan 29 22:47:24 2011
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Sat, 29 Jan 2011 22:47:24 +0100
Subject: [Rd] patch dendrogram.R from stats [was: Re: dendrogram plot does
 not draw long labels ?]
In-Reply-To: <4D3F323D.2090803@openanalytics.eu>
References: <AANLkTikuvd7q4xbyzEdfp+G_k1CsEM_db7zxZXpiQcWg@mail.gmail.com>
	<4D3EB147.8000906@openanalytics.eu>
	<AANLkTi=3rXNF5RQRbcQwonUqA-0Q1XBT--p4hyfNQ9VZ@mail.gmail.com>
	<4D3F323D.2090803@openanalytics.eu>
Message-ID: <19780.35564.504538.916224@stat.math.ethz.ch>

>>>>> Tobias Verbeke <tobias.verbeke at openanalytics.eu>
>>>>>     on Tue, 25 Jan 2011 21:27:41 +0100 writes:

    > L.S.
    > Please find below a patch for dendrogram.R (stats package)
    > against revision r54107 which allows one to pass the xpd
    > parameter as a component of the nodePar list (to be
    > passed to plot.dendrogram).

    > I hope I did not overlook anything.

Thank you, Tobias.

Note BTW, that on Linux I don't have your problems that the
label is "not drawn" when it does not fit.
For me, it just is clipped (to the figure region as you note),
so "chopped off" but the part inside the figure box is well
visible.

I was searching a bit and did not find mentioned on ?par or
?clip that clipping happens device dependently,
but I vaguely recall to have seen it stated..

However the patch is a good idea, anyway,
and it will be in R 2.13.x..

Thanks again,
Martin Maechler

    > Best,
    > Tobias

    > 378a379
    >> lab.xpd <- Xtract("xpd", nPar, default = c(TRUE, TRUE), i)
    > 391c392
    > < 	    text(X, Y, nodeText, xpd = TRUE, srt = srt, adj = adj,
    > ---
    >> text(X, Y, nodeText, xpd = lab.xpd, srt = srt, adj = adj,
    > 436c437
    > < 		text(xBot, yBot + vln, nodeText, xpd = TRUE,
    > ---
    >> text(xBot, yBot + vln, nodeText, xpd = lab.xpd,



    > On 01/25/2011 04:34 PM, Karl Forner wrote:
    >> Hi Tobias and thank you for your reply,
    >> 
    >> Using your insight I managed to work-around the issue (with some help)
    >> by increasing
    >> the "mai" option of par().
    >> For example a "mai" with first coordinate (bottom) set to 5 allows to
    >> display ~ 42 letters.
    >> 
    >> We tried to change the xpd value in the text() call that you mentioned,
    >> but it did not seem to fix the problem.
    >> 
    >> But I think this is very annoying: the dendrogram plot is meant to be
    >> the common unique plotting for all clustering stuff
    >> and suddenly if your labels are just too long, nothing get displayed,
    >> without even a warning.
    >> I suppose that the margins should be dynamically set based on the max
    >> label text drawn length...
    >> 
    >> The hclust plot seemed to handle very nicely these long labels, but I
    >> need to display colored labels and the only way I found is to use the
    >> plot.dendrogram for this.
    >> 
    >> Best,
    >> 
    >> Karl
    >> 
    >> On Tue, Jan 25, 2011 at 12:17 PM, Tobias Verbeke
    >> <tobias.verbeke at openanalytics.eu
    >> <mailto:tobias.verbeke at openanalytics.eu>> wrote:
    >> 
    >> Hi Karl,
    >> 
    >> 
    >> On 01/25/2011 11:27 AM, Karl Forner wrote:
    >> 
    >> It seems that the plot function for dendrograms does not draw
    >> labels when
    >> they are too long.
    >> 
    >> hc<- hclust(dist(USArrests), "ave")
    >> dend1<- as.dendrogram(hc)
    >> dend2<- cut(dend1, h=70)
    >> dd<- dend2$lower[[1]]
    >> plot(dd) # first label is drawn
    >> attr(dd[[1]], "label")<- "aaaaaaaaaaaaaaaaaa"
    >> plot(dd) # first label is NOT drawn
    >> 
    >> 
    >> Is this expected ?
    >> 
    >> 
    >> Reading the code of stats:::plotNode, yes.
    >> 
    >> Clipping to the figure region is hard-coded.
    >> 
    >> You can see it is clipping to the figure region as follows:
    >> 
    >> 
    >> hc <- hclust(dist(USArrests), "ave")
    >> dend1 <- as.dendrogram(hc)
    >> dend2 <- cut(dend1, h=70)
    >> dd <- dend2$lower[[1]]
    >> op <- par(oma = c(8,4,4,2)+0.1, xpd = NA)
    >> 
    >> plot(dd) # first label is drawn
    >> attr(dd[[1]], "label") <- "abcdefghijklmnopqrstuvwxyz"
    >> 
    >> plot(dd) # first label is NOT drawn
    >> box(which = "figure")
    >> par(op)
    >> 
    >> 
    >> Is it possible to force the drawing ?
    >> 
    >> 
    >> These are (from very quick reading -- not verified)
    >> the culprit lines in plotNode, I think:
    >> 
    >> text(xBot, yBot + vln, nodeText, xpd = TRUE, # <- clipping hard-coded
    >> cex = lab.cex, col = lab.col, font = lab.font)
    >> 
    >> Best,
    >> Tobias
    >> 
    >> 

    > ______________________________________________
    > R-devel at r-project.org mailing list
    > https://stat.ethz.ch/mailman/listinfo/r-devel


From ripley at stats.ox.ac.uk  Sat Jan 29 23:59:10 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 29 Jan 2011 22:59:10 +0000 (GMT)
Subject: [Rd] Clipping (was Re: patch dendrogram.R from stats [was: Re:
 dendrogram plot does not draw long labels ?])
In-Reply-To: <19780.35564.504538.916224@stat.math.ethz.ch>
References: <AANLkTikuvd7q4xbyzEdfp+G_k1CsEM_db7zxZXpiQcWg@mail.gmail.com>
	<4D3EB147.8000906@openanalytics.eu>
	<AANLkTi=3rXNF5RQRbcQwonUqA-0Q1XBT--p4hyfNQ9VZ@mail.gmail.com>
	<4D3F323D.2090803@openanalytics.eu>
	<19780.35564.504538.916224@stat.math.ethz.ch>
Message-ID: <alpine.LFD.2.02.1101292239520.10557@gannet.stats.ox.ac.uk>

On Sat, 29 Jan 2011, Martin Maechler wrote:

>>>>>> Tobias Verbeke <tobias.verbeke at openanalytics.eu>
>>>>>>     on Tue, 25 Jan 2011 21:27:41 +0100 writes:
>
>    > L.S.
>    > Please find below a patch for dendrogram.R (stats package)
>    > against revision r54107 which allows one to pass the xpd
>    > parameter as a component of the nodePar list (to be
>    > passed to plot.dendrogram).
>
>    > I hope I did not overlook anything.
>
> Thank you, Tobias.
>
> Note BTW, that on Linux I don't have your problems that the
> label is "not drawn" when it does not fit.
> For me, it just is clipped (to the figure region as you note),
> so "chopped off" but the part inside the figure box is well
> visible.
>
> I was searching a bit and did not find mentioned on ?par or
> ?clip that clipping happens device dependently,
> but I vaguely recall to have seen it stated..

Yes, it is device-dependent (but then most low-level things about 
graphics are, in particular everything about fonts).

The designers of the graphics internals never documented their 
principles, but I retrospectively tried to do so in the R-ints manual. 
So whereas clipping of lines is done in the graphics engine, for text 
the manual says:

   If possible, the graphics device should handle clipping of text. It
   indicates this by the structure element 'canClip' which if true will
   result in calls to the callback 'clip' to set the clipping region. If
   this is not done, the engine will clip very crudely (by omitting any
   text that does not appear to be wholly inside the clipping region).

I'll add a note to ?clip, but perhaps this can serve as a reminder 
that the R-ints manual is the place to look for low-level graphics 
details.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From tobias.verbeke at openanalytics.eu  Sun Jan 30 21:42:32 2011
From: tobias.verbeke at openanalytics.eu (Tobias Verbeke)
Date: Sun, 30 Jan 2011 21:42:32 +0100
Subject: [Rd] Clipping (was Re: patch dendrogram.R from stats [was: Re:
 dendrogram plot does not draw long labels ?])
In-Reply-To: <alpine.LFD.2.02.1101292239520.10557@gannet.stats.ox.ac.uk>
References: <AANLkTikuvd7q4xbyzEdfp+G_k1CsEM_db7zxZXpiQcWg@mail.gmail.com>
	<4D3EB147.8000906@openanalytics.eu>
	<AANLkTi=3rXNF5RQRbcQwonUqA-0Q1XBT--p4hyfNQ9VZ@mail.gmail.com>
	<4D3F323D.2090803@openanalytics.eu>
	<19780.35564.504538.916224@stat.math.ethz.ch>
	<alpine.LFD.2.02.1101292239520.10557@gannet.stats.ox.ac.uk>
Message-ID: <4D45CD38.5030409@openanalytics.eu>

On 01/29/2011 11:59 PM, Prof Brian Ripley wrote:
> On Sat, 29 Jan 2011, Martin Maechler wrote:
>
>>>>>>> Tobias Verbeke <tobias.verbeke at openanalytics.eu>
>>>>>>> on Tue, 25 Jan 2011 21:27:41 +0100 writes:
>>
>> > L.S.
>> > Please find below a patch for dendrogram.R (stats package)
>> > against revision r54107 which allows one to pass the xpd
>> > parameter as a component of the nodePar list (to be
>> > passed to plot.dendrogram).
>>
>> > I hope I did not overlook anything.
>>
>> Thank you, Tobias.
>>
>> Note BTW, that on Linux I don't have your problems that the
>> label is "not drawn" when it does not fit.
>> For me, it just is clipped (to the figure region as you note),
>> so "chopped off" but the part inside the figure box is well
>> visible.
>>
>> I was searching a bit and did not find mentioned on ?par or
>> ?clip that clipping happens device dependently,
>> but I vaguely recall to have seen it stated..
>
> Yes, it is device-dependent (but then most low-level things about
> graphics are, in particular everything about fonts).
>
> The designers of the graphics internals never documented their
> principles, but I retrospectively tried to do so in the R-ints manual.
> So whereas clipping of lines is done in the graphics engine, for text
> the manual says:
>
> If possible, the graphics device should handle clipping of text. It
> indicates this by the structure element 'canClip' which if true will
> result in calls to the callback 'clip' to set the clipping region. If
> this is not done, the engine will clip very crudely (by omitting any
> text that does not appear to be wholly inside the clipping region).
>
> I'll add a note to ?clip, but perhaps this can serve as a reminder that
> the R-ints manual is the place to look for low-level graphics details.

Many thanks, Prof Ripley and Martin, for your work
integrating the patch, documentation updates as well
as for the additional explanation putting the observed
behaviour in perspective.

Kind regards,
Tobias Verbeke


From hb at biostat.ucsf.edu  Mon Jan 31 05:14:52 2011
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Sun, 30 Jan 2011 20:14:52 -0800
Subject: [Rd] data.frame(A=X): Prepend "A." also for single-column X:s [WISH]
Message-ID: <AANLkTinbH0vd7z0+CLe4OKKGGp4CmNwugX51URHBcCs2@mail.gmail.com>

Hi.

The following results in a data.frame with column names starting with "A.":

> X <- data.frame(x=1:2, y=1:2)
> X
   x y
1 1 1
2 2 2

> data.frame(A=X)
  A.x A.y
1   1   1
2   2   2


whereas with a single-column matrix you won't get "A.":

> Y <- X[,1,drop=FALSE];
> Y
  x
1 1
2 2

> data.frame(A=Y);
  x
1 1
2 2

I'd like to obtain column name "A.x" in the latter case too.  Note
that Y is still a matrix.

What I am really looking for is a way to automatically prefix data
frame names, e.g:

> data.frame(A=Y, B=Y);  # wish
A.x B.x
1 1   1
2 2   2

analogously to:

> data.frame(A=X, B=X);

  A.x A.y B.x B.y
1   1   1   1   1
2   2   2   2   2

instead of as now:

> data.frame(A=Y, B=Y);
  x x.1
1 1   1
2 2   2


Looking at the code for data.frame(), I find:

        if (ncols[i] > 1L) {
            if (length(namesi) == 0L)
                namesi <- seq_len(ncols[i])
            if (no.vn[i])
                vnames[[i]] <- namesi
            else vnames[[i]] <- paste(vnames[[i]], namesi, sep = ".")
        }
        else {
          ...
        }

I guess that (ncols[i] > 1L) test causes data.frame() to treat the
one-column case specially, and replacing it with (ncols[i] > 0L) would
create "A.x".

Acknowledging that data.frame() has legacy, is there any possibility
for updating this behavior?  Note that the current output is still
obtained if leaving out "A", i.e.

> data.frame(Y);
  x
1 1
2 2

/Henrik


From hb at biostat.ucsf.edu  Mon Jan 31 20:16:59 2011
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Mon, 31 Jan 2011 11:16:59 -0800
Subject: [Rd] str() on raster objects fails for certain dimensions
Message-ID: <AANLkTimycPK-3_mj5OPd0eLauAh41r2-Wkrp7j2jo1sw@mail.gmail.com>

Hi,

str() on raster objects fails for certain dimensions.  For example:

> str(as.raster(0, nrow=1, ncol=100))
 'raster' chr [1, 1:100] "#000000" "#000000" "#000000" "#000000" ...

> str(as.raster(0, nrow=1, ncol=101))
Error in `[.raster`(object, seq_len(max.len)) : subscript out of bounds

This seems to do with how str() and "[.raster"() is coded; when
subsetting as a vector, which str() relies on, "[.raster"() still
returns a matrix-like object, e.g.

> img <- as.raster(1:25, max=25, nrow=5, ncol=5);
> img[1:2]
     [,1]      [,2]      [,3]      [,4]      [,5]
[1,] "#0A0A0A" "#3D3D3D" "#707070" "#A3A3A3" "#D6D6D6"
[2,] "#141414" "#474747" "#7A7A7A" "#ADADAD" "#E0E0E0"

compare with:

> as.matrix(img)[1:2]
[1] "#0A0A0A" "#3D3D3D"


The easy but incomplete fix is to do:

str.raster <- function(object, ...) {
  str(as.matrix(object), ...);
}

Other suggestions?


> sessionInfo()
R version 2.13.0 Under development (unstable) (2011-01-27 r54129)
Platform: x86_64-pc-mingw32/x64 (64-bit)

locale:
[1] LC_COLLATE=English_United States.1252
[2] LC_CTYPE=English_United States.1252
[3] LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C
[5] LC_TIME=English_United States.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):

/Henrik


From ripley at stats.ox.ac.uk  Mon Jan 31 20:48:33 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 31 Jan 2011 19:48:33 +0000 (GMT)
Subject: [Rd] Warning: you may need to use R-patched with recent R distros
Message-ID: <alpine.LFD.2.02.1101311928400.30471@gannet.stats.ox.ac.uk>

Two things have emerged in testing on x86_64 Fedora 14 which mean that 
a recent R-patched is probably needed.

1) That OS uses zlib 1.2.5: that claims to be binary-compatible with 
zlib 1.2.3 but is not, as we found (painfully) on Windows.  The remedy 
was to remap _all_ the symbols in R's own copy of zlib (not just those 
zlib arranged to remap).

The symptoms were crashes using packages XML and rgoobi (both of which 
link to zlib) and incorrect results in RJaCGH (which contains a copy 
of zlib).  There may well be other problems ....

2)  Fedora 14 uses gcc 4.5.1. With CFLAGS containing the default -O2 
or higher, HAVE_C99_COMPLEX was detected as false because there is a 
(genuine) incompatibility between types Rcomplex and C99's double 
complex.  This means that R's fallback code is used, and regretably 
that contains a serious bug in an 'optimization' by a colleague, so 
z^n is incorrect for most complex z and integer n (and has been since 
2.10.0).  The remedy is to use R-patched or R-devel, or only optimize 
to -O.

We've also seen incorrect results from package mvtnorm when C 
optimization was -O3.

The upshot is that there is likely to be a 2.12.2 to fix these issues.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From Ken.Williams at thomsonreuters.com  Mon Jan 31 20:59:48 2011
From: Ken.Williams at thomsonreuters.com (Ken.Williams at thomsonreuters.com)
Date: Mon, 31 Jan 2011 13:59:48 -0600
Subject: [Rd] Warning: you may need to use R-patched with recent R
 distros
In-Reply-To: <alpine.LFD.2.02.1101311928400.30471@gannet.stats.ox.ac.uk>
Message-ID: <C96C7042.22581%ken.williams@thomsonreuters.com>

For the complex-numbers bug, do you know a reliable way (besides looking
at version numbers) to determine whether the bug is present or absent in a
given build?  

I don't know what version of gcc was used in my build nor the optimization
flags, so I did a few test exponentiations z^n and the results look okay,
but maybe I'm not tickling the right bits.


--
Ken Williams
Senior Research Scientist
Thomson Reuters
Phone: 651-848-7712
ken.williams at thomsonreuters.com
http://labs.thomsonreuters.com





On 1/31/11 1:48 PM, "Prof Brian Ripley" <ripley at stats.ox.ac.uk> wrote:

>Two things have emerged in testing on x86_64 Fedora 14 which mean that
>a recent R-patched is probably needed.
>
>1) That OS uses zlib 1.2.5: that claims to be binary-compatible with
>zlib 1.2.3 but is not, as we found (painfully) on Windows.  The remedy
>was to remap _all_ the symbols in R's own copy of zlib (not just those
>zlib arranged to remap).
>
>The symptoms were crashes using packages XML and rgoobi (both of which
>link to zlib) and incorrect results in RJaCGH (which contains a copy
>of zlib).  There may well be other problems ....
>
>2)  Fedora 14 uses gcc 4.5.1. With CFLAGS containing the default -O2
>or higher, HAVE_C99_COMPLEX was detected as false because there is a
>(genuine) incompatibility between types Rcomplex and C99's double
>complex.  This means that R's fallback code is used, and regretably
>that contains a serious bug in an 'optimization' by a colleague, so
>z^n is incorrect for most complex z and integer n (and has been since
>2.10.0).  The remedy is to use R-patched or R-devel, or only optimize
>to -O.
>
>We've also seen incorrect results from package mvtnorm when C
>optimization was -O3.
>
>The upshot is that there is likely to be a 2.12.2 to fix these issues.
>
>-- 
>Brian D. Ripley,                  ripley at stats.ox.ac.uk
>Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>University of Oxford,             Tel:  +44 1865 272861 (self)
>1 South Parks Road,                     +44 1865 272866 (PA)
>Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
>______________________________________________
>R-devel at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-devel
>


From ripley at stats.ox.ac.uk  Mon Jan 31 21:18:01 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 31 Jan 2011 20:18:01 +0000 (GMT)
Subject: [Rd] Warning: you may need to use R-patched with recent R
 distros
In-Reply-To: <C96C7042.22581%ken.williams@thomsonreuters.com>
References: <C96C7042.22581%ken.williams@thomsonreuters.com>
Message-ID: <alpine.LFD.2.02.1101312015170.18622@gannet.stats.ox.ac.uk>

On Mon, 31 Jan 2011, Ken.Williams at thomsonreuters.com wrote:

> For the complex-numbers bug, do you know a reliable way (besides looking
> at version numbers) to determine whether the bug is present or absent in a
> given build?

I know a way: See tests/complex.R in R-devel.

z <- 0.2853725+0.3927816i
z2 <- z^(1:20)
z3 <- z^-(1:20)
z0 <- cumprod(rep(z, 20))
stopifnot(all.equal(z2, z0), all.equal(z3, 1/z0))
## z^3 had value z^2 ....



>
> I don't know what version of gcc was used in my build nor the optimization
> flags, so I did a few test exponentiations z^n and the results look okay,
> but maybe I'm not tickling the right bits.
>
>
> --
> Ken Williams
> Senior Research Scientist
> Thomson Reuters
> Phone: 651-848-7712
> ken.williams at thomsonreuters.com
> http://labs.thomsonreuters.com
>
>
>
>
>
> On 1/31/11 1:48 PM, "Prof Brian Ripley" <ripley at stats.ox.ac.uk> wrote:
>
>> Two things have emerged in testing on x86_64 Fedora 14 which mean that
>> a recent R-patched is probably needed.
>>
>> 1) That OS uses zlib 1.2.5: that claims to be binary-compatible with
>> zlib 1.2.3 but is not, as we found (painfully) on Windows.  The remedy
>> was to remap _all_ the symbols in R's own copy of zlib (not just those
>> zlib arranged to remap).
>>
>> The symptoms were crashes using packages XML and rgoobi (both of which
>> link to zlib) and incorrect results in RJaCGH (which contains a copy
>> of zlib).  There may well be other problems ....
>>
>> 2)  Fedora 14 uses gcc 4.5.1. With CFLAGS containing the default -O2
>> or higher, HAVE_C99_COMPLEX was detected as false because there is a
>> (genuine) incompatibility between types Rcomplex and C99's double
>> complex.  This means that R's fallback code is used, and regretably
>> that contains a serious bug in an 'optimization' by a colleague, so
>> z^n is incorrect for most complex z and integer n (and has been since
>> 2.10.0).  The remedy is to use R-patched or R-devel, or only optimize
>> to -O.
>>
>> We've also seen incorrect results from package mvtnorm when C
>> optimization was -O3.
>>
>> The upshot is that there is likely to be a 2.12.2 to fix these issues.
>>
>> --
>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>> University of Oxford,             Tel:  +44 1865 272861 (self)
>> 1 South Parks Road,                     +44 1865 272866 (PA)
>> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


