From ripley at stats.ox.ac.uk  Mon Jan  2 15:57:51 2012
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 02 Jan 2012 14:57:51 +0000
Subject: [Rd] CRAN links are available again
In-Reply-To: <20223.8426.556399.538710@stat.math.ethz.ch>
References: <4EFE2E08.1070101@gmail.com> <4EFEAD54.1070301@stats.ox.ac.uk>
	<20222.61118.495992.777618@stat.math.ethz.ch>
	<20223.8426.556399.538710@stat.math.ethz.ch>
Message-ID: <4F01C5EF.2030505@stats.ox.ac.uk>

The CRAN master has now had web/packages recreated[*], and this should 
now propagate to the mirrors.

Recreating the summary area for dcens failed, but that package remains 
available via install.packages() (as packages have always been).

[*] Thanks to Stefan Theussl.

On 31/12/2011 14:49, Martin Maechler wrote:
>>>>>> Martin Maechler<maechler at stat.math.ethz.ch>
>>>>>>      on Sat, 31 Dec 2011 12:15:10 +0100 writes:
>
>>>>>> Prof Brian Ripley<ripley at stats.ox.ac.uk>
>>>>>>      on Sat, 31 Dec 2011 06:36:04 +0000 writes:
>
>      >>  This is not the CRAN webmaster's address[*], and the
>      >>  problem has been reported several times already to the
>      >>  proper places.  No one reading this list apart from the
>      >>  handful with CRAN administrator rights can do anything
>      >>  about this.
>
>      >>  The package repository is still there, and the check
>      >>  information is still up (via
>      >>  http://cran.r-project.org/web/checks/check_summary.html).
>      >>  The only thing that appears to be missing is the
>      >>  web-formatted summary information.  That is secondary
>      >>  information, and it looks like the web/packages area
>      >>  needs to be regenerated.
>
>      >>  My memory is that some of the mirrors do not auto-delete,
>      >>  and so will remain populated.  I believe
>      >>  http://stat.ethz.ch/CRAN/web/packages/ to be one of those
>      >>  and it looks intact.
>
>      >  Well, yes..  Actually, my mirroring script does
>      >  auto-deletion but "slowly": never more than a few hundred
>      >  files at a time (apart from the 'Recommended/'
>      >  subdirectories: There, it is important to delete, i.e.,
>      >  important to not have more than one version of a
>      >  recommended package .. for our tools/rsync-recommended
>      >  script )
>
> In the mean time, I have
>   - changed my mirror script to *NOT* delete anything for now
>   - rsync'ed (-u: do not overwrite newer)
>     a backup of web/packages/ from  2011-12-29 12:20:29
>
> This has recovered 76 Mega bytes already..
> Now indeed,  the CH mirror should contain a full web/packages/
> again,
> i.e. -->   http://cran.CH.r-project.org/web/packages/
> which is  http://stat.ethz.ch/CRAN/web/packages/
>
> should again be "fully loaded".
>
> Martin Maechler, ETH Zurich
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From lunds at iastate.edu  Tue Jan  3 00:16:29 2012
From: lunds at iastate.edu (Steven Lund)
Date: Mon, 2 Jan 2012 17:16:29 -0600
Subject: [Rd] How to list package dependency on a Bioconductor package?
Message-ID: <CAMe5z5nqAOk7hWXZ8ePs8XsPv=cSk8zO1vrm3doDZA4k+buhFQ@mail.gmail.com>

I know others have asked similar questions to the R developers, but I
could not find the solution to this question.  Please forgive me if I
have missed a crucial point in a previous post.

I would like to submit a package to CRAN that depends on the
bioconductor package "edgeR".  Listing "edgeR" under the Depends or
Imports lines in the DESCRIPTION file for my package causes an error
when running the `R CMD check' command on my package's 'tar.gz' file:

* checking package dependencies ... ERROR
Package required but not available: ?edgeR?

Is there documentation or an example anywhere of how to handle
dependencies on Bioconductor packages when creating a package for
CRAN?

Thank you!

-Steve


From ligges at statistik.tu-dortmund.de  Tue Jan  3 13:42:39 2012
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Tue, 3 Jan 2012 13:42:39 +0100
Subject: [Rd] How to list package dependency on a Bioconductor package?
In-Reply-To: <CAMe5z5nqAOk7hWXZ8ePs8XsPv=cSk8zO1vrm3doDZA4k+buhFQ@mail.gmail.com>
References: <CAMe5z5nqAOk7hWXZ8ePs8XsPv=cSk8zO1vrm3doDZA4k+buhFQ@mail.gmail.com>
Message-ID: <4F02F7BF.4040606@statistik.tu-dortmund.de>



On 03.01.2012 00:16, Steven Lund wrote:
> I know others have asked similar questions to the R developers, but I
> could not find the solution to this question.  Please forgive me if I
> have missed a crucial point in a previous post.
>
> I would like to submit a package to CRAN that depends on the
> bioconductor package "edgeR".  Listing "edgeR" under the Depends or
> Imports lines in the DESCRIPTION file for my package causes an error
> when running the `R CMD check' command on my package's 'tar.gz' file:
>
> * checking package dependencies ... ERROR
> Package required but not available: ?edgeR?
>
> Is there documentation or an example anywhere of how to handle
> dependencies on Bioconductor packages when creating a package for
> CRAN?


Same as for CRAN packages. The CRAN check farm will automatically 
install the dependency from BioConductor if available for the 
corresponding platform / R version.

Uwe Ligges




>
> Thank you!
>
> -Steve
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From pauljohn32 at gmail.com  Tue Jan  3 21:08:14 2012
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Tue, 3 Jan 2012 14:08:14 -0600
Subject: [Rd] returning information from functions via attributes rather
 than return list
Message-ID: <CAErODj8GiAnVbirM5JtdFAOBqPrqa+XcEagy5RYRhofdqrQ+QA@mail.gmail.com>

I would like to ask for advice from R experts about the benefits or
dangers of using attr to return information with an object that is
returned from a function. I have a feeling as though I have cheated by
using attributes, and wonder if I've done something fishy.

Maybe I mean to ask, where is the dividing line between attributes and
instance variables?  The separation is not clear in my mind anymore.

Background: I paste below a function that takes in a regression object
and make changes to the data and/or call and then run a
revised regression.  In my earlier effort, I was building a return
list, including the new fitted regression object plus some
variables that have information about the changes that a were made.

That creates some inconvenience, however.  When the regression is in a
list object, then methods for lm objects don't apply to that result
object. The return is not an lm anymore.  I either need to write
custom methods for every function or remember to extract the object
from the list before sending to the generic function.

I *guessed* it would work to write the new information as object
attributes, and it seems to work. There is a generic function
"meanCenter" and a method "meanCenter.default". At the end of
meanCenter.default, here's my use (or abuse) of attributes.

  res <- eval(mc)
  class(res) <- c("mcreg", class(model))
  attr(res, "centeredVars") <- nc
  attr(res, "centerCall") <-  match.call()
  res

I wrote print and summary methods, but other methods that work for lm
objects like plot will also work for these new ones.



meanCenter <- function(model, centerOnlyInteractors=TRUE,
centerDV=FALSE, standardize=FALSE, centerContrasts = F){
  UseMethod("meanCenter")
}

meanCenter.default <- function(model, centerOnlyInteractors=TRUE,
centerDV=FALSE, standardize=FALSE, centerContrasts = F){

  std <- function(x) {
    if( !is.numeric(x) ){
      stop("center.lm tried to center a factor variable. No Can Do!")
    } else {
      scale(x, center = TRUE, scale = standardize)
    }
  }

  rdf <- get_all_vars(formula(model), model$model) #raw data frame
  t <- terms(model)
  tl <- attr(t, "term.labels")
  tmdc <- attr(t, "dataClasses") ##term model data classes

  isNumeric <- names(tmdc)[ which(tmdc %in% c("numeric"))]
  isFac <-  names(tmdc)[ which(tmdc %in% c("factor"))]
  if (tmdc[1] != "numeric") stop("Sorry, DV not a single numeric column")

  ##Build "nc", a vector of variable names that "need centering"
  ##
  if (!centerDV) {
    if (centerOnlyInteractors == FALSE){
      nc <- isNumeric[-1] #-1 excludes response
      unique(nc)
    }else{
      interactTerms <- tl[grep(":", tl)]
      nc <- unique(unlist(strsplit( interactTerms, ":")))
      nc <-  nc[which(nc %in% isNumeric)]
    }
  }else{
    if (centerOnlyInteractors == FALSE){
      nc <- isNumeric
    }else{
      interactTerms <- tl[grep(":", tl)]
      nc <- unique(unlist(strsplit( interactTerms, ":")))
      nc <- nc[which(nc %in% isNumeric)]
      nc <- c( names(tmdc)[1] , nc)
    }
  }


  mc <- model$call
  # run same model call, replacing non centered data with centered data.
  ## if no need to center factor contrasts:
  if (!centerContrasts)
    {
      stddat <- rdf
      for (i in nc) stddat[ , i] <- std( stddat[, i])
      mc$data <- quote(stddat)
    }else{
      ##dm: design matrix, only includes intercept and predictors
      dm <- model.matrix(model, data=rdf, contrasts.arg =
model$contrasts, xlev = model$xlevels)
      ##contrastIdx: indexes of contrast variables in dm
      contrastIdx <- which(attr(dm, "assign")== match(isFac, tl))
      contrastVars <- colnames(dm)[contrastIdx]
      nc <- c(nc, contrastVars)

      dm <- as.data.frame(dm)

      hasIntercept <- attr(t, "intercept")
      if (hasIntercept) dm <- dm[ , -1] # removes intercept, column 1

      dv <- rdf[ ,names(tmdc)[1]] #tmdc[1] is response variable name
      dm <- cbind(dv, dm)
      colnames(dm)[1] <- names(tmdc)[1] #put colname for dv

      dmnames <- colnames(dm)
      hasColon <- dmnames[grep(":", dmnames)]
      dm <- dm[ , -match(hasColon, dmnames)] ##remove vars with colons
(lm will recreate)

      ##Now, standardise the variables that need standardizing
      for (i in nc) dm[ , i] <- std( dm[, i])


      fmla <- formula(paste(dmnames[1], " ~ ",  paste(dmnames[-1],
collapse=" + ")))
      cat("This fitted model will use those centered variables\n")
      cat("Model-constructed interactions such as \"x1:x3\" are built
from centered variables\n")
      mc$formula <- formula(fmla)
      mc$data <-  quote(dm)
    }

  cat("These variables", nc, "Are centered in the design matrix \n")

  res <- eval(mc)
  class(res) <- c("mcreg", class(model))
  attr(res, "centeredVars") <- nc
  attr(res, "centerCall") <-  match.call()
  res
}

summary.mcreg <- function(object, ...){
  nc <- attr(object, "centeredVars")
  cat("The centered variables were: \n")
  print(nc)
  cat("Even though the variables here have the same names as their
non-centered counterparts, I assure you these are centered.\n")
  mc <- attr(object, "centerCall")
  cat("These results were produced from: \n")
  print(mc)
  NextMethod(generic = "summary", object = object, ...)
}


print.mcreg <- function(x, ...){
  nc <- attr(x, "centeredVars")
  cat("The centered variables were: \n")
  print(nc)
  cat("Even though the variables here have the same names as their
non-centered counterparts, I assure you these are centered.\n")
  mc <- attr(x, "centerCall")
  cat("These results were produced from: \n")
  print(mc)
  NextMethod(generic = "print", object = x, ...)
}


-- 
Paul E. Johnson
Professor, Political Science
1541 Lilac Lane, Room 504
University of Kansas


From simon.urbanek at r-project.org  Tue Jan  3 22:59:24 2012
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Tue, 3 Jan 2012 16:59:24 -0500
Subject: [Rd] returning information from functions via attributes rather
	than return list
In-Reply-To: <CAErODj8GiAnVbirM5JtdFAOBqPrqa+XcEagy5RYRhofdqrQ+QA@mail.gmail.com>
References: <CAErODj8GiAnVbirM5JtdFAOBqPrqa+XcEagy5RYRhofdqrQ+QA@mail.gmail.com>
Message-ID: <B12E72A9-7A9F-467E-822C-737561B3B06D@r-project.org>

Paul,

On Jan 3, 2012, at 3:08 PM, Paul Johnson wrote:

> I would like to ask for advice from R experts about the benefits or
> dangers of using attr to return information with an object that is
> returned from a function. I have a feeling as though I have cheated by
> using attributes, and wonder if I've done something fishy.
> 
> Maybe I mean to ask, where is the dividing line between attributes and
> instance variables?  The separation is not clear in my mind anymore.
> 
> Background: I paste below a function that takes in a regression object
> and make changes to the data and/or call and then run a
> revised regression.  In my earlier effort, I was building a return
> list, including the new fitted regression object plus some
> variables that have information about the changes that a were made.
> 
> That creates some inconvenience, however.  When the regression is in a
> list object, then methods for lm objects don't apply to that result
> object. The return is not an lm anymore.

Why don't you just subclass it? That's the "normal" way of doing things - you simply add additional entries for your subclass (e.g. m$myItem1, m$myItem2, ...), prepend your new subclass name and you're done. You can still dispatch on your subclass before the superclass while superclass methods just work as well..

Cheers,
Simon


>  I either need to write
> custom methods for every function or remember to extract the object
> from the list before sending to the generic function.
> 
> I *guessed* it would work to write the new information as object
> attributes, and it seems to work. There is a generic function
> "meanCenter" and a method "meanCenter.default". At the end of
> meanCenter.default, here's my use (or abuse) of attributes.
> 
>  res <- eval(mc)
>  class(res) <- c("mcreg", class(model))
>  attr(res, "centeredVars") <- nc
>  attr(res, "centerCall") <-  match.call()
>  res
> 
> I wrote print and summary methods, but other methods that work for lm
> objects like plot will also work for these new ones.
> 
> 
> 
> meanCenter <- function(model, centerOnlyInteractors=TRUE,
> centerDV=FALSE, standardize=FALSE, centerContrasts = F){
>  UseMethod("meanCenter")
> }
> 
> meanCenter.default <- function(model, centerOnlyInteractors=TRUE,
> centerDV=FALSE, standardize=FALSE, centerContrasts = F){
> 
>  std <- function(x) {
>    if( !is.numeric(x) ){
>      stop("center.lm tried to center a factor variable. No Can Do!")
>    } else {
>      scale(x, center = TRUE, scale = standardize)
>    }
>  }
> 
>  rdf <- get_all_vars(formula(model), model$model) #raw data frame
>  t <- terms(model)
>  tl <- attr(t, "term.labels")
>  tmdc <- attr(t, "dataClasses") ##term model data classes
> 
>  isNumeric <- names(tmdc)[ which(tmdc %in% c("numeric"))]
>  isFac <-  names(tmdc)[ which(tmdc %in% c("factor"))]
>  if (tmdc[1] != "numeric") stop("Sorry, DV not a single numeric column")
> 
>  ##Build "nc", a vector of variable names that "need centering"
>  ##
>  if (!centerDV) {
>    if (centerOnlyInteractors == FALSE){
>      nc <- isNumeric[-1] #-1 excludes response
>      unique(nc)
>    }else{
>      interactTerms <- tl[grep(":", tl)]
>      nc <- unique(unlist(strsplit( interactTerms, ":")))
>      nc <-  nc[which(nc %in% isNumeric)]
>    }
>  }else{
>    if (centerOnlyInteractors == FALSE){
>      nc <- isNumeric
>    }else{
>      interactTerms <- tl[grep(":", tl)]
>      nc <- unique(unlist(strsplit( interactTerms, ":")))
>      nc <- nc[which(nc %in% isNumeric)]
>      nc <- c( names(tmdc)[1] , nc)
>    }
>  }
> 
> 
>  mc <- model$call
>  # run same model call, replacing non centered data with centered data.
>  ## if no need to center factor contrasts:
>  if (!centerContrasts)
>    {
>      stddat <- rdf
>      for (i in nc) stddat[ , i] <- std( stddat[, i])
>      mc$data <- quote(stddat)
>    }else{
>      ##dm: design matrix, only includes intercept and predictors
>      dm <- model.matrix(model, data=rdf, contrasts.arg =
> model$contrasts, xlev = model$xlevels)
>      ##contrastIdx: indexes of contrast variables in dm
>      contrastIdx <- which(attr(dm, "assign")== match(isFac, tl))
>      contrastVars <- colnames(dm)[contrastIdx]
>      nc <- c(nc, contrastVars)
> 
>      dm <- as.data.frame(dm)
> 
>      hasIntercept <- attr(t, "intercept")
>      if (hasIntercept) dm <- dm[ , -1] # removes intercept, column 1
> 
>      dv <- rdf[ ,names(tmdc)[1]] #tmdc[1] is response variable name
>      dm <- cbind(dv, dm)
>      colnames(dm)[1] <- names(tmdc)[1] #put colname for dv
> 
>      dmnames <- colnames(dm)
>      hasColon <- dmnames[grep(":", dmnames)]
>      dm <- dm[ , -match(hasColon, dmnames)] ##remove vars with colons
> (lm will recreate)
> 
>      ##Now, standardise the variables that need standardizing
>      for (i in nc) dm[ , i] <- std( dm[, i])
> 
> 
>      fmla <- formula(paste(dmnames[1], " ~ ",  paste(dmnames[-1],
> collapse=" + ")))
>      cat("This fitted model will use those centered variables\n")
>      cat("Model-constructed interactions such as \"x1:x3\" are built
> from centered variables\n")
>      mc$formula <- formula(fmla)
>      mc$data <-  quote(dm)
>    }
> 
>  cat("These variables", nc, "Are centered in the design matrix \n")
> 
>  res <- eval(mc)
>  class(res) <- c("mcreg", class(model))
>  attr(res, "centeredVars") <- nc
>  attr(res, "centerCall") <-  match.call()
>  res
> }
> 
> summary.mcreg <- function(object, ...){
>  nc <- attr(object, "centeredVars")
>  cat("The centered variables were: \n")
>  print(nc)
>  cat("Even though the variables here have the same names as their
> non-centered counterparts, I assure you these are centered.\n")
>  mc <- attr(object, "centerCall")
>  cat("These results were produced from: \n")
>  print(mc)
>  NextMethod(generic = "summary", object = object, ...)
> }
> 
> 
> print.mcreg <- function(x, ...){
>  nc <- attr(x, "centeredVars")
>  cat("The centered variables were: \n")
>  print(nc)
>  cat("Even though the variables here have the same names as their
> non-centered counterparts, I assure you these are centered.\n")
>  mc <- attr(x, "centerCall")
>  cat("These results were produced from: \n")
>  print(mc)
>  NextMethod(generic = "print", object = x, ...)
> }
> 
> 
> -- 
> Paul E. Johnson
> Professor, Political Science
> 1541 Lilac Lane, Room 504
> University of Kansas
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From rdxcheena at gmail.com  Wed Jan  4 10:57:15 2012
From: rdxcheena at gmail.com (rdxcheena)
Date: Wed, 4 Jan 2012 01:57:15 -0800 (PST)
Subject: [Rd] rmpi vs snow - which one is better from communication overhead
 point of view
Message-ID: <1325671035717-4260660.post@n4.nabble.com>

Hi,

I need to understand when is it best to use /rmpi/ and when is it best to
use /snow/ for parallel programming in R? I understand snow can be used for
a group of non-clustered work stations also. But I wish to understand from
the point of view of using both on clusters for a problem which has few
chunks of straightforward data-parallelism interleaved with some
communication. Since both are based on /mpi/, which one provides better
performance for same kind of communication? Can I do explicit send, receive,
broadcast, etc with snow?

Also, if I use /foreach/ on either of these, does this add further overhead?

Please help me understand the difference in the provisions of the two and
select one of them for my current and future projects.

Thanks a lot in advance.

Best,

Aditi

--
View this message in context: http://r.789695.n4.nabble.com/rmpi-vs-snow-which-one-is-better-from-communication-overhead-point-of-view-tp4260660p4260660.html
Sent from the R devel mailing list archive at Nabble.com.


From manuel.lopez-ibanez at ulb.ac.be  Wed Jan  4 12:59:58 2012
From: manuel.lopez-ibanez at ulb.ac.be (=?ISO-8859-1?Q?Manuel_L=F3pez-Ib=E1=F1ez?=)
Date: Wed, 04 Jan 2012 12:59:58 +0100
Subject: [Rd] [ping] fix type explanation in plot.default
Message-ID: <4F043F3E.6050008@ulb.ac.be>

Dear R-devel,

I sent this in December, but I didn't get any answer...

The explanation of the 'type' parameter of plot.default is a bit confusing, 
plus the stray closing parenthesis. I suggest the following small change to 
match the one given in plot. Feel free to adjust at your convenience.

Apply to http://svn.r-project.org/R/trunk/src/library/graphics/man/plot.default.Rd

Cheers,
	Manuel.




-------------- next part --------------
A non-text attachment was scrubbed...
Name: plot.default.Rd.patch
Type: text/x-diff
Size: 721 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20120104/68399155/attachment.bin>

From stephen.b.weston at gmail.com  Wed Jan  4 14:55:14 2012
From: stephen.b.weston at gmail.com (Stephen Weston)
Date: Wed, 4 Jan 2012 08:55:14 -0500
Subject: [Rd] rmpi vs snow - which one is better from communication
 overhead point of view
In-Reply-To: <1325671035717-4260660.post@n4.nabble.com>
References: <1325671035717-4260660.post@n4.nabble.com>
Message-ID: <CALh21i+xDGp96RB9WQyDAiWcP5pFsMALd2dGHW8CF+LeuN+P8w@mail.gmail.com>

On Wed, Jan 4, 2012 at 4:57 AM, rdxcheena <rdxcheena at gmail.com> wrote:
> Hi,
>
> I need to understand when is it best to use /rmpi/ and when is it best to
> use /snow/ for parallel programming in R? I understand snow can be used for
> a group of non-clustered work stations also. But I wish to understand from
> the point of view of using both on clusters for a problem which has few
> chunks of straightforward data-parallelism interleaved with some
> communication. Since both are based on /mpi/, which one provides better
> performance for same kind of communication? Can I do explicit send, receive,

Snow uses MPI via the Rmpi package, so you can always write equivalent
code in Rmpi that is at least as fast as snow.  You might want to read the
paper "State of the Art in Parallel Computing with R" by Markus Schmidberger,
Martin Morgan, Dirk Eddelbuettel, Hao Yu, Luke Tierney, and Ulrich
Mansmann for a more information on that subject.

> broadcast, etc with snow?

Snow doesn't provide any explicit communication operations, unless you
count clusterExport.

> Also, if I use /foreach/ on either of these, does this add further overhead?

Yes, foreach will definitely add overhead, and it doesn't give you access to
explicit communication either.

> Please help me understand the difference in the provisions of the two and
> select one of them for my current and future projects.

If you're primarily interested in performance, you should almost certainly
pick Rmpi.  And if you want to perform explicit MPI communication, such as
broadcasting, it's your only choice as far as I know.

- Steve


From mxkuhn at gmail.com  Wed Jan  4 15:19:11 2012
From: mxkuhn at gmail.com (Max Kuhn)
Date: Wed, 4 Jan 2012 09:19:11 -0500
Subject: [Rd] informal conventions/checklist for new predictive modeling
	packages
Message-ID: <CAJ9CoWkE-suPfebAs5K9jnBJ7epj4RRBLNAOiAExWWwP5QLnKw@mail.gmail.com>

Working on the caret package has exposed me to the wide variety of
approaches that different authors have taken to creating predictive
modeling functions (aka machine learning)(aka pattern recognition).

I suspect that many package authors are neophyte R users and are
stumbling through the process of writing their first R package (or R
code). As such, they may not have been exposed to some of the informal
conventions that have evolved over time. Also, their package may be
intended to demonstrate their research and not for "production"
modeling. In any case, it might be a good idea to print up a few
points for consideration when creating a predictive modeling package.
I don't propose changes to existing code.

Some of this is obvious and not limited to this class of modeling
packages. Many of these points are arguable, so please do so.

If this seems useful, perhaps we could repost the final list to R-Help
to use as a checklist.

Those of you who have used my code will probably realize that I am not
a grand architect of R packages =] I'd love to get feedback from those
of you with a broader perspective and better software engineering
skills than I (a low bar to step over).

I have marked a few of these items with an OCD tag since I might be
taking it a bit too far.

The list:

(1) Extend the work of others. There is an amazing amount of unneeded
redundancy. There are plenty of times that users implement their own
version of a function because there is an missing feature, but a lot
of time is spent re-creating duplicate functions. For example, kernlab
has an excellent set of kernel functions that are really efficient and
have useful ancillary functions. People may not new aware of these
functions, but they are one RSiteSearch away. (Perhaps we could
nominate a few packages like kernlab that implement a specific tool
well)

(2) When modeling a categorical outcome, use a factor as input (as
opposed to 0/1 indicators or integers). Factors are exactly the kind
of feature that separates R from other languages (I'm looking at you
SAS) and is a natural structure for this data type.

corollary (2a): save the factor levels in the model object somewhere

corollary (2b): return predicted classes as factors with the same
levels (and ordering of levels).

(3) Implement a separate prediction function. Some packages only make
predictions when the model is built, so effectively the model cannot
be used at any point in the future.

corollary (3a): use object-orientation (eg. predict.{class}) and not
some made-up function name "modelPredict()" for predicting new
samples.

(4) If the method only accepts a specific type of input (eg. matrix or
data frame), please do the conversion whenever appropriate.

(5) Provide a formula interface (eg. foo(y~x, data = dat)) and
non-formula interface (foo(x, y) to the function. Formula methods are
really inefficient at this time for large dimensional data but are
fantastically convenient. There are some good reasons to not use
formulas, such as functions that do not use a design matrix (eg.
cforest()) or need factors to be handled in a non-standard way (eg.
cubist()).

(6) Don't require a test set when model building.

(7) Control all written output during model-building time with a
verbose option. Resampling can make a mess out of things if
output/logging is always exposed.

(8) Please use RSiteSearch to avoid name collisions between packages
(eg. gam(), splsda(), roc(), LogitBoost()). Also search Bioconductor.

(9) Allow the predict function to generate results from many different
sub-models simultaneously. For example, pls() can return predictions
across many values of ncomp. enet(), cubist(), blackboost() are other
examples.

corollary (9a): [OCD] ensure the same object type for predictions.
There are occasions where predict() will return a vector or a matrix
depending on the context. I would argue that this is not optimal.

(10) Use a limited vocabulary for options. For example, some predict()
functions have a "type" options to switch between predicted classes
and class probabilities. Values of "type" pertaining to class
probabilities range from "prob", "probability", "posterior", "raw",
"response", etc. I'll make a suggestion of "prob" as a possible
standard for this situation.

(11) Make sure that class probabilities sum to one. Seriously.

(12) If the model implicitly conducts feature selection, do not
require un-used predictors to be present in future data sets for
prediction. This may be a problem when the formula interface to models
is used, but it looks like many functions reference columns by
position and not name.

(13) Packages that have their own cross-validation functions should
allow the users to pass in the specific folds/resamping indicators to
maintain consistency across similar functions in other packages.

(14) [OCD] For binary classification models, model the probability of
the first level of a factor as the event of interest (again, for
consistency) Note that glm() does not do this but most others use the
first level.

Thanks,

Max


From murdoch.duncan at gmail.com  Wed Jan  4 15:23:45 2012
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 04 Jan 2012 09:23:45 -0500
Subject: [Rd] [ping] fix type explanation in plot.default
In-Reply-To: <4F043F3E.6050008@ulb.ac.be>
References: <4F043F3E.6050008@ulb.ac.be>
Message-ID: <4F0460F1.9090901@gmail.com>

On 04/01/2012 6:59 AM, Manuel L?pez-Ib??ez wrote:
> Dear R-devel,
>
> I sent this in December, but I didn't get any answer...
>
> The explanation of the 'type' parameter of plot.default is a bit confusing,
> plus the stray closing parenthesis. I suggest the following small change to
> match the one given in plot. Feel free to adjust at your convenience.
>
> Apply to http://svn.r-project.org/R/trunk/src/library/graphics/man/plot.default.Rd

thanks, will fix.

Duncan Murdoch


From pauljohn32 at gmail.com  Wed Jan  4 21:19:44 2012
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Wed, 4 Jan 2012 14:19:44 -0600
Subject: [Rd] returning information from functions via attributes rather
 than return list
In-Reply-To: <B12E72A9-7A9F-467E-822C-737561B3B06D@r-project.org>
References: <CAErODj8GiAnVbirM5JtdFAOBqPrqa+XcEagy5RYRhofdqrQ+QA@mail.gmail.com>
	<B12E72A9-7A9F-467E-822C-737561B3B06D@r-project.org>
Message-ID: <CAErODj_-HYuF-hamKQcr-p0zg-sqPmoargu88s+oGMaLsJwWDg@mail.gmail.com>

On Tue, Jan 3, 2012 at 3:59 PM, Simon Urbanek
<simon.urbanek at r-project.org> wrote:
> Paul,
>
> On Jan 3, 2012, at 3:08 PM, Paul Johnson wrote:
>
>> I would like to ask for advice from R experts about the benefits or
>> dangers of using attr to return information with an object that is
>> returned from a function. I have a feeling as though I have cheated by
>> using attributes, and wonder if I've done something fishy.
>>
>> Maybe I mean to ask, where is the dividing line between attributes and
>> instance variables? ?The separation is not clear in my mind anymore.
>>
>> Background: I paste below a function that takes in a regression object
>> and make changes to the data and/or call and then run a
>> revised regression. ?In my earlier effort, I was building a return
>> list, including the new fitted regression object plus some
>> variables that have information about the changes that a were made.
>>
>> That creates some inconvenience, however. ?When the regression is in a
>> list object, then methods for lm objects don't apply to that result
>> object. The return is not an lm anymore.
>
> Why don't you just subclass it? That's the "normal" way of doing things - you simply add additional entries for your subclass (e.g. m$myItem1, m$myItem2, ...), prepend your new subclass name and you're done. You can still dispatch on your subclass before the superclass while superclass methods just work as well..
>
> Cheers,
> Simon
>

Yes. I see that now.

But I'm still wondering about the attribute versus variable question.
To the programmer, is there any difference between returning
information as attributes or variables?

Does R care if I do this:

class(res) <- c("mcreg", "lm")
attr(res, "centeredVars") <- nc

Or this:

class(res) <- c("mcreg", "lm")
res$centeredVars <- nc

Is there some place "down there," in the C foundations of R,  where an
attribute is just a variable, as is centeredVars?

pj

-- 
Paul E. Johnson
Professor, Political Science
1541 Lilac Lane, Room 504
University of Kansas


From murdoch.duncan at gmail.com  Wed Jan  4 22:23:42 2012
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 04 Jan 2012 16:23:42 -0500
Subject: [Rd] returning information from functions via attributes rather
 than return list
In-Reply-To: <CAErODj_-HYuF-hamKQcr-p0zg-sqPmoargu88s+oGMaLsJwWDg@mail.gmail.com>
References: <CAErODj8GiAnVbirM5JtdFAOBqPrqa+XcEagy5RYRhofdqrQ+QA@mail.gmail.com>
	<B12E72A9-7A9F-467E-822C-737561B3B06D@r-project.org>
	<CAErODj_-HYuF-hamKQcr-p0zg-sqPmoargu88s+oGMaLsJwWDg@mail.gmail.com>
Message-ID: <4F04C35E.1090401@gmail.com>

On 12-01-04 3:19 PM, Paul Johnson wrote:
> On Tue, Jan 3, 2012 at 3:59 PM, Simon Urbanek
> <simon.urbanek at r-project.org>  wrote:
>> Paul,
>>
>> On Jan 3, 2012, at 3:08 PM, Paul Johnson wrote:
>>
>>> I would like to ask for advice from R experts about the benefits or
>>> dangers of using attr to return information with an object that is
>>> returned from a function. I have a feeling as though I have cheated by
>>> using attributes, and wonder if I've done something fishy.
>>>
>>> Maybe I mean to ask, where is the dividing line between attributes and
>>> instance variables?  The separation is not clear in my mind anymore.
>>>
>>> Background: I paste below a function that takes in a regression object
>>> and make changes to the data and/or call and then run a
>>> revised regression.  In my earlier effort, I was building a return
>>> list, including the new fitted regression object plus some
>>> variables that have information about the changes that a were made.
>>>
>>> That creates some inconvenience, however.  When the regression is in a
>>> list object, then methods for lm objects don't apply to that result
>>> object. The return is not an lm anymore.
>>
>> Why don't you just subclass it? That's the "normal" way of doing things - you simply add additional entries for your subclass (e.g. m$myItem1, m$myItem2, ...), prepend your new subclass name and you're done. You can still dispatch on your subclass before the superclass while superclass methods just work as well..
>>
>> Cheers,
>> Simon
>>
>
> Yes. I see that now.
>
> But I'm still wondering about the attribute versus variable question.
> To the programmer, is there any difference between returning
> information as attributes or variables?
>
> Does R care if I do this:
>
> class(res)<- c("mcreg", "lm")
> attr(res, "centeredVars")<- nc
>
> Or this:
>
> class(res)<- c("mcreg", "lm")
> res$centeredVars<- nc
>
> Is there some place "down there," in the C foundations of R,  where an
> attribute is just a variable, as is centeredVars?

Yes, the internal implementation is different (res$centeredVars implies 
res is a list, but attributes are stored as a pairlist).  But the thing 
itself (your nc) can't tell where it is stored.

Attributes are slightly harder to work with, so Simon's recommendation 
is good advice.  But in cases where you want other functions to work 
with the result, and the result isn't a named list with a class, then 
attributes are a convenient way to go.

The only two snags I can think of are 1, that R uses a few attributes 
for its own purposes (e.g. "names", "dim" and "dimnames") and if you use 
those attribute names for something incompatible you'll probably run 
into all sorts of problems and 2, that S4 objects use attributes 
internally.  I wouldn't recommend using attributes on an S4 object.

Duncan Murdoch


From hadley at rice.edu  Thu Jan  5 00:31:56 2012
From: hadley at rice.edu (Hadley Wickham)
Date: Wed, 4 Jan 2012 17:31:56 -0600
Subject: [Rd] returning information from functions via attributes rather
 than return list
In-Reply-To: <4F04C35E.1090401@gmail.com>
References: <CAErODj8GiAnVbirM5JtdFAOBqPrqa+XcEagy5RYRhofdqrQ+QA@mail.gmail.com>
	<B12E72A9-7A9F-467E-822C-737561B3B06D@r-project.org>
	<CAErODj_-HYuF-hamKQcr-p0zg-sqPmoargu88s+oGMaLsJwWDg@mail.gmail.com>
	<4F04C35E.1090401@gmail.com>
Message-ID: <CABdHhvFRzfVHGjCdL58YDADupj9vCX0Of3u2gvqJEx9OzdWL8g@mail.gmail.com>

> Attributes are slightly harder to work with, so Simon's recommendation is
> good advice. ?But in cases where you want other functions to work with the
> result, and the result isn't a named list with a class, then attributes are
> a convenient way to go.
>
> The only two snags I can think of are 1, that R uses a few attributes for
> its own purposes (e.g. "names", "dim" and "dimnames") and if you use those
> attribute names for something incompatible you'll probably run into all
> sorts of problems and 2, that S4 objects use attributes internally. ?I
> wouldn't recommend using attributes on an S4 object.

Attributes are also useful when you're extending a atomic vector, and
want to be able to store objects of your new class inside data frames
etc.

Hadley

-- 
Assistant Professor / Dobelman Family Junior Chair
Department of Statistics / Rice University
http://had.co.nz/


From andy_liaw at merck.com  Thu Jan  5 14:34:35 2012
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 5 Jan 2012 08:34:35 -0500
Subject: [Rd] informal conventions/checklist for new predictive
	modeling	packages
In-Reply-To: <CAJ9CoWkE-suPfebAs5K9jnBJ7epj4RRBLNAOiAExWWwP5QLnKw@mail.gmail.com>
References: <CAJ9CoWkE-suPfebAs5K9jnBJ7epj4RRBLNAOiAExWWwP5QLnKw@mail.gmail.com>
Message-ID: <D5FA03935F7418419332B61CA255F65F5E85C337B6@USCTMXP51012.merck.com>

From: Max Kuhn
> 
> Working on the caret package has exposed me to the wide variety of
> approaches that different authors have taken to creating predictive
> modeling functions (aka machine learning)(aka pattern recognition).
> 
> I suspect that many package authors are neophyte R users and are
> stumbling through the process of writing their first R package (or R
> code). As such, they may not have been exposed to some of the informal
> conventions that have evolved over time. Also, their package may be
> intended to demonstrate their research and not for "production"
> modeling. In any case, it might be a good idea to print up a few
> points for consideration when creating a predictive modeling package.
> I don't propose changes to existing code.
> 
> Some of this is obvious and not limited to this class of modeling
> packages. Many of these points are arguable, so please do so.
> 
> If this seems useful, perhaps we could repost the final list to R-Help
> to use as a checklist.

I think this is great, Max!  May I suggest that a "standard" be put together
(with concensus of many ML package authors), and packages that conform to
the standard are marked as such in the ML task view?

Andy


> Those of you who have used my code will probably realize that I am not
> a grand architect of R packages =] I'd love to get feedback from those
> of you with a broader perspective and better software engineering
> skills than I (a low bar to step over).
> 
> I have marked a few of these items with an OCD tag since I might be
> taking it a bit too far.
> 
> The list:
> 
> (1) Extend the work of others. There is an amazing amount of unneeded
> redundancy. There are plenty of times that users implement their own
> version of a function because there is an missing feature, but a lot
> of time is spent re-creating duplicate functions. For example, kernlab
> has an excellent set of kernel functions that are really efficient and
> have useful ancillary functions. People may not new aware of these
> functions, but they are one RSiteSearch away. (Perhaps we could
> nominate a few packages like kernlab that implement a specific tool
> well)
> 
> (2) When modeling a categorical outcome, use a factor as input (as
> opposed to 0/1 indicators or integers). Factors are exactly the kind
> of feature that separates R from other languages (I'm looking at you
> SAS) and is a natural structure for this data type.
> 
> corollary (2a): save the factor levels in the model object somewhere
> 
> corollary (2b): return predicted classes as factors with the same
> levels (and ordering of levels).
> 
> (3) Implement a separate prediction function. Some packages only make
> predictions when the model is built, so effectively the model cannot
> be used at any point in the future.
> 
> corollary (3a): use object-orientation (eg. predict.{class}) and not
> some made-up function name "modelPredict()" for predicting new
> samples.
> 
> (4) If the method only accepts a specific type of input (eg. matrix or
> data frame), please do the conversion whenever appropriate.
> 
> (5) Provide a formula interface (eg. foo(y~x, data = dat)) and
> non-formula interface (foo(x, y) to the function. Formula methods are
> really inefficient at this time for large dimensional data but are
> fantastically convenient. There are some good reasons to not use
> formulas, such as functions that do not use a design matrix (eg.
> cforest()) or need factors to be handled in a non-standard way (eg.
> cubist()).
> 
> (6) Don't require a test set when model building.
> 
> (7) Control all written output during model-building time with a
> verbose option. Resampling can make a mess out of things if
> output/logging is always exposed.
> 
> (8) Please use RSiteSearch to avoid name collisions between packages
> (eg. gam(), splsda(), roc(), LogitBoost()). Also search Bioconductor.
> 
> (9) Allow the predict function to generate results from many different
> sub-models simultaneously. For example, pls() can return predictions
> across many values of ncomp. enet(), cubist(), blackboost() are other
> examples.
> 
> corollary (9a): [OCD] ensure the same object type for predictions.
> There are occasions where predict() will return a vector or a matrix
> depending on the context. I would argue that this is not optimal.
> 
> (10) Use a limited vocabulary for options. For example, some predict()
> functions have a "type" options to switch between predicted classes
> and class probabilities. Values of "type" pertaining to class
> probabilities range from "prob", "probability", "posterior", "raw",
> "response", etc. I'll make a suggestion of "prob" as a possible
> standard for this situation.
> 
> (11) Make sure that class probabilities sum to one. Seriously.
> 
> (12) If the model implicitly conducts feature selection, do not
> require un-used predictors to be present in future data sets for
> prediction. This may be a problem when the formula interface to models
> is used, but it looks like many functions reference columns by
> position and not name.
> 
> (13) Packages that have their own cross-validation functions should
> allow the users to pass in the specific folds/resamping indicators to
> maintain consistency across similar functions in other packages.
> 
> (14) [OCD] For binary classification models, model the probability of
> the first level of a factor as the event of interest (again, for
> consistency) Note that glm() does not do this but most others use the
> first level.
> 
> Thanks,
> 
> Max
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
Notice:  This e-mail message, together with any attachme...{{dropped:11}}


From mailinglist.honeypot at gmail.com  Thu Jan  5 16:16:54 2012
From: mailinglist.honeypot at gmail.com (Steve Lianoglou)
Date: Thu, 5 Jan 2012 10:16:54 -0500
Subject: [Rd] informal conventions/checklist for new predictive modeling
	packages
In-Reply-To: <CAJ9CoWkE-suPfebAs5K9jnBJ7epj4RRBLNAOiAExWWwP5QLnKw@mail.gmail.com>
References: <CAJ9CoWkE-suPfebAs5K9jnBJ7epj4RRBLNAOiAExWWwP5QLnKw@mail.gmail.com>
Message-ID: <CAHA9McMNx4YHL1mZMc2byRMJEyjCQQdq_bJ4ZgTOixJh6vW6rw@mail.gmail.com>

Good stuff, Max!

Would also be nice to nail your 14 theses to a more permanent wall
than the r-help mailing list ... not sure where that would be, though
... isn't someone supposed to be redesigning the r-project.org
website? [I jest, I jest] More seriously, though, it might be worth
linking to from the developer.r-project.org site as well as from some
blurb in the header of the ML task view.


-steve

On Wed, Jan 4, 2012 at 9:19 AM, Max Kuhn <mxkuhn at gmail.com> wrote:
> Working on the caret package has exposed me to the wide variety of
> approaches that different authors have taken to creating predictive
> modeling functions (aka machine learning)(aka pattern recognition).
>
> I suspect that many package authors are neophyte R users and are
> stumbling through the process of writing their first R package (or R
> code). As such, they may not have been exposed to some of the informal
> conventions that have evolved over time. Also, their package may be
> intended to demonstrate their research and not for "production"
> modeling. In any case, it might be a good idea to print up a few
> points for consideration when creating a predictive modeling package.
> I don't propose changes to existing code.
>
> Some of this is obvious and not limited to this class of modeling
> packages. Many of these points are arguable, so please do so.
>
> If this seems useful, perhaps we could repost the final list to R-Help
> to use as a checklist.
>
> Those of you who have used my code will probably realize that I am not
> a grand architect of R packages =] I'd love to get feedback from those
> of you with a broader perspective and better software engineering
> skills than I (a low bar to step over).
>
> I have marked a few of these items with an OCD tag since I might be
> taking it a bit too far.
>
> The list:
>
> (1) Extend the work of others. There is an amazing amount of unneeded
> redundancy. There are plenty of times that users implement their own
> version of a function because there is an missing feature, but a lot
> of time is spent re-creating duplicate functions. For example, kernlab
> has an excellent set of kernel functions that are really efficient and
> have useful ancillary functions. People may not new aware of these
> functions, but they are one RSiteSearch away. (Perhaps we could
> nominate a few packages like kernlab that implement a specific tool
> well)
>
> (2) When modeling a categorical outcome, use a factor as input (as
> opposed to 0/1 indicators or integers). Factors are exactly the kind
> of feature that separates R from other languages (I'm looking at you
> SAS) and is a natural structure for this data type.
>
> corollary (2a): save the factor levels in the model object somewhere
>
> corollary (2b): return predicted classes as factors with the same
> levels (and ordering of levels).
>
> (3) Implement a separate prediction function. Some packages only make
> predictions when the model is built, so effectively the model cannot
> be used at any point in the future.
>
> corollary (3a): use object-orientation (eg. predict.{class}) and not
> some made-up function name "modelPredict()" for predicting new
> samples.
>
> (4) If the method only accepts a specific type of input (eg. matrix or
> data frame), please do the conversion whenever appropriate.
>
> (5) Provide a formula interface (eg. foo(y~x, data = dat)) and
> non-formula interface (foo(x, y) to the function. Formula methods are
> really inefficient at this time for large dimensional data but are
> fantastically convenient. There are some good reasons to not use
> formulas, such as functions that do not use a design matrix (eg.
> cforest()) or need factors to be handled in a non-standard way (eg.
> cubist()).
>
> (6) Don't require a test set when model building.
>
> (7) Control all written output during model-building time with a
> verbose option. Resampling can make a mess out of things if
> output/logging is always exposed.
>
> (8) Please use RSiteSearch to avoid name collisions between packages
> (eg. gam(), splsda(), roc(), LogitBoost()). Also search Bioconductor.
>
> (9) Allow the predict function to generate results from many different
> sub-models simultaneously. For example, pls() can return predictions
> across many values of ncomp. enet(), cubist(), blackboost() are other
> examples.
>
> corollary (9a): [OCD] ensure the same object type for predictions.
> There are occasions where predict() will return a vector or a matrix
> depending on the context. I would argue that this is not optimal.
>
> (10) Use a limited vocabulary for options. For example, some predict()
> functions have a "type" options to switch between predicted classes
> and class probabilities. Values of "type" pertaining to class
> probabilities range from "prob", "probability", "posterior", "raw",
> "response", etc. I'll make a suggestion of "prob" as a possible
> standard for this situation.
>
> (11) Make sure that class probabilities sum to one. Seriously.
>
> (12) If the model implicitly conducts feature selection, do not
> require un-used predictors to be present in future data sets for
> prediction. This may be a problem when the formula interface to models
> is used, but it looks like many functions reference columns by
> position and not name.
>
> (13) Packages that have their own cross-validation functions should
> allow the users to pass in the specific folds/resamping indicators to
> maintain consistency across similar functions in other packages.
>
> (14) [OCD] For binary classification models, model the probability of
> the first level of a factor as the event of interest (again, for
> consistency) Note that glm() does not do this but most others use the
> first level.
>
> Thanks,
>
> Max
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel



-- 
Steve Lianoglou
Graduate Student: Computational Systems Biology
?| Memorial Sloan-Kettering Cancer Center
?| Weill Medical College of Cornell University
Contact Info: http://cbio.mskcc.org/~lianos/contact


From pauljohn32 at gmail.com  Thu Jan  5 21:26:45 2012
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Thu, 5 Jan 2012 14:26:45 -0600
Subject: [Rd] delete.response leaves response in attribute dataClasses
Message-ID: <CAErODj9Aibpb4M=xq9+hHKw6Qurphxb2O7nb4A8x=F3UxPZLgA@mail.gmail.com>

I posted this one as an R bug
(https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=14767), but
Prof. Ripley says I'm premature, and I should raise the question here.

Here's the behavior I assert is a bug:
The output from delete.response on a terms object alters the formula
by removing the dependent variable. It removes the response from the
"variables" attribute and it changes the response attribute from 1 to
0.  The response is removed from "predvars"

But it leaves the name of the dependent variable first in the in
"dataClasses".  It caused an unexpected behavior in my code, so (as
usual) the bug may be mine, but in my heart, I believe it belongs to
delete.response.

To illustrate, here's a terms object from a regression.

> tt
y ~ x1 * x2 + x3 + x4
attr(,"variables")
list(y, x1, x2, x3, x4)
attr(,"factors")
   x1 x2 x3 x4 x1:x2
y   0  0  0  0     0
x1  1  0  0  0     1
x2  0  1  0  0     1
x3  0  0  1  0     0
x4  0  0  0  1     0
attr(,"term.labels")
[1] "x1"    "x2"    "x3"    "x4"    "x1:x2"
attr(,"order")
[1] 1 1 1 1 2
attr(,"intercept")
[1] 1
attr(,"response")
[1] 1
attr(,".Environment")
<environment: R_GlobalEnv>
attr(,"predvars")
list(y, x1, x2, x3, x4)
attr(,"dataClasses")
        y        x1        x2        x3        x4
"numeric" "numeric" "numeric" "numeric" "numeric"

Now observe that delete.response removes the response from all
attributes except dataClasses.

> delete.response(tt)
~x1 * x2 + x3 + x4
attr(,"variables")
list(x1, x2, x3, x4)
attr(,"factors")
   x1 x2 x3 x4 x1:x2
x1  1  0  0  0     1
x2  0  1  0  0     1
x3  0  0  1  0     0
x4  0  0  0  1     0
attr(,"term.labels")
[1] "x1"    "x2"    "x3"    "x4"    "x1:x2"
attr(,"order")
[1] 1 1 1 1 2
attr(,"intercept")
[1] 1
attr(,"response")
[1] 0
attr(,".Environment")
<environment: R_GlobalEnv>
attr(,"predvars")
list(x1, x2, x3, x4)
attr(,"dataClasses")
        y        x1        x2        x3        x4
"numeric" "numeric" "numeric" "numeric" "numeric"


pj

-- 
Paul E. Johnson
Professor, Political Science
1541 Lilac Lane, Room 504
University of Kansas


From pauljohn32 at gmail.com  Thu Jan  5 21:44:41 2012
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Thu, 5 Jan 2012 14:44:41 -0600
Subject: [Rd] informal conventions/checklist for new predictive modeling
	packages
In-Reply-To: <CAJ9CoWkE-suPfebAs5K9jnBJ7epj4RRBLNAOiAExWWwP5QLnKw@mail.gmail.com>
References: <CAJ9CoWkE-suPfebAs5K9jnBJ7epj4RRBLNAOiAExWWwP5QLnKw@mail.gmail.com>
Message-ID: <CAErODj8YXA5L9__dOovvxLuF6ttp+PLaSUtoWWCrXh+fhz_bkw@mail.gmail.com>

I agree with almost all, except the last point. Since I have
participated in wheel-reinvention lately, I agree with the bulk of
your comment. I don't think the fix is as easy as you suspect,
RSiteSearch won't help me find a function I need when I don't know the
magic words.  Some R functions have such unexpected names that only a
fastidious source-code reader would find them ("pretty", for example).
 But I agree with your concern.

But, as far as the last one is concerned, I think you are mistaken.
Explanation below.

On Wed, Jan 4, 2012 at 8:19 AM, Max Kuhn <mxkuhn at gmail.com> wrote:
>
> (14) [OCD] For binary classification models, model the probability of
> the first level of a factor as the event of interest (again, for
> consistency) Note that glm() does not do this but most others use the
> first level.
>
When the DV is thought of as 0 and 1, and 1 is an "event" "success" or
"win" and 0 is a "non event" "failure" or "loss",  if there is to be a
single predicted probability, I want it to be the probability of the
higher outcome.

glm is doing the thing I want, and I don't know of others that go the
other way, except PROC LOGISTIC in SAS.  And that has a long history
of causing confusion and despair.

I'd like to consider adding one thing to your list, though.  I have
wished (in this list and elsewhere) that there were a more regular
approach for calculating "newdata" objects that are used in predict.
Many packages have re-invented this (datadist in rms, effects), and
almost nobody here agreed with my wish for a more standard approach.
But if there were a standard approach, it would be much easier to hold
up R as an alternative to Stata when users pop up with "marginal
effects tables" from Stata that are very difficult to reproduce with
R.

Regards,
pj

-- 
Paul E. Johnson
Professor, Political Science
1541 Lilac Lane, Room 504
University of Kansas


From wdunlap at tibco.com  Thu Jan  5 21:56:30 2012
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 5 Jan 2012 20:56:30 +0000
Subject: [Rd] delete.response leaves response in attribute dataClasses
In-Reply-To: <CAErODj9Aibpb4M=xq9+hHKw6Qurphxb2O7nb4A8x=F3UxPZLgA@mail.gmail.com>
References: <CAErODj9Aibpb4M=xq9+hHKw6Qurphxb2O7nb4A8x=F3UxPZLgA@mail.gmail.com>
Message-ID: <E66794E69CFDE04D9A70842786030B932574D6@PA-MBX03.na.tibco.com>

I had noticed the same thing but figured that most
people (writers of predict methods) would be looking
up entries in dataClasses by name and not by position,
since predict's newdata argument need not have entries
in the same order as the data used to fit the model.
Hence the extra entry would not noticed (nor would it be
missed if it were omitted).

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com 

> -----Original Message-----
> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org] On Behalf Of Paul Johnson
> Sent: Thursday, January 05, 2012 12:27 PM
> To: R Devel List
> Subject: [Rd] delete.response leaves response in attribute dataClasses
> 
> I posted this one as an R bug
> (https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=14767), but
> Prof. Ripley says I'm premature, and I should raise the question here.
> 
> Here's the behavior I assert is a bug:
> The output from delete.response on a terms object alters the formula
> by removing the dependent variable. It removes the response from the
> "variables" attribute and it changes the response attribute from 1 to
> 0.  The response is removed from "predvars"
> 
> But it leaves the name of the dependent variable first in the in
> "dataClasses".  It caused an unexpected behavior in my code, so (as
> usual) the bug may be mine, but in my heart, I believe it belongs to
> delete.response.
> 
> To illustrate, here's a terms object from a regression.
> 
> > tt
> y ~ x1 * x2 + x3 + x4
> attr(,"variables")
> list(y, x1, x2, x3, x4)
> attr(,"factors")
>    x1 x2 x3 x4 x1:x2
> y   0  0  0  0     0
> x1  1  0  0  0     1
> x2  0  1  0  0     1
> x3  0  0  1  0     0
> x4  0  0  0  1     0
> attr(,"term.labels")
> [1] "x1"    "x2"    "x3"    "x4"    "x1:x2"
> attr(,"order")
> [1] 1 1 1 1 2
> attr(,"intercept")
> [1] 1
> attr(,"response")
> [1] 1
> attr(,".Environment")
> <environment: R_GlobalEnv>
> attr(,"predvars")
> list(y, x1, x2, x3, x4)
> attr(,"dataClasses")
>         y        x1        x2        x3        x4
> "numeric" "numeric" "numeric" "numeric" "numeric"
> 
> Now observe that delete.response removes the response from all
> attributes except dataClasses.
> 
> > delete.response(tt)
> ~x1 * x2 + x3 + x4
> attr(,"variables")
> list(x1, x2, x3, x4)
> attr(,"factors")
>    x1 x2 x3 x4 x1:x2
> x1  1  0  0  0     1
> x2  0  1  0  0     1
> x3  0  0  1  0     0
> x4  0  0  0  1     0
> attr(,"term.labels")
> [1] "x1"    "x2"    "x3"    "x4"    "x1:x2"
> attr(,"order")
> [1] 1 1 1 1 2
> attr(,"intercept")
> [1] 1
> attr(,"response")
> [1] 0
> attr(,".Environment")
> <environment: R_GlobalEnv>
> attr(,"predvars")
> list(x1, x2, x3, x4)
> attr(,"dataClasses")
>         y        x1        x2        x3        x4
> "numeric" "numeric" "numeric" "numeric" "numeric"
> 
> 
> pj
> 
> --
> Paul E. Johnson
> Professor, Political Science
> 1541 Lilac Lane, Room 504
> University of Kansas
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From wdunlap at tibco.com  Thu Jan  5 22:15:33 2012
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 5 Jan 2012 21:15:33 +0000
Subject: [Rd] delete.response leaves response in attribute dataClasses
In-Reply-To: <E66794E69CFDE04D9A70842786030B932574D6@PA-MBX03.na.tibco.com>
References: <CAErODj9Aibpb4M=xq9+hHKw6Qurphxb2O7nb4A8x=F3UxPZLgA@mail.gmail.com>
	<E66794E69CFDE04D9A70842786030B932574D6@PA-MBX03.na.tibco.com>
Message-ID: <E66794E69CFDE04D9A70842786030B932574F5@PA-MBX03.na.tibco.com>

My feeling that everyone would index dataClasses by name was
wrong.  I looked through the packages that used dataClasses
and saw code that would break if the first (response) entry
were omitted.  (I didn't check to see if passing the output
of delete.response to these functions would be appropriate.)
E.g.,
file: AICcmodavg/R/predictSE.mer.r
  ##matrix with info on factors
  fact.frame <- attr(attr(orig.frame, "terms"), "dataClasses")[-1]

  ##continue if factors
  if(any(fact.frame == "factor")) {
    id.factors <- which(fact.frame == "factor")
    fact.name <- names(fact.frame)[id.factors] #identify the rows for factors

Some packages create a dataClass attribute for a model.frame
(not its terms attribute) that does not have any names:
file: caper/R/macrocaic.R
   attr(mf, "dataClasses") <- rep("numeric", dim(termFactors)[2])
.checkMFClasses() does not throw an error for that, but it
doesn't do any real checking either.

Most users of dataClasses do pass it to .checkMFClasses() to
compare it with newdata and that doesn't care if you have extra
entries in dataClasses.

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com 

> -----Original Message-----
> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org] On Behalf Of William Dunlap
> Sent: Thursday, January 05, 2012 12:57 PM
> To: Paul Johnson; R Devel List
> Subject: Re: [Rd] delete.response leaves response in attribute dataClasses
> 
> I had noticed the same thing but figured that most
> people (writers of predict methods) would be looking
> up entries in dataClasses by name and not by position,
> since predict's newdata argument need not have entries
> in the same order as the data used to fit the model.
> Hence the extra entry would not noticed (nor would it be
> missed if it were omitted).
> 
> Bill Dunlap
> Spotfire, TIBCO Software
> wdunlap tibco.com
> 
> > -----Original Message-----
> > From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org] On Behalf Of Paul Johnson
> > Sent: Thursday, January 05, 2012 12:27 PM
> > To: R Devel List
> > Subject: [Rd] delete.response leaves response in attribute dataClasses
> >
> > I posted this one as an R bug
> > (https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=14767), but
> > Prof. Ripley says I'm premature, and I should raise the question here.
> >
> > Here's the behavior I assert is a bug:
> > The output from delete.response on a terms object alters the formula
> > by removing the dependent variable. It removes the response from the
> > "variables" attribute and it changes the response attribute from 1 to
> > 0.  The response is removed from "predvars"
> >
> > But it leaves the name of the dependent variable first in the in
> > "dataClasses".  It caused an unexpected behavior in my code, so (as
> > usual) the bug may be mine, but in my heart, I believe it belongs to
> > delete.response.
> >
> > To illustrate, here's a terms object from a regression.
> >
> > > tt
> > y ~ x1 * x2 + x3 + x4
> > attr(,"variables")
> > list(y, x1, x2, x3, x4)
> > attr(,"factors")
> >    x1 x2 x3 x4 x1:x2
> > y   0  0  0  0     0
> > x1  1  0  0  0     1
> > x2  0  1  0  0     1
> > x3  0  0  1  0     0
> > x4  0  0  0  1     0
> > attr(,"term.labels")
> > [1] "x1"    "x2"    "x3"    "x4"    "x1:x2"
> > attr(,"order")
> > [1] 1 1 1 1 2
> > attr(,"intercept")
> > [1] 1
> > attr(,"response")
> > [1] 1
> > attr(,".Environment")
> > <environment: R_GlobalEnv>
> > attr(,"predvars")
> > list(y, x1, x2, x3, x4)
> > attr(,"dataClasses")
> >         y        x1        x2        x3        x4
> > "numeric" "numeric" "numeric" "numeric" "numeric"
> >
> > Now observe that delete.response removes the response from all
> > attributes except dataClasses.
> >
> > > delete.response(tt)
> > ~x1 * x2 + x3 + x4
> > attr(,"variables")
> > list(x1, x2, x3, x4)
> > attr(,"factors")
> >    x1 x2 x3 x4 x1:x2
> > x1  1  0  0  0     1
> > x2  0  1  0  0     1
> > x3  0  0  1  0     0
> > x4  0  0  0  1     0
> > attr(,"term.labels")
> > [1] "x1"    "x2"    "x3"    "x4"    "x1:x2"
> > attr(,"order")
> > [1] 1 1 1 1 2
> > attr(,"intercept")
> > [1] 1
> > attr(,"response")
> > [1] 0
> > attr(,".Environment")
> > <environment: R_GlobalEnv>
> > attr(,"predvars")
> > list(x1, x2, x3, x4)
> > attr(,"dataClasses")
> >         y        x1        x2        x3        x4
> > "numeric" "numeric" "numeric" "numeric" "numeric"
> >
> >
> > pj
> >
> > --
> > Paul E. Johnson
> > Professor, Political Science
> > 1541 Lilac Lane, Room 504
> > University of Kansas
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From mtmorgan at fhcrc.org  Fri Jan  6 09:16:00 2012
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Fri, 06 Jan 2012 00:16:00 -0800
Subject: [Rd] interesting connection / finalizer bug?
Message-ID: <4F06ADC0.8090404@fhcrc.org>

This

setOldClass(c("file", "connection"))
.A <- setRefClass("A", fields=list(con="connection"),
                   methods=list(
                     finalize = function() {
                         if (isOpen(con)) close(con)
                     }))

f <- tempdir()
a <- .A$new(con=file(f, "rb"))
close(a$con)
a <- .A$new(con=file(f, "rb"))
bin <- readBin(a$con, raw(), as.integer(1e8))

crashes (hangs, usually) at the last line, with valgrind saying

==14875== Invalid read of size 8
==14875==    at 0x4EB23DA: do_readbin (connections.c:3678)
==14875==    by 0x4F795E4: do_internal (names.c:1236)
==14875==    by 0x4F15F63: Rf_eval (eval.c:471)
==14875==    by 0x4F18BA7: do_begin (eval.c:1422)
==14875==    by 0x4F15F63: Rf_eval (eval.c:471)
==14875==    by 0x4F16F0C: Rf_applyClosure (eval.c:840)
==14875==    by 0x4F16276: Rf_eval (eval.c:515)
==14875==    by 0x4F19939: do_set (eval.c:1726)
==14875==    by 0x4F15F63: Rf_eval (eval.c:471)
==14875==    by 0x4F5EF6C: Rf_ReplIteration (main.c:256)
==14875==    by 0x4F5F159: R_ReplConsole (main.c:305)
==14875==    by 0x4F607B8: run_Rmainloop (main.c:986)
==14875==  Address 0x907f1d8 is 136 bytes inside a block of size 448 free'd
==14875==    at 0x4C25F7B: free (in 
/usr/lib64/valgrind/vgpreload_memcheck-amd64-linux.so)
==14875==    by 0x4EB0282: con_destroy (connections.c:3086)
==14875==    by 0x4EB03B3: do_close (connections.c:3105)
==14875==    by 0x4F795E4: do_internal (names.c:1236)
==14875==    by 0x4F15F63: Rf_eval (eval.c:471)
==14875==    by 0x4F19D7F: Rf_evalList (eval.c:1840)
==

A little more revealing, with two surprises noted, is

 > f <- tempdir()
 > a <- .A$new(con=file(f, "rb"))
 > close(a$con)
 > a <- .A$new(con=file(f, "rb"))
 > gc() ## run finalizer -- should complain about invalid connection!
          used (Mb) gc trigger (Mb) max used (Mb)
Ncells 205579 11.0     407500 21.8   350000 18.7
Vcells 162784  1.3     786432  6.0   558828  4.3
 > bin <- readBin(a$con, raw(), as.integer(1e8))  ## a$con should be ok!
Error in readBin(a$con, raw(), as.integer(1e+08)) : invalid connection

Presumably the example without the explicit garbage collection results 
from a garbage collection triggered after the connection has been tested 
for validity. This is not a finalizer bug, as the following elicits the 
same behavior

invisible(gcinfo(TRUE))
f <- tempdir()

e <- new.env()
reg.finalizer(e, function(e) tryCatch({
     if (isOpen(e$con)) close(e$con)
}))
e$con <- file(f, "rb")
close(e$con)

e <- new.env()
e$con <- file(f, "rb")
bin <- readBin(e$con, raw(), as.integer(1e8))

 > sessionInfo()
R Under development (unstable) (2012-01-04 r58051)
Platform: x86_64-unknown-linux-gnu (64-bit)

locale:
  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
  [7] LC_PAPER=C                 LC_NAME=C
  [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base


-- 
Computational Biology
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N. PO Box 19024 Seattle, WA 98109

Location: M1-B861
Telephone: 206 667-2793


From hadley at rice.edu  Fri Jan  6 19:31:55 2012
From: hadley at rice.edu (Hadley Wickham)
Date: Fri, 6 Jan 2012 12:31:55 -0600
Subject: [Rd] seq_along and rep_along
Message-ID: <CABdHhvEUtWfj6+2kT6fsD5CYgx66g1+C5gNhdLTA0M60Dw+YbQ@mail.gmail.com>

Hi all,

A couple of ideas for improving seq_along:

* It would be really useful to have a second argument dim:

    seq_along(mtcars, 1)
    seq_along(mtcars, 2)
    # equivalent to
    seq_len(dim(mtcars)[1])
    seq_len(dim(mtcars)[2])

  I often find myself wanting to iterate over the rows or column of a
data frame, and there isn't a particularly nice idiom if you want to
avoid problems with zeros - you have to use seq_len(nrow(df)) etc

* To me, it would seem be very natural to have a rep_along function:

  rep_along <- function(x, y) rep(x, length.out = length(y))

  possibly with more checking for the case where the lengths aren't
integer multiples.

I'd be happy to submit proposed implementations/documentation if there
was interest.

Hadley

-- 
Assistant Professor / Dobelman Family Junior Chair
Department of Statistics / Rice University
http://had.co.nz/


From jeff.hamann at forestinformatics.com  Fri Jan  6 20:11:46 2012
From: jeff.hamann at forestinformatics.com (Jeff Hamann)
Date: Fri, 6 Jan 2012 11:11:46 -0800
Subject: [Rd] R CMD check WARNING \usage question
Message-ID: <7B79779F-EBDC-4147-B92D-C61C19EE4349@forestinformatics.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20120106/90b95913/attachment.pl>

From pauljohn32 at gmail.com  Fri Jan  6 20:17:01 2012
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Fri, 6 Jan 2012 13:17:01 -0600
Subject: [Rd] delete.response leaves response in attribute dataClasses
In-Reply-To: <E66794E69CFDE04D9A70842786030B932574F5@PA-MBX03.na.tibco.com>
References: <CAErODj9Aibpb4M=xq9+hHKw6Qurphxb2O7nb4A8x=F3UxPZLgA@mail.gmail.com>
	<E66794E69CFDE04D9A70842786030B932574D6@PA-MBX03.na.tibco.com>
	<E66794E69CFDE04D9A70842786030B932574F5@PA-MBX03.na.tibco.com>
Message-ID: <CAErODj8210v5vS+xQcLxhrdd_opanptoWaUKWKzwbgryYzSe_g@mail.gmail.com>

Thanks, Bill

Counter-arguments at the end

On Thu, Jan 5, 2012 at 3:15 PM, William Dunlap <wdunlap at tibco.com> wrote:
> My feeling that everyone would index dataClasses by name was
> wrong. ?I looked through the packages that used dataClasses
> and saw code that would break if the first (response) entry
> were omitted. ?(I didn't check to see if passing the output
> of delete.response to these functions would be appropriate.)
> E.g.,
> file: AICcmodavg/R/predictSE.mer.r
> ?##matrix with info on factors
> ?fact.frame <- attr(attr(orig.frame, "terms"), "dataClasses")[-1]
>
> ?##continue if factors
> ?if(any(fact.frame == "factor")) {
> ? ?id.factors <- which(fact.frame == "factor")
> ? ?fact.name <- names(fact.frame)[id.factors] #identify the rows for factors
>
> Some packages create a dataClass attribute for a model.frame
> (not its terms attribute) that does not have any names:
> file: caper/R/macrocaic.R
> ? attr(mf, "dataClasses") <- rep("numeric", dim(termFactors)[2])
> .checkMFClasses() does not throw an error for that, but it
> doesn't do any real checking either.
>
> Most users of dataClasses do pass it to .checkMFClasses() to
> compare it with newdata and that doesn't care if you have extra
> entries in dataClasses.
>
> Bill Dunlap
> Spotfire, TIBCO Software
> wdunlap tibco.com
>

I can't understand what your point is.  I agree we can work around the
problem, but why should we have to?

If you confine yourself to the output of "delete.response" applied to
a terms object from a regression, can you point to any package or
usage that depends on leaving the response variable in the dataClasses
attribute?  I can't find one.  In R base, these are all the references
to delete.response:

stats/R/models.R:delete.response <- function (termobj)
stats/R/lm.R:        Terms <- delete.response(tt)
stats/R/lm.R:        Terms <- delete.response(tt)
stats/R/ppr.R:        Terms <- delete.response(object$terms)
stats/R/loess.R:
as.matrix(model.frame(delete.response(terms(object)), newdata,
stats/R/dummy.coef.R:    Terms <- delete.response(Terms)

I've looked it over carefully and predict.lm (in lm.R) would not be
affected by the change I propose. I can't find any usage in loess.R of
the dataClasses attribute.

Furthermore, I can't see how a person would use the dataClasses
attribute at all, after the other markers of the response are
eliminated. How is a method to find which variable is the response,
after response=0?

I'm not disagreeing with you that I can workaround the peculiarity
that the response is left in the dataClasses attribute of the output
object from delete.response.  I'm just saying it is a complication
that programmers should not have to put up with, because I think
delete.response should delete the response from all attributes of a
terms object.

pj


-- 
Paul E. Johnson
Professor, Political Science
1541 Lilac Lane, Room 504
University of Kansas


From murdoch.duncan at gmail.com  Fri Jan  6 20:27:36 2012
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 06 Jan 2012 14:27:36 -0500
Subject: [Rd] seq_along and rep_along
In-Reply-To: <CABdHhvEUtWfj6+2kT6fsD5CYgx66g1+C5gNhdLTA0M60Dw+YbQ@mail.gmail.com>
References: <CABdHhvEUtWfj6+2kT6fsD5CYgx66g1+C5gNhdLTA0M60Dw+YbQ@mail.gmail.com>
Message-ID: <4F074B28.8020307@gmail.com>

On 12-01-06 1:31 PM, Hadley Wickham wrote:
> Hi all,
>
> A couple of ideas for improving seq_along:
>
> * It would be really useful to have a second argument dim:
>
>      seq_along(mtcars, 1)
>      seq_along(mtcars, 2)
>      # equivalent to
>      seq_len(dim(mtcars)[1])
>      seq_len(dim(mtcars)[2])
>
>    I often find myself wanting to iterate over the rows or column of a
> data frame, and there isn't a particularly nice idiom if you want to
> avoid problems with zeros - you have to use seq_len(nrow(df)) etc

I don't see the benefit of seq_along(mtcars, 1) versus seq_len(nrow(df)) 
in readability.

Duncan Murdoch

>
> * To me, it would seem be very natural to have a rep_along function:
>
>    rep_along<- function(x, y) rep(x, length.out = length(y))
>
>    possibly with more checking for the case where the lengths aren't
> integer multiples.
>
> I'd be happy to submit proposed implementations/documentation if there
> was interest.
>
> Hadley
>


From jeff.hamann at forestinformatics.com  Fri Jan  6 20:48:25 2012
From: jeff.hamann at forestinformatics.com (Jeff Hamann)
Date: Fri, 6 Jan 2012 11:48:25 -0800
Subject: [Rd] R CMD check WARNING \usage question
In-Reply-To: <B3C0C36D-9514-441B-AED1-A0AAA1CED53F@depauw.edu>
References: <7B79779F-EBDC-4147-B92D-C61C19EE4349@forestinformatics.com>
	<B3C0C36D-9514-441B-AED1-A0AAA1CED53F@depauw.edu>
Message-ID: <EA381AAB-EF25-4626-98C7-F65799710395@forestinformatics.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20120106/0711f699/attachment.pl>

From hadley at rice.edu  Fri Jan  6 20:52:22 2012
From: hadley at rice.edu (Hadley Wickham)
Date: Fri, 6 Jan 2012 13:52:22 -0600
Subject: [Rd] seq_along and rep_along
In-Reply-To: <4F074B28.8020307@gmail.com>
References: <CABdHhvEUtWfj6+2kT6fsD5CYgx66g1+C5gNhdLTA0M60Dw+YbQ@mail.gmail.com>
	<4F074B28.8020307@gmail.com>
Message-ID: <CABdHhvHPOjrKBKimuJ9F++YcXXL2y9Mn+LghAHo8k1qSc1gTDg@mail.gmail.com>

> I don't see the benefit of seq_along(mtcars, 1) versus seq_len(nrow(df)) in
> readability.

I like it because:

* it reads nicely: I want a sequence along this structure in that direction
* it's more consistent: for(i in seq_along(x)) -> for(row in
seq_along(mtcars, 1))
* it generalised in a straightforward way to arrays

I don't think it's a huge improvement, but it is frustrating when base
functionality only works with vectors, not matrices, or arrays. It
would be more compelling if (e.g.) t and rev also had dimension
arguments.

Hadley

-- 
Assistant Professor / Dobelman Family Junior Chair
Department of Statistics / Rice University
http://had.co.nz/


From hanson at depauw.edu  Fri Jan  6 20:38:55 2012
From: hanson at depauw.edu (Bryan Hanson)
Date: Fri, 6 Jan 2012 14:38:55 -0500
Subject: [Rd] R CMD check WARNING \usage question
In-Reply-To: <7B79779F-EBDC-4147-B92D-C61C19EE4349@forestinformatics.com>
References: <7B79779F-EBDC-4147-B92D-C61C19EE4349@forestinformatics.com>
Message-ID: <B3C0C36D-9514-441B-AED1-A0AAA1CED53F@depauw.edu>

Jeff, quick question: is this a data set or a function you are documenting?  What you say sounds like it's data, but the Rd file reads more like a function.  Or are you trying to document a data format/object which stores specific data sets?

Let us know, and I'll bet the answer will appear pretty quickly. Bryan

***********
Bryan Hanson
Professor of Chemistry & Biochemistry
DePauw University

On Jan 6, 2012, at 2:11 PM, Jeff Hamann wrote:

> I'm trying to update a package and would like to crush a WARNING message for a clean build. 
> 
> I've been struggling with this question and haven't gotten any traction on the web either.
> 
> I've got a document file (Rd) that contains the following \usage statement:
> 
> \name{sample.data}
> \alias{sample.data}
> 
> \title{CONIFERS forest growth model sample data}
> 
> \description{ A list object of type \code{sample.data} stores all of
> the basic information about a \code{\link{data.frame}} object
> representing a sample of plants.}
> 
> \usage{
> x <- list( plots=data.frame(), plants=data.frame(), age=0, x0=0.0, n.years.projected=0 )
> class(x)  <- "sample.data"
> }
> 
> When I run R CMD check [pkg], I get the following WARNING:
> 
> * checking Rd \usage sections ... WARNING
> Assignments in \usage in documentation object 'sample.data':
>  x <- list(plots, plants, age = 0, x0 = 0, n.years.projected = 0)
>  class(x) <- "sample.data"
> 
> Functions with \usage entries need to have the appropriate \alias
> entries, and all their arguments documented.
> The \usage entries must correspond to syntactically valid R code.
> See the chapter 'Writing R documentation files' in manual 'Writing R
> Extensions'.
> * checking Rd contents ... OK
> 
> I'm not sure if there's a problem with the \alias section or the \usage section or both sections (I'm assuming this is the case).
> 
> I've read the Chapter 2 of R-ext.pdf plenty and just can't seem to see where I'm blowing it.
> 
> Respectfully,
> Jeff.
> 
> 
> Jeff Hamann, PhD
> PO Box 1421
> Corvallis, Oregon 97339-1421
> 541-754-2457
> jeff.hamann[at]forestinformatics[dot]com
> jeff.d.hamann[at]gmail[dot]com
> http://www.forestinformatics.com
> http://en.wikipedia.org/wiki/Forest_informatics
> 
> To ensure that your email is processed, include a subject entry in your email.
> 
> 
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From hanson at depauw.edu  Fri Jan  6 21:01:44 2012
From: hanson at depauw.edu (Bryan Hanson)
Date: Fri, 6 Jan 2012 15:01:44 -0500
Subject: [Rd] R CMD check WARNING \usage question
In-Reply-To: <EA381AAB-EF25-4626-98C7-F65799710395@forestinformatics.com>
References: <7B79779F-EBDC-4147-B92D-C61C19EE4349@forestinformatics.com>
	<B3C0C36D-9514-441B-AED1-A0AAA1CED53F@depauw.edu>
	<EA381AAB-EF25-4626-98C7-F65799710395@forestinformatics.com>
Message-ID: <376ED685-3D25-4F70-8D5F-38CAC51E257E@depauw.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20120106/84568958/attachment.pl>

From murdoch.duncan at gmail.com  Fri Jan  6 21:09:53 2012
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 06 Jan 2012 15:09:53 -0500
Subject: [Rd] R CMD check WARNING \usage question
In-Reply-To: <EA381AAB-EF25-4626-98C7-F65799710395@forestinformatics.com>
References: <7B79779F-EBDC-4147-B92D-C61C19EE4349@forestinformatics.com>
	<B3C0C36D-9514-441B-AED1-A0AAA1CED53F@depauw.edu>
	<EA381AAB-EF25-4626-98C7-F65799710395@forestinformatics.com>
Message-ID: <4F075511.3030308@gmail.com>

  On 12-01-06 2:48 PM, Jeff Hamann wrote:
> I know I should provide a better answer, but I think it's really for a function.
>
> For this package, we simply pass a list object about, but have to obfuscate it using a domain familiar nomenclature for the users.
>
> So, not a data set, but a function. I think.

You are documenting "sample.data", according to the name and alias.  But 
you create an object called "x".  There is no object (function or data) 
called "sample.data".  It's the name of an S3 class.

Now, there isn't a \docType setting for documenting an S3 class; they 
are usually documented along with the function that produces them.  So 
the easiest thing to do is probably to create a function (called 
sample.data, if you like) that produces the object, and document its usage.

Alternatively, don't use Rd for your documentation, write a vignette. 
But that's a lot more work.

Or create a prototype sample.data object (which is what your x looks 
like, being mostly empty), and document it using \docType{data}.  Move 
the code from your \usage section to \examples.

Duncan Murdoch

>
> Here's the file in it's entirety:
>
>
> %%	$Id $	
>
> \name{sample.data}
> \alias{sample.data}
>
> \title{CONIFERS forest growth model sample data}
>
> \description{ A list object of type \code{sample.data} stores all of
> the basic information about a \code{\link{data.frame}} object
> representing a sample of plants.}
>
> \usage{
> x<- list( plots=data.frame(), plants=data.frame(), age=0, x0=0.0, n.years.projected=0 )
> class(x)<- "sample.data"
> }
>
> \details{
> 	To create the basic data type used in rconifers, you create a
> 	list object with the following elements (order is not
> 	important):
> \describe{
> \item{plots}{is a \link{data.frame} with the the same elements as \code{\link{plots.swo}}.}
> \item{plants}{is a \link{data.frame} with the the same elements as \code{\link{plants.swo}}.}
> \item{age}{is an integer value that represents the age of the plants,
> in years.}
> \item{x0}{is the $x_{0}$ coefficient for the Hann and Wang (1990) mortality model.}
> \item{n.years.projected}{is the number of years that $x$ has been
> 	projected forward in time.}
> }
> }
>
> \references{
>
> Ritchie, M.W. 2008. User's Guide and Help System for CONIFERS: A Simulator for Young Conifer Plantations Version
> 4.10. See \url{http://www.fs.fed.us/psw/programs/ecology_of_western_forests/projects/conifers/}
>
> }
>
> \author{Jeff D. Hamann \email{jeff.hamann at forestinformatics.com},\cr
> 	     Martin W. Ritchie \email{mritchie at fs.fed.us} }
>
> \seealso{    \code{\link{plants.smc}},
> 	     \code{\link{plots.smc}}
> 	     \code{\link{plants.swo}},
> 	     \code{\link{plots.swo}},
> 	     \code{\link{sample.data}},
> 	     \code{\link{set.species.map}},		
> 	     \code{\link{set.variant}},		
>   	     \code{\link{smc}},
>   	     \code{\link{summary.sample.data}},
> 	     \code{\link{swo}},
> 	     \code{\link{thin}}
> }
>
> \examples{
> library( rconifers )
> ## Example for SWO variant
> ## set the variant to the SWO variant and set species map
> ##set.species.map( set.variant(0) )
> set.variant(0)
>
> ## grow the data that was originally swo in the smc variant
> # load and display CONIFERS example plots
> data( plots.swo )
> print( plots.swo )
>
> # load and display CONIFERS example plants
> data( plants.swo )
> print( plants.swo )
>
> # create the sample.data list object
> sample.swo.3<- list( plots=plots.swo, plants=plants.swo, age=3, x0=0.0,n.years.projected=0)
> class(sample.swo.3)<- "sample.data"
>
>
> }
>
> \keyword{models}
>
> and the WARNING:
>
> * checking Rd \usage sections ... WARNING
> Assignments in \usage in documentation object 'sample.data':
>    x<- list(plots, plants, age = 0, x0 = 0, n.years.projected = 0)
>    class(x)<- "sample.data"
>
> Functions with \usage entries need to have the appropriate \alias
> entries, and all their arguments documented.
> The \usage entries must correspond to syntactically valid R code.
> See the chapter 'Writing R documentation files' in manual 'Writing R
> Extensions'.
> * checking Rd contents ... OK
>
>
>
> Respectfully,
> Jeff.
>
>
> Jeff Hamann, PhD
> PO Box 1421
> Corvallis, Oregon 97339-1421
> 541-754-2457
> jeff.hamann[at]forestinformatics[dot]com
> jeff.d.hamann[at]gmail[dot]com
> http://www.forestinformatics.com
> http://en.wikipedia.org/wiki/Forest_informatics
>
> To ensure that your email is processed, include a subject entry in your email.
>
>
>
>
> On Jan 6, 2012, at 11:38 AM, Bryan Hanson wrote:
>
>> Jeff, quick question: is this a data set or a function you are documenting?  What you say sounds like it's data, but the Rd file reads more like a function.  Or are you trying to document a data format/object which stores specific data sets?
>>
>> Let us know, and I'll bet the answer will appear pretty quickly. Bryan
>>
>> ***********
>> Bryan Hanson
>> Professor of Chemistry&  Biochemistry
>> DePauw University
>>
>> On Jan 6, 2012, at 2:11 PM, Jeff Hamann wrote:
>>
>>> I'm trying to update a package and would like to crush a WARNING message for a clean build.
>>>
>>> I've been struggling with this question and haven't gotten any traction on the web either.
>>>
>>> I've got a document file (Rd) that contains the following \usage statement:
>>>
>>> \name{sample.data}
>>> \alias{sample.data}
>>>
>>> \title{CONIFERS forest growth model sample data}
>>>
>>> \description{ A list object of type \code{sample.data} stores all of
>>> the basic information about a \code{\link{data.frame}} object
>>> representing a sample of plants.}
>>>
>>> \usage{
>>> x<- list( plots=data.frame(), plants=data.frame(), age=0, x0=0.0, n.years.projected=0 )
>>> class(x)<- "sample.data"
>>> }
>>>
>>> When I run R CMD check [pkg], I get the following WARNING:
>>>
>>> * checking Rd \usage sections ... WARNING
>>> Assignments in \usage in documentation object 'sample.data':
>>> x<- list(plots, plants, age = 0, x0 = 0, n.years.projected = 0)
>>> class(x)<- "sample.data"
>>>
>>> Functions with \usage entries need to have the appropriate \alias
>>> entries, and all their arguments documented.
>>> The \usage entries must correspond to syntactically valid R code.
>>> See the chapter 'Writing R documentation files' in manual 'Writing R
>>> Extensions'.
>>> * checking Rd contents ... OK
>>>
>>> I'm not sure if there's a problem with the \alias section or the \usage section or both sections (I'm assuming this is the case).
>>>
>>> I've read the Chapter 2 of R-ext.pdf plenty and just can't seem to see where I'm blowing it.
>>>
>>> Respectfully,
>>> Jeff.
>>>
>>>
>>> Jeff Hamann, PhD
>>> PO Box 1421
>>> Corvallis, Oregon 97339-1421
>>> 541-754-2457
>>> jeff.hamann[at]forestinformatics[dot]com
>>> jeff.d.hamann[at]gmail[dot]com
>>> http://www.forestinformatics.com
>>> http://en.wikipedia.org/wiki/Forest_informatics
>>>
>>> To ensure that your email is processed, include a subject entry in your email.
>>>
>>>
>>>
>>>
>>>
>>> 	[[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From wdunlap at tibco.com  Fri Jan  6 21:23:38 2012
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 6 Jan 2012 20:23:38 +0000
Subject: [Rd] delete.response leaves response in attribute dataClasses
In-Reply-To: <CAErODj8210v5vS+xQcLxhrdd_opanptoWaUKWKzwbgryYzSe_g@mail.gmail.com>
References: <CAErODj9Aibpb4M=xq9+hHKw6Qurphxb2O7nb4A8x=F3UxPZLgA@mail.gmail.com>
	<E66794E69CFDE04D9A70842786030B932574D6@PA-MBX03.na.tibco.com>
	<E66794E69CFDE04D9A70842786030B932574F5@PA-MBX03.na.tibco.com>
	<CAErODj8210v5vS+xQcLxhrdd_opanptoWaUKWKzwbgryYzSe_g@mail.gmail.com>
Message-ID: <E66794E69CFDE04D9A70842786030B93257A97@PA-MBX03.na.tibco.com>

> -----Original Message-----
> From: Paul Johnson [mailto:pauljohn32 at gmail.com]
> Sent: Friday, January 06, 2012 11:17 AM
> To: William Dunlap
> Cc: R Devel List
> Subject: Re: [Rd] delete.response leaves response in attribute dataClasses
> 
> Thanks, Bill
> 
> Counter-arguments at the end
> 
> On Thu, Jan 5, 2012 at 3:15 PM, William Dunlap <wdunlap at tibco.com> wrote:
> > My feeling that everyone would index dataClasses by name was
> > wrong. ?I looked through the packages that used dataClasses
> > and saw code that would break if the first (response) entry
> > were omitted. ?(I didn't check to see if passing the output
> > of delete.response to these functions would be appropriate.)
> > E.g.,
> > file: AICcmodavg/R/predictSE.mer.r
> > ?##matrix with info on factors
> > ?fact.frame <- attr(attr(orig.frame, "terms"), "dataClasses")[-1]
> >
> > ?##continue if factors
> > ?if(any(fact.frame == "factor")) {
> > ? ?id.factors <- which(fact.frame == "factor")
> > ? ?fact.name <- names(fact.frame)[id.factors] #identify the rows for factors
> >
> > Some packages create a dataClass attribute for a model.frame
> > (not its terms attribute) that does not have any names:
> > file: caper/R/macrocaic.R
> > ? attr(mf, "dataClasses") <- rep("numeric", dim(termFactors)[2])
> > .checkMFClasses() does not throw an error for that, but it
> > doesn't do any real checking either.
> >
> > Most users of dataClasses do pass it to .checkMFClasses() to
> > compare it with newdata and that doesn't care if you have extra
> > entries in dataClasses.
> >
> > Bill Dunlap
> > Spotfire, TIBCO Software
> > wdunlap tibco.com
> >
> 
> I can't understand what your point is.  I agree we can work around the
> problem, but why should we have to?

I guess my point was that it would make sense for delete.response
to drop the response element from dataClasses, as it has no use.
It was almost certainly an oversight that it wasn't dropped, as most
terms objects don't have the dataClasses attribute.

Properly written code, which only subscripted dataClasses by name
(not by number) would not be affected by the change but improperly
written code (e.g., AICcmodavg's predictSE, which assumes the response
is in position 1) would be adversely affected in the unlikely case that
someone passed it the output of delete.response.

I don't know how much you want to cater to "errors" by package writers.

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com 



> 
> If you confine yourself to the output of "delete.response" applied to
> a terms object from a regression, can you point to any package or
> usage that depends on leaving the response variable in the dataClasses
> attribute?  I can't find one.  In R base, these are all the references
> to delete.response:
> 
> stats/R/models.R:delete.response <- function (termobj)
> stats/R/lm.R:        Terms <- delete.response(tt)
> stats/R/lm.R:        Terms <- delete.response(tt)
> stats/R/ppr.R:        Terms <- delete.response(object$terms)
> stats/R/loess.R:
> as.matrix(model.frame(delete.response(terms(object)), newdata,
> stats/R/dummy.coef.R:    Terms <- delete.response(Terms)
> 
> I've looked it over carefully and predict.lm (in lm.R) would not be
> affected by the change I propose. I can't find any usage in loess.R of
> the dataClasses attribute.
> 
> Furthermore, I can't see how a person would use the dataClasses
> attribute at all, after the other markers of the response are
> eliminated. How is a method to find which variable is the response,
> after response=0?
> 
> I'm not disagreeing with you that I can workaround the peculiarity
> that the response is left in the dataClasses attribute of the output
> object from delete.response.  I'm just saying it is a complication
> that programmers should not have to put up with, because I think
> delete.response should delete the response from all attributes of a
> terms object.
> 
> pj
> 
> 
> --
> Paul E. Johnson
> Professor, Political Science
> 1541 Lilac Lane, Room 504
> University of Kansas


From bbolker at gmail.com  Fri Jan  6 21:24:53 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 6 Jan 2012 15:24:53 -0500
Subject: [Rd] pointers on including SVN revision number in package info?
Message-ID: <4F075895.3030509@gmail.com>


  I'm trying to keep debugging of a development package relatively sane.

  I see that some packages manage to incorporate what appears to be
Subversion (SVN) revision information in the package description; for
example,

> library(MASS)
> sessionInfo()$otherPkgs$MASS$Revision
[1] "$Rev: 3016 $"

  which looks like an auto-generated revision number.

  On the other hand, the rgl package (for example) appears to manually
encode the SVN revision in the package number:

> library(rgl)
> sessionInfo()$otherPkgs$rgl$Version
[1] "0.92.829"

  I'd love an automatic strategy, if possible, so I can be lazy about
updating the DESCRIPTION file every time I commit a change to SVN ...
I searched the R extensions manual (and the r-forge manual), but I'm
sure I could have missed something ...

  Or can people suggest other useful strategies for keeping track of
which development (micro-)version a random user might be working with?

 thanks,
  Ben Bolker


From kapelner at gmail.com  Fri Jan  6 21:23:57 2012
From: kapelner at gmail.com (kapelner)
Date: Fri, 6 Jan 2012 12:23:57 -0800 (PST)
Subject: [Rd] rJava System.out / System.err & stacktraces
Message-ID: <1325881437130-4270712.post@n4.nabble.com>

Hi,

Is there any way to initialize rJava so it can print System.out and
System.err to console? Also, is there any way to see stack traces? Otherwise
we're limited to just seeing:

> .jcall(machine, "V", "Build")
> .jcheck()
Error: java.lang.IndexOutOfBoundsException: Index: 0, Size: 0

which doesn't tell me much about the problem nor where the problem occurred
in the Java code.

If there's no way to do this, I'm just going to have to send every
System.out/err statement in my code to a log file which is a very ugly way
of doing debugging.

Thanks,
Adam


--
View this message in context: http://r.789695.n4.nabble.com/rJava-System-out-System-err-stacktraces-tp4270712p4270712.html
Sent from the R devel mailing list archive at Nabble.com.


From ripley at stats.ox.ac.uk  Fri Jan  6 21:37:39 2012
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 06 Jan 2012 20:37:39 +0000
Subject: [Rd] pointers on including SVN revision number in package info?
In-Reply-To: <4F075895.3030509@gmail.com>
References: <4F075895.3030509@gmail.com>
Message-ID: <4F075B93.5020105@stats.ox.ac.uk>

On 06/01/2012 20:24, Ben Bolker wrote:
>
>    I'm trying to keep debugging of a development package relatively sane.
>
>    I see that some packages manage to incorporate what appears to be
> Subversion (SVN) revision information in the package description; for
> example,
>
>> library(MASS)
>> sessionInfo()$otherPkgs$MASS$Revision
> [1] "$Rev: 3016 $"
>
>    which looks like an auto-generated revision number.
>
>    On the other hand, the rgl package (for example) appears to manually
> encode the SVN revision in the package number:
>
>> library(rgl)
>> sessionInfo()$otherPkgs$rgl$Version
> [1] "0.92.829"
>
>    I'd love an automatic strategy, if possible, so I can be lazy about
> updating the DESCRIPTION file every time I commit a change to SVN ...
> I searched the R extensions manual (and the r-forge manual), but I'm
> sure I could have missed something ...

The Subversion book?  The MASS/DESCRIPTION file has

gannet% svn proplist DESCRIPTION
Properties on 'DESCRIPTION':
   svn:keywords

Note this only tracks the version when DESCRIPTION is changed, not what 
anything else is updated.  But then I change the DESCRIPTION file 
immediately before release.

>    Or can people suggest other useful strategies for keeping track of
> which development (micro-)version a random user might be working with?
>
>   thanks,
>    Ben Bolker
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From edd at debian.org  Fri Jan  6 22:09:39 2012
From: edd at debian.org (Dirk Eddelbuettel)
Date: Fri, 6 Jan 2012 15:09:39 -0600
Subject: [Rd] pointers on including SVN revision number in package info?
In-Reply-To: <4F075B93.5020105@stats.ox.ac.uk>
References: <4F075895.3030509@gmail.com>
	<4F075B93.5020105@stats.ox.ac.uk>
Message-ID: <20231.25363.848636.523979@max.nulle.part>


On 6 January 2012 at 20:37, Prof Brian Ripley wrote:
| The Subversion book?  The MASS/DESCRIPTION file has
| 
| gannet% svn proplist DESCRIPTION
| Properties on 'DESCRIPTION':
|    svn:keywords

Yep, I do the same for the $Date$ property in my DESCRIPTION files.  Upon
commit of the file (eg when incrementing the minor version), the date gets
updated automagically.  You have to set the Date property, which even has its
own sub-menu if you happen to use the psvn mode under the One True Editor (TM).
 
Eg for the most recent Rcpp:

   Date: $Date: 2011-12-25 14:14:33 -0600 (Sun, 25 Dec 2011) $

and the two $ signs give it away if you know these SVN tricks...

| Note this only tracks the version when DESCRIPTION is changed, not what 
| anything else is updated.  But then I change the DESCRIPTION file 
| immediately before release.

Correct.

The flipside is that you can also add $Revision$, $URL$, ... to each R source
file individually, and they all get their own stamps.  I luuuv monotonically
increasing SVN revs, but some git fanboy will surely chime in within the hour
and tell me that I am off my rocker. ;-)
 
| >    Or can people suggest other useful strategies for keeping track of
| > which development (micro-)version a random user might be working with?

You cannot do something simple

    Version: 0.2.3.$Revision$

because the $ will stay there, as discussed above. But you can filter.  In
the littler sources we do this with a helper script (which I include below).
That gets us this revision display with an autocreated header file:

   edd at max:~$ r --version | head -2
   r ('littler') version 0.1.5
   	   svn revision 185 as of 2011-09-17 09:35:56
   edd at max:~$ 

You can use the other magic keywords listed in section "Keyword Substitution"
in Chapter 3: "Advanced Topics" of the SVN book which Brian Ripley already
pointed to.

Dirk

-- 
"Outside of a dog, a book is a man's best friend. Inside of a dog, it is too
dark to read." -- Groucho Marx


From murdoch.duncan at gmail.com  Fri Jan  6 22:45:42 2012
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 6 Jan 2012 16:45:42 -0500
Subject: [Rd] pointers on including SVN revision number in package info?
In-Reply-To: <4F075895.3030509@gmail.com>
References: <4F075895.3030509@gmail.com>
Message-ID: <4F076B86.2010008@gmail.com>

On 12-01-06 3:24 PM, Ben Bolker wrote:
>
>    I'm trying to keep debugging of a development package relatively sane.
>
>    I see that some packages manage to incorporate what appears to be
> Subversion (SVN) revision information in the package description; for
> example,
>
>> library(MASS)
>> sessionInfo()$otherPkgs$MASS$Revision
> [1] "$Rev: 3016 $"
>
>    which looks like an auto-generated revision number.
>
>    On the other hand, the rgl package (for example) appears to manually
> encode the SVN revision in the package number:
>
>> library(rgl)
>> sessionInfo()$otherPkgs$rgl$Version
> [1] "0.92.829"

Yes, those are done manually.

>    I'd love an automatic strategy, if possible, so I can be lazy about
> updating the DESCRIPTION file every time I commit a change to SVN ...
> I searched the R extensions manual (and the r-forge manual), but I'm
> sure I could have missed something ...

I'd like one that produced an R version number directly, but I think 
Dirk's script is the only way to do it, and I forget how to use such 
scripts five minutes after I write them.

>
>    Or can people suggest other useful strategies for keeping track of
> which development (micro-)version a random user might be working with?

R-forge sometimes gets out of sync in what it displays as the revision, 
the Version, and what it actually offers as the "Package source" (let 
alone binaries), so I find putting the revision into the version number 
very helpful.  But I often forget to do it...

Duncan Murdoch

>
>   thanks,
>    Ben Bolker
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From edd at debian.org  Fri Jan  6 23:59:17 2012
From: edd at debian.org (Dirk Eddelbuettel)
Date: Fri, 6 Jan 2012 16:59:17 -0600
Subject: [Rd] pointers on including SVN revision number in package info?
In-Reply-To: <4F076B86.2010008@gmail.com>
References: <4F075895.3030509@gmail.com>
	<4F076B86.2010008@gmail.com>
Message-ID: <20231.31941.488263.523839@max.nulle.part>


On 6 January 2012 at 16:45, Duncan Murdoch wrote:
| I'd like one that produced an R version number directly, but I think 
| Dirk's script is the only way to do it, and I forget how to use such 
| scripts five minutes after I write them.

And I of course forgot to include the little script once written for
littler; now below.

For Rcpp and RInside, I wrote little ad-hoc release helper scripts to also
run doxygen, copy vignettes and tarballs to webfolders etc pp. If you do
that, you have a hook -- but then you'd have to run this once pre-commit /
build.

| R-forge sometimes gets out of sync in what it displays as the revision, 
| the Version, and what it actually offers as the "Package source" (let 
| alone binaries), so I find putting the revision into the version number 
| very helpful.  But I often forget to do it...

Scripts can help. Somewhat.

Dirk

PS The ad-hoc script 'bootstrap' from littler is below.  

#!/bin/bash -e

call_svnversion() {
    svnrevision=`LC_ALL=C svn info | awk '/^Revision:/ {print $2}'`
    svndate=`LC_ALL=C svn info | awk '/^Last Changed Date:/ {print $4,$5}'`

    now=`date`

    if [ "$svnrevision" != "" ]; then
	if [ "$svndate" != "" ]; then
	    cat <<EOF > svnversion.h

// Do not edit!  This file was autogenerated 
//      by $0 
//      on $now
//
// svnrevision and svndate are as reported by svn at that point in time,
// compiledate and compiletime are being filled gcc at compilation

#include <stdlib.h>
 
static const char* svnrevision = "$svnrevision";
static const char* svndate = "$svndate";
static const char* compiletime = __TIME__;
static const char* compiledate = __DATE__;

EOF
	fi
    fi
}

if [ "$#" -ge 0 ]; then
    if [ "$1" = "--svnversion" ]; then
        # added hoops: make sure we only call this when we have a 
	# svn binary in the path ... so that this does not get called
	# on machines that do not have svn
	set +e
	svnprog=`type -p svn`
	set -e
	if [ "${svnprog}" != "" ]; then
	    call_svnversion 
	fi
	exit
    fi
fi

test -f svnversion.h || call_svnversion
aclocal 
autoheader 
automake 
autoconf 
./configure 
make


-- 
"Outside of a dog, a book is a man's best friend. Inside of a dog, it is too
dark to read." -- Groucho Marx


From Roger.bivand at nhh.no  Sat Jan  7 14:10:49 2012
From: Roger.bivand at nhh.no (Roger Bivand)
Date: Sat, 7 Jan 2012 13:10:49 +0000
Subject: [Rd] pointers on including SVN revision number in package info?
References: <4F075895.3030509@gmail.com>
Message-ID: <loom.20120107T135826-429@post.gmane.org>

Ben Bolker <bbolker <at> gmail.com> writes:

> 
> 
>   I'm trying to keep debugging of a development package relatively sane.
> 
...
> 
>   Or can people suggest other useful strategies for keeping track of
> which development (micro-)version a random user might be working with?
> 

Rather than update the DESCRIPTION file, rgeos includes the SVN revision 
in the startup messages, by copying in ./configure (here ./configure.in):

if test -e ".svn" ; then
  svnversion -n > inst/SVN_VERSION
fi

and testing for the file in R/AAA.R:

  fn <- system.file("SVN_VERSION", package="rgeos")
  if (file.exists(fn)) {
    svn_version <- scan(system.file("SVN_VERSION", package="rgeos"),
      what=character(1), sep="\n", quiet=TRUE)
  } else {
    svn_version <- "(unknown)"
  }

Clunky, and inst/SVN_VERSION isn't in svn itself, but it does work if the 
build machine uses SVN and is up-to-date. I think I'll try to use the
DESCRIPTION Revision tag too. Naturally, this is feasible in packages 
using ./configure already. The package is on R-Forge, so the implicated 
files can be browsed online.

Roger

>  thanks,
>   Ben Bolker
> 
>


From hankin.robin at gmail.com  Sun Jan  8 20:58:55 2012
From: hankin.robin at gmail.com (robin hankin)
Date: Mon, 9 Jan 2012 08:58:55 +1300
Subject: [Rd] seq_along and rep_along
In-Reply-To: <CABdHhvHPOjrKBKimuJ9F++YcXXL2y9Mn+LghAHo8k1qSc1gTDg@mail.gmail.com>
References: <CABdHhvEUtWfj6+2kT6fsD5CYgx66g1+C5gNhdLTA0M60Dw+YbQ@mail.gmail.com>
	<4F074B28.8020307@gmail.com>
	<CABdHhvHPOjrKBKimuJ9F++YcXXL2y9Mn+LghAHo8k1qSc1gTDg@mail.gmail.com>
Message-ID: <CAHHjBM6J2PvGd-ZRYF6rrAzcrbNZn7-t488yawO=cPJDfonpcw@mail.gmail.com>

hello folks

[snip]

> but it is frustrating when base
> functionality only works with vectors, not matrices, or arrays. It
> would be more compelling if (e.g.) t and rev also had dimension
> arguments.
>
> Hadley
>
> --

well put!  I would add, though, that t() generalizes to aperm(),
and the magic package contains  arev()  which is a generalization
of rev().

I'm always on the lookout for other array functionality of this type
that might sit well with magic.  Anyone?

best wishes

Robin




> Assistant Professor / Dobelman Family Junior Chair
> Department of Statistics / Rice University
> http://had.co.nz/
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel



-- 
Robin Hankin
Uncertainty Analyst
hankin.robin at gmail.com


From hadley at rice.edu  Mon Jan  9 01:24:48 2012
From: hadley at rice.edu (Hadley Wickham)
Date: Sun, 8 Jan 2012 18:24:48 -0600
Subject: [Rd] seq_along and rep_along
In-Reply-To: <CAHHjBM6J2PvGd-ZRYF6rrAzcrbNZn7-t488yawO=cPJDfonpcw@mail.gmail.com>
References: <CABdHhvEUtWfj6+2kT6fsD5CYgx66g1+C5gNhdLTA0M60Dw+YbQ@mail.gmail.com>
	<4F074B28.8020307@gmail.com>
	<CABdHhvHPOjrKBKimuJ9F++YcXXL2y9Mn+LghAHo8k1qSc1gTDg@mail.gmail.com>
	<CAHHjBM6J2PvGd-ZRYF6rrAzcrbNZn7-t488yawO=cPJDfonpcw@mail.gmail.com>
Message-ID: <CABdHhvGVZo2GLwNrPpZpUOgqMr3Gv76_5_d_8u5jOrTX_d92_A@mail.gmail.com>

> well put! ?I would add, though, that t() generalizes to aperm(),
> and the magic package contains ?arev() ?which is a generalization
> of rev().

There are the flip operators of matlab, and rotating matrices/array by
multiples of 90 degrees.

> I'm always on the lookout for other array functionality of this type
> that might sit well with magic. ?Anyone?

Have you considered pulling out the matric manipulation functions from
magic?  I think they'd do well in their own package, and would be more
findable.

Hadley

-- 
Assistant Professor / Dobelman Family Junior Chair
Department of Statistics / Rice University
http://had.co.nz/


From hankin.robin at gmail.com  Mon Jan  9 02:55:13 2012
From: hankin.robin at gmail.com (robin hankin)
Date: Mon, 9 Jan 2012 14:55:13 +1300
Subject: [Rd] seq_along and rep_along
In-Reply-To: <CABdHhvGVZo2GLwNrPpZpUOgqMr3Gv76_5_d_8u5jOrTX_d92_A@mail.gmail.com>
References: <CABdHhvEUtWfj6+2kT6fsD5CYgx66g1+C5gNhdLTA0M60Dw+YbQ@mail.gmail.com>
	<4F074B28.8020307@gmail.com>
	<CABdHhvHPOjrKBKimuJ9F++YcXXL2y9Mn+LghAHo8k1qSc1gTDg@mail.gmail.com>
	<CAHHjBM6J2PvGd-ZRYF6rrAzcrbNZn7-t488yawO=cPJDfonpcw@mail.gmail.com>
	<CABdHhvGVZo2GLwNrPpZpUOgqMr3Gv76_5_d_8u5jOrTX_d92_A@mail.gmail.com>
Message-ID: <CAHHjBM6wpmDVmR6JUfGmaR=xuxn+EFVdFO1SWUNTGW9jL1NWWQ@mail.gmail.com>

hello Hadley

thanks for this...


> There are the flip operators of matlab, and rotating matrices/array by
> multiples of 90 degrees.
>

arot() in the magic package does this (which is an operation
frequently encountered in magic hypercubes)


>> I'm always on the lookout for other array functionality of this type
>> that might sit well with magic. ?Anyone?
>
> Have you considered pulling out the matric manipulation functions from
> magic? ?I think they'd do well in their own package, and would be more
> findable.
>


That is a very good idea.  I have fought shy of this because the array
functionality of the magic package didn't seem to be enough to
justify a package of its own, but maybe that isn't true any more.
And I must say that the majority of user comments on the magic package
are in relation to functions such as arot() and adiag()  and apad()
and aplus() etc etc that are not specific to magic hypercubes.

Does the List have any comments?

rksh





> Hadley
>
> --
> Assistant Professor / Dobelman Family Junior Chair
> Department of Statistics / Rice University
> http://had.co.nz/



-- 
Robin Hankin
Uncertainty Analyst
hankin.robin at gmail.com


From ripley at stats.ox.ac.uk  Mon Jan  9 09:28:37 2012
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 09 Jan 2012 08:28:37 +0000
Subject: [Rd] Updated Windows toolchain
In-Reply-To: <alpine.LFD.2.02.1111281109480.16728@toucan.stats.ox.ac.uk>
References: <alpine.LFD.2.02.1111281109480.16728@toucan.stats.ox.ac.uk>
Message-ID: <4F0AA535.4030006@stats.ox.ac.uk>

CRAN Windows binary packages built for R-devel are now online, and Uwe's 
winbuilder has gained the ability to check source packages under R-devel.

Windows check results are available from
http://cran.r-project.org/bin/windows/contrib/checkSummaryWin.html
and in due course from the main CRAN check page.

There have been a few updates to the toolchain:

(i) It is now based on a beta of gcc 4.6.3, and so reports almost the 
same compilation warnings/errors as the CRAN check machines.

(ii) There are various bug-fixes to the toolchain: notably x^n and 
exp(x) use gradual underflow to denormal numbers rather than abrubtly 
underflowing to zero.

(iii) This is a 'multilib' toolchain: the compiler is named 'gcc.exe' 
for both architectures, selected by flag -m32 (the default) and -m64.

On 29/11/2011 07:56, Prof Brian Ripley wrote:
> An updated toolchain is now being used for Windows' builds of R-devel:
> details are in the R-admin manual and at
> http://www.murdoch-sutherland.com/Rtools/ and
> http://www.stats.ox.ac.uk/pub/Rtools/
>
> Both 32- and 64-bit parts of the toolchain use v2.0.1 of the Mingw-w64
> project's runtime and a beta of gcc 4.5.4: the Mingw.org project's
> builds are no longer used. This should mean that code which compiles for
> 64-bit Windows also compiles for 32-bit Windows, and v.v. unless code
> makes (incorrect but common) assumptions that pointers fit into longs.
>
> A very few packages will need modifications because they contain
> declarations which clash with the headers in this toolchain: where we
> are aware of problems the maintainers have been informed.
>
> At DLL level different Windows' toolchains should be compatible: at C
> level they mostly are but at C++ level they are pretty much incompatible
> (so that for example GDAL has to be re-compiled for every toolchain: and
> Rcpp users need to be careful to use only one toolchain for Rcpp and
> their packages). All the external software previously made available
> (and more) is made available at http://www.stats.ox.ac.uk/pub/Rtools .
>
> The toolchain has support for OpenMP and pthreads: however OpenMP
> support is not enabled by default in R (it is too slow to be much use).
> If you do make use of it in your packages, be aware that you will need
> to ship the appropriate pthreads DLL(s).
>
> It is expected that there will be several further minor updates prior to
> the release of 2.15.0 in ca 4 months, but this step is the major one.
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From jeroen.ooms at stat.ucla.edu  Mon Jan  9 09:47:29 2012
From: jeroen.ooms at stat.ucla.edu (Jeroen Ooms)
Date: Mon, 9 Jan 2012 00:47:29 -0800
Subject: [Rd] serializing recordedplot object
Message-ID: <CABFfbXvzRJZ-72v6EqyvZyUi4NtNVn-BforTc-2+hP6GxU_Pag@mail.gmail.com>

I use recordPlot() to save plots to disk that I render later to a
variety of formats. This works fine for base R plots and ggplot2
plots, and also used to work for lattice plots. However somewhere in
version 2.14 things stopped working for lattice plots. Here is an
example:

library(lattice);
histogram(rnorm(100));
x <- recordPlot();
saveRDS(x, "myplot.rds");
y <- readRDS("myplot.rds");
print(y);
Error: NULL value passed as symbol address

printing x works fine, but printing y either gives an error or prints
an empty page. The problem seems to be related to serializing the
recordedplot object, which contains a lot of memory pointers. Any tips
or workarounds?

> sessionInfo()
R version 2.14.1 (2011-12-22)
Platform: i686-pc-linux-gnu (32-bit)

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
 [7] LC_PAPER=C                 LC_NAME=C
 [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] lattice_0.20-0

loaded via a namespace (and not attached):
[1] grid_2.14.1


From gallon at mnhn.fr  Mon Jan  9 14:59:55 2012
From: gallon at mnhn.fr (Gallon =?iso-8859-1?b?UulnaXM=?=)
Date: Mon, 09 Jan 2012 14:59:55 +0100
Subject: [Rd] problem with R installation package
Message-ID: <20120109145955.35226bbrlrp57fff@vdmz1mail.ifremer.fr>

Dear,

I have created my first package "G2Sd : Grain Size Statistiques and  
Description". I submitted it to the CRAN after I have checked the  
tar.gz file. All was ok, but since it is on the CRAN I can't install  
it :

In getDependencies(pkgs, dependencies, available, lib) :
   package ?G2Sd? is not available (for R version 2.13.2)

I've got the same message with R 2.14.1.

In the description file, I wrote in the "Depends" item R (>=2.10.0)
In the namespace file :
  import("stats","graphics")
  export(granstat,granplot)

Can you help me?

Regis




________________________________________

R?gis GALLON
Doctorant MNHN

Station Marine de Dinard
Centre de recherche et d'enseignement sur les ?cosyst?mes c?tiers
38 rue du Port Blanc, 35800 Dinard.
----------
PhD student
French national museum of natural history

Dinard Marine Station
Center for research and teaching on coastal ecosystem
38 rue du port blanc,
35800 Dinard, FRANCE

web : http://regisgallon.wordpress.com/
T?l : +33 (0)2 23 18 58 85
Fax : +33 (0)2 23 18 58 80
Port : +33 (0)6 60 84 38 12


From dtenenba at fhcrc.org  Mon Jan  9 22:54:53 2012
From: dtenenba at fhcrc.org (Dan Tenenbaum)
Date: Mon, 9 Jan 2012 13:54:53 -0800
Subject: [Rd] problem with R installation package
In-Reply-To: <20120109145955.35226bbrlrp57fff@vdmz1mail.ifremer.fr>
References: <20120109145955.35226bbrlrp57fff@vdmz1mail.ifremer.fr>
Message-ID: <CAF42j22HBVEK5Ha5mfRcZ1J9MmDMm7p00bjbngK9TWnGt91H_g@mail.gmail.com>

2012/1/9 Gallon R?gis <gallon at mnhn.fr>:
> Dear,
>
> I have created my first package "G2Sd : Grain Size Statistiques and
> Description". I submitted it to the CRAN after I have checked the tar.gz
> file. All was ok, but since it is on the CRAN I can't install it :
>
> In getDependencies(pkgs, dependencies, available, lib) :
> ?package ?G2Sd? is not available (for R version 2.13.2)
>
> I've got the same message with R 2.14.1.
>
> In the description file, I wrote in the "Depends" item R (>=2.10.0)
> In the namespace file :
> ?import("stats","graphics")
> ?export(granstat,granplot)
>
> Can you help me?
>

Looks like it hasn't (yet) build for all platforms; try
install.packages("G2Sd", type="source")

Dan


> Regis
>
>
>
>
> ________________________________________
>
> R?gis GALLON
> Doctorant MNHN
>
> Station Marine de Dinard
> Centre de recherche et d'enseignement sur les ?cosyst?mes c?tiers
> 38 rue du Port Blanc, 35800 Dinard.
> ----------
> PhD student
> French national museum of natural history
>
> Dinard Marine Station
> Center for research and teaching on coastal ecosystem
> 38 rue du port blanc,
> 35800 Dinard, FRANCE
>
> web : http://regisgallon.wordpress.com/
> T?l : +33 (0)2 23 18 58 85
> Fax : +33 (0)2 23 18 58 80
> Port : +33 (0)6 60 84 38 12
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From jeroenooms at gmail.com  Mon Jan  9 22:56:44 2012
From: jeroenooms at gmail.com (Jeroen Ooms)
Date: Mon, 9 Jan 2012 13:56:44 -0800 (PST)
Subject: [Rd] problem with R installation package
In-Reply-To: <20120109145955.35226bbrlrp57fff@vdmz1mail.ifremer.fr>
References: <20120109145955.35226bbrlrp57fff@vdmz1mail.ifremer.fr>
Message-ID: <1326146204616-4280212.post@n4.nabble.com>

Hi Regis,

As you can see on the cran page of your package, no binaries have been build
yet for windows or osx. This can take a couple of days, you have to be
patient. For now you can install your package from source using:

install.packages("G2Sd", type="source")

ps: This is a question for the r-help mailing list, not r-devel.

--
View this message in context: http://r.789695.n4.nabble.com/problem-with-R-installation-package-tp4280190p4280212.html
Sent from the R devel mailing list archive at Nabble.com.


From Mark.Bravington at csiro.au  Tue Jan 10 02:05:44 2012
From: Mark.Bravington at csiro.au (Mark.Bravington at csiro.au)
Date: Tue, 10 Jan 2012 12:05:44 +1100
Subject: [Rd] S4 summary method not being called (VGAM)
Message-ID: <3D59DF35E7CF3E42BA70C23BD5CBE6A85F6DA93028@exvic-mbx04.nexus.csiro.au>

The symptom triggering this email is that an S4 summary method sometimes refuses to be invoked, even when a package is explicitly loaded, if the first load of the package is implicit. It may or may not be specific to 'summary' methods and/or the 'VGAM' package. I've sent to R-devel because (i) it looks like some kind of bug to me, but I'm not sure; (ii) it's not something I personally need any help with; and (iii) it seems a bit specialized for R-help.

Here's the case notes. I have an object 'nf1' of S4 class 'vglm', created by calling 'vglm(...)' from package 'VGAM' (you can create your own from the examples in VGAM). It's save()d into a file "nf1.rda". If I start a new R session, call 'library( VGAM)', and then 'load("nf1.rda")', then 'summary(nf1)' works fine. But if instead I start a pretty basic R session and load() the file *without* having explicitly called library( VGAM), the summary method for 'vglm' doesn't get called whether or not I subsequently call library( VGAM). Transcript below.

I'm using R 2.13.2 on Windows XP, VGAM 0.8-4. The same thing happens with R 2.15 devel v57866.

bye
Mark

Mark Bravington
CSIRO CMIS
Marine Lab
Hobart
Australia


#############################
# Start a basic R session, and then:

>  search()
 [1] ".GlobalEnv"        "package:stats4"    "package:splines"   "package:stats"     "package:graphics" 
 [6] "package:grDevices" "package:utils"     "package:datasets"  "package:methods"   "Autoloads"         "package:base" 

> print( load( "nf1.rda")) # which should implicitly load VGAM, but not attach it
[1] "nf1"

> search()
# ...snipped. No explicit VGAM

> loadedNamespaces()
# ...snipped. VGAM is there at the end.

> nf1
Call:
vglm(formula = form, family = posbinomial, data = data, trace = TRUE)

Coefficients:
# ...snipped. The print() or show() or whatever method seems to get called OK

> summary( nf1)
Length  Class   Mode 
     1   vglm     S4 

# Hmmm... default method is being called, that's wrong. Try explicitly attaching 'VGAM':

> library( VGAM)
Loading required package: splines
Loading required package: stats4

Attaching package: 'VGAM'

The following object(s) are masked from 'package:splines':

    bs, ns

The following object(s) are masked from 'package:stats':

    biplot, case.names, coefficients, df.residual, fitted, fitted.values, formula, poly, residuals,
    variable.names, weights

The following object(s) are masked from 'package:base':

    identity, print, scale.default

> summary( nf1)
Length  Class   Mode 
     1   vglm     S4 
# Hmmm... even though VGAM is on the search path etc, the wrong method is being called 

###############################


From jeroen.ooms at stat.ucla.edu  Tue Jan 10 07:06:13 2012
From: jeroen.ooms at stat.ucla.edu (Jeroen Ooms)
Date: Mon, 9 Jan 2012 22:06:13 -0800
Subject: [Rd] serializing recordedplot object
In-Reply-To: <CABFfbXvzRJZ-72v6EqyvZyUi4NtNVn-BforTc-2+hP6GxU_Pag@mail.gmail.com>
References: <CABFfbXvzRJZ-72v6EqyvZyUi4NtNVn-BforTc-2+hP6GxU_Pag@mail.gmail.com>
Message-ID: <CABFfbXu9mycTn0Ctt1Rsre7JwF5+cxjkeJeLrTOOF9Cov_H9sw@mail.gmail.com>

The underlying problem turns out to be serialization of objects of
class "NativeSymbolInfo". When these are serialized and unserialized,
the memory address turns into a nullpointer, causing the fail.?To fix
it, one can simply create new nativeSymbolInfo objects. E.g:

# The old example:
library(lattice);
histogram(rnorm(100));
x <- recordPlot();
saveRDS(x, "myplot.rds");
y <- readRDS("myplot.rds");

# y contains nullpointers making it fail.
print(y);

# To fix:
for(i in 1:length(y[[1]])) {
? if( "NativeSymbolInfo" %in% class(y[[1]][[i]][[2]][[1]]) ){
? ? y[[1]][[i]][[2]][[1]] <- getNativeSymbolInfo(y[[1]][[i]][[2]][[1]]$name);
? }
}
print(y);

Now this works, but it is a bit ugly. Is there a more general method
of serializing objects in a way that native objects are restored where
possible?






On Mon, Jan 9, 2012 at 12:47 AM, Jeroen Ooms <jeroen.ooms at stat.ucla.edu> wrote:
>
> I use recordPlot() to save plots to disk that I render later to a
> variety of formats. This works fine for base R plots and ggplot2
> plots, and also used to work for lattice plots. However somewhere in
> version 2.14 things stopped working for lattice plots. Here is an
> example:
>
> library(lattice);
> histogram(rnorm(100));
> x <- recordPlot();
> saveRDS(x, "myplot.rds");
> y <- readRDS("myplot.rds");
> print(y);
> Error: NULL value passed as symbol address
>
> printing x works fine, but printing y either gives an error or prints
> an empty page. The problem seems to be related to serializing the
> recordedplot object, which contains a lot of memory pointers. Any tips
> or workarounds?
>
> > sessionInfo()
> R version 2.14.1 (2011-12-22)
> Platform: i686-pc-linux-gnu (32-bit)
>
> locale:
> ?[1] LC_CTYPE=en_US.UTF-8 ? ? ? LC_NUMERIC=C
> ?[3] LC_TIME=en_US.UTF-8 ? ? ? ?LC_COLLATE=en_US.UTF-8
> ?[5] LC_MONETARY=en_US.UTF-8 ? ?LC_MESSAGES=en_US.UTF-8
> ?[7] LC_PAPER=C ? ? ? ? ? ? ? ? LC_NAME=C
> ?[9] LC_ADDRESS=C ? ? ? ? ? ? ? LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats ? ? graphics ?grDevices utils ? ? datasets ?methods ? base
>
> other attached packages:
> [1] lattice_0.20-0
>
> loaded via a namespace (and not attached):
> [1] grid_2.14.1


From maechler at stat.math.ethz.ch  Tue Jan 10 09:16:13 2012
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 10 Jan 2012 09:16:13 +0100
Subject: [Rd] problem with R installation package
In-Reply-To: <1326146204616-4280212.post@n4.nabble.com>
References: <20120109145955.35226bbrlrp57fff@vdmz1mail.ifremer.fr>
	<1326146204616-4280212.post@n4.nabble.com>
Message-ID: <20235.62413.93361.761262@stat.math.ethz.ch>

>>>>> Jeroen Ooms <jeroenooms at gmail.com>
>>>>>     on Mon, 9 Jan 2012 13:56:44 -0800 writes:

    > Hi Regis,

    > As you can see on the cran page of your package, no binaries have been build
    > yet for windows or osx. This can take a couple of days, you have to be
    > patient. For now you can install your package from source using:

    > install.packages("G2Sd", type="source")

    > ps: This is a question for the r-help mailing list, not r-devel.

Yes, indeed!

Martin Maechler


From ripley at stats.ox.ac.uk  Tue Jan 10 11:39:24 2012
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 10 Jan 2012 10:39:24 +0000
Subject: [Rd] CRAN binary packages (was problem with R installation
	package)
In-Reply-To: <20235.62413.93361.761262@stat.math.ethz.ch>
References: <20120109145955.35226bbrlrp57fff@vdmz1mail.ifremer.fr>
	<1326146204616-4280212.post@n4.nabble.com>
	<20235.62413.93361.761262@stat.math.ethz.ch>
Message-ID: <4F0C155C.9000005@stats.ox.ac.uk>

On 10/01/2012 08:16, Martin Maechler wrote:
>>>>>> Jeroen Ooms<jeroenooms at gmail.com>
>>>>>>      on Mon, 9 Jan 2012 13:56:44 -0800 writes:
>
>      >  Hi Regis,
>
>      >  As you can see on the cran page of your package, no binaries have been build
>      >  yet for windows or osx. This can take a couple of days, you have to be
>      >  patient. For now you can install your package from source using:
>
>      >  install.packages("G2Sd", type="source")
>
>      >  ps: This is a question for the r-help mailing list, not r-devel.
>
> Yes, indeed!
>
> Martin Maechler

Except that for Windows binaries packages, people are asked in several 
places (including the @ReadMe and the rw-FAQ) not to ask about them on 
R-help, and for Mac binary packages only R-sig-mac is possibly appropriate.

There are only a handful of people who could do anything about binary 
packages, and they are very busy people and probably only skim R-help at 
most.  If there really is a problem not explained by impatience or the 
results on the CRAN log page at 
http://cran.r-project.org/web/checks/check_summary.html it would be best 
to contact them directly: but please check carefully that there is not 
yet an explanation on e.g. R-sig-mac.

The whole CRAN process is running close to its human and machine 
resource limits: there are plans afoot to ease some of the pressures, 
but they too need resources to design and implement.

It would help a lot if people would follow the checklist in 'Writing R 
Extensions' and the policies linked from 
http://cran.r-project.org/web/packages/index.html, and in particular not 
submit too-frequent updates and submit tarballs that check cleanly and 
have been checked on win-builder.  And definitely: send a submission 
email mentioning the package in the subject line.

Slightly off-subject (but applied to Regis' submission):  CRAN is 
nowadays taking some NOTEs as more serious, so e.g.

- new submissions are required to have a NAMESPACE file and updates will 
get nagged to add one.

- packages are expected not to call C/C++ assert, abort, exit or FORTRAN 
stop, so please address that before submission.  (The reason this is 
still a NOTE is that there are false positives on some platforms: check 
on Linux if at all possible.)


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From simon.urbanek at r-project.org  Tue Jan 10 15:17:15 2012
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Tue, 10 Jan 2012 09:17:15 -0500
Subject: [Rd] serializing recordedplot object
In-Reply-To: <CABFfbXu9mycTn0Ctt1Rsre7JwF5+cxjkeJeLrTOOF9Cov_H9sw@mail.gmail.com>
References: <CABFfbXvzRJZ-72v6EqyvZyUi4NtNVn-BforTc-2+hP6GxU_Pag@mail.gmail.com>
	<CABFfbXu9mycTn0Ctt1Rsre7JwF5+cxjkeJeLrTOOF9Cov_H9sw@mail.gmail.com>
Message-ID: <7CE3B991-C200-45D5-836F-96E6DE807BCF@r-project.org>


On Jan 10, 2012, at 1:06 AM, Jeroen Ooms wrote:

> The underlying problem turns out to be serialization of objects of
> class "NativeSymbolInfo". When these are serialized and unserialized,
> the memory address turns into a nullpointer, causing the fail. To fix
> it, one can simply create new nativeSymbolInfo objects. E.g:
> 
> # The old example:
> library(lattice);
> histogram(rnorm(100));
> x <- recordPlot();
> saveRDS(x, "myplot.rds");
> y <- readRDS("myplot.rds");
> 
> # y contains nullpointers making it fail.
> print(y);
> 
> # To fix:
> for(i in 1:length(y[[1]])) {
>  if( "NativeSymbolInfo" %in% class(y[[1]][[i]][[2]][[1]]) ){
>    y[[1]][[i]][[2]][[1]] <- getNativeSymbolInfo(y[[1]][[i]][[2]][[1]]$name);
>  }
> }
> print(y);
> 
> Now this works, but it is a bit ugly. Is there a more general method
> of serializing objects in a way that native objects are restored where
> possible?
> 

Unfortunately R doesn't provide a way for this. Without changes to unserialization (on the wishlist for a few years now, but not easy to design) the best you can do is to check the native symbols for NULL pointers on usage and then re-fetch - that's something that could be done reasonably easily, although it's still a hack ...



> 
> 
> 
> 
> 
> On Mon, Jan 9, 2012 at 12:47 AM, Jeroen Ooms <jeroen.ooms at stat.ucla.edu> wrote:
>> 
>> I use recordPlot() to save plots to disk that I render later to a
>> variety of formats. This works fine for base R plots and ggplot2
>> plots, and also used to work for lattice plots. However somewhere in
>> version 2.14 things stopped working for lattice plots. Here is an
>> example:
>> 
>> library(lattice);
>> histogram(rnorm(100));
>> x <- recordPlot();
>> saveRDS(x, "myplot.rds");
>> y <- readRDS("myplot.rds");
>> print(y);
>> Error: NULL value passed as symbol address
>> 
>> printing x works fine, but printing y either gives an error or prints
>> an empty page. The problem seems to be related to serializing the
>> recordedplot object, which contains a lot of memory pointers. Any tips
>> or workarounds?
>> 
>>> sessionInfo()
>> R version 2.14.1 (2011-12-22)
>> Platform: i686-pc-linux-gnu (32-bit)
>> 
>> locale:
>> [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>> [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>> [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>> [7] LC_PAPER=C                 LC_NAME=C
>> [9] LC_ADDRESS=C               LC_TELEPHONE=C
>> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>> 
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>> 
>> other attached packages:
>> [1] lattice_0.20-0
>> 
>> loaded via a namespace (and not attached):
>> [1] grid_2.14.1
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From ripley at stats.ox.ac.uk  Tue Jan 10 15:26:17 2012
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 10 Jan 2012 14:26:17 +0000
Subject: [Rd] serializing recordedplot object
In-Reply-To: <7CE3B991-C200-45D5-836F-96E6DE807BCF@r-project.org>
References: <CABFfbXvzRJZ-72v6EqyvZyUi4NtNVn-BforTc-2+hP6GxU_Pag@mail.gmail.com>
	<CABFfbXu9mycTn0Ctt1Rsre7JwF5+cxjkeJeLrTOOF9Cov_H9sw@mail.gmail.com>
	<7CE3B991-C200-45D5-836F-96E6DE807BCF@r-project.org>
Message-ID: <4F0C4A89.7060103@stats.ox.ac.uk>

I don't think anyone has yet mentioned that the canonical way to save 
lattice plots is to save the object produced by lattice, and print() it 
again when required.

recordPlot was only ever intended to be a temporary expedient, as the 
help page says.

On 10/01/2012 14:17, Simon Urbanek wrote:
>
> On Jan 10, 2012, at 1:06 AM, Jeroen Ooms wrote:
>
>> The underlying problem turns out to be serialization of objects of
>> class "NativeSymbolInfo". When these are serialized and unserialized,
>> the memory address turns into a nullpointer, causing the fail. To fix
>> it, one can simply create new nativeSymbolInfo objects. E.g:
>>
>> # The old example:
>> library(lattice);
>> histogram(rnorm(100));
>> x<- recordPlot();
>> saveRDS(x, "myplot.rds");
>> y<- readRDS("myplot.rds");
>>
>> # y contains nullpointers making it fail.
>> print(y);
>>
>> # To fix:
>> for(i in 1:length(y[[1]])) {
>>   if( "NativeSymbolInfo" %in% class(y[[1]][[i]][[2]][[1]]) ){
>>     y[[1]][[i]][[2]][[1]]<- getNativeSymbolInfo(y[[1]][[i]][[2]][[1]]$name);
>>   }
>> }
>> print(y);
>>
>> Now this works, but it is a bit ugly. Is there a more general method
>> of serializing objects in a way that native objects are restored where
>> possible?
>>
>
> Unfortunately R doesn't provide a way for this. Without changes to unserialization (on the wishlist for a few years now, but not easy to design) the best you can do is to check the native symbols for NULL pointers on usage and then re-fetch - that's something that could be done reasonably easily, although it's still a hack ...
>
>
>
>>
>>
>>
>>
>>
>> On Mon, Jan 9, 2012 at 12:47 AM, Jeroen Ooms<jeroen.ooms at stat.ucla.edu>  wrote:
>>>
>>> I use recordPlot() to save plots to disk that I render later to a
>>> variety of formats. This works fine for base R plots and ggplot2
>>> plots, and also used to work for lattice plots. However somewhere in
>>> version 2.14 things stopped working for lattice plots. Here is an
>>> example:
>>>
>>> library(lattice);
>>> histogram(rnorm(100));
>>> x<- recordPlot();
>>> saveRDS(x, "myplot.rds");
>>> y<- readRDS("myplot.rds");
>>> print(y);
>>> Error: NULL value passed as symbol address
>>>
>>> printing x works fine, but printing y either gives an error or prints
>>> an empty page. The problem seems to be related to serializing the
>>> recordedplot object, which contains a lot of memory pointers. Any tips
>>> or workarounds?
>>>
>>>> sessionInfo()
>>> R version 2.14.1 (2011-12-22)
>>> Platform: i686-pc-linux-gnu (32-bit)
>>>
>>> locale:
>>> [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>>> [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>>> [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>>> [7] LC_PAPER=C                 LC_NAME=C
>>> [9] LC_ADDRESS=C               LC_TELEPHONE=C
>>> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>>>
>>> attached base packages:
>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>
>>> other attached packages:
>>> [1] lattice_0.20-0
>>>
>>> loaded via a namespace (and not attached):
>>> [1] grid_2.14.1
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From jmc at r-project.org  Tue Jan 10 17:43:16 2012
From: jmc at r-project.org (John Chambers)
Date: Tue, 10 Jan 2012 08:43:16 -0800
Subject: [Rd] S4 summary method not being called (VGAM)
In-Reply-To: <3D59DF35E7CF3E42BA70C23BD5CBE6A85F6DA93028@exvic-mbx04.nexus.csiro.au>
References: <3D59DF35E7CF3E42BA70C23BD5CBE6A85F6DA93028@exvic-mbx04.nexus.csiro.au>
Message-ID: <4F0C6AA4.4080102@r-project.org>

A relevant report, not just for VGAM but for maintainers of other 
packages that define methods for functions that have both generic and 
non-generic versions in other packages.

The problem is that VGAM "Depends" on stats4 but does not import from 
it.  So when VGAM is loaded, only the old version of summary() is 
available.  Importing the relevant functions from stats4 in VGAM should 
fix the problem.

With the current R 2.14.1 this happens silently.  With the latest 
r-devel, the installation of VGAM produces a warning:

"Functions for exporting methods must have been made generic, explicitly 
or implicitly; not true when loading 'VGAM' for 'AIC', 'coef', 'logLik', 
'plot', 'summary', 'vcov' "

This implies (a bit obscurely) that the package has generic versions in 
its dependencies, but has not imported them.

Maintainers of CRAN packages should check installation against the 
development version.  Warning messages like this suggest a problem with 
the imports.


John

On 1/9/12 5:05 PM, Mark.Bravington at csiro.au wrote:
> The symptom triggering this email is that an S4 summary method sometimes refuses to be invoked, even when a package is explicitly loaded, if the first load of the package is implicit. It may or may not be specific to 'summary' methods and/or the 'VGAM' package. I've sent to R-devel because (i) it looks like some kind of bug to me, but I'm not sure; (ii) it's not something I personally need any help with; and (iii) it seems a bit specialized for R-help.
>
> Here's the case notes. I have an object 'nf1' of S4 class 'vglm', created by calling 'vglm(...)' from package 'VGAM' (you can create your own from the examples in VGAM). It's save()d into a file "nf1.rda". If I start a new R session, call 'library( VGAM)', and then 'load("nf1.rda")', then 'summary(nf1)' works fine. But if instead I start a pretty basic R session and load() the file *without* having explicitly called library( VGAM), the summary method for 'vglm' doesn't get called whether or not I subsequently call library( VGAM). Transcript below.
>
> I'm using R 2.13.2 on Windows XP, VGAM 0.8-4. The same thing happens with R 2.15 devel v57866.
>
> bye
> Mark
>
> Mark Bravington
> CSIRO CMIS
> Marine Lab
> Hobart
> Australia
>
>
> #############################
> # Start a basic R session, and then:
>
>>   search()
>   [1] ".GlobalEnv"        "package:stats4"    "package:splines"   "package:stats"     "package:graphics"
>   [6] "package:grDevices" "package:utils"     "package:datasets"  "package:methods"   "Autoloads"         "package:base"
>
>> print( load( "nf1.rda")) # which should implicitly load VGAM, but not attach it
> [1] "nf1"
>
>> search()
> # ...snipped. No explicit VGAM
>
>> loadedNamespaces()
> # ...snipped. VGAM is there at the end.
>
>> nf1
> Call:
> vglm(formula = form, family = posbinomial, data = data, trace = TRUE)
>
> Coefficients:
> # ...snipped. The print() or show() or whatever method seems to get called OK
>
>> summary( nf1)
> Length  Class   Mode
>       1   vglm     S4
>
> # Hmmm... default method is being called, that's wrong. Try explicitly attaching 'VGAM':
>
>> library( VGAM)
> Loading required package: splines
> Loading required package: stats4
>
> Attaching package: 'VGAM'
>
> The following object(s) are masked from 'package:splines':
>
>      bs, ns
>
> The following object(s) are masked from 'package:stats':
>
>      biplot, case.names, coefficients, df.residual, fitted, fitted.values, formula, poly, residuals,
>      variable.names, weights
>
> The following object(s) are masked from 'package:base':
>
>      identity, print, scale.default
>
>> summary( nf1)
> Length  Class   Mode
>       1   vglm     S4
> # Hmmm... even though VGAM is on the search path etc, the wrong method is being called
>
> ###############################
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From wdunlap at tibco.com  Tue Jan 10 17:52:39 2012
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 10 Jan 2012 16:52:39 +0000
Subject: [Rd] inconsistent overflow handling by strtoi() on 32-bit Windows
Message-ID: <E66794E69CFDE04D9A70842786030B9325900F@PA-MBX03.na.tibco.com>

Using the precompiled R 2.14.1 on 32-bit Windows XP strtoi(x)
gives 2^31-1 for x>2^31-1 but NA when x goes out of range
in the negative direction:

> x <- c("2147483646", "2147483647", "2147483648", "2147483649")
> str(strtoi(x))
 int [1:4] 2147483646 2147483647 2147483647 2147483647
> str(strtoi(sprintf("-%s", x)))
 int [1:4] -2147483646 -2147483647 NA NA

> sessionInfo()
R version 2.14.1 (2011-12-22)
Platform: i386-pc-mingw32/i386 (32-bit)

locale:
[1] LC_COLLATE=English_United States.1252 
[2] LC_CTYPE=English_United States.1252   
[3] LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C                          
[5] LC_TIME=English_United States.1252    

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base  

On 64-bit Linux overflow in the either direction gives NA.

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com    


From ripley at stats.ox.ac.uk  Tue Jan 10 18:47:35 2012
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 10 Jan 2012 17:47:35 +0000
Subject: [Rd] S4 summary method not being called (VGAM)
In-Reply-To: <4F0C6AA4.4080102@r-project.org>
References: <3D59DF35E7CF3E42BA70C23BD5CBE6A85F6DA93028@exvic-mbx04.nexus.csiro.au>
	<4F0C6AA4.4080102@r-project.org>
Message-ID: <4F0C79B7.7050907@stats.ox.ac.uk>

All maintainers of CRAN packages which produced such a report were asked 
for an update a week or so ago.  Several have already done so.

The remaining list is
DMwR FAiR VGAM arm arulesSequences dcmle depmixS4 flip mirt spacom tlemix


On 10/01/2012 16:43, John Chambers wrote:
> A relevant report, not just for VGAM but for maintainers of other
> packages that define methods for functions that have both generic and
> non-generic versions in other packages.
>
> The problem is that VGAM "Depends" on stats4 but does not import from
> it. So when VGAM is loaded, only the old version of summary() is
> available. Importing the relevant functions from stats4 in VGAM should
> fix the problem.
>
> With the current R 2.14.1 this happens silently. With the latest
> r-devel, the installation of VGAM produces a warning:
>
> "Functions for exporting methods must have been made generic, explicitly
> or implicitly; not true when loading 'VGAM' for 'AIC', 'coef', 'logLik',
> 'plot', 'summary', 'vcov' "
>
> This implies (a bit obscurely) that the package has generic versions in
> its dependencies, but has not imported them.
>
> Maintainers of CRAN packages should check installation against the
> development version. Warning messages like this suggest a problem with
> the imports.
>
>
> John
>
> On 1/9/12 5:05 PM, Mark.Bravington at csiro.au wrote:
>> The symptom triggering this email is that an S4 summary method
>> sometimes refuses to be invoked, even when a package is explicitly
>> loaded, if the first load of the package is implicit. It may or may
>> not be specific to 'summary' methods and/or the 'VGAM' package. I've
>> sent to R-devel because (i) it looks like some kind of bug to me, but
>> I'm not sure; (ii) it's not something I personally need any help with;
>> and (iii) it seems a bit specialized for R-help.
>>
>> Here's the case notes. I have an object 'nf1' of S4 class 'vglm',
>> created by calling 'vglm(...)' from package 'VGAM' (you can create
>> your own from the examples in VGAM). It's save()d into a file
>> "nf1.rda". If I start a new R session, call 'library( VGAM)', and then
>> 'load("nf1.rda")', then 'summary(nf1)' works fine. But if instead I
>> start a pretty basic R session and load() the file *without* having
>> explicitly called library( VGAM), the summary method for 'vglm'
>> doesn't get called whether or not I subsequently call library( VGAM).
>> Transcript below.
>>
>> I'm using R 2.13.2 on Windows XP, VGAM 0.8-4. The same thing happens
>> with R 2.15 devel v57866.
>>
>> bye
>> Mark
>>
>> Mark Bravington
>> CSIRO CMIS
>> Marine Lab
>> Hobart
>> Australia
>>
>>
>> #############################
>> # Start a basic R session, and then:
>>
>>> search()
>> [1] ".GlobalEnv" "package:stats4" "package:splines" "package:stats"
>> "package:graphics"
>> [6] "package:grDevices" "package:utils" "package:datasets"
>> "package:methods" "Autoloads" "package:base"
>>
>>> print( load( "nf1.rda")) # which should implicitly load VGAM, but not
>>> attach it
>> [1] "nf1"
>>
>>> search()
>> # ...snipped. No explicit VGAM
>>
>>> loadedNamespaces()
>> # ...snipped. VGAM is there at the end.
>>
>>> nf1
>> Call:
>> vglm(formula = form, family = posbinomial, data = data, trace = TRUE)
>>
>> Coefficients:
>> # ...snipped. The print() or show() or whatever method seems to get
>> called OK
>>
>>> summary( nf1)
>> Length Class Mode
>> 1 vglm S4
>>
>> # Hmmm... default method is being called, that's wrong. Try explicitly
>> attaching 'VGAM':
>>
>>> library( VGAM)
>> Loading required package: splines
>> Loading required package: stats4
>>
>> Attaching package: 'VGAM'
>>
>> The following object(s) are masked from 'package:splines':
>>
>> bs, ns
>>
>> The following object(s) are masked from 'package:stats':
>>
>> biplot, case.names, coefficients, df.residual, fitted, fitted.values,
>> formula, poly, residuals,
>> variable.names, weights
>>
>> The following object(s) are masked from 'package:base':
>>
>> identity, print, scale.default
>>
>>> summary( nf1)
>> Length Class Mode
>> 1 vglm S4
>> # Hmmm... even though VGAM is on the search path etc, the wrong method
>> is being called
>>
>> ###############################
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From dtenenba at fhcrc.org  Tue Jan 10 18:51:35 2012
From: dtenenba at fhcrc.org (Dan Tenenbaum)
Date: Tue, 10 Jan 2012 09:51:35 -0800
Subject: [Rd] Updated Windows toolchain
In-Reply-To: <alpine.LFD.2.02.1111281109480.16728@toucan.stats.ox.ac.uk>
References: <alpine.LFD.2.02.1111281109480.16728@toucan.stats.ox.ac.uk>
Message-ID: <CAF42j22d_bPv17VJLGH0nbD=8mKn=JnUmJUUm6Zs81prfxCZxw@mail.gmail.com>

On Mon, Nov 28, 2011 at 11:56 PM, Prof Brian Ripley
<ripley at stats.ox.ac.uk> wrote:
> An updated toolchain is now being used for Windows' builds of R-devel:
> details are in the R-admin manual and at
> http://www.murdoch-sutherland.com/Rtools/ and
> http://www.stats.ox.ac.uk/pub/Rtools/
>

Thanks for the update.
I saw that
http://cran.r-project.org/bin/windows/Rtools/VERSION.txt
had the following contents:
Rtools version 2.15.0.1911

So I downloaded Rtools215.exe but when I installed it, the VERSION.txt
that was extracted read:
Rtools version 2.15.0.1908

...which is the same version I previously had installed.

Has the new version not propagated yet or is there some other issue?
Thanks,
Dan


> Both 32- and 64-bit parts of the toolchain use v2.0.1 of the Mingw-w64
> project's runtime and a beta of gcc 4.5.4: the Mingw.org project's builds
> are no longer used. ?This should mean that code which compiles for 64-bit
> Windows also compiles for 32-bit Windows, and v.v. unless code makes
> (incorrect but common) assumptions that pointers fit into longs.
>
> A very few packages will need modifications because they contain
> declarations which clash with the headers in this toolchain: where we are
> aware of problems the maintainers have been informed.
>
> At DLL level different Windows' toolchains should be compatible: at C level
> they mostly are but at C++ level they are pretty much incompatible (so that
> for example GDAL has to be re-compiled for every toolchain: and Rcpp users
> need to be careful to use only one toolchain for Rcpp and their packages).
> ?All the external software previously made available (and more) is made
> available at http://www.stats.ox.ac.uk/pub/Rtools .
>
> The toolchain has support for OpenMP and pthreads: however OpenMP support is
> not enabled by default in R (it is too slow to be much use). ?If you do make
> use of it in your packages, be aware that you will need to ship the
> appropriate pthreads DLL(s).
>
> It is expected that there will be several further minor updates prior to the
> release of 2.15.0 in ca 4 months, but this step is the major one.
>
> --
> Brian D. Ripley, ? ? ? ? ? ? ? ? ?ripley at stats.ox.ac.uk
> Professor of Applied Statistics, ?http://www.stats.ox.ac.uk/~ripley/
> University of Oxford, ? ? ? ? ? ? Tel: ?+44 1865 272861 (self)
> 1 South Parks Road, ? ? ? ? ? ? ? ? ? ? +44 1865 272866 (PA)
> Oxford OX1 3TG, UK ? ? ? ? ? ? ? ?Fax: ?+44 1865 272595
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From ligges at statistik.tu-dortmund.de  Tue Jan 10 19:05:43 2012
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Tue, 10 Jan 2012 19:05:43 +0100
Subject: [Rd] Updated Windows toolchain
In-Reply-To: <CAF42j22d_bPv17VJLGH0nbD=8mKn=JnUmJUUm6Zs81prfxCZxw@mail.gmail.com>
References: <alpine.LFD.2.02.1111281109480.16728@toucan.stats.ox.ac.uk>
	<CAF42j22d_bPv17VJLGH0nbD=8mKn=JnUmJUUm6Zs81prfxCZxw@mail.gmail.com>
Message-ID: <4F0C7DF7.9090106@statistik.tu-dortmund.de>



On 10.01.2012 18:51, Dan Tenenbaum wrote:
> On Mon, Nov 28, 2011 at 11:56 PM, Prof Brian Ripley
> <ripley at stats.ox.ac.uk>  wrote:
>> An updated toolchain is now being used for Windows' builds of R-devel:
>> details are in the R-admin manual and at
>> http://www.murdoch-sutherland.com/Rtools/ and
>> http://www.stats.ox.ac.uk/pub/Rtools/
>>
>
> Thanks for the update.
> I saw that
> http://cran.r-project.org/bin/windows/Rtools/VERSION.txt
> had the following contents:
> Rtools version 2.15.0.1911
>
> So I downloaded Rtools215.exe but when I installed it, the VERSION.txt
> that was extracted read:
> Rtools version 2.15.0.1908
>
> ...which is the same version I previously had installed.
>
> Has the new version not propagated yet or is there some other issue?

Looks like it failed. I just checked the original sources and CRAN and 
the versions differ. We will take care soon.

Uwe


> Thanks,
> Dan
>
>
>> Both 32- and 64-bit parts of the toolchain use v2.0.1 of the Mingw-w64
>> project's runtime and a beta of gcc 4.5.4: the Mingw.org project's builds
>> are no longer used.  This should mean that code which compiles for 64-bit
>> Windows also compiles for 32-bit Windows, and v.v. unless code makes
>> (incorrect but common) assumptions that pointers fit into longs.
>>
>> A very few packages will need modifications because they contain
>> declarations which clash with the headers in this toolchain: where we are
>> aware of problems the maintainers have been informed.
>>
>> At DLL level different Windows' toolchains should be compatible: at C level
>> they mostly are but at C++ level they are pretty much incompatible (so that
>> for example GDAL has to be re-compiled for every toolchain: and Rcpp users
>> need to be careful to use only one toolchain for Rcpp and their packages).
>>   All the external software previously made available (and more) is made
>> available at http://www.stats.ox.ac.uk/pub/Rtools .
>>
>> The toolchain has support for OpenMP and pthreads: however OpenMP support is
>> not enabled by default in R (it is too slow to be much use).  If you do make
>> use of it in your packages, be aware that you will need to ship the
>> appropriate pthreads DLL(s).
>>
>> It is expected that there will be several further minor updates prior to the
>> release of 2.15.0 in ca 4 months, but this step is the major one.
>>
>> --
>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>> University of Oxford,             Tel:  +44 1865 272861 (self)
>> 1 South Parks Road,                     +44 1865 272866 (PA)
>> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From murdoch.duncan at gmail.com  Tue Jan 10 19:09:46 2012
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 10 Jan 2012 13:09:46 -0500
Subject: [Rd] Updated Windows toolchain
In-Reply-To: <CAF42j22d_bPv17VJLGH0nbD=8mKn=JnUmJUUm6Zs81prfxCZxw@mail.gmail.com>
References: <alpine.LFD.2.02.1111281109480.16728@toucan.stats.ox.ac.uk>
	<CAF42j22d_bPv17VJLGH0nbD=8mKn=JnUmJUUm6Zs81prfxCZxw@mail.gmail.com>
Message-ID: <4F0C7EEA.3080404@gmail.com>

On 10/01/2012 12:51 PM, Dan Tenenbaum wrote:
> On Mon, Nov 28, 2011 at 11:56 PM, Prof Brian Ripley
> <ripley at stats.ox.ac.uk>  wrote:
> >  An updated toolchain is now being used for Windows' builds of R-devel:
> >  details are in the R-admin manual and at
> >  http://www.murdoch-sutherland.com/Rtools/ and
> >  http://www.stats.ox.ac.uk/pub/Rtools/
> >
>
> Thanks for the update.
> I saw that
> http://cran.r-project.org/bin/windows/Rtools/VERSION.txt
> had the following contents:
> Rtools version 2.15.0.1911
>
> So I downloaded Rtools215.exe but when I installed it, the VERSION.txt
> that was extracted read:
> Rtools version 2.15.0.1908
>
> ...which is the same version I previously had installed.
>
> Has the new version not propagated yet or is there some other issue?

I see 2.15.0.1911 in the original of that file, but the file on the 
Canadian mirror is the 1908 version (not current).  Not sure how that 
happened; it might just be really bad luck in the update timing.

I'll wait until tomorrow to see if things clear themselves up automatically.

Duncan Murdoch

> Thanks,
> Dan
>
>
> >  Both 32- and 64-bit parts of the toolchain use v2.0.1 of the Mingw-w64
> >  project's runtime and a beta of gcc 4.5.4: the Mingw.org project's builds
> >  are no longer used.  This should mean that code which compiles for 64-bit
> >  Windows also compiles for 32-bit Windows, and v.v. unless code makes
> >  (incorrect but common) assumptions that pointers fit into longs.
> >
> >  A very few packages will need modifications because they contain
> >  declarations which clash with the headers in this toolchain: where we are
> >  aware of problems the maintainers have been informed.
> >
> >  At DLL level different Windows' toolchains should be compatible: at C level
> >  they mostly are but at C++ level they are pretty much incompatible (so that
> >  for example GDAL has to be re-compiled for every toolchain: and Rcpp users
> >  need to be careful to use only one toolchain for Rcpp and their packages).
> >    All the external software previously made available (and more) is made
> >  available at http://www.stats.ox.ac.uk/pub/Rtools .
> >
> >  The toolchain has support for OpenMP and pthreads: however OpenMP support is
> >  not enabled by default in R (it is too slow to be much use).  If you do make
> >  use of it in your packages, be aware that you will need to ship the
> >  appropriate pthreads DLL(s).
> >
> >  It is expected that there will be several further minor updates prior to the
> >  release of 2.15.0 in ca 4 months, but this step is the major one.
> >
> >  --
> >  Brian D. Ripley,                  ripley at stats.ox.ac.uk
> >  Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> >  University of Oxford,             Tel:  +44 1865 272861 (self)
> >  1 South Parks Road,                     +44 1865 272866 (PA)
> >  Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> >
> >  ______________________________________________
> >  R-devel at r-project.org mailing list
> >  https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From jeroen.ooms at stat.ucla.edu  Tue Jan 10 22:12:13 2012
From: jeroen.ooms at stat.ucla.edu (Jeroen Ooms)
Date: Tue, 10 Jan 2012 13:12:13 -0800
Subject: [Rd] serializing recordedplot object
In-Reply-To: <7CE3B991-C200-45D5-836F-96E6DE807BCF@r-project.org>
References: <CABFfbXvzRJZ-72v6EqyvZyUi4NtNVn-BforTc-2+hP6GxU_Pag@mail.gmail.com>
	<CABFfbXu9mycTn0Ctt1Rsre7JwF5+cxjkeJeLrTOOF9Cov_H9sw@mail.gmail.com>
	<7CE3B991-C200-45D5-836F-96E6DE807BCF@r-project.org>
Message-ID: <CABFfbXs3P2nFpyA-_39EDnjPP-_TP8wxO-Va4PHXXOsABeuS9Q@mail.gmail.com>

On Tue, Jan 10, 2012 at 6:17 AM, Simon Urbanek
<simon.urbanek at r-project.org> wrote:
> Unfortunately R doesn't provide a way for this. Without changes to unserialization (on the wishlist for a few years now, but not easy to design) the best you can do is to check the native symbols for NULL pointers on usage and then re-fetch - that's something that could be done reasonably easily, although it's still a hack ...

Hmm that concerns me a bit. I make heavy use of saveRDS and readRDS in
my framework and have assumed that for all practical purposes most
objects can be saved to disk and loaded later on without problems. Are
there any other types of objects that are not being
serialized-unserialized to a state where they are functional again?

In the case of the NativeSymbolInfo object, it should not be too hard
to add an optional feature to unserialize which reloads the package
and NativeSymbolInfo when it runs into nullpointers during
unserialization? I am currently doing this manually after the
unserialization, but that introduces quite some overhead.

Thanks,

Jeroen


From simon.urbanek at r-project.org  Tue Jan 10 23:54:23 2012
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Tue, 10 Jan 2012 17:54:23 -0500
Subject: [Rd] serializing recordedplot object
In-Reply-To: <CABFfbXs3P2nFpyA-_39EDnjPP-_TP8wxO-Va4PHXXOsABeuS9Q@mail.gmail.com>
References: <CABFfbXvzRJZ-72v6EqyvZyUi4NtNVn-BforTc-2+hP6GxU_Pag@mail.gmail.com>
	<CABFfbXu9mycTn0Ctt1Rsre7JwF5+cxjkeJeLrTOOF9Cov_H9sw@mail.gmail.com>
	<7CE3B991-C200-45D5-836F-96E6DE807BCF@r-project.org>
	<CABFfbXs3P2nFpyA-_39EDnjPP-_TP8wxO-Va4PHXXOsABeuS9Q@mail.gmail.com>
Message-ID: <410EAB3D-92AC-4C29-98AD-E99BF48AE9AC@r-project.org>

On Jan 10, 2012, at 4:12 PM, Jeroen Ooms wrote:

> On Tue, Jan 10, 2012 at 6:17 AM, Simon Urbanek
> <simon.urbanek at r-project.org> wrote:
>> Unfortunately R doesn't provide a way for this. Without changes to unserialization (on the wishlist for a few years now, but not easy to design) the best you can do is to check the native symbols for NULL pointers on usage and then re-fetch - that's something that could be done reasonably easily, although it's still a hack ...
> 
> Hmm that concerns me a bit. I make heavy use of saveRDS and readRDS in
> my framework and have assumed that for all practical purposes most
> objects can be saved to disk and loaded later on without problems. Are
> there any other types of objects that are not being
> serialized-unserialized to a state where they are functional again?
> 

No, AFAIR just external pointers (and weak references I presume). There is simply no way to serialize them, because by definition such objects are transient and only present in the running process. They lose meaning the moment the process is terminated.


> In the case of the NativeSymbolInfo object, it should not be too hard
> to add an optional feature to unserialize which reloads the package
> and NativeSymbolInfo when it runs into nullpointers during
> unserialization? I am currently doing this manually after the
> unserialization, but that introduces quite some overhead.
> 

You could hard-code a special case of NativeSymbolInfo into R itself, but there are many other uses of external pointers in packages. The practical problem is that by definition you have no way of knowing which code will be able to unserialize a given external pointer. The fact that it is wrapped in a class is quite irrelevant to the pointer itself which doesn't know that. And conversely the class itself doesn't know that it may contain an external pointer - it's just a vanilla structure and you can't feasibly run a method on every single object you unserialize just to find out. Also you would need a special way of creating some raw byte stream that represents the state of the external pointer - apart from the regular serialization. That's why the current "solution" is that code using external pointers checks for NULL pointers and attempts to deal with that by inferring whether it can restore it or not from the information available (which is not always possible).

Cheers,
Simon


From mtmorgan at fhcrc.org  Wed Jan 11 00:33:25 2012
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Tue, 10 Jan 2012 15:33:25 -0800
Subject: [Rd] serializing recordedplot object
In-Reply-To: <410EAB3D-92AC-4C29-98AD-E99BF48AE9AC@r-project.org>
References: <CABFfbXvzRJZ-72v6EqyvZyUi4NtNVn-BforTc-2+hP6GxU_Pag@mail.gmail.com>	<CABFfbXu9mycTn0Ctt1Rsre7JwF5+cxjkeJeLrTOOF9Cov_H9sw@mail.gmail.com>	<7CE3B991-C200-45D5-836F-96E6DE807BCF@r-project.org>	<CABFfbXs3P2nFpyA-_39EDnjPP-_TP8wxO-Va4PHXXOsABeuS9Q@mail.gmail.com>
	<410EAB3D-92AC-4C29-98AD-E99BF48AE9AC@r-project.org>
Message-ID: <4F0CCAC5.1050706@fhcrc.org>

On 01/10/2012 02:54 PM, Simon Urbanek wrote:
> On Jan 10, 2012, at 4:12 PM, Jeroen Ooms wrote:
>
>> On Tue, Jan 10, 2012 at 6:17 AM, Simon Urbanek
>> <simon.urbanek at r-project.org>  wrote:
>>> Unfortunately R doesn't provide a way for this. Without changes to unserialization (on the wishlist for a few years now, but not easy to design) the best you can do is to check the native symbols for NULL pointers on usage and then re-fetch - that's something that could be done reasonably easily, although it's still a hack ...
>>
>> Hmm that concerns me a bit. I make heavy use of saveRDS and readRDS in
>> my framework and have assumed that for all practical purposes most
>> objects can be saved to disk and loaded later on without problems. Are
>> there any other types of objects that are not being
>> serialized-unserialized to a state where they are functional again?
>>
>
> No, AFAIR just external pointers (and weak references I presume).
> There is simply no way to serialize them, because by definition such
> objects are transient and only present in the running process. They
> lose meaning the moment the process is terminated.

Maybe obvious so I won't waste public bandwidth, but opened connections 
of all sorts (e.g., to data bases) and [to be explicit] references to c 
/ c++ (probably many packages using Rcpp produce these) objects. Martin

>
>
>> In the case of the NativeSymbolInfo object, it should not be too hard
>> to add an optional feature to unserialize which reloads the package
>> and NativeSymbolInfo when it runs into nullpointers during
>> unserialization? I am currently doing this manually after the
>> unserialization, but that introduces quite some overhead.
>>
>
> You could hard-code a special case of NativeSymbolInfo into R itself, but there are many other uses of external pointers in packages. The practical problem is that by definition you have no way of knowing which code will be able to unserialize a given external pointer. The fact that it is wrapped in a class is quite irrelevant to the pointer itself which doesn't know that. And conversely the class itself doesn't know that it may contain an external pointer - it's just a vanilla structure and you can't feasibly run a method on every single object you unserialize just to find out. Also you would need a special way of creating some raw byte stream that represents the state of the external pointer - apart from the regular serialization. That's why the current "solution" is that code using external pointers checks for NULL pointers and attempts to deal with that by inferring whether it can restore it or not from the information available (which is not always possible).
>
> Cheers,
> Simon
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
Computational Biology
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N. PO Box 19024 Seattle, WA 98109

Location: M1-B861
Telephone: 206 667-2793


From rhurlin at gwdg.de  Wed Jan 11 11:13:50 2012
From: rhurlin at gwdg.de (Rainer Hurling)
Date: Wed, 11 Jan 2012 11:13:50 +0100
Subject: [Rd] lubridate does not install on FreeBSD any more
Message-ID: <4F0D60DE.7020807@gwdg.de>

With newest R devel

#sessionInfo()
R Under development (unstable) (2012-01-10 r58085)
Platform: amd64-portbld-freebsd10.0 (64-bit)
locale:
[1] 
de_DE.ISO8859-15/de_DE.ISO8859-15/de_DE.ISO8859-15/C/de_DE.ISO8859-15/de_DE.ISO8859-15
attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

I get the following error when I try to build and install lubridate from 
sources on FreeBSD 10.0-CURRENT (amd64):

#R CMD INSTALL lubridate_0.2.6.tar.gz
* installing to library '/usr/local/lib/R/library'
* installing *source* package 'lubridate' ...
** package 'lubridate' successfully unpacked and MD5 sums checked
** R
** data
**  moving datasets to lazyload DB
** inst
** preparing package for lazy loading
** help
*** installing help indices
** building package indices
** testing if installed package can be loaded
During startup - Warning messages:
1: Setting LC_CTYPE failed, using "C"
2: Setting LC_TIME failed, using "C"
3: Setting LC_MESSAGES failed, using "C"
4: Setting LC_PAPER failed, using "C"
Error : .onLoad failed in loadNamespace() for 'lubridate', details:
   call: utils::assignInNamespace("+.Date", add_dates, "base")
   error: locked binding of '+.Date' cannot be changed
Error: loading failed
Execution halted
ERROR: loading failed
* removing '/usr/local/lib/R/library/lubridate'
* restoring previous '/usr/local/lib/R/library/lubridate'


Do you have any idea what is going on here?

Thanks in advance,
Rainer Hurling


From ligges at statistik.tu-dortmund.de  Wed Jan 11 11:32:13 2012
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Wed, 11 Jan 2012 11:32:13 +0100
Subject: [Rd] lubridate does not install on FreeBSD any more
In-Reply-To: <4F0D60DE.7020807@gwdg.de>
References: <4F0D60DE.7020807@gwdg.de>
Message-ID: <4F0D652D.4060103@statistik.tu-dortmund.de>



On 11.01.2012 11:13, Rainer Hurling wrote:
> With newest R devel
>
> #sessionInfo()
> R Under development (unstable) (2012-01-10 r58085)
> Platform: amd64-portbld-freebsd10.0 (64-bit)
> locale:
> [1]
> de_DE.ISO8859-15/de_DE.ISO8859-15/de_DE.ISO8859-15/C/de_DE.ISO8859-15/de_DE.ISO8859-15
>
> attached base packages:
> [1] stats graphics grDevices utils datasets methods base
>
> I get the following error when I try to build and install lubridate from
> sources on FreeBSD 10.0-CURRENT (amd64):
>
> #R CMD INSTALL lubridate_0.2.6.tar.gz
> * installing to library '/usr/local/lib/R/library'
> * installing *source* package 'lubridate' ...
> ** package 'lubridate' successfully unpacked and MD5 sums checked
> ** R
> ** data
> ** moving datasets to lazyload DB
> ** inst
> ** preparing package for lazy loading
> ** help
> *** installing help indices
> ** building package indices
> ** testing if installed package can be loaded
> During startup - Warning messages:
> 1: Setting LC_CTYPE failed, using "C"
> 2: Setting LC_TIME failed, using "C"
> 3: Setting LC_MESSAGES failed, using "C"
> 4: Setting LC_PAPER failed, using "C"
> Error : .onLoad failed in loadNamespace() for 'lubridate', details:
> call: utils::assignInNamespace("+.Date", add_dates, "base")
> error: locked binding of '+.Date' cannot be changed
> Error: loading failed
> Execution halted
> ERROR: loading failed
> * removing '/usr/local/lib/R/library/lubridate'
> * restoring previous '/usr/local/lib/R/library/lubridate'
>
>
> Do you have any idea what is going on here?

Yes: locked bindings cannot be changed in R-devel any more, and 
lubridate does that. The maintainer has been asked for an update already.

Uwe Ligges



>
> Thanks in advance,
> Rainer Hurling
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From pdalgd at gmail.com  Wed Jan 11 11:45:50 2012
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 11 Jan 2012 11:45:50 +0100
Subject: [Rd] lubridate does not install on FreeBSD any more
In-Reply-To: <4F0D60DE.7020807@gwdg.de>
References: <4F0D60DE.7020807@gwdg.de>
Message-ID: <0FD07819-3964-4904-80EB-B505C174AEAE@gmail.com>


On Jan 11, 2012, at 11:13 , Rainer Hurling wrote:

> With newest R devel
> 
> #sessionInfo()
> R Under development (unstable) (2012-01-10 r58085)
> Platform: amd64-portbld-freebsd10.0 (64-bit)
> locale:
> [1] de_DE.ISO8859-15/de_DE.ISO8859-15/de_DE.ISO8859-15/C/de_DE.ISO8859-15/de_DE.ISO8859-15
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> I get the following error when I try to build and install lubridate from sources on FreeBSD 10.0-CURRENT (amd64):
> 
> #R CMD INSTALL lubridate_0.2.6.tar.gz
> * installing to library '/usr/local/lib/R/library'
> * installing *source* package 'lubridate' ...
> ** package 'lubridate' successfully unpacked and MD5 sums checked
> ** R
> ** data
> **  moving datasets to lazyload DB
> ** inst
> ** preparing package for lazy loading
> ** help
> *** installing help indices
> ** building package indices
> ** testing if installed package can be loaded
> During startup - Warning messages:
> 1: Setting LC_CTYPE failed, using "C"
> 2: Setting LC_TIME failed, using "C"
> 3: Setting LC_MESSAGES failed, using "C"
> 4: Setting LC_PAPER failed, using "C"
> Error : .onLoad failed in loadNamespace() for 'lubridate', details:
>  call: utils::assignInNamespace("+.Date", add_dates, "base")
>  error: locked binding of '+.Date' cannot be changed
> Error: loading failed
> Execution halted
> ERROR: loading failed
> * removing '/usr/local/lib/R/library/lubridate'
> * restoring previous '/usr/local/lib/R/library/lubridate'
> 
> 
> Do you have any idea what is going on here?

I think that should be rather obvious. It tries to modify/define a base function and no longer gets away with that bit of bad programming citizenship. 

-- 
Peter Dalgaard, Professor
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From claudia.beleites at ipht-jena.de  Wed Jan 11 11:46:27 2012
From: claudia.beleites at ipht-jena.de (Claudia Beleites)
Date: Wed, 11 Jan 2012 11:46:27 +0100
Subject: [Rd] Command completion of the R binary / Ubuntu
Message-ID: <4F0D6883.8010309@ipht-jena.de>

Dear Deepayan and dear list,

I notice a small inconsistency with the command completion of the R CMD
check. --no-latex is deprecated sincs R 2.12.0 and defunct since 2.13.0
but the command line completion still suggests it:

cb at cbdesktop:~/r-devel$ bin/R CMD check --no-<here I hit tab>
--no-clean      --no-examples   --no-latex      --no-vignettes
--no-codoc      --no-install    --no-tests
cb at cbdesktop:~/r-devel$ bin/R CMD check --no-latex
Fehler: '--no-latex' is defunct: use '--no-manual' instead

I gather the command line options could be updated to current R CMD
check in file /etc/bash_completion.d/R:

cb at cbdesktop:~/tmp$ diff R /etc/bash_completion.d/R
244,247c244,245
< 		    --no-install --no-tests --no-vignettes --no-manual \
<           --no-rebuild-vignettes --install-args  --check-subdirs \
<           --extra-arch --multiarch --no-multiarch --force-multiarch \
< 		    --timings  --use-gct --use-valgrind --rcfile"
---
> 		    --no-install --no-tests --no-vignettes --no-latex \
> 		    --use-gct --use-valgrind --rcfile"

I gather from the mailing list archives, that the original is available at
http://code.google.com/p/rcompletion/source/browse/trunk/bash_completion/R

Should I suggest the patch there? Will changes propagate to the packaged
linux distributions from there or should the updated file be brought to
the attention somewhere else?

Best regards,

Claudia







> sessionInfo ()
R version 2.14.1 (2011-12-22)
Platform: x86_64-pc-linux-gnu (64-bit)

locale:
 [1] LC_CTYPE=de_DE.UTF-8       LC_NUMERIC=C
 [3] LC_TIME=de_DE.UTF-8        LC_COLLATE=de_DE.UTF-8
 [5] LC_MONETARY=de_DE.UTF-8    LC_MESSAGES=de_DE.UTF-8
 [7] LC_PAPER=C                 LC_NAME=C
 [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=de_DE.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

-- 
Claudia Beleites
Spectroscopy/Imaging
Institute of Photonic Technology
Albert-Einstein-Str. 9
07745 Jena
Germany

email: claudia.beleites at ipht-jena.de
phone: +49 3641 206-133
fax:   +49 2641 206-399




-------------- next part --------------
A non-text attachment was scrubbed...
Name: bash_completion.diff
Type: text/x-patch
Size: 379 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20120111/49bdef24/attachment.bin>

From rhurlin at gwdg.de  Wed Jan 11 11:58:50 2012
From: rhurlin at gwdg.de (Rainer Hurling)
Date: Wed, 11 Jan 2012 11:58:50 +0100
Subject: [Rd] lubridate does not install on FreeBSD any more
In-Reply-To: <4F0D652D.4060103@statistik.tu-dortmund.de>
References: <4F0D60DE.7020807@gwdg.de>
	<4F0D652D.4060103@statistik.tu-dortmund.de>
Message-ID: <4F0D6B6A.9060704@gwdg.de>

On 11.01.2012 11:32 (UTC+1), Uwe Ligges wrote:
> On 11.01.2012 11:13, Rainer Hurling wrote:
>> With newest R devel
>>
>> #sessionInfo()
>> R Under development (unstable) (2012-01-10 r58085)
>> Platform: amd64-portbld-freebsd10.0 (64-bit)
>> locale:
>> [1]
>> de_DE.ISO8859-15/de_DE.ISO8859-15/de_DE.ISO8859-15/C/de_DE.ISO8859-15/de_DE.ISO8859-15
>>
>>
>> attached base packages:
>> [1] stats graphics grDevices utils datasets methods base
>>
>> I get the following error when I try to build and install lubridate from
>> sources on FreeBSD 10.0-CURRENT (amd64):
>>
>> #R CMD INSTALL lubridate_0.2.6.tar.gz
>> * installing to library '/usr/local/lib/R/library'
>> * installing *source* package 'lubridate' ...
>> ** package 'lubridate' successfully unpacked and MD5 sums checked
>> ** R
>> ** data
>> ** moving datasets to lazyload DB
>> ** inst
>> ** preparing package for lazy loading
>> ** help
>> *** installing help indices
>> ** building package indices
>> ** testing if installed package can be loaded
>> During startup - Warning messages:
>> 1: Setting LC_CTYPE failed, using "C"
>> 2: Setting LC_TIME failed, using "C"
>> 3: Setting LC_MESSAGES failed, using "C"
>> 4: Setting LC_PAPER failed, using "C"
>> Error : .onLoad failed in loadNamespace() for 'lubridate', details:
>> call: utils::assignInNamespace("+.Date", add_dates, "base")
>> error: locked binding of '+.Date' cannot be changed
>> Error: loading failed
>> Execution halted
>> ERROR: loading failed
>> * removing '/usr/local/lib/R/library/lubridate'
>> * restoring previous '/usr/local/lib/R/library/lubridate'
>>
>>
>> Do you have any idea what is going on here?
>
> Yes: locked bindings cannot be changed in R-devel any more, and
> lubridate does that. The maintainer has been asked for an update already.
>
> Uwe Ligges
>
>> Thanks in advance,
>> Rainer Hurling

Thanks, Uwe Ligges and Peter Dalgaard, for clarifying this. So we have 
to wait for an update ...


From deepayan.sarkar at r-project.org  Wed Jan 11 13:03:12 2012
From: deepayan.sarkar at r-project.org (Deepayan Sarkar)
Date: Wed, 11 Jan 2012 17:33:12 +0530
Subject: [Rd] Command completion of the R binary / Ubuntu
In-Reply-To: <4F0D6883.8010309@ipht-jena.de>
References: <4F0D6883.8010309@ipht-jena.de>
Message-ID: <CADfFDC5qZU3Wuz7uA3H4CvzhOTns=cxDrYevCC-w0WND90rZeg@mail.gmail.com>

On Wed, Jan 11, 2012 at 4:16 PM, Claudia Beleites
<claudia.beleites at ipht-jena.de> wrote:
> Dear Deepayan and dear list,
>
> I notice a small inconsistency with the command completion of the R CMD
> check. --no-latex is deprecated sincs R 2.12.0 and defunct since 2.13.0
> but the command line completion still suggests it:
>
> cb at cbdesktop:~/r-devel$ bin/R CMD check --no-<here I hit tab>
> --no-clean ? ? ?--no-examples ? --no-latex ? ? ?--no-vignettes
> --no-codoc ? ? ?--no-install ? ?--no-tests
> cb at cbdesktop:~/r-devel$ bin/R CMD check --no-latex
> Fehler: '--no-latex' is defunct: use '--no-manual' instead
>
> I gather the command line options could be updated to current R CMD
> check in file /etc/bash_completion.d/R:
>
> cb at cbdesktop:~/tmp$ diff R /etc/bash_completion.d/R
> 244,247c244,245
> < ? ? ? ? ? ? ? ? ? --no-install --no-tests --no-vignettes --no-manual \
> < ? ? ? ? ? --no-rebuild-vignettes --install-args ?--check-subdirs \
> < ? ? ? ? ? --extra-arch --multiarch --no-multiarch --force-multiarch \
> < ? ? ? ? ? ? ? ? ? --timings ?--use-gct --use-valgrind --rcfile"
> ---
>> ? ? ? ? ? ? ? ? ? --no-install --no-tests --no-vignettes --no-latex \
>> ? ? ? ? ? ? ? ? ? --use-gct --use-valgrind --rcfile"
>
> I gather from the mailing list archives, that the original is available at
> http://code.google.com/p/rcompletion/source/browse/trunk/bash_completion/R
>
> Should I suggest the patch there? Will changes propagate to the packaged
> linux distributions from there or should the updated file be brought to
> the attention somewhere else?

Thanks for the patch.

I believe only Debian/Ubuntu package it (and this would have been more
appropriate for r-sig-debian). I'll coordinate with Dirk et al to
update the relevant files.

-Deepayan


From sdmorris at u.washington.edu  Tue Jan 10 19:17:42 2012
From: sdmorris at u.washington.edu (Stephanie M. Gogarten)
Date: Tue, 10 Jan 2012 10:17:42 -0800
Subject: [Rd] importing S3 methods with importFrom
Message-ID: <4F0C80C6.2050307@u.washington.edu>

In my own package, I want to use the default S3 method of the generic 
function lrtest() from the lmtest package.  Since I need only one 
function from lmtest, I tried to use importFrom in my NAMESPACE:

importFrom(lmtest, lrtest)

However, this fails R CMD check in the examples:
Error in UseMethod("lrtest") :
   no applicable method for 'lrtest' applied to an object of class 
"c('glm', 'lm')"
Calls: assocTestRegression ... append -> RunRegression -> append -> 
unlist -> lrtest

Relevant line of code in assocTestRegression is
tmp <- append(tmp, unlist(lrtest(mod, mod0))[c(8,10)])
where mod and mod0 are both results of the glm() function.

If I instead import the entire package in my NAMESPACE:

import(lmtest)

The example runs without error.  Is there a way to import all methods 
for an S3 generic function without importing the entire package?

thanks,
Stephanie Gogarten

sessionInfo()
R version 2.14.0 (2011-10-31)
Platform: x86_64-apple-darwin9.8.0/x86_64 (64-bit)

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] lmtest_0.9-28 zoo_1.7-4

loaded via a namespace (and not attached):
[1] grid_2.14.0    lattice_0.20-0 tools_2.14.0


From Berwin.Turlach at gmail.com  Wed Jan 11 14:16:45 2012
From: Berwin.Turlach at gmail.com (Berwin A Turlach)
Date: Wed, 11 Jan 2012 21:16:45 +0800
Subject: [Rd] Changed behaviour of 'R CMD INSTALL'
Message-ID: <20120111211645.451379c2@absentia>

G'day all,

I found the following snippet in the NEWS file for R 2.14.1: 

    ? R CMD INSTALL will now do a test load for all sub-architectures
      for which code was compiled (rather than just the primary
      sub-architecture).

This seems to have the following (unintended?) consequence:

Most of my machines are running some version of 64-bit Ubuntu and I do
not necessarily have all 32-bit libraries installed on these.  In
particular, the 32-bit TCL/Tk libraries are frequently missing.  Thus,
on such a machine the 32-bit sub-architecture of R does not have the
capability to use TCL/tk and the tcltk package is only installed for the
primary sub-architecture (64-bit).

Until now, I could always install the Rcmdr package on these machine.
However, this is no longer possible in 2.14.1.  Now attempts to install
Rcmdr on such a machine ends with:

    ** testing if installed package can be loaded
    *** arch - 32
    Error : package 'tcltk' is not installed for 'arch=32'
    Error: loading failed
    Execution halted
    *** arch - 64
    ERROR: loading failed for '32'
    * removing '/home/opt/R/R-2.14.1/lib64/R/library/Rcmdr'

Is there a way of installing Rcmdr only for the 64-bit primary
sub-architecture?  Or do I really have to install the 32-bit versions
of the TCL/Tk libraries and then reinstall R from scratch?

Cheers,

	Berwin


From simon.urbanek at r-project.org  Wed Jan 11 14:53:27 2012
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Wed, 11 Jan 2012 08:53:27 -0500
Subject: [Rd] Changed behaviour of 'R CMD INSTALL'
In-Reply-To: <20120111211645.451379c2@absentia>
References: <20120111211645.451379c2@absentia>
Message-ID: <60F108C3-D591-46AF-A33D-1035F717FF29@r-project.org>

try --no-multiarch

On Jan 11, 2012, at 8:16 AM, Berwin A Turlach wrote:

> G'day all,
> 
> I found the following snippet in the NEWS file for R 2.14.1: 
> 
>    ? R CMD INSTALL will now do a test load for all sub-architectures
>      for which code was compiled (rather than just the primary
>      sub-architecture).
> 
> This seems to have the following (unintended?) consequence:
> 
> Most of my machines are running some version of 64-bit Ubuntu and I do
> not necessarily have all 32-bit libraries installed on these.  In
> particular, the 32-bit TCL/Tk libraries are frequently missing.  Thus,
> on such a machine the 32-bit sub-architecture of R does not have the
> capability to use TCL/tk and the tcltk package is only installed for the
> primary sub-architecture (64-bit).
> 
> Until now, I could always install the Rcmdr package on these machine.
> However, this is no longer possible in 2.14.1.  Now attempts to install
> Rcmdr on such a machine ends with:
> 
>    ** testing if installed package can be loaded
>    *** arch - 32
>    Error : package 'tcltk' is not installed for 'arch=32'
>    Error: loading failed
>    Execution halted
>    *** arch - 64
>    ERROR: loading failed for '32'
>    * removing '/home/opt/R/R-2.14.1/lib64/R/library/Rcmdr'
> 
> Is there a way of installing Rcmdr only for the 64-bit primary
> sub-architecture?  Or do I really have to install the 32-bit versions
> of the TCL/Tk libraries and then reinstall R from scratch?
> 
> Cheers,
> 
> 	Berwin
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From Berwin.Turlach at gmail.com  Wed Jan 11 15:00:43 2012
From: Berwin.Turlach at gmail.com (Berwin A Turlach)
Date: Wed, 11 Jan 2012 22:00:43 +0800
Subject: [Rd] Changed behaviour of 'R CMD INSTALL'
In-Reply-To: <60F108C3-D591-46AF-A33D-1035F717FF29@r-project.org>
References: <20120111211645.451379c2@absentia>
	<60F108C3-D591-46AF-A33D-1035F717FF29@r-project.org>
Message-ID: <20120111220043.04481c3e@absentia>

G'day Simon,

On Wed, 11 Jan 2012 08:53:27 -0500
Simon Urbanek <simon.urbanek at r-project.org> wrote:

> try --no-multiarch

Thanks, works perfectly.

And now I notice that this option is given as an example in the help
file for install.packages() as a possible value that one wants to pass
to 'R CMD INSTALL'.  Could kick myself. Well, it is always easier to
find something when one knows what one is looking for... :)

Cheers,
		
	Berwin


From ligges at statistik.tu-dortmund.de  Wed Jan 11 15:08:25 2012
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Wed, 11 Jan 2012 15:08:25 +0100
Subject: [Rd] Changed behaviour of 'R CMD INSTALL'
In-Reply-To: <20120111211645.451379c2@absentia>
References: <20120111211645.451379c2@absentia>
Message-ID: <4F0D97D9.4040607@statistik.tu-dortmund.de>



On 11.01.2012 14:16, Berwin A Turlach wrote:
> G'day all,
>
> I found the following snippet in the NEWS file for R 2.14.1:
>
>      ? R CMD INSTALL will now do a test load for all sub-architectures
>        for which code was compiled (rather than just the primary
>        sub-architecture).
>
> This seems to have the following (unintended?) consequence:
>
> Most of my machines are running some version of 64-bit Ubuntu and I do
> not necessarily have all 32-bit libraries installed on these.  In
> particular, the 32-bit TCL/Tk libraries are frequently missing.  Thus,
> on such a machine the 32-bit sub-architecture of R does not have the
> capability to use TCL/tk and the tcltk package is only installed for the
> primary sub-architecture (64-bit).
>
> Until now, I could always install the Rcmdr package on these machine.
> However, this is no longer possible in 2.14.1.  Now attempts to install
> Rcmdr on such a machine ends with:
>
>      ** testing if installed package can be loaded
>      *** arch - 32
>      Error : package 'tcltk' is not installed for 'arch=32'
>      Error: loading failed
>      Execution halted
>      *** arch - 64
>      ERROR: loading failed for '32'
>      * removing '/home/opt/R/R-2.14.1/lib64/R/library/Rcmdr'
>
> Is there a way of installing Rcmdr only for the 64-bit primary
> sub-architecture?  Or do I really have to install the 32-bit versions
> of the TCL/Tk libraries and then reinstall R from scratch?



Have you read

R CMD INSTALL --help ?

there is, among other, the line:
      --no-multiarch    build only the main architecture

or if you want to build and don't care about loading:
      --no-test-load    skip test of loading installed package

Uwe Ligges



> Cheers,
>
> 	Berwin
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From ligges at statistik.tu-dortmund.de  Wed Jan 11 15:28:53 2012
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Wed, 11 Jan 2012 15:28:53 +0100
Subject: [Rd] importing S3 methods with importFrom
In-Reply-To: <4F0C80C6.2050307@u.washington.edu>
References: <4F0C80C6.2050307@u.washington.edu>
Message-ID: <4F0D9CA5.4090003@statistik.tu-dortmund.de>

This is a problem in the lmtest package:

"lrtest.default" is exported as a function rather than declared as an 
S3method in its NAMESPACE. I am CCing the maintainer.
For the meantime, you hav to import the default function explicitly, I 
believe.

Best,
Uwe Ligges



On 10.01.2012 19:17, Stephanie M. Gogarten wrote:
> In my own package, I want to use the default S3 method of the generic
> function lrtest() from the lmtest package. Since I need only one
> function from lmtest, I tried to use importFrom in my NAMESPACE:
>
> importFrom(lmtest, lrtest)
>
> However, this fails R CMD check in the examples:
> Error in UseMethod("lrtest") :
> no applicable method for 'lrtest' applied to an object of class
> "c('glm', 'lm')"
> Calls: assocTestRegression ... append -> RunRegression -> append ->
> unlist -> lrtest
>
> Relevant line of code in assocTestRegression is
> tmp <- append(tmp, unlist(lrtest(mod, mod0))[c(8,10)])
> where mod and mod0 are both results of the glm() function.
>
> If I instead import the entire package in my NAMESPACE:
>
> import(lmtest)
>
> The example runs without error. Is there a way to import all methods for
> an S3 generic function without importing the entire package?
>
> thanks,
> Stephanie Gogarten
>
> sessionInfo()
> R version 2.14.0 (2011-10-31)
> Platform: x86_64-apple-darwin9.8.0/x86_64 (64-bit)
>
> locale:
> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>
> attached base packages:
> [1] stats graphics grDevices utils datasets methods base
>
> other attached packages:
> [1] lmtest_0.9-28 zoo_1.7-4
>
> loaded via a namespace (and not attached):
> [1] grid_2.14.0 lattice_0.20-0 tools_2.14.0
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From claudia.beleites at ipht-jena.de  Wed Jan 11 16:02:20 2012
From: claudia.beleites at ipht-jena.de (Claudia Beleites)
Date: Wed, 11 Jan 2012 16:02:20 +0100
Subject: [Rd] Command completion of the R binary / Ubuntu: result
In-Reply-To: <4F0D6883.8010309@ipht-jena.de>
References: <4F0D6883.8010309@ipht-jena.de>
Message-ID: <4F0DA47C.7060105@ipht-jena.de>

Dear list,

for the benefit of people searching for this in the future (and as
r-devel archives are searched by RSiteSearch, but r-sig-debian isn't):

- command line completion of the R command doesn't have anything to do
with R
- Deepayan told me that as far as he knows, only Debian (and Ubuntu)
have it, so

R-sig-debian

is the appropriate mailing list. Deepayan moved the discussion there.
Thanks.

Have a nice day,

Claudia



-- 
Claudia Beleites
Spectroscopy/Imaging
Institute of Photonic Technology
Albert-Einstein-Str. 9
07745 Jena
Germany

email: claudia.beleites at ipht-jena.de
phone: +49 3641 206-133
fax:   +49 2641 206-399


From ripley at stats.ox.ac.uk  Wed Jan 11 16:16:48 2012
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 11 Jan 2012 15:16:48 +0000
Subject: [Rd] Changed behaviour of 'R CMD INSTALL'
In-Reply-To: <20120111220043.04481c3e@absentia>
References: <20120111211645.451379c2@absentia>
	<60F108C3-D591-46AF-A33D-1035F717FF29@r-project.org>
	<20120111220043.04481c3e@absentia>
Message-ID: <4F0DA7E0.9050601@stats.ox.ac.uk>

On 11/01/2012 14:00, Berwin A Turlach wrote:
> G'day Simon,
>
> On Wed, 11 Jan 2012 08:53:27 -0500
> Simon Urbanek<simon.urbanek at r-project.org>  wrote:
>
>> try --no-multiarch
>
> Thanks, works perfectly.
>
> And now I notice that this option is given as an example in the help
> file for install.packages() as a possible value that one wants to pass
> to 'R CMD INSTALL'.  Could kick myself. Well, it is always easier to
> find something when one knows what one is looking for... :)

There are good reasons for the change in logic.  Far too often people 
have installed packages that actually only work for one architecture, 
and then distributed them as binary packages.  Most of us really do want 
to know if the package works at the end of INSTALL.  So it seemed a lot 
safer that you need to actually say that you intended to install only 
one architecture.

And BTW, test-loading has saved me many times blowing away a working 
package for one that does not work, so it has been far more useful than 
I anticipated when I added it.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From dwinsemius at comcast.net  Wed Jan 11 17:39:42 2012
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 11 Jan 2012 11:39:42 -0500
Subject: [Rd] Command completion of the R binary / Ubuntu: result
In-Reply-To: <4F0DA47C.7060105@ipht-jena.de>
References: <4F0D6883.8010309@ipht-jena.de> <4F0DA47C.7060105@ipht-jena.de>
Message-ID: <EBAFF14B-A7C6-4DDF-8CE7-672EF05FB100@comcast.net>


On Jan 11, 2012, at 10:02 AM, Claudia Beleites wrote:

> Dear list,
>
> for the benefit of people searching for this in the future (and as
> r-devel archives are searched by RSiteSearch,

The Baron search page claims to search r-devel, but most of my  
attempts to follow the links it offers have failed. They end up at  
links like:

http://finzi.psych.upenn.edu/R/R-devel/2010-December/059322.html

(which 404s.)

  I instead search the r-devel Archive with Google Advanced Search  
with a domain of

site:https://stat.ethz.ch/pipermail/r-devel/

I just edited the URL to see if the directory and naming conventions  
would agree and they do seem to,

https://stat.ethz.ch/pipermail/r-devel/2010-December/059322.html

  .... so I will copy this to John Baron to see if he wants to address  
it.

-- 
David.


> but r-sig-debian isn't):
>
> - command line completion of the R command doesn't have anything to do
> with R
> - Deepayan told me that as far as he knows, only Debian (and Ubuntu)
> have it, so
>
> R-sig-debian
>
> is the appropriate mailing list. Deepayan moved the discussion there.
> Thanks.
>
> Have a nice day,
>
> Claudia


David Winsemius, MD
West Hartford, CT


From taylor.arnold at yale.edu  Wed Jan 11 18:08:27 2012
From: taylor.arnold at yale.edu (Taylor Arnold)
Date: Wed, 11 Jan 2012 12:08:27 -0500
Subject: [Rd] Copying objects prior to .Call
Message-ID: <CAM3Zkc4WuKMKS-CSCu2yYnqkEzZ=_39awBOyAa=H=_DY-U1YeA@mail.gmail.com>

R-devel,

I have noticed that making a copy of an object in R prior to using
.Call on the original object can
cause the C code to alter not only the object passed to it but also
the copy in R. A simple example
is:

> x <- 2
> y <- x
> .Call("addOne", x, DUP=TRUE) # Changing DUP does not alter output
NULL
> x
[1] 3
> y
[1] 3

And corresponding simple C code:

"test.c":
#include <R.h>
#include <Rinternals.h>
#include <Rmath.h>

SEXP addOne(SEXP input) {
? REAL(input)[0] = REAL(input)[0] + 1;
? return R_NilValue;
}

I assume that this is simply a result of lazy loading in R, and well
documented. My question is, do
there exist functions to (1) force R to make a copy of an object
(force() does not work), and (2) to check
whether two objects are actually pointing to the same memory address.
For question 1, I have
found specific operations which force a copy of a given datatype, but
would prefer a more general
solution.

Thank you,

Taylor

> sessionInfo()
R version 2.14.1 (2011-12-22)
Platform: x86_64-apple-darwin9.8.0/x86_64 (64-bit)

locale:
[1] en_GB.UTF-8/en_GB.UTF-8/en_GB.UTF-8/C/en_GB.UTF-8/en_GB.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] tools_2.14.1


--
Taylor B. Arnold
Department of Statistics
Yale University
24 Hillhouse Avenue
New Haven, CT 06520

e-mail: taylor.arnold at yale.edu


From simon.urbanek at r-project.org  Wed Jan 11 18:49:33 2012
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Wed, 11 Jan 2012 12:49:33 -0500
Subject: [Rd] Copying objects prior to .Call
In-Reply-To: <CAM3Zkc4WuKMKS-CSCu2yYnqkEzZ=_39awBOyAa=H=_DY-U1YeA@mail.gmail.com>
References: <CAM3Zkc4WuKMKS-CSCu2yYnqkEzZ=_39awBOyAa=H=_DY-U1YeA@mail.gmail.com>
Message-ID: <B3877BB6-1156-4BD1-8B13-3EE2D3F81ABF@r-project.org>


On Jan 11, 2012, at 12:08 PM, Taylor Arnold wrote:

> R-devel,
> 
> I have noticed that making a copy of an object in R prior to using
> .Call on the original object can
> cause the C code to alter not only the object passed to it but also
> the copy in R.

Please see the docs - .Call does *NOT* have a DUP argument - you are responsible for duplication at all times if you make modifications (e.g. using duplicate()).

Cheers,
Simon


> A simple example
> is:
> 
>> x <- 2
>> y <- x
>> .Call("addOne", x, DUP=TRUE) # Changing DUP does not alter output
> NULL
>> x
> [1] 3
>> y
> [1] 3
> 
> And corresponding simple C code:
> 
> "test.c":
> #include <R.h>
> #include <Rinternals.h>
> #include <Rmath.h>
> 
> SEXP addOne(SEXP input) {
>   REAL(input)[0] = REAL(input)[0] + 1;
>   return R_NilValue;
> }
> 
> I assume that this is simply a result of lazy loading in R, and well
> documented. My question is, do
> there exist functions to (1) force R to make a copy of an object
> (force() does not work), and (2) to check
> whether two objects are actually pointing to the same memory address.
> For question 1, I have
> found specific operations which force a copy of a given datatype, but
> would prefer a more general
> solution.
> 
> Thank you,
> 
> Taylor
> 
>> sessionInfo()
> R version 2.14.1 (2011-12-22)
> Platform: x86_64-apple-darwin9.8.0/x86_64 (64-bit)
> 
> locale:
> [1] en_GB.UTF-8/en_GB.UTF-8/en_GB.UTF-8/C/en_GB.UTF-8/en_GB.UTF-8
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> loaded via a namespace (and not attached):
> [1] tools_2.14.1
> 
> 
> --
> Taylor B. Arnold
> Department of Statistics
> Yale University
> 24 Hillhouse Avenue
> New Haven, CT 06520
> 
> e-mail: taylor.arnold at yale.edu
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From bates at stat.wisc.edu  Wed Jan 11 19:03:24 2012
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 11 Jan 2012 12:03:24 -0600
Subject: [Rd] Copying objects prior to .Call
In-Reply-To: <B3877BB6-1156-4BD1-8B13-3EE2D3F81ABF@r-project.org>
References: <CAM3Zkc4WuKMKS-CSCu2yYnqkEzZ=_39awBOyAa=H=_DY-U1YeA@mail.gmail.com>
	<B3877BB6-1156-4BD1-8B13-3EE2D3F81ABF@r-project.org>
Message-ID: <CAO7JsnRvgwUSX=qwTByHMVhy5fYEh=FXh4-Q0gQRcBEp6PBQ5g@mail.gmail.com>

On Wed, Jan 11, 2012 at 11:49 AM, Simon Urbanek
<simon.urbanek at r-project.org> wrote:
>
> On Jan 11, 2012, at 12:08 PM, Taylor Arnold wrote:
>
>> R-devel,
>>
>> I have noticed that making a copy of an object in R prior to using
>> .Call on the original object can
>> cause the C code to alter not only the object passed to it but also
>> the copy in R.

> Please see the docs - .Call does *NOT* have a DUP argument - you are responsible for duplication at all times if you make modifications (e.g. using duplicate()).

Except that duplicate will create a new SEXPREC and the original
poster wanted to modify the SEXPREC passed through a pointer in .Call.

Purposely changing the value of arguments to .Call is a bad design,
Taylor.  R is a functional language and this breaks the functional
semantics. It is the sort of thing that you do only when you can't
think of a better approach.  It may, perhaps, be justified if the R
objects you are passing happen to be fields in a reference class (see
?setRefClass) but otherwise it is just opening yourself up to errors.
At the level of C/C++ all R objects passed as arguments to .Call
should be regarded as

const SEXP


>> A simple example
>> is:
>>
>>> x <- 2
>>> y <- x
>>> .Call("addOne", x, DUP=TRUE) # Changing DUP does not alter output
>> NULL
>>> x
>> [1] 3
>>> y
>> [1] 3
>>
>> And corresponding simple C code:
>>
>> "test.c":
>> #include <R.h>
>> #include <Rinternals.h>
>> #include <Rmath.h>
>>
>> SEXP addOne(SEXP input) {
>> ? REAL(input)[0] = REAL(input)[0] + 1;
>> ? return R_NilValue;
>> }
>>
>> I assume that this is simply a result of lazy loading in R, and well
>> documented. My question is, do
>> there exist functions to (1) force R to make a copy of an object
>> (force() does not work), and (2) to check
>> whether two objects are actually pointing to the same memory address.
>> For question 1, I have
>> found specific operations which force a copy of a given datatype, but
>> would prefer a more general
>> solution.
>>
>> Thank you,
>>
>> Taylor
>>
>>> sessionInfo()
>> R version 2.14.1 (2011-12-22)
>> Platform: x86_64-apple-darwin9.8.0/x86_64 (64-bit)
>>
>> locale:
>> [1] en_GB.UTF-8/en_GB.UTF-8/en_GB.UTF-8/C/en_GB.UTF-8/en_GB.UTF-8
>>
>> attached base packages:
>> [1] stats ? ? graphics ?grDevices utils ? ? datasets ?methods ? base
>>
>> loaded via a namespace (and not attached):
>> [1] tools_2.14.1
>>
>>
>> --
>> Taylor B. Arnold
>> Department of Statistics
>> Yale University
>> 24 Hillhouse Avenue
>> New Haven, CT 06520
>>
>> e-mail: taylor.arnold at yale.edu
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From ligges at statistik.tu-dortmund.de  Wed Jan 11 19:04:12 2012
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Wed, 11 Jan 2012 19:04:12 +0100
Subject: [Rd] Copying objects prior to .Call
In-Reply-To: <B3877BB6-1156-4BD1-8B13-3EE2D3F81ABF@r-project.org>
References: <CAM3Zkc4WuKMKS-CSCu2yYnqkEzZ=_39awBOyAa=H=_DY-U1YeA@mail.gmail.com>
	<B3877BB6-1156-4BD1-8B13-3EE2D3F81ABF@r-project.org>
Message-ID: <4F0DCF1C.60005@statistik.tu-dortmund.de>



On 11.01.2012 18:49, Simon Urbanek wrote:
>
> On Jan 11, 2012, at 12:08 PM, Taylor Arnold wrote:
>
>> R-devel,
>>
>> I have noticed that making a copy of an object in R prior to using
>> .Call on the original object can
>> cause the C code to alter not only the object passed to it but also
>> the copy in R.
>
> Please see the docs - .Call does *NOT* have a DUP argument - you are responsible for duplication at all times if you make modifications (e.g. using duplicate()).
>
> Cheers,
> Simon
>
>
>> A simple example
>> is:
>>
>>> x<- 2
>>> y<- x
>>> .Call("addOne", x, DUP=TRUE) # Changing DUP does not alter output
>> NULL
>>> x
>> [1] 3
>>> y
>> [1] 3
>>
>> And corresponding simple C code:
>>
>> "test.c":
>> #include<R.h>
>> #include<Rinternals.h>
>> #include<Rmath.h>
>>
>> SEXP addOne(SEXP input) {
>>    REAL(input)[0] = REAL(input)[0] + 1;
>>    return R_NilValue;
>> }
>>
>> I assume that this is simply a result of lazy loading

In addition to Simon: it is "lazy evalution" rather than lazy loading in 
this case.

Uwe


>> in R, and well
>> documented. My question is, do
>> there exist functions to (1) force R to make a copy of an object
>> (force() does not work), and (2) to check
>> whether two objects are actually pointing to the same memory address.
>> For question 1, I have
>> found specific operations which force a copy of a given datatype, but
>> would prefer a more general
>> solution.
>>
>> Thank you,
>>
>> Taylor
>>
>>> sessionInfo()
>> R version 2.14.1 (2011-12-22)
>> Platform: x86_64-apple-darwin9.8.0/x86_64 (64-bit)
>>
>> locale:
>> [1] en_GB.UTF-8/en_GB.UTF-8/en_GB.UTF-8/C/en_GB.UTF-8/en_GB.UTF-8
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> loaded via a namespace (and not attached):
>> [1] tools_2.14.1
>>
>>
>> --
>> Taylor B. Arnold
>> Department of Statistics
>> Yale University
>> 24 Hillhouse Avenue
>> New Haven, CT 06520
>>
>> e-mail: taylor.arnold at yale.edu
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From chuck at sharpsteen.net  Wed Jan 11 19:11:19 2012
From: chuck at sharpsteen.net (Sharpie)
Date: Wed, 11 Jan 2012 10:11:19 -0800 (PST)
Subject: [Rd] Inconsistencies in device_Raster when axes are reflected
Message-ID: <1326305479642-4286320.post@n4.nabble.com>

I noticed some undocumented and inconsistent behavior in device_Raster when a
plot is produced with reflected axes such as:

    image(volcano, xlim = c(1,0), useRaster = TRUE)
    image(volcano, ylim = c(1,0), useRaster = TRUE)

The `pdf` device will perform horizontal and vertical reflections, while
`quartz` will ignore the transformations when plotting to the screen, but
when plotting to a file, `quartz(file = 'test.pdf', type = 'pdf')`, it will
produce horizontal reflections and ignore vertical ones.

When the `xlim` or `ylim` is reversed, negative widths and heights are
passed to the C function `device_Raster`, which is not a behavior documented
in `R_ext/GraphicsDevice.h`. Also, the values of `x` and `y` passed to
`device_Raster` will be shifted by the width or height of the image such
that the coordinates no longer reference the bottom-left corner of the image
as `R_ext/GraphicsDevice.h` says they should.

Given the inconsistencies in documentation and behavior, I am wondering what
the intended behavior of `device_Raster` is in this situation.

Thanks!

-Charlie

-----
Charlie Sharpsteen
Undergraduate-- Environmental Resources Engineering
Humboldt State University
--
View this message in context: http://r.789695.n4.nabble.com/Inconsistencies-in-device-Raster-when-axes-are-reflected-tp4286320p4286320.html
Sent from the R devel mailing list archive at Nabble.com.


From edd at debian.org  Wed Jan 11 19:12:37 2012
From: edd at debian.org (Dirk Eddelbuettel)
Date: Wed, 11 Jan 2012 12:12:37 -0600
Subject: [Rd] Command completion of the R binary / Ubuntu
In-Reply-To: <CADfFDC5qZU3Wuz7uA3H4CvzhOTns=cxDrYevCC-w0WND90rZeg@mail.gmail.com>
References: <4F0D6883.8010309@ipht-jena.de>
	<CADfFDC5qZU3Wuz7uA3H4CvzhOTns=cxDrYevCC-w0WND90rZeg@mail.gmail.com>
Message-ID: <20237.53525.534664.107631@max.nulle.part>


On 11 January 2012 at 17:33, Deepayan Sarkar wrote:
| On Wed, Jan 11, 2012 at 4:16 PM, Claudia Beleites
| <claudia.beleites at ipht-jena.de> wrote:
| > Dear Deepayan and dear list,
| >
| > I notice a small inconsistency with the command completion of the R CMD
| > check. --no-latex is deprecated sincs R 2.12.0 and defunct since 2.13.0
| > but the command line completion still suggests it:
| >
| > cb at cbdesktop:~/r-devel$ bin/R CMD check --no-<here I hit tab>
| > --no-clean ? ? ?--no-examples ? --no-latex ? ? ?--no-vignettes
| > --no-codoc ? ? ?--no-install ? ?--no-tests
| > cb at cbdesktop:~/r-devel$ bin/R CMD check --no-latex
| > Fehler: '--no-latex' is defunct: use '--no-manual' instead
| >
| > I gather the command line options could be updated to current R CMD
| > check in file /etc/bash_completion.d/R:
| >
| > cb at cbdesktop:~/tmp$ diff R /etc/bash_completion.d/R
| > 244,247c244,245
| > < ? ? ? ? ? ? ? ? ? --no-install --no-tests --no-vignettes --no-manual \
| > < ? ? ? ? ? --no-rebuild-vignettes --install-args ?--check-subdirs \
| > < ? ? ? ? ? --extra-arch --multiarch --no-multiarch --force-multiarch \
| > < ? ? ? ? ? ? ? ? ? --timings ?--use-gct --use-valgrind --rcfile"
| > ---
| >> ? ? ? ? ? ? ? ? ? --no-install --no-tests --no-vignettes --no-latex \
| >> ? ? ? ? ? ? ? ? ? --use-gct --use-valgrind --rcfile"
| >
| > I gather from the mailing list archives, that the original is available at
| > http://code.google.com/p/rcompletion/source/browse/trunk/bash_completion/R
| >
| > Should I suggest the patch there? Will changes propagate to the packaged
| > linux distributions from there or should the updated file be brought to
| > the attention somewhere else?
| 
| Thanks for the patch.
| 
| I believe only Debian/Ubuntu package it (and this would have been more
| appropriate for r-sig-debian). I'll coordinate with Dirk et al to
| update the relevant files.

That is indeed almost entirely a Deepayan (juicy code) and Dirk (mere
packaging) issue as the rest (Ubuntun etc) just follows from there.  And
r-sig-debian would indeed have been a good venue too.  But posting here makes
it a nice reminder to everybody not using the .deb package about what they
are missing :)

Dirk
 
| -Deepayan
| 
| ______________________________________________
| R-devel at r-project.org mailing list
| https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
"Outside of a dog, a book is a man's best friend. Inside of a dog, it is too
dark to read." -- Groucho Marx


From simon.urbanek at r-project.org  Wed Jan 11 19:21:05 2012
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Wed, 11 Jan 2012 13:21:05 -0500
Subject: [Rd] Copying objects prior to .Call
In-Reply-To: <4F0DCF1C.60005@statistik.tu-dortmund.de>
References: <CAM3Zkc4WuKMKS-CSCu2yYnqkEzZ=_39awBOyAa=H=_DY-U1YeA@mail.gmail.com>
	<B3877BB6-1156-4BD1-8B13-3EE2D3F81ABF@r-project.org>
	<4F0DCF1C.60005@statistik.tu-dortmund.de>
Message-ID: <7EEE1F9F-A6B2-4885-9FC0-09C90164FBB4@r-project.org>


On Jan 11, 2012, at 1:04 PM, Uwe Ligges wrote:

> 
> 
> On 11.01.2012 18:49, Simon Urbanek wrote:
>> 
>> On Jan 11, 2012, at 12:08 PM, Taylor Arnold wrote:
>> 
>>> R-devel,
>>> 
>>> I have noticed that making a copy of an object in R prior to using
>>> .Call on the original object can
>>> cause the C code to alter not only the object passed to it but also
>>> the copy in R.
>> 
>> Please see the docs - .Call does *NOT* have a DUP argument - you are responsible for duplication at all times if you make modifications (e.g. using duplicate()).
>> 
>> Cheers,
>> Simon
>> 
>> 
>>> A simple example
>>> is:
>>> 
>>>> x<- 2
>>>> y<- x
>>>> .Call("addOne", x, DUP=TRUE) # Changing DUP does not alter output
>>> NULL
>>>> x
>>> [1] 3
>>>> y
>>> [1] 3
>>> 
>>> And corresponding simple C code:
>>> 
>>> "test.c":
>>> #include<R.h>
>>> #include<Rinternals.h>
>>> #include<Rmath.h>
>>> 
>>> SEXP addOne(SEXP input) {
>>>   REAL(input)[0] = REAL(input)[0] + 1;
>>>   return R_NilValue;
>>> }
>>> 
>>> I assume that this is simply a result of lazy loading
> 
> In addition to Simon: it is "lazy evalution" rather than lazy loading in this case.
> 

It is actually neither. `x` gets evaluated, but the value is shared with `y` because R has no reason to create a copy of identical information until modified. That's why the .Call() code must create a copy if it wants to touch the value that it received. Note that .Call does *not* get `x` itself - it gets a value obtained from the binding of `x` so the only legal way to modify `x` is to assign a value to it. You can try to be more efficieint and check if a value has references to it and prevent copying if it doesn't (see NAMED), but if it does, you have to copy it.

Cheers,
Simon
 


> Uwe
> 
> 
>>> in R, and well
>>> documented. My question is, do
>>> there exist functions to (1) force R to make a copy of an object
>>> (force() does not work), and (2) to check
>>> whether two objects are actually pointing to the same memory address.
>>> For question 1, I have
>>> found specific operations which force a copy of a given datatype, but
>>> would prefer a more general
>>> solution.
>>> 
>>> Thank you,
>>> 
>>> Taylor
>>> 
>>>> sessionInfo()
>>> R version 2.14.1 (2011-12-22)
>>> Platform: x86_64-apple-darwin9.8.0/x86_64 (64-bit)
>>> 
>>> locale:
>>> [1] en_GB.UTF-8/en_GB.UTF-8/en_GB.UTF-8/C/en_GB.UTF-8/en_GB.UTF-8
>>> 
>>> attached base packages:
>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>> 
>>> loaded via a namespace (and not attached):
>>> [1] tools_2.14.1
>>> 
>>> 
>>> --
>>> Taylor B. Arnold
>>> Department of Statistics
>>> Yale University
>>> 24 Hillhouse Avenue
>>> New Haven, CT 06520
>>> 
>>> e-mail: taylor.arnold at yale.edu
>>> 
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>> 
>>> 
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From chuck at sharpsteen.net  Wed Jan 11 19:53:22 2012
From: chuck at sharpsteen.net (Sharpie)
Date: Wed, 11 Jan 2012 10:53:22 -0800 (PST)
Subject: [Rd] Command completion of the R binary / Ubuntu
In-Reply-To: <CADfFDC5qZU3Wuz7uA3H4CvzhOTns=cxDrYevCC-w0WND90rZeg@mail.gmail.com>
References: <4F0D6883.8010309@ipht-jena.de>
	<CADfFDC5qZU3Wuz7uA3H4CvzhOTns=cxDrYevCC-w0WND90rZeg@mail.gmail.com>
Message-ID: <1326308002886-4286476.post@n4.nabble.com>


Deepayan Sarkar-3 wrote
> 
> I believe only Debian/Ubuntu package it (and this would have been more
> appropriate for r-sig-debian). I'll coordinate with Dirk et al to
> update the relevant files.
> 
> -Deepayan
> 

The bash completion script is also used by the Homebrew package manager on
OS X.

-Charlie

-----
Charlie Sharpsteen
Undergraduate-- Environmental Resources Engineering
Humboldt State University
--
View this message in context: http://r.789695.n4.nabble.com/Command-completion-of-the-R-binary-Ubuntu-tp4285040p4286476.html
Sent from the R devel mailing list archive at Nabble.com.


From edd at debian.org  Wed Jan 11 20:42:39 2012
From: edd at debian.org (Dirk Eddelbuettel)
Date: Wed, 11 Jan 2012 13:42:39 -0600
Subject: [Rd] Silently loading and Depends: versus NAMESPACE imports
Message-ID: <20237.58927.327444.422917@max.nulle.part>


R CMD check really hates it when my .onLoad() function contains
    suppressMessages(library(foo))

However, _and for non-public packages not going to CRAN_ I prefer doing this
over using explicit Depends or import statements in the NAMESPACE file as the
latter do not give me an ability to make the loading less verbose.  With the
R universe of packages being as vast as at is, a simple (non-public) package
I have loads about five or six other packages explicitly, each of which loads
even more.  The net result is totally intimidating _sixty lines full_ of
verbose noise that is meaningful to me as an R programmer, but not for the
colleagues expected to use the packages. It looks rather uninviting, frankly.

How do I use imports via NAMESPACE, and yet keep the noise level down to zero?

Dirk

-- 
"Outside of a dog, a book is a man's best friend. Inside of a dog, it is too
dark to read." -- Groucho Marx


From Mark.Bravington at csiro.au  Wed Jan 11 21:54:12 2012
From: Mark.Bravington at csiro.au (Mark.Bravington at csiro.au)
Date: Thu, 12 Jan 2012 07:54:12 +1100
Subject: [Rd] parse( connection) and source-keeping
Message-ID: <3D59DF35E7CF3E42BA70C23BD5CBE6A85F6DA9302F@exvic-mbx04.nexus.csiro.au>

In R <= 2.13.x, calling 'parse( con)' where 'con' is a connection, 'options( keep.source)' is TRUE,  and default 'srcfile' would preserve the source. In R >= 2.14.1, it doesn't. 

> tf <- tempfile()
> options( keep.source=TRUE)
> texto <- c( 'function() { # comment', '}')
> parse( text=texto)
expression(function() { # comment
})
> cat( texto, file=tf, sep='\n')
> parse( file=tf)
expression(function() { # comment
})
> parse( file( tf))
expression(function() {
})
> parse( textConnection( texto))
expression(function() {
})

and yes I didn't bother closing any connections.

My suspicion is that this change is unintentional, and it seems to me that the best option would be for 'connection' to work like 'text' does here, ie to attach a 'srcfilecopy' containing the contents.

I didn't submit a bug report because the documentation (which hasn't changed in this respect) actually doesn't say what 'parse' should do with 'connection' (as opposed to 'text' or 'file') argument when 'getOption( keep.source)' is TRUE and 'srcfile' is NULL. [BTW it's also unstated which argument takes precedence if a non-default 'srcfile' argument is specified.] So some additional explanation is needed there at a minimum, but also a decision as to what the best behaviour would be.

bye
Mark

Mark Bravington
CSIRO CMIS
Marine Lab
Hobart
Australia


From jeff.hamann at forestinformatics.com  Wed Jan 11 23:11:41 2012
From: jeff.hamann at forestinformatics.com (Jeff Hamann)
Date: Wed, 11 Jan 2012 14:11:41 -0800
Subject: [Rd] package DESCRIPTION file and CRAN Task View entries?
Message-ID: <6584ED8B-D4FD-4954-BD31-DBEB786566FA@forestinformatics.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20120111/46f73a39/attachment.pl>

From jeff.hamann at forestinformatics.com  Wed Jan 11 23:33:33 2012
From: jeff.hamann at forestinformatics.com (Jeff Hamann)
Date: Wed, 11 Jan 2012 14:33:33 -0800
Subject: [Rd] R CMD check pkg and 32/64 bit.
Message-ID: <F423EE25-835E-4E5D-8FDE-68A10B16AD22@forestinformatics.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20120111/4084ff50/attachment.pl>

From edd at debian.org  Wed Jan 11 23:36:36 2012
From: edd at debian.org (Dirk Eddelbuettel)
Date: Wed, 11 Jan 2012 16:36:36 -0600
Subject: [Rd] package DESCRIPTION file and CRAN Task View entries?
In-Reply-To: <6584ED8B-D4FD-4954-BD31-DBEB786566FA@forestinformatics.com>
References: <6584ED8B-D4FD-4954-BD31-DBEB786566FA@forestinformatics.com>
Message-ID: <20238.3828.911616.51365@max.nulle.part>


On 11 January 2012 at 14:11, Jeff Hamann wrote:
| I'd like to add the updated rconifers package to the Environmetrics View.

In my case, other maintainers typically just email me suggestions for
inclusion in the two Task Views I look after.  And after all, there is always
a one-to-one match between a Task View and its (human, not robot) editor with
an email address.

Dirk

-- 
"Outside of a dog, a book is a man's best friend. Inside of a dog, it is too
dark to read." -- Groucho Marx


From murdoch.duncan at gmail.com  Thu Jan 12 02:36:03 2012
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 11 Jan 2012 20:36:03 -0500
Subject: [Rd] parse( connection) and source-keeping
In-Reply-To: <3D59DF35E7CF3E42BA70C23BD5CBE6A85F6DA9302F@exvic-mbx04.nexus.csiro.au>
References: <3D59DF35E7CF3E42BA70C23BD5CBE6A85F6DA9302F@exvic-mbx04.nexus.csiro.au>
Message-ID: <4F0E3903.1040803@gmail.com>

On 12-01-11 3:54 PM, Mark.Bravington at csiro.au wrote:
> In R<= 2.13.x, calling 'parse( con)' where 'con' is a connection, 'options( keep.source)' is TRUE,  and default 'srcfile' would preserve the source. In R>= 2.14.1, it doesn't.

Actually, it preserved the "source" attribute of the function if it 
could, but didn't add a srcref.  Sometimes it would fail, giving a 
message like

Error in parse(textConnection(texto)) :
   function is too long to keep source (at line 8812)


>
>> tf<- tempfile()
>> options( keep.source=TRUE)
>> texto<- c( 'function() { # comment', '}')
>> parse( text=texto)
> expression(function() { # comment
> })
>> cat( texto, file=tf, sep='\n')
>> parse( file=tf)
> expression(function() { # comment
> })
>> parse( file( tf))
> expression(function() {
> })
>> parse( textConnection( texto))
> expression(function() {
> })
>
> and yes I didn't bother closing any connections.
>
> My suspicion is that this change is unintentional, and it seems to me that the best option would be for 'connection' to work like 'text' does here, ie to attach a 'srcfilecopy' containing the contents.

Yes, that does sound like a good idea.

Duncan Murdoch

> I didn't submit a bug report because the documentation (which hasn't changed in this respect) actually doesn't say what 'parse' should do with 'connection' (as opposed to 'text' or 'file') argument when 'getOption( keep.source)' is TRUE and 'srcfile' is NULL. [BTW it's also unstated which argument takes precedence if a non-default 'srcfile' argument is specified.] So some additional explanation is needed there at a minimum, but also a decision as to what the best behaviour would be.
>
> bye
> Mark
>
> Mark Bravington
> CSIRO CMIS
> Marine Lab
> Hobart
> Australia
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From p.murrell at auckland.ac.nz  Thu Jan 12 03:58:08 2012
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Thu, 12 Jan 2012 15:58:08 +1300
Subject: [Rd] Inconsistencies in device_Raster when axes are reflected
In-Reply-To: <1326305479642-4286320.post@n4.nabble.com>
References: <1326305479642-4286320.post@n4.nabble.com>
Message-ID: <4F0E4C40.5060407@auckland.ac.nz>

Hi

On 12/01/2012 7:11 a.m., Sharpie wrote:
> I noticed some undocumented and inconsistent behavior in device_Raster when a
> plot is produced with reflected axes such as:
>
>      image(volcano, xlim = c(1,0), useRaster = TRUE)
>      image(volcano, ylim = c(1,0), useRaster = TRUE)
>
> The `pdf` device will perform horizontal and vertical reflections, while
> `quartz` will ignore the transformations when plotting to the screen, but
> when plotting to a file, `quartz(file = 'test.pdf', type = 'pdf')`, it will
> produce horizontal reflections and ignore vertical ones.
>
> When the `xlim` or `ylim` is reversed, negative widths and heights are
> passed to the C function `device_Raster`, which is not a behavior documented
> in `R_ext/GraphicsDevice.h`. Also, the values of `x` and `y` passed to
> `device_Raster` will be shifted by the width or height of the image such
> that the coordinates no longer reference the bottom-left corner of the image
> as `R_ext/GraphicsDevice.h` says they should.
>
> Given the inconsistencies in documentation and behavior, I am wondering what
> the intended behavior of `device_Raster` is in this situation.

I think the problem is that I just failed to anticipate this situation 
(i.e., the current documentation and behaviour both assume xlim[1] < 
xlim[2] and ylim[1] < ylim[2]).

Will take a look at where to apply a fix (EITHER allow the API to be 
more flexible [allow negative 'width' and 'height' and 'x' and 'y' to be 
other than left-bottom], which will require complicating the code in 
some devices OR keep the API fixed and complicate the graphics engine 
code instead).  The rotation argument adds an interesting twist ...

Thanks for the report!

Paul

> Thanks!
>
> -Charlie
>
> -----
> Charlie Sharpsteen
> Undergraduate-- Environmental Resources Engineering
> Humboldt State University
> --
> View this message in context: http://r.789695.n4.nabble.com/Inconsistencies-in-device-Raster-when-axes-are-reflected-tp4286320p4286320.html
> Sent from the R devel mailing list archive at Nabble.com.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/


From ripley at stats.ox.ac.uk  Thu Jan 12 05:51:41 2012
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 12 Jan 2012 04:51:41 +0000
Subject: [Rd] R CMD check pkg and 32/64 bit.
In-Reply-To: <F423EE25-835E-4E5D-8FDE-68A10B16AD22@forestinformatics.com>
References: <F423EE25-835E-4E5D-8FDE-68A10B16AD22@forestinformatics.com>
Message-ID: <4F0E66DD.6060802@stats.ox.ac.uk>

Take a closer look: the differences in output are not just in trailing 
digits.

We solve the latter in R itself mainly by use of e.g. options(digits=5) 
in the relevant \examples{} sections.

However, we also try to remove the numerical instability in the 
algorithms that leads to this.  Perhaps some convergence criterion is 
too loose?

Also, you can find out if this really is a 32/64-bit issue by running 
both architectures on the Mac (although 32/64 tends to be closer on that 
platform than on Linux or Windows).

On 11/01/2012 22:33, Jeff Hamann wrote:
> R gurus:
>
> I'm trying to get another round of rconifers out and I need some advice/help crushing differences in the examples test.
>
> I'm trying to make sure the max sdi values are being respected.
>
> I've added a tests/rconifers-Ex.Rout.save (from windows i386-pc-mingw32) and when I ran R CMD check (both R-2.13.0), I got the following results:
>
> * using log directory 'c:/conifers/trunk/rconifers.Rcheck'
> * using R version 2.13.0 (2011-04-13)
> * using platform: i386-pc-mingw32 (32-bit)
> * using session charset: ISO8859-1
> * checking for file 'rconifers/DESCRIPTION' ... OK
> * this is package 'rconifers' version '1.0.7'
> * checking package dependencies ... OK
> * checking if this is a source package ... OK
> * checking for executable files ... OK
> * checking whether package 'rconifers' can be installed ... OK
> * checking installed package size ... OK
> * checking package directory ... OK
> * checking for portable file names ... OK
> * checking DESCRIPTION meta-information ... OK
> * checking top-level files ... OK
> * checking index information ... OK
> * checking package subdirectories ... OK
> * checking R files for non-ASCII characters ... OK
> * checking R files for syntax errors ... OK
> * checking whether the package can be loaded ... OK
> * checking whether the package can be loaded with stated dependencies ... OK
> * checking whether the package can be unloaded cleanly ... OK
> * checking for unstated dependencies in R code ... OK
> * checking S3 generic/method consistency ... OK
> * checking replacement functions ... OK
> * checking foreign function calls ... OK
> * checking R code for possible problems ... OK
> * checking Rd files ... OK
> * checking Rd metadata ... OK
> * checking Rd cross-references ... OK
> * checking for missing documentation entries ... OK
> * checking for code/documentation mismatches ... OK
> * checking Rd \usage sections ... OK
> * checking Rd contents ... OK
> * checking for unstated dependencies in examples ... OK
> * checking contents of 'data' directory ... OK
> * checking data for non-ASCII characters ... OK
> * checking data for ASCII and uncompressed saves ... OK
> * checking line endings in C/C++/Fortran sources/headers ... WARNING
> Found the following sources/headers with CR or CRLF line endings:
>    src/coeffs_cips.c
>    src/coeffs_mgt.c
>    src/coeffs_smc.c
>    src/coeffs_swo.c
>    src/coeffs_swohybrid.c
>    src/conifers.h
>    src/file_io.c
>    src/grow.c
>    src/model_cips.c
>    src/model_smc.c
>    src/model_swo.c
>    src/model_swohybrid.c
>    src/mortality.c
>    src/plot.c
>    src/rconifers.c
>    src/stats.c
>    src/thin.c
> Some Unix compilers require LF line endings.
> * checking line endings in Makefiles ... OK
> * checking for portable use of $(BLAS_LIBS) and $(LAPACK_LIBS) ... OK
> * checking examples ... OK
> * checking differences from 'rconifers-Ex.Rout' to 'rconifers-Ex.Rout.save' ... OK
> * checking PDF version of manual ... OK
> WARNING: There was 1 warning, see
>    'c:/conifers/trunk/rconifers.Rcheck/00check.log'
> for details
>
> The magic line is:
>
> * checking differences from 'rconifers-Ex.Rout' to 'rconifers-Ex.Rout.save' ... OK
>
> which tells me that the check file matched the expected file.
>
>
>
> When I ran the check under OSX and got the following results:
>
> macbook:Desktop hamannjd$ R CMD check rconifers
> * using log directory ?/Users/hamannjd/Desktop/rconifers.Rcheck?
> * using R version 2.13.0 (2011-04-13)
> * using platform: x86_64-apple-darwin10.7.0 (64-bit)
> * using session charset: UTF-8
> * checking for file ?rconifers/DESCRIPTION? ... OK
> * this is package ?rconifers? version ?1.0.7?
> * checking package dependencies ... OK
> * checking if this is a source package ... OK
> * checking for executable files ... OK
> * checking whether package ?rconifers? can be installed ... OK
> * checking installed package size ... OK
> * checking package directory ... OK
> * checking for portable file names ... OK
> * checking for sufficient/correct file permissions ... OK
> * checking DESCRIPTION meta-information ... OK
> * checking top-level files ... OK
> * checking index information ... OK
> * checking package subdirectories ... OK
> * checking R files for non-ASCII characters ... OK
> * checking R files for syntax errors ... OK
> * checking whether the package can be loaded ... OK
> * checking whether the package can be loaded with stated dependencies ... OK
> * checking whether the package can be unloaded cleanly ... OK
> * checking for unstated dependencies in R code ... OK
> * checking S3 generic/method consistency ... OK
> * checking replacement functions ... OK
> * checking foreign function calls ... OK
> * checking R code for possible problems ... OK
> * checking Rd files ... OK
> * checking Rd metadata ... OK
> * checking Rd cross-references ... OK
> * checking for missing documentation entries ... OK
> * checking for code/documentation mismatches ... OK
> * checking Rd \usage sections ... OK
> * checking Rd contents ... OK
> * checking for unstated dependencies in examples ... OK
> * checking contents of 'data' directory ... OK
> * checking data for non-ASCII characters ... OK
> * checking data for ASCII and uncompressed saves ... OK
> * checking line endings in C/C++/Fortran sources/headers ... OK
> * checking line endings in Makefiles ... OK
> * checking for portable use of $(BLAS_LIBS) and $(LAPACK_LIBS) ... OK
> * checking examples ... OK
> * checking differences from ?rconifers-Ex.Rout? to ?rconifers-Ex.Rout.save? ...
> 0a1
>>> options(pager = "console")
> 377,383c378,384
> <  1    1      DF 2.08 0.61  7.08 0.845       1  100        4.40      0
> <  2    1      PP 4.80 2.91 11.50 0.852       1  100        7.55      0
> <  3    2      IC 0.60 0.00  1.70 0.706       1  100        1.17      0
> <  4    2      PP 0.51 0.00  1.34 0.478       1  100        1.37      0
> <  5    2      IC 0.50 0.00  1.06 0.623       1  100        0.98      0
> <  6    2      IC 0.34 0.00  0.76 0.474       1  100        0.60      0
> <  7    2      IC 0.17 0.00  0.58 0.310       1  100        0.29      0
> ---
>> 1    1      DF  2.08  0.61  7.08 0.845       1 100.00    4.400000      0
>> 2    1      PP  4.80  2.91 11.50 0.852       1 100.00    7.550000      0
>> 3    2      WF 49.00 35.20 77.96 0.368       1   2.96   30.152669      0
>> 4    2      PP  2.43  1.10  6.28 0.705       1 100.00    3.773147      0
>> 5    2    COCO  0.49  0.00  3.90 1.000      18 100.00    2.360064      0
>> 6    2      DF  1.06  0.00  3.88 0.794       1 100.00    2.973220      0
>> 7    2      IC  0.60  0.00  1.70 0.706       1 100.00    1.170000      0
> 2076c2077
> <  max sdi =  400.955
> ---
>> max sdi =  400.222
> 2078,2084c2079,2085
> <  CEIN  0.000000  8.57557  0.000000 250.00 250.00
> <  COCO  0.000000 10.65750  0.000000 825.00 825.00
> <  DF    3.871848 32.37521 34.749737 425.00 425.00
> <  IC    0.680329  7.94603  0.757329 300.00 500.00
> <  PM    4.882285 33.89248 84.505614 650.00 650.00
> <  PP   10.747477 42.37973 62.999774 100.00 100.00
> <  WF    1.961988  7.49918  5.264321 250.74 275.74
> ---
>> CEIN  0.000000  8.83025  0.00000 250.00 250.00
>> COCO  0.000000 10.52370  0.00000 825.00 825.00
>> DF    3.380206 28.96161 26.48507 425.00 425.00
>> IC    0.997025  8.10528  1.49098 275.00 500.00
>> PM    5.036259 34.20425 89.91983 650.00 650.00
>> PP   10.505312 41.18743 60.19271 100.00 100.00
>> WF    2.089732  7.81061  5.37670 225.74 275.74
> 2094c2095
> <  max sdi =  400.955
> ---
>> max sdi =  400.222
> 2096,2102c2097,2103
> <  CEIN  0.000000  8.57557  0.000000 250.00 250.00
> <  COCO  0.000000 10.65750  0.000000 825.00 825.00
> <  DF    3.871848 32.37521 34.749737 425.00 425.00
> <  IC    0.680329  7.94603  0.757329 300.00 500.00
> <  PM    4.882285 33.89248 84.505614 650.00 650.00
> <  PP   10.747477 42.37973 62.999774 100.00 100.00
> <  WF    1.961988  7.49918  5.264321 250.74 275.74
> ---
>> CEIN  0.000000  8.83025  0.00000 250.00 250.00
>> COCO  0.000000 10.52370  0.00000 825.00 825.00
>> DF    3.380206 28.96161 26.48507 425.00 425.00
>> IC    0.997025  8.10528  1.49098 275.00 500.00
>> PM    5.036259 34.20425 89.91983 650.00 650.00
>> PP   10.505312 41.18743 60.19271 100.00 100.00
>> WF    2.089732  7.81061  5.37670 225.74 275.74
> 2513c2514
> <  max sdi =  398.99
> ---
>> max sdi =  398.321
> 2515,2521c2516,2522
> <  CEIN  0.00000  8.74666  0.000000 250.00 250.00
> <  COCO  0.00000 10.60946  0.000000 825.00 825.00
> <  DF    3.17032 28.17772 23.298195 425.00 425.00
> <  IC    1.02363  6.08777  0.857239 150.00 500.00
> <  PM    5.02216 33.93141 89.417000 650.00 650.00
> <  PP   10.53209 40.19664 60.500008 100.00 100.00
> <  WF    2.52830  5.38780  5.255483 150.74 275.74
> ---
>> CEIN  0.00000  8.73566  0.000000 250.00 250.00
>> COCO  0.00000 10.60959  0.000000 825.00 825.00
>> DF    3.11552 27.87012 22.499678 425.00 425.00
>> IC    1.02147  6.04613  0.853626 150.00 500.00
>> PM    5.01949 33.92538 89.322114 650.00 650.00
>> PP   10.60861 40.42145 61.382237 100.00 100.00
>> WF    2.52834  5.37677  5.255645 150.74 275.74
> 2535c2536
> <  max sdi =  392.682
> ---
>> max sdi =  392.183
> 2537,2543c2538,2544
> <  CEIN  0.00000  8.74666  0.000000 250.0000 250.0000
> <  COCO  0.00000 10.60946  0.000000 825.0000 825.0000
> <  DF    6.12078 42.83671 10.413135  50.9615  50.9615
> <  IC    1.02363  6.08777  0.857239 150.0000 500.0000
> <  PM    5.02216 33.93141 89.417000 650.0000 650.0000
> <  PP   10.53209 40.19664 60.500008 100.0000 100.0000
> <  WF    2.52830  5.38780  5.255483 150.7400 275.7400
> ---
>> CEIN  0.00000  8.73566  0.000000 250.0000 250.0000
>> COCO  0.00000 10.60959  0.000000 825.0000 825.0000
>> DF    6.01295 42.00488 10.049466  50.9615  50.9615
>> IC    1.02147  6.04613  0.853626 150.0000 500.0000
>> PM    5.01949 33.92538 89.322114 650.0000 650.0000
>> PP   10.60861 40.42145 61.382237 100.0000 100.0000
>> WF    2.52834  5.37677  5.255645 150.7400 275.7400
> 2555c2556
> <  max sdi =  390.319
> ---
>> max sdi =  389.507
> 2557,2563c2558,2564
> <  CEIN  0.00000  8.74666 0.0000000 250.00000 250.00000
> <  COCO  0.00000 10.60946 0.0000000 825.00000 825.00000
> <  DF    6.25984 44.26174 3.2535039  15.22296  15.22296
> <  IC    1.20533 11.86522 0.0609674   7.69418  11.76394
> <  PM    4.85482 33.74425 2.0646472  16.06105  16.06105
> <  PP   11.23175 42.87801 8.8974623  12.93139  12.93139
> <  WF    3.77143  6.55036 0.3592728   4.63112   6.08461
> ---
>> CEIN  0.00000  8.73566 0.0000000 250.00000 250.00000
>> COCO  0.00000 10.60959 0.0000000 825.00000 825.00000
>> DF    6.15956 43.58377 3.1501027  15.22296  15.22296
>> IC    1.20280 11.77230 0.0607118   7.69418  11.76394
>> PM    4.84104 33.71376 2.0529479  16.06105  16.06105
>> PP   11.34546 43.47322 9.0785299  12.93139  12.93139
>> WF    3.77112  6.46029 0.3592136   4.63112   6.08461
> 2575c2576
> <  max sdi =  380.439
> ---
>> max sdi =  380.211
> 2577,2578c2578,2579
> <  CEIN  0.00000  8.74666  0.00000 250.00 250.00
> <  COCO  0.00000 10.60946  0.00000 825.00 825.00
> ---
>> CEIN  0.00000  8.73566  0.00000 250.00 250.00
>> COCO  0.00000 10.60959  0.00000 825.00 825.00
> 2581,2583c2582,2584
> <  PM    5.44998 35.20515 12.15001  75.00  75.00
> <  PP   11.68521 44.09759 28.47847  38.24  38.24
> <  WF   35.20006 78.07609  5.00086   0.74   0.74
> ---
>> PM    5.45033 35.20515 12.15159  75.00  75.00
>> PP   11.79190 44.68573 29.00089  38.24  38.24
>> WF   35.20006 78.07794  5.00086   0.74   0.74
> 2595c2596
> <  max sdi =  392.617
> ---
>> max sdi =  391.885
> 2597,2603c2598,2604
> <  CEIN  0.00000  8.74666  0.000000 250.00 250.00
> <  COCO  0.00000 10.60946  0.000000 825.00 825.00
> <  DF    3.17032 28.17772 23.298195 425.00 425.00
> <  IC    1.02363  6.08777  0.857239 150.00 500.00
> <  PM    5.21231 34.66273 16.670145 112.50 112.50
> <  PP   10.53209 40.19664 60.500008 100.00 100.00
> <  WF    2.52830  5.38780  5.255483 150.74 275.74
> ---
>> CEIN  0.00000  8.73566  0.000000 250.00 250.00
>> COCO  0.00000 10.60959  0.000000 825.00 825.00
>> DF    3.11552 27.87012 22.499678 425.00 425.00
>> IC    1.02147  6.04613  0.853626 150.00 500.00
>> PM    5.20525 34.64531 16.624992 112.50 112.50
>> PP   10.60861 40.42145 61.382237 100.00 100.00
>> WF    2.52834  5.37677  5.255645 150.74 275.74
> 3543,3544c3544,3545
> <  x0 =  6.83298
> <  max sdi =  398.507
> ---
>> x0 =  6.83124
>> max sdi =  398.773
> 3546,3552c3547,3553
> <  CEIN  0.00000  8.76683  0.000000 250.0000 250.0000
> <  COCO  0.00000 10.60933  0.000000 825.0000 825.0000
> <  DF    3.14048 27.68502 21.449519 398.7488 398.7488
> <  IC    1.01997  6.15100  0.798552 140.7349 469.1162
> <  PM    5.02023 33.92625 83.829537 609.8511 609.8511
> <  PP   10.60746 40.60003 57.578321  93.8232  93.8232
> <  WF    2.53410  5.48953  4.953497 141.4292 258.7082
> ---
>> CEIN  0.00000  8.74366  0.00000 250.0000 250.0000
>> COCO  0.00000 10.61129  0.00000 825.0000 825.0000
>> DF    3.16517 28.02873 21.78805 398.7488 398.7488
>> IC    1.00100  6.04754  0.76913 140.7349 469.1162
>> PM    5.01960 33.92487 83.80863 609.8511 609.8511
>> PP   10.57284 40.39489 57.20315  93.8232  93.8232
>> WF    2.53248  5.45694  4.94718 141.4292 258.7082
> 3565,3566c3566,3567
> <  x0 =  6.83298
> <  max sdi =  392.685
> ---
>> x0 =  6.83124
>> max sdi =  392.866
> 3568,3574c3569,3575
> <  CEIN  0.00000  8.76683  0.000000 250.0000 250.0000
> <  COCO  0.00000 10.60933  0.000000 825.0000 825.0000
> <  DF    6.06366 42.37577 10.219698  50.9615  50.9615
> <  IC    1.01997  6.15100  0.798552 140.7349 469.1162
> <  PM    5.02023 33.92625 83.829537 609.8511 609.8511
> <  PP   10.60746 40.60003 57.578321  93.8232  93.8232
> <  WF    2.53410  5.48953  4.953497 141.4292 258.7082
> ---
>> CEIN  0.00000  8.74366  0.00000 250.0000 250.0000
>> COCO  0.00000 10.61129  0.00000 825.0000 825.0000
>> DF    6.10480 42.74745 10.35884  50.9615  50.9615
>> IC    1.00100  6.04754  0.76913 140.7349 469.1162
>> PM    5.01960 33.92487 83.80863 609.8511 609.8511
>> PP   10.57284 40.39489 57.20315  93.8232  93.8232
>> WF    2.53248  5.45694  4.94718 141.4292 258.7082
> 3586,3587c3587,3588
> <  x0 =  6.83298
> <  max sdi =  389.955
> ---
>> x0 =  6.83124
>> max sdi =  390.023
> 3589,3595c3590,3596
> <  CEIN  0.00000  8.76683 0.0000000 250.00000 250.00000
> <  COCO  0.00000 10.60933 0.0000000 825.00000 825.00000
> <  DF    6.22626 44.06074 3.2186911  15.22296  15.22296
> <  IC    1.20102 12.07219 0.0605327   7.69418  11.76394
> <  PM    4.84437 33.71814 2.0557684  16.06105  16.06105
> <  PP   11.29807 43.23521 9.0028449  12.93139  12.93139
> <  WF    3.77756  6.95055 0.3604408   4.63112   6.08461
> ---
>> CEIN  0.00000  8.74366 0.0000000 250.00000 250.00000
>> COCO  0.00000 10.61129 0.0000000 825.00000 825.00000
>> DF    6.24021 44.22627 3.2331328  15.22296  15.22296
>> IC    1.17869 11.77423 0.0583023   7.69418  11.76394
>> PM    4.84002 33.71119 2.0520768  16.06105  16.06105
>> PP   11.28971 43.23397 8.9895303  12.93139  12.93139
>> WF    3.77333  6.65046 0.3596351   4.63112   6.08461
> 3607,3608c3608,3609
> <  x0 =  6.83298
> <  max sdi =  380.894
> ---
>> x0 =  6.83124
>> max sdi =  380.956
> 3610,3611c3611,3612
> <  CEIN  0.0000  8.76683  0.00000 250.000000 250.000000
> <  COCO  0.0000 10.60933  0.00000 825.000000 825.000000
> ---
>> CEIN  0.00000  8.74366  0.00000 250.000000 250.000000
>> COCO  0.00000 10.61129  0.00000 825.000000 825.000000
> 3614,3616c3615,3617
> <  PM    5.4510 35.20515 10.65304  65.734863  65.734863
> <  PP   11.7561 44.51895 25.29875  33.561724  33.561724
> <  WF   35.2001 78.07525  4.69197   0.694292   0.694292
> ---
>> PM    5.44942 35.20515 10.64688  65.734863  65.734863
>> PP   11.72679 44.43688 25.17262  33.561724  33.561724
>> WF   35.20006 78.07609  4.69197   0.694292   0.694292
> 3627,3628c3628,3629
> <  x0 =  6.83298
> <  max sdi =  392.251
> ---
>> x0 =  6.83124
>> max sdi =  392.539
> 3630,3636c3631,3637
> <  CEIN  0.00000  8.76683  0.000000 250.0000 250.0000
> <  COCO  0.00000 10.60933  0.000000 825.0000 825.0000
> <  DF    3.14048 27.68502 21.449519 398.7488 398.7488
> <  IC    1.01997  6.15100  0.798552 140.7349 469.1162
> <  PM    5.20745 34.64782 16.639048 112.5000 112.5000
> <  PP   10.60746 40.60003 57.578321  93.8232  93.8232
> <  WF    2.53410  5.48953  4.953497 141.4292 258.7082
> ---
>> CEIN  0.00000  8.74366  0.00000 250.0000 250.0000
>> COCO  0.00000 10.61129  0.00000 825.0000 825.0000
>> DF    3.16517 28.02873 21.78805 398.7488 398.7488
>> IC    1.00100  6.04754  0.76913 140.7349 469.1162
>> PM    5.20398 34.64385 16.61688 112.5000 112.5000
>> PP   10.57284 40.39489 57.20315  93.8232  93.8232
>> WF    2.53248  5.45694  4.94718 141.4292 258.7082
> 3645c3646
> <  PM   0.1872181 0.7215733 -67.19049 -497.3511 -497.3511
> ---
>> PM   0.1843748 0.7189766 -67.19175 -497.3511 -497.3511
> 4375c4376
> <  max sdi =  398.846
> ---
>> max sdi =  398.41
> 4377,4383c4378,4384
> <  CEIN  0.00000  8.77646  0.00000 250.00 250.00
> <  COCO  0.00000 10.60993  0.00000 825.00 825.00
> <  DF    3.13603 27.61661 22.79684 425.00 425.00
> <  IC    1.04211  6.09452  0.88848 150.00 500.00
> <  PM    5.02090 33.92971 89.37223 650.00 650.00
> <  PP   10.51368 40.06350 60.28859 100.00 100.00
> <  WF    2.52873  5.30578  5.25726 150.74 275.74
> ---
>> CEIN  0.00000  8.77723  0.000000 250.00 250.00
>> COCO  0.00000 10.61171  0.000000 825.00 825.00
>> DF    3.14884 27.68445 22.983527 425.00 425.00
>> IC    1.00402  6.06886  0.824718 150.00 500.00
>> PM    5.01909 33.92520 89.307792 650.00 650.00
>> PP   10.64086 41.03086 61.755992 100.00 100.00
>> WF    2.53101  5.46218  5.266755 150.74 275.74
> 4403c4404
> <  max sdi =  392.643
> ---
>> max sdi =  392.207
> 4405,4411c4406,4412
> <  CEIN  0.00000  8.77646  0.00000 250.0000 250.0000
> <  COCO  0.00000 10.60993  0.00000 825.0000 825.0000
> <  DF    6.06295 42.12905 10.21732  50.9615  50.9615
> <  IC    1.04211  6.09452  0.88848 150.0000 500.0000
> <  PM    5.02090 33.92971 89.37223 650.0000 650.0000
> <  PP   10.51368 40.06350 60.28859 100.0000 100.0000
> <  WF    2.52873  5.30578  5.25726 150.7400 275.7400
> ---
>> CEIN  0.00000  8.77723  0.000000 250.0000 250.0000
>> COCO  0.00000 10.61171  0.000000 825.0000 825.0000
>> DF    6.09105 42.58754 10.312236  50.9615  50.9615
>> IC    1.00402  6.06886  0.824718 150.0000 500.0000
>> PM    5.01909 33.92520 89.307792 650.0000 650.0000
>> PP   10.64086 41.03086 61.755992 100.0000 100.0000
>> WF    2.53101  5.46218  5.266755 150.7400 275.7400
> 4423c4424
> <  max sdi =  389.885
> ---
>> max sdi =  389.775
> 4425,4431c4426,4432
> <  CEIN  0.00000  8.77646 0.0000000 250.00000 250.00000
> <  COCO  0.00000 10.60993 0.0000000 825.00000 825.00000
> <  DF    6.16773 43.35916 3.1584660  15.22296  15.22296
> <  IC    1.22710 11.95206 0.0631897   7.69418  11.76394
> <  PM    4.84963 33.73568 2.0602370  16.06105  16.06105
> <  PP   11.24155 42.89267 8.9129985  12.93139  12.93139
> <  WF    3.76924  6.14318 0.3588566   4.63112   6.08461
> ---
>> CEIN  0.00000  8.77723 0.0000000 250.00000 250.00000
>> COCO  0.00000 10.61171 0.0000000 825.00000 825.00000
>> DF    6.23059 44.06992 3.2231765  15.22296  15.22296
>> IC    1.18225 11.84774 0.0586553   7.69418  11.76394
>> PM    4.84046 33.71283 2.0524548  16.06105  16.06105
>> PP   11.35786 43.84667 9.0983840  12.93139  12.93139
>> WF    3.77715  6.98331 0.3603637   4.63112   6.08461
> 4443c4444
> <  max sdi =  380.596
> ---
>> max sdi =  380.196
> 4445,4446c4446,4447
> <  CEIN  0.00000  8.77646  0.00000 250.00 250.00
> <  COCO  0.00000 10.60993  0.00000 825.00 825.00
> ---
>> CEIN  0.00000  8.77723  0.00000 250.00 250.00
>> COCO  0.00000 10.61171  0.00000 825.00 825.00
> 4449,4451c4450,4452
> <  PM    5.45189 35.20515 12.15853  75.00  75.00
> <  PP   11.61414 43.44836 28.13313  38.24  38.24
> <  WF   35.20006 78.06928  5.00086   0.74   0.74
> ---
>> PM    5.45229 35.20515 12.16032  75.00  75.00
>> PP   11.80005 45.00217 29.04102  38.24  38.24
>> WF   35.20006 78.07701  5.00086   0.74   0.74
> 4463c4464
> <  max sdi =  392.417
> ---
>> max sdi =  392.047
> 4465,4471c4466,4472
> <  CEIN  0.00000  8.77646  0.00000 250.00 250.00
> <  COCO  0.00000 10.60993  0.00000 825.00 825.00
> <  DF    3.13603 27.61661 22.79684 425.00 425.00
> <  IC    1.04211  6.09452  0.88848 150.00 500.00
> <  PM    5.21096 34.65783 16.66151 112.50 112.50
> <  PP   10.51368 40.06350 60.28859 100.00 100.00
> <  WF    2.52873  5.30578  5.25726 150.74 275.74
> ---
>> CEIN  0.00000  8.77723  0.000000 250.00 250.00
>> COCO  0.00000 10.61171  0.000000 825.00 825.00
>> DF    3.14884 27.68445 22.983527 425.00 425.00
>> IC    1.00402  6.06886  0.824718 150.00 500.00
>> PM    5.20639 34.64478 16.632280 112.50 112.50
>> PP   10.64086 41.03086 61.755992 100.00 100.00
>> WF    2.53101  5.46218  5.266755 150.74 275.74
>   OK
> * checking PDF version of manual ... OK
>
> macbook:Desktop hamannjd$
>
> I need to control the number of digits printed to remove the , but need to focus on the max sdi values.
>
> I'm assuming this is a 32/64-bit issue, but don't yet know how to control for that.
>
> Ideas?
>
> Respectfully,
> Jeff.
>
>
> Jeff Hamann, PhD
> PO Box 1421
> Corvallis, Oregon 97339-1421
> 541-754-2457
> jeff.hamann[at]forestinformatics[dot]com
> jeff.d.hamann[at]gmail[dot]com
> http://www.forestinformatics.com
> http://en.wikipedia.org/wiki/Forest_informatics
>
> To ensure that your email is processed, include a subject entry in your email.
>
>
>
>
>
> 	[[alternative HTML version deleted]]
>
>
>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From claudia.beleites at ipht-jena.de  Thu Jan 12 11:10:36 2012
From: claudia.beleites at ipht-jena.de (Claudia Beleites)
Date: Thu, 12 Jan 2012 11:10:36 +0100
Subject: [Rd] Command completion of the R binary / Ubuntu
In-Reply-To: <1326308002886-4286476.post@n4.nabble.com>
References: <4F0D6883.8010309@ipht-jena.de>
	<CADfFDC5qZU3Wuz7uA3H4CvzhOTns=cxDrYevCC-w0WND90rZeg@mail.gmail.com>
	<1326308002886-4286476.post@n4.nabble.com>
Message-ID: <4F0EB19C.60503@ipht-jena.de>

Am 11.01.2012 19:53, schrieb Sharpie:
> The bash completion script is also used by the Homebrew package manager on
> OS X.
There we go... good to know.


-- 
Claudia Beleites
Spectroscopy/Imaging
Institute of Photonic Technology
Albert-Einstein-Str. 9
07745 Jena
Germany

email: claudia.beleites at ipht-jena.de
phone: +49 3641 206-133
fax:   +49 2641 206-399


From murdoch.duncan at gmail.com  Thu Jan 12 14:57:00 2012
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 12 Jan 2012 08:57:00 -0500
Subject: [Rd] parse( connection) and source-keeping
In-Reply-To: <4F0E3903.1040803@gmail.com>
References: <3D59DF35E7CF3E42BA70C23BD5CBE6A85F6DA9302F@exvic-mbx04.nexus.csiro.au>
	<4F0E3903.1040803@gmail.com>
Message-ID: <4F0EE6AC.7010606@gmail.com>

On 11/01/2012 8:36 PM, Duncan Murdoch wrote:
> On 12-01-11 3:54 PM, Mark.Bravington at csiro.au wrote:
> >  In R<= 2.13.x, calling 'parse( con)' where 'con' is a connection, 'options( keep.source)' is TRUE,  and default 'srcfile' would preserve the source. In R>= 2.14.1, it doesn't.
>
> Actually, it preserved the "source" attribute of the function if it
> could, but didn't add a srcref.  Sometimes it would fail, giving a
> message like
>
> Error in parse(textConnection(texto)) :
>     function is too long to keep source (at line 8812)
>
>
> >
> >>  tf<- tempfile()
> >>  options( keep.source=TRUE)
> >>  texto<- c( 'function() { # comment', '}')
> >>  parse( text=texto)
> >  expression(function() { # comment
> >  })
> >>  cat( texto, file=tf, sep='\n')
> >>  parse( file=tf)
> >  expression(function() { # comment
> >  })
> >>  parse( file( tf))
> >  expression(function() {
> >  })
> >>  parse( textConnection( texto))
> >  expression(function() {
> >  })
> >
> >  and yes I didn't bother closing any connections.
> >
> >  My suspicion is that this change is unintentional, and it seems to me that the best option would be for 'connection' to work like 'text' does here, ie to attach a 'srcfilecopy' containing the contents.
>
> Yes, that does sound like a good idea.

I've taken a look, and this doesn't look like something I'll fix for 
2.15.0.  Here's why:

The entry points to the parser are really quite a mess, and need to be 
cleaned up:  working around this problem without that cleanup would make 
them messier, and I don't have time for the cleanup before 2.15.0.

Part of the problem is that connections are so flexible:  the parser 
doesn't know whether the connection passed to it is at the beginning, or 
whether you've already read some lines from it; it might not even have a 
beginning (e.g. stdin()).

There is a relatively easy workaround if you really need this:   you can 
make the srcfilecopy yourself, and pass it as the "srcfile" argument to 
parse.  (This won't work on the stdin() connection, but if you're the 
one creating the connection, you can perhaps work around that.  By the 
time parse() is called, it's too late.)

The parser does manage to handle input coming from the console, because 
that case uses a different entry point to the parser, and it keeps a 
buffer of all input.  (It needs to do this because you might not be 
finished typing yet, and it will start over again when you enter the 
next line.)  So connections (even stdin()) could be handled in the same 
way, and when I do the big cleanup, that's probably what will happen.

If you have a particular use case in mind and the workaround above isn't 
sufficient, let me know.

Duncan Murdoch


From ron_michael70 at yahoo.com  Thu Jan 12 16:27:05 2012
From: ron_michael70 at yahoo.com (Ron Michael)
Date: Thu, 12 Jan 2012 20:57:05 +0530 (IST)
Subject: [Rd] How to modify the start-up message
Message-ID: <1326382025.29925.YahooMailNeo@web94902.mail.in2.yahoo.com>

Hi all, I got a custom R package in .zip (i.e. meant only for Windows installation). When I load that package, there are some start-up messages, probably loading through .onLoad() function. However I want to modify those messages. Please note that I do not have any other version of that package like .tar.gz fomat etc.

Having only the .zip version, is there any possibility to modify those start-up functionalities of that package?

Thanks for your help.


From chuck at sharpsteen.net  Thu Jan 12 18:18:22 2012
From: chuck at sharpsteen.net (Sharpie)
Date: Thu, 12 Jan 2012 09:18:22 -0800 (PST)
Subject: [Rd] Inconsistencies in device_Raster when axes are reflected
In-Reply-To: <4F0E4C40.5060407@auckland.ac.nz>
References: <1326305479642-4286320.post@n4.nabble.com>
	<4F0E4C40.5060407@auckland.ac.nz>
Message-ID: <1326388702792-4289713.post@n4.nabble.com>


Paul Murrell wrote
> 
> I think the problem is that I just failed to anticipate this situation 
> (i.e., the current documentation and behaviour both assume xlim[1] < 
> xlim[2] and ylim[1] < ylim[2]).
> 
> Will take a look at where to apply a fix (EITHER allow the API to be 
> more flexible [allow negative 'width' and 'height' and 'x' and 'y' to be 
> other than left-bottom], which will require complicating the code in 
> some devices OR keep the API fixed and complicate the graphics engine 
> code instead).  The rotation argument adds an interesting twist ...
> 
> Thanks for the report!
> 
> Paul
> 

Thanks for the reply Paul!

This isn't too hard to handle at the device level. For example, all I had to
do to the tikzDevice was add a loop and some logic that re-ordered the
raster vector and re-positioned the coordinate anchor:


int i, j, index, target, row_offset = 0, col_offset = 0, row_trans = 1,
col_trans = 1;
  if ( height < 0 ) {
    /* Using these parameters, one can cause a loop to "count backwards" */
    row_trans = -1;
    row_offset = h - 1;
    /*
     * If a dimension is negative, the (x,y) coordinate no longer references
     * the lower left corner of the image. We correct for this and then make
     * sure the dimension is positive.
     */
    y += height;
    height = fabs(height);
  }

  if ( width < 0 ) {
    col_trans = -1;
    col_offset = w - 1;
    x += width;
    width = fabs(width);
  }

  for ( i = 0; i < h; ++i ) {
    for ( j = 0; j < w; ++j ) {
      target = i*w + j;
      index = (row_trans*i + row_offset)*w + (col_trans*j + col_offset);

      INTEGER(red_vec)[target] = R_RED(raster[index]);
      INTEGER(green_vec)[target] = R_BLUE(raster[index]);
      INTEGER(blue_vec)[target] = R_GREEN(raster[index]);
      INTEGER(alpha_vec)[target] = R_ALPHA(raster[index]);
    }
  }


This gives the device the same behavior as the PDF device. So, the behavior
isn't too difficult to correct on the device end---I was just concerned by
the difference between documentation and behavior and wanted to make sure
the graphics engine was not expecting something different.


-Charlie

-----
Charlie Sharpsteen
Undergraduate-- Environmental Resources Engineering
Humboldt State University
--
View this message in context: http://r.789695.n4.nabble.com/Inconsistencies-in-device-Raster-when-axes-are-reflected-tp4286320p4289713.html
Sent from the R devel mailing list archive at Nabble.com.


From hpages at fhcrc.org  Thu Jan 12 21:12:48 2012
From: hpages at fhcrc.org (=?ISO-8859-1?Q?Herv=E9_Pag=E8s?=)
Date: Thu, 12 Jan 2012 12:12:48 -0800
Subject: [Rd] Silently loading and Depends: versus NAMESPACE imports
In-Reply-To: <20237.58927.327444.422917@max.nulle.part>
References: <20237.58927.327444.422917@max.nulle.part>
Message-ID: <4F0F3EC0.5060500@fhcrc.org>

Hi Dirk,

On 01/11/2012 11:42 AM, Dirk Eddelbuettel wrote:
>
> R CMD check really hates it when my .onLoad() function contains
>      suppressMessages(library(foo))

Note that you can always fool 'R CMD check' by doing something like:

     sillyname <- library
     suppressMessages(sillyname("foo"))

Also isn't suppressPackageStartupMessages() more appropriate?

>
> However, _and for non-public packages not going to CRAN_ I prefer doing this
> over using explicit Depends or import statements in the NAMESPACE file as the
> latter do not give me an ability to make the loading less verbose.  With the
> R universe of packages being as vast as at is, a simple (non-public) package
> I have loads about five or six other packages explicitly, each of which loads
> even more.  The net result is totally intimidating _sixty lines full_ of
> verbose noise that is meaningful to me as an R programmer, but not for the
> colleagues expected to use the packages. It looks rather uninviting, frankly.
>
> How do I use imports via NAMESPACE, and yet keep the noise level down to zero?

If you only need to import foo (i.e. and actually don't need to attach
it to the search path) then putting foo in Imports and using import
statements in NAMESPACE will keep the noise level down to zero.

So I guess your question is: how do we suppress package startup messages
for packages listed in Depends?

Cheers,
H.

>
> Dirk
>


-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fhcrc.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From hb at biostat.ucsf.edu  Fri Jan 13 04:17:18 2012
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Thu, 12 Jan 2012 19:17:18 -0800
Subject: [Rd] WISHLIST: Be able to timeout readline()/stdin via setTimeLimit
	in all consoles
Message-ID: <CAFDcVCQsT-WwaqJkZwvtBJ=g42w73LHSxt2sDzDheXM4B55XVg@mail.gmail.com>

Hi.

WISHLIST:
Regardless on console, I'd like to be able to timeout a call to
readline()/file("stdin", blocking=TRUE) via setTimeLimit.


OBSERVATION:
On Windows Rterm as well as plain R on Linux, setTimeLimit() does not
momentarily interrupt from stdin, but only after hitting RETURN.  A
few examples:

timeout00 <- function() {
  setTimeLimit(elapsed=5);
  Sys.sleep(10);
}

timeout01 <- function() {
  setTimeLimit(elapsed=5);
  readline();
}

timeout02 <- function() {
  setTimeLimit(elapsed=5);
  con <- file("stdin", blocking=TRUE);
  on.exit(close(con));
  readChar(con, nchars=1);
}

timeout03 <- function() {
  setTimeLimit(elapsed=5);
  con <- socketConnection(port=6011, blocking=TRUE);
  on.exit(close(con));
  readChar(con, nchars=1);
}

# Times out after 5 second
> timeout00()
Error in Sys.sleep(10) : reached elapsed time limit

# Times out only after pressing ENTER
> timeout01()
foo
[1] "foo"
Error: reached elapsed time limit

# Times out only after pressing ENTER
> timeout02()
bar
[1] "b"
Error: reached elapsed time limit

# Times out after 5 second
> timeout03()
Error in socketConnection(port = 6011, blocking = TRUE)
  reached elapsed time limit

Note also, that it is possible to interrupted timeout01() and
timeout02() via Ctrl+C as well as by sending SIGINT to the R process
(at least on a Linux system).


Doing the same in Rgui, the timeout will indeed timeout:

# Times out after 5 second
> timeout01()
Error in readline() : reached elapsed time limit

# Times out after 5 second (but somehow returns immediately)
> timeout02()
character(0)
Error: reached elapsed time limit



DOCUMENTATION:
The help("setTimeLimit", package="base") documentation says:

"Time limits are checked whenever a user interrupt could occur. This
will happen frequently in R code and during Sys.sleep, but only at
points in compiled C and Fortran code identified by the code author."

Maybe one could clarify/examplify(?) by adding: "Depending on the type
of console, timeouts when reading from stdio (e.g. via readline()) may
not be effective until a line is completed (i.e. ENTER is pressed).



HOW UPDATING SOURCE CODE TO SUPPORT INTERRUPTS?
I'm not sure where this "behavior" is originating from, and whether it
is possible to obtain a cross-platform solution or not.  I located the
following native do_readln() function in src/main/scan.c that is
called by readline():

SEXP attribute_hidden do_readln(SEXP call, SEXP op, SEXP args, SEXP rho)
{
...
	    while ((c = ConsoleGetchar())!= '\n' && c != R_EOF) {
		if (bufp >= &buffer[MAXELTSIZE - 2]) continue;
		*bufp++ = c;
	    }
...
}

with ConsoleGetchar():

/* used by readline() and menu() */
static int ConsoleGetchar(void)
{
    if (--ConsoleBufCnt < 0) {
	ConsoleBuf[CONSOLE_BUFFER_SIZE] = '\0';
	if (R_ReadConsole(ConsolePrompt, ConsoleBuf,
			  CONSOLE_BUFFER_SIZE, 0) == 0) {
	    R_ClearerrConsole();
	    return R_EOF;
	}
	ConsoleBufp = ConsoleBuf;
	ConsoleBufCnt = strlen((char *)ConsoleBuf);
	ConsoleBufCnt--;
    }
    /* at this point we need to use unsigned char or similar */
    return (int) *ConsoleBufp++;
}

where in turn R_ReadConsole() appears to be specific to platform and
console, e.g. from src/gnuwin32/system.c:

 * R_ReadConsole calls TrueReadConsole which points to:
 * case 1: GuiReadConsole
 * case 2 and 3: ThreadedReadConsole
 * case 4: FileReadConsole
 * ThreadedReadConsole wake up our 'reader thread' and wait until
 * a new line of input is available. The 'reader thread' uses
 * InThreadReadConsole to get it. InThreadReadConsole points to:
 * case 2: CharReadConsole
 * case 3: FileReadConsole

Here I get a bit lost, but there is:

/*2: from character console with getline (only used as InThreadReadConsole)*/
static int
CharReadConsole(const char *prompt, char *buf, int len, int addtohistory)
{
    int res = getline(prompt, buf, len);
    if (addtohistory) gl_histadd(buf);
    return !res;
}

and, AFAIU, getline() is from the GNU getline library.  Is it possible
to timeout getline()?  At least it appears to be responding to SIGINT.

/Henrik


From bibiko at eva.mpg.de  Fri Jan 13 14:06:46 2012
From: bibiko at eva.mpg.de (=?iso-8859-1?Q?Hans-J=F6rg_Bibiko?=)
Date: Fri, 13 Jan 2012 14:06:46 +0100
Subject: [Rd] checkRd freezes while parsing erroneous preprocessor macros
Message-ID: <77DF0CE8-2DC6-4DB2-AEB0-7C68D6EC9DEF@eva.mpg.de>

Dear developers,

I came across with a bug while parsing Rd files.

Given is the following minimal Rd file:

----
\name{foo}
\title{foo}
\description{
#ifdef windows
	win
#endifd
#ifdef unix
	unix
#endif
}
----

By accident I have a typo at line 6, instead of having #endif I typed #endifd.

If I run checkRd(), parse_Rd(), Rd2HTML(), or others including the command line "R CMD Rconv" R will freeze and the only chance I have is to kill R.

As far as I can tell for checkRd() the problem is the internal function prepare_Rd() which runs for ever.

Is there a way to avoid having that freezing behaviour?

I'm on a Mac running Snow Leopard:

R version 2.14.0 (2011-10-31)
Platform: x86_64-apple-darwin9.8.0/x86_64 (64-bit)

locale:
[1] en_GB.UTF-8/en_US.UTF-8/en_GB.UTF-8/C/en_GB.UTF-8/en_GB.UTF-8

attached base packages:
[1] tools     stats     graphics  grDevices utils     datasets  methods   base     


Many thanks in advance,
--Hans

From murdoch.duncan at gmail.com  Fri Jan 13 14:45:34 2012
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 13 Jan 2012 08:45:34 -0500
Subject: [Rd] checkRd freezes while parsing erroneous preprocessor macros
In-Reply-To: <77DF0CE8-2DC6-4DB2-AEB0-7C68D6EC9DEF@eva.mpg.de>
References: <77DF0CE8-2DC6-4DB2-AEB0-7C68D6EC9DEF@eva.mpg.de>
Message-ID: <4F10357E.5070700@gmail.com>

On 13/01/2012 8:06 AM, Hans-J?rg Bibiko wrote:
> Dear developers,
>
> I came across with a bug while parsing Rd files.
>
> Given is the following minimal Rd file:
>
> ----
> \name{foo}
> \title{foo}
> \description{
> #ifdef windows
> 	win
> #endifd
> #ifdef unix
> 	unix
> #endif
> }
> ----
>
> By accident I have a typo at line 6, instead of having #endif I typed #endifd.
>
> If I run checkRd(), parse_Rd(), Rd2HTML(), or others including the command line "R CMD Rconv" R will freeze and the only chance I have is to kill R.
>
> As far as I can tell for checkRd() the problem is the internal function prepare_Rd() which runs for ever.
>
> Is there a way to avoid having that freezing behaviour?


The obvious way is not to have the typo in your file, but I'll look into 
what's causing it so you're allowed to have errors.

Duncan Murdoch

> I'm on a Mac running Snow Leopard:
>
> R version 2.14.0 (2011-10-31)
> Platform: x86_64-apple-darwin9.8.0/x86_64 (64-bit)
>
> locale:
> [1] en_GB.UTF-8/en_US.UTF-8/en_GB.UTF-8/C/en_GB.UTF-8/en_GB.UTF-8
>
> attached base packages:
> [1] tools     stats     graphics  grDevices utils     datasets  methods   base
>
>
> Many thanks in advance,
> --Hans
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From Zwang at ccmckids.org  Fri Jan 13 16:15:26 2012
From: Zwang at ccmckids.org (Zhu Wang)
Date: Fri, 13 Jan 2012 10:15:26 -0500
Subject: [Rd] checking complied code found 'abort'
Message-ID: <4F10043E020000DD00024758@gwmail3.harthosp.org>

Hello,
 
The package cts on CRAN generated a note on some systems. For
instance:
 
checking compiled code ... NOTE
File ?/home/ripley/R/Lib32/cts/libs/cts.so?:
Found ?abort?, possibly from ?abort? (C)

which can be found from the link
http://www.r-project.org/nosvn/R.check/r-patched-solaris-sparc/cts-00check.html
 
But the package uses Fortran subroutines only without any C
subroutines. In addition, it appears that no stop statement was used in
the Fortran subroutines. See the following check results:
 
http://www.r-project.org/nosvn/R.check/r-devel-linux-x86_64-gcc-fedora/cts-00check.html
 
I would welcome any thoughts on this matter.
 
Thank you very much.
 
Zhu Wang
 

From pauljohn32 at gmail.com  Fri Jan 13 23:46:01 2012
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Fri, 13 Jan 2012 16:46:01 -0600
Subject: [Rd] Example of "task seeds" with R parallel. Critique?
Message-ID: <CAErODj-1LzCaoxoqdr1TWxE+AdSkqJX1LZuGh36=q=U=2zuK8Q@mail.gmail.com>

Greetings:

In R parallel's vignette, there is a comment "It would however take
only slightly more work to allocate a stream to each task." (p.6).
I've written down a working example that can allocate not just one,
but several separate seeds for each task.  (We have just a few project
here that need multiple streams).  I would like to help work that up
for inclusion in the parallel package, if possible.

This approach is not original. It combines the idea behind snowFT and
ideas for setting and monitoring seeds to replicate random streams in
John Chambers Software for Data Analysis, Section 6.10. I'm able to
save a block of seeds in a file, run a simulation for each one, and
then re-run any particular task and match the random numbers.

But I realize there are a lot of dangers I am not yet aware of, so I'm
asking you what can go wrong?  I see danger in conflicts between my
effort to manage seeds and the work of parallel functions that try to
manage seeds for me.  That's why I wish I could integrate task-based
seeds into parallel itself.


RNGkind("L'Ecuyer-CMRG")
set.seed(23456)

library(parallel)

## nrep = number of repetitions (or tasks)
## streamsPerRep = number of streams needed by each repetition
nReps <- 2000
streamsPerRep <- 2

## projSeeds=list of lists of stream seeds
projSeeds <- vector(mode="list", nReps)
for (i in 1:nReps) projSeeds[[i]] <- vector(mode="list", streamsPerRep)

runif(1) ##establishes .Random.seed
##Grab first seed
s <- .Random.seed
origSeed <- s

x <- rnorm(4) ##will compare later
x

for (i in 1:nReps) {
  for (j in 1:streamsPerRep){
    projSeeds[[i]][[j]] <- s
    s <- nextRNGStream(s)
  }
}


save(projSeeds, file="projSeeds.rda")

rm(projSeeds)

load("projSeeds.rda")

##Note that origSeed does match projSeeds
origSeed
projSeeds[[1]][[1]]


## And we get same random draws from project 1, stream 1
.Random.seed <- projSeeds[[1]][[1]]
rnorm(4)
x

##Another way (preferred?) to reset stream
assign(".Random.seed", projSeeds[[1]][[1]], envir = .GlobalEnv)
rnorm(4)




## Now, how to make this more systematic
## Each task needs streamsPerRep seeds
## startSeeds = for each stream, a starting seed
## currentSeeds = for each stream, a seed recording stream's current position
## currentStream = integer indicator of which stream is in use


## Test that interactively
currentStream <- 1
currentSeeds <- startSeeds <- projSeeds[[1]]
.Random.seed <- startSeeds[[currentStream]]

useStream <- function(n = NULL, origin = FALSE){
  if (n > length(currentSeeds)) stop("requested stream does not exist")
  currentSeeds[[currentStream]] <- .Random.seed
  if (origin) assign(".Random.seed", startSeeds[[n]], envir = .GlobalEnv)
  else assign(".Random.seed",  currentSeeds[[n]], envir = .GlobalEnv)
  currentStream <<- n
}


useStream(n=1, origin=TRUE)
rnorm(4)

currentStream

useStream(n=2, origin=TRUE)
rnorm(4)

currentStream


## Now, make that work in a clustered environment

cl <- makeCluster(9, "MPI")

## run on worker, so can retrieve seeds for particular run
initSeeds <- function(p = NULL){
  currentStream <<- 1
  projSeeds[[p]]
}


clusterEvalQ(cl, {
  RNGkind("L'Ecuyer-CMRG")
})

clusterExport(cl, c("projSeeds", "useStream", "initSeeds"))

someHorrendousFunction <- function(run, parm){
  currentStream <- 1
  currentSeeds <- startSeeds <- initSeeds(run)
  assign(".Random.seed",  startSeeds[[currentStream]],  envir = .GlobalEnv)

  ##then some gigantic, long lasting computation occurs
  dat <- data.frame(x1 = rnorm(parm$N), x2 = rnorm(parm$N), y = rnorm(parm$N))
  m1 <- lm(y ~ x1 + x2, data=dat)
  list(m1, summary(m1), model.matrix(m1))
}

whatever <- list("N" = 999)

res <- parLapply(cl, 1:nReps, someHorrendousFunction, parm = whatever)

res[[77]]

##Prove I can repeat 77'th task

res77 <- someHorrendousFunction(77, parm = whatever)

## well, that worked.
stopCluster(cl)

-- 
Paul E. Johnson
Professor, Political Science
1541 Lilac Lane, Room 504
University of Kansas


From maechler at stat.math.ethz.ch  Sat Jan 14 22:54:55 2012
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Sat, 14 Jan 2012 22:54:55 +0100
Subject: [Rd] A: ImportFrom(B, ...)  -- B: ImportFrom(A, ...)
Message-ID: <20241.63919.31556.448651@stat.math.ethz.ch>

If I have a package A  whose NAMESPACE has
 ImportFrom(B, <B-syms>)) 

and a package B  whose NAMESPACE has
 ImportFrom(A, <A-syms>)

and we can assume that <A-syms> and <B-syms> are disjoint.
The clue would be that I only import relatively little from
one namespace to the other.

I currently get an error

  Error in loadNamespace(imp[[1L]], c(lib.loc, .libPaths())) : 
    cyclic namespace dependency detected when loading ?A?, 
    already loading ?B?, ?A?


but isn't this an unnecessary (and too limiting) restriction?

The use case would be packages Rmpfr and gmp, both for high
precision arithmetic, and it would be considerably more natural
if each could import some facilities from the other, instead of
having an asymmetry  A --> B  (or B --> A).

Martin


From ripley at stats.ox.ac.uk  Sun Jan 15 08:34:36 2012
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 15 Jan 2012 07:34:36 +0000
Subject: [Rd] A: ImportFrom(B, ...)  -- B: ImportFrom(A, ...)
In-Reply-To: <20241.63919.31556.448651@stat.math.ethz.ch>
References: <20241.63919.31556.448651@stat.math.ethz.ch>
Message-ID: <4F12818C.3050700@stats.ox.ac.uk>

It is necessary (in most cases, and as implemented).

When R goes to load the namespace of A, it has to find the objects you 
wish to import from B.  Remember that objects in R are not standalone: 
they may have shared components and functions have environments, so the 
only way to so this is to load the whole of their environment, the 
namespace of B.  That would lead to a cycle.

importFrom() differs from import() only in what it copies into A's 
'import' environment.

Remember too that namespaces can re-export imports (e.g. S4 generics), 
and that loading a namespace may load compiled code which may have 
dependencies (your examples do) for which order may matter.

On 14/01/2012 21:54, Martin Maechler wrote:
> If I have a package A  whose NAMESPACE has
>   ImportFrom(B,<B-syms>))
>
> and a package B  whose NAMESPACE has
>   ImportFrom(A,<A-syms>)
>
> and we can assume that<A-syms>  and<B-syms>  are disjoint.
> The clue would be that I only import relatively little from
> one namespace to the other.
>
> I currently get an error
>
>    Error in loadNamespace(imp[[1L]], c(lib.loc, .libPaths())) :
>      cyclic namespace dependency detected when loading ?A?,
>      already loading ?B?, ?A?
>
>
> but isn't this an unnecessary (and too limiting) restriction?
>
> The use case would be packages Rmpfr and gmp, both for high
> precision arithmetic, and it would be considerably more natural
> if each could import some facilities from the other, instead of
> having an asymmetry  A -->  B  (or B -->  A).
>
> Martin
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From tal.galili at gmail.com  Sun Jan 15 11:31:17 2012
From: tal.galili at gmail.com (Tal Galili)
Date: Sun, 15 Jan 2012 12:31:17 +0200
Subject: [Rd] patching ?merge to allow the user to keep the order of one of
 the two data.frame objects merged
Message-ID: <CANdJ3dU0ZGsh4BE1N+i0P4-=EErCiqQnfqbQ-G92ezjknHC29A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20120115/1c669360/attachment.pl>

From kasperdanielhansen at gmail.com  Sun Jan 15 16:41:54 2012
From: kasperdanielhansen at gmail.com (Kasper Daniel Hansen)
Date: Sun, 15 Jan 2012 10:41:54 -0500
Subject: [Rd] configure-args for R CMD build
Message-ID: <CAC2h7usPzZfXDZr25J=ors7Uu4nK4Bb4NT=8kN9F+EGi8faSPQ@mail.gmail.com>

When I build a package containing a vignette, the package gets
installed to build the vignette.  However, it appears that R CMD build
does not allow for --configure-args.  In my case, I have a C library
installed in a non-standard position, and I need to tell the package
where it is.  It works fine with R CMD INSTALL, but R CMD build
complains

  Warning: unknown option
?--configure-args=--with-graphviz=/Users/khansen/Source/usr?

and the subsequent installation fails with an error.

Suggestion: allow R CMD build to accept --configure-args (and probably
also --configure-vars)

Best,
Kasper


From gfinak at fhcrc.org  Sun Jan 15 16:48:19 2012
From: gfinak at fhcrc.org (Finak, Greg)
Date: Sun, 15 Jan 2012 07:48:19 -0800
Subject: [Rd] configure-args for R CMD build
In-Reply-To: <CAC2h7usPzZfXDZr25J=ors7Uu4nK4Bb4NT=8kN9F+EGi8faSPQ@mail.gmail.com>
References: <CAC2h7usPzZfXDZr25J=ors7Uu4nK4Bb4NT=8kN9F+EGi8faSPQ@mail.gmail.com>
Message-ID: <165CA0BD-060F-4916-AFC0-9C720B9E8D43@fhcrc.org>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20120115/94ce5a74/attachment.pl>

From kasperdanielhansen at gmail.com  Sun Jan 15 17:02:34 2012
From: kasperdanielhansen at gmail.com (Kasper Daniel Hansen)
Date: Sun, 15 Jan 2012 11:02:34 -0500
Subject: [Rd] configure-args for R CMD build
In-Reply-To: <165CA0BD-060F-4916-AFC0-9C720B9E8D43@fhcrc.org>
References: <CAC2h7usPzZfXDZr25J=ors7Uu4nK4Bb4NT=8kN9F+EGi8faSPQ@mail.gmail.com>
	<165CA0BD-060F-4916-AFC0-9C720B9E8D43@fhcrc.org>
Message-ID: <CAC2h7uvzo6yyxv0+sNB++sPX+Y9GvZvD8N9a_+46s0pe_W1R3g@mail.gmail.com>

On Sun, Jan 15, 2012 at 10:48 AM, Finak, Greg <gfinak at fhcrc.org> wrote:
> I think you need to enclose the arguments to configure-args in quotes.
> i.e.
>
> --configure-args='--with-graphviz=/Users/khansen/Source/usr'

I did, I was quoting the error message, not the command where I use

R CMD build --configure-args='--with-graphviz=/Users/khansen/Source/usr'
Rgraphviz

Note that I said the same command works for R CMD INSTALL.  Also, it
is clearly documented that R CMD build does not support
--configure-args.  My suggestion is that it probably ought to.

Btw, same comment but for R CMD check, which I forgot to mention in my
original post.

Kasper

> On 2012-01-15, at 7:43 AM, "Kasper Daniel Hansen"
> <kasperdanielhansen at gmail.com> wrote:
>
> When I build a package containing a vignette, the package gets
> installed to build the vignette. ?However, it appears that R CMD build
> does not allow for --configure-args. ?In my case, I have a C library
> installed in a non-standard position, and I need to tell the package
> where it is. ?It works fine with R CMD INSTALL, but R CMD build
> complains
>
> ?Warning: unknown option
> ?--configure-args=--with-graphviz=/Users/khansen/Source/usr?
>
> and the subsequent installation fails with an error.
>
> Suggestion: allow R CMD build to accept --configure-args (and probably
> also --configure-vars)
>
> Best,
> Kasper
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From ligges at statistik.tu-dortmund.de  Sun Jan 15 19:18:10 2012
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sun, 15 Jan 2012 19:18:10 +0100
Subject: [Rd] How to modify the start-up message
In-Reply-To: <1326382025.29925.YahooMailNeo@web94902.mail.in2.yahoo.com>
References: <1326382025.29925.YahooMailNeo@web94902.mail.in2.yahoo.com>
Message-ID: <4F131862.60604@statistik.tu-dortmund.de>



On 12.01.2012 16:27, Ron Michael wrote:
> Hi all, I got a custom R package in .zip (i.e. meant only for Windows installation). When I load that package, there are some start-up messages, probably loading through .onLoad() function. However I want to modify those messages. Please note that I do not have any other version of that package like .tar.gz fomat etc.
>
> Having only the .zip version, is there any possibility to modify those start-up functionalities of that package?


You should always modify packages by applying the changes to the source 
package and reinstall that.  Hence ask those who provided the binary 
package for a source version.

Uwe Ligges




>
> Thanks for your help.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From ligges at statistik.tu-dortmund.de  Sun Jan 15 19:27:47 2012
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sun, 15 Jan 2012 19:27:47 +0100
Subject: [Rd] checking complied code found 'abort'
In-Reply-To: <4F10043E020000DD00024758@gwmail3.harthosp.org>
References: <4F10043E020000DD00024758@gwmail3.harthosp.org>
Message-ID: <4F131AA3.3010406@statistik.tu-dortmund.de>

I looked quickly through the most common keywords and have not found any 
instance in your source files. The R checks are not really sure about 
the problems ands may result in false positives, hence these are notes 
rather than WARNINGs or ERRORs. If this is a false positive, the Note 
can be ignores.

Best,
Uwe Ligges




On 13.01.2012 16:15, Zhu Wang wrote:
> Hello,
>
> The package cts on CRAN generated a note on some systems. For
> instance:
>
> checking compiled code ... NOTE
> File ?/home/ripley/R/Lib32/cts/libs/cts.so?:
> Found ?abort?, possibly from ?abort? (C)
>
> which can be found from the link
> http://www.r-project.org/nosvn/R.check/r-patched-solaris-sparc/cts-00check.html
>
> But the package uses Fortran subroutines only without any C
> subroutines. In addition, it appears that no stop statement was used in
> the Fortran subroutines. See the following check results:
>
> http://www.r-project.org/nosvn/R.check/r-devel-linux-x86_64-gcc-fedora/cts-00check.html
>
> I would welcome any thoughts on this matter.
>
> Thank you very much.
>
> Zhu Wang
>
>
>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From gavin.simpson at ucl.ac.uk  Mon Jan 16 11:13:06 2012
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Mon, 16 Jan 2012 10:13:06 +0000
Subject: [Rd] package DESCRIPTION file and CRAN Task View entries?
In-Reply-To: <6584ED8B-D4FD-4954-BD31-DBEB786566FA@forestinformatics.com>
References: <6584ED8B-D4FD-4954-BD31-DBEB786566FA@forestinformatics.com>
Message-ID: <1326708786.32063.6.camel@prometheus.geog.ucl.ac.uk>

Apologies - it was a very busy week.

What you are seeing is CRAN sugar, processing the task views to identify
packages in the views. There is nothing that you as a packager can do to
get you package in a task view other than email the maintainer with a
request and brief description of the package's main features or text to
fit into the existing view.

I'll add rconifers to the ctv package sources later in the week and it
should start showing up on CRAN sometime after that.

All the best,

G

On Wed, 2012-01-11 at 14:11 -0800, Jeff Hamann wrote:
> I'm in the middle of a long overdue package update, and after seeing
> the CRAN Task Views I thought there would be an entry, in the
> DESCRIPTIONS file, for that entry that appears on the package
> webpage. 
> 
> 
> For example,
> 
> 
> http://cran.case.edu/web/packages/vegan/index.html
> 
> 
> Since it's been some time since I've updated the package, I did a
> little reading (R-exts.pdf) and web searching and recently read on
> http://www.r-bloggers.com/another-look-at-cran-task-views/
> 
> 
> "These are web pages that are maintained by volunteers with expertise
> in a specified area. The maintainers provide annotated guidance to
> routines and packages."
> 
> 
> I'm not sure I'm correct about this, but I'm beginning to think there
> is no connection between the DESCRIPTIONS file and the CRAN Task View
> entry on the web page. 
> 
> 
> Is that correct? 
> 
> 
> I'd like to add the updated rconifers package to the Environmetrics
> View.
> 
> 
> Package rconifers provides a set of forest growth simulators and
> miscellaneous functions for data analysis in forestry.
> 
> 
> Since the CRAN Task View is used to help organize the r packages
> better, help novice users find appropriate packages, and provide
> information on new packages, is there any talk of adding this
> "feature?"
> 
> 
> Respectfully,
> Jeff.
> 
> 
> 
> 
> 
> Jeff Hamann, PhD
> PO Box 1421
> Corvallis, Oregon 97339-1421
> 541-754-2457
> jeff.hamann[at]forestinformatics[dot]com
> jeff.d.hamann[at]gmail[dot]com
> http://www.forestinformatics.com
> http://en.wikipedia.org/wiki/Forest_informatics
> 
> 
> 
> To ensure that your email is processed, include a subject entry in
> your email.
> 
> 
> 
> 
> 
> 
> 

-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
 Dr. Gavin Simpson             [t] +44 (0)20 7679 0522
 ECRC, UCL Geography,          [f] +44 (0)20 7679 0565
 Pearson Building,             [e] gavin.simpsonATNOSPAMucl.ac.uk
 Gower Street, London          [w] http://www.ucl.ac.uk/~ucfagls/
 UK. WC1E 6BT.                 [w] http://www.freshwaters.org.uk
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%


From ron_michael70 at yahoo.com  Mon Jan 16 12:20:04 2012
From: ron_michael70 at yahoo.com (Ron Michael)
Date: Mon, 16 Jan 2012 16:50:04 +0530 (IST)
Subject: [Rd] How to modify the start-up message
In-Reply-To: <4F131862.60604@statistik.tu-dortmund.de>
References: <1326382025.29925.YahooMailNeo@web94902.mail.in2.yahoo.com>
	<4F131862.60604@statistik.tu-dortmund.de>
Message-ID: <1326712804.88094.YahooMailNeo@web94912.mail.in2.yahoo.com>

Thanks Uwe for you reply. However you used 'should' which brings some confusion to me! Did you mean that, **it is never possible** to modify those message given I only have windows binary?
?
Thanks,


----- Original Message -----
From: Uwe Ligges <ligges at statistik.tu-dortmund.de>
To: Ron Michael <ron_michael70 at yahoo.com>
Cc: "r-devel at r-project.org" <r-devel at r-project.org>
Sent: Monday, 16 January 2012 12:03 AM
Subject: Re: [Rd] How to modify the start-up message



On 12.01.2012 16:27, Ron Michael wrote:
> Hi all, I got a custom R package in .zip (i.e. meant only for Windows installation). When I load that package, there are some start-up messages, probably loading through .onLoad() function. However I want to modify those messages. Please note that I do not have any other version of that package like .tar.gz fomat etc.
>
> Having only the .zip version, is there any possibility to modify those start-up functionalities of that package?


You should always modify packages by applying the changes to the source 
package and reinstall that.? Hence ask those who provided the binary 
package for a source version.

Uwe Ligges




>
> Thanks for your help.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From ligges at statistik.tu-dortmund.de  Mon Jan 16 13:29:44 2012
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Mon, 16 Jan 2012 13:29:44 +0100
Subject: [Rd] How to modify the start-up message
In-Reply-To: <1326712804.88094.YahooMailNeo@web94912.mail.in2.yahoo.com>
References: <1326382025.29925.YahooMailNeo@web94902.mail.in2.yahoo.com>
	<4F131862.60604@statistik.tu-dortmund.de>
	<1326712804.88094.YahooMailNeo@web94912.mail.in2.yahoo.com>
Message-ID: <4F141838.6010604@statistik.tu-dortmund.de>



On 16.01.2012 12:20, Ron Michael wrote:
> Thanks Uwe for you reply. However you used 'should' which brings some confusion to me! Did you mean that, **it is never possible** to modify those message given I only have windows binary?

Actually, it may be possible (and I am not sure without reading the 
sources): One could read, implant and write back the databases, but we 
do not have the tools to do that easily, hence some work would be needed 
to find out. Anyway, it simply does not make sense to mess around given 
you just need to ask for the source package in order to change the stuff.

Best,
Uwe Ligges



>
> Thanks,
>
>
> ----- Original Message -----
> From: Uwe Ligges<ligges at statistik.tu-dortmund.de>
> To: Ron Michael<ron_michael70 at yahoo.com>
> Cc: "r-devel at r-project.org"<r-devel at r-project.org>
> Sent: Monday, 16 January 2012 12:03 AM
> Subject: Re: [Rd] How to modify the start-up message
>
>
>
> On 12.01.2012 16:27, Ron Michael wrote:
>> Hi all, I got a custom R package in .zip (i.e. meant only for Windows installation). When I load that package, there are some start-up messages, probably loading through .onLoad() function. However I want to modify those messages. Please note that I do not have any other version of that package like .tar.gz fomat etc.
>>
>> Having only the .zip version, is there any possibility to modify those start-up functionalities of that package?
>
>
> You should always modify packages by applying the changes to the source
> package and reinstall that.  Hence ask those who provided the binary
> package for a source version.
>
> Uwe Ligges
>
>
>
>
>>
>> Thanks for your help.
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel


From ron_michael70 at yahoo.com  Mon Jan 16 20:30:50 2012
From: ron_michael70 at yahoo.com (Ron Michael)
Date: Tue, 17 Jan 2012 01:00:50 +0530 (IST)
Subject: [Rd] How to modify the start-up message
In-Reply-To: <4F141838.6010604@statistik.tu-dortmund.de>
References: <1326382025.29925.YahooMailNeo@web94902.mail.in2.yahoo.com>
	<4F131862.60604@statistik.tu-dortmund.de>
	<1326712804.88094.YahooMailNeo@web94912.mail.in2.yahoo.com>
	<4F141838.6010604@statistik.tu-dortmund.de>
Message-ID: <1326742250.93966.YahooMailNeo@web94912.mail.in2.yahoo.com>

Actually this is a paid package and developer was reluctant to distribute the source. Therefore I was exploring whether I could do something by myself. So you are talking about some tools. Are those tools available somewhere over Net, or if it is not still available, is there any plan in any future from R core team to build such one?
?
Thanks,


----- Original Message -----
From: Uwe Ligges <ligges at statistik.tu-dortmund.de>
To: Ron Michael <ron_michael70 at yahoo.com>
Cc: "r-devel at r-project.org" <r-devel at r-project.org>
Sent: Monday, 16 January 2012 6:14 PM
Subject: Re: [Rd] How to modify the start-up message



On 16.01.2012 12:20, Ron Michael wrote:
> Thanks Uwe for you reply. However you used 'should' which brings some confusion to me! Did you mean that, **it is never possible** to modify those message given I only have windows binary?

Actually, it may be possible (and I am not sure without reading the 
sources): One could read, implant and write back the databases, but we 
do not have the tools to do that easily, hence some work would be needed 
to find out. Anyway, it simply does not make sense to mess around given 
you just need to ask for the source package in order to change the stuff.

Best,
Uwe Ligges



>
> Thanks,
>
>
> ----- Original Message -----
> From: Uwe Ligges<ligges at statistik.tu-dortmund.de>
> To: Ron Michael<ron_michael70 at yahoo.com>
> Cc: "r-devel at r-project.org"<r-devel at r-project.org>
> Sent: Monday, 16 January 2012 12:03 AM
> Subject: Re: [Rd] How to modify the start-up message
>
>
>
> On 12.01.2012 16:27, Ron Michael wrote:
>> Hi all, I got a custom R package in .zip (i.e. meant only for Windows installation). When I load that package, there are some start-up messages, probably loading through .onLoad() function. However I want to modify those messages. Please note that I do not have any other version of that package like .tar.gz fomat etc.
>>
>> Having only the .zip version, is there any possibility to modify those start-up functionalities of that package?
>
>
> You should always modify packages by applying the changes to the source
> package and reinstall that.? Hence ask those who provided the binary
> package for a source version.
>
> Uwe Ligges
>
>
>
>
>>
>> Thanks for your help.
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel


From jwiley.psych at gmail.com  Mon Jan 16 21:46:51 2012
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Mon, 16 Jan 2012 12:46:51 -0800
Subject: [Rd] How to modify the start-up message
In-Reply-To: <1326742250.93966.YahooMailNeo@web94912.mail.in2.yahoo.com>
References: <1326382025.29925.YahooMailNeo@web94902.mail.in2.yahoo.com>
	<4F131862.60604@statistik.tu-dortmund.de>
	<1326712804.88094.YahooMailNeo@web94912.mail.in2.yahoo.com>
	<4F141838.6010604@statistik.tu-dortmund.de>
	<1326742250.93966.YahooMailNeo@web94912.mail.in2.yahoo.com>
Message-ID: <CANz9Z_JVmJpOdh42T4JhWVEKuhM0+-Z9NipvKg=mp4kkXHmFKQ@mail.gmail.com>

Hi Ron,

If all you want changed is the message, this seems like a cosmetic
issue.  If that is true, something like this may work where you just
send the unwanted messages to a temporary file and print your own:

require2 <- function(x) {
  junk <- file(file.path(tempdir(), "junk.txt"), open = "wt")
  sink(junk, type="message")
  eval(substitute(require(pkg), list(pkg = x)))
  sink(type="message")
  if (x == "vegan") {
    cat("The message I really want showing", fill = TRUE)
  }
}

require2("vegan")

You could rearrange so that it calls require() for most packages and
only does something special for the one package you want changed.

Cheers,

Josh

On Mon, Jan 16, 2012 at 11:30 AM, Ron Michael <ron_michael70 at yahoo.com> wrote:
> Actually this is a paid package and developer was reluctant to distribute the source. Therefore I was exploring whether I could do something by myself. So you are talking about some tools. Are those tools available somewhere over Net, or if it is not still available, is there any plan in any future from R core team to build such one?
>
> Thanks,
>
>
> ----- Original Message -----
> From: Uwe Ligges <ligges at statistik.tu-dortmund.de>
> To: Ron Michael <ron_michael70 at yahoo.com>
> Cc: "r-devel at r-project.org" <r-devel at r-project.org>
> Sent: Monday, 16 January 2012 6:14 PM
> Subject: Re: [Rd] How to modify the start-up message
>
>
>
> On 16.01.2012 12:20, Ron Michael wrote:
>> Thanks Uwe for you reply. However you used 'should' which brings some confusion to me! Did you mean that, **it is never possible** to modify those message given I only have windows binary?
>
> Actually, it may be possible (and I am not sure without reading the
> sources): One could read, implant and write back the databases, but we
> do not have the tools to do that easily, hence some work would be needed
> to find out. Anyway, it simply does not make sense to mess around given
> you just need to ask for the source package in order to change the stuff.
>
> Best,
> Uwe Ligges
>
>
>
>>
>> Thanks,
>>
>>
>> ----- Original Message -----
>> From: Uwe Ligges<ligges at statistik.tu-dortmund.de>
>> To: Ron Michael<ron_michael70 at yahoo.com>
>> Cc: "r-devel at r-project.org"<r-devel at r-project.org>
>> Sent: Monday, 16 January 2012 12:03 AM
>> Subject: Re: [Rd] How to modify the start-up message
>>
>>
>>
>> On 12.01.2012 16:27, Ron Michael wrote:
>>> Hi all, I got a custom R package in .zip (i.e. meant only for Windows installation). When I load that package, there are some start-up messages, probably loading through .onLoad() function. However I want to modify those messages. Please note that I do not have any other version of that package like .tar.gz fomat etc.
>>>
>>> Having only the .zip version, is there any possibility to modify those start-up functionalities of that package?
>>
>>
>> You should always modify packages by applying the changes to the source
>> package and reinstall that.? Hence ask those who provided the binary
>> package for a source version.
>>
>> Uwe Ligges
>>
>>
>>
>>
>>>
>>> Thanks for your help.
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel



-- 
Joshua Wiley
Ph.D. Student, Health Psychology
Programmer Analyst II, Statistical Consulting Group
University of California, Los Angeles
https://joshuawiley.com/


From murdoch.duncan at gmail.com  Mon Jan 16 22:27:16 2012
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 16 Jan 2012 16:27:16 -0500
Subject: [Rd] How to modify the start-up message
In-Reply-To: <1326742250.93966.YahooMailNeo@web94912.mail.in2.yahoo.com>
References: <1326382025.29925.YahooMailNeo@web94902.mail.in2.yahoo.com>
	<4F131862.60604@statistik.tu-dortmund.de>
	<1326712804.88094.YahooMailNeo@web94912.mail.in2.yahoo.com>
	<4F141838.6010604@statistik.tu-dortmund.de>
	<1326742250.93966.YahooMailNeo@web94912.mail.in2.yahoo.com>
Message-ID: <4F149634.2040605@gmail.com>

On 12-01-16 2:30 PM, Ron Michael wrote:
> Actually this is a paid package and developer was reluctant to distribute the source. Therefore I was exploring whether I could do something by myself.

If you use closed source packages, be careful that you are not violating 
some part of the license that requires you to display the startup notice.

I find it easier to just stick to open source; I don't like reading (or 
inadvertantly violating) long license documents.

Duncan Murdoch

 > So you are talking about some tools. Are those tools available 
somewhere over Net, or if it is not still available, is there any plan 
in any future from R core team to build such one?
>
> Thanks,
>
>
> ----- Original Message -----
> From: Uwe Ligges<ligges at statistik.tu-dortmund.de>
> To: Ron Michael<ron_michael70 at yahoo.com>
> Cc: "r-devel at r-project.org"<r-devel at r-project.org>
> Sent: Monday, 16 January 2012 6:14 PM
> Subject: Re: [Rd] How to modify the start-up message
>
>
>
> On 16.01.2012 12:20, Ron Michael wrote:
>> Thanks Uwe for you reply. However you used 'should' which brings some confusion to me! Did you mean that, **it is never possible** to modify those message given I only have windows binary?
>
> Actually, it may be possible (and I am not sure without reading the
> sources): One could read, implant and write back the databases, but we
> do not have the tools to do that easily, hence some work would be needed
> to find out. Anyway, it simply does not make sense to mess around given
> you just need to ask for the source package in order to change the stuff.
>
> Best,
> Uwe Ligges
>
>
>
>>
>> Thanks,
>>
>>
>> ----- Original Message -----
>> From: Uwe Ligges<ligges at statistik.tu-dortmund.de>
>> To: Ron Michael<ron_michael70 at yahoo.com>
>> Cc: "r-devel at r-project.org"<r-devel at r-project.org>
>> Sent: Monday, 16 January 2012 12:03 AM
>> Subject: Re: [Rd] How to modify the start-up message
>>
>>
>>
>> On 12.01.2012 16:27, Ron Michael wrote:
>>> Hi all, I got a custom R package in .zip (i.e. meant only for Windows installation). When I load that package, there are some start-up messages, probably loading through .onLoad() function. However I want to modify those messages. Please note that I do not have any other version of that package like .tar.gz fomat etc.
>>>
>>> Having only the .zip version, is there any possibility to modify those start-up functionalities of that package?
>>
>>
>> You should always modify packages by applying the changes to the source
>> package and reinstall that.  Hence ask those who provided the binary
>> package for a source version.
>>
>> Uwe Ligges
>>
>>
>>
>>
>>>
>>> Thanks for your help.
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From mdowle at mdowle.plus.com  Tue Jan 17 09:11:59 2012
From: mdowle at mdowle.plus.com (Matthew Dowle)
Date: Tue, 17 Jan 2012 08:11:59 +0000
Subject: [Rd] names<- appears to copy 3 times?
Message-ID: <1326787919.14043.113.camel@netbook>

Hi,

$ R --vanilla
R version 2.14.1 (2011-12-22)
Platform: i686-pc-linux-gnu (32-bit)
> DF = data.frame(a=1:3,b=4:6)
> DF
  a b
1 1 4
2 2 5
3 3 6
> tracemem(DF)
[1] "<0x8898098>"
> names(DF)[2]="B"
tracemem[0x8898098 -> 0x8763e18]: 
tracemem[0x8763e18 -> 0x8766be8]: 
tracemem[0x8766be8 -> 0x8766b68]: 
> DF
  a B
1 1 4
2 2 5
3 3 6
> 

Are those 3 copies really taking place? 

Matthew


From tlumley at uw.edu  Tue Jan 17 22:50:38 2012
From: tlumley at uw.edu (Thomas Lumley)
Date: Wed, 18 Jan 2012 10:50:38 +1300
Subject: [Rd] names<- appears to copy 3 times?
In-Reply-To: <1326787919.14043.113.camel@netbook>
References: <1326787919.14043.113.camel@netbook>
Message-ID: <CAJ55+dKJ_av9Gac1dA1J_AksrJBpnHcdaB9Qdj=soExWFpBafA@mail.gmail.com>

On Tue, Jan 17, 2012 at 9:11 PM, Matthew Dowle <mdowle at mdowle.plus.com> wrote:
> Hi,
>
> $ R --vanilla
> R version 2.14.1 (2011-12-22)
> Platform: i686-pc-linux-gnu (32-bit)
>> DF = data.frame(a=1:3,b=4:6)
>> DF
> ?a b
> 1 1 4
> 2 2 5
> 3 3 6
>> tracemem(DF)
> [1] "<0x8898098>"
>> names(DF)[2]="B"
> tracemem[0x8898098 -> 0x8763e18]:
> tracemem[0x8763e18 -> 0x8766be8]:
> tracemem[0x8766be8 -> 0x8766b68]:
>> DF
> ?a B
> 1 1 4
> 2 2 5
> 3 3 6
>>
>
> Are those 3 copies really taking place?
>

tracemem() isn't likely to give false positives.  Since you're on
Linux, you could check by running under gdb and setting a breakpoint
on memtrace_report, which is the function that prints the message.
That would show where the duplicates are happening.

  - thomas

-- 
Thomas Lumley
Professor of Biostatistics
University of Auckland


From simon.urbanek at r-project.org  Tue Jan 17 23:30:37 2012
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Tue, 17 Jan 2012 17:30:37 -0500
Subject: [Rd] names<- appears to copy 3 times?
In-Reply-To: <CAJ55+dKJ_av9Gac1dA1J_AksrJBpnHcdaB9Qdj=soExWFpBafA@mail.gmail.com>
References: <1326787919.14043.113.camel@netbook>
	<CAJ55+dKJ_av9Gac1dA1J_AksrJBpnHcdaB9Qdj=soExWFpBafA@mail.gmail.com>
Message-ID: <5696212E-2F2A-4FB4-BE39-4F684A30F009@r-project.org>


On Jan 17, 2012, at 4:50 PM, Thomas Lumley wrote:

> On Tue, Jan 17, 2012 at 9:11 PM, Matthew Dowle <mdowle at mdowle.plus.com> wrote:
>> Hi,
>> 
>> $ R --vanilla
>> R version 2.14.1 (2011-12-22)
>> Platform: i686-pc-linux-gnu (32-bit)
>>> DF = data.frame(a=1:3,b=4:6)
>>> DF
>>  a b
>> 1 1 4
>> 2 2 5
>> 3 3 6
>>> tracemem(DF)
>> [1] "<0x8898098>"
>>> names(DF)[2]="B"
>> tracemem[0x8898098 -> 0x8763e18]:
>> tracemem[0x8763e18 -> 0x8766be8]:
>> tracemem[0x8766be8 -> 0x8766b68]:
>>> DF
>>  a B
>> 1 1 4
>> 2 2 5
>> 3 3 6
>>> 
>> 
>> Are those 3 copies really taking place?
>> 
> 
> tracemem() isn't likely to give false positives.  Since you're on
> Linux, you could check by running under gdb and setting a breakpoint
> on memtrace_report, which is the function that prints the message.
> That would show where the duplicates are happening.
> 

My gut feeling is that it comes from the extra recursion caused by the subset assignment which needs DF to be dragged around deeper (I'm too lazy to actually check so it may be wrong). As expected you get less copying if you set the names directly:

> DF = data.frame(a=1:3,b=4:6)
> tracemem(DF)
[1] "<0x100c82628>"
> n = names(DF)
> n[2]="B"
> names(DF) = n
tracemem[0x100c82628 -> 0x100c82778]: 
tracemem[0x100c82778 -> 0x100c712b0]: 

and as we discussed here earlier, using the assignment primitive directly makes just one copy:

> DF = data.frame(a=1:3,b=4:6)
> tracemem(DF)
[1] "<0x1029a3c68>"
> n = names(DF)
> n[2]="B"
> DF = `names<-`(DF, n)
tracemem[0x1029a3c68 -> 0x1029a3b18]: 

Cheers,
Simon


From dtenenba at fhcrc.org  Wed Jan 18 01:09:29 2012
From: dtenenba at fhcrc.org (Dan Tenenbaum)
Date: Tue, 17 Jan 2012 16:09:29 -0800
Subject: [Rd] Updated Windows toolchain
In-Reply-To: <4F0AA535.4030006@stats.ox.ac.uk>
References: <alpine.LFD.2.02.1111281109480.16728@toucan.stats.ox.ac.uk>
	<4F0AA535.4030006@stats.ox.ac.uk>
Message-ID: <CAF42j23Km+B6+w7ur12s7-_8xq-GCE17wpi40SKdLWreXnTFeg@mail.gmail.com>

Hello,

On Mon, Jan 9, 2012 at 12:28 AM, Prof Brian Ripley
<ripley at stats.ox.ac.uk> wrote:
> CRAN Windows binary packages built for R-devel are now online, and Uwe's
> winbuilder has gained the ability to check source packages under R-devel.
>
> Windows check results are available from
> http://cran.r-project.org/bin/windows/contrib/checkSummaryWin.html
> and in due course from the main CRAN check page.
>
> There have been a few updates to the toolchain:
>
> (i) It is now based on a beta of gcc 4.6.3, and so reports almost the same
> compilation warnings/errors as the CRAN check machines.
>

Is the binary R-devel provided by CRAN built against this toolchain?
If it is, should I expect "R --arch x64 CMD config CC" to report
"gcc"? It still reports "x86_64-w64-mingw32-gcc" (R-devel 58077).

Also, I have the latest Rtools installed (VERSION.txt reads "Rtools
version 2.15.0.1911") and it is first on my PATH.

I expect "gcc --version" to report 4.6.3 but it still says 4.5.0.

"x86_64-w64-mingw32-gcc --version" reports 4.5.2.
"which gcc" reports "/cygdrive/c/Rtools215/MinGW/bin/gcc".

"which x86_64-w64-mingw32-gcc" reports
"/cygdrive/c/Rtools215/MinGW64/bin/x86_64-w64-mingw32-gcc".

> (ii) There are various bug-fixes to the toolchain: notably x^n and exp(x)
> use gradual underflow to denormal numbers rather than abrubtly underflowing
> to zero.
>
> (iii) This is a 'multilib' toolchain: the compiler is named 'gcc.exe' for
> both architectures, selected by flag -m32 (the default) and -m64.

Looks like to check gcc versions I should (instead of what I do above)
do simply "gcc --version". I imagine that "gcc -m32 --version" would
report the same thing as "gcc -m64 --version".

Thanks,
Dan


>
>
> On 29/11/2011 07:56, Prof Brian Ripley wrote:
>>
>> An updated toolchain is now being used for Windows' builds of R-devel:
>> details are in the R-admin manual and at
>> http://www.murdoch-sutherland.com/Rtools/ and
>> http://www.stats.ox.ac.uk/pub/Rtools/
>>
>> Both 32- and 64-bit parts of the toolchain use v2.0.1 of the Mingw-w64
>> project's runtime and a beta of gcc 4.5.4: the Mingw.org project's
>> builds are no longer used. This should mean that code which compiles for
>> 64-bit Windows also compiles for 32-bit Windows, and v.v. unless code
>> makes (incorrect but common) assumptions that pointers fit into longs.
>>
>> A very few packages will need modifications because they contain
>> declarations which clash with the headers in this toolchain: where we
>> are aware of problems the maintainers have been informed.
>>
>> At DLL level different Windows' toolchains should be compatible: at C
>> level they mostly are but at C++ level they are pretty much incompatible
>> (so that for example GDAL has to be re-compiled for every toolchain: and
>> Rcpp users need to be careful to use only one toolchain for Rcpp and
>> their packages). All the external software previously made available
>> (and more) is made available at http://www.stats.ox.ac.uk/pub/Rtools .
>>
>> The toolchain has support for OpenMP and pthreads: however OpenMP
>> support is not enabled by default in R (it is too slow to be much use).
>> If you do make use of it in your packages, be aware that you will need
>> to ship the appropriate pthreads DLL(s).
>>
>> It is expected that there will be several further minor updates prior to
>> the release of 2.15.0 in ca 4 months, but this step is the major one.
>>
>
>
> --
> Brian D. Ripley, ? ? ? ? ? ? ? ? ?ripley at stats.ox.ac.uk
> Professor of Applied Statistics, ?http://www.stats.ox.ac.uk/~ripley/
> University of Oxford, ? ? ? ? ? ? Tel: ?+44 1865 272861 (self)
> 1 South Parks Road, ? ? ? ? ? ? ? ? ? ? +44 1865 272866 (PA)
> Oxford OX1 3TG, UK ? ? ? ? ? ? ? ?Fax: ?+44 1865 272595
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From ligges at statistik.tu-dortmund.de  Wed Jan 18 09:18:51 2012
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Wed, 18 Jan 2012 09:18:51 +0100
Subject: [Rd] Updated Windows toolchain
In-Reply-To: <CAF42j23Km+B6+w7ur12s7-_8xq-GCE17wpi40SKdLWreXnTFeg@mail.gmail.com>
References: <alpine.LFD.2.02.1111281109480.16728@toucan.stats.ox.ac.uk>
	<4F0AA535.4030006@stats.ox.ac.uk>
	<CAF42j23Km+B6+w7ur12s7-_8xq-GCE17wpi40SKdLWreXnTFeg@mail.gmail.com>
Message-ID: <4F16806B.7000104@statistik.tu-dortmund.de>



On 18.01.2012 01:09, Dan Tenenbaum wrote:
> Hello,
>
> On Mon, Jan 9, 2012 at 12:28 AM, Prof Brian Ripley
> <ripley at stats.ox.ac.uk>  wrote:
>> CRAN Windows binary packages built for R-devel are now online, and Uwe's
>> winbuilder has gained the ability to check source packages under R-devel.
>>
>> Windows check results are available from
>> http://cran.r-project.org/bin/windows/contrib/checkSummaryWin.html
>> and in due course from the main CRAN check page.
>>
>> There have been a few updates to the toolchain:
>>
>> (i) It is now based on a beta of gcc 4.6.3, and so reports almost the same
>> compilation warnings/errors as the CRAN check machines.
>>
>
> Is the binary R-devel provided by CRAN built against this toolchain?
> If it is, should I expect "R --arch x64 CMD config CC" to report
> "gcc"? It still reports "x86_64-w64-mingw32-gcc" (R-devel 58077).

Actually "gcc -m64" and that is also the case when I just tried 
yesterday's CRAN version (which is 58125). I guess you have an older 
version of R in your PATH?



> Also, I have the latest Rtools installed (VERSION.txt reads "Rtools
> version 2.15.0.1911") and it is first on my PATH.
>
> I expect "gcc --version" to report 4.6.3 but it still says 4.5.0.
>
> "x86_64-w64-mingw32-gcc --version" reports 4.5.2.
> "which gcc" reports "/cygdrive/c/Rtools215/MinGW/bin/gcc".
>
> "which x86_64-w64-mingw32-gcc" reports
> "/cygdrive/c/Rtools215/MinGW64/bin/x86_64-w64-mingw32-gcc".


Yes, these are the version you need for old versions of R that are 
included in the Rtools, but it has a third gcc in subdir gcc-4.6.3 which 
is the one you should have first in the path in order to use the new 
toolchain.

Uwe Ligges




>> (ii) There are various bug-fixes to the toolchain: notably x^n and exp(x)
>> use gradual underflow to denormal numbers rather than abrubtly underflowing
>> to zero.
>>
>> (iii) This is a 'multilib' toolchain: the compiler is named 'gcc.exe' for
>> both architectures, selected by flag -m32 (the default) and -m64.
>
> Looks like to check gcc versions I should (instead of what I do above)
> do simply "gcc --version". I imagine that "gcc -m32 --version" would
> report the same thing as "gcc -m64 --version".
>
> Thanks,
> Dan
>
>
>>
>>
>> On 29/11/2011 07:56, Prof Brian Ripley wrote:
>>>
>>> An updated toolchain is now being used for Windows' builds of R-devel:
>>> details are in the R-admin manual and at
>>> http://www.murdoch-sutherland.com/Rtools/ and
>>> http://www.stats.ox.ac.uk/pub/Rtools/
>>>
>>> Both 32- and 64-bit parts of the toolchain use v2.0.1 of the Mingw-w64
>>> project's runtime and a beta of gcc 4.5.4: the Mingw.org project's
>>> builds are no longer used. This should mean that code which compiles for
>>> 64-bit Windows also compiles for 32-bit Windows, and v.v. unless code
>>> makes (incorrect but common) assumptions that pointers fit into longs.
>>>
>>> A very few packages will need modifications because they contain
>>> declarations which clash with the headers in this toolchain: where we
>>> are aware of problems the maintainers have been informed.
>>>
>>> At DLL level different Windows' toolchains should be compatible: at C
>>> level they mostly are but at C++ level they are pretty much incompatible
>>> (so that for example GDAL has to be re-compiled for every toolchain: and
>>> Rcpp users need to be careful to use only one toolchain for Rcpp and
>>> their packages). All the external software previously made available
>>> (and more) is made available at http://www.stats.ox.ac.uk/pub/Rtools .
>>>
>>> The toolchain has support for OpenMP and pthreads: however OpenMP
>>> support is not enabled by default in R (it is too slow to be much use).
>>> If you do make use of it in your packages, be aware that you will need
>>> to ship the appropriate pthreads DLL(s).
>>>
>>> It is expected that there will be several further minor updates prior to
>>> the release of 2.15.0 in ca 4 months, but this step is the major one.
>>>
>>
>>
>> --
>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>> University of Oxford,             Tel:  +44 1865 272861 (self)
>> 1 South Parks Road,                     +44 1865 272866 (PA)
>> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From edzer.pebesma at uni-muenster.de  Wed Jan 18 09:28:28 2012
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Wed, 18 Jan 2012 09:28:28 +0100
Subject: [Rd] how to check all CRAN dependencies for my package,
	before submitting
Message-ID: <4F1682AC.1060700@uni-muenster.de>

Suppose I'm author of a package on which quite a few other packages
depend. When I submit to CRAN, I run R CMD check on it, Kurt does that
too, and if things work out fine, it is accepted. When one or more of
the packages that depend on it break because of my changes, however,
hell breaks loose.

I would like to extend my testing (currently: R CMD check pkg) to
running R CMD check on all dependent packages, in their most recent
(CRAN) version. I got stuck trying this.

Does anyone know how to get (i) a list of all packages that depend,
directly or indirectly, on my package, and (ii) a list of file names of
their package sources in their latest version (i.e., including their
latest version number)?
-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763  http://ifgi.uni-muenster.de
http://www.52north.org/geostatistics      e.pebesma at wwu.de


From ligges at statistik.tu-dortmund.de  Wed Jan 18 10:33:40 2012
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Wed, 18 Jan 2012 10:33:40 +0100
Subject: [Rd] how to check all CRAN dependencies for my package,
 before submitting
In-Reply-To: <4F1682AC.1060700@uni-muenster.de>
References: <4F1682AC.1060700@uni-muenster.de>
Message-ID: <4F1691F4.8010402@statistik.tu-dortmund.de>



On 18.01.2012 09:28, Edzer Pebesma wrote:
> Suppose I'm author of a package on which quite a few other packages
> depend. When I submit to CRAN, I run R CMD check on it, Kurt does that
> too, and if things work out fine, it is accepted. When one or more of
> the packages that depend on it break because of my changes, however,
> hell breaks loose.
>
> I would like to extend my testing (currently: R CMD check pkg) to
> running R CMD check on all dependent packages, in their most recent
> (CRAN) version. I got stuck trying this.
>
> Does anyone know how to get (i) a list of all packages that depend,
> directly or indirectly, on my package, and (ii) a list of file names of
> their package sources in their latest version (i.e., including their
> latest version number)?


Quick an dirty example:


packages_to_check <- function(dep, which = c("Depends", "Imports", 
"LinkingTo", "Suggests"), recursive = FALSE){
 
download.file("http://cran.R-project.org/web/packages/packages.rds", 
"packages.rds", mode="wb")
     x <- readRDS("packages.rds")
     x <- x[!duplicated(x[,1]),]
     packages <- x[,1]
     rdeps <- tools:::.package_dependencies(packages = dep, x,
                         which = which,
                         recursive = recursive, reverse = TRUE)
     paste(apply(x[x[,1] %in% rdeps[[1]], 1:2], 1, paste, collapse="_"), 
".tar.gz", sep="")
}

result <-  packages_to_check("sp")

or if you want the whole chain including recursive dependencies:

result <-  packages_to_check("sp", recursive=TRUE)


Best,
Uwe


From murdoch.duncan at gmail.com  Wed Jan 18 14:17:41 2012
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 18 Jan 2012 08:17:41 -0500
Subject: [Rd] Updated Windows toolchain
In-Reply-To: <CAF42j23Km+B6+w7ur12s7-_8xq-GCE17wpi40SKdLWreXnTFeg@mail.gmail.com>
References: <alpine.LFD.2.02.1111281109480.16728@toucan.stats.ox.ac.uk>
	<4F0AA535.4030006@stats.ox.ac.uk>
	<CAF42j23Km+B6+w7ur12s7-_8xq-GCE17wpi40SKdLWreXnTFeg@mail.gmail.com>
Message-ID: <4F16C675.10407@gmail.com>

On 12-01-17 7:09 PM, Dan Tenenbaum wrote:
> Hello,
>
> On Mon, Jan 9, 2012 at 12:28 AM, Prof Brian Ripley
> <ripley at stats.ox.ac.uk>  wrote:
>> CRAN Windows binary packages built for R-devel are now online, and Uwe's
>> winbuilder has gained the ability to check source packages under R-devel.
>>
>> Windows check results are available from
>> http://cran.r-project.org/bin/windows/contrib/checkSummaryWin.html
>> and in due course from the main CRAN check page.
>>
>> There have been a few updates to the toolchain:
>>
>> (i) It is now based on a beta of gcc 4.6.3, and so reports almost the same
>> compilation warnings/errors as the CRAN check machines.
>>
>
> Is the binary R-devel provided by CRAN built against this toolchain?
> If it is, should I expect "R --arch x64 CMD config CC" to report
> "gcc"? It still reports "x86_64-w64-mingw32-gcc" (R-devel 58077).
>
> Also, I have the latest Rtools installed (VERSION.txt reads "Rtools
> version 2.15.0.1911") and it is first on my PATH.

This is a temporary problem:  you want a different path for R-devel 
builds (one that puts the new compiler first) than for R 2.14.x builds.

I think Rtools should default to offering the path for 2.14.x, but 
perhaps it should offer the newer one as well.

What I do is have a bash alias that resets the path when I choose to 
work in a particular version, but Rtools doesn't include anything like this.

Duncan Murdoch

>
> I expect "gcc --version" to report 4.6.3 but it still says 4.5.0.
>
> "x86_64-w64-mingw32-gcc --version" reports 4.5.2.
> "which gcc" reports "/cygdrive/c/Rtools215/MinGW/bin/gcc".
>
> "which x86_64-w64-mingw32-gcc" reports
> "/cygdrive/c/Rtools215/MinGW64/bin/x86_64-w64-mingw32-gcc".
>
>> (ii) There are various bug-fixes to the toolchain: notably x^n and exp(x)
>> use gradual underflow to denormal numbers rather than abrubtly underflowing
>> to zero.
>>
>> (iii) This is a 'multilib' toolchain: the compiler is named 'gcc.exe' for
>> both architectures, selected by flag -m32 (the default) and -m64.
>
> Looks like to check gcc versions I should (instead of what I do above)
> do simply "gcc --version". I imagine that "gcc -m32 --version" would
> report the same thing as "gcc -m64 --version".
>
> Thanks,
> Dan
>
>
>>
>>
>> On 29/11/2011 07:56, Prof Brian Ripley wrote:
>>>
>>> An updated toolchain is now being used for Windows' builds of R-devel:
>>> details are in the R-admin manual and at
>>> http://www.murdoch-sutherland.com/Rtools/ and
>>> http://www.stats.ox.ac.uk/pub/Rtools/
>>>
>>> Both 32- and 64-bit parts of the toolchain use v2.0.1 of the Mingw-w64
>>> project's runtime and a beta of gcc 4.5.4: the Mingw.org project's
>>> builds are no longer used. This should mean that code which compiles for
>>> 64-bit Windows also compiles for 32-bit Windows, and v.v. unless code
>>> makes (incorrect but common) assumptions that pointers fit into longs.
>>>
>>> A very few packages will need modifications because they contain
>>> declarations which clash with the headers in this toolchain: where we
>>> are aware of problems the maintainers have been informed.
>>>
>>> At DLL level different Windows' toolchains should be compatible: at C
>>> level they mostly are but at C++ level they are pretty much incompatible
>>> (so that for example GDAL has to be re-compiled for every toolchain: and
>>> Rcpp users need to be careful to use only one toolchain for Rcpp and
>>> their packages). All the external software previously made available
>>> (and more) is made available at http://www.stats.ox.ac.uk/pub/Rtools .
>>>
>>> The toolchain has support for OpenMP and pthreads: however OpenMP
>>> support is not enabled by default in R (it is too slow to be much use).
>>> If you do make use of it in your packages, be aware that you will need
>>> to ship the appropriate pthreads DLL(s).
>>>
>>> It is expected that there will be several further minor updates prior to
>>> the release of 2.15.0 in ca 4 months, but this step is the major one.
>>>
>>
>>
>> --
>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>> University of Oxford,             Tel:  +44 1865 272861 (self)
>> 1 South Parks Road,                     +44 1865 272866 (PA)
>> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From smckinney at bccrc.ca  Wed Jan 18 23:22:28 2012
From: smckinney at bccrc.ca (Steven McKinney)
Date: Wed, 18 Jan 2012 14:22:28 -0800
Subject: [Rd] png cairo device problems on Mac 10.6.8
Message-ID: <DCE81E14EB74504B971DAD4D2DB0356B0892780966@crcmail4.BCCRC.CA>


Hi all,

I have been having problems generating png files on a Mac running OS X 10.6.8. 

Here's a simple example

> png("foo.png", type = "cairo"); plot(1:10); dev.off();
null device 
          1 
libpng warning: Application built with libpng-1.2.26 but running with 1.5.2

The resultant file is of size 0 Kb.

Is this the proper place to report this issue?  Or should this
be reported to r-sig-mac?


If I run

> png("foo.png"); plot(1:10); dev.off();
null device 
          1 

I get a 16 Kb file with the appropriate plot.  (Odd, since the default type is "cairo".)

Whenever I see the libpng warning, I end up with a 0 Kb file.

Details of R session below.


Regards

Steve McKinney



R version 2.14.1 Patched (2012-01-11 r58090)
Copyright (C) 2012 The R Foundation for Statistical Computing
ISBN 3-900051-07-0
Platform: x86_64-apple-darwin9.8.0/x86_64 (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

[R.app GUI 1.44 (5997) x86_64-apple-darwin9.8.0]

[History restored from /Users/stevenmckinney/.Rhistory]

> png("foo.png"); plot(1:10); dev.off();
null device 
          1 
> png("foo.png", type = "cairo"); plot(1:10); dev.off();
null device 
          1 
libpng warning: Application built with libpng-1.2.26 but running with 1.5.2
> ?png
starting httpd help server ... done
> capabilities()
    jpeg      png     tiff    tcltk      X11     aqua http/ftp  sockets   libxml     fifo 
    TRUE     TRUE     TRUE     TRUE     TRUE     TRUE     TRUE     TRUE     TRUE     TRUE 
  cledit    iconv      NLS  profmem    cairo 
    TRUE     TRUE     TRUE     TRUE     TRUE 
> png("foo.png"); plot(1:10); dev.off();
null device 
          1 
> sessionInfo()
R version 2.14.1 Patched (2012-01-11 r58090)
Platform: x86_64-apple-darwin9.8.0/x86_64 (64-bit)

locale:
[1] en_CA.UTF-8/en_CA.UTF-8/en_CA.UTF-8/C/en_CA.UTF-8/en_CA.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

loaded via a namespace (and not attached):
[1] tools_2.14.1
> 


Steven McKinney, Ph.D.

Statistician
Molecular Oncology and Breast Cancer Program
British Columbia Cancer Research Centre

email: smckinney +at+ bccrc +dot+ ca

tel: 604-675-8000 x7561

BCCRC
Molecular Oncology
675 West 10th Ave, Floor 4
Vancouver B.C.
V5Z 1L3
Canada


From thomas at zumbrunn.name  Wed Jan 18 23:54:43 2012
From: thomas at zumbrunn.name (Thomas Zumbrunn)
Date: Wed, 18 Jan 2012 23:54:43 +0100
Subject: [Rd] use of UTF-8 \uxxxx escape sequences in function arguments
Message-ID: <201201182354.43607.thomas@zumbrunn.name>

While preparing a function that contained non-ASCII characters for inclusion 
into a package, I replaced all non-ASCII characters with UTF-8 escape 
sequences (using \uxxxx) in order to make the package portable (and adhere to 
"R CMD check"). What I didn't expect: when one uses UTF-8 escape sequences in 
function arguments, one needs to use UTF-8 escape sequences when calling the 
function, too - even when working in a UTF-8 locale. Is this an intended 
behaviour?

Here's an example to illustrate the (putative) problem:

   ## function that uses non-ASCII characters in arguments
   plain <- function(myarg = c("Basel", "Bern", "Z?rich")) {
     myarg <- match.arg(myarg)
   }

   ## function that uses UTF-8 escape sequences in arguments
   escaped <- function(myarg = c("Basel", "Bern", "Z\u00BCrich")) {
     myarg <- match.arg(myarg)
   }

   ## test
   plain("Z?rich")  ## works
   plain("Z\u00BCrich")  ## fails
   escaped("Z?rich")  ## fails
   escaped("Z\u00BCrich")  ## works

Thank you for your help.
Thomas Zumbrunn


> sessionInfo()                                                                                                                                                                                                                              
R version 2.14.1 (2011-12-22)                                                                                                                                                                                                                
Platform: x86_64-unknown-linux-gnu (64-bit)                                                                                                                                                                                                  
                                                                                                                                                                                                                                             
locale:                                                                                                                                                                                                                                      
 [1] LC_CTYPE=en_GB.UTF-8       LC_NUMERIC=C               LC_TIME=en_GB.UTF-8                                                                                                                                                               
 [4] LC_COLLATE=en_GB.UTF-8     LC_MONETARY=en_GB.UTF-8    
LC_MESSAGES=en_GB.UTF-8                                                                                                                                                           
 [7] LC_PAPER=C                 LC_NAME=C                  LC_ADDRESS=C                                                                                                                                                                      
[10] LC_TELEPHONE=C             LC_MEASUREMENT=en_GB.UTF-8 LC_IDENTIFICATION=C  


From simon.urbanek at r-project.org  Thu Jan 19 00:10:19 2012
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Wed, 18 Jan 2012 18:10:19 -0500
Subject: [Rd] png cairo device problems on Mac 10.6.8
In-Reply-To: <DCE81E14EB74504B971DAD4D2DB0356B0892780966@crcmail4.BCCRC.CA>
References: <DCE81E14EB74504B971DAD4D2DB0356B0892780966@crcmail4.BCCRC.CA>
Message-ID: <1189F438-FDC3-4B34-BCBF-E551686B5329@r-project.org>


On Jan 18, 2012, at 5:22 PM, Steven McKinney wrote:

> 
> Hi all,
> 
> I have been having problems generating png files on a Mac running OS X 10.6.8. 
> 
> Here's a simple example
> 
>> png("foo.png", type = "cairo"); plot(1:10); dev.off();
> null device 
>          1 
> libpng warning: Application built with libpng-1.2.26 but running with 1.5.2
> 
> The resultant file is of size 0 Kb.
> 
> Is this the proper place to report this issue?  Or should this
> be reported to r-sig-mac?
> 

yes


> If I run
> 
>> png("foo.png"); plot(1:10); dev.off();
> null device 
>          1 
> 
> I get a 16 Kb file with the appropriate plot.  (Odd, since the default type is "cairo".)
> 

No, the default is "quartz" unless you change it in your options.

On a similar note type="cairo-png" works as well.

The problem seems to be with R's configuration - for some mysterious reason it picks libpng12 flags even though cairo clearly includes libpng15 (and so does pkg-config). I'll need to dig a bit into that.

Cheers,
Simon


> Whenever I see the libpng warning, I end up with a 0 Kb file.
> 
> Details of R session below.
> 
> 
> Regards
> 
> Steve McKinney
> 
> 
> 
> R version 2.14.1 Patched (2012-01-11 r58090)
> Copyright (C) 2012 The R Foundation for Statistical Computing
> ISBN 3-900051-07-0
> Platform: x86_64-apple-darwin9.8.0/x86_64 (64-bit)
> 
> R is free software and comes with ABSOLUTELY NO WARRANTY.
> You are welcome to redistribute it under certain conditions.
> Type 'license()' or 'licence()' for distribution details.
> 
>  Natural language support but running in an English locale
> 
> R is a collaborative project with many contributors.
> Type 'contributors()' for more information and
> 'citation()' on how to cite R or R packages in publications.
> 
> Type 'demo()' for some demos, 'help()' for on-line help, or
> 'help.start()' for an HTML browser interface to help.
> Type 'q()' to quit R.
> 
> [R.app GUI 1.44 (5997) x86_64-apple-darwin9.8.0]
> 
> [History restored from /Users/stevenmckinney/.Rhistory]
> 
>> png("foo.png"); plot(1:10); dev.off();
> null device 
>          1 
>> png("foo.png", type = "cairo"); plot(1:10); dev.off();
> null device 
>          1 
> libpng warning: Application built with libpng-1.2.26 but running with 1.5.2
>> ?png
> starting httpd help server ... done
>> capabilities()
>    jpeg      png     tiff    tcltk      X11     aqua http/ftp  sockets   libxml     fifo 
>    TRUE     TRUE     TRUE     TRUE     TRUE     TRUE     TRUE     TRUE     TRUE     TRUE 
>  cledit    iconv      NLS  profmem    cairo 
>    TRUE     TRUE     TRUE     TRUE     TRUE 
>> png("foo.png"); plot(1:10); dev.off();
> null device 
>          1 
>> sessionInfo()
> R version 2.14.1 Patched (2012-01-11 r58090)
> Platform: x86_64-apple-darwin9.8.0/x86_64 (64-bit)
> 
> locale:
> [1] en_CA.UTF-8/en_CA.UTF-8/en_CA.UTF-8/C/en_CA.UTF-8/en_CA.UTF-8
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base     
> 
> loaded via a namespace (and not attached):
> [1] tools_2.14.1
>> 
> 
> 
> Steven McKinney, Ph.D.
> 
> Statistician
> Molecular Oncology and Breast Cancer Program
> British Columbia Cancer Research Centre
> 
> email: smckinney +at+ bccrc +dot+ ca
> 
> tel: 604-675-8000 x7561
> 
> BCCRC
> Molecular Oncology
> 675 West 10th Ave, Floor 4
> Vancouver B.C.
> V5Z 1L3
> Canada
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From pdalgd at gmail.com  Thu Jan 19 00:17:37 2012
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 19 Jan 2012 00:17:37 +0100
Subject: [Rd] use of UTF-8 \uxxxx escape sequences in function arguments
In-Reply-To: <201201182354.43607.thomas@zumbrunn.name>
References: <201201182354.43607.thomas@zumbrunn.name>
Message-ID: <2855A65F-5760-4076-BF1D-E80FEDCA0DB0@gmail.com>


On Jan 18, 2012, at 23:54 , Thomas Zumbrunn wrote:

>   plain("Z?rich")  ## works
>   plain("Z\u00BCrich")  ## fails
>   escaped("Z?rich")  ## fails
>   escaped("Z\u00BCrich")  ## works

Using the correct UTF-8 code helps quite a bit:

U+00BC	?	c2 bc	VULGAR FRACTION ONE QUARTER
U+00FC	?	c3 bc	LATIN SMALL LETTER U WITH DIAERESIS

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From smckinney at bccrc.ca  Thu Jan 19 00:33:50 2012
From: smckinney at bccrc.ca (Steven McKinney)
Date: Wed, 18 Jan 2012 15:33:50 -0800
Subject: [Rd] png cairo device problems on Mac 10.6.8
In-Reply-To: <1189F438-FDC3-4B34-BCBF-E551686B5329@r-project.org>
References: <DCE81E14EB74504B971DAD4D2DB0356B0892780966@crcmail4.BCCRC.CA>
	<1189F438-FDC3-4B34-BCBF-E551686B5329@r-project.org>
Message-ID: <DCE81E14EB74504B971DAD4D2DB0356B0892A7081D@crcmail4.BCCRC.CA>



> -----Original Message-----
> From: Simon Urbanek [mailto:simon.urbanek at r-project.org]
> Sent: January-18-12 3:10 PM
> To: Steven McKinney
> Cc: R-devel at r-project.org
> Subject: Re: [Rd] png cairo device problems on Mac 10.6.8
> 
> 
> On Jan 18, 2012, at 5:22 PM, Steven McKinney wrote:
> 
> >
> > Hi all,
> >
> > I have been having problems generating png files on a Mac running OS X
> 10.6.8.
> >
> > Here's a simple example
> >
> >> png("foo.png", type = "cairo"); plot(1:10); dev.off();
> > null device
> >          1
> > libpng warning: Application built with libpng-1.2.26 but running with
> 1.5.2
> >
> > The resultant file is of size 0 Kb.
> >
> > Is this the proper place to report this issue?  Or should this
> > be reported to r-sig-mac?
> >
> 
> yes
> 
> 
> > If I run
> >
> >> png("foo.png"); plot(1:10); dev.off();
> > null device
> >          1
> >
> > I get a 16 Kb file with the appropriate plot.  (Odd, since the default
> type is "cairo".)
> >
> 
> No, the default is "quartz" unless you change it in your options.

D'oh!  I should have verified by reading the source.  Apologies for
the misinformation.  The fact that "cairo" appears first in the
type argument list does not make it the default.

> 
> On a similar note type="cairo-png" works as well.

Yes, type="cairo-png" yields a successful file.

The png() function shows a call of 

   invisible(.External(devCairo, filename, 2L, g$width, ...

for type="cairo" and a call of

   invisible(.External(devCairo, filename, 5L, g$width, ...

with type="cairo-png" so the third argument (2 or 5)
appears to be the only difference.  I have not dug into
the devCairo code to see how that arg is handled.


> 
> The problem seems to be with R's configuration - for some mysterious reason
> it picks libpng12 flags even though cairo clearly includes libpng15 (and so
> does pkg-config). I'll need to dig a bit into that.

Thank you very much.

Cheers

Steve 

> 
> Cheers,
> Simon
> 
> 
> > Whenever I see the libpng warning, I end up with a 0 Kb file.
> >
> > Details of R session below.
> >
> >
> > Regards
> >
> > Steve McKinney
> >
> >
> >
> > R version 2.14.1 Patched (2012-01-11 r58090)
> > Copyright (C) 2012 The R Foundation for Statistical Computing
> > ISBN 3-900051-07-0
> > Platform: x86_64-apple-darwin9.8.0/x86_64 (64-bit)
> >
> > R is free software and comes with ABSOLUTELY NO WARRANTY.
> > You are welcome to redistribute it under certain conditions.
> > Type 'license()' or 'licence()' for distribution details.
> >
> >  Natural language support but running in an English locale
> >
> > R is a collaborative project with many contributors.
> > Type 'contributors()' for more information and
> > 'citation()' on how to cite R or R packages in publications.
> >
> > Type 'demo()' for some demos, 'help()' for on-line help, or
> > 'help.start()' for an HTML browser interface to help.
> > Type 'q()' to quit R.
> >
> > [R.app GUI 1.44 (5997) x86_64-apple-darwin9.8.0]
> >
> > [History restored from /Users/stevenmckinney/.Rhistory]
> >
> >> png("foo.png"); plot(1:10); dev.off();
> > null device
> >          1
> >> png("foo.png", type = "cairo"); plot(1:10); dev.off();
> > null device
> >          1
> > libpng warning: Application built with libpng-1.2.26 but running with
> 1.5.2
> >> ?png
> > starting httpd help server ... done
> >> capabilities()
> >    jpeg      png     tiff    tcltk      X11     aqua http/ftp  sockets
> libxml     fifo
> >    TRUE     TRUE     TRUE     TRUE     TRUE     TRUE     TRUE     TRUE
> TRUE     TRUE
> >  cledit    iconv      NLS  profmem    cairo
> >    TRUE     TRUE     TRUE     TRUE     TRUE
> >> png("foo.png"); plot(1:10); dev.off();
> > null device
> >          1
> >> sessionInfo()
> > R version 2.14.1 Patched (2012-01-11 r58090)
> > Platform: x86_64-apple-darwin9.8.0/x86_64 (64-bit)
> >
> > locale:
> > [1] en_CA.UTF-8/en_CA.UTF-8/en_CA.UTF-8/C/en_CA.UTF-8/en_CA.UTF-8
> >
> > attached base packages:
> > [1] stats     graphics  grDevices utils     datasets  methods   base
> >
> > loaded via a namespace (and not attached):
> > [1] tools_2.14.1
> >>
> >
> >
> > Steven McKinney, Ph.D.
> >
> > Statistician
> > Molecular Oncology and Breast Cancer Program
> > British Columbia Cancer Research Centre
> >
> > email: smckinney +at+ bccrc +dot+ ca
> >
> > tel: 604-675-8000 x7561
> >
> > BCCRC
> > Molecular Oncology
> > 675 West 10th Ave, Floor 4
> > Vancouver B.C.
> > V5Z 1L3
> > Canada
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
> >


From dtenenba at fhcrc.org  Thu Jan 19 02:03:04 2012
From: dtenenba at fhcrc.org (Dan Tenenbaum)
Date: Wed, 18 Jan 2012 17:03:04 -0800
Subject: [Rd] Updated Windows toolchain
In-Reply-To: <4F16806B.7000104@statistik.tu-dortmund.de>
References: <alpine.LFD.2.02.1111281109480.16728@toucan.stats.ox.ac.uk>
	<4F0AA535.4030006@stats.ox.ac.uk>
	<CAF42j23Km+B6+w7ur12s7-_8xq-GCE17wpi40SKdLWreXnTFeg@mail.gmail.com>
	<4F16806B.7000104@statistik.tu-dortmund.de>
Message-ID: <CAF42j20KOnRYQM+X=z9KPOLHp4wc-wNofMH-cGDn6N=9krZmkQ@mail.gmail.com>

Hi Uwe,

2012/1/18 Uwe Ligges <ligges at statistik.tu-dortmund.de>:
>
>
> On 18.01.2012 01:09, Dan Tenenbaum wrote:
>>
>> Hello,
>>
>> On Mon, Jan 9, 2012 at 12:28 AM, Prof Brian Ripley
>> <ripley at stats.ox.ac.uk> ?wrote:
>>>
>>> CRAN Windows binary packages built for R-devel are now online, and Uwe's
>>> winbuilder has gained the ability to check source packages under R-devel.
>>>
>>> Windows check results are available from
>>> http://cran.r-project.org/bin/windows/contrib/checkSummaryWin.html
>>> and in due course from the main CRAN check page.
>>>
>>> There have been a few updates to the toolchain:
>>>
>>> (i) It is now based on a beta of gcc 4.6.3, and so reports almost the
>>> same
>>> compilation warnings/errors as the CRAN check machines.
>>>
>>
>> Is the binary R-devel provided by CRAN built against this toolchain?
>> If it is, should I expect "R --arch x64 CMD config CC" to report
>> "gcc"? It still reports "x86_64-w64-mingw32-gcc" (R-devel 58077).
>
>
> Actually "gcc -m64" and that is also the case when I just tried yesterday's
> CRAN version (which is 58125). I guess you have an older version of R in
> your PATH?
>


I can't seem to download the latest R-devel. When I try and download this file:
http://cran.r-project.org/bin/windows/base/R-devel-win.exe

and install that, it turns out to be r58077. I've tried with two
different browsers and with curl, and with another CRAN mirror. I
tried this on a fresh machine with no previous R installations or
installer .exes lying around.

The web page
http://cran.r-project.org/bin/windows/base/rdevel.html
says I should be downloading r58133 but that doesn't seem to be the
case....can you look into this?


>
>
>
>> Also, I have the latest Rtools installed (VERSION.txt reads "Rtools
>> version 2.15.0.1911") and it is first on my PATH.
>>
>> I expect "gcc --version" to report 4.6.3 but it still says 4.5.0.
>>
>> "x86_64-w64-mingw32-gcc --version" reports 4.5.2.
>> "which gcc" reports "/cygdrive/c/Rtools215/MinGW/bin/gcc".
>>
>> "which x86_64-w64-mingw32-gcc" reports
>> "/cygdrive/c/Rtools215/MinGW64/bin/x86_64-w64-mingw32-gcc".
>
>
>
> Yes, these are the version you need for old versions of R that are included
> in the Rtools, but it has a third gcc in subdir gcc-4.6.3 which is the one
> you should have first in the path in order to use the new toolchain.


Good, I did not know about this directory. I will put it first in my
PATH after I am able to get a recent R-devel binary.
Thanks,
Dan




>
> Uwe Ligges
>
>
>
>
>
>>> (ii) There are various bug-fixes to the toolchain: notably x^n and exp(x)
>>> use gradual underflow to denormal numbers rather than abrubtly
>>> underflowing
>>> to zero.
>>>
>>> (iii) This is a 'multilib' toolchain: the compiler is named 'gcc.exe' for
>>> both architectures, selected by flag -m32 (the default) and -m64.
>>
>>
>> Looks like to check gcc versions I should (instead of what I do above)
>> do simply "gcc --version". I imagine that "gcc -m32 --version" would
>> report the same thing as "gcc -m64 --version".
>>
>> Thanks,
>> Dan
>>
>>
>>>
>>>
>>> On 29/11/2011 07:56, Prof Brian Ripley wrote:
>>>>
>>>>
>>>> An updated toolchain is now being used for Windows' builds of R-devel:
>>>> details are in the R-admin manual and at
>>>> http://www.murdoch-sutherland.com/Rtools/ and
>>>> http://www.stats.ox.ac.uk/pub/Rtools/
>>>>
>>>> Both 32- and 64-bit parts of the toolchain use v2.0.1 of the Mingw-w64
>>>> project's runtime and a beta of gcc 4.5.4: the Mingw.org project's
>>>> builds are no longer used. This should mean that code which compiles for
>>>> 64-bit Windows also compiles for 32-bit Windows, and v.v. unless code
>>>> makes (incorrect but common) assumptions that pointers fit into longs.
>>>>
>>>> A very few packages will need modifications because they contain
>>>> declarations which clash with the headers in this toolchain: where we
>>>> are aware of problems the maintainers have been informed.
>>>>
>>>> At DLL level different Windows' toolchains should be compatible: at C
>>>> level they mostly are but at C++ level they are pretty much incompatible
>>>> (so that for example GDAL has to be re-compiled for every toolchain: and
>>>> Rcpp users need to be careful to use only one toolchain for Rcpp and
>>>> their packages). All the external software previously made available
>>>> (and more) is made available at http://www.stats.ox.ac.uk/pub/Rtools .
>>>>
>>>> The toolchain has support for OpenMP and pthreads: however OpenMP
>>>> support is not enabled by default in R (it is too slow to be much use).
>>>> If you do make use of it in your packages, be aware that you will need
>>>> to ship the appropriate pthreads DLL(s).
>>>>
>>>> It is expected that there will be several further minor updates prior to
>>>> the release of 2.15.0 in ca 4 months, but this step is the major one.
>>>>
>>>
>>>
>>> --
>>> Brian D. Ripley, ? ? ? ? ? ? ? ? ?ripley at stats.ox.ac.uk
>>> Professor of Applied Statistics, ?http://www.stats.ox.ac.uk/~ripley/
>>> University of Oxford, ? ? ? ? ? ? Tel: ?+44 1865 272861 (self)
>>> 1 South Parks Road, ? ? ? ? ? ? ? ? ? ? +44 1865 272866 (PA)
>>> Oxford OX1 3TG, UK ? ? ? ? ? ? ? ?Fax: ?+44 1865 272595
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel


From ligges at statistik.tu-dortmund.de  Thu Jan 19 10:57:21 2012
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Thu, 19 Jan 2012 10:57:21 +0100
Subject: [Rd] Updated Windows toolchain
In-Reply-To: <CAF42j20KOnRYQM+X=z9KPOLHp4wc-wNofMH-cGDn6N=9krZmkQ@mail.gmail.com>
References: <alpine.LFD.2.02.1111281109480.16728@toucan.stats.ox.ac.uk>
	<4F0AA535.4030006@stats.ox.ac.uk>
	<CAF42j23Km+B6+w7ur12s7-_8xq-GCE17wpi40SKdLWreXnTFeg@mail.gmail.com>
	<4F16806B.7000104@statistik.tu-dortmund.de>
	<CAF42j20KOnRYQM+X=z9KPOLHp4wc-wNofMH-cGDn6N=9krZmkQ@mail.gmail.com>
Message-ID: <4F17E901.3090606@statistik.tu-dortmund.de>

For the records: This rsync infelicity has been solved in the meantime.

Uwe Ligges

On 19.01.2012 02:03, Dan Tenenbaum wrote:
> Hi Uwe,
>
> 2012/1/18 Uwe Ligges<ligges at statistik.tu-dortmund.de>:
>>
>>
>> On 18.01.2012 01:09, Dan Tenenbaum wrote:
>>>
>>> Hello,
>>>
>>> On Mon, Jan 9, 2012 at 12:28 AM, Prof Brian Ripley
>>> <ripley at stats.ox.ac.uk>    wrote:
>>>>
>>>> CRAN Windows binary packages built for R-devel are now online, and Uwe's
>>>> winbuilder has gained the ability to check source packages under R-devel.
>>>>
>>>> Windows check results are available from
>>>> http://cran.r-project.org/bin/windows/contrib/checkSummaryWin.html
>>>> and in due course from the main CRAN check page.
>>>>
>>>> There have been a few updates to the toolchain:
>>>>
>>>> (i) It is now based on a beta of gcc 4.6.3, and so reports almost the
>>>> same
>>>> compilation warnings/errors as the CRAN check machines.
>>>>
>>>
>>> Is the binary R-devel provided by CRAN built against this toolchain?
>>> If it is, should I expect "R --arch x64 CMD config CC" to report
>>> "gcc"? It still reports "x86_64-w64-mingw32-gcc" (R-devel 58077).
>>
>>
>> Actually "gcc -m64" and that is also the case when I just tried yesterday's
>> CRAN version (which is 58125). I guess you have an older version of R in
>> your PATH?
>>
>
>
> I can't seem to download the latest R-devel. When I try and download this file:
> http://cran.r-project.org/bin/windows/base/R-devel-win.exe
>
> and install that, it turns out to be r58077. I've tried with two
> different browsers and with curl, and with another CRAN mirror. I
> tried this on a fresh machine with no previous R installations or
> installer .exes lying around.
>
> The web page
> http://cran.r-project.org/bin/windows/base/rdevel.html
> says I should be downloading r58133 but that doesn't seem to be the
> case....can you look into this?
>
>
>>
>>
>>
>>> Also, I have the latest Rtools installed (VERSION.txt reads "Rtools
>>> version 2.15.0.1911") and it is first on my PATH.
>>>
>>> I expect "gcc --version" to report 4.6.3 but it still says 4.5.0.
>>>
>>> "x86_64-w64-mingw32-gcc --version" reports 4.5.2.
>>> "which gcc" reports "/cygdrive/c/Rtools215/MinGW/bin/gcc".
>>>
>>> "which x86_64-w64-mingw32-gcc" reports
>>> "/cygdrive/c/Rtools215/MinGW64/bin/x86_64-w64-mingw32-gcc".
>>
>>
>>
>> Yes, these are the version you need for old versions of R that are included
>> in the Rtools, but it has a third gcc in subdir gcc-4.6.3 which is the one
>> you should have first in the path in order to use the new toolchain.
>
>
> Good, I did not know about this directory. I will put it first in my
> PATH after I am able to get a recent R-devel binary.
> Thanks,
> Dan
>
>
>
>
>>
>> Uwe Ligges
>>
>>
>>
>>
>>
>>>> (ii) There are various bug-fixes to the toolchain: notably x^n and exp(x)
>>>> use gradual underflow to denormal numbers rather than abrubtly
>>>> underflowing
>>>> to zero.
>>>>
>>>> (iii) This is a 'multilib' toolchain: the compiler is named 'gcc.exe' for
>>>> both architectures, selected by flag -m32 (the default) and -m64.
>>>
>>>
>>> Looks like to check gcc versions I should (instead of what I do above)
>>> do simply "gcc --version". I imagine that "gcc -m32 --version" would
>>> report the same thing as "gcc -m64 --version".
>>>
>>> Thanks,
>>> Dan
>>>
>>>
>>>>
>>>>
>>>> On 29/11/2011 07:56, Prof Brian Ripley wrote:
>>>>>
>>>>>
>>>>> An updated toolchain is now being used for Windows' builds of R-devel:
>>>>> details are in the R-admin manual and at
>>>>> http://www.murdoch-sutherland.com/Rtools/ and
>>>>> http://www.stats.ox.ac.uk/pub/Rtools/
>>>>>
>>>>> Both 32- and 64-bit parts of the toolchain use v2.0.1 of the Mingw-w64
>>>>> project's runtime and a beta of gcc 4.5.4: the Mingw.org project's
>>>>> builds are no longer used. This should mean that code which compiles for
>>>>> 64-bit Windows also compiles for 32-bit Windows, and v.v. unless code
>>>>> makes (incorrect but common) assumptions that pointers fit into longs.
>>>>>
>>>>> A very few packages will need modifications because they contain
>>>>> declarations which clash with the headers in this toolchain: where we
>>>>> are aware of problems the maintainers have been informed.
>>>>>
>>>>> At DLL level different Windows' toolchains should be compatible: at C
>>>>> level they mostly are but at C++ level they are pretty much incompatible
>>>>> (so that for example GDAL has to be re-compiled for every toolchain: and
>>>>> Rcpp users need to be careful to use only one toolchain for Rcpp and
>>>>> their packages). All the external software previously made available
>>>>> (and more) is made available at http://www.stats.ox.ac.uk/pub/Rtools .
>>>>>
>>>>> The toolchain has support for OpenMP and pthreads: however OpenMP
>>>>> support is not enabled by default in R (it is too slow to be much use).
>>>>> If you do make use of it in your packages, be aware that you will need
>>>>> to ship the appropriate pthreads DLL(s).
>>>>>
>>>>> It is expected that there will be several further minor updates prior to
>>>>> the release of 2.15.0 in ca 4 months, but this step is the major one.
>>>>>
>>>>
>>>>
>>>> --
>>>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>>>> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>>>> University of Oxford,             Tel:  +44 1865 272861 (self)
>>>> 1 South Parks Road,                     +44 1865 272866 (PA)
>>>> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From Dimosthenis.Gaidatzis at fmi.ch  Thu Jan 19 12:56:57 2012
From: Dimosthenis.Gaidatzis at fmi.ch (Gaidatzis, Dimosthenis)
Date: Thu, 19 Jan 2012 11:56:57 +0000
Subject: [Rd] Capturing interrupts during the execution of system/system2
Message-ID: <B2A3FCD3A6CA804DA7F40AE7FD8F7BE0224995DF@EXCHANGE1.fmi.ch>

Dear R Team

I have a question about the system/system2 command in R on linux. My goal is to run a system command (which can take a long time) and to detect if it was successful or not. If i understood correctly the return value of system should give me exactly this information. However if i try to do this, system returns 0, even if i interrupt the execution with CTRL-C (which is the event i would like to detect). Here is an example (just piping /dev/zero to /dev/null) to illustrate the behavior after pressing CTRL-C.

> ret <- system("cat /dev/zero > /dev/null"); print(ret)
^C[1] 0

I also tried to use a tryCatch block to detect this event but pressing CTRL-C during the execution of the system command does not result in a capture of this interrupt event. Only releasing resources is called which happens in any case:

> tryCatch({
+   ret <- system("cat /dev/zero > /dev/null"); print(ret)
+ }, interrupt = function(ex) {
+   cat("An interrupt was detected.\n");
+   print(ex);
+ }, error = function(ex) {
+   cat("An error was detected.\n");
+   print(ex);
+ }, finally = {
+   cat("Releasing resources...");
+   cat("done\n");
+ })
^C[1] 0
Releasing resources...done


Is there still a way to find out if the user stopped the R script while the system command was running?

R version 2.14.1 (2011-12-22)
Platform: x86_64-unknown-linux-gnu (64-bit)

Kind regards
Dimos Gaidatzis


From gisli at analytica.is  Thu Jan 19 16:03:29 2012
From: gisli at analytica.is (=?iso-8859-1?Q?G=EDsli_Leifsson?=)
Date: Thu, 19 Jan 2012 15:03:29 +0000
Subject: [Rd] RApache installation problems
Message-ID: <95B0A4BC18C4A04C85B1939A95D1E27101181E2BF4@umsisexch02.innra.umsja.is>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20120119/c11047ca/attachment.pl>

From thomas at zumbrunn.name  Fri Jan 20 00:39:18 2012
From: thomas at zumbrunn.name (Thomas Zumbrunn)
Date: Fri, 20 Jan 2012 00:39:18 +0100
Subject: [Rd] use of UTF-8 \uxxxx escape sequences in function arguments
In-Reply-To: <2855A65F-5760-4076-BF1D-E80FEDCA0DB0@gmail.com>
References: <201201182354.43607.thomas@zumbrunn.name>
	<2855A65F-5760-4076-BF1D-E80FEDCA0DB0@gmail.com>
Message-ID: <201201200039.18352.thomas@zumbrunn.name>

On Thursday 19 January 2012, peter dalgaard wrote:
> On Jan 18, 2012, at 23:54 , Thomas Zumbrunn wrote:
> >   plain("Z?rich")  ## works
> >   plain("Z\u00BCrich")  ## fails
> >   escaped("Z?rich")  ## fails
> >   escaped("Z\u00BCrich")  ## works
> 
> Using the correct UTF-8 code helps quite a bit:
> 
> U+00BC	?	c2 bc	VULGAR FRACTION ONE QUARTER
> U+00FC	?	c3 bc	LATIN SMALL LETTER U WITH DIAERESIS

Thank you for pointing that out. How embarrassing - I systematically used the 
wrong representations. Even worse, I didn't carefully read "Writing R 
Extensions" which speaks of "Unicode as \uxxxx escapes" rather than "UTF-8 as 
\uxxxx escapes", so e.g. looking up the UTF-16 byte representations would have 
done the trick.

I didn't find a recommended method of replacing non-ASCII characters with 
Unicode \uxxxx escape sequences and ended up using the Unix command line tool 
"iconv". However, the iconv version installed on my GNU/Linux machine 
(openSUSE 11.4) seems to be outdated and doesn't support the very useful "--
unicode-subst" option yet. I installed "libiconv" from 
http://www.gnu.org/software/libiconv/, and now I can easily replace all non-
ASCII characters in my UTF-8 encoded R files with:

  iconv -f UTF-8 -t ASCII --unicode-subst="\u%04X" my-utf-8-encoded-file.R

Thomas Zumbrunn


From jeroen.ooms at stat.ucla.edu  Fri Jan 20 01:27:46 2012
From: jeroen.ooms at stat.ucla.edu (Jeroen Ooms)
Date: Thu, 19 Jan 2012 16:27:46 -0800
Subject: [Rd] use of UTF-8 \uxxxx escape sequences in function arguments
In-Reply-To: <201201200039.18352.thomas@zumbrunn.name>
References: <201201182354.43607.thomas@zumbrunn.name>
	<2855A65F-5760-4076-BF1D-E80FEDCA0DB0@gmail.com>
	<201201200039.18352.thomas@zumbrunn.name>
Message-ID: <CABFfbXv+9y94tAn+NKgyW8zw0Ee2L7t+AQNbXVyOKDYKE44xOA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20120119/e875d8d0/attachment.pl>

From dtenenba at fhcrc.org  Fri Jan 20 01:40:57 2012
From: dtenenba at fhcrc.org (Dan Tenenbaum)
Date: Thu, 19 Jan 2012 16:40:57 -0800
Subject: [Rd] Updated Windows toolchain
In-Reply-To: <19549_1326967036_4F17E8FC_19549_13846_1_4F17E901.3090606@statistik.tu-dortmund.de>
References: <alpine.LFD.2.02.1111281109480.16728@toucan.stats.ox.ac.uk>
	<4F0AA535.4030006@stats.ox.ac.uk>
	<CAF42j23Km+B6+w7ur12s7-_8xq-GCE17wpi40SKdLWreXnTFeg@mail.gmail.com>
	<4F16806B.7000104@statistik.tu-dortmund.de>
	<CAF42j20KOnRYQM+X=z9KPOLHp4wc-wNofMH-cGDn6N=9krZmkQ@mail.gmail.com>
	<19549_1326967036_4F17E8FC_19549_13846_1_4F17E901.3090606@statistik.tu-dortmund.de>
Message-ID: <CAF42j22T7v78iwYa5a-GfJ+gXjb1pcLzgAeWe2KpBA-uLSLimw@mail.gmail.com>

2012/1/19 Uwe Ligges <ligges at statistik.tu-dortmund.de>:
> For the records: This rsync infelicity has been solved in the meantime.

I can confirm that it works; just downloaded r58140.
Thanks!
Dan

>
> Uwe Ligges
>
>
> On 19.01.2012 02:03, Dan Tenenbaum wrote:
>>
>> Hi Uwe,
>>
>> 2012/1/18 Uwe Ligges<ligges at statistik.tu-dortmund.de>:
>>>
>>>
>>>
>>> On 18.01.2012 01:09, Dan Tenenbaum wrote:
>>>>
>>>>
>>>> Hello,
>>>>
>>>> On Mon, Jan 9, 2012 at 12:28 AM, Prof Brian Ripley
>>>> <ripley at stats.ox.ac.uk> ? ?wrote:
>>>>>
>>>>>
>>>>> CRAN Windows binary packages built for R-devel are now online, and
>>>>> Uwe's
>>>>> winbuilder has gained the ability to check source packages under
>>>>> R-devel.
>>>>>
>>>>> Windows check results are available from
>>>>> http://cran.r-project.org/bin/windows/contrib/checkSummaryWin.html
>>>>> and in due course from the main CRAN check page.
>>>>>
>>>>> There have been a few updates to the toolchain:
>>>>>
>>>>> (i) It is now based on a beta of gcc 4.6.3, and so reports almost the
>>>>> same
>>>>> compilation warnings/errors as the CRAN check machines.
>>>>>
>>>>
>>>> Is the binary R-devel provided by CRAN built against this toolchain?
>>>> If it is, should I expect "R --arch x64 CMD config CC" to report
>>>> "gcc"? It still reports "x86_64-w64-mingw32-gcc" (R-devel 58077).
>>>
>>>
>>>
>>> Actually "gcc -m64" and that is also the case when I just tried
>>> yesterday's
>>> CRAN version (which is 58125). I guess you have an older version of R in
>>> your PATH?
>>>
>>
>>
>> I can't seem to download the latest R-devel. When I try and download this
>> file:
>> http://cran.r-project.org/bin/windows/base/R-devel-win.exe
>>
>> and install that, it turns out to be r58077. I've tried with two
>> different browsers and with curl, and with another CRAN mirror. I
>> tried this on a fresh machine with no previous R installations or
>> installer .exes lying around.
>>
>> The web page
>> http://cran.r-project.org/bin/windows/base/rdevel.html
>> says I should be downloading r58133 but that doesn't seem to be the
>> case....can you look into this?
>>
>>
>>>
>>>
>>>
>>>> Also, I have the latest Rtools installed (VERSION.txt reads "Rtools
>>>> version 2.15.0.1911") and it is first on my PATH.
>>>>
>>>> I expect "gcc --version" to report 4.6.3 but it still says 4.5.0.
>>>>
>>>> "x86_64-w64-mingw32-gcc --version" reports 4.5.2.
>>>> "which gcc" reports "/cygdrive/c/Rtools215/MinGW/bin/gcc".
>>>>
>>>> "which x86_64-w64-mingw32-gcc" reports
>>>> "/cygdrive/c/Rtools215/MinGW64/bin/x86_64-w64-mingw32-gcc".
>>>
>>>
>>>
>>>
>>> Yes, these are the version you need for old versions of R that are
>>> included
>>> in the Rtools, but it has a third gcc in subdir gcc-4.6.3 which is the
>>> one
>>> you should have first in the path in order to use the new toolchain.
>>
>>
>>
>> Good, I did not know about this directory. I will put it first in my
>> PATH after I am able to get a recent R-devel binary.
>> Thanks,
>> Dan
>>
>>
>>
>>
>>>
>>> Uwe Ligges
>>>
>>>
>>>
>>>
>>>
>>>>> (ii) There are various bug-fixes to the toolchain: notably x^n and
>>>>> exp(x)
>>>>> use gradual underflow to denormal numbers rather than abrubtly
>>>>> underflowing
>>>>> to zero.
>>>>>
>>>>> (iii) This is a 'multilib' toolchain: the compiler is named 'gcc.exe'
>>>>> for
>>>>> both architectures, selected by flag -m32 (the default) and -m64.
>>>>
>>>>
>>>>
>>>> Looks like to check gcc versions I should (instead of what I do above)
>>>> do simply "gcc --version". I imagine that "gcc -m32 --version" would
>>>> report the same thing as "gcc -m64 --version".
>>>>
>>>> Thanks,
>>>> Dan
>>>>
>>>>
>>>>>
>>>>>
>>>>> On 29/11/2011 07:56, Prof Brian Ripley wrote:
>>>>>>
>>>>>>
>>>>>>
>>>>>> An updated toolchain is now being used for Windows' builds of R-devel:
>>>>>> details are in the R-admin manual and at
>>>>>> http://www.murdoch-sutherland.com/Rtools/ and
>>>>>> http://www.stats.ox.ac.uk/pub/Rtools/
>>>>>>
>>>>>> Both 32- and 64-bit parts of the toolchain use v2.0.1 of the Mingw-w64
>>>>>> project's runtime and a beta of gcc 4.5.4: the Mingw.org project's
>>>>>> builds are no longer used. This should mean that code which compiles
>>>>>> for
>>>>>> 64-bit Windows also compiles for 32-bit Windows, and v.v. unless code
>>>>>> makes (incorrect but common) assumptions that pointers fit into longs.
>>>>>>
>>>>>> A very few packages will need modifications because they contain
>>>>>> declarations which clash with the headers in this toolchain: where we
>>>>>> are aware of problems the maintainers have been informed.
>>>>>>
>>>>>> At DLL level different Windows' toolchains should be compatible: at C
>>>>>> level they mostly are but at C++ level they are pretty much
>>>>>> incompatible
>>>>>> (so that for example GDAL has to be re-compiled for every toolchain:
>>>>>> and
>>>>>> Rcpp users need to be careful to use only one toolchain for Rcpp and
>>>>>> their packages). All the external software previously made available
>>>>>> (and more) is made available at http://www.stats.ox.ac.uk/pub/Rtools .
>>>>>>
>>>>>> The toolchain has support for OpenMP and pthreads: however OpenMP
>>>>>> support is not enabled by default in R (it is too slow to be much
>>>>>> use).
>>>>>> If you do make use of it in your packages, be aware that you will need
>>>>>> to ship the appropriate pthreads DLL(s).
>>>>>>
>>>>>> It is expected that there will be several further minor updates prior
>>>>>> to
>>>>>> the release of 2.15.0 in ca 4 months, but this step is the major one.
>>>>>>
>>>>>
>>>>>
>>>>> --
>>>>> Brian D. Ripley, ? ? ? ? ? ? ? ? ?ripley at stats.ox.ac.uk
>>>>> Professor of Applied Statistics, ?http://www.stats.ox.ac.uk/~ripley/
>>>>> University of Oxford, ? ? ? ? ? ? Tel: ?+44 1865 272861 (self)
>>>>> 1 South Parks Road, ? ? ? ? ? ? ? ? ? ? +44 1865 272866 (PA)
>>>>> Oxford OX1 3TG, UK ? ? ? ? ? ? ? ?Fax: ?+44 1865 272595
>>>>>
>>>>> ______________________________________________
>>>>> R-devel at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>
>>>>
>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel


From simon.urbanek at r-project.org  Fri Jan 20 02:58:54 2012
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Thu, 19 Jan 2012 20:58:54 -0500
Subject: [Rd] use of UTF-8 \uxxxx escape sequences in function arguments
In-Reply-To: <201201200039.18352.thomas@zumbrunn.name>
References: <201201182354.43607.thomas@zumbrunn.name>
	<2855A65F-5760-4076-BF1D-E80FEDCA0DB0@gmail.com>
	<201201200039.18352.thomas@zumbrunn.name>
Message-ID: <0D9CB9D9-E945-4761-BDA4-AC347E9F70C3@r-project.org>


On Jan 19, 2012, at 6:39 PM, Thomas Zumbrunn wrote:

> On Thursday 19 January 2012, peter dalgaard wrote:
>> On Jan 18, 2012, at 23:54 , Thomas Zumbrunn wrote:
>>>  plain("Z?rich")  ## works
>>>  plain("Z\u00BCrich")  ## fails
>>>  escaped("Z?rich")  ## fails
>>>  escaped("Z\u00BCrich")  ## works
>> 
>> Using the correct UTF-8 code helps quite a bit:
>> 
>> U+00BC	?	c2 bc	VULGAR FRACTION ONE QUARTER
>> U+00FC	?	c3 bc	LATIN SMALL LETTER U WITH DIAERESIS
> 
> Thank you for pointing that out. How embarrassing - I systematically used the 
> wrong representations. Even worse, I didn't carefully read "Writing R 
> Extensions" which speaks of "Unicode as \uxxxx escapes" rather than "UTF-8 as 
> \uxxxx escapes", so e.g. looking up the UTF-16 byte representations would have 
> done the trick.
> 
> I didn't find a recommended method of replacing non-ASCII characters with 
> Unicode \uxxxx escape sequences and ended up using the Unix command line tool 
> "iconv". However, the iconv version installed on my GNU/Linux machine 
> (openSUSE 11.4) seems to be outdated and doesn't support the very useful "--
> unicode-subst" option yet. I installed "libiconv" from 
> http://www.gnu.org/software/libiconv/, and now I can easily replace all non-
> ASCII characters in my UTF-8 encoded R files with:
> 
>  iconv -f UTF-8 -t ASCII --unicode-subst="\u%04X" my-utf-8-encoded-file.R
> 


You can actually do that with R alone:

## you'll have to make sure that you're in C locale so R does the conversion for you
Sys.setlocale(,"C")

utf8conv <- function(conn) gsub("<U\\+([0-9A-F]{4})>","\\\\u\\1",capture.output(writeLines(readLines(conn,encoding="UTF-8"))))

> writeLines(utf8conv("test.txt"))
M\u00F6gliche L\u00F6sung
ne nebezpe\u010Dn\u00E9

Cheers,
Simon


From simon.urbanek at r-project.org  Fri Jan 20 02:59:37 2012
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Thu, 19 Jan 2012 20:59:37 -0500
Subject: [Rd] use of UTF-8 \uxxxx escape sequences in function arguments
In-Reply-To: <CABFfbXv+9y94tAn+NKgyW8zw0Ee2L7t+AQNbXVyOKDYKE44xOA@mail.gmail.com>
References: <201201182354.43607.thomas@zumbrunn.name>
	<2855A65F-5760-4076-BF1D-E80FEDCA0DB0@gmail.com>
	<201201200039.18352.thomas@zumbrunn.name>
	<CABFfbXv+9y94tAn+NKgyW8zw0Ee2L7t+AQNbXVyOKDYKE44xOA@mail.gmail.com>
Message-ID: <71C3FFBE-B0A0-43A2-AA11-459576712566@r-project.org>


On Jan 19, 2012, at 7:27 PM, Jeroen Ooms wrote:

>> 
>> I installed "libiconv" from http://www.gnu.org/software/libiconv/, and
>> now I can easily replace all non- ASCII characters in my UTF-8 encoded R
>> files with: iconv -f UTF-8 -t ASCII --unicode-subst="\u%04X"
>> my-utf-8-encoded-file.R
> 
> 
> Maybe it would be possible to create an R package that exposes an R
> interface to libiconv, in a smililar spirt as how the package XML
> interfaces to libxml2 and RCurl to libcurl, etc
> 

Well, R does that - see ?iconv ...


From Berwin.Turlach at gmail.com  Fri Jan 20 06:30:14 2012
From: Berwin.Turlach at gmail.com (Berwin A Turlach)
Date: Fri, 20 Jan 2012 13:30:14 +0800
Subject: [Rd] nobs() and logLik()
Message-ID: <20120120133014.56c9fd05@bossiaea>

Dear all,

I am studying a bit the various support functions that exist for
extracting information from fitted model objects.

From the help files it is not completely clear to me whether the number 
returned by nobs() should be the same as the "nobs" attribute of the
object returned by logLik().  

If so, then there is a slight inconsistency in the methods for 'nls'
objects with logLik.nls() taking zero weights into account while
nobs.nls() does not.  Admittedly, the help page of nobs() states that:

	For 'lm' and 'glm' fits, observations with zero weight are not
	included.

i.e. does not comment on what nls does.  

But I wonder whether the following behaviour is desirable:

R> DNase1 <- subset(DNase, Run == 1)
R> fm3DNase2 <- nls(density ~ Asym/(1 + exp((xmid - log(conc))/scal)), 
+         data = DNase1, weights=c(0,rep(1,14),0), 
+         start = list(Asym = 3, xmid = 0, scal = 1))
R> nobs(fm3DNase2)
[1] 16
> logLik(fm3DNase2)
'log Lik.' 42.62777 (df=4)
> nobs(logLik(fm3DNase2))
[1] 14
 
Cheers,

	Berwin


From ripley at stats.ox.ac.uk  Fri Jan 20 07:20:30 2012
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 20 Jan 2012 06:20:30 +0000
Subject: [Rd] nobs() and logLik()
In-Reply-To: <20120120133014.56c9fd05@bossiaea>
References: <20120120133014.56c9fd05@bossiaea>
Message-ID: <4F1907AE.3090302@stats.ox.ac.uk>

I do wonder why people use zero weights rather than 'subset', and I 
don't particularly like the discontinuity as a weight goes to zero.

But this came up for glm() and it would be better to be consistent, so 
thanks for pointing out the nls() cases.  We'll alter them.

On 20/01/2012 05:30, Berwin A Turlach wrote:
> Dear all,
>
> I am studying a bit the various support functions that exist for
> extracting information from fitted model objects.
>
>> From the help files it is not completely clear to me whether the number
> returned by nobs() should be the same as the "nobs" attribute of the
> object returned by logLik().
>
> If so, then there is a slight inconsistency in the methods for 'nls'
> objects with logLik.nls() taking zero weights into account while
> nobs.nls() does not.  Admittedly, the help page of nobs() states that:
>
> 	For 'lm' and 'glm' fits, observations with zero weight are not
> 	included.
>
> i.e. does not comment on what nls does.
>
> But I wonder whether the following behaviour is desirable:
>
> R>  DNase1<- subset(DNase, Run == 1)
> R>  fm3DNase2<- nls(density ~ Asym/(1 + exp((xmid - log(conc))/scal)),
> +         data = DNase1, weights=c(0,rep(1,14),0),
> +         start = list(Asym = 3, xmid = 0, scal = 1))
> R>  nobs(fm3DNase2)
> [1] 16
>> logLik(fm3DNase2)
> 'log Lik.' 42.62777 (df=4)
>> nobs(logLik(fm3DNase2))
> [1] 14
>
> Cheers,
>
> 	Berwin
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From Berwin.Turlach at gmail.com  Fri Jan 20 07:42:08 2012
From: Berwin.Turlach at gmail.com (Berwin A Turlach)
Date: Fri, 20 Jan 2012 14:42:08 +0800
Subject: [Rd] nobs() and logLik()
In-Reply-To: <4F1907AE.3090302@stats.ox.ac.uk>
References: <20120120133014.56c9fd05@bossiaea>
	<4F1907AE.3090302@stats.ox.ac.uk>
Message-ID: <20120120144208.2d6fdfed@bossiaea>

G'day Brian,

On Fri, 20 Jan 2012 06:20:30 +0000
Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:

> I do wonder why people use zero weights rather than 'subset', and I 
> don't particularly like the discontinuity as a weight goes to zero.

I completely agree, and for developers it is a bit of a pain to make
sure that all possible combinations of 'subset' and 'weights' play
"nicely" together.

One reason that I can see for people to use zero weights rather than
'subset' is that fitted() and predict() in the former case readily
produce fitted values for the observations that received a zero weight.

Cheers,

	Berwin


From thomas at zumbrunn.name  Fri Jan 20 13:52:36 2012
From: thomas at zumbrunn.name (Thomas Zumbrunn)
Date: Fri, 20 Jan 2012 13:52:36 +0100
Subject: [Rd] use of UTF-8 \uxxxx escape sequences in function arguments
In-Reply-To: <0D9CB9D9-E945-4761-BDA4-AC347E9F70C3@r-project.org>
References: <201201182354.43607.thomas@zumbrunn.name>
	<201201200039.18352.thomas@zumbrunn.name>
	<0D9CB9D9-E945-4761-BDA4-AC347E9F70C3@r-project.org>
Message-ID: <201201201352.36369.thomas@zumbrunn.name>

On Friday 20 January 2012, Simon Urbanek wrote:
> On Jan 19, 2012, at 6:39 PM, Thomas Zumbrunn wrote:
> > On Thursday 19 January 2012, peter dalgaard wrote:
> >> On Jan 18, 2012, at 23:54 , Thomas Zumbrunn wrote:
> >>>  plain("Z?rich")  ## works
> >>>  plain("Z\u00BCrich")  ## fails
> >>>  escaped("Z?rich")  ## fails
> >>>  escaped("Z\u00BCrich")  ## works
> >> 
> >> Using the correct UTF-8 code helps quite a bit:
> >> 
> >> U+00BC	?	c2 bc	VULGAR FRACTION ONE QUARTER
> >> U+00FC	?	c3 bc	LATIN SMALL LETTER U WITH DIAERESIS
> > 
> > Thank you for pointing that out. How embarrassing - I systematically used
> > the wrong representations. Even worse, I didn't carefully read "Writing
> > R Extensions" which speaks of "Unicode as \uxxxx escapes" rather than
> > "UTF-8 as \uxxxx escapes", so e.g. looking up the UTF-16 byte
> > representations would have done the trick.
> > 
> > I didn't find a recommended method of replacing non-ASCII characters with
> > Unicode \uxxxx escape sequences and ended up using the Unix command line
> > tool "iconv". However, the iconv version installed on my GNU/Linux
> > machine (openSUSE 11.4) seems to be outdated and doesn't support the
> > very useful "-- unicode-subst" option yet. I installed "libiconv" from
> > http://www.gnu.org/software/libiconv/, and now I can easily replace all
> > non-
> > 
> > ASCII characters in my UTF-8 encoded R files with:
> >  iconv -f UTF-8 -t ASCII --unicode-subst="\u%04X" my-utf-8-encoded-file.R
> 
> You can actually do that with R alone:
> 
> ## you'll have to make sure that you're in C locale so R does the conversion for you
> Sys.setlocale(,"C")
> 
> utf8conv <- function(conn)
> gsub("<U\\+([0-9A-F]{4})>","\\\\u\\1",capture.output(writeLines(readLines(conn,encoding="UTF-8"))))
> 
> > writeLines(utf8conv("test.txt"))
> 
> M\u00F6gliche L\u00F6sung
> ne nebezpe\u010Dn\u00E9
> 
> Cheers,
> Simon

Thanks for the above function (which I wouldn't have managed to construct, ever...). Maybe this is worth mentioning in the 
"Writing R Extensions" manual (next to where the \uxxxx Unicode escape sequences are mentioned).

Thomas


From friendly at yorku.ca  Fri Jan 20 15:19:30 2012
From: friendly at yorku.ca (Michael Friendly)
Date: Fri, 20 Jan 2012 09:19:30 -0500
Subject: [Rd] nobs() and logLik()
In-Reply-To: <20120120144208.2d6fdfed@bossiaea>
References: <20120120133014.56c9fd05@bossiaea>
	<4F1907AE.3090302@stats.ox.ac.uk>
	<20120120144208.2d6fdfed@bossiaea>
Message-ID: <4F1977F2.8030905@yorku.ca>

On 1/20/2012 1:42 AM, Berwin A Turlach wrote:
> One reason that I can see for people to use zero weights rather than
> 'subset' is that fitted() and predict() in the former case readily
> produce fitted values for the observations that received a zero weight.
>
Another is that including the case of zero weights naturally allows a 
variety of simple robust methods via a weight function that descends to 
0.  A discontinuity at 0 in the handling of weights prevents this use.

-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept.
York University      Voice: 416 736-5115 x66249 Fax: 416 736-5814
4700 Keele Street    Web:   http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA


From matt at biostatmatt.com  Sat Jan 21 15:20:21 2012
From: matt at biostatmatt.com (Matt Shotwell)
Date: Sat, 21 Jan 2012 08:20:21 -0600
Subject: [Rd] RApache installation problems
In-Reply-To: <95B0A4BC18C4A04C85B1939A95D1E27101181E2BF4@umsisexch02.innra.umsja.is>
References: <95B0A4BC18C4A04C85B1939A95D1E27101181E2BF4@umsisexch02.innra.umsja.is>
Message-ID: <1327155621.2546.3.camel@pal>

Here are some leads:

1) https://github.com/jeffreyhorner/rapache/commit/c208e0b17eed04e265e7d555bd9f5395ae6ff7cb

2) http://www.rapache.net/rapache-1.1.16.tar.gz

On Thu, 2012-01-19 at 15:03 +0000, G?sli Leifsson wrote:
> Hi all
> 
> I was trying to isntall RApache last week but ran into strnge problems that no one else seems to be experiencing. At least I couldn't find anything after extensive googling.
> 
> First off, the machine I'm installing on looks like this:
> 
> Dell Optiplex 745
> 32 bit
> 2GB RAM
> Fedora 15
> httpd -v
> Server version: Apache/2.2.21 (Unix)
> Server built:   Sep 13 2011 13:46:23
> R:
> R-2.14.0-3.fc15.i686
> perl
>                 perl-5.12.4-164.fc15.i686
> 
> What I did was the following:
> 
> 
>          Downloaded the package, rapache-1.1.15.tar.gz
> 
>          Ran configure --with-apache2-apxs=/usr/sbin/apxs, make, make install.
> 
>          Added this to my httpd.conf:
> 
> o       LoadModule R_module /usr/lib/httpd/modules/mod_R.so
> 
> o
> 
> o       # Output R errors and warnings to the browser
> 
> o       ROutputErrors
> 
> o
> 
> o       # Displays information about rapache and R
> 
> o       <Location /RApacheInfo>
> 
> o          SetHandler r-info
> 
> o       </Location>
> Also added the Directory directives but commented them when I was trying to get this to work. I figured if I couldn't see the r-info, nothing would work.
> 
> Then I navigated to  /RApacheInfo on the machine and got an internal server error. The log says this:
> 
> [Thu Jan 19 14:37:33 2012] [error] [client 10.101.77.150] rApache Notice!
> No RApache Directive specified for 'SetHandler r-info'
> 
> I figured that had to be coming from the R module. I tried searching for this error message but it seemed like no one has been experiencing it.
> 
> After this I decided to revisit the configure script. I ran it again, this time I added the -with-R switch:
> 
> ./configure --with-apache2-apxs=/usr/sbin/apxs --with-R=/usr/bin/R
> 
> I examined the output and saw that there seemed to be an error but still the script ended with apparent success.
> 
> [root at keilir rapache-1.1.15]# ./configure --with-apache2-apxs=/usr/sbin/apxs --with-R=/usr/bin/R
> checking for a BSD-compatible install... /usr/bin/install -c
> checking whether build environment is sane... yes
> checking for a thread-safe mkdir -p... /bin/mkdir -p
> checking for gawk... gawk
> checking whether make sets $(MAKE)... yes
> checking whether to enable maintainer-specific portions of Makefiles... no
> checking build system type... i686-pc-linux-gnu
> checking host system type... i686-pc-linux-gnu
> checking for gcc... gcc
> checking whether the C compiler works... yes
> checking for C compiler default output file name... a.out
> checking for suffix of executables...
> checking whether we are cross compiling... no
> checking for suffix of object files... o
> checking whether we are using the GNU C compiler... yes
> checking whether gcc accepts -g... yes
> checking for gcc option to accept ISO C89... none needed
> checking for a sed that does not truncate output... /bin/sed
> checking for grep that handles long lines and -e... /bin/grep
> checking for egrep... /bin/grep -E
> checking for fgrep... /bin/grep -F
> checking for ld used by gcc... /usr/bin/ld
> checking if the linker (/usr/bin/ld) is GNU ld... yes
> checking for BSD- or MS-compatible name lister (nm)... /usr/bin/nm -B
> checking the name lister (/usr/bin/nm -B) interface... BSD nm
> checking whether ln -s works... yes
> checking the maximum length of command line arguments... 1572864
> checking whether the shell understands some XSI constructs... yes
> checking whether the shell understands "+="... yes
> checking for /usr/bin/ld option to reload object files... -r
> checking for objdump... objdump
> checking how to recognize dependent libraries... pass_all
> checking for ar... ar
> checking for strip... strip
> checking for ranlib... ranlib
> checking command to parse /usr/bin/nm -B output from gcc object... ok
> checking how to run the C preprocessor... gcc -E
> checking for ANSI C header files... yes
> checking for sys/types.h... yes
> checking for sys/stat.h... yes
> checking for stdlib.h... yes
> checking for string.h... yes
> checking for memory.h... yes
> checking for strings.h... yes
> checking for inttypes.h... yes
> checking for stdint.h... yes
> checking for unistd.h... yes
> checking for dlfcn.h... yes
> checking for objdir... .libs
> checking if gcc supports -fno-rtti -fno-exceptions... no
> checking for gcc option to produce PIC... -fPIC -DPIC
> checking if gcc PIC flag -fPIC -DPIC works... yes
> checking if gcc static flag -static works... no
> checking if gcc supports -c -o file.o... yes
> checking if gcc supports -c -o file.o... (cached) yes
> checking whether the gcc linker (/usr/bin/ld) supports shared libraries... yes
> checking whether -lc should be explicitly linked in... no
> checking dynamic linker characteristics... GNU/Linux ld.so
> checking how to hardcode library paths into programs... immediate
> checking whether stripping libraries is possible... yes
> checking if libtool supports shared libraries... yes
> checking whether to build shared libraries... yes
> checking whether to build static libraries... yes
> checking for sys/types.h... (cached) yes
> checking for unistd.h... (cached) yes
> checking for stdlib.h... (cached) yes
> checking for uname... /bin/uname
> checking for apxs2... checking for R Program... /usr/bin/R
> checking for apreq2-config... no
> 
> 
> Using libapreq2 that comes bundled with mod_R
> 
> checking for a BSD-compatible install... /usr/bin/install -c
> checking whether build environment is sane... yes
> checking for gawk... gawk
> checking whether make sets $(MAKE)... yes
> checking whether make sets $(MAKE)... (cached) yes
> checking for gcc... gcc
> checking for C compiler default output file name... a.out
> checking whether the C compiler works... yes
> checking whether we are cross compiling... no
> checking for suffix of executables...
> checking for suffix of object files... o
> checking whether we are using the GNU C compiler... yes
> checking whether gcc accepts -g... yes
> checking for gcc option to accept ANSI C... none needed
> checking for style of include used by make... GNU
> checking dependency style of gcc... gcc3
> checking build system type... i686-pc-linux-gnu
> checking host system type... i686-pc-linux-gnu
> checking for a sed that does not truncate output... /bin/sed
> checking for egrep... grep -E
> checking for ld used by gcc... /usr/bin/ld
> checking if the linker (/usr/bin/ld) is GNU ld... yes
> checking for /usr/bin/ld option to reload object files... -r
> checking for BSD-compatible nm... /usr/bin/nm -B
> checking whether ln -s works... yes
> checking how to recognise dependent libraries... pass_all
> checking how to run the C preprocessor... gcc -E
> checking for ANSI C header files... yes
> checking for sys/types.h... yes
> checking for sys/stat.h... yes
> checking for stdlib.h... yes
> checking for string.h... yes
> checking for memory.h... yes
> checking for strings.h... yes
> checking for inttypes.h... yes
> checking for stdint.h... yes
> checking for unistd.h... yes
> checking dlfcn.h usability... yes
> checking dlfcn.h presence... yes
> checking for dlfcn.h... yes
> checking for g++... g++
> checking whether we are using the GNU C++ compiler... yes
> checking whether g++ accepts -g... yes
> checking dependency style of g++... gcc3
> checking how to run the C++ preprocessor... g++ -E
> checking for g77... no
> checking for f77... no
> checking for xlf... no
> checking for frt... no
> checking for pgf77... no
> checking for fort77... no
> checking for fl32... no
> checking for af77... no
> checking for f90... no
> checking for xlf90... no
> checking for pgf90... no
> checking for epcf90... no
> checking for f95... f95
> checking whether we are using the GNU Fortran 77 compiler... yes
> checking whether f95 accepts -g... yes
> checking the maximum length of command line arguments... 32768
> checking command to parse /usr/bin/nm -B output from gcc object... ok
> checking for objdir... .libs
> checking for ar... ar
> checking for ranlib... ranlib
> checking for strip... strip
> checking if gcc static flag  works... yes
> checking if gcc supports -fno-rtti -fno-exceptions... no
> checking for gcc option to produce PIC... -fPIC
> checking if gcc PIC flag -fPIC works... yes
> checking if gcc supports -c -o file.o... yes
> checking whether the gcc linker (/usr/bin/ld) supports shared libraries... yes
> checking whether -lc should be explicitly linked in... no
> checking dynamic linker characteristics... GNU/Linux ld.so
> checking how to hardcode library paths into programs... immediate
> checking whether stripping libraries is possible... yes
> checking if libtool supports shared libraries... yes
> checking whether to build shared libraries... yes
> checking whether to build static libraries... yes
> configure: creating libtool
> appending configuration tag "CXX" to libtool
> checking for ld used by g++... /usr/bin/ld
> checking if the linker (/usr/bin/ld) is GNU ld... yes
> checking whether the g++ linker (/usr/bin/ld) supports shared libraries... yes
> checking for g++ option to produce PIC... -fPIC
> checking if g++ PIC flag -fPIC works... yes
> checking if g++ supports -c -o file.o... yes
> checking whether the g++ linker (/usr/bin/ld) supports shared libraries... yes
> checking dynamic linker characteristics... GNU/Linux ld.so
> checking how to hardcode library paths into programs... immediate
> checking whether stripping libraries is possible... yes
> appending configuration tag "F77" to libtool
> checking if libtool supports shared libraries... yes
> checking whether to build shared libraries... yes
> checking whether to build static libraries... yes
> checking for f95 option to produce PIC... -fPIC
> checking if f95 PIC flag -fPIC works... yes
> checking if f95 supports -c -o file.o... yes
> checking whether the f95 linker (/usr/bin/ld) supports shared libraries... yes
> checking dynamic linker characteristics... GNU/Linux ld.so
> checking how to hardcode library paths into programs... immediate
> checking whether stripping libraries is possible... yes
> checking for ranlib... (cached) ranlib
> checking for a BSD-compatible install... /usr/bin/install -c
> checking whether ln -s works... yes
> checking whether to enable maintainer-specific portions of Makefiles... no
> checking for /usr/bin/apr-1-config... yes
> checking for /usr/bin/apu-1-config... yes
> Can't locate Apache/Test.pm in @INC (@INC contains: /usr/local/lib/perl5 /usr/local/share/perl5 /usr/lib/perl5/vendor_perl /usr/share/perl5/vendor_perl /usr/lib/perl5 /usr/share/perl5 .) at build/version_check.pl line 27.
>   setting APR_INCLUDES to " -I/usr/include/apr-1 "
>   setting APR_LTFLAGS to " /usr/lib/libapr-1.la"
>   adding "/usr/lib/libaprutil-1.la" to APR_LTFLAGS
>   setting APR_LIBS to " -lldap -llber -llber -ldb-4.8 -lexpat -ldb-4.8 "
>   adding "-lpthread" to APR_LIBS
>   adding "-ldl" to APR_LIBS
>   setting APR_LDFLAGS to " -L/usr/lib -laprutil-1 "
>   adding "-lapr-1" to APR_LDFLAGS
>   setting CPPFLAGS to " -DLINUX=2 -D_REENTRANT -D_GNU_SOURCE -D_LARGEFILE64_SOURCE"
> libapreq2 Version: 2.1.0
> configure: creating ./config.status
> config.status: creating Makefile
> config.status: creating include/Makefile
> config.status: creating library/Makefile
> config.status: creating library/t/Makefile
> config.status: creating module/Makefile
> config.status: creating module/apache2/Makefile
> config.status: creating module/apache/Makefile
> config.status: creating glue/Makefile
> config.status: creating build/doxygen.conf
> config.status: creating include/groups.dox
> config.status: creating apreq2-config
> config.status: creating include/apreq_config.h
> config.status: include/apreq_config.h is unchanged
> config.status: executing depfiles commands
> configure: creating ./config.status
> config.status: creating Makefile
> config.status: creating mod_R.h
> config.status: executing libtool commands
> 
> I don't know if this error is critical but I couldn't get rid of it.
> 
> I'm not an R user myself. Not yet at least. Just the IT guy in my company. But the R people can't seem to contain themselves over RApache and really want to see it working.
> 
> Hope you can point me in the right direction.
> 
> Take care,
>   Gisli
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From xie at yihui.name  Sat Jan 21 19:50:14 2012
From: xie at yihui.name (Yihui Xie)
Date: Sat, 21 Jan 2012 12:50:14 -0600
Subject: [Rd] bug in pdf(file = NULL)
Message-ID: <CANROs4cPoTPBtBBqRn=cSp7=bAbnG_tS-SoLQsVVf8uCM82Vcw@mail.gmail.com>

Hi,

pdf(file = NULL) will actually create a file named NA, which is
inconsistent with its documentation. A minimal example:

pdf(file = NULL)
plot(1)
dev.off()

Perhaps this is a bug?

> list.files(pattern = '^NA$')
character(0)
> pdf(file = NULL)
> plot(1)
> dev.off()
null device
? ? ? ? ?1
> list.files(pattern = '^NA$')
[1] "NA"
> sessionInfo()
R version 2.14.1 (2011-12-22)
Platform: x86_64-pc-linux-gnu (64-bit)

locale:
?[1] LC_CTYPE=en_US.UTF-8 ? ? ? LC_NUMERIC=C
?[3] LC_TIME=en_US.UTF-8 ? ? ? ?LC_COLLATE=en_US.UTF-8
?[5] LC_MONETARY=en_US.UTF-8 ? ?LC_MESSAGES=en_US.UTF-8
?[7] LC_PAPER=C ? ? ? ? ? ? ? ? LC_NAME=C
?[9] LC_ADDRESS=C ? ? ? ? ? ? ? LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats ? ? graphics ?grDevices utils ? ? datasets ?methods ? base


Regards,
Yihui
--
Yihui Xie <xieyihui at gmail.com>
Phone: 515-294-2465 Web: http://yihui.name
Department of Statistics, Iowa State University
2215 Snedecor Hall, Ames, IA


From ripley at stats.ox.ac.uk  Sun Jan 22 14:56:01 2012
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 22 Jan 2012 13:56:01 +0000
Subject: [Rd] serialize/unserialize vector improvement
In-Reply-To: <alpine.LFD.2.02.1110030828220.15986@nokomis.stat.uiowa.edu>
References: <CANwu5-oZXZjThFof++sf9bE2xYt-1g60+HjhA3vogD7Qnm_m6Q@mail.gmail.com>
	<CANwu5-qjBe_3-KOH2QvufgBVnt8URRvnYz4Z9Be7m+g0KdeFVA@mail.gmail.com>
	<alpine.LFD.2.02.1110030828220.15986@nokomis.stat.uiowa.edu>
Message-ID: <4F1C1571.8090800@stats.ox.ac.uk>

This has languished for a long time, and we should make a decision 
before FF for 2.15.0.

It seems to me that in so far as there is a problem, it is that we 
serialize via XDR, and that since that was invented little-endian CPUs 
have taken over the world.  So for the only cases I can imagine this is 
really a problem (passing objects in 'parallel'/snow ... contexts) a 
better answer might be to pass without byte-reordering: go back to the 
RDB format which was exposed for save() but AFAIK never for serialize.

I would say Sparc is the only big-endian platform left (some PPC Mac 
users may disagree), so little-endian really does rule.

Brian

On 03/10/2011 14:28, luke-tierney at uiowa.edu wrote:
> It's on my list to look at but I may not get to it for a couple of
> weeks. Someone else may get there earlier.
>
> Best,
>
> luke
>
> On Mon, 3 Oct 2011, Michael Spiegel wrote:
>
>> Any thoughts? I haven't heard any feedback on this patch.
>>
>> Thanks!
>> --Michael
>>
>> On Wed, Sep 28, 2011 at 3:10 PM, Michael Spiegel
>> <michael.m.spiegel at gmail.com> wrote:
>>> Hi folks,
>>>
>>> I've attached a patch to the svn trunk that improves the performance
>>> of the serialize/unserialize interface for vector types. The current
>>> implementation: a) invokes the R_XDREncode operation for each element
>>> of the vector type, and b) uses a switch statement to determine the
>>> stream type for each element of the vector type. I've added
>>> R_XDREncodeVector/R_XDRDecodeVector functions that accept N elements
>>> at a time, and I've reorganized the implementation so that the stream
>>> type is not queried once per element.
>>>
>>> In the following microbenchmark (below), I've observed performance
>>> improvements of about x2.4.  In a real benchmark that is using the
>>> serialization interface to make MPI calls, I see about a 10%
>>> improvement in performance.
>>>
>>> Cheers,
>>> --Michael
>>>
>>> microbenchmark:
>>>
>>> input <- matrix(1:100000000, 10000, 10000)
>>> output <- serialize(input, NULL)
>>> for(i in 1:10) { print(system.time(serialize(input, NULL))) }
>>> for(i in 1:10) { print(system.time(unserialize(output))) }
>>>
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From sylvain.loiseau at univ-paris13.fr  Sun Jan 22 23:20:56 2012
From: sylvain.loiseau at univ-paris13.fr (Sylvain Loiseau)
Date: Sun, 22 Jan 2012 23:20:56 +0100
Subject: [Rd] hook for configuring checking of \example{} sections of the
	documentation during R CMD check
Message-ID: <90332261-F32C-422C-8FCA-67FBCC526ECF@univ-paris13.fr>

Dear all,

In a new package, I try to check the examples given in the \example section of the Rd files.

However, the examples cannot be run if the package is not instructed, during startup time, in the place where some data are to be found ( with system.file("exampleData", "xyz", package="rcqp").

Is there any hook available, or a place where some code might be added, so that it is executed before all the examples collected in Rd files are executed?

Best regards,
Sylvain Loiseau

-----
Sylvain Loiseau
sylvain.loiseau at univ-paris13.fr

Universit? Paris 13-Nord
Laboratoire Lexiques, Dictionnaires, Informatique
(UMR 7187 CNRS/Universit? Paris 13-Nord)
99 avenue Jean-Baptiste Cl?ment
F-93410 Villetaneuse


From yintengfei at gmail.com  Sun Jan 22 23:40:30 2012
From: yintengfei at gmail.com (Tengfei Yin)
Date: Sun, 22 Jan 2012 16:40:30 -0600
Subject: [Rd] [R] semi-transparency not supported in devel R? "alpha"
 cannot be specified in qplot()
In-Reply-To: <CANROs4e1GTH1BS_tGz7DyCuVn0w7HoHQjiv7Z2qeJLzrU8nXkg@mail.gmail.com>
References: <CAPJsq9nxN05K1mPrK-DE03AfxS5koEvQ9osRf0mpYa94wj9GMw@mail.gmail.com>
	<CANROs4e1GTH1BS_tGz7DyCuVn0w7HoHQjiv7Z2qeJLzrU8nXkg@mail.gmail.com>
Message-ID: <CAPJsq9=4UTAuA=XYGFWCZRwKhtN01jcbT56+gcQUmVF2d9w=_A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20120122/c1fe13ee/attachment.pl>

From murdoch.duncan at gmail.com  Mon Jan 23 00:24:51 2012
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 22 Jan 2012 18:24:51 -0500
Subject: [Rd] hook for configuring checking of \example{} sections of
 the documentation during R CMD check
In-Reply-To: <90332261-F32C-422C-8FCA-67FBCC526ECF@univ-paris13.fr>
References: <90332261-F32C-422C-8FCA-67FBCC526ECF@univ-paris13.fr>
Message-ID: <4F1C9AC3.90603@gmail.com>

On 12-01-22 5:20 PM, Sylvain Loiseau wrote:
> Dear all,
>
> In a new package, I try to check the examples given in the \example section of the Rd files.
>
> However, the examples cannot be run if the package is not instructed, during startup time, in the place where some data are to be found ( with system.file("exampleData", "xyz", package="rcqp").
>
> Is there any hook available, or a place where some code might be added, so that it is executed before all the examples collected in Rd files are executed?

There are no special hooks for example files.

You could do this in a package load hook, though it might be more 
trouble than it's worth.  In your load hook, save the result of that 
call in a local variable.  Then reference that variable from your examples.

However, it's probably easiest just to put the line

exampleData <- system.file("exampleData", package="rcqp")

at the start of each example that needs it.

Duncan Murdoch


From chiefmurphy at gmail.com  Mon Jan 23 16:07:01 2012
From: chiefmurphy at gmail.com (Dan Murphy)
Date: Mon, 23 Jan 2012 07:07:01 -0800
Subject: [Rd] factor S4 class is NA when as.character method exists
Message-ID: <CAHgH9_F0s+QfZfamfJszfbyt=s7gC=--eOSNFMrkdhGzTZgR-g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20120123/fe281a2c/attachment.pl>

From pdalgd at gmail.com  Mon Jan 23 17:25:21 2012
From: pdalgd at gmail.com (peter dalgaard)
Date: Mon, 23 Jan 2012 17:25:21 +0100
Subject: [Rd] factor S4 class is NA when as.character method exists
In-Reply-To: <CAHgH9_F0s+QfZfamfJszfbyt=s7gC=--eOSNFMrkdhGzTZgR-g@mail.gmail.com>
References: <CAHgH9_F0s+QfZfamfJszfbyt=s7gC=--eOSNFMrkdhGzTZgR-g@mail.gmail.com>
Message-ID: <6BB22C49-C945-4481-A41F-7E1D29249C10@gmail.com>


On Jan 23, 2012, at 16:07 , Dan Murphy wrote:

> Hello,
> 
> 'factor' returns <NA> for my S4 object when the class is given an
> "as.character" method. Here is a minimal example:
> 
>> setClass("foo", contains="numeric")
>> bar <- new("foo", 12)
>> factor(bar)
> [1] 12
> Levels: 12
>> setMethod("as.character", "foo", function(x) paste("x=", x at .Data))
> [1] "as.character"
>> as.character(bar)
> [1] "x= 12"
>> factor(bar)
> [1] <NA>
> Levels: 12
> 
> I would like to 'aggregate' by my S4 objects, but 'factor' seems to be
> getting in the way. Is there an 'as.character' implementation that works
> better for S4 classes? I searched help.search("factor S4 class") and
> help.search("factor S4 as.character") without success.

Single-stepping the factor call would have shown you that the real problem is that you don't have a unique() method for your class:

> unique(bar)
[1] 12

i.e., you are getting the default numeric method, which returns a numeric vector, so the levels become as.character(unique(bar)) which is c("12") and doesn't match any of the values of as.character(bar).

So, either provide a unique() method, or use factor(as.character(bar)).

> 
> Thank you.
> 
> Dan Murphy
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Peter Dalgaard, Professor
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From chuck at sharpsteen.net  Mon Jan 23 17:46:54 2012
From: chuck at sharpsteen.net (Sharpie)
Date: Mon, 23 Jan 2012 08:46:54 -0800 (PST)
Subject: [Rd] Ignore user interrupts
Message-ID: <1327337214864-4321252.post@n4.nabble.com>

Is there a way to suspend user interrupts for the duration of a function
call? There is a point in one of my packages where values are being written
to a Filehash database. If the user is unlucky enough to send an interrupt
while this code is active, then they have to:

  - Hunt down a lock file and dispose of it before the package will work
again.

  - Possibly trash the Filehash database and start over if the interrupt
caused R to leave the database file in a corrupted state.

Is there something analogous to the C macros
BEGIN_SUSPEND_INTERRUPTS/END_SUSPEND_INTERRUPTS that I can use at the R
level to delay interrupts until after critical code has executed?

If not, would it work to move the function call into a C function that uses
`eval` inside a block protected by BEGIN_SUSPEND_INTERRUPTS?

-Charlie

-----
Charlie Sharpsteen
Undergraduate-- Environmental Resources Engineering
Humboldt State University
--
View this message in context: http://r.789695.n4.nabble.com/Ignore-user-interrupts-tp4321252p4321252.html
Sent from the R devel mailing list archive at Nabble.com.


From chuck at sharpsteen.net  Mon Jan 23 21:00:07 2012
From: chuck at sharpsteen.net (Sharpie)
Date: Mon, 23 Jan 2012 12:00:07 -0800 (PST)
Subject: [Rd] Ignore user interrupts
In-Reply-To: <1327337214864-4321252.post@n4.nabble.com>
References: <1327337214864-4321252.post@n4.nabble.com>
Message-ID: <1327348807154-4321817.post@n4.nabble.com>


Sharpie wrote
> 
> If not, would it work to move the function call into a C function that
> uses `eval` inside a block protected by BEGIN_SUSPEND_INTERRUPTS?
> 

Just to clarify, if there is no functionality at the R level for evaluating
an expression without interrupts, would it be possible to create it by
defining a function:

evalWithoutInterrupts <- function(expr, envir = parent.frame())
{
  .Call(do_evalWithoutInterrupts, expr, envir)
}


With a C-level implemention:

SEXPR do_evalWithoutInterrupts(SEXP expr, SEXP envir)
{
  SEXP result;

  BEGIN_SUSPEND_INTERRUPTS{
    result = eval(expr, envir);
  }END_SUSPEND_INTERRUPTS;

  return result;
}


Would that be a correct way to tackle the problem?

-Charlie

-----
Charlie Sharpsteen
Undergraduate-- Environmental Resources Engineering
Humboldt State University
--
View this message in context: http://r.789695.n4.nabble.com/Ignore-user-interrupts-tp4321252p4321817.html
Sent from the R devel mailing list archive at Nabble.com.


From chiefmurphy at gmail.com  Tue Jan 24 07:31:22 2012
From: chiefmurphy at gmail.com (Dan Murphy)
Date: Mon, 23 Jan 2012 22:31:22 -0800
Subject: [Rd] factor S4 class is NA when as.character method exists
In-Reply-To: <6BB22C49-C945-4481-A41F-7E1D29249C10@gmail.com>
References: <CAHgH9_F0s+QfZfamfJszfbyt=s7gC=--eOSNFMrkdhGzTZgR-g@mail.gmail.com>
	<6BB22C49-C945-4481-A41F-7E1D29249C10@gmail.com>
Message-ID: <CAHgH9_GKcJX4Dz1-YQbttOxssK_L8qG089RfAHmnxZT0Yv5gqg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20120123/c0fab09f/attachment.pl>

From john.maindonald at anu.edu.au  Tue Jan 24 09:30:38 2012
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Tue, 24 Jan 2012 19:30:38 +1100
Subject: [Rd] Failure to get compactPDF to compact a pdf file
Message-ID: <99653988-422A-48FA-BC50-DDEB12C90F32@anu.edu.au>

I am failing to get compactPDF to make any change to a pdf file
that, a/c to the message from the CRAN upload site, can be very
substantially compacted.  Any ideas what may be wrong?

I have also tried recreating the pdf file.  I also tried
R CMD build --resave-data --compact-vignettes DAAG

The data files compact alright (but I get the 'significantly better compression'
warning message that might suggest that this is not happening), but the pdf
file appears to go into the package unmodified.

<<<<
> tools::compactPDF('/Users/johnm/packages/DAAG/inst/doc/', gs_quality = "ebook")
> dir('/Users/johnm/packages/DAAG/inst/doc/')
[1] "rockArt.pdf"
> sessionInfo()
R version 2.14.1 (2011-12-22)
Platform: x86_64-apple-darwin9.8.0/x86_64 (64-bit)

locale:
[1] C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

loaded via a namespace (and not attached):
[1] tools_2.14.1
>>>>

From the Unix command line:
jhm:doc johnm$ ls -lt /Users/johnm/packages/DAAG/inst/doc
total 1368
-rw-r--r--@ 1 johnm  staff  696762  2 Aug 12:35 rockArt.pdf

Message from the CRAN upload site:

* checking sizes of PDF files under ?inst/doc? ... NOTE
 ?gs? made some significant size reductions:
    compacted ?rockArt.pdf? from 680Kb to 58Kb
 consider running tools::compactPDF(gs_quality = "ebook") on these files

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.
http://www.maths.anu.edu.au/~johnm


From ripley at stats.ox.ac.uk  Tue Jan 24 13:22:31 2012
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 24 Jan 2012 12:22:31 +0000
Subject: [Rd] Failure to get compactPDF to compact a pdf file
In-Reply-To: <99653988-422A-48FA-BC50-DDEB12C90F32@anu.edu.au>
References: <99653988-422A-48FA-BC50-DDEB12C90F32@anu.edu.au>
Message-ID: <4F1EA287.8000506@stats.ox.ac.uk>

On 24/01/2012 08:30, John Maindonald wrote:
> I am failing to get compactPDF to make any change to a pdf file
> that, a/c to the message from the CRAN upload site, can be very
> substantially compacted.  Any ideas what may be wrong?

AFAICS you are quoting a message from R-devel, which tries to find 'gs' 
for you.  In R 2.14.1 you need to tell compactPDF where it is (assuming 
you do have it installed): see its help.

> I have also tried recreating the pdf file.  I also tried
> R CMD build --resave-data --compact-vignettes DAAG

Again, in R-devel you can do R CMD build --compact-vignettes=gs 
(assuming that is in your path or R_GSCMD is set), but not in R 2.14.1.

But I have already told you directly (and been ignored) that the problem 
is the excessive resolution of the embedded bitmap image which needs to 
be down-sampled.


> The data files compact alright (but I get the 'significantly better compression'
> warning message that might suggest that this is not happening), but the pdf
> file appears to go into the package unmodified.
>
> <<<<
>> tools::compactPDF('/Users/johnm/packages/DAAG/inst/doc/', gs_quality = "ebook")
>> dir('/Users/johnm/packages/DAAG/inst/doc/')
> [1] "rockArt.pdf"
>> sessionInfo()
> R version 2.14.1 (2011-12-22)
> Platform: x86_64-apple-darwin9.8.0/x86_64 (64-bit)
>
> locale:
> [1] C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> loaded via a namespace (and not attached):
> [1] tools_2.14.1
>>>>>
>
>> From the Unix command line:
> jhm:doc johnm$ ls -lt /Users/johnm/packages/DAAG/inst/doc
> total 1368
> -rw-r--r--@ 1 johnm  staff  696762  2 Aug 12:35 rockArt.pdf
>
> Message from the CRAN upload site:
>
> * checking sizes of PDF files under ?inst/doc? ... NOTE
>   ?gs? made some significant size reductions:
>      compacted ?rockArt.pdf? from 680Kb to 58Kb
>   consider running tools::compactPDF(gs_quality = "ebook") on these files
>
> John Maindonald             email: john.maindonald at anu.edu.au
> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
> Centre for Mathematics&  Its Applications, Room 1194,
> John Dedman Mathematical Sciences Building (Building 27)
> Australian National University, Canberra ACT 0200.
> http://www.maths.anu.edu.au/~johnm
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From Zwang at ccmckids.org  Tue Jan 24 16:53:27 2012
From: Zwang at ccmckids.org (Zhu Wang)
Date: Tue, 24 Jan 2012 10:53:27 -0500
Subject: [Rd] Rnw file generated strange symbols in pdf file
Message-ID: <4F1E8DA7020000DD00024CCA@gwmail3.harthosp.org>

Hello,
 
I found my Rnw file generated strange symbols in pdf file. For instance, on page 4 of the following file,
 
http://cran.r-project.org/web/packages/cts/vignettes/kf.pdf
 
you can see Belcher et~al on line 2, and Figure~1 on line 5. The symbol ~ should not appear in the pdf file although the symbol was in the original Rnw file (something like Figure~\ref{...}, section~\ref{...}). On page 1, the symbol ~ also appears after Keywords but in my original Rnw file I have \Keywords{continuous time autoregressive model, state space model, Kalman filter, Kalman smoothing, \proglang{R}}.
 
The symbol ~ didn't appear in the generated pdf file with the early R version before 2.14, if my memory serves me correctly. So what's wrong here and how to correct it rather than modifying my original Rnw file?
 
Thank you very much.
 
Zhu Wang

From friendly at yorku.ca  Tue Jan 24 17:42:28 2012
From: friendly at yorku.ca (Michael Friendly)
Date: Tue, 24 Jan 2012 11:42:28 -0500
Subject: [Rd] R-devel now triggers nags on notes from vignettes
Message-ID: <4F1EDF74.5020108@yorku.ca>

I recently submitted a minor update to a CRAN package that passed all 
CRAN checks
~ two weeks ago.

Now, I get the response below from the CRAN-check-daemon

R-devel reports

* checking installed files from ?inst/doc? ... NOTE
The following files are already in R: ?jss.cls?
Please remove them from your package.
The following files should probably not be installed:
?sfheaders.sty?
The following directories should probably not be installed:
?fig?

Consider the use of a .Rinstignore file: see ?Writing R Extensions?,
or move the vignette sources from ?inst/doc? to ?vignettes?.

Please fix.

I added a .Rinstignore file to my project, (at top level, same as 
DESCRIPTION) containing

inst/doc/fig/
inst/doc/jss.cls
inst/doc/sfheaders.sty

and re-submitted to CRAN, but the same nag notes return again. How to fix?

And, why has the CRAN-check-daemon suddenly gotten so picky about NOTEs,
particularly from vignettes?

-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept.
York University      Voice: 416 736-5115 x66249 Fax: 416 736-5814
4700 Keele Street    Web:http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA


From bbolker at gmail.com  Tue Jan 24 17:44:54 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 24 Jan 2012 16:44:54 +0000
Subject: [Rd] Rnw file generated strange symbols in pdf file
References: <4F1E8DA7020000DD00024CCA@gwmail3.harthosp.org>
Message-ID: <loom.20120124T173204-296@post.gmane.org>

Zhu Wang <Zwang <at> ccmckids.org> writes:

> I found my Rnw file generated strange symbols in pdf file. 
> For instance, on page 4 of the following file,
> 
> http://cran.r-project.org/web/packages/cts/vignettes/kf.pdf

> you can see Belcher et~al on line 2, and Figure~1 on line 5. The
> symbol ~ should not appear in the pdf file although the symbol was
> in the original Rnw file (something like Figure~\ref{...},
> section~\ref{...}). On page 1, the symbol ~ also appears after
> Keywords but in my original Rnw file I have \Keywords{continuous
> time autoregressive model, state space model, Kalman filter, Kalman
> smoothing, \proglang{R}}.
 
> The symbol ~ didn't appear in the generated pdf file with the early
> R version before 2.14, if my memory serves me correctly. So what's
> wrong here and how to correct it rather than modifying my original
> Rnw file?

  This has come up before, I'm not sure what the current status is,
not what gets run on CRAN.  I know that if I use texi2pdf on my
(now fairly old) 10.04 version of Ubuntu, I get the 'tilde problem'
if I use texi2pdf but not if I use pdflatex.  If I \usepackage[english]{babel}
the problem also goes away.

References:

http://comments.gmane.org/gmane.comp.lang.r.debian/848

http://bugs.debian.org/cgi-bin/bugreport.cgi?bug=534458

http://www2.it.lut.fi/wiki/doku.php/common/latex_hints  says:
If you use both natbib and babel packages, load natbib before babel to
prevent tilde showing up in citations. Loading natbib after babel and
using citep-command will make ?et al.? shown as ?et~al.?.


From wdunlap at tibco.com  Tue Jan 24 18:17:34 2012
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 24 Jan 2012 17:17:34 +0000
Subject: [Rd] factor S4 class is NA when as.character method exists
In-Reply-To: <CAHgH9_GKcJX4Dz1-YQbttOxssK_L8qG089RfAHmnxZT0Yv5gqg@mail.gmail.com>
References: <CAHgH9_F0s+QfZfamfJszfbyt=s7gC=--eOSNFMrkdhGzTZgR-g@mail.gmail.com>
	<6BB22C49-C945-4481-A41F-7E1D29249C10@gmail.com>
	<CAHgH9_GKcJX4Dz1-YQbttOxssK_L8qG089RfAHmnxZT0Yv5gqg@mail.gmail.com>
Message-ID: <E66794E69CFDE04D9A70842786030B9325F8A4@PA-MBX03.na.tibco.com>

Here is code that does make factor() work on a new
class like yours.  It uses Sv3 methods.
  > setClass("foo", contains="numeric")
  [1] "foo"
  > as.character.foo <- function(x) paste("x=",x at .Data,sep="")
  > unique.foo <- function(x, ...) structure(NextMethod("unique"), class=class(x))
  > someFoo <- new("foo", c(11, 13, 11, 13, 12))
  > str(factor(someFoo))
   Factor w/ 3 levels "x=11","x=12",..: 1 3 1 3 2

It would be nice to have a list of methods that one
needs to define for a new class in order to make it
do the "basic" things you expect.

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com 

> -----Original Message-----
> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org] On Behalf Of Dan Murphy
> Sent: Monday, January 23, 2012 10:31 PM
> To: peter dalgaard
> Cc: r-devel at r-project.org
> Subject: Re: [Rd] factor S4 class is NA when as.character method exists
> 
> Thank you for your reply, Peter. But that didn't work either. Continuing
> the example:
> 
> setGeneric("unique")
> setMethod("unique", "foo",  function(x,  incomparables = FALSE, ...){
>     y <- callNextMethod(x = getDataPart(x),  incomparables = incomparables,
> ...)
>     new("foo", y)
>     })
> 
> > unique(bar)
> An object of class "foo"
> [1] 12
> > factor(bar)
> [1] <NA>
> Levels: 12
> 
> Indeed I had tried stepping through the 'factor' call, but perhaps in an
> unsophisticated manner -- I had copied the body of 'factor' to a local
> version of the function:
> 
> myfactor <- function (x = character(), levels, labels = levels, exclude =
> NA,
>     ordered = is.ordered(x))
> {
>     if (is.null(x)) ...
> etc.
> 
> And 'myfactor' worked as desired:
> 
> > myfactor(bar)
> [1] x= 12
> Levels: x= 12
> 
> I hypothesized that there might be a deeper interaction of an S4
> 'as.character' method with base::factor, but, having exhausted my woeful
> lack of expertise, I decided to write my original email.
> 
> Thanks for your consideration.
> 
> Dan
> 
> On Mon, Jan 23, 2012 at 8:25 AM, peter dalgaard <pdalgd at gmail.com> wrote:
> 
> >
> > On Jan 23, 2012, at 16:07 , Dan Murphy wrote:
> >
> > > Hello,
> > >
> > > 'factor' returns <NA> for my S4 object when the class is given an
> > > "as.character" method. Here is a minimal example:
> > >
> > >> setClass("foo", contains="numeric")
> > >> bar <- new("foo", 12)
> > >> factor(bar)
> > > [1] 12
> > > Levels: 12
> > >> setMethod("as.character", "foo", function(x) paste("x=", x at .Data))
> > > [1] "as.character"
> > >> as.character(bar)
> > > [1] "x= 12"
> > >> factor(bar)
> > > [1] <NA>
> > > Levels: 12
> > >
> > > I would like to 'aggregate' by my S4 objects, but 'factor' seems to be
> > > getting in the way. Is there an 'as.character' implementation that works
> > > better for S4 classes? I searched help.search("factor S4 class") and
> > > help.search("factor S4 as.character") without success.
> >
> > Single-stepping the factor call would have shown you that the real problem
> > is that you don't have a unique() method for your class:
> >
> > > unique(bar)
> > [1] 12
> >
> > i.e., you are getting the default numeric method, which returns a numeric
> > vector, so the levels become as.character(unique(bar)) which is c("12") and
> > doesn't match any of the values of as.character(bar).
> >
> > So, either provide a unique() method, or use factor(as.character(bar)).
> >
> > >
> > > Thank you.
> > >
> > > Dan Murphy
> > >
> > >       [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-devel at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
> > --
> > Peter Dalgaard, Professor
> > Center for Statistics, Copenhagen Business School
> > Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> > Phone: (+45)38153501
> > Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
> >
> >
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From ripley at stats.ox.ac.uk  Tue Jan 24 18:35:30 2012
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 24 Jan 2012 17:35:30 +0000
Subject: [Rd] factor S4 class is NA when as.character method exists
In-Reply-To: <E66794E69CFDE04D9A70842786030B9325F8A4@PA-MBX03.na.tibco.com>
References: <CAHgH9_F0s+QfZfamfJszfbyt=s7gC=--eOSNFMrkdhGzTZgR-g@mail.gmail.com>
	<6BB22C49-C945-4481-A41F-7E1D29249C10@gmail.com>
	<CAHgH9_GKcJX4Dz1-YQbttOxssK_L8qG089RfAHmnxZT0Yv5gqg@mail.gmail.com>
	<E66794E69CFDE04D9A70842786030B9325F8A4@PA-MBX03.na.tibco.com>
Message-ID: <4F1EEBE2.50408@stats.ox.ac.uk>

On 24/01/2012 17:17, William Dunlap wrote:
> Here is code that does make factor() work on a new
> class like yours.  It uses Sv3 methods.

Which is necessary as unique() is an S3 generic in the base namespace, 
and creating some other function named 'unique' elsewhere (which is what 
setGeneric does) is ineffective.

>    >  setClass("foo", contains="numeric")
>    [1] "foo"
>    >  as.character.foo<- function(x) paste("x=",x at .Data,sep="")
>    >  unique.foo<- function(x, ...) structure(NextMethod("unique"), class=class(x))
>    >  someFoo<- new("foo", c(11, 13, 11, 13, 12))
>    >  str(factor(someFoo))
>     Factor w/ 3 levels "x=11","x=12",..: 1 3 1 3 2
>
> It would be nice to have a list of methods that one
> needs to define for a new class in order to make it
> do the "basic" things you expect.

It would be nice to have a list of such things ... I suspect they depend 
more heavily on the value of 'you' than the class.

> Bill Dunlap
> Spotfire, TIBCO Software
> wdunlap tibco.com
>
>> -----Original Message-----
>> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org] On Behalf Of Dan Murphy
>> Sent: Monday, January 23, 2012 10:31 PM
>> To: peter dalgaard
>> Cc: r-devel at r-project.org
>> Subject: Re: [Rd] factor S4 class is NA when as.character method exists
>>
>> Thank you for your reply, Peter. But that didn't work either. Continuing
>> the example:
>>
>> setGeneric("unique")
>> setMethod("unique", "foo",  function(x,  incomparables = FALSE, ...){
>>      y<- callNextMethod(x = getDataPart(x),  incomparables = incomparables,
>> ...)
>>      new("foo", y)
>>      })
>>
>>> unique(bar)
>> An object of class "foo"
>> [1] 12
>>> factor(bar)
>> [1]<NA>
>> Levels: 12
>>
>> Indeed I had tried stepping through the 'factor' call, but perhaps in an
>> unsophisticated manner -- I had copied the body of 'factor' to a local
>> version of the function:
>>
>> myfactor<- function (x = character(), levels, labels = levels, exclude =
>> NA,
>>      ordered = is.ordered(x))
>> {
>>      if (is.null(x)) ...
>> etc.
>>
>> And 'myfactor' worked as desired:
>>
>>> myfactor(bar)
>> [1] x= 12
>> Levels: x= 12
>>
>> I hypothesized that there might be a deeper interaction of an S4
>> 'as.character' method with base::factor, but, having exhausted my woeful
>> lack of expertise, I decided to write my original email.
>>
>> Thanks for your consideration.
>>
>> Dan
>>
>> On Mon, Jan 23, 2012 at 8:25 AM, peter dalgaard<pdalgd at gmail.com>  wrote:
>>
>>>
>>> On Jan 23, 2012, at 16:07 , Dan Murphy wrote:
>>>
>>>> Hello,
>>>>
>>>> 'factor' returns<NA>  for my S4 object when the class is given an
>>>> "as.character" method. Here is a minimal example:
>>>>
>>>>> setClass("foo", contains="numeric")
>>>>> bar<- new("foo", 12)
>>>>> factor(bar)
>>>> [1] 12
>>>> Levels: 12
>>>>> setMethod("as.character", "foo", function(x) paste("x=", x at .Data))
>>>> [1] "as.character"
>>>>> as.character(bar)
>>>> [1] "x= 12"
>>>>> factor(bar)
>>>> [1]<NA>
>>>> Levels: 12
>>>>
>>>> I would like to 'aggregate' by my S4 objects, but 'factor' seems to be
>>>> getting in the way. Is there an 'as.character' implementation that works
>>>> better for S4 classes? I searched help.search("factor S4 class") and
>>>> help.search("factor S4 as.character") without success.
>>>
>>> Single-stepping the factor call would have shown you that the real problem
>>> is that you don't have a unique() method for your class:
>>>
>>>> unique(bar)
>>> [1] 12
>>>
>>> i.e., you are getting the default numeric method, which returns a numeric
>>> vector, so the levels become as.character(unique(bar)) which is c("12") and
>>> doesn't match any of the values of as.character(bar).
>>>
>>> So, either provide a unique() method, or use factor(as.character(bar)).
>>>
>>>>
>>>> Thank you.
>>>>
>>>> Dan Murphy
>>>>
>>>>        [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>> --
>>> Peter Dalgaard, Professor
>>> Center for Statistics, Copenhagen Business School
>>> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
>>> Phone: (+45)38153501
>>> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>>>
>>>
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From therneau at mayo.edu  Tue Jan 24 20:50:15 2012
From: therneau at mayo.edu (Terry Therneau)
Date: Tue, 24 Jan 2012 13:50:15 -0600
Subject: [Rd] Sweave driver extension
Message-ID: <1327434615.8525.38.camel@nemo>

Almost all of the coxme package and an increasing amount of the survival
package are now written in noweb, i.e., .Rnw files.  It would be nice to
process these using the Sweave function + a special driver, which I can
do using a modified version of Sweave.  The primary change is to allow
the following type of construction

<<coxme>>
coxme <- function(formula, data, subset, blah blah  ){
   <<coxme-check-arguments>>
   <<coxme-build>>
   <<coxme-compute>>
   <<coxme-finish>>
}
@

where the parts referred to come later, and will themselves be made up
of other parts.  Since the point of this file is to document source
code, the order in which chunks are defined is driven by "create a
textbook" thoughts and won't match the final code order for R.  
The standard noweb driver only allows one level of recursion, and no
references to things defined further down in the file.   

  The primary change to the function simply breaks the main loop into
two parts: first read through the all the lines and create a list of
code chunks (some with names), then go through the list of chunks and
call driver routines.  There are a couple of other minor details, e.g. a
precheck for infinite recursions, but no change to what is passed to the
driver routines, nor to anything but the Sweave function itself.

Primary question: who on the core team should I be holding this
conversation with?  
Secondary: Testing level?  I have a few vignettes but not many.
    I'll need a "noweb" package anyway to contain the drivers -- should
we just duplicate the modified Sweave under another name?  
    Call the package "noweb", "Rnoweb", ...?  

And before someone asks: Roxygen is a completely different animal and
doesn't address what I need.  I have latex equations just above the code
that impliments them, an annotated graph of the call tree next to the
section parsing a formula, etc. This is stuff that doesn't fit in
comment lines. The text/code ratio is >1.  On the other hand I've
thought very little about integration of manual pages and description
files with the code, issues which Roxygen addresses.

Terry Therneau


From hb at biostat.ucsf.edu  Tue Jan 24 21:25:19 2012
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Tue, 24 Jan 2012 12:25:19 -0800
Subject: [Rd] R-devel now triggers nags on notes from vignettes
In-Reply-To: <4F1EDF74.5020108@yorku.ca>
References: <4F1EDF74.5020108@yorku.ca>
Message-ID: <CAFDcVCSEU0tG8Ea=0G29-Uc81ras9xmd9=Vk0HHsBcTvOEY8Gg@mail.gmail.com>

On Tue, Jan 24, 2012 at 8:42 AM, Michael Friendly <friendly at yorku.ca> wrote:
> I recently submitted a minor update to a CRAN package that passed all CRAN
> checks
> ~ two weeks ago.
>
> Now, I get the response below from the CRAN-check-daemon
>
> R-devel reports
>
> * checking installed files from ?inst/doc? ... NOTE
> The following files are already in R: ?jss.cls?
> Please remove them from your package.
> The following files should probably not be installed:
> ?sfheaders.sty?
> The following directories should probably not be installed:
> ?fig?
>
> Consider the use of a .Rinstignore file: see ?Writing R Extensions?,
> or move the vignette sources from ?inst/doc? to ?vignettes?.
>
> Please fix.
>
> I added a .Rinstignore file to my project, (at top level, same as
> DESCRIPTION) containing
>
> inst/doc/fig/
> inst/doc/jss.cls
> inst/doc/sfheaders.sty
>
> and re-submitted to CRAN, but the same nag notes return again. How to fix?

As a start, you can get the same NOTEs by using the latest R devel
version (I see them using 2012-01-20 r58143).

/Henrik
>
> And, why has the CRAN-check-daemon suddenly gotten so picky about NOTEs,
> particularly from vignettes?
>
> --
> Michael Friendly ? ? Email: friendly AT yorku DOT ca
> Professor, Psychology Dept.
> York University ? ? ?Voice: 416 736-5115 x66249 Fax: 416 736-5814
> 4700 Keele Street ? ?Web:http://www.datavis.ca
> Toronto, ONT ?M3J 1P3 CANADA
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From john.maindonald at anu.edu.au  Tue Jan 24 22:22:55 2012
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Wed, 25 Jan 2012 08:22:55 +1100
Subject: [Rd] Failure to get compactPDF to compact a pdf file
In-Reply-To: <4F1EA287.8000506@stats.ox.ac.uk>
References: <99653988-422A-48FA-BC50-DDEB12C90F32@anu.edu.au>
	<4F1EA287.8000506@stats.ox.ac.uk>
Message-ID: <2A170CCC-145A-43D7-8199-3D1E7B890DCB@anu.edu.au>

Quoting from the R-2.14.1 help page for compactPDF:
"
This by default makes use of 'qpdf', available from <URL:
    http://qpdf.sourceforge.net/> (including as a Windows binary) and
    included with the CRAN Mac OS X distribution of R.  If 'gs_cmd' is
    non-empty, GhostScript will used instead.
"

The defaults are:
compactPDF(paths, qpdf = Sys.getenv("R_QPDF", "qpdf"),
               gs_cmd = Sys.getenv("R_GSCMD", ""),
               gs_quality = c("printer", "ebook", "screen"),
               gs_extras = character())

> Sys.getenv("R_QPDF", "qpdf")
[1] "/Library/Frameworks/R.framework/Resources/bin/qpdf"
> Sys.getenv("R_GSCMD", "")
[1] ""
> 

Thus, as far as I can see, compactPDF is set up (on my system) to use qpdf to compress.

I take it then that the "Writing R Extensions manual [2.14.1 (2011-12-22)] is anticipating what is in R-devel:
"
The --compact-vignettes option will run tools::compactPDF over the PDF files in inst/doc (and its subdirectories) to losslessly compress them. This is not enabled by default (it can be selected by environment variable _R_BUILD_COMPACT_VIGNETTES_) and needs qpdf(http://qpdf.sourceforge.net/) to be available.
"

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.
http://www.maths.anu.edu.au/~johnm

On 24/01/2012, at 11:22 PM, Prof Brian Ripley wrote:

> On 24/01/2012 08:30, John Maindonald wrote:
>> I am failing to get compactPDF to make any change to a pdf file
>> that, a/c to the message from the CRAN upload site, can be very
>> substantially compacted.  Any ideas what may be wrong?
> 
> AFAICS you are quoting a message from R-devel, which tries to find 'gs' for you.  In R 2.14.1 you need to tell compactPDF where it is (assuming you do have it installed): see its help.
> 
>> I have also tried recreating the pdf file.  I also tried
>> R CMD build --resave-data --compact-vignettes DAAG
> 
> Again, in R-devel you can do R CMD build --compact-vignettes=gs (assuming that is in your path or R_GSCMD is set), but not in R 2.14.1.
> 
> But I have already told you directly (and been ignored) that the problem is the excessive resolution of the embedded bitmap image which needs to be down-sampled.
> 
> 
>> The data files compact alright (but I get the 'significantly better compression'
>> warning message that might suggest that this is not happening), but the pdf
>> file appears to go into the package unmodified.
>> 
>> <<<<
>>> tools::compactPDF('/Users/johnm/packages/DAAG/inst/doc/', gs_quality = "ebook")
>>> dir('/Users/johnm/packages/DAAG/inst/doc/')
>> [1] "rockArt.pdf"
>>> sessionInfo()
>> R version 2.14.1 (2011-12-22)
>> Platform: x86_64-apple-darwin9.8.0/x86_64 (64-bit)
>> 
>> locale:
>> [1] C
>> 
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>> 
>> loaded via a namespace (and not attached):
>> [1] tools_2.14.1
>>>>>> 
>> 
>>> From the Unix command line:
>> jhm:doc johnm$ ls -lt /Users/johnm/packages/DAAG/inst/doc
>> total 1368
>> -rw-r--r--@ 1 johnm  staff  696762  2 Aug 12:35 rockArt.pdf
>> 
>> Message from the CRAN upload site:
>> 
>> * checking sizes of PDF files under ?inst/doc? ... NOTE
>> ?gs? made some significant size reductions:
>>    compacted ?rockArt.pdf? from 680Kb to 58Kb
>> consider running tools::compactPDF(gs_quality = "ebook") on these files
>> 
>> John Maindonald             email: john.maindonald at anu.edu.au
>> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
>> Centre for Mathematics&  Its Applications, Room 1194,
>> John Dedman Mathematical Sciences Building (Building 27)
>> Australian National University, Canberra ACT 0200.
>> http://www.maths.anu.edu.au/~johnm
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From jmc at r-project.org  Wed Jan 25 00:05:20 2012
From: jmc at r-project.org (John Chambers)
Date: Tue, 24 Jan 2012 15:05:20 -0800
Subject: [Rd] factor S4 class is NA when as.character method exists
In-Reply-To: <4F1EEBE2.50408@stats.ox.ac.uk>
References: <CAHgH9_F0s+QfZfamfJszfbyt=s7gC=--eOSNFMrkdhGzTZgR-g@mail.gmail.com>
	<6BB22C49-C945-4481-A41F-7E1D29249C10@gmail.com>
	<CAHgH9_GKcJX4Dz1-YQbttOxssK_L8qG089RfAHmnxZT0Yv5gqg@mail.gmail.com>
	<E66794E69CFDE04D9A70842786030B9325F8A4@PA-MBX03.na.tibco.com>
	<4F1EEBE2.50408@stats.ox.ac.uk>
Message-ID: <4F1F3930.3050106@r-project.org>



On 1/24/12 9:35 AM, Prof Brian Ripley wrote:
> On 24/01/2012 17:17, William Dunlap wrote:
>> Here is code that does make factor() work on a new
>> class like yours.  It uses Sv3 methods.
>
> Which is necessary as unique() is an S3 generic in the base namespace,
> and creating some other function named 'unique' elsewhere (which is
> what setGeneric does) is ineffective.

Creating a simple generic version of unique() (not just "some other 
function...") causes S4 method selection to work for code that has 
access to that function, but calls from within the base namespace will 
still see the S3 version.

The safest technique is to ensure that both S4 and S3 dispatch see the 
same method.
------------------------
setClass("myFactor", contains = "factor")

setGeneric("unique")

unique.myFactor <- function (x, incomparables = FALSE, ...)
     unique(as.character(x))

setMethod("unique", "myFactor", unique.myFactor)
------------------------

With this in PkgA and suitable exports from the namespace:

> library(PkgA)
> methods("unique")
[1] unique.POSIXlt         unique.array           unique.data.frame
[4] unique.default         unique.matrix          unique.myFactor
[7] unique.numeric_version
> showMethods("unique")
Function: unique (package base)
x="ANY"
x="myFactor"

Someday there may be a more natural approach.

John

>
>> >  setClass("foo", contains="numeric")
>>    [1] "foo"
>> >  as.character.foo<- function(x) paste("x=",x at .Data,sep="")
>> >  unique.foo<- function(x, ...) structure(NextMethod("unique"),
>> class=class(x))
>> >  someFoo<- new("foo", c(11, 13, 11, 13, 12))
>> >  str(factor(someFoo))
>>     Factor w/ 3 levels "x=11","x=12",..: 1 3 1 3 2
>>
>> It would be nice to have a list of methods that one
>> needs to define for a new class in order to make it
>> do the "basic" things you expect.
>
> It would be nice to have a list of such things ... I suspect they
> depend more heavily on the value of 'you' than the class.
>
>> Bill Dunlap
>> Spotfire, TIBCO Software
>> wdunlap tibco.com
>>
>>> -----Original Message-----
>>> From: r-devel-bounces at r-project.org
>>> [mailto:r-devel-bounces at r-project.org] On Behalf Of Dan Murphy
>>> Sent: Monday, January 23, 2012 10:31 PM
>>> To: peter dalgaard
>>> Cc: r-devel at r-project.org
>>> Subject: Re: [Rd] factor S4 class is NA when as.character method exists
>>>
>>> Thank you for your reply, Peter. But that didn't work either.
>>> Continuing
>>> the example:
>>>
>>> setGeneric("unique")
>>> setMethod("unique", "foo",  function(x,  incomparables = FALSE, ...){
>>>      y<- callNextMethod(x = getDataPart(x),  incomparables =
>>> incomparables,
>>> ...)
>>>      new("foo", y)
>>>      })
>>>
>>>> unique(bar)
>>> An object of class "foo"
>>> [1] 12
>>>> factor(bar)
>>> [1]<NA>
>>> Levels: 12
>>>
>>> Indeed I had tried stepping through the 'factor' call, but perhaps
>>> in an
>>> unsophisticated manner -- I had copied the body of 'factor' to a local
>>> version of the function:
>>>
>>> myfactor<- function (x = character(), levels, labels = levels,
>>> exclude =
>>> NA,
>>>      ordered = is.ordered(x))
>>> {
>>>      if (is.null(x)) ...
>>> etc.
>>>
>>> And 'myfactor' worked as desired:
>>>
>>>> myfactor(bar)
>>> [1] x= 12
>>> Levels: x= 12
>>>
>>> I hypothesized that there might be a deeper interaction of an S4
>>> 'as.character' method with base::factor, but, having exhausted my
>>> woeful
>>> lack of expertise, I decided to write my original email.
>>>
>>> Thanks for your consideration.
>>>
>>> Dan
>>>
>>> On Mon, Jan 23, 2012 at 8:25 AM, peter dalgaard<pdalgd at gmail.com>
>>> wrote:
>>>
>>>>
>>>> On Jan 23, 2012, at 16:07 , Dan Murphy wrote:
>>>>
>>>>> Hello,
>>>>>
>>>>> 'factor' returns<NA>  for my S4 object when the class is given an
>>>>> "as.character" method. Here is a minimal example:
>>>>>
>>>>>> setClass("foo", contains="numeric")
>>>>>> bar<- new("foo", 12)
>>>>>> factor(bar)
>>>>> [1] 12
>>>>> Levels: 12
>>>>>> setMethod("as.character", "foo", function(x) paste("x=", x at .Data))
>>>>> [1] "as.character"
>>>>>> as.character(bar)
>>>>> [1] "x= 12"
>>>>>> factor(bar)
>>>>> [1]<NA>
>>>>> Levels: 12
>>>>>
>>>>> I would like to 'aggregate' by my S4 objects, but 'factor' seems
>>>>> to be
>>>>> getting in the way. Is there an 'as.character' implementation that
>>>>> works
>>>>> better for S4 classes? I searched help.search("factor S4 class") and
>>>>> help.search("factor S4 as.character") without success.
>>>>
>>>> Single-stepping the factor call would have shown you that the real
>>>> problem
>>>> is that you don't have a unique() method for your class:
>>>>
>>>>> unique(bar)
>>>> [1] 12
>>>>
>>>> i.e., you are getting the default numeric method, which returns a
>>>> numeric
>>>> vector, so the levels become as.character(unique(bar)) which is
>>>> c("12") and
>>>> doesn't match any of the values of as.character(bar).
>>>>
>>>> So, either provide a unique() method, or use
>>>> factor(as.character(bar)).
>>>>
>>>>>
>>>>> Thank you.
>>>>>
>>>>> Dan Murphy
>>>>>
>>>>>        [[alternative HTML version deleted]]
>>>>>
>>>>> ______________________________________________
>>>>> R-devel at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>
>>>> --
>>>> Peter Dalgaard, Professor
>>>> Center for Statistics, Copenhagen Business School
>>>> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
>>>> Phone: (+45)38153501
>>>> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>>>>
>>>>
>>>
>>>     [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From xie at yihui.name  Wed Jan 25 05:24:41 2012
From: xie at yihui.name (Yihui Xie)
Date: Tue, 24 Jan 2012 22:24:41 -0600
Subject: [Rd] Sweave driver extension
In-Reply-To: <1327434615.8525.38.camel@nemo>
References: <1327434615.8525.38.camel@nemo>
Message-ID: <CANROs4f+ObUuxTN5hvdbWhZbuTwL_Gdq1GQCXKnM2taWDrzQ7Q@mail.gmail.com>

Maybe this is a my personal taste: I do not like pseudo R code in the
form <<coxme-build>> inside a chunk, and I'm curious about why you do
not use real R functions to do the job.

coxme <- function(formula, data, subset, blah blah  ){
  coxme_check_arguments(...)
  coxme_build(...)
  coxme_compute(...)
  coxme_finish(...)
}

You can define these coxme_xxx functions later in the parent
environment. It is also easy for one function to call another, so the
recursion is natural. Compared to text-processing tricks, I prefer
well-defined functions.

Your idea of using a named list to store R code is what I used in the
knitr package (http://yihui.github.com/knitr/demo/reference/), e.g.

% empty here
<<chunk1, echo=TRUE>>=
@

% real code is defined here
<<chunk1, echo=FALSE>>=
rnorm(10)
@

The second chunk appears later, but when you weave the document, the
code rnorm(10) will also go to the first chunk since the label
'chunk1' will index the code from the second chunk.

Regards,
Yihui
--
Yihui Xie <xieyihui at gmail.com>
Phone: 515-294-2465 Web: http://yihui.name
Department of Statistics, Iowa State University
2215 Snedecor Hall, Ames, IA



On Tue, Jan 24, 2012 at 1:50 PM, Terry Therneau <therneau at mayo.edu> wrote:
> Almost all of the coxme package and an increasing amount of the survival
> package are now written in noweb, i.e., .Rnw files. ?It would be nice to
> process these using the Sweave function + a special driver, which I can
> do using a modified version of Sweave. ?The primary change is to allow
> the following type of construction
>
> <<coxme>>
> coxme <- function(formula, data, subset, blah blah ?){
> ? <<coxme-check-arguments>>
> ? <<coxme-build>>
> ? <<coxme-compute>>
> ? <<coxme-finish>>
> }
> @
>
> where the parts referred to come later, and will themselves be made up
> of other parts. ?Since the point of this file is to document source
> code, the order in which chunks are defined is driven by "create a
> textbook" thoughts and won't match the final code order for R.
> The standard noweb driver only allows one level of recursion, and no
> references to things defined further down in the file.
>
> ?The primary change to the function simply breaks the main loop into
> two parts: first read through the all the lines and create a list of
> code chunks (some with names), then go through the list of chunks and
> call driver routines. ?There are a couple of other minor details, e.g. a
> precheck for infinite recursions, but no change to what is passed to the
> driver routines, nor to anything but the Sweave function itself.
>
> Primary question: who on the core team should I be holding this
> conversation with?
> Secondary: Testing level? ?I have a few vignettes but not many.
> ? ?I'll need a "noweb" package anyway to contain the drivers -- should
> we just duplicate the modified Sweave under another name?
> ? ?Call the package "noweb", "Rnoweb", ...?
>
> And before someone asks: Roxygen is a completely different animal and
> doesn't address what I need. ?I have latex equations just above the code
> that impliments them, an annotated graph of the call tree next to the
> section parsing a formula, etc. This is stuff that doesn't fit in
> comment lines. The text/code ratio is >1. ?On the other hand I've
> thought very little about integration of manual pages and description
> files with the code, issues which Roxygen addresses.
>
> Terry Therneau
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From pauljohn32 at gmail.com  Wed Jan 25 05:40:48 2012
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Tue, 24 Jan 2012 22:40:48 -0600
Subject: [Rd] Last Call: Who says this is not a bug in delete.response()?
Message-ID: <CAErODj8i-ba4KZ8kNtLO7-KWy4tEjG9o0yR2Pz1F+c_T9=5O4A@mail.gmail.com>

On January 5, I posted here concerning this issue
(https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=14767), and I
have not heard any answers from people who think this is not a bug,
or a simple accident in the delete.response function.

The output from delete.response on a terms object alters the formula
by removing the dependent variable. It removes the response from the
"variables" attribute and it changes the response attribute from 1 to
0.  The response is removed from "predvars"

But it leaves the name of the dependent variable first in the in
"dataClasses" attribute.  I believe delete.response should be fixed, and if
I'm wrong, I wish one of you would tell me.  Otherwise, I will ask Prof.
Ripley to re-open the bug report.

This is an important API question, since functions that use regression
models (in my opinion) ought to be able to count on delete.response
to leave behind a dataClasses attribute that no longer includes the response.

If we could count on that, then, some methods that work with fitted regressions
could work more easily. For example, the work in termplot
with variables "carrier" and "carrier.terms" would be unnecessary,
since the column names of
"dataClasses" would be, exactly, the carrier.name vector and the data
type information
of those variables would eliminate a lot of fancy footwork one has to
do in order
to calculate predicted values.

-- 
Paul E. Johnson
Professor, Political Science
1541 Lilac Lane, Room 504
University of Kansas


From renaud at mancala.cbio.uct.ac.za  Wed Jan 25 08:32:50 2012
From: renaud at mancala.cbio.uct.ac.za (Renaud Gaujoux)
Date: Wed, 25 Jan 2012 09:32:50 +0200
Subject: [Rd] Default subset and concatenation operators for namedList
Message-ID: <4F1FB022.3090809@cbio.uct.ac.za>

Hi,

in R version 2.14.1 (2011-12-22), is it wanted that the class namedList 
does not overloads the '[' and 'c' operators:

showMethods('c', class='namedList')
showMethods('[', class='namedList')

This means that if one creates a class that inherits from namedList, one 
has to define these operators so that they do not drop the S4 class 
(code below). I agree that one would probably have to define custom 
operators to correctly handle other possible extra slots when subsetting 
and concatenatiing. But it seems that namedList could at least deal with 
the slot `names` and not convert the object to a standard list, which is 
troublesome.

Is there a reason why these operators are not pre-defined in namedList?
Thank you.

Renaud

##########################
setClass('A', contains='namedList')
a <- new('A', list(a=1,b=2,c=3))
str(a)

# subset converts to standard list
str(a[1:2])
str(a[2:3])

# concatenation converts to standard list
str(c(a, list(d=4, e=5)))


-- 
Renaud Gaujoux
Computational Biology - University of Cape Town
South Africa


From ligges at statistik.tu-dortmund.de  Wed Jan 25 11:19:49 2012
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Wed, 25 Jan 2012 11:19:49 +0100
Subject: [Rd] Failure to get compactPDF to compact a pdf file
In-Reply-To: <2A170CCC-145A-43D7-8199-3D1E7B890DCB@anu.edu.au>
References: <99653988-422A-48FA-BC50-DDEB12C90F32@anu.edu.au>
	<4F1EA287.8000506@stats.ox.ac.uk>
	<2A170CCC-145A-43D7-8199-3D1E7B890DCB@anu.edu.au>
Message-ID: <4F1FD745.9090203@statistik.tu-dortmund.de>



On 24.01.2012 22:22, John Maindonald wrote:
> Quoting from the R-2.14.1 help page for compactPDF:
> "
> This by default makes use of 'qpdf', available from<URL:
>      http://qpdf.sourceforge.net/>  (including as a Windows binary) and
>      included with the CRAN Mac OS X distribution of R.  If 'gs_cmd' is
>      non-empty, GhostScript will used instead.
> "
>
> The defaults are:
> compactPDF(paths, qpdf = Sys.getenv("R_QPDF", "qpdf"),
>                 gs_cmd = Sys.getenv("R_GSCMD", ""),
>                 gs_quality = c("printer", "ebook", "screen"),
>                 gs_extras = character())
>
>> Sys.getenv("R_QPDF", "qpdf")
> [1] "/Library/Frameworks/R.framework/Resources/bin/qpdf"
>> Sys.getenv("R_GSCMD", "")
> [1] ""
>>
>
> Thus, as far as I can see, compactPDF is set up (on my system) to use qpdf to compress.
>
> I take it then that the "Writing R Extensions manual [2.14.1 (2011-12-22)] is anticipating what is in R-devel:
> "
> The --compact-vignettes option will run tools::compactPDF over the PDF files in inst/doc (and its subdirectories) to losslessly compress them. This is not enabled by default (it can be selected by environment variable _R_BUILD_COMPACT_VIGNETTES_) and needs qpdf(http://qpdf.sourceforge.net/) to be available.
> "

No entirely: it was not anticipating that "--compact-vignettes=ps" is 
possible in R-devel.

Best,
Uwe





> John Maindonald             email: john.maindonald at anu.edu.au
> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
> Centre for Mathematics&  Its Applications, Room 1194,
> John Dedman Mathematical Sciences Building (Building 27)
> Australian National University, Canberra ACT 0200.
> http://www.maths.anu.edu.au/~johnm
>
> On 24/01/2012, at 11:22 PM, Prof Brian Ripley wrote:
>
>> On 24/01/2012 08:30, John Maindonald wrote:
>>> I am failing to get compactPDF to make any change to a pdf file
>>> that, a/c to the message from the CRAN upload site, can be very
>>> substantially compacted.  Any ideas what may be wrong?
>>
>> AFAICS you are quoting a message from R-devel, which tries to find 'gs' for you.  In R 2.14.1 you need to tell compactPDF where it is (assuming you do have it installed): see its help.
>>
>>> I have also tried recreating the pdf file.  I also tried
>>> R CMD build --resave-data --compact-vignettes DAAG
>>
>> Again, in R-devel you can do R CMD build --compact-vignettes=gs (assuming that is in your path or R_GSCMD is set), but not in R 2.14.1.
>>
>> But I have already told you directly (and been ignored) that the problem is the excessive resolution of the embedded bitmap image which needs to be down-sampled.
>>
>>
>>> The data files compact alright (but I get the 'significantly better compression'
>>> warning message that might suggest that this is not happening), but the pdf
>>> file appears to go into the package unmodified.
>>>
>>> <<<<
>>>> tools::compactPDF('/Users/johnm/packages/DAAG/inst/doc/', gs_quality = "ebook")
>>>> dir('/Users/johnm/packages/DAAG/inst/doc/')
>>> [1] "rockArt.pdf"
>>>> sessionInfo()
>>> R version 2.14.1 (2011-12-22)
>>> Platform: x86_64-apple-darwin9.8.0/x86_64 (64-bit)
>>>
>>> locale:
>>> [1] C
>>>
>>> attached base packages:
>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>
>>> loaded via a namespace (and not attached):
>>> [1] tools_2.14.1
>>>>>>>
>>>
>>>>  From the Unix command line:
>>> jhm:doc johnm$ ls -lt /Users/johnm/packages/DAAG/inst/doc
>>> total 1368
>>> -rw-r--r--@ 1 johnm  staff  696762  2 Aug 12:35 rockArt.pdf
>>>
>>> Message from the CRAN upload site:
>>>
>>> * checking sizes of PDF files under ?inst/doc? ... NOTE
>>> ?gs? made some significant size reductions:
>>>     compacted ?rockArt.pdf? from 680Kb to 58Kb
>>> consider running tools::compactPDF(gs_quality = "ebook") on these files
>>>
>>> John Maindonald             email: john.maindonald at anu.edu.au
>>> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
>>> Centre for Mathematics&   Its Applications, Room 1194,
>>> John Dedman Mathematical Sciences Building (Building 27)
>>> Australian National University, Canberra ACT 0200.
>>> http://www.maths.anu.edu.au/~johnm
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>> --
>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>> University of Oxford,             Tel:  +44 1865 272861 (self)
>> 1 South Parks Road,                     +44 1865 272866 (PA)
>> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From chiefmurphy at gmail.com  Wed Jan 25 16:22:04 2012
From: chiefmurphy at gmail.com (Dan Murphy)
Date: Wed, 25 Jan 2012 07:22:04 -0800
Subject: [Rd] factor S4 class is NA when as.character method exists
In-Reply-To: <4F1EEBE2.50408@stats.ox.ac.uk>
References: <CAHgH9_F0s+QfZfamfJszfbyt=s7gC=--eOSNFMrkdhGzTZgR-g@mail.gmail.com>
	<6BB22C49-C945-4481-A41F-7E1D29249C10@gmail.com>
	<CAHgH9_GKcJX4Dz1-YQbttOxssK_L8qG089RfAHmnxZT0Yv5gqg@mail.gmail.com>
	<E66794E69CFDE04D9A70842786030B9325F8A4@PA-MBX03.na.tibco.com>
	<4F1EEBE2.50408@stats.ox.ac.uk>
Message-ID: <CAHgH9_HSTMB6Uuw5OFROgBm0rSq2_Vc16tOhDM4ucMn98ryHXA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20120125/870278a5/attachment.pl>

From ligges at statistik.tu-dortmund.de  Wed Jan 25 16:51:28 2012
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Wed, 25 Jan 2012 16:51:28 +0100
Subject: [Rd] [R] x11() graphic device, displaying raster
In-Reply-To: <20120125154425.301780@gmx.net>
References: <20120125114544.91270@gmx.net>
	<4F1FEED9.5040201@statistik.tu-dortmund.de>
	<20120125124240.124370@gmx.net>
	<4F200BEF.6010600@statistik.tu-dortmund.de>
	<20120125144746.153680@gmx.net>
	<4F2016ED.3020906@statistik.tu-dortmund.de>
	<20120125154425.301780@gmx.net>
Message-ID: <4F202500.7060901@statistik.tu-dortmund.de>



On 25.01.2012 16:44, Johannes Radinger wrote:
>>>>>>> Hello,
>>>>>>>
>>>>>>> I am wondering about the X11() graphic device on Windows.
>>>>>>> I try to plot a raster image but nothing gets displayed. I
>>>>>>> found some pages where it is mentioned that x11() not
>>>>>>> always supports raster rendering.
>>>>>>> Is there any add on for x11, any update or any R-package
>>>>>>> which solves that displaying problem in Windows?
>>>>>>>
>>>>>>> What I try to test it is an example from the
>>>>>>> package {raster}:
>>>>>>>
>>>>>>> library(raster)
>>>>>>> DEU_alt<- getData("alt", country="DEU", mask=TRUE)
>>>>>>> x11()
>>>>>>> plot(DEU_alt,axes=TRUE)
>>>>>>>
>>>>>>> best regards,
>>>>>>>
>>>>>>> /johannes
>>>>>>
>>>>>> Try an R version that is recent - it works for me.
>>>>>>
>>>>>> Uwe Ligges
>>>>>
>>>>> I first tried it with R 2.13.2 and raster version 1.9-64
>>>> (16-January-2012).
>>>>> Now I also installed the most recent version R 2.14.1 (Platform:
>>>> i386-pc-mingw32/i386 (32-bit)) and raster version 1.9-64
>> (16-January-2012).
>>>>>
>>>>> But in both cases no success. X11() opens and draws the axis and the
>>>>> border for the scale but no raster...
>>>>
>>>> I do not really understand why you are using x11(). The Windows device
>>>> is called windows() and you actually do not need to open it, since plot
>>>> opens it anyway. Or are you under cygwin (which is not really Windows)?
>>>> If not: Which version of Windows is this?
>>>
>>> Of course I do not need to open a graphic device (as you said it is open
>> when calling plot). I just wanted to make it reproducable as e.g. Mac OS X
>> opens Quartz as a standard device when calling plot on my Mac machine.
>>>
>>> So far as I understand the help are "all the devices (X11(), x11() and
>> windows() implemented as variants of the same device". Thus it makes no
>> difference if I call x11() or windows() or if 'plot' opens the device
>> automatically. In all cases there is no raster displayed.
>>>
>>> Just some additional information from the 'grDevices' package:
>>>> library(grDevices)
>>>> dev.capabilities()
>>> $semiTransparency
>>> [1] TRUE
>>>
>>> $transparentBackground
>>> [1] "fully"
>>>
>>> $rasterImage
>>> [1] "yes"
>>>
>>> $capture
>>> [1] TRUE
>>>
>>> $locator
>>> [1] TRUE
>>>
>>> $events
>>> [1] "MouseDown" "MouseMove" "MouseUp"   "Keybd"
>>>
>>> I am running R via the standard RGUI (so no Eclipse, Rtinn etc.). The
>> machine I am working on is Windows 2008 Server Enterprise (Version 6.0) which
>> I am remotely accessing from a ThinClient with WindowsXP-embedded.
>>> This is the standard configuration of our institution. Maybe that
>> configuration with ThinClients is a reason? But what should I ask our admin? What
>> should he check etc?
>>
>> Yes! the remotesoftware is probably unable to send the rasterimage!
>>
>> See ?image:
>>
>> "Problems with the rendering of raster images have been reported using
>> ?windows()? devices under Remote Desktop."
>>
>
>
> I shifted this corresponce over to the more suitable r-devel-list.
>
> @Uwe Ligges: Thank you for that usefull but very disappointing message. So it seems that these are know problems caused by the RemoteDesktop Setup.
>
> I just wanted to know if the source of the problem is caused by the R-code or the RemoteDesktop Software. If it is caused by the RemoteDesktop (as you stated)..are there any settings which need to be set by our IT-admin? Or is there anything I/we can do to solve that problem?

Since it is correctly displayed locally, we can assume this is a problem 
of the RDP connection. We do not know of a setting that enables the 
feature via RemoteDesktop, but if you know any, please let us know and 
we will include this in the documentation as a hint for others.

Best,
Uwe Ligges


>
> Best regards,
>
> Johannes
>
>


From JRadinger at gmx.at  Wed Jan 25 16:44:25 2012
From: JRadinger at gmx.at (Johannes Radinger)
Date: Wed, 25 Jan 2012 16:44:25 +0100
Subject: [Rd] [R] x11() graphic device, displaying raster
In-Reply-To: <4F2016ED.3020906@statistik.tu-dortmund.de>
References: <20120125114544.91270@gmx.net>
	<4F1FEED9.5040201@statistik.tu-dortmund.de>
	<20120125124240.124370@gmx.net>
	<4F200BEF.6010600@statistik.tu-dortmund.de>
	<20120125144746.153680@gmx.net>
	<4F2016ED.3020906@statistik.tu-dortmund.de>
Message-ID: <20120125154425.301780@gmx.net>

> >>>>> Hello,
> >>>>>
> >>>>> I am wondering about the X11() graphic device on Windows.
> >>>>> I try to plot a raster image but nothing gets displayed. I
> >>>>> found some pages where it is mentioned that x11() not
> >>>>> always supports raster rendering.
> >>>>> Is there any add on for x11, any update or any R-package
> >>>>> which solves that displaying problem in Windows?
> >>>>>
> >>>>> What I try to test it is an example from the
> >>>>> package {raster}:
> >>>>>
> >>>>> library(raster)
> >>>>> DEU_alt<- getData("alt", country="DEU", mask=TRUE)
> >>>>> x11()
> >>>>> plot(DEU_alt,axes=TRUE)
> >>>>>
> >>>>> best regards,
> >>>>>
> >>>>> /johannes
> >>>>
> >>>> Try an R version that is recent - it works for me.
> >>>>
> >>>> Uwe Ligges
> >>>
> >>> I first tried it with R 2.13.2 and raster version 1.9-64
> >> (16-January-2012).
> >>> Now I also installed the most recent version R 2.14.1 (Platform:
> >> i386-pc-mingw32/i386 (32-bit)) and raster version 1.9-64
> (16-January-2012).
> >>>
> >>> But in both cases no success. X11() opens and draws the axis and the
> >>> border for the scale but no raster...
> >>
> >> I do not really understand why you are using x11(). The Windows device
> >> is called windows() and you actually do not need to open it, since plot
> >> opens it anyway. Or are you under cygwin (which is not really Windows)?
> >> If not: Which version of Windows is this?
> >
> > Of course I do not need to open a graphic device (as you said it is open
> when calling plot). I just wanted to make it reproducable as e.g. Mac OS X
> opens Quartz as a standard device when calling plot on my Mac machine.
> >
> > So far as I understand the help are "all the devices (X11(), x11() and
> windows() implemented as variants of the same device". Thus it makes no
> difference if I call x11() or windows() or if 'plot' opens the device
> automatically. In all cases there is no raster displayed.
> >
> > Just some additional information from the 'grDevices' package:
> >> library(grDevices)
> >> dev.capabilities()
> > $semiTransparency
> > [1] TRUE
> >
> > $transparentBackground
> > [1] "fully"
> >
> > $rasterImage
> > [1] "yes"
> >
> > $capture
> > [1] TRUE
> >
> > $locator
> > [1] TRUE
> >
> > $events
> > [1] "MouseDown" "MouseMove" "MouseUp"   "Keybd"
> >
> > I am running R via the standard RGUI (so no Eclipse, Rtinn etc.). The
> machine I am working on is Windows 2008 Server Enterprise (Version 6.0) which
> I am remotely accessing from a ThinClient with WindowsXP-embedded.
> > This is the standard configuration of our institution. Maybe that
> configuration with ThinClients is a reason? But what should I ask our admin? What
> should he check etc?
> 
> Yes! the remotesoftware is probably unable to send the rasterimage!
> 
> See ?image:
> 
> "Problems with the rendering of raster images have been reported using 
> ?windows()? devices under Remote Desktop."
> 


I shifted this corresponce over to the more suitable r-devel-list.

@Uwe Ligges: Thank you for that usefull but very disappointing message. So it seems that these are know problems caused by the RemoteDesktop Setup.

I just wanted to know if the source of the problem is caused by the R-code or the RemoteDesktop Software. If it is caused by the RemoteDesktop (as you stated)..are there any settings which need to be set by our IT-admin? Or is there anything I/we can do to solve that problem?

Best regards,

Johannes


-- 
"Feel free" - 10 GB Mailbox, 100 FreeSMS/Monat ...


From melikamp at melikamp.com  Wed Jan 25 18:33:22 2012
From: melikamp at melikamp.com (Ivan Zaigralin)
Date: Wed, 25 Jan 2012 12:33:22 -0500
Subject: [Rd] Non-default build options
Message-ID: <4F203CE2.9070607@melikamp.com>

Hi! I am a current maintainer of the R slackbuild script (for Slackware
GNU/Linux distribution). I received requests from users to build R with
--enable-R-shlib and --enable-BLAS-shlib, so now I am trying to decide
whether to do so by default.

Is there a downside to building R with either option?

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 900 bytes
Desc: OpenPGP digital signature
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20120125/5c4f7f6c/attachment.bin>

From edd at debian.org  Wed Jan 25 22:29:49 2012
From: edd at debian.org (Dirk Eddelbuettel)
Date: Wed, 25 Jan 2012 15:29:49 -0600
Subject: [Rd] Non-default build options
In-Reply-To: <4F203CE2.9070607@melikamp.com>
References: <4F203CE2.9070607@melikamp.com>
Message-ID: <20256.29773.715185.829638@max.nulle.part>


On 25 January 2012 at 12:33, Ivan Zaigralin wrote:
| Hi! I am a current maintainer of the R slackbuild script (for Slackware
| GNU/Linux distribution). I received requests from users to build R with
| --enable-R-shlib and --enable-BLAS-shlib, so now I am trying to decide
| whether to do so by default.
| 
| Is there a downside to building R with either option?

To some, building as a shared library is a bad choice because a few percent
of peak performance may be left behind.  That's the static vs dynamic linking
debate of yore.  [ And whether this applies to an interpreted language which
is not going to be the fastest horse in any race is best left for another
debate... ]

To others, it gives you a large amount of flexibility and allows a few good
things: 

   a) having R as a shared library permits easier linking against R (which
      has after all a pretty stable APU) as well as embedding into other
      applications; examples are rApache, rkward, littler (ie "r"), RInside,
      and probably a few I am forgetting now

   b) having BLAS as a defined interface is wonderful for swapping default
      (unaccelerated) BLAS for accelerated BLAS like Atlas, Goto, OpenBLAS,
      MKL, ... Several of these BLAS have in fact been available for either
      Debian or Ubuntu in some form (sometimes involving a helper script as
      eg Goto could never be part of an FLOSS distro).

I have been somewhat involved with the Debian builds of R since the late
1990s and we enthusiastically support both options.  We have had a drop-in
replacement of Atlas (to accelerate linear algebra) for probably a decade.
Derivative distro like Ubuntu, Mint, Arch, ... don't seem to mind, and
neither do the users.

In fact, apart from the repated calls by one vocal R Core member (who, to the
best of my knowledge, uses neither Debian nor a derivative), nobody ever
asked for a change in this policy...

So my two cents would be to go for it as your users suggest.

Cheers, Dirk

| 
| xapplication/pgp-signature [Click mouse-2 to save to a file]
| 
| ----------------------------------------------------------------------
| ______________________________________________
| R-devel at r-project.org mailing list
| https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
"Outside of a dog, a book is a man's best friend. Inside of a dog, it is too
dark to read." -- Groucho Marx


From chuck at sharpsteen.net  Thu Jan 26 07:07:30 2012
From: chuck at sharpsteen.net (Sharpie)
Date: Wed, 25 Jan 2012 22:07:30 -0800 (PST)
Subject: [Rd] Non-default build options
In-Reply-To: <20256.29773.715185.829638@max.nulle.part>
References: <4F203CE2.9070607@melikamp.com>
	<20256.29773.715185.829638@max.nulle.part>
Message-ID: <1327558050311-4329615.post@n4.nabble.com>


Dirk Eddelbuettel wrote
> 
>    b) having BLAS as a defined interface is wonderful for swapping default
>       (unaccelerated) BLAS for accelerated BLAS like Atlas, Goto,
> OpenBLAS,
>       MKL, ... Several of these BLAS have in fact been available for
> either
>       Debian or Ubuntu in some form (sometimes involving a helper script
> as
>       eg Goto could never be part of an FLOSS distro).
> 

Just an aside: Goto BLAS is now available under the BSD license, so it
should be perfectly acceptable to include in a FLOSS distribution. However,
development has ceased so Goto will probably loose it's edge as new CPU
families are shipped.

-Charlie

-----
Charlie Sharpsteen
Undergraduate-- Environmental Resources Engineering
Humboldt State University
--
View this message in context: http://r.789695.n4.nabble.com/Non-default-build-options-tp4328512p4329615.html
Sent from the R devel mailing list archive at Nabble.com.


From murdoch.duncan at gmail.com  Thu Jan 26 15:23:12 2012
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 26 Jan 2012 09:23:12 -0500
Subject: [Rd] [R] x11() graphic device, displaying raster
In-Reply-To: <4F202500.7060901@statistik.tu-dortmund.de>
References: <20120125114544.91270@gmx.net>
	<4F1FEED9.5040201@statistik.tu-dortmund.de>
	<20120125124240.124370@gmx.net>
	<4F200BEF.6010600@statistik.tu-dortmund.de>
	<20120125144746.153680@gmx.net>
	<4F2016ED.3020906@statistik.tu-dortmund.de>
	<20120125154425.301780@gmx.net>
	<4F202500.7060901@statistik.tu-dortmund.de>
Message-ID: <4F2161D0.8010306@gmail.com>

On 12-01-25 10:51 AM, Uwe Ligges wrote:
>
>
> On 25.01.2012 16:44, Johannes Radinger wrote:
>>>>>>>> Hello,
>>>>>>>>
>>>>>>>> I am wondering about the X11() graphic device on Windows.
>>>>>>>> I try to plot a raster image but nothing gets displayed. I
>>>>>>>> found some pages where it is mentioned that x11() not
>>>>>>>> always supports raster rendering.
>>>>>>>> Is there any add on for x11, any update or any R-package
>>>>>>>> which solves that displaying problem in Windows?
>>>>>>>>
>>>>>>>> What I try to test it is an example from the
>>>>>>>> package {raster}:
>>>>>>>>
>>>>>>>> library(raster)
>>>>>>>> DEU_alt<- getData("alt", country="DEU", mask=TRUE)
>>>>>>>> x11()
>>>>>>>> plot(DEU_alt,axes=TRUE)
>>>>>>>>
>>>>>>>> best regards,
>>>>>>>>
>>>>>>>> /johannes
>>>>>>>
>>>>>>> Try an R version that is recent - it works for me.
>>>>>>>
>>>>>>> Uwe Ligges
>>>>>>
>>>>>> I first tried it with R 2.13.2 and raster version 1.9-64
>>>>> (16-January-2012).
>>>>>> Now I also installed the most recent version R 2.14.1 (Platform:
>>>>> i386-pc-mingw32/i386 (32-bit)) and raster version 1.9-64
>>> (16-January-2012).
>>>>>>
>>>>>> But in both cases no success. X11() opens and draws the axis and the
>>>>>> border for the scale but no raster...
>>>>>
>>>>> I do not really understand why you are using x11(). The Windows device
>>>>> is called windows() and you actually do not need to open it, since plot
>>>>> opens it anyway. Or are you under cygwin (which is not really Windows)?
>>>>> If not: Which version of Windows is this?
>>>>
>>>> Of course I do not need to open a graphic device (as you said it is open
>>> when calling plot). I just wanted to make it reproducable as e.g. Mac OS X
>>> opens Quartz as a standard device when calling plot on my Mac machine.
>>>>
>>>> So far as I understand the help are "all the devices (X11(), x11() and
>>> windows() implemented as variants of the same device". Thus it makes no
>>> difference if I call x11() or windows() or if 'plot' opens the device
>>> automatically. In all cases there is no raster displayed.
>>>>
>>>> Just some additional information from the 'grDevices' package:
>>>>> library(grDevices)
>>>>> dev.capabilities()
>>>> $semiTransparency
>>>> [1] TRUE
>>>>
>>>> $transparentBackground
>>>> [1] "fully"
>>>>
>>>> $rasterImage
>>>> [1] "yes"
>>>>
>>>> $capture
>>>> [1] TRUE
>>>>
>>>> $locator
>>>> [1] TRUE
>>>>
>>>> $events
>>>> [1] "MouseDown" "MouseMove" "MouseUp"   "Keybd"
>>>>
>>>> I am running R via the standard RGUI (so no Eclipse, Rtinn etc.). The
>>> machine I am working on is Windows 2008 Server Enterprise (Version 6.0) which
>>> I am remotely accessing from a ThinClient with WindowsXP-embedded.
>>>> This is the standard configuration of our institution. Maybe that
>>> configuration with ThinClients is a reason? But what should I ask our admin? What
>>> should he check etc?
>>>
>>> Yes! the remotesoftware is probably unable to send the rasterimage!
>>>
>>> See ?image:
>>>
>>> "Problems with the rendering of raster images have been reported using
>>> ?windows()? devices under Remote Desktop."
>>>
>>
>>
>> I shifted this corresponce over to the more suitable r-devel-list.
>>
>> @Uwe Ligges: Thank you for that usefull but very disappointing message. So it seems that these are know problems caused by the RemoteDesktop Setup.
>>
>> I just wanted to know if the source of the problem is caused by the R-code or the RemoteDesktop Software. If it is caused by the RemoteDesktop (as you stated)..are there any settings which need to be set by our IT-admin? Or is there anything I/we can do to solve that problem?
>
> Since it is correctly displayed locally, we can assume this is a problem
> of the RDP connection. We do not know of a setting that enables the
> feature via RemoteDesktop, but if you know any, please let us know and
> we will include this in the documentation as a hint for others.
>

I would add to this:  please report this as a bug to your vendor 
(presumably Microsoft).  They may have a workaround, or may point out 
something R could do to avoid it.

Duncan Murdoch


From chuck at sharpsteen.net  Thu Jan 26 21:16:27 2012
From: chuck at sharpsteen.net (Sharpie)
Date: Thu, 26 Jan 2012 12:16:27 -0800 (PST)
Subject: [Rd] Ignore user interrupts
In-Reply-To: <1327348807154-4321817.post@n4.nabble.com>
References: <1327337214864-4321252.post@n4.nabble.com>
	<1327348807154-4321817.post@n4.nabble.com>
Message-ID: <1327608987129-4331653.post@n4.nabble.com>


Sharpie wrote
> 
> evalWithoutInterrupts <- function(expr, envir = parent.frame())
> {
>   .Call(do_evalWithoutInterrupts, expr, envir)
> }
> 
> 
> With a C-level implemention:
> 
> SEXPR do_evalWithoutInterrupts(SEXP expr, SEXP envir)
> {
>   SEXP result;
> 
>   BEGIN_SUSPEND_INTERRUPTS{
>     result = eval(expr, envir);
>   }END_SUSPEND_INTERRUPTS;
> 
>   return result;
> }
> 

Some more info, and a possible bug:

This approach appears to work if I change `evalWithoutInterrupts` so that it
invokes `substitute` on `expr` before passing to the C code:


    evalWithoutInterrupts <- function(expr, envir = parent.frame())
    {
      .Call(do_evalWithoutInterrupts, substitute(expr), envir)
    }


For example, I can do the following (using OS X, R 2.14.1 in Terminal.app):

    eval({for(i in 1:10000000){log(i)};message("Hello, world!")})
    evalWithoutInterrupts({for(i in 1:10000000){log(i)};message("Hello,
world!")})

The `eval` call can be interrupted by CTRL-C as normal. However, with the
`evalWithoutInterrupts` call, I can tap on CTRL-C and the loop will still
execute, "Hello, world!" will be printed and then the interrupt will be
registered:

    > evalWithoutInterrupts({for(i in 1:10000000){log(i)};message("Hello,
world!")})
    ^C^C^C^C^CHello, world!

    > 


The only odd thing I came across was when I tried to test this function
using `Sys.sleep` instead of a long loop:

    evalWithoutInterrupts(Sys.sleep(3);message("Hello, world!")})

The call can be interrupted immediately by CTRL-C. Some poking in GDB
reveals that the call chain passes from my C function
`evalWithoutInterrupts` to `do_syssleep` an finally to `Rf_onintr` through
`R_checkActivity`:

Breakpoint 1, Rf_onintr () at errors.c:123
123	    if (R_interrupts_suspended) {
(gdb) bt   
#0  Rf_onintr () at errors.c:123
#1  0x00000001001ced41 in R_SelectEx (n=1, readfds=0x10038cdc0,
writefds=0x0, exceptfds=0x0, timeout=0x7fff5fbf8b60, intr=0) at
sys-std.c:127
#2  0x00000001001cf109 in R_checkActivityEx (usec=3000000, ignore_stdin=1,
intr=0) at sys-std.c:329
#3  0x00000001001cf14b in R_checkActivity (usec=3000000, ignore_stdin=1) at
sys-std.c:338
#4  0x00000001001d0fbb in do_syssleep (call=0x1025bb200, op=0x10086d0d8,
args=0x1033679b8, rho=0x1033679f0) at sys-std.c:1299
#5  0x00000001000c7608 in bcEval (body=0x1025ba878, rho=0x1033679f0,
useCache=TRUE) at eval.c:4445
#6  0x00000001000bcb69 in Rf_eval (e=0x1025ba878, rho=0x1033679f0) at
eval.c:401
#7  0x00000001000bddd7 in Rf_applyClosure (call=0x103366e38, op=0x1025ba8e8,
arglist=0x103367a60, rho=0x100877ea8, suppliedenv=0x100877ee0) at eval.c:840
#8  0x00000001000bd22e in Rf_eval (e=0x103366e38, rho=0x100877ea8) at
eval.c:515
#9  0x00000001000bf879 in do_begin (call=0x103366ee0, op=0x10084e6e0,
args=0x103366dc8, rho=0x100877ea8) at eval.c:1422
#10 0x00000001000bcf40 in Rf_eval (e=0x103366ee0, rho=0x100877ea8) at
eval.c:471
#11 0x0000000102fc736d in evalWithoutInterrupts ()


However, at this point the variable `R_interrupts_suspended` is not set to
`TRUE` as I would expect due to the `BEGIN_SUSPEND_INTERRUPTS` block in
`evalWithoutInterrupts`:

(gdb) p R_interrupts_suspended 
$1 = FALSE


Bug?

-Charlie


-----
Charlie Sharpsteen
Undergraduate-- Environmental Resources Engineering
Humboldt State University
--
View this message in context: http://r.789695.n4.nabble.com/Ignore-user-interrupts-tp4321252p4331653.html
Sent from the R devel mailing list archive at Nabble.com.


From zepu.zhang at gmail.com  Thu Jan 26 21:27:08 2012
From: zepu.zhang at gmail.com (Zepu Zhang)
Date: Thu, 26 Jan 2012 11:27:08 -0900
Subject: [Rd] Conflicts between 'parallel' and 'Rprof',
	and between two parallel R sessions
In-Reply-To: <CAG5L0QWqkg0zAMgqSKd5vzREiW0kDfRyymdy4O9Zo=Awf17V3Q@mail.gmail.com>
References: <CAG5L0QWqkg0zAMgqSKd5vzREiW0kDfRyymdy4O9Zo=Awf17V3Q@mail.gmail.com>
Message-ID: <CAG5L0QVzYqYz+RZfDBcMEUjvQ9XFfXPZrNCN3ysbKPn0Pq5eKg@mail.gmail.com>

Dear list,

I observed two problems that I suppose are generic.

First, using 'Rprof' to profile a parallel (based on the package
'parallel') code caused

.... Error in unserialize(node$con) : error reading from connection....

Second, on a multicore desktop, I concurrently opened two terminals
and ran two separate R sessions, both running (actually
identical) parallel code (which sets up a cluster with as many nodes
as there are cores). I got

?...Error in socketConnection("localhost", port = port, server = TRUE,
blocking = TRUE, ?: ? cannot open the connection
In addition: Warning message:
In socketConnection("localhost", port = port, server = TRUE, blocking = TRUE, ?:
?port 10187 cannot be opened

Are there ways to do the two things above without problems?

Thanks!

Zepu


From presnell at stat.ufl.edu  Thu Jan 26 23:31:54 2012
From: presnell at stat.ufl.edu (Brett Presnell)
Date: Thu, 26 Jan 2012 17:31:54 -0500
Subject: [Rd] ftable.formula
Message-ID: <8762fy3xk5.fsf@stat.ufl.edu>


I apologize in advance if this is the wrong forum for this
report/request, and for the fact that I have not read the code for
ftable.formula in any detail.

>From reading the documentation for ftable.formula, I expected that the
following two calls to ftable would produce the same results:

data(UCBAdmissions)
ftable(UCBAdmissions, row.vars = "Dept", col.vars = c("Gender", "Admit"))
ftable(UCBAdmissions, Gender + Admit ~ Dept)

Is this a bug or the intended behavior?  I prefer the formula interface,
so I would be happiest if the output was the same for the two calls.
However, if this is the intended behavior, then I think that the
documentation should be clearer on this point.

FWIW:

platform       x86_64-pc-linux-gnu          
arch           x86_64                       
os             linux-gnu                    
system         x86_64, linux-gnu            
status                                      
major          2                            
minor          14.1                         
year           2011                         
month          12                           
day            22                           
svn rev        57956                        
language       R                            
version.string R version 2.14.1 (2011-12-22)


From timothy.c.bates at gmail.com  Fri Jan 27 00:17:25 2012
From: timothy.c.bates at gmail.com (Timothy Bates)
Date: Thu, 26 Jan 2012 23:17:25 +0000
Subject: [Rd] ftable.formula
In-Reply-To: <8762fy3xk5.fsf@stat.ufl.edu>
References: <8762fy3xk5.fsf@stat.ufl.edu>
Message-ID: <73E6F405-80DA-4DC6-994C-6AA895E7DAF7@gmail.com>

At least this is correct :-)

 ftable(UCBAdmissions, Dept ~ Gender + Admit)

But yes: the formula
ftable(UCBAdmissions, Gender + Admit ~ Dept)

should see "The left and right hand side of formula specify the column and row variables, respectively"

# demo of right-hand side bug

ftable(UCBAdmissions, Gender + Admit ~ Dept) # "Dept" should be in the rows...
                Dept   A   B   C   D   E   F
Admit    Gender                             
Admitted Male        512 353 120 138  53  22
         Female       89  17 202 131  94  24
Rejected Male        313 207 205 279 138 351
         Female       19   8 391 244 299 317


Also, the example appears not to be a correct use of the "." shortcut.

x <- ftable(Survived ~ ., data = Titanic)
# Error in ftable.formula(Survived ~ ., data = Titanic) : 
#  cannot use dots in formula with given data

Also "Survived" should be "survived"
And in this example, all vars should be lower-case

ftable(Sex ~ Class + Age, data = x)

t

On 26 Jan 2012, at 22:31, Brett Presnell wrote:
> From reading the documentation for ftable.formula, I expected that the
> following two calls to ftable would produce the same results:
> 
> data(UCBAdmissions)
> ftable(UCBAdmissions, row.vars = "Dept", col.vars = c("Gender", "Admit"))
> ftable(UCBAdmissions, Gender + Admit ~ Dept)
> 
> Is this a bug or the intended behavior?  I prefer the formula interface,
> so I would be happiest if the output was the same for the two calls.
> However, if this is the intended behavior, then I think that the
> documentation should be clearer on this point.


From wdunlap at tibco.com  Fri Jan 27 02:06:39 2012
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 27 Jan 2012 01:06:39 +0000
Subject: [Rd] ftable.formula
In-Reply-To: <73E6F405-80DA-4DC6-994C-6AA895E7DAF7@gmail.com>
References: <8762fy3xk5.fsf@stat.ufl.edu>
	<73E6F405-80DA-4DC6-994C-6AA895E7DAF7@gmail.com>
Message-ID: <E66794E69CFDE04D9A70842786030B93260B31@PA-MBX03.na.tibco.com>

Put the formula first in the argument list or label
the data argument data= and put the formula after it
if you want to use the formula method for ftable.

  > ftable(data=UCBAdmissions, Gender + Admit ~ Dept)
       Gender     Male            Female
       Admit  Admitted Rejected Admitted Rejected
  Dept
  A                512      313       89       19
  B                353      207       17        8
  C                120      205      202      391
  D                138      279      131      244
  E                 53      138       94      299
  F                 22      351       24      317

The array method for ftable appears to ignore a formula.
It expects a row.vars and/or col.vars argument:
  > ftable(UCBAdmissions, nonSense ~ more + nonSense)
                  Dept   A   B   C   D   E   F
  Admit    Gender
  Admitted Male        512 353 120 138  53  22
           Female       89  17 202 131  94  24
  Rejected Male        313 207 205 279 138 351
           Female       19   8 391 244 299 317

Since most generic functions and methods have ... in the
argument list you don't get warned about supplying
arguments that the method does not expect.

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com 

> -----Original Message-----
> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org] On Behalf Of Timothy Bates
> Sent: Thursday, January 26, 2012 3:17 PM
> To: r-devel at stat.math.ethz.ch
> Subject: Re: [Rd] ftable.formula
> 
> At least this is correct :-)
> 
>  ftable(UCBAdmissions, Dept ~ Gender + Admit)
> 
> But yes: the formula
> ftable(UCBAdmissions, Gender + Admit ~ Dept)
> 
> should see "The left and right hand side of formula specify the column and row variables,
> respectively"
> 
> # demo of right-hand side bug
> 
> ftable(UCBAdmissions, Gender + Admit ~ Dept) # "Dept" should be in the rows...
>                 Dept   A   B   C   D   E   F
> Admit    Gender
> Admitted Male        512 353 120 138  53  22
>          Female       89  17 202 131  94  24
> Rejected Male        313 207 205 279 138 351
>          Female       19   8 391 244 299 317
> 
> 
> Also, the example appears not to be a correct use of the "." shortcut.
> 
> x <- ftable(Survived ~ ., data = Titanic)
> # Error in ftable.formula(Survived ~ ., data = Titanic) :
> #  cannot use dots in formula with given data
> 
> Also "Survived" should be "survived"
> And in this example, all vars should be lower-case
> 
> ftable(Sex ~ Class + Age, data = x)
> 
> t
> 
> On 26 Jan 2012, at 22:31, Brett Presnell wrote:
> > From reading the documentation for ftable.formula, I expected that the
> > following two calls to ftable would produce the same results:
> >
> > data(UCBAdmissions)
> > ftable(UCBAdmissions, row.vars = "Dept", col.vars = c("Gender", "Admit"))
> > ftable(UCBAdmissions, Gender + Admit ~ Dept)
> >
> > Is this a bug or the intended behavior?  I prefer the formula interface,
> > so I would be happiest if the output was the same for the two calls.
> > However, if this is the intended behavior, then I think that the
> > documentation should be clearer on this point.
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From m.cowley at garvan.org.au  Fri Jan 27 10:47:35 2012
From: m.cowley at garvan.org.au (Mark Cowley)
Date: Fri, 27 Jan 2012 20:47:35 +1100
Subject: [Rd] Unable to reload Rdoc
Message-ID: <5E2DFDD7-D68B-4B8B-915F-2ACFC08C4D94@garvan.org.au>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20120127/da0ad921/attachment.pl>

From ripley at stats.ox.ac.uk  Fri Jan 27 10:55:53 2012
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 27 Jan 2012 09:55:53 +0000
Subject: [Rd] serialize/unserialize vector improvement
In-Reply-To: <4F1C1571.8090800@stats.ox.ac.uk>
References: <CANwu5-oZXZjThFof++sf9bE2xYt-1g60+HjhA3vogD7Qnm_m6Q@mail.gmail.com>
	<CANwu5-qjBe_3-KOH2QvufgBVnt8URRvnYz4Z9Be7m+g0KdeFVA@mail.gmail.com>
	<alpine.LFD.2.02.1110030828220.15986@nokomis.stat.uiowa.edu>
	<4F1C1571.8090800@stats.ox.ac.uk>
Message-ID: <4F2274A9.7040505@stats.ox.ac.uk>

On 22/01/2012 13:56, Prof Brian Ripley wrote:
> This has languished for a long time, and we should make a decision
> before FF for 2.15.0.
>
> It seems to me that in so far as there is a problem, it is that we
> serialize via XDR, and that since that was invented little-endian CPUs
> have taken over the world. So for the only cases I can imagine this is
> really a problem (passing objects in 'parallel'/snow ... contexts) a
> better answer might be to pass without byte-reordering: go back to the
> RDB format which was exposed for save() but AFAIK never for serialize.
>
> I would say Sparc is the only big-endian platform left (some PPC Mac
> users may disagree), so little-endian really does rule.

This does all seem to depend on the quality of the platform's XDR 
implementation: for example, a similar example runs twice as fast on 
x86_64 Mac OS X as on i386 R on the same machine.

On all the (little-endian) platforms I tried not using XDR 
(serialize(xdr = FALSE)) made an improvement of around 3x.  On some a 
version of Spiegel's patch helped equally and on others it made a much 
smaller improvement.  In the best-case scenario (i386 OS X) there was a 
10x improvement.  But that is only going to be noticeable in rare 
applications.

A version of Spiegel's idea (with changes confined to just one file) 
will appear in R-devel shortly.


> Brian
>
> On 03/10/2011 14:28, luke-tierney at uiowa.edu wrote:
>> It's on my list to look at but I may not get to it for a couple of
>> weeks. Someone else may get there earlier.
>>
>> Best,
>>
>> luke
>>
>> On Mon, 3 Oct 2011, Michael Spiegel wrote:
>>
>>> Any thoughts? I haven't heard any feedback on this patch.
>>>
>>> Thanks!
>>> --Michael
>>>
>>> On Wed, Sep 28, 2011 at 3:10 PM, Michael Spiegel
>>> <michael.m.spiegel at gmail.com> wrote:
>>>> Hi folks,
>>>>
>>>> I've attached a patch to the svn trunk that improves the performance
>>>> of the serialize/unserialize interface for vector types. The current
>>>> implementation: a) invokes the R_XDREncode operation for each element
>>>> of the vector type, and b) uses a switch statement to determine the
>>>> stream type for each element of the vector type. I've added
>>>> R_XDREncodeVector/R_XDRDecodeVector functions that accept N elements
>>>> at a time, and I've reorganized the implementation so that the stream
>>>> type is not queried once per element.
>>>>
>>>> In the following microbenchmark (below), I've observed performance
>>>> improvements of about x2.4. In a real benchmark that is using the
>>>> serialization interface to make MPI calls, I see about a 10%
>>>> improvement in performance.
>>>>
>>>> Cheers,
>>>> --Michael
>>>>
>>>> microbenchmark:
>>>>
>>>> input <- matrix(1:100000000, 10000, 10000)
>>>> output <- serialize(input, NULL)
>>>> for(i in 1:10) { print(system.time(serialize(input, NULL))) }
>>>> for(i in 1:10) { print(system.time(unserialize(output))) }
>>>>
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>
>>
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Fri Jan 27 11:26:21 2012
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 27 Jan 2012 10:26:21 +0000
Subject: [Rd] Unable to reload Rdoc
In-Reply-To: <5E2DFDD7-D68B-4B8B-915F-2ACFC08C4D94@garvan.org.au>
References: <5E2DFDD7-D68B-4B8B-915F-2ACFC08C4D94@garvan.org.au>
Message-ID: <4F227BCD.5070407@stats.ox.ac.uk>

This is simply not supported.  Lazy-load databases are cached, and you 
cannot expect to change them during the R session once they have been used.

Spend the few milliseconds needed to start a new session.

And R CMD Rdconv is a much simpler way to check a changed .Rd file.

On 27/01/2012 09:47, Mark Cowley wrote:
> Dear list,
> I'm hoping the R guru's can help with an error i've been getting for at least a year during active package development.
>
> I have a package loaded&  spot a documentation bug, so I:
> edit the Rd file (or in the roxygen header + roxygenize); then
> R CMD BUILD,
> R CMD INSTALL
> then in the same R session, reload the library&  lookup a man page, I always get this error:
> Error in fetch(key) : internal error -3 in R_decompress1
>
> I've tried all ways of reloading the package that i'm aware of:
> detach then library
> unloadNamespace then library
> devtools::install
> devtools::reload
>
> all lead to the error.
>
> I see from ?detach:
> ... So detaching and re-attaching a package may
> not refresh some or all components of the package, and is
> inadvisable.

You were warned ....

>
> restarting the R session results in loading the updated man file, but do you have any ideas how to word around this&  continue within the same R session?
>
> cheers,
> Mark
>
> # 1) using Hadley's devtools
>> library(devtools)
>> library(updateR) # my package under development
>> install("~/src/R/updateR")
>> install("~/src/R/updateR")
> Installing updateR
> * checking for file ?/Users/marcow/src/R/updateR/DESCRIPTION? ... OK
> * preparing ?updateR?:
> * checking DESCRIPTION meta-information ... OK
> * checking for LF line-endings in source and make files
> * checking for empty or unneeded directories
> * building ?updateR_1.0.4.tar.gz?
>
> Warning in normalizePath(c(new, .Library.site, .Library), "/") :
>    path[3]="": No such file or directory
> * installing *source* package ?updateR? ...
> ** R
> ** inst
> ** preparing package for lazy loading
> ** help
> *** installing help indices
> ** building package indices ...
> ** testing if installed package can be loaded
>
> * DONE (updateR)
> Reloading installed updateR
>> ?get.full.path
> Error in fetch(key) : internal error -3 in R_decompress1
>
> 2) using detach + library
> $ R --vanilla
> library(updateR)
> # ?list.my.packages
> detach(pos=2, unload=TRUE, force=TRUE)
> #<<make a change to an Rd file>>
> system("cd ~/src/R&&  R CMD BUILD updateR&&  R CMD INSTALL updateR")
> library("updateR")
> ?list.my.packages
> Error in fetch(key) : internal error -3 in R_decompress1
>
>
> 3) using unloadNamespace
> $ R --vanilla
> library(updateR)
> # ?list.my.packages
> unloadNamespace("updateR")
> #<<make a change to an Rd file>>
> system("cd ~/src/R&&  R CMD BUILD updateR&&  R CMD INSTALL updateR")
> library("updateR")
> ?list.my.packages
> Error in fetch(key) : internal error -3 in R_decompress1
>
>
>> sessionInfo()
> R version 2.13.1 (2011-07-08)
> Platform: x86_64-apple-darwin9.8.0/x86_64 (64-bit)
>
> locale:
> [1] en_AU.UTF-8/en_AU.UTF-8/C/C/en_AU.UTF-8/en_AU.UTF-8
>
> attached base packages:
> [1] tools     stats     graphics  grDevices datasets  utils     methods
> [8] base
>
> other attached packages:
> [1] updateR_1.0.4   codetools_0.2-8 devtools_0.4
>
> loaded via a namespace (and not attached):
> [1] RCurl_1.6-7
>
> -----------------------------------------------------
> Mark Cowley, PhD
>
> Pancreatic Cancer Program | Peter Wills Bioinformatics Centre
> Garvan Institute of Medical Research, Sydney, Australia
> -----------------------------------------------------
>
>
> 	[[alternative HTML version deleted]]
>
>
>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From hwborchers at googlemail.com  Fri Jan 27 13:23:45 2012
From: hwborchers at googlemail.com (Hans W Borchers)
Date: Fri, 27 Jan 2012 13:23:45 +0100
Subject: [Rd] Numerical instability in new R Windows development version
Message-ID: <CAML4n3MNRsp_kTpPHarDh7_kLCVwGZJkweOxkoo6S8OMwENfjg@mail.gmail.com>

I have a question concerning the new Windows toolchain for R >= 2.14.2.
When trying out my package 'pracma' on the win-builder development version
it will stop with the following error message:

  > f3 <- function(x, y) sqrt((1 - (x^2 + y^2)) * (x^2 + y^2 <= 1))
  > dblquad(f3, -1, 1, -1, 1)     #   2.094395124 , i.e. 2/3*pi , err = 2e-8
  Warning in sqrt((1 - (x^2 + y^2)) * (x^2 + y^2 <= 1)) : NaNs produced
  Warning in sqrt((1 - (x^2 + y^2)) * (x^2 + y^2 <= 1)) : NaNs produced
  Error in integrate(function(y) f(x, y), ya, yb, subdivisions = subdivs,  :
    non-finite function value
  Calls: dblquad ...
         <Anonymous> -> f -> do.call -> mapply -> <Anonymous> -> integrate
  Execution halted
  ** running examples for arch 'x64' ... ERROR
  Running examples in 'pracma-Ex.R' failed

This probably means that the following expression got negative for some
values x, y:

  (1 - (x^2 + y^2)) * (x^2 + y^2 <= 1)

It appears to be an often used trick in numerical analysis. One advantage is
that a function using it is immediately vectorized while an expression such
as, e.g., "max(0, 1 - (x^2 + y^2))" is not.

The example runs fine on Debian Linux and Mac OS X 32-/64-bit architectures.
In my understanding the approach is correct and, as said above, often used in
numerical applications.

Can someone explain to me why this fails for the Windows 64-bit compiler and
what I should use instead. Thanks.

Hans Werner Borchers
ABB Corporate Research


From murdoch.duncan at gmail.com  Fri Jan 27 14:26:50 2012
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 27 Jan 2012 08:26:50 -0500
Subject: [Rd] Numerical instability in new R Windows development version
In-Reply-To: <CAML4n3MNRsp_kTpPHarDh7_kLCVwGZJkweOxkoo6S8OMwENfjg@mail.gmail.com>
References: <CAML4n3MNRsp_kTpPHarDh7_kLCVwGZJkweOxkoo6S8OMwENfjg@mail.gmail.com>
Message-ID: <4F22A61A.4020301@gmail.com>

On 12-01-27 7:23 AM, Hans W Borchers wrote:
> I have a question concerning the new Windows toolchain for R>= 2.14.2.
> When trying out my package 'pracma' on the win-builder development version
> it will stop with the following error message:
>
>    >  f3<- function(x, y) sqrt((1 - (x^2 + y^2)) * (x^2 + y^2<= 1))
>    >  dblquad(f3, -1, 1, -1, 1)     #   2.094395124 , i.e. 2/3*pi , err = 2e-8
>    Warning in sqrt((1 - (x^2 + y^2)) * (x^2 + y^2<= 1)) : NaNs produced
>    Warning in sqrt((1 - (x^2 + y^2)) * (x^2 + y^2<= 1)) : NaNs produced
>    Error in integrate(function(y) f(x, y), ya, yb, subdivisions = subdivs,  :
>      non-finite function value
>    Calls: dblquad ...
>           <Anonymous>  ->  f ->  do.call ->  mapply ->  <Anonymous>  ->  integrate
>    Execution halted
>    ** running examples for arch 'x64' ... ERROR
>    Running examples in 'pracma-Ex.R' failed
>
> This probably means that the following expression got negative for some
> values x, y:
>
>    (1 - (x^2 + y^2)) * (x^2 + y^2<= 1)

I think you're right, it's a bug, hopefully easy to fix.  Here's a 
simpler version:

x <- 0*(-1)
sqrt(x)

x is a "negative zero", and the sqrt() function incorrectly produces a 
NaN in the new toolchain.

Duncan Murdoch

>
> It appears to be an often used trick in numerical analysis. One advantage is
> that a function using it is immediately vectorized while an expression such
> as, e.g., "max(0, 1 - (x^2 + y^2))" is not.
>
> The example runs fine on Debian Linux and Mac OS X 32-/64-bit architectures.
> In my understanding the approach is correct and, as said above, often used in
> numerical applications.
>
> Can someone explain to me why this fails for the Windows 64-bit compiler and
> what I should use instead. Thanks.
>
> Hans Werner Borchers
> ABB Corporate Research
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From pdalgd at gmail.com  Fri Jan 27 14:42:09 2012
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 27 Jan 2012 14:42:09 +0100
Subject: [Rd] Numerical instability in new R Windows development version
In-Reply-To: <CAML4n3MNRsp_kTpPHarDh7_kLCVwGZJkweOxkoo6S8OMwENfjg@mail.gmail.com>
References: <CAML4n3MNRsp_kTpPHarDh7_kLCVwGZJkweOxkoo6S8OMwENfjg@mail.gmail.com>
Message-ID: <68DCB1CC-FD34-4B33-9C7F-94FE1B054E2F@gmail.com>


On Jan 27, 2012, at 13:23 , Hans W Borchers wrote:

>  (1 - (x^2 + y^2)) * (x^2 + y^2 <= 1)
> 
> It appears to be an often used trick in numerical analysis. One advantage is
> that a function using it is immediately vectorized while an expression such
> as, e.g., "max(0, 1 - (x^2 + y^2))" is not.

However, "pmax(0, 1 - (x^2 + y^2))" is (unless 0-length x,y is an issue). 

But of course, Duncan is right: It is a bug if you can't take the square root of negative zero.

-- 
Peter Dalgaard, Professor
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From hadley at rice.edu  Fri Jan 27 15:15:45 2012
From: hadley at rice.edu (Hadley Wickham)
Date: Fri, 27 Jan 2012 08:15:45 -0600
Subject: [Rd] Unable to reload Rdoc
In-Reply-To: <5E2DFDD7-D68B-4B8B-915F-2ACFC08C4D94@garvan.org.au>
References: <5E2DFDD7-D68B-4B8B-915F-2ACFC08C4D94@garvan.org.au>
Message-ID: <CABdHhvHYxxAuxpxEQJb5ztrbUs7pwWZZvBPACO3MTzidjwEy0g@mail.gmail.com>

On Fri, Jan 27, 2012 at 3:47 AM, Mark Cowley <m.cowley at garvan.org.au> wrote:
> Dear list,
> I'm hoping the R guru's can help with an error i've been getting for at least a year during active package development.
>
> I have a package loaded & spot a documentation bug, so I:
> edit the Rd file (or in the roxygen header + roxygenize); then
> R CMD BUILD,
> R CMD INSTALL
> then in the same R session, reload the library & lookup a man page, I always get this error:
> Error in fetch(key) : internal error -3 in R_decompress1
>
> I've tried all ways of reloading the package that i'm aware of:
> detach then library
> unloadNamespace then library
> devtools::install
> devtools::reload
>
> all lead to the error.
>
> I see from ?detach:
> ... So detaching and re-attaching a package may
> not refresh some or all components of the package, and is
> inadvisable.
>
> restarting the R session results in loading the updated man file, but do you have any ideas how to word around this & continue within the same R session?
>
> cheers,
> Mark
>
> # 1) using Hadley's devtools
>> library(devtools)
>> library(updateR) # my package under development
>> install("~/src/R/updateR")

To avoid this problem, the latest version of devtools has show_rd(),
which allows you to preview an Rd file in R without having to
reinstall the package.  This was actually really simple to implement,
and I don't know why I didn't think of it ages ago - it's certainly
made my workflow much smoother.

Hadley

-- 
Assistant Professor / Dobelman Family Junior Chair
Department of Statistics / Rice University
http://had.co.nz/


From luke-tierney at uiowa.edu  Fri Jan 27 15:25:11 2012
From: luke-tierney at uiowa.edu (luke-tierney at uiowa.edu)
Date: Fri, 27 Jan 2012 08:25:11 -0600
Subject: [Rd] Ignore user interrupts
In-Reply-To: <1327608987129-4331653.post@n4.nabble.com>
References: <1327337214864-4321252.post@n4.nabble.com>
	<1327348807154-4321817.post@n4.nabble.com>
	<1327608987129-4331653.post@n4.nabble.com>
Message-ID: <alpine.DEB.2.00.1201270815280.2339@luke-inspiron>

On Thu, 26 Jan 2012, Sharpie wrote:

>
> Sharpie wrote
>>
>> evalWithoutInterrupts <- function(expr, envir = parent.frame())
>> {
>>   .Call(do_evalWithoutInterrupts, expr, envir)
>> }
>>
>>
>> With a C-level implemention:
>>
>> SEXPR do_evalWithoutInterrupts(SEXP expr, SEXP envir)
>> {
>>   SEXP result;
>>
>>   BEGIN_SUSPEND_INTERRUPTS{
>>     result = eval(expr, envir);
>>   }END_SUSPEND_INTERRUPTS;
>>
>>   return result;
>> }
>>
>
> Some more info, and a possible bug:
>
> This approach appears to work if I change `evalWithoutInterrupts` so that it
> invokes `substitute` on `expr` before passing to the C code:
>
>
>    evalWithoutInterrupts <- function(expr, envir = parent.frame())
>    {
>      .Call(do_evalWithoutInterrupts, substitute(expr), envir)
>    }
>
>
> For example, I can do the following (using OS X, R 2.14.1 in Terminal.app):
>
>    eval({for(i in 1:10000000){log(i)};message("Hello, world!")})
>    evalWithoutInterrupts({for(i in 1:10000000){log(i)};message("Hello,
> world!")})
>
> The `eval` call can be interrupted by CTRL-C as normal. However, with the
> `evalWithoutInterrupts` call, I can tap on CTRL-C and the loop will still
> execute, "Hello, world!" will be printed and then the interrupt will be
> registered:
>
>    > evalWithoutInterrupts({for(i in 1:10000000){log(i)};message("Hello,
> world!")})
>    ^C^C^C^C^CHello, world!
>
>    >
>
>
> The only odd thing I came across was when I tried to test this function
> using `Sys.sleep` instead of a long loop:
>
>    evalWithoutInterrupts(Sys.sleep(3);message("Hello, world!")})
>
> The call can be interrupted immediately by CTRL-C. Some poking in GDB
> reveals that the call chain passes from my C function
> `evalWithoutInterrupts` to `do_syssleep` an finally to `Rf_onintr` through
> `R_checkActivity`:
>
> Breakpoint 1, Rf_onintr () at errors.c:123
> 123	    if (R_interrupts_suspended) {
> (gdb) bt
> #0  Rf_onintr () at errors.c:123
> #1  0x00000001001ced41 in R_SelectEx (n=1, readfds=0x10038cdc0,
> writefds=0x0, exceptfds=0x0, timeout=0x7fff5fbf8b60, intr=0) at
> sys-std.c:127
> #2  0x00000001001cf109 in R_checkActivityEx (usec=3000000, ignore_stdin=1,
> intr=0) at sys-std.c:329
> #3  0x00000001001cf14b in R_checkActivity (usec=3000000, ignore_stdin=1) at
> sys-std.c:338
> #4  0x00000001001d0fbb in do_syssleep (call=0x1025bb200, op=0x10086d0d8,
> args=0x1033679b8, rho=0x1033679f0) at sys-std.c:1299
> #5  0x00000001000c7608 in bcEval (body=0x1025ba878, rho=0x1033679f0,
> useCache=TRUE) at eval.c:4445
> #6  0x00000001000bcb69 in Rf_eval (e=0x1025ba878, rho=0x1033679f0) at
> eval.c:401
> #7  0x00000001000bddd7 in Rf_applyClosure (call=0x103366e38, op=0x1025ba8e8,
> arglist=0x103367a60, rho=0x100877ea8, suppliedenv=0x100877ee0) at eval.c:840
> #8  0x00000001000bd22e in Rf_eval (e=0x103366e38, rho=0x100877ea8) at
> eval.c:515
> #9  0x00000001000bf879 in do_begin (call=0x103366ee0, op=0x10084e6e0,
> args=0x103366dc8, rho=0x100877ea8) at eval.c:1422
> #10 0x00000001000bcf40 in Rf_eval (e=0x103366ee0, rho=0x100877ea8) at
> eval.c:471
> #11 0x0000000102fc736d in evalWithoutInterrupts ()
>
>
> However, at this point the variable `R_interrupts_suspended` is not set to
> `TRUE` as I would expect due to the `BEGIN_SUSPEND_INTERRUPTS` block in
> `evalWithoutInterrupts`:
>
> (gdb) p R_interrupts_suspended
> $1 = FALSE
>
>
> Bug?

No.

The interrupt managemant we have now is intended for the C level to
make sure interrupts can only occur where they are safe for the C
code, and at this point in sleep they are and so do_syssleep enables
them.

There is a need for interrupt management at the R level but getting it
right is not easy.  It isn't just a matter of suspending them, but
suspending and and re-enabling them where they are safe. Some code
that would potentially hang needs to enable them -- typically these
are operations that could signal other sorts of errors, like read
errors, timeouts, etc. and code that needs to ensure cleanup code is
run would need to catch those as well. (Interrupts are catchable as
"interrupt" conditions by the way).  There is some literature on this
(in particular an article "Asynchronous Exceptions in Haskell") that I
need to study more before implementing something at the R level.

luke

>
> -Charlie
>
>
> -----
> Charlie Sharpsteen
> Undergraduate-- Environmental Resources Engineering
> Humboldt State University
> --
> View this message in context: http://r.789695.n4.nabble.com/Ignore-user-interrupts-tp4321252p4331653.html
> Sent from the R devel mailing list archive at Nabble.com.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Luke Tierney
Chair, Statistics and Actuarial Science
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From edd at debian.org  Fri Jan 27 15:57:11 2012
From: edd at debian.org (Dirk Eddelbuettel)
Date: Fri, 27 Jan 2012 08:57:11 -0600
Subject: [Rd] Silently loading and Depends: versus NAMESPACE imports
In-Reply-To: <4F0F3EC0.5060500@fhcrc.org>
References: <20237.58927.327444.422917@max.nulle.part>
	<4F0F3EC0.5060500@fhcrc.org>
Message-ID: <20258.47943.798999.741944@max.nulle.part>


On 12 January 2012 at 12:12, Herv? Pag?s wrote:
| Hi Dirk,
| 
| On 01/11/2012 11:42 AM, Dirk Eddelbuettel wrote:
| >
| > R CMD check really hates it when my .onLoad() function contains
| >      suppressMessages(library(foo))
| 
| Note that you can always fool 'R CMD check' by doing something like:
| 
|      sillyname <- library
|      suppressMessages(sillyname("foo"))
| 
| Also isn't suppressPackageStartupMessages() more appropriate?
| 
| >
| > However, _and for non-public packages not going to CRAN_ I prefer doing this
| > over using explicit Depends or import statements in the NAMESPACE file as the
| > latter do not give me an ability to make the loading less verbose.  With the
| > R universe of packages being as vast as at is, a simple (non-public) package
| > I have loads about five or six other packages explicitly, each of which loads
| > even more.  The net result is totally intimidating _sixty lines full_ of
| > verbose noise that is meaningful to me as an R programmer, but not for the
| > colleagues expected to use the packages. It looks rather uninviting, frankly.
| >
| > How do I use imports via NAMESPACE, and yet keep the noise level down to zero?
| 
| If you only need to import foo (i.e. and actually don't need to attach
| it to the search path) then putting foo in Imports and using import
| statements in NAMESPACE will keep the noise level down to zero.

I don't think so.  

I have an internal package, call it fooUtils, that (among other things) needs
to figure at startup whether it runs on this or that OS.  

So that package fooUtils does

    .onLoad <- function(libname, pkgname) {
    
        if (.Platform$OS.type == "windows") {
            packageStartupMessage("Running on Windows")
    	# [... more stuff here ... ]
        } else if (.Platform$OS.type == "unix") {
            packageStartupMessage("Running on Linux")
    	# [... more stuff here ... ]
        } else {
            warning("Platform ", .Platform$OS.type, " not recognised")
            drives <- NULL
        }
    
        # ....
    
    }


and contrary to your claim, this is not silent as soon as I do


   importFrom(fooUtils, someThing)


the messages above pop up. While I can suppress them for 'normal' loads via

   suppressMessages(library(fooUtils))

or

   suppressPackageStartupMessages(library(fooUtils))


I cannot suppress them via NAMESPACE imports.  

Dirk
 
| So I guess your question is: how do we suppress package startup messages
| for packages listed in Depends?
| 
| Cheers,
| H.
| 
| >
| > Dirk
| >
| 
| 
| -- 
| Herv? Pag?s
| 
| Program in Computational Biology
| Division of Public Health Sciences
| Fred Hutchinson Cancer Research Center
| 1100 Fairview Ave. N, M1-B514
| P.O. Box 19024
| Seattle, WA 98109-1024
| 
| E-mail: hpages at fhcrc.org
| Phone:  (206) 667-5791
| Fax:    (206) 667-1319

-- 
"Outside of a dog, a book is a man's best friend. Inside of a dog, it is too
dark to read." -- Groucho Marx


From bbolker at gmail.com  Fri Jan 27 18:03:01 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 27 Jan 2012 12:03:01 -0500
Subject: [Rd] misfeature: forced file.copy() of a file over itself truncates
 the file ...
Message-ID: <4F22D8C5.5040602@ufl.edu>


  Try this:

  fn <- "tmp.dat"
  x <- 1:3
  dump("x",file=fn)
  file.info(fn)  ## 9 bytes
  file.copy(paste("./",fn,sep=""),fn,overwrite=TRUE)
  file.info(fn)  ## 0 bytes (!!)

  Normally file.copy() checks and disallows overwriting a file with
itself, but it only checks whether character string 'from' is the same
as character string 'to' and not whether the copy refers to the same
file by different names, so it lets this go ahead.  It then creates a
new file with the name of 'to' using file.create():

     ?file.create? creates files with the given names if they do not
     already exist and truncates them if they do.

This trashes the existing 'from' file (which was not detected).
file.copy() then happily appends the contents of 'from' (which is now
empty) to 'to' ...

  I don't know whether there's any simple way to fix this, or whether
it's just a case of "don't do that".  It might be worth mentioning in
the documentation:

 `file.copy' will normally refuse to copy a file to itself, but in
cases where the same file is referred to by different names (as in
copying "/full/path/to/filename" to "filename" in the current working
directory), it will truncate the file to zero.

  Now that I write that it really seems like a 'mis-feature'.
  On a Unix system I would probably compare inodes, but I don't know if
there's a good system-independent way to test file identity ...

$ ls -i tmp.dat
114080 tmp.dat
$ ls -i /home/bolker/R/pkgs/r2jags/pkg/tests/tmp.dat
114080 /home/bolker/R/pkgs/r2jags/pkg/tests/tmp.dat

  Would normalizePath() work for this ... ?

> normalizePath("tmp.dat")
[1] "/mnt/hgfs/bolker/Documents/R/pkgs/r2jags/pkg/tests/tmp.dat"

   sincerely
    Ben Bolker


From ripley at stats.ox.ac.uk  Fri Jan 27 18:32:02 2012
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 27 Jan 2012 17:32:02 +0000
Subject: [Rd] Numerical instability in new R Windows development version
In-Reply-To: <4F22A61A.4020301@gmail.com>
References: <CAML4n3MNRsp_kTpPHarDh7_kLCVwGZJkweOxkoo6S8OMwENfjg@mail.gmail.com>
	<4F22A61A.4020301@gmail.com>
Message-ID: <4F22DF92.9000204@stats.ox.ac.uk>

On 27/01/2012 13:26, Duncan Murdoch wrote:
> On 12-01-27 7:23 AM, Hans W Borchers wrote:
>> I have a question concerning the new Windows toolchain for R>= 2.14.2.
>> When trying out my package 'pracma' on the win-builder development
>> version
>> it will stop with the following error message:
>>
>> > f3<- function(x, y) sqrt((1 - (x^2 + y^2)) * (x^2 + y^2<= 1))
>> > dblquad(f3, -1, 1, -1, 1) # 2.094395124 , i.e. 2/3*pi , err = 2e-8
>> Warning in sqrt((1 - (x^2 + y^2)) * (x^2 + y^2<= 1)) : NaNs produced
>> Warning in sqrt((1 - (x^2 + y^2)) * (x^2 + y^2<= 1)) : NaNs produced
>> Error in integrate(function(y) f(x, y), ya, yb, subdivisions = subdivs, :
>> non-finite function value
>> Calls: dblquad ...
>> <Anonymous> -> f -> do.call -> mapply -> <Anonymous> -> integrate
>> Execution halted
>> ** running examples for arch 'x64' ... ERROR
>> Running examples in 'pracma-Ex.R' failed
>>
>> This probably means that the following expression got negative for some
>> values x, y:
>>
>> (1 - (x^2 + y^2)) * (x^2 + y^2<= 1)
>
> I think you're right, it's a bug, hopefully easy to fix. Here's a
> simpler version:
>
> x <- 0*(-1)
> sqrt(x)
>
> x is a "negative zero", and the sqrt() function incorrectly produces a
> NaN in the new toolchain.

Well, for some definition of 'incorrectly'.  It is clearly what the 
author of that piece of code intended.

It would be helpful if people would cite definitive references.  Someone 
is going to have to report this on the bugtracker, and at present I 
don't have enough evidence to do so: the C99/C11 standards do not seem 
to mandate a particular value (they do say what happens for values less 
than zero, but C compilers are allowed to have or not have signed 
zeroes).  (Various Unix-alikes say what they do, usually -0, but that's 
not evidence that other answers are 'incorrect'.)

> Duncan Murdoch
>
>>
>> It appears to be an often used trick in numerical analysis. One
>> advantage is
>> that a function using it is immediately vectorized while an expression
>> such
>> as, e.g., "max(0, 1 - (x^2 + y^2))" is not.
>>
>> The example runs fine on Debian Linux and Mac OS X 32-/64-bit
>> architectures.
>> In my understanding the approach is correct and, as said above, often
>> used in
>> numerical applications.
>>
>> Can someone explain to me why this fails for the Windows 64-bit
>> compiler and
>> what I should use instead. Thanks.
>>
>> Hans Werner Borchers
>> ABB Corporate Research
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From wdunlap at tibco.com  Fri Jan 27 18:47:36 2012
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 27 Jan 2012 17:47:36 +0000
Subject: [Rd] misfeature: forced file.copy() of a file over itself
 truncates the file ...
In-Reply-To: <4F22D8C5.5040602@ufl.edu>
References: <4F22D8C5.5040602@ufl.edu>
Message-ID: <E66794E69CFDE04D9A70842786030B93260D79@PA-MBX03.na.tibco.com>

Since the problem can only occur if the 'to' file
exists, a check like
   if (normalizePath(from) == normalizePath(to)) {
      stop("'from' and 'to' files are the same")
   }
(after verifying that 'to', and 'from', exist)
would avoid the problem.

S+ has a function, match.path, that can say if two paths refer to
the same file (on Unixen compare inode and device
numbers, on Windows compare the output of normalizePath),
That avoids automounter/NFS problems like the following.

We have a unix machine has two names, "sea-union" and "seabldlnx3201",
and the /nfs directory contains both names.  At the shell (on a
second Linux machine) we can see they refer to the same place:
   % pwd
   /nfs/sea-union
   % ls -id usr /nfs/seabldlnx3201/usr /nfs/sea-union/usr
   358337 /nfs/seabldlnx3201/usr/  358337 /nfs/sea-union/usr/  358337 usr/
   % df usr /nfs/seabldlnx3201/usr /nfs/sea-union/usr
   Filesystem           1K-blocks      Used Available Use% Mounted on
   sea-union:/usr        15385888   3526656  11077664  25% /nfs/sea-union/usr
   seabldlnx3201:/usr    15385888   3526656  11077664  25% /nfs/seabldlnx3201/usr
   sea-union:/usr        15385888   3526656  11077664  25% /nfs/sea-union/usr

S+'s match.path also indicates that they are the same   
   S+> getwd()
   [1] "/nfs/sea-union"
   S+> match.path( c("usr", "/nfs/seabldlnx3201/usr"), "/nfs/sea-union/usr")
   [1] 1 1
   (The last indicates that both paths in the first argument match the
   path in the second, as match() does for strings.)
But R's normalizePath() would lead you to think that they are different
directories
   > getwd()
   [1] "/nfs/sea-union"
   > normalizePath(c("usr", "/nfs/seabldlnx3201/usr", "/nfs/sea-union/usr"))
   [1] "/nfs/sea-union/usr"     "/nfs/seabldlnx3201/usr" "/nfs/sea-union/usr"

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com 

> -----Original Message-----
> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org] On Behalf Of Ben Bolker
> Sent: Friday, January 27, 2012 9:03 AM
> To: r-devel at r-project.org
> Subject: [Rd] misfeature: forced file.copy() of a file over itself truncates the file ...
> 
> 
>   Try this:
> 
>   fn <- "tmp.dat"
>   x <- 1:3
>   dump("x",file=fn)
>   file.info(fn)  ## 9 bytes
>   file.copy(paste("./",fn,sep=""),fn,overwrite=TRUE)
>   file.info(fn)  ## 0 bytes (!!)
> 
>   Normally file.copy() checks and disallows overwriting a file with
> itself, but it only checks whether character string 'from' is the same
> as character string 'to' and not whether the copy refers to the same
> file by different names, so it lets this go ahead.  It then creates a
> new file with the name of 'to' using file.create():
> 
>      'file.create' creates files with the given names if they do not
>      already exist and truncates them if they do.
> 
> This trashes the existing 'from' file (which was not detected).
> file.copy() then happily appends the contents of 'from' (which is now
> empty) to 'to' ...
> 
>   I don't know whether there's any simple way to fix this, or whether
> it's just a case of "don't do that".  It might be worth mentioning in
> the documentation:
> 
>  `file.copy' will normally refuse to copy a file to itself, but in
> cases where the same file is referred to by different names (as in
> copying "/full/path/to/filename" to "filename" in the current working
> directory), it will truncate the file to zero.
> 
>   Now that I write that it really seems like a 'mis-feature'.
>   On a Unix system I would probably compare inodes, but I don't know if
> there's a good system-independent way to test file identity ...
> 
> $ ls -i tmp.dat
> 114080 tmp.dat
> $ ls -i /home/bolker/R/pkgs/r2jags/pkg/tests/tmp.dat
> 114080 /home/bolker/R/pkgs/r2jags/pkg/tests/tmp.dat
> 
>   Would normalizePath() work for this ... ?
> 
> > normalizePath("tmp.dat")
> [1] "/mnt/hgfs/bolker/Documents/R/pkgs/r2jags/pkg/tests/tmp.dat"
> 
>    sincerely
>     Ben Bolker
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From murdoch.duncan at gmail.com  Fri Jan 27 19:26:17 2012
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 27 Jan 2012 13:26:17 -0500
Subject: [Rd] Numerical instability in new R Windows development version
In-Reply-To: <4F22DF92.9000204@stats.ox.ac.uk>
References: <CAML4n3MNRsp_kTpPHarDh7_kLCVwGZJkweOxkoo6S8OMwENfjg@mail.gmail.com>
	<4F22A61A.4020301@gmail.com> <4F22DF92.9000204@stats.ox.ac.uk>
Message-ID: <4F22EC49.80603@gmail.com>

On 27/01/2012 12:32 PM, Prof Brian Ripley wrote:
> On 27/01/2012 13:26, Duncan Murdoch wrote:
> >  On 12-01-27 7:23 AM, Hans W Borchers wrote:
> >>  I have a question concerning the new Windows toolchain for R>= 2.14.2.
> >>  When trying out my package 'pracma' on the win-builder development
> >>  version
> >>  it will stop with the following error message:
> >>
> >>  >  f3<- function(x, y) sqrt((1 - (x^2 + y^2)) * (x^2 + y^2<= 1))
> >>  >  dblquad(f3, -1, 1, -1, 1) # 2.094395124 , i.e. 2/3*pi , err = 2e-8
> >>  Warning in sqrt((1 - (x^2 + y^2)) * (x^2 + y^2<= 1)) : NaNs produced
> >>  Warning in sqrt((1 - (x^2 + y^2)) * (x^2 + y^2<= 1)) : NaNs produced
> >>  Error in integrate(function(y) f(x, y), ya, yb, subdivisions = subdivs, :
> >>  non-finite function value
> >>  Calls: dblquad ...
> >>  <Anonymous>  ->  f ->  do.call ->  mapply ->  <Anonymous>  ->  integrate
> >>  Execution halted
> >>  ** running examples for arch 'x64' ... ERROR
> >>  Running examples in 'pracma-Ex.R' failed
> >>
> >>  This probably means that the following expression got negative for some
> >>  values x, y:
> >>
> >>  (1 - (x^2 + y^2)) * (x^2 + y^2<= 1)
> >
> >  I think you're right, it's a bug, hopefully easy to fix. Here's a
> >  simpler version:
> >
> >  x<- 0*(-1)
> >  sqrt(x)
> >
> >  x is a "negative zero", and the sqrt() function incorrectly produces a
> >  NaN in the new toolchain.
>
> Well, for some definition of 'incorrectly'.  It is clearly what the
> author of that piece of code intended.
>
> It would be helpful if people would cite definitive references.  Someone
> is going to have to report this on the bugtracker, and at present I
> don't have enough evidence to do so: the C99/C11 standards do not seem
> to mandate a particular value (they do say what happens for values less
> than zero, but C compilers are allowed to have or not have signed
> zeroes).  (Various Unix-alikes say what they do, usually -0, but that's
> not evidence that other answers are 'incorrect'.)

Section 6.3 of IEEE 754-2008 says

Except that squareRoot(?0) shall be ?0, every numeric squareRoot result 
shall have a positive sign.

Duncan Murdoch


From murdoch.duncan at gmail.com  Fri Jan 27 19:37:45 2012
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 27 Jan 2012 13:37:45 -0500
Subject: [Rd] Numerical instability in new R Windows development version
In-Reply-To: <4F22EC49.80603@gmail.com>
References: <CAML4n3MNRsp_kTpPHarDh7_kLCVwGZJkweOxkoo6S8OMwENfjg@mail.gmail.com>
	<4F22A61A.4020301@gmail.com> <4F22DF92.9000204@stats.ox.ac.uk>
	<4F22EC49.80603@gmail.com>
Message-ID: <4F22EEF9.8000809@gmail.com>

On 27/01/2012 1:26 PM, Duncan Murdoch wrote:
> On 27/01/2012 12:32 PM, Prof Brian Ripley wrote:
> >  On 27/01/2012 13:26, Duncan Murdoch wrote:
> >  >   On 12-01-27 7:23 AM, Hans W Borchers wrote:
> >  >>   I have a question concerning the new Windows toolchain for R>= 2.14.2.
> >  >>   When trying out my package 'pracma' on the win-builder development
> >  >>   version
> >  >>   it will stop with the following error message:
> >  >>
> >  >>   >   f3<- function(x, y) sqrt((1 - (x^2 + y^2)) * (x^2 + y^2<= 1))
> >  >>   >   dblquad(f3, -1, 1, -1, 1) # 2.094395124 , i.e. 2/3*pi , err = 2e-8
> >  >>   Warning in sqrt((1 - (x^2 + y^2)) * (x^2 + y^2<= 1)) : NaNs produced
> >  >>   Warning in sqrt((1 - (x^2 + y^2)) * (x^2 + y^2<= 1)) : NaNs produced
> >  >>   Error in integrate(function(y) f(x, y), ya, yb, subdivisions = subdivs, :
> >  >>   non-finite function value
> >  >>   Calls: dblquad ...
> >  >>   <Anonymous>   ->   f ->   do.call ->   mapply ->   <Anonymous>   ->   integrate
> >  >>   Execution halted
> >  >>   ** running examples for arch 'x64' ... ERROR
> >  >>   Running examples in 'pracma-Ex.R' failed
> >  >>
> >  >>   This probably means that the following expression got negative for some
> >  >>   values x, y:
> >  >>
> >  >>   (1 - (x^2 + y^2)) * (x^2 + y^2<= 1)
> >  >
> >  >   I think you're right, it's a bug, hopefully easy to fix. Here's a
> >  >   simpler version:
> >  >
> >  >   x<- 0*(-1)
> >  >   sqrt(x)
> >  >
> >  >   x is a "negative zero", and the sqrt() function incorrectly produces a
> >  >   NaN in the new toolchain.
> >
> >  Well, for some definition of 'incorrectly'.  It is clearly what the
> >  author of that piece of code intended.
> >
> >  It would be helpful if people would cite definitive references.  Someone
> >  is going to have to report this on the bugtracker, and at present I
> >  don't have enough evidence to do so: the C99/C11 standards do not seem
> >  to mandate a particular value (they do say what happens for values less
> >  than zero, but C compilers are allowed to have or not have signed
> >  zeroes).  (Various Unix-alikes say what they do, usually -0, but that's
> >  not evidence that other answers are 'incorrect'.)
>
> Section 6.3 of IEEE 754-2008 says
>
> Except that squareRoot(?0) shall be ?0, every numeric squareRoot result
> shall have a positive sign.

I believe the corresponding ISO standard is ISO/IEC/IEEE 60559:2011, but I don't have a copy, and I don't think my library does.

Duncan Murdoch


From murdoch.duncan at gmail.com  Fri Jan 27 19:40:54 2012
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 27 Jan 2012 13:40:54 -0500
Subject: [Rd] Numerical instability in new R Windows development version
In-Reply-To: <4F22DF92.9000204@stats.ox.ac.uk>
References: <CAML4n3MNRsp_kTpPHarDh7_kLCVwGZJkweOxkoo6S8OMwENfjg@mail.gmail.com>
	<4F22A61A.4020301@gmail.com> <4F22DF92.9000204@stats.ox.ac.uk>
Message-ID: <4F22EFB6.9010407@gmail.com>

On 27/01/2012 12:32 PM, Prof Brian Ripley wrote:
> On 27/01/2012 13:26, Duncan Murdoch wrote:
> >  On 12-01-27 7:23 AM, Hans W Borchers wrote:
> >>  I have a question concerning the new Windows toolchain for R>= 2.14.2.
> >>  When trying out my package 'pracma' on the win-builder development
> >>  version
> >>  it will stop with the following error message:
> >>
> >>  >  f3<- function(x, y) sqrt((1 - (x^2 + y^2)) * (x^2 + y^2<= 1))
> >>  >  dblquad(f3, -1, 1, -1, 1) # 2.094395124 , i.e. 2/3*pi , err = 2e-8
> >>  Warning in sqrt((1 - (x^2 + y^2)) * (x^2 + y^2<= 1)) : NaNs produced
> >>  Warning in sqrt((1 - (x^2 + y^2)) * (x^2 + y^2<= 1)) : NaNs produced
> >>  Error in integrate(function(y) f(x, y), ya, yb, subdivisions = subdivs, :
> >>  non-finite function value
> >>  Calls: dblquad ...
> >>  <Anonymous>  ->  f ->  do.call ->  mapply ->  <Anonymous>  ->  integrate
> >>  Execution halted
> >>  ** running examples for arch 'x64' ... ERROR
> >>  Running examples in 'pracma-Ex.R' failed
> >>
> >>  This probably means that the following expression got negative for some
> >>  values x, y:
> >>
> >>  (1 - (x^2 + y^2)) * (x^2 + y^2<= 1)
> >
> >  I think you're right, it's a bug, hopefully easy to fix. Here's a
> >  simpler version:
> >
> >  x<- 0*(-1)
> >  sqrt(x)
> >
> >  x is a "negative zero", and the sqrt() function incorrectly produces a
> >  NaN in the new toolchain.
>
> Well, for some definition of 'incorrectly'.  It is clearly what the
> author of that piece of code intended.
>
> It would be helpful if people would cite definitive references.  Someone
> is going to have to report this on the bugtracker, and at present I
> don't have enough evidence to do so: the C99/C11 standards do not seem
> to mandate a particular value (they do say what happens for values less
> than zero, but C compilers are allowed to have or not have signed
> zeroes).  (Various Unix-alikes say what they do, usually -0, but that's
> not evidence that other answers are 'incorrect'.)

This page:

http://pubs.opengroup.org/onlinepubs/9699919799/functions/sqrt.html

also says that the correct answer is -0.  I don't know if that has any 
authority at all...

Duncan Murdoch


From stephen.b.weston at gmail.com  Fri Jan 27 20:04:01 2012
From: stephen.b.weston at gmail.com (Stephen Weston)
Date: Fri, 27 Jan 2012 14:04:01 -0500
Subject: [Rd] Numerical instability in new R Windows development version
In-Reply-To: <4F22EFB6.9010407@gmail.com>
References: <CAML4n3MNRsp_kTpPHarDh7_kLCVwGZJkweOxkoo6S8OMwENfjg@mail.gmail.com>
	<4F22A61A.4020301@gmail.com> <4F22DF92.9000204@stats.ox.ac.uk>
	<4F22EFB6.9010407@gmail.com>
Message-ID: <CALh21iL37vgi=r2rHSx9okiCihtuc9Z3xccT-XE8=-H7Lh+3ig@mail.gmail.com>

On Fri, Jan 27, 2012 at 1:40 PM, Duncan Murdoch
<murdoch.duncan at gmail.com> wrote:
> On 27/01/2012 12:32 PM, Prof Brian Ripley wrote:
>>
>> On 27/01/2012 13:26, Duncan Murdoch wrote:
>> > ?On 12-01-27 7:23 AM, Hans W Borchers wrote:
>> >> ?I have a question concerning the new Windows toolchain for R>= 2.14.2.
>> >> ?When trying out my package 'pracma' on the win-builder development
>> >> ?version
>> >> ?it will stop with the following error message:
>> >>
>> >> ?> ?f3<- function(x, y) sqrt((1 - (x^2 + y^2)) * (x^2 + y^2<= 1))
>> >> ?> ?dblquad(f3, -1, 1, -1, 1) # 2.094395124 , i.e. 2/3*pi , err = 2e-8
>> >> ?Warning in sqrt((1 - (x^2 + y^2)) * (x^2 + y^2<= 1)) : NaNs produced
>> >> ?Warning in sqrt((1 - (x^2 + y^2)) * (x^2 + y^2<= 1)) : NaNs produced
>> >> ?Error in integrate(function(y) f(x, y), ya, yb, subdivisions =
>> >> subdivs, :
>> >> ?non-finite function value
>> >> ?Calls: dblquad ...
>> >> ?<Anonymous> ?-> ?f -> ?do.call -> ?mapply -> ?<Anonymous> ?->
>> >> ?integrate
>> >> ?Execution halted
>> >> ?** running examples for arch 'x64' ... ERROR
>> >> ?Running examples in 'pracma-Ex.R' failed
>> >>
>> >> ?This probably means that the following expression got negative for
>> >> some
>> >> ?values x, y:
>> >>
>> >> ?(1 - (x^2 + y^2)) * (x^2 + y^2<= 1)
>> >
>> > ?I think you're right, it's a bug, hopefully easy to fix. Here's a
>> > ?simpler version:
>> >
>> > ?x<- 0*(-1)
>> > ?sqrt(x)
>> >
>> > ?x is a "negative zero", and the sqrt() function incorrectly produces a
>> > ?NaN in the new toolchain.
>>
>> Well, for some definition of 'incorrectly'. ?It is clearly what the
>> author of that piece of code intended.
>>
>> It would be helpful if people would cite definitive references. ?Someone
>> is going to have to report this on the bugtracker, and at present I
>> don't have enough evidence to do so: the C99/C11 standards do not seem
>> to mandate a particular value (they do say what happens for values less
>> than zero, but C compilers are allowed to have or not have signed
>> zeroes). ?(Various Unix-alikes say what they do, usually -0, but that's
>> not evidence that other answers are 'incorrect'.)
>
>
> This page:
>
> http://pubs.opengroup.org/onlinepubs/9699919799/functions/sqrt.html
>
> also says that the correct answer is -0. ?I don't know if that has any
> authority at all...
>
> Duncan Murdoch

Section 5.4.1 "Arithmetic operations" of "IEEE Standard for Floating-
Point Arithmetic", IEEE Std 754-2008 says:

  "The operation squareRoot(x) computes ? x. It has a positive sign for
all operands ? 0, except that squareRoot(?0) shall be ?0."

- Steve


From chuck at sharpsteen.net  Fri Jan 27 20:53:24 2012
From: chuck at sharpsteen.net (Charlie Sharpsteen)
Date: Fri, 27 Jan 2012 11:53:24 -0800
Subject: [Rd] Ignore user interrupts
In-Reply-To: <alpine.DEB.2.00.1201270815280.2339@luke-inspiron>
References: <1327337214864-4321252.post@n4.nabble.com>
	<1327348807154-4321817.post@n4.nabble.com>
	<1327608987129-4331653.post@n4.nabble.com>
	<alpine.DEB.2.00.1201270815280.2339@luke-inspiron>
Message-ID: <CAMEX5swynaZ5q4Wo5Yr706KA2-9d=bsAdu0TOHtGPWL0SFb+9Q@mail.gmail.com>

On Fri, Jan 27, 2012 at 6:25 AM,  <luke-tierney at uiowa.edu> wrote:
> On Thu, 26 Jan 2012, Sharpie wrote:
>> The only odd thing I came across was when I tried to test this function
>> using `Sys.sleep` instead of a long loop:
>>
>> ? evalWithoutInterrupts(Sys.sleep(3);message("Hello, world!")})
>>
>> The call can be interrupted immediately by CTRL-C. Some poking in GDB
>> reveals that the call chain passes from my C function
>> `evalWithoutInterrupts` to `do_syssleep` an finally to `Rf_onintr` through
>> `R_checkActivity`:

...

>> However, at this point the variable `R_interrupts_suspended` is not set to
>> `TRUE` as I would expect due to the `BEGIN_SUSPEND_INTERRUPTS` block in
>> `evalWithoutInterrupts`:
>>
>> (gdb) p R_interrupts_suspended
>> $1 = FALSE
>>
>>
>> Bug?
>
>
> No.
>
> The interrupt managemant we have now is intended for the C level to
> make sure interrupts can only occur where they are safe for the C
> code, and at this point in sleep they are and so do_syssleep enables
> them.


Thanks for the confirmation Luke---I figured Sys.sleep was somehow
explicitly ignoring the suspended state of interrupts. However, it
seems possible that a situation could arise where R needs to sleep
while waiting for some information needed to finish a critical
operation. I agree that this sounds like poorly written code, but it
would be nice to have a "do not disturb" sign that sets up a context
where all code will ignore SIGINTs generated by the user---even if
that code is just napping for a few seconds.

If someone really wants to halt a critical section of code, they
should need a signal like SIGTERM or SIGKILL that expresses the
severity of such an action.


> There is a need for interrupt management at the R level but getting it
> right is not easy. ?It isn't just a matter of suspending them, but
> suspending and and re-enabling them where they are safe. Some code
> that would potentially hang needs to enable them -- typically these
> are operations that could signal other sorts of errors, like read
> errors, timeouts, etc. and code that needs to ensure cleanup code is
> run would need to catch those as well.


The only thing I am worried about are user-generated interrupts. I
have had a few bug reports that are the result of users just being
unlucky enough to signal an interrupt while a filehash operation was
running. I am pretty confident that these operations either complete
or throw an error, so it is very helpful to delay the processing of
SIGINT for a few microseconds until the filehash ops complete.


> (Interrupts are catchable as "interrupt" conditions by the way).


I tried playing around with `tryCatch` before turning my attention to
BEGIN_SUSPEND_INTERRUPTS and didn't have much success. I could not
find any way to create an interrupt handler that returned control to
the interrupted function call at the point where the interrupt was
signaled. For example, the following catches warnings and ignores
them:

    withCallingHandlers(expr, warning = function(w)
invokeRestart("muffleWarning"))

I am looking for a similar restart handler that traps interrupts and
continues on with the original function call as if nothing happened
(or maybe keeps track of the rate at which interrupts are being
signaled and finally breaks out if the user seems insistent).


-Charlie


From jlisic at gmail.com  Fri Jan 27 20:46:25 2012
From: jlisic at gmail.com (Jonathan Lisic)
Date: Fri, 27 Jan 2012 14:46:25 -0500
Subject: [Rd] .C returned array has odd results
Message-ID: <CAFumHFH2mRqFQHvQpzNK8qGhruXMUt7Rws=mfOiK_5v_VCCRFw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20120127/99967613/attachment.pl>

From presnell at stat.ufl.edu  Fri Jan 27 21:12:55 2012
From: presnell at stat.ufl.edu (Brett Presnell)
Date: Fri, 27 Jan 2012 15:12:55 -0500
Subject: [Rd] ftable.formula
In-Reply-To: <E66794E69CFDE04D9A70842786030B93260B31@PA-MBX03.na.tibco.com>
	(William Dunlap's message of "Fri, 27 Jan 2012 01:06:39 +0000")
References: <E66794E69CFDE04D9A70842786030B93260B31@PA-MBX03.na.tibco.com>
Message-ID: <878vkshpko.fsf@stat.ufl.edu>


William Dunlap <wdunlap at tibco.com> writes:

> Put the formula first in the argument list or label
> the data argument data= and put the formula after it
> if you want to use the formula method for ftable.

Ack!  So it was a question for R-help after all.  Thanks Bill,
especially for being so polite about it.


From murdoch.duncan at gmail.com  Fri Jan 27 21:29:07 2012
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 27 Jan 2012 15:29:07 -0500
Subject: [Rd] .C returned array has odd results
In-Reply-To: <CAFumHFH2mRqFQHvQpzNK8qGhruXMUt7Rws=mfOiK_5v_VCCRFw@mail.gmail.com>
References: <CAFumHFH2mRqFQHvQpzNK8qGhruXMUt7Rws=mfOiK_5v_VCCRFw@mail.gmail.com>
Message-ID: <4F230913.7070506@gmail.com>

On 27/01/2012 2:46 PM, Jonathan Lisic wrote:
> Hi, I'm sure this is a fairly simple problem, but I can't seem to find any
> specific information in the documentation as to what is going on.  I am
> writing a simple nearest neighbor program that takes in a set of of points
> on a plane and returns the neighbors of those points, for a fixed number of
> neighbors.  However, the returned integer array that is allocated in R
> seems to occasionally return incorrect results.
>
> I thought this would be because of GC, but I thought this was only for
> SEXPs, or at least this is the impression I got from reading the
> documentation.  So is there some obvious reason why my results seem to get
> mangled by this call?  I have checked my program through several thousand
> loops in C, and always get the same results, so I assume that this is
> something I'm doing wrong in R.

You don't show us what your incorrect results are.  The most likely 
causes are on the C side, and besides just doing the wrong calculation, 
I'd be suspicious of out of bounds writes to arrays.  Do you treat any 
of the other arguments besides the 5th one as arrays?  Are you sure the 
length of array passed in is long enough?  Do you have local allocations 
of arrays, and are they long enough?  Do your type declarations in C 
match the four double* declarations followed by six int* declarations 
implied by your .C call?

Duncan Murdoch

> Here is the code for my .C call.  I could post the C code if someone thinks
> it's important, but I'm just changing the values of integer array specified
> in R.
>
> r.result<-
> .C("evalPoly",
>   as.double(c.polygonX),
>   as.double(c.polygonY),
>   as.double(c.neighborX),
>   as.double(c.neighborY),
>   integer(c.numberOfNeighbors*c.height*c.length),
>   as.integer(c.polygonLength),
>   as.integer(c.neighborLength),
>   as.integer(c.numberOfNeighbors),
>   as.integer(c.length),
>   as.integer(c.height),
>   DUP=TRUE
> )[[5]]
>
>
> Cheers,
>
> Jonathan
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From faheem at faheem.info  Fri Jan 27 22:03:05 2012
From: faheem at faheem.info (Faheem Mitha)
Date: Sat, 28 Jan 2012 02:33:05 +0530 (IST)
Subject: [Rd] The following code (using rgamma) hangs
Message-ID: <alpine.DEB.2.00.1201280141080.18502@orwell.homelinux.org>


Hi,

I'm seeing something that may be a bug in R's standalone math library, 
which is packaged by Debian as r-mathlib. I reported it to the Debian BTS 
as http://bugs.debian.org/657573

I'm using Debian squeeze, and the code was tested with r-mathlib 2.11.1-6 
(default on stable) and 2.14.1-1 (from testing/unstable).

I summarize this report below. The following code with the R math library 
hangs. Note that set_seed is defined as taking two unsigned int arguments, 
so 0's are valid arguments. I'm guessing that since 0 is as low as an 
unsigned integer can go, it represents some kind of edge case.

################################################
#define MATHLIB_STANDALONE
#include <Rmath.h>

int main(void)
{
   set_seed(0, 0);
   rgamma(1, 1);
}
################################################

If I add the definitions of `get_seed` and `set_seed` from 
`src/nmath/standalone/sunif.c` to my code, then the hang disappears.

################################################
#define MATHLIB_STANDALONE
#include <Rmath.h>

/* A version of Marsaglia-MultiCarry */

static unsigned int I1=1234, I2=5678;

void set_seed(unsigned int i1, unsigned int i2)
{
     I1 = i1; I2 = i2;
}

void get_seed(unsigned int *i1, unsigned int *i2)
{
     *i1 = I1; *i2 = I2;
}

int main(void)
{
   set_seed(0, 0);
   rgamma(1, 1);
}
################################################

I assume sunif.c defines the `get_seed` and `set_seed` for the R 
standalone random number generation facilities.

However, I wonder why

a) redefining them in my source file makes the hang go away

and

b) why doesn't redefining `get_seed` and `set_seed` (even with the same 
definition) give a linker error, since the function has been defined in 
the library already?

Dirk also pointed out (in the bug report) that you get the following

##########################################################
int main(void)
{
     set_seed(0, 0);
     cout << "one normal " << norm_rand() << endl;
}
##########################################################

edd at max:/tmp$ g++ -o faheem faheem.cpp -lRmath; ./faheem
one normal -inf

One would expect norm_rand to return finite values, even in edge cases.

If you want me to report this as a bug, let me know. Thanks.

                                                        Regards, Faheem


From edd at debian.org  Fri Jan 27 22:14:56 2012
From: edd at debian.org (Dirk Eddelbuettel)
Date: Fri, 27 Jan 2012 15:14:56 -0600
Subject: [Rd] The following code (using rgamma) hangs
In-Reply-To: <alpine.DEB.2.00.1201280141080.18502@orwell.homelinux.org>
References: <alpine.DEB.2.00.1201280141080.18502@orwell.homelinux.org>
Message-ID: <20259.5072.790261.193341@max.nulle.part>


On 28 January 2012 at 02:33, Faheem Mitha wrote:
| 
| Hi,
| 
| I'm seeing something that may be a bug in R's standalone math library, 
| which is packaged by Debian as r-mathlib. I reported it to the Debian BTS 
| as http://bugs.debian.org/657573
| 
| I'm using Debian squeeze, and the code was tested with r-mathlib 2.11.1-6 
| (default on stable) and 2.14.1-1 (from testing/unstable).
| 
| I summarize this report below. The following code with the R math library 
| hangs. Note that set_seed is defined as taking two unsigned int arguments, 
| so 0's are valid arguments. I'm guessing that since 0 is as low as an 
| unsigned integer can go, it represents some kind of edge case.
| 
| ################################################
| #define MATHLIB_STANDALONE
| #include <Rmath.h>
| 
| int main(void)
| {
|    set_seed(0, 0);
|    rgamma(1, 1);
| }
| ################################################
| 
| If I add the definitions of `get_seed` and `set_seed` from 
| `src/nmath/standalone/sunif.c` to my code, then the hang disappears.
| 
| ################################################
| #define MATHLIB_STANDALONE
| #include <Rmath.h>
| 
| /* A version of Marsaglia-MultiCarry */
| 
| static unsigned int I1=1234, I2=5678;
| 
| void set_seed(unsigned int i1, unsigned int i2)
| {
|      I1 = i1; I2 = i2;
| }
| 
| void get_seed(unsigned int *i1, unsigned int *i2)
| {
|      *i1 = I1; *i2 = I2;
| }
| 
| int main(void)
| {
|    set_seed(0, 0);
|    rgamma(1, 1);
| }
| ################################################
| 
| I assume sunif.c defines the `get_seed` and `set_seed` for the R 
| standalone random number generation facilities.
| 
| However, I wonder why
| 
| a) redefining them in my source file makes the hang go away
| 
| and
| 
| b) why doesn't redefining `get_seed` and `set_seed` (even with the same 
| definition) give a linker error, since the function has been defined in 
| the library already?
| 
| Dirk also pointed out (in the bug report) that you get the following
| 
| ##########################################################
| int main(void)
| {
|      set_seed(0, 0);
|      cout << "one normal " << norm_rand() << endl;
| }
| ##########################################################
| 
| edd at max:/tmp$ g++ -o faheem faheem.cpp -lRmath; ./faheem
| one normal -inf

Well I actually sent you a complete program of which you showed only an
incomplete part.  A better quote would have shown all:

  #define MATHLIB_STANDALONE
  #include <Rmath.h>
  #include <iostream>
  using std::cout;
  using std::endl;

  int main(void) {
      set_seed(0, 0);
      cout << "one normal " << norm_rand() << endl;
  }


That does indeed return -Inf on my Ubuntu server.  It works with other seed
values as does the rgamma which hangs only for value 0 and 0.

Dirk
 
| One would expect norm_rand to return finite values, even in edge cases.
| 
| If you want me to report this as a bug, let me know. Thanks.
| 
|                                                         Regards, Faheem
| 
| ______________________________________________
| R-devel at r-project.org mailing list
| https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
"Outside of a dog, a book is a man's best friend. Inside of a dog, it is too
dark to read." -- Groucho Marx


From hb at biostat.ucsf.edu  Fri Jan 27 22:29:57 2012
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Fri, 27 Jan 2012 13:29:57 -0800
Subject: [Rd] Unable to reload Rdoc
In-Reply-To: <CABdHhvHYxxAuxpxEQJb5ztrbUs7pwWZZvBPACO3MTzidjwEy0g@mail.gmail.com>
References: <5E2DFDD7-D68B-4B8B-915F-2ACFC08C4D94@garvan.org.au>
	<CABdHhvHYxxAuxpxEQJb5ztrbUs7pwWZZvBPACO3MTzidjwEy0g@mail.gmail.com>
Message-ID: <CAFDcVCQOGSFD0ZHPo6g+2Yx-JEFZVxFh0cf2Gi_Aj4N7OWeShQ@mail.gmail.com>

Related: To simplify reloading a help page after restarting R, I do
have the following in my ~/.Rprofile:

# Always only the HTML help on the same port
local({
  port <- sum(c(1e3,10)*as.double(R.Version()[c("major", "minor")]));
  ports <- 10*port + 0:9;
  options(help.ports=ports);
});

# Try to start HTML help server
tryCatch({
  if (interactive()) {
    tools::startDynamicHelp();
  }
}, error = function(ex) {
  print(ex);
})

That way the URL for the help page remain the same (as long as you
only run one R session) and the internal web server is up and running
(no need for help.start()).

My $.02

/Henrik

On Fri, Jan 27, 2012 at 6:15 AM, Hadley Wickham <hadley at rice.edu> wrote:
> On Fri, Jan 27, 2012 at 3:47 AM, Mark Cowley <m.cowley at garvan.org.au> wrote:
>> Dear list,
>> I'm hoping the R guru's can help with an error i've been getting for at least a year during active package development.
>>
>> I have a package loaded & spot a documentation bug, so I:
>> edit the Rd file (or in the roxygen header + roxygenize); then
>> R CMD BUILD,
>> R CMD INSTALL
>> then in the same R session, reload the library & lookup a man page, I always get this error:
>> Error in fetch(key) : internal error -3 in R_decompress1
>>
>> I've tried all ways of reloading the package that i'm aware of:
>> detach then library
>> unloadNamespace then library
>> devtools::install
>> devtools::reload
>>
>> all lead to the error.
>>
>> I see from ?detach:
>> ... So detaching and re-attaching a package may
>> not refresh some or all components of the package, and is
>> inadvisable.
>>
>> restarting the R session results in loading the updated man file, but do you have any ideas how to word around this & continue within the same R session?
>>
>> cheers,
>> Mark
>>
>> # 1) using Hadley's devtools
>>> library(devtools)
>>> library(updateR) # my package under development
>>> install("~/src/R/updateR")
>
> To avoid this problem, the latest version of devtools has show_rd(),
> which allows you to preview an Rd file in R without having to
> reinstall the package. ?This was actually really simple to implement,
> and I don't know why I didn't think of it ages ago - it's certainly
> made my workflow much smoother.
>
> Hadley
>
> --
> Assistant Professor / Dobelman Family Junior Chair
> Department of Statistics / Rice University
> http://had.co.nz/
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From faheem at faheem.info  Fri Jan 27 23:14:34 2012
From: faheem at faheem.info (Faheem Mitha)
Date: Sat, 28 Jan 2012 03:44:34 +0530 (IST)
Subject: [Rd] The following code (using rgamma) hangs
In-Reply-To: <20259.5072.790261.193341@max.nulle.part>
References: <alpine.DEB.2.00.1201280141080.18502@orwell.homelinux.org>
	<20259.5072.790261.193341@max.nulle.part>
Message-ID: <alpine.DEB.2.00.1201280341430.18502@orwell.homelinux.org>



On Fri, 27 Jan 2012, Dirk Eddelbuettel wrote:

> | Dirk also pointed out (in the bug report) that you get the following
> |
> | ##########################################################
> | int main(void)
> | {
> |      set_seed(0, 0);
> |      cout << "one normal " << norm_rand() << endl;
> | }
> | ##########################################################
> |
> | edd at max:/tmp$ g++ -o faheem faheem.cpp -lRmath; ./faheem
> | one normal -inf
>
> Well I actually sent you a complete program of which you showed only an
> incomplete part.  A better quote would have shown all:
>
>  #define MATHLIB_STANDALONE
>  #include <Rmath.h>
>  #include <iostream>
>  using std::cout;
>  using std::endl;
>
>  int main(void) {
>      set_seed(0, 0);
>      cout << "one normal " << norm_rand() << endl;
>  }
>
>
> That does indeed return -Inf on my Ubuntu server.  It works with other seed
> values as does the rgamma which hangs only for value 0 and 0.

Yes, apologies for not including the complete code.

Btw, adding the definitions of `get_seed` and `set_seed` from
| `src/nmath/standalone/sunif.c` fixes the problem here as well.

faheem at orwell[default branch:rev 12]:~/corrmodel/bug$ ./edd one normal 
-1.26974

where previously it was giving -inf.
                                                        Regards, Faheem


From ligges at statistik.tu-dortmund.de  Sat Jan 28 16:52:14 2012
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sat, 28 Jan 2012 16:52:14 +0100
Subject: [Rd] Silently loading and Depends: versus NAMESPACE imports
In-Reply-To: <20258.47943.798999.741944@max.nulle.part>
References: <20237.58927.327444.422917@max.nulle.part>
	<4F0F3EC0.5060500@fhcrc.org>
	<20258.47943.798999.741944@max.nulle.part>
Message-ID: <4F2419AE.5010203@statistik.tu-dortmund.de>



On 27.01.2012 15:57, Dirk Eddelbuettel wrote:
>
> On 12 January 2012 at 12:12, Herv? Pag?s wrote:
> | Hi Dirk,
> |
> | On 01/11/2012 11:42 AM, Dirk Eddelbuettel wrote:
> |>
> |>  R CMD check really hates it when my .onLoad() function contains
> |>       suppressMessages(library(foo))
> |
> | Note that you can always fool 'R CMD check' by doing something like:
> |
> |      sillyname<- library
> |      suppressMessages(sillyname("foo"))
> |
> | Also isn't suppressPackageStartupMessages() more appropriate?
> |
> |>
> |>  However, _and for non-public packages not going to CRAN_ I prefer doing this
> |>  over using explicit Depends or import statements in the NAMESPACE file as the
> |>  latter do not give me an ability to make the loading less verbose.  With the
> |>  R universe of packages being as vast as at is, a simple (non-public) package
> |>  I have loads about five or six other packages explicitly, each of which loads
> |>  even more.  The net result is totally intimidating _sixty lines full_ of
> |>  verbose noise that is meaningful to me as an R programmer, but not for the
> |>  colleagues expected to use the packages. It looks rather uninviting, frankly.
> |>
> |>  How do I use imports via NAMESPACE, and yet keep the noise level down to zero?
> |
> | If you only need to import foo (i.e. and actually don't need to attach
> | it to the search path) then putting foo in Imports and using import
> | statements in NAMESPACE will keep the noise level down to zero.
>
> I don't think so.
>
> I have an internal package, call it fooUtils, that (among other things) needs
> to figure at startup whether it runs on this or that OS.
>
> So that package fooUtils does
>
>      .onLoad<- function(libname, pkgname) {
>
>          if (.Platform$OS.type == "windows") {
>              packageStartupMessage("Running on Windows")
>      	# [... more stuff here ... ]
>          } else if (.Platform$OS.type == "unix") {
>              packageStartupMessage("Running on Linux")
>      	# [... more stuff here ... ]
>          } else {
>              warning("Platform ", .Platform$OS.type, " not recognised")
>              drives<- NULL
>          }
>
>          # ....
>
>      }

Are you sure you want the messages in .onLoad rather than .onAttach?

See ?.onLoad and its "Good practice" section:

"Loading a namespace should where possible be silent, with startup 
messages given by .onAttach. These messages (and any essential ones from 
.onLoad) should use packageStartupMessage so they can be silenced where 
they would be a distraction."

Best,
Uwe



>
> and contrary to your claim, this is not silent as soon as I do
>
>
>     importFrom(fooUtils, someThing)
>
>
> the messages above pop up. While I can suppress them for 'normal' loads via
>
>     suppressMessages(library(fooUtils))
>
> or
>
>     suppressPackageStartupMessages(library(fooUtils))
>
>
> I cannot suppress them via NAMESPACE imports.
 >
> Dirk
>
> | So I guess your question is: how do we suppress package startup messages
> | for packages listed in Depends?
> |
> | Cheers,
> | H.
> |
> |>
> |>  Dirk
> |>
> |
> |
> | --
> | Herv? Pag?s
> |
> | Program in Computational Biology
> | Division of Public Health Sciences
> | Fred Hutchinson Cancer Research Center
> | 1100 Fairview Ave. N, M1-B514
> | P.O. Box 19024
> | Seattle, WA 98109-1024
> |
> | E-mail: hpages at fhcrc.org
> | Phone:  (206) 667-5791
> | Fax:    (206) 667-1319
>


From edd at debian.org  Sat Jan 28 17:15:27 2012
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sat, 28 Jan 2012 10:15:27 -0600
Subject: [Rd] Silently loading and Depends: versus NAMESPACE imports
In-Reply-To: <4F2419AE.5010203@statistik.tu-dortmund.de>
References: <20237.58927.327444.422917@max.nulle.part>
	<4F0F3EC0.5060500@fhcrc.org>
	<20258.47943.798999.741944@max.nulle.part>
	<4F2419AE.5010203@statistik.tu-dortmund.de>
Message-ID: <20260.7967.353013.815027@max.nulle.part>


On 28 January 2012 at 16:52, Uwe Ligges wrote:
| 
| 
| On 27.01.2012 15:57, Dirk Eddelbuettel wrote:
| >
| > On 12 January 2012 at 12:12, Herv? Pag?s wrote:
| > | Hi Dirk,
| > |
| > | On 01/11/2012 11:42 AM, Dirk Eddelbuettel wrote:
| > |>
| > |>  R CMD check really hates it when my .onLoad() function contains
| > |>       suppressMessages(library(foo))
| > |
| > | Note that you can always fool 'R CMD check' by doing something like:
| > |
| > |      sillyname<- library
| > |      suppressMessages(sillyname("foo"))
| > |
| > | Also isn't suppressPackageStartupMessages() more appropriate?
| > |
| > |>
| > |>  However, _and for non-public packages not going to CRAN_ I prefer doing this
| > |>  over using explicit Depends or import statements in the NAMESPACE file as the
| > |>  latter do not give me an ability to make the loading less verbose.  With the
| > |>  R universe of packages being as vast as at is, a simple (non-public) package
| > |>  I have loads about five or six other packages explicitly, each of which loads
| > |>  even more.  The net result is totally intimidating _sixty lines full_ of
| > |>  verbose noise that is meaningful to me as an R programmer, but not for the
| > |>  colleagues expected to use the packages. It looks rather uninviting, frankly.
| > |>
| > |>  How do I use imports via NAMESPACE, and yet keep the noise level down to zero?
| > |
| > | If you only need to import foo (i.e. and actually don't need to attach
| > | it to the search path) then putting foo in Imports and using import
| > | statements in NAMESPACE will keep the noise level down to zero.
| >
| > I don't think so.
| >
| > I have an internal package, call it fooUtils, that (among other things) needs
| > to figure at startup whether it runs on this or that OS.
| >
| > So that package fooUtils does
| >
| >      .onLoad<- function(libname, pkgname) {
| >
| >          if (.Platform$OS.type == "windows") {
| >              packageStartupMessage("Running on Windows")
| >      	# [... more stuff here ... ]
| >          } else if (.Platform$OS.type == "unix") {
| >              packageStartupMessage("Running on Linux")
| >      	# [... more stuff here ... ]
| >          } else {
| >              warning("Platform ", .Platform$OS.type, " not recognised")
| >              drives<- NULL
| >          }
| >
| >          # ....
| >
| >      }
| 
| Are you sure you want the messages in .onLoad rather than .onAttach?

Thanks Uwe -- looks like that was exactly the hint I needed.  

By splitting the task across onLoad and onAttach I seem to be able to get
want I need even if the package is "tickled" via NAMESPACE's importFrom.

Dirk

| See ?.onLoad and its "Good practice" section:
| 
| "Loading a namespace should where possible be silent, with startup 
| messages given by .onAttach. These messages (and any essential ones from 
| .onLoad) should use packageStartupMessage so they can be silenced where 
| they would be a distraction."
| 
| Best,
| Uwe
| 
| 
| 
| >
| > and contrary to your claim, this is not silent as soon as I do
| >
| >
| >     importFrom(fooUtils, someThing)
| >
| >
| > the messages above pop up. While I can suppress them for 'normal' loads via
| >
| >     suppressMessages(library(fooUtils))
| >
| > or
| >
| >     suppressPackageStartupMessages(library(fooUtils))
| >
| >
| > I cannot suppress them via NAMESPACE imports.
|  >
| > Dirk
| >
| > | So I guess your question is: how do we suppress package startup messages
| > | for packages listed in Depends?
| > |
| > | Cheers,
| > | H.
| > |
| > |>
| > |>  Dirk
| > |>
| > |
| > |
| > | --
| > | Herv? Pag?s
| > |
| > | Program in Computational Biology
| > | Division of Public Health Sciences
| > | Fred Hutchinson Cancer Research Center
| > | 1100 Fairview Ave. N, M1-B514
| > | P.O. Box 19024
| > | Seattle, WA 98109-1024
| > |
| > | E-mail: hpages at fhcrc.org
| > | Phone:  (206) 667-5791
| > | Fax:    (206) 667-1319
| >

-- 
"Outside of a dog, a book is a man's best friend. Inside of a dog, it is too
dark to read." -- Groucho Marx


From pauljohn32 at gmail.com  Sat Jan 28 20:59:31 2012
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Sat, 28 Jan 2012 13:59:31 -0600
Subject: [Rd] need gui matrix editor: does R Core team have advice on how?
Message-ID: <CAErODj9ZMXTEbnSD-bRShAuXfXK6nBROFjt4UnadL-SkKFt4NA@mail.gmail.com>

Dear R-devel:

Would R core team consider endorsing a graphical toolkit and trying to
facilitate development of little GUI tools?

I need a gui matrix editor for users that want to be able to write
matrices that are later used to simulate data.  Instead of teaching
them to write a covariance matrix (for example, for mvtnorm), I want
to tell them run a function that pops up a table they can fill in.

The users need to be able to enter variable names in the matrix, so
something that would accept

a  0  0
0  b  0
c  d  e

would be great.  Something that would accept formulae like this would
be even more great.

a  0  0
0  b  a^2
c  d  e

I want this gui matrix editor to "just work" on Windows, Mac, Linux. I
don't mind building this on top of some widget set, but it is
important that the widget set be easily installable on the user end.

That's why I wish R core would offer us some guidance or advice.  I'm
not a programmer, but I can learn to program with a library, as long
as it is not a waste of time.

I've been searching R archives and here's what I found so far.

1. tcl/tk

Building on R tcltk2, for people that have the Tcl addon widget
TkTable installed, there are several packages.  in tcltk2 itself,
there is a function tk2edit, and there are others that try to
embellish.  I've tried several of these, they seem to be not-quite
done yet, one can't copy a rectangle, for example. But maybe I could
learn how to fix them up and make yet another tktable based editor.

Problem: requires user to have enough understanding to install the Tcl
widget TkTable.  And, for platforms like Windows, user has to install
tcl/tk itself.  On Linux and Mac, that is not as big of a hurdle, so
far as I can tell.  On Debian linux, I found that in a package
libtktable that works, but I have no idea how tough that would be on
other linux systems or Macintosh or Windows.

Another problem is that tcl/tk editions change rapidly, and on several
of our systems, we still don't have access to tcl/tk 8.5
(RedHat/Centos based clusters still running version 5 are like that).

2. Gtk

Building on Rgtk, I found the package RGtk2Extras.  This of course
requires a function gtk tool chain, which used to be a big problem on
the various platforms.  But the function dfedit appears to be almost
exactly what I'm looking for.  I can create a character matrix and put
in letters how I want, but I later face the problem of how to evaluate
the matrix.

Problem: even more than tcl/tk, GTK versions change and become
incompatible, especially across platforms.

What about QT or WX-Widgets.  I gather RkWard is built on KDE, and
hence Qt.  I don't find matrix editors using those languages, but I
don't know why not.

Maybe this is impossible for R core to advise us because you may
disagree on which widget library is best, but if there is some
consensus, I would be glad to know because I would do whatever you
recommend.

I'm pretty sure that, if you said, "use library X, version XYZ", then
the worldwide usage of R is sufficiently broad that people would step
forward and help make sure those libraries are packaged for all OS.  I
mean, if there were no tktable package for any linux for which I make
packages (RedHat, Fedora, Debian, Ubuntu), I would create the
packages.   But I'm not doing it now because I have no reason to
believe that is a good path from here on out.


-- 
Paul E. Johnson
Professor, Political Science
1541 Lilac Lane, Room 504
University of Kansas


From ggrothendieck at gmail.com  Sat Jan 28 22:33:05 2012
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 28 Jan 2012 16:33:05 -0500
Subject: [Rd] need gui matrix editor: does R Core team have advice on
	how?
In-Reply-To: <CAErODj9ZMXTEbnSD-bRShAuXfXK6nBROFjt4UnadL-SkKFt4NA@mail.gmail.com>
References: <CAErODj9ZMXTEbnSD-bRShAuXfXK6nBROFjt4UnadL-SkKFt4NA@mail.gmail.com>
Message-ID: <CAP01uRk2O9bTDijvxLXRpnXihJFAZe4XS4NcQeN-KHOqhwf8rA@mail.gmail.com>

On Sat, Jan 28, 2012 at 2:59 PM, Paul Johnson <pauljohn32 at gmail.com> wrote:
> Dear R-devel:
>
> Would R core team consider endorsing a graphical toolkit and trying to
> facilitate development of little GUI tools?
>
> I need a gui matrix editor for users that want to be able to write
> matrices that are later used to simulate data. ?Instead of teaching
> them to write a covariance matrix (for example, for mvtnorm), I want
> to tell them run a function that pops up a table they can fill in.
>
> The users need to be able to enter variable names in the matrix, so
> something that would accept
>
> a ?0 ?0
> 0 ?b ?0
> c ?d ?e
>
> would be great. ?Something that would accept formulae like this would
> be even more great.
>
> a ?0 ?0
> 0 ?b ?a^2
> c ?d ?e
>
> I want this gui matrix editor to "just work" on Windows, Mac, Linux. I
> don't mind building this on top of some widget set, but it is
> important that the widget set be easily installable on the user end.
>
> That's why I wish R core would offer us some guidance or advice. ?I'm
> not a programmer, but I can learn to program with a library, as long
> as it is not a waste of time.
>
> I've been searching R archives and here's what I found so far.
>
> 1. tcl/tk
>
> Building on R tcltk2, for people that have the Tcl addon widget
> TkTable installed, there are several packages. ?in tcltk2 itself,
> there is a function tk2edit, and there are others that try to
> embellish. ?I've tried several of these, they seem to be not-quite
> done yet, one can't copy a rectangle, for example. But maybe I could
> learn how to fix them up and make yet another tktable based editor.
>
> Problem: requires user to have enough understanding to install the Tcl
> widget TkTable. ?And, for platforms like Windows, user has to install
> tcl/tk itself.

Regarding Windows, both the tcltk R package and tcl/tk itself are
included with R for Windows and work out of the box without doing
anything special.   You can use addTclPath(libdir) to add additional
locations to the tcl library search path so you can include additional
tcl/tk packages in your R package and in conjunction with
system.file(..., package = "myPackage") you can have them
automatically accessed without the user having to do anything special.
 Also you can use all or nearly all of tcl's facilities including
sourcing your own tcl code and you can issue tcl commands one by one
from R too using the facilities of the tcltk package.  There are also
various other R packages that build on top of tcltk.

I too think that a standard R installation should ensure that tcltk
just works out of the box but that seems not to be the case for every
R distribution although it is true for some (possibly most) including
the standard Windows distribution.


-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From jfox at mcmaster.ca  Sat Jan 28 23:04:51 2012
From: jfox at mcmaster.ca (John Fox)
Date: Sat, 28 Jan 2012 17:04:51 -0500
Subject: [Rd] need gui matrix editor: does R Core team have advice
	on	how?
In-Reply-To: <CAP01uRk2O9bTDijvxLXRpnXihJFAZe4XS4NcQeN-KHOqhwf8rA@mail.gmail.com>
References: <CAErODj9ZMXTEbnSD-bRShAuXfXK6nBROFjt4UnadL-SkKFt4NA@mail.gmail.com>
	<CAP01uRk2O9bTDijvxLXRpnXihJFAZe4XS4NcQeN-KHOqhwf8rA@mail.gmail.com>
Message-ID: <002401ccde08$dc207100$94615300$@mcmaster.ca>

Dear Paul and Gabor,

The Rcmdr GUI uses the tcltk package, so I have some experience with
providing an R tcltk-based GUI for various platforms. 

As Gabor says, everything works very smoothly on Windows because the R
Windows binary includes Tcl/Tk. On Mac OS X, it's necessary for the user to
install Tcl/Tk for X Windows and to insure that X Windows is installed (as
it typically is in recent releases of Mac OS X). In my experience, most
Linux users already have Tcl/Tk and X Windows (or if they don't, they're
familiar with how to install software on their systems), so that things work
smoothly there as well. 

The upshot of this is that Mac OS X is the platform that seems to generate
the most problems for naive users, although installing Tcl/Tk for X Windows
isn't that difficult. Take a look, e.g., at the Rcmdr installation notes
<http://socserv.socsci.mcmaster.ca/jfox/Misc/Rcmdr/installation-notes.html>.

I hope this helps,
 John

--------------------------------
John Fox
Senator William McMaster
  Professor of Social Statistics
Department of Sociology
McMaster University
Hamilton, Ontario, Canada
http://socserv.mcmaster.ca/jfox



> -----Original Message-----
> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-
> project.org] On Behalf Of Gabor Grothendieck
> Sent: January-28-12 4:33 PM
> To: Paul Johnson
> Cc: R Devel List
> Subject: Re: [Rd] need gui matrix editor: does R Core team have advice
> on how?
> 
> On Sat, Jan 28, 2012 at 2:59 PM, Paul Johnson <pauljohn32 at gmail.com>
> wrote:
> > Dear R-devel:
> >
> > Would R core team consider endorsing a graphical toolkit and trying
> to
> > facilitate development of little GUI tools?
> >
> > I need a gui matrix editor for users that want to be able to write
> > matrices that are later used to simulate data. ?Instead of teaching
> > them to write a covariance matrix (for example, for mvtnorm), I want
> > to tell them run a function that pops up a table they can fill in.
> >
> > The users need to be able to enter variable names in the matrix, so
> > something that would accept
> >
> > a ?0 ?0
> > 0 ?b ?0
> > c ?d ?e
> >
> > would be great. ?Something that would accept formulae like this
> would
> > be even more great.
> >
> > a ?0 ?0
> > 0 ?b ?a^2
> > c ?d ?e
> >
> > I want this gui matrix editor to "just work" on Windows, Mac, Linux.
> I
> > don't mind building this on top of some widget set, but it is
> > important that the widget set be easily installable on the user end.
> >
> > That's why I wish R core would offer us some guidance or
> advice. ?I'm
> > not a programmer, but I can learn to program with a library, as long
> > as it is not a waste of time.
> >
> > I've been searching R archives and here's what I found so far.
> >
> > 1. tcl/tk
> >
> > Building on R tcltk2, for people that have the Tcl addon widget
> > TkTable installed, there are several packages. ?in tcltk2 itself,
> > there is a function tk2edit, and there are others that try to
> > embellish. ?I've tried several of these, they seem to be not-quite
> > done yet, one can't copy a rectangle, for example. But maybe I could
> > learn how to fix them up and make yet another tktable based editor.
> >
> > Problem: requires user to have enough understanding to install the
> Tcl
> > widget TkTable. ?And, for platforms like Windows, user has to
> install
> > tcl/tk itself.
> 
> Regarding Windows, both the tcltk R package and tcl/tk itself are
> included with R for Windows and work out of the box without doing
> anything special.   You can use addTclPath(libdir) to add additional
> locations to the tcl library search path so you can include additional
> tcl/tk packages in your R package and in conjunction with
> system.file(..., package = "myPackage") you can have them
> automatically accessed without the user having to do anything special.
>  Also you can use all or nearly all of tcl's facilities including
> sourcing your own tcl code and you can issue tcl commands one by one
> from R too using the facilities of the tcltk package.  There are also
> various other R packages that build on top of tcltk.
> 
> I too think that a standard R installation should ensure that tcltk
> just works out of the box but that seems not to be the case for every
> R distribution although it is true for some (possibly most) including
> the standard Windows distribution.
> 
> 
> --
> Statistics & Software Consulting
> GKX Group, GKX Associates Inc.
> tel: 1-877-GKX-GROUP
> email: ggrothendieck at gmail.com
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From ripley at stats.ox.ac.uk  Sun Jan 29 13:10:19 2012
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 29 Jan 2012 12:10:19 +0000
Subject: [Rd] tcltk GUIs (was need gui matrix editor: does R Core team
 have advice on	how?)
In-Reply-To: <002401ccde08$dc207100$94615300$@mcmaster.ca>
References: <CAErODj9ZMXTEbnSD-bRShAuXfXK6nBROFjt4UnadL-SkKFt4NA@mail.gmail.com>
	<CAP01uRk2O9bTDijvxLXRpnXihJFAZe4XS4NcQeN-KHOqhwf8rA@mail.gmail.com>
	<002401ccde08$dc207100$94615300$@mcmaster.ca>
Message-ID: <4F25372B.8020307@stats.ox.ac.uk>

On 28/01/2012 22:04, John Fox wrote:
> Dear Paul and Gabor,
>
> The Rcmdr GUI uses the tcltk package, so I have some experience with
> providing an R tcltk-based GUI for various platforms.
>
> As Gabor says, everything works very smoothly on Windows because the R
> Windows binary includes Tcl/Tk.

Maybe, but getting it there was very far from smooth.  Tcl/Tk compiled 
under the compilers we used, but the resulting DLLs crashed R.  No one 
has ever found the cause and I used the system SDK (essentiallly a 
version of VC++) to build them.  And that puts us in a bind since the 
current system SDKs generate code depending on DLLs that are not part of 
the minimal OS versions we support (e.g. Windows XP and Server 2003, and 
the machine used to build was retired 2 years ago).

> On Mac OS X, it's necessary for the user to
> install Tcl/Tk for X Windows and to insure that X Windows is installed (as
> it typically is in recent releases of Mac OS X). In my experience, most
> Linux users already have Tcl/Tk and X Windows (or if they don't, they're
> familiar with how to install software on their systems), so that things work
> smoothly there as well.
>
> The upshot of this is that Mac OS X is the platform that seems to generate
> the most problems for naive users, although installing Tcl/Tk for X Windows
> isn't that difficult. Take a look, e.g., at the Rcmdr installation notes
> <http://socserv.socsci.mcmaster.ca/jfox/Misc/Rcmdr/installation-notes.html>.

If this were really a problem it could be resolved with far less effort 
than was needed on Windows.  The X11 version of Tk is only needed to get 
R's tcltk to play under R.app.  For those wanting a Tk-based front end 
for command-line R, it is easy to build R against the Tcl/Tk which ships 
with OS X (or an update of it) and get fully Aqua-themed widgets.  If I 
want to show Rcmdr to a Mac user, that is what I use.

As various recent threads on R-sig-mac show, some useRs are capable of 
misconfiguring their Macs so that X11 does not work, does not find any 
fonts ... but maybe they could manage the same on any other Unix-alike.

> I hope this helps,
>   John
>
> --------------------------------
> John Fox
> Senator William McMaster
>    Professor of Social Statistics
> Department of Sociology
> McMaster University
> Hamilton, Ontario, Canada
> http://socserv.mcmaster.ca/jfox
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ggrothendieck at gmail.com  Sun Jan 29 16:18:28 2012
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sun, 29 Jan 2012 10:18:28 -0500
Subject: [Rd] tcltk GUIs (was need gui matrix editor: does R Core team
 have advice on how?)
In-Reply-To: <4F25372B.8020307@stats.ox.ac.uk>
References: <CAErODj9ZMXTEbnSD-bRShAuXfXK6nBROFjt4UnadL-SkKFt4NA@mail.gmail.com>
	<CAP01uRk2O9bTDijvxLXRpnXihJFAZe4XS4NcQeN-KHOqhwf8rA@mail.gmail.com>
	<002401ccde08$dc207100$94615300$@mcmaster.ca>
	<4F25372B.8020307@stats.ox.ac.uk>
Message-ID: <CAP01uRntZiV0TfYKtEvottFsJXGnxNemwOALtBiHqrfjWyd_yA@mail.gmail.com>

On Sun, Jan 29, 2012 at 7:10 AM, Prof Brian Ripley
<ripley at stats.ox.ac.uk> wrote:
> On 28/01/2012 22:04, John Fox wrote:
>>
>> Dear Paul and Gabor,
>>
>> The Rcmdr GUI uses the tcltk package, so I have some experience with
>> providing an R tcltk-based GUI for various platforms.
>>
>> As Gabor says, everything works very smoothly on Windows because the R
>> Windows binary includes Tcl/Tk.
>
>
> Maybe, but getting it there was very far from smooth. ?Tcl/Tk compiled under
> the compilers we used, but the resulting DLLs crashed R. ?No one has ever
> found the cause and I used the system SDK (essentiallly a version of VC++)
> to build them. ?And that puts us in a bind since the current system SDKs
> generate code depending on DLLs that are not part of the minimal OS versions
> we support (e.g. Windows XP and Server 2003, and the machine used to build
> was retired 2 years ago).
>
>> On Mac OS X, it's necessary for the user to
>> install Tcl/Tk for X Windows and to insure that X Windows is installed (as
>> it typically is in recent releases of Mac OS X). In my experience, most
>> Linux users already have Tcl/Tk and X Windows (or if they don't, they're
>> familiar with how to install software on their systems), so that things
>> work
>> smoothly there as well.
>>
>> The upshot of this is that Mac OS X is the platform that seems to generate
>> the most problems for naive users, although installing Tcl/Tk for X
>> Windows
>> isn't that difficult. Take a look, e.g., at the Rcmdr installation notes
>>
>> <http://socserv.socsci.mcmaster.ca/jfox/Misc/Rcmdr/installation-notes.html>.
>
>
> If this were really a problem it could be resolved with far less effort than
> was needed on Windows. ?The X11 version of Tk is only needed to get R's
> tcltk to play under R.app. ?For those wanting a Tk-based front end for
> command-line R, it is easy to build R against the Tcl/Tk which ships with OS
> X (or an update of it) and get fully Aqua-themed widgets. ?If I want to show
> Rcmdr to a Mac user, that is what I use.
>
> As various recent threads on R-sig-mac show, some useRs are capable of
> misconfiguring their Macs so that X11 does not work, does not find any fonts
> ... but maybe they could manage the same on any other Unix-alike.
>

Although it would be ideal if the tcltk package just worked out of the
box on every platform so that cross platform GUIs "just worked" if
that is too difficult to manage it would still be helpful if tcl
without tk "just worked" on every platform out of the box for other
applications not involving GUIs but still involving tcl.

-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From pauljohn32 at gmail.com  Sun Jan 29 23:35:05 2012
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Sun, 29 Jan 2012 16:35:05 -0600
Subject: [Rd] tcltk GUIs (was need gui matrix editor: does R Core team
 have advice on how?)
In-Reply-To: <4F25372B.8020307@stats.ox.ac.uk>
References: <CAErODj9ZMXTEbnSD-bRShAuXfXK6nBROFjt4UnadL-SkKFt4NA@mail.gmail.com>
	<CAP01uRk2O9bTDijvxLXRpnXihJFAZe4XS4NcQeN-KHOqhwf8rA@mail.gmail.com>
	<002401ccde08$dc207100$94615300$@mcmaster.ca>
	<4F25372B.8020307@stats.ox.ac.uk>
Message-ID: <CAErODj8-CMoQDJOcLTY0F=_-rT0fEkWDZ5Y5JKSGL1HRBq2epA@mail.gmail.com>

On Sun, Jan 29, 2012 at 6:10 AM, Prof Brian Ripley
<ripley at stats.ox.ac.uk> wrote:
> On 28/01/2012 22:04, John Fox wrote:
>>
>> Dear Paul and Gabor,
>>
>> The Rcmdr GUI uses the tcltk package, so I have some experience with
>> providing an R tcltk-based GUI for various platforms.
>>
>> As Gabor says, everything works very smoothly on Windows because the R
>> Windows binary includes Tcl/Tk.
>
>
> Maybe, but getting it there was very far from smooth. ?Tcl/Tk compiled under
> the compilers we used, but the resulting DLLs crashed R. ?No one has ever
> found the cause and I used the system SDK (essentiallly a version of VC++)
> to build them. ?And that puts us in a bind since the current system SDKs
> generate code depending on DLLs that are not part of the minimal OS versions
> we support (e.g. Windows XP and Server 2003, and the machine used to build
> was retired 2 years ago).
>

Thanks, this is clearing things up. I believe these comments mean
that, at the current time, tcl/tk is as close as there is to an
officially endorsed graphical toolkit.  As I search more, I find many
other community contributors (besides Prof. Fox) using tcl/tk
(Sciviews).  So I should learn how to work with that.  Prof Ripley's
comment makes me think the endorsement is not entirely enthusiastic,
though.

If there were a change to emphasize Gtk2, I don't think I would be
disappointed. I've been testing table-making examples today.  On
Debian Linux, I am having more luck with the Gtk2 based packages.
dfedit in RGtk2Extras "just works" for me. Example:

> library(RGtk2Extras)
> mat <- matrix(rnorm(100), 10, 10)
> dfedit(mat)

That edits the R object mat as expected.

On the other hand, I don't have success with the tk2edit from tcltk2,
even with the example in the help page:

> library(tcltk2)
Loading required package: tcltk
Loading Tcl/Tk interface ... done
> ?tk2edit
>   data(iris)
>      tk2edit(iris)
Error in matrix("", nrow = nrow(tA), ncol = ncol(tA)) :
  non-numeric matrix extent

I've fiddled with this quite a bit, I believe there's some little
mismatch between this particular system's tcl/tk libraries and the
ones that tcltk2 is expecting. Packaging of tcl/tk has caused lots of
trouble with Swarm simulations that we run, maybe that's breaking
tktable usage too.   I'm going to look into that some more.

I think the idea behind gWidgetstcltk is great, it aims to create R
functions that can use either Gtk2 or tclk.  But the implementation is
a big hassle, it seems to me.  It inherits all of the management
troubles of both tcltk and Gtk2. For example.

> library(gWidgetstcltk)
> mat <- matrix(rnorm(100), 10 , 10)
> gdf(mat)
Select a GUI toolkit

1: gWidgetsRGtk2
2: gWidgetstcltk

Selection: 2
guiWidget of type: NULL for toolkit: guiWidgetsToolkittcltk
Warning message:
In .gdf(toolkit, items = items, name = name, do.subset = do.subset,  :
  Container is not correct. No NULL containers possible

When I run the example at the end of the help from ?gdf in
gWidgetstcltk, I get this (even before trying to use the table at
all).

>    obj[,] <- head(mtcars) ## replace df
Error in `.leftBracket<-`(`*tmp*`, toolkit, ..., value = list(mpg = c(21,  :
  Value has different number of rows than the replacement area

If I make the other selection, opting for Gtk2, I don't get an error,
but nothing happens--no table pops up either.

> library(gWidgetstcltk)
> mat <- matrix(100, 10, 10)
> gdf(mat)
Select a GUI toolkit

1: gWidgetsRGtk2
2: gWidgetstcltk

Selection: 1
Loading required package: gWidgetsRGtk2
guiWidget of type: gGridRGtk for toolkit: guiWidgetsToolkitRGtk2

If I had not seen the Gtk2 table work well with RGtk2Extras, I'd have
no faith at all.

In conclusion, what am I supposed to work on?

If tcl/tk is likely to stay in the R for Windows package, then we can
work on streamlining the Macintosh and Windows instructions for tcltk
maintenance, then I see my mission now is to make TkTable based
widgets work.   Right?

Something Prof. Grothendieck said made me curious.  One can package
the TkTable library with an R package?  Why is it not already included
in packages like tcltk2 or gWidgetstcltk?

Debian package libtktable2.9 installs these files:

/usr/lib/Tktable2.9/libTktable2.9.so
/usr/lib/Tktable2.9/pkgIndex.tcl
/usr/lib/Tktable2.9/tkTable.tcl

So TkTable requries not just the tcl bit, but a shared library. Is
that a substantial roadblock to R packaging of TkTable? (I've never
tried it).

pj
-- 
Paul E. Johnson
Professor, Political Science
1541 Lilac Lane, Room 504
University of Kansas


From m.cowley at garvan.org.au  Mon Jan 30 00:23:52 2012
From: m.cowley at garvan.org.au (Mark Cowley)
Date: Mon, 30 Jan 2012 10:23:52 +1100
Subject: [Rd] Unable to reload Rdoc
In-Reply-To: <CAFDcVCQOGSFD0ZHPo6g+2Yx-JEFZVxFh0cf2Gi_Aj4N7OWeShQ@mail.gmail.com>
References: <5E2DFDD7-D68B-4B8B-915F-2ACFC08C4D94@garvan.org.au>
	<CABdHhvHYxxAuxpxEQJb5ztrbUs7pwWZZvBPACO3MTzidjwEy0g@mail.gmail.com>
	<CAFDcVCQOGSFD0ZHPo6g+2Yx-JEFZVxFh0cf2Gi_Aj4N7OWeShQ@mail.gmail.com>
Message-ID: <9AC21AED-E3A6-4EB3-A2A5-151A9819D31B@garvan.org.au>

Gentlemen,
Thanks for your insights, all 3 hints are very useful.

Mark
On 28/01/2012, at 8:29 AM, Henrik Bengtsson wrote:

> Related: To simplify reloading a help page after restarting R, I do
> have the following in my ~/.Rprofile:
> 
> # Always only the HTML help on the same port
> local({
>  port <- sum(c(1e3,10)*as.double(R.Version()[c("major", "minor")]));
>  ports <- 10*port + 0:9;
>  options(help.ports=ports);
> });
> 
> # Try to start HTML help server
> tryCatch({
>  if (interactive()) {
>    tools::startDynamicHelp();
>  }
> }, error = function(ex) {
>  print(ex);
> })
> 
> That way the URL for the help page remain the same (as long as you
> only run one R session) and the internal web server is up and running
> (no need for help.start()).
> 
> My $.02
> 
> /Henrik
> 
> On Fri, Jan 27, 2012 at 6:15 AM, Hadley Wickham <hadley at rice.edu> wrote:
>> On Fri, Jan 27, 2012 at 3:47 AM, Mark Cowley <m.cowley at garvan.org.au> wrote:
>>> Dear list,
>>> I'm hoping the R guru's can help with an error i've been getting for at least a year during active package development.
>>> 
>>> I have a package loaded & spot a documentation bug, so I:
>>> edit the Rd file (or in the roxygen header + roxygenize); then
>>> R CMD BUILD,
>>> R CMD INSTALL
>>> then in the same R session, reload the library & lookup a man page, I always get this error:
>>> Error in fetch(key) : internal error -3 in R_decompress1
>>> 
>>> I've tried all ways of reloading the package that i'm aware of:
>>> detach then library
>>> unloadNamespace then library
>>> devtools::install
>>> devtools::reload
>>> 
>>> all lead to the error.
>>> 
>>> I see from ?detach:
>>> ... So detaching and re-attaching a package may
>>> not refresh some or all components of the package, and is
>>> inadvisable.
>>> 
>>> restarting the R session results in loading the updated man file, but do you have any ideas how to word around this & continue within the same R session?
>>> 
>>> cheers,
>>> Mark
>>> 
>>> # 1) using Hadley's devtools
>>>> library(devtools)
>>>> library(updateR) # my package under development
>>>> install("~/src/R/updateR")
>> 
>> To avoid this problem, the latest version of devtools has show_rd(),
>> which allows you to preview an Rd file in R without having to
>> reinstall the package.  This was actually really simple to implement,
>> and I don't know why I didn't think of it ages ago - it's certainly
>> made my workflow much smoother.
>> 
>> Hadley
>> 
>> --
>> Assistant Professor / Dobelman Family Junior Chair
>> Department of Statistics / Rice University
>> http://had.co.nz/
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel


From simon.urbanek at r-project.org  Mon Jan 30 03:39:16 2012
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Sun, 29 Jan 2012 21:39:16 -0500
Subject: [Rd] tcltk GUIs (was need gui matrix editor: does R Core team
	have advice on how?)
In-Reply-To: <CAErODj8-CMoQDJOcLTY0F=_-rT0fEkWDZ5Y5JKSGL1HRBq2epA@mail.gmail.com>
References: <CAErODj9ZMXTEbnSD-bRShAuXfXK6nBROFjt4UnadL-SkKFt4NA@mail.gmail.com>
	<CAP01uRk2O9bTDijvxLXRpnXihJFAZe4XS4NcQeN-KHOqhwf8rA@mail.gmail.com>
	<002401ccde08$dc207100$94615300$@mcmaster.ca>
	<4F25372B.8020307@stats.ox.ac.uk>
	<CAErODj8-CMoQDJOcLTY0F=_-rT0fEkWDZ5Y5JKSGL1HRBq2epA@mail.gmail.com>
Message-ID: <3D6458BE-D37C-4340-AD45-79D3A29D6DD2@r-project.org>


On Jan 29, 2012, at 5:35 PM, Paul Johnson wrote:

> On Sun, Jan 29, 2012 at 6:10 AM, Prof Brian Ripley
> <ripley at stats.ox.ac.uk> wrote:
>> On 28/01/2012 22:04, John Fox wrote:
>>> 
>>> Dear Paul and Gabor,
>>> 
>>> The Rcmdr GUI uses the tcltk package, so I have some experience with
>>> providing an R tcltk-based GUI for various platforms.
>>> 
>>> As Gabor says, everything works very smoothly on Windows because the R
>>> Windows binary includes Tcl/Tk.
>> 
>> 
>> Maybe, but getting it there was very far from smooth.  Tcl/Tk compiled under
>> the compilers we used, but the resulting DLLs crashed R.  No one has ever
>> found the cause and I used the system SDK (essentiallly a version of VC++)
>> to build them.  And that puts us in a bind since the current system SDKs
>> generate code depending on DLLs that are not part of the minimal OS versions
>> we support (e.g. Windows XP and Server 2003, and the machine used to build
>> was retired 2 years ago).
>> 
> 
> Thanks, this is clearing things up. I believe these comments mean
> that, at the current time, tcl/tk is as close as there is to an
> officially endorsed graphical toolkit.  As I search more, I find many
> other community contributors (besides Prof. Fox) using tcl/tk
> (Sciviews).  So I should learn how to work with that.  Prof Ripley's
> comment makes me think the endorsement is not entirely enthusiastic,
> though.
> 

I can certainly second that (but I may be biased by having to deal with its infelicities - I would also prefer to have a working native toolkit in the binary distribution). Tcl/Tk is not a graphical toolkit, it is a language that happens to support some kind of graphical interface but I would certainly not recommend it as a GUI toolkit. My interpretation is that its presence in R is purely historical (it was an option that someone wrote code for at the time). That said, given the lack of choices, a lot of code was based on it. Now with the advent of packages, you have the choice - there are many toolkits you can choose from now.

This is just my $0.02, not an "official" endorsement ;).

Cheers,
Simon



> If there were a change to emphasize Gtk2, I don't think I would be
> disappointed. I've been testing table-making examples today.  On
> Debian Linux, I am having more luck with the Gtk2 based packages.
> dfedit in RGtk2Extras "just works" for me. Example:
> 
>> library(RGtk2Extras)
>> mat <- matrix(rnorm(100), 10, 10)
>> dfedit(mat)
> 
> That edits the R object mat as expected.
> 
> On the other hand, I don't have success with the tk2edit from tcltk2,
> even with the example in the help page:
> 
>> library(tcltk2)
> Loading required package: tcltk
> Loading Tcl/Tk interface ... done
>> ?tk2edit
>>  data(iris)
>>     tk2edit(iris)
> Error in matrix("", nrow = nrow(tA), ncol = ncol(tA)) :
>  non-numeric matrix extent
> 
> I've fiddled with this quite a bit, I believe there's some little
> mismatch between this particular system's tcl/tk libraries and the
> ones that tcltk2 is expecting. Packaging of tcl/tk has caused lots of
> trouble with Swarm simulations that we run, maybe that's breaking
> tktable usage too.   I'm going to look into that some more.
> 
> I think the idea behind gWidgetstcltk is great, it aims to create R
> functions that can use either Gtk2 or tclk.  But the implementation is
> a big hassle, it seems to me.  It inherits all of the management
> troubles of both tcltk and Gtk2. For example.
> 
>> library(gWidgetstcltk)
>> mat <- matrix(rnorm(100), 10 , 10)
>> gdf(mat)
> Select a GUI toolkit
> 
> 1: gWidgetsRGtk2
> 2: gWidgetstcltk
> 
> Selection: 2
> guiWidget of type: NULL for toolkit: guiWidgetsToolkittcltk
> Warning message:
> In .gdf(toolkit, items = items, name = name, do.subset = do.subset,  :
>  Container is not correct. No NULL containers possible
> 
> When I run the example at the end of the help from ?gdf in
> gWidgetstcltk, I get this (even before trying to use the table at
> all).
> 
>>   obj[,] <- head(mtcars) ## replace df
> Error in `.leftBracket<-`(`*tmp*`, toolkit, ..., value = list(mpg = c(21,  :
>  Value has different number of rows than the replacement area
> 
> If I make the other selection, opting for Gtk2, I don't get an error,
> but nothing happens--no table pops up either.
> 
>> library(gWidgetstcltk)
>> mat <- matrix(100, 10, 10)
>> gdf(mat)
> Select a GUI toolkit
> 
> 1: gWidgetsRGtk2
> 2: gWidgetstcltk
> 
> Selection: 1
> Loading required package: gWidgetsRGtk2
> guiWidget of type: gGridRGtk for toolkit: guiWidgetsToolkitRGtk2
> 
> If I had not seen the Gtk2 table work well with RGtk2Extras, I'd have
> no faith at all.
> 
> In conclusion, what am I supposed to work on?
> 
> If tcl/tk is likely to stay in the R for Windows package, then we can
> work on streamlining the Macintosh and Windows instructions for tcltk
> maintenance, then I see my mission now is to make TkTable based
> widgets work.   Right?
> 
> Something Prof. Grothendieck said made me curious.  One can package
> the TkTable library with an R package?  Why is it not already included
> in packages like tcltk2 or gWidgetstcltk?
> 
> Debian package libtktable2.9 installs these files:
> 
> /usr/lib/Tktable2.9/libTktable2.9.so
> /usr/lib/Tktable2.9/pkgIndex.tcl
> /usr/lib/Tktable2.9/tkTable.tcl
> 
> So TkTable requries not just the tcl bit, but a shared library. Is
> that a substantial roadblock to R packaging of TkTable? (I've never
> tried it).
> 
> pj
> -- 
> Paul E. Johnson
> Professor, Political Science
> 1541 Lilac Lane, Room 504
> University of Kansas
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From jverzani at gmail.com  Mon Jan 30 03:29:53 2012
From: jverzani at gmail.com (j verzani)
Date: Mon, 30 Jan 2012 02:29:53 +0000
Subject: [Rd] tcltk GUIs (was need gui matrix editor: does R Core team
	have advice on how?)
References: <CAErODj9ZMXTEbnSD-bRShAuXfXK6nBROFjt4UnadL-SkKFt4NA@mail.gmail.com>
	<CAP01uRk2O9bTDijvxLXRpnXihJFAZe4XS4NcQeN-KHOqhwf8rA@mail.gmail.com>
	<002401ccde08$dc207100$94615300$@mcmaster.ca>
	<4F25372B.8020307@stats.ox.ac.uk>
	<CAErODj8-CMoQDJOcLTY0F=_-rT0fEkWDZ5Y5JKSGL1HRBq2epA@mail.gmail.com>
Message-ID: <loom.20120130T030953-702@post.gmane.org>

Paul Johnson <pauljohn32 <at> gmail.com> writes:


.. snip ..



> I think the idea behind gWidgetstcltk is great, it aims to create R
> functions that can use either Gtk2 or tclk.  But the implementation is
> a big hassle, it seems to me.  It inherits all of the management
> troubles of both tcltk and Gtk2. For example.
> 
> > library(gWidgetstcltk)
> > mat <- matrix(rnorm(100), 10 , 10)
> > gdf(mat)
> Select a GUI toolkit
> 
> 1: gWidgetsRGtk2
> 2: gWidgetstcltk
> 
> Selection: 2
> guiWidget of type: NULL for toolkit: guiWidgetsToolkittcltk
> Warning message:
> In .gdf(toolkit, items = items, name = name, do.subset = do.subset,  :
>   Container is not correct. No NULL containers possible
> 

Although, this discussion is better suited for the GUIs list,
I'll weigh in a bit on the gWidgets discussion here, but first note
that Tom Taverner spent a lot of time on the the table editor
inRGtk2Extras.  It is by far the most like a spread sheet.


The gdf(mat) call requires a parent container, e.g. gdf(mat,
container=gwindow()). You would also want to save the object so you
can manipulate the edited values.


> When I run the example at the end of the help from ?gdf in
> gWidgetstcltk, I get this (even before trying to use the table at
> all).
> 
> >    obj[,] <- head(mtcars) ## replace df
> Error in `.leftBracket<-`(`*tmp*`, toolkit, ..., value = list(mpg = c(21,  :
>   Value has different number of rows than the replacement area
> 


The table implementation varies widely among the toolkits. The tcltk
one uses tkTable and I didn't spend a lot of time on this. I just
copied the implementation in tcltk2. As implemented here, this basic
one doesn't let you adjust rows and columns, just edit them.

The in-progress gWidgets2tcltk (on github) avoids the extra library by
creating a row editor. Not the most natural, but it can do more of
this type of thing.


.. snip ..

> In conclusion, what am I supposed to work on?
> 

Well, tcltk is the easiest to install. RGtk2 has the nicest table
editor. Qt isn't ready for windows users, but has the best table
widget of all the three. You also have a nice editor in JGR, which
uses rjava. Your choice, but you haven't mentioned the most universal
of all -- the web browser.

You could leverage R's help server (say with Rook) and create a form
to edit.  You could even use gWidgetsWWW2 and take advantage of Ext's
table editor which isn't bad, though you have to specify the size
ahead of time. (Well even here you have issues. The in-progress
version (again on github) isn't working with IE until Ext
stabilizes...)


From henrik.alsing.friberg at mosek.com  Mon Jan 30 09:04:11 2012
From: henrik.alsing.friberg at mosek.com (Henrik Alsing Friberg)
Date: Mon, 30 Jan 2012 09:04:11 +0100
Subject: [Rd] Deprecation of "--min-nsize" and "--min-vsize"
Message-ID: <CAETHZs14bscmR6pCto3-+WZrMSUqjNdp6XzAYV1T+oD-Y1s6wg@mail.gmail.com>

Hi R-devel,

I only run the released version of R where "--min-nsize" and
"--min-vsize" have now been deprecated, and am told that this
functionality has been removed in the dev-version. However, having R
not repeatedly ask the operating system for more memory while
executing, and raising the "gc trigger" level so that garbage
collection is postproned, is a time-wise effective way of running R
scripts. Of course, you need a system that can handle the larger
memory footprint.

Here is an example:
----------------------------------------------
gc(); system.time({
  N  = 2000000;
  SUBLENGTH <- rep(3, N);
  CONEVAL <- matrix(1:(3*N), ncol=3);

  cones <- matrix(list(), nrow=2, ncol=N, dimnames=list(c("type","sub"),c()));
  for (i in 1:N) {
    cones[,i] <- list("MSK_CT_QUAD", CONEVAL[i,]);
  }
}) gc();
----------------------------------------------

Normal execution:
   user  system elapsed
 28.030   0.190  28.238

With high values of "--min-nsize" and "--min-vsize":
   user  system elapsed
 10.330   1.130  11.464

So the effect is a factor 2 to 3. I agree that these arguments are too
technical for the average user and that you would rarely really need
them, but it would be nice to have an easy way of speeding up R
scripts. Also, setting high values of "--min-nsize" and "--min-vsize"
gives more consistent system.time() results when more methods are
tested after each other, because garbage collection and the
availability of memory in the R process does not interfere.

Take this as a thought, and not a need-to-have from my side..

Kind regards,
Henrik


From kevin.r.coombes at gmail.com  Mon Jan 30 15:17:36 2012
From: kevin.r.coombes at gmail.com (Kevin R. Coombes)
Date: Mon, 30 Jan 2012 08:17:36 -0600
Subject: [Rd] tcltk GUIs (was need gui matrix editor: does R Core team
 have advice on how?)
In-Reply-To: <CAErODj8-CMoQDJOcLTY0F=_-rT0fEkWDZ5Y5JKSGL1HRBq2epA@mail.gmail.com>
References: <CAErODj9ZMXTEbnSD-bRShAuXfXK6nBROFjt4UnadL-SkKFt4NA@mail.gmail.com>
	<CAP01uRk2O9bTDijvxLXRpnXihJFAZe4XS4NcQeN-KHOqhwf8rA@mail.gmail.com>
	<002401ccde08$dc207100$94615300$@mcmaster.ca>
	<4F25372B.8020307@stats.ox.ac.uk>
	<CAErODj8-CMoQDJOcLTY0F=_-rT0fEkWDZ5Y5JKSGL1HRBq2epA@mail.gmail.com>
Message-ID: <4F26A680.10706@gmail.com>



On 1/29/2012 4:35 PM, Paul Johnson wrote:
> On Sun, Jan 29, 2012 at 6:10 AM, Prof Brian Ripley
> <ripley at stats.ox.ac.uk>  wrote:
>> On 28/01/2012 22:04, John Fox wrote:
>>> Dear Paul and Gabor,
>>>
>>> The Rcmdr GUI uses the tcltk package, so I have some experience with
>>> providing an R tcltk-based GUI for various platforms.
>>>
>>> As Gabor says, everything works very smoothly on Windows because the R
>>> Windows binary includes Tcl/Tk.
>>
>> Maybe, but getting it there was very far from smooth.  Tcl/Tk compiled under
>> the compilers we used, but the resulting DLLs crashed R.  No one has ever
>> found the cause and I used the system SDK (essentiallly a version of VC++)
>> to build them.  And that puts us in a bind since the current system SDKs
>> generate code depending on DLLs that are not part of the minimal OS versions
>> we support (e.g. Windows XP and Server 2003, and the machine used to build
>> was retired 2 years ago).
>>
> Thanks, this is clearing things up. I believe these comments mean
> that, at the current time, tcl/tk is as close as there is to an
> officially endorsed graphical toolkit.  As I search more, I find many
> other community contributors (besides Prof. Fox) using tcl/tk
> (Sciviews).  So I should learn how to work with that.  Prof Ripley's
> comment makes me think the endorsement is not entirely enthusiastic,
> though.
There's this famous quotation from Winston Churchill: "it has been said 
that democracy is the worst form of government except all those other 
forms that have been tried."

Using Tcl/Tk in R is similar.  It's there, and the R Core team (mostly) 
makes sure it works cross-platform, so it is the obvious choice for GUI 
development in R.  But it is far from perfect.  For one thing, the 
documentation in R is quite limited.  The manual pages list all of the 
functions in the tcltk package, but they basically take "..." as their 
arguments.  As a result, you sometimes have to guess how to get the 
inputs formatted correctly to pass them back-and-forth between the R 
process and the Tcl/Tk process (which have very different syntax).  For 
another thing, communication between the two processes (at least on 
Windows) sometimes breaks down in non-reproducible and hard-to-debug 
ways.  We built a tcltk GUI that uses a tabbed notebook interface, which 
is supposed to display five tabs.  Most of the time, it does.  But it 
can end up displaying anything from 1 to 5 tabs.  It always displays 
them in order, so it apparently runs into a problem at some random point 
and stops.  Closing the GUi and restarting it usually fixes the 
problem.  Since we cannot trigger it reproducibly, we have never found 
the underlying source of the problem.

This message is not meant to dissuade you from using Tcl/Tk.  It's just 
a warning to expect some bumps along the way....

Good luck,
     Kevin


From Gael.Millot at curie.fr  Mon Jan 30 15:46:55 2012
From: Gael.Millot at curie.fr (Millot Gael)
Date: Mon, 30 Jan 2012 14:46:55 +0000
Subject: [Rd] Help page of colors() : add a new example ?
Message-ID: <D62EEDC839E38446B9F9378AFA4408E907FB1299@mbxparis02.recherche.curie.fr>

Dear all,

May I suggest to add an example in the help page of the colors() function ?
The following code could be useful to easily choose any color from colors() :

## Millot G. (2011), p.71.
## Figure displaying all the 657 built-in color names of colors().
palette(colors())
tempo<-NULL
for(i in 14:1){tempo<-c(tempo, rep(i,50))}
windows(width=10) # replace by quartz(width=10) for MacOS and by X11(width=10) for Linux
par(ann=FALSE, xaxt="n", yaxt="n", bty="n")
plot(rep(1:50,14)[1:657], tempo[1:657], pch=22, bg=1:657, cex=1.5, bty="n")
par(xpd=TRUE)
axis(side=2, at=14:1, labels=, cex.axis=1.5, srt=90)
text(rep(-2, 14), 14:1, as.character((0:13)*50+1), srt=0, cex=1)
text(c(10,20,30,40,50), rep(-0.5,5), c(10,20,30,40,50), srt=0, cex=1)

## palette(colors()) allow to replace the color names by the numbers indicated
## in the figure.
palette(colors())
plot(1, col=630, pch=16, cex=10) # 630 is "tomato"

This code comes from the page 71 of the book I published in french:
Millot G. Comprendre et r?aliser les tests statistiques ? l'aide de R, 2nd edition. De Boeck editions, Bruxelles . 2011, 767 pages.

I wrote it since my students usually complain about the difficulty to select a color
from colors() when the names are displayed.

Kind regards,

Gael Millot.


From murdoch.duncan at gmail.com  Mon Jan 30 16:13:15 2012
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 30 Jan 2012 10:13:15 -0500
Subject: [Rd] tcltk GUIs (was need gui matrix editor: does R Core team
 have advice on how?)
In-Reply-To: <4F26A680.10706@gmail.com>
References: <CAErODj9ZMXTEbnSD-bRShAuXfXK6nBROFjt4UnadL-SkKFt4NA@mail.gmail.com>	<CAP01uRk2O9bTDijvxLXRpnXihJFAZe4XS4NcQeN-KHOqhwf8rA@mail.gmail.com>	<002401ccde08$dc207100$94615300$@mcmaster.ca>	<4F25372B.8020307@stats.ox.ac.uk>	<CAErODj8-CMoQDJOcLTY0F=_-rT0fEkWDZ5Y5JKSGL1HRBq2epA@mail.gmail.com>
	<4F26A680.10706@gmail.com>
Message-ID: <4F26B38B.5040808@gmail.com>

On 30/01/2012 9:17 AM, Kevin R. Coombes wrote:
>
> On 1/29/2012 4:35 PM, Paul Johnson wrote:
> >  On Sun, Jan 29, 2012 at 6:10 AM, Prof Brian Ripley
> >  <ripley at stats.ox.ac.uk>   wrote:
> >>  On 28/01/2012 22:04, John Fox wrote:
> >>>  Dear Paul and Gabor,
> >>>
> >>>  The Rcmdr GUI uses the tcltk package, so I have some experience with
> >>>  providing an R tcltk-based GUI for various platforms.
> >>>
> >>>  As Gabor says, everything works very smoothly on Windows because the R
> >>>  Windows binary includes Tcl/Tk.
> >>
> >>  Maybe, but getting it there was very far from smooth.  Tcl/Tk compiled under
> >>  the compilers we used, but the resulting DLLs crashed R.  No one has ever
> >>  found the cause and I used the system SDK (essentiallly a version of VC++)
> >>  to build them.  And that puts us in a bind since the current system SDKs
> >>  generate code depending on DLLs that are not part of the minimal OS versions
> >>  we support (e.g. Windows XP and Server 2003, and the machine used to build
> >>  was retired 2 years ago).
> >>
> >  Thanks, this is clearing things up. I believe these comments mean
> >  that, at the current time, tcl/tk is as close as there is to an
> >  officially endorsed graphical toolkit.  As I search more, I find many
> >  other community contributors (besides Prof. Fox) using tcl/tk
> >  (Sciviews).  So I should learn how to work with that.  Prof Ripley's
> >  comment makes me think the endorsement is not entirely enthusiastic,
> >  though.
> There's this famous quotation from Winston Churchill: "it has been said
> that democracy is the worst form of government except all those other
> forms that have been tried."
>
> Using Tcl/Tk in R is similar.  It's there, and the R Core team (mostly)
> makes sure it works cross-platform, so it is the obvious choice for GUI
> development in R.  But it is far from perfect.  For one thing, the
> documentation in R is quite limited.  The manual pages list all of the
> functions in the tcltk package, but they basically take "..." as their
> arguments.  As a result, you sometimes have to guess how to get the
> inputs formatted correctly to pass them back-and-forth between the R
> process and the Tcl/Tk process (which have very different syntax).  For
> another thing, communication between the two processes (at least on
> Windows) sometimes breaks down in non-reproducible and hard-to-debug
> ways.  We built a tcltk GUI that uses a tabbed notebook interface, which
> is supposed to display five tabs.  Most of the time, it does.  But it
> can end up displaying anything from 1 to 5 tabs.  It always displays
> them in order, so it apparently runs into a problem at some random point
> and stops.  Closing the GUi and restarting it usually fixes the
> problem.  Since we cannot trigger it reproducibly, we have never found
> the underlying source of the problem.
>
> This message is not meant to dissuade you from using Tcl/Tk.  It's just
> a warning to expect some bumps along the way....

Just one addition:  the full Tcl/Tk documentation should be available to 
most users.  It is included in the Windows distribution (and referenced 
from the ?tcltk help page) and I would guess other platforms install it 
when they install Tcl/Tk.  It is written assuming that you're writing in 
Tcl rather than R, but once you work out the translation, it's actually 
somewhat usable.

Duncan Murdoch


From matthieu.stigler at gmail.com  Mon Jan 30 18:24:24 2012
From: matthieu.stigler at gmail.com (Matthieu Stigler)
Date: Mon, 30 Jan 2012 18:24:24 +0100
Subject: [Rd] zip() containing windows specific code?
Message-ID: <4F26D248.4070009@gmail.com>

Dear R devel list

I was wondering whether zip() contains a windows specific call to 
system(), as the argument "invisible"  seems to be windows specific, yet 
is used anytime by zip:

invisible(system2(zip, args, invisible = TRUE))


Indeed, calling zip() on Linux results in a warning message:

>  file.create("try")

[1] TRUE

>  zip("try.zip", "try")

   adding: try (stored 0%)

Message d'avis :

In system2(zip, args, invisible = TRUE) :

   arguments 'minimized' and 'invisible' are for Windows only

>  unlink("try")


Best

Matthieu

 > sessionInfo()
R version 2.14.1 (2011-12-22)
Platform: x86_64-pc-linux-gnu (64-bit)

locale:
  [1] LC_CTYPE=fr_FR.UTF-8       LC_NUMERIC=C
  [3] LC_TIME=fr_FR.UTF-8        LC_COLLATE=fr_FR.UTF-8
  [5] LC_MONETARY=fr_FR.UTF-8    LC_MESSAGES=en_US.utf8
  [7] LC_PAPER=C                 LC_NAME=C
  [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=fr_FR.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] colorout_0.9-9


From manuel.lopez-ibanez at ulb.ac.be  Mon Jan 30 18:24:30 2012
From: manuel.lopez-ibanez at ulb.ac.be (=?ISO-8859-1?Q?Manuel_L=F3pez-Ib=E1=F1ez?=)
Date: Mon, 30 Jan 2012 18:24:30 +0100
Subject: [Rd] panel.first for bxp
Message-ID: <4F26D24E.9030508@ulb.ac.be>

I am intrigued why bxp does not support panel.first in order to draw a grid 
behind the boxplots. The advice given here:

https://stat.ethz.ch/pipermail/r-help/2006-April/104608.html

seems utterly bogus, and the result is noticeably different in PDF.

I would propose the following patch, which follows what is done for 
plot.default. If it is ok, I can produce also patches for the documentation.

Please apply to:

https://svn.r-project.org/R/trunk/src/library/graphics/R/boxplot.R

Cheers,
	Manuel.


-------------- next part --------------
A non-text attachment was scrubbed...
Name: bxp-panel-first.patch
Type: text/x-diff
Size: 824 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20120130/273132e0/attachment.bin>

From kevin.r.coombes at gmail.com  Mon Jan 30 19:07:59 2012
From: kevin.r.coombes at gmail.com (Kevin R. Coombes)
Date: Mon, 30 Jan 2012 12:07:59 -0600
Subject: [Rd] Sweave driver extension
In-Reply-To: <CANROs4f+ObUuxTN5hvdbWhZbuTwL_Gdq1GQCXKnM2taWDrzQ7Q@mail.gmail.com>
References: <1327434615.8525.38.camel@nemo>
	<CANROs4f+ObUuxTN5hvdbWhZbuTwL_Gdq1GQCXKnM2taWDrzQ7Q@mail.gmail.com>
Message-ID: <4F26DC7F.7040903@gmail.com>

I prefer the code chunks myself.

Function calls have overhead. In a bioinformatics world with large 
datasets and an R default that uses call-by-value rather than 
call-by-reference, the function calls may have a _lot_ of overhead.  
Writing the functions to make sure they use call-by-reference for the 
large objects instead has a different kind of overhead in the stress it 
puts on the writers and maintainers of code.

But then, I'm old enough to have looked at some of Knuth's source code 
for TeX and read his book on Literate Programming, where the ideas of 
"weave" and "tangle" were created for exactly the kind of application 
that Terry asked about.  Knuth's fundamental idea here is that the 
documentation (mainly the stuff processed through "weave") is created 
for humans, while the executable code (in Knuth's view, the stuff 
created by "tangle") is intended for computers.  If you want people to 
understand the code, then you often want to use a top-down approach that 
outlines the structure -- code chunks with forward references work 
perfectly for this purpose.

One of the difficulties in mapping Knuth's idea over to R and Sweave is 
that the operations of weave and tangle have gotten, well, tangled.  
Sweave does not just prepare the documentation; it also executes the 
code in order to put the results of the computation into the 
documentation.  In order to get the forward references to work with 
Sweave, you would have to makes two passes through the file: one to make 
sure you know where each named chunk is and build a cross-reference 
table, and one to actually execute the code in the correct order.  That 
would presumably also require a major rewrite of Sweave.

The solution I use is to cheat and hide the chunks initially and reveal 
them later to get the output that want. This comes down to combining 
eval, echo, keep.source, and expand in the right combinations. Something 
like:

%%%%%%%%
% set up a prologue that contains the code chunks. Do not evaluate or 
display them.
<<coxme-check-arguments,echo=FALSE,eval=FALSE>>=
# do something sensible. If multiple steps, define them above here
# using the same idea.
@
% also define the other code chunks here

\section{Start the First Section}

The \texttt{coxme} function is defined as follows:
<<coxme,keep.source=TRUE,expand=FALSE>>=
coxme <- function(formula, data, subset, blah blah  ){
<<coxme-check-arguments>>
<<coxme-build>>
<<coxme-compute>>
<<coxme-finish>>
}
@

Argument checking is important:
<<name-does-not-matter-since-not-reused,eval=FALSE,expand=TRUE>>=
<<coxme-check-arguments>>=
@
% Describe the other chunks here

%%%%%%%%


     Kevin

On 1/24/2012 10:24 PM, Yihui Xie wrote:
> Maybe this is a my personal taste: I do not like pseudo R code in the
> form<<coxme-build>>  inside a chunk, and I'm curious about why you do
> not use real R functions to do the job.
>
> coxme<- function(formula, data, subset, blah blah  ){
>    coxme_check_arguments(...)
>    coxme_build(...)
>    coxme_compute(...)
>    coxme_finish(...)
> }
>
> You can define these coxme_xxx functions later in the parent
> environment. It is also easy for one function to call another, so the
> recursion is natural. Compared to text-processing tricks, I prefer
> well-defined functions.
>
> Your idea of using a named list to store R code is what I used in the
> knitr package (http://yihui.github.com/knitr/demo/reference/), e.g.
>
> % empty here
> <<chunk1, echo=TRUE>>=
> @
>
> % real code is defined here
> <<chunk1, echo=FALSE>>=
> rnorm(10)
> @
>
> The second chunk appears later, but when you weave the document, the
> code rnorm(10) will also go to the first chunk since the label
> 'chunk1' will index the code from the second chunk.
>
> Regards,
> Yihui
> --
> Yihui Xie<xieyihui at gmail.com>
> Phone: 515-294-2465 Web: http://yihui.name
> Department of Statistics, Iowa State University
> 2215 Snedecor Hall, Ames, IA
>
>
>
> On Tue, Jan 24, 2012 at 1:50 PM, Terry Therneau<therneau at mayo.edu>  wrote:
>> Almost all of the coxme package and an increasing amount of the survival
>> package are now written in noweb, i.e., .Rnw files.  It would be nice to
>> process these using the Sweave function + a special driver, which I can
>> do using a modified version of Sweave.  The primary change is to allow
>> the following type of construction
>>
>> <<coxme>>
>> coxme<- function(formula, data, subset, blah blah  ){
>>    <<coxme-check-arguments>>
>>    <<coxme-build>>
>>    <<coxme-compute>>
>>    <<coxme-finish>>
>> }
>> @
>>
>> where the parts referred to come later, and will themselves be made up
>> of other parts.  Since the point of this file is to document source
>> code, the order in which chunks are defined is driven by "create a
>> textbook" thoughts and won't match the final code order for R.
>> The standard noweb driver only allows one level of recursion, and no
>> references to things defined further down in the file.
>>
>>   The primary change to the function simply breaks the main loop into
>> two parts: first read through the all the lines and create a list of
>> code chunks (some with names), then go through the list of chunks and
>> call driver routines.  There are a couple of other minor details, e.g. a
>> precheck for infinite recursions, but no change to what is passed to the
>> driver routines, nor to anything but the Sweave function itself.
>>
>> Primary question: who on the core team should I be holding this
>> conversation with?
>> Secondary: Testing level?  I have a few vignettes but not many.
>>     I'll need a "noweb" package anyway to contain the drivers -- should
>> we just duplicate the modified Sweave under another name?
>>     Call the package "noweb", "Rnoweb", ...?
>>
>> And before someone asks: Roxygen is a completely different animal and
>> doesn't address what I need.  I have latex equations just above the code
>> that impliments them, an annotated graph of the call tree next to the
>> section parsing a formula, etc. This is stuff that doesn't fit in
>> comment lines. The text/code ratio is>1.  On the other hand I've
>> thought very little about integration of manual pages and description
>> files with the code, issues which Roxygen addresses.
>>
>> Terry Therneau
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From ripley at stats.ox.ac.uk  Mon Jan 30 19:11:30 2012
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 30 Jan 2012 18:11:30 +0000
Subject: [Rd] zip() containing windows specific code?
In-Reply-To: <4F26D248.4070009@gmail.com>
References: <4F26D248.4070009@gmail.com>
Message-ID: <4F26DD52.8050601@stats.ox.ac.uk>

On 30/01/2012 17:24, Matthieu Stigler wrote:
> Dear R devel list
>
> I was wondering whether zip() contains a windows specific call to
> system(),

Actually, it does not contain a call to system() ....

as the argument "invisible" seems to be windows specific, yet
> is used anytime by zip:

And what is your problem here?  R ignores the arguments to systems() 
where not needed.

> invisible(system2(zip, args, invisible = TRUE))
>
>
> Indeed, calling zip() on Linux results in a warning message:
>
>> file.create("try")
>
> [1] TRUE
>
>> zip("try.zip", "try")
>
> adding: try (stored 0%)
>
> Message d'avis :
>
> In system2(zip, args, invisible = TRUE) :
>
> arguments 'minimized' and 'invisible' are for Windows only
>
>> unlink("try")
>
>
> Best
>
> Matthieu
>
>  > sessionInfo()
> R version 2.14.1 (2011-12-22)
> Platform: x86_64-pc-linux-gnu (64-bit)
>
> locale:
> [1] LC_CTYPE=fr_FR.UTF-8 LC_NUMERIC=C
> [3] LC_TIME=fr_FR.UTF-8 LC_COLLATE=fr_FR.UTF-8
> [5] LC_MONETARY=fr_FR.UTF-8 LC_MESSAGES=en_US.utf8
> [7] LC_PAPER=C LC_NAME=C
> [9] LC_ADDRESS=C LC_TELEPHONE=C
> [11] LC_MEASUREMENT=fr_FR.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats graphics grDevices utils datasets methods base
>
> other attached packages:
> [1] colorout_0.9-9
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From kw.stat at gmail.com  Mon Jan 30 19:27:36 2012
From: kw.stat at gmail.com (Kevin Wright)
Date: Mon, 30 Jan 2012 12:27:36 -0600
Subject: [Rd] Help page of colors() : add a new example ?
In-Reply-To: <D62EEDC839E38446B9F9378AFA4408E907FB1299@mbxparis02.recherche.curie.fr>
References: <D62EEDC839E38446B9F9378AFA4408E907FB1299@mbxparis02.recherche.curie.fr>
Message-ID: <CAKFxdiS5x03o=5W_eY81Q056g5xNLOJGH5g1TCv1fuxM-zU76A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20120130/0e06fefa/attachment.pl>

From murdoch.duncan at gmail.com  Mon Jan 30 19:53:04 2012
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 30 Jan 2012 13:53:04 -0500
Subject: [Rd] Numerical instability in new R Windows development version
In-Reply-To: <CAML4n3MNRsp_kTpPHarDh7_kLCVwGZJkweOxkoo6S8OMwENfjg@mail.gmail.com>
References: <CAML4n3MNRsp_kTpPHarDh7_kLCVwGZJkweOxkoo6S8OMwENfjg@mail.gmail.com>
Message-ID: <4F26E710.1060907@gmail.com>

This did turn out to be a bug in the new toolchain, and Brian Ripley has 
devised a patch and put together a new one.  I've uploaded a new 
Rtools215.exe, which should be available for download tomorrow, and 
builds of R-patched and R-devel will soon use it.  Everything takes a 
while to propagate to the volunteers and systems that build binaries and 
the mirrors, but we should all be up to date by the end of the week or so.

Thanks for the report!

Duncan Murdoch


On 27/01/2012 7:23 AM, Hans W Borchers wrote:
> I have a question concerning the new Windows toolchain for R>= 2.14.2.
> When trying out my package 'pracma' on the win-builder development version
> it will stop with the following error message:
>
>    >  f3<- function(x, y) sqrt((1 - (x^2 + y^2)) * (x^2 + y^2<= 1))
>    >  dblquad(f3, -1, 1, -1, 1)     #   2.094395124 , i.e. 2/3*pi , err = 2e-8
>    Warning in sqrt((1 - (x^2 + y^2)) * (x^2 + y^2<= 1)) : NaNs produced
>    Warning in sqrt((1 - (x^2 + y^2)) * (x^2 + y^2<= 1)) : NaNs produced
>    Error in integrate(function(y) f(x, y), ya, yb, subdivisions = subdivs,  :
>      non-finite function value
>    Calls: dblquad ...
>           <Anonymous>  ->  f ->  do.call ->  mapply ->  <Anonymous>  ->  integrate
>    Execution halted
>    ** running examples for arch 'x64' ... ERROR
>    Running examples in 'pracma-Ex.R' failed
>
> This probably means that the following expression got negative for some
> values x, y:
>
>    (1 - (x^2 + y^2)) * (x^2 + y^2<= 1)
>
> It appears to be an often used trick in numerical analysis. One advantage is
> that a function using it is immediately vectorized while an expression such
> as, e.g., "max(0, 1 - (x^2 + y^2))" is not.
>
> The example runs fine on Debian Linux and Mac OS X 32-/64-bit architectures.
> In my understanding the approach is correct and, as said above, often used in
> numerical applications.
>
> Can someone explain to me why this fails for the Windows 64-bit compiler and
> what I should use instead. Thanks.
>
> Hans Werner Borchers
> ABB Corporate Research
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From djmuser at gmail.com  Mon Jan 30 19:51:08 2012
From: djmuser at gmail.com (Dennis Murphy)
Date: Mon, 30 Jan 2012 10:51:08 -0800
Subject: [Rd] Help page of colors() : add a new example ?
In-Reply-To: <D62EEDC839E38446B9F9378AFA4408E907FB1299@mbxparis02.recherche.curie.fr>
References: <D62EEDC839E38446B9F9378AFA4408E907FB1299@mbxparis02.recherche.curie.fr>
Message-ID: <CADv2QyHFPUR4=Jn+7paXYj-BSgs+5aAp=6Q5cXkcEAy06m2+kw@mail.gmail.com>

Here's another graphic that shows R colors in a table, from Earl Glynn
of the Stowers Institute of Medicine:

http://research.stowers-institute.org/efg/R/Color/Chart/

If the link doesn't bring up the page (my didn't initially), Google on
'Earl Glynn Stowers' and look for the link 'Chart of R Colors'.

Dennis


On Mon, Jan 30, 2012 at 6:46 AM, Millot Gael <Gael.Millot at curie.fr> wrote:
> Dear all,
>
> May I suggest to add an example in the help page of the colors() function ?
> The following code could be useful to easily choose any color from colors() :
>
> ## Millot G. (2011), p.71.
> ## Figure displaying all the 657 built-in color names of colors().
> palette(colors())
> tempo<-NULL
> for(i in 14:1){tempo<-c(tempo, rep(i,50))}
> windows(width=10) # replace by quartz(width=10) for MacOS and by X11(width=10) for Linux
> par(ann=FALSE, xaxt="n", yaxt="n", bty="n")
> plot(rep(1:50,14)[1:657], tempo[1:657], pch=22, bg=1:657, cex=1.5, bty="n")
> par(xpd=TRUE)
> axis(side=2, at=14:1, labels=, cex.axis=1.5, srt=90)
> text(rep(-2, 14), 14:1, as.character((0:13)*50+1), srt=0, cex=1)
> text(c(10,20,30,40,50), rep(-0.5,5), c(10,20,30,40,50), srt=0, cex=1)
>
> ## palette(colors()) allow to replace the color names by the numbers indicated
> ## in the figure.
> palette(colors())
> plot(1, col=630, pch=16, cex=10) # 630 is "tomato"
>
> This code comes from the page 71 of the book I published in french:
> Millot G. Comprendre et r?aliser les tests statistiques ? l'aide de R, 2nd edition. De Boeck editions, Bruxelles . 2011, 767 pages.
>
> I wrote it since my students usually complain about the difficulty to select a color
> from colors() when the names are displayed.
>
> Kind regards,
>
> Gael Millot.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From dpugmire at gmail.com  Mon Jan 30 23:20:10 2012
From: dpugmire at gmail.com (Dave Pugmire)
Date: Mon, 30 Jan 2012 17:20:10 -0500
Subject: [Rd] Crash when using embedded R.
Message-ID: <CAM6_Vwx5k4apDMp5vMuct9FtSXz-vB36JY7VCisGh6HXA22TBg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20120130/115827aa/attachment.pl>

From xie at yihui.name  Tue Jan 31 03:41:50 2012
From: xie at yihui.name (Yihui Xie)
Date: Mon, 30 Jan 2012 20:41:50 -0600
Subject: [Rd] Sweave driver extension
In-Reply-To: <4F26DC7F.7040903@gmail.com>
References: <1327434615.8525.38.camel@nemo>
	<CANROs4f+ObUuxTN5hvdbWhZbuTwL_Gdq1GQCXKnM2taWDrzQ7Q@mail.gmail.com>
	<4F26DC7F.7040903@gmail.com>
Message-ID: <CANROs4c6QFR2QVyFiu6GHhKdWHRiEptSB9MpciEbGR--JwRuVQ@mail.gmail.com>

OK, I did not realize the overhead problem is so overwhelming in your
situation. Therefore I re-implemented the chunk reference in the knitr
package in another way. In Sweave we use

<<a>>=
# code in chunk a
@

<<b>>=
# use code in a
<<a>>
@

And in knitr, we can use real R code:

<<a>>=
# code in chunk a
@

<<b>>=
# use code in a
run_chunk('a')
@

This also allows arbitrary levels of recursion, e.g. I add another
chunk called 'c':

<<c>=
run_chunk('b')
@

Because b uses a, so when c calls b, it will consequently call a as well.

The function run_chunk() will not bring overhead problems, because it
simply extracts the code from other chunks and evaluates it here. It
is not a functional call. This feature is still in the development
version (well, I did it this afternoon):
https://github.com/yihui/knitr.

--------------

Talking about Knuth's original idea, I do not know as much as you, but
under knitr's design, you can arrange code freely, since the code is
stored in a named list after the input document is parsed. You can
define code before using it, or use it before defining it (later); it
is indexed by the chunk label. Top-down or bottom-up, in whatever
order you want. And you are right; it requires a major rewrite, and
that is exactly what I tried to do. I appreciate your feedback because
I know you have very rich experience in reproducible research.

Regards,
Yihui
--
Yihui Xie <xieyihui at gmail.com>
Phone: 515-294-2465 Web: http://yihui.name
Department of Statistics, Iowa State University
2215 Snedecor Hall, Ames, IA



On Mon, Jan 30, 2012 at 12:07 PM, Kevin R. Coombes
<kevin.r.coombes at gmail.com> wrote:
> I prefer the code chunks myself.
>
> Function calls have overhead. In a bioinformatics world with large datasets
> and an R default that uses call-by-value rather than call-by-reference, the
> function calls may have a _lot_ of overhead. ?Writing the functions to make
> sure they use call-by-reference for the large objects instead has a
> different kind of overhead in the stress it puts on the writers and
> maintainers of code.
>
> But then, I'm old enough to have looked at some of Knuth's source code for
> TeX and read his book on Literate Programming, where the ideas of "weave"
> and "tangle" were created for exactly the kind of application that Terry
> asked about. ?Knuth's fundamental idea here is that the documentation
> (mainly the stuff processed through "weave") is created for humans, while
> the executable code (in Knuth's view, the stuff created by "tangle") is
> intended for computers. ?If you want people to understand the code, then you
> often want to use a top-down approach that outlines the structure -- code
> chunks with forward references work perfectly for this purpose.
>
> One of the difficulties in mapping Knuth's idea over to R and Sweave is that
> the operations of weave and tangle have gotten, well, tangled. ?Sweave does
> not just prepare the documentation; it also executes the code in order to
> put the results of the computation into the documentation. ?In order to get
> the forward references to work with Sweave, you would have to makes two
> passes through the file: one to make sure you know where each named chunk is
> and build a cross-reference table, and one to actually execute the code in
> the correct order. ?That would presumably also require a major rewrite of
> Sweave.
>
> The solution I use is to cheat and hide the chunks initially and reveal them
> later to get the output that want. This comes down to combining eval, echo,
> keep.source, and expand in the right combinations. Something like:
>
> %%%%%%%%
> % set up a prologue that contains the code chunks. Do not evaluate or
> display them.
> <<coxme-check-arguments,echo=FALSE,eval=FALSE>>=
> # do something sensible. If multiple steps, define them above here
> # using the same idea.
> @
> % also define the other code chunks here
>
> \section{Start the First Section}
>
> The \texttt{coxme} function is defined as follows:
> <<coxme,keep.source=TRUE,expand=FALSE>>=
>
> coxme <- function(formula, data, subset, blah blah ?){
> <<coxme-check-arguments>>
> <<coxme-build>>
> <<coxme-compute>>
> <<coxme-finish>>
> }
> @
>
> Argument checking is important:
> <<name-does-not-matter-since-not-reused,eval=FALSE,expand=TRUE>>=
> <<coxme-check-arguments>>=
> @
> % Describe the other chunks here
>
> %%%%%%%%
>
>
> ? ?Kevin
>


From Gael.Millot at curie.fr  Tue Jan 31 10:32:14 2012
From: Gael.Millot at curie.fr (Millot Gael)
Date: Tue, 31 Jan 2012 09:32:14 +0000
Subject: [Rd] Help page of colors() : add a new example ?
In-Reply-To: <CADv2QyHFPUR4=Jn+7paXYj-BSgs+5aAp=6Q5cXkcEAy06m2+kw@mail.gmail.com>
References: <D62EEDC839E38446B9F9378AFA4408E907FB1299@mbxparis02.recherche.curie.fr>
	<CADv2QyHFPUR4=Jn+7paXYj-BSgs+5aAp=6Q5cXkcEAy06m2+kw@mail.gmail.com>
Message-ID: <D62EEDC839E38446B9F9378AFA4408E907FB1472@mbxparis02.recherche.curie.fr>

Very nice graphic indeed !
One way or another, it would be useful to have such examples
in the help page of colors(). 

Thanks for your time !!

Best,

Gael.


> -----Message d'origine-----
> De?: Dennis Murphy [mailto:djmuser at gmail.com]
> Envoy??: lundi 30 janvier 2012 19:51
> ??: Millot Gael
> Cc?: r-devel at r-project.org
> Objet?: Re: [Rd] Help page of colors() : add a new example ?
> 
> Here's another graphic that shows R colors in a table, from Earl Glynn
> of the Stowers Institute of Medicine:
> 
> http://research.stowers-institute.org/efg/R/Color/Chart/
> 
> If the link doesn't bring up the page (my didn't initially), Google on
> 'Earl Glynn Stowers' and look for the link 'Chart of R Colors'.
> 
> Dennis
> 
> 
> On Mon, Jan 30, 2012 at 6:46 AM, Millot Gael <Gael.Millot at curie.fr> wrote:
> > Dear all,
> >
> > May I suggest to add an example in the help page of the colors() function ?
> > The following code could be useful to easily choose any color from colors() :
> >
> > ## Millot G. (2011), p.71.
> > ## Figure displaying all the 657 built-in color names of colors().
> > palette(colors())
> > tempo<-NULL
> > for(i in 14:1){tempo<-c(tempo, rep(i,50))}
> > windows(width=10) # replace by quartz(width=10) for MacOS and by
> X11(width=10) for Linux
> > par(ann=FALSE, xaxt="n", yaxt="n", bty="n")
> > plot(rep(1:50,14)[1:657], tempo[1:657], pch=22, bg=1:657, cex=1.5, bty="n")
> > par(xpd=TRUE)
> > axis(side=2, at=14:1, labels=, cex.axis=1.5, srt=90)
> > text(rep(-2, 14), 14:1, as.character((0:13)*50+1), srt=0, cex=1)
> > text(c(10,20,30,40,50), rep(-0.5,5), c(10,20,30,40,50), srt=0, cex=1)
> >
> > ## palette(colors()) allow to replace the color names by the numbers indicated
> > ## in the figure.
> > palette(colors())
> > plot(1, col=630, pch=16, cex=10) # 630 is "tomato"
> >
> > This code comes from the page 71 of the book I published in french:
> > Millot G. Comprendre et r?aliser les tests statistiques ? l'aide de R, 2nd edition.
> De Boeck editions, Bruxelles . 2011, 767 pages.
> >
> > I wrote it since my students usually complain about the difficulty to select a color
> > from colors() when the names are displayed.
> >
> > Kind regards,
> >
> > Gael Millot.
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel


From therneau at mayo.edu  Tue Jan 31 14:18:10 2012
From: therneau at mayo.edu (Terry Therneau)
Date: Tue, 31 Jan 2012 07:18:10 -0600
Subject: [Rd] Sweave driver extension
In-Reply-To: <CANROs4c6QFR2QVyFiu6GHhKdWHRiEptSB9MpciEbGR--JwRuVQ@mail.gmail.com>
References: <1327434615.8525.38.camel@nemo>
	<CANROs4f+ObUuxTN5hvdbWhZbuTwL_Gdq1GQCXKnM2taWDrzQ7Q@mail.gmail.com>
	<4F26DC7F.7040903@gmail.com>
	<CANROs4c6QFR2QVyFiu6GHhKdWHRiEptSB9MpciEbGR--JwRuVQ@mail.gmail.com>
Message-ID: <1328015890.14959.16.camel@nemo>

Three thinngs -
   My original questions to R-help was "who do I talk to".  That was
answered by Brian R, and the discussion of how to change Sweave moved
offline.  FYI, I have a recode in hand that allows arbitrary reordering
of chunks; but changes to code used by hundreds need to be approached
cautiously.  Like the witch says in Wizard of Oz: "... But that's not
what's worrying me, it's how to do it.  These things must be done
delicately, or you hurt the spell."

   A few emails have made me aware of others who use noweb.  Most of
them, as I have, use the original Unix utility.  But since survival is
so interwoven with R I am trying to impliment that functionality
entirely in R to make the code self contained.  Just working out how to
best do so.

  Yihui: with respect to the note below, I don't see why you want to add
new syntax.  Why add "run_chunk(a)" when it is a synonym for <<a>>?    

Terry T.



On Mon, 2012-01-30 at 20:41 -0600, Yihui Xie wrote:
> OK, I did not realize the overhead problem is so overwhelming in your
> situation. Therefore I re-implemented the chunk reference in the knitr
> package in another way. In Sweave we use
> 
> <<a>>=
> # code in chunk a
> @
> 
> <<b>>=
> # use code in a
> <<a>>
> @
> 
> And in knitr, we can use real R code:
> 
> <<a>>=
> # code in chunk a
> @
> 
> <<b>>=
> # use code in a
> run_chunk('a')
> @
> 
> This also allows arbitrary levels of recursion, e.g. I add another
> chunk called 'c':
> 
> <<c>=
> run_chunk('b')
> @
> 
> Because b uses a, so when c calls b, it will consequently call a as well.
> 
> The function run_chunk() will not bring overhead problems, because it
> simply extracts the code from other chunks and evaluates it here. It
> is not a functional call. This feature is still in the development
> version (well, I did it this afternoon):
> https://github.com/yihui/knitr.
> 
> --------------
> 
> Talking about Knuth's original idea, I do not know as much as you, but
> under knitr's design, you can arrange code freely, since the code is
> stored in a named list after the input document is parsed. You can
> define code before using it, or use it before defining it (later); it
> is indexed by the chunk label. Top-down or bottom-up, in whatever
> order you want. And you are right; it requires a major rewrite, and
> that is exactly what I tried to do. I appreciate your feedback because
> I know you have very rich experience in reproducible research.
> 
> Regards,
> Yihui
> --
> Yihui Xie <xieyihui at gmail.com>
> Phone: 515-294-2465 Web: http://yihui.name
> Department of Statistics, Iowa State University
> 2215 Snedecor Hall, Ames, IA
> 
> 
> 
> On Mon, Jan 30, 2012 at 12:07 PM, Kevin R. Coombes
> <kevin.r.coombes at gmail.com> wrote:
> > I prefer the code chunks myself.
> >
> > Function calls have overhead. In a bioinformatics world with large datasets
> > and an R default that uses call-by-value rather than call-by-reference, the
> > function calls may have a _lot_ of overhead.  Writing the functions to make
> > sure they use call-by-reference for the large objects instead has a
> > different kind of overhead in the stress it puts on the writers and
> > maintainers of code.
> >
> > But then, I'm old enough to have looked at some of Knuth's source code for
> > TeX and read his book on Literate Programming, where the ideas of "weave"
> > and "tangle" were created for exactly the kind of application that Terry
> > asked about.  Knuth's fundamental idea here is that the documentation
> > (mainly the stuff processed through "weave") is created for humans, while
> > the executable code (in Knuth's view, the stuff created by "tangle") is
> > intended for computers.  If you want people to understand the code, then you
> > often want to use a top-down approach that outlines the structure -- code
> > chunks with forward references work perfectly for this purpose.
> >
> > One of the difficulties in mapping Knuth's idea over to R and Sweave is that
> > the operations of weave and tangle have gotten, well, tangled.  Sweave does
> > not just prepare the documentation; it also executes the code in order to
> > put the results of the computation into the documentation.  In order to get
> > the forward references to work with Sweave, you would have to makes two
> > passes through the file: one to make sure you know where each named chunk is
> > and build a cross-reference table, and one to actually execute the code in
> > the correct order.  That would presumably also require a major rewrite of
> > Sweave.
> >
> > The solution I use is to cheat and hide the chunks initially and reveal them
> > later to get the output that want. This comes down to combining eval, echo,
> > keep.source, and expand in the right combinations. Something like:
> >
> > %%%%%%%%
> > % set up a prologue that contains the code chunks. Do not evaluate or
> > display them.
> > <<coxme-check-arguments,echo=FALSE,eval=FALSE>>=
> > # do something sensible. If multiple steps, define them above here
> > # using the same idea.
> > @
> > % also define the other code chunks here
> >
> > \section{Start the First Section}
> >
> > The \texttt{coxme} function is defined as follows:
> > <<coxme,keep.source=TRUE,expand=FALSE>>=
> >
> > coxme <- function(formula, data, subset, blah blah  ){
> > <<coxme-check-arguments>>
> > <<coxme-build>>
> > <<coxme-compute>>
> > <<coxme-finish>>
> > }
> > @
> >
> > Argument checking is important:
> > <<name-does-not-matter-since-not-reused,eval=FALSE,expand=TRUE>>=
> > <<coxme-check-arguments>>=
> > @
> > % Describe the other chunks here
> >
> > %%%%%%%%
> >
> >
> >    Kevin
> >


From xie at yihui.name  Tue Jan 31 18:23:56 2012
From: xie at yihui.name (Yihui Xie)
Date: Tue, 31 Jan 2012 11:23:56 -0600
Subject: [Rd] Sweave driver extension
In-Reply-To: <1328015890.14959.16.camel@nemo>
References: <1327434615.8525.38.camel@nemo>
	<CANROs4f+ObUuxTN5hvdbWhZbuTwL_Gdq1GQCXKnM2taWDrzQ7Q@mail.gmail.com>
	<4F26DC7F.7040903@gmail.com>
	<CANROs4c6QFR2QVyFiu6GHhKdWHRiEptSB9MpciEbGR--JwRuVQ@mail.gmail.com>
	<1328015890.14959.16.camel@nemo>
Message-ID: <CANROs4e+bsa6WuaW7ARXwnzd_cTGTWzE0G+h3TjkRNDRy-b0Qg@mail.gmail.com>

On Tue, Jan 31, 2012 at 7:18 AM, Terry Therneau <therneau at mayo.edu> wrote:
> Three thinngs -
> ? My original questions to R-help was "who do I talk to". ?That was
> answered by Brian R, and the discussion of how to change Sweave moved
> offline. ?FYI, I have a recode in hand that allows arbitrary reordering
> of chunks; but changes to code used by hundreds need to be approached
> cautiously. ?Like the witch says in Wizard of Oz: "... But that's not
> what's worrying me, it's how to do it. ?These things must be done
> delicately, or you hurt the spell."
>
> ? A few emails have made me aware of others who use noweb. ?Most of
> them, as I have, use the original Unix utility. ?But since survival is
> so interwoven with R I am trying to impliment that functionality
> entirely in R to make the code self contained. ?Just working out how to
> best do so.
>
> ?Yihui: with respect to the note below, I don't see why you want to add
> new syntax. ?Why add "run_chunk(a)" when it is a synonym for <<a>>?

A short answer is it is easy to implement, because run_chunk() uses
eval() which naturally supports recursion (you can eval(parse(text =
"eval(parse(text = ...))"))).

I think I will add <<>> in the next few days too. There have been
quite a few features like this one that I did not plan to do because I
do not use them at all, but I added them to knitr one by one anyway
when I saw convincing reasons (function overhead problems in this
case). So I really appreciate these discussions.

I feel r-devel is not a good place for me to chime in, so I will turn
the discussion irrelevant to r-devel offline later.

>
> Terry T.
>
>


Regards,
Yihui
--
Yihui Xie <xieyihui at gmail.com>
Phone: 515-294-2465 Web: http://yihui.name
Department of Statistics, Iowa State University
2215 Snedecor Hall, Ames, IA


From bbolker at gmail.com  Tue Jan 31 20:16:09 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 31 Jan 2012 19:16:09 +0000
Subject: [Rd] misfeature: forced file.copy() of a file over itself
	truncates the file ...
References: <4F22D8C5.5040602@ufl.edu>
Message-ID: <loom.20120131T200855-900@post.gmane.org>

Ben Bolker <bbolker <at> gmail.com> writes:

>

  Bump.  Will I be scolded if I submit this as a bug report/wishlist
item?

  Test case:

>   fn <- "tmp.dat"
>   x <- 1:3
>   dump("x",file=fn)
>   file.info(fn)  ## 9 bytes
>   file.copy(paste("./",fn,sep=""),fn,overwrite=TRUE)
>   file.info(fn)  ## 0 bytes (!!)
> 
>   Normally file.copy() checks and disallows overwriting a file with
> itself, but it only checks whether character string 'from' is the same
> as character string 'to' and not whether the copy refers to the same
> file by different names, so it lets this go ahead.  It then creates a
> new file with the name of 'to' using file.create():
> 
>      ?file.create? creates files with the given names if they do not
>      already exist and truncates them if they do.
> 
> This trashes the existing 'from' file (which was not detected).
> file.copy() then happily appends the contents of 'from' (which is now
> empty) to 'to' ...
> 
  
 [snip]

  My proposed fix (thanks to W. Dunlap) is to use normalizePath();
as he points out, this won't catch situations where the same file
can be referred to via an NFS mount, but it should help at least.
Writing a platform-independent version a la S-PLUS's match.path()
seemed to much work at the moment.

===================================================================
--- files.R	(revision 58240)
+++ files.R	(working copy)
@@ -116,7 +116,7 @@
     if(nt > nf) from <- rep(from, length.out = nt)
     okay <- file.exists(from)
     if (!overwrite) okay[file.exists(to)] <- FALSE
-    if (any(from[okay] %in% to[okay]))
+    if (any(normalizePath(from[okay]) %in% normalizePath(to[okay])))
         stop("file can not be copied both 'from' and 'to'")
     if (any(okay)) { # care: file.create could fail but file.append work.
     	okay[okay] <- file.create(to[okay])


  thanks
    Ben Bolker


From edd at debian.org  Tue Jan 31 20:56:36 2012
From: edd at debian.org (Dirk Eddelbuettel)
Date: Tue, 31 Jan 2012 13:56:36 -0600
Subject: [Rd] seq.Date bug?
Message-ID: <20264.18292.474587.518409@max.nulle.part>


R> seq(as.Date(Sys.Date()), by="-1 months", length=6)
[1] "2012-01-31" "2011-12-31" "2011-12-01" "2011-10-31" "2011-10-01" "2011-08-31"
R> 

Notice how October appears twice.

Now, date arithmetic is gruesome but the documentation for seq.Date et al
does not hint it wouldn't honour the by= argument.  So a bug, or merely a
somewhat less than desirable features.

(And yes, I think I know that Hadley's lubridate has code for this too, but
so may my RcppBDT which is sitting on top of Boost::DateTime code ...)

Dirk

-- 
"Outside of a dog, a book is a man's best friend. Inside of a dog, it is too
dark to read." -- Groucho Marx


From sarah.goslee at gmail.com  Tue Jan 31 21:07:06 2012
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Tue, 31 Jan 2012 15:07:06 -0500
Subject: [Rd] seq.Date bug?
In-Reply-To: <20264.18292.474587.518409@max.nulle.part>
References: <20264.18292.474587.518409@max.nulle.part>
Message-ID: <CAM_vjuk4Nc8jMGjz3_OqEXc+-p6w61v2BXKG+qQWBxu7h4Wabg@mail.gmail.com>

I was prompted to try it myself:

On Tue, Jan 31, 2012 at 2:56 PM, Dirk Eddelbuettel <edd at debian.org> wrote:
>
> R> seq(as.Date(Sys.Date()), by="-1 months", length=6)
> [1] "2012-01-31" "2011-12-31" "2011-12-01" "2011-10-31" "2011-10-01" "2011-08-31"
> R>
>
> Notice how October appears twice.

As does December.

> Now, date arithmetic is gruesome but the documentation for seq.Date et al
> does not hint it wouldn't honour the by= argument. ?So a bug, or merely a
> somewhat less than desirable features.

The by argument chokes on "month" if the current day is greater than the
shortest month in the sequence (presumably due to the irregular nature
of month lengths):

For leap year 2012:
> seq(as.Date("2012/1/29"), by="month", length.out=12) # works
 [1] "2012-01-29" "2012-02-29" "2012-03-29" "2012-04-29" "2012-05-29"
 [6] "2012-06-29" "2012-07-29" "2012-08-29" "2012-09-29" "2012-10-29"
[11] "2012-11-29" "2012-12-29"
> seq(as.Date("2012/1/30"), by="month", length.out=12) # fails
 [1] "2012-01-30" "2012-03-01" "2012-03-30" "2012-04-30" "2012-05-30"
 [6] "2012-06-30" "2012-07-30" "2012-08-30" "2012-09-30" "2012-10-30"
[11] "2012-11-30" "2012-12-30"

While for non-leap year 2011:
> seq(as.Date("2011/1/28"), by="month", length.out=12) # works
 [1] "2011-01-28" "2011-02-28" "2011-03-28" "2011-04-28" "2011-05-28"
 [6] "2011-06-28" "2011-07-28" "2011-08-28" "2011-09-28" "2011-10-28"
[11] "2011-11-28" "2011-12-28"
> seq(as.Date("2011/1/29"), by="month", length.out=12) #fails
 [1] "2011-01-29" "2011-03-01" "2011-03-29" "2011-04-29" "2011-05-29"
 [6] "2011-06-29" "2011-07-29" "2011-08-29" "2011-09-29" "2011-10-29"
[11] "2011-11-29" "2011-12-29"

> sessionInfo()
R version 2.14.1 (2011-12-22)
Platform: x86_64-redhat-linux-gnu (64-bit)

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
 [7] LC_PAPER=C                 LC_NAME=C
 [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] tools_2.14.1



-- 
Sarah Goslee
http://www.functionaldiversity.org


From murdoch.duncan at gmail.com  Tue Jan 31 21:17:42 2012
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 31 Jan 2012 15:17:42 -0500
Subject: [Rd] seq.Date bug?
In-Reply-To: <20264.18292.474587.518409@max.nulle.part>
References: <20264.18292.474587.518409@max.nulle.part>
Message-ID: <4F284C66.2020409@gmail.com>

On 12-01-31 2:56 PM, Dirk Eddelbuettel wrote:
>
> R>  seq(as.Date(Sys.Date()), by="-1 months", length=6)
> [1] "2012-01-31" "2011-12-31" "2011-12-01" "2011-10-31" "2011-10-01" "2011-08-31"
> R>
>
> Notice how October appears twice.

>
> Now, date arithmetic is gruesome but the documentation for seq.Date et al
> does not hint it wouldn't honour the by= argument.  So a bug, or merely a
> somewhat less than desirable features.

It is giving you Jan 31, Dec 31, Nov 31, Oct 31, Sep 31, Aug 31 -- 
except some of those months don't have 31 days, so it is converting 
those dates to ones that really exist.  (This is documented in ?seq.POSIXt.)

Isn't this what you asked for?

Duncan Murdoch


>
> (And yes, I think I know that Hadley's lubridate has code for this too, but
> so may my RcppBDT which is sitting on top of Boost::DateTime code ...)
>
> Dirk
>


From marc_schwartz at me.com  Tue Jan 31 21:20:46 2012
From: marc_schwartz at me.com (Marc Schwartz)
Date: Tue, 31 Jan 2012 14:20:46 -0600
Subject: [Rd] seq.Date bug?
In-Reply-To: <CAM_vjuk4Nc8jMGjz3_OqEXc+-p6w61v2BXKG+qQWBxu7h4Wabg@mail.gmail.com>
References: <20264.18292.474587.518409@max.nulle.part>
	<CAM_vjuk4Nc8jMGjz3_OqEXc+-p6w61v2BXKG+qQWBxu7h4Wabg@mail.gmail.com>
Message-ID: <FE917B4D-E8CA-4E95-B55B-7230C3F30A79@me.com>


On Jan 31, 2012, at 2:07 PM, Sarah Goslee wrote:

> I was prompted to try it myself:
> 
> On Tue, Jan 31, 2012 at 2:56 PM, Dirk Eddelbuettel <edd at debian.org> wrote:
>> 
>> R> seq(as.Date(Sys.Date()), by="-1 months", length=6)
>> [1] "2012-01-31" "2011-12-31" "2011-12-01" "2011-10-31" "2011-10-01" "2011-08-31"
>> R>
>> 
>> Notice how October appears twice.
> 
> As does December.
> 
>> Now, date arithmetic is gruesome but the documentation for seq.Date et al
>> does not hint it wouldn't honour the by= argument.  So a bug, or merely a
>> somewhat less than desirable features.
> 
> The by argument chokes on "month" if the current day is greater than the
> shortest month in the sequence (presumably due to the irregular nature
> of month lengths):
> 
> For leap year 2012:
>> seq(as.Date("2012/1/29"), by="month", length.out=12) # works
> [1] "2012-01-29" "2012-02-29" "2012-03-29" "2012-04-29" "2012-05-29"
> [6] "2012-06-29" "2012-07-29" "2012-08-29" "2012-09-29" "2012-10-29"
> [11] "2012-11-29" "2012-12-29"
>> seq(as.Date("2012/1/30"), by="month", length.out=12) # fails
> [1] "2012-01-30" "2012-03-01" "2012-03-30" "2012-04-30" "2012-05-30"
> [6] "2012-06-30" "2012-07-30" "2012-08-30" "2012-09-30" "2012-10-30"
> [11] "2012-11-30" "2012-12-30"
> 
> While for non-leap year 2011:
>> seq(as.Date("2011/1/28"), by="month", length.out=12) # works
> [1] "2011-01-28" "2011-02-28" "2011-03-28" "2011-04-28" "2011-05-28"
> [6] "2011-06-28" "2011-07-28" "2011-08-28" "2011-09-28" "2011-10-28"
> [11] "2011-11-28" "2011-12-28"
>> seq(as.Date("2011/1/29"), by="month", length.out=12) #fails
> [1] "2011-01-29" "2011-03-01" "2011-03-29" "2011-04-29" "2011-05-29"
> [6] "2011-06-29" "2011-07-29" "2011-08-29" "2011-09-29" "2011-10-29"
> [11] "2011-11-29" "2011-12-29"


The issue is the if the next month in sequence does not contain the date, then the date is advanced until the next valid date. For example:

> seq.Date(as.Date("2012/01/30"), by = "month", length.out = 3)
[1] "2012-01-30" "2012-03-01" "2012-03-30"

February 30th does not exist, thus that date is advanced to March 1st, then the next date in the sequence is March 30th. Thus, two days in March.


> seq.Date(as.Date("2012/10/31"), by = "month", length.out = 3)
[1] "2012-10-31" "2012-12-01" "2012-12-31"

Here, November 31st does not exist, so the date is advanced to the next valid date, December 1 and then the next date is December 31. Thus, two days in December.


So it appears to be working correctly.

HTH,

Marc Schwartz


From sarah.goslee at gmail.com  Tue Jan 31 21:28:11 2012
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Tue, 31 Jan 2012 15:28:11 -0500
Subject: [Rd] seq.Date bug?
In-Reply-To: <4F284C66.2020409@gmail.com>
References: <20264.18292.474587.518409@max.nulle.part>
	<4F284C66.2020409@gmail.com>
Message-ID: <CAM_vju=AbKnsBsyMrTiWdYbcFNFnhHO0aGFMzH2YQ4bRv8y5Pw@mail.gmail.com>

As Duncan pointed out, this is documented in ?seq.POSIXt:

     Using ?"month"? first advances the month without changing the day:
     if this results in an invalid day of the month, it is counted
     forward into the next month: see the examples.

But ?seq.Date gives the impression that the construct Dirk and I tried
should work:

     ## find all 7th of the month between two dates, the last being a 7th.
     st <- as.Date("1998-12-17")
     en <- as.Date("2000-1-7")
     ll <- seq(en, st, by="-1 month")
     rev(ll[ll > st & ll < en])

is given as an example, and it is not pointed out that this won't work for
the 30th of the month. Normally one can extrapolate from patterns given
in the examples, and here that isn't true. So perhaps the help should
be modified slightly instead?

Sarah

-- 
Sarah Goslee
http://www.sarahgoslee.com


From edd at debian.org  Tue Jan 31 21:37:24 2012
From: edd at debian.org (Dirk Eddelbuettel)
Date: Tue, 31 Jan 2012 14:37:24 -0600
Subject: [Rd] seq.Date bug?
In-Reply-To: <4F284C66.2020409@gmail.com>
References: <20264.18292.474587.518409@max.nulle.part>
	<4F284C66.2020409@gmail.com>
Message-ID: <20264.20740.502345.146850@max.nulle.part>


On 31 January 2012 at 15:17, Duncan Murdoch wrote:
| On 12-01-31 2:56 PM, Dirk Eddelbuettel wrote:
| >
| > R>  seq(as.Date(Sys.Date()), by="-1 months", length=6)
| > [1] "2012-01-31" "2011-12-31" "2011-12-01" "2011-10-31" "2011-10-01" "2011-08-31"
| > R>
| >
| > Notice how October appears twice.
| 
| >
| > Now, date arithmetic is gruesome but the documentation for seq.Date et al
| > does not hint it wouldn't honour the by= argument.  So a bug, or merely a
| > somewhat less than desirable features.
| 
| It is giving you Jan 31, Dec 31, Nov 31, Oct 31, Sep 31, Aug 31 -- 
| except some of those months don't have 31 days, so it is converting 
| those dates to ones that really exist.  (This is documented in ?seq.POSIXt.)
| 
| Isn't this what you asked for?

No as I was feeding this into format(..., "%b-%y") to create 'pretty' names,
and the double entries screw that.

Morale:  pick a mid-month date, and shift that.

Dirk
 
| Duncan Murdoch
| 
| 
| >
| > (And yes, I think I know that Hadley's lubridate has code for this too, but
| > so may my RcppBDT which is sitting on top of Boost::DateTime code ...)
| >
| > Dirk
| >
| 

-- 
"Outside of a dog, a book is a man's best friend. Inside of a dog, it is too
dark to read." -- Groucho Marx


From jeffrey.ryan at lemnica.com  Tue Jan 31 21:46:59 2012
From: jeffrey.ryan at lemnica.com (Jeffrey Ryan)
Date: Tue, 31 Jan 2012 14:46:59 -0600
Subject: [Rd] seq.Date bug?
In-Reply-To: <20264.20740.502345.146850@max.nulle.part>
References: <20264.18292.474587.518409@max.nulle.part>
	<4F284C66.2020409@gmail.com>
	<20264.20740.502345.146850@max.nulle.part>
Message-ID: <CABDUZc-qG7rRneXg_XEamXPiGgNBAiqr_DFV6OqDzB2Ekj04Eg@mail.gmail.com>

format(ISOdate(2012,1:12,1),"%b-%Y")

[1] "Jan-2012" "Feb-2012" "Mar-2012" "Apr-2012" "May-2012" "Jun-2012"
[7] "Jul-2012" "Aug-2012" "Sep-2012" "Oct-2012" "Nov-2012" "Dec-2012"

First of the month is just as clean, and AFAIR they all have a first ;-)

Jeff

On Tue, Jan 31, 2012 at 2:37 PM, Dirk Eddelbuettel <edd at debian.org> wrote:
>
> On 31 January 2012 at 15:17, Duncan Murdoch wrote:
> | On 12-01-31 2:56 PM, Dirk Eddelbuettel wrote:
> | >
> | > R> ?seq(as.Date(Sys.Date()), by="-1 months", length=6)
> | > [1] "2012-01-31" "2011-12-31" "2011-12-01" "2011-10-31" "2011-10-01" "2011-08-31"
> | > R>
> | >
> | > Notice how October appears twice.
> |
> | >
> | > Now, date arithmetic is gruesome but the documentation for seq.Date et al
> | > does not hint it wouldn't honour the by= argument. ?So a bug, or merely a
> | > somewhat less than desirable features.
> |
> | It is giving you Jan 31, Dec 31, Nov 31, Oct 31, Sep 31, Aug 31 --
> | except some of those months don't have 31 days, so it is converting
> | those dates to ones that really exist. ?(This is documented in ?seq.POSIXt.)
> |
> | Isn't this what you asked for?
>
> No as I was feeding this into format(..., "%b-%y") to create 'pretty' names,
> and the double entries screw that.
>
> Morale: ?pick a mid-month date, and shift that.
>
> Dirk
>
> | Duncan Murdoch
> |
> |
> | >
> | > (And yes, I think I know that Hadley's lubridate has code for this too, but
> | > so may my RcppBDT which is sitting on top of Boost::DateTime code ...)
> | >
> | > Dirk
> | >
> |
>
> --
> "Outside of a dog, a book is a man's best friend. Inside of a dog, it is too
> dark to read." -- Groucho Marx
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel



-- 
Jeffrey Ryan
jeffrey.ryan at lemnica.com

www.lemnica.com
www.esotericR.com

R/Finance 2012: Applied Finance with R
www.RinFinance.com

See you in Chicago!!!!


From edd at debian.org  Tue Jan 31 21:50:07 2012
From: edd at debian.org (Dirk Eddelbuettel)
Date: Tue, 31 Jan 2012 14:50:07 -0600
Subject: [Rd] seq.Date bug?
In-Reply-To: <CAM_vju=AbKnsBsyMrTiWdYbcFNFnhHO0aGFMzH2YQ4bRv8y5Pw@mail.gmail.com>
References: <20264.18292.474587.518409@max.nulle.part>
	<4F284C66.2020409@gmail.com>
	<CAM_vju=AbKnsBsyMrTiWdYbcFNFnhHO0aGFMzH2YQ4bRv8y5Pw@mail.gmail.com>
Message-ID: <20264.21503.502544.595849@max.nulle.part>


On 31 January 2012 at 15:28, Sarah Goslee wrote:
| As Duncan pointed out, this is documented in ?seq.POSIXt:
| 
|      Using ?"month"? first advances the month without changing the day:
|      if this results in an invalid day of the month, it is counted
|      forward into the next month: see the examples.
| 
| But ?seq.Date gives the impression that the construct Dirk and I tried
| should work:
| 
|      ## find all 7th of the month between two dates, the last being a 7th.
|      st <- as.Date("1998-12-17")
|      en <- as.Date("2000-1-7")
|      ll <- seq(en, st, by="-1 month")
|      rev(ll[ll > st & ll < en])
| 
| is given as an example, and it is not pointed out that this won't work for
| the 30th of the month. Normally one can extrapolate from patterns given
| in the examples, and here that isn't true. So perhaps the help should
| be modified slightly instead?

Yup, that would indeed help with this "infelicity".

Dirk

-- 
"Outside of a dog, a book is a man's best friend. Inside of a dog, it is too
dark to read." -- Groucho Marx


From smckinney at bccrc.ca  Tue Jan 31 23:07:02 2012
From: smckinney at bccrc.ca (Steven McKinney)
Date: Tue, 31 Jan 2012 14:07:02 -0800
Subject: [Rd] seq.Date bug?
In-Reply-To: <12061_1328046269_1328046269_CABDUZc-qG7rRneXg_XEamXPiGgNBAiqr_DFV6OqDzB2Ekj04Eg@mail.gmail.com>
References: <20264.18292.474587.518409@max.nulle.part>
	<4F284C66.2020409@gmail.com>	<20264.20740.502345.146850@max.nulle.part>
	<12061_1328046269_1328046269_CABDUZc-qG7rRneXg_XEamXPiGgNBAiqr_DFV6OqDzB2Ekj04Eg@mail.gmail.com>
Message-ID: <DCE81E14EB74504B971DAD4D2DB0356B0892A7083B@crcmail4.BCCRC.CA>


> -----Original Message-----
> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org]
> On Behalf Of Jeffrey Ryan
> Sent: January-31-12 12:47 PM
> To: Dirk Eddelbuettel
> Cc: R-devel org
> Subject: Re: [Rd] seq.Date bug?
> 
> format(ISOdate(2012,1:12,1),"%b-%Y")
> 
> [1] "Jan-2012" "Feb-2012" "Mar-2012" "Apr-2012" "May-2012" "Jun-2012"
> [7] "Jul-2012" "Aug-2012" "Sep-2012" "Oct-2012" "Nov-2012" "Dec-2012"
> 
> First of the month is just as clean, and AFAIR they all have a first ;-)

>From which you can get the last...

> format(ISOdate(2012,1:12,1)-86400,"%d-%b-%Y")
 [1] "31-Dec-2011" "31-Jan-2012" "29-Feb-2012" "31-Mar-2012" "30-Apr-2012" "31-May-2012"
 [7] "30-Jun-2012" "31-Jul-2012" "31-Aug-2012" "30-Sep-2012" "31-Oct-2012" "30-Nov-2012"

... though leap seconds might require a bit more tweaking...

Steven McKinney
Statistician
Molecular Oncology and Breast Cancer Program
British Columbia Cancer Research Centre



> 
> Jeff
> 
> On Tue, Jan 31, 2012 at 2:37 PM, Dirk Eddelbuettel <edd at debian.org> wrote:
> >
> > On 31 January 2012 at 15:17, Duncan Murdoch wrote:
> > | On 12-01-31 2:56 PM, Dirk Eddelbuettel wrote:
> > | >
> > | > R> ?seq(as.Date(Sys.Date()), by="-1 months", length=6)
> > | > [1] "2012-01-31" "2011-12-31" "2011-12-01" "2011-10-31" "2011-10-01"
> "2011-08-31"
> > | > R>
> > | >
> > | > Notice how October appears twice.
> > |
> > | >
> > | > Now, date arithmetic is gruesome but the documentation for seq.Date
> et al
> > | > does not hint it wouldn't honour the by= argument. ?So a bug, or
> merely a
> > | > somewhat less than desirable features.
> > |
> > | It is giving you Jan 31, Dec 31, Nov 31, Oct 31, Sep 31, Aug 31 --
> > | except some of those months don't have 31 days, so it is converting
> > | those dates to ones that really exist. ?(This is documented in
> ?seq.POSIXt.)
> > |
> > | Isn't this what you asked for?
> >
> > No as I was feeding this into format(..., "%b-%y") to create 'pretty'
> names,
> > and the double entries screw that.
> >
> > Morale: ?pick a mid-month date, and shift that.
> >
> > Dirk
> >
> > | Duncan Murdoch
> > |
> > |
> > | >
> > | > (And yes, I think I know that Hadley's lubridate has code for this
> too, but
> > | > so may my RcppBDT which is sitting on top of Boost::DateTime code
> ...)
> > | >
> > | > Dirk
> > | >
> > |
> >
> > --
> > "Outside of a dog, a book is a man's best friend. Inside of a dog, it is
> too
> > dark to read." -- Groucho Marx
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 
> 
> --
> Jeffrey Ryan
> jeffrey.ryan at lemnica.com
> 
> www.lemnica.com
> www.esotericR.com
> 
> R/Finance 2012: Applied Finance with R
> www.RinFinance.com
> 
> See you in Chicago!!!!
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


