From bbo|ker @end|ng |rom gm@||@com  Fri Dec  8 00:21:08 2023
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Thu, 7 Dec 2023 18:21:08 -0500
Subject: [Rd] option to silence/quieten stats::confint.glm ?
Message-ID: <1dbd2ca6-6f37-4ff3-a44d-8e90654fc992@gmail.com>

    confint.glm prints a message "Waiting for profiling to be done..."

    I could have sworn that there used to be an option (quiet = TRUE?) 
to turn this message off without resorting to suppressMessages() 
(finer/more specific control is always preferable ...) -- but on the 
basis of looking back at archived versions of MASS, and at this Stack 
Overflow post:

https://stackoverflow.com/questions/43847705/how-do-i-silence-confint-in-r

  I think I was hallucinating.

  Do people think this would be a reasonable minor feature request/would 
a patch suggestion be considered? What would the  best name for the 
argument be? (scan() has "quiet")

pos <- tail(search(), 1)  ## base package
tt <- lapply(c(lsf.str(pos = pos)), \(x) names(formals(x))) |> unlist() 
|> table()
 > tt[["quiet"]]
[1] 4
 > tt[["silent"]]
[1] 1
 > tt[["verbose"]]
[1] 9


    cheers
      Ben Bolker


From j@goreck| @end|ng |rom w|t@edu@p|  Sun Dec 10 16:09:26 2023
From: j@goreck| @end|ng |rom w|t@edu@p| (Jan Gorecki)
Date: Sun, 10 Dec 2023 16:09:26 +0100
Subject: [Rd] capabilities() could report strict-barrier
Message-ID: <CAOO9MKWEOJiZAy=y6vLSFOpqgRxLk34SMBx6OYRQquFoviE3-Q@mail.gmail.com>

Hi,

I would like to propose for capabilities() function to include information
about strict-barrier (--enable-strict-barrier flag).
I can now do "grep barrier /usr/local/lib/R/etc/Makeconf" but having that
in R, in platform independent way, would be useful.

Best Regards,
Jan Gorecki

	[[alternative HTML version deleted]]


From e@ @end|ng |rom enr|co@chum@nn@net  Mon Dec 11 13:48:52 2023
From: e@ @end|ng |rom enr|co@chum@nn@net (Enrico Schumann)
Date: Mon, 11 Dec 2023 13:48:52 +0100
Subject: [Rd] Small typo in Sweave.Rnw
Message-ID: <878r60nbuz.fsf@enricoschumann.net>

In the first paragraph of Sweave.Rnw
(./src/library/utils/vignettes/Sweave.Rnw), it reads

  for literate programming \cite{fla:Knuth:1984}.

but probably should be

  for literate programming \citep{fla:Knuth:1984}.
                                ^

kind regards
    Enrico
    
-- 
Enrico Schumann
Lucerne, Switzerland
http://enricoschumann.net


From tkpmep m@iii@g oii gm@ii@com  Mon Dec 11 15:44:24 2023
From: tkpmep m@iii@g oii gm@ii@com (tkpmep m@iii@g oii gm@ii@com)
Date: Mon, 11 Dec 2023 20:14:24 +0530
Subject: [Rd] Base R wilcox.test gives incorrect answers,
 has been fixed in DescTools, solution can likely be ported to Base R
Message-ID: <00c101da2c40$89ffc220$9dff4660$@gmail.com>

While using the Hodges Lehmann Mean in DescTools (DescTools::HodgesLehmann),
I found that it generated incorrect answers (see
<https://github.com/AndriSignorell/DescTools/issues/97>
https://github.com/AndriSignorell/DescTools/issues/97). The error is driven
by the existence of tied values forcing wilcox.test in Base R to switch to
an approximate algorithm that returns incorrect results - see
<https://aakinshin.net/posts/r-hodges-lehmann-problems/>
https://aakinshin.net/posts/r-hodges-lehmann-problems/ for a detailed
exposition of the issue.

 

Andri Signorell and Cyril Moser have a new C++ implementation of
DescTools::HodgesLehmann using a O(N log(N)) algorithm due to Monahan, but
wilcox.test in Base R appears to be still broken. Will someone kindly bring
this observation, as well as the existence of a solution, to the attention
of the relevant person(s) in the Base R development team? 

 

The paper by Mohanan, as well as the original Fortran implementation of the
algorithm are linked to from
<https://github.com/AndriSignorell/DescTools/issues/97>
https://github.com/AndriSignorell/DescTools/issues/97). Inefficient O(N^2)
algorithms for the Hodges-Lehmann mean are known and are implemented in a
variety of packages. For example, the authors of rt.test
(https://cran.r-project.org/web/packages/rt.test) use the O(N^2) approach. I
suspect that Andri and Cyril will be more than happy to assist with fixing
wilcox.test in Base R with their implementation of Monahan's fast algorithm.

 

Sincerely

 

Thomas Philips

 


	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Mon Dec 11 17:03:28 2023
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Mon, 11 Dec 2023 11:03:28 -0500
Subject: [Rd] Base R wilcox.test gives incorrect answers,
 has been fixed in DescTools, solution can likely be ported to Base R
In-Reply-To: <00c101da2c40$89ffc220$9dff4660$@gmail.com>
References: <00c101da2c40$89ffc220$9dff4660$@gmail.com>
Message-ID: <98e7f899-b5cf-4fb8-bc8a-fa9cb1ec3afb@gmail.com>

   You could request a bugzilla account and post it to 
https://bugs.r-project.org/ yourself: from 
https://www.r-project.org/bugs.html,

 > In order to get a bugzilla account (i.e., become ?member?), please 
send an e-mail (from the address you want to use as your login) to 
bug-report-request at r-project.org briefly explaining why, and a volunteer 
will add you to R?s Bugzilla members.

   (On the other hand, I think that posting to this list was a good idea 
in any case, as it is more visible than the bugs list and may spark some 
useful discussion.)

    cheers
    Ben Bolker


On 2023-12-11 9:44 a.m., tkpmep at gmail.com wrote:
> While using the Hodges Lehmann Mean in DescTools (DescTools::HodgesLehmann),
> I found that it generated incorrect answers (see
> <https://github.com/AndriSignorell/DescTools/issues/97>
> https://github.com/AndriSignorell/DescTools/issues/97). The error is driven
> by the existence of tied values forcing wilcox.test in Base R to switch to
> an approximate algorithm that returns incorrect results - see
> <https://aakinshin.net/posts/r-hodges-lehmann-problems/>
> https://aakinshin.net/posts/r-hodges-lehmann-problems/ for a detailed
> exposition of the issue.
> 
>   
> 
> Andri Signorell and Cyril Moser have a new C++ implementation of
> DescTools::HodgesLehmann using a O(N log(N)) algorithm due to Monahan, but
> wilcox.test in Base R appears to be still broken. Will someone kindly bring
> this observation, as well as the existence of a solution, to the attention
> of the relevant person(s) in the Base R development team?
> 
>   
> 
> The paper by Mohanan, as well as the original Fortran implementation of the
> algorithm are linked to from
> <https://github.com/AndriSignorell/DescTools/issues/97>
> https://github.com/AndriSignorell/DescTools/issues/97). Inefficient O(N^2)
> algorithms for the Hodges-Lehmann mean are known and are implemented in a
> variety of packages. For example, the authors of rt.test
> (https://cran.r-project.org/web/packages/rt.test) use the O(N^2) approach. I
> suspect that Andri and Cyril will be more than happy to assist with fixing
> wilcox.test in Base R with their implementation of Monahan's fast algorithm.
> 
>   
> 
> Sincerely
> 
>   
> 
> Thomas Philips
> 
>   
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From Kurt@Horn|k @end|ng |rom wu@@c@@t  Mon Dec 11 19:54:06 2023
From: Kurt@Horn|k @end|ng |rom wu@@c@@t (Kurt Hornik)
Date: Mon, 11 Dec 2023 19:54:06 +0100
Subject: [Rd] Small typo in Sweave.Rnw
In-Reply-To: <878r60nbuz.fsf@enricoschumann.net>
References: <878r60nbuz.fsf@enricoschumann.net>
Message-ID: <25975.23246.833882.469653@hornik.net>

>>>>> Enrico Schumann writes:

Great, thanks: changed now.

Best
-k

> In the first paragraph of Sweave.Rnw
> (./src/library/utils/vignettes/Sweave.Rnw), it reads

>   for literate programming \cite{fla:Knuth:1984}.

> but probably should be

>   for literate programming \citep{fla:Knuth:1984}.
>                                 ^

> kind regards
>     Enrico
    
> -- 
> Enrico Schumann
> Lucerne, Switzerland
> http://enricoschumann.net

> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From h||m@r@berger @end|ng |rom gmx@de  Mon Dec 11 21:11:48 2023
From: h||m@r@berger @end|ng |rom gmx@de (Hilmar Berger)
Date: Mon, 11 Dec 2023 21:11:48 +0100
Subject: [Rd] Partial matching performance in data frame rownames using [
Message-ID: <de5e1dad-7ffc-4c35-8c51-1e0e21e585b9@gmx.de>

Dear all,

I have seen that others have discussed the partial matching behaviour of
data.frame[idx,] in the past, in particular with respect to unexpected
results sets.

I am aware of the fact that one can work around this using either
match() or switching to tibble/data.table or similar altogether.

I have a different issue with the partial matching, in particular its
performance when used on large data frames or more specifically, with
large queries matched against its row names.

I came across a case where I wanted to extract data from a large table
(approx 1M rows) using an index which matched only about 50% to the row
names, i.e. about 50% row name hits and 50% misses.

What was unexpected is that in this case was that [.data.frame was
hanging for a long time (I waited about 10 minutes and then restarted
R). Also, this cannot be interrupted in interactive mode.

ids <- paste0("cg", sprintf("%06d",0:(1e6-1)))
d1 <- data.frame(row.names=ids, v=1:(1e6) )

q1 <- sample(ids, 1e6, replace=F)
system.time({r <- d1[q1,,drop=F]})
#?? user? system elapsed
#? 0.464?? 0.000?? 0.465

# those will hang a long time, I stopped R after 10 minutes
q2 <- c(q1[1:5e5], gsub("cg", "ct", q1[(5e5+1):1e6]) )
system.time({r <- d1[q2,,drop=F]})

# same here
q3 <- c(q1[1:5e5], rep("FOO",5e5) )
system.time({r <- d1[q3,,drop=F]})

It seems that the penalty of partial matching the non-hits across the
whole row name vector is not negligible any more with large tables and
queries, compared to small and medium tables.

I checked and pmatch(q2, rownames(d1) is equally slow.

Is there a chance to a) document this in the help page ("with large
indexes/tables use match()") or even better b) add an exact flag to
[.data.frame ?

Thanks a lot!

Best regards

Hilmar


From kry|ov@r00t @end|ng |rom gm@||@com  Tue Dec 12 13:55:19 2023
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Tue, 12 Dec 2023 15:55:19 +0300
Subject: [Rd] 
 Partial matching performance in data frame rownames using [
In-Reply-To: <de5e1dad-7ffc-4c35-8c51-1e0e21e585b9@gmx.de>
References: <de5e1dad-7ffc-4c35-8c51-1e0e21e585b9@gmx.de>
Message-ID: <20231212155519.2ccbd3d2@arachnoid>

? Mon, 11 Dec 2023 21:11:48 +0100
Hilmar Berger via R-devel <r-devel at r-project.org> ?????:

> What was unexpected is that in this case was that [.data.frame was
> hanging for a long time (I waited about 10 minutes and then restarted
> R). Also, this cannot be interrupted in interactive mode.

That's unfortunate. If an operation takes a long time, it ought to be
interruptible. Here's a patch that passes make check-devel:

--- src/main/unique.c	(revision 85667)
+++ src/main/unique.c	(working copy)
@@ -1631,6 +1631,7 @@
 	}
     }
 
+    unsigned int ic = 9999;
     if(nexact < n_input) {
 	/* Second pass, partial matching */
 	for (R_xlen_t i = 0; i < n_input; i++) {
@@ -1642,6 +1643,10 @@
 	    mtch = 0;
 	    mtch_count = 0;
 	    for (int j = 0; j < n_target; j++) {
+		if (!--ic) {
+		    R_CheckUserInterrupt();
+		    ic = 9999;
+		}
 		if (no_dups && used[j]) continue;
 		if (strncmp(ss, tar[j], temp) == 0) {
 		    mtch = j + 1;

-- 
Best regards,
Ivan


From h||m@r@berger @end|ng |rom gmx@de  Wed Dec 13 09:04:18 2023
From: h||m@r@berger @end|ng |rom gmx@de (Hilmar Berger)
Date: Wed, 13 Dec 2023 09:04:18 +0100
Subject: [Rd] 
 Partial matching performance in data frame rownames using [
In-Reply-To: <20231212155519.2ccbd3d2@arachnoid>
References: <de5e1dad-7ffc-4c35-8c51-1e0e21e585b9@gmx.de>
 <20231212155519.2ccbd3d2@arachnoid>
Message-ID: <8022eea1-9577-476c-9f06-67e8f32a6a61@gmx.de>

Dear Ivan,

thanks a lot, that is helpful.

Still, I feel that default partial matching cripples the functionality
of data.frame for larger tables.

Thanks again and best regards

Hilmar

On 12.12.23 13:55, Ivan Krylov wrote:
> ? Mon, 11 Dec 2023 21:11:48 +0100
> Hilmar Berger via R-devel <r-devel at r-project.org> ?????:
>
>> What was unexpected is that in this case was that [.data.frame was
>> hanging for a long time (I waited about 10 minutes and then restarted
>> R). Also, this cannot be interrupted in interactive mode.
> That's unfortunate. If an operation takes a long time, it ought to be
> interruptible. Here's a patch that passes make check-devel:
>
> --- src/main/unique.c	(revision 85667)
> +++ src/main/unique.c	(working copy)
> @@ -1631,6 +1631,7 @@
>   	}
>       }
>
> +    unsigned int ic = 9999;
>       if(nexact < n_input) {
>   	/* Second pass, partial matching */
>   	for (R_xlen_t i = 0; i < n_input; i++) {
> @@ -1642,6 +1643,10 @@
>   	    mtch = 0;
>   	    mtch_count = 0;
>   	    for (int j = 0; j < n_target; j++) {
> +		if (!--ic) {
> +		    R_CheckUserInterrupt();
> +		    ic = 9999;
> +		}
>   		if (no_dups && used[j]) continue;
>   		if (strncmp(ss, tar[j], temp) == 0) {
>   		    mtch = j + 1;
>


From |@go@g|ne @end|ng |rom @jd@e@  Wed Dec 13 10:19:04 2023
From: |@go@g|ne @end|ng |rom @jd@e@ (=?iso-8859-1?Q?Iago_Gin=E9_V=E1zquez?=)
Date: Wed, 13 Dec 2023 09:19:04 +0000
Subject: [Rd] Request: documenting more specifically language objects in the
 R Language Definition document
Message-ID: <AM6PR02MB4423AAD93EAD292D78BF3CF4948DA@AM6PR02MB4423.eurprd02.prod.outlook.com>

Dear  all,


This is a request to get language objects more documented in the R Language Definition document (CRAN version<https://cran.r-project.org/doc/manuals/r-release/R-lang.html>, ETHZ R-devel version<https://stat.ethz.ch/R-manual/R-devel/doc/manual/R-lang.html>).

Section '2.1.3 Language objects' claims
There are three types of objects that constitute the R language. They are calls, expressions, and names.
But then there is only a subsection '2.1.3.1 Symbol objects' which, if I do not understand wrongly, correspond to names subtype of language objects. It would be great if calls and expressions subtypes were specified with more detail as well. And also calls subtype 'formula'.

I came to here since when looking help for formula, it documents the stats function formula -Model Formula-, and it just says that it produces an object of class '"formula"' [...] and that a formula object has an associated environment [...]. Maybe this, and saying  that the mode of a formula is a call it is enough to describe a formula?

Same section 2.1.3 also claims

They can be [...] converted to and from lists by the as.list and as.call functions

It could be added also a description of how these lists should be (structured, their components, names, etc.) for the different language objects, that is, for names, expressions, calls, formulas and so on.

Thank you.

Best wishes,
Iago




	[[alternative HTML version deleted]]


From murdoch@dunc@n @end|ng |rom gm@||@com  Wed Dec 13 11:27:53 2023
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Wed, 13 Dec 2023 05:27:53 -0500
Subject: [Rd] 
 Request: documenting more specifically language objects in the
 R Language Definition document
In-Reply-To: <AM6PR02MB4423AAD93EAD292D78BF3CF4948DA@AM6PR02MB4423.eurprd02.prod.outlook.com>
References: <AM6PR02MB4423AAD93EAD292D78BF3CF4948DA@AM6PR02MB4423.eurprd02.prod.outlook.com>
Message-ID: <6218e0e0-d23f-429a-9e50-2229175bf97a@gmail.com>

I doubt if anyone will take you up on this request.  Only R Core members 
can change those manuals, and it's hard work to write clear and correct 
documentation.  This probably won't make it high enough on their lists 
of priorities to actually be addressed.

What you could do is try to write it yourself.  Find some helpers who 
really know the details (not necessarily R Core members) to review your 
proposal.  Once you have it written and everyone agrees it is correct, 
either publish it as a blog entry somewhere, or submit it to R Core for 
inclusion in the manual.  I don't recommend posting early drafts to this 
mailing list, though you could post near-final ones here:  you're only 
going to get a few comments before people lose interest.

This would be a lot of work for you.  Besides the work of writing 
clearly and correctly, you need to learn the material.  But that's a big 
benefit for you if you are really interested in working with this kind 
of thing.

Duncan Murdoch

On 13/12/2023 4:19 a.m., Iago Gin? V?zquez wrote:
> Dear  all,
> 
> 
> This is a request to get language objects more documented in the R Language Definition document (CRAN version<https://cran.r-project.org/doc/manuals/r-release/R-lang.html>, ETHZ R-devel version<https://stat.ethz.ch/R-manual/R-devel/doc/manual/R-lang.html>).
> 
> Section '2.1.3 Language objects' claims
> There are three types of objects that constitute the R language. They are calls, expressions, and names.
> But then there is only a subsection '2.1.3.1 Symbol objects' which, if I do not understand wrongly, correspond to names subtype of language objects. It would be great if calls and expressions subtypes were specified with more detail as well. And also calls subtype 'formula'.
> 
> I came to here since when looking help for formula, it documents the stats function formula -Model Formula-, and it just says that it produces an object of class '"formula"' [...] and that a formula object has an associated environment [...]. Maybe this, and saying  that the mode of a formula is a call it is enough to describe a formula?
> 
> Same section 2.1.3 also claims
> 
> They can be [...] converted to and from lists by the as.list and as.call functions
> 
> It could be added also a description of how these lists should be (structured, their components, names, etc.) for the different language objects, that is, for names, expressions, calls, formulas and so on.
> 
> Thank you.
> 
> Best wishes,
> Iago
> 
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From tom@@@k@||ber@ @end|ng |rom gm@||@com  Wed Dec 13 12:05:23 2023
From: tom@@@k@||ber@ @end|ng |rom gm@||@com (Tomas Kalibera)
Date: Wed, 13 Dec 2023 12:05:23 +0100
Subject: [Rd] 
 Request: documenting more specifically language objects in the
 R Language Definition document
In-Reply-To: <6218e0e0-d23f-429a-9e50-2229175bf97a@gmail.com>
References: <AM6PR02MB4423AAD93EAD292D78BF3CF4948DA@AM6PR02MB4423.eurprd02.prod.outlook.com>
 <6218e0e0-d23f-429a-9e50-2229175bf97a@gmail.com>
Message-ID: <69d74d33-fcd1-455a-85e4-5d496813f327@gmail.com>

On 12/13/23 11:27, Duncan Murdoch wrote:
> I doubt if anyone will take you up on this request.? Only R Core 
> members can change those manuals, and it's hard work to write clear 
> and correct documentation.? This probably won't make it high enough on 
> their lists of priorities to actually be addressed.

There is another aspect of this - portable R packages only use 
documented behavior of R, relying on that such behavior will not change 
unless absolutely necessary. A very hard part of writing/expanding the 
official documentation is deciding on what should and what shouldn't be 
the stable/documented behavior, and even more so when it is about 
fundamental things. It is essential that some behavior stays 
undocumented and is not relied on, otherwise it wouldn't be possible to 
maintain and improve R.

So if you primarily wanted to get an answer to a specific technical 
question about say formulas, it is best to just ask that question, 
rather than asking for expanding the documentation.

Tomas


>
> What you could do is try to write it yourself.? Find some helpers who 
> really know the details (not necessarily R Core members) to review 
> your proposal.? Once you have it written and everyone agrees it is 
> correct, either publish it as a blog entry somewhere, or submit it to 
> R Core for inclusion in the manual.? I don't recommend posting early 
> drafts to this mailing list, though you could post near-final ones 
> here:? you're only going to get a few comments before people lose 
> interest.
>
> This would be a lot of work for you.? Besides the work of writing 
> clearly and correctly, you need to learn the material.? But that's a 
> big benefit for you if you are really interested in working with this 
> kind of thing.
>
> Duncan Murdoch
>
> On 13/12/2023 4:19 a.m., Iago Gin? V?zquez wrote:
>> Dear? all,
>>
>>
>> This is a request to get language objects more documented in the R 
>> Language Definition document (CRAN 
>> version<https://cran.r-project.org/doc/manuals/r-release/R-lang.html>, 
>> ETHZ R-devel 
>> version<https://stat.ethz.ch/R-manual/R-devel/doc/manual/R-lang.html>).
>>
>> Section '2.1.3 Language objects' claims
>> There are three types of objects that constitute the R language. They 
>> are calls, expressions, and names.
>> But then there is only a subsection '2.1.3.1 Symbol objects' which, 
>> if I do not understand wrongly, correspond to names subtype of 
>> language objects. It would be great if calls and expressions subtypes 
>> were specified with more detail as well. And also calls subtype 
>> 'formula'.
>>
>> I came to here since when looking help for formula, it documents the 
>> stats function formula -Model Formula-, and it just says that it 
>> produces an object of class '"formula"' [...] and that a formula 
>> object has an associated environment [...]. Maybe this, and saying? 
>> that the mode of a formula is a call it is enough to describe a formula?
>>
>> Same section 2.1.3 also claims
>>
>> They can be [...] converted to and from lists by the as.list and 
>> as.call functions
>>
>> It could be added also a description of how these lists should be 
>> (structured, their components, names, etc.) for the different 
>> language objects, that is, for names, expressions, calls, formulas 
>> and so on.
>>
>> Thank you.
>>
>> Best wishes,
>> Iago
>>
>>
>>
>>
>> ????[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From |@go@g|ne @end|ng |rom @jd@e@  Wed Dec 13 13:31:17 2023
From: |@go@g|ne @end|ng |rom @jd@e@ (=?UTF-8?Q?Iago_Gin=C3=A9_V=C3=A1zquez?=)
Date: Wed, 13 Dec 2023 13:31:17 +0100
Subject: [Rd] 
 Request: documenting more specifically language objects in the
 R Language Definition document
In-Reply-To: <69d74d33-fcd1-455a-85e4-5d496813f327@gmail.com>
References: <AM6PR02MB4423AAD93EAD292D78BF3CF4948DA@AM6PR02MB4423.eurprd02.prod.outlook.com>
 <6218e0e0-d23f-429a-9e50-2229175bf97a@gmail.com>
 <69d74d33-fcd1-455a-85e4-5d496813f327@gmail.com>
Message-ID: <9a0d268e-00cf-43b3-b8b7-bc91e578e820@sjd.es>

Thank you for your answers.

Just let me disagree slightly with Tomas view.

On 13/12/2023 12:05, Tomas Kalibera wrote:
> On 12/13/23 11:27, Duncan Murdoch wrote:
>> I doubt if anyone will take you up on this request.? Only R Core 
>> members can change those manuals, and it's hard work to write clear 
>> and correct documentation.? This probably won't make it high enough 
>> on their lists of priorities to actually be addressed.
>
> There is another aspect of this - portable R packages only use 
> documented behavior of R, relying on that such behavior will not 
> change unless absolutely necessary. A very hard part of 
> writing/expanding the official documentation is deciding on what 
> should and what shouldn't be the stable/documented behavior, and even 
> more so when it is about fundamental things. It is essential that some 
> behavior stays undocumented and is not relied on, otherwise it 
> wouldn't be possible to maintain and improve R.

Actually, I would say that "portable R packages" use a lot these types 
of objects (formulas, calls, ...) and I would bet that they even use 
quite a lot of the undocumented behaviour I would expect to find, which 
is more needed precisely "when it is about fundamental things".


Iago


>
> So if you primarily wanted to get an answer to a specific technical 
> question about say formulas, it is best to just ask that question, 
> rather than asking for expanding the documentation.
>
> Tomas
>
>
>>
>> What you could do is try to write it yourself.? Find some helpers who 
>> really know the details (not necessarily R Core members) to review 
>> your proposal.? Once you have it written and everyone agrees it is 
>> correct, either publish it as a blog entry somewhere, or submit it to 
>> R Core for inclusion in the manual. I don't recommend posting early 
>> drafts to this mailing list, though you could post near-final ones 
>> here:? you're only going to get a few comments before people lose 
>> interest.
>>
>> This would be a lot of work for you.? Besides the work of writing 
>> clearly and correctly, you need to learn the material. But that's a 
>> big benefit for you if you are really interested in working with this 
>> kind of thing.
>>
>> Duncan Murdoch
>>
>> On 13/12/2023 4:19 a.m., Iago Gin? V?zquez wrote:
>>> Dear? all,
>>>
>>>
>>> This is a request to get language objects more documented in the R 
>>> Language Definition document (CRAN 
>>> version<https://cran.r-project.org/doc/manuals/r-release/R-lang.html>, 
>>> ETHZ R-devel 
>>> version<https://stat.ethz.ch/R-manual/R-devel/doc/manual/R-lang.html>).
>>>
>>> Section '2.1.3 Language objects' claims
>>> There are three types of objects that constitute the R language. 
>>> They are calls, expressions, and names.
>>> But then there is only a subsection '2.1.3.1 Symbol objects' which, 
>>> if I do not understand wrongly, correspond to names subtype of 
>>> language objects. It would be great if calls and expressions 
>>> subtypes were specified with more detail as well. And also calls 
>>> subtype 'formula'.
>>>
>>> I came to here since when looking help for formula, it documents the 
>>> stats function formula -Model Formula-, and it just says that it 
>>> produces an object of class '"formula"' [...] and that a formula 
>>> object has an associated environment [...]. Maybe this, and saying? 
>>> that the mode of a formula is a call it is enough to describe a 
>>> formula?
>>>
>>> Same section 2.1.3 also claims
>>>
>>> They can be [...] converted to and from lists by the as.list and 
>>> as.call functions
>>>
>>> It could be added also a description of how these lists should be 
>>> (structured, their components, names, etc.) for the different 
>>> language objects, that is, for names, expressions, calls, formulas 
>>> and so on.
>>>
>>> Thank you.
>>>
>>> Best wishes,
>>> Iago
>>>
>>>
>>>
>>>
>>> ????[[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
	[[alternative HTML version deleted]]


From kry|ov@r00t @end|ng |rom gm@||@com  Sat Dec 16 10:48:42 2023
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Sat, 16 Dec 2023 12:48:42 +0300
Subject: [Rd] 
 Partial matching performance in data frame rownames using [
In-Reply-To: <8022eea1-9577-476c-9f06-67e8f32a6a61@gmx.de>
References: <de5e1dad-7ffc-4c35-8c51-1e0e21e585b9@gmx.de>
 <20231212155519.2ccbd3d2@arachnoid>
 <8022eea1-9577-476c-9f06-67e8f32a6a61@gmx.de>
Message-ID: <20231216124842.4d889cdd@Tarkus>

On Wed, 13 Dec 2023 09:04:18 +0100
Hilmar Berger via R-devel <r-devel at r-project.org> wrote:

> Still, I feel that default partial matching cripples the functionality
> of data.frame for larger tables.

Changing the default now would require a long deprecation cycle to give
everyone who uses `[.data.frame` and relies on partial matching
(whether they know it or not) enough time to adjust.

Still, adding an argument feels like a small change: edit
https://svn.r-project.org/R/trunk/src/library/base/R/dataframe.R and
add a condition before calling pmatch(). Adjust the warning() for named
arguments. Don't forget to document the new argument in the man page at
https://svn.r-project.org/R/trunk/src/library/base/man/Extract.data.frame.Rd

Index: src/library/base/R/dataframe.R
===================================================================
--- src/library/base/R/dataframe.R	(revision 85664)
+++ src/library/base/R/dataframe.R	(working copy)
@@ -591,14 +591,14 @@
 ###  These are a little less general than S
 
 `[.data.frame` <-
-    function(x, i, j, drop = if(missing(i)) TRUE else length(cols) == 1)
+    function(x, i, j, drop = if(missing(i)) TRUE else length(cols) == 1, pmatch.rows = TRUE)
 {
     mdrop <- missing(drop)
     Narg <- nargs() - !mdrop  # number of arg from x,i,j that were specified
     has.j <- !missing(j)
-    if(!all(names(sys.call()) %in% c("", "drop"))
+    if(!all(names(sys.call()) %in% c("", "drop", "pmatch.rows"))
        && !isS4(x)) # at least don't warn for callNextMethod!
-        warning("named arguments other than 'drop' are discouraged")
+        warning("named arguments other than 'drop', 'pmatch.rows' are discouraged")
 
     if(Narg < 3L) {  # list-like indexing or matrix indexing
         if(!mdrop) warning("'drop' argument will be ignored")
@@ -679,7 +679,11 @@
             ## for consistency with [, <length-1>]
             if(is.character(i)) {
                 rows <- attr(xx, "row.names")
-                i <- pmatch(i, rows, duplicates.ok = TRUE)
+                i <- if (pmatch.rows) {
+                    pmatch(i, rows, duplicates.ok = TRUE)
+                } else {
+                    match(i, rows)
+                }
             }
             ## need to figure which col was selected:
             ## cannot use .subset2 directly as that may
@@ -699,7 +703,11 @@
                  # as this can be expensive.
     if(is.character(i)) {
         rows <- attr(xx, "row.names")
-        i <- pmatch(i, rows, duplicates.ok = TRUE)
+        i <- if (pmatch.rows) {
+            pmatch(i, rows, duplicates.ok = TRUE)
+        } else {
+            match(i, rows)
+        }
     }
     for(j in seq_along(x)) {
         xj <- xx[[ sxx[j] ]]
Index: src/library/base/man/Extract.data.frame.Rd
===================================================================
--- src/library/base/man/Extract.data.frame.Rd	(revision 85664)
+++ src/library/base/man/Extract.data.frame.Rd	(working copy)
@@ -15,7 +15,7 @@
   Extract or replace subsets of data frames.
 }
 \usage{
-\method{[}{data.frame}(x, i, j, drop = )
+\method{[}{data.frame}(x, i, j, drop =, pmatch.rows = TRUE)
 \method{[}{data.frame}(x, i, j) <- value
 \method{[[}{data.frame}(x, ..., exact = TRUE)
 \method{[[}{data.frame}(x, i, j) <- value
@@ -45,6 +45,9 @@
     column is selected.}
 
    \item{exact}{logical: see \code{\link{[}}, and applies to column names.}
+
+   \item{pmatch.rows}{logical: whether to perform partial matching on
+     row names in case \code{i} is a character vector.}
 }
 \details{
   Data frames can be indexed in several modes.  When \code{[} and


system.time({r <- d1[q2,, drop=FALSE, pmatch.rows = FALSE]})
#    user  system elapsed 
#   0.478   0.004   0.482 

Unfortunately, that would be only the beginning. The prose in the whole
?`[.data.frame` would have to be updated; the new behaviour would have
to be tested in tests/**.R. There may be very good reasons why named
arguments to `[` other than drop= are discouraged for data.frames. I'm
afraid I lack the whole-project view to consider whether such an
addition would be safe.

-- 
Best regards,
Ivan


From greg @end|ng |rom w@rne@@net  Sat Dec 16 23:34:18 2023
From: greg @end|ng |rom w@rne@@net (Gregory Warnes)
Date: Sat, 16 Dec 2023 17:34:18 -0500
Subject: [Rd] zapsmall(x) for scalar x
Message-ID: <EC76CAE0-A775-4DCB-AD99-81B47E963225@warnes.net>

I was quite suprised to discover that applying `zapsmall` to a scalar value has no apparent effect.  For example: 

> y <- 2.220446e-16
> zapsmall(y,)
[1] 2.2204e-16

I was expecting zapsmall(x)` to act like

> round(y, digits=getOption('digits'))
[1] 0

Looking at the current source code, indicates that `zapsmall` is expecting a vector:

zapsmall <-
function (x, digits = getOption("digits")) 
{
    if (length(digits) == 0L) 
        stop("invalid 'digits'")
    if (all(ina <- is.na(x))) 
        return(x)
    mx <- max(abs(x[!ina]))
    round(x, digits = if (mx > 0) max(0L, digits - as.numeric(log10(mx))) else digits)
}

If `x` is a non-zero scalar, zapsmall will never perform rounding.

The man page simply states:
zapsmall determines a digits argument dr for calling round(x, digits = dr) such that values close to zero (compared with the maximal absolute value) are ?zapped?, i.e., replaced by 0.

and doesn?t provide any details about how ?close to zero? is defined. 

Perhaps handling the special when `x` is a scalar (or only contains a single non-NA value)  would make sense:

zapsmall <-
function (x, digits = getOption("digits")) 
{
    if (length(digits) == 0L) 
        stop("invalid 'digits'")
    if (all(ina <- is.na(x))) 
        return(x)
    mx <- max(abs(x[!ina]))
    round(x, digits = if (mx > 0 && (length(x)-sum(ina))>1 ) max(0L, digits - as.numeric(log10(mx))) else digits)
}

Yielding:

> y <- 2.220446e-16
> zapsmall(y)
[1] 0

Another edge case would be when all of the non-na values are the same:

> y <- 2.220446e-16
> zapsmall(c(y,y))
[1] 2.220446e-16 2.220446e-16

Thoughts?


Gregory R. Warnes, Ph.D.
greg at warnes.net
Eternity is a long time, take a friend!



	[[alternative HTML version deleted]]


From @tevem@rt|n041 @end|ng |rom gm@||@com  Sun Dec 17 06:11:31 2023
From: @tevem@rt|n041 @end|ng |rom gm@||@com (Steve Martin)
Date: Sun, 17 Dec 2023 00:11:31 -0500
Subject: [Rd] zapsmall(x) for scalar x
In-Reply-To: <EC76CAE0-A775-4DCB-AD99-81B47E963225@warnes.net>
References: <EC76CAE0-A775-4DCB-AD99-81B47E963225@warnes.net>
Message-ID: <CAP=dwz8bGEvMEiXL+64dNH0cYtvAF3Y6ouCiVfX99y+1-VGGUA@mail.gmail.com>

Zapping a vector of small numbers to zero would cause problems when
printing the results of summary(). For example, if
zapsmall(c(2.220446e-16, ..., 2.220446e-16)) == c(0, ..., 0) then
print(summary(2.220446e-16), digits = 7) would print
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
        0          0            0           0           0          0

The same problem can also appear when printing the results of
summary.glm() with show.residuals = TRUE if there's little dispersion
in the residuals.

Steve

On Sat, 16 Dec 2023 at 17:34, Gregory Warnes <greg at warnes.net> wrote:
>
> I was quite suprised to discover that applying `zapsmall` to a scalar value has no apparent effect.  For example:
>
> > y <- 2.220446e-16
> > zapsmall(y,)
> [1] 2.2204e-16
>
> I was expecting zapsmall(x)` to act like
>
> > round(y, digits=getOption('digits'))
> [1] 0
>
> Looking at the current source code, indicates that `zapsmall` is expecting a vector:
>
> zapsmall <-
> function (x, digits = getOption("digits"))
> {
>     if (length(digits) == 0L)
>         stop("invalid 'digits'")
>     if (all(ina <- is.na(x)))
>         return(x)
>     mx <- max(abs(x[!ina]))
>     round(x, digits = if (mx > 0) max(0L, digits - as.numeric(log10(mx))) else digits)
> }
>
> If `x` is a non-zero scalar, zapsmall will never perform rounding.
>
> The man page simply states:
> zapsmall determines a digits argument dr for calling round(x, digits = dr) such that values close to zero (compared with the maximal absolute value) are ?zapped?, i.e., replaced by 0.
>
> and doesn?t provide any details about how ?close to zero? is defined.
>
> Perhaps handling the special when `x` is a scalar (or only contains a single non-NA value)  would make sense:
>
> zapsmall <-
> function (x, digits = getOption("digits"))
> {
>     if (length(digits) == 0L)
>         stop("invalid 'digits'")
>     if (all(ina <- is.na(x)))
>         return(x)
>     mx <- max(abs(x[!ina]))
>     round(x, digits = if (mx > 0 && (length(x)-sum(ina))>1 ) max(0L, digits - as.numeric(log10(mx))) else digits)
> }
>
> Yielding:
>
> > y <- 2.220446e-16
> > zapsmall(y)
> [1] 0
>
> Another edge case would be when all of the non-na values are the same:
>
> > y <- 2.220446e-16
> > zapsmall(c(y,y))
> [1] 2.220446e-16 2.220446e-16
>
> Thoughts?
>
>
> Gregory R. Warnes, Ph.D.
> greg at warnes.net
> Eternity is a long time, take a friend!
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From greg @end|ng |rom w@rne@@net  Sun Dec 17 14:43:08 2023
From: greg @end|ng |rom w@rne@@net (Gregory R. Warnes)
Date: Sun, 17 Dec 2023 08:43:08 -0500
Subject: [Rd] zapsmall(x) for scalar x
In-Reply-To: <CAP=dwz8bGEvMEiXL+64dNH0cYtvAF3Y6ouCiVfX99y+1-VGGUA@mail.gmail.com>
References: <CAP=dwz8bGEvMEiXL+64dNH0cYtvAF3Y6ouCiVfX99y+1-VGGUA@mail.gmail.com>
Message-ID: <B7FE40A5-18D3-437B-A446-EEA5B20A98AA@warnes.net>

Isn?t that the correct outcome?  The user can change the number of digits if they want to see small values?


--  
Change your thoughts and you change the world.
--Dr. Norman Vincent Peale

> On Dec 17, 2023, at 12:11?AM, Steve Martin <stevemartin041 at gmail.com> wrote:
> 
> ?Zapping a vector of small numbers to zero would cause problems when
> printing the results of summary(). For example, if
> zapsmall(c(2.220446e-16, ..., 2.220446e-16)) == c(0, ..., 0) then
> print(summary(2.220446e-16), digits = 7) would print
>   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
>        0          0            0           0           0          0
> 
> The same problem can also appear when printing the results of
> summary.glm() with show.residuals = TRUE if there's little dispersion
> in the residuals.
> 
> Steve
> 
>> On Sat, 16 Dec 2023 at 17:34, Gregory Warnes <greg at warnes.net> wrote:
>> 
>> I was quite suprised to discover that applying `zapsmall` to a scalar value has no apparent effect.  For example:
>> 
>>> y <- 2.220446e-16
>>> zapsmall(y,)
>> [1] 2.2204e-16
>> 
>> I was expecting zapsmall(x)` to act like
>> 
>>> round(y, digits=getOption('digits'))
>> [1] 0
>> 
>> Looking at the current source code, indicates that `zapsmall` is expecting a vector:
>> 
>> zapsmall <-
>> function (x, digits = getOption("digits"))
>> {
>>    if (length(digits) == 0L)
>>        stop("invalid 'digits'")
>>    if (all(ina <- is.na(x)))
>>        return(x)
>>    mx <- max(abs(x[!ina]))
>>    round(x, digits = if (mx > 0) max(0L, digits - as.numeric(log10(mx))) else digits)
>> }
>> 
>> If `x` is a non-zero scalar, zapsmall will never perform rounding.
>> 
>> The man page simply states:
>> zapsmall determines a digits argument dr for calling round(x, digits = dr) such that values close to zero (compared with the maximal absolute value) are ?zapped?, i.e., replaced by 0.
>> 
>> and doesn?t provide any details about how ?close to zero? is defined.
>> 
>> Perhaps handling the special when `x` is a scalar (or only contains a single non-NA value)  would make sense:
>> 
>> zapsmall <-
>> function (x, digits = getOption("digits"))
>> {
>>    if (length(digits) == 0L)
>>        stop("invalid 'digits'")
>>    if (all(ina <- is.na(x)))
>>        return(x)
>>    mx <- max(abs(x[!ina]))
>>    round(x, digits = if (mx > 0 && (length(x)-sum(ina))>1 ) max(0L, digits - as.numeric(log10(mx))) else digits)
>> }
>> 
>> Yielding:
>> 
>>> y <- 2.220446e-16
>>> zapsmall(y)
>> [1] 0
>> 
>> Another edge case would be when all of the non-na values are the same:
>> 
>>> y <- 2.220446e-16
>>> zapsmall(c(y,y))
>> [1] 2.220446e-16 2.220446e-16
>> 
>> Thoughts?
>> 
>> 
>> Gregory R. Warnes, Ph.D.
>> greg at warnes.net
>> Eternity is a long time, take a friend!
>> 
>> 
>> 
>>        [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel

	[[alternative HTML version deleted]]


From murdoch@dunc@n @end|ng |rom gm@||@com  Sun Dec 17 15:17:03 2023
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Sun, 17 Dec 2023 09:17:03 -0500
Subject: [Rd] zapsmall(x) for scalar x
In-Reply-To: <B7FE40A5-18D3-437B-A446-EEA5B20A98AA@warnes.net>
References: <CAP=dwz8bGEvMEiXL+64dNH0cYtvAF3Y6ouCiVfX99y+1-VGGUA@mail.gmail.com>
 <B7FE40A5-18D3-437B-A446-EEA5B20A98AA@warnes.net>
Message-ID: <f993249d-65be-4a14-b9a6-003a05398a29@gmail.com>

I'm really confused.  Steve's example wasn't a scalar x, it was a 
vector.  Your zapsmall() proposal wouldn't zap it to zero, and I don't 
see why summary() would if it was using your proposal.

Duncan Murdoch

On 17/12/2023 8:43 a.m., Gregory R. Warnes wrote:
> Isn?t that the correct outcome?  The user can change the number of digits if they want to see small values?
> 
> 
> --
> Change your thoughts and you change the world.
> --Dr. Norman Vincent Peale
> 
>> On Dec 17, 2023, at 12:11?AM, Steve Martin <stevemartin041 at gmail.com> wrote:
>>
>> ?Zapping a vector of small numbers to zero would cause problems when
>> printing the results of summary(). For example, if
>> zapsmall(c(2.220446e-16, ..., 2.220446e-16)) == c(0, ..., 0) then
>> print(summary(2.220446e-16), digits = 7) would print
>>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
>>         0          0            0           0           0          0
>>
>> The same problem can also appear when printing the results of
>> summary.glm() with show.residuals = TRUE if there's little dispersion
>> in the residuals.
>>
>> Steve
>>
>>> On Sat, 16 Dec 2023 at 17:34, Gregory Warnes <greg at warnes.net> wrote:
>>>
>>> I was quite suprised to discover that applying `zapsmall` to a scalar value has no apparent effect.  For example:
>>>
>>>> y <- 2.220446e-16
>>>> zapsmall(y,)
>>> [1] 2.2204e-16
>>>
>>> I was expecting zapsmall(x)` to act like
>>>
>>>> round(y, digits=getOption('digits'))
>>> [1] 0
>>>
>>> Looking at the current source code, indicates that `zapsmall` is expecting a vector:
>>>
>>> zapsmall <-
>>> function (x, digits = getOption("digits"))
>>> {
>>>     if (length(digits) == 0L)
>>>         stop("invalid 'digits'")
>>>     if (all(ina <- is.na(x)))
>>>         return(x)
>>>     mx <- max(abs(x[!ina]))
>>>     round(x, digits = if (mx > 0) max(0L, digits - as.numeric(log10(mx))) else digits)
>>> }
>>>
>>> If `x` is a non-zero scalar, zapsmall will never perform rounding.
>>>
>>> The man page simply states:
>>> zapsmall determines a digits argument dr for calling round(x, digits = dr) such that values close to zero (compared with the maximal absolute value) are ?zapped?, i.e., replaced by 0.
>>>
>>> and doesn?t provide any details about how ?close to zero? is defined.
>>>
>>> Perhaps handling the special when `x` is a scalar (or only contains a single non-NA value)  would make sense:
>>>
>>> zapsmall <-
>>> function (x, digits = getOption("digits"))
>>> {
>>>     if (length(digits) == 0L)
>>>         stop("invalid 'digits'")
>>>     if (all(ina <- is.na(x)))
>>>         return(x)
>>>     mx <- max(abs(x[!ina]))
>>>     round(x, digits = if (mx > 0 && (length(x)-sum(ina))>1 ) max(0L, digits - as.numeric(log10(mx))) else digits)
>>> }
>>>
>>> Yielding:
>>>
>>>> y <- 2.220446e-16
>>>> zapsmall(y)
>>> [1] 0
>>>
>>> Another edge case would be when all of the non-na values are the same:
>>>
>>>> y <- 2.220446e-16
>>>> zapsmall(c(y,y))
>>> [1] 2.220446e-16 2.220446e-16
>>>
>>> Thoughts?
>>>
>>>
>>> Gregory R. Warnes, Ph.D.
>>> greg at warnes.net
>>> Eternity is a long time, take a friend!
>>>
>>>
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From b@row||ng@on @end|ng |rom |@nc@@ter@@c@uk  Sun Dec 17 18:26:23 2023
From: b@row||ng@on @end|ng |rom |@nc@@ter@@c@uk (Barry Rowlingson)
Date: Sun, 17 Dec 2023 17:26:23 +0000
Subject: [Rd] [External] Re:  zapsmall(x) for scalar x
In-Reply-To: <bbcaa531201446a69c7fdedd311393ed@LO6P265MB6080.GBRP265.PROD.OUTLOOK.COM>
References: <CAP=dwz8bGEvMEiXL+64dNH0cYtvAF3Y6ouCiVfX99y+1-VGGUA@mail.gmail.com>
 <B7FE40A5-18D3-437B-A446-EEA5B20A98AA@warnes.net>
 <bbcaa531201446a69c7fdedd311393ed@LO6P265MB6080.GBRP265.PROD.OUTLOOK.COM>
Message-ID: <CANVKczNLxChkreGnAa=oDUz7w8SEG_i3xW3_9k3BjaC7Q_Y+9Q@mail.gmail.com>

I think what's been missed is that zapsmall works relative to the absolute
largest value in the vector. Hence if there's only one
item in the vector, it is the largest, so its not zapped. The function's
raison d'etre isn't to replace absolutely small values,
but small values relative to the largest. Hence a vector of similar tiny
values doesn't get zapped.

Maybe the line in the docs:

" (compared with the maximal absolute value)"

needs to read:

" (compared with the maximal absolute value in the vector)"

Barry





On Sun, Dec 17, 2023 at 2:17?PM Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> This email originated outside the University. Check before clicking links
> or attachments.
>
> I'm really confused.  Steve's example wasn't a scalar x, it was a
> vector.  Your zapsmall() proposal wouldn't zap it to zero, and I don't
> see why summary() would if it was using your proposal.
>
> Duncan Murdoch
>
> On 17/12/2023 8:43 a.m., Gregory R. Warnes wrote:
> > Isn?t that the correct outcome?  The user can change the number of
> digits if they want to see small values?
> >
> >
> > --
> > Change your thoughts and you change the world.
> > --Dr. Norman Vincent Peale
> >
> >> On Dec 17, 2023, at 12:11?AM, Steve Martin <stevemartin041 at gmail.com>
> wrote:
> >>
> >> ?Zapping a vector of small numbers to zero would cause problems when
> >> printing the results of summary(). For example, if
> >> zapsmall(c(2.220446e-16, ..., 2.220446e-16)) == c(0, ..., 0) then
> >> print(summary(2.220446e-16), digits = 7) would print
> >>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
> >>         0          0            0           0           0          0
> >>
> >> The same problem can also appear when printing the results of
> >> summary.glm() with show.residuals = TRUE if there's little dispersion
> >> in the residuals.
> >>
> >> Steve
> >>
> >>> On Sat, 16 Dec 2023 at 17:34, Gregory Warnes <greg at warnes.net> wrote:
> >>>
> >>> I was quite suprised to discover that applying `zapsmall` to a scalar
> value has no apparent effect.  For example:
> >>>
> >>>> y <- 2.220446e-16
> >>>> zapsmall(y,)
> >>> [1] 2.2204e-16
> >>>
> >>> I was expecting zapsmall(x)` to act like
> >>>
> >>>> round(y, digits=getOption('digits'))
> >>> [1] 0
> >>>
> >>> Looking at the current source code, indicates that `zapsmall` is
> expecting a vector:
> >>>
> >>> zapsmall <-
> >>> function (x, digits = getOption("digits"))
> >>> {
> >>>     if (length(digits) == 0L)
> >>>         stop("invalid 'digits'")
> >>>     if (all(ina <- is.na(x)))
> >>>         return(x)
> >>>     mx <- max(abs(x[!ina]))
> >>>     round(x, digits = if (mx > 0) max(0L, digits -
> as.numeric(log10(mx))) else digits)
> >>> }
> >>>
> >>> If `x` is a non-zero scalar, zapsmall will never perform rounding.
> >>>
> >>> The man page simply states:
> >>> zapsmall determines a digits argument dr for calling round(x, digits =
> dr) such that values close to zero (compared with the maximal absolute
> value) are ?zapped?, i.e., replaced by 0.
> >>>
> >>> and doesn?t provide any details about how ?close to zero? is defined.
> >>>
> >>> Perhaps handling the special when `x` is a scalar (or only contains a
> single non-NA value)  would make sense:
> >>>
> >>> zapsmall <-
> >>> function (x, digits = getOption("digits"))
> >>> {
> >>>     if (length(digits) == 0L)
> >>>         stop("invalid 'digits'")
> >>>     if (all(ina <- is.na(x)))
> >>>         return(x)
> >>>     mx <- max(abs(x[!ina]))
> >>>     round(x, digits = if (mx > 0 && (length(x)-sum(ina))>1 ) max(0L,
> digits - as.numeric(log10(mx))) else digits)
> >>> }
> >>>
> >>> Yielding:
> >>>
> >>>> y <- 2.220446e-16
> >>>> zapsmall(y)
> >>> [1] 0
> >>>
> >>> Another edge case would be when all of the non-na values are the same:
> >>>
> >>>> y <- 2.220446e-16
> >>>> zapsmall(c(y,y))
> >>> [1] 2.220446e-16 2.220446e-16
> >>>
> >>> Thoughts?
> >>>
> >>>
> >>> Gregory R. Warnes, Ph.D.
> >>> greg at warnes.net
> >>> Eternity is a long time, take a friend!
> >>>
> >>>
> >>>
> >>>         [[alternative HTML version deleted]]
> >>>
> >>> ______________________________________________
> >>> R-devel at r-project.org mailing list
> >>> https://stat.ethz.ch/mailman/listinfo/r-devel
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From @tevem@rt|n041 @end|ng |rom gm@||@com  Sun Dec 17 22:01:04 2023
From: @tevem@rt|n041 @end|ng |rom gm@||@com (Steve Martin)
Date: Sun, 17 Dec 2023 16:01:04 -0500
Subject: [Rd] [External] Re:  zapsmall(x) for scalar x
In-Reply-To: <CANVKczNLxChkreGnAa=oDUz7w8SEG_i3xW3_9k3BjaC7Q_Y+9Q@mail.gmail.com>
References: <CAP=dwz8bGEvMEiXL+64dNH0cYtvAF3Y6ouCiVfX99y+1-VGGUA@mail.gmail.com>
 <B7FE40A5-18D3-437B-A446-EEA5B20A98AA@warnes.net>
 <bbcaa531201446a69c7fdedd311393ed@LO6P265MB6080.GBRP265.PROD.OUTLOOK.COM>
 <CANVKczNLxChkreGnAa=oDUz7w8SEG_i3xW3_9k3BjaC7Q_Y+9Q@mail.gmail.com>
Message-ID: <CAP=dwz_yARvyBtBHLwqtPBwZym7zwmTv52xEOXttaYXBb1cKGA@mail.gmail.com>

Sorry for being unclear. I was commenting on the edge case that
Gregory brought up when calling zapsmall() with a vector of small
values. I thought Gregory was asking for thoughts on that as well, but
maybe I misunderstood. IMO it would be weird for zapsmall() to make a
small scalar zero but not a vector of the identical values.

The example with summary() was meant to show that zapping a vector of
small values to 0 could change the current printing behavior for
certain objects. Ducan is right that zapping only a scalar to zero
wouldn't do anything.

>>> Isn?t that the correct outcome?  The user can change the number of digits if they want to see small values?

I'm not sure a user would be able to change the digits without
updating other functions. If xx[finite] <- zapsmall(x[finite]) in
print.summaryDefault() makes a vector of 0s (e.g., zapsmall(x) works
like round(x, digits = getOption("digits")) and getOptions("digits")
is 7) then calling print(summary(2.220446e-16), digits = 16) would
still print a vector of 0s. The digits argument to print() wouldn't do
anything.

In any case, I just wanted to point out that changes to zapsmall() in
the corner case Gregory brought up could affect the way certain
objects are printed, both changing the current behavior and perhaps
requiring changes to some other functions.

Steve

On Sun, 17 Dec 2023 at 12:26, Barry Rowlingson
<b.rowlingson at lancaster.ac.uk> wrote:
>
> I think what's been missed is that zapsmall works relative to the absolute largest value in the vector. Hence if there's only one
> item in the vector, it is the largest, so its not zapped. The function's raison d'etre isn't to replace absolutely small values,
> but small values relative to the largest. Hence a vector of similar tiny values doesn't get zapped.
>
> Maybe the line in the docs:
>
> " (compared with the maximal absolute value)"
>
> needs to read:
>
> " (compared with the maximal absolute value in the vector)"
>
> Barry
>
>
>
>
>
> On Sun, Dec 17, 2023 at 2:17?PM Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>>
>> This email originated outside the University. Check before clicking links or attachments.
>>
>> I'm really confused.  Steve's example wasn't a scalar x, it was a
>> vector.  Your zapsmall() proposal wouldn't zap it to zero, and I don't
>> see why summary() would if it was using your proposal.
>>
>> Duncan Murdoch
>>
>> On 17/12/2023 8:43 a.m., Gregory R. Warnes wrote:
>> > Isn?t that the correct outcome?  The user can change the number of digits if they want to see small values?
>> >
>> >
>> > --
>> > Change your thoughts and you change the world.
>> > --Dr. Norman Vincent Peale
>> >
>> >> On Dec 17, 2023, at 12:11?AM, Steve Martin <stevemartin041 at gmail.com> wrote:
>> >>
>> >> ?Zapping a vector of small numbers to zero would cause problems when
>> >> printing the results of summary(). For example, if
>> >> zapsmall(c(2.220446e-16, ..., 2.220446e-16)) == c(0, ..., 0) then
>> >> print(summary(2.220446e-16), digits = 7) would print
>> >>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
>> >>         0          0            0           0           0          0
>> >>
>> >> The same problem can also appear when printing the results of
>> >> summary.glm() with show.residuals = TRUE if there's little dispersion
>> >> in the residuals.
>> >>
>> >> Steve
>> >>
>> >>> On Sat, 16 Dec 2023 at 17:34, Gregory Warnes <greg at warnes.net> wrote:
>> >>>
>> >>> I was quite suprised to discover that applying `zapsmall` to a scalar value has no apparent effect.  For example:
>> >>>
>> >>>> y <- 2.220446e-16
>> >>>> zapsmall(y,)
>> >>> [1] 2.2204e-16
>> >>>
>> >>> I was expecting zapsmall(x)` to act like
>> >>>
>> >>>> round(y, digits=getOption('digits'))
>> >>> [1] 0
>> >>>
>> >>> Looking at the current source code, indicates that `zapsmall` is expecting a vector:
>> >>>
>> >>> zapsmall <-
>> >>> function (x, digits = getOption("digits"))
>> >>> {
>> >>>     if (length(digits) == 0L)
>> >>>         stop("invalid 'digits'")
>> >>>     if (all(ina <- is.na(x)))
>> >>>         return(x)
>> >>>     mx <- max(abs(x[!ina]))
>> >>>     round(x, digits = if (mx > 0) max(0L, digits - as.numeric(log10(mx))) else digits)
>> >>> }
>> >>>
>> >>> If `x` is a non-zero scalar, zapsmall will never perform rounding.
>> >>>
>> >>> The man page simply states:
>> >>> zapsmall determines a digits argument dr for calling round(x, digits = dr) such that values close to zero (compared with the maximal absolute value) are ?zapped?, i.e., replaced by 0.
>> >>>
>> >>> and doesn?t provide any details about how ?close to zero? is defined.
>> >>>
>> >>> Perhaps handling the special when `x` is a scalar (or only contains a single non-NA value)  would make sense:
>> >>>
>> >>> zapsmall <-
>> >>> function (x, digits = getOption("digits"))
>> >>> {
>> >>>     if (length(digits) == 0L)
>> >>>         stop("invalid 'digits'")
>> >>>     if (all(ina <- is.na(x)))
>> >>>         return(x)
>> >>>     mx <- max(abs(x[!ina]))
>> >>>     round(x, digits = if (mx > 0 && (length(x)-sum(ina))>1 ) max(0L, digits - as.numeric(log10(mx))) else digits)
>> >>> }
>> >>>
>> >>> Yielding:
>> >>>
>> >>>> y <- 2.220446e-16
>> >>>> zapsmall(y)
>> >>> [1] 0
>> >>>
>> >>> Another edge case would be when all of the non-na values are the same:
>> >>>
>> >>>> y <- 2.220446e-16
>> >>>> zapsmall(c(y,y))
>> >>> [1] 2.220446e-16 2.220446e-16
>> >>>
>> >>> Thoughts?
>> >>>
>> >>>
>> >>> Gregory R. Warnes, Ph.D.
>> >>> greg at warnes.net
>> >>> Eternity is a long time, take a friend!
>> >>>
>> >>>
>> >>>
>> >>>         [[alternative HTML version deleted]]
>> >>>
>> >>> ______________________________________________
>> >>> R-devel at r-project.org mailing list
>> >>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-devel at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel


From @oko| @end|ng |rom |n@@-tou|ou@e@|r  Mon Dec 18 10:29:02 2023
From: @oko| @end|ng |rom |n@@-tou|ou@e@|r (Serguei Sokol)
Date: Mon, 18 Dec 2023 10:29:02 +0100
Subject: [Rd] [External] Re: zapsmall(x) for scalar x
In-Reply-To: <CANVKczNLxChkreGnAa=oDUz7w8SEG_i3xW3_9k3BjaC7Q_Y+9Q@mail.gmail.com>
References: <CAP=dwz8bGEvMEiXL+64dNH0cYtvAF3Y6ouCiVfX99y+1-VGGUA@mail.gmail.com>
 <B7FE40A5-18D3-437B-A446-EEA5B20A98AA@warnes.net>
 <bbcaa531201446a69c7fdedd311393ed@LO6P265MB6080.GBRP265.PROD.OUTLOOK.COM>
 <CANVKczNLxChkreGnAa=oDUz7w8SEG_i3xW3_9k3BjaC7Q_Y+9Q@mail.gmail.com>
Message-ID: <f3751191-443f-4577-805a-2577a87506ed@insa-toulouse.fr>

Le 17/12/2023 ? 18:26, Barry Rowlingson a ?crit?:
> I think what's been missed is that zapsmall works relative to the absolute
> largest value in the vector. Hence if there's only one
> item in the vector, it is the largest, so its not zapped. The function's
> raison d'etre isn't to replace absolutely small values,
> but small values relative to the largest. Hence a vector of similar tiny
> values doesn't get zapped.
>
> Maybe the line in the docs:
>
> " (compared with the maximal absolute value)"
>
> needs to read:
>
> " (compared with the maximal absolute value in the vector)"
I agree that this change in the doc would clarify the situation but 
would not resolve proposed corner cases.
I think that an additional argument 'mx' (absolute max value of 
reference) would do. Consider:

zapsmall2 <-
function (x, digits = getOption("digits"), mx=max(abs(x), na.rm=TRUE))
{
 ??? if (length(digits) == 0L)
 ??????? stop("invalid 'digits'")
 ??? if (all(ina <- is.na(x)))
 ??????? return(x)
 ??? round(x, digits = if (mx > 0) max(0L, digits - 
as.numeric(log10(mx))) else digits)
}

then zapsmall2() without explicit 'mx' behaves identically to actual 
zapsmall() and for a scalar or a vector of identical value, user can 
manually fix the scale of what should be considered as small:

 > zapsmall2(y)
[1] 2.220446e-16
 > zapsmall2(y, mx=1)
[1] 0
 > zapsmall2(c(y, y), mx=1)
[1] 0 0
 > zapsmall2(c(y, NA))
[1] 2.220446e-16?????????? NA
 > zapsmall2(c(y, NA), mx=1)
[1]? 0 NA

Obviously, the name 'zapsmall2' was chosen just for this explanation. 
The original name 'zapsmall' could be reused as a full backward 
compatibility is preserved.

Best,
Serguei.

>
> Barry
>
>
>
>
>
> On Sun, Dec 17, 2023 at 2:17?PM Duncan Murdoch <murdoch.duncan at gmail.com>
> wrote:
>
>> This email originated outside the University. Check before clicking links
>> or attachments.
>>
>> I'm really confused.  Steve's example wasn't a scalar x, it was a
>> vector.  Your zapsmall() proposal wouldn't zap it to zero, and I don't
>> see why summary() would if it was using your proposal.
>>
>> Duncan Murdoch
>>
>> On 17/12/2023 8:43 a.m., Gregory R. Warnes wrote:
>>> Isn?t that the correct outcome?  The user can change the number of
>> digits if they want to see small values?
>>>
>>> --
>>> Change your thoughts and you change the world.
>>> --Dr. Norman Vincent Peale
>>>
>>>> On Dec 17, 2023, at 12:11?AM, Steve Martin <stevemartin041 at gmail.com>
>> wrote:
>>>> ?Zapping a vector of small numbers to zero would cause problems when
>>>> printing the results of summary(). For example, if
>>>> zapsmall(c(2.220446e-16, ..., 2.220446e-16)) == c(0, ..., 0) then
>>>> print(summary(2.220446e-16), digits = 7) would print
>>>>     Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
>>>>          0          0            0           0           0          0
>>>>
>>>> The same problem can also appear when printing the results of
>>>> summary.glm() with show.residuals = TRUE if there's little dispersion
>>>> in the residuals.
>>>>
>>>> Steve
>>>>
>>>>> On Sat, 16 Dec 2023 at 17:34, Gregory Warnes <greg at warnes.net> wrote:
>>>>>
>>>>> I was quite suprised to discover that applying `zapsmall` to a scalar
>> value has no apparent effect.  For example:
>>>>>> y <- 2.220446e-16
>>>>>> zapsmall(y,)
>>>>> [1] 2.2204e-16
>>>>>
>>>>> I was expecting zapsmall(x)` to act like
>>>>>
>>>>>> round(y, digits=getOption('digits'))
>>>>> [1] 0
>>>>>
>>>>> Looking at the current source code, indicates that `zapsmall` is
>> expecting a vector:
>>>>> zapsmall <-
>>>>> function (x, digits = getOption("digits"))
>>>>> {
>>>>>      if (length(digits) == 0L)
>>>>>          stop("invalid 'digits'")
>>>>>      if (all(ina <- is.na(x)))
>>>>>          return(x)
>>>>>      mx <- max(abs(x[!ina]))
>>>>>      round(x, digits = if (mx > 0) max(0L, digits -
>> as.numeric(log10(mx))) else digits)
>>>>> }
>>>>>
>>>>> If `x` is a non-zero scalar, zapsmall will never perform rounding.
>>>>>
>>>>> The man page simply states:
>>>>> zapsmall determines a digits argument dr for calling round(x, digits =
>> dr) such that values close to zero (compared with the maximal absolute
>> value) are ?zapped?, i.e., replaced by 0.
>>>>> and doesn?t provide any details about how ?close to zero? is defined.
>>>>>
>>>>> Perhaps handling the special when `x` is a scalar (or only contains a
>> single non-NA value)  would make sense:
>>>>> zapsmall <-
>>>>> function (x, digits = getOption("digits"))
>>>>> {
>>>>>      if (length(digits) == 0L)
>>>>>          stop("invalid 'digits'")
>>>>>      if (all(ina <- is.na(x)))
>>>>>          return(x)
>>>>>      mx <- max(abs(x[!ina]))
>>>>>      round(x, digits = if (mx > 0 && (length(x)-sum(ina))>1 ) max(0L,
>> digits - as.numeric(log10(mx))) else digits)
>>>>> }
>>>>>
>>>>> Yielding:
>>>>>
>>>>>> y <- 2.220446e-16
>>>>>> zapsmall(y)
>>>>> [1] 0
>>>>>
>>>>> Another edge case would be when all of the non-na values are the same:
>>>>>
>>>>>> y <- 2.220446e-16
>>>>>> zapsmall(c(y,y))
>>>>> [1] 2.220446e-16 2.220446e-16
>>>>>
>>>>> Thoughts?
>>>>>
>>>>>
>>>>> Gregory R. Warnes, Ph.D.
>>>>> greg at warnes.net
>>>>> Eternity is a long time, take a friend!
>>>>>
>>>>>
>>>>>
>>>>>          [[alternative HTML version deleted]]
>>>>>
>>>>> ______________________________________________
>>>>> R-devel at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>        [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
Serguei Sokol
Ingenieur de recherche INRAE

Cellule Math?matiques
TBI, INSA/INRAE UMR 792, INSA/CNRS UMR 5504
135 Avenue de Rangueil
31077 Toulouse Cedex 04

tel: +33 5 61 55 98 49
email: sokol at insa-toulouse.fr
https://www.toulouse-biotechnology-institute.fr/en/plateformes-plateaux/cellule-mathematiques/


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Mon Dec 18 11:24:40 2023
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Mon, 18 Dec 2023 11:24:40 +0100
Subject: [Rd] [External] Re: zapsmall(x) for scalar x
In-Reply-To: <f3751191-443f-4577-805a-2577a87506ed@insa-toulouse.fr>
References: <CAP=dwz8bGEvMEiXL+64dNH0cYtvAF3Y6ouCiVfX99y+1-VGGUA@mail.gmail.com>
 <B7FE40A5-18D3-437B-A446-EEA5B20A98AA@warnes.net>
 <bbcaa531201446a69c7fdedd311393ed@LO6P265MB6080.GBRP265.PROD.OUTLOOK.COM>
 <CANVKczNLxChkreGnAa=oDUz7w8SEG_i3xW3_9k3BjaC7Q_Y+9Q@mail.gmail.com>
 <f3751191-443f-4577-805a-2577a87506ed@insa-toulouse.fr>
Message-ID: <25984.7656.269922.822939@stat.math.ethz.ch>

>>>>> Serguei Sokol via R-devel 
>>>>>     on Mon, 18 Dec 2023 10:29:02 +0100 writes:

    > Le 17/12/2023 ? 18:26, Barry Rowlingson a ?crit?:
    >> I think what's been missed is that zapsmall works relative to the absolute
    >> largest value in the vector. Hence if there's only one
    >> item in the vector, it is the largest, so its not zapped. The function's
    >> raison d'etre isn't to replace absolutely small values,
    >> but small values relative to the largest. Hence a vector of similar tiny
    >> values doesn't get zapped.
    >> 
    >> Maybe the line in the docs:
    >> 
    >> " (compared with the maximal absolute value)"
    >> 
    >> needs to read:
    >> 
    >> " (compared with the maximal absolute value in the vector)"

    > I agree that this change in the doc would clarify the situation but 
    > would not resolve proposed corner cases.

    > I think that an additional argument 'mx' (absolute max value of 
    > reference) would do. Consider:

    > zapsmall2 <-
    > function (x, digits = getOption("digits"), mx=max(abs(x), na.rm=TRUE))
    > {
    > ??? if (length(digits) == 0L)
    > ??????? stop("invalid 'digits'")
    > ??? if (all(ina <- is.na(x)))
    > ??????? return(x)
    > ??? round(x, digits = if (mx > 0) max(0L, digits - 
    > as.numeric(log10(mx))) else digits)
    > }

    > then zapsmall2() without explicit 'mx' behaves identically to actual 
    > zapsmall() and for a scalar or a vector of identical value, user can 
    > manually fix the scale of what should be considered as small:

    >> zapsmall2(y)
    > [1] 2.220446e-16
    >> zapsmall2(y, mx=1)
    > [1] 0
    >> zapsmall2(c(y, y), mx=1)
    > [1] 0 0
    >> zapsmall2(c(y, NA))
    > [1] 2.220446e-16?????????? NA
    >> zapsmall2(c(y, NA), mx=1)
    > [1]? 0 NA

    > Obviously, the name 'zapsmall2' was chosen just for this explanation. 
    > The original name 'zapsmall' could be reused as a full backward 
    > compatibility is preserved.

    > Best,
    > Serguei.

Thank you, Serguei, Duncan, Barry et al.

Generally :
  Yes, zapsmall was meant and is used for zapping *relatively*
  small numbers.  In the other cases,  directly  round()ing is
  what you should use.

Specifically to Serguei's proposal of allowing the "max" value
to be user specified (in which case it is not really a true
max() anymore):

I've spent quite a a few hours on this problem in May 2022, to
make it even more flexible, e.g. allowing to use a 99%
percentile instead of the max(), or allowing to exclude +Inf
from the "mx"; but -- compared to your zapsmall2() --
to allow reproducible automatic choice :


zapsmall <- function(x, digits = getOption("digits"),
                     mFUN = function(x, ina) max(abs(x[!ina])),
		     min.d = 0L)
{
    if (length(digits) == 0L)
        stop("invalid 'digits'")
    if (all(ina <- is.na(x)))
        return(x)
    mx <- mFUN(x, ina)
    round(x, digits = if(mx > 0) max(min.d, digits - as.numeric(log10(mx))) else digits)
}

with optional 'min.d' as I had (vaguely remember to have) found
at the time that the '0' is also not always "the only correct" choice.

Somehow I never got to propose/discuss the above,
but it seems a good time to do so now.

Martin



    >> barry
    >> 
    >> 
    >> On Sun, Dec 17, 2023 at 2:17?PM Duncan Murdoch <murdoch.duncan at gmail.com>
    >> wrote:
    >> 
    >>> This email originated outside the University. Check before clicking links
    >>> or attachments.
    >>> 
    >>> I'm really confused.  Steve's example wasn't a scalar x, it was a
    >>> vector.  Your zapsmall() proposal wouldn't zap it to zero, and I don't
    >>> see why summary() would if it was using your proposal.
    >>> 
    >>> Duncan Murdoch
    >>> 
    >>> On 17/12/2023 8:43 a.m., Gregory R. Warnes wrote:
    >>>> Isn?t that the correct outcome?  The user can change the number of
    >>> digits if they want to see small values?
    >>>> 
    >>>> --
    >>>> Change your thoughts and you change the world.
    >>>> --Dr. Norman Vincent Peale
    >>>> 
    >>>>> On Dec 17, 2023, at 12:11?AM, Steve Martin <stevemartin041 at gmail.com>
    >>> wrote:
    >>>>> ?Zapping a vector of small numbers to zero would cause problems when
    >>>>> printing the results of summary(). For example, if
    >>>>> zapsmall(c(2.220446e-16, ..., 2.220446e-16)) == c(0, ..., 0) then
    >>>>> print(summary(2.220446e-16), digits = 7) would print
    >>>>> Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
    >>>>> 0          0            0           0           0          0
    >>>>> 
    >>>>> The same problem can also appear when printing the results of
    >>>>> summary.glm() with show.residuals = TRUE if there's little dispersion
    >>>>> in the residuals.
    >>>>> 
    >>>>> Steve
    >>>>> 
>>>>> On Sat, 16 Dec 2023 at 17:34, Gregory Warnes <greg at warnes.net> wrote:
    >>>>>> 
>>>>> I was quite suprised to discover that applying `zapsmall` to a scalar
    >>> value has no apparent effect.  For example:
    >>>>>>> y <- 2.220446e-16
    >>>>>>> zapsmall(y,)
>>>>> [1] 2.2204e-16
    >>>>>> 
>>>>> I was expecting zapsmall(x)` to act like
    >>>>>> 
    >>>>>>> round(y, digits=getOption('digits'))
>>>>> [1] 0
    >>>>>> 
>>>>> Looking at the current source code, indicates that `zapsmall` is
    >>> expecting a vector:
>>>>> zapsmall <-
>>>>> function (x, digits = getOption("digits"))
>>>>> {
>>>>>      if (length(digits) == 0L)
>>>>>          stop("invalid 'digits'")
>>>>>      if (all(ina <- is.na(x)))
>>>>>          return(x)
>>>>>      mx <- max(abs(x[!ina]))
>>>>>      round(x, digits = if (mx > 0) max(0L, digits -
    >>> as.numeric(log10(mx))) else digits)
>>>>> }
    >>>>>> 
>>>>> If `x` is a non-zero scalar, zapsmall will never perform rounding.
    >>>>>> 
>>>>> The man page simply states:
>>>>> zapsmall determines a digits argument dr for calling round(x, digits =
    >>> dr) such that values close to zero (compared with the maximal absolute
    >>> value) are ?zapped?, i.e., replaced by 0.
>>>>> and doesn?t provide any details about how ?close to zero? is defined.
    >>>>>> 
>>>>> Perhaps handling the special when `x` is a scalar (or only contains a
    >>> single non-NA value)  would make sense:
>>>>> zapsmall <-
>>>>> function (x, digits = getOption("digits"))
>>>>> {
>>>>>      if (length(digits) == 0L)
>>>>>          stop("invalid 'digits'")
>>>>>      if (all(ina <- is.na(x)))
>>>>>          return(x)
>>>>>      mx <- max(abs(x[!ina]))
>>>>>      round(x, digits = if (mx > 0 && (length(x)-sum(ina))>1 ) max(0L,
    >>> digits - as.numeric(log10(mx))) else digits)
>>>>> }
    >>>>>> 
>>>>> Yielding:
    >>>>>> 
    >>>>>>> y <- 2.220446e-16
    >>>>>>> zapsmall(y)
>>>>> [1] 0
    >>>>>> 
>>>>> Another edge case would be when all of the non-na values are the same:
    >>>>>> 
    >>>>>>> y <- 2.220446e-16
    >>>>>>> zapsmall(c(y,y))
>>>>> [1] 2.220446e-16 2.220446e-16
    >>>>>> 
>>>>> Thoughts?
    >>>>>> 
    >>>>>> 
>>>>> Gregory R. Warnes, Ph.D.
>>>>> greg at warnes.net
>>>>> Eternity is a long time, take a friend!
    >>>>>> 
    >>>>>> 
    >>>>>> 
>>>>>          [[alternative HTML version deleted]]
    >>>>>> 
>>>>> ______________________________________________
>>>>> R-devel at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
    >>>> [[alternative HTML version deleted]]
    >>>> 
    >>>> ______________________________________________
    >>>> R-devel at r-project.org mailing list
    >>>> https://stat.ethz.ch/mailman/listinfo/r-devel
    >>> ______________________________________________
    >>> R-devel at r-project.org mailing list
    >>> https://stat.ethz.ch/mailman/listinfo/r-devel
    >>> 
    >> [[alternative HTML version deleted]]
    >> 
    >> ______________________________________________
    >> R-devel at r-project.org mailing list
    >> https://stat.ethz.ch/mailman/listinfo/r-devel


    > -- 
    > Serguei Sokol
    > Ingenieur de recherche INRAE

    > Cellule Math?matiques
    > TBI, INSA/INRAE UMR 792, INSA/CNRS UMR 5504
    > 135 Avenue de Rangueil
    > 31077 Toulouse Cedex 04

    > tel: +33 5 61 55 98 49
    > email: sokol at insa-toulouse.fr
    > https://www.toulouse-biotechnology-institute.fr/en/plateformes-plateaux/cellule-mathematiques/

    > ______________________________________________
    > R-devel at r-project.org mailing list
    > https://stat.ethz.ch/mailman/listinfo/r-devel


From @oko| @end|ng |rom |n@@-tou|ou@e@|r  Mon Dec 18 11:47:19 2023
From: @oko| @end|ng |rom |n@@-tou|ou@e@|r (Serguei Sokol)
Date: Mon, 18 Dec 2023 11:47:19 +0100
Subject: [Rd] [External] Re: zapsmall(x) for scalar x
In-Reply-To: <25984.7656.269922.822939@stat.math.ethz.ch>
References: <CAP=dwz8bGEvMEiXL+64dNH0cYtvAF3Y6ouCiVfX99y+1-VGGUA@mail.gmail.com>
 <B7FE40A5-18D3-437B-A446-EEA5B20A98AA@warnes.net>
 <bbcaa531201446a69c7fdedd311393ed@LO6P265MB6080.GBRP265.PROD.OUTLOOK.COM>
 <CANVKczNLxChkreGnAa=oDUz7w8SEG_i3xW3_9k3BjaC7Q_Y+9Q@mail.gmail.com>
 <f3751191-443f-4577-805a-2577a87506ed@insa-toulouse.fr>
 <25984.7656.269922.822939@stat.math.ethz.ch>
Message-ID: <b2463b7c-755a-47c9-8c31-75ba748777bf@insa-toulouse.fr>

Le 18/12/2023 ? 11:24, Martin Maechler a ?crit?:
>>>>>> Serguei Sokol via R-devel
>>>>>>      on Mon, 18 Dec 2023 10:29:02 +0100 writes:
>      > Le 17/12/2023 ? 18:26, Barry Rowlingson a ?crit?:
>      >> I think what's been missed is that zapsmall works relative to the absolute
>      >> largest value in the vector. Hence if there's only one
>      >> item in the vector, it is the largest, so its not zapped. The function's
>      >> raison d'etre isn't to replace absolutely small values,
>      >> but small values relative to the largest. Hence a vector of similar tiny
>      >> values doesn't get zapped.
>      >>
>      >> Maybe the line in the docs:
>      >>
>      >> " (compared with the maximal absolute value)"
>      >>
>      >> needs to read:
>      >>
>      >> " (compared with the maximal absolute value in the vector)"
>
>      > I agree that this change in the doc would clarify the situation but
>      > would not resolve proposed corner cases.
>
>      > I think that an additional argument 'mx' (absolute max value of
>      > reference) would do. Consider:
>
>      > zapsmall2 <-
>      > function (x, digits = getOption("digits"), mx=max(abs(x), na.rm=TRUE))
>      > {
>      > ??? if (length(digits) == 0L)
>      > ??????? stop("invalid 'digits'")
>      > ??? if (all(ina <- is.na(x)))
>      > ??????? return(x)
>      > ??? round(x, digits = if (mx > 0) max(0L, digits -
>      > as.numeric(log10(mx))) else digits)
>      > }
>
>      > then zapsmall2() without explicit 'mx' behaves identically to actual
>      > zapsmall() and for a scalar or a vector of identical value, user can
>      > manually fix the scale of what should be considered as small:
>
>      >> zapsmall2(y)
>      > [1] 2.220446e-16
>      >> zapsmall2(y, mx=1)
>      > [1] 0
>      >> zapsmall2(c(y, y), mx=1)
>      > [1] 0 0
>      >> zapsmall2(c(y, NA))
>      > [1] 2.220446e-16?????????? NA
>      >> zapsmall2(c(y, NA), mx=1)
>      > [1]? 0 NA
>
>      > Obviously, the name 'zapsmall2' was chosen just for this explanation.
>      > The original name 'zapsmall' could be reused as a full backward
>      > compatibility is preserved.
>
>      > Best,
>      > Serguei.
>
> Thank you, Serguei, Duncan, Barry et al.
>
> Generally :
>    Yes, zapsmall was meant and is used for zapping *relatively*
>    small numbers.  In the other cases,  directly  round()ing is
>    what you should use.
>
> Specifically to Serguei's proposal of allowing the "max" value
> to be user specified (in which case it is not really a true
> max() anymore):
>
> I've spent quite a a few hours on this problem in May 2022, to
> make it even more flexible, e.g. allowing to use a 99%
> percentile instead of the max(), or allowing to exclude +Inf
> from the "mx"; but -- compared to your zapsmall2() --
> to allow reproducible automatic choice :
>
>
> zapsmall <- function(x, digits = getOption("digits"),
>                       mFUN = function(x, ina) max(abs(x[!ina])),
> 		     min.d = 0L)
> {
>      if (length(digits) == 0L)
>          stop("invalid 'digits'")
>      if (all(ina <- is.na(x)))
>          return(x)
>      mx <- mFUN(x, ina)
>      round(x, digits = if(mx > 0) max(min.d, digits - as.numeric(log10(mx))) else digits)
> }
>
> with optional 'min.d' as I had (vaguely remember to have) found
> at the time that the '0' is also not always "the only correct" choice.
Do you have a case or two where min.d could be useful?

Serguei.

>
> Somehow I never got to propose/discuss the above,
> but it seems a good time to do so now.
>
> Martin
>
>
>
>      >> barry
>      >>
>      >>
>      >> On Sun, Dec 17, 2023 at 2:17?PM Duncan Murdoch <murdoch.duncan at gmail.com>
>      >> wrote:
>      >>
>      >>> This email originated outside the University. Check before clicking links
>      >>> or attachments.
>      >>>
>      >>> I'm really confused.  Steve's example wasn't a scalar x, it was a
>      >>> vector.  Your zapsmall() proposal wouldn't zap it to zero, and I don't
>      >>> see why summary() would if it was using your proposal.
>      >>>
>      >>> Duncan Murdoch
>      >>>
>      >>> On 17/12/2023 8:43 a.m., Gregory R. Warnes wrote:
>      >>>> Isn?t that the correct outcome?  The user can change the number of
>      >>> digits if they want to see small values?
>      >>>>
>      >>>> --
>      >>>> Change your thoughts and you change the world.
>      >>>> --Dr. Norman Vincent Peale
>      >>>>
>      >>>>> On Dec 17, 2023, at 12:11?AM, Steve Martin <stevemartin041 at gmail.com>
>      >>> wrote:
>      >>>>> ?Zapping a vector of small numbers to zero would cause problems when
>      >>>>> printing the results of summary(). For example, if
>      >>>>> zapsmall(c(2.220446e-16, ..., 2.220446e-16)) == c(0, ..., 0) then
>      >>>>> print(summary(2.220446e-16), digits = 7) would print
>      >>>>> Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
>      >>>>> 0          0            0           0           0          0
>      >>>>>
>      >>>>> The same problem can also appear when printing the results of
>      >>>>> summary.glm() with show.residuals = TRUE if there's little dispersion
>      >>>>> in the residuals.
>      >>>>>
>      >>>>> Steve
>      >>>>>
>>>>>> On Sat, 16 Dec 2023 at 17:34, Gregory Warnes <greg at warnes.net> wrote:
>      >>>>>>
>>>>>> I was quite suprised to discover that applying `zapsmall` to a scalar
>      >>> value has no apparent effect.  For example:
>      >>>>>>> y <- 2.220446e-16
>      >>>>>>> zapsmall(y,)
>>>>>> [1] 2.2204e-16
>      >>>>>>
>>>>>> I was expecting zapsmall(x)` to act like
>      >>>>>>
>      >>>>>>> round(y, digits=getOption('digits'))
>>>>>> [1] 0
>      >>>>>>
>>>>>> Looking at the current source code, indicates that `zapsmall` is
>      >>> expecting a vector:
>>>>>> zapsmall <-
>>>>>> function (x, digits = getOption("digits"))
>>>>>> {
>>>>>>       if (length(digits) == 0L)
>>>>>>           stop("invalid 'digits'")
>>>>>>       if (all(ina <- is.na(x)))
>>>>>>           return(x)
>>>>>>       mx <- max(abs(x[!ina]))
>>>>>>       round(x, digits = if (mx > 0) max(0L, digits -
>      >>> as.numeric(log10(mx))) else digits)
>>>>>> }
>      >>>>>>
>>>>>> If `x` is a non-zero scalar, zapsmall will never perform rounding.
>      >>>>>>
>>>>>> The man page simply states:
>>>>>> zapsmall determines a digits argument dr for calling round(x, digits =
>      >>> dr) such that values close to zero (compared with the maximal absolute
>      >>> value) are ?zapped?, i.e., replaced by 0.
>>>>>> and doesn?t provide any details about how ?close to zero? is defined.
>      >>>>>>
>>>>>> Perhaps handling the special when `x` is a scalar (or only contains a
>      >>> single non-NA value)  would make sense:
>>>>>> zapsmall <-
>>>>>> function (x, digits = getOption("digits"))
>>>>>> {
>>>>>>       if (length(digits) == 0L)
>>>>>>           stop("invalid 'digits'")
>>>>>>       if (all(ina <- is.na(x)))
>>>>>>           return(x)
>>>>>>       mx <- max(abs(x[!ina]))
>>>>>>       round(x, digits = if (mx > 0 && (length(x)-sum(ina))>1 ) max(0L,
>      >>> digits - as.numeric(log10(mx))) else digits)
>>>>>> }
>      >>>>>>
>>>>>> Yielding:
>      >>>>>>
>      >>>>>>> y <- 2.220446e-16
>      >>>>>>> zapsmall(y)
>>>>>> [1] 0
>      >>>>>>
>>>>>> Another edge case would be when all of the non-na values are the same:
>      >>>>>>
>      >>>>>>> y <- 2.220446e-16
>      >>>>>>> zapsmall(c(y,y))
>>>>>> [1] 2.220446e-16 2.220446e-16
>      >>>>>>
>>>>>> Thoughts?
>      >>>>>>
>      >>>>>>
>>>>>> Gregory R. Warnes, Ph.D.
>>>>>> greg at warnes.net
>>>>>> Eternity is a long time, take a friend!
>      >>>>>>
>      >>>>>>
>      >>>>>>
>>>>>>           [[alternative HTML version deleted]]
>      >>>>>>
>>>>>> ______________________________________________
>>>>>> R-devel at r-project.org mailing list
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>      >>>> [[alternative HTML version deleted]]
>      >>>>
>      >>>> ______________________________________________
>      >>>> R-devel at r-project.org mailing list
>      >>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>      >>> ______________________________________________
>      >>> R-devel at r-project.org mailing list
>      >>> https://stat.ethz.ch/mailman/listinfo/r-devel
>      >>>
>      >> [[alternative HTML version deleted]]
>      >>
>      >> ______________________________________________
>      >> R-devel at r-project.org mailing list
>      >> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>
>      > --
>      > Serguei Sokol
>      > Ingenieur de recherche INRAE
>
>      > Cellule Math?matiques
>      > TBI, INSA/INRAE UMR 792, INSA/CNRS UMR 5504
>      > 135 Avenue de Rangueil
>      > 31077 Toulouse Cedex 04
>
>      > tel: +33 5 61 55 98 49
>      > email: sokol at insa-toulouse.fr
>      > https://www.toulouse-biotechnology-institute.fr/en/plateformes-plateaux/cellule-mathematiques/
>
>      > ______________________________________________
>      > R-devel at r-project.org mailing list
>      > https://stat.ethz.ch/mailman/listinfo/r-devel


From @tevem@rt|n041 @end|ng |rom gm@||@com  Mon Dec 18 13:56:46 2023
From: @tevem@rt|n041 @end|ng |rom gm@||@com (Steve Martin)
Date: Mon, 18 Dec 2023 07:56:46 -0500
Subject: [Rd] [External] Re: zapsmall(x) for scalar x
In-Reply-To: <b2463b7c-755a-47c9-8c31-75ba748777bf@insa-toulouse.fr>
References: <CAP=dwz8bGEvMEiXL+64dNH0cYtvAF3Y6ouCiVfX99y+1-VGGUA@mail.gmail.com>
 <B7FE40A5-18D3-437B-A446-EEA5B20A98AA@warnes.net>
 <bbcaa531201446a69c7fdedd311393ed@LO6P265MB6080.GBRP265.PROD.OUTLOOK.COM>
 <CANVKczNLxChkreGnAa=oDUz7w8SEG_i3xW3_9k3BjaC7Q_Y+9Q@mail.gmail.com>
 <f3751191-443f-4577-805a-2577a87506ed@insa-toulouse.fr>
 <25984.7656.269922.822939@stat.math.ethz.ch>
 <b2463b7c-755a-47c9-8c31-75ba748777bf@insa-toulouse.fr>
Message-ID: <CAP=dwz-oWc_K9ABHd4JQRYceY5+PsPmGTGGg1RmQw9+_xq=+hQ@mail.gmail.com>

Does mFUN() really need to be a function of x and the NA values of x? I
can't think of a case where it would be used on anything but the non-NA
values of x.

I think it would be easier to specify a different mFUN() (and document this
new argument) if the function has one argument and is applied to the non-NA
values of x.

zapsmall <- function(x,
    digits = getOption("digits"),
    mFUN = function(x) max(abs(x)),
    min.d = 0L
) {
    if (length(digits) == 0L)
        stop("invalid 'digits'")
    if (all(ina <- is.na(x)))
        return(x)
    mx <- mFUN(x[!ina])
    round(x, digits = if(mx > 0) max(min.d, digits - as.numeric(log10(mx)))
else digits)
}

Steve

On Mon, Dec 18, 2023, 05:47 Serguei Sokol via R-devel <r-devel at r-project.org>
wrote:

> Le 18/12/2023 ? 11:24, Martin Maechler a ?crit :
> >>>>>> Serguei Sokol via R-devel
> >>>>>>      on Mon, 18 Dec 2023 10:29:02 +0100 writes:
> >      > Le 17/12/2023 ? 18:26, Barry Rowlingson a ?crit :
> >      >> I think what's been missed is that zapsmall works relative to
> the absolute
> >      >> largest value in the vector. Hence if there's only one
> >      >> item in the vector, it is the largest, so its not zapped. The
> function's
> >      >> raison d'etre isn't to replace absolutely small values,
> >      >> but small values relative to the largest. Hence a vector of
> similar tiny
> >      >> values doesn't get zapped.
> >      >>
> >      >> Maybe the line in the docs:
> >      >>
> >      >> " (compared with the maximal absolute value)"
> >      >>
> >      >> needs to read:
> >      >>
> >      >> " (compared with the maximal absolute value in the vector)"
> >
> >      > I agree that this change in the doc would clarify the situation
> but
> >      > would not resolve proposed corner cases.
> >
> >      > I think that an additional argument 'mx' (absolute max value of
> >      > reference) would do. Consider:
> >
> >      > zapsmall2 <-
> >      > function (x, digits = getOption("digits"), mx=max(abs(x),
> na.rm=TRUE))
> >      > {
> >      >     if (length(digits) == 0L)
> >      >         stop("invalid 'digits'")
> >      >     if (all(ina <- is.na(x)))
> >      >         return(x)
> >      >     round(x, digits = if (mx > 0) max(0L, digits -
> >      > as.numeric(log10(mx))) else digits)
> >      > }
> >
> >      > then zapsmall2() without explicit 'mx' behaves identically to
> actual
> >      > zapsmall() and for a scalar or a vector of identical value, user
> can
> >      > manually fix the scale of what should be considered as small:
> >
> >      >> zapsmall2(y)
> >      > [1] 2.220446e-16
> >      >> zapsmall2(y, mx=1)
> >      > [1] 0
> >      >> zapsmall2(c(y, y), mx=1)
> >      > [1] 0 0
> >      >> zapsmall2(c(y, NA))
> >      > [1] 2.220446e-16           NA
> >      >> zapsmall2(c(y, NA), mx=1)
> >      > [1]  0 NA
> >
> >      > Obviously, the name 'zapsmall2' was chosen just for this
> explanation.
> >      > The original name 'zapsmall' could be reused as a full backward
> >      > compatibility is preserved.
> >
> >      > Best,
> >      > Serguei.
> >
> > Thank you, Serguei, Duncan, Barry et al.
> >
> > Generally :
> >    Yes, zapsmall was meant and is used for zapping *relatively*
> >    small numbers.  In the other cases,  directly  round()ing is
> >    what you should use.
> >
> > Specifically to Serguei's proposal of allowing the "max" value
> > to be user specified (in which case it is not really a true
> > max() anymore):
> >
> > I've spent quite a a few hours on this problem in May 2022, to
> > make it even more flexible, e.g. allowing to use a 99%
> > percentile instead of the max(), or allowing to exclude +Inf
> > from the "mx"; but -- compared to your zapsmall2() --
> > to allow reproducible automatic choice :
> >
> >
> > zapsmall <- function(x, digits = getOption("digits"),
> >                       mFUN = function(x, ina) max(abs(x[!ina])),
> >                    min.d = 0L)
> > {
> >      if (length(digits) == 0L)
> >          stop("invalid 'digits'")
> >      if (all(ina <- is.na(x)))
> >          return(x)
> >      mx <- mFUN(x, ina)
> >      round(x, digits = if(mx > 0) max(min.d, digits -
> as.numeric(log10(mx))) else digits)
> > }
> >
> > with optional 'min.d' as I had (vaguely remember to have) found
> > at the time that the '0' is also not always "the only correct" choice.
> Do you have a case or two where min.d could be useful?
>
> Serguei.
>
> >
> > Somehow I never got to propose/discuss the above,
> > but it seems a good time to do so now.
> >
> > Martin
> >
> >
> >
> >      >> barry
> >      >>
> >      >>
> >      >> On Sun, Dec 17, 2023 at 2:17?PM Duncan Murdoch <
> murdoch.duncan at gmail.com>
> >      >> wrote:
> >      >>
> >      >>> This email originated outside the University. Check before
> clicking links
> >      >>> or attachments.
> >      >>>
> >      >>> I'm really confused.  Steve's example wasn't a scalar x, it was
> a
> >      >>> vector.  Your zapsmall() proposal wouldn't zap it to zero, and
> I don't
> >      >>> see why summary() would if it was using your proposal.
> >      >>>
> >      >>> Duncan Murdoch
> >      >>>
> >      >>> On 17/12/2023 8:43 a.m., Gregory R. Warnes wrote:
> >      >>>> Isn?t that the correct outcome?  The user can change the
> number of
> >      >>> digits if they want to see small values?
> >      >>>>
> >      >>>> --
> >      >>>> Change your thoughts and you change the world.
> >      >>>> --Dr. Norman Vincent Peale
> >      >>>>
> >      >>>>> On Dec 17, 2023, at 12:11?AM, Steve Martin <
> stevemartin041 at gmail.com>
> >      >>> wrote:
> >      >>>>> ?Zapping a vector of small numbers to zero would cause
> problems when
> >      >>>>> printing the results of summary(). For example, if
> >      >>>>> zapsmall(c(2.220446e-16, ..., 2.220446e-16)) == c(0, ..., 0)
> then
> >      >>>>> print(summary(2.220446e-16), digits = 7) would print
> >      >>>>> Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
> >      >>>>> 0          0            0           0           0          0
> >      >>>>>
> >      >>>>> The same problem can also appear when printing the results of
> >      >>>>> summary.glm() with show.residuals = TRUE if there's little
> dispersion
> >      >>>>> in the residuals.
> >      >>>>>
> >      >>>>> Steve
> >      >>>>>
> >>>>>> On Sat, 16 Dec 2023 at 17:34, Gregory Warnes <greg at warnes.net>
> wrote:
> >      >>>>>>
> >>>>>> I was quite suprised to discover that applying `zapsmall` to a
> scalar
> >      >>> value has no apparent effect.  For example:
> >      >>>>>>> y <- 2.220446e-16
> >      >>>>>>> zapsmall(y,)
> >>>>>> [1] 2.2204e-16
> >      >>>>>>
> >>>>>> I was expecting zapsmall(x)` to act like
> >      >>>>>>
> >      >>>>>>> round(y, digits=getOption('digits'))
> >>>>>> [1] 0
> >      >>>>>>
> >>>>>> Looking at the current source code, indicates that `zapsmall` is
> >      >>> expecting a vector:
> >>>>>> zapsmall <-
> >>>>>> function (x, digits = getOption("digits"))
> >>>>>> {
> >>>>>>       if (length(digits) == 0L)
> >>>>>>           stop("invalid 'digits'")
> >>>>>>       if (all(ina <- is.na(x)))
> >>>>>>           return(x)
> >>>>>>       mx <- max(abs(x[!ina]))
> >>>>>>       round(x, digits = if (mx > 0) max(0L, digits -
> >      >>> as.numeric(log10(mx))) else digits)
> >>>>>> }
> >      >>>>>>
> >>>>>> If `x` is a non-zero scalar, zapsmall will never perform rounding.
> >      >>>>>>
> >>>>>> The man page simply states:
> >>>>>> zapsmall determines a digits argument dr for calling round(x,
> digits =
> >      >>> dr) such that values close to zero (compared with the maximal
> absolute
> >      >>> value) are ?zapped?, i.e., replaced by 0.
> >>>>>> and doesn?t provide any details about how ?close to zero? is
> defined.
> >      >>>>>>
> >>>>>> Perhaps handling the special when `x` is a scalar (or only contains
> a
> >      >>> single non-NA value)  would make sense:
> >>>>>> zapsmall <-
> >>>>>> function (x, digits = getOption("digits"))
> >>>>>> {
> >>>>>>       if (length(digits) == 0L)
> >>>>>>           stop("invalid 'digits'")
> >>>>>>       if (all(ina <- is.na(x)))
> >>>>>>           return(x)
> >>>>>>       mx <- max(abs(x[!ina]))
> >>>>>>       round(x, digits = if (mx > 0 && (length(x)-sum(ina))>1 )
> max(0L,
> >      >>> digits - as.numeric(log10(mx))) else digits)
> >>>>>> }
> >      >>>>>>
> >>>>>> Yielding:
> >      >>>>>>
> >      >>>>>>> y <- 2.220446e-16
> >      >>>>>>> zapsmall(y)
> >>>>>> [1] 0
> >      >>>>>>
> >>>>>> Another edge case would be when all of the non-na values are the
> same:
> >      >>>>>>
> >      >>>>>>> y <- 2.220446e-16
> >      >>>>>>> zapsmall(c(y,y))
> >>>>>> [1] 2.220446e-16 2.220446e-16
> >      >>>>>>
> >>>>>> Thoughts?
> >      >>>>>>
> >      >>>>>>
> >>>>>> Gregory R. Warnes, Ph.D.
> >>>>>> greg at warnes.net
> >>>>>> Eternity is a long time, take a friend!
> >      >>>>>>
> >      >>>>>>
> >      >>>>>>
> >>>>>>           [[alternative HTML version deleted]]
> >      >>>>>>
> >>>>>> ______________________________________________
> >>>>>> R-devel at r-project.org mailing list
> >>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
> >      >>>> [[alternative HTML version deleted]]
> >      >>>>
> >      >>>> ______________________________________________
> >      >>>> R-devel at r-project.org mailing list
> >      >>>> https://stat.ethz.ch/mailman/listinfo/r-devel
> >      >>> ______________________________________________
> >      >>> R-devel at r-project.org mailing list
> >      >>> https://stat.ethz.ch/mailman/listinfo/r-devel
> >      >>>
> >      >> [[alternative HTML version deleted]]
> >      >>
> >      >> ______________________________________________
> >      >> R-devel at r-project.org mailing list
> >      >> https://stat.ethz.ch/mailman/listinfo/r-devel
> >
> >
> >      > --
> >      > Serguei Sokol
> >      > Ingenieur de recherche INRAE
> >
> >      > Cellule Math?matiques
> >      > TBI, INSA/INRAE UMR 792, INSA/CNRS UMR 5504
> >      > 135 Avenue de Rangueil
> >      > 31077 Toulouse Cedex 04
> >
> >      > tel: +33 5 61 55 98 49
> >      > email: sokol at insa-toulouse.fr
> >      >
> https://www.toulouse-biotechnology-institute.fr/en/plateformes-plateaux/cellule-mathematiques/
> >
> >      > ______________________________________________
> >      > R-devel at r-project.org mailing list
> >      > https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Tue Dec 19 17:25:30 2023
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Tue, 19 Dec 2023 17:25:30 +0100
Subject: [Rd] [External] Re: zapsmall(x) for scalar x
In-Reply-To: <CAP=dwz-oWc_K9ABHd4JQRYceY5+PsPmGTGGg1RmQw9+_xq=+hQ@mail.gmail.com>
References: <CAP=dwz8bGEvMEiXL+64dNH0cYtvAF3Y6ouCiVfX99y+1-VGGUA@mail.gmail.com>
 <B7FE40A5-18D3-437B-A446-EEA5B20A98AA@warnes.net>
 <bbcaa531201446a69c7fdedd311393ed@LO6P265MB6080.GBRP265.PROD.OUTLOOK.COM>
 <CANVKczNLxChkreGnAa=oDUz7w8SEG_i3xW3_9k3BjaC7Q_Y+9Q@mail.gmail.com>
 <f3751191-443f-4577-805a-2577a87506ed@insa-toulouse.fr>
 <25984.7656.269922.822939@stat.math.ethz.ch>
 <b2463b7c-755a-47c9-8c31-75ba748777bf@insa-toulouse.fr>
 <CAP=dwz-oWc_K9ABHd4JQRYceY5+PsPmGTGGg1RmQw9+_xq=+hQ@mail.gmail.com>
Message-ID: <25985.50170.190748.540475@stat.math.ethz.ch>

>>>>> Steve Martin 
>>>>>     on Mon, 18 Dec 2023 07:56:46 -0500 writes:

    > Does mFUN() really need to be a function of x and the NA values of x? I
    > can't think of a case where it would be used on anything but the non-NA
    > values of x.

    > I think it would be easier to specify a different mFUN() (and document this
    > new argument) if the function has one argument and is applied to the non-NA
    > values of x.

    > zapsmall <- function(x,
    >     digits = getOption("digits"),
    >     mFUN = function(x) max(abs(x)),
    >     min.d = 0L) {
    >     if (length(digits) == 0L)
    >         stop("invalid 'digits'")
    >     if (all(ina <- is.na(x)))
    >         return(x)
    >     mx <- mFUN(x[!ina])
    >     round(x, digits = if(mx > 0) max(min.d, digits - as.numeric(log10(mx)))
    > else digits)
    > }

    > Steve

Thank you, Steve,
you are right that it would look simpler to do it that way.

On the other hand, in your case, mFUN() no longer sees the
original  n observations, and would not know if there where NAs
in that case how many NAs there were in the original data.

The examples I have on my version of zapsmall's help page (see below)
uses a robust mFUN, "the upper hinge of a box plot":

   mF_rob <- function(x, ina) boxplot.stats(x, do.conf=FALSE)$stats[5]

and if you inspect boxplot.stats() you may know that indeed it
also wants to use the full data 'x' to compute its statistics and
then deal with NAs directly.  Your simplified mFUN interface
would not be fully consistent with boxplot(), and I think could
not be made so,  hence my more flexible 2-argument "design" for  mFUN().

.... and BTW, these examples also exemplify the use of  `min.d`
about which  Serguei Sokol asked for an example or two.

Here I repeat my definition of zapsmall, and then my current set
of examples:

zapsmall <- function(x, digits = getOption("digits"),
                     mFUN = function(x, ina) max(abs(x[!ina])), min.d = 0L)
{
    if (length(digits) == 0L)
        stop("invalid 'digits'")
    if (all(ina <- is.na(x)))
        return(x)
    mx <- mFUN(x, ina)
    round(x, digits = if(mx > 0) max(min.d, digits - as.numeric(log10(mx))) else digits)
}


##--- \examples{
x2 <- pi * 100^(-2:2)/10
   print(  x2, digits = 4)
zapsmall(  x2) # automatical digits
zapsmall(  x2, digits = 4)
zapsmall(c(x2, Inf)) # round()s to integer ..
zapsmall(c(x2, Inf), min.d=-Inf) # everything  is small wrt  Inf

(z <- exp(1i*0:4*pi/2))
zapsmall(z)

zapShow <- function(x, ...) rbind(orig = x, zapped = zapsmall(x, ...))
zapShow(x2)

## using a *robust* mFUN
mF_rob <- function(x, ina) boxplot.stats(x, do.conf=FALSE)$stats[5]
## with robust mFUN(), 'Inf' is no longer distorting the picture:
zapShow(c(x2, Inf), mFUN = mF_rob)
zapShow(c(x2, Inf), mFUN = mF_rob, min.d = -5) # the same
zapShow(c(x2, 999), mFUN = mF_rob) # same *rounding* as w/ Inf
zapShow(c(x2, 999), mFUN = mF_rob, min.d =  3) # the same
zapShow(c(x2, 999), mFUN = mF_rob, min.d =  8) # small diff
##--- }



    > On Mon, Dec 18, 2023, 05:47 Serguei Sokol via R-devel <r-devel at r-project.org>
    > wrote:

> Le 18/12/2023 ? 11:24, Martin Maechler a ?crit :
> >>>>>> Serguei Sokol via R-devel
> >>>>>>      on Mon, 18 Dec 2023 10:29:02 +0100 writes:
> >      > Le 17/12/2023 ? 18:26, Barry Rowlingson a ?crit :
> >      >> I think what's been missed is that zapsmall works relative to the absolute
> >      >> largest value in the vector. Hence if there's only one
> >      >> item in the vector, it is the largest, so its not zapped. The function's
> >      >> raison d'etre isn't to replace absolutely small values,
> >      >> but small values relative to the largest. Hence a vector of similar tiny
> >      >> values doesn't get zapped.
> >      >>
> >      >> Maybe the line in the docs:
> >      >>
> >      >> " (compared with the maximal absolute value)"
> >      >>
> >      >> needs to read:
> >      >>
> >      >> " (compared with the maximal absolute value in the vector)"
> >
> >      > I agree that this change in the doc would clarify the situation but
> >      > would not resolve proposed corner cases.
> >
> >      > I think that an additional argument 'mx' (absolute max value of
> >      > reference) would do. Consider:
> >
> >      > zapsmall2 <-
> >      > function (x, digits = getOption("digits"), mx=max(abs(x),  na.rm=TRUE))
> >      > {
> >      >     if (length(digits) == 0L)
> >      >         stop("invalid 'digits'")
> >      >     if (all(ina <- is.na(x)))
> >      >         return(x)
> >      >     round(x, digits = if (mx > 0) max(0L, digits - as.numeric(log10(mx))) else digits)
> >      > }
> >
> >      > then zapsmall2() without explicit 'mx' behaves
> >      > identically to actual
> >      > zapsmall() and for a scalar or a vector of identical value, user
> can
> >      > manually fix the scale of what should be considered as small:
> >
> >      >> zapsmall2(y)
> >      > [1] 2.220446e-16
> >      >> zapsmall2(y, mx=1)
> >      > [1] 0
> >      >> zapsmall2(c(y, y), mx=1)
> >      > [1] 0 0
> >      >> zapsmall2(c(y, NA))
> >      > [1] 2.220446e-16           NA
> >      >> zapsmall2(c(y, NA), mx=1)
> >      > [1]  0 NA
> >
> >      > Obviously, the name 'zapsmall2' was chosen just for this
> explanation.
> >      > The original name 'zapsmall' could be reused as a full backward
> >      > compatibility is preserved.
> >
> >      > Best,
> >      > Serguei.
[.......................]


From j@goreck| @end|ng |rom w|t@edu@p|  Tue Dec 19 19:29:40 2023
From: j@goreck| @end|ng |rom w|t@edu@p| (Jan Gorecki)
Date: Tue, 19 Dec 2023 19:29:40 +0100
Subject: [Rd] tools:: extracting pkg dependencies from DCF
In-Reply-To: <CAOO9MKVxEwe6Vxy_SMDaw5Wy-x2c-qUqqz3B5Y2wa3485Q_Ejg@mail.gmail.com>
References: <CAOO9MKVH1u3ojT4PHiVpQfS3xnq9ysWjp37vEyAQRtGKJ6cgtQ@mail.gmail.com>
 <CA+6hu7cjkoG9K0bX-eAZJWPqSHu7T84XTZdgAyN0cFFcc9nYdQ@mail.gmail.com>
 <CAOO9MKW+2k-VgbFwybqAFZU+qT3FTwUJG8kGy9dTitmvHu5-ig@mail.gmail.com>
 <CAD4oTHE23nGhjz6p1-Qc0Jur3hASsFoHJ-jfn74jOBJYC95DPw@mail.gmail.com>
 <CAOO9MKVe8zUio4KCB=+F3neGQnd8Q_794y2MKj7gpbosF2WUpQ@mail.gmail.com>
 <0ED5F2BA-61F0-4210-870B-61EACBE6431C@R-project.org>
 <CAOO9MKX2_wAC1BCzp8saNHNd=J_=7=t3h-mrc7tUDymzARO+sg@mail.gmail.com>
 <CAOO9MKUnQqXVorTm0RD3PymVSqHOCuczZa3Px7CNv2Z5BYgZZw@mail.gmail.com>
 <CAD4oTHGJ0a00Ap4ho+2-fVvzXP-8qO1W15+RuvZuO_UQcCVTWw@mail.gmail.com>
 <CAOO9MKWQNoGdbRPXmVtJUR-H9hxrJDTU-8J_C5iCKucgzTJoSQ@mail.gmail.com>
 <CAD4oTHERXkoCY2GfYSTbxqF8kK28d-LZMcjDr2biwEaMktU-7Q@mail.gmail.com>
 <CAOO9MKVxEwe6Vxy_SMDaw5Wy-x2c-qUqqz3B5Y2wa3485Q_Ejg@mail.gmail.com>
Message-ID: <CAOO9MKXTE1wBtNpyZ_XCc0B-jjvLtNRJ3e0rJTKUauGjJVLT9A@mail.gmail.com>

Hello all,

Following up on this old thread as I have recently observed, rather a
bad practice (maintaining order of installation for R packages rather
than relying on R for that), for solving a problem that R branch
tools4pkgs (mentioned in this email) addresses very well.
More details can be found in
https://github.com/dewittpe/R-install-dependencies/issues/3

Therefore I extracted functionality from base R branch and put into
standalone package, named after R branch:
https://github.com/jangorecki/tools4pkgs
Sharing for whoever would reach this email thread in future.

Best Regards,
Jan Gorecki


On Sat, Oct 29, 2022 at 6:26?PM Jan Gorecki <j.gorecki at wit.edu.pl> wrote:
>
> Thank you Gabriel,
>
> Just for future readers. Below is a base R way to address this common
> problem, as instructed by you (+stopifnot to suppress print).
>
> Rscript -e 'stopifnot(file.copy("DESCRIPTION",
> file.path(tdir<-tempdir(), "PACKAGES")));
> db<-available.packages(paste0("file://", tdir));
> install.packages(setdiff(tools::package_dependencies(read.dcf("DESCRIPTION",
> fields="Package")[[1L]], db, which="most")[[1L]],
> installed.packages(priority="high")[,"Package"]))'
>
> 3 liner, 310 chars long command, far from ideal, but does work.
>
> Best,
> Jan
>
>
> On Fri, Oct 28, 2022 at 10:42 PM Gabriel Becker <gabembecker at gmail.com> wrote:
> >
> > Hi Jan,
> >
> >
> > On Fri, Oct 28, 2022 at 1:57 PM Jan Gorecki <j.gorecki at wit.edu.pl> wrote:
> >>
> >> Gabriel,
> >>
> >> It is the most basic CI use case. One wants to install only
> >> dependencies only of the package, and run R CMD check on the package.
> >
> >
> > Really what you're looking for though, is to install all the dependencies which aren't present right? Excluding base packages is just a particular way to do that under certain assumptions about the CI environment.
> >
> > So
> >
> >
> > needed_pkgs <- setdiff(package_dependencies(...), installed.packages()[,"Package"])
> > install.packages(needed_pkgs, repos = fancyrepos)
> >
> >
> > will do what you want without installing the package itself, if that is important. This will filter out base and recommended packages (which will be already installed in your CI container, since R is).
> >
> >
> > Now this does not take into account versioned dependencies, so it's not actually fully correct (whereas installing the package is), but it gets you where you're trying to go. And in a clean CI container without cached package installation for the deps, its equivalent.
> >
> >
> > Also, as an aside, if you need to get the base packages, you can do
> >
> > installed.packages(priority="base")[,"Package"]
> >
> >        base    compiler    datasets    graphics   grDevices        grid
> >
> >      "base"  "compiler"  "datasets"  "graphics" "grDevices"      "grid"
> >
> >     methods    parallel     splines       stats      stats4       tcltk
> >
> >   "methods"  "parallel"   "splines"     "stats"    "stats4"     "tcltk"
> >
> >       tools       utils
> >
> >     "tools"     "utils"
> >
> >
> > (to get base and recommended packages use 'high' instead of 'base')
> >
> > No need to be reaching down into unexported functions. So if you *really* only want to exclude base functions (which likely will give you some protection from versioned dep issues), you can change the code above to
> >
> > needed_pkgs <- setdiff(package_dependencies(...), installed.packages(priority = "high")[,"Package"])
> > install.packages(needed_pkgs, repos = fancyrepos)
> >
> > Best,
> > ~G
> >
> >>
> >> On Fri, Oct 28, 2022 at 8:42 PM Gabriel Becker <gabembecker at gmail.com> wrote:
> >> >
> >> > Hi Jan,
> >> >
> >> > The reason, I suspect without speaking for R-core, is that by design you should not be specifying package dependencies as additional packages to install. install.packages already does this for you, as it did in the construct of a repository code that I provided previously in the thread. You should be *only* doing
> >> >
> >> > install.packages(<pkg in question>, repos = *)
> >> >
> >> > Then everything happens automatically via extremely well tested very mature code.
> >> >
> >> > I (still) don't understand why you'd need to pass install.packages the vector of dependencies yourself, as that is counter to install.packages' core design.
> >> >
> >> > Does that make sense?
> >> >
> >> > Best,
> >> > ~G
> >> >
> >> > On Fri, Oct 28, 2022 at 12:18 PM Jan Gorecki <j.gorecki at wit.edu.pl> wrote:
> >> >>
> >> >> Gabriel,
> >> >>
> >> >> I am trying to design generic solution that could be applied to
> >> >> arbitrary package. Therefore I went with the latter solution you
> >> >> proposed.
> >> >> If we wouldn't have to exclude base packages, then its a 3 liner
> >> >>
> >> >> file.copy("DESCRIPTION", file.path(tdir<-tempdir(), "PACKAGES"));
> >> >> db<-available.packages(paste0("file://", tdir));
> >> >> utils::install.packages(tools::package_dependencies("pkgname", db,
> >> >> which="most")[[1L]])
> >> >>
> >> >> As you noticed, we still have to filter out base packages. Otherwise
> >> >> it won't be a robust utility that can be used in CI. Therefore we have
> >> >> to add a call to tools:::.get_standard_package_names() which is an
> >> >> internal function (as of now). Not only complicating the call but also
> >> >> putting the functionality outside of safe use.
> >> >>
> >> >> Considering above, don't you agree that the following one liner could
> >> >> nicely address the problem? The problem that hundreds/thousands of
> >> >> packages are now addressing in their CI scripts by using a third party
> >> >> packages.
> >> >>
> >> >> utils::install.packages(packages.dcf("DESCRIPTION", which="most"))
> >> >>
> >> >> It is hard to me to understand why R members don't consider this basic
> >> >> functionality to be part of base R. Possibly they just don't need it
> >> >> themselves. Yet isn't this sufficient that hundreds/thousands of
> >> >> packages does need this functionality?
> >> >>
> >> >> Best regards,
> >> >> Jan
> >> >>
> >> >> On Mon, Oct 17, 2022 at 8:39 AM Jan Gorecki <j.gorecki at wit.edu.pl> wrote:
> >> >> >
> >> >> > Gabriel and Simon
> >> >> >
> >> >> > I completely agree with what you are saying.
> >> >> > The thing is that obtaining recursive deps, all/most whatever, is already well supported in core R. What is missing is just this single functionality I am requesting.
> >> >> >
> >> >> > If you will look into the branch you can see there is mirror.packages function meant to mirror a slice of CRAN. It is doing exactly what you described: package_dependencies; to obtain recursive deps, then download all, etc.
> >> >> > I would love to have this function provided by core R as well, but we need to start somewhere.
> >> >> >
> >> >> > There are other use cases as well.
> >> >> > For example CI, where one wants to install all/most dependencies and then run R CMD check. Then we don't worry about recursive deps are they will be resolved automatically.
> >> >> > I don't think it's reasonable to force users to use 3rd party packages to handle such a common and simple use case. Otherwise one has to hard code deps in CI script. Not robust at all.
> >> >> >
> >> >> > packages.dcf and repos.dcf makes all that way easier, and are solid base for building customized orchestration like mirroring slice of CRAN.
> >> >> >
> >> >> > Best regards
> >> >> > Jan
> >> >> >
> >> >> > On Sun, Oct 16, 2022, 01:31 Simon Urbanek <simon.urbanek at r-project.org> wrote:
> >> >> >>
> >> >> >> Jan,
> >> >> >>
> >> >> >> I think using a single DCF as input is not very practical and would not be useful in the context you describe (creating self contained repos) since they typically concern a list of packages, but essentially splitting out the part of install.packages() which determines which files will be pulled from where would be very useful as it would be trivial to use it to create repository (what we always do in corporate environments) instead of installing the packages. I suspect that install packages is already too complex so instead of adding a flag to install.packages one could move that functionality into a separate function - we all do that constantly for the sites we manage, so it would be certainly something worthwhile.
> >> >> >>
> >> >> >> Cheers,
> >> >> >> Simon
> >> >> >>
> >> >> >>
> >> >> >> > On Oct 15, 2022, at 7:14 PM, Jan Gorecki <j.gorecki at wit.edu.pl> wrote:
> >> >> >> >
> >> >> >> > Hi Gabriel,
> >> >> >> >
> >> >> >> > It's very nice usage you provided here. Maybe instead of adding new
> >> >> >> > function we could extend packages_depenedncies then? To accept file path to
> >> >> >> > dsc file.
> >> >> >> >
> >> >> >> > What about repos.dcf? Maybe additional repositories could be an attribute
> >> >> >> > attached to returned character vector.
> >> >> >> >
> >> >> >> > The use case is to, for a given package sources, obtain its dependencies,
> >> >> >> > so one can use that for installing them/mirroring CRAN subset, or whatever.
> >> >> >> > The later is especially important for a production environment where one
> >> >> >> > wants to have fixed version of packages, and mirroring relevant subset of
> >> >> >> > CRAN is the most simple, and IMO reliable, way to manage such environment.
> >> >> >> >
> >> >> >> > Regards
> >> >> >> > Jan
> >> >> >> >
> >> >> >> > On Fri, Oct 14, 2022, 23:34 Gabriel Becker <gabembecker at gmail.com> wrote:
> >> >> >> >
> >> >> >> >> Hi Jan and Jan,
> >> >> >> >>
> >> >> >> >> Can you explain a little more what exactly you want the non-recursive,
> >> >> >> >> non-version aware dependencies from an individual package for?
> >> >> >> >>
> >> >> >> >> Either way package_dependencies will do this for you* with a little
> >> >> >> >> "aggressive convincing". It wants output from available.packages, but who
> >> >> >> >> really cares what it wants? It's a function and we are people :)
> >> >> >> >>
> >> >> >> >>> library(tools)
> >> >> >> >>> db <- read.dcf("~/gabe/checkedout/rtables_clean/DESCRIPTION")
> >> >> >> >>> package_dependencies("rtables", db, which = intersect(c("Depends",
> >> >> >> >> "Suggests", "Imports", "LinkingTo"), colnames(db)))
> >> >> >> >> $rtables
> >> >> >> >> [1] "methods"    "magrittr"   "formatters" "dplyr"      "tibble"
> >> >> >> >> [6] "tidyr"      "testthat"   "xml2"       "knitr"      "rmarkdown"
> >> >> >> >> [11] "flextable"  "officer"    "stats"      "htmltools"  "grid"
> >> >> >> >>
> >> >> >> >>
> >> >> >> >> The only gotcha that I see immediately is that "LinkingTo" isn't always
> >> >> >> >> there (whereas it is with real output from available.packages). If you
> >> >> >> >> know your package doesn't have that (or that it does) at call time , this
> >> >> >> >> becomes a one-liner:
> >> >> >> >>
> >> >> >> >> package_dependencies("rtables", db =
> >> >> >> >> read.dcf("~/gabe/checkedout/rtables_clean/DESCRIPTION"), which =
> >> >> >> >> c("Depends", "Suggests", "Imports"))
> >> >> >> >> $rtables
> >> >> >> >> [1] "methods"    "magrittr"   "formatters" "dplyr"      "tibble"
> >> >> >> >> [6] "tidyr"      "testthat"   "xml2"       "knitr"      "rmarkdown"
> >> >> >> >> [11] "flextable"  "officer"    "stats"      "htmltools"  "grid"
> >> >> >> >>
> >> >> >> >> You can also trick it a slightly different way by giving it what it
> >> >> >> >> actually wants
> >> >> >> >>
> >> >> >> >>> tdir <- tempdir()
> >> >> >> >>> file.copy("~/gabe/checkedout/rtables_clean/DESCRIPTION", file.path(tdir,
> >> >> >> >> "PACKAGES"))
> >> >> >> >> [1] TRUE
> >> >> >> >>> avl <- available.packages(paste0("file://", tdir))
> >> >> >> >>> library(tools)
> >> >> >> >>> package_dependencies("rtables", avl)
> >> >> >> >> $rtables
> >> >> >> >> [1] "methods"    "magrittr"   "formatters" "stats"      "htmltools"
> >> >> >> >> [6] "grid"
> >> >> >> >>
> >> >> >> >>> package_dependencies("rtables", avl, which = "all")
> >> >> >> >> $rtables
> >> >> >> >> [1] "methods"    "magrittr"   "formatters" "stats"      "htmltools"
> >> >> >> >> [6] "grid"       "dplyr"      "tibble"     "tidyr"      "testthat"
> >> >> >> >> [11] "xml2"       "knitr"      "rmarkdown"  "flextable"  "officer"
> >> >> >> >>
> >> >> >> >> So the only real benefits I see that we'd be picking up here is automatic
> >> >> >> >> filtering by priority, and automatic extraction of the package name from
> >> >> >> >> the DESCRIPTION file. I'm not sure either of those warrant a new exported
> >> >> >> >> function that R-core has to maintain forever.
> >> >> >> >>
> >> >> >> >> Best,
> >> >> >> >> ~G
> >> >> >> >>
> >> >> >> >> * I haven't tested this across all OSes, but I dont' know of any reason it
> >> >> >> >> wouldn't work generally.
> >> >> >> >>
> >> >> >> >> On Fri, Oct 14, 2022 at 2:33 PM Jan Gorecki <j.gorecki at wit.edu.pl> wrote:
> >> >> >> >>
> >> >> >> >>> Hello Jan,
> >> >> >> >>>
> >> >> >> >>> Thanks for confirming about many packages reinventing this missing
> >> >> >> >>> functionality.
> >> >> >> >>> packages.dcf was not meant handle versions. It just extracts names of
> >> >> >> >>> dependencies... Yes, such a simple thing, yet missing in base R.
> >> >> >> >>>
> >> >> >> >>> Versions of packages can be controlled when setting up R pkgs repo. This
> >> >> >> >>> is
> >> >> >> >>> how I used to handle it. Making a CRAN subset mirror of fixed version
> >> >> >> >>> pkgs.
> >> >> >> >>> BTW. function for that is also included in mentioned branch. I am just not
> >> >> >> >>> proposing it, to increase the chance of having at least this simple,
> >> >> >> >>> missing, functionality merged.
> >> >> >> >>>
> >> >> >> >>> Best
> >> >> >> >>> Jan
> >> >> >> >>>
> >> >> >> >>> On Fri, Oct 14, 2022, 15:14 Jan Net?k <netikja at gmail.com> wrote:
> >> >> >> >>>
> >> >> >> >>>> Hello Jan,
> >> >> >> >>>>
> >> >> >> >>>> I have seen many packages that implemented dependencies "extraction" on
> >> >> >> >>>> their own for internal purposes and today I was doing exactly that for
> >> >> >> >>>> mine. It's not a big deal using read.dcf on DESCRIPTION. It was
> >> >> >> >>> sufficient
> >> >> >> >>>> for me, but I had to take care of some \n chars (the overall returned
> >> >> >> >>> value
> >> >> >> >>>> has some rough edges, in my opinion). However, the function from the
> >> >> >> >>> branch
> >> >> >> >>>> seems to not care about version requirements, which are crucial for me.
> >> >> >> >>>> Maybe that is something to reconsider before merging.
> >> >> >> >>>>
> >> >> >> >>>> Best,
> >> >> >> >>>> Jan
> >> >> >> >>>>
> >> >> >> >>>> p? 14. 10. 2022 v 2:27 odes?latel Jan Gorecki <j.gorecki at wit.edu.pl>
> >> >> >> >>>> napsal:
> >> >> >> >>>>
> >> >> >> >>>>> Dear R devs,
> >> >> >> >>>>>
> >> >> >> >>>>> I would like to raise a request for a simple helper function.
> >> >> >> >>>>> Utility function to extract package dependencies from DESCRIPTION file.
> >> >> >> >>>>>
> >> >> >> >>>>> I do think that tools package is better place, for such a fundamental
> >> >> >> >>>>> functionality, than community packages.
> >> >> >> >>>>>
> >> >> >> >>>>> tools pkg seems perfect fit (having already great function
> >> >> >> >>>>> write_PACKAGES).
> >> >> >> >>>>>
> >> >> >> >>>>> Functionality I am asking for is already in R svn repository since
> >> >> >> >>> 2016,
> >> >> >> >>>>> in
> >> >> >> >>>>> a branch tools4pkgs. Function is called 'packages.dcf'.
> >> >> >> >>>>> Another one 'repos.dcf' would be a good functional complementary to it.
> >> >> >> >>>>>
> >> >> >> >>>>> Those two simple helper functions really makes it easier for
> >> >> >> >>> organizations
> >> >> >> >>>>> to glue together usage of their own R packages repos and CRAN repo in a
> >> >> >> >>>>> smooth way. That could possibly help to offload CRAN from new
> >> >> >> >>> submissions.
> >> >> >> >>>>>
> >> >> >> >>>>> gh mirror link for easy preview:
> >> >> >> >>>>>
> >> >> >> >>>>>
> >> >> >> >>> https://github.com/wch/r-source/blob/tools4pkgs/src/library/tools/R/packages.R#L419
> >> >> >> >>>>>
> >> >> >> >>>>> Regards
> >> >> >> >>>>> Jan Gorecki
> >> >> >> >>>>>
> >> >> >> >>>>>        [[alternative HTML version deleted]]
> >> >> >> >>>>>
> >> >> >> >>>>> ______________________________________________
> >> >> >> >>>>> R-devel at r-project.org mailing list
> >> >> >> >>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
> >> >> >> >>>>>
> >> >> >> >>>>
> >> >> >> >>>
> >> >> >> >>>        [[alternative HTML version deleted]]
> >> >> >> >>>
> >> >> >> >>> ______________________________________________
> >> >> >> >>> R-devel at r-project.org mailing list
> >> >> >> >>> https://stat.ethz.ch/mailman/listinfo/r-devel
> >> >> >> >>>
> >> >> >> >>
> >> >> >> >
> >> >> >> >       [[alternative HTML version deleted]]
> >> >> >> >
> >> >> >> > ______________________________________________
> >> >> >> > R-devel at r-project.org mailing list
> >> >> >> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >> >> >> >
> >> >> >>


From tdhock5 @end|ng |rom gm@||@com  Tue Dec 19 21:57:01 2023
From: tdhock5 @end|ng |rom gm@||@com (Toby Hocking)
Date: Tue, 19 Dec 2023 13:57:01 -0700
Subject: [Rd] 
 Partial matching performance in data frame rownames using [
In-Reply-To: <20231216124842.4d889cdd@Tarkus>
References: <de5e1dad-7ffc-4c35-8c51-1e0e21e585b9@gmx.de>
 <20231212155519.2ccbd3d2@arachnoid>
 <8022eea1-9577-476c-9f06-67e8f32a6a61@gmx.de> <20231216124842.4d889cdd@Tarkus>
Message-ID: <CALK03d00QLn6zwWVo7urwSnY3H+Gxmq5bpHGL3ezGvKsrSYmYA@mail.gmail.com>

Hi Hilmar and Ivan,
I have used your code examples to write a blog post about this topic,
which has figures that show the asymptotic time complexity of the
various approaches,
https://tdhock.github.io/blog/2023/df-partial-match/
The asymptotic complexity of partial matching appears to be quadratic
O(N^2) whereas the other approaches are asymptotically faster: linear
O(N) or log-linear O(N log N).
I think that accepting Ivan's pmatch.rows patch would add un-necessary
complexity to base R, since base R already provides an efficient
work-around, d1[match(q1,rownames(d1)),]
I do think the CheckUserInterrupt patch is a good idea, though.
Best,
Toby

On Sat, Dec 16, 2023 at 2:49?AM Ivan Krylov <krylov.r00t at gmail.com> wrote:
>
> On Wed, 13 Dec 2023 09:04:18 +0100
> Hilmar Berger via R-devel <r-devel at r-project.org> wrote:
>
> > Still, I feel that default partial matching cripples the functionality
> > of data.frame for larger tables.
>
> Changing the default now would require a long deprecation cycle to give
> everyone who uses `[.data.frame` and relies on partial matching
> (whether they know it or not) enough time to adjust.
>
> Still, adding an argument feels like a small change: edit
> https://svn.r-project.org/R/trunk/src/library/base/R/dataframe.R and
> add a condition before calling pmatch(). Adjust the warning() for named
> arguments. Don't forget to document the new argument in the man page at
> https://svn.r-project.org/R/trunk/src/library/base/man/Extract.data.frame.Rd
>
> Index: src/library/base/R/dataframe.R
> ===================================================================
> --- src/library/base/R/dataframe.R      (revision 85664)
> +++ src/library/base/R/dataframe.R      (working copy)
> @@ -591,14 +591,14 @@
>  ###  These are a little less general than S
>
>  `[.data.frame` <-
> -    function(x, i, j, drop = if(missing(i)) TRUE else length(cols) == 1)
> +    function(x, i, j, drop = if(missing(i)) TRUE else length(cols) == 1, pmatch.rows = TRUE)
>  {
>      mdrop <- missing(drop)
>      Narg <- nargs() - !mdrop  # number of arg from x,i,j that were specified
>      has.j <- !missing(j)
> -    if(!all(names(sys.call()) %in% c("", "drop"))
> +    if(!all(names(sys.call()) %in% c("", "drop", "pmatch.rows"))
>         && !isS4(x)) # at least don't warn for callNextMethod!
> -        warning("named arguments other than 'drop' are discouraged")
> +        warning("named arguments other than 'drop', 'pmatch.rows' are discouraged")
>
>      if(Narg < 3L) {  # list-like indexing or matrix indexing
>          if(!mdrop) warning("'drop' argument will be ignored")
> @@ -679,7 +679,11 @@
>              ## for consistency with [, <length-1>]
>              if(is.character(i)) {
>                  rows <- attr(xx, "row.names")
> -                i <- pmatch(i, rows, duplicates.ok = TRUE)
> +                i <- if (pmatch.rows) {
> +                    pmatch(i, rows, duplicates.ok = TRUE)
> +                } else {
> +                    match(i, rows)
> +                }
>              }
>              ## need to figure which col was selected:
>              ## cannot use .subset2 directly as that may
> @@ -699,7 +703,11 @@
>                   # as this can be expensive.
>      if(is.character(i)) {
>          rows <- attr(xx, "row.names")
> -        i <- pmatch(i, rows, duplicates.ok = TRUE)
> +        i <- if (pmatch.rows) {
> +            pmatch(i, rows, duplicates.ok = TRUE)
> +        } else {
> +            match(i, rows)
> +        }
>      }
>      for(j in seq_along(x)) {
>          xj <- xx[[ sxx[j] ]]
> Index: src/library/base/man/Extract.data.frame.Rd
> ===================================================================
> --- src/library/base/man/Extract.data.frame.Rd  (revision 85664)
> +++ src/library/base/man/Extract.data.frame.Rd  (working copy)
> @@ -15,7 +15,7 @@
>    Extract or replace subsets of data frames.
>  }
>  \usage{
> -\method{[}{data.frame}(x, i, j, drop = )
> +\method{[}{data.frame}(x, i, j, drop =, pmatch.rows = TRUE)
>  \method{[}{data.frame}(x, i, j) <- value
>  \method{[[}{data.frame}(x, ..., exact = TRUE)
>  \method{[[}{data.frame}(x, i, j) <- value
> @@ -45,6 +45,9 @@
>      column is selected.}
>
>     \item{exact}{logical: see \code{\link{[}}, and applies to column names.}
> +
> +   \item{pmatch.rows}{logical: whether to perform partial matching on
> +     row names in case \code{i} is a character vector.}
>  }
>  \details{
>    Data frames can be indexed in several modes.  When \code{[} and
>
>
> system.time({r <- d1[q2,, drop=FALSE, pmatch.rows = FALSE]})
> #    user  system elapsed
> #   0.478   0.004   0.482
>
> Unfortunately, that would be only the beginning. The prose in the whole
> ?`[.data.frame` would have to be updated; the new behaviour would have
> to be tested in tests/**.R. There may be very good reasons why named
> arguments to `[` other than drop= are discouraged for data.frames. I'm
> afraid I lack the whole-project view to consider whether such an
> addition would be safe.
>
> --
> Best regards,
> Ivan
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From tdhock5 @end|ng |rom gm@||@com  Tue Dec 19 21:57:31 2023
From: tdhock5 @end|ng |rom gm@||@com (Toby Hocking)
Date: Tue, 19 Dec 2023 13:57:31 -0700
Subject: [Rd] 
 Partial matching performance in data frame rownames using [
In-Reply-To: <20231216124842.4d889cdd@Tarkus>
References: <de5e1dad-7ffc-4c35-8c51-1e0e21e585b9@gmx.de>
 <20231212155519.2ccbd3d2@arachnoid>
 <8022eea1-9577-476c-9f06-67e8f32a6a61@gmx.de> <20231216124842.4d889cdd@Tarkus>
Message-ID: <CALK03d2gzY1=iegH6FYCE2m1z7G-W-+Y9OgfKtrs1xmH2co8rg@mail.gmail.com>

Hi Hilmar and Ivan,
I have used your code examples to write a blog post about this topic,
which has figures that show the asymptotic time complexity of the
various approaches,
https://tdhock.github.io/blog/2023/df-partial-match/
The asymptotic complexity of partial matching appears to be quadratic
O(N^2) whereas the other approaches are asymptotically faster: linear
O(N) or log-linear O(N log N).
I think that accepting Ivan's pmatch.rows patch would add un-necessary
complexity to base R, since base R already provides an efficient
work-around, d1[match(q1,rownames(d1)),]
I do think the CheckUserInterrupt patch is a good idea, though.
Best,
Toby

On Sat, Dec 16, 2023 at 2:49?AM Ivan Krylov <krylov.r00t at gmail.com> wrote:
>
> On Wed, 13 Dec 2023 09:04:18 +0100
> Hilmar Berger via R-devel <r-devel at r-project.org> wrote:
>
> > Still, I feel that default partial matching cripples the functionality
> > of data.frame for larger tables.
>
> Changing the default now would require a long deprecation cycle to give
> everyone who uses `[.data.frame` and relies on partial matching
> (whether they know it or not) enough time to adjust.
>
> Still, adding an argument feels like a small change: edit
> https://svn.r-project.org/R/trunk/src/library/base/R/dataframe.R and
> add a condition before calling pmatch(). Adjust the warning() for named
> arguments. Don't forget to document the new argument in the man page at
> https://svn.r-project.org/R/trunk/src/library/base/man/Extract.data.frame.Rd
>
> Index: src/library/base/R/dataframe.R
> ===================================================================
> --- src/library/base/R/dataframe.R      (revision 85664)
> +++ src/library/base/R/dataframe.R      (working copy)
> @@ -591,14 +591,14 @@
>  ###  These are a little less general than S
>
>  `[.data.frame` <-
> -    function(x, i, j, drop = if(missing(i)) TRUE else length(cols) == 1)
> +    function(x, i, j, drop = if(missing(i)) TRUE else length(cols) == 1, pmatch.rows = TRUE)
>  {
>      mdrop <- missing(drop)
>      Narg <- nargs() - !mdrop  # number of arg from x,i,j that were specified
>      has.j <- !missing(j)
> -    if(!all(names(sys.call()) %in% c("", "drop"))
> +    if(!all(names(sys.call()) %in% c("", "drop", "pmatch.rows"))
>         && !isS4(x)) # at least don't warn for callNextMethod!
> -        warning("named arguments other than 'drop' are discouraged")
> +        warning("named arguments other than 'drop', 'pmatch.rows' are discouraged")
>
>      if(Narg < 3L) {  # list-like indexing or matrix indexing
>          if(!mdrop) warning("'drop' argument will be ignored")
> @@ -679,7 +679,11 @@
>              ## for consistency with [, <length-1>]
>              if(is.character(i)) {
>                  rows <- attr(xx, "row.names")
> -                i <- pmatch(i, rows, duplicates.ok = TRUE)
> +                i <- if (pmatch.rows) {
> +                    pmatch(i, rows, duplicates.ok = TRUE)
> +                } else {
> +                    match(i, rows)
> +                }
>              }
>              ## need to figure which col was selected:
>              ## cannot use .subset2 directly as that may
> @@ -699,7 +703,11 @@
>                   # as this can be expensive.
>      if(is.character(i)) {
>          rows <- attr(xx, "row.names")
> -        i <- pmatch(i, rows, duplicates.ok = TRUE)
> +        i <- if (pmatch.rows) {
> +            pmatch(i, rows, duplicates.ok = TRUE)
> +        } else {
> +            match(i, rows)
> +        }
>      }
>      for(j in seq_along(x)) {
>          xj <- xx[[ sxx[j] ]]
> Index: src/library/base/man/Extract.data.frame.Rd
> ===================================================================
> --- src/library/base/man/Extract.data.frame.Rd  (revision 85664)
> +++ src/library/base/man/Extract.data.frame.Rd  (working copy)
> @@ -15,7 +15,7 @@
>    Extract or replace subsets of data frames.
>  }
>  \usage{
> -\method{[}{data.frame}(x, i, j, drop = )
> +\method{[}{data.frame}(x, i, j, drop =, pmatch.rows = TRUE)
>  \method{[}{data.frame}(x, i, j) <- value
>  \method{[[}{data.frame}(x, ..., exact = TRUE)
>  \method{[[}{data.frame}(x, i, j) <- value
> @@ -45,6 +45,9 @@
>      column is selected.}
>
>     \item{exact}{logical: see \code{\link{[}}, and applies to column names.}
> +
> +   \item{pmatch.rows}{logical: whether to perform partial matching on
> +     row names in case \code{i} is a character vector.}
>  }
>  \details{
>    Data frames can be indexed in several modes.  When \code{[} and
>
>
> system.time({r <- d1[q2,, drop=FALSE, pmatch.rows = FALSE]})
> #    user  system elapsed
> #   0.478   0.004   0.482
>
> Unfortunately, that would be only the beginning. The prose in the whole
> ?`[.data.frame` would have to be updated; the new behaviour would have
> to be tested in tests/**.R. There may be very good reasons why named
> arguments to `[` other than drop= are discouraged for data.frames. I'm
> afraid I lack the whole-project view to consider whether such an
> addition would be safe.
>
> --
> Best regards,
> Ivan
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From @tevem@rt|n041 @end|ng |rom gm@||@com  Wed Dec 20 04:01:12 2023
From: @tevem@rt|n041 @end|ng |rom gm@||@com (Steve Martin)
Date: Tue, 19 Dec 2023 22:01:12 -0500
Subject: [Rd] [External] Re: zapsmall(x) for scalar x
In-Reply-To: <25985.50170.190748.540475@stat.math.ethz.ch>
References: <CAP=dwz8bGEvMEiXL+64dNH0cYtvAF3Y6ouCiVfX99y+1-VGGUA@mail.gmail.com>
 <B7FE40A5-18D3-437B-A446-EEA5B20A98AA@warnes.net>
 <bbcaa531201446a69c7fdedd311393ed@LO6P265MB6080.GBRP265.PROD.OUTLOOK.COM>
 <CANVKczNLxChkreGnAa=oDUz7w8SEG_i3xW3_9k3BjaC7Q_Y+9Q@mail.gmail.com>
 <f3751191-443f-4577-805a-2577a87506ed@insa-toulouse.fr>
 <25984.7656.269922.822939@stat.math.ethz.ch>
 <b2463b7c-755a-47c9-8c31-75ba748777bf@insa-toulouse.fr>
 <CAP=dwz-oWc_K9ABHd4JQRYceY5+PsPmGTGGg1RmQw9+_xq=+hQ@mail.gmail.com>
 <25985.50170.190748.540475@stat.math.ethz.ch>
Message-ID: <CAP=dwz9bcSMuTriwj=RqgBLjSBPqZ9S=SB=+97FFidqSpztvmw@mail.gmail.com>

Thanks for sharing, Martin. You're right that the interface for mFUN
should be more general than I initially thought.*

Perhaps you have other cases/examples where the ina argument is
useful, in which case ignore me, but your example with the robust mFUN
doesn't use the ina argument. What about having mFUN be only an
argument of x (NAs and all), with a default of \(x) max(abs(x), na.rm
= TRUE)? It's a minor difference, but it might make the mFUN argument
a bit simpler to use (no need to carry a dummy argument when NAs in x
can be handled directly).

Steve

* Tangent: Does boxplot.stats() use the number of NA values? The
documentation says NAs are omitted, and a quick scan of the code and
some tests suggests boxplot.stats(x) should give the same result as
boxplot.stats(x[!is.na(x)]), although I may be missing something. But
your point is well taken, and the interface should be more general
than I initially thought.

On Tue, 19 Dec 2023 at 11:25, Martin Maechler
<maechler at stat.math.ethz.ch> wrote:
>
> >>>>> Steve Martin
> >>>>>     on Mon, 18 Dec 2023 07:56:46 -0500 writes:
>
>     > Does mFUN() really need to be a function of x and the NA values of x? I
>     > can't think of a case where it would be used on anything but the non-NA
>     > values of x.
>
>     > I think it would be easier to specify a different mFUN() (and document this
>     > new argument) if the function has one argument and is applied to the non-NA
>     > values of x.
>
>     > zapsmall <- function(x,
>     >     digits = getOption("digits"),
>     >     mFUN = function(x) max(abs(x)),
>     >     min.d = 0L) {
>     >     if (length(digits) == 0L)
>     >         stop("invalid 'digits'")
>     >     if (all(ina <- is.na(x)))
>     >         return(x)
>     >     mx <- mFUN(x[!ina])
>     >     round(x, digits = if(mx > 0) max(min.d, digits - as.numeric(log10(mx)))
>     > else digits)
>     > }
>
>     > Steve
>
> Thank you, Steve,
> you are right that it would look simpler to do it that way.
>
> On the other hand, in your case, mFUN() no longer sees the
> original  n observations, and would not know if there where NAs
> in that case how many NAs there were in the original data.
>
> The examples I have on my version of zapsmall's help page (see below)
> uses a robust mFUN, "the upper hinge of a box plot":
>
>    mF_rob <- function(x, ina) boxplot.stats(x, do.conf=FALSE)$stats[5]
>
> and if you inspect boxplot.stats() you may know that indeed it
> also wants to use the full data 'x' to compute its statistics and
> then deal with NAs directly.  Your simplified mFUN interface
> would not be fully consistent with boxplot(), and I think could
> not be made so,  hence my more flexible 2-argument "design" for  mFUN().
>
> .... and BTW, these examples also exemplify the use of  `min.d`
> about which  Serguei Sokol asked for an example or two.
>
> Here I repeat my definition of zapsmall, and then my current set
> of examples:
>
> zapsmall <- function(x, digits = getOption("digits"),
>                      mFUN = function(x, ina) max(abs(x[!ina])), min.d = 0L)
> {
>     if (length(digits) == 0L)
>         stop("invalid 'digits'")
>     if (all(ina <- is.na(x)))
>         return(x)
>     mx <- mFUN(x, ina)
>     round(x, digits = if(mx > 0) max(min.d, digits - as.numeric(log10(mx))) else digits)
> }
>
>
> ##--- \examples{
> x2 <- pi * 100^(-2:2)/10
>    print(  x2, digits = 4)
> zapsmall(  x2) # automatical digits
> zapsmall(  x2, digits = 4)
> zapsmall(c(x2, Inf)) # round()s to integer ..
> zapsmall(c(x2, Inf), min.d=-Inf) # everything  is small wrt  Inf
>
> (z <- exp(1i*0:4*pi/2))
> zapsmall(z)
>
> zapShow <- function(x, ...) rbind(orig = x, zapped = zapsmall(x, ...))
> zapShow(x2)
>
> ## using a *robust* mFUN
> mF_rob <- function(x, ina) boxplot.stats(x, do.conf=FALSE)$stats[5]
> ## with robust mFUN(), 'Inf' is no longer distorting the picture:
> zapShow(c(x2, Inf), mFUN = mF_rob)
> zapShow(c(x2, Inf), mFUN = mF_rob, min.d = -5) # the same
> zapShow(c(x2, 999), mFUN = mF_rob) # same *rounding* as w/ Inf
> zapShow(c(x2, 999), mFUN = mF_rob, min.d =  3) # the same
> zapShow(c(x2, 999), mFUN = mF_rob, min.d =  8) # small diff
> ##--- }
>
>
>
>     > On Mon, Dec 18, 2023, 05:47 Serguei Sokol via R-devel <r-devel at r-project.org>
>     > wrote:
>
> > Le 18/12/2023 ? 11:24, Martin Maechler a ?crit :
> > >>>>>> Serguei Sokol via R-devel
> > >>>>>>      on Mon, 18 Dec 2023 10:29:02 +0100 writes:
> > >      > Le 17/12/2023 ? 18:26, Barry Rowlingson a ?crit :
> > >      >> I think what's been missed is that zapsmall works relative to the absolute
> > >      >> largest value in the vector. Hence if there's only one
> > >      >> item in the vector, it is the largest, so its not zapped. The function's
> > >      >> raison d'etre isn't to replace absolutely small values,
> > >      >> but small values relative to the largest. Hence a vector of similar tiny
> > >      >> values doesn't get zapped.
> > >      >>
> > >      >> Maybe the line in the docs:
> > >      >>
> > >      >> " (compared with the maximal absolute value)"
> > >      >>
> > >      >> needs to read:
> > >      >>
> > >      >> " (compared with the maximal absolute value in the vector)"
> > >
> > >      > I agree that this change in the doc would clarify the situation but
> > >      > would not resolve proposed corner cases.
> > >
> > >      > I think that an additional argument 'mx' (absolute max value of
> > >      > reference) would do. Consider:
> > >
> > >      > zapsmall2 <-
> > >      > function (x, digits = getOption("digits"), mx=max(abs(x),  na.rm=TRUE))
> > >      > {
> > >      >     if (length(digits) == 0L)
> > >      >         stop("invalid 'digits'")
> > >      >     if (all(ina <- is.na(x)))
> > >      >         return(x)
> > >      >     round(x, digits = if (mx > 0) max(0L, digits - as.numeric(log10(mx))) else digits)
> > >      > }
> > >
> > >      > then zapsmall2() without explicit 'mx' behaves
> > >      > identically to actual
> > >      > zapsmall() and for a scalar or a vector of identical value, user
> > can
> > >      > manually fix the scale of what should be considered as small:
> > >
> > >      >> zapsmall2(y)
> > >      > [1] 2.220446e-16
> > >      >> zapsmall2(y, mx=1)
> > >      > [1] 0
> > >      >> zapsmall2(c(y, y), mx=1)
> > >      > [1] 0 0
> > >      >> zapsmall2(c(y, NA))
> > >      > [1] 2.220446e-16           NA
> > >      >> zapsmall2(c(y, NA), mx=1)
> > >      > [1]  0 NA
> > >
> > >      > Obviously, the name 'zapsmall2' was chosen just for this
> > explanation.
> > >      > The original name 'zapsmall' could be reused as a full backward
> > >      > compatibility is preserved.
> > >
> > >      > Best,
> > >      > Serguei.
> [.......................]
>


From h||m@r@berger @end|ng |rom gmx@de  Thu Dec 21 09:50:01 2023
From: h||m@r@berger @end|ng |rom gmx@de (Hilmar Berger)
Date: Thu, 21 Dec 2023 09:50:01 +0100
Subject: [Rd] 
 Partial matching performance in data frame rownames using [
In-Reply-To: <CALK03d2gzY1=iegH6FYCE2m1z7G-W-+Y9OgfKtrs1xmH2co8rg@mail.gmail.com>
References: <de5e1dad-7ffc-4c35-8c51-1e0e21e585b9@gmx.de>
 <20231212155519.2ccbd3d2@arachnoid>
 <8022eea1-9577-476c-9f06-67e8f32a6a61@gmx.de>
 <20231216124842.4d889cdd@Tarkus>
 <CALK03d2gzY1=iegH6FYCE2m1z7G-W-+Y9OgfKtrs1xmH2co8rg@mail.gmail.com>
Message-ID: <2f81f14f-c640-4b73-b63c-34e5319248fd@gmx.de>

Dear Toby and Ivan,

thanks a lot for the proposed patch and this detailed analysis. The
timing analysis nicely shows what I suspected - that partial matching in
large tables (>>10^5 rows) can get prohibitively slow. For 10^6 rows
with 50% non-hits in exact matching I roughly would expect 10,000
seconds, i.e. almost 3h.

That would be quite slow even if one would want partial matching. My
suspicion, however, is that most users do not want partial matching at
all and use row name indexing using character vectors in the same way as
applied in data.table or tibble, i.e. as a unique key to table rows.

I can't remember a valid use case where I would have used partial
matching for a rowname index in the last 10 years, and I would be happy
to learn how widespread such use cases are.

Regarding the workaround, I do not fully agree that adding match() to
the call of [.data.frame() would be a preferable solution. In cases
where one cannot exclude that the data.frame will grow large and that
there might be considerable proportions of non-hits in exact matching,
the workaround would have to applied always in order to achieve a
predictable performance. Which, in my opinion, raises the question if
and when the ordinary, partial matching option would be still applicable.

I am not knowledgeable to say how much work it would be, but I believe
that we could test the impact of Ivan's proposed solution by running
CRAN/BioC package tests against a patched R compared to an unpatched
one. I can offer to have a look at failing test cases to see if those
are intentional or unintentional uses of partial matching.

Best regards

Hilmar

On 19.12.23 21:57, Toby Hocking wrote:
> Hi Hilmar and Ivan,
> I have used your code examples to write a blog post about this topic,
> which has figures that show the asymptotic time complexity of the
> various approaches,
> https://tdhock.github.io/blog/2023/df-partial-match/
> The asymptotic complexity of partial matching appears to be quadratic
> O(N^2) whereas the other approaches are asymptotically faster: linear
> O(N) or log-linear O(N log N).
> I think that accepting Ivan's pmatch.rows patch would add un-necessary
> complexity to base R, since base R already provides an efficient
> work-around, d1[match(q1,rownames(d1)),]
> I do think the CheckUserInterrupt patch is a good idea, though.
> Best,
> Toby
>
> On Sat, Dec 16, 2023 at 2:49?AM Ivan Krylov <krylov.r00t at gmail.com> wrote:
>> On Wed, 13 Dec 2023 09:04:18 +0100
>> Hilmar Berger via R-devel <r-devel at r-project.org> wrote:
>>
>>> Still, I feel that default partial matching cripples the functionality
>>> of data.frame for larger tables.
>> Changing the default now would require a long deprecation cycle to give
>> everyone who uses `[.data.frame` and relies on partial matching
>> (whether they know it or not) enough time to adjust.
>>
>> Still, adding an argument feels like a small change: edit
>> https://svn.r-project.org/R/trunk/src/library/base/R/dataframe.R and
>> add a condition before calling pmatch(). Adjust the warning() for named
>> arguments. Don't forget to document the new argument in the man page at
>> https://svn.r-project.org/R/trunk/src/library/base/man/Extract.data.frame.Rd
>>
>> Index: src/library/base/R/dataframe.R
>> ===================================================================
>> --- src/library/base/R/dataframe.R      (revision 85664)
>> +++ src/library/base/R/dataframe.R      (working copy)
>> @@ -591,14 +591,14 @@
>>   ###  These are a little less general than S
>>
>>   `[.data.frame` <-
>> -    function(x, i, j, drop = if(missing(i)) TRUE else length(cols) == 1)
>> +    function(x, i, j, drop = if(missing(i)) TRUE else length(cols) == 1, pmatch.rows = TRUE)
>>   {
>>       mdrop <- missing(drop)
>>       Narg <- nargs() - !mdrop  # number of arg from x,i,j that were specified
>>       has.j <- !missing(j)
>> -    if(!all(names(sys.call()) %in% c("", "drop"))
>> +    if(!all(names(sys.call()) %in% c("", "drop", "pmatch.rows"))
>>          && !isS4(x)) # at least don't warn for callNextMethod!
>> -        warning("named arguments other than 'drop' are discouraged")
>> +        warning("named arguments other than 'drop', 'pmatch.rows' are discouraged")
>>
>>       if(Narg < 3L) {  # list-like indexing or matrix indexing
>>           if(!mdrop) warning("'drop' argument will be ignored")
>> @@ -679,7 +679,11 @@
>>               ## for consistency with [, <length-1>]
>>               if(is.character(i)) {
>>                   rows <- attr(xx, "row.names")
>> -                i <- pmatch(i, rows, duplicates.ok = TRUE)
>> +                i <- if (pmatch.rows) {
>> +                    pmatch(i, rows, duplicates.ok = TRUE)
>> +                } else {
>> +                    match(i, rows)
>> +                }
>>               }
>>               ## need to figure which col was selected:
>>               ## cannot use .subset2 directly as that may
>> @@ -699,7 +703,11 @@
>>                    # as this can be expensive.
>>       if(is.character(i)) {
>>           rows <- attr(xx, "row.names")
>> -        i <- pmatch(i, rows, duplicates.ok = TRUE)
>> +        i <- if (pmatch.rows) {
>> +            pmatch(i, rows, duplicates.ok = TRUE)
>> +        } else {
>> +            match(i, rows)
>> +        }
>>       }
>>       for(j in seq_along(x)) {
>>           xj <- xx[[ sxx[j] ]]
>> Index: src/library/base/man/Extract.data.frame.Rd
>> ===================================================================
>> --- src/library/base/man/Extract.data.frame.Rd  (revision 85664)
>> +++ src/library/base/man/Extract.data.frame.Rd  (working copy)
>> @@ -15,7 +15,7 @@
>>     Extract or replace subsets of data frames.
>>   }
>>   \usage{
>> -\method{[}{data.frame}(x, i, j, drop = )
>> +\method{[}{data.frame}(x, i, j, drop =, pmatch.rows = TRUE)
>>   \method{[}{data.frame}(x, i, j) <- value
>>   \method{[[}{data.frame}(x, ..., exact = TRUE)
>>   \method{[[}{data.frame}(x, i, j) <- value
>> @@ -45,6 +45,9 @@
>>       column is selected.}
>>
>>      \item{exact}{logical: see \code{\link{[}}, and applies to column names.}
>> +
>> +   \item{pmatch.rows}{logical: whether to perform partial matching on
>> +     row names in case \code{i} is a character vector.}
>>   }
>>   \details{
>>     Data frames can be indexed in several modes.  When \code{[} and
>>
>>
>> system.time({r <- d1[q2,, drop=FALSE, pmatch.rows = FALSE]})
>> #    user  system elapsed
>> #   0.478   0.004   0.482
>>
>> Unfortunately, that would be only the beginning. The prose in the whole
>> ?`[.data.frame` would have to be updated; the new behaviour would have
>> to be tested in tests/**.R. There may be very good reasons why named
>> arguments to `[` other than drop= are discouraged for data.frames. I'm
>> afraid I lack the whole-project view to consider whether such an
>> addition would be safe.
>>
>> --
>> Best regards,
>> Ivan
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


