From weigand.stephen at charter.net  Thu Mar  1 05:41:37 2007
From: weigand.stephen at charter.net (Stephen D. Weigand)
Date: Wed, 28 Feb 2007 22:41:37 -0600
Subject: [Rd] typo in reshape.Rd
Message-ID: <d143a33585413d77d0aa4400d69b8f6d@charter.net>

The 3 lines below are from paragraph 4 of \details in reshape.Rd.
In line [2], a space is needed before "where" and the "to" at the
end of the line should be removed.

[1]these names.  The default is variable names like \code{x.1},
[2]\code{x.2},where \code{split=list(regexp="\\.",include=FALSE)} to
[3]specifies to split at the dot and drop it from the name. To have 
alphabetic

Thanks,

Stephen


Stephen Weigand
Rochester, Minnesota, USA


From gregor.gorjanc at bfro.uni-lj.si  Thu Mar  1 11:39:24 2007
From: gregor.gorjanc at bfro.uni-lj.si (Gregor Gorjanc)
Date: Thu, 01 Mar 2007 11:39:24 +0100
Subject: [Rd] Registration of native routines
Message-ID: <45E6AD5C.2030508@bfro.uni-lj.si>

Dear R developers,

I am working on registration of native C and FORTRAN routines and have
encountered "inconsistencies" about this issue. I am referring to
"Registering native routines" section of R-ext manual.

*(DL_FUNC), &F77_SUB, &F77_SYMBOL

On line 5108 of R-ext.texi the array for method myCall is defined as

  {"myCall", &myCall, 3},

but looking at examples in src/library/stats/src/init.c I notice
addition of (DL_FUNC) i.e. upper definition would be

  {"myCall", (DL_FUNC) &myCall, 3},

This probably shows my poor knowledge of C, but what is the role of
(DL_FUNC)? Looking around the code I notice that DL_FUNC is used also in
other places. IMHO I would suggest that (DL_FUNC) is also "mentioned" in
the manual.

Additionally, what is the role of &F77_SUB() in registration of FORTRAN
subroutines i.e. the following line is one example from
src/library/stats/src/init.c.

    {"lowesw", (DL_FUNC) &F77_SUB(lowesw), 4}

src/main/registration.c for example uses &F77_SYMBOL() instead of
&F77_SUB(). Poking around the source I see that this is related to _. I
would again suggest to add this to the manual.

*Type and style field

For .C() and .Fortran() manual says that registration array can also
hold type and style fields. It is shown how type field should look like,
but nothing usable is said about style except

<manualSays>Typically, one omits this information in the registration
data.</manualSays>

Why would one omit this if

<manualSays>The purpose is to allow @R{} to transfer values more
efficiently across the R-C/FORTRAN interface by avoiding copying values
when it is not necessary.</manualSays>?

Thank you!

Gregor


From gregor.gorjanc at bfro.uni-lj.si  Thu Mar  1 11:47:42 2007
From: gregor.gorjanc at bfro.uni-lj.si (Gregor Gorjanc)
Date: Thu, 01 Mar 2007 11:47:42 +0100
Subject: [Rd] Same method for more than one class
Message-ID: <45E6AF4E.9050107@bfro.uni-lj.si>

Hi,

when defining method (I used length bellow just for the simplicity) for
myClass (S4 class) I use

setMethod(f="length", signature(x="myClass"),
          def=function(x) {
            cat("works")
          })

If I have myClass1 and myClass2 and mentioned method, which is not the
default one, applies to both classes I have to write two setMethod()
statements. Would it be possible to use

signature(x=c("myClass1", "myClass2"))

Currently it issues an error

setClass(Class="myClass1", representation=representation(x="integer"))
setClass(Class="myClass2", representation=representation(x="integer"))
setMethod(f="length", signature(x="myClass1"),
          def=function(x) {
            cat("works")
          })
## OK.

setMethod(f="length", signature(x=c("myClass1", "myClass1")),
          def=function(x) {
            cat("works")
          })
Error in signature(x = c("myClass1", "myClass1")) :
	bad class specified for element 1 (should be a single character string)

Regards, Gregor


From sdavis2 at mail.nih.gov  Thu Mar  1 12:18:11 2007
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Thu, 1 Mar 2007 06:18:11 -0500
Subject: [Rd] Same method for more than one class
In-Reply-To: <45E6AF4E.9050107@bfro.uni-lj.si>
References: <45E6AF4E.9050107@bfro.uni-lj.si>
Message-ID: <200703010618.11599.sdavis2@mail.nih.gov>

On Thursday 01 March 2007 05:47, Gregor Gorjanc wrote:
> Hi,
>
> when defining method (I used length bellow just for the simplicity) for
> myClass (S4 class) I use
>
> setMethod(f="length", signature(x="myClass"),
>           def=function(x) {
>             cat("works")
>           })
>
> If I have myClass1 and myClass2 and mentioned method, which is not the
> default one, applies to both classes I have to write two setMethod()
> statements. Would it be possible to use
>
> signature(x=c("myClass1", "myClass2"))

Could you do:

catFun <- function(x) {
  cat("Works")
}
setMethod(f="length", signature(x="myClass1"),def=catFun)
setMethod(f="length", signature(x="myClass2"),def=catFun)

Sean


From sdavis2 at mail.nih.gov  Thu Mar  1 12:20:56 2007
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Thu, 1 Mar 2007 06:20:56 -0500
Subject: [Rd] Same method for more than one class
In-Reply-To: <200703010618.11599.sdavis2@mail.nih.gov>
References: <45E6AF4E.9050107@bfro.uni-lj.si>
	<200703010618.11599.sdavis2@mail.nih.gov>
Message-ID: <200703010620.56795.sdavis2@mail.nih.gov>

On Thursday 01 March 2007 06:18, Sean Davis wrote:
> On Thursday 01 March 2007 05:47, Gregor Gorjanc wrote:
> > Hi,
> >
> > when defining method (I used length bellow just for the simplicity) for
> > myClass (S4 class) I use
> >
> > setMethod(f="length", signature(x="myClass"),
> >           def=function(x) {
> >             cat("works")
> >           })
> >
> > If I have myClass1 and myClass2 and mentioned method, which is not the
> > default one, applies to both classes I have to write two setMethod()
> > statements. Would it be possible to use
> >
> > signature(x=c("myClass1", "myClass2"))
>
> Could you do:
>
> catFun <- function(x) {
>   cat("Works")
> }
> setMethod(f="length", signature(x="myClass1"),def=catFun)
> setMethod(f="length", signature(x="myClass2"),def=catFun)

That said, it your myclass1 and myclass2 are related, you may want to make 
them both subclasses of a virtual class.  You could then use that virtual 
class in the signature or anywhere you wanted common functionality for two or 
more classes.

Sean


From gregor.gorjanc at bfro.uni-lj.si  Thu Mar  1 12:36:27 2007
From: gregor.gorjanc at bfro.uni-lj.si (Gregor Gorjanc)
Date: Thu, 01 Mar 2007 12:36:27 +0100
Subject: [Rd] Same method for more than one class
In-Reply-To: <200703010618.11599.sdavis2@mail.nih.gov>
References: <45E6AF4E.9050107@bfro.uni-lj.si>
	<200703010618.11599.sdavis2@mail.nih.gov>
Message-ID: <45E6BABB.2070709@bfro.uni-lj.si>

Sean Davis wrote:
...
> 
> Could you do:
> 
> catFun <- function(x) {
>   cat("Works")
> }
> setMethod(f="length", signature(x="myClass1"),def=catFun)
> setMethod(f="length", signature(x="myClass2"),def=catFun)

Yep, that is what I wanted.

setMethod(f="length", signature(x=c("myClass1", "myClass2"))

would be shorter, but your proposal is also OK.

Thank you again, Gregor


From kajla at bioinfo.pl  Thu Mar  1 16:27:33 2007
From: kajla at bioinfo.pl (laszlo kajan)
Date: Thu, 01 Mar 2007 16:27:33 +0100
Subject: [Rd] rgl update:  please test!
In-Reply-To: <45DD7848.70602@stats.uwo.ca>
References: <45DD7848.70602@stats.uwo.ca>
Message-ID: <45E6F0E5.9040604@bioinfo.pl>

Hello Duncan,

rgl.snapshot seems ok!

I compiled the source as usual: R CMD INSTALL rgl_0.70.564.tar.gz
on a
Linux hostname 2.6.19-1.2895.fc6 #1 SMP Wed Jan 10 18:50:56 EST 2007 
x86_64 x86_64 x86_64 GNU/Linux

Fedora Core 6.

I tested the rgl.snapshot, and it creates the snapshot png without a hitch.

Best regards,

Laszlo


Duncan Murdoch wrote:
> (This is bcc'd to a list of people who have had problems with rgl lately 
> or who are known to be big users; not cc'd, so you don't all get cc'd 
> all the responses on the R-devel list).
> 
> I've just put together a test build of rgl, and put it on my web site as
> 
> http://www.stats.uwo.ca/faculty/murdoch/software/rgl_0.70.564.tar.gz 
> (source)
> 
> and
> 
> http://www.stats.uwo.ca/faculty/murdoch/software/rgl_0.70.564.zip 
> (Windows binary).
> 
> This includes a number of changes:
> 
>   - changes to configure script from Laszlo Kajan and Brian Ripley: 
> should now be much more portable
>   - removed deprecated OSX font setting calls
>   - texture properties are now returned by material3d()
>   - allowed normals and texture coordinates to be specified in triangles 
> and quads
>   - normals may be specified in qmesh objects, but (at present) 
> subdivide removes them
>   - material3d() now preserves the values of unspecified parameters (as 
> documented, but not previously functioning)
>   - open3d() now resets all material properties to the defaults.
> 
> Could people who have been having problems with rgl (or just making use 
> of it) please test this update?  Some of the changes are very recent, 
> and may still be buggy:  but I'm going offline from late tomorrow until 
> March 4, so I'm not going to have an opportunity to test them myself 
> well enough to want to send this to CRAN.
> 
> I'm hoping to send this to CRAN soon after I return.
> 
> Duncan Murdoch


From r.hankin at noc.soton.ac.uk  Fri Mar  2 15:01:59 2007
From: r.hankin at noc.soton.ac.uk (Robin Hankin)
Date: Fri, 2 Mar 2007 14:01:59 +0000
Subject: [Rd] S3 best practice
Message-ID: <5D78FE68-7F9C-4605-84E5-B7B91EB0BDB5@soc.soton.ac.uk>

Hello everyone

Suppose I have an S3 class "dog" and a function plot.dog() which
looks like this:

plot.dog <- function(x,show.uncertainty, ...){
     <do a simple plot>
   if (show.uncertainty){
   <perform complicated combinatorial stuff that takes 20 minutes
       and superimpose the results on the simple plot>
   }
}


I think that it would be better to somehow precalculate the
uncertainty stuff and plot it separately.

How best to do this
in the context of an S3 method for plot()?

What is Best Practice here?



--
Robin Hankin
Uncertainty Analyst
National Oceanography Centre, Southampton
European Way, Southampton SO14 3ZH, UK
  tel  023-8059-7743


From juan at ufcengenharia.com.br  Fri Mar  2 11:52:01 2007
From: juan at ufcengenharia.com.br (juan at ufcengenharia.com.br)
Date: Fri,  2 Mar 2007 11:52:01 +0100 (CET)
Subject: [Rd] Install.packages() bug in Windows XP (PR#9540)
Message-ID: <20070302105201.4595C5D614@slim.kubism.ku.dk>

Dear User=B4s,
=20
run R2.2.0 for Windows Version (S.O. Windows XP) when install.packages()
function, after select the mirror, shown:
--- Please select a CRAN mirror for use in this session ---
Aviso: unable to access index for repository
http://cran.br.r-project.org/bin/windows/contrib/2.2
Aviso: unable to access index for repository
http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/2.2
Erro em install.packages() : argumento "pkgs" ausente, sem padr=E3o

Thanks,
=20
=20
Eng=BA Juan S. Ramseyer.
=20

	[[alternative HTML version deleted]]


From ligges at statistik.uni-dortmund.de  Fri Mar  2 16:37:57 2007
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 02 Mar 2007 16:37:57 +0100
Subject: [Rd] Install.packages() bug in Windows XP (PR#9540)
In-Reply-To: <20070302105201.4595C5D614@slim.kubism.ku.dk>
References: <20070302105201.4595C5D614@slim.kubism.ku.dk>
Message-ID: <45E844D5.4010007@statistik.uni-dortmund.de>

This is not a bug.
And if a bug, you are asked to only report bugs of recent versions of R!
Please ask questions on R-help!

1. Please check your firewall and proxy settings.
2. Please upgrade to a recent version of R.

Uwe Ligges



juan at ufcengenharia.com.br wrote:
> Dear User=B4s,
> =20
> run R2.2.0 for Windows Version (S.O. Windows XP) when install.packages()
> function, after select the mirror, shown:
> --- Please select a CRAN mirror for use in this session ---
> Aviso: unable to access index for repository
> http://cran.br.r-project.org/bin/windows/contrib/2.2
> Aviso: unable to access index for repository
> http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/2.2
> Erro em install.packages() : argumento "pkgs" ausente, sem padr=E3o
> 
> Thanks,
> =20
> =20
> Eng=BA Juan S. Ramseyer.
> =20
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From sfalcon at fhcrc.org  Fri Mar  2 17:22:29 2007
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Fri, 02 Mar 2007 08:22:29 -0800
Subject: [Rd] S3 best practice
In-Reply-To: <5D78FE68-7F9C-4605-84E5-B7B91EB0BDB5@soc.soton.ac.uk> (Robin
	Hankin's message of "Fri, 2 Mar 2007 14:01:59 +0000")
References: <5D78FE68-7F9C-4605-84E5-B7B91EB0BDB5@soc.soton.ac.uk>
Message-ID: <m28xefaa4a.fsf@ziti.local>

Robin Hankin <r.hankin at noc.soton.ac.uk> writes:

> Hello everyone
>
> Suppose I have an S3 class "dog" and a function plot.dog() which
> looks like this:
>
> plot.dog <- function(x,show.uncertainty, ...){
>      <do a simple plot>
>    if (show.uncertainty){
>    <perform complicated combinatorial stuff that takes 20 minutes
>        and superimpose the results on the simple plot>
>    }
> }

How uncertain is the dog in the window?

> I think that it would be better to somehow precalculate the
> uncertainty stuff and plot it separately.
>
> How best to do this
> in the context of an S3 method for plot()?

Doing long computations within plot functions can be annoying because
often one needs to "tweak" the visual style of a plot and this
requires numerous round trips.  So I like your idea of precomputing
the uncertainty stuff.

uncertainty.dog could return data that could then optionally be passed
into the plot method.  Another possibility is that the dog "class"
could store the uncertainty data and then the plot method would plot
it if it is there (and/or if an option to plot is given).  In this
case, I guess it would be:  x <- addUncertainty(x)

+ seth


From gavin.simpson at ucl.ac.uk  Fri Mar  2 17:53:11 2007
From: gavin.simpson at ucl.ac.uk (gavin.simpson at ucl.ac.uk)
Date: Fri,  2 Mar 2007 17:53:11 +0100 (CET)
Subject: [Rd] Wishlist: Make screeplot() a generic (PR#9541)
Message-ID: <20070302165311.447935AD11@slim.kubism.ku.dk>

Full_Name: Gavin Simpson
Version: 2.5.0
OS: Linux (FC5)
Submission from: (NULL) (128.40.33.76)


Screeplots are a common plot-type used to interpret the results of various
ordination methods and other techniques. A number of packages include ordination
techniques not included in a standard R installation. screeplot() works for
princomp and prcomp objects, but not for these other techniques as it was not
designed to do so. The current situation means, for example, that I have called
a function Screeplot() in one of my packages, but it would be easier for users
if they only had to remember to use screeplot() to generate a screeplot.

I would like to request that screeplot be made generic and methods for prcomp
and princomp added to R devel. This way, package authors can provide screeplot
methods for their functions as appropriate.

I have taken a look at the sources for R devel (from the SVN repository) in file
princomp-add.R and prcomp.R and it looks a relatively simple change to make
screeplot generic.

I would be happy to provide patches and documentation if R Core were interested
in making this change - I haven't done this yet as I don't want to spend time
doing something that might not be acceptable to R core in general.

Many thanks,

G


From hpages at fhcrc.org  Fri Mar  2 19:39:37 2007
From: hpages at fhcrc.org (Herve Pages)
Date: Fri, 02 Mar 2007 10:39:37 -0800
Subject: [Rd] extracting rows from a data frame by looping over the row
 names: performance issues
Message-ID: <45E86F69.80507@fhcrc.org>

Hi,


I have a big data frame:

  > mat <- matrix(rep(paste(letters, collapse=""), 5*300000), ncol=5)
  > dat <- as.data.frame(mat)

and I need to do some computation on each row. Currently I'm doing this:

  > for (key in row.names(dat)) { row <- dat[key, ]; ... do some computation on row... }

which could probably considered a very natural (and R'ish) way of doing it
(but maybe I'm wrong and the real idiom for doing this is something different).

The problem with this "idiomatic form" is that it is _very_ slow. The loop
itself + the simple extraction of the rows (no computation on the rows) takes
10 hours on a powerful server (quad core Linux with 8G of RAM)!

Looping over the first 100 rows takes 12 seconds:

  > system.time(for (key in row.names(dat)[1:100]) { row <- dat[key, ] })
     user  system elapsed
   12.637   0.120  12.756

But if, instead of the above, I do this:

  > for (i in nrow(dat)) { row <- sapply(dat, function(col) col[i]) }

then it's 20 times faster!!

  > system.time(for (i in 1:100) { row <- sapply(dat, function(col) col[i]) })
     user  system elapsed
    0.576   0.096   0.673

I hope you will agree that this second form is much less natural.

So I was wondering why the "idiomatic form" is so slow? Shouldn't the idiomatic
form be, not only elegant and easy to read, but also efficient?


Thanks,
H.


> sessionInfo()
R version 2.5.0 Under development (unstable) (2007-01-05 r40386)
x86_64-unknown-linux-gnu

locale:
LC_CTYPE=en_US;LC_NUMERIC=C;LC_TIME=en_US;LC_COLLATE=en_US;LC_MONETARY=en_US;LC_MESSAGES=en_US;LC_PAPER=en_US;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=en_US;LC_IDENTIFICATION=C

attached base packages:
[1] "stats"     "graphics"  "grDevices" "utils"     "datasets"  "methods"
[7] "base"


From hpages at fhcrc.org  Fri Mar  2 20:03:07 2007
From: hpages at fhcrc.org (Herve Pages)
Date: Fri, 02 Mar 2007 11:03:07 -0800
Subject: [Rd] extracting rows from a data frame by looping over the row
 names: performance issues
In-Reply-To: <45E86F69.80507@fhcrc.org>
References: <45E86F69.80507@fhcrc.org>
Message-ID: <45E874EB.7010503@fhcrc.org>

Herve Pages wrote:
...
> But if, instead of the above, I do this:
> 
>   > for (i in nrow(dat)) { row <- sapply(dat, function(col) col[i]) }

Should have been:

  > for (i in 1:nrow(dat)) { row <- sapply(dat, function(col) col[i]) }

> 
> then it's 20 times faster!!
> 
>   > system.time(for (i in 1:100) { row <- sapply(dat, function(col) col[i]) })
>      user  system elapsed
>     0.576   0.096   0.673

...

Cheers,
H.


From rdpeng at gmail.com  Fri Mar  2 20:43:07 2007
From: rdpeng at gmail.com (Roger D. Peng)
Date: Fri, 02 Mar 2007 14:43:07 -0500
Subject: [Rd] extracting rows from a data frame by looping over the row
 names: performance issues
In-Reply-To: <45E86F69.80507@fhcrc.org>
References: <45E86F69.80507@fhcrc.org>
Message-ID: <45E87E4B.6070803@gmail.com>

Extracting rows from data frames is tricky, since each of the columns could be 
of a different class.  For your toy example, it seems a matrix would be a more 
reasonable option.

R-devel has some improvements to row extraction, if I remember correctly.  You 
might want to try your example there.

-roger

Herve Pages wrote:
> Hi,
> 
> 
> I have a big data frame:
> 
>   > mat <- matrix(rep(paste(letters, collapse=""), 5*300000), ncol=5)
>   > dat <- as.data.frame(mat)
> 
> and I need to do some computation on each row. Currently I'm doing this:
> 
>   > for (key in row.names(dat)) { row <- dat[key, ]; ... do some computation on row... }
> 
> which could probably considered a very natural (and R'ish) way of doing it
> (but maybe I'm wrong and the real idiom for doing this is something different).
> 
> The problem with this "idiomatic form" is that it is _very_ slow. The loop
> itself + the simple extraction of the rows (no computation on the rows) takes
> 10 hours on a powerful server (quad core Linux with 8G of RAM)!
> 
> Looping over the first 100 rows takes 12 seconds:
> 
>   > system.time(for (key in row.names(dat)[1:100]) { row <- dat[key, ] })
>      user  system elapsed
>    12.637   0.120  12.756
> 
> But if, instead of the above, I do this:
> 
>   > for (i in nrow(dat)) { row <- sapply(dat, function(col) col[i]) }
> 
> then it's 20 times faster!!
> 
>   > system.time(for (i in 1:100) { row <- sapply(dat, function(col) col[i]) })
>      user  system elapsed
>     0.576   0.096   0.673
> 
> I hope you will agree that this second form is much less natural.
> 
> So I was wondering why the "idiomatic form" is so slow? Shouldn't the idiomatic
> form be, not only elegant and easy to read, but also efficient?
> 
> 
> Thanks,
> H.
> 
> 
>> sessionInfo()
> R version 2.5.0 Under development (unstable) (2007-01-05 r40386)
> x86_64-unknown-linux-gnu
> 
> locale:
> LC_CTYPE=en_US;LC_NUMERIC=C;LC_TIME=en_US;LC_COLLATE=en_US;LC_MONETARY=en_US;LC_MESSAGES=en_US;LC_PAPER=en_US;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=en_US;LC_IDENTIFICATION=C
> 
> attached base packages:
> [1] "stats"     "graphics"  "grDevices" "utils"     "datasets"  "methods"
> [7] "base"
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 

-- 
Roger D. Peng  |  http://www.biostat.jhsph.edu/~rpeng/


From Greg.Snow at intermountainmail.org  Fri Mar  2 20:51:05 2007
From: Greg.Snow at intermountainmail.org (Greg Snow)
Date: Fri, 2 Mar 2007 12:51:05 -0700
Subject: [Rd] extracting rows from a data frame by looping over the row
 names: performance issues
In-Reply-To: <45E86F69.80507@fhcrc.org>
Message-ID: <07E228A5BE53C24CAD490193A7381BBB879882@LP-EXCHVS07.CO.IHC.COM>

Your 2 examples have 2 differences and they are therefore confounded in
their effects.

What are your results for:

system.time(for (i in 1:100) {row <-  dat[i, ] })



-- 
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at intermountainmail.org
(801) 408-8111
 
 

> -----Original Message-----
> From: r-devel-bounces at r-project.org 
> [mailto:r-devel-bounces at r-project.org] On Behalf Of Herve Pages
> Sent: Friday, March 02, 2007 11:40 AM
> To: r-devel at r-project.org
> Subject: [Rd] extracting rows from a data frame by looping 
> over the row names: performance issues
> 
> Hi,
> 
> 
> I have a big data frame:
> 
>   > mat <- matrix(rep(paste(letters, collapse=""), 5*300000), ncol=5)
>   > dat <- as.data.frame(mat)
> 
> and I need to do some computation on each row. Currently I'm 
> doing this:
> 
>   > for (key in row.names(dat)) { row <- dat[key, ]; ... do 
> some computation on row... }
> 
> which could probably considered a very natural (and R'ish) 
> way of doing it (but maybe I'm wrong and the real idiom for 
> doing this is something different).
> 
> The problem with this "idiomatic form" is that it is _very_ 
> slow. The loop itself + the simple extraction of the rows (no 
> computation on the rows) takes 10 hours on a powerful server 
> (quad core Linux with 8G of RAM)!
> 
> Looping over the first 100 rows takes 12 seconds:
> 
>   > system.time(for (key in row.names(dat)[1:100]) { row <- 
> dat[key, ] })
>      user  system elapsed
>    12.637   0.120  12.756
> 
> But if, instead of the above, I do this:
> 
>   > for (i in nrow(dat)) { row <- sapply(dat, function(col) col[i]) }
> 
> then it's 20 times faster!!
> 
>   > system.time(for (i in 1:100) { row <- sapply(dat, 
> function(col) col[i]) })
>      user  system elapsed
>     0.576   0.096   0.673
> 
> I hope you will agree that this second form is much less natural.
> 
> So I was wondering why the "idiomatic form" is so slow? 
> Shouldn't the idiomatic form be, not only elegant and easy to 
> read, but also efficient?
> 
> 
> Thanks,
> H.
> 
> 
> > sessionInfo()
> R version 2.5.0 Under development (unstable) (2007-01-05 
> r40386) x86_64-unknown-linux-gnu
> 
> locale:
> LC_CTYPE=en_US;LC_NUMERIC=C;LC_TIME=en_US;LC_COLLATE=en_US;LC_
> MONETARY=en_US;LC_MESSAGES=en_US;LC_PAPER=en_US;LC_NAME=C;LC_A
> DDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=en_US;LC_IDENTIFICATION=C
> 
> attached base packages:
> [1] "stats"     "graphics"  "grDevices" "utils"     
> "datasets"  "methods"
> [7] "base"
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From huber at ebi.ac.uk  Fri Mar  2 21:01:17 2007
From: huber at ebi.ac.uk (Wolfgang Huber)
Date: Fri, 02 Mar 2007 20:01:17 +0000
Subject: [Rd] extracting rows from a data frame by looping over the row
 names: performance issues
In-Reply-To: <45E87E4B.6070803@gmail.com>
References: <45E86F69.80507@fhcrc.org> <45E87E4B.6070803@gmail.com>
Message-ID: <45E8828D.1060200@ebi.ac.uk>


Hi Herv?

depending on your problem, using "mapply" might help, as in the code 
example below:

a = data.frame(matrix(1:3e4, ncol=3))

print(system.time({
r1 = numeric(nrow(a))
for(i in seq_len(nrow(a))) {
   g = a[i,]
   r1[i] = mean(c(g$X1, g$X2, g$X3))
}}))

print(system.time({
f = function(X1,X2,X3) mean(c(X1, X2, X3))
r2 = do.call("mapply", args=append(f, a))
}))

print(identical(r1, r2))

#   user  system elapsed
   6.049   0.200   6.987
    user  system elapsed
   0.508   0.000   0.509
[1] TRUE

  Best wishes
   Wolfgang

Roger D. Peng wrote:
> Extracting rows from data frames is tricky, since each of the columns could be 
> of a different class.  For your toy example, it seems a matrix would be a more 
> reasonable option.
> 
> R-devel has some improvements to row extraction, if I remember correctly.  You 
> might want to try your example there.
> 
> -roger
> 
> Herve Pages wrote:
>> Hi,
>>
>>
>> I have a big data frame:
>>
>>   > mat <- matrix(rep(paste(letters, collapse=""), 5*300000), ncol=5)
>>   > dat <- as.data.frame(mat)
>>
>> and I need to do some computation on each row. Currently I'm doing this:
>>
>>   > for (key in row.names(dat)) { row <- dat[key, ]; ... do some computation on row... }
>>
>> which could probably considered a very natural (and R'ish) way of doing it
>> (but maybe I'm wrong and the real idiom for doing this is something different).
>>
>> The problem with this "idiomatic form" is that it is _very_ slow. The loop
>> itself + the simple extraction of the rows (no computation on the rows) takes
>> 10 hours on a powerful server (quad core Linux with 8G of RAM)!
>>
>> Looping over the first 100 rows takes 12 seconds:
>>
>>   > system.time(for (key in row.names(dat)[1:100]) { row <- dat[key, ] })
>>      user  system elapsed
>>    12.637   0.120  12.756
>>
>> But if, instead of the above, I do this:
>>
>>   > for (i in nrow(dat)) { row <- sapply(dat, function(col) col[i]) }
>>
>> then it's 20 times faster!!
>>
>>   > system.time(for (i in 1:100) { row <- sapply(dat, function(col) col[i]) })
>>      user  system elapsed
>>     0.576   0.096   0.673
>>
>> I hope you will agree that this second form is much less natural.
>>
>> So I was wondering why the "idiomatic form" is so slow? Shouldn't the idiomatic
>> form be, not only elegant and easy to read, but also efficient?
>>
>>
>> Thanks,
>> H.
>>
>>
>>> sessionInfo()
>> R version 2.5.0 Under development (unstable) (2007-01-05 r40386)
>> x86_64-unknown-linux-gnu
>>
>> locale:
>> LC_CTYPE=en_US;LC_NUMERIC=C;LC_TIME=en_US;LC_COLLATE=en_US;LC_MONETARY=en_US;LC_MESSAGES=en_US;LC_PAPER=en_US;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=en_US;LC_IDENTIFICATION=C
>>
>> attached base packages:
>> [1] "stats"     "graphics"  "grDevices" "utils"     "datasets"  "methods"
>> [7] "base"
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
> 


-- 

Best wishes
   Wolfgang

------------------------------------------------------------------
Wolfgang Huber  EBI/EMBL  Cambridge UK  http://www.ebi.ac.uk/huber


From charles.dupont at vanderbilt.edu  Fri Mar  2 22:49:48 2007
From: charles.dupont at vanderbilt.edu (Charles Dupont)
Date: Fri, 02 Mar 2007 15:49:48 -0600
Subject: [Rd] Patch for format.pval limitation in format.R
Message-ID: <45E89BFC.4010901@vanderbilt.edu>

'format.pval' has a major limitation in its implementation for example
suppose a person had a vector like 'a' and the error being ?0.001.

     > a <- c(0.1, 0.3, 0.4, 0.5, 0.3, 0.0001)
     > format.pval(a, eps=0.001)

The person wants to have the 'format.pval' output with 2 digits always
showing like this

     [1] "0.10"   "0.30"   "0.40"   "0.50"   "0.30"   "<0.001"

How ever format.pval can only display this

     [1] "0.1"    "0.3"    "0.4"    "0.5"    "0.3"    "<0.001"

If this was the 'format' function this could be corrected by setting the
'nsmall' argument to 2.  But 'format.pval' has no ability to pass
arguments to format.


I think that the best solution would be to give 'format.pval' a '...'
argument that would get passed to all the 'format' function calls in
'format.pval'.

I have attached a patch that does this.  This patch is against svn
r-release-branch, but it also works with r-devel.


Charles Dupont
-- 
Charles Dupont	Computer System Analyst		School of Medicine
		Department of Biostatistics	Vanderbilt University

-------------- next part --------------
A non-text attachment was scrubbed...
Name: format.pval.patch
Type: text/x-diff
Size: 2009 bytes
Desc: not available
Url : https://stat.ethz.ch/pipermail/r-devel/attachments/20070302/04e94bd0/attachment.bin 

From hpages at fhcrc.org  Fri Mar  2 23:13:13 2007
From: hpages at fhcrc.org (Herve Pages)
Date: Fri, 02 Mar 2007 14:13:13 -0800
Subject: [Rd] extracting rows from a data frame by looping over the row
 names: performance issues
In-Reply-To: <45E87E4B.6070803@gmail.com>
References: <45E86F69.80507@fhcrc.org> <45E87E4B.6070803@gmail.com>
Message-ID: <45E8A179.4040804@fhcrc.org>

Roger D. Peng wrote:
> Extracting rows from data frames is tricky, since each of the columns
> could be of a different class.  For your toy example, it seems a matrix
> would be a more reasonable option.

There is no doubt about this ;-)

  > mat <- matrix(rep(paste(letters, collapse=""), 5*300000), ncol=5)
  > dat <- as.data.frame(mat)

With the matrix:

  > system.time(for (i in 1:100) { row <- mat[i, ] })
     user  system elapsed
        0       0       0

With the data frame:

  > system.time(for (key in row.names(dat)[1:100]) { row <- dat[key, ] })
     user  system elapsed
   12.565   0.296  12.859


And even with a mixed-type data frame, it's very tempting to convert it
to a matrix before to do any loop on it:

  > dat2 <- as.data.frame(mat, stringsAsFactors=FALSE)
  > dat2 <- cbind(dat2, ii=1:300000)
  > sapply(dat2, typeof)
           V1          V2          V3          V4          V5          ii
  "character" "character" "character" "character" "character"   "integer"

  > system.time(for (key in row.names(dat2)[1:100]) { row <- dat2[key, ] })
     user  system elapsed
   13.201   0.144  13.360

  > system.time({mat2 <- as.matrix(dat2); for (i in 1:100) { row <- mat2[i, ] }})
     user  system elapsed
    0.128   0.036   0.163

Big win isn't it? (only if you have enough memory for it though...)

Cheers,
H.



> 
> R-devel has some improvements to row extraction, if I remember
> correctly.  You might want to try your example there.
> 
> -roger
> 
> Herve Pages wrote:
>> Hi,
>>
>>
>> I have a big data frame:
>>
>>   > mat <- matrix(rep(paste(letters, collapse=""), 5*300000), ncol=5)
>>   > dat <- as.data.frame(mat)
>>
>> and I need to do some computation on each row. Currently I'm doing this:
>>
>>   > for (key in row.names(dat)) { row <- dat[key, ]; ... do some
>> computation on row... }
>>
>> which could probably considered a very natural (and R'ish) way of
>> doing it
>> (but maybe I'm wrong and the real idiom for doing this is something
>> different).
>>
>> The problem with this "idiomatic form" is that it is _very_ slow. The
>> loop
>> itself + the simple extraction of the rows (no computation on the
>> rows) takes
>> 10 hours on a powerful server (quad core Linux with 8G of RAM)!
>>
>> Looping over the first 100 rows takes 12 seconds:
>>
>>   > system.time(for (key in row.names(dat)[1:100]) { row <- dat[key, ] })
>>      user  system elapsed
>>    12.637   0.120  12.756
>>
>> But if, instead of the above, I do this:
>>
>>   > for (i in nrow(dat)) { row <- sapply(dat, function(col) col[i]) }
>>
>> then it's 20 times faster!!
>>
>>   > system.time(for (i in 1:100) { row <- sapply(dat, function(col)
>> col[i]) })
>>      user  system elapsed
>>     0.576   0.096   0.673
>>
>> I hope you will agree that this second form is much less natural.
>>
>> So I was wondering why the "idiomatic form" is so slow? Shouldn't the
>> idiomatic
>> form be, not only elegant and easy to read, but also efficient?
>>
>>
>> Thanks,
>> H.
>>
>>
>>> sessionInfo()
>> R version 2.5.0 Under development (unstable) (2007-01-05 r40386)
>> x86_64-unknown-linux-gnu
>>
>> locale:
>> LC_CTYPE=en_US;LC_NUMERIC=C;LC_TIME=en_US;LC_COLLATE=en_US;LC_MONETARY=en_US;LC_MESSAGES=en_US;LC_PAPER=en_US;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=en_US;LC_IDENTIFICATION=C
>>
>>
>> attached base packages:
>> [1] "stats"     "graphics"  "grDevices" "utils"     "datasets"  "methods"
>> [7] "base"
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>


From ulfmartin at web.de  Fri Mar  2 23:19:09 2007
From: ulfmartin at web.de (Ulf Martin)
Date: Fri, 02 Mar 2007 23:19:09 +0100
Subject: [Rd] extracting rows from a data frame by looping over the row
 names: performance issues
In-Reply-To: <45E8828D.1060200@ebi.ac.uk>
References: <45E86F69.80507@fhcrc.org> <45E87E4B.6070803@gmail.com>
	<45E8828D.1060200@ebi.ac.uk>
Message-ID: <45E8A2DD.8040205@web.de>

Here is an even faster one; the general point is to create a properly
vectorized custom function/expression:

mymean <- function(x, y, z) (x+y+z)/3

a = data.frame(matrix(1:3e4, ncol=3))
attach(a)
print(system.time({r3 = mymean(X1,X2,X3)}))
detach(a)

# Yields:
# [1] 0.000 0.010 0.005 0.000 0.000

print(identical(r2, r3))
# [1] TRUE

# May values for version 1 and 2 resp. were
# time for r1:
[1] 29.420 23.090 60.093  0.000  0.000

# time for r2:
[1] 1.400 0.050 1.505 0.000 0.000

Best wishes
Ulf


P.S. A somewhat more meaningful comparison of version 2 and 3:

a = data.frame(matrix(1:3e5, ncol=3))
# time r2e5:
[1] 12.04  0.15 12.92  0.00  0.00

# time r3e5:
[1] 0.030 0.020 0.051 0.000 0.000

> depending on your problem, using "mapply" might help, as in the code 
> example below:
> 
> a = data.frame(matrix(1:3e4, ncol=3))
> 
> print(system.time({
> r1 = numeric(nrow(a))
> for(i in seq_len(nrow(a))) {
>    g = a[i,]
>    r1[i] = mean(c(g$X1, g$X2, g$X3))
> }}))
> 
> print(system.time({
> f = function(X1,X2,X3) mean(c(X1, X2, X3))
> r2 = do.call("mapply", args=append(f, a))
> }))
> 
> print(identical(r1, r2))
> 
> #   user  system elapsed
>    6.049   0.200   6.987
>     user  system elapsed
>    0.508   0.000   0.509
> [1] TRUE
> 
>   Best wishes
>    Wolfgang
> 
> Roger D. Peng wrote:
>> Extracting rows from data frames is tricky, since each of the columns could be 
>> of a different class.  For your toy example, it seems a matrix would be a more 
>> reasonable option.
>>
>> R-devel has some improvements to row extraction, if I remember correctly.  You 
>> might want to try your example there.
>>
>> -roger
>>
>> Herve Pages wrote:
>>> Hi,
>>>
>>>
>>> I have a big data frame:
>>>
>>>   > mat <- matrix(rep(paste(letters, collapse=""), 5*300000), ncol=5)
>>>   > dat <- as.data.frame(mat)
>>>
>>> and I need to do some computation on each row. Currently I'm doing this:
>>>
>>>   > for (key in row.names(dat)) { row <- dat[key, ]; ... do some computation on row... }
>>>
>>> which could probably considered a very natural (and R'ish) way of doing it
>>> (but maybe I'm wrong and the real idiom for doing this is something different).
>>>
>>> The problem with this "idiomatic form" is that it is _very_ slow. The loop
>>> itself + the simple extraction of the rows (no computation on the rows) takes
>>> 10 hours on a powerful server (quad core Linux with 8G of RAM)!
>>>
>>> Looping over the first 100 rows takes 12 seconds:
>>>
>>>   > system.time(for (key in row.names(dat)[1:100]) { row <- dat[key, ] })
>>>      user  system elapsed
>>>    12.637   0.120  12.756
>>>
>>> But if, instead of the above, I do this:
>>>
>>>   > for (i in nrow(dat)) { row <- sapply(dat, function(col) col[i]) }
>>>
>>> then it's 20 times faster!!
>>>
>>>   > system.time(for (i in 1:100) { row <- sapply(dat, function(col) col[i]) })
>>>      user  system elapsed
>>>     0.576   0.096   0.673
>>>
>>> I hope you will agree that this second form is much less natural.
>>>
>>> So I was wondering why the "idiomatic form" is so slow? Shouldn't the idiomatic
>>> form be, not only elegant and easy to read, but also efficient?
>>>
>>>
>>> Thanks,
>>> H.
>>>
>>>
>>>> sessionInfo()
>>> R version 2.5.0 Under development (unstable) (2007-01-05 r40386)
>>> x86_64-unknown-linux-gnu
>>>
>>> locale:
>>> LC_CTYPE=en_US;LC_NUMERIC=C;LC_TIME=en_US;LC_COLLATE=en_US;LC_MONETARY=en_US;LC_MESSAGES=en_US;LC_PAPER=en_US;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=en_US;LC_IDENTIFICATION=C
>>>
>>> attached base packages:
>>> [1] "stats"     "graphics"  "grDevices" "utils"     "datasets"  "methods"
>>> [7] "base"
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
> 
>


From hpages at fhcrc.org  Fri Mar  2 23:51:53 2007
From: hpages at fhcrc.org (Herve Pages)
Date: Fri, 02 Mar 2007 14:51:53 -0800
Subject: [Rd] extracting rows from a data frame by looping over the row
 names: performance issues
In-Reply-To: <45E8A2DD.8040205@web.de>
References: <45E86F69.80507@fhcrc.org>
	<45E87E4B.6070803@gmail.com>	<45E8828D.1060200@ebi.ac.uk>
	<45E8A2DD.8040205@web.de>
Message-ID: <45E8AA89.3020401@fhcrc.org>

Ulf Martin wrote:
> Here is an even faster one; the general point is to create a properly
> vectorized custom function/expression:
> 
> mymean <- function(x, y, z) (x+y+z)/3
> 
> a = data.frame(matrix(1:3e4, ncol=3))
> attach(a)
> print(system.time({r3 = mymean(X1,X2,X3)}))
> detach(a)
> 
> # Yields:
> # [1] 0.000 0.010 0.005 0.000 0.000
> 

Very fast indeed! And you don't need the attach/detach trick to make your point
since it is (almost) as fast without it:

  a = data.frame(matrix(1:3e4, ncol=3))
  print(system.time({r3 = mymean(a$X1,a$X2,a$X3)}))

However, you are lucky here because in this example (the "mean" example), you can
use vectorized arithmetic which is of course very fast.
What about the general case? Unfortunately situations where you can "properly vectorize"
tend to be much more frequent in tutorials and demos than in the real world.
Maybe the "mean" example is a little bit too specific to answer the
general question of "what's the best way to _efficiently_ step on a data
frame row by row".

Cheers,
H.



> print(identical(r2, r3))
> # [1] TRUE
> 
> # May values for version 1 and 2 resp. were
> # time for r1:
> [1] 29.420 23.090 60.093  0.000  0.000
> 
> # time for r2:
> [1] 1.400 0.050 1.505 0.000 0.000
> 
> Best wishes
> Ulf
> 
> 
> P.S. A somewhat more meaningful comparison of version 2 and 3:
> 
> a = data.frame(matrix(1:3e5, ncol=3))
> # time r2e5:
> [1] 12.04  0.15 12.92  0.00  0.00
> 
> # time r3e5:
> [1] 0.030 0.020 0.051 0.000 0.000
> 
>> depending on your problem, using "mapply" might help, as in the code 
>> example below:
>>
>> a = data.frame(matrix(1:3e4, ncol=3))
>>
>> print(system.time({
>> r1 = numeric(nrow(a))
>> for(i in seq_len(nrow(a))) {
>>    g = a[i,]
>>    r1[i] = mean(c(g$X1, g$X2, g$X3))
>> }}))
>>
>> print(system.time({
>> f = function(X1,X2,X3) mean(c(X1, X2, X3))
>> r2 = do.call("mapply", args=append(f, a))
>> }))
>>
>> print(identical(r1, r2))
>>
>> #   user  system elapsed
>>    6.049   0.200   6.987
>>     user  system elapsed
>>    0.508   0.000   0.509
>> [1] TRUE
>>
>>   Best wishes
>>    Wolfgang
>>
>> Roger D. Peng wrote:
>>> Extracting rows from data frames is tricky, since each of the columns could be 
>>> of a different class.  For your toy example, it seems a matrix would be a more 
>>> reasonable option.
>>>
>>> R-devel has some improvements to row extraction, if I remember correctly.  You 
>>> might want to try your example there.
>>>
>>> -roger
>>>
>>> Herve Pages wrote:
>>>> Hi,
>>>>
>>>>
>>>> I have a big data frame:
>>>>
>>>>   > mat <- matrix(rep(paste(letters, collapse=""), 5*300000), ncol=5)
>>>>   > dat <- as.data.frame(mat)
>>>>
>>>> and I need to do some computation on each row. Currently I'm doing this:
>>>>
>>>>   > for (key in row.names(dat)) { row <- dat[key, ]; ... do some computation on row... }
>>>>
>>>> which could probably considered a very natural (and R'ish) way of doing it
>>>> (but maybe I'm wrong and the real idiom for doing this is something different).
>>>>
>>>> The problem with this "idiomatic form" is that it is _very_ slow. The loop
>>>> itself + the simple extraction of the rows (no computation on the rows) takes
>>>> 10 hours on a powerful server (quad core Linux with 8G of RAM)!
>>>>
>>>> Looping over the first 100 rows takes 12 seconds:
>>>>
>>>>   > system.time(for (key in row.names(dat)[1:100]) { row <- dat[key, ] })
>>>>      user  system elapsed
>>>>    12.637   0.120  12.756
>>>>
>>>> But if, instead of the above, I do this:
>>>>
>>>>   > for (i in nrow(dat)) { row <- sapply(dat, function(col) col[i]) }
>>>>
>>>> then it's 20 times faster!!
>>>>
>>>>   > system.time(for (i in 1:100) { row <- sapply(dat, function(col) col[i]) })
>>>>      user  system elapsed
>>>>     0.576   0.096   0.673
>>>>
>>>> I hope you will agree that this second form is much less natural.
>>>>
>>>> So I was wondering why the "idiomatic form" is so slow? Shouldn't the idiomatic
>>>> form be, not only elegant and easy to read, but also efficient?
>>>>
>>>>
>>>> Thanks,
>>>> H.
>>>>
>>>>
>>>>> sessionInfo()
>>>> R version 2.5.0 Under development (unstable) (2007-01-05 r40386)
>>>> x86_64-unknown-linux-gnu
>>>>
>>>> locale:
>>>> LC_CTYPE=en_US;LC_NUMERIC=C;LC_TIME=en_US;LC_COLLATE=en_US;LC_MONETARY=en_US;LC_MESSAGES=en_US;LC_PAPER=en_US;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=en_US;LC_IDENTIFICATION=C
>>>>
>>>> attached base packages:
>>>> [1] "stats"     "graphics"  "grDevices" "utils"     "datasets"  "methods"
>>>> [7] "base"
>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>
>>
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From hpages at fhcrc.org  Sat Mar  3 00:23:27 2007
From: hpages at fhcrc.org (Herve Pages)
Date: Fri, 02 Mar 2007 15:23:27 -0800
Subject: [Rd] extracting rows from a data frame by looping over the row
 names: performance issues
In-Reply-To: <45E8828D.1060200@ebi.ac.uk>
References: <45E86F69.80507@fhcrc.org> <45E87E4B.6070803@gmail.com>
	<45E8828D.1060200@ebi.ac.uk>
Message-ID: <45E8B1EF.9020608@fhcrc.org>

Hi Wolfgang,


Wolfgang Huber wrote:
> 
> Hi Herv?
> 
> depending on your problem, using "mapply" might help, as in the code
> example below:
> 
> a = data.frame(matrix(1:3e4, ncol=3))
> 
> print(system.time({
> r1 = numeric(nrow(a))
> for(i in seq_len(nrow(a))) {
>   g = a[i,]
>   r1[i] = mean(c(g$X1, g$X2, g$X3))
> }}))
> 
> print(system.time({
> f = function(X1,X2,X3) mean(c(X1, X2, X3))
> r2 = do.call("mapply", args=append(f, a))
> }))
> 
> print(identical(r1, r2))
> 
> #   user  system elapsed
>   6.049   0.200   6.987
>    user  system elapsed
>   0.508   0.000   0.509
> [1] TRUE

Thanks for the tip! It's good to know about the mapply function (which I just
realize is mentioned in the "See Also" section of the lapply man page).

Cheers,
H.


> 
>  Best wishes
>   Wolfgang
> 
> Roger D. Peng wrote:
>> Extracting rows from data frames is tricky, since each of the columns
>> could be of a different class.  For your toy example, it seems a
>> matrix would be a more reasonable option.
>>
>> R-devel has some improvements to row extraction, if I remember
>> correctly.  You might want to try your example there.
>>
>> -roger
>>
>> Herve Pages wrote:
>>> Hi,
>>>
>>>
>>> I have a big data frame:
>>>
>>>   > mat <- matrix(rep(paste(letters, collapse=""), 5*300000), ncol=5)
>>>   > dat <- as.data.frame(mat)
>>>
>>> and I need to do some computation on each row. Currently I'm doing this:
>>>
>>>   > for (key in row.names(dat)) { row <- dat[key, ]; ... do some
>>> computation on row... }
>>>
>>> which could probably considered a very natural (and R'ish) way of
>>> doing it
>>> (but maybe I'm wrong and the real idiom for doing this is something
>>> different).
>>>
>>> The problem with this "idiomatic form" is that it is _very_ slow. The
>>> loop
>>> itself + the simple extraction of the rows (no computation on the
>>> rows) takes
>>> 10 hours on a powerful server (quad core Linux with 8G of RAM)!
>>>
>>> Looping over the first 100 rows takes 12 seconds:
>>>
>>>   > system.time(for (key in row.names(dat)[1:100]) { row <- dat[key,
>>> ] })
>>>      user  system elapsed
>>>    12.637   0.120  12.756
>>>
>>> But if, instead of the above, I do this:
>>>
>>>   > for (i in nrow(dat)) { row <- sapply(dat, function(col) col[i]) }
>>>
>>> then it's 20 times faster!!
>>>
>>>   > system.time(for (i in 1:100) { row <- sapply(dat, function(col)
>>> col[i]) })
>>>      user  system elapsed
>>>     0.576   0.096   0.673
>>>
>>> I hope you will agree that this second form is much less natural.
>>>
>>> So I was wondering why the "idiomatic form" is so slow? Shouldn't the
>>> idiomatic
>>> form be, not only elegant and easy to read, but also efficient?
>>>
>>>
>>> Thanks,
>>> H.
>>>
>>>
>>>> sessionInfo()
>>> R version 2.5.0 Under development (unstable) (2007-01-05 r40386)
>>> x86_64-unknown-linux-gnu
>>>
>>> locale:
>>> LC_CTYPE=en_US;LC_NUMERIC=C;LC_TIME=en_US;LC_COLLATE=en_US;LC_MONETARY=en_US;LC_MESSAGES=en_US;LC_PAPER=en_US;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=en_US;LC_IDENTIFICATION=C
>>>
>>>
>>> attached base packages:
>>> [1] "stats"     "graphics"  "grDevices" "utils"     "datasets" 
>>> "methods"
>>> [7] "base"
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>
> 
>


From hpages at fhcrc.org  Sat Mar  3 03:03:57 2007
From: hpages at fhcrc.org (Herve Pages)
Date: Fri, 02 Mar 2007 18:03:57 -0800
Subject: [Rd] extracting rows from a data frame by looping over the row
 names: performance issues
In-Reply-To: <07E228A5BE53C24CAD490193A7381BBB879882@LP-EXCHVS07.CO.IHC.COM>
References: <07E228A5BE53C24CAD490193A7381BBB879882@LP-EXCHVS07.CO.IHC.COM>
Message-ID: <45E8D78D.20003@fhcrc.org>

Hi Greg,

Greg Snow wrote:
> Your 2 examples have 2 differences and they are therefore confounded in
> their effects.
> 
> What are your results for:
> 
> system.time(for (i in 1:100) {row <-  dat[i, ] })
> 
> 
> 

Right. What you suggest is even faster (and more simple):

  > mat <- matrix(rep(paste(letters, collapse=""), 5*300000), ncol=5)
  > dat <- as.data.frame(mat)

  > system.time(for (key in row.names(dat)[1:100]) { row <- dat[key, ] })
     user  system elapsed
   13.241   0.460  13.702

  > system.time(for (i in 1:100) { row <- sapply(dat, function(col) col[i]) })
     user  system elapsed
    0.280   0.372   0.650

  > system.time(for (i in 1:100) {row <-  dat[i, ] })
     user  system elapsed
    0.044   0.088   0.130

So apparently here extracting with dat[i, ] is 300 times faster than
extracting with dat[key, ] !

> system.time(for (i in 1:100) dat["1", ])
   user  system elapsed
 12.680   0.396  13.075

> system.time(for (i in 1:100) dat[1, ])
   user  system elapsed
  0.060   0.076   0.137

Good to know!

Thanks a lot,
H.


From sfalcon at fhcrc.org  Sat Mar  3 06:48:15 2007
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Fri, 02 Mar 2007 21:48:15 -0800
Subject: [Rd] extracting rows from a data frame by looping over the row
	names: performance issues
In-Reply-To: <45E8D78D.20003@fhcrc.org> (Herve Pages's message of "Fri,
	02 Mar 2007 18:03:57 -0800")
References: <07E228A5BE53C24CAD490193A7381BBB879882@LP-EXCHVS07.CO.IHC.COM>
	<45E8D78D.20003@fhcrc.org>
Message-ID: <m27ity98tc.fsf@ziti.local>

Herve Pages <hpages at fhcrc.org> writes:
> So apparently here extracting with dat[i, ] is 300 times faster than
> extracting with dat[key, ] !
>
>> system.time(for (i in 1:100) dat["1", ])
>    user  system elapsed
>  12.680   0.396  13.075
>
>> system.time(for (i in 1:100) dat[1, ])
>    user  system elapsed
>   0.060   0.076   0.137
>
> Good to know!

I think what you are seeing here has to do with the space efficient
storage of row.names of a data.frame.  The example data you are
working with has no specified row names and so they get stored in a
compact fashion:

    mat <- matrix(rep(paste(letters, collapse=""), 5*300000), ncol=5)
    dat <- as.data.frame(mat)
    
    > typeof(attr(dat, "row.names"))
    [1] "integer"

In the call to [.data.frame when i is character, the appropriate index
is found using pmatch and this requires that the row names be
converted to character.  So in a loop, you get to convert the integer
vector to character vector at each iteration.

If you assign character row names, things will be a bit faster:

    # before
    system.time(for (i in 1:25) dat["2", ])
       user  system elapsed 
      9.337   0.404  10.731 
    
    # this looks funny, but has the desired result
    rownames(dat) <- rownames(dat)
    typeof(attr(dat, "row.names")
    
    # after
    system.time(for (i in 1:25) dat["2", ])
       user  system elapsed 
      0.343   0.226   0.608 

And you probably would have seen this if you had looked at the the
profiling data:

    Rprof()
    for (i in 1:25) dat["2", ]
    Rprof(NULL)
    summaryRprof()


+ seth


From hpages at fhcrc.org  Sat Mar  3 09:22:23 2007
From: hpages at fhcrc.org (hpages at fhcrc.org)
Date: Sat,  3 Mar 2007 00:22:23 -0800
Subject: [Rd] extracting rows from a data frame by looping over the
	row	names: performance issues
In-Reply-To: <m27ity98tc.fsf@ziti.local>
References: <07E228A5BE53C24CAD490193A7381BBB879882@LP-EXCHVS07.CO.IHC.COM>
	<45E8D78D.20003@fhcrc.org> <m27ity98tc.fsf@ziti.local>
Message-ID: <1172910143.45e9303fea61d@webmail.fhcrc.org>

Hi Seth,

Quoting Seth Falcon <sfalcon at fhcrc.org>:

> Herve Pages <hpages at fhcrc.org> writes:
> > So apparently here extracting with dat[i, ] is 300 times faster than
> > extracting with dat[key, ] !
> >
> >> system.time(for (i in 1:100) dat["1", ])
> >    user  system elapsed
> >  12.680   0.396  13.075
> >
> >> system.time(for (i in 1:100) dat[1, ])
> >    user  system elapsed
> >   0.060   0.076   0.137
> >
> > Good to know!
> 
> I think what you are seeing here has to do with the space efficient
> storage of row.names of a data.frame.  The example data you are
> working with has no specified row names and so they get stored in a
> compact fashion:
> 
>     mat <- matrix(rep(paste(letters, collapse=""), 5*300000), ncol=5)
>     dat <- as.data.frame(mat)
>     
>     > typeof(attr(dat, "row.names"))
>     [1] "integer"
> 
> In the call to [.data.frame when i is character, the appropriate index
> is found using pmatch and this requires that the row names be
> converted to character.  So in a loop, you get to convert the integer
> vector to character vector at each iteration.

Maybe this could be avoided. Why do you need to call pmath when
the row names are integer?

In [.data.frame if you replace this:

    ...
    if (is.character(i)) {
        rows <- attr(xx, "row.names")
        i <- pmatch(i, rows, duplicates.ok = TRUE)
    }
    ...

by this

    ...
    if (is.character(i)) {
        rows <- attr(xx, "row.names")
        if (typeof(rows) == "integer")
            i <- as.integer(i)
        else
            i <- pmatch(i, rows, duplicates.ok = TRUE)
    }
    ...

then you get a huge boost:

  - with current [.data.frame
    > system.time(for (i in 1:100) dat["1", ])
       user  system elapsed
     34.994   1.084  37.915

  - with "patched" [.data.frame
    > system.time(for (i in 1:100) dat["1", ])
       user  system elapsed
      0.264   0.068   0.364

but maybe I'm missing somethig...

Cheers,
H.

> 
> If you assign character row names, things will be a bit faster:
> 
>     # before
>     system.time(for (i in 1:25) dat["2", ])
>        user  system elapsed 
>       9.337   0.404  10.731 
>     
>     # this looks funny, but has the desired result
>     rownames(dat) <- rownames(dat)
>     typeof(attr(dat, "row.names")
>     
>     # after
>     system.time(for (i in 1:25) dat["2", ])
>        user  system elapsed 
>       0.343   0.226   0.608 
> 
> And you probably would have seen this if you had looked at the the
> profiling data:
> 
>     Rprof()
>     for (i in 1:25) dat["2", ]
>     Rprof(NULL)
>     summaryRprof()
> 
> 
> + seth
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From hpages at fhcrc.org  Sat Mar  3 18:28:22 2007
From: hpages at fhcrc.org (hpages at fhcrc.org)
Date: Sat,  3 Mar 2007 09:28:22 -0800
Subject: [Rd] extracting rows from a data frame by looping over
	the	row	names: performance issues
In-Reply-To: <1172910143.45e9303fea61d@webmail.fhcrc.org>
References: <07E228A5BE53C24CAD490193A7381BBB879882@LP-EXCHVS07.CO.IHC.COM>
	<45E8D78D.20003@fhcrc.org> <m27ity98tc.fsf@ziti.local>
	<1172910143.45e9303fea61d@webmail.fhcrc.org>
Message-ID: <1172942902.45e9b0369780c@webmail.fhcrc.org>

Quoting hpages at fhcrc.org:
> In [.data.frame if you replace this:
> 
>     ...
>     if (is.character(i)) {
>         rows <- attr(xx, "row.names")
>         i <- pmatch(i, rows, duplicates.ok = TRUE)
>     }
>     ...
> 
> by this
> 
>     ...
>     if (is.character(i)) {
>         rows <- attr(xx, "row.names")
>         if (typeof(rows) == "integer")
>             i <- as.integer(i)
>         else
>             i <- pmatch(i, rows, duplicates.ok = TRUE)
>     }
>     ...
> 
> then you get a huge boost:
> 
>   - with current [.data.frame
>     > system.time(for (i in 1:100) dat["1", ])
>        user  system elapsed
>      34.994   1.084  37.915
> 
>   - with "patched" [.data.frame
>     > system.time(for (i in 1:100) dat["1", ])
>        user  system elapsed
>       0.264   0.068   0.364
> 

mmmh, replacing
    i <- pmatch(i, rows, duplicates.ok = TRUE)
by just
    i <- as.integer(i)
was a bit naive. It will be wrong if rows is not a "seq_len" sequence.

So I need to be more carefull by first calling 'match' to find the exact
matches and then calling 'pmatch' _only_ on those indices that don't have
an exact match. For example like doing something like this:

    if (is.character(i)) {
        rows <- attr(xx, "row.names")
        if (typeof(rows) == "integer") {
            i2 <- match(as.integer(i), rows)
            if (any(is.na(i2)))
                i2[is.na(i2)] <- pmatch(i[is.na(i2)], rows, duplicates.ok =
TRUE)
            i <- i2
        } else {
            i <- pmatch(i, rows, duplicates.ok = TRUE)
        }
    }

Correctness:

  > dat2 <- data.frame(aa=c('a', 'b', 'c', 'd'), bb=1:4,
                       row.names=c(11,25,1,3))
  > dat2
     aa bb
  11  a  1
  25  b  2
  1   c  3
  3   d  4

  > dat2["1",]
    aa bb
  1  c  3

  > dat2["3",]
    aa bb
  3  d  4

  > dat2["2",]
     aa bb
  25  b  2

Performance:

  > mat <- matrix(rep(paste(letters, collapse=""), 5*300000), ncol=5)
  > dat <- as.data.frame(mat)
  > system.time(for (i in 1:100) dat["1", ])
     user  system elapsed
    2.036   0.880   2.917

Still 17 times faster than with non-patched [.data.frame.

Maybe 'pmatch(x, table, ...)' itself could be improved to be
more efficient when 'x' is a character vector and 'table' an
integer vector so the above trick is not needed anymore.

My point is that something can probably be done to improve the
performance of 'dat[i, ]' when the row names are integer and 'i'
a character vector. I'm assuming that, in the typical use-case,
there is an exact match for 'i' in the row names so converting
those row names to a character vector in order to find this match
is (most of the time) a waste of time.

Cheers,
H.


> but maybe I'm missing somethig...
> 
> Cheers,
> H.
> 
> > 
> > If you assign character row names, things will be a bit faster:
> > 
> >     # before
> >     system.time(for (i in 1:25) dat["2", ])
> >        user  system elapsed 
> >       9.337   0.404  10.731 
> >     
> >     # this looks funny, but has the desired result
> >     rownames(dat) <- rownames(dat)
> >     typeof(attr(dat, "row.names")
> >     
> >     # after
> >     system.time(for (i in 1:25) dat["2", ])
> >        user  system elapsed 
> >       0.343   0.226   0.608 
> > 
> > And you probably would have seen this if you had looked at the the
> > profiling data:
> > 
> >     Rprof()
> >     for (i in 1:25) dat["2", ]
> >     Rprof(NULL)
> >     summaryRprof()
> > 
> > 
> > + seth
> > 
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From h.wickham at gmail.com  Sat Mar  3 20:13:07 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Sat, 3 Mar 2007 13:13:07 -0600
Subject: [Rd] extracting rows from a data frame by looping over the row
	names: performance issues
In-Reply-To: <1172942902.45e9b0369780c@webmail.fhcrc.org>
References: <07E228A5BE53C24CAD490193A7381BBB879882@LP-EXCHVS07.CO.IHC.COM>
	<45E8D78D.20003@fhcrc.org> <m27ity98tc.fsf@ziti.local>
	<1172910143.45e9303fea61d@webmail.fhcrc.org>
	<1172942902.45e9b0369780c@webmail.fhcrc.org>
Message-ID: <f8e6ff050703031113m6643ee43w3655dd2d8570a3ae@mail.gmail.com>

On 3/3/07, hpages at fhcrc.org <hpages at fhcrc.org> wrote:
> Quoting hpages at fhcrc.org:
> > In [.data.frame if you replace this:
> >
> >     ...
> >     if (is.character(i)) {
> >         rows <- attr(xx, "row.names")
> >         i <- pmatch(i, rows, duplicates.ok = TRUE)
> >     }
> >     ...
> >
> > by this
> >
> >     ...
> >     if (is.character(i)) {
> >         rows <- attr(xx, "row.names")
> >         if (typeof(rows) == "integer")
> >             i <- as.integer(i)
> >         else
> >             i <- pmatch(i, rows, duplicates.ok = TRUE)
> >     }
> >     ...
> >
> > then you get a huge boost:
> >
> >   - with current [.data.frame
> >     > system.time(for (i in 1:100) dat["1", ])
> >        user  system elapsed
> >      34.994   1.084  37.915
> >
> >   - with "patched" [.data.frame
> >     > system.time(for (i in 1:100) dat["1", ])
> >        user  system elapsed
> >       0.264   0.068   0.364
> >
>
> mmmh, replacing
>     i <- pmatch(i, rows, duplicates.ok = TRUE)
> by just
>     i <- as.integer(i)
> was a bit naive. It will be wrong if rows is not a "seq_len" sequence.
>
> So I need to be more carefull by first calling 'match' to find the exact
> matches and then calling 'pmatch' _only_ on those indices that don't have
> an exact match. For example like doing something like this:
>
>     if (is.character(i)) {
>         rows <- attr(xx, "row.names")
>         if (typeof(rows) == "integer") {
>             i2 <- match(as.integer(i), rows)
>             if (any(is.na(i2)))
>                 i2[is.na(i2)] <- pmatch(i[is.na(i2)], rows, duplicates.ok =
> TRUE)
>             i <- i2
>         } else {
>             i <- pmatch(i, rows, duplicates.ok = TRUE)
>         }
>     }
>
> Correctness:
>
>   > dat2 <- data.frame(aa=c('a', 'b', 'c', 'd'), bb=1:4,
>                        row.names=c(11,25,1,3))
>   > dat2
>      aa bb
>   11  a  1
>   25  b  2
>   1   c  3
>   3   d  4
>
>   > dat2["1",]
>     aa bb
>   1  c  3
>
>   > dat2["3",]
>     aa bb
>   3  d  4
>
>   > dat2["2",]
>      aa bb
>   25  b  2
>
> Performance:
>
>   > mat <- matrix(rep(paste(letters, collapse=""), 5*300000), ncol=5)
>   > dat <- as.data.frame(mat)
>   > system.time(for (i in 1:100) dat["1", ])
>      user  system elapsed
>     2.036   0.880   2.917
>
> Still 17 times faster than with non-patched [.data.frame.
>
> Maybe 'pmatch(x, table, ...)' itself could be improved to be
> more efficient when 'x' is a character vector and 'table' an
> integer vector so the above trick is not needed anymore.
>
> My point is that something can probably be done to improve the
> performance of 'dat[i, ]' when the row names are integer and 'i'
> a character vector. I'm assuming that, in the typical use-case,
> there is an exact match for 'i' in the row names so converting
> those row names to a character vector in order to find this match
> is (most of the time) a waste of time.

But why bother?  If you know the index of the row, why not index with
a numeric vector rather than a string?  The behaviour in that case
seems obvious and fast.

Hadley


From gregor.gorjanc at bfro.uni-lj.si  Sat Mar  3 21:42:52 2007
From: gregor.gorjanc at bfro.uni-lj.si (Gregor Gorjanc)
Date: Sat, 03 Mar 2007 21:42:52 +0100
Subject: [Rd] Segmentation fault on bin/R --version in R-devel
Message-ID: <45E9DDCC.7040705@bfro.uni-lj.si>

Hello!

I have tried to build and install latest version of R, but I am not able
to perform the install, due to seg. fault. I did the following after SVN
checkout and wget for recommendeds:

./configure --prefix=/usr/local/R-devel
make
make install

...
...
  tcut                              text    html    latex   example
  tobin                             text    html    latex   example
  untangle.specials                 text    html    latex   example
  veteran                           text    html    latex
** building package indices ...
* DONE (survival)
make[2]: Leaving directory
`/home/share/projectSoft/R/R/src/library/Recommended'
make[1]: Leaving directory
`/home/share/projectSoft/R/R/src/library/Recommended'
make[1]: Entering directory `/home/share/projectSoft/R/R/doc/manual'
make[1]: Nothing to be done for `front-matter'.
make[1]: Nothing to be done for `html-non-svn'.
make[1]: Leaving directory `/home/share/projectSoft/R/R/doc/manual'
SVN-REVISION is unchanged
make[1]: Entering directory `/home/share/projectSoft/R/R/m4'
make[1]: Nothing to be done for `install'.
make[1]: Leaving directory `/home/share/projectSoft/R/R/m4'
make[1]: Entering directory `/home/share/projectSoft/R/R/tools'
make[1]: Nothing to be done for `install'.
make[1]: Leaving directory `/home/share/projectSoft/R/R/tools'
make[1]: Entering directory `/home/share/projectSoft/R/R/doc'
installing doc ...
/usr/bin/install -c -m 644 ../NEWS "/usr/local/R-devel/lib/R/doc"
sh: line 1: 15129 Segmentation fault      ../bin/R --version 2>/dev/null
help2man: can't get `--version' info from ../bin/R
make[1]: *** [R.1] Error 139
make[1]: Leaving directory `/home/share/projectSoft/R/R/doc'
make: *** [install] Error 1

gcc --version
gcc (GCC) 4.1.2 20061115 (prerelease) (Debian 4.1.1-21)
Copyright (C) 2006 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.

As can be seen I have Debian GNU/Linux.
Any clues?

Thank you!

Gregor


From hpages at fhcrc.org  Sun Mar  4 01:03:07 2007
From: hpages at fhcrc.org (hpages at fhcrc.org)
Date: Sat,  3 Mar 2007 16:03:07 -0800
Subject: [Rd] extracting rows from a data frame by looping over the row
	names: performance issues
In-Reply-To: <f8e6ff050703031113m6643ee43w3655dd2d8570a3ae@mail.gmail.com>
References: <07E228A5BE53C24CAD490193A7381BBB879882@LP-EXCHVS07.CO.IHC.COM>
	<45E8D78D.20003@fhcrc.org> <m27ity98tc.fsf@ziti.local>
	<1172910143.45e9303fea61d@webmail.fhcrc.org>
	<1172942902.45e9b0369780c@webmail.fhcrc.org>
	<f8e6ff050703031113m6643ee43w3655dd2d8570a3ae@mail.gmail.com>
Message-ID: <1172966587.45ea0cbb2b147@webmail.fhcrc.org>

Quoting hadley wickham <h.wickham at gmail.com>:

> On 3/3/07, hpages at fhcrc.org <hpages at fhcrc.org> wrote:
> > Quoting hpages at fhcrc.org:
> > > In [.data.frame if you replace this:
> > >
> > >     ...
> > >     if (is.character(i)) {
> > >         rows <- attr(xx, "row.names")
> > >         i <- pmatch(i, rows, duplicates.ok = TRUE)
> > >     }
> > >     ...
> > >
> > > by this
> > >
> > >     ...
> > >     if (is.character(i)) {
> > >         rows <- attr(xx, "row.names")
> > >         if (typeof(rows) == "integer")
> > >             i <- as.integer(i)
> > >         else
> > >             i <- pmatch(i, rows, duplicates.ok = TRUE)
> > >     }
> > >     ...
> > >
> > > then you get a huge boost:
> > >
> > >   - with current [.data.frame
> > >     > system.time(for (i in 1:100) dat["1", ])
> > >        user  system elapsed
> > >      34.994   1.084  37.915
> > >
> > >   - with "patched" [.data.frame
> > >     > system.time(for (i in 1:100) dat["1", ])
> > >        user  system elapsed
> > >       0.264   0.068   0.364
> > >
> >
> > mmmh, replacing
> >     i <- pmatch(i, rows, duplicates.ok = TRUE)
> > by just
> >     i <- as.integer(i)
> > was a bit naive. It will be wrong if rows is not a "seq_len" sequence.
> >
> > So I need to be more carefull by first calling 'match' to find the exact
> > matches and then calling 'pmatch' _only_ on those indices that don't have
> > an exact match. For example like doing something like this:
> >
> >     if (is.character(i)) {
> >         rows <- attr(xx, "row.names")
> >         if (typeof(rows) == "integer") {
> >             i2 <- match(as.integer(i), rows)
> >             if (any(is.na(i2)))
> >                 i2[is.na(i2)] <- pmatch(i[is.na(i2)], rows, duplicates.ok
> =
> > TRUE)
> >             i <- i2
> >         } else {
> >             i <- pmatch(i, rows, duplicates.ok = TRUE)
> >         }
> >     }
> >
> > Correctness:
> >
> >   > dat2 <- data.frame(aa=c('a', 'b', 'c', 'd'), bb=1:4,
> >                        row.names=c(11,25,1,3))
> >   > dat2
> >      aa bb
> >   11  a  1
> >   25  b  2
> >   1   c  3
> >   3   d  4
> >
> >   > dat2["1",]
> >     aa bb
> >   1  c  3
> >
> >   > dat2["3",]
> >     aa bb
> >   3  d  4
> >
> >   > dat2["2",]
> >      aa bb
> >   25  b  2
> >
> > Performance:
> >
> >   > mat <- matrix(rep(paste(letters, collapse=""), 5*300000), ncol=5)
> >   > dat <- as.data.frame(mat)
> >   > system.time(for (i in 1:100) dat["1", ])
> >      user  system elapsed
> >     2.036   0.880   2.917
> >
> > Still 17 times faster than with non-patched [.data.frame.
> >
> > Maybe 'pmatch(x, table, ...)' itself could be improved to be
> > more efficient when 'x' is a character vector and 'table' an
> > integer vector so the above trick is not needed anymore.
> >
> > My point is that something can probably be done to improve the
> > performance of 'dat[i, ]' when the row names are integer and 'i'
> > a character vector. I'm assuming that, in the typical use-case,
> > there is an exact match for 'i' in the row names so converting
> > those row names to a character vector in order to find this match
> > is (most of the time) a waste of time.
> 
> But why bother?  If you know the index of the row, why not index with
> a numeric vector rather than a string?  The behaviour in that case
> seems obvious and fast.

Because if I want to access a given row by its key (row name) then I _must_
use a string:

  > dat=data.frame(aa=letters[1:6], bb=1:6,
                   row.names=as.integer(c(51, 52, 11, 25, 1, 3)))

  > dat
     aa bb
  51  a  1
  52  b  2
  11  c  3
  25  d  4
  1   e  5
  3   f  6

If my key is "1":

  > dat["1", ]
    aa bb
  1  e  5

OK

I can't use a numeric index:

  > dat[1, ]
     aa bb
  51  a  1

Not what I want!

With a big data frame (e.g. 10**6 rows), every time I do 'dat["1", ]'
I'm charged the price of the coercion from a 10**6-element character
vector to an integer vector. A very high (and unreasonable) price that
could be easily avoided.

You could argue that I can still work around this by extracting
'attr(dat, "row.names")' myself, check its mode, and then, if its
mode is integer, use 'match' to find the position (i2) of my key in
the row.names, then finally call 'dat[i2, ]'. Is is unreasonable to
expect [.data.frame to do that for me?

Cheers,
H.

> 
> Hadley
>


From simon.urbanek at r-project.org  Sun Mar  4 03:03:27 2007
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Sat, 3 Mar 2007 21:03:27 -0500
Subject: [Rd] Segmentation fault on bin/R --version in R-devel
In-Reply-To: <45E9DDCC.7040705@bfro.uni-lj.si>
References: <45E9DDCC.7040705@bfro.uni-lj.si>
Message-ID: <F9114594-E530-4885-97EE-39F73C3EBB66@r-project.org>

Thanks, Gregor, it should be now fixed in the current R-devel.

Cheers,
Simon

On Mar 3, 2007, at 3:42 PM, Gregor Gorjanc wrote:

> Hello!
>
> I have tried to build and install latest version of R, but I am not  
> able
> to perform the install, due to seg. fault. I did the following  
> after SVN
> checkout and wget for recommendeds:
>
> ./configure --prefix=/usr/local/R-devel
> make
> make install
>
> ...
> ...
>   tcut                              text    html    latex   example
>   tobin                             text    html    latex   example
>   untangle.specials                 text    html    latex   example
>   veteran                           text    html    latex
> ** building package indices ...
> * DONE (survival)
> make[2]: Leaving directory
> `/home/share/projectSoft/R/R/src/library/Recommended'
> make[1]: Leaving directory
> `/home/share/projectSoft/R/R/src/library/Recommended'
> make[1]: Entering directory `/home/share/projectSoft/R/R/doc/manual'
> make[1]: Nothing to be done for `front-matter'.
> make[1]: Nothing to be done for `html-non-svn'.
> make[1]: Leaving directory `/home/share/projectSoft/R/R/doc/manual'
> SVN-REVISION is unchanged
> make[1]: Entering directory `/home/share/projectSoft/R/R/m4'
> make[1]: Nothing to be done for `install'.
> make[1]: Leaving directory `/home/share/projectSoft/R/R/m4'
> make[1]: Entering directory `/home/share/projectSoft/R/R/tools'
> make[1]: Nothing to be done for `install'.
> make[1]: Leaving directory `/home/share/projectSoft/R/R/tools'
> make[1]: Entering directory `/home/share/projectSoft/R/R/doc'
> installing doc ...
> /usr/bin/install -c -m 644 ../NEWS "/usr/local/R-devel/lib/R/doc"
> sh: line 1: 15129 Segmentation fault      ../bin/R --version 2>/dev/ 
> null
> help2man: can't get `--version' info from ../bin/R
> make[1]: *** [R.1] Error 139
> make[1]: Leaving directory `/home/share/projectSoft/R/R/doc'
> make: *** [install] Error 1
>
> gcc --version
> gcc (GCC) 4.1.2 20061115 (prerelease) (Debian 4.1.1-21)
> Copyright (C) 2006 Free Software Foundation, Inc.
> This is free software; see the source for copying conditions.   
> There is NO
> warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR  
> PURPOSE.
>
> As can be seen I have Debian GNU/Linux.
> Any clues?
>
> Thank you!
>
> Gregor
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From gregor.gorjanc at bfro.uni-lj.si  Sun Mar  4 12:36:51 2007
From: gregor.gorjanc at bfro.uni-lj.si (Gregor Gorjanc)
Date: Sun, 04 Mar 2007 12:36:51 +0100
Subject: [Rd] Segmentation fault on bin/R --version in R-devel
In-Reply-To: <F9114594-E530-4885-97EE-39F73C3EBB66@r-project.org>
References: <45E9DDCC.7040705@bfro.uni-lj.si>
	<F9114594-E530-4885-97EE-39F73C3EBB66@r-project.org>
Message-ID: <45EAAF53.70202@bfro.uni-lj.si>

Simon Urbanek wrote:
> Thanks, Gregor, it should be now fixed in the current R-devel.
> 
> Cheers,
> Simon

Which I gladly confirm.

Gregor


From gregor.gorjanc at bfro.uni-lj.si  Sun Mar  4 13:14:49 2007
From: gregor.gorjanc at bfro.uni-lj.si (Gregor Gorjanc)
Date: Sun, 04 Mar 2007 13:14:49 +0100
Subject: [Rd] fortune() in .Rprofile conflicts with R CMD INSTALL
Message-ID: <45EAB839.9090203@bfro.uni-lj.si>

Hello,

This is about fortune package, but I think that might be related also to
base R, so I am sending to package maintainer and R-devel list.

I have the following in my .Rprofile to break monotony of code writing

library(utils)
library(fortunes)
fortune()
detach("package:fortunes")

so I get a fortune every time I start R. It seems that this conflicts
with R CMD INSTALL in latest R-devel on Linux. Two things can happen:

1. R CMD INSTALL fails
----------------------------------------------------------------------

$ R-devel CMD INSTALL connectedness
* Installing to library '
My preference goes with the numbering scheme attributed to a tribe on some
island in the Pacific which consists of a 'factor' with four levels: 'one',
'two', 'three', and 'lots'. Hence, I'd go with 'lots of R users'.
   -- Dirk Eddelbuettel (in a discussion about trying to estimate the
number of
      R users)
      R-help (April 2004)

/usr/local/R-devel/lib/R/library'
ERROR: cannot write to or create directory '
My preference goes with the numbering scheme attributed to a tribe on some
island in the Pacific which consists of a 'factor' with four levels: 'one',
'two', 'three', and 'lots'. Hence, I'd go with 'lots of R users'.
   -- Dirk Eddelbuettel (in a discussion about trying to estimate the
number of
      R users)
      R-help (April 2004)

/usr/local/R-devel/lib/R/library'

2. R CMD INSTALL installs package in wrong place - see bellow
----------------------------------------------------------------------

$ R-devel CMD INSTALL connectedness
* Installing to library '
If you imagine that this pen is Trellis, then Lattice is not this pen.
   -- Paul Murrell (on the difference of Lattice (which eventually was
called
      grid) and Trellis)
      DSC 2001, Wien (March 2001)

/usr/local/R-devel/lib/R/library'
* Installing *source* package 'connectedness' ...
** R
** data
** inst
cat: /home/ggorjan/programs/R/devel/r-ggorjan/: Is a directory
cat: If: No such file or directory
cat: you: No such file or directory
cat: imagine: No such file or directory
cat: that: No such file or directory
cat: this: No such file or directory
cat: pen: No such file or directory
cat: is: No such file or directory
cat: Trellis,: No such file or directory
cat: then: No such file or directory
cat: Lattice: No such file or directory
cat: is: No such file or directory
cat: not: No such file or directory
cat: this: No such file or directory
cat: pen.: No such file or directory
cat: Paul: No such file or directory
cat: Murrell: No such file or directory
cat: (on: No such file or directory
cat: the: No such file or directory
cat: difference: No such file or directory
cat: of: No such file or directory
cat: Lattice: No such file or directory
cat: (which: No such file or directory
cat: eventually: No such file or directory
cat: was: No such file or directory
cat: called: No such file or directory
cat: grid): No such file or directory
cat: and: No such file or directory
cat: Trellis): No such file or directory
cat: DSC: No such file or directory
cat: 2001,: No such file or directory
cat: Wien: No such file or directory
cat: (March: No such file or directory
cat: 2001): No such file or directory
cat: /usr/local/R-devel/lib/R/library/connectedness/R/connectedness: No
such file or directory
** help
 >>> Building/Updating help pages for package 'connectedness'
     Formats: text html latex example
  connect                           text    html    latex
  connectedness                     text    html    latex   example
  levelsBySubset                    text    html    latex   example
  plot.connectedness                text    html    latex   example
  subset.connectedness              text    html    latex   example
** building package indices ...
* DONE (connectedness)

$ tree -d
.
|-- \012If you imagine that this pen is Trellis, then Lattice is not
this pen.\012   -- Paul Murrell (on the difference of Lattice (which
eventually was called\012      grid) and Trellis)\012      DSC 2001,
Wien (March 2001)\012\012
|   `-- usr
|       `-- local
|           `-- R-devel
|               `-- lib
|                   `-- R
|                       `-- library
|                           `-- connectedness
|                               |-- Meta
|                               |-- R
|                               |-- R-ex
|                               |-- data
|                               |-- doc
|                               |-- help
|                               |-- html
|                               |-- latex
|                               |-- man
|                               `-- unitTests
|-- connectedness
|   |-- R
|   |-- data
|   |-- inst
|   |   |-- doc
|   |   `-- unitTests
|   |-- man
|   `-- tests
...

Looks like a bug to me.

Gregor


From sfalcon at fhcrc.org  Sun Mar  4 17:18:38 2007
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Sun, 04 Mar 2007 08:18:38 -0800
Subject: [Rd] fortune() in .Rprofile conflicts with R CMD INSTALL
In-Reply-To: <45EAB839.9090203@bfro.uni-lj.si> (Gregor Gorjanc's message of
	"Sun, 04 Mar 2007 13:14:49 +0100")
References: <45EAB839.9090203@bfro.uni-lj.si>
Message-ID: <m2tzx19e3l.fsf@ziti.local>

Gregor Gorjanc <gregor.gorjanc at bfro.uni-lj.si> writes:

> Hello,
>
> This is about fortune package, but I think that might be related also to
> base R, so I am sending to package maintainer and R-devel list.
>
> I have the following in my .Rprofile to break monotony of code writing
>
> library(utils)
> library(fortunes)
> fortune()
> detach("package:fortunes")
>

The quick fix for you is, I believe,

    if (interactive()) {
        library(fortunes)
        fortune()
        detach("package:fortunes")
    }

Whether something could be changed so that R's output doesn't confuse
itself and gcc when doing R CMD INSTALL, seems like it should be
possible.

+ seth

-- 
Seth Falcon | Computational Biology | Fred Hutchinson Cancer Research Center
http://bioconductor.org


From cstrato at aon.at  Sun Mar  4 17:26:40 2007
From: cstrato at aon.at (cstrato)
Date: Sun, 04 Mar 2007 17:26:40 +0100
Subject: [Rd] Problem using callNextMethod() in S4
Message-ID: <45EAF340.50707@aon.at>

Dear all,

Maybe, I am doing something wrong, but using R-2.5.0 on my Intel-Mac, I 
have problems
using function callNextMethod() in method initialize.

I am loading the following code as file "testS4.R":

setClass("baseClass",
   representation(myname = "character",
                  mydir  = "character",
                  "VIRTUAL"),
   prototype(myname = "",
             mydir  = "")
)#baseClass

setClass("derivedClass",
   representation(mytitle = "character"),
   contains=c("baseClass"),
   prototype(mytitle = "")
)#derivedClass


setMethod("initialize", "baseClass",
   function(.Object, ...) {
print("---initialize:baseClass---")
#    .Object <- callNextMethod();
      if (.Object at mydir == "") {
         .Object at mydir <- as.character(getwd());
      }#if
print(paste("mydir = ", .Object at mydir))
    .Object <- callNextMethod();
    .Object;
   }
)#initialize

setValidity("baseClass",
   function(object) {
print("---setValidity:baseClass---")
      strg <- object at myname;
      if (!(is(strg, "character") && nchar(strg) > 0)) {
         warning(paste(sQuote("myname"), "is missing"));
      }#if
print(paste("myname = ",object at myname))
      strg <- object at mydir;
      if (!(is(strg, "character") && file.exists(strg))) {
         warning(paste(sQuote("mydir"), "is not a system directory"));
      }#if
      if (substr(strg, nchar(strg), nchar(strg)) == "/") {
         object at mydir <- substr(strg, 0, nchar(strg)-1);
      }#if
print(paste("mydir = ",object at mydir))
   }
)#setValidity

setMethod("initialize", "derivedClass",
   function(.Object, ...) {
print("---initialize:derivedClass---")
#    .Object <- callNextMethod();
      if (.Object at mytitle == "") {
         .Object at mytitle = "MyTitle";
      }#if
print(paste("mytitle = ",.Object at mytitle))
#    .Object <- callNextMethod();
    .Object;
   }
)#initialize

setValidity("derivedClass",
   function(object) {
print("---setValidity:derivedClass---")
      strg <- object at mytitle;
      if (!(is(strg, "character") && nchar(strg) > 0)) {
         warning(paste(sQuote("mytitle"), "is missing"));
      }#if
print(paste("mytitle = ",object at mytitle))
   }
)#setValidity


This is the output of an R session:

 > library(methods)
 > source("testS4.R")
 > tmp<-new("derivedClass")
[1] "---initialize:derivedClass---"
[1] "mytitle =  MyTitle"
[1] "---initialize:baseClass---"
[1] "mydir =  /Volumes/CoreData/CRAN/Workspaces/tests"
 >
 > tmp<-new("derivedClass",myname="testname",mytitle="testitle")
[1] "---initialize:derivedClass---"
[1] "mytitle =  MyTitle"
[1] "---initialize:baseClass---"
[1] "mydir =  /Volumes/CoreData/CRAN/Workspaces/tests"
[1] "---setValidity:baseClass---"
[1] "myname =  testname"
[1] "mydir =  /Volumes/CoreData/CRAN/Workspaces/tests"
Error in validObject(.Object) : invalid class "derivedClass" object: 
mydir =  /Volumes/CoreData/CRAN/Workspaces/tests
 >
 > tmp<-new("derivedClass",myname="testname",mydir="",mytitle="testitle")
[1] "---initialize:derivedClass---"
[1] "mytitle =  MyTitle"
[1] "---initialize:baseClass---"
[1] "mydir =  /Volumes/CoreData/CRAN/Workspaces/tests"
[1] "---setValidity:baseClass---"
[1] "myname =  testname"
[1] "mydir =  "
Error in validObject(.Object) : invalid class "derivedClass" object: 
mydir = 
In addition: Warning message:
'mydir' is not a system directory in: validityMethod(as(object, 
superClass))
 >

Can someone tell me why mydir gives an error although it is defined 
correctly?

Thank you in advance
Best regards
Christian
_._._._._._._._._._._._._._._._
C.h.i.s.t.i.a.n S.t.r.a.t.o.w.a
V.i.e.n.n.a       A.u.s.t.r.i.a
_._._._._._._._._._._._._._._._


From sfalcon at fhcrc.org  Sun Mar  4 18:23:06 2007
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Sun, 04 Mar 2007 09:23:06 -0800
Subject: [Rd] Problem using callNextMethod() in S4
In-Reply-To: <45EAF340.50707@aon.at> (cstrato@aon.at's message of "Sun,
	04 Mar 2007 17:26:40 +0100")
References: <45EAF340.50707@aon.at>
Message-ID: <m2odn8apol.fsf@ziti.local>

cstrato <cstrato at aon.at> writes:

> Dear all,
>
> Maybe, I am doing something wrong, but using R-2.5.0 on my Intel-Mac, I 
> have problems
> using function callNextMethod() in method initialize.
>
> I am loading the following code as file "testS4.R":

I don't think this is the code in the same state as that which you ran
the examples.  Did you add/remove some comment lines perhaps?

After copy/pasting the code you posted, I get:

    > tmp<-new("derivedClass")
    [1] "---initialize:derivedClass---"
    [1] "mytitle =  MyTitle"
    > tmp<-new("derivedClass",myname="testname",mytitle="testitle")
    [1] "---initialize:derivedClass---"
    [1] "mytitle =  MyTitle"

> setValidity("baseClass",
>    function(object) {
> print("---setValidity:baseClass---")
>       strg <- object at myname;
>       if (!(is(strg, "character") && nchar(strg) > 0)) {
>          warning(paste(sQuote("myname"), "is missing"));
>       }#if
> print(paste("myname = ",object at myname))
>       strg <- object at mydir;
>       if (!(is(strg, "character") && file.exists(strg))) {
>          warning(paste(sQuote("mydir"), "is not a system directory"));
>       }#if
>       if (substr(strg, nchar(strg), nchar(strg)) == "/") {
>          object at mydir <- substr(strg, 0, nchar(strg)-1);
>       }#if
> print(paste("mydir = ",object at mydir))
>    }
> )#setValidity

Your validity function isn't valid :-P It should either return TRUE or
return a character vector describing what isn't valid about the
object.  Don't call warning() or print().

Also, you don't need those ';'

And finally, you are operating on a _copy_ in the validity method
(just like everywhere else) and so this

>       if (substr(strg, nchar(strg), nchar(strg)) == "/") {
>          object at mydir <- substr(strg, 0, nchar(strg)-1);
>       }#if

will not have any effect on the instance passed in.  It is an odd
thing to do in a validity method.

+ seth

-- 
Seth Falcon | Computational Biology | Fred Hutchinson Cancer Research Center
http://bioconductor.org


From cstrato at aon.at  Sun Mar  4 19:51:45 2007
From: cstrato at aon.at (cstrato)
Date: Sun, 04 Mar 2007 19:51:45 +0100
Subject: [Rd] Problem using callNextMethod() in S4
In-Reply-To: <m2odn8apol.fsf@ziti.local>
References: <45EAF340.50707@aon.at> <m2odn8apol.fsf@ziti.local>
Message-ID: <45EB1541.2020308@aon.at>

Dear Seth

Thank you for your comments. Please see my comments and at the end my 
corrected code and output.
Sorrowly, the problem remains the same.

Seth Falcon wrote:
> cstrato <cstrato at aon.at> writes:
>
>   
>> Dear all,
>>
>> Maybe, I am doing something wrong, but using R-2.5.0 on my Intel-Mac, I 
>> have problems
>> using function callNextMethod() in method initialize.
>>
>> I am loading the following code as file "testS4.R":
>>     
>
> I don't think this is the code in the same state as that which you ran
> the examples.  Did you add/remove some comment lines perhaps?
>
> After copy/pasting the code you posted, I get:
>
>     > tmp<-new("derivedClass")
>     [1] "---initialize:derivedClass---"
>     [1] "mytitle =  MyTitle"
>     > tmp<-new("derivedClass",myname="testname",mytitle="testitle")
>     [1] "---initialize:derivedClass---"
>     [1] "mytitle =  MyTitle"
>
>   
I am sorry, you are correct, I have commented out ".Object <- 
callNextMethod()" in method
initialize for derivedClass afterwards.
>> setValidity("baseClass",
>>    function(object) {
>> print("---setValidity:baseClass---")
>>       strg <- object at myname;
>>       if (!(is(strg, "character") && nchar(strg) > 0)) {
>>          warning(paste(sQuote("myname"), "is missing"));
>>       }#if
>> print(paste("myname = ",object at myname))
>>       strg <- object at mydir;
>>       if (!(is(strg, "character") && file.exists(strg))) {
>>          warning(paste(sQuote("mydir"), "is not a system directory"));
>>       }#if
>>       if (substr(strg, nchar(strg), nchar(strg)) == "/") {
>>          object at mydir <- substr(strg, 0, nchar(strg)-1);
>>       }#if
>> print(paste("mydir = ",object at mydir))
>>    }
>> )#setValidity
>>     
>
> Your validity function isn't valid :-P It should either return TRUE or
> return a character vector describing what isn't valid about the
> object.  Don't call warning() or print().
>   
Please see my corrected code where I use "validMsg()" from BioBase.
> Also, you don't need those ';'
>
> And finally, you are operating on a _copy_ in the validity method
> (just like everywhere else) and so this
>
>   
>>       if (substr(strg, nchar(strg), nchar(strg)) == "/") {
>>          object at mydir <- substr(strg, 0, nchar(strg)-1);
>>       }#if
>>     
>
> will not have any effect on the instance passed in.  It is an odd
> thing to do in a validity method.
>   
You are right, I moved this code to method "initialize".
> + seth
>
>   
Here is my new code "testS4.R" (as used in the output):

setClass("baseClass",
   representation(myname = "character",
                  mydir  = "character",
                  "VIRTUAL"),
   prototype(myname = "",
             mydir  = "")
)#baseClass

setClass("derivedClass",
   representation(mytitle = "character"),
   contains=c("baseClass"),
   prototype(mytitle = "")
)#derivedClass

# taken from package BioBase: tools.R
validMsg <- function(msg, result) {
   if (is.character(result)) {
      append(msg, result);
   } else {
      msg;
   }#if
}

setMethod("initialize", "baseClass",
   function(.Object, ...) {
print("---initialize:baseClass---")
#    .Object <- callNextMethod();
      strg <- .Object at mydir;
print(paste("base:strg = ", strg))
      if (strg == "") {
         .Object at mydir <- as.character(getwd());
      }#if
      if (substr(strg, nchar(strg), nchar(strg)) == "/") {
         .Object at mydir <- substr(strg, 0, nchar(strg)-1);
      }#if
print(paste("base:mydir = ", .Object at mydir))
    .Object <- callNextMethod();
    .Object;
   }
)#initialize

setValidity("baseClass",
   function(object) {
print("---setValidity:baseClass---")
      msg <- NULL;
      strg <- object at myname;
      if (!(is(strg, "character") && nchar(strg) > 0)) {
         msg <- validMsg(msg, paste(sQuote("myname"), "is missing"));
      }#if
print(paste("base:myname = ",object at myname))
      strg <- object at mydir;
      if (!(is(strg, "character") && file.exists(strg))) {
         msg <- validMsg(msg, paste(sQuote("mydir"), "is not a system 
directory"));
      }#if
print(paste("base:mydir = ",object at mydir))
      if (is.null(msg)) TRUE else msg;
   }
)#setValidity

setMethod("initialize", "derivedClass",
   function(.Object, ...) {
print("---initialize:derivedClass---")
#    .Object <- callNextMethod();
      if (.Object at mytitle == "") {
         .Object at mytitle = "MyTitle";
      }#if
print(paste("derived:mytitle = ",.Object at mytitle))
    .Object <- callNextMethod();
    .Object;
   }
)#initialize

setValidity("derivedClass",
   function(object) {
print("---setValidity:derivedClass---")
      msg <- NULL;
      strg <- object at mytitle;
      if (!(is(strg, "character") && nchar(strg) > 0)) {
         msg <- validMsg(msg, paste(sQuote("mytitle"), "is missing"));
      }#if
print(paste("derived:mytitle = ",object at mytitle))
      if (is.null(msg)) TRUE else msg;
   }
)#setValidity


Here is the new output with the same error:

 > library(methods)
 > source("testS4.R")
 > tmp<-new("derivedClass")
[1] "---initialize:derivedClass---"
[1] "derived:mytitle =  MyTitle"
[1] "---initialize:baseClass---"
[1] "base:strg =  "
[1] "base:mydir =  /Volumes/CoreData/CRAN/Workspaces/tests"
 >
 > tmp<-new("derivedClass",myname="testname",mydir="",mytitle="testitle")
[1] "---initialize:derivedClass---"
[1] "derived:mytitle =  MyTitle"
[1] "---initialize:baseClass---"
[1] "base:strg =  "
[1] "base:mydir =  /Volumes/CoreData/CRAN/Workspaces/tests"
[1] "---setValidity:baseClass---"
[1] "base:myname =  testname"
[1] "base:mydir =  "
Error in validObject(.Object) : invalid class "derivedClass" object: 
'mydir' is not a system directory

I do not understand why "mydir" is not recognized correctly?

Thank you
Christian


From gregor.gorjanc at bfro.uni-lj.si  Sun Mar  4 23:04:57 2007
From: gregor.gorjanc at bfro.uni-lj.si (Gregor Gorjanc)
Date: Sun, 4 Mar 2007 22:04:57 +0000 (UTC)
Subject: [Rd] fortune() in .Rprofile conflicts with R CMD INSTALL
References: <45EAB839.9090203@bfro.uni-lj.si> <m2tzx19e3l.fsf@ziti.local>
Message-ID: <loom.20070304T230316-753@post.gmane.org>

Seth Falcon <sfalcon <at> fhcrc.org> writes:
> The quick fix for you is, I believe,
> 
>     if (interactive()) {
>         library(fortunes)
>         fortune()
>         detach("package:fortunes")
>     }
> 
> Whether something could be changed so that R's output doesn't confuse
> itself and gcc when doing R CMD INSTALL, seems like it should be
> possible.

Yes, this solves my! problem. I do not know what is causing this behaviour. This
did not happen with 2.4.1

Thank you Seth.

Gregor


From mtmorgan at fhcrc.org  Mon Mar  5 04:48:54 2007
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Sun, 04 Mar 2007 19:48:54 -0800
Subject: [Rd] Problem using callNextMethod() in S4
In-Reply-To: <45EB1541.2020308@aon.at> (cstrato@aon.at's message of "Sun, 04
	Mar 2007 19:51:45 +0100")
References: <45EAF340.50707@aon.at> <m2odn8apol.fsf@ziti.local>
	<45EB1541.2020308@aon.at>
Message-ID: <6phwt1wcpuh.fsf@gopher4.fhcrc.org>

In this method...

setMethod("initialize", "baseClass",
   function(.Object, ...) {
print("---initialize:baseClass---")
#    .Object <- callNextMethod();
      strg <- .Object at mydir;
print(paste("base:strg = ", strg))
      if (strg == "") {
         .Object at mydir <- as.character(getwd());
      }#if
      if (substr(strg, nchar(strg), nchar(strg)) == "/") {
         .Object at mydir <- substr(strg, 0, nchar(strg)-1);
      }#if
print(paste("base:mydir = ", .Object at mydir))
    .Object <- callNextMethod();
    .Object;
   }
)#initialize

the argument '...' includes the argument mydir="". Later, when you
.Object <- callNextMethod(), it invokes the 'next' method with the
same argument, i.e., with mydir="". This causes the 'mydir' slot to be
initialized with "", triggering the validity error. You can see this
more clearly in the following, where the provided argument x=10:1
overrides the assignment in initialize:

> setClass("A", representation=representation(x="numeric"))
[1] "A"
> setMethod("initialize", "A",
+           function(.Object, ...) {
+               .Object at x <- 1:10
+               callNextMethod()
+           })
[1] "initialize"

> new("A", x=10:1)
An object of class "A"
Slot "x":
 [1] 10  9  8  7  6  5  4  3  2  1

One solution is to name any arguments you're going to manipulate in
the initialize method, and then make sure the correct arguments are
passed to callNextMethod. You'll probably want to provide a sensible
default argument to mydir, so that user doesn't have to do anything
clever (like remember to pass "") to get the default behavior. Here's
what I end up with:

setMethod("initialize", "baseClass",
          function(.Object, mydir=as.character(getwd()), ...) {
              if (substr(mydir, nchar(mydir), nchar(mydir)) == "/") {
                  mydir <- substr(mydir, 0, nchar(mydir)-1)
              }
              callNextMethod(.Object, mydir=mydir, ...);
          })

setMethod("initialize", "derivedClass",
          function(.Object, mytitle="MyTitle", ...) {
              callNextMethod(.Object, mytitle=mytitle, ...)
          })

Another solution is to follow the convention where callNextMethod()
comes first (constructing a valid object!), and your initialize method
then fills in slots with the appropriate values.

One interesting part of your example is that new('derivedClass') does
NOT cause a validity error, even though the object is invalid
('myname' is ""; also, none of your validity method messages are
printed)! Apparently, the assumption is that you (the programmer, as
opposed to the user) are not going to create an invalid object by
default.

Also, take a look at the initialize method that R has constructed for
derivedClass:

> getMethod("initialize", "derivedClass")
Method Definition:

function (.Object, ...) 
{
    .local <- function (.Object, mytitle = "MyTitle", ...) 
    {
        callNextMethod(.Object, mytitle = mytitle, ...)
    }
    .local(.Object, ...)
}

Signatures:
        .Object       
target  "derivedClass"
defined "derivedClass"

Notice how the function is defined in terms of .Object and .... The
named arguments not present in the generic signature (i.e., 'mytitle')
are 'hidden' in the .local function definition. By the time
callNextMethod() has been evaluated, '...' does NOT include
'mytitle'. I think this is why you must explicitly include any named
arguments you want to pass to callNextMethod -- the default is to
callNextMethod with the generic signature, but with symbols (.Object,
...) taking their current value. Here's a simpler illustration:

setClass("A", representation=representation(x="numeric"))
setMethod("initialize", "A",
          function(.Object, x, ...) callNextMethod())

This leads to the perhaps unexpected outcome

> new("A", x=10:1)
An object of class "A"
Slot "x":
numeric(0)

I say unexpected because, if there was no initialize method, or if the
initialize method were written without 'x' in the signature, then the
argument 'x' would be used to fill the slot:x.

Here's the solution like that for baseClass, above:

setMethod("initialize", "A",
          function(.Object, x, ...)
          callNextMethod(.Object, x=x, ...))

...which leads to

> new("A", x=10:1)
An object of class "A"
Slot "x":
 [1] 10  9  8  7  6  5  4  3  2  1

Hope that helps,

Martin

cstrato <cstrato at aon.at> writes:

> Dear Seth
>
> Thank you for your comments. Please see my comments and at the end my 
> corrected code and output.
> Sorrowly, the problem remains the same.
>
> Seth Falcon wrote:
>> cstrato <cstrato at aon.at> writes:
>>
>>   
>>> Dear all,
>>>
>>> Maybe, I am doing something wrong, but using R-2.5.0 on my Intel-Mac, I 
>>> have problems
>>> using function callNextMethod() in method initialize.
>>>
>>> I am loading the following code as file "testS4.R":
>>>     
>>
>> I don't think this is the code in the same state as that which you ran
>> the examples.  Did you add/remove some comment lines perhaps?
>>
>> After copy/pasting the code you posted, I get:
>>
>>     > tmp<-new("derivedClass")
>>     [1] "---initialize:derivedClass---"
>>     [1] "mytitle =  MyTitle"
>>     > tmp<-new("derivedClass",myname="testname",mytitle="testitle")
>>     [1] "---initialize:derivedClass---"
>>     [1] "mytitle =  MyTitle"
>>
>>   
> I am sorry, you are correct, I have commented out ".Object <- 
> callNextMethod()" in method
> initialize for derivedClass afterwards.
>>> setValidity("baseClass",
>>>    function(object) {
>>> print("---setValidity:baseClass---")
>>>       strg <- object at myname;
>>>       if (!(is(strg, "character") && nchar(strg) > 0)) {
>>>          warning(paste(sQuote("myname"), "is missing"));
>>>       }#if
>>> print(paste("myname = ",object at myname))
>>>       strg <- object at mydir;
>>>       if (!(is(strg, "character") && file.exists(strg))) {
>>>          warning(paste(sQuote("mydir"), "is not a system directory"));
>>>       }#if
>>>       if (substr(strg, nchar(strg), nchar(strg)) == "/") {
>>>          object at mydir <- substr(strg, 0, nchar(strg)-1);
>>>       }#if
>>> print(paste("mydir = ",object at mydir))
>>>    }
>>> )#setValidity
>>>     
>>
>> Your validity function isn't valid :-P It should either return TRUE or
>> return a character vector describing what isn't valid about the
>> object.  Don't call warning() or print().
>>   
> Please see my corrected code where I use "validMsg()" from BioBase.
>> Also, you don't need those ';'
>>
>> And finally, you are operating on a _copy_ in the validity method
>> (just like everywhere else) and so this
>>
>>   
>>>       if (substr(strg, nchar(strg), nchar(strg)) == "/") {
>>>          object at mydir <- substr(strg, 0, nchar(strg)-1);
>>>       }#if
>>>     
>>
>> will not have any effect on the instance passed in.  It is an odd
>> thing to do in a validity method.
>>   
> You are right, I moved this code to method "initialize".
>> + seth
>>
>>   
> Here is my new code "testS4.R" (as used in the output):
>
> setClass("baseClass",
>    representation(myname = "character",
>                   mydir  = "character",
>                   "VIRTUAL"),
>    prototype(myname = "",
>              mydir  = "")
> )#baseClass
>
> setClass("derivedClass",
>    representation(mytitle = "character"),
>    contains=c("baseClass"),
>    prototype(mytitle = "")
> )#derivedClass
>
> # taken from package BioBase: tools.R
> validMsg <- function(msg, result) {
>    if (is.character(result)) {
>       append(msg, result);
>    } else {
>       msg;
>    }#if
> }
>
> setMethod("initialize", "baseClass",
>    function(.Object, ...) {
> print("---initialize:baseClass---")
> #    .Object <- callNextMethod();
>       strg <- .Object at mydir;
> print(paste("base:strg = ", strg))
>       if (strg == "") {
>          .Object at mydir <- as.character(getwd());
>       }#if
>       if (substr(strg, nchar(strg), nchar(strg)) == "/") {
>          .Object at mydir <- substr(strg, 0, nchar(strg)-1);
>       }#if
> print(paste("base:mydir = ", .Object at mydir))
>     .Object <- callNextMethod();
>     .Object;
>    }
> )#initialize
>
> setValidity("baseClass",
>    function(object) {
> print("---setValidity:baseClass---")
>       msg <- NULL;
>       strg <- object at myname;
>       if (!(is(strg, "character") && nchar(strg) > 0)) {
>          msg <- validMsg(msg, paste(sQuote("myname"), "is missing"));
>       }#if
> print(paste("base:myname = ",object at myname))
>       strg <- object at mydir;
>       if (!(is(strg, "character") && file.exists(strg))) {
>          msg <- validMsg(msg, paste(sQuote("mydir"), "is not a system 
> directory"));
>       }#if
> print(paste("base:mydir = ",object at mydir))
>       if (is.null(msg)) TRUE else msg;
>    }
> )#setValidity
>
> setMethod("initialize", "derivedClass",
>    function(.Object, ...) {
> print("---initialize:derivedClass---")
> #    .Object <- callNextMethod();
>       if (.Object at mytitle == "") {
>          .Object at mytitle = "MyTitle";
>       }#if
> print(paste("derived:mytitle = ",.Object at mytitle))
>     .Object <- callNextMethod();
>     .Object;
>    }
> )#initialize
>
> setValidity("derivedClass",
>    function(object) {
> print("---setValidity:derivedClass---")
>       msg <- NULL;
>       strg <- object at mytitle;
>       if (!(is(strg, "character") && nchar(strg) > 0)) {
>          msg <- validMsg(msg, paste(sQuote("mytitle"), "is missing"));
>       }#if
> print(paste("derived:mytitle = ",object at mytitle))
>       if (is.null(msg)) TRUE else msg;
>    }
> )#setValidity
>
>
> Here is the new output with the same error:
>
>  > library(methods)
>  > source("testS4.R")
>  > tmp<-new("derivedClass")
> [1] "---initialize:derivedClass---"
> [1] "derived:mytitle =  MyTitle"
> [1] "---initialize:baseClass---"
> [1] "base:strg =  "
> [1] "base:mydir =  /Volumes/CoreData/CRAN/Workspaces/tests"
>  >
>  > tmp<-new("derivedClass",myname="testname",mydir="",mytitle="testitle")
> [1] "---initialize:derivedClass---"
> [1] "derived:mytitle =  MyTitle"
> [1] "---initialize:baseClass---"
> [1] "base:strg =  "
> [1] "base:mydir =  /Volumes/CoreData/CRAN/Workspaces/tests"
> [1] "---setValidity:baseClass---"
> [1] "base:myname =  testname"
> [1] "base:mydir =  "
> Error in validObject(.Object) : invalid class "derivedClass" object: 
> 'mydir' is not a system directory
>
> I do not understand why "mydir" is not recognized correctly?
>
> Thank you
> Christian
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Martin Morgan
Bioconductor / Computational Biology
http://bioconductor.org


From Kurt.Hornik at wu-wien.ac.at  Mon Mar  5 12:27:36 2007
From: Kurt.Hornik at wu-wien.ac.at (Kurt Hornik)
Date: Mon, 5 Mar 2007 12:27:36 +0100
Subject: [Rd] fortune() in .Rprofile conflicts with R CMD INSTALL
In-Reply-To: <loom.20070304T230316-753@post.gmane.org>
References: <45EAB839.9090203@bfro.uni-lj.si> <m2tzx19e3l.fsf@ziti.local>
	<loom.20070304T230316-753@post.gmane.org>
Message-ID: <17899.65192.532067.867254@mithrandir.hornik.net>

>>>>> Gregor Gorjanc writes:

> Seth Falcon <sfalcon <at> fhcrc.org> writes:
>> The quick fix for you is, I believe,
>> 
>> if (interactive()) {
>> library(fortunes)
>> fortune()
>> detach("package:fortunes")
>> }
>> 
>> Whether something could be changed so that R's output doesn't confuse
>> itself and gcc when doing R CMD INSTALL, seems like it should be
>> possible.

> Yes, this solves my! problem. I do not know what is causing this
> behaviour.

Well, r-devel's src/scripts/INSTALL.in now has

if test -z "${lib}"; then
  lib=`echo "cat(.libPaths()[1])" | \
    R_DEFAULT_PACKAGES=NULL "${R_EXE}" --no-save --slave`
  message "Installing to library '$lib'"

so we need to find a way to "just get" the result of cat(.libPaths()[1])
into $lib as intended.

One idea might be ensuring that this gets into the last line on its own,
and then taking $lib as the last line of what we got ...

Best
-k

> This did not happen with 2.4.1

> Thank you Seth.

> Gregor

> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From jose.sierra at integromics.com  Mon Mar  5 13:39:06 2007
From: jose.sierra at integromics.com (Jose Sierra)
Date: Mon, 05 Mar 2007 13:39:06 +0100
Subject: [Rd] RJDBC
Message-ID: <45EC0F6A.20309@integromics.com>

I need help.

I'm trying to connect with an Oracle DBMS and MySQL DBMS, I'm using 
RJDBC package.

My code is the next:

library('rJava')
library('DBI')
library('RJDBC')

//Mysql
drv <- 
JDBC("com.mysql.jdbc.Driver","C:\\Temporal\\mysql-connector-java-3.0.9-stable-bin.jar","'") 

conn <- dbConnect(drv, "jdbc:mysql://localhost:3306/bd", "user", 
"password")

//Oracle
drv <- 
JDBC("oracle.jdbc.driver.OracleDriver","C:\\Temporal\\classes12.jar","'")
conn <- 
dbConnect(drv,"jdbc:oracle:thin:@192.168.1.70:1521:SDS22","user","password") 


R always returns for oracle
"Error en .local(drv, ...) : Unable to connect JDBC to 
jdbc:oracle:thin:@192.168.1.70:1521:SDS22"
and for mysql
"Error en .local(drv, ...) : Unable to connect JDBC to 
jdbc:mysql://localhost:3306/bd"

And the function summary(drv) returns:
JDBCDriver
name = JDBC
driver.version = 0.1-1
DBI.version = 0.1-1
client.version = NA
max.connections = NA

Can you help me, please?

Another question:
I try to compile ROracle and RMysql for windows but i need Rdll.lib and 
it need R.exp. Can you give me one of this files?


Regards.
Jose Sierra


		
______________________________________________ 
LLama Gratis a cualquier PC del Mundo. 
Llamadas a fijos y m?viles desde 1 c?ntimo por minuto. 
http://es.voice.yahoo.com


From sdavis2 at mail.nih.gov  Mon Mar  5 13:50:57 2007
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Mon, 05 Mar 2007 07:50:57 -0500
Subject: [Rd] RJDBC
In-Reply-To: <45EC0F6A.20309@integromics.com>
References: <45EC0F6A.20309@integromics.com>
Message-ID: <45EC1231.20108@mail.nih.gov>

Jose Sierra wrote:
> I need help.
>
> I'm trying to connect with an Oracle DBMS and MySQL DBMS, I'm using 
> RJDBC package.
>
> My code is the next:
>
> library('rJava')
> library('DBI')
> library('RJDBC')
>
> //Mysql
> drv <- 
> JDBC("com.mysql.jdbc.Driver","C:\\Temporal\\mysql-connector-java-3.0.9-stable-bin.jar","'") 
>
> conn <- dbConnect(drv, "jdbc:mysql://localhost:3306/bd", "user", 
> "password")
>
> //Oracle
> drv <- 
> JDBC("oracle.jdbc.driver.OracleDriver","C:\\Temporal\\classes12.jar","'")
> conn <- 
> dbConnect(drv,"jdbc:oracle:thin:@192.168.1.70:1521:SDS22","user","password") 
>
>
> R always returns for oracle
> "Error en .local(drv, ...) : Unable to connect JDBC to 
> jdbc:oracle:thin:@192.168.1.70:1521:SDS22"
> and for mysql
> "Error en .local(drv, ...) : Unable to connect JDBC to 
> jdbc:mysql://localhost:3306/bd"
>
> And the function summary(drv) returns:
> JDBCDriver
> name = JDBC
> driver.version = 0.1-1
> DBI.version = 0.1-1
> client.version = NA
> max.connections = NA
>
> Can you help me, please?
>   
Jose,

This message should go to the R-help or the R-SIG-DB list.  When you 
send it, I suggest you include your Java version, the output of a call 
to sessionInfo(), and let folks know whether you can connect from your 
machine using JDBC in Java.  I don't use RJDBC, so I can't help 
directly--sorry.

Sean


From jose.sierra at integromics.com  Mon Mar  5 14:02:33 2007
From: jose.sierra at integromics.com (Jose Sierra)
Date: Mon, 05 Mar 2007 14:02:33 +0100
Subject: [Rd] RJDBC
In-Reply-To: <45EC1231.20108@mail.nih.gov>
References: <45EC0F6A.20309@integromics.com> <45EC1231.20108@mail.nih.gov>
Message-ID: <45EC14E9.7090401@integromics.com>

Thank you Sean.

I send the message to R-help.

Sean Davis escribi?:
> Jose Sierra wrote:
>> I need help.
>>
>> I'm trying to connect with an Oracle DBMS and MySQL DBMS, I'm using 
>> RJDBC package.
>>
>> My code is the next:
>>
>> library('rJava')
>> library('DBI')
>> library('RJDBC')
>>
>> //Mysql
>> drv <- 
>> JDBC("com.mysql.jdbc.Driver","C:\\Temporal\\mysql-connector-java-3.0.9-stable-bin.jar","'") 
>>
>> conn <- dbConnect(drv, "jdbc:mysql://localhost:3306/bd", "user", 
>> "password")
>>
>> //Oracle
>> drv <- 
>> JDBC("oracle.jdbc.driver.OracleDriver","C:\\Temporal\\classes12.jar","'") 
>>
>> conn <- 
>> dbConnect(drv,"jdbc:oracle:thin:@192.168.1.70:1521:SDS22","user","password") 
>>
>>
>> R always returns for oracle
>> "Error en .local(drv, ...) : Unable to connect JDBC to 
>> jdbc:oracle:thin:@192.168.1.70:1521:SDS22"
>> and for mysql
>> "Error en .local(drv, ...) : Unable to connect JDBC to 
>> jdbc:mysql://localhost:3306/bd"
>>
>> And the function summary(drv) returns:
>> JDBCDriver
>> name = JDBC
>> driver.version = 0.1-1
>> DBI.version = 0.1-1
>> client.version = NA
>> max.connections = NA
>>
>> Can you help me, please?
>>   
> Jose,
>
> This message should go to the R-help or the R-SIG-DB list.  When you 
> send it, I suggest you include your Java version, the output of a call 
> to sessionInfo(), and let folks know whether you can connect from your 
> machine using JDBC in Java.  I don't use RJDBC, so I can't help 
> directly--sorry.
>
> Sean
>

		
______________________________________________ 
LLama Gratis a cualquier PC del Mundo. 
Llamadas a fijos y m?viles desde 1 c?ntimo por minuto. 
http://es.voice.yahoo.com


From jmanuel_sierra at yahoo.es  Mon Mar  5 13:06:02 2007
From: jmanuel_sierra at yahoo.es (Jose Sierra)
Date: Mon, 05 Mar 2007 13:06:02 +0100
Subject: [Rd] RJDBC
Message-ID: <45EC07AA.4030109@yahoo.es>

I need help.

I'm trying to connect with an Oracle DBMS and MySQL DBMS, I'm using 
RJDBC package.

My code is the next:

library('rJava')
library('DBI')
library('RJDBC')

//Mysql
drv <- 
JDBC("com.mysql.jdbc.Driver","C:\\Temporal\\mysql-connector-java-3.0.9-stable-bin.jar","'")
conn <- dbConnect(drv, "jdbc:mysql://localhost:3306/bd", "user", "password")

//Oracle
drv <- 
JDBC("oracle.jdbc.driver.OracleDriver","C:\\Temporal\\classes12.jar","'")
conn <- dbConnect(drv,"jdbc:oracle:thin:@192.168.1.70:1521:SDS22","user","password")

R always returns for oracle
 "Error en .local(drv, ...) : Unable to connect JDBC to jdbc:oracle:thin:@192.168.1.70:1521:SDS22"
and for mysql
 "Error en .local(drv, ...) : Unable to connect JDBC to jdbc:mysql://localhost:3306/bd"

And the function summary(drv) returns:
JDBCDriver
name = JDBC
driver.version = 0.1-1
DBI.version = 0.1-1
client.version = NA
max.connections = NA

Can you help me, please?

Another question: 

I try to compile ROracle and RMysql for windows but i need Rdll.lib and it need R.exp. Can you give me one of this files?

 
Regards.
Jose Sierra


From oehl_list at gmx.de  Sat Mar  3 18:48:59 2007
From: oehl_list at gmx.de (oehl_list at gmx.de)
Date: Sat,  3 Mar 2007 18:48:59 +0100 (CET)
Subject: [Rd] 2 bugs in max.col() (PR#9542)
Message-ID: <20070303174859.C9C375D625@slim.kubism.ku.dk>

Dear R-Developers,

I think I found two bugs in max.col(). Ties between zeros are not broken, which might affect simulations. -Inf and Zero can be treated the same, which can give completely wrong results, e.g. when the second max is sought by replacing all maxs by -Inf. 

To fix max.col I do offer the C-code behind my function rowMax(), which also handles NAs and seems to be faster. However, since max.col() is widely used and since I only occasionally program C, I'd appreciate if someone would do code-review and (again) thorough testing before publishing it. Please note that the code was developed under R 1.6.2 and might need porting to R 2.4.1 .

Best regards


Jens Oehlschl?gel



# -- output of max.col under 2.4.1. ------------------------

> x <- rbind(c(1,1), c(0,0), c(-Inf, 0), c(0, Inf), c(0, NA), c(NA, 0))
> rownames(x) <- paste("c(", apply(x, 1, paste, collapse=","), ")")
> x
            [,1] [,2]
c( 1,1 )       1    1
c( 0,0 )       0    0
c( -Inf,0 ) -Inf    0
c( 0,Inf )     0  Inf
c( 0,NA )      0   NA
c( NA,0 )     NA    0
> 
> cat("ties not broken for c(0,0)\n")
ties not broken for c(0,0)
> cat("erroneously ties broken for c(-Inf, 0)\n")
erroneously ties broken for c(-Inf, 0)
> tmp <- sapply(1:10, function(i)max.col(x, ties.method="random"));rownames(tmp)<-rownames(x);tmp
            [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]
c( 1,1 )       2    1    2    2    1    1    1    2    1     1
c( 0,0 )       2    2    2    2    2    2    2    2    2     2
c( -Inf,0 )    2    1    1    2    2    1    2    1    1     1
c( 0,Inf )     2    2    2    2    2    2    2    2    2     2
c( 0,NA )     NA   NA   NA   NA   NA   NA   NA   NA   NA    NA
c( NA,0 )     NA   NA   NA   NA   NA   NA   NA   NA   NA    NA
> cat("The following look good\n")
The following look good
> tmp <- sapply(1:10, function(i)max.col(x, ties.method="first"));rownames(tmp)<-rownames(x);tmp
            [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]
c( 1,1 )       1    1    1    1    1    1    1    1    1     1
c( 0,0 )       1    1    1    1    1    1    1    1    1     1
c( -Inf,0 )    2    2    2    2    2    2    2    2    2     2
c( 0,Inf )     2    2    2    2    2    2    2    2    2     2
c( 0,NA )     NA   NA   NA   NA   NA   NA   NA   NA   NA    NA
c( NA,0 )     NA   NA   NA   NA   NA   NA   NA   NA   NA    NA
> tmp <- sapply(1:10, function(i)max.col(x, ties.method="last"));rownames(tmp)<-rownames(x);tmp
            [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]
c( 1,1 )       2    2    2    2    2    2    2    2    2     2
c( 0,0 )       2    2    2    2    2    2    2    2    2     2
c( -Inf,0 )    2    2    2    2    2    2    2    2    2     2
c( 0,Inf )     2    2    2    2    2    2    2    2    2     2
c( 0,NA )     NA   NA   NA   NA   NA   NA   NA   NA   NA    NA
c( NA,0 )     NA   NA   NA   NA   NA   NA   NA   NA   NA    NA

> version
               _                           
platform       i386-pc-mingw32             
arch           i386                        
os             mingw32                     
system         i386, mingw32               
status                                     
major          2                           
minor          4.1                         
year           2006                        
month          12                          
day            18                          
svn rev        40228                       
language       R                           
version.string R version 2.4.1 (2006-12-18)


# -- output of rowMax under 1.6.2 --------

> tmp <- sapply(1:10, function(i)rowMax(x, value=FALSE, na.rm=TRUE, ties.method="random"));rownames(tmp)<-rownames(x);tmp
            [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]
c( 1,1 )       2    2    2    2    1    2    2    1    1     1
c( 0,0 )       1    1    2    2    2    2    1    1    1     2
c( -Inf,0 )    2    2    2    2    2    2    2    2    2     2
c( 0,Inf )     2    2    2    2    2    2    2    2    2     2
c( 0,NA )      1    1    1    1    1    1    1    1    1     1
c( NA,0 )      2    2    2    2    2    2    2    2    2     2
> tmp <- sapply(1:10, function(i)rowMax(x, value=FALSE, na.rm=TRUE, ties.method="first"));rownames(tmp)<-rownames(x);tmp
            [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]
c( 1,1 )       1    1    1    1    1    1    1    1    1     1
c( 0,0 )       1    1    1    1    1    1    1    1    1     1
c( -Inf,0 )    2    2    2    2    2    2    2    2    2     2
c( 0,Inf )     2    2    2    2    2    2    2    2    2     2
c( 0,NA )      1    1    1    1    1    1    1    1    1     1
c( NA,0 )      2    2    2    2    2    2    2    2    2     2
> tmp <- sapply(1:10, function(i)rowMax(x, value=FALSE, na.rm=TRUE, ties.method="last"));rownames(tmp)<-rownames(x);tmp
            [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]
c( 1,1 )       2    2    2    2    2    2    2    2    2     2
c( 0,0 )       2    2    2    2    2    2    2    2    2     2
c( -Inf,0 )    2    2    2    2    2    2    2    2    2     2
c( 0,Inf )     2    2    2    2    2    2    2    2    2     2
c( 0,NA )      1    1    1    1    1    1    1    1    1     1
c( NA,0 )      2    2    2    2    2    2    2    2    2     2



# -- replication ----------

x <- rbind(c(1,1), c(0,0), c(-Inf, 0), c(0, Inf), c(0, NA), c(NA, 0))
rownames(x) <- paste("c(", apply(x, 1, paste, collapse=","), ")")
x

cat("ties not broken for c(0,0)\n")
cat("erroneously ties broken for c(-Inf, 0)\n")
tmp <- sapply(1:10, function(i)max.col(x, ties.method="random"));rownames(tmp)<-rownames(x);tmp
cat("The following look good\n")
tmp <- sapply(1:10, function(i)max.col(x, ties.method="first"));rownames(tmp)<-rownames(x);tmp
tmp <- sapply(1:10, function(i)max.col(x, ties.method="last"));rownames(tmp)<-rownames(x);tmp

# rowMax under R 1.6.2
tmp <- sapply(1:10, function(i)rowMax(x, value=FALSE, na.rm=TRUE, ties.method="random"));rownames(tmp)<-rownames(x);tmp
tmp <- sapply(1:10, function(i)rowMax(x, value=FALSE, na.rm=TRUE, ties.method="first"));rownames(tmp)<-rownames(x);tmp
tmp <- sapply(1:10, function(i)rowMax(x, value=FALSE, na.rm=TRUE, ties.method="last"));rownames(tmp)<-rownames(x);tmp


# -- R 1.6.2 -----------

## Copyright 2003-2007 Jens Oehlschl?gel
## May be used (possibly modified) with name "max.col" under GPL
## Provided "as is"
## Use at own risk

rowMax <- function(x, value=TRUE, index=NULL, na.rm=FALSE, ties.method = c("random", "first", "last"), use.names=FALSE){
  if (!length(x))
    stop("x has no length")
  d <- dim(x)
  if (!is.null(index) && !identical(d, dim(index)))
      stop("index has wrong dimension")
  if (length(d)!=2)
    stop("x must be a matrix")
  if (is.na(value) || !value){
    ties.method <- pmatch(ties.method, c("random", "first", "last"))
    if (is.na(ties.method))
      stop("illegal ties method")
    ret <- .C("R_row_maxwithindex_double"
    , x=as.double(x)
    , nr=d[1]
    , nc=d[2]
    , narm = as.integer(na.rm)
    , index=integer(d[1])
    , tiesmethod=as.integer(ties.method)
    , NAOK = TRUE, DUP = FALSE, PACKAGE = "base")[c("index")]
    i <- cbind(seq(length=d[1]), ret$index)
    if (is.na(value))
      ret$value <- x[i]
    if (!is.null(index))
      ret$index <- index[i]
    if (is.na(value)){
      if (use.names){
        names(ret$index) <- dimnames(x)[1]
        names(ret$values) <- dimnames(x)[1]
      }
      return(ret)
    }else{
      if (use.names){
        names(ret$index) <- dimnames(x)[1]
      }
      return(ret$index)
    }
  }else{
    ret <- .C("R_row_max_double"
    , x=as.double(x)
    , nr=d[1]
    , nc=d[2]
    , narm = as.integer(na.rm)
    , values=double(d[1])
    , NAOK = TRUE, DUP = FALSE, PACKAGE = "base")["values"]
    if (use.names){
      names(ret$values) <- dimnames(x)[1]
    }
    return(ret$values)
  }
}


# -- C --------------

// Author: Jens Oehlschl?gel
// Date:   3.3.2007
// Provided 'as is' under GPL
// Use at own risk

#include <R_ext/Arith.h>        /* NA handling */
#include <Rmath.h>              /* probably not needed */
#include <R_ext/Random.h>       /* ..RNGstate */
#include <R_ext/Applic.h>       /* NA handling */
#include <R_ext/Utils.h>      /* probably not needed */

#define RELTOL 1e-5


void R_row_maxwithindex_double(
  double *x
, int *nr
, int *nc
, int *narm
, int *index
, int *tiesmethod
)
{
    int   r, c, m, ntie, n_r = *nr, n_c = *nc, na_rm = *narm, ties_method = *tiesmethod;
    double a = 0; // to avoid uninitialized compiler warning
    double b, tol, small, absa;
    Rboolean isna;
    if (ties_method==1)
      GetRNGstate();

    for (r = 0; r < n_r; r++) {
        /* first check row for any NAs and find the smallst entry */
        small = R_PosInf;
        if (na_rm){
          isna = TRUE;
          for (c = 0; c < n_c; c++){
              a = x[r + c * n_r];
              if (!ISNAN(a)) {
                isna = FALSE;
                absa = fabs(a);
                if (absa<small && absa!=0)
                  small = absa;
              }
          }
        }else{
          isna = FALSE;
          for (c = 0; c < n_c; c++) {
              a = x[r + c * n_r];
              if (ISNAN(a)) {
                 isna = TRUE;
                 break;
              }else{
                absa = fabs(a);
                if (absa<small && absa!=0)
                  small = absa;
              }
          }
        }
        if (isna) {
          index[r] = NA_INTEGER;
        }else{
          if (R_FINITE(small))
            tol = RELTOL * small;
          else
            tol = 0;
          //Rprintf("small=%g tol=%g\n", small, tol);
          // the following loop has two parts
          // 1) find non-NA
          // 2) find extreme (and don't ask  ISNAN anymore)
          m = NA_INTEGER;
          ntie = 1;
          for (c = 0; c < n_c; c++) {
            a = x[r + c * n_r];
            if (!ISNAN(a)){
              m = c;
              break;
            }
          }
          for (c++; c < n_c; c++) {
              b = x[r + c * n_r];
              //Rprintf("a-tol=%g a=%g a+tol=%g b=%g\n", a-tol, a, a+tol, b);
              if (b > a + tol){   // MASS had >= here, which does not tie zeros and Inf
                  ntie = 1;
                  a = b;
                  m = c;
              } else if (b >= a - tol) {
                  if (ties_method==1){
                    ntie++;
                    if (ntie * unif_rand() < 1.) m = c;
                  }else if (ties_method==3){
                    m=c;
                  }
              }
          }
          index[r] = m + 1;
        }
    }
    if (ties_method==1)
      PutRNGstate();
}


void R_row_max_double(double *x, int *nr, int *nc, int *narm, double *values)
{
    int   r, c, n_r = *nr, n_c = *nc, na_rm = *narm;
    double e, extreme;
    Rboolean isna;

    for (r = 0; r < n_r; r++) {
        /* first check row for any NAs and find the largest entry */
        extreme = R_NegInf;
        isna = FALSE;
        for (c = 0; c < n_c; c++) {
            e = x[r + c * n_r];
            if (ISNAN(e)){
                if (!na_rm){
                    isna = TRUE;
                    break;
                }
            }else if (e>extreme){
                extreme = e;
            }

        }
        if (isna)
            values[r] = NA_REAL;
        else
            values[r] = extreme;
    }
}

-- 
"Feel free" - 10 GB Mailbox, 100 FreeSMS/Monat ...
Jetzt GMX TopMail testen: www.gmx.net/de/go/mailfooter/topmail-out


From Greg.Snow at intermountainmail.org  Mon Mar  5 17:07:56 2007
From: Greg.Snow at intermountainmail.org (Greg Snow)
Date: Mon, 5 Mar 2007 09:07:56 -0700
Subject: [Rd] extracting rows from a data frame by looping over the row
 names: performance issues
In-Reply-To: <45E8D78D.20003@fhcrc.org>
Message-ID: <07E228A5BE53C24CAD490193A7381BBB87996D@LP-EXCHVS07.CO.IHC.COM>

The difference is in indexing by row number vs. indexing by row name.
It has long been known that names slow matricies down, some routines
make a copy of dimnames of a matrix, remove the dimnames, do the
computations with the matrix, then put the dimnames back on.  This can
speed things up quite a bit in some circumstances.  For your example,
indexing by number means jumping to a specific offset in the matrix,
indexing by name means searching through all the names and doing string
comparisons to find the match.  A 300 fold difference in speed is not
suprising.



-- 
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at intermountainmail.org
(801) 408-8111
 
 

> -----Original Message-----
> From: Herve Pages [mailto:hpages at fhcrc.org] 
> Sent: Friday, March 02, 2007 7:04 PM
> To: Greg Snow
> Cc: r-devel at r-project.org
> Subject: Re: [Rd] extracting rows from a data frame by 
> looping over the row names: performance issues
> 
> Hi Greg,
> 
> Greg Snow wrote:
> > Your 2 examples have 2 differences and they are therefore 
> confounded 
> > in their effects.
> > 
> > What are your results for:
> > 
> > system.time(for (i in 1:100) {row <-  dat[i, ] })
> > 
> > 
> > 
> 
> Right. What you suggest is even faster (and more simple):
> 
>   > mat <- matrix(rep(paste(letters, collapse=""), 5*300000), ncol=5)
>   > dat <- as.data.frame(mat)
> 
>   > system.time(for (key in row.names(dat)[1:100]) { row <- 
> dat[key, ] })
>      user  system elapsed
>    13.241   0.460  13.702
> 
>   > system.time(for (i in 1:100) { row <- sapply(dat, 
> function(col) col[i]) })
>      user  system elapsed
>     0.280   0.372   0.650
> 
>   > system.time(for (i in 1:100) {row <-  dat[i, ] })
>      user  system elapsed
>     0.044   0.088   0.130
> 
> So apparently here extracting with dat[i, ] is 300 times 
> faster than extracting with dat[key, ] !
> 
> > system.time(for (i in 1:100) dat["1", ])
>    user  system elapsed
>  12.680   0.396  13.075
> 
> > system.time(for (i in 1:100) dat[1, ])
>    user  system elapsed
>   0.060   0.076   0.137
> 
> Good to know!
> 
> Thanks a lot,
> H.
> 
> 
>


From simon.urbanek at r-project.org  Mon Mar  5 17:54:12 2007
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Mon, 5 Mar 2007 11:54:12 -0500
Subject: [Rd] RJDBC
In-Reply-To: <45EC0F6A.20309@integromics.com>
References: <45EC0F6A.20309@integromics.com>
Message-ID: <642D1D67-5003-4566-9FC5-81E01B8EB322@r-project.org>

Jose,

On Mar 5, 2007, at 7:39 AM, Jose Sierra wrote:

> I need help.
>
> I'm trying to connect with an Oracle DBMS and MySQL DBMS, I'm using
> RJDBC package.
>
> My code is the next:
>
> library('rJava')
> library('DBI')
> library('RJDBC')
>
> //Mysql
> drv <-
> JDBC("com.mysql.jdbc.Driver","C:\\Temporal\\mysql-connector- 
> java-3.0.9-stable-bin.jar","'")
>
> conn <- dbConnect(drv, "jdbc:mysql://localhost:3306/bd", "user",
> "password")
>
> //Oracle
> drv <-
> JDBC("oracle.jdbc.driver.OracleDriver","C:\\Temporal\ 
> \classes12.jar","'")
> conn <-
> dbConnect 
> (drv,"jdbc:oracle:thin:@192.168.1.70:1521:SDS22","user","password")
>
>
> R always returns for oracle
> "Error en .local(drv, ...) : Unable to connect JDBC to
> jdbc:oracle:thin:@192.168.1.70:1521:SDS22"
> and for mysql
> "Error en .local(drv, ...) : Unable to connect JDBC to
> jdbc:mysql://localhost:3306/bd"
>

It is very likely a problem with your DB connection or  
authentication. I have tested it with MySQL (I don't have Oracle) and  
it worked without problems. Please test it step-by-step to make sure  
that your DB is configured properly.

Unfortunately RJDBC doesn't pass non-fatal SQL errors back to the  
user, so connection problems are not easy to debug, but you can try  
this to show the connection problem:

dbCheck = function(url, user='', pwd='') {
  j = .jcall("java/sql/DriverManager", "Ljava/sql/Connection;",  
"getConnection", url, user, pwd, check=FALSE)
  x = .jgetEx()
  .jcheck()
  x
}

and use it like this:

 > dbCheck("jdbc:mysql://localhost/foo","user","pwd")
[1] "Java-Object{java.sql.SQLException: Access denied for user  
'user'@'localhost' (using password: YES)}"
 >
 > dbCheck("jdbc:mysql://localhost/foo","root","")
[1] "Java-Object{java.sql.SQLException: Unknown database 'foo'}"
 > dbCheck("jdbc:mysql://bar/foo","root","")

I'll see if I can provide some more helpful response in the dbConnect  
for the next release..


> Another question:
> I try to compile ROracle and RMysql for windows but i need Rdll.lib  
> and  it need R.exp.

No, you don't need those files, because R is linked directly. Simply  
follow the instructions for building R packages on Windows.

Cheers,
Simon


From piotr2.chmielowski at citigroup.com  Mon Mar  5 18:05:43 2007
From: piotr2.chmielowski at citigroup.com (Chmielowski, Piotr2 [CAI])
Date: Mon, 5 Mar 2007 12:05:43 -0500
Subject: [Rd] non-blocking socketConnection
Message-ID: <617C6D86F3B78E44B37B5949CF1F8B0105942A4F@EXNJMB20.nam.nsroot.net>

In an R session I have

> c <-socketConnection("localhost", port=6011, blocking=F, server=T,
open="w+")

After I connect to the  server from, say, telnet 

% telnet localhost 6011

the socketConnection returns and gives a valid c. 

My problem is as follows : I would expect something like 

> readLines(con=c, n=1)

 to return immediately when reading from c non-blocking c, whether there
are any contents to be read or not. However, readLines only returns when
there is some input to be consumed, ie if in the telnet session I type
foo followed by newline. In short, readLines seems to be blocking even
though the connection is presumably non-blocking.

FYI, A "file" connection does behave as expected, but I do need the
socketConnection here. I am Running R 2.2.0-2.fc4, on Linux
2.6.11-1.1369.

Any help would be greatly appreciated.


From murdoch at stats.uwo.ca  Mon Mar  5 18:41:49 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Mon, 05 Mar 2007 12:41:49 -0500
Subject: [Rd] typo in R-lang.texi
In-Reply-To: <17889.27067.556027.967012@notch.damtp.cam.ac.uk>
References: <17889.27067.556027.967012@notch.damtp.cam.ac.uk>
Message-ID: <45EC565D.6040500@stats.uwo.ca>

On 2/25/2007 5:49 AM, Stephen Eglen wrote:
> Hi, 
> 
> R-lang.texi line 2020/1 currently says:
> 
>   This allows, e.g., a 
>   local variable in a function to have the same name AS a global object. 
> 
> The word "AS" is missing in that sentence.
> 
> (Line number according to
>  https://svn.r-project.org/R/trunk/doc/manual/R-lang.texi)

Fixed, thanks.

Duncan Murdoch


From murdoch at stats.uwo.ca  Mon Mar  5 18:43:34 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Mon, 05 Mar 2007 12:43:34 -0500
Subject: [Rd] typo in nls.Rd
In-Reply-To: <Pine.GSO.4.56.0702261153330.24809@laurel.few.vu.nl>
References: <Pine.GSO.4.56.0702261153330.24809@laurel.few.vu.nl>
Message-ID: <45EC56C6.2090902@stats.uwo.ca>

On 2/26/2007 6:43 AM, Katharine Mullen wrote:
 > in R version 2.5.0 Under development (unstable) (2007-02-25 r40804),
 > the `formula' entry in the `arguments' section of nls.Rd (L25-26) reads
 >
 > \item{formula}{a nonlinear model \link{formula} including variables and
 >     parameters.  Will be coerced to a formula is necessary.}
 >
 > `is' should be `if'.

Fixed, thanks.

Duncan Murdoch


From murdoch at stats.uwo.ca  Mon Mar  5 18:45:25 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Mon, 05 Mar 2007 12:45:25 -0500
Subject: [Rd] typo in reshape.Rd
In-Reply-To: <d143a33585413d77d0aa4400d69b8f6d@charter.net>
References: <d143a33585413d77d0aa4400d69b8f6d@charter.net>
Message-ID: <45EC5735.5060302@stats.uwo.ca>

On 2/28/2007 11:41 PM, Stephen D. Weigand wrote:
> The 3 lines below are from paragraph 4 of \details in reshape.Rd.
> In line [2], a space is needed before "where" and the "to" at the
> end of the line should be removed.
> 
> [1]these names.  The default is variable names like \code{x.1},
> [2]\code{x.2},where \code{split=list(regexp="\\.",include=FALSE)} to
> [3]specifies to split at the dot and drop it from the name. To have 
> alphabetic

Fixed, thanks.

Duncan Murdoch


From simon.urbanek at r-project.org  Mon Mar  5 19:17:25 2007
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Mon, 5 Mar 2007 13:17:25 -0500
Subject: [Rd] non-blocking socketConnection
In-Reply-To: <617C6D86F3B78E44B37B5949CF1F8B0105942A4F@EXNJMB20.nam.nsroot.net>
References: <617C6D86F3B78E44B37B5949CF1F8B0105942A4F@EXNJMB20.nam.nsroot.net>
Message-ID: <739CEED1-ADDA-4D1F-A4D3-1222B43CF69E@r-project.org>


On Mar 5, 2007, at 12:05 PM, Chmielowski, Piotr2 [CAI] wrote:

> In an R session I have
>
>> c <-socketConnection("localhost", port=6011, blocking=F, server=T,
> open="w+")
>
> After I connect to the  server from, say, telnet
>
> % telnet localhost 6011
>
> the socketConnection returns and gives a valid c.
>
> My problem is as follows : I would expect something like
>
>> readLines(con=c, n=1)
>
>  to return immediately when reading from c non-blocking c, whether  
> there
> are any contents to be read or not. However, readLines only returns  
> when
> there is some input to be consumed, ie if in the telnet session I type
> foo followed by newline. In short, readLines seems to be blocking even
> though the connection is presumably non-blocking.
>
> FYI, A "file" connection does behave as expected, but I do need the
> socketConnection here. I am Running R 2.2.0-2.fc4, on Linux
> 2.6.11-1.1369.
>
> Any help would be greatly appreciated.
>

if (socketSelect(list(c),,0)) readLines(c, 1)

Cheers,
Simon


From cstrato at aon.at  Mon Mar  5 21:41:36 2007
From: cstrato at aon.at (cstrato)
Date: Mon, 05 Mar 2007 21:41:36 +0100
Subject: [Rd] Problem using callNextMethod() in S4
In-Reply-To: <6phwt1wcpuh.fsf@gopher4.fhcrc.org>
References: <45EAF340.50707@aon.at>
	<m2odn8apol.fsf@ziti.local>	<45EB1541.2020308@aon.at>
	<6phwt1wcpuh.fsf@gopher4.fhcrc.org>
Message-ID: <45EC8080.80707@aon.at>

Dear Martin

Thank you for this extensive explanation!
I hope that I have understood it, but I will realize it as I proceed with my
package. Now, my example works as I have expected it to work, great!

One problem that I face is lack of extensive explanation of S4 classes,
especially with respect to inheritance.  (Neither the tutorial "S4 Classes
in 15 pages" nor the book "S Programming" are really helpful.) Most
of the time I study the code in BioBase and affy, since there are not
many packages available using S4 and inheritance.
Your explanation below is a good example, how a good S4 tutorial
should cover these issues.

Best regards
Christian

Martin Morgan wrote:
> In this method...
>
> setMethod("initialize", "baseClass",
>    function(.Object, ...) {
> print("---initialize:baseClass---")
> #    .Object <- callNextMethod();
>       strg <- .Object at mydir;
> print(paste("base:strg = ", strg))
>       if (strg == "") {
>          .Object at mydir <- as.character(getwd());
>       }#if
>       if (substr(strg, nchar(strg), nchar(strg)) == "/") {
>          .Object at mydir <- substr(strg, 0, nchar(strg)-1);
>       }#if
> print(paste("base:mydir = ", .Object at mydir))
>     .Object <- callNextMethod();
>     .Object;
>    }
> )#initialize
>
> the argument '...' includes the argument mydir="". Later, when you
> .Object <- callNextMethod(), it invokes the 'next' method with the
> same argument, i.e., with mydir="". This causes the 'mydir' slot to be
> initialized with "", triggering the validity error. You can see this
> more clearly in the following, where the provided argument x=10:1
> overrides the assignment in initialize:
>
>   
>> setClass("A", representation=representation(x="numeric"))
>>     
> [1] "A"
>   
>> setMethod("initialize", "A",
>>     
> +           function(.Object, ...) {
> +               .Object at x <- 1:10
> +               callNextMethod()
> +           })
> [1] "initialize"
>
>   
>> new("A", x=10:1)
>>     
> An object of class "A"
> Slot "x":
>  [1] 10  9  8  7  6  5  4  3  2  1
>
> One solution is to name any arguments you're going to manipulate in
> the initialize method, and then make sure the correct arguments are
> passed to callNextMethod. You'll probably want to provide a sensible
> default argument to mydir, so that user doesn't have to do anything
> clever (like remember to pass "") to get the default behavior. Here's
> what I end up with:
>
> setMethod("initialize", "baseClass",
>           function(.Object, mydir=as.character(getwd()), ...) {
>               if (substr(mydir, nchar(mydir), nchar(mydir)) == "/") {
>                   mydir <- substr(mydir, 0, nchar(mydir)-1)
>               }
>               callNextMethod(.Object, mydir=mydir, ...);
>           })
>
> setMethod("initialize", "derivedClass",
>           function(.Object, mytitle="MyTitle", ...) {
>               callNextMethod(.Object, mytitle=mytitle, ...)
>           })
>
> Another solution is to follow the convention where callNextMethod()
> comes first (constructing a valid object!), and your initialize method
> then fills in slots with the appropriate values.
>
> One interesting part of your example is that new('derivedClass') does
> NOT cause a validity error, even though the object is invalid
> ('myname' is ""; also, none of your validity method messages are
> printed)! Apparently, the assumption is that you (the programmer, as
> opposed to the user) are not going to create an invalid object by
> default.
>
> Also, take a look at the initialize method that R has constructed for
> derivedClass:
>
>   
>> getMethod("initialize", "derivedClass")
>>     
> Method Definition:
>
> function (.Object, ...) 
> {
>     .local <- function (.Object, mytitle = "MyTitle", ...) 
>     {
>         callNextMethod(.Object, mytitle = mytitle, ...)
>     }
>     .local(.Object, ...)
> }
>
> Signatures:
>         .Object       
> target  "derivedClass"
> defined "derivedClass"
>
> Notice how the function is defined in terms of .Object and .... The
> named arguments not present in the generic signature (i.e., 'mytitle')
> are 'hidden' in the .local function definition. By the time
> callNextMethod() has been evaluated, '...' does NOT include
> 'mytitle'. I think this is why you must explicitly include any named
> arguments you want to pass to callNextMethod -- the default is to
> callNextMethod with the generic signature, but with symbols (.Object,
> ...) taking their current value. Here's a simpler illustration:
>
> setClass("A", representation=representation(x="numeric"))
> setMethod("initialize", "A",
>           function(.Object, x, ...) callNextMethod())
>
> This leads to the perhaps unexpected outcome
>
>   
>> new("A", x=10:1)
>>     
> An object of class "A"
> Slot "x":
> numeric(0)
>
> I say unexpected because, if there was no initialize method, or if the
> initialize method were written without 'x' in the signature, then the
> argument 'x' would be used to fill the slot:x.
>
> Here's the solution like that for baseClass, above:
>
> setMethod("initialize", "A",
>           function(.Object, x, ...)
>           callNextMethod(.Object, x=x, ...))
>
> ...which leads to
>
>   
>> new("A", x=10:1)
>>     
> An object of class "A"
> Slot "x":
>  [1] 10  9  8  7  6  5  4  3  2  1
>
> Hope that helps,
>
> Martin
>
>


From hb at stat.berkeley.edu  Mon Mar  5 22:00:43 2007
From: hb at stat.berkeley.edu (Henrik Bengtsson)
Date: Mon, 5 Mar 2007 13:00:43 -0800
Subject: [Rd] Periods in package names?
Message-ID: <59d7961d0703051300y38374e06jcbf241d7eb1bc9a@mail.gmail.com>

Hi,

is it ok to have more than one period in a package name, e.g. aroma.light.bioc?

I remember there was once a limitation/a recommendation that one
should use at most one period in a package name.  I just browsed
"Writing R Extensions" (for R v2.4.1) and scanned it for words
"period" and "dot", and I cannot find this limitation anymore, but
only:

"The Package and Version fields give the name and the version of the
package, respectively. The name should consist of letters, numbers,
and the dot character and start with a letter. [...]"

Best

Henrik


From Kurt.Hornik at wu-wien.ac.at  Mon Mar  5 22:29:06 2007
From: Kurt.Hornik at wu-wien.ac.at (Kurt Hornik)
Date: Mon, 5 Mar 2007 22:29:06 +0100
Subject: [Rd] fortune() in .Rprofile conflicts with R CMD INSTALL
In-Reply-To: <17899.65192.532067.867254@mithrandir.hornik.net>
References: <45EAB839.9090203@bfro.uni-lj.si> <m2tzx19e3l.fsf@ziti.local>
	<loom.20070304T230316-753@post.gmane.org>
	<17899.65192.532067.867254@mithrandir.hornik.net>
Message-ID: <17900.35746.713592.701130@mithrandir.hornik.net>

>>>>> Kurt Hornik writes:

>>>>> Gregor Gorjanc writes:
>> Seth Falcon <sfalcon <at> fhcrc.org> writes:
>>> The quick fix for you is, I believe,
>>> 
>>> if (interactive()) {
>>> library(fortunes)
>>> fortune()
>>> detach("package:fortunes")
>>> }
>>> 
>>> Whether something could be changed so that R's output doesn't confuse
>>> itself and gcc when doing R CMD INSTALL, seems like it should be
>>> possible.

>> Yes, this solves my! problem. I do not know what is causing this
>> behaviour.

> Well, r-devel's src/scripts/INSTALL.in now has

> if test -z "${lib}"; then
>   lib=`echo "cat(.libPaths()[1])" | \
>     R_DEFAULT_PACKAGES=NULL "${R_EXE}" --no-save --slave`
>   message "Installing to library '$lib'"

> so we need to find a way to "just get" the result of cat(.libPaths()[1])
> into $lib as intended.

> One idea might be ensuring that this gets into the last line on its own,
> and then taking $lib as the last line of what we got ...

I think I found (and committed) a solution for this.

Best
-k


From thomas.friedrichsmeier at ruhr-uni-bochum.de  Tue Mar  6 15:03:38 2007
From: thomas.friedrichsmeier at ruhr-uni-bochum.de (thomas.friedrichsmeier at ruhr-uni-bochum.de)
Date: Tue,  6 Mar 2007 15:03:38 +0100 (CET)
Subject: [Rd] Wish: Option to configure the default par() (PR#9545)
Message-ID: <20070306140338.CE3F65D608@slim.kubism.ku.dk>

Full_Name: Thomas Friedrichsmeier
Version: 2.4.1
OS: linux (Debian unstable)
Submission from: (NULL) (84.60.113.185)


Summary: It would be nice to have a centralized option for setting default par()
options for all devices and all plots. This would ease producing graphs in a
customized but consistent way. Suggesting options("par.default").

Example problem: Make all graphs look like

par(bg="light gray", las=2)

both on screen and for various produced file formats such as png() and
postscript().

Current situation: To solve the example problem, two approaches come to mind:
1) Always call par() before the next plot. This could be wrapped into a function
to make it easier to stay consistent. E.g.:

postscript()
myDefaultPar()       # calls par(bg="light gray", las=2)
plot(...)

2) Create wrappers for all devices of interest, like e.g. (not quite correct,
but good enough for this example):

myX11 <- function(...) {
  X11(...)
  par(bg="light gray", las=2)
}

Both solutions work, but are not entirely elegant. The drawback of 1) is that
you still need to add the given line manually at all places. The drawback of 2)
is that a similar wrapper will have to be created (and used) for each different
device.

Wish:
Add a new option: options("par.default"), similar to the existing
options("par.ask.default"). This option would accept a list of all par settings
to set a custom default for:

options(par.default=list(bg="light gray", las=2))

par() options specified while creating the device, in calls to plot() or in
subsequent calls to par() would take precendence over options("par.default").


From Greg.Snow at intermountainmail.org  Tue Mar  6 17:56:11 2007
From: Greg.Snow at intermountainmail.org (Greg Snow)
Date: Tue, 6 Mar 2007 09:56:11 -0700
Subject: [Rd] Wish: Option to configure the default par() (PR#9545)
In-Reply-To: <20070306140338.CE3F65D608@slim.kubism.ku.dk>
Message-ID: <07E228A5BE53C24CAD490193A7381BBB879B60@LP-EXCHVS07.CO.IHC.COM>

Another approach may be to use hooks (see ?setHook).  The plot.new
function already has a hook, so you could do your option #1
automatically by setting that hook.

Better would be if all the graphics device functions had hooks (or a
common hook), then you could set that hook to set your graphics
parameters and they would be set every time a new graphics device was
started.

-- 
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at intermountainmail.org
(801) 408-8111
 
 

> -----Original Message-----
> From: r-devel-bounces at r-project.org 
> [mailto:r-devel-bounces at r-project.org] On Behalf Of 
> thomas.friedrichsmeier at ruhr-uni-bochum.de
> Sent: Tuesday, March 06, 2007 7:04 AM
> To: r-devel at stat.math.ethz.ch
> Cc: R-bugs at biostat.ku.dk
> Subject: [Rd] Wish: Option to configure the default par() (PR#9545)
> 
> Full_Name: Thomas Friedrichsmeier
> Version: 2.4.1
> OS: linux (Debian unstable)
> Submission from: (NULL) (84.60.113.185)
> 
> 
> Summary: It would be nice to have a centralized option for 
> setting default par() options for all devices and all plots. 
> This would ease producing graphs in a customized but 
> consistent way. Suggesting options("par.default").
> 
> Example problem: Make all graphs look like
> 
> par(bg="light gray", las=2)
> 
> both on screen and for various produced file formats such as 
> png() and postscript().
> 
> Current situation: To solve the example problem, two 
> approaches come to mind:
> 1) Always call par() before the next plot. This could be 
> wrapped into a function to make it easier to stay consistent. E.g.:
> 
> postscript()
> myDefaultPar()       # calls par(bg="light gray", las=2)
> plot(...)
> 
> 2) Create wrappers for all devices of interest, like e.g. 
> (not quite correct, but good enough for this example):
> 
> myX11 <- function(...) {
>   X11(...)
>   par(bg="light gray", las=2)
> }
> 
> Both solutions work, but are not entirely elegant. The 
> drawback of 1) is that you still need to add the given line 
> manually at all places. The drawback of 2) is that a similar 
> wrapper will have to be created (and used) for each different device.
> 
> Wish:
> Add a new option: options("par.default"), similar to the 
> existing options("par.ask.default"). This option would accept 
> a list of all par settings to set a custom default for:
> 
> options(par.default=list(bg="light gray", las=2))
> 
> par() options specified while creating the device, in calls 
> to plot() or in subsequent calls to par() would take 
> precendence over options("par.default").
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From Greg.Snow at intermountainmail.org  Tue Mar  6 17:56:44 2007
From: Greg.Snow at intermountainmail.org (Greg.Snow at intermountainmail.org)
Date: Tue,  6 Mar 2007 17:56:44 +0100 (CET)
Subject: [Rd] Wish: Option to configure the default par() (PR#9545)
Message-ID: <20070306165644.610345AD64@slim.kubism.ku.dk>

Another approach may be to use hooks (see ?setHook).  The plot.new
function already has a hook, so you could do your option #1
automatically by setting that hook.

Better would be if all the graphics device functions had hooks (or a
common hook), then you could set that hook to set your graphics
parameters and they would be set every time a new graphics device was
started.

--=20
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at intermountainmail.org
(801) 408-8111
=20
=20

> -----Original Message-----
> From: r-devel-bounces at r-project.org=20
> [mailto:r-devel-bounces at r-project.org] On Behalf Of=20
> thomas.friedrichsmeier at ruhr-uni-bochum.de
> Sent: Tuesday, March 06, 2007 7:04 AM
> To: r-devel at stat.math.ethz.ch
> Cc: R-bugs at biostat.ku.dk
> Subject: [Rd] Wish: Option to configure the default par() (PR#9545)
>=20
> Full_Name: Thomas Friedrichsmeier
> Version: 2.4.1
> OS: linux (Debian unstable)
> Submission from: (NULL) (84.60.113.185)
>=20
>=20
> Summary: It would be nice to have a centralized option for=20
> setting default par() options for all devices and all plots.=20
> This would ease producing graphs in a customized but=20
> consistent way. Suggesting options("par.default").
>=20
> Example problem: Make all graphs look like
>=20
> par(bg=3D"light gray", las=3D2)
>=20
> both on screen and for various produced file formats such as=20
> png() and postscript().
>=20
> Current situation: To solve the example problem, two=20
> approaches come to mind:
> 1) Always call par() before the next plot. This could be=20
> wrapped into a function to make it easier to stay consistent. E.g.:
>=20
> postscript()
> myDefaultPar()       # calls par(bg=3D"light gray", las=3D2)
> plot(...)
>=20
> 2) Create wrappers for all devices of interest, like e.g.=20
> (not quite correct, but good enough for this example):
>=20
> myX11 <- function(...) {
>   X11(...)
>   par(bg=3D"light gray", las=3D2)
> }
>=20
> Both solutions work, but are not entirely elegant. The=20
> drawback of 1) is that you still need to add the given line=20
> manually at all places. The drawback of 2) is that a similar=20
> wrapper will have to be created (and used) for each different device.
>=20
> Wish:
> Add a new option: options("par.default"), similar to the=20
> existing options("par.ask.default"). This option would accept=20
> a list of all par settings to set a custom default for:
>=20
> options(par.default=3Dlist(bg=3D"light gray", las=3D2))
>=20
> par() options specified while creating the device, in calls=20
> to plot() or in subsequent calls to par() would take=20
> precendence over options("par.default").
>=20
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>=20



From Stephanie.Mahevas at ifremer.fr  Tue Mar  6 18:15:21 2007
From: Stephanie.Mahevas at ifremer.fr (Stephanie.Mahevas at ifremer.fr)
Date: Tue,  6 Mar 2007 18:15:21 +0100 (CET)
Subject: [Rd] parse error with if else (PR#9551)
Message-ID: <20070306171521.CC6C25D5F7@slim.kubism.ku.dk>

Full_Name: Stephanie MAHEVAS
Version: 2.4.1
OS: Windows NT
Submission from: (NULL) (134.246.55.50)



the two following instructions provide a synthax  error :

if ( 5 > 4 ) cat("ok1")
else cat("ok2")

and

if ( 5 > 4 ){ cat("ok1")}
else cat("ok2")

whereas these ones don't

if ( 5 > 4 ) cat("ok1") else cat("ok2")

and

if ( 5 > 4 ){ cat("ok1")
}else cat("ok2")

It looks like a parser problem. If else is not on the same line as if or if the
end of block statement of if } is not paste to else, else does not seem linked
with if


From ligges at statistik.uni-dortmund.de  Tue Mar  6 19:33:36 2007
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 06 Mar 2007 19:33:36 +0100
Subject: [Rd] parse error with if else (PR#9551)
In-Reply-To: <20070306171521.CC6C25D5F7@slim.kubism.ku.dk>
References: <20070306171521.CC6C25D5F7@slim.kubism.ku.dk>
Message-ID: <45EDB400.1070206@statistik.uni-dortmund.de>



Stephanie.Mahevas at ifremer.fr wrote:
> Full_Name: Stephanie MAHEVAS
> Version: 2.4.1
> OS: Windows NT
> Submission from: (NULL) (134.246.55.50)
> 
> 
> 
> the two following instructions provide a synthax  error :
> 
> if ( 5 > 4 ) cat("ok1")
> else cat("ok2")

This is not a bug!

Since you are allowed to omit the else, R cannot know whether you want 
to provide it and thinks you have finished, since
     if ( 5 > 4 ) cat("ok1")
already is a valid and complete expression.
Therefore
     else cat("ok2")
is a *new* expression which obviously is not valid without if() before.

If you want that R looks at the whole at first, either do as below or 
make it a whole expression by putting it into braces as in:

{
     if ( 5 > 4 ) cat("ok1")
     else cat("ok2")
}


Uwe Ligges




> and
> 
> if ( 5 > 4 ){ cat("ok1")}
> else cat("ok2")
> 
> whereas these ones don't
> 
> if ( 5 > 4 ) cat("ok1") else cat("ok2")
> 
> and
> 
> if ( 5 > 4 ){ cat("ok1")
> }else cat("ok2")
> 
> It looks like a parser problem. If else is not on the same line as if or if the
> end of block statement of if } is not paste to else, else does not seem linked
> with if
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From murdoch at stats.uwo.ca  Tue Mar  6 19:35:35 2007
From: murdoch at stats.uwo.ca (murdoch at stats.uwo.ca)
Date: Tue,  6 Mar 2007 19:35:35 +0100 (CET)
Subject: [Rd] parse error with if else (PR#9551)
Message-ID: <20070306183535.90BE95D5F7@slim.kubism.ku.dk>

On 3/6/2007 12:15 PM, Stephanie.Mahevas at ifremer.fr wrote:
> Full_Name: Stephanie MAHEVAS
> Version: 2.4.1
> OS: Windows NT
> Submission from: (NULL) (134.246.55.50)
> 
> 
> 
> the two following instructions provide a synthax  error :
> 
> if ( 5 > 4 ) cat("ok1")
> else cat("ok2")
> 
> and
> 
> if ( 5 > 4 ){ cat("ok1")}
> else cat("ok2")
> 
> whereas these ones don't
> 
> if ( 5 > 4 ) cat("ok1") else cat("ok2")
> 
> and
> 
> if ( 5 > 4 ){ cat("ok1")
> }else cat("ok2")
> 
> It looks like a parser problem. If else is not on the same line as if or if the
> end of block statement of if } is not paste to else, else does not seem linked
> with if

This is a documented "feature" of the language, not a bug.  (See the 
language guide, section 3.2.1 "if", around the 4th paragraph.)

It arises because R tries to evaluate a statement as soon as it is 
complete, and

if ( 5 > 4 ) cat("ok1")

is a complete statement.  You can get the behaviour you want by wrapping 
the whole think in curly brackets so that R doesn't start evaluating too 
early, e.g.

 > {
+  if ( 5 > 4 ) cat("ok1")
+  else cat("ok2")
+ }
ok1>

Duncan Murdoch


From peter-m.schumacher at db.com  Tue Mar  6 21:18:42 2007
From: peter-m.schumacher at db.com (peter-m.schumacher at db.com)
Date: Tue,  6 Mar 2007 21:18:42 +0100 (CET)
Subject: [Rd] bug: sticky symbol refs? (PR#9555)
Message-ID: <20070306201842.D5A8A5D626@slim.kubism.ku.dk>



Hello. What happens in the following is that I create two simple functions, f and g, on the workspace. Then I
replace g. When I then call f, it uses the old version of g. Now clearly, the circumstances for this to happen
must be quite special and rare. But I'd say they're not pathological. It seems to require two things: 1) masked versions
of f and g on a search position lower down the search list (but I'm not sure that's necessary), and 2) using
source() to create the objects, but evaluated in a local environment, not the global one. I'm pretty confident that
2) is necessary for the bug.

Practical impact: like I suppose many users, I maintain my own R functions in a .RData file which I've always got
attached at pos 2. Periodically I dump() them to file, take that file to another site, and source() them in there.
However I don't want all the functions to be created on search pos'n 1, so I have a wrapper my.source() which creates
them in a local environment then copies from that down to search pos 2. So that's all fairly innocent, and probably
not uncommon.

How to reproduce:

########## put this code in /temp/myFuns.R:
`f` <-
function (x)
{
    g(x)
}
`g` <-
function(x)
{
    is.null(x)
}
############

# now create a fresh .RData and attach it at pos 2:
> save(list = character(0), file = "/temp/.RData")    # to create it
> attach( "/temp/.RData", pos=2 )

# now source() /temp/myFuns.R in a local env, then copy new objs to search pos 2:
> newEnv <- new.env()
> eval(expression(source(file = "/temp/myFuns.R", local = T)), envir=newEnv)
> for( objName in objects(envir = newEnv, all.names = T) ) {
      assign(objName, get(objName, envir = newEnv), pos = 2)
}

> f <- f # copy from pos 2 to workspace; (needed?)
> g <- g # copy from pos 2 to workspace; (needed?)
> f(1) # gives correct answer
[1] FALSE
> g <- function(x) stop( "this is the new g" )
> f(1) # gives wrong answer; uses the old g();
[1] FALSE

# now re-create f from scratch, assign under new name:
> f2 <- eval( parse( text=deparse(f) ) )
> f2(1) # gives correct answer
Error in g(x) : this is the new g

# note that the original f() continues to malfunction;

--please do not edit the information below--

Version:
 platform = i386-pc-mingw32
 arch = i386
 os = mingw32
 system = i386, mingw32
 status =
 major = 2
 minor = 4.1
 year = 2006
 month = 12
 day = 18
 svn rev = 40228
 language = R
 version.string = R version 2.4.1 (2006-12-18)

Windows XP Professional (build 2600) Service Pack 2.0

Locale:
LC_COLLATE=English_United Kingdom.1252;LC_CTYPE=English_United Kingdom.1252;LC_MONETARY=English_United

Kingdom.1252;LC_NUMERIC=C;LC_TIME=English_United Kingdom.1252

Search Path:
 .GlobalEnv, file:/temp/.RData, file:c:/schupl/R/myRLib/.RData, file:c:/schupl/R/myFinanceLib/.RData, file:c:/schupl/R/recycler/.RData,

package:stats, package:graphics, package:grDevices, package:utils, package:datasets, package:methods, Autoloads, package:base
---

This e-mail may contain confidential and/or privileged infor...{{dropped}}


From huber at ebi.ac.uk  Tue Mar  6 23:13:23 2007
From: huber at ebi.ac.uk (Wolfgang Huber)
Date: Tue, 06 Mar 2007 22:13:23 +0000
Subject: [Rd] SVG and tooltips, hyperlinks
Message-ID: <45EDE783.2030403@ebi.ac.uk>

Dear all,

is there a good way to create SVG plots with R whose elements have 
titles (tooltips) or act as hyperlinks?

I am using the RSvgDevice package, which works great - but it doesn't 
seem to support the notion that plot objects have titles or are act as 
hyperlinks, so I am helping myself by giving the objects funny unique 
colors and then postprocessing the .svg file.

I wonder whether somebody has already implemented this in a more elegant 
way.

Best wishes
   Wolfgang

------------------------------------------------------------------
Wolfgang Huber  EBI/EMBL  Cambridge UK  http://www.ebi.ac.uk/huber


From p.murrell at auckland.ac.nz  Tue Mar  6 23:43:20 2007
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Wed, 07 Mar 2007 11:43:20 +1300
Subject: [Rd] SVG and tooltips, hyperlinks
In-Reply-To: <45EDE783.2030403@ebi.ac.uk>
References: <45EDE783.2030403@ebi.ac.uk>
Message-ID: <45EDEE88.7000008@stat.auckland.ac.nz>

Hi


Wolfgang Huber wrote:
> Dear all,
> 
> is there a good way to create SVG plots with R whose elements have 
> titles (tooltips) or act as hyperlinks?
> 
> I am using the RSvgDevice package, which works great - but it doesn't 
> seem to support the notion that plot objects have titles or are act as 
> hyperlinks, so I am helping myself by giving the objects funny unique 
> colors and then postprocessing the .svg file.
> 
> I wonder whether somebody has already implemented this in a more elegant 
> way.


Well, elegance is in the eye of the beholder, but you might want to take
a look at the gridSVG package anyway ...
http://www.stat.auckland.ac.nz/~paul/index.html

Paul


> Best wishes
>    Wolfgang
> 
> ------------------------------------------------------------------
> Wolfgang Huber  EBI/EMBL  Cambridge UK  http://www.ebi.ac.uk/huber
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/


From hb at stat.berkeley.edu  Wed Mar  7 01:39:12 2007
From: hb at stat.berkeley.edu (Henrik Bengtsson)
Date: Tue, 6 Mar 2007 16:39:12 -0800
Subject: [Rd] Reordering the search path?
Message-ID: <59d7961d0703061639i2b0a6daaycb8233a4973fa2df@mail.gmail.com>

Hi, without arguing for doing it or not, is the following a correct
way to reorder the search path:

moveInSearchPath <- function(from, to) {
  # Excluding validation of 'from' and 'to' here etc.

  # Get enviroment to be moved
  env <- pos.to.env(from);

  # Detach old position without side effects, cf. detach().
  .Internal(detach(from));

  if (to > from)
    to <- to - 1;

  # Attach at new position
  attach(env, pos=to, name=attr(env, "name"));
}

Thanks

/Henrik


From p.dalgaard at biostat.ku.dk  Wed Mar  7 08:02:57 2007
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Wed, 07 Mar 2007 08:02:57 +0100
Subject: [Rd] bug: sticky symbol refs? (PR#9555)
In-Reply-To: <20070306201842.D5A8A5D626@slim.kubism.ku.dk>
References: <20070306201842.D5A8A5D626@slim.kubism.ku.dk>
Message-ID: <45EE63A1.2020809@biostat.ku.dk>

peter-m.schumacher at db.com wrote:
> Hello. What happens in the following is that I create two simple functions, f and g, on the workspace. Then I
> replace g. When I then call f, it uses the old version of g. Now clearly, the circumstances for this to happen
> must be quite special and rare. But I'd say they're not pathological. It seems to require two things: 1) masked versions
> of f and g on a search position lower down the search list (but I'm not sure that's necessary), and 2) using
> source() to create the objects, but evaluated in a local environment, not the global one. I'm pretty confident that
> 2) is necessary for the bug.
>
> Practical impact: like I suppose many users, I maintain my own R functions in a .RData file which I've always got
> attached at pos 2. Periodically I dump() them to file, take that file to another site, and source() them in there.
> However I don't want all the functions to be created on search pos'n 1, so I have a wrapper my.source() which creates
> them in a local environment then copies from that down to search pos 2. So that's all fairly innocent, and probably
> not uncommon.
>
> How to reproduce:
>
> ########## put this code in /temp/myFuns.R:
> `f` <-
> function (x)
> {
>     g(x)
> }
> `g` <-
> function(x)
> {
>     is.null(x)
> }
> ############
>
> # now create a fresh .RData and attach it at pos 2:
>   
>> save(list = character(0), file = "/temp/.RData")    # to create it
>> attach( "/temp/.RData", pos=2 )
>>     
>
> # now source() /temp/myFuns.R in a local env, then copy new objs to search pos 2:
>   
>> newEnv <- new.env()
>> eval(expression(source(file = "/temp/myFuns.R", local = T)), envir=newEnv)
>> for( objName in objects(envir = newEnv, all.names = T) ) {
>>     
>       assign(objName, get(objName, envir = newEnv), pos = 2)
> }
>
>   
>> f <- f # copy from pos 2 to workspace; (needed?)
>> g <- g # copy from pos 2 to workspace; (needed?)
>> f(1) # gives correct answer
>>     
> [1] FALSE
>   
>> g <- function(x) stop( "this is the new g" )
>> f(1) # gives wrong answer; uses the old g();
>>     
> [1] FALSE
>
> # now re-create f from scratch, assign under new name:
>   
>> f2 <- eval( parse( text=deparse(f) ) )
>> f2(1) # gives correct answer
>>     
> Error in g(x) : this is the new g
>
> # note that the original f() continues to malfunction;
>   
Not a bug, as far as I can see. The environment of f  is newEnv, and 
this is where it goes looking for g copying f to the global environment 
doesn't change that. That information is part of the function object not 
a matter of where the object is bound to a variable. Look at 
environment(f), resp. f2 to see the point.

> --please do not edit the information below--
>
> Version:
>  platform = i386-pc-mingw32
>  arch = i386
>  os = mingw32
>  system = i386, mingw32
>  status =
>  major = 2
>  minor = 4.1
>  year = 2006
>  month = 12
>  day = 18
>  svn rev = 40228
>  language = R
>  version.string = R version 2.4.1 (2006-12-18)
>
> Windows XP Professional (build 2600) Service Pack 2.0
>
> Locale:
> LC_COLLATE=English_United Kingdom.1252;LC_CTYPE=English_United Kingdom.1252;LC_MONETARY=English_United
>
> Kingdom.1252;LC_NUMERIC=C;LC_TIME=English_United Kingdom.1252
>
> Search Path:
>  .GlobalEnv, file:/temp/.RData, file:c:/schupl/R/myRLib/.RData, file:c:/schupl/R/myFinanceLib/.RData, file:c:/schupl/R/recycler/.RData,
>
> package:stats, package:graphics, package:grDevices, package:utils, package:datasets, package:methods, Autoloads, package:base
> ---
>
> This e-mail may contain confidential and/or privileged infor...{{dropped}}
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From huber at ebi.ac.uk  Wed Mar  7 09:38:04 2007
From: huber at ebi.ac.uk (Wolfgang Huber)
Date: Wed, 07 Mar 2007 08:38:04 +0000
Subject: [Rd] bug: sticky symbol refs? (PR#9555)
In-Reply-To: <20070306201842.D5A8A5D626@slim.kubism.ku.dk>
References: <20070306201842.D5A8A5D626@slim.kubism.ku.dk>
Message-ID: <45EE79EC.60106@ebi.ac.uk>


Dear Peter,

would the problem persist if you maintained your favorite set of R
functions in a proper package rather than in some .RData file?

Packages offer a lot of goodies such as namespaces, version numbers, man
pages.

Best wishes
   Wolfgang

------------------------------------------------------------------
Wolfgang Huber  EBI/EMBL  Cambridge UK  http://www.ebi.ac.uk/huber


peter-m.schumacher at db.com wrote:
> 
> Hello. What happens in the following is that I create two simple functions, f and g, on the workspace. Then I
> replace g. When I then call f, it uses the old version of g. Now clearly, the circumstances for this to happen
> must be quite special and rare. But I'd say they're not pathological. It seems to require two things: 1) masked versions
> of f and g on a search position lower down the search list (but I'm not sure that's necessary), and 2) using
> source() to create the objects, but evaluated in a local environment, not the global one. I'm pretty confident that
> 2) is necessary for the bug.
> 
> Practical impact: like I suppose many users, I maintain my own R functions in a .RData file which I've always got
> attached at pos 2. Periodically I dump() them to file, take that file to another site, and source() them in there.
> However I don't want all the functions to be created on search pos'n 1, so I have a wrapper my.source() which creates
> them in a local environment then copies from that down to search pos 2. So that's all fairly innocent, and probably
> not uncommon.
> 
> How to reproduce:
> 
> ########## put this code in /temp/myFuns.R:
> `f` <-
> function (x)
> {
>     g(x)
> }
> `g` <-
> function(x)
> {
>     is.null(x)
> }
> ############
> 
> # now create a fresh .RData and attach it at pos 2:
>> save(list = character(0), file = "/temp/.RData")    # to create it
>> attach( "/temp/.RData", pos=2 )
> 
> # now source() /temp/myFuns.R in a local env, then copy new objs to search pos 2:
>> newEnv <- new.env()
>> eval(expression(source(file = "/temp/myFuns.R", local = T)), envir=newEnv)
>> for( objName in objects(envir = newEnv, all.names = T) ) {
>       assign(objName, get(objName, envir = newEnv), pos = 2)
> }
> 
>> f <- f # copy from pos 2 to workspace; (needed?)
>> g <- g # copy from pos 2 to workspace; (needed?)
>> f(1) # gives correct answer
> [1] FALSE
>> g <- function(x) stop( "this is the new g" )
>> f(1) # gives wrong answer; uses the old g();
> [1] FALSE
> 
> # now re-create f from scratch, assign under new name:
>> f2 <- eval( parse( text=deparse(f) ) )
>> f2(1) # gives correct answer
> Error in g(x) : this is the new g
> 
> # note that the original f() continues to malfunction;
> 
> --please do not edit the information below--
> 
> Version:
>  platform = i386-pc-mingw32
>  arch = i386
>  os = mingw32
>  system = i386, mingw32
>  status =
>  major = 2
>  minor = 4.1
>  year = 2006
>  month = 12
>  day = 18
>  svn rev = 40228
>  language = R
>  version.string = R version 2.4.1 (2006-12-18)
> 
> Windows XP Professional (build 2600) Service Pack 2.0
> 
> Locale:
> LC_COLLATE=English_United Kingdom.1252;LC_CTYPE=English_United Kingdom.1252;LC_MONETARY=English_United
> 
> Kingdom.1252;LC_NUMERIC=C;LC_TIME=English_United Kingdom.1252
> 
> Search Path:
>  .GlobalEnv, file:/temp/.RData, file:c:/schupl/R/myRLib/.RData, file:c:/schupl/R/myFinanceLib/.RData, file:c:/schupl/R/recycler/.RData,
> 
> package:stats, package:graphics, package:grDevices, package:utils, package:datasets, package:methods, Autoloads, package:base
> ---
> 
> This e-mail may contain confidential and/or privileged infor...{{dropped}}
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


--


From x.sole at iconcologia.net  Wed Mar  7 12:42:06 2007
From: x.sole at iconcologia.net (Sole Acha, Xavi)
Date: Wed, 7 Mar 2007 12:42:06 +0100
Subject: [Rd] Garbage collector crashes after calling a C function
Message-ID: <50805D6FBD91904D86AF433349315E420AC759@ICOSRVCORREO01.ICO.SCS.local>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20070307/08461199/attachment.pl 

From antonio.fabio at gmail.com  Wed Mar  7 12:59:54 2007
From: antonio.fabio at gmail.com (Antonio, Fabio Di Narzo)
Date: Wed, 7 Mar 2007 12:59:54 +0100
Subject: [Rd] Garbage collector crashes after calling a C function
In-Reply-To: <50805D6FBD91904D86AF433349315E420AC759@ICOSRVCORREO01.ICO.SCS.local>
References: <50805D6FBD91904D86AF433349315E420AC759@ICOSRVCORREO01.ICO.SCS.local>
Message-ID: <b0808fdc0703070359h28b8643ct91952a597ffd0d22@mail.gmail.com>

2007/3/7, Sole Acha, Xavi <x.sole at iconcologia.net>:
> Dear listers,
>
>
>
> a few days ago I asked a question about a problem I had with a C function programmed by myself to be called from R. Thanks to your help, I have been able to look a bit further into it, so now I can be a bit more specific when telling what happens.
>
>
>
> The fact is that, when my C function finishes its execution (after calling it via the ".C" interface), R seems ok but then crashes when the garbage collector executes, giving a segmentation fault.
>
>
>
> As some of you suggested, I have executed my function with valgrind, and I get no memory errors, but some memory leaks (which I am not able to locate although compiling my program with the -c flag),

In gcc, maybe you mean the '-g' flag

> and I also get the memory error from RunGenCollect: (which I suppose is causes the segmentation fault). You can see a small piece of the valgrind output below
>
>
>
> Using gctorture to make the garbage collector crash inside the execution of my program didn't work (my program finished). The question is: what are the typical programming errors that can make R garbage collector crash? Could it be because of these memory leaks? If so, how could I trace them? I have tried it, but running my program with gdb is not an easy task to do, as it performs a huge number of iterations.
>
>
>
> Thank you very much in advance for your help. I would appreciate any hint that could help me solve this tricky problem.
>
>
>
> Best regards,
>
>
>
> Xavier Sol?.
>
>
>
> -----------
>
> ### This is one of the memory leaks
>
> ==9370== 162 (160 direct, 2 indirect) bytes in 1 blocks are definitely lost in loss record 11 of 42
>
> ==9370==    at 0x4A19D35: malloc (vg_replace_malloc.c:149)
>
> ==9370==    by 0x84490E0: ???
>
> ==9370==    by 0x844D346: ???
>
> ==9370==    by 0x4BBE1A2: do_dotCode (in /usr/lib64/R/lib/libR.so)
>
> ==9370==    by 0x4BE9035: Rf_eval (in /usr/lib64/R/lib/libR.so)
>
> ==9370==    by 0x4BEBA3F: do_set (in /usr/lib64/R/lib/libR.so)
>
> ==9370==    by 0x4BE8E5E: Rf_eval (in /usr/lib64/R/lib/libR.so)
>
> ==9370==    by 0x4BEAF0D: do_begin (in /usr/lib64/R/lib/libR.so)
>
> ==9370==    by 0x4BE8E5E: Rf_eval (in /usr/lib64/R/lib/libR.so)
>
> ==9370==    by 0x4BE9711: Rf_applyClosure (in /usr/lib64/R/lib/libR.so)
>
> ==9370==    by 0x4BE9107: Rf_eval (in /usr/lib64/R/lib/libR.so)
>
> ==9370==    by 0x4BEBA3F: do_set (in /usr/lib64/R/lib/libR.so)
>
>
>
> ### This is the RunGenCollect memory error
>
> ==9370== Invalid write of size 8
>
> ==9370==    at 0x4C1F73A: RunGenCollect (in /usr/lib64/R/lib/libR.so)
>
> ==9370==    by 0x4C23E55: R_gc_internal (in /usr/lib64/R/lib/libR.so)
>
> ==9370==    by 0x4C22DC3: Rf_cons (in /usr/lib64/R/lib/libR.so)
>
> ==9370==    by 0x4C23AE1: Rf_allocList (in /usr/lib64/R/lib/libR.so)
>
> ==9370==    by 0x4B6926B: installAttrib (in /usr/lib64/R/lib/libR.so)
>
> ==9370==    by 0x4B69961: Rf_classgets (in /usr/lib64/R/lib/libR.so)
>
> ==9370==    by 0x4B68DC1: Rf_setAttrib (in /usr/lib64/R/lib/libR.so)
>
> ==9370==    by 0x4B69A40: do_classgets (in /usr/lib64/R/lib/libR.so)
>
> ==9370==    by 0x4BE908E: Rf_eval (in /usr/lib64/R/lib/libR.so)
>
> ==9370==    by 0x4BEB6FD: applydefine (in /usr/lib64/R/lib/libR.so)
>
> ==9370==    by 0x4BEBAE3: do_set (in /usr/lib64/R/lib/libR.so)
>
> ==9370==    by 0x4BE8E5E: Rf_eval (in /usr/lib64/R/lib/libR.so)
>
> ==9370==  Address 0x10 is not stack'd, malloc'd or (recently) free'd
>
>
>
>
>         [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


-- 
Antonio, Fabio Di Narzo
Ph.D. student at
Department of Statistical Sciences
University of Bologna, Italy


From x.sole at iconcologia.net  Wed Mar  7 13:19:08 2007
From: x.sole at iconcologia.net (Sole Acha, Xavi)
Date: Wed, 7 Mar 2007 13:19:08 +0100
Subject: [Rd] Garbage collector crashes after calling a C function
Message-ID: <50805D6FBD91904D86AF433349315E420AC772@ICOSRVCORREO01.ICO.SCS.local>

Sorry, that was a mistake. You are right Antonio, I wanted to say the "-g" flag.

Xavi.

-----Mensaje original-----
De: Antonio, Fabio Di Narzo [mailto:antonio.fabio at gmail.com] 
Enviado el: dimecres, 7 / mar? / 2007 13:00
Para: Sole Acha, Xavi
CC: r-devel at stat.math.ethz.ch
Asunto: Re: [Rd] Garbage collector crashes after calling a C function

2007/3/7, Sole Acha, Xavi <x.sole at iconcologia.net>:
> Dear listers,
>
>
>
> a few days ago I asked a question about a problem I had with a C function programmed by myself to be called from R. Thanks to your help, I have been able to look a bit further into it, so now I can be a bit more specific when telling what happens.
>
>
>
> The fact is that, when my C function finishes its execution (after calling it via the ".C" interface), R seems ok but then crashes when the garbage collector executes, giving a segmentation fault.
>
>
>
> As some of you suggested, I have executed my function with valgrind, and I get no memory errors, but some memory leaks (which I am not able to locate although compiling my program with the -c flag),

In gcc, maybe you mean the '-g' flag

> and I also get the memory error from RunGenCollect: (which I suppose is causes the segmentation fault). You can see a small piece of the valgrind output below
>
>
>
> Using gctorture to make the garbage collector crash inside the execution of my program didn't work (my program finished). The question is: what are the typical programming errors that can make R garbage collector crash? Could it be because of these memory leaks? If so, how could I trace them? I have tried it, but running my program with gdb is not an easy task to do, as it performs a huge number of iterations.
>
>
>
> Thank you very much in advance for your help. I would appreciate any hint that could help me solve this tricky problem.
>
>
>
> Best regards,
>
>
>
> Xavier Sol?.
>
>
>
> -----------
>
> ### This is one of the memory leaks
>
> ==9370== 162 (160 direct, 2 indirect) bytes in 1 blocks are definitely lost in loss record 11 of 42
>
> ==9370==    at 0x4A19D35: malloc (vg_replace_malloc.c:149)
>
> ==9370==    by 0x84490E0: ???
>
> ==9370==    by 0x844D346: ???
>
> ==9370==    by 0x4BBE1A2: do_dotCode (in /usr/lib64/R/lib/libR.so)
>
> ==9370==    by 0x4BE9035: Rf_eval (in /usr/lib64/R/lib/libR.so)
>
> ==9370==    by 0x4BEBA3F: do_set (in /usr/lib64/R/lib/libR.so)
>
> ==9370==    by 0x4BE8E5E: Rf_eval (in /usr/lib64/R/lib/libR.so)
>
> ==9370==    by 0x4BEAF0D: do_begin (in /usr/lib64/R/lib/libR.so)
>
> ==9370==    by 0x4BE8E5E: Rf_eval (in /usr/lib64/R/lib/libR.so)
>
> ==9370==    by 0x4BE9711: Rf_applyClosure (in /usr/lib64/R/lib/libR.so)
>
> ==9370==    by 0x4BE9107: Rf_eval (in /usr/lib64/R/lib/libR.so)
>
> ==9370==    by 0x4BEBA3F: do_set (in /usr/lib64/R/lib/libR.so)
>
>
>
> ### This is the RunGenCollect memory error
>
> ==9370== Invalid write of size 8
>
> ==9370==    at 0x4C1F73A: RunGenCollect (in /usr/lib64/R/lib/libR.so)
>
> ==9370==    by 0x4C23E55: R_gc_internal (in /usr/lib64/R/lib/libR.so)
>
> ==9370==    by 0x4C22DC3: Rf_cons (in /usr/lib64/R/lib/libR.so)
>
> ==9370==    by 0x4C23AE1: Rf_allocList (in /usr/lib64/R/lib/libR.so)
>
> ==9370==    by 0x4B6926B: installAttrib (in /usr/lib64/R/lib/libR.so)
>
> ==9370==    by 0x4B69961: Rf_classgets (in /usr/lib64/R/lib/libR.so)
>
> ==9370==    by 0x4B68DC1: Rf_setAttrib (in /usr/lib64/R/lib/libR.so)
>
> ==9370==    by 0x4B69A40: do_classgets (in /usr/lib64/R/lib/libR.so)
>
> ==9370==    by 0x4BE908E: Rf_eval (in /usr/lib64/R/lib/libR.so)
>
> ==9370==    by 0x4BEB6FD: applydefine (in /usr/lib64/R/lib/libR.so)
>
> ==9370==    by 0x4BEBAE3: do_set (in /usr/lib64/R/lib/libR.so)
>
> ==9370==    by 0x4BE8E5E: Rf_eval (in /usr/lib64/R/lib/libR.so)
>
> ==9370==  Address 0x10 is not stack'd, malloc'd or (recently) free'd
>
>
>
>
>         [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


-- 
Antonio, Fabio Di Narzo
Ph.D. student at
Department of Statistical Sciences
University of Bologna, Italy


From murdoch at stats.uwo.ca  Wed Mar  7 13:34:09 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Wed, 07 Mar 2007 07:34:09 -0500
Subject: [Rd] Garbage collector crashes after calling a C function
In-Reply-To: <50805D6FBD91904D86AF433349315E420AC759@ICOSRVCORREO01.ICO.SCS.local>
References: <50805D6FBD91904D86AF433349315E420AC759@ICOSRVCORREO01.ICO.SCS.local>
Message-ID: <45EEB141.1070506@stats.uwo.ca>

On 3/7/2007 6:42 AM, Sole Acha, Xavi wrote:
> Dear listers,
> 
>  
> 
> a few days ago I asked a question about a problem I had with a C function programmed by myself to be called from R. Thanks to your help, I have been able to look a bit further into it, so now I can be a bit more specific when telling what happens.
> 
>  
> 
> The fact is that, when my C function finishes its execution (after calling it via the ".C" interface), R seems ok but then crashes when the garbage collector executes, giving a segmentation fault.
> 
>  
> 
> As some of you suggested, I have executed my function with valgrind, and I get no memory errors, but some memory leaks (which I am not able to locate although compiling my program with the -c flag), and I also get the memory error from RunGenCollect: (which I suppose is causes the segmentation fault). You can see a small piece of the valgrind output below
> 
>  
> 
> Using gctorture to make the garbage collector crash inside the execution of my program didn't work (my program finished). The question is: what are the typical programming errors that can make R garbage collector crash? Could it be because of these memory leaks? If so, how could I trace them? I have tried it, but running my program with gdb is not an easy task to do, as it performs a huge number of iterations.
> 
>  
> 
> Thank you very much in advance for your help. I would appreciate any hint that could help me solve this tricky problem.

The obvious guess is that you're writing out of bounds in some array. 
Remember to explicitly set the type of arrays you pass in to .C (e.g. 
as.double(1:10) is different from 1:10), and remember that R uses 
1-based indexing (from 1 to 10 in the case above) whereas C uses 0 based 
indexing (from 0 to 9).

I don't know what sort of tests valgrind does and why it doesn't notice 
an error in your code; it doesn't run in Windows, as far as I know.

Duncan Murdoch


From jombart at biomserv.univ-lyon1.fr  Wed Mar  7 15:47:13 2007
From: jombart at biomserv.univ-lyon1.fr (Thibaut Jombart)
Date: Wed, 07 Mar 2007 15:47:13 +0100
Subject: [Rd] possible bug in model.frame.default
Message-ID: <45EED071.6070609@biomserv.univ-lyon1.fr>

Dear list,

I may have found a bug in model.frame.default (called by the lm function).
The problem arises in my R dev version but not in my R 2.4.0.
Here is my config :

 > version
               
_                                                              
platform       
x86_64-unknown-linux-gnu                                       
arch           
x86_64                                                         
os             
linux-gnu                                                      
system         x86_64, 
linux-gnu                                              
status         Under development 
(unstable)                                   
major          
2                                                              
minor          
5.0                                                            
year           
2007                                                           
month          
03                                                             
day            
04                                                             
svn rev        
40813                                                          
language       
R                                                              
version.string R version 2.5.0 Under development (unstable) (2007-03-04 
r40813)

Now a simple example to (hopefully) reproduce the bug (after a 
rm(list=ls())):

 > dat=data.frame(y=rnorm(10),x1=runif(10),x2=runif(10))
 > weights=1:10/(sum(1:10))
 > form <- as.formula("y~x1+x2")
# here is the error
 > lm(form,data=dat,weights=weights)
Erreur dans model.frame(formula, rownames, variables, varnames, extras, 
extranames,  :
    type (closure) incorrect pour la variable '(weights)'

(sorry, error message is in French)

As I said, these commands works using R.2.4.0 (same machine, same OS).
Moreover, the following commands work:
 > temp=weights
 > lm(form,data=dat,weights=temp)

This currently seems to cause a check fail in the ade4 package. I tried 
to find out where the bug came from: all I found is the (potential) bug 
comes from model.frame.default, and more precisely:
debug: data <- .Internal(model.frame(formula, rownames, variables, 
varnames,
    extras, extranames, subset, na.action))
Browse[1]>
Erreur dans model.frame(formula, rownames, variables, varnames, extras, 
extranames,  :
    type (closure) incorrect pour la variable '(weights)'

I couldn't go further because of the .Internal. I tried to googlise 
this, but I found no such problem reported recently.

Can anyone tell if this is actually a bug? (In case not, please tell me 
where I got wrong).

Regards,

Thibaut.

-- 
######################################
Thibaut JOMBART
CNRS UMR 5558 - Laboratoire de Biom?trie et Biologie Evolutive
Universite Lyon 1
43 bd du 11 novembre 1918
69622 Villeurbanne Cedex
T?l. : 04.72.43.29.35
Fax : 04.72.43.13.88
jombart at biomserv.univ-lyon1.fr
http://biomserv.univ-lyon1.fr/sitelabo/pageperso.php?id_personne=178


From thomas.friedrichsmeier at ruhr-uni-bochum.de  Wed Mar  7 16:05:21 2007
From: thomas.friedrichsmeier at ruhr-uni-bochum.de (thomas.friedrichsmeier at ruhr-uni-bochum.de)
Date: Wed,  7 Mar 2007 16:05:21 +0100 (CET)
Subject: [Rd] Wish: Option to configure the default par() (PR#9545)
Message-ID: <20070307150521.1EBCD5ABF8@slim.kubism.ku.dk>

--nextPart4163908.Y9KBlY7Qjy
Content-Type: text/plain;
  charset="iso-8859-1"
Content-Transfer-Encoding: quoted-printable
Content-Disposition: inline

On Tuesday 06 March 2007 17:56, Greg Snow wrote:
> Another approach may be to use hooks (see ?setHook).  The plot.new
> function already has a hook, so you could do your option #1
> automatically by setting that hook.
>
> Better would be if all the graphics device functions had hooks (or a
> common hook), then you could set that hook to set your graphics
> parameters and they would be set every time a new graphics device was
> started.

Thanks for your suggestion. This does almost everything I want. Two small=20
drawbacks:

1) Setting par(bg=3D...) from the hook has no effect for the first graph pl=
otted=20
in the new device. For this to work, the hook would need to be called=20
before .Internal(plot.new()) instead of afterwards in plot.new().

2) Any par() parameters explicitely set in the call to X11()/postscript()..=
=2E=20
will be overridded, instead of taking precendence over the defaults.

=46or many purposes this method is really useful, however, so thanks again =
for=20
pointing it out.

Regards
Thomas

--nextPart4163908.Y9KBlY7Qjy
Content-Type: application/pgp-signature

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.6 (GNU/Linux)

iD8DBQBF7tTmEKRv+5DVNhgRAhZ4AJ9StffA3KSO+h4ONdkWE7A1JarXWACdF8vu
pRW+6rL5DCS8iXppfxdIk88=
=rKvB
-----END PGP SIGNATURE-----

--nextPart4163908.Y9KBlY7Qjy--


From murdoch at stats.uwo.ca  Wed Mar  7 16:16:53 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Wed, 07 Mar 2007 10:16:53 -0500
Subject: [Rd] possible bug in model.frame.default
In-Reply-To: <45EED071.6070609@biomserv.univ-lyon1.fr>
References: <45EED071.6070609@biomserv.univ-lyon1.fr>
Message-ID: <45EED765.9030504@stats.uwo.ca>

On 3/7/2007 9:47 AM, Thibaut Jombart wrote:
> Dear list,
> 
> I may have found a bug in model.frame.default (called by the lm function).
> The problem arises in my R dev version but not in my R 2.4.0.
> Here is my config :

I don't see this bug in r40818 in Windows, and the log entry for r40817 
looks like it may be relevant:

fixing a buglet that crept in from the change to have $ warn
when applied to an atomic vector

This modified model.R and the NAMESPACE file of the stats package.

Could you try a slightly newer build?

Duncan Murdoch

> 
>  > version
>                
> _                                                              
> platform       
> x86_64-unknown-linux-gnu                                       
> arch           
> x86_64                                                         
> os             
> linux-gnu                                                      
> system         x86_64, 
> linux-gnu                                              
> status         Under development 
> (unstable)                                   
> major          
> 2                                                              
> minor          
> 5.0                                                            
> year           
> 2007                                                           
> month          
> 03                                                             
> day            
> 04                                                             
> svn rev        
> 40813                                                          
> language       
> R                                                              
> version.string R version 2.5.0 Under development (unstable) (2007-03-04 
> r40813)
> 
> Now a simple example to (hopefully) reproduce the bug (after a 
> rm(list=ls())):
> 
>  > dat=data.frame(y=rnorm(10),x1=runif(10),x2=runif(10))
>  > weights=1:10/(sum(1:10))
>  > form <- as.formula("y~x1+x2")
> # here is the error
>  > lm(form,data=dat,weights=weights)
> Erreur dans model.frame(formula, rownames, variables, varnames, extras, 
> extranames,  :
>     type (closure) incorrect pour la variable '(weights)'
> 
> (sorry, error message is in French)
> 
> As I said, these commands works using R.2.4.0 (same machine, same OS).
> Moreover, the following commands work:
>  > temp=weights
>  > lm(form,data=dat,weights=temp)
> 
> This currently seems to cause a check fail in the ade4 package. I tried 
> to find out where the bug came from: all I found is the (potential) bug 
> comes from model.frame.default, and more precisely:
> debug: data <- .Internal(model.frame(formula, rownames, variables, 
> varnames,
>     extras, extranames, subset, na.action))
> Browse[1]>
> Erreur dans model.frame(formula, rownames, variables, varnames, extras, 
> extranames,  :
>     type (closure) incorrect pour la variable '(weights)'
> 
> I couldn't go further because of the .Internal. I tried to googlise 
> this, but I found no such problem reported recently.
> 
> Can anyone tell if this is actually a bug? (In case not, please tell me 
> where I got wrong).
> 
> Regards,
> 
> Thibaut.
>


From rfrancois at mango-solutions.com  Wed Mar  7 16:46:08 2007
From: rfrancois at mango-solutions.com (Romain Francois)
Date: Wed, 07 Mar 2007 15:46:08 +0000
Subject: [Rd] SVG and tooltips, hyperlinks
In-Reply-To: <45EDE783.2030403@ebi.ac.uk>
References: <45EDE783.2030403@ebi.ac.uk>
Message-ID: <45EEDE40.9070803@mango-solutions.com>

Wolfgang Huber wrote:
> Dear all,
>
> is there a good way to create SVG plots with R whose elements have 
> titles (tooltips) or act as hyperlinks?
>
> I am using the RSvgDevice package, which works great - but it doesn't 
> seem to support the notion that plot objects have titles or are act as 
> hyperlinks, so I am helping myself by giving the objects funny unique 
> colors and then postprocessing the .svg file.
>
> I wonder whether somebody has already implemented this in a more elegant 
> way.
>
> Best wishes
>    Wolfgang
>   
Tony Plate posted an altered version of RSvgDevice on the finance list a
couple of weeks ago.
https://stat.ethz.ch/pipermail/r-sig-finance/2007q1/001261.html

It does not do hyperlinks yet, but that should not be too difficult to do.

Cheers,

Romain

-- 
Mango Solutions
data analysis that delivers

Tel:  +44(0) 1249 467 467
Fax:  +44(0) 1249 467 468
Mob:  +44(0) 7813 526 123


From jose.sierra at integromics.com  Wed Mar  7 16:54:13 2007
From: jose.sierra at integromics.com (Jose Sierra)
Date: Wed, 07 Mar 2007 16:54:13 +0100
Subject: [Rd] RJDBC
In-Reply-To: <642D1D67-5003-4566-9FC5-81E01B8EB322@r-project.org>
References: <45EC0F6A.20309@integromics.com>
	<642D1D67-5003-4566-9FC5-81E01B8EB322@r-project.org>
Message-ID: <45EEE025.8020609@integromics.com>

Thank you Simon.

I have used your script with Oracle and Mysql and both returns

[1] "Java-Object{java.sql.SQLException: No suitable driver}"

My script is the next:

library('rJava')
library('DBI')
library('RJDBC')

drv <-  
JDBC("com.mysql.jdbc.Driver","C:\\Temporal\\mysql-connector-java-3.0.9-stable-bin.jar","'") 

dbCheck("jdbc:mysql://localhost/foo","user","pwd")

I can connect with Oracle and Mysql by JDBC from another applications 
with this jar. It contains com.mysql.jdbc.Driver.class or 
oracle.jdbc.driver.OracleDriver.class

Can you help me?

Simon Urbanek escribi?:
> Jose,
>
> On Mar 5, 2007, at 7:39 AM, Jose Sierra wrote:
>
>> I need help.
>>
>> I'm trying to connect with an Oracle DBMS and MySQL DBMS, I'm using
>> RJDBC package.
>>
>> My code is the next:
>>
>> library('rJava')
>> library('DBI')
>> library('RJDBC')
>>
>> //Mysql
>> drv <-
>> JDBC("com.mysql.jdbc.Driver","C:\\Temporal\\mysql-connector-java-3.0.9-stable-bin.jar","'") 
>>
>>
>> conn <- dbConnect(drv, "jdbc:mysql://localhost:3306/bd", "user",
>> "password")
>>
>> //Oracle
>> drv <-
>> JDBC("oracle.jdbc.driver.OracleDriver","C:\\Temporal\\classes12.jar","'") 
>>
>> conn <-
>> dbConnect(drv,"jdbc:oracle:thin:@192.168.1.70:1521:SDS22","user","password") 
>>
>>
>>
>> R always returns for oracle
>> "Error en .local(drv, ...) : Unable to connect JDBC to
>> jdbc:oracle:thin:@192.168.1.70:1521:SDS22"
>> and for mysql
>> "Error en .local(drv, ...) : Unable to connect JDBC to
>> jdbc:mysql://localhost:3306/bd"
>>
>
> It is very likely a problem with your DB connection or authentication. 
> I have tested it with MySQL (I don't have Oracle) and it worked 
> without problems. Please test it step-by-step to make sure that your 
> DB is configured properly.
>
> Unfortunately RJDBC doesn't pass non-fatal SQL errors back to the 
> user, so connection problems are not easy to debug, but you can try 
> this to show the connection problem:
>
> dbCheck = function(url, user='', pwd='') {
>  j = .jcall("java/sql/DriverManager", "Ljava/sql/Connection;", 
> "getConnection", url, user, pwd, check=FALSE)
>  x = .jgetEx()
>  .jcheck()
>  x
> }
>
> and use it like this:
>
> > dbCheck("jdbc:mysql://localhost/foo","user","pwd")
> [1] "Java-Object{java.sql.SQLException: Access denied for user 
> 'user'@'localhost' (using password: YES)}"
> >
> > dbCheck("jdbc:mysql://localhost/foo","root","")
> [1] "Java-Object{java.sql.SQLException: Unknown database 'foo'}"
> > dbCheck("jdbc:mysql://bar/foo","root","")
>
> I'll see if I can provide some more helpful response in the dbConnect 
> for the next release..
>
>
>> Another question:
>> I try to compile ROracle and RMysql for windows but i need Rdll.lib 
>> and  it need R.exp.
>
> No, you don't need those files, because R is linked directly. Simply 
> follow the instructions for building R packages on Windows.
>
> Cheers,
> Simon
>
>
>
>
>
>

		
______________________________________________ 
LLama Gratis a cualquier PC del Mundo. 
Llamadas a fijos y m?viles desde 1 c?ntimo por minuto. 
http://es.voice.yahoo.com


From tlumley at u.washington.edu  Wed Mar  7 16:57:19 2007
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Wed, 7 Mar 2007 07:57:19 -0800 (PST)
Subject: [Rd] possible bug in model.frame.default
In-Reply-To: <45EED071.6070609@biomserv.univ-lyon1.fr>
References: <45EED071.6070609@biomserv.univ-lyon1.fr>
Message-ID: <Pine.LNX.4.64.0703070755130.27471@homer23.u.washington.edu>


I don't see this bug (in r-devel r40818) but there are two changes between 
40814 and 40818 that might have fixed it.

 	-thomas


On Wed, 7 Mar 2007, Thibaut Jombart wrote:

> Dear list,
>
> I may have found a bug in model.frame.default (called by the lm function).
> The problem arises in my R dev version but not in my R 2.4.0.
> Here is my config :
>
> > version
>
> _
> platform
> x86_64-unknown-linux-gnu
> arch
> x86_64
> os
> linux-gnu
> system         x86_64,
> linux-gnu
> status         Under development
> (unstable)
> major
> 2
> minor
> 5.0
> year
> 2007
> month
> 03
> day
> 04
> svn rev
> 40813
> language
> R
> version.string R version 2.5.0 Under development (unstable) (2007-03-04
> r40813)
>
> Now a simple example to (hopefully) reproduce the bug (after a
> rm(list=ls())):
>
> > dat=data.frame(y=rnorm(10),x1=runif(10),x2=runif(10))
> > weights=1:10/(sum(1:10))
> > form <- as.formula("y~x1+x2")
> # here is the error
> > lm(form,data=dat,weights=weights)
> Erreur dans model.frame(formula, rownames, variables, varnames, extras,
> extranames,  :
>    type (closure) incorrect pour la variable '(weights)'
>
> (sorry, error message is in French)
>
> As I said, these commands works using R.2.4.0 (same machine, same OS).
> Moreover, the following commands work:
> > temp=weights
> > lm(form,data=dat,weights=temp)
>
> This currently seems to cause a check fail in the ade4 package. I tried
> to find out where the bug came from: all I found is the (potential) bug
> comes from model.frame.default, and more precisely:
> debug: data <- .Internal(model.frame(formula, rownames, variables,
> varnames,
>    extras, extranames, subset, na.action))
> Browse[1]>
> Erreur dans model.frame(formula, rownames, variables, varnames, extras,
> extranames,  :
>    type (closure) incorrect pour la variable '(weights)'
>
> I couldn't go further because of the .Internal. I tried to googlise
> this, but I found no such problem reported recently.
>
> Can anyone tell if this is actually a bug? (In case not, please tell me
> where I got wrong).
>
> Regards,
>
> Thibaut.
>
> -- 
> ######################################
> Thibaut JOMBART
> CNRS UMR 5558 - Laboratoire de Biom?trie et Biologie Evolutive
> Universite Lyon 1
> 43 bd du 11 novembre 1918
> 69622 Villeurbanne Cedex
> T?l. : 04.72.43.29.35
> Fax : 04.72.43.13.88
> jombart at biomserv.univ-lyon1.fr
> http://biomserv.univ-lyon1.fr/sitelabo/pageperso.php?id_personne=178
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle

From rgentlem at fhcrc.org  Wed Mar  7 16:59:30 2007
From: rgentlem at fhcrc.org (Robert Gentleman)
Date: Wed, 07 Mar 2007 07:59:30 -0800
Subject: [Rd] possible bug in model.frame.default
In-Reply-To: <45EED071.6070609@biomserv.univ-lyon1.fr>
References: <45EED071.6070609@biomserv.univ-lyon1.fr>
Message-ID: <45EEE162.2030204@fhcrc.org>

Please update to the latest snapshot
R version 2.5.0 Under development (unstable) (2007-03-05 r40816)
where all is well,

Thibaut Jombart wrote:
> Dear list,
> 
> I may have found a bug in model.frame.default (called by the lm function).
> The problem arises in my R dev version but not in my R 2.4.0.
> Here is my config :
> 
>  > version
>                
> _                                                              
> platform       
> x86_64-unknown-linux-gnu                                       
> arch           
> x86_64                                                         
> os             
> linux-gnu                                                      
> system         x86_64, 
> linux-gnu                                              
> status         Under development 
> (unstable)                                   
> major          
> 2                                                              
> minor          
> 5.0                                                            
> year           
> 2007                                                           
> month          
> 03                                                             
> day            
> 04                                                             
> svn rev        
> 40813                                                          
> language       
> R                                                              
> version.string R version 2.5.0 Under development (unstable) (2007-03-04 
> r40813)
> 
> Now a simple example to (hopefully) reproduce the bug (after a 
> rm(list=ls())):
> 
>  > dat=data.frame(y=rnorm(10),x1=runif(10),x2=runif(10))
>  > weights=1:10/(sum(1:10))
>  > form <- as.formula("y~x1+x2")
> # here is the error
>  > lm(form,data=dat,weights=weights)
> Erreur dans model.frame(formula, rownames, variables, varnames, extras, 
> extranames,  :
>     type (closure) incorrect pour la variable '(weights)'
> 
> (sorry, error message is in French)
> 
> As I said, these commands works using R.2.4.0 (same machine, same OS).
> Moreover, the following commands work:
>  > temp=weights
>  > lm(form,data=dat,weights=temp)
> 
> This currently seems to cause a check fail in the ade4 package. I tried 
> to find out where the bug came from: all I found is the (potential) bug 
> comes from model.frame.default, and more precisely:
> debug: data <- .Internal(model.frame(formula, rownames, variables, 
> varnames,
>     extras, extranames, subset, na.action))
> Browse[1]>
> Erreur dans model.frame(formula, rownames, variables, varnames, extras, 
> extranames,  :
>     type (closure) incorrect pour la variable '(weights)'
> 
> I couldn't go further because of the .Internal. I tried to googlise 
> this, but I found no such problem reported recently.
> 
> Can anyone tell if this is actually a bug? (In case not, please tell me 
> where I got wrong).
> 
> Regards,
> 
> Thibaut.
> 

-- 
Robert Gentleman, PhD
Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M2-B876
PO Box 19024
Seattle, Washington 98109-1024
206-667-7700
rgentlem at fhcrc.org


From jombart at biomserv.univ-lyon1.fr  Wed Mar  7 17:11:17 2007
From: jombart at biomserv.univ-lyon1.fr (Thibaut Jombart)
Date: Wed, 07 Mar 2007 17:11:17 +0100
Subject: [Rd] possible bug in model.frame.default
In-Reply-To: <45EED765.9030504@stats.uwo.ca>
References: <45EED071.6070609@biomserv.univ-lyon1.fr>
	<45EED765.9030504@stats.uwo.ca>
Message-ID: <45EEE425.7090608@biomserv.univ-lyon1.fr>

Duncan Murdoch wrote:

> On 3/7/2007 9:47 AM, Thibaut Jombart wrote:
>
>> Dear list,
>>
>> I may have found a bug in model.frame.default (called by the lm 
>> function).
>> The problem arises in my R dev version but not in my R 2.4.0.
>> Here is my config :
>
>
> I don't see this bug in r40818 in Windows, and the log entry for 
> r40817 looks like it may be relevant:
>
> fixing a buglet that crept in from the change to have $ warn
> when applied to an atomic vector
>
> This modified model.R and the NAMESPACE file of the stats package.
>
> Could you try a slightly newer build?
>
> Duncan Murdoch
>
You are right, this is fixed in R 40818. I naively didn't expect R dev 
version to change so quickly.

Thanks.

Thibaut.
-- 
######################################
Thibaut JOMBART
CNRS UMR 5558 - Laboratoire de Biom?trie et Biologie Evolutive
Universite Lyon 1
43 bd du 11 novembre 1918
69622 Villeurbanne Cedex
T?l. : 04.72.43.29.35
Fax : 04.72.43.13.88
jombart at biomserv.univ-lyon1.fr
http://biomserv.univ-lyon1.fr/sitelabo/pageperso.php?id_personne=178


From ggrothendieck at gmail.com  Wed Mar  7 18:04:52 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Wed, 7 Mar 2007 12:04:52 -0500
Subject: [Rd] Wish: Option to configure the default par() (PR#9545)
In-Reply-To: <20070306140338.CE3F65D608@slim.kubism.ku.dk>
References: <20070306140338.CE3F65D608@slim.kubism.ku.dk>
Message-ID: <971536df0703070904y54556568w3bf548259c0b47be@mail.gmail.com>

Here are a few ideas:

For #1 define:

"$.Par" <- function(x, FUN) {
   par.default <- getOption("par.default")
   if (!is.null(par.default)) do.call("par", par.default)
   get(FUN, parent.frame())
}
Par <- structure(NA, class = "Par")

# and now one can preface any function with Par$ and it will
# call par and then the function.  This eliminates an extra statement
# but does mean you have to preface plot, say, with Par$
# e.g.

options(par.default = list(bg = "light gray", las = 2))
Par$plot(1:10)
Par$boxplot(1:10)


For #2 do:

plot <- Par$plot


Another idea for #2 is to use the connect package.  See:
http://code.google.com/p/r-connect/


On 3/6/07, thomas.friedrichsmeier at ruhr-uni-bochum.de
<thomas.friedrichsmeier at ruhr-uni-bochum.de> wrote:
> Full_Name: Thomas Friedrichsmeier
> Version: 2.4.1
> OS: linux (Debian unstable)
> Submission from: (NULL) (84.60.113.185)
>
>
> Summary: It would be nice to have a centralized option for setting default par()
> options for all devices and all plots. This would ease producing graphs in a
> customized but consistent way. Suggesting options("par.default").
>
> Example problem: Make all graphs look like
>
> par(bg="light gray", las=2)
>
> both on screen and for various produced file formats such as png() and
> postscript().
>
> Current situation: To solve the example problem, two approaches come to mind:
> 1) Always call par() before the next plot. This could be wrapped into a function
> to make it easier to stay consistent. E.g.:
>
> postscript()
> myDefaultPar()       # calls par(bg="light gray", las=2)
> plot(...)
>
> 2) Create wrappers for all devices of interest, like e.g. (not quite correct,
> but good enough for this example):
>
> myX11 <- function(...) {
>  X11(...)
>  par(bg="light gray", las=2)
> }
>
> Both solutions work, but are not entirely elegant. The drawback of 1) is that
> you still need to add the given line manually at all places. The drawback of 2)
> is that a similar wrapper will have to be created (and used) for each different
> device.
>
> Wish:
> Add a new option: options("par.default"), similar to the existing
> options("par.ask.default"). This option would accept a list of all par settings
> to set a custom default for:
>
> options(par.default=list(bg="light gray", las=2))
>
> par() options specified while creating the device, in calls to plot() or in
> subsequent calls to par() would take precendence over options("par.default").
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From bill at insightful.com  Wed Mar  7 21:31:36 2007
From: bill at insightful.com (bill at insightful.com)
Date: Wed,  7 Mar 2007 21:31:36 +0100 (CET)
Subject: [Rd] missing axes in irregular lattice plots (PR#9556)
Message-ID: <20070307203136.A2B7A5AC23@slim.kubism.ku.dk>

In the lattice functions, if the first or last
panel in a row or column is not at the edge of the array
of panels there will be no axis drawn for that row or column,
except that when the said panel is the last in the array
its right y axis will be drawn.  For example,
 > d<-data.frame(x=1:20, y=1:20, g=rep(LETTERS[1:4],len=20))
 > library(lattice)
 > bwplot(floor(x/8)~y|g, layout=c(1,3), as.table=T, data=d)
That bwplot() call should make 2 pages of panels with 3 panels
on page 1 and 1 panel on page 2.  The single panel on the second
page has x tick marks at its top edge, but no tick marks or
labels below it.  Thus you have to look at the first page of
panel to determine the x scale.

In the second example (using the same data.frame) there
are no x or y tick labels for any panel.
 > xyplot(y~x|g, layout=c(3,3), skip=c(T,T,F, F,F,T, T,F,T), as.table=T, data=d)
This example is rather contrived, but might arise when one
wants to omit panels with no data in them but to leave a
hole in the array for unused factor levels in the given
vector.

Exactly the same problem happens in S-Plus.  I patched it to
put an axis on the first and last panels in each row and
column, instead of only on the plots in position 1 and nrow
(or ncol) of each row and column.

One might also fix it by putting axes all around the array of
plots, at the edge of the array.  Perhaps you only want axes
on rows and columns that have at least one plot in them.

One might prefer to only attack the layout(1,n),as.table=T
problem by making sure the last plot has x axis tick labels
associated with it, just as the last plot always gets y
axis tick labels associated with it.

----------------------------------------------------------------------------
Bill Dunlap
Insightful Corporation
bill at insightful dot com
360-428-8146

 "All statements in this message represent the opinions of the author and do
 not necessarily reflect Insightful Corporation policy or position."

--please do not edit the information below--

Version:
 platform = i686-pc-linux-gnu
 arch = i686
 os = linux-gnu
 system = i686, linux-gnu
 status = Under development (unstable)
 major = 2
 minor = 5.0
 year = 2007
 month = 02
 day = 05
 svn rev = 40659
 language = R
 version.string = R version 2.5.0 Under development (unstable) (2007-02-05 r40659)

Locale:
LC_CTYPE=en_US.UTF-8;LC_NUMERIC=C;LC_TIME=en_US.UTF-8;LC_COLLATE=en_US.UTF-8;LC_MONETARY=en_US.UTF-8;LC_MESSAGES=en_US.UTF-8;LC_PAPER=en_US.UTF-8;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=en_US.UTF-8;LC_IDENTIFICATION=C

Search Path:
 .GlobalEnv, package:lattice, package:stats, package:graphics, package:grDevices, package:utils, package:datasets, package:methods, Autoloads, package:base


From hb at stat.berkeley.edu  Wed Mar  7 23:24:29 2007
From: hb at stat.berkeley.edu (Henrik Bengtsson)
Date: Wed, 7 Mar 2007 14:24:29 -0800
Subject: [Rd] Small inconsistency in serialize() between R versions and
	implications on digest()
Message-ID: <59d7961d0703071424l688e50cep99e93e4e9f105bf0@mail.gmail.com>

Hi,

I noticed that serialize() gives different results depending on R
version, which has implications to the digest() function in the digest
package.  Note, it does give the same output across platforms.  I know
that serialize() is under development, but is this expected, e.g. is
there some kind of header in the result that specifies "who" generated
the stream, and if so, exactly what bytes are they?

SETUP:

R versions:
A) R v2.4.0 (2006-10-03)
B) R v2.4.1pat (2007-01-13 r40470)
C) R v2.5.0dev (2006-12-12 r40167)

This is on WinXP and I start R with Rterm --vanilla.

Example: Identical serialize() calls using the different R versions.

> raw <- serialize(1, connection=NULL, ascii=TRUE)
> print(raw)

gives:

(A): [1] 41 0a 32 0a 31 33 32 30 39 36 0a 31 33 31 38 34 30 0a 31 34
0a 31 0a 31 0a
(B): [1] 41 0a 32 0a 31 33 32 30 39 37 0a 31 33 31 38 34 30 0a 31 34
0a 31 0a 31 0a
(C): [1] 41 0a 32 0a 31 33 32 33 35 32 0a 31 33 31 38 34 30 0a 31 34
0a 31 0a 31 0a

Note the difference in raw bytes 8 to 10, i.e.

> raw[7:11]
(A): [1] 32 30 39 36 0a
(B): [1] 32 30 39 37 0a
(C): [1] 32 33 35 32 0a

Does bytes 8, 9 and 10 in the raw vector somehow contain information
about the R version or similar?  The following poor mans test says
that is the only difference:

On all R versions, the following gives identical results:

> raw <- serialize(1:1e4, connection=NULL, ascii=TRUE)
> raw <- as.integer(raw[-c(8:10)])
> sum(raw)
[1] 2147884
> sum(log(raw))
[1] 177201.2

If it is true that there is a R version specific header in serialized
objects, then the digest() function should exclude such header in
order to produce consistent results across R versions, because now
digest(1) gives different results.

Thank you

Henrik


From hb at stat.berkeley.edu  Thu Mar  8 05:11:00 2007
From: hb at stat.berkeley.edu (Henrik Bengtsson)
Date: Wed, 7 Mar 2007 20:11:00 -0800
Subject: [Rd] Small inconsistency in serialize() between R versions and
	implications on digest()
In-Reply-To: <59d7961d0703071424l688e50cep99e93e4e9f105bf0@mail.gmail.com>
References: <59d7961d0703071424l688e50cep99e93e4e9f105bf0@mail.gmail.com>
Message-ID: <59d7961d0703072011v3af90918k51506a557591eb0@mail.gmail.com>

To follow up, I went ahead and generated "random" object to scan for a
common header for a given R version, and it seems to be that at most
the first 18 bytes are non-data specific, which could be the length of
the serialization header.

Here is my code for this:

scanSerialize <- function(object, hdr=NULL, ...) {
  # Serialize object
  raw <- serialize(object, connection=NULL, ascii=TRUE);

  # First run?
  if (is.null(hdr))
    return(raw);

  # Find differences between current longest header and new raw vector
  n <- length(hdr);
  diffs <- (as.integer(hdr) != as.integer(raw[1:n]));

  # No differences?
  if (!any(diffs))
    return(hdr);

  # Position of first difference
  idx <- which(diffs)[1];

  # Keep common header
  hdr <- hdr[seq_len(idx-1)];

  hdr;
};

# Serialize a first "random" object
hdr <- scanSerialize(NA);
for (kk in 1:100)
  hdr <- scanSerialize(kk, hdr=hdr);
for (kk in 1:100) {
  x <- sample(letters, size=sample(100), replace=TRUE);
  hdr <- scanSerialize(x, hdr=hdr);
}
for (kk in 1:100) {
  hdr <- scanSerialize(kk, hdr=hdr);
  hdr <- scanSerialize(hdr, hdr=hdr);
}

cat("Length:", length(hdr), "\n");
print(hdr);
print(rawToChar(hdr));

On R v2.5.0 devel, this gives:
Length: 18
 [1] 41 0a 32 0a 31 33 32 33 35 32 0a 31 33 31 38 34 30 0a
[1] "A\n2\n132352\n131840\n"

However, it would still be good to get an "official" statement from
one in the R-code team about the serialization header and where the
data section start.  Again, I want to cut out as much as possible for
consistency between R version without loosing data dependent bytes.

Thanks

/Henrik

On 3/7/07, Henrik Bengtsson <hb at stat.berkeley.edu> wrote:
> Hi,
>
> I noticed that serialize() gives different results depending on R
> version, which has implications to the digest() function in the digest
> package.  Note, it does give the same output across platforms.  I know
> that serialize() is under development, but is this expected, e.g. is
> there some kind of header in the result that specifies "who" generated
> the stream, and if so, exactly what bytes are they?
>
> SETUP:
>
> R versions:
> A) R v2.4.0 (2006-10-03)
> B) R v2.4.1pat (2007-01-13 r40470)
> C) R v2.5.0dev (2006-12-12 r40167)
>
> This is on WinXP and I start R with Rterm --vanilla.
>
> Example: Identical serialize() calls using the different R versions.
>
> > raw <- serialize(1, connection=NULL, ascii=TRUE)
> > print(raw)
>
> gives:
>
> (A): [1] 41 0a 32 0a 31 33 32 30 39 36 0a 31 33 31 38 34 30 0a 31 34
> 0a 31 0a 31 0a
> (B): [1] 41 0a 32 0a 31 33 32 30 39 37 0a 31 33 31 38 34 30 0a 31 34
> 0a 31 0a 31 0a
> (C): [1] 41 0a 32 0a 31 33 32 33 35 32 0a 31 33 31 38 34 30 0a 31 34
> 0a 31 0a 31 0a
>
> Note the difference in raw bytes 8 to 10, i.e.
>
> > raw[7:11]
> (A): [1] 32 30 39 36 0a
> (B): [1] 32 30 39 37 0a
> (C): [1] 32 33 35 32 0a
>
> Does bytes 8, 9 and 10 in the raw vector somehow contain information
> about the R version or similar?  The following poor mans test says
> that is the only difference:
>
> On all R versions, the following gives identical results:
>
> > raw <- serialize(1:1e4, connection=NULL, ascii=TRUE)
> > raw <- as.integer(raw[-c(8:10)])
> > sum(raw)
> [1] 2147884
> > sum(log(raw))
> [1] 177201.2
>
> If it is true that there is a R version specific header in serialized
> objects, then the digest() function should exclude such header in
> order to produce consistent results across R versions, because now
> digest(1) gives different results.
>
> Thank you
>
> Henrik
>


From luke at stat.uiowa.edu  Thu Mar  8 13:14:12 2007
From: luke at stat.uiowa.edu (Luke Tierney)
Date: Thu, 8 Mar 2007 06:14:12 -0600 (CST)
Subject: [Rd] Small inconsistency in serialize() between R versions and
 implications on digest()
In-Reply-To: <59d7961d0703072011v3af90918k51506a557591eb0@mail.gmail.com>
References: <59d7961d0703071424l688e50cep99e93e4e9f105bf0@mail.gmail.com>
	<59d7961d0703072011v3af90918k51506a557591eb0@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0703080601220.2371@itasca2.wildberry.org>

On Wed, 7 Mar 2007, Henrik Bengtsson wrote:

> To follow up, I went ahead and generated "random" object to scan for a
> common header for a given R version, and it seems to be that at most
> the first 18 bytes are non-data specific, which could be the length of
> the serialization header.
>
> Here is my code for this:
>
> scanSerialize <- function(object, hdr=NULL, ...) {
>  # Serialize object
>  raw <- serialize(object, connection=NULL, ascii=TRUE);
>
>  # First run?
>  if (is.null(hdr))
>    return(raw);
>
>  # Find differences between current longest header and new raw vector
>  n <- length(hdr);
>  diffs <- (as.integer(hdr) != as.integer(raw[1:n]));
>
>  # No differences?
>  if (!any(diffs))
>    return(hdr);
>
>  # Position of first difference
>  idx <- which(diffs)[1];
>
>  # Keep common header
>  hdr <- hdr[seq_len(idx-1)];
>
>  hdr;
> };
>
> # Serialize a first "random" object
> hdr <- scanSerialize(NA);
> for (kk in 1:100)
>  hdr <- scanSerialize(kk, hdr=hdr);
> for (kk in 1:100) {
>  x <- sample(letters, size=sample(100), replace=TRUE);
>  hdr <- scanSerialize(x, hdr=hdr);
> }
> for (kk in 1:100) {
>  hdr <- scanSerialize(kk, hdr=hdr);
>  hdr <- scanSerialize(hdr, hdr=hdr);
> }
>
> cat("Length:", length(hdr), "\n");
> print(hdr);
> print(rawToChar(hdr));
>
> On R v2.5.0 devel, this gives:
> Length: 18
> [1] 41 0a 32 0a 31 33 32 33 35 32 0a 31 33 31 38 34 30 0a
> [1] "A\n2\n132352\n131840\n"
>
> However, it would still be good to get an "official" statement from
> one in the R-code team about the serialization header and where the
> data section start.  Again, I want to cut out as much as possible for
> consistency between R version without loosing data dependent bytes.

An official, and definitive, statement from the _R-core_ team has been
available to you all along at

 	https://svn.r-project.org/R/trunk/src/main/serialize.c

My unofficial and non-definitive interpretation of that statement is
that there is a header of four items,

     A format code 'A' or 'X' ('B' also possible in older formats)
     version number of the format
     Packed integer containint the R version that did the serializing
     Packed integer containing the oldest R version that can read the format

You can see this if you look at the ascii version as text:

     > serialize(1, stdout(), ascii=TRUE)
     A
     2
     132097
     131840
     14
     1
     1
     NULL
     > serialize(as.integer(1), stdout(), ascii=TRUE)
     A
     2
     132097
     131840
     13
     1
     1
     NULL

In the non-ascii 'X' (as in xdr) format this will constitute 13 bytes.
In ascii format I believe it is currently 18 bytes but this could
change with the version number of R -- I'd have to read the official
and definitive statement to see how the integer packing is done and
work out whether that could change the number of bytes. The number of
bytes would also change if we reached format version 10, but something
about the format would also change of course.  A safer way to look at
the header in the ascii version is as the first four lines.

Best,

luke

>
> Thanks
>
> /Henrik
>
> On 3/7/07, Henrik Bengtsson <hb at stat.berkeley.edu> wrote:
>> Hi,
>>
>> I noticed that serialize() gives different results depending on R
>> version, which has implications to the digest() function in the digest
>> package.  Note, it does give the same output across platforms.  I know
>> that serialize() is under development, but is this expected, e.g. is
>> there some kind of header in the result that specifies "who" generated
>> the stream, and if so, exactly what bytes are they?
>>
>> SETUP:
>>
>> R versions:
>> A) R v2.4.0 (2006-10-03)
>> B) R v2.4.1pat (2007-01-13 r40470)
>> C) R v2.5.0dev (2006-12-12 r40167)
>>
>> This is on WinXP and I start R with Rterm --vanilla.
>>
>> Example: Identical serialize() calls using the different R versions.
>>
>>> raw <- serialize(1, connection=NULL, ascii=TRUE)
>>> print(raw)
>>
>> gives:
>>
>> (A): [1] 41 0a 32 0a 31 33 32 30 39 36 0a 31 33 31 38 34 30 0a 31 34
>> 0a 31 0a 31 0a
>> (B): [1] 41 0a 32 0a 31 33 32 30 39 37 0a 31 33 31 38 34 30 0a 31 34
>> 0a 31 0a 31 0a
>> (C): [1] 41 0a 32 0a 31 33 32 33 35 32 0a 31 33 31 38 34 30 0a 31 34
>> 0a 31 0a 31 0a
>>
>> Note the difference in raw bytes 8 to 10, i.e.
>>
>>> raw[7:11]
>> (A): [1] 32 30 39 36 0a
>> (B): [1] 32 30 39 37 0a
>> (C): [1] 32 33 35 32 0a
>>
>> Does bytes 8, 9 and 10 in the raw vector somehow contain information
>> about the R version or similar?  The following poor mans test says
>> that is the only difference:
>>
>> On all R versions, the following gives identical results:
>>
>>> raw <- serialize(1:1e4, connection=NULL, ascii=TRUE)
>>> raw <- as.integer(raw[-c(8:10)])
>>> sum(raw)
>> [1] 2147884
>>> sum(log(raw))
>> [1] 177201.2
>>
>> If it is true that there is a R version specific header in serialized
>> objects, then the digest() function should exclude such header in
>> order to produce consistent results across R versions, because now
>> digest(1) gives different results.
>>
>> Thank you
>>
>> Henrik
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Luke Tierney
Chair, Statistics and Actuarial Science
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From p.murrell at auckland.ac.nz  Thu Mar  8 20:30:16 2007
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Fri, 09 Mar 2007 08:30:16 +1300
Subject: [Rd] Small inconsistency in serialize() between R versions and
 implications on digest()
In-Reply-To: <Pine.LNX.4.64.0703080601220.2371@itasca2.wildberry.org>
References: <59d7961d0703071424l688e50cep99e93e4e9f105bf0@mail.gmail.com>	<59d7961d0703072011v3af90918k51506a557591eb0@mail.gmail.com>
	<Pine.LNX.4.64.0703080601220.2371@itasca2.wildberry.org>
Message-ID: <45F06448.9020102@stat.auckland.ac.nz>

Hi


Luke Tierney wrote:
> On Wed, 7 Mar 2007, Henrik Bengtsson wrote:
> 
>> To follow up, I went ahead and generated "random" object to scan for a
>> common header for a given R version, and it seems to be that at most
>> the first 18 bytes are non-data specific, which could be the length of
>> the serialization header.
>>
>> Here is my code for this:
>>
>> scanSerialize <- function(object, hdr=NULL, ...) {
>>  # Serialize object
>>  raw <- serialize(object, connection=NULL, ascii=TRUE);
>>
>>  # First run?
>>  if (is.null(hdr))
>>    return(raw);
>>
>>  # Find differences between current longest header and new raw vector
>>  n <- length(hdr);
>>  diffs <- (as.integer(hdr) != as.integer(raw[1:n]));
>>
>>  # No differences?
>>  if (!any(diffs))
>>    return(hdr);
>>
>>  # Position of first difference
>>  idx <- which(diffs)[1];
>>
>>  # Keep common header
>>  hdr <- hdr[seq_len(idx-1)];
>>
>>  hdr;
>> };
>>
>> # Serialize a first "random" object
>> hdr <- scanSerialize(NA);
>> for (kk in 1:100)
>>  hdr <- scanSerialize(kk, hdr=hdr);
>> for (kk in 1:100) {
>>  x <- sample(letters, size=sample(100), replace=TRUE);
>>  hdr <- scanSerialize(x, hdr=hdr);
>> }
>> for (kk in 1:100) {
>>  hdr <- scanSerialize(kk, hdr=hdr);
>>  hdr <- scanSerialize(hdr, hdr=hdr);
>> }
>>
>> cat("Length:", length(hdr), "\n");
>> print(hdr);
>> print(rawToChar(hdr));
>>
>> On R v2.5.0 devel, this gives:
>> Length: 18
>> [1] 41 0a 32 0a 31 33 32 33 35 32 0a 31 33 31 38 34 30 0a
>> [1] "A\n2\n132352\n131840\n"
>>
>> However, it would still be good to get an "official" statement from
>> one in the R-code team about the serialization header and where the
>> data section start.  Again, I want to cut out as much as possible for
>> consistency between R version without loosing data dependent bytes.
> 
> An official, and definitive, statement from the _R-core_ team has been
> available to you all along at
> 
>  	https://svn.r-project.org/R/trunk/src/main/serialize.c


There's also a bit of info on this in Section 1.7 of the "R Internals"
Manual.

Paul


> My unofficial and non-definitive interpretation of that statement is
> that there is a header of four items,
> 
>      A format code 'A' or 'X' ('B' also possible in older formats)
>      version number of the format
>      Packed integer containint the R version that did the serializing
>      Packed integer containing the oldest R version that can read the format
> 
> You can see this if you look at the ascii version as text:
> 
>      > serialize(1, stdout(), ascii=TRUE)
>      A
>      2
>      132097
>      131840
>      14
>      1
>      1
>      NULL
>      > serialize(as.integer(1), stdout(), ascii=TRUE)
>      A
>      2
>      132097
>      131840
>      13
>      1
>      1
>      NULL
> 
> In the non-ascii 'X' (as in xdr) format this will constitute 13 bytes.
> In ascii format I believe it is currently 18 bytes but this could
> change with the version number of R -- I'd have to read the official
> and definitive statement to see how the integer packing is done and
> work out whether that could change the number of bytes. The number of
> bytes would also change if we reached format version 10, but something
> about the format would also change of course.  A safer way to look at
> the header in the ascii version is as the first four lines.
> 
> Best,
> 
> luke
> 
>> Thanks
>>
>> /Henrik
>>
>> On 3/7/07, Henrik Bengtsson <hb at stat.berkeley.edu> wrote:
>>> Hi,
>>>
>>> I noticed that serialize() gives different results depending on R
>>> version, which has implications to the digest() function in the digest
>>> package.  Note, it does give the same output across platforms.  I know
>>> that serialize() is under development, but is this expected, e.g. is
>>> there some kind of header in the result that specifies "who" generated
>>> the stream, and if so, exactly what bytes are they?
>>>
>>> SETUP:
>>>
>>> R versions:
>>> A) R v2.4.0 (2006-10-03)
>>> B) R v2.4.1pat (2007-01-13 r40470)
>>> C) R v2.5.0dev (2006-12-12 r40167)
>>>
>>> This is on WinXP and I start R with Rterm --vanilla.
>>>
>>> Example: Identical serialize() calls using the different R versions.
>>>
>>>> raw <- serialize(1, connection=NULL, ascii=TRUE)
>>>> print(raw)
>>> gives:
>>>
>>> (A): [1] 41 0a 32 0a 31 33 32 30 39 36 0a 31 33 31 38 34 30 0a 31 34
>>> 0a 31 0a 31 0a
>>> (B): [1] 41 0a 32 0a 31 33 32 30 39 37 0a 31 33 31 38 34 30 0a 31 34
>>> 0a 31 0a 31 0a
>>> (C): [1] 41 0a 32 0a 31 33 32 33 35 32 0a 31 33 31 38 34 30 0a 31 34
>>> 0a 31 0a 31 0a
>>>
>>> Note the difference in raw bytes 8 to 10, i.e.
>>>
>>>> raw[7:11]
>>> (A): [1] 32 30 39 36 0a
>>> (B): [1] 32 30 39 37 0a
>>> (C): [1] 32 33 35 32 0a
>>>
>>> Does bytes 8, 9 and 10 in the raw vector somehow contain information
>>> about the R version or similar?  The following poor mans test says
>>> that is the only difference:
>>>
>>> On all R versions, the following gives identical results:
>>>
>>>> raw <- serialize(1:1e4, connection=NULL, ascii=TRUE)
>>>> raw <- as.integer(raw[-c(8:10)])
>>>> sum(raw)
>>> [1] 2147884
>>>> sum(log(raw))
>>> [1] 177201.2
>>>
>>> If it is true that there is a R version specific header in serialized
>>> objects, then the digest() function should exclude such header in
>>> order to produce consistent results across R versions, because now
>>> digest(1) gives different results.
>>>
>>> Thank you
>>>
>>> Henrik
>>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
> 

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/


From luke at stat.uiowa.edu  Thu Mar  8 20:43:36 2007
From: luke at stat.uiowa.edu (Luke Tierney)
Date: Thu, 8 Mar 2007 13:43:36 -0600 (CST)
Subject: [Rd] Small inconsistency in serialize() between R versions and
 implications on digest()
In-Reply-To: <45F06448.9020102@stat.auckland.ac.nz>
References: <59d7961d0703071424l688e50cep99e93e4e9f105bf0@mail.gmail.com>
	<59d7961d0703072011v3af90918k51506a557591eb0@mail.gmail.com>
	<Pine.LNX.4.64.0703080601220.2371@itasca2.wildberry.org>
	<45F06448.9020102@stat.auckland.ac.nz>
Message-ID: <Pine.LNX.4.64.0703081340210.7672@nokomis.stat.uiowa.edu>

On Fri, 9 Mar 2007, Paul Murrell wrote:

> Hi
>
>
> Luke Tierney wrote:
>> On Wed, 7 Mar 2007, Henrik Bengtsson wrote:
>>
>>> To follow up, I went ahead and generated "random" object to scan for a
>>> common header for a given R version, and it seems to be that at most
>>> the first 18 bytes are non-data specific, which could be the length of
>>> the serialization header.
>>>
>>> Here is my code for this:
>>>
>>> scanSerialize <- function(object, hdr=NULL, ...) {
>>>  # Serialize object
>>>  raw <- serialize(object, connection=NULL, ascii=TRUE);
>>>
>>>  # First run?
>>>  if (is.null(hdr))
>>>    return(raw);
>>>
>>>  # Find differences between current longest header and new raw vector
>>>  n <- length(hdr);
>>>  diffs <- (as.integer(hdr) != as.integer(raw[1:n]));
>>>
>>>  # No differences?
>>>  if (!any(diffs))
>>>    return(hdr);
>>>
>>>  # Position of first difference
>>>  idx <- which(diffs)[1];
>>>
>>>  # Keep common header
>>>  hdr <- hdr[seq_len(idx-1)];
>>>
>>>  hdr;
>>> };
>>>
>>> # Serialize a first "random" object
>>> hdr <- scanSerialize(NA);
>>> for (kk in 1:100)
>>>  hdr <- scanSerialize(kk, hdr=hdr);
>>> for (kk in 1:100) {
>>>  x <- sample(letters, size=sample(100), replace=TRUE);
>>>  hdr <- scanSerialize(x, hdr=hdr);
>>> }
>>> for (kk in 1:100) {
>>>  hdr <- scanSerialize(kk, hdr=hdr);
>>>  hdr <- scanSerialize(hdr, hdr=hdr);
>>> }
>>>
>>> cat("Length:", length(hdr), "\n");
>>> print(hdr);
>>> print(rawToChar(hdr));
>>>
>>> On R v2.5.0 devel, this gives:
>>> Length: 18
>>> [1] 41 0a 32 0a 31 33 32 33 35 32 0a 31 33 31 38 34 30 0a
>>> [1] "A\n2\n132352\n131840\n"
>>>
>>> However, it would still be good to get an "official" statement from
>>> one in the R-code team about the serialization header and where the
>>> data section start.  Again, I want to cut out as much as possible for
>>> consistency between R version without loosing data dependent bytes.
>>
>> An official, and definitive, statement from the _R-core_ team has been
>> available to you all along at
>>
>>  	https://svn.r-project.org/R/trunk/src/main/serialize.c
>
>
> There's also a bit of info on this in Section 1.7 of the "R Internals"
> Manual.
>
> Paul

Thanks -- I'd forgotten about that.  Looking at that shows that my
unofficial and non-definitive interpretation was not quite right for
the binary case -- the header there is 14 bytes (I forgot that there
is a \n after the X even in the binary case).

Best,

luke

>
>
>> My unofficial and non-definitive interpretation of that statement is
>> that there is a header of four items,
>>
>>      A format code 'A' or 'X' ('B' also possible in older formats)
>>      version number of the format
>>      Packed integer containint the R version that did the serializing
>>      Packed integer containing the oldest R version that can read the format
>>
>> You can see this if you look at the ascii version as text:
>>
>>     > serialize(1, stdout(), ascii=TRUE)
>>      A
>>      2
>>      132097
>>      131840
>>      14
>>      1
>>      1
>>      NULL
>>     > serialize(as.integer(1), stdout(), ascii=TRUE)
>>      A
>>      2
>>      132097
>>      131840
>>      13
>>      1
>>      1
>>      NULL
>>
>> In the non-ascii 'X' (as in xdr) format this will constitute 13 bytes.
>> In ascii format I believe it is currently 18 bytes but this could
>> change with the version number of R -- I'd have to read the official
>> and definitive statement to see how the integer packing is done and
>> work out whether that could change the number of bytes. The number of
>> bytes would also change if we reached format version 10, but something
>> about the format would also change of course.  A safer way to look at
>> the header in the ascii version is as the first four lines.
>>
>> Best,
>>
>> luke
>>
>>> Thanks
>>>
>>> /Henrik
>>>
>>> On 3/7/07, Henrik Bengtsson <hb at stat.berkeley.edu> wrote:
>>>> Hi,
>>>>
>>>> I noticed that serialize() gives different results depending on R
>>>> version, which has implications to the digest() function in the digest
>>>> package.  Note, it does give the same output across platforms.  I know
>>>> that serialize() is under development, but is this expected, e.g. is
>>>> there some kind of header in the result that specifies "who" generated
>>>> the stream, and if so, exactly what bytes are they?
>>>>
>>>> SETUP:
>>>>
>>>> R versions:
>>>> A) R v2.4.0 (2006-10-03)
>>>> B) R v2.4.1pat (2007-01-13 r40470)
>>>> C) R v2.5.0dev (2006-12-12 r40167)
>>>>
>>>> This is on WinXP and I start R with Rterm --vanilla.
>>>>
>>>> Example: Identical serialize() calls using the different R versions.
>>>>
>>>>> raw <- serialize(1, connection=NULL, ascii=TRUE)
>>>>> print(raw)
>>>> gives:
>>>>
>>>> (A): [1] 41 0a 32 0a 31 33 32 30 39 36 0a 31 33 31 38 34 30 0a 31 34
>>>> 0a 31 0a 31 0a
>>>> (B): [1] 41 0a 32 0a 31 33 32 30 39 37 0a 31 33 31 38 34 30 0a 31 34
>>>> 0a 31 0a 31 0a
>>>> (C): [1] 41 0a 32 0a 31 33 32 33 35 32 0a 31 33 31 38 34 30 0a 31 34
>>>> 0a 31 0a 31 0a
>>>>
>>>> Note the difference in raw bytes 8 to 10, i.e.
>>>>
>>>>> raw[7:11]
>>>> (A): [1] 32 30 39 36 0a
>>>> (B): [1] 32 30 39 37 0a
>>>> (C): [1] 32 33 35 32 0a
>>>>
>>>> Does bytes 8, 9 and 10 in the raw vector somehow contain information
>>>> about the R version or similar?  The following poor mans test says
>>>> that is the only difference:
>>>>
>>>> On all R versions, the following gives identical results:
>>>>
>>>>> raw <- serialize(1:1e4, connection=NULL, ascii=TRUE)
>>>>> raw <- as.integer(raw[-c(8:10)])
>>>>> sum(raw)
>>>> [1] 2147884
>>>>> sum(log(raw))
>>>> [1] 177201.2
>>>>
>>>> If it is true that there is a R version specific header in serialized
>>>> objects, then the digest() function should exclude such header in
>>>> order to produce consistent results across R versions, because now
>>>> digest(1) gives different results.
>>>>
>>>> Thank you
>>>>
>>>> Henrik
>>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>
>
>

-- 
Luke Tierney
Chair, Statistics and Actuarial Science
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From hb at stat.berkeley.edu  Thu Mar  8 21:57:29 2007
From: hb at stat.berkeley.edu (Henrik Bengtsson)
Date: Thu, 8 Mar 2007 12:57:29 -0800
Subject: [Rd] Small inconsistency in serialize() between R versions and
	implications on digest()
In-Reply-To: <Pine.LNX.4.64.0703081340210.7672@nokomis.stat.uiowa.edu>
References: <59d7961d0703071424l688e50cep99e93e4e9f105bf0@mail.gmail.com>
	<59d7961d0703072011v3af90918k51506a557591eb0@mail.gmail.com>
	<Pine.LNX.4.64.0703080601220.2371@itasca2.wildberry.org>
	<45F06448.9020102@stat.auckland.ac.nz>
	<Pine.LNX.4.64.0703081340210.7672@nokomis.stat.uiowa.edu>
Message-ID: <59d7961d0703081257m2bf9e422h14fafbeaf2bc8c09@mail.gmail.com>

On 3/8/07, Luke Tierney <luke at stat.uiowa.edu> wrote:
> On Fri, 9 Mar 2007, Paul Murrell wrote:
>
> > Hi
> >
> >
> > Luke Tierney wrote:
> >> On Wed, 7 Mar 2007, Henrik Bengtsson wrote:
> >>
> >>> To follow up, I went ahead and generated "random" object to scan for a
> >>> common header for a given R version, and it seems to be that at most
> >>> the first 18 bytes are non-data specific, which could be the length of
> >>> the serialization header.
> >>>
> >>> Here is my code for this:
> >>>
> >>> scanSerialize <- function(object, hdr=NULL, ...) {
> >>>  # Serialize object
> >>>  raw <- serialize(object, connection=NULL, ascii=TRUE);
> >>>
> >>>  # First run?
> >>>  if (is.null(hdr))
> >>>    return(raw);
> >>>
> >>>  # Find differences between current longest header and new raw vector
> >>>  n <- length(hdr);
> >>>  diffs <- (as.integer(hdr) != as.integer(raw[1:n]));
> >>>
> >>>  # No differences?
> >>>  if (!any(diffs))
> >>>    return(hdr);
> >>>
> >>>  # Position of first difference
> >>>  idx <- which(diffs)[1];
> >>>
> >>>  # Keep common header
> >>>  hdr <- hdr[seq_len(idx-1)];
> >>>
> >>>  hdr;
> >>> };
> >>>
> >>> # Serialize a first "random" object
> >>> hdr <- scanSerialize(NA);
> >>> for (kk in 1:100)
> >>>  hdr <- scanSerialize(kk, hdr=hdr);
> >>> for (kk in 1:100) {
> >>>  x <- sample(letters, size=sample(100), replace=TRUE);
> >>>  hdr <- scanSerialize(x, hdr=hdr);
> >>> }
> >>> for (kk in 1:100) {
> >>>  hdr <- scanSerialize(kk, hdr=hdr);
> >>>  hdr <- scanSerialize(hdr, hdr=hdr);
> >>> }
> >>>
> >>> cat("Length:", length(hdr), "\n");
> >>> print(hdr);
> >>> print(rawToChar(hdr));
> >>>
> >>> On R v2.5.0 devel, this gives:
> >>> Length: 18
> >>> [1] 41 0a 32 0a 31 33 32 33 35 32 0a 31 33 31 38 34 30 0a
> >>> [1] "A\n2\n132352\n131840\n"
> >>>
> >>> However, it would still be good to get an "official" statement from
> >>> one in the R-code team about the serialization header and where the
> >>> data section start.  Again, I want to cut out as much as possible for
> >>> consistency between R version without loosing data dependent bytes.
> >>
> >> An official, and definitive, statement from the _R-core_ team has been
> >> available to you all along at
> >>
> >>      https://svn.r-project.org/R/trunk/src/main/serialize.c
> >
> >
> > There's also a bit of info on this in Section 1.7 of the "R Internals"
> > Manual.
> >
> > Paul
>
> Thanks -- I'd forgotten about that.  Looking at that shows that my
> unofficial and non-definitive interpretation was not quite right for
> the binary case -- the header there is 14 bytes (I forgot that there
> is a \n after the X even in the binary case).

Luke and Paul, thank you for this.  Searching for the 4th newline
seems to be the most robust thing to do in the ASCII case.

/Henrik

>
> Best,
>
> luke
>
> >
> >
> >> My unofficial and non-definitive interpretation of that statement is
> >> that there is a header of four items,
> >>
> >>      A format code 'A' or 'X' ('B' also possible in older formats)
> >>      version number of the format
> >>      Packed integer containint the R version that did the serializing
> >>      Packed integer containing the oldest R version that can read the format
> >>
> >> You can see this if you look at the ascii version as text:
> >>
> >>     > serialize(1, stdout(), ascii=TRUE)
> >>      A
> >>      2
> >>      132097
> >>      131840
> >>      14
> >>      1
> >>      1
> >>      NULL
> >>     > serialize(as.integer(1), stdout(), ascii=TRUE)
> >>      A
> >>      2
> >>      132097
> >>      131840
> >>      13
> >>      1
> >>      1
> >>      NULL
> >>
> >> In the non-ascii 'X' (as in xdr) format this will constitute 13 bytes.
> >> In ascii format I believe it is currently 18 bytes but this could
> >> change with the version number of R -- I'd have to read the official
> >> and definitive statement to see how the integer packing is done and
> >> work out whether that could change the number of bytes. The number of
> >> bytes would also change if we reached format version 10, but something
> >> about the format would also change of course.  A safer way to look at
> >> the header in the ascii version is as the first four lines.
> >>
> >> Best,
> >>
> >> luke
> >>
> >>> Thanks
> >>>
> >>> /Henrik
> >>>
> >>> On 3/7/07, Henrik Bengtsson <hb at stat.berkeley.edu> wrote:
> >>>> Hi,
> >>>>
> >>>> I noticed that serialize() gives different results depending on R
> >>>> version, which has implications to the digest() function in the digest
> >>>> package.  Note, it does give the same output across platforms.  I know
> >>>> that serialize() is under development, but is this expected, e.g. is
> >>>> there some kind of header in the result that specifies "who" generated
> >>>> the stream, and if so, exactly what bytes are they?
> >>>>
> >>>> SETUP:
> >>>>
> >>>> R versions:
> >>>> A) R v2.4.0 (2006-10-03)
> >>>> B) R v2.4.1pat (2007-01-13 r40470)
> >>>> C) R v2.5.0dev (2006-12-12 r40167)
> >>>>
> >>>> This is on WinXP and I start R with Rterm --vanilla.
> >>>>
> >>>> Example: Identical serialize() calls using the different R versions.
> >>>>
> >>>>> raw <- serialize(1, connection=NULL, ascii=TRUE)
> >>>>> print(raw)
> >>>> gives:
> >>>>
> >>>> (A): [1] 41 0a 32 0a 31 33 32 30 39 36 0a 31 33 31 38 34 30 0a 31 34
> >>>> 0a 31 0a 31 0a
> >>>> (B): [1] 41 0a 32 0a 31 33 32 30 39 37 0a 31 33 31 38 34 30 0a 31 34
> >>>> 0a 31 0a 31 0a
> >>>> (C): [1] 41 0a 32 0a 31 33 32 33 35 32 0a 31 33 31 38 34 30 0a 31 34
> >>>> 0a 31 0a 31 0a
> >>>>
> >>>> Note the difference in raw bytes 8 to 10, i.e.
> >>>>
> >>>>> raw[7:11]
> >>>> (A): [1] 32 30 39 36 0a
> >>>> (B): [1] 32 30 39 37 0a
> >>>> (C): [1] 32 33 35 32 0a
> >>>>
> >>>> Does bytes 8, 9 and 10 in the raw vector somehow contain information
> >>>> about the R version or similar?  The following poor mans test says
> >>>> that is the only difference:
> >>>>
> >>>> On all R versions, the following gives identical results:
> >>>>
> >>>>> raw <- serialize(1:1e4, connection=NULL, ascii=TRUE)
> >>>>> raw <- as.integer(raw[-c(8:10)])
> >>>>> sum(raw)
> >>>> [1] 2147884
> >>>>> sum(log(raw))
> >>>> [1] 177201.2
> >>>>
> >>>> If it is true that there is a R version specific header in serialized
> >>>> objects, then the digest() function should exclude such header in
> >>>> order to produce consistent results across R versions, because now
> >>>> digest(1) gives different results.
> >>>>
> >>>> Thank you
> >>>>
> >>>> Henrik
> >>>>
> >>> ______________________________________________
> >>> R-devel at r-project.org mailing list
> >>> https://stat.ethz.ch/mailman/listinfo/r-devel
> >>>
> >>
> >
> >
>
> --
> Luke Tierney
> Chair, Statistics and Actuarial Science
> Ralph E. Wareham Professor of Mathematical Sciences
> University of Iowa                  Phone:             319-335-3386
> Department of Statistics and        Fax:               319-335-3017
>     Actuarial Science
> 241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
> Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu
>


From gregor.gorjanc at bfro.uni-lj.si  Fri Mar  9 11:25:14 2007
From: gregor.gorjanc at bfro.uni-lj.si (Gregor Gorjanc)
Date: Fri, 09 Mar 2007 11:25:14 +0100
Subject: [Rd] fortune() in .Rprofile conflicts with R CMD INSTALL
In-Reply-To: <17900.35746.713592.701130@mithrandir.hornik.net>
References: <45EAB839.9090203@bfro.uni-lj.si>	<m2tzx19e3l.fsf@ziti.local>	<loom.20070304T230316-753@post.gmane.org>	<17899.65192.532067.867254@mithrandir.hornik.net>
	<17900.35746.713592.701130@mithrandir.hornik.net>
Message-ID: <45F1360A.20602@bfro.uni-lj.si>

Kurt Hornik wrote:
>>>>>> Kurt Hornik writes:
 >> Well, r-devel's src/scripts/INSTALL.in now has
> 
>> if test -z "${lib}"; then
>>   lib=`echo "cat(.libPaths()[1])" | \
>>     R_DEFAULT_PACKAGES=NULL "${R_EXE}" --no-save --slave`
>>   message "Installing to library '$lib'"
> 
>> so we need to find a way to "just get" the result of cat(.libPaths()[1])
>> into $lib as intended.
> 
>> One idea might be ensuring that this gets into the last line on its own,
>> and then taking $lib as the last line of what we got ...
> 
> I think I found (and committed) a solution for this.

Yep, looks OK now.

Thanks, Gregor


From hb at stat.berkeley.edu  Sun Mar 11 21:35:08 2007
From: hb at stat.berkeley.edu (Henrik Bengtsson)
Date: Sun, 11 Mar 2007 21:35:08 +0100
Subject: [Rd] File locking in R?
Message-ID: <59d7961d0703111335t7b11bf56paea0b76e1f1c3174@mail.gmail.com>

Hi,

I guess the answer will be no, because of the different underlying
operating systems, but just in case: Is there a way to open a file
such that it is locked for other processes to write to it (until the
file is closed/the lock is released)?

/Henrik


From sgiannerini at gmail.com  Mon Mar 12 13:15:48 2007
From: sgiannerini at gmail.com (Simone Giannerini)
Date: Mon, 12 Mar 2007 13:15:48 +0100
Subject: [Rd] Is there any package on CRAN that uses Fortran-90/95
In-Reply-To: <7FFEE688B57D7346BC6241C55900E730F31D73@pollux.bfro.uni-lj.si>
References: <7FFEE688B57D7346BC6241C55900E730F31D73@pollux.bfro.uni-lj.si>
Message-ID: <3c12769c0703120515l6ddc3e3am6ceb0e603faea7b9@mail.gmail.com>

I use F95 code in some functions of the developement version of the
package tseriesChaos
but I must say we have encountered so many problems with the gfortran
compiler (both on Win and Linux) that we are compelled to distribute
at least the Win binaries separately.
The new version of the package is not on CRAN yet but you may follow
its development and download the F90 code here:

http://code.google.com/p/tserieschaos/


Regards

Simone



On 2/26/07, Gorjanc Gregor <Gregor.Gorjanc at bfro.uni-lj.si> wrote:
> Hi!
>
> Is there any package on CRAN that uses Fortran-90/95? I would like
> to study it.
>
> Thanks, Gregor
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


-- 
______________________________________________________

Simone Giannerini
Dipartimento di Scienze Statistiche "Paolo Fortunati"
Universita' di Bologna
Via delle belle arti 41 - 40126  Bologna,  ITALY
Tel: +39 051 2098262  Fax: +39 051 232153


From Bert.DeBoeck at Ugent.be  Thu Mar  8 15:56:35 2007
From: Bert.DeBoeck at Ugent.be (Bert.DeBoeck at Ugent.be)
Date: Thu,  8 Mar 2007 15:56:35 +0100 (CET)
Subject: [Rd] integrate function (PR#9557)
Message-ID: <20070308145635.BF93819B3B@slim.kubism.ku.dk>

Full_Name: Bert De Boeck
Version: R 2.2.0
OS: Windows
Submission from: (NULL) (157.193.193.152)


I think there is a bug when using integrate for integrating a function which is
0 in a whole sub-interval. For example:

#define uniform function
f<-function(x){ifelse(x<1,0,ifelse(x<3,1,0))}

#this is the correct integral
integrate(f,-10,10)

#here there is a problem
integrate(f,-50,50)
integrate(f,-10,50)
integrate(f,-50,10)
integrate(f,-50,50,sub=10000)

# I noticed this for a more complex function, but as you see even for a trivial

# function there is a serious problem


From sgiannerini at gmail.com  Mon Mar 12 19:13:25 2007
From: sgiannerini at gmail.com (Simone Giannerini)
Date: Mon, 12 Mar 2007 19:13:25 +0100
Subject: [Rd] integrate function (PR#9557)
In-Reply-To: <20070308145635.BF93819B3B@slim.kubism.ku.dk>
References: <20070308145635.BF93819B3B@slim.kubism.ku.dk>
Message-ID: <3c12769c0703121113u637b227h10e1456cebba8f54@mail.gmail.com>

I think the behaviour is somehow documented, see ?integrate, in any case
I take the opportunity to report some more on integrate:


Under Win XP (AMD 64 3700+ 2Gb RAM)

> integrate(dnorm,0,2,sub=1e+09)
Error: cannot allocate vector of size 1889872 Kb
In addition: Warning messages:
1: Reached total allocation of 1536Mb: see help(memory.size)
2: Reached total allocation of 1536Mb: see help(memory.size)

> integrate(dnorm,0,2,sub=1e+10)
Error in if (limit < 1 || (abs.tol <= 0 && rel.tol < max(50 *
.Machine$double.eps,  :
        missing value where TRUE/FALSE needed
In addition: Warning message:
NAs introduced by coercion

but .....

> integrate(dnorm,0,2,sub=1e+08)

crashes the RGUI with an access violation error

> R.version
               _
platform       i386-pc-mingw32
arch           i386
os             mingw32
system         i386, mingw32
status
major          2
minor          4.1
year           2006
month          12
day            18
svn rev        40228
language       R
version.string R version 2.4.1 (2006-12-18)


*****************************************************************************************
Under LINUX SUSE 10.2 (Quad Opteron 8218 32Gb RAM)

> integrate(dnorm,0,2,sub=1e+08)
0.4772499 with absolute error < 5.3e-15

> integrate(dnorm,0,2,sub=1e+09)

 *** caught segfault ***
address (nil), cause 'memory not mapped'

Traceback:
 1: .External("call_dqags", ff, rho = environment(), as.double(lower),
    as.double(upper), as.double(abs.tol), as.double(rel.tol),
limit = limit, PACKAGE = "base")
 2: integrate(dnorm, 0, 2, sub = 1e+09)



> R.version
               _
platform       x86_64-unknown-linux-gnu
arch           x86_64
os             linux-gnu
system         x86_64, linux-gnu
status
major          2
minor          4.1
year           2006
month          12
day            18
svn rev        40228
language       R
version.string R version 2.4.1 (2006-12-18)

______________________________________________________

Simone Giannerini
Dipartimento di Scienze Statistiche "Paolo Fortunati"
Universita' di Bologna
Via delle belle arti 41 - 40126  Bologna,  ITALY
Tel: +39 051 2098262  Fax: +39 051 232153
______________________________________________________


On 3/8/07, Bert.DeBoeck at ugent.be <Bert.DeBoeck at ugent.be> wrote:
> Full_Name: Bert De Boeck
> Version: R 2.2.0
> OS: Windows
> Submission from: (NULL) (157.193.193.152)
>
>
> I think there is a bug when using integrate for integrating a function which is
> 0 in a whole sub-interval. For example:
>
> #define uniform function
> f<-function(x){ifelse(x<1,0,ifelse(x<3,1,0))}
>
> #this is the correct integral
> integrate(f,-10,10)
>
> #here there is a problem
> integrate(f,-50,50)
> integrate(f,-10,50)
> integrate(f,-50,10)
> integrate(f,-50,50,sub=10000)
>
> # I noticed this for a more complex function, but as you see even for a trivial
>
> # function there is a serious problem
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


-- 
______________________________________________________

Simone Giannerini
Dipartimento di Scienze Statistiche "Paolo Fortunati"
Universita' di Bologna
Via delle belle arti 41 - 40126  Bologna,  ITALY
Tel: +39 051 2098262  Fax: +39 051 232153


From tlumley at u.washington.edu  Mon Mar 12 19:23:37 2007
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon, 12 Mar 2007 11:23:37 -0700 (PDT)
Subject: [Rd] integrate function (PR#9557)
In-Reply-To: <20070308145635.BF93819B3B@slim.kubism.ku.dk>
References: <20070308145635.BF93819B3B@slim.kubism.ku.dk>
Message-ID: <Pine.LNX.4.64.0703121118480.30727@homer24.u.washington.edu>


This is what numerical integration functions are like, unfortunately. 
That's why the help page says:
  "Like all numerical integration routines, these evaluate the function on a
   finite set of points. If the function is approximately constant (in
   particular, zero) over nearly all its range it is possible that the
   result and error estimate may be seriously wrong."

If you know anything about where the function has jumps you can use this 
knowledge to pick better intervals.  Changing the subdvisions argument has 
no effect, since this is the *maximum* number, not the minimum number.

I don't think we know of numerical quadrature routines that are uniformly 
better than these and GPL-compatible.

 	-thomas


On Thu, 8 Mar 2007, Bert.DeBoeck at Ugent.be wrote:

> Full_Name: Bert De Boeck
> Version: R 2.2.0
> OS: Windows
> Submission from: (NULL) (157.193.193.152)
>
>
> I think there is a bug when using integrate for integrating a function which is
> 0 in a whole sub-interval. For example:
>
> #define uniform function
> f<-function(x){ifelse(x<1,0,ifelse(x<3,1,0))}
>
> #this is the correct integral
> integrate(f,-10,10)
>
> #here there is a problem
> integrate(f,-50,50)
> integrate(f,-10,50)
> integrate(f,-50,10)
> integrate(f,-50,50,sub=10000)
>
> # I noticed this for a more complex function, but as you see even for a trivial
>
> # function there is a serious problem
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle


From murdoch at stats.uwo.ca  Mon Mar 12 19:42:07 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Mon, 12 Mar 2007 14:42:07 -0400
Subject: [Rd] integrate function (PR#9557)
In-Reply-To: <3c12769c0703121113u637b227h10e1456cebba8f54@mail.gmail.com>
References: <20070308145635.BF93819B3B@slim.kubism.ku.dk>
	<3c12769c0703121113u637b227h10e1456cebba8f54@mail.gmail.com>
Message-ID: <45F59EFF.9020506@stats.uwo.ca>

On 3/12/2007 2:13 PM, Simone Giannerini wrote:
> I think the behaviour is somehow documented, see ?integrate, in any case
> I take the opportunity to report some more on integrate:
> 
> 
> Under Win XP (AMD 64 3700+ 2Gb RAM)
> 
>> integrate(dnorm,0,2,sub=1e+09)
> Error: cannot allocate vector of size 1889872 Kb
> In addition: Warning messages:
> 1: Reached total allocation of 1536Mb: see help(memory.size)
> 2: Reached total allocation of 1536Mb: see help(memory.size)
> 
>> integrate(dnorm,0,2,sub=1e+10)
> Error in if (limit < 1 || (abs.tol <= 0 && rel.tol < max(50 *
> .Machine$double.eps,  :
>         missing value where TRUE/FALSE needed
> In addition: Warning message:
> NAs introduced by coercion
> 
> but .....
> 
>> integrate(dnorm,0,2,sub=1e+08)
> 
> crashes the RGUI with an access violation error

I see this in 2.4.1 and R-patched, but not in R-devel.  It appears to 
have been fixed by Brian Ripley as part of his improvement of the 
allocation error messages; I'll port just the fix part over to R-patched.

Duncan Murdoch

>> R.version
>                _
> platform       i386-pc-mingw32
> arch           i386
> os             mingw32
> system         i386, mingw32
> status
> major          2
> minor          4.1
> year           2006
> month          12
> day            18
> svn rev        40228
> language       R
> version.string R version 2.4.1 (2006-12-18)
> 
> 
> *****************************************************************************************
> Under LINUX SUSE 10.2 (Quad Opteron 8218 32Gb RAM)
> 
>> integrate(dnorm,0,2,sub=1e+08)
> 0.4772499 with absolute error < 5.3e-15
> 
>> integrate(dnorm,0,2,sub=1e+09)
> 
>  *** caught segfault ***
> address (nil), cause 'memory not mapped'
> 
> Traceback:
>  1: .External("call_dqags", ff, rho = environment(), as.double(lower),
>     as.double(upper), as.double(abs.tol), as.double(rel.tol),
> limit = limit, PACKAGE = "base")
>  2: integrate(dnorm, 0, 2, sub = 1e+09)

> 
> 
> 
>> R.version
>                _
> platform       x86_64-unknown-linux-gnu
> arch           x86_64
> os             linux-gnu
> system         x86_64, linux-gnu
> status
> major          2
> minor          4.1
> year           2006
> month          12
> day            18
> svn rev        40228
> language       R
> version.string R version 2.4.1 (2006-12-18)
> 
> ______________________________________________________
> 
> Simone Giannerini
> Dipartimento di Scienze Statistiche "Paolo Fortunati"
> Universita' di Bologna
> Via delle belle arti 41 - 40126  Bologna,  ITALY
> Tel: +39 051 2098262  Fax: +39 051 232153
> ______________________________________________________
> 
> 
> On 3/8/07, Bert.DeBoeck at ugent.be <Bert.DeBoeck at ugent.be> wrote:
>> Full_Name: Bert De Boeck
>> Version: R 2.2.0
>> OS: Windows
>> Submission from: (NULL) (157.193.193.152)
>>
>>
>> I think there is a bug when using integrate for integrating a function which is
>> 0 in a whole sub-interval. For example:
>>
>> #define uniform function
>> f<-function(x){ifelse(x<1,0,ifelse(x<3,1,0))}
>>
>> #this is the correct integral
>> integrate(f,-10,10)
>>
>> #here there is a problem
>> integrate(f,-50,50)
>> integrate(f,-10,50)
>> integrate(f,-50,10)
>> integrate(f,-50,50,sub=10000)
>>
>> # I noticed this for a more complex function, but as you see even for a trivial
>>
>> # function there is a serious problem
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
> 
>


From hin-tak.leung at cimr.cam.ac.uk  Tue Mar 13 16:46:20 2007
From: hin-tak.leung at cimr.cam.ac.uk (Hin-Tak Leung)
Date: Tue, 13 Mar 2007 15:46:20 +0000
Subject: [Rd] configure cross_compiling+iconv wierdness
Message-ID: <45F6C74C.4050907@cimr.cam.ac.uk>

Hi,

I noticed sometimes ago that my 32-bit R 2.4.1 is
non-MBSC/iconv capable, whereas my 64-bit R (both built locally
myself, on x86_64 linux) is. I know my system is
rather beefed up on any kind of CJK-related stuff, and it shouldn't
be the case. So I just looked into it, and found that the configure
script basically automatically assume that the system is non-iconv/MBSC
capable if it looks as if one is trying to cross-compile:

===============
   echo "$as_me:$LINENO: checking whether iconv() accepts \"UTF-8\", 
\"latin1\" and \"UCS-*\"" >&5
echo $ECHO_N "checking whether iconv() accepts \"UTF-8\", \"latin1\" and 
\"UCS-*\"... $ECHO_C" >&6
if test "${r_cv_iconv_latin1+set}" = set; then
   echo $ECHO_N "(cached) $ECHO_C" >&6
else
   if test "$cross_compiling" = yes; then
   r_cv_iconv_latin1=no
else
   cat >conftest.$ac_ext <<_ACEOF
.....
_ACEOF
=============

FWIW, I am doing my "cross-compile" with a slightly more complicated 
version of this:

LDFLAGS=-m32 CFLAGS=-m32 CPPFLAGS=-m32 CXXFLAGS=-m32 FFLAGS=-m32 \
./configure --build=x86_64-redhat-linux-gnu \
--target=i686-redhat-linux-gnu --host=i686-redhat-linux-gnu

okay, now that I know what's going on, I can work around it, but
I think the "else" part probably should skip the cross_compiling
check, at least under some circumstance, and drop through to
the explicit test...

Thanks for listening...

Hin-Tak Leung


From tcallawa at redhat.com  Tue Mar 13 21:05:15 2007
From: tcallawa at redhat.com (Tom 'spot' Callaway)
Date: Tue, 13 Mar 2007 15:05:15 -0500
Subject: [Rd] Support for noarch packages in /usr/share/R/library
Message-ID: <1173816315.15673.6.camel@localhost.localdomain>

As originally raised here:
https://bugzilla.redhat.com/bugzilla/show_bug.cgi?id=231220

It has been proposed that R should support noarch packages
in /usr/share/R/library in addition to architecture specific packages
in /usr/lib/R/library or /usr/lib64/R/library.

For example, the mAr addon doesn't have any architecture specific bits.
Strictly speaking, the Filesystem Hierarchy Standard says it doesn't
belong in /usr/lib, but rather, /usr/share.

Ideas on the best way to resolve this would be greatly appreciated.

Thanks in advance,

~spot


From edd at debian.org  Wed Mar 14 04:16:03 2007
From: edd at debian.org (Dirk Eddelbuettel)
Date: Tue, 13 Mar 2007 22:16:03 -0500
Subject: [Rd] Support for noarch packages in /usr/share/R/library
In-Reply-To: <1173816315.15673.6.camel@localhost.localdomain>
References: <1173816315.15673.6.camel@localhost.localdomain>
Message-ID: <17911.26867.251483.409870@basebud.nulle.part>


Tom,

On 13 March 2007 at 15:05, Tom 'spot' Callaway wrote:
| As originally raised here:
| https://bugzilla.redhat.com/bugzilla/show_bug.cgi?id=231220
| 
| It has been proposed that R should support noarch packages
| in /usr/share/R/library in addition to architecture specific packages
| in /usr/lib/R/library or /usr/lib64/R/library.
| 
| For example, the mAr addon doesn't have any architecture specific bits.
| Strictly speaking, the Filesystem Hierarchy Standard says it doesn't
| belong in /usr/lib, but rather, /usr/share.
| 
| Ideas on the best way to resolve this would be greatly appreciated.

[ NB I don't speal for R Core here so take it with a grain of salt... ]

Well, R already allows you to source packages from different
directories. E.g. for Debian, we have long used

edd at basebud:~> grep -B2 R_LIBS /etc/R/Renviron
# edd Apr 2003  Allow local install in /usr/local, also add a directory for
#               Debian packaged CRAN packages, and finally the default dir
R_LIBS=${R_LIBS-'/usr/local/lib/R/site-library:/usr/lib/R/site-library:/usr/lib/R/library'}

which uses 

	/usr/local/lib/R/site-library		'user' stuff
	/usr/lib/R/site-library			debs but not r-recommended
	/usr/lib/R/library			debs from r-recommended

Now, if I wanted to, I guess I could modify our already effectively automated
scripts that build the few r-cran-* Debian packages to

a) detect if they are 'arch' or 'noarch', and 

b) in the case of 'noarch' install into a fourth location

	/usr/share/R/site-library		'noarch' debs 

   provided that R_LIBS has also been updated to look there.  

Conceptually at least, this should work.  Ultimately, the FHS has a valid
point and R Core may decide to eventually support this automagically -- just
as R did move towards some support of /usr/share/R after some prodding
following an initial bug report by a Debian user. 

That said, I think the OP from the bugzilla report you referenec may not be
aware just much a 'one file tree below $R_HOME' view R itself (still) has,
but that is a different story.

Hoep this helps, Dirk

-- 
Hell, there are no rules here - we're trying to accomplish something. 
                                                  -- Thomas A. Edison


From aferris at mrl.ubc.ca  Wed Mar 14 18:56:02 2007
From: aferris at mrl.ubc.ca (Andrew Ferris)
Date: Wed, 14 Mar 2007 10:56:02 -0700
Subject: [Rd] compile 2.4.1 for linux on power cpus
References: <45F7CB380200007B0004C384@mail.mrl.ubc.ca>
	<45F7D4C20200007B0004C3BF@mail.mrl.ubc.ca>
Message-ID: <45F7D4C2.0211.007B.0@mrl.ubc.ca>

Hello,

I've been asked to get R (2.4.1) installed on a IBM p570 server. This is a server with power CPUs and is running SLES 10. It currently has 12GB of RAM so I'd like to make sure I have the 64 bit version of R so as to take advantage of the extra memory. Since it's a power CPU server that means I'll have to compile R from source. 

I've searched the r_users list but most of the power CPU correspondence concerns either AIX or Macs. SLES 10 uses GCC 4.1.0 by default. Could someone please help me with some guidance on the necessary parameters for configure to ensure a 64 bit version of R is compiled? 
 

Andrew Ferris
Network Support Analyst
iCAPTURE Research Centre
University of British Columbia


***CONFIDENTIALITY NOTICE***
This electronic message is intended only for the use of the addressee and may contain information that is privileged and confidential.  Any dissemination, distribution or copying of this communication by unauthorized individuals is strictly prohibited. If you have received this communication in error, please notify the sender immediately by reply e-mail and delete the original and all copies from your system.


From p.dalgaard at biostat.ku.dk  Wed Mar 14 21:34:21 2007
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Wed, 14 Mar 2007 21:34:21 +0100
Subject: [Rd] compile 2.4.1 for linux on power cpus
In-Reply-To: <45F7D4C2.0211.007B.0@mrl.ubc.ca>
References: <45F7CB380200007B0004C384@mail.mrl.ubc.ca>	<45F7D4C20200007B0004C3BF@mail.mrl.ubc.ca>
	<45F7D4C2.0211.007B.0@mrl.ubc.ca>
Message-ID: <45F85C4D.9080005@biostat.ku.dk>

Andrew Ferris wrote:
> Hello,
>
> I've been asked to get R (2.4.1) installed on a IBM p570 server. This is a server with power CPUs and is running SLES 10. It currently has 12GB of RAM so I'd like to make sure I have the 64 bit version of R so as to take advantage of the extra memory. Since it's a power CPU server that means I'll have to compile R from source. 
>
> I've searched the r_users list but most of the power CPU correspondence concerns either AIX or Macs. SLES 10 uses GCC 4.1.0 by default. Could someone please help me with some guidance on the necessary parameters for configure to ensure a 64 bit version of R is compiled? 
>  
>
>   
Just running the 64bit version of the OS usually suffices (at least on 
Linux variants). Easiest check on a running R is

 > .Machine$sizeof.pointer
[1] 4

which gives 8 on 64-bit builds.


From aferris at mrl.ubc.ca  Wed Mar 14 23:00:07 2007
From: aferris at mrl.ubc.ca (Andrew Ferris)
Date: Wed, 14 Mar 2007 15:00:07 -0700
Subject: [Rd] compile 2.4.1 for linux on power cpus
In-Reply-To: <45F85C4D.9080005@biostat.ku.dk>
References: <45F7CB380200007B0004C384@mail.mrl.ubc.ca>	<45F7D4C20200007B0004C3BF@mail.mrl.ubc.ca>
	<45F7D4C2.0211.007B.0@mrl.ubc.ca><45F7D4C2.0211.007B.0@mrl.ubc.ca>
	<45F85C4D.9080005@biostat.ku.dk>
Message-ID: <45F80DF7.0211.007B.0@mrl.ubc.ca>

Thank you for the reply Peter. 

I've compiled R from source using the following:

./configure --host=powerpc64-power5-linux-gnu --build=powerpc64-power5-linux-gnu '--with-blas=-framework blas-3.1.0-11'

and after I've made R I get this:

> .Machine$sizeof.pointer
[1] 4

meanwhile uname -a prints out this:

Linux [hostname] 2.6.16.21-0.8-ppc64 #1 SMP Mon Jul 3 18:25:39 UTC 2006 ppc64 ppc64 ppc64 GNU/Linux

and in the root filesystem there's a /lib and /lib64. I suspect that R needs to have the 64 bit libraries specified so is there a way to do that?

Andrew Ferris
Network Support Analyst
iCAPTURE Research Centre
University of British Columbia

>>> Peter Dalgaard <p.dalgaard at biostat.ku.dk> 03/14/07 1:34 PM >>>
Andrew Ferris wrote:
> Hello,
>
> I've been asked to get R (2.4.1) installed on a IBM p570 server. This is a server with power CPUs and is running SLES 10. It currently has 12GB of RAM so I'd like to make sure I have the 64 bit version of R so as to take advantage of the extra memory. Since it's a power CPU server that means I'll have to compile R from source. 
>
> I've searched the r_users list but most of the power CPU correspondence concerns either AIX or Macs. SLES 10 uses GCC 4.1.0 by default. Could someone please help me with some guidance on the necessary parameters for configure to ensure a 64 bit version of R is compiled? 
>  
>
>   
Just running the 64bit version of the OS usually suffices (at least on 
Linux variants). Easiest check on a running R is

 > .Machine$sizeof.pointer
[1] 4

which gives 8 on 64-bit builds.





***CONFIDENTIALITY NOTICE***
This electronic message is intended only for the use of the addressee and may contain information that is privileged and confidential.  Any dissemination, distribution or copying of this communication by unauthorized individuals is strictly prohibited. If you have received this communication in error, please notify the sender immediately by reply e-mail and delete the original and all copies from your system.


From p.dalgaard at biostat.ku.dk  Thu Mar 15 01:03:47 2007
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Thu, 15 Mar 2007 01:03:47 +0100
Subject: [Rd] compile 2.4.1 for linux on power cpus
In-Reply-To: <45F80DF7.0211.007B.0@mrl.ubc.ca>
References: <45F7CB380200007B0004C384@mail.mrl.ubc.ca>	<45F7D4C20200007B0004C3BF@mail.mrl.ubc.ca>
	<45F7D4C2.0211.007B.0@mrl.ubc.ca><45F7D4C2.0211.007B.0@mrl.ubc.ca>
	<45F85C4D.9080005@biostat.ku.dk> <45F80DF7.0211.007B.0@mrl.ubc.ca>
Message-ID: <45F88D63.2000704@biostat.ku.dk>

Andrew Ferris wrote:
> Thank you for the reply Peter. 
>
> I've compiled R from source using the following:
>
> ./configure --host=powerpc64-power5-linux-gnu --build=powerpc64-power5-linux-gnu '--with-blas=-framework blas-3.1.0-11'
>
> and after I've made R I get this:
>
>   
>> .Machine$sizeof.pointer
>>     
> [1] 4
>
> meanwhile uname -a prints out this:
>
> Linux [hostname] 2.6.16.21-0.8-ppc64 #1 SMP Mon Jul 3 18:25:39 UTC 2006 ppc64 ppc64 ppc64 GNU/Linux
>
>   
So I was wrong in assuming that 64 bit SLES would be set up for 64 bit 
compiles.....

> and in the root filesystem there's a /lib and /lib64. I suspect that R needs to have the 64 bit libraries specified so is there a way to do that?
First check the toolchain:

which gcc
gcc -dumpmachine

You might need to revise your path and/or install 64 bit versions of the 
compilers.

Actually, looking at the package list for SLES 10, I see that some 
packages have a -64bit variant, e.g.

glibc-64bit 2.4 
<http://www.novell.com/products/linuxpackages/server10/ppc/glibc-64bit.html> 
(Standard Shared Libraries (from the GNU C Library))
glibc-devel-64bit 2.4 
<http://www.novell.com/products/linuxpackages/server10/ppc/glibc-devel-64bit.html> 
(Include Files and Libraries Mandatory for Development)

but the gcc package does not, and the gcc-fortran-64bit 4.1.0 
<http://www.novell.com/products/linuxpackages/server10/ppc/gcc-fortran-64bit.html> 
packages contains only libraries. So my guess is that there is one 
compiler that does both 32 bit and 64 bit compiling, but you need to set 
a compiler flag for the latter.

I don't think messing with --build and --host is likely to do any good.


From aferris at mrl.ubc.ca  Thu Mar 15 02:08:37 2007
From: aferris at mrl.ubc.ca (Andrew Ferris)
Date: Wed, 14 Mar 2007 18:08:37 -0700
Subject: [Rd] compile 2.4.1 for linux on power cpus
In-Reply-To: <45F88D63.2000704@biostat.ku.dk>
References: <45F7CB380200007B0004C384@mail.mrl.ubc.ca>	<45F7D4C20200007B0004C3BF@mail.mrl.ubc.ca>
	<45F7D4C2.0211.007B.0@mrl.ubc.ca><45F7D4C2.0211.007B.0@mrl.ubc.ca>
	<45F85C4D.9080005@biostat.ku.dk>
	<45F80DF7.0211.007B.0@mrl.ubc.ca><45F80DF7.0211.007B.0@mrl.ubc.ca>
	<45F88D63.2000704@biostat.ku.dk>
Message-ID: <45F83A25.0211.007B.0@mrl.ubc.ca>

Peter,

First off, as you may have guessed, I don't compile many 64 bit programs so thanks again for the help. I'll revert back to powerpc64-unknown-linux-gnu which is the default for -build and -host.

Here's the gcc information
[hostname]:/ # which gcc
/usr/bin/gcc
[hostname]:/ # gcc -dumpmachine
powerpc64-suse-linux

>From looking at the GNU documentation for GCC  - IBM RS/6000 and PowerPC Options, I see that it mentions this option:

-m64
    
Generate code for 32-bit or 64-bit environments of Darwin and SVR4 targets (including GNU/Linux). The 32-bit environment sets int, long and pointer to 32 bits and generates code that runs on any PowerPC variant. The 64-bit environment sets int to 32 bits and long and pointer to 64 bits, and generates code for PowerPC64, as for -mpowerpc64. 

So would some compiler flags such as these work:

'CC=gcc -m64' 'CXX=g++ -m64' 'FC=gfortran -mc64' 'F77=gfortran -m64' 'LDFLAGS=-L/lib64'



Andrew Ferris
Network Support Analyst
iCAPTURE Research Centre
University of British Columbia

>>> Peter Dalgaard <p.dalgaard at biostat.ku.dk> 03/14/07 5:03 PM >>>
Andrew Ferris wrote:
> Thank you for the reply Peter. 
>
> I've compiled R from source using the following:
>
> ./configure --host=powerpc64-power5-linux-gnu --build=powerpc64-power5-linux-gnu '--with-blas=-framework blas-3.1.0-11'
>
> and after I've made R I get this:
>
>   
>> .Machine$sizeof.pointer
>>     
> [1] 4
>
> meanwhile uname -a prints out this:
>
> Linux [hostname] 2.6.16.21-0.8-ppc64 #1 SMP Mon Jul 3 18:25:39 UTC 2006 ppc64 ppc64 ppc64 GNU/Linux
>
>   
So I was wrong in assuming that 64 bit SLES would be set up for 64 bit 
compiles.....

> and in the root filesystem there's a /lib and /lib64. I suspect that R needs to have the 64 bit libraries specified so is there a way to do that?
First check the toolchain:

which gcc
gcc -dumpmachine

You might need to revise your path and/or install 64 bit versions of the 
compilers.

Actually, looking at the package list for SLES 10, I see that some 
packages have a -64bit variant, e.g.

glibc-64bit 2.4 
<http://www.novell.com/products/linuxpackages/server10/ppc/glibc-64bit.html> 
(Standard Shared Libraries (from the GNU C Library))
glibc-devel-64bit 2.4 
<http://www.novell.com/products/linuxpackages/server10/ppc/glibc-devel-64bit.html> 
(Include Files and Libraries Mandatory for Development)

but the gcc package does not, and the gcc-fortran-64bit 4.1.0 
<http://www.novell.com/products/linuxpackages/server10/ppc/gcc-fortran-64bit.html> 
packages contains only libraries. So my guess is that there is one 
compiler that does both 32 bit and 64 bit compiling, but you need to set 
a compiler flag for the latter.

I don't think messing with --build and --host is likely to do any good.



***CONFIDENTIALITY NOTICE***
This electronic message is intended only for the use of the addressee and may contain information that is privileged and confidential.  Any dissemination, distribution or copying of this communication by unauthorized individuals is strictly prohibited. If you have received this communication in error, please notify the sender immediately by reply e-mail and delete the original and all copies from your system.


From sfalcon at fhcrc.org  Thu Mar 15 06:15:57 2007
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Wed, 14 Mar 2007 22:15:57 -0700
Subject: [Rd] methods package PROTECT "bug"
Message-ID: <m2y7lzccj6.fsf@ziti.local>

Hi,

src/library/methods/src/methods_list_dispatch.c has the following code
which is part of the definition of R_dispatchGeneric:

          /*  get its class */
            SEXP arg; int check_err;
            PROTECT(arg = R_tryEval(arg_sym, ev, &check_err));
            if(check_err)
                error(_("error in evaluating the argument '%s' in selecting a me thod for function '%s'"),
                      CHAR(PRINTNAME(arg_sym)),CHAR(asChar(fname)));
            PROTECT(thisClass = R_data_class(arg, TRUE)); nprotect++;
            UNPROTECT(1); /* for arg */
        }
    SET_VECTOR_ELT(classes, i, thisClass);
    lwidth += strlen(STRING_VALUE(thisClass)) + 1;

Based on the comment and the fact that nprotect gets incremented, I
think the wrong object is being unprotected.  It doesn't really matter
since thisClass will get protection by being placed in the classes
vector.  But I think the code would be easier to read with a patch
like the following:

--- a/src/library/methods/src/methods_list_dispatch.c
+++ b/src/library/methods/src/methods_list_dispatch.c
@@ -837,8 +837,9 @@ SEXP R_dispatchGeneric(SEXP fname, SEXP ev, SEXP fdef)
            if(check_err)
                error(_("error in evaluating the argument '%s' in selecting a method for function '%s'"),
                      CHAR(PRINTNAME(arg_sym)),CHAR(asChar(fname)));
-           PROTECT(thisClass = R_data_class(arg, TRUE)); nprotect++;
+           thisClass = R_data_class(arg, TRUE);
            UNPROTECT(1); /* for arg */
+           PROTECT(thisClass); nprotect++;
        }
     SET_VECTOR_ELT(classes, i, thisClass);
     lwidth += strlen(STRING_VALUE(thisClass)) + 1;


-- 
Seth Falcon | Computational Biology | Fred Hutchinson Cancer Research Center
http://bioconductor.org


From p.dalgaard at biostat.ku.dk  Thu Mar 15 08:05:36 2007
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Thu, 15 Mar 2007 08:05:36 +0100
Subject: [Rd] compile 2.4.1 for linux on power cpus
In-Reply-To: <45F83A25.0211.007B.0@mrl.ubc.ca>
References: <45F7CB380200007B0004C384@mail.mrl.ubc.ca>	<45F7D4C20200007B0004C3BF@mail.mrl.ubc.ca>
	<45F7D4C2.0211.007B.0@mrl.ubc.ca><45F7D4C2.0211.007B.0@mrl.ubc.ca>
	<45F85C4D.9080005@biostat.ku.dk>
	<45F80DF7.0211.007B.0@mrl.ubc.ca><45F80DF7.0211.007B.0@mrl.ubc.ca>
	<45F88D63.2000704@biostat.ku.dk> <45F83A25.0211.007B.0@mrl.ubc.ca>
Message-ID: <45F8F040.6070907@biostat.ku.dk>

Andrew Ferris wrote:
> Peter,
>
> First off, as you may have guessed, I don't compile many 64 bit programs so thanks again for the help. I'll revert back to powerpc64-unknown-linux-gnu which is the default for -build and -host.
>
> Here's the gcc information
> [hostname]:/ # which gcc
> /usr/bin/gcc
> [hostname]:/ # gcc -dumpmachine
> powerpc64-suse-linux
>
> From looking at the GNU documentation for GCC  - IBM RS/6000 and PowerPC Options, I see that it mentions this option:
>
> -m64
>     
> Generate code for 32-bit or 64-bit environments of Darwin and SVR4 targets (including GNU/Linux). The 32-bit environment sets int, long and pointer to 32 bits and generates code that runs on any PowerPC variant. The 64-bit environment sets int to 32 bits and long and pointer to 64 bits, and generates code for PowerPC64, as for -mpowerpc64. 
>
> So would some compiler flags such as these work:
>
> 'CC=gcc -m64' 'CXX=g++ -m64' 'FC=gfortran -mc64' 'F77=gfortran -m64' 'LDFLAGS=-L/lib64'
>   
>

That's likely. Or use CFLAGS=-m64, and FFLAGS, CXXFLAGS similarly.

I'd try compiling a simple hello.c program first. Try e.g. "gcc -m64 
hello.c" and see what "file a.out" has to say about the result.

You may also find yourself having to install a number of packages  with 
names like foo-64bit_xx.yy to get 64bit C libraries, but configure 
should tell you about any missing bits in due course, once you have it 
convinced not to build for 32bit.


From ripley at stats.ox.ac.uk  Thu Mar 15 08:11:34 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 15 Mar 2007 07:11:34 +0000 (GMT)
Subject: [Rd] compile 2.4.1 for linux on power cpus
In-Reply-To: <45F8F040.6070907@biostat.ku.dk>
References: <45F7CB380200007B0004C384@mail.mrl.ubc.ca>
	<45F7D4C20200007B0004C3BF@mail.mrl.ubc.ca>
	<45F7D4C2.0211.007B.0@mrl.ubc.ca><45F7D4C2.0211.007B.0@mrl.ubc.ca>
	<45F85C4D.9080005@biostat.ku.dk>
	<45F80DF7.0211.007B.0@mrl.ubc.ca><45F80DF7.0211.007B.0@mrl.ubc.ca>
	<45F88D63.2000704@biostat.ku.dk> <45F83A25.0211.007B.0@mrl.ubc.ca>
	<45F8F040.6070907@biostat.ku.dk>
Message-ID: <Pine.LNX.4.64.0703150709370.30980@gannet.stats.ox.ac.uk>

On Thu, 15 Mar 2007, Peter Dalgaard wrote:

> Andrew Ferris wrote:
>> Peter,
>>
>> First off, as you may have guessed, I don't compile many 64 bit programs so thanks again for the help. I'll revert back to powerpc64-unknown-linux-gnu which is the default for -build and -host.
>>
>> Here's the gcc information
>> [hostname]:/ # which gcc
>> /usr/bin/gcc
>> [hostname]:/ # gcc -dumpmachine
>> powerpc64-suse-linux
>>
>> From looking at the GNU documentation for GCC  - IBM RS/6000 and PowerPC Options, I see that it mentions this option:
>>
>> -m64
>>
>> Generate code for 32-bit or 64-bit environments of Darwin and SVR4 targets (including GNU/Linux). The 32-bit environment sets int, long and pointer to 32 bits and generates code that runs on any PowerPC variant. The 64-bit environment sets int to 32 bits and long and pointer to 64 bits, and generates code for PowerPC64, as for -mpowerpc64.
>>
>> So would some compiler flags such as these work:
>>
>> 'CC=gcc -m64' 'CXX=g++ -m64' 'FC=gfortran -mc64' 'F77=gfortran -m64' 'LDFLAGS=-L/lib64'
>>
>>
>
> That's likely. Or use CFLAGS=-m64, and FFLAGS, CXXFLAGS similarly.

The CC etc forms are preferred, as not all configure scripts use the 
environment CFLAGS.

See the Solaris 64-bit notes in the R-admin manual for proven examples.

>
> I'd try compiling a simple hello.c program first. Try e.g. "gcc -m64
> hello.c" and see what "file a.out" has to say about the result.
>
> You may also find yourself having to install a number of packages  with
> names like foo-64bit_xx.yy to get 64bit C libraries, but configure
> should tell you about any missing bits in due course, once you have it
> convinced not to build for 32bit.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From hsiu-khuern.tang at hp.com  Wed Mar 14 18:58:31 2007
From: hsiu-khuern.tang at hp.com (hsiu-khuern.tang at hp.com)
Date: Wed, 14 Mar 2007 18:58:31 +0100 (CET)
Subject: [Rd] cannot delete the last column of a dataframe using "[<-"
	(PR#9565)
Message-ID: <20070314175831.EB38B5AAB1@slim.kubism.ku.dk>

Hi,

If df is a dataframe, its last column can't be deleted using "[<-", but
other columns can be deleted this way.

Example:

> (df <- df0 <- data.frame(x = 1:3, y = 4:6, z = 7:9))
  x y z
1 1 4 7
2 2 5 8
3 3 6 9
> df[, "z"] <- NULL
Error in x[[jj]] : subscript out of bounds
> df[, 3] <- NULL
Error in x[[jj]] : subscript out of bounds
> df["z"] <- NULL
Error in x[[jj]] : subscript out of bounds
> df[3] <- NULL
Error in x[[jj]] : subscript out of bounds

> df[, "y"] <- NULL
> df
  x z
1 1 7
2 2 8
3 3 9
> df <- df0; df[, 2] <- NULL
> df <- df0; df["y"] <- NULL
> df <- df0; df[2] <- NULL

Deleting using "$<-" and "[[<-" works for all columns.  Is it wrong to use
"[<-" for deleting?  help("[<-.data.frame") has an example, but it doesn't work
for deleting the last column either:

> sw <- swiss[1:5, 1:4]  # select a manageable subset

> ## adding a column
> sw["new1"] <- LETTERS[1:5]   # adds a character column
> sw[["new2"]] <- letters[1:5] # ditto
> sw[, "new3"] <- LETTERS[1:5] # ditto
> sw$new4 <- 1:5
> sw$new4 <- NULL              # delete the column
> (sw0 <- sw)
             Fertility Agriculture Examination Education new1 new2 new3
Courtelary        80.2        17.0          15        12    A    a    A
Delemont          83.1        45.1           6         9    B    b    B
Franches-Mnt      92.5        39.7           5         5    C    c    C
Moutier           85.8        36.5          12         7    D    d    D
Neuveville        76.9        43.5          17        15    E    e    E

> # This works:
> sw[6:8] <- list(letters[10:14], NULL, aa=1:5) # delete col7, update 6, append

> # But this doesn't:
> sw <- sw0
> sw[6:8] <- list(letters[10:14], aa=1:5, NULL)
Error in x[[jj]] : subscript out of bounds

Best,
Hsiu-Khuern.

----------
Version:
 platform = i486-pc-linux-gnu
 arch = i486
 os = linux-gnu
 system = i486, linux-gnu
 status = 
 major = 2
 minor = 4.1
 year = 2006
 month = 12
 day = 18
 svn rev = 40228
 language = R
 version.string = R version 2.4.1 (2006-12-18)

Locale:
C

Search Path:
 .GlobalEnv, package:datasets, package:stats, package:graphics, package:grDevices, package:utils, package:methods, Autoloads, package:base


From Matthew at CONCORDIAFUNDS.com  Wed Mar 14 18:44:04 2007
From: Matthew at CONCORDIAFUNDS.com (Matthew Dowle)
Date: Wed, 14 Mar 2007 17:44:04 -0000
Subject: [Rd] allocVector reference
Message-ID: <946928E281E8FD4B91D5B2CC3C91967DAA9912@lnex01.CONCORDIAFUNDS.COM>


Hi,

I'm trying to write a function to return an R vector which points
directly to a contiguous subset of another vector, without taking a
copy.  Since SEXPREC is a header followed by the data, rather than the
header plus a pointer to the data, I'm not sure what I'm trying to do is
possible.  Is there a way of doing this?  Similar in spirit to how the R
assignment "x=y" does not copy y until x is modified, but for a
contiguous subset of y e.g. "x=y[5:9]" would become "x=vecref(y,5,5)".

SEXP vecref(SEXP v, SEXP offset, SEXP len)
{
    // assuming v is an integer vector, offset>=0, len>=0 and
(offset+len)<length(v)
    SEXP ans;
    PROTECT(ans = allocVector(INTSXP, 0));
    DATAPTR(ans) = INTEGER(v) + INTEGER(offset)[0];		// this
line doesn't work since DATAPTR is really an offset by the header
    LENGTH(ans) = INTEGER(len)[0];
    UNPROTECT(1);
    return(ans);
}

Thanks in advance,
Matthew


From atp at piskorski.com  Thu Mar 15 13:01:49 2007
From: atp at piskorski.com (Andrew Piskorski)
Date: Thu, 15 Mar 2007 08:01:49 -0400
Subject: [Rd] allocVector reference
In-Reply-To: <946928E281E8FD4B91D5B2CC3C91967DAA9912@lnex01.CONCORDIAFUNDS.COM>
References: <946928E281E8FD4B91D5B2CC3C91967DAA9912@lnex01.CONCORDIAFUNDS.COM>
Message-ID: <20070315120149.GA68701@tehun.pair.com>

On Wed, Mar 14, 2007 at 05:44:04PM -0000, Matthew Dowle wrote:
> 
> Hi,
> 
> I'm trying to write a function to return an R vector which points
> directly to a contiguous subset of another vector, without taking a
> copy.

Matthew, I don't know the answer to your question, but this all seems
related to support for references in R.  I've included my notes on R
references below.

Ah, I think Jens Oehlschlaegel's "ref" package is what you want:

  http://tolstoy.newcastle.edu.au/R/packages/04/0008.html

  Class refdata is a transparent wrapper to matrices and data.frames
  which allows for memory efficient nested subsetting. I.e. you can
  create a subset of a subset ... of a data.frame without duplicating
  the data in memory, instead only indexing information is duplicated.

> Since SEXPREC is a header followed by the data, rather than the
> header plus a pointer to the data, I'm not sure what I'm trying to
> do is possible.  Is there a way of doing this?  Similar in spirit to
> how the R assignment "x=y" does not copy y until x is modified,

Is you last statement above in fact true?  I was under the impression
that R does NOT do copy on write, that when you make a copy of a
variable, R immediately allocates memory and makes a deep copy of the
value.

But you're using old deprecated "=" for assignment, which is weird, so
maybe you mean when you pass named arguments to a function?  Function
args are evaluated lazily, and I think that is used (I don't know how
exactly) to give copy on write behavior - but only for function
arguments.

My (older) notes on R references:

R does not support reference variables and does not do copy on write -
when you copy a variable, it eagerly allocates all memory and makes a
deep copy.  (I believe S-Plus has the same behavior but have not
checked.)  This can be annoying...

There are however specific exceptions.  For example, R environments
are treated as references, NOT values like most everything else in R.
The July 2006 "attributes of environments" thread makes that clear:

  https://stat.ethz.ch/pipermail/r-devel/2006-July/038352.html

Jens Oehlschlaegel's ref package implements references for both R and
S-Plus:

  http://cran.r-project.org/src/contrib/Descriptions/ref.html
  http://www.maths.lth.se/help/R/.R/library/ref/html/00Index.html
  http://tolstoy.newcastle.edu.au/~rking/R/packages/04/0008.html

Henrik Bengtsson's R.oo package emulates reference variables via R
environments (but perhaps only in the context of his OO framework, I'm
not sure).

  http://www.braju.com/R/
  http://cran.r-project.org/src/contrib/Descriptions/R.oo.html
  http://www.maths.lth.se/help/R/R.oo/

Bengtsson also wrote a 2002 paper, "Implementing support for
references in R":

  http://www.maths.lth.se/help/R/ImplementingReferences/

Further out, see also Tierny's (mostly old) R development notes

  Notes on References, External Objects, or Mutable State for R:
    http://www.stat.uiowa.edu/~luke/R/references.html
  Simple References with Finalization:
    http://www.stat.uiowa.edu/~luke/R/simpleref.html
  Finalization and Weak References in R:
    http://www.stat.uiowa.edu/~luke/R/references/weakfinex.html

-- 
Andrew Piskorski <atp at piskorski.com>
http://www.piskorski.com/


From ml-it-r-devel at epigenomics.com  Thu Mar 15 19:06:21 2007
From: ml-it-r-devel at epigenomics.com (ml-it-r-devel at epigenomics.com)
Date: Thu, 15 Mar 2007 19:06:21 +0100
Subject: [Rd] R 2.5.0 devel try issue in conjuntion with S4 method dispatch
Message-ID: <45F98B1D.2060501@epigenomics.com>



Hi,

after updating R 2.5.0 devel yesterday we today observed many new
unexpected failures in our daily package build and test system runs,
which can be traced to recent changes in the implementation in try()
(as noted in NEWS).

Investigating this new implementation I come across an issue in
conjuntion with using S4 classes and methods. try(expr) does not return an
object with attribute 'try-error' in case of method dispatch failure
in the wrapped expression which to me seems not
quite correct.

Examples to reproduce the observation:

##  using functions all is well:
f <- function(x) { print(x); ret<-try(stop("forced.")); print(ret)}

f(3)
[1] 3
Error in try(stop("forced.")) : forced.
[1] "Error in try(stop(\"forced.\")) : forced.\n"
attr(,"class")
[1] "try-error"


##  using S4 classes and methods
setClass("fooBase",
         representation("VIRTUAL",
                        width      = "numeric",
                        height     = "numeric"),
         prototype(width      = 1024,
                   height     = 1024),
         validity = NULL,
         where    = .GlobalEnv,
         sealed   = TRUE,
         )

if (!isGeneric("plotObject")) {

  setGeneric("plotObject",
             def=function(x, y, ...) {
               value <- standardGeneric("plotObject")
               return(value)
             },
             where=.GlobalEnv,
             useAsDefault=TRUE
             )
}

setClass("foo",
         representation("fooBase"),
         validity = NULL,
         where    = .GlobalEnv,
         sealed   = TRUE)


plotObject.foo <- function(x, y) {
  plot(x,y)
}

setMethod("plotObject", signature=c("foo", "numeric"), plotObject.foo,
where=.GlobalEnv)


fooObject <- new("foo")
##  should fail and return object with attribute 'try-error' set
ret <- try(plotObject(fooObject, character(1)))

Error in as.list(call)[[1]] == "doTryCatch" :
        comparison (1) is possible only for atomic and list types

>is(ret)
Error in .class1(object) : object "ret" not found

which I belive is in contradiction to the documentation, where in
Details:

     The value of the expression if 'expr' is evaluated without error,
     but an invisible object of class '"try-error"' containing the
     error message if it fails.

This is crucial for our current implementation of check functions in
package RUnit.

Is this new behaviour 'as intended' and only the documentation has not
caught up?


Regards,

  Matthias





>sessionInfo()
R version 2.5.0 Under development (unstable) (2007-03-13 r40832)
i686-pc-linux-gnu

locale:
C

attached base packages:
[1] "stats"     "graphics"  "grDevices" "datasets"  "utils"     "methods"
[7] "base"

other attached packages:
rcompletion    rcompgen
    "0.1-2"     "0.1-5"

-- 
Matthias Burger                     Project Manager/ Biostatistician
Epigenomics AG    Kleine Praesidentenstr. 1    10178 Berlin, Germany
phone:+49-30-24345-371                          fax:+49-30-24345-555
http://www.epigenomics.com           matthias.burger at epigenomics.com
--
Epigenomics AG Berlin           Amtsgericht Charlottenburg HRB 75861
Vorstand:   Geert Nygaard (CEO/Vorsitzender),  Dr. Kurt Berlin (CSO)
              Oliver Schacht PhD (CFO),  Christian Piepenbrock (COO)
Aufsichtsrat:   Prof. Dr. Dr. hc. Rolf Krebs (Chairman/Vorsitzender)


From simon.urbanek at r-project.org  Thu Mar 15 20:14:14 2007
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Thu, 15 Mar 2007 15:14:14 -0400
Subject: [Rd] allocVector reference
In-Reply-To: <20070315120149.GA68701@tehun.pair.com>
References: <946928E281E8FD4B91D5B2CC3C91967DAA9912@lnex01.CONCORDIAFUNDS.COM>
	<20070315120149.GA68701@tehun.pair.com>
Message-ID: <1C4063EA-8EF9-4373-ABE2-38337150A8CD@r-project.org>

Andrew,

On Mar 15, 2007, at 8:01 AM, Andrew Piskorski wrote:

> On Wed, Mar 14, 2007 at 05:44:04PM -0000, Matthew Dowle wrote:
>>
>> Hi,
>>
>> I'm trying to write a function to return an R vector which points  
>> directly to a contiguous subset of another vector, without taking  
>> a copy.
>
> Matthew, I don't know the answer to your question, but this all  
> seems related to support for references in R.  I've included my  
> notes on R references below.
> [...]
>> Since SEXPREC is a header followed by the data, rather than the  
>> header plus a pointer to the data, I'm not sure what I'm trying to  
>> do is possible.  Is there a way of doing this?  Similar in spirit  
>> to how the R assignment "x=y" does not copy y until x is modified,
>
> Is you last statement above in fact true?


Yes. Just try
a=1:100000000
gc()
b=a
gc()
b[0]=0:0
gc()


>   I was under the impression that R does NOT do copy on write, that  
> when you make a copy of a variable, R immediately allocates memory  
> and makes a deep copy of the value.
>

Nope.


> But you're using old deprecated "=" for assignment,

"old deprecated"? It was introduced in 1.4.0 and it is the most  
recently introduced assignment operator in R. I think that you are  
mistaking it for "_" which is no assignment operator anymore but used  
to be.


> which is weird, so maybe you mean when you pass named arguments to  
> a function?  Function args are evaluated lazily, and I think that  
> is used (I don't know how exactly) to give copy on write behavior -  
> but only for function arguments.


Cheers,
Simon


From aferris at mrl.ubc.ca  Thu Mar 15 21:51:05 2007
From: aferris at mrl.ubc.ca (Andrew Ferris)
Date: Thu, 15 Mar 2007 13:51:05 -0700
Subject: [Rd] compile 2.4.1 for linux on power cpus
In-Reply-To: <Pine.LNX.4.64.0703150709370.30980@gannet.stats.ox.ac.uk>
References: <45F7CB380200007B0004C384@mail.mrl.ubc.ca>
	<45F7D4C20200007B0004C3BF@mail.mrl.ubc.ca>
	<45F7D4C2.0211.007B.0@mrl.ubc.ca><45F7D4C2.0211.007B.0@mrl.ubc.ca>
	<45F85C4D.9080005@biostat.ku.dk>
	<45F80DF7.0211.007B.0@mrl.ubc.ca><45F80DF7.0211.007B.0@mrl.ubc.ca>
	<45F88D63.2000704@biostat.ku.dk> <45F83A25.0211.007B.0@mrl.ubc.ca>
	<45F8F040.6070907@biostat.ku.dk>
	<Pine.LNX.4.64.0703150709370.30980@gannet.stats.ox.ac.uk>
Message-ID: <45F94F49.0211.007B.0@mrl.ubc.ca>

I'm closer but still not quite there. Here's the configure command I'm using:

 ./configure 'CC=gcc -m64' 'CXX=g++ -m64 -mminimal-toc' 'FC=gfortran -mc64 -fno-optimize-sibling-calls' 'F77=gfortran -m64 -fno-optimize-sibling-calls' 'LDFLAGS=-L/usr/lib64' R_PAPERSIZE='letter'

I'm using the -mminimal-toc and -fno-optimize-sibling-calls flags because of this error during make:

/usr/bin/ld: ../nmath/libnmath.a(gamma.o)(.text+0xf4): sibling call optimization to `Rf_chebyshev_eval' does not allow automatic multiple TOCs; recompile with -mminimal-toc or -fno-optimize-sibling-calls, or make `Rf_chebyshev_eval' extern
/usr/bin/ld: ../nmath/libnmath.a(gamma.o)(.text+0x270): sibling call optimization to `Rf_stirlerr' does not allow automatic multiple TOCs; recompile with -mminimal-toc or -fno-optimize-sibling-calls, or make `Rf_stirlerr' extern
/usr/bin/ld: ../nmath/libnmath.a(gamma.o)(.text+0x34c): sibling call optimization to `Rf_lgammacor' does not allow automatic multiple TOCs; recompile with -mminimal-toc or -fno-optimize-sibling-calls, or make `Rf_lgammacor' extern
/usr/bin/ld: final link failed: Bad value
collect2: ld returned 1 exit status
make[3]: *** [R.bin] Error 1
make[3]: Leaving directory `/usr/local/R-2.4.1/src/main'
make[2]: *** [R] Error 2
make[2]: Leaving directory `/usr/local/R-2.4.1/src/main'
make[1]: *** [R] Error 1
make[1]: Leaving directory `/usr/local/R-2.4.1/src'
make: *** [R] Error 1

But those flags aren't helping as those errors persist. Is there anything else I can do?

thanks,


Andrew Ferris
Network Support Analyst
iCAPTURE Research Centre
University of British Columbia

>>> Prof Brian Ripley <ripley at stats.ox.ac.uk> 03/15/07 12:11 AM >>>
On Thu, 15 Mar 2007, Peter Dalgaard wrote:

> Andrew Ferris wrote:
>> Peter,
>>
>> First off, as you may have guessed, I don't compile many 64 bit programs so thanks again for the help. I'll revert back to powerpc64-unknown-linux-gnu which is the default for -build and -host.
>>
>> Here's the gcc information
>> [hostname]:/ # which gcc
>> /usr/bin/gcc
>> [hostname]:/ # gcc -dumpmachine
>> powerpc64-suse-linux
>>
>> From looking at the GNU documentation for GCC  - IBM RS/6000 and PowerPC Options, I see that it mentions this option:
>>
>> -m64
>>
>> Generate code for 32-bit or 64-bit environments of Darwin and SVR4 targets (including GNU/Linux). The 32-bit environment sets int, long and pointer to 32 bits and generates code that runs on any PowerPC variant. The 64-bit environment sets int to 32 bits and long and pointer to 64 bits, and generates code for PowerPC64, as for -mpowerpc64.
>>
>> So would some compiler flags such as these work:
>>
>> 'CC=gcc -m64' 'CXX=g++ -m64' 'FC=gfortran -mc64' 'F77=gfortran -m64' 'LDFLAGS=-L/lib64'
>>
>>
>
> That's likely. Or use CFLAGS=-m64, and FFLAGS, CXXFLAGS similarly.

The CC etc forms are preferred, as not all configure scripts use the 
environment CFLAGS.

See the Solaris 64-bit notes in the R-admin manual for proven examples.

>
> I'd try compiling a simple hello.c program first. Try e.g. "gcc -m64
> hello.c" and see what "file a.out" has to say about the result.
>
> You may also find yourself having to install a number of packages  with
> names like foo-64bit_xx.yy to get 64bit C libraries, but configure
> should tell you about any missing bits in due course, once you have it
> convinced not to build for 32bit.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel 
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk 
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/ 
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



***CONFIDENTIALITY NOTICE***
This electronic message is intended only for the use of the addressee and may contain information that is privileged and confidential.  Any dissemination, distribution or copying of this communication by unauthorized individuals is strictly prohibited. If you have received this communication in error, please notify the sender immediately by reply e-mail and delete the original and all copies from your system.


From krc at mdacc.tmc.edu  Thu Mar 15 18:58:45 2007
From: krc at mdacc.tmc.edu (krc at mdacc.tmc.edu)
Date: Thu, 15 Mar 2007 18:58:45 +0100 (CET)
Subject: [Rd] Sweave bug using 'FDR' in chunk label (PR#9567)
Message-ID: <20070315175845.6E07A5A6A0@slim.kubism.ku.dk>

Full_Name: Kevin Coombes
Version: 2.4.0
OS: Windows XP
Submission from: (NULL) (143.111.22.24)


I'm running R 2.4.0 on a Windows XP machine, with only the default packages
loaded.

Running Sweave or Stangle on the following Rnw file:
--------------
% bug.Rnw
\begin{document}
Demonstrate an Sweave/Stangle bug.
<<info>>=
sessionInfo()
@ 

<<getFDR>>=
x <- 1
@ 
<<getFDX>>=
y <- 2
@ 
<<problem>>=
<<getFDX>>
<<getFDR>>
@ 

\end{document}
---------------

produces an error message:

> Stangle("bug.Rnw")
Writing to file bug.R 
Warning message:
reference to unknown chunk 'getFDR' in: Sweave(file = file, driver = driver,
...) 


Here is the relevant part of the "bug.R" file produced by Stangle.  Note that
the label has been truncated on chunk2 (should be getFDR) but is not affected on
chunk3. Also note that chunk4 has not been expanded properly.

###################################################
### chunk number 2: getF
###################################################
x <- 1

###################################################
### chunk number 3: getFDX
###################################################
y <- 2

###################################################
### chunk number 4: problem
###################################################
y <- 2


From cstrato at aon.at  Thu Mar 15 22:58:41 2007
From: cstrato at aon.at (cstrato)
Date: Thu, 15 Mar 2007 22:58:41 +0100
Subject: [Rd] Inherited S4 methods
Message-ID: <45F9C191.5020803@aon.at>

Dear all,

Recently, there was a question to use the same method for more than one 
class:
https://stat.ethz.ch/pipermail/r-devel/2007-March/044809.html

I have a variation of this question:
Is it possible to use the same function name, e.g. "myfunction" in both, 
an S4
baseClass and derivedClass. The method "myfunction" in derivedCalss should
extend the functionality defined in baseClass, analogously to C++ methods.
If this is possible, does there exist an example?

Best regards
Christian
_._._._._._._._._._._._._._._._
C.h.i.s.t.i.a.n S.t.r.a.t.o.w.a
V.i.e.n.n.a       A.u.s.t.r.i.a
_._._._._._._._._._._._._._._._


From sfalcon at fhcrc.org  Thu Mar 15 23:05:32 2007
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Thu, 15 Mar 2007 15:05:32 -0700
Subject: [Rd] R 2.5.0 devel try issue in conjuntion with S4 method
	dispatch
In-Reply-To: <45F98B1D.2060501@epigenomics.com>
	(ml-it-r-devel@epigenomics.com's message of "Thu,
	15 Mar 2007 19:06:21 +0100")
References: <45F98B1D.2060501@epigenomics.com>
Message-ID: <m2ejnq88nn.fsf@ziti.local>

ml-it-r-devel at epigenomics.com writes:
> Investigating this new implementation I come across an issue in
> conjuntion with using S4 classes and methods. try(expr) does not return an
> object with attribute 'try-error' in case of method dispatch failure
> in the wrapped expression which to me seems not
> quite correct.

We've seen some similar issues but had not had time to track them
down.

> Examples to reproduce the observation:

It isn't S4 specific.  The issue seems more about anonymous
calls/functions.

   ll = list()
   ll[[1]] = function(x) stop("died")
   
   v = try(do.call(ll[[1]], list(1)), silent=TRUE)
   Error in as.list(call)[[1]] == "doTryCatch" : 
   	comparison (1) is possible only for atomic and list types
   > v
   Error: object "v" not found

I don't fully understand why the call is being computed, but the
following seems to get things going.

+ seth

--- a/src/library/base/R/New-Internal.R
+++ b/src/library/base/R/New-Internal.R
@@ -7,7 +7,8 @@ try <- function(expr, silent = FALSE) {
             ## Patch up the call to produce nicer result for testing as
             ## try(stop(...)).  This will need adjusting if the
             ## implementation of tryCatch changes.
-            if (as.list(call)[[1]] == "doTryCatch")
+            callFun <- as.list(call)[[1]]
+            if (is.name(callFun) && callFun == "doTryCatch")
                 call <- sys.call(-4)
             dcall <- deparse(call)[1]
             prefix <- paste("Error in", dcall, ": ")



-- 
Seth Falcon | Computational Biology | Fred Hutchinson Cancer Research Center
http://bioconductor.org


From murdoch at stats.uwo.ca  Fri Mar 16 01:32:01 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 15 Mar 2007 20:32:01 -0400
Subject: [Rd] Sweave bug using 'FDR' in chunk label (PR#9567)
In-Reply-To: <20070315175845.6E07A5A6A0@slim.kubism.ku.dk>
References: <20070315175845.6E07A5A6A0@slim.kubism.ku.dk>
Message-ID: <45F9E581.9090704@stats.uwo.ca>

On 3/15/2007 1:58 PM, krc at mdacc.tmc.edu wrote:
> Full_Name: Kevin Coombes
> Version: 2.4.0
> OS: Windows XP
> Submission from: (NULL) (143.111.22.24)
> 
> 
> I'm running R 2.4.0 on a Windows XP machine, with only the default packages
> loaded.
> 
> Running Sweave or Stangle on the following Rnw file:
> --------------
> % bug.Rnw
> \begin{document}
> Demonstrate an Sweave/Stangle bug.
> <<info>>=
> sessionInfo()
> @ 
> 
> <<getFDR>>=
> x <- 1
> @ 
> <<getFDX>>=
> y <- 2
> @ 
> <<problem>>=
> <<getFDX>>
> <<getFDR>>
> @ 
> 
> \end{document}

I can confirm this bug in R 2.4.1 and R-devel.  It's because of an error 
in a regular expression in  SweaveParseOptions; it is supposed to strip 
off a trailing ".R", but it doesn't escape the dot, and so it matches 
the DR in getFDR.

I'll fix it in R-devel and R-patched after testing...

Duncan Murdoch


> ---------------
> 
> produces an error message:
> 
>> Stangle("bug.Rnw")
> Writing to file bug.R 
> Warning message:
> reference to unknown chunk 'getFDR' in: Sweave(file = file, driver = driver,
> ...) 
> 
> 
> Here is the relevant part of the "bug.R" file produced by Stangle.  Note that
> the label has been truncated on chunk2 (should be getFDR) but is not affected on
> chunk3. Also note that chunk4 has not been expanded properly.
> 
> ###################################################
> ### chunk number 2: getF
> ###################################################
> x <- 1
> 
> ###################################################
> ### chunk number 3: getFDX
> ###################################################
> y <- 2
> 
> ###################################################
> ### chunk number 4: problem
> ###################################################
> y <- 2
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From nakama at ki.rim.or.jp  Fri Mar 16 03:01:40 2007
From: nakama at ki.rim.or.jp (Ei-ji Nakama)
Date: Fri, 16 Mar 2007 11:01:40 +0900
Subject: [Rd] compile 2.4.1 for linux on power cpus
In-Reply-To: <45F94F49.0211.007B.0@mrl.ubc.ca>
References: <45F7CB380200007B0004C384@mail.mrl.ubc.ca>
	<45F7D4C20200007B0004C3BF@mail.mrl.ubc.ca>
	<45F7D4C2.0211.007B.0@mrl.ubc.ca> <45F85C4D.9080005@biostat.ku.dk>
	<45F80DF7.0211.007B.0@mrl.ubc.ca> <45F88D63.2000704@biostat.ku.dk>
	<45F83A25.0211.007B.0@mrl.ubc.ca> <45F8F040.6070907@biostat.ku.dk>
	<Pine.LNX.4.64.0703150709370.30980@gannet.stats.ox.ac.uk>
	<45F94F49.0211.007B.0@mrl.ubc.ca>
Message-ID: <dc41e1260703151901x46c366b1ha74f73e547500741@mail.gmail.com>

2007/3/16, Andrew Ferris <aferris at mrl.ubc.ca>:
> I'm closer but still not quite there. Here's the configure command I'm using:
>
>  ./configure 'CC=gcc -m64' 'CXX=g++ -m64 -mminimal-toc' 'FC=gfortran -mc64 -fno-optimize-sibling-calls' 'F77=gfortran -m64 -fno-optimize-sibling-calls' 'LDFLAGS=-L/usr/lib64' R_PAPERSIZE='letter'

$ uname -a
Linux macg5 2.6.18-3-powerpc64 #1 SMP Mon Dec 4 15:40:16 CET 2006
ppc64 GNU/Linux

$ gcc -v
Using built-in specs.
Target: powerpc-linux-gnu
Configured with: ../src/configure -v
--enable-languages=c,c++,fortran,objc,obj-c++,treelang --prefix=/usr
--enable-shared --with-system-zlib --libexecdir=/usr/lib
--without-included-gettext --enable-threads=posix --enable-nls
--program-suffix=-4.1 --enable-__cxa_atexit --enable-clocale=gnu
--enable-libstdcxx-debug --enable-mpfr --disable-softfloat
--enable-targets=powerpc-linux,powerpc64-linux --with-cpu=default32
--enable-checking=release powerpc-linux-gnu
Thread model: posix
gcc version 4.1.2 20061115 (prerelease) (Debian 4.1.1-21)

$ gcc -print-multi-lib
.;@fPIC at mstrict-align
64;@m64 at fPIC@mstrict-align

$ ./configure CC="gcc -m64" \
                   CXX="gxx -m64" \
                   F77="gfortran -m64" \
                   FC="gfortran -m64" \
                   CFLAGS="-mminimal-toc -fno-optimize-sibling-calls -g -O2" \
                   FFLAGS="-mminimal-toc -fno-optimize-sibling-calls -g -O2" \
                   --without-x

$ file bin/exec/R
bin/exec/R: ELF 64-bit MSB executable, PowerPC 64-bit or cisco 7500,
version 1 (SYSV), for GNU/Linux 2.6.0, dynamically linked (uses shared
libs), for GNU/Linux 2.6.0, not stripped

-- 
EI-JI Nakama  <nakama at ki.rim.or.jp>
"\u4e2d\u9593\u6804\u6cbb"  <nakama at ki.rim.or.jp>


From p.dalgaard at biostat.ku.dk  Fri Mar 16 08:09:00 2007
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Fri, 16 Mar 2007 08:09:00 +0100
Subject: [Rd] R 2.5.0 devel try issue in conjuntion with S4
	method	dispatch
In-Reply-To: <m2ejnq88nn.fsf@ziti.local>
References: <45F98B1D.2060501@epigenomics.com> <m2ejnq88nn.fsf@ziti.local>
Message-ID: <45FA428C.9030402@biostat.ku.dk>

Seth Falcon wrote:
> ml-it-r-devel at epigenomics.com writes:
>   
>> Investigating this new implementation I come across an issue in
>> conjuntion with using S4 classes and methods. try(expr) does not return an
>> object with attribute 'try-error' in case of method dispatch failure
>> in the wrapped expression which to me seems not
>> quite correct.
>>     
>
> We've seen some similar issues but had not had time to track them
> down.
>
>   
>> Examples to reproduce the observation:
>>     
>
> It isn't S4 specific.  The issue seems more about anonymous
> calls/functions.
>
>    ll = list()
>    ll[[1]] = function(x) stop("died")
>    
>    v = try(do.call(ll[[1]], list(1)), silent=TRUE)
>    Error in as.list(call)[[1]] == "doTryCatch" : 
>    	comparison (1) is possible only for atomic and list types
>    > v
>    Error: object "v" not found
>
> I don't fully understand why the call is being computed, but the
> following seems to get things going.
>
> + seth
>
> --- a/src/library/base/R/New-Internal.R
> +++ b/src/library/base/R/New-Internal.R
> @@ -7,7 +7,8 @@ try <- function(expr, silent = FALSE) {
>              ## Patch up the call to produce nicer result for testing as
>              ## try(stop(...)).  This will need adjusting if the
>              ## implementation of tryCatch changes.
> -            if (as.list(call)[[1]] == "doTryCatch")
> +            callFun <- as.list(call)[[1]]
> +            if (is.name(callFun) && callFun == "doTryCatch")
>                  call <- sys.call(-4)
>              dcall <- deparse(call)[1]
>              prefix <- paste("Error in", dcall, ": ")
>
>   
Good catch, Seth. The code still looks a bit clunky though, and I wonder 
if this wouldn't be nicer:

if (identical(call[[1]], quote(doTryCatch))) call <- sys.call(-4)

I.e., the thing that is clearly wrong is the use of "==" on something 
that is not necessarily a simple name, but the use of as.list seems 
unnecessary and comparisons between strings and names is a bit awkward too.


From maechler at stat.math.ethz.ch  Fri Mar 16 09:32:12 2007
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 16 Mar 2007 09:32:12 +0100
Subject: [Rd] R 2.5.0 devel try issue in conjuntion with S4 method
	dispatch
In-Reply-To: <45FA428C.9030402@biostat.ku.dk>
References: <45F98B1D.2060501@epigenomics.com> <m2ejnq88nn.fsf@ziti.local>
	<45FA428C.9030402@biostat.ku.dk>
Message-ID: <17914.22028.162669.917442@stat.math.ethz.ch>


>>>>> "PD" == Peter Dalgaard <p.dalgaard at biostat.ku.dk>
>>>>>     on Fri, 16 Mar 2007 08:09:00 +0100 writes:

    PD> Seth Falcon wrote:
    >> ml-it-r-devel at epigenomics.com writes:
    >> 
    >>> Investigating this new implementation I come across an issue in
    >>> conjuntion with using S4 classes and methods. try(expr) does not return an
    >>> object with attribute 'try-error' in case of method dispatch failure
    >>> in the wrapped expression which to me seems not
    >>> quite correct.
    >>> 
    >> 
    >> We've seen some similar issues but had not had time to track them
    >> down.
    >> 
    >> 
    >>> Examples to reproduce the observation:
    >>> 
    >> 
    >> It isn't S4 specific.  The issue seems more about anonymous
    >> calls/functions.
    >> 
    >> ll = list()
    >> ll[[1]] = function(x) stop("died")
    >> 
    >> v = try(do.call(ll[[1]], list(1)), silent=TRUE)
    >> Error in as.list(call)[[1]] == "doTryCatch" : 
    >> comparison (1) is possible only for atomic and list types
    >> > v
    >> Error: object "v" not found
    >> 
    >> I don't fully understand why the call is being computed, but the
    >> following seems to get things going.
    >> 
    >> + seth
    >> 
    >> --- a/src/library/base/R/New-Internal.R
    >> +++ b/src/library/base/R/New-Internal.R
    >> @@ -7,7 +7,8 @@ try <- function(expr, silent = FALSE) {
    >> ## Patch up the call to produce nicer result for testing as
    >> ## try(stop(...)).  This will need adjusting if the
    >> ## implementation of tryCatch changes.
    >> -            if (as.list(call)[[1]] == "doTryCatch")
    >> +            callFun <- as.list(call)[[1]]
    >> +            if (is.name(callFun) && callFun == "doTryCatch")
    >> call <- sys.call(-4)
    >> dcall <- deparse(call)[1]
    >> prefix <- paste("Error in", dcall, ": ")
    >> 
    >> 
    PD> Good catch, Seth. 

yes, indeed!

    PD> The code still looks a bit clunky though, and I wonder 
    PD> if this wouldn't be nicer:

    PD> if (identical(call[[1]], quote(doTryCatch))) call <- sys.call(-4)

    PD> I.e., the thing that is clearly wrong is the use of "==" on something 
    PD> that is not necessarily a simple name, but the use of as.list seems 
    PD> unnecessary and comparisons between strings and names is a bit awkward too.

Indeed, I had similar thoughts when reading the part of code
Seth was patching 
{ but would have used the old-fashioned   as.name("doTryCatch")
  instead of the modern  quote(doTryCatch)
  for the only reason that I'm probably slightly ``older fashioned''
  than Peter  ;-)  
}

Martin


From nilsson.henric at gmail.com  Fri Mar 16 12:36:11 2007
From: nilsson.henric at gmail.com (Henric Nilsson (Public))
Date: Fri, 16 Mar 2007 12:36:11 +0100
Subject: [Rd] Unhidden predict methods
Message-ID: <45FA812B.1060104@gmail.com>

Hi,

I've noted that not all `predict' methods are hidden in the namespace:

 > methods("predict")
  [1] predict.ar*                predict.Arima*
  [3] predict.arima0*            predict.glm
  [5] predict.HoltWinters*       predict.lm
  [7] predict.loess*             predict.mlm
  [9] predict.nls*               predict.poly
[11] predict.ppr*               predict.prcomp*
[13] predict.princomp*          predict.smooth.spline*
[15] predict.smooth.spline.fit* predict.StructTS*

    Non-visible functions are asterisked

I'm sure there's a good reason for this, but I haven't been able to 
figure it out. Please enlighten me.

Thanks!


Henric


From hb at stat.berkeley.edu  Fri Mar 16 12:48:06 2007
From: hb at stat.berkeley.edu (Henrik Bengtsson)
Date: Fri, 16 Mar 2007 12:48:06 +0100
Subject: [Rd] Unhidden predict methods
In-Reply-To: <45FA812B.1060104@gmail.com>
References: <45FA812B.1060104@gmail.com>
Message-ID: <59d7961d0703160448n7099497bra3971355f693f0b0@mail.gmail.com>

One reason is that you should never call those methods directly but
only via the generic function predict(), and this is a way to prevent
such misuse/mishaps.  You can always use getAnywhere() if you want
look at the code.

/H

On 3/16/07, Henric Nilsson (Public) <nilsson.henric at gmail.com> wrote:
> Hi,
>
> I've noted that not all `predict' methods are hidden in the namespace:
>
>  > methods("predict")
>   [1] predict.ar*                predict.Arima*
>   [3] predict.arima0*            predict.glm
>   [5] predict.HoltWinters*       predict.lm
>   [7] predict.loess*             predict.mlm
>   [9] predict.nls*               predict.poly
> [11] predict.ppr*               predict.prcomp*
> [13] predict.princomp*          predict.smooth.spline*
> [15] predict.smooth.spline.fit* predict.StructTS*
>
>     Non-visible functions are asterisked
>
> I'm sure there's a good reason for this, but I haven't been able to
> figure it out. Please enlighten me.
>
> Thanks!
>
>
> Henric
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From ripley at stats.ox.ac.uk  Fri Mar 16 13:25:50 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 16 Mar 2007 12:25:50 +0000 (GMT)
Subject: [Rd] Unhidden predict methods
In-Reply-To: <45FA812B.1060104@gmail.com>
References: <45FA812B.1060104@gmail.com>
Message-ID: <Pine.LNX.4.64.0703161222340.8349@gannet.stats.ox.ac.uk>

The reason some are not hidden is historical: they were called explicitly 
by (contributed) package code at the time namespaces were introduced.

It would be a good idea to revisit some of those decisions, but it is not 
a very appealing way to spend one's time.

On Fri, 16 Mar 2007, Henric Nilsson (Public) wrote:

> Hi,
>
> I've noted that not all `predict' methods are hidden in the namespace:
>
> > methods("predict")
>  [1] predict.ar*                predict.Arima*
>  [3] predict.arima0*            predict.glm
>  [5] predict.HoltWinters*       predict.lm
>  [7] predict.loess*             predict.mlm
>  [9] predict.nls*               predict.poly
> [11] predict.ppr*               predict.prcomp*
> [13] predict.princomp*          predict.smooth.spline*
> [15] predict.smooth.spline.fit* predict.StructTS*
>
>    Non-visible functions are asterisked
>
> I'm sure there's a good reason for this, but I haven't been able to
> figure it out. Please enlighten me.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Fri Mar 16 13:34:44 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 16 Mar 2007 12:34:44 +0000 (GMT)
Subject: [Rd] allocVector reference
In-Reply-To: <20070315120149.GA68701@tehun.pair.com>
References: <946928E281E8FD4B91D5B2CC3C91967DAA9912@lnex01.CONCORDIAFUNDS.COM>
	<20070315120149.GA68701@tehun.pair.com>
Message-ID: <Pine.LNX.4.64.0703151306581.22636@gannet.stats.ox.ac.uk>

I believe your assertions are incorrect about both '=' and when copying is 
done.

'=' is neither old nor deprecated and is syntactically different from 
'<-', but where it means assignment, it invokes the same internal code as 
'<-'.

R maintains a call-by-value illusion, but it does not actually copy on 
assignment: Like evaluation, copying on assignment is lazy.  Matthew's 
comment is not the whole story, as x <- y copies if _either_ x or y is 
changed by e.g. subassignment.

Nowadays there is an 'R Internals' manual which explains a great deal of 
how things actually work.  In particular the SEXTYPEs ENVSXP, EXTPTRSXP 
and WEAKREFSXP have different assignment semantics to the others, and it 
explains how the NAMED macros work.

I do not believe you can do in R what Matthew asked: the various reference 
approaches do not return objects that the internal code will handle as if 
they were atomic vectors.  And one has always to remember that the two 
class systems are very largely implemented at interpreted level: internal 
code will often ignore classes (although not as often as it once did).

On Thu, 15 Mar 2007, Andrew Piskorski wrote:

> On Wed, Mar 14, 2007 at 05:44:04PM -0000, Matthew Dowle wrote:
>>
>> Hi,
>>
>> I'm trying to write a function to return an R vector which points
>> directly to a contiguous subset of another vector, without taking a
>> copy.
>
> Matthew, I don't know the answer to your question, but this all seems
> related to support for references in R.  I've included my notes on R
> references below.
>
> Ah, I think Jens Oehlschlaegel's "ref" package is what you want:
>
>  http://tolstoy.newcastle.edu.au/R/packages/04/0008.html
>
>  Class refdata is a transparent wrapper to matrices and data.frames
>  which allows for memory efficient nested subsetting. I.e. you can
>  create a subset of a subset ... of a data.frame without duplicating
>  the data in memory, instead only indexing information is duplicated.
>
>> Since SEXPREC is a header followed by the data, rather than the

Actually, that is a VECTOR_SEXPREC, used for the vector types.

>> header plus a pointer to the data, I'm not sure what I'm trying to
>> do is possible.  Is there a way of doing this?  Similar in spirit to
>> how the R assignment "x=y" does not copy y until x is modified,
>
> Is you last statement above in fact true?  I was under the impression
> that R does NOT do copy on write, that when you make a copy of a
> variable, R immediately allocates memory and makes a deep copy of the
> value.
>
> But you're using old deprecated "=" for assignment, which is weird, so
> maybe you mean when you pass named arguments to a function?  Function
> args are evaluated lazily, and I think that is used (I don't know how
> exactly) to give copy on write behavior - but only for function
> arguments.
>
> My (older) notes on R references:
>
> R does not support reference variables and does not do copy on write -
> when you copy a variable, it eagerly allocates all memory and makes a
> deep copy.  (I believe S-Plus has the same behavior but have not
> checked.)  This can be annoying...
>
> There are however specific exceptions.  For example, R environments
> are treated as references, NOT values like most everything else in R.
> The July 2006 "attributes of environments" thread makes that clear:
>
>  https://stat.ethz.ch/pipermail/r-devel/2006-July/038352.html
>
> Jens Oehlschlaegel's ref package implements references for both R and
> S-Plus:
>
>  http://cran.r-project.org/src/contrib/Descriptions/ref.html
>  http://www.maths.lth.se/help/R/.R/library/ref/html/00Index.html
>  http://tolstoy.newcastle.edu.au/~rking/R/packages/04/0008.html
>
> Henrik Bengtsson's R.oo package emulates reference variables via R
> environments (but perhaps only in the context of his OO framework, I'm
> not sure).
>
>  http://www.braju.com/R/
>  http://cran.r-project.org/src/contrib/Descriptions/R.oo.html
>  http://www.maths.lth.se/help/R/R.oo/
>
> Bengtsson also wrote a 2002 paper, "Implementing support for
> references in R":
>
>  http://www.maths.lth.se/help/R/ImplementingReferences/
>
> Further out, see also Tierny's (mostly old) R development notes
>
>  Notes on References, External Objects, or Mutable State for R:
>    http://www.stat.uiowa.edu/~luke/R/references.html
>  Simple References with Finalization:
>    http://www.stat.uiowa.edu/~luke/R/simpleref.html
>  Finalization and Weak References in R:
>    http://www.stat.uiowa.edu/~luke/R/references/weakfinex.html
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From nilsson.henric at gmail.com  Fri Mar 16 13:42:35 2007
From: nilsson.henric at gmail.com (Henric Nilsson (Public))
Date: Fri, 16 Mar 2007 13:42:35 +0100
Subject: [Rd] Unhidden predict methods
In-Reply-To: <Pine.LNX.4.64.0703161222340.8349@gannet.stats.ox.ac.uk>
References: <45FA812B.1060104@gmail.com>
	<Pine.LNX.4.64.0703161222340.8349@gannet.stats.ox.ac.uk>
Message-ID: <45FA90BB.3020308@gmail.com>

Den 2007-03-16 13:25, Prof Brian Ripley skrev:

> The reason some are not hidden is historical: they were called 
> explicitly by (contributed) package code at the time namespaces were 
> introduced.

Ah, I see.

In that case I'll just hide away as much as possible in the new package 
I'm working on.

> It would be a good idea to revisit some of those decisions, but it is 
> not a very appealing way to spend one's time.

Agreed.

Thanks again!


Henric



> 
> On Fri, 16 Mar 2007, Henric Nilsson (Public) wrote:
> 
>> Hi,
>>
>> I've noted that not all `predict' methods are hidden in the namespace:
>>
>> > methods("predict")
>>  [1] predict.ar*                predict.Arima*
>>  [3] predict.arima0*            predict.glm
>>  [5] predict.HoltWinters*       predict.lm
>>  [7] predict.loess*             predict.mlm
>>  [9] predict.nls*               predict.poly
>> [11] predict.ppr*               predict.prcomp*
>> [13] predict.princomp*          predict.smooth.spline*
>> [15] predict.smooth.spline.fit* predict.StructTS*
>>
>>    Non-visible functions are asterisked
>>
>> I'm sure there's a good reason for this, but I haven't been able to
>> figure it out. Please enlighten me.
>


From ggrothendieck at gmail.com  Fri Mar 16 14:21:08 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 16 Mar 2007 09:21:08 -0400
Subject: [Rd] Unhidden predict methods
In-Reply-To: <45FA812B.1060104@gmail.com>
References: <45FA812B.1060104@gmail.com>
Message-ID: <971536df0703160621s18770186vd5c9ac8d50460025@mail.gmail.com>

Sometimes its useful to call a method on a class other than the method
indicated by the suffix of the method name and in that case one needs
to call the method directly rather than via the generic.

For an example, see:

http://tolstoy.newcastle.edu.au/R/e2/help/07/01/9383.html


On 3/16/07, Henric Nilsson (Public) <nilsson.henric at gmail.com> wrote:
> Hi,
>
> I've noted that not all `predict' methods are hidden in the namespace:
>
>  > methods("predict")
>  [1] predict.ar*                predict.Arima*
>  [3] predict.arima0*            predict.glm
>  [5] predict.HoltWinters*       predict.lm
>  [7] predict.loess*             predict.mlm
>  [9] predict.nls*               predict.poly
> [11] predict.ppr*               predict.prcomp*
> [13] predict.princomp*          predict.smooth.spline*
> [15] predict.smooth.spline.fit* predict.StructTS*
>
>    Non-visible functions are asterisked
>
> I'm sure there's a good reason for this, but I haven't been able to
> figure it out. Please enlighten me.
>
> Thanks!
>
>
> Henric
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From sfalcon at fhcrc.org  Fri Mar 16 16:24:29 2007
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Fri, 16 Mar 2007 08:24:29 -0700
Subject: [Rd] R 2.5.0 devel try issue in conjuntion with S4 method
	dispatch
In-Reply-To: <45F98B1D.2060501@epigenomics.com>
	(ml-it-r-devel@epigenomics.com's message of "Thu,
	15 Mar 2007 19:06:21 +0100")
References: <45F98B1D.2060501@epigenomics.com>
Message-ID: <m2y7lx5hzm.fsf@ziti.local>

This is off-topic, but since the discussion moved towards coding
style...  Here are some comments on S4 style.

ml-it-r-devel at epigenomics.com writes:
> ##  using S4 classes and methods
> setClass("fooBase",
>          representation("VIRTUAL",
>                         width      = "numeric",
>                         height     = "numeric"),
>          prototype(width      = 1024,
>                    height     = 1024),
>          validity = NULL,
>          where    = .GlobalEnv,
>          sealed   = TRUE,
>          )

I think for package code, you don't want to specify the where to be
.GlobalEnv.  If you omit the where argument, the class will be defined
within the package environment which is what one usually wants.


> if (!isGeneric("plotObject")) {
>
>   setGeneric("plotObject",
>              def=function(x, y, ...) {
>                value <- standardGeneric("plotObject")
>                return(value)
>              },
>              where=.GlobalEnv,
>              useAsDefault=TRUE
>              )
> }

This idiom of conditionally defining an S4 generic is wide-spread and
I suspect was required at some point in time.  However, at this point,
I don't understand why one would do this and it seems that it can only
lead to hard to catch bugs.  I think it should be strongly discouraged.

To define a method on a generic, you need to know what that generic
is.  For example, you need to know the names of the formal arguments.
With conditional definition as above, you risk attempting to define a
method on a generic you know nothing about.

If you want your own generic, define it.  If you want to set a method
on someone else's generic, say so.  For example, you can do:

   setMethod(otherPkg::theirGeneric, ...)

> plotObject.foo <- function(x, y) {
>   plot(x,y)
> }
>
> setMethod("plotObject", signature=c("foo", "numeric"), plotObject.foo,
> where=.GlobalEnv)

This code is a bit confusing to read since an S3 method for class
"foo" and S3 generic plotObject would be plotObject.foo.  Maybe not
worth worrying about.

Finally, a further subtle point about how the generic was defined in
your example code.  Especially for a standardGeneric, it is best not
to name the result before returning as this can affect when results
get copied.  Here's an illustration:

   setGeneric("frob1", function(x) {
       value <- standardGeneric("frob1")
       value
   })
   
   setGeneric("frob2", function(x) {
       standardGeneric("frob2")
   })
   
   setMethod("frob1", "integer",
             function(x) vector(mode="integer", length=x))
   
   setMethod("frob2", "integer",
             function(x) vector(mode="integer", length=x))


   ###
   
   x1 <- frob1(5L)
   > tracemem(x1)
   [1] "<0x3de8098>"
   > x1[1L] <- 5L
   tracemem[0x3de8098 -> 0x3de80d0]: 
   > 
   > x2 <- frob2(5L)
   > tracemem(x2)
   [1] "<0x3de8140>"
   > x2[1L] <- 5L

Best Wishes,

+ seth

-- 
Seth Falcon | Computational Biology | Fred Hutchinson Cancer Research Center
http://bioconductor.org


From sfalcon at fhcrc.org  Fri Mar 16 17:40:09 2007
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Fri, 16 Mar 2007 09:40:09 -0700
Subject: [Rd] Inherited S4 methods
In-Reply-To: <45F9C191.5020803@aon.at> (cstrato@aon.at's message of "Thu,
	15 Mar 2007 22:58:41 +0100")
References: <45F9C191.5020803@aon.at>
Message-ID: <m2fy855ehi.fsf@ziti.local>

cstrato <cstrato at aon.at> writes:
> I have a variation of this question:
> Is it possible to use the same function name, e.g. "myfunction" in both, 
> an S4
> baseClass and derivedClass. The method "myfunction" in derivedCalss should
> extend the functionality defined in baseClass, analogously to C++ methods.
> If this is possible, does there exist an example?

The S4 object system is generic function based.  Methods are not
contained inside classes.

You can define a generic 'myfunction' and then define methods for
BaseClass and DerivedClass.

+ seth

-- 
Seth Falcon | Computational Biology | Fred Hutchinson Cancer Research Center
http://bioconductor.org


From mtmorgan at fhcrc.org  Fri Mar 16 17:49:41 2007
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Fri, 16 Mar 2007 09:49:41 -0700
Subject: [Rd] Incomplete valgrind instrumentation level documentation
Message-ID: <6phzm6dw2u2.fsf@gopher4.fhcrc.org>

The 'Writing R Extensions' manual, configure.ac, and the comment at
the top of memory.c suggests that there are valgrind instrumentation
levels 0, 1, 2 but I think the actual code has four levels.

   level 0 is no additional instrumentation

   level 1 marks uninitialized numeric, logical, integer vectors
           and R_alloc memory

   level 2 marks free memory (DATAPTR, STRING_PTR) and the protection
           stack as inaccessible

   level 3 marks SEXP as inaccessible
-- 
Martin Morgan
Bioconductor / Computational Biology
http://bioconductor.org


From mtmorgan at fhcrc.org  Fri Mar 16 17:57:23 2007
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Fri, 16 Mar 2007 09:57:23 -0700
Subject: [Rd] Invalidating inaccessible SEXP?
Message-ID: <6phveh1w2h8.fsf@gopher4.fhcrc.org>

Is there a (C or R) function to invalidate the relevant parts of SEXP
/ data that are inaccessible? My problem is in tracking down
protection and other memory mismanagement bugs, where I have to rely
on luck to invalidate or overwrite data to trigger a detectable
error. This makes it hard to track down a bug (it sometimes doesn't
occur), or to know that a patch fixes the problem.

Thanks,

Martin
-- 
Martin Morgan
Bioconductor / Computational Biology
http://bioconductor.org


From aferris at mrl.ubc.ca  Fri Mar 16 18:41:08 2007
From: aferris at mrl.ubc.ca (Andrew Ferris)
Date: Fri, 16 Mar 2007 10:41:08 -0700
Subject: [Rd] compile 2.4.1 for linux on power cpus SOLVED
In-Reply-To: <dc41e1260703151901x46c366b1ha74f73e547500741@mail.gmail.com>
References: <45F7CB380200007B0004C384@mail.mrl.ubc.ca>
	<45F7D4C20200007B0004C3BF@mail.mrl.ubc.ca>
	<45F7D4C2.0211.007B.0@mrl.ubc.ca> <45F85C4D.9080005@biostat.ku.dk>
	<45F80DF7.0211.007B.0@mrl.ubc.ca> <45F88D63.2000704@biostat.ku.dk>
	<45F83A25.0211.007B.0@mrl.ubc.ca> <45F8F040.6070907@biostat.ku.dk>
	<Pine.LNX.4.64.0703150709370.30980@gannet.stats.ox.ac.uk>
	<45F94F49.0211.007B.0@mrl.ubc.ca>
	<dc41e1260703151901x46c366b1ha74f73e547500741@mail.gmail.com>
Message-ID: <45FA7444.0211.007B.0@mrl.ubc.ca>

Thank you Ei-ji, 

That seems to have done it.

> .Machine$sizeof.pointer
[1] 8

So in total I've done the following to get it work:

Installed these readline rpms from the SLES10 media:

readline-devel-64bit-5.1-24.4
readline-devel-5.1-24.4

This is the configure command:

./configure CC="gcc -m64" /
CXX="gxx -m64" /
F77="gfortran -m64" / 
FC="gfortran -m64" /
CFLAGS="-mminimal-toc -fno-optimize-sibling-calls -g -O2" /
FFLAGS="-mminimal-toc -fno-optimize-sibling-calls -g -O2" /
LDFLAGS=-L/usr/lib64 /
--without-x

which gets this:

R is now configured for powerpc64-unknown-linux-gnu

  Source directory:          .
  Installation directory:    /usr/local

  C compiler:                gcc -m64 -std=gnu99  -mminimal-toc -fno-optimize-sibling-calls -g -O2
  Fortran 77 compiler:       gfortran -m64  -mminimal-toc -fno-optimize-sibling-calls -g -O2

  C++ compiler:              gxx -m64
  Fortran 90/95 compiler:    gfortran -m64 -g -O2

  Interfaces supported:
  External libraries:        readline
  Additional capabilities:   iconv, MBCS, NLS
  Options enabled:           shared BLAS, R profiling

  Recommended packages:      yes

configure: WARNING: I could not determine CXXPICFLAGS.
configure: WARNING: I could not determine SHLIB_CXXLDFLAGS
configure: WARNING: I could not determine CXXPICFLAGS.
configure: WARNING: you cannot build DVI versions of the R manuals
configure: WARNING: you cannot build PDF versions of the R manuals
configure: WARNING: I could not determine a PDF viewer

And that gets through make with no errors. That's R 2.4.1 on SLES10 on a power5 CPU server. 

Thank-you to Peter Dalgaard and Prof. Ripley for their help with this.

Andrew Ferris
Network Support Analyst
iCAPTURE Research Centre
University of British Columbia

>>> "Ei-ji Nakama" <nakama at ki.rim.or.jp> 3/15/2007 7:01 PM >>>
2007/3/16, Andrew Ferris <aferris at mrl.ubc.ca>:
> I'm closer but still not quite there. Here's the configure command I'm using:
>
>  ./configure 'CC=gcc -m64' 'CXX=g++ -m64 -mminimal-toc' 'FC=gfortran -mc64 -fno-optimize-sibling-calls' 'F77=gfortran -m64 -fno-optimize-sibling-calls' 'LDFLAGS=-L/usr/lib64' R_PAPERSIZE='letter'

$ uname -a
Linux macg5 2.6.18-3-powerpc64 #1 SMP Mon Dec 4 15:40:16 CET 2006
ppc64 GNU/Linux

$ gcc -v
Using built-in specs.
Target: powerpc-linux-gnu
Configured with: ../src/configure -v
--enable-languages=c,c++,fortran,objc,obj-c++,treelang --prefix=/usr
--enable-shared --with-system-zlib --libexecdir=/usr/lib
--without-included-gettext --enable-threads=posix --enable-nls
--program-suffix=-4.1 --enable-__cxa_atexit --enable-clocale=gnu
--enable-libstdcxx-debug --enable-mpfr --disable-softfloat
--enable-targets=powerpc-linux,powerpc64-linux --with-cpu=default32
--enable-checking=release powerpc-linux-gnu
Thread model: posix
gcc version 4.1.2 20061115 (prerelease) (Debian 4.1.1-21)

$ gcc -print-multi-lib
.;@fPIC at mstrict-align
64;@m64 at fPIC@mstrict-align

$ ./configure CC="gcc -m64" \
                   CXX="gxx -m64" \
                   F77="gfortran -m64" \
                   FC="gfortran -m64" \
                   CFLAGS="-mminimal-toc -fno-optimize-sibling-calls -g -O2" \
                   FFLAGS="-mminimal-toc -fno-optimize-sibling-calls -g -O2" \
                   --without-x

$ file bin/exec/R
bin/exec/R: ELF 64-bit MSB executable, PowerPC 64-bit or cisco 7500,
version 1 (SYSV), for GNU/Linux 2.6.0, dynamically linked (uses shared
libs), for GNU/Linux 2.6.0, not stripped

-- 
EI-JI Nakama  <nakama at ki.rim.or.jp>
"\u4e2d\u9593\u6804\u6cbb"  <nakama at ki.rim.or.jp>



***CONFIDENTIALITY NOTICE***
This electronic message is intended only for the use of the addressee and may contain information that is privileged and confidential.  Any dissemination, distribution or copying of this communication by unauthorized individuals is strictly prohibited. If you have received this communication in error, please notify the sender immediately by reply e-mail and delete the original and all copies from your system.


From ggrothendieck at gmail.com  Fri Mar 16 18:54:45 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 16 Mar 2007 13:54:45 -0400
Subject: [Rd] NextMethod and $.myclass
Message-ID: <971536df0703161054w3ebe6682q1aad4ffc30fe5a99@mail.gmail.com>

The following redefines $ on "myclass" objects so that it looks up
the concatenation of the unevaluated second argument and 2
in the object and returns the result:

"$.myclass" <- function(x, name) x[[paste(substitute(name), 2, sep = "")]]

# test
myobject <- structure(list(x2 = 3), class = "myclass")
myobject$x # 3

The above worked as desired but now I want to rewrite $.myclass so that
it continues to work the same way but uses NextMethod
to get the next $ method where the remaining work is done. The problem
involves the fact that $ does not evaluate name.   Can this still be done
somehow?

"$.myclass" <- function(x, name) {
    modified.name <- paste(substitute(name), 2, sep = "")
    # ???
    NextMethod()
}


From cstrato at aon.at  Fri Mar 16 21:52:38 2007
From: cstrato at aon.at (cstrato)
Date: Fri, 16 Mar 2007 21:52:38 +0100
Subject: [Rd]  Inherited S4 methods
References: 45F9C191.5020803@aon.at
Message-ID: <45FB0396.2060209@aon.at>

Dear Seth

Thank you, maybe I still do not understand S4 methods.

I thought that the purpose of function "callNextMethod()" is to allow
some kind of inheritance. In the Bioconuductor packages which are
using S4, it is only used for method("initialize") but I thought, that
it can be used with every method "mymethod()", is this correct?

Best regards
Christian


From cstrato at aon.at  Fri Mar 16 21:55:58 2007
From: cstrato at aon.at (cstrato)
Date: Fri, 16 Mar 2007 21:55:58 +0100
Subject: [Rd] Problems with package containing S4 classes
Message-ID: <45FB045E.3090909@aon.at>

Dear all,

Currently, I am trying to create a test package "testS4" using S4 classes,
which I am attaching.

Running R CMD check gives the following error:

coeurebooks-computer:/Volumes/CoreData/CRAN cs$ R CMD check 
testS4_0.1.1.tar.gz
* checking for working latex ...sh: line 1: latex: command not found
 NO
* using log directory '/Volumes/CoreData/CRAN/testS4.Rcheck'
* using R version 2.5.0 Under development (unstable) (2007-02-26 r40806)
* checking for file 'testS4/DESCRIPTION' ... OK
* this is package 'testS4' version '0.1.1'
* checking package dependencies ... OK
* checking if this is a source package ... OK
* checking whether package 'testS4' can be installed ... OK
* checking package directory ... OK
* checking for portable file names ... OK
* checking for sufficient/correct file permissions ... OK
* checking DESCRIPTION meta-information ... OK
* checking top-level files ... OK
* checking index information ... OK
* checking package subdirectories ... OK
* checking R files for non-ASCII characters ... OK
* checking R files for syntax errors ... OK
* checking whether the package can be loaded ... ERROR
Error in library.dynam(lib, package, package.lib) :
        shared library 'testS4' not found
Error: package/namespace load failed for 'testS4'
Execution halted

Can someone explain what this error means?
What is meant with "shared library"?

For another test package I get the following error
coeurebooks-computer:/Volumes/CoreData/CRAN cs$ R CMD INSTALL -l 
~/Library/R/library mytest_0.3.2.tar.gz
* Installing *source* package 'mytest' ...
** R
** save image
Error in setMethod("export", "derivedClass", export.derivedClass) :
        no existing definition for function "export"
Error: unable to load R code in package 'mytest'
Execution halted

This error is even more strange since I cannot reproduce it in the 
attached package.
What may be the reason for this error?

Thank you in advance.
Best regards
Christian
_._._._._._._._._._._._._._._._
C.h.i.s.t.i.a.n S.t.r.a.t.o.w.a
V.i.e.n.n.a       A.u.s.t.r.i.a
_._._._._._._._._._._._._._._._

-------------- next part --------------
A non-text attachment was scrubbed...
Name: testS4_0.1.1.tar.gz
Type: application/x-gzip
Size: 3180 bytes
Desc: not available
Url : https://stat.ethz.ch/pipermail/r-devel/attachments/20070316/d4ef7ed7/attachment.gz 

From bcarvalh at jhsph.edu  Fri Mar 16 22:03:34 2007
From: bcarvalh at jhsph.edu (Benilton Carvalho)
Date: Fri, 16 Mar 2007 17:03:34 -0400
Subject: [Rd] Problems with package containing S4 classes
In-Reply-To: <45FB045E.3090909@aon.at>
References: <45FB045E.3090909@aon.at>
Message-ID: <72DA1101-B6C5-4DB7-A9F8-2CC091D8AC7E@jhsph.edu>

your namespace probably contains:

useDynLib(testS4)

but you don't have any compiled code...

remove that line and everything will be fine.

btw, if you're playing with S4, you must import 'methods'

b

On Mar 16, 2007, at 4:55 PM, cstrato wrote:

> Dear all,
>
> Currently, I am trying to create a test package "testS4" using S4  
> classes,
> which I am attaching.
>
> Running R CMD check gives the following error:
>
> coeurebooks-computer:/Volumes/CoreData/CRAN cs$ R CMD check  
> testS4_0.1.1.tar.gz
> * checking for working latex ...sh: line 1: latex: command not found
> NO
> * using log directory '/Volumes/CoreData/CRAN/testS4.Rcheck'
> * using R version 2.5.0 Under development (unstable) (2007-02-26  
> r40806)
> * checking for file 'testS4/DESCRIPTION' ... OK
> * this is package 'testS4' version '0.1.1'
> * checking package dependencies ... OK
> * checking if this is a source package ... OK
> * checking whether package 'testS4' can be installed ... OK
> * checking package directory ... OK
> * checking for portable file names ... OK
> * checking for sufficient/correct file permissions ... OK
> * checking DESCRIPTION meta-information ... OK
> * checking top-level files ... OK
> * checking index information ... OK
> * checking package subdirectories ... OK
> * checking R files for non-ASCII characters ... OK
> * checking R files for syntax errors ... OK
> * checking whether the package can be loaded ... ERROR
> Error in library.dynam(lib, package, package.lib) :
>        shared library 'testS4' not found
> Error: package/namespace load failed for 'testS4'
> Execution halted
>
> Can someone explain what this error means?
> What is meant with "shared library"?
>
> For another test package I get the following error
> coeurebooks-computer:/Volumes/CoreData/CRAN cs$ R CMD INSTALL -l ~/ 
> Library/R/library mytest_0.3.2.tar.gz
> * Installing *source* package 'mytest' ...
> ** R
> ** save image
> Error in setMethod("export", "derivedClass", export.derivedClass) :
>        no existing definition for function "export"
> Error: unable to load R code in package 'mytest'
> Execution halted
>
> This error is even more strange since I cannot reproduce it in the  
> attached package.
> What may be the reason for this error?
>
> Thank you in advance.
> Best regards
> Christian
> _._._._._._._._._._._._._._._._
> C.h.i.s.t.i.a.n S.t.r.a.t.o.w.a
> V.i.e.n.n.a       A.u.s.t.r.i.a
> _._._._._._._._._._._._._._._._
>
> <testS4_0.1.1.tar.gz>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From vobolonkin at lic.co.nz  Thu Mar 15 21:18:12 2007
From: vobolonkin at lic.co.nz (vobolonkin at lic.co.nz)
Date: Thu, 15 Mar 2007 21:18:12 +0100 (CET)
Subject: [Rd] Incorrect matrix of spearman correlations .... in 64-bit Linux
	... (PR#9568)
Message-ID: <20070315201812.D238E5AA69@slim.kubism.ku.dk>

Full_Name: Vladimir Obolonkin
Version: tested in 2.0 to 2.4.1
OS: linux, win, mac
Submission from: (NULL) (202.14.96.194)

{{ Subject shortened manually -- to pass anti-spam filters 

   Original-subject: Incorrect matrix of spearman correlations working \
     large (24000 by 425 and 78 by 425 data frames)  in 64-bit Linux machines;\
      the same code gives correct results in 32-bits Win and Mac (PR#9568)
}}

cc_s<-cor(phenos,vec,method="spearman",use="pairwise.complete.obs")

this is a line copied from real script producing different results in 64
bit/Linux/R (wrong) and Mac&Win (correct)

The script was implemented on 4 machines with Linux 64, Suse 9-10, in 5 variants
of R -- versions from 2.3 to 2.4.1, compiled with few different settings of
optimization and 2 versions of compilers. In all cases the results of spearman
correlation were identical, but wrong.

The same script was started up to 10 times in Win32 on Intel and Linux32 on Mac
with the Rs from 2.3 to 2.4.1 -- in this set of cases the results were identical
and correct.

'phenos' and 'vec' are data frames of 425x78 and 425x24128 respectively, all
numeric variables. The 'phenos' has moderate number of NAs in some columnes.

The problem dissapeared when trying to reduce the size of matrices (by selection
of rows and/or columns) and/or when simulating the data with random generators.


From cstrato at aon.at  Fri Mar 16 22:38:53 2007
From: cstrato at aon.at (cstrato)
Date: Fri, 16 Mar 2007 22:38:53 +0100
Subject: [Rd] Problems with package containing S4 classes
In-Reply-To: <72DA1101-B6C5-4DB7-A9F8-2CC091D8AC7E@jhsph.edu>
References: <45FB045E.3090909@aon.at>
	<72DA1101-B6C5-4DB7-A9F8-2CC091D8AC7E@jhsph.edu>
Message-ID: <45FB0E6D.3010803@aon.at>

Dear Benilton

Thank you, now my package works.

Do you have an explanation for my second problem:

* Installing *source* package 'mytest' ...
** R
** save image
Error in setMethod("export", "derivedClass", export.derivedClass) :
        no existing definition for function "export"
Error: unable to load R code in package 'mytest'
Execution halted

What may be the reason for this error?

Best regards
Christian


Benilton Carvalho wrote:
> your namespace probably contains:
>
> useDynLib(testS4)
>
> but you don't have any compiled code...
>
> remove that line and everything will be fine.
>
> btw, if you're playing with S4, you must import 'methods'
>
> b
>
> On Mar 16, 2007, at 4:55 PM, cstrato wrote:
>
>> Dear all,
>>
>> Currently, I am trying to create a test package "testS4" using S4 
>> classes,
>> which I am attaching.
>>
>> Running R CMD check gives the following error:
>>
>> coeurebooks-computer:/Volumes/CoreData/CRAN cs$ R CMD check 
>> testS4_0.1.1.tar.gz
>> * checking for working latex ...sh: line 1: latex: command not found
>> NO
>> * using log directory '/Volumes/CoreData/CRAN/testS4.Rcheck'
>> * using R version 2.5.0 Under development (unstable) (2007-02-26 r40806)
>> * checking for file 'testS4/DESCRIPTION' ... OK
>> * this is package 'testS4' version '0.1.1'
>> * checking package dependencies ... OK
>> * checking if this is a source package ... OK
>> * checking whether package 'testS4' can be installed ... OK
>> * checking package directory ... OK
>> * checking for portable file names ... OK
>> * checking for sufficient/correct file permissions ... OK
>> * checking DESCRIPTION meta-information ... OK
>> * checking top-level files ... OK
>> * checking index information ... OK
>> * checking package subdirectories ... OK
>> * checking R files for non-ASCII characters ... OK
>> * checking R files for syntax errors ... OK
>> * checking whether the package can be loaded ... ERROR
>> Error in library.dynam(lib, package, package.lib) :
>>        shared library 'testS4' not found
>> Error: package/namespace load failed for 'testS4'
>> Execution halted
>>
>> Can someone explain what this error means?
>> What is meant with "shared library"?
>>
>> For another test package I get the following error
>> coeurebooks-computer:/Volumes/CoreData/CRAN cs$ R CMD INSTALL -l 
>> ~/Library/R/library mytest_0.3.2.tar.gz
>> * Installing *source* package 'mytest' ...
>> ** R
>> ** save image
>> Error in setMethod("export", "derivedClass", export.derivedClass) :
>>        no existing definition for function "export"
>> Error: unable to load R code in package 'mytest'
>> Execution halted
>>
>> This error is even more strange since I cannot reproduce it in the 
>> attached package.
>> What may be the reason for this error?
>>
>> Thank you in advance.
>> Best regards
>> Christian
>> _._._._._._._._._._._._._._._._
>> C.h.i.s.t.i.a.n S.t.r.a.t.o.w.a
>> V.i.e.n.n.a       A.u.s.t.r.i.a
>> _._._._._._._._._._._._._._._._
>>
>> <testS4_0.1.1.tar.gz>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From p.dalgaard at biostat.ku.dk  Fri Mar 16 22:44:27 2007
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Fri, 16 Mar 2007 22:44:27 +0100
Subject: [Rd] Incorrect matrix of spearman correlations .... in 64-bit
 Linux	... (PR#9568)
In-Reply-To: <20070315201812.D238E5AA69@slim.kubism.ku.dk>
References: <20070315201812.D238E5AA69@slim.kubism.ku.dk>
Message-ID: <45FB0FBB.6090607@biostat.ku.dk>

vobolonkin at lic.co.nz wrote:
> Full_Name: Vladimir Obolonkin
> Version: tested in 2.0 to 2.4.1
> OS: linux, win, mac
> Submission from: (NULL) (202.14.96.194)
>
> {{ Subject shortened manually -- to pass anti-spam filters 
>
>    Original-subject: Incorrect matrix of spearman correlations working \
>      large (24000 by 425 and 78 by 425 data frames)  in 64-bit Linux machines;\
>       the same code gives correct results in 32-bits Win and Mac (PR#9568)
> }}
>
> cc_s<-cor(phenos,vec,method="spearman",use="pairwise.complete.obs")
>
> this is a line copied from real script producing different results in 64
> bit/Linux/R (wrong) and Mac&Win (correct)
>
> The script was implemented on 4 machines with Linux 64, Suse 9-10, in 5 variants
> of R -- versions from 2.3 to 2.4.1, compiled with few different settings of
> optimization and 2 versions of compilers. In all cases the results of spearman
> correlation were identical, but wrong.
>
> The same script was started up to 10 times in Win32 on Intel and Linux32 on Mac
> with the Rs from 2.3 to 2.4.1 -- in this set of cases the results were identical
> and correct.
>
> 'phenos' and 'vec' are data frames of 425x78 and 425x24128 respectively, all
> numeric variables. The 'phenos' has moderate number of NAs in some columnes.
>
> The problem dissapeared when trying to reduce the size of matrices (by selection
> of rows and/or columns) and/or when simulating the data with random generators.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>   
I don't see anything to reproduce here, so how are we supposed to get a 
handle on the issue?


From p.dalgaard at biostat.ku.dk  Fri Mar 16 22:44:51 2007
From: p.dalgaard at biostat.ku.dk (p.dalgaard at biostat.ku.dk)
Date: Fri, 16 Mar 2007 22:44:51 +0100 (CET)
Subject: [Rd] Incorrect matrix of spearman correlations .... in 64-bit
	(PR#9570)
Message-ID: <20070316214451.9A6225ABD0@slim.kubism.ku.dk>

vobolonkin at lic.co.nz wrote:
> Full_Name: Vladimir Obolonkin
> Version: tested in 2.0 to 2.4.1
> OS: linux, win, mac
> Submission from: (NULL) (202.14.96.194)
>
> {{ Subject shortened manually -- to pass anti-spam filters 
>
>    Original-subject: Incorrect matrix of spearman correlations working \
>      large (24000 by 425 and 78 by 425 data frames)  in 64-bit Linux machines;\
>       the same code gives correct results in 32-bits Win and Mac (PR#9568)
> }}
>
> cc_s<-cor(phenos,vec,method="spearman",use="pairwise.complete.obs")
>
> this is a line copied from real script producing different results in 64
> bit/Linux/R (wrong) and Mac&Win (correct)
>
> The script was implemented on 4 machines with Linux 64, Suse 9-10, in 5 variants
> of R -- versions from 2.3 to 2.4.1, compiled with few different settings of
> optimization and 2 versions of compilers. In all cases the results of spearman
> correlation were identical, but wrong.
>
> The same script was started up to 10 times in Win32 on Intel and Linux32 on Mac
> with the Rs from 2.3 to 2.4.1 -- in this set of cases the results were identical
> and correct.
>
> 'phenos' and 'vec' are data frames of 425x78 and 425x24128 respectively, all
> numeric variables. The 'phenos' has moderate number of NAs in some columnes.
>
> The problem dissapeared when trying to reduce the size of matrices (by selection
> of rows and/or columns) and/or when simulating the data with random generators.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>   
I don't see anything to reproduce here, so how are we supposed to get a 
handle on the issue?


From bcarvalh at jhsph.edu  Fri Mar 16 22:52:47 2007
From: bcarvalh at jhsph.edu (Benilton Carvalho)
Date: Fri, 16 Mar 2007 17:52:47 -0400
Subject: [Rd] Problems with package containing S4 classes
In-Reply-To: <45FB0E6D.3010803@aon.at>
References: <45FB045E.3090909@aon.at>
	<72DA1101-B6C5-4DB7-A9F8-2CC091D8AC7E@jhsph.edu>
	<45FB0E6D.3010803@aon.at>
Message-ID: <D023A1FD-2388-40C3-AC7D-A20773326A62@jhsph.edu>

do you have a generic for 'export'?

On Mar 16, 2007, at 5:38 PM, cstrato wrote:

> Dear Benilton
>
> Thank you, now my package works.
>
> Do you have an explanation for my second problem:
>
> * Installing *source* package 'mytest' ...
> ** R
> ** save image
> Error in setMethod("export", "derivedClass", export.derivedClass) :
>        no existing definition for function "export"
> Error: unable to load R code in package 'mytest'
> Execution halted
>
> What may be the reason for this error?
>
> Best regards
> Christian
>
>
> Benilton Carvalho wrote:
>> your namespace probably contains:
>>
>> useDynLib(testS4)
>>
>> but you don't have any compiled code...
>>
>> remove that line and everything will be fine.
>>
>> btw, if you're playing with S4, you must import 'methods'
>>
>> b
>>
>> On Mar 16, 2007, at 4:55 PM, cstrato wrote:
>>
>>> Dear all,
>>>
>>> Currently, I am trying to create a test package "testS4" using S4  
>>> classes,
>>> which I am attaching.
>>>
>>> Running R CMD check gives the following error:
>>>
>>> coeurebooks-computer:/Volumes/CoreData/CRAN cs$ R CMD check  
>>> testS4_0.1.1.tar.gz
>>> * checking for working latex ...sh: line 1: latex: command not found
>>> NO
>>> * using log directory '/Volumes/CoreData/CRAN/testS4.Rcheck'
>>> * using R version 2.5.0 Under development (unstable) (2007-02-26  
>>> r40806)
>>> * checking for file 'testS4/DESCRIPTION' ... OK
>>> * this is package 'testS4' version '0.1.1'
>>> * checking package dependencies ... OK
>>> * checking if this is a source package ... OK
>>> * checking whether package 'testS4' can be installed ... OK
>>> * checking package directory ... OK
>>> * checking for portable file names ... OK
>>> * checking for sufficient/correct file permissions ... OK
>>> * checking DESCRIPTION meta-information ... OK
>>> * checking top-level files ... OK
>>> * checking index information ... OK
>>> * checking package subdirectories ... OK
>>> * checking R files for non-ASCII characters ... OK
>>> * checking R files for syntax errors ... OK
>>> * checking whether the package can be loaded ... ERROR
>>> Error in library.dynam(lib, package, package.lib) :
>>>        shared library 'testS4' not found
>>> Error: package/namespace load failed for 'testS4'
>>> Execution halted
>>>
>>> Can someone explain what this error means?
>>> What is meant with "shared library"?
>>>
>>> For another test package I get the following error
>>> coeurebooks-computer:/Volumes/CoreData/CRAN cs$ R CMD INSTALL -l  
>>> ~/Library/R/library mytest_0.3.2.tar.gz
>>> * Installing *source* package 'mytest' ...
>>> ** R
>>> ** save image
>>> Error in setMethod("export", "derivedClass", export.derivedClass) :
>>>        no existing definition for function "export"
>>> Error: unable to load R code in package 'mytest'
>>> Execution halted
>>>
>>> This error is even more strange since I cannot reproduce it in  
>>> the attached package.
>>> What may be the reason for this error?
>>>
>>> Thank you in advance.
>>> Best regards
>>> Christian
>>> _._._._._._._._._._._._._._._._
>>> C.h.i.s.t.i.a.n S.t.r.a.t.o.w.a
>>> V.i.e.n.n.a       A.u.s.t.r.i.a
>>> _._._._._._._._._._._._._._._._
>>>
>>> <testS4_0.1.1.tar.gz>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>


From sfalcon at fhcrc.org  Fri Mar 16 22:58:10 2007
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Fri, 16 Mar 2007 14:58:10 -0700
Subject: [Rd] Inherited S4 methods
In-Reply-To: <45FB0396.2060209@aon.at> (cstrato@aon.at's message of "Fri,
	16 Mar 2007 21:52:38 +0100")
References: <45FB0396.2060209@aon.at>
Message-ID: <m2abyc4zrh.fsf@ziti.local>

cstrato <cstrato at aon.at> writes:

> Dear Seth
>
> Thank you, maybe I still do not understand S4 methods.
>
> I thought that the purpose of function "callNextMethod()" is to allow
> some kind of inheritance. In the Bioconuductor packages which are
> using S4, it is only used for method("initialize") but I thought, that
> it can be used with every method "mymethod()", is this correct?

Yes, callNextMethod can be used in any method definition.  When you
call a generic function, the system creates a list of all methods for
that generic that are applicable and orders them so that the most
specific method comes first.  When you call callNextMethod, you enter
the next most specific method.

+ seth

-- 
Seth Falcon | Computational Biology | Fred Hutchinson Cancer Research Center
http://bioconductor.org


From cstrato at aon.at  Fri Mar 16 23:22:36 2007
From: cstrato at aon.at (cstrato)
Date: Fri, 16 Mar 2007 23:22:36 +0100
Subject: [Rd]  Inherited S4 methods
References: 45FB0396.2060209@aon.at
Message-ID: <45FB18AC.9070705@aon.at>

Dear Seth

Thank you, I will further explain this feature.

Best regards
Christian


From cstrato at aon.at  Fri Mar 16 23:35:06 2007
From: cstrato at aon.at (cstrato)
Date: Fri, 16 Mar 2007 23:35:06 +0100
Subject: [Rd] Problems with package containing S4 classes
In-Reply-To: <D023A1FD-2388-40C3-AC7D-A20773326A62@jhsph.edu>
References: <45FB045E.3090909@aon.at>
	<72DA1101-B6C5-4DB7-A9F8-2CC091D8AC7E@jhsph.edu>
	<45FB0E6D.3010803@aon.at>
	<D023A1FD-2388-40C3-AC7D-A20773326A62@jhsph.edu>
Message-ID: <45FB1B9A.3040406@aon.at>

Dear Benilton

Yes, but the error disappears only when I define it twice.

For my package I create three files:

1. MyClasses.R:
Here I define the classes only using
setClass("baseClass")
setClass("derivedClass")

2. methods.baseClass.R
Here I define the methods for baseClass
setGeneric("export", function(object,...) standardGeneric("export"))
setMethod("export", "baseClass", export.baseClass);

3. methods.derivedClass.R
Here I define the methods for derivedClass
setGeneric("export", function(object,...) standardGeneric("export"))
setMethod("export", "derivedClass", export.derivedClass);

As you see, I need to define setGeneric twice, otherwise I get the error.
It is not clear to me, why this is the case?

I know, that BioBase has a file AllGeneric.R, but I would like to define
the generics in the respective methods files.

Best regards
Christian

Benilton Carvalho wrote:
> do you have a generic for 'export'?
>
> On Mar 16, 2007, at 5:38 PM, cstrato wrote:
>
>> Dear Benilton
>>
>> Thank you, now my package works.
>>
>> Do you have an explanation for my second problem:
>>
>> * Installing *source* package 'mytest' ...
>> ** R
>> ** save image
>> Error in setMethod("export", "derivedClass", export.derivedClass) :
>>        no existing definition for function "export"
>> Error: unable to load R code in package 'mytest'
>> Execution halted
>>
>> What may be the reason for this error?
>>
>> Best regards
>> Christian
>>
>>


From bcarvalh at jhsph.edu  Fri Mar 16 23:45:41 2007
From: bcarvalh at jhsph.edu (Benilton Carvalho)
Date: Fri, 16 Mar 2007 18:45:41 -0400
Subject: [Rd] Problems with package containing S4 classes
In-Reply-To: <45FB1B9A.3040406@aon.at>
References: <45FB045E.3090909@aon.at>
	<72DA1101-B6C5-4DB7-A9F8-2CC091D8AC7E@jhsph.edu>
	<45FB0E6D.3010803@aon.at>
	<D023A1FD-2388-40C3-AC7D-A20773326A62@jhsph.edu>
	<45FB1B9A.3040406@aon.at>
Message-ID: <C92F4691-41B7-4881-B604-57E0BA978BE6@jhsph.edu>

Well, my understanding is that if you "need" to define it (the  
generic) twice you're doing something wrong.

Do you have a collate field in your description file? IMHO, the  
"AllGeneric.R"/"AllClasses.R" approach is the way to go... keeping  
your code organized is always a good thing, right?

b

On Mar 16, 2007, at 6:35 PM, cstrato wrote:

> Dear Benilton
>
> Yes, but the error disappears only when I define it twice.
>
> For my package I create three files:
>
> 1. MyClasses.R:
> Here I define the classes only using
> setClass("baseClass")
> setClass("derivedClass")
>
> 2. methods.baseClass.R
> Here I define the methods for baseClass
> setGeneric("export", function(object,...) standardGeneric("export"))
> setMethod("export", "baseClass", export.baseClass);
>
> 3. methods.derivedClass.R
> Here I define the methods for derivedClass
> setGeneric("export", function(object,...) standardGeneric("export"))
> setMethod("export", "derivedClass", export.derivedClass);
>
> As you see, I need to define setGeneric twice, otherwise I get the  
> error.
> It is not clear to me, why this is the case?
>
> I know, that BioBase has a file AllGeneric.R, but I would like to  
> define
> the generics in the respective methods files.
>
> Best regards
> Christian
>
> Benilton Carvalho wrote:
>> do you have a generic for 'export'?
>>
>> On Mar 16, 2007, at 5:38 PM, cstrato wrote:
>>
>>> Dear Benilton
>>>
>>> Thank you, now my package works.
>>>
>>> Do you have an explanation for my second problem:
>>>
>>> * Installing *source* package 'mytest' ...
>>> ** R
>>> ** save image
>>> Error in setMethod("export", "derivedClass", export.derivedClass) :
>>>        no existing definition for function "export"
>>> Error: unable to load R code in package 'mytest'
>>> Execution halted
>>>
>>> What may be the reason for this error?
>>>
>>> Best regards
>>> Christian
>>>
>>>


From cstrato at aon.at  Sat Mar 17 00:01:23 2007
From: cstrato at aon.at (cstrato)
Date: Sat, 17 Mar 2007 00:01:23 +0100
Subject: [Rd] Problems with package containing S4 classes
In-Reply-To: <C92F4691-41B7-4881-B604-57E0BA978BE6@jhsph.edu>
References: <45FB045E.3090909@aon.at>
	<72DA1101-B6C5-4DB7-A9F8-2CC091D8AC7E@jhsph.edu>
	<45FB0E6D.3010803@aon.at>
	<D023A1FD-2388-40C3-AC7D-A20773326A62@jhsph.edu>
	<45FB1B9A.3040406@aon.at>
	<C92F4691-41B7-4881-B604-57E0BA978BE6@jhsph.edu>
Message-ID: <45FB21C3.1050205@aon.at>

I agree, but I hope that "AllGeneric.R" is not the only possibility.
BTW, what is a collate field?

Best regards
Christian

Benilton Carvalho wrote:
> Well, my understanding is that if you "need" to define it (the 
> generic) twice you're doing something wrong.
>
> Do you have a collate field in your description file? IMHO, the 
> "AllGeneric.R"/"AllClasses.R" approach is the way to go... keeping 
> your code organized is always a good thing, right?
>
> b
>
> On Mar 16, 2007, at 6:35 PM, cstrato wrote:
>
>> Dear Benilton
>>
>> Yes, but the error disappears only when I define it twice.
>>
>> For my package I create three files:
>>
>> 1. MyClasses.R:
>> Here I define the classes only using
>> setClass("baseClass")
>> setClass("derivedClass")
>>
>> 2. methods.baseClass.R
>> Here I define the methods for baseClass
>> setGeneric("export", function(object,...) standardGeneric("export"))
>> setMethod("export", "baseClass", export.baseClass);
>>
>> 3. methods.derivedClass.R
>> Here I define the methods for derivedClass
>> setGeneric("export", function(object,...) standardGeneric("export"))
>> setMethod("export", "derivedClass", export.derivedClass);
>>
>> As you see, I need to define setGeneric twice, otherwise I get the 
>> error.
>> It is not clear to me, why this is the case?
>>
>> I know, that BioBase has a file AllGeneric.R, but I would like to define
>> the generics in the respective methods files.
>>
>> Best regards
>> Christian
>>
>> Benilton Carvalho wrote:
>>> do you have a generic for 'export'?
>>>
>>> On Mar 16, 2007, at 5:38 PM, cstrato wrote:
>>>
>>>> Dear Benilton
>>>>
>>>> Thank you, now my package works.
>>>>
>>>> Do you have an explanation for my second problem:
>>>>
>>>> * Installing *source* package 'mytest' ...
>>>> ** R
>>>> ** save image
>>>> Error in setMethod("export", "derivedClass", export.derivedClass) :
>>>>        no existing definition for function "export"
>>>> Error: unable to load R code in package 'mytest'
>>>> Execution halted
>>>>
>>>> What may be the reason for this error?
>>>>
>>>> Best regards
>>>> Christian
>>>>
>>>>
>
>


From bcarvalh at jhsph.edu  Sat Mar 17 00:35:08 2007
From: bcarvalh at jhsph.edu (Benilton Carvalho)
Date: Fri, 16 Mar 2007 19:35:08 -0400
Subject: [Rd] Problems with package containing S4 classes
In-Reply-To: <45FB21C3.1050205@aon.at>
References: <45FB045E.3090909@aon.at>
	<72DA1101-B6C5-4DB7-A9F8-2CC091D8AC7E@jhsph.edu>
	<45FB0E6D.3010803@aon.at>
	<D023A1FD-2388-40C3-AC7D-A20773326A62@jhsph.edu>
	<45FB1B9A.3040406@aon.at>
	<C92F4691-41B7-4881-B604-57E0BA978BE6@jhsph.edu>
	<45FB21C3.1050205@aon.at>
Message-ID: <0173F567-3E02-422B-BE69-28A058DD8BF5@jhsph.edu>

The Collate field gives the order that the files are going to be  
concatenated. If they're concatenated using the "wrong" order, your  
installation might fail (for example, the generic is defined after  
the method).

A recommended source is the  "Writing R Extensions"

http://cran.r-project.org/doc/manuals/R-exts.html

Session 1.1.1 - The Description File (Writing R Extensions)

says exactly what you shohuld know about the Collate field (and not  
only that).

b

On Mar 16, 2007, at 7:01 PM, cstrato wrote:

> I agree, but I hope that "AllGeneric.R" is not the only possibility.
> BTW, what is a collate field?
>
> Best regards
> Christian
>
> Benilton Carvalho wrote:
>> Well, my understanding is that if you "need" to define it (the  
>> generic) twice you're doing something wrong.
>>
>> Do you have a collate field in your description file? IMHO, the  
>> "AllGeneric.R"/"AllClasses.R" approach is the way to go... keeping  
>> your code organized is always a good thing, right?
>>
>> b
>>
>> On Mar 16, 2007, at 6:35 PM, cstrato wrote:
>>
>>> Dear Benilton
>>>
>>> Yes, but the error disappears only when I define it twice.
>>>
>>> For my package I create three files:
>>>
>>> 1. MyClasses.R:
>>> Here I define the classes only using
>>> setClass("baseClass")
>>> setClass("derivedClass")
>>>
>>> 2. methods.baseClass.R
>>> Here I define the methods for baseClass
>>> setGeneric("export", function(object,...) standardGeneric("export"))
>>> setMethod("export", "baseClass", export.baseClass);
>>>
>>> 3. methods.derivedClass.R
>>> Here I define the methods for derivedClass
>>> setGeneric("export", function(object,...) standardGeneric("export"))
>>> setMethod("export", "derivedClass", export.derivedClass);
>>>
>>> As you see, I need to define setGeneric twice, otherwise I get  
>>> the error.
>>> It is not clear to me, why this is the case?
>>>
>>> I know, that BioBase has a file AllGeneric.R, but I would like to  
>>> define
>>> the generics in the respective methods files.
>>>
>>> Best regards
>>> Christian
>>>
>>> Benilton Carvalho wrote:
>>>> do you have a generic for 'export'?
>>>>
>>>> On Mar 16, 2007, at 5:38 PM, cstrato wrote:
>>>>
>>>>> Dear Benilton
>>>>>
>>>>> Thank you, now my package works.
>>>>>
>>>>> Do you have an explanation for my second problem:
>>>>>
>>>>> * Installing *source* package 'mytest' ...
>>>>> ** R
>>>>> ** save image
>>>>> Error in setMethod("export", "derivedClass",  
>>>>> export.derivedClass) :
>>>>>        no existing definition for function "export"
>>>>> Error: unable to load R code in package 'mytest'
>>>>> Execution halted
>>>>>
>>>>> What may be the reason for this error?
>>>>>
>>>>> Best regards
>>>>> Christian
>>>>>
>>>>>
>>
>>


From cstrato at aon.at  Sat Mar 17 00:43:52 2007
From: cstrato at aon.at (cstrato)
Date: Sat, 17 Mar 2007 00:43:52 +0100
Subject: [Rd] Problems with package containing S4 classes
In-Reply-To: <0173F567-3E02-422B-BE69-28A058DD8BF5@jhsph.edu>
References: <45FB045E.3090909@aon.at>
	<72DA1101-B6C5-4DB7-A9F8-2CC091D8AC7E@jhsph.edu>
	<45FB0E6D.3010803@aon.at>
	<D023A1FD-2388-40C3-AC7D-A20773326A62@jhsph.edu>
	<45FB1B9A.3040406@aon.at>
	<C92F4691-41B7-4881-B604-57E0BA978BE6@jhsph.edu>
	<45FB21C3.1050205@aon.at>
	<0173F567-3E02-422B-BE69-28A058DD8BF5@jhsph.edu>
Message-ID: <45FB2BB8.1080601@aon.at>

Thank you, I have already read the R-exts manual, but the collate field 
is optional.
Do you know a package which uses the Collate field so that I can study it?

Best regards
Christian

Benilton Carvalho wrote:
> The Collate field gives the order that the files are going to be 
> concatenated. If they're concatenated using the "wrong" order, your 
> installation might fail (for example, the generic is defined after the 
> method).
>
> A recommended source is the  "Writing R Extensions"
>
> http://cran.r-project.org/doc/manuals/R-exts.html
>
> Session 1.1.1 - The Description File (Writing R Extensions)
>
> says exactly what you shohuld know about the Collate field (and not 
> only that).
>
> b
>
> On Mar 16, 2007, at 7:01 PM, cstrato wrote:


From bcarvalh at jhsph.edu  Sat Mar 17 00:49:21 2007
From: bcarvalh at jhsph.edu (Benilton Carvalho)
Date: Fri, 16 Mar 2007 19:49:21 -0400
Subject: [Rd] Problems with package containing S4 classes
In-Reply-To: <45FB2BB8.1080601@aon.at>
References: <45FB045E.3090909@aon.at>
	<72DA1101-B6C5-4DB7-A9F8-2CC091D8AC7E@jhsph.edu>
	<45FB0E6D.3010803@aon.at>
	<D023A1FD-2388-40C3-AC7D-A20773326A62@jhsph.edu>
	<45FB1B9A.3040406@aon.at>
	<C92F4691-41B7-4881-B604-57E0BA978BE6@jhsph.edu>
	<45FB21C3.1050205@aon.at>
	<0173F567-3E02-422B-BE69-28A058DD8BF5@jhsph.edu>
	<45FB2BB8.1080601@aon.at>
Message-ID: <B8AC4754-A8CE-4066-9F84-3E85CE13CA14@jhsph.edu>

Biobase itself does.
b

On Mar 16, 2007, at 7:43 PM, cstrato wrote:

> Thank you, I have already read the R-exts manual, but the collate  
> field is optional.
> Do you know a package which uses the Collate field so that I can  
> study it?
>
> Best regards
> Christian
>
> Benilton Carvalho wrote:
>> The Collate field gives the order that the files are going to be  
>> concatenated. If they're concatenated using the "wrong" order,  
>> your installation might fail (for example, the generic is defined  
>> after the method).
>>
>> A recommended source is the  "Writing R Extensions"
>>
>> http://cran.r-project.org/doc/manuals/R-exts.html
>>
>> Session 1.1.1 - The Description File (Writing R Extensions)
>>
>> says exactly what you shohuld know about the Collate field (and  
>> not only that).
>>
>> b
>>
>> On Mar 16, 2007, at 7:01 PM, cstrato wrote:


From sfalcon at fhcrc.org  Sat Mar 17 01:14:05 2007
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Fri, 16 Mar 2007 17:14:05 -0700
Subject: [Rd] R 2.5.0 devel try issue in conjuntion with S4 method
	dispatch
In-Reply-To: <19990.89.62.105.96.1174089033.squirrel@gk.uu.epigenomics.net>
	(Matthias Burger's message of "17 Mar 2007 00:50:33 +0100")
References: <45F98B1D.2060501@epigenomics.com>
	<19990.89.62.105.96.1174089033.squirrel@gk.uu.epigenomics.net>
Message-ID: <m2ps783ewi.fsf@ziti.local>

"Matthias Burger" <matthias.burger at epigenomics.com> writes:
> Well, I understand I should have spent more time trimming my example
> to the minimal required code. Again this piece was copied & reduced.

No need to have done anything differently.  I commented on the code
in hopes that it might be helpful for others learning S4 stuff -- so I
think the discussion is useful even if it isn't your real code :-)

> The actual package uses a namespace which only exports the method but not
> the function.
> Using the .className extension scheme I can still get at the actual
> code at the R prompt via ':::'  which I find just handy.

If you switched to _className, then there would be no S3 confusion.
There are performance implications in doing things this way, but I
agree it is convenient.

Cheers,

+ seth

-- 
Seth Falcon | Computational Biology | Fred Hutchinson Cancer Research Center
http://bioconductor.org


From cstrato at aon.at  Sat Mar 17 01:16:57 2007
From: cstrato at aon.at (cstrato)
Date: Sat, 17 Mar 2007 01:16:57 +0100
Subject: [Rd] Problems with package containing S4 classes
In-Reply-To: <B8AC4754-A8CE-4066-9F84-3E85CE13CA14@jhsph.edu>
References: <45FB045E.3090909@aon.at>
	<72DA1101-B6C5-4DB7-A9F8-2CC091D8AC7E@jhsph.edu>
	<45FB0E6D.3010803@aon.at>
	<D023A1FD-2388-40C3-AC7D-A20773326A62@jhsph.edu>
	<45FB1B9A.3040406@aon.at>
	<C92F4691-41B7-4881-B604-57E0BA978BE6@jhsph.edu>
	<45FB21C3.1050205@aon.at>
	<0173F567-3E02-422B-BE69-28A058DD8BF5@jhsph.edu>
	<45FB2BB8.1080601@aon.at>
	<B8AC4754-A8CE-4066-9F84-3E85CE13CA14@jhsph.edu>
Message-ID: <45FB3379.8030001@aon.at>

I must have missed this, thank you.

Good night
Christian

Benilton Carvalho wrote:
> Biobase itself does.
> b
>
> On Mar 16, 2007, at 7:43 PM, cstrato wrote:
>
>> Thank you, I have already read the R-exts manual, but the collate 
>> field is optional.
>> Do you know a package which uses the Collate field so that I can 
>> study it?
>>
>> Best regards
>> Christian
>>
>> Benilton Carvalho wrote:
>>> The Collate field gives the order that the files are going to be 
>>> concatenated. If they're concatenated using the "wrong" order, your 
>>> installation might fail (for example, the generic is defined after 
>>> the method).
>>>
>>> A recommended source is the  "Writing R Extensions"
>>>
>>> http://cran.r-project.org/doc/manuals/R-exts.html
>>>
>>> Session 1.1.1 - The Description File (Writing R Extensions)
>>>
>>> says exactly what you shohuld know about the Collate field (and not 
>>> only that).
>>>
>>> b
>>>
>>> On Mar 16, 2007, at 7:01 PM, cstrato wrote:
>
>


From matthias.burger at epigenomics.com  Sat Mar 17 00:17:06 2007
From: matthias.burger at epigenomics.com (Matthias Burger)
Date: 17 Mar 2007 00:17:06 +0100
Subject: [Rd] R 2.5.0 devel try issue in conjuntion with S4 method
	dispatch
In-Reply-To: <45F98B1D.2060501@epigenomics.com>
References: <45F98B1D.2060501@epigenomics.com>
Message-ID: <26643.89.62.105.96.1174087026.squirrel@gk.uu.epigenomics.net>


Hi Seth,

>It isn't S4 specific.  The issue seems more about anonymous
>calls/functions.
>
>   ll = list()
>   ll[[1]] = function(x) stop("died")
>
>   v = try(do.call(ll[[1]], list(1)), silent=TRUE)
>   Error in as.list(call)[[1]] == "doTryCatch" :
>   	comparison (1) is possible only for atomic and list types
>   > v
>   Error: object "v" not found

>I don't fully understand why the call is being computed, but the
>following seems to get things going.
>
>+ seth

I applied your patch and the issues seems to be resolved.  Now I just wait
to see if all test case failures related to this disappear.

Thank you for your kind help!

  Matthias

-- 
Matthias Burger                     Project Manager/ Biostatistician
Epigenomics AG    Kleine Praesidentenstr. 1    10178 Berlin, Germany
phone:+49-30-24345-371                          fax:+49-30-24345-555
http://www.epigenomics.com           matthias.burger at epigenomics.com
--
Epigenomics AG Berlin           Amtsgericht Charlottenburg HRB 75861
Vorstand:   Geert Nygaard (CEO/Vorsitzender),  Dr. Kurt Berlin (CSO)
              Oliver Schacht PhD (CFO),  Christian Piepenbrock (COO)
Aufsichtsrat:   Prof. Dr. Dr. hc. Rolf Krebs (Chairman/Vorsitzender)


From p.dalgaard at biostat.ku.dk  Sat Mar 17 10:03:32 2007
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Sat, 17 Mar 2007 10:03:32 +0100
Subject: [Rd] R 2.5.0 devel try issue in conjuntion with S4
	method	dispatch
In-Reply-To: <26643.89.62.105.96.1174087026.squirrel@gk.uu.epigenomics.net>
References: <45F98B1D.2060501@epigenomics.com>
	<26643.89.62.105.96.1174087026.squirrel@gk.uu.epigenomics.net>
Message-ID: <45FBAEE4.7070908@biostat.ku.dk>

Matthias Burger wrote:
> Hi Seth,
>   
....

> I applied your patch and the issues seems to be resolved.  Now I just wait
> to see if all test case failures related to this disappear.
>
> Thank you for your kind help!
>
>   Matthias
>   
I have just committed my variation of Seth's patch, so please check the 
current r-devel too.


From ripley at stats.ox.ac.uk  Sat Mar 17 10:59:16 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 17 Mar 2007 09:59:16 +0000 (GMT)
Subject: [Rd] Periods in package names?
In-Reply-To: <59d7961d0703051300y38374e06jcbf241d7eb1bc9a@mail.gmail.com>
References: <59d7961d0703051300y38374e06jcbf241d7eb1bc9a@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0703170956550.24819@auk.stats>

On Mon, 5 Mar 2007, Henrik Bengtsson wrote:

> Hi,
>
> is it ok to have more than one period in a package name, e.g. aroma.light.bioc?
>
> I remember there was once a limitation/a recommendation that one
> should use at most one period in a package name.  I just browsed
> "Writing R Extensions" (for R v2.4.1) and scanned it for words
> "period" and "dot", and I cannot find this limitation anymore, but
> only:

It was dropped a while back: from src/gnuwin32/CHANGES for 2.3.0

   The restriction on the number of dots in a package name (which
   stemmed from an undocumented restriction in ld.exe) has been worked
   around.


> "The Package and Version fields give the name and the version of the
> package, respectively. The name should consist of letters, numbers,
> and the dot character and start with a letter. [...]"

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Sat Mar 17 11:42:32 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 17 Mar 2007 10:42:32 +0000 (GMT)
Subject: [Rd] Support for noarch packages in /usr/share/R/library
In-Reply-To: <1173816315.15673.6.camel@localhost.localdomain>
References: <1173816315.15673.6.camel@localhost.localdomain>
Message-ID: <Pine.LNX.4.64.0703141253321.18829@gannet.stats.ox.ac.uk>

There is nothing in the R definition of a package to indicate if it is 
architecture-specific or not.  Further, one version of a package might be, 
but an updated version might not (as has just happened with 'ifa').

Thus there are currently no 'noarch' R packages.

[For those who miss the subtleties, the installed versions of both the R 
files and the help files may depend on the OS, as could in principle the 
data files.  You need to read every file to find out.  This is not just 
about whether there is arch-specific compiled code.]

On Tue, 13 Mar 2007, Tom 'spot' Callaway wrote:

> As originally raised here:
> https://bugzilla.redhat.com/bugzilla/show_bug.cgi?id=231220
>
> It has been proposed that R should support noarch packages
> in /usr/share/R/library in addition to architecture specific packages
> in /usr/lib/R/library or /usr/lib64/R/library.

R supports libraries anywhere specified by the users, and this can be 
specified at site level.  So this seems to be a non-issue: R always has 
supported packages in /usr/share/R/library.

> For example, the mAr addon doesn't have any architecture specific bits.
> Strictly speaking, the Filesystem Hierarchy Standard says it doesn't
> belong in /usr/lib, but rather, /usr/share.

I don't read it as saying so, but it is so badly written that it is 
subject to many interpretations.

> Ideas on the best way to resolve this would be greatly appreciated.

It really only seems to occur if people want to re-package R packages as 
RPMs and use a single file system for multiple architectures.  For those 
(rare) people, setting the default libraries in (say) 
R_HOME/etc/Renviron.site seems a complete solution.   We could add
${sharedir}/R/library to the default .libPaths(), but it does not seem 
worth adding something that would not be tested regularly and can so 
easily be done by the end user.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From gavin.simpson at ucl.ac.uk  Sat Mar 17 14:02:29 2007
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Sat, 17 Mar 2007 13:02:29 +0000
Subject: [Rd] Wishlist: Make screeplot() a generic (PR#9541)
In-Reply-To: <20070302165311.447935AD11@slim.kubism.ku.dk>
References: <20070302165311.447935AD11@slim.kubism.ku.dk>
Message-ID: <1174136549.3146.16.camel@dhcppc2.my.nat.localnet>

Dear List

Having not received any comments for or against my proposal to make
screeplot() a generic function, I found some time to make the relevant
changes to the svn trunk repository (revision 40848).

Please find attached a patch against the R svn trunk sources including
changes to the relevant help files and NAMESPACE. This builds and passes
make check-devel out of the box on my FC4 machine.

I took the option of making the default method for screeplot the
existing function and the plot methods for princomp and prcomp both call
screeplot.default directly. This, I hope, preserves the current
behaviour and should be backwards compatible with
code/packages/examples/docs that use these functions.

One alternative would be to have explicit methods for classes "prcomp"
and "princomp" that extract the relevant variances and pass on to
screeplot.default for plotting. If this is preferred I can provide a
patch for this scenario for consideration?

All the best,

Gav

On Fri, 2007-03-02 at 17:53 +0100, gavin.simpson at ucl.ac.uk wrote:
> Full_Name: Gavin Simpson
> Version: 2.5.0
> OS: Linux (FC5)
> Submission from: (NULL) (128.40.33.76)
> 
> 
> Screeplots are a common plot-type used to interpret the results of various
> ordination methods and other techniques. A number of packages include ordination
> techniques not included in a standard R installation. screeplot() works for
> princomp and prcomp objects, but not for these other techniques as it was not
> designed to do so. The current situation means, for example, that I have called
> a function Screeplot() in one of my packages, but it would be easier for users
> if they only had to remember to use screeplot() to generate a screeplot.
> 
> I would like to request that screeplot be made generic and methods for prcomp
> and princomp added to R devel. This way, package authors can provide screeplot
> methods for their functions as appropriate.
> 
> I have taken a look at the sources for R devel (from the SVN repository) in file
> princomp-add.R and prcomp.R and it looks a relatively simple change to make
> screeplot generic.
> 
> I would be happy to provide patches and documentation if R Core were interested
> in making this change - I haven't done this yet as I don't want to spend time
> doing something that might not be acceptable to R core in general.
> 
> Many thanks,
> 
> G

-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
Gavin Simpson                     [t] +44 (0)20 7679 0522
ECRC                              [f] +44 (0)20 7679 0565
UCL Department of Geography
Pearson Building                  [e] gavin.simpsonATNOSPAMucl.ac.uk
Gower Street
London, UK                        [w] http://www.ucl.ac.uk/~ucfagls/
WC1E 6BT                          [w] http://www.freshwaters.org.uk/
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
-------------- next part --------------
A non-text attachment was scrubbed...
Name: screeplot.patch
Type: text/x-patch
Size: 3978 bytes
Desc: not available
Url : https://stat.ethz.ch/pipermail/r-devel/attachments/20070317/46171f2e/attachment.bin 

From sfalcon at fhcrc.org  Sat Mar 17 16:11:37 2007
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Sat, 17 Mar 2007 08:11:37 -0700
Subject: [Rd] R 2.5.0 devel try issue in conjuntion with S4
	method	dispatch
In-Reply-To: <45FBAEE4.7070908@biostat.ku.dk> (Peter Dalgaard's message of
	"Sat, 17 Mar 2007 10:03:32 +0100")
References: <45F98B1D.2060501@epigenomics.com>
	<26643.89.62.105.96.1174087026.squirrel@gk.uu.epigenomics.net>
	<45FBAEE4.7070908@biostat.ku.dk>
Message-ID: <m28xdv3nx2.fsf@ziti.local>

Peter Dalgaard <p.dalgaard at biostat.ku.dk> writes:
> I have just committed my variation of Seth's patch, so please check the 
> current r-devel too.

Thanks, Peter.  And I agree that your variation is cleaner.

-- 
Seth Falcon | Computational Biology | Fred Hutchinson Cancer Research Center
http://bioconductor.org


From maechler at stat.math.ethz.ch  Sat Mar 17 20:40:11 2007
From: maechler at stat.math.ethz.ch (maechler at stat.math.ethz.ch)
Date: Sat, 17 Mar 2007 20:40:11 +0100 (CET)
Subject: [Rd] Wishlist: Make screeplot() a generic (PR#9541)
Message-ID: <20070317194011.42B3E5AD20@slim.kubism.ku.dk>

>>>>> "GS" == Gavin Simpson <gavin.simpson at ucl.ac.uk>
>>>>>     on Sat, 17 Mar 2007 13:02:29 +0000 writes:

    GS> Dear List
    GS> Having not received any comments for or against my proposal to make
    GS> screeplot() a generic function, I found some time to make the relevant
    GS> changes to the svn trunk repository (revision 40848).

    GS> Please find attached a patch against the R svn trunk sources including
    GS> changes to the relevant help files and NAMESPACE. This builds and passes
    GS> make check-devel out of the box on my FC4 machine.

also for me;
thank you Gavin!

    GS> I took the option of making the default method for screeplot the
    GS> existing function and the plot methods for princomp and prcomp both call
    GS> screeplot.default directly. This, I hope, preserves the current
    GS> behaviour and should be backwards compatible with
    GS> code/packages/examples/docs that use these functions.

[[it is still a matter of taste if  screeplot.default should be
  called explicitly, but since this is in the same namespace, it
  works nicely and slightly more efficiently]]

I have committed your patches (+ a NEWS entry) as is, to be
there early enough before beta stage.



    GS> One alternative would be to have explicit methods for classes "prcomp"
    GS> and "princomp" that extract the relevant variances and pass on to
    GS> screeplot.default for plotting. If this is preferred I can provide a
    GS> patch for this scenario for consideration?

I'd prefer it in general, but not in this case where the plot.*
method for these already use screeplot();  still another matter
of taste.

Thanks for your contribution.

Martin


From spencer.graves at pdf.com  Sun Mar 18 06:23:17 2007
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sat, 17 Mar 2007 22:23:17 -0700
Subject: [Rd] eigen returns NAs from a real matrix
Message-ID: <45FCCCC5.3060806@pdf.com>

Hi, All: 

      Attached please find a symmetric, indefinite matrix for which 
'eigen(...)$vectors' included NAs: 

 > load("eigenBug.Rdata")
 > sum(is.na(eigen(eigenBug)$vectors))
[1] 5670
 > sessioninfo()
Error: could not find function "sessioninfo"
 > sessionInfo()
R version 2.4.1 (2006-12-18)
i386-pc-mingw32

locale:
LC_COLLATE=English_United States.1252;LC_CTYPE=English_United 
States.1252;LC_MONETARY=English_United 
States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252

attached base packages:
[1] "stats"     "graphics"  "grDevices" "utils"     "datasets"  "methods" 
[7] "base"    

      Using EISPACK does NOT return NAs: 
 > sum(is.na(eigen(eigenBug, EISPACK=TRUE)$vectors))
[1] 0


      I traced the problem to the following line in 'eigen': 

            z <- if (!complex.x)
                .Call("La_rs", x, only.values, PACKAGE = "base")


      Comments?
      Best Wishes,
      Spencer Graves


From ripley at stats.ox.ac.uk  Sun Mar 18 07:51:58 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 18 Mar 2007 06:51:58 +0000 (GMT)
Subject: [Rd] eigen returns NAs from a real matrix
In-Reply-To: <45FCCCC5.3060806@pdf.com>
References: <45FCCCC5.3060806@pdf.com>
Message-ID: <Pine.LNX.4.64.0703180651080.24029@gannet.stats.ox.ac.uk>

On Sat, 17 Mar 2007, Spencer Graves wrote:

> Hi, All:
>     Attached please find a symmetric, indefinite matrix for which 
> 'eigen(...)$vectors' included NAs: 
>> load("eigenBug.Rdata")
>> sum(is.na(eigen(eigenBug)$vectors))
> [1] 5670
>> sessioninfo()
> Error: could not find function "sessioninfo"
>> sessionInfo()
> R version 2.4.1 (2006-12-18)
> i386-pc-mingw32
>
> locale:
> LC_COLLATE=English_United States.1252;LC_CTYPE=English_United 
> States.1252;LC_MONETARY=English_United 
> States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252
>
> attached base packages:
> [1] "stats"     "graphics"  "grDevices" "utils"     "datasets"  "methods" [7] 
> "base"
>     Using EISPACK does NOT return NAs: > sum(is.na(eigen(eigenBug, 
> EISPACK=TRUE)$vectors))
> [1] 0
>
>
>     I traced the problem to the following line in 'eigen':
>           z <- if (!complex.x)
>               .Call("La_rs", x, only.values, PACKAGE = "base")
>
>
>     Comments?

Nothing appeared as an attachment.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ross at biostat.ucsf.edu  Sun Mar 18 20:39:14 2007
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Sun, 18 Mar 2007 12:39:14 -0700
Subject: [Rd] R CMD check ignores .Rbuildignore?
Message-ID: <20070318193913.GM30753@wheat.betterworld.us>

The contents of .Rbuildignore seems to affect
R CMD build
but not 
R CMD check.

I'm using R 2.4.0 on Debian.

Is my understanding correct?  And is there anything I can do about it?
In my case, some of the excluded files contain references to other
libraries, so linking fails under R CMD check.  I realize I could add
the library to the build (with Makevars, I guess), but I do not want
to introduce the dependency.

Thanks.
Ross


From maechler at stat.math.ethz.ch  Mon Mar 19 11:33:37 2007
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 19 Mar 2007 11:33:37 +0100
Subject: [Rd] R CMD check ignores .Rbuildignore?
In-Reply-To: <20070318193913.GM30753@wheat.betterworld.us>
References: <20070318193913.GM30753@wheat.betterworld.us>
Message-ID: <17918.26369.732045.755412@stat.math.ethz.ch>

>>>>> "RossB" == Ross Boylan <ross at biostat.ucsf.edu>
>>>>>     on Sun, 18 Mar 2007 12:39:14 -0700 writes:

    RossB> The contents of .Rbuildignore seems to affect
    RossB> R CMD build
    RossB> but not 
    RossB> R CMD check.

    RossB> I'm using R 2.4.0 on Debian.

    RossB> Is my understanding correct?  

yes.  That's why it's called 'buildignore'.
It's a big feature for me as package developer:

E.g., I can have extra tests (which e.g. only apply on my
specific platform) in addition to those which are use when the
package is built (to be checked on all possible platforms).

Some have proposed to additionally define a '.Rcheckignore' 
but they haven't been convincing enough.

    RossB> And is there anything I can do about it?

"First build, then check" is one way;
Something which is recommended anyway in some cases,
e.g., if you have an (Sweave - based) vignette.

    RossB> In my case, some of the excluded files contain references to other
    RossB> libraries, so linking fails under R CMD check.  I realize I could add
    RossB> the library to the build (with Makevars, I guess), but I do not want
    RossB> to introduce the dependency.

It depends on the circumstances on how I would solve this
problem.... 
[Why have these files as part of the package sources at all?]

Regads,
Martin Maechler, ETH Zurich


From maechler at stat.math.ethz.ch  Mon Mar 19 11:48:39 2007
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 19 Mar 2007 11:48:39 +0100
Subject: [Rd] eigen returns NAs from a real matrix
In-Reply-To: <Pine.LNX.4.64.0703180651080.24029@gannet.stats.ox.ac.uk>
References: <45FCCCC5.3060806@pdf.com>
	<Pine.LNX.4.64.0703180651080.24029@gannet.stats.ox.ac.uk>
Message-ID: <17918.27271.48263.371325@stat.math.ethz.ch>

>>>>> "BDR" == Prof Brian Ripley <ripley at stats.ox.ac.uk>
>>>>>     on Sun, 18 Mar 2007 06:51:58 +0000 (GMT) writes:

    BDR> On Sat, 17 Mar 2007, Spencer Graves wrote:
    >> Hi, All:
    >> Attached please find a symmetric, indefinite matrix for which 
    >> 'eigen(...)$vectors' included NAs: 
    >>> load("eigenBug.Rdata")
    >>> sum(is.na(eigen(eigenBug)$vectors))
    >> [1] 5670
    >>> sessioninfo()
    >> Error: could not find function "sessioninfo"
    >>> sessionInfo()
    >> R version 2.4.1 (2006-12-18)
    >> i386-pc-mingw32
    >> 
    >> locale:
    >> LC_COLLATE=English_United States.1252;LC_CTYPE=English_United 
    >> States.1252;LC_MONETARY=English_United 
    >> States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252
    >> 
    >> attached base packages:
    >> [1] "stats"     "graphics"  "grDevices" "utils"     "datasets"  "methods" [7] 
    >> "base"
    >> Using EISPACK does NOT return NAs: > sum(is.na(eigen(eigenBug, 
    >> EISPACK=TRUE)$vectors))
    >> [1] 0
    >> 
    >> 
    >> I traced the problem to the following line in 'eigen':
    >> z <- if (!complex.x)
    >> .Call("La_rs", x, only.values, PACKAGE = "base")
    >> 
    >> 
    >> Comments?

    BDR> Nothing appeared as an attachment.

it was a zip file which is not among the allowed ones
(.tar.gz / *.tgz  would work).

Spencer has also contacted me in private,
so you now can use something like :

  F <- tempfile()
  download.file("ftp://stat.ethz.ch/U/maechler/R/eigenBug.Rdata", F)
  load(F)
  str(eigenBug)# tons of dinames; get rid of them:
  M <- unname(eigenBug)

  sum(is.na(eigen(M)$vectors))
  # 0 (for MM, on Linux);  '5670' for Spencer
  sum(is.na(eigen(M, EISPACK=TRUE)$vectors))
  # 0

  ## Guess about what kind of BLAS/Lapack I'm using :
  file.info(list.files(R.home("lib"), full=TRUE))[,1:3]
  ##                                        size isdir mode
  ## ....64-linux-inst/lib/libRblas.so    422558 FALSE  755
  ## ....64-linux-inst/lib/libRlapack.so 3144596 FALSE  755


I.e. I don't get any NA's
which shows to me that the bug is most probably in the Lapack -
Version that Spencer's version of R is linked against.

Martin Maechler, ETH Zurich


From felix at nfrac.org  Mon Mar 19 06:32:39 2007
From: felix at nfrac.org (felix at nfrac.org)
Date: Mon, 19 Mar 2007 06:32:39 +0100 (CET)
Subject: [Rd] R4.1: seq.POSIXt, tz="AEST" (PR#9572)
Message-ID: <20070319053239.6FBA75AC20@slim.kubism.ku.dk>

Times from seq.POSIXt come out wrong in AEST timezone around Feb 29 every
leap year before 1970 (on Windows XP).

According to help(DateTimeClasses), this is handled by "our own C code".

> x <- as.POSIXct("1968-02-27") # tz="AEST"
> x.gmt <- as.POSIXct("1968-02-27", tz="GMT")
> data.frame(
     GMT=seq(x.gmt, by="day", length=8),
     byday=seq(x, by="day", length=8),
     byDST=seq(x, by="DSTday", length=8))
         GMT      byday      byDST
1 1968-02-27 1968-02-27 1968-02-27
2 1968-02-28 1968-02-28 1968-02-28
3 1968-02-29 1968-03-01 1968-03-02
4 1968-03-01 1968-03-02 1968-03-02
5 1968-03-02 1968-03-02 1968-03-02
6 1968-03-03 1968-03-03 1968-03-03
7 1968-03-04 1968-03-04 1968-03-04
8 1968-03-05 1968-03-05 1968-03-05

> R.version
               _
platform       i386-pc-mingw32
arch           i386
os             mingw32
system         i386, mingw32
status
major          2
minor          4.1
year           2006
month          12
day            18
svn rev        40228
language       R
version.string R version 2.4.1 (2006-12-18)



-- 
Felix Andrews / $B0BJ!N)(B
Beijing Bag, Locked Bag 40, Kingston ACT 2604
Building 48A, Linnaeus Way, The Australian National University ACT 0200
Australia
http://www.neurofractal.org/felix/
mailto:felix at nfrac.org
voice:+86_1051404394 (in China)
mobile:+86_13522529265 (in China)
mobile:+61_410400963 (in Australia)
xmpp:foolish.android at gmail.com
3358 543D AAC6 22C2 D336  80D9 360B 72DD 3E4C F5D8

	[[alternative HTML version deleted]]


From ripley at stats.ox.ac.uk  Mon Mar 19 13:03:42 2007
From: ripley at stats.ox.ac.uk (ripley at stats.ox.ac.uk)
Date: Mon, 19 Mar 2007 13:03:42 +0100 (CET)
Subject: [Rd] R4.1: seq.POSIXt, tz="AEST" (PR#9572)
Message-ID: <20070319120342.4FDD05AC28@slim.kubism.ku.dk>

Hmm, AEST is not a valid time zone on Windows.
See ?as.POSIXlt for one of several places where this is documented.

But in any case, the underlying problem is in the OS, and we only try to 
work around it to the best of our knowledge (and that excludes 
undocumented time zones).


On Mon, 19 Mar 2007, felix at nfrac.org wrote:

> Times from seq.POSIXt come out wrong in AEST timezone around Feb 29 every
> leap year before 1970 (on Windows XP).
>
> According to help(DateTimeClasses), this is handled by "our own C code".
>
>> x <- as.POSIXct("1968-02-27") # tz="AEST"
>> x.gmt <- as.POSIXct("1968-02-27", tz="GMT")
>> data.frame(
>     GMT=seq(x.gmt, by="day", length=8),
>     byday=seq(x, by="day", length=8),
>     byDST=seq(x, by="DSTday", length=8))
>         GMT      byday      byDST
> 1 1968-02-27 1968-02-27 1968-02-27
> 2 1968-02-28 1968-02-28 1968-02-28
> 3 1968-02-29 1968-03-01 1968-03-02
> 4 1968-03-01 1968-03-02 1968-03-02
> 5 1968-03-02 1968-03-02 1968-03-02
> 6 1968-03-03 1968-03-03 1968-03-03
> 7 1968-03-04 1968-03-04 1968-03-04
> 8 1968-03-05 1968-03-05 1968-03-05
>
>> R.version
>               _
> platform       i386-pc-mingw32
> arch           i386
> os             mingw32
> system         i386, mingw32
> status
> major          2
> minor          4.1
> year           2006
> month          12
> day            18
> svn rev        40228
> language       R
> version.string R version 2.4.1 (2006-12-18)
>
>
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From p.dalgaard at biostat.ku.dk  Mon Mar 19 13:27:22 2007
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Mon, 19 Mar 2007 13:27:22 +0100
Subject: [Rd] R 2.5.0 slated for April 24
Message-ID: <x2vegxifkl.fsf@viggo.kubism.ku.dk>


This is to announce that we plan to release R version 2.5.0 on Tuesday
April 24, 2007. The following information is mainly for developers,
package maintainers and repository maintainers. 

The planned procedure is

March 27: "Grand Feature" Freeze  2.5.0 alpha
April 10: Feature Freeze          2.5.0 beta
April 17: Code Freeze             2.5.0 RC
April 24: Release                 2.5.0

GFF: No major restructuring past this point
FF:  Feature set complete, only bugfixing from now on
CF:  Only critical bugfixes and platform build issues

Maintainers of recommended packages should notice that as they become
part of the final R tarball, we expect them to follow a similar freeze
pattern (and beware of potential CRAN delays, so please do not cut it
too close to the deadlines).

Notice that the main structural discontinuities occurs at GFF:

The SVN repository is affected as follows 
    The trunk version is set to "2.6.0 Under development (unstable)".
    A new branch, R-2-5-branch is created.

This also implies new version numbers for "r-devel" and
"r-release-branch", in the sense of

http://developer.r-project.org/SVNtips.html  

Also, "r-release-branch" needs to have its tag updated. 

Repository maintainers may need to revise directory structures
accordingly.

"R 2.4.1 Patched" will be closed to further development at GFF (as all
the release branches, it can be reopened if the need arises, we just
don't anticipate such a need.)

The source alpha/beta/RC tarballs will be made available daily
(barring build troubles) by a cron job running at 5AM CET, and the
tarballs can be picked up at 

http://cran.r-project.org/src/base-prerelease/

a little later. 

The various freeze points are marked by changes to the VERSION file
this is also done automatically by a cron job which runs just after
midnight on the relevant days.


-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From j.van_den_hoff at fzd.de  Mon Mar 19 13:56:45 2007
From: j.van_den_hoff at fzd.de (Joerg van den Hoff)
Date: Mon, 19 Mar 2007 13:56:45 +0100
Subject: [Rd] R CMD CHECK problem
Message-ID: <20070319125645.GA15395@marco.fz-rossendorf.de>


I tried two times to get some help for this from the help list but to no avail. I hope,
it's OK to post this here (once...). if not, please ignore (the rest of) this
mail:

for one of my private packages R CMD CHECK {package} givves me annoying warnings
due to 'missing links' in the manpages for functions from another private
package mentioned in the manpages. specifically, I have two packages, the first
(named `pkc') depending on the second one (named `roiutils'). The source code
and DESCRIPTION files describes the dependency as it should be, I think
('Imports', `require'). but if I run

R CMD CHECK pkc 

I get "significant warnings" related to missing links (refering to functions
from the second package) in the manpages of the first package as can be
seen below. despite the warnings, after installing the two packages the help
system works just fine including the cross-references.

my question:
why is it, that R CMD CHECK is complaining?  what am I doing wrong?
how have I to specify the links in the manpages to tell CHECK that
everything is basically OK? 

========================CUT====================================
* checking for working latex ... OK
* using log directory '/Users/vdh/rfiles/Rlibrary/.check/pkc.Rcheck'
* using R version 2.4.0 (2006-10-03)
* checking for file 'pkc/DESCRIPTION' ... OK
* this is package 'pkc' version '1.1'
* checking package dependencies ... OK
* checking if this is a source package ... OK
* checking whether package 'pkc' can be installed ... WARNING
Found the following significant warnings:
       missing link(s):  readroi readroi readroi figure readroi conv3exmodel readroi
       missing link(s):  figure readroi
* checking package directory ... OK
* checking for portable file names ... OK
* checking for sufficient/correct file permissions ... OK
* checking DESCRIPTION meta-information ... OK
* checking top-level files ... OK
* checking index information ... OK
* checking package subdirectories ... OK
* checking R files for syntax errors ... OK
* checking R files for non-ASCII characters ... OK
* checking whether the package can be loaded ... OK
* checking whether the package can be loaded with stated dependencies ... OK
* checking whether the name space can be loaded with stated dependencies ... OK
* checking S3 generic/method consistency ... OK
* checking replacement functions ... OK
* checking foreign function calls ... OK
* checking R code for possible problems ... OK
* checking Rd files ... WARNING
Rd files with unknown sections:
  /Users/vdh/rfiles/Rlibrary/pkc/man/fitdemo.Rd: example

See the chapter 'Writing R documentation files' in manual 'Writing R
Extensions'.
* checking Rd cross-references ... WARNING
Missing link(s) in documentation object 'compfit.Rd':
  readroi readroi readroi figure readroi conv3exmodel readroi

Missing link(s) in documentation object 'exp3fit.Rd':
  figure readroi
========================CUT====================================


any hints appreciated,

joerg


From murdoch at stats.uwo.ca  Mon Mar 19 14:01:39 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Mon, 19 Mar 2007 09:01:39 -0400
Subject: [Rd] eigen returns NAs from a real matrix
In-Reply-To: <17918.27271.48263.371325@stat.math.ethz.ch>
References: <45FCCCC5.3060806@pdf.com>	<Pine.LNX.4.64.0703180651080.24029@gannet.stats.ox.ac.uk>
	<17918.27271.48263.371325@stat.math.ethz.ch>
Message-ID: <45FE89B3.5050505@stats.uwo.ca>

On 3/19/2007 6:48 AM, Martin Maechler wrote:
>>>>>> "BDR" == Prof Brian Ripley <ripley at stats.ox.ac.uk>
>>>>>>     on Sun, 18 Mar 2007 06:51:58 +0000 (GMT) writes:
> 
>     BDR> On Sat, 17 Mar 2007, Spencer Graves wrote:
>     >> Hi, All:
>     >> Attached please find a symmetric, indefinite matrix for which 
>     >> 'eigen(...)$vectors' included NAs: 
>     >>> load("eigenBug.Rdata")
>     >>> sum(is.na(eigen(eigenBug)$vectors))
>     >> [1] 5670
>     >>> sessioninfo()
>     >> Error: could not find function "sessioninfo"
>     >>> sessionInfo()
>     >> R version 2.4.1 (2006-12-18)
>     >> i386-pc-mingw32
>     >> 
>     >> locale:
>     >> LC_COLLATE=English_United States.1252;LC_CTYPE=English_United 
>     >> States.1252;LC_MONETARY=English_United 
>     >> States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252
>     >> 
>     >> attached base packages:
>     >> [1] "stats"     "graphics"  "grDevices" "utils"     "datasets"  "methods" [7] 
>     >> "base"
>     >> Using EISPACK does NOT return NAs: > sum(is.na(eigen(eigenBug, 
>     >> EISPACK=TRUE)$vectors))
>     >> [1] 0
>     >> 
>     >> 
>     >> I traced the problem to the following line in 'eigen':
>     >> z <- if (!complex.x)
>     >> .Call("La_rs", x, only.values, PACKAGE = "base")
>     >> 
>     >> 
>     >> Comments?
> 
>     BDR> Nothing appeared as an attachment.
> 
> it was a zip file which is not among the allowed ones
> (.tar.gz / *.tgz  would work).
> 
> Spencer has also contacted me in private,
> so you now can use something like :
> 
>   F <- tempfile()
>   download.file("ftp://stat.ethz.ch/U/maechler/R/eigenBug.Rdata", F)
>   load(F)

This is unrelated to Spencer's problem, but this sequence failed for me. 
  By default it will treat the file as a text file, and convert EOL 
markers for Windows.  Adding "mode='wb'" to the download.file() call is 
necessary.

>   str(eigenBug)# tons of dinames; get rid of them:
>   M <- unname(eigenBug)
> 
>   sum(is.na(eigen(M)$vectors))
>   # 0 (for MM, on Linux);  '5670' for Spencer

I get the same as Spencer in 2.4.1, but zero in R-devel, in Windows.  I 
haven't tried R-patched yet:  there were network problems here this 
morning, and the build failed.

Duncan Murdoch

>   sum(is.na(eigen(M, EISPACK=TRUE)$vectors))
>   # 0
> 
>   ## Guess about what kind of BLAS/Lapack I'm using :
>   file.info(list.files(R.home("lib"), full=TRUE))[,1:3]
>   ##                                        size isdir mode
>   ## ....64-linux-inst/lib/libRblas.so    422558 FALSE  755
>   ## ....64-linux-inst/lib/libRlapack.so 3144596 FALSE  755
> 
> 
> I.e. I don't get any NA's
> which shows to me that the bug is most probably in the Lapack -
> Version that Spencer's version of R is linked against.
> 
> Martin Maechler, ETH Zurich
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From maechler at stat.math.ethz.ch  Mon Mar 19 14:12:55 2007
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 19 Mar 2007 14:12:55 +0100
Subject: [Rd] eigen returns NAs from a real matrix
In-Reply-To: <45FE89B3.5050505@stats.uwo.ca>
References: <45FCCCC5.3060806@pdf.com>
	<Pine.LNX.4.64.0703180651080.24029@gannet.stats.ox.ac.uk>
	<17918.27271.48263.371325@stat.math.ethz.ch>
	<45FE89B3.5050505@stats.uwo.ca>
Message-ID: <17918.35927.594199.926088@stat.math.ethz.ch>

>>>>> "Duncan" == Duncan Murdoch <murdoch at stats.uwo.ca>
>>>>>     on Mon, 19 Mar 2007 09:01:39 -0400 writes:

    Duncan> On 3/19/2007 6:48 AM, Martin Maechler wrote:
    >>>>>>> "BDR" == Prof Brian Ripley <ripley at stats.ox.ac.uk>
    >>>>>>> on Sun, 18 Mar 2007 06:51:58 +0000 (GMT) writes:
    >> 
    BDR> On Sat, 17 Mar 2007, Spencer Graves wrote:
    >> >> Hi, All:
    >> >> Attached please find a symmetric, indefinite matrix for which 
    >> >> 'eigen(...)$vectors' included NAs: 
    >> >>> load("eigenBug.Rdata")
    >> >>> sum(is.na(eigen(eigenBug)$vectors))
    >> >> [1] 5670
    >> >>> sessioninfo()
    >> >> Error: could not find function "sessioninfo"
    >> >>> sessionInfo()
    >> >> R version 2.4.1 (2006-12-18)
    >> >> i386-pc-mingw32
    >> >> 
    >> >> locale:
    >> >> LC_COLLATE=English_United States.1252;LC_CTYPE=English_United 
    >> >> States.1252;LC_MONETARY=English_United 
    >> >> States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252
    >> >> 
    >> >> attached base packages:
    >> >> [1] "stats"     "graphics"  "grDevices" "utils"     "datasets"  "methods" [7] 
    >> >> "base"
    >> >> Using EISPACK does NOT return NAs: > sum(is.na(eigen(eigenBug, 
    >> >> EISPACK=TRUE)$vectors))
    >> >> [1] 0
    >> >> 
    >> >> 
    >> >> I traced the problem to the following line in 'eigen':
    >> >> z <- if (!complex.x)
    >> >> .Call("La_rs", x, only.values, PACKAGE = "base")
    >> >> 
    >> >> 
    >> >> Comments?
    >> 
    BDR> Nothing appeared as an attachment.
    >> 
    >> it was a zip file which is not among the allowed ones
    >> (.tar.gz / *.tgz  would work).
    >> 
    >> Spencer has also contacted me in private,
    >> so you now can use something like :
    >> 
    >> F <- tempfile()
    >> download.file("ftp://stat.ethz.ch/U/maechler/R/eigenBug.Rdata", F)
    >> load(F)

    Duncan> This is unrelated to Spencer's problem, but this
    Duncan> sequence failed for me.

    Duncan> By default it will treat the file as a text file,
    Duncan> and convert EOL markers for Windows.  Adding
    Duncan> "mode='wb'" to the download.file() call is necessary.

ok;  Thank you, Duncan.

{For me, that's yet another reason why I think it would be  ``nice''
 if both  load() and source()  would work with general
 connections the same way as read.table(), and I could just say

     load("ftp://stat.ethz.ch/U/maechler/R/eigenBug.Rdata")
}

    >> str(eigenBug)# tons of dinames; get rid of them:
    >> M <- unname(eigenBug)
    >> 
    >> sum(is.na(eigen(M)$vectors))
    >> # 0 (for MM, on Linux);  '5670' for Spencer

    Duncan> I get the same as Spencer in 2.4.1, but zero in
    Duncan> R-devel, in Windows. 

ahh, that's good news.

Maybe Spencer could install a revcent version R-devel on his
Windows machine, and try the example?


    Duncan> I haven't tried R-patched yet: there were network
    Duncan> problems here this morning, and the build failed.

    Duncan> Duncan Murdoch

    >> sum(is.na(eigen(M, EISPACK=TRUE)$vectors))
    >> # 0
    >> 
    >> ## Guess about what kind of BLAS/Lapack I'm using :
    >> file.info(list.files(R.home("lib"), full=TRUE))[,1:3]
    >> ##                                        size isdir mode
    >> ## ....64-linux-inst/lib/libRblas.so    422558 FALSE  755
    >> ## ....64-linux-inst/lib/libRlapack.so 3144596 FALSE  755
    >> 
    >> 
    >> I.e. I don't get any NA's
    >> which shows to me that the bug is most probably in the Lapack -
    >> Version that Spencer's version of R is linked against.
    >> 
    >> Martin Maechler, ETH Zurich


From ligges at statistik.uni-dortmund.de  Mon Mar 19 14:13:43 2007
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 19 Mar 2007 14:13:43 +0100
Subject: [Rd] R CMD CHECK problem
In-Reply-To: <20070319125645.GA15395@marco.fz-rossendorf.de>
References: <20070319125645.GA15395@marco.fz-rossendorf.de>
Message-ID: <45FE8C87.1050101@statistik.uni-dortmund.de>



Joerg van den Hoff wrote:
> I tried two times to get some help for this from the help list but to no avail. I hope,
> it's OK to post this here (once...). if not, please ignore (the rest of) this
> mail:
> 
> for one of my private packages R CMD CHECK {package} givves me annoying warnings
> due to 'missing links' in the manpages for functions from another private
> package mentioned in the manpages. specifically, I have two packages, the first
> (named `pkc') depending on the second one (named `roiutils'). The source code
> and DESCRIPTION files describes the dependency as it should be, I think
> ('Imports', `require'). but if I run
> 
> R CMD CHECK pkc 
> 
> I get "significant warnings" related to missing links (refering to functions
> from the second package) in the manpages of the first package as can be
> seen below. despite the warnings, after installing the two packages the help
> system works just fine including the cross-references.
> 
> my question:
> why is it, that R CMD CHECK is complaining?  what am I doing wrong?
> how have I to specify the links in the manpages to tell CHECK that
> everything is basically OK? 


Specify links in the form \link[roiutils]{readroi} as the Writing R 
Extension manual suggests.

Uwe Ligges


> ========================CUT====================================
> * checking for working latex ... OK
> * using log directory '/Users/vdh/rfiles/Rlibrary/.check/pkc.Rcheck'
> * using R version 2.4.0 (2006-10-03)
> * checking for file 'pkc/DESCRIPTION' ... OK
> * this is package 'pkc' version '1.1'
> * checking package dependencies ... OK
> * checking if this is a source package ... OK
> * checking whether package 'pkc' can be installed ... WARNING
> Found the following significant warnings:
>        missing link(s):  readroi readroi readroi figure readroi conv3exmodel readroi
>        missing link(s):  figure readroi
> * checking package directory ... OK
> * checking for portable file names ... OK
> * checking for sufficient/correct file permissions ... OK
> * checking DESCRIPTION meta-information ... OK
> * checking top-level files ... OK
> * checking index information ... OK
> * checking package subdirectories ... OK
> * checking R files for syntax errors ... OK
> * checking R files for non-ASCII characters ... OK
> * checking whether the package can be loaded ... OK
> * checking whether the package can be loaded with stated dependencies ... OK
> * checking whether the name space can be loaded with stated dependencies ... OK
> * checking S3 generic/method consistency ... OK
> * checking replacement functions ... OK
> * checking foreign function calls ... OK
> * checking R code for possible problems ... OK
> * checking Rd files ... WARNING
> Rd files with unknown sections:
>   /Users/vdh/rfiles/Rlibrary/pkc/man/fitdemo.Rd: example
> 
> See the chapter 'Writing R documentation files' in manual 'Writing R
> Extensions'.
> * checking Rd cross-references ... WARNING
> Missing link(s) in documentation object 'compfit.Rd':
>   readroi readroi readroi figure readroi conv3exmodel readroi
> 
> Missing link(s) in documentation object 'exp3fit.Rd':
>   figure readroi
> ========================CUT====================================
> 
> 
> any hints appreciated,
> 
> joerg
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From murdoch at stats.uwo.ca  Mon Mar 19 14:33:26 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Mon, 19 Mar 2007 09:33:26 -0400
Subject: [Rd] eigen returns NAs from a real matrix
In-Reply-To: <17918.35927.594199.926088@stat.math.ethz.ch>
References: <45FCCCC5.3060806@pdf.com>	<Pine.LNX.4.64.0703180651080.24029@gannet.stats.ox.ac.uk>	<17918.27271.48263.371325@stat.math.ethz.ch>	<45FE89B3.5050505@stats.uwo.ca>
	<17918.35927.594199.926088@stat.math.ethz.ch>
Message-ID: <45FE9126.8030603@stats.uwo.ca>

On 3/19/2007 9:12 AM, Martin Maechler wrote:
>>>>>> "Duncan" == Duncan Murdoch <murdoch at stats.uwo.ca>
>>>>>>     on Mon, 19 Mar 2007 09:01:39 -0400 writes:
> 
>     Duncan> On 3/19/2007 6:48 AM, Martin Maechler wrote:
>     >>>>>>> "BDR" == Prof Brian Ripley <ripley at stats.ox.ac.uk>
>     >>>>>>> on Sun, 18 Mar 2007 06:51:58 +0000 (GMT) writes:
>     >> 
>     BDR> On Sat, 17 Mar 2007, Spencer Graves wrote:
>     >> >> Hi, All:
>     >> >> Attached please find a symmetric, indefinite matrix for which 
>     >> >> 'eigen(...)$vectors' included NAs: 
>     >> >>> load("eigenBug.Rdata")
>     >> >>> sum(is.na(eigen(eigenBug)$vectors))
>     >> >> [1] 5670
>     >> >>> sessioninfo()
>     >> >> Error: could not find function "sessioninfo"
>     >> >>> sessionInfo()
>     >> >> R version 2.4.1 (2006-12-18)
>     >> >> i386-pc-mingw32
>     >> >> 
>     >> >> locale:
>     >> >> LC_COLLATE=English_United States.1252;LC_CTYPE=English_United 
>     >> >> States.1252;LC_MONETARY=English_United 
>     >> >> States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252
>     >> >> 
>     >> >> attached base packages:
>     >> >> [1] "stats"     "graphics"  "grDevices" "utils"     "datasets"  "methods" [7] 
>     >> >> "base"
>     >> >> Using EISPACK does NOT return NAs: > sum(is.na(eigen(eigenBug, 
>     >> >> EISPACK=TRUE)$vectors))
>     >> >> [1] 0
>     >> >> 
>     >> >> 
>     >> >> I traced the problem to the following line in 'eigen':
>     >> >> z <- if (!complex.x)
>     >> >> .Call("La_rs", x, only.values, PACKAGE = "base")
>     >> >> 
>     >> >> 
>     >> >> Comments?
>     >> 
>     BDR> Nothing appeared as an attachment.
>     >> 
>     >> it was a zip file which is not among the allowed ones
>     >> (.tar.gz / *.tgz  would work).
>     >> 
>     >> Spencer has also contacted me in private,
>     >> so you now can use something like :
>     >> 
>     >> F <- tempfile()
>     >> download.file("ftp://stat.ethz.ch/U/maechler/R/eigenBug.Rdata", F)
>     >> load(F)
> 
>     Duncan> This is unrelated to Spencer's problem, but this
>     Duncan> sequence failed for me.
> 
>     Duncan> By default it will treat the file as a text file,
>     Duncan> and convert EOL markers for Windows.  Adding
>     Duncan> "mode='wb'" to the download.file() call is necessary.
> 
> ok;  Thank you, Duncan.
> 
> {For me, that's yet another reason why I think it would be  ``nice''
>  if both  load() and source()  would work with general
>  connections the same way as read.table(), and I could just say
> 
>      load("ftp://stat.ethz.ch/U/maechler/R/eigenBug.Rdata")
> }
> 
>     >> str(eigenBug)# tons of dinames; get rid of them:
>     >> M <- unname(eigenBug)
>     >> 
>     >> sum(is.na(eigen(M)$vectors))
>     >> # 0 (for MM, on Linux);  '5670' for Spencer
> 
>     Duncan> I get the same as Spencer in 2.4.1, but zero in
>     Duncan> R-devel, in Windows. 
> 
> ahh, that's good news.
> 
> Maybe Spencer could install a revcent version R-devel on his
> Windows machine, and try the example?
> 
> 
>     Duncan> I haven't tried R-patched yet: there were network
>     Duncan> problems here this morning, and the build failed.

I just tried it, and it gives the error the same as R 2.4.1.

Duncan Murdoch

> 
>     Duncan> Duncan Murdoch
> 
>     >> sum(is.na(eigen(M, EISPACK=TRUE)$vectors))
>     >> # 0
>     >> 
>     >> ## Guess about what kind of BLAS/Lapack I'm using :
>     >> file.info(list.files(R.home("lib"), full=TRUE))[,1:3]
>     >> ##                                        size isdir mode
>     >> ## ....64-linux-inst/lib/libRblas.so    422558 FALSE  755
>     >> ## ....64-linux-inst/lib/libRlapack.so 3144596 FALSE  755
>     >> 
>     >> 
>     >> I.e. I don't get any NA's
>     >> which shows to me that the bug is most probably in the Lapack -
>     >> Version that Spencer's version of R is linked against.
>     >> 
>     >> Martin Maechler, ETH Zurich
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From ripley at stats.ox.ac.uk  Mon Mar 19 14:37:15 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 19 Mar 2007 13:37:15 +0000 (GMT)
Subject: [Rd] eigen returns NAs from a real matrix
In-Reply-To: <17918.35927.594199.926088@stat.math.ethz.ch>
References: <45FCCCC5.3060806@pdf.com>
	<Pine.LNX.4.64.0703180651080.24029@gannet.stats.ox.ac.uk>
	<17918.27271.48263.371325@stat.math.ethz.ch>
	<45FE89B3.5050505@stats.uwo.ca>
	<17918.35927.594199.926088@stat.math.ethz.ch>
Message-ID: <Pine.LNX.4.64.0703191327460.27195@gannet.stats.ox.ac.uk>

On Mon, 19 Mar 2007, Martin Maechler wrote:

>>>>>> "Duncan" == Duncan Murdoch <murdoch at stats.uwo.ca>
>>>>>>     on Mon, 19 Mar 2007 09:01:39 -0400 writes:
>
>    Duncan> On 3/19/2007 6:48 AM, Martin Maechler wrote:
>    >>>>>>> "BDR" == Prof Brian Ripley <ripley at stats.ox.ac.uk>
>    >>>>>>> on Sun, 18 Mar 2007 06:51:58 +0000 (GMT) writes:
>    >>
>    BDR> On Sat, 17 Mar 2007, Spencer Graves wrote:
>    >> >> Hi, All:
>    >> >> Attached please find a symmetric, indefinite matrix for which
>    >> >> 'eigen(...)$vectors' included NAs:
>    >> >>> load("eigenBug.Rdata")
>    >> >>> sum(is.na(eigen(eigenBug)$vectors))
>    >> >> [1] 5670
>    >> >>> sessioninfo()
>    >> >> Error: could not find function "sessioninfo"
>    >> >>> sessionInfo()
>    >> >> R version 2.4.1 (2006-12-18)
>    >> >> i386-pc-mingw32
>    >> >>
>    >> >> locale:
>    >> >> LC_COLLATE=English_United States.1252;LC_CTYPE=English_United
>    >> >> States.1252;LC_MONETARY=English_United
>    >> >> States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252
>    >> >>
>    >> >> attached base packages:
>    >> >> [1] "stats"     "graphics"  "grDevices" "utils"     "datasets"  "methods" [7]
>    >> >> "base"
>    >> >> Using EISPACK does NOT return NAs: > sum(is.na(eigen(eigenBug,
>    >> >> EISPACK=TRUE)$vectors))
>    >> >> [1] 0
>    >> >>
>    >> >>
>    >> >> I traced the problem to the following line in 'eigen':
>    >> >> z <- if (!complex.x)
>    >> >> .Call("La_rs", x, only.values, PACKAGE = "base")
>    >> >>
>    >> >>
>    >> >> Comments?
>    >>
>    BDR> Nothing appeared as an attachment.
>    >>
>    >> it was a zip file which is not among the allowed ones
>    >> (.tar.gz / *.tgz  would work).
>    >>
>    >> Spencer has also contacted me in private,
>    >> so you now can use something like :
>    >>
>    >> F <- tempfile()
>    >> download.file("ftp://stat.ethz.ch/U/maechler/R/eigenBug.Rdata", F)
>    >> load(F)
>
>    Duncan> This is unrelated to Spencer's problem, but this
>    Duncan> sequence failed for me.
>
>    Duncan> By default it will treat the file as a text file,
>    Duncan> and convert EOL markers for Windows.  Adding
>    Duncan> "mode='wb'" to the download.file() call is necessary.
>
> ok;  Thank you, Duncan.
>
> {For me, that's yet another reason why I think it would be  ``nice''
> if both  load() and source()  would work with general
> connections the same way as read.table(), and I could just say
>
>     load("ftp://stat.ethz.ch/U/maechler/R/eigenBug.Rdata")
> }

The help page for load() does have an example of using a url() connection 
here, and that works in this example on Windows, as does

load(url("ftp://stat.ethz.ch/U/maechler/R/eigenBug.Rdata"))

Not so hard, surely?  (The reason load() is different is that it can 
transparently handle compressed files, unlike read.table.)

>
>    >> str(eigenBug)# tons of dinames; get rid of them:
>    >> M <- unname(eigenBug)
>    >>
>    >> sum(is.na(eigen(M)$vectors))
>    >> # 0 (for MM, on Linux);  '5670' for Spencer
>
>    Duncan> I get the same as Spencer in 2.4.1, but zero in
>    Duncan> R-devel, in Windows.
>
> ahh, that's good news.
>
> Maybe Spencer could install a revcent version R-devel on his
> Windows machine, and try the example?

My belief is that the LAPACK update has solved this on Windows: it does 
not happen on my Linux systems, and does happen in R-patched on Windows.


>    Duncan> I haven't tried R-patched yet: there were network
>    Duncan> problems here this morning, and the build failed.
>
>    Duncan> Duncan Murdoch
>
>    >> sum(is.na(eigen(M, EISPACK=TRUE)$vectors))
>    >> # 0
>    >>
>    >> ## Guess about what kind of BLAS/Lapack I'm using :
>    >> file.info(list.files(R.home("lib"), full=TRUE))[,1:3]
>    >> ##                                        size isdir mode
>    >> ## ....64-linux-inst/lib/libRblas.so    422558 FALSE  755
>    >> ## ....64-linux-inst/lib/libRlapack.so 3144596 FALSE  755
>    >>
>    >>
>    >> I.e. I don't get any NA's
>    >> which shows to me that the bug is most probably in the Lapack -
>    >> Version that Spencer's version of R is linked against.
>    >>
>    >> Martin Maechler, ETH Zurich
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ernest.turro at ic.ac.uk  Mon Mar 19 14:47:47 2007
From: ernest.turro at ic.ac.uk (Ernest Turro)
Date: Mon, 19 Mar 2007 13:47:47 +0000
Subject: [Rd] Carriage returns and Sweave output
Message-ID: <30B148B0-0C89-49BA-AEC9-160A6BA72D56@ic.ac.uk>

Dear all,

I have a code chunk in my Rnw file that, when executed, outputs  
carriage return characters ('\r') to inform on the progress (e.g.  
"sweep 4 of 1024\r"). But Sweave interprets this as a newline  
character, and therefore I get countless pages of output in my  
vignette where I only really want one line. Any ideas?

Thanks

E


From felix at nfrac.org  Mon Mar 19 14:58:50 2007
From: felix at nfrac.org (felix at nfrac.org)
Date: Mon, 19 Mar 2007 14:58:50 +0100 (CET)
Subject: [Rd] R4.1: seq.POSIXt, tz="AEST" (PR#9572)
Message-ID: <20070319135850.2C6CC5AC1E@slim.kubism.ku.dk>

------=_Part_63767_16761935.1174312715444
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit
Content-Disposition: inline

I am sorry, "AEST" was wrong. I can't work out what timezone code it is, but
my default timezone here in eastern australia prints as:
> as.POSIXct("1970-01-01", tz="")
[1] "1970-01-01 AUS Eastern Daylight Time"

and that is the one that has repeated dates before 1970.

But I take your point that it is fundamentally a problem with Windows.

--Felix


On 3/19/07, Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
>
> Hmm, AEST is not a valid time zone on Windows.
> See ?as.POSIXlt for one of several places where this is documented.
>
> But in any case, the underlying problem is in the OS, and we only try to
> work around it to the best of our knowledge (and that excludes
> undocumented time zones).
>
>
> On Mon, 19 Mar 2007, felix at nfrac.org wrote:
>
> > Times from seq.POSIXt come out wrong in AEST timezone around Feb 29
> every
> > leap year before 1970 (on Windows XP).
> >
> > According to help(DateTimeClasses), this is handled by "our own C code".
> >
> >> x <- as.POSIXct("1968-02-27") # tz="AEST"
> >> x.gmt <- as.POSIXct("1968-02-27", tz="GMT")
> >> data.frame(
> >     GMT=seq(x.gmt, by="day", length=8),
> >     byday=seq(x, by="day", length=8),
> >     byDST=seq(x, by="DSTday", length=8))
> >         GMT      byday      byDST
> > 1 1968-02-27 1968-02-27 1968-02-27
> > 2 1968-02-28 1968-02-28 1968-02-28
> > 3 1968-02-29 1968-03-01 1968-03-02
> > 4 1968-03-01 1968-03-02 1968-03-02
> > 5 1968-03-02 1968-03-02 1968-03-02
> > 6 1968-03-03 1968-03-03 1968-03-03
> > 7 1968-03-04 1968-03-04 1968-03-04
> > 8 1968-03-05 1968-03-05 1968-03-05
> >
> >> R.version
> >               _
> > platform       i386-pc-mingw32
> > arch           i386
> > os             mingw32
> > system         i386, mingw32
> > status
> > major          2
> > minor          4.1
> > year           2006
> > month          12
> > day            18
> > svn rev        40228
> > language       R
> > version.string R version 2.4.1 (2006-12-18)
> >
> >
> >
> >
>
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>

------=_Part_63767_16761935.1174312715444
Content-Type: text/html; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit
Content-Disposition: inline

I am sorry, &quot;AEST&quot; was wrong. I can&#39;t work out what timezone code it is, but my default timezone here in eastern australia prints as:<br>&gt; as.POSIXct(&quot;1970-01-01&quot;, tz=&quot;&quot;)<br>[1] &quot;1970-01-01 AUS Eastern Daylight Time&quot;
<br><br>and that is the one that has repeated dates before 1970.<br><br>But I take your point that it is fundamentally a problem with Windows.<br><br>--Felix<br><br><br><div><span class="gmail_quote">On 3/19/07, <b class="gmail_sendername">
Prof Brian Ripley</b> &lt;<a href="mailto:ripley at stats.ox.ac.uk">ripley at stats.ox.ac.uk</a>&gt; wrote:</span><blockquote class="gmail_quote" style="border-left: 1px solid rgb(204, 204, 204); margin: 0pt 0pt 0pt 0.8ex; padding-left: 1ex;">
Hmm, AEST is not a valid time zone on Windows.<br>See ?as.POSIXlt for one of several places where this is documented.<br><br>But in any case, the underlying problem is in the OS, and we only try to<br>work around it to the best of our knowledge (and that excludes
<br>undocumented time zones).<br><br><br>On Mon, 19 Mar 2007, <a href="mailto:felix at nfrac.org">felix at nfrac.org</a> wrote:<br><br>&gt; Times from seq.POSIXt come out wrong in AEST timezone around Feb 29 every<br>&gt; leap year before 1970 (on Windows XP).
<br>&gt;<br>&gt; According to help(DateTimeClasses), this is handled by &quot;our own C code&quot;.<br>&gt;<br>&gt;&gt; x &lt;- as.POSIXct(&quot;1968-02-27&quot;) # tz=&quot;AEST&quot;<br>&gt;&gt; x.gmt &lt;- as.POSIXct(&quot;1968-02-27&quot;, tz=&quot;GMT&quot;)
<br>&gt;&gt; data.frame(<br>&gt;&nbsp;&nbsp;&nbsp;&nbsp; GMT=seq(x.gmt, by=&quot;day&quot;, length=8),<br>&gt;&nbsp;&nbsp;&nbsp;&nbsp; byday=seq(x, by=&quot;day&quot;, length=8),<br>&gt;&nbsp;&nbsp;&nbsp;&nbsp; byDST=seq(x, by=&quot;DSTday&quot;, length=8))<br>&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; GMT&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;byday&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;byDST
<br>&gt; 1 1968-02-27 1968-02-27 1968-02-27<br>&gt; 2 1968-02-28 1968-02-28 1968-02-28<br>&gt; 3 1968-02-29 1968-03-01 1968-03-02<br>&gt; 4 1968-03-01 1968-03-02 1968-03-02<br>&gt; 5 1968-03-02 1968-03-02 1968-03-02<br>&gt; 6 1968-03-03 1968-03-03 1968-03-03
<br>&gt; 7 1968-03-04 1968-03-04 1968-03-04<br>&gt; 8 1968-03-05 1968-03-05 1968-03-05<br>&gt;<br>&gt;&gt; R.version<br>&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; _<br>&gt; platform&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; i386-pc-mingw32<br>&gt; arch&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; i386<br>&gt; os&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; mingw32
<br>&gt; system&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; i386, mingw32<br>&gt; status<br>&gt; major&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2<br>&gt; minor&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;4.1<br>&gt; year&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 2006<br>&gt; month&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;12<br>&gt; day&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;18<br>&gt; svn rev&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;40228<br>&gt; language&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; R
<br>&gt; version.string R version 2.4.1 (2006-12-18)<br>&gt;<br>&gt;<br>&gt;<br>&gt;<br><br>--<br>Brian D. Ripley,&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href="mailto:ripley at stats.ox.ac.uk">ripley at stats.ox.ac.uk</a><br>Professor of Applied Statistics,&nbsp;&nbsp;
<a href="http://www.stats.ox.ac.uk/~ripley/">http://www.stats.ox.ac.uk/~ripley/</a><br>University of Oxford,&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Tel:&nbsp;&nbsp;+44 1865 272861 (self)<br>1 South Parks Road,&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; +44 1865 272866 (PA)<br>Oxford OX1 3TG, UK&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Fax:&nbsp;&nbsp;+44 1865 272595
<br></blockquote></div><br><br>

------=_Part_63767_16761935.1174312715444--


From r.hankin at noc.soton.ac.uk  Mon Mar 19 15:00:30 2007
From: r.hankin at noc.soton.ac.uk (Robin Hankin)
Date: Mon, 19 Mar 2007 14:00:30 +0000
Subject: [Rd] R CMD Rd2dvi
Message-ID: <73DF5ED4-DBAC-46F4-B6AC-D07815D9A7F4@soc.soton.ac.uk>

Hello

perhaps this is a bit late for R-2.5.0,
but does anyone find R CMD Rd2dvi refusing
to overwrite an existing dvi file useful?

I am forever leaving the .dvi file in
my scratch directory and have to
remove it manually.

I know that one can specify --output=f.dvi,
but this just defers the problem
because f.dvi won't be overwritten either.

Does anyone value this behaviour?

If not, could we change it?


For me, the typical session goes:

octopus:~/scratch% R CMD Rd2dvi ./BACCO
Hmm ... looks like a package bundle
file 'BACCO.dvi' exists; please remove first

octopus:~/scratch% rm BACCO.dvi
octopus:~/scratch% R CMD Rd2dvi ./BACCO
Hmm ... looks like a package bundle
[snip].






--
Robin Hankin
Uncertainty Analyst
National Oceanography Centre, Southampton
European Way, Southampton SO14 3ZH, UK
  tel  023-8059-7743


From maechler at stat.math.ethz.ch  Mon Mar 19 15:15:20 2007
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 19 Mar 2007 15:15:20 +0100
Subject: [Rd] eigen returns NAs from a real matrix
In-Reply-To: <Pine.LNX.4.64.0703191327460.27195@gannet.stats.ox.ac.uk>
References: <45FCCCC5.3060806@pdf.com>
	<Pine.LNX.4.64.0703180651080.24029@gannet.stats.ox.ac.uk>
	<17918.27271.48263.371325@stat.math.ethz.ch>
	<45FE89B3.5050505@stats.uwo.ca>
	<17918.35927.594199.926088@stat.math.ethz.ch>
	<Pine.LNX.4.64.0703191327460.27195@gannet.stats.ox.ac.uk>
Message-ID: <17918.39672.670678.897364@stat.math.ethz.ch>

>>>>> "BDR" == Prof Brian Ripley <ripley at stats.ox.ac.uk>
>>>>>     on Mon, 19 Mar 2007 13:37:15 +0000 (GMT) writes:

    BDR> On Mon, 19 Mar 2007, Martin Maechler wrote:
    >>>>>>> "Duncan" == Duncan Murdoch <murdoch at stats.uwo.ca>
    >>>>>>> on Mon, 19 Mar 2007 09:01:39 -0400 writes:
    >> 
    Duncan> On 3/19/2007 6:48 AM, Martin Maechler wrote:
    >> >>>>>>> "BDR" == Prof Brian Ripley <ripley at stats.ox.ac.uk>
    >> >>>>>>> on Sun, 18 Mar 2007 06:51:58 +0000 (GMT) writes:
    >> >>
    BDR> On Sat, 17 Mar 2007, Spencer Graves wrote:
    >> >> >> Hi, All:
    >> >> >> Attached please find a symmetric, indefinite matrix for which
    >> >> >> 'eigen(...)$vectors' included NAs:
    >> >> >>> load("eigenBug.Rdata")
    >> >> >>> sum(is.na(eigen(eigenBug)$vectors))
    >> >> >> [1] 5670
    >> >> >>> sessioninfo()
    >> >> >> Error: could not find function "sessioninfo"
    >> >> >>> sessionInfo()
    >> >> >> R version 2.4.1 (2006-12-18)
    >> >> >> i386-pc-mingw32
    >> >> >>
    >> >> >> locale:
    >> >> >> LC_COLLATE=English_United States.1252;LC_CTYPE=English_United
    >> >> >> States.1252;LC_MONETARY=English_United
    >> >> >> States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252
    >> >> >>
    >> >> >> attached base packages:
    >> >> >> [1] "stats"     "graphics"  "grDevices" "utils"     "datasets"  "methods" [7]
    >> >> >> "base"
    >> >> >> Using EISPACK does NOT return NAs: > sum(is.na(eigen(eigenBug,
    >> >> >> EISPACK=TRUE)$vectors))
    >> >> >> [1] 0
    >> >> >>
    >> >> >>
    >> >> >> I traced the problem to the following line in 'eigen':
    >> >> >> z <- if (!complex.x)
    >> >> >> .Call("La_rs", x, only.values, PACKAGE = "base")
    >> >> >>
    >> >> >>
    >> >> >> Comments?
    >> >>
    BDR> Nothing appeared as an attachment.
    >> >>
    >> >> it was a zip file which is not among the allowed ones
    >> >> (.tar.gz / *.tgz  would work).
    >> >>
    >> >> Spencer has also contacted me in private,
    >> >> so you now can use something like :
    >> >>
    >> >> F <- tempfile()
    >> >> download.file("ftp://stat.ethz.ch/U/maechler/R/eigenBug.Rdata", F)
    >> >> load(F)
    >> 
    Duncan> This is unrelated to Spencer's problem, but this
    Duncan> sequence failed for me.
    >> 
    Duncan> By default it will treat the file as a text file,
    Duncan> and convert EOL markers for Windows.  Adding
    Duncan> "mode='wb'" to the download.file() call is necessary.
    >> 
    >> ok;  Thank you, Duncan.
    >> 
    >> {For me, that's yet another reason why I think it would be  ``nice''
    >> if both  load() and source()  would work with general
    >> connections the same way as read.table(), and I could just say
    >> 
    >> load("ftp://stat.ethz.ch/U/maechler/R/eigenBug.Rdata")
    >> }

    BDR> The help page for load() does have an example of using a url() connection 
    BDR> here, and that works in this example on Windows, as does

    BDR> load(url("ftp://stat.ethz.ch/U/maechler/R/eigenBug.Rdata"))

    BDR> Not so hard, surely?

definitely not.  Here, I've confused  load() and source() 
and just last week in a course I gave I had wished that I could
use
	source(url(....))

    BDR>   (The reason load() is different is that it can transparently handle compressed files, unlike read.table.)

yes, indeed; I had forgotten about the reason.
Martin


From huber at ebi.ac.uk  Mon Mar 19 15:49:31 2007
From: huber at ebi.ac.uk (Wolfgang Huber)
Date: Mon, 19 Mar 2007 14:49:31 +0000
Subject: [Rd] Carriage returns and Sweave output
In-Reply-To: <30B148B0-0C89-49BA-AEC9-160A6BA72D56@ic.ac.uk>
References: <30B148B0-0C89-49BA-AEC9-160A6BA72D56@ic.ac.uk>
Message-ID: <45FEA2FB.7030105@ebi.ac.uk>

Dear Ernest,

this may not be exactly what you asked for, but how about setting 
"results=hide" in the options of your code chunk?

Best wishes
   Wolfgang

------------------------------------------------------------------
Wolfgang Huber  EBI/EMBL  Cambridge UK  http://www.ebi.ac.uk/huber

Ernest Turro wrote:
> Dear all,
> 
> I have a code chunk in my Rnw file that, when executed, outputs  
> carriage return characters ('\r') to inform on the progress (e.g.  
> "sweep 4 of 1024\r"). But Sweave interprets this as a newline  
> character, and therefore I get countless pages of output in my  
> vignette where I only really want one line. Any ideas?
> 
> Thanks
> 
> E


From ernest.turro at ic.ac.uk  Mon Mar 19 16:03:27 2007
From: ernest.turro at ic.ac.uk (Ernest Turro)
Date: Mon, 19 Mar 2007 15:03:27 +0000
Subject: [Rd] Carriage returns and Sweave output
In-Reply-To: <45FEA2FB.7030105@ebi.ac.uk>
References: <30B148B0-0C89-49BA-AEC9-160A6BA72D56@ic.ac.uk>
	<45FEA2FB.7030105@ebi.ac.uk>
Message-ID: <DC49D83C-7739-4CEA-A837-0200D658BED7@ic.ac.uk>

Hi Wolfgang,

the problem with results=hide is that it suppresses everything. I  
just need Sweave to suppress strings ending in '\r'...

Best,

Ernest


On 19 Mar 2007, at 14:49, Wolfgang Huber wrote:

> Dear Ernest,
>
> this may not be exactly what you asked for, but how about setting  
> "results=hide" in the options of your code chunk?
>
> Best wishes
>   Wolfgang
>
> ------------------------------------------------------------------
> Wolfgang Huber  EBI/EMBL  Cambridge UK  http://www.ebi.ac.uk/huber
>
> Ernest Turro wrote:
>> Dear all,
>> I have a code chunk in my Rnw file that, when executed, outputs   
>> carriage return characters ('\r') to inform on the progress (e.g.   
>> "sweep 4 of 1024\r"). But Sweave interprets this as a newline   
>> character, and therefore I get countless pages of output in my   
>> vignette where I only really want one line. Any ideas?
>> Thanks
>> E


From tlumley at u.washington.edu  Mon Mar 19 16:14:05 2007
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon, 19 Mar 2007 08:14:05 -0700 (PDT)
Subject: [Rd] Invalidating inaccessible SEXP?
In-Reply-To: <6phveh1w2h8.fsf@gopher4.fhcrc.org>
References: <6phveh1w2h8.fsf@gopher4.fhcrc.org>
Message-ID: <Pine.LNX.4.64.0703190810310.17682@homer22.u.washington.edu>

On Fri, 16 Mar 2007, Martin Morgan wrote:

> Is there a (C or R) function to invalidate the relevant parts of SEXP
> / data that are inaccessible? My problem is in tracking down
> protection and other memory mismanagement bugs, where I have to rely
> on luck to invalidate or overwrite data to trigger a detectable
> error. This makes it hard to track down a bug (it sometimes doesn't
> occur), or to know that a patch fixes the problem.
>

Under Valgrind when R is compiled  --with-valgrind-instrumentation=2 the 
code walks the list of newly freed SEXPs and marks them as inaccessible 
(which is one reason why it is so slow).

I don't know of any other facilities to do what you want.

 	-thomas


From tlumley at u.washington.edu  Mon Mar 19 16:19:05 2007
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon, 19 Mar 2007 08:19:05 -0700 (PDT)
Subject: [Rd] Incomplete valgrind instrumentation level documentation
In-Reply-To: <6phzm6dw2u2.fsf@gopher4.fhcrc.org>
References: <6phzm6dw2u2.fsf@gopher4.fhcrc.org>
Message-ID: <Pine.LNX.4.64.0703190818400.17682@homer22.u.washington.edu>

On Fri, 16 Mar 2007, Martin Morgan wrote:

> The 'Writing R Extensions' manual, configure.ac, and the comment at
> the top of memory.c suggests that there are valgrind instrumentation
> levels 0, 1, 2 but I think the actual code has four levels.

Yes, but only three of them work. Those are the ones that are documented.

 	-thomas

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle


From huber at ebi.ac.uk  Mon Mar 19 16:38:00 2007
From: huber at ebi.ac.uk (Wolfgang Huber)
Date: Mon, 19 Mar 2007 15:38:00 +0000
Subject: [Rd] Carriage returns and Sweave output
In-Reply-To: <DC49D83C-7739-4CEA-A837-0200D658BED7@ic.ac.uk>
References: <30B148B0-0C89-49BA-AEC9-160A6BA72D56@ic.ac.uk>
	<45FEA2FB.7030105@ebi.ac.uk>
	<DC49D83C-7739-4CEA-A837-0200D658BED7@ic.ac.uk>
Message-ID: <45FEAE58.4030208@ebi.ac.uk>

 > the problem with results=hide is that it suppresses everything. I just
 > need Sweave to suppress strings ending in '\r'...


Dear Ernest,

IMHO it is good practice to make the printing of these progress reports 
("sweep 4 of 1024\r") optional and produce them only if the user calls 
your function with, say, "verbose=TRUE", and furthermore set the default 
value of the 'verbose' argument to "verbose=interactive()".

  Best wishes
  Wolfgang


> On 19 Mar 2007, at 14:49, Wolfgang Huber wrote:
> 
>> Dear Ernest,
>>
>> this may not be exactly what you asked for, but how about setting 
>> "results=hide" in the options of your code chunk?
>>
>> Best wishes
>>   Wolfgang
>>
>> ------------------------------------------------------------------
>> Wolfgang Huber  EBI/EMBL  Cambridge UK  http://www.ebi.ac.uk/huber
>>
>> Ernest Turro wrote:
>>> Dear all,
>>> I have a code chunk in my Rnw file that, when executed, outputs  
>>> carriage return characters ('\r') to inform on the progress (e.g.  
>>> "sweep 4 of 1024\r"). But Sweave interprets this as a newline  
>>> character, and therefore I get countless pages of output in my  
>>> vignette where I only really want one line. Any ideas?
>>> Thanks
>>> E


From sfalcon at fhcrc.org  Mon Mar 19 16:50:26 2007
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Mon, 19 Mar 2007 08:50:26 -0700
Subject: [Rd] Carriage returns and Sweave output
In-Reply-To: <DC49D83C-7739-4CEA-A837-0200D658BED7@ic.ac.uk> (Ernest Turro's
	message of "Mon, 19 Mar 2007 15:03:27 +0000")
References: <30B148B0-0C89-49BA-AEC9-160A6BA72D56@ic.ac.uk>
	<45FEA2FB.7030105@ebi.ac.uk>
	<DC49D83C-7739-4CEA-A837-0200D658BED7@ic.ac.uk>
Message-ID: <m2648xz0zh.fsf@ziti.local>

Ernest Turro <ernest.turro at ic.ac.uk> writes:

> Hi Wolfgang,
>
> the problem with results=hide is that it suppresses everything. I  
> just need Sweave to suppress strings ending in '\r'...

Perhaps another idea is to add a verbose=FALSE option to the function
that spews \r.  In general, any status output of calculation should be
optional since they can get in the way of things like Sweave, etc.


-- 
Seth Falcon | Computational Biology | Fred Hutchinson Cancer Research Center
http://bioconductor.org


From jli3 at ncsu.edu  Mon Mar 19 17:06:30 2007
From: jli3 at ncsu.edu (Jiangtian Li)
Date: Mon, 19 Mar 2007 12:06:30 -0400 (EDT)
Subject: [Rd] free variable, built-in R functions
Message-ID: <34436.152.14.86.171.1174320390.squirrel@webmail.ncsu.edu>

Hi,

I have one question about built-in R functions. I am looking into
interprocedural analysis and since R supports "free variable", it would
become complicated if free variable is read inside a function. It is
uncommon and probably not good to read free variables when implementing R
functions. I suppose R built-in functions don't read free variables
(therefore don't depend on global variables). Could someone in the
development team confirm about that? Thank you very much.

Best regards,
Jiangtian


From nakama at ki.rim.or.jp  Mon Mar 19 17:12:09 2007
From: nakama at ki.rim.or.jp (Ei-ji Nakama)
Date: Tue, 20 Mar 2007 01:12:09 +0900
Subject: [Rd] build 2.4.1 for AIX 5.2L
Message-ID: <dc41e1260703190912u25ddaa9by3ede98a18ec5d6d7@mail.gmail.com>

nobody tested it in xlf.
but was able to build it in gcc.
when link as main, export is necessary by all means.

I put patch.
http://prs.ism.ac.jp/%7enakama/AIX/

I am happy if useful.
--
EI-JI Nakama  <nakama at ki.rim.or.jp>
"\u4e2d\u9593\u6804\u6cbb"  <nakama at ki.rim.or.jp>


From ross at biostat.ucsf.edu  Mon Mar 19 18:38:02 2007
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Mon, 19 Mar 2007 10:38:02 -0700
Subject: [Rd] R CMD check ignores .Rbuildignore?
In-Reply-To: <17918.26369.732045.755412@stat.math.ethz.ch>
References: <20070318193913.GM30753@wheat.betterworld.us>
	<17918.26369.732045.755412@stat.math.ethz.ch>
Message-ID: <20070319173802.GO30753@wheat.betterworld.us>

On Mon, Mar 19, 2007 at 11:33:37AM +0100, Martin Maechler wrote:
> >>>>> "RossB" == Ross Boylan <ross at biostat.ucsf.edu>
> >>>>>     on Sun, 18 Mar 2007 12:39:14 -0700 writes:
> 
>     RossB> The contents of .Rbuildignore seems to affect
>     RossB> R CMD build
>     RossB> but not 
>     RossB> R CMD check.
> 
>     RossB> I'm using R 2.4.0 on Debian.
> 
>     RossB> Is my understanding correct?  
> 
> yes.  That's why it's called 'buildignore'.
> It's a big feature for me as package developer:
It's more of a bug for me :(.  I was thinking of check as answering
the question "If I build this package, will it work?"
> 
> E.g., I can have extra tests (which e.g. only apply on my
> specific platform) in addition to those which are use when the
> package is built (to be checked on all possible platforms).
> 
> Some have proposed to additionally define a '.Rcheckignore' 
> but they haven't been convincing enough.

How about an option to have check use the buildignore file?  If there
are 2 separate files, there's always the risk they will get out of
sync.  Of course, in your case, you want them out of sync...

> 
>     RossB> And is there anything I can do about it?
> 
> "First build, then check" is one way;
> Something which is recommended anyway in some cases,
> e.g., if you have an (Sweave - based) vignette.
Kurt Hornick, offlist, also advised this, as well as noting that using
R CMD check directly on the main development directory isn't really
supported.

>From my perspective, needing to do a build before a check is extra
friction, which would reduce the amount of checking I do during
development.  Also, doesn't build do some of the same checks as check?

Minimally, I think some advice in the R Extensions manual needs to be
qualified:
In 
1.3 Checking and building packages
==================================

Before using these tools, please check that your package can be
installed and loaded.  `R CMD check' will _inter alia_ do this, but you
will get more informative error messages doing the checks directly.

---------------
There seem to be a couple of problems with this advice, aside from the
fact that it says to check first.  One problem is that the advice
seems internally inconsistent.  "Before using these tools" seems to
refer to the build and check tools in the section.  Since check is one
of the tools, it can't be used before using the tools.

Also, I still can't figure out what "doing the checks directly" refers
to.

Another section:
1.3.2 Building packages
-----------------------
[2 paragraphs skipped]

   Run-time checks whether the package works correctly should be
performed using `R CMD check' prior to invoking the build procedure.
------------------------
Since this advice, check then build, is the exact opposite of the
current recommendations, build then check, it probably needs to be
changed.

R CMD check --help (and other spots) refer to the command as
"Check R packages from package sources, which can be directories or
gzipped package 'tar' archives with extension '.tar.gz' or '.tgz'."  I
read this as referring to my source directory, although I guess other
readings are possible (i.e., package source = the source bundle as
distributed).

> 
>     RossB> In my case, some of the excluded files contain references to other
>     RossB> libraries, so linking fails under R CMD check.  I realize I could add
>     RossB> the library to the build (with Makevars, I guess), but I do not want
>     RossB> to introduce the dependency.
> 
> It depends on the circumstances on how I would solve this
> problem.... 
> [Why have these files as part of the package sources at all?]

I have 2 kinds of checks, those at the R level, which get executed as
part of R CMD check, and C++ unit tests, which I execute separately.
The latter use the boost test library, part of which is a link-time
library that ordinary users should not need.

All the C++ sources come from a web (as in Knuth's web) file, so the
main files and the testing files all get produced at once.

I worked around the problem by using the top level config script to
delete the test files.  I suppose I could also look into moving those
files into another directory when they are produced, but that would
further complicate my build system.

Ross


From ross at biostat.ucsf.edu  Mon Mar 19 18:50:10 2007
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Mon, 19 Mar 2007 10:50:10 -0700
Subject: [Rd] R CMD check ignores .Rbuildignore? [correction]
In-Reply-To: <20070319173802.GO30753@wheat.betterworld.us>
References: <20070318193913.GM30753@wheat.betterworld.us>
	<17918.26369.732045.755412@stat.math.ethz.ch>
	<20070319173802.GO30753@wheat.betterworld.us>
Message-ID: <20070319175010.GQ30753@wheat.betterworld.us>

On Mon, Mar 19, 2007 at 10:38:02AM -0700, Ross Boylan wrote:
> Kurt Hornick, offlist, also advised this, as well as noting that using
Sorry.  That should be "Kurt Hornik."
Ross


From ggrothendieck at gmail.com  Mon Mar 19 18:58:48 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 19 Mar 2007 13:58:48 -0400
Subject: [Rd] R CMD check ignores .Rbuildignore?
In-Reply-To: <20070319173802.GO30753@wheat.betterworld.us>
References: <20070318193913.GM30753@wheat.betterworld.us>
	<17918.26369.732045.755412@stat.math.ethz.ch>
	<20070319173802.GO30753@wheat.betterworld.us>
Message-ID: <971536df0703191058l19edbc8cle8d9a31542b2a124@mail.gmail.com>

On 3/19/07, Ross Boylan <ross at biostat.ucsf.edu> wrote:

> How about an option to have check use the buildignore file?  If there
> are 2 separate files, there's always the risk they will get out of
> sync.  Of course, in your case, you want them out of sync...


For Windows users only there is a batch file, makepkg.bat, in
the batchfiles distribution that will run a build prior to a check
or install so that .Rbuildignore gets invoked.  It would be possible
to create a similar shell file for UNIX.

http://code.google.com/p/batchfiles/


From mgd at santafe.edu  Mon Mar 19 21:47:01 2007
From: mgd at santafe.edu (Marcus G. Daniels)
Date: Mon, 19 Mar 2007 14:47:01 -0600
Subject: [Rd] -std=c99 and inline semantics
Message-ID: <45FEF6C5.1070900@santafe.edu>

Hi,

I noticed that with the GCC trunk (4.3.0), the semantics of "extern 
inline" have reversed.  
The net result is that R will build without the usual-stdc=gnu99 but it 
won't with it.
Many multiple definitions result otherwise. 

Marcus


From ernest.turro at ic.ac.uk  Mon Mar 19 22:23:49 2007
From: ernest.turro at ic.ac.uk (Ernest Turro)
Date: Mon, 19 Mar 2007 21:23:49 +0000
Subject: [Rd] Rinternals.h and undefined symbols
Message-ID: <9001E5A6-9080-4224-92ED-4867C858C637@ic.ac.uk>

Hi,

I'm trying to register my native routines using R_registerRoutines 
(...). I can compile the code, but the loader cannot resolve the symbol:

undefined symbol:  
_Z18R_registerRoutinesP8_DllInfoPK12R_CMethodDefPK15R_CallMethodDefS3_S6 
_

$ nm bgx.Rcheck/bgx/libs/bgx.so | grep R_registerRoutines
                  U  
_Z18R_registerRoutinesP8_DllInfoPK12R_CMethodDefPK15R_CallMethodDefS3_S6 
_

Why does it have this funny name? If I look at libR.so, I get an  
ordinary symbol name:

$ nm ~/lib64/R/lib/libR.so | grep R_registerRoutines
0000000000032f80 T R_registerRoutines

I get normal symbol names for R functions not in Rinternals.h and  
there is no problem there. For example:

nm bgx.Rcheck/bgx/libs/bgx.so | grep Rprintf
                  U Rprintf

$ nm ~/lib64/R/lib/libR.so  | grep Rprintf
0000000000129690 T Rprintf

The shared library dependencies are also fine:

$ ldd bgx.Rcheck/bgx/libs/bgx.so
         libR.so => /home/et04/lib64/R/lib/libR.so (0x0000002a95676000)
         libstdc++.so.6 => /usr/lib64/libstdc++.so.6  
(0x0000002a95a80000)
         libm.so.6 => /lib64/tls/libm.so.6 (0x0000002a95c70000)
         libgcc_s.so.1 => /lib64/libgcc_s.so.1 (0x0000002a95df7000)
         libc.so.6 => /lib64/tls/libc.so.6 (0x0000002a95f02000)
         libRblas.so => /home/et04/lib64/R/lib/libRblas.so  
(0x0000002a96136000)
         libg2c.so.0 => /usr/lib64/libg2c.so.0 (0x0000002a96262000)
         libreadline.so.4 => /usr/lib64/libreadline.so.4  
(0x0000002a96383000)
         libncurses.so.5 => /usr/lib64/libncurses.so.5  
(0x0000002a964bc000)
         libdl.so.2 => /lib64/libdl.so.2 (0x0000002a96618000)
         /lib64/ld-linux-x86-64.so.2 (0x000000552aaaa000)

My LD_LIBRARY_PATH environmental variable is set appropriately.

Any ideas?

Thanks,

E


From murdoch at stats.uwo.ca  Mon Mar 19 22:32:27 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Mon, 19 Mar 2007 17:32:27 -0400
Subject: [Rd] Rinternals.h and undefined symbols
In-Reply-To: <9001E5A6-9080-4224-92ED-4867C858C637@ic.ac.uk>
References: <9001E5A6-9080-4224-92ED-4867C858C637@ic.ac.uk>
Message-ID: <45FF016B.3060505@stats.uwo.ca>

On 3/19/2007 5:23 PM, Ernest Turro wrote:
> Hi,
> 
> I'm trying to register my native routines using R_registerRoutines 
> (...). I can compile the code, but the loader cannot resolve the symbol:
> 
> undefined symbol:  
> _Z18R_registerRoutinesP8_DllInfoPK12R_CMethodDefPK15R_CallMethodDefS3_S6 
> _
> 
> $ nm bgx.Rcheck/bgx/libs/bgx.so | grep R_registerRoutines
>                   U  
> _Z18R_registerRoutinesP8_DllInfoPK12R_CMethodDefPK15R_CallMethodDefS3_S6 
> _
> 
> Why does it have this funny name? If I look at libR.so, I get an  
> ordinary symbol name:

That looks like C++ name mangling.  Are you wrapping your declarations in

extern "C" { }

?

Duncan Murdoch


> 
> $ nm ~/lib64/R/lib/libR.so | grep R_registerRoutines
> 0000000000032f80 T R_registerRoutines
> 
> I get normal symbol names for R functions not in Rinternals.h and  
> there is no problem there. For example:
> 
> nm bgx.Rcheck/bgx/libs/bgx.so | grep Rprintf
>                   U Rprintf
> 
> $ nm ~/lib64/R/lib/libR.so  | grep Rprintf
> 0000000000129690 T Rprintf
> 
> The shared library dependencies are also fine:
> 
> $ ldd bgx.Rcheck/bgx/libs/bgx.so
>          libR.so => /home/et04/lib64/R/lib/libR.so (0x0000002a95676000)
>          libstdc++.so.6 => /usr/lib64/libstdc++.so.6  
> (0x0000002a95a80000)
>          libm.so.6 => /lib64/tls/libm.so.6 (0x0000002a95c70000)
>          libgcc_s.so.1 => /lib64/libgcc_s.so.1 (0x0000002a95df7000)
>          libc.so.6 => /lib64/tls/libc.so.6 (0x0000002a95f02000)
>          libRblas.so => /home/et04/lib64/R/lib/libRblas.so  
> (0x0000002a96136000)
>          libg2c.so.0 => /usr/lib64/libg2c.so.0 (0x0000002a96262000)
>          libreadline.so.4 => /usr/lib64/libreadline.so.4  
> (0x0000002a96383000)
>          libncurses.so.5 => /usr/lib64/libncurses.so.5  
> (0x0000002a964bc000)
>          libdl.so.2 => /lib64/libdl.so.2 (0x0000002a96618000)
>          /lib64/ld-linux-x86-64.so.2 (0x000000552aaaa000)
> 
> My LD_LIBRARY_PATH environmental variable is set appropriately.
> 
> Any ideas?
> 
> Thanks,
> 
> E
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From ernest.turro at ic.ac.uk  Tue Mar 20 00:41:16 2007
From: ernest.turro at ic.ac.uk (Ernest Turro)
Date: Mon, 19 Mar 2007 23:41:16 +0000
Subject: [Rd] Rinternals.h and undefined symbols
In-Reply-To: <45FF016B.3060505@stats.uwo.ca>
References: <9001E5A6-9080-4224-92ED-4867C858C637@ic.ac.uk>
	<45FF016B.3060505@stats.uwo.ca>
Message-ID: <4E0FCC76-D2E2-40E3-A2F7-C15519D286C1@ic.ac.uk>


On 19 Mar 2007, at 21:32, Duncan Murdoch wrote:

> On 3/19/2007 5:23 PM, Ernest Turro wrote:
>> Hi,
>> I'm trying to register my native routines using R_registerRoutines  
>> (...). I can compile the code, but the loader cannot resolve the  
>> symbol:
>> undefined symbol:   
>> _Z18R_registerRoutinesP8_DllInfoPK12R_CMethodDefPK15R_CallMethodDefS3 
>> _S6 _
>> $ nm bgx.Rcheck/bgx/libs/bgx.so | grep R_registerRoutines
>>                   U   
>> _Z18R_registerRoutinesP8_DllInfoPK12R_CMethodDefPK15R_CallMethodDefS3 
>> _S6 _
>> Why does it have this funny name? If I look at libR.so, I get an   
>> ordinary symbol name:
>
> That looks like C++ name mangling.  Are you wrapping your  
> declarations in
>
> extern "C" { }
>
> ?

Yeah, the routine is literally just:

extern "C"
   void R_init_bgx(DllInfo *info) {
     R_registerRoutines(info, cMethods,NULL,NULL,NULL);
   }

with cMethods declared outside as a static const R_CMethodDef.

The two routines that I am registering are also wrapped in extern "C".

Ernest


>
> Duncan Murdoch
>
>
>> $ nm ~/lib64/R/lib/libR.so | grep R_registerRoutines
>> 0000000000032f80 T R_registerRoutines
>> I get normal symbol names for R functions not in Rinternals.h and   
>> there is no problem there. For example:
>> nm bgx.Rcheck/bgx/libs/bgx.so | grep Rprintf
>>                   U Rprintf
>> $ nm ~/lib64/R/lib/libR.so  | grep Rprintf
>> 0000000000129690 T Rprintf
>> The shared library dependencies are also fine:
>> $ ldd bgx.Rcheck/bgx/libs/bgx.so
>>          libR.so => /home/et04/lib64/R/lib/libR.so  
>> (0x0000002a95676000)
>>          libstdc++.so.6 => /usr/lib64/libstdc++.so.6   
>> (0x0000002a95a80000)
>>          libm.so.6 => /lib64/tls/libm.so.6 (0x0000002a95c70000)
>>          libgcc_s.so.1 => /lib64/libgcc_s.so.1 (0x0000002a95df7000)
>>          libc.so.6 => /lib64/tls/libc.so.6 (0x0000002a95f02000)
>>          libRblas.so => /home/et04/lib64/R/lib/libRblas.so   
>> (0x0000002a96136000)
>>          libg2c.so.0 => /usr/lib64/libg2c.so.0 (0x0000002a96262000)
>>          libreadline.so.4 => /usr/lib64/libreadline.so.4   
>> (0x0000002a96383000)
>>          libncurses.so.5 => /usr/lib64/libncurses.so.5   
>> (0x0000002a964bc000)
>>          libdl.so.2 => /lib64/libdl.so.2 (0x0000002a96618000)
>>          /lib64/ld-linux-x86-64.so.2 (0x000000552aaaa000)
>> My LD_LIBRARY_PATH environmental variable is set appropriately.
>> Any ideas?
>> Thanks,
>> E
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From ernest.turro at ic.ac.uk  Tue Mar 20 01:41:33 2007
From: ernest.turro at ic.ac.uk (Ernest Turro)
Date: Tue, 20 Mar 2007 00:41:33 +0000
Subject: [Rd] Rinternals.h and undefined symbols
In-Reply-To: <45FF2866.7060705@stats.uwo.ca>
References: <9001E5A6-9080-4224-92ED-4867C858C637@ic.ac.uk>
	<45FF016B.3060505@stats.uwo.ca>
	<4E0FCC76-D2E2-40E3-A2F7-C15519D286C1@ic.ac.uk>
	<45FF2866.7060705@stats.uwo.ca>
Message-ID: <B97996F0-05E3-424E-B79F-BA9C9EE125FE@ic.ac.uk>


On 20 Mar 2007, at 00:18, Duncan Murdoch wrote:

> On 3/19/2007 7:41 PM, Ernest Turro wrote:
>> On 19 Mar 2007, at 21:32, Duncan Murdoch wrote:
>>> On 3/19/2007 5:23 PM, Ernest Turro wrote:
>>>> Hi,
>>>> I'm trying to register my native routines using  
>>>> R_registerRoutines  (...). I can compile the code, but the  
>>>> loader cannot resolve the  symbol:
>>>> undefined symbol:    
>>>> _Z18R_registerRoutinesP8_DllInfoPK12R_CMethodDefPK15R_CallMethodDef 
>>>> S3 _S6 _
>>>> $ nm bgx.Rcheck/bgx/libs/bgx.so | grep R_registerRoutines
>>>>                   U    
>>>> _Z18R_registerRoutinesP8_DllInfoPK12R_CMethodDefPK15R_CallMethodDef 
>>>> S3 _S6 _
>>>> Why does it have this funny name? If I look at libR.so, I get  
>>>> an   ordinary symbol name:
>>> That looks like C++ name mangling.  Are you wrapping your   
>>> declarations in
>>>
>>> extern "C" { }
>>>
>>> ?
>> Yeah, the routine is literally just:
>> extern "C"
>>    void R_init_bgx(DllInfo *info) {
>>      R_registerRoutines(info, cMethods,NULL,NULL,NULL);
>>    }
>> with cMethods declared outside as a static const R_CMethodDef.
>
> I'm no C++ expert, but that looks like it declares R_init_bgx to be  
> a "C" routine, but not R_registerRoutines (which is what the error  
> was about).  Its declaration is in Rdynload.h:
>
> #ifdef __cplusplus
> extern "C" {
> #endif
> int R_registerRoutines(DllInfo *info, const R_CMethodDef * const  
> croutines,
> 		       const R_CallMethodDef * const callRoutines,
> 		       const R_FortranMethodDef * const fortranRoutines,
>                        const R_ExternalMethodDef * const  
> externalRoutines);
>
> Rboolean R_useDynamicSymbols(DllInfo *info, Rboolean value);
> #ifdef __cplusplus
> }
> #endif
>
> so maybe your compiler doesn't define __cplusplus, or you didn't  
> include R_ext/Rdynload.h?

Thanks for the reply.

__cplusplus is defined and I do #include <R_ext/Rdynload.h> (after  
all, it does compile)...

I've tried this on two different machines, so it's not a problem  
specific to my setup either...  ):

Ernest


>
> Duncan Murdoch
>
>
>> The two routines that I am registering are also wrapped in extern  
>> "C".
>> Ernest
>>> Duncan Murdoch
>>>
>>>
>>>> $ nm ~/lib64/R/lib/libR.so | grep R_registerRoutines
>>>> 0000000000032f80 T R_registerRoutines
>>>> I get normal symbol names for R functions not in Rinternals.h  
>>>> and   there is no problem there. For example:
>>>> nm bgx.Rcheck/bgx/libs/bgx.so | grep Rprintf
>>>>                   U Rprintf
>>>> $ nm ~/lib64/R/lib/libR.so  | grep Rprintf
>>>> 0000000000129690 T Rprintf
>>>> The shared library dependencies are also fine:
>>>> $ ldd bgx.Rcheck/bgx/libs/bgx.so
>>>>          libR.so => /home/et04/lib64/R/lib/libR.so   
>>>> (0x0000002a95676000)
>>>>          libstdc++.so.6 => /usr/lib64/libstdc++.so.6    
>>>> (0x0000002a95a80000)
>>>>          libm.so.6 => /lib64/tls/libm.so.6 (0x0000002a95c70000)
>>>>          libgcc_s.so.1 => /lib64/libgcc_s.so.1 (0x0000002a95df7000)
>>>>          libc.so.6 => /lib64/tls/libc.so.6 (0x0000002a95f02000)
>>>>          libRblas.so => /home/et04/lib64/R/lib/libRblas.so    
>>>> (0x0000002a96136000)
>>>>          libg2c.so.0 => /usr/lib64/libg2c.so.0 (0x0000002a96262000)
>>>>          libreadline.so.4 => /usr/lib64/libreadline.so.4    
>>>> (0x0000002a96383000)
>>>>          libncurses.so.5 => /usr/lib64/libncurses.so.5    
>>>> (0x0000002a964bc000)
>>>>          libdl.so.2 => /lib64/libdl.so.2 (0x0000002a96618000)
>>>>          /lib64/ld-linux-x86-64.so.2 (0x000000552aaaa000)
>>>> My LD_LIBRARY_PATH environmental variable is set appropriately.
>>>> Any ideas?
>>>> Thanks,
>>>> E
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From ernest.turro at ic.ac.uk  Tue Mar 20 01:55:06 2007
From: ernest.turro at ic.ac.uk (Ernest Turro)
Date: Tue, 20 Mar 2007 00:55:06 +0000
Subject: [Rd] Rinternals.h and undefined symbols
In-Reply-To: <45FF2FD4.1080601@stats.uwo.ca>
References: <9001E5A6-9080-4224-92ED-4867C858C637@ic.ac.uk>
	<45FF016B.3060505@stats.uwo.ca>
	<4E0FCC76-D2E2-40E3-A2F7-C15519D286C1@ic.ac.uk>
	<45FF2866.7060705@stats.uwo.ca>
	<B97996F0-05E3-424E-B79F-BA9C9EE125FE@ic.ac.uk>
	<45FF2FD4.1080601@stats.uwo.ca>
Message-ID: <BE02BC30-532E-4398-AF56-BA5B76DDD308@ic.ac.uk>


On 20 Mar 2007, at 00:50, Duncan Murdoch wrote:

> On 3/19/2007 8:41 PM, Ernest Turro wrote:
>> On 20 Mar 2007, at 00:18, Duncan Murdoch wrote:
>>> On 3/19/2007 7:41 PM, Ernest Turro wrote:
>>>> On 19 Mar 2007, at 21:32, Duncan Murdoch wrote:
>>>>> On 3/19/2007 5:23 PM, Ernest Turro wrote:
>>>>>> Hi,
>>>>>> I'm trying to register my native routines using   
>>>>>> R_registerRoutines  (...). I can compile the code, but the   
>>>>>> loader cannot resolve the  symbol:
>>>>>> undefined symbol:     
>>>>>> _Z18R_registerRoutinesP8_DllInfoPK12R_CMethodDefPK15R_CallMethodD 
>>>>>> ef S3 _S6 _
>>>>>> $ nm bgx.Rcheck/bgx/libs/bgx.so | grep R_registerRoutines
>>>>>>                   U     
>>>>>> _Z18R_registerRoutinesP8_DllInfoPK12R_CMethodDefPK15R_CallMethodD 
>>>>>> ef S3 _S6 _
>>>>>> Why does it have this funny name? If I look at libR.so, I get   
>>>>>> an   ordinary symbol name:
>>>>> That looks like C++ name mangling.  Are you wrapping your    
>>>>> declarations in
>>>>>
>>>>> extern "C" { }
>>>>>
>>>>> ?
>>>> Yeah, the routine is literally just:
>>>> extern "C"
>>>>    void R_init_bgx(DllInfo *info) {
>>>>      R_registerRoutines(info, cMethods,NULL,NULL,NULL);
>>>>    }
>>>> with cMethods declared outside as a static const R_CMethodDef.
>>> I'm no C++ expert, but that looks like it declares R_init_bgx to  
>>> be  a "C" routine, but not R_registerRoutines (which is what the  
>>> error  was about).  Its declaration is in Rdynload.h:
>>>
>>> #ifdef __cplusplus
>>> extern "C" {
>>> #endif
>>> int R_registerRoutines(DllInfo *info, const R_CMethodDef * const   
>>> croutines,
>>> 		       const R_CallMethodDef * const callRoutines,
>>> 		       const R_FortranMethodDef * const fortranRoutines,
>>>                        const R_ExternalMethodDef * const   
>>> externalRoutines);
>>>
>>> Rboolean R_useDynamicSymbols(DllInfo *info, Rboolean value);
>>> #ifdef __cplusplus
>>> }
>>> #endif
>>>
>>> so maybe your compiler doesn't define __cplusplus, or you didn't   
>>> include R_ext/Rdynload.h?


Duncan, you hit the nail on the head. Thanks so much.

If you download R-2.4.1.tar.gz from CRAN you will find that the  
extern "C" is missing in Rdynload.h! I added it to my copy and my  
code compiles now. I wonder why it's missing. Has this been fixed in  
cvs?

Thanks,

Ernest

PS. you don't need the braces after extern "C"



>> Thanks for the reply.
>> __cplusplus is defined and I do #include <R_ext/Rdynload.h>  
>> (after  all, it does compile)...
>> I've tried this on two different machines, so it's not a problem   
>> specific to my setup either...  ):
>
> Here I'm just guessing:  you don't wrap the whole function in  
> extern "C", you just put extern "C" ahead of its header. That's not  
> the usual way it's done, but I don't know C++ well enough to know  
> if it matters. Nevertheless, I'd try
>
>  extern "C" {
>     void R_init_bgx(DllInfo *info) {
>       R_registerRoutines(info, cMethods,NULL,NULL,NULL);
>     }
>  }
>
> just to see if it helps.
>
> Duncan Murdoch


From murdoch at stats.uwo.ca  Tue Mar 20 02:00:12 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Mon, 19 Mar 2007 21:00:12 -0400
Subject: [Rd] Rinternals.h and undefined symbols
In-Reply-To: <BE02BC30-532E-4398-AF56-BA5B76DDD308@ic.ac.uk>
References: <9001E5A6-9080-4224-92ED-4867C858C637@ic.ac.uk>
	<45FF016B.3060505@stats.uwo.ca>
	<4E0FCC76-D2E2-40E3-A2F7-C15519D286C1@ic.ac.uk>
	<45FF2866.7060705@stats.uwo.ca>
	<B97996F0-05E3-424E-B79F-BA9C9EE125FE@ic.ac.uk>
	<45FF2FD4.1080601@stats.uwo.ca>
	<BE02BC30-532E-4398-AF56-BA5B76DDD308@ic.ac.uk>
Message-ID: <45FF321C.2020400@stats.uwo.ca>

On 3/19/2007 8:55 PM, Ernest Turro wrote:
> On 20 Mar 2007, at 00:50, Duncan Murdoch wrote:
> 
>> On 3/19/2007 8:41 PM, Ernest Turro wrote:
>>> On 20 Mar 2007, at 00:18, Duncan Murdoch wrote:
>>>> On 3/19/2007 7:41 PM, Ernest Turro wrote:
>>>>> On 19 Mar 2007, at 21:32, Duncan Murdoch wrote:
>>>>>> On 3/19/2007 5:23 PM, Ernest Turro wrote:
>>>>>>> Hi,
>>>>>>> I'm trying to register my native routines using   
>>>>>>> R_registerRoutines  (...). I can compile the code, but the   
>>>>>>> loader cannot resolve the  symbol:
>>>>>>> undefined symbol:     
>>>>>>> _Z18R_registerRoutinesP8_DllInfoPK12R_CMethodDefPK15R_CallMethodD 
>>>>>>> ef S3 _S6 _
>>>>>>> $ nm bgx.Rcheck/bgx/libs/bgx.so | grep R_registerRoutines
>>>>>>>                   U     
>>>>>>> _Z18R_registerRoutinesP8_DllInfoPK12R_CMethodDefPK15R_CallMethodD 
>>>>>>> ef S3 _S6 _
>>>>>>> Why does it have this funny name? If I look at libR.so, I get   
>>>>>>> an   ordinary symbol name:
>>>>>> That looks like C++ name mangling.  Are you wrapping your    
>>>>>> declarations in
>>>>>>
>>>>>> extern "C" { }
>>>>>>
>>>>>> ?
>>>>> Yeah, the routine is literally just:
>>>>> extern "C"
>>>>>    void R_init_bgx(DllInfo *info) {
>>>>>      R_registerRoutines(info, cMethods,NULL,NULL,NULL);
>>>>>    }
>>>>> with cMethods declared outside as a static const R_CMethodDef.
>>>> I'm no C++ expert, but that looks like it declares R_init_bgx to  
>>>> be  a "C" routine, but not R_registerRoutines (which is what the  
>>>> error  was about).  Its declaration is in Rdynload.h:
>>>>
>>>> #ifdef __cplusplus
>>>> extern "C" {
>>>> #endif
>>>> int R_registerRoutines(DllInfo *info, const R_CMethodDef * const   
>>>> croutines,
>>>> 		       const R_CallMethodDef * const callRoutines,
>>>> 		       const R_FortranMethodDef * const fortranRoutines,
>>>>                        const R_ExternalMethodDef * const   
>>>> externalRoutines);
>>>>
>>>> Rboolean R_useDynamicSymbols(DllInfo *info, Rboolean value);
>>>> #ifdef __cplusplus
>>>> }
>>>> #endif
>>>>
>>>> so maybe your compiler doesn't define __cplusplus, or you didn't   
>>>> include R_ext/Rdynload.h?
> 
> 
> Duncan, you hit the nail on the head. Thanks so much.
> 
> If you download R-2.4.1.tar.gz from CRAN you will find that the  
> extern "C" is missing in Rdynload.h! I added it to my copy and my  
> code compiles now. I wonder why it's missing. Has this been fixed in  
> cvs?

Yes, it's a new addition Duncan Temple Lang added in November.  I didn't 
remember that or I would have mentioned it.

Duncan Murdoch

> Thanks,
> 
> Ernest
> 
> PS. you don't need the braces after extern "C"
> 
> 
> 
>>> Thanks for the reply.
>>> __cplusplus is defined and I do #include <R_ext/Rdynload.h>  
>>> (after  all, it does compile)...
>>> I've tried this on two different machines, so it's not a problem   
>>> specific to my setup either...  ):
>> Here I'm just guessing:  you don't wrap the whole function in  
>> extern "C", you just put extern "C" ahead of its header. That's not  
>> the usual way it's done, but I don't know C++ well enough to know  
>> if it matters. Nevertheless, I'd try
>>
>>  extern "C" {
>>     void R_init_bgx(DllInfo *info) {
>>       R_registerRoutines(info, cMethods,NULL,NULL,NULL);
>>     }
>>  }
>>
>> just to see if it helps.
>>
>> Duncan Murdoch


From ripley at stats.ox.ac.uk  Tue Mar 20 08:12:25 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 20 Mar 2007 07:12:25 +0000 (GMT)
Subject: [Rd] Rinternals.h and undefined symbols
In-Reply-To: <45FF321C.2020400@stats.uwo.ca>
References: <9001E5A6-9080-4224-92ED-4867C858C637@ic.ac.uk>
	<45FF016B.3060505@stats.uwo.ca>
	<4E0FCC76-D2E2-40E3-A2F7-C15519D286C1@ic.ac.uk>
	<45FF2866.7060705@stats.uwo.ca>
	<B97996F0-05E3-424E-B79F-BA9C9EE125FE@ic.ac.uk>
	<45FF2FD4.1080601@stats.uwo.ca>
	<BE02BC30-532E-4398-AF56-BA5B76DDD308@ic.ac.uk>
	<45FF321C.2020400@stats.uwo.ca>
Message-ID: <Pine.LNX.4.64.0703200707430.6222@gannet.stats.ox.ac.uk>

Note though that you should include C header files inside extern "C" in 
your C++ code.  'Writing R Extensions' says

   Some @R{} header files are C and not C++ header files and should be
   included within an @code{extern "C"} block: for clarity this is
   advisable for all @R{} header files.

On Mon, 19 Mar 2007, Duncan Murdoch wrote:

> On 3/19/2007 8:55 PM, Ernest Turro wrote:
>> On 20 Mar 2007, at 00:50, Duncan Murdoch wrote:
>>
>>> On 3/19/2007 8:41 PM, Ernest Turro wrote:
>>>> On 20 Mar 2007, at 00:18, Duncan Murdoch wrote:
>>>>> On 3/19/2007 7:41 PM, Ernest Turro wrote:
>>>>>> On 19 Mar 2007, at 21:32, Duncan Murdoch wrote:
>>>>>>> On 3/19/2007 5:23 PM, Ernest Turro wrote:
>>>>>>>> Hi,
>>>>>>>> I'm trying to register my native routines using
>>>>>>>> R_registerRoutines  (...). I can compile the code, but the
>>>>>>>> loader cannot resolve the  symbol:
>>>>>>>> undefined symbol:
>>>>>>>> _Z18R_registerRoutinesP8_DllInfoPK12R_CMethodDefPK15R_CallMethodD
>>>>>>>> ef S3 _S6 _
>>>>>>>> $ nm bgx.Rcheck/bgx/libs/bgx.so | grep R_registerRoutines
>>>>>>>>                   U
>>>>>>>> _Z18R_registerRoutinesP8_DllInfoPK12R_CMethodDefPK15R_CallMethodD
>>>>>>>> ef S3 _S6 _
>>>>>>>> Why does it have this funny name? If I look at libR.so, I get
>>>>>>>> an   ordinary symbol name:
>>>>>>> That looks like C++ name mangling.  Are you wrapping your
>>>>>>> declarations in
>>>>>>>
>>>>>>> extern "C" { }
>>>>>>>
>>>>>>> ?
>>>>>> Yeah, the routine is literally just:
>>>>>> extern "C"
>>>>>>    void R_init_bgx(DllInfo *info) {
>>>>>>      R_registerRoutines(info, cMethods,NULL,NULL,NULL);
>>>>>>    }
>>>>>> with cMethods declared outside as a static const R_CMethodDef.
>>>>> I'm no C++ expert, but that looks like it declares R_init_bgx to
>>>>> be  a "C" routine, but not R_registerRoutines (which is what the
>>>>> error  was about).  Its declaration is in Rdynload.h:
>>>>>
>>>>> #ifdef __cplusplus
>>>>> extern "C" {
>>>>> #endif
>>>>> int R_registerRoutines(DllInfo *info, const R_CMethodDef * const
>>>>> croutines,
>>>>> 		       const R_CallMethodDef * const callRoutines,
>>>>> 		       const R_FortranMethodDef * const fortranRoutines,
>>>>>                        const R_ExternalMethodDef * const
>>>>> externalRoutines);
>>>>>
>>>>> Rboolean R_useDynamicSymbols(DllInfo *info, Rboolean value);
>>>>> #ifdef __cplusplus
>>>>> }
>>>>> #endif
>>>>>
>>>>> so maybe your compiler doesn't define __cplusplus, or you didn't
>>>>> include R_ext/Rdynload.h?
>>
>>
>> Duncan, you hit the nail on the head. Thanks so much.
>>
>> If you download R-2.4.1.tar.gz from CRAN you will find that the
>> extern "C" is missing in Rdynload.h! I added it to my copy and my
>> code compiles now. I wonder why it's missing. Has this been fixed in
>> cvs?
>
> Yes, it's a new addition Duncan Temple Lang added in November.  I didn't
> remember that or I would have mentioned it.
>
> Duncan Murdoch
>
>> Thanks,
>>
>> Ernest
>>
>> PS. you don't need the braces after extern "C"
>>
>>
>>
>>>> Thanks for the reply.
>>>> __cplusplus is defined and I do #include <R_ext/Rdynload.h>
>>>> (after  all, it does compile)...
>>>> I've tried this on two different machines, so it's not a problem
>>>> specific to my setup either...  ):
>>> Here I'm just guessing:  you don't wrap the whole function in
>>> extern "C", you just put extern "C" ahead of its header. That's not
>>> the usual way it's done, but I don't know C++ well enough to know
>>> if it matters. Nevertheless, I'd try
>>>
>>>  extern "C" {
>>>     void R_init_bgx(DllInfo *info) {
>>>       R_registerRoutines(info, cMethods,NULL,NULL,NULL);
>>>     }
>>>  }
>>>
>>> just to see if it helps.
>>>
>>> Duncan Murdoch
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From maechler at stat.math.ethz.ch  Tue Mar 20 08:53:39 2007
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 20 Mar 2007 08:53:39 +0100
Subject: [Rd] Carriage returns and Sweave output
In-Reply-To: <45FEAE58.4030208@ebi.ac.uk>
References: <30B148B0-0C89-49BA-AEC9-160A6BA72D56@ic.ac.uk>
	<45FEA2FB.7030105@ebi.ac.uk>
	<DC49D83C-7739-4CEA-A837-0200D658BED7@ic.ac.uk>
	<45FEAE58.4030208@ebi.ac.uk>
Message-ID: <17919.37635.203919.143033@stat.math.ethz.ch>

>>>>> "Wolfi" == Wolfgang Huber <huber at ebi.ac.uk>
>>>>>     on Mon, 19 Mar 2007 15:38:00 +0000 writes:

    >> the problem with results=hide is that it suppresses everything. I just
    >> need Sweave to suppress strings ending in '\r'...


    Wolfi> Dear Ernest,

    Wolfi> IMHO it is good practice to make the printing of these progress reports 
    Wolfi> ("sweep 4 of 1024\r") optional and produce them only if the user calls 
    Wolfi> your function with, say, "verbose=TRUE", 

I strongly agree.

    Wolfi> and furthermore set the default value of the
    Wolfi> 'verbose' argument to "verbose=interactive()".

or -- typically my choice -- to  'verbose = getOption("verbose")

Martin Maechler, ETH Zurich

    Wolfi> Best wishes
    Wolfi> Wolfgang

 [............]

    >>> Ernest Turro wrote:
    >>>> Dear all,
    >>>> I have a code chunk in my Rnw file that, when executed, outputs  
    >>>> carriage return characters ('\r') to inform on the progress (e.g.  
    >>>> "sweep 4 of 1024\r"). But Sweave interprets this as a newline  
    >>>> character, and therefore I get countless pages of output in my  
    >>>> vignette where I only really want one line. Any ideas?
    >>>> Thanks
    >>>> E


From knoblauch at lyon.inserm.fr  Mon Mar 19 19:30:37 2007
From: knoblauch at lyon.inserm.fr (Ken Knoblauch)
Date: Mon, 19 Mar 2007 17:30:37 -0100 (CET)
Subject: [Rd] Having rbind dispatch to a different method than data.frame
 with arguments inheriting from data.frame
Message-ID: <50631.194.57.165.22.1174321837.squirrel@webmail.lyon.inserm.fr>


I have defined an S3 class that inherits from data.frame.  It has
some additional attributes and a particular structure that a modeling
function that I wrote require.   I want to write an rbind
method for this class which will combine the attributes correctly
as well as the data.frame components.  But the help page for
rbind indicates

Note that this algorithm can result in calling the data frame method if
the arguments are all either data frames or vectors

and indeed, the data.frame method is called unless I explicitly
invoke

rbind.mymethod(mm1, mm2)

How can I get dispatch to mymethod rather than data.frame?

I can imagine stripping the data.frame class before the call,
but this seems awkward and I am hoping that there is a better way.

Thank you.



-- 
Ken Knoblauch
Inserm U846
Institut Cellule Souche et Cerveau
D?partement Neurosciences Int?gratives
18 avenue du Doyen L?pine
69500 Bron
France
tel: +33 (0)4 72 91 34 77
fax: +33 (0)4 72 91 34 61
portable: +33 (0)6 84 10 64 10
http://www.pizzerialesgemeaux.com/u846/


From ripley at stats.ox.ac.uk  Tue Mar 20 09:36:58 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 20 Mar 2007 08:36:58 +0000 (GMT)
Subject: [Rd] -std=c99 and inline semantics
In-Reply-To: <45FEF6C5.1070900@santafe.edu>
References: <45FEF6C5.1070900@santafe.edu>
Message-ID: <Pine.LNX.4.64.0703200826390.3114@auk.stats>

As even 4.2.0 is not released yet, we will make changes at an appropriate 
time.  The GNU and C99 semantics for 'inline' are known to be 
incompatible.

>From src/include/Rinlinedfuns.h:

/* this header is always to be included from others.
    It is only called if COMPILING_R is defined (in util.c) or
    from GNU C systems.

    There are different conventions for inlining across compilation units.
    We pro tem only use the GCC one.  See
    http://www.greenend.org.uk/rjk/2003/03/inline.html
*/

and note the 'pro tem'.

On Mon, 19 Mar 2007, Marcus G. Daniels wrote:

> Hi,
>
> I noticed that with the GCC trunk (4.3.0), the semantics of "extern
> inline" have reversed.
> The net result is that R will build without the usual-stdc=gnu99 but it
> won't with it.
> Many multiple definitions result otherwise.
>
> Marcus
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From maechler at stat.math.ethz.ch  Tue Mar 20 10:17:02 2007
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 20 Mar 2007 10:17:02 +0100
Subject: [Rd] nclass.scott() and nclass.FD()   {Re: [R] truehist bug?}
In-Reply-To: <17919.37372.611766.569270@stat.math.ethz.ch>
References: <45FF78EA.5060205@ms.unimelb.edu.au>
	<17919.37372.611766.569270@stat.math.ethz.ch>
Message-ID: <17919.42638.718240.656427@stat.math.ethz.ch>

[This has become entirely a topic for 'R-devel' hence, I'm
 diverting to there keeping R-help once; please follow-up
 only to R-devel ]

>>>>> "MM" == Martin Maechler <maechler at stat.math.ethz.ch>
>>>>>     on Tue, 20 Mar 2007 08:49:16 +0100 writes:

>>>>> "Gad" == Gad Abraham <g.abraham at ms.unimelb.edu.au>
>>>>>     on Tue, 20 Mar 2007 17:02:18 +1100 writes:

    Gad> Hi,
    Gad> Is this a bug in truehist()?

    >>> library(MASS)
    >>> x <- rep(1, 10)
    >>> truehist(x)
    Gad> Error in pretty(data, nbins) : invalid 'n' value

    MM> You get something similar though slightly more helpful
    MM> from
    MM>    hist(x, "scott")

    MM> which then uses the same method for determining the number of bins /
    MM> classes for the histogram.

    MM> I'd say the main "bug" is in   
    MM> nclass.scott()   [ and  also nclass.FD() ]

    MM> which do not work when  var(x) == 0  as in this case.
    MM> One could argue that  

    MM> 1) truehist(x) should not use "scott" as
    MM> default when var(x) == 0   {hence a buglet in truehist()}

    MM> and either

    MM> 2) both hist() and truehist() should produce a better error
    MM> message when "scott" (or "FD") is used explicitly and var(x) == 0

    MM> or, rather IMO,

    MM> 3) nclass.scott(x) and nclass.FD(x) should be extended to return a 
    MM> non-negative integer even when  var(x) == 0

after some further thought,
I'm proposing to adopt '3)'  {only; '1)' becomes unneeded}
with the following new code  which is back-compatible for the
case where 'h > 0' and does something reasonable for the case h == 0 :

nclass.scott <- function(x)
{
    h <- 3.5 * sqrt(stats::var(x)) * length(x)^(-1/3)
    if(h > 0) ceiling(diff(range(x))/h) else 1L
}

nclass.FD <- function(x)
{
    h <- stats::IQR(x)
    if(h == 0) h <- stats::mad(x, constant = 2) # c=2: consistent with IQR
    if (h > 0) ceiling(diff(range(x))/(2 * h * length(x)^(-1/3))) else 1L
}


Martin


From termcc at googlemail.com  Tue Mar 20 11:36:09 2007
From: termcc at googlemail.com (Thomas McCallum)
Date: Tue, 20 Mar 2007 10:36:09 +0000
Subject: [Rd] Symbol and Ellipsis problems
Message-ID: <5a7daaf70703200336i7889cf8ft8be3b145750fcdac@mail.gmail.com>

Hi Everyone,

When I have a load of functions which have various arguments passed
via the ellipsis argument it keeps on assigning them as symbol making
them unusable to the function.  My current work around involves using
do.call but this is rather cumbersome.

Does anyone know why it suddenly changes the types to symbol and if
there is a way to get the actual data pointed to by the symbol? (I
have tried eval but that does not work and most functions just treat a
symbol as a string).

( An example which shows the type conversion is given below with the
output - the key is the following "dataX=data" which makes the object
data passed as a symbol and not the actual data).

Many thanks

Tom

====EXAMPLE CODE====
data=c(1,2,3,4,5,6,7,8,9);

x <- function( ... ) {
        args <- list();
        extras <- match.call(expand.dots = FALSE)$...;
        for( i in names(extras) ) {
                args[[ i ]] <- extras[[ i ]];
                print(args[[i]]);
                print(typeof(extras[[i]]));
        }


}

cat("TYPE OF DATA:");
print(typeof(data));
x(dataX=data);


From murdoch at stats.uwo.ca  Tue Mar 20 11:47:21 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue, 20 Mar 2007 06:47:21 -0400
Subject: [Rd] Symbol and Ellipsis problems
In-Reply-To: <5a7daaf70703200336i7889cf8ft8be3b145750fcdac@mail.gmail.com>
References: <5a7daaf70703200336i7889cf8ft8be3b145750fcdac@mail.gmail.com>
Message-ID: <45FFBBB9.5030902@stats.uwo.ca>

On 3/20/2007 6:36 AM, Thomas McCallum wrote:
> Hi Everyone,
> 
> When I have a load of functions which have various arguments passed
> via the ellipsis argument it keeps on assigning them as symbol making
> them unusable to the function.  My current work around involves using
> do.call but this is rather cumbersome.
> 
> Does anyone know why it suddenly changes the types to symbol and if
> there is a way to get the actual data pointed to by the symbol? (I
> have tried eval but that does not work and most functions just treat a
> symbol as a string).
> 
> ( An example which shows the type conversion is given below with the
> output - the key is the following "dataX=data" which makes the object
> data passed as a symbol and not the actual data).

match.call() doesn't evaluate the args, it just shows you the 
unevaluated call.  If you print your "extras" variable in your function, 
you'll see

$dataX
data

because you called the function with dataX=data.  If you'd called it as
x(dataY = 1+2) you'd see

1 + 2
[1] "language"

for the same reason.

If you want to evaluate the ... args, use list(...) instead of match.call.

Duncan Murdoch

> Many thanks
> 
> Tom
> 
> ====EXAMPLE CODE====
> data=c(1,2,3,4,5,6,7,8,9);
> 
> x <- function( ... ) {
>         args <- list();
>         extras <- match.call(expand.dots = FALSE)$...;
>         for( i in names(extras) ) {
>                 args[[ i ]] <- extras[[ i ]];
>                 print(args[[i]]);
>                 print(typeof(extras[[i]]));
>         }
> 
> 
> }
> 
> cat("TYPE OF DATA:");
> print(typeof(data));
> x(dataX=data);
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From ernest.turro at ic.ac.uk  Tue Mar 20 12:53:40 2007
From: ernest.turro at ic.ac.uk (Ernest Turro)
Date: Tue, 20 Mar 2007 11:53:40 +0000
Subject: [Rd] Carriage returns and Sweave output
In-Reply-To: <17919.37635.203919.143033@stat.math.ethz.ch>
References: <30B148B0-0C89-49BA-AEC9-160A6BA72D56@ic.ac.uk>
	<45FEA2FB.7030105@ebi.ac.uk>
	<DC49D83C-7739-4CEA-A837-0200D658BED7@ic.ac.uk>
	<45FEAE58.4030208@ebi.ac.uk>
	<17919.37635.203919.143033@stat.math.ethz.ch>
Message-ID: <E8DDD4AC-6B1B-449E-A805-E99B52EAA498@ic.ac.uk>


On 20 Mar 2007, at 07:53, Martin Maechler wrote:

>>>>>> "Wolfi" == Wolfgang Huber <huber at ebi.ac.uk>
>>>>>>     on Mon, 19 Mar 2007 15:38:00 +0000 writes:
>
>>> the problem with results=hide is that it suppresses everything. I  
>>> just
>>> need Sweave to suppress strings ending in '\r'...
>
>
>     Wolfi> Dear Ernest,
>
>     Wolfi> IMHO it is good practice to make the printing of these  
> progress reports
>     Wolfi> ("sweep 4 of 1024\r") optional and produce them only if  
> the user calls
>     Wolfi> your function with, say, "verbose=TRUE",
>
> I strongly agree.
>
>     Wolfi> and furthermore set the default value of the
>     Wolfi> 'verbose' argument to "verbose=interactive()".
>
> or -- typically my choice -- to  'verbose = getOption("verbose")
>
> Martin Maechler, ETH Zurich
>
>     Wolfi> Best wishes
>     Wolfi> Wolfgang
>
>  [............]
>

I agree that users should be free to choose the level of verbosity.  
Here, I want to show the verbose output and print it onto the tex  
file using Sweave to give users a good idea of what happens. What I  
don't want is countless lines being printed because \r is being  
interpreted as \n ...

Thanks,

Ernest






>>>> Ernest Turro wrote:
>>>>> Dear all,
>>>>> I have a code chunk in my Rnw file that, when executed, outputs
>>>>> carriage return characters ('\r') to inform on the progress (e.g.
>>>>> "sweep 4 of 1024\r"). But Sweave interprets this as a newline
>>>>> character, and therefore I get countless pages of output in my
>>>>> vignette where I only really want one line. Any ideas?
>>>>> Thanks
>>>>> E


From bates at stat.wisc.edu  Tue Mar 20 14:24:33 2007
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 20 Mar 2007 08:24:33 -0500
Subject: [Rd] Carriage returns and Sweave output
In-Reply-To: <E8DDD4AC-6B1B-449E-A805-E99B52EAA498@ic.ac.uk>
References: <30B148B0-0C89-49BA-AEC9-160A6BA72D56@ic.ac.uk>
	<45FEA2FB.7030105@ebi.ac.uk>
	<DC49D83C-7739-4CEA-A837-0200D658BED7@ic.ac.uk>
	<45FEAE58.4030208@ebi.ac.uk>
	<17919.37635.203919.143033@stat.math.ethz.ch>
	<E8DDD4AC-6B1B-449E-A805-E99B52EAA498@ic.ac.uk>
Message-ID: <40e66e0b0703200624o2e4e2f36v7a65a7583f866d80@mail.gmail.com>

On 3/20/07, Ernest Turro <ernest.turro at ic.ac.uk> wrote:
>
> On 20 Mar 2007, at 07:53, Martin Maechler wrote:
>
> >>>>>> "Wolfi" == Wolfgang Huber <huber at ebi.ac.uk>
> >>>>>>     on Mon, 19 Mar 2007 15:38:00 +0000 writes:
> >
> >>> the problem with results=hide is that it suppresses everything. I
> >>> just
> >>> need Sweave to suppress strings ending in '\r'...
> >
> >
> >     Wolfi> Dear Ernest,
> >
> >     Wolfi> IMHO it is good practice to make the printing of these
> > progress reports
> >     Wolfi> ("sweep 4 of 1024\r") optional and produce them only if
> > the user calls
> >     Wolfi> your function with, say, "verbose=TRUE",
> >
> > I strongly agree.
> >
> >     Wolfi> and furthermore set the default value of the
> >     Wolfi> 'verbose' argument to "verbose=interactive()".
> >
> > or -- typically my choice -- to  'verbose = getOption("verbose")
> >
> > Martin Maechler, ETH Zurich
> >
> >     Wolfi> Best wishes
> >     Wolfi> Wolfgang
> >
> >  [............]
> >
>
> I agree that users should be free to choose the level of verbosity.
> Here, I want to show the verbose output and print it onto the tex
> file using Sweave to give users a good idea of what happens. What I
> don't want is countless lines being printed because \r is being
> interpreted as \n ...

In cases like this capture.output() is your friend.  Write one code
chunk with results=hide,echo=FALSE that uses capture.output to trap
the desired output as character strings then use string manipulation
functions to do the desired replacement.  A second code chunk with
eval=FALSE shows the code that apparently produces the output and a
third code chunk with echo=FALSE uses cat on the manipulated character
strings with quote=FALSE to show what apparently was produced.

> >>>> Ernest Turro wrote:
> >>>>> Dear all,
> >>>>> I have a code chunk in my Rnw file that, when executed, outputs
> >>>>> carriage return characters ('\r') to inform on the progress (e.g.
> >>>>> "sweep 4 of 1024\r"). But Sweave interprets this as a newline
> >>>>> character, and therefore I get countless pages of output in my
> >>>>> vignette where I only really want one line. Any ideas?
> >>>>> Thanks
> >>>>> E
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From ml-it-r-devel at epigenomics.com  Tue Mar 20 16:11:58 2007
From: ml-it-r-devel at epigenomics.com (ml-it-r-devel at epigenomics.com)
Date: Tue, 20 Mar 2007 16:11:58 +0100
Subject: [Rd] R 2.5.0 devel try issue in conjuntion with S4 method
	dispatch
In-Reply-To: <45FBAEE4.7070908@biostat.ku.dk>
References: <45F98B1D.2060501@epigenomics.com>	<26643.89.62.105.96.1174087026.squirrel@gk.uu.epigenomics.net>
	<45FBAEE4.7070908@biostat.ku.dk>
Message-ID: <45FFF9BE.9030701@epigenomics.com>


Peter Dalgaard wrote:
> Matthias Burger wrote:
>> Hi Seth,
>>   
> ....
[...]
>>   
> I have just committed my variation of Seth's patch, so please check the 
> current r-devel too.

For the record:
With R 2.5.0 devel (2007-03-18 r40854)
the issue I was concerned about has been resolved.

Thanks to all of you!

Regards,

  Matthias

> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 


-- 
Matthias Burger                     Project Manager/ Biostatistician
Epigenomics AG    Kleine Praesidentenstr. 1    10178 Berlin, Germany
phone:+49-30-24345-371                          fax:+49-30-24345-555
http://www.epigenomics.com           matthias.burger at epigenomics.com
--
Epigenomics AG Berlin           Amtsgericht Charlottenburg HRB 75861
Vorstand:   Geert Nygaard (CEO/Vorsitzender),  Dr. Kurt Berlin (CSO)
              Oliver Schacht PhD (CFO),  Christian Piepenbrock (COO)
Aufsichtsrat:   Prof. Dr. Dr. hc. Rolf Krebs (Chairman/Vorsitzender)


From charles.dupont at vanderbilt.edu  Tue Mar 20 16:19:11 2007
From: charles.dupont at vanderbilt.edu (charles.dupont at vanderbilt.edu)
Date: Tue, 20 Mar 2007 16:19:11 +0100 (CET)
Subject: [Rd] wishlist -- Fix for major format.pval limitation (PR#9574)
Message-ID: <20070320151911.E591E5ACCE@slim.kubism.ku.dk>

Full_Name: Charles Dupont
Version: 2.4.1
OS: linux 2.6.18
Submission from: (NULL) (160.129.129.136)


'format.pval' has a major limitation in its implementation. For example
suppose a person had a vector like 'a' and the error being ?0.001.

    > a <- c(0.1, 0.3, 0.4, 0.5, 0.3, 0.0001)
    > format.pval(a, eps=0.01)

If that person wants to have the 'format.pval' output with 2 digits always
showing (like passing nsmall=2 to 'format'). That output would look like 
this.

    [1] "0.10"   "0.30"   "0.40"   "0.50"   "0.30"   "<0.01"

That output is currently impossible because format.pval can only 
produce output like this.

    [1] "0.1"    "0.3"    "0.4"    "0.5"    "0.3"    "<0.01"


---------------------------------------------------------------
a <- c(0.1, 0.3, 0.4, 0.5, 0.3, 0.0001)
format.pval(a, eps=0.01)


From murdoch at stats.uwo.ca  Tue Mar 20 17:36:56 2007
From: murdoch at stats.uwo.ca (murdoch at stats.uwo.ca)
Date: Tue, 20 Mar 2007 17:36:56 +0100 (CET)
Subject: [Rd] wishlist -- Fix for major format.pval limitation (PR#9574)
Message-ID: <20070320163656.2B81F5ABEB@slim.kubism.ku.dk>

On 3/20/2007 11:19 AM, charles.dupont at vanderbilt.edu wrote:
> Full_Name: Charles Dupont
> Version: 2.4.1
> OS: linux 2.6.18
> Submission from: (NULL) (160.129.129.136)
> 
> 
> 'format.pval' has a major limitation in its implementation. For example
> suppose a person had a vector like 'a' and the error being ?0.001.
> 
>     > a <- c(0.1, 0.3, 0.4, 0.5, 0.3, 0.0001)
>     > format.pval(a, eps=0.01)
> 
> If that person wants to have the 'format.pval' output with 2 digits always
> showing (like passing nsmall=2 to 'format'). That output would look like 
> this.
> 
>     [1] "0.10"   "0.30"   "0.40"   "0.50"   "0.30"   "<0.01"
> 
> That output is currently impossible because format.pval can only 
> produce output like this.
> 
>     [1] "0.1"    "0.3"    "0.4"    "0.5"    "0.3"    "<0.01"
> 
> 
> ---------------------------------------------------------------
> a <- c(0.1, 0.3, 0.4, 0.5, 0.3, 0.0001)
> format.pval(a, eps=0.01)

But there's a very easy workaround:

format.pval(c(0.12, a), eps=0.01)[-1]

gives you what you want (because the 0.12 forces two decimal place 
display on all values, and then the [-1] removes it).

Duncan Murdoch


From ggrothendieck at gmail.com  Tue Mar 20 17:44:51 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 20 Mar 2007 12:44:51 -0400
Subject: [Rd] wishlist -- Fix for major format.pval limitation (PR#9574)
In-Reply-To: <20070320163656.2B81F5ABEB@slim.kubism.ku.dk>
References: <20070320163656.2B81F5ABEB@slim.kubism.ku.dk>
Message-ID: <971536df0703200944x62af2966yf11b9b3ab6af3d11@mail.gmail.com>

On 3/20/07, murdoch at stats.uwo.ca <murdoch at stats.uwo.ca> wrote:
> On 3/20/2007 11:19 AM, charles.dupont at vanderbilt.edu wrote:
> > Full_Name: Charles Dupont
> > Version: 2.4.1
> > OS: linux 2.6.18
> > Submission from: (NULL) (160.129.129.136)
> >
> >
> > 'format.pval' has a major limitation in its implementation. For example
> > suppose a person had a vector like 'a' and the error being ?0.001.
> >
> >     > a <- c(0.1, 0.3, 0.4, 0.5, 0.3, 0.0001)
> >     > format.pval(a, eps=0.01)
> >
> > If that person wants to have the 'format.pval' output with 2 digits always
> > showing (like passing nsmall=2 to 'format'). That output would look like
> > this.
> >
> >     [1] "0.10"   "0.30"   "0.40"   "0.50"   "0.30"   "<0.01"
> >
> > That output is currently impossible because format.pval can only
> > produce output like this.
> >
> >     [1] "0.1"    "0.3"    "0.4"    "0.5"    "0.3"    "<0.01"
> >
> >
> > ---------------------------------------------------------------
> > a <- c(0.1, 0.3, 0.4, 0.5, 0.3, 0.0001)
> > format.pval(a, eps=0.01)
>
> But there's a very easy workaround:
>
> format.pval(c(0.12, a), eps=0.01)[-1]
>
> gives you what you want (because the 0.12 forces two decimal place
> display on all values, and then the [-1] removes it).
>

Clever, but the problem would be that summary.lm, etc. call format.pval so the
user does not have a chance to do that.


From murdoch at stats.uwo.ca  Tue Mar 20 18:17:05 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue, 20 Mar 2007 13:17:05 -0400
Subject: [Rd] wishlist -- Fix for major format.pval limitation (PR#9574)
In-Reply-To: <971536df0703200944x62af2966yf11b9b3ab6af3d11@mail.gmail.com>
References: <20070320163656.2B81F5ABEB@slim.kubism.ku.dk>
	<971536df0703200944x62af2966yf11b9b3ab6af3d11@mail.gmail.com>
Message-ID: <46001711.6090008@stats.uwo.ca>

On 3/20/2007 12:44 PM, Gabor Grothendieck wrote:
> On 3/20/07, murdoch at stats.uwo.ca <murdoch at stats.uwo.ca> wrote:
>> On 3/20/2007 11:19 AM, charles.dupont at vanderbilt.edu wrote:
>> > Full_Name: Charles Dupont
>> > Version: 2.4.1
>> > OS: linux 2.6.18
>> > Submission from: (NULL) (160.129.129.136)
>> >
>> >
>> > 'format.pval' has a major limitation in its implementation. For example
>> > suppose a person had a vector like 'a' and the error being ?0.001.
>> >
>> >     > a <- c(0.1, 0.3, 0.4, 0.5, 0.3, 0.0001)
>> >     > format.pval(a, eps=0.01)
>> >
>> > If that person wants to have the 'format.pval' output with 2 digits always
>> > showing (like passing nsmall=2 to 'format'). That output would look like
>> > this.
>> >
>> >     [1] "0.10"   "0.30"   "0.40"   "0.50"   "0.30"   "<0.01"
>> >
>> > That output is currently impossible because format.pval can only
>> > produce output like this.
>> >
>> >     [1] "0.1"    "0.3"    "0.4"    "0.5"    "0.3"    "<0.01"
>> >
>> >
>> > ---------------------------------------------------------------
>> > a <- c(0.1, 0.3, 0.4, 0.5, 0.3, 0.0001)
>> > format.pval(a, eps=0.01)
>>
>> But there's a very easy workaround:
>>
>> format.pval(c(0.12, a), eps=0.01)[-1]
>>
>> gives you what you want (because the 0.12 forces two decimal place
>> display on all values, and then the [-1] removes it).
>>
> 
> Clever, but the problem would be that summary.lm, etc. call format.pval so the
> user does not have a chance to do that.

I don't see how this is relevant.  summary.lm doesn't let you pass a new 
eps value either.  Adding an "nsmall=2" argument to format.pval wouldn't 
help with the display in summary.lm.

I suppose we could track down every use of format.pval in every function 
in every package and add nsmall and eps as arguments to each of them, 
but that's just ridiculous.  People should accept the fact that R 
doesn't produce publication quality text, it just provides you with ways 
to produce that yourself.

Duncan Murdoch


From ggrothendieck at gmail.com  Tue Mar 20 18:40:42 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 20 Mar 2007 13:40:42 -0400
Subject: [Rd] wishlist -- Fix for major format.pval limitation (PR#9574)
In-Reply-To: <46001711.6090008@stats.uwo.ca>
References: <20070320163656.2B81F5ABEB@slim.kubism.ku.dk>
	<971536df0703200944x62af2966yf11b9b3ab6af3d11@mail.gmail.com>
	<46001711.6090008@stats.uwo.ca>
Message-ID: <971536df0703201040u45d3a9a2u4a08959455a8d997@mail.gmail.com>

On 3/20/07, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> On 3/20/2007 12:44 PM, Gabor Grothendieck wrote:
> > On 3/20/07, murdoch at stats.uwo.ca <murdoch at stats.uwo.ca> wrote:
> >> On 3/20/2007 11:19 AM, charles.dupont at vanderbilt.edu wrote:
> >> > Full_Name: Charles Dupont
> >> > Version: 2.4.1
> >> > OS: linux 2.6.18
> >> > Submission from: (NULL) (160.129.129.136)
> >> >
> >> >
> >> > 'format.pval' has a major limitation in its implementation. For example
> >> > suppose a person had a vector like 'a' and the error being ?0.001.
> >> >
> >> >     > a <- c(0.1, 0.3, 0.4, 0.5, 0.3, 0.0001)
> >> >     > format.pval(a, eps=0.01)
> >> >
> >> > If that person wants to have the 'format.pval' output with 2 digits always
> >> > showing (like passing nsmall=2 to 'format'). That output would look like
> >> > this.
> >> >
> >> >     [1] "0.10"   "0.30"   "0.40"   "0.50"   "0.30"   "<0.01"
> >> >
> >> > That output is currently impossible because format.pval can only
> >> > produce output like this.
> >> >
> >> >     [1] "0.1"    "0.3"    "0.4"    "0.5"    "0.3"    "<0.01"
> >> >
> >> >
> >> > ---------------------------------------------------------------
> >> > a <- c(0.1, 0.3, 0.4, 0.5, 0.3, 0.0001)
> >> > format.pval(a, eps=0.01)
> >>
> >> But there's a very easy workaround:
> >>
> >> format.pval(c(0.12, a), eps=0.01)[-1]
> >>
> >> gives you what you want (because the 0.12 forces two decimal place
> >> display on all values, and then the [-1] removes it).
> >>
> >
> > Clever, but the problem would be that summary.lm, etc. call format.pval so the
> > user does not have a chance to do that.
>
> I don't see how this is relevant.  summary.lm doesn't let you pass a new
> eps value either.  Adding an "nsmall=2" argument to format.pval wouldn't
> help with the display in summary.lm.
>
> I suppose we could track down every use of format.pval in every function
> in every package and add nsmall and eps as arguments to each of them,
> but that's just ridiculous.  People should accept the fact that R
> doesn't produce publication quality text, it just provides you with ways
> to produce that yourself.
>
> Duncan Murdoch
>

You are right in terms of my example which was not applicable but I
think in general that format.pval is used from within other routines rather than
directly by the user so the user may not have a chance to massage it
directly.


From murdoch at stats.uwo.ca  Tue Mar 20 19:26:26 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue, 20 Mar 2007 14:26:26 -0400
Subject: [Rd] wishlist -- Fix for major format.pval limitation (PR#9574)
In-Reply-To: <971536df0703201040u45d3a9a2u4a08959455a8d997@mail.gmail.com>
References: <20070320163656.2B81F5ABEB@slim.kubism.ku.dk>	
	<971536df0703200944x62af2966yf11b9b3ab6af3d11@mail.gmail.com>	
	<46001711.6090008@stats.uwo.ca>
	<971536df0703201040u45d3a9a2u4a08959455a8d997@mail.gmail.com>
Message-ID: <46002752.3070704@stats.uwo.ca>

On 3/20/2007 1:40 PM, Gabor Grothendieck wrote:
> On 3/20/07, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
>> On 3/20/2007 12:44 PM, Gabor Grothendieck wrote:
>> > On 3/20/07, murdoch at stats.uwo.ca <murdoch at stats.uwo.ca> wrote:
>> >> On 3/20/2007 11:19 AM, charles.dupont at vanderbilt.edu wrote:
>> >> > Full_Name: Charles Dupont
>> >> > Version: 2.4.1
>> >> > OS: linux 2.6.18
>> >> > Submission from: (NULL) (160.129.129.136)
>> >> >
>> >> >
>> >> > 'format.pval' has a major limitation in its implementation. For example
>> >> > suppose a person had a vector like 'a' and the error being ?0.001.
>> >> >
>> >> >     > a <- c(0.1, 0.3, 0.4, 0.5, 0.3, 0.0001)
>> >> >     > format.pval(a, eps=0.01)
>> >> >
>> >> > If that person wants to have the 'format.pval' output with 2 digits always
>> >> > showing (like passing nsmall=2 to 'format'). That output would look like
>> >> > this.
>> >> >
>> >> >     [1] "0.10"   "0.30"   "0.40"   "0.50"   "0.30"   "<0.01"
>> >> >
>> >> > That output is currently impossible because format.pval can only
>> >> > produce output like this.
>> >> >
>> >> >     [1] "0.1"    "0.3"    "0.4"    "0.5"    "0.3"    "<0.01"
>> >> >
>> >> >
>> >> > ---------------------------------------------------------------
>> >> > a <- c(0.1, 0.3, 0.4, 0.5, 0.3, 0.0001)
>> >> > format.pval(a, eps=0.01)
>> >>
>> >> But there's a very easy workaround:
>> >>
>> >> format.pval(c(0.12, a), eps=0.01)[-1]
>> >>
>> >> gives you what you want (because the 0.12 forces two decimal place
>> >> display on all values, and then the [-1] removes it).
>> >>
>> >
>> > Clever, but the problem would be that summary.lm, etc. call format.pval so the
>> > user does not have a chance to do that.
>>
>> I don't see how this is relevant.  summary.lm doesn't let you pass a new
>> eps value either.  Adding an "nsmall=2" argument to format.pval wouldn't
>> help with the display in summary.lm.
>>
>> I suppose we could track down every use of format.pval in every function
>> in every package and add nsmall and eps as arguments to each of them,
>> but that's just ridiculous.  People should accept the fact that R
>> doesn't produce publication quality text, it just provides you with ways
>> to produce that yourself.
>>
>> Duncan Murdoch
>>
> 
> You are right in terms of my example which was not applicable but I
> think in general that format.pval is used from within other routines rather than
> directly by the user so the user may not have a chance to massage it
> directly.

Right, but this means that it is more or less useless to change the 
argument list for format.pvals in the way Charles suggested, because all 
of the existing uses of it would ignore the new parameters.

It would not be so difficult to change the behaviour of format.pvals so 
that for example "digits=2" implied the equivalent of "nsmall=2", but I 
don't think that's a universally desirable change.

The difficulty here is that different people have different tastes for 
presentation-quality text.  Not everyone would agree that the version 
with trailing zeros is preferable to the one without.  R should be 
flexible enough to allow people to customize their displays, but not 
necessarily by having every print method flexible enough to satisfy 
every user:  sometimes users need to construct their own output formats.

Duncan Murdoch


From h.wickham at gmail.com  Tue Mar 20 19:42:34 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Tue, 20 Mar 2007 13:42:34 -0500
Subject: [Rd] wishlist -- Fix for major format.pval limitation (PR#9574)
In-Reply-To: <46002752.3070704@stats.uwo.ca>
References: <20070320163656.2B81F5ABEB@slim.kubism.ku.dk>
	<971536df0703200944x62af2966yf11b9b3ab6af3d11@mail.gmail.com>
	<46001711.6090008@stats.uwo.ca>
	<971536df0703201040u45d3a9a2u4a08959455a8d997@mail.gmail.com>
	<46002752.3070704@stats.uwo.ca>
Message-ID: <f8e6ff050703201142q405d8b09ke282d78d838d120d@mail.gmail.com>

On 3/20/07, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> On 3/20/2007 1:40 PM, Gabor Grothendieck wrote:
> > On 3/20/07, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> >> On 3/20/2007 12:44 PM, Gabor Grothendieck wrote:
> >> > On 3/20/07, murdoch at stats.uwo.ca <murdoch at stats.uwo.ca> wrote:
> >> >> On 3/20/2007 11:19 AM, charles.dupont at vanderbilt.edu wrote:
> >> >> > Full_Name: Charles Dupont
> >> >> > Version: 2.4.1
> >> >> > OS: linux 2.6.18
> >> >> > Submission from: (NULL) (160.129.129.136)
> >> >> >
> >> >> >
> >> >> > 'format.pval' has a major limitation in its implementation. For example
> >> >> > suppose a person had a vector like 'a' and the error being ?0.001.
> >> >> >
> >> >> >     > a <- c(0.1, 0.3, 0.4, 0.5, 0.3, 0.0001)
> >> >> >     > format.pval(a, eps=0.01)
> >> >> >
> >> >> > If that person wants to have the 'format.pval' output with 2 digits always
> >> >> > showing (like passing nsmall=2 to 'format'). That output would look like
> >> >> > this.
> >> >> >
> >> >> >     [1] "0.10"   "0.30"   "0.40"   "0.50"   "0.30"   "<0.01"
> >> >> >
> >> >> > That output is currently impossible because format.pval can only
> >> >> > produce output like this.
> >> >> >
> >> >> >     [1] "0.1"    "0.3"    "0.4"    "0.5"    "0.3"    "<0.01"
> >> >> >
> >> >> >
> >> >> > ---------------------------------------------------------------
> >> >> > a <- c(0.1, 0.3, 0.4, 0.5, 0.3, 0.0001)
> >> >> > format.pval(a, eps=0.01)
> >> >>
> >> >> But there's a very easy workaround:
> >> >>
> >> >> format.pval(c(0.12, a), eps=0.01)[-1]
> >> >>
> >> >> gives you what you want (because the 0.12 forces two decimal place
> >> >> display on all values, and then the [-1] removes it).
> >> >>
> >> >
> >> > Clever, but the problem would be that summary.lm, etc. call format.pval so the
> >> > user does not have a chance to do that.
> >>
> >> I don't see how this is relevant.  summary.lm doesn't let you pass a new
> >> eps value either.  Adding an "nsmall=2" argument to format.pval wouldn't
> >> help with the display in summary.lm.
> >>
> >> I suppose we could track down every use of format.pval in every function
> >> in every package and add nsmall and eps as arguments to each of them,
> >> but that's just ridiculous.  People should accept the fact that R
> >> doesn't produce publication quality text, it just provides you with ways
> >> to produce that yourself.
> >>
> >> Duncan Murdoch
> >>
> >
> > You are right in terms of my example which was not applicable but I
> > think in general that format.pval is used from within other routines rather than
> > directly by the user so the user may not have a chance to massage it
> > directly.
>
> Right, but this means that it is more or less useless to change the
> argument list for format.pvals in the way Charles suggested, because all
> of the existing uses of it would ignore the new parameters.
>
> It would not be so difficult to change the behaviour of format.pvals so
> that for example "digits=2" implied the equivalent of "nsmall=2", but I
> don't think that's a universally desirable change.
>
> The difficulty here is that different people have different tastes for
> presentation-quality text.  Not everyone would agree that the version
> with trailing zeros is preferable to the one without.  R should be
> flexible enough to allow people to customize their displays, but not
> necessarily by having every print method flexible enough to satisfy
> every user:  sometimes users need to construct their own output formats.

It would be interesting to take a similar approach to grid - return a
table object which could then be tweaked as necessary, rather than
having to build everything up from scratch.  A very big job though!

Hadley


From ernest.turro at ic.ac.uk  Tue Mar 20 19:58:51 2007
From: ernest.turro at ic.ac.uk (Ernest Turro)
Date: Tue, 20 Mar 2007 18:58:51 +0000
Subject: [Rd] PKG_CFLAGS/CFLAGS and PKG_CXXFLAGS/CXXFLAGS
Message-ID: <438FA5BB-AA84-4E61-8D3F-FDCA637CDD53@ic.ac.uk>

Why is it that R places CFLAGS after PKG_CFLAGS and not before when  
compiling a package (e.g. through R CMD build pkg)? This can be  
problematic if, for instance, you want to use -O3, but -O2 is in  
R_HOME/etc/Makeconf. If -O2 (in CFLAGS) appears after -O3 (in  
PKG_CFLAGS), you are left with what you didn't want: -O2.

In R-exts, it says that "Flags which are set in file etc/Makeconf can  
be overridden by the environment variable MAKEFLAGS (at least for  
systems using GNU make), as in (Bourne shell syntax)" but this  
doesn't work if I set either MAKEFLAGS or CFLAGS/CXXFLAGS in my  
configure.ac script or package Makevars.

Does anyone have any ideas on how to reliably override the default  
CFLAGS/CXXFLAGS given in Makeconf?

Many thanks,

Ernest


From ernest.turro at ic.ac.uk  Tue Mar 20 20:02:51 2007
From: ernest.turro at ic.ac.uk (Ernest Turro)
Date: Tue, 20 Mar 2007 19:02:51 +0000
Subject: [Rd] Carriage returns and Sweave output
In-Reply-To: <40e66e0b0703200624o2e4e2f36v7a65a7583f866d80@mail.gmail.com>
References: <30B148B0-0C89-49BA-AEC9-160A6BA72D56@ic.ac.uk>
	<45FEA2FB.7030105@ebi.ac.uk>
	<DC49D83C-7739-4CEA-A837-0200D658BED7@ic.ac.uk>
	<45FEAE58.4030208@ebi.ac.uk>
	<17919.37635.203919.143033@stat.math.ethz.ch>
	<E8DDD4AC-6B1B-449E-A805-E99B52EAA498@ic.ac.uk>
	<40e66e0b0703200624o2e4e2f36v7a65a7583f866d80@mail.gmail.com>
Message-ID: <E4A0E9A7-E9CA-46E1-B5D3-D7CCB4C53A6F@ic.ac.uk>


On 20 Mar 2007, at 13:24, Douglas Bates wrote:

> [snip]

> In cases like this capture.output() is your friend.  Write one code
> chunk with results=hide,echo=FALSE that uses capture.output to trap
> the desired output as character strings then use string manipulation
> functions to do the desired replacement.  A second code chunk with
> eval=FALSE shows the code that apparently produces the output and a
> third code chunk with echo=FALSE uses cat on the manipulated character
> strings with quote=FALSE to show what apparently was produced.

That is extremely helpful. Thanks very much Douglas.

Ernest


>
>> >>>> Ernest Turro wrote:
>> >>>>> Dear all,
>> >>>>> I have a code chunk in my Rnw file that, when executed, outputs
>> >>>>> carriage return characters ('\r') to inform on the progress  
>> (e.g.
>> >>>>> "sweep 4 of 1024\r"). But Sweave interprets this as a newline
>> >>>>> character, and therefore I get countless pages of output in my
>> >>>>> vignette where I only really want one line. Any ideas?
>> >>>>> Thanks
>> >>>>> E
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>


From khansen at stat.Berkeley.EDU  Tue Mar 20 22:32:08 2007
From: khansen at stat.Berkeley.EDU (Kasper Daniel Hansen)
Date: Tue, 20 Mar 2007 22:32:08 +0100
Subject: [Rd] PKG_CFLAGS/CFLAGS and PKG_CXXFLAGS/CXXFLAGS
In-Reply-To: <438FA5BB-AA84-4E61-8D3F-FDCA637CDD53@ic.ac.uk>
References: <438FA5BB-AA84-4E61-8D3F-FDCA637CDD53@ic.ac.uk>
Message-ID: <F2257117-F22F-4FA4-A74D-59C1D5E6C252@stat.berkeley.edu>


On Mar 20, 2007, at 7:58 PM, Ernest Turro wrote:

> Why is it that R places CFLAGS after PKG_CFLAGS and not before when
> compiling a package (e.g. through R CMD build pkg)? This can be
> problematic if, for instance, you want to use -O3, but -O2 is in
> R_HOME/etc/Makeconf. If -O2 (in CFLAGS) appears after -O3 (in
> PKG_CFLAGS), you are left with what you didn't want: -O2.
>
> In R-exts, it says that "Flags which are set in file etc/Makeconf can
> be overridden by the environment variable MAKEFLAGS (at least for
> systems using GNU make), as in (Bourne shell syntax)" but this
> doesn't work if I set either MAKEFLAGS or CFLAGS/CXXFLAGS in my
> configure.ac script or package Makevars.

In you example above you want to force the user to use a higher  
optimization flag. But (s)he may have very valid reasons for not  
doing so - and are you really sure that you are comfortable setting - 
O3 on _all_ platforms? Also -O. is GCC specific so it does not work  
for all compilers.

If a user really wants a super fast R (s)he will (should) compile it  
with -O3.

Having said that, I think it is problematic that one cannot   
_downgrade_ the optimization. I am maintaining a package including an  
external library (outside of my control) which does not work with -O2  
on some platforms, due to alignment problems.

> Does anyone have any ideas on how to reliably override the default
> CFLAGS/CXXFLAGS given in Makeconf?

I was given the following code some while ago by Simon Urbanek:

all: $(SHLIB)

MYCXXFLAGS=-O0

%.o: %.cpp
         $(CXX) $(ALL_CPPFLAGS) $(ALL_CXXFLAGS) $(MYCXXFLAGS) -c $< - 
o $@

(this is for C++, I imagine the syntax is straightforward for C). Put  
it in src/Makevars.

But as I said above, I think it is a bad idea to raise the  
optimization level for all users.

Kasper

> Many thanks,
>
> Ernest
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From ernest.turro at ic.ac.uk  Tue Mar 20 23:13:10 2007
From: ernest.turro at ic.ac.uk (Ernest Turro)
Date: Tue, 20 Mar 2007 22:13:10 +0000
Subject: [Rd] PKG_CFLAGS/CFLAGS and PKG_CXXFLAGS/CXXFLAGS
In-Reply-To: <F2257117-F22F-4FA4-A74D-59C1D5E6C252@stat.berkeley.edu>
References: <438FA5BB-AA84-4E61-8D3F-FDCA637CDD53@ic.ac.uk>
	<F2257117-F22F-4FA4-A74D-59C1D5E6C252@stat.berkeley.edu>
Message-ID: <136CD506-BE3D-4095-8132-A631306524E0@ic.ac.uk>


On 20 Mar 2007, at 21:32, Kasper Daniel Hansen wrote:

>
> On Mar 20, 2007, at 7:58 PM, Ernest Turro wrote:
>
>> Why is it that R places CFLAGS after PKG_CFLAGS and not before when
>> compiling a package (e.g. through R CMD build pkg)? This can be
>> problematic if, for instance, you want to use -O3, but -O2 is in
>> R_HOME/etc/Makeconf. If -O2 (in CFLAGS) appears after -O3 (in
>> PKG_CFLAGS), you are left with what you didn't want: -O2.
>>
>> In R-exts, it says that "Flags which are set in file etc/Makeconf can
>> be overridden by the environment variable MAKEFLAGS (at least for
>> systems using GNU make), as in (Bourne shell syntax)" but this
>> doesn't work if I set either MAKEFLAGS or CFLAGS/CXXFLAGS in my
>> configure.ac script or package Makevars.
>
> In you example above you want to force the user to use a higher  
> optimization flag. But (s)he may have very valid reasons for not  
> doing so - and are you really sure that you are comfortable setting  
> -O3 on _all_ platforms? Also -O. is GCC specific so it does not  
> work for all compilers.

My configure script checks for GCC before setting -O3 (and -ffast-math).

>
> If a user really wants a super fast R (s)he will (should) compile  
> it with -O3.

I'm compiling a MCMC simulation package. It is very intensive and so - 
O3  should definitely be the default level on systems with GCC.

>
> Having said that, I think it is problematic that one cannot   
> _downgrade_ the optimization. I am maintaining a package including  
> an external library (outside of my control) which does not work  
> with -O2 on some platforms, due to alignment problems.
>
>> Does anyone have any ideas on how to reliably override the default
>> CFLAGS/CXXFLAGS given in Makeconf?
>
> I was given the following code some while ago by Simon Urbanek:
>
> all: $(SHLIB)
>
> MYCXXFLAGS=-O0
>
> %.o: %.cpp
>         $(CXX) $(ALL_CPPFLAGS) $(ALL_CXXFLAGS) $(MYCXXFLAGS) -c $< - 
> o $@
>
> (this is for C++, I imagine the syntax is straightforward for C).  
> Put it in src/Makevars.

Thanks very much. That does indeed allow me to place my flags _after_  
the flags from R_HOME/etc/Makeconf. It would be nice, though, if the  
PKG_CXXFLAGS/PKG_CFLAGS were automatically placed _after_ CXXFLAGS/ 
CFLAGS by R... I vaguely recall the Windows version placing them in  
that order.

Cheers,

Ernest


>
> But as I said above, I think it is a bad idea to raise the  
> optimization level for all users.
>
> Kasper
>
>> Many thanks,
>>
>> Ernest
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From maechler at stat.math.ethz.ch  Tue Mar 20 23:19:54 2007
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 20 Mar 2007 23:19:54 +0100
Subject: [Rd] cbind() & rbind() for S4 objects -- 'Matrix' package changes
Message-ID: <17920.24074.153169.96910@stat.math.ethz.ch>

As some of you may have seen / heard in the past,
it is not possible to make cbind() and rbind() into proper S4
generic functions, since their first formal argument is '...'.
[ BTW: S3-methods for these of course only dispatch on the first
  argument which is also not really satisfactory in the context
  of many possible matrix classes.]

For this reason, after quite some discussion on R-core (and
maybe a bit on R-devel) about the options, since R-2.2.0 we have
had S4 generic functions cbind2() and rbind2() (and default methods)
in R's "methods" which are a version of cbind() and
rbind() respectively for two arguments (x,y)
 {and fixed 'deparse.level = 0' : the argument names are 'x' and 'y' and
  hence don't make sense to be used to construct column-names or
  row-names for rbind(), respectively.}

We have been defining methods for cbind2() and rbind2()
for the 'Matrix' classes in late summer 2005 as well.  So far so
good.

In addition, [see also  help(cbind2) ],
we have defined cbind() and rbind() functions which recursively call
cbind2() and rbind2(), more or less following John Chambers
proposal of dealing with such "(...)" argument functions.
These new recursively defined cbind() / rbind() functions
however have typically remained invisible in the methods package
[you can see them via  methods:::cbind  or  methods:::rbind ]
and have been ``activated'' --- replacing  base::cbind / rbind ---
only via an explicit or implicit call to
     methods:::bind_activation(TRUE)

One reason I didn't dare to make them the default was that I
noticed they didn't behave identically to cbind() / rbind() in
all cases, though IIRC the rare difference was only in the dimnames
returned; further, being entirely written in R, and recursive,
they were slower than the mostly C-based fast  cbind() / rbind()
functions.

As some Bioconductor developers have recently found,
these versions of cbind() and rbind() that have been
automagically activated by loading the  Matrix package
can have a detrimental effect in some extreme cases,
e.g. when using
     do.call(cbind, list_of_length_1000)
because of the recursion and the many many calls to the S4
generic, each time searching for method dispatch ...
For the bioconductor applications and potentially for others using cbind() /
rbind() extensively, this can lead to unacceptable performance
loss just because loading 'Matrix' currently calls
     methods:::bind_activation(TRUE)

For this reason, we plan to refrain from doing this activation
on loading of Matrix, but propose to

1)  define and export
	    cBind <- methods:::cbind
	    rBind <- methods:::cbind

    also do this for R-2.5.0 so that other useRs / packages
    can start cBind() / rBind() in their code when they want to
    have something that can become properly object-oriented

Possibly --- and this is the big  RFC (request for comments) ---

2) __ for 'Matrix' only __ also
   define and export
	    cbind <- methods:::cbind
	    rbind <- methods:::cbind

I currently see the possibilities of doing
 either '1)'
 or     '1) and 2)'
 or less likely  '2) alone'

and like to get your feedback on this.

"1)" alone would have the considerable drawback for current
  Matrix useRs that their code / scripts which has been using
  cbind() and rbind() for "Matrix" (and "matrix" and "numeric")
  objects no longer works, but needs to be changed to use
	rBind() and cBind()  *instead*

As soon as "2)" is done (in conjunction with "1)" or not),
those who need a very fast but non-OO version of cbind() / rbind()
need to call  base::cbind() or  base::rbind()  explicitly.
This however would not be necessary for packages with a NAMESPACE
since these import 'base' automagically and hence would use
base::cbind() automagically {unless they also import(Matrix)}.

We are quite interested in your feedback!

Martin Maechler and Doug Bates <Matrix-authors at R-project.org>


From John.Maindonald at anu.edu.au  Wed Mar 21 00:06:05 2007
From: John.Maindonald at anu.edu.au (John Maindonald)
Date: Wed, 21 Mar 2007 10:06:05 +1100
Subject: [Rd] [R-downunder] las with stripchart
In-Reply-To: <46003B06.4070507@stat.auckland.ac.nz>
References: <AD5F4D19-91FD-4311-8C57-418657666AFD@anu.edu.au>
	<45FF552C.10708@stat.auckland.ac.nz>
	<46003B06.4070507@stat.auckland.ac.nz>
Message-ID: <2785F331-6969-4424-94BF-09E18AC4FE58@anu.edu.au>

Hi Ross -
I believe I was wrong in thinking that passing via the ...
list to stripchart() was ever allowed.  Here are patches:

Add ... to the argument list
Add, at the beginning of the function:

pars <- list(...)

There are two calls to axis().  Modify these to:

       axis(1, at = at, labels = names(groups), las=pars$las)
       axis(2, at = at, labels = names(groups), las=pars$las)

Also col=pars$col and bg=pars$bg should probably get
passed in the call to points()

Are there also parameters that should be passed in the
call to title(), as Paul mooted in that July 2001 discussion?

For the earlier 2001 discussion, see

http://tolstoy.newcastle.edu.au/R/devel/01b/0089.html

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.


On 21 Mar 2007, at 6:50 AM, Ross Ihaka wrote:

> Paul Murrell wrote:
>> Hi
>> John Maindonald wrote:
>>> Hi Paul -
>>> Do you know why las can no longer be passed as a parameter
>>> to stripchart(), though of course it can be set using par.  I note
>>> that is is still available for dotchart().
>> When was 'las' allowed in stripchart()?  (it is missing back as  
>> far as
>> 2.2.1 at least)
>> stripchart() does not allow many par() settings inline at all.  My
>> suspicion is that this is oversight rather than design, but I  
>> don't know
>> who the original author was.
>
> 'twas I. This is almost certainly an oversight.  Patch anyone?
>
>
> -- 
> Ross Ihaka                         Email:  ihaka at stat.auckland.ac.nz
> Department of Statistics           Phone:  (64-9) 373-7599 x 85054
> University of Auckland             Fax:    (64-9) 373-7018
> Private Bag 92019, Auckland
> New Zealand


From edd at debian.org  Wed Mar 21 01:51:36 2007
From: edd at debian.org (Dirk Eddelbuettel)
Date: Tue, 20 Mar 2007 19:51:36 -0500
Subject: [Rd] PKG_CFLAGS/CFLAGS and PKG_CXXFLAGS/CXXFLAGS
In-Reply-To: <438FA5BB-AA84-4E61-8D3F-FDCA637CDD53@ic.ac.uk>
References: <438FA5BB-AA84-4E61-8D3F-FDCA637CDD53@ic.ac.uk>
Message-ID: <17920.33176.19329.830174@basebud.nulle.part>


On 20 March 2007 at 18:58, Ernest Turro wrote:
| Why is it that R places CFLAGS after PKG_CFLAGS and not before when  
| compiling a package (e.g. through R CMD build pkg)? This can be  
| problematic if, for instance, you want to use -O3, but -O2 is in  
| R_HOME/etc/Makeconf. If -O2 (in CFLAGS) appears after -O3 (in  
| PKG_CFLAGS), you are left with what you didn't want: -O2.
| 
| In R-exts, it says that "Flags which are set in file etc/Makeconf can  
| be overridden by the environment variable MAKEFLAGS (at least for  
| systems using GNU make), as in (Bourne shell syntax)" but this  
| doesn't work if I set either MAKEFLAGS or CFLAGS/CXXFLAGS in my  
| configure.ac script or package Makevars.
| 
| Does anyone have any ideas on how to reliably override the default  
| CFLAGS/CXXFLAGS given in Makeconf?

It's one of my token problems too for the Debian package builds. 

Often it is simply not possible to do this easily due to the automated
insertion 'at the wrong' place that you mention.  

One way around is to set CFLAGS (or CXXFLAGS) inside a MAKEFLAGS variable. It
must be properly quoted -- which seems to lead to the restriction that you
get only one token at a time, see below.

I.e. the following was once useful when I needed to tone down the
optimization due to an architecture-specific optimisation bug:

	MAKEFLAGS="FFLAGS=-O1" R CMD INSTALL -l $(debRlib) --clean .

An example of the 'one toke only' problem is 

	MAKEFLAGS="CXXFLAGS+=-I/some/path/some/header \
		CXXFLAGS+=-I/some/other/header \
		LDFLAGS+=-L/some/where \
		LDFLAGS+=-llibfoo LDFLAGS+=-llibbar"  \
		R CMD INSTALL foo

This issue has come up before, and e.g. Kurt has, IIRC, made some suggestions
about overrides below ~/.R.  In my particular case that wouldn't always help
as automated Debian builds are disconnected from individual user accounts.

Dirk

-- 
Hell, there are no rules here - we're trying to accomplish something. 
                                                  -- Thomas A. Edison


From luke at stat.uiowa.edu  Wed Mar 21 02:27:18 2007
From: luke at stat.uiowa.edu (Luke Tierney)
Date: Tue, 20 Mar 2007 20:27:18 -0500 (CDT)
Subject: [Rd] cbind() & rbind() for S4 objects -- 'Matrix' package
	changes
In-Reply-To: <17920.24074.153169.96910@stat.math.ethz.ch>
References: <17920.24074.153169.96910@stat.math.ethz.ch>
Message-ID: <Pine.LNX.4.64.0703201951590.4457@itasca2.wildberry.org>

On Tue, 20 Mar 2007, Martin Maechler wrote:

> As some of you may have seen / heard in the past,
> it is not possible to make cbind() and rbind() into proper S4
> generic functions, since their first formal argument is '...'.
> [ BTW: S3-methods for these of course only dispatch on the first
>  argument which is also not really satisfactory in the context
>  of many possible matrix classes.]
>
> For this reason, after quite some discussion on R-core (and
> maybe a bit on R-devel) about the options, since R-2.2.0 we have
> had S4 generic functions cbind2() and rbind2() (and default methods)
> in R's "methods" which are a version of cbind() and
> rbind() respectively for two arguments (x,y)
> {and fixed 'deparse.level = 0' : the argument names are 'x' and 'y' and
>  hence don't make sense to be used to construct column-names or
>  row-names for rbind(), respectively.}
>
> We have been defining methods for cbind2() and rbind2()
> for the 'Matrix' classes in late summer 2005 as well.  So far so
> good.
>
> In addition, [see also  help(cbind2) ],
> we have defined cbind() and rbind() functions which recursively call
> cbind2() and rbind2(), more or less following John Chambers
> proposal of dealing with such "(...)" argument functions.
> These new recursively defined cbind() / rbind() functions
> however have typically remained invisible in the methods package
> [you can see them via  methods:::cbind  or  methods:::rbind ]
> and have been ``activated'' --- replacing  base::cbind / rbind ---
> only via an explicit or implicit call to
>     methods:::bind_activation(TRUE)
>
> One reason I didn't dare to make them the default was that I
> noticed they didn't behave identically to cbind() / rbind() in
> all cases, though IIRC the rare difference was only in the dimnames
> returned; further, being entirely written in R, and recursive,
> they were slower than the mostly C-based fast  cbind() / rbind()
> functions.
>
> As some Bioconductor developers have recently found,
> these versions of cbind() and rbind() that have been
> automagically activated by loading the  Matrix package
> can have a detrimental effect in some extreme cases,
> e.g. when using
>     do.call(cbind, list_of_length_1000)
> because of the recursion and the many many calls to the S4
> generic, each time searching for method dispatch ...
> For the bioconductor applications and potentially for others using cbind() /
> rbind() extensively, this can lead to unacceptable performance
> loss just because loading 'Matrix' currently calls
>     methods:::bind_activation(TRUE)

The recursion part is potentially problematic because stack space
limitations will cause this to fail for "relatively" short
list_of_length_1000, but that should be easily curable by rewriting
methods:::cbind and methods:::rbind to use iteration rather than
recursion. This might also help a little with efficiency by avoiding
call overhead.  It would be interesting to know how much of the
performance hit is dispatch overhead and how much closure call
overhead.  If it's dispatch overhead then it may be worth figuring out
some way of handling this with internal dispatch at the C level (at
the cost of maintaining the C level stuff).

My initial reaction to scanning the methods:::cbind code is that it is
doing too much, at least too much R-level work, but I haven't thought
it through carefully.

> For this reason, we plan to refrain from doing this activation
> on loading of Matrix, but propose to
>
> 1)  define and export
> 	    cBind <- methods:::cbind
> 	    rBind <- methods:::cbind
>
>    also do this for R-2.5.0 so that other useRs / packages
>    can start cBind() / rBind() in their code when they want to
>    have something that can become properly object-oriented

In mackage methods?

> Possibly --- and this is the big  RFC (request for comments) ---
>
> 2) __ for 'Matrix' only __ also
>   define and export
> 	    cbind <- methods:::cbind
> 	    rbind <- methods:::cbind
>
> I currently see the possibilities of doing
> either '1)'
> or     '1) and 2)'
> or less likely  '2) alone'
>
> and like to get your feedback on this.
>
> "1)" alone would have the considerable drawback for current
>  Matrix useRs that their code / scripts which has been using
>  cbind() and rbind() for "Matrix" (and "matrix" and "numeric")
>  objects no longer works, but needs to be changed to use
> 	rBind() and cBind()  *instead*
>
> As soon as "2)" is done (in conjunction with "1)" or not),
> those who need a very fast but non-OO version of cbind() / rbind()
> need to call  base::cbind() or  base::rbind()  explicitly.
> This however would not be necessary for packages with a NAMESPACE
> since these import 'base' automagically and hence would use
> base::cbind() automagically {unless they also import(Matrix)}.
>
> We are quite interested in your feedback!

Either one seems cleaner to me than having loading of one package
result in mucking about in the internals of another.

If we are thinking of these as long term solutions then I think having
different names is cleaner, so 1) but not 2).  If we are thinking of
this as a transition towards making base::cbind and base::rbind
support S4 dispatch via cbind2/rbind2 (assuming this can be done
efficiently) then there may be some merit to 2) to minimize the need
for code rewriting.

It might be worth experimenting with having .Internal(cbind(...))
check its arguments and call methods:::cbind if (Methods is loaded
and) any of the arguments are S4 -- as the S4 property is now cheap to
determine that may be very low cost especially if done after the
object bits have been checked with positive result.

Best,

luke

> Martin Maechler and Doug Bates <Matrix-authors at R-project.org>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Luke Tierney
Chair, Statistics and Actuarial Science
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From ggrothendieck at gmail.com  Wed Mar 21 03:10:27 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 20 Mar 2007 22:10:27 -0400
Subject: [Rd] wishlist -- Fix for major format.pval limitation (PR#9574)
In-Reply-To: <46002752.3070704@stats.uwo.ca>
References: <20070320163656.2B81F5ABEB@slim.kubism.ku.dk>
	<971536df0703200944x62af2966yf11b9b3ab6af3d11@mail.gmail.com>
	<46001711.6090008@stats.uwo.ca>
	<971536df0703201040u45d3a9a2u4a08959455a8d997@mail.gmail.com>
	<46002752.3070704@stats.uwo.ca>
Message-ID: <971536df0703201910r3c3cea33ncb8ea64fe61367dd@mail.gmail.com>

On 3/20/07, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> On 3/20/2007 1:40 PM, Gabor Grothendieck wrote:
> > On 3/20/07, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> >> On 3/20/2007 12:44 PM, Gabor Grothendieck wrote:
> >> > On 3/20/07, murdoch at stats.uwo.ca <murdoch at stats.uwo.ca> wrote:
> >> >> On 3/20/2007 11:19 AM, charles.dupont at vanderbilt.edu wrote:
> >> >> > Full_Name: Charles Dupont
> >> >> > Version: 2.4.1
> >> >> > OS: linux 2.6.18
> >> >> > Submission from: (NULL) (160.129.129.136)
> >> >> >
> >> >> >
> >> >> > 'format.pval' has a major limitation in its implementation. For example
> >> >> > suppose a person had a vector like 'a' and the error being ?0.001.
> >> >> >
> >> >> >     > a <- c(0.1, 0.3, 0.4, 0.5, 0.3, 0.0001)
> >> >> >     > format.pval(a, eps=0.01)
> >> >> >
> >> >> > If that person wants to have the 'format.pval' output with 2 digits always
> >> >> > showing (like passing nsmall=2 to 'format'). That output would look like
> >> >> > this.
> >> >> >
> >> >> >     [1] "0.10"   "0.30"   "0.40"   "0.50"   "0.30"   "<0.01"
> >> >> >
> >> >> > That output is currently impossible because format.pval can only
> >> >> > produce output like this.
> >> >> >
> >> >> >     [1] "0.1"    "0.3"    "0.4"    "0.5"    "0.3"    "<0.01"
> >> >> >
> >> >> >
> >> >> > ---------------------------------------------------------------
> >> >> > a <- c(0.1, 0.3, 0.4, 0.5, 0.3, 0.0001)
> >> >> > format.pval(a, eps=0.01)
> >> >>
> >> >> But there's a very easy workaround:
> >> >>
> >> >> format.pval(c(0.12, a), eps=0.01)[-1]
> >> >>
> >> >> gives you what you want (because the 0.12 forces two decimal place
> >> >> display on all values, and then the [-1] removes it).
> >> >>
> >> >
> >> > Clever, but the problem would be that summary.lm, etc. call format.pval so the
> >> > user does not have a chance to do that.
> >>
> >> I don't see how this is relevant.  summary.lm doesn't let you pass a new
> >> eps value either.  Adding an "nsmall=2" argument to format.pval wouldn't
> >> help with the display in summary.lm.
> >>
> >> I suppose we could track down every use of format.pval in every function
> >> in every package and add nsmall and eps as arguments to each of them,
> >> but that's just ridiculous.  People should accept the fact that R
> >> doesn't produce publication quality text, it just provides you with ways
> >> to produce that yourself.
> >>
> >> Duncan Murdoch
> >>
> >
> > You are right in terms of my example which was not applicable but I
> > think in general that format.pval is used from within other routines rather than
> > directly by the user so the user may not have a chance to massage it
> > directly.
>
> Right, but this means that it is more or less useless to change the
> argument list for format.pvals in the way Charles suggested, because all
> of the existing uses of it would ignore the new parameters.
>
> It would not be so difficult to change the behaviour of format.pvals so
> that for example "digits=2" implied the equivalent of "nsmall=2", but I
> don't think that's a universally desirable change.
>
> The difficulty here is that different people have different tastes for
> presentation-quality text.  Not everyone would agree that the version
> with trailing zeros is preferable to the one without.  R should be
> flexible enough to allow people to customize their displays, but not
> necessarily by having every print method flexible enough to satisfy
> every user:  sometimes users need to construct their own output formats.
>
> Duncan Murdoch
>

One possibility would be to add args to format.pval whose defaults
can be set through options.  Not beautiful but it would give the user
who really needed it a way to do it.


From maechler at stat.math.ethz.ch  Wed Mar 21 08:39:01 2007
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 21 Mar 2007 08:39:01 +0100
Subject: [Rd] wishlist -- Fix for major format.pval limitation (PR#9574)
In-Reply-To: <971536df0703201910r3c3cea33ncb8ea64fe61367dd@mail.gmail.com>
References: <20070320163656.2B81F5ABEB@slim.kubism.ku.dk>
	<971536df0703200944x62af2966yf11b9b3ab6af3d11@mail.gmail.com>
	<46001711.6090008@stats.uwo.ca>
	<971536df0703201040u45d3a9a2u4a08959455a8d997@mail.gmail.com>
	<46002752.3070704@stats.uwo.ca>
	<971536df0703201910r3c3cea33ncb8ea64fe61367dd@mail.gmail.com>
Message-ID: <17920.57621.554417.821721@stat.math.ethz.ch>

>>>>> "Gabor" == Gabor Grothendieck <ggrothendieck at gmail.com>
>>>>>     on Tue, 20 Mar 2007 22:10:27 -0400 writes:

    Gabor> On 3/20/07, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
    >> On 3/20/2007 1:40 PM, Gabor Grothendieck wrote:
    >> > On 3/20/07, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
    >> >> On 3/20/2007 12:44 PM, Gabor Grothendieck wrote:
    >> >> > On 3/20/07, murdoch at stats.uwo.ca <murdoch at stats.uwo.ca> wrote:
    >> >> >> On 3/20/2007 11:19 AM, charles.dupont at vanderbilt.edu wrote:
    >> >> >> > Full_Name: Charles Dupont
    >> >> >> > Version: 2.4.1
    >> >> >> > OS: linux 2.6.18
    >> >> >> > Submission from: (NULL) (160.129.129.136)
    >> >> >> >
    >> >> >> >
    >> >> >> > 'format.pval' has a major limitation in its implementation. For example
    >> >> >> > suppose a person had a vector like 'a' and the error being ?0.001.
    >> >> >> >
    >> >> >> >     > a <- c(0.1, 0.3, 0.4, 0.5, 0.3, 0.0001)
    >> >> >> >     > format.pval(a, eps=0.01)
    >> >> >> >
    >> >> >> > If that person wants to have the 'format.pval' output with 2 digits always
    >> >> >> > showing (like passing nsmall=2 to 'format'). That output would look like
    >> >> >> > this.
    >> >> >> >
    >> >> >> >     [1] "0.10"   "0.30"   "0.40"   "0.50"   "0.30"   "<0.01"
    >> >> >> >
    >> >> >> > That output is currently impossible because format.pval can only
    >> >> >> > produce output like this.
    >> >> >> >
    >> >> >> >     [1] "0.1"    "0.3"    "0.4"    "0.5"    "0.3"    "<0.01"
    >> >> >> >
    >> >> >> >
    >> >> >> > ---------------------------------------------------------------
    >> >> >> > a <- c(0.1, 0.3, 0.4, 0.5, 0.3, 0.0001)
    >> >> >> > format.pval(a, eps=0.01)
    >> >> >>
    >> >> >> But there's a very easy workaround:
    >> >> >>
    >> >> >> format.pval(c(0.12, a), eps=0.01)[-1]
    >> >> >>
    >> >> >> gives you what you want (because the 0.12 forces two decimal place
    >> >> >> display on all values, and then the [-1] removes it).
    >> >> >>
    >> >> >
    >> >> > Clever, but the problem would be that summary.lm, etc. call format.pval so the
    >> >> > user does not have a chance to do that.
    >> >>
    >> >> I don't see how this is relevant.  summary.lm doesn't let you pass a new
    >> >> eps value either.  Adding an "nsmall=2" argument to format.pval wouldn't
    >> >> help with the display in summary.lm.
    >> >>
    >> >> I suppose we could track down every use of format.pval in every function
    >> >> in every package and add nsmall and eps as arguments to each of them,
    >> >> but that's just ridiculous.  People should accept the fact that R
    >> >> doesn't produce publication quality text, it just provides you with ways
    >> >> to produce that yourself.
    >> >>
    >> >> Duncan Murdoch
    >> >>
    >> >
    >> > You are right in terms of my example which was not applicable but I
    >> > think in general that format.pval is used from within other routines rather than
    >> > directly by the user so the user may not have a chance to massage it
    >> > directly.
    >> 
    >> Right, but this means that it is more or less useless to change the
    >> argument list for format.pvals in the way Charles suggested, because all
    >> of the existing uses of it would ignore the new parameters.
    >> 
    >> It would not be so difficult to change the behaviour of format.pvals so
    >> that for example "digits=2" implied the equivalent of "nsmall=2", but I
    >> don't think that's a universally desirable change.
    >> 
    >> The difficulty here is that different people have different tastes for
    >> presentation-quality text.  Not everyone would agree that the version
    >> with trailing zeros is preferable to the one without.  R should be
    >> flexible enough to allow people to customize their displays, but not
    >> necessarily by having every print method flexible enough to satisfy
    >> every user:  sometimes users need to construct their own output formats.
    >> 
    >> Duncan Murdoch

    Gabor> One possibility would be to add args to format.pval whose defaults
    Gabor> can be set through options.  Not beautiful but it would give the user
    Gabor> who really needed it a way to do it.

Yes indeed, I had had the same thought (very early in this
thread).  This doesn't mean that I wouldn't agree with Duncan's
statement above anyway.

Whereas I have strong opinion on *not* allowing options() to
influence too many things [it's entirely contrary to the
principle of functional programming], 
options() have always been used to tweak print()ing; so they
could be used here as well.
As original author of format.pval(), I'm happy to accept patches
--- if they are done well and also patch 
    src/library/base/man/format.pval.Rd and ..../man/options.Rd 

Martin


From murdoch at stats.uwo.ca  Wed Mar 21 12:01:39 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Wed, 21 Mar 2007 07:01:39 -0400
Subject: [Rd] wishlist -- Fix for major format.pval limitation (PR#9574)
In-Reply-To: <17920.57621.554417.821721@stat.math.ethz.ch>
References: <20070320163656.2B81F5ABEB@slim.kubism.ku.dk>	<971536df0703200944x62af2966yf11b9b3ab6af3d11@mail.gmail.com>	<46001711.6090008@stats.uwo.ca>	<971536df0703201040u45d3a9a2u4a08959455a8d997@mail.gmail.com>	<46002752.3070704@stats.uwo.ca>	<971536df0703201910r3c3cea33ncb8ea64fe61367dd@mail.gmail.com>
	<17920.57621.554417.821721@stat.math.ethz.ch>
Message-ID: <46011093.7020401@stats.uwo.ca>

On 3/21/2007 3:39 AM, Martin Maechler wrote:
>>>>>> "Gabor" == Gabor Grothendieck <ggrothendieck at gmail.com>
>>>>>>     on Tue, 20 Mar 2007 22:10:27 -0400 writes:
> 
>     Gabor> On 3/20/07, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
>     >> On 3/20/2007 1:40 PM, Gabor Grothendieck wrote:
>     >> > On 3/20/07, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
>     >> >> On 3/20/2007 12:44 PM, Gabor Grothendieck wrote:
>     >> >> > On 3/20/07, murdoch at stats.uwo.ca <murdoch at stats.uwo.ca> wrote:
>     >> >> >> On 3/20/2007 11:19 AM, charles.dupont at vanderbilt.edu wrote:
>     >> >> >> > Full_Name: Charles Dupont
>     >> >> >> > Version: 2.4.1
>     >> >> >> > OS: linux 2.6.18
>     >> >> >> > Submission from: (NULL) (160.129.129.136)
>     >> >> >> >
>     >> >> >> >
>     >> >> >> > 'format.pval' has a major limitation in its implementation. For example
>     >> >> >> > suppose a person had a vector like 'a' and the error being ?0.001.
>     >> >> >> >
>     >> >> >> >     > a <- c(0.1, 0.3, 0.4, 0.5, 0.3, 0.0001)
>     >> >> >> >     > format.pval(a, eps=0.01)
>     >> >> >> >
>     >> >> >> > If that person wants to have the 'format.pval' output with 2 digits always
>     >> >> >> > showing (like passing nsmall=2 to 'format'). That output would look like
>     >> >> >> > this.
>     >> >> >> >
>     >> >> >> >     [1] "0.10"   "0.30"   "0.40"   "0.50"   "0.30"   "<0.01"
>     >> >> >> >
>     >> >> >> > That output is currently impossible because format.pval can only
>     >> >> >> > produce output like this.
>     >> >> >> >
>     >> >> >> >     [1] "0.1"    "0.3"    "0.4"    "0.5"    "0.3"    "<0.01"
>     >> >> >> >
>     >> >> >> >
>     >> >> >> > ---------------------------------------------------------------
>     >> >> >> > a <- c(0.1, 0.3, 0.4, 0.5, 0.3, 0.0001)
>     >> >> >> > format.pval(a, eps=0.01)
>     >> >> >>
>     >> >> >> But there's a very easy workaround:
>     >> >> >>
>     >> >> >> format.pval(c(0.12, a), eps=0.01)[-1]
>     >> >> >>
>     >> >> >> gives you what you want (because the 0.12 forces two decimal place
>     >> >> >> display on all values, and then the [-1] removes it).
>     >> >> >>
>     >> >> >
>     >> >> > Clever, but the problem would be that summary.lm, etc. call format.pval so the
>     >> >> > user does not have a chance to do that.
>     >> >>
>     >> >> I don't see how this is relevant.  summary.lm doesn't let you pass a new
>     >> >> eps value either.  Adding an "nsmall=2" argument to format.pval wouldn't
>     >> >> help with the display in summary.lm.
>     >> >>
>     >> >> I suppose we could track down every use of format.pval in every function
>     >> >> in every package and add nsmall and eps as arguments to each of them,
>     >> >> but that's just ridiculous.  People should accept the fact that R
>     >> >> doesn't produce publication quality text, it just provides you with ways
>     >> >> to produce that yourself.
>     >> >>
>     >> >> Duncan Murdoch
>     >> >>
>     >> >
>     >> > You are right in terms of my example which was not applicable but I
>     >> > think in general that format.pval is used from within other routines rather than
>     >> > directly by the user so the user may not have a chance to massage it
>     >> > directly.
>     >> 
>     >> Right, but this means that it is more or less useless to change the
>     >> argument list for format.pvals in the way Charles suggested, because all
>     >> of the existing uses of it would ignore the new parameters.
>     >> 
>     >> It would not be so difficult to change the behaviour of format.pvals so
>     >> that for example "digits=2" implied the equivalent of "nsmall=2", but I
>     >> don't think that's a universally desirable change.
>     >> 
>     >> The difficulty here is that different people have different tastes for
>     >> presentation-quality text.  Not everyone would agree that the version
>     >> with trailing zeros is preferable to the one without.  R should be
>     >> flexible enough to allow people to customize their displays, but not
>     >> necessarily by having every print method flexible enough to satisfy
>     >> every user:  sometimes users need to construct their own output formats.
>     >> 
>     >> Duncan Murdoch
> 
>     Gabor> One possibility would be to add args to format.pval whose defaults
>     Gabor> can be set through options.  Not beautiful but it would give the user
>     Gabor> who really needed it a way to do it.
> 
> Yes indeed, I had had the same thought (very early in this
> thread).  This doesn't mean that I wouldn't agree with Duncan's
> statement above anyway.

I think this is harder than it looks at first.  The problem is knowing 
where to stop.  If the value of nsmall used by format.pval() when it 
calls format() can be changed, why not other parameters?  Why not allow 
the same flexibility for other users of format.default()?  What about 
other defaults of format.pval and other format.XXX methods?

I'd like to see some thought put into these questions before adding an 
option, because if the option is too specific, it will make it harder to 
make other such changes in the future.  On the other hand, if it's too 
general, it will be hard to document and unusable.

Duncan Murdoch

> 
> Whereas I have strong opinion on *not* allowing options() to
> influence too many things [it's entirely contrary to the
> principle of functional programming], 
> options() have always been used to tweak print()ing; so they
> could be used here as well.
> As original author of format.pval(), I'm happy to accept patches
> --- if they are done well and also patch 
>     src/library/base/man/format.pval.Rd and ..../man/options.Rd 
> 
> Martin


From roger.bos at us.rothschild.com  Wed Mar 21 13:14:24 2007
From: roger.bos at us.rothschild.com (Bos, Roger)
Date: Wed, 21 Mar 2007 08:14:24 -0400
Subject: [Rd] Unable to register TclNotifier window class
Message-ID: <D8C95B444AD6EE4AAD638D818A9CFD343A20CC@RINNYCSE000.rth.ad.rothschild.com>

Running R 2.4.1 in batch mode on a Windows Server 2003 machine
occasionally gives me the following error in the ".Rout" file:

Loading required package: tcltk
Loading Tcl/Tk interface ... Unable to register TclNotifier window class

This application has requested the Runtime to terminate it in an unusual
way.
Please contact the application's support team for more information.

Does anyone have any hints on how to debug this or what the possible
cause might be?  Is the Tcl/Tk interface mandatory, or can I somehow
turn it off?  I use this batch to run overnight jobs where reliability
is important.

Thanks,

Roger


Roger J. Bos, CFA
Rothschild Asset Management
1251 Avenue of the Americas
New York, NY  10020
(212) 403-5471
 

********************************************************************** * 
This message is for the named person's use only. It may 
contain confidential, proprietary or legally privileged 
information. No right to confidential or privileged treatment 
of this message is waived or lost by any error in 
transmission. If you have received this message in error, 
please immediately notify the sender by e-mail, 
delete the message and all copies from your system and destroy 
any hard copies. You must not, directly or indirectly, use, 
disclose, distribute, print or copy any part of this message 
if you are not the intended recipient.


From ripley at stats.ox.ac.uk  Wed Mar 21 14:51:56 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 21 Mar 2007 13:51:56 +0000 (GMT)
Subject: [Rd] -std=c99 and inline semantics
In-Reply-To: <Pine.LNX.4.64.0703200826390.3114@auk.stats>
References: <45FEF6C5.1070900@santafe.edu>
	<Pine.LNX.4.64.0703200826390.3114@auk.stats>
Message-ID: <Pine.LNX.4.64.0703211325250.30424@gannet.stats.ox.ac.uk>

The answer seems to be simple: add -fgnu89-inline, which will be available 
for gcc >= 4.1.3 (not yet released) according to the info files in the 
trunk.

BTW, the two OSes I tried the GCC trunk on (FC5 and MinGW) both had 
problems of their own with this change of semantics.  AFAICS, wchar.h in 
glibc 2.5 (the latest release) still does.  This is going to make for 
interesting times when you can choose on a per-compilation-unit (and not 
per-header) basis what the 'inline' semantics should be.

On Tue, 20 Mar 2007, Prof Brian Ripley wrote:

> As even 4.2.0 is not released yet, we will make changes at an appropriate
> time.  The GNU and C99 semantics for 'inline' are known to be
> incompatible.
>
>> From src/include/Rinlinedfuns.h:
>
> /* this header is always to be included from others.
>    It is only called if COMPILING_R is defined (in util.c) or
>    from GNU C systems.
>
>    There are different conventions for inlining across compilation units.
>    We pro tem only use the GCC one.  See
>    http://www.greenend.org.uk/rjk/2003/03/inline.html
> */
>
> and note the 'pro tem'.
>
> On Mon, 19 Mar 2007, Marcus G. Daniels wrote:
>
>> Hi,
>>
>> I noticed that with the GCC trunk (4.3.0), the semantics of "extern
>> inline" have reversed.
>> The net result is that R will build without the usual-stdc=gnu99 but it
>> won't with it.
>> Many multiple definitions result otherwise.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From jeff.horner at vanderbilt.edu  Wed Mar 21 15:09:25 2007
From: jeff.horner at vanderbilt.edu (Jeffrey Horner)
Date: Wed, 21 Mar 2007 09:09:25 -0500
Subject: [Rd] wishlist -- Fix for major format.pval limitation (PR#9574)
In-Reply-To: <46011093.7020401@stats.uwo.ca>
References: <20070320163656.2B81F5ABEB@slim.kubism.ku.dk>	<971536df0703200944x62af2966yf11b9b3ab6af3d11@mail.gmail.com>	<46001711.6090008@stats.uwo.ca>	<971536df0703201040u45d3a9a2u4a08959455a8d997@mail.gmail.com>	<46002752.3070704@stats.uwo.ca>	<971536df0703201910r3c3cea33ncb8ea64fe61367dd@mail.gmail.com>	<17920.57621.554417.821721@stat.math.ethz.ch>
	<46011093.7020401@stats.uwo.ca>
Message-ID: <46013C95.40709@vanderbilt.edu>

Duncan Murdoch wrote:
> On 3/21/2007 3:39 AM, Martin Maechler wrote:
>>>>>>> "Gabor" == Gabor Grothendieck <ggrothendieck at gmail.com>
>>>>>>>     on Tue, 20 Mar 2007 22:10:27 -0400 writes:
>>     Gabor> On 3/20/07, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
>>     >> On 3/20/2007 1:40 PM, Gabor Grothendieck wrote:
>>     >> > On 3/20/07, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
>>     >> >> On 3/20/2007 12:44 PM, Gabor Grothendieck wrote:
>>     >> >> > On 3/20/07, murdoch at stats.uwo.ca <murdoch at stats.uwo.ca> wrote:
>>     >> >> >> On 3/20/2007 11:19 AM, charles.dupont at vanderbilt.edu wrote:
>>     >> >> >> > Full_Name: Charles Dupont
>>     >> >> >> > Version: 2.4.1
>>     >> >> >> > OS: linux 2.6.18
>>     >> >> >> > Submission from: (NULL) (160.129.129.136)
>>     >> >> >> >
>>     >> >> >> >
>>     >> >> >> > 'format.pval' has a major limitation in its implementation. For example
>>     >> >> >> > suppose a person had a vector like 'a' and the error being ?0.001.
>>     >> >> >> >
>>     >> >> >> >     > a <- c(0.1, 0.3, 0.4, 0.5, 0.3, 0.0001)
>>     >> >> >> >     > format.pval(a, eps=0.01)
>>     >> >> >> >
>>     >> >> >> > If that person wants to have the 'format.pval' output with 2 digits always
>>     >> >> >> > showing (like passing nsmall=2 to 'format'). That output would look like
>>     >> >> >> > this.
>>     >> >> >> >
>>     >> >> >> >     [1] "0.10"   "0.30"   "0.40"   "0.50"   "0.30"   "<0.01"
>>     >> >> >> >
>>     >> >> >> > That output is currently impossible because format.pval can only
>>     >> >> >> > produce output like this.
>>     >> >> >> >
>>     >> >> >> >     [1] "0.1"    "0.3"    "0.4"    "0.5"    "0.3"    "<0.01"
>>     >> >> >> >
>>     >> >> >> >
>>     >> >> >> > ---------------------------------------------------------------
>>     >> >> >> > a <- c(0.1, 0.3, 0.4, 0.5, 0.3, 0.0001)
>>     >> >> >> > format.pval(a, eps=0.01)
>>     >> >> >>
>>     >> >> >> But there's a very easy workaround:
>>     >> >> >>
>>     >> >> >> format.pval(c(0.12, a), eps=0.01)[-1]
>>     >> >> >>
>>     >> >> >> gives you what you want (because the 0.12 forces two decimal place
>>     >> >> >> display on all values, and then the [-1] removes it).
>>     >> >> >>
>>     >> >> >
>>     >> >> > Clever, but the problem would be that summary.lm, etc. call format.pval so the
>>     >> >> > user does not have a chance to do that.
>>     >> >>
>>     >> >> I don't see how this is relevant.  summary.lm doesn't let you pass a new
>>     >> >> eps value either.  Adding an "nsmall=2" argument to format.pval wouldn't
>>     >> >> help with the display in summary.lm.
>>     >> >>
>>     >> >> I suppose we could track down every use of format.pval in every function
>>     >> >> in every package and add nsmall and eps as arguments to each of them,
>>     >> >> but that's just ridiculous.  People should accept the fact that R
>>     >> >> doesn't produce publication quality text, it just provides you with ways
>>     >> >> to produce that yourself.
>>     >> >>
>>     >> >> Duncan Murdoch
>>     >> >>
>>     >> >
>>     >> > You are right in terms of my example which was not applicable but I
>>     >> > think in general that format.pval is used from within other routines rather than
>>     >> > directly by the user so the user may not have a chance to massage it
>>     >> > directly.
>>     >> 
>>     >> Right, but this means that it is more or less useless to change the
>>     >> argument list for format.pvals in the way Charles suggested, because all
>>     >> of the existing uses of it would ignore the new parameters.
>>     >> 
>>     >> It would not be so difficult to change the behaviour of format.pvals so
>>     >> that for example "digits=2" implied the equivalent of "nsmall=2", but I
>>     >> don't think that's a universally desirable change.
>>     >> 
>>     >> The difficulty here is that different people have different tastes for
>>     >> presentation-quality text.  Not everyone would agree that the version
>>     >> with trailing zeros is preferable to the one without.  R should be
>>     >> flexible enough to allow people to customize their displays, but not
>>     >> necessarily by having every print method flexible enough to satisfy
>>     >> every user:  sometimes users need to construct their own output formats.
>>     >> 
>>     >> Duncan Murdoch
>>
>>     Gabor> One possibility would be to add args to format.pval whose defaults
>>     Gabor> can be set through options.  Not beautiful but it would give the user
>>     Gabor> who really needed it a way to do it.
>>
>> Yes indeed, I had had the same thought (very early in this
>> thread).  This doesn't mean that I wouldn't agree with Duncan's
>> statement above anyway.
> 
> I think this is harder than it looks at first.  The problem is knowing 
> where to stop.  If the value of nsmall used by format.pval() when it 
> calls format() can be changed, why not other parameters?  Why not allow 
> the same flexibility for other users of format.default()?  What about 
> other defaults of format.pval and other format.XXX methods?


What about using attributes for format options? I proposed this for 
difftime objects here:

http://tolstoy.newcastle.edu.au/R/e2/devel/07/02/2256.html

Jeff


> 
> I'd like to see some thought put into these questions before adding an 
> option, because if the option is too specific, it will make it harder to 
> make other such changes in the future.  On the other hand, if it's too 
> general, it will be hard to document and unusable.
> 
> Duncan Murdoch
> 
>> Whereas I have strong opinion on *not* allowing options() to
>> influence too many things [it's entirely contrary to the
>> principle of functional programming], 
>> options() have always been used to tweak print()ing; so they
>> could be used here as well.
>> As original author of format.pval(), I'm happy to accept patches
>> --- if they are done well and also patch 
>>     src/library/base/man/format.pval.Rd and ..../man/options.Rd 
>>
>> Martin
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
http://biostat.mc.vanderbilt.edu/JeffreyHorner


From prechelt at inf.fu-berlin.de  Wed Mar 21 16:18:22 2007
From: prechelt at inf.fu-berlin.de (prechelt at inf.fu-berlin.de)
Date: Wed, 21 Mar 2007 16:18:22 +0100 (CET)
Subject: [Rd] rbind.data.frame reacts on levels without factor (PR#9578)
Message-ID: <20070321151822.B6CCF5AC11@slim.kubism.ku.dk>

Full_Name: Lutz Prechelt
Version: 2.4.1
OS: Windows XP
Submission from: (NULL) (160.45.111.67)


I stack a number of data.frames using rbind.
Each of these dataframes has a column 'authorname', which is a factor
and a column author = unclass(authorname) as piecewise pseudonyms.
When using rbind to stack these dataframes, R warns about invalid factor levels
and inserts all NAs in the author column.

The reason appears to be that rbind.data.frame looks for the presence of levels,
not actually for class==factor when deciding what to handle as a factor:
                  if (!is.null(levels(xj))) {

I find this behavior surprising, hence dangerous, and it is not documented.
Rather, the documentation says:
    "The 'rbind' data frame method takes the classes of the columns
     from the first data frame, and matches columns by name (rather
     than by position).  Factors have their levels expanded as
     necessary [...]"

The behavior has bitten me fairly hard, because I searched for the origin of the
warning in all the wrong places before finding the real one after about 3
hours.
(Although I still have not understood _why_ it results in that warning.)

I believe the behavior of rbind.data.frame should be fixed, so that it ignores
levels attributes when there is no factor class as well.

The alternative would be to just add a warning to the documentation that
'unclass' on factors is insufficient if users want to avoid factor handling for
rbind.


From jbrzusto at fastmail.fm  Wed Mar 21 15:58:35 2007
From: jbrzusto at fastmail.fm (jbrzusto at fastmail.fm)
Date: Wed, 21 Mar 2007 15:58:35 +0100 (CET)
Subject: [Rd] bug and patch: strptime first-of-month error in (possibly
	unsupported use of) "%j" format (PR#9577)
Message-ID: <20070321145835.647A85AB2A@slim.kubism.ku.dk>

Full_Name: John Brzustowski
Version: R-devel-trunk
OS: linux (problem under Windows too)
Submission from: (NULL) (74.101.124.238)


(This bug was discovered by Phil Taylor, Acadia University.)
I'm not sure from reading the documentation whether strptime(x, "%j") is meant
to be supported, but if so, there is a bug which prevents it from working on the
first day of months after January:

> strptime(31:33, "%j")
[1] "2007-01-31" NA           "2007-02-02"

# the full extent of R's taunting
strptime(1 + cumsum(c(31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30)), "%j")
 [1] NA NA NA NA NA NA NA NA NA NA NA
>

The problem is an edge-case comparison in datetime.c:glibc_fix().  This
generates a date like "Jan 32", which validate_tm() catches and NAs.
(Values of field tm->tm_yday start at 0, not 1.)
=================================================================================
PATCH:

--- R/src/main/datetime.c	(revision 40860)
+++ R/src/main/datetime.c	(working copy)
@@ -796,7 +796,7 @@
     if(tm->tm_yday != NA_INTEGER) {
 	/* since we have yday, let that take precedence over mon/mday */
 	int yday = tm->tm_yday, mon = 0;
-	while(yday > (tmp = days_in_month[mon] +
+	while(yday >= (tmp = days_in_month[mon] +
 		      ((mon==1 && isleap(1900+tm->tm_year))? 1 : 0))) {
 	    yday -= tmp;
 	    mon++;


From charles.dupont at vanderbilt.edu  Wed Mar 21 18:23:15 2007
From: charles.dupont at vanderbilt.edu (Charles Dupont)
Date: Wed, 21 Mar 2007 12:23:15 -0500
Subject: [Rd] wishlist -- Fix for major format.pval limitation (PR#9574)
In-Reply-To: <17920.57621.554417.821721@stat.math.ethz.ch>
References: <20070320163656.2B81F5ABEB@slim.kubism.ku.dk>	<971536df0703200944x62af2966yf11b9b3ab6af3d11@mail.gmail.com>	<46001711.6090008@stats.uwo.ca>	<971536df0703201040u45d3a9a2u4a08959455a8d997@mail.gmail.com>	<46002752.3070704@stats.uwo.ca>	<971536df0703201910r3c3cea33ncb8ea64fe61367dd@mail.gmail.com>
	<17920.57621.554417.821721@stat.math.ethz.ch>
Message-ID: <46016A03.3020001@vanderbilt.edu>

Martin Maechler wrote:
>>>>>> "Gabor" == Gabor Grothendieck <ggrothendieck at gmail.com>
>>>>>>     on Tue, 20 Mar 2007 22:10:27 -0400 writes:
> 
>     Gabor> On 3/20/07, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
>     >> On 3/20/2007 1:40 PM, Gabor Grothendieck wrote:
>     >> > On 3/20/07, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
>     >> >> On 3/20/2007 12:44 PM, Gabor Grothendieck wrote:
>     >> >> > On 3/20/07, murdoch at stats.uwo.ca <murdoch at stats.uwo.ca> wrote:
>     >> >> >> On 3/20/2007 11:19 AM, charles.dupont at vanderbilt.edu wrote:
>     >> >> >> > Full_Name: Charles Dupont
>     >> >> >> > Version: 2.4.1
>     >> >> >> > OS: linux 2.6.18
>     >> >> >> > Submission from: (NULL) (160.129.129.136)
>     >> >> >> >
>     >> >> >> >
>     >> >> >> > 'format.pval' has a major limitation in its implementation. For example
>     >> >> >> > suppose a person had a vector like 'a' and the error being ?0.001.
>     >> >> >> >
>     >> >> >> >     > a <- c(0.1, 0.3, 0.4, 0.5, 0.3, 0.0001)
>     >> >> >> >     > format.pval(a, eps=0.01)
>     >> >> >> >
>     >> >> >> > If that person wants to have the 'format.pval' output with 2 digits always
>     >> >> >> > showing (like passing nsmall=2 to 'format'). That output would look like
>     >> >> >> > this.
>     >> >> >> >
>     >> >> >> >     [1] "0.10"   "0.30"   "0.40"   "0.50"   "0.30"   "<0.01"
>     >> >> >> >
>     >> >> >> > That output is currently impossible because format.pval can only
>     >> >> >> > produce output like this.
>     >> >> >> >
>     >> >> >> >     [1] "0.1"    "0.3"    "0.4"    "0.5"    "0.3"    "<0.01"
>     >> >> >> >
>     >> >> >> >
>     >> >> >> > ---------------------------------------------------------------
>     >> >> >> > a <- c(0.1, 0.3, 0.4, 0.5, 0.3, 0.0001)
>     >> >> >> > format.pval(a, eps=0.01)
>     >> >> >>
>     >> >> >> But there's a very easy workaround:
>     >> >> >>
>     >> >> >> format.pval(c(0.12, a), eps=0.01)[-1]
>     >> >> >>
>     >> >> >> gives you what you want (because the 0.12 forces two decimal place
>     >> >> >> display on all values, and then the [-1] removes it).
>     >> >> >>
>     >> >> >
>     >> >> > Clever, but the problem would be that summary.lm, etc. call format.pval so the
>     >> >> > user does not have a chance to do that.
>     >> >>
>     >> >> I don't see how this is relevant.  summary.lm doesn't let you pass a new
>     >> >> eps value either.  Adding an "nsmall=2" argument to format.pval wouldn't
>     >> >> help with the display in summary.lm.
>     >> >>
>     >> >> I suppose we could track down every use of format.pval in every function
>     >> >> in every package and add nsmall and eps as arguments to each of them,
>     >> >> but that's just ridiculous.  People should accept the fact that R
>     >> >> doesn't produce publication quality text, it just provides you with ways
>     >> >> to produce that yourself.
>     >> >>
>     >> >> Duncan Murdoch
>     >> >>
>     >> >
>     >> > You are right in terms of my example which was not applicable but I
>     >> > think in general that format.pval is used from within other routines rather than
>     >> > directly by the user so the user may not have a chance to massage it
>     >> > directly.
>     >> 
>     >> Right, but this means that it is more or less useless to change the
>     >> argument list for format.pvals in the way Charles suggested, because all
>     >> of the existing uses of it would ignore the new parameters.
>     >> 
>     >> It would not be so difficult to change the behaviour of format.pvals so
>     >> that for example "digits=2" implied the equivalent of "nsmall=2", but I
>     >> don't think that's a universally desirable change.
>     >> 
>     >> The difficulty here is that different people have different tastes for
>     >> presentation-quality text.  Not everyone would agree that the version
>     >> with trailing zeros is preferable to the one without.  R should be
>     >> flexible enough to allow people to customize their displays, but not
>     >> necessarily by having every print method flexible enough to satisfy
>     >> every user:  sometimes users need to construct their own output formats.
>     >> 
>     >> Duncan Murdoch
> 
>     Gabor> One possibility would be to add args to format.pval whose defaults
>     Gabor> can be set through options.  Not beautiful but it would give the user
>     Gabor> who really needed it a way to do it.
> 
> Yes indeed, I had had the same thought (very early in this
> thread).  This doesn't mean that I wouldn't agree with Duncan's
> statement above anyway.
> 
> Whereas I have strong opinion on *not* allowing options() to
> influence too many things [it's entirely contrary to the
> principle of functional programming], 
> options() have always been used to tweak print()ing; so they
> could be used here as well.
> As original author of format.pval(), I'm happy to accept patches
> --- if they are done well and also patch 
>     src/library/base/man/format.pval.Rd and ..../man/options.Rd 
> 
> Martin
> 

I have included a patch for 'format.pval' in which I have implemented 
what I think of as the optimal solution for the problem.  Which is to 
add a '...' arg to format.pval and pass it to the 'format' function calls.

Patch was created for the r-release branch but will successfully apply 
to the r-devel branch.

Index: src/library/base/R/format.R
===================================================================
--- src/library/base/R/format.R (revision 40867)
+++ src/library/base/R/format.R (working copy)
@@ -43,7 +43,7 @@
  }

  format.pval <- function(pv, digits = max(1, getOption("digits")-2),
-                       eps = .Machine$double.eps, na.form = "NA")
+                       eps = .Machine$double.eps, na.form = "NA", ...)
  {
      ## Format  P values; auxiliary for print.summary.[g]lm(.)

@@ -55,8 +55,8 @@
         ## be smart -- differ for fixp. and expon. display:
         expo <- floor(log10(ifelse(pv > 0, pv, 1e-50)))
         fixp <- expo >= -3 | (expo == -4 & digits>1)
-       if(any( fixp)) rr[ fixp] <- format(pv[ fixp], dig=digits)
-       if(any(!fixp)) rr[!fixp] <- format(pv[!fixp], dig=digits)
+       if(any( fixp)) rr[ fixp] <- format(pv[ fixp], dig=digits, ...)
+       if(any(!fixp)) rr[!fixp] <- format(pv[!fixp], dig=digits, ...)
         r[!is0]<- rr
      }
      if(any(is0)) {
@@ -67,7 +67,7 @@
                 digits <- max(1, nc - 7)
             sep <- if(digits==1 && nc <= 6) "" else " "
         } else sep <- if(digits==1) "" else " "
-       r[is0] <- paste("<", format(eps, digits=digits), sep = sep)
+       r[is0] <- paste("<", format(eps, digits=digits, ...), sep = sep)
      }
      if(has.na) { ## rarely
         rok <- r
Index: src/library/base/man/format.pval.Rd
===================================================================
--- src/library/base/man/format.pval.Rd (revision 40867)
+++ src/library/base/man/format.pval.Rd (working copy)
@@ -6,13 +6,14 @@
  \alias{format.pval}
  \usage{
  format.pval(pv, digits = max(1, getOption("digits") - 2),
-            eps = .Machine$double.eps, na.form = "NA")
+            eps = .Machine$double.eps, na.form = "NA", \dots)
  }
  \arguments{
    \item{pv}{a numeric vector.}
    \item{digits}{how many significant digits are to be used.}
    \item{eps}{a numerical tolerance: see Details.}
    \item{na.form}{character representation of \code{NA}s.}
+  \item{\dots}{arguments passed to the \code{\link{format}} function.}
  }
  \value{
    A character vector.


-- 
Charles Dupont	Computer System Analyst		School of Medicine
		Department of Biostatistics	Vanderbilt University


From ripley at stats.ox.ac.uk  Wed Mar 21 22:13:27 2007
From: ripley at stats.ox.ac.uk (ripley at stats.ox.ac.uk)
Date: Wed, 21 Mar 2007 22:13:27 +0100 (CET)
Subject: [Rd] rbind.data.frame reacts on levels without factor (PR#9578)
Message-ID: <20070321211327.1FB715AD32@slim.kubism.ku.dk>

There is no example to reproduce here. Please do show the courtesy to 
follow the request at the bottom of every R-help posting and many other 
places and provide some reproducible evidence to support your points.

On Wed, 21 Mar 2007, prechelt at inf.fu-berlin.de wrote:

> Full_Name: Lutz Prechelt
> Version: 2.4.1
> OS: Windows XP
> Submission from: (NULL) (160.45.111.67)
>
>
> I stack a number of data.frames using rbind.
> Each of these dataframes has a column 'authorname', which is a factor
> and a column author = unclass(authorname) as piecewise pseudonyms.
> When using rbind to stack these dataframes, R warns about invalid factor levels
> and inserts all NAs in the author column.
>
> The reason appears to be that rbind.data.frame looks for the presence of levels,
> not actually for class==factor when deciding what to handle as a factor:
>                  if (!is.null(levels(xj))) {
>
> I find this behavior surprising, hence dangerous, and it is not documented.
> Rather, the documentation says:
>    "The 'rbind' data frame method takes the classes of the columns
>     from the first data frame, and matches columns by name (rather
>     than by position).  Factors have their levels expanded as
>     necessary [...]"
>
> The behavior has bitten me fairly hard, because I searched for the origin of the
> warning in all the wrong places before finding the real one after about 3
> hours.
> (Although I still have not understood _why_ it results in that warning.)
>
> I believe the behavior of rbind.data.frame should be fixed, so that it ignores
> levels attributes when there is no factor class as well.
>
> The alternative would be to just add a warning to the documentation that
> 'unclass' on factors is insufficient if users want to avoid factor handling for
> rbind.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Thu Mar 22 12:52:13 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 22 Mar 2007 11:52:13 +0000 (GMT)
Subject: [Rd] (PR#9577) bug and patch: strptime first-of-month error in
 (possibly unsupported use of) "%j" format
In-Reply-To: <20070321145835.647A85AB2A@slim.kubism.ku.dk>
References: <20070321145835.647A85AB2A@slim.kubism.ku.dk>
Message-ID: <Pine.LNX.4.64.0703221150340.27006@auk.stats>

The aim was to fix up some unsupported cases in glibc and related 
implementations, and clearly we only managed to do so partially.

Thank you: I've applied the change (and a regression test) to 2.5.0-to-be.

On Wed, 21 Mar 2007, jbrzusto at fastmail.fm wrote:

> Full_Name: John Brzustowski
> Version: R-devel-trunk
> OS: linux (problem under Windows too)
> Submission from: (NULL) (74.101.124.238)
>
>
> (This bug was discovered by Phil Taylor, Acadia University.)
> I'm not sure from reading the documentation whether strptime(x, "%j") is meant
> to be supported, but if so, there is a bug which prevents it from working on the
> first day of months after January:
>
>> strptime(31:33, "%j")
> [1] "2007-01-31" NA           "2007-02-02"
>
> # the full extent of R's taunting
> strptime(1 + cumsum(c(31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30)), "%j")
> [1] NA NA NA NA NA NA NA NA NA NA NA
>>
>
> The problem is an edge-case comparison in datetime.c:glibc_fix().  This
> generates a date like "Jan 32", which validate_tm() catches and NAs.
> (Values of field tm->tm_yday start at 0, not 1.)
> =================================================================================
> PATCH:
>
> --- R/src/main/datetime.c	(revision 40860)
> +++ R/src/main/datetime.c	(working copy)
> @@ -796,7 +796,7 @@
>     if(tm->tm_yday != NA_INTEGER) {
> 	/* since we have yday, let that take precedence over mon/mday */
> 	int yday = tm->tm_yday, mon = 0;
> -	while(yday > (tmp = days_in_month[mon] +
> +	while(yday >= (tmp = days_in_month[mon] +
> 		      ((mon==1 && isleap(1900+tm->tm_year))? 1 : 0))) {
> 	    yday -= tmp;
> 	    mon++;
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From mtmorgan at fhcrc.org  Thu Mar 22 20:05:03 2007
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Thu, 22 Mar 2007 12:05:03 -0700
Subject: [Rd] Shared lib locations (was Re: [R] problem with RCurl install
 on Unix0
In-Reply-To: <Pine.LNX.4.64.0703221115560.19977@auk.stats> (Brian Ripley's
	message of "Thu, 22 Mar 2007 11:25:05 +0000 (GMT)")
References: <4601AD1E.30408@gmail.com>
	<0BE438149FF2254DB4199E2682C8DFEB0235FB7B@crcmail1.BCCRC.CA>
	<17922.20431.96168.831263@stat.math.ethz.ch>
	<Pine.LNX.4.64.0703221115560.19977@auk.stats>
Message-ID: <6phwt19umjk.fsf_-_@gopher4.fhcrc.org>

[moved to R-devel]

As a package author, how can I let R know of a non-standard location
for shared libs, e.g., because my configure script went to extra
effort to find a shared library, or my package has more than one
shared library? Maybe another question is, in a package, where should
I place my shared libs (and how should they be named) so that R will
find them (I realize library libs/X.so is created for package X; it
seems that a library Y.so that X.so uses is not found when named
libs/Y.so or libs/libY.so).

Thanks,

(another) Martin

Prof Brian Ripley <ripley at stats.ox.ac.uk> writes:

> On Thu, 22 Mar 2007, Martin Maechler wrote:
>
>>>>>>> "Steven" == Steven McKinney <smckinney at bccrc.ca>
>>>>>>>     on Wed, 21 Mar 2007 19:29:43 -0700 writes:
>>
>>    Steven> I get the same problem, and haven't
>>    Steven> figured it out yet.
>>
>>    Steven> Is it a 32bit/64bit clash?
>>
>> Well, I can install and run  RCurl  on both 32bit and 64bit
>> (Redhat / FC6  Linux; with own compilers, extra libs, ...).
>>
>>    Steven> (Similarly, I don't have RMySQL up and running cleanly.)
>>
>>
>>
>>
>>    >> library(RCurl)
>>    Steven> Error in dyn.load(x, as.logical(local), as.logical(now)) :
>>    Steven> unable to load shared library '/share/apps/R/R-2.4.1/library/RCurl/libs/RCurl.so':
>>    Steven> libcurl.so.4: cannot open shared object file: No such file or directory
>>    Steven> Error: package/namespace load failed for 'RCurl'
>>
>> You might need to set  LD_LIBRARY_PATH  correctly
>> before starting R -- typically it would be set the same as it
>> was when RCurl was installed (which includes a 'configure' !) on
>> your system?  Or  RCurl's configure is not quite robust enough
>> and did not check for the presence of a libcurl.so.4
>>
>> I assume
>>
>>  ldd /share/apps/R/R-2.4.1/library/RCurl/libs/RCurl.so
>
> You may well need
>
> R CMD ldd /share/apps/R/R-2.4.1/library/RCurl/libs/RCurl.so
>
> as the R front end sets LD_LIBRARY_PATH.
>
>> also tells about the missing  libcurl.so.4 ?
>> Make sure you find that (in /usr/lib; /usr/local/lib, ... ?)
>> and then set your LD_LIBRARY_PATH
>> or even   'ldconfig' as root to make sure that libcurl.so.4 ``is
>> found''.
>> IMO the latter {correct ldconfig call / /etc/ld.so.conf setup}
>> should have happened as part of the installation of the curl
>> library.
>
> I find it very common for software packages to install into 
> /usr/local/lib (not lib64) and not to think about the ldconfig paths.
> Both are things that RPMs tend to correct.
>
>> On the 64-bit architecture, note that
>>
>> > system(paste("ldd", dir(system.file("libs", package = "RCurl"), full=TRUE)))
>>
>> finds all libraries in /lib64 and /usr/lib64 .
>
> I think you mean on Redhat-based AMD64 Linux.  This is something that 
> differs by 64-bit architecture (ia64 uses /lib) and also Linux distro (at 
> least in the past).
>
> RMySQL does not install out of the box on any of our 64-bit systems 
> (another lib vs lib64 issue), and I've sent patches to the maintainer.
>
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Martin Morgan
Bioconductor / Computational Biology
http://bioconductor.org


From ripley at stats.ox.ac.uk  Thu Mar 22 20:12:40 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 22 Mar 2007 19:12:40 +0000 (GMT)
Subject: [Rd] [R] Can I scale the labels in a 'persp' graph?
In-Reply-To: <45FA999D.1090406@stats.uwo.ca>
References: <mailman.11.1174042804.26780.r-help@stat.math.ethz.ch>
	<Pine.LNX.4.64.0703161252350.30144@obelix.umh.es>
	<45FA999D.1090406@stats.uwo.ca>
Message-ID: <Pine.LNX.4.64.0703221909020.22676@gannet.stats.ox.ac.uk>

[Moved to R-devel to ask a policy question.]

On Fri, 16 Mar 2007, Duncan Murdoch wrote:

> On 3/16/2007 8:02 AM, salcaraz at obelix.umh.es wrote:
>> Hi all:
>>
>> I'm using 'persp' for 3D graphics.
>>
>> I need the axis's labels smaller than by defect.
>>
>> I see in 'help()', the information about 'par()'.
>>
>> I have wrote:
>>
>>> par(.....,cex.axis=0.5,cex.lab=0.5)
>> perspc(.................)
>>
>> and the result don't change.
>>
>> The question is: Can I change the size of labels in the perps graph??
>>
>> Thank you in advance:
>>
>> /salva
>>
>> 'cex.axis' The magnification to be used for axis annotation
>>            relative to the current setting of 'cex'. (Some functions
>>            such as 'points' accept a vector of values which are
>>            recycled.  Other uses will take just the first value if a
>>            vector of length greater than one is supplied.)
>>
>> 'cex.lab' The magnification to be used for x and y labels relative
>>            to the current setting of 'cex'.
>
> Those don't appear to be supported by persp, but cex is: e.g.
>
> x <- 1:10
> y <- 1:10
> z <- outer(x,y,function(x,y) sin((x+y)/10))
> persp(x,y,z, cex=0.5)

I've added this to ?persp and ?par, but I wondered if people thought we 
should change this to be like 2D plots.  Especially Ross I., who I believe 
is the author here?

Brian

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From cstrato at aon.at  Thu Mar 22 23:22:09 2007
From: cstrato at aon.at (cstrato)
Date: Thu, 22 Mar 2007 23:22:09 +0100
Subject: [Rd] how to use debug.mypkg
Message-ID: <46030191.30006@aon.at>

Dear all,

The package "affy" has the following statement in file "AffyBatch.R":
if (debug.affy123) cat("-->initAffyBatch\n")

This is great and I would also like to use it. However, when I run my 
package
I get the following error:
Error in .local(object, ...) : object "debug.mypkg" not found

Since I am not able to find the position where "affy" defines 
"debug.affy123"
my question is: where do I need to  define "debug.mypkg"?

Thank you in advance
Best regards
Christian
_._._._._._._._._._._._._._._._
C.h.i.s.t.i.a.n S.t.r.a.t.o.w.a
V.i.e.n.n.a       A.u.s.t.r.i.a
_._._._._._._._._._._._._._._._


From bcarvalh at jhsph.edu  Thu Mar 22 23:35:10 2007
From: bcarvalh at jhsph.edu (Benilton Carvalho)
Date: Thu, 22 Mar 2007 18:35:10 -0400
Subject: [Rd] how to use debug.mypkg
In-Reply-To: <46030191.30006@aon.at>
References: <46030191.30006@aon.at>
Message-ID: <5BDFDBB7-9AE2-4410-916A-3A17FA4DD3E9@jhsph.edu>

debug.affy123 is not a function... it's just a logical flag set in  
ProgressBarText.R.

b

On Mar 22, 2007, at 6:22 PM, cstrato wrote:

> Dear all,
>
> The package "affy" has the following statement in file "AffyBatch.R":
> if (debug.affy123) cat("-->initAffyBatch\n")
>
> This is great and I would also like to use it. However, when I run my
> package
> I get the following error:
> Error in .local(object, ...) : object "debug.mypkg" not found
>
> Since I am not able to find the position where "affy" defines
> "debug.affy123"
> my question is: where do I need to  define "debug.mypkg"?
>
> Thank you in advance
> Best regards
> Christian
> _._._._._._._._._._._._._._._._
> C.h.i.s.t.i.a.n S.t.r.a.t.o.w.a
> V.i.e.n.n.a       A.u.s.t.r.i.a
> _._._._._._._._._._._._._._._._
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From cstrato at aon.at  Thu Mar 22 23:52:01 2007
From: cstrato at aon.at (cstrato)
Date: Thu, 22 Mar 2007 23:52:01 +0100
Subject: [Rd] how to use debug.mypkg
In-Reply-To: <5BDFDBB7-9AE2-4410-916A-3A17FA4DD3E9@jhsph.edu>
References: <46030191.30006@aon.at>
	<5BDFDBB7-9AE2-4410-916A-3A17FA4DD3E9@jhsph.edu>
Message-ID: <46030891.3030207@aon.at>

Yes, I know, but somewhere in my package I need to define this flag.
When I set the flag "debug.mypkg<-T" in the R session, everything works,
but the problem is that if I do not set it, it is undefined. So I need 
to set it
initially in my package, but where?

Christian

Benilton Carvalho wrote:
> debug.affy123 is not a function... it's just a logical flag set in 
> ProgressBarText.R.
>
> b
>
> On Mar 22, 2007, at 6:22 PM, cstrato wrote:
>
>> Dear all,
>>
>> The package "affy" has the following statement in file "AffyBatch.R":
>> if (debug.affy123) cat("-->initAffyBatch\n")
>>
>> This is great and I would also like to use it. However, when I run my
>> package
>> I get the following error:
>> Error in .local(object, ...) : object "debug.mypkg" not found
>>
>> Since I am not able to find the position where "affy" defines
>> "debug.affy123"
>> my question is: where do I need to  define "debug.mypkg"?
>>
>> Thank you in advance
>> Best regards
>> Christian
>> _._._._._._._._._._._._._._._._
>> C.h.i.s.t.i.a.n S.t.r.a.t.o.w.a
>> V.i.e.n.n.a       A.u.s.t.r.i.a
>> _._._._._._._._._._._._._._._._
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From bcarvalh at jhsph.edu  Fri Mar 23 02:37:14 2007
From: bcarvalh at jhsph.edu (Benilton Carvalho)
Date: Thu, 22 Mar 2007 21:37:14 -0400
Subject: [Rd] how to use debug.mypkg
In-Reply-To: <46030891.3030207@aon.at>
References: <46030191.30006@aon.at>
	<5BDFDBB7-9AE2-4410-916A-3A17FA4DD3E9@jhsph.edu>
	<46030891.3030207@aon.at>
Message-ID: <B0F5F7FF-89D9-46EF-B7D4-EA3D363D9A68@jhsph.edu>

it doesn't matter where..

just pick one of your files and set it...

of course, your file should be listed in the Collate field (in case  
you changed your mind and are now using it).

b

On Mar 22, 2007, at 6:52 PM, cstrato wrote:

> Yes, I know, but somewhere in my package I need to define this flag.
> When I set the flag "debug.mypkg<-T" in the R session, everything  
> works,
> but the problem is that if I do not set it, it is undefined. So I  
> need to set it
> initially in my package, but where?
>
> Christian
>
> Benilton Carvalho wrote:
>> debug.affy123 is not a function... it's just a logical flag set in  
>> ProgressBarText.R.
>>
>> b
>>
>> On Mar 22, 2007, at 6:22 PM, cstrato wrote:
>>
>>> Dear all,
>>>
>>> The package "affy" has the following statement in file  
>>> "AffyBatch.R":
>>> if (debug.affy123) cat("-->initAffyBatch\n")
>>>
>>> This is great and I would also like to use it. However, when I  
>>> run my
>>> package
>>> I get the following error:
>>> Error in .local(object, ...) : object "debug.mypkg" not found
>>>
>>> Since I am not able to find the position where "affy" defines
>>> "debug.affy123"
>>> my question is: where do I need to  define "debug.mypkg"?
>>>
>>> Thank you in advance
>>> Best regards
>>> Christian
>>> _._._._._._._._._._._._._._._._
>>> C.h.i.s.t.i.a.n S.t.r.a.t.o.w.a
>>> V.i.e.n.n.a       A.u.s.t.r.i.a
>>> _._._._._._._._._._._._._._._._
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>


From sfalcon at fhcrc.org  Fri Mar 23 02:54:04 2007
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Thu, 22 Mar 2007 18:54:04 -0700
Subject: [Rd] how to use debug.mypkg
In-Reply-To: <B0F5F7FF-89D9-46EF-B7D4-EA3D363D9A68@jhsph.edu> (Benilton
	Carvalho's message of "Thu, 22 Mar 2007 21:37:14 -0400")
References: <46030191.30006@aon.at>
	<5BDFDBB7-9AE2-4410-916A-3A17FA4DD3E9@jhsph.edu>
	<46030891.3030207@aon.at>
	<B0F5F7FF-89D9-46EF-B7D4-EA3D363D9A68@jhsph.edu>
Message-ID: <m2hcsc67yb.fsf@ziti.fhcrc.org>

Benilton Carvalho <bcarvalh at jhsph.edu> writes:

> it doesn't matter where..
>
> just pick one of your files and set it...
>
> of course, your file should be listed in the Collate field (in case  
> you changed your mind and are now using it).

One useful trick is to create an environment object in your package's
namespace.  It is probably best to put this early in the Collate order
so all your code can assume it is there:

   OPTIONS <- new.env(hash=TRUE, parent=emptyenv())

Then you could have, for example, a debug flag that gets a default
value of FALSE, but can be interactively toggled.  In your package
code you would have:

   OPTIONS$debug <- FALSE

Then you could either export this object from your namespace or, more
conservatively, export a function to toggle.  Then an end user (or
developer) can do:

  R> toggleDebug()

Obviously, for this to be useful, you need to have package code that
checks if(OPTIONS$debug) and does something different.

+ seth

-- 
Seth Falcon | Computational Biology | Fred Hutchinson Cancer Research Center
http://bioconductor.org


From bcarvalh at jhsph.edu  Fri Mar 23 03:16:54 2007
From: bcarvalh at jhsph.edu (Benilton Carvalho)
Date: Thu, 22 Mar 2007 22:16:54 -0400
Subject: [Rd] how to use debug.mypkg
In-Reply-To: <m2hcsc67yb.fsf@ziti.fhcrc.org>
References: <46030191.30006@aon.at>
	<5BDFDBB7-9AE2-4410-916A-3A17FA4DD3E9@jhsph.edu>
	<46030891.3030207@aon.at>
	<B0F5F7FF-89D9-46EF-B7D4-EA3D363D9A68@jhsph.edu>
	<m2hcsc67yb.fsf@ziti.fhcrc.org>
Message-ID: <14A6B3CD-CAA8-466F-8AE6-BD18B43E61E7@jhsph.edu>

Great tip Seth...

thanks a bunch...

b

On Mar 22, 2007, at 9:54 PM, Seth Falcon wrote:

> Benilton Carvalho <bcarvalh at jhsph.edu> writes:
>
>> it doesn't matter where..
>>
>> just pick one of your files and set it...
>>
>> of course, your file should be listed in the Collate field (in case
>> you changed your mind and are now using it).
>
> One useful trick is to create an environment object in your package's
> namespace.  It is probably best to put this early in the Collate order
> so all your code can assume it is there:
>
>    OPTIONS <- new.env(hash=TRUE, parent=emptyenv())
>
> Then you could have, for example, a debug flag that gets a default
> value of FALSE, but can be interactively toggled.  In your package
> code you would have:
>
>    OPTIONS$debug <- FALSE
>
> Then you could either export this object from your namespace or, more
> conservatively, export a function to toggle.  Then an end user (or
> developer) can do:
>
>   R> toggleDebug()
>
> Obviously, for this to be useful, you need to have package code that
> checks if(OPTIONS$debug) and does something different.
>
> + seth
>
> --  
> Seth Falcon | Computational Biology | Fred Hutchinson Cancer  
> Research Center
> http://bioconductor.org
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From mwkimpel at gmail.com  Fri Mar 23 03:40:07 2007
From: mwkimpel at gmail.com (Mark W Kimpel)
Date: Thu, 22 Mar 2007 22:40:07 -0400
Subject: [Rd] can't load just saved R object "ReadItem: unknown type 65"
Message-ID: <46033E07.4040905@gmail.com>

I have run into a problem loading a just saved R object using R-devel. I 
have been saving and loading this particular type of R object for a long 
while and never ran into this problem. I save, then immediately reload 
(to test save) and get "ReadItem: unnknown type 65".

This error is reproducible after logout from server and restart of emacs 
and R.

Below is my output and sessionInfo().

Thanks,
Mark

 > setwd("~/Genomics/Experiments.Genomic/BB01/acb.shell")
 > local(save(affy.object.preprocessed, file 
="affy.object.preprocessed.R" ))
 > load("affy.object.preprocessed.R")
Error in load("affy.object.preprocessed.R") :
	ReadItem: unknown type 65, perhaps written by later version of R
 > sessionInfo()
R version 2.5.0 Under development (unstable) (2007-03-11 r40824)
powerpc64-unknown-linux-gnu

locale:
LC_CTYPE=en_US.UTF-8;LC_NUMERIC=C;LC_TIME=en_US.UTF-8;LC_COLLATE=en_US.UTF-8;LC_MONETARY=en_US.UTF-8;LC_MESSAGES=en_US.UTF-8;LC_PAPER=en_US.UTF-8;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=en_US.UTF-8;LC_IDENTIFICATION=C

attached base packages:
[1] "splines"   "stats"     "graphics"  "grDevices" "datasets"  "utils"
[7] "tools"     "methods"   "base"

other attached packages:
      multtest    rat2302cdf affycoretools       annaffy        xtable
      "1.13.1"      "1.15.0"       "1.7.8"       "1.7.3"       "1.4-3"
         gcrma   matchprobes       biomaRt         RCurl           XML
       "2.7.3"       "1.7.4"      "1.9.21"       "0.8-0"       "1.6-0"
       GOstats      Category        Matrix       lattice    genefilter
      "2.1.13"      "2.1.20"   "0.9975-11"     "0.14-16"      "1.13.8"
      survival          KEGG          RBGL      annotate            GO
        "2.31"     "1.15.12"      "1.11.4"      "1.13.6"     "1.15.12"
         graph         limma          affy        affyio       Biobase
      "1.13.6"      "2.9.13"     "1.13.14"       "1.3.3"     "1.13.39"
-- 
Mark W. Kimpel MD
Neuroinformatics
Department of Psychiatry
Indiana University School of Medicine


From groemp at tfh-berlin.de  Fri Mar 23 13:13:56 2007
From: groemp at tfh-berlin.de (=?UTF-8?Q?Ulrike_Gr=C3=B6mping?=)
Date: Fri, 23 Mar 2007 05:13:56 -0700 (PDT)
Subject: [Rd] Bug in str or issue with class management in my package?
Message-ID: <9633559.post@talk.nabble.com>


Dear developeRs,

with R 2.4.1 (and also 2.4.0), the function str() fails on objects of class
relimplmbooteval, if there are unused slots, which is very often the case. I
am not sure whether this is a bug in str() or a correct behavior of str()
that unmasks some sloppiness in my usage of S4 classes (that I am not aware
of)?

Reproducible example (package relaimpo needed):

The program 

require(relaimpo)
bte<-booteval.relimp(boot.relimp(swiss,b=100))
str(bte)

yields the error message

Errorr in FUN(c("lmg.lower", "lmg.upper", "lmg.rank.lower",
"lmg.rank.upper",  : 
        no slot named "pmvd.lower" for this object of class
"relimplmbooteval"
(back-translated from German).

Regards, Ulrike
-- 
View this message in context: http://www.nabble.com/Bug-in-str-or-issue-with-class-management-in-my-package--tf3453429.html#a9633559
Sent from the R devel mailing list archive at Nabble.com.


From luke at stat.uiowa.edu  Fri Mar 23 13:56:14 2007
From: luke at stat.uiowa.edu (Luke Tierney)
Date: Fri, 23 Mar 2007 07:56:14 -0500 (CDT)
Subject: [Rd] [R] can't load just saved R object "ReadItem: unknown type
	65"
In-Reply-To: <46033E07.4040905@gmail.com>
References: <46033E07.4040905@gmail.com>
Message-ID: <Pine.LNX.4.64.0703230753500.20383@nokomis.stat.uiowa.edu>

According to the logs nothing at all has changed in the serialization
code in a month and nothing of consequence for much longer than that.
To track this down we will need a complete, reproducible, and
preferably minimal example.

Best,

luke

On Thu, 22 Mar 2007, Mark W Kimpel wrote:

> I have run into a problem loading a just saved R object using R-devel. I
> have been saving and loading this particular type of R object for a long
> while and never ran into this problem. I save, then immediately reload
> (to test save) and get "ReadItem: unnknown type 65".
>
> This error is reproducible after logout from server and restart of emacs
> and R.
>
> Below is my output and sessionInfo().
>
> Thanks,
> Mark
>
> > setwd("~/Genomics/Experiments.Genomic/BB01/acb.shell")
> > local(save(affy.object.preprocessed, file
> ="affy.object.preprocessed.R" ))
> > load("affy.object.preprocessed.R")
> Error in load("affy.object.preprocessed.R") :
> 	ReadItem: unknown type 65, perhaps written by later version of R
> > sessionInfo()
> R version 2.5.0 Under development (unstable) (2007-03-11 r40824)
> powerpc64-unknown-linux-gnu
>
> locale:
> LC_CTYPE=en_US.UTF-8;LC_NUMERIC=C;LC_TIME=en_US.UTF-8;LC_COLLATE=en_US.UTF-8;LC_MONETARY=en_US.UTF-8;LC_MESSAGES=en_US.UTF-8;LC_PAPER=en_US.UTF-8;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=en_US.UTF-8;LC_IDENTIFICATION=C
>
> attached base packages:
> [1] "splines"   "stats"     "graphics"  "grDevices" "datasets"  "utils"
> [7] "tools"     "methods"   "base"
>
> other attached packages:
>      multtest    rat2302cdf affycoretools       annaffy        xtable
>      "1.13.1"      "1.15.0"       "1.7.8"       "1.7.3"       "1.4-3"
>         gcrma   matchprobes       biomaRt         RCurl           XML
>       "2.7.3"       "1.7.4"      "1.9.21"       "0.8-0"       "1.6-0"
>       GOstats      Category        Matrix       lattice    genefilter
>      "2.1.13"      "2.1.20"   "0.9975-11"     "0.14-16"      "1.13.8"
>      survival          KEGG          RBGL      annotate            GO
>        "2.31"     "1.15.12"      "1.11.4"      "1.13.6"     "1.15.12"
>         graph         limma          affy        affyio       Biobase
>      "1.13.6"      "2.9.13"     "1.13.14"       "1.3.3"     "1.13.39"
>

-- 
Luke Tierney
Chair, Statistics and Actuarial Science
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From mtmorgan at fhcrc.org  Fri Mar 23 14:01:04 2007
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Fri, 23 Mar 2007 06:01:04 -0700
Subject: [Rd] Bug in str or issue with class management in my package?
In-Reply-To: <9633559.post@talk.nabble.com> (Ulrike
	=?iso-8859-1?q?Gr=F6mping's?= message of "Fri,
	23 Mar 2007 05:13:56 -0700 (PDT)")
References: <9633559.post@talk.nabble.com>
Message-ID: <6phzm646rn3.fsf@gopher4.fhcrc.org>

Ulrike,

booteval.relimp has the statement

    ausgabe <- calc.relimp(empcov, type = type, diff = diff, 
        rank = rank, rela = rela, always = always, groups = groups, 
        groupnames = groupnames)
    class(ausgabe) <- "relimplmbooteval"

This changes the name of the class of ausgabe, without changing its
structure. I'm guessing that prior to this call ausgabe did not have a
slot "pmvd.lower". Here's the simpler version:

>setClass("A", representation=representation(x="numeric"))
[1] "A"
> setClass("B", contains="A", representation=representation(y="numeric"))
[1] "B"
> a <- new("A")
> class(a) <- "B"
> str(a)
Error in FUN(c("y", "x")[[1L]], ...) : no slot of name "y" for this object of class "B"

and some behavior which is somehow weird:

> slot(a, "y")
Error in slot(a, "y") : no slot of name "y" for this object of class "B"
> slot(a, "y") <- 10 # 'creates' the slot!
> slot(a, "y")
[1] 10

Probably what you want to do is to create a 'setAs' method

setAs('relimplm', 'relimplmbooteval',
      function(from) {
          <your code here, e.g.,>
      })

and use

    ausgabe <- as(ausgabe, "relimplmbooteval")

I'm not really sure what <your code here> should look like; my first
stab was

          obj <- new("relimplmbooteval")
          slots <- slotNames(from)
          for (slt in slots)
              slot(obj, slt) <- slot(from, slt)
          obj

which would not be very memory efficient (each slot assignment copies
the entire object) but is perhaps fine for your needs.

Hope that helps

Martin

Ulrike Gr?mping <groemp at tfh-berlin.de> writes:

> Dear developeRs,
>
> with R 2.4.1 (and also 2.4.0), the function str() fails on objects of class
> relimplmbooteval, if there are unused slots, which is very often the case. I
> am not sure whether this is a bug in str() or a correct behavior of str()
> that unmasks some sloppiness in my usage of S4 classes (that I am not aware
> of)?
>
> Reproducible example (package relaimpo needed):
>
> The program 
>
> require(relaimpo)
> bte<-booteval.relimp(boot.relimp(swiss,b=100))
> str(bte)
>
> yields the error message
>
> Errorr in FUN(c("lmg.lower", "lmg.upper", "lmg.rank.lower",
> "lmg.rank.upper",  : 
>         no slot named "pmvd.lower" for this object of class
> "relimplmbooteval"
> (back-translated from German).
>
> Regards, Ulrike
> -- 
> View this message in context: http://www.nabble.com/Bug-in-str-or-issue-with-class-management-in-my-package--tf3453429.html#a9633559
> Sent from the R devel mailing list archive at Nabble.com.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Martin Morgan
Bioconductor / Computational Biology
http://bioconductor.org


From pgilbert at bank-banque-canada.ca  Fri Mar 23 14:48:06 2007
From: pgilbert at bank-banque-canada.ca (Paul Gilbert)
Date: Fri, 23 Mar 2007 09:48:06 -0400
Subject: [Rd] how to use debug.mypkg
In-Reply-To: <m2hcsc67yb.fsf@ziti.fhcrc.org>
References: <46030191.30006@aon.at>	<5BDFDBB7-9AE2-4410-916A-3A17FA4DD3E9@jhsph.edu>	<46030891.3030207@aon.at>	<B0F5F7FF-89D9-46EF-B7D4-EA3D363D9A68@jhsph.edu>
	<m2hcsc67yb.fsf@ziti.fhcrc.org>
Message-ID: <4603DA96.4080706@bank-banque-canada.ca>

Here is the way I do something similar in my dse1 package:

..onLoad  <- function(library, section) {
    .DSEflags(list(COMPILED=TRUE, DUP=TRUE))
    invisible(TRUE)
    }

..DSEflags <- local({
    .DSE.flags <- character(0)
    function(new) {
        if(!missing(new))
            .DSE.flags <<- new
        else
            .DSE.flags
        }
})

This was suggested to me a few years ago (by Kurt I think).  It works 
well.  A call to .DSEflags() displays the settings and a list argument 
sets them.

Paul

Seth Falcon wrote:
> Benilton Carvalho <bcarvalh at jhsph.edu> writes:
> 
>> it doesn't matter where..
>>
>> just pick one of your files and set it...
>>
>> of course, your file should be listed in the Collate field (in case  
>> you changed your mind and are now using it).
> 
> One useful trick is to create an environment object in your package's
> namespace.  It is probably best to put this early in the Collate order
> so all your code can assume it is there:
> 
>    OPTIONS <- new.env(hash=TRUE, parent=emptyenv())
> 
> Then you could have, for example, a debug flag that gets a default
> value of FALSE, but can be interactively toggled.  In your package
> code you would have:
> 
>    OPTIONS$debug <- FALSE
> 
> Then you could either export this object from your namespace or, more
> conservatively, export a function to toggle.  Then an end user (or
> developer) can do:
> 
>   R> toggleDebug()
> 
> Obviously, for this to be useful, you need to have package code that
> checks if(OPTIONS$debug) and does something different.
> 
> + seth
> 
====================================================================================

La version fran?aise suit le texte anglais.

------------------------------------------------------------------------------------

This email may contain privileged and/or confidential inform...{{dropped}}


From groemp at tfh-berlin.de  Fri Mar 23 16:39:32 2007
From: groemp at tfh-berlin.de (=?UTF-8?Q?Ulrike_Gr=C3=B6mping?=)
Date: Fri, 23 Mar 2007 08:39:32 -0700 (PDT)
Subject: [Rd] Bug in str or issue with class management in my package?
In-Reply-To: <6phzm646rn3.fsf@gopher4.fhcrc.org>
References: <9633559.post@talk.nabble.com> <6phzm646rn3.fsf@gopher4.fhcrc.org>
Message-ID: <9637517.post@talk.nabble.com>


Martin,

thank you, you've pointed me in the right direction! I just wasn't aware
that a slot must not be unassigned (everything but str worked so far, and
even str works in R 2.3.1). 

Actually, looking up the help for function new, I see that the solution is
much easier, because my class relimplmbooteval extends the class relimplm of
the object ausgabe. Therefore, I can simply write 
          obj <- new("relimplmbooteval", ausgabe)
which copies all slots from ausgabe to the right place in the new obj.

Regards, Ulrike


Martin Morgan wrote:
> 
> Ulrike,
> 
> booteval.relimp has the statement
> 
>     ausgabe <- calc.relimp(empcov, type = type, diff = diff, 
>         rank = rank, rela = rela, always = always, groups = groups, 
>         groupnames = groupnames)
>     class(ausgabe) <- "relimplmbooteval"
> 
> This changes the name of the class of ausgabe, without changing its
> structure. I'm guessing that prior to this call ausgabe did not have a
> slot "pmvd.lower". Here's the simpler version:
> 
>>setClass("A", representation=representation(x="numeric"))
> [1] "A"
>> setClass("B", contains="A", representation=representation(y="numeric"))
> [1] "B"
>> a <- new("A")
>> class(a) <- "B"
>> str(a)
> Error in FUN(c("y", "x")[[1L]], ...) : no slot of name "y" for this object
> of class "B"
> 
> and some behavior which is somehow weird:
> 
>> slot(a, "y")
> Error in slot(a, "y") : no slot of name "y" for this object of class "B"
>> slot(a, "y") <- 10 # 'creates' the slot!
>> slot(a, "y")
> [1] 10
> 
> Probably what you want to do is to create a 'setAs' method
> 
> setAs('relimplm', 'relimplmbooteval',
>       function(from) {
>           <your code here, e.g.,>
>       })
> 
> and use
> 
>     ausgabe <- as(ausgabe, "relimplmbooteval")
> 
> I'm not really sure what <your code here> should look like; my first
> stab was
> 
>           obj <- new("relimplmbooteval")
>           slots <- slotNames(from)
>           for (slt in slots)
>               slot(obj, slt) <- slot(from, slt)
>           obj
> 
> which would not be very memory efficient (each slot assignment copies
> the entire object) but is perhaps fine for your needs.
> 
> Hope that helps
> 
> Martin
> 
> Ulrike Gr?mping <groemp at tfh-berlin.de> writes:
> 
>> Dear developeRs,
>>
>> with R 2.4.1 (and also 2.4.0), the function str() fails on objects of
>> class
>> relimplmbooteval, if there are unused slots, which is very often the
>> case. I
>> am not sure whether this is a bug in str() or a correct behavior of str()
>> that unmasks some sloppiness in my usage of S4 classes (that I am not
>> aware
>> of)?
>>
>> Reproducible example (package relaimpo needed):
>>
>> The program 
>>
>> require(relaimpo)
>> bte<-booteval.relimp(boot.relimp(swiss,b=100))
>> str(bte)
>>
>> yields the error message
>>
>> Errorr in FUN(c("lmg.lower", "lmg.upper", "lmg.rank.lower",
>> "lmg.rank.upper",  : 
>>         no slot named "pmvd.lower" for this object of class
>> "relimplmbooteval"
>> (back-translated from German).
>>
>> Regards, Ulrike
>> -- 
>> View this message in context:
>> http://www.nabble.com/Bug-in-str-or-issue-with-class-management-in-my-package--tf3453429.html#a9633559
>> Sent from the R devel mailing list archive at Nabble.com.
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> -- 
> Martin Morgan
> Bioconductor / Computational Biology
> http://bioconductor.org
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 

-- 
View this message in context: http://www.nabble.com/Bug-in-str-or-issue-with-class-management-in-my-package--tf3453429.html#a9637517
Sent from the R devel mailing list archive at Nabble.com.


From maechler at stat.math.ethz.ch  Fri Mar 23 17:53:09 2007
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 23 Mar 2007 17:53:09 +0100
Subject: [Rd] Bug in str or issue with class management in my package?
In-Reply-To: <9637517.post@talk.nabble.com>
References: <9633559.post@talk.nabble.com> <6phzm646rn3.fsf@gopher4.fhcrc.org>
	<9637517.post@talk.nabble.com>
Message-ID: <17924.1525.361430.93301@stat.math.ethz.ch>

Hi,

>>>>> "Ulrike" == Ulrike Gr?mping <groemp at tfh-berlin.de>
>>>>>     on Fri, 23 Mar 2007 08:39:32 -0700 (PDT) writes:

    Ulrike> Martin,

    Ulrike> thank you, you've pointed me in the right direction! I just wasn't aware
    Ulrike> that a slot must not be unassigned (everything but str worked so far, and
    Ulrike> even str works in R 2.3.1). 

That "everything worked" is actually quite astonishing to me.

I'd have expected that you should get an *error* when using

  class(<S4-object>) <- "arbitraryString"

since - as Martin Morgan mentioned - you typically coerce
S4 objects to a new class by  as(<..>, "new class")
                              ~~~~~~~~~~~~~~~~~~~~~
[ which either needs an explicit  SetAs(from,to, ....)
  declaration ``earlier on'' (typically by one of the class
  designers, often package authors),
  or an implicit one - as in your case, when one class extends
  another ]

Martin M?chler, ETH Zurich



    Ulrike> Actually, looking up the help for function new, I see that the solution is
    Ulrike> much easier, because my class relimplmbooteval extends the class relimplm of
    Ulrike> the object ausgabe. Therefore, I can simply write 
    Ulrike> obj <- new("relimplmbooteval", ausgabe)
    Ulrike> which copies all slots from ausgabe to the right place in the new obj.

    Ulrike> Regards, Ulrike


    Ulrike> Martin Morgan wrote:
    >> 
    >> Ulrike,
    >> 
    >> booteval.relimp has the statement
    >> 
    >> ausgabe <- calc.relimp(empcov, type = type, diff = diff, 
    >> rank = rank, rela = rela, always = always, groups = groups, 
    >> groupnames = groupnames)
    >> class(ausgabe) <- "relimplmbooteval"
    >> 
    >> This changes the name of the class of ausgabe, without changing its
    >> structure. I'm guessing that prior to this call ausgabe did not have a
    >> slot "pmvd.lower". Here's the simpler version:
    >> 
    >>> setClass("A", representation=representation(x="numeric"))
    >> [1] "A"
    >>> setClass("B", contains="A", representation=representation(y="numeric"))
    >> [1] "B"
    >>> a <- new("A")
    >>> class(a) <- "B"
    >>> str(a)
    >> Error in FUN(c("y", "x")[[1L]], ...) : no slot of name "y" for this object
    >> of class "B"
    >> 
    >> and some behavior which is somehow weird:
    >> 
    >>> slot(a, "y")
    >> Error in slot(a, "y") : no slot of name "y" for this object of class "B"
    >>> slot(a, "y") <- 10 # 'creates' the slot!
    >>> slot(a, "y")
    >> [1] 10
    >> 
    >> Probably what you want to do is to create a 'setAs' method
    >> 
    >> setAs('relimplm', 'relimplmbooteval',
    >> function(from) {
    >> <your code here, e.g.,>
    >> })
    >> 
    >> and use
    >> 
    >> ausgabe <- as(ausgabe, "relimplmbooteval")
    >> 
    >> I'm not really sure what <your code here> should look like; my first
    >> stab was
    >> 
    >> obj <- new("relimplmbooteval")
    >> slots <- slotNames(from)
    >> for (slt in slots)
    >> slot(obj, slt) <- slot(from, slt)
    >> obj
    >> 
    >> which would not be very memory efficient (each slot assignment copies
    >> the entire object) but is perhaps fine for your needs.
    >> 
    >> Hope that helps
    >> 
    >> Martin
    >> 
    >> Ulrike Gr?mping <groemp at tfh-berlin.de> writes:
    >> 
    >>> Dear developeRs,
    >>> 
    >>> with R 2.4.1 (and also 2.4.0), the function str() fails on objects of
    >>> class
    >>> relimplmbooteval, if there are unused slots, which is very often the
    >>> case. I
    >>> am not sure whether this is a bug in str() or a correct behavior of str()
    >>> that unmasks some sloppiness in my usage of S4 classes (that I am not
    >>> aware
    >>> of)?
    >>> 
    >>> Reproducible example (package relaimpo needed):
    >>> 
    >>> The program 
    >>> 
    >>> require(relaimpo)
    >>> bte<-booteval.relimp(boot.relimp(swiss,b=100))
    >>> str(bte)
    >>> 
    >>> yields the error message
    >>> 
    >>> Errorr in FUN(c("lmg.lower", "lmg.upper", "lmg.rank.lower",
    >>> "lmg.rank.upper",  : 
    >>> no slot named "pmvd.lower" for this object of class
    >>> "relimplmbooteval"
    >>> (back-translated from German).
    >>> 
    >>> Regards, Ulrike
    >>> -- 
    >>> View this message in context:
    >>> http://www.nabble.com/Bug-in-str-or-issue-with-class-management-in-my-package--tf3453429.html#a9633559
    >>> Sent from the R devel mailing list archive at Nabble.com.
    >>> 
    >>> ______________________________________________
    >>> R-devel at r-project.org mailing list
    >>> https://stat.ethz.ch/mailman/listinfo/r-devel
    >> 
    >> -- 
    >> Martin Morgan
    >> Bioconductor / Computational Biology
    >> http://bioconductor.org
    >> 
    >> ______________________________________________
    >> R-devel at r-project.org mailing list
    >> https://stat.ethz.ch/mailman/listinfo/r-devel
    >> 
    >> 

    Ulrike> -- 
    Ulrike> View this message in context: http://www.nabble.com/Bug-in-str-or-issue-with-class-management-in-my-package--tf3453429.html#a9637517
    Ulrike> Sent from the R devel mailing list archive at Nabble.com.

    Ulrike> ______________________________________________
    Ulrike> R-devel at r-project.org mailing list
    Ulrike> https://stat.ethz.ch/mailman/listinfo/r-devel


From groemping at tfh-berlin.de  Fri Mar 23 18:06:34 2007
From: groemping at tfh-berlin.de (=?ISO-8859-1?Q?Ulrike_Gr=F6mping?=)
Date: Fri, 23 Mar 2007 18:06:34 +0100
Subject: [Rd] Bug in str or issue with class management in my package?
In-Reply-To: <17924.1525.361430.93301@stat.math.ethz.ch>
References: <9633559.post@talk.nabble.com> <6phzm646rn3.fsf@gopher4.fhcrc.org>
	<9637517.post@talk.nabble.com>
	<17924.1525.361430.93301@stat.math.ethz.ch>
Message-ID: <20070323165806.M919@tfh-berlin.de>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20070323/ba432f83/attachment.pl 

From cstrato at aon.at  Fri Mar 23 18:26:06 2007
From: cstrato at aon.at (cstrato)
Date: Fri, 23 Mar 2007 18:26:06 +0100
Subject: [Rd] how to use debug.mypkg
In-Reply-To: <B0F5F7FF-89D9-46EF-B7D4-EA3D363D9A68@jhsph.edu>
References: <46030191.30006@aon.at>
	<5BDFDBB7-9AE2-4410-916A-3A17FA4DD3E9@jhsph.edu>
	<46030891.3030207@aon.at>
	<B0F5F7FF-89D9-46EF-B7D4-EA3D363D9A68@jhsph.edu>
Message-ID: <46040DAE.70104@aon.at>

Thank you all for your suggestions, I have implemented the OPTIONS "option",
since it allows to define other options, too.

Yes, I use now the Collate field, since it gives me the possibility to 
organize my
files in the way I want.

Best regards
Christian

Benilton Carvalho wrote:
> it doesn't matter where..
>
> just pick one of your files and set it...
>
> of course, your file should be listed in the Collate field (in case 
> you changed your mind and are now using it).
>
> b
>
> On Mar 22, 2007, at 6:52 PM, cstrato wrote:
>
>> Yes, I know, but somewhere in my package I need to define this flag.
>> When I set the flag "debug.mypkg<-T" in the R session, everything works,
>> but the problem is that if I do not set it, it is undefined. So I 
>> need to set it
>> initially in my package, but where?
>>
>> Christian
>>


From maechler at stat.math.ethz.ch  Fri Mar 23 18:31:35 2007
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 23 Mar 2007 18:31:35 +0100
Subject: [Rd] cbind() & rbind() for S4 objects -- 'Matrix' package
	changes
In-Reply-To: <Pine.LNX.4.64.0703201951590.4457@itasca2.wildberry.org>
References: <17920.24074.153169.96910@stat.math.ethz.ch>
	<Pine.LNX.4.64.0703201951590.4457@itasca2.wildberry.org>
Message-ID: <17924.3831.702106.533033@stat.math.ethz.ch>

Thank you, Luke, for your feedback,

   (more inline below)

>>>>> "Luke" == Luke Tierney <luke at stat.uiowa.edu>
>>>>>     on Tue, 20 Mar 2007 20:27:18 -0500 (CDT) writes:

    Luke> On Tue, 20 Mar 2007, Martin Maechler wrote:

    >> As some of you may have seen / heard in the past,
    >> it is not possible to make cbind() and rbind() into proper S4
    >> generic functions, since their first formal argument is '...'.
    >> [ BTW: S3-methods for these of course only dispatch on the first
    >> argument which is also not really satisfactory in the context
    >> of many possible matrix classes.]
    >> 
    >> For this reason, after quite some discussion on R-core (and
    >> maybe a bit on R-devel) about the options, since R-2.2.0 we have
    >> had S4 generic functions cbind2() and rbind2() (and default methods)
    >> in R's "methods" which are a version of cbind() and
    >> rbind() respectively for two arguments (x,y)
    >> {and fixed 'deparse.level = 0' : the argument names are 'x' and 'y' and
    >> hence don't make sense to be used to construct column-names or
    >> row-names for rbind(), respectively.}
    >> 
    >> We have been defining methods for cbind2() and rbind2()
    >> for the 'Matrix' classes in late summer 2005 as well.  So far so
    >> good.
    >> 
    >> In addition, [see also  help(cbind2) ],
    >> we have defined cbind() and rbind() functions which recursively call
    >> cbind2() and rbind2(), more or less following John Chambers
    >> proposal of dealing with such "(...)" argument functions.
    >> These new recursively defined cbind() / rbind() functions
    >> however have typically remained invisible in the methods package
    >> [you can see them via  methods:::cbind  or  methods:::rbind ]
    >> and have been ``activated'' --- replacing  base::cbind / rbind ---
    >> only via an explicit or implicit call to
    >> methods:::bind_activation(TRUE)
    >> 
    >> One reason I didn't dare to make them the default was that I
    >> noticed they didn't behave identically to cbind() / rbind() in
    >> all cases, though IIRC the rare difference was only in the dimnames
    >> returned; further, being entirely written in R, and recursive,
    >> they were slower than the mostly C-based fast  cbind() / rbind()
    >> functions.
    >> 
    >> As some Bioconductor developers have recently found,
    >> these versions of cbind() and rbind() that have been
    >> automagically activated by loading the  Matrix package
    >> can have a detrimental effect in some extreme cases,
    >> e.g. when using
    >> do.call(cbind, list_of_length_1000)
    >> because of the recursion and the many many calls to the S4
    >> generic, each time searching for method dispatch ...
    >> For the bioconductor applications and potentially for others using cbind() /
    >> rbind() extensively, this can lead to unacceptable performance
    >> loss just because loading 'Matrix' currently calls
    >> methods:::bind_activation(TRUE)

    Luke> The recursion part is potentially problematic because stack space
    Luke> limitations will cause this to fail for "relatively" short
    Luke> list_of_length_1000, but that should be easily curable by rewriting
    Luke> methods:::cbind and methods:::rbind to use iteration rather than
    Luke> recursion.

Yes, thank you, Luke,  something I should have at least tried
doing but didn't get to.

    Luke> This might also help a little with efficiency by avoiding
    Luke> call overhead.  It would be interesting to know how much of the
    Luke> performance hit is dispatch overhead and how much closure call
    Luke> overhead.  If it's dispatch overhead then it may be worth figuring out
    Luke> some way of handling this with internal dispatch at the C level (at
    Luke> the cost of maintaining the C level stuff).

    Luke> My initial reaction to scanning the methods:::cbind code is that it is
    Luke> doing too much, at least too much R-level work, but I haven't thought
    Luke> it through carefully.

I can well understand that reaction..
The code started up quite small and easily understandable ...
until I started trying to emulate the "standard"  cbind() /
rbind() behavior, notably about automatic colnames / rownames
creation. When delving into that the code got the current
partial messyness....

    >> For this reason, we plan to refrain from doing this activation
    >> on loading of Matrix, but propose to
    >> 
    >> 1)  define and export
    >> cBind <- methods:::cbind
    >> rBind <- methods:::cbind
    >> 
    >> also do this for R-2.5.0 so that other useRs / packages
    >> can start cBind() / rBind() in their code when they want to
    >> have something that can become properly object-oriented

    Luke> In mackage methods?

yes, inside methods, such that in fact there  cBind <- cbind
(plus namespace export) would be sufficient.

In the mean time I'm less sure if this is desirable; 
but at least this would ``expose'' the code and have it used
and consequently hopefully made more efficient (and hopefully
even simplified).

    >> Possibly --- and this is the big  RFC (request for comments) ---
    >> 
    >> 2) __ for 'Matrix' only __ also
    >> define and export
    >> cbind <- methods:::cbind
    >> rbind <- methods:::cbind
    >> 
    >> I currently see the possibilities of doing
    >> either '1)'
    >> or     '1) and 2)'
    >> or less likely  '2) alone'

    >> and like to get your feedback on this.

    >> "1)" alone would have the considerable drawback for current
    >> Matrix useRs that their code / scripts which has been using
    >> cbind() and rbind() for "Matrix" (and "matrix" and "numeric")
    >> objects no longer works, but needs to be changed to use
    >> rBind() and cBind()  *instead*
    >> 
    >> As soon as "2)" is done (in conjunction with "1)" or not),
    >> those who need a very fast but non-OO version of cbind() / rbind()
    >> need to call  base::cbind() or  base::rbind()  explicitly.
    >> This however would not be necessary for packages with a NAMESPACE
    >> since these import 'base' automagically and hence would use
    >> base::cbind() automagically {unless they also import(Matrix)}.
    >> 
    >> We are quite interested in your feedback!

    Luke> Either one seems cleaner to me than having loading of one package
    Luke> result in mucking about in the internals of another.

I agree {{the reason I had chosen the unclean approach was the
	  hope that methods:::cbind could be improved to soon replace
	  base::cbind -- and so "Matrix" would just do something
	  that would happen more universally in the future anyway}}

    Luke> If we are thinking of these as long term solutions then I think having
    Luke> different names is cleaner, so 1) but not 2).  If we are thinking of
    Luke> this as a transition towards making base::cbind and base::rbind
    Luke> support S4 dispatch via cbind2/rbind2 (assuming this can be done
    Luke> efficiently) then there may be some merit to 2) to minimize the need
    Luke> for code rewriting.

Yes, exactly.  
My originally intent was strongly in the direction of making
base::cbind support S4 via cbind2() and rbind2() -- and one will
continue to be able to experiment with that after calling
methods:::bind_activation(TRUE).
The problem I had underestimated is 
    Luke> assuming this can be done efficiently

    Luke> It might be worth experimenting with having .Internal(cbind(...))
    Luke> check its arguments and call methods:::cbind if (Methods is loaded
    Luke> and) any of the arguments are S4 -- as the S4 property is now cheap to
    Luke> determine that may be very low cost especially if done after the
    Luke> object bits have been checked with positive result.

Very nice idea ... currently I don't have the time to do it, so,
unless another R-core member (or an avid R-devel reader) jumps
in, I don't see this possible for R 2.5.0 (and hence the 2.5.x
series).

Too bad that nobody else (on R-devel) seems interested enough.
In the mean time, I'm proposing to implement '2)'
which will give

>>    > library(Matrix)
>>    Loading required package: lattice
>> 
>>    Attaching package: 'Matrix'
>> 
>> 
>> 	   The following object(s) are masked from package:base :
>> 
>> 	    cbind,
>> 	    rbind 

every time Matrix is loaded, but that seems appropriate to me.

The question remains if it wasn't worth to do '1)' as well
{not in Matrix, but the 'methods' package} such that people can
more easily get experience with such a  cbind2/rbind2 - based
version of cbind/rbind.

Martin


    Luke> Best,

    Luke> luke

    >> Martin Maechler and Doug Bates <Matrix-authors at R-project.org>

    Luke> -- 
    Luke> Luke Tierney
    Luke> Chair, Statistics and Actuarial Science
    Luke> Ralph E. Wareham Professor of Mathematical Sciences
    Luke> University of Iowa                  Phone:             319-335-3386
    Luke> Department of Statistics and        Fax:               319-335-3017
    Luke> Actuarial Science
    Luke> 241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
    Luke> Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From mwkimpel at gmail.com  Fri Mar 23 20:35:28 2007
From: mwkimpel at gmail.com (Mark W Kimpel)
Date: Fri, 23 Mar 2007 15:35:28 -0400
Subject: [Rd] [R] can't load just saved R object "ReadItem: unknown type
	65"
In-Reply-To: <Pine.LNX.4.64.0703230753500.20383@nokomis.stat.uiowa.edu>
References: <46033E07.4040905@gmail.com>
	<Pine.LNX.4.64.0703230753500.20383@nokomis.stat.uiowa.edu>
Message-ID: <46042C00.7060601@gmail.com>

Luke, I'll be gone for about 2 weeks but will work on getting you a 
reproducible example when I get back. If this topic comes up with anyone 
else, please copy me on your responses as I may miss it in the 600 
emails I'll have to delete on my return :) Mark

Luke Tierney wrote:
> According to the logs nothing at all has changed in the serialization
> code in a month and nothing of consequence for much longer than that.
> To track this down we will need a complete, reproducible, and
> preferably minimal example.
> 
> Best,
> 
> luke
> 
> On Thu, 22 Mar 2007, Mark W Kimpel wrote:
> 
>> I have run into a problem loading a just saved R object using R-devel. I
>> have been saving and loading this particular type of R object for a long
>> while and never ran into this problem. I save, then immediately reload
>> (to test save) and get "ReadItem: unnknown type 65".
>>
>> This error is reproducible after logout from server and restart of emacs
>> and R.
>>
>> Below is my output and sessionInfo().
>>
>> Thanks,
>> Mark
>>
>> > setwd("~/Genomics/Experiments.Genomic/BB01/acb.shell")
>> > local(save(affy.object.preprocessed, file
>> ="affy.object.preprocessed.R" ))
>> > load("affy.object.preprocessed.R")
>> Error in load("affy.object.preprocessed.R") :
>>     ReadItem: unknown type 65, perhaps written by later version of R
>> > sessionInfo()
>> R version 2.5.0 Under development (unstable) (2007-03-11 r40824)
>> powerpc64-unknown-linux-gnu
>>
>> locale:
>> LC_CTYPE=en_US.UTF-8;LC_NUMERIC=C;LC_TIME=en_US.UTF-8;LC_COLLATE=en_US.UTF-8;LC_MONETARY=en_US.UTF-8;LC_MESSAGES=en_US.UTF-8;LC_PAPER=en_US.UTF-8;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=en_US.UTF-8;LC_IDENTIFICATION=C 
>>
>>
>> attached base packages:
>> [1] "splines"   "stats"     "graphics"  "grDevices" "datasets"  "utils"
>> [7] "tools"     "methods"   "base"
>>
>> other attached packages:
>>      multtest    rat2302cdf affycoretools       annaffy        xtable
>>      "1.13.1"      "1.15.0"       "1.7.8"       "1.7.3"       "1.4-3"
>>         gcrma   matchprobes       biomaRt         RCurl           XML
>>       "2.7.3"       "1.7.4"      "1.9.21"       "0.8-0"       "1.6-0"
>>       GOstats      Category        Matrix       lattice    genefilter
>>      "2.1.13"      "2.1.20"   "0.9975-11"     "0.14-16"      "1.13.8"
>>      survival          KEGG          RBGL      annotate            GO
>>        "2.31"     "1.15.12"      "1.11.4"      "1.13.6"     "1.15.12"
>>         graph         limma          affy        affyio       Biobase
>>      "1.13.6"      "2.9.13"     "1.13.14"       "1.3.3"     "1.13.39"
>>
> 

-- 
Mark W. Kimpel MD
Neuroinformatics
Department of Psychiatry
Indiana University School of Medicine


From vdergachev at rcgardis.com  Sat Mar 24 00:30:03 2007
From: vdergachev at rcgardis.com (Vladimir Dergachev)
Date: Fri, 23 Mar 2007 19:30:03 -0400
Subject: [Rd] as.Date nuance
Message-ID: <200703231930.03846.vdergachev@rcgardis.com>


Hi, 

  I have encountered a nuance in as.Date() behaviour that is not altogether 
obvious - not sure whether this is intended or not:

> as.Date("2001-01-01error")
[1] "2001-01-01"

I.e. it ignores the rest of the characters. This happens both in 2.3.1 and 
2.4.1 versions. 

This also happens with explicit format specification:
> as.Date("2006-01-01error", format="%Y-%m-%d")
[1] "2006-01-01"

                    thank you

                        Vladimir Dergachev


From ripley at stats.ox.ac.uk  Sat Mar 24 11:21:41 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 24 Mar 2007 10:21:41 +0000 (GMT)
Subject: [Rd] as.Date nuance
In-Reply-To: <200703231930.03846.vdergachev@rcgardis.com>
References: <200703231930.03846.vdergachev@rcgardis.com>
Message-ID: <Pine.LNX.4.64.0703241017450.32697@gannet.stats.ox.ac.uk>

This is how strptime() works: it processes the input to match the format.

On Fri, 23 Mar 2007, Vladimir Dergachev wrote:

>  I have encountered a nuance in as.Date() behaviour that is not altogether
> obvious - not sure whether this is intended or not:
>
>> as.Date("2001-01-01error")
> [1] "2001-01-01"
>
> I.e. it ignores the rest of the characters. This happens both in 2.3.1 and
> 2.4.1 versions.

It has always occurred.

> This also happens with explicit format specification:
>> as.Date("2006-01-01error", format="%Y-%m-%d")
> [1] "2006-01-01"
>
>                    thank you
>
>                        Vladimir Dergachev

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From franck.arnaud at gmail.com  Fri Mar 23 23:40:09 2007
From: franck.arnaud at gmail.com (Franck Arnaud)
Date: Fri, 23 Mar 2007 23:40:09 +0100
Subject: [Rd] substitute and S4 objects
Message-ID: <44dc13910703231540g5ade432en6b0911e31434bb7c@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20070323/35f9fb39/attachment.pl 

From vdergachev at rcgardis.com  Sat Mar 24 16:51:13 2007
From: vdergachev at rcgardis.com (Vladimir Dergachev)
Date: Sat, 24 Mar 2007 11:51:13 -0400
Subject: [Rd] as.Date nuance
In-Reply-To: <Pine.LNX.4.64.0703241017450.32697@gannet.stats.ox.ac.uk>
References: <200703231930.03846.vdergachev@rcgardis.com>
	<Pine.LNX.4.64.0703241017450.32697@gannet.stats.ox.ac.uk>
Message-ID: <200703241151.13734.vdergachev@rcgardis.com>

On Saturday 24 March 2007 6:21 am, Prof Brian Ripley wrote:
> This is how strptime() works: it processes the input to match the format.

Except that the format does not match the string - there are leftover 
characters. Even by R's own definition:

> match("a", "ab")
[1] NA

as, of course, is reasonable.

Is there some way to make sure there is an exact match ?

                        thank you !

                                   Vladimir Dergachev

>
> On Fri, 23 Mar 2007, Vladimir Dergachev wrote:
> >  I have encountered a nuance in as.Date() behaviour that is not
> > altogether
> >
> > obvious - not sure whether this is intended or not:
> >> as.Date("2001-01-01error")
> >
> > [1] "2001-01-01"
> >
> > I.e. it ignores the rest of the characters. This happens both in 2.3.1
> > and 2.4.1 versions.
>
> It has always occurred.
>
> > This also happens with explicit format specification:
> >> as.Date("2006-01-01error", format="%Y-%m-%d")
> >
> > [1] "2006-01-01"
> >
> >                    thank you
> >
> >                        Vladimir Dergachev


From ggrothendieck at gmail.com  Sat Mar 24 17:12:23 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 24 Mar 2007 12:12:23 -0400
Subject: [Rd] as.Date nuance
In-Reply-To: <200703241151.13734.vdergachev@rcgardis.com>
References: <200703231930.03846.vdergachev@rcgardis.com>
	<Pine.LNX.4.64.0703241017450.32697@gannet.stats.ox.ac.uk>
	<200703241151.13734.vdergachev@rcgardis.com>
Message-ID: <971536df0703240912m8eb5798pe99ad5a66fd71e3a@mail.gmail.com>

It matches in the sense of grep or regexpr

grep("a", "ab") > 0
regexpr("a", "ab") > 0

Try this:

x <- c("2006-01-01error", "2006-01-01")
as.Date(x, "%Y-%m-%d") + ifelse(regexpr("^....-..-..$", x) > 0, 0, NA)



On 3/24/07, Vladimir Dergachev <vdergachev at rcgardis.com> wrote:
> On Saturday 24 March 2007 6:21 am, Prof Brian Ripley wrote:
> > This is how strptime() works: it processes the input to match the format.
>
> Except that the format does not match the string - there are leftover
> characters. Even by R's own definition:
>
> > match("a", "ab")
> [1] NA
>
> as, of course, is reasonable.
>
> Is there some way to make sure there is an exact match ?
>
>                        thank you !
>
>                                   Vladimir Dergachev
>
> >
> > On Fri, 23 Mar 2007, Vladimir Dergachev wrote:
> > >  I have encountered a nuance in as.Date() behaviour that is not
> > > altogether
> > >
> > > obvious - not sure whether this is intended or not:
> > >> as.Date("2001-01-01error")
> > >
> > > [1] "2001-01-01"
> > >
> > > I.e. it ignores the rest of the characters. This happens both in 2.3.1
> > > and 2.4.1 versions.
> >
> > It has always occurred.
> >
> > > This also happens with explicit format specification:
> > >> as.Date("2006-01-01error", format="%Y-%m-%d")
> > >
> > > [1] "2006-01-01"
> > >
> > >                    thank you
> > >
> > >                        Vladimir Dergachev
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From jeff.horner at vanderbilt.edu  Sat Mar 24 23:02:29 2007
From: jeff.horner at vanderbilt.edu (Jeffrey Horner)
Date: Sat, 24 Mar 2007 17:02:29 -0500
Subject: [Rd] Subtle bug in do_basename
Message-ID: <46059FF5.409@vanderbilt.edu>

Hello,


I've been wondering why my no-optimization R-devel builds have been 
hanging during "building/updating package indices ...". I tracked it 
down with gdb to this line from do_basename in utils.c:

while ( *(p = buf + strlen(buf) - 1) == fsp ) *p = '\0';

Now, imagine if your compiler places the variable fsp immediately before 
buf on the stack, and strlen(buf) is 0. Yup, you get an infinite loop 
because p will always be assigned the address of fsp. I'm not quite sure 
what happens when the stack variables are ordered in a different 
configuration, probably something bad?

Here's a quick fix, but maybe someone would want to find a better one:

$ svn diff src/main/util.c
Index: src/main/util.c
===================================================================
--- src/main/util.c     (revision 40876)
+++ src/main/util.c     (working copy)
@@ -694,7 +694,8 @@
         R_fixslash(buf);
  #endif
         /* remove trailing file separator(s) */
-       while ( *(p = buf + strlen(buf) - 1) == fsp ) *p = '\0';
+       if(strlen(p))
+           while ( *(p = buf + strlen(buf) - 1) == fsp ) *p = '\0';
         if ((p = Rf_strrchr(buf, fsp)))
             p++;
         else

Best,

Jeff
-- 
http://biostat.mc.vanderbilt.edu/JeffreyHorner


From murdoch at stats.uwo.ca  Sat Mar 24 23:11:26 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sat, 24 Mar 2007 18:11:26 -0400
Subject: [Rd] Subtle bug in do_basename
In-Reply-To: <46059FF5.409@vanderbilt.edu>
References: <46059FF5.409@vanderbilt.edu>
Message-ID: <4605A20E.8030008@stats.uwo.ca>

On 3/24/2007 6:02 PM, Jeffrey Horner wrote:
> Hello,
> 
> 
> I've been wondering why my no-optimization R-devel builds have been 
> hanging during "building/updating package indices ...". I tracked it 
> down with gdb to this line from do_basename in utils.c:
> 
> while ( *(p = buf + strlen(buf) - 1) == fsp ) *p = '\0';
> 
> Now, imagine if your compiler places the variable fsp immediately before 
> buf on the stack, and strlen(buf) is 0. Yup, you get an infinite loop 
> because p will always be assigned the address of fsp. I'm not quite sure 
> what happens when the stack variables are ordered in a different 
> configuration, probably something bad?
> 
> Here's a quick fix, but maybe someone would want to find a better one:

I think that looks like the right solution; I'll commit it.

Duncan Murdoch
> 
> $ svn diff src/main/util.c
> Index: src/main/util.c
> ===================================================================
> --- src/main/util.c     (revision 40876)
> +++ src/main/util.c     (working copy)
> @@ -694,7 +694,8 @@
>          R_fixslash(buf);
>   #endif
>          /* remove trailing file separator(s) */
> -       while ( *(p = buf + strlen(buf) - 1) == fsp ) *p = '\0';
> +       if(strlen(p))
> +           while ( *(p = buf + strlen(buf) - 1) == fsp ) *p = '\0';
>          if ((p = Rf_strrchr(buf, fsp)))
>              p++;
>          else
> 
> Best,
> 
> Jeff


From jmc at r-project.org  Sun Mar 25 01:00:01 2007
From: jmc at r-project.org (John Chambers)
Date: Sat, 24 Mar 2007 17:00:01 -0700
Subject: [Rd] substitute and S4 objects
In-Reply-To: <44dc13910703231540g5ade432en6b0911e31434bb7c@mail.gmail.com>
References: <44dc13910703231540g5ade432en6b0911e31434bb7c@mail.gmail.com>
Message-ID: <4605BB81.2050400@r-project.org>

First, by "doesn't work" you mean the printed output.  The value 
returned is the same.

Second, the problem is not a general one with S4 methods but with 
primitive functions.  To see this, define a real function with a similar 
method:

 > setGeneric("foo", function(e1, e2) standardGeneric("foo"))
[1] "foo"

 > setMethod("foo", "num", function(e1, e2) {
    cat("Computing\n", deparse(substitute(e1)), "+", 
deparse(substitute(e2)),
        "\n")
    e1 at x + e2@ x
})

[1] "foo"
 > foo(a,b)
Computing
 a + b
[1] 1.8

The problem with primitives, such as `+`, is that they aren't called in 
the way functions are normally called.  If my understanding is correct, 
substitute() with one argument uses the "promise" objects corresponding 
to the formal arguments in order to extract the unevaluated expression.  
There are no such things with primitives.

I think you need to use a different function for whatever you really wanted.

Franck Arnaud wrote:
> Hi all,
> I don't understand why this does not what I expect :
>
> ## code start here ##############
> setClass("num",representation(x="numeric"))
>
> num<-function(x) new("num",x=x)
>
> add<-function(e1,e2) {
>     cat("Computing
> ",deparse(substitute(e1)),"+",deparse(substitute(e2)),"\n")
>     e1 at x+e2@x
> }
>
> setMethod("+","num",function(e1,e2) {
>     cat("Computing
> ",deparse(substitute(e1)),"+",deparse(substitute(e2)),"\n")
>     e1 at x+e2@x
> })
>
>
> a<-num(3.2)
> b<-num(-1.4)
>
> add(a,b)
> a+b
> ## code ends here ##############
>
> a+b does not work : I would like that add(a,b) and a+b give the exact same
> result
> I've seen a post on R-devel, but the answer seemed not to apply here.
> I've tried to use deparse(substitute(e1,sys.frame (-1))) and
> deparse(substitute(e1,sys.frame(-2))) (as it was advised by GG in january
> 2006). But it did not work.
>
> Therefore, i'm looking for 1) an explanation for this phenomenon (link to a
> doc, anything) and/or 2) a way to do what i want, if it is possible.
>
> Thanks a lot
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From ripley at stats.ox.ac.uk  Sun Mar 25 12:50:41 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 25 Mar 2007 11:50:41 +0100 (BST)
Subject: [Rd] [R] How to create a list that grows automatically
In-Reply-To: <f8e6ff050703091121u4fb3d109yf5eeac6bfdd9661@mail.gmail.com>
References: <9a2a73210703090808x2fd9ce77i4537d3428045c061@mail.gmail.com>
	<f8e6ff050703091121u4fb3d109yf5eeac6bfdd9661@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0703251133310.1260@gannet.stats.ox.ac.uk>

[Moved to R-devel for a technical comment.]

On Fri, 9 Mar 2007, hadley wickham wrote:

>> I would like to know if there is a way to create a list or an array (or
>> anything) which grows automatically as more elements are put into it. What I
>> want to find is something equivalent to an ArrayList object of Java
>> language. In Java, I can do the following thing:
>>
>> // Java code
>> ArrayList myArray = new ArrayList();
>> myArray.add("object1");
>> myArray.add("object2");
>> ....
>> // End of java code
>
> As others have mentioned, you can do this with lists in R.
>
> However, there is an important difference between ArrayLists in Java
> and Lists in R.  In Java, when an ArrayList grows past its bound, it
> doesn't allocate just enough space, it allocates a lot more, so the
> next time you allocate past the end of the array, there's space
> already reserved.  This gives (IIRC) amortised O(n) behaviour.  R
> doesn't do this however, so has to copy the entire array every time
> giving O(n^2) behaviour.

In fact this is an implementation detail.  R has both 'length' and 
'truelength' fields in its headers for vectors (including lists) and could 
grow the allocation in the same way as you report Java does.  When I asked 
Ross what the intention had been (the 'truelength' field is almost unused) 
he mentioned this potential usage.  Given that these structures are opaque 
to all but R internal code it should not be hard to change R's scheme to 
over-allocate: to decide how much to do would be harder (but say rounding 
vectors in the large allocation class up to a VM page would get a 
noticeable benefit in some usages with a negligible impact on memory 
footprint).  Backwards compatibility of save() format would be an issue.

It seems the really inefficient uses are of the type

x <- NULL
for(i in 1:10000) x <- c(x, fn(i))

and those would be unaltered.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From h.wickham at gmail.com  Sun Mar 25 15:43:22 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Sun, 25 Mar 2007 08:43:22 -0500
Subject: [Rd] [R] How to create a list that grows automatically
In-Reply-To: <Pine.LNX.4.64.0703251133310.1260@gannet.stats.ox.ac.uk>
References: <9a2a73210703090808x2fd9ce77i4537d3428045c061@mail.gmail.com>
	<f8e6ff050703091121u4fb3d109yf5eeac6bfdd9661@mail.gmail.com>
	<Pine.LNX.4.64.0703251133310.1260@gannet.stats.ox.ac.uk>
Message-ID: <f8e6ff050703250643r4a578289m19ad9dc2cd8c7757@mail.gmail.com>

On 3/25/07, Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
> [Moved to R-devel for a technical comment.]
>
> On Fri, 9 Mar 2007, hadley wickham wrote:
>
> >> I would like to know if there is a way to create a list or an array (or
> >> anything) which grows automatically as more elements are put into it. What I
> >> want to find is something equivalent to an ArrayList object of Java
> >> language. In Java, I can do the following thing:
> >>
> >> // Java code
> >> ArrayList myArray = new ArrayList();
> >> myArray.add("object1");
> >> myArray.add("object2");
> >> ....
> >> // End of java code
> >
> > As others have mentioned, you can do this with lists in R.
> >
> > However, there is an important difference between ArrayLists in Java
> > and Lists in R.  In Java, when an ArrayList grows past its bound, it
> > doesn't allocate just enough space, it allocates a lot more, so the
> > next time you allocate past the end of the array, there's space
> > already reserved.  This gives (IIRC) amortised O(n) behaviour.  R
> > doesn't do this however, so has to copy the entire array every time
> > giving O(n^2) behaviour.
>
> In fact this is an implementation detail.  R has both 'length' and
> 'truelength' fields in its headers for vectors (including lists) and could
> grow the allocation in the same way as you report Java does.  When I asked
> Ross what the intention had been (the 'truelength' field is almost unused)
> he mentioned this potential usage.  Given that these structures are opaque
> to all but R internal code it should not be hard to change R's scheme to
> over-allocate: to decide how much to do would be harder (but say rounding
> vectors in the large allocation class up to a VM page would get a
> noticeable benefit in some usages with a negligible impact on memory
> footprint).  Backwards compatibility of save() format would be an issue.

Interesting - it would be fascinating (but difficult!) to find out how
much such a change would affect the average running time of all R
code.

> It seems the really inefficient uses are of the type
>
> x <- NULL
> for(i in 1:10000) x <- c(x, fn(i))
>
> and those would be unaltered.

Does R do any manipulations of the AST after the code has been parsed?
 If it did, wouldn't it be fairly easy to recognise this idiom and
optimise it to x[length(x) + 1] <- fn(i) ?  It has something of the
flavour of tail recursion optimisation.  Maybe this is something that
Luke is working on in his byte-code compiler.

Hadley


From simon.urbanek at r-project.org  Mon Mar 26 16:16:35 2007
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Mon, 26 Mar 2007 10:16:35 -0400
Subject: [Rd] Subtle bug in do_basename
In-Reply-To: <46059FF5.409@vanderbilt.edu>
References: <46059FF5.409@vanderbilt.edu>
Message-ID: <0F06D0A8-2245-4967-81C3-050C2B3D0B2E@r-project.org>

Good catch, there is even one more problem I believe - it  can still  
run past the beginning of the buffer (e.g. if you use "///").
This is a bit more more efficient due to fewer calls to strlen and  
fixes both problems:

if (*buf) {
   p = buf + strlen(buf) - 1;
   while (p>=buf && *p == fsp) *(p--)='\0';
}

Cheers,
Simon

On Mar 24, 2007, at 6:02 PM, Jeffrey Horner wrote:

> Hello,
>
>
> I've been wondering why my no-optimization R-devel builds have been
> hanging during "building/updating package indices ...". I tracked it
> down with gdb to this line from do_basename in utils.c:
>
> while ( *(p = buf + strlen(buf) - 1) == fsp ) *p = '\0';
>
> Now, imagine if your compiler places the variable fsp immediately  
> before
> buf on the stack, and strlen(buf) is 0. Yup, you get an infinite loop
> because p will always be assigned the address of fsp. I'm not quite  
> sure
> what happens when the stack variables are ordered in a different
> configuration, probably something bad?
>
> Here's a quick fix, but maybe someone would want to find a better one:
>
> $ svn diff src/main/util.c
> Index: src/main/util.c
> ===================================================================
> --- src/main/util.c     (revision 40876)
> +++ src/main/util.c     (working copy)
> @@ -694,7 +694,8 @@
>          R_fixslash(buf);
>   #endif
>          /* remove trailing file separator(s) */
> -       while ( *(p = buf + strlen(buf) - 1) == fsp ) *p = '\0';
> +       if(strlen(p))
> +           while ( *(p = buf + strlen(buf) - 1) == fsp ) *p = '\0';
>          if ((p = Rf_strrchr(buf, fsp)))
>              p++;
>          else
>
> Best,
>
> Jeff
> -- 
> http://biostat.mc.vanderbilt.edu/JeffreyHorner
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From hin-tak.leung at cimr.cam.ac.uk  Mon Mar 26 16:30:35 2007
From: hin-tak.leung at cimr.cam.ac.uk (Hin-Tak Leung)
Date: Mon, 26 Mar 2007 15:30:35 +0100
Subject: [Rd] typo in R-ints
In-Reply-To: <Pine.LNX.4.64.0702241828570.14494@gannet.stats.ox.ac.uk>
References: <f8e6ff050702231738x74d515c1pd246403fdf8ad21a@mail.gmail.com>
	<Pine.LNX.4.64.0702241828570.14494@gannet.stats.ox.ac.uk>
Message-ID: <4607D90B.6080005@cimr.cam.ac.uk>

Just been reading R internals, and noticed a typo (duplicate "should")
- patch attached, and also pasted below:

--- ./doc/manual/R-ints.texi.orig       2007-02-13 10:30:38.000000000 +0000
+++ ./doc/manual/R-ints.texi    2007-03-26 15:25:08.000000000 +0100
@@ -1093,7 +1093,7 @@
  contain references to environments, which then have enclosing
  environments and so on.  (Environments recognized as package or name
  space environments are saved by name.)  Further, there are `reference
-objects' which are not duplicated on copy and should should remain
+objects' which are not duplicated on copy and should remain
  shared on unserialization.  These are weak references, external pointers
  and environments other than those associated with packages, name spaces
  and the global environment.  These are handled via a hash table, and
-------------- next part --------------
A non-text attachment was scrubbed...
Name: R-ints.patch
Type: text/x-patch
Size: 707 bytes
Desc: not available
Url : https://stat.ethz.ch/pipermail/r-devel/attachments/20070326/dab836e7/attachment.bin 

From murdoch at stats.uwo.ca  Mon Mar 26 18:18:14 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Mon, 26 Mar 2007 12:18:14 -0400
Subject: [Rd] typo in R-ints
In-Reply-To: <4607D90B.6080005@cimr.cam.ac.uk>
References: <f8e6ff050702231738x74d515c1pd246403fdf8ad21a@mail.gmail.com>	<Pine.LNX.4.64.0702241828570.14494@gannet.stats.ox.ac.uk>
	<4607D90B.6080005@cimr.cam.ac.uk>
Message-ID: <4607F246.6070101@stats.uwo.ca>

On 3/26/2007 10:30 AM, Hin-Tak Leung wrote:
> Just been reading R internals, and noticed a typo (duplicate "should")
> - patch attached, and also pasted below:

Thanks, I'll commit the change.

Duncan Murdoch

> 
> --- ./doc/manual/R-ints.texi.orig       2007-02-13 10:30:38.000000000 +0000
> +++ ./doc/manual/R-ints.texi    2007-03-26 15:25:08.000000000 +0100
> @@ -1093,7 +1093,7 @@
>   contain references to environments, which then have enclosing
>   environments and so on.  (Environments recognized as package or name
>   space environments are saved by name.)  Further, there are `reference
> -objects' which are not duplicated on copy and should should remain
> +objects' which are not duplicated on copy and should remain
>   shared on unserialization.  These are weak references, external pointers
>   and environments other than those associated with packages, name spaces
>   and the global environment.  These are handled via a hash table, and
> 
> 
> ------------------------------------------------------------------------
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From jlaznarte at decsai.ugr.es  Mon Mar 26 18:42:43 2007
From: jlaznarte at decsai.ugr.es (=?ISO-8859-1?Q?=22Jos=E9_Luis_Aznarte_M=2E=22?=)
Date: Mon, 26 Mar 2007 18:42:43 +0200
Subject: [Rd] Developer work cycle
Message-ID: <4607F803.7060700@decsai.ugr.es>

    Hi! I've been browsing through the last months' archive and I can't
find an answer to my question, so here it is (let's hope it's not too
obvious):
    I'm working on extensions of an R library, and I would be very
surprised if everyone developing R packages is doing the following, as I do:

        1.- Write down a modification of an R file
        2.- Exit the current R session
        3.- Install the package as root (sudo R CMD INSTALL...)
        4.- Launch a new R session
        5.- Test the change, if it does not work, go back to 1 or debug.
        6.- Finish.

    Is this the proper (but quite awkward) way to proceed or there is an
alternative to skip steps 2 to 4? I'm using emacs with ESS under linux.
Thank you in advance for your time! Best regards,

--                                                      --
Jose Luis Aznarte M.       http://decsai.ugr.es/~jlaznarte
Department of Computer Science and Artificial Intelligence
Universidad de Granada           Tel. +34 - 958 - 24 04 67
GRANADA (Spain)                  Fax: +34 - 958 - 24 00 79


From ripley at stats.ox.ac.uk  Mon Mar 26 19:23:11 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 26 Mar 2007 18:23:11 +0100 (BST)
Subject: [Rd] Developer work cycle
In-Reply-To: <4607F803.7060700@decsai.ugr.es>
References: <4607F803.7060700@decsai.ugr.es>
Message-ID: <Pine.LNX.4.64.0703261818060.14141@gannet.stats.ox.ac.uk>

It depends on the change, but I never install an unreleased package into 
the main library, so do not need sudo for 3).  I have a 'test-library' 
library that is in R_LIBS in ~/.Rprofile and I use solely for package 
testing.

If this is a change to the NAMESPACE or an unexported object you do need 
to re-install, but many changes can be tested via source()ing the new file 
and example().

If the test suite is good enough, 'R CMD check' may do all the tests you 
need without installing the test package anywhere else.

On Mon, 26 Mar 2007, "Jos? Luis Aznarte M." wrote:

>    Hi! I've been browsing through the last months' archive and I can't
> find an answer to my question, so here it is (let's hope it's not too
> obvious):
>    I'm working on extensions of an R library, and I would be very
> surprised if everyone developing R packages is doing the following, as I do:
>
>        1.- Write down a modification of an R file
>        2.- Exit the current R session
>        3.- Install the package as root (sudo R CMD INSTALL...)
>        4.- Launch a new R session
>        5.- Test the change, if it does not work, go back to 1 or debug.
>        6.- Finish.
>
>    Is this the proper (but quite awkward) way to proceed or there is an
> alternative to skip steps 2 to 4? I'm using emacs with ESS under linux.
> Thank you in advance for your time! Best regards,
>
> --                                                      --
> Jose Luis Aznarte M.       http://decsai.ugr.es/~jlaznarte
> Department of Computer Science and Artificial Intelligence
> Universidad de Granada           Tel. +34 - 958 - 24 04 67
> GRANADA (Spain)                  Fax: +34 - 958 - 24 00 79
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From hin-tak.leung at cimr.cam.ac.uk  Mon Mar 26 19:23:43 2007
From: hin-tak.leung at cimr.cam.ac.uk (Hin-Tak Leung)
Date: Mon, 26 Mar 2007 18:23:43 +0100
Subject: [Rd] Developer work cycle
In-Reply-To: <4607F803.7060700@decsai.ugr.es>
References: <4607F803.7060700@decsai.ugr.es>
Message-ID: <4608019F.7000303@cimr.cam.ac.uk>

Jos? Luis Aznarte M. wrote:
>     Hi! I've been browsing through the last months' archive and I can't
> find an answer to my question, so here it is (let's hope it's not too
> obvious):
>     I'm working on extensions of an R library, and I would be very
> surprised if everyone developing R packages is doing the following, as I do:
> 
>         1.- Write down a modification of an R file
>         2.- Exit the current R session
>         3.- Install the package as root (sudo R CMD INSTALL...)
>         4.- Launch a new R session
>         5.- Test the change, if it does not work, go back to 1 or debug.
>         6.- Finish.
> 
>     Is this the proper (but quite awkward) way to proceed or there is an
> alternative to skip steps 2 to 4? I'm using emacs with ESS under linux.
> Thank you in advance for your time! Best regards,

I don't do 2, 3, 4 that way. I just run the sessions in parallel,
and do (no root privilege required):

R CMD INSTALL -l sometemplace mypackage

and in a parallel session, do

library(mypackage, lib.loc="sometemplate")

okay, after a while, I ended up with a few /sometemplace's and a few R 
sessions, but it is much better than doing installing system-wide
as root and overwriting it over and over with semi-broken or
work-in-progress versions.

Hope this helps.

Hin-Tak Leung


From h.wickham at gmail.com  Mon Mar 26 19:33:39 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Mon, 26 Mar 2007 12:33:39 -0500
Subject: [Rd] Developer work cycle
In-Reply-To: <4607F803.7060700@decsai.ugr.es>
References: <4607F803.7060700@decsai.ugr.es>
Message-ID: <f8e6ff050703261033i744a6a0eu112c576dabfa61bb@mail.gmail.com>

On 3/26/07, "Jos? Luis Aznarte M." <jlaznarte at decsai.ugr.es> wrote:
>     Hi! I've been browsing through the last months' archive and I can't
> find an answer to my question, so here it is (let's hope it's not too
> obvious):
>     I'm working on extensions of an R library, and I would be very
> surprised if everyone developing R packages is doing the following, as I do:
>
>         1.- Write down a modification of an R file
>         2.- Exit the current R session
>         3.- Install the package as root (sudo R CMD INSTALL...)
>         4.- Launch a new R session
>         5.- Test the change, if it does not work, go back to 1 or debug.
>         6.- Finish.
>
>     Is this the proper (but quite awkward) way to proceed or there is an
> alternative to skip steps 2 to 4? I'm using emacs with ESS under linux.
> Thank you in advance for your time! Best regards,

I have a file in the root directory of all of my packages that looks like this:

library(meifly)
lapply(dir("~/documents/meifly/meifly/R", "\\.[Sr]$", full.name=T), source)

That way I can modify files in my text editor, and then run
source("load.r") to update all my changes.  This isn't completely full
proof as it loads everything into the global workspace so any
namespace problems won't be apparent.

I also have

"\e[A": history-search-backward
"\e[B": history-search-forward

in my .inputrc file.  This lets me type in "s", then press the up key
a couple of times to get back to the last time I used source(...).
Similarly for any other prefix of a previously typed command - this is
a huge time saver.

Finally, in ~/.profile  I have

alias R='R --no-save --no-restore-data --quiet'

which saves me a few keystrokes when quitting R (and a lot of guff
when I open R) and ensures I always start with a clean workspace.

Hadley


From cstrato at aon.at  Mon Mar 26 19:49:27 2007
From: cstrato at aon.at (cstrato)
Date: Mon, 26 Mar 2007 19:49:27 +0200
Subject: [Rd] Limitation of dirname() and basename()
Message-ID: <460807A7.5030405@aon.at>

Dear all,

I have already twice encountered a case which I consider a limitation of
dirname() and basename().

In my functions I have a parameter "outfile" which e.g. tells where a file
should be stored. Usually "outfile" is of the form:
oufile = "/my/path/myname.txt"

 > outfile <- "/my/path/myname.txt"
 > dirname(outfile)
[1] "/my/path"
 > basename(outfile)
[1] "myname.txt"

However, in addition I want to be able to define the path only, while
creating the name "myname.txt" automatically.
Sorrowly, I get the following:

 > outfile <- "/my/path/"
 > dirname(outfile)
[1] "/my"
 > basename(outfile)
[1] "path"

It would be great if dirname() and basename() could recognize:
dirname("/my/path/")      = /my/path/
basename(""/my/path/")  = ""
i.e. they should be able to recognize a trailing "/".

Best regards
Christian
_._._._._._._._._._._._._._._._
C.h.i.s.t.i.a.n S.t.r.a.t.o.w.a
V.i.e.n.n.a       A.u.s.t.r.i.a
_._._._._._._._._._._._._._._._


From hin-tak.leung at cimr.cam.ac.uk  Mon Mar 26 20:38:05 2007
From: hin-tak.leung at cimr.cam.ac.uk (Hin-Tak Leung)
Date: Mon, 26 Mar 2007 19:38:05 +0100
Subject: [Rd] Developer work cycle
In-Reply-To: <4608102B.1090604@decsai.ugr.es>
References: <4607F803.7060700@decsai.ugr.es> <4608019F.7000303@cimr.cam.ac.uk>
	<4608102B.1090604@decsai.ugr.es>
Message-ID: <4608130D.9080801@cimr.cam.ac.uk>

Jos? Luis Aznarte M. wrote:
> Hin-Tak Leung wrote:
>> I don't do 2, 3, 4 that way. I just run the sessions in parallel,
>> and do (no root privilege required):
>>
>> R CMD INSTALL -l sometemplace mypackage
>>
>> and in a parallel session, do
>>
>> library(mypackage, lib.loc="sometemplate")
>     What do you mean by "sometemplate"? Is that the complete path to
> where the library's source is? Or is it a temporary folder to install
> it? In that case, I could use /tmp/ (in linux) to install test versions
> of the library? And, by doing the "library(mypackage, lib.log="/tmp")"
> call, do I overwrite the current one, including namespaces and so on?
>     Sorry I did not understand exactly what you meant. Thank you so much
> anyway. :-)

typo... happier with this below? Both of them (same "/tmp") is
an alternative installed location, not source location.

R CMD INSTALL -l /tmp mypackage

library(mypackage, lib.loc="/tmp")

I don't think you can do 'library(mypackage, lib.loc="/tmp")' twice
(with a re-install in the middle), if that's what you are thinking.
I think you need to do detach(package:mypackage) at least,
and even then, windows's dll loader gets very confused. I believe
I had managed to crash R by dyn.load()'ing two object files of the
same name twice under wine, so I am not sure it is a good idea.

I read somewhere that object files are never unloaded, but you'll need 
to hear it from the R experts...

HTL


From vdergachev at rcgardis.com  Mon Mar 26 23:08:18 2007
From: vdergachev at rcgardis.com (Vladimir Dergachev)
Date: Mon, 26 Mar 2007 17:08:18 -0400
Subject: [Rd] as.Date nuance
In-Reply-To: <971536df0703240912m8eb5798pe99ad5a66fd71e3a@mail.gmail.com>
References: <200703231930.03846.vdergachev@rcgardis.com>
	<200703241151.13734.vdergachev@rcgardis.com>
	<971536df0703240912m8eb5798pe99ad5a66fd71e3a@mail.gmail.com>
Message-ID: <200703261708.18572.vdergachev@rcgardis.com>

On Saturday 24 March 2007 12:12 pm, Gabor Grothendieck wrote:
> It matches in the sense of grep or regexpr
>
> grep("a", "ab") > 0
> regexpr("a", "ab") > 0
>
> Try this:
>
> x <- c("2006-01-01error", "2006-01-01")
> as.Date(x, "%Y-%m-%d") + ifelse(regexpr("^....-..-..$", x) > 0, 0, NA)
>

Well, still I would have expected as.Date() to do the same thing as.integer() 
or as.numeric() do - return NA and produce a warning.

After poking in the code I also noticed that the format guess is done using 
the first element only:

> as.Date(c("2006", "2006-01-01"))
Error in fromchar(x) : character string is not in a standard unambiguous 
format

> as.Date(c("2006-01-01", "2006"))
[1] "2006-01-01" NA

I attached a patch that changes do_strptime to behave like coerceToInteger, 
please let me know if it is reasonable - I'll then see about getting 
as.Date() to work correctly..

                                thank you

                                       Vladimir Dergachev

Index: src/main/datetime.c
===================================================================
--- src/main/datetime.c	(revision 40895)
+++ src/main/datetime.c	(working copy)
@@ -818,9 +818,9 @@
 SEXP attribute_hidden do_strptime(SEXP call, SEXP op, SEXP args, SEXP env)
 {
     SEXP x, sformat, ans, ansnames, klass, stz, tzone;
-    int i, n, m, N, invalid, isgmt = 0, settz = 0;
+    int i, n, m, N, invalid, isgmt = 0, settz = 0, warn = 0;
     struct tm tm, tm2;
-    char *tz = NULL, oldtz[20] = "";
+    char *tz = NULL, oldtz[20] = "", *p;
     double psecs = 0.0;
 
     checkArity(op, args);
@@ -859,10 +859,15 @@
 	tm.tm_year = tm.tm_mon = tm.tm_mday = tm.tm_yday = 
 	    tm.tm_wday = NA_INTEGER;
 	tm.tm_isdst = -1;
-	invalid = STRING_ELT(x, i%n) == NA_STRING ||
-	    !R_strptime(CHAR(STRING_ELT(x, i%n)),
-			CHAR(STRING_ELT(sformat, i%m)), &tm, &psecs);
+	invalid = STRING_ELT(x, i%n) == NA_STRING;
 	if(!invalid) {
+	    invalid = !(p=R_strptime(CHAR(STRING_ELT(x, i%n)),
+			CHAR(STRING_ELT(sformat, i%m)), &tm, &psecs)) ||
+	    		(*p);
+	    warn |= invalid;
+	    }
+
+	if(!invalid) {
 	    /* Solaris sets missing fields to 0 */
 	    if(tm.tm_mday == 0) tm.tm_mday = NA_INTEGER;
 	    if(tm.tm_mon == NA_INTEGER || tm.tm_mday == NA_INTEGER
@@ -901,6 +906,8 @@
     }
     if(settz) reset_tz(oldtz);
 
+    if(warn) warning(_("NAs introduced by coercion"));
+
     UNPROTECT(3);
     return ans;
 }


From hpages at fhcrc.org  Tue Mar 27 05:48:33 2007
From: hpages at fhcrc.org (hpages at fhcrc.org)
Date: Mon, 26 Mar 2007 20:48:33 -0700
Subject: [Rd] Unexpected result of as.character() and unlist() applied to a
	data frame
Message-ID: <1174967313.460894116113f@webmail.fhcrc.org>

Hi,

> dd <- data.frame(A=c("b","c","a"), B=3:1)
> dd
  A B
1 b 3
2 c 2
3 a 1
> unlist(dd)
A1 A2 A3 B1 B2 B3
 2  3  1  3  2  1

Someone else might get something different. It all depends on the
values of its 'stringsAsFactors' option:

> dd2 <- data.frame(A=c("b","c","a"), B=3:1, stringsAsFactors=FALSE)
> dd2
  A B
1 b 3
2 c 2
3 a 1
> unlist(dd2)
 A1  A2  A3  B1  B2  B3
"b" "c" "a" "3" "2" "1"

Same thing with as.character:

> as.character(dd)
[1] "c(2, 3, 1)" "c(3, 2, 1)"
> as.character(dd2)
[1] "c(\"b\", \"c\", \"a\")" "c(3, 2, 1)"

Bug or "feature"?

Note that as.character applied directly on dd$A doesn't
have this "feature":

> as.character(dd$A)
[1] "b" "c" "a"
> as.character(dd2$A)
[1] "b" "c" "a"

Cheers,
H.


From ripley at stats.ox.ac.uk  Tue Mar 27 08:50:50 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 27 Mar 2007 07:50:50 +0100 (BST)
Subject: [Rd] Limitation of dirname() and basename()
In-Reply-To: <460807A7.5030405@aon.at>
References: <460807A7.5030405@aon.at>
Message-ID: <Pine.LNX.4.64.0703270744580.9277@gannet.stats.ox.ac.uk>

These functions work as they should: did you not read the help page which 
explicitly tells you what happens in this case?

The Unix originals work in the same way:

gannet% dirname /my/path/
/my

Please DO study the R posting guide and do the homework requesting of you 
before posting.

On Mon, 26 Mar 2007, cstrato wrote:

> Dear all,
>
> I have already twice encountered a case which I consider a limitation of
> dirname() and basename().
>
> In my functions I have a parameter "outfile" which e.g. tells where a file
> should be stored. Usually "outfile" is of the form:
> oufile = "/my/path/myname.txt"
>
> > outfile <- "/my/path/myname.txt"
> > dirname(outfile)
> [1] "/my/path"
> > basename(outfile)
> [1] "myname.txt"
>
> However, in addition I want to be able to define the path only, while
> creating the name "myname.txt" automatically.
> Sorrowly, I get the following:
>
> > outfile <- "/my/path/"
> > dirname(outfile)
> [1] "/my"
> > basename(outfile)
> [1] "path"
>
> It would be great if dirname() and basename() could recognize:
> dirname("/my/path/")      = /my/path/
> basename(""/my/path/")  = ""
> i.e. they should be able to recognize a trailing "/".

Not according to the documentation.

>
> Best regards
> Christian
> _._._._._._._._._._._._._._._._
> C.h.i.s.t.i.a.n S.t.r.a.t.o.w.a
> V.i.e.n.n.a       A.u.s.t.r.i.a
> _._._._._._._._._._._._._._._._

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From andy_liaw at merck.com  Tue Mar 27 16:03:04 2007
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue, 27 Mar 2007 10:03:04 -0400
Subject: [Rd] Unexpected result of as.character() and unlist() applied
 to a data frame
In-Reply-To: <1174967313.460894116113f@webmail.fhcrc.org>
References: <1174967313.460894116113f@webmail.fhcrc.org>
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFA03EB2FBB@usctmx1106.merck.com>

Given that the behavior is exactly as I expected it be, I would call
that "feature" (and IMHO not a very special one).  The two data frames
are just different (try str() on them:  A in dd is factor, while A in
dd2 is character), so I don't know why you'd expect unlist() on them to
give you the same answer.

Andy

From: hpages at fhcrc.org
> 
> Hi,
> 
> > dd <- data.frame(A=c("b","c","a"), B=3:1) dd
>   A B
> 1 b 3
> 2 c 2
> 3 a 1
> > unlist(dd)
> A1 A2 A3 B1 B2 B3
>  2  3  1  3  2  1
> 
> Someone else might get something different. It all depends on 
> the values of its 'stringsAsFactors' option:
> 
> > dd2 <- data.frame(A=c("b","c","a"), B=3:1, stringsAsFactors=FALSE)
> > dd2
>   A B
> 1 b 3
> 2 c 2
> 3 a 1
> > unlist(dd2)
>  A1  A2  A3  B1  B2  B3
> "b" "c" "a" "3" "2" "1"
> 
> Same thing with as.character:
> 
> > as.character(dd)
> [1] "c(2, 3, 1)" "c(3, 2, 1)"
> > as.character(dd2)
> [1] "c(\"b\", \"c\", \"a\")" "c(3, 2, 1)"
> 
> Bug or "feature"?
> 
> Note that as.character applied directly on dd$A doesn't have 
> this "feature":
> 
> > as.character(dd$A)
> [1] "b" "c" "a"
> > as.character(dd2$A)
> [1] "b" "c" "a"
> 
> Cheers,
> H.
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 
> 


------------------------------------------------------------------------------
Notice:  This e-mail message, together with any attachments,...{{dropped}}


From maechler at stat.math.ethz.ch  Tue Mar 27 17:25:25 2007
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 27 Mar 2007 17:25:25 +0200
Subject: [Rd] Unexpected result of as.character() and unlist() applied
	to a data frame
In-Reply-To: <1174967313.460894116113f@webmail.fhcrc.org>
References: <1174967313.460894116113f@webmail.fhcrc.org>
Message-ID: <17929.14181.944972.334471@stat.math.ethz.ch>

>>>>> "Herve" == Herve Pages <hpages at fhcrc.org>
>>>>>     on Mon, 26 Mar 2007 20:48:33 -0700 writes:

    Herve> Hi,
    >> dd <- data.frame(A=c("b","c","a"), B=3:1) dd
    Herve>   A B 1 b 3 2 c 2 3 a 1
    >> unlist(dd)
    Herve> A1 A2 A3 B1 B2 B3 2 3 1 3 2 1

    Herve> Someone else might get something different. It all
    Herve> depends on the values of its 'stringsAsFactors'  option:

yes, and I don't like that (last) fact either.
IMO, an option should never be allowed to influence such a basic
function as  data.frame().

I know I would have had time earlier to start discussing this,
but for some (probably good) reasons, I didn't get to it at the
time. 
As Andy comments, everything is behaving as it should / is documented,
including the  'stringsAsFactors' option;
but personally, I really would want to consider changing
the default for  data.frame()s stringAsFactors back (as
pre-R-2.4.0) to 'TRUE' instead of  default.stringsAsFactors()
which is a smart version of getOption("stringsAsFactors"). 
I find it ok ("acceptable") if its influencing  read.table()
but feel differently for data.frame().

Martin





    >> dd2 <- data.frame(A=c("b","c","a"), B=3:1,
    >>                   stringsAsFactors=FALSE)
    >> dd2
    Herve>   A B 1 b 3 2 c 2 3 a 1
    >> unlist(dd2)
    Herve>  A1 A2 A3 B1 B2 B3 "b" "c" "a" "3" "2" "1"

    Herve> Same thing with as.character:

    >> as.character(dd)
    Herve> [1] "c(2, 3, 1)" "c(3, 2, 1)"
    >> as.character(dd2)
    Herve> [1] "c(\"b\", \"c\", \"a\")" "c(3, 2, 1)"

    Herve> Bug or "feature"?

    Herve> Note that as.character applied directly on dd$A
    Herve> doesn't have this "feature":

    >> as.character(dd$A)
    Herve> [1] "b" "c" "a"
    >> as.character(dd2$A)
    Herve> [1] "b" "c" "a"

    Herve> Cheers, H.

    Herve> ______________________________________________
    Herve> R-devel at r-project.org mailing list
    Herve> https://stat.ethz.ch/mailman/listinfo/r-devel


From hpages at fhcrc.org  Tue Mar 27 19:23:55 2007
From: hpages at fhcrc.org (Herve Pages)
Date: Tue, 27 Mar 2007 10:23:55 -0700
Subject: [Rd] Unexpected result of as.character() and unlist() applied
 to a data frame
In-Reply-To: <39B6DDB9048D0F4DAD42CB26AAFF0AFA03EB2FBB@usctmx1106.merck.com>
References: <1174967313.460894116113f@webmail.fhcrc.org>
	<39B6DDB9048D0F4DAD42CB26AAFF0AFA03EB2FBB@usctmx1106.merck.com>
Message-ID: <4609532B.5050506@fhcrc.org>

Liaw, Andy wrote:
> Given that the behavior is exactly as I expected it be, I would call
> that "feature" (and IMHO not a very special one).  The two data frames
> are just different (try str() on them:  A in dd is factor, while A in
> dd2 is character), so I don't know why you'd expect unlist() on them to
> give you the same answer.

Not sure what I would expect for unlist(). I was just curious and decided
to try unlist() on a data frame and found this funny behaviour.

But for as.character(), I definetly wouldn't expect this:
  > as.character(dd)
  [1] "c(2, 3, 1)" "c(3, 2, 1)"
  > as.character(dd$A)
  [1] "b" "c" "a"

And generally speaking, it's a bad idea to have the semantic of standard objects
controlled by some obscure global option.  Here 2 people with a different
"stringsAsFactors" option will not get the same results when manipulating 'dd'.
It makes writing reproducible code harder because then you must remember to specify
the stringsAsFactors option everytime you create a data frame.

Cheers,
H.


> 
> Andy
> 
> From: hpages at fhcrc.org
>> Hi,
>>
>>> dd <- data.frame(A=c("b","c","a"), B=3:1) dd
>>   A B
>> 1 b 3
>> 2 c 2
>> 3 a 1
>>> unlist(dd)
>> A1 A2 A3 B1 B2 B3
>>  2  3  1  3  2  1
>>
>> Someone else might get something different. It all depends on 
>> the values of its 'stringsAsFactors' option:
>>
>>> dd2 <- data.frame(A=c("b","c","a"), B=3:1, stringsAsFactors=FALSE)
>>> dd2
>>   A B
>> 1 b 3
>> 2 c 2
>> 3 a 1
>>> unlist(dd2)
>>  A1  A2  A3  B1  B2  B3
>> "b" "c" "a" "3" "2" "1"
>>
>> Same thing with as.character:
>>
>>> as.character(dd)
>> [1] "c(2, 3, 1)" "c(3, 2, 1)"
>>> as.character(dd2)
>> [1] "c(\"b\", \"c\", \"a\")" "c(3, 2, 1)"
>>
>> Bug or "feature"?
>>
>> Note that as.character applied directly on dd$A doesn't have 
>> this "feature":
>>
>>> as.character(dd$A)
>> [1] "b" "c" "a"
>>> as.character(dd2$A)
>> [1] "b" "c" "a"
>>
>> Cheers,
>> H.
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>>
> 
> 
> ------------------------------------------------------------------------------
> Notice:  This e-mail message, together with any attachment...{{dropped}}


From cstrato at aon.at  Tue Mar 27 19:44:56 2007
From: cstrato at aon.at (cstrato)
Date: Tue, 27 Mar 2007 19:44:56 +0200
Subject: [Rd] Limitation of dirname() and basename()
In-Reply-To: <Pine.LNX.4.64.0703270744580.9277@gannet.stats.ox.ac.uk>
References: <460807A7.5030405@aon.at>
	<Pine.LNX.4.64.0703270744580.9277@gannet.stats.ox.ac.uk>
Message-ID: <46095818.9080703@aon.at>

1. I did read the help file.
2. I have my own workaround, using e.g. 
   file.info("/my/path/")[,"isdir"]
3. This was a suggestion.
4. If you agree with me that "/my/path/" is a path, then both
   "dirname()" and "dirname" give an incorrect answer.
5. Maybe, you can give me a logical reason (besides a
   historical reason) why this should be the way it is.


Prof Brian Ripley wrote:
> These functions work as they should: did you not read the help page 
> which explicitly tells you what happens in this case?
>
> The Unix originals work in the same way:
>
> gannet% dirname /my/path/
> /my
>
> Please DO study the R posting guide and do the homework requesting of 
> you before posting.
>
> On Mon, 26 Mar 2007, cstrato wrote:
>
>> Dear all,
>>
>> I have already twice encountered a case which I consider a limitation of
>> dirname() and basename().
>>
>> In my functions I have a parameter "outfile" which e.g. tells where a 
>> file
>> should be stored. Usually "outfile" is of the form:
>> oufile = "/my/path/myname.txt"
>>
>> > outfile <- "/my/path/myname.txt"
>> > dirname(outfile)
>> [1] "/my/path"
>> > basename(outfile)
>> [1] "myname.txt"
>>
>> However, in addition I want to be able to define the path only, while
>> creating the name "myname.txt" automatically.
>> Sorrowly, I get the following:
>>
>> > outfile <- "/my/path/"
>> > dirname(outfile)
>> [1] "/my"
>> > basename(outfile)
>> [1] "path"
>>
>> It would be great if dirname() and basename() could recognize:
>> dirname("/my/path/")      = /my/path/
>> basename(""/my/path/")  = ""
>> i.e. they should be able to recognize a trailing "/".
>
> Not according to the documentation.
>
>>
>> Best regards
>> Christian
>> _._._._._._._._._._._._._._._._
>> C.h.i.s.t.i.a.n S.t.r.a.t.o.w.a
>> V.i.e.n.n.a       A.u.s.t.r.i.a
>> _._._._._._._._._._._._._._._._
>


From hin-tak.leung at cimr.cam.ac.uk  Tue Mar 27 20:25:04 2007
From: hin-tak.leung at cimr.cam.ac.uk (Hin-Tak Leung)
Date: Tue, 27 Mar 2007 19:25:04 +0100
Subject: [Rd] Limitation of dirname() and basename()
In-Reply-To: <46095818.9080703@aon.at>
References: <460807A7.5030405@aon.at>	<Pine.LNX.4.64.0703270744580.9277@gannet.stats.ox.ac.uk>
	<46095818.9080703@aon.at>
Message-ID: <46096180.5070907@cimr.cam.ac.uk>

cstrato wrote:
> 1. I did read the help file.
> 2. I have my own workaround, using e.g. 
>    file.info("/my/path/")[,"isdir"]
> 3. This was a suggestion.
> 4. If you agree with me that "/my/path/" is a path, then both
>    "dirname()" and "dirname" give an incorrect answer.
> 5. Maybe, you can give me a logical reason (besides a
>    historical reason) why this should be the way it is.

Can you just read "man 3 dirname" and "man 1 dirname" on any unix box?
Isn't "historical reason" - this is how dirname works for the last 25(?) 
years, some people will be *very* upset if it behaves differently now -
a good enough reason?

HTL

> Prof Brian Ripley wrote:
>> These functions work as they should: did you not read the help page 
>> which explicitly tells you what happens in this case?
>>
>> The Unix originals work in the same way:
>>
>> gannet% dirname /my/path/
>> /my
>>
>> Please DO study the R posting guide and do the homework requesting of 
>> you before posting.
>>
>> On Mon, 26 Mar 2007, cstrato wrote:
>>
>>> Dear all,
>>>
>>> I have already twice encountered a case which I consider a limitation of
>>> dirname() and basename().
>>>
>>> In my functions I have a parameter "outfile" which e.g. tells where a 
>>> file
>>> should be stored. Usually "outfile" is of the form:
>>> oufile = "/my/path/myname.txt"
>>>
>>>> outfile <- "/my/path/myname.txt"
>>>> dirname(outfile)
>>> [1] "/my/path"
>>>> basename(outfile)
>>> [1] "myname.txt"
>>>
>>> However, in addition I want to be able to define the path only, while
>>> creating the name "myname.txt" automatically.
>>> Sorrowly, I get the following:
>>>
>>>> outfile <- "/my/path/"
>>>> dirname(outfile)
>>> [1] "/my"
>>>> basename(outfile)
>>> [1] "path"
>>>
>>> It would be great if dirname() and basename() could recognize:
>>> dirname("/my/path/")      = /my/path/
>>> basename(""/my/path/")  = ""
>>> i.e. they should be able to recognize a trailing "/".
>> Not according to the documentation.
>>
>>> Best regards
>>> Christian
>>> _._._._._._._._._._._._._._._._
>>> C.h.i.s.t.i.a.n S.t.r.a.t.o.w.a
>>> V.i.e.n.n.a       A.u.s.t.r.i.a
>>> _._._._._._._._._._._._._._._._
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From lmada at gmx.net  Tue Mar 27 20:41:30 2007
From: lmada at gmx.net (Leonard Mada)
Date: Tue, 27 Mar 2007 21:41:30 +0300
Subject: [Rd] Bridging R to OpenOffice
Message-ID: <4609655A.5070209@gmx.net>

Dear members of the R Development Team,

I am looking for people with a deep understanding of R internals to 
assist in bridging R to OpenOffice.

While R is a state of the art statistical environment, less experienced 
users often find it difficult to work with R. Therefore, I believe that 
a bridge between R and a spreadsheet program will make this transition 
less painful. I sincerely believe that this will benefit both the R 
community as well as the potential new users.

OpenOffice is an open-source office suite that includes a spreadsheet 
program (Calc).

OpenOffice.org (OOo) is participating in the Google Summer of Code 2007 
initiative sponsored by Google and one of the proposed projects involves 
the creation of an add-on component that allows an OOo Calc user to let 
the R environment do calculations on data from Calc cells and put the 
results into the spreadsheet again. A brief description can be found on 
the OOo Summer of Code wiki page 
(http://wiki.services.openoffice.org/wiki/Summer_of_Code_2007).

Two students have already shown interest in this project (see the OOo 
mailing list, 
http://sc.openoffice.org/servlets/BrowseList?listName=dev&from=2007-03-01&to=2007-03-31&by=date&first=21&selectedPage=2, 
the "Summer of Code: R and Calc" thread).

While mentoring is already available from a member of the OpenOffice 
team (I will try to offer a helping hand on statistics and R-syntax, but 
NOT the coding part itself), I feel that we still need someone with 
R-core expertise. I am aware of various existing packages (rcom, RDCOM) 
and the availability of various online-informations (like 
http://developer.r-project.org/embedded.html), however more specific 
questions may arise in the future, especially as this embedding should 
be platform-independent, and I would welcome any help from the R-core 
team members.

I am looking forward to hear from you and hope that this project will be 
a great success. I would like to thank you in advance for your effort.

Sincerely,

Leonard Mada


From cstrato at aon.at  Tue Mar 27 20:49:29 2007
From: cstrato at aon.at (cstrato)
Date: Tue, 27 Mar 2007 20:49:29 +0200
Subject: [Rd] Limitation of dirname() and basename()
In-Reply-To: <46096180.5070907@cimr.cam.ac.uk>
References: <460807A7.5030405@aon.at>	<Pine.LNX.4.64.0703270744580.9277@gannet.stats.ox.ac.uk>
	<46095818.9080703@aon.at> <46096180.5070907@cimr.cam.ac.uk>
Message-ID: <46096739.20006@aon.at>

Hin-Tak Leung wrote:
> cstrato wrote:
>> 1. I did read the help file.
>> 2. I have my own workaround, using e.g.    
>> file.info("/my/path/")[,"isdir"]
>> 3. This was a suggestion.
>> 4. If you agree with me that "/my/path/" is a path, then both
>>    "dirname()" and "dirname" give an incorrect answer.
>> 5. Maybe, you can give me a logical reason (besides a
>>    historical reason) why this should be the way it is.
>
> Can you just read "man 3 dirname" and "man 1 dirname" on any unix box?
> Isn't "historical reason" - this is how dirname works for the last 
> 25(?) years, some people will be *very* upset if it behaves 
> differently now -
> a good enough reason?
>
> HTL
A 25 year old mistake is no reason for R to duplicate this mistake.
>
>> Prof Brian Ripley wrote:
>>> These functions work as they should: did you not read the help page 
>>> which explicitly tells you what happens in this case?
>>>
>>> The Unix originals work in the same way:
>>>
>>> gannet% dirname /my/path/
>>> /my
>>>
>>> Please DO study the R posting guide and do the homework requesting 
>>> of you before posting.
>>>
>>> On Mon, 26 Mar 2007, cstrato wrote:
>>>
>>>> Dear all,
>>>>
>>>> I have already twice encountered a case which I consider a 
>>>> limitation of
>>>> dirname() and basename().
>>>>
>>>> In my functions I have a parameter "outfile" which e.g. tells where 
>>>> a file
>>>> should be stored. Usually "outfile" is of the form:
>>>> oufile = "/my/path/myname.txt"
>>>>
>>>>> outfile <- "/my/path/myname.txt"
>>>>> dirname(outfile)
>>>> [1] "/my/path"
>>>>> basename(outfile)
>>>> [1] "myname.txt"
>>>>
>>>> However, in addition I want to be able to define the path only, while
>>>> creating the name "myname.txt" automatically.
>>>> Sorrowly, I get the following:
>>>>
>>>>> outfile <- "/my/path/"
>>>>> dirname(outfile)
>>>> [1] "/my"
>>>>> basename(outfile)
>>>> [1] "path"
>>>>
>>>> It would be great if dirname() and basename() could recognize:
>>>> dirname("/my/path/")      = /my/path/
>>>> basename(""/my/path/")  = ""
>>>> i.e. they should be able to recognize a trailing "/".
>>> Not according to the documentation.
>>>
>>>> Best regards
>>>> Christian
>>>> _._._._._._._._._._._._._._._._
>>>> C.h.i.s.t.i.a.n S.t.r.a.t.o.w.a
>>>> V.i.e.n.n.a       A.u.s.t.r.i.a
>>>> _._._._._._._._._._._._._._._._
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>
>


From ggrothendieck at gmail.com  Tue Mar 27 20:57:04 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 27 Mar 2007 14:57:04 -0400
Subject: [Rd] Limitation of dirname() and basename()
In-Reply-To: <46096739.20006@aon.at>
References: <460807A7.5030405@aon.at>
	<Pine.LNX.4.64.0703270744580.9277@gannet.stats.ox.ac.uk>
	<46095818.9080703@aon.at> <46096180.5070907@cimr.cam.ac.uk>
	<46096739.20006@aon.at>
Message-ID: <971536df0703271157m30f48281of787093a8a4d5c4a@mail.gmail.com>

On 3/27/07, cstrato <cstrato at aon.at> wrote:
> Hin-Tak Leung wrote:
> > cstrato wrote:
> >> 1. I did read the help file.
> >> 2. I have my own workaround, using e.g.
> >> file.info("/my/path/")[,"isdir"]
> >> 3. This was a suggestion.
> >> 4. If you agree with me that "/my/path/" is a path, then both
> >>    "dirname()" and "dirname" give an incorrect answer.
> >> 5. Maybe, you can give me a logical reason (besides a
> >>    historical reason) why this should be the way it is.
> >
> > Can you just read "man 3 dirname" and "man 1 dirname" on any unix box?
> > Isn't "historical reason" - this is how dirname works for the last
> > 25(?) years, some people will be *very* upset if it behaves
> > differently now -
> > a good enough reason?
> >
> > HTL
> A 25 year old mistake is no reason for R to duplicate this mistake.
> >

It would be possible to have the way it works controlled by an argument
if backward compatibility is the issue:
e.g.

dirname("/my/path/", extended = TRUE)

or it would be possible to have a second command:

dirname2("/my/path/")


From cstrato at aon.at  Tue Mar 27 21:05:09 2007
From: cstrato at aon.at (cstrato)
Date: Tue, 27 Mar 2007 21:05:09 +0200
Subject: [Rd] Limitation of dirname() and basename()
In-Reply-To: <971536df0703271157m30f48281of787093a8a4d5c4a@mail.gmail.com>
References: <460807A7.5030405@aon.at>	
	<Pine.LNX.4.64.0703270744580.9277@gannet.stats.ox.ac.uk>	
	<46095818.9080703@aon.at> <46096180.5070907@cimr.cam.ac.uk>	
	<46096739.20006@aon.at>
	<971536df0703271157m30f48281of787093a8a4d5c4a@mail.gmail.com>
Message-ID: <46096AE5.1010606@aon.at>

Gabor Grothendieck wrote:
> On 3/27/07, cstrato <cstrato at aon.at> wrote:
>> Hin-Tak Leung wrote:
>> > cstrato wrote:
>> >> 1. I did read the help file.
>> >> 2. I have my own workaround, using e.g.
>> >> file.info("/my/path/")[,"isdir"]
>> >> 3. This was a suggestion.
>> >> 4. If you agree with me that "/my/path/" is a path, then both
>> >>    "dirname()" and "dirname" give an incorrect answer.
>> >> 5. Maybe, you can give me a logical reason (besides a
>> >>    historical reason) why this should be the way it is.
>> >
>> > Can you just read "man 3 dirname" and "man 1 dirname" on any unix box?
>> > Isn't "historical reason" - this is how dirname works for the last
>> > 25(?) years, some people will be *very* upset if it behaves
>> > differently now -
>> > a good enough reason?
>> >
>> > HTL
>> A 25 year old mistake is no reason for R to duplicate this mistake.
>> >
>
> It would be possible to have the way it works controlled by an argument
> if backward compatibility is the issue:
> e.g.
>
> dirname("/my/path/", extended = TRUE)
>
> or it would be possible to have a second command:
>
> dirname2("/my/path/")
>
>
Thank you, I like your first suggestion very much, it is very elegant.
(dirname2() is also a possibility but not so elegant.)
Best regards
Christian


From p.murrell at auckland.ac.nz  Tue Mar 27 23:11:08 2007
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Wed, 28 Mar 2007 09:11:08 +1200
Subject: [Rd] [R] Can I scale the labels in a 'persp' graph?
In-Reply-To: <Pine.LNX.4.64.0703221909020.22676@gannet.stats.ox.ac.uk>
References: <mailman.11.1174042804.26780.r-help@stat.math.ethz.ch>	<Pine.LNX.4.64.0703161252350.30144@obelix.umh.es>	<45FA999D.1090406@stats.uwo.ca>
	<Pine.LNX.4.64.0703221909020.22676@gannet.stats.ox.ac.uk>
Message-ID: <4609886C.7020402@stat.auckland.ac.nz>

Hi


Prof Brian Ripley wrote:
> [Moved to R-devel to ask a policy question.]
> 
> On Fri, 16 Mar 2007, Duncan Murdoch wrote:
> 
>> On 3/16/2007 8:02 AM, salcaraz at obelix.umh.es wrote:
>>> Hi all:
>>>
>>> I'm using 'persp' for 3D graphics.
>>>
>>> I need the axis's labels smaller than by defect.
>>>
>>> I see in 'help()', the information about 'par()'.
>>>
>>> I have wrote:
>>>
>>>> par(.....,cex.axis=0.5,cex.lab=0.5)
>>> perspc(.................)
>>>
>>> and the result don't change.
>>>
>>> The question is: Can I change the size of labels in the perps graph??
>>>
>>> Thank you in advance:
>>>
>>> /salva
>>>
>>> 'cex.axis' The magnification to be used for axis annotation
>>>            relative to the current setting of 'cex'. (Some functions
>>>            such as 'points' accept a vector of values which are
>>>            recycled.  Other uses will take just the first value if a
>>>            vector of length greater than one is supplied.)
>>>
>>> 'cex.lab' The magnification to be used for x and y labels relative
>>>            to the current setting of 'cex'.
>> Those don't appear to be supported by persp, but cex is: e.g.
>>
>> x <- 1:10
>> y <- 1:10
>> z <- outer(x,y,function(x,y) sin((x+y)/10))
>> persp(x,y,z, cex=0.5)
> 
> I've added this to ?persp and ?par, but I wondered if people thought we 
> should change this to be like 2D plots.  Especially Ross I., who I believe 
> is the author here?


I think Ross wrote the original.  I've hacked some of it a couple of
times.  I have no problem with allowing par()s to work with persp(),
though not everything makes sense (e.g., par("mar"), or par("mgp") where
it gets tricky to get units right or units just do not make sense).
There are also 2D-specific ones, like par("xaxt"), though in those cases
one option might be to just offer an inline z-analogue in the arguments
to persp() (?)

Paul
-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/


From simon.urbanek at r-project.org  Tue Mar 27 23:11:23 2007
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Tue, 27 Mar 2007 17:11:23 -0400
Subject: [Rd] Limitation of dirname() and basename()
In-Reply-To: <46096739.20006@aon.at>
References: <460807A7.5030405@aon.at>	<Pine.LNX.4.64.0703270744580.9277@gannet.stats.ox.ac.uk>
	<46095818.9080703@aon.at> <46096180.5070907@cimr.cam.ac.uk>
	<46096739.20006@aon.at>
Message-ID: <ADFA2A8A-B14B-44D9-899C-EFBE529E6F66@r-project.org>


On Mar 27, 2007, at 2:49 PM, cstrato wrote:

> Hin-Tak Leung wrote:
>> cstrato wrote:
>>> 1. I did read the help file.
>>> 2. I have my own workaround, using e.g.
>>> file.info("/my/path/")[,"isdir"]
>>> 3. This was a suggestion.
>>> 4. If you agree with me that "/my/path/" is a path, then both
>>>    "dirname()" and "dirname" give an incorrect answer.
>>> 5. Maybe, you can give me a logical reason (besides a
>>>    historical reason) why this should be the way it is.
>>
>> Can you just read "man 3 dirname" and "man 1 dirname" on any unix  
>> box?
>> Isn't "historical reason" - this is how dirname works for the last
>> 25(?) years, some people will be *very* upset if it behaves
>> differently now -
>> a good enough reason?
>>
>> HTL
> A 25 year old mistake is no reason for R to duplicate this mistake.


Please read the corresponding docs before posting such nonsense  
(especially the Rationale section):
http://www.opengroup.org/onlinepubs/000095399/utilities/basename.html

Your proposed behavior is inconsistent, anyway. The purpose of  
dirname is to return parent directory of the entity represented by  
the pathname. "/my/path" and "/my/path/" are equivalent as they both  
represent the directory "path" whose parent is "/my", therefore  
returning "/my/path" in either case is inconsistent with the purpose  
of this function. As of trailing slashes (independently of dirname),  
sadly, some programs exploit the equivalence of both representations  
by encoding meta-information in the representation, but this behavior  
is quite confusing and error-prone. You're free to add such special  
cases to your application, but there is no reason to add such  
confusion to R.

Cheers,
Simon



>>
>>> Prof Brian Ripley wrote:
>>>> These functions work as they should: did you not read the help page
>>>> which explicitly tells you what happens in this case?
>>>>
>>>> The Unix originals work in the same way:
>>>>
>>>> gannet% dirname /my/path/
>>>> /my
>>>>
>>>> Please DO study the R posting guide and do the homework requesting
>>>> of you before posting.
>>>>
>>>> On Mon, 26 Mar 2007, cstrato wrote:
>>>>
>>>>> Dear all,
>>>>>
>>>>> I have already twice encountered a case which I consider a
>>>>> limitation of
>>>>> dirname() and basename().
>>>>>
>>>>> In my functions I have a parameter "outfile" which e.g. tells  
>>>>> where
>>>>> a file
>>>>> should be stored. Usually "outfile" is of the form:
>>>>> oufile = "/my/path/myname.txt"
>>>>>
>>>>>> outfile <- "/my/path/myname.txt"
>>>>>> dirname(outfile)
>>>>> [1] "/my/path"
>>>>>> basename(outfile)
>>>>> [1] "myname.txt"
>>>>>
>>>>> However, in addition I want to be able to define the path only,  
>>>>> while
>>>>> creating the name "myname.txt" automatically.
>>>>> Sorrowly, I get the following:
>>>>>
>>>>>> outfile <- "/my/path/"
>>>>>> dirname(outfile)
>>>>> [1] "/my"
>>>>>> basename(outfile)
>>>>> [1] "path"
>>>>>
>>>>> It would be great if dirname() and basename() could recognize:
>>>>> dirname("/my/path/")      = /my/path/
>>>>> basename(""/my/path/")  = ""
>>>>> i.e. they should be able to recognize a trailing "/".
>>>> Not according to the documentation.
>>>>
>>>>> Best regards
>>>>> Christian
>>>>> _._._._._._._._._._._._._._._._
>>>>> C.h.i.s.t.i.a.n S.t.r.a.t.o.w.a
>>>>> V.i.e.n.n.a       A.u.s.t.r.i.a
>>>>> _._._._._._._._._._._._._._._._
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From hpages at fhcrc.org  Tue Mar 27 23:42:52 2007
From: hpages at fhcrc.org (Herve Pages)
Date: Tue, 27 Mar 2007 14:42:52 -0700
Subject: [Rd] Limitation of dirname() and basename()
In-Reply-To: <ADFA2A8A-B14B-44D9-899C-EFBE529E6F66@r-project.org>
References: <460807A7.5030405@aon.at>	<Pine.LNX.4.64.0703270744580.9277@gannet.stats.ox.ac.uk>	<46095818.9080703@aon.at>
	<46096180.5070907@cimr.cam.ac.uk>	<46096739.20006@aon.at>
	<ADFA2A8A-B14B-44D9-899C-EFBE529E6F66@r-project.org>
Message-ID: <46098FDC.4010707@fhcrc.org>

Hi,

Simon Urbanek wrote:
> Your proposed behavior is inconsistent, anyway. The purpose of  
> dirname is to return parent directory of the entity represented by  
> the pathname.

Mmmm, I don't think this is true:

  > dirname("aaa/..")
  [1] "aaa"

"aaa" is not the parent directory of "aaa/.."

Same here:

  > dirname("/usr/./.")
  [1] "/usr/."


> "/my/path" and "/my/path/" are equivalent as they both  
> represent the directory "path" whose parent is "/my", therefore  
> returning "/my/path" in either case is inconsistent with the purpose  
> of this function. As of trailing slashes (independently of dirname),  
> sadly, some programs exploit the equivalence of both representations  
> by encoding meta-information in the representation, but this behavior  
> is quite confusing and error-prone. You're free to add such special  
> cases to your application, but there is no reason to add such  
> confusion to R.

Note that Python's designers were not afraid to emancipate from Unix for
this particular case:

  >>> import os.path
  >>> os.path.dirname("aaa/..")
  'aaa'
  >>> os.path.dirname("aaa/../")
  'aaa/..'


Also note that, if the goal was to mimic Unix behaviour, then why not
fully go for it, even for edge-cases:

  R
  ----
  > dirname("/")
  [1] "/"
  > basename("/")
  [1] ""

  Unix
  ----
  hpages at lamb1:~> dirname "/"
  /
  hpages at lamb1:~> basename "/"
  /

Just my 2 cents...

Cheers,
H.


> 
> Cheers,
> Simon
> 
> 
> 
>>>> Prof Brian Ripley wrote:
>>>>> These functions work as they should: did you not read the help page
>>>>> which explicitly tells you what happens in this case?
>>>>>
>>>>> The Unix originals work in the same way:
>>>>>
>>>>> gannet% dirname /my/path/
>>>>> /my
>>>>>
>>>>> Please DO study the R posting guide and do the homework requesting
>>>>> of you before posting.
>>>>>
>>>>> On Mon, 26 Mar 2007, cstrato wrote:
>>>>>
>>>>>> Dear all,
>>>>>>
>>>>>> I have already twice encountered a case which I consider a
>>>>>> limitation of
>>>>>> dirname() and basename().
>>>>>>
>>>>>> In my functions I have a parameter "outfile" which e.g. tells  
>>>>>> where
>>>>>> a file
>>>>>> should be stored. Usually "outfile" is of the form:
>>>>>> oufile = "/my/path/myname.txt"
>>>>>>
>>>>>>> outfile <- "/my/path/myname.txt"
>>>>>>> dirname(outfile)
>>>>>> [1] "/my/path"
>>>>>>> basename(outfile)
>>>>>> [1] "myname.txt"
>>>>>>
>>>>>> However, in addition I want to be able to define the path only,  
>>>>>> while
>>>>>> creating the name "myname.txt" automatically.
>>>>>> Sorrowly, I get the following:
>>>>>>
>>>>>>> outfile <- "/my/path/"
>>>>>>> dirname(outfile)
>>>>>> [1] "/my"
>>>>>>> basename(outfile)
>>>>>> [1] "path"
>>>>>>
>>>>>> It would be great if dirname() and basename() could recognize:
>>>>>> dirname("/my/path/")      = /my/path/
>>>>>> basename(""/my/path/")  = ""
>>>>>> i.e. they should be able to recognize a trailing "/".
>>>>> Not according to the documentation.
>>>>>
>>>>>> Best regards
>>>>>> Christian
>>>>>> _._._._._._._._._._._._._._._._
>>>>>> C.h.i.s.t.i.a.n S.t.r.a.t.o.w.a
>>>>>> V.i.e.n.n.a       A.u.s.t.r.i.a
>>>>>> _._._._._._._._._._._._._._._._
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From cstrato at aon.at  Tue Mar 27 23:47:52 2007
From: cstrato at aon.at (cstrato)
Date: Tue, 27 Mar 2007 23:47:52 +0200
Subject: [Rd] Limitation of dirname() and basename()
In-Reply-To: <ADFA2A8A-B14B-44D9-899C-EFBE529E6F66@r-project.org>
References: <460807A7.5030405@aon.at>	<Pine.LNX.4.64.0703270744580.9277@gannet.stats.ox.ac.uk>
	<46095818.9080703@aon.at> <46096180.5070907@cimr.cam.ac.uk>
	<46096739.20006@aon.at>
	<ADFA2A8A-B14B-44D9-899C-EFBE529E6F66@r-project.org>
Message-ID: <46099108.1010309@aon.at>

Simon Urbanek wrote:
>
> On Mar 27, 2007, at 2:49 PM, cstrato wrote:
>
>> Hin-Tak Leung wrote:
>>> cstrato wrote:
>>>> 1. I did read the help file.
>>>> 2. I have my own workaround, using e.g.
>>>> file.info("/my/path/")[,"isdir"]
>>>> 3. This was a suggestion.
>>>> 4. If you agree with me that "/my/path/" is a path, then both
>>>>    "dirname()" and "dirname" give an incorrect answer.
>>>> 5. Maybe, you can give me a logical reason (besides a
>>>>    historical reason) why this should be the way it is.
>>>
>>> Can you just read "man 3 dirname" and "man 1 dirname" on any unix box?
>>> Isn't "historical reason" - this is how dirname works for the last
>>> 25(?) years, some people will be *very* upset if it behaves
>>> differently now -
>>> a good enough reason?
>>>
>>> HTL
>> A 25 year old mistake is no reason for R to duplicate this mistake.
>
>
> Please read the corresponding docs before posting such nonsense 
> (especially the Rationale section):
> http://www.opengroup.org/onlinepubs/000095399/utilities/basename.html
>
> Your proposed behavior is inconsistent, anyway. The purpose of dirname 
> is to return parent directory of the entity represented by the 
> pathname. "/my/path" and "/my/path/" are equivalent as they both 
> represent the directory "path" whose parent is "/my", therefore 
> returning "/my/path" in either case is inconsistent with the purpose 
> of this function. As of trailing slashes (independently of dirname), 
> sadly, some programs exploit the equivalence of both representations 
> by encoding meta-information in the representation, but this behavior 
> is quite confusing and error-prone. You're free to add such special 
> cases to your application, but there is no reason to add such 
> confusion to R.
>
> Cheers,
> Simon
>
Your explanation of dirname returning the "parent" directory sounds 
reasonable, however, none of the documents mentions this.
Maybe, I do not understand the documents correctly, nevertheless I have 
to accept this behavior.

Best regards
Christian


From simon.urbanek at r-project.org  Wed Mar 28 00:31:49 2007
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Tue, 27 Mar 2007 18:31:49 -0400
Subject: [Rd] Limitation of dirname() and basename()
In-Reply-To: <46098FDC.4010707@fhcrc.org>
References: <460807A7.5030405@aon.at>	<Pine.LNX.4.64.0703270744580.9277@gannet.stats.ox.ac.uk>	<46095818.9080703@aon.at>
	<46096180.5070907@cimr.cam.ac.uk>	<46096739.20006@aon.at>
	<ADFA2A8A-B14B-44D9-899C-EFBE529E6F66@r-project.org>
	<46098FDC.4010707@fhcrc.org>
Message-ID: <0060E2BA-CABF-40C3-8C1A-19D9B5384835@r-project.org>


On Mar 27, 2007, at 5:42 PM, Herve Pages wrote:

> Simon Urbanek wrote:
>> Your proposed behavior is inconsistent, anyway. The purpose of  
>> dirname is to return parent directory of the entity represented by  
>> the pathname.
>
> Mmmm, I don't think this is true:
>
>> dirname("aaa/..")
>   [1] "aaa"
>
> "aaa" is not the parent directory of "aaa/.."
>
> Same here:
>
>> dirname("/usr/./.")
>   [1] "/usr/."
>

Yes, the problem is that most dirname implementations don't  
canonicalize the path - they are working on the string representation  
and don't use the underlying FS. I wasn't saying that dirname is  
perfect, in fact I refrained from commenting on this earlier exactly  
because of the behavior you describe, but the decision to remove  
trailing slashes was a deliberate as can be seen from the specs.  
Semantically correct behavior (taking the definition of the dirname  
function literally) would be dirname "/usr/." = "/", basename "/ 
usr/." = "usr". However, I suspect that not many people would expect  
this ;). As was proposed earlier, one could think of "true" dirname"  
or perhaps better "parentdir" function, although admittedly I don't  
see an issue here ...

Cheers,
Simon



>
>> "/my/path" and "/my/path/" are equivalent as they both
>> represent the directory "path" whose parent is "/my", therefore
>> returning "/my/path" in either case is inconsistent with the purpose
>> of this function. As of trailing slashes (independently of dirname),
>> sadly, some programs exploit the equivalence of both representations
>> by encoding meta-information in the representation, but this behavior
>> is quite confusing and error-prone. You're free to add such special
>> cases to your application, but there is no reason to add such
>> confusion to R.
>
> Note that Python's designers were not afraid to emancipate from  
> Unix for
> this particular case:
>
>>>> import os.path
>>>> os.path.dirname("aaa/..")
>   'aaa'
>>>> os.path.dirname("aaa/../")
>   'aaa/..'
>
>
> Also note that, if the goal was to mimic Unix behaviour, then why not
> fully go for it, even for edge-cases:
>
>   R
>   ----
>> dirname("/")
>   [1] "/"
>> basename("/")
>   [1] ""
>
>   Unix
>   ----
>   hpages at lamb1:~> dirname "/"
>   /
>   hpages at lamb1:~> basename "/"
>   /
>
> Just my 2 cents...
>
> Cheers,
> H.
>
>
>>
>> Cheers,
>> Simon
>>
>>
>>
>>>>> Prof Brian Ripley wrote:
>>>>>> These functions work as they should: did you not read the help  
>>>>>> page
>>>>>> which explicitly tells you what happens in this case?
>>>>>>
>>>>>> The Unix originals work in the same way:
>>>>>>
>>>>>> gannet% dirname /my/path/
>>>>>> /my
>>>>>>
>>>>>> Please DO study the R posting guide and do the homework  
>>>>>> requesting
>>>>>> of you before posting.
>>>>>>
>>>>>> On Mon, 26 Mar 2007, cstrato wrote:
>>>>>>
>>>>>>> Dear all,
>>>>>>>
>>>>>>> I have already twice encountered a case which I consider a
>>>>>>> limitation of
>>>>>>> dirname() and basename().
>>>>>>>
>>>>>>> In my functions I have a parameter "outfile" which e.g. tells
>>>>>>> where
>>>>>>> a file
>>>>>>> should be stored. Usually "outfile" is of the form:
>>>>>>> oufile = "/my/path/myname.txt"
>>>>>>>
>>>>>>>> outfile <- "/my/path/myname.txt"
>>>>>>>> dirname(outfile)
>>>>>>> [1] "/my/path"
>>>>>>>> basename(outfile)
>>>>>>> [1] "myname.txt"
>>>>>>>
>>>>>>> However, in addition I want to be able to define the path only,
>>>>>>> while
>>>>>>> creating the name "myname.txt" automatically.
>>>>>>> Sorrowly, I get the following:
>>>>>>>
>>>>>>>> outfile <- "/my/path/"
>>>>>>>> dirname(outfile)
>>>>>>> [1] "/my"
>>>>>>>> basename(outfile)
>>>>>>> [1] "path"
>>>>>>>
>>>>>>> It would be great if dirname() and basename() could recognize:
>>>>>>> dirname("/my/path/")      = /my/path/
>>>>>>> basename(""/my/path/")  = ""
>>>>>>> i.e. they should be able to recognize a trailing "/".
>>>>>> Not according to the documentation.
>>>>>>
>>>>>>> Best regards
>>>>>>> Christian
>>>>>>> _._._._._._._._._._._._._._._._
>>>>>>> C.h.i.s.t.i.a.n S.t.r.a.t.o.w.a
>>>>>>> V.i.e.n.n.a       A.u.s.t.r.i.a
>>>>>>> _._._._._._._._._._._._._._._._
>>>>> ______________________________________________
>>>>> R-devel at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>
>>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>>
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From ripley at stats.ox.ac.uk  Wed Mar 28 00:45:13 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 27 Mar 2007 23:45:13 +0100 (BST)
Subject: [Rd] [R] Can I scale the labels in a 'persp' graph?
In-Reply-To: <4609886C.7020402@stat.auckland.ac.nz>
References: <mailman.11.1174042804.26780.r-help@stat.math.ethz.ch>
	<Pine.LNX.4.64.0703161252350.30144@obelix.umh.es>
	<45FA999D.1090406@stats.uwo.ca>
	<Pine.LNX.4.64.0703221909020.22676@gannet.stats.ox.ac.uk>
	<4609886C.7020402@stat.auckland.ac.nz>
Message-ID: <Pine.LNX.4.64.0703272341450.17069@gannet.stats.ox.ac.uk>

On Wed, 28 Mar 2007, Paul Murrell wrote:

> Hi
>
>
> Prof Brian Ripley wrote:
>> [Moved to R-devel to ask a policy question.]
>>
>> On Fri, 16 Mar 2007, Duncan Murdoch wrote:
>>
>>> On 3/16/2007 8:02 AM, salcaraz at obelix.umh.es wrote:
>>>> Hi all:
>>>>
>>>> I'm using 'persp' for 3D graphics.
>>>>
>>>> I need the axis's labels smaller than by defect.
>>>>
>>>> I see in 'help()', the information about 'par()'.
>>>>
>>>> I have wrote:
>>>>
>>>>> par(.....,cex.axis=0.5,cex.lab=0.5)
>>>> perspc(.................)
>>>>
>>>> and the result don't change.
>>>>
>>>> The question is: Can I change the size of labels in the perps graph??
>>>>
>>>> Thank you in advance:
>>>>
>>>> /salva
>>>>
>>>> 'cex.axis' The magnification to be used for axis annotation
>>>>            relative to the current setting of 'cex'. (Some functions
>>>>            such as 'points' accept a vector of values which are
>>>>            recycled.  Other uses will take just the first value if a
>>>>            vector of length greater than one is supplied.)
>>>>
>>>> 'cex.lab' The magnification to be used for x and y labels relative
>>>>            to the current setting of 'cex'.
>>> Those don't appear to be supported by persp, but cex is: e.g.
>>>
>>> x <- 1:10
>>> y <- 1:10
>>> z <- outer(x,y,function(x,y) sin((x+y)/10))
>>> persp(x,y,z, cex=0.5)
>>
>> I've added this to ?persp and ?par, but I wondered if people thought we
>> should change this to be like 2D plots.  Especially Ross I., who I believe
>> is the author here?
>
>
> I think Ross wrote the original.  I've hacked some of it a couple of
> times.  I have no problem with allowing par()s to work with persp(),
> though not everything makes sense (e.g., par("mar"), or par("mgp") where
> it gets tricky to get units right or units just do not make sense).
> There are also 2D-specific ones, like par("xaxt"), though in those cases
> one option might be to just offer an inline z-analogue in the arguments
> to persp() (?)

I was not proposing anything so radical, just that 'cex' (and perhaps 
'font') should perhaps work in the same way as 2D plots.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From p.murrell at auckland.ac.nz  Wed Mar 28 00:46:47 2007
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Wed, 28 Mar 2007 10:46:47 +1200
Subject: [Rd] [R] Can I scale the labels in a 'persp' graph?
In-Reply-To: <Pine.LNX.4.64.0703272341450.17069@gannet.stats.ox.ac.uk>
References: <mailman.11.1174042804.26780.r-help@stat.math.ethz.ch>
	<Pine.LNX.4.64.0703161252350.30144@obelix.umh.es>
	<45FA999D.1090406@stats.uwo.ca>
	<Pine.LNX.4.64.0703221909020.22676@gannet.stats.ox.ac.uk>
	<4609886C.7020402@stat.auckland.ac.nz>
	<Pine.LNX.4.64.0703272341450.17069@gannet.stats.ox.ac.uk>
Message-ID: <46099ED7.9060001@stat.auckland.ac.nz>

Hi


Prof Brian Ripley wrote:
> On Wed, 28 Mar 2007, Paul Murrell wrote:
> 
>> Hi
>>
>>
>> Prof Brian Ripley wrote:
>>> [Moved to R-devel to ask a policy question.]
>>>
>>> On Fri, 16 Mar 2007, Duncan Murdoch wrote:
>>>
>>>> On 3/16/2007 8:02 AM, salcaraz at obelix.umh.es wrote:
>>>>> Hi all:
>>>>>
>>>>> I'm using 'persp' for 3D graphics.
>>>>>
>>>>> I need the axis's labels smaller than by defect.
>>>>>
>>>>> I see in 'help()', the information about 'par()'.
>>>>>
>>>>> I have wrote:
>>>>>
>>>>>> par(.....,cex.axis=0.5,cex.lab=0.5)
>>>>> perspc(.................)
>>>>>
>>>>> and the result don't change.
>>>>>
>>>>> The question is: Can I change the size of labels in the perps graph??
>>>>>
>>>>> Thank you in advance:
>>>>>
>>>>> /salva
>>>>>
>>>>> 'cex.axis' The magnification to be used for axis annotation
>>>>>            relative to the current setting of 'cex'. (Some functions
>>>>>            such as 'points' accept a vector of values which are
>>>>>            recycled.  Other uses will take just the first value if a
>>>>>            vector of length greater than one is supplied.)
>>>>>
>>>>> 'cex.lab' The magnification to be used for x and y labels relative
>>>>>            to the current setting of 'cex'.
>>>> Those don't appear to be supported by persp, but cex is: e.g.
>>>>
>>>> x <- 1:10
>>>> y <- 1:10
>>>> z <- outer(x,y,function(x,y) sin((x+y)/10))
>>>> persp(x,y,z, cex=0.5)
>>> I've added this to ?persp and ?par, but I wondered if people thought we
>>> should change this to be like 2D plots.  Especially Ross I., who I believe
>>> is the author here?
>>
>> I think Ross wrote the original.  I've hacked some of it a couple of
>> times.  I have no problem with allowing par()s to work with persp(),
>> though not everything makes sense (e.g., par("mar"), or par("mgp") where
>> it gets tricky to get units right or units just do not make sense).
>> There are also 2D-specific ones, like par("xaxt"), though in those cases
>> one option might be to just offer an inline z-analogue in the arguments
>> to persp() (?)
> 
> I was not proposing anything so radical, just that 'cex' (and perhaps 
> 'font') should perhaps work in the same way as 2D plots.


Yep, sounds cool.

Paul
-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/


From edd at debian.org  Wed Mar 28 04:34:00 2007
From: edd at debian.org (Dirk Eddelbuettel)
Date: Tue, 27 Mar 2007 21:34:00 -0500
Subject: [Rd] Rmpi and OpenMPI ?
Message-ID: <17929.54296.884935.214790@basebud.nulle.part>


Has anybody tried to use Rmpi with the OpenMPI library instead of LAM/MPI?

LAM appears to be somewhat hardcoded in the Rmpi setup. Before I start to
experiment with changing this, has anybody else tried Rmpi with non-LAM MPI
implementations?

Dirk

-- 
Hell, there are no rules here - we're trying to accomplish something. 
                                                  -- Thomas A. Edison


From bcarvalh at jhsph.edu  Wed Mar 28 06:39:27 2007
From: bcarvalh at jhsph.edu (Benilton Carvalho)
Date: Wed, 28 Mar 2007 00:39:27 -0400
Subject: [Rd] accessing "hidden" functions
Message-ID: <5CA14556-E1F2-4B9D-A1EE-59818DA67FB9@jhsph.edu>

Hi,

(I tried looking for it, but I don't think it was discussed before...  
or maybe I didn't use the correct keywords).

I have a package (say, pkg1), which uses NAMESPACE. This package  
contains a bunch of functions the are used internally, therefore  
they're not exported (say, internalFunc1).

Even though internalFunc1 is not exported, I can access it externally  
using pkg1:::internalFunc1 (yes, I do understand this is not supposed  
to be done).

Okay... now I have a second internal function, which starts with a  
dot (eg, ".internalFunc2").

Is there a way of accessing it without exporting it (or exposing it  
by removing the "dot")? ie, something like pkg1:::.internalFunc2 ?

thanks a lot,

beniton


From ripley at stats.ox.ac.uk  Wed Mar 28 09:00:16 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 28 Mar 2007 08:00:16 +0100 (BST)
Subject: [Rd] accessing "hidden" functions
In-Reply-To: <5CA14556-E1F2-4B9D-A1EE-59818DA67FB9@jhsph.edu>
References: <5CA14556-E1F2-4B9D-A1EE-59818DA67FB9@jhsph.edu>
Message-ID: <Pine.LNX.4.64.0703280758160.2363@gannet.stats.ox.ac.uk>

On Wed, 28 Mar 2007, Benilton Carvalho wrote:

> Hi,
>
> (I tried looking for it, but I don't think it was discussed before...
> or maybe I didn't use the correct keywords).
>
> I have a package (say, pkg1), which uses NAMESPACE. This package
> contains a bunch of functions the are used internally, therefore
> they're not exported (say, internalFunc1).
>
> Even though internalFunc1 is not exported, I can access it externally
> using pkg1:::internalFunc1 (yes, I do understand this is not supposed
> to be done).
>
> Okay... now I have a second internal function, which starts with a
> dot (eg, ".internalFunc2").
>
> Is there a way of accessing it without exporting it (or exposing it
> by removing the "dot")? ie, something like pkg1:::.internalFunc2 ?

Yes.  Starting a name with a dot is merely a convention, and almost 
everything (including the ::: operator) treats all names the same.

You will see lots of examples in the tools package used by R CMD check.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From rdiaz at cnio.es  Wed Mar 28 10:21:43 2007
From: rdiaz at cnio.es (Ramon Diaz-Uriarte)
Date: Wed, 28 Mar 2007 10:21:43 +0200
Subject: [Rd] Rmpi and OpenMPI ?
In-Reply-To: <17929.54296.884935.214790@basebud.nulle.part>
References: <17929.54296.884935.214790@basebud.nulle.part>
Message-ID: <200703281021.43542.rdiaz@cnio.es>

Hi Dirk,

On Wednesday 28 March 2007 04:34, Dirk Eddelbuettel wrote:
> Has anybody tried to use Rmpi with the OpenMPI library instead of LAM/MPI?
>

I have not, but I'd be very interested in whatever you find. One thing that 
stopped me as soon as I considered it is that, if I understand correctly, 
there is (still) nothing in OpenMPI like the "lamboot" command of LAM/MPI 
(and that is a crucial part of our set up).

Best,

R.



> LAM appears to be somewhat hardcoded in the Rmpi setup. Before I start to
> experiment with changing this, has anybody else tried Rmpi with non-LAM MPI
> implementations?
>
> Dirk






-- 
Ram?n D?az-Uriarte
Statistical Computing Team
Centro Nacional de Investigaciones Oncol?gicas (CNIO)
(Spanish National Cancer Center)
Melchor Fern?ndez Almagro, 3
28029 Madrid (Spain)
Fax: +-34-91-224-6972
Phone: +-34-91-224-6900

http://ligarto.org/rdiaz
PGP KeyID: 0xE89B3462
(http://ligarto.org/rdiaz/0xE89B3462.asc)



**NOTA DE CONFIDENCIALIDAD** Este correo electr?nico, y en s...{{dropped}}


From hin-tak.leung at cimr.cam.ac.uk  Wed Mar 28 11:57:11 2007
From: hin-tak.leung at cimr.cam.ac.uk (Hin-Tak Leung)
Date: Wed, 28 Mar 2007 10:57:11 +0100
Subject: [Rd] Bridging R to OpenOffice
In-Reply-To: <4609655A.5070209@gmx.net>
References: <4609655A.5070209@gmx.net>
Message-ID: <460A3BF7.8010605@cimr.cam.ac.uk>

Hmm, if all you are interested is reading/writing Excel spreadsheets
from R, there are much lighter and easier ways of doing it, than
hooking up with openoffice. The Perl people have had
Spreadsheet::ParseExcel and Spreadsheet::WriteExcel for years (and
they work quite well, personal experience). Those are tiny
(a couple of Mb's?) compared to the size of openoffice.

HTL

Leonard Mada wrote:
> Dear members of the R Development Team,
> 
> I am looking for people with a deep understanding of R internals to 
> assist in bridging R to OpenOffice.
> 
> While R is a state of the art statistical environment, less experienced 
> users often find it difficult to work with R. Therefore, I believe that 
> a bridge between R and a spreadsheet program will make this transition 
> less painful. I sincerely believe that this will benefit both the R 
> community as well as the potential new users.
> 
> OpenOffice is an open-source office suite that includes a spreadsheet 
> program (Calc).
> 
> OpenOffice.org (OOo) is participating in the Google Summer of Code 2007 
> initiative sponsored by Google and one of the proposed projects involves 
> the creation of an add-on component that allows an OOo Calc user to let 
> the R environment do calculations on data from Calc cells and put the 
> results into the spreadsheet again. A brief description can be found on 
> the OOo Summer of Code wiki page 
> (http://wiki.services.openoffice.org/wiki/Summer_of_Code_2007).
> 
> Two students have already shown interest in this project (see the OOo 
> mailing list, 
> http://sc.openoffice.org/servlets/BrowseList?listName=dev&from=2007-03-01&to=2007-03-31&by=date&first=21&selectedPage=2, 
> the "Summer of Code: R and Calc" thread).
> 
> While mentoring is already available from a member of the OpenOffice 
> team (I will try to offer a helping hand on statistics and R-syntax, but 
> NOT the coding part itself), I feel that we still need someone with 
> R-core expertise. I am aware of various existing packages (rcom, RDCOM) 
> and the availability of various online-informations (like 
> http://developer.r-project.org/embedded.html), however more specific 
> questions may arise in the future, especially as this embedding should 
> be platform-independent, and I would welcome any help from the R-core 
> team members.
> 
> I am looking forward to hear from you and hope that this project will be 
> a great success. I would like to thank you in advance for your effort.
> 
> Sincerely,
> 
> Leonard Mada
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From tuechler at gmx.at  Wed Mar 28 13:16:49 2007
From: tuechler at gmx.at (Heinz Tuechler)
Date: Wed, 28 Mar 2007 12:16:49 +0100
Subject: [Rd] Unexpected result of as.character() and unlist() appliedto
 a data frame
In-Reply-To: <17929.14181.944972.334471@stat.math.ethz.ch>
References: <1174967313.460894116113f@webmail.fhcrc.org>
	<1174967313.460894116113f@webmail.fhcrc.org>
Message-ID: <3.0.6.32.20070328121649.00b11450@pop.gmx.net>

At 17:25 27.03.2007 +0200, Martin Maechler wrote:
>>>>>> "Herve" == Herve Pages <hpages at fhcrc.org>
>>>>>>     on Mon, 26 Mar 2007 20:48:33 -0700 writes:
>
>    Herve> Hi,
>    >> dd <- data.frame(A=c("b","c","a"), B=3:1) dd
>    Herve>   A B 1 b 3 2 c 2 3 a 1
>    >> unlist(dd)
>    Herve> A1 A2 A3 B1 B2 B3 2 3 1 3 2 1
>
>    Herve> Someone else might get something different. It all
>    Herve> depends on the values of its 'stringsAsFactors'  option:
>
>yes, and I don't like that (last) fact either.
>IMO, an option should never be allowed to influence such a basic
>function as  data.frame().
>
>I know I would have had time earlier to start discussing this,
>but for some (probably good) reasons, I didn't get to it at the
>time. 
>As Andy comments, everything is behaving as it should / is documented,
>including the  'stringsAsFactors' option;
>but personally, I really would want to consider changing
>the default for  data.frame()s stringAsFactors back (as
>pre-R-2.4.0) to 'TRUE' instead of  default.stringsAsFactors()
>which is a smart version of getOption("stringsAsFactors"). 
>I find it ok ("acceptable") if its influencing  read.table()
>but feel differently for data.frame().
>
>Martin
>
Martin!

I see the problem with options influencing "such a basic function as
data.frame().", but in my view the difficulty starts earlier. In my
understanding data.frame() is _the_ basic way to store empirical source
data in R and I found the earlier default behaviour, to change character
variables to factors, problematic.
If changing character variables to factors were only an internal process,
not visible to the user, I would not mind, but to include a character
variable in a data frame and get a factor out of it, is somewhat disturbing.
A naive user like me was especially confused by the fact that I could read
an SPSS file with spss.get (default: charfactor=FALSE) and get a character
variable in a data.frame as a character variable but then putting it in a
different data.frame it changed to factor.
I would wish a data.frame() function that behaves as a "data container"
with the idea of rows(=cases) and columns(=variables) but without changing
the mode/class of the objects.

Heinz

>
>
>
>
>    >> dd2 <- data.frame(A=c("b","c","a"), B=3:1,
>    >>                   stringsAsFactors=FALSE)
>    >> dd2
>    Herve>   A B 1 b 3 2 c 2 3 a 1
>    >> unlist(dd2)
>    Herve>  A1 A2 A3 B1 B2 B3 "b" "c" "a" "3" "2" "1"
>
>    Herve> Same thing with as.character:
>
>    >> as.character(dd)
>    Herve> [1] "c(2, 3, 1)" "c(3, 2, 1)"
>    >> as.character(dd2)
>    Herve> [1] "c(\"b\", \"c\", \"a\")" "c(3, 2, 1)"
>
>    Herve> Bug or "feature"?
>
>    Herve> Note that as.character applied directly on dd$A
>    Herve> doesn't have this "feature":
>
>    >> as.character(dd$A)
>    Herve> [1] "b" "c" "a"
>    >> as.character(dd2$A)
>    Herve> [1] "b" "c" "a"
>
>    Herve> Cheers, H.
>
>    Herve> ______________________________________________
>    Herve> R-devel at r-project.org mailing list
>    Herve> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>______________________________________________
>R-devel at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-devel
>


From Roger.Bivand at nhh.no  Wed Mar 28 12:25:03 2007
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 28 Mar 2007 12:25:03 +0200 (CEST)
Subject: [Rd] Bridging R to OpenOffice
In-Reply-To: <460A3BF7.8010605@cimr.cam.ac.uk>
Message-ID: <Pine.LNX.4.44.0703281210390.31714-100000@reclus.nhh.no>

On Wed, 28 Mar 2007, Hin-Tak Leung wrote:

> Hmm, if all you are interested is reading/writing Excel spreadsheets
> from R, there are much lighter and easier ways of doing it, than
> hooking up with openoffice. The Perl people have had
> Spreadsheet::ParseExcel and Spreadsheet::WriteExcel for years (and
> they work quite well, personal experience). Those are tiny
> (a couple of Mb's?) compared to the size of openoffice.

I don't think this is the problem here - the proposal says: "Create an
add-on component that allows a Calc user to let the R environment do
calculations on data from Calc cells and put the results into the
spreadsheet again". It feels much more like embedding R in the OO
spreadsheet and/or elsewhere, which would be similar to using DCOM in
Excel. There would also be questions about how tightly integrated an
embedded R should be, how functionality would be provided and documented,
and how such a setup ought to be administered and maintained.

As RExcel, the structure depends crucially on having joint expertise in
place to write and maintain the R script glue (dialogues) to provide the
functionality being added to Calc. Typically, this would be something an
organisation of some size might need, but it would be unlikely to be a GUI
for novice R users unwilling to scale the learning curve (a steep learning
curve, of course, means learn a lot in a short time, hence a good thing!).

Roger

> 
> HTL
> 
> Leonard Mada wrote:
> > Dear members of the R Development Team,
> > 
> > I am looking for people with a deep understanding of R internals to 
> > assist in bridging R to OpenOffice.
> > 
> > While R is a state of the art statistical environment, less experienced 
> > users often find it difficult to work with R. Therefore, I believe that 
> > a bridge between R and a spreadsheet program will make this transition 
> > less painful. I sincerely believe that this will benefit both the R 
> > community as well as the potential new users.
> > 
> > OpenOffice is an open-source office suite that includes a spreadsheet 
> > program (Calc).
> > 
> > OpenOffice.org (OOo) is participating in the Google Summer of Code 2007 
> > initiative sponsored by Google and one of the proposed projects involves 
> > the creation of an add-on component that allows an OOo Calc user to let 
> > the R environment do calculations on data from Calc cells and put the 
> > results into the spreadsheet again. A brief description can be found on 
> > the OOo Summer of Code wiki page 
> > (http://wiki.services.openoffice.org/wiki/Summer_of_Code_2007).
> > 
> > Two students have already shown interest in this project (see the OOo 
> > mailing list, 
> > http://sc.openoffice.org/servlets/BrowseList?listName=dev&from=2007-03-01&to=2007-03-31&by=date&first=21&selectedPage=2, 
> > the "Summer of Code: R and Calc" thread).
> > 
> > While mentoring is already available from a member of the OpenOffice 
> > team (I will try to offer a helping hand on statistics and R-syntax, but 
> > NOT the coding part itself), I feel that we still need someone with 
> > R-core expertise. I am aware of various existing packages (rcom, RDCOM) 
> > and the availability of various online-informations (like 
> > http://developer.r-project.org/embedded.html), however more specific 
> > questions may arise in the future, especially as this embedding should 
> > be platform-independent, and I would welcome any help from the R-core 
> > team members.
> > 
> > I am looking forward to hear from you and hope that this project will be 
> > a great success. I would like to thank you in advance for your effort.
> > 
> > Sincerely,
> > 
> > Leonard Mada
> > 
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From sdavis2 at mail.nih.gov  Wed Mar 28 12:48:53 2007
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Wed, 28 Mar 2007 06:48:53 -0400
Subject: [Rd] Bridging R to OpenOffice
In-Reply-To: <Pine.LNX.4.44.0703281210390.31714-100000@reclus.nhh.no>
References: <Pine.LNX.4.44.0703281210390.31714-100000@reclus.nhh.no>
Message-ID: <200703280648.54111.sdavis2@mail.nih.gov>

On Wednesday 28 March 2007 06:25, Roger Bivand wrote:
> On Wed, 28 Mar 2007, Hin-Tak Leung wrote:
> > Hmm, if all you are interested is reading/writing Excel spreadsheets
> > from R, there are much lighter and easier ways of doing it, than
> > hooking up with openoffice. The Perl people have had
> > Spreadsheet::ParseExcel and Spreadsheet::WriteExcel for years (and
> > they work quite well, personal experience). Those are tiny
> > (a couple of Mb's?) compared to the size of openoffice.
>
> I don't think this is the problem here - the proposal says: "Create an
> add-on component that allows a Calc user to let the R environment do
> calculations on data from Calc cells and put the results into the
> spreadsheet again". It feels much more like embedding R in the OO
> spreadsheet and/or elsewhere, which would be similar to using DCOM in
> Excel. There would also be questions about how tightly integrated an
> embedded R should be, how functionality would be provided and documented,
> and how such a setup ought to be administered and maintained.
>
> As RExcel, the structure depends crucially on having joint expertise in
> place to write and maintain the R script glue (dialogues) to provide the
> functionality being added to Calc. Typically, this would be something an
> organisation of some size might need, but it would be unlikely to be a GUI
> for novice R users unwilling to scale the learning curve (a steep learning
> curve, of course, means learn a lot in a short time, hence a good thing!).

There are examples of doing this with Excel, which have been quite successful.  
Here is at least one example (which I post for potential contact 
information):

http://linus.nci.nih.gov/BRB-ArrayTools.html

Sean


From murdoch at stats.uwo.ca  Wed Mar 28 14:51:00 2007
From: murdoch at stats.uwo.ca (murdoch at stats.uwo.ca)
Date: Wed, 28 Mar 2007 14:51:00 +0200 (CEST)
Subject: [Rd] Fwd: Re: documentation clarifications (PR#9586)
Message-ID: <20070328125100.32B4D5DCFC@slim.kubism.ku.dk>

On 3/27/2007 11:36 PM, Richard M. Heiberger wrote:
> I verified that this is a difference in behavior in both the released 2.4.1 for Windows
> and the "2.5.0 Under development (unstable) (2007-02-10 r40690)" for Windows.
> In htmlhelp, the word "interaction" is clickable and goes to the interaction{lattice}
> page.  In chmhelp, the word "interaction" is not clickable.

Thanks for the report.  That does look like a bug; I'll see if I can 
track it down before 2.5.0.  The "interaction" link is coded as
\link[lattice:interaction]{interaction} and apparently that kind of link 
is not currently working in CHTML files.

Duncan Murdoch

> 
> Rich
> 
> ---- Original message ----
>>Date: Tue, 27 Mar 2007 19:54:32 -0700
>>From: "Deepayan Sarkar" <deepayan.sarkar at gmail.com>  
>>Subject: Re: documentation clarifications  
>>To: "Richard M. Heiberger" <rmh at temple.edu>
>>
>>On 3/3/07, Richard M. Heiberger <rmh at temple.edu> wrote:
>>> Eventually I found this line in the ?Lattice page:
>>>   Tools to augment lattice plots after they are drawn (including
>>>   locator-like functionality) is described in the interaction help page.
>>>
>>> "interaction" was not highlighted and therefore not clickable.
>>> ?interaction
>>> goes to interaction(base) which is a totally different capability.
>>
>>That would be a bug in whatever interface you are using. "interaction"
>>should be a link pointing to lattice:interaction, and that works in an
>>HTML interface.
>>


From sz at sun.com  Wed Mar 28 15:20:09 2007
From: sz at sun.com (Stefan Zimmermann)
Date: Wed, 28 Mar 2007 15:20:09 +0200
Subject: [Rd] Bridging R to OpenOffice
In-Reply-To: <200703280648.54111.sdavis2@mail.nih.gov>
References: <Pine.LNX.4.44.0703281210390.31714-100000@reclus.nhh.no>
	<200703280648.54111.sdavis2@mail.nih.gov>
Message-ID: <460A6B89.8030903@sun.com>

Still didn't get the point, or missed the topic ?
It's OpenOffice.org and R not Excel and R, two totally different 
products at least from a philosophical standpoint. Not everybody is 
willing to pay license fee for Excel to be able to use R via a GUI.
That's how the idea was born to integrate or bridge R with 
OpenOffice.org Calc
Access statistical data analysis functionality computed by the almighty 
R engine from menues in Calc, and getting the results back in Calc (more 
for users than for developers). A plugin could do the job.
There is no point in saying "there is something in Excel" like there is 
none in saying "Why not using "S" ?
You may want to follow the link, offered by Leonard, to the "Google 
Summer of Code"-project which is menthored by Sun Microsystems 
(Star/OpenOffice developers), to get a clearer picture about it.
http://wiki.services.openoffice.org/wiki/Summer_of_Code_2007#Integration_of_R_into_Calc

best regards
Stefan


Sean Davis said the following on 28.03.2007 12:48:
> On Wednesday 28 March 2007 06:25, Roger Bivand wrote:
>   
>> On Wed, 28 Mar 2007, Hin-Tak Leung wrote:
>>     
>>> Hmm, if all you are interested is reading/writing Excel spreadsheets
>>> from R, there are much lighter and easier ways of doing it, than
>>> hooking up with openoffice. The Perl people have had
>>> Spreadsheet::ParseExcel and Spreadsheet::WriteExcel for years (and
>>> they work quite well, personal experience). Those are tiny
>>> (a couple of Mb's?) compared to the size of openoffice.
>>>       
>> I don't think this is the problem here - the proposal says: "Create an
>> add-on component that allows a Calc user to let the R environment do
>> calculations on data from Calc cells and put the results into the
>> spreadsheet again". It feels much more like embedding R in the OO
>> spreadsheet and/or elsewhere, which would be similar to using DCOM in
>> Excel. There would also be questions about how tightly integrated an
>> embedded R should be, how functionality would be provided and documented,
>> and how such a setup ought to be administered and maintained.
>>
>> As RExcel, the structure depends crucially on having joint expertise in
>> place to write and maintain the R script glue (dialogues) to provide the
>> functionality being added to Calc. Typically, this would be something an
>> organisation of some size might need, but it would be unlikely to be a GUI
>> for novice R users unwilling to scale the learning curve (a steep learning
>> curve, of course, means learn a lot in a short time, hence a good thing!).
>>     
>
> There are examples of doing this with Excel, which have been quite successful.  
> Here is at least one example (which I post for potential contact 
> information):
>
> http://linus.nci.nih.gov/BRB-ArrayTools.html
>
> Sean
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>   

-- 
"Just because the message may never be received does not mean it is not 
worth sending." 
******************************************************************* 
Stefan Zimmermann Tel/Fax: +49 40 23646 - 645/950 Six Sigma Black Belt, 
StarOffice mailto:sz at sun.com Sun Microsystems GmbH 
http://www.sun.com/staroffice Nagelsweg 55, D-20097 Hamburg mobile: +49 
172 87 57 504 
******************************************************************* Sitz 
der Gesellschaft: Sun Microsystems GmbH, Sonnenallee 1, D-85551 
Kirchheim-Heimstetten Amtsgericht Muenchen: HRB 161028 
Geschaeftsfuehrer: Marcel Schneider, Wolfgang Engels, Dr. Roland Boemer 
Vorsitzender des Aufsichtsrates: Martin Haering


From sdavis2 at mail.nih.gov  Wed Mar 28 15:33:45 2007
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Wed, 28 Mar 2007 09:33:45 -0400
Subject: [Rd] Bridging R to OpenOffice
In-Reply-To: <460A6B89.8030903@sun.com>
References: <Pine.LNX.4.44.0703281210390.31714-100000@reclus.nhh.no>
	<200703280648.54111.sdavis2@mail.nih.gov>
	<460A6B89.8030903@sun.com>
Message-ID: <200703280933.45736.sdavis2@mail.nih.gov>

On Wednesday 28 March 2007 09:20, Stefan Zimmermann wrote:
> Still didn't get the point, or missed the topic ?

I had gotten the point, yes--just trying to be helpful.  I'm sorry it wasn't 
taken as such. 

Sean


> It's OpenOffice.org and R not Excel and R, two totally different
> products at least from a philosophical standpoint. Not everybody is
> willing to pay license fee for Excel to be able to use R via a GUI.
> That's how the idea was born to integrate or bridge R with
> OpenOffice.org Calc
> Access statistical data analysis functionality computed by the almighty
> R engine from menues in Calc, and getting the results back in Calc (more
> for users than for developers). A plugin could do the job.
> There is no point in saying "there is something in Excel" like there is
> none in saying "Why not using "S" ?
> You may want to follow the link, offered by Leonard, to the "Google
> Summer of Code"-project which is menthored by Sun Microsystems
> (Star/OpenOffice developers), to get a clearer picture about it.
> http://wiki.services.openoffice.org/wiki/Summer_of_Code_2007#Integration_of
>_R_into_Calc
>
> best regards
> Stefan
>
> Sean Davis said the following on 28.03.2007 12:48:
> > On Wednesday 28 March 2007 06:25, Roger Bivand wrote:
> >> On Wed, 28 Mar 2007, Hin-Tak Leung wrote:
> >>> Hmm, if all you are interested is reading/writing Excel spreadsheets
> >>> from R, there are much lighter and easier ways of doing it, than
> >>> hooking up with openoffice. The Perl people have had
> >>> Spreadsheet::ParseExcel and Spreadsheet::WriteExcel for years (and
> >>> they work quite well, personal experience). Those are tiny
> >>> (a couple of Mb's?) compared to the size of openoffice.
> >>
> >> I don't think this is the problem here - the proposal says: "Create an
> >> add-on component that allows a Calc user to let the R environment do
> >> calculations on data from Calc cells and put the results into the
> >> spreadsheet again". It feels much more like embedding R in the OO
> >> spreadsheet and/or elsewhere, which would be similar to using DCOM in
> >> Excel. There would also be questions about how tightly integrated an
> >> embedded R should be, how functionality would be provided and
> >> documented, and how such a setup ought to be administered and
> >> maintained.
> >>
> >> As RExcel, the structure depends crucially on having joint expertise in
> >> place to write and maintain the R script glue (dialogues) to provide the
> >> functionality being added to Calc. Typically, this would be something an
> >> organisation of some size might need, but it would be unlikely to be a
> >> GUI for novice R users unwilling to scale the learning curve (a steep
> >> learning curve, of course, means learn a lot in a short time, hence a
> >> good thing!).
> >
> > There are examples of doing this with Excel, which have been quite
> > successful. Here is at least one example (which I post for potential
> > contact information):
> >
> > http://linus.nci.nih.gov/BRB-ArrayTools.html
> >
> > Sean
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel


From ripley at stats.ox.ac.uk  Wed Mar 28 15:58:44 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 28 Mar 2007 14:58:44 +0100 (BST)
Subject: [Rd] Bridging R to OpenOffice
In-Reply-To: <Pine.LNX.4.44.0703281210390.31714-100000@reclus.nhh.no>
References: <Pine.LNX.4.44.0703281210390.31714-100000@reclus.nhh.no>
Message-ID: <Pine.LNX.4.64.0703281435460.17699@gannet.stats.ox.ac.uk>

I beieve Leonard Mada intended to contact R-core, from his penultimate 
para (our address is R-core at r-project.org).  I only see any point in 
discussing this on R-devel if some non-R-core-developer wishes to 
volunteer to help -- otherwise R-core will discuss this.


On Wed, 28 Mar 2007, Roger Bivand wrote:

> On Wed, 28 Mar 2007, Hin-Tak Leung wrote:
>
>> Hmm, if all you are interested is reading/writing Excel spreadsheets
>> from R, there are much lighter and easier ways of doing it, than
>> hooking up with openoffice. The Perl people have had
>> Spreadsheet::ParseExcel and Spreadsheet::WriteExcel for years (and
>> they work quite well, personal experience). Those are tiny
>> (a couple of Mb's?) compared to the size of openoffice.
>
> I don't think this is the problem here - the proposal says: "Create an
> add-on component that allows a Calc user to let the R environment do
> calculations on data from Calc cells and put the results into the
> spreadsheet again". It feels much more like embedding R in the OO
> spreadsheet and/or elsewhere, which would be similar to using DCOM in
> Excel. There would also be questions about how tightly integrated an
> embedded R should be, how functionality would be provided and documented,
> and how such a setup ought to be administered and maintained.
>
> As RExcel, the structure depends crucially on having joint expertise in
> place to write and maintain the R script glue (dialogues) to provide the
> functionality being added to Calc. Typically, this would be something an
> organisation of some size might need, but it would be unlikely to be a GUI
> for novice R users unwilling to scale the learning curve (a steep learning
> curve, of course, means learn a lot in a short time, hence a good thing!).
>
> Roger
>
>>
>> HTL
>>
>> Leonard Mada wrote:
>>> Dear members of the R Development Team,
>>>
>>> I am looking for people with a deep understanding of R internals to
>>> assist in bridging R to OpenOffice.
>>>
>>> While R is a state of the art statistical environment, less experienced
>>> users often find it difficult to work with R. Therefore, I believe that
>>> a bridge between R and a spreadsheet program will make this transition
>>> less painful. I sincerely believe that this will benefit both the R
>>> community as well as the potential new users.
>>>
>>> OpenOffice is an open-source office suite that includes a spreadsheet
>>> program (Calc).
>>>
>>> OpenOffice.org (OOo) is participating in the Google Summer of Code 2007
>>> initiative sponsored by Google and one of the proposed projects involves
>>> the creation of an add-on component that allows an OOo Calc user to let
>>> the R environment do calculations on data from Calc cells and put the
>>> results into the spreadsheet again. A brief description can be found on
>>> the OOo Summer of Code wiki page
>>> (http://wiki.services.openoffice.org/wiki/Summer_of_Code_2007).
>>>
>>> Two students have already shown interest in this project (see the OOo
>>> mailing list,
>>> http://sc.openoffice.org/servlets/BrowseList?listName=dev&from=2007-03-01&to=2007-03-31&by=date&first=21&selectedPage=2,
>>> the "Summer of Code: R and Calc" thread).
>>>
>>> While mentoring is already available from a member of the OpenOffice
>>> team (I will try to offer a helping hand on statistics and R-syntax, but
>>> NOT the coding part itself), I feel that we still need someone with
>>> R-core expertise. I am aware of various existing packages (rcom, RDCOM)
>>> and the availability of various online-informations (like
>>> http://developer.r-project.org/embedded.html), however more specific
>>> questions may arise in the future, especially as this embedding should
>>> be platform-independent, and I would welcome any help from the R-core
>>> team members.
>>>
>>> I am looking forward to hear from you and hope that this project will be
>>> a great success. I would like to thank you in advance for your effort.
>>>
>>> Sincerely,
>>>
>>> Leonard Mada
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Wed Mar 28 16:04:01 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 28 Mar 2007 15:04:01 +0100 (BST)
Subject: [Rd] Server transitions
Message-ID: <Pine.LNX.4.64.0703281459100.17699@gannet.stats.ox.ac.uk>

Later today the servers

www.stats.ox.ac.uk
ftp.stats.ox.ac.uk

used by tests/internet.R (and also for Windows package downloads) will 
transition to new hardware (on new IP addresses).  This may make access 
unstable until the DNS changes propagate through and web caches get 
flushed, so please do not be alarmed if some of those tests fail 
occasionally.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From P.Dalgaard at biostat.ku.dk  Wed Mar 28 17:25:38 2007
From: P.Dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Wed, 28 Mar 2007 17:25:38 +0200
Subject: [Rd] Bridging R to OpenOffice
In-Reply-To: <200703280648.54111.sdavis2@mail.nih.gov>
References: <Pine.LNX.4.44.0703281210390.31714-100000@reclus.nhh.no>
	<200703280648.54111.sdavis2@mail.nih.gov>
Message-ID: <460A88F2.3080600@biostat.ku.dk>

Sean Davis wrote:
> On Wednesday 28 March 2007 06:25, Roger Bivand wrote:
>   
>> On Wed, 28 Mar 2007, Hin-Tak Leung wrote:
>>     
>>> Hmm, if all you are interested is reading/writing Excel spreadsheets
>>> from R, there are much lighter and easier ways of doing it, than
>>> hooking up with openoffice. The Perl people have had
>>> Spreadsheet::ParseExcel and Spreadsheet::WriteExcel for years (and
>>> they work quite well, personal experience). Those are tiny
>>> (a couple of Mb's?) compared to the size of openoffice.
>>>       
>> I don't think this is the problem here - the proposal says: "Create an
>> add-on component that allows a Calc user to let the R environment do
>> calculations on data from Calc cells and put the results into the
>> spreadsheet again". It feels much more like embedding R in the OO
>> spreadsheet and/or elsewhere, which would be similar to using DCOM in
>> Excel. There would also be questions about how tightly integrated an
>> embedded R should be, how functionality would be provided and documented,
>> and how such a setup ought to be administered and maintained.
>>
>> As RExcel, the structure depends crucially on having joint expertise in
>> place to write and maintain the R script glue (dialogues) to provide the
>> functionality being added to Calc. Typically, this would be something an
>> organisation of some size might need, but it would be unlikely to be a GUI
>> for novice R users unwilling to scale the learning curve (a steep learning
>> curve, of course, means learn a lot in a short time, hence a good thing!).
>>     
>
> There are examples of doing this with Excel, which have been quite successful.  
> Here is at least one example (which I post for potential contact 
> information):
>
> http://linus.nci.nih.gov/BRB-ArrayTools.html
>   
I feel (without much hard evidence to build the feeling on...) that the
main issue is that OOo isn't making it really clear what the preferred
embedding/interfacing methods should be. I did look into the related
issue of database connectivity at some point; toying with the idea of
using oobase or oocalc as a backend for RODBC, but apparently no  ODBC
interface exists. (The other way around is possible: using oobase as a
front end for e.g. mysql via ODBC).

The Windows tools have (D)COM for interfacing to an R server process,
and the corresponding OOo interface is something called UNO, but
step-by-step instructions for using it appear to be hard to come by.

One possible starting point could be to look at the existing language
bindings and see whether they inspire a similar set of R bindings. There
is some experience around with interfacing issues: RSPerl, RPy, RGtk,
the tcltk package, etc. It tends to get somewhat tricky because R's
object model differs from that of OO languages like Java and C++, and is
closer to Lisp's CLOS. Also, if R's property of being a rapid
prototyping language is to be preserved, it is unattractive to blindly
wrap C libraries containing functions of 27 arguments each...

Digging around, I notice that there is an existing "tcluno" package.
This might be made accessible from R's tcltk package.

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From P.Dalgaard at biostat.ku.dk  Wed Mar 28 17:40:39 2007
From: P.Dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Wed, 28 Mar 2007 17:40:39 +0200
Subject: [Rd] Bridging R to OpenOffice
In-Reply-To: <200703280933.45736.sdavis2@mail.nih.gov>
References: <Pine.LNX.4.44.0703281210390.31714-100000@reclus.nhh.no>	<200703280648.54111.sdavis2@mail.nih.gov>	<460A6B89.8030903@sun.com>
	<200703280933.45736.sdavis2@mail.nih.gov>
Message-ID: <460A8C77.2040009@biostat.ku.dk>

Sean Davis wrote:
> On Wednesday 28 March 2007 09:20, Stefan Zimmermann wrote:
>   
>> Still didn't get the point, or missed the topic ?
>>     
>
> I had gotten the point, yes--just trying to be helpful.  I'm sorry it wasn't 
> taken as such. 
>
>   
Your reply was largely to the point. Excel and Calc are architecturally
different, but present a similar user interface. Knowing what can be
done with Excel is useful for pointing out directions in which you might
want to go with Calc. Given that the original poster pointed to R's
COM/DCOM interfaces, he probably knows all about this already, though.
> Sean
>
>
>   
>> It's OpenOffice.org and R not Excel and R, two totally different
>> products at least from a philosophical standpoint. Not everybody is
>> willing to pay license fee for Excel to be able to use R via a GUI.
>> That's how the idea was born to integrate or bridge R with
>> OpenOffice.org Calc
>> Access statistical data analysis functionality computed by the almighty
>> R engine from menues in Calc, and getting the results back in Calc (more
>> for users than for developers). A plugin could do the job.
>> There is no point in saying "there is something in Excel" like there is
>> none in saying "Why not using "S" ?
>> You may want to follow the link, offered by Leonard, to the "Google
>> Summer of Code"-project which is menthored by Sun Microsystems
>> (Star/OpenOffice developers), to get a clearer picture about it.
>> http://wiki.services.openoffice.org/wiki/Summer_of_Code_2007#Integration_of
>> _R_into_Calc
>>
>> best regards
>> Stefan
>>
>> Sean Davis said the following on 28.03.2007 12:48:
>>     
>>> On Wednesday 28 March 2007 06:25, Roger Bivand wrote:
>>>       
>>>> On Wed, 28 Mar 2007, Hin-Tak Leung wrote:
>>>>         
>>>>> Hmm, if all you are interested is reading/writing Excel spreadsheets
>>>>> from R, there are much lighter and easier ways of doing it, than
>>>>> hooking up with openoffice. The Perl people have had
>>>>> Spreadsheet::ParseExcel and Spreadsheet::WriteExcel for years (and
>>>>> they work quite well, personal experience). Those are tiny
>>>>> (a couple of Mb's?) compared to the size of openoffice.
>>>>>           
>>>> I don't think this is the problem here - the proposal says: "Create an
>>>> add-on component that allows a Calc user to let the R environment do
>>>> calculations on data from Calc cells and put the results into the
>>>> spreadsheet again". It feels much more like embedding R in the OO
>>>> spreadsheet and/or elsewhere, which would be similar to using DCOM in
>>>> Excel. There would also be questions about how tightly integrated an
>>>> embedded R should be, how functionality would be provided and
>>>> documented, and how such a setup ought to be administered and
>>>> maintained.
>>>>
>>>> As RExcel, the structure depends crucially on having joint expertise in
>>>> place to write and maintain the R script glue (dialogues) to provide the
>>>> functionality being added to Calc. Typically, this would be something an
>>>> organisation of some size might need, but it would be unlikely to be a
>>>> GUI for novice R users unwilling to scale the learning curve (a steep
>>>> learning curve, of course, means learn a lot in a short time, hence a
>>>> good thing!).
>>>>         
>>> There are examples of doing this with Excel, which have been quite
>>> successful. Here is at least one example (which I post for potential
>>> contact information):
>>>
>>> http://linus.nci.nih.gov/BRB-ArrayTools.html
>>>
>>> Sean
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>       
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>   


-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From marc_schwartz at comcast.net  Wed Mar 28 17:43:22 2007
From: marc_schwartz at comcast.net (Marc Schwartz)
Date: Wed, 28 Mar 2007 10:43:22 -0500
Subject: [Rd] Bridging R to OpenOffice
In-Reply-To: <460A88F2.3080600@biostat.ku.dk>
References: <Pine.LNX.4.44.0703281210390.31714-100000@reclus.nhh.no>
	<200703280648.54111.sdavis2@mail.nih.gov>
	<460A88F2.3080600@biostat.ku.dk>
Message-ID: <1175096603.14657.43.camel@Bellerophon>

On Wed, 2007-03-28 at 17:25 +0200, Peter Dalgaard wrote:
> Sean Davis wrote:
> > On Wednesday 28 March 2007 06:25, Roger Bivand wrote:
> >   
> >> On Wed, 28 Mar 2007, Hin-Tak Leung wrote:
> >>     
> >>> Hmm, if all you are interested is reading/writing Excel spreadsheets
> >>> from R, there are much lighter and easier ways of doing it, than
> >>> hooking up with openoffice. The Perl people have had
> >>> Spreadsheet::ParseExcel and Spreadsheet::WriteExcel for years (and
> >>> they work quite well, personal experience). Those are tiny
> >>> (a couple of Mb's?) compared to the size of openoffice.
> >>>       
> >> I don't think this is the problem here - the proposal says: "Create an
> >> add-on component that allows a Calc user to let the R environment do
> >> calculations on data from Calc cells and put the results into the
> >> spreadsheet again". It feels much more like embedding R in the OO
> >> spreadsheet and/or elsewhere, which would be similar to using DCOM in
> >> Excel. There would also be questions about how tightly integrated an
> >> embedded R should be, how functionality would be provided and documented,
> >> and how such a setup ought to be administered and maintained.
> >>
> >> As RExcel, the structure depends crucially on having joint expertise in
> >> place to write and maintain the R script glue (dialogues) to provide the
> >> functionality being added to Calc. Typically, this would be something an
> >> organisation of some size might need, but it would be unlikely to be a GUI
> >> for novice R users unwilling to scale the learning curve (a steep learning
> >> curve, of course, means learn a lot in a short time, hence a good thing!).
> >>     
> >
> > There are examples of doing this with Excel, which have been quite successful.  
> > Here is at least one example (which I post for potential contact 
> > information):
> >
> > http://linus.nci.nih.gov/BRB-ArrayTools.html
> >   
> I feel (without much hard evidence to build the feeling on...) that the
> main issue is that OOo isn't making it really clear what the preferred
> embedding/interfacing methods should be. I did look into the related
> issue of database connectivity at some point; toying with the idea of
> using oobase or oocalc as a backend for RODBC, but apparently no  ODBC
> interface exists. (The other way around is possible: using oobase as a
> front end for e.g. mysql via ODBC).

OO.org's Base is an embedded HSQLDB java based database application
(http://hsqldb.org/). 

To my knowledge it does not support ODBC, but at least in the
'non-embedded' versions, there is a JDBC interface available.

This issue comes up periodically on the OO.org lists, which I tend to
peruse and occasionally post to via gmane.

For whomever might pursue this, there is a list of OO.org projects here:

http://projects.openoffice.org/index.html

including sections for API's etc.

HTH,

Marc


From kevin.hendricks at sympatico.ca  Wed Mar 28 19:42:21 2007
From: kevin.hendricks at sympatico.ca (Kevin B. Hendricks)
Date: Wed, 28 Mar 2007 13:42:21 -0400
Subject: [Rd] Bridging R to OpenOffice
In-Reply-To: <460A8C77.2040009@biostat.ku.dk>
References: <Pine.LNX.4.44.0703281210390.31714-100000@reclus.nhh.no>	<200703280648.54111.sdavis2@mail.nih.gov>	<460A6B89.8030903@sun.com>
	<200703280933.45736.sdavis2@mail.nih.gov>
	<460A8C77.2040009@biostat.ku.dk>
Message-ID: <3B913F96-E9A0-4219-AEB4-00408E3D6055@sympatico.ca>

Hi,

I would like to potentially become involved with this project.  I am  
still learning about R-project internals but I have been digging  
around a lot in the internal R-code.  That said, I am initimately  
familiar with OOo since I was involved as a volunteer for that  
project previously.  I wrote some of the OOo bridge code that allows  
Linux PPC, and Mac PPC to make UNO calls (translates the abi calling  
conventions from C++ to uno and then from uno back to C++ on the fly)  
and also wrote their first spellchecker which used the UNO  
interface.  Similar uno bridges exist for Java and python.  I don't  
think there is a bridge from uno to fortran and back but since the  
bulk of internal R code is C and that R itself can be built as a  
shared library, that should not really be an issue.

As I remember, I think someone has built an interface from Gnumeric  
to R if I am not mistaken.  That project if it is still alive might  
provide a nice model of how to interface from a spreadsheet to R  
without lots of GUI front end stuff being needed.  As I remember, it  
just allowed a number of advanced features from R to be used from  
within GNumeric (just as if you added an analysis toolpack to Excel)

It would be nice for example to have a list of extended functions  
that Calc can invoke that are actually run in R and returned to  
Calc's cells.  I can think of many matrix functions such as finding  
eigenvalues and eigenvectors that Calc can not easily do now but that  
would extend Calc's usefulness as a linear model learning tool.

Anyway, my 2 cents.

As I am not a member of R-core, I would vote that the discussion  
concerning this project stay on this list or failing that, that  
interested people CC-me directly (khendricks at sympatico.ca).

Thanks,

Kevin

On Mar 28, 2007, at 11:40 AM, Peter Dalgaard wrote:

> Sean Davis wrote:
>> On Wednesday 28 March 2007 09:20, Stefan Zimmermann wrote:
>>
>>> Still didn't get the point, or missed the topic ?
>>>
>>
>> I had gotten the point, yes--just trying to be helpful.  I'm sorry  
>> it wasn't
>> taken as such.


From cstrato at aon.at  Wed Mar 28 20:00:31 2007
From: cstrato at aon.at (cstrato)
Date: Wed, 28 Mar 2007 20:00:31 +0200
Subject: [Rd] Limitation of dirname() and basename(): file.name() and
 file.dir() ?
In-Reply-To: <0060E2BA-CABF-40C3-8C1A-19D9B5384835@r-project.org>
References: <460807A7.5030405@aon.at>	<Pine.LNX.4.64.0703270744580.9277@gannet.stats.ox.ac.uk>	<46095818.9080703@aon.at>
	<46096180.5070907@cimr.cam.ac.uk>	<46096739.20006@aon.at>
	<ADFA2A8A-B14B-44D9-899C-EFBE529E6F66@r-project.org>
	<46098FDC.4010707@fhcrc.org>
	<0060E2BA-CABF-40C3-8C1A-19D9B5384835@r-project.org>
Message-ID: <460AAD3F.6040104@aon.at>

I am glad to hear that there seems to be some commitment for improvement,
although I must admit, that I did not realize that both functions do not 
check
if a name is a directory or a filename, even though the  definition in "The
Open Group Base Specifications" says:
   dirname  - return the directory portion of a pathname
   basename - return non-directory portion of a pathname

Using basename() and dirname() I tried to define functions, which show
what I wanted to do:

file.name <- function(fullname, name.exists=T) {
   isdir <- file.info(fullname)[,"isdir"]
   if (is.na(isdir)) return(ifelse (name.exists, NA, basename(fullname)))
   ifelse (isdir, "", basename(fullname))  
}

file.dir <-function(fullname, name.exists=T) {
   isdir <- file.info(fullname)[,"isdir"]
   if (is.na(isdir)) return(ifelse (name.exists, NA, 
file.dir(dirname(fullname))))
   path.expand(ifelse (isdir, fullname, dirname(fullname))) 
}

Here are some examples:

 > file.name("/net/home/stratowa/Diverses/tmp.txt")
[1] "tmp.txt"
 > file.name("/net/home/stratowa/Diverses/")
[1] ""
 > file.name("/net/home/stratowa/Diverses")
[1] ""
 > file.dir("/net/home/stratowa/Diverses/tmp.txt")
[1] "/net/home/stratowa/Diverses"
 > file.dir("/net/home/stratowa/Diverses/")
[1] "/net/home/stratowa/Diverses/"
 > file.dir("/net/home/stratowa/Diverses")
[1] "/net/home/stratowa/Diverses"

To get the filename part for a novel filename, I can set "name.exists=F".

I think, that it would be really helpful, if R could add these (or similar)
functions to the base package, but this is my personal opinion.

Best regards
Christian


Simon Urbanek wrote:
>
> On Mar 27, 2007, at 5:42 PM, Herve Pages wrote:
>
>> Simon Urbanek wrote:
>>> Your proposed behavior is inconsistent, anyway. The purpose of 
>>> dirname is to return parent directory of the entity represented by 
>>> the pathname.
>>
>> Mmmm, I don't think this is true:
>>
>>> dirname("aaa/..")
>>   [1] "aaa"
>>
>> "aaa" is not the parent directory of "aaa/.."
>>
>> Same here:
>>
>>> dirname("/usr/./.")
>>   [1] "/usr/."
>>
>
> Yes, the problem is that most dirname implementations don't 
> canonicalize the path - they are working on the string representation 
> and don't use the underlying FS. I wasn't saying that dirname is 
> perfect, in fact I refrained from commenting on this earlier exactly 
> because of the behavior you describe, but the decision to remove 
> trailing slashes was a deliberate as can be seen from the specs. 
> Semantically correct behavior (taking the definition of the dirname 
> function literally) would be dirname "/usr/." = "/", basename "/usr/." 
> = "usr". However, I suspect that not many people would expect this ;). 
> As was proposed earlier, one could think of "true" dirname" or perhaps 
> better "parentdir" function, although admittedly I don't see an issue 
> here ...
>
> Cheers,
> Simon
>
>
>
>>
>>> "/my/path" and "/my/path/" are equivalent as they both
>>> represent the directory "path" whose parent is "/my", therefore
>>> returning "/my/path" in either case is inconsistent with the purpose
>>> of this function. As of trailing slashes (independently of dirname),
>>> sadly, some programs exploit the equivalence of both representations
>>> by encoding meta-information in the representation, but this behavior
>>> is quite confusing and error-prone. You're free to add such special
>>> cases to your application, but there is no reason to add such
>>> confusion to R.
>>
>> Note that Python's designers were not afraid to emancipate from Unix for
>> this particular case:
>>
>>>>> import os.path
>>>>> os.path.dirname("aaa/..")
>>   'aaa'
>>>>> os.path.dirname("aaa/../")
>>   'aaa/..'
>>
>>
>> Also note that, if the goal was to mimic Unix behaviour, then why not
>> fully go for it, even for edge-cases:
>>
>>   R
>>   ----
>>> dirname("/")
>>   [1] "/"
>>> basename("/")
>>   [1] ""
>>
>>   Unix
>>   ----
>>   hpages at lamb1:~> dirname "/"
>>   /
>>   hpages at lamb1:~> basename "/"
>>   /
>>
>> Just my 2 cents...
>>
>> Cheers,
>> H.
>>
>>


From lmada at gmx.net  Wed Mar 28 20:29:18 2007
From: lmada at gmx.net (Leonard Mada)
Date: Wed, 28 Mar 2007 21:29:18 +0300
Subject: [Rd] Bridging R to OpenOffice
In-Reply-To: <460A3BF7.8010605@cimr.cam.ac.uk>
References: <4609655A.5070209@gmx.net> <460A3BF7.8010605@cimr.cam.ac.uk>
Message-ID: <460AB3FE.10101@gmx.net>

Many thanks for the many kind replies. It is very reassuring to have 
support from a strong community.


Hin-Tak Leung wrote:
 > Hmm, if all you are interested is reading/writing Excel spreadsheets
 > from R, there are much lighter and easier ways of doing it, than
 > hooking up with openoffice. The Perl people have had
 > Spreadsheet::ParseExcel and Spreadsheet::WriteExcel for years (and
 > they work quite well, personal experience). Those are tiny
 > (a couple of Mb's?) compared to the size of openoffice.

I believe that this R-OOo bridge should pursue a different path. I 
favour the idea to facilitate access to R for common spreadsheet users. 
As these users are less likely to learn the full S language, the 
implemented method should by largely offer a GUI-driven interface to 
important statistical (R)-functions (at least in the beginning; adding 
further functionality later on).

Having an R package to read/write .ods files seems reasonable, too, (and 
I would definitely like it) however this will not benefit the larger 
spreadsheet community. Again, it will ease the life of power users, but 
the novice must still first learn R. The package odfWeave (see R News 
vol 6/4, October 2006) offers already basic support for OOo Writer files 
and, while it currently lacks spreadsheet functionality, I am looking 
forward to see it implemented, too.

1. Teaching Role
There are some deeper reasons why I cling to the R-OOo bridging idea. I 
have read in my life hundreds of biomedical articles (probably even more 
than a thousand) and I have a very bitter taste about the quality of 
most of these articles. The statistics have played an important role in 
my judgment.

The fact is, that most researchers will use a spreadsheet program to 
gather their data. And most will use this spreadsheet program to do 
their analysis, too. If this spreadsheet program offers more advanced 
statistical methods (and also a sensible help file on these methods), 
then some users will try to use them. Some of these will take the next 
step, too, and will dwell a little bit deeper into statistics, thus 
raising the quality of the research.

In this way, this bridge would have also a teaching role, persuading 
some users to take a deeper look at statistics (especially learning more 
advanced and various newer methods). It will make R more popular, too.

2. Implementing Advanced Statistical Functions in OOo
I do not favour this idea, because:
- newer methods are not always trivial to implement
- spreadsheet programs are notorious for poor statistical algorithms 
(non-robust implementation)
- more resources (programmers, testing frameworks) are needed, when free 
(and much better) alternatives already do exist
- community would have to form first (e.g. help, FAQ), while R already 
has a large community

Many thanks,

Leonard


From hb at stat.berkeley.edu  Wed Mar 28 23:25:37 2007
From: hb at stat.berkeley.edu (Henrik Bengtsson)
Date: Wed, 28 Mar 2007 14:25:37 -0700
Subject: [Rd] Suggestion for memory optimization and as.double() with friends
Message-ID: <59d7961d0703281425n161a100lf4fb36bcf95ac742@mail.gmail.com>

Hi,

when doing as.double() on an object that is already a double, the
object seems to be copied internally, doubling the memory requirement.
 See example below.  Same for as.character() etc.  Is this intended?

Example:

% R --vanilla
> x <- double(1e7)
> gc()
           used (Mb) gc trigger (Mb) max used (Mb)
Ncells   234019  6.3     467875 12.5   350000  9.4
Vcells 10103774 77.1   11476770 87.6 10104223 77.1
> x <- as.double(x)
> gc()
           used (Mb) gc trigger  (Mb) max used  (Mb)
Ncells   234113  6.3     467875  12.5   350000   9.4
Vcells 10103790 77.1   21354156 163.0 20103818 153.4

However, couldn't this easily be avoided by letting as.double() return
the object as is if already a double?

Example:

% R --vanilla
> as.double.double <- function(x, ...) x
> x <- double(1e7)
> gc()
           used (Mb) gc trigger (Mb) max used (Mb)
Ncells   234019  6.3     467875 12.5   350000  9.4
Vcells 10103774 77.1   11476770 87.6 10104223 77.1
> x <- as.double(x)
> gc()
           used (Mb) gc trigger (Mb) max used (Mb)
Ncells   234028  6.3     467875 12.5   350000  9.4
Vcells 10103779 77.1   12130608 92.6 10104223 77.1

What's the catch?


The reason why I bring it up, is because many (most?) methods are
using as.double() etc "just in case" when passing arguments to
.Call(), .Fortran() etc, e.g. stats::smooth.spline():

    fit <- .Fortran(R_qsbart, as.double(penalty), as.double(dofoff),
        x = as.double(xbar), y = as.double(ybar), w = as.double(wbar), <etc>)

Your memory usage is peaking in the actual call and the garbage
collector cannot clean it up until after the call. This seems to be
waste of memory, especially when the objects are large (100-1000MBs).

Cheers

Henrik


From tplate at acm.org  Wed Mar 28 23:56:01 2007
From: tplate at acm.org (Tony Plate)
Date: Wed, 28 Mar 2007 15:56:01 -0600
Subject: [Rd] checking existence of active bindings
Message-ID: <460AE471.3040702@acm.org>

Is there any way to check whether an active binding exists without 
actually calling the active binding?  I'd like to be able to do 
something like exists("x", ...) and know whether "x" exists without 
actually fetching its value if it is an active binding (because it could 
consume significant resources to fetch the value).

The documentation for exists() doesn't really say whether or not the 
value is actually retrieved.  I guess that ?exists was written before 
the (experimental) active binding code, but still it would be nice if 
exists("x", mode="any") didn't call an active binding for "x".

Here's an example showing that exists() does result in the active 
binding being called:

 > fx <- function(v) {
+     if (missing(v))
+         cat("getting x1\n")
+     else {
+         cat("setting x1\n")
+         assign("x1", v, envir=globalenv())
+     }
+     get("x1", envir=globalenv())
+ }
 > makeActiveBinding("x", fx, globalenv())
NULL
 > x1 <- 3
 > x
getting x1
[1] 3
 > exists("x", inherits=FALSE)
getting x1
[1] TRUE
 > sessionInfo()
R version 2.4.1 (2006-12-18)
i386-pc-mingw32

locale:
LC_COLLATE=English_United States.1252;LC_CTYPE=English_United 
States.1252;LC_MONETARY=English_United 
States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252

attached base packages:
[1] "stats"     "graphics"  "grDevices" "utils"     "datasets" 
"methods"   "base"

other attached packages:
       abind      g.data       chron   fCalendar     fEcofin
     "1.1-0"       "1.6"    "2.3-10" "240.10068" "240.10067"
 >


 From looking at the source, the exists() calls function 
findVarInFrame3() (envir.c) with doGet=FALSE.  The comments for the 
argument doGet on findVarInFrame3() say:

   The final argument is usually TRUE and indicates whether the
   lookup is being done in order to get the value (TRUE) or
   simply to check whether there is a value bound to the specified
   symbol in this frame (FALSE).  This is used for get() and exists().

Nonetheless, the value is actually retrieved when doGet=FALSE (at least 
for ordinary environments, such as the global environment).  (I'm not 
trying to claim that this behavior contradicts the documentation, but 
it's not what I expected from reading the documentation.)

The only ways I can see to check in pure R if an active binding exists 
without calling the binding are things like
 > identical(TRUE, try(bindingIsActive("x", globalenv()), silent=TRUE))
 > is.element("x", objects(all=T, envir=globalenv()))
but I was hoping to just be able to use exists().

Was this interaction of exists() with active bindings intended, or did 
it just arise by accident and might be subject to future improvement?

-- Tony Plate


From hb at stat.berkeley.edu  Wed Mar 28 23:59:08 2007
From: hb at stat.berkeley.edu (Henrik Bengtsson)
Date: Wed, 28 Mar 2007 14:59:08 -0700
Subject: [Rd] Suggestion for memory optimization and as.double() with
	friends
In-Reply-To: <59d7961d0703281425n161a100lf4fb36bcf95ac742@mail.gmail.com>
References: <59d7961d0703281425n161a100lf4fb36bcf95ac742@mail.gmail.com>
Message-ID: <59d7961d0703281459i19eadfa6j197b8a30b4d15ac0@mail.gmail.com>

On 3/28/07, Henrik Bengtsson <hb at stat.berkeley.edu> wrote:
> Hi,
>
> when doing as.double() on an object that is already a double, the
> object seems to be copied internally, doubling the memory requirement.
>  See example below.  Same for as.character() etc.  Is this intended?
>
> Example:
>
> % R --vanilla
> > x <- double(1e7)
> > gc()
>            used (Mb) gc trigger (Mb) max used (Mb)
> Ncells   234019  6.3     467875 12.5   350000  9.4
> Vcells 10103774 77.1   11476770 87.6 10104223 77.1
> > x <- as.double(x)
> > gc()
>            used (Mb) gc trigger  (Mb) max used  (Mb)
> Ncells   234113  6.3     467875  12.5   350000   9.4
> Vcells 10103790 77.1   21354156 163.0 20103818 153.4
>
> However, couldn't this easily be avoided by letting as.double() return
> the object as is if already a double?
>
> Example:
>
> % R --vanilla
> > as.double.double <- function(x, ...) x
> > x <- double(1e7)
> > gc()
>            used (Mb) gc trigger (Mb) max used (Mb)
> Ncells   234019  6.3     467875 12.5   350000  9.4
> Vcells 10103774 77.1   11476770 87.6 10104223 77.1
> > x <- as.double(x)
> > gc()
>            used (Mb) gc trigger (Mb) max used (Mb)
> Ncells   234028  6.3     467875 12.5   350000  9.4
> Vcells 10103779 77.1   12130608 92.6 10104223 77.1
>
> What's the catch?

Ok, one catch that my example didn't illustrate is: "as.double'
attempts to coerce its argument to be of double type: like 'as.vector'
it strips attributes including names." (from ?as.double).

So, answering my own question, I can see how stripping the attributes
"requires" a internal copy.  Anyhow, when there are stripping
attributes, the same idea still applies, with a more clever
as.double() function.

In the case when one want to coerce to a double, and keep existing
attributes, one could extend as.double() with:

 as.double(x, stripAttributes=FALSE)

and that code could be clever enough not to create and internal copy.

/Henrik

>
>
> The reason why I bring it up, is because many (most?) methods are
> using as.double() etc "just in case" when passing arguments to
> .Call(), .Fortran() etc, e.g. stats::smooth.spline():
>
>     fit <- .Fortran(R_qsbart, as.double(penalty), as.double(dofoff),
>         x = as.double(xbar), y = as.double(ybar), w = as.double(wbar), <etc>)
>
> Your memory usage is peaking in the actual call and the garbage
> collector cannot clean it up until after the call. This seems to be
> waste of memory, especially when the objects are large (100-1000MBs).
>
> Cheers
>
> Henrik
>


From murdoch at stats.uwo.ca  Thu Mar 29 00:04:07 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Wed, 28 Mar 2007 18:04:07 -0400
Subject: [Rd] Suggestion for memory optimization and as.double() with
 friends
In-Reply-To: <59d7961d0703281425n161a100lf4fb36bcf95ac742@mail.gmail.com>
References: <59d7961d0703281425n161a100lf4fb36bcf95ac742@mail.gmail.com>
Message-ID: <460AE657.9040402@stats.uwo.ca>

On 3/28/2007 5:25 PM, Henrik Bengtsson wrote:
> Hi,
> 
> when doing as.double() on an object that is already a double, the
> object seems to be copied internally, doubling the memory requirement.
>  See example below.  Same for as.character() etc.  Is this intended?
> 
> Example:
> 
> % R --vanilla
>> x <- double(1e7)
>> gc()
>            used (Mb) gc trigger (Mb) max used (Mb)
> Ncells   234019  6.3     467875 12.5   350000  9.4
> Vcells 10103774 77.1   11476770 87.6 10104223 77.1
>> x <- as.double(x)
>> gc()
>            used (Mb) gc trigger  (Mb) max used  (Mb)
> Ncells   234113  6.3     467875  12.5   350000   9.4
> Vcells 10103790 77.1   21354156 163.0 20103818 153.4
> 
> However, couldn't this easily be avoided by letting as.double() return
> the object as is if already a double?

as.double calls the internal as.vector, which also strips off 
attributes.  But in the case where the output is identical to the input, 
this does seem like an easy optimization.  I don't know if it would help 
most people, but it might help in the kinds of cases you mention.

Duncan Murdoch

> 
> Example:
> 
> % R --vanilla
>> as.double.double <- function(x, ...) x
>> x <- double(1e7)
>> gc()
>            used (Mb) gc trigger (Mb) max used (Mb)
> Ncells   234019  6.3     467875 12.5   350000  9.4
> Vcells 10103774 77.1   11476770 87.6 10104223 77.1
>> x <- as.double(x)
>> gc()
>            used (Mb) gc trigger (Mb) max used (Mb)
> Ncells   234028  6.3     467875 12.5   350000  9.4
> Vcells 10103779 77.1   12130608 92.6 10104223 77.1
> 
> What's the catch?
> 
> 
> The reason why I bring it up, is because many (most?) methods are
> using as.double() etc "just in case" when passing arguments to
> .Call(), .Fortran() etc, e.g. stats::smooth.spline():
> 
>     fit <- .Fortran(R_qsbart, as.double(penalty), as.double(dofoff),
>         x = as.double(xbar), y = as.double(ybar), w = as.double(wbar), <etc>)
> 
> Your memory usage is peaking in the actual call and the garbage
> collector cannot clean it up until after the call. This seems to be
> waste of memory, especially when the objects are large (100-1000MBs).
> 
> Cheers
> 
> Henrik
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From bates at stat.wisc.edu  Thu Mar 29 01:21:57 2007
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 28 Mar 2007 18:21:57 -0500
Subject: [Rd] [R] Use of 'defineVar' and 'install' in .Call
In-Reply-To: <f13f1c9c0703270156hba5b26fyb541817bed557b0c@mail.gmail.com>
References: <f13f1c9c0703270156hba5b26fyb541817bed557b0c@mail.gmail.com>
Message-ID: <40e66e0b0703281621u58200b39oe3695fc4eaa6d948@mail.gmail.com>

I did read your second message about the problem symptoms disappearing
but I thought that I might make a couple of suggestions about your
code anyway.

There are a number of helper functions declared in Rinternals.h such
as ScalarReal, which is equivalent to your mkans.  (Also
ScalarInteger, ScalarLogical, ...) The functions to convert scalars in
the other direction, i.e. taking an SEXP and returning an int or a
double or a ... , are called asInteger, asReal, ...

If you are writing a package you can define an initialization function
called R_init_<pkgname> to perform initialization for the package.  If
you are going to use a symbol like x many times then you can save the
result of install("x") as a global, say, myPkg_xSymbol during
initialization and use the global variable instead of calling install
many times.  The overhead for calling install is small but if you can
avoid it I don't see a reason not to.

Finally, why do you want to use identifiers like u1, u2, ... when you
could pass a vector named "u" and use that.  In other words, wouldn't
it be easier to do the extraction of the components in the R code for
the function rather than generating a whole bunch of different names?

I suggest that this thread be moved to the r-devel list, which I have cc:d.

On 3/27/07, Daniel Berg <daniel at danielberg.no> wrote:
> Dear all,
>
> [system and version information below]
>
> I am trying to modify a C function for finding the root of an
> expression. The function is to be called from R as .Call with input
> parameters:
>
> f: expression for which we will find the root
> guesses: interval for the solution
> stol: tolerance
> rho: environment
>
> The original functions I use are:
>
> SEXP mkans(double x) {
>   SEXP ans;
>   PROTECT(ans = allocVector(REALSXP, 1));
>   REAL(ans)[0] = x;
>   UNPROTECT(1);
>   return ans;
> }
> double feval(double x, SEXP f, SEXP rho) {
>   defineVar(install("x"), mkans(x), rho);
>   return(REAL(eval(f, rho))[0]);
> }
> SEXP zero(SEXP f, SEXP guesses, SEXP stol, SEXP rho) {
>   double x0 = REAL(guesses)[0], x1 = REAL(guesses)[1], tol = REAL(stol)[0];
>   double f0, f1, fc, xc;
>   if(tol <= 0.0) error("non-positive tol value");
>   f0 = feval(x0, f, rho); f1 = feval(x1, f, rho);
>   if(f0 == 0.0) return mkans(x0);
>   if(f1 == 0.0) return mkans(x1);
>   if(f0*f1 > 0.0) error("x[0] and x[1] have the same sign");
>   for(;;) {
>     xc = 0.5*(x0+x1);
>     if(fabs(x0-x1) < tol) return mkans(xc);
>     fc = feval(xc, f, rho);
>     if(fc == 0) return mkans(xc);
>     if(f0*fc > 0.0) {
>       x0 = xc; f0 = fc;
>     }
>     else {
>       x1 = xc; f1 = fc;
>     }
>   }
> }
>
>
> This works great. However, I wish to make it more general, by
> modifying 'feval'. Given that my problem involves a data set 'u', with
> dimension (i x j), I need to assign values to 'u1', 'u2', ..., 'ui'
> via defineVar(install(...)). I tried the following:
>
> double feval(double x, double *u, int d, double v, SEXP f, SEXP rho) {
>   int i;
>   char *str1="u", str2[1001], *str3;
>   defineVar(install("x"), mkans(x), rho);
>   defineVar(install("y"), mkans(v), rho);
>   for(i=0;i<d;i++) {
>     sprintf(str2,"%d",i+1);
>     str3 = (char *)malloc((strlen(str1)+strlen(str2)+1)*sizeof(char));
>     strcpy(str3,str1);
>     strcat(str3,str2);
>     defineVar(install(str3), mkans(u[i]), rho);
>   }
>   free(str3);
>   return(REAL(eval(f,rho))[0]);
> }
>
> My R-package still compiles without errors but R crashes due to the
> defineVar command.
>
> Any suggestions to how I can do the defineVar bit?
>
> Thanks in advance.
>
> Reagards,
> Daniel Berg
>
> --------------------------------------------
> > R.Version()
> $platform
> [1] "i486-pc-linux-gnu"
> $arch
> [1] "i486"
> $os
> [1] "linux-gnu"
> $system
> [1] "i486, linux-gnu"
> $status
> [1] ""
> $major
> [1] "2"
> $minor
> [1] "3.1"
> $year
> [1] "2006"
> $month
> [1] "06"
> $day
> [1] "01"
> $`svn rev`
> [1] "38247"
> $language
> [1] "R"
> $version.string
> [1] "Version 2.3.1 (2006-06-01)"
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From hb at stat.berkeley.edu  Thu Mar 29 02:17:39 2007
From: hb at stat.berkeley.edu (Henrik Bengtsson)
Date: Wed, 28 Mar 2007 17:17:39 -0700
Subject: [Rd] Suggestion for memory optimization and as.double() with
	friends
In-Reply-To: <460AE657.9040402@stats.uwo.ca>
References: <59d7961d0703281425n161a100lf4fb36bcf95ac742@mail.gmail.com>
	<460AE657.9040402@stats.uwo.ca>
Message-ID: <59d7961d0703281717h4a5b5c84t25995be775c99b4e@mail.gmail.com>

On 3/28/07, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> On 3/28/2007 5:25 PM, Henrik Bengtsson wrote:
> > Hi,
> >
> > when doing as.double() on an object that is already a double, the
> > object seems to be copied internally, doubling the memory requirement.
> >  See example below.  Same for as.character() etc.  Is this intended?
> >
> > Example:
> >
> > % R --vanilla
> >> x <- double(1e7)
> >> gc()
> >            used (Mb) gc trigger (Mb) max used (Mb)
> > Ncells   234019  6.3     467875 12.5   350000  9.4
> > Vcells 10103774 77.1   11476770 87.6 10104223 77.1
> >> x <- as.double(x)
> >> gc()
> >            used (Mb) gc trigger  (Mb) max used  (Mb)
> > Ncells   234113  6.3     467875  12.5   350000   9.4
> > Vcells 10103790 77.1   21354156 163.0 20103818 153.4
> >
> > However, couldn't this easily be avoided by letting as.double() return
> > the object as is if already a double?
>
> as.double calls the internal as.vector, which also strips off
> attributes.  But in the case where the output is identical to the input,
> this does seem like an easy optimization.  I don't know if it would help
> most people, but it might help in the kinds of cases you mention.

What about,

as.double.double <- function(x, ...) {
 if (is.null(attributes(x))) x else NextMethod("as.double", x, ...)
}

and same for as.integer(), as.logical(), as.complex(), as.raw(), and
as.character()?

/Henrik

>
> Duncan Murdoch
>
> >
> > Example:
> >
> > % R --vanilla
> >> as.double.double <- function(x, ...) x
> >> x <- double(1e7)
> >> gc()
> >            used (Mb) gc trigger (Mb) max used (Mb)
> > Ncells   234019  6.3     467875 12.5   350000  9.4
> > Vcells 10103774 77.1   11476770 87.6 10104223 77.1
> >> x <- as.double(x)
> >> gc()
> >            used (Mb) gc trigger (Mb) max used (Mb)
> > Ncells   234028  6.3     467875 12.5   350000  9.4
> > Vcells 10103779 77.1   12130608 92.6 10104223 77.1
> >
> > What's the catch?
> >
> >
> > The reason why I bring it up, is because many (most?) methods are
> > using as.double() etc "just in case" when passing arguments to
> > .Call(), .Fortran() etc, e.g. stats::smooth.spline():
> >
> >     fit <- .Fortran(R_qsbart, as.double(penalty), as.double(dofoff),
> >         x = as.double(xbar), y = as.double(ybar), w = as.double(wbar), <etc>)
> >
> > Your memory usage is peaking in the actual call and the garbage
> > collector cannot clean it up until after the call. This seems to be
> > waste of memory, especially when the objects are large (100-1000MBs).
> >
> > Cheers
> >
> > Henrik
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From murdoch at stats.uwo.ca  Thu Mar 29 03:48:09 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Wed, 28 Mar 2007 21:48:09 -0400
Subject: [Rd] Suggestion for memory optimization and as.double() with
 friends
In-Reply-To: <59d7961d0703281717h4a5b5c84t25995be775c99b4e@mail.gmail.com>
References: <59d7961d0703281425n161a100lf4fb36bcf95ac742@mail.gmail.com>	
	<460AE657.9040402@stats.uwo.ca>
	<59d7961d0703281717h4a5b5c84t25995be775c99b4e@mail.gmail.com>
Message-ID: <460B1AD9.7080705@stats.uwo.ca>

On 3/28/2007 8:17 PM, Henrik Bengtsson wrote:
> On 3/28/07, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
>> On 3/28/2007 5:25 PM, Henrik Bengtsson wrote:
>>> Hi,
>>>
>>> when doing as.double() on an object that is already a double, the
>>> object seems to be copied internally, doubling the memory requirement.
>>>  See example below.  Same for as.character() etc.  Is this intended?
>>>
>>> Example:
>>>
>>> % R --vanilla
>>>> x <- double(1e7)
>>>> gc()
>>>            used (Mb) gc trigger (Mb) max used (Mb)
>>> Ncells   234019  6.3     467875 12.5   350000  9.4
>>> Vcells 10103774 77.1   11476770 87.6 10104223 77.1
>>>> x <- as.double(x)
>>>> gc()
>>>            used (Mb) gc trigger  (Mb) max used  (Mb)
>>> Ncells   234113  6.3     467875  12.5   350000   9.4
>>> Vcells 10103790 77.1   21354156 163.0 20103818 153.4
>>>
>>> However, couldn't this easily be avoided by letting as.double() return
>>> the object as is if already a double?
>> as.double calls the internal as.vector, which also strips off
>> attributes.  But in the case where the output is identical to the input,
>> this does seem like an easy optimization.  I don't know if it would help
>> most people, but it might help in the kinds of cases you mention.
> 
> What about,
> 
> as.double.double <- function(x, ...) {
>  if (is.null(attributes(x))) x else NextMethod("as.double", x, ...)
> }
> 
> and same for as.integer(), as.logical(), as.complex(), as.raw(), and
> as.character()?

Yes, something like that, except it should be within the internal 
as.vector code.  Writing it in R code would impact all users, and might 
even negate any advantage you got from the lack of duplication.  For 
example, you'll be duplicating the attributes of x with the code above, 
but internal code could do the test without the duplication.

Duncan Murdoch

> 
> /Henrik
> 
>> Duncan Murdoch
>>
>>> Example:
>>>
>>> % R --vanilla
>>>> as.double.double <- function(x, ...) x
>>>> x <- double(1e7)
>>>> gc()
>>>            used (Mb) gc trigger (Mb) max used (Mb)
>>> Ncells   234019  6.3     467875 12.5   350000  9.4
>>> Vcells 10103774 77.1   11476770 87.6 10104223 77.1
>>>> x <- as.double(x)
>>>> gc()
>>>            used (Mb) gc trigger (Mb) max used (Mb)
>>> Ncells   234028  6.3     467875 12.5   350000  9.4
>>> Vcells 10103779 77.1   12130608 92.6 10104223 77.1
>>>
>>> What's the catch?
>>>
>>>
>>> The reason why I bring it up, is because many (most?) methods are
>>> using as.double() etc "just in case" when passing arguments to
>>> .Call(), .Fortran() etc, e.g. stats::smooth.spline():
>>>
>>>     fit <- .Fortran(R_qsbart, as.double(penalty), as.double(dofoff),
>>>         x = as.double(xbar), y = as.double(ybar), w = as.double(wbar), <etc>)
>>>
>>> Your memory usage is peaking in the actual call and the garbage
>>> collector cannot clean it up until after the call. This seems to be
>>> waste of memory, especially when the objects are large (100-1000MBs).
>>>
>>> Cheers
>>>
>>> Henrik
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>


From ripley at stats.ox.ac.uk  Thu Mar 29 04:11:18 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 29 Mar 2007 03:11:18 +0100 (BST)
Subject: [Rd] Suggestion for memory optimization and as.double() with
 friends
In-Reply-To: <460AE657.9040402@stats.uwo.ca>
References: <59d7961d0703281425n161a100lf4fb36bcf95ac742@mail.gmail.com>
	<460AE657.9040402@stats.uwo.ca>
Message-ID: <Pine.LNX.4.64.0703290256240.6919@gannet.stats.ox.ac.uk>

On Wed, 28 Mar 2007, Duncan Murdoch wrote:

> On 3/28/2007 5:25 PM, Henrik Bengtsson wrote:
>> Hi,
>>
>> when doing as.double() on an object that is already a double, the
>> object seems to be copied internally, doubling the memory requirement.
>>  See example below.  Same for as.character() etc.  Is this intended?
>>
>> Example:
>>
>> % R --vanilla
>>> x <- double(1e7)
>>> gc()
>>            used (Mb) gc trigger (Mb) max used (Mb)
>> Ncells   234019  6.3     467875 12.5   350000  9.4
>> Vcells 10103774 77.1   11476770 87.6 10104223 77.1
>>> x <- as.double(x)
>>> gc()
>>            used (Mb) gc trigger  (Mb) max used  (Mb)
>> Ncells   234113  6.3     467875  12.5   350000   9.4
>> Vcells 10103790 77.1   21354156 163.0 20103818 153.4
>>
>> However, couldn't this easily be avoided by letting as.double() return
>> the object as is if already a double?
>
> as.double calls the internal as.vector, which also strips off
> attributes.  But in the case where the output is identical to the input,
> this does seem like an easy optimization.  I don't know if it would help
> most people, but it might help in the kinds of cases you mention.

The cases mentioned are going to copy going into .Fortran and back out 
from .Fortran, so saving one copy will not be a big gain.  The (known) 
problem is using .C/.Fortran for large vectors, not as.double, and in the 
smooth.spline example the vectors will not be large in the intended usage.

The usual 'trick' to avoid this copy is

storage.mode(x) <- "double"

if you don't care about stripping attributes.

I have looked at this (internal) optimization before and not found any 
real-life problems where it seemed important.  People should expect to 
profile a real example and find as.vector taking an appreciable part of 
the time *before* spending developer time on speculative optimizations.

>
> Duncan Murdoch
>
>>
>> Example:
>>
>> % R --vanilla
>>> as.double.double <- function(x, ...) x
>>> x <- double(1e7)
>>> gc()
>>            used (Mb) gc trigger (Mb) max used (Mb)
>> Ncells   234019  6.3     467875 12.5   350000  9.4
>> Vcells 10103774 77.1   11476770 87.6 10104223 77.1
>>> x <- as.double(x)
>>> gc()
>>            used (Mb) gc trigger (Mb) max used (Mb)
>> Ncells   234028  6.3     467875 12.5   350000  9.4
>> Vcells 10103779 77.1   12130608 92.6 10104223 77.1
>>
>> What's the catch?
>>
>>
>> The reason why I bring it up, is because many (most?) methods are
>> using as.double() etc "just in case" when passing arguments to
>> .Call(), .Fortran() etc, e.g. stats::smooth.spline():
>>
>>     fit <- .Fortran(R_qsbart, as.double(penalty), as.double(dofoff),
>>         x = as.double(xbar), y = as.double(ybar), w = as.double(wbar), <etc>)
>>
>> Your memory usage is peaking in the actual call and the garbage
>> collector cannot clean it up until after the call. This seems to be
>> waste of memory, especially when the objects are large (100-1000MBs).
>>
>> Cheers
>>
>> Henrik
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From murdoch at stats.uwo.ca  Thu Mar 29 04:18:10 2007
From: murdoch at stats.uwo.ca (murdoch at stats.uwo.ca)
Date: Thu, 29 Mar 2007 04:18:10 +0200 (CEST)
Subject: [Rd] Fwd: Re: documentation clarifications (PR#9587)
Message-ID: <20070329021810.5E6E34BE81@slim.kubism.ku.dk>

On 3/28/2007 8:50 AM, Duncan Murdoch wrote:
> On 3/27/2007 11:36 PM, Richard M. Heiberger wrote:
>> I verified that this is a difference in behavior in both the released 2.4.1 for Windows
>> and the "2.5.0 Under development (unstable) (2007-02-10 r40690)" for Windows.
>> In htmlhelp, the word "interaction" is clickable and goes to the interaction{lattice}
>> page.  In chmhelp, the word "interaction" is not clickable.
> 
> Thanks for the report.  That does look like a bug; I'll see if I can 
> track it down before 2.5.0.  The "interaction" link is coded as
> \link[lattice:interaction]{interaction} and apparently that kind of link 
> is not currently working in CHTML files.

I've found and fixed the bug; I'll commit it after a bit more testing.

Duncan Murdoch

> 
> Duncan Murdoch
> 
>> Rich
>>
>> ---- Original message ----
>>> Date: Tue, 27 Mar 2007 19:54:32 -0700
>>> From: "Deepayan Sarkar" <deepayan.sarkar at gmail.com>  
>>> Subject: Re: documentation clarifications  
>>> To: "Richard M. Heiberger" <rmh at temple.edu>
>>>
>>> On 3/3/07, Richard M. Heiberger <rmh at temple.edu> wrote:
>>>> Eventually I found this line in the ?Lattice page:
>>>>   Tools to augment lattice plots after they are drawn (including
>>>>   locator-like functionality) is described in the interaction help page.
>>>>
>>>> "interaction" was not highlighted and therefore not clickable.
>>>> ?interaction
>>>> goes to interaction(base) which is a totally different capability.
>>> That would be a bug in whatever interface you are using. "interaction"
>>> should be a link pointing to lattice:interaction, and that works in an
>>> HTML interface.
>>>
> 
>


From daniel at danielberg.no  Thu Mar 29 08:32:10 2007
From: daniel at danielberg.no (Daniel Berg)
Date: Thu, 29 Mar 2007 08:32:10 +0200
Subject: [Rd] [R] Use of 'defineVar' and 'install' in .Call
In-Reply-To: <40e66e0b0703281621u58200b39oe3695fc4eaa6d948@mail.gmail.com>
References: <f13f1c9c0703270156hba5b26fyb541817bed557b0c@mail.gmail.com>
	<40e66e0b0703281621u58200b39oe3695fc4eaa6d948@mail.gmail.com>
Message-ID: <f13f1c9c0703282332i56223fd0u4f97a7e263b8945c@mail.gmail.com>

Thanks for your suggestions Douglas,

I just discovered the asInteger, asReal etc. but did not know of
ScalarInteger etc. Will examine these immediately. I am very new to
.Call and SEXP, just started experimenting with these. Previously I
have been using .C for all my functions, transforming a matrix to a
vector for the passing from R to C and back. Did not know of R_init
and the corresponding global opportunities either, thanks. Perhaps I
should go through "Writing R extensions" all over again now that I can
understand more of it :)

Concerning "x", the value to be assigned to "x" will be different for
each observation of my data set and each time the function is called.
This also applies to all the other variables I am installing. It
sounds like a good idea to rather do the assignment of u1,u2,... in R
and make my "zero"/"feval" functions even more general. I could
basically just pass the dimension, i.e. the number of u's that needs
to be assigned. Will examine this. But in my code I have
defineVar(install("u1"),mkans(x),rho) to assign the value of x to u1
in R. Then I run eval(f) to evaluate the expression f that includes
u1. How can I assign values to all u's, do I need a separate function
in R that I also need to pass to C? This function being a function to
assign values to expressions? Or can I send an entire vector to
defineVar(install())?

//Daniel

On 3/29/07, Douglas Bates <bates at stat.wisc.edu> wrote:
> I did read your second message about the problem symptoms disappearing
> but I thought that I might make a couple of suggestions about your
> code anyway.
>
> There are a number of helper functions declared in Rinternals.h such
> as ScalarReal, which is equivalent to your mkans.  (Also
> ScalarInteger, ScalarLogical, ...) The functions to convert scalars in
> the other direction, i.e. taking an SEXP and returning an int or a
> double or a ... , are called asInteger, asReal, ...
>
> If you are writing a package you can define an initialization function
> called R_init_<pkgname> to perform initialization for the package.  If
> you are going to use a symbol like x many times then you can save the
> result of install("x") as a global, say, myPkg_xSymbol during
> initialization and use the global variable instead of calling install
> many times.  The overhead for calling install is small but if you can
> avoid it I don't see a reason not to.
>
> Finally, why do you want to use identifiers like u1, u2, ... when you
> could pass a vector named "u" and use that.  In other words, wouldn't
> it be easier to do the extraction of the components in the R code for
> the function rather than generating a whole bunch of different names?
>
> I suggest that this thread be moved to the r-devel list, which I have cc:d.
>
> On 3/27/07, Daniel Berg <daniel at danielberg.no> wrote:
> > Dear all,
> >
> > [system and version information below]
> >
> > I am trying to modify a C function for finding the root of an
> > expression. The function is to be called from R as .Call with input
> > parameters:
> >
> > f: expression for which we will find the root
> > guesses: interval for the solution
> > stol: tolerance
> > rho: environment
> >
> > The original functions I use are:
> >
> > SEXP mkans(double x) {
> >   SEXP ans;
> >   PROTECT(ans = allocVector(REALSXP, 1));
> >   REAL(ans)[0] = x;
> >   UNPROTECT(1);
> >   return ans;
> > }
> > double feval(double x, SEXP f, SEXP rho) {
> >   defineVar(install("x"), mkans(x), rho);
> >   return(REAL(eval(f, rho))[0]);
> > }
> > SEXP zero(SEXP f, SEXP guesses, SEXP stol, SEXP rho) {
> >   double x0 = REAL(guesses)[0], x1 = REAL(guesses)[1], tol = REAL(stol)[0];
> >   double f0, f1, fc, xc;
> >   if(tol <= 0.0) error("non-positive tol value");
> >   f0 = feval(x0, f, rho); f1 = feval(x1, f, rho);
> >   if(f0 == 0.0) return mkans(x0);
> >   if(f1 == 0.0) return mkans(x1);
> >   if(f0*f1 > 0.0) error("x[0] and x[1] have the same sign");
> >   for(;;) {
> >     xc = 0.5*(x0+x1);
> >     if(fabs(x0-x1) < tol) return mkans(xc);
> >     fc = feval(xc, f, rho);
> >     if(fc == 0) return mkans(xc);
> >     if(f0*fc > 0.0) {
> >       x0 = xc; f0 = fc;
> >     }
> >     else {
> >       x1 = xc; f1 = fc;
> >     }
> >   }
> > }
> >
> >
> > This works great. However, I wish to make it more general, by
> > modifying 'feval'. Given that my problem involves a data set 'u', with
> > dimension (i x j), I need to assign values to 'u1', 'u2', ..., 'ui'
> > via defineVar(install(...)). I tried the following:
> >
> > double feval(double x, double *u, int d, double v, SEXP f, SEXP rho) {
> >   int i;
> >   char *str1="u", str2[1001], *str3;
> >   defineVar(install("x"), mkans(x), rho);
> >   defineVar(install("y"), mkans(v), rho);
> >   for(i=0;i<d;i++) {
> >     sprintf(str2,"%d",i+1);
> >     str3 = (char *)malloc((strlen(str1)+strlen(str2)+1)*sizeof(char));
> >     strcpy(str3,str1);
> >     strcat(str3,str2);
> >     defineVar(install(str3), mkans(u[i]), rho);
> >   }
> >   free(str3);
> >   return(REAL(eval(f,rho))[0]);
> > }
> >
> > My R-package still compiles without errors but R crashes due to the
> > defineVar command.
> >
> > Any suggestions to how I can do the defineVar bit?
> >
> > Thanks in advance.
> >
> > Reagards,
> > Daniel Berg
> >
> > --------------------------------------------
> > > R.Version()
> > $platform
> > [1] "i486-pc-linux-gnu"
> > $arch
> > [1] "i486"
> > $os
> > [1] "linux-gnu"
> > $system
> > [1] "i486, linux-gnu"
> > $status
> > [1] ""
> > $major
> > [1] "2"
> > $minor
> > [1] "3.1"
> > $year
> > [1] "2006"
> > $month
> > [1] "06"
> > $day
> > [1] "01"
> > $`svn rev`
> > [1] "38247"
> > $language
> > [1] "R"
> > $version.string
> > [1] "Version 2.3.1 (2006-06-01)"
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>


-- 
danielberg.no


From ripley at stats.ox.ac.uk  Thu Mar 29 08:27:30 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 29 Mar 2007 07:27:30 +0100 (BST)
Subject: [Rd] AIX testers needed
Message-ID: <Pine.LNX.4.64.0703290708120.17596@gannet.stats.ox.ac.uk>

With much thanks to Ei-ji Nakama, R 2.5.0 alpha supports building on AIX 
(at least AIX 5.2 on one system).

Would anyone able to test this please get the latest tarball from

http://cran.r-project.org/src/base-prerelease/R-latest.tar.gz

and try installing (after reading the AIX notes in R-admin.html section 
C.9).

In particular it would be very helpful to know if

1) --enable-BLAS-shlib works (it is the default everywhere except AIX and 
Darwin)

2) if people succeed in installing GNU libiconv and building without 
needing --without-iconv.

I am Cc:ing all the people I tracked down who reported attempted AIX 
installations in 2006 in the hope that they may still be interested.

Please report success and any hints or problems in the R-devel list.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From prechelt at inf.fu-berlin.de  Thu Mar 29 10:55:40 2007
From: prechelt at inf.fu-berlin.de (prechelt at inf.fu-berlin.de)
Date: Thu, 29 Mar 2007 10:55:40 +0200 (CEST)
Subject: [Rd] 'union' does not handle factors while 'intersect' does
	(PR#9589)
Message-ID: <20070329085540.575AE5AAB4@slim.kubism.ku.dk>

Full_Name: Lutz Prechelt
Version: 2.4.1
OS: Windows XP
Submission from: (NULL) (160.45.111.67)


'union' ignores the fact if its arguments are factors while all other set
operations (intersect, setdiff, setequal, is.element) treat them sensibly.
The manpage does not even mention the term 'factor'.

Example:
f1=factor(c("a","b","b","c"));
f2=factor(c("a","d","d","e"));
print(union(f1,f2));
print(intersect(f1,f2));
print(setdiff(f1,f2));
print(setequal(f1,f2));
print(is.element(f1,f2))

prints

[1] 1 2 3
[1] a
Levels: a d e
[1] b c
Levels: a b c
[1] FALSE
[1]  TRUE FALSE FALSE FALSE


From ripley at stats.ox.ac.uk  Thu Mar 29 12:59:19 2007
From: ripley at stats.ox.ac.uk (ripley at stats.ox.ac.uk)
Date: Thu, 29 Mar 2007 12:59:19 +0200 (CEST)
Subject: [Rd] (PR#9578) rbind.data.frame reacts on levels without
Message-ID: <20070329105919.A8ED95DE78@slim.kubism.ku.dk>

In your data frames, 'y' is a category and the following comment in the
code makes clear this is deliberate.

 		    if( !is.null(levels(xj)) ) {
 			all.levs[[j]] <- levels(xj)
                         facCol[j] <- TRUE # turn categories into factors
                     } else facCol[j] <- is.factor(xj)

The behaviour is compatible with S apart from the comment in the R help 
page.  That categories are promoted to factors is consistent with the help 
for 'category'.

It is not a bug, but the help page could say what happens for categories.

On Fri, 23 Mar 2007, Lutz Prechelt wrote:

> I am sorry.
> Here is a minimal example:
>
> a=data.frame(x=c(1:3),y=unclass(factor(c(5:7))))
> b=data.frame(x=c(11:13),y=unclass(factor(c(7:9))))
> rbind(a,b)
>
>  Lutz Prechelt
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Thu Mar 29 13:19:34 2007
From: ripley at stats.ox.ac.uk (ripley at stats.ox.ac.uk)
Date: Thu, 29 Mar 2007 13:19:34 +0200 (CEST)
Subject: [Rd] (PR#9589) 'union' does not handle factors while 'intersect'
Message-ID: <20070329111934.D5FC05DE7A@slim.kubism.ku.dk>

This is not a bug, nor is the subject line true: both do accept 
factors but what they do with factors is undocumented.  From the help 
(not 'man') page

      Performs *set* union, intersection, (asymmetric!) difference,
      equality and membership on two vectors.
                                     ^^^^^^^
so it is not said to work on factors.  I disagree that what intersect() 
for factors does is 'sensible': e.g. it is asymmetric in its arguments.

The 'standard' behaviour would be for R to coerce arguments to whatever 
they are documented to be, here using as.vector, and we will consider 
doing that.


On Thu, 29 Mar 2007, prechelt at inf.fu-berlin.de wrote:

> Full_Name: Lutz Prechelt
> Version: 2.4.1
> OS: Windows XP
> Submission from: (NULL) (160.45.111.67)
>
>
> 'union' ignores the fact if its arguments are factors while all other set
> operations (intersect, setdiff, setequal, is.element) treat them sensibly.
> The manpage does not even mention the term 'factor'.

Indeed, it excludes them as valid inputs.

> Example:
> f1=factor(c("a","b","b","c"));
> f2=factor(c("a","d","d","e"));
> print(union(f1,f2));
> print(intersect(f1,f2));
> print(setdiff(f1,f2));
> print(setequal(f1,f2));
> print(is.element(f1,f2))
>
> prints
>
> [1] 1 2 3
> [1] a
> Levels: a d e
> [1] b c
> Levels: a b c
> [1] FALSE
> [1]  TRUE FALSE FALSE FALSE
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From prechelt at inf.fu-berlin.de  Thu Mar 29 13:44:49 2007
From: prechelt at inf.fu-berlin.de (prechelt at inf.fu-berlin.de)
Date: Thu, 29 Mar 2007 13:44:49 +0200 (CEST)
Subject: [Rd] (PR#9578) rbind.data.frame reacts on levels without factor
Message-ID: <20070329114449.B4AD85AA6A@slim.kubism.ku.dk>

Brian wrote:
> In your data frames, 'y' is a category
...
> The behaviour is compatible with S apart from the comment in=20
> the R help=20
> page.  That categories are promoted to factors is consistent=20
> with the help for 'category'.

I have been around S and R for about 10 years, but had
never heard of categories before.
All information I get about categories via=20
  ?category=20
in R 2.4.1 is
  'category' has been an old-S function before there were factors;
  should be replaced by 'factor' throughout!

Maybe it's time to drop this particular backwards compatibility=20
feature from rbind?

  Lutz

> It is not a bug, but the help page could say what happens for=20
> categories.
>=20
> On Fri, 23 Mar 2007, Lutz Prechelt wrote:
>=20
> > I am sorry.
> > Here is a minimal example:
> >
> > a=3Ddata.frame(x=3Dc(1:3),y=3Dunclass(factor(c(5:7))))
> > b=3Ddata.frame(x=3Dc(11:13),y=3Dunclass(factor(c(7:9))))
> > rbind(a,b)


From b.rowlingson at lancaster.ac.uk  Thu Mar 29 14:07:29 2007
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Thu, 29 Mar 2007 13:07:29 +0100
Subject: [Rd] Bridging R to OpenOffice
In-Reply-To: <3B913F96-E9A0-4219-AEB4-00408E3D6055@sympatico.ca>
References: <Pine.LNX.4.44.0703281210390.31714-100000@reclus.nhh.no>	<200703280648.54111.sdavis2@mail.nih.gov>	<460A6B89.8030903@sun.com>	<200703280933.45736.sdavis2@mail.nih.gov>	<460A8C77.2040009@biostat.ku.dk>
	<3B913F96-E9A0-4219-AEB4-00408E3D6055@sympatico.ca>
Message-ID: <460BAC01.1080104@lancaster.ac.uk>

Kevin B. Hendricks wrote:

> As I remember, I think someone has built an interface from Gnumeric  
> to R if I am not mistaken.  That project if it is still alive might  
> provide a nice model of how to interface from a spreadsheet to R  
> without lots of GUI front end stuff being needed.  As I remember, it  
> just allowed a number of advanced features from R to be used from  
> within GNumeric (just as if you added an analysis toolpack to Excel)

It seems to me from looking at the R-Excel and R-Gnumeric connections 
that these things work at a cell-based level, where you can put a value 
in a cell from an R function (eg =rpois(4)) or you can transfer values 
back and forth to R objects from spreadsheet cells.

  But where's the bigger picture? Can we think at an analysis/sheet level?

  You could have your X and Y data in Sheet1, click some button, and 
then have a Sheet1_lm sheet appear, containing the information from R's 
summary(lm(Y~X)), columns of fitted values and residuals, and plots of 
fitted values vs residuals etc - the plots you get from plot(lm(Y~X)) - 
but made with the spreadsheet's plot engine rather than R's.

  Of course this may be a bit to spssxy for some.

  The cell-level access seems more trouble than its worth for anyone 
actually concerned with doing an analysis - they'd have to know R and 
would probably find it easier importing the data and doing it in R. I 
can only see it being worthwhile for creating a spreadsheet with a bunch 
of R code embedded in cells in order to pass a bespoke analysis on to 
someone with no R knowledge. Instead of saying "Here's my R Code to do 
heterogeneous boomsquaddling", and them going "Your what code?", you'd 
say, "here, load boomsquaddle.xls, stick your data in column A, the 
boomsquaddle factor appears in cell X23".

  Is anyone collecting actual R & spreadsheet use cases or is this a 
case of 'hey this would be a neat thing to do'?

Barry


From murdoch at stats.uwo.ca  Thu Mar 29 14:38:21 2007
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 29 Mar 2007 08:38:21 -0400
Subject: [Rd] Index for a package
In-Reply-To: <924946.77793.qm@web23401.mail.ird.yahoo.com>
References: <924946.77793.qm@web23401.mail.ird.yahoo.com>
Message-ID: <460BB33D.5030509@stats.uwo.ca>

On 3/29/2007 8:09 AM, fabio frascati wrote:
> Hi. I am Fabio Frascati and I am from Italy. I have a dubt about R: How can I have alphabetical index of my package index of  functions? Example:
>    
>                             --A--
>   aaa
>   aaab
>    
>                              --B--
>    
>   bbbbb
>   bbc
>    
>   Thank you,

Please ask questions like this on the R-devel mailing list, so everyone 
can see the answers (and can provide better ones).

When you install a package R will automatically create an index of the 
sort you want.  It will only break it up by starting letter ("--A--", 
etc.) if there are more than 100 entries.  The index is stored in 
RHOME/library/<package name>/html/00Index.html.

"R CMD Rd2dvi" will also create an alphabetical table of contents in 
various formats.  (I believe it's alphabetical by filename, but lists 
the internal name in the TOC; if those are different, it will appear not 
to be alphabetical.)

Duncan Murdoch


From sdavis2 at mail.nih.gov  Thu Mar 29 14:39:26 2007
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Thu, 29 Mar 2007 08:39:26 -0400
Subject: [Rd] Error building R-alpha (from 28-Mar-07, r40918)
Message-ID: <200703290839.26690.sdavis2@mail.nih.gov>

This could easily be my fault, but I don't see the same issue with r40902, so 
I am posting here:

% uname -a
Linux pressa 2.6.18.8-0.1-default #1 SMP Fri Mar 2 13:51:59 UTC 2007 x86_64 
x86_64 x86_64 GNU/Linux
% gcc -v
gcc version 4.1.2 20061115 (prerelease) (SUSE Linux)

On a fresh download of R-alpha (r40918):

configure ....
make ....
make install
....

mkdir -p -- /home/sdavis/R-alpha/lib64/R/include/R_ext
/usr/bin/install: cannot stat `./stats_stubs.c': No such file or directory
make[3]: *** [install] Error 1
make[3]: Leaving directory `/home/sdavis/source/R-alpha/src/include/R_ext'
make[2]: *** [install] Error 1
make[2]: Leaving directory `/home/sdavis/source/R-alpha/src/include'
make[1]: *** [install] Error 1
make[1]: Leaving directory `/home/sdavis/source/R-alpha/src'
make: *** [install] Error 1

Thanks,
Sean


From erich.neuwirth at univie.ac.at  Thu Mar 29 14:55:11 2007
From: erich.neuwirth at univie.ac.at (Erich Neuwirth)
Date: Thu, 29 Mar 2007 14:55:11 +0200
Subject: [Rd] Bridging R to OpenOffice
In-Reply-To: <4609655A.5070209@gmx.net>
References: <4609655A.5070209@gmx.net>
Message-ID: <460BB72F.1050209@univie.ac.at>

Since I implemented the RExcel interface I also would like this
discussion to be continued on r-devel or some other list where
I can follow it.

Let me add some thoughts:

As Leonhard Mada suggested, probably the most needed connection
between R and a spreadsheet program is a way to transfer
dataframes easily from the spreadsheet to R and analysis
results back from R to Excel. To do this, one needs to have a
mechanism to transfer large amounts of data of different types.
An additional complication for the way back fro R to the
spreadsheet is that R results quite often have data types not
supported by the spreadsheet program (complex numbers for
example).

The convenience tool that people really want in the first place
is an item on the menu which allows to transfer a range with
data from the spreadsheet to R.

The question then is: should the users see the R command line?
There has to be a way of telling R what kind of analysis to
perform. Using a menu like the one supplied by RCommander is a
sensible option. Using this also would reuse all the work
invested in designing a good menu structure for end users.

Getting results back into the spreadsheet is more difficult.
Not technically, but from the design point of view. Analysis
results in R usually are not arrays, but lists, i.e. compounds
of compounds of data of different basic types, and of different
sizes. There is no clear general rule how to put R results into
spreadsheet ranges. The basic compound data type in
spreadsheets are arrays, and the data types in R are much more
complicated, and the conceptual mapping of result lists to
spreadsheet ranges has to be designed differently for different
types of analyses and results. Of course, a brute force method
(implemented for example by the connection mechanism between
NAG and Excel) would be to "just print" the results into the
spreadsheet as strings. This way, spreadsheet rows become
printed lines without further structure, and numbers in the
results are not easily accessible for further computations on
the spreadsheet.

Such a "transfer data frame and get results" connection,
however, is not really using the spreadsheet program as a
spreadsheet program, but as a data grid and output formatting
machinery, since it is completely independent of the
spreadsheet program's most important feature, automatic
recalculation triggered by changes of cell values.

A really tight integration of R and a spreadsheet can extend
the spreadsheet program's computational engine by the complete
R engine. It could allow spreadsheet formulas like

RApply("pchisq",A1,A2)

which would have R compute the value of the chi-squared
distribution with arguments in cells A1 and A2 of the
spreadsheet. Changing the value in A1 would trigger R to
recalculate the chi-square value.

In this case, the connection between R and the spreadsheet
program has to be very fast, since the spreadsheet program
essentially is using R as a dynamically linked library. The
problem of incompatible data types also becomes much harder to
deal with. The results of R computations are directly put into
spreadsheet ranges, so having R results consisting of lists
makes things really difficult.

Thomas Baier and I recently published a paper in Computational
Statistics which discusses different models of integration
between R and spreadsheets. Excel is used as an example, but
the concepts are independent from the concrete implementation.

It is accessible at http://dx.doi.org/10.1007/s00180-007-0023-6
If you cannot access it, write to me, I will send you a copy.

Currently, we are working on a cross-platform alternative to using
COM to connect the spread-sheet to R. The platforms in mind are
(at least) Windows, Linux and MacOS (X). The spreadsheet program
of choice for our next integration will be Gnumeric, where the
integration is already worked on by students.



-- 
Erich Neuwirth, Didactic Center for Computer Science
University of Vienna
Visit our SunSITE at http://sunsite.univie.ac.at
Phone: +43-1-4277-39464 Fax: +43-1-4277-9394


From hin-tak.leung at cimr.cam.ac.uk  Thu Mar 29 16:02:19 2007
From: hin-tak.leung at cimr.cam.ac.uk (Hin-Tak Leung)
Date: Thu, 29 Mar 2007 15:02:19 +0100
Subject: [Rd] zlib+shlib issue with the official EL4 R binary
Message-ID: <460BC6EB.3010502@cimr.cam.ac.uk>

Hi,

I have got a curious issue with an R package which uses zlib, against
the official binary here:
http://cran.r-project.org/bin/linux/redhat/el4/i386/R-2.4.1-1.rh4AS.i386.rpm
on a Redhat EL4 i686 system.

The problem is that at the end of reading a gzip'ed file within my
C code, gzgetc() returns -1 (no more to read or error) but
gzeof() doesn't return true. Now one can probably jump to conclusion
that this is a zlib problem (or mine), but it is not. Here is
the summary table (my package binary is the same one on the four
2.4.1 cases below - built against the official EL4 binary on EL4)

Rver    shlib   buildhost   runhost    status of zlib code in mypackage
2.3.1   no      EL4         EL4        ok
2.4.1   no      EL4         EL4        ok
2.4.1   yes     EL4         EL4        broken
2.4.1   yes     EL4         FC6        ok
2.4.1   yes     FC6         FC6        ok

The most curious part is entry 3 vs 4 - if I just transplant
the official R binary for EL4 and run it on FC6 (x86_64 and
loading the same mypackage i686 binary), then it works.
The dynamic linker on FC6 is very different from all the earlier
redhat releases [and supposedly a lot faster...]. 
(http://docs.fedoraproject.org/release-notes/fc6/en_US/sn-Devel.html#id2956225)

so it looks like an issue due to a bad interaction for the
combination of both the shlib compile-time option and the EL4
runtime environment. (e.g. R 2.4.1 is shipped and bundled with
zlib 1.2.3 but EL4 is only equiped with zlib 1.2.1.2...).

For the moment I'll just recommend anybody who needs to run my
package (snpMatrix in http://www-gene.cimr.cam.ac.uk/clayton/software/)
on Redhat EL4 to just build and install R from source, since shlib=no
is the default for compiling from source.

Anybody has any idea how this strange brokenness of zlib might happen?

Hin-Tak Leung


From ripley at stats.ox.ac.uk  Thu Mar 29 16:24:28 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 29 Mar 2007 15:24:28 +0100 (BST)
Subject: [Rd] zlib+shlib issue with the official EL4 R binary
In-Reply-To: <460BC6EB.3010502@cimr.cam.ac.uk>
References: <460BC6EB.3010502@cimr.cam.ac.uk>
Message-ID: <Pine.LNX.4.64.0703291522480.24561@auk.stats>

I presume you are talking about RPMs built with --with-system-zlib?

That's not recommended in the R-admin manual, and perhaps you can persuade 
Martyn Plummer not to do it.

On Thu, 29 Mar 2007, Hin-Tak Leung wrote:

> Hi,
>
> I have got a curious issue with an R package which uses zlib, against
> the official binary here:
> http://cran.r-project.org/bin/linux/redhat/el4/i386/R-2.4.1-1.rh4AS.i386.rpm
> on a Redhat EL4 i686 system.
>
> The problem is that at the end of reading a gzip'ed file within my
> C code, gzgetc() returns -1 (no more to read or error) but
> gzeof() doesn't return true. Now one can probably jump to conclusion
> that this is a zlib problem (or mine), but it is not. Here is
> the summary table (my package binary is the same one on the four
> 2.4.1 cases below - built against the official EL4 binary on EL4)
>
> Rver    shlib   buildhost   runhost    status of zlib code in mypackage
> 2.3.1   no      EL4         EL4        ok
> 2.4.1   no      EL4         EL4        ok
> 2.4.1   yes     EL4         EL4        broken
> 2.4.1   yes     EL4         FC6        ok
> 2.4.1   yes     FC6         FC6        ok
>
> The most curious part is entry 3 vs 4 - if I just transplant
> the official R binary for EL4 and run it on FC6 (x86_64 and
> loading the same mypackage i686 binary), then it works.
> The dynamic linker on FC6 is very different from all the earlier
> redhat releases [and supposedly a lot faster...].
> (http://docs.fedoraproject.org/release-notes/fc6/en_US/sn-Devel.html#id2956225)
>
> so it looks like an issue due to a bad interaction for the
> combination of both the shlib compile-time option and the EL4
> runtime environment. (e.g. R 2.4.1 is shipped and bundled with
> zlib 1.2.3 but EL4 is only equiped with zlib 1.2.1.2...).
>
> For the moment I'll just recommend anybody who needs to run my
> package (snpMatrix in http://www-gene.cimr.cam.ac.uk/clayton/software/)
> on Redhat EL4 to just build and install R from source, since shlib=no
> is the default for compiling from source.
>
> Anybody has any idea how this strange brokenness of zlib might happen?
>
> Hin-Tak Leung
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Thu Mar 29 16:49:04 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 29 Mar 2007 15:49:04 +0100 (BST)
Subject: [Rd] zlib+shlib issue with the official EL4 R binary
In-Reply-To: <Pine.LNX.4.64.0703291522480.24561@auk.stats>
References: <460BC6EB.3010502@cimr.cam.ac.uk>
	<Pine.LNX.4.64.0703291522480.24561@auk.stats>
Message-ID: <Pine.LNX.4.64.0703291539130.17915@gannet.stats.ox.ac.uk>

On Thu, 29 Mar 2007, Prof Brian Ripley wrote:

> I presume you are talking about RPMs built with --with-system-zlib?
>
> That's not recommended in the R-admin manual, and perhaps you can persuade
> Martyn Plummer not to do it.

I've checked, and he no longer does so, sorry.  So there is a zlib inside 
R, and its entry points will be visible to a packages' .so when R is built 
as a binary, but not when it is built as a shared library.  In that case 
it depends on the fine details (including of what you did) whether
mypackage.so resolved against R.bin or libz.so in the first two lines of 
your table.  But it is entirely possible that it links against R.bin in 
line 2 and libz.so in line 3.

If your program is that sensitive to the version of libz I think you 
should statically link against your own copy (which is R's solution for 
its own purposes).

>
> On Thu, 29 Mar 2007, Hin-Tak Leung wrote:
>
>> Hi,
>>
>> I have got a curious issue with an R package which uses zlib, against
>> the official binary here:
>> http://cran.r-project.org/bin/linux/redhat/el4/i386/R-2.4.1-1.rh4AS.i386.rpm
>> on a Redhat EL4 i686 system.
>>
>> The problem is that at the end of reading a gzip'ed file within my
>> C code, gzgetc() returns -1 (no more to read or error) but
>> gzeof() doesn't return true. Now one can probably jump to conclusion
>> that this is a zlib problem (or mine), but it is not. Here is
>> the summary table (my package binary is the same one on the four
>> 2.4.1 cases below - built against the official EL4 binary on EL4)
>>
>> Rver    shlib   buildhost   runhost    status of zlib code in mypackage
>> 2.3.1   no      EL4         EL4        ok
>> 2.4.1   no      EL4         EL4        ok
>> 2.4.1   yes     EL4         EL4        broken
>> 2.4.1   yes     EL4         FC6        ok
>> 2.4.1   yes     FC6         FC6        ok
>>
>> The most curious part is entry 3 vs 4 - if I just transplant
>> the official R binary for EL4 and run it on FC6 (x86_64 and
>> loading the same mypackage i686 binary), then it works.
>> The dynamic linker on FC6 is very different from all the earlier
>> redhat releases [and supposedly a lot faster...].
>> (http://docs.fedoraproject.org/release-notes/fc6/en_US/sn-Devel.html#id2956225)
>>
>> so it looks like an issue due to a bad interaction for the
>> combination of both the shlib compile-time option and the EL4
>> runtime environment. (e.g. R 2.4.1 is shipped and bundled with
>> zlib 1.2.3 but EL4 is only equiped with zlib 1.2.1.2...).
>>
>> For the moment I'll just recommend anybody who needs to run my
>> package (snpMatrix in http://www-gene.cimr.cam.ac.uk/clayton/software/)
>> on Redhat EL4 to just build and install R from source, since shlib=no
>> is the default for compiling from source.
>>
>> Anybody has any idea how this strange brokenness of zlib might happen?
>>
>> Hin-Tak Leung
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From hin-tak.leung at cimr.cam.ac.uk  Thu Mar 29 16:49:58 2007
From: hin-tak.leung at cimr.cam.ac.uk (Hin-Tak Leung)
Date: Thu, 29 Mar 2007 15:49:58 +0100
Subject: [Rd] zlib+shlib issue with the official EL4 R binary
In-Reply-To: <Pine.LNX.4.64.0703291522480.24561@auk.stats>
References: <460BC6EB.3010502@cimr.cam.ac.uk>
	<Pine.LNX.4.64.0703291522480.24561@auk.stats>
Message-ID: <460BD216.8080803@cimr.cam.ac.uk>

Prof Brian Ripley wrote:
> I presume you are talking about RPMs built with --with-system-zlib?
> 
> That's not recommended in the R-admin manual, and perhaps you can 
> persuade Martyn Plummer not to do it.

Not quite - the problematic option seems to be "--enable-R-shlib" which 
the official RPM was built with (I know there are good reasons, such
as various embedded uses).
I have actually three 2.4.1 R binaries on EL4:
(1) official rpm (linked below)
(2) ./configure ; make   (; make distclean)
(3) ./configure --enable-R-shlib ; make   (; make distclean)

I have repeat step 2/3 twice (i.e. 2->3->2->3 to make sure it
is --enable-R-shlib .

I don't think the system zlib is broken per se, because when R is
not built with shlib, my package is linked with the system zlib anyway
(via PKG_LIBS) and it does work correctly when linked against system
zlib.

(I have actually tried R CMD SHLIB *.c and fiddle with the last line
and manually make my package's shared lib statically linked to zlib,
- via copying libz.a to somewhere and doing -L there - but it
doesn't seem to help at all).

Hin-Tak

> On Thu, 29 Mar 2007, Hin-Tak Leung wrote:
> 
>> Hi,
>>
>> I have got a curious issue with an R package which uses zlib, against
>> the official binary here:
>> http://cran.r-project.org/bin/linux/redhat/el4/i386/R-2.4.1-1.rh4AS.i386.rpm 
>>
>> on a Redhat EL4 i686 system.
>>
>> The problem is that at the end of reading a gzip'ed file within my
>> C code, gzgetc() returns -1 (no more to read or error) but
>> gzeof() doesn't return true. Now one can probably jump to conclusion
>> that this is a zlib problem (or mine), but it is not. Here is
>> the summary table (my package binary is the same one on the four
>> 2.4.1 cases below - built against the official EL4 binary on EL4)
>>
>> Rver    shlib   buildhost   runhost    status of zlib code in mypackage
>> 2.3.1   no      EL4         EL4        ok
>> 2.4.1   no      EL4         EL4        ok
>> 2.4.1   yes     EL4         EL4        broken
>> 2.4.1   yes     EL4         FC6        ok
>> 2.4.1   yes     FC6         FC6        ok
>>
>> The most curious part is entry 3 vs 4 - if I just transplant
>> the official R binary for EL4 and run it on FC6 (x86_64 and
>> loading the same mypackage i686 binary), then it works.
>> The dynamic linker on FC6 is very different from all the earlier
>> redhat releases [and supposedly a lot faster...].
>> (http://docs.fedoraproject.org/release-notes/fc6/en_US/sn-Devel.html#id2956225) 
>>
>>
>> so it looks like an issue due to a bad interaction for the
>> combination of both the shlib compile-time option and the EL4
>> runtime environment. (e.g. R 2.4.1 is shipped and bundled with
>> zlib 1.2.3 but EL4 is only equiped with zlib 1.2.1.2...).
>>
>> For the moment I'll just recommend anybody who needs to run my
>> package (snpMatrix in http://www-gene.cimr.cam.ac.uk/clayton/software/)
>> on Redhat EL4 to just build and install R from source, since shlib=no
>> is the default for compiling from source.
>>
>> Anybody has any idea how this strange brokenness of zlib might happen?
>>
>> Hin-Tak Leung
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>


From sfalcon at fhcrc.org  Thu Mar 29 16:57:02 2007
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Thu, 29 Mar 2007 07:57:02 -0700
Subject: [Rd] Suggestion for memory optimization and as.double() with
	friends
In-Reply-To: <Pine.LNX.4.64.0703290256240.6919@gannet.stats.ox.ac.uk> (Brian
	Ripley's message of "Thu, 29 Mar 2007 03:11:18 +0100 (BST)")
References: <59d7961d0703281425n161a100lf4fb36bcf95ac742@mail.gmail.com>
	<460AE657.9040402@stats.uwo.ca>
	<Pine.LNX.4.64.0703290256240.6919@gannet.stats.ox.ac.uk>
Message-ID: <m21wj8ksht.fsf@ziti.fhcrc.org>

Prof Brian Ripley <ripley at stats.ox.ac.uk> writes:
> The usual 'trick' to avoid this copy is
>
> storage.mode(x) <- "double"

Hmm, this does not appear to avoid the copy for me.  Using R 2.5.0
alpha r40916 I get:

    > x <- 1:10 * 2.3
    > names(x)=LETTERS[1:10]
    > storage.mode(x)
    [1] "double"
    > tracemem(x)
    [1] "<0x2a7f008>"
    > storage.mode(x) <- "double"
    tracemem[0x2a7f008 -> 0x1fa6df8]: 

Note that actually changing the storage results in a surprising amount
of copying:

    > storage.mode(x) <- "integer"
    tracemem[0x1fa6df8 -> 0x1fa6d60]: 
    tracemem[0x1fa6d60 -> 0x1fa6808]: as.integer.default as.integer eval eval storage.mode<- 
    tracemem[0x1fa6808 -> 0x2c26b18]: as.integer.default as.integer eval eval storage.mode<- 
    tracemem[0x2c26b18 -> 0x2c26a88]: storage.mode<- 


+ seth

-- 
Seth Falcon | Computational Biology | Fred Hutchinson Cancer Research Center
http://bioconductor.org


From hin-tak.leung at cimr.cam.ac.uk  Thu Mar 29 16:59:30 2007
From: hin-tak.leung at cimr.cam.ac.uk (Hin-Tak Leung)
Date: Thu, 29 Mar 2007 15:59:30 +0100
Subject: [Rd] zlib+shlib issue with the official EL4 R binary
In-Reply-To: <Pine.LNX.4.64.0703291539130.17915@gannet.stats.ox.ac.uk>
References: <460BC6EB.3010502@cimr.cam.ac.uk>
	<Pine.LNX.4.64.0703291522480.24561@auk.stats>
	<Pine.LNX.4.64.0703291539130.17915@gannet.stats.ox.ac.uk>
Message-ID: <460BD452.2030705@cimr.cam.ac.uk>

Prof Brian Ripley wrote:
> On Thu, 29 Mar 2007, Prof Brian Ripley wrote:
> 
>> I presume you are talking about RPMs built with --with-system-zlib?
>>
>> That's not recommended in the R-admin manual, and perhaps you can 
>> persuade
>> Martyn Plummer not to do it.
> 
> I've checked, and he no longer does so, sorry.  So there is a zlib 
> inside R, and its entry points will be visible to a packages' .so when R 
> is built as a binary, but not when it is built as a shared library.  In 
> that case it depends on the fine details (including of what you did) 
> whether
> mypackage.so resolved against R.bin or libz.so in the first two lines of 
> your table.  But it is entirely possible that it links against R.bin in 
> line 2 and libz.so in line 3.
> 
> If your program is that sensitive to the version of libz I think you 
> should statically link against your own copy (which is R's solution for 
> its own purposes).

Hmm, I have always thought it is the reverse - i.e. when R is built
with shlib, the internal version of zlib is exposed to packages' so?

gzeof() is just for detecting end of file - I don't think it is
a "sensitive" use of zlib. It is just better to be able to tell when
read failed, whether one has *actually* reach end of file or not.

I'll try bundling the latest zlib with my package and see if it
makes any differences... thanks!

Hin-Tak

>> On Thu, 29 Mar 2007, Hin-Tak Leung wrote:
>>
>>> Hi,
>>>
>>> I have got a curious issue with an R package which uses zlib, against
>>> the official binary here:
>>> http://cran.r-project.org/bin/linux/redhat/el4/i386/R-2.4.1-1.rh4AS.i386.rpm 
>>>
>>> on a Redhat EL4 i686 system.
>>>
>>> The problem is that at the end of reading a gzip'ed file within my
>>> C code, gzgetc() returns -1 (no more to read or error) but
>>> gzeof() doesn't return true. Now one can probably jump to conclusion
>>> that this is a zlib problem (or mine), but it is not. Here is
>>> the summary table (my package binary is the same one on the four
>>> 2.4.1 cases below - built against the official EL4 binary on EL4)
>>>
>>> Rver    shlib   buildhost   runhost    status of zlib code in mypackage
>>> 2.3.1   no      EL4         EL4        ok
>>> 2.4.1   no      EL4         EL4        ok
>>> 2.4.1   yes     EL4         EL4        broken
>>> 2.4.1   yes     EL4         FC6        ok
>>> 2.4.1   yes     FC6         FC6        ok
>>>
>>> The most curious part is entry 3 vs 4 - if I just transplant
>>> the official R binary for EL4 and run it on FC6 (x86_64 and
>>> loading the same mypackage i686 binary), then it works.
>>> The dynamic linker on FC6 is very different from all the earlier
>>> redhat releases [and supposedly a lot faster...].
>>> (http://docs.fedoraproject.org/release-notes/fc6/en_US/sn-Devel.html#id2956225) 
>>>
>>>
>>> so it looks like an issue due to a bad interaction for the
>>> combination of both the shlib compile-time option and the EL4
>>> runtime environment. (e.g. R 2.4.1 is shipped and bundled with
>>> zlib 1.2.3 but EL4 is only equiped with zlib 1.2.1.2...).
>>>
>>> For the moment I'll just recommend anybody who needs to run my
>>> package (snpMatrix in http://www-gene.cimr.cam.ac.uk/clayton/software/)
>>> on Redhat EL4 to just build and install R from source, since shlib=no
>>> is the default for compiling from source.
>>>
>>> Anybody has any idea how this strange brokenness of zlib might happen?
>>>
>>> Hin-Tak Leung
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>
>>
>


From kevin.hendricks at sympatico.ca  Thu Mar 29 17:18:29 2007
From: kevin.hendricks at sympatico.ca (Kevin B. Hendricks)
Date: Thu, 29 Mar 2007 11:18:29 -0400
Subject: [Rd] Bridging R to OpenOffice
In-Reply-To: <460BB72F.1050209@univie.ac.at>
References: <4609655A.5070209@gmx.net> <460BB72F.1050209@univie.ac.at>
Message-ID: <05DA3D56-444E-4733-A77E-3FFF8CC531D7@sympatico.ca>

Hi,

On Mar 29, 2007, at 8:55 AM, Erich Neuwirth wrote:
> It is accessible at http://dx.doi.org/10.1007/s00180-007-0023-6
> If you cannot access it, write to me, I will send you a copy.
>
> Currently, we are working on a cross-platform alternative to using
> COM to connect the spread-sheet to R. The platforms in mind are
> (at least) Windows, Linux and MacOS (X). The spreadsheet program
> of choice for our next integration will be Gnumeric, where the
> integration is already worked on by students.


Thanks for that link.  I read the paper and I think that 80% to 90%  
of the work you have done would be directly translateable into  
OpenOffice.org (OOo).  OOo uses it own component object model UNO and  
it can abstract its interfaces in similar ways and can employ  
embedding of objects (including the entire application) in much the  
same way.  OOo spreadsheet has its own Basic programming language  
interface (some work has been done by the Novell people to actually  
enable extend the OOo Basic object model to translate and run VBA  
macros).

The ideas and concepts behind how you interfaced R and Excel in the  
paper should be almost exactly the same as how OOo and R could be  
integrated.  The UNO component model is already cross-platform and  
network based (OOo runs on Mac, Windows, Linux, Solaris, some BSD's  
etc).  Bridges for C++ - UNO, C - UNO, Java - UNO, Python - UNO, and  
obviously back already exist for multiple processors, multiple  
compilers, and multiple operating systems.   Similarly to MS Office,  
each application in OOo is actually its own component (I once played  
around with a Java app that embedded all of Calc in it with only a  
few lines of code).  And of course, OOo is fully LGPL now.

Given that Calc will most probably rapidly replace GNumeric as the  
GNU/OSS spreadsheet of choice (it already replaced GNumeric in the  
GNome Desktop office environment) and given the UNO cross-platform  
component model already exists (and I believe was modeled after DCOM/ 
COM), someone may be able to take the source code and rcom package  
talked about in the paper and convert it with hopefully minimal pain  
to create an runo package and associated source code that would use  
OOo's Basic and not VBA to create an Add-In.

FWIW,

Kevin


From ripley at stats.ox.ac.uk  Thu Mar 29 17:47:05 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 29 Mar 2007 16:47:05 +0100 (BST)
Subject: [Rd] zlib+shlib issue with the official EL4 R binary
In-Reply-To: <460BD452.2030705@cimr.cam.ac.uk>
References: <460BC6EB.3010502@cimr.cam.ac.uk>
	<Pine.LNX.4.64.0703291522480.24561@auk.stats>
	<Pine.LNX.4.64.0703291539130.17915@gannet.stats.ox.ac.uk>
	<460BD452.2030705@cimr.cam.ac.uk>
Message-ID: <Pine.LNX.4.64.0703291625230.30037@gannet.stats.ox.ac.uk>

On Thu, 29 Mar 2007, Hin-Tak Leung wrote:

> Prof Brian Ripley wrote:
>> On Thu, 29 Mar 2007, Prof Brian Ripley wrote:
>> 
>>> I presume you are talking about RPMs built with --with-system-zlib?
>>> 
>>> That's not recommended in the R-admin manual, and perhaps you can persuade
>>> Martyn Plummer not to do it.
>> 
>> I've checked, and he no longer does so, sorry.  So there is a zlib inside 
>> R, and its entry points will be visible to a packages' .so when R is built 
>> as a binary, but not when it is built as a shared library.  In that case it 
>> depends on the fine details (including of what you did) whether
>> mypackage.so resolved against R.bin or libz.so in the first two lines of 
>> your table.  But it is entirely possible that it links against R.bin in 
>> line 2 and libz.so in line 3.
>> 
>> If your program is that sensitive to the version of libz I think you should 
>> statically link against your own copy (which is R's solution for its own 
>> purposes).
>
> Hmm, I have always thought it is the reverse - i.e. when R is built
> with shlib, the internal version of zlib is exposed to packages' so?

My belief is that the systems you are considering support visibility 
attributes (but I don't know for sure about EL4 since Redhat versions of 
tools do when the standard ones do not).  If so, libR.so does not export 
the zlib entry points.

> gzeof() is just for detecting end of file - I don't think it is
> a "sensitive" use of zlib. It is just better to be able to tell when
> read failed, whether one has *actually* reach end of file or not.

sensitive _to a particular bug_  There has been such a bug: see the 
comments in gzfile_fgetc and its history.

> I'll try bundling the latest zlib with my package and see if it
> makes any differences... thanks!
>
> Hin-Tak
>
>>> On Thu, 29 Mar 2007, Hin-Tak Leung wrote:
>>> 
>>>> Hi,
>>>> 
>>>> I have got a curious issue with an R package which uses zlib, against
>>>> the official binary here:
>>>> http://cran.r-project.org/bin/linux/redhat/el4/i386/R-2.4.1-1.rh4AS.i386.rpm 
>>>> on a Redhat EL4 i686 system.
>>>> 
>>>> The problem is that at the end of reading a gzip'ed file within my
>>>> C code, gzgetc() returns -1 (no more to read or error) but
>>>> gzeof() doesn't return true. Now one can probably jump to conclusion
>>>> that this is a zlib problem (or mine), but it is not. Here is
>>>> the summary table (my package binary is the same one on the four
>>>> 2.4.1 cases below - built against the official EL4 binary on EL4)
>>>> 
>>>> Rver    shlib   buildhost   runhost    status of zlib code in mypackage
>>>> 2.3.1   no      EL4         EL4        ok
>>>> 2.4.1   no      EL4         EL4        ok
>>>> 2.4.1   yes     EL4         EL4        broken
>>>> 2.4.1   yes     EL4         FC6        ok
>>>> 2.4.1   yes     FC6         FC6        ok
>>>> 
>>>> The most curious part is entry 3 vs 4 - if I just transplant
>>>> the official R binary for EL4 and run it on FC6 (x86_64 and
>>>> loading the same mypackage i686 binary), then it works.
>>>> The dynamic linker on FC6 is very different from all the earlier
>>>> redhat releases [and supposedly a lot faster...].
>>>> (http://docs.fedoraproject.org/release-notes/fc6/en_US/sn-Devel.html#id2956225) 
>>>> 
>>>> so it looks like an issue due to a bad interaction for the
>>>> combination of both the shlib compile-time option and the EL4
>>>> runtime environment. (e.g. R 2.4.1 is shipped and bundled with
>>>> zlib 1.2.3 but EL4 is only equiped with zlib 1.2.1.2...).
>>>> 
>>>> For the moment I'll just recommend anybody who needs to run my
>>>> package (snpMatrix in http://www-gene.cimr.cam.ac.uk/clayton/software/)
>>>> on Redhat EL4 to just build and install R from source, since shlib=no
>>>> is the default for compiling from source.
>>>> 
>>>> Anybody has any idea how this strange brokenness of zlib might happen?
>>>> 
>>>> Hin-Tak Leung
>>>> 
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>> 
>>> 
>>> 
>> 
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Thu Mar 29 18:31:06 2007
From: ripley at stats.ox.ac.uk (ripley at stats.ox.ac.uk)
Date: Thu, 29 Mar 2007 18:31:06 +0200 (CEST)
Subject: [Rd] R4.1: seq.POSIXt, tz="AEST" (PR#9572)
Message-ID: <20070329163106.A5F3C5DE81@slim.kubism.ku.dk>

I think I have managed to track this down, but only by setting a Windows 
box to that timezone via the control panel.

One cannot set a timezone in Windows to one with Australian DST settings, 
and according to my Linux machine you were in DST on 1968-02-28.  That's 
the problem as we compare 1968 with a later year to find the DST settings, 
and during those calculations Windows 'corrects' the tm structure (it is 
not supposed to according to POSIX).

A workaround to the non-POSIX compliance will appear in 2.5.0.

On Tue, 20 Mar 2007, Felix Andrews wrote:

> I am sorry, "AEST" was wrong. I can't work out what timezone code it is, but
> my default timezone here in eastern australia prints as:
>> as.POSIXct("1970-01-01", tz="")
> [1] "1970-01-01 AUS Eastern Daylight Time"
>
> and that is the one that has repeated dates before 1970.
>
> But I take your point that it is fundamentally a problem with Windows.
>
> --Felix
>
>
> On 3/19/07, Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
>> 
>> Hmm, AEST is not a valid time zone on Windows.
>> See ?as.POSIXlt for one of several places where this is documented.
>> 
>> But in any case, the underlying problem is in the OS, and we only try to
>> work around it to the best of our knowledge (and that excludes
>> undocumented time zones).
>> 
>> 
>> On Mon, 19 Mar 2007, felix at nfrac.org wrote:
>> 
>> > Times from seq.POSIXt come out wrong in AEST timezone around Feb 29
>> every
>> > leap year before 1970 (on Windows XP).
>> >
>> > According to help(DateTimeClasses), this is handled by "our own C code".
>> >
>> >> x <- as.POSIXct("1968-02-27") # tz="AEST"
>> >> x.gmt <- as.POSIXct("1968-02-27", tz="GMT")
>> >> data.frame(
>> >     GMT=seq(x.gmt, by="day", length=8),
>> >     byday=seq(x, by="day", length=8),
>> >     byDST=seq(x, by="DSTday", length=8))
>> >         GMT      byday      byDST
>> > 1 1968-02-27 1968-02-27 1968-02-27
>> > 2 1968-02-28 1968-02-28 1968-02-28
>> > 3 1968-02-29 1968-03-01 1968-03-02
>> > 4 1968-03-01 1968-03-02 1968-03-02
>> > 5 1968-03-02 1968-03-02 1968-03-02
>> > 6 1968-03-03 1968-03-03 1968-03-03
>> > 7 1968-03-04 1968-03-04 1968-03-04
>> > 8 1968-03-05 1968-03-05 1968-03-05
>> >
>> >> R.version
>> >               _
>> > platform       i386-pc-mingw32
>> > arch           i386
>> > os             mingw32
>> > system         i386, mingw32
>> > status
>> > major          2
>> > minor          4.1
>> > year           2006
>> > month          12
>> > day            18
>> > svn rev        40228
>> > language       R
>> > version.string R version 2.4.1 (2006-12-18)
>> >
>> >
>> >
>> >
>> 
>> --
>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>> University of Oxford,             Tel:  +44 1865 272861 (self)
>> 1 South Parks Road,                     +44 1865 272866 (PA)
>> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>> 
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From hin-tak.leung at cimr.cam.ac.uk  Thu Mar 29 19:55:40 2007
From: hin-tak.leung at cimr.cam.ac.uk (Hin-Tak Leung)
Date: Thu, 29 Mar 2007 18:55:40 +0100
Subject: [Rd] zlib+shlib issue with the official EL4 R binary
In-Reply-To: <Pine.LNX.4.64.0703291625230.30037@gannet.stats.ox.ac.uk>
References: <460BC6EB.3010502@cimr.cam.ac.uk>
	<Pine.LNX.4.64.0703291522480.24561@auk.stats>
	<Pine.LNX.4.64.0703291539130.17915@gannet.stats.ox.ac.uk>
	<460BD452.2030705@cimr.cam.ac.uk>
	<Pine.LNX.4.64.0703291625230.30037@gannet.stats.ox.ac.uk>
Message-ID: <460BFD9C.5090208@cimr.cam.ac.uk>

Prof Brian Ripley wrote:
> On Thu, 29 Mar 2007, Hin-Tak Leung wrote:
> 
>> Prof Brian Ripley wrote:
>>> On Thu, 29 Mar 2007, Prof Brian Ripley wrote:
>>>
>>>> I presume you are talking about RPMs built with --with-system-zlib?
>>>>
>>>> That's not recommended in the R-admin manual, and perhaps you can 
>>>> persuade
>>>> Martyn Plummer not to do it.
>>>
>>> I've checked, and he no longer does so, sorry.  So there is a zlib 
>>> inside R, and its entry points will be visible to a packages' .so 
>>> when R is built as a binary, but not when it is built as a shared 
>>> library.  In that case it depends on the fine details (including of 
>>> what you did) whether
>>> mypackage.so resolved against R.bin or libz.so in the first two lines 
>>> of your table.  But it is entirely possible that it links against 
>>> R.bin in line 2 and libz.so in line 3.
>>>
>>> If your program is that sensitive to the version of libz I think you 
>>> should statically link against your own copy (which is R's solution 
>>> for its own purposes).
>>
>> Hmm, I have always thought it is the reverse - i.e. when R is built
>> with shlib, the internal version of zlib is exposed to packages' so?
> 
> My belief is that the systems you are considering support visibility 
> attributes (but I don't know for sure about EL4 since Redhat versions of 
> tools do when the standard ones do not).  If so, libR.so does not export 
> the zlib entry points.

Indeed, "nm libR.so | grep gz" shows the zlib symbols as
local (lowercase "t").

I can also confirm that just bundling the zlib source (12 *.c and
10 *.h files, stripped of not-interesting stuff) and remove
PKG_LIBS=-lz gives the correct behavior.

Thanks a lot for your insights.

Hin-Tak


From bates at stat.wisc.edu  Thu Mar 29 20:03:05 2007
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 29 Mar 2007 13:03:05 -0500
Subject: [Rd] Developer work cycle
In-Reply-To: <4607F803.7060700@decsai.ugr.es>
References: <4607F803.7060700@decsai.ugr.es>
Message-ID: <40e66e0b0703291103m2ff62deej1af424ab1de13ab@mail.gmail.com>

On 3/26/07, "Jos? Luis Aznarte M." <jlaznarte at decsai.ugr.es> wrote:
>     Hi! I've been browsing through the last months' archive and I can't
> find an answer to my question, so here it is (let's hope it's not too
> obvious):
>     I'm working on extensions of an R library, and I would be very
> surprised if everyone developing R packages is doing the following, as I do:
>
>         1.- Write down a modification of an R file
>         2.- Exit the current R session
>         3.- Install the package as root (sudo R CMD INSTALL...)
>         4.- Launch a new R session
>         5.- Test the change, if it does not work, go back to 1 or debug.
>         6.- Finish.
>
>     Is this the proper (but quite awkward) way to proceed or there is an
> alternative to skip steps 2 to 4? I'm using emacs with ESS under linux.

John Chambers has provided an alternative approach of using

trace(fname, edit = TRUE)

where fname is the name of your function.  (Make sure that the server
for emacsclient has been started in your emacs session with M-x
server-start.)  This opens an emacs buffer containing the source for
the function which you can then edit.  After writing the file and
closing the client (C-x #) your ESS session has the new definition
installed in the package's namespace.

This will work even for objects hidden in the namespace.  The argument
"signature" allows you to edit S4 methods on the fly like this.  In my
experience you cannot edit registered S3 methods like this but it may
be that I am just not using trace correctly.

Of course you must copy the modified version of the source code to
your package sources when you are done.

As others have indicated, it is a good practice to install development
versions of packages in a private library so you do not need to use
sudo or worry about messing up system-wide directories.


From thomas.friedrichsmeier at ruhr-uni-bochum.de  Thu Mar 29 21:39:16 2007
From: thomas.friedrichsmeier at ruhr-uni-bochum.de (Thomas Friedrichsmeier)
Date: Thu, 29 Mar 2007 21:39:16 +0200
Subject: [Rd] small bug in ansari.test
Message-ID: <200703292139.21253.thomas.friedrichsmeier@ruhr-uni-bochum.de>

The help page for ansari.test() says (emphasis added):

	By default (if exact is not specified), an exact p-value is computed if both 	
samples contain less than 50 finite values **and there are no ties**. 
Otherwise, a normal approximation is used.

However, this does not appear to be the case in R 2.4.1 or R 2.5.0. In fact, 
even

	example(ansari.test)

produces a warning

	Warning message:
	cannot compute exact p-value with ties in: ansari.test.default(ramsay, 
jung.parekh)

although the "exact" parameter is omitted.

Patch:

Index: src/library/stats/R/ansari.test.R
===================================================================
--- src/library/stats/R/ansari.test.R   (revision 40902)
+++ src/library/stats/R/ansari.test.R   (working copy)
@@ -29,7 +29,7 @@
     TIES <- (length(r) != length(unique(r)))

     if(is.null(exact))
-        exact <- ((m < 50) && (n < 50))
+        exact <- ((m < 50) && (n < 50) && (!TIES))

     if(exact && !TIES) {
         pansari <- function(q, m, n) {


Regards
Thomas Friedrichsmeier
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 189 bytes
Desc: not available
Url : https://stat.ethz.ch/pipermail/r-devel/attachments/20070329/16ab7353/attachment.bin 

From thomas.friedrichsmeier at ruhr-uni-bochum.de  Thu Mar 29 21:49:35 2007
From: thomas.friedrichsmeier at ruhr-uni-bochum.de (Thomas Friedrichsmeier)
Date: Thu, 29 Mar 2007 21:49:35 +0200
Subject: [Rd] small bug in ansari.test
In-Reply-To: <200703292139.21253.thomas.friedrichsmeier@ruhr-uni-bochum.de>
References: <200703292139.21253.thomas.friedrichsmeier@ruhr-uni-bochum.de>
Message-ID: <200703292149.39133.thomas.friedrichsmeier@ruhr-uni-bochum.de>

On Thursday 29 March 2007 21:39, Thomas Friedrichsmeier wrote:
> The help page for ansari.test() says (emphasis added):
>
> 	By default (if exact is not specified), an exact p-value is computed if
> both samples contain less than 50 finite values **and there are no ties**.
> Otherwise, a normal approximation is used.
>
> However, this does not appear to be the case in R 2.4.1 or R 2.5.0.

Well, to be precise, the exact p-value really isn't computed in this case, but 
there's still the warning, as though exact=TRUE had been specified, which I 
don't believe is intended.

Regards
Thomas Friedrichsmeier
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 189 bytes
Desc: not available
Url : https://stat.ethz.ch/pipermail/r-devel/attachments/20070329/1e62cf91/attachment.bin 

From ross at biostat.ucsf.edu  Thu Mar 29 22:20:30 2007
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Thu, 29 Mar 2007 13:20:30 -0700
Subject: [Rd] Rmpi and OpenMPI ?
In-Reply-To: <17929.54296.884935.214790@basebud.nulle.part>
References: <17929.54296.884935.214790@basebud.nulle.part>
Message-ID: <1175199630.26829.197.camel@iron.psg.net>

On Tue, 2007-03-27 at 21:34 -0500, Dirk Eddelbuettel wrote:
> Has anybody tried to use Rmpi with the OpenMPI library instead of LAM/MPI?
> 
> LAM appears to be somewhat hardcoded in the Rmpi setup. Before I start to
> experiment with changing this, has anybody else tried Rmpi with non-LAM MPI
> implementations?
http://www.stats.uwo.ca/faculty/yu/Rmpi/, which seems to be the package
author's page, describes using MPICH under MS Windows.  I hope that's a
sign that RMPI is not too tied to LAM.

We're using LAM here, but interested in OpenMPI in hopes of better
integration with Sun Grid Engine.

-- 
Ross Boylan                                      wk:  (415) 514-8146
185 Berry St #5700                               ross at biostat.ucsf.edu
Dept of Epidemiology and Biostatistics           fax: (415) 514-8150
University of California, San Francisco
San Francisco, CA 94107-1739                     hm:  (415) 550-1062


From weigand.stephen at gmail.com  Thu Mar 29 22:36:10 2007
From: weigand.stephen at gmail.com (Stephen Weigand)
Date: Thu, 29 Mar 2007 15:36:10 -0500
Subject: [Rd] ansari.test.default: bug in call to uniroot?
Message-ID: <bc47d3330703291336p58257253ufc43920d782e2dca@mail.gmail.com>

A recent message on ansari.test() prompted me to play with the examples. This
doesn't work for me in R version 2.4.1

R> ansari.test(rnorm(100), rnorm(100, 0, 2), conf.int = TRUE)

Error in uniroot(ab, srange, tol = 1e-04, zq = qnorm(alpha/2, lower = FALSE)) :
	object "ab" not found

It looks like there's a small typo in ccia() inside
ansari.test.default() in which 'ab' is
passed to uniroot rather than 'ab2'. The definition of ccia below was
just copied
from https://svn.r-project.org/R/trunk/src/library/stats/R/ansari.test.R

ccia <- function(alpha) {
     ## Check if the statistic exceeds both quantiles
     ## first.
     statu <- ab2(srange[1], zq=qnorm(alpha/2))
     statl <- ab2(srange[2], zq=qnorm(alpha/2, lower=FALSE))
     if (statu > 0 || statl < 0) {
         warning("samples differ in location: cannot compute
confidence set, returning NA")
         return(c(NA, NA))
     }
     u <- uniroot(ab2, srange, tol=1e-4,
                  zq=qnorm(alpha/2))$root
     l <- uniroot(ab, srange, tol=1e-4,
                  zq=qnorm(alpha/2, lower=FALSE))$root
     ## The process of the statistics does not need to be
     ## monotone: sort is ok here.
     sort(c(u, l))
 }

Stephen
Rochester, MN USA


From simon.urbanek at r-project.org  Thu Mar 29 23:05:50 2007
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Thu, 29 Mar 2007 17:05:50 -0400
Subject: [Rd] Suggestion for memory optimization and as.double() with
	friends
In-Reply-To: <m21wj8ksht.fsf@ziti.fhcrc.org>
References: <59d7961d0703281425n161a100lf4fb36bcf95ac742@mail.gmail.com>
	<460AE657.9040402@stats.uwo.ca>
	<Pine.LNX.4.64.0703290256240.6919@gannet.stats.ox.ac.uk>
	<m21wj8ksht.fsf@ziti.fhcrc.org>
Message-ID: <C2E734A2-B2E8-4502-B468-175C95B18F47@r-project.org>

Seth, good point. I think we should be able to do better...

On Mar 29, 2007, at 10:57 AM, Seth Falcon wrote:

> Prof Brian Ripley <ripley at stats.ox.ac.uk> writes:
>> The usual 'trick' to avoid this copy is
>>
>> storage.mode(x) <- "double"
>
> Hmm, this does not appear to avoid the copy for me.  Using R 2.5.0  
> alpha r40916 I get:
>
>> x <- 1:10 * 2.3
>> names(x)=LETTERS[1:10]
>> storage.mode(x)
>     [1] "double"
>> tracemem(x)
>     [1] "<0x2a7f008>"
>> storage.mode(x) <- "double"
>     tracemem[0x2a7f008 -> 0x1fa6df8]:
>
> Note that actually changing the storage results in a surprising amount
> of copying:
>
>> storage.mode(x) <- "integer"
>     tracemem[0x1fa6df8 -> 0x1fa6d60]:

I believe this is due to arguments copy because of NAMED=2 - it  
doesn't appear when you work on a pristine x (NAMED=1). (*)


>     tracemem[0x1fa6d60 -> 0x1fa6808]: as.integer.default as.integer  
> eval eval storage.mode<-

comes from as.vector, additional copy due to NAMED>0. In fact,  
as.vector does something like this (in ascommon at coerce.c):
         if (NAMED(u))
             v = duplicate(u);
         else v = u;
        [...]
         v = coerceVector(v, type);

I suppose the duplication could be avoided, because coerceVector will  
produce a copy anyway ... Would it be safe to change it to something  
like this:?

    v = coerceVector(u, type);
    if (v == u && NAMED(u)) v = duplicate(u);

I suspect that the duplication is necessary only because of the fact  
that attributes may get scrubbed later. If that is true, can we defer  
the copying just before CLEAR_ATTRIB branch ... Are my assumptions  
correct?


>     tracemem[0x1fa6808 -> 0x2c26b18]: as.integer.default as.integer  
> eval eval storage.mode<-

this is the conversion itself (coerceVector), that's fine


>     tracemem[0x2c26b18 -> 0x2c26a88]: storage.mode<-
>

This one is caused by:
  attr(x, "Csingle") <- if (value == "single") TRUE

in "storage.mode<-". It calls attr<- unconditionally, so either  
attr<- should be smart enough to not copy x on a no-op  or it could  
be replaced by something like:
if (value == "single") attr(x, "Csingle") <- TRUE else if (!is.null 
(attr(x, "Csingle"))) attr(x, "Csingle") <- NULL

I guess that in most cases Csingle will be untouched anyway.

---

Ok, so I can see how we can eliminate 2 of the four copies. I'm still  
not sure what causes the first one (*).

 > x=rnorm(100)
 > tracemem(x)
[1] "<0x1b3da00>"
 > storage.mode(x)<-"double"
 > storage.mode(x)<-"double"
tracemem[0x1b3da00 -> 0x1820800]:
 > storage.mode(x)<-"double"
tracemem[0x1820800 -> 0x1f29600]:

The only difference is that the resulting x has NAMED=2:

 > x=rnorm(100)
 > tracemem(x)
[1] "<0x29b1a00>"
 > insp(x)
@029b1a00 14 REALSXP [NAM(1)] (len=100, tl=34)
 > storage.mode(x)<-"double"
 > insp(x)
@029b1a00 14 REALSXP [NAM(2)] (len=100, tl=34)
 > storage.mode(x)<-"double"
tracemem[0x29b1a00 -> 0x1a47e00]:

I'm not sure why, because storage.mode is a no-op if the mode is  
correct... it has probably to do with the subassignment function  
evaluation I suppose (which I didn't look at ...), but I'm not sure...

Cheers,
Simon


From p.dalgaard at biostat.ku.dk  Thu Mar 29 23:05:30 2007
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Thu, 29 Mar 2007 23:05:30 +0200
Subject: [Rd] small bug in ansari.test
In-Reply-To: <200703292149.39133.thomas.friedrichsmeier@ruhr-uni-bochum.de>
	(Thomas Friedrichsmeier's message of "Thu,
	29 Mar 2007 21:49:35 +0200")
References: <200703292139.21253.thomas.friedrichsmeier@ruhr-uni-bochum.de>
	<200703292149.39133.thomas.friedrichsmeier@ruhr-uni-bochum.de>
Message-ID: <x2r6r7kbfp.fsf@viggo.kubism.ku.dk>

Thomas Friedrichsmeier <thomas.friedrichsmeier at ruhr-uni-bochum.de>
writes:

> On Thursday 29 March 2007 21:39, Thomas Friedrichsmeier wrote:
>> The help page for ansari.test() says (emphasis added):
>>
>> 	By default (if exact is not specified), an exact p-value is computed if
>> both samples contain less than 50 finite values **and there are no ties**.
>> Otherwise, a normal approximation is used.
>>
>> However, this does not appear to be the case in R 2.4.1 or R 2.5.0.
>
> Well, to be precise, the exact p-value really isn't computed in this case, but 
> there's still the warning, as though exact=TRUE had been specified, which I 
> don't believe is intended.

Yes?

Those samples contain less than 50 values but there are ties, so you
get the normal approximation with a warning.  If you specify
exact=FALSE, you get the same result without the warning. 

Where's the bug??


-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From ross at biostat.ucsf.edu  Thu Mar 29 23:27:22 2007
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Thu, 29 Mar 2007 14:27:22 -0700
Subject: [Rd] S4 generic surprise
Message-ID: <1175203642.26829.209.camel@iron.psg.net>

I discovered the following behavior when source'ing the same file
repeatedly as I edited it.  My generic stopped acting like a generic.  I
can't tell from the docs what, if any, behavior is expected in this
case.  R 2.4.0

> foo <- function(object) 3
> isGeneric("foo")
[1] FALSE
> setMethod("foo", "matrix", function(object) 4)
Creating a new generic function for "foo" in ".GlobalEnv"
[1] "foo"
> foo(0)
[1] 3
> foo(matrix(0))
[1] 4
> isGeneric("foo")
[1] TRUE
# The next step is where things start to go astray
> foo <- function(object) 2
> isGeneric("foo")
[1] TRUE
> setMethod("foo", "matrix", function(object) 40)
[1] "foo"
> foo(0)
[1] 2
# isGeneric is TRUE, but method lookup no longer works
# I think the cause is that the function foo that used
# to do the dispatch has been overwritten by my plain old
# function that returns 2.
> foo(matrix(0))
[1] 2
> removeGeneric("foo")
[1] FALSE
Warning message:
generic function "foo" not found for removal in: removeGeneric("foo") 
> isGeneric("foo")
[1] TRUE

My mental model and R's diverged at the point I overwrote foo with a
regular function (foo <- function(object) 2).  At this point I thought R
would know that the function was no longer generic, and then would
rebuild the generic at the next setMethod.  Instead, R thought the
function remain generic, and so did not rebuild it at the next
setMethod.

If I had practiced the recommended style, I would have done
foo<-function(object) 2
setGeneric("foo")
and all would have been well.  So that's what I'll do.

I thought I'd report this in case others run into it, or somebody
considers this a matter that calls for documentation or R behavior
changes.
-- 
Ross Boylan                                      wk:  (415) 514-8146
185 Berry St #5700                               ross at biostat.ucsf.edu
Dept of Epidemiology and Biostatistics           fax: (415) 514-8150
University of California, San Francisco
San Francisco, CA 94107-1739                     hm:  (415) 550-1062


From thomas.friedrichsmeier at ruhr-uni-bochum.de  Thu Mar 29 23:29:02 2007
From: thomas.friedrichsmeier at ruhr-uni-bochum.de (Thomas Friedrichsmeier)
Date: Thu, 29 Mar 2007 23:29:02 +0200
Subject: [Rd] small bug in ansari.test
In-Reply-To: <x2r6r7kbfp.fsf@viggo.kubism.ku.dk>
References: <200703292139.21253.thomas.friedrichsmeier@ruhr-uni-bochum.de>
	<200703292149.39133.thomas.friedrichsmeier@ruhr-uni-bochum.de>
	<x2r6r7kbfp.fsf@viggo.kubism.ku.dk>
Message-ID: <200703292329.05577.thomas.friedrichsmeier@ruhr-uni-bochum.de>

On Thursday 29 March 2007 23:05, Peter Dalgaard wrote:
> Thomas Friedrichsmeier <thomas.friedrichsmeier at ruhr-uni-bochum.de>
> > Well, to be precise, the exact p-value really isn't computed in this
> > case, but there's still the warning, as though exact=TRUE had been
> > specified, which I don't believe is intended.
>
> Yes?
>
> Those samples contain less than 50 values but there are ties, so you
> get the normal approximation with a warning.  If you specify
> exact=FALSE, you get the same result without the warning.
>
> Where's the bug??

Yes, I was a bit too fast in calling this a bug. Which is why I sent the 
second mail. Sorry about that.

What behavior you expect probably depends on how you read the exact parameter. 
Initially I read it as "if exact is omitted, chose a sensible default". It 
does not warn about there being 50 or more values either, it just picks a 
useful default, in this case. That's why it looked to me, like the current 
behavior was not intended.

If it is indeed intended, I suggest to rewrite the documentation to:

"By default (if exact is not specified) an exact test is requested if and only 
if both samples contain less than 50 finite values.

If an exact test is requested (exact==TRUE or see above), and there are no 
ties, an exact p-value is computed. If an exact test is requested, and there 
are ties, a warning is issued, and an approximation is used. In all other 
cases an approximation is used."

Admittedly, not a pretty wording, but I guess it would get the point across. 
Right now it makes me feel "hey, I didn't ask it to do an exact test, so why 
does it complain?". I also tend to be surprised, when example code produces a 
warning message without any further comment about that in the example code.

All of this is due to me working with wrong assumptions, but maybe those wrong 
assumptions are prevalent in other people as well.

Regards
Thomas Friedrichsmeier
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 189 bytes
Desc: not available
Url : https://stat.ethz.ch/pipermail/r-devel/attachments/20070329/11775e09/attachment.bin 

From lmada at gmx.net  Thu Mar 29 23:41:09 2007
From: lmada at gmx.net (Leonard Mada)
Date: Fri, 30 Mar 2007 00:41:09 +0300
Subject: [Rd] Bridging R to OpenOffice
In-Reply-To: <Pine.LNX.4.64.0703290844390.19865@gannet.stats.ox.ac.uk>
References: <4609655A.5070209@gmx.net>
	<Pine.LNX.4.64.0703281504150.17699@gannet.stats.ox.ac.uk>
	<460AD496.1020302@gmx.net>
	<Pine.LNX.4.64.0703290844390.19865@gannet.stats.ox.ac.uk>
Message-ID: <460C3275.8010708@gmx.net>

Hi.

Indeed, there is still some time left before the students get allocated. 
Though I would like to have various issues already analysed before the 
actual coding starts (me already drawing a tough schedule for the 
students ;-) ).

Some projects are OK when you simply start to write code and refine it 
later. I often favour such an approach, too.

But I feel this one is much to important for such an approach and there 
are surely many issues where clever ideas and solutions would make a 
difference.

1. I am still unsure of many of these issues. One involves importing the 
data back from R (as Prof. Neuwirth pointed out). Unfortunately OOo Calc 
does only have simple data structures (numbers, date, strings and 
formulas) and NO complex objects. More complex objects would be helpful 
(having various methods, like a summary - what to display in the cell, 
and also various built in functions interpreting only some subvalues of 
it). I will probably address this issue on the Calc development list 
(though this one would be difficult to implement, too).

2. As there is interest in this discussion, should we move back to the 
devel-list?

Sincerely,

Leonard


Prof Brian Ripley wrote:
> Quick comments:
>
> 1) I had intended to mention Java, as I believe Oo uses that on the 
> database side. I tend to struggle with Java (e.g. it is only recently 
> working with JNI on my main platform, AMD64 Linux).  Simon Urbanek and 
> Duncan Temple Lang are our Java gurus.
>
> 2) Doug Bates and I mentored a SoC student last year, so we know about 
> a lot of the issues.  Unless this year's allocations are done a _lot_ 
> more smoothly, I would recommended sitting this out until a student is 
> definitely allocated.  At that point design work can begin in earnest 
> (and one mistake we made was not being *sure* the student understood 
> the design right at the beginning).  I think it is then that we can 
> help most (in choosing between strategies).
>
> Brian Ripley
>
>
> On Wed, 28 Mar 2007, Leonard Mada wrote:
>
>> Dear Prof. Ripley, dear R-core Team,
>>
>> thank you very much for your kind comments.
>>
>>
>> Prof Brian Ripley wrote:
>>> My guess is that you intended to contact the R core team: I am sorry
>>> that you have had a somewhat unhelpful response from the R-devel list
>>> members.
>>
>> I was indeed unsure which list was best suited for my question. Most
>> responses were nevertheless quite interesting.
>>
>> 1. Cross-Platform
>> Indeed, there may be a problem with the cross-platform requirement, as
>> you pointed out. I had some thoughts on this problem. My feeling is that
>> the code should be split into 2-3 modules: an OOo module
>> (platform-independent), an abstraction layer (platform - DEpendent) and
>> an R module (hopefully as much platform independent as possible). This
>> bears another problem, as there would be now 3 inter-module interfaces.
>> If the R-module (package) has to be platform-dependent, then embedding
>> the abstraction layer into this module seems OK (only 2 modules to deal
>> with). I still believe that the bridge should work on most platforms
>> (but somebody may want to challenge my view).
>>
>> [One of the students came with an idea of using a java-connector, though
>> this surely has to be analysed more thoroughly.]
>>
>>
>> 2. What type of embedding/bridge?
>> I left this question deliberately open. I favour to build in the initial
>> phase something that resembles more closely a GUI to some common
>> statistical functions (there will be definitely another discussion which
>> functions these should be).
>>
>> My hope is too, that later on more advanced features are added, making
>> it a true bridge. While having the ability to read/write .ods files from
>> within R is a sensible alternative for power users, there will be always
>> things that are easier to do in a spreadsheet. Therefore, a real
>> connection will ease the work even for more advanced users.
>>
>> However, if the development of this more powerful bridge needs a very
>> different approach from the simple GUI approach, then starting directly
>> with the more complex code should be analysed more closely. I am still
>> unsure about the right path, especially because I have no understanding
>> of the R internals.
>>
>> 3. Who will do the work?
>> Well, the Google Summer of Code is intended for students: students apply
>> for various projects and those who will be accepted will get paid over
>> the summer by Google. There are various mentors and mentoring
>> organisations, but much of the coding should be done by the students. [I
>> missed R on the Google Sumer of Code list: http://code.google.com/soc/ .
>> While it is unlikely that a student will work on the core, there would
>> be enough alternatives, like writing some packages. I am sure that the
>> listing on the Google site alone will make the program more popular in
>> various other communities.]
>>
>> That said, 2 students showed interest in this project and I hope that
>> they will be accepted (results are still pending).
>>
>> However, I am aware that this will be a tough project and the students
>> will surely need much help. Bridging 2 open-source applications proves
>> (again and again) not to be that simple and expertise from both
>> communities will be invaluable.
>>
>> Independent of the outcome of the Google Summer of Code Initiative, I
>> believe that creating a powerful bridge between R and OOo is essential
>> for the future.
>>
>> There is surely much more to discuss, but I am optimistic that most
>> problems will be solved.
>>
>> Sincerely,
>>
>> Leonard
>>
>> _______________________________________________
>> R-core list: https://stat.ethz.ch/mailman/listinfo/r-core
>>
>


From thomas.friedrichsmeier at ruhr-uni-bochum.de  Thu Mar 29 23:45:42 2007
From: thomas.friedrichsmeier at ruhr-uni-bochum.de (Thomas Friedrichsmeier)
Date: Thu, 29 Mar 2007 23:45:42 +0200
Subject: [Rd] SPAM items in wishlist category of bugs.r-project.org
Message-ID: <200703292345.46436.thomas.friedrichsmeier@ruhr-uni-bochum.de>

Report numbers 9550, 9552, and 9553 are sorted into wishlist (and have been 
for a while, now), but should go into trashcan, instead.

Regards
Thomas Friedrichsmeier
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 189 bytes
Desc: not available
Url : https://stat.ethz.ch/pipermail/r-devel/attachments/20070329/270e5a58/attachment.bin 

From ripley at stats.ox.ac.uk  Fri Mar 30 00:36:10 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 29 Mar 2007 23:36:10 +0100 (BST)
Subject: [Rd] ansari.test.default: bug in call to uniroot?
In-Reply-To: <bc47d3330703291336p58257253ufc43920d782e2dca@mail.gmail.com>
References: <bc47d3330703291336p58257253ufc43920d782e2dca@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0703292334040.6682@gannet.stats.ox.ac.uk>

Yes, thanks, an obvious typo and I will fix shortly.

On Thu, 29 Mar 2007, Stephen Weigand wrote:

> A recent message on ansari.test() prompted me to play with the examples. This
> doesn't work for me in R version 2.4.1
>
> R> ansari.test(rnorm(100), rnorm(100, 0, 2), conf.int = TRUE)
>
> Error in uniroot(ab, srange, tol = 1e-04, zq = qnorm(alpha/2, lower = FALSE)) :
> 	object "ab" not found
>
> It looks like there's a small typo in ccia() inside
> ansari.test.default() in which 'ab' is
> passed to uniroot rather than 'ab2'. The definition of ccia below was
> just copied
> from https://svn.r-project.org/R/trunk/src/library/stats/R/ansari.test.R
>
> ccia <- function(alpha) {
>     ## Check if the statistic exceeds both quantiles
>     ## first.
>     statu <- ab2(srange[1], zq=qnorm(alpha/2))
>     statl <- ab2(srange[2], zq=qnorm(alpha/2, lower=FALSE))
>     if (statu > 0 || statl < 0) {
>         warning("samples differ in location: cannot compute
> confidence set, returning NA")
>         return(c(NA, NA))
>     }
>     u <- uniroot(ab2, srange, tol=1e-4,
>                  zq=qnorm(alpha/2))$root
>     l <- uniroot(ab, srange, tol=1e-4,
>                  zq=qnorm(alpha/2, lower=FALSE))$root
>     ## The process of the statistics does not need to be
>     ## monotone: sort is ok here.
>     sort(c(u, l))
> }
>
> Stephen
> Rochester, MN USA
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From jmc at r-project.org  Fri Mar 30 02:34:17 2007
From: jmc at r-project.org (John Chambers)
Date: Thu, 29 Mar 2007 17:34:17 -0700
Subject: [Rd] Developer work cycle
In-Reply-To: <40e66e0b0703291103m2ff62deej1af424ab1de13ab@mail.gmail.com>
References: <4607F803.7060700@decsai.ugr.es>
	<40e66e0b0703291103m2ff62deej1af424ab1de13ab@mail.gmail.com>
Message-ID: <460C5B09.4070501@r-project.org>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20070329/caba1e22/attachment.pl 

From Mark.Bravington at csiro.au  Fri Mar 30 02:58:37 2007
From: Mark.Bravington at csiro.au (Mark.Bravington at csiro.au)
Date: Fri, 30 Mar 2007 10:58:37 +1000
Subject: [Rd] Developer work cycle
References: <4607F803.7060700@decsai.ugr.es><40e66e0b0703291103m2ff62deej1af424ab1de13ab@mail.gmail.com>
	<460C5B09.4070501@r-project.org>
Message-ID: <D79013E40FEF254AAF0D72DFC94F27482308B4@extas4-hba.tas.csiro.au>

Couple of quick points:

FYI1: the 'mtrace' function in the 'debug' package does let you trace hidden S3 methods (though it lacks the edit= argument).

FYI2: In my own alpha-version of 'mvbutils', I am able to do live edits of code in (selected) installed packages, including adding & deleting functions from the namespace, and also to do a quick patch of the installed library from inside R (rather than requiring re-installation) so that the modified version is loaded next time I use 'library'. I only need to re-build the package with rcmd when I want to update the helpfiles. My plan is to release the new 'mvbutils' later this year-- time permitting.

Mark

Mark Bravington
CSIRO Mathematical & Information Sciences
Marine Laboratory
Castray Esplanade
Hobart 7001
TAS

ph (+61) 3 6232 5118
fax (+61) 3 6232 5012
mob (+61) 438 315 623
 

> -----Original Message-----
> From: r-devel-bounces at r-project.org 
> [mailto:r-devel-bounces at r-project.org] On Behalf Of John Chambers
> Sent: Friday, 30 March 2007 10:34 AM
> To: Douglas Bates
> Cc: "Jos? Luis Aznarte M."; r-devel at r-project.org
> Subject: Re: [Rd] Developer work cycle
> 
> Douglas Bates wrote:
> > On 3/26/07, "Jos? Luis Aznarte M." <jlaznarte at decsai.ugr.es> wrote:
> >   
> >>     Hi! I've been browsing through the last months' archive and I 
> >> can't find an answer to my question, so here it is (let's 
> hope it's 
> >> not too
> >> obvious):
> >>     I'm working on extensions of an R library, and I would be very 
> >> surprised if everyone developing R packages is doing the 
> following, as I do:
> >>
> >>         1.- Write down a modification of an R file
> >>         2.- Exit the current R session
> >>         3.- Install the package as root (sudo R CMD INSTALL...)
> >>         4.- Launch a new R session
> >>         5.- Test the change, if it does not work, go back 
> to 1 or debug.
> >>         6.- Finish.
> >>
> >>     Is this the proper (but quite awkward) way to proceed 
> or there is 
> >> an alternative to skip steps 2 to 4? I'm using emacs with 
> ESS under linux.
> >>     
> >
> > John Chambers has provided an alternative approach of using
> >
> > trace(fname, edit = TRUE)
> >
> > where fname is the name of your function.  (Make sure that 
> the server 
> > for emacsclient has been started in your emacs session with M-x
> > server-start.)  This opens an emacs buffer containing the 
> source for 
> > the function which you can then edit.  After writing the file and 
> > closing the client (C-x #) your ESS session has the new definition 
> > installed in the package's namespace.
> >
> > This will work even for objects hidden in the namespace.  
> The argument 
> > "signature" allows you to edit S4 methods on the fly like 
> this.  In my 
> > experience you cannot edit registered S3 methods like this 
> but it may 
> > be that I am just not using trace correctly.
> >   
> Indeed, trace() does not currently work for registered S3 
> methods, with or without the edit=TRUE argument.
> 
> There is a fix, just committed to r-devel, which should be in 
> the final 2.5.0.
> > Of course you must copy the modified version of the source code to 
> > your package sources when you are done.
> >
> > As others have indicated, it is a good practice to install 
> development 
> > versions of packages in a private library so you do not need to use 
> > sudo or worry about messing up system-wide directories.
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
> >   
> 
> 	[[alternative HTML version deleted]]
> 
> 
>


From nakama at ki.rim.or.jp  Fri Mar 30 05:48:39 2007
From: nakama at ki.rim.or.jp (Ei-ji Nakama)
Date: Fri, 30 Mar 2007 12:48:39 +0900
Subject: [Rd] Rmpi and OpenMPI ?
In-Reply-To: <17929.54296.884935.214790@basebud.nulle.part>
References: <17929.54296.884935.214790@basebud.nulle.part>
Message-ID: <dc41e1260703292048j65ed60bfv13f4eb6862de6715@mail.gmail.com>

Prof. Nakano(ism Japan) and I wrestled in Rmpi on HP-MPI.
Do not know a method to distinguish MPI well?
It is an ad-hoc patch at that time as follows.

diff -ruN Rmpi.orig/configure Rmpi/configure
--- Rmpi.orig/configure 2006-10-12 23:47:03.000000000 +0900
+++ Rmpi/configure      2007-01-10 21:24:55.000000000 +0900
@@ -1268,7 +1268,7 @@
 fi;

 if test -z "$MPI_ROOT"; then
-  for d in /opt/lib /usr/local/lib /usr/lib; do
+  for d in /opt /opt/lib /usr/local/lib /usr/lib; do
     if test -f $d/lam/include/mpi.h && test -f $d/lam/lib/libmpi.a; then
       echo "I am here $d/lam"
       MPI_ROOT=$d/lam
@@ -1281,6 +1281,10 @@
       echo "I am here $d/mpich"
       MPI_ROOT=$d/mpich
       break
+    elif test -f $d/hpmpi/include/mpi.h; then
+      echo "I am here $d/hpmpi"
+      MPI_ROOT=$d/hpmpi
+      break
     fi
   done
 fi
@@ -2781,6 +2785,9 @@
 if test -f ${MPI_ROOT}/lib/libmpi.a; then
         echo "Found libmpi in ${MPI_ROOT}/lib"
         MPI_LIBS="-L${MPI_ROOT}/lib -lmpi"
+elif test -f ${MPI_ROOT}/lib/linux_amd64/libmpi.a; then
+        echo "Found in ${MPI_ROOT}/lib/linux_amd64"
+        MPI_LIBS="-L${MPI_ROOT}/lib/linux_amd64 -lmpi -lmpio
-Wl,-rpath=${MPI_ROOT}/lib/linux_amd64"
 elif test -f ${MPI_ROOT}/lib/libmpich.a; then
         echo "Found libmpich in ${MPI_ROOT}/lib"
         MPI_LIBS="-L${MPI_ROOT}/lib -lmpich"
@@ -2835,7 +2842,7 @@
 echo "$as_me:$LINENO: result: $ac_cv_lib_mpi_main" >&5
 echo "${ECHO_T}$ac_cv_lib_mpi_main" >&6
 if test $ac_cv_lib_mpi_main = yes; then
-     MPI_LIBS="-lmpi"
+     MPI_LIBS="-lmpi -lmpio"
 else
      echo "libmpi not found. exiting..."
                exit 1
diff -ruN Rmpi.orig/R/Rcomm.R Rmpi/R/Rcomm.R
--- Rmpi.orig/R/Rcomm.R 2006-02-08 07:11:25.000000000 +0900
+++ Rmpi/R/Rcomm.R      2007-01-10 21:26:42.000000000 +0900
@@ -72,11 +72,11 @@

     if (!is.character(slave))
         stop("character argument (slave) expected")
-    #if (nslaves > mpi.universe.size()){
-    #            tmp <- paste("Number of R slaves is over",
-    #                    mpi.universe.size(),": maximum CPUs.")
-    #            warning(tmp)
-    #    }
+    if (nslaves > mpi.universe.size()){
+                tmp <- paste("Number of R slaves is over",
+                        mpi.universe.size(),": maximum CPUs.")
+                warning(tmp)
+    }
     else if (nslaves <= 0)
         stop("Choose a positive number of slaves.")
     .Call("mpi_comm_spawn",
diff -ruN Rmpi.orig/R/zzz.R Rmpi/R/zzz.R
--- Rmpi.orig/R/zzz.R   2005-11-24 04:19:26.000000000 +0900
+++ Rmpi/R/zzz.R        2007-01-10 21:18:49.000000000 +0900
@@ -7,13 +7,13 @@
     #    cat(vertxt)

     # Check if lam-mpi is running
-    if (.Platform$OS=="unix"){
-       if (length(system("lamnodes",TRUE,ignore.stderr = TRUE)) == 0){
-               cat("\n\tLAM/MPI runtime environment is not operating.\n")
-               cat("\tStarting LAM/MPI runtime environment.\n")
-               system("lamboot -H",ignore.stderr = TRUE)
-               }
-    }
+    #if (.Platform$OS=="unix"){
+    #  if (length(system("lamnodes",TRUE,ignore.stderr = TRUE)) == 0){
+    #          cat("\n\tLAM/MPI runtime environment is not operating.\n")
+    #          cat("\tStarting LAM/MPI runtime environment.\n")
+    #          system("lamboot -H",ignore.stderr = TRUE)
+    #  }
+    #}

     library.dynam("Rmpi", pkg, lib)
     if (!TRUE)
diff -ruN Rmpi.orig/src/Rmpi.c Rmpi/src/Rmpi.c
--- Rmpi.orig/src/Rmpi.c        2006-09-05 23:10:59.000000000 +0900
+++ Rmpi/src/Rmpi.c     2007-01-10 21:18:49.000000000 +0900
@@ -77,7 +77,7 @@
        return AsInt(LENGTH(STRING_ELT(sexp_data,0)));
 }

-#ifdef MPI2
+#if defined(MPI2) || (defined(HP_MPI) && HP_MPI > 200)
 SEXP mpi_universe_size(){
        int *MPI_Universe_Size;
        int univ_flag;
@@ -857,7 +857,7 @@
        return AsInt(flag);
 }

-#ifdef MPI2
+#if defined(MPI2) || (defined(HP_MPI) && HP_MPI > 200)
 SEXP mpi_comm_spawn (SEXP sexp_slave,
                                         SEXP sexp_argv,
                                         SEXP sexp_nslave,


2007/3/28, Dirk Eddelbuettel <edd at debian.org>:
>
> Has anybody tried to use Rmpi with the OpenMPI library instead of LAM/MPI?
>
> LAM appears to be somewhat hardcoded in the Rmpi setup. Before I start to
> experiment with changing this, has anybody else tried Rmpi with non-LAM MPI
> implementations?
>
> Dirk
>
> --
> Hell, there are no rules here - we're trying to accomplish something.
>                                                   -- Thomas A. Edison
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>
>

-- 
EI-JI Nakama  <nakama at ki.rim.or.jp>
"\u4e2d\u9593\u6804\u6cbb"  <nakama at ki.rim.or.jp>


From edd at debian.org  Fri Mar 30 22:01:19 2007
From: edd at debian.org (Dirk Eddelbuettel)
Date: Fri, 30 Mar 2007 15:01:19 -0500
Subject: [Rd] Rmpi and OpenMPI ?
In-Reply-To: <dc41e1260703292048j65ed60bfv13f4eb6862de6715@mail.gmail.com>
References: <17929.54296.884935.214790@basebud.nulle.part>
	<dc41e1260703292048j65ed60bfv13f4eb6862de6715@mail.gmail.com>
Message-ID: <17933.27791.611377.369470@basebud.nulle.part>


On 30 March 2007 at 12:48, Ei-ji Nakama wrote:
| Prof. Nakano(ism Japan) and I wrestled in Rmpi on HP-MPI.
| Do not know a method to distinguish MPI well?
| It is an ad-hoc patch at that time as follows.

Thank you *very much* for this.  I tried an ad-hoc patch that did about half
of this (i.e. coping with configure, and not letting zzz.R play with lamboot)
which let to Rmpi at least building ... but not yet running.

I will look more closely at what needs to happen at the C/C++ level in MPI
and see if I can (eventually) put the rest together.

As for your question about distinguishing MPI implementations: Not sure yet.
Under Debian, I had to un-install the lam and mpich2 development packages as
configure would otherwise find their mpi.h first.  I'll have to see if there
is a canonical / portable identifier for MPI.

For anybody else reading along, this appears to be a great resource (and it
requires a free registration for webct): 

	http://webct.ncsa.uiuc.edu:8900/public/MPI/

Regards,  Dirk

-- 
Hell, there are no rules here - we're trying to accomplish something. 
                                                  -- Thomas A. Edison


From hkawakat at gmail.com  Fri Mar 30 18:38:28 2007
From: hkawakat at gmail.com (Hiroyuki Kawakatsu)
Date: Fri, 30 Mar 2007 17:38:28 +0100
Subject: [Rd] bug?
Message-ID: <307b90470703300938s7f74538eqdb93303eca0cd2c8@mail.gmail.com>

> rep(2,0)
numeric(0)
> rep(2,0,2)
[1] 2 2
> rep(2,0,2,0)
Floating exception (core dumped)

#yes, i should not be doing this but i mistakenly did
#par(oma=rep(2,0,2,0)) when i meant c(2,0,2,0)
#
#both on
#2.4.1 Patched (2007-03-21 r40875); x86_64-unknown-freebsd6.2
#and
#2.5.0 alpha (2007-03-30 r40957); i386-pc-mingw32

-- 
----------------------------------
Hiroyuki Kawakatsu
Business School
Dublin City University
Dublin 9, Ireland
Tel +353 (0)1 700 7496


From wolfram at fischer-zim.ch  Fri Mar 30 09:48:00 2007
From: wolfram at fischer-zim.ch (wolfram at fischer-zim.ch)
Date: Fri, 30 Mar 2007 09:48:00 +0200 (CEST)
Subject: [Rd] use of ... in some functions does not work (PR#9591)
Message-ID: <20070330074800.E82F85AC5B@slim.kubism.ku.dk>

Consider:

	x.lm <- function( ... ) lm( ... )
	x.xyplot <- function( ... ) xyplot( ... )
	x.dotplot <- function( ... ) dotplot( ... )

	lm( dist ~ speed, data=cars, weight=speed )
	x.lm( dist ~ speed, data=cars, weight=speed )

	xyplot( variety ~ yield | site, groups=year, data=barley )
	x.xyplot( variety ~ yield | site, groups=year, data=barley )

	dotplot( variety ~ yield | site, groups=year, data=barley )
	x.dotplot( variety ~ yield | site, groups=year, data=barley )

Out of the x.* functions only the x.xyplot function works.
The others results in a message like:
	Error in eval(expr, envir, enclos) : ..2
	used in an incorrect context, no ... to look in

Regards - Wolfram


From jszinger at gmail.com  Thu Mar 29 18:10:24 2007
From: jszinger at gmail.com (jszinger at gmail.com)
Date: Thu, 29 Mar 2007 18:10:24 +0200 (CEST)
Subject: [Rd] error in lattice formattedTicksAndLabels.Date (PR#9590)
Message-ID: <20070329161024.DE9455DE81@slim.kubism.ku.dk>

Full_Name: James Szinger
Version: 2.4.1
OS: linux and MacOS X
Submission from: (NULL) (128.165.24.206)


I'm trying to plot some data from the past 12 months and the lattice package is
not labeling the time axis correctly.  It shows only two labels instead of the
expected 12.  The base graphics get it right.  

I think the problem is the commented-out line in formattedTicksAndLabels.Date in
lattice's axis.R:
    ## z <- c(range, x[is.finite(x)])

The following example demonstrates the problem:

require(lattice)  #lattice_0.14-16

x <- rnorm(12)
t <- seq( as.Date("2006-04-01"),by="month", length=12)

plot(x~t)      # Has labels "May", "Jul", "Sep", "Nov", Jan", "Mar"
xyplot(x~t)    # Has labels "Jan", "Mar"


From cstrato at aon.at  Fri Mar 30 22:45:38 2007
From: cstrato at aon.at (cstrato)
Date: Fri, 30 Mar 2007 22:45:38 +0200
Subject: [Rd] Replacing slot of S4 class in method of S4 class?
Message-ID: <460D76F2.1060300@aon.at>

Dear all,

Assume that I have an S4 class "MyClass" with a slot "myname", which
is initialized to:  myname="" in method("initialize"):
   myclass <- new("MyClass", myname="")

Assume that class "MyClass" has a method "mymethod":
   "mymethod.MyClass" <-
   function(object, myname=character(0), ...) {
       object at myname <- myname;
   #or:    myName(object) <- myname
   }
   setMethod("mymethod", "MyClass", mymethod.MyClass);

Furthermore, I have a replacement method:
setReplaceMethod("myName", signature(object="MyClass", value="character"),
   function(object, value) {
      object at myname <- value;
      return(object);
   }
)

I know that it is possible to call:
   myName(myclass) <- "newname"

However, I want to replace the value of slot "myname" for object "myclass"
in method "mymethod":
   mymethod(myclass,  myname="newname")

Sorrowly, the above code in method "mymethod" does not work.

Is there a possibility to change the value of a slot in the method of a 
class?

Best regards
Christian
_._._._._._._._._._._._._._._._
C.h.i.s.t.i.a.n S.t.r.a.t.o.w.a
V.i.e.n.n.a       A.u.s.t.r.i.a
_._._._._._._._._._._._._._._._


From ripley at stats.ox.ac.uk  Fri Mar 30 22:53:36 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 30 Mar 2007 21:53:36 +0100 (BST)
Subject: [Rd] bug?
In-Reply-To: <307b90470703300938s7f74538eqdb93303eca0cd2c8@mail.gmail.com>
References: <307b90470703300938s7f74538eqdb93303eca0cd2c8@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0703302149090.22919@gannet.stats.ox.ac.uk>

Yes, it is a bug, thanks.

It needs a test for each > 0 if length.out > 0 is set. Added for 2.5.0.

On Fri, 30 Mar 2007, Hiroyuki Kawakatsu wrote:

>> rep(2,0)
> numeric(0)
>> rep(2,0,2)
> [1] 2 2
>> rep(2,0,2,0)
> Floating exception (core dumped)
>
> #yes, i should not be doing this but i mistakenly did
> #par(oma=rep(2,0,2,0)) when i meant c(2,0,2,0)
> #
> #both on
> #2.4.1 Patched (2007-03-21 r40875); x86_64-unknown-freebsd6.2
> #and
> #2.5.0 alpha (2007-03-30 r40957); i386-pc-mingw32
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From mgd at santafe.edu  Fri Mar 30 22:56:35 2007
From: mgd at santafe.edu (Marcus G. Daniels)
Date: Fri, 30 Mar 2007 14:56:35 -0600
Subject: [Rd] error in lattice formattedTicksAndLabels.Date (PR#9590)
In-Reply-To: <20070329161024.DE9455DE81@slim.kubism.ku.dk>
References: <20070329161024.DE9455DE81@slim.kubism.ku.dk>
Message-ID: <460D7983.4010000@santafe.edu>

Hi Jim,
> x <- rnorm(12)
> t <- seq( as.Date("2006-04-01"),by="month", length=12)
>
> plot(x~t)      # Has labels "May", "Jul", "Sep", "Nov", Jan", "Mar"
> xyplot(x~t)    # Has labels "Jan", "Mar"
How about:

plot(x~t,xaxt="n")
axis(1,at=t,labels=format.Date(t))


From simon.urbanek at r-project.org  Fri Mar 30 23:04:55 2007
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Fri, 30 Mar 2007 17:04:55 -0400
Subject: [Rd] Replacing slot of S4 class in method of S4 class?
In-Reply-To: <460D76F2.1060300@aon.at>
References: <460D76F2.1060300@aon.at>
Message-ID: <1699164A-2765-43DB-B31D-CD698C3F01CC@r-project.org>

Please read the posting guide and use the appropriate mailing list (R- 
help) - your question has nothing to do with the development of R.

Cheers,
Simon

PS: look closely at your code - your mymethod is a noop.


On Mar 30, 2007, at 4:45 PM, cstrato wrote:

> Dear all,
>
> Assume that I have an S4 class "MyClass" with a slot "myname", which
> is initialized to:  myname="" in method("initialize"):
>    myclass <- new("MyClass", myname="")
>
> Assume that class "MyClass" has a method "mymethod":
>    "mymethod.MyClass" <-
>    function(object, myname=character(0), ...) {
>        object at myname <- myname;
>    #or:    myName(object) <- myname
>    }
>    setMethod("mymethod", "MyClass", mymethod.MyClass);
>
> Furthermore, I have a replacement method:
> setReplaceMethod("myName", signature(object="MyClass",  
> value="character"),
>    function(object, value) {
>       object at myname <- value;
>       return(object);
>    }
> )
>
> I know that it is possible to call:
>    myName(myclass) <- "newname"
>
> However, I want to replace the value of slot "myname" for object  
> "myclass"
> in method "mymethod":
>    mymethod(myclass,  myname="newname")
>
> Sorrowly, the above code in method "mymethod" does not work.
>
> Is there a possibility to change the value of a slot in the method  
> of a
> class?
>
> Best regards
> Christian
> _._._._._._._._._._._._._._._._
> C.h.i.s.t.i.a.n S.t.r.a.t.o.w.a
> V.i.e.n.n.a       A.u.s.t.r.i.a
> _._._._._._._._._._._._._._._._
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From ross at biostat.ucsf.edu  Fri Mar 30 23:35:06 2007
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Fri, 30 Mar 2007 14:35:06 -0700
Subject: [Rd] Replacing slot of S4 class in method of S4 class?
In-Reply-To: <460D76F2.1060300@aon.at>
References: <460D76F2.1060300@aon.at>
Message-ID: <20070330213506.GA16934@wheat.betterworld.us>

On Fri, Mar 30, 2007 at 10:45:38PM +0200, cstrato wrote:
> Dear all,
> 
> Assume that I have an S4 class "MyClass" with a slot "myname", which
> is initialized to:  myname="" in method("initialize"):
>    myclass <- new("MyClass", myname="")
> 
> Assume that class "MyClass" has a method "mymethod":
>    "mymethod.MyClass" <-
>    function(object, myname=character(0), ...) {
>        object at myname <- myname;
>    #or:    myName(object) <- myname
>    }
>    setMethod("mymethod", "MyClass", mymethod.MyClass);
> 
> Furthermore, I have a replacement method:
> setReplaceMethod("myName", signature(object="MyClass", value="character"),
>    function(object, value) {
>       object at myname <- value;
>       return(object);
>    }
> )
> 
> I know that it is possible to call:
>    myName(myclass) <- "newname"
> 
> However, I want to replace the value of slot "myname" for object "myclass"
> in method "mymethod":
>    mymethod(myclass,  myname="newname")
> 
> Sorrowly, the above code in method "mymethod" does not work.
> 
> Is there a possibility to change the value of a slot in the method of a 
> class?

Yes, but to make the effect persistent (visible might be a more
accurate description) that method must return the
object being updated, and you must use the return value.  R uses call
by value semantics, so in the definition of mymethod.MyClass when you
change object you only change a local copy.  It needs to be
 "mymethod.MyClass" <-
    function(object, myname=character(0), ...) {
        object at myname <- myname;
	object
  }

Further, if you invoke it with
mymethod(myclass, "new name")
you will discover myclass is unchanged.  You need
myclass <- mymethod(myclass, "new name")

You might consider using the R.oo package, which probably has
semantics closer to what you're expecting.  Alternately, you could
study more about R and functional programming.

Ross Boylan

P.S. Regarding the follow up saying that this is the wrong list, the
guide to mailing lists says of R-devel
"This list is intended for questions and discussion about code
development in R. Questions likely to prompt discussion unintelligible
to non-programmers or topics that are too technical for R-help's
audience should go to R-devel,"
The question seems to fall under this description to me, though I am
not authoritative.  It is true that further study would have disclosed
what is going on.  Since the same thing tripped me up too, I thought
I'd share the answer.


From ross at biostat.ucsf.edu  Fri Mar 30 23:47:56 2007
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Fri, 30 Mar 2007 14:47:56 -0700
Subject: [Rd] Rmpi and OpenMPI ?
In-Reply-To: <17933.27791.611377.369470@basebud.nulle.part>
References: <17929.54296.884935.214790@basebud.nulle.part>
	<dc41e1260703292048j65ed60bfv13f4eb6862de6715@mail.gmail.com>
	<17933.27791.611377.369470@basebud.nulle.part>
Message-ID: <20070330214756.GB16934@wheat.betterworld.us>

On Fri, Mar 30, 2007 at 03:01:19PM -0500, Dirk Eddelbuettel wrote:
> 
> On 30 March 2007 at 12:48, Ei-ji Nakama wrote:
> | Prof. Nakano(ism Japan) and I wrestled in Rmpi on HP-MPI.
> | Do not know a method to distinguish MPI well?
> | It is an ad-hoc patch at that time as follows.

There are some autoconf snippets for figuring out how to compile
various MPI versions; it's not clear to me they are much help in
figuring out which version you've got.  Perhaps they are some help:
http://autoconf-archive.cryp.to/ax_openmp.html
http://autoconf-archive.cryp.to/acx_mpi.html

Ross


From deepayan.sarkar at gmail.com  Fri Mar 30 23:59:51 2007
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Fri, 30 Mar 2007 14:59:51 -0700
Subject: [Rd] error in lattice formattedTicksAndLabels.Date (PR#9590)
In-Reply-To: <20070329161024.DE9455DE81@slim.kubism.ku.dk>
References: <20070329161024.DE9455DE81@slim.kubism.ku.dk>
Message-ID: <eb555e660703301459o78faca6fna2cb31b67869909f@mail.gmail.com>

On 3/29/07, jszinger at gmail.com <jszinger at gmail.com> wrote:
> Full_Name: James Szinger
> Version: 2.4.1
> OS: linux and MacOS X
> Submission from: (NULL) (128.165.24.206)

Bugs in packages are supposed to go to package maintainers, not r-bugs.

> I'm trying to plot some data from the past 12 months and the lattice package is
> not labeling the time axis correctly.  It shows only two labels instead of the
> expected 12.  The base graphics get it right.
>
> I think the problem is the commented-out line in formattedTicksAndLabels.Date in
> lattice's axis.R:
>     ## z <- c(range, x[is.finite(x)])

Why do you think so? This has nothing to do with it.

> The following example demonstrates the problem:
>
> require(lattice)  #lattice_0.14-16
>
> x <- rnorm(12)
> t <- seq( as.Date("2006-04-01"),by="month", length=12)
>
> plot(x~t)      # Has labels "May", "Jul", "Sep", "Nov", Jan", "Mar"
> xyplot(x~t)    # Has labels "Jan", "Mar"

The problem is in the nuances of the algorithm used. You can trigger
the same behavior with base graphics by mimicking what's happening
internally in lattice:

> tt = lattice:::extend.limits(range(t))
> tt
[1] "2006-03-08" "2007-03-24"
> plot(range(x) ~ tt, xaxs = "i")

There is a fundamental difference in how base and lattice handle axis
annotation. In particular, base uses all the data to determine tick
positions, while lattice uses only the range. This is hard to change
given how lattice comes up with a common range combining different
panels. It might still be possible to get around this, but don't
expect a quick solution.

(You can of course specify tick positions explicitly using 'scales')

-Deepayan


From cstrato at aon.at  Sat Mar 31 00:10:15 2007
From: cstrato at aon.at (cstrato)
Date: Sat, 31 Mar 2007 00:10:15 +0200
Subject: [Rd] Replacing slot of S4 class in method of S4 class?
In-Reply-To: <20070330213506.GA16934@wheat.betterworld.us>
References: <460D76F2.1060300@aon.at>
	<20070330213506.GA16934@wheat.betterworld.us>
Message-ID: <460D8AC7.8040404@aon.at>

Dear Ross

Thank you for your explanation, now mymethod works (Simon gave me 
already a hint).

Regarding the use of this list, I am confused. Which of my former questions
regarding S4 classes belong to this list:
https://stat.ethz.ch/pipermail/r-devel/2007-March/044840.html
https://stat.ethz.ch/pipermail/r-devel/2007-March/044918.html
https://stat.ethz.ch/pipermail/r-devel/2007-March/044937.html
Since I am trying to develop a package for Bioconductor, should I use the
Bioconductor development list instead?

Best regards
Christian


Ross Boylan wrote:
> On Fri, Mar 30, 2007 at 10:45:38PM +0200, cstrato wrote:
>   
>> Dear all,
>>
>> Assume that I have an S4 class "MyClass" with a slot "myname", which
>> is initialized to:  myname="" in method("initialize"):
>>    myclass <- new("MyClass", myname="")
>>
>> Assume that class "MyClass" has a method "mymethod":
>>    "mymethod.MyClass" <-
>>    function(object, myname=character(0), ...) {
>>        object at myname <- myname;
>>    #or:    myName(object) <- myname
>>    }
>>    setMethod("mymethod", "MyClass", mymethod.MyClass);
>>
>> Furthermore, I have a replacement method:
>> setReplaceMethod("myName", signature(object="MyClass", value="character"),
>>    function(object, value) {
>>       object at myname <- value;
>>       return(object);
>>    }
>> )
>>
>> I know that it is possible to call:
>>    myName(myclass) <- "newname"
>>
>> However, I want to replace the value of slot "myname" for object "myclass"
>> in method "mymethod":
>>    mymethod(myclass,  myname="newname")
>>
>> Sorrowly, the above code in method "mymethod" does not work.
>>
>> Is there a possibility to change the value of a slot in the method of a 
>> class?
>>     
>
> Yes, but to make the effect persistent (visible might be a more
> accurate description) that method must return the
> object being updated, and you must use the return value.  R uses call
> by value semantics, so in the definition of mymethod.MyClass when you
> change object you only change a local copy.  It needs to be
>  "mymethod.MyClass" <-
>     function(object, myname=character(0), ...) {
>         object at myname <- myname;
> 	object
>   }
>
> Further, if you invoke it with
> mymethod(myclass, "new name")
> you will discover myclass is unchanged.  You need
> myclass <- mymethod(myclass, "new name")
>
> You might consider using the R.oo package, which probably has
> semantics closer to what you're expecting.  Alternately, you could
> study more about R and functional programming.
>
> Ross Boylan
>
> P.S. Regarding the follow up saying that this is the wrong list, the
> guide to mailing lists says of R-devel
> "This list is intended for questions and discussion about code
> development in R. Questions likely to prompt discussion unintelligible
> to non-programmers or topics that are too technical for R-help's
> audience should go to R-devel,"
> The question seems to fall under this description to me, though I am
> not authoritative.  It is true that further study would have disclosed
> what is going on.  Since the same thing tripped me up too, I thought
> I'd share the answer.
>
>
>


From edd at debian.org  Sat Mar 31 00:55:09 2007
From: edd at debian.org (Dirk Eddelbuettel)
Date: Fri, 30 Mar 2007 17:55:09 -0500
Subject: [Rd] Rmpi and OpenMPI ?
In-Reply-To: <20070330214756.GB16934@wheat.betterworld.us>
References: <17929.54296.884935.214790@basebud.nulle.part>
	<dc41e1260703292048j65ed60bfv13f4eb6862de6715@mail.gmail.com>
	<17933.27791.611377.369470@basebud.nulle.part>
	<20070330214756.GB16934@wheat.betterworld.us>
Message-ID: <17933.38221.317265.758462@basebud.nulle.part>


Ross,

On 30 March 2007 at 14:47, Ross Boylan wrote:
| On Fri, Mar 30, 2007 at 03:01:19PM -0500, Dirk Eddelbuettel wrote:
| > 
| > On 30 March 2007 at 12:48, Ei-ji Nakama wrote:
| > | Prof. Nakano(ism Japan) and I wrestled in Rmpi on HP-MPI.
| > | Do not know a method to distinguish MPI well?
| > | It is an ad-hoc patch at that time as follows.
| 
| There are some autoconf snippets for figuring out how to compile
| various MPI versions; it's not clear to me they are much help in
| figuring out which version you've got.  Perhaps they are some help:

Thanks, potentially very helpful.  

| http://autoconf-archive.cryp.to/ax_openmp.html

[ Nit:  OpenMP != OpenMPI ]

| http://autoconf-archive.cryp.to/acx_mpi.html

That seems more about testing C, C++ and F77/F90 for MPI. Still useful, but
not a discriminator between different MPI flavours.

But I don't mean to criticise -- this autoconf-archive looke very useful, so
thanks again.

Dirk

-- 
Hell, there are no rules here - we're trying to accomplish something. 
                                                  -- Thomas A. Edison


From hb at stat.berkeley.edu  Sat Mar 31 08:28:51 2007
From: hb at stat.berkeley.edu (Henrik Bengtsson)
Date: Fri, 30 Mar 2007 23:28:51 -0700
Subject: [Rd] Too long pathname in bitmap() crashes R on WinXP
Message-ID: <59d7961d0703302328ha435a50u3f9c5deb2a9b01a3@mail.gmail.com>

Hi,

using too long pathnames for bitmap() crash R on WinXP.  I've verified
that this is the case with R version 2.4.1 Patched (2007-03-25 r40958)
and R version 2.5.0 alpha (2007-03-30 r40957). I cannot reproduce it
on Linux.

REPRODUCIBLE EXAMPLE:

% Rterm --vanilla

# Tell R where Ghostscript is
gsexe <- "C:/gs/gs8.54/bin/gswin32c.exe";
gsexe <- "C:/Program Files/gs/gs8.56/bin/gswin32c.exe";
gsexe <- shortPathName(gsexe);
Sys.putenv("R_GSCMD"=gsexe);

# Total length of pathname (R crashes when it is too long)
n <- 130;

# Output path
path <- tempdir();

# Filename
name <- paste(rep("a", n-5-nchar(path)), collapse="");
filename <- paste(name, "png", sep=".");

# Full pathname
pathname <- file.path(path, filename);
print(pathname);
stopifnot(nchar(pathname) == n);

bitmap(pathname);
plot(1);
dev.off();

R crash with dev.off(), but the PNG file is still created.


# MORE DETAILED EXAMPLE:

n <- 130;
path <- tempdir();
name <- paste(rep("a", n-5-nchar(path)), collapse="");
filename <- paste(name, "png", sep=".");
pathname <- file.path(path, filename);
print(pathname);

# Tell R where Ghostscript is
gsexe <- "C:/gs/gs8.54/bin/gswin32c.exe";
gsexe <- "C:/Program Files/gs/gs8.56/bin/gswin32c.exe";
gsexe <- shortPathName(gsexe);

cmd <- paste(gsexe, " -dNOPAUSE -dBATCH -q -sDEVICE=png256 -r72
-g432x432 -sOutputFile=", pathname, sep="");
print(cmd);
print(nchar(cmd));

tmp <- tempfile();
postscript(file=tmp, width=6, height=6, pointsize=9, paper="special",
horizontal=FALSE, print.it=TRUE, command=cmd);
plot(1);
dev.off();

It seems to have to do with the length of 'cmd' (since the possible
pathname length varies with the length of 'gsexe' used).

Any ideas?

/Henrik


From ripley at stats.ox.ac.uk  Sat Mar 31 09:27:55 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 31 Mar 2007 08:27:55 +0100 (BST)
Subject: [Rd] Too long pathname in bitmap() crashes R on WinXP
In-Reply-To: <59d7961d0703302328ha435a50u3f9c5deb2a9b01a3@mail.gmail.com>
References: <59d7961d0703302328ha435a50u3f9c5deb2a9b01a3@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0703310825330.23741@gannet.stats.ox.ac.uk>

It is also possible to trigger this on Unix: a buffer in postscript() is 
PATH_MAX when it should be 2*PATH_MAX + 2.

I'll fix this in 2.5.0 alpha (there is also a potential issue inside the 
Windows' runcmd that needs fixing).

On Fri, 30 Mar 2007, Henrik Bengtsson wrote:

> Hi,
>
> using too long pathnames for bitmap() crash R on WinXP.  I've verified
> that this is the case with R version 2.4.1 Patched (2007-03-25 r40958)
> and R version 2.5.0 alpha (2007-03-30 r40957). I cannot reproduce it
> on Linux.
>
> REPRODUCIBLE EXAMPLE:
>
> % Rterm --vanilla
>
> # Tell R where Ghostscript is
> gsexe <- "C:/gs/gs8.54/bin/gswin32c.exe";
> gsexe <- "C:/Program Files/gs/gs8.56/bin/gswin32c.exe";
> gsexe <- shortPathName(gsexe);
> Sys.putenv("R_GSCMD"=gsexe);
>
> # Total length of pathname (R crashes when it is too long)
> n <- 130;
>
> # Output path
> path <- tempdir();
>
> # Filename
> name <- paste(rep("a", n-5-nchar(path)), collapse="");
> filename <- paste(name, "png", sep=".");
>
> # Full pathname
> pathname <- file.path(path, filename);
> print(pathname);
> stopifnot(nchar(pathname) == n);
>
> bitmap(pathname);
> plot(1);
> dev.off();
>
> R crash with dev.off(), but the PNG file is still created.
>
>
> # MORE DETAILED EXAMPLE:
>
> n <- 130;
> path <- tempdir();
> name <- paste(rep("a", n-5-nchar(path)), collapse="");
> filename <- paste(name, "png", sep=".");
> pathname <- file.path(path, filename);
> print(pathname);
>
> # Tell R where Ghostscript is
> gsexe <- "C:/gs/gs8.54/bin/gswin32c.exe";
> gsexe <- "C:/Program Files/gs/gs8.56/bin/gswin32c.exe";
> gsexe <- shortPathName(gsexe);
>
> cmd <- paste(gsexe, " -dNOPAUSE -dBATCH -q -sDEVICE=png256 -r72
> -g432x432 -sOutputFile=", pathname, sep="");
> print(cmd);
> print(nchar(cmd));
>
> tmp <- tempfile();
> postscript(file=tmp, width=6, height=6, pointsize=9, paper="special",
> horizontal=FALSE, print.it=TRUE, command=cmd);
> plot(1);
> dev.off();
>
> It seems to have to do with the length of 'cmd' (since the possible
> pathname length varies with the length of 'gsexe' used).
>
> Any ideas?
>
> /Henrik
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From hb at stat.berkeley.edu  Sat Mar 31 17:36:12 2007
From: hb at stat.berkeley.edu (Henrik Bengtsson)
Date: Sat, 31 Mar 2007 08:36:12 -0700
Subject: [Rd] Too long pathname in bitmap() crashes R on WinXP
In-Reply-To: <Pine.LNX.4.64.0703310825330.23741@gannet.stats.ox.ac.uk>
References: <59d7961d0703302328ha435a50u3f9c5deb2a9b01a3@mail.gmail.com>
	<Pine.LNX.4.64.0703310825330.23741@gannet.stats.ox.ac.uk>
Message-ID: <59d7961d0703310836o24d26d2awaa63aff78d28f097@mail.gmail.com>

Thanks. /Henrik

On 3/31/07, Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
> It is also possible to trigger this on Unix: a buffer in postscript() is
> PATH_MAX when it should be 2*PATH_MAX + 2.
>
> I'll fix this in 2.5.0 alpha (there is also a potential issue inside the
> Windows' runcmd that needs fixing).
>
> On Fri, 30 Mar 2007, Henrik Bengtsson wrote:
>
> > Hi,
> >
> > using too long pathnames for bitmap() crash R on WinXP.  I've verified
> > that this is the case with R version 2.4.1 Patched (2007-03-25 r40958)
> > and R version 2.5.0 alpha (2007-03-30 r40957). I cannot reproduce it
> > on Linux.
> >
> > REPRODUCIBLE EXAMPLE:
> >
> > % Rterm --vanilla
> >
> > # Tell R where Ghostscript is
> > gsexe <- "C:/gs/gs8.54/bin/gswin32c.exe";
> > gsexe <- "C:/Program Files/gs/gs8.56/bin/gswin32c.exe";
> > gsexe <- shortPathName(gsexe);
> > Sys.putenv("R_GSCMD"=gsexe);
> >
> > # Total length of pathname (R crashes when it is too long)
> > n <- 130;
> >
> > # Output path
> > path <- tempdir();
> >
> > # Filename
> > name <- paste(rep("a", n-5-nchar(path)), collapse="");
> > filename <- paste(name, "png", sep=".");
> >
> > # Full pathname
> > pathname <- file.path(path, filename);
> > print(pathname);
> > stopifnot(nchar(pathname) == n);
> >
> > bitmap(pathname);
> > plot(1);
> > dev.off();
> >
> > R crash with dev.off(), but the PNG file is still created.
> >
> >
> > # MORE DETAILED EXAMPLE:
> >
> > n <- 130;
> > path <- tempdir();
> > name <- paste(rep("a", n-5-nchar(path)), collapse="");
> > filename <- paste(name, "png", sep=".");
> > pathname <- file.path(path, filename);
> > print(pathname);
> >
> > # Tell R where Ghostscript is
> > gsexe <- "C:/gs/gs8.54/bin/gswin32c.exe";
> > gsexe <- "C:/Program Files/gs/gs8.56/bin/gswin32c.exe";
> > gsexe <- shortPathName(gsexe);
> >
> > cmd <- paste(gsexe, " -dNOPAUSE -dBATCH -q -sDEVICE=png256 -r72
> > -g432x432 -sOutputFile=", pathname, sep="");
> > print(cmd);
> > print(nchar(cmd));
> >
> > tmp <- tempfile();
> > postscript(file=tmp, width=6, height=6, pointsize=9, paper="special",
> > horizontal=FALSE, print.it=TRUE, command=cmd);
> > plot(1);
> > dev.off();
> >
> > It seems to have to do with the length of 'cmd' (since the possible
> > pathname length varies with the length of 'gsexe' used).
> >
> > Any ideas?
> >
> > /Henrik
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
>
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>


From rhurlin at gwdg.de  Sat Mar 31 19:03:44 2007
From: rhurlin at gwdg.de (Rainer Hurling)
Date: Sat, 31 Mar 2007 19:03:44 +0200
Subject: [Rd] Matrix package: compilation error
Message-ID: <460E9470.1010307@gwdg.de>

Trying to compile the package Matrix_0.9975-11.tar.gz with newest 
R-2.5.0 alpha (2007-03-31 r40986) on FreeBSD 7.0-CURRENT (i386) I get 
the following error:

-----
R CMD INSTALL Matrix_0.9975-11.tar.gz
* Installing to library '/usr/local/lib/R/library'
* Installing *source* package 'Matrix' ...
** libs
** arch -
"Makefile", line 10: Missing dependency operator
"Makefile", line 12: Need an operator
"Makefile", line 14: Need an operator
make: fatal errors encountered -- cannot continue
ERROR: compilation failed for package 'Matrix'
** Removing '/usr/local/lib/R/library/Matrix'
-----


Under FreeBSD I have installed the LAPACK package (3.0.2) with library 
at location

/usr/local/lib/liblapack.so.4

Is it possible that the Makefile of package Matrix fails because of that?

Any help is appreciated,
Rainer Hurling


From cstrato at aon.at  Sat Mar 31 19:56:34 2007
From: cstrato at aon.at (cstrato)
Date: Sat, 31 Mar 2007 19:56:34 +0200
Subject: [Rd] Problem with S4 inheritance: unexpected re-initialization?
Message-ID: <460EA0D2.3060409@aon.at>

Dear all,

To explain my problem I am attaching a demonstration package "myclasspkg":
I have the following two S4 classes with similar inheritance:
   SubSubClassA <- SubClassB <- BaseClass
   SubSubClassB <- SubClassB <- BaseClass

In R I am calling the following functions:
 > library(myclasspkg)
 > subA <- 
new("SubClassA",filename="OutSubA",filedir="/Volumes/CoreData/CRAN/Workspaces/rclasspkg",mytitle="TitleSubA")
 > subsubA <- 
new("SubSubClassA",filename="MyFileName",filedir="/Volumes/CoreData/CRAN/Workspaces/rclasspkg",subA=subA)
 > subsubB <- 
new("SubSubClassB",filename="MyFileNameB",filedir="/Volumes/CoreData/CRAN/Workspaces/rclasspkg",subA=subA)

Creating subsubA works fine and gives the correct result:
 > subsubA <- 
new("SubSubClassA",filename="MyFileName",filedir="/Volumes/CoreData/CRAN/Workspaces/rclasspkg",subA=subA)
[1] "------initialize:SubSubClassA------"
[1] "SubSubClassA:init:class(.Object) =  SubSubClassA"
[1] "------initialize:SubClassB------"
[1] "SubClassB:init:class(.Object) =  SubSubClassA"
[1] "------initialize:BaseClass------"
[1] "BaseClass:init:class(.Object) =  SubSubClassA"
[1] "------pathFile------"
[1] "BaseClass:init:dirfile =  
/Volumes/CoreData/CRAN/Workspaces/rclasspkg/MyFileName"
[1] "------setValidity:BaseClass------"
[1] "BaseClass:val:class(object) =  SubClassB"
[1] "BaseClass:val:dirfile =  
/Volumes/CoreData/CRAN/Workspaces/rclasspkg/MyFileName"
[1] "BaseClass:val:filedir =  /Volumes/CoreData/CRAN/Workspaces/rclasspkg"
[1] "------setValidity:SubClassB------"
[1] "SubClassB:val:class(object) =  SubClassB"
[1] "SubClassB:val:filename =  MyFileName"
[1] "BaseClass:val:dirfile =  
/Volumes/CoreData/CRAN/Workspaces/rclasspkg/MyFileName"
[1] "------setValidity:SubSubClassA------"
[1] "SubSubClassA:val:class(.Object) =  SubSubClassA"

In contrast, when trying to create subsubB, it seems that setValidity
re-initializes SubClassB:
 > subsubB <- 
new("SubSubClassB",filename="MyFileNameB",filedir="/Volumes/CoreData/CRAN/Workspaces/rclasspkg",subA=subA)
[1] "------initialize:SubSubClassB------"
[1] "SubSubClassB:init:class(.Object) =  SubSubClassB"
[1] "SubSubClassB:init:subsubnameB =  subsubNameB"
[1] "------initialize:SubClassB------"
[1] "SubClassB:init:class(.Object) =  SubSubClassB"
[1] "------initialize:BaseClass------"
[1] "BaseClass:init:class(.Object) =  SubSubClassB"
[1] "------pathFile------"
[1] "BaseClass:init:dirfile =  
/Volumes/CoreData/CRAN/Workspaces/rclasspkg/MyFileNameB"
[1] "------setValidity:BaseClass------"
[1] "------initialize:SubClassB------"
[1] "SubClassB:init:class(.Object) =  SubClassB"
[1] "------initialize:BaseClass------"
[1] "BaseClass:init:class(.Object) =  SubClassB"
[1] "------pathFile------"
Error in if (dirname(filename) != ".") { :
        argument is of length zero

Can someone tell me why the first case works fine, but the second case not?
Probably, I am making some mistake, but since two weeks I am unable to 
find it.
Thank you in advance.

P.S.: I am running R-2.5.0 on Intel-Mac OS 10.4.8.

Best regards
Christian
_._._._._._._._._._._._._._._._
C.h.i.s.t.i.a.n S.t.r.a.t.o.w.a
V.i.e.n.n.a       A.u.s.t.r.i.a
_._._._._._._._._._._._._._._._

-------------- next part --------------
A non-text attachment was scrubbed...
Name: myclasspkg_0.1.1.tar.gz
Type: application/x-gzip
Size: 5160 bytes
Desc: not available
Url : https://stat.ethz.ch/pipermail/r-devel/attachments/20070331/06308a2d/attachment.gz 

From ripley at stats.ox.ac.uk  Sat Mar 31 20:01:26 2007
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 31 Mar 2007 19:01:26 +0100 (BST)
Subject: [Rd] Matrix package: compilation error
In-Reply-To: <460E9470.1010307@gwdg.de>
References: <460E9470.1010307@gwdg.de>
Message-ID: <Pine.LNX.4.64.0703311859120.15900@gannet.stats.ox.ac.uk>

This is because of the GNUism in Matrix/src/Makefile

## get rid of this, once we have 'Depends: R (>= 2.5.0)':
ifeq (, $(findstring -lRlapack, $(LAPACK_LIBS)))
SOURCES_LAPACK =
else
SOURCES_LAPACK = zpotf2.f zpotrf.f zlacgv.f
endif

I guess you know what you need to do to fix it for BSD make?

On Sat, 31 Mar 2007, Rainer Hurling wrote:

> Trying to compile the package Matrix_0.9975-11.tar.gz with newest
> R-2.5.0 alpha (2007-03-31 r40986) on FreeBSD 7.0-CURRENT (i386) I get
> the following error:
>
> -----
> R CMD INSTALL Matrix_0.9975-11.tar.gz
> * Installing to library '/usr/local/lib/R/library'
> * Installing *source* package 'Matrix' ...
> ** libs
> ** arch -
> "Makefile", line 10: Missing dependency operator
> "Makefile", line 12: Need an operator
> "Makefile", line 14: Need an operator
> make: fatal errors encountered -- cannot continue
> ERROR: compilation failed for package 'Matrix'
> ** Removing '/usr/local/lib/R/library/Matrix'
> -----
>
>
> Under FreeBSD I have installed the LAPACK package (3.0.2) with library
> at location
>
> /usr/local/lib/liblapack.so.4
>
> Is it possible that the Makefile of package Matrix fails because of that?

Not used unless you asked for it during R's configure.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From maechler at stat.math.ethz.ch  Sat Mar 31 20:33:21 2007
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Sat, 31 Mar 2007 20:33:21 +0200
Subject: [Rd] Matrix package: compilation error
In-Reply-To: <460E9470.1010307@gwdg.de>
References: <460E9470.1010307@gwdg.de>
Message-ID: <17934.43377.867703.247098@stat.math.ethz.ch>

>>>>> "Rainer" == Rainer Hurling <rhurlin at gwdg.de>
>>>>>     on Sat, 31 Mar 2007 19:03:44 +0200 writes:

    Rainer> Trying to compile the package
    Rainer> Matrix_0.9975-11.tar.gz 
    Rainer> with newest R-2.5.0 alpha
    Rainer> (2007-03-31 r40986) on FreeBSD 7.0-CURRENT (i386) 

does FreeBSD use a make that is 'GNU make' compatible?
Matrix/DESCRIPTION has  a line which says
--------------------------------------
SystemRequirements: GNU make
--------------------------------------

Regards,
Martin Maechler, ETH Zurich

    Rainer> I get the following error:


    Rainer> -----
    Rainer> R CMD INSTALL Matrix_0.9975-11.tar.gz
    Rainer> * Installing to library '/usr/local/lib/R/library'
    Rainer> * Installing *source* package 'Matrix' ...
    Rainer> ** libs
    Rainer> ** arch -
    Rainer> "Makefile", line 10: Missing dependency operator
    Rainer> "Makefile", line 12: Need an operator
    Rainer> "Makefile", line 14: Need an operator
    Rainer> make: fatal errors encountered -- cannot continue
    Rainer> ERROR: compilation failed for package 'Matrix'
    Rainer> ** Removing '/usr/local/lib/R/library/Matrix'
    Rainer> -----


    Rainer> Under FreeBSD I have installed the LAPACK package (3.0.2) with library 
    Rainer> at location

    Rainer> /usr/local/lib/liblapack.so.4

    Rainer> Is it possible that the Makefile of package Matrix fails because of that?

    Rainer> Any help is appreciated,
    Rainer> Rainer Hurling

    Rainer> ______________________________________________
    Rainer> R-devel at r-project.org mailing list
    Rainer> https://stat.ethz.ch/mailman/listinfo/r-devel


From rhurlin at gwdg.de  Sat Mar 31 22:10:45 2007
From: rhurlin at gwdg.de (Rainer Hurling)
Date: Sat, 31 Mar 2007 22:10:45 +0200
Subject: [Rd] Matrix package: compilation error
In-Reply-To: <Pine.LNX.4.64.0703311859120.15900@gannet.stats.ox.ac.uk>
References: <460E9470.1010307@gwdg.de>
	<Pine.LNX.4.64.0703311859120.15900@gannet.stats.ox.ac.uk>
Message-ID: <460EC045.4050205@gwdg.de>

Thanks, Brian and Martin,

I think you are both right, Matrix tries to use BSD make (/usr/bin/make) 
on FreeBSD instead of GNU make (/usr/local/bin/gmake).

Sorry, but I don't know how to persuade the configure script to use 
gmake :-(

Rainer


Prof Brian Ripley schrieb:
> This is because of the GNUism in Matrix/src/Makefile
> 
> ## get rid of this, once we have 'Depends: R (>= 2.5.0)':
> ifeq (, $(findstring -lRlapack, $(LAPACK_LIBS)))
> SOURCES_LAPACK =
> else
> SOURCES_LAPACK = zpotf2.f zpotrf.f zlacgv.f
> endif
> 
> I guess you know what you need to do to fix it for BSD make?
> 
> On Sat, 31 Mar 2007, Rainer Hurling wrote:
> 
>> Trying to compile the package Matrix_0.9975-11.tar.gz with newest
>> R-2.5.0 alpha (2007-03-31 r40986) on FreeBSD 7.0-CURRENT (i386) I get
>> the following error:
>>
>> -----
>> R CMD INSTALL Matrix_0.9975-11.tar.gz
>> * Installing to library '/usr/local/lib/R/library'
>> * Installing *source* package 'Matrix' ...
>> ** libs
>> ** arch -
>> "Makefile", line 10: Missing dependency operator
>> "Makefile", line 12: Need an operator
>> "Makefile", line 14: Need an operator
>> make: fatal errors encountered -- cannot continue
>> ERROR: compilation failed for package 'Matrix'
>> ** Removing '/usr/local/lib/R/library/Matrix'
>> -----
>>
>>
>> Under FreeBSD I have installed the LAPACK package (3.0.2) with library
>> at location
>>
>> /usr/local/lib/liblapack.so.4
>>
>> Is it possible that the Makefile of package Matrix fails because of that?
> 
> Not used unless you asked for it during R's configure.
>


From A.Robinson at ms.unimelb.edu.au  Sat Mar 31 22:24:04 2007
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Sun, 1 Apr 2007 06:24:04 +1000
Subject: [Rd] Matrix package: compilation error
In-Reply-To: <460EC045.4050205@gwdg.de>
References: <460E9470.1010307@gwdg.de>
	<Pine.LNX.4.64.0703311859120.15900@gannet.stats.ox.ac.uk>
	<460EC045.4050205@gwdg.de>
Message-ID: <20070331202404.GT47923@ms.unimelb.edu.au>

Hi Rainer,

check the following post for an alternative solution:

http://tolstoy.newcastle.edu.au/R/help/06/01/18908.html

if you would like more detailed instructions, let me know.

Andrew


On Sat, Mar 31, 2007 at 10:10:45PM +0200, Rainer Hurling wrote:
> Thanks, Brian and Martin,
> 
> I think you are both right, Matrix tries to use BSD make (/usr/bin/make) 
> on FreeBSD instead of GNU make (/usr/local/bin/gmake).
> 
> Sorry, but I don't know how to persuade the configure script to use 
> gmake :-(
> 
> Rainer
> 
> 
> Prof Brian Ripley schrieb:
> > This is because of the GNUism in Matrix/src/Makefile
> > 
> > ## get rid of this, once we have 'Depends: R (>= 2.5.0)':
> > ifeq (, $(findstring -lRlapack, $(LAPACK_LIBS)))
> > SOURCES_LAPACK =
> > else
> > SOURCES_LAPACK = zpotf2.f zpotrf.f zlacgv.f
> > endif
> > 
> > I guess you know what you need to do to fix it for BSD make?
> > 
> > On Sat, 31 Mar 2007, Rainer Hurling wrote:
> > 
> >> Trying to compile the package Matrix_0.9975-11.tar.gz with newest
> >> R-2.5.0 alpha (2007-03-31 r40986) on FreeBSD 7.0-CURRENT (i386) I get
> >> the following error:
> >>
> >> -----
> >> R CMD INSTALL Matrix_0.9975-11.tar.gz
> >> * Installing to library '/usr/local/lib/R/library'
> >> * Installing *source* package 'Matrix' ...
> >> ** libs
> >> ** arch -
> >> "Makefile", line 10: Missing dependency operator
> >> "Makefile", line 12: Need an operator
> >> "Makefile", line 14: Need an operator
> >> make: fatal errors encountered -- cannot continue
> >> ERROR: compilation failed for package 'Matrix'
> >> ** Removing '/usr/local/lib/R/library/Matrix'
> >> -----
> >>
> >>
> >> Under FreeBSD I have installed the LAPACK package (3.0.2) with library
> >> at location
> >>
> >> /usr/local/lib/liblapack.so.4
> >>
> >> Is it possible that the Makefile of package Matrix fails because of that?
> > 
> > Not used unless you asked for it during R's configure.
> >
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Andrew Robinson  
Department of Mathematics and Statistics            Tel: +61-3-8344-9763
University of Melbourne, VIC 3010 Australia         Fax: +61-3-8344-4599
http://www.ms.unimelb.edu.au/~andrewpr
http://blogs.mbs.edu/fishing-in-the-bay/


From rfrancois at mango-solutions.com  Sat Mar 31 22:31:49 2007
From: rfrancois at mango-solutions.com (Romain Francois)
Date: Sat, 31 Mar 2007 21:31:49 +0100
Subject: [Rd] Probem with argument "append" in "Rprof"
Message-ID: <460EC535.600@mango-solutions.com>

Hello,

Appending information to the profiler's output seems to generate
problems. Here is a small example of code :

<code r>
require(boot)
Rprof( memory.profiling = TRUE)
Rprof(NULL)
for(i in 1:2){
  Rprof( memory.profiling = TRUE, append = TRUE)
  example(boot)
  Rprof(NULL)
}
</code>

The problem is that the file Rprof.out contains more than once the
header information:

$ grep "sample.interval=" Rprof.out
memory profiling: sample.interval=20000
memory profiling: sample.interval=20000
memory profiling: sample.interval=20000

and `summaryRprof` or `R CMD Rprof` are not dealing with it

> idx <- grep( "sample", rownames( smp <- summaryRprof()[[1]] ) );
smp[idx, ]
                      self.time self.pct total.time total.pct
sample.interval=20000         0        0       0.04       0.1

`sample.interval=20000` is incorrectly considered as a function.


This is not too much of a big deal, but then if I ask for memory
profiling information as well, I get nothing:

> summaryRprof( mem = "stats")
Error in tapply(1:1L, list(index = c("sample.interval=20000:profiling:",  :
        arguments must have same length
> summaryRprof( mem = "tseries")
Error in data.frame(..., check.names = FALSE) :
        arguments imply differing number of rows: 1, 1490
> summaryRprof( mem = "both")
Error in apply(sapply(strsplit(memstuff, ":"), as.numeric), 1, diff) :
        dim(X) must have a positive length

$ R CMD Rprof Rprof.out

Each sample represents  seconds.
Total run time: 0 seconds.

Total seconds: time spent in function and callees.
Self seconds: time spent in function alone.

   %       total       %       self
 total    seconds     self    seconds    name
Illegal division by zero at /usr/local/lib/R/bin/Rprof line 91, <> line
1491.
                         
A quick fix could be to ignore all the lines containing sample.interval=
except the first one, but then if someone wants to actually change the
interval argument in Rprof, it would not be correct. I attach a patch
against R-devel/src/library/utils/R/summRprof.R to do that anyway, but I
will look at a better solution.

I am not fluent enough in Perl to do the same in the Rprof script, it
looks like it does not handle the memory profiling information anyway. I
am about to learn Perl, so I guess it could be a useful way to do it. I
also attach a patch against R-devel/src/scripts/Rprof that would at
least get rid of the memory profiling information (if any). This is not
as good as dealing with it, but ... this is the first time I ever touch
a Perl script.


Cheers,

Romain



> version
              
_                                                              
platform      
i686-pc-linux-gnu                                              
arch          
i686                                                           
os            
linux-gnu                                                      
system         i686,
linux-gnu                                                
status         Under development
(unstable)                                   
major         
2                                                              
minor          6.0                                  
year          
2007                                                           
month         
03                                                             
day           
30                                                             
svn rev       
40983                                                          
language      
R                                                              
version.string R version 2.6.0 Under development (unstable) (2007-03-30
r40983)

-- 
Mango Solutions
data analysis that delivers

Tel:  +44(0) 1249 467 467
Fax:  +44(0) 1249 467 468
Mob:  +44(0) 7813 526 123

-------------- next part --------------
A non-text attachment was scrubbed...
Name: summRprof.patch
Type: text/x-patch
Size: 770 bytes
Desc: not available
Url : https://stat.ethz.ch/pipermail/r-devel/attachments/20070331/bed20353/attachment.bin 

From rfrancois at mango-solutions.com  Sat Mar 31 22:33:42 2007
From: rfrancois at mango-solutions.com (Romain Francois)
Date: Sat, 31 Mar 2007 21:33:42 +0100
Subject: [Rd] Probem with argument "append" in "Rprof"
Message-ID: <460EC5A6.8080401@mango-solutions.com>

[forgot to attach the second patch in the first mail, sorry.]

Hello,

Appending information to the profiler's output seems to generate
problems. Here is a small example of code :

<code r>
require(boot)
Rprof( memory.profiling = TRUE)
Rprof(NULL)
for(i in 1:2){
  Rprof( memory.profiling = TRUE, append = TRUE)
  example(boot)
  Rprof(NULL)
}
</code>

The problem is that the file Rprof.out contains more than once the
header information:

$ grep "sample.interval=" Rprof.out
memory profiling: sample.interval=20000
memory profiling: sample.interval=20000
memory profiling: sample.interval=20000

and `summaryRprof` or `R CMD Rprof` are not dealing with it

> idx <- grep( "sample", rownames( smp <- summaryRprof()[[1]] ) );
smp[idx, ]
                      self.time self.pct total.time total.pct
sample.interval=20000         0        0       0.04       0.1

`sample.interval=20000` is incorrectly considered as a function.


This is not too much of a big deal, but then if I ask for memory
profiling information as well, I get nothing:

> summaryRprof( mem = "stats")
Error in tapply(1:1L, list(index = c("sample.interval=20000:profiling:",  :
        arguments must have same length
> summaryRprof( mem = "tseries")
Error in data.frame(..., check.names = FALSE) :
        arguments imply differing number of rows: 1, 1490
> summaryRprof( mem = "both")
Error in apply(sapply(strsplit(memstuff, ":"), as.numeric), 1, diff) :
        dim(X) must have a positive length

$ R CMD Rprof Rprof.out

Each sample represents  seconds.
Total run time: 0 seconds.

Total seconds: time spent in function and callees.
Self seconds: time spent in function alone.

   %       total       %       self
 total    seconds     self    seconds    name
Illegal division by zero at /usr/local/lib/R/bin/Rprof line 91, <> line
1491.

A quick fix could be to ignore all the lines containing sample.interval=
except the first one, but then if someone wants to actually change the
interval argument in Rprof, it would not be correct. I attach a patch
against R-devel/src/library/utils/R/summRprof.R to do that anyway, but I
will look at a better solution.

I am not fluent enough in Perl to do the same in the Rprof script, it
looks like it does not handle the memory profiling information anyway. I
am about to learn Perl, so I guess it could be a useful way to do it. I
also attach a patch against R-devel/src/scripts/Rprof that would at
least get rid of the memory profiling information (if any). This is not
as good as dealing with it, but ... this is the first time I ever touch
a Perl script.


Cheers,

Romain



> version

_
platform
i686-pc-linux-gnu
arch
i686
os
linux-gnu
system         i686,
linux-gnu
status         Under development
(unstable)
major
2
minor          6.0
year
2007
month
03
day
30
svn rev
40983
language
R
version.string R version 2.6.0 Under development (unstable) (2007-03-30
r40983)

-- 
Mango Solutions
data analysis that delivers

Tel:  +44(0) 1249 467 467
Fax:  +44(0) 1249 467 468
Mob:  +44(0) 7813 526 123


-------------- next part --------------
A non-text attachment was scrubbed...
Name: summRprof.patch
Type: text/x-patch
Size: 771 bytes
Desc: not available
Url : https://stat.ethz.ch/pipermail/r-devel/attachments/20070331/5df186d4/attachment.bin 
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Rprof.patch
Type: text/x-patch
Size: 412 bytes
Desc: not available
Url : https://stat.ethz.ch/pipermail/r-devel/attachments/20070331/5df186d4/attachment-0001.bin 

From rhurlin at gwdg.de  Sat Mar 31 22:40:01 2007
From: rhurlin at gwdg.de (Rainer Hurling)
Date: Sat, 31 Mar 2007 22:40:01 +0200
Subject: [Rd] Matrix package: compilation error
In-Reply-To: <20070331202404.GT47923@ms.unimelb.edu.au>
References: <460E9470.1010307@gwdg.de>
	<Pine.LNX.4.64.0703311859120.15900@gannet.stats.ox.ac.uk>
	<460EC045.4050205@gwdg.de>
	<20070331202404.GT47923@ms.unimelb.edu.au>
Message-ID: <460EC721.9060206@gwdg.de>

Thank you Andrew,

'setenv MAKE gmake' did it.

Now I can use latest spdep package :-)

Rainer


Andrew Robinson schrieb:
> Hi Rainer,
> 
> check the following post for an alternative solution:
> 
> http://tolstoy.newcastle.edu.au/R/help/06/01/18908.html
> 
> if you would like more detailed instructions, let me know.
> 
> Andrew
> 
> 
> On Sat, Mar 31, 2007 at 10:10:45PM +0200, Rainer Hurling wrote:
>> Thanks, Brian and Martin,
>>
>> I think you are both right, Matrix tries to use BSD make (/usr/bin/make) 
>> on FreeBSD instead of GNU make (/usr/local/bin/gmake).
>>
>> Sorry, but I don't know how to persuade the configure script to use 
>> gmake :-(
>>
>> Rainer
>>
>>
>> Prof Brian Ripley schrieb:
>>> This is because of the GNUism in Matrix/src/Makefile
>>>
>>> ## get rid of this, once we have 'Depends: R (>= 2.5.0)':
>>> ifeq (, $(findstring -lRlapack, $(LAPACK_LIBS)))
>>> SOURCES_LAPACK =
>>> else
>>> SOURCES_LAPACK = zpotf2.f zpotrf.f zlacgv.f
>>> endif
>>>
>>> I guess you know what you need to do to fix it for BSD make?
>>>
>>> On Sat, 31 Mar 2007, Rainer Hurling wrote:
>>>
>>>> Trying to compile the package Matrix_0.9975-11.tar.gz with newest
>>>> R-2.5.0 alpha (2007-03-31 r40986) on FreeBSD 7.0-CURRENT (i386) I get
>>>> the following error:
>>>>
>>>> -----
>>>> R CMD INSTALL Matrix_0.9975-11.tar.gz
>>>> * Installing to library '/usr/local/lib/R/library'
>>>> * Installing *source* package 'Matrix' ...
>>>> ** libs
>>>> ** arch -
>>>> "Makefile", line 10: Missing dependency operator
>>>> "Makefile", line 12: Need an operator
>>>> "Makefile", line 14: Need an operator
>>>> make: fatal errors encountered -- cannot continue
>>>> ERROR: compilation failed for package 'Matrix'
>>>> ** Removing '/usr/local/lib/R/library/Matrix'
>>>> -----
>>>>
>>>>
>>>> Under FreeBSD I have installed the LAPACK package (3.0.2) with library
>>>> at location
>>>>
>>>> /usr/local/lib/liblapack.so.4
>>>>
>>>> Is it possible that the Makefile of package Matrix fails because of that?
>>> Not used unless you asked for it during R's configure.
>>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>


