From ripley at stats.ox.ac.uk  Sun Dec  1 07:55:42 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 01 Dec 2013 06:55:42 +0000
Subject: [Rd] Setting locale to support UTF-8
In-Reply-To: <529A45F9.3090101@gmail.com>
References: <529A45F9.3090101@gmail.com>
Message-ID: <529ADD6E.1040101@stats.ox.ac.uk>

On 30/11/2013 20:09, Duncan Murdoch wrote:
> In Sweave, if the locale is set to C, non-ASCII characters are not
> handled nicely even if I declare the encoding of the file to be "UTF-8".
>   I'm trying to find a workaround for this, because I'm using Sweave
> from within TeXShop.   TeXShop runs its typesetting engines in the C
> locale, and non-ascii characters are messed up.
>
> Is there a way to declare that I am in a "generic" UTF-8 locale?  It is
> like the C locale in other respects, but it knows about UTF-8 characters.

Locales are about more than encodings, but LC_CTYPE=en_US.UTF-8 will 
works almost everywhere.  The only place I know where it might give 
trouble is Debian which micromanages glibc and makes installation of 
locales optional.

But on a OS which supports UTF-8 locales it would be perverse not to 
have a least one UTF-8 locale installed.

(There is also the issue of .UTF-8 vs .utf8, but I think everyone 
accepts the first now.)

>
> Duncan Murdoch
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From jeroen.ooms at stat.ucla.edu  Mon Dec  2 07:32:58 2013
From: jeroen.ooms at stat.ucla.edu (Jeroen Ooms)
Date: Sun, 1 Dec 2013 22:32:58 -0800
Subject: [Rd] g++ ignores TMPDIR when called from install.packages
Message-ID: <CABFfbXs0gfuyPhdCyn-KAcnSqxC2qC8vSowVORUAwkNXZj5yig@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20131201/af01e818/attachment.pl>

From karl.forner at gmail.com  Mon Dec  2 10:18:16 2013
From: karl.forner at gmail.com (Karl Forner)
Date: Mon, 2 Dec 2013 10:18:16 +0100
Subject: [Rd] How to catch warnings sent by arguments of s4 methods ?
In-Reply-To: <CAMd4_AfmWJ7bYS31QH1Gt+==QVXR=E-RQtgV8MsUUQ_iwsf9rw@mail.gmail.com>
References: <CAMd4_AfmWJ7bYS31QH1Gt+==QVXR=E-RQtgV8MsUUQ_iwsf9rw@mail.gmail.com>
Message-ID: <CAMd4_AekqTPSAFNv=wfAc0HoNZcdk6=NQaubozuPc1feVo1vJw@mail.gmail.com>

Hi,
Just to add some information and to clarify why I feel this is an
important issue.

If you have a S4 method with a default argument, it seems that you can
not catch the warnings
emitted during their evaluation. It matters because on some occasions
those warnings carry an essential information,
that your code needs to use.

Martin Morgan added some information about this issue on:
http://stackoverflow.com/questions/20268021/how-to-catch-warnings-sent-during-s4-method-selection
Basically the C function R_dispatchGeneric  uses R_tryEvalSilent to
evaluate the method arguments, that seems no to use the calling
handlers.

Best,
Karl


On Fri, Nov 29, 2013 at 11:30 AM, Karl Forner <karl.forner at gmail.com> wrote:
> Hello,
>
> I apologized if this had already been addressed, and I also submitted
> this problem on SO:
> http://stackoverflow.com/questions/20268021/how-to-catch-warnings-sent-during-s4-method-selection
>
> Example code:
> setGeneric('my_method', function(x) standardGeneric('my_method') )
> setMethod('my_method', 'ANY', function(x) invisible())
>
> withCallingHandlers(my_method(warning('argh')), warning = function(w)
> { stop('got warning:', w) })
> # this does not catch the warning
>
> It seems that the warnings emitted during the evaluation of the
> arguments of S4 methods can not get caught using
> withCallingHandlers().
>
> Is this expected ? Is there a work-around ?
>
> Best,
> Karl Forner


From edd at debian.org  Mon Dec  2 14:04:04 2013
From: edd at debian.org (Dirk Eddelbuettel)
Date: Mon, 2 Dec 2013 07:04:04 -0600
Subject: [Rd] R 3.1.0 and C++11
In-Reply-To: <21075.11278.577153.103691@max.nulle.part>
References: <21073.63553.888272.510490@max.nulle.part>
	<31E214B6DF75104E942856C2F74953CB0505C0F9@exchange>
	<21075.11278.577153.103691@max.nulle.part>
Message-ID: <21148.34116.611590.24751@max.nulle.part>


Following up on the thread spawned a while back, I just wanted to say that I
appreciate today's RSS serving of R-devel NEWS:

   CHANGES IN R-devel PACKAGE INSTALLATION

   There is _experimental_ support for compiling C++11 code in packages. The
   file ?src/Makevars? or ?src/Makevars.win? should define the macro
   ?USE_CXX11 = true?. Where needed, an alternative C++11 compiler can be
   specified by setting macros ?CXX11?, ?CXX11FLAGS? and so on, either when R
   is configured or in a personal ?Makevars? file. (The default is to use
   ?$(CXX) -std=c++11?.) 

Thanks for initial and incremental changes. They are appreciated.

Dirk

-- 
Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com


From Peder.Axensten at slu.se  Mon Dec  2 15:57:17 2013
From: Peder.Axensten at slu.se (Peder Axensten)
Date: Mon, 2 Dec 2013 14:57:17 +0000
Subject: [Rd] pesky \usage-warnings with R CMD check
Message-ID: <D6B4F090-152F-4F06-8664-8112B6BA7DC7@slu.se>

I?m in the process of preparing a package for CRAN.

The package is called ?exportR? and since it really just consists of one function, I found it natural to call it ?exportR? too.

The function returns a function that does the actual job, but it is set up to work in different ways, depending on the arguments given to its creator. In short:
library( exportR )
exporter <- exportR( the, arguments )
exporter( its, own, arguments )

When I run R CMD check I get two warnings:
-----------------
* checking for code/documentation mismatches ... WARNING
Functions or methods with usage in documentation object 'exportR' but not in code:
  exporter

* checking Rd \usage sections ... WARNING
Assignments in \usage in documentation object 'exportR':
  exporter <- exportR(fname, type = "latex", format = "4", prefix = "", 
      append = FALSE)

Functions with \usage entries need to have the appropriate \alias
entries, and all their arguments documented.
The \usage entries must correspond to syntactically valid R code.
See the chapter ?Writing R documentation files? in the ?Writing R
Extensions? manual.
????????

The first warning I understand, but I don?t know how to proceed to rid myself of it. Indeed it is nowhere in my code, as exportR creates it, but I still need to document it. I would very much appreciate advice.

The second warning I don?t understand. I do have both \name{exportR} and \alias{exportR} (as well as \alias{exporter}) at the top of the .Rd file. The function name, arguments, and default values are copied directly from the source, so they are identical. I changed the package name to exporteR to see if the problem was that the package name and the function name were the same, but that did not remove the warning. I used package.skeleton to create a .Rd template for the function and it was syntactically identical. Installing the package and running it works, obviously. I?m running out of ideas and any help is appreciated. I have this nagging feeling that I?m missing something obvious?? 

I post the entire contents of the .Rd file at the bottom.

Best regards,

Peder Axensten
Research engineer

Swedish University of Agricultural Sciences
Department of Forest Resource Management
Remote Sensing
SE-901 83 Ume?
Visiting address: Skogsmarksgr?nd
Phone: +46 90 786 85 00
peder.axensten at slu.se, www.slu.se/srh

The Department of Forest Resource Management is environmentally certified in accordance with ISO 14001.

??????????????????????????????????
\name{exportR}
\alias{exportR}
\alias{export}
\alias{exporter}
\alias{latex}
\alias{conversion}
\alias{exportR.latex}
\title{Easy export of R results}
\description{A flexible and simple way to export R results to LaTeX and [maybe later] other formats.}
\usage{
exporter <- exportR( fname, type="latex", format="4", prefix="", append=FALSE )
exporter( ..., format=NA, prefix=NA, named=FALSE )
}
\arguments{
	\item{...}{The value[s] to be exported. To name them, use the normal R convention: \code{exporter(first=123, second=456)}. If no such name is given, the variable name is used:  \code{exporter(myvar, second=456)}. For other expressions the naming is undetermined, be sure to name them: \code{exporter(myname=2*pi/sqrt(2))}. Non-valid characters will be substituted by \code{x}, i.e. \code{my_var1} will result in \code{\\myxvarx} in LaTeX.}
	\item{fname}{The path to the destination file.}
	\item{type}{The name of export file type, e.g. \code{exporter}. May be a string vector to export to more than one format at once. But presently, only \code{exporter} is implemented.}
	\item{format}{The numerical format to use. When given to \code{exportR}, it sets the default \code{.format} to be used by \code{exporter}. When used in a call to \code{exporter}, it is used for the present value[s]. The number suffix is the number of significant digits to use. The formats are: \tabular{llll}{
    							\tab Format    	\tab Example	\tab \cr
    sprintf expression			\tab \%<expr.>  \tab \%.5e		\tab 10000*pi -> 3.14159*10^4\cr
	flexible					\tab <n>		\tab 8			\tab 10000*pi -> 31415.927\cr
    integer						\tab i			\tab i			\tab 10000*pi -> 31415\cr
    float						\tab f<n>		\tab f4			\tab 10000*pi -> 3.142*10^4\cr
    float, factor 3 exponent   	\tab e<n>		\tab e4			\tab 10000*pi -> 31.42*10^3\cr
    float, with suffix			\tab s<n>		\tab s4			\tab 10000*pi -> 31.42 k\cr
    float, with 2^10 suffix		\tab b<n>		\tab b3			\tab 10000*pi -> 12.06 Ki\cr
	fraction					\tab d or d<n>	\tab d6			\tab pi -> 1146408/364913\cr
	fraction, with integer		\tab D or D<n>	\tab D6			\tab pi -> 3+51669/364913\cr
}
}
	\item{prefix}{If a naming prefix is to be used. When given to \code{exportR}, it sets the default \code{.prefix} to be used by \code{exporter}. When used in a call to \code{exporter}, it is used for the present and following value[s].}
	\item{append}{If \code{TRUE}, values will be appended to the \code{fname} file, instead of rewriting it.}
	\item{named}{If \code{TRUE}, the row names of a 2-d data structure (i.e. a \code{data.frame}) will be included as the first column. if \code{TRUE}, the item names of a 1-d data structure (i.e. a \code{list}) will be included.}
}
\details{
It's actually the function returned by \code{exportR} that does the job, so typically \code{exportR} is called only once. But more than one such function can be active at the same time.

When the returned function (called \code{exporter}, above) is created, a header is written to the file \code{fname}. During subsequent calls, actual values are appended to the file.

Presently, the following classes are recognized: \code{NULL}, \code{logical} (including \code{NA}), \code{character}, \code{factor}, \code{call} (it's evaluated through \code{eval}), \code{numeric} (including \code{INF} and \code{NaN}), \code{complex} (including \code{INF}), \code{matrix}, \code{array}, \code{list}, \code{pairlist}, \code{table}, \code{data.frame}, \code{lm}, \code{randomForest}, \code{randomForest.formula}, \code{ts}, \code{bigz} and \code{bigq} from package \code{gmp}, \code{int64} and \code{uint64} from package \code{int64}, and \code{integer64} from package \code{bit64}. Other classes are processed with \code{as.character( value )}. 

Table-like structures defines three commands for each structure:
\code{nameColumns,} that can be used as a column-format,
\code{nameHeader,} contains the column names, and
\code{nameBody} contains the actual table contents.
Example: \code{\\begin{tabular}{\\nameColumns}\\nameHeader\\hline \\nameBody\\end{tabular}}

Some structures, like \code{lm}, may define even more variants. Try, and see what is generated!

Support for more classes can be implemented by defining functions \code{as.exportR.<your-class>}. Call \code{as.exportR} on each item in your class to get the correct output. See \code{as.exportR.lm} in file \code{R/exportR.R} as an example on how to do this.

Output formats presently supported: only \code{LaTeX}. Support for more formats can be implemented by writing a function \code{exportR.<your-format>} in the same manner as \code{exportR.latex}, present in the file \code{R/latexR.R}.
}
\value{
\code{exportR} returns a function that is used to output formatted values.

This [returned] function returns no value, when called. 
}
\author{Peder Axensten}
\examples{
library(exporteR)
ltx <- exportR( tempfile( pattern = "test", fileext = ".tex" ) )

x <- 2*pi
ltx(x)                    # Writes \newcommand{\x}{6.283}
ltx(two_pi=2*pi)          # Writes \newcommand{\twoxpi}{6.283}

# Alternatively, in one go:
ltx(x, two_pi=2*pi)
}
\keyword{export}
\keyword{latex}
\keyword{utilities}
\keyword{conversion}
??????????????????????????????????


From murdoch.duncan at gmail.com  Mon Dec  2 17:26:19 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 02 Dec 2013 11:26:19 -0500
Subject: [Rd] pesky \usage-warnings with R CMD check
In-Reply-To: <D6B4F090-152F-4F06-8664-8112B6BA7DC7@slu.se>
References: <D6B4F090-152F-4F06-8664-8112B6BA7DC7@slu.se>
Message-ID: <529CB4AB.3020609@gmail.com>

On 02/12/2013 9:57 AM, Peder Axensten wrote:
> I?m in the process of preparing a package for CRAN.
>
> The package is called ?exportR? and since it really just consists of one function, I found it natural to call it ?exportR? too.
>
> The function returns a function that does the actual job, but it is set up to work in different ways, depending on the arguments given to its creator. In short:
> library( exportR )
> exporter <- exportR( the, arguments )
> exporter( its, own, arguments )
>
> When I run R CMD check I get two warnings:
> -----------------
> * checking for code/documentation mismatches ... WARNING
> Functions or methods with usage in documentation object 'exportR' but not in code:
>    exporter
>
> * checking Rd \usage sections ... WARNING
> Assignments in \usage in documentation object 'exportR':
>    exporter <- exportR(fname, type = "latex", format = "4", prefix = "",
>        append = FALSE)
>
> Functions with \usage entries need to have the appropriate \alias
> entries, and all their arguments documented.
> The \usage entries must correspond to syntactically valid R code.
> See the chapter ?Writing R documentation files? in the ?Writing R
> Extensions? manual.
> ????????
>
> The first warning I understand, but I don?t know how to proceed to rid myself of it. Indeed it is nowhere in my code, as exportR creates it, but I still need to document it. I would very much appreciate advice.

You should put exportR in your usage section, not exporter.  To document 
exporter, you have at least a couple of choices:

1.  The most straightforward way is simply to document it in the Details 
section of the help page.  You can write what
you like there; syntax of the help text will be checked, but not content.

2.  You could actually run exportR in your package .R file, and create 
and export an exporter function.  This will only make
sense if there's a simple default one that would make sense for all 
users.  But if you do that, then you can include exporter(its, own, 
arguments) in the usage section, and in the value section, say that the 
result of exportR will be a function that looks like exporter.

You should not include an assignment in your usage section.  I think it 
is being seen as a call to the "<-" function, so you get the warning 
about documenting something that is not an alias.  (I might be wrong 
about the last part of the warning, I haven't looked closely.)

Duncan Murdoch

>
> The second warning I don?t understand. I do have both \name{exportR} and \alias{exportR} (as well as \alias{exporter}) at the top of the .Rd file. The function name, arguments, and default values are copied directly from the source, so they are identical. I changed the package name to exporteR to see if the problem was that the package name and the function name were the same, but that did not remove the warning. I used package.skeleton to create a .Rd template for the function and it was syntactically identical. Installing the package and running it works, obviously. I?m running out of ideas and any help is appreciated. I have this nagging feeling that I?m missing something obvious??
>
> I post the entire contents of the .Rd file at the bottom.
>
> Best regards,
>
> Peder Axensten
> Research engineer
>
> Swedish University of Agricultural Sciences
> Department of Forest Resource Management
> Remote Sensing
> SE-901 83 Ume?
> Visiting address: Skogsmarksgr?nd
> Phone: +46 90 786 85 00
> peder.axensten at slu.se, www.slu.se/srh
>
> The Department of Forest Resource Management is environmentally certified in accordance with ISO 14001.
>
> ??????????????????????????????????
> \name{exportR}
> \alias{exportR}
> \alias{export}
> \alias{exporter}
> \alias{latex}
> \alias{conversion}
> \alias{exportR.latex}
> \title{Easy export of R results}
> \description{A flexible and simple way to export R results to LaTeX and [maybe later] other formats.}
> \usage{
> exporter <- exportR( fname, type="latex", format="4", prefix="", append=FALSE )
> exporter( ..., format=NA, prefix=NA, named=FALSE )
> }
> \arguments{
> 	\item{...}{The value[s] to be exported. To name them, use the normal R convention: \code{exporter(first=123, second=456)}. If no such name is given, the variable name is used:  \code{exporter(myvar, second=456)}. For other expressions the naming is undetermined, be sure to name them: \code{exporter(myname=2*pi/sqrt(2))}. Non-valid characters will be substituted by \code{x}, i.e. \code{my_var1} will result in \code{\\myxvarx} in LaTeX.}
> 	\item{fname}{The path to the destination file.}
> 	\item{type}{The name of export file type, e.g. \code{exporter}. May be a string vector to export to more than one format at once. But presently, only \code{exporter} is implemented.}
> 	\item{format}{The numerical format to use. When given to \code{exportR}, it sets the default \code{.format} to be used by \code{exporter}. When used in a call to \code{exporter}, it is used for the present value[s]. The number suffix is the number of significant digits to use. The formats are: \tabular{llll}{
>      							\tab Format    	\tab Example	\tab \cr
>      sprintf expression			\tab \%<expr.>  \tab \%.5e		\tab 10000*pi -> 3.14159*10^4\cr
> 	flexible					\tab <n>		\tab 8			\tab 10000*pi -> 31415.927\cr
>      integer						\tab i			\tab i			\tab 10000*pi -> 31415\cr
>      float						\tab f<n>		\tab f4			\tab 10000*pi -> 3.142*10^4\cr
>      float, factor 3 exponent   	\tab e<n>		\tab e4			\tab 10000*pi -> 31.42*10^3\cr
>      float, with suffix			\tab s<n>		\tab s4			\tab 10000*pi -> 31.42 k\cr
>      float, with 2^10 suffix		\tab b<n>		\tab b3			\tab 10000*pi -> 12.06 Ki\cr
> 	fraction					\tab d or d<n>	\tab d6			\tab pi -> 1146408/364913\cr
> 	fraction, with integer		\tab D or D<n>	\tab D6			\tab pi -> 3+51669/364913\cr
> }
> }
> 	\item{prefix}{If a naming prefix is to be used. When given to \code{exportR}, it sets the default \code{.prefix} to be used by \code{exporter}. When used in a call to \code{exporter}, it is used for the present and following value[s].}
> 	\item{append}{If \code{TRUE}, values will be appended to the \code{fname} file, instead of rewriting it.}
> 	\item{named}{If \code{TRUE}, the row names of a 2-d data structure (i.e. a \code{data.frame}) will be included as the first column. if \code{TRUE}, the item names of a 1-d data structure (i.e. a \code{list}) will be included.}
> }
> \details{
> It's actually the function returned by \code{exportR} that does the job, so typically \code{exportR} is called only once. But more than one such function can be active at the same time.
>
> When the returned function (called \code{exporter}, above) is created, a header is written to the file \code{fname}. During subsequent calls, actual values are appended to the file.
>
> Presently, the following classes are recognized: \code{NULL}, \code{logical} (including \code{NA}), \code{character}, \code{factor}, \code{call} (it's evaluated through \code{eval}), \code{numeric} (including \code{INF} and \code{NaN}), \code{complex} (including \code{INF}), \code{matrix}, \code{array}, \code{list}, \code{pairlist}, \code{table}, \code{data.frame}, \code{lm}, \code{randomForest}, \code{randomForest.formula}, \code{ts}, \code{bigz} and \code{bigq} from package \code{gmp}, \code{int64} and \code{uint64} from package \code{int64}, and \code{integer64} from package \code{bit64}. Other classes are processed with \code{as.character( value )}.
>
> Table-like structures defines three commands for each structure:
> \code{nameColumns,} that can be used as a column-format,
> \code{nameHeader,} contains the column names, and
> \code{nameBody} contains the actual table contents.
> Example: \code{\\begin{tabular}{\\nameColumns}\\nameHeader\\hline \\nameBody\\end{tabular}}
>
> Some structures, like \code{lm}, may define even more variants. Try, and see what is generated!
>
> Support for more classes can be implemented by defining functions \code{as.exportR.<your-class>}. Call \code{as.exportR} on each item in your class to get the correct output. See \code{as.exportR.lm} in file \code{R/exportR.R} as an example on how to do this.
>
> Output formats presently supported: only \code{LaTeX}. Support for more formats can be implemented by writing a function \code{exportR.<your-format>} in the same manner as \code{exportR.latex}, present in the file \code{R/latexR.R}.
> }
> \value{
> \code{exportR} returns a function that is used to output formatted values.
>
> This [returned] function returns no value, when called.
> }
> \author{Peder Axensten}
> \examples{
> library(exporteR)
> ltx <- exportR( tempfile( pattern = "test", fileext = ".tex" ) )
>
> x <- 2*pi
> ltx(x)                    # Writes \newcommand{\x}{6.283}
> ltx(two_pi=2*pi)          # Writes \newcommand{\twoxpi}{6.283}
>
> # Alternatively, in one go:
> ltx(x, two_pi=2*pi)
> }
> \keyword{export}
> \keyword{latex}
> \keyword{utilities}
> \keyword{conversion}
> ??????????????????????????????????
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From swapnil.gaikwad at ichec.ie  Mon Dec  2 19:39:13 2013
From: swapnil.gaikwad at ichec.ie (Swapnil Gaikwad)
Date: Mon, 02 Dec 2013 18:39:13 +0000
Subject: [Rd] Arithmetic Error while compiling R with the Intel compilers
Message-ID: <529CD3D1.9020105@ichec.ie>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20131202/edc6a15a/attachment.pl>

From murdoch.duncan at gmail.com  Mon Dec  2 20:12:11 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 02 Dec 2013 14:12:11 -0500
Subject: [Rd] Arithmetic Error while compiling R with the Intel compilers
In-Reply-To: <529CD3D1.9020105@ichec.ie>
References: <529CD3D1.9020105@ichec.ie>
Message-ID: <529CDB8B.3050106@gmail.com>

On 02/12/2013 1:39 PM, Swapnil Gaikwad wrote:
> Hi Team,
>                 I downloaded the R 3.0.2 and,  built and installed it
> using Intel compilers (icc and ifort) from Intel parallel studio 2013,
> sp1. After performing make tried to check it using 'make check'. Most of
> the tests passed successfully but while checking a 'stats' package I saw
> many lines were printed which did not match the desired output.
>
> e.g.
>         There were two types of mismatch
> Case 1)
> 6300c6300
> < Grand Mean: 291.5937
> ---
>   > Grand Mean: 291.5938
>
> Case 2)
> 12699c12699
> < UrbanPop *0.278* -0.873 -0.378  0.134
> ---
>   > UrbanPop *-0.278* -0.873 -0.378  0.134
>
>
>                 Case 1 was having slight difference in the values and
> assumed due to the floating point error, but Case 2 is having values
> with difference signs. Is such behaviour is normal or there is any issue
> with the Intel libraries.

You need to look at the context of what is being tested.  In this 
particular case, you are testing principal component loadings:  they can 
all be multiplied by -1 and give exactly the same results, so this one 
is okay.  (The choice of sign is probably being made in the linear 
algebra routines.)


> I used some of the libraries from Intel MKL
> like fftw, mkl_lapack etc. I am pasting below the command that I used to
> configure this R package.
>
>
> ./configure --prefix=$INSTALL_DIR --with-blas="-lmkl_intel_lp64
> -lmkl_intel_thread -lmkl_lapack -lmkl_core -lpthread -lfftw3xf_intel
> -lfftw3xc_intel" --with-lapack
>
>               I also tried installing using Intel compilers without using
> Intel MKL libraries. It was done using below command.
>
> ./configure --prefix=$INSTALL_DIR
>
>         Exactly same errors were there.
>         There were no mismatch observed while compiling with gcc.Kindly
> provide your suggestions whether it is good idea to use Intel compilers.
> Thanks for your kind attention and time.


Can't help you with your final question, I have no experience with them.

Duncan Murdoch


From Peder.Axensten at slu.se  Mon Dec  2 23:25:24 2013
From: Peder.Axensten at slu.se (Peder Axensten)
Date: Mon, 2 Dec 2013 22:25:24 +0000
Subject: [Rd] pesky \usage-warnings with R CMD check
In-Reply-To: <529CB4AB.3020609@gmail.com>
References: <D6B4F090-152F-4F06-8664-8112B6BA7DC7@slu.se>
	<529CB4AB.3020609@gmail.com>
Message-ID: <B6D95982-6B1A-4B02-967E-88BABB59F0E0@slu.se>

Duncan,

As soon as I read your letter I realized the logic. I followed your advice and the warnings are gone. I don?t know how long it would have taken me to see it myself, but probably quite some time ? thank you!

I do think it?s a pity, in this special case, that I can?t put the returning function inside \usage. It would have made the documentation more clear and concise.

Best regards,

Peder Axensten
Research engineer

Swedish University of Agricultural Sciences
Department of Forest Resource Management
Remote Sensing
SE-901 83 Ume?
Visiting address: Skogsmarksgr?nd
Phone: +46 90 786 85 00
peder.axensten at slu.se, www.slu.se/srh

The Department of Forest Resource Management is environmentally certified in accordance with ISO 14001.

On 2 dec 2013, at 17:26, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:

> On 02/12/2013 9:57 AM, Peder Axensten wrote:
>> I?m in the process of preparing a package for CRAN.
>> 
>> The package is called ?exportR? and since it really just consists of one function, I found it natural to call it ?exportR? too.
>> 
>> The function returns a function that does the actual job, but it is set up to work in different ways, depending on the arguments given to its creator. In short:
>> library( exportR )
>> exporter <- exportR( the, arguments )
>> exporter( its, own, arguments )
>> 
>> When I run R CMD check I get two warnings:
>> -----------------
>> * checking for code/documentation mismatches ... WARNING
>> Functions or methods with usage in documentation object 'exportR' but not in code:
>>   exporter
>> 
>> * checking Rd \usage sections ... WARNING
>> Assignments in \usage in documentation object 'exportR':
>>   exporter <- exportR(fname, type = "latex", format = "4", prefix = "",
>>       append = FALSE)
>> 
>> Functions with \usage entries need to have the appropriate \alias
>> entries, and all their arguments documented.
>> The \usage entries must correspond to syntactically valid R code.
>> See the chapter ?Writing R documentation files? in the ?Writing R
>> Extensions? manual.
>> ????????
>> 
>> The first warning I understand, but I don?t know how to proceed to rid myself of it. Indeed it is nowhere in my code, as exportR creates it, but I still need to document it. I would very much appreciate advice.
> 
> You should put exportR in your usage section, not exporter.  To document exporter, you have at least a couple of choices:
> 
> 1.  The most straightforward way is simply to document it in the Details section of the help page.  You can write what
> you like there; syntax of the help text will be checked, but not content.
> 
> 2.  You could actually run exportR in your package .R file, and create and export an exporter function.  This will only make
> sense if there's a simple default one that would make sense for all users.  But if you do that, then you can include exporter(its, own, arguments) in the usage section, and in the value section, say that the result of exportR will be a function that looks like exporter.
> 
> You should not include an assignment in your usage section.  I think it is being seen as a call to the "<-" function, so you get the warning about documenting something that is not an alias.  (I might be wrong about the last part of the warning, I haven't looked closely.)
> 
> Duncan Murdoch
> 
>> 
>> The second warning I don?t understand. I do have both \name{exportR} and \alias{exportR} (as well as \alias{exporter}) at the top of the .Rd file. The function name, arguments, and default values are copied directly from the source, so they are identical. I changed the package name to exporteR to see if the problem was that the package name and the function name were the same, but that did not remove the warning. I used package.skeleton to create a .Rd template for the function and it was syntactically identical. Installing the package and running it works, obviously. I?m running out of ideas and any help is appreciated. I have this nagging feeling that I?m missing something obvious??
>> 
>> I post the entire contents of the .Rd file at the bottom.
>> 
>> Best regards,
>> 
>> Peder Axensten
>> Research engineer
>> 
>> Swedish University of Agricultural Sciences
>> Department of Forest Resource Management
>> Remote Sensing
>> SE-901 83 Ume?
>> Visiting address: Skogsmarksgr?nd
>> Phone: +46 90 786 85 00
>> peder.axensten at slu.se, www.slu.se/srh
>> 
>> The Department of Forest Resource Management is environmentally certified in accordance with ISO 14001.
>> 
>> ??????????????????????????????????
>> \name{exportR}
>> \alias{exportR}
>> \alias{export}
>> \alias{exporter}
>> \alias{latex}
>> \alias{conversion}
>> \alias{exportR.latex}
>> \title{Easy export of R results}
>> \description{A flexible and simple way to export R results to LaTeX and [maybe later] other formats.}
>> \usage{
>> exporter <- exportR( fname, type="latex", format="4", prefix="", append=FALSE )
>> exporter( ..., format=NA, prefix=NA, named=FALSE )
>> }
>> \arguments{
>> 	\item{...}{The value[s] to be exported. To name them, use the normal R convention: \code{exporter(first=123, second=456)}. If no such name is given, the variable name is used:  \code{exporter(myvar, second=456)}. For other expressions the naming is undetermined, be sure to name them: \code{exporter(myname=2*pi/sqrt(2))}. Non-valid characters will be substituted by \code{x}, i.e. \code{my_var1} will result in \code{\\myxvarx} in LaTeX.}
>> 	\item{fname}{The path to the destination file.}
>> 	\item{type}{The name of export file type, e.g. \code{exporter}. May be a string vector to export to more than one format at once. But presently, only \code{exporter} is implemented.}
>> 	\item{format}{The numerical format to use. When given to \code{exportR}, it sets the default \code{.format} to be used by \code{exporter}. When used in a call to \code{exporter}, it is used for the present value[s]. The number suffix is the number of significant digits to use. The formats are: \tabular{llll}{
>>     							\tab Format    	\tab Example	\tab \cr
>>     sprintf expression			\tab \%<expr.>  \tab \%.5e		\tab 10000*pi -> 3.14159*10^4\cr
>> 	flexible					\tab <n>		\tab 8			\tab 10000*pi -> 31415.927\cr
>>     integer						\tab i			\tab i			\tab 10000*pi -> 31415\cr
>>     float						\tab f<n>		\tab f4			\tab 10000*pi -> 3.142*10^4\cr
>>     float, factor 3 exponent   	\tab e<n>		\tab e4			\tab 10000*pi -> 31.42*10^3\cr
>>     float, with suffix			\tab s<n>		\tab s4			\tab 10000*pi -> 31.42 k\cr
>>     float, with 2^10 suffix		\tab b<n>		\tab b3			\tab 10000*pi -> 12.06 Ki\cr
>> 	fraction					\tab d or d<n>	\tab d6			\tab pi -> 1146408/364913\cr
>> 	fraction, with integer		\tab D or D<n>	\tab D6			\tab pi -> 3+51669/364913\cr
>> }
>> }
>> 	\item{prefix}{If a naming prefix is to be used. When given to \code{exportR}, it sets the default \code{.prefix} to be used by \code{exporter}. When used in a call to \code{exporter}, it is used for the present and following value[s].}
>> 	\item{append}{If \code{TRUE}, values will be appended to the \code{fname} file, instead of rewriting it.}
>> 	\item{named}{If \code{TRUE}, the row names of a 2-d data structure (i.e. a \code{data.frame}) will be included as the first column. if \code{TRUE}, the item names of a 1-d data structure (i.e. a \code{list}) will be included.}
>> }
>> \details{
>> It's actually the function returned by \code{exportR} that does the job, so typically \code{exportR} is called only once. But more than one such function can be active at the same time.
>> 
>> When the returned function (called \code{exporter}, above) is created, a header is written to the file \code{fname}. During subsequent calls, actual values are appended to the file.
>> 
>> Presently, the following classes are recognized: \code{NULL}, \code{logical} (including \code{NA}), \code{character}, \code{factor}, \code{call} (it's evaluated through \code{eval}), \code{numeric} (including \code{INF} and \code{NaN}), \code{complex} (including \code{INF}), \code{matrix}, \code{array}, \code{list}, \code{pairlist}, \code{table}, \code{data.frame}, \code{lm}, \code{randomForest}, \code{randomForest.formula}, \code{ts}, \code{bigz} and \code{bigq} from package \code{gmp}, \code{int64} and \code{uint64} from package \code{int64}, and \code{integer64} from package \code{bit64}. Other classes are processed with \code{as.character( value )}.
>> 
>> Table-like structures defines three commands for each structure:
>> \code{nameColumns,} that can be used as a column-format,
>> \code{nameHeader,} contains the column names, and
>> \code{nameBody} contains the actual table contents.
>> Example: \code{\\begin{tabular}{\\nameColumns}\\nameHeader\\hline \\nameBody\\end{tabular}}
>> 
>> Some structures, like \code{lm}, may define even more variants. Try, and see what is generated!
>> 
>> Support for more classes can be implemented by defining functions \code{as.exportR.<your-class>}. Call \code{as.exportR} on each item in your class to get the correct output. See \code{as.exportR.lm} in file \code{R/exportR.R} as an example on how to do this.
>> 
>> Output formats presently supported: only \code{LaTeX}. Support for more formats can be implemented by writing a function \code{exportR.<your-format>} in the same manner as \code{exportR.latex}, present in the file \code{R/latexR.R}.
>> }
>> \value{
>> \code{exportR} returns a function that is used to output formatted values.
>> 
>> This [returned] function returns no value, when called.
>> }
>> \author{Peder Axensten}
>> \examples{
>> library(exporteR)
>> ltx <- exportR( tempfile( pattern = "test", fileext = ".tex" ) )
>> 
>> x <- 2*pi
>> ltx(x)                    # Writes \newcommand{\x}{6.283}
>> ltx(two_pi=2*pi)          # Writes \newcommand{\twoxpi}{6.283}
>> 
>> # Alternatively, in one go:
>> ltx(x, two_pi=2*pi)
>> }
>> \keyword{export}
>> \keyword{latex}
>> \keyword{utilities}
>> \keyword{conversion}
>> ??????????????????????????????????
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel


From murdoch.duncan at gmail.com  Tue Dec  3 01:04:34 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 02 Dec 2013 19:04:34 -0500
Subject: [Rd] pesky \usage-warnings with R CMD check
In-Reply-To: <B6D95982-6B1A-4B02-967E-88BABB59F0E0@slu.se>
References: <D6B4F090-152F-4F06-8664-8112B6BA7DC7@slu.se>
	<529CB4AB.3020609@gmail.com>
	<B6D95982-6B1A-4B02-967E-88BABB59F0E0@slu.se>
Message-ID: <529D2012.9000104@gmail.com>

On 13-12-02 5:25 PM, Peder Axensten wrote:
> Duncan,
>
> As soon as I read your letter I realized the logic. I followed your advice and the warnings are gone. I don?t know how long it would have taken me to see it myself, but probably quite some time ? thank you!
>
> I do think it?s a pity, in this special case, that I can?t put the returning function inside \usage. It would have made the documentation more clear and concise.

I partially disagree.  It's not up to you to name function results: 
users should do that.  So documenting "exporter" doesn't make sense, 
beyond the documentation you give in the Details or Value section of 
your help page, unless there really is an object named "exporter" in 
your package.

On the other hand, I do agree it is a pity that you can't somehow 
document return values that are functions using code that is similar to 
the \usage code, and have automatic Rd checking give some quality 
assurance.  (It wouldn't be easy to write those QA checks, but they'd be 
useful.)

Duncan Murdoch

>
> Best regards,
>
> Peder Axensten
> Research engineer
>
> Swedish University of Agricultural Sciences
> Department of Forest Resource Management
> Remote Sensing
> SE-901 83 Ume?
> Visiting address: Skogsmarksgr?nd
> Phone: +46 90 786 85 00
> peder.axensten at slu.se, www.slu.se/srh
>
> The Department of Forest Resource Management is environmentally certified in accordance with ISO 14001.
>
> On 2 dec 2013, at 17:26, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>
>> On 02/12/2013 9:57 AM, Peder Axensten wrote:
>>> I?m in the process of preparing a package for CRAN.
>>>
>>> The package is called ?exportR? and since it really just consists of one function, I found it natural to call it ?exportR? too.
>>>
>>> The function returns a function that does the actual job, but it is set up to work in different ways, depending on the arguments given to its creator. In short:
>>> library( exportR )
>>> exporter <- exportR( the, arguments )
>>> exporter( its, own, arguments )
>>>
>>> When I run R CMD check I get two warnings:
>>> -----------------
>>> * checking for code/documentation mismatches ... WARNING
>>> Functions or methods with usage in documentation object 'exportR' but not in code:
>>>    exporter
>>>
>>> * checking Rd \usage sections ... WARNING
>>> Assignments in \usage in documentation object 'exportR':
>>>    exporter <- exportR(fname, type = "latex", format = "4", prefix = "",
>>>        append = FALSE)
>>>
>>> Functions with \usage entries need to have the appropriate \alias
>>> entries, and all their arguments documented.
>>> The \usage entries must correspond to syntactically valid R code.
>>> See the chapter ?Writing R documentation files? in the ?Writing R
>>> Extensions? manual.
>>> ????????
>>>
>>> The first warning I understand, but I don?t know how to proceed to rid myself of it. Indeed it is nowhere in my code, as exportR creates it, but I still need to document it. I would very much appreciate advice.
>>
>> You should put exportR in your usage section, not exporter.  To document exporter, you have at least a couple of choices:
>>
>> 1.  The most straightforward way is simply to document it in the Details section of the help page.  You can write what
>> you like there; syntax of the help text will be checked, but not content.
>>
>> 2.  You could actually run exportR in your package .R file, and create and export an exporter function.  This will only make
>> sense if there's a simple default one that would make sense for all users.  But if you do that, then you can include exporter(its, own, arguments) in the usage section, and in the value section, say that the result of exportR will be a function that looks like exporter.
>>
>> You should not include an assignment in your usage section.  I think it is being seen as a call to the "<-" function, so you get the warning about documenting something that is not an alias.  (I might be wrong about the last part of the warning, I haven't looked closely.)
>>
>> Duncan Murdoch
>>
>>>
>>> The second warning I don?t understand. I do have both \name{exportR} and \alias{exportR} (as well as \alias{exporter}) at the top of the .Rd file. The function name, arguments, and default values are copied directly from the source, so they are identical. I changed the package name to exporteR to see if the problem was that the package name and the function name were the same, but that did not remove the warning. I used package.skeleton to create a .Rd template for the function and it was syntactically identical. Installing the package and running it works, obviously. I?m running out of ideas and any help is appreciated. I have this nagging feeling that I?m missing something obvious??
>>>
>>> I post the entire contents of the .Rd file at the bottom.
>>>
>>> Best regards,
>>>
>>> Peder Axensten
>>> Research engineer
>>>
>>> Swedish University of Agricultural Sciences
>>> Department of Forest Resource Management
>>> Remote Sensing
>>> SE-901 83 Ume?
>>> Visiting address: Skogsmarksgr?nd
>>> Phone: +46 90 786 85 00
>>> peder.axensten at slu.se, www.slu.se/srh
>>>
>>> The Department of Forest Resource Management is environmentally certified in accordance with ISO 14001.
>>>
>>> ??????????????????????????????????
>>> \name{exportR}
>>> \alias{exportR}
>>> \alias{export}
>>> \alias{exporter}
>>> \alias{latex}
>>> \alias{conversion}
>>> \alias{exportR.latex}
>>> \title{Easy export of R results}
>>> \description{A flexible and simple way to export R results to LaTeX and [maybe later] other formats.}
>>> \usage{
>>> exporter <- exportR( fname, type="latex", format="4", prefix="", append=FALSE )
>>> exporter( ..., format=NA, prefix=NA, named=FALSE )
>>> }
>>> \arguments{
>>> 	\item{...}{The value[s] to be exported. To name them, use the normal R convention: \code{exporter(first=123, second=456)}. If no such name is given, the variable name is used:  \code{exporter(myvar, second=456)}. For other expressions the naming is undetermined, be sure to name them: \code{exporter(myname=2*pi/sqrt(2))}. Non-valid characters will be substituted by \code{x}, i.e. \code{my_var1} will result in \code{\\myxvarx} in LaTeX.}
>>> 	\item{fname}{The path to the destination file.}
>>> 	\item{type}{The name of export file type, e.g. \code{exporter}. May be a string vector to export to more than one format at once. But presently, only \code{exporter} is implemented.}
>>> 	\item{format}{The numerical format to use. When given to \code{exportR}, it sets the default \code{.format} to be used by \code{exporter}. When used in a call to \code{exporter}, it is used for the present value[s]. The number suffix is the number of significant digits to use. The formats are: \tabular{llll}{
>>>      							\tab Format    	\tab Example	\tab \cr
>>>      sprintf expression			\tab \%<expr.>  \tab \%.5e		\tab 10000*pi -> 3.14159*10^4\cr
>>> 	flexible					\tab <n>		\tab 8			\tab 10000*pi -> 31415.927\cr
>>>      integer						\tab i			\tab i			\tab 10000*pi -> 31415\cr
>>>      float						\tab f<n>		\tab f4			\tab 10000*pi -> 3.142*10^4\cr
>>>      float, factor 3 exponent   	\tab e<n>		\tab e4			\tab 10000*pi -> 31.42*10^3\cr
>>>      float, with suffix			\tab s<n>		\tab s4			\tab 10000*pi -> 31.42 k\cr
>>>      float, with 2^10 suffix		\tab b<n>		\tab b3			\tab 10000*pi -> 12.06 Ki\cr
>>> 	fraction					\tab d or d<n>	\tab d6			\tab pi -> 1146408/364913\cr
>>> 	fraction, with integer		\tab D or D<n>	\tab D6			\tab pi -> 3+51669/364913\cr
>>> }
>>> }
>>> 	\item{prefix}{If a naming prefix is to be used. When given to \code{exportR}, it sets the default \code{.prefix} to be used by \code{exporter}. When used in a call to \code{exporter}, it is used for the present and following value[s].}
>>> 	\item{append}{If \code{TRUE}, values will be appended to the \code{fname} file, instead of rewriting it.}
>>> 	\item{named}{If \code{TRUE}, the row names of a 2-d data structure (i.e. a \code{data.frame}) will be included as the first column. if \code{TRUE}, the item names of a 1-d data structure (i.e. a \code{list}) will be included.}
>>> }
>>> \details{
>>> It's actually the function returned by \code{exportR} that does the job, so typically \code{exportR} is called only once. But more than one such function can be active at the same time.
>>>
>>> When the returned function (called \code{exporter}, above) is created, a header is written to the file \code{fname}. During subsequent calls, actual values are appended to the file.
>>>
>>> Presently, the following classes are recognized: \code{NULL}, \code{logical} (including \code{NA}), \code{character}, \code{factor}, \code{call} (it's evaluated through \code{eval}), \code{numeric} (including \code{INF} and \code{NaN}), \code{complex} (including \code{INF}), \code{matrix}, \code{array}, \code{list}, \code{pairlist}, \code{table}, \code{data.frame}, \code{lm}, \code{randomForest}, \code{randomForest.formula}, \code{ts}, \code{bigz} and \code{bigq} from package \code{gmp}, \code{int64} and \code{uint64} from package \code{int64}, and \code{integer64} from package \code{bit64}. Other classes are processed with \code{as.character( value )}.
>>>
>>> Table-like structures defines three commands for each structure:
>>> \code{nameColumns,} that can be used as a column-format,
>>> \code{nameHeader,} contains the column names, and
>>> \code{nameBody} contains the actual table contents.
>>> Example: \code{\\begin{tabular}{\\nameColumns}\\nameHeader\\hline \\nameBody\\end{tabular}}
>>>
>>> Some structures, like \code{lm}, may define even more variants. Try, and see what is generated!
>>>
>>> Support for more classes can be implemented by defining functions \code{as.exportR.<your-class>}. Call \code{as.exportR} on each item in your class to get the correct output. See \code{as.exportR.lm} in file \code{R/exportR.R} as an example on how to do this.
>>>
>>> Output formats presently supported: only \code{LaTeX}. Support for more formats can be implemented by writing a function \code{exportR.<your-format>} in the same manner as \code{exportR.latex}, present in the file \code{R/latexR.R}.
>>> }
>>> \value{
>>> \code{exportR} returns a function that is used to output formatted values.
>>>
>>> This [returned] function returns no value, when called.
>>> }
>>> \author{Peder Axensten}
>>> \examples{
>>> library(exporteR)
>>> ltx <- exportR( tempfile( pattern = "test", fileext = ".tex" ) )
>>>
>>> x <- 2*pi
>>> ltx(x)                    # Writes \newcommand{\x}{6.283}
>>> ltx(two_pi=2*pi)          # Writes \newcommand{\twoxpi}{6.283}
>>>
>>> # Alternatively, in one go:
>>> ltx(x, two_pi=2*pi)
>>> }
>>> \keyword{export}
>>> \keyword{latex}
>>> \keyword{utilities}
>>> \keyword{conversion}
>>> ??????????????????????????????????
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From renaud at mancala.cbio.uct.ac.za  Thu Dec  5 11:40:04 2013
From: renaud at mancala.cbio.uct.ac.za (Renaud Gaujoux)
Date: Thu, 5 Dec 2013 12:40:04 +0200
Subject: [Rd] S4 method for '[' with extra arguments: distinguishing between
 x[i] and x[i, ]
Message-ID: <CAHavPHH5jo_7q+=MT9tdM0v10MimCoNqq0rubZEJJKU4gRCj1Q@mail.gmail.com>

Hi,

I want to implement a '[' for an S4 class, that behaves differently
when called with a single index argument or multiple indexes (possibly
missing), like what happens when subsetting matrices x[i] vs. x[i, ].

I manage to do it using nargs() and checking if drop is missing (see
code below), but when I want to add an extra argument to the method
(before drop), then the parent call somehow changes and always
includes all indexes in the call (even missing ones) and nargs()
always returns the same value.

I thought there might be a generic for a single index (with no j in
the definition) but could not find its definition, and can't see how
setMethod will know for which '[' to define the method. Defining a
method for signature(x = 'A', j = 'missing') has the same issue.

Is there actually a way to do this?
Thank you.

Bests,
Renaud


####
# Code
####

# Class A
setClass('A', contains = 'character')

# No extra argument is fine
setMethod('[', 'A', function(x, i, j, ..., drop = TRUE){
            ca <- match.call()
            mdrop <- missing(drop)
            Nargs <- nargs() - !mdrop
            print(ca)
            print(nargs())
            print(mdrop)
            print(Nargs)
            if( !missing(i) && Nargs < 3 ) TRUE
            else FALSE
        })

testA <- function(){
    a <- new('A')
    tests <- c('a[1]', 'a[1,]', 'a[,1]')
    sapply(tests, function(s){
        message('\n#', s); message('single arg: ', eval(parse(text = s)))
        s <- sub(']', ', drop = FALSE]', s, fixed = TRUE)
        message('\n#', s); message('single arg: ', eval(parse(text = s)))
    })
    invisible()
}

testA()

# with extra argument => cannot distinguish the calls
setMethod('[', 'A', function(x, i, j, ..., extra = FALSE, drop = TRUE){
            ca <- match.call()
            mdrop <- missing(drop)
            Nargs <- nargs() - !mdrop
            print(ca)
            print(nargs())
            print(mdrop)
            print(Nargs)
            if( !missing(i) && Nargs < 3 ) TRUE
            else FALSE
        })

testA()

# System info
sessionInfo()
R.version


####
# RESULTS
####

> # Class A
> setClass('A', contains = 'character')
>
> # No extra argument is fine
> setMethod('[', 'A', function(x, i, j, ..., drop = TRUE){
+             ca <- match.call()
+             mdrop <- missing(drop)
+             Nargs <- nargs() - !mdrop
+             print(ca)
+             print(nargs())
+             print(mdrop)
+             print(Nargs)
+             if( !missing(i) && Nargs < 3 ) TRUE
+             else FALSE
+         })
[1] "["
>
> testA <- function(){
+     a <- new('A')
+     tests <- c('a[1]', 'a[1,]', 'a[,1]')
+     sapply(tests, function(s){
+         message('\n#', s); message('single arg: ', eval(parse(text = s)))
+         s <- sub(']', ', drop = FALSE]', s, fixed = TRUE)
+         message('\n#', s); message('single arg: ', eval(parse(text = s)))
+     })
+     invisible()
+ }
>
> testA()

#a[1]
a[i = 1]
[1] 2
[1] TRUE
[1] 2
single arg: TRUE

#a[1, drop = FALSE]
a[i = 1, drop = FALSE]
[1] 3
[1] FALSE
[1] 2
single arg: TRUE

#a[1,]
a[i = 1]
[1] 3
[1] TRUE
[1] 3
single arg: FALSE

#a[1,, drop = FALSE]
a[i = 1, drop = FALSE]
[1] 4
[1] FALSE
[1] 3
single arg: FALSE

#a[,1]
a[j = 1]
[1] 3
[1] TRUE
[1] 3
single arg: FALSE

#a[,1, drop = FALSE]
a[j = 1, drop = FALSE]
[1] 4
[1] FALSE
[1] 3
single arg: FALSE
>
> # with extra argument => cannot distinguish the calls
> setMethod('[', 'A', function(x, i, j, ..., extra = FALSE, drop = TRUE){
+             ca <- match.call()
+             mdrop <- missing(drop)
+             Nargs <- nargs() - !mdrop
+             print(ca)
+             print(nargs())
+             print(mdrop)
+             print(Nargs)
+             if( !missing(i) && Nargs < 3 ) TRUE
+             else FALSE
+         })
[1] "["
>
> testA()

#a[1]
.local(x = x, i = i, j = j, drop = drop)
[1] 4
[1] FALSE
[1] 3
single arg: FALSE

#a[1, drop = FALSE]
.local(x = x, i = i, j = j, drop = drop)
[1] 4
[1] FALSE
[1] 3
single arg: FALSE

#a[1,]
.local(x = x, i = i, j = j, drop = drop)
[1] 4
[1] FALSE
[1] 3
single arg: FALSE

#a[1,, drop = FALSE]
.local(x = x, i = i, j = j, drop = drop)
[1] 4
[1] FALSE
[1] 3
single arg: FALSE

#a[,1]
.local(x = x, i = i, j = j, drop = drop)
[1] 4
[1] FALSE
[1] 3
single arg: FALSE

#a[,1, drop = FALSE]
.local(x = x, i = i, j = j, drop = drop)
[1] 4
[1] FALSE
[1] 3
single arg: FALSE
>
> # System info
> sessionInfo()
R version 3.0.2 (2013-09-25)
Platform: x86_64-pc-linux-gnu (64-bit)

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
 [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base
> R.version
               _
platform       x86_64-pc-linux-gnu
arch           x86_64
os             linux-gnu
system         x86_64, linux-gnu
status
major          3
minor          0.2
year           2013
month          09
day            25
svn rev        63987
language       R
version.string R version 3.0.2 (2013-09-25)
nickname       Frisbee Sailing
>


From pablo.barbera at nyu.edu  Thu Dec  5 22:50:15 2013
From: pablo.barbera at nyu.edu (=?ISO-8859-1?Q?Pablo_Barber=E1?=)
Date: Thu, 5 Dec 2013 16:50:15 -0500
Subject: [Rd] bug in default print method / floating point problem?
Message-ID: <CAGxaO+Bt9DY-akWgzdGoMwFLq+ULVJiwxHnU98=X7buYAa4uNA@mail.gmail.com>

In R 3.0.2, I found this weird behavior:

> 7/0.07
[1]100
> 6/0.06
[1] 100

There's one space missing between the bracket and the 100 in the first
case. I don't know if this is a known bug or not. It might have
something to do with precision of floating point numbers:

> options(digits=22)
> 7/0.07
[1] 99.99999999999998578915

Maybe R doesn't add the extra space when it rounds the number for
display? This is probably an irrelevant issue, but I thought I would
report it just in case.

Pablo Barbera


From dstr7320 at uni.sydney.edu.au  Fri Dec  6 04:00:10 2013
From: dstr7320 at uni.sydney.edu.au (Dario Strbenac)
Date: Fri, 6 Dec 2013 03:00:10 +0000
Subject: [Rd] Undocumented S4 method Warning For Bracket
Message-ID: <ae2b45e5a97f444aaa68bbc850f4b4bd@BLUPR01MB035.prod.exchangelabs.com>

Hello,

With R version 3.0.2 Patched (2013-10-30 r64123) I don't see warnings that I get in R Under development (unstable) (2013-11-03 r64145)

The warnings are like :

Undocumented S4 methods:
  generic '[' and siglist 'BayMethList,ANY,ANY'

The function actually looks like :

setMethod("[", "BayMethList",
    function(x, i) {
  # Code to subset object.
}

It has 2 parameters, not 3. The warning also happens in R 3.0.2 Release. Has this been fixed in Patched but not in the development version ?

--------------------------------------
Dario Strbenac
PhD Student
University of Sydney
Camperdown NSW 2050
Australia

From ripley at stats.ox.ac.uk  Fri Dec  6 08:45:30 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 06 Dec 2013 07:45:30 +0000
Subject: [Rd] bug in default print method / floating point problem?
In-Reply-To: <CAGxaO+Bt9DY-akWgzdGoMwFLq+ULVJiwxHnU98=X7buYAa4uNA@mail.gmail.com>
References: <CAGxaO+Bt9DY-akWgzdGoMwFLq+ULVJiwxHnU98=X7buYAa4uNA@mail.gmail.com>
Message-ID: <52A1809A.3070907@stats.ox.ac.uk>

On 05/12/2013 21:50, Pablo Barber? wrote:
> In R 3.0.2, I found this weird behavior:
>
>> 7/0.07
> [1]100
>> 6/0.06
> [1] 100
>
> There's one space missing between the bracket and the 100 in the first
> case. I don't know if this is a known bug or not. It might have
> something to do with precision of floating point numbers:
>
>> options(digits=22)
>> 7/0.07
> [1] 99.99999999999998578915
>
> Maybe R doesn't add the extra space when it rounds the number for
> display? This is probably an irrelevant issue, but I thought I would
> report it just in case.
>
> Pablo Barbera

Sees to be the same as the recent bug report PR#15583, which is under 
investigation.

R always used to round before computing the width, but someone 
'optimized' it recently: 3.0.1 did not do this.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From larissahauer at googlemail.com  Fri Dec  6 14:21:10 2013
From: larissahauer at googlemail.com (Larissa Hauer)
Date: Fri, 06 Dec 2013 14:21:10 +0100
Subject: [Rd] Matrix memory layout R vs. C
Message-ID: <52A1CF46.7070408@googlemail.com>


Hi everybody,

I'm trying to pass a matrix from R to C, where some computation is done 
for performance reasons, and back to R for evaluation. But I've run into 
the problem that R and C seem to have different ways of representing the 
matrix in main memory. The C representation of a 2D matrix in linear 
memory is concatenation of the rows whereas in R, it's a concatenation 
of the columns.  That leads to the problem. that an R-matrix, for example
123
456
789
is seen by C as
147
258
369
and vice versa.

Here's an example of C code that simply prints the matrix it gets from R:

#include <stdlib.h>
#include "R.h"

void printMatrix(int *mPtr, int *m, int *n) {
   int (*matrix)[*n] = mPtr;

   int j,k;

   for(j = 0; j < *m; j++){
     for(k = 0; k < *n; k++) {
       printf("%d", matrix[j][k]);
     }
   printf("\n");
   }
}

And here's what happens when I call the function in R:

> m <- 3; n <- 3
> mat <- matrix(c(1:9), nrow=m, ncol=n, byrow=TRUE)
> mat
      [,1] [,2] [,3]
[1,]    1    2    3
[2,]    4    5    6
[3,]    7    8    9
> mat <- .C("printMatrix", mat, as.integer(m), as.integer(n))[[1]]
147
258
369


No matter if you create the matrix with byrow=TRUE or FALSE, C always 
interprets it the other way round. Is there a way to avoid this? I've 
read previous posts on passing a matrix from R to C, but the essence of 
the answers was that "a matrix in R is just a vector with attributes", 
but I don't see how this helps. Maybe someone can clarify.

Thanks a lot in advance!

Cheers
Larissa

Here's the C main function showing that the C code itself is correct:

#include <stdlib.h>

void printMatrix(int *mPtr, int *m, int *n);

int main(void) {
   int m, n, i;
   int *mPtr, *nPtr;
   m = 3;
   n = 3;
   mPtr = &m;
   nPtr = &n;

   int *M = malloc(m * n * sizeof(int));

   for (i = 0; i < m * n; i++){
   M[i] = i + 1;
   }

   printMatrix(M, mPtr, nPtr);

   return EXIT_SUCCESS;


From lorenz at usgs.gov  Fri Dec  6 14:55:26 2013
From: lorenz at usgs.gov (Lorenz, David)
Date: Fri, 6 Dec 2013 07:55:26 -0600
Subject: [Rd] Matrix memory layout R vs. C
In-Reply-To: <52A1CF46.7070408@googlemail.com>
References: <52A1CF46.7070408@googlemail.com>
Message-ID: <CALxY2LfqCXXXY5mr1Cyi+iC_hiuCRPdKfH8rUmaQzyO21C8V6Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20131206/426ba0e9/attachment.pl>

From murdoch.duncan at gmail.com  Fri Dec  6 15:38:51 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 06 Dec 2013 09:38:51 -0500
Subject: [Rd] Matrix memory layout R vs. C
In-Reply-To: <52A1CF46.7070408@googlemail.com>
References: <52A1CF46.7070408@googlemail.com>
Message-ID: <52A1E17B.8090200@gmail.com>

On 06/12/2013 8:21 AM, Larissa Hauer wrote:
> Hi everybody,
>
> I'm trying to pass a matrix from R to C, where some computation is done
> for performance reasons, and back to R for evaluation. But I've run into
> the problem that R and C seem to have different ways of representing the
> matrix in main memory. The C representation of a 2D matrix in linear
> memory is concatenation of the rows whereas in R, it's a concatenation
> of the columns.  That leads to the problem. that an R-matrix, for example
> 123
> 456
> 789
> is seen by C as
> 147
> 258
> 369
> and vice versa.
>
> Here's an example of C code that simply prints the matrix it gets from R:
>
> #include <stdlib.h>
> #include "R.h"
>
> void printMatrix(int *mPtr, int *m, int *n) {
>     int (*matrix)[*n] = mPtr;
>
>     int j,k;
>
>     for(j = 0; j < *m; j++){
>       for(k = 0; k < *n; k++) {
>         printf("%d", matrix[j][k]);
>       }
>     printf("\n");
>     }
> }
>
> And here's what happens when I call the function in R:
>
> > m <- 3; n <- 3
> > mat <- matrix(c(1:9), nrow=m, ncol=n, byrow=TRUE)
> > mat
>        [,1] [,2] [,3]
> [1,]    1    2    3
> [2,]    4    5    6
> [3,]    7    8    9
> > mat <- .C("printMatrix", mat, as.integer(m), as.integer(n))[[1]]
> 147
> 258
> 369
>
>
> No matter if you create the matrix with byrow=TRUE or FALSE, C always
> interprets it the other way round. Is there a way to avoid this? I've
> read previous posts on passing a matrix from R to C, but the essence of
> the answers was that "a matrix in R is just a vector with attributes",
> but I don't see how this helps. Maybe someone can clarify.

I would not assume that a 2D matrix in C doesn't have gaps in it between 
the rows.  Let C treat it as a vector, and write a little macro that 
does the indexing.  For example,

#define INDEX(i,j) (i) + rows*(j)

Then mPtr[INDEX(i,j)] will do R-style indexing (except it will be 
0-based, not 1-based.  You could fix that too if you wanted.)

Duncan Murdoch
>
> Thanks a lot in advance!
>
> Cheers
> Larissa
>
> Here's the C main function showing that the C code itself is correct:
>
> #include <stdlib.h>
>
> void printMatrix(int *mPtr, int *m, int *n);
>
> int main(void) {
>     int m, n, i;
>     int *mPtr, *nPtr;
>     m = 3;
>     n = 3;
>     mPtr = &m;
>     nPtr = &n;
>
>     int *M = malloc(m * n * sizeof(int));
>
>     for (i = 0; i < m * n; i++){
>     M[i] = i + 1;
>     }
>
>     printMatrix(M, mPtr, nPtr);
>
>     return EXIT_SUCCESS;
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From csardi.gabor at gmail.com  Fri Dec  6 15:42:37 2013
From: csardi.gabor at gmail.com (=?ISO-8859-1?B?R+Fib3IgQ3PhcmRp?=)
Date: Fri, 6 Dec 2013 09:42:37 -0500
Subject: [Rd] Matrix memory layout R vs. C
In-Reply-To: <52A1E17B.8090200@gmail.com>
References: <52A1CF46.7070408@googlemail.com>
	<52A1E17B.8090200@gmail.com>
Message-ID: <CABtg=KnYfx_VYvGdmximPm7GSSj-eY-vzdcYKpPPtHDcd1ppXg@mail.gmail.com>

On Fri, Dec 6, 2013 at 9:38 AM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> On 06/12/2013 8:21 AM, Larissa Hauer wrote:
[...]
>
>
> I would not assume that a 2D matrix in C doesn't have gaps in it between the
> rows.  Let C treat it as a vector, and write a little macro that does the
> indexing.  For example,
>
> #define INDEX(i,j) (i) + rows*(j)

I would make this

#define INDEX(i,j) ((i) + rows*(j))

just to be on the safe side.

Gabor

[...]


From ripley at stats.ox.ac.uk  Fri Dec  6 16:42:37 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 06 Dec 2013 15:42:37 +0000
Subject: [Rd] Matrix memory layout R vs. C
In-Reply-To: <CABtg=KnYfx_VYvGdmximPm7GSSj-eY-vzdcYKpPPtHDcd1ppXg@mail.gmail.com>
References: <52A1CF46.7070408@googlemail.com>	<52A1E17B.8090200@gmail.com>
	<CABtg=KnYfx_VYvGdmximPm7GSSj-eY-vzdcYKpPPtHDcd1ppXg@mail.gmail.com>
Message-ID: <52A1F06D.3080701@stats.ox.ac.uk>

On 06/12/2013 14:42, G?bor Cs?rdi wrote:
> On Fri, Dec 6, 2013 at 9:38 AM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>> On 06/12/2013 8:21 AM, Larissa Hauer wrote:
> [...]
>>
>>
>> I would not assume that a 2D matrix in C doesn't have gaps in it between the
>> rows.  Let C treat it as a vector, and write a little macro that does the
>> indexing.  For example,
>>
>> #define INDEX(i,j) (i) + rows*(j)
>
> I would make this
>
> #define INDEX(i,j) ((i) + rows*(j))
>
> just to be on the safe side.

And to be safer on a 64-bit platform

#define INDEX(i,j) ((i) + rows*(R_xlen_t)(j))

since rows*j might overflow there.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From csardi.gabor at gmail.com  Fri Dec  6 16:49:38 2013
From: csardi.gabor at gmail.com (=?ISO-8859-1?B?R+Fib3IgQ3PhcmRp?=)
Date: Fri, 6 Dec 2013 10:49:38 -0500
Subject: [Rd] Matrix memory layout R vs. C
In-Reply-To: <52A1F06D.3080701@stats.ox.ac.uk>
References: <52A1CF46.7070408@googlemail.com> <52A1E17B.8090200@gmail.com>
	<CABtg=KnYfx_VYvGdmximPm7GSSj-eY-vzdcYKpPPtHDcd1ppXg@mail.gmail.com>
	<52A1F06D.3080701@stats.ox.ac.uk>
Message-ID: <CABtg=KmrrJJhLXFRvY0YmxgKuAP=SkS95qbrD3nmpes-mowGEw@mail.gmail.com>

On Fri, Dec 6, 2013 at 10:42 AM, Prof Brian Ripley
<ripley at stats.ox.ac.uk> wrote:
> On 06/12/2013 14:42, G?bor Cs?rdi wrote:
>>
>> On Fri, Dec 6, 2013 at 9:38 AM, Duncan Murdoch <murdoch.duncan at gmail.com>
>> wrote:
>>>
>>> On 06/12/2013 8:21 AM, Larissa Hauer wrote:
>>
>> [...]
>>>
>>>
>>>
>>> I would not assume that a 2D matrix in C doesn't have gaps in it between
>>> the
>>> rows.  Let C treat it as a vector, and write a little macro that does the
>>> indexing.  For example,
>>>
>>> #define INDEX(i,j) (i) + rows*(j)
>>
>>
>> I would make this
>>
>> #define INDEX(i,j) ((i) + rows*(j))
>>
>> just to be on the safe side.
>
>
> And to be safer on a 64-bit platform
>
> #define INDEX(i,j) ((i) + rows*(R_xlen_t)(j))
>
> since rows*j might overflow there.

Indeed. Of course this still does not save you from indexing
out-of-range and integer overflow in the addition.

Gabor

[...]


From lexcarvalho at gmail.com  Fri Dec  6 15:23:13 2013
From: lexcarvalho at gmail.com (Luis Carvalho)
Date: Fri, 6 Dec 2013 09:23:13 -0500
Subject: [Rd] Matrix memory layout R vs. C
In-Reply-To: <52A1CF46.7070408@googlemail.com>
References: <52A1CF46.7070408@googlemail.com>
Message-ID: <20131206142313.GA16781@saci>

Hi Larissa,

> I'm trying to pass a matrix from R to C, where some computation is
> done for performance reasons, and back to R for evaluation. But I've
> run into the problem that R and C seem to have different ways of
> representing the matrix in main memory. The C representation of a 2D
> matrix in linear memory is concatenation of the rows whereas in R,
> it's a concatenation of the columns.  That leads to the problem.

<snip>

R uses column-major order [1] because that's the order used by FORTRAN and R
uses many libraries with a FORTRAN interface (most important: BLAS and LAPACK
for numerical linear algebra.) That's the situation with many other languages
/ libraries that use similar interfaces, such as MATLAB, Octave, Julia, and
Scilab [1]. So, there's no way around it and you just have to get used to
referencing matrix entries in col-major order.

[1] http://en.wikipedia.org/wiki/Row-major_order


> Here's an example of C code that simply prints the matrix it gets from R:

<snip>

Try this instead:

#include <stdlib.h>
#include "R.h"

void printMatrix(int *mPtr, int m, int n) {
  int j,k;

  for(j = 0; j < m; j++){
    for(k = 0; k < n; k++) {
      printf("%d\t", mPtr[j + m * k]);
    }
    printf("\n");
  }
}

> No matter if you create the matrix with byrow=TRUE or FALSE, C
> always interprets it the other way round. Is there a way to avoid
> this? I've read previous posts on passing a matrix from R to C, but
> the essence of the answers was that "a matrix in R is just a vector
> with attributes", but I don't see how this helps. Maybe someone can
> clarify.

Specifying byrow=TRUE only changes how the matrix is *read*, not how it's
stored. A matrix -- and, more generally, an array -- is in fact just a vector
with (dimension) attributes, but that just specifies the memory layout of the
matrix, and not its representation (that is, it doesn't help.) Unfortunately,
there's no way to avoid this, but it shouldn't be too bad to get used to it.
:)

Cheers,
Luis

-- 
Computers are useless. They can only give you answers.
                -- Pablo Picasso

-- 
Luis Carvalho (Kozure)
lua -e 'print((("lexcarvalho at NO.gmail.SPAM.com"):gsub("(%u+%.)","")))'


From lexcarvalho at gmail.com  Fri Dec  6 16:51:39 2013
From: lexcarvalho at gmail.com (Luis Carvalho)
Date: Fri, 6 Dec 2013 10:51:39 -0500
Subject: [Rd] Matrix memory layout R vs. C
In-Reply-To: <52A1F06D.3080701@stats.ox.ac.uk>
References: <52A1CF46.7070408@googlemail.com> <52A1E17B.8090200@gmail.com>
	<CABtg=KnYfx_VYvGdmximPm7GSSj-eY-vzdcYKpPPtHDcd1ppXg@mail.gmail.com>
	<52A1F06D.3080701@stats.ox.ac.uk>
Message-ID: <20131206155139.GA2804@saci>

> And to be safer on a 64-bit platform
> 
> #define INDEX(i,j) ((i) + rows*(R_xlen_t)(j))
> 
> since rows*j might overflow there.

Shouldn't 'rows' be also a parameter?

#define INDEX(rows,i,j) ((i) + (rows)*((R_xlen_t)(j)))

Cheers,
Luis

-- 
Computers are useless. They can only give you answers.
                -- Pablo Picasso

-- 
Luis Carvalho (Kozure)
lua -e 'print((("lexcarvalho at NO.gmail.SPAM.com"):gsub("(%u+%.)","")))'


From ripley at stats.ox.ac.uk  Fri Dec  6 16:52:37 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 06 Dec 2013 15:52:37 +0000
Subject: [Rd] Matrix memory layout R vs. C
In-Reply-To: <CABtg=KmrrJJhLXFRvY0YmxgKuAP=SkS95qbrD3nmpes-mowGEw@mail.gmail.com>
References: <52A1CF46.7070408@googlemail.com>	<52A1E17B.8090200@gmail.com>	<CABtg=KnYfx_VYvGdmximPm7GSSj-eY-vzdcYKpPPtHDcd1ppXg@mail.gmail.com>	<52A1F06D.3080701@stats.ox.ac.uk>
	<CABtg=KmrrJJhLXFRvY0YmxgKuAP=SkS95qbrD3nmpes-mowGEw@mail.gmail.com>
Message-ID: <52A1F2C5.4080401@stats.ox.ac.uk>

On 06/12/2013 15:49, G?bor Cs?rdi wrote:
> On Fri, Dec 6, 2013 at 10:42 AM, Prof Brian Ripley
> <ripley at stats.ox.ac.uk> wrote:
>> On 06/12/2013 14:42, G?bor Cs?rdi wrote:
>>>
>>> On Fri, Dec 6, 2013 at 9:38 AM, Duncan Murdoch <murdoch.duncan at gmail.com>
>>> wrote:
>>>>
>>>> On 06/12/2013 8:21 AM, Larissa Hauer wrote:
>>>
>>> [...]
>>>>
>>>>
>>>>
>>>> I would not assume that a 2D matrix in C doesn't have gaps in it between
>>>> the
>>>> rows.  Let C treat it as a vector, and write a little macro that does the
>>>> indexing.  For example,
>>>>
>>>> #define INDEX(i,j) (i) + rows*(j)
>>>
>>>
>>> I would make this
>>>
>>> #define INDEX(i,j) ((i) + rows*(j))
>>>
>>> just to be on the safe side.
>>
>>
>> And to be safer on a 64-bit platform
>>
>> #define INDEX(i,j) ((i) + rows*(R_xlen_t)(j))
>>
>> since rows*j might overflow there.
>
> Indeed. Of course this still does not save you from indexing
> out-of-range and integer overflow in the addition.

To a large extent it does.  It means the arithmetic is done in R_xlen_t, 
64-bit on 64-bit machines, and so any legitimate index gets computed 
correctly.


>
> Gabor
>
> [...]
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Fri Dec  6 17:06:02 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 06 Dec 2013 16:06:02 +0000
Subject: [Rd] Matrix memory layout R vs. C
In-Reply-To: <20131206155139.GA2804@saci>
References: <52A1CF46.7070408@googlemail.com>
	<52A1E17B.8090200@gmail.com>	<CABtg=KnYfx_VYvGdmximPm7GSSj-eY-vzdcYKpPPtHDcd1ppXg@mail.gmail.com>	<52A1F06D.3080701@stats.ox.ac.uk>
	<20131206155139.GA2804@saci>
Message-ID: <52A1F5EA.9000909@stats.ox.ac.uk>

On 06/12/2013 15:51, Luis Carvalho wrote:
>> And to be safer on a 64-bit platform
>>
>> #define INDEX(i,j) ((i) + rows*(R_xlen_t)(j))
>>
>> since rows*j might overflow there.
>
> Shouldn't 'rows' be also a parameter?

This is a macro, not a function.  'rows' (I would have use nr or nrows) 
is going to be the same at all invocations.

>
> #define INDEX(rows,i,j) ((i) + (rows)*((R_xlen_t)(j)))
>
> Cheers,
> Luis
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From h.wickham at gmail.com  Fri Dec  6 22:20:35 2013
From: h.wickham at gmail.com (Hadley Wickham)
Date: Fri, 6 Dec 2013 15:20:35 -0600
Subject: [Rd] Depending/Importing data only packages
Message-ID: <CABdHhvEXM_Bbr7GXP0nRiURCGfVzcFXOi--9sLUiBe3YrdP-qQ@mail.gmail.com>

Hi all,

What should you do when you rely on a data only package. If you just
"Depend" on it, you get the following from R CMD check:

Package in Depends field not imported from: 'hflights'
  These packages needs to imported from for the case when
  this namespace is loaded but not attached.

But there's nothing in the namespace to import, so adding it to
imports doesn't seem like the right answer.  Is that just a spurious
note?

Hadley

-- 
http://had.co.nz/


From h.wickham at gmail.com  Fri Dec  6 22:29:48 2013
From: h.wickham at gmail.com (Hadley Wickham)
Date: Fri, 6 Dec 2013 15:29:48 -0600
Subject: [Rd] Linking to native routines in other packages
In-Reply-To: <528742AD.1090804@r-enthusiasts.com>
References: <528742AD.1090804@r-enthusiasts.com>
Message-ID: <CABdHhvHVms0UcNNP-AUhAoptbvQzLb3MKimaJQvDQo6FcZgQ=A@mail.gmail.com>

> But now if I do Depends: Rcpp or Imports: Rcpp for the sole purpose of this
> LinkingTo mechanism, I'm getting
>
> * checking dependencies in R code ... NOTE
> Namespace in Imports field not imported from: ?Rcpp?
>   All declared Imports should be used.
> See the information on DESCRIPTION files in the chapter ?Creating R
> packages? of the ?Writing R Extensions? manual.

This is just a note, so perhaps it's spurious, and can be ignored as
long as you provide an explanation when submitting to CRAN.

Hadley

-- 
http://had.co.nz/


From romain at r-enthusiasts.com  Sat Dec  7 04:49:25 2013
From: romain at r-enthusiasts.com (Romain Francois)
Date: Sat, 7 Dec 2013 04:49:25 +0100
Subject: [Rd] Linking to native routines in other packages
In-Reply-To: <CABdHhvHVms0UcNNP-AUhAoptbvQzLb3MKimaJQvDQo6FcZgQ=A@mail.gmail.com>
References: <528742AD.1090804@r-enthusiasts.com>
	<CABdHhvHVms0UcNNP-AUhAoptbvQzLb3MKimaJQvDQo6FcZgQ=A@mail.gmail.com>
Message-ID: <52A29AC5.8010005@r-enthusiasts.com>

Le 06/12/2013 22:29, Hadley Wickham a ?crit :
>> But now if I do Depends: Rcpp or Imports: Rcpp for the sole purpose of this
>> LinkingTo mechanism, I'm getting
>>
>> * checking dependencies in R code ... NOTE
>> Namespace in Imports field not imported from: ?Rcpp?
>>    All declared Imports should be used.
>> See the information on DESCRIPTION files in the chapter ?Creating R
>> packages? of the ?Writing R Extensions? manual.
>
> This is just a note, so perhaps it's spurious, and can be ignored as
> long as you provide an explanation when submitting to CRAN.
>
> Hadley

The problem is that I'd have to ask every package maintainer to 
negociate that when they release a package that depends on Rcpp.

Perhaps that's alright.

Romain

-- 
Romain Francois
Professional R Enthusiast
+33(0) 6 28 91 30 30


From pgilbert902 at gmail.com  Sat Dec  7 17:51:44 2013
From: pgilbert902 at gmail.com (Paul Gilbert)
Date: Sat, 07 Dec 2013 11:51:44 -0500
Subject: [Rd] Depending/Importing data only packages
In-Reply-To: <CABdHhvEXM_Bbr7GXP0nRiURCGfVzcFXOi--9sLUiBe3YrdP-qQ@mail.gmail.com>
References: <CABdHhvEXM_Bbr7GXP0nRiURCGfVzcFXOi--9sLUiBe3YrdP-qQ@mail.gmail.com>
Message-ID: <52A35220.7010307@gmail.com>

Would "Suggests" not work in this situation? I don't understand why you 
would need Depends. In what sense do you rely on the data only package?

Paul

On 13-12-06 04:20 PM, Hadley Wickham wrote:
> Hi all,
>
> What should you do when you rely on a data only package. If you just
> "Depend" on it, you get the following from R CMD check:
>
> Package in Depends field not imported from: 'hflights'
>    These packages needs to imported from for the case when
>    this namespace is loaded but not attached.
>
> But there's nothing in the namespace to import, so adding it to
> imports doesn't seem like the right answer.  Is that just a spurious
> note?
>
> Hadley
>


From csardi.gabor at gmail.com  Sat Dec  7 18:19:31 2013
From: csardi.gabor at gmail.com (=?ISO-8859-1?B?R+Fib3IgQ3PhcmRp?=)
Date: Sat, 7 Dec 2013 12:19:31 -0500
Subject: [Rd] Depending/Importing data only packages
In-Reply-To: <52A35220.7010307@gmail.com>
References: <CABdHhvEXM_Bbr7GXP0nRiURCGfVzcFXOi--9sLUiBe3YrdP-qQ@mail.gmail.com>
	<52A35220.7010307@gmail.com>
Message-ID: <CABtg=K=pVVZzRxj5JtLuP92kL1Fiho3gxC85HJouV6ZHjeikDw@mail.gmail.com>

I don't know about this particular case, but in general it makes sense
to rely on a data package. E.g. I am creating a package that does
Bayesian inference for a particular problem, potentially relying on
prior knowledge. I think it makes sense to put the data that is used
to calculate the prior into another package, because it will be larger
than the code, and it does not change that often.

Gabor

On Sat, Dec 7, 2013 at 11:51 AM, Paul Gilbert <pgilbert902 at gmail.com> wrote:
> Would "Suggests" not work in this situation? I don't understand why you
> would need Depends. In what sense do you rely on the data only package?
>
> Paul
>
> On 13-12-06 04:20 PM, Hadley Wickham wrote:
>>
>> Hi all,
>>
>> What should you do when you rely on a data only package. If you just
>> "Depend" on it, you get the following from R CMD check:
>>
>> Package in Depends field not imported from: 'hflights'
>>    These packages needs to imported from for the case when
>>    this namespace is loaded but not attached.
>>
>> But there's nothing in the namespace to import, so adding it to
>> imports doesn't seem like the right answer.  Is that just a spurious
>> note?
>>
>> Hadley
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From h.wickham at gmail.com  Sat Dec  7 19:05:26 2013
From: h.wickham at gmail.com (Hadley Wickham)
Date: Sat, 7 Dec 2013 12:05:26 -0600
Subject: [Rd] Depending/Importing data only packages
In-Reply-To: <52A35220.7010307@gmail.com>
References: <CABdHhvEXM_Bbr7GXP0nRiURCGfVzcFXOi--9sLUiBe3YrdP-qQ@mail.gmail.com>
	<52A35220.7010307@gmail.com>
Message-ID: <CABdHhvF29hhMb-VnAGL8QVe0UGywKYSwOsBc+Yc-3aBiWn4GYA@mail.gmail.com>

> Would "Suggests" not work in this situation? I don't understand why you
> would need Depends. In what sense do you rely on the data only package?

Because I want someone who downloads the package to be able to run the
examples without having to take additional action.

Hadley


-- 
http://had.co.nz/


From pgilbert902 at gmail.com  Sat Dec  7 19:35:33 2013
From: pgilbert902 at gmail.com (Paul Gilbert)
Date: Sat, 07 Dec 2013 13:35:33 -0500
Subject: [Rd] Depending/Importing data only packages
In-Reply-To: <CABtg=K=pVVZzRxj5JtLuP92kL1Fiho3gxC85HJouV6ZHjeikDw@mail.gmail.com>
References: <CABdHhvEXM_Bbr7GXP0nRiURCGfVzcFXOi--9sLUiBe3YrdP-qQ@mail.gmail.com>	<52A35220.7010307@gmail.com>
	<CABtg=K=pVVZzRxj5JtLuP92kL1Fiho3gxC85HJouV6ZHjeikDw@mail.gmail.com>
Message-ID: <52A36A75.5030900@gmail.com>



On 13-12-07 12:19 PM, G?bor Cs?rdi wrote:
> I don't know about this particular case, but in general it makes sense
> to rely on a data package. E.g. I am creating a package that does
> Bayesian inference for a particular problem, potentially relying on
> prior knowledge. I think it makes sense to put the data that is used
> to calculate the prior into another package, because it will be larger
> than the code, and it does not change that often.
>
> Gabor
>
> On Sat, Dec 7, 2013 at 11:51 AM, Paul Gilbert <pgilbert902 at gmail.com> wrote:
>> Would "Suggests" not work in this situation? I don't understand why you
>> would need Depends. In what sense do you rely on the data only package?
>>

HW> Because I want someone who downloads the package to be able to run
HW> the examples without having to take additional action.
HW>
HW> Hadley

I went through this myself, including thinking it was a nuisance for 
users to need to attach other packages to run examples. In the end I 
decided it is not so bad to be explicit about what package the example 
data comes from, so illustrate it in the examples. Users may not always 
want this data, and other packages that build on yours probably do not 
want it.

Even in the Bayesian inference case pointed out by G?bor, I am not 
convinced. It means the prior knowledge base cannot be exchanged for 
another one. The package would be more general if it allowed the 
possibility of attaching a different database of prior information. But 
this is clearly a more important case, since the code probably does not 
work without some database. (There are a few other situations where 
something like "RequireOneOf:" would be useful.)

Paul

>> Paul
>>
>> On 13-12-06 04:20 PM, Hadley Wickham wrote:
>>>
>>> Hi all,
>>>
>>> What should you do when you rely on a data only package. If you just
>>> "Depend" on it, you get the following from R CMD check:
>>>
>>> Package in Depends field not imported from: 'hflights'
>>>     These packages needs to imported from for the case when
>>>     this namespace is loaded but not attached.
>>>
>>> But there's nothing in the namespace to import, so adding it to
>>> imports doesn't seem like the right answer.  Is that just a spurious
>>> note?
>>>
>>> Hadley
>>>
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel


From ggrothendieck at gmail.com  Sat Dec  7 19:47:29 2013
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 7 Dec 2013 13:47:29 -0500
Subject: [Rd] Depending/Importing data only packages
In-Reply-To: <52A36A75.5030900@gmail.com>
References: <CABdHhvEXM_Bbr7GXP0nRiURCGfVzcFXOi--9sLUiBe3YrdP-qQ@mail.gmail.com>
	<52A35220.7010307@gmail.com>
	<CABtg=K=pVVZzRxj5JtLuP92kL1Fiho3gxC85HJouV6ZHjeikDw@mail.gmail.com>
	<52A36A75.5030900@gmail.com>
Message-ID: <CAP01uRnaiEP5Es8=eTxu8Y2ZuiE+gvND72zbm4Q67FR-R-jQPQ@mail.gmail.com>

On Sat, Dec 7, 2013 at 1:35 PM, Paul Gilbert <pgilbert902 at gmail.com> wrote:
>
>
> On 13-12-07 12:19 PM, G?bor Cs?rdi wrote:
>>
>> I don't know about this particular case, but in general it makes sense
>> to rely on a data package. E.g. I am creating a package that does
>> Bayesian inference for a particular problem, potentially relying on
>> prior knowledge. I think it makes sense to put the data that is used
>> to calculate the prior into another package, because it will be larger
>> than the code, and it does not change that often.
>>
>> Gabor
>>
>> On Sat, Dec 7, 2013 at 11:51 AM, Paul Gilbert <pgilbert902 at gmail.com>
>> wrote:
>>>
>>> Would "Suggests" not work in this situation? I don't understand why you
>>> would need Depends. In what sense do you rely on the data only package?
>>>
>
> HW> Because I want someone who downloads the package to be able to run
> HW> the examples without having to take additional action.
> HW>
> HW> Hadley
>
> I went through this myself, including thinking it was a nuisance for users
> to need to attach other packages to run examples. In the end I decided it is
> not so bad to be explicit about what package the example data comes from, so
> illustrate it in the examples. Users may not always want this data, and
> other packages that build on yours probably do not want it.
>
> Even in the Bayesian inference case pointed out by G?bor, I am not
> convinced. It means the prior knowledge base cannot be exchanged for another
> one. The package would be more general if it allowed the possibility of
> attaching a different database of prior information. But this is clearly a
> more important case, since the code probably does not work without some
> database. (There are a few other situations where something like
> "RequireOneOf:" would be useful.)
>

Requiring users to load packages which could be loaded automatically
seems to go against ease of use.  Its just one more thing that they
have to remember to do.

It really should be possible to write a "batteries included" package
while leveraging off of other packages.


From csardi.gabor at gmail.com  Sat Dec  7 19:58:45 2013
From: csardi.gabor at gmail.com (=?ISO-8859-1?B?R+Fib3IgQ3PhcmRp?=)
Date: Sat, 7 Dec 2013 13:58:45 -0500
Subject: [Rd] Depending/Importing data only packages
In-Reply-To: <52A36A75.5030900@gmail.com>
References: <CABdHhvEXM_Bbr7GXP0nRiURCGfVzcFXOi--9sLUiBe3YrdP-qQ@mail.gmail.com>
	<52A35220.7010307@gmail.com>
	<CABtg=K=pVVZzRxj5JtLuP92kL1Fiho3gxC85HJouV6ZHjeikDw@mail.gmail.com>
	<52A36A75.5030900@gmail.com>
Message-ID: <CABtg=Km3TdbiEv2ygAYU4CEJbtw1W43c2r=6CNK4c199SxqwWw@mail.gmail.com>

On Sat, Dec 7, 2013 at 1:35 PM, Paul Gilbert <pgilbert902 at gmail.com> wrote:
>
>
> On 13-12-07 12:19 PM, G?bor Cs?rdi wrote:
>>
>> I don't know about this particular case, but in general it makes sense
>> to rely on a data package. E.g. I am creating a package that does
>> Bayesian inference for a particular problem, potentially relying on
>> prior knowledge. I think it makes sense to put the data that is used
>> to calculate the prior into another package, because it will be larger
>> than the code, and it does not change that often.
>>
>> Gabor
>>
>>
>> On Sat, Dec 7, 2013 at 11:51 AM, Paul Gilbert <pgilbert902 at gmail.com>
>> wrote:
>>>
>>> Would "Suggests" not work in this situation? I don't understand why you
>>> would need Depends. In what sense do you rely on the data only package?
>>>
>
> HW> Because I want someone who downloads the package to be able to run
> HW> the examples without having to take additional action.
> HW>
> HW> Hadley
>
> I went through this myself, including thinking it was a nuisance for users
> to need to attach other packages to run examples. In the end I decided it is
> not so bad to be explicit about what package the example data comes from, so
> illustrate it in the examples. Users may not always want this data, and
> other packages that build on yours probably do not want it.
>
> Even in the Bayesian inference case pointed out by G?bor, I am not
> convinced. It means the prior knowledge base cannot be exchanged for another
> one. The package would be more general if it allowed the possibility of
> attaching a different database of prior information. But this is clearly a
> more important case, since the code probably does not work without some
> database. (There are a few other situations where something like
> "RequireOneOf:" would be useful.)

First, as you say, you went through this yourself, which means that
the "right" answer to the problem is not obvious. This is (mainly) a
design decision, and if it is not obvious that depending on a data
package is always bad design. Then why not let the package developer
decide?

Second, I very much think that using 'Suggests' is misleading in this
case. The data package is clearly required. I, as a user, would expect
that if I downloaded all requirements, then the package will work,
which is not true any more.

(Let's not go into what 'Suggests' actually means, and how totally
confusing it is already.)

'RequireOneOf' would be indeed useful.

Best,
Gabor

> Paul

[...]


From edd at debian.org  Sat Dec  7 20:24:58 2013
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sat, 7 Dec 2013 13:24:58 -0600
Subject: [Rd] Depending/Importing data only packages
In-Reply-To: <CABtg=Km3TdbiEv2ygAYU4CEJbtw1W43c2r=6CNK4c199SxqwWw@mail.gmail.com>
References: <CABdHhvEXM_Bbr7GXP0nRiURCGfVzcFXOi--9sLUiBe3YrdP-qQ@mail.gmail.com>
	<52A35220.7010307@gmail.com>
	<CABtg=K=pVVZzRxj5JtLuP92kL1Fiho3gxC85HJouV6ZHjeikDw@mail.gmail.com>
	<52A36A75.5030900@gmail.com>
	<CABtg=Km3TdbiEv2ygAYU4CEJbtw1W43c2r=6CNK4c199SxqwWw@mail.gmail.com>
Message-ID: <21155.30218.21613.132618@max.nulle.part>


On 7 December 2013 at 13:58, G?bor Cs?rdi wrote:
| 'RequireOneOf' would be indeed useful.

The DESCRIPTION file follows Debian Control File formats. Another aspect of
these could be useful here: the '|' operator. Eg for ess (the Debian package)
we have

  Depends: dpkg (>= 1.15.4) | install-info, emacs23 | emacs22 | emacs21 | emacsen

saying that either a recent enough dpkg [package tool] or the install-info
package are needed [to deal with .info files] and that one of the available
emacs versions will do, with the first one being the default choice and the
last one a virtual package providing a catch-all fallback.

The R package does similar things to pick one of several blas and lapack
packages:

  Depends: zip, unzip, libpaper-utils, xdg-utils, \
    libblas3 | libblas.so.3 | libatlas3-base, [...] \
    liblapack3 | liblapack.so.3 | libatlas3-base, [...]

Dirk

-- 
Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com


From murdoch.duncan at gmail.com  Sat Dec  7 21:05:46 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 07 Dec 2013 15:05:46 -0500
Subject: [Rd] Depending/Importing data only packages
In-Reply-To: <CABdHhvEXM_Bbr7GXP0nRiURCGfVzcFXOi--9sLUiBe3YrdP-qQ@mail.gmail.com>
References: <CABdHhvEXM_Bbr7GXP0nRiURCGfVzcFXOi--9sLUiBe3YrdP-qQ@mail.gmail.com>
Message-ID: <52A37F9A.1010106@gmail.com>

On 13-12-06 4:20 PM, Hadley Wickham wrote:
> Hi all,
>
> What should you do when you rely on a data only package. If you just
> "Depend" on it, you get the following from R CMD check:
>
> Package in Depends field not imported from: 'hflights'
>    These packages needs to imported from for the case when
>    this namespace is loaded but not attached.
>
> But there's nothing in the namespace to import, so adding it to
> imports doesn't seem like the right answer.  Is that just a spurious
> note?
>
> Hadley
>

I don't know whether the author of that note would consider it spurious 
or not.   A simple workaround for you (as the author of hflights) is to 
put a function into the namespace.  For example, get_hflights(), that 
gets a copy of the data:

get_hflights <- function() {
   data("hflights", package="hflights", envir=environment())
   hflights
}

I don't know a simple workaround for someone who depends on a data-only 
package that they did not author.

Duncan Murdoch


From h.wickham at gmail.com  Sat Dec  7 21:35:53 2013
From: h.wickham at gmail.com (Hadley Wickham)
Date: Sat, 7 Dec 2013 14:35:53 -0600
Subject: [Rd] Depending/Importing data only packages
In-Reply-To: <52A37F9A.1010106@gmail.com>
References: <CABdHhvEXM_Bbr7GXP0nRiURCGfVzcFXOi--9sLUiBe3YrdP-qQ@mail.gmail.com>
	<52A37F9A.1010106@gmail.com>
Message-ID: <CABdHhvEK4Aq8DLhifTbtE5FDSG1yjFfcsKw0MATye_ETOWi5CA@mail.gmail.com>

> I don't know whether the author of that note would consider it spurious or
> not.   A simple workaround for you (as the author of hflights) is to put a
> function into the namespace.  For example, get_hflights(), that gets a copy
> of the data:
>
> get_hflights <- function() {
>   data("hflights", package="hflights", envir=environment())
>   hflights
> }

Another option is to put it in sysdata.rda and then export it - but
then (I think) you don't get the nice lazy loading.  It would be nice
to have some official guidance on what is preferred.

Hadley

-- 
http://had.co.nz/


From pgilbert902 at gmail.com  Sat Dec  7 23:08:10 2013
From: pgilbert902 at gmail.com (Paul Gilbert)
Date: Sat, 07 Dec 2013 17:08:10 -0500
Subject: [Rd] Depending/Importing data only packages
In-Reply-To: <CAP01uRnaiEP5Es8=eTxu8Y2ZuiE+gvND72zbm4Q67FR-R-jQPQ@mail.gmail.com>
References: <CABdHhvEXM_Bbr7GXP0nRiURCGfVzcFXOi--9sLUiBe3YrdP-qQ@mail.gmail.com>
	<52A35220.7010307@gmail.com>
	<CABtg=K=pVVZzRxj5JtLuP92kL1Fiho3gxC85HJouV6ZHjeikDw@mail.gmail.com>
	<52A36A75.5030900@gmail.com>
	<CAP01uRnaiEP5Es8=eTxu8Y2ZuiE+gvND72zbm4Q67FR-R-jQPQ@mail.gmail.com>
Message-ID: <52A39C4A.8000305@gmail.com>



On 13-12-07 01:47 PM, Gabor Grothendieck wrote:
> On Sat, Dec 7, 2013 at 1:35 PM, Paul Gilbert <pgilbert902 at gmail.com> wrote:
>>
>>
>> On 13-12-07 12:19 PM, G?bor Cs?rdi wrote:
>>>
>>> I don't know about this particular case, but in general it makes sense
>>> to rely on a data package. E.g. I am creating a package that does
>>> Bayesian inference for a particular problem, potentially relying on
>>> prior knowledge. I think it makes sense to put the data that is used
>>> to calculate the prior into another package, because it will be larger
>>> than the code, and it does not change that often.
>>>
>>> Gabor
>>>
>>> On Sat, Dec 7, 2013 at 11:51 AM, Paul Gilbert <pgilbert902 at gmail.com>
>>> wrote:
>>>>
>>>> Would "Suggests" not work in this situation? I don't understand why you
>>>> would need Depends. In what sense do you rely on the data only package?
>>>>
>>
>> HW> Because I want someone who downloads the package to be able to run
>> HW> the examples without having to take additional action.
>> HW>
>> HW> Hadley
>>
>> I went through this myself, including thinking it was a nuisance for users
>> to need to attach other packages to run examples. In the end I decided it is
>> not so bad to be explicit about what package the example data comes from, so
>> illustrate it in the examples. Users may not always want this data, and
>> other packages that build on yours probably do not want it.
>>
>> Even in the Bayesian inference case pointed out by G?bor, I am not
>> convinced. It means the prior knowledge base cannot be exchanged for another
>> one. The package would be more general if it allowed the possibility of
>> attaching a different database of prior information. But this is clearly a
>> more important case, since the code probably does not work without some
>> database. (There are a few other situations where something like
>> "RequireOneOf:" would be useful.)
>>
>
> Requiring users to load packages which could be loaded automatically
> seems to go against ease of use.  Its just one more thing that they
> have to remember to do.
>
> It really should be possible to write a "batteries included" package
> while leveraging off of other packages.
>
Just to be clear, I distinguish the "batteries included" situation from 
the "spare batteries included" situation. I think it should be possible 
to automatically load everything that is really needed, that is why I 
think the Bayesian database is a more important case. But it strikes me 
as bad to attach everything that could ever possibly be wanted by a 
user. After all, it would be possible to automatically attach all 
packages. Some packages seemed to be headed in that direction before the 
new rules started to be enforced.

There is certainly a trade-off here between ease of use, not needing the 
user to attach packages, and namespace conflicts, which will result in 
time and difficulty debugging. For packages that no one ever uses in 
other packages, there would be a tendency to lean toward ease of use. 
But as soon as anyone starts building on top of a package with another 
one, I think that avoiding potential conflicts will dominate.

Paul


From h.wickham at gmail.com  Sat Dec  7 23:16:06 2013
From: h.wickham at gmail.com (Hadley Wickham)
Date: Sat, 7 Dec 2013 16:16:06 -0600
Subject: [Rd] Depending/Importing data only packages
In-Reply-To: <52A39C4A.8000305@gmail.com>
References: <CABdHhvEXM_Bbr7GXP0nRiURCGfVzcFXOi--9sLUiBe3YrdP-qQ@mail.gmail.com>
	<52A35220.7010307@gmail.com>
	<CABtg=K=pVVZzRxj5JtLuP92kL1Fiho3gxC85HJouV6ZHjeikDw@mail.gmail.com>
	<52A36A75.5030900@gmail.com>
	<CAP01uRnaiEP5Es8=eTxu8Y2ZuiE+gvND72zbm4Q67FR-R-jQPQ@mail.gmail.com>
	<52A39C4A.8000305@gmail.com>
Message-ID: <CABdHhvEGZfuRgjGcbg38CBnODwGdEUzFEpMoT2-=zz5bQnwogA@mail.gmail.com>

> Just to be clear, I distinguish the "batteries included" situation from the
> "spare batteries included" situation. I think it should be possible to
> automatically load everything that is really needed, that is why I think the
> Bayesian database is a more important case. But it strikes me as bad to
> attach everything that could ever possibly be wanted by a user. After all,
> it would be possible to automatically attach all packages. Some packages
> seemed to be headed in that direction before the new rules started to be
> enforced.

I agree, but for data only packages, attaching the namespace has no
impact on other code because it's empty.

Hadley


-- 
http://had.co.nz/


From gmbecker at ucdavis.edu  Sat Dec  7 23:17:26 2013
From: gmbecker at ucdavis.edu (Gabriel Becker)
Date: Sat, 7 Dec 2013 14:17:26 -0800
Subject: [Rd] Depending/Importing data only packages
In-Reply-To: <52A39C4A.8000305@gmail.com>
References: <CABdHhvEXM_Bbr7GXP0nRiURCGfVzcFXOi--9sLUiBe3YrdP-qQ@mail.gmail.com>
	<52A35220.7010307@gmail.com>
	<CABtg=K=pVVZzRxj5JtLuP92kL1Fiho3gxC85HJouV6ZHjeikDw@mail.gmail.com>
	<52A36A75.5030900@gmail.com>
	<CAP01uRnaiEP5Es8=eTxu8Y2ZuiE+gvND72zbm4Q67FR-R-jQPQ@mail.gmail.com>
	<52A39C4A.8000305@gmail.com>
Message-ID: <CADwqtCN_Hx6pbUrjFZoNgTazJ5hH9SoB=h=E3+6rC+u0jr5a1Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20131207/4752199f/attachment.pl>

From h.wickham at gmail.com  Sat Dec  7 23:21:47 2013
From: h.wickham at gmail.com (Hadley Wickham)
Date: Sat, 7 Dec 2013 16:21:47 -0600
Subject: [Rd] Depending/Importing data only packages
In-Reply-To: <CADwqtCN_Hx6pbUrjFZoNgTazJ5hH9SoB=h=E3+6rC+u0jr5a1Q@mail.gmail.com>
References: <CABdHhvEXM_Bbr7GXP0nRiURCGfVzcFXOi--9sLUiBe3YrdP-qQ@mail.gmail.com>
	<52A35220.7010307@gmail.com>
	<CABtg=K=pVVZzRxj5JtLuP92kL1Fiho3gxC85HJouV6ZHjeikDw@mail.gmail.com>
	<52A36A75.5030900@gmail.com>
	<CAP01uRnaiEP5Es8=eTxu8Y2ZuiE+gvND72zbm4Q67FR-R-jQPQ@mail.gmail.com>
	<52A39C4A.8000305@gmail.com>
	<CADwqtCN_Hx6pbUrjFZoNgTazJ5hH9SoB=h=E3+6rC+u0jr5a1Q@mail.gmail.com>
Message-ID: <CABdHhvEGMmJszw0pY6xpddWPapGeY9yqRbA7k2JVLkKVcqiD2Q@mail.gmail.com>

> The Writing R Extensions manual says that Suggests is for packages which
> are required only for examples, which I believe matches Hadley's original
> question.

Yes, but without this package they won't be able to run the majority
of examples, which I think delivers a poor experience to the user. It
also means I have to litter my examples with if(require("x")),
decreasing the signal to noise ratio in the examples.

But we're getting a bit far from my original question about the NOTE:

  Package in Depends field not imported from: 'hflights'
  These packages needs to imported from for the case when
  this namespace is loaded but not attached.

Depending on (or linking to) a package is not just about making the
functions in the package available.

Hadley

-- 
http://had.co.nz/


From pgilbert902 at gmail.com  Sun Dec  8 05:15:49 2013
From: pgilbert902 at gmail.com (Paul Gilbert)
Date: Sat, 07 Dec 2013 23:15:49 -0500
Subject: [Rd] Depending/Importing data only packages
In-Reply-To: <CABdHhvEGMmJszw0pY6xpddWPapGeY9yqRbA7k2JVLkKVcqiD2Q@mail.gmail.com>
References: <CABdHhvEXM_Bbr7GXP0nRiURCGfVzcFXOi--9sLUiBe3YrdP-qQ@mail.gmail.com>
	<52A35220.7010307@gmail.com>
	<CABtg=K=pVVZzRxj5JtLuP92kL1Fiho3gxC85HJouV6ZHjeikDw@mail.gmail.com>
	<52A36A75.5030900@gmail.com>
	<CAP01uRnaiEP5Es8=eTxu8Y2ZuiE+gvND72zbm4Q67FR-R-jQPQ@mail.gmail.com>
	<52A39C4A.8000305@gmail.com>
	<CADwqtCN_Hx6pbUrjFZoNgTazJ5hH9SoB=h=E3+6rC+u0jr5a1Q@mail.gmail.com>
	<CABdHhvEGMmJszw0pY6xpddWPapGeY9yqRbA7k2JVLkKVcqiD2Q@mail.gmail.com>
Message-ID: <52A3F275.8000804@gmail.com>



On 13-12-07 05:21 PM, Hadley Wickham wrote:
>> The Writing R Extensions manual says that Suggests is for packages which
>> are required only for examples, which I believe matches Hadley's original
>> question.
>
> Yes, but without this package they won't be able to run the majority
> of examples, which I think delivers a poor experience to the user. It
> also means I have to litter my examples with if(require("x")),

I think you just need require("x") or library("x"). If it is in Suggests 
then it is available whenever examples are tested, so you don't need the 
if(). In my opinion, this increases the signal by indicating to the 
reader where the data comes from.

> decreasing the signal to noise ratio in the examples.
>
> But we're getting a bit far from my original question about the NOTE:
>
>    Package in Depends field not imported from: 'hflights'
>    These packages needs to imported from for the case when
>    this namespace is loaded but not attached.
>
> Depending on (or linking to) a package is not just about making the
> functions in the package available.

Several of us used to think that, but the modern interpretation seems to 
be just about making things in the package yours depends on available to 
users of your package. "Exports:" might be a better term than 
"Depends:", at least if Depends: was not trying to mean both Imports: 
and Exports:".

Paul
>
> Hadley
>


From i.richa.khandelwal at gmail.com  Mon Dec  9 11:45:46 2013
From: i.richa.khandelwal at gmail.com (rk0709)
Date: Mon, 9 Dec 2013 02:45:46 -0800 (PST)
Subject: [Rd] How to package cran package into a debian package so that it
 can be installed using apt-get
Message-ID: <1386585946559-4681859.post@n4.nabble.com>

Debian packages are not available for all r-cran-* packages. 

In one of my R scripts, i am using forecast package which is not available
as apt-get package. Also it is dependent on R 3.0

To install such packages on my server i do not want to go by
install.packages(), rather i would prefer to create debian package.

How can package cran into a debian package so that i can install it on my
servers using apt-get ?



--
View this message in context: http://r.789695.n4.nabble.com/How-to-package-cran-package-into-a-debian-package-so-that-it-can-be-installed-using-apt-get-tp4681859.html
Sent from the R devel mailing list archive at Nabble.com.


From edd at debian.org  Mon Dec  9 13:19:49 2013
From: edd at debian.org (Dirk Eddelbuettel)
Date: Mon, 9 Dec 2013 06:19:49 -0600
Subject: [Rd] How to package cran package into a debian package so that
 it can be installed using apt-get
In-Reply-To: <1386585946559-4681859.post@n4.nabble.com>
References: <1386585946559-4681859.post@n4.nabble.com>
Message-ID: <21157.46437.916601.760605@max.nulle.part>


On 9 December 2013 at 02:45, rk0709 wrote:
| Debian packages are not available for all r-cran-* packages. 

They are. Look at 

     http://debian-r.debian.net/

| In one of my R scripts, i am using forecast package which is not available
| as apt-get package. Also it is dependent on R 3.0
| 
| To install such packages on my server i do not want to go by
| install.packages(), rather i would prefer to create debian package.
| 
| How can package cran into a debian package so that i can install it on my
| servers using apt-get ?

There are maybe two hundred r-cran-* packages. Did you look at their sources?
[ Hint: it is pretty mechanic as 'R CMD INSTALL' is well standardized. ]
Did you look at the Debian packaging documentation?  It would probably be a
good exercise for you to try to create your own r-cran-forecast package.

Anyway, all this is probably off-topic for r-devel. Consider the r-sig-debian
list, or one of the Debian lists.

Dirk

-- 
Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com


From mtmorgan at fhcrc.org  Wed Dec 11 11:39:52 2013
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Wed, 11 Dec 2013 02:39:52 -0800
Subject: [Rd] Undocumented S4 method Warning For Bracket
In-Reply-To: <ae2b45e5a97f444aaa68bbc850f4b4bd@BLUPR01MB035.prod.exchangelabs.com>
References: <ae2b45e5a97f444aaa68bbc850f4b4bd@BLUPR01MB035.prod.exchangelabs.com>
Message-ID: <52A840F8.1060808@fhcrc.org>

On 12/05/2013 07:00 PM, Dario Strbenac wrote:
> Hello,
>
> With R version 3.0.2 Patched (2013-10-30 r64123) I don't see warnings that I get in R Under development (unstable) (2013-11-03 r64145)
>
> The warnings are like :
>
> Undocumented S4 methods:
>    generic '[' and siglist 'BayMethList,ANY,ANY'
>
> The function actually looks like :
>
> setMethod("[", "BayMethList",
>      function(x, i) {
>    # Code to subset object.
> }
>
> It has 2 parameters, not 3. The warning also happens in R 3.0.2 Release. Has this been fixed in Patched but not in the development version ?
>

Not a complete answer but actually the generic is

 > getGeneric("[")
standardGeneric for "[" defined from package "base"

function (x, i, j, ..., drop = TRUE)
standardGeneric("[", .Primitive("["))
<bytecode: 0x46a54e0>
<environment: 0x4698330>
Methods may be defined for arguments: x, i, j, drop
Use  showMethods("[")  for currently available ones.

and the fact that you've implemented a simpler method signature doesn't change 
the overall signature

 > getMethod("[", "BayMethList")
Method Definition:

function (x, i, j, ..., drop = TRUE)
{
     .local <- function (x, i)
     {
     }
     .local(x, i, ...)
}

Signatures:
         x
target  "BayMethList"
defined "BayMethList"

Notice how your method actually accepts and then silently ignores a 'j' 
argument. A better (?) method definition would be

    setMethod("[", c("BayMethList", "ANY", "missing"),
        function(x, i, j, ..., drop=TRUE) {})

so a user providing a 'j' argument would be told that there was no matching method.

Martin
> --------------------------------------
> Dario Strbenac
> PhD Student
> University of Sydney
> Camperdown NSW 2050
> Australia
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


-- 
Computational Biology / Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N.
PO Box 19024 Seattle, WA 98109

Location: Arnold Building M1 B861
Phone: (206) 667-2793


From kirill.mueller at ivt.baug.ethz.ch  Thu Dec 12 01:39:39 2013
From: kirill.mueller at ivt.baug.ethz.ch (=?ISO-8859-1?Q?Kirill_M=FCller?=)
Date: Thu, 12 Dec 2013 01:39:39 +0100
Subject: [Rd] Strategies for keeping autogenerated .Rd files out of a Git
	tree
Message-ID: <52A905CB.4020701@ivt.baug.ethz.ch>

Hi

Quite a few R packages are now available on GitHub long before they 
appear on CRAN, installation is simple thanks to 
devtools::install_github(). However, it seems to be common practice to 
keep the .Rd files (and NAMESPACE and the Collate section in the 
DESCRIPTION) in the Git tree, and to manually update it, even if they 
are autogenerated from the R code by roxygen2. This requires extra work 
for each update of the documentation and also binds package development 
to a specific version of roxygen2 (because otherwise lots of bogus 
changes can be added by roxygenizing with a different version).

What options are there to generate the .Rd files during build/install? 
In https://github.com/hadley/devtools/issues/43 the issue has been 
discussed, perhaps it can be summarized as follows:

- The devtools package is not the right place to implement 
roxygenize-before-build
- A continuous integration service would be better for that, but 
currently there's nothing that would be easy to use
- Roxygenizing via src/Makefile could work but requires further 
investigation and an installation of Rtools/xcode on Windows/OS X

Especially the last point looks interesting to me, but since this is not 
widely used there must be pitfalls I'm not aware of. The general idea 
would be:

- Place code that builds/updates the .Rd and NAMESPACE files into 
src/Makefile
- Users installing the package from source will require infrastructure 
(Rtools/make)
- For binary packages, the .Rd files are already generated and added to 
the .tar.gz during R CMD build before they are submitted to 
CRAN/WinBuilder, and they are also generated (in theory) by R CMD build 
--binary

I'd like to hear your opinion on that. I have also found a thread on 
package development workflow 
(https://stat.ethz.ch/pipermail/r-devel/2011-September/061955.html) but 
there was nothing on un-versioning .Rd files.


Cheers

Kirill


From csardi.gabor at gmail.com  Thu Dec 12 02:21:18 2013
From: csardi.gabor at gmail.com (=?ISO-8859-1?B?R+Fib3IgQ3PhcmRp?=)
Date: Wed, 11 Dec 2013 20:21:18 -0500
Subject: [Rd] Strategies for keeping autogenerated .Rd files out of a
	Git tree
In-Reply-To: <52A905CB.4020701@ivt.baug.ethz.ch>
References: <52A905CB.4020701@ivt.baug.ethz.ch>
Message-ID: <CABtg=KkgGqaQOYSfzAnXfdgfK0UojLEjsd=amzc=BThS4EV7+w@mail.gmail.com>

Hi,

this is maybe mostly a personal preference, but I prefer not to put
generated files in the vc repository. Changes in the generated files,
especially if there is many of them, pollute the diffs and make them
less useful.

If you really want to be able to install the package directly from
github, one solution is to
1. create another repository, that contains the complete generated
package, so that install_github() can install it.
2. set up a CI service, that can download the package from github,
build the package or the generated files (check the package, while it
is at it), and then push the build stuff back to github.
3. set up a hook on github, that invokes the CI after each commit.

I have used this setup in various projects with jenkins-ci and it
works well. Diffs are clean, the package is checked and built
frequently, and people can download it without having to install the
tools that generate the generated files.

The only downside is that you need to install a CI, so you need a
"server" for that. Maybe you can do this with travis-ci, maybe not, I
am not familiar with it that much.

Best,
Gabor

On Wed, Dec 11, 2013 at 7:39 PM, Kirill M?ller
<kirill.mueller at ivt.baug.ethz.ch> wrote:
> Hi
>
> Quite a few R packages are now available on GitHub long before they appear
> on CRAN, installation is simple thanks to devtools::install_github().
> However, it seems to be common practice to keep the .Rd files (and NAMESPACE
> and the Collate section in the DESCRIPTION) in the Git tree, and to manually
> update it, even if they are autogenerated from the R code by roxygen2. This
> requires extra work for each update of the documentation and also binds
> package development to a specific version of roxygen2 (because otherwise
> lots of bogus changes can be added by roxygenizing with a different
> version).
>
> What options are there to generate the .Rd files during build/install? In
> https://github.com/hadley/devtools/issues/43 the issue has been discussed,
> perhaps it can be summarized as follows:
>
> - The devtools package is not the right place to implement
> roxygenize-before-build
> - A continuous integration service would be better for that, but currently
> there's nothing that would be easy to use
> - Roxygenizing via src/Makefile could work but requires further
> investigation and an installation of Rtools/xcode on Windows/OS X
>
> Especially the last point looks interesting to me, but since this is not
> widely used there must be pitfalls I'm not aware of. The general idea would
> be:
>
> - Place code that builds/updates the .Rd and NAMESPACE files into
> src/Makefile
> - Users installing the package from source will require infrastructure
> (Rtools/make)
> - For binary packages, the .Rd files are already generated and added to the
> .tar.gz during R CMD build before they are submitted to CRAN/WinBuilder, and
> they are also generated (in theory) by R CMD build --binary
>
> I'd like to hear your opinion on that. I have also found a thread on package
> development workflow
> (https://stat.ethz.ch/pipermail/r-devel/2011-September/061955.html) but
> there was nothing on un-versioning .Rd files.
>
>
> Cheers
>
> Kirill
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From htl10 at users.sourceforge.net  Thu Dec 12 04:30:31 2013
From: htl10 at users.sourceforge.net (Hin-Tak Leung)
Date: Thu, 12 Dec 2013 03:30:31 +0000
Subject: [Rd] freetype 2.5.2, problem with the survival package,
 build R 2.15.x with gcc 4.8.x
In-Reply-To: <52948B3C.8020801@users.sourceforge.net>
References: <1371134413.44971.YahooMailClassic@web172306.mail.ir2.yahoo.com>
	<5225B120.8050406@users.sourceforge.net>
	<52948B3C.8020801@users.sourceforge.net>
Message-ID: <52A92DD7.2050905@users.sourceforge.net>

Here is a rather long discussion etc about freetype 2.5.2, problem with the 
survival package, and build R 2.15.x with gcc 4.8.x. Please feel free to skip 
forward.

- freetype 2.5.2:

the fix to cope with one of the Mac OS X's system fonts just before the release 
of freetype 2.5.1 caused a regression, crashing over one of Microsoft windows' 
system fonts. So there is a 2.5.2. There are new 2.5.2 bundles for windows & Mac 
OS X. The official win/mac binaries of R were built statically with 2+-years-old 
freetype with a few known problems. Most should upgrade/rebuild.

http://sourceforge.net/projects/outmodedbonsai/files/R/

- problem with the survival package:

Trying to re-run a vignette to get the same result as two years ago
reveal a strange change. I went and bisected it down to
r11513 and r11516 of the survival package.

-------------- r11513 --------------------
clogit(cc ~ addContr(A) + addContr(C) + addContr(A.C) + strata(set))


                    coef exp(coef) se(coef)     z      p
addContr(A)2     -0.620     0.538    0.217 -2.86 0.0043
addContr(C)2      0.482     1.620    0.217  2.22 0.0270
addContr(A.C)1-2 -0.778     0.459    0.275 -2.83 0.0047
addContr(A.C)2-1     NA        NA    0.000    NA     NA
addContr(A.C)2-2     NA        NA    0.000    NA     NA

Likelihood ratio test=26  on 3 df, p=9.49e-06  n= 13110, number of events= 3524
------------------------------------------

------------- r11516 ---------------------
clogit(cc ~ addContr(A) + addContr(C) + addContr(A.C) + strata(set))


                      coef exp(coef) se(coef)         z  p
addContr(A)2     -0.14250     0.867   110812 -1.29e-06  1
addContr(C)2      0.00525     1.005   110812  4.74e-08  1
addContr(A.C)1-2 -0.30097     0.740   110812 -2.72e-06  1
addContr(A.C)2-1 -0.47712     0.621   110812 -4.31e-06  1
addContr(A.C)2-2       NA        NA        0        NA NA

Likelihood ratio test=26  on 4 df, p=3.15e-05  n= 13110, number of events= 3524
------------------------------------------

r11514 does not build, and r11515 have serious memory hogs, so the survival
package broke somewhere between r11513 and r11516. Anyway, here is the diff in
the vignette, and the data, etc is in the directory above. If somebody want to
fix this before I spend any more time on this particular matter, please feel 
free to do so.

http://sourceforge.net/projects/outmodedbonsai/files/Manuals%2C%20Overviews%20and%20Slides%20for%20talks/2013SummerCourse/practicals/with-answers/practical8_survival-clogit-diff.pdf/download

That's the one problem from David's 10 practicals which are not due to bugs in 
snpStats. Some might find it reassuring that only 3 of the 4 problems with the 
practicals are due to snpStats bugs.

http://sourceforge.net/projects/outmodedbonsai/files/Manuals%2C%20Overviews%20and%20Slides%20for%20talks/2013SummerCourse/practicals/with-answers/practical7_snpStatsBug-diff.pdf/download
http://sourceforge.net/projects/outmodedbonsai/files/Manuals%2C%20Overviews%20and%20Slides%20for%20talks/2013SummerCourse/practicals/with-answers/practical6_snpStatsBug-diff.pdf/download
http://sourceforge.net/projects/outmodedbonsai/files/Manuals%2C%20Overviews%20and%20Slides%20for%20talks/2013SummerCourse/practicals/with-answers/practical3_snpStatsBug-diff.pdf/download

- build R 2.15.x with gcc 4.8.x

I wish the R commit log was a bit more detailed with r62430 than just
"tweak needed for gcc 4.8.x". Anyway, building R 2.15.x with gcc 4.8.x
could result in segfaults in usage as innocent and essential
as running summary() on a data.frame:

--------------------------------
  *** caught segfault ***
address 0x2f8e6a00, cause 'memory not mapped'

Traceback:
  1: sort.list(y)
  2: factor(a, exclude = exclude)
  3: table(object, exclude = NULL)
  4: summary.default(X[[3L]], ...)
  5: FUN(X[[3L]], ...)
  6: lapply(X = as.list(object), FUN = summary, maxsum = maxsum, digits = 12, 
   ...)
  7: summary.data.frame(support)
...
--------------------------------

r62430 needs a bit of adapting to apply to R 2.15.x , but you get the idea.
I hope this info is useful to somebody else who is still using R 2.15.x , no 
doubt for very good reasons.

Hin-Tak Leung wrote:
> The freetype people fixed the 2nd set of issues with system fonts shipped with
> Mac OS X, and released 2.5.1 almost immediately after that. So there are
> new bundles under http://sourceforge.net/projects/outmodedbonsai/files/R/ .
>
> Just a reminder that the official R binaries for windows/mac OS X are statically
> linked with rather dated versions of freetype with a few known issues. This
> affects the cairo-based functionalities in R. So a rebuild is needed.
>
> Most unix users should just upgrade their system's libfreetype, and
> dynamic-linking should take care of the rest.


From djsamperi at gmail.com  Thu Dec 12 08:12:41 2013
From: djsamperi at gmail.com (Dominick Samperi)
Date: Thu, 12 Dec 2013 02:12:41 -0500
Subject: [Rd] R CMD INSTALL may create invalid DLL under Windows
Message-ID: <CADUbQ5i2depWPQKik2jrTPk5JxjH+CN9P0jQaR-w+JS7R-FeRw@mail.gmail.com>

Under Windows the make include share/make/winshlib.mk
uses nm to grab symbols from object files to insert into a
module definition file tmp.def that is used to create a
package DLL. This works fine provided the DLL is only
used via exported function entry points, which is the case
currently, I suspect.

But the pattern SYMPAT (defined in Makeconf) used to
capture symbols includes non-function symbols of
type's BCDR, not just T (.text or code). These symbols
need to be flagged in the module definition file by adding
the string DATA after the symbol name. If this is not done
then a client of this DLL (another DLL or a main
program) will not be able to import these variables
correctly (using dllexport/dllimport decorations is
another less convenient strategy).

I have checked this with gcc 4.6.3 (shipped with Rtools),
and also with gcc 4.8.1 (MinGW). In both cases if the
value of a simple 'int' is fetched from a DLL where the
int is exported without the DATA keyword, the result
is garbage, and inserting the DATA keyword fixes the
problem.

Thus the fix here is very simple. Just modify winshlib.mk
so that the DATA flag follows non-function symbols.
Alternatively, only function symbols can be captured, in
which case only SYMPAT needs to change.

Dominick


From kmillar at google.com  Thu Dec 12 20:08:18 2013
From: kmillar at google.com (Karl Millar)
Date: Thu, 12 Dec 2013 11:08:18 -0800
Subject: [Rd] Status of reserved keywords and builtins
Message-ID: <CABz6aZeTjummNsA4cKBBf3MiZQLLvjHtnmAkSQJi+LoQ4ZXY8Q@mail.gmail.com>

According to http://cran.r-project.org/doc/manuals/r-release/R-lang.html#Reserved-words

  if else repeat while function for in next break
  TRUE FALSE NULL Inf NaN
  NA NA_integer_ NA_real_ NA_complex_ NA_character_
  ... ..1 ..2 etc.

are all reserved keywords.


However, in R 3.0.2 you can do things like:
   `if` <- function(cond, val1, val2) val2
after which
   if(TRUE) 1 else 2
returns 2.

Similarly, users can change the implementation of `<-`, `(`, `{`, `||` and `&&`.


Two questions:
  - Is this intended behaviour?

  - If so, would it be a good idea to change the language definition
to prevent this?  Doing so would both have the benefits that users
could count on keywords having their normal interpretation, and allow
R implementations to implement these more efficiently, including not
having to lookup the symbol each time.  It'd break any code that
assumes that this is valid, but hopefully there's little or no code
that does.

Thanks

Karl


From murdoch.duncan at gmail.com  Thu Dec 12 21:22:45 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 12 Dec 2013 15:22:45 -0500
Subject: [Rd] Status of reserved keywords and builtins
In-Reply-To: <CABz6aZeTjummNsA4cKBBf3MiZQLLvjHtnmAkSQJi+LoQ4ZXY8Q@mail.gmail.com>
References: <CABz6aZeTjummNsA4cKBBf3MiZQLLvjHtnmAkSQJi+LoQ4ZXY8Q@mail.gmail.com>
Message-ID: <52AA1B15.6020509@gmail.com>

On 12/12/2013 2:08 PM, Karl Millar wrote:
> According to http://cran.r-project.org/doc/manuals/r-release/R-lang.html#Reserved-words
>
>    if else repeat while function for in next break
>    TRUE FALSE NULL Inf NaN
>    NA NA_integer_ NA_real_ NA_complex_ NA_character_
>    ... ..1 ..2 etc.
>
> are all reserved keywords.
>
>
> However, in R 3.0.2 you can do things like:
>     `if` <- function(cond, val1, val2) val2
> after which
>     if(TRUE) 1 else 2
> returns 2.
>
> Similarly, users can change the implementation of `<-`, `(`, `{`, `||` and `&&`.
>
>
> Two questions:
>    - Is this intended behaviour?

I would say yes.
>
>    - If so, would it be a good idea to change the language definition
> to prevent this?

I would say not.  In the case of "if", what sophisticated users would 
expect to happen from

  if (TRUE) 1 else 2

is that the `if` function will be called with arguments TRUE, 1, 2.

> Doing so would both have the benefits that users
> could count on keywords having their normal interpretation, and allow
> R implementations to implement these more efficiently, including not
> having to lookup the symbol each time.  It'd break any code that
> assumes that this is valid, but hopefully there's little or no code
> that does.
>

It would have those benefits, but it would be harder to prototype 
changes by actually replacing the `if` function.  Implementations that 
want to optimize the calls have other ways to do it, e.g. the sorts of 
things the compiler does.

Duncan Murdoch


From romain at r-enthusiasts.com  Thu Dec 12 21:32:59 2013
From: romain at r-enthusiasts.com (=?windows-1252?Q?Romain_Fran=E7ois?=)
Date: Thu, 12 Dec 2013 21:32:59 +0100
Subject: [Rd] internal manipulation of ...
Message-ID: <EDC77346-95D8-4562-A49C-889109F5DF92@r-enthusiasts.com>

Hello, 

I?m looking for examples on how to manipulate the ... internally, e.g. in a .Call or .External function. 

I?m particularly interested in accessing the environment in which each contribution to ... can be evaluated. 

So far, I?m using tricks involving passing down the sys.calls() and sys.frames() down to the C function. The documentation in http://cran.r-project.org/doc/manuals/R-ints.html#Dot_002ddot_002ddot-arguments did not help me a lot. 

Romain

From simon.urbanek at r-project.org  Fri Dec 13 00:15:21 2013
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Thu, 12 Dec 2013 18:15:21 -0500
Subject: [Rd] internal manipulation of ...
In-Reply-To: <EDC77346-95D8-4562-A49C-889109F5DF92@r-enthusiasts.com>
References: <EDC77346-95D8-4562-A49C-889109F5DF92@r-enthusiasts.com>
Message-ID: <25A6CE5E-D2FC-409D-8AD8-BAE87EAD68C5@r-project.org>


On Dec 12, 2013, at 3:32 PM, Romain Fran?ois <romain at r-enthusiasts.com> wrote:

> Hello, 
> 
> I?m looking for examples on how to manipulate the ... internally, e.g. in a .Call or .External function. 
> 
> I?m particularly interested in accessing the environment in which each contribution to ... can be evaluated. 
> 

Arguments in ... are evaluated *before* being passed down to .Call/.External so there is no ... by the time you enter the C code. AFAIR R doesn't allow you to get at the promises outside of internal code, so you either get the call or the values, but nothing in between.

Cheers,
Simon



> So far, I?m using tricks involving passing down the sys.calls() and sys.frames() down to the C function. The documentation in http://cran.r-project.org/doc/manuals/R-ints.html#Dot_002ddot_002ddot-arguments did not help me a lot. 
> 
> Romain
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 


From romain at r-enthusiasts.com  Fri Dec 13 00:18:54 2013
From: romain at r-enthusiasts.com (=?windows-1252?Q?Romain_Fran=E7ois?=)
Date: Fri, 13 Dec 2013 00:18:54 +0100
Subject: [Rd] internal manipulation of ...
In-Reply-To: <25A6CE5E-D2FC-409D-8AD8-BAE87EAD68C5@r-project.org>
References: <EDC77346-95D8-4562-A49C-889109F5DF92@r-enthusiasts.com>
	<25A6CE5E-D2FC-409D-8AD8-BAE87EAD68C5@r-project.org>
Message-ID: <91773308-D979-42D4-9450-D4BA6518F1DC@r-enthusiasts.com>


Le 13 d?c. 2013 ? 00:15, Simon Urbanek <simon.urbanek at r-project.org> a ?crit :

> 
> On Dec 12, 2013, at 3:32 PM, Romain Fran?ois <romain at r-enthusiasts.com> wrote:
> 
>> Hello, 
>> 
>> I?m looking for examples on how to manipulate the ... internally, e.g. in a .Call or .External function. 
>> 
>> I?m particularly interested in accessing the environment in which each contribution to ... can be evaluated. 
>> 
> 
> Arguments in ... are evaluated *before* being passed down to .Call/.External so there is no ... by the time you enter the C code. AFAIR R doesn't allow you to get at the promises outside of internal code, so you either get the call or the values, but nothing in between.
> 
> Cheers,
> Simon

Thanks. That confirms what I feared. 
Back at low level manipulation of call stack and frame stack then. :/

Romain

From h.wickham at gmail.com  Fri Dec 13 01:09:04 2013
From: h.wickham at gmail.com (Hadley Wickham)
Date: Thu, 12 Dec 2013 18:09:04 -0600
Subject: [Rd] internal manipulation of ...
In-Reply-To: <EDC77346-95D8-4562-A49C-889109F5DF92@r-enthusiasts.com>
References: <EDC77346-95D8-4562-A49C-889109F5DF92@r-enthusiasts.com>
Message-ID: <CABdHhvE_TodiJp5pzBYWdQKn3QuKHSwJ62xwun2-cG3tX04EKQ@mail.gmail.com>

Could you pass the environment and then look for the object called ... in it?

f <- function(...) {
  .Call("my_fun", environment())
}

I think (and may well be wrong) that you can use standard tools to
find the DOTSXP object in that environment.

Hadley


On Thu, Dec 12, 2013 at 2:32 PM, Romain Fran?ois
<romain at r-enthusiasts.com> wrote:
> Hello,
>
> I?m looking for examples on how to manipulate the ... internally, e.g. in a .Call or .External function.
>
> I?m particularly interested in accessing the environment in which each contribution to ... can be evaluated.
>
> So far, I?m using tricks involving passing down the sys.calls() and sys.frames() down to the C function. The documentation in http://cran.r-project.org/doc/manuals/R-ints.html#Dot_002ddot_002ddot-arguments did not help me a lot.
>
> Romain
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel



-- 
http://had.co.nz/


From murdoch.duncan at gmail.com  Fri Dec 13 01:18:09 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 12 Dec 2013 19:18:09 -0500
Subject: [Rd] Status of reserved keywords and builtins
In-Reply-To: <52AA1B15.6020509@gmail.com>
References: <CABz6aZeTjummNsA4cKBBf3MiZQLLvjHtnmAkSQJi+LoQ4ZXY8Q@mail.gmail.com>
	<52AA1B15.6020509@gmail.com>
Message-ID: <52AA5241.5000403@gmail.com>

On 13-12-12 3:22 PM, Duncan Murdoch wrote:
> On 12/12/2013 2:08 PM, Karl Millar wrote:
>> According to http://cran.r-project.org/doc/manuals/r-release/R-lang.html#Reserved-words
>>
>>     if else repeat while function for in next break
>>     TRUE FALSE NULL Inf NaN
>>     NA NA_integer_ NA_real_ NA_complex_ NA_character_
>>     ... ..1 ..2 etc.
>>
>> are all reserved keywords.
>>
>>
>> However, in R 3.0.2 you can do things like:
>>      `if` <- function(cond, val1, val2) val2
>> after which
>>      if(TRUE) 1 else 2
>> returns 2.
>>
>> Similarly, users can change the implementation of `<-`, `(`, `{`, `||` and `&&`.
>>
>>
>> Two questions:
>>     - Is this intended behaviour?
>
> I would say yes.
>>
>>     - If so, would it be a good idea to change the language definition
>> to prevent this?
>
> I would say not.  In the case of "if", what sophisticated users would
> expect to happen from
>
>    if (TRUE) 1 else 2
>
> is that the `if` function will be called with arguments TRUE, 1, 2.
>
>> Doing so would both have the benefits that users
>> could count on keywords having their normal interpretation, and allow
>> R implementations to implement these more efficiently, including not
>> having to lookup the symbol each time.  It'd break any code that
>> assumes that this is valid, but hopefully there's little or no code
>> that does.
>>
>
> It would have those benefits, but it would be harder to prototype
> changes by actually replacing the `if` function.  Implementations that
> want to optimize the calls have other ways to do it, e.g. the sorts of
> things the compiler does.

One other comment:

A package could replace `if` for the user, but it would not affect any 
packages, unless those packages chose to import the new definition.  So 
this is a risk to people who write lots of code in scripts and 
indiscriminately attach packages, but not much risk to people who put 
their code in packages and are careful about what they import.  And 
those people with the scripts are already at risk due to changes to 
functions like mean(), sum(), c(), etc.  So they shouldn't do that. 
That's been the standard advice for a long time...

Duncan Murdoch


From hb at biostat.ucsf.edu  Fri Dec 13 01:57:34 2013
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Thu, 12 Dec 2013 16:57:34 -0800
Subject: [Rd] Proper way to drop 'srcref' from an expression created via
 substitute(function() ...)?
Message-ID: <CAFDcVCRe7SF5bb_mWkOgXD4jB4iZ7sYUzCKvYqUBb0qYmM=wOA@mail.gmail.com>

First, why does this expression have a 'srcref' element:

> exprA <- substitute(function(x) a*x, list(a=2))
> print(exprA)
function(x) 2 * x
> str(as.list(exprA))
List of 4
 $ : symbol function
 $ :Dotted pair list of 1
  ..$ x: symbol
 $ : language 2 * x
 $ :Class 'srcref'  atomic [1:8] 1 20 1 34 20 34 1 1
  .. ..- attr(*, "srcfile")=Classes 'srcfilecopy', 'srcfile'
<environment: 0x00000000111feaf8>

whereas this does not:

> exprB <- substitute(a*x, list(a=2))
> print(exprB)
2 * x
> str(as.list(exprB))
List of 3
 $ : symbol *
 $ : num 2
 $ : symbol x


Second, what is the proper way to drop that 'srcref' element in
'exprA'?  I can think of either

exprC <- exprA
exprC[[4L]] <- NULL

or

exprC <- parse(text=deparse(exprA))

Anything better/safer?


BACKGROUND:
The reason for this is that I wish to create a function dynamically
via variable substitution such that when printed, the function
displays the substituted values, e.g.

> fcnA <- eval(exprA)
> print(fcnA)
function(x) a*x

versus

> fcnC <- eval(exprC)
> print(fcnC)
function(x) 2 * x

Thanks,

Henrik


From murdoch.duncan at gmail.com  Fri Dec 13 02:27:59 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 12 Dec 2013 20:27:59 -0500
Subject: [Rd] Proper way to drop 'srcref' from an expression created via
 substitute(function() ...)?
In-Reply-To: <CAFDcVCRe7SF5bb_mWkOgXD4jB4iZ7sYUzCKvYqUBb0qYmM=wOA@mail.gmail.com>
References: <CAFDcVCRe7SF5bb_mWkOgXD4jB4iZ7sYUzCKvYqUBb0qYmM=wOA@mail.gmail.com>
Message-ID: <52AA629F.3080500@gmail.com>

On 13-12-12 7:57 PM, Henrik Bengtsson wrote:
> First, why does this expression have a 'srcref' element:
>
>> exprA <- substitute(function(x) a*x, list(a=2))
>> print(exprA)
> function(x) 2 * x
>> str(as.list(exprA))
> List of 4
>   $ : symbol function
>   $ :Dotted pair list of 1
>    ..$ x: symbol
>   $ : language 2 * x
>   $ :Class 'srcref'  atomic [1:8] 1 20 1 34 20 34 1 1
>    .. ..- attr(*, "srcfile")=Classes 'srcfilecopy', 'srcfile'
> <environment: 0x00000000111feaf8>
>
> whereas this does not:
>
>> exprB <- substitute(a*x, list(a=2))
>> print(exprB)
> 2 * x
>> str(as.list(exprB))
> List of 3
>   $ : symbol *
>   $ : num 2
>   $ : symbol x
>

Function definitions get srcrefs.

>
> Second, what is the proper way to drop that 'srcref' element in
> 'exprA'?  I can think of either
>
> exprC <- exprA
> exprC[[4L]] <- NULL

That should be best.

Duncan Murdoch

>
> or
>
> exprC <- parse(text=deparse(exprA))
>
> Anything better/safer?
>
>
> BACKGROUND:
> The reason for this is that I wish to create a function dynamically
> via variable substitution such that when printed, the function
> displays the substituted values, e.g.
>
>> fcnA <- eval(exprA)
>> print(fcnA)
> function(x) a*x
>
> versus
>
>> fcnC <- eval(exprC)
>> print(fcnC)
> function(x) 2 * x
>
> Thanks,
>
> Henrik
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From hb at biostat.ucsf.edu  Fri Dec 13 02:30:21 2013
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Thu, 12 Dec 2013 17:30:21 -0800
Subject: [Rd] Proper way to drop 'srcref' from an expression created via
 substitute(function() ...)?
In-Reply-To: <52AA629F.3080500@gmail.com>
References: <CAFDcVCRe7SF5bb_mWkOgXD4jB4iZ7sYUzCKvYqUBb0qYmM=wOA@mail.gmail.com>
	<52AA629F.3080500@gmail.com>
Message-ID: <CAFDcVCT+0_UDMcorteNJPv=0DSH2+W-dh8DqPNA2DMfU-p8Dzw@mail.gmail.com>

Thanks. /Henrik

On Thu, Dec 12, 2013 at 5:27 PM, Duncan Murdoch
<murdoch.duncan at gmail.com> wrote:
> On 13-12-12 7:57 PM, Henrik Bengtsson wrote:
>>
>> First, why does this expression have a 'srcref' element:
>>
>>> exprA <- substitute(function(x) a*x, list(a=2))
>>> print(exprA)
>>
>> function(x) 2 * x
>>>
>>> str(as.list(exprA))
>>
>> List of 4
>>   $ : symbol function
>>   $ :Dotted pair list of 1
>>    ..$ x: symbol
>>   $ : language 2 * x
>>   $ :Class 'srcref'  atomic [1:8] 1 20 1 34 20 34 1 1
>>    .. ..- attr(*, "srcfile")=Classes 'srcfilecopy', 'srcfile'
>> <environment: 0x00000000111feaf8>
>>
>> whereas this does not:
>>
>>> exprB <- substitute(a*x, list(a=2))
>>> print(exprB)
>>
>> 2 * x
>>>
>>> str(as.list(exprB))
>>
>> List of 3
>>   $ : symbol *
>>   $ : num 2
>>   $ : symbol x
>>
>
> Function definitions get srcrefs.
>
>
>>
>> Second, what is the proper way to drop that 'srcref' element in
>> 'exprA'?  I can think of either
>>
>> exprC <- exprA
>> exprC[[4L]] <- NULL
>
>
> That should be best.
>
> Duncan Murdoch
>
>>
>> or
>>
>> exprC <- parse(text=deparse(exprA))
>>
>> Anything better/safer?
>>
>>
>> BACKGROUND:
>> The reason for this is that I wish to create a function dynamically
>> via variable substitution such that when printed, the function
>> displays the substituted values, e.g.
>>
>>> fcnA <- eval(exprA)
>>> print(fcnA)
>>
>> function(x) a*x
>>
>> versus
>>
>>> fcnC <- eval(exprC)
>>> print(fcnC)
>>
>> function(x) 2 * x
>>
>> Thanks,
>>
>> Henrik
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>


From hpages at fhcrc.org  Fri Dec 13 10:07:41 2013
From: hpages at fhcrc.org (=?windows-1252?Q?Herv=E9_Pag=E8s?=)
Date: Fri, 13 Dec 2013 01:07:41 -0800
Subject: [Rd] substring() and propagation of names
Message-ID: <52AACE5D.2040409@fhcrc.org>

Hi,

In R < 3.0.0, we used to get:

   > substring(c(A="abcdefghij", B="123456789"), 2, 6:2)
         A       B       A       B       A
   "bcdef"  "2345"   "bcd"    "23"     "b"

But in R >= 3.0.0, we get:

   > substring(c(A="abcdefghij", B="123456789"), 2, 6:2)
   [1] "bcdef" "2345"  "bcd"   "23"    "b"

The names are not propagated anymore.

Is this an intended change or a bug? I can't find anything about
this in the NEWS file. The man page for substring() in R >= 3.0.0
still states:

   Value:

      ...

      For ?substring?, a character vector of length the longest of the
      arguments.  This will have names taken from ?x? (if it has any
      after coercion, repeated as needed), and other attributes copied
      from ?x? if it is the longest of the arguments).

Also note that the first argument of substring() is 'text' not 'x'.

Thanks,
H.

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fhcrc.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From kirill.mueller at ivt.baug.ethz.ch  Fri Dec 13 12:03:44 2013
From: kirill.mueller at ivt.baug.ethz.ch (=?ISO-8859-1?Q?Kirill_M=FCller?=)
Date: Fri, 13 Dec 2013 12:03:44 +0100
Subject: [Rd] Strategies for keeping autogenerated .Rd files out of a
 Git tree
In-Reply-To: <CABtg=KkgGqaQOYSfzAnXfdgfK0UojLEjsd=amzc=BThS4EV7+w@mail.gmail.com>
References: <52A905CB.4020701@ivt.baug.ethz.ch>
	<CABtg=KkgGqaQOYSfzAnXfdgfK0UojLEjsd=amzc=BThS4EV7+w@mail.gmail.com>
Message-ID: <52AAE990.1050102@ivt.baug.ethz.ch>

Gabor

I agree with you. There's Travis CI, and r-travis -- an attempt to 
integrate R package testing with Travis. Pushing back to GitHub is 
possible, but the setup is somewhat difficult. Also, this can be subject 
to race conditions because each push triggers a test run and they can 
happen in parallel even for the same repository. How do you handle branches?

It would be really great to be able to execute custom R code before 
building. Perhaps in a PreBuild: section in DESCRIPTION?


Cheers

Kirill



On 12/12/2013 02:21 AM, G?bor Cs?rdi wrote:
> Hi,
>
> this is maybe mostly a personal preference, but I prefer not to put
> generated files in the vc repository. Changes in the generated files,
> especially if there is many of them, pollute the diffs and make them
> less useful.
>
> If you really want to be able to install the package directly from
> github, one solution is to
> 1. create another repository, that contains the complete generated
> package, so that install_github() can install it.
> 2. set up a CI service, that can download the package from github,
> build the package or the generated files (check the package, while it
> is at it), and then push the build stuff back to github.
> 3. set up a hook on github, that invokes the CI after each commit.
>
> I have used this setup in various projects with jenkins-ci and it
> works well. Diffs are clean, the package is checked and built
> frequently, and people can download it without having to install the
> tools that generate the generated files.
>
> The only downside is that you need to install a CI, so you need a
> "server" for that. Maybe you can do this with travis-ci, maybe not, I
> am not familiar with it that much.
>
> Best,
> Gabor
>
> On Wed, Dec 11, 2013 at 7:39 PM, Kirill M?ller
> <kirill.mueller at ivt.baug.ethz.ch> wrote:
>> Hi
>>
>> Quite a few R packages are now available on GitHub long before they appear
>> on CRAN, installation is simple thanks to devtools::install_github().
>> However, it seems to be common practice to keep the .Rd files (and NAMESPACE
>> and the Collate section in the DESCRIPTION) in the Git tree, and to manually
>> update it, even if they are autogenerated from the R code by roxygen2. This
>> requires extra work for each update of the documentation and also binds
>> package development to a specific version of roxygen2 (because otherwise
>> lots of bogus changes can be added by roxygenizing with a different
>> version).
>>
>> What options are there to generate the .Rd files during build/install? In
>> https://github.com/hadley/devtools/issues/43 the issue has been discussed,
>> perhaps it can be summarized as follows:
>>
>> - The devtools package is not the right place to implement
>> roxygenize-before-build
>> - A continuous integration service would be better for that, but currently
>> there's nothing that would be easy to use
>> - Roxygenizing via src/Makefile could work but requires further
>> investigation and an installation of Rtools/xcode on Windows/OS X
>>
>> Especially the last point looks interesting to me, but since this is not
>> widely used there must be pitfalls I'm not aware of. The general idea would
>> be:
>>
>> - Place code that builds/updates the .Rd and NAMESPACE files into
>> src/Makefile
>> - Users installing the package from source will require infrastructure
>> (Rtools/make)
>> - For binary packages, the .Rd files are already generated and added to the
>> .tar.gz during R CMD build before they are submitted to CRAN/WinBuilder, and
>> they are also generated (in theory) by R CMD build --binary
>>
>> I'd like to hear your opinion on that. I have also found a thread on package
>> development workflow
>> (https://stat.ethz.ch/pipermail/r-devel/2011-September/061955.html) but
>> there was nothing on un-versioning .Rd files.
>>
>>
>> Cheers
>>
>> Kirill
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
_________________________________________________
ETH Z?rich
Institute for Transport Planning and Systems
HIL F 32.2
Wolfgang-Pauli-Str. 15
8093 Z?rich

Phone:       +41 44 633 33 17
Fax:         +41 44 633 10 57
Secretariat: +41 44 633 31 05
E-Mail:      kirill.mueller at ivt.baug.ethz.ch


From romain at r-enthusiasts.com  Fri Dec 13 12:50:34 2013
From: romain at r-enthusiasts.com (Romain Francois)
Date: Fri, 13 Dec 2013 12:50:34 +0100
Subject: [Rd] Strategies for keeping autogenerated .Rd files out of a
	Git tree
In-Reply-To: <52AAE990.1050102@ivt.baug.ethz.ch>
References: <52A905CB.4020701@ivt.baug.ethz.ch>
	<CABtg=KkgGqaQOYSfzAnXfdgfK0UojLEjsd=amzc=BThS4EV7+w@mail.gmail.com>
	<52AAE990.1050102@ivt.baug.ethz.ch>
Message-ID: <175312B6-9672-4C71-AB2F-AFA05A06162C@r-enthusiasts.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20131213/97cb6133/attachment.pl>

From justintalbot at gmail.com  Fri Dec 13 14:36:58 2013
From: justintalbot at gmail.com (Justin Talbot)
Date: Fri, 13 Dec 2013 05:36:58 -0800
Subject: [Rd] Status of reserved keywords and builtins
Message-ID: <CALLn38MY7tqe=fMCJf9qk5Y3itoniFSZKgN14cDBZoqZcUuYiA@mail.gmail.com>

>
> It would have those benefits, but it would be harder to prototype
> changes by actually replacing the `if` function.  Implementations that
> want to optimize the calls have other ways to do it, e.g. the sorts of
> things the compiler does.
>

Does anyone actually prototype changes to the `if` function?

Allowing users to replace the definitions of reserved keywords and
builtins is horribly expensive performance-wise with or without
compilation. If you look at the compiler package, the way it optimizes
these function calls is by breaking the language spec. See the
beginnings of sections 5 and 6 of Luke's write up
(http://homepage.stat.uiowa.edu/~luke/R/compiler/compiler.pdf), noting
that the *default* optimization level is 2, at which level, "In
addition to the inlining permitted by Level 1, functions that are
syntactically special or are considered core language functions and
are found via the global environment at compile time may be inlined."

This is an area where a small change to the language spec would impact
essentially no users and would result in a language that could be
executed much more efficiently.

Justin Talbot


From kirill.mueller at ivt.baug.ethz.ch  Fri Dec 13 14:51:43 2013
From: kirill.mueller at ivt.baug.ethz.ch (=?UTF-8?B?S2lyaWxsIE3DvGxsZXI=?=)
Date: Fri, 13 Dec 2013 14:51:43 +0100
Subject: [Rd] Strategies for keeping autogenerated .Rd files out of a
 Git tree
In-Reply-To: <175312B6-9672-4C71-AB2F-AFA05A06162C@r-enthusiasts.com>
References: <52A905CB.4020701@ivt.baug.ethz.ch>
	<CABtg=KkgGqaQOYSfzAnXfdgfK0UojLEjsd=amzc=BThS4EV7+w@mail.gmail.com>
	<52AAE990.1050102@ivt.baug.ethz.ch>
	<175312B6-9672-4C71-AB2F-AFA05A06162C@r-enthusiasts.com>
Message-ID: <52AB10EF.9070503@ivt.baug.ethz.ch>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20131213/9cea53f0/attachment.pl>

From h.wickham at gmail.com  Fri Dec 13 14:59:24 2013
From: h.wickham at gmail.com (Hadley Wickham)
Date: Fri, 13 Dec 2013 07:59:24 -0600
Subject: [Rd] Status of reserved keywords and builtins
In-Reply-To: <CALLn38MY7tqe=fMCJf9qk5Y3itoniFSZKgN14cDBZoqZcUuYiA@mail.gmail.com>
References: <CALLn38MY7tqe=fMCJf9qk5Y3itoniFSZKgN14cDBZoqZcUuYiA@mail.gmail.com>
Message-ID: <CABdHhvHiNSXcAvJAJwnUqEV=qcdkpr0FLcb9uMwz6CUNhcuz=g@mail.gmail.com>

>> It would have those benefits, but it would be harder to prototype
>> changes by actually replacing the `if` function.  Implementations that
>> want to optimize the calls have other ways to do it, e.g. the sorts of
>> things the compiler does.
>>
>
> Does anyone actually prototype changes to the `if` function?

I do - in the dplyr package (https://github.com/hadley/dplyr), I
construct environments where many of the most common R functions are
replaced by alternates that return SQL strings. This makes it possible
to use R's parser, while translating output into another language. I
think it's a pretty elegant approach that's facilitated by lexical
scoping and first-class environments, but it's an admittedly rare
case.

Hadley

-- 
http://had.co.nz/


From murdoch.duncan at gmail.com  Fri Dec 13 15:14:05 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 13 Dec 2013 09:14:05 -0500
Subject: [Rd] Status of reserved keywords and builtins
In-Reply-To: <CALLn38MY7tqe=fMCJf9qk5Y3itoniFSZKgN14cDBZoqZcUuYiA@mail.gmail.com>
References: <CALLn38MY7tqe=fMCJf9qk5Y3itoniFSZKgN14cDBZoqZcUuYiA@mail.gmail.com>
Message-ID: <52AB162D.2090904@gmail.com>

On 13-12-13 8:36 AM, Justin Talbot wrote:
>>
>> It would have those benefits, but it would be harder to prototype
>> changes by actually replacing the `if` function.  Implementations that
>> want to optimize the calls have other ways to do it, e.g. the sorts of
>> things the compiler does.
>>
>
> Does anyone actually prototype changes to the `if` function?

I don't know of any examples of that, but I can easily imagine someone 
wanting to.  For example, some conditions take a long time to evaluate. 
  Maybe I would want to compute both TRUE and FALSE paths in parallel in 
anticipation of the result, if I have cores to spare.  That's pretty 
tricky to get right because of side effects, so prototyping in R code 
could make a lot of sense.

>
> Allowing users to replace the definitions of reserved keywords and
> builtins is horribly expensive performance-wise with or without
> compilation.  If you look at the compiler package, the way it optimizes
> these function calls is by breaking the language spec. See the
> beginnings of sections 5 and 6 of Luke's write up
> (http://homepage.stat.uiowa.edu/~luke/R/compiler/compiler.pdf), noting
> that the *default* optimization level is 2, at which level, "In
> addition to the inlining permitted by Level 1, functions that are
> syntactically special or are considered core language functions and
> are found via the global environment at compile time may be inlined."
>
> This is an area where a small change to the language spec would impact
> essentially no users and would result in a language that could be
> executed much more efficiently.

That only breaks the language spec if the compiler doesn't detect cases 
where it is an invalid optimization.  It may be that that is currently 
the case (I haven't checked), but it needn't always be.  I would much 
prefer that the compiler code were made smarter about detecting this 
rather than adding exceptions to the language design.

Duncan Murdoch


From dwinsemius at comcast.net  Fri Dec 13 17:20:57 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 13 Dec 2013 08:20:57 -0800
Subject: [Rd] [R] freetype 2.5.2, problem with the survival package,
	build R 2.15.x with gcc 4.8.x
In-Reply-To: <52A92DD7.2050905@users.sourceforge.net>
References: <1371134413.44971.YahooMailClassic@web172306.mail.ir2.yahoo.com>
	<5225B120.8050406@users.sourceforge.net>
	<52948B3C.8020801@users.sourceforge.net>
	<52A92DD7.2050905@users.sourceforge.net>
Message-ID: <DE726C1F-C35B-4072-9C05-8532243AED08@comcast.net>


On Dec 11, 2013, at 7:30 PM, Hin-Tak Leung wrote:

> Here is a rather long discussion etc about freetype 2.5.2, problem with the survival package, and build R 2.15.x with gcc 4.8.x. Please feel free to skip forward.
> 
> - freetype 2.5.2:
> 
> the fix to cope with one of the Mac OS X's system fonts just before the release of freetype 2.5.1 caused a regression, crashing over one of Microsoft windows' system fonts. So there is a 2.5.2. There are new 2.5.2 bundles for windows & Mac OS X. The official win/mac binaries of R were built statically with 2+-years-old freetype with a few known problems. Most should upgrade/rebuild.
> 
> http://sourceforge.net/projects/outmodedbonsai/files/R/
> 
> - problem with the survival package:
> 
> Trying to re-run a vignette to get the same result as two years ago
> reveal a strange change. I went and bisected it down to
> r11513 and r11516 of the survival package.
> 
> -------------- r11513 --------------------
> clogit(cc ~ addContr(A) + addContr(C) + addContr(A.C) + strata(set))
> 
> 
>                   coef exp(coef) se(coef)     z      p
> addContr(A)2     -0.620     0.538    0.217 -2.86 0.0043
> addContr(C)2      0.482     1.620    0.217  2.22 0.0270
> addContr(A.C)1-2 -0.778     0.459    0.275 -2.83 0.0047
> addContr(A.C)2-1     NA        NA    0.000    NA     NA
> addContr(A.C)2-2     NA        NA    0.000    NA     NA
> 
> Likelihood ratio test=26  on 3 df, p=9.49e-06  n= 13110, number of events= 3524
> ------------------------------------------
> 
> ------------- r11516 ---------------------
> clogit(cc ~ addContr(A) + addContr(C) + addContr(A.C) + strata(set))
> 
> 
>                     coef exp(coef) se(coef)         z  p
> addContr(A)2     -0.14250     0.867   110812 -1.29e-06  1
> addContr(C)2      0.00525     1.005   110812  4.74e-08  1
> addContr(A.C)1-2 -0.30097     0.740   110812 -2.72e-06  1
> addContr(A.C)2-1 -0.47712     0.621   110812 -4.31e-06  1
> addContr(A.C)2-2       NA        NA        0        NA NA
> 
> Likelihood ratio test=26  on 4 df, p=3.15e-05  n= 13110, number of events= 3524
> ------------------------------------------
> 
> r11514 does not build, and r11515 have serious memory hogs, so the survival
> package broke somewhere between r11513 and r11516. Anyway, here is the diff in
> the vignette, and the data, etc is in the directory above. If somebody want to
> fix this before I spend any more time on this particular matter, please feel free to do so.
> 
> http://sourceforge.net/projects/outmodedbonsai/files/Manuals%2C%20Overviews%20and%20Slides%20for%20talks/2013SummerCourse/practicals/with-answers/practical8_survival-clogit-diff.pdf/download
> 
> That's the one problem from David's 10 practicals which are not due to bugs in snpStats. Some might find it reassuring that only 3 of the 4 problems with the practicals are due to snpStats bugs.
> 
> http://sourceforge.net/projects/outmodedbonsai/files/Manuals%2C%20Overviews%20and%20Slides%20for%20talks/2013SummerCourse/practicals/with-answers/practical7_snpStatsBug-diff.pdf/download
> http://sourceforge.net/projects/outmodedbonsai/files/Manuals%2C%20Overviews%20and%20Slides%20for%20talks/2013SummerCourse/practicals/with-answers/practical6_snpStatsBug-diff.pdf/download
> http://sourceforge.net/projects/outmodedbonsai/files/Manuals%2C%20Overviews%20and%20Slides%20for%20talks/2013SummerCourse/practicals/with-answers/practical3_snpStatsBug-diff.pdf/download
> 
> - build R 2.15.x with gcc 4.8.x
> 
> I wish the R commit log was a bit more detailed with r62430 than just
> "tweak needed for gcc 4.8.x". Anyway, building R 2.15.x with gcc 4.8.x
> could result in segfaults in usage as innocent and essential
> as running summary() on a data.frame:
> 
> --------------------------------
> *** caught segfault ***
> address 0x2f8e6a00, cause 'memory not mapped'
> 
> Traceback:
> 1: sort.list(y)
> 2: factor(a, exclude = exclude)
> 3: table(object, exclude = NULL)
> 4: summary.default(X[[3L]], ...)
> 5: FUN(X[[3L]], ...)
> 6: lapply(X = as.list(object), FUN = summary, maxsum = maxsum, digits = 12,   ...)
> 7: summary.data.frame(support)
> ...
> --------------------------------
> 
> r62430 needs a bit of adapting to apply to R 2.15.x , but you get the idea.
> I hope this info is useful to somebody else who is still using R 2.15.x , no doubt for very good reasons.
> 
> Hin-Tak Leung wrote:
>> The freetype people fixed the 2nd set of issues with system fonts shipped with
>> Mac OS X, and released 2.5.1 almost immediately after that. So there are
>> new bundles under http://sourceforge.net/projects/outmodedbonsai/files/R/ .
>> 
>> Just a reminder that the official R binaries for windows/mac OS X are statically
>> linked with rather dated versions of freetype with a few known issues. This
>> affects the cairo-based functionalities in R. So a rebuild is needed.
>> 
>> Most unix users should just upgrade their system's libfreetype, and
>> dynamic-linking should take care of the rest.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Fri Dec 13 17:29:41 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 13 Dec 2013 08:29:41 -0800
Subject: [Rd] [R] freetype 2.5.2, problem with the survival package,
	build R 2.15.x with gcc 4.8.x
In-Reply-To: <52A92DD7.2050905@users.sourceforge.net>
References: <1371134413.44971.YahooMailClassic@web172306.mail.ir2.yahoo.com>
	<5225B120.8050406@users.sourceforge.net>
	<52948B3C.8020801@users.sourceforge.net>
	<52A92DD7.2050905@users.sourceforge.net>
Message-ID: <B2B90DBE-B988-44BF-ACB9-764F30F8E6E5@comcast.net>


On Dec 11, 2013, at 7:30 PM, Hin-Tak Leung wrote:

> Here is a rather long discussion etc about freetype 2.5.2, problem with the survival package, and build R 2.15.x with gcc 4.8.x. Please feel free to skip forward.
> 
> - freetype 2.5.2:
> 
> the fix to cope with one of the Mac OS X's system fonts just before the release of freetype 2.5.1 caused a regression, crashing over one of Microsoft windows' system fonts. So there is a 2.5.2. There are new 2.5.2 bundles for windows & Mac OS X. The official win/mac binaries of R were built statically with 2+-years-old freetype with a few known problems. Most should upgrade/rebuild.
> 
> http://sourceforge.net/projects/outmodedbonsai/files/R/
> 
> - problem with the survival package:
> 
> Trying to re-run a vignette to get the same result as two years ago
> reveal a strange change. I went and bisected it down to
> r11513 and r11516 of the survival package.
> 
> -------------- r11513 --------------------
> clogit(cc ~ addContr(A) + addContr(C) + addContr(A.C) + strata(set))
> 
> 
>                   coef exp(coef) se(coef)     z      p
> addContr(A)2     -0.620     0.538    0.217 -2.86 0.0043
> addContr(C)2      0.482     1.620    0.217  2.22 0.0270
> addContr(A.C)1-2 -0.778     0.459    0.275 -2.83 0.0047
> addContr(A.C)2-1     NA        NA    0.000    NA     NA
> addContr(A.C)2-2     NA        NA    0.000    NA     NA
> 
> Likelihood ratio test=26  on 3 df, p=9.49e-06  n= 13110, number of events= 3524
> ------------------------------------------
> 
> ------------- r11516 ---------------------
> clogit(cc ~ addContr(A) + addContr(C) + addContr(A.C) + strata(set))
> 
> 
>                     coef exp(coef) se(coef)         z  p
> addContr(A)2     -0.14250     0.867   110812 -1.29e-06  1
> addContr(C)2      0.00525     1.005   110812  4.74e-08  1
> addContr(A.C)1-2 -0.30097     0.740   110812 -2.72e-06  1
> addContr(A.C)2-1 -0.47712     0.621   110812 -4.31e-06  1
> addContr(A.C)2-2       NA        NA        0        NA NA
> 
> Likelihood ratio test=26  on 4 df, p=3.15e-05  n= 13110, number of events= 3524
> ------------------------------------------
> 
> r11514 does not build, and r11515 have serious memory hogs, so the survival
> package broke somewhere between r11513 and r11516. Anyway, here is the diff in
> the vignette, and the data, etc is in the directory above. If somebody want to
> fix this before I spend any more time on this particular matter, please feel free to do so.
> 
> http://sourceforge.net/projects/outmodedbonsai/files/Manuals%2C%20Overviews%20and%20Slides%20for%20talks/2013SummerCourse/practicals/with-answers/practical8_survival-clogit-diff.pdf/download
> 
> That's the one problem from David's 10 practicals which are not due to bugs in snpStats. Some might find it reassuring that only 3 of the 4 problems with the practicals are due to snpStats bugs.
> 
> http://sourceforge.net/projects/outmodedbonsai/files/Manuals%2C%20Overviews%20and%20Slides%20for%20talks/2013SummerCourse/practicals/with-answers/practical7_snpStatsBug-diff.pdf/download
> http://sourceforge.net/projects/outmodedbonsai/files/Manuals%2C%20Overviews%20and%20Slides%20for%20talks/2013SummerCourse/practicals/with-answers/practical6_snpStatsBug-diff.pdf/download
> http://sourceforge.net/projects/outmodedbonsai/files/Manuals%2C%20Overviews%20and%20Slides%20for%20talks/2013SummerCourse/practicals/with-answers/practical3_snpStatsBug-diff.pdf/download
> 
> - build R 2.15.x with gcc 4.8.x
> 
> I wish the R commit log was a bit more detailed with r62430 than just
> "tweak needed for gcc 4.8.x". Anyway, building R 2.15.x with gcc 4.8.x
> could result in segfaults in usage as innocent and essential
> as running summary() on a data.frame:
> 
> --------------------------------
> *** caught segfault ***
> address 0x2f8e6a00, cause 'memory not mapped'
> 
> Traceback:
> 1: sort.list(y)
> 2: factor(a, exclude = exclude)
> 3: table(object, exclude = NULL)
> 4: summary.default(X[[3L]], ...)
> 5: FUN(X[[3L]], ...)
> 6: lapply(X = as.list(object), FUN = summary, maxsum = maxsum, digits = 12,   ...)
> 7: summary.data.frame(support)
> ...
> --------------------------------
> 
> r62430 needs a bit of adapting to apply to R 2.15.x , but you get the idea.
> I hope this info is useful to somebody else who is still using R 2.15.x , no doubt for very good reasons.

First: Sorry for the blank message. Need more coffee.

Second: Does this mean that only Mac users who are still using 2.15.x need to worry about this issue?

Third: I'm reading this (and Terry's comment about singularity conditions)  to mean that a numerical  discrepancy between vignette output when code was run being from what was expected was causing a segfault under some situation that I cannot quite reconstruct. Was the implication that Mac users (of 2.15.x) need to build from sources only if they wanted to build the survival package from source? Does this have any implications for those of us who use the survival package as the binary? (And I'm using 3.0.2, so a split answer might be needed to cover 2.15.x and the current versions separately)

-- 
David.
> 
> Hin-Tak Leung wrote:
>> The freetype people fixed the 2nd set of issues with system fonts shipped with
>> Mac OS X, and released 2.5.1 almost immediately after that. So there are
>> new bundles under http://sourceforge.net/projects/outmodedbonsai/files/R/ .
>> 
>> Just a reminder that the official R binaries for windows/mac OS X are statically
>> linked with rather dated versions of freetype with a few known issues. This
>> affects the cairo-based functionalities in R. So a rebuild is needed.
>> 
>> Most unix users should just upgrade their system's libfreetype, and
>> dynamic-linking should take care of the rest.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From brian.s.diggs at gmail.com  Fri Dec 13 18:09:53 2013
From: brian.s.diggs at gmail.com (Brian Diggs)
Date: Fri, 13 Dec 2013 09:09:53 -0800
Subject: [Rd] Strategies for keeping autogenerated .Rd files out of a
	Git tree
In-Reply-To: <52A905CB.4020701@ivt.baug.ethz.ch>
References: <52A905CB.4020701@ivt.baug.ethz.ch>
Message-ID: <52AB3F61.6000007@ohsu.edu>

On 12/11/2013 4:39 PM, Kirill M?ller wrote:
> Hi
>
> Quite a few R packages are now available on GitHub long before they
> appear on CRAN, installation is simple thanks to
> devtools::install_github(). However, it seems to be common practice to
> keep the .Rd files (and NAMESPACE and the Collate section in the
> DESCRIPTION) in the Git tree, and to manually update it, even if they
> are autogenerated from the R code by roxygen2. This requires extra work
> for each update of the documentation and also binds package development
> to a specific version of roxygen2 (because otherwise lots of bogus
> changes can be added by roxygenizing with a different version).
>
> What options are there to generate the .Rd files during build/install?
> In https://github.com/hadley/devtools/issues/43 the issue has been
> discussed, perhaps it can be summarized as follows:
>
> - The devtools package is not the right place to implement
> roxygenize-before-build
> - A continuous integration service would be better for that, but
> currently there's nothing that would be easy to use
> - Roxygenizing via src/Makefile could work but requires further
> investigation and an installation of Rtools/xcode on Windows/OS X
>
> Especially the last point looks interesting to me, but since this is not
> widely used there must be pitfalls I'm not aware of. The general idea
> would be:
>
> - Place code that builds/updates the .Rd and NAMESPACE files into
> src/Makefile
> - Users installing the package from source will require infrastructure
> (Rtools/make)
> - For binary packages, the .Rd files are already generated and added to
> the .tar.gz during R CMD build before they are submitted to
> CRAN/WinBuilder, and they are also generated (in theory) by R CMD build
> --binary
>
> I'd like to hear your opinion on that. I have also found a thread on
> package development workflow
> (https://stat.ethz.ch/pipermail/r-devel/2011-September/061955.html) but
> there was nothing on un-versioning .Rd files.

One downside I can see with this third approach is that by making the 
package documentation generation part of the build process, you must 
then make the package depend/require roxygen (or whatever tools you are 
using to generate documentation). This dependence, though, is just to 
build the package, not to actually use the package. And by pushing this 
dependency onto the end users of the package, you have transferred the 
problem you mentioned ("... and also binds package development to a 
specific version of roxygen2 ...") to the many end users rather than the 
few developers.

> Cheers
>
> Kirill
>


-- 
Brian S. Diggs, PhD
Senior Research Associate, Department of Surgery
Oregon Health & Science University


From csardi.gabor at gmail.com  Fri Dec 13 18:26:32 2013
From: csardi.gabor at gmail.com (=?ISO-8859-1?B?R+Fib3IgQ3PhcmRp?=)
Date: Fri, 13 Dec 2013 12:26:32 -0500
Subject: [Rd] Strategies for keeping autogenerated .Rd files out of a
	Git tree
In-Reply-To: <52AAE990.1050102@ivt.baug.ethz.ch>
References: <52A905CB.4020701@ivt.baug.ethz.ch>
	<CABtg=KkgGqaQOYSfzAnXfdgfK0UojLEjsd=amzc=BThS4EV7+w@mail.gmail.com>
	<52AAE990.1050102@ivt.baug.ethz.ch>
Message-ID: <CABtg=KmL=+_HKLN=KgdAXTWBr_c1qHW4JP3HEASNJhDhfF+f6g@mail.gmail.com>

On Fri, Dec 13, 2013 at 6:03 AM, Kirill M?ller
<kirill.mueller at ivt.baug.ethz.ch> wrote:
> Gabor
>
> I agree with you. There's Travis CI, and r-travis -- an attempt to integrate
> R package testing with Travis. Pushing back to GitHub is possible, but the
> setup is somewhat difficult. Also, this can be subject to race conditions
> because each push triggers a test run and they can happen in parallel even
> for the same repository.

I set my CI, so that it does not allow concurrent builds from the same
job. So there are no race conditions. This is probably possible with
Travis, I don't know.

> How do you handle branches?

So far I didn't, and only pushed back "main" branch. But you can just
push back to different branches. In this case I would probably create
another repo, and have the same branches in both in the "source" repo
and the "publish" repo.

> It would be really great to be able to execute custom R code before
> building. Perhaps in a PreBuild: section in DESCRIPTION?

I am just using make to create the package. This creates all
autogenerated files and then calls R PKG build.

Another option for this whole problem is not using github at all, but
setting up a CRAN-like repository, and make the CI publish the built
and checked packages there.

Gabor

>
> Cheers
>
> Kirill
>
>
>
>
> On 12/12/2013 02:21 AM, G?bor Cs?rdi wrote:
>>
>> Hi,
>>
>> this is maybe mostly a personal preference, but I prefer not to put
>> generated files in the vc repository. Changes in the generated files,
>> especially if there is many of them, pollute the diffs and make them
>> less useful.
>>
>> If you really want to be able to install the package directly from
>> github, one solution is to
>> 1. create another repository, that contains the complete generated
>> package, so that install_github() can install it.
>> 2. set up a CI service, that can download the package from github,
>> build the package or the generated files (check the package, while it
>> is at it), and then push the build stuff back to github.
>> 3. set up a hook on github, that invokes the CI after each commit.
>>
>> I have used this setup in various projects with jenkins-ci and it
>> works well. Diffs are clean, the package is checked and built
>> frequently, and people can download it without having to install the
>> tools that generate the generated files.
>>
>> The only downside is that you need to install a CI, so you need a
>> "server" for that. Maybe you can do this with travis-ci, maybe not, I
>> am not familiar with it that much.
>>
>> Best,
>> Gabor
>>
>> On Wed, Dec 11, 2013 at 7:39 PM, Kirill M?ller
>> <kirill.mueller at ivt.baug.ethz.ch> wrote:
>>>
>>> Hi
>>>
>>> Quite a few R packages are now available on GitHub long before they
>>> appear
>>> on CRAN, installation is simple thanks to devtools::install_github().
>>> However, it seems to be common practice to keep the .Rd files (and
>>> NAMESPACE
>>> and the Collate section in the DESCRIPTION) in the Git tree, and to
>>> manually
>>> update it, even if they are autogenerated from the R code by roxygen2.
>>> This
>>> requires extra work for each update of the documentation and also binds
>>> package development to a specific version of roxygen2 (because otherwise
>>> lots of bogus changes can be added by roxygenizing with a different
>>> version).
>>>
>>> What options are there to generate the .Rd files during build/install? In
>>> https://github.com/hadley/devtools/issues/43 the issue has been
>>> discussed,
>>> perhaps it can be summarized as follows:
>>>
>>> - The devtools package is not the right place to implement
>>> roxygenize-before-build
>>> - A continuous integration service would be better for that, but
>>> currently
>>> there's nothing that would be easy to use
>>> - Roxygenizing via src/Makefile could work but requires further
>>> investigation and an installation of Rtools/xcode on Windows/OS X
>>>
>>> Especially the last point looks interesting to me, but since this is not
>>> widely used there must be pitfalls I'm not aware of. The general idea
>>> would
>>> be:
>>>
>>> - Place code that builds/updates the .Rd and NAMESPACE files into
>>> src/Makefile
>>> - Users installing the package from source will require infrastructure
>>> (Rtools/make)
>>> - For binary packages, the .Rd files are already generated and added to
>>> the
>>> .tar.gz during R CMD build before they are submitted to CRAN/WinBuilder,
>>> and
>>> they are also generated (in theory) by R CMD build --binary
>>>
>>> I'd like to hear your opinion on that. I have also found a thread on
>>> package
>>> development workflow
>>> (https://stat.ethz.ch/pipermail/r-devel/2011-September/061955.html) but
>>> there was nothing on un-versioning .Rd files.
>>>
>>>
>>> Cheers
>>>
>>> Kirill
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>
> --
> _________________________________________________
> ETH Z?rich
> Institute for Transport Planning and Systems
> HIL F 32.2
> Wolfgang-Pauli-Str. 15
> 8093 Z?rich
>
> Phone:       +41 44 633 33 17
> Fax:         +41 44 633 10 57
> Secretariat: +41 44 633 31 05
> E-Mail:      kirill.mueller at ivt.baug.ethz.ch
>


From gmbecker at ucdavis.edu  Fri Dec 13 18:50:33 2013
From: gmbecker at ucdavis.edu (Gabriel Becker)
Date: Fri, 13 Dec 2013 09:50:33 -0800
Subject: [Rd] Strategies for keeping autogenerated .Rd files out of a
	Git tree
In-Reply-To: <CABtg=KmL=+_HKLN=KgdAXTWBr_c1qHW4JP3HEASNJhDhfF+f6g@mail.gmail.com>
References: <52A905CB.4020701@ivt.baug.ethz.ch>
	<CABtg=KkgGqaQOYSfzAnXfdgfK0UojLEjsd=amzc=BThS4EV7+w@mail.gmail.com>
	<52AAE990.1050102@ivt.baug.ethz.ch>
	<CABtg=KmL=+_HKLN=KgdAXTWBr_c1qHW4JP3HEASNJhDhfF+f6g@mail.gmail.com>
Message-ID: <CADwqtCOOCeJFzdMJDbkovnMv5AcdCtvUaq_OB=bXbDjuoNQ2DA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20131213/8ba2d220/attachment.pl>

From simon.urbanek at r-project.org  Fri Dec 13 21:14:18 2013
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Fri, 13 Dec 2013 15:14:18 -0500
Subject: [Rd] Strategies for keeping autogenerated .Rd files out of a
	Git tree
In-Reply-To: <52AB10EF.9070503@ivt.baug.ethz.ch>
References: <52A905CB.4020701@ivt.baug.ethz.ch>
	<CABtg=KkgGqaQOYSfzAnXfdgfK0UojLEjsd=amzc=BThS4EV7+w@mail.gmail.com>
	<52AAE990.1050102@ivt.baug.ethz.ch>
	<175312B6-9672-4C71-AB2F-AFA05A06162C@r-enthusiasts.com>
	<52AB10EF.9070503@ivt.baug.ethz.ch>
Message-ID: <0C2772D3-C8CD-4437-B112-4DD0AD7D084C@r-project.org>

FWIW this is essentially what RForge.net provides. Each GitHub commit triggers a build (branches are supported as the branch info is passed in the WebHook) which can be either "classic" R CMD build or a custom shell script (hence you can do anything you want). The result is a tar ball (which includes the generated files) and that tar ball gets published in the R package repository. R CMD  check is run as well on the tar ball and the results are published.
This way you don't need devtools, users can simply use install.packages() without requiring any additional tools.

There are some talks about providing the above as a cloud service, so that anyone can run and/or use it.

Cheers,
Simon


On Dec 13, 2013, at 8:51 AM, Kirill M?ller <kirill.mueller at ivt.baug.ethz.ch> wrote:

> On 12/13/2013 12:50 PM, Romain Francois wrote:
>> Pushing back to github is not so difficult. See e.g 
>> http://blog.r-enthusiasts.com/2013/12/04/automated-blogging.html
> Thanks for the writeup, I'll try this. Perhaps it's better to push the 
> results of `R CMD build`, though.
>> You can manage branches easily in travis. You could for example decide 
>> to do something different if you are on the master branch ...
> That's right. But then no .Rd files are built when I'm on a branch, so I 
> can't easily preview the result.
> 
> The ideal situation would be:
> 
> 1. I manage only R source files on GitHub, not Rd files, NAMESPACE nor 
> the "Collate" section of DESCRIPTION. Machine-readable instructions on 
> how to build those are provided with the package.
> 2. Anyone can install from GitHub using devtools::install_github(). This 
> also should work for branches, forks and pull requests.
> 3. I can build the package so that the result can be accepted by CRAN.
> 
> The crucial point on that list is point 2, the others I can easily solve 
> myself.
> 
> The way I see it, point 2 can be tackled by extending devtools or 
> extending the ways packages are built. Extending devtools seems to be 
> the inferior approach, although, to be honest, I'd be fine with that as 
> well.
> 
> 
> -Kirill
> 
>> 
>> Romain
>> 
>> Le 13 d?c. 2013 ? 12:03, Kirill M?ller 
>> <kirill.mueller at ivt.baug.ethz.ch 
>> <mailto:kirill.mueller at ivt.baug.ethz.ch>> a ?crit :
>> 
>>> Gabor
>>> 
>>> I agree with you. There's Travis CI, and r-travis -- an attempt to 
>>> integrate R package testing with Travis. Pushing back to GitHub is 
>>> possible, but the setup is somewhat difficult. Also, this can be 
>>> subject to race conditions because each push triggers a test run and 
>>> they can happen in parallel even for the same repository. How do you 
>>> handle branches?
>>> 
>>> It would be really great to be able to execute custom R code before 
>>> building. Perhaps in a PreBuild: section in DESCRIPTION?
>>> 
>>> 
>>> Cheers
>>> 
>>> Kirill
>>> 
>>> 
>>> On 12/12/2013 02:21 AM, G?bor Cs?rdi wrote:
>>>> Hi,
>>>> 
>>>> this is maybe mostly a personal preference, but I prefer not to put
>>>> generated files in the vc repository. Changes in the generated files,
>>>> especially if there is many of them, pollute the diffs and make them
>>>> less useful.
>>>> 
>>>> If you really want to be able to install the package directly from
>>>> github, one solution is to
>>>> 1. create another repository, that contains the complete generated
>>>> package, so that install_github() can install it.
>>>> 2. set up a CI service, that can download the package from github,
>>>> build the package or the generated files (check the package, while it
>>>> is at it), and then push the build stuff back to github.
>>>> 3. set up a hook on github, that invokes the CI after each commit.
>>>> 
>>>> I have used this setup in various projects with jenkins-ci and it
>>>> works well. Diffs are clean, the package is checked and built
>>>> frequently, and people can download it without having to install the
>>>> tools that generate the generated files.
>>>> 
>>>> The only downside is that you need to install a CI, so you need a
>>>> "server" for that. Maybe you can do this with travis-ci, maybe not, I
>>>> am not familiar with it that much.
>>>> 
>>>> Best,
>>>> Gabor
>>>> 
>>>> On Wed, Dec 11, 2013 at 7:39 PM, Kirill M?ller
>>>> <kirill.mueller at ivt.baug.ethz.ch 
>>>> <mailto:kirill.mueller at ivt.baug.ethz.ch>> wrote:
>>>>> Hi
>>>>> 
>>>>> Quite a few R packages are now available on GitHub long before they 
>>>>> appear
>>>>> on CRAN, installation is simple thanks to devtools::install_github().
>>>>> However, it seems to be common practice to keep the .Rd files (and 
>>>>> NAMESPACE
>>>>> and the Collate section in the DESCRIPTION) in the Git tree, and to 
>>>>> manually
>>>>> update it, even if they are autogenerated from the R code by 
>>>>> roxygen2. This
>>>>> requires extra work for each update of the documentation and also binds
>>>>> package development to a specific version of roxygen2 (because 
>>>>> otherwise
>>>>> lots of bogus changes can be added by roxygenizing with a different
>>>>> version).
>>>>> 
>>>>> What options are there to generate the .Rd files during 
>>>>> build/install? In
>>>>> https://github.com/hadley/devtools/issues/43 the issue has been 
>>>>> discussed,
>>>>> perhaps it can be summarized as follows:
>>>>> 
>>>>> - The devtools package is not the right place to implement
>>>>> roxygenize-before-build
>>>>> - A continuous integration service would be better for that, but 
>>>>> currently
>>>>> there's nothing that would be easy to use
>>>>> - Roxygenizing via src/Makefile could work but requires further
>>>>> investigation and an installation of Rtools/xcode on Windows/OS X
>>>>> 
>>>>> Especially the last point looks interesting to me, but since this 
>>>>> is not
>>>>> widely used there must be pitfalls I'm not aware of. The general 
>>>>> idea would
>>>>> be:
>>>>> 
>>>>> - Place code that builds/updates the .Rd and NAMESPACE files into
>>>>> src/Makefile
>>>>> - Users installing the package from source will require infrastructure
>>>>> (Rtools/make)
>>>>> - For binary packages, the .Rd files are already generated and 
>>>>> added to the
>>>>> .tar.gz during R CMD build before they are submitted to 
>>>>> CRAN/WinBuilder, and
>>>>> they are also generated (in theory) by R CMD build --binary
>>>>> 
>>>>> I'd like to hear your opinion on that. I have also found a thread 
>>>>> on package
>>>>> development workflow
>>>>> (https://stat.ethz.ch/pipermail/r-devel/2011-September/061955.html) but
>>>>> there was nothing on un-versioning .Rd files.
>>>>> 
>>>>> 
>>>>> Cheers
>>>>> 
>>>>> Kirill
>>>>> 
>>>>> ______________________________________________
>>>>> R-devel at r-project.org <mailto:R-devel at r-project.org> mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>> 
>>> -- 
>>> _________________________________________________
>>> ETH Z?rich
>>> Institute for Transport Planning and Systems
>>> HIL F 32.2
>>> Wolfgang-Pauli-Str. 15
>>> 8093 Z?rich
>>> 
>>> Phone:       +41 44 633 33 17
>>> Fax:         +41 44 633 10 57
>>> Secretariat: +41 44 633 31 05
>>> E-Mail: kirill.mueller at ivt.baug.ethz.ch 
>>> <mailto:kirill.mueller at ivt.baug.ethz.ch>
>>> 
>>> ______________________________________________
>>> R-devel at r-project.org <mailto:R-devel at r-project.org> mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> -- 
> _________________________________________________
> ETH Z?rich
> Institute for Transport Planning and Systems
> HIL F 32.2
> Wolfgang-Pauli-Str. 15
> 8093 Z?rich
> 
> Phone:       +41 44 633 33 17
> Fax:         +41 44 633 10 57
> Secretariat: +41 44 633 31 05
> E-Mail:      kirill.mueller at ivt.baug.ethz.ch
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From csardi.gabor at gmail.com  Fri Dec 13 21:24:40 2013
From: csardi.gabor at gmail.com (=?ISO-8859-1?B?R+Fib3IgQ3PhcmRp?=)
Date: Fri, 13 Dec 2013 15:24:40 -0500
Subject: [Rd] Strategies for keeping autogenerated .Rd files out of a
	Git tree
In-Reply-To: <0C2772D3-C8CD-4437-B112-4DD0AD7D084C@r-project.org>
References: <52A905CB.4020701@ivt.baug.ethz.ch>
	<CABtg=KkgGqaQOYSfzAnXfdgfK0UojLEjsd=amzc=BThS4EV7+w@mail.gmail.com>
	<52AAE990.1050102@ivt.baug.ethz.ch>
	<175312B6-9672-4C71-AB2F-AFA05A06162C@r-enthusiasts.com>
	<52AB10EF.9070503@ivt.baug.ethz.ch>
	<0C2772D3-C8CD-4437-B112-4DD0AD7D084C@r-project.org>
Message-ID: <CABtg=Kn4H8yz7bV7QK+nGqd0XXoGawNwqTQD5_460iXS-JzfYw@mail.gmail.com>

Oh, I didn't know RForge.net supported external git repos, cool!

Gabor

On Fri, Dec 13, 2013 at 3:14 PM, Simon Urbanek
<simon.urbanek at r-project.org> wrote:
> FWIW this is essentially what RForge.net provides. Each GitHub commit triggers a build (branches are supported as the branch info is passed in the WebHook) which can be either "classic" R CMD build or a custom shell script (hence you can do anything you want). The result is a tar ball (which includes the generated files) and that tar ball gets published in the R package repository. R CMD  check is run as well on the tar ball and the results are published.
> This way you don't need devtools, users can simply use install.packages() without requiring any additional tools.
>
> There are some talks about providing the above as a cloud service, so that anyone can run and/or use it.
>
[...]


From csardi.gabor at gmail.com  Fri Dec 13 21:29:24 2013
From: csardi.gabor at gmail.com (=?ISO-8859-1?B?R+Fib3IgQ3PhcmRp?=)
Date: Fri, 13 Dec 2013 15:29:24 -0500
Subject: [Rd] Strategies for keeping autogenerated .Rd files out of a
	Git tree
In-Reply-To: <CABtg=Kn4H8yz7bV7QK+nGqd0XXoGawNwqTQD5_460iXS-JzfYw@mail.gmail.com>
References: <52A905CB.4020701@ivt.baug.ethz.ch>
	<CABtg=KkgGqaQOYSfzAnXfdgfK0UojLEjsd=amzc=BThS4EV7+w@mail.gmail.com>
	<52AAE990.1050102@ivt.baug.ethz.ch>
	<175312B6-9672-4C71-AB2F-AFA05A06162C@r-enthusiasts.com>
	<52AB10EF.9070503@ivt.baug.ethz.ch>
	<0C2772D3-C8CD-4437-B112-4DD0AD7D084C@r-project.org>
	<CABtg=Kn4H8yz7bV7QK+nGqd0XXoGawNwqTQD5_460iXS-JzfYw@mail.gmail.com>
Message-ID: <CABtg=KmqA5tnoJ_F5dS4ZePBSkS5Sz3d_4ys_pYooENHUBe_Dg@mail.gmail.com>

Btw. one thing that probably would not work (well) with RForge.net (or
another CRAN-like repo), is the multiple branches.

The problem is that you cannot put the branch name in the package
version string, because that is not allowed, and then the versions
from the multiple branches get mixed up. This works fine with
install_github() because you can explicitly specify the branch there.

One possible solution is to create multiple repos, one for each
branch. Not really elegant, though.

I don't really need this myself, I am just saying because it came up
in this thread.

Gabor

On Fri, Dec 13, 2013 at 3:24 PM, G?bor Cs?rdi <csardi.gabor at gmail.com> wrote:
> Oh, I didn't know RForge.net supported external git repos, cool!
>
> Gabor
>
> On Fri, Dec 13, 2013 at 3:14 PM, Simon Urbanek
> <simon.urbanek at r-project.org> wrote:
>> FWIW this is essentially what RForge.net provides. Each GitHub commit triggers a build (branches are supported as the branch info is passed in the WebHook) which can be either "classic" R CMD build or a custom shell script (hence you can do anything you want). The result is a tar ball (which includes the generated files) and that tar ball gets published in the R package repository. R CMD  check is run as well on the tar ball and the results are published.
>> This way you don't need devtools, users can simply use install.packages() without requiring any additional tools.
>>
>> There are some talks about providing the above as a cloud service, so that anyone can run and/or use it.
>>
> [...]


From kirill.mueller at ivt.baug.ethz.ch  Fri Dec 13 21:43:59 2013
From: kirill.mueller at ivt.baug.ethz.ch (=?ISO-8859-1?Q?Kirill_M=FCller?=)
Date: Fri, 13 Dec 2013 21:43:59 +0100
Subject: [Rd] Strategies for keeping autogenerated .Rd files out of a
 Git tree
In-Reply-To: <0C2772D3-C8CD-4437-B112-4DD0AD7D084C@r-project.org>
References: <52A905CB.4020701@ivt.baug.ethz.ch>
	<CABtg=KkgGqaQOYSfzAnXfdgfK0UojLEjsd=amzc=BThS4EV7+w@mail.gmail.com>
	<52AAE990.1050102@ivt.baug.ethz.ch>
	<175312B6-9672-4C71-AB2F-AFA05A06162C@r-enthusiasts.com>
	<52AB10EF.9070503@ivt.baug.ethz.ch>
	<0C2772D3-C8CD-4437-B112-4DD0AD7D084C@r-project.org>
Message-ID: <52AB718F.5030704@ivt.baug.ethz.ch>

Thanks a lot. This would indeed solve the problem. I'll try mkdist today ;-)

Is the NEWS file parsed before of after mkdist has been executed?

Would you be willing to share the code for the infrastructure, perhaps 
on GitHub?


-Kirill


On 12/13/2013 09:14 PM, Simon Urbanek wrote:
> FWIW this is essentially what RForge.net provides. Each GitHub commit triggers a build (branches are supported as the branch info is passed in the WebHook) which can be either "classic" R CMD build or a custom shell script (hence you can do anything you want). The result is a tar ball (which includes the generated files) and that tar ball gets published in the R package repository. R CMD  check is run as well on the tar ball and the results are published.
> This way you don't need devtools, users can simply use install.packages() without requiring any additional tools.
>
> There are some talks about providing the above as a cloud service, so that anyone can run and/or use it.
>
> Cheers,
> Simon
>
>
> On Dec 13, 2013, at 8:51 AM, Kirill M?ller <kirill.mueller at ivt.baug.ethz.ch> wrote:
>
>> On 12/13/2013 12:50 PM, Romain Francois wrote:
>>> Pushing back to github is not so difficult. See e.g
>>> http://blog.r-enthusiasts.com/2013/12/04/automated-blogging.html
>> Thanks for the writeup, I'll try this. Perhaps it's better to push the
>> results of `R CMD build`, though.
>>> You can manage branches easily in travis. You could for example decide
>>> to do something different if you are on the master branch ...
>> That's right. But then no .Rd files are built when I'm on a branch, so I
>> can't easily preview the result.
>>
>> The ideal situation would be:
>>
>> 1. I manage only R source files on GitHub, not Rd files, NAMESPACE nor
>> the "Collate" section of DESCRIPTION. Machine-readable instructions on
>> how to build those are provided with the package.
>> 2. Anyone can install from GitHub using devtools::install_github(). This
>> also should work for branches, forks and pull requests.
>> 3. I can build the package so that the result can be accepted by CRAN.
>>
>> The crucial point on that list is point 2, the others I can easily solve
>> myself.
>>
>> The way I see it, point 2 can be tackled by extending devtools or
>> extending the ways packages are built. Extending devtools seems to be
>> the inferior approach, although, to be honest, I'd be fine with that as
>> well.
>>
>>
>> -Kirill
>>
>>> Romain
>>>
>>> Le 13 d?c. 2013 ? 12:03, Kirill M?ller
>>> <kirill.mueller at ivt.baug.ethz.ch
>>> <mailto:kirill.mueller at ivt.baug.ethz.ch>> a ?crit :
>>>
>>>> Gabor
>>>>
>>>> I agree with you. There's Travis CI, and r-travis -- an attempt to
>>>> integrate R package testing with Travis. Pushing back to GitHub is
>>>> possible, but the setup is somewhat difficult. Also, this can be
>>>> subject to race conditions because each push triggers a test run and
>>>> they can happen in parallel even for the same repository. How do you
>>>> handle branches?
>>>>
>>>> It would be really great to be able to execute custom R code before
>>>> building. Perhaps in a PreBuild: section in DESCRIPTION?
>>>>
>>>>
>>>> Cheers
>>>>
>>>> Kirill
>>>>
>>>>
>>>> On 12/12/2013 02:21 AM, G?bor Cs?rdi wrote:
>>>>> Hi,
>>>>>
>>>>> this is maybe mostly a personal preference, but I prefer not to put
>>>>> generated files in the vc repository. Changes in the generated files,
>>>>> especially if there is many of them, pollute the diffs and make them
>>>>> less useful.
>>>>>
>>>>> If you really want to be able to install the package directly from
>>>>> github, one solution is to
>>>>> 1. create another repository, that contains the complete generated
>>>>> package, so that install_github() can install it.
>>>>> 2. set up a CI service, that can download the package from github,
>>>>> build the package or the generated files (check the package, while it
>>>>> is at it), and then push the build stuff back to github.
>>>>> 3. set up a hook on github, that invokes the CI after each commit.
>>>>>
>>>>> I have used this setup in various projects with jenkins-ci and it
>>>>> works well. Diffs are clean, the package is checked and built
>>>>> frequently, and people can download it without having to install the
>>>>> tools that generate the generated files.
>>>>>
>>>>> The only downside is that you need to install a CI, so you need a
>>>>> "server" for that. Maybe you can do this with travis-ci, maybe not, I
>>>>> am not familiar with it that much.
>>>>>
>>>>> Best,
>>>>> Gabor
>>>>>
>>>>> On Wed, Dec 11, 2013 at 7:39 PM, Kirill M?ller
>>>>> <kirill.mueller at ivt.baug.ethz.ch
>>>>> <mailto:kirill.mueller at ivt.baug.ethz.ch>> wrote:
>>>>>> Hi
>>>>>>
>>>>>> Quite a few R packages are now available on GitHub long before they
>>>>>> appear
>>>>>> on CRAN, installation is simple thanks to devtools::install_github().
>>>>>> However, it seems to be common practice to keep the .Rd files (and
>>>>>> NAMESPACE
>>>>>> and the Collate section in the DESCRIPTION) in the Git tree, and to
>>>>>> manually
>>>>>> update it, even if they are autogenerated from the R code by
>>>>>> roxygen2. This
>>>>>> requires extra work for each update of the documentation and also binds
>>>>>> package development to a specific version of roxygen2 (because
>>>>>> otherwise
>>>>>> lots of bogus changes can be added by roxygenizing with a different
>>>>>> version).
>>>>>>
>>>>>> What options are there to generate the .Rd files during
>>>>>> build/install? In
>>>>>> https://github.com/hadley/devtools/issues/43 the issue has been
>>>>>> discussed,
>>>>>> perhaps it can be summarized as follows:
>>>>>>
>>>>>> - The devtools package is not the right place to implement
>>>>>> roxygenize-before-build
>>>>>> - A continuous integration service would be better for that, but
>>>>>> currently
>>>>>> there's nothing that would be easy to use
>>>>>> - Roxygenizing via src/Makefile could work but requires further
>>>>>> investigation and an installation of Rtools/xcode on Windows/OS X
>>>>>>
>>>>>> Especially the last point looks interesting to me, but since this
>>>>>> is not
>>>>>> widely used there must be pitfalls I'm not aware of. The general
>>>>>> idea would
>>>>>> be:
>>>>>>
>>>>>> - Place code that builds/updates the .Rd and NAMESPACE files into
>>>>>> src/Makefile
>>>>>> - Users installing the package from source will require infrastructure
>>>>>> (Rtools/make)
>>>>>> - For binary packages, the .Rd files are already generated and
>>>>>> added to the
>>>>>> .tar.gz during R CMD build before they are submitted to
>>>>>> CRAN/WinBuilder, and
>>>>>> they are also generated (in theory) by R CMD build --binary
>>>>>>
>>>>>> I'd like to hear your opinion on that. I have also found a thread
>>>>>> on package
>>>>>> development workflow
>>>>>> (https://stat.ethz.ch/pipermail/r-devel/2011-September/061955.html) but
>>>>>> there was nothing on un-versioning .Rd files.
>>>>>>
>>>>>>
>>>>>> Cheers
>>>>>>
>>>>>> Kirill
>>>>>>
>>>>>> ______________________________________________
>>>>>> R-devel at r-project.org <mailto:R-devel at r-project.org> mailing list
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>> -- 
>>>> _________________________________________________
>>>> ETH Z?rich
>>>> Institute for Transport Planning and Systems
>>>> HIL F 32.2
>>>> Wolfgang-Pauli-Str. 15
>>>> 8093 Z?rich
>>>>
>>>> Phone:       +41 44 633 33 17
>>>> Fax:         +41 44 633 10 57
>>>> Secretariat: +41 44 633 31 05
>>>> E-Mail: kirill.mueller at ivt.baug.ethz.ch
>>>> <mailto:kirill.mueller at ivt.baug.ethz.ch>
>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org <mailto:R-devel at r-project.org> mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> -- 
>> _________________________________________________
>> ETH Z?rich
>> Institute for Transport Planning and Systems
>> HIL F 32.2
>> Wolfgang-Pauli-Str. 15
>> 8093 Z?rich
>>
>> Phone:       +41 44 633 33 17
>> Fax:         +41 44 633 10 57
>> Secretariat: +41 44 633 31 05
>> E-Mail:      kirill.mueller at ivt.baug.ethz.ch
>>
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
_________________________________________________
ETH Z?rich
Institute for Transport Planning and Systems
HIL F 32.2
Wolfgang-Pauli-Str. 15
8093 Z?rich

Phone:       +41 44 633 33 17
Fax:         +41 44 633 10 57
Secretariat: +41 44 633 31 05
E-Mail:      kirill.mueller at ivt.baug.ethz.ch


From kirill.mueller at ivt.baug.ethz.ch  Fri Dec 13 21:53:20 2013
From: kirill.mueller at ivt.baug.ethz.ch (=?ISO-8859-1?Q?Kirill_M=FCller?=)
Date: Fri, 13 Dec 2013 21:53:20 +0100
Subject: [Rd] Strategies for keeping autogenerated .Rd files out of a
	Git tree
In-Reply-To: <52AB3F61.6000007@ohsu.edu>
References: <52A905CB.4020701@ivt.baug.ethz.ch> <52AB3F61.6000007@ohsu.edu>
Message-ID: <52AB73C0.2080107@ivt.baug.ethz.ch>

On 12/13/2013 06:09 PM, Brian Diggs wrote:
> One downside I can see with this third approach is that by making the 
> package documentation generation part of the build process, you must 
> then make the package depend/require roxygen (or whatever tools you 
> are using to generate documentation). This dependence, though, is just 
> to build the package, not to actually use the package. And by pushing 
> this dependency onto the end users of the package, you have 
> transferred the problem you mentioned ("... and also binds package 
> development to a specific version of roxygen2 ...") to the many end 
> users rather than the few developers.
That's right. As outlined in another message, roxygen2 would be required 
for building from the "raw" source (hosted on GitHub) but not for 
installing from a source tarball (which would contain the .Rd files). 
Not sure if that's possible, though.


From romain at r-enthusiasts.com  Sat Dec 14 15:12:18 2013
From: romain at r-enthusiasts.com (=?windows-1252?Q?Romain_Fran=E7ois?=)
Date: Sat, 14 Dec 2013 15:12:18 +0100
Subject: [Rd] internal manipulation of ...
In-Reply-To: <CABdHhvE_TodiJp5pzBYWdQKn3QuKHSwJ62xwun2-cG3tX04EKQ@mail.gmail.com>
References: <EDC77346-95D8-4562-A49C-889109F5DF92@r-enthusiasts.com>
	<CABdHhvE_TodiJp5pzBYWdQKn3QuKHSwJ62xwun2-cG3tX04EKQ@mail.gmail.com>
Message-ID: <26F53C67-F7E8-4C0F-85F3-6C50E4F87168@r-enthusiasts.com>

Thanks. This works for me. See this gist: https://gist.github.com/romainfrancois/7959531

Romain

Le 13 d?c. 2013 ? 01:09, Hadley Wickham <h.wickham at gmail.com> a ?crit :

> Could you pass the environment and then look for the object called ... in it?
> 
> f <- function(...) {
>  .Call("my_fun", environment())
> }
> 
> I think (and may well be wrong) that you can use standard tools to
> find the DOTSXP object in that environment.
> 
> Hadley
> 
> 
> On Thu, Dec 12, 2013 at 2:32 PM, Romain Fran?ois
> <romain at r-enthusiasts.com> wrote:
>> Hello,
>> 
>> I?m looking for examples on how to manipulate the ... internally, e.g. in a .Call or .External function.
>> 
>> I?m particularly interested in accessing the environment in which each contribution to ... can be evaluated.
>> 
>> So far, I?m using tricks involving passing down the sys.calls() and sys.frames() down to the C function. The documentation in http://cran.r-project.org/doc/manuals/R-ints.html#Dot_002ddot_002ddot-arguments did not help me a lot.
>> 
>> Romain
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 
> 
> -- 
> http://had.co.nz/


From peter.meilstrup at gmail.com  Sat Dec 14 21:43:54 2013
From: peter.meilstrup at gmail.com (Peter Meilstrup)
Date: Sat, 14 Dec 2013 12:43:54 -0800
Subject: [Rd] internal manipulation of ...
In-Reply-To: <26F53C67-F7E8-4C0F-85F3-6C50E4F87168@r-enthusiasts.com>
References: <EDC77346-95D8-4562-A49C-889109F5DF92@r-enthusiasts.com>
	<CABdHhvE_TodiJp5pzBYWdQKn3QuKHSwJ62xwun2-cG3tX04EKQ@mail.gmail.com>
	<26F53C67-F7E8-4C0F-85F3-6C50E4F87168@r-enthusiasts.com>
Message-ID: <CAJoaRhb5JTJ16SO2qpfBT43xeStcysVe1z9yyPGgictcJo-YrQ@mail.gmail.com>

In R code, get("...", environment()) will retrieve the DOTSXP object.
So another way is to write your wrapper functions like

someFunc <- function(...) {
  .External("someFunc_extern", get("...", ifnotfound=NULL) )
}

If you're trying to mimic what substitute() et al do, you'll sometimes
need to follow a chain of promises-that-have-promises in the PREXP
slot until you get to the "real" one.

Peter

On Sat, Dec 14, 2013 at 6:12 AM, Romain Fran?ois
<romain at r-enthusiasts.com> wrote:
> Thanks. This works for me. See this gist: https://gist.github.com/romainfrancois/7959531
>
> Romain
>
> Le 13 d?c. 2013 ? 01:09, Hadley Wickham <h.wickham at gmail.com> a ?crit :
>
>> Could you pass the environment and then look for the object called ... in it?
>>
>> f <- function(...) {
>>  .Call("my_fun", environment())
>> }
>>
>> I think (and may well be wrong) that you can use standard tools to
>> find the DOTSXP object in that environment.
>>
>> Hadley
>>
>>
>> On Thu, Dec 12, 2013 at 2:32 PM, Romain Fran?ois
>> <romain at r-enthusiasts.com> wrote:
>>> Hello,
>>>
>>> I?m looking for examples on how to manipulate the ... internally, e.g. in a .Call or .External function.
>>>
>>> I?m particularly interested in accessing the environment in which each contribution to ... can be evaluated.
>>>
>>> So far, I?m using tricks involving passing down the sys.calls() and sys.frames() down to the C function. The documentation in http://cran.r-project.org/doc/manuals/R-ints.html#Dot_002ddot_002ddot-arguments did not help me a lot.
>>>
>>> Romain
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>>
>> --
>> http://had.co.nz/
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From mitomaster at gmail.com  Mon Dec 16 04:11:08 2013
From: mitomaster at gmail.com (Krzysztof Mlynarczyk)
Date: Mon, 16 Dec 2013 04:11:08 +0100
Subject: [Rd] External pointers and changing SEXPTYPE
Message-ID: <CAPxYnfpR=0bVy2m2214f7765MBDmGupFs6=VB7L5K7cH35Z5Ng@mail.gmail.com>

Dear Developers,


I've been struggling through writing R extension in C. I've been using
an external pointer to store my data (please see sample below). I
encountered a very weird erroneous behaviour: when I tried to use my
external pointer to a structure holding several types of data,
including SEXPs, I discovered that SEXPs change their types between
returning from initialization function and another one that uses the
pointer.

sample R code:

# initializing
a <- init_my_ptr(fname)

# reading more data: error!
df <- read_my_data(a)

data structure in C:
typedef struct {
  SEXP ans, ans_nms, R_z, R_a, R_b, R_c;
  FTYPE *datafile;
  char *fname;
  float *a, *b, *c;
  int f_type;
  float t, p, l;
  int st, na, result, bFlags;
  XXX z;
} my_data_ptr;

// In a C function initializing the external pointer:
my_data_ptr *mydata = Calloc( 1, my_data_ptr ) ;
SEXP Rdata;
PROTECT(Rdata = R_MakeExternalPtr( mydata, R_fname, R_NilValue ));
...
mydata->a = Calloc(mydata->na, float);
// same for b and c
// initializing names so that I could use e.g. df$a where df is
returned by read_my_data()
PROTECT(mydata->ans_nms = Rf_allocVector(STRSXP, efldNR ));
  for( ix = 0; ix < efldNR; ix++ )
    SET_STRING_ELT(mydata->ans_nms, ix, mkChar(vnames[ix]));

// later I bind values of non-R variables from my data structure to a
proper vector
PROTECT(mydata->ans = Rf_allocVector(VECSXP, efldNR ));

  Rf_setAttrib(mydata->ans, R_NamesSymbol, mytraj->ans_nms);
  SET_VECTOR_ELT(mydata->ans, 0,      mydata->R_a );
  SET_VECTOR_ELT(mydata->ans, 1,      mydata->R_b );
...
// all protects get unprotected before return
// finalizer is registered as well
return Rdata;

Later on in read_my_data() I read the pointer:
my_data_ptr *mydata = (my_data_ptr*) R_ExternalPtrAddr(Rdata);

// and REAL(mydata->R_a) yields error since TYPEOF(mydata->R_a) is not
REALSXP as it should be but RAWSXP for some reason // (sometimes it's
STRSXP or INTSXP while it should always be REALSXP)
// The error message says:
// REAL() can only be applied to a 'numeric', not a 'raw'

// mydata->ans is the object returned to R where all the data is made
available to R user:
return mydata->ans;

// end of example code

Could you please point the possible reasons for the error along with
the ways of fixing this issue? I've been trying in R-3.0.2, 3.0.1 and
even 2.15 -- the problem happens in each of them.


Regards,
Christopher


From pdalgd at gmail.com  Mon Dec 16 10:19:20 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Mon, 16 Dec 2013 10:19:20 +0100
Subject: [Rd] External pointers and changing SEXPTYPE
In-Reply-To: <CAPxYnfpR=0bVy2m2214f7765MBDmGupFs6=VB7L5K7cH35Z5Ng@mail.gmail.com>
References: <CAPxYnfpR=0bVy2m2214f7765MBDmGupFs6=VB7L5K7cH35Z5Ng@mail.gmail.com>
Message-ID: <02A6F984-9A2F-47E4-9CC5-904592BE6803@gmail.com>

Offhand, I'd say that if "all protects get unprotected before return"
mydata->ans is not protected against garbage collection, and thus very likely collected and reused. If mydata is created by Calloc, the GC has no way of knowing that it might have pointers to things that are intended to persist. 

I haven't played with external pointers for a while, but I'd expect that you'd need to retain a PROTECT on mydata->ans, and then UNPROTECT_PTR or so in the finalizer.

-pd

On 16 Dec 2013, at 04:11 , Krzysztof Mlynarczyk <mitomaster at gmail.com> wrote:

> Dear Developers,
> 
> 
> I've been struggling through writing R extension in C. I've been using
> an external pointer to store my data (please see sample below). I
> encountered a very weird erroneous behaviour: when I tried to use my
> external pointer to a structure holding several types of data,
> including SEXPs, I discovered that SEXPs change their types between
> returning from initialization function and another one that uses the
> pointer.
> 
> sample R code:
> 
> # initializing
> a <- init_my_ptr(fname)
> 
> # reading more data: error!
> df <- read_my_data(a)
> 
> data structure in C:
> typedef struct {
>  SEXP ans, ans_nms, R_z, R_a, R_b, R_c;
>  FTYPE *datafile;
>  char *fname;
>  float *a, *b, *c;
>  int f_type;
>  float t, p, l;
>  int st, na, result, bFlags;
>  XXX z;
> } my_data_ptr;
> 
> // In a C function initializing the external pointer:
> my_data_ptr *mydata = Calloc( 1, my_data_ptr ) ;
> SEXP Rdata;
> PROTECT(Rdata = R_MakeExternalPtr( mydata, R_fname, R_NilValue ));
> ...
> mydata->a = Calloc(mydata->na, float);
> // same for b and c
> // initializing names so that I could use e.g. df$a where df is
> returned by read_my_data()
> PROTECT(mydata->ans_nms = Rf_allocVector(STRSXP, efldNR ));
>  for( ix = 0; ix < efldNR; ix++ )
>    SET_STRING_ELT(mydata->ans_nms, ix, mkChar(vnames[ix]));
> 
> // later I bind values of non-R variables from my data structure to a
> proper vector
> PROTECT(mydata->ans = Rf_allocVector(VECSXP, efldNR ));
> 
>  Rf_setAttrib(mydata->ans, R_NamesSymbol, mytraj->ans_nms);
>  SET_VECTOR_ELT(mydata->ans, 0,      mydata->R_a );
>  SET_VECTOR_ELT(mydata->ans, 1,      mydata->R_b );
> ...
> // all protects get unprotected before return
> // finalizer is registered as well
> return Rdata;
> 
> Later on in read_my_data() I read the pointer:
> my_data_ptr *mydata = (my_data_ptr*) R_ExternalPtrAddr(Rdata);
> 
> // and REAL(mydata->R_a) yields error since TYPEOF(mydata->R_a) is not
> REALSXP as it should be but RAWSXP for some reason // (sometimes it's
> STRSXP or INTSXP while it should always be REALSXP)
> // The error message says:
> // REAL() can only be applied to a 'numeric', not a 'raw'
> 
> // mydata->ans is the object returned to R where all the data is made
> available to R user:
> return mydata->ans;
> 
> // end of example code
> 
> Could you please point the possible reasons for the error along with
> the ways of fixing this issue? I've been trying in R-3.0.2, 3.0.1 and
> even 2.15 -- the problem happens in each of them.
> 
> 
> Regards,
> Christopher
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Peter Dalgaard, Professor
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From mitomaster at gmail.com  Mon Dec 16 12:07:22 2013
From: mitomaster at gmail.com (Krzysztof Mlynarczyk)
Date: Mon, 16 Dec 2013 12:07:22 +0100
Subject: [Rd] External pointers and changing SEXPTYPE
In-Reply-To: <02A6F984-9A2F-47E4-9CC5-904592BE6803@gmail.com>
References: <CAPxYnfpR=0bVy2m2214f7765MBDmGupFs6=VB7L5K7cH35Z5Ng@mail.gmail.com>
	<02A6F984-9A2F-47E4-9CC5-904592BE6803@gmail.com>
Message-ID: <CAPxYnfpj-Z0SNEFdNW33vr+GZLzD8nD_vCEUacfEUA0Mi_Q-9Q@mail.gmail.com>

As far as I understood the documentation, external pointer should be
automatically protected from gc when returned to environment. The
solution you've just suggested would cause stack imbalance.
Recently I've been thinking of encapsulating the pointer into a nice
object using Rcpp. This sounds better that telling people to have fun
with an external pointer itself.

KM

2013/12/16 peter dalgaard <pdalgd at gmail.com>:
> Offhand, I'd say that if "all protects get unprotected before return"
> mydata->ans is not protected against garbage collection, and thus very likely collected and reused. If mydata is created by Calloc, the GC has no way of knowing that it might have pointers to things that are intended to persist.
>
> I haven't played with external pointers for a while, but I'd expect that you'd need to retain a PROTECT on mydata->ans, and then UNPROTECT_PTR or so in the finalizer.
>
> -pd
>
> On 16 Dec 2013, at 04:11 , Krzysztof Mlynarczyk <mitomaster at gmail.com> wrote:
>
>> Dear Developers,
>>
>>
>> I've been struggling through writing R extension in C. I've been using
>> an external pointer to store my data (please see sample below). I
>> encountered a very weird erroneous behaviour: when I tried to use my
>> external pointer to a structure holding several types of data,
>> including SEXPs, I discovered that SEXPs change their types between
>> returning from initialization function and another one that uses the
>> pointer.
>>
>> sample R code:
>>
>> # initializing
>> a <- init_my_ptr(fname)
>>
>> # reading more data: error!
>> df <- read_my_data(a)
>>
>> data structure in C:
>> typedef struct {
>>  SEXP ans, ans_nms, R_z, R_a, R_b, R_c;
>>  FTYPE *datafile;
>>  char *fname;
>>  float *a, *b, *c;
>>  int f_type;
>>  float t, p, l;
>>  int st, na, result, bFlags;
>>  XXX z;
>> } my_data_ptr;
>>
>> // In a C function initializing the external pointer:
>> my_data_ptr *mydata = Calloc( 1, my_data_ptr ) ;
>> SEXP Rdata;
>> PROTECT(Rdata = R_MakeExternalPtr( mydata, R_fname, R_NilValue ));
>> ...
>> mydata->a = Calloc(mydata->na, float);
>> // same for b and c
>> // initializing names so that I could use e.g. df$a where df is
>> returned by read_my_data()
>> PROTECT(mydata->ans_nms = Rf_allocVector(STRSXP, efldNR ));
>>  for( ix = 0; ix < efldNR; ix++ )
>>    SET_STRING_ELT(mydata->ans_nms, ix, mkChar(vnames[ix]));
>>
>> // later I bind values of non-R variables from my data structure to a
>> proper vector
>> PROTECT(mydata->ans = Rf_allocVector(VECSXP, efldNR ));
>>
>>  Rf_setAttrib(mydata->ans, R_NamesSymbol, mytraj->ans_nms);
>>  SET_VECTOR_ELT(mydata->ans, 0,      mydata->R_a );
>>  SET_VECTOR_ELT(mydata->ans, 1,      mydata->R_b );
>> ...
>> // all protects get unprotected before return
>> // finalizer is registered as well
>> return Rdata;
>>
>> Later on in read_my_data() I read the pointer:
>> my_data_ptr *mydata = (my_data_ptr*) R_ExternalPtrAddr(Rdata);
>>
>> // and REAL(mydata->R_a) yields error since TYPEOF(mydata->R_a) is not
>> REALSXP as it should be but RAWSXP for some reason // (sometimes it's
>> STRSXP or INTSXP while it should always be REALSXP)
>> // The error message says:
>> // REAL() can only be applied to a 'numeric', not a 'raw'
>>
>> // mydata->ans is the object returned to R where all the data is made
>> available to R user:
>> return mydata->ans;
>>
>> // end of example code
>>
>> Could you please point the possible reasons for the error along with
>> the ways of fixing this issue? I've been trying in R-3.0.2, 3.0.1 and
>> even 2.15 -- the problem happens in each of them.
>>
>>
>> Regards,
>> Christopher
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> --
> Peter Dalgaard, Professor
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>


From romain at r-enthusiasts.com  Mon Dec 16 12:15:40 2013
From: romain at r-enthusiasts.com (=?iso-8859-1?Q?Romain_Fran=E7ois?=)
Date: Mon, 16 Dec 2013 12:15:40 +0100
Subject: [Rd] External pointers and changing SEXPTYPE
In-Reply-To: <CAPxYnfpj-Z0SNEFdNW33vr+GZLzD8nD_vCEUacfEUA0Mi_Q-9Q@mail.gmail.com>
References: <CAPxYnfpR=0bVy2m2214f7765MBDmGupFs6=VB7L5K7cH35Z5Ng@mail.gmail.com>
	<02A6F984-9A2F-47E4-9CC5-904592BE6803@gmail.com>
	<CAPxYnfpj-Z0SNEFdNW33vr+GZLzD8nD_vCEUacfEUA0Mi_Q-9Q@mail.gmail.com>
Message-ID: <DA03CB77-EBB1-49B5-84E7-007F2B559EB2@r-enthusiasts.com>

Hi, 

One solution to protect an object from the GC is to use the R_PreserveObject and R_ReleaseObject functions. 

This way, you are not subject to the stack that PROTECT, UNPROTECT, UNPROTECT_PTR uses. 

Using R_PreserveObject and R_ReleaseObject is one of the best things that has ever happened to Rcpp. 

Romain

Le 16 d?c. 2013 ? 12:07, Krzysztof Mlynarczyk <mitomaster at gmail.com> a ?crit :

> As far as I understood the documentation, external pointer should be
> automatically protected from gc when returned to environment. The
> solution you've just suggested would cause stack imbalance.
> Recently I've been thinking of encapsulating the pointer into a nice
> object using Rcpp. This sounds better that telling people to have fun
> with an external pointer itself.
> 
> KM
> 
> 2013/12/16 peter dalgaard <pdalgd at gmail.com>:
>> Offhand, I'd say that if "all protects get unprotected before return"
>> mydata->ans is not protected against garbage collection, and thus very likely collected and reused. If mydata is created by Calloc, the GC has no way of knowing that it might have pointers to things that are intended to persist.
>> 
>> I haven't played with external pointers for a while, but I'd expect that you'd need to retain a PROTECT on mydata->ans, and then UNPROTECT_PTR or so in the finalizer.
>> 
>> -pd
>> 
>> On 16 Dec 2013, at 04:11 , Krzysztof Mlynarczyk <mitomaster at gmail.com> wrote:
>> 
>>> Dear Developers,
>>> 
>>> 
>>> I've been struggling through writing R extension in C. I've been using
>>> an external pointer to store my data (please see sample below). I
>>> encountered a very weird erroneous behaviour: when I tried to use my
>>> external pointer to a structure holding several types of data,
>>> including SEXPs, I discovered that SEXPs change their types between
>>> returning from initialization function and another one that uses the
>>> pointer.
>>> 
>>> sample R code:
>>> 
>>> # initializing
>>> a <- init_my_ptr(fname)
>>> 
>>> # reading more data: error!
>>> df <- read_my_data(a)
>>> 
>>> data structure in C:
>>> typedef struct {
>>> SEXP ans, ans_nms, R_z, R_a, R_b, R_c;
>>> FTYPE *datafile;
>>> char *fname;
>>> float *a, *b, *c;
>>> int f_type;
>>> float t, p, l;
>>> int st, na, result, bFlags;
>>> XXX z;
>>> } my_data_ptr;
>>> 
>>> // In a C function initializing the external pointer:
>>> my_data_ptr *mydata = Calloc( 1, my_data_ptr ) ;
>>> SEXP Rdata;
>>> PROTECT(Rdata = R_MakeExternalPtr( mydata, R_fname, R_NilValue ));
>>> ...
>>> mydata->a = Calloc(mydata->na, float);
>>> // same for b and c
>>> // initializing names so that I could use e.g. df$a where df is
>>> returned by read_my_data()
>>> PROTECT(mydata->ans_nms = Rf_allocVector(STRSXP, efldNR ));
>>> for( ix = 0; ix < efldNR; ix++ )
>>>   SET_STRING_ELT(mydata->ans_nms, ix, mkChar(vnames[ix]));
>>> 
>>> // later I bind values of non-R variables from my data structure to a
>>> proper vector
>>> PROTECT(mydata->ans = Rf_allocVector(VECSXP, efldNR ));
>>> 
>>> Rf_setAttrib(mydata->ans, R_NamesSymbol, mytraj->ans_nms);
>>> SET_VECTOR_ELT(mydata->ans, 0,      mydata->R_a );
>>> SET_VECTOR_ELT(mydata->ans, 1,      mydata->R_b );
>>> ...
>>> // all protects get unprotected before return
>>> // finalizer is registered as well
>>> return Rdata;
>>> 
>>> Later on in read_my_data() I read the pointer:
>>> my_data_ptr *mydata = (my_data_ptr*) R_ExternalPtrAddr(Rdata);
>>> 
>>> // and REAL(mydata->R_a) yields error since TYPEOF(mydata->R_a) is not
>>> REALSXP as it should be but RAWSXP for some reason // (sometimes it's
>>> STRSXP or INTSXP while it should always be REALSXP)
>>> // The error message says:
>>> // REAL() can only be applied to a 'numeric', not a 'raw'
>>> 
>>> // mydata->ans is the object returned to R where all the data is made
>>> available to R user:
>>> return mydata->ans;
>>> 
>>> // end of example code
>>> 
>>> Could you please point the possible reasons for the error along with
>>> the ways of fixing this issue? I've been trying in R-3.0.2, 3.0.1 and
>>> even 2.15 -- the problem happens in each of them.
>>> 
>>> 
>>> Regards,
>>> Christopher
>>> 
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> 
>> --
>> Peter Dalgaard, Professor
>> Center for Statistics, Copenhagen Business School
>> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
>> Phone: (+45)38153501
>> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>> 
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From ripley at stats.ox.ac.uk  Mon Dec 16 12:17:03 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 16 Dec 2013 11:17:03 +0000
Subject: [Rd] External pointers and changing SEXPTYPE
In-Reply-To: <CAPxYnfpj-Z0SNEFdNW33vr+GZLzD8nD_vCEUacfEUA0Mi_Q-9Q@mail.gmail.com>
References: <CAPxYnfpR=0bVy2m2214f7765MBDmGupFs6=VB7L5K7cH35Z5Ng@mail.gmail.com>	<02A6F984-9A2F-47E4-9CC5-904592BE6803@gmail.com>
	<CAPxYnfpj-Z0SNEFdNW33vr+GZLzD8nD_vCEUacfEUA0Mi_Q-9Q@mail.gmail.com>
Message-ID: <52AEE12F.1090506@stats.ox.ac.uk>

On 16/12/2013 11:07, Krzysztof Mlynarczyk wrote:
> As far as I understood the documentation, external pointer should be
> automatically protected from gc when returned to environment. The

Yes, but you didn't give us the complete reproducible example the 
posting guide asks for.  Peter's diagnosis is very likely right, but you 
have failed to give us anything like enough to go on.

> solution you've just suggested would cause stack imbalance.

It would not work anyway: the pointer stack top is reset when .Call (or 
similar) returns.

There is R_PreserveObject for this purpose.

> Recently I've been thinking of encapsulating the pointer into a nice
> object using Rcpp. This sounds better that telling people to have fun
> with an external pointer itself.
>
> KM
>
> 2013/12/16 peter dalgaard <pdalgd at gmail.com>:
>> Offhand, I'd say that if "all protects get unprotected before return"
>> mydata->ans is not protected against garbage collection, and thus very likely collected and reused. If mydata is created by Calloc, the GC has no way of knowing that it might have pointers to things that are intended to persist.
>>
>> I haven't played with external pointers for a while, but I'd expect that you'd need to retain a PROTECT on mydata->ans, and then UNPROTECT_PTR or so in the finalizer.
>>
>> -pd
>>
>> On 16 Dec 2013, at 04:11 , Krzysztof Mlynarczyk <mitomaster at gmail.com> wrote:
>>
>>> Dear Developers,
>>>
>>>
>>> I've been struggling through writing R extension in C. I've been using
>>> an external pointer to store my data (please see sample below). I
>>> encountered a very weird erroneous behaviour: when I tried to use my
>>> external pointer to a structure holding several types of data,
>>> including SEXPs, I discovered that SEXPs change their types between
>>> returning from initialization function and another one that uses the
>>> pointer.
>>>
>>> sample R code:
>>>
>>> # initializing
>>> a <- init_my_ptr(fname)
>>>
>>> # reading more data: error!
>>> df <- read_my_data(a)
>>>
>>> data structure in C:
>>> typedef struct {
>>>   SEXP ans, ans_nms, R_z, R_a, R_b, R_c;
>>>   FTYPE *datafile;
>>>   char *fname;
>>>   float *a, *b, *c;
>>>   int f_type;
>>>   float t, p, l;
>>>   int st, na, result, bFlags;
>>>   XXX z;
>>> } my_data_ptr;
>>>
>>> // In a C function initializing the external pointer:
>>> my_data_ptr *mydata = Calloc( 1, my_data_ptr ) ;
>>> SEXP Rdata;
>>> PROTECT(Rdata = R_MakeExternalPtr( mydata, R_fname, R_NilValue ));
>>> ...
>>> mydata->a = Calloc(mydata->na, float);
>>> // same for b and c
>>> // initializing names so that I could use e.g. df$a where df is
>>> returned by read_my_data()
>>> PROTECT(mydata->ans_nms = Rf_allocVector(STRSXP, efldNR ));
>>>   for( ix = 0; ix < efldNR; ix++ )
>>>     SET_STRING_ELT(mydata->ans_nms, ix, mkChar(vnames[ix]));
>>>
>>> // later I bind values of non-R variables from my data structure to a
>>> proper vector
>>> PROTECT(mydata->ans = Rf_allocVector(VECSXP, efldNR ));
>>>
>>>   Rf_setAttrib(mydata->ans, R_NamesSymbol, mytraj->ans_nms);
>>>   SET_VECTOR_ELT(mydata->ans, 0,      mydata->R_a );
>>>   SET_VECTOR_ELT(mydata->ans, 1,      mydata->R_b );
>>> ...
>>> // all protects get unprotected before return
>>> // finalizer is registered as well
>>> return Rdata;
>>>
>>> Later on in read_my_data() I read the pointer:
>>> my_data_ptr *mydata = (my_data_ptr*) R_ExternalPtrAddr(Rdata);
>>>
>>> // and REAL(mydata->R_a) yields error since TYPEOF(mydata->R_a) is not
>>> REALSXP as it should be but RAWSXP for some reason // (sometimes it's
>>> STRSXP or INTSXP while it should always be REALSXP)
>>> // The error message says:
>>> // REAL() can only be applied to a 'numeric', not a 'raw'
>>>
>>> // mydata->ans is the object returned to R where all the data is made
>>> available to R user:
>>> return mydata->ans;
>>>
>>> // end of example code
>>>
>>> Could you please point the possible reasons for the error along with
>>> the ways of fixing this issue? I've been trying in R-3.0.2, 3.0.1 and
>>> even 2.15 -- the problem happens in each of them.
>>>
>>>
>>> Regards,
>>> Christopher
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>> --
>> Peter Dalgaard, Professor
>> Center for Statistics, Copenhagen Business School
>> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
>> Phone: (+45)38153501
>> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From mitomaster at gmail.com  Mon Dec 16 18:18:47 2013
From: mitomaster at gmail.com (Krzysztof Mlynarczyk)
Date: Mon, 16 Dec 2013 18:18:47 +0100
Subject: [Rd] External pointers and changing SEXPTYPE
In-Reply-To: <52AEE12F.1090506@stats.ox.ac.uk>
References: <CAPxYnfpR=0bVy2m2214f7765MBDmGupFs6=VB7L5K7cH35Z5Ng@mail.gmail.com>
	<02A6F984-9A2F-47E4-9CC5-904592BE6803@gmail.com>
	<CAPxYnfpj-Z0SNEFdNW33vr+GZLzD8nD_vCEUacfEUA0Mi_Q-9Q@mail.gmail.com>
	<52AEE12F.1090506@stats.ox.ac.uk>
Message-ID: <CAPxYnfp2btvLFUf9t6PQfToXqWVjBd5YXgnfTZresAZXk8ykjw@mail.gmail.com>

Yes, it turned out that using R_PreserveObject and R_ReleaseObject
solved that problem.
I sincerely apologize for posting only several chunks of code.
Fortunately for me, the descritpion I gave was sufficient to track
down what was missing.
Thank you very much!

Chris

2013/12/16 Prof Brian Ripley <ripley at stats.ox.ac.uk>:
> On 16/12/2013 11:07, Krzysztof Mlynarczyk wrote:
>>
>> As far as I understood the documentation, external pointer should be
>> automatically protected from gc when returned to environment. The
>
>
> Yes, but you didn't give us the complete reproducible example the posting
> guide asks for.  Peter's diagnosis is very likely right, but you have failed
> to give us anything like enough to go on.
>
>
>> solution you've just suggested would cause stack imbalance.
>
>
> It would not work anyway: the pointer stack top is reset when .Call (or
> similar) returns.
>
> There is R_PreserveObject for this purpose.
>
>
>> Recently I've been thinking of encapsulating the pointer into a nice
>> object using Rcpp. This sounds better that telling people to have fun
>> with an external pointer itself.
>>
>> KM
>>
>> 2013/12/16 peter dalgaard <pdalgd at gmail.com>:
>>>
>>> Offhand, I'd say that if "all protects get unprotected before return"
>>> mydata->ans is not protected against garbage collection, and thus very
>>> likely collected and reused. If mydata is created by Calloc, the GC has no
>>> way of knowing that it might have pointers to things that are intended to
>>> persist.
>>>
>>> I haven't played with external pointers for a while, but I'd expect that
>>> you'd need to retain a PROTECT on mydata->ans, and then UNPROTECT_PTR or so
>>> in the finalizer.
>>>
>>> -pd
>>>
>>> On 16 Dec 2013, at 04:11 , Krzysztof Mlynarczyk <mitomaster at gmail.com>
>>> wrote:
>>>
>>>> Dear Developers,
>>>>
>>>>
>>>> I've been struggling through writing R extension in C. I've been using
>>>> an external pointer to store my data (please see sample below). I
>>>> encountered a very weird erroneous behaviour: when I tried to use my
>>>> external pointer to a structure holding several types of data,
>>>> including SEXPs, I discovered that SEXPs change their types between
>>>> returning from initialization function and another one that uses the
>>>> pointer.
>>>>
>>>> sample R code:
>>>>
>>>> # initializing
>>>> a <- init_my_ptr(fname)
>>>>
>>>> # reading more data: error!
>>>> df <- read_my_data(a)
>>>>
>>>> data structure in C:
>>>> typedef struct {
>>>>   SEXP ans, ans_nms, R_z, R_a, R_b, R_c;
>>>>   FTYPE *datafile;
>>>>   char *fname;
>>>>   float *a, *b, *c;
>>>>   int f_type;
>>>>   float t, p, l;
>>>>   int st, na, result, bFlags;
>>>>   XXX z;
>>>> } my_data_ptr;
>>>>
>>>> // In a C function initializing the external pointer:
>>>> my_data_ptr *mydata = Calloc( 1, my_data_ptr ) ;
>>>> SEXP Rdata;
>>>> PROTECT(Rdata = R_MakeExternalPtr( mydata, R_fname, R_NilValue ));
>>>> ...
>>>> mydata->a = Calloc(mydata->na, float);
>>>> // same for b and c
>>>> // initializing names so that I could use e.g. df$a where df is
>>>> returned by read_my_data()
>>>> PROTECT(mydata->ans_nms = Rf_allocVector(STRSXP, efldNR ));
>>>>   for( ix = 0; ix < efldNR; ix++ )
>>>>     SET_STRING_ELT(mydata->ans_nms, ix, mkChar(vnames[ix]));
>>>>
>>>> // later I bind values of non-R variables from my data structure to a
>>>> proper vector
>>>> PROTECT(mydata->ans = Rf_allocVector(VECSXP, efldNR ));
>>>>
>>>>   Rf_setAttrib(mydata->ans, R_NamesSymbol, mytraj->ans_nms);
>>>>   SET_VECTOR_ELT(mydata->ans, 0,      mydata->R_a );
>>>>   SET_VECTOR_ELT(mydata->ans, 1,      mydata->R_b );
>>>> ...
>>>> // all protects get unprotected before return
>>>> // finalizer is registered as well
>>>> return Rdata;
>>>>
>>>> Later on in read_my_data() I read the pointer:
>>>> my_data_ptr *mydata = (my_data_ptr*) R_ExternalPtrAddr(Rdata);
>>>>
>>>> // and REAL(mydata->R_a) yields error since TYPEOF(mydata->R_a) is not
>>>> REALSXP as it should be but RAWSXP for some reason // (sometimes it's
>>>> STRSXP or INTSXP while it should always be REALSXP)
>>>> // The error message says:
>>>> // REAL() can only be applied to a 'numeric', not a 'raw'
>>>>
>>>> // mydata->ans is the object returned to R where all the data is made
>>>> available to R user:
>>>> return mydata->ans;
>>>>
>>>> // end of example code
>>>>
>>>> Could you please point the possible reasons for the error along with
>>>> the ways of fixing this issue? I've been trying in R-3.0.2, 3.0.1 and
>>>> even 2.15 -- the problem happens in each of them.
>>>>
>>>>
>>>> Regards,
>>>> Christopher
>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>>
>>> --
>>> Peter Dalgaard, Professor
>>> Center for Statistics, Copenhagen Business School
>>> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
>>> Phone: (+45)38153501
>>> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>>>
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
>
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From mtmorgan at fhcrc.org  Mon Dec 16 19:00:11 2013
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Mon, 16 Dec 2013 10:00:11 -0800
Subject: [Rd] External pointers and changing SEXPTYPE
In-Reply-To: <CAPxYnfp2btvLFUf9t6PQfToXqWVjBd5YXgnfTZresAZXk8ykjw@mail.gmail.com>
References: <CAPxYnfpR=0bVy2m2214f7765MBDmGupFs6=VB7L5K7cH35Z5Ng@mail.gmail.com>	<02A6F984-9A2F-47E4-9CC5-904592BE6803@gmail.com>	<CAPxYnfpj-Z0SNEFdNW33vr+GZLzD8nD_vCEUacfEUA0Mi_Q-9Q@mail.gmail.com>	<52AEE12F.1090506@stats.ox.ac.uk>
	<CAPxYnfp2btvLFUf9t6PQfToXqWVjBd5YXgnfTZresAZXk8ykjw@mail.gmail.com>
Message-ID: <52AF3FAB.2070609@fhcrc.org>

On 12/16/2013 09:18 AM, Krzysztof Mlynarczyk wrote:
> Yes, it turned out that using R_PreserveObject and R_ReleaseObject
> solved that problem.

Instead I think you want to use the third argument to R_MakeExternalPtr to 
protect the SEXP's you'd like to persist for the duration of the object, maybe 
having bundled your ans, ans_nms, R_z, R_a, R_b, R_c into a list. This is 
suggested by the argument name 'prot' and description in Writing R Extensions 
section 5.13.

Martin


> I sincerely apologize for posting only several chunks of code.
> Fortunately for me, the descritpion I gave was sufficient to track
> down what was missing.
> Thank you very much!
>
> Chris
>
> 2013/12/16 Prof Brian Ripley <ripley at stats.ox.ac.uk>:
>> On 16/12/2013 11:07, Krzysztof Mlynarczyk wrote:
>>>
>>> As far as I understood the documentation, external pointer should be
>>> automatically protected from gc when returned to environment. The
>>
>>
>> Yes, but you didn't give us the complete reproducible example the posting
>> guide asks for.  Peter's diagnosis is very likely right, but you have failed
>> to give us anything like enough to go on.
>>
>>
>>> solution you've just suggested would cause stack imbalance.
>>
>>
>> It would not work anyway: the pointer stack top is reset when .Call (or
>> similar) returns.
>>
>> There is R_PreserveObject for this purpose.
>>
>>
>>> Recently I've been thinking of encapsulating the pointer into a nice
>>> object using Rcpp. This sounds better that telling people to have fun
>>> with an external pointer itself.
>>>
>>> KM
>>>
>>> 2013/12/16 peter dalgaard <pdalgd at gmail.com>:
>>>>
>>>> Offhand, I'd say that if "all protects get unprotected before return"
>>>> mydata->ans is not protected against garbage collection, and thus very
>>>> likely collected and reused. If mydata is created by Calloc, the GC has no
>>>> way of knowing that it might have pointers to things that are intended to
>>>> persist.
>>>>
>>>> I haven't played with external pointers for a while, but I'd expect that
>>>> you'd need to retain a PROTECT on mydata->ans, and then UNPROTECT_PTR or so
>>>> in the finalizer.
>>>>
>>>> -pd
>>>>
>>>> On 16 Dec 2013, at 04:11 , Krzysztof Mlynarczyk <mitomaster at gmail.com>
>>>> wrote:
>>>>
>>>>> Dear Developers,
>>>>>
>>>>>
>>>>> I've been struggling through writing R extension in C. I've been using
>>>>> an external pointer to store my data (please see sample below). I
>>>>> encountered a very weird erroneous behaviour: when I tried to use my
>>>>> external pointer to a structure holding several types of data,
>>>>> including SEXPs, I discovered that SEXPs change their types between
>>>>> returning from initialization function and another one that uses the
>>>>> pointer.
>>>>>
>>>>> sample R code:
>>>>>
>>>>> # initializing
>>>>> a <- init_my_ptr(fname)
>>>>>
>>>>> # reading more data: error!
>>>>> df <- read_my_data(a)
>>>>>
>>>>> data structure in C:
>>>>> typedef struct {
>>>>>    SEXP ans, ans_nms, R_z, R_a, R_b, R_c;
>>>>>    FTYPE *datafile;
>>>>>    char *fname;
>>>>>    float *a, *b, *c;
>>>>>    int f_type;
>>>>>    float t, p, l;
>>>>>    int st, na, result, bFlags;
>>>>>    XXX z;
>>>>> } my_data_ptr;
>>>>>
>>>>> // In a C function initializing the external pointer:
>>>>> my_data_ptr *mydata = Calloc( 1, my_data_ptr ) ;
>>>>> SEXP Rdata;
>>>>> PROTECT(Rdata = R_MakeExternalPtr( mydata, R_fname, R_NilValue ));
>>>>> ...
>>>>> mydata->a = Calloc(mydata->na, float);
>>>>> // same for b and c
>>>>> // initializing names so that I could use e.g. df$a where df is
>>>>> returned by read_my_data()
>>>>> PROTECT(mydata->ans_nms = Rf_allocVector(STRSXP, efldNR ));
>>>>>    for( ix = 0; ix < efldNR; ix++ )
>>>>>      SET_STRING_ELT(mydata->ans_nms, ix, mkChar(vnames[ix]));
>>>>>
>>>>> // later I bind values of non-R variables from my data structure to a
>>>>> proper vector
>>>>> PROTECT(mydata->ans = Rf_allocVector(VECSXP, efldNR ));
>>>>>
>>>>>    Rf_setAttrib(mydata->ans, R_NamesSymbol, mytraj->ans_nms);
>>>>>    SET_VECTOR_ELT(mydata->ans, 0,      mydata->R_a );
>>>>>    SET_VECTOR_ELT(mydata->ans, 1,      mydata->R_b );
>>>>> ...
>>>>> // all protects get unprotected before return
>>>>> // finalizer is registered as well
>>>>> return Rdata;
>>>>>
>>>>> Later on in read_my_data() I read the pointer:
>>>>> my_data_ptr *mydata = (my_data_ptr*) R_ExternalPtrAddr(Rdata);
>>>>>
>>>>> // and REAL(mydata->R_a) yields error since TYPEOF(mydata->R_a) is not
>>>>> REALSXP as it should be but RAWSXP for some reason // (sometimes it's
>>>>> STRSXP or INTSXP while it should always be REALSXP)
>>>>> // The error message says:
>>>>> // REAL() can only be applied to a 'numeric', not a 'raw'
>>>>>
>>>>> // mydata->ans is the object returned to R where all the data is made
>>>>> available to R user:
>>>>> return mydata->ans;
>>>>>
>>>>> // end of example code
>>>>>
>>>>> Could you please point the possible reasons for the error along with
>>>>> the ways of fixing this issue? I've been trying in R-3.0.2, 3.0.1 and
>>>>> even 2.15 -- the problem happens in each of them.
>>>>>
>>>>>
>>>>> Regards,
>>>>> Christopher
>>>>>
>>>>> ______________________________________________
>>>>> R-devel at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>
>>>>
>>>> --
>>>> Peter Dalgaard, Professor
>>>> Center for Statistics, Copenhagen Business School
>>>> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
>>>> Phone: (+45)38153501
>>>> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>>>>
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>
>>
>> --
>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>> University of Oxford,             Tel:  +44 1865 272861 (self)
>> 1 South Parks Road,                     +44 1865 272866 (PA)
>> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


-- 
Computational Biology / Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N.
PO Box 19024 Seattle, WA 98109

Location: Arnold Building M1 B861
Phone: (206) 667-2793


From hb at biostat.ucsf.edu  Tue Dec 17 22:44:48 2013
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Tue, 17 Dec 2013 13:44:48 -0800
Subject: [Rd] In-string variable/symbol substitution: What formats/syntax is
	out there?
Message-ID: <CAFDcVCQ-fXQh3Hm6EDji-Nuv1Pk53=n2fM=KH++HLO0-xbSVvg@mail.gmail.com>

Hi,

I'm try to collect a list of methods/packages available in R for doing
in-string variable/symbol substitution, e.g. someFcn("pi=${pi}"),
anotherFcn("pi=@pi@") and so on becomes "pi=3.141593".  I am aware of
the following:

** gsubfn() in the 'gsubfn' package, e.g.
> gsubfn( , , "pi = $pi, 2pi = `2*pi`")
[1] "pi = 3.14159265358979, 2pi = 6.28318530717959"


** gstring() in the 'R.utils' package, e.g.
> gstring("pi = ${pi}, 2pi = ${`2*pi`}")
[1] "pi = 3.14159265358979, 2pi = 6.28318530717959"


I'm sure there are other approaches - do you know of any in R?  They
don't have to support in-line calculations such as in the first two
examples, but if they do, it's a bonus.  I'm looking for simpler
functions and not full blown literate programming methods (e.g.
Sweave, noweb, knitr, brew, RSP, ...).  It should also be *in-string*
substitution out of the box, so sub(), sprintf() and friends does not
count.

Thanks

Henrik

PS. The following is on the borderline because it does not do
automatic variable look up, but since others may bring it up and/or
know of a neater approach, I mention it too:

** copySubstitute() in the 'Biobase' package (with some efforts), e.g.
> bbsubst <- function(fmt, ...) {
  args <- lapply(list(...), FUN=as.character)
  in <- textConnection(fmt)
  out <- textConnection("res", open="w")
  on.exit({ close(in); close(out) })
  copySubstitute(in, out, symbolValues=args)
  res
}
> bbsubst("pi = @pi@", pi=pi)
[1] "pi = 3.14159265358979"


From murdoch.duncan at gmail.com  Tue Dec 17 23:00:08 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 17 Dec 2013 17:00:08 -0500
Subject: [Rd] In-string variable/symbol substitution: What
 formats/syntax is out there?
In-Reply-To: <CAFDcVCQ-fXQh3Hm6EDji-Nuv1Pk53=n2fM=KH++HLO0-xbSVvg@mail.gmail.com>
References: <CAFDcVCQ-fXQh3Hm6EDji-Nuv1Pk53=n2fM=KH++HLO0-xbSVvg@mail.gmail.com>
Message-ID: <52B0C968.70509@gmail.com>

On 13-12-17 4:44 PM, Henrik Bengtsson wrote:
> Hi,
>
> I'm try to collect a list of methods/packages available in R for doing
> in-string variable/symbol substitution, e.g. someFcn("pi=${pi}"),
> anotherFcn("pi=@pi@") and so on becomes "pi=3.141593".  I am aware of
> the following:
>
> ** gsubfn() in the 'gsubfn' package, e.g.
>> gsubfn( , , "pi = $pi, 2pi = `2*pi`")
> [1] "pi = 3.14159265358979, 2pi = 6.28318530717959"
>
>
> ** gstring() in the 'R.utils' package, e.g.
>> gstring("pi = ${pi}, 2pi = ${`2*pi`}")
> [1] "pi = 3.14159265358979, 2pi = 6.28318530717959"
>
>
> I'm sure there are other approaches - do you know of any in R?  They
> don't have to support in-line calculations such as in the first two
> examples, but if they do, it's a bonus.  I'm looking for simpler
> functions and not full blown literate programming methods (e.g.
> Sweave, noweb, knitr, brew, RSP, ...).  It should also be *in-string*
> substitution out of the box, so sub(), sprintf() and friends does not
> count.

rgl has a function subst() used internally, mainly for substitutions in 
the Javascript that writeWebGL writes.

The equivalent of your example above would be

rgl:::subst("pi = %pi%, 2pi = %twopi%", pi = pi, twopi = 2*pi)

i.e. general expressions aren't supported, just specific named 
substitutions.

Duncan Murdoch

>
> Thanks
>
> Henrik
>
> PS. The following is on the borderline because it does not do
> automatic variable look up, but since others may bring it up and/or
> know of a neater approach, I mention it too:
>
> ** copySubstitute() in the 'Biobase' package (with some efforts), e.g.
>> bbsubst <- function(fmt, ...) {
>    args <- lapply(list(...), FUN=as.character)
>    in <- textConnection(fmt)
>    out <- textConnection("res", open="w")
>    on.exit({ close(in); close(out) })
>    copySubstitute(in, out, symbolValues=args)
>    res
> }
>> bbsubst("pi = @pi@", pi=pi)
> [1] "pi = 3.14159265358979"
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From peter.meilstrup at gmail.com  Tue Dec 17 23:08:51 2013
From: peter.meilstrup at gmail.com (Peter Meilstrup)
Date: Tue, 17 Dec 2013 14:08:51 -0800
Subject: [Rd] In-string variable/symbol substitution: What
 formats/syntax is out there?
In-Reply-To: <CAFDcVCQ-fXQh3Hm6EDji-Nuv1Pk53=n2fM=KH++HLO0-xbSVvg@mail.gmail.com>
References: <CAFDcVCQ-fXQh3Hm6EDji-Nuv1Pk53=n2fM=KH++HLO0-xbSVvg@mail.gmail.com>
Message-ID: <CAJoaRhaFt=mfSzNVH5KfnXffuEUqp6ZAVLyv2Gw-s=1dG1U1rg@mail.gmail.com>

There's also knit_expand() in knitr, which uses the form "pi = {{pi}}"
with general expressions.

Peter

On Tue, Dec 17, 2013 at 1:44 PM, Henrik Bengtsson <hb at biostat.ucsf.edu> wrote:
> Hi,
>
> I'm try to collect a list of methods/packages available in R for doing
> in-string variable/symbol substitution, e.g. someFcn("pi=${pi}"),
> anotherFcn("pi=@pi@") and so on becomes "pi=3.141593".  I am aware of
> the following:
>
> ** gsubfn() in the 'gsubfn' package, e.g.
>> gsubfn( , , "pi = $pi, 2pi = `2*pi`")
> [1] "pi = 3.14159265358979, 2pi = 6.28318530717959"
>
>
> ** gstring() in the 'R.utils' package, e.g.
>> gstring("pi = ${pi}, 2pi = ${`2*pi`}")
> [1] "pi = 3.14159265358979, 2pi = 6.28318530717959"
>
>
> I'm sure there are other approaches - do you know of any in R?  They
> don't have to support in-line calculations such as in the first two
> examples, but if they do, it's a bonus.  I'm looking for simpler
> functions and not full blown literate programming methods (e.g.
> Sweave, noweb, knitr, brew, RSP, ...).  It should also be *in-string*
> substitution out of the box, so sub(), sprintf() and friends does not
> count.
>
> Thanks
>
> Henrik
>
> PS. The following is on the borderline because it does not do
> automatic variable look up, but since others may bring it up and/or
> know of a neater approach, I mention it too:
>
> ** copySubstitute() in the 'Biobase' package (with some efforts), e.g.
>> bbsubst <- function(fmt, ...) {
>   args <- lapply(list(...), FUN=as.character)
>   in <- textConnection(fmt)
>   out <- textConnection("res", open="w")
>   on.exit({ close(in); close(out) })
>   copySubstitute(in, out, symbolValues=args)
>   res
> }
>> bbsubst("pi = @pi@", pi=pi)
> [1] "pi = 3.14159265358979"
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From htl10 at users.sourceforge.net  Wed Dec 18 01:06:30 2013
From: htl10 at users.sourceforge.net (Hin-Tak Leung)
Date: Wed, 18 Dec 2013 00:06:30 +0000 (GMT)
Subject: [Rd] [R] freetype 2.5.2, problem with the survival package,
	build R 2.15.x with gcc 4.8.x
Message-ID: <1387325190.48859.YahooMailBasic@web133202.mail.ir2.yahoo.com>

------------------------------
On Fri, Dec 13, 2013 16:29 GMT David Winsemius wrote:

>
>On Dec 11, 2013, at 7:30 PM, Hin-Tak Leung wrote:
>
>> Here is a rather long discussion etc about freetype 2.5.2, problem with the survival package, and build R 2.15.x with gcc 4.8.x. Please feel free to skip forward.
>> 
>> - freetype 2.5.2:
>> 
>> the fix to cope with one of the Mac OS X's system fonts just before the release of freetype 2.5.1 caused a regression, crashing over one of Microsoft windows' system fonts. So there is a 2.5.2. There are new 2.5.2 bundles for windows & Mac OS X. The official win/mac binaries of R were built statically with 2+-years-old freetype with a few known problems. Most should upgrade/rebuild.
>> 
>> http://sourceforge.net/projects/outmodedbonsai/files/R/
>> 
>> - problem with the survival package:
>> 
>> Trying to re-run a vignette to get the same result as two years ago
>> reveal a strange change. I went and bisected it down to
>> r11513 and r11516 of the survival package.
>> 
>> -------------- r11513 --------------------
>> clogit(cc ~ addContr(A) + addContr(C) + addContr(A.C) + strata(set))
>> 
>> 
>>? ? ? ? ? ? ? ? ???coef exp(coef) se(coef)? ???z? ? ? p
>> addContr(A)2? ???-0.620? ???0.538? ? 0.217 -2.86 0.0043
>> addContr(C)2? ? ? 0.482? ???1.620? ? 0.217? 2.22 0.0270
>> addContr(A.C)1-2 -0.778? ???0.459? ? 0.275 -2.83 0.0047
>> addContr(A.C)2-1? ???NA? ? ? ? NA? ? 0.000? ? NA? ???NA
>> addContr(A.C)2-2? ???NA? ? ? ? NA? ? 0.000? ? NA? ???NA
>> 
>> Likelihood ratio test=26? on 3 df, p=9.49e-06? n= 13110, number of events= 3524
>> ------------------------------------------
>> 
>> ------------- r11516 ---------------------
>> clogit(cc ~ addContr(A) + addContr(C) + addContr(A.C) + strata(set))
>> 
>> 
>>? ? ? ? ? ? ? ? ? ???coef exp(coef) se(coef)? ? ? ???z? p
>> addContr(A)2? ???-0.14250? ???0.867???110812 -1.29e-06? 1
>> addContr(C)2? ? ? 0.00525? ???1.005???110812? 4.74e-08? 1
>> addContr(A.C)1-2 -0.30097? ???0.740???110812 -2.72e-06? 1
>> addContr(A.C)2-1 -0.47712? ???0.621???110812 -4.31e-06? 1
>> addContr(A.C)2-2? ? ???NA? ? ? ? NA? ? ? ? 0? ? ? ? NA NA
>> 
>> Likelihood ratio test=26? on 4 df, p=3.15e-05? n= 13110, number of events= 3524
>> ------------------------------------------
>> 
>> r11514 does not build, and r11515 have serious memory hogs, so the survival
>> package broke somewhere between r11513 and r11516. Anyway, here is the diff in
>> the vignette, and the data, etc is in the directory above. If somebody want to
>> fix this before I spend any more time on this particular matter, please feel free to do so.
>> 
>> http://sourceforge.net/projects/outmodedbonsai/files/Manuals%2C%20Overviews%20and%20Slides%20for%20talks/2013SummerCourse/practicals/with-answers/practical8_survival-clogit-diff.pdf/download
>> 
>> That's the one problem from David's 10 practicals which are not due to bugs in snpStats. Some might find it reassuring that only 3 of the 4 problems with the practicals are due to snpStats bugs.
>> 
>> http://sourceforge.net/projects/outmodedbonsai/files/Manuals%2C%20Overviews%20and%20Slides%20for%20talks/2013SummerCourse/practicals/with-answers/practical7_snpStatsBug-diff.pdf/download
>> http://sourceforge.net/projects/outmodedbonsai/files/Manuals%2C%20Overviews%20and%20Slides%20for%20talks/2013SummerCourse/practicals/with-answers/practical6_snpStatsBug-diff.pdf/download
>> http://sourceforge.net/projects/outmodedbonsai/files/Manuals%2C%20Overviews%20and%20Slides%20for%20talks/2013SummerCourse/practicals/with-answers/practical3_snpStatsBug-diff.pdf/download
>> 
>> - build R 2.15.x with gcc 4.8.x
>> 
>> I wish the R commit log was a bit more detailed with r62430 than just
>> "tweak needed for gcc 4.8.x". Anyway, building R 2.15.x with gcc 4.8.x
>> could result in segfaults in usage as innocent and essential
>> as running summary() on a data.frame:
>> 
>> --------------------------------
>> *** caught segfault ***
>> address 0x2f8e6a00, cause 'memory not mapped'
>> 
>> Traceback:
>> 1: sort.list(y)
>> 2: factor(a, exclude = exclude)
>> 3: table(object, exclude = NULL)
>> 4: summary.default(X[[3L]], ...)
>> 5: FUN(X[[3L]], ...)
>> 6: lapply(X = as.list(object), FUN = summary, maxsum = maxsum, digits = 12,???...)
>> 7: summary.data.frame(support)
>> ...
>> --------------------------------
>> 
>> r62430 needs a bit of adapting to apply to R 2.15.x , but you get the idea.
>> I hope this info is useful to somebody else who is still using R 2.15.x , no doubt for very good reasons.
>
>First: Sorry for the blank message. Need more coffee.
>
>Second: Does this mean that only Mac users who are still using 2.15.x need to worry about this issue?
>

The freetype issues affects both windows and mac users. Unix users have it easier, since R on unices (*excluding* Mac OS X) dynamically
links to the system's shared freetype, so upgrading at the system level would work. R for windows and Mac OS X are statically linked to
a rather out-dated version of freetype.

The survival package issues affects everybody using R more recent than survival package r11513 
Date:   Wed Feb 1 22:47:36 2012 +0000
    Remove "browser()" line from survobrien,
    add coxexact.fit

>Third: I'm reading this (and Terry's comment about singularity conditions)? to mean that a numerical? discrepancy between vignette output when code was run being from what was expected was causing a segfault under some situation that I cannot quite reconstruct. Was the implication that Mac users (of 2.15.x) need to build from sources only if they wanted to build the survival package from source? Does this have any implications for those of us who use the survival package as the binary? (And I'm using 3.0.2, so a split answer might be needed to cover 2.15.x and the current versions separately)
>

Your comprehension of the issue seem to be entirely wrong. Between r11513 and r11516, some tuning of internal parmeters were done, so the process of finding the rank of a singular matrix no longer converges (within the time/tolerance implicitly specified). There are warnings issued, but then there are misc warnings before and after (and one gets "desensitised" about them). Also the nature of the problem, which is to test for possibility of interactions - or lacking thereof -

outcome ~ factor A + factor B + factor A x factor B

or just extra terms in "outcome ~ factor A + factor B + ..." as an exploration of auxiliary effects, more often than not extra terms won't make
any difference and the matrix involved just isn't the nicest to manipulate; it is in the nature of that kind of exploratory work.

Professor Therneau replied that it is possible to get the older convergent behaviour by manual tuning of some of the convergence criteria parameters; I have responded that while that is possible, often one is simultaneously exploring many models with many possible auxiliary effects (and lacking thereof), manual tuning for each is neither feasible nor appropriate; and we sort of left it at that.

BTW, I trimmed the vignette and the data down - from a 70MB thing - to a 40k and about 20 lines of R code, and put it under *_trimmed.{Rcode/Rda}.
http://sourceforge.net/projects/outmodedbonsai/files/Manuals%2C%20Overviews%20and%20Slides%20for%20talks/2013SummerCourse/practicals/with-answers/

and with the outcomes (*.Rout.*) from R 3.1.0 (R dev trunk), R 2.15.x, and R 2.15.x with survival r11513.

There are also *_memoryhog.{Rcode,Rda}, for those who want to see what's the memory hog problem with r11515. Obviously there is no Rout files, since I had to kill the R process to stop it hogging my system :-).

As for the gcc 4.8.x issue, I rather think describing r62430 as "tweak needed for gcc 4.8.x" is unfortunate. For those who haven't got
R dev trunk history handy, r62430 put a zero at the end of an array of 16 to make it 17-element long. Without it, as I wrote,
R 2.15.x built that way would segfault at very innocent things like doing a summary() on a data.frame. (r62431 is part of R 3.0.0 RC).

However, if put a zero at the end of an array of 16 to make it 17-element long is a "fix" to a segmentation fault, it must mean that the code has always been wrong, and that it had relied on the C compiler to generously pad with nulls on uninitialized memory, for the code to work as intended beforehand. AFAIK, the Sun studio compiler behaves that way, and so does a few proprietary unix system's C compiler; It is notably not true for gcc (the gcc developers largerly think programmers should write good code where the i's are dotted and t's are crossed, instead of having the compiler protecting them from their own oversights); moreover, on recent redhat fedora systems (where gcc 4.8.x is likely the first to land), uninitialized memories are explicitly filled with random non-nulls to foil malwares which utilises and skips nulls (=no-ops) to jump to the next instruction the malware places in memory. So "tweak needed for gcc 4.8.x" just isn't a good
 description for that change.

>-- 
>David.
>> 
>> Hin-Tak Leung wrote:
>> The freetype people fixed the 2nd set of issues with system fonts shipped with
>> Mac OS X, and released 2.5.1 almost immediately after that. So there are
>> new bundles under http://sourceforge.net/projects/outmodedbonsai/files/R/ .
>> 
>> Just a reminder that the official R binaries for windows/mac OS X are statically
>> linked with rather dated versions of freetype with a few known issues. This
>> affects the cairo-based functionalities in R. So a rebuild is needed.
>> 
>> Most unix users should just upgrade their system's libfreetype, and
>> dynamic-linking should take care of the rest.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>David Winsemius
>Alameda, CA, USA
>


From ggrothendieck at gmail.com  Wed Dec 18 05:13:51 2013
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 17 Dec 2013 23:13:51 -0500
Subject: [Rd] In-string variable/symbol substitution: What
 formats/syntax is out there?
In-Reply-To: <CAFDcVCQ-fXQh3Hm6EDji-Nuv1Pk53=n2fM=KH++HLO0-xbSVvg@mail.gmail.com>
References: <CAFDcVCQ-fXQh3Hm6EDji-Nuv1Pk53=n2fM=KH++HLO0-xbSVvg@mail.gmail.com>
Message-ID: <CAP01uRkGbZOyOb=7ONdSSGOrop084q0mVw9LSs5Cx6ZSrqFZUA@mail.gmail.com>

On Tue, Dec 17, 2013 at 4:44 PM, Henrik Bengtsson <hb at biostat.ucsf.edu> wrote:
> Hi,
>
> I'm try to collect a list of methods/packages available in R for doing
> in-string variable/symbol substitution, e.g. someFcn("pi=${pi}"),
> anotherFcn("pi=@pi@") and so on becomes "pi=3.141593".  I am aware of
> the following:
>
> ** gsubfn() in the 'gsubfn' package, e.g.
>> gsubfn( , , "pi = $pi, 2pi = `2*pi`")
> [1] "pi = 3.14159265358979, 2pi = 6.28318530717959"
>
>
> ** gstring() in the 'R.utils' package, e.g.
>> gstring("pi = ${pi}, 2pi = ${`2*pi`}")
> [1] "pi = 3.14159265358979, 2pi = 6.28318530717959"
>
>
> I'm sure there are other approaches - do you know of any in R?  They
> don't have to support in-line calculations such as in the first two
> examples, but if they do, it's a bonus.  I'm looking for simpler
> functions and not full blown literate programming methods (e.g.
> Sweave, noweb, knitr, brew, RSP, ...).  It should also be *in-string*
> substitution out of the box, so sub(), sprintf() and friends does not
> count.
>
> Thanks
>
> Henrik
>
> PS. The following is on the borderline because it does not do
> automatic variable look up, but since others may bring it up and/or
> know of a neater approach, I mention it too:
>
> ** copySubstitute() in the 'Biobase' package (with some efforts), e.g.
>> bbsubst <- function(fmt, ...) {
>   args <- lapply(list(...), FUN=as.character)
>   in <- textConnection(fmt)
>   out <- textConnection("res", open="w")
>   on.exit({ close(in); close(out) })
>   copySubstitute(in, out, symbolValues=args)
>   res
> }
>> bbsubst("pi = @pi@", pi=pi)
> [1] "pi = 3.14159265358979"

Note that the gsubfn example above is the default only but by
specifying the pattern argument (first arg) it can be changed. e.g.

library(gsubfn)

pat <- "[$]([[:alpha:]][[:alnum:].]*)|[$][{]([^}]*)[}]"
gsubfn(pat,, "pi=$pi 2pi=${2*pi}")

pat2 <- "@([^@]*)@"
gsubfn(pat2,, "pi=@pi@ 2pi=@2*pi@")

pat3 <- "%([^%]*)%"
gsubfn(pat3,, "pi=%pi% 2pi=%2*pi%")

pat4 <- "{{(.*?)}}"
gsubfn(pat4,, "pi={{pi}} 2pi={{2*pi}}")



-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From barthelemy at geovariances.com  Wed Dec 18 11:24:27 2013
From: barthelemy at geovariances.com (Olivier BARTHELEMY)
Date: Wed, 18 Dec 2013 11:24:27 +0100
Subject: [Rd] Symlinks when building R on windows
Message-ID: <CAK9jXVXuzVbDF5s10_0BDnVyNN6bESTBmUrUtg7Yh_iS-At=tA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20131218/51448518/attachment.pl>

From murdoch.duncan at gmail.com  Wed Dec 18 14:13:39 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 18 Dec 2013 08:13:39 -0500
Subject: [Rd] Symlinks when building R on windows
In-Reply-To: <CAK9jXVXuzVbDF5s10_0BDnVyNN6bESTBmUrUtg7Yh_iS-At=tA@mail.gmail.com>
References: <CAK9jXVXuzVbDF5s10_0BDnVyNN6bESTBmUrUtg7Yh_iS-At=tA@mail.gmail.com>
Message-ID: <52B19F83.4020707@gmail.com>

On 13-12-18 5:24 AM, Olivier BARTHELEMY wrote:
> I think this is more suited for the devel mailing list than the help one.
>
> I'm trying to build R on windows, With Rtools installed, and configure/make
> in R-3.0.2 sources folder from a cygwin console.

This doesn't sound like a good idea.  The Rtools are set up for native 
Windows builds.  If you run configure yourself, you'll be targeting a 
Cygwin build -- but that's something we don't support.

What you should do is follow the instructions for native Windows builds 
that are given in chapter 3 of the Installation and Administration 
manual.  In particular, *do not* run configure.

If you do choose to create a Cygwin build, please make sure it passes 
the tests before you use it.  I haven't seen one that does.

Duncan Murdoch


> I am stuck at the moment, because the build process tries create symlinks,
> and gcc build fails because the opened files containe the metadata of the
> not working symlink, and not the linked file.
> The first problematic files is src/extra/xz/alone_decoder.c, pointing to
> common/alone_decoder.c, but i guess the following buildt files would have
> the same problem.
> My configure didn't even detect the symlink cmd off cygwin while performing
> the tests, and i even launched configure with --disable-symlinks, but their
> creationis attmpted anyways.
> Is there any quick way to workaround that? And since it's .c or.h files we
> are symlinking here, couldn't we simply do 'eponym' C or h files that do a
> C #include to the relative path, which would be more portable than symlinks?
>


From arppe at ualberta.ca  Wed Dec 18 18:08:21 2013
From: arppe at ualberta.ca (Antti Arppe)
Date: Wed, 18 Dec 2013 17:08:21 +0000
Subject: [Rd] Fwd: Bad \usage lines question
In-Reply-To: <52B1D5FA.5000400@ualberta.ca>
References: <52B1D5FA.5000400@ualberta.ca>
Message-ID: <52B1D685.6080209@iki.fi>

Dear colleagues,

In checking a function I am adding to an R package, I get the following
warning pair:

...
Bad \usage lines found in documentation object 'nominal':
   "\\method{print}{nominal}"(x, max.print = 10,
      posthoc = "std.pearson.residuals.sign",
      assoc = ifelse("univariate"
        list(c("N", "alpha.X2", "uc.12", "uc.21")),
        list(c("N1", "N2", "N12", "uc.12", "uc.21"))),
      sort.key = NULL, ...)
   "\\method{summary}{nominal}"(object, posthoc =
"std.pearson.residuals.sign",
      assoc = ifelse("univariate"
        list(c("N", "alpha.X2", "uc.12", "uc.21")),
        list(c("N1", "N2", "N12", "uc.12", "uc.21"))),
      sort.key = NULL, ...)

Functions with \usage entries need to have the appropriate \alias
entries, and all their arguments documented.
The \usage entries must correspond to syntactically valid R code.
See the chapter ?Writing R documentation files? in the ?Writing R
Extensions? manual.
...

The functions are described in the (same) manual page document file as
follows:

---- nominal.Rd -----
\name{nominal}
\alias{nominal}
\alias{print.nominal}
\alias{summary.nominal}
\alias{print.summary.nominal}

\title{
   Univariate and bivariate statistics for categorical,
   unordered variables
}
\description{

   \code{nominal} takes a data frame with categorical (i.e. nominal)
   variables and calculates a range of categorical statistics and
   posthoc analyses.

}
\usage{
nominal(formula, data, sort.bivariate = NULL, std.pearson.residual.min = 2,
    correct = FALSE, report.interval = 100, transform.variables = FALSE)

\method{print}{nominal}(x, max.print = 10,
    posthoc = "std.pearson.residuals.sign",
    assoc = ifelse("univariate" %in% class(x),
      list(c("N", "alpha.X2", "uc.12", "uc.21")),
      list(c("N1", "N2", "N12", "uc.12", "uc.21"))),
    sort.key = NULL, \dots)

\method{summary}{nominal}(object, posthoc = "std.pearson.residuals.sign",
    assoc = ifelse("univariate" %in% class(object),
      list(c("N", "alpha.X2", "uc.12", "uc.21")),
      list(c("N1", "N2", "N12", "uc.12", "uc.21"))),
    sort.key = NULL, \dots)

\method{print}{summary.nominal}(x, max.print = 10, \dots)

}
...
-----

The functions themselves are described as follows:

----- nominal.R -----
print.nominal <- function(x, max.print=10,
posthoc="std.pearson.residuals.sign", assoc=ifelse("univariate" %in%
class(x), list(c("N","alpha.X2","uc.12","uc.21")), list(c("N1","N\
2","N12","uc.12","uc.21"))), sort.key=NULL, ...)
...

summary.nominal <- function(object,
posthoc="std.pearson.residuals.sign", assoc=ifelse("univariate" %in%
class(object), list(c("N","alpha.X2","uc.12","uc.21")), list(c("N1","N2"\
,"N12","uc.12","uc.21"))), sort.key=NULL, ...)
...
-----

I've checked that the function specifications in the code match the
specifications in the manual page, and that all the arguments are
described in the manual page as well. The problem did not disappear when
I separated the summary method and its corresponding print method to a
separate file. I suppose the only difference between the code and the
manual pages is that in the manual pages I've tried to make the line
widths narrower (so there are differences in terms of space or newlines,
but nothing else).

But when building the package and installing it, everything appears fine
within R, whether using the terminal or GUI versions.

Am I missing something here, or what? Any suggestions or pointers will
be much appreciated.

Thanks, -Antti Arppe

-- 
======================================================================
Antti Arppe - Ph.D (General Linguistics), M.Sc. (Engineering)
Assistant Professor of Quantitative Linguistics
Department of Linguistics, University of Alberta
E-mail: arppe at ualberta.ca, antti.arppe at iki.fi
WWW: http://www.ualberta.ca/~arppe
Maanahtu ina reed?ti ihza umm?nuuti ihannaq - dulum ugulak ?mun ingul


From murdoch.duncan at gmail.com  Wed Dec 18 18:42:48 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 18 Dec 2013 12:42:48 -0500
Subject: [Rd] Fwd: Bad \usage lines question
In-Reply-To: <52B1D685.6080209@iki.fi>
References: <52B1D5FA.5000400@ualberta.ca> <52B1D685.6080209@iki.fi>
Message-ID: <52B1DE98.3070107@gmail.com>

On 18/12/2013 12:08 PM, Antti Arppe wrote:
> Dear colleagues,
>
> In checking a function I am adding to an R package, I get the following
> warning pair:
>
> ...
> Bad \usage lines found in documentation object 'nominal':
>     "\\method{print}{nominal}"(x, max.print = 10,
>        posthoc = "std.pearson.residuals.sign",
>        assoc = ifelse("univariate"

Notice how the line above differs from your source -- the % signs are 
taken as comment markers.  You need to escape them.

Duncan Murdoch

>          list(c("N", "alpha.X2", "uc.12", "uc.21")),
>          list(c("N1", "N2", "N12", "uc.12", "uc.21"))),
>        sort.key = NULL, ...)
>     "\\method{summary}{nominal}"(object, posthoc =
> "std.pearson.residuals.sign",
>        assoc = ifelse("univariate"
>          list(c("N", "alpha.X2", "uc.12", "uc.21")),
>          list(c("N1", "N2", "N12", "uc.12", "uc.21"))),
>        sort.key = NULL, ...)
>
> Functions with \usage entries need to have the appropriate \alias
> entries, and all their arguments documented.
> The \usage entries must correspond to syntactically valid R code.
> See the chapter ?Writing R documentation files? in the ?Writing R
> Extensions? manual.
> ...
>
> The functions are described in the (same) manual page document file as
> follows:
>
> ---- nominal.Rd -----
> \name{nominal}
> \alias{nominal}
> \alias{print.nominal}
> \alias{summary.nominal}
> \alias{print.summary.nominal}
>
> \title{
>     Univariate and bivariate statistics for categorical,
>     unordered variables
> }
> \description{
>
>     \code{nominal} takes a data frame with categorical (i.e. nominal)
>     variables and calculates a range of categorical statistics and
>     posthoc analyses.
>
> }
> \usage{
> nominal(formula, data, sort.bivariate = NULL, std.pearson.residual.min = 2,
>      correct = FALSE, report.interval = 100, transform.variables = FALSE)
>
> \method{print}{nominal}(x, max.print = 10,
>      posthoc = "std.pearson.residuals.sign",
>      assoc = ifelse("univariate" %in% class(x),
>        list(c("N", "alpha.X2", "uc.12", "uc.21")),
>        list(c("N1", "N2", "N12", "uc.12", "uc.21"))),
>      sort.key = NULL, \dots)
>
> \method{summary}{nominal}(object, posthoc = "std.pearson.residuals.sign",
>      assoc = ifelse("univariate" %in% class(object),
>        list(c("N", "alpha.X2", "uc.12", "uc.21")),
>        list(c("N1", "N2", "N12", "uc.12", "uc.21"))),
>      sort.key = NULL, \dots)
>
> \method{print}{summary.nominal}(x, max.print = 10, \dots)
>
> }
> ...
> -----
>
> The functions themselves are described as follows:
>
> ----- nominal.R -----
> print.nominal <- function(x, max.print=10,
> posthoc="std.pearson.residuals.sign", assoc=ifelse("univariate" %in%
> class(x), list(c("N","alpha.X2","uc.12","uc.21")), list(c("N1","N\
> 2","N12","uc.12","uc.21"))), sort.key=NULL, ...)
> ...
>
> summary.nominal <- function(object,
> posthoc="std.pearson.residuals.sign", assoc=ifelse("univariate" %in%
> class(object), list(c("N","alpha.X2","uc.12","uc.21")), list(c("N1","N2"\
> ,"N12","uc.12","uc.21"))), sort.key=NULL, ...)
> ...
> -----
>
> I've checked that the function specifications in the code match the
> specifications in the manual page, and that all the arguments are
> described in the manual page as well. The problem did not disappear when
> I separated the summary method and its corresponding print method to a
> separate file. I suppose the only difference between the code and the
> manual pages is that in the manual pages I've tried to make the line
> widths narrower (so there are differences in terms of space or newlines,
> but nothing else).
>
> But when building the package and installing it, everything appears fine
> within R, whether using the terminal or GUI versions.
>
> Am I missing something here, or what? Any suggestions or pointers will
> be much appreciated.
>
> Thanks, -Antti Arppe
>


From arppe at ualberta.ca  Wed Dec 18 18:53:08 2013
From: arppe at ualberta.ca (Antti Arppe)
Date: Wed, 18 Dec 2013 17:53:08 +0000
Subject: [Rd] Fwd: Bad \usage lines question
In-Reply-To: <52B1DE98.3070107@gmail.com>
References: <52B1D5FA.5000400@ualberta.ca> <52B1D685.6080209@iki.fi>
	<52B1DE98.3070107@gmail.com>
Message-ID: <52B1E104.2070000@ualberta.ca>

Thanks, that resolved it. Somehow I just thought that the line was 
truncated in the error message and that the problem was elsewhere, and 
didn't see/realize the obvious that '%' can indeed be a special 
character in Rd files.

	-Antti Arppe

On 2013-12-18 5:42 PM, Duncan Murdoch wrote:
> On 18/12/2013 12:08 PM, Antti Arppe wrote:
>> Dear colleagues,
>>
>> In checking a function I am adding to an R package, I get the following
>> warning pair:
>>
>> ...
>> Bad \usage lines found in documentation object 'nominal':
>>     "\\method{print}{nominal}"(x, max.print = 10,
>>        posthoc = "std.pearson.residuals.sign",
>>        assoc = ifelse("univariate"
>
> Notice how the line above differs from your source -- the % signs are
> taken as comment markers.  You need to escape them.
>
> Duncan Murdoch
>
>>          list(c("N", "alpha.X2", "uc.12", "uc.21")),
>>          list(c("N1", "N2", "N12", "uc.12", "uc.21"))),
>>        sort.key = NULL, ...)
>>     "\\method{summary}{nominal}"(object, posthoc =
>> "std.pearson.residuals.sign",
>>        assoc = ifelse("univariate"
>>          list(c("N", "alpha.X2", "uc.12", "uc.21")),
>>          list(c("N1", "N2", "N12", "uc.12", "uc.21"))),
>>        sort.key = NULL, ...)
>>
>> Functions with \usage entries need to have the appropriate \alias
>> entries, and all their arguments documented.
>> The \usage entries must correspond to syntactically valid R code.
>> See the chapter ?Writing R documentation files? in the ?Writing R
>> Extensions? manual.
>> ...
>>
>> The functions are described in the (same) manual page document file as
>> follows:
>>
>> ---- nominal.Rd -----
>> \name{nominal}
>> \alias{nominal}
>> \alias{print.nominal}
>> \alias{summary.nominal}
>> \alias{print.summary.nominal}
>>
>> \title{
>>     Univariate and bivariate statistics for categorical,
>>     unordered variables
>> }
>> \description{
>>
>>     \code{nominal} takes a data frame with categorical (i.e. nominal)
>>     variables and calculates a range of categorical statistics and
>>     posthoc analyses.
>>
>> }
>> \usage{
>> nominal(formula, data, sort.bivariate = NULL, std.pearson.residual.min
>> = 2,
>>      correct = FALSE, report.interval = 100, transform.variables = FALSE)
>>
>> \method{print}{nominal}(x, max.print = 10,
>>      posthoc = "std.pearson.residuals.sign",
>>      assoc = ifelse("univariate" %in% class(x),
>>        list(c("N", "alpha.X2", "uc.12", "uc.21")),
>>        list(c("N1", "N2", "N12", "uc.12", "uc.21"))),
>>      sort.key = NULL, \dots)
>>
>> \method{summary}{nominal}(object, posthoc = "std.pearson.residuals.sign",
>>      assoc = ifelse("univariate" %in% class(object),
>>        list(c("N", "alpha.X2", "uc.12", "uc.21")),
>>        list(c("N1", "N2", "N12", "uc.12", "uc.21"))),
>>      sort.key = NULL, \dots)
>>
>> \method{print}{summary.nominal}(x, max.print = 10, \dots)
>>
>> }
>> ...
>> -----
>>
>> The functions themselves are described as follows:
>>
>> ----- nominal.R -----
>> print.nominal <- function(x, max.print=10,
>> posthoc="std.pearson.residuals.sign", assoc=ifelse("univariate" %in%
>> class(x), list(c("N","alpha.X2","uc.12","uc.21")), list(c("N1","N\
>> 2","N12","uc.12","uc.21"))), sort.key=NULL, ...)
>> ...
>>
>> summary.nominal <- function(object,
>> posthoc="std.pearson.residuals.sign", assoc=ifelse("univariate" %in%
>> class(object), list(c("N","alpha.X2","uc.12","uc.21")), list(c("N1","N2"\
>> ,"N12","uc.12","uc.21"))), sort.key=NULL, ...)
>> ...
>> -----
>>
>> I've checked that the function specifications in the code match the
>> specifications in the manual page, and that all the arguments are
>> described in the manual page as well. The problem did not disappear when
>> I separated the summary method and its corresponding print method to a
>> separate file. I suppose the only difference between the code and the
>> manual pages is that in the manual pages I've tried to make the line
>> widths narrower (so there are differences in terms of space or newlines,
>> but nothing else).
>>
>> But when building the package and installing it, everything appears fine
>> within R, whether using the terminal or GUI versions.
>>
>> Am I missing something here, or what? Any suggestions or pointers will
>> be much appreciated.
>>
>> Thanks, -Antti Arppe
>>
>

-- 
======================================================================
Antti Arppe - Ph.D (General Linguistics), M.Sc. (Engineering)
Assistant Professor of Quantitative Linguistics
Department of Linguistics, University of Alberta
E-mail: arppe at ualberta.ca, antti.arppe at iki.fi
WWW: http://www.ualberta.ca/~arppe
Maanahtu ina reed?ti ihza umm?nuuti ihannaq - dulum ugulak ?mun ingul


From winstonchang1 at gmail.com  Thu Dec 19 19:19:53 2013
From: winstonchang1 at gmail.com (Winston Chang)
Date: Thu, 19 Dec 2013 12:19:53 -0600
Subject: [Rd] Strange warnings when unloading packages with S4 classes
Message-ID: <CAFOpNVG5S1eLSe5bb3NfOxhp3zTYthk50ODFYHTxoYvzjDMOzw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20131219/7c510155/attachment.pl>

From winstonchang1 at gmail.com  Thu Dec 19 19:24:54 2013
From: winstonchang1 at gmail.com (Winston Chang)
Date: Thu, 19 Dec 2013 12:24:54 -0600
Subject: [Rd] Strange warnings when unloading packages with S4 classes
In-Reply-To: <CAFOpNVG5S1eLSe5bb3NfOxhp3zTYthk50ODFYHTxoYvzjDMOzw@mail.gmail.com>
References: <CAFOpNVG5S1eLSe5bb3NfOxhp3zTYthk50ODFYHTxoYvzjDMOzw@mail.gmail.com>
Message-ID: <CAFOpNVGgP3C_NFr8BUb4pjDfmDhGmHc3yNGQnkiZ-R+QX0SYkg@mail.gmail.com>

(Sorry, this was previously sent with HTML mail. Resending in plain text.)

I've been seeing warnings when unloading packages. They can be seen
with the shiny and sp packages, among others (this is on R 3.0.2). For
example:
> library(sp)
> unloadNamespace('sp')
Warning messages:
1: In FUN(X[[2L]], ...) :
  Created a package name, ?2013-12-19 12:14:24?, when none found
2: In FUN(X[[2L]], ...) :
  Created a package name, ?2013-12-19 12:14:24?, when none found
3: In FUN(X[[2L]], ...) :
  Created a package name, ?2013-12-19 12:14:24?, when none found
4: In FUN(X[[2L]], ...) :
  Created a package name, ?2013-12-19 12:14:24?, when none found

It appears to be related to the methods:::.removeSuperclassBackRefs function.


I can get the warnings to appear when the following are both true:
* The package has an S4 class which inherits from a class outside of
the package.
* The NAMESPACE file contains import(methods)

I've created some very simple test packages here which illustrate the
problem, along with instructions on how to duplicate the warning.
https://github.com/wch/s4unload

The warnings only appear when unloading the package where both of the
conditions above are true. I'm not sure why import(methods) should
make a difference, but it does.

Is this a bug in the implementation of S4?

Best,
-Winston


From jmc at r-project.org  Thu Dec 19 20:22:45 2013
From: jmc at r-project.org (John Chambers)
Date: Thu, 19 Dec 2013 11:22:45 -0800
Subject: [Rd] Strange warnings when unloading packages with S4 classes
In-Reply-To: <CAFOpNVG5S1eLSe5bb3NfOxhp3zTYthk50ODFYHTxoYvzjDMOzw@mail.gmail.com>
References: <CAFOpNVG5S1eLSe5bb3NfOxhp3zTYthk50ODFYHTxoYvzjDMOzw@mail.gmail.com>
Message-ID: <9AA8DFF7-B07E-4A14-BBD6-92449741947E@r-project.org>

Previously reported and fixed in 3.0.2-patched (Bug 15481).  Unless there is a 3.0.3, you will have to wait for 3.1.0.

On Dec 19, 2013, at 10:19 AM, Winston Chang <winstonchang1 at gmail.com> wrote:

> I've been seeing warnings when unloading packages. They can be seen with
> the shiny and sp packages, among others (this is on R 3.0.2). For example:
>> library(sp)
>> unloadNamespace('sp')
> Warning messages:
> 1: In FUN(X[[2L]], ...) :
>  Created a package name, ?2013-12-19 12:14:24?, when none found
> 2: In FUN(X[[2L]], ...) :
>  Created a package name, ?2013-12-19 12:14:24?, when none found
> 3: In FUN(X[[2L]], ...) :
>  Created a package name, ?2013-12-19 12:14:24?, when none found
> 4: In FUN(X[[2L]], ...) :
>  Created a package name, ?2013-12-19 12:14:24?, when none found
> 
> It appears to be related to the methods:::.removeSuperclassBackRefs
> function.
> 
> 
> I can get the warnings to appear when the following are both true:
> * The package has an S4 class which inherits from a class outside of the
> package.
> * The NAMESPACE file contains import(methods)
> 
> I've created some very simple test packages here which illustrate the
> problem, along with instructions on how to duplicate the warning.
> https://github.com/wch/s4unload
> 
> The warnings only appear when unloading the package where both of the
> conditions above are true. I'm not sure why import(methods) should make a
> difference, but it does.
> 
> Is this a bug in the implementation of S4?
> 
> Best,
> -Winston
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From winstonchang1 at gmail.com  Thu Dec 19 21:25:58 2013
From: winstonchang1 at gmail.com (Winston Chang)
Date: Thu, 19 Dec 2013 14:25:58 -0600
Subject: [Rd] Strange warnings when unloading packages with S4 classes
In-Reply-To: <9AA8DFF7-B07E-4A14-BBD6-92449741947E@r-project.org>
References: <CAFOpNVG5S1eLSe5bb3NfOxhp3zTYthk50ODFYHTxoYvzjDMOzw@mail.gmail.com>
	<9AA8DFF7-B07E-4A14-BBD6-92449741947E@r-project.org>
Message-ID: <CAFOpNVGwsGdG3EA7Y_=nY3Hx7rjEmik85PszJiAirwvxgJ+KoA@mail.gmail.com>

Excellent, thanks.

-Winston

On Thu, Dec 19, 2013 at 1:22 PM, John Chambers <jmc at r-project.org> wrote:
> Previously reported and fixed in 3.0.2-patched (Bug 15481).  Unless there is a 3.0.3, you will have to wait for 3.1.0.
>
> On Dec 19, 2013, at 10:19 AM, Winston Chang <winstonchang1 at gmail.com> wrote:
>
>> I've been seeing warnings when unloading packages. They can be seen with
>> the shiny and sp packages, among others (this is on R 3.0.2). For example:
>>> library(sp)
>>> unloadNamespace('sp')
>> Warning messages:
>> 1: In FUN(X[[2L]], ...) :
>>  Created a package name, ?2013-12-19 12:14:24?, when none found
>> 2: In FUN(X[[2L]], ...) :
>>  Created a package name, ?2013-12-19 12:14:24?, when none found
>> 3: In FUN(X[[2L]], ...) :
>>  Created a package name, ?2013-12-19 12:14:24?, when none found
>> 4: In FUN(X[[2L]], ...) :
>>  Created a package name, ?2013-12-19 12:14:24?, when none found
>>
>> It appears to be related to the methods:::.removeSuperclassBackRefs
>> function.
>>
>>
>> I can get the warnings to appear when the following are both true:
>> * The package has an S4 class which inherits from a class outside of the
>> package.
>> * The NAMESPACE file contains import(methods)
>>
>> I've created some very simple test packages here which illustrate the
>> problem, along with instructions on how to duplicate the warning.
>> https://github.com/wch/s4unload
>>
>> The warnings only appear when unloading the package where both of the
>> conditions above are true. I'm not sure why import(methods) should make a
>> difference, but it does.
>>
>> Is this a bug in the implementation of S4?
>>
>> Best,
>> -Winston
>>
>>       [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From skyebend at skyeome.net  Fri Dec 20 19:37:11 2013
From: skyebend at skyeome.net (Skye Bender-deMoll)
Date: Fri, 20 Dec 2013 10:37:11 -0800
Subject: [Rd] How to force dispatch to an internal generic?
Message-ID: <52B48E57.8010308@skyeome.net>

Dear R-devel,

I have a class 'myClass' in R that is essentially a list with 
pre-specified structure. It has an assignment operator which is going to 
do some things and then should assign the value using the regular list 
assignment operator

`$<-.myClass`<-function(x,i,value){
    # do some pre-processing  stuff

    # make the assignment using the default list assignment
    x[[i]]<-value
    x
  }

But I can't actually use x[[i]]<-value as it will dispatch to the 
already existing [[<-.myClass method.

In similar S3 dispatching cases, I've been able use UseMethod or 
specifically call [[<-.list, or [[<-.default but those don't seem to 
exist because $<- and [[<- are primitive generics, right?  I couldn't 
figure out a way to effectively call call NextMethod, and I assume 
calling .Primitive("$<-") is not appropriate.

My current solution mirrors $<-.data.frame

`$<-.data.frame` <- function (x, name, value) {
   cl <- oldClass(x)
   class(x) <- NULL
   x[[name]] <- value
   class(x) <- cl
   x
}

but according to tracemem(), this is triggering three deep copies of 
myClass objects (which can be expensive as the object is often very 
large ) with each $ assignment instead of one.

Is there a better way to dispatch the assignment to the default 
assignment method?


Note: I previously posted the same question at
http://stackoverflow.com/questions/20627776/how-to-force-dispatch-to-an-internal-generic-in-r

thanks for your help,
  -skye


From sannandi at umail.iu.edu  Fri Dec 20 20:00:23 2013
From: sannandi at umail.iu.edu (Sandip Nandi)
Date: Fri, 20 Dec 2013 11:00:23 -0800
Subject: [Rd] Fwd: How to check if R interpreter is initiated
In-Reply-To: <CAGSjAUD+RTivxeWq=gwgDd=gaGUeFJPJbNXpb3abLshu9Fjaqg@mail.gmail.com>
References: <CAGSjAUD+RTivxeWq=gwgDd=gaGUeFJPJbNXpb3abLshu9Fjaqg@mail.gmail.com>
Message-ID: <CAGSjAUDWELeQyt6hQRjjeOb823+vva970fkb7FEjWbhiPUu3sQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20131220/b22086c0/attachment.pl>

From murdoch.duncan at gmail.com  Fri Dec 20 22:07:15 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 20 Dec 2013 16:07:15 -0500
Subject: [Rd] Fwd: How to check if R interpreter is initiated
In-Reply-To: <CAGSjAUDWELeQyt6hQRjjeOb823+vva970fkb7FEjWbhiPUu3sQ@mail.gmail.com>
References: <CAGSjAUD+RTivxeWq=gwgDd=gaGUeFJPJbNXpb3abLshu9Fjaqg@mail.gmail.com>
	<CAGSjAUDWELeQyt6hQRjjeOb823+vva970fkb7FEjWbhiPUu3sQ@mail.gmail.com>
Message-ID: <52B4B183.1020409@gmail.com>

On 13-12-20 2:00 PM, Sandip Nandi wrote:
> Hi R-Developers ,
>
> I am using R-3.1 , moved from R-2.15 . I am facing a problem which I have
> raised in R bug report with bug 15596 .
>
> My problem is how to check if R is initiated before initiating R
>
> I am embedding R in parallel environment and reusing process already
> running to reduce overhead . Each process is running infinitely. So when a
> process is reused,it finds R is already initialized there and throws the
> error.
>
> Till 2.15 it was solved using R_Is_running variable . So I am assuming
> there should be some flag or return value in R-3.0.2 which provides the
> user with information if already initialized .
>
> Anyone has faced the problem ?
>
> It will be great if anyone could suggest alternate solution to this problem
> for R-3.0.

As you've already been told:  just maintain your own variable for this. 
  Before initializing R, set it to 0.  After initializing R, set it to 1.

Duncan Murdoch


From walterwan at 126.com  Tue Dec 24 07:15:34 2013
From: walterwan at 126.com (Yu Wan)
Date: Mon, 23 Dec 2013 22:15:34 -0800 (PST)
Subject: [Rd] Parallel computing: how to transmit multiple parameters to a
 function in parLapply?
Message-ID: <1387865734355-4682667.post@n4.nabble.com>

Hi R-developers

In the package Parallel, the function parLapply(cl, x, f) seems to allow
transmission of only one parameter (x) to the function f. Hence in order to
compute f(x, y) parallelly, I had to define f(x, y) as f(x) and tried to
access y within the function, whereas y was defined outside of f(x).

Script:

library(parallel)

f <- function(x) {
  z <- 2 * x + .GlobalEnv$y  # Try to access y in the global scope.
  return(z)
}

np <- detectCores(logical = FALSE)  # Two cores of my laptop
x <- seq(1, 10, by = 1)
y <- 0.5  # Y may be an array in reality.
cl <- makeCluster(np)  # initiate the cluster
  r <- parLapply(cl, x, f)  # apply f to x for parallel computing
stopCluster(cl)

The r was a list with 10 empty elements which means f failed to access y.

Then I tested f without parallel computing:
z <- f(x)
print(z)
[1]  2.5  4.5  6.5  8.5 10.5 12.5 14.5 16.5 18.5 20.5

The results indicates that we can access y using .GlobalEnv$y in a function
without parLapply.

The question is, is there any method for me to transmit y to f, or access y
within f during parallel computing?

The version of my R is 3.0.1 and I am running it on a Win8-64x system.

Thanks,

Yu



--
View this message in context: http://r.789695.n4.nabble.com/Parallel-computing-how-to-transmit-multiple-parameters-to-a-function-in-parLapply-tp4682667.html
Sent from the R devel mailing list archive at Nabble.com.


From alexios at 4dscape.com  Tue Dec 24 13:20:45 2013
From: alexios at 4dscape.com (alexios ghalanos)
Date: Tue, 24 Dec 2013 12:20:45 +0000
Subject: [Rd] Parallel computing: how to transmit multiple parameters to
	a function in parLapply?
In-Reply-To: <1387865734355-4682667.post@n4.nabble.com>
References: <1387865734355-4682667.post@n4.nabble.com>
Message-ID: <277D0BAB-13CB-4633-982E-01F611092344@4dscape.com>

This works:

clusterExport(cl, c("f","y"), envir=environment())
r <- parLapply(cl, x, function(x) f(x,y))

You need to export your function (?f?) and additional variables (?y?), and then 
define that function inside parLapply ("f(x,y)?). If you were to also make use of
additional libraries (or source some scripts) then you should also consult 
?clusterEvalQ?.
The makeCluster command (at least in windows via socket) just initializes new R 
processes which do not know about your functions or variables unless you
export those to them.

Perhaps a question best suited for R-help.

Alexios



On 24 Dec 2013, at 06:15, Yu Wan <walterwan at 126.com> wrote:

> Hi R-developers
> 
> In the package Parallel, the function parLapply(cl, x, f) seems to allow
> transmission of only one parameter (x) to the function f. Hence in order to
> compute f(x, y) parallelly, I had to define f(x, y) as f(x) and tried to
> access y within the function, whereas y was defined outside of f(x).
> 
> Script:
> 
> library(parallel)
> 
> f <- function(x) {
>  z <- 2 * x + .GlobalEnv$y  # Try to access y in the global scope.
>  return(z)
> }
> 
> np <- detectCores(logical = FALSE)  # Two cores of my laptop
> x <- seq(1, 10, by = 1)
> y <- 0.5  # Y may be an array in reality.
> cl <- makeCluster(np)  # initiate the cluster
>  r <- parLapply(cl, x, f)  # apply f to x for parallel computing
> stopCluster(cl)
> 
> The r was a list with 10 empty elements which means f failed to access y.
> 
> Then I tested f without parallel computing:
> z <- f(x)
> print(z)
> [1]  2.5  4.5  6.5  8.5 10.5 12.5 14.5 16.5 18.5 20.5
> 
> The results indicates that we can access y using .GlobalEnv$y in a function
> without parLapply.
> 
> The question is, is there any method for me to transmit y to f, or access y
> within f during parallel computing?
> 
> The version of my R is 3.0.1 and I am running it on a Win8-64x system.
> 
> Thanks,
> 
> Yu
> 
> 
> 
> --
> View this message in context: http://r.789695.n4.nabble.com/Parallel-computing-how-to-transmit-multiple-parameters-to-a-function-in-parLapply-tp4682667.html
> Sent from the R devel mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 


From wdunlap at tibco.com  Tue Dec 24 16:57:06 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 24 Dec 2013 15:57:06 +0000
Subject: [Rd] Parallel computing: how to transmit multiple parameters to
 a function in parLapply?
In-Reply-To: <1387865734355-4682667.post@n4.nabble.com>
References: <1387865734355-4682667.post@n4.nabble.com>
Message-ID: <E66794E69CFDE04D9A70842786030B933FA1F0E8@PA-MBX01.na.tibco.com>

You can put the function of interest and any global
variables it needs into a private environment, which gets sent
along with the function to the child processes.  E.g.

library(parallel)
cl3 <- makeCluster(3)
y <- c(1,100,10000)
addY <- function(x) x + y
withGlobals <- function(FUN, ...){
    environment(FUN) <- list2env(list(...))
    FUN
}
parLapply(cl3, 1:4, withGlobals(addY, y=y))
# [[1]]
# [1]     2   101 10001
# 
# [[2]]
# [1]     3   102 10002
# ...

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org] On Behalf
> Of Yu Wan
> Sent: Monday, December 23, 2013 10:16 PM
> To: r-devel at r-project.org
> Subject: [Rd] Parallel computing: how to transmit multiple parameters to a function in
> parLapply?
> 
> Hi R-developers
> 
> In the package Parallel, the function parLapply(cl, x, f) seems to allow
> transmission of only one parameter (x) to the function f. Hence in order to
> compute f(x, y) parallelly, I had to define f(x, y) as f(x) and tried to
> access y within the function, whereas y was defined outside of f(x).
> 
> Script:
> 
> library(parallel)
> 
> f <- function(x) {
>   z <- 2 * x + .GlobalEnv$y  # Try to access y in the global scope.
>   return(z)
> }
> 
> np <- detectCores(logical = FALSE)  # Two cores of my laptop
> x <- seq(1, 10, by = 1)
> y <- 0.5  # Y may be an array in reality.
> cl <- makeCluster(np)  # initiate the cluster
>   r <- parLapply(cl, x, f)  # apply f to x for parallel computing
> stopCluster(cl)
> 
> The r was a list with 10 empty elements which means f failed to access y.
> 
> Then I tested f without parallel computing:
> z <- f(x)
> print(z)
> [1]  2.5  4.5  6.5  8.5 10.5 12.5 14.5 16.5 18.5 20.5
> 
> The results indicates that we can access y using .GlobalEnv$y in a function
> without parLapply.
> 
> The question is, is there any method for me to transmit y to f, or access y
> within f during parallel computing?
> 
> The version of my R is 3.0.1 and I am running it on a Win8-64x system.
> 
> Thanks,
> 
> Yu
> 
> 
> 
> --
> View this message in context: http://r.789695.n4.nabble.com/Parallel-computing-how-
> to-transmit-multiple-parameters-to-a-function-in-parLapply-tp4682667.html
> Sent from the R devel mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From fgnu32 at yahoo.com  Tue Dec 24 21:26:28 2013
From: fgnu32 at yahoo.com (Fg Nu)
Date: Tue, 24 Dec 2013 12:26:28 -0800 (PST)
Subject: [Rd] Object type name and class name
Message-ID: <1387916788.92832.YahooMailNeo@web162701.mail.bf1.yahoo.com>




I came across the distinction between the name of an object and the name of the class that it belongs to in an oblique way again today, which made me question my acceptance that it would be natural for them to differ.

I asked a question on SO here:
http://stackoverflow.com/questions/20762559/why-is-the-name-of-an-object-type-different-from-the-name-of-the-class-it-belong

I wonder if anyone on the R-Devel list has a better explanation for why the class name of an object and the object type name of an object should differ??

Happy holidays,

fg


From gmbecker at ucdavis.edu  Tue Dec 24 22:32:48 2013
From: gmbecker at ucdavis.edu (Gabriel Becker)
Date: Tue, 24 Dec 2013 13:32:48 -0800
Subject: [Rd] Object type name and class name
In-Reply-To: <1387916788.92832.YahooMailNeo@web162701.mail.bf1.yahoo.com>
References: <1387916788.92832.YahooMailNeo@web162701.mail.bf1.yahoo.com>
Message-ID: <CADwqtCPGiqGP4jA3Z7BSbLyjDxRDeNt5fWEZNp0HiZgsYk9sJw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20131224/a4959ccc/attachment.pl>

From fgnu32 at yahoo.com  Tue Dec 24 22:57:06 2013
From: fgnu32 at yahoo.com (Fg Nu)
Date: Tue, 24 Dec 2013 13:57:06 -0800 (PST)
Subject: [Rd] Object type name and class name
In-Reply-To: <CADwqtCPGiqGP4jA3Z7BSbLyjDxRDeNt5fWEZNp0HiZgsYk9sJw@mail.gmail.com>
References: <1387916788.92832.YahooMailNeo@web162701.mail.bf1.yahoo.com>
	<CADwqtCPGiqGP4jA3Z7BSbLyjDxRDeNt5fWEZNp0HiZgsYk9sJw@mail.gmail.com>
Message-ID: <1387922226.70767.YahooMailNeo@web162703.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20131224/d54a1e7e/attachment.pl>

From gmbecker at ucdavis.edu  Tue Dec 24 23:19:40 2013
From: gmbecker at ucdavis.edu (Gabriel Becker)
Date: Tue, 24 Dec 2013 14:19:40 -0800
Subject: [Rd] Object type name and class name
In-Reply-To: <1387922226.70767.YahooMailNeo@web162703.mail.bf1.yahoo.com>
References: <1387916788.92832.YahooMailNeo@web162701.mail.bf1.yahoo.com>
	<CADwqtCPGiqGP4jA3Z7BSbLyjDxRDeNt5fWEZNp0HiZgsYk9sJw@mail.gmail.com>
	<1387922226.70767.YahooMailNeo@web162703.mail.bf1.yahoo.com>
Message-ID: <CADwqtCO94my9Zm4C81W30wGUHfG7SKWZXRFp0werzzmiWx_d=Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20131224/9e96a9a6/attachment.pl>

From fgnu32 at yahoo.com  Tue Dec 24 23:30:15 2013
From: fgnu32 at yahoo.com (Fg Nu)
Date: Tue, 24 Dec 2013 14:30:15 -0800 (PST)
Subject: [Rd] Object type name and class name
In-Reply-To: <CADwqtCO94my9Zm4C81W30wGUHfG7SKWZXRFp0werzzmiWx_d=Q@mail.gmail.com>
References: <1387916788.92832.YahooMailNeo@web162701.mail.bf1.yahoo.com>	<CADwqtCPGiqGP4jA3Z7BSbLyjDxRDeNt5fWEZNp0HiZgsYk9sJw@mail.gmail.com>	<1387922226.70767.YahooMailNeo@web162703.mail.bf1.yahoo.com>
	<CADwqtCO94my9Zm4C81W30wGUHfG7SKWZXRFp0werzzmiWx_d=Q@mail.gmail.com>
Message-ID: <1387924215.45924.YahooMailNeo@web162703.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20131224/7337253b/attachment.pl>

From fgnu32 at yahoo.com  Tue Dec 24 23:43:08 2013
From: fgnu32 at yahoo.com (Fg Nu)
Date: Tue, 24 Dec 2013 14:43:08 -0800 (PST)
Subject: [Rd] Object type name and class name
In-Reply-To: <1387924215.45924.YahooMailNeo@web162703.mail.bf1.yahoo.com>
References: <1387916788.92832.YahooMailNeo@web162701.mail.bf1.yahoo.com>	<CADwqtCPGiqGP4jA3Z7BSbLyjDxRDeNt5fWEZNp0HiZgsYk9sJw@mail.gmail.com>	<1387922226.70767.YahooMailNeo@web162703.mail.bf1.yahoo.com>
	<CADwqtCO94my9Zm4C81W30wGUHfG7SKWZXRFp0werzzmiWx_d=Q@mail.gmail.com>
	<1387924215.45924.YahooMailNeo@web162703.mail.bf1.yahoo.com>
Message-ID: <1387924988.3487.YahooMailNeo@web162704.mail.bf1.yahoo.com>



[Resending because HTML was scrubbed.]


Gabriel,


Thanks. Not trying to influence any changes, just trying to understand better what is going on when the term "object type" is used. From what you and the SO answer seem to suggest, it has little to do with OOP/classes at all. This would be fine if John Chambers weren't explicitly juxtaposing the two in the quote given in the original post.


Regards.


>On Wednesday, December 25, 2013 3:49 AM, Gabriel Becker <gmbecker at ucdavis.edu> wrote:
> 
>It sounds like you're attempting to apply a version of object orientation (objects being instances of classes) which does not apply to R (in the S3 world anyway).
>>
>>That simply isn't how S3 classes work (in many ways S3 classes aren't really "classes" at all in the way you seem to be using the word, they are simply dispatch instructions) and that fact is AFAIK at the core of the language. 
>>
>>I'm not a core developer of R, and so I don't speak for them, but the likelihood of that changes seems vanishingly small at this juncture. Whether it "should" work the way you describe is debatable (I am not convinced myself), but regardless of whether it should it almost surely isn't going to.
>>
>>~G
>>
>>
>>
>>
>>On Tue, Dec 24, 2013 at 1:57 PM, Fg Nu <fgnu32 at yahoo.com> wrote:
>>
>>
>>>
>>>Gabriel,
>>>
>>>
>>>[I understand that this is not about R development, but it seemed that this was a question about R internals that would be better answered on the R-devel list.]
>>>
>>>
>>>Thanks for your answer. Yes, this is what the person who answered on SO said as well.?
>>>
>>>
>>>But my question is about terminology really. Why is the internal storage type called object type, which clashes with my understanding of an object being an instance of a class, and hence should share the same name? This is a purely technical notion, which should have nothing to do with the physical reality of C storage and types.
>>>
>>>
>>>Thanks.
>>>
>>>
>>>
>>>On Wednesday, December 25, 2013 3:02 AM, Gabriel Becker <gmbecker at ucdavis.edu> wrote:
>>> 
>>>Fg,
>>>>
>>>>This is not really an r-devel question. It is more appropriate for r-help as far as I know. Please ask questions like it there in the future.
>>>>
>>>>Anyway, my understanding is that the type of an object has to do with how it is stored internally, whereas the class has to do with how it is dispatched on. For example, in the S3 system , it is entirely reasonable to do the following:
>>>>
>>>>
>>>>> x = 1:10
>>>>> class(x) = "myspecialint"
>>>>> x
>>>>?[1]? 1? 2? 3? 4? 5? 6? 7? 8? 9 10
>>>>attr(,"class")
>>>>[1] "myspecialint"
>>>>> print.myspecialint = function(x, ...) print(mean(x))
>>>>> print(x)
>>>>[1] 5.5
>>>>> typeof(x)
>>>>[1] "integer"
>>>>
>>>>As you can see, changing the "class" of x did not change how it was stored internally.
>>>>
>>>>
>>>>Another canonical example is the matrix class. Matrices in R are stored as vectors of the relevant type, with additional attributes indicating their dimension. So while there is a matrix class, there is no matrix type.
>>>>
>>>>
>>>>> x = matrix(1:10, nrow=2)
>>>>> x
>>>>???? [,1] [,2] [,3] [,4] [,5]
>>>>[1,]??? 1??? 3??? 5??? 7??? 9
>>>>[2,]??? 2??? 4??? 6??? 8?? 10
>>>>> typeof(x)
>>>>[1] "integer"
>>>>
>>>>
>>>>HTH,
>>>>~G
>>>>
>>>>
>>>>
>>>>
>>>>On Tue, Dec 24, 2013 at 12:26 PM, Fg Nu <fgnu32 at yahoo.com> wrote:
>>>>
>>>>
>>>>>
>>>>>
>>>>>I came across the distinction between the name of an object and the name of the class that it belongs to in an oblique way again today, which made me question my acceptance that it would be natural for them to differ.
>>>>>
>>>>>I asked a question on SO here:
>>>>>http://stackoverflow.com/questions/20762559/why-is-the-name-of-an-object-type-different-from-the-name-of-the-class-it-belong
>>>>>
>>>>>I wonder if anyone on the R-Devel list has a better explanation for why the class name of an object and the object type name of an object should differ??
>>>>>
>>>>>Happy holidays,
>>>>>
>>>>>fg
>>>>>
>>>>>______________________________________________
>>>>>R-devel at r-project.org mailing list
>>>>>https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>>
>>>>
>>>>
>>>>-- 
>>>>Gabriel Becker
>>>>Graduate Student
>>>>Statistics Department
>>>>University of California, Davis
>>>>
>>>>
>>>>
>>
>>
>>-- 
>>Gabriel Becker
>>Graduate Student
>>Statistics Department
>>University of California, Davis
>>
>>
>>
>
>


From peter.meilstrup at gmail.com  Fri Dec 27 04:26:21 2013
From: peter.meilstrup at gmail.com (Peter Meilstrup)
Date: Thu, 26 Dec 2013 19:26:21 -0800
Subject: [Rd] RHS of assignment is evaluated eagerly?
Message-ID: <CAJoaRhZY4_scgDmCP3244-WHDQwFBqzQPH_hFz5AsAWhJAc6sw@mail.gmail.com>

Is this expected behavior, and if so, why? I would have expected
neither 'arg' nor 'value' to evaluate until forced.

`test<-` <- function(obj, arg, value) {
  1 #force no args
}
x <- 1
test(x, print("evaled arg")) <- print("evaluated value")

## [1] "evaluated value"

Peter


From simon.urbanek at r-project.org  Fri Dec 27 05:57:44 2013
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Thu, 26 Dec 2013 23:57:44 -0500
Subject: [Rd] RHS of assignment is evaluated eagerly?
In-Reply-To: <CAJoaRhZY4_scgDmCP3244-WHDQwFBqzQPH_hFz5AsAWhJAc6sw@mail.gmail.com>
References: <CAJoaRhZY4_scgDmCP3244-WHDQwFBqzQPH_hFz5AsAWhJAc6sw@mail.gmail.com>
Message-ID: <9AE5940B-3A40-4365-9AD0-D7B5026FBD23@r-project.org>

On Dec 26, 2013, at 10:26 PM, Peter Meilstrup <peter.meilstrup at gmail.com> wrote:

> Is this expected behavior, and if so, why? I would have expected
> neither 'arg' nor 'value' to evaluate until forced.
> 
> `test<-` <- function(obj, arg, value) {
>  1 #force no args
> }
> x <- 1
> test(x, print("evaled arg")) <- print("evaluated value")
> 
> ## [1] "evaluated value?
> 

?Use the source, Luke?:

    /*  It's important that the rhs get evaluated first because                                                                       
        assignment is right associative i.e.  a <- b <- c is parsed as                                                                
        a <- (b <- c).  */

Compare to

> `test<-`(x, print("evaled arg"), print("evaluated value"))
[1] 1

Cheers,
Simon


From wdunlap at tibco.com  Fri Dec 27 17:59:38 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 27 Dec 2013 16:59:38 +0000
Subject: [Rd] Parallel computing: how to transmit multiple parameters to
 a function in parLapply?
In-Reply-To: <52BD686C.80202@126.com>
References: <1387865734355-4682667.post@n4.nabble.com>
	<E66794E69CFDE04D9A70842786030B933FA1F0E8@PA-MBX01.na.tibco.com>
	<52BD686C.80202@126.com>
Message-ID: <E66794E69CFDE04D9A70842786030B933FA1F41A@PA-MBX01.na.tibco.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20131227/0c1abc34/attachment.pl>

From elad.zippory at gmail.com  Sun Dec 29 00:06:32 2013
From: elad.zippory at gmail.com (Elad Zippory)
Date: Sat, 28 Dec 2013 18:06:32 -0500
Subject: [Rd] help page of warnings()
Message-ID: <CA+aKpMd+eUty3BM+eirvBQ3CB8hr_PBKZ5eq-Yehz-TQEgnHEw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20131228/cdef3adc/attachment.pl>

From skostysh at princeton.edu  Sun Dec 29 03:19:20 2013
From: skostysh at princeton.edu (Scott Kostyshak)
Date: Sat, 28 Dec 2013 21:19:20 -0500
Subject: [Rd] help page of warnings()
In-Reply-To: <CA+aKpMd+eUty3BM+eirvBQ3CB8hr_PBKZ5eq-Yehz-TQEgnHEw@mail.gmail.com>
References: <CA+aKpMd+eUty3BM+eirvBQ3CB8hr_PBKZ5eq-Yehz-TQEgnHEw@mail.gmail.com>
Message-ID: <CAE3=dmfvHOw1jais_OO5DW--Z8fkA7rm=SCrBn=jwmFwONMy3g@mail.gmail.com>

On Sat, Dec 28, 2013 at 6:06 PM, Elad Zippory <elad.zippory at gmail.com> wrote:
> Hi,
>
> I raised this issue at stackoverflow and it was suggested to raise it here:
>
> >From the current help page, it is unclear that "warnings()" does not clear
> after rm(list=ls()). Currently the page states that:
>
> "Warning: It is undocumented where last.warning is stored nor that it is
> visible, and this is subject to change. Prior to R 2.4.0 it was stored in
> the workspace, but no longer."
>
> Yet, I suggest that, if to keep the current behavior or until the behavior
> is changed, at least write explicitly in the help file something like
> "clearing the global environment will not clear the warning list. To do so
> use assign("last.warning", NULL, envir = baseenv())"
>
> Thank you,
> Elad Zippory

Hi Elad,

I'm not a decision maker around here but I'm curious about your
suggestion. I always find it helpful to try to understand how people
use R and how they expect R to work.

>From what I understand, you agree that there's no contradiction of
behavior in terms of how R is documented to work and you agree that
rm(list=ls()) should indeed not clear the warnings list. First, let me
give my observation that I think the policy of writing R documentation
is to give sufficient information for what a function does. When there
is something surprising or there are performance issues to keep in
mind, occasionally the R documentation appropriately mentions what a
function does not do.

I think you are interested in making more of a "let's make it easier
on the user" argument so let me try to address that. I think it's easy
to learn how to find the last.warning object. This would only require
a user to read the first line of ?warnings and then to know about the
getAnywhere function. That's it.

In fact, I think that's too easy. I would personally be in favor of
making it _more_ difficult for a beginning user to modify
last.warning. I've never had to do such a thing and I would be
suspicious of beginning/intermediate users who claim there's a need
to. If you want a fresh R session, use a fresh R session. Clearing the
global environment will not give a fresh R session. Clearing the
global environment and clearing warnings will not do so either. In my
opinion, it is tricks like these that can lead to unfortunate
situations where results are not reproducible.

Also, you mention a Stack Overflow question. If you are going to refer
to something, please provide a link (perhaps in a footnote like this
[1] if you do not want to put a long distracting URL in your message).
Maybe there is no useful discussion there, but maybe there is and the
discussion has already raised the points I raise in this email. The
reader of your message is thus left wondering.

Let me note that I'm just an ordinary R user. I hope I don't scare you
off from giving more suggestions and wouldn't be surprised if others
disagree. I hope you send more messages like the one you just sent
because I'm interested in understanding what R users find confusing.

Best regards,

Scott

[1] an old but related Stack Overflow question:
http://stackoverflow.com/questions/5725106/r-how-to-clear-all-warnings

--
Scott Kostyshak
Economics PhD Candidate
Princeton University


From skostysh at princeton.edu  Sun Dec 29 09:51:55 2013
From: skostysh at princeton.edu (Scott Kostyshak)
Date: Sun, 29 Dec 2013 03:51:55 -0500
Subject: [Rd] help page of warnings()
In-Reply-To: <CA+aKpMfukGXVj9_QUwvh+LZg3-6_jJT76s_Go=9OUKo20YDnWQ@mail.gmail.com>
References: <CA+aKpMd+eUty3BM+eirvBQ3CB8hr_PBKZ5eq-Yehz-TQEgnHEw@mail.gmail.com>
	<CAE3=dmfvHOw1jais_OO5DW--Z8fkA7rm=SCrBn=jwmFwONMy3g@mail.gmail.com>
	<CA+aKpMfukGXVj9_QUwvh+LZg3-6_jJT76s_Go=9OUKo20YDnWQ@mail.gmail.com>
Message-ID: <CAE3=dmcrLm+_nhm5T_8RAm4VZfmFGKfupBm9ZkQ99xmYiW7thw@mail.gmail.com>

On Sat, Dec 28, 2013 at 11:19 PM, Elad Zippory <elad.zippory at gmail.com> wrote:
> Hi Scott,
>
> Thank you for your detailed response. (btw, the reason why I didn't link the
> Stack Overflow question is because I deleted it after I sent the e-mail).

Hi Elad,

Please keep the conversation on the list unless there is a reason for
it to be private, in which case please say so. This way everyone can
participate (and more importantly can correct my errors).

> The rationale behind my proposal was because I was surprised to learn that
> rm(list=ls()) does not clear the warning list. The reason why I was
> surprised is because it is not clear from the help page (if you are at a
> level that requires you to read the help page of such a base function, the
> warning that I quoted does not fully warn the 'user', who is not a
> 'developer', what is going on. Environments in R are not trivial knowledge
> that can be raised too concisely).

In some cases environments can be thought of like lists. As for how
name look-up goes, yes it takes some studying to learn about that.

> The reason why it mattered is because I am writing a program to be run on
> our HPC, and I want it to abort when there is a warning so I can attend to
> it right away. No point to discover after expensive usage that some warning
> should be investigated, casting doubt on several days of computation. It is
> also useful when writing recursive code, to abort immediately when the
> warning list is populated as it is very hard to understand what went wrong,
> and especially, where...

This is a great programming strategy. You might be interested in one
of my favorite recommendations: treat warnings like errors.

options(warn = 2) # asks R to treat warnings as errors. See ?options

As far as knowing more precisely where something went wrong (where not
in the sense of what line of code, but in which function), consider
using the traceback function. Or, in addition to the above options
command, you might like:

options(error = recover) # asks R to enter the debugger when there is an error

and because warnings are now errors, it also enters the debugger for
warnings. This way you can poke around where the warning occurred.

> So, those were my motivations. Again, if I would know that I need a fresh R
> session, I would get it. I don't like 'touching' what I don't understand. I
> just wish I knew I needed to do so without wasting a day trying to debug a
> warning, where all my actions to debug it were 'virtual'.

I still don't see a need to manually access last.warning for the
situation you described.

> Again, thank you for your detailed response, I hope that the case I am
> making is clearer now.

Thank you for giving more details on what you're trying to accomplish.

Scott


--
Scott Kostyshak
Economics PhD Candidate
Princeton University

> Best regards,
> Elad Zippory
> Ph.D student
> Politics, NYU

> On Sat, Dec 28, 2013 at 9:19 PM, Scott Kostyshak <skostysh at princeton.edu>
> wrote:
>>
>> On Sat, Dec 28, 2013 at 6:06 PM, Elad Zippory <elad.zippory at gmail.com>
>> wrote:
>> > Hi,
>> >
>> > I raised this issue at stackoverflow and it was suggested to raise it
>> > here:
>> >
>> > >From the current help page, it is unclear that "warnings()" does not
>> > clear
>> > after rm(list=ls()). Currently the page states that:
>> >
>> > "Warning: It is undocumented where last.warning is stored nor that it is
>> > visible, and this is subject to change. Prior to R 2.4.0 it was stored
>> > in
>> > the workspace, but no longer."
>> >
>> > Yet, I suggest that, if to keep the current behavior or until the
>> > behavior
>> > is changed, at least write explicitly in the help file something like
>> > "clearing the global environment will not clear the warning list. To do
>> > so
>> > use assign("last.warning", NULL, envir = baseenv())"
>> >
>> > Thank you,
>> > Elad Zippory
>>
>> Hi Elad,
>>
>> I'm not a decision maker around here but I'm curious about your
>> suggestion. I always find it helpful to try to understand how people
>> use R and how they expect R to work.
>>
>> From what I understand, you agree that there's no contradiction of
>> behavior in terms of how R is documented to work and you agree that
>> rm(list=ls()) should indeed not clear the warnings list. First, let me
>> give my observation that I think the policy of writing R documentation
>> is to give sufficient information for what a function does. When there
>> is something surprising or there are performance issues to keep in
>> mind, occasionally the R documentation appropriately mentions what a
>> function does not do.
>>
>> I think you are interested in making more of a "let's make it easier
>> on the user" argument so let me try to address that. I think it's easy
>> to learn how to find the last.warning object. This would only require
>> a user to read the first line of ?warnings and then to know about the
>> getAnywhere function. That's it.
>>
>> In fact, I think that's too easy. I would personally be in favor of
>> making it _more_ difficult for a beginning user to modify
>> last.warning. I've never had to do such a thing and I would be
>> suspicious of beginning/intermediate users who claim there's a need
>> to. If you want a fresh R session, use a fresh R session. Clearing the
>> global environment will not give a fresh R session. Clearing the
>> global environment and clearing warnings will not do so either. In my
>> opinion, it is tricks like these that can lead to unfortunate
>> situations where results are not reproducible.
>>
>> Also, you mention a Stack Overflow question. If you are going to refer
>> to something, please provide a link (perhaps in a footnote like this
>> [1] if you do not want to put a long distracting URL in your message).
>> Maybe there is no useful discussion there, but maybe there is and the
>> discussion has already raised the points I raise in this email. The
>> reader of your message is thus left wondering.
>>
>> Let me note that I'm just an ordinary R user. I hope I don't scare you
>> off from giving more suggestions and wouldn't be surprised if others
>> disagree. I hope you send more messages like the one you just sent
>> because I'm interested in understanding what R users find confusing.
>>
>> Best regards,
>>
>> Scott
>>
>> [1] an old but related Stack Overflow question:
>> http://stackoverflow.com/questions/5725106/r-how-to-clear-all-warnings
>>
>> --
>> Scott Kostyshak
>> Economics PhD Candidate
>> Princeton University
>
>


From elad.zippory at gmail.com  Mon Dec 30 03:57:55 2013
From: elad.zippory at gmail.com (Elad Zippory)
Date: Sun, 29 Dec 2013 21:57:55 -0500
Subject: [Rd] help page of warnings()
In-Reply-To: <CAE3=dmcrLm+_nhm5T_8RAm4VZfmFGKfupBm9ZkQ99xmYiW7thw@mail.gmail.com>
References: <CA+aKpMd+eUty3BM+eirvBQ3CB8hr_PBKZ5eq-Yehz-TQEgnHEw@mail.gmail.com>
	<CAE3=dmfvHOw1jais_OO5DW--Z8fkA7rm=SCrBn=jwmFwONMy3g@mail.gmail.com>
	<CA+aKpMfukGXVj9_QUwvh+LZg3-6_jJT76s_Go=9OUKo20YDnWQ@mail.gmail.com>
	<CAE3=dmcrLm+_nhm5T_8RAm4VZfmFGKfupBm9ZkQ99xmYiW7thw@mail.gmail.com>
Message-ID: <CA+aKpMcPi0CHou3uGytWigT0YuFGKJj2Zxy4pibyVOgohi+XBQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20131229/ffb91e12/attachment.pl>

From gmbecker at ucdavis.edu  Mon Dec 30 06:27:26 2013
From: gmbecker at ucdavis.edu (Gabriel Becker)
Date: Sun, 29 Dec 2013 21:27:26 -0800
Subject: [Rd] help page of warnings()
In-Reply-To: <CA+aKpMcPi0CHou3uGytWigT0YuFGKJj2Zxy4pibyVOgohi+XBQ@mail.gmail.com>
References: <CA+aKpMd+eUty3BM+eirvBQ3CB8hr_PBKZ5eq-Yehz-TQEgnHEw@mail.gmail.com>
	<CAE3=dmfvHOw1jais_OO5DW--Z8fkA7rm=SCrBn=jwmFwONMy3g@mail.gmail.com>
	<CA+aKpMfukGXVj9_QUwvh+LZg3-6_jJT76s_Go=9OUKo20YDnWQ@mail.gmail.com>
	<CAE3=dmcrLm+_nhm5T_8RAm4VZfmFGKfupBm9ZkQ99xmYiW7thw@mail.gmail.com>
	<CA+aKpMcPi0CHou3uGytWigT0YuFGKJj2Zxy4pibyVOgohi+XBQ@mail.gmail.com>
Message-ID: <CADwqtCN3x95-oGgzgzj77QDjsh6pRDhuTfiYUT1DMMXSQqZ4og@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20131229/189631d6/attachment.pl>

From barthelemy at geovariances.com  Mon Dec 30 10:47:10 2013
From: barthelemy at geovariances.com (Olivier BARTHELEMY)
Date: Mon, 30 Dec 2013 10:47:10 +0100
Subject: [Rd] Symlinks when building R on windows
In-Reply-To: <52B19F83.4020707@gmail.com>
References: <CAK9jXVXuzVbDF5s10_0BDnVyNN6bESTBmUrUtg7Yh_iS-At=tA@mail.gmail.com>
	<52B19F83.4020707@gmail.com>
Message-ID: <CAK9jXVUA6xULbzFbq4qExZzhe+oK-paTnH0fbCe2bQdgRBBqOg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20131230/c3f4d29b/attachment.pl>

From murdoch.duncan at gmail.com  Mon Dec 30 13:04:29 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 30 Dec 2013 07:04:29 -0500
Subject: [Rd] Symlinks when building R on windows
In-Reply-To: <CAK9jXVUA6xULbzFbq4qExZzhe+oK-paTnH0fbCe2bQdgRBBqOg@mail.gmail.com>
References: <CAK9jXVXuzVbDF5s10_0BDnVyNN6bESTBmUrUtg7Yh_iS-At=tA@mail.gmail.com>	<52B19F83.4020707@gmail.com>
	<CAK9jXVUA6xULbzFbq4qExZzhe+oK-paTnH0fbCe2bQdgRBBqOg@mail.gmail.com>
Message-ID: <52C1614D.5010307@gmail.com>

On 13-12-30 4:47 AM, Olivier BARTHELEMY wrote:
> Ok, i used the procedure in the manual. I think i am almost at the end of
> the build process. I am stuck however at the build of grDevices module.
> While byte-compiling it, i get the following error :
> Error in solve.default(rgb) : 'a' must be a complex matrix
> The line of that syntax errror can be found back in make.rgb of
> src/library/grDevices/R/convertColor.R
> I doubt this file has a syntax error. The only possible cause i can think
> of is if the previous rbind that creates rgb returns NULL, but i can't find
> what would cause that.
> Any hints on where i could look for the problem?

I've never seen that error, so can't offer much help.  Did you delete 
everything from your previous unsuccessful build attempts?

Do note that it is not a syntax error, it's an evaluation error.  It 
would likely have happened during the construction of the colorspaces 
list, which calls make.rgb later in that same file.  You could insert 
print() or message() statements to localize the error, but it's not an 
error that should have happened in a valid build.

Duncan Murdoch

>
> I hope this is not too offtopic with the initial subject and the
> developmenet mailing list
>
>
> 2013/12/18 Duncan Murdoch <murdoch.duncan at gmail.com>
>
>> On 13-12-18 5:24 AM, Olivier BARTHELEMY wrote:
>>
>>> I think this is more suited for the devel mailing list than the help one.
>>>
>>> I'm trying to build R on windows, With Rtools installed, and
>>> configure/make
>>> in R-3.0.2 sources folder from a cygwin console.
>>>
>>
>> This doesn't sound like a good idea.  The Rtools are set up for native
>> Windows builds.  If you run configure yourself, you'll be targeting a
>> Cygwin build -- but that's something we don't support.
>>
>> What you should do is follow the instructions for native Windows builds
>> that are given in chapter 3 of the Installation and Administration manual.
>>   In particular, *do not* run configure.
>>
>> If you do choose to create a Cygwin build, please make sure it passes the
>> tests before you use it.  I haven't seen one that does.
>>
>> Duncan Murdoch
>>
>>
>>
>>   I am stuck at the moment, because the build process tries create symlinks,
>>> and gcc build fails because the opened files containe the metadata of the
>>> not working symlink, and not the linked file.
>>> The first problematic files is src/extra/xz/alone_decoder.c, pointing to
>>> common/alone_decoder.c, but i guess the following buildt files would have
>>> the same problem.
>>> My configure didn't even detect the symlink cmd off cygwin while
>>> performing
>>> the tests, and i even launched configure with --disable-symlinks, but
>>> their
>>> creationis attmpted anyways.
>>> Is there any quick way to workaround that? And since it's .c or.h files we
>>> are symlinking here, couldn't we simply do 'eponym' C or h files that do a
>>> C #include to the relative path, which would be more portable than
>>> symlinks?
>>>
>>>
>>
>
>


From h.wickham at gmail.com  Mon Dec 30 15:17:08 2013
From: h.wickham at gmail.com (Hadley Wickham)
Date: Mon, 30 Dec 2013 08:17:08 -0600
Subject: [Rd] help page of warnings()
In-Reply-To: <CADwqtCN3x95-oGgzgzj77QDjsh6pRDhuTfiYUT1DMMXSQqZ4og@mail.gmail.com>
References: <CA+aKpMd+eUty3BM+eirvBQ3CB8hr_PBKZ5eq-Yehz-TQEgnHEw@mail.gmail.com>
	<CAE3=dmfvHOw1jais_OO5DW--Z8fkA7rm=SCrBn=jwmFwONMy3g@mail.gmail.com>
	<CA+aKpMfukGXVj9_QUwvh+LZg3-6_jJT76s_Go=9OUKo20YDnWQ@mail.gmail.com>
	<CAE3=dmcrLm+_nhm5T_8RAm4VZfmFGKfupBm9ZkQ99xmYiW7thw@mail.gmail.com>
	<CA+aKpMcPi0CHou3uGytWigT0YuFGKJj2Zxy4pibyVOgohi+XBQ@mail.gmail.com>
	<CADwqtCN3x95-oGgzgzj77QDjsh6pRDhuTfiYUT1DMMXSQqZ4og@mail.gmail.com>
Message-ID: <CABdHhvG2OhFEKUu7oEvNgV0mFhffBZz-pic+Um8ULr9SzNVKqQ@mail.gmail.com>

> Finally, for your specific use case, see also ?withCallingHandlers which
> can not only detect warnings, but also set callback functions which can
> decide whether to abort or process and restart when a warning is thrown.
> The documentation for that function is a little rough, though you can see
> it in action in Hadley Wickham's evaluate package (specifically
> evaluate/R/eval.r).

I've also written a little about it at
http://adv-r.had.co.nz/Exceptions-Debugging.html#condition-handling.

But I think the main problem is assuming that rm(list=ls()) "resets"
back to a clean state.  Apart from the last warning, there are many
other things that this command will not clean up. You're much better
off getting into the habit of restarting R. In Rstudio, this is
particularly convenient because there's a keyboard shortcut (cmd +
shift + F10).

Hadley

-- 
http://had.co.nz/


From barthelemy at geovariances.com  Mon Dec 30 17:43:02 2013
From: barthelemy at geovariances.com (Olivier BARTHELEMY)
Date: Mon, 30 Dec 2013 17:43:02 +0100
Subject: [Rd] Symlinks when building R on windows
In-Reply-To: <52C1614D.5010307@gmail.com>
References: <CAK9jXVXuzVbDF5s10_0BDnVyNN6bESTBmUrUtg7Yh_iS-At=tA@mail.gmail.com>
	<52B19F83.4020707@gmail.com>
	<CAK9jXVUA6xULbzFbq4qExZzhe+oK-paTnH0fbCe2bQdgRBBqOg@mail.gmail.com>
	<52C1614D.5010307@gmail.com>
Message-ID: <CAK9jXVUgFkXKSWzYYaJto3nHApf2dnRJ8zWMCggSQ0=vvSVB=w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20131230/d470c914/attachment.pl>

From sachko.honda at mountainpacificgroup.com  Tue Dec 31 02:06:50 2013
From: sachko.honda at mountainpacificgroup.com (Sachko Honda)
Date: Mon, 30 Dec 2013 19:06:50 -0600
Subject: [Rd] SQLite database file gets corrupted and XP goes blue
Message-ID: <42143135B5270A45996065C2EFFC2B590BB98C58@MBX39.exg5.exghost.com>

Dear fellows,

I'm getting blue screen on XP while populating SQLite database, using
RStudio and RQLite package.

The blue screen says "INVALID PROCESS ATTACH ATTEMPT" before goes into
memory check and reboot.
The database (file) is corrupted and not readable after this happens.

I'm iterating over CSV files, each contans a time-series of as many as
500x5000: rows being dates, columns being dependent variables.  For each
CSV creates a 500x5000 matrix (preallocated), and it is "remove"-ed
immediately after its use, among other relatively large objects.

Without this explicit resource deallocation, the blue screen stuff
occurred at much earlier during the process.

Still, XP's Process Monitor shows steady increase in memory usage. 

My XP has 3GB RAM.  It seems that the screen goes blue when the usage
goes near 1GB.

The database file, when it is corrupted, has only 150MB.  SQLite's max
db size is 2TB, XP32's max file size is 4GB.  So, I'm well under the limits.

In the past, when an R process goes out of memory, it rather graceful
returned, like "Out of memory".

I have closed any other applications that accesses the database such as
SQLite Browser.

Any insight appreciated.
Sachko


From h.wickham at gmail.com  Tue Dec 31 16:22:35 2013
From: h.wickham at gmail.com (Hadley Wickham)
Date: Tue, 31 Dec 2013 09:22:35 -0600
Subject: [Rd] SQLite database file gets corrupted and XP goes blue
In-Reply-To: <42143135B5270A45996065C2EFFC2B590BB98C58@MBX39.exg5.exghost.com>
References: <42143135B5270A45996065C2EFFC2B590BB98C58@MBX39.exg5.exghost.com>
Message-ID: <CABdHhvH5W_U8MsEgbn+K=J0kqa1o7VriM-RieKStbxoYDEvzgg@mail.gmail.com>

I'd recommend sending a reproducible example to the maintainer of the
RSQLite package (cc'd in case he doesn't follow r-devel any more)
Hadley

On Mon, Dec 30, 2013 at 7:06 PM, Sachko Honda
<sachko.honda at mountainpacificgroup.com> wrote:
> Dear fellows,
>
> I'm getting blue screen on XP while populating SQLite database, using
> RStudio and RQLite package.
>
> The blue screen says "INVALID PROCESS ATTACH ATTEMPT" before goes into
> memory check and reboot.
> The database (file) is corrupted and not readable after this happens.
>
> I'm iterating over CSV files, each contans a time-series of as many as
> 500x5000: rows being dates, columns being dependent variables.  For each
> CSV creates a 500x5000 matrix (preallocated), and it is "remove"-ed
> immediately after its use, among other relatively large objects.
>
> Without this explicit resource deallocation, the blue screen stuff
> occurred at much earlier during the process.
>
> Still, XP's Process Monitor shows steady increase in memory usage.
>
> My XP has 3GB RAM.  It seems that the screen goes blue when the usage
> goes near 1GB.
>
> The database file, when it is corrupted, has only 150MB.  SQLite's max
> db size is 2TB, XP32's max file size is 4GB.  So, I'm well under the limits.
>
> In the past, when an R process goes out of memory, it rather graceful
> returned, like "Out of memory".
>
> I have closed any other applications that accesses the database such as
> SQLite Browser.
>
> Any insight appreciated.
> Sachko
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel



-- 
http://had.co.nz/


