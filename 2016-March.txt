From daroczig at rapporter.net  Tue Mar  1 09:11:03 2016
From: daroczig at rapporter.net (=?UTF-8?Q?Gergely_Dar=C3=B3czi?=)
Date: Tue, 1 Mar 2016 00:11:03 -0800
Subject: [Rd] Milestone: 8000 packages on CRAN
In-Reply-To: <CAFDcVCSwKGzHEgVytUBeJ3k4QE_fPFTk0njk-9TBpH4_o5f4Vg@mail.gmail.com>
References: <CAFDcVCSwKGzHEgVytUBeJ3k4QE_fPFTk0njk-9TBpH4_o5f4Vg@mail.gmail.com>
Message-ID: <CAPvvxJWxgouN3-4-bDmTY-nbvQAJOaZ4n9zSg_pXbqUzVh4fEQ@mail.gmail.com>

Thank you very much, Henrik, for maintaining this list -- it's always
a pleasure to see the ever growing number of useful R packages!

I decided a few times in the past to extend your research with the
list of archived packages, but did not actually start coding -- until
tonight: https://gist.github.com/daroczig/3cf06d6db4be2bbe3368 (this
includes the a CSV with 9K rows, so might be slow to load -- but it;s
worth waiting, as you get a searchable list of package names, dates &
index)

In short, combining the list of current CRAN packages + the list of
archived packages results in a list with more than 9,000 R packages by
now with the following milestones (using the numbers from your
analysis):

##      date              index   name
##  1: 2016-01-12   9000   dChipIO
##  2: 2015-06-30   8000   gkmSVM
##  3: 2014-10-22   7000   glmvsd
##  4: 2014-02-05   6000   bilan
##  5: 2013-03-20   5000   Rgnuplot
##  6: 2012-06-21   4000   HIBAG
##  7: 2011-04-24   3000   SPECIES
##  8: 2009-09-10   2000   maticce
##  9: 2007-03-11   1000   cairoDevice
## 10: 2005-02-21    500   micEcon
## 11: 2003-03-19    250   polspline

So including the archived packages in this report, 8K was actually
reached at the time of useR! 2015 :)

Best,
Gergely

On Mon, Feb 29, 2016 at 12:54 PM, Henrik Bengtsson
<henrik.bengtsson at gmail.com> wrote:
> Another 1000 packages were added to CRAN, which took less than 7
> months. Today (February 29, 2017), the Comprehensive R Archive Network
> (CRAN) [1] reports:
>
> ?Currently, the CRAN package repository features 8002 available packages.?
>
> The rate with which new packages are added to CRAN is increasing.  In
> 2014-2015 we had 1000 packages added to CRAN in 355 days (2.8 per
> day), the following 1000 packages took 287 days (3.5 per day) and now
> the most recent 1000 packages clocked in at an impressive 201 days
> (5.0 per day).  Since the start of CRAN 18.9 years ago on April 23,
> 1997 [2], there has been on average one new package appearing on CRAN
> every 20.6 hours - it is actually more frequent than that because
> dropped/archived packages are not accounted for. The 8000 packages on
> CRAN are maintained by ~4279 people [3].
>
> Thanks to the CRAN team and to all package developers. You can give
> back by carefully reporting bugs to the maintainers, properly citing
> any packages you use in your publications, cf. citation("pkg name")
> and help out helping others using the R.
>
> Milestones:
>
> 2016-02-29: 8000 packages [this post]
> 2015-08-12: 7000 packages [11]
> 2014-10-29: 6000 packages [10]
> 2013-11-08: 5000 packages [9]
> 2012-08-23: 4000 packages [8]
> 2011-05-12: 3000 packages [7]
> 2009-10-04: 2000 packages [6]
> 2007-04-12: 1000 packages [5]
> 2004-10-01: 500 packages [4]
> 2003-04-01: 250 packages [4]
>
> These data are for CRAN only. There are many more packages elsewhere,
> e.g. R-Forge, Bioconductor, Github etc.
>
> [1] http://cran.r-project.org/web/packages/
> [2] https://en.wikipedia.org/wiki/R_(programming_language)#Milestones
> [3] http://www.r-pkg.org/
> [4] Private data
> [5] https://stat.ethz.ch/pipermail/r-devel/2007-April/045359.html
> [6] https://stat.ethz.ch/pipermail/r-devel/2009-October/055049.html
> [7] https://stat.ethz.ch/pipermail/r-devel/2011-May/061002.html
> [8] https://stat.ethz.ch/pipermail/r-devel/2012-August/064675.html
> [9] https://stat.ethz.ch/pipermail/r-devel/2013-November/067935.html
> [10] https://stat.ethz.ch/pipermail/r-devel/2014-October/069997.html
> [11] https://stat.ethz.ch/pipermail/r-package-devel/2015q3/000393.html
>
> Thanks
>
> Henrik
> (a long-term fan)
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From h.wickham at gmail.com  Tue Mar  1 16:12:00 2016
From: h.wickham at gmail.com (Hadley Wickham)
Date: Tue, 1 Mar 2016 09:12:00 -0600
Subject: [Rd] Data frame printing buglet when multiple empty column names
Message-ID: <CABdHhvEZbfENNUp8w1SszEFkKYfGNAsvZ_KXw=wMhqebmv0DAg@mail.gmail.com>

This is admittedly minor, and you shouldn't have repeated names in a
data frame anyway, but:

df <- data.frame(1:3, 1:3, 1:3)

# Ok
setNames(df, c("x", "y", ""))

# Not ok
setNames(df, c("x", "", ""))

Hadley

-- 
http://hadley.nz


From henrik.bengtsson at gmail.com  Tue Mar  1 17:58:22 2016
From: henrik.bengtsson at gmail.com (Henrik Bengtsson)
Date: Tue, 1 Mar 2016 08:58:22 -0800
Subject: [Rd] Milestone: 8000 packages on CRAN
In-Reply-To: <CAPvvxJWxgouN3-4-bDmTY-nbvQAJOaZ4n9zSg_pXbqUzVh4fEQ@mail.gmail.com>
References: <CAFDcVCSwKGzHEgVytUBeJ3k4QE_fPFTk0njk-9TBpH4_o5f4Vg@mail.gmail.com>
	<CAPvvxJWxgouN3-4-bDmTY-nbvQAJOaZ4n9zSg_pXbqUzVh4fEQ@mail.gmail.com>
Message-ID: <CAFDcVCR0pu8uHDqjFiPV2x92O98+-sqyKJz91S=9GFWM5ZsGjw@mail.gmail.com>

Thank you Gergely - great work.

So on planet CRAN with have a large living population of packages and
some deceased packages of the past ... and then there are packages
that reincarnate one or more times.

I wonder how long it will be before someone makes this into an R data
package? ;)

Cheers,

Henrik

On Tue, Mar 1, 2016 at 12:11 AM, Gergely Dar?czi <daroczig at rapporter.net> wrote:
> Thank you very much, Henrik, for maintaining this list -- it's always
> a pleasure to see the ever growing number of useful R packages!
>
> I decided a few times in the past to extend your research with the
> list of archived packages, but did not actually start coding -- until
> tonight: https://gist.github.com/daroczig/3cf06d6db4be2bbe3368 (this
> includes the a CSV with 9K rows, so might be slow to load -- but it;s
> worth waiting, as you get a searchable list of package names, dates &
> index)
>
> In short, combining the list of current CRAN packages + the list of
> archived packages results in a list with more than 9,000 R packages by
> now with the following milestones (using the numbers from your
> analysis):
>
> ##      date              index   name
> ##  1: 2016-01-12   9000   dChipIO
> ##  2: 2015-06-30   8000   gkmSVM
> ##  3: 2014-10-22   7000   glmvsd
> ##  4: 2014-02-05   6000   bilan
> ##  5: 2013-03-20   5000   Rgnuplot
> ##  6: 2012-06-21   4000   HIBAG
> ##  7: 2011-04-24   3000   SPECIES
> ##  8: 2009-09-10   2000   maticce
> ##  9: 2007-03-11   1000   cairoDevice
> ## 10: 2005-02-21    500   micEcon
> ## 11: 2003-03-19    250   polspline
>
> So including the archived packages in this report, 8K was actually
> reached at the time of useR! 2015 :)
>
> Best,
> Gergely
>
> On Mon, Feb 29, 2016 at 12:54 PM, Henrik Bengtsson
> <henrik.bengtsson at gmail.com> wrote:
>> Another 1000 packages were added to CRAN, which took less than 7
>> months. Today (February 29, 2017), the Comprehensive R Archive Network
>> (CRAN) [1] reports:
>>
>> ?Currently, the CRAN package repository features 8002 available packages.?
>>
>> The rate with which new packages are added to CRAN is increasing.  In
>> 2014-2015 we had 1000 packages added to CRAN in 355 days (2.8 per
>> day), the following 1000 packages took 287 days (3.5 per day) and now
>> the most recent 1000 packages clocked in at an impressive 201 days
>> (5.0 per day).  Since the start of CRAN 18.9 years ago on April 23,
>> 1997 [2], there has been on average one new package appearing on CRAN
>> every 20.6 hours - it is actually more frequent than that because
>> dropped/archived packages are not accounted for. The 8000 packages on
>> CRAN are maintained by ~4279 people [3].
>>
>> Thanks to the CRAN team and to all package developers. You can give
>> back by carefully reporting bugs to the maintainers, properly citing
>> any packages you use in your publications, cf. citation("pkg name")
>> and help out helping others using the R.
>>
>> Milestones:
>>
>> 2016-02-29: 8000 packages [this post]
>> 2015-08-12: 7000 packages [11]
>> 2014-10-29: 6000 packages [10]
>> 2013-11-08: 5000 packages [9]
>> 2012-08-23: 4000 packages [8]
>> 2011-05-12: 3000 packages [7]
>> 2009-10-04: 2000 packages [6]
>> 2007-04-12: 1000 packages [5]
>> 2004-10-01: 500 packages [4]
>> 2003-04-01: 250 packages [4]
>>
>> These data are for CRAN only. There are many more packages elsewhere,
>> e.g. R-Forge, Bioconductor, Github etc.
>>
>> [1] http://cran.r-project.org/web/packages/
>> [2] https://en.wikipedia.org/wiki/R_(programming_language)#Milestones
>> [3] http://www.r-pkg.org/
>> [4] Private data
>> [5] https://stat.ethz.ch/pipermail/r-devel/2007-April/045359.html
>> [6] https://stat.ethz.ch/pipermail/r-devel/2009-October/055049.html
>> [7] https://stat.ethz.ch/pipermail/r-devel/2011-May/061002.html
>> [8] https://stat.ethz.ch/pipermail/r-devel/2012-August/064675.html
>> [9] https://stat.ethz.ch/pipermail/r-devel/2013-November/067935.html
>> [10] https://stat.ethz.ch/pipermail/r-devel/2014-October/069997.html
>> [11] https://stat.ethz.ch/pipermail/r-package-devel/2015q3/000393.html
>>
>> Thanks
>>
>> Henrik
>> (a long-term fan)
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel


From maechler at stat.math.ethz.ch  Tue Mar  1 19:48:30 2016
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 1 Mar 2016 19:48:30 +0100
Subject: [Rd] Data frame printing buglet when multiple empty column names
In-Reply-To: <CABdHhvEZbfENNUp8w1SszEFkKYfGNAsvZ_KXw=wMhqebmv0DAg@mail.gmail.com>
References: <CABdHhvEZbfENNUp8w1SszEFkKYfGNAsvZ_KXw=wMhqebmv0DAg@mail.gmail.com>
Message-ID: <22229.58366.599055.635348@stat.math.ethz.ch>

>>>>> Hadley Wickham <h.wickham at gmail.com>
>>>>>     on Tue, 1 Mar 2016 09:12:00 -0600 writes:

    > This is admittedly minor, and you shouldn't have repeated names in a
    > data frame anyway, but:

    > df <- data.frame(1:3, 1:3, 1:3)

    > # Ok
    > setNames(df, c("x", "y", ""))

    > # Not ok
    > setNames(df, c("x", "", ""))

    > Hadley
    > -- 
    > http://hadley.nz

This has been fixed in R-devel several months ago, but not been
ported to R-patched, the change really being in
format.data.frame(.)  which in R-devel makes use of a quite
smartly improved as.data.frame.list() method.

At the time, I was reluctant to port all these changes to
R-patched, as they were non trivial... but indeed I did like the
result (code, not just this case) quite a bit better.

This is the log entry 
------------------------------------------------------------------------
r69582 | maechler | 2015-10-29 17:12:54 +0100 (Thu, 29 Oct 2015) | 2 lines

PR#16580: data frames with column name "StringsAsFactors" now format and print correctly;
  data.frame() gains argument `fix.empty.names` and as.data.frame.list() gets new `cut.names`, `col.names` and `fix.empty.names`.
------------------------------------------------------------------------


I'm still a bit reluctant to port this to R-patched... but may
could be motivated ...

Martin


From pdalgd at gmail.com  Tue Mar  1 21:13:36 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Tue, 1 Mar 2016 21:13:36 +0100
Subject: [Rd] Source code of early S versions
In-Reply-To: <CANVKczNSrz-imi01Rxsph3p4y_N2OMEFHcKAdH+W4E-qMCJh1w@mail.gmail.com>
References: <CANVKczMqo7qC1OU-a2sq3LHTP9T5k+xCuLXZUvpNmd323aWaWg@mail.gmail.com>
	<cd82998773964e899c6cd4a1a947a8b8@EX-0-HT0.lancs.local>
	<CANVKczNSrz-imi01Rxsph3p4y_N2OMEFHcKAdH+W4E-qMCJh1w@mail.gmail.com>
Message-ID: <58CD97E3-51F6-4647-B99C-C7B6B33C877C@gmail.com>


> On 29 Feb 2016, at 19:54 , Barry Rowlingson <b.rowlingson at lancaster.ac.uk> wrote:
> 
>> PS:  somehow "historical" would be less unnerving than "archeological"
> 
> At least I didn't say palaeontological.

So John should feel more like stone age than dinosaur?

(Some portion of this must be a fortune candidate!)

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From Achim.Zeileis at uibk.ac.at  Tue Mar  1 21:39:56 2016
From: Achim.Zeileis at uibk.ac.at (Achim Zeileis)
Date: Tue, 1 Mar 2016 21:39:56 +0100 (CET)
Subject: [Rd] Source code of early S versions
In-Reply-To: <58CD97E3-51F6-4647-B99C-C7B6B33C877C@gmail.com>
References: <CANVKczMqo7qC1OU-a2sq3LHTP9T5k+xCuLXZUvpNmd323aWaWg@mail.gmail.com>
	<cd82998773964e899c6cd4a1a947a8b8@EX-0-HT0.lancs.local>
	<CANVKczNSrz-imi01Rxsph3p4y_N2OMEFHcKAdH+W4E-qMCJh1w@mail.gmail.com>
	<58CD97E3-51F6-4647-B99C-C7B6B33C877C@gmail.com>
Message-ID: <alpine.DEB.2.20.1603012138590.337@paninaro>

On Tue, 1 Mar 2016, peter dalgaard wrote:

>
>> On 29 Feb 2016, at 19:54 , Barry Rowlingson <b.rowlingson at lancaster.ac.uk> wrote:
>>
>>> PS:  somehow "historical" would be less unnerving than "archeological"
>>
>> At least I didn't say palaeontological.
>
> So John should feel more like stone age than dinosaur?
>
> (Some portion of this must be a fortune candidate!)

:-) Unless anyone objects:

R> fortune(373)

Barry Rowlingson: I've been unable to locate any version of S online. Does
anyone have a copy, somewhere, rusting away on an old hard disk or slowly
flaking off a tape? [...] Obviously this would be for archaeological 
purposes.
John Chambers: [...] somehow "historical" would be less unnerving than
"archeological".
Barry Rowlingson: At least I didn't say palaeontological.
    -- Barry Rowlingson and John Chambers (on the availability of the
       source code for early versions of S)
       R-devel (February 2016)


> -- 
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Office: A 4.23
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>
>
>
>
>
>
>
>
>
>


From h.wickham at gmail.com  Tue Mar  1 23:48:24 2016
From: h.wickham at gmail.com (Hadley Wickham)
Date: Tue, 1 Mar 2016 16:48:24 -0600
Subject: [Rd] Data frame printing buglet when multiple empty column names
In-Reply-To: <22229.58366.599055.635348@stat.math.ethz.ch>
References: <CABdHhvEZbfENNUp8w1SszEFkKYfGNAsvZ_KXw=wMhqebmv0DAg@mail.gmail.com>
	<22229.58366.599055.635348@stat.math.ethz.ch>
Message-ID: <CABdHhvF25TDGeOCPuwp6puowC0fKEss_Qhp+B9ZDjqzBQ3BR7w@mail.gmail.com>

On Tue, Mar 1, 2016 at 12:48 PM, Martin Maechler
<maechler at stat.math.ethz.ch> wrote:
>>>>>> Hadley Wickham <h.wickham at gmail.com>
>>>>>>     on Tue, 1 Mar 2016 09:12:00 -0600 writes:
>
>     > This is admittedly minor, and you shouldn't have repeated names in a
>     > data frame anyway, but:
>
>     > df <- data.frame(1:3, 1:3, 1:3)
>
>     > # Ok
>     > setNames(df, c("x", "y", ""))
>
>     > # Not ok
>     > setNames(df, c("x", "", ""))
>
>     > Hadley
>     > --
>     > http://hadley.nz
>
> This has been fixed in R-devel several months ago, but not been
> ported to R-patched, the change really being in
> format.data.frame(.)  which in R-devel makes use of a quite
> smartly improved as.data.frame.list() method.

Thanks Martin!

> At the time, I was reluctant to port all these changes to
> R-patched, as they were non trivial... but indeed I did like the
> result (code, not just this case) quite a bit better.
>
> This is the log entry
> ------------------------------------------------------------------------
> r69582 | maechler | 2015-10-29 17:12:54 +0100 (Thu, 29 Oct 2015) | 2 lines
>
> PR#16580: data frames with column name "StringsAsFactors" now format and print correctly;
>   data.frame() gains argument `fix.empty.names` and as.data.frame.list() gets new `cut.names`, `col.names` and `fix.empty.names`.
> ------------------------------------------------------------------------
>
>
> I'm still a bit reluctant to port this to R-patched... but may
> could be motivated ...

It's not high priority for me - I'm happy knowing that it'll be fixed in R 3.3.0

Hadley

-- 
http://hadley.nz


From thierry.onkelinx at inbo.be  Wed Mar  2 10:16:28 2016
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Wed, 2 Mar 2016 10:16:28 +0100
Subject: [Rd] install.packages() fails with drat repository on networkdrive
Message-ID: <CAJuCY5w-BC8ePSD_-g=tcRiWgtQ9ik-FSaDWz1WwZLtC4yKBcw@mail.gmail.com>

Dear all,

install.packages("lme4") fails with error
Error in read.dcf(file = tmpf) : cannot open the connection
In addition: Warning message:
In read.dcf(file = tmpf) :
  cannot open compressed file
'//servername/repository_path/bin/windows/contrib/3.2/PACKAGES',
probable reason 'No such file or directory'

the repositories set in .Rprofile are
"http://lib.ugent.be/CRAN/" "file://servername/repository_path"

There is a file PACKAGES.gz at
//servername/repository_path/bin/windows/contrib/3.2/ but no file
PACKAGES

I'm not sure if this is
1) a bug in the drat package: not creating PACKAGES
2) a bug in read.dcf(): not looking if PACKAGES.gz is present
3) a bug in available.packages(). Debugging install.packages()
indicates that the error occurs at the line below with type <-
"win.binary", repos <- getOption("repos") and missing(method) == TRUE

av2 <- available.packages(contriburl = contrib.url(repos, type2),
method = method)

It would be nice if available.packages() handled an error returned by
read.dcf() more gracefully. An error with one repository now
completely blocks install.packages()

sessionInfo("drat")
R version 3.2.3 (2015-12-10)
Platform: i386-w64-mingw32/i386 (32-bit)
Running under: Windows 7 x64 (build 7601) Service Pack 1

locale:
[1] LC_COLLATE=Dutch_Belgium.1252  LC_CTYPE=Dutch_Belgium.1252
LC_MONETARY=Dutch_Belgium.1252 LC_NUMERIC=C
LC_TIME=Dutch_Belgium.1252

attached base packages:
character(0)

other attached packages:
[1] drat_0.1.0.1

loaded via a namespace (and not attached):
[1] graphics_3.2.3  tools_3.2.3     utils_3.2.3     grDevices_3.2.3
stats_3.2.3     datasets_3.2.3  methods_3.2.3   base_3.2.3
fortunes_1.5-3


Best regards,


ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature
and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no
more than asking him to perform a post-mortem examination: he may be
able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does
not ensure that a reasonable answer can be extracted from a given body
of data. ~ John Tukey


From maechler at stat.math.ethz.ch  Wed Mar  2 10:46:00 2016
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 2 Mar 2016 10:46:00 +0100
Subject: [Rd] [patch] Support many columns in model.matrix
In-Reply-To: <CABz6aZd4cMhiSu7jb6oFzMULAuHEhhout12_B0Ld=0zBE8iZEQ@mail.gmail.com>
References: <CABz6aZdZvLr=3_8yOqPr+_HYu-Vi=XQD5vKc8zATt0pFMUtypQ@mail.gmail.com>
	<22228.34710.467047.134759@stat.math.ethz.ch>
	<CABz6aZd4cMhiSu7jb6oFzMULAuHEhhout12_B0Ld=0zBE8iZEQ@mail.gmail.com>
Message-ID: <22230.46680.947978.60697@stat.math.ethz.ch>

>>>>> Karl Millar <kmillar at google.com>
>>>>>     on Mon, 29 Feb 2016 10:22:51 -0800 writes:

    > Thanks.
    > Couldn't you implement model.matrix(..., sparse = TRUE)  with a small
    > amount of R code similar to MatrixModels::model.Matrix ?

yes, and basically call R level  Matrix::sparse.model.matrix()
[[ or even just mention the latter on the help page for
   model.matrix() ]].

Thank you, Karl

    > On Mon, Feb 29, 2016 at 10:01 AM, Martin Maechler
    > <maechler at stat.math.ethz.ch> wrote:
    >>>>>>> Karl Millar via R-devel <r-devel at r-project.org>
    >>>>>>> on Fri, 26 Feb 2016 15:58:20 -0800 writes:
    >> 
    >> > Generating a model matrix with very large numbers of
    >> > columns overflows the stack and/or runs very slowly, due
    >> > to the implementation of TrimRepeats().
    >> 
    >> > This patch modifies it to use Rf_duplicated() to find the
    >> > duplicates.  This makes the running time linear in the
    >> > number of columns and eliminates the recursive function
    >> > calls.
    >> 
    >> Thank you, Karl.
    >> I've committed this (very slightly modified) to R-devel,
    >> 
    >> (also after looking for a an example that runs on a non-huge
    >> computer and shows the difference) :
    >> 
    >> nF <- 11 ; set.seed(1)
    >> lff <- setNames(replicate(nF, as.factor(rpois(128, 1/4)), simplify=FALSE), letters[1:nF])
    >> str(dd <- as.data.frame(lff)); prod(sapply(dd, nlevels))
    >> ## 'data.frame':        128 obs. of  11 variables:
    >> ##  $ a: Factor w/ 3 levels "0","1","2": 1 1 1 2 1 2 2 1 1 1 ...
    >> ##  $ b: Factor w/ 3 levels "0","1","2": 1 1 1 1 1 1 2 1 1 1 ...
    >> ##  $ c: Factor w/ 3 levels "0","1","2": 1 1 1 2 1 1 1 2 1 1 ...
    >> ##  $ d: Factor w/ 3 levels "0","1","2": 1 1 2 2 1 2 1 1 2 1 ...
    >> ##  $ e: Factor w/ 3 levels "0","1","2": 1 1 1 1 1 1 1 1 2 1 ...
    >> ##  $ f: Factor w/ 2 levels "0","1": 2 1 2 1 2 1 1 2 1 2 ...
    >> ##  $ g: Factor w/ 4 levels "0","1","2","3": 2 1 1 2 1 3 1 1 1 1 ...
    >> ##  $ h: Factor w/ 4 levels "0","1","2","4": 1 1 1 1 2 1 1 1 1 1 ...
    >> ##  $ i: Factor w/ 2 levels "0","1": 1 1 1 1 1 1 1 1 1 2 ...
    >> ##  $ j: Factor w/ 3 levels "0","1","2": 1 2 3 1 1 1 1 1 1 1 ...
    >> ##  $ k: Factor w/ 3 levels "0","1","2": 1 1 1 1 1 1 1 1 1 1 ...
    >> ##
    >> ## [1] 139968
    >> 
    >> system.time(mff <- model.matrix(~ . ^ 11, dd, contrasts = list(a = "contr.helmert")))
    >> ##  user  system elapsed
    >> ## 0.255   0.033   0.287  --- *with* the patch on my desktop (16 GB)
    >> ## 1.489   0.031   1.522  --- for R-patched (i.e. w/o the patch)
    >> 
    >>> dim(mff)
    >> [1]    128 139968
    >>> object.size(mff)
    >> 154791504 bytes
    >> 
    >> ---
    >> 
    >> BTW: These example would gain tremendously if I finally got
    >> around to provide
    >> 
    >> model.matrix(........, sparse = TRUE)
    >> 
    >> which would then produce a Matrix-package sparse matrix.
    >> 
    >> Even for this somewhat small case, a sparse matrix is a factor
    >> of 13.5 x smaller :
    >> 
    >>> s1 <- object.size(mff); s2 <- object.size(M <- Matrix::Matrix(mff)); as.vector( s1/s2 )
    >> [1] 13.47043
    >> 
    >> I'm happy to collaborate with you on adding such a (C level)
    >> interface to sparse matrices for this case.
    >> 
    >> Martin Maechler


From edd at debian.org  Wed Mar  2 12:18:13 2016
From: edd at debian.org (Dirk Eddelbuettel)
Date: Wed, 2 Mar 2016 05:18:13 -0600
Subject: [Rd] install.packages() fails with drat repository on
	networkdrive
In-Reply-To: <CAJuCY5w-BC8ePSD_-g=tcRiWgtQ9ik-FSaDWz1WwZLtC4yKBcw@mail.gmail.com>
References: <CAJuCY5w-BC8ePSD_-g=tcRiWgtQ9ik-FSaDWz1WwZLtC4yKBcw@mail.gmail.com>
Message-ID: <22230.52213.475906.844429@max.nulle.part>


Hi Thierry,

On 2 March 2016 at 10:16, Thierry Onkelinx wrote:
| Dear all,
| 
| install.packages("lme4") fails with error
| Error in read.dcf(file = tmpf) : cannot open the connection
| In addition: Warning message:
| In read.dcf(file = tmpf) :
|   cannot open compressed file
| '//servername/repository_path/bin/windows/contrib/3.2/PACKAGES',
| probable reason 'No such file or directory'
| 
| the repositories set in .Rprofile are
| "http://lib.ugent.be/CRAN/" "file://servername/repository_path"
| 
| There is a file PACKAGES.gz at
| //servername/repository_path/bin/windows/contrib/3.2/ but no file
| PACKAGES
| 
| I'm not sure if this is
| 1) a bug in the drat package: not creating PACKAGES
| 2) a bug in read.dcf(): not looking if PACKAGES.gz is present
| 3) a bug in available.packages(). Debugging install.packages()
| indicates that the error occurs at the line below with type <-
| "win.binary", repos <- getOption("repos") and missing(method) == TRUE
| 
| av2 <- available.packages(contriburl = contrib.url(repos, type2),
| method = method)
| 
| It would be nice if available.packages() handled an error returned by
| read.dcf() more gracefully. An error with one repository now
| completely blocks install.packages()

I also found the file semantics over the network drive to be tricky to get
right.  In the drat documentation I refer to 'file://...' but I found
accessing via http to be easier.

But it still works.  Quick example from work with one local repo (which I
just copied to /tmp here):

R> AP <- available.packages()
R> dim(AP)
[1] 8048   17
R> options("repos")
$repos
                      CRAN                      Local 
"https://cran.rstudio.com"             "file://tmp/R" 

R> 

As you can see this uses the file:// notation just fine.  We can also drill
down:


R> r <- c("CRAN"="https://cran.rstudio.com", "Local"="file://tmp/R")
R> options("repos"=r[1])
R> options("repos")
$repos
                      CRAN 
"https://cran.rstudio.com" 

R> dim(AP <- available.packages())
[1] 8009   17
R> options("repos"=r[2])
R> dim(AP <- available.packages())
[1] 46 17
R> 

As I recall, there may have been extra complications on Windows with network
drives.  

But if there is something (maybe documentation ?) that drat could/should do
better please feel free to open an issue ticket.

Hth,  Dirk

| 
| sessionInfo("drat")
| R version 3.2.3 (2015-12-10)
| Platform: i386-w64-mingw32/i386 (32-bit)
| Running under: Windows 7 x64 (build 7601) Service Pack 1
| 
| locale:
| [1] LC_COLLATE=Dutch_Belgium.1252  LC_CTYPE=Dutch_Belgium.1252
| LC_MONETARY=Dutch_Belgium.1252 LC_NUMERIC=C
| LC_TIME=Dutch_Belgium.1252
| 
| attached base packages:
| character(0)
| 
| other attached packages:
| [1] drat_0.1.0.1
| 
| loaded via a namespace (and not attached):
| [1] graphics_3.2.3  tools_3.2.3     utils_3.2.3     grDevices_3.2.3
| stats_3.2.3     datasets_3.2.3  methods_3.2.3   base_3.2.3
| fortunes_1.5-3
| 
| 
| Best regards,
| 
| 
| ir. Thierry Onkelinx
| Instituut voor natuur- en bosonderzoek / Research Institute for Nature
| and Forest
| team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
| Kliniekstraat 25
| 1070 Anderlecht
| Belgium
| 
| To call in the statistician after the experiment is done may be no
| more than asking him to perform a post-mortem examination: he may be
| able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
| The plural of anecdote is not data. ~ Roger Brinner
| The combination of some data and an aching desire for an answer does
| not ensure that a reasonable answer can be extracted from a given body
| of data. ~ John Tukey
| 
| ______________________________________________
| R-devel at r-project.org mailing list
| https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From bbolker at gmail.com  Wed Mar  2 14:58:06 2016
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 2 Mar 2016 08:58:06 -0500
Subject: [Rd] *tiny* inaccuracy in ?dbinom
Message-ID: <56D6F16E.2070902@gmail.com>


   under "Value", ?dbinom says

      If ?size? is not an integer, ?NaN? is returned.

That should be something like

       If ?size? is not an integer, ?NaN? is returned (or 'NA' for rbinom).

   ... at least that's what happens for me under svn rev 70138, Ubuntu 14

 > rbinom(1,size=0.5,prob=0.5)
[1] NA
Warning message:
In rbinom(1, size = 0.5, prob = 0.5) : NAs produced
 > dbinom(1,size=0.5,prob=0.5)
[1] NaN
Warning message:
In dbinom(1, size = 0.5, prob = 0.5) : NaNs produced


From renaud at techunix.technion.ac.il  Thu Mar  3 09:13:59 2016
From: renaud at techunix.technion.ac.il (Renaud Gaujoux)
Date: Thu, 3 Mar 2016 10:13:59 +0200
Subject: [Rd] Ubuntu console weird behaviour
Message-ID: <CAHavPHHVgmKA2mb1Zrf7f4scsuexhDq3KbRFMPn87M_YQ8yA+g@mail.gmail.com>

Hi,

I have been experiencing a weird behavior when running R in Ubuntu terminal.
I don't know exactly what triggers the issue and could not find a 100%
reproducible way of getting it.
The problem is that sometimes (often after an error is thrown, or after
copy/paste of plain text from an editor), the console acts as if its width
was limited, breaking lines and makes very difficult to navigate into
command history or edit previous commands. Essentially, the console is
messed up and only comes back to normal when restarting R in a fresh
session.

I understand it is a bit of a poor error report, but I was hoping that
people might have encountered the same issue (and would recognize it as
described here).

I looked at bash checkwinsize as suggested here and it is on:
http://unix.stackexchange.com/questions/61584/how-to-solve-the-issue-that-a-terminal-screen-is-messed-up-usually-after-a-res

Thank you.

Bests,
Renaud

My settings are:

R version 3.2.3 (2015-12-10)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 15.10

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
 [3] LC_TIME=en_ZA.UTF-8        LC_COLLATE=en_US.UTF-8
 [5] LC_MONETARY=en_ZA.UTF-8    LC_MESSAGES=en_US.UTF-8
 [7] LC_PAPER=en_ZA.UTF-8       LC_NAME=C
 [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_ZA.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base


-- 
Renaud Gaujoux, PhD
Systems Immunology - Technion, Haifa, Israel

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Thu Mar  3 09:59:19 2016
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Thu, 3 Mar 2016 09:59:19 +0100
Subject: [Rd] install.packages() fails with drat repository on
	networkdrive
In-Reply-To: <22230.52213.475906.844429@max.nulle.part>
References: <CAJuCY5w-BC8ePSD_-g=tcRiWgtQ9ik-FSaDWz1WwZLtC4yKBcw@mail.gmail.com>
	<22230.52213.475906.844429@max.nulle.part>
Message-ID: <CAJuCY5xAta1WPDXQ5TdxoCEaRTMNqOOq1rwWGTUtK2oZvv_efQ@mail.gmail.com>

Hi Dirk,

I've (re-)added a binary package to our drat repository. The PACKAGES file
was created so the problem is solved. I assume that the PACKAGES got
removed by mistake.

The problem remains however in case when we have no connection to the
network share (e.g. when working outside the office without VPN connection).

updating available.packages() by replacing lines 48-49
in src/library/utils/R/packages.R

            res0 <- read.dcf(file = tmpf)
            if(length(res0)) rownames(res0) <- res0[, "Package"]

with

            res0 <- try(read.dcf(file = tmpf))
            if(length(res0) & !inherits(res0, "try-error")) rownames(res0)
<- res0[, "Package"]

works around this problem.

Best regards,

Thierry

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2016-03-02 12:18 GMT+01:00 Dirk Eddelbuettel <edd at debian.org>:

>
> Hi Thierry,
>
> On 2 March 2016 at 10:16, Thierry Onkelinx wrote:
> | Dear all,
> |
> | install.packages("lme4") fails with error
> | Error in read.dcf(file = tmpf) : cannot open the connection
> | In addition: Warning message:
> | In read.dcf(file = tmpf) :
> |   cannot open compressed file
> | '//servername/repository_path/bin/windows/contrib/3.2/PACKAGES',
> | probable reason 'No such file or directory'
> |
> | the repositories set in .Rprofile are
> | "http://lib.ugent.be/CRAN/" "file://servername/repository_path"
> |
> | There is a file PACKAGES.gz at
> | //servername/repository_path/bin/windows/contrib/3.2/ but no file
> | PACKAGES
> |
> | I'm not sure if this is
> | 1) a bug in the drat package: not creating PACKAGES
> | 2) a bug in read.dcf(): not looking if PACKAGES.gz is present
> | 3) a bug in available.packages(). Debugging install.packages()
> | indicates that the error occurs at the line below with type <-
> | "win.binary", repos <- getOption("repos") and missing(method) == TRUE
> |
> | av2 <- available.packages(contriburl = contrib.url(repos, type2),
> | method = method)
> |
> | It would be nice if available.packages() handled an error returned by
> | read.dcf() more gracefully. An error with one repository now
> | completely blocks install.packages()
>
> I also found the file semantics over the network drive to be tricky to get
> right.  In the drat documentation I refer to 'file://...' but I found
> accessing via http to be easier.
>
> But it still works.  Quick example from work with one local repo (which I
> just copied to /tmp here):
>
> R> AP <- available.packages()
> R> dim(AP)
> [1] 8048   17
> R> options("repos")
> $repos
>                       CRAN                      Local
> "https://cran.rstudio.com"             "file://tmp/R"
>
> R>
>
> As you can see this uses the file:// notation just fine.  We can also drill
> down:
>
>
> R> r <- c("CRAN"="https://cran.rstudio.com", "Local"="file://tmp/R")
> R> options("repos"=r[1])
> R> options("repos")
> $repos
>                       CRAN
> "https://cran.rstudio.com"
>
> R> dim(AP <- available.packages())
> [1] 8009   17
> R> options("repos"=r[2])
> R> dim(AP <- available.packages())
> [1] 46 17
> R>
>
> As I recall, there may have been extra complications on Windows with
> network
> drives.
>
> But if there is something (maybe documentation ?) that drat could/should do
> better please feel free to open an issue ticket.
>
> Hth,  Dirk
>
> |
> | sessionInfo("drat")
> | R version 3.2.3 (2015-12-10)
> | Platform: i386-w64-mingw32/i386 (32-bit)
> | Running under: Windows 7 x64 (build 7601) Service Pack 1
> |
> | locale:
> | [1] LC_COLLATE=Dutch_Belgium.1252  LC_CTYPE=Dutch_Belgium.1252
> | LC_MONETARY=Dutch_Belgium.1252 LC_NUMERIC=C
> | LC_TIME=Dutch_Belgium.1252
> |
> | attached base packages:
> | character(0)
> |
> | other attached packages:
> | [1] drat_0.1.0.1
> |
> | loaded via a namespace (and not attached):
> | [1] graphics_3.2.3  tools_3.2.3     utils_3.2.3     grDevices_3.2.3
> | stats_3.2.3     datasets_3.2.3  methods_3.2.3   base_3.2.3
> | fortunes_1.5-3
> |
> |
> | Best regards,
> |
> |
> | ir. Thierry Onkelinx
> | Instituut voor natuur- en bosonderzoek / Research Institute for Nature
> | and Forest
> | team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> | Kliniekstraat 25
> | 1070 Anderlecht
> | Belgium
> |
> | To call in the statistician after the experiment is done may be no
> | more than asking him to perform a post-mortem examination: he may be
> | able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> | The plural of anecdote is not data. ~ Roger Brinner
> | The combination of some data and an aching desire for an answer does
> | not ensure that a reasonable answer can be extracted from a given body
> | of data. ~ John Tukey
> |
> | ______________________________________________
> | R-devel at r-project.org mailing list
> | https://stat.ethz.ch/mailman/listinfo/r-devel
>
> --
> http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org
>

	[[alternative HTML version deleted]]


From jeff.laake at noaa.gov  Thu Mar  3 16:23:38 2016
From: jeff.laake at noaa.gov (Jeff Laake - NOAA Federal)
Date: Thu, 3 Mar 2016 07:23:38 -0800
Subject: [Rd] as.vector in R-devel loaded 3/3/2016
Message-ID: <CA+_rFBK8c5gXFm41StNPDiBYTW=uLXvj5d4cGzpfi9gdv-mW7A@mail.gmail.com>

I just installed R-devel to check my package before submitting.  I got an
error in my vignette in regards to as.vector.  When I looked at the code
for as.vector in R-devel it is

standardGeneric for "as.vector" defined from package "base"

function (x, mode)
standardGeneric("as.vector")
<environment: 0x0918ad70>
Methods may be defined for arguments: x, mode
Use  showMethods("as.vector")  for currently available ones.

The code from R3.2.3 is
> as.vector
function (x, mode = "any")
.Internal(as.vector(x, mode))
<bytecode: 0x02dfb858>
<environment: namespace:base>
>

Is default for mode missing as I suspect or will mode be required from now
on?

	[[alternative HTML version deleted]]


From jeff.laake at noaa.gov  Fri Mar  4 01:09:47 2016
From: jeff.laake at noaa.gov (Jeff Laake - NOAA Federal)
Date: Thu, 3 Mar 2016 16:09:47 -0800
Subject: [Rd] as.vector in R-devel loaded 3/3/2016
In-Reply-To: <CA+_rFBK8c5gXFm41StNPDiBYTW=uLXvj5d4cGzpfi9gdv-mW7A@mail.gmail.com>
References: <CA+_rFBK8c5gXFm41StNPDiBYTW=uLXvj5d4cGzpfi9gdv-mW7A@mail.gmail.com>
Message-ID: <CA+_rFBJbtEw47Qq-yfs54E7AwgX8+HK3FcXL3a7z+coDA=-KeQ@mail.gmail.com>

I dug into this a little further and discovered the problem.  When my
package is for checking, it loads Matrix.  In the R-devel version of
Matrix, as.vector is re-defined without mode specified

> as.vector
standardGeneric for "as.vector" defined from package "base"

function (x, mode)
standardGeneric("as.vector")
<environment: 0x082faf08>
Methods may be defined for arguments: x, mode
Use  showMethods("as.vector")  for currently available ones.

In R3.2.3 it is defined with mode="any" specified.

> as.vector
standardGeneric for "as.vector" defined from package "base"

function (x, mode = "any")
standardGeneric("as.vector")
<environment: 0x084af110>
Methods may be defined for arguments: x, mode
Use  showMethods("as.vector")  for currently available ones.

Until this is fixed I'll copy over the devel version of Matrix.

--jeff


On Thu, Mar 3, 2016 at 7:23 AM, Jeff Laake - NOAA Federal <
jeff.laake at noaa.gov> wrote:

> I just installed R-devel to check my package before submitting.  I got an
> error in my vignette in regards to as.vector.  When I looked at the code
> for as.vector in R-devel it is
>
> standardGeneric for "as.vector" defined from package "base"
>
> function (x, mode)
> standardGeneric("as.vector")
> <environment: 0x0918ad70>
> Methods may be defined for arguments: x, mode
> Use  showMethods("as.vector")  for currently available ones.
>
> The code from R3.2.3 is
> > as.vector
> function (x, mode = "any")
> .Internal(as.vector(x, mode))
> <bytecode: 0x02dfb858>
> <environment: namespace:base>
> >
>
> Is default for mode missing as I suspect or will mode be required from now
> on?
>

	[[alternative HTML version deleted]]


From edd at debian.org  Fri Mar  4 04:52:04 2016
From: edd at debian.org (Dirk Eddelbuettel)
Date: Thu, 3 Mar 2016 21:52:04 -0600
Subject: [Rd] R 3.2.4 rc issue
Message-ID: <22233.1636.385295.261603@max.nulle.part>


I generally run 'make; make check' (with more settings) when building the
Debian package.  Running 3.2.4 rc from last night, I see a lot of package
loading issues during 'make check'.  Here is splines as one examples:

checking package 'splines'
* using log directory '/build/r-base-3.2.3.20160303/tests/splines.Rcheck'
* using R version 3.2.4 RC (2016-03-02 r70270)
* using platform: x86_64-pc-linux-gnu (64-bit)
* using session charset: ASCII
* using option '--no-build-vignettes'
* looks like 'splines' is a base package
* skipping installation test
* checking package directory ... OK
* checking DESCRIPTION meta-information ... OK
* checking top-level files ... OK
* checking for left-over files ... OK
* checking index information ... OK
* checking package subdirectories ... OK
* checking whether the package can be loaded ... OK
* checking whether the package can be loaded with stated dependencies ... OK
* checking whether the package can be unloaded cleanly ... OK
* checking whether the namespace can be loaded with stated dependencies ... OK
* checking whether the namespace can be unloaded cleanly ... OK
* checking S3 generic/method consistency ... OK
* checking replacement functions ... OK
* checking foreign function calls ... OK
* checking R code for possible problems ... OK
* checking Rd files ... OK
* checking Rd metadata ... OK
* checking Rd cross-references ... WARNING
Unknown package 'Matrix' in Rd xrefs
* checking for missing documentation entries ... OK
* checking for code/documentation mismatches ... OK
* checking Rd \usage sections ... OK
* checking Rd contents ... OK
* checking compiled code ... OK
* checking examples ... SKIPPED
* checking tests ...
  Running 'spline-tst.R'
 ERROR
Running the tests in 'tests/spline-tst.R' failed.
Last 13 lines of output:
  > proc.time()
     user  system elapsed 
    2.272   0.020   2.291 
  > 
  > ###----------------- sparse / dense   interpSpline() ---------------------------
  > 
  > ## from  help(interpSpline) -- ../man/interpSpline.Rd
  > ispl <- interpSpline( women$height, women$weight)
  > isp. <- interpSpline( women$height, women$weight, sparse=TRUE)
  Error in splineDesign(knots, x, ord, derivs, sparse = sparse) : 
    splineDesign(*, sparse=TRUE) needs package 'Matrix' correctly installed
  Calls: interpSpline -> interpSpline.default -> splineDesign
  Execution halted
* checking PDF version of manual ... OK
* DONE

Status: 1 ERROR, 1 WARNING
See
  '/build/r-base-3.2.3.20160303/tests/splines.Rcheck/00check.log'
for details.


Did something change in requirements?

Dirk

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From pdalgd at gmail.com  Fri Mar  4 09:11:42 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 4 Mar 2016 09:11:42 +0100
Subject: [Rd] R 3.2.4 rc issue
In-Reply-To: <22233.1636.385295.261603@max.nulle.part>
References: <22233.1636.385295.261603@max.nulle.part>
Message-ID: <DDCB6BD8-BC16-4CF6-9AFB-8188F334CDF0@gmail.com>

Thanks for the info, Dirk.

The tarball builds don't run make check (because of a policy decision that it is better to have the sources available on all platforms for testing than to have none if it breaks on a single platform). However the build as of tonight has no problem with make check on the build machine. Did you by any chance forget that Matrix is a recommended package and expected to be available when checking?

-pd

> On 04 Mar 2016, at 04:52 , Dirk Eddelbuettel <edd at debian.org> wrote:
> 
> 
> I generally run 'make; make check' (with more settings) when building the
> Debian package.  Running 3.2.4 rc from last night, I see a lot of package
> loading issues during 'make check'.  Here is splines as one examples:
> 
> checking package 'splines'
> * using log directory '/build/r-base-3.2.3.20160303/tests/splines.Rcheck'
> * using R version 3.2.4 RC (2016-03-02 r70270)
> * using platform: x86_64-pc-linux-gnu (64-bit)
> * using session charset: ASCII
> * using option '--no-build-vignettes'
> * looks like 'splines' is a base package
> * skipping installation test
> * checking package directory ... OK
> * checking DESCRIPTION meta-information ... OK
> * checking top-level files ... OK
> * checking for left-over files ... OK
> * checking index information ... OK
> * checking package subdirectories ... OK
> * checking whether the package can be loaded ... OK
> * checking whether the package can be loaded with stated dependencies ... OK
> * checking whether the package can be unloaded cleanly ... OK
> * checking whether the namespace can be loaded with stated dependencies ... OK
> * checking whether the namespace can be unloaded cleanly ... OK
> * checking S3 generic/method consistency ... OK
> * checking replacement functions ... OK
> * checking foreign function calls ... OK
> * checking R code for possible problems ... OK
> * checking Rd files ... OK
> * checking Rd metadata ... OK
> * checking Rd cross-references ... WARNING
> Unknown package 'Matrix' in Rd xrefs
> * checking for missing documentation entries ... OK
> * checking for code/documentation mismatches ... OK
> * checking Rd \usage sections ... OK
> * checking Rd contents ... OK
> * checking compiled code ... OK
> * checking examples ... SKIPPED
> * checking tests ...
>  Running 'spline-tst.R'
> ERROR
> Running the tests in 'tests/spline-tst.R' failed.
> Last 13 lines of output:
>> proc.time()
>     user  system elapsed 
>    2.272   0.020   2.291 
>> 
>> ###----------------- sparse / dense   interpSpline() ---------------------------
>> 
>> ## from  help(interpSpline) -- ../man/interpSpline.Rd
>> ispl <- interpSpline( women$height, women$weight)
>> isp. <- interpSpline( women$height, women$weight, sparse=TRUE)
>  Error in splineDesign(knots, x, ord, derivs, sparse = sparse) : 
>    splineDesign(*, sparse=TRUE) needs package 'Matrix' correctly installed
>  Calls: interpSpline -> interpSpline.default -> splineDesign
>  Execution halted
> * checking PDF version of manual ... OK
> * DONE
> 
> Status: 1 ERROR, 1 WARNING
> See
>  '/build/r-base-3.2.3.20160303/tests/splines.Rcheck/00check.log'
> for details.
> 
> 
> Did something change in requirements?
> 
> Dirk
> 
> -- 
> http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From pdalgd at gmail.com  Fri Mar  4 09:21:48 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 4 Mar 2016 09:21:48 +0100
Subject: [Rd] as.vector in R-devel loaded 3/3/2016
In-Reply-To: <CA+_rFBJbtEw47Qq-yfs54E7AwgX8+HK3FcXL3a7z+coDA=-KeQ@mail.gmail.com>
References: <CA+_rFBK8c5gXFm41StNPDiBYTW=uLXvj5d4cGzpfi9gdv-mW7A@mail.gmail.com>
	<CA+_rFBJbtEw47Qq-yfs54E7AwgX8+HK3FcXL3a7z+coDA=-KeQ@mail.gmail.com>
Message-ID: <CB88A7FF-6C3D-400A-A086-6C6E5E75B507@gmail.com>

Er, until _what_ is fixed?

I see no anomalies with the version in R-pre:

> library(Matrix)
> as.vector
standardGeneric for "as.vector" defined from package "base"

function (x, mode = "any") 
standardGeneric("as.vector")
<environment: 0x7fe8f4516640>
Methods may be defined for arguments: x, mode
Use  showMethods("as.vector")  for currently available ones.
> str(as.vector(1:3))
 int [1:3] 1 2 3
> str(as.vector(1:3+0))
 num [1:3] 1 2 3
> str(as.vector(list(1,2,3))
+ )
List of 3
 $ : num 1
 $ : num 2
 $ : num 3
> str(as.vector(list(1,2,3), mode="integer"))
 int [1:3] 1 2 3
> str(as.vector(list(1,2,3), mode="numeric"))
 num [1:3] 1 2 3


Also, *current* r-devel has the same definition:

$ ~/r-devel/BUILD-dist/bin/R

R Under development (unstable) (2016-03-03 r70270) -- "Unsuffered Consequences"
[...yadayada...]
> library(Matrix)
> as.vector
function (x, mode = "any") 
.Internal(as.vector(x, mode))
<bytecode: 0x7fdf69279780>
<environment: namespace:base>


> On 04 Mar 2016, at 01:09 , Jeff Laake - NOAA Federal <jeff.laake at noaa.gov> wrote:
> 
> I dug into this a little further and discovered the problem.  When my
> package is for checking, it loads Matrix.  In the R-devel version of
> Matrix, as.vector is re-defined without mode specified
> 
>> as.vector
> standardGeneric for "as.vector" defined from package "base"
> 
> function (x, mode)
> standardGeneric("as.vector")
> <environment: 0x082faf08>
> Methods may be defined for arguments: x, mode
> Use  showMethods("as.vector")  for currently available ones.
> 
> In R3.2.3 it is defined with mode="any" specified.
> 
>> as.vector
> standardGeneric for "as.vector" defined from package "base"
> 
> function (x, mode = "any")
> standardGeneric("as.vector")
> <environment: 0x084af110>
> Methods may be defined for arguments: x, mode
> Use  showMethods("as.vector")  for currently available ones.
> 
> Until this is fixed I'll copy over the devel version of Matrix.
> 
> --jeff
> 
> 
> On Thu, Mar 3, 2016 at 7:23 AM, Jeff Laake - NOAA Federal <
> jeff.laake at noaa.gov> wrote:
> 
>> I just installed R-devel to check my package before submitting.  I got an
>> error in my vignette in regards to as.vector.  When I looked at the code
>> for as.vector in R-devel it is
>> 
>> standardGeneric for "as.vector" defined from package "base"
>> 
>> function (x, mode)
>> standardGeneric("as.vector")
>> <environment: 0x0918ad70>
>> Methods may be defined for arguments: x, mode
>> Use  showMethods("as.vector")  for currently available ones.
>> 
>> The code from R3.2.3 is
>>> as.vector
>> function (x, mode = "any")
>> .Internal(as.vector(x, mode))
>> <bytecode: 0x02dfb858>
>> <environment: namespace:base>
>>> 
>> 
>> Is default for mode missing as I suspect or will mode be required from now
>> on?
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From maechler at stat.math.ethz.ch  Fri Mar  4 12:05:49 2016
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 4 Mar 2016 12:05:49 +0100
Subject: [Rd] as.vector in R-devel loaded 3/3/2016
In-Reply-To: <CB88A7FF-6C3D-400A-A086-6C6E5E75B507@gmail.com>
References: <CA+_rFBK8c5gXFm41StNPDiBYTW=uLXvj5d4cGzpfi9gdv-mW7A@mail.gmail.com>
	<CA+_rFBJbtEw47Qq-yfs54E7AwgX8+HK3FcXL3a7z+coDA=-KeQ@mail.gmail.com>
	<CB88A7FF-6C3D-400A-A086-6C6E5E75B507@gmail.com>
Message-ID: <22233.27661.347312.341398@stat.math.ethz.ch>

>>>>> peter dalgaard <pdalgd at gmail.com>
>>>>>     on Fri, 4 Mar 2016 09:21:48 +0100 writes:

    > Er, until _what_ is fixed?
    > I see no anomalies with the version in R-pre:

Indeed.

The problem ... I also have stumbled over ..
is that I'm sure Jeff is accidentally loading a different
version of 'Matrix' than the one that is part of R-devel.

Jeff you must accidentally be loading a version Matrix made with
R 3.2.x in R 3.3.0  and that will fail with the as.vector()
mismatch error message.

(and IIRC, you also get such an error message if you load a
 3.3.0-built version of Matrix into a non-3.3.0 version of R).


Martin


From jean-externe.maurice at edf.fr  Fri Mar  4 09:34:27 2016
From: jean-externe.maurice at edf.fr (MAURICE Jean - externe)
Date: Fri, 4 Mar 2016 08:34:27 +0000
Subject: [Rd] ALLOCATE in a FORTRAN subroutine
Message-ID: <6c39c4cbb0fb4e6d80fb36ad28b2b89f@NOEINTPEXMU007.NEOPROD.EDF.FR>

Hi,
I am a FORTRAN developer and I am 'translating' R functions in FORTRAN subroutines. I am 'new' to R. It's my first question in this mailing-list and English is not my natural language.

Very often, an R function gives an  'array' as result and you don't have to bother with the dimension of the array : R creates automatically an array with the good length. It's not really the case with FORTRAN. I call FORTRAN subroutines with .fortran().

Until now, I create an array with the 'max' dimensions in R, give it to FORTRAN; FORTRAN updates the array and R retrieves it. But calculating the 'max' before calling the FORTRAN subroutine can be complicated. Is it possible to create a 'new' array in a FORTRAN subroutine and to make it be read by R ?

Or is it possible to have a 'pointer' in R, to give it to the FORTRAN subroutine where an ALLOCATE can create the array and then R works with the array ?
The other solution, is to work with dummies dimension in FORTRAN (REAL*8 array1(*)) but can R work with that ?

TIA
Jean

-------------- next part --------------



Ce message et toutes les pi?ces jointes (ci-apr?s le 'Message') sont ?tablis ? l'intention exclusive des destinataires et les informations qui y figurent sont strictement confidentielles. Toute utilisation de ce Message non conforme ? sa destination, toute diffusion ou toute publication totale ou partielle, est interdite sauf autorisation expresse.

Si vous n'?tes pas le destinataire de ce Message, il vous est interdit de le copier, de le faire suivre, de le divulguer ou d'en utiliser tout ou partie. Si vous avez re?u ce Message par erreur, merci de le supprimer de votre syst?me, ainsi que toutes ses copies, et de n'en garder aucune trace sur quelque support que ce soit. Nous vous remercions ?galement d'en avertir imm?diatement l'exp?diteur par retour du message.

Il est impossible de garantir que les communications par messagerie ?lectronique arrivent en temps utile, sont s?curis?es ou d?nu?es de toute erreur ou virus.
____________________________________________________

This message and any attachments (the 'Message') are intended solely for the addressees. The information contained in this Message is confidential. Any use of information contained in this Message not in accord with its purpose, any dissemination or disclosure, either whole or partial, is prohibited except formal approval.

If you are not the addressee, you may not copy, forward, disclose or use any part of it. If you have received this message in error, please delete it and all copies from your system and notify the sender immediately by return message.

E-mail communication cannot be guaranteed to be timely secure, error or virus-free.

From murdoch.duncan at gmail.com  Fri Mar  4 12:40:51 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 4 Mar 2016 06:40:51 -0500
Subject: [Rd] ALLOCATE in a FORTRAN subroutine
In-Reply-To: <6c39c4cbb0fb4e6d80fb36ad28b2b89f@NOEINTPEXMU007.NEOPROD.EDF.FR>
References: <6c39c4cbb0fb4e6d80fb36ad28b2b89f@NOEINTPEXMU007.NEOPROD.EDF.FR>
Message-ID: <56D97443.2010800@gmail.com>

On 04/03/2016 3:34 AM, MAURICE Jean - externe wrote:
> Hi,
> I am a FORTRAN developer and I am 'translating' R functions in FORTRAN subroutines. I am 'new' to R. It's my first question in this mailing-list and English is not my natural language.
>
> Very often, an R function gives an  'array' as result and you don't have to bother with the dimension of the array : R creates automatically an array with the good length. It's not really the case with FORTRAN. I call FORTRAN subroutines with .fortran().
>
> Until now, I create an array with the 'max' dimensions in R, give it to FORTRAN; FORTRAN updates the array and R retrieves it. But calculating the 'max' before calling the FORTRAN subroutine can be complicated. Is it possible to create a 'new' array in a FORTRAN subroutine and to make it be read by R ?

I don't think this is possible in pure Fortran, but it is certainly 
possible in C or C++ code.  You need to call the external routine using 
.Call() instead of .C or .Fortran.  See the section 5.9 of the Writing R 
Extensions manual for details.

> Or is it possible to have a 'pointer' in R, to give it to the FORTRAN subroutine where an ALLOCATE can create the array and then R works with the array ?

No.  R needs to manage allocations of all the objects it uses.  However, 
if you never need to use these arrays in R code (you just want R to keep 
references to them to pass to other external routines), you can (in C or 
C++) use the external pointer type.  I don't think there's any support 
for that in Fortran.

> The other solution, is to work with dummies dimension in FORTRAN (REAL*8 array1(*)) but can R work with that ?

No, for the same reason.

Duncan Murdoch


From Martin.Morgan at roswellpark.org  Fri Mar  4 13:36:25 2016
From: Martin.Morgan at roswellpark.org (Morgan, Martin)
Date: Fri, 4 Mar 2016 12:36:25 +0000
Subject: [Rd] as.vector in R-devel loaded 3/3/2016
In-Reply-To: <22233.27661.347312.341398@stat.math.ethz.ch>
References: <CA+_rFBK8c5gXFm41StNPDiBYTW=uLXvj5d4cGzpfi9gdv-mW7A@mail.gmail.com>
	<CA+_rFBJbtEw47Qq-yfs54E7AwgX8+HK3FcXL3a7z+coDA=-KeQ@mail.gmail.com>
	<CB88A7FF-6C3D-400A-A086-6C6E5E75B507@gmail.com>,
	<22233.27661.347312.341398@stat.math.ethz.ch>
Message-ID: <BN4PR12MB0883CA6ED32FC60B5F8CC902E1BE0@BN4PR12MB0883.namprd12.prod.outlook.com>

I see as below, where getGeneric and getMethod imply a different signature; the signature is mode="any" for both cases in R version 3.2.3 Patched (2016-01-28 r70038)I don't know how to reproduce Jeff's error, though.

> library(Matrix)
> as.vector
function (x, mode = "any") 
.Internal(as.vector(x, mode))
<bytecode: 0xe79f88>
<environment: namespace:base>
> getGeneric("as.vector")
standardGeneric for "as.vector" defined from package "base"

function (x, mode) 
standardGeneric("as.vector")
<bytecode: 0x29a6bd0>
<environment: 0x299f988>
Methods may be defined for arguments: x
Use  showMethods("as.vector")  for currently available ones.
> selectMethod("as.vector", "ANY")
Method Definition (Class "internalDispatchMethod"):

function (x, mode) 
.Internal(as.vector(x, mode))
<environment: base>

Signatures:
        x    
target  "ANY"
defined "ANY"
> sessionInfo()
R Under development (unstable) (2016-02-27 r70232)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 14.04.4 LTS

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                 
 [9] LC_ADDRESS=C               LC_TELEPHONE=C            
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] Matrix_1.2-4

loaded via a namespace (and not attached):
[1] grid_3.3.0      lattice_0.20-33


________________________________________
From: R-devel <r-devel-bounces at r-project.org> on behalf of Martin Maechler <maechler at stat.math.ethz.ch>
Sent: Friday, March 4, 2016 6:05 AM
To: peter dalgaard
Cc: r-devel at r-project.org; Jeff Laake - NOAA Federal
Subject: Re: [Rd] as.vector in R-devel loaded 3/3/2016

>>>>> peter dalgaard <pdalgd at gmail.com>
>>>>>     on Fri, 4 Mar 2016 09:21:48 +0100 writes:

    > Er, until _what_ is fixed?
    > I see no anomalies with the version in R-pre:

Indeed.

The problem ... I also have stumbled over ..
is that I'm sure Jeff is accidentally loading a different
version of 'Matrix' than the one that is part of R-devel.

Jeff you must accidentally be loading a version Matrix made with
R 3.2.x in R 3.3.0  and that will fail with the as.vector()
mismatch error message.

(and IIRC, you also get such an error message if you load a
 3.3.0-built version of Matrix into a non-3.3.0 version of R).


Martin

______________________________________________
R-devel at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-devel

This email message may contain legally privileged and/or confidential information.  If you are not the intended recipient(s), or the employee or agent responsible for the delivery of this message to the intended recipient(s), you are hereby notified that any disclosure, copying, distribution, or use of this email message is prohibited.  If you have received this message in error, please notify the sender immediately by e-mail and delete this email message from your computer. Thank you.

From edd at debian.org  Fri Mar  4 13:37:43 2016
From: edd at debian.org (Dirk Eddelbuettel)
Date: Fri, 4 Mar 2016 06:37:43 -0600
Subject: [Rd] R 3.2.4 rc issue
In-Reply-To: <DDCB6BD8-BC16-4CF6-9AFB-8188F334CDF0@gmail.com>
References: <22233.1636.385295.261603@max.nulle.part>
	<DDCB6BD8-BC16-4CF6-9AFB-8188F334CDF0@gmail.com>
Message-ID: <22233.33175.270791.397346@max.nulle.part>


On 4 March 2016 at 09:11, peter dalgaard wrote:
| Thanks for the info, Dirk.
| 
| The tarball builds don't run make check (because of a policy decision that it is better to have the sources available on all platforms for testing than to have none if it breaks on a single platform). However the build as of tonight has no problem with make check on the build machine. Did you by any chance forget that Matrix is a recommended package and expected to be available when checking?

Our build systems are heavily standardized and create pristine chroot
environments with exactly what we prescibe.

'Recommended packages' was never part of it, yet we have been running 'make;
make check' since (if memory serves) before the 1.0.0 days.  "It never
mattered".  Yesterday, it failed. I'll try to try again on the weekend.

Dirk
 
| -pd
| 
| > On 04 Mar 2016, at 04:52 , Dirk Eddelbuettel <edd at debian.org> wrote:
| > 
| > 
| > I generally run 'make; make check' (with more settings) when building the
| > Debian package.  Running 3.2.4 rc from last night, I see a lot of package
| > loading issues during 'make check'.  Here is splines as one examples:
| > 
| > checking package 'splines'
| > * using log directory '/build/r-base-3.2.3.20160303/tests/splines.Rcheck'
| > * using R version 3.2.4 RC (2016-03-02 r70270)
| > * using platform: x86_64-pc-linux-gnu (64-bit)
| > * using session charset: ASCII
| > * using option '--no-build-vignettes'
| > * looks like 'splines' is a base package
| > * skipping installation test
| > * checking package directory ... OK
| > * checking DESCRIPTION meta-information ... OK
| > * checking top-level files ... OK
| > * checking for left-over files ... OK
| > * checking index information ... OK
| > * checking package subdirectories ... OK
| > * checking whether the package can be loaded ... OK
| > * checking whether the package can be loaded with stated dependencies ... OK
| > * checking whether the package can be unloaded cleanly ... OK
| > * checking whether the namespace can be loaded with stated dependencies ... OK
| > * checking whether the namespace can be unloaded cleanly ... OK
| > * checking S3 generic/method consistency ... OK
| > * checking replacement functions ... OK
| > * checking foreign function calls ... OK
| > * checking R code for possible problems ... OK
| > * checking Rd files ... OK
| > * checking Rd metadata ... OK
| > * checking Rd cross-references ... WARNING
| > Unknown package 'Matrix' in Rd xrefs
| > * checking for missing documentation entries ... OK
| > * checking for code/documentation mismatches ... OK
| > * checking Rd \usage sections ... OK
| > * checking Rd contents ... OK
| > * checking compiled code ... OK
| > * checking examples ... SKIPPED
| > * checking tests ...
| >  Running 'spline-tst.R'
| > ERROR
| > Running the tests in 'tests/spline-tst.R' failed.
| > Last 13 lines of output:
| >> proc.time()
| >     user  system elapsed 
| >    2.272   0.020   2.291 
| >> 
| >> ###----------------- sparse / dense   interpSpline() ---------------------------
| >> 
| >> ## from  help(interpSpline) -- ../man/interpSpline.Rd
| >> ispl <- interpSpline( women$height, women$weight)
| >> isp. <- interpSpline( women$height, women$weight, sparse=TRUE)
| >  Error in splineDesign(knots, x, ord, derivs, sparse = sparse) : 
| >    splineDesign(*, sparse=TRUE) needs package 'Matrix' correctly installed
| >  Calls: interpSpline -> interpSpline.default -> splineDesign
| >  Execution halted
| > * checking PDF version of manual ... OK
| > * DONE
| > 
| > Status: 1 ERROR, 1 WARNING
| > See
| >  '/build/r-base-3.2.3.20160303/tests/splines.Rcheck/00check.log'
| > for details.
| > 
| > 
| > Did something change in requirements?
| > 
| > Dirk
| > 
| > -- 
| > http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org
| > 
| > ______________________________________________
| > R-devel at r-project.org mailing list
| > https://stat.ethz.ch/mailman/listinfo/r-devel
| 
| -- 
| Peter Dalgaard, Professor,
| Center for Statistics, Copenhagen Business School
| Solbjerg Plads 3, 2000 Frederiksberg, Denmark
| Phone: (+45)38153501
| Office: A 4.23
| Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
| 
| 
| 
| 
| 
| 
| 
| 
| 

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From jeff.laake at noaa.gov  Fri Mar  4 14:35:12 2016
From: jeff.laake at noaa.gov (Jeff Laake - NOAA Federal)
Date: Fri, 4 Mar 2016 05:35:12 -0800
Subject: [Rd] as.vector in R-devel loaded 3/3/2016
In-Reply-To: <BN4PR12MB0883CA6ED32FC60B5F8CC902E1BE0@BN4PR12MB0883.namprd12.prod.outlook.com>
References: <CA+_rFBK8c5gXFm41StNPDiBYTW=uLXvj5d4cGzpfi9gdv-mW7A@mail.gmail.com>
	<CA+_rFBJbtEw47Qq-yfs54E7AwgX8+HK3FcXL3a7z+coDA=-KeQ@mail.gmail.com>
	<CB88A7FF-6C3D-400A-A086-6C6E5E75B507@gmail.com>
	<22233.27661.347312.341398@stat.math.ethz.ch>
	<BN4PR12MB0883CA6ED32FC60B5F8CC902E1BE0@BN4PR12MB0883.namprd12.prod.outlook.com>
Message-ID: <CA+_rFBL-XaTqG1pYcU_YBnMA-dVuRdsiv=Ss=qaJb2W5ux=bMg@mail.gmail.com>

Thanks. Indeed I was having a permission issue installing/updating packages
and had put a version of Matrix in my personal library which must have been
getting loaded ahead of the one in revel library. Sorry for the bother.

On Friday, March 4, 2016, Morgan, Martin <Martin.Morgan at roswellpark.org>
wrote:

> I see as below, where getGeneric and getMethod imply a different
> signature; the signature is mode="any" for both cases in R version 3.2.3
> Patched (2016-01-28 r70038)I don't know how to reproduce Jeff's error,
> though.
>
> > library(Matrix)
> > as.vector
> function (x, mode = "any")
> .Internal(as.vector(x, mode))
> <bytecode: 0xe79f88>
> <environment: namespace:base>
> > getGeneric("as.vector")
> standardGeneric for "as.vector" defined from package "base"
>
> function (x, mode)
> standardGeneric("as.vector")
> <bytecode: 0x29a6bd0>
> <environment: 0x299f988>
> Methods may be defined for arguments: x
> Use  showMethods("as.vector")  for currently available ones.
> > selectMethod("as.vector", "ANY")
> Method Definition (Class "internalDispatchMethod"):
>
> function (x, mode)
> .Internal(as.vector(x, mode))
> <environment: base>
>
> Signatures:
>         x
> target  "ANY"
> defined "ANY"
> > sessionInfo()
> R Under development (unstable) (2016-02-27 r70232)
> Platform: x86_64-pc-linux-gnu (64-bit)
> Running under: Ubuntu 14.04.4 LTS
>
> locale:
>  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] Matrix_1.2-4
>
> loaded via a namespace (and not attached):
> [1] grid_3.3.0      lattice_0.20-33
>
>
> ________________________________________
> From: R-devel <r-devel-bounces at r-project.org <javascript:;>> on behalf of
> Martin Maechler <maechler at stat.math.ethz.ch <javascript:;>>
> Sent: Friday, March 4, 2016 6:05 AM
> To: peter dalgaard
> Cc: r-devel at r-project.org <javascript:;>; Jeff Laake - NOAA Federal
> Subject: Re: [Rd] as.vector in R-devel loaded 3/3/2016
>
> >>>>> peter dalgaard <pdalgd at gmail.com <javascript:;>>
> >>>>>     on Fri, 4 Mar 2016 09:21:48 +0100 writes:
>
>     > Er, until _what_ is fixed?
>     > I see no anomalies with the version in R-pre:
>
> Indeed.
>
> The problem ... I also have stumbled over ..
> is that I'm sure Jeff is accidentally loading a different
> version of 'Matrix' than the one that is part of R-devel.
>
> Jeff you must accidentally be loading a version Matrix made with
> R 3.2.x in R 3.3.0  and that will fail with the as.vector()
> mismatch error message.
>
> (and IIRC, you also get such an error message if you load a
>  3.3.0-built version of Matrix into a non-3.3.0 version of R).
>
>
> Martin
>
> ______________________________________________
> R-devel at r-project.org <javascript:;> mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> This email message may contain legally privileged and/or confidential
> information.  If you are not the intended recipient(s), or the employee or
> agent responsible for the delivery of this message to the intended
> recipient(s), you are hereby notified that any disclosure, copying,
> distribution, or use of this email message is prohibited.  If you have
> received this message in error, please notify the sender immediately by
> e-mail and delete this email message from your computer. Thank you.
>

	[[alternative HTML version deleted]]


From maechler at stat.math.ethz.ch  Fri Mar  4 14:38:14 2016
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 4 Mar 2016 14:38:14 +0100
Subject: [Rd] as.vector in R-devel loaded 3/3/2016
In-Reply-To: <BN4PR12MB0883CA6ED32FC60B5F8CC902E1BE0@BN4PR12MB0883.namprd12.prod.outlook.com>
References: <CA+_rFBK8c5gXFm41StNPDiBYTW=uLXvj5d4cGzpfi9gdv-mW7A@mail.gmail.com>
	<CA+_rFBJbtEw47Qq-yfs54E7AwgX8+HK3FcXL3a7z+coDA=-KeQ@mail.gmail.com>
	<CB88A7FF-6C3D-400A-A086-6C6E5E75B507@gmail.com>
	<22233.27661.347312.341398@stat.math.ethz.ch>
	<BN4PR12MB0883CA6ED32FC60B5F8CC902E1BE0@BN4PR12MB0883.namprd12.prod.outlook.com>
Message-ID: <22233.36806.752001.689591@stat.math.ethz.ch>

>>>>> Morgan, Martin <Martin.Morgan at RoswellPark.org>
>>>>>     on Fri, 4 Mar 2016 12:36:25 +0000 writes:

    > I see as below, where getGeneric and getMethod imply a different signature; the signature is mode="any" for both cases in R version 3.2.3 Patched (2016-01-28 r70038)I don't know how to reproduce Jeff's error, though.

    >> library(Matrix)

    >> as.vector
    > function (x, mode = "any") 
    > .Internal(as.vector(x, mode))
    > <bytecode: 0xe79f88>
    > <environment: namespace:base>

so note, that even though Matrix is loaded, as.vector did not
have to change to a standardGeneric(.).

"The" reason is list among the NEWS  for R-devel :

 o   S4 dispatch works within calls to .Internal(). This means explicit
     S4 generics are no longer needed for unlist and as.vector.  

so this change was very much on purpose and has had the goal to
keep as.vector() "as fast as possible".

*BUT* indeed, the "signature mismatch" you observe has been
an bogous side effect of the change, and it may even be the
reason why versions of Matrix built in different versions of R
(3.2.x  vs  3.3.x) are problematic.

I'll commit a fix for this buglet {which also affects 'unlist' !} 
in a moment.

So after all, I'm very glad for this thread!
Martin

    >> getGeneric("as.vector")
    > standardGeneric for "as.vector" defined from package "base"

    > function (x, mode) 
    > standardGeneric("as.vector")
    > <bytecode: 0x29a6bd0>
    > <environment: 0x299f988>
    > Methods may be defined for arguments: x
    > Use  showMethods("as.vector")  for currently available ones.
    >> selectMethod("as.vector", "ANY")
    > Method Definition (Class "internalDispatchMethod"):

    > function (x, mode) 
    > .Internal(as.vector(x, mode))
    > <environment: base>

    > Signatures:
    > x    
    > target  "ANY"
    > defined "ANY"
    >> sessionInfo()
    > R Under development (unstable) (2016-02-27 r70232)
    > Platform: x86_64-pc-linux-gnu (64-bit)
    > Running under: Ubuntu 14.04.4 LTS

    > locale:
    > [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              
    > [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    
    > [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   
    > [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                 
    > [9] LC_ADDRESS=C               LC_TELEPHONE=C            
    > [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       

    > attached base packages:
    > [1] stats     graphics  grDevices utils     datasets  methods   base     

    > other attached packages:
    > [1] Matrix_1.2-4

    > loaded via a namespace (and not attached):
    > [1] grid_3.3.0      lattice_0.20-33


From Zwang at connecticutchildrens.org  Fri Mar  4 15:44:49 2016
From: Zwang at connecticutchildrens.org (Wang, Zhu)
Date: Fri, 4 Mar 2016 14:44:49 +0000
Subject: [Rd] vignette index
Message-ID: <DABBA49CC8C7AA4B959D2D0FEE496D72519C92C6@EXINFRCHMB1P.ccmc.local>

Dear helpers,

I have multiple vignette files for a package, and I would like to have the "right" order of these files when displayed online. For instance, see below:

https://cran.r-project.org/web/packages/bst/index.html

The order of vignette links on CRAN is different from what I hoped for:

> vignette(package="bst")
Vignettes in package 'bst':

pros                    Cancer Classification Using Mass
                        Spectrometry-based Proteomics Data (source,
                        pdf)
static_khan             Classification of Cancer Types Using Gene
                        Expression Data (Long) (source, pdf)
khan                    Classification of Cancer Types Using Gene
                        Expression Data (Short) (source, pdf)
static_mcl              Classification of UCI Machine Learning Datasets
                        (Long) (source, pdf)
mcl                     Classification of UCI Machine Learning Datasets
                        (Short) (source, pdf)

The package bst already has an index.html,  and I thought that should have done the job, but apparently not. Any suggestions?

Thanks,

Zhu

/bst/inst/doc/index.html
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head><title>R: Vignettes and other documentation</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<link rel="stylesheet" type="text/css" href="/doc/html/R.css" />
</head><body>
<h1> Vignettes and other documentation
<img class="toplogo" src="/doc/html/logo.jpg" alt="[R logo]" />
</h1>
<hr/>
<div style="text-align: center;">
<a href="/doc/html/index.html"><img class="arrow" src="/doc/html/up.jpg" alt="[Top]" /></a>
</div>
<h2>Vignettes from package 'bst'</h2>
<table width="100%">
<col style="width: 22%;" />
<col style="width:  2%;" />
<col style="width: 50%;" />
<col style="width:  8%;" />
<col style="width:  8%;" />
<col style="width:  8%;" />
<tr><td style="text-align: right; vertical-align: top;"><a href="../../../library/bst/doc/pros.pdf">bst::pros</a></td>
<td></td><td valign="top">Cancer Classification Using Mass Spectrometry-based Proteomics Data</td>
<td valign="top"><a href="../../../library/bst/doc/pros.pdf">PDF</a></td>
<td valign="top"><a href="../../../library/bst/doc/pros.Rnw">source</a></td>
<td valign="top" style="white-space: nowrap"><a href="../../../library/bst/doc/pros.R">R code</a></td></tr>
<tr><td style="text-align: right; vertical-align: top;"><a href="../../../library/bst/doc/static_khan.pdf">bst::static_khan</a></td>
<td></td><td valign="top">Classification of Cancer Types Using Gene Expression Data (Long)</td>
<td valign="top"><a href="../../../library/bst/doc/static_khan.pdf">PDF</a></td>
<td valign="top"><a href="../../../library/bst/doc/static_khan.pdf.asis">source</a></td>
<td valign="top" style="white-space: nowrap"></td></tr>
<tr><td style="text-align: right; vertical-align: top;"><a href="../../../library/bst/doc/khan.pdf">bst::khan</a></td>
<td></td><td valign="top">Classification of Cancer Types Using Gene Expression Data (Short)</td>
<td valign="top"><a href="../../../library/bst/doc/khan.pdf">PDF</a></td>
<td valign="top"><a href="../../../library/bst/doc/khan.Rnw">source</a></td>
<td valign="top" style="white-space: nowrap"><a href="../../../library/bst/doc/khan.R">R code</a></td></tr>
<tr><td style="text-align: right; vertical-align: top;"><a href="../../../library/bst/doc/static_mcl.pdf">bst::static_mcl</a></td>
<td></td><td valign="top">Classification of UCI Machine Learning Datasets (Long)</td>
<td valign="top"><a href="../../../library/bst/doc/static_mcl.pdf">PDF</a></td>
<td valign="top"><a href="../../../library/bst/doc/static_mcl.pdf.asis">source</a></td>
<td valign="top" style="white-space: nowrap"></td></tr>
<tr><td style="text-align: right; vertical-align: top;"><a href="../../../library/bst/doc/mcl.pdf">bst::mcl</a></td>
<td></td><td valign="top">Classification of UCI Machine Learning Datasets (Short)</td>
<td valign="top"><a href="../../../library/bst/doc/mcl.pdf">PDF</a></td>
<td valign="top"><a href="../../../library/bst/doc/mcl.Rnw">source</a></td>
<td valign="top" style="white-space: nowrap"><a href="../../../library/bst/doc/mcl.R">R code</a></td></tr>
</table>
</body></html>
../../Rpkg/bst/inst/doc/index.html (END)


**Connecticut Children's Confidentiality Notice**
This e-mail message, including any attachments, is for t...{{dropped:8}}


From brian at braverock.com  Fri Mar  4 16:36:41 2016
From: brian at braverock.com (Brian G. Peterson)
Date: Fri, 04 Mar 2016 09:36:41 -0600
Subject: [Rd] vignette index
In-Reply-To: <DABBA49CC8C7AA4B959D2D0FEE496D72519C92C6@EXINFRCHMB1P.ccmc.local>
References: <DABBA49CC8C7AA4B959D2D0FEE496D72519C92C6@EXINFRCHMB1P.ccmc.local>
Message-ID: <1457105801.29173.4.camel@brian-rcg>

This probably belongs on  r-package-devel at r-project.org as it is not
about the development of R itself, but about package development.
-- 
Brian 

On Fri, 2016-03-04 at 14:44 +0000, Wang, Zhu wrote:
> Dear helpers,
> 
> I have multiple vignette files for a package, and I would like to have the "right" order of these files when displayed online. For instance, see below:
> 
> https://cran.r-project.org/web/packages/bst/index.html
> 
> The order of vignette links on CRAN is different from what I hoped for:
> 
> > vignette(package="bst")
> Vignettes in package 'bst':
> 
> pros                    Cancer Classification Using Mass
>                         Spectrometry-based Proteomics Data (source,
>                         pdf)
> static_khan             Classification of Cancer Types Using Gene
>                         Expression Data (Long) (source, pdf)
> khan                    Classification of Cancer Types Using Gene
>                         Expression Data (Short) (source, pdf)
> static_mcl              Classification of UCI Machine Learning Datasets
>                         (Long) (source, pdf)
> mcl                     Classification of UCI Machine Learning Datasets
>                         (Short) (source, pdf)
> 
> The package bst already has an index.html,  and I thought that should have done the job, but apparently not. Any suggestions?
> 
> Thanks,
> 
> Zhu
> 
> /bst/inst/doc/index.html
> <!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
> <html xmlns="http://www.w3.org/1999/xhtml">
> <head><title>R: Vignettes and other documentation</title>
> <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
> <link rel="stylesheet" type="text/css" href="/doc/html/R.css" />
> </head><body>
> <h1> Vignettes and other documentation
> <img class="toplogo" src="/doc/html/logo.jpg" alt="[R logo]" />
> </h1>
> <hr/>
> <div style="text-align: center;">
> <a href="/doc/html/index.html"><img class="arrow" src="/doc/html/up.jpg" alt="[Top]" /></a>
> </div>
> <h2>Vignettes from package 'bst'</h2>
> <table width="100%">
> <col style="width: 22%;" />
> <col style="width:  2%;" />
> <col style="width: 50%;" />
> <col style="width:  8%;" />
> <col style="width:  8%;" />
> <col style="width:  8%;" />
> <tr><td style="text-align: right; vertical-align: top;"><a href="../../../library/bst/doc/pros.pdf">bst::pros</a></td>
> <td></td><td valign="top">Cancer Classification Using Mass Spectrometry-based Proteomics Data</td>
> <td valign="top"><a href="../../../library/bst/doc/pros.pdf">PDF</a></td>
> <td valign="top"><a href="../../../library/bst/doc/pros.Rnw">source</a></td>
> <td valign="top" style="white-space: nowrap"><a href="../../../library/bst/doc/pros.R">R code</a></td></tr>
> <tr><td style="text-align: right; vertical-align: top;"><a href="../../../library/bst/doc/static_khan.pdf">bst::static_khan</a></td>
> <td></td><td valign="top">Classification of Cancer Types Using Gene Expression Data (Long)</td>
> <td valign="top"><a href="../../../library/bst/doc/static_khan.pdf">PDF</a></td>
> <td valign="top"><a href="../../../library/bst/doc/static_khan.pdf.asis">source</a></td>
> <td valign="top" style="white-space: nowrap"></td></tr>
> <tr><td style="text-align: right; vertical-align: top;"><a href="../../../library/bst/doc/khan.pdf">bst::khan</a></td>
> <td></td><td valign="top">Classification of Cancer Types Using Gene Expression Data (Short)</td>
> <td valign="top"><a href="../../../library/bst/doc/khan.pdf">PDF</a></td>
> <td valign="top"><a href="../../../library/bst/doc/khan.Rnw">source</a></td>
> <td valign="top" style="white-space: nowrap"><a href="../../../library/bst/doc/khan.R">R code</a></td></tr>
> <tr><td style="text-align: right; vertical-align: top;"><a href="../../../library/bst/doc/static_mcl.pdf">bst::static_mcl</a></td>
> <td></td><td valign="top">Classification of UCI Machine Learning Datasets (Long)</td>
> <td valign="top"><a href="../../../library/bst/doc/static_mcl.pdf">PDF</a></td>
> <td valign="top"><a href="../../../library/bst/doc/static_mcl.pdf.asis">source</a></td>
> <td valign="top" style="white-space: nowrap"></td></tr>
> <tr><td style="text-align: right; vertical-align: top;"><a href="../../../library/bst/doc/mcl.pdf">bst::mcl</a></td>
> <td></td><td valign="top">Classification of UCI Machine Learning Datasets (Short)</td>
> <td valign="top"><a href="../../../library/bst/doc/mcl.pdf">PDF</a></td>
> <td valign="top"><a href="../../../library/bst/doc/mcl.Rnw">source</a></td>
> <td valign="top" style="white-space: nowrap"><a href="../../../library/bst/doc/mcl.R">R code</a></td></tr>
> </table>
> </body></html>
> ../../Rpkg/bst/inst/doc/index.html (END)
> 
> 
> **Connecticut Children's Confidentiality Notice**
> This e-mail message, including any attachments, is for...{{dropped:6}}


From murdoch.duncan at gmail.com  Fri Mar  4 16:47:03 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 4 Mar 2016 10:47:03 -0500
Subject: [Rd] vignette index
In-Reply-To: <DABBA49CC8C7AA4B959D2D0FEE496D72519C92C6@EXINFRCHMB1P.ccmc.local>
References: <DABBA49CC8C7AA4B959D2D0FEE496D72519C92C6@EXINFRCHMB1P.ccmc.local>
Message-ID: <56D9ADF7.2050506@gmail.com>

On 04/03/2016 9:44 AM, Wang, Zhu wrote:
> Dear helpers,
>
> I have multiple vignette files for a package, and I would like to have the "right" order of these files when displayed online. For instance, see below:
>
> https://cran.r-project.org/web/packages/bst/index.html
>
> The order of vignette links on CRAN is different from what I hoped for:
>
> > vignette(package="bst")
> Vignettes in package 'bst':
>
> pros                    Cancer Classification Using Mass
>                          Spectrometry-based Proteomics Data (source,
>                          pdf)
> static_khan             Classification of Cancer Types Using Gene
>                          Expression Data (Long) (source, pdf)
> khan                    Classification of Cancer Types Using Gene
>                          Expression Data (Short) (source, pdf)
> static_mcl              Classification of UCI Machine Learning Datasets
>                          (Long) (source, pdf)
> mcl                     Classification of UCI Machine Learning Datasets
>                          (Short) (source, pdf)
>
> The package bst already has an index.html,  and I thought that should have done the job, but apparently not. Any suggestions?
>

The index.html file should be used in the online help system, but 
vignette() doesn't use that, it looks in the internal database of 
vignettes.  I don't think you can control the order in which it displays 
things.

This could conceivably be changed, but not by consulting your index.html 
file --- it is not required to follow a particular structure, so we 
can't find what order you want from it.  One more likely possibility 
would be to sort alphabetically in the current locale according to 
filename or vignette title.  So then you could get what you want by 
naming your vignettes 1pros, 2static_khan, etc.

It would also be possible to add a new \VignetteXXXX directive so affect 
collation order, but that seems like overkill.

Duncan Murdoch


From Zwang at connecticutchildrens.org  Fri Mar  4 17:18:14 2016
From: Zwang at connecticutchildrens.org (Wang, Zhu)
Date: Fri, 4 Mar 2016 16:18:14 +0000
Subject: [Rd] vignette index
In-Reply-To: <56D9ADF7.2050506@gmail.com>
References: <DABBA49CC8C7AA4B959D2D0FEE496D72519C92C6@EXINFRCHMB1P.ccmc.local>
	<56D9ADF7.2050506@gmail.com>
Message-ID: <DABBA49CC8C7AA4B959D2D0FEE496D72519C9301@EXINFRCHMB1P.ccmc.local>

I think the online order of vignette files are not based on vignette title or filename alphabetically. I am just curious: by what order these vignette files were displayed online so I can make changes accordingly?

Thanks,

Zhu

-----Original Message-----
From: Duncan Murdoch [mailto:murdoch.duncan at gmail.com]
Sent: Friday, March 04, 2016 10:47 AM
To: Wang, Zhu; r-devel at r-project.org
Subject: Re: [Rd] vignette index

On 04/03/2016 9:44 AM, Wang, Zhu wrote:
> Dear helpers,
>
> I have multiple vignette files for a package, and I would like to have the "right" order of these files when displayed online. For instance, see below:
>
> https://cran.r-project.org/web/packages/bst/index.html
>
> The order of vignette links on CRAN is different from what I hoped for:
>
> > vignette(package="bst")
> Vignettes in package 'bst':
>
> pros                    Cancer Classification Using Mass
>                          Spectrometry-based Proteomics Data (source,
>                          pdf)
> static_khan             Classification of Cancer Types Using Gene
>                          Expression Data (Long) (source, pdf)
> khan                    Classification of Cancer Types Using Gene
>                          Expression Data (Short) (source, pdf)
> static_mcl              Classification of UCI Machine Learning Datasets
>                          (Long) (source, pdf)
> mcl                     Classification of UCI Machine Learning Datasets
>                          (Short) (source, pdf)
>
> The package bst already has an index.html,  and I thought that should have done the job, but apparently not. Any suggestions?
>

The index.html file should be used in the online help system, but
vignette() doesn't use that, it looks in the internal database of vignettes.  I don't think you can control the order in which it displays things.

This could conceivably be changed, but not by consulting your index.html file --- it is not required to follow a particular structure, so we can't find what order you want from it.  One more likely possibility would be to sort alphabetically in the current locale according to filename or vignette title.  So then you could get what you want by naming your vignettes 1pros, 2static_khan, etc.

It would also be possible to add a new \VignetteXXXX directive so affect collation order, but that seems like overkill.

Duncan Murdoch

**Connecticut Children's Confidentiality Notice**
This e-mail message, including any attachments, is for t...{{dropped:8}}


From martyn.byng at nag.co.uk  Fri Mar  4 17:52:44 2016
From: martyn.byng at nag.co.uk (Martyn Byng)
Date: Fri, 4 Mar 2016 16:52:44 +0000
Subject: [Rd] ALLOCATE in a FORTRAN subroutine
In-Reply-To: <6c39c4cbb0fb4e6d80fb36ad28b2b89f@NOEINTPEXMU007.NEOPROD.EDF.FR>
References: <6c39c4cbb0fb4e6d80fb36ad28b2b89f@NOEINTPEXMU007.NEOPROD.EDF.FR>
Message-ID: <VI1PR05MB153679050141DD2F5DE716E2A1BE0@VI1PR05MB1536.eurprd05.prod.outlook.com>

Hi,

Until you get a more definitive answer, I will make an attempt to give some advice.

When using an assumed sized array (i.e. REAL*8 array1(*)) you still need to allocate the memory prior to calling the Fortran subroutine, so you would still need to know its maximum length.

Arrays created in a Fortran subroutine via the use of the ALLOCATE statements are not simple arrays (in the sense of C like pointers), but are more akin to a C structure, in that they also contain information concerning the size of the array, stride etc. These structures are compiler dependent, their contents often not clearly documented and subject to change. They are therefore not very good for cross-language computing (or even cross-compiler computing).

To try and alleviate this the Fortran standard introduced C interoperability (see https://gcc.gnu.org/onlinedocs/gfortran/Interoperability-with-C.html for example) and I expect you are going to have to take a look at this in order to pass memory allocated in your Fortran program back up to R. Care is going to have be taken to make sure that the memory is deallocated when it has been finished with (which is probably going to have to be done in Fortran).

The easiest way of getting all this to interact nicely with R is probably through the R C API which is described in documents like https://cran.r-project.org/doc/manuals/R-exts.pdf.

Martyn


-----Original Message-----
From: R-devel [mailto:r-devel-bounces at r-project.org] On Behalf Of MAURICE Jean - externe
Sent: 04 March 2016 08:34
To: r-devel at r-project.org
Subject: [Rd] ALLOCATE in a FORTRAN subroutine

Hi,
I am a FORTRAN developer and I am 'translating' R functions in FORTRAN subroutines. I am 'new' to R. It's my first question in this mailing-list and English is not my natural language.

Very often, an R function gives an  'array' as result and you don't have to bother with the dimension of the array : R creates automatically an array with the good length. It's not really the case with FORTRAN. I call FORTRAN subroutines with .fortran().

Until now, I create an array with the 'max' dimensions in R, give it to FORTRAN; FORTRAN updates the array and R retrieves it. But calculating the 'max' before calling the FORTRAN subroutine can be complicated. Is it possible to create a 'new' array in a FORTRAN subroutine and to make it be read by R ?

Or is it possible to have a 'pointer' in R, to give it to the FORTRAN subroutine where an ALLOCATE can create the array and then R works with the array ?
The other solution, is to work with dummies dimension in FORTRAN (REAL*8 array1(*)) but can R work with that ?

TIA
Jean


________________________________________________________________________
This e-mail has been scanned for all viruses by Star.\ _...{{dropped:16}}


From Martin.Morgan at roswellpark.org  Fri Mar  4 19:19:20 2016
From: Martin.Morgan at roswellpark.org (Morgan, Martin)
Date: Fri, 4 Mar 2016 18:19:20 +0000
Subject: [Rd] vignette index
In-Reply-To: <DABBA49CC8C7AA4B959D2D0FEE496D72519C9301@EXINFRCHMB1P.ccmc.local>
References: <DABBA49CC8C7AA4B959D2D0FEE496D72519C92C6@EXINFRCHMB1P.ccmc.local>
	<56D9ADF7.2050506@gmail.com>,
	<DABBA49CC8C7AA4B959D2D0FEE496D72519C9301@EXINFRCHMB1P.ccmc.local>
Message-ID: <BN4PR12MB08836A911334D0FDE3F04DB6E1BE0@BN4PR12MB0883.namprd12.prod.outlook.com>

Within R these are determined by \VignetteIndexEntry{}. I think you are referring to the order on the CRAN landing page for your package https://cran.r-project.org/web/packages/bst/index.html, and then the question is for a CRAN member.

In Rnw

\documentclass{article}

% \VignetteIndexEntry{01-Foo}

\begin{document}
01-Foo
\end{document}

or Rmd as

---
title: "Demo"
author: Ima Scientist <ima at scientist.org>
vignette: >
  % \VignetteIndexEntry{01-Foo}
  % \VignetteEngine{knitr::rmarkdown}
---

________________________________________
From: R-devel <r-devel-bounces at r-project.org> on behalf of Wang, Zhu <Zwang at connecticutchildrens.org>
Sent: Friday, March 4, 2016 11:18 AM
To: Duncan Murdoch; r-devel at r-project.org
Subject: Re: [Rd] vignette index

I think the online order of vignette files are not based on vignette title or filename alphabetically. I am just curious: by what order these vignette files were displayed online so I can make changes accordingly?

Thanks,

Zhu

-----Original Message-----
From: Duncan Murdoch [mailto:murdoch.duncan at gmail.com]
Sent: Friday, March 04, 2016 10:47 AM
To: Wang, Zhu; r-devel at r-project.org
Subject: Re: [Rd] vignette index

On 04/03/2016 9:44 AM, Wang, Zhu wrote:
> Dear helpers,
>
> I have multiple vignette files for a package, and I would like to have the "right" order of these files when displayed online. For instance, see below:
>
> https://cran.r-project.org/web/packages/bst/index.html
>
> The order of vignette links on CRAN is different from what I hoped for:
>
> > vignette(package="bst")
> Vignettes in package 'bst':
>
> pros                    Cancer Classification Using Mass
>                          Spectrometry-based Proteomics Data (source,
>                          pdf)
> static_khan             Classification of Cancer Types Using Gene
>                          Expression Data (Long) (source, pdf)
> khan                    Classification of Cancer Types Using Gene
>                          Expression Data (Short) (source, pdf)
> static_mcl              Classification of UCI Machine Learning Datasets
>                          (Long) (source, pdf)
> mcl                     Classification of UCI Machine Learning Datasets
>                          (Short) (source, pdf)
>
> The package bst already has an index.html,  and I thought that should have done the job, but apparently not. Any suggestions?
>

The index.html file should be used in the online help system, but
vignette() doesn't use that, it looks in the internal database of vignettes.  I don't think you can control the order in which it displays things.

This could conceivably be changed, but not by consulting your index.html file --- it is not required to follow a particular structure, so we can't find what order you want from it.  One more likely possibility would be to sort alphabetically in the current locale according to filename or vignette title.  So then you could get what you want by naming your vignettes 1pros, 2static_khan, etc.

It would also be possible to add a new \VignetteXXXX directive so affect collation order, but that seems like overkill.

Duncan Murdoch

**Connecticut Children's Confidentiality Notice**
This e-mail message, including any attachments, is for =...{{dropped:15}}


From murdoch.duncan at gmail.com  Fri Mar  4 23:42:35 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 4 Mar 2016 17:42:35 -0500
Subject: [Rd] vignette index
In-Reply-To: <DABBA49CC8C7AA4B959D2D0FEE496D72519C9301@EXINFRCHMB1P.ccmc.local>
References: <DABBA49CC8C7AA4B959D2D0FEE496D72519C92C6@EXINFRCHMB1P.ccmc.local>
	<56D9ADF7.2050506@gmail.com>
	<DABBA49CC8C7AA4B959D2D0FEE496D72519C9301@EXINFRCHMB1P.ccmc.local>
Message-ID: <56DA0F5B.3010109@gmail.com>

On 04/03/2016 11:18 AM, Wang, Zhu wrote:
> I think the online order of vignette files are not based on vignette title or filename alphabetically. I am just curious: by what order these vignette files were displayed online so I can make changes accordingly?

You have the source code, and can figure it out as well as I can.

Duncan Murdoch

>
> Thanks,
>
> Zhu
>
> -----Original Message-----
> From: Duncan Murdoch [mailto:murdoch.duncan at gmail.com]
> Sent: Friday, March 04, 2016 10:47 AM
> To: Wang, Zhu; r-devel at r-project.org
> Subject: Re: [Rd] vignette index
>
> On 04/03/2016 9:44 AM, Wang, Zhu wrote:
>> Dear helpers,
>>
>> I have multiple vignette files for a package, and I would like to have the "right" order of these files when displayed online. For instance, see below:
>>
>> https://cran.r-project.org/web/packages/bst/index.html
>>
>> The order of vignette links on CRAN is different from what I hoped for:
>>
>>> vignette(package="bst")
>> Vignettes in package 'bst':
>>
>> pros                    Cancer Classification Using Mass
>>                           Spectrometry-based Proteomics Data (source,
>>                           pdf)
>> static_khan             Classification of Cancer Types Using Gene
>>                           Expression Data (Long) (source, pdf)
>> khan                    Classification of Cancer Types Using Gene
>>                           Expression Data (Short) (source, pdf)
>> static_mcl              Classification of UCI Machine Learning Datasets
>>                           (Long) (source, pdf)
>> mcl                     Classification of UCI Machine Learning Datasets
>>                           (Short) (source, pdf)
>>
>> The package bst already has an index.html,  and I thought that should have done the job, but apparently not. Any suggestions?
>>
>
> The index.html file should be used in the online help system, but
> vignette() doesn't use that, it looks in the internal database of vignettes.  I don't think you can control the order in which it displays things.
>
> This could conceivably be changed, but not by consulting your index.html file --- it is not required to follow a particular structure, so we can't find what order you want from it.  One more likely possibility would be to sort alphabetically in the current locale according to filename or vignette title.  So then you could get what you want by naming your vignettes 1pros, 2static_khan, etc.
>
> It would also be possible to add a new \VignetteXXXX directive so affect collation order, but that seems like overkill.
>
> Duncan Murdoch
>
> **Connecticut Children's Confidentiality Notice**
> This e-mail message, including any attachments, is for...{{dropped:3}}


From r.turner at auckland.ac.nz  Sat Mar  5 03:35:39 2016
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Sat, 5 Mar 2016 15:35:39 +1300
Subject: [Rd] Problem installing R-devel data 4 March 2016.
Message-ID: <56DA45FB.7050807@auckland.ac.nz>


I am trying to install the latest development version of R so as to be 
able to perform a package check according the rules specified for CRAN.

I performed the following steps:

(1) Downloaded  R-devel.tar.gz, dated 04-Mar-2016 03:21, from CRAN
(2) Upacked.
(3) Created directory "BldDir" next to the directory "R-devel".
(4) Changed directories to BldDir.
(5) Executed  ../R-devel/configure --with-tcltk --with-cairo .
(6) Executed make .
(7) Executed sudo make install .

I got the error messages:
   .
   .
   .
> mkdir -p -- /usr/local/lib64/R/doc
> /usr/bin/install: cannot stat `FAQ': No such file or directory
> /usr/bin/install: cannot stat `RESOURCES': No such file or directory
> /usr/bin/install: cannot stat `NEWS': No such file or directory
> /usr/bin/install: cannot stat `NEWS.pdf': No such file or directory
> /usr/bin/install: cannot stat `NEWS.rds': No such file or directory
> /usr/bin/install: cannot stat `NEWS': No such file or directory
> /usr/bin/install: cannot stat `NEWS.pdf': No such file or directory
> make[1]: *** [install-sources2] Error 1
> make[1]: Leaving directory `/home/rolf/Desktop/R-dev-inst/BldDir/doc'
> make: *** [install] Error 1

Can someone/anyone tell me what I am missing or doing wrong?

Ta.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From pdalgd at gmail.com  Sat Mar  5 15:10:11 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Sat, 5 Mar 2016 15:10:11 +0100
Subject: [Rd] Problem installing R-devel data 4 March 2016.
In-Reply-To: <56DA45FB.7050807@auckland.ac.nz>
References: <56DA45FB.7050807@auckland.ac.nz>
Message-ID: <0FE01F30-ED12-475E-88F8-FFF67C610493@gmail.com>


> On 05 Mar 2016, at 03:35 , Rolf Turner <r.turner at auckland.ac.nz> wrote:
> 
> 
> I am trying to install the latest development version of R so as to be able to perform a package check according the rules specified for CRAN.
> 
> I performed the following steps:
> 
> (1) Downloaded  R-devel.tar.gz, dated 04-Mar-2016 03:21, from CRAN
> (2) Upacked.
> (3) Created directory "BldDir" next to the directory "R-devel".
> (4) Changed directories to BldDir.
> (5) Executed  ../R-devel/configure --with-tcltk --with-cairo .
> (6) Executed make .
> (7) Executed sudo make install .
> 
> I got the error messages:
>  .
>  .
>  .
>> mkdir -p -- /usr/local/lib64/R/doc
>> /usr/bin/install: cannot stat `FAQ': No such file or directory
>> /usr/bin/install: cannot stat `RESOURCES': No such file or directory
>> /usr/bin/install: cannot stat `NEWS': No such file or directory
>> /usr/bin/install: cannot stat `NEWS.pdf': No such file or directory
>> /usr/bin/install: cannot stat `NEWS.rds': No such file or directory
>> /usr/bin/install: cannot stat `NEWS': No such file or directory
>> /usr/bin/install: cannot stat `NEWS.pdf': No such file or directory
>> make[1]: *** [install-sources2] Error 1
>> make[1]: Leaving directory `/home/rolf/Desktop/R-dev-inst/BldDir/doc'
>> make: *** [install] Error 1
> 
> Can someone/anyone tell me what I am missing or doing wrong?
> 

Beats me. & I just checked that make install works on my system (usually, I just run test versions out of their build dirs).

You might check a couple of things though:

- does ~/Desktop/R-dev-inst/BldDir/bin/R work?
- does ~/Desktop/R-dev-inst/BldDir/doc/FAQ et al. actually exist?
- is there an overzealous virus checker active (those have been known to move fresh files to "safe locations" right under peoples feet...)

-pd


> Ta.
> 
> cheers,
> 
> Rolf Turner
> 
> -- 
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From r.turner at auckland.ac.nz  Sun Mar  6 04:54:06 2016
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Sun, 6 Mar 2016 16:54:06 +1300
Subject: [Rd] Problem installing R-devel dated 4 March 2016.
In-Reply-To: <0FE01F30-ED12-475E-88F8-FFF67C610493@gmail.com>
References: <56DA45FB.7050807@auckland.ac.nz>
	<0FE01F30-ED12-475E-88F8-FFF67C610493@gmail.com>
Message-ID: <56DBA9DE.6090906@auckland.ac.nz>


Thanks Peter.  I tried running the uninstalled R; it worked.  I checked 
on the existence of FAQ, etc. --- yep everything was there.  I don't 
know about over-zealous virus checkers; I haven't overtly installed any 
such.

So, mystified, I started all over again from scratch.  This time it 
worked; seamlessly.

Totally mysterious.  Story of my life.  Be that as it were, all systems 
are go now, and my package checking was successful.

Sorry for the noise.

cheers,

Rolf

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276

On 06/03/16 03:10, peter dalgaard wrote:
>
>> On 05 Mar 2016, at 03:35 , Rolf Turner <r.turner at auckland.ac.nz> wrote:
>>
>>
>> I am trying to install the latest development version of R so as to be able to perform a package check according the rules specified for CRAN.
>>
>> I performed the following steps:
>>
>> (1) Downloaded  R-devel.tar.gz, dated 04-Mar-2016 03:21, from CRAN
>> (2) Upacked.
>> (3) Created directory "BldDir" next to the directory "R-devel".
>> (4) Changed directories to BldDir.
>> (5) Executed  ../R-devel/configure --with-tcltk --with-cairo .
>> (6) Executed make .
>> (7) Executed sudo make install .
>>
>> I got the error messages:
>>   .
>>   .
>>   .
>>> mkdir -p -- /usr/local/lib64/R/doc
>>> /usr/bin/install: cannot stat `FAQ': No such file or directory
>>> /usr/bin/install: cannot stat `RESOURCES': No such file or directory
>>> /usr/bin/install: cannot stat `NEWS': No such file or directory
>>> /usr/bin/install: cannot stat `NEWS.pdf': No such file or directory
>>> /usr/bin/install: cannot stat `NEWS.rds': No such file or directory
>>> /usr/bin/install: cannot stat `NEWS': No such file or directory
>>> /usr/bin/install: cannot stat `NEWS.pdf': No such file or directory
>>> make[1]: *** [install-sources2] Error 1
>>> make[1]: Leaving directory `/home/rolf/Desktop/R-dev-inst/BldDir/doc'
>>> make: *** [install] Error 1
>>
>> Can someone/anyone tell me what I am missing or doing wrong?
>>
>
> Beats me. & I just checked that make install works on my system (usually, I just run test versions out of their build dirs).
>
> You might check a couple of things though:
>
> - does ~/Desktop/R-dev-inst/BldDir/bin/R work?
> - does ~/Desktop/R-dev-inst/BldDir/doc/FAQ et al. actually exist?
> - is there an overzealous virus checker active (those have been known to move fresh files to "safe locations" right under peoples feet...)
>
> -pd
>
>
>> Ta.


From pdalgd at gmail.com  Sun Mar  6 09:27:22 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Sun, 6 Mar 2016 09:27:22 +0100
Subject: [Rd] Problem installing R-devel dated 4 March 2016.
In-Reply-To: <56DBA9DE.6090906@auckland.ac.nz>
References: <56DA45FB.7050807@auckland.ac.nz>
	<0FE01F30-ED12-475E-88F8-FFF67C610493@gmail.com>
	<56DBA9DE.6090906@auckland.ac.nz>
Message-ID: <560BB72C-86F2-4062-8E7F-481B4E9C02C8@gmail.com>

Hm, we'll likely never find out. It looks a bit like a race condition or a Makefile deficiency in which some dependencies are not explicitly recorded (so that it tries to copy files before they have been made). I suppose that could happen if you try "make install" w/o a preceding "make". 

-pd

> On 06 Mar 2016, at 04:54 , Rolf Turner <r.turner at auckland.ac.nz> wrote:
> 
> 
> Thanks Peter.  I tried running the uninstalled R; it worked.  I checked on the existence of FAQ, etc. --- yep everything was there.  I don't know about over-zealous virus checkers; I haven't overtly installed any such.
> 
> So, mystified, I started all over again from scratch.  This time it worked; seamlessly.
> 
> Totally mysterious.  Story of my life.  Be that as it were, all systems are go now, and my package checking was successful.
> 
> Sorry for the noise.
> 
> cheers,
> 
> Rolf
> 
> -- 
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
> 
> On 06/03/16 03:10, peter dalgaard wrote:
>> 
>>> On 05 Mar 2016, at 03:35 , Rolf Turner <r.turner at auckland.ac.nz> wrote:
>>> 
>>> 
>>> I am trying to install the latest development version of R so as to be able to perform a package check according the rules specified for CRAN.
>>> 
>>> I performed the following steps:
>>> 
>>> (1) Downloaded  R-devel.tar.gz, dated 04-Mar-2016 03:21, from CRAN
>>> (2) Upacked.
>>> (3) Created directory "BldDir" next to the directory "R-devel".
>>> (4) Changed directories to BldDir.
>>> (5) Executed  ../R-devel/configure --with-tcltk --with-cairo .
>>> (6) Executed make .
>>> (7) Executed sudo make install .
>>> 
>>> I got the error messages:
>>>  .
>>>  .
>>>  .
>>>> mkdir -p -- /usr/local/lib64/R/doc
>>>> /usr/bin/install: cannot stat `FAQ': No such file or directory
>>>> /usr/bin/install: cannot stat `RESOURCES': No such file or directory
>>>> /usr/bin/install: cannot stat `NEWS': No such file or directory
>>>> /usr/bin/install: cannot stat `NEWS.pdf': No such file or directory
>>>> /usr/bin/install: cannot stat `NEWS.rds': No such file or directory
>>>> /usr/bin/install: cannot stat `NEWS': No such file or directory
>>>> /usr/bin/install: cannot stat `NEWS.pdf': No such file or directory
>>>> make[1]: *** [install-sources2] Error 1
>>>> make[1]: Leaving directory `/home/rolf/Desktop/R-dev-inst/BldDir/doc'
>>>> make: *** [install] Error 1
>>> 
>>> Can someone/anyone tell me what I am missing or doing wrong?
>>> 
>> 
>> Beats me. & I just checked that make install works on my system (usually, I just run test versions out of their build dirs).
>> 
>> You might check a couple of things though:
>> 
>> - does ~/Desktop/R-dev-inst/BldDir/bin/R work?
>> - does ~/Desktop/R-dev-inst/BldDir/doc/FAQ et al. actually exist?
>> - is there an overzealous virus checker active (those have been known to move fresh files to "safe locations" right under peoples feet...)
>> 
>> -pd
>> 
>> 
>>> Ta.
> 
> 
> 

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From r.turner at auckland.ac.nz  Sun Mar  6 10:15:59 2016
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Sun, 6 Mar 2016 22:15:59 +1300
Subject: [Rd] Problem installing R-devel dated 4 March 2016.
In-Reply-To: <560BB72C-86F2-4062-8E7F-481B4E9C02C8@gmail.com>
References: <56DA45FB.7050807@auckland.ac.nz>
	<0FE01F30-ED12-475E-88F8-FFF67C610493@gmail.com>
	<56DBA9DE.6090906@auckland.ac.nz>
	<560BB72C-86F2-4062-8E7F-481B4E9C02C8@gmail.com>
Message-ID: <56DBF54F.9080804@auckland.ac.nz>

On 06/03/16 21:27, peter dalgaard wrote:
> Hm, we'll likely never find out. It looks a bit like a race condition
> or a Makefile deficiency in which some dependencies are not
> explicitly recorded (so that it tries to copy files before they have
> been made). I suppose that could happen if you try "make install" w/o
> a preceding "make".

I am *certain* that the latter contretemps did not occur.  I *know* that
I did a make.  Of course I *have* been known to be certain of things 
that weren't actually true ....  But in this instance .....

As you say, we'll never find out.

cheers,

Rolf

>
> -pd
>
>> On 06 Mar 2016, at 04:54 , Rolf Turner <r.turner at auckland.ac.nz> wrote:
>>
>>
>> Thanks Peter.  I tried running the uninstalled R; it worked.  I checked on the existence of FAQ, etc. --- yep everything was there.  I don't know about over-zealous virus checkers; I haven't overtly installed any such.
>>
>> So, mystified, I started all over again from scratch.  This time it worked; seamlessly.
>>
>> Totally mysterious.  Story of my life.  Be that as it were, all systems are go now, and my package checking was successful.
>>
>> Sorry for the noise.
>>
>> cheers,
>>
>> Rolf
>>
>> --
>> Technical Editor ANZJS
>> Department of Statistics
>> University of Auckland
>> Phone: +64-9-373-7599 ext. 88276
>>
>> On 06/03/16 03:10, peter dalgaard wrote:
>>>
>>>> On 05 Mar 2016, at 03:35 , Rolf Turner <r.turner at auckland.ac.nz> wrote:
>>>>
>>>>
>>>> I am trying to install the latest development version of R so as to be able to perform a package check according the rules specified for CRAN.
>>>>
>>>> I performed the following steps:
>>>>
>>>> (1) Downloaded  R-devel.tar.gz, dated 04-Mar-2016 03:21, from CRAN
>>>> (2) Upacked.
>>>> (3) Created directory "BldDir" next to the directory "R-devel".
>>>> (4) Changed directories to BldDir.
>>>> (5) Executed  ../R-devel/configure --with-tcltk --with-cairo .
>>>> (6) Executed make .
>>>> (7) Executed sudo make install .
>>>>
>>>> I got the error messages:
>>>>   .
>>>>   .
>>>>   .
>>>>> mkdir -p -- /usr/local/lib64/R/doc
>>>>> /usr/bin/install: cannot stat `FAQ': No such file or directory
>>>>> /usr/bin/install: cannot stat `RESOURCES': No such file or directory
>>>>> /usr/bin/install: cannot stat `NEWS': No such file or directory
>>>>> /usr/bin/install: cannot stat `NEWS.pdf': No such file or directory
>>>>> /usr/bin/install: cannot stat `NEWS.rds': No such file or directory
>>>>> /usr/bin/install: cannot stat `NEWS': No such file or directory
>>>>> /usr/bin/install: cannot stat `NEWS.pdf': No such file or directory
>>>>> make[1]: *** [install-sources2] Error 1
>>>>> make[1]: Leaving directory `/home/rolf/Desktop/R-dev-inst/BldDir/doc'
>>>>> make: *** [install] Error 1
>>>>
>>>> Can someone/anyone tell me what I am missing or doing wrong?
>>>>
>>>
>>> Beats me. & I just checked that make install works on my system (usually, I just run test versions out of their build dirs).
>>>
>>> You might check a couple of things though:
>>>
>>> - does ~/Desktop/R-dev-inst/BldDir/bin/R work?
>>> - does ~/Desktop/R-dev-inst/BldDir/doc/FAQ et al. actually exist?
>>> - is there an overzealous virus checker active (those have been known to move fresh files to "safe locations" right under peoples feet...)
>>>
>>> -pd
>>>
>>>
>>>> Ta.
>>
>>
>>


From edd at debian.org  Sun Mar  6 17:27:35 2016
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sun, 6 Mar 2016 10:27:35 -0600
Subject: [Rd] R 3.2.4 rc issue
In-Reply-To: <22233.33175.270791.397346@max.nulle.part>
References: <22233.1636.385295.261603@max.nulle.part>
	<DDCB6BD8-BC16-4CF6-9AFB-8188F334CDF0@gmail.com>
	<22233.33175.270791.397346@max.nulle.part>
Message-ID: <22236.23159.583666.91789@max.nulle.part>


On 4 March 2016 at 06:37, Dirk Eddelbuettel wrote:
| 
| On 4 March 2016 at 09:11, peter dalgaard wrote:
| | Thanks for the info, Dirk.
| | 
| | The tarball builds don't run make check (because of a policy decision that it is better to have the sources available on all platforms for testing than to have none if it breaks on a single platform). However the build as of tonight has no problem with make check on the build machine. Did you by any chance forget that Matrix is a recommended package and expected to be available when checking?
| 
| Our build systems are heavily standardized and create pristine chroot
| environments with exactly what we prescibe.
| 
| 'Recommended packages' was never part of it, yet we have been running 'make;
| make check' since (if memory serves) before the 1.0.0 days.  "It never
| mattered".  Yesterday, it failed. I'll try to try again on the weekend.

Thanks -- looks better again. Now the 'make check' over the included packages
just emits a few NOTE each that other packages needed for crossreference or
checks (such as lattice, MASS, Matrix, ...) are missing (which is expected as
they not part of the Build-Depends as it would create a dependency cycle).

So thumbs up for 3.2.4 next week.

Dirk

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From wilke at austin.utexas.edu  Sun Mar  6 19:34:36 2016
From: wilke at austin.utexas.edu (Wilke, Claus O)
Date: Sun, 6 Mar 2016 18:34:36 +0000
Subject: [Rd] Could unit.list() from grid package be made an exported
	function?
Message-ID: <DE6ECFF5-1424-4039-833D-BE1C4192A558@austin.utexas.edu>

Hello,

certain manipulations of ggplot2 graphs, in particular aligning them, require the function grid:::unit.list(). See e.g. these posts on stackoverflow:
http://stackoverflow.com/questions/34032621/element-replacement-in-grid-unit-vector
http://stackoverflow.com/questions/32580946/setting-absolute-size-of-facets-in-ggplot2/32583612#32583612
http://stackoverflow.com/a/35823179/4975218

Since this seems to be a reasonably common issue, would it be possible to export grid:::unit.list(), so it can be used in packages?

(Am I sending this to the right audience? It?s not clear to me how to reach the maintainer of the grid package in base R.)

Thanks!

Claus

--
Claus Wilke
Professor and Department Chair, Integrative Biology
The University of Texas at Austin
2500 Speedway, A4800
Austin, Texas 78712
512 232 2459


	[[alternative HTML version deleted]]


From jean-externe.maurice at edf.fr  Mon Mar  7 16:45:46 2016
From: jean-externe.maurice at edf.fr (MAURICE Jean - externe)
Date: Mon, 7 Mar 2016 15:45:46 +0000
Subject: [Rd] ALLOCATE in a FORTRAN subroutine
In-Reply-To: <VI1PR05MB153679050141DD2F5DE716E2A1BE0@VI1PR05MB1536.eurprd05.prod.outlook.com>
References: <6c39c4cbb0fb4e6d80fb36ad28b2b89f@NOEINTPEXMU007.NEOPROD.EDF.FR>
	<VI1PR05MB153679050141DD2F5DE716E2A1BE0@VI1PR05MB1536.eurprd05.prod.outlook.com>
Message-ID: <4dd413361f024d3381b387ea2331a007@NOEINTPEXMU007.NEOPROD.EDF.FR>

Hi Martyn,

Many thanks for your answer. If I make it short : 
we can, once we know how to do it, 'drive' R from within FORTRAN for example to do a 
  Myarray = seq(0, mydimension) 
in R once we have compute mydimension in FORTRAN. Is that correct ?
If yes : it's too 'complicated' for the time I am hired (I mean I have been hired to do FORTRAN code not to learn R !).

Second question : for what I have understood in r_exts, it's more 'efficient' to translate R routines in C rather than in FORTRAN (speed must be the 'same', but there are a lot more possibilities in C for the programmer) : right ? I do not know why my customer (client ?) wanted to translate some R routines in FORTRAN. May be it's by accident (in my humble opinion they even don't know about C). If you confirm this fact, I'll speak about C with my customer because we are at the very beginning of great works (great amounts of work ?) and I don't matter, I am also a skilled C programmer !!

I hope you understand what I want to say, english is not my natural language !

Thanks again and best regards.
Jean
-------------- next part --------------



Ce message et toutes les pi?ces jointes (ci-apr?s le 'Message') sont ?tablis ? l'intention exclusive des destinataires et les informations qui y figurent sont strictement confidentielles. Toute utilisation de ce Message non conforme ? sa destination, toute diffusion ou toute publication totale ou partielle, est interdite sauf autorisation expresse.

Si vous n'?tes pas le destinataire de ce Message, il vous est interdit de le copier, de le faire suivre, de le divulguer ou d'en utiliser tout ou partie. Si vous avez re?u ce Message par erreur, merci de le supprimer de votre syst?me, ainsi que toutes ses copies, et de n'en garder aucune trace sur quelque support que ce soit. Nous vous remercions ?galement d'en avertir imm?diatement l'exp?diteur par retour du message.

Il est impossible de garantir que les communications par messagerie ?lectronique arrivent en temps utile, sont s?curis?es ou d?nu?es de toute erreur ou virus.
____________________________________________________

This message and any attachments (the 'Message') are intended solely for the addressees. The information contained in this Message is confidential. Any use of information contained in this Message not in accord with its purpose, any dissemination or disclosure, either whole or partial, is prohibited except formal approval.

If you are not the addressee, you may not copy, forward, disclose or use any part of it. If you have received this message in error, please delete it and all copies from your system and notify the sender immediately by return message.

E-mail communication cannot be guaranteed to be timely secure, error or virus-free.

From maechler at stat.math.ethz.ch  Mon Mar  7 18:26:25 2016
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 7 Mar 2016 18:26:25 +0100
Subject: [Rd] body(NULL) <- something;  ditto formals() -- should not work
Message-ID: <22237.47553.217160.571753@stat.math.ethz.ch>

I'm proposing to signal an error (from R >= 3.3.0) in such
examples -- which do "work" in R 3.2.x and earlier :

> f <- NULL; body(f) <- quote(sin(a+1)); f
function () 
sin(a + 1)
<environment: 0x48f9798>

> g <- NULL; formals(g) <- alist(x = pi, y=); g
function (x = pi, y) 
NULL
<environment: 0x4e6dfe8>
>

The proposal is that the underlying C code will signal an error
when such replacement functions would create a function out of
"something not a function".

Martin Maechler, ETH Zurich


From martyn.byng at nag.co.uk  Mon Mar  7 18:27:45 2016
From: martyn.byng at nag.co.uk (Martyn Byng)
Date: Mon, 7 Mar 2016 17:27:45 +0000
Subject: [Rd] ALLOCATE in a FORTRAN subroutine
In-Reply-To: <4dd413361f024d3381b387ea2331a007@NOEINTPEXMU007.NEOPROD.EDF.FR>
References: <6c39c4cbb0fb4e6d80fb36ad28b2b89f@NOEINTPEXMU007.NEOPROD.EDF.FR>
	<VI1PR05MB153679050141DD2F5DE716E2A1BE0@VI1PR05MB1536.eurprd05.prod.outlook.com>
	<4dd413361f024d3381b387ea2331a007@NOEINTPEXMU007.NEOPROD.EDF.FR>
Message-ID: <VI1PR05MB1536653150889A3C6C8D2E18A1B10@VI1PR05MB1536.eurprd05.prod.outlook.com>

Hi,

"we can, once we know how to do it, 'drive' R from within FORTRAN"
 I am not sure I understand what you mean by this ...

You can call routines written in Fortran or C from within R - how easy this is depends on the interfaces to those routines.
You can call (some) R functionality from C (see for example http://quantitative-ecology.blogspot.co.uk/2008/11/call-c-from-r-and-r-from-c.html). As you can call C from within Fortran, it is obviously possible also call R from within Fortran, but it is not something I have done so have no idea how much work is required to do that.

"for what I have understood in r_exts, it's more 'efficient' to translate R routines in C rather than in FORTRAN"
As far as I aware the R API for writing extensions etc is only available in C and there isn't a Fortran equivalent, so I guess it would be more "efficient" / easier in that sense as that would be one less level of cross-language programming you would have to worry about.

"I do not know why my customer (client ?) wanted to translate some R routines in FORTRAN."
Which language is preferred really boils down to personal preference and I am going to be slightly biased as I do almost all my numerical computing in Fortran. There is a good argument that Fortran is the most natural fit for numerical computing with its built in syntax to deal with complex numbers, matrices, array slicing, array operations  etc. In theory this gives compilers a good base to optimise from. The more restrictive nature of Fortran does make it more difficult to interface with other languages than C (but conversely makes it much more difficult to shoot yourself in the foot - and the Fortran compilers tend to pick up more problems at compile time than the C ones).

Martyn

-----Original Message-----
From: MAURICE Jean - externe [mailto:jean-externe.maurice at edf.fr]
Sent: 07 March 2016 15:46
To: Martyn Byng <martyn.byng at nag.co.uk>
Cc: r-devel at r-project.org
Subject: RE: ALLOCATE in a FORTRAN subroutine

Hi Martyn,

Many thanks for your answer. If I make it short :
we can, once we know how to do it, 'drive' R from within FORTRAN for example to do a
  Myarray = seq(0, mydimension)
in R once we have compute mydimension in FORTRAN. Is that correct ?
If yes : it's too 'complicated' for the time I am hired (I mean I have been hired to do FORTRAN code not to learn R !).

Second question : for what I have understood in r_exts, it's more 'efficient' to translate R routines in C rather than in FORTRAN (speed must be the 'same', but there are a lot more possibilities in C for the programmer) : right ? I do not know why my customer (client ?) wanted to translate some R routines in FORTRAN. May be it's by accident (in my humble opinion they even don't know about C). If you confirm this fact, I'll speak about C with my customer because we are at the very beginning of great works (great amounts of work ?) and I don't matter, I am also a skilled C programmer !!

I hope you understand what I want to say, english is not my natural language !

Thanks again and best regards.
Jean

________________________________________________________________________
This e-mail has been scanned for all viruses by Star.\ _...{{dropped:16}}


From bhh at xs4all.nl  Mon Mar  7 18:55:37 2016
From: bhh at xs4all.nl (Berend Hasselman)
Date: Mon, 7 Mar 2016 18:55:37 +0100
Subject: [Rd] ALLOCATE in a FORTRAN subroutine
In-Reply-To: <4dd413361f024d3381b387ea2331a007@NOEINTPEXMU007.NEOPROD.EDF.FR>
References: <6c39c4cbb0fb4e6d80fb36ad28b2b89f@NOEINTPEXMU007.NEOPROD.EDF.FR>
	<VI1PR05MB153679050141DD2F5DE716E2A1BE0@VI1PR05MB1536.eurprd05.prod.outlook.com>
	<4dd413361f024d3381b387ea2331a007@NOEINTPEXMU007.NEOPROD.EDF.FR>
Message-ID: <59C52CB5-61FA-495B-89AB-411A44F959CA@xs4all.nl>


> On 7 Mar 2016, at 16:45, MAURICE Jean - externe <jean-externe.maurice at edf.fr> wrote:
> 
> Hi Martyn,
> 
> Many thanks for your answer. If I make it short : 
> we can, once we know how to do it, 'drive' R from within FORTRAN for example to do a 
>  Myarray = seq(0, mydimension) 
> in R once we have compute mydimension in FORTRAN. Is that correct ?

I too do not understand what you mean by this.

I told you on the R-help mailing list that what you could do is to 

- write a subroutine that calculates the required dimension given your parameters; you can do this within R code.
- allocate in R (or C) a matrix/vector/.. with the required dimension.
- call your Fortran subroutine(s) with the allocated matrix/vector

There are several packages, as I replied before on the R help list,  that do this (from within an R function or a C function).


Berend

> If yes : it's too 'complicated' for the time I am hired (I mean I have been hired to do FORTRAN code not to learn R !).
> 
> Second question : for what I have understood in r_exts, it's more 'efficient' to translate R routines in C rather than in FORTRAN (speed must be the 'same', but there are a lot more possibilities in C for the programmer) : right ? I do not know why my customer (client ?) wanted to translate some R routines in FORTRAN. May be it's by accident (in my humble opinion they even don't know about C). If you confirm this fact, I'll speak about C with my customer because we are at the very beginning of great works (great amounts of work ?) and I don't matter, I am also a skilled C programmer !!
> 
> I hope you understand what I want to say, english is not my natural language !
> 
> Thanks again and best regards.
> Jean
> 
> 
> 
> Ce message et toutes les pi?ces jointes (ci-apr?s le 'Message') sont ?tablis ? l'intention exclusive des destinataires et les informations qui y figurent sont strictement confidentielles. Toute utilisation de ce Message non conforme ? sa destination, toute diffusion ou toute publication totale ou partielle, est interdite sauf autorisation expresse.
> 
> Si vous n'?tes pas le destinataire de ce Message, il vous est interdit de le copier, de le faire suivre, de le divulguer ou d'en utiliser tout ou partie. Si vous avez re?u ce Message par erreur, merci de le supprimer de votre syst?me, ainsi que toutes ses copies, et de n'en garder aucune trace sur quelque support que ce soit. Nous vous remercions ?galement d'en avertir imm?diatement l'exp?diteur par retour du message.
> 
> Il est impossible de garantir que les communications par messagerie ?lectronique arrivent en temps utile, sont s?curis?es ou d?nu?es de toute erreur ou virus.
> ____________________________________________________
> 
> This message and any attachments (the 'Message') are intended solely for the addressees. The information contained in this Message is confidential. Any use of information contained in this Message not in accord with its purpose, any dissemination or disclosure, either whole or partial, is prohibited except formal approval.
> 
> If you are not the addressee, you may not copy, forward, disclose or use any part of it. If you have received this message in error, please delete it and all copies from your system and notify the sender immediately by return message.
> 
> E-mail communication cannot be guaranteed to be timely secure, error or virus-free.
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From bhh at xs4all.nl  Mon Mar  7 19:43:37 2016
From: bhh at xs4all.nl (Berend Hasselman)
Date: Mon, 7 Mar 2016 19:43:37 +0100
Subject: [Rd] ALLOCATE in a FORTRAN subroutine
In-Reply-To: <59C52CB5-61FA-495B-89AB-411A44F959CA@xs4all.nl>
References: <6c39c4cbb0fb4e6d80fb36ad28b2b89f@NOEINTPEXMU007.NEOPROD.EDF.FR>
	<VI1PR05MB153679050141DD2F5DE716E2A1BE0@VI1PR05MB1536.eurprd05.prod.outlook.com>
	<4dd413361f024d3381b387ea2331a007@NOEINTPEXMU007.NEOPROD.EDF.FR>
	<59C52CB5-61FA-495B-89AB-411A44F959CA@xs4all.nl>
Message-ID: <17E8BAB1-EFAC-4B3A-A2BC-E40A007A9118@xs4all.nl>


> On 7 Mar 2016, at 18:55, Berend Hasselman <bhh at xs4all.nl> wrote:
> 
>> 
>> On 7 Mar 2016, at 16:45, MAURICE Jean - externe <jean-externe.maurice at edf.fr> wrote:
>> 
>> Hi Martyn,
>> 
>> Many thanks for your answer. If I make it short : 
>> we can, once we know how to do it, 'drive' R from within FORTRAN for example to do a 
>> Myarray = seq(0, mydimension) 
>> in R once we have compute mydimension in FORTRAN. Is that correct ?
> 
> I too do not understand what you mean by this.
> 
> I told you on the R-help mailing list that what you could do is to 
> 
> - write a subroutine that calculates the required dimension given your parameters; you can do this within R code.

Correction: write a subroutine in Fortran that calculates the required dimension(s), call that routine from within R and make it return the required dimension(s).

etc.etc.

Berend

> - allocate in R (or C) a matrix/vector/.. with the required dimension.
> - call your Fortran subroutine(s) with the allocated matrix/vector
> 
> There are several packages, as I replied before on the R help list,  that do this (from within an R function or a C function).
> 
> 
> Berend
> 
>> If yes : it's too 'complicated' for the time I am hired (I mean I have been hired to do FORTRAN code not to learn R !).
>> 
>> Second question : for what I have understood in r_exts, it's more 'efficient' to translate R routines in C rather than in FORTRAN (speed must be the 'same', but there are a lot more possibilities in C for the programmer) : right ? I do not know why my customer (client ?) wanted to translate some R routines in FORTRAN. May be it's by accident (in my humble opinion they even don't know about C). If you confirm this fact, I'll speak about C with my customer because we are at the very beginning of great works (great amounts of work ?) and I don't matter, I am also a skilled C programmer !!
>> 
>> I hope you understand what I want to say, english is not my natural language !
>> 
>> Thanks again and best regards.
>> Jean
>> 
>> 
>> 
>> Ce message et toutes les pi?ces jointes (ci-apr?s le 'Message') sont ?tablis ? l'intention exclusive des destinataires et les informations qui y figurent sont strictement confidentielles. Toute utilisation de ce Message non conforme ? sa destination, toute diffusion ou toute publication totale ou partielle, est interdite sauf autorisation expresse.
>> 
>> Si vous n'?tes pas le destinataire de ce Message, il vous est interdit de le copier, de le faire suivre, de le divulguer ou d'en utiliser tout ou partie. Si vous avez re?u ce Message par erreur, merci de le supprimer de votre syst?me, ainsi que toutes ses copies, et de n'en garder aucune trace sur quelque support que ce soit. Nous vous remercions ?galement d'en avertir imm?diatement l'exp?diteur par retour du message.
>> 
>> Il est impossible de garantir que les communications par messagerie ?lectronique arrivent en temps utile, sont s?curis?es ou d?nu?es de toute erreur ou virus.
>> ____________________________________________________
>> 
>> This message and any attachments (the 'Message') are intended solely for the addressees. The information contained in this Message is confidential. Any use of information contained in this Message not in accord with its purpose, any dissemination or disclosure, either whole or partial, is prohibited except formal approval.
>> 
>> If you are not the addressee, you may not copy, forward, disclose or use any part of it. If you have received this message in error, please delete it and all copies from your system and notify the sender immediately by return message.
>> 
>> E-mail communication cannot be guaranteed to be timely secure, error or virus-free.
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From paul at stat.auckland.ac.nz  Mon Mar  7 20:01:07 2016
From: paul at stat.auckland.ac.nz (Paul Murrell)
Date: Tue, 8 Mar 2016 08:01:07 +1300
Subject: [Rd] Could unit.list() from grid package be made an exported
 function?
In-Reply-To: <DE6ECFF5-1424-4039-833D-BE1C4192A558@austin.utexas.edu>
References: <DE6ECFF5-1424-4039-833D-BE1C4192A558@austin.utexas.edu>
Message-ID: <56DDCFF3.9060601@stat.auckland.ac.nz>

Hi

I think the right solution is to add [<- methods for units.
I will take a look at whether I can get that done for the release of R 3.3.0

Paul

On 07/03/16 07:34, Wilke, Claus O wrote:
> Hello,
>
> certain manipulations of ggplot2 graphs, in particular aligning them,
> require the function grid:::unit.list(). See e.g. these posts on
> stackoverflow:
> http://stackoverflow.com/questions/34032621/element-replacement-in-grid-unit-vector
>
>
http://stackoverflow.com/questions/32580946/setting-absolute-size-of-facets-in-ggplot2/32583612#32583612
> http://stackoverflow.com/a/35823179/4975218
>
> Since this seems to be a reasonably common issue, would it be
> possible to export grid:::unit.list(), so it can be used in
> packages?
>
> (Am I sending this to the right audience? It?s not clear to me how to
> reach the maintainer of the grid package in base R.)
>
> Thanks!
>
> Claus
>
> -- Claus Wilke Professor and Department Chair, Integrative Biology
> The University of Texas at Austin 2500 Speedway, A4800 Austin, Texas
> 78712 512 232 2459
>
>
> [[alternative HTML version deleted]]
>
> ______________________________________________ R-devel at r-project.org
> mailing list https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/


From paul at stat.auckland.ac.nz  Mon Mar  7 21:12:08 2016
From: paul at stat.auckland.ac.nz (Paul Murrell)
Date: Tue, 8 Mar 2016 09:12:08 +1300
Subject: [Rd] Could unit.list() from grid package be made an exported
 function?
In-Reply-To: <DE6ECFF5-1424-4039-833D-BE1C4192A558@austin.utexas.edu>
References: <DE6ECFF5-1424-4039-833D-BE1C4192A558@austin.utexas.edu>
Message-ID: <56DDE098.20708@stat.auckland.ac.nz>

Hi

Subassignment for units has been committed to r-devel.
You should now be able to do things like ...

x <- unit(1:3, "mm")
x[2] <- unit(.5, "npc")

(see grid/tests/units.R for more complex examples)

This works for me for the three stackoverflow scenarios.
Any confirmation that it also works for you would be welcome.

Paul

On 07/03/16 07:34, Wilke, Claus O wrote:
> Hello,
>
> certain manipulations of ggplot2 graphs, in particular aligning them,
> require the function grid:::unit.list(). See e.g. these posts on
> stackoverflow:
> http://stackoverflow.com/questions/34032621/element-replacement-in-grid-unit-vector
>
>
http://stackoverflow.com/questions/32580946/setting-absolute-size-of-facets-in-ggplot2/32583612#32583612
> http://stackoverflow.com/a/35823179/4975218
>
> Since this seems to be a reasonably common issue, would it be
> possible to export grid:::unit.list(), so it can be used in
> packages?
>
> (Am I sending this to the right audience? It?s not clear to me how to
> reach the maintainer of the grid package in base R.)
>
> Thanks!
>
> Claus
>
> -- Claus Wilke Professor and Department Chair, Integrative Biology
> The University of Texas at Austin 2500 Speedway, A4800 Austin, Texas
> 78712 512 232 2459
>
>
> [[alternative HTML version deleted]]
>
> ______________________________________________ R-devel at r-project.org
> mailing list https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/


From jean-externe.maurice at edf.fr  Tue Mar  8 12:57:51 2016
From: jean-externe.maurice at edf.fr (MAURICE Jean - externe)
Date: Tue, 8 Mar 2016 11:57:51 +0000
Subject: [Rd] ALLOCATE in a FORTRAN subroutine
In-Reply-To: <VI1PR05MB1536653150889A3C6C8D2E18A1B10@VI1PR05MB1536.eurprd05.prod.outlook.com>
References: <6c39c4cbb0fb4e6d80fb36ad28b2b89f@NOEINTPEXMU007.NEOPROD.EDF.FR>
	<VI1PR05MB153679050141DD2F5DE716E2A1BE0@VI1PR05MB1536.eurprd05.prod.outlook.com>
	<4dd413361f024d3381b387ea2331a007@NOEINTPEXMU007.NEOPROD.EDF.FR>
	<VI1PR05MB1536653150889A3C6C8D2E18A1B10@VI1PR05MB1536.eurprd05.prod.outlook.com>
Message-ID: <f1fc0374ef324178bc80444ac909996a@NOEINTPEXMU007.NEOPROD.EDF.FR>

> You can call (some) R functionality from C
When I read about 'R api' I thought that we could call all the functionality of R. I think that in the windows world, this is called OLE automation. From a pure programmer point of view, it is very convenient and my customer is creating a team of programmers. But, if only 'some' functionalities can be called, it's not so useful. So we'll stick with FORTRAN (I mean I don't want to make revolution).

Jean
-------------- next part --------------



Ce message et toutes les pi?ces jointes (ci-apr?s le 'Message') sont ?tablis ? l'intention exclusive des destinataires et les informations qui y figurent sont strictement confidentielles. Toute utilisation de ce Message non conforme ? sa destination, toute diffusion ou toute publication totale ou partielle, est interdite sauf autorisation expresse.

Si vous n'?tes pas le destinataire de ce Message, il vous est interdit de le copier, de le faire suivre, de le divulguer ou d'en utiliser tout ou partie. Si vous avez re?u ce Message par erreur, merci de le supprimer de votre syst?me, ainsi que toutes ses copies, et de n'en garder aucune trace sur quelque support que ce soit. Nous vous remercions ?galement d'en avertir imm?diatement l'exp?diteur par retour du message.

Il est impossible de garantir que les communications par messagerie ?lectronique arrivent en temps utile, sont s?curis?es ou d?nu?es de toute erreur ou virus.
____________________________________________________

This message and any attachments (the 'Message') are intended solely for the addressees. The information contained in this Message is confidential. Any use of information contained in this Message not in accord with its purpose, any dissemination or disclosure, either whole or partial, is prohibited except formal approval.

If you are not the addressee, you may not copy, forward, disclose or use any part of it. If you have received this message in error, please delete it and all copies from your system and notify the sender immediately by return message.

E-mail communication cannot be guaranteed to be timely secure, error or virus-free.

From simon.urbanek at r-project.org  Tue Mar  8 15:24:16 2016
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Tue, 8 Mar 2016 09:24:16 -0500
Subject: [Rd] ALLOCATE in a FORTRAN subroutine
In-Reply-To: <f1fc0374ef324178bc80444ac909996a@NOEINTPEXMU007.NEOPROD.EDF.FR>
References: <6c39c4cbb0fb4e6d80fb36ad28b2b89f@NOEINTPEXMU007.NEOPROD.EDF.FR>
	<VI1PR05MB153679050141DD2F5DE716E2A1BE0@VI1PR05MB1536.eurprd05.prod.outlook.com>
	<4dd413361f024d3381b387ea2331a007@NOEINTPEXMU007.NEOPROD.EDF.FR>
	<VI1PR05MB1536653150889A3C6C8D2E18A1B10@VI1PR05MB1536.eurprd05.prod.outlook.com>
	<f1fc0374ef324178bc80444ac909996a@NOEINTPEXMU007.NEOPROD.EDF.FR>
Message-ID: <9B5870DC-5F65-4F2A-B35E-109F2B7B6851@r-project.org>


On Mar 8, 2016, at 6:57 AM, MAURICE Jean - externe <jean-externe.maurice at edf.fr> wrote:

>> You can call (some) R functionality from C
> When I read about 'R api' I thought that we could call all the functionality of R. I think that in the windows world, this is called OLE automation. From a pure programmer point of view, it is very convenient and my customer is creating a team of programmers. But, if only 'some' functionalities can be called, it's not so useful. So we'll stick with FORTRAN (I mean I don't want to make revolution).
> 

You can call *all* R functionality from C.
FWIW it's not related to OLE which is IPC and much more limited. The R API is direct linking and uses the same code as R implementation itself.

Cheers,
S



> Jean
> 
> 
> 
> Ce message et toutes les pi?ces jointes (ci-apr?s le 'Message') sont ?tablis ? l'intention exclusive des destinataires et les informations qui y figurent sont strictement confidentielles. Toute utilisation de ce Message non conforme ? sa destination, toute diffusion ou toute publication totale ou partielle, est interdite sauf autorisation expresse.
> 
> Si vous n'?tes pas le destinataire de ce Message, il vous est interdit de le copier, de le faire suivre, de le divulguer ou d'en utiliser tout ou partie. Si vous avez re?u ce Message par erreur, merci de le supprimer de votre syst?me, ainsi que toutes ses copies, et de n'en garder aucune trace sur quelque support que ce soit. Nous vous remercions ?galement d'en avertir imm?diatement l'exp?diteur par retour du message.
> 
> Il est impossible de garantir que les communications par messagerie ?lectronique arrivent en temps utile, sont s?curis?es ou d?nu?es de toute erreur ou virus.
> ____________________________________________________
> 
> This message and any attachments (the 'Message') are intended solely for the addressees. The information contained in this Message is confidential. Any use of information contained in this Message not in accord with its purpose, any dissemination or disclosure, either whole or partial, is prohibited except formal approval.
> 
> If you are not the addressee, you may not copy, forward, disclose or use any part of it. If you have received this message in error, please delete it and all copies from your system and notify the sender immediately by return message.
> 
> E-mail communication cannot be guaranteed to be timely secure, error or virus-free.
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From jean-externe.maurice at edf.fr  Tue Mar  8 15:39:03 2016
From: jean-externe.maurice at edf.fr (MAURICE Jean - externe)
Date: Tue, 8 Mar 2016 14:39:03 +0000
Subject: [Rd] ALLOCATE in a FORTRAN subroutine
In-Reply-To: <9B5870DC-5F65-4F2A-B35E-109F2B7B6851@r-project.org>
References: <6c39c4cbb0fb4e6d80fb36ad28b2b89f@NOEINTPEXMU007.NEOPROD.EDF.FR>
	<VI1PR05MB153679050141DD2F5DE716E2A1BE0@VI1PR05MB1536.eurprd05.prod.outlook.com>
	<4dd413361f024d3381b387ea2331a007@NOEINTPEXMU007.NEOPROD.EDF.FR>
	<VI1PR05MB1536653150889A3C6C8D2E18A1B10@VI1PR05MB1536.eurprd05.prod.outlook.com>
	<f1fc0374ef324178bc80444ac909996a@NOEINTPEXMU007.NEOPROD.EDF.FR>
	<9B5870DC-5F65-4F2A-B35E-109F2B7B6851@r-project.org>
Message-ID: <3a264b597c634a239745cbdbeaff8eea@NOEINTPEXMU007.NEOPROD.EDF.FR>

>> You can call (some) R functionality from C
> You can call *all* R functionality from C.
I'll dig that (I mean I'll read more in the help to be sure)

> FWIW it's not related to OLE which is IPC and much more limited
It was an example of what I was trying to say with "driving R from within FORTRAN". I have done a lot of Word Automation, Excel Automation and even Open Office 'automation' working with Visual Foxpro. I am 'easy' with that.

Thank you a lot for your interest.
Jean
-------------- next part --------------



Ce message et toutes les pi?ces jointes (ci-apr?s le 'Message') sont ?tablis ? l'intention exclusive des destinataires et les informations qui y figurent sont strictement confidentielles. Toute utilisation de ce Message non conforme ? sa destination, toute diffusion ou toute publication totale ou partielle, est interdite sauf autorisation expresse.

Si vous n'?tes pas le destinataire de ce Message, il vous est interdit de le copier, de le faire suivre, de le divulguer ou d'en utiliser tout ou partie. Si vous avez re?u ce Message par erreur, merci de le supprimer de votre syst?me, ainsi que toutes ses copies, et de n'en garder aucune trace sur quelque support que ce soit. Nous vous remercions ?galement d'en avertir imm?diatement l'exp?diteur par retour du message.

Il est impossible de garantir que les communications par messagerie ?lectronique arrivent en temps utile, sont s?curis?es ou d?nu?es de toute erreur ou virus.
____________________________________________________

This message and any attachments (the 'Message') are intended solely for the addressees. The information contained in this Message is confidential. Any use of information contained in this Message not in accord with its purpose, any dissemination or disclosure, either whole or partial, is prohibited except formal approval.

If you are not the addressee, you may not copy, forward, disclose or use any part of it. If you have received this message in error, please delete it and all copies from your system and notify the sender immediately by return message.

E-mail communication cannot be guaranteed to be timely secure, error or virus-free.

From wilke at austin.utexas.edu  Tue Mar  8 21:54:48 2016
From: wilke at austin.utexas.edu (Wilke, Claus O)
Date: Tue, 8 Mar 2016 20:54:48 +0000
Subject: [Rd] Could unit.list() from grid package be made an exported
 function?
In-Reply-To: <56DDE098.20708@stat.auckland.ac.nz>
References: <DE6ECFF5-1424-4039-833D-BE1C4192A558@austin.utexas.edu>
	<56DDE098.20708@stat.auckland.ac.nz>
Message-ID: <D7E599B9-ADAC-459D-B561-6A268E5A57CF@austin.utexas.edu>

Paul,

Subassignment for units has been committed to r-devel.
You should now be able to do things like ...

x <- unit(1:3, "mm")
x[2] <- unit(.5, "npc")

(see grid/tests/units.R for more complex examples)

Yes, I just tried the latest R devel and it works for me. However:

This works for me for the three stackoverflow scenarios.

I ran into an additional problem when trying to replicate this example:
http://stackoverflow.com/a/32583612/4975218

This line in the function set_panel_size() causes an error for me:
g$widths[panel_index_w] <-  rep(list(width), nw)

Error in `[<-.unit`(`*tmp*`, panel_index_w, value = list(4, 4, 4)) :
  Value being assigned must be a unit

I can avoid the error by changing the line into:
g$widths[panel_index_w] <-  rep(grid:::unit.list(width), nw)

This, however, again uses grid:::unit.list(). Maybe there?s another way around this, but turning a single width value into a unit.list seems the obvious way to go in a case like this. So again, I?d like to request that grid:::unit.list() be made an exported function as well. It seems quite useful any time somebody wants to make a list of units.

Thanks!

Claus

--
Claus Wilke
Professor and Department Chair, Integrative Biology
The University of Texas at Austin
2500 Speedway, A4800
Austin, Texas 78712
512 232 2459


	[[alternative HTML version deleted]]


From paul at stat.auckland.ac.nz  Tue Mar  8 22:38:24 2016
From: paul at stat.auckland.ac.nz (Paul Murrell)
Date: Wed, 9 Mar 2016 10:38:24 +1300
Subject: [Rd] Could unit.list() from grid package be made an exported
 function?
In-Reply-To: <D7E599B9-ADAC-459D-B561-6A268E5A57CF@austin.utexas.edu>
References: <DE6ECFF5-1424-4039-833D-BE1C4192A558@austin.utexas.edu>
	<56DDE098.20708@stat.auckland.ac.nz>
	<D7E599B9-ADAC-459D-B561-6A268E5A57CF@austin.utexas.edu>
Message-ID: <56DF4650.7030804@stat.auckland.ac.nz>

Hi

On 09/03/16 09:54, Wilke, Claus O wrote:
> Paul,
>
>> Subassignment for units has been committed to r-devel.
>> You should now be able to do things like ...
>>
>> x <- unit(1:3, "mm")
>> x[2] <- unit(.5, "npc")
>>
>> (see grid/tests/units.R for more complex examples)
>
> Yes, I just tried the latest R devel and it works for me. However:

Great.  Thanks for testing it out.

>> This works for me for the three stackoverflow scenarios.
>
> I ran into an additional problem when trying to replicate this example:
> http://stackoverflow.com/a/32583612/4975218
>
> This line in the function set_panel_size() causes an error for me:
> g$widths[panel_index_w] <-  rep(list(width), nw)
>
> Error in `[<-.unit`(`*tmp*`, panel_index_w, value = list(4, 4, 4)) :
>    Value being assigned must be a unit

Right, that line (and the one below) can now just use rep() on a unit 
(no need for lists anymore), like this ...

g$widths[panel_index_w] <-  rep(width, nw)

(full example code attached)

Paul

> I can avoid the error by changing the line into:
> g$widths[panel_index_w] <-  rep(grid:::unit.list(width), nw)
>
> This, however, again uses grid:::unit.list(). Maybe there?s another way
> around this, but turning a single width value into a unit.list seems the
> obvious way to go in a case like this. So again, I?d like to request
> that grid:::unit.list() be made an exported function as well. It seems
> quite useful any time somebody wants to make a list of units.
>
> Thanks!
>
> Claus
>
> --
> Claus Wilke
> Professor and Department Chair, Integrative Biology
> The University of Texas at Austin
> 2500 Speedway, A4800
> Austin, Texas 78712
> 512 232 2459
>

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/

From M.van_Iterson at lumc.nl  Thu Mar 10 12:47:07 2016
From: M.van_Iterson at lumc.nl (M.van_Iterson at lumc.nl)
Date: Thu, 10 Mar 2016 11:47:07 +0000
Subject: [Rd] rmultinom.c error probability not sum to 1
Message-ID: <6C970093269C804E91E22510E87295281C3A448C@MAIL-MB01.lumcnet.prod.intern>

Dear all,

I have a questions regarding using the c function rmultinom.c.

I got the following error message "rbinom: probability sum should be 1, but is 0.999264"

Which is thrown by:

if(fabs((double)(p_tot - 1.)) > 1e-7)
 MATHLIB_ERROR(_("rbinom: probability sum should be 1, but is %g"),
 (double) p_tot);

I understand my probabilities do not sum to one close enough. I tried the following,
p[2] = 1. - p[0] - p[1],  where 'p', are the probabilities but this is not sufficient to pass the error message!

Thanks in advance!

Regards,
Maarten

(I don't think this is an issue with versions but I used R version 3.2.3 and can provide more details on my linux build if necessary.)



	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Thu Mar 10 13:26:09 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 10 Mar 2016 13:26:09 +0100
Subject: [Rd] rmultinom.c error probability not sum to 1
In-Reply-To: <6C970093269C804E91E22510E87295281C3A448C@MAIL-MB01.lumcnet.prod.intern>
References: <6C970093269C804E91E22510E87295281C3A448C@MAIL-MB01.lumcnet.prod.intern>
Message-ID: <AD6651EC-AA5B-4EFA-8EA1-54170F809F1A@gmail.com>


On 10 Mar 2016, at 12:47 , M.van_Iterson at lumc.nl wrote:

> Dear all,
> 
> I have a questions regarding using the c function rmultinom.c.
> 
> I got the following error message "rbinom: probability sum should be 1, but is 0.999264"
> 
> Which is thrown by:
> 
> if(fabs((double)(p_tot - 1.)) > 1e-7)
> MATHLIB_ERROR(_("rbinom: probability sum should be 1, but is %g"),
> (double) p_tot);
> 
> I understand my probabilities do not sum to one close enough. I tried the following,
> p[2] = 1. - p[0] - p[1],  where 'p', are the probabilities but this is not sufficient to pass the error message!
> 


p[0] ????


> Thanks in advance!
> 
> Regards,
> Maarten
> 
> (I don't think this is an issue with versions but I used R version 3.2.3 and can provide more details on my linux build if necessary.)
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From kirill.mueller at ivt.baug.ethz.ch  Thu Mar 10 14:27:53 2016
From: kirill.mueller at ivt.baug.ethz.ch (=?UTF-8?Q?Kirill_M=c3=bcller?=)
Date: Thu, 10 Mar 2016 14:27:53 +0100
Subject: [Rd] getParseData() for installed packages
Message-ID: <56E17659.7010904@ivt.baug.ethz.ch>

I can't seem to reliably obtain parse data via getParseData() for 
functions from installed packages. The parse data seems to be available 
only for the *last* file in the package.

See [1] for a small example package with just two functions f and g in 
two files a.R and b.R. See [2] for a documented test run on installed 
package (Ubuntu 15.10, UTF-8 locale, R 3.2.3). Same behavior with 
r-devel (r70303).

The parse data helps reliable coverage analysis [3]. Please advise.


Best regards

Kirill


[1] https://github.com/krlmlr/covr.dummy
[2] http://rpubs.com/krlmlr/getParseData
[3] https://github.com/jimhester/covr/pull/154


From murdoch.duncan at gmail.com  Thu Mar 10 15:49:36 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 10 Mar 2016 09:49:36 -0500
Subject: [Rd] getParseData() for installed packages
In-Reply-To: <56E17659.7010904@ivt.baug.ethz.ch>
References: <56E17659.7010904@ivt.baug.ethz.ch>
Message-ID: <56E18980.3000301@gmail.com>

On 10/03/2016 8:27 AM, Kirill M?ller wrote:
> I can't seem to reliably obtain parse data via getParseData() for
> functions from installed packages. The parse data seems to be available
> only for the *last* file in the package.
>
> See [1] for a small example package with just two functions f and g in
> two files a.R and b.R. See [2] for a documented test run on installed
> package (Ubuntu 15.10, UTF-8 locale, R 3.2.3). Same behavior with
> r-devel (r70303).
>
> The parse data helps reliable coverage analysis [3]. Please advise.

You don't say how you built the package.  Parse data is omitted by default.

Duncan Murdoch
>
> Best regards
>
> Kirill
>
>
> [1] https://github.com/krlmlr/covr.dummy
> [2] http://rpubs.com/krlmlr/getParseData
> [3] https://github.com/jimhester/covr/pull/154
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From kirill.mueller at ivt.baug.ethz.ch  Thu Mar 10 15:53:17 2016
From: kirill.mueller at ivt.baug.ethz.ch (=?UTF-8?Q?Kirill_M=c3=bcller?=)
Date: Thu, 10 Mar 2016 15:53:17 +0100
Subject: [Rd] getParseData() for installed packages
In-Reply-To: <56E18980.3000301@gmail.com>
References: <56E17659.7010904@ivt.baug.ethz.ch> <56E18980.3000301@gmail.com>
Message-ID: <56E18A5D.9050807@ivt.baug.ethz.ch>



On 10.03.2016 15:49, Duncan Murdoch wrote:
> On 10/03/2016 8:27 AM, Kirill M?ller wrote:
>> I can't seem to reliably obtain parse data via getParseData() for
>> functions from installed packages. The parse data seems to be available
>> only for the *last* file in the package.
>>
>> See [1] for a small example package with just two functions f and g in
>> two files a.R and b.R. See [2] for a documented test run on installed
>> package (Ubuntu 15.10, UTF-8 locale, R 3.2.3). Same behavior with
>> r-devel (r70303).
>>
>> The parse data helps reliable coverage analysis [3]. Please advise.
>
> You don't say how you built the package.  Parse data is omitted by 
> default.
>
> Duncan Murdoch

I install using R CMD INSTALL ., and I have options(keep.source = TRUE, 
keep.source.pkgs = TRUE) in my .Rprofile . The srcrefs are all there, 
it's just that the parse data is not where I'd expect it to be.


-Kirill

>>
>> Best regards
>>
>> Kirill
>>
>>
>> [1] https://github.com/krlmlr/covr.dummy
>> [2] http://rpubs.com/krlmlr/getParseData
>> [3] https://github.com/jimhester/covr/pull/154
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From murdoch.duncan at gmail.com  Thu Mar 10 16:05:24 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 10 Mar 2016 10:05:24 -0500
Subject: [Rd] getParseData() for installed packages
In-Reply-To: <56E18A5D.9050807@ivt.baug.ethz.ch>
References: <56E17659.7010904@ivt.baug.ethz.ch> <56E18980.3000301@gmail.com>
	<56E18A5D.9050807@ivt.baug.ethz.ch>
Message-ID: <56E18D34.7030401@gmail.com>

On 10/03/2016 9:53 AM, Kirill M?ller wrote:
>
> On 10.03.2016 15:49, Duncan Murdoch wrote:
> > On 10/03/2016 8:27 AM, Kirill M?ller wrote:
> >> I can't seem to reliably obtain parse data via getParseData() for
> >> functions from installed packages. The parse data seems to be available
> >> only for the *last* file in the package.
> >>
> >> See [1] for a small example package with just two functions f and g in
> >> two files a.R and b.R. See [2] for a documented test run on installed
> >> package (Ubuntu 15.10, UTF-8 locale, R 3.2.3). Same behavior with
> >> r-devel (r70303).
> >>
> >> The parse data helps reliable coverage analysis [3]. Please advise.
> >
> > You don't say how you built the package.  Parse data is omitted by
> > default.
> >
> > Duncan Murdoch
>
> I install using R CMD INSTALL ., and I have options(keep.source = TRUE,
> keep.source.pkgs = TRUE) in my .Rprofile . The srcrefs are all there,
> it's just that the parse data is not where I'd expect it to be.
>

Okay, I see what you describe.  I'm not going to have time to track this 
down for a while, so I'm going to post your message as a bug report, and 
hopefully will be able to get to it before 3.3.0.

Duncan Murdoch


From kirill.mueller at ivt.baug.ethz.ch  Thu Mar 10 16:36:47 2016
From: kirill.mueller at ivt.baug.ethz.ch (=?UTF-8?Q?Kirill_M=c3=bcller?=)
Date: Thu, 10 Mar 2016 16:36:47 +0100
Subject: [Rd] getParseData() for installed packages
In-Reply-To: <56E18D34.7030401@gmail.com>
References: <56E17659.7010904@ivt.baug.ethz.ch> <56E18980.3000301@gmail.com>
	<56E18A5D.9050807@ivt.baug.ethz.ch> <56E18D34.7030401@gmail.com>
Message-ID: <56E1948F.6080503@ivt.baug.ethz.ch>

On 10.03.2016 16:05, Duncan Murdoch wrote:
> On 10/03/2016 9:53 AM, Kirill M?ller wrote:
>>
>> On 10.03.2016 15:49, Duncan Murdoch wrote:
>>
>>
>> I install using R CMD INSTALL ., and I have options(keep.source = TRUE,
>> keep.source.pkgs = TRUE) in my .Rprofile . The srcrefs are all there,
>> it's just that the parse data is not where I'd expect it to be.
>>
>
> Okay, I see what you describe.  I'm not going to have time to track 
> this down for a while, so I'm going to post your message as a bug 
> report, and hopefully will be able to get to it before 3.3.0.
>
Thanks. A related note: Would it be possible to make available all of 
first_byte/last_byte/first_column/last_column in the parse data, for 
easier srcref reconstruction?


-Kirill


From mick.jordan at oracle.com  Thu Mar 10 17:51:23 2016
From: mick.jordan at oracle.com (Mick Jordan)
Date: Thu, 10 Mar 2016 08:51:23 -0800
Subject: [Rd] Problem building R-3.2.4
Message-ID: <56E1A60B.6060701@oracle.com>

I am trying to build R-3.2.4 on an Oracle Enterprise Linux system, where 
I have previously built R-3.1.3 and predecessors without problems. I ran 
"./configure --with-x=no" ok. The make fails in src/extra/xz with what 
looks like a Makefile problem:

liblzma.a: $(liblzma_a_OBJECTS)
     $rm -f $@
     $(AR) -cr $@ $(liblzma_a_OBJECTS)
     $(RANLIB) $@


What I see in the make log is:

gcc -std=gnu99 -I./api -I. -I../../../src/include -I../../../src/include 
-I/usr/local/include -DHAVE_CONFIG_H -fopenmp  -g -O2  -c x86.c -o x86.o
m -f liblzma.a
make[4]: m: Command not found
make[4]: *** [liblzma.a] Error 127
make[4]: Leaving directory `/tmp/R-3.2.4/src/extra/xz'
make[3]: *** [R] Error 2
make[3]: Leaving directory `/tmp/R-3.2.4/src/extra/xz'
make[2]: *** [make.xz] Error 2
make[2]: Leaving directory `/tmp/R-3.2.4/src/extra'
make[1]: *** [R] Error 1
make[1]: Leaving directory `/tmp/R-3.2.4/src'
make: *** [R] Error 1

I'm very suspicious of the "$rm -f @a" line, which also appears in the 
Makefile.in. Seems like $r has resolved to empty leading to the command 
"m -f liblzma.a"

Mick Jordan


From plummerm at iarc.fr  Thu Mar 10 18:20:38 2016
From: plummerm at iarc.fr (Martyn Plummer)
Date: Thu, 10 Mar 2016 17:20:38 +0000
Subject: [Rd] Problem building R-3.2.4
In-Reply-To: <56E1A60B.6060701@oracle.com>
References: <56E1A60B.6060701@oracle.com>
Message-ID: <1457630437.2599.197.camel@iarc.fr>

This was reported as a bug earlier today and has been fixed in R-
patched:

https://bugs.r-project.org/bugzilla/show_bug.cgi?id=16755

Martyn

On Thu, 2016-03-10 at 08:51 -0800, Mick Jordan wrote:
> I am trying to build R-3.2.4 on an Oracle Enterprise Linux system,
> where?
> I have previously built R-3.1.3 and predecessors without problems. I
> ran?
> "./configure --with-x=no" ok. The make fails in src/extra/xz with
> what?
> looks like a Makefile problem:
> 
> liblzma.a: $(liblzma_a_OBJECTS)
> ?????$rm -f $@
> ?????$(AR) -cr $@ $(liblzma_a_OBJECTS)
> ?????$(RANLIB) $@
> 
> 
> What I see in the make log is:
> 
> gcc -std=gnu99 -I./api -I. -I../../../src/include
> -I../../../src/include?
> -I/usr/local/include -DHAVE_CONFIG_H -fopenmp??-g -O2??-c x86.c -o
> x86.o
> m -f liblzma.a
> make[4]: m: Command not found
> make[4]: *** [liblzma.a] Error 127
> make[4]: Leaving directory `/tmp/R-3.2.4/src/extra/xz'
> make[3]: *** [R] Error 2
> make[3]: Leaving directory `/tmp/R-3.2.4/src/extra/xz'
> make[2]: *** [make.xz] Error 2
> make[2]: Leaving directory `/tmp/R-3.2.4/src/extra'
> make[1]: *** [R] Error 1
> make[1]: Leaving directory `/tmp/R-3.2.4/src'
> make: *** [R] Error 1
> 
> I'm very suspicious of the "$rm -f @a" line, which also appears in
> the?
> Makefile.in. Seems like $r has resolved to empty leading to the
> command?
> "m -f liblzma.a"
> 
> Mick Jordan
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel-----------------------------------------------------------------------
This message and its attachments are strictly confidenti...{{dropped:8}}


From pdalgd at gmail.com  Thu Mar 10 18:22:21 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 10 Mar 2016 18:22:21 +0100
Subject: [Rd] Problem building R-3.2.4
In-Reply-To: <56E1A60B.6060701@oracle.com>
References: <56E1A60B.6060701@oracle.com>
Message-ID: <15988E00-52DA-4579-9E52-8BD1B78805FF@gmail.com>

Yes, this is fixed in R-patched, but you can just change the $ to @ which is what was intended.

You could also install a system-wide version of the library. Notice that in 3.3.x, the included xz & al. will disappear.

-pd

> On 10 Mar 2016, at 17:51 , Mick Jordan <mick.jordan at oracle.com> wrote:
> 
> I am trying to build R-3.2.4 on an Oracle Enterprise Linux system, where I have previously built R-3.1.3 and predecessors without problems. I ran "./configure --with-x=no" ok. The make fails in src/extra/xz with what looks like a Makefile problem:
> 
> liblzma.a: $(liblzma_a_OBJECTS)
>    $rm -f $@
>    $(AR) -cr $@ $(liblzma_a_OBJECTS)
>    $(RANLIB) $@
> 
> 
> What I see in the make log is:
> 
> gcc -std=gnu99 -I./api -I. -I../../../src/include -I../../../src/include -I/usr/local/include -DHAVE_CONFIG_H -fopenmp  -g -O2  -c x86.c -o x86.o
> m -f liblzma.a
> make[4]: m: Command not found
> make[4]: *** [liblzma.a] Error 127
> make[4]: Leaving directory `/tmp/R-3.2.4/src/extra/xz'
> make[3]: *** [R] Error 2
> make[3]: Leaving directory `/tmp/R-3.2.4/src/extra/xz'
> make[2]: *** [make.xz] Error 2
> make[2]: Leaving directory `/tmp/R-3.2.4/src/extra'
> make[1]: *** [R] Error 1
> make[1]: Leaving directory `/tmp/R-3.2.4/src'
> make: *** [R] Error 1
> 
> I'm very suspicious of the "$rm -f @a" line, which also appears in the Makefile.in. Seems like $r has resolved to empty leading to the command "m -f liblzma.a"
> 
> Mick Jordan
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From edd at debian.org  Thu Mar 10 18:22:30 2016
From: edd at debian.org (Dirk Eddelbuettel)
Date: Thu, 10 Mar 2016 11:22:30 -0600
Subject: [Rd] Problem building R-3.2.4
In-Reply-To: <56E1A60B.6060701@oracle.com>
References: <56E1A60B.6060701@oracle.com>
Message-ID: <22241.44374.630560.420218@max.nulle.part>


On 10 March 2016 at 08:51, Mick Jordan wrote:
| I am trying to build R-3.2.4 on an Oracle Enterprise Linux system, where 
| I have previously built R-3.1.3 and predecessors without problems. I ran 

Well that is pretty much why R Core asks us to build early, and build often.

| "./configure --with-x=no" ok. The make fails in src/extra/xz with what 
| looks like a Makefile problem:
| 
| liblzma.a: $(liblzma_a_OBJECTS)
|      $rm -f $@
|      $(AR) -cr $@ $(liblzma_a_OBJECTS)
|      $(RANLIB) $@
| 
| 
| What I see in the make log is:
| 
| gcc -std=gnu99 -I./api -I. -I../../../src/include -I../../../src/include 
| -I/usr/local/include -DHAVE_CONFIG_H -fopenmp  -g -O2  -c x86.c -o x86.o
| m -f liblzma.a
| make[4]: m: Command not found
| make[4]: *** [liblzma.a] Error 127
| make[4]: Leaving directory `/tmp/R-3.2.4/src/extra/xz'
| make[3]: *** [R] Error 2
| make[3]: Leaving directory `/tmp/R-3.2.4/src/extra/xz'
| make[2]: *** [make.xz] Error 2
| make[2]: Leaving directory `/tmp/R-3.2.4/src/extra'
| make[1]: *** [R] Error 1
| make[1]: Leaving directory `/tmp/R-3.2.4/src'
| make: *** [R] Error 1
| 
| I'm very suspicious of the "$rm -f @a" line, which also appears in the 
| Makefile.in. Seems like $r has resolved to empty leading to the command 
| "m -f liblzma.a"

The same issue was already reported (and resolved) in the bug tracker earlier
today.  All this is due to 'most systems' using their system lzma (so the
issue was not tickled in eg all the Debian and Ubuntu builds we do) but you
here do not -- and hence got bitten by a Makefile typo.

Just fix it locally to

      @rm -f $@

or use a system lzma.  More details at 

   https://bugs.r-project.org/bugzilla/show_bug.cgi?id=16755

Dirk

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From mick.jordan at oracle.com  Thu Mar 10 18:35:35 2016
From: mick.jordan at oracle.com (Mick Jordan)
Date: Thu, 10 Mar 2016 09:35:35 -0800
Subject: [Rd] Problem building R-3.2.4
In-Reply-To: <22241.44374.630560.420218@max.nulle.part>
References: <56E1A60B.6060701@oracle.com>
	<22241.44374.630560.420218@max.nulle.part>
Message-ID: <56E1B067.6020209@oracle.com>

On 3/10/16 9:22 AM, Dirk Eddelbuettel wrote:
>
>
> The same issue was already reported (and resolved) in the bug tracker earlier
> today.  All this is due to 'most systems' using their system lzma (so the
> issue was not tickled in eg all the Debian and Ubuntu builds we do) but you
> here do not -- and hence got bitten by a Makefile typo.
>
> Just fix it locally to
>
>        @rm -f $@
>
> or use a system lzma.  More details at
>
>     https://bugs.r-project.org/bugzilla/show_bug.cgi?id=16755
>
>
Thx. I made that change optimistically and it worked. Aren't thsee 
multiple Linux platforms a pain.

BTW, Firefox claimed that the bugzilla URL was insecure:

The owner of bugs.r-project.org has configured their website improperly. 
To protect your information from being stolen, Firefox has not connected 
to this website.


From murdoch.duncan at gmail.com  Thu Mar 10 18:38:07 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 10 Mar 2016 12:38:07 -0500
Subject: [Rd] Problem building R-3.2.4
In-Reply-To: <56E1B067.6020209@oracle.com>
References: <56E1A60B.6060701@oracle.com>
	<22241.44374.630560.420218@max.nulle.part>
	<56E1B067.6020209@oracle.com>
Message-ID: <56E1B0FF.6060306@gmail.com>

On 10/03/2016 12:35 PM, Mick Jordan wrote:
> On 3/10/16 9:22 AM, Dirk Eddelbuettel wrote:
> >
> >
> > The same issue was already reported (and resolved) in the bug tracker earlier
> > today.  All this is due to 'most systems' using their system lzma (so the
> > issue was not tickled in eg all the Debian and Ubuntu builds we do) but you
> > here do not -- and hence got bitten by a Makefile typo.
> >
> > Just fix it locally to
> >
> >        @rm -f $@
> >
> > or use a system lzma.  More details at
> >
> >     https://bugs.r-project.org/bugzilla/show_bug.cgi?id=16755
> >
> >
> Thx. I made that change optimistically and it worked. Aren't thsee
> multiple Linux platforms a pain.
>
> BTW, Firefox claimed that the bugzilla URL was insecure:
>
> The owner of bugs.r-project.org has configured their website improperly.
> To protect your information from being stolen, Firefox has not connected
> to this website.

Yes, the certificate expired today.

Duncan Murdoch


From jeroen.ooms at stat.ucla.edu  Thu Mar 10 21:07:49 2016
From: jeroen.ooms at stat.ucla.edu (Jeroen Ooms)
Date: Thu, 10 Mar 2016 21:07:49 +0100
Subject: [Rd] checking https certificates
Message-ID: <CABFfbXs5v9ieVwzn+pa985ViTYqaGKTwi+m1C0BVoxu9O9kPyA@mail.gmail.com>

It looks like the https certificate on r-project.org is currently
expired. I am sure sysadmin in Vienna is on it, but perhaps we can
prevent this from happening again by adding a check in R or the mirror
report [1] to warn about mirrors with https certs that are about to
expire:

  library(openssl)
  certs <- download_ssl_cert("r-project.org")
  cert_verify(certs)
  # Error in cert_verify_cert(cert[[1]], cert[-1], root) :
  #   Certificate validation failed: certificate has expired
  as.list(certs[[1]])$validity
  # [1] "Mar 10 17:14:13 2014 GMT" "Mar 10 17:14:13 2016 GMT"

PS: the cert that is deployed on r-forge.r-project.org is valid for
*.r-project.org and is valid until 2018 so that should make an easy
fix:

  cert <- download_ssl_cert("r-forge.r-project.org")
  cert_verify(cert)
  as.list(cert[[1]])


[1] https://cran.rstudio.com/mirmon_report.html


From M.van_Iterson at lumc.nl  Thu Mar 10 21:25:20 2016
From: M.van_Iterson at lumc.nl (M.van_Iterson at lumc.nl)
Date: Thu, 10 Mar 2016 20:25:20 +0000
Subject: [Rd] rmultinom.c error probability not sum to 1
In-Reply-To: <AD6651EC-AA5B-4EFA-8EA1-54170F809F1A@gmail.com>
References: <6C970093269C804E91E22510E87295281C3A448C@MAIL-MB01.lumcnet.prod.intern>,
	<AD6651EC-AA5B-4EFA-8EA1-54170F809F1A@gmail.com>
Message-ID: <6C970093269C804E91E22510E87295281C3A4619@MAIL-MB01.lumcnet.prod.intern>

Hi all, 

I should have given a better explanation of my problem. Here it is.

I extracted from my code the bit that gives the error. Place this in a file called test.c

#include <math.h>
#include <R.h>
#include <Rmath.h>
#include <float.h>
#include <R_ext/Print.h>

int main(){

  double prob[3] = {0.0, 0.0, 0.0};
  double prob_tot = 0.;

  prob[0] = 0.3*dnorm(2, 0, 1, 0);
  prob[1] = 0.5*dnorm(5, 0, 1, 0);
  prob[2] = 0.2*dnorm(-3, 0, 1, 0);

  //obtain prob_tot
  prob_tot = 0.;
  for(int j = 0; j < 3; j++)
    prob_tot += prob[j];

  //normalize probabilities
  for(int j = 0; j < 3; j++)
    prob[j] = prob[j]/prob_tot;

  //or this give the same error
  //prob[2] = 1.0 - prob[1] - prob[0];

  //checking indeed prob_tot not exactly 1
  for(int j = 0; j < 3; j++)
    prob_tot += prob[j];

  Rprintf("Prob_tot: %f\n", prob_tot);

  int rN[3];
  rmultinom(1, prob, 1, rN);
  return 0;
}
 
run R CMD SHLIB test.c to generate the test.so. Now from within R

> dyn.load("test.so")
> .C("main")
Prob_tot: 1.017084
Error: rbinom: probability sum should be 1, but is 0.948075

Maybe I miss some trivial C knowledge why this is not exactly one!

Thanks in advance!

Regards, 
Maarten
________________________________________
From: peter dalgaard [pdalgd at gmail.com]
Sent: Thursday, March 10, 2016 1:26 PM
To: Iterson, M. van (MOLEPI)
Cc: r-devel at r-project.org
Subject: Re: [Rd] rmultinom.c error probability not sum to 1

On 10 Mar 2016, at 12:47 , M.van_Iterson at lumc.nl wrote:

> Dear all,
>
> I have a questions regarding using the c function rmultinom.c.
>
> I got the following error message "rbinom: probability sum should be 1, but is 0.999264"
>
> Which is thrown by:
>
> if(fabs((double)(p_tot - 1.)) > 1e-7)
> MATHLIB_ERROR(_("rbinom: probability sum should be 1, but is %g"),
> (double) p_tot);
>
> I understand my probabilities do not sum to one close enough. I tried the following,
> p[2] = 1. - p[0] - p[1],  where 'p', are the probabilities but this is not sufficient to pass the error message!
>


p[0] ????


> Thanks in advance!
>
> Regards,
> Maarten
>
> (I don't think this is an issue with versions but I used R version 3.2.3 and can provide more details on my linux build if necessary.)
>
>
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

--
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com



From bhh at xs4all.nl  Thu Mar 10 21:38:28 2016
From: bhh at xs4all.nl (Berend Hasselman)
Date: Thu, 10 Mar 2016 21:38:28 +0100
Subject: [Rd] rmultinom.c error probability not sum to 1
In-Reply-To: <6C970093269C804E91E22510E87295281C3A4619@MAIL-MB01.lumcnet.prod.intern>
References: <6C970093269C804E91E22510E87295281C3A448C@MAIL-MB01.lumcnet.prod.intern>
	<AD6651EC-AA5B-4EFA-8EA1-54170F809F1A@gmail.com>
	<6C970093269C804E91E22510E87295281C3A4619@MAIL-MB01.lumcnet.prod.intern>
Message-ID: <18259741-558B-4D4C-8BE5-DEB802CA5263@xs4all.nl>


> On 10 Mar 2016, at 21:25, M.van_Iterson at lumc.nl wrote:
> 
> Hi all, 
> 
> I should have given a better explanation of my problem. Here it is.
> 
> I extracted from my code the bit that gives the error. Place this in a file called test.c
> 
> #include <math.h>
> #include <R.h>
> #include <Rmath.h>
> #include <float.h>
> #include <R_ext/Print.h>
> 
> int main(){
> 
>  double prob[3] = {0.0, 0.0, 0.0};
>  double prob_tot = 0.;
> 
>  prob[0] = 0.3*dnorm(2, 0, 1, 0);
>  prob[1] = 0.5*dnorm(5, 0, 1, 0);
>  prob[2] = 0.2*dnorm(-3, 0, 1, 0);
> 
>  //obtain prob_tot
>  prob_tot = 0.;
>  for(int j = 0; j < 3; j++)
>    prob_tot += prob[j];
> 
>  //normalize probabilities
>  for(int j = 0; j < 3; j++)
>    prob[j] = prob[j]/prob_tot;
> 
>  //or this give the same error
>  //prob[2] = 1.0 - prob[1] - prob[0];
> 
>  //checking indeed prob_tot not exactly 1
>  for(int j = 0; j < 3; j++)
>    prob_tot += prob[j];
> 

You haven't initialized prob_tot before starting the for loop.
Set prob_tot to 0.0 before starting the for loop.

Berend

>  Rprintf("Prob_tot: %f\n", prob_tot);
> 
>  int rN[3];
>  rmultinom(1, prob, 1, rN);
>  return 0;
> }
> 
> run R CMD SHLIB test.c to generate the test.so. Now from within R
> 
>> dyn.load("test.so")
>> .C("main")
> Prob_tot: 1.017084
> Error: rbinom: probability sum should be 1, but is 0.948075
> 
> Maybe I miss some trivial C knowledge why this is not exactly one!
> 
> Thanks in advance!
> 
> Regards, 
> Maarten
> ________________________________________
> From: peter dalgaard [pdalgd at gmail.com]
> Sent: Thursday, March 10, 2016 1:26 PM
> To: Iterson, M. van (MOLEPI)
> Cc: r-devel at r-project.org
> Subject: Re: [Rd] rmultinom.c error probability not sum to 1
> 
> On 10 Mar 2016, at 12:47 , M.van_Iterson at lumc.nl wrote:
> 
>> Dear all,
>> 
>> I have a questions regarding using the c function rmultinom.c.
>> 
>> I got the following error message "rbinom: probability sum should be 1, but is 0.999264"
>> 
>> Which is thrown by:
>> 
>> if(fabs((double)(p_tot - 1.)) > 1e-7)
>> MATHLIB_ERROR(_("rbinom: probability sum should be 1, but is %g"),
>> (double) p_tot);
>> 
>> I understand my probabilities do not sum to one close enough. I tried the following,
>> p[2] = 1. - p[0] - p[1],  where 'p', are the probabilities but this is not sufficient to pass the error message!
>> 
> 
> 
> p[0] ????
> 
> 
>> Thanks in advance!
>> 
>> Regards,
>> Maarten
>> 
>> (I don't think this is an issue with versions but I used R version 3.2.3 and can provide more details on my linux build if necessary.)
>> 
>> 
>> 
>>      [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> --
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Office: A 4.23
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
> 
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From pdalgd at gmail.com  Thu Mar 10 21:45:26 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 10 Mar 2016 21:45:26 +0100
Subject: [Rd] rmultinom.c error probability not sum to 1
In-Reply-To: <6C970093269C804E91E22510E87295281C3A4619@MAIL-MB01.lumcnet.prod.intern>
References: <6C970093269C804E91E22510E87295281C3A448C@MAIL-MB01.lumcnet.prod.intern>
	<AD6651EC-AA5B-4EFA-8EA1-54170F809F1A@gmail.com>
	<6C970093269C804E91E22510E87295281C3A4619@MAIL-MB01.lumcnet.prod.intern>
Message-ID: <16AB388F-BE5F-4521-AA57-373CC54A2088@gmail.com>


> On 10 Mar 2016, at 21:25 , M.van_Iterson at lumc.nl wrote:
> 
> Hi all, 
> 
> I should have given a better explanation of my problem. Here it is.
> 
> I extracted from my code the bit that gives the error. Place this in a file called test.c

Aha. Missing info #1, C not R...

> 
> #include <math.h>
> #include <R.h>
> #include <Rmath.h>
> #include <float.h>
> #include <R_ext/Print.h>
> 
> int main(){
> 
>  double prob[3] = {0.0, 0.0, 0.0};
>  double prob_tot = 0.;
> 
>  prob[0] = 0.3*dnorm(2, 0, 1, 0);
>  prob[1] = 0.5*dnorm(5, 0, 1, 0);
>  prob[2] = 0.2*dnorm(-3, 0, 1, 0);
> 
>  //obtain prob_tot
>  prob_tot = 0.;
>  for(int j = 0; j < 3; j++)
>    prob_tot += prob[j];
> 
>  //normalize probabilities
>  for(int j = 0; j < 3; j++)
>    prob[j] = prob[j]/prob_tot;
> 
>  //or this give the same error
>  //prob[2] = 1.0 - prob[1] - prob[0];
> 

prob_tot = 0; missing here

>  //checking indeed prob_tot not exactly 1
>  for(int j = 0; j < 3; j++)
>    prob_tot += prob[j];
> 
>  Rprintf("Prob_tot: %f\n", prob_tot);
> 
>  int rN[3];
>  rmultinom(1, prob, 1, rN);

Er, where do you tell rmultinom that variates are three-dimensional? It's not going to infer it from array sizes. 

-pd

>  return 0;
> }
> 
> run R CMD SHLIB test.c to generate the test.so. Now from within R
> 
>> dyn.load("test.so")
>> .C("main")
> Prob_tot: 1.017084
> Error: rbinom: probability sum should be 1, but is 0.948075
> 
> Maybe I miss some trivial C knowledge why this is not exactly one!
> 
> Thanks in advance!
> 
> Regards, 
> Maarten
> ________________________________________
> From: peter dalgaard [pdalgd at gmail.com]
> Sent: Thursday, March 10, 2016 1:26 PM
> To: Iterson, M. van (MOLEPI)
> Cc: r-devel at r-project.org
> Subject: Re: [Rd] rmultinom.c error probability not sum to 1
> 
> On 10 Mar 2016, at 12:47 , M.van_Iterson at lumc.nl wrote:
> 
>> Dear all,
>> 
>> I have a questions regarding using the c function rmultinom.c.
>> 
>> I got the following error message "rbinom: probability sum should be 1, but is 0.999264"
>> 
>> Which is thrown by:
>> 
>> if(fabs((double)(p_tot - 1.)) > 1e-7)
>> MATHLIB_ERROR(_("rbinom: probability sum should be 1, but is %g"),
>> (double) p_tot);
>> 
>> I understand my probabilities do not sum to one close enough. I tried the following,
>> p[2] = 1. - p[0] - p[1],  where 'p', are the probabilities but this is not sufficient to pass the error message!
>> 
> 
> 
> p[0] ????
> 
> 
>> Thanks in advance!
>> 
>> Regards,
>> Maarten
>> 
>> (I don't think this is an issue with versions but I used R version 3.2.3 and can provide more details on my linux build if necessary.)
>> 
>> 
>> 
>>      [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> --
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Office: A 4.23
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
> 

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From M.van_Iterson at lumc.nl  Thu Mar 10 22:12:35 2016
From: M.van_Iterson at lumc.nl (M.van_Iterson at lumc.nl)
Date: Thu, 10 Mar 2016 21:12:35 +0000
Subject: [Rd] rmultinom.c error probability not sum to 1
In-Reply-To: <16AB388F-BE5F-4521-AA57-373CC54A2088@gmail.com>
References: <6C970093269C804E91E22510E87295281C3A448C@MAIL-MB01.lumcnet.prod.intern>
	<AD6651EC-AA5B-4EFA-8EA1-54170F809F1A@gmail.com>
	<6C970093269C804E91E22510E87295281C3A4619@MAIL-MB01.lumcnet.prod.intern>,
	<16AB388F-BE5F-4521-AA57-373CC54A2088@gmail.com>
Message-ID: <6C970093269C804E91E22510E87295281C3A4647@MAIL-MB01.lumcnet.prod.intern>

Thanks for your replies. Indeed, I had to add the dimension of the probability vector like this

 rmultinom(1, prob, 3, rN);

Regards, 
Maarten
________________________________________
From: peter dalgaard [pdalgd at gmail.com]
Sent: Thursday, March 10, 2016 9:45 PM
To: Iterson, M. van (MOLEPI)
Cc: r-devel at r-project.org
Subject: Re: [Rd] rmultinom.c error probability not sum to 1

> On 10 Mar 2016, at 21:25 , M.van_Iterson at lumc.nl wrote:
>
> Hi all,
>
> I should have given a better explanation of my problem. Here it is.
>
> I extracted from my code the bit that gives the error. Place this in a file called test.c

Aha. Missing info #1, C not R...

>
> #include <math.h>
> #include <R.h>
> #include <Rmath.h>
> #include <float.h>
> #include <R_ext/Print.h>
>
> int main(){
>
>  double prob[3] = {0.0, 0.0, 0.0};
>  double prob_tot = 0.;
>
>  prob[0] = 0.3*dnorm(2, 0, 1, 0);
>  prob[1] = 0.5*dnorm(5, 0, 1, 0);
>  prob[2] = 0.2*dnorm(-3, 0, 1, 0);
>
>  //obtain prob_tot
>  prob_tot = 0.;
>  for(int j = 0; j < 3; j++)
>    prob_tot += prob[j];
>
>  //normalize probabilities
>  for(int j = 0; j < 3; j++)
>    prob[j] = prob[j]/prob_tot;
>
>  //or this give the same error
>  //prob[2] = 1.0 - prob[1] - prob[0];
>

prob_tot = 0; missing here

>  //checking indeed prob_tot not exactly 1
>  for(int j = 0; j < 3; j++)
>    prob_tot += prob[j];
>
>  Rprintf("Prob_tot: %f\n", prob_tot);
>
>  int rN[3];
>  rmultinom(1, prob, 1, rN);

Er, where do you tell rmultinom that variates are three-dimensional? It's not going to infer it from array sizes.

-pd

>  return 0;
> }
>
> run R CMD SHLIB test.c to generate the test.so. Now from within R
>
>> dyn.load("test.so")
>> .C("main")
> Prob_tot: 1.017084
> Error: rbinom: probability sum should be 1, but is 0.948075
>
> Maybe I miss some trivial C knowledge why this is not exactly one!
>
> Thanks in advance!
>
> Regards,
> Maarten
> ________________________________________
> From: peter dalgaard [pdalgd at gmail.com]
> Sent: Thursday, March 10, 2016 1:26 PM
> To: Iterson, M. van (MOLEPI)
> Cc: r-devel at r-project.org
> Subject: Re: [Rd] rmultinom.c error probability not sum to 1
>
> On 10 Mar 2016, at 12:47 , M.van_Iterson at lumc.nl wrote:
>
>> Dear all,
>>
>> I have a questions regarding using the c function rmultinom.c.
>>
>> I got the following error message "rbinom: probability sum should be 1, but is 0.999264"
>>
>> Which is thrown by:
>>
>> if(fabs((double)(p_tot - 1.)) > 1e-7)
>> MATHLIB_ERROR(_("rbinom: probability sum should be 1, but is %g"),
>> (double) p_tot);
>>
>> I understand my probabilities do not sum to one close enough. I tried the following,
>> p[2] = 1. - p[0] - p[1],  where 'p', are the probabilities but this is not sufficient to pass the error message!
>>
>
>
> p[0] ????
>
>
>> Thanks in advance!
>>
>> Regards,
>> Maarten
>>
>> (I don't think this is an issue with versions but I used R version 3.2.3 and can provide more details on my linux build if necessary.)
>>
>>
>>
>>      [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> --
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Office: A 4.23
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>

--
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com











From mick.jordan at oracle.com  Sat Mar 12 00:05:50 2016
From: mick.jordan at oracle.com (Mick Jordan)
Date: Fri, 11 Mar 2016 15:05:50 -0800
Subject: [Rd] Regression in strptime
Message-ID: <56E34F4E.30006@oracle.com>

This is definitely obscure but we had a unit test that called 
.Internal(strptime, "1942/01/01", %Y/%m/%d") with timezone (TZ) set to 
CET. In R-3.1.3 that returned "1942-01-01 CEST" which, paradoxically, is 
correct as they evidently did strange things in Germany during the war 
period. Java also returns the same. However, R-3.2.4 returns "1942-01-01 
CET".

Mick Jordan


From mick.jordan at oracle.com  Sat Mar 12 03:52:26 2016
From: mick.jordan at oracle.com (Mick Jordan)
Date: Fri, 11 Mar 2016 18:52:26 -0800
Subject: [Rd] R-3.2.4 Mac/Linux different in < on characters
Message-ID: <56E3846A.5040808@oracle.com>

Linux:
 > x<-c("0","1");y<-c("a","-1"); x<y
[1] TRUE TRUE

Mac:

x<-c("0","1");y<-c("a","-1"); x<y
[1]  TRUE FALSE


On both systems, LC_COLLATE/LC_CTYPE/LANG are set to en_US.UTF-8

In Java,FWIW, I get the Mac answer if I use String.compareTo and the 
Linux answer if I use Collator.compareTo, but the result is consistent 
on Mac and Linux.

Mick Jordan


From mick.jordan at oracle.com  Sat Mar 12 03:58:07 2016
From: mick.jordan at oracle.com (Mick Jordan)
Date: Fri, 11 Mar 2016 18:58:07 -0800
Subject: [Rd] R-3.2.4 Mac/Linux different in < on characters
In-Reply-To: <56E3846A.5040808@oracle.com>
References: <56E3846A.5040808@oracle.com>
Message-ID: <56E385BF.2020109@oracle.com>

On 3/11/16 6:52 PM, Mick Jordan wrote:
> Linux:
> > x<-c("0","1");y<-c("a","-1"); x<y
> [1] TRUE TRUE
>
> Mac:
>
> x<-c("0","1");y<-c("a","-1"); x<y
> [1]  TRUE FALSE
>
>
> On both systems, LC_COLLATE/LC_CTYPE/LANG are set to en_US.UTF-8
>
> In Java,FWIW, I get the Mac answer if I use String.compareTo and the 
> Linux answer if I use Collator.compareTo, but the result is consistent 
> on Mac and Linux.
>
So this is probably related to the fact that the Linux system in 
question answers "ICU not in use" whereas the Mac answers "root"?

Mick


From dwinsemius at comcast.net  Sat Mar 12 06:50:28 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 11 Mar 2016 21:50:28 -0800
Subject: [Rd] R-3.2.4 Mac/Linux different in < on characters
In-Reply-To: <56E3846A.5040808@oracle.com>
References: <56E3846A.5040808@oracle.com>
Message-ID: <3ED54186-ACFC-4071-BE1C-778034F81DF1@comcast.net>


> On Mar 11, 2016, at 6:52 PM, Mick Jordan <mick.jordan at oracle.com> wrote:
> 
> Linux:
> > x<-c("0","1");y<-c("a","-1"); x<y
> [1] TRUE TRUE
> 
> Mac:
> 
> x<-c("0","1");y<-c("a","-1"); x<y
> [1]  TRUE FALSE
> 

On a Mac (and noting the the documentation [somewhere that I cannot find right now] warns us the the collation sequence for characters is OS dependent):

require(R.oo)
charToInt("-")
#[1] 45
charToInt("1")
#[1] 49

> 
> On both systems, LC_COLLATE/LC_CTYPE/LANG are set to en_US.UTF-8
> 
> In Java,FWIW, I get the Mac answer if I use String.compareTo and the Linux answer if I use Collator.compareTo, but the result is consistent on Mac and Linux.
> 
> Mick Jordan
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

David Winsemius
Alameda, CA, USA


From pdalgd at gmail.com  Sat Mar 12 09:33:28 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Sat, 12 Mar 2016 09:33:28 +0100
Subject: [Rd] Regression in strptime
In-Reply-To: <56E34F4E.30006@oracle.com>
References: <56E34F4E.30006@oracle.com>
Message-ID: <7CB65C37-52E1-48E4-9AF9-83FE0BAEFCC8@gmail.com>


> On 12 Mar 2016, at 00:05 , Mick Jordan <mick.jordan at oracle.com> wrote:
> 
> This is definitely obscure but we had a unit test that called .Internal(strptime, "1942/01/01", %Y/%m/%d") with timezone (TZ) set to CET.

Umm, that doesn't even parse. And fixing the typo, it doesn't run:

> .Internal(strptime, "1942/01/01", %Y/%m/%d")
Error: unexpected SPECIAL in ".Internal(strptime, "1942/01/01", %Y/%"
> .Internal(strptime, "1942/01/01", "%Y/%m/%d")
Error in .Internal(strptime, "1942/01/01", "%Y/%m/%d") : 
  3 arguments passed to '.Internal' which requires 1



> In R-3.1.3 that returned "1942-01-01 CEST" which, paradoxically, is correct as they evidently did strange things in Germany during the war period. Java also returns the same. However, R-3.2.4 returns "1942-01-01 CET".

Did you mean:

pd$ r-release-branch/BUILD-dist/bin/R

R version 3.2.4 Patched (2016-03-10 r70319) -- "Very Secure Dishes"
Copyright (C) 2016 The R Foundation for Statistical Computing
Platform: x86_64-apple-darwin13.4.0/x86_64 (64-bit)
[...]
> strptime("1942/01/01", "%Y/%m/%d", tz="CET")
[1] "1942-01-01 CEST"

But then as you see, it does have DST on New Years Day.

All in all, there is something you are not telling us.

Notice that all DST information is OS dependent as it depends on which version of the "Olson database" is installed.


> 
> Mick Jordan
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From mick.jordan at oracle.com  Sat Mar 12 17:43:07 2016
From: mick.jordan at oracle.com (Mick Jordan)
Date: Sat, 12 Mar 2016 08:43:07 -0800
Subject: [Rd] Regression in strptime
In-Reply-To: <7CB65C37-52E1-48E4-9AF9-83FE0BAEFCC8@gmail.com>
References: <56E34F4E.30006@oracle.com>
	<7CB65C37-52E1-48E4-9AF9-83FE0BAEFCC8@gmail.com>
Message-ID: <56E4471B.6020001@oracle.com>

On 3/12/16 12:33 AM, peter dalgaard wrote:
>> On 12 Mar 2016, at 00:05 , Mick Jordan <mick.jordan at oracle.com> wrote:
>>
>> This is definitely obscure but we had a unit test that called .Internal(strptime, "1942/01/01", %Y/%m/%d") with timezone (TZ) set to CET.
> Umm, that doesn't even parse. And fixing the typo, it doesn't run:
>
>> .Internal(strptime, "1942/01/01", %Y/%m/%d")
> Error: unexpected SPECIAL in ".Internal(strptime, "1942/01/01", %Y/%"
>> .Internal(strptime, "1942/01/01", "%Y/%m/%d")
> Error in .Internal(strptime, "1942/01/01", "%Y/%m/%d") :
>    3 arguments passed to '.Internal' which requires 1
>
>
>
>> In R-3.1.3 that returned "1942-01-01 CEST" which, paradoxically, is correct as they evidently did strange things in Germany during the war period. Java also returns the same. However, R-3.2.4 returns "1942-01-01 CET".
> Did you mean:
>
> pd$ r-release-branch/BUILD-dist/bin/R
>
> R version 3.2.4 Patched (2016-03-10 r70319) -- "Very Secure Dishes"
> Copyright (C) 2016 The R Foundation for Statistical Computing
> Platform: x86_64-apple-darwin13.4.0/x86_64 (64-bit)
> [...]
>> strptime("1942/01/01", "%Y/%m/%d", tz="CET")
> [1] "1942-01-01 CEST"
>
> But then as you see, it does have DST on New Years Day.
>
> All in all, there is something you are not telling us.
>
> Notice that all DST information is OS dependent as it depends on which version of the "Olson database" is installed.
>
>
You are correct that I was sloppy with syntax for the example. We are, 
for better or worse, calling the .Internal, but actually with a large 
vector of arguments, of which the 1942 entry is element 82. I can 
confirm that for the vector of length 1 example that I didn't test but 
just assumed would also fail, the answer is correct. However, it is not 
for the full vector:

 > .Internal(strptime(argv[[1]], argv[[2]], "CET"))
   [1] "1937-01-01 CET" "1916-01-01 CET" "1913-01-01 CET" "1927-01-01 CET"
   [5] "1947-01-01 CET" "1913-01-01 CET" "1917-01-01 CET" "1923-01-01 CET"
   [9] "1921-01-01 CET" "1926-01-01 CET" "1920-01-01 CET" "1915-01-01 CET"
  [13] "1914-01-01 CET" "1914-01-01 CET" "1914-01-01 CET" "1919-01-01 CET"
  [17] "1948-01-01 CET" "1911-01-01 CET" "1909-01-01 CET" "1913-01-01 CET"
  [21] "1925-01-01 CET" "1926-01-01 CET" "1910-01-01 CET" "1917-01-01 CET"
  [25] "1936-01-01 CET" "1938-01-01 CET" "1960-01-01 CET" "1915-01-01 CET"
  [29] "1919-01-01 CET" "1924-01-01 CET" "1914-01-01 CET" "1905-01-01 CET"
  [33] "1921-01-01 CET" "1929-01-01 CET" "1926-01-01 CET" "1921-01-01 CET"
  [37] "1908-01-01 CET" "1928-01-01 CET" "1919-01-01 CET" "1921-01-01 CET"
  [41] "1925-01-01 CET" "1934-01-01 CET" "1927-01-01 CET" "1928-01-01 CET"
  [45] "1934-01-01 CET" "1922-01-01 CET" "1923-01-01 CET" "1915-01-01 CET"
  [49] "1934-01-01 CET" "1925-01-01 CET" "1922-01-01 CET" "1930-01-01 CET"
  [53] "1924-01-01 CET" "1923-01-01 CET" "1919-01-01 CET" "1932-01-01 CET"
  [57] "1930-01-01 CET" "1923-01-01 CET" "1930-01-01 CET" "1922-01-01 CET"
  [61] "1919-01-01 CET" "1932-01-01 CET" "1939-01-01 CET" "1923-01-01 CET"
  [65] "1920-01-01 CET" "1919-01-01 CET" "1952-01-01 CET" "1927-01-01 CET"
  [69] "1924-01-01 CET" "1919-01-01 CET" "1925-01-01 CET" "1945-01-01 CET"
  [73] "1916-01-01 CET" "1943-01-01 CET" "1920-01-01 CET" "1920-01-01 CET"
  [77] "1931-01-01 CET" "1924-01-01 CET" "1919-01-01 CET" "1926-01-01 CET"
  [81] "1920-01-01 CET" "1942-01-01 CET" "1919-01-01 CET" "1930-01-01 CET"
  [85] "1925-01-01 CET" "1924-01-01 CET" "1926-01-01 CET" "1918-01-01 CET"
  [89] "1922-01-01 CET" "1921-01-01 CET" "1925-01-01 CET" "1928-01-01 CET"
  [93] "1925-01-01 CET" "1929-01-01 CET" "1933-01-01 CET" "1947-01-01 CET"
  [97] "1950-01-01 CET" "1945-01-01 CET" "1924-01-01 CET" "1939-01-01 CET"
[101] "1924-01-01 CET" "1933-01-01 CET" "1928-01-01 CET"
 > .Internal( strptime("1942/01/01", "%Y/%m/%d", ''))
[1] "1942-01-01 CEST"
 > > argv[[1]][[82]]
[1] "1942/01/01"

We actually pass "" as the timezone, having set TZ=CET in the shell.

I am attaching a file that defines the large vector for sourcing.

Mick

-------------- next part --------------
argv <- list(c('1937/01/01', '1916/01/01', '1913/01/01', '1927/01/01', '1947/01/01', '1913/01/01', '1917/01/01', '1923/01/01',
               '1921/01/01', '1926/01/01', '1920/01/01', '1915/01/01', '1914/01/01', '1914/01/01', '1914/01/01', '1919/01/01',
               '1948/01/01', '1911/01/01', '1909/01/01', '1913/01/01', '1925/01/01', '1926/01/01', '1910/01/01', '1917/01/01',
               '1936/01/01', '1938/01/01', '1960/01/01', '1915/01/01', '1919/01/01', '1924/01/01', '1914/01/01', '1905/01/01',
               '1921/01/01', '1929/01/01', '1926/01/01', '1921/01/01', '1908/01/01', '1928/01/01', '1919/01/01', '1921/01/01',
               '1925/01/01', '1934/01/01', '1927/01/01', '1928/01/01', '1934/01/01', '1922/01/01', '1923/01/01', '1915/01/01',
               '1934/01/01', '1925/01/01', '1922/01/01', '1930/01/01', '1924/01/01', '1923/01/01', '1919/01/01', '1932/01/01',
               '1930/01/01', '1923/01/01', '1930/01/01', '1922/01/01', '1919/01/01', '1932/01/01', '1939/01/01', '1923/01/01',
               '1920/01/01', '1919/01/01', '1952/01/01', '1927/01/01', '1924/01/01', '1919/01/01', '1925/01/01', '1945/01/01',
               '1916/01/01', '1943/01/01', '1920/01/01', '1920/01/01', '1931/01/01', '1924/01/01', '1919/01/01', '1926/01/01',
               '1920/01/01', '1942/01/01', '1919/01/01', '1930/01/01', '1925/01/01', '1924/01/01', '1926/01/01', '1918/01/01',
               '1922/01/01', '1921/01/01', '1925/01/01', '1928/01/01', '1925/01/01', '1929/01/01', '1933/01/01', '1947/01/01',
               '1950/01/01', '1945/01/01', '1924/01/01', '1939/01/01', '1924/01/01', '1933/01/01', '1928/01/01'), '%Y/%m/%d', '');

From pdalgd at gmail.com  Sat Mar 12 19:11:40 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Sat, 12 Mar 2016 19:11:40 +0100
Subject: [Rd] Regression in strptime
In-Reply-To: <56E4471B.6020001@oracle.com>
References: <56E34F4E.30006@oracle.com>
	<7CB65C37-52E1-48E4-9AF9-83FE0BAEFCC8@gmail.com>
	<56E4471B.6020001@oracle.com>
Message-ID: <EE281D98-018A-496B-B851-3C89D59BF540@gmail.com>

OK, .Internal is not necessary to reproduce oddity in this area. I also see things like (notice 1980)

> strptime(paste0(sample(1900:1999,80,replace=TRUE),"/01/01"), "%Y/%m/%d", tz="CET")
 [1] "1942-01-01 CEST" "1902-01-01 CET"  "1956-01-01 CET"  "1972-01-01 CET" 
 [5] "1962-01-01 CET"  "1900-01-01 CET"  "1921-01-01 CET"  "1972-01-01 CET" 
 [9] "1918-01-01 CET"  "1989-01-01 CET"  "1900-01-01 CET"  "1970-01-01 CET" 
[13] "1971-01-01 CET"  "1910-01-01 CET"  "1956-01-01 CET"  "1953-01-01 CET" 
[17] "1964-01-01 CET"  "1932-01-01 CET"  "1968-01-01 CET"  "1990-01-01 CET" 
[21] "1961-01-01 CET"  "1920-01-01 CET"  "1961-01-01 CET"  "1941-01-01 CEST"
[25] "1947-01-01 CET"  "1979-01-01 CET"  "1943-01-01 CET"  "1976-01-01 CET" 
[29] "1951-01-01 CET"  "1912-01-01 CET"  "1983-01-01 CET"  "1985-01-01 CET" 
[33] "1970-01-01 CET"  "1917-01-01 CET"  "1930-01-01 CET"  "1966-01-01 CET" 
[37] "1953-01-01 CET"  "1938-01-01 CET"  "1974-01-01 CET"  "1959-01-01 CET" 
[41] "1984-01-01 CET"  "1928-01-01 CET"  "1970-01-01 CET"  "1959-01-01 CET" 
[45] "1935-01-01 CET"  "1934-01-01 CET"  "1935-01-01 CET"  "1951-01-01 CET" 
[49] "1907-01-01 CET"  "1985-01-01 CET"  "1906-01-01 CET"  "1912-01-01 CET" 
[53] "1966-01-01 CET"  "1944-01-01 CET"  "1952-01-01 CET"  "1936-01-01 CET" 
[57] "1967-01-01 CET"  "1925-01-01 CET"  "1980-01-01 CEST" "1930-01-01 CET" 
[61] "1999-01-01 CET"  "1965-01-01 CET"  "1903-01-01 CET"  "1942-01-01 CET" 
[65] "1917-01-01 CET"  "1995-01-01 CET"  "1939-01-01 CET"  "1949-01-01 CET" 
[69] "1950-01-01 CET"  "1966-01-01 CET"  "1996-01-01 CET"  "1966-01-01 CET" 
[73] "1999-01-01 CET"  "1961-01-01 CET"  "1946-01-01 CET"  "1902-01-01 CET" 
[77] "1983-01-01 CET"  "1981-01-01 CET"  "1949-01-01 CET"  "1977-01-01 CET" 

The issue seems to be present in R-devel but not in (CRAN) 3.2.0

-pd


> On 12 Mar 2016, at 17:43 , Mick Jordan <mick.jordan at oracle.com> wrote:
> 
> On 3/12/16 12:33 AM, peter dalgaard wrote:
>>> On 12 Mar 2016, at 00:05 , Mick Jordan <mick.jordan at oracle.com> wrote:
>>> 
>>> This is definitely obscure but we had a unit test that called .Internal(strptime, "1942/01/01", %Y/%m/%d") with timezone (TZ) set to CET.
>> Umm, that doesn't even parse. And fixing the typo, it doesn't run:
>> 
>>> .Internal(strptime, "1942/01/01", %Y/%m/%d")
>> Error: unexpected SPECIAL in ".Internal(strptime, "1942/01/01", %Y/%"
>>> .Internal(strptime, "1942/01/01", "%Y/%m/%d")
>> Error in .Internal(strptime, "1942/01/01", "%Y/%m/%d") :
>>   3 arguments passed to '.Internal' which requires 1
>> 
>> 
>> 
>>> In R-3.1.3 that returned "1942-01-01 CEST" which, paradoxically, is correct as they evidently did strange things in Germany during the war period. Java also returns the same. However, R-3.2.4 returns "1942-01-01 CET".
>> Did you mean:
>> 
>> pd$ r-release-branch/BUILD-dist/bin/R
>> 
>> R version 3.2.4 Patched (2016-03-10 r70319) -- "Very Secure Dishes"
>> Copyright (C) 2016 The R Foundation for Statistical Computing
>> Platform: x86_64-apple-darwin13.4.0/x86_64 (64-bit)
>> [...]
>>> strptime("1942/01/01", "%Y/%m/%d", tz="CET")
>> [1] "1942-01-01 CEST"
>> 
>> But then as you see, it does have DST on New Years Day.
>> 
>> All in all, there is something you are not telling us.
>> 
>> Notice that all DST information is OS dependent as it depends on which version of the "Olson database" is installed.
>> 
>> 
> You are correct that I was sloppy with syntax for the example. We are, for better or worse, calling the .Internal, but actually with a large vector of arguments, of which the 1942 entry is element 82. I can confirm that for the vector of length 1 example that I didn't test but just assumed would also fail, the answer is correct. However, it is not for the full vector:
> 
> > .Internal(strptime(argv[[1]], argv[[2]], "CET"))
>  [1] "1937-01-01 CET" "1916-01-01 CET" "1913-01-01 CET" "1927-01-01 CET"
>  [5] "1947-01-01 CET" "1913-01-01 CET" "1917-01-01 CET" "1923-01-01 CET"
>  [9] "1921-01-01 CET" "1926-01-01 CET" "1920-01-01 CET" "1915-01-01 CET"
> [13] "1914-01-01 CET" "1914-01-01 CET" "1914-01-01 CET" "1919-01-01 CET"
> [17] "1948-01-01 CET" "1911-01-01 CET" "1909-01-01 CET" "1913-01-01 CET"
> [21] "1925-01-01 CET" "1926-01-01 CET" "1910-01-01 CET" "1917-01-01 CET"
> [25] "1936-01-01 CET" "1938-01-01 CET" "1960-01-01 CET" "1915-01-01 CET"
> [29] "1919-01-01 CET" "1924-01-01 CET" "1914-01-01 CET" "1905-01-01 CET"
> [33] "1921-01-01 CET" "1929-01-01 CET" "1926-01-01 CET" "1921-01-01 CET"
> [37] "1908-01-01 CET" "1928-01-01 CET" "1919-01-01 CET" "1921-01-01 CET"
> [41] "1925-01-01 CET" "1934-01-01 CET" "1927-01-01 CET" "1928-01-01 CET"
> [45] "1934-01-01 CET" "1922-01-01 CET" "1923-01-01 CET" "1915-01-01 CET"
> [49] "1934-01-01 CET" "1925-01-01 CET" "1922-01-01 CET" "1930-01-01 CET"
> [53] "1924-01-01 CET" "1923-01-01 CET" "1919-01-01 CET" "1932-01-01 CET"
> [57] "1930-01-01 CET" "1923-01-01 CET" "1930-01-01 CET" "1922-01-01 CET"
> [61] "1919-01-01 CET" "1932-01-01 CET" "1939-01-01 CET" "1923-01-01 CET"
> [65] "1920-01-01 CET" "1919-01-01 CET" "1952-01-01 CET" "1927-01-01 CET"
> [69] "1924-01-01 CET" "1919-01-01 CET" "1925-01-01 CET" "1945-01-01 CET"
> [73] "1916-01-01 CET" "1943-01-01 CET" "1920-01-01 CET" "1920-01-01 CET"
> [77] "1931-01-01 CET" "1924-01-01 CET" "1919-01-01 CET" "1926-01-01 CET"
> [81] "1920-01-01 CET" "1942-01-01 CET" "1919-01-01 CET" "1930-01-01 CET"
> [85] "1925-01-01 CET" "1924-01-01 CET" "1926-01-01 CET" "1918-01-01 CET"
> [89] "1922-01-01 CET" "1921-01-01 CET" "1925-01-01 CET" "1928-01-01 CET"
> [93] "1925-01-01 CET" "1929-01-01 CET" "1933-01-01 CET" "1947-01-01 CET"
> [97] "1950-01-01 CET" "1945-01-01 CET" "1924-01-01 CET" "1939-01-01 CET"
> [101] "1924-01-01 CET" "1933-01-01 CET" "1928-01-01 CET"
> > .Internal( strptime("1942/01/01", "%Y/%m/%d", ''))
> [1] "1942-01-01 CEST"
> > > argv[[1]][[82]]
> [1] "1942/01/01"
> 
> We actually pass "" as the timezone, having set TZ=CET in the shell.
> 
> I am attaching a file that defines the large vector for sourcing.
> 
> Mick
> 
> <pbug.r>

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From henrik.bengtsson at gmail.com  Sun Mar 13 14:54:09 2016
From: henrik.bengtsson at gmail.com (Henrik Bengtsson)
Date: Sun, 13 Mar 2016 06:54:09 -0700
Subject: [Rd] formals(x)<- drops attributes including class
Message-ID: <CAFDcVCR3pqH-9qOiexCgpNmjcu2BzFGTG8LJLaYmqC0FC2yO2A@mail.gmail.com>

Just checking in to see whether it is intended or not that assigning
new formals to a function/closure causes any attributes to be dropped:

EXAMPLE:
> fcn <- structure(function() {}, foo="foo", class=c("foo"))
> str(fcn)
function ()
 - attr(*, "srcref")=Class 'srcref'  atomic [1:8] 1 18 1 30 18 30 1 1
  .. ..- attr(*, "srcfile")=Classes 'srcfilecopy', 'srcfile' <environment: 0x000
000000c00d128>
 - attr(*, "foo")= chr "foo"
 - attr(*, "class")= chr "foo"

> formals(fcn) <- list(a=1)
> str(fcn)
function (a = 1)
> attributes(fcn)
NULL


TROUBLESHOOTING:
>From the definition of formals()<-, it's quite clear why this happens:

> `formals<-`
function (fun, envir = environment(fun), value)
{
    bd <- body(fun)
    as.function(c(value, if (is.null(bd) || is.list(bd)) list(bd) else bd),
        envir)
}
<bytecode: 0x000000000b97a848>
<environment: namespace:base>


I'm fine with this, but I just wanted to make sure it's not overlooked.

/Henrik


From murdoch.duncan at gmail.com  Sun Mar 13 15:19:13 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 13 Mar 2016 10:19:13 -0400
Subject: [Rd] formals(x)<- drops attributes including class
In-Reply-To: <CAFDcVCR3pqH-9qOiexCgpNmjcu2BzFGTG8LJLaYmqC0FC2yO2A@mail.gmail.com>
References: <CAFDcVCR3pqH-9qOiexCgpNmjcu2BzFGTG8LJLaYmqC0FC2yO2A@mail.gmail.com>
Message-ID: <56E576E1.5030909@gmail.com>

On 13/03/2016 9:54 AM, Henrik Bengtsson wrote:
> Just checking in to see whether it is intended or not that assigning
> new formals to a function/closure causes any attributes to be dropped:

For srcref, yes.  Changing the formals or body of a function would 
usually make them invalid.

I think it makes a reasonable default behaviour for other attributes as 
well.

Duncan Murdoch

>
> EXAMPLE:
>> fcn <- structure(function() {}, foo="foo", class=c("foo"))
>> str(fcn)
> function ()
>   - attr(*, "srcref")=Class 'srcref'  atomic [1:8] 1 18 1 30 18 30 1 1
>    .. ..- attr(*, "srcfile")=Classes 'srcfilecopy', 'srcfile' <environment: 0x000
> 000000c00d128>
>   - attr(*, "foo")= chr "foo"
>   - attr(*, "class")= chr "foo"
>
>> formals(fcn) <- list(a=1)
>> str(fcn)
> function (a = 1)
>> attributes(fcn)
> NULL
>
>
> TROUBLESHOOTING:
>>From the definition of formals()<-, it's quite clear why this happens:
>
>> `formals<-`
> function (fun, envir = environment(fun), value)
> {
>      bd <- body(fun)
>      as.function(c(value, if (is.null(bd) || is.list(bd)) list(bd) else bd),
>          envir)
> }
> <bytecode: 0x000000000b97a848>
> <environment: namespace:base>
>
>
> I'm fine with this, but I just wanted to make sure it's not overlooked.
>
> /Henrik
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From mick.jordan at oracle.com  Mon Mar 14 21:49:55 2016
From: mick.jordan at oracle.com (Mick Jordan)
Date: Mon, 14 Mar 2016 13:49:55 -0700
Subject: [Rd] Help with libiconv problem
Message-ID: <56E723F3.8040305@oracle.com>

A couple of my colleagues are having problems building R-3.2.4 on Mac OS 
X El Capitan somehow related to libiconv. I personally don't have any 
problems on either of my Macs. I'm hoping thie make log might trigger 
something in the readers of this list:

gcc -dynamiclib -Wl,-headerpad_max_install_names -undefined 
dynamic_lookup -single_module -multiply_defined suppress 
-L../../../../lib -L/usr/local/lib -o tools.so text.o init.o Rmd5.o 
md5.o signals.o install.o getfmts.o http.o gramLatex.o gramRd.o 
-L../../../../lib -lR -Wl,-framework -Wl,CoreFoundation
mkdir ../../../../library/tools/libs
installing 'sysdata.rda'
Warning messages:
1: In strptime(paste(.leap.seconds, "23:59:60"), "%Y-%m-%d %H:%M:%S") :
   unknown timezone 'America/Los_Angeles'
2: In strptime(paste(.leap.seconds, "23:59:60"), "%Y-%m-%d %H:%M:%S") :
   unknown timezone 'GMT'
3: In strptime(paste(.leap.seconds, "23:59:60"), "%Y-%m-%d %H:%M:%S") :
   unknown timezone 'America/New_York'
dyld: lazy symbol binding failed: Symbol not found: _libiconv_open
   Referenced from: 
/Users/someone/work/abc/fastr/com.oracle.truffle.r.native/gnur/R-3.2.4/lib/libR.dylib
   Expected in: flat namespace

dyld: Symbol not found: _libiconv_open
   Referenced from: 
/Users/someone/work/abc/fastr/com.oracle.truffle.r.native/gnur/R-3.2.4/lib/libR.dylib
   Expected in: flat namespace

/bin/sh: line 1: 16127 Done                    echo 
"tools:::sysdata2LazyLoadDB(\"./R/sysdata.rda\",\"../../../library/tools/R\")"
      16128 Trace/BPT trap: 5       | R_DEFAULT_PACKAGES=NULL LC_ALL=C 
../../../bin/R --vanilla --slave
make[7]: *** [sysdata] Error 133
make[6]: *** [all] Error 2
make[5]: *** [R] Error 1
make[4]: *** [R] Error 1
make[3]: *** [R] Error 1

We always get the unknown timezone messages which I think are unrelated 
but I'm curious about those.

Thanks
Mick Jordan


From 538280 at gmail.com  Mon Mar 14 22:27:44 2016
From: 538280 at gmail.com (Greg Snow)
Date: Mon, 14 Mar 2016 15:27:44 -0600
Subject: [Rd] Different results based on the order of arguments to par
Message-ID: <CAFEqCdyG5WRaPkKn9MQ4vyqN5sKpTfbx3AtyEt9_JP6qy51+oA@mail.gmail.com>

I ran into this issue when trying to modify a subplot (subplot
function in the TeachingDemos package), but here is a more minimal
example of the issue (I don't know that it is serious enough to call a
bug):

This code works how I expect:

dev.new()
hist(rexp(100))

par(plt=c(0.5,0.9,0.5,0.77), usr=c(0,1,0,1))

box() # show new plt region
points(c(0,1), c(0,1), pch=16, col='red', cex=3)

it creates a histogram then changes the plotting region so that I can
add an annotation, changes the user coordinates within the new region,
then plots some points using the new coordinate system.

But if I change the order of the arguments to par like so:

dev.new()
hist(rexp(100))

par(usr=c(0,1,0,1), plt=c(0.5,0.9,0.5,0.77))

box() #show new plt region
points(c(0,1), c(0,1), pch=16, col='red')

then the points do not show up (or if we add xpd=NA to the par call
then we see them outside of the plotting region).  So clearly the
behavior of par depends on the order of the arguments specified.

This is not explicitly documented, though there is a hinting at the
behavior in the note on the par help page (it was following this
warning that led to me first encountering the issue, since I was
specifying only the parameters that I needed, not everything, and
happened to specify usr before plt), but "usr" is not included in the
list in the note (because it does something different from what the
note is specifically warning about).


I see a few different potential responses to this issue:

1. consider that this is a rare enough issue that only Greg Snow will
ever care and he has already learned the lesson, so do nothing (other
than laugh at Greg when he forgets and has to remember to properly
order his par arguments).

2. Since this came up as an issue with subplot, force the author of
subplot and the TeachingDemos package to add a note or warning to the
documentation for that function.

3.  Expand the note on the help page for par (or add another note)
that warns that the order of the parameters matters and to therefore
be careful in which order you specify arguments (probably with some
detail on the suggested ordering).  While there will be many users who
never read this, we will at least be able to point to the note if
anyone else is affected by this issue.

4. Modify the par function to reorder the list created from its args
so that they are evaluated in a consistent order (and probably add
documentation to the help page to this effect).


Thoughts?




-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From mick.jordan at oracle.com  Tue Mar 15 00:04:09 2016
From: mick.jordan at oracle.com (Mick Jordan)
Date: Mon, 14 Mar 2016 16:04:09 -0700
Subject: [Rd] Help with libiconv problem
In-Reply-To: <56E723F3.8040305@oracle.com>
References: <56E723F3.8040305@oracle.com>
Message-ID: <56E74369.6080800@oracle.com>

On 3/14/16 1:49 PM, Mick Jordan wrote:
> A couple of my colleagues are having problems building R-3.2.4 on Mac 
> OS X El Capitan somehow related to libiconv. I personally don't have 
> any problems on either of my Macs. I'm hoping thie make log might 
> trigger something in the readers of this list:
>
> gcc -dynamiclib -Wl,-headerpad_max_install_names -undefined 
> dynamic_lookup -single_module -multiply_defined suppress 
> -L../../../../lib -L/usr/local/lib -o tools.so text.o init.o Rmd5.o 
> md5.o signals.o install.o getfmts.o http.o gramLatex.o gramRd.o 
> -L../../../../lib -lR -Wl,-framework -Wl,CoreFoundation
> mkdir ../../../../library/tools/libs
> installing 'sysdata.rda'
> Warning messages:
> 1: In strptime(paste(.leap.seconds, "23:59:60"), "%Y-%m-%d %H:%M:%S") :
>   unknown timezone 'America/Los_Angeles'
> 2: In strptime(paste(.leap.seconds, "23:59:60"), "%Y-%m-%d %H:%M:%S") :
>   unknown timezone 'GMT'
> 3: In strptime(paste(.leap.seconds, "23:59:60"), "%Y-%m-%d %H:%M:%S") :
>   unknown timezone 'America/New_York'
> dyld: lazy symbol binding failed: Symbol not found: _libiconv_open
>   Referenced from: 
> /Users/someone/work/abc/fastr/com.oracle.truffle.r.native/gnur/R-3.2.4/lib/libR.dylib
>   Expected in: flat namespace
>
> dyld: Symbol not found: _libiconv_open
>   Referenced from: 
> /Users/someone/work/abc/fastr/com.oracle.truffle.r.native/gnur/R-3.2.4/lib/libR.dylib
>   Expected in: flat namespace
>
> /bin/sh: line 1: 16127 Done                    echo 
> "tools:::sysdata2LazyLoadDB(\"./R/sysdata.rda\",\"../../../library/tools/R\")"
>      16128 Trace/BPT trap: 5       | R_DEFAULT_PACKAGES=NULL LC_ALL=C 
> ../../../bin/R --vanilla --slave
> make[7]: *** [sysdata] Error 133
> make[6]: *** [all] Error 2
> make[5]: *** [R] Error 1
> make[4]: *** [R] Error 1
> make[3]: *** [R] Error 1
>
This seems to be related to having a macports install of libiconv. The 
compile step for sysutils.c puts the macport include header before 
/usr/local/include but the link step for libR doesn't - in fact it 
doesn't include a -L for the macport directory at all. So there is an an 
inconsistency in the expected symbols. (Why the macport version defines 
libiconv_open instead of iconv_open I have no idea).

ick


From paul at stat.auckland.ac.nz  Tue Mar 15 02:04:54 2016
From: paul at stat.auckland.ac.nz (Paul Murrell)
Date: Tue, 15 Mar 2016 14:04:54 +1300
Subject: [Rd] [FORGED] Different results based on the order of arguments
 to par
In-Reply-To: <CAFEqCdyG5WRaPkKn9MQ4vyqN5sKpTfbx3AtyEt9_JP6qy51+oA@mail.gmail.com>
References: <CAFEqCdyG5WRaPkKn9MQ4vyqN5sKpTfbx3AtyEt9_JP6qy51+oA@mail.gmail.com>
Message-ID: <56E75FB6.7020808@stat.auckland.ac.nz>

Hi

I'm going to try to blame user error here.

par(usr) is used to reset the coordinates on the CURRENT plot.

par(plt) is used to specify the location of the NEXT plot.

The correct approach should be to set up the location for the next plot, 
start a new plot, set up coordinates on the new plot.

Neither of your examples performs the "start a new plot" step.

I would expect to see something like ...

dev.new()
hist(rexp(100))
# Set up location of new plot
par(plt=c(0.5,0.9,0.5,0.77))
# Avoid new page
par(new=TRUE)
# Start new plot
plot.new()
# Set up coordinates on new plot
# (though plot.window() might be better here)
par(usr=c(0,1,0,1))
# Start drawing
box()
points(c(0,1), c(0,1), pch=16, col='red', cex=3)

Is there a good argument against doing that?

Paul

On 15/03/16 10:27, Greg Snow wrote:
> I ran into this issue when trying to modify a subplot (subplot
> function in the TeachingDemos package), but here is a more minimal
> example of the issue (I don't know that it is serious enough to call a
> bug):
>
> This code works how I expect:
>
> dev.new()
> hist(rexp(100))
>
> par(plt=c(0.5,0.9,0.5,0.77), usr=c(0,1,0,1))
>
> box() # show new plt region
> points(c(0,1), c(0,1), pch=16, col='red', cex=3)
>
> it creates a histogram then changes the plotting region so that I can
> add an annotation, changes the user coordinates within the new region,
> then plots some points using the new coordinate system.
>
> But if I change the order of the arguments to par like so:
>
> dev.new()
> hist(rexp(100))
>
> par(usr=c(0,1,0,1), plt=c(0.5,0.9,0.5,0.77))
>
> box() #show new plt region
> points(c(0,1), c(0,1), pch=16, col='red')
>
> then the points do not show up (or if we add xpd=NA to the par call
> then we see them outside of the plotting region).  So clearly the
> behavior of par depends on the order of the arguments specified.
>
> This is not explicitly documented, though there is a hinting at the
> behavior in the note on the par help page (it was following this
> warning that led to me first encountering the issue, since I was
> specifying only the parameters that I needed, not everything, and
> happened to specify usr before plt), but "usr" is not included in the
> list in the note (because it does something different from what the
> note is specifically warning about).
>
>
> I see a few different potential responses to this issue:
>
> 1. consider that this is a rare enough issue that only Greg Snow will
> ever care and he has already learned the lesson, so do nothing (other
> than laugh at Greg when he forgets and has to remember to properly
> order his par arguments).
>
> 2. Since this came up as an issue with subplot, force the author of
> subplot and the TeachingDemos package to add a note or warning to the
> documentation for that function.
>
> 3.  Expand the note on the help page for par (or add another note)
> that warns that the order of the parameters matters and to therefore
> be careful in which order you specify arguments (probably with some
> detail on the suggested ordering).  While there will be many users who
> never read this, we will at least be able to point to the note if
> anyone else is affected by this issue.
>
> 4. Modify the par function to reorder the list created from its args
> so that they are evaluated in a consistent order (and probably add
> documentation to the help page to this effect).
>
>
> Thoughts?
>
>
>
>

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/


From maechler at stat.math.ethz.ch  Tue Mar 15 11:52:38 2016
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 15 Mar 2016 11:52:38 +0100
Subject: [Rd] Regression in strptime
In-Reply-To: <EE281D98-018A-496B-B851-3C89D59BF540@gmail.com>
References: <56E34F4E.30006@oracle.com>
	<7CB65C37-52E1-48E4-9AF9-83FE0BAEFCC8@gmail.com>
	<56E4471B.6020001@oracle.com>
	<EE281D98-018A-496B-B851-3C89D59BF540@gmail.com>
Message-ID: <22247.59766.215169.312799@stat.math.ethz.ch>

>>>>> peter dalgaard <pdalgd at gmail.com>
>>>>>     on Sat, 12 Mar 2016 19:11:40 +0100 writes:

    > OK, .Internal is not necessary to reproduce oddity in this area. I also see things like (notice 1980)
    >> strptime(paste0(sample(1900:1999,80,replace=TRUE),"/01/01"), "%Y/%m/%d", tz="CET")
    ...............

    > The issue seems to be present in R-devel but not in (CRAN) 3.2.0

nor in R 3.2.3 (and earlier), but indeed unfortunately in 3.2.4.

This has been fixed now in  "R 3.2.4 patched"  (and R-devel of course).
Thank you Mick, for the report...
...
...
though I "must" add: If you do have your own tests / checks (as
you said in the OP) and are company as big as Oracle using the
free (in the full sense of "speech" *and* "beer") software R, 
it would be *really* *really* courteous if you did run your test
suite when we announce and release betas or release candidates
("RC") (and in the case of the upcoming yearly release in April,
even "alphas" before them) so we, the R community and the R core
developers could find bugs *before* release. 

Thank you -- and others, please! -- in advance for doing it next time, i.e.,
*now*: The R web page  https://www.r-project.org/  (for a few weeks) has the news

o  R version 3.3.0 (Supposedly Educational) prerelease versions will appear starting Monday 2016-03-14. Final release is scheduled for Thursday 2016-04-14.

Martin Maechler
ETH Zurich (and R Core team)



    >> On 12 Mar 2016, at 17:43 , Mick Jordan <mick.jordan at oracle.com> wrote:
    >> 
    >> On 3/12/16 12:33 AM, peter dalgaard wrote:
    >>>> On 12 Mar 2016, at 00:05 , Mick Jordan <mick.jordan at oracle.com> wrote:
    >>>> 
    >>>> This is definitely obscure but we had a unit test that called .Internal(strptime, "1942/01/01", %Y/%m/%d") with timezone (TZ) set to CET.
    >>> Umm, that doesn't even parse. And fixing the typo, it doesn't run:
    >>> 
    >>>> .Internal(strptime, "1942/01/01", %Y/%m/%d")
    >>> Error: unexpected SPECIAL in ".Internal(strptime, "1942/01/01", %Y/%"
    >>>> .Internal(strptime, "1942/01/01", "%Y/%m/%d")
    >>> Error in .Internal(strptime, "1942/01/01", "%Y/%m/%d") :
    >>> 3 arguments passed to '.Internal' which requires 1
    >>> 
    >>> 
    >>> 
    >>>> In R-3.1.3 that returned "1942-01-01 CEST" which, paradoxically, is correct as they evidently did strange things in Germany during the war period. Java also returns the same. However, R-3.2.4 returns "1942-01-01 CET".
    >>> Did you mean:
    >>> 
    >>> pd$ r-release-branch/BUILD-dist/bin/R
    >>> 
    >>> R version 3.2.4 Patched (2016-03-10 r70319) -- "Very Secure Dishes"
    >>> Copyright (C) 2016 The R Foundation for Statistical Computing
    >>> Platform: x86_64-apple-darwin13.4.0/x86_64 (64-bit)
    >>> [...]
    >>>> strptime("1942/01/01", "%Y/%m/%d", tz="CET")
    >>> [1] "1942-01-01 CEST"
    >>> 
    >>> But then as you see, it does have DST on New Years Day.
    >>> 
    >>> All in all, there is something you are not telling us.
    >>> 
    >>> Notice that all DST information is OS dependent as it depends on which version of the "Olson database" is installed.
    >>> 
    >>> 
    >> You are correct that I was sloppy with syntax for the example. We are, for better or worse, calling the .Internal, but actually with a large vector of arguments, of which the 1942 entry is element 82. I can confirm that for the vector of length 1 example that I didn't test but just assumed would also fail, the answer is correct. However, it is not for the full vector:
    >> 
    >> > .Internal(strptime(argv[[1]], argv[[2]], "CET"))
    >> [1] "1937-01-01 CET" "1916-01-01 CET" "1913-01-01 CET" "1927-01-01 CET"
    >> [5] "1947-01-01 CET" "1913-01-01 CET" "1917-01-01 CET" "1923-01-01 CET"
    >> [9] "1921-01-01 CET" "1926-01-01 CET" "1920-01-01 CET" "1915-01-01 CET"
    >> [13] "1914-01-01 CET" "1914-01-01 CET" "1914-01-01 CET" "1919-01-01 CET"
    >> [17] "1948-01-01 CET" "1911-01-01 CET" "1909-01-01 CET" "1913-01-01 CET"
    >> [21] "1925-01-01 CET" "1926-01-01 CET" "1910-01-01 CET" "1917-01-01 CET"
    >> [25] "1936-01-01 CET" "1938-01-01 CET" "1960-01-01 CET" "1915-01-01 CET"
    >> [29] "1919-01-01 CET" "1924-01-01 CET" "1914-01-01 CET" "1905-01-01 CET"
    >> [33] "1921-01-01 CET" "1929-01-01 CET" "1926-01-01 CET" "1921-01-01 CET"
    >> [37] "1908-01-01 CET" "1928-01-01 CET" "1919-01-01 CET" "1921-01-01 CET"
    >> [41] "1925-01-01 CET" "1934-01-01 CET" "1927-01-01 CET" "1928-01-01 CET"
    >> [45] "1934-01-01 CET" "1922-01-01 CET" "1923-01-01 CET" "1915-01-01 CET"
    >> [49] "1934-01-01 CET" "1925-01-01 CET" "1922-01-01 CET" "1930-01-01 CET"
    >> [53] "1924-01-01 CET" "1923-01-01 CET" "1919-01-01 CET" "1932-01-01 CET"
    >> [57] "1930-01-01 CET" "1923-01-01 CET" "1930-01-01 CET" "1922-01-01 CET"
    >> [61] "1919-01-01 CET" "1932-01-01 CET" "1939-01-01 CET" "1923-01-01 CET"
    >> [65] "1920-01-01 CET" "1919-01-01 CET" "1952-01-01 CET" "1927-01-01 CET"
    >> [69] "1924-01-01 CET" "1919-01-01 CET" "1925-01-01 CET" "1945-01-01 CET"
    >> [73] "1916-01-01 CET" "1943-01-01 CET" "1920-01-01 CET" "1920-01-01 CET"
    >> [77] "1931-01-01 CET" "1924-01-01 CET" "1919-01-01 CET" "1926-01-01 CET"
    >> [81] "1920-01-01 CET" "1942-01-01 CET" "1919-01-01 CET" "1930-01-01 CET"
    >> [85] "1925-01-01 CET" "1924-01-01 CET" "1926-01-01 CET" "1918-01-01 CET"
    >> [89] "1922-01-01 CET" "1921-01-01 CET" "1925-01-01 CET" "1928-01-01 CET"
    >> [93] "1925-01-01 CET" "1929-01-01 CET" "1933-01-01 CET" "1947-01-01 CET"
    >> [97] "1950-01-01 CET" "1945-01-01 CET" "1924-01-01 CET" "1939-01-01 CET"
    >> [101] "1924-01-01 CET" "1933-01-01 CET" "1928-01-01 CET"
    >> > .Internal( strptime("1942/01/01", "%Y/%m/%d", ''))
    >> [1] "1942-01-01 CEST"
    >> > > argv[[1]][[82]]
    >> [1] "1942/01/01"
    >> 
    >> We actually pass "" as the timezone, having set TZ=CET in the shell.
    >> 
    >> I am attaching a file that defines the large vector for sourcing.
    >> 
    >> Mick
    >> 
    >> <pbug.r>

    > -- 
    > Peter Dalgaard, Professor,
    > Center for Statistics, Copenhagen Business School
    > Solbjerg Plads 3, 2000 Frederiksberg, Denmark
    > Phone: (+45)38153501
    > Office: A 4.23
    > Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From lukas.stadler at oracle.com  Tue Mar 15 15:36:03 2016
From: lukas.stadler at oracle.com (Lukas Stadler)
Date: Tue, 15 Mar 2016 15:36:03 +0100
Subject: [Rd] Regression in strptime
In-Reply-To: <22247.59766.215169.312799@stat.math.ethz.ch>
References: <56E34F4E.30006@oracle.com>
	<7CB65C37-52E1-48E4-9AF9-83FE0BAEFCC8@gmail.com>
	<56E4471B.6020001@oracle.com>
	<EE281D98-018A-496B-B851-3C89D59BF540@gmail.com>
	<22247.59766.215169.312799@stat.math.ethz.ch>
Message-ID: <7AFC7C45-1377-4ECC-9253-0A0EE56E949B@oracle.com>

Hi!

Some context for the tests Mick mentioned:
Our tests, which are part of the open-source FastR repository, consist of small executable R snippets.
While working on FastR, we test regularly by comparing the output generated when running them on FastR and GNUR.
Every difference hints at a problem in our implementation of the R language.

FastR, along with the tests, is based on a specific version or R, and every once in a while, we update this R version - we recently went from 3.1.3 to 3.2.4.
This is a complex process: we implement new builtins, modify and update tests, etc.
During that process we need to investigate any new differences that appear, and that?s how the strptime issue came to our attention.

These tests could theoretically also be used to detect changes in behavior between R versions.
It?s not that easy, though, since the output will differ depending on operating systems, compilers, and configuration details.
For FastR, we actually had to choose an platform with which we want to be consistent, because Java, with a tighter spec than C, does not have the same variations.

The set of tests can be seen in this file (which is autogenerated from our junit tests):
https://raw.githubusercontent.com/graalvm/fastr/master/com.oracle.truffle.r.test/src/com/oracle/truffle/r/test/ExpectedTestOutput.test
It?s ~20k individual tests, partly written by hand, partly generated algorithmically, and partly generated by the testR project.

I?ve attached a small script that I just hacked together that runs these tests - it could easily be adapted to compare the output of two different R installations.
Do you think this could be turned into a tool useful for R core development?

- Lukas

-------------- next part --------------

> On 15 Mar 2016, at 11:52, Martin Maechler <maechler at stat.math.ethz.ch> wrote:
> 
>>>>>> peter dalgaard <pdalgd at gmail.com>
>>>>>>    on Sat, 12 Mar 2016 19:11:40 +0100 writes:
> 
>> OK, .Internal is not necessary to reproduce oddity in this area. I also see things like (notice 1980)
>>> strptime(paste0(sample(1900:1999,80,replace=TRUE),"/01/01"), "%Y/%m/%d", tz="CET")
>    ...............
> 
>> The issue seems to be present in R-devel but not in (CRAN) 3.2.0
> 
> nor in R 3.2.3 (and earlier), but indeed unfortunately in 3.2.4.
> 
> This has been fixed now in  "R 3.2.4 patched"  (and R-devel of course).
> Thank you Mick, for the report...
> ...
> ...
> though I "must" add: If you do have your own tests / checks (as
> you said in the OP) and are company as big as Oracle using the
> free (in the full sense of "speech" *and* "beer") software R, 
> it would be *really* *really* courteous if you did run your test
> suite when we announce and release betas or release candidates
> ("RC") (and in the case of the upcoming yearly release in April,
> even "alphas" before them) so we, the R community and the R core
> developers could find bugs *before* release. 
> 
> Thank you -- and others, please! -- in advance for doing it next time, i.e.,
> *now*: The R web page  https://www.r-project.org/  (for a few weeks) has the news
> 
> o  R version 3.3.0 (Supposedly Educational) prerelease versions will appear starting Monday 2016-03-14. Final release is scheduled for Thursday 2016-04-14.
> 
> Martin Maechler
> ETH Zurich (and R Core team)
> 
> 
> 
>>> On 12 Mar 2016, at 17:43 , Mick Jordan <mick.jordan at oracle.com> wrote:
>>> 
>>> On 3/12/16 12:33 AM, peter dalgaard wrote:
>>>>> On 12 Mar 2016, at 00:05 , Mick Jordan <mick.jordan at oracle.com> wrote:
>>>>> 
>>>>> This is definitely obscure but we had a unit test that called .Internal(strptime, "1942/01/01", %Y/%m/%d") with timezone (TZ) set to CET.
>>>> Umm, that doesn't even parse. And fixing the typo, it doesn't run:
>>>> 
>>>>> .Internal(strptime, "1942/01/01", %Y/%m/%d")
>>>> Error: unexpected SPECIAL in ".Internal(strptime, "1942/01/01", %Y/%"
>>>>> .Internal(strptime, "1942/01/01", "%Y/%m/%d")
>>>> Error in .Internal(strptime, "1942/01/01", "%Y/%m/%d") :
>>>> 3 arguments passed to '.Internal' which requires 1
>>>> 
>>>> 
>>>> 
>>>>> In R-3.1.3 that returned "1942-01-01 CEST" which, paradoxically, is correct as they evidently did strange things in Germany during the war period. Java also returns the same. However, R-3.2.4 returns "1942-01-01 CET".
>>>> Did you mean:
>>>> 
>>>> pd$ r-release-branch/BUILD-dist/bin/R
>>>> 
>>>> R version 3.2.4 Patched (2016-03-10 r70319) -- "Very Secure Dishes"
>>>> Copyright (C) 2016 The R Foundation for Statistical Computing
>>>> Platform: x86_64-apple-darwin13.4.0/x86_64 (64-bit)
>>>> [...]
>>>>> strptime("1942/01/01", "%Y/%m/%d", tz="CET")
>>>> [1] "1942-01-01 CEST"
>>>> 
>>>> But then as you see, it does have DST on New Years Day.
>>>> 
>>>> All in all, there is something you are not telling us.
>>>> 
>>>> Notice that all DST information is OS dependent as it depends on which version of the "Olson database" is installed.
>>>> 
>>>> 
>>> You are correct that I was sloppy with syntax for the example. We are, for better or worse, calling the .Internal, but actually with a large vector of arguments, of which the 1942 entry is element 82. I can confirm that for the vector of length 1 example that I didn't test but just assumed would also fail, the answer is correct. However, it is not for the full vector:
>>> 
>>>> .Internal(strptime(argv[[1]], argv[[2]], "CET"))
>>> [1] "1937-01-01 CET" "1916-01-01 CET" "1913-01-01 CET" "1927-01-01 CET"
>>> [5] "1947-01-01 CET" "1913-01-01 CET" "1917-01-01 CET" "1923-01-01 CET"
>>> [9] "1921-01-01 CET" "1926-01-01 CET" "1920-01-01 CET" "1915-01-01 CET"
>>> [13] "1914-01-01 CET" "1914-01-01 CET" "1914-01-01 CET" "1919-01-01 CET"
>>> [17] "1948-01-01 CET" "1911-01-01 CET" "1909-01-01 CET" "1913-01-01 CET"
>>> [21] "1925-01-01 CET" "1926-01-01 CET" "1910-01-01 CET" "1917-01-01 CET"
>>> [25] "1936-01-01 CET" "1938-01-01 CET" "1960-01-01 CET" "1915-01-01 CET"
>>> [29] "1919-01-01 CET" "1924-01-01 CET" "1914-01-01 CET" "1905-01-01 CET"
>>> [33] "1921-01-01 CET" "1929-01-01 CET" "1926-01-01 CET" "1921-01-01 CET"
>>> [37] "1908-01-01 CET" "1928-01-01 CET" "1919-01-01 CET" "1921-01-01 CET"
>>> [41] "1925-01-01 CET" "1934-01-01 CET" "1927-01-01 CET" "1928-01-01 CET"
>>> [45] "1934-01-01 CET" "1922-01-01 CET" "1923-01-01 CET" "1915-01-01 CET"
>>> [49] "1934-01-01 CET" "1925-01-01 CET" "1922-01-01 CET" "1930-01-01 CET"
>>> [53] "1924-01-01 CET" "1923-01-01 CET" "1919-01-01 CET" "1932-01-01 CET"
>>> [57] "1930-01-01 CET" "1923-01-01 CET" "1930-01-01 CET" "1922-01-01 CET"
>>> [61] "1919-01-01 CET" "1932-01-01 CET" "1939-01-01 CET" "1923-01-01 CET"
>>> [65] "1920-01-01 CET" "1919-01-01 CET" "1952-01-01 CET" "1927-01-01 CET"
>>> [69] "1924-01-01 CET" "1919-01-01 CET" "1925-01-01 CET" "1945-01-01 CET"
>>> [73] "1916-01-01 CET" "1943-01-01 CET" "1920-01-01 CET" "1920-01-01 CET"
>>> [77] "1931-01-01 CET" "1924-01-01 CET" "1919-01-01 CET" "1926-01-01 CET"
>>> [81] "1920-01-01 CET" "1942-01-01 CET" "1919-01-01 CET" "1930-01-01 CET"
>>> [85] "1925-01-01 CET" "1924-01-01 CET" "1926-01-01 CET" "1918-01-01 CET"
>>> [89] "1922-01-01 CET" "1921-01-01 CET" "1925-01-01 CET" "1928-01-01 CET"
>>> [93] "1925-01-01 CET" "1929-01-01 CET" "1933-01-01 CET" "1947-01-01 CET"
>>> [97] "1950-01-01 CET" "1945-01-01 CET" "1924-01-01 CET" "1939-01-01 CET"
>>> [101] "1924-01-01 CET" "1933-01-01 CET" "1928-01-01 CET"
>>>> .Internal( strptime("1942/01/01", "%Y/%m/%d", ''))
>>> [1] "1942-01-01 CEST"
>>>>> argv[[1]][[82]]
>>> [1] "1942/01/01"
>>> 
>>> We actually pass "" as the timezone, having set TZ=CET in the shell.
>>> 
>>> I am attaching a file that defines the large vector for sourcing.
>>> 
>>> Mick
>>> 
>>> <pbug.r>
> 
>> -- 
>> Peter Dalgaard, Professor,
>> Center for Statistics, Copenhagen Business School
>> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
>> Phone: (+45)38153501
>> Office: A 4.23
>> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From lukas.stadler at oracle.com  Tue Mar 15 16:25:20 2016
From: lukas.stadler at oracle.com (Lukas Stadler)
Date: Tue, 15 Mar 2016 16:25:20 +0100
Subject: [Rd] Help with libiconv problem
In-Reply-To: <56E74369.6080800@oracle.com>
References: <56E723F3.8040305@oracle.com> <56E74369.6080800@oracle.com>
Message-ID: <3225B82E-CD0E-4861-9EB8-2945BB9AD2A4@oracle.com>


> On 15 Mar 2016, at 0:04, Mick Jordan <mick.jordan at oracle.com> wrote:
> 
> On 3/14/16 1:49 PM, Mick Jordan wrote:
>> A couple of my colleagues are having problems building R-3.2.4 on Mac OS X El Capitan somehow related to libiconv. I personally don't have any problems on either of my Macs. I'm hoping thie make log might trigger something in the readers of this list:
>> 
>> gcc -dynamiclib -Wl,-headerpad_max_install_names -undefined dynamic_lookup -single_module -multiply_defined suppress -L../../../../lib -L/usr/local/lib -o tools.so text.o init.o Rmd5.o md5.o signals.o install.o getfmts.o http.o gramLatex.o gramRd.o -L../../../../lib -lR -Wl,-framework -Wl,CoreFoundation
>> mkdir ../../../../library/tools/libs
>> installing 'sysdata.rda'
>> Warning messages:
>> 1: In strptime(paste(.leap.seconds, "23:59:60"), "%Y-%m-%d %H:%M:%S") :
>>  unknown timezone 'America/Los_Angeles'
>> 2: In strptime(paste(.leap.seconds, "23:59:60"), "%Y-%m-%d %H:%M:%S") :
>>  unknown timezone 'GMT'
>> 3: In strptime(paste(.leap.seconds, "23:59:60"), "%Y-%m-%d %H:%M:%S") :
>>  unknown timezone 'America/New_York'
>> dyld: lazy symbol binding failed: Symbol not found: _libiconv_open
>>  Referenced from: /Users/someone/work/abc/fastr/com.oracle.truffle.r.native/gnur/R-3.2.4/lib/libR.dylib
>>  Expected in: flat namespace
>> 
>> dyld: Symbol not found: _libiconv_open
>>  Referenced from: /Users/someone/work/abc/fastr/com.oracle.truffle.r.native/gnur/R-3.2.4/lib/libR.dylib
>>  Expected in: flat namespace
>> 
>> /bin/sh: line 1: 16127 Done                    echo "tools:::sysdata2LazyLoadDB(\"./R/sysdata.rda\",\"../../../library/tools/R\")"
>>     16128 Trace/BPT trap: 5       | R_DEFAULT_PACKAGES=NULL LC_ALL=C ../../../bin/R --vanilla --slave
>> make[7]: *** [sysdata] Error 133
>> make[6]: *** [all] Error 2
>> make[5]: *** [R] Error 1
>> make[4]: *** [R] Error 1
>> make[3]: *** [R] Error 1
>> 
> This seems to be related to having a macports install of libiconv. The compile step for sysutils.c puts the macport include header before /usr/local/include but the link step for libR doesn't - in fact it doesn't include a -L for the macport directory at all. So there is an an inconsistency in the expected symbols. (Why the macport version defines libiconv_open instead of iconv_open I have no idea).

FWIW, the workaround we now use is to specify -DLIBICONV_PLUG, because then all libiconv variations behave the same.

- Lukas

From 538280 at gmail.com  Tue Mar 15 16:31:18 2016
From: 538280 at gmail.com (Greg Snow)
Date: Tue, 15 Mar 2016 09:31:18 -0600
Subject: [Rd] [FORGED] Different results based on the order of arguments
 to par
In-Reply-To: <56E75FB6.7020808@stat.auckland.ac.nz>
References: <CAFEqCdyG5WRaPkKn9MQ4vyqN5sKpTfbx3AtyEt9_JP6qy51+oA@mail.gmail.com>
	<56E75FB6.7020808@stat.auckland.ac.nz>
Message-ID: <CAFEqCdxki2D5QoRc4+iJpxofvcmY0n2cu0B52GXsMCpHwkrK6Q@mail.gmail.com>

Paul,

I was trying to make a minimal self contained example, but I guess I
went too far on the minimizing.  The original problem came from code
more like:

library(TeachingDemos)

hist(rexp(1000), main='')
abline( v=1, col='red')

sp.par <- subplot(hist(rnorm(100), main=''), x='topright')

op <- par(sp.par[c('usr', 'plt')])
abline(v=0, col='red')
par(op)

and so plot.new, plot.window, etc. are called as part of the sub plot
(specifically by hist(rnorm(100))) and I am trying to go back and add
a reference line to the subplot so the user coordinates need to be set
back to match the subplot (and the plotting region needs to be set so
that the line is clipped appropriately).  With the code as above the
user coordinates are not changed appropriately, in fact if 'xpd=NA' is
added to the par call then the vertical line is added at 0 on the big
histogram, not the little one as planned.

If the order is changed in the call to par ( op <-
par(sp.par[c('plt','usr')]) ) then everything works as planned.  It
just seems a potential danger to have different behavior when the
order of the arguments change without this fact at least documented.

Maybe a warning and additional examples in the subplot documentation
will be sufficient, since nobody else seems to have complained about
this yet.  But, I am vain enough to think that somewhere in the world
there is someone else who will make as stupid a mistake as me, so
wanted to make others aware.  If nothing else, the next person (which
may be forgetful future me) may see this in a search and at least know
to order the arguments correctly.


On Mon, Mar 14, 2016 at 7:04 PM, Paul Murrell <paul at stat.auckland.ac.nz> wrote:
> Hi
>
> I'm going to try to blame user error here.
>
> par(usr) is used to reset the coordinates on the CURRENT plot.
>
> par(plt) is used to specify the location of the NEXT plot.
>
> The correct approach should be to set up the location for the next plot,
> start a new plot, set up coordinates on the new plot.
>
> Neither of your examples performs the "start a new plot" step.
>
> I would expect to see something like ...
>
> dev.new()
> hist(rexp(100))
> # Set up location of new plot
> par(plt=c(0.5,0.9,0.5,0.77))
> # Avoid new page
> par(new=TRUE)
> # Start new plot
> plot.new()
> # Set up coordinates on new plot
> # (though plot.window() might be better here)
> par(usr=c(0,1,0,1))
> # Start drawing
> box()
> points(c(0,1), c(0,1), pch=16, col='red', cex=3)
>
> Is there a good argument against doing that?
>
> Paul
>
>
> On 15/03/16 10:27, Greg Snow wrote:
>>
>> I ran into this issue when trying to modify a subplot (subplot
>> function in the TeachingDemos package), but here is a more minimal
>> example of the issue (I don't know that it is serious enough to call a
>> bug):
>>
>> This code works how I expect:
>>
>> dev.new()
>> hist(rexp(100))
>>
>> par(plt=c(0.5,0.9,0.5,0.77), usr=c(0,1,0,1))
>>
>> box() # show new plt region
>> points(c(0,1), c(0,1), pch=16, col='red', cex=3)
>>
>> it creates a histogram then changes the plotting region so that I can
>> add an annotation, changes the user coordinates within the new region,
>> then plots some points using the new coordinate system.
>>
>> But if I change the order of the arguments to par like so:
>>
>> dev.new()
>> hist(rexp(100))
>>
>> par(usr=c(0,1,0,1), plt=c(0.5,0.9,0.5,0.77))
>>
>> box() #show new plt region
>> points(c(0,1), c(0,1), pch=16, col='red')
>>
>> then the points do not show up (or if we add xpd=NA to the par call
>> then we see them outside of the plotting region).  So clearly the
>> behavior of par depends on the order of the arguments specified.
>>
>> This is not explicitly documented, though there is a hinting at the
>> behavior in the note on the par help page (it was following this
>> warning that led to me first encountering the issue, since I was
>> specifying only the parameters that I needed, not everything, and
>> happened to specify usr before plt), but "usr" is not included in the
>> list in the note (because it does something different from what the
>> note is specifically warning about).
>>
>>
>> I see a few different potential responses to this issue:
>>
>> 1. consider that this is a rare enough issue that only Greg Snow will
>> ever care and he has already learned the lesson, so do nothing (other
>> than laugh at Greg when he forgets and has to remember to properly
>> order his par arguments).
>>
>> 2. Since this came up as an issue with subplot, force the author of
>> subplot and the TeachingDemos package to add a note or warning to the
>> documentation for that function.
>>
>> 3.  Expand the note on the help page for par (or add another note)
>> that warns that the order of the parameters matters and to therefore
>> be careful in which order you specify arguments (probably with some
>> detail on the suggested ordering).  While there will be many users who
>> never read this, we will at least be able to point to the note if
>> anyone else is affected by this issue.
>>
>> 4. Modify the par function to reorder the list created from its args
>> so that they are evaluated in a consistent order (and probably add
>> documentation to the help page to this effect).
>>
>>
>> Thoughts?
>>
>>
>>
>>
>
> --
> Dr Paul Murrell
> Department of Statistics
> The University of Auckland
> Private Bag 92019
> Auckland
> New Zealand
> 64 9 3737599 x85392
> paul at stat.auckland.ac.nz
> http://www.stat.auckland.ac.nz/~paul/



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From pdalgd at gmail.com  Tue Mar 15 17:43:28 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Tue, 15 Mar 2016 17:43:28 +0100
Subject: [Rd] Regression in strptime
In-Reply-To: <22247.59766.215169.312799@stat.math.ethz.ch>
References: <56E34F4E.30006@oracle.com>
	<7CB65C37-52E1-48E4-9AF9-83FE0BAEFCC8@gmail.com>
	<56E4471B.6020001@oracle.com>
	<EE281D98-018A-496B-B851-3C89D59BF540@gmail.com>
	<22247.59766.215169.312799@stat.math.ethz.ch>
Message-ID: <33AF5BC2-AC86-4145-94DD-DE0D2AC78D85@gmail.com>


> On 15 Mar 2016, at 11:52 , Martin Maechler <maechler at stat.math.ethz.ch> wrote:
> 
> 
> o  R version 3.3.0 (Supposedly Educational) prerelease versions will appear starting Monday 2016-03-14. Final release is scheduled for Thursday 2016-04-14.

Oops, that's actually incorrect. It's R-3.2.4-patched for a couple more days. Branching for R-3.3.x happens on Thursday. But R-devel snapshots will be of the same thing until then.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From paul at stat.auckland.ac.nz  Tue Mar 15 21:10:33 2016
From: paul at stat.auckland.ac.nz (Paul Murrell)
Date: Wed, 16 Mar 2016 09:10:33 +1300
Subject: [Rd] [FORGED] Different results based on the order of arguments
 to par
In-Reply-To: <CAFEqCdxki2D5QoRc4+iJpxofvcmY0n2cu0B52GXsMCpHwkrK6Q@mail.gmail.com>
References: <CAFEqCdyG5WRaPkKn9MQ4vyqN5sKpTfbx3AtyEt9_JP6qy51+oA@mail.gmail.com>
	<56E75FB6.7020808@stat.auckland.ac.nz>
	<CAFEqCdxki2D5QoRc4+iJpxofvcmY0n2cu0B52GXsMCpHwkrK6Q@mail.gmail.com>
Message-ID: <56E86C39.5070904@stat.auckland.ac.nz>

Hi

The main issue here is that the 'graphics' package has no real concept 
of going back to a previous plot (the 'grid' package has explicit 
support for that sort of thing).  In 'graphics' you can only go forwards 
to the next plot;  you can fake going back by creating a new plot that 
is like a previous plot.

par(plt=, usr=) is not designed to return you to a previous plot.
If it sounds like I am reluctant to change the behaviour of par(plt=, 
usr=) to support your use case, that is probably because I am.

You could add examples and warnings to subplot() documentation about 
this behaviour, but ideally users would not be encouraged to do this at all.

I would prefer to see something along the lines of ...

   hist(rexp(1000), main='')
   abline( v=1, col='red')

   sp.par <- subplot(hist(rnorm(100), main=''), x='topright')

   subplotadd <- function(fun, pars) {
       par(new=TRUE)
       par(pars['plt'])
       plot.new()
       par(pars['usr'])
       fun
   }

   subplotadd(abline(v=0, col='red'), sp.par)


Paul


On 16/03/16 04:31, Greg Snow wrote:
> Paul,
>
> I was trying to make a minimal self contained example, but I guess I
> went too far on the minimizing.  The original problem came from code
> more like:
>
> library(TeachingDemos)
>
> hist(rexp(1000), main='')
> abline( v=1, col='red')
>
> sp.par <- subplot(hist(rnorm(100), main=''), x='topright')
>
> op <- par(sp.par[c('usr', 'plt')])
> abline(v=0, col='red')
> par(op)
>
> and so plot.new, plot.window, etc. are called as part of the sub plot
> (specifically by hist(rnorm(100))) and I am trying to go back and add
> a reference line to the subplot so the user coordinates need to be set
> back to match the subplot (and the plotting region needs to be set so
> that the line is clipped appropriately).  With the code as above the
> user coordinates are not changed appropriately, in fact if 'xpd=NA' is
> added to the par call then the vertical line is added at 0 on the big
> histogram, not the little one as planned.
>
> If the order is changed in the call to par ( op <-
> par(sp.par[c('plt','usr')]) ) then everything works as planned.  It
> just seems a potential danger to have different behavior when the
> order of the arguments change without this fact at least documented.
>
> Maybe a warning and additional examples in the subplot documentation
> will be sufficient, since nobody else seems to have complained about
> this yet.  But, I am vain enough to think that somewhere in the world
> there is someone else who will make as stupid a mistake as me, so
> wanted to make others aware.  If nothing else, the next person (which
> may be forgetful future me) may see this in a search and at least know
> to order the arguments correctly.
>
>
> On Mon, Mar 14, 2016 at 7:04 PM, Paul Murrell <paul at stat.auckland.ac.nz> wrote:
>> Hi
>>
>> I'm going to try to blame user error here.
>>
>> par(usr) is used to reset the coordinates on the CURRENT plot.
>>
>> par(plt) is used to specify the location of the NEXT plot.
>>
>> The correct approach should be to set up the location for the next plot,
>> start a new plot, set up coordinates on the new plot.
>>
>> Neither of your examples performs the "start a new plot" step.
>>
>> I would expect to see something like ...
>>
>> dev.new()
>> hist(rexp(100))
>> # Set up location of new plot
>> par(plt=c(0.5,0.9,0.5,0.77))
>> # Avoid new page
>> par(new=TRUE)
>> # Start new plot
>> plot.new()
>> # Set up coordinates on new plot
>> # (though plot.window() might be better here)
>> par(usr=c(0,1,0,1))
>> # Start drawing
>> box()
>> points(c(0,1), c(0,1), pch=16, col='red', cex=3)
>>
>> Is there a good argument against doing that?
>>
>> Paul
>>
>>
>> On 15/03/16 10:27, Greg Snow wrote:
>>>
>>> I ran into this issue when trying to modify a subplot (subplot
>>> function in the TeachingDemos package), but here is a more minimal
>>> example of the issue (I don't know that it is serious enough to call a
>>> bug):
>>>
>>> This code works how I expect:
>>>
>>> dev.new()
>>> hist(rexp(100))
>>>
>>> par(plt=c(0.5,0.9,0.5,0.77), usr=c(0,1,0,1))
>>>
>>> box() # show new plt region
>>> points(c(0,1), c(0,1), pch=16, col='red', cex=3)
>>>
>>> it creates a histogram then changes the plotting region so that I can
>>> add an annotation, changes the user coordinates within the new region,
>>> then plots some points using the new coordinate system.
>>>
>>> But if I change the order of the arguments to par like so:
>>>
>>> dev.new()
>>> hist(rexp(100))
>>>
>>> par(usr=c(0,1,0,1), plt=c(0.5,0.9,0.5,0.77))
>>>
>>> box() #show new plt region
>>> points(c(0,1), c(0,1), pch=16, col='red')
>>>
>>> then the points do not show up (or if we add xpd=NA to the par call
>>> then we see them outside of the plotting region).  So clearly the
>>> behavior of par depends on the order of the arguments specified.
>>>
>>> This is not explicitly documented, though there is a hinting at the
>>> behavior in the note on the par help page (it was following this
>>> warning that led to me first encountering the issue, since I was
>>> specifying only the parameters that I needed, not everything, and
>>> happened to specify usr before plt), but "usr" is not included in the
>>> list in the note (because it does something different from what the
>>> note is specifically warning about).
>>>
>>>
>>> I see a few different potential responses to this issue:
>>>
>>> 1. consider that this is a rare enough issue that only Greg Snow will
>>> ever care and he has already learned the lesson, so do nothing (other
>>> than laugh at Greg when he forgets and has to remember to properly
>>> order his par arguments).
>>>
>>> 2. Since this came up as an issue with subplot, force the author of
>>> subplot and the TeachingDemos package to add a note or warning to the
>>> documentation for that function.
>>>
>>> 3.  Expand the note on the help page for par (or add another note)
>>> that warns that the order of the parameters matters and to therefore
>>> be careful in which order you specify arguments (probably with some
>>> detail on the suggested ordering).  While there will be many users who
>>> never read this, we will at least be able to point to the note if
>>> anyone else is affected by this issue.
>>>
>>> 4. Modify the par function to reorder the list created from its args
>>> so that they are evaluated in a consistent order (and probably add
>>> documentation to the help page to this effect).
>>>
>>>
>>> Thoughts?
>>>
>>>
>>>
>>>
>>
>> --
>> Dr Paul Murrell
>> Department of Statistics
>> The University of Auckland
>> Private Bag 92019
>> Auckland
>> New Zealand
>> 64 9 3737599 x85392
>> paul at stat.auckland.ac.nz
>> http://www.stat.auckland.ac.nz/~paul/
>
>
>

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/


From 538280 at gmail.com  Tue Mar 15 22:45:52 2016
From: 538280 at gmail.com (Greg Snow)
Date: Tue, 15 Mar 2016 15:45:52 -0600
Subject: [Rd] [FORGED] Different results based on the order of arguments
 to par
In-Reply-To: <56E86C39.5070904@stat.auckland.ac.nz>
References: <CAFEqCdyG5WRaPkKn9MQ4vyqN5sKpTfbx3AtyEt9_JP6qy51+oA@mail.gmail.com>
	<56E75FB6.7020808@stat.auckland.ac.nz>
	<CAFEqCdxki2D5QoRc4+iJpxofvcmY0n2cu0B52GXsMCpHwkrK6Q@mail.gmail.com>
	<56E86C39.5070904@stat.auckland.ac.nz>
Message-ID: <CAFEqCdyojZkXRFPuaX+7+S7FOgsSGC0sjM0gK-LCms=mjEf6Lg@mail.gmail.com>

Paul,

I am fine with not changing the par function, mainly mentioned it as a
possibility in case someone else saw additional pitfalls, but nobody
else has chimed in.

What are your thoughts on adding an additional note to the help for
par?  it could make it more clear to call things like par(plt= before
plot.new and things like par(usr= after plot.new.

Your subplotadd function works for this case, but I don't want to
think through all the possible combinations of the parameters that may
need to be set depending on what changes are wanted.

I plan to update the help page for subplot to make this more clear for
people coming from that direction, I will probably include an example
like

subplot( {hist(rnorm(100)); abline(v=0, col='red')}, x='topright')

as well to show that if you plan ahead you don't need to go back and
can avoid the whole issue.

Thanks for your comments,


On Tue, Mar 15, 2016 at 2:10 PM, Paul Murrell <paul at stat.auckland.ac.nz> wrote:
> Hi
>
> The main issue here is that the 'graphics' package has no real concept of
> going back to a previous plot (the 'grid' package has explicit support for
> that sort of thing).  In 'graphics' you can only go forwards to the next
> plot;  you can fake going back by creating a new plot that is like a
> previous plot.
>
> par(plt=, usr=) is not designed to return you to a previous plot.
> If it sounds like I am reluctant to change the behaviour of par(plt=, usr=)
> to support your use case, that is probably because I am.
>
> You could add examples and warnings to subplot() documentation about this
> behaviour, but ideally users would not be encouraged to do this at all.
>
> I would prefer to see something along the lines of ...
>
>   hist(rexp(1000), main='')
>   abline( v=1, col='red')
>
>   sp.par <- subplot(hist(rnorm(100), main=''), x='topright')
>
>   subplotadd <- function(fun, pars) {
>       par(new=TRUE)
>       par(pars['plt'])
>       plot.new()
>       par(pars['usr'])
>       fun
>   }
>
>   subplotadd(abline(v=0, col='red'), sp.par)
>
>
> Paul
>
>
>
> On 16/03/16 04:31, Greg Snow wrote:
>>
>> Paul,
>>
>> I was trying to make a minimal self contained example, but I guess I
>> went too far on the minimizing.  The original problem came from code
>> more like:
>>
>> library(TeachingDemos)
>>
>> hist(rexp(1000), main='')
>> abline( v=1, col='red')
>>
>> sp.par <- subplot(hist(rnorm(100), main=''), x='topright')
>>
>> op <- par(sp.par[c('usr', 'plt')])
>> abline(v=0, col='red')
>> par(op)
>>
>> and so plot.new, plot.window, etc. are called as part of the sub plot
>> (specifically by hist(rnorm(100))) and I am trying to go back and add
>> a reference line to the subplot so the user coordinates need to be set
>> back to match the subplot (and the plotting region needs to be set so
>> that the line is clipped appropriately).  With the code as above the
>> user coordinates are not changed appropriately, in fact if 'xpd=NA' is
>> added to the par call then the vertical line is added at 0 on the big
>> histogram, not the little one as planned.
>>
>> If the order is changed in the call to par ( op <-
>> par(sp.par[c('plt','usr')]) ) then everything works as planned.  It
>> just seems a potential danger to have different behavior when the
>> order of the arguments change without this fact at least documented.
>>
>> Maybe a warning and additional examples in the subplot documentation
>> will be sufficient, since nobody else seems to have complained about
>> this yet.  But, I am vain enough to think that somewhere in the world
>> there is someone else who will make as stupid a mistake as me, so
>> wanted to make others aware.  If nothing else, the next person (which
>> may be forgetful future me) may see this in a search and at least know
>> to order the arguments correctly.
>>
>>
>> On Mon, Mar 14, 2016 at 7:04 PM, Paul Murrell <paul at stat.auckland.ac.nz>
>> wrote:
>>>
>>> Hi
>>>
>>> I'm going to try to blame user error here.
>>>
>>> par(usr) is used to reset the coordinates on the CURRENT plot.
>>>
>>> par(plt) is used to specify the location of the NEXT plot.
>>>
>>> The correct approach should be to set up the location for the next plot,
>>> start a new plot, set up coordinates on the new plot.
>>>
>>> Neither of your examples performs the "start a new plot" step.
>>>
>>> I would expect to see something like ...
>>>
>>> dev.new()
>>> hist(rexp(100))
>>> # Set up location of new plot
>>> par(plt=c(0.5,0.9,0.5,0.77))
>>> # Avoid new page
>>> par(new=TRUE)
>>> # Start new plot
>>> plot.new()
>>> # Set up coordinates on new plot
>>> # (though plot.window() might be better here)
>>> par(usr=c(0,1,0,1))
>>> # Start drawing
>>> box()
>>> points(c(0,1), c(0,1), pch=16, col='red', cex=3)
>>>
>>> Is there a good argument against doing that?
>>>
>>> Paul
>>>
>>>
>>> On 15/03/16 10:27, Greg Snow wrote:
>>>>
>>>>
>>>> I ran into this issue when trying to modify a subplot (subplot
>>>> function in the TeachingDemos package), but here is a more minimal
>>>> example of the issue (I don't know that it is serious enough to call a
>>>> bug):
>>>>
>>>> This code works how I expect:
>>>>
>>>> dev.new()
>>>> hist(rexp(100))
>>>>
>>>> par(plt=c(0.5,0.9,0.5,0.77), usr=c(0,1,0,1))
>>>>
>>>> box() # show new plt region
>>>> points(c(0,1), c(0,1), pch=16, col='red', cex=3)
>>>>
>>>> it creates a histogram then changes the plotting region so that I can
>>>> add an annotation, changes the user coordinates within the new region,
>>>> then plots some points using the new coordinate system.
>>>>
>>>> But if I change the order of the arguments to par like so:
>>>>
>>>> dev.new()
>>>> hist(rexp(100))
>>>>
>>>> par(usr=c(0,1,0,1), plt=c(0.5,0.9,0.5,0.77))
>>>>
>>>> box() #show new plt region
>>>> points(c(0,1), c(0,1), pch=16, col='red')
>>>>
>>>> then the points do not show up (or if we add xpd=NA to the par call
>>>> then we see them outside of the plotting region).  So clearly the
>>>> behavior of par depends on the order of the arguments specified.
>>>>
>>>> This is not explicitly documented, though there is a hinting at the
>>>> behavior in the note on the par help page (it was following this
>>>> warning that led to me first encountering the issue, since I was
>>>> specifying only the parameters that I needed, not everything, and
>>>> happened to specify usr before plt), but "usr" is not included in the
>>>> list in the note (because it does something different from what the
>>>> note is specifically warning about).
>>>>
>>>>
>>>> I see a few different potential responses to this issue:
>>>>
>>>> 1. consider that this is a rare enough issue that only Greg Snow will
>>>> ever care and he has already learned the lesson, so do nothing (other
>>>> than laugh at Greg when he forgets and has to remember to properly
>>>> order his par arguments).
>>>>
>>>> 2. Since this came up as an issue with subplot, force the author of
>>>> subplot and the TeachingDemos package to add a note or warning to the
>>>> documentation for that function.
>>>>
>>>> 3.  Expand the note on the help page for par (or add another note)
>>>> that warns that the order of the parameters matters and to therefore
>>>> be careful in which order you specify arguments (probably with some
>>>> detail on the suggested ordering).  While there will be many users who
>>>> never read this, we will at least be able to point to the note if
>>>> anyone else is affected by this issue.
>>>>
>>>> 4. Modify the par function to reorder the list created from its args
>>>> so that they are evaluated in a consistent order (and probably add
>>>> documentation to the help page to this effect).
>>>>
>>>>
>>>> Thoughts?
>>>>
>>>>
>>>>
>>>>
>>>
>>> --
>>> Dr Paul Murrell
>>> Department of Statistics
>>> The University of Auckland
>>> Private Bag 92019
>>> Auckland
>>> New Zealand
>>> 64 9 3737599 x85392
>>> paul at stat.auckland.ac.nz
>>> http://www.stat.auckland.ac.nz/~paul/
>>
>>
>>
>>
>
> --
> Dr Paul Murrell
> Department of Statistics
> The University of Auckland
> Private Bag 92019
> Auckland
> New Zealand
> 64 9 3737599 x85392
> paul at stat.auckland.ac.nz
> http://www.stat.auckland.ac.nz/~paul/



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From mick.jordan at oracle.com  Wed Mar 16 03:50:48 2016
From: mick.jordan at oracle.com (Mick Jordan)
Date: Tue, 15 Mar 2016 19:50:48 -0700
Subject: [Rd] Regression in strptime
In-Reply-To: <22247.59766.215169.312799@stat.math.ethz.ch>
References: <56E34F4E.30006@oracle.com>
	<7CB65C37-52E1-48E4-9AF9-83FE0BAEFCC8@gmail.com>
	<56E4471B.6020001@oracle.com>
	<EE281D98-018A-496B-B851-3C89D59BF540@gmail.com>
	<22247.59766.215169.312799@stat.math.ethz.ch>
Message-ID: <56E8CA08.6080301@oracle.com>

On 3/15/16 3:52 AM, Martin Maechler wrote:
>>>>>> peter dalgaard <pdalgd at gmail.com>
>>>>>>      on Sat, 12 Mar 2016 19:11:40 +0100 writes:
>      > OK, .Internal is not necessary to reproduce oddity in this area. I also see things like (notice 1980)
>      >> strptime(paste0(sample(1900:1999,80,replace=TRUE),"/01/01"), "%Y/%m/%d", tz="CET")
>      ...............
>
>      > The issue seems to be present in R-devel but not in (CRAN) 3.2.0
>
> nor in R 3.2.3 (and earlier), but indeed unfortunately in 3.2.4.
>
> This has been fixed now in  "R 3.2.4 patched"  (and R-devel of course).
> Thank you Mick, for the report...
> ...
> ...
> though I "must" add: If you do have your own tests / checks (as
> you said in the OP) and are company as big as Oracle using the
> free (in the full sense of "speech" *and* "beer") software R,
> it would be *really* *really* courteous if you did run your test
> suite when we announce and release betas or release candidates
> ("RC") (and in the case of the upcoming yearly release in April,
> even "alphas" before them) so we, the R community and the R core
> developers could find bugs *before* release.
>
>
Following up on Lukas's explanatory message, we will try to sync up with 
R releases on a more regular schedule from now on, even if we don't 
actually push FastR based on that version. So we should discover test 
regressions earlier.

Mick


From hpages at fredhutch.org  Wed Mar 16 08:39:07 2016
From: hpages at fredhutch.org (=?UTF-8?B?SGVydsOpIFBhZ8Oocw==?=)
Date: Wed, 16 Mar 2016 00:39:07 -0700
Subject: [Rd] print( , right=TRUE) displays the col numbers on the left
Message-ID: <56E90D9B.7060603@fredhutch.org>

Hi,

I noticed that when using print( , right=TRUE) on a character
matrix with no colnames, the col numbers get displayed on the
left of each column:

 > m <- matrix(rep(c("XXXXXX", "XXXX"), 6), ncol=3)

 > print(m, right=FALSE)
      [,1]     [,2]     [,3]
[1,] "XXXXXX" "XXXXXX" "XXXXXX"
[2,] "XXXX"   "XXXX"   "XXXX"
[3,] "XXXXXX" "XXXXXX" "XXXXXX"
[4,] "XXXX"   "XXXX"   "XXXX"

 > print(m, right=TRUE)
      [,1]     [,2]     [,3]
[1,] "XXXXXX" "XXXXXX" "XXXXXX"
[2,]   "XXXX"   "XXXX"   "XXXX"
[3,] "XXXXXX" "XXXXXX" "XXXXXX"
[4,]   "XXXX"   "XXXX"   "XXXX"

OTOH if the matrix has colnames, they do get displayed on the
right of each column when 'right=TRUE':

 > colnames(m) <- letters[1:3]

 > print(m, right=FALSE)
      a        b        c
[1,] "XXXXXX" "XXXXXX" "XXXXXX"
[2,] "XXXX"   "XXXX"   "XXXX"
[3,] "XXXXXX" "XXXXXX" "XXXXXX"
[4,] "XXXX"   "XXXX"   "XXXX"

 > print(m, right=TRUE)
             a        b        c
[1,] "XXXXXX" "XXXXXX" "XXXXXX"
[2,]   "XXXX"   "XXXX"   "XXXX"
[3,] "XXXXXX" "XXXXXX" "XXXXXX"
[4,]   "XXXX"   "XXXX"   "XXXX"

That looks better!

Shouldn't the same happen for the col numbers when 'right=TRUE'?

Thanks,
H.

 > sessionInfo()
R Under development (unstable) (2016-01-07 r69884)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 14.04.4 LTS

locale:
  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
  [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base


-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fredhutch.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From maechler at stat.math.ethz.ch  Wed Mar 16 11:35:04 2016
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 16 Mar 2016 11:35:04 +0100
Subject: [Rd] Regression in strptime
In-Reply-To: <56E8CA08.6080301@oracle.com>
References: <56E34F4E.30006@oracle.com>
	<7CB65C37-52E1-48E4-9AF9-83FE0BAEFCC8@gmail.com>
	<56E4471B.6020001@oracle.com>
	<EE281D98-018A-496B-B851-3C89D59BF540@gmail.com>
	<22247.59766.215169.312799@stat.math.ethz.ch>
	<56E8CA08.6080301@oracle.com>
Message-ID: <22249.14040.401149.819154@stat.math.ethz.ch>

>>>>> Mick Jordan <mick.jordan at oracle.com>
>>>>>     on Tue, 15 Mar 2016 19:50:48 -0700 writes:

    > On 3/15/16 3:52 AM, Martin Maechler wrote:
    >>>>>>> peter dalgaard <pdalgd at gmail.com>
    >>>>>>> on Sat, 12 Mar 2016 19:11:40 +0100 writes:
    >> > OK, .Internal is not necessary to reproduce oddity in this area. I also see things like (notice 1980)
    >> >> strptime(paste0(sample(1900:1999,80,replace=TRUE),"/01/01"), "%Y/%m/%d", tz="CET")
    >> ...............
    >> 
    >> > The issue seems to be present in R-devel but not in (CRAN) 3.2.0
    >> 
    >> nor in R 3.2.3 (and earlier), but indeed unfortunately in 3.2.4.
    >> 
    >> This has been fixed now in  "R 3.2.4 patched"  (and R-devel of course).
    >> Thank you Mick, for the report...
    >> ...
    >> ...
    >> though I "must" add: If you do have your own tests / checks (as
    >> you said in the OP) and are company as big as Oracle using the
    >> free (in the full sense of "speech" *and* "beer") software R,
    >> it would be *really* *really* courteous if you did run your test
    >> suite when we announce and release betas or release candidates
    >> ("RC") (and in the case of the upcoming yearly release in April,
    >> even "alphas" before them) so we, the R community and the R core
    >> developers could find bugs *before* release.
    >> 
    >> 
    > Following up on Lukas's explanatory message, we will try to sync up with 
    > R releases on a more regular schedule from now on, even if we don't 
    > actually push FastR based on that version. So we should discover test 
    > regressions earlier.

Thank you, Mick and Lukas, in advance!

Note that my "admonition"  was not at all aimed at you /
Oracle in particular, but rather to the general (advanced, as in
"R-devel") R public: 

Free Software projects such as R have traditionally very much
profited from volunteer beta testers, and we, R core, are trying
to get more beta testers (on an informal basis, still) than we
currently seem to have.

Best regards,
Martin Maechler


From therneau at mayo.edu  Wed Mar 16 16:03:58 2016
From: therneau at mayo.edu (Therneau, Terry M., Ph.D.)
Date: Wed, 16 Mar 2016 10:03:58 -0500
Subject: [Rd] match and unique
Message-ID: <519743$2l7cj3@ironport10.mayo.edu>

Is the phrase  "index <- match(x, sort(unique(x)))" reliable, in the sense that it will 
never return NA?

Context: Calculation of survival curves involves the concept of unique death times.  I've 
had reported cases in the past where survfit failed, and it was due to the fact that two 
"differ by machine precision" values would sometimes match and sometimes not, depending on 
how I compared them.  I've dealt with those piecemeal in the past, but am going to do a 
code review and make sure that I do things consistently throughout the survival package.  
The basic plan will be to change time to an integer, do all the work, then restore labels 
at the end.  The above line is one candidate for the first step.

An alternative is index <- as.numeric(factor(x)), with as.numeric(levels(factor(x))) as 
the final labeling step.  This is a more severe rounding, is it not?  But perhaps it is 
preferable? The KM branch of the current survfit routine does this, and I've had one user 
report a bug in that
     x <- runif(20)
     fit <- survfit(Surv(x) ~1)
     summary(fit, times=x)
will produce lines with 0, 1 or 2 events when "they all should be 1".

The same issue just came up in an rpart example, sent to me.  For coxph models is may only 
be a matter of time.

Suggestions and opinions are welcome.

Terry Therneau


From wdunlap at tibco.com  Wed Mar 16 16:59:46 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 16 Mar 2016 08:59:46 -0700
Subject: [Rd] keepNA in nchar and nzchar
Message-ID: <CAF8bMcaL8_E96qqyQFUkb5Xpvsi+iYMt-gUyAqipTkK0OXSqUA@mail.gmail.com>

Is it intended that in yesterday's version of R-devel the default value of
keepNA is different in nchar (NA) and nzchar (FALSE)?

  > args(nchar)
  function (x, type = "chars", allowNA = FALSE, keepNA = NA)
  NULL
  > args(nzchar)
  function (x, keepNA = FALSE)
  NULL

Is it intended that for keepNA=NA, nchar and nzchar do not
give concordant results?

  > vapply(c(TRUE, FALSE, NA), function(keepNA) nchar(NA_character_,
keepNA=keepNA), FUN.VALUE=integer(1))
  [1] NA  2 NA
  > vapply(c(TRUE, FALSE, NA), function(keepNA) nzchar(NA_character_,
keepNA=keepNA), FUN.VALUE=logical(1))
  [1]   NA TRUE TRUE

> version$version.string
[1] "R Under development (unstable) (2016-03-15 r70334)"

Bill Dunlap
TIBCO Software
wdunlap tibco.com

	[[alternative HTML version deleted]]


From hpages at fredhutch.org  Thu Mar 17 21:20:57 2016
From: hpages at fredhutch.org (=?UTF-8?B?SGVydsOpIFBhZ8Oocw==?=)
Date: Thu, 17 Mar 2016 13:20:57 -0700
Subject: [Rd] match and unique
In-Reply-To: <519743$2l7cj3@ironport10.mayo.edu>
References: <519743$2l7cj3@ironport10.mayo.edu>
Message-ID: <56EB11A9.5010405@fredhutch.org>

Hi Terry,

On 03/16/2016 08:03 AM, Therneau, Terry M., Ph.D. wrote:
> Is the phrase  "index <- match(x, sort(unique(x)))" reliable, in the
> sense that it will never return NA?

This is assuming that match() and unique() will never disagree on
equality between 2 floating point values. I believe they share some
code internally (same hashing routine?), so maybe it's reliable.

Anyway, it's always preferable to not rely on this kind of assumption.

A safer thing to do is to use rank():

   r <- rank(x, ties.method="min")  # could use "max"

Think of 'r' as a unique ID assigned to each value in 'x'. This ID takes
its values in the (1,length(x)) range but we want it to take its values
in the (1,length(unique(x))) range:

   ID_remapping <- cumsum(tabulate(r, nbins=length(r)) != 0L)
   index <- ID_remapping[r]

'index' will be the same as 'match(x, sort(unique(x))' but doesn't rely
on the assumption that match() and unique() agree on equality between
2 floating point values.

Unfortunately rank() is very slow, much slower than sort(). Here is a
faster solution based on sort.list(x, na.last=NA, method="quick"):

   assignID <- function(x)
   {
     oo <- sort.list(x, na.last=NA, method="quick")
     sorted <- x[oo]
     is_unique <- c(TRUE, sorted[-length(sorted)] != sorted[-1L])
     sorted_ID <- cumsum(is_unique)
     ID <- integer(length(x))
     ID[oo] <- sorted_ID
     ID
   }

'assignID(x)' is also slightly faster than 'match(x, sort(unique(x)))':

   x <- runif(5000000)
   system.time(index1 <- match(x, sort(unique(x))))
   #   user  system elapsed
   #  2.170   0.552   2.725

   system.time(index2 <- assignID(x))
   #   user  system elapsed
   #  0.885   0.032   0.917

   identical(index1, index2)
   # [1] TRUE

Cheers,
H.

>
> Context: Calculation of survival curves involves the concept of unique
> death times.  I've had reported cases in the past where survfit failed,
> and it was due to the fact that two "differ by machine precision" values
> would sometimes match and sometimes not, depending on how I compared
> them.  I've dealt with those piecemeal in the past, but am going to do a
> code review and make sure that I do things consistently throughout the
> survival package. The basic plan will be to change time to an integer,
> do all the work, then restore labels at the end.  The above line is one
> candidate for the first step.
>
> An alternative is index <- as.numeric(factor(x)), with
> as.numeric(levels(factor(x))) as the final labeling step.  This is a
> more severe rounding, is it not?  But perhaps it is preferable? The KM
> branch of the current survfit routine does this, and I've had one user
> report a bug in that
>      x <- runif(20)
>      fit <- survfit(Surv(x) ~1)
>      summary(fit, times=x)
> will produce lines with 0, 1 or 2 events when "they all should be 1".
>
> The same issue just came up in an rpart example, sent to me.  For coxph
> models is may only be a matter of time.
>
> Suggestions and opinions are welcome.
>
> Terry Therneau
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fredhutch.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From therneau at mayo.edu  Thu Mar 17 22:37:45 2016
From: therneau at mayo.edu (Therneau, Terry M., Ph.D.)
Date: Thu, 17 Mar 2016 16:37:45 -0500
Subject: [Rd] match and unique
In-Reply-To: <56EB11A9.5010405@fredhutch.org>
References: <519743$2l7cj3@ironport10.mayo.edu>
	<56EB11A9.5010405@fredhutch.org>
Message-ID: <519743$2llmco@ironport10.mayo.edu>

Herve,
   Thank you for the insightful response.  It led to the following check:

> set.seed(1953)  # a good year...
> x <- runif(5e6)
> ux <- sort(unique(x))
> length(ux)
[1] 4997142

> table(is.na(match(x, ux))
   FALSE
5000000

> index1 <- match(x, ux)
> index2 <- findInterval(x, ux)
> all.equal(index1, index2)
[1] TRUE

> length(levels(factor(x)))
[1] 999885

--------------------------

1.  At the terminal, the factor command was definitely the slowest, everything else was 
quite reasonable for 1 million values, which is larger than I expect for a survival curve.

2. The match and unique functions agreed for this data set, but you are correct that this 
is not guarranteed.  The findInterval command will alleviate this.

3. Factor has the advantage of documented behavior, via its call to as.character.  The 
conversion to and from character is likely what slows it down.

Terry



On 03/17/2016 03:20 PM, Herv? Pag?s wrote:
> Hi Terry,
>
> On 03/16/2016 08:03 AM, Therneau, Terry M., Ph.D. wrote:
>> Is the phrase  "index <- match(x, sort(unique(x)))" reliable, in the
>> sense that it will never return NA?
>
> This is assuming that match() and unique() will never disagree on
> equality between 2 floating point values. I believe they share some
> code internally (same hashing routine?), so maybe it's reliable.
>
> Anyway, it's always preferable to not rely on this kind of assumption.
>
> A safer thing to do is to use rank():
>
>    r <- rank(x, ties.method="min")  # could use "max"
>
> Think of 'r' as a unique ID assigned to each value in 'x'. This ID takes
> its values in the (1,length(x)) range but we want it to take its values
> in the (1,length(unique(x))) range:
>
>    ID_remapping <- cumsum(tabulate(r, nbins=length(r)) != 0L)
>    index <- ID_remapping[r]
>
> 'index' will be the same as 'match(x, sort(unique(x))' but doesn't rely
> on the assumption that match() and unique() agree on equality between
> 2 floating point values.
>
> Unfortunately rank() is very slow, much slower than sort(). Here is a
> faster solution based on sort.list(x, na.last=NA, method="quick"):
>
>    assignID <- function(x)
>    {
>      oo <- sort.list(x, na.last=NA, method="quick")
>      sorted <- x[oo]
>      is_unique <- c(TRUE, sorted[-length(sorted)] != sorted[-1L])
>      sorted_ID <- cumsum(is_unique)
>      ID <- integer(length(x))
>      ID[oo] <- sorted_ID
>      ID
>    }
>
> 'assignID(x)' is also slightly faster than 'match(x, sort(unique(x)))':
>
>    x <- runif(5000000)
>    system.time(index1 <- match(x, sort(unique(x))))
>    #   user  system elapsed
>    #  2.170   0.552   2.725
>
>    system.time(index2 <- assignID(x))
>    #   user  system elapsed
>    #  0.885   0.032   0.917
>
>    identical(index1, index2)
>    # [1] TRUE
>
> Cheers,
> H.
>
>>
>> Context: Calculation of survival curves involves the concept of unique
>> death times.  I've had reported cases in the past where survfit failed,
>> and it was due to the fact that two "differ by machine precision" values
>> would sometimes match and sometimes not, depending on how I compared
>> them.  I've dealt with those piecemeal in the past, but am going to do a
>> code review and make sure that I do things consistently throughout the
>> survival package. The basic plan will be to change time to an integer,
>> do all the work, then restore labels at the end.  The above line is one
>> candidate for the first step.
>>
>> An alternative is index <- as.numeric(factor(x)), with
>> as.numeric(levels(factor(x))) as the final labeling step.  This is a
>> more severe rounding, is it not?  But perhaps it is preferable? The KM
>> branch of the current survfit routine does this, and I've had one user
>> report a bug in that
>>      x <- runif(20)
>>      fit <- survfit(Surv(x) ~1)
>>      summary(fit, times=x)
>> will produce lines with 0, 1 or 2 events when "they all should be 1".
>>
>> The same issue just came up in an rpart example, sent to me.  For coxph
>> models is may only be a matter of time.
>>
>> Suggestions and opinions are welcome.
>>
>> Terry Therneau
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From lukas.stadler at oracle.com  Fri Mar 18 11:09:56 2016
From: lukas.stadler at oracle.com (Lukas Stadler)
Date: Fri, 18 Mar 2016 11:09:56 +0100
Subject: [Rd] formatting of complex matrix
Message-ID: <691AF49D-88A3-4FE5-B66A-8F99347B0F74@oracle.com>

While working on the printing code, my colleague Zbyn?k ?lajchrt noticed that complex matrixes are sometimes misaligned:

> { matrix(1i,2,13) }
     [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13]
[1,] 0+1i 0+1i 0+1i 0+1i 0+1i 0+1i 0+1i 0+1i 0+1i 0+1i 0+1i 0+1i 0+1i
[2,] 0+1i 0+1i 0+1i 0+1i 0+1i 0+1i 0+1i 0+1i 0+1i 0+1i 0+1i 0+1i 0+1i

(the values in the last four columns should be prefixed by two spaces instead of one)
while the formatting is fine, e.g., for real values:

> { matrix(1,2,13) }
     [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13]
[1,]    1    1    1    1    1    1    1    1    1     1     1     1     1
[2,]    1    1    1    1    1    1    1    1    1     1     1     1     1

The problem seems to be in printarray.c:275 (https://github.com/wch/r-source/blob/trunk/src/main/printarray.c#L275):
EncodeComplex(x[i + j * r],
    wr[j] + R_print.gap, dr[j], er[j],
    wi[j], di[j], ei[j], OutDec)) )

The width of the real part wr[j] + the width of the imaginary part wi[j] + R_print.gap doesn?t always add up to the width of the column w[j].

As far as we can see, calculating the width of the real part on the fly fixes the problem:
EncodeComplex(x[i + j * r],
    w[j] - wi[j] - 2, dr[j], er[j],
    wi[j], di[j], ei[j], OutDec)) )

Regards,
 Lukas
	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Fri Mar 18 11:24:08 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 18 Mar 2016 06:24:08 -0400
Subject: [Rd] formatting of complex matrix
In-Reply-To: <691AF49D-88A3-4FE5-B66A-8F99347B0F74@oracle.com>
References: <691AF49D-88A3-4FE5-B66A-8F99347B0F74@oracle.com>
Message-ID: <56EBD748.204@gmail.com>

On 18/03/2016 6:09 AM, Lukas Stadler wrote:
> While working on the printing code, my colleague Zbyn?k ?lajchrt noticed that complex matrixes are sometimes misaligned:
>
>> { matrix(1i,2,13) }
>       [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13]
> [1,] 0+1i 0+1i 0+1i 0+1i 0+1i 0+1i 0+1i 0+1i 0+1i 0+1i 0+1i 0+1i 0+1i
> [2,] 0+1i 0+1i 0+1i 0+1i 0+1i 0+1i 0+1i 0+1i 0+1i 0+1i 0+1i 0+1i 0+1i
>
> (the values in the last four columns should be prefixed by two spaces instead of one)
> while the formatting is fine, e.g., for real values:
>
>> { matrix(1,2,13) }
>       [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13]
> [1,]    1    1    1    1    1    1    1    1    1     1     1     1     1
> [2,]    1    1    1    1    1    1    1    1    1     1     1     1     1
>
> The problem seems to be in printarray.c:275 (https://github.com/wch/r-source/blob/trunk/src/main/printarray.c#L275):
> EncodeComplex(x[i + j * r],
>      wr[j] + R_print.gap, dr[j], er[j],
>      wi[j], di[j], ei[j], OutDec)) )
>
> The width of the real part wr[j] + the width of the imaginary part wi[j] + R_print.gap doesn?t always add up to the width of the column w[j].
>
> As far as we can see, calculating the width of the real part on the fly fixes the problem:
> EncodeComplex(x[i + j * r],
>      w[j] - wi[j] - 2, dr[j], er[j],
>      wi[j], di[j], ei[j], OutDec)) )

Thanks, I'll take a look.

Duncan Murdoch


From ggrothendieck at gmail.com  Fri Mar 18 15:25:42 2016
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 18 Mar 2016 10:25:42 -0400
Subject: [Rd] for in r-devel
Message-ID: <CAP01uRmNXTg1Qb+8j5vMi2akOqRCQ4Yz6Gt_r=Q3=CHCDdVNWQ@mail.gmail.com>

Regarding, this news item for r-devel:

?for()? loops are generalized to iterate over any object with ?[[? and
?length()? methods. Thanks to Herv? Pag?s for the idea and the patch.

Below dd is an object for which [[ and length work but the result is
still numeric rather than Date class in  "R Under development
(unstable) (2016-03-15 r70334)" as observed in the comments to:
http://stackoverflow.com/questions/36074344/why-does-for-convert-date-to-numeric#comment59794873_36074344
Expanding on that:

    dd <- Sys.Date() + 0:1

    dd[[1]]  # [[ works
    ## [1] "2016-03-18"

    length(dd)  # length works
    ## [1]  2

    for(d in dd) str(d)  # gives numeric rather than Date class
    ## num 16878
    ## num 16879


-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From lawrence.michael at gene.com  Fri Mar 18 16:03:21 2016
From: lawrence.michael at gene.com (Michael Lawrence)
Date: Fri, 18 Mar 2016 08:03:21 -0700
Subject: [Rd] for in r-devel
In-Reply-To: <CAP01uRmNXTg1Qb+8j5vMi2akOqRCQ4Yz6Gt_r=Q3=CHCDdVNWQ@mail.gmail.com>
References: <CAP01uRmNXTg1Qb+8j5vMi2akOqRCQ4Yz6Gt_r=Q3=CHCDdVNWQ@mail.gmail.com>
Message-ID: <CAOQ5NyfRzmL8VVQBEuUmxnDY0E1aRKg8qNYky5iCjvARaugFTg@mail.gmail.com>

Thanks for pointing this out. The commit you cite was reverted a couple
days later, because we are still thinking about how it should work. While
it appears Date would benefit, weird things happen e.g. with POSIXlt and
other data structures in the wild. This is due to inconsistency in the
behaviors of length() and [[() methods. One thought is introducing a
generic that coerces to something with consistent behavior, e.g.
iterable(). We were even thinking that an iterable might be allowed to
return NA for length, in which case it would need to support methods like
next() and hasNext(). Ideas welcome.

Michael





On Fri, Mar 18, 2016 at 7:25 AM, Gabor Grothendieck <ggrothendieck at gmail.com
> wrote:

> Regarding, this news item for r-devel:
>
> ?for()? loops are generalized to iterate over any object with ?[[? and
> ?length()? methods. Thanks to Herv? Pag?s for the idea and the patch.
>
> Below dd is an object for which [[ and length work but the result is
> still numeric rather than Date class in  "R Under development
> (unstable) (2016-03-15 r70334)" as observed in the comments to:
>
> http://stackoverflow.com/questions/36074344/why-does-for-convert-date-to-numeric#comment59794873_36074344
> Expanding on that:
>
>     dd <- Sys.Date() + 0:1
>
>     dd[[1]]  # [[ works
>     ## [1] "2016-03-18"
>
>     length(dd)  # length works
>     ## [1]  2
>
>     for(d in dd) str(d)  # gives numeric rather than Date class
>     ## num 16878
>     ## num 16879
>
>
> --
> Statistics & Software Consulting
> GKX Group, GKX Associates Inc.
> tel: 1-877-GKX-GROUP
> email: ggrothendieck at gmail.com
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

	[[alternative HTML version deleted]]


From hpages at fredhutch.org  Fri Mar 18 22:53:30 2016
From: hpages at fredhutch.org (=?UTF-8?B?SGVydsOpIFBhZ8Oocw==?=)
Date: Fri, 18 Mar 2016 14:53:30 -0700
Subject: [Rd] unary class union of an S3 class
Message-ID: <56EC78DA.2010803@fredhutch.org>

Hi,

Short story
-----------

   setClassUnion("ArrayLike", "array")

   showClass("ArrayLike")  # no slot

   setClass("MyArrayLikeConcreteSubclass",
       contains="ArrayLike",
       representation(stuff="ANY")
   )

   showClass("MyArrayLikeConcreteSubclass") # 2 slots!!

That doesn't seem right.

Long story
----------

S4 provides at least 3 ways to create a little class hierarchy
like this:

        FooLike ............. virtual class with no slot
         ^   ^
         |   |
       foo   anotherfoo ..... 2 concrete subclasses

(1) The "standard" way: define FooLike first, then foo and anotherfoo
as subclasses of FooLike:

   setClass("FooLike")

   setClass("foo",
       contains="FooLike",
       representation(stuff="ANY")
   )

   setClass("anotherfoo",
       contains="FooLike",
       representation(stuff="ANY")
   )

   showClass("FooLike")    # displays foo and anotherfoo as
                           # known subclasses

   x1 <- new("foo")
   is(x1, "foo")           # TRUE
   is(x1, "FooLike")       # TRUE
   is(x1, "anotherfoo")    # FALSE

   x2 <- new("anotherfoo")
   is(x2, "anotherfoo")    # TRUE
   is(x2, "FooLike")       # TRUE
   is(x2, "foo")           # FALSE

Everything works as expected.

(2) Using a class union: define foo and anotherfoo first, then FooLike
as the union of foo and anotherfoo:

   setClass("foo", representation(stuff="ANY"))
   setClass("anotherfoo", representation(stuff="ANY"))
   setClassUnion("FooLike", c("foo", "anotherfoo"))

   showClass("FooLike")    # displays foo and anotherfoo as
                           # known subclasses

(3) Using a *unary* class union: define foo first, then FooLike as the
(unary) union of foo, then anotherfoo as a subclass of FooLike:

   setClass("foo", representation(stuff="ANY"))
   setClassUnion("FooLike", "foo")

   showClass("FooLike")   # displays foo as the only known subclass

   setClass("anotherfoo",
       contains="FooLike",
       representation(stuff="ANY")
   )

   showClass("FooLike")   # now displays foo and anotherfoo as
                          # known subclasses

The 3 ways lead to the same hierarchy. However the 3rd way is
interesting because it allows one to define the FooLike virtual
class as the parent of an existing foo class that s/he doesn't
control.

For example, to define an ArrayLike class:

   setClassUnion("ArrayLike", "array")
   showClass("ArrayLike")  # displays array as a known subclass

Note that ArrayLike is virtual with no slots (analog to a Java
Interface), which is what is expected.

   setClass("MyArrayLikeConcreteSubclass",
       contains="ArrayLike",
       representation(stuff="ANY")
   )

   showClass("MyArrayLikeConcreteSubclass")  # shows 2 slots!!

What is the .Data slot doing here? I would expect to see that slot
if MyArrayLikeConcreteSubclass was extending array but this is not
the case here.

   a <- new("MyArrayLikeConcreteSubclass")

   is(a, "MyArrayLikeConcreteSubclass")  # TRUE  --> ok
   is(a, "ArrayLike")                    # TRUE  --> ok
   is(a, "array")                        # FALSE --> ok

But:

   is.array(a)  # TRUE --> not ok!

Is is.array() confused by the presence of the .Data slot?

I can fix it by defining an "is.array" method for
MyArrayLikeConcreteSubclass objects:

   setMethod("is.array", "MyArrayLikeConcreteSubclass",
       function(x) FALSE
   )

However, it feels that I shouldn't have to do this.

Is the presence of the .Data slot in MyArrayLikeConcreteSubclass
objects an unintended feature?

Thanks,
H.

 > sessionInfo()
R Under development (unstable) (2016-01-07 r69884)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 14.04.4 LTS

locale:
  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
  [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fredhutch.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From lawrence.michael at gene.com  Fri Mar 18 23:28:14 2016
From: lawrence.michael at gene.com (Michael Lawrence)
Date: Fri, 18 Mar 2016 15:28:14 -0700
Subject: [Rd] unary class union of an S3 class
In-Reply-To: <56EC78DA.2010803@fredhutch.org>
References: <56EC78DA.2010803@fredhutch.org>
Message-ID: <CAOQ5NydT6YjFRw5xCTueA-e5DjM8pi0Y2fqUUb=PvJyJmtpeag@mail.gmail.com>

On Fri, Mar 18, 2016 at 2:53 PM, Herv? Pag?s <hpages at fredhutch.org> wrote:

> Hi,
>
> Short story
> -----------
>
>   setClassUnion("ArrayLike", "array")
>
>   showClass("ArrayLike")  # no slot
>
>   setClass("MyArrayLikeConcreteSubclass",
>       contains="ArrayLike",
>       representation(stuff="ANY")
>   )
>
>   showClass("MyArrayLikeConcreteSubclass") # 2 slots!!
>
> That doesn't seem right.
>
> Long story
> ----------
>
> S4 provides at least 3 ways to create a little class hierarchy
> like this:
>
>        FooLike ............. virtual class with no slot
>         ^   ^
>         |   |
>       foo   anotherfoo ..... 2 concrete subclasses
>
> (1) The "standard" way: define FooLike first, then foo and anotherfoo
> as subclasses of FooLike:
>
>   setClass("FooLike")
>
>   setClass("foo",
>       contains="FooLike",
>       representation(stuff="ANY")
>   )
>
>   setClass("anotherfoo",
>       contains="FooLike",
>       representation(stuff="ANY")
>   )
>
>   showClass("FooLike")    # displays foo and anotherfoo as
>                           # known subclasses
>
>   x1 <- new("foo")
>   is(x1, "foo")           # TRUE
>   is(x1, "FooLike")       # TRUE
>   is(x1, "anotherfoo")    # FALSE
>
>   x2 <- new("anotherfoo")
>   is(x2, "anotherfoo")    # TRUE
>   is(x2, "FooLike")       # TRUE
>   is(x2, "foo")           # FALSE
>
> Everything works as expected.
>
> (2) Using a class union: define foo and anotherfoo first, then FooLike
> as the union of foo and anotherfoo:
>
>   setClass("foo", representation(stuff="ANY"))
>   setClass("anotherfoo", representation(stuff="ANY"))
>   setClassUnion("FooLike", c("foo", "anotherfoo"))
>
>   showClass("FooLike")    # displays foo and anotherfoo as
>                           # known subclasses
>
> (3) Using a *unary* class union: define foo first, then FooLike as the
> (unary) union of foo, then anotherfoo as a subclass of FooLike:
>
>   setClass("foo", representation(stuff="ANY"))
>   setClassUnion("FooLike", "foo")
>
>   showClass("FooLike")   # displays foo as the only known subclass
>
>   setClass("anotherfoo",
>       contains="FooLike",
>       representation(stuff="ANY")
>   )
>
>   showClass("FooLike")   # now displays foo and anotherfoo as
>                          # known subclasses
>
> The 3 ways lead to the same hierarchy. However the 3rd way is
> interesting because it allows one to define the FooLike virtual
> class as the parent of an existing foo class that s/he doesn't
> control.
>
>
Why not use setIs() for this? Everything then behaves as expected. I don't
think it makes much sense to "contain" a class union. Rather, you just want
to establish the inheritance relationship.


> For example, to define an ArrayLike class:
>
>   setClassUnion("ArrayLike", "array")
>   showClass("ArrayLike")  # displays array as a known subclass
>
> Note that ArrayLike is virtual with no slots (analog to a Java
> Interface), which is what is expected.
>
>   setClass("MyArrayLikeConcreteSubclass",
>       contains="ArrayLike",
>       representation(stuff="ANY")
>   )
>
>   showClass("MyArrayLikeConcreteSubclass")  # shows 2 slots!!
>
> What is the .Data slot doing here? I would expect to see that slot
> if MyArrayLikeConcreteSubclass was extending array but this is not
> the case here.
>
>   a <- new("MyArrayLikeConcreteSubclass")
>
>   is(a, "MyArrayLikeConcreteSubclass")  # TRUE  --> ok
>   is(a, "ArrayLike")                    # TRUE  --> ok
>   is(a, "array")                        # FALSE --> ok
>
> But:
>
>   is.array(a)  # TRUE --> not ok!
>
> Is is.array() confused by the presence of the .Data slot?
>
>
It looks like the unary union somehow equates ArrayLike and array and thus
makes ArrayLike confer a dim attribute (and thus is.array(a) returns TRUE).
Since S4 objects cannot have attributes that are not slots, it must do this
via a data part, thus the .Data slot.



> I can fix it by defining an "is.array" method for
> MyArrayLikeConcreteSubclass objects:
>
>   setMethod("is.array", "MyArrayLikeConcreteSubclass",
>       function(x) FALSE
>   )
>
> However, it feels that I shouldn't have to do this.
>
> Is the presence of the .Data slot in MyArrayLikeConcreteSubclass
> objects an unintended feature?
>
> Thanks,
> H.
>
> > sessionInfo()
> R Under development (unstable) (2016-01-07 r69884)
> Platform: x86_64-pc-linux-gnu (64-bit)
> Running under: Ubuntu 14.04.4 LTS
>
> locale:
>  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> --
> Herv? Pag?s
>
> Program in Computational Biology
> Division of Public Health Sciences
> Fred Hutchinson Cancer Research Center
> 1100 Fairview Ave. N, M1-B514
> P.O. Box 19024
> Seattle, WA 98109-1024
>
> E-mail: hpages at fredhutch.org
> Phone:  (206) 667-5791
> Fax:    (206) 667-1319
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

	[[alternative HTML version deleted]]


From hpages at fredhutch.org  Sat Mar 19 08:10:40 2016
From: hpages at fredhutch.org (=?UTF-8?B?SGVydsOpIFBhZ8Oocw==?=)
Date: Sat, 19 Mar 2016 00:10:40 -0700
Subject: [Rd] unary class union of an S3 class
In-Reply-To: <CAOQ5NydT6YjFRw5xCTueA-e5DjM8pi0Y2fqUUb=PvJyJmtpeag@mail.gmail.com>
References: <56EC78DA.2010803@fredhutch.org>
	<CAOQ5NydT6YjFRw5xCTueA-e5DjM8pi0Y2fqUUb=PvJyJmtpeag@mail.gmail.com>
Message-ID: <56ECFB70.2080506@fredhutch.org>

On 03/18/2016 03:28 PM, Michael Lawrence wrote:
>
> On Fri, Mar 18, 2016 at 2:53 PM, Herv? Pag?s <hpages at fredhutch.org
> <mailto:hpages at fredhutch.org>> wrote:
>
>     Hi,
>
>     Short story
>     -----------
>
>        setClassUnion("ArrayLike", "array")
>
>        showClass("ArrayLike")  # no slot
>
>        setClass("MyArrayLikeConcreteSubclass",
>            contains="ArrayLike",
>            representation(stuff="ANY")
>        )
>
>        showClass("MyArrayLikeConcreteSubclass") # 2 slots!!
>
>     That doesn't seem right.
>
>     Long story
>     ----------
>
>     S4 provides at least 3 ways to create a little class hierarchy
>     like this:
>
>             FooLike ............. virtual class with no slot
>              ^   ^
>              |   |
>            foo   anotherfoo ..... 2 concrete subclasses
>
>     (1) The "standard" way: define FooLike first, then foo and anotherfoo
>     as subclasses of FooLike:
>
>        setClass("FooLike")
>
>        setClass("foo",
>            contains="FooLike",
>            representation(stuff="ANY")
>        )
>
>        setClass("anotherfoo",
>            contains="FooLike",
>            representation(stuff="ANY")
>        )
>
>        showClass("FooLike")    # displays foo and anotherfoo as
>                                # known subclasses
>
>        x1 <- new("foo")
>        is(x1, "foo")           # TRUE
>        is(x1, "FooLike")       # TRUE
>        is(x1, "anotherfoo")    # FALSE
>
>        x2 <- new("anotherfoo")
>        is(x2, "anotherfoo")    # TRUE
>        is(x2, "FooLike")       # TRUE
>        is(x2, "foo")           # FALSE
>
>     Everything works as expected.
>
>     (2) Using a class union: define foo and anotherfoo first, then FooLike
>     as the union of foo and anotherfoo:
>
>        setClass("foo", representation(stuff="ANY"))
>        setClass("anotherfoo", representation(stuff="ANY"))
>        setClassUnion("FooLike", c("foo", "anotherfoo"))
>
>        showClass("FooLike")    # displays foo and anotherfoo as
>                                # known subclasses
>
>     (3) Using a *unary* class union: define foo first, then FooLike as the
>     (unary) union of foo, then anotherfoo as a subclass of FooLike:
>
>        setClass("foo", representation(stuff="ANY"))
>        setClassUnion("FooLike", "foo")
>
>        showClass("FooLike")   # displays foo as the only known subclass
>
>        setClass("anotherfoo",
>            contains="FooLike",
>            representation(stuff="ANY")
>        )
>
>        showClass("FooLike")   # now displays foo and anotherfoo as
>                               # known subclasses
>
>     The 3 ways lead to the same hierarchy. However the 3rd way is
>     interesting because it allows one to define the FooLike virtual
>     class as the parent of an existing foo class that s/he doesn't
>     control.
>
>
> Why not use setIs() for this?

   > setClass("ArrayLike")
   > setIs("array", "ArrayLike")
   Error in setIs("array", "ArrayLike") :
     class ?array? is sealed; new superclasses can not be defined, 
except by 'setClassUnion'

How do you define a virtual class as the parent of an existing class
with setIs?

> Everything then behaves as expected. I
> don't think it makes much sense to "contain" a class union.

Why is that? A class union is just a virtual class with no slot
that is the parent of the classes that are in the union. All the
classes in the union contain their parent. What's interesting is that
this union is actually open to new members: when I later define a new
class that contains the class union, I'm just adding a new member to
the union.

> Rather, you
> just want to establish the inheritance relationship.

Isn't what I'm doing when I define a new class that contains the
class union?

>
>     For example, to define an ArrayLike class:
>
>        setClassUnion("ArrayLike", "array")
>        showClass("ArrayLike")  # displays array as a known subclass
>
>     Note that ArrayLike is virtual with no slots (analog to a Java
>     Interface), which is what is expected.
>
>        setClass("MyArrayLikeConcreteSubclass",
>            contains="ArrayLike",
>            representation(stuff="ANY")
>        )
>
>        showClass("MyArrayLikeConcreteSubclass")  # shows 2 slots!!
>
>     What is the .Data slot doing here? I would expect to see that slot
>     if MyArrayLikeConcreteSubclass was extending array but this is not
>     the case here.
>
>        a <- new("MyArrayLikeConcreteSubclass")
>
>        is(a, "MyArrayLikeConcreteSubclass")  # TRUE  --> ok
>        is(a, "ArrayLike")                    # TRUE  --> ok
>        is(a, "array")                        # FALSE --> ok
>
>     But:
>
>        is.array(a)  # TRUE --> not ok!
>
>     Is is.array() confused by the presence of the .Data slot?
>
>
> It looks like the unary union somehow equates ArrayLike and array

Clearly the unary union makes ArrayLike a parent of array, as it should
be. This can be confirmed by extends():

   > extends("array", "ArrayLike")
   [1] TRUE
   > extends("ArrayLike", "array")
   [1] FALSE

The results for is(a, "ArrayLike") (TRUE) and is(a, "array") (FALSE)
on a MyArrayLikeConcreteSubclass instance are consistent with this.

So the little 3-class hierarchy I end up with in the above example
is exactly how expected:

          ArrayLike
           ^    ^
           |    |
       array    MyArrayLikeConcreteSubclass

What is not expected is that MyArrayLikeConcreteSubclass has a .Data
slot and that is.array(a) returns TRUE on a MyArrayLikeConcreteSubclass
object.

H.

> and
> thus makes ArrayLike confer a dim attribute (and thus is.array(a)
> returns TRUE). Since S4 objects cannot have attributes that are not
> slots, it must do this via a data part, thus the .Data slot.
>
>     I can fix it by defining an "is.array" method for
>     MyArrayLikeConcreteSubclass objects:
>
>        setMethod("is.array", "MyArrayLikeConcreteSubclass",
>            function(x) FALSE
>        )
>
>     However, it feels that I shouldn't have to do this.
>
>     Is the presence of the .Data slot in MyArrayLikeConcreteSubclass
>     objects an unintended feature?
>
>     Thanks,
>     H.
>
>      > sessionInfo()
>     R Under development (unstable) (2016-01-07 r69884)
>     Platform: x86_64-pc-linux-gnu (64-bit)
>     Running under: Ubuntu 14.04.4 LTS
>
>     locale:
>       [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>       [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>       [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>       [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>       [9] LC_ADDRESS=C               LC_TELEPHONE=C
>     [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>
>     attached base packages:
>     [1] stats     graphics  grDevices utils     datasets  methods   base
>
>     --
>     Herv? Pag?s
>
>     Program in Computational Biology
>     Division of Public Health Sciences
>     Fred Hutchinson Cancer Research Center
>     1100 Fairview Ave. N, M1-B514
>     P.O. Box 19024
>     Seattle, WA 98109-1024
>
>     E-mail: hpages at fredhutch.org <mailto:hpages at fredhutch.org>
>     Phone: (206) 667-5791 <tel:%28206%29%20667-5791>
>     Fax: (206) 667-1319 <tel:%28206%29%20667-1319>
>
>     ______________________________________________
>     R-devel at r-project.org <mailto:R-devel at r-project.org> mailing list
>     https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fredhutch.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From lawrence.michael at gene.com  Sat Mar 19 09:22:25 2016
From: lawrence.michael at gene.com (Michael Lawrence)
Date: Sat, 19 Mar 2016 01:22:25 -0700
Subject: [Rd] unary class union of an S3 class
In-Reply-To: <56ECFB70.2080506@fredhutch.org>
References: <56EC78DA.2010803@fredhutch.org>
	<CAOQ5NydT6YjFRw5xCTueA-e5DjM8pi0Y2fqUUb=PvJyJmtpeag@mail.gmail.com>
	<56ECFB70.2080506@fredhutch.org>
Message-ID: <CAOQ5NycudrAu9tHeL2JYKM8jLiQRO4nT+-CM7ayf7teGSqra0A@mail.gmail.com>

On Sat, Mar 19, 2016 at 12:10 AM, Herv? Pag?s <hpages at fredhutch.org> wrote:

> On 03/18/2016 03:28 PM, Michael Lawrence wrote:
>
>>
>> On Fri, Mar 18, 2016 at 2:53 PM, Herv? Pag?s <hpages at fredhutch.org
>> <mailto:hpages at fredhutch.org>> wrote:
>>
>>     Hi,
>>
>>     Short story
>>     -----------
>>
>>        setClassUnion("ArrayLike", "array")
>>
>>        showClass("ArrayLike")  # no slot
>>
>>        setClass("MyArrayLikeConcreteSubclass",
>>            contains="ArrayLike",
>>            representation(stuff="ANY")
>>        )
>>
>>        showClass("MyArrayLikeConcreteSubclass") # 2 slots!!
>>
>>     That doesn't seem right.
>>
>>     Long story
>>     ----------
>>
>>     S4 provides at least 3 ways to create a little class hierarchy
>>     like this:
>>
>>             FooLike ............. virtual class with no slot
>>              ^   ^
>>              |   |
>>            foo   anotherfoo ..... 2 concrete subclasses
>>
>>     (1) The "standard" way: define FooLike first, then foo and anotherfoo
>>     as subclasses of FooLike:
>>
>>        setClass("FooLike")
>>
>>        setClass("foo",
>>            contains="FooLike",
>>            representation(stuff="ANY")
>>        )
>>
>>        setClass("anotherfoo",
>>            contains="FooLike",
>>            representation(stuff="ANY")
>>        )
>>
>>        showClass("FooLike")    # displays foo and anotherfoo as
>>                                # known subclasses
>>
>>        x1 <- new("foo")
>>        is(x1, "foo")           # TRUE
>>        is(x1, "FooLike")       # TRUE
>>        is(x1, "anotherfoo")    # FALSE
>>
>>        x2 <- new("anotherfoo")
>>        is(x2, "anotherfoo")    # TRUE
>>        is(x2, "FooLike")       # TRUE
>>        is(x2, "foo")           # FALSE
>>
>>     Everything works as expected.
>>
>>     (2) Using a class union: define foo and anotherfoo first, then FooLike
>>     as the union of foo and anotherfoo:
>>
>>        setClass("foo", representation(stuff="ANY"))
>>        setClass("anotherfoo", representation(stuff="ANY"))
>>        setClassUnion("FooLike", c("foo", "anotherfoo"))
>>
>>        showClass("FooLike")    # displays foo and anotherfoo as
>>                                # known subclasses
>>
>>     (3) Using a *unary* class union: define foo first, then FooLike as the
>>     (unary) union of foo, then anotherfoo as a subclass of FooLike:
>>
>>        setClass("foo", representation(stuff="ANY"))
>>        setClassUnion("FooLike", "foo")
>>
>>        showClass("FooLike")   # displays foo as the only known subclass
>>
>>        setClass("anotherfoo",
>>            contains="FooLike",
>>            representation(stuff="ANY")
>>        )
>>
>>        showClass("FooLike")   # now displays foo and anotherfoo as
>>                               # known subclasses
>>
>>     The 3 ways lead to the same hierarchy. However the 3rd way is
>>     interesting because it allows one to define the FooLike virtual
>>     class as the parent of an existing foo class that s/he doesn't
>>     control.
>>
>>
>> Why not use setIs() for this?
>>
>
>   > setClass("ArrayLike")
>   > setIs("array", "ArrayLike")
>   Error in setIs("array", "ArrayLike") :
>     class ?array? is sealed; new superclasses can not be defined, except
> by 'setClassUnion'
>
> How do you define a virtual class as the parent of an existing class
> with setIs?
>
>
You can only do that with setClassUnion(). But the new classes should use
setIs() to inherit from the union. So it's:

setClassUnion("ArrayLike", "array")
setClass("MyArrayLike")
setIs("MyArrayLike", "ArrayLike")


> Everything then behaves as expected. I
>> don't think it makes much sense to "contain" a class union.
>>
>
> Why is that? A class union is just a virtual class with no slot
> that is the parent of the classes that are in the union. All the
> classes in the union contain their parent. What's interesting is that
> this union is actually open to new members: when I later define a new
> class that contains the class union, I'm just adding a new member to
> the union.
>
> Rather, you
>> just want to establish the inheritance relationship.
>>
>
> Isn't what I'm doing when I define a new class that contains the
> class union?
>

Containing does two things: establishes the is() relationship and adds
slots to the class. These slots are comprised of the slots of the contained
class, and as a special case the "array" class and other native types
confer a data part that comes from the prototype of the class. The "array"
class has a double vector with a dim attribute as its prototype. That is
all well understood. What is surprising is that "ArrayLike" has the same
prototype as "array". That happens via setIs(doComplete=TRUE), called by
setClassUnion(). When a class gains its first non-virtual child, the parent
assumes the prototype of its child.  I'm not sure why, but the logic is
very explicit and I've come to just accept it as a "feature". I ran into
this some months ago when defining my own ArrayLike when working on a very
similar package to the one you are developing ;)


>
>>     For example, to define an ArrayLike class:
>>
>>        setClassUnion("ArrayLike", "array")
>>        showClass("ArrayLike")  # displays array as a known subclass
>>
>>     Note that ArrayLike is virtual with no slots (analog to a Java
>>     Interface), which is what is expected.
>>
>>        setClass("MyArrayLikeConcreteSubclass",
>>            contains="ArrayLike",
>>            representation(stuff="ANY")
>>        )
>>
>>        showClass("MyArrayLikeConcreteSubclass")  # shows 2 slots!!
>>
>>     What is the .Data slot doing here? I would expect to see that slot
>>     if MyArrayLikeConcreteSubclass was extending array but this is not
>>     the case here.
>>
>>        a <- new("MyArrayLikeConcreteSubclass")
>>
>>        is(a, "MyArrayLikeConcreteSubclass")  # TRUE  --> ok
>>        is(a, "ArrayLike")                    # TRUE  --> ok
>>        is(a, "array")                        # FALSE --> ok
>>
>>     But:
>>
>>        is.array(a)  # TRUE --> not ok!
>>
>>     Is is.array() confused by the presence of the .Data slot?
>>
>>
>> It looks like the unary union somehow equates ArrayLike and array
>>
>
> Clearly the unary union makes ArrayLike a parent of array, as it should
> be. This can be confirmed by extends():
>
>   > extends("array", "ArrayLike")
>   [1] TRUE
>   > extends("ArrayLike", "array")
>   [1] FALSE
>
> The results for is(a, "ArrayLike") (TRUE) and is(a, "array") (FALSE)
> on a MyArrayLikeConcreteSubclass instance are consistent with this.
>
> So the little 3-class hierarchy I end up with in the above example
> is exactly how expected:
>
>          ArrayLike
>           ^    ^
>           |    |
>       array    MyArrayLikeConcreteSubclass
>
> What is not expected is that MyArrayLikeConcreteSubclass has a .Data
> slot and that is.array(a) returns TRUE on a MyArrayLikeConcreteSubclass
> object.
>
> H.
>
> and
>> thus makes ArrayLike confer a dim attribute (and thus is.array(a)
>> returns TRUE). Since S4 objects cannot have attributes that are not
>> slots, it must do this via a data part, thus the .Data slot.
>>
>>     I can fix it by defining an "is.array" method for
>>     MyArrayLikeConcreteSubclass objects:
>>
>>        setMethod("is.array", "MyArrayLikeConcreteSubclass",
>>            function(x) FALSE
>>        )
>>
>>     However, it feels that I shouldn't have to do this.
>>
>>     Is the presence of the .Data slot in MyArrayLikeConcreteSubclass
>>     objects an unintended feature?
>>
>>     Thanks,
>>     H.
>>
>>      > sessionInfo()
>>     R Under development (unstable) (2016-01-07 r69884)
>>     Platform: x86_64-pc-linux-gnu (64-bit)
>>     Running under: Ubuntu 14.04.4 LTS
>>
>>     locale:
>>       [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>>       [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>>       [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>>       [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>>       [9] LC_ADDRESS=C               LC_TELEPHONE=C
>>     [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>>
>>     attached base packages:
>>     [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>>     --
>>     Herv? Pag?s
>>
>>     Program in Computational Biology
>>     Division of Public Health Sciences
>>     Fred Hutchinson Cancer Research Center
>>     1100 Fairview Ave. N, M1-B514
>>     P.O. Box 19024
>>     Seattle, WA 98109-1024
>>
>>     E-mail: hpages at fredhutch.org <mailto:hpages at fredhutch.org>
>>     Phone: (206) 667-5791 <tel:%28206%29%20667-5791>
>>     Fax: (206) 667-1319 <tel:%28206%29%20667-1319>
>>
>>     ______________________________________________
>>     R-devel at r-project.org <mailto:R-devel at r-project.org> mailing list
>>     https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>>
> --
> Herv? Pag?s
>
> Program in Computational Biology
> Division of Public Health Sciences
> Fred Hutchinson Cancer Research Center
> 1100 Fairview Ave. N, M1-B514
> P.O. Box 19024
> Seattle, WA 98109-1024
>
> E-mail: hpages at fredhutch.org
> Phone:  (206) 667-5791
> Fax:    (206) 667-1319
>
>

	[[alternative HTML version deleted]]


From hpages at fredhutch.org  Sat Mar 19 12:29:36 2016
From: hpages at fredhutch.org (=?UTF-8?B?SGVydsOpIFBhZ8Oocw==?=)
Date: Sat, 19 Mar 2016 04:29:36 -0700
Subject: [Rd] unary class union of an S3 class
In-Reply-To: <CAOQ5NycudrAu9tHeL2JYKM8jLiQRO4nT+-CM7ayf7teGSqra0A@mail.gmail.com>
References: <56EC78DA.2010803@fredhutch.org>
	<CAOQ5NydT6YjFRw5xCTueA-e5DjM8pi0Y2fqUUb=PvJyJmtpeag@mail.gmail.com>
	<56ECFB70.2080506@fredhutch.org>
	<CAOQ5NycudrAu9tHeL2JYKM8jLiQRO4nT+-CM7ayf7teGSqra0A@mail.gmail.com>
Message-ID: <56ED3820.3080001@fredhutch.org>

On 03/19/2016 01:22 AM, Michael Lawrence wrote:
>
>
> On Sat, Mar 19, 2016 at 12:10 AM, Herv? Pag?s <hpages at fredhutch.org
> <mailto:hpages at fredhutch.org>> wrote:
>
>     On 03/18/2016 03:28 PM, Michael Lawrence wrote:
>
>
>         On Fri, Mar 18, 2016 at 2:53 PM, Herv? Pag?s
>         <hpages at fredhutch.org <mailto:hpages at fredhutch.org>
>         <mailto:hpages at fredhutch.org <mailto:hpages at fredhutch.org>>> wrote:
>
>              Hi,
>
>              Short story
>              -----------
>
>                 setClassUnion("ArrayLike", "array")
>
>                 showClass("ArrayLike")  # no slot
>
>                 setClass("MyArrayLikeConcreteSubclass",
>                     contains="ArrayLike",
>                     representation(stuff="ANY")
>                 )
>
>                 showClass("MyArrayLikeConcreteSubclass") # 2 slots!!
>
>              That doesn't seem right.
>
>              Long story
>              ----------
>
>              S4 provides at least 3 ways to create a little class hierarchy
>              like this:
>
>                      FooLike ............. virtual class with no slot
>                       ^   ^
>                       |   |
>                     foo   anotherfoo ..... 2 concrete subclasses
>
>              (1) The "standard" way: define FooLike first, then foo and
>         anotherfoo
>              as subclasses of FooLike:
>
>                 setClass("FooLike")
>
>                 setClass("foo",
>                     contains="FooLike",
>                     representation(stuff="ANY")
>                 )
>
>                 setClass("anotherfoo",
>                     contains="FooLike",
>                     representation(stuff="ANY")
>                 )
>
>                 showClass("FooLike")    # displays foo and anotherfoo as
>                                         # known subclasses
>
>                 x1 <- new("foo")
>                 is(x1, "foo")           # TRUE
>                 is(x1, "FooLike")       # TRUE
>                 is(x1, "anotherfoo")    # FALSE
>
>                 x2 <- new("anotherfoo")
>                 is(x2, "anotherfoo")    # TRUE
>                 is(x2, "FooLike")       # TRUE
>                 is(x2, "foo")           # FALSE
>
>              Everything works as expected.
>
>              (2) Using a class union: define foo and anotherfoo first,
>         then FooLike
>              as the union of foo and anotherfoo:
>
>                 setClass("foo", representation(stuff="ANY"))
>                 setClass("anotherfoo", representation(stuff="ANY"))
>                 setClassUnion("FooLike", c("foo", "anotherfoo"))
>
>                 showClass("FooLike")    # displays foo and anotherfoo as
>                                         # known subclasses
>
>              (3) Using a *unary* class union: define foo first, then
>         FooLike as the
>              (unary) union of foo, then anotherfoo as a subclass of FooLike:
>
>                 setClass("foo", representation(stuff="ANY"))
>                 setClassUnion("FooLike", "foo")
>
>                 showClass("FooLike")   # displays foo as the only known
>         subclass
>
>                 setClass("anotherfoo",
>                     contains="FooLike",
>                     representation(stuff="ANY")
>                 )
>
>                 showClass("FooLike")   # now displays foo and anotherfoo as
>                                        # known subclasses
>
>              The 3 ways lead to the same hierarchy. However the 3rd way is
>              interesting because it allows one to define the FooLike virtual
>              class as the parent of an existing foo class that s/he doesn't
>              control.
>
>
>         Why not use setIs() for this?
>
>
>        > setClass("ArrayLike")
>        > setIs("array", "ArrayLike")
>        Error in setIs("array", "ArrayLike") :
>          class ?array? is sealed; new superclasses can not be defined,
>     except by 'setClassUnion'
>
>     How do you define a virtual class as the parent of an existing class
>     with setIs?
>
>
> You can only do that with setClassUnion(). But the new classes should
> use setIs() to inherit from the union. So it's:
>
> setClassUnion("ArrayLike", "array")
> setClass("MyArrayLike")
> setIs("MyArrayLike", "ArrayLike")
>
>         Everything then behaves as expected. I
>         don't think it makes much sense to "contain" a class union.
>
>
>     Why is that? A class union is just a virtual class with no slot
>     that is the parent of the classes that are in the union. All the
>     classes in the union contain their parent. What's interesting is that
>     this union is actually open to new members: when I later define a new
>     class that contains the class union, I'm just adding a new member to
>     the union.
>
>         Rather, you
>         just want to establish the inheritance relationship.
>
>
>     Isn't what I'm doing when I define a new class that contains the
>     class union?
>
>
> Containing does two things: establishes the is() relationship and adds
> slots to the class.

I understand that. But in that case, since a class union has no slots,
one would expect that using setIs() is equivalent to containing.

> These slots are comprised of the slots of the
> contained class, and as a special case the "array" class and other
> native types confer a data part that comes from the prototype of the
> class. The "array" class has a double vector with a dim attribute as its
> prototype. That is all well understood. What is surprising is that
> "ArrayLike" has the same prototype as "array". That happens via
> setIs(doComplete=TRUE), called by setClassUnion(). When a class gains
> its first non-virtual child, the parent assumes the prototype of its
> child.  I'm not sure why, but the logic is very explicit and I've come
> to just accept it as a "feature".

Never noticed that. Thanks for clarifying. So with this "feature":

   - setClassUnion("A", c("B", "C")) is not the same as
     setClassUnion("A", c("C", "B"))

   - if 2 packages define concrete subclasses of a virtual
     class defined in a 3rd package, the prototype of the virtual
     class will depend on the order the packages are loaded

   - using setIs("MyArrayLike", "ArrayLike") is not equivalent
     to containing (even though ArrayLike has no slots)

   - containing adds an undesirable .Data slot

   - containing breaks is.array() but not is( , "array")

Seems pretty harmful to me. Would be good to understand the rationale 
behind this feature. In particular it's not clear to me why a virtual
class with no slot would need to have a prototype at all (i.e. other
than NULL).

> I ran into this some months ago when
> defining my own ArrayLike when working on a very similar package to the
> one you are developing ;)

After giving it more thoughts I realized that I can do without the
ArrayLike class. That will keep the class hierarchy in HDF5Array to the
strict minimum.

Thanks for the feedback,
H.

>
>
>
>              For example, to define an ArrayLike class:
>
>                 setClassUnion("ArrayLike", "array")
>                 showClass("ArrayLike")  # displays array as a known subclass
>
>              Note that ArrayLike is virtual with no slots (analog to a Java
>              Interface), which is what is expected.
>
>                 setClass("MyArrayLikeConcreteSubclass",
>                     contains="ArrayLike",
>                     representation(stuff="ANY")
>                 )
>
>                 showClass("MyArrayLikeConcreteSubclass")  # shows 2 slots!!
>
>              What is the .Data slot doing here? I would expect to see
>         that slot
>              if MyArrayLikeConcreteSubclass was extending array but this
>         is not
>              the case here.
>
>                 a <- new("MyArrayLikeConcreteSubclass")
>
>                 is(a, "MyArrayLikeConcreteSubclass")  # TRUE  --> ok
>                 is(a, "ArrayLike")                    # TRUE  --> ok
>                 is(a, "array")                        # FALSE --> ok
>
>              But:
>
>                 is.array(a)  # TRUE --> not ok!
>
>              Is is.array() confused by the presence of the .Data slot?
>
>
>         It looks like the unary union somehow equates ArrayLike and array
>
>
>     Clearly the unary union makes ArrayLike a parent of array, as it should
>     be. This can be confirmed by extends():
>
>        > extends("array", "ArrayLike")
>        [1] TRUE
>        > extends("ArrayLike", "array")
>        [1] FALSE
>
>     The results for is(a, "ArrayLike") (TRUE) and is(a, "array") (FALSE)
>     on a MyArrayLikeConcreteSubclass instance are consistent with this.
>
>     So the little 3-class hierarchy I end up with in the above example
>     is exactly how expected:
>
>               ArrayLike
>                ^    ^
>                |    |
>            array    MyArrayLikeConcreteSubclass
>
>     What is not expected is that MyArrayLikeConcreteSubclass has a .Data
>     slot and that is.array(a) returns TRUE on a MyArrayLikeConcreteSubclass
>     object.
>
>     H.
>
>         and
>         thus makes ArrayLike confer a dim attribute (and thus is.array(a)
>         returns TRUE). Since S4 objects cannot have attributes that are not
>         slots, it must do this via a data part, thus the .Data slot.
>
>              I can fix it by defining an "is.array" method for
>              MyArrayLikeConcreteSubclass objects:
>
>                 setMethod("is.array", "MyArrayLikeConcreteSubclass",
>                     function(x) FALSE
>                 )
>
>              However, it feels that I shouldn't have to do this.
>
>              Is the presence of the .Data slot in
>         MyArrayLikeConcreteSubclass
>              objects an unintended feature?
>
>              Thanks,
>              H.
>
>               > sessionInfo()
>              R Under development (unstable) (2016-01-07 r69884)
>              Platform: x86_64-pc-linux-gnu (64-bit)
>              Running under: Ubuntu 14.04.4 LTS
>
>              locale:
>                [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>                [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>                [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>                [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>                [9] LC_ADDRESS=C               LC_TELEPHONE=C
>              [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>
>              attached base packages:
>              [1] stats     graphics  grDevices utils     datasets
>         methods   base
>
>              --
>              Herv? Pag?s
>
>              Program in Computational Biology
>              Division of Public Health Sciences
>              Fred Hutchinson Cancer Research Center
>              1100 Fairview Ave. N, M1-B514
>              P.O. Box 19024
>              Seattle, WA 98109-1024
>
>              E-mail: hpages at fredhutch.org <mailto:hpages at fredhutch.org>
>         <mailto:hpages at fredhutch.org <mailto:hpages at fredhutch.org>>
>              Phone: (206) 667-5791 <tel:%28206%29%20667-5791>
>         <tel:%28206%29%20667-5791>
>              Fax: (206) 667-1319 <tel:%28206%29%20667-1319>
>         <tel:%28206%29%20667-1319>
>
>              ______________________________________________
>         R-devel at r-project.org <mailto:R-devel at r-project.org>
>         <mailto:R-devel at r-project.org <mailto:R-devel at r-project.org>>
>         mailing list
>         https://stat.ethz.ch/mailman/listinfo/r-devel
>
>
>
>     --
>     Herv? Pag?s
>
>     Program in Computational Biology
>     Division of Public Health Sciences
>     Fred Hutchinson Cancer Research Center
>     1100 Fairview Ave. N, M1-B514
>     P.O. Box 19024
>     Seattle, WA 98109-1024
>
>     E-mail: hpages at fredhutch.org <mailto:hpages at fredhutch.org>
>     Phone: (206) 667-5791 <tel:%28206%29%20667-5791>
>     Fax: (206) 667-1319 <tel:%28206%29%20667-1319>
>
>

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fredhutch.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From lawrence.michael at gene.com  Sat Mar 19 14:35:26 2016
From: lawrence.michael at gene.com (Michael Lawrence)
Date: Sat, 19 Mar 2016 06:35:26 -0700
Subject: [Rd] unary class union of an S3 class
In-Reply-To: <56ED3820.3080001@fredhutch.org>
References: <56EC78DA.2010803@fredhutch.org>
	<CAOQ5NydT6YjFRw5xCTueA-e5DjM8pi0Y2fqUUb=PvJyJmtpeag@mail.gmail.com>
	<56ECFB70.2080506@fredhutch.org>
	<CAOQ5NycudrAu9tHeL2JYKM8jLiQRO4nT+-CM7ayf7teGSqra0A@mail.gmail.com>
	<56ED3820.3080001@fredhutch.org>
Message-ID: <CAOQ5Nydk1L1+Yr=oLv45nkH2V+P=jBDqzYnbTMg+p9757bUC+g@mail.gmail.com>

On Sat, Mar 19, 2016 at 4:29 AM, Herv? Pag?s <hpages at fredhutch.org> wrote:

> On 03/19/2016 01:22 AM, Michael Lawrence wrote:
>
>>
>>
>> On Sat, Mar 19, 2016 at 12:10 AM, Herv? Pag?s <hpages at fredhutch.org
>> <mailto:hpages at fredhutch.org>> wrote:
>>
>>     On 03/18/2016 03:28 PM, Michael Lawrence wrote:
>>
>>
>>         On Fri, Mar 18, 2016 at 2:53 PM, Herv? Pag?s
>>         <hpages at fredhutch.org <mailto:hpages at fredhutch.org>
>>         <mailto:hpages at fredhutch.org <mailto:hpages at fredhutch.org>>>
>> wrote:
>>
>>              Hi,
>>
>>              Short story
>>              -----------
>>
>>                 setClassUnion("ArrayLike", "array")
>>
>>                 showClass("ArrayLike")  # no slot
>>
>>                 setClass("MyArrayLikeConcreteSubclass",
>>                     contains="ArrayLike",
>>                     representation(stuff="ANY")
>>                 )
>>
>>                 showClass("MyArrayLikeConcreteSubclass") # 2 slots!!
>>
>>              That doesn't seem right.
>>
>>              Long story
>>              ----------
>>
>>              S4 provides at least 3 ways to create a little class
>> hierarchy
>>              like this:
>>
>>                      FooLike ............. virtual class with no slot
>>                       ^   ^
>>                       |   |
>>                     foo   anotherfoo ..... 2 concrete subclasses
>>
>>              (1) The "standard" way: define FooLike first, then foo and
>>         anotherfoo
>>              as subclasses of FooLike:
>>
>>                 setClass("FooLike")
>>
>>                 setClass("foo",
>>                     contains="FooLike",
>>                     representation(stuff="ANY")
>>                 )
>>
>>                 setClass("anotherfoo",
>>                     contains="FooLike",
>>                     representation(stuff="ANY")
>>                 )
>>
>>                 showClass("FooLike")    # displays foo and anotherfoo as
>>                                         # known subclasses
>>
>>                 x1 <- new("foo")
>>                 is(x1, "foo")           # TRUE
>>                 is(x1, "FooLike")       # TRUE
>>                 is(x1, "anotherfoo")    # FALSE
>>
>>                 x2 <- new("anotherfoo")
>>                 is(x2, "anotherfoo")    # TRUE
>>                 is(x2, "FooLike")       # TRUE
>>                 is(x2, "foo")           # FALSE
>>
>>              Everything works as expected.
>>
>>              (2) Using a class union: define foo and anotherfoo first,
>>         then FooLike
>>              as the union of foo and anotherfoo:
>>
>>                 setClass("foo", representation(stuff="ANY"))
>>                 setClass("anotherfoo", representation(stuff="ANY"))
>>                 setClassUnion("FooLike", c("foo", "anotherfoo"))
>>
>>                 showClass("FooLike")    # displays foo and anotherfoo as
>>                                         # known subclasses
>>
>>              (3) Using a *unary* class union: define foo first, then
>>         FooLike as the
>>              (unary) union of foo, then anotherfoo as a subclass of
>> FooLike:
>>
>>                 setClass("foo", representation(stuff="ANY"))
>>                 setClassUnion("FooLike", "foo")
>>
>>                 showClass("FooLike")   # displays foo as the only known
>>         subclass
>>
>>                 setClass("anotherfoo",
>>                     contains="FooLike",
>>                     representation(stuff="ANY")
>>                 )
>>
>>                 showClass("FooLike")   # now displays foo and anotherfoo
>> as
>>                                        # known subclasses
>>
>>              The 3 ways lead to the same hierarchy. However the 3rd way is
>>              interesting because it allows one to define the FooLike
>> virtual
>>              class as the parent of an existing foo class that s/he
>> doesn't
>>              control.
>>
>>
>>         Why not use setIs() for this?
>>
>>
>>        > setClass("ArrayLike")
>>        > setIs("array", "ArrayLike")
>>        Error in setIs("array", "ArrayLike") :
>>          class ?array? is sealed; new superclasses can not be defined,
>>     except by 'setClassUnion'
>>
>>     How do you define a virtual class as the parent of an existing class
>>     with setIs?
>>
>>
>> You can only do that with setClassUnion(). But the new classes should
>> use setIs() to inherit from the union. So it's:
>>
>> setClassUnion("ArrayLike", "array")
>> setClass("MyArrayLike")
>> setIs("MyArrayLike", "ArrayLike")
>>
>>         Everything then behaves as expected. I
>>         don't think it makes much sense to "contain" a class union.
>>
>>
>>     Why is that? A class union is just a virtual class with no slot
>>     that is the parent of the classes that are in the union. All the
>>     classes in the union contain their parent. What's interesting is that
>>     this union is actually open to new members: when I later define a new
>>     class that contains the class union, I'm just adding a new member to
>>     the union.
>>
>>         Rather, you
>>         just want to establish the inheritance relationship.
>>
>>
>>     Isn't what I'm doing when I define a new class that contains the
>>     class union?
>>
>>
>> Containing does two things: establishes the is() relationship and adds
>> slots to the class.
>>
>
> I understand that. But in that case, since a class union has no slots,
> one would expect that using setIs() is equivalent to containing.
>
> These slots are comprised of the slots of the
>> contained class, and as a special case the "array" class and other
>> native types confer a data part that comes from the prototype of the
>> class. The "array" class has a double vector with a dim attribute as its
>> prototype. That is all well understood. What is surprising is that
>> "ArrayLike" has the same prototype as "array". That happens via
>> setIs(doComplete=TRUE), called by setClassUnion(). When a class gains
>> its first non-virtual child, the parent assumes the prototype of its
>> child.  I'm not sure why, but the logic is very explicit and I've come
>> to just accept it as a "feature".
>>
>
> Never noticed that. Thanks for clarifying. So with this "feature":
>
>   - setClassUnion("A", c("B", "C")) is not the same as
>     setClassUnion("A", c("C", "B"))
>
>   - if 2 packages define concrete subclasses of a virtual
>     class defined in a 3rd package, the prototype of the virtual
>     class will depend on the order the packages are loaded
>
>   - using setIs("MyArrayLike", "ArrayLike") is not equivalent
>     to containing (even though ArrayLike has no slots)
>
>   - containing adds an undesirable .Data slot
>
>   - containing breaks is.array() but not is( , "array")
>
> Seems pretty harmful to me. Would be good to understand the rationale
> behind this feature. In particular it's not clear to me why a virtual
> class with no slot would need to have a prototype at all (i.e. other
> than NULL).
>
> I ran into this some months ago when
>> defining my own ArrayLike when working on a very similar package to the
>> one you are developing ;)
>>
>
> After giving it more thoughts I realized that I can do without the
> ArrayLike class. That will keep the class hierarchy in HDF5Array to the
> strict minimum.
>
>
Yea I've come to realize that declaring virtual classes that indicate
whether an object behaves like a base type is overkill. It usually suffices
to say that the object satisfies the basic contract of an array, list,
vector, etc. It would be nice to have something like a Java interface for
specifying such contracts.


> Thanks for the feedback,
> H.
>
>
>>
>>
>>              For example, to define an ArrayLike class:
>>
>>                 setClassUnion("ArrayLike", "array")
>>                 showClass("ArrayLike")  # displays array as a known
>> subclass
>>
>>              Note that ArrayLike is virtual with no slots (analog to a
>> Java
>>              Interface), which is what is expected.
>>
>>                 setClass("MyArrayLikeConcreteSubclass",
>>                     contains="ArrayLike",
>>                     representation(stuff="ANY")
>>                 )
>>
>>                 showClass("MyArrayLikeConcreteSubclass")  # shows 2
>> slots!!
>>
>>              What is the .Data slot doing here? I would expect to see
>>         that slot
>>              if MyArrayLikeConcreteSubclass was extending array but this
>>         is not
>>              the case here.
>>
>>                 a <- new("MyArrayLikeConcreteSubclass")
>>
>>                 is(a, "MyArrayLikeConcreteSubclass")  # TRUE  --> ok
>>                 is(a, "ArrayLike")                    # TRUE  --> ok
>>                 is(a, "array")                        # FALSE --> ok
>>
>>              But:
>>
>>                 is.array(a)  # TRUE --> not ok!
>>
>>              Is is.array() confused by the presence of the .Data slot?
>>
>>
>>         It looks like the unary union somehow equates ArrayLike and array
>>
>>
>>     Clearly the unary union makes ArrayLike a parent of array, as it
>> should
>>     be. This can be confirmed by extends():
>>
>>        > extends("array", "ArrayLike")
>>        [1] TRUE
>>        > extends("ArrayLike", "array")
>>        [1] FALSE
>>
>>     The results for is(a, "ArrayLike") (TRUE) and is(a, "array") (FALSE)
>>     on a MyArrayLikeConcreteSubclass instance are consistent with this.
>>
>>     So the little 3-class hierarchy I end up with in the above example
>>     is exactly how expected:
>>
>>               ArrayLike
>>                ^    ^
>>                |    |
>>            array    MyArrayLikeConcreteSubclass
>>
>>     What is not expected is that MyArrayLikeConcreteSubclass has a .Data
>>     slot and that is.array(a) returns TRUE on a
>> MyArrayLikeConcreteSubclass
>>     object.
>>
>>     H.
>>
>>         and
>>         thus makes ArrayLike confer a dim attribute (and thus is.array(a)
>>         returns TRUE). Since S4 objects cannot have attributes that are
>> not
>>         slots, it must do this via a data part, thus the .Data slot.
>>
>>              I can fix it by defining an "is.array" method for
>>              MyArrayLikeConcreteSubclass objects:
>>
>>                 setMethod("is.array", "MyArrayLikeConcreteSubclass",
>>                     function(x) FALSE
>>                 )
>>
>>              However, it feels that I shouldn't have to do this.
>>
>>              Is the presence of the .Data slot in
>>         MyArrayLikeConcreteSubclass
>>              objects an unintended feature?
>>
>>              Thanks,
>>              H.
>>
>>               > sessionInfo()
>>              R Under development (unstable) (2016-01-07 r69884)
>>              Platform: x86_64-pc-linux-gnu (64-bit)
>>              Running under: Ubuntu 14.04.4 LTS
>>
>>              locale:
>>                [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>>                [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>>                [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>>                [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>>                [9] LC_ADDRESS=C               LC_TELEPHONE=C
>>              [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>>
>>              attached base packages:
>>              [1] stats     graphics  grDevices utils     datasets
>>         methods   base
>>
>>              --
>>              Herv? Pag?s
>>
>>              Program in Computational Biology
>>              Division of Public Health Sciences
>>              Fred Hutchinson Cancer Research Center
>>              1100 Fairview Ave. N, M1-B514
>>              P.O. Box 19024
>>              Seattle, WA 98109-1024
>>
>>              E-mail: hpages at fredhutch.org <mailto:hpages at fredhutch.org>
>>         <mailto:hpages at fredhutch.org <mailto:hpages at fredhutch.org>>
>>              Phone: (206) 667-5791 <tel:%28206%29%20667-5791>
>>         <tel:%28206%29%20667-5791>
>>              Fax: (206) 667-1319 <tel:%28206%29%20667-1319>
>>         <tel:%28206%29%20667-1319>
>>
>>              ______________________________________________
>>         R-devel at r-project.org <mailto:R-devel at r-project.org>
>>         <mailto:R-devel at r-project.org <mailto:R-devel at r-project.org>>
>>         mailing list
>>         https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>>
>>     --
>>     Herv? Pag?s
>>
>>     Program in Computational Biology
>>     Division of Public Health Sciences
>>     Fred Hutchinson Cancer Research Center
>>     1100 Fairview Ave. N, M1-B514
>>     P.O. Box 19024
>>     Seattle, WA 98109-1024
>>
>>     E-mail: hpages at fredhutch.org <mailto:hpages at fredhutch.org>
>>     Phone: (206) 667-5791 <tel:%28206%29%20667-5791>
>>     Fax: (206) 667-1319 <tel:%28206%29%20667-1319>
>>
>>
>>
> --
> Herv? Pag?s
>
> Program in Computational Biology
> Division of Public Health Sciences
> Fred Hutchinson Cancer Research Center
> 1100 Fairview Ave. N, M1-B514
> P.O. Box 19024
> Seattle, WA 98109-1024
>
> E-mail: hpages at fredhutch.org
> Phone:  (206) 667-5791
> Fax:    (206) 667-1319
>
>

	[[alternative HTML version deleted]]


From hpages at fredhutch.org  Sat Mar 19 21:03:44 2016
From: hpages at fredhutch.org (=?UTF-8?B?SGVydsOpIFBhZ8Oocw==?=)
Date: Sat, 19 Mar 2016 13:03:44 -0700
Subject: [Rd] unary class union of an S3 class
In-Reply-To: <CAOQ5Nydk1L1+Yr=oLv45nkH2V+P=jBDqzYnbTMg+p9757bUC+g@mail.gmail.com>
References: <56EC78DA.2010803@fredhutch.org>
	<CAOQ5NydT6YjFRw5xCTueA-e5DjM8pi0Y2fqUUb=PvJyJmtpeag@mail.gmail.com>
	<56ECFB70.2080506@fredhutch.org>
	<CAOQ5NycudrAu9tHeL2JYKM8jLiQRO4nT+-CM7ayf7teGSqra0A@mail.gmail.com>
	<56ED3820.3080001@fredhutch.org>
	<CAOQ5Nydk1L1+Yr=oLv45nkH2V+P=jBDqzYnbTMg+p9757bUC+g@mail.gmail.com>
Message-ID: <56EDB0A0.9010005@fredhutch.org>

On 03/19/2016 06:35 AM, Michael Lawrence wrote:
>
>
> On Sat, Mar 19, 2016 at 4:29 AM, Herv? Pag?s <hpages at fredhutch.org
> <mailto:hpages at fredhutch.org>> wrote:
>
>     On 03/19/2016 01:22 AM, Michael Lawrence wrote:
>
>
>
>         On Sat, Mar 19, 2016 at 12:10 AM, Herv? Pag?s
>         <hpages at fredhutch.org <mailto:hpages at fredhutch.org>
>         <mailto:hpages at fredhutch.org <mailto:hpages at fredhutch.org>>> wrote:
>
>              On 03/18/2016 03:28 PM, Michael Lawrence wrote:
>
>
>                  On Fri, Mar 18, 2016 at 2:53 PM, Herv? Pag?s
>                  <hpages at fredhutch.org <mailto:hpages at fredhutch.org>
>         <mailto:hpages at fredhutch.org <mailto:hpages at fredhutch.org>>
>                  <mailto:hpages at fredhutch.org
>         <mailto:hpages at fredhutch.org> <mailto:hpages at fredhutch.org
>         <mailto:hpages at fredhutch.org>>>> wrote:
>
>                       Hi,
>
>                       Short story
>                       -----------
>
>                          setClassUnion("ArrayLike", "array")
>
>                          showClass("ArrayLike")  # no slot
>
>                          setClass("MyArrayLikeConcreteSubclass",
>                              contains="ArrayLike",
>                              representation(stuff="ANY")
>                          )
>
>                          showClass("MyArrayLikeConcreteSubclass") # 2
>         slots!!
>
>                       That doesn't seem right.
>
>                       Long story
>                       ----------
>
>                       S4 provides at least 3 ways to create a little
>         class hierarchy
>                       like this:
>
>                               FooLike ............. virtual class with
>         no slot
>                                ^   ^
>                                |   |
>                              foo   anotherfoo ..... 2 concrete subclasses
>
>                       (1) The "standard" way: define FooLike first, then
>         foo and
>                  anotherfoo
>                       as subclasses of FooLike:
>
>                          setClass("FooLike")
>
>                          setClass("foo",
>                              contains="FooLike",
>                              representation(stuff="ANY")
>                          )
>
>                          setClass("anotherfoo",
>                              contains="FooLike",
>                              representation(stuff="ANY")
>                          )
>
>                          showClass("FooLike")    # displays foo and
>         anotherfoo as
>                                                  # known subclasses
>
>                          x1 <- new("foo")
>                          is(x1, "foo")           # TRUE
>                          is(x1, "FooLike")       # TRUE
>                          is(x1, "anotherfoo")    # FALSE
>
>                          x2 <- new("anotherfoo")
>                          is(x2, "anotherfoo")    # TRUE
>                          is(x2, "FooLike")       # TRUE
>                          is(x2, "foo")           # FALSE
>
>                       Everything works as expected.
>
>                       (2) Using a class union: define foo and anotherfoo
>         first,
>                  then FooLike
>                       as the union of foo and anotherfoo:
>
>                          setClass("foo", representation(stuff="ANY"))
>                          setClass("anotherfoo", representation(stuff="ANY"))
>                          setClassUnion("FooLike", c("foo", "anotherfoo"))
>
>                          showClass("FooLike")    # displays foo and
>         anotherfoo as
>                                                  # known subclasses
>
>                       (3) Using a *unary* class union: define foo first,
>         then
>                  FooLike as the
>                       (unary) union of foo, then anotherfoo as a
>         subclass of FooLike:
>
>                          setClass("foo", representation(stuff="ANY"))
>                          setClassUnion("FooLike", "foo")
>
>                          showClass("FooLike")   # displays foo as the
>         only known
>                  subclass
>
>                          setClass("anotherfoo",
>                              contains="FooLike",
>                              representation(stuff="ANY")
>                          )
>
>                          showClass("FooLike")   # now displays foo and
>         anotherfoo as
>                                                 # known subclasses
>
>                       The 3 ways lead to the same hierarchy. However the
>         3rd way is
>                       interesting because it allows one to define the
>         FooLike virtual
>                       class as the parent of an existing foo class that
>         s/he doesn't
>                       control.
>
>
>                  Why not use setIs() for this?
>
>
>                 > setClass("ArrayLike")
>                 > setIs("array", "ArrayLike")
>                 Error in setIs("array", "ArrayLike") :
>                   class ?array? is sealed; new superclasses can not be
>         defined,
>              except by 'setClassUnion'
>
>              How do you define a virtual class as the parent of an
>         existing class
>              with setIs?
>
>
>         You can only do that with setClassUnion(). But the new classes
>         should
>         use setIs() to inherit from the union. So it's:
>
>         setClassUnion("ArrayLike", "array")
>         setClass("MyArrayLike")
>         setIs("MyArrayLike", "ArrayLike")
>
>                  Everything then behaves as expected. I
>                  don't think it makes much sense to "contain" a class union.
>
>
>              Why is that? A class union is just a virtual class with no slot
>              that is the parent of the classes that are in the union.
>         All the
>              classes in the union contain their parent. What's
>         interesting is that
>              this union is actually open to new members: when I later
>         define a new
>              class that contains the class union, I'm just adding a new
>         member to
>              the union.
>
>                  Rather, you
>                  just want to establish the inheritance relationship.
>
>
>              Isn't what I'm doing when I define a new class that
>         contains the
>              class union?
>
>
>         Containing does two things: establishes the is() relationship
>         and adds
>         slots to the class.
>
>
>     I understand that. But in that case, since a class union has no slots,
>     one would expect that using setIs() is equivalent to containing.
>
>         These slots are comprised of the slots of the
>         contained class, and as a special case the "array" class and other
>         native types confer a data part that comes from the prototype of the
>         class. The "array" class has a double vector with a dim
>         attribute as its
>         prototype. That is all well understood. What is surprising is that
>         "ArrayLike" has the same prototype as "array". That happens via
>         setIs(doComplete=TRUE), called by setClassUnion(). When a class
>         gains
>         its first non-virtual child, the parent assumes the prototype of its
>         child.  I'm not sure why, but the logic is very explicit and
>         I've come
>         to just accept it as a "feature".
>
>
>     Never noticed that. Thanks for clarifying. So with this "feature":
>
>        - setClassUnion("A", c("B", "C")) is not the same as
>          setClassUnion("A", c("C", "B"))
>
>        - if 2 packages define concrete subclasses of a virtual
>          class defined in a 3rd package, the prototype of the virtual
>          class will depend on the order the packages are loaded
>
>        - using setIs("MyArrayLike", "ArrayLike") is not equivalent
>          to containing (even though ArrayLike has no slots)
>
>        - containing adds an undesirable .Data slot
>
>        - containing breaks is.array() but not is( , "array")
>
>     Seems pretty harmful to me. Would be good to understand the
>     rationale behind this feature. In particular it's not clear to me
>     why a virtual
>     class with no slot would need to have a prototype at all (i.e. other
>     than NULL).
>
>         I ran into this some months ago when
>         defining my own ArrayLike when working on a very similar package
>         to the
>         one you are developing ;)
>
>
>     After giving it more thoughts I realized that I can do without the
>     ArrayLike class. That will keep the class hierarchy in HDF5Array to the
>     strict minimum.
>
>
> Yea I've come to realize that declaring virtual classes that indicate
> whether an object behaves like a base type is overkill.

If it was just to indicate this, it would definitely be overkill.
But it's convenient to be able to define methods at the level of
ArrayLike. A typical use case is when a method for a subclass
coerces to "array" and delegates to the method for "array":

     x <- as.array(x)
     callGeneric()

If you don't have the ArrayLike class, you have to define the same
method over and over for each ArrayLike subclass.

It's also useful to be able to use ArrayLike as slots in other
classes.

Anyway, it turns out that I don't need any of these features in
HDF5Array, at least for now.

> It usually
> suffices to say that the object satisfies the basic contract of an
> array, list, vector, etc. It would be nice to have something like a Java
> interface for specifying such contracts.

I'd rather fix what we already have ;-)

H.

>
>     Thanks for the feedback,
>     H.
>
>
>
>
>                       For example, to define an ArrayLike class:
>
>                          setClassUnion("ArrayLike", "array")
>                          showClass("ArrayLike")  # displays array as a
>         known subclass
>
>                       Note that ArrayLike is virtual with no slots
>         (analog to a Java
>                       Interface), which is what is expected.
>
>                          setClass("MyArrayLikeConcreteSubclass",
>                              contains="ArrayLike",
>                              representation(stuff="ANY")
>                          )
>
>                          showClass("MyArrayLikeConcreteSubclass")  #
>         shows 2 slots!!
>
>                       What is the .Data slot doing here? I would expect
>         to see
>                  that slot
>                       if MyArrayLikeConcreteSubclass was extending array
>         but this
>                  is not
>                       the case here.
>
>                          a <- new("MyArrayLikeConcreteSubclass")
>
>                          is(a, "MyArrayLikeConcreteSubclass")  # TRUE
>         --> ok
>                          is(a, "ArrayLike")                    # TRUE
>         --> ok
>                          is(a, "array")                        # FALSE
>         --> ok
>
>                       But:
>
>                          is.array(a)  # TRUE --> not ok!
>
>                       Is is.array() confused by the presence of the
>         .Data slot?
>
>
>                  It looks like the unary union somehow equates ArrayLike
>         and array
>
>
>              Clearly the unary union makes ArrayLike a parent of array,
>         as it should
>              be. This can be confirmed by extends():
>
>                 > extends("array", "ArrayLike")
>                 [1] TRUE
>                 > extends("ArrayLike", "array")
>                 [1] FALSE
>
>              The results for is(a, "ArrayLike") (TRUE) and is(a,
>         "array") (FALSE)
>              on a MyArrayLikeConcreteSubclass instance are consistent
>         with this.
>
>              So the little 3-class hierarchy I end up with in the above
>         example
>              is exactly how expected:
>
>                        ArrayLike
>                         ^    ^
>                         |    |
>                     array    MyArrayLikeConcreteSubclass
>
>              What is not expected is that MyArrayLikeConcreteSubclass
>         has a .Data
>              slot and that is.array(a) returns TRUE on a
>         MyArrayLikeConcreteSubclass
>              object.
>
>              H.
>
>                  and
>                  thus makes ArrayLike confer a dim attribute (and thus
>         is.array(a)
>                  returns TRUE). Since S4 objects cannot have attributes
>         that are not
>                  slots, it must do this via a data part, thus the .Data
>         slot.
>
>                       I can fix it by defining an "is.array" method for
>                       MyArrayLikeConcreteSubclass objects:
>
>                          setMethod("is.array",
>         "MyArrayLikeConcreteSubclass",
>                              function(x) FALSE
>                          )
>
>                       However, it feels that I shouldn't have to do this.
>
>                       Is the presence of the .Data slot in
>                  MyArrayLikeConcreteSubclass
>                       objects an unintended feature?
>
>                       Thanks,
>                       H.
>
>                        > sessionInfo()
>                       R Under development (unstable) (2016-01-07 r69884)
>                       Platform: x86_64-pc-linux-gnu (64-bit)
>                       Running under: Ubuntu 14.04.4 LTS
>
>                       locale:
>                         [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>                         [3] LC_TIME=en_US.UTF-8
>         LC_COLLATE=en_US.UTF-8
>                         [5] LC_MONETARY=en_US.UTF-8
>         LC_MESSAGES=en_US.UTF-8
>                         [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>                         [9] LC_ADDRESS=C               LC_TELEPHONE=C
>                       [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>
>                       attached base packages:
>                       [1] stats     graphics  grDevices utils     datasets
>                  methods   base
>
>                       --
>                       Herv? Pag?s
>
>                       Program in Computational Biology
>                       Division of Public Health Sciences
>                       Fred Hutchinson Cancer Research Center
>                       1100 Fairview Ave. N, M1-B514
>                       P.O. Box 19024
>                       Seattle, WA 98109-1024
>
>                       E-mail: hpages at fredhutch.org
>         <mailto:hpages at fredhutch.org> <mailto:hpages at fredhutch.org
>         <mailto:hpages at fredhutch.org>>
>                  <mailto:hpages at fredhutch.org
>         <mailto:hpages at fredhutch.org> <mailto:hpages at fredhutch.org
>         <mailto:hpages at fredhutch.org>>>
>                       Phone: (206) 667-5791 <tel:%28206%29%20667-5791>
>         <tel:%28206%29%20667-5791>
>                  <tel:%28206%29%20667-5791>
>                       Fax: (206) 667-1319 <tel:%28206%29%20667-1319>
>         <tel:%28206%29%20667-1319>
>                  <tel:%28206%29%20667-1319>
>
>                       ______________________________________________
>         R-devel at r-project.org <mailto:R-devel at r-project.org>
>         <mailto:R-devel at r-project.org <mailto:R-devel at r-project.org>>
>                  <mailto:R-devel at r-project.org
>         <mailto:R-devel at r-project.org> <mailto:R-devel at r-project.org
>         <mailto:R-devel at r-project.org>>>
>                  mailing list
>         https://stat.ethz.ch/mailman/listinfo/r-devel
>
>
>
>              --
>              Herv? Pag?s
>
>              Program in Computational Biology
>              Division of Public Health Sciences
>              Fred Hutchinson Cancer Research Center
>              1100 Fairview Ave. N, M1-B514
>              P.O. Box 19024
>              Seattle, WA 98109-1024
>
>              E-mail: hpages at fredhutch.org <mailto:hpages at fredhutch.org>
>         <mailto:hpages at fredhutch.org <mailto:hpages at fredhutch.org>>
>              Phone: (206) 667-5791 <tel:%28206%29%20667-5791>
>         <tel:%28206%29%20667-5791>
>              Fax: (206) 667-1319 <tel:%28206%29%20667-1319>
>         <tel:%28206%29%20667-1319>
>
>
>
>     --
>     Herv? Pag?s
>
>     Program in Computational Biology
>     Division of Public Health Sciences
>     Fred Hutchinson Cancer Research Center
>     1100 Fairview Ave. N, M1-B514
>     P.O. Box 19024
>     Seattle, WA 98109-1024
>
>     E-mail: hpages at fredhutch.org <mailto:hpages at fredhutch.org>
>     Phone: (206) 667-5791 <tel:%28206%29%20667-5791>
>     Fax: (206) 667-1319 <tel:%28206%29%20667-1319>
>
>

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fredhutch.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From alfonso.izzo88 at gmail.com  Wed Mar 23 09:52:19 2016
From: alfonso.izzo88 at gmail.com (Alfonso Izzo)
Date: Wed, 23 Mar 2016 09:52:19 +0100
Subject: [Rd] R Memory Management
Message-ID: <CACL+WbQkx3T9VHkcQuOoUbF6kG=P6BUoCCu-2j6V_RTWFSa58Q@mail.gmail.com>

Good morning.
I am looking for some technical information about how R manages memory
and data allocation...
Could you please help me??

-- 
Thank you all.
Alfonso Izzo.

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Wed Mar 23 10:42:29 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 23 Mar 2016 05:42:29 -0400
Subject: [Rd] R Memory Management
In-Reply-To: <CACL+WbQkx3T9VHkcQuOoUbF6kG=P6BUoCCu-2j6V_RTWFSa58Q@mail.gmail.com>
References: <CACL+WbQkx3T9VHkcQuOoUbF6kG=P6BUoCCu-2j6V_RTWFSa58Q@mail.gmail.com>
Message-ID: <56F26505.5030402@gmail.com>

On 23/03/2016 4:52 AM, Alfonso Izzo wrote:
> Good morning.
> I am looking for some technical information about how R manages memory
> and data allocation...
> Could you please help me??
>

There is some user-level information in Writing R Extensions in section 
5.9 among other places, some internals documentation in R Internals, and 
some more detailed technical information in the Technical Papers 
collection, in particular

Under new memory management. Luke Tierney, R News, 1(1):10-11, January 2001

These are all linked into the help system.

Duncan Murdoch


From maechler at stat.math.ethz.ch  Thu Mar 24 18:09:27 2016
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 24 Mar 2016 18:09:27 +0100
Subject: [Rd] summary( prcomp(*, tol = .) ) -- and 'rank.'
In-Reply-To: <22257.31275.659023.572089@stat.math.ethz.ch>
References: <6F13CD7F-B11B-4D8B-A0AE-47A438A3A196@noaa.gov>
	<22257.31275.659023.572089@stat.math.ethz.ch>
Message-ID: <22260.8007.313385.414830@stat.math.ethz.ch>

Following from the R-help thread of March 22 on "Memory usage in prcomp",

I've started looking into adding an optional   'rank.'  argument
to prcomp  allowing to more efficiently get only a few PCs
instead of the full p PCs, say when p = 1000 and you know you
only want 5 PCs.

 (https://stat.ethz.ch/pipermail/r-help/2016-March/437228.html

As it was mentioned, we already have an optional 'tol' argument
which allows *not* to choose all PCs.

When I do that,
say

     C <- chol(S <- toeplitz(.9 ^ (0:31))) # Cov.matrix and its root
     all.equal(S, crossprod(C))
     set.seed(17)
     X <- matrix(rnorm(32000), 1000, 32)
     Z <- X %*% C  ## ==>  cov(Z) ~=  C'C = S
     all.equal(cov(Z), S, tol = 0.08)
     pZ <- prcomp(Z, tol = 0.1)
     summary(pZ) # only ~14 PCs (out of 32)
     
I get for the last line, the   summary.prcomp(.) call :

> summary(pZ) # only ~14 PCs (out of 32)
Importance of components:
                          PC1    PC2    PC3    PC4     PC5     PC6     PC7     PC8
Standard deviation     3.6415 2.7178 1.8447 1.3943 1.10207 0.90922 0.76951 0.67490
Proportion of Variance 0.4352 0.2424 0.1117 0.0638 0.03986 0.02713 0.01943 0.01495
Cumulative Proportion  0.4352 0.6775 0.7892 0.8530 0.89288 0.92001 0.93944 0.95439
                           PC9    PC10    PC11    PC12    PC13   PC14
Standard deviation     0.60833 0.51638 0.49048 0.44452 0.40326 0.3904
Proportion of Variance 0.01214 0.00875 0.00789 0.00648 0.00534 0.0050
Cumulative Proportion  0.96653 0.97528 0.98318 0.98966 0.99500 1.0000
>

which computes the *proportions* as if there were only 14 PCs in
total (but there were 32 originally).

I would think that the summary should  or could in addition show
the usual  "proportion of variance explained"  like result which
does involve all 32  variances or std.dev.s ... which are
returned from the svd() anyway, even in the case when I use my
new 'rank.' argument which only returns a "few" PCs instead of
all.

Would you think the current  summary() output is good enough or
rather misleading?

I think I would want to see (possibly in addition) proportions
with respect to the full variance and not just to the variance
of those few components selected.

Opinions?

Martin Maechler
ETH Zurich


From kasperdanielhansen at gmail.com  Thu Mar 24 19:58:24 2016
From: kasperdanielhansen at gmail.com (Kasper Daniel Hansen)
Date: Thu, 24 Mar 2016 14:58:24 -0400
Subject: [Rd] summary( prcomp(*, tol = .) ) -- and 'rank.'
In-Reply-To: <22260.8007.313385.414830@stat.math.ethz.ch>
References: <6F13CD7F-B11B-4D8B-A0AE-47A438A3A196@noaa.gov>
	<22257.31275.659023.572089@stat.math.ethz.ch>
	<22260.8007.313385.414830@stat.math.ethz.ch>
Message-ID: <CAC2h7uspi2uzATUEPUVPJ7OOJWdAf276rVUf_0DqLfBkRGZ9Jg@mail.gmail.com>

Martin, I fully agree.  This becomes an issue when you have big matrices.

(Note that there are awesome methods for actually only computing a small
number of PCs (unlike your code which uses svn which gets all of them);
these are available in various CRAN packages).

Best,
Kasper

On Thu, Mar 24, 2016 at 1:09 PM, Martin Maechler <maechler at stat.math.ethz.ch
> wrote:

> Following from the R-help thread of March 22 on "Memory usage in prcomp",
>
> I've started looking into adding an optional   'rank.'  argument
> to prcomp  allowing to more efficiently get only a few PCs
> instead of the full p PCs, say when p = 1000 and you know you
> only want 5 PCs.
>
>  (https://stat.ethz.ch/pipermail/r-help/2016-March/437228.html
>
> As it was mentioned, we already have an optional 'tol' argument
> which allows *not* to choose all PCs.
>
> When I do that,
> say
>
>      C <- chol(S <- toeplitz(.9 ^ (0:31))) # Cov.matrix and its root
>      all.equal(S, crossprod(C))
>      set.seed(17)
>      X <- matrix(rnorm(32000), 1000, 32)
>      Z <- X %*% C  ## ==>  cov(Z) ~=  C'C = S
>      all.equal(cov(Z), S, tol = 0.08)
>      pZ <- prcomp(Z, tol = 0.1)
>      summary(pZ) # only ~14 PCs (out of 32)
>
> I get for the last line, the   summary.prcomp(.) call :
>
> > summary(pZ) # only ~14 PCs (out of 32)
> Importance of components:
>                           PC1    PC2    PC3    PC4     PC5     PC6
>  PC7     PC8
> Standard deviation     3.6415 2.7178 1.8447 1.3943 1.10207 0.90922 0.76951
> 0.67490
> Proportion of Variance 0.4352 0.2424 0.1117 0.0638 0.03986 0.02713 0.01943
> 0.01495
> Cumulative Proportion  0.4352 0.6775 0.7892 0.8530 0.89288 0.92001 0.93944
> 0.95439
>                            PC9    PC10    PC11    PC12    PC13   PC14
> Standard deviation     0.60833 0.51638 0.49048 0.44452 0.40326 0.3904
> Proportion of Variance 0.01214 0.00875 0.00789 0.00648 0.00534 0.0050
> Cumulative Proportion  0.96653 0.97528 0.98318 0.98966 0.99500 1.0000
> >
>
> which computes the *proportions* as if there were only 14 PCs in
> total (but there were 32 originally).
>
> I would think that the summary should  or could in addition show
> the usual  "proportion of variance explained"  like result which
> does involve all 32  variances or std.dev.s ... which are
> returned from the svd() anyway, even in the case when I use my
> new 'rank.' argument which only returns a "few" PCs instead of
> all.
>
> Would you think the current  summary() output is good enough or
> rather misleading?
>
> I think I would want to see (possibly in addition) proportions
> with respect to the full variance and not just to the variance
> of those few components selected.
>
> Opinions?
>
> Martin Maechler
> ETH Zurich
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From sbronder at stevebronder.com  Fri Mar 25 00:01:46 2016
From: sbronder at stevebronder.com (Steve Bronder)
Date: Thu, 24 Mar 2016 19:01:46 -0400
Subject: [Rd] summary( prcomp(*, tol = .) ) -- and 'rank.'
In-Reply-To: <CAC2h7uspi2uzATUEPUVPJ7OOJWdAf276rVUf_0DqLfBkRGZ9Jg@mail.gmail.com>
References: <6F13CD7F-B11B-4D8B-A0AE-47A438A3A196@noaa.gov>
	<22257.31275.659023.572089@stat.math.ethz.ch>
	<22260.8007.313385.414830@stat.math.ethz.ch>
	<CAC2h7uspi2uzATUEPUVPJ7OOJWdAf276rVUf_0DqLfBkRGZ9Jg@mail.gmail.com>
Message-ID: <CAAVP=a=58VTBbNbW=DhCy85MG+kGmXv_VnxXoJZnJm5p2NR4=g@mail.gmail.com>

I agree with Kasper, this is a 'big' issue. Does your method of taking only
n PCs reduce the load on memory?

The new addition to the summary looks like a good idea, but Proportion of
Variance as you describe it may be confusing to new users. Am I correct in
saying Proportion of variance describes the amount of variance with respect
to the number of components the user chooses to show? So if I only choose
one I will explain 100% of the variance? I think showing 'Total Proportion
of Variance' is important if that is the case.

Regards,

Steve Bronder
Website: stevebronder.com
Phone: 412-719-1282
Email: sbronder at stevebronder.com


On Thu, Mar 24, 2016 at 2:58 PM, Kasper Daniel Hansen <
kasperdanielhansen at gmail.com> wrote:

> Martin, I fully agree.  This becomes an issue when you have big matrices.
>
> (Note that there are awesome methods for actually only computing a small
> number of PCs (unlike your code which uses svn which gets all of them);
> these are available in various CRAN packages).
>
> Best,
> Kasper
>
> On Thu, Mar 24, 2016 at 1:09 PM, Martin Maechler <
> maechler at stat.math.ethz.ch
> > wrote:
>
> > Following from the R-help thread of March 22 on "Memory usage in prcomp",
> >
> > I've started looking into adding an optional   'rank.'  argument
> > to prcomp  allowing to more efficiently get only a few PCs
> > instead of the full p PCs, say when p = 1000 and you know you
> > only want 5 PCs.
> >
> >  (https://stat.ethz.ch/pipermail/r-help/2016-March/437228.html
> >
> > As it was mentioned, we already have an optional 'tol' argument
> > which allows *not* to choose all PCs.
> >
> > When I do that,
> > say
> >
> >      C <- chol(S <- toeplitz(.9 ^ (0:31))) # Cov.matrix and its root
> >      all.equal(S, crossprod(C))
> >      set.seed(17)
> >      X <- matrix(rnorm(32000), 1000, 32)
> >      Z <- X %*% C  ## ==>  cov(Z) ~=  C'C = S
> >      all.equal(cov(Z), S, tol = 0.08)
> >      pZ <- prcomp(Z, tol = 0.1)
> >      summary(pZ) # only ~14 PCs (out of 32)
> >
> > I get for the last line, the   summary.prcomp(.) call :
> >
> > > summary(pZ) # only ~14 PCs (out of 32)
> > Importance of components:
> >                           PC1    PC2    PC3    PC4     PC5     PC6
> >  PC7     PC8
> > Standard deviation     3.6415 2.7178 1.8447 1.3943 1.10207 0.90922
> 0.76951
> > 0.67490
> > Proportion of Variance 0.4352 0.2424 0.1117 0.0638 0.03986 0.02713
> 0.01943
> > 0.01495
> > Cumulative Proportion  0.4352 0.6775 0.7892 0.8530 0.89288 0.92001
> 0.93944
> > 0.95439
> >                            PC9    PC10    PC11    PC12    PC13   PC14
> > Standard deviation     0.60833 0.51638 0.49048 0.44452 0.40326 0.3904
> > Proportion of Variance 0.01214 0.00875 0.00789 0.00648 0.00534 0.0050
> > Cumulative Proportion  0.96653 0.97528 0.98318 0.98966 0.99500 1.0000
> > >
> >
> > which computes the *proportions* as if there were only 14 PCs in
> > total (but there were 32 originally).
> >
> > I would think that the summary should  or could in addition show
> > the usual  "proportion of variance explained"  like result which
> > does involve all 32  variances or std.dev.s ... which are
> > returned from the svd() anyway, even in the case when I use my
> > new 'rank.' argument which only returns a "few" PCs instead of
> > all.
> >
> > Would you think the current  summary() output is good enough or
> > rather misleading?
> >
> > I think I would want to see (possibly in addition) proportions
> > with respect to the full variance and not just to the variance
> > of those few components selected.
> >
> > Opinions?
> >
> > Martin Maechler
> > ETH Zurich
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From sbronder at stevebronder.com  Fri Mar 25 00:02:28 2016
From: sbronder at stevebronder.com (Steve Bronder)
Date: Thu, 24 Mar 2016 19:02:28 -0400
Subject: [Rd] summary( prcomp(*, tol = .) ) -- and 'rank.'
In-Reply-To: <CAC2h7uspi2uzATUEPUVPJ7OOJWdAf276rVUf_0DqLfBkRGZ9Jg@mail.gmail.com>
References: <6F13CD7F-B11B-4D8B-A0AE-47A438A3A196@noaa.gov>
	<22257.31275.659023.572089@stat.math.ethz.ch>
	<22260.8007.313385.414830@stat.math.ethz.ch>
	<CAC2h7uspi2uzATUEPUVPJ7OOJWdAf276rVUf_0DqLfBkRGZ9Jg@mail.gmail.com>
Message-ID: <CAAVP=anLKjKX9-tS6v3geo9SSOqxz2tEv11BSbk9er9znmSzFw@mail.gmail.com>

I agree with Kasper, this is a 'big' issue. Does your method of taking only
n PCs reduce the load on memory?

The new addition to the summary looks like a good idea, but Proportion of
Variance as you describe it may be confusing to new users. Am I correct in
saying Proportion of variance describes the amount of variance with respect
to the number of components the user chooses to show? So if I only choose
one I will explain 100% of the variance? I think showing 'Total Proportion
of Variance' is important if that is the case.


Regards,

Steve Bronder
Website: stevebronder.com
Phone: 412-719-1282
Email: sbronder at stevebronder.com


On Thu, Mar 24, 2016 at 2:58 PM, Kasper Daniel Hansen <
kasperdanielhansen at gmail.com> wrote:

> Martin, I fully agree.  This becomes an issue when you have big matrices.
>
> (Note that there are awesome methods for actually only computing a small
> number of PCs (unlike your code which uses svn which gets all of them);
> these are available in various CRAN packages).
>
> Best,
> Kasper
>
> On Thu, Mar 24, 2016 at 1:09 PM, Martin Maechler <
> maechler at stat.math.ethz.ch
> > wrote:
>
> > Following from the R-help thread of March 22 on "Memory usage in prcomp",
> >
> > I've started looking into adding an optional   'rank.'  argument
> > to prcomp  allowing to more efficiently get only a few PCs
> > instead of the full p PCs, say when p = 1000 and you know you
> > only want 5 PCs.
> >
> >  (https://stat.ethz.ch/pipermail/r-help/2016-March/437228.html
> >
> > As it was mentioned, we already have an optional 'tol' argument
> > which allows *not* to choose all PCs.
> >
> > When I do that,
> > say
> >
> >      C <- chol(S <- toeplitz(.9 ^ (0:31))) # Cov.matrix and its root
> >      all.equal(S, crossprod(C))
> >      set.seed(17)
> >      X <- matrix(rnorm(32000), 1000, 32)
> >      Z <- X %*% C  ## ==>  cov(Z) ~=  C'C = S
> >      all.equal(cov(Z), S, tol = 0.08)
> >      pZ <- prcomp(Z, tol = 0.1)
> >      summary(pZ) # only ~14 PCs (out of 32)
> >
> > I get for the last line, the   summary.prcomp(.) call :
> >
> > > summary(pZ) # only ~14 PCs (out of 32)
> > Importance of components:
> >                           PC1    PC2    PC3    PC4     PC5     PC6
> >  PC7     PC8
> > Standard deviation     3.6415 2.7178 1.8447 1.3943 1.10207 0.90922
> 0.76951
> > 0.67490
> > Proportion of Variance 0.4352 0.2424 0.1117 0.0638 0.03986 0.02713
> 0.01943
> > 0.01495
> > Cumulative Proportion  0.4352 0.6775 0.7892 0.8530 0.89288 0.92001
> 0.93944
> > 0.95439
> >                            PC9    PC10    PC11    PC12    PC13   PC14
> > Standard deviation     0.60833 0.51638 0.49048 0.44452 0.40326 0.3904
> > Proportion of Variance 0.01214 0.00875 0.00789 0.00648 0.00534 0.0050
> > Cumulative Proportion  0.96653 0.97528 0.98318 0.98966 0.99500 1.0000
> > >
> >
> > which computes the *proportions* as if there were only 14 PCs in
> > total (but there were 32 originally).
> >
> > I would think that the summary should  or could in addition show
> > the usual  "proportion of variance explained"  like result which
> > does involve all 32  variances or std.dev.s ... which are
> > returned from the svd() anyway, even in the case when I use my
> > new 'rank.' argument which only returns a "few" PCs instead of
> > all.
> >
> > Would you think the current  summary() output is good enough or
> > rather misleading?
> >
> > I think I would want to see (possibly in addition) proportions
> > with respect to the full variance and not just to the variance
> > of those few components selected.
> >
> > Opinions?
> >
> > Martin Maechler
> > ETH Zurich
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Fri Mar 25 09:41:00 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 25 Mar 2016 09:41:00 +0100
Subject: [Rd] summary( prcomp(*, tol = .) ) -- and 'rank.'
In-Reply-To: <CAAVP=anLKjKX9-tS6v3geo9SSOqxz2tEv11BSbk9er9znmSzFw@mail.gmail.com>
References: <6F13CD7F-B11B-4D8B-A0AE-47A438A3A196@noaa.gov>
	<22257.31275.659023.572089@stat.math.ethz.ch>
	<22260.8007.313385.414830@stat.math.ethz.ch>
	<CAC2h7uspi2uzATUEPUVPJ7OOJWdAf276rVUf_0DqLfBkRGZ9Jg@mail.gmail.com>
	<CAAVP=anLKjKX9-tS6v3geo9SSOqxz2tEv11BSbk9er9znmSzFw@mail.gmail.com>
Message-ID: <2F82767A-47E8-4181-BE1F-179D23F37931@gmail.com>

As I see it, the display showing the first p << n PCs adding up to 100% of the variance is plainly wrong. 

I suspect it comes about via a mental short-circuit: If we try to control p using a tolerance, then that amounts to saying that the remaining PCs are effectively zero-variance, but that is (usually) not the intention at all. 

The common case is that the remainder terms have a roughly _constant_, small-ish variance and are interpreted as noise. Of course the magnitude of the noise is important information.  

-pd

> On 25 Mar 2016, at 00:02 , Steve Bronder <sbronder at stevebronder.com> wrote:
> 
> I agree with Kasper, this is a 'big' issue. Does your method of taking only
> n PCs reduce the load on memory?
> 
> The new addition to the summary looks like a good idea, but Proportion of
> Variance as you describe it may be confusing to new users. Am I correct in
> saying Proportion of variance describes the amount of variance with respect
> to the number of components the user chooses to show? So if I only choose
> one I will explain 100% of the variance? I think showing 'Total Proportion
> of Variance' is important if that is the case.
> 
> 
> Regards,
> 
> Steve Bronder
> Website: stevebronder.com
> Phone: 412-719-1282
> Email: sbronder at stevebronder.com
> 
> 
> On Thu, Mar 24, 2016 at 2:58 PM, Kasper Daniel Hansen <
> kasperdanielhansen at gmail.com> wrote:
> 
>> Martin, I fully agree.  This becomes an issue when you have big matrices.
>> 
>> (Note that there are awesome methods for actually only computing a small
>> number of PCs (unlike your code which uses svn which gets all of them);
>> these are available in various CRAN packages).
>> 
>> Best,
>> Kasper
>> 
>> On Thu, Mar 24, 2016 at 1:09 PM, Martin Maechler <
>> maechler at stat.math.ethz.ch
>>> wrote:
>> 
>>> Following from the R-help thread of March 22 on "Memory usage in prcomp",
>>> 
>>> I've started looking into adding an optional   'rank.'  argument
>>> to prcomp  allowing to more efficiently get only a few PCs
>>> instead of the full p PCs, say when p = 1000 and you know you
>>> only want 5 PCs.
>>> 
>>> (https://stat.ethz.ch/pipermail/r-help/2016-March/437228.html
>>> 
>>> As it was mentioned, we already have an optional 'tol' argument
>>> which allows *not* to choose all PCs.
>>> 
>>> When I do that,
>>> say
>>> 
>>>     C <- chol(S <- toeplitz(.9 ^ (0:31))) # Cov.matrix and its root
>>>     all.equal(S, crossprod(C))
>>>     set.seed(17)
>>>     X <- matrix(rnorm(32000), 1000, 32)
>>>     Z <- X %*% C  ## ==>  cov(Z) ~=  C'C = S
>>>     all.equal(cov(Z), S, tol = 0.08)
>>>     pZ <- prcomp(Z, tol = 0.1)
>>>     summary(pZ) # only ~14 PCs (out of 32)
>>> 
>>> I get for the last line, the   summary.prcomp(.) call :
>>> 
>>>> summary(pZ) # only ~14 PCs (out of 32)
>>> Importance of components:
>>>                          PC1    PC2    PC3    PC4     PC5     PC6
>>> PC7     PC8
>>> Standard deviation     3.6415 2.7178 1.8447 1.3943 1.10207 0.90922
>> 0.76951
>>> 0.67490
>>> Proportion of Variance 0.4352 0.2424 0.1117 0.0638 0.03986 0.02713
>> 0.01943
>>> 0.01495
>>> Cumulative Proportion  0.4352 0.6775 0.7892 0.8530 0.89288 0.92001
>> 0.93944
>>> 0.95439
>>>                           PC9    PC10    PC11    PC12    PC13   PC14
>>> Standard deviation     0.60833 0.51638 0.49048 0.44452 0.40326 0.3904
>>> Proportion of Variance 0.01214 0.00875 0.00789 0.00648 0.00534 0.0050
>>> Cumulative Proportion  0.96653 0.97528 0.98318 0.98966 0.99500 1.0000
>>>> 
>>> 
>>> which computes the *proportions* as if there were only 14 PCs in
>>> total (but there were 32 originally).
>>> 
>>> I would think that the summary should  or could in addition show
>>> the usual  "proportion of variance explained"  like result which
>>> does involve all 32  variances or std.dev.s ... which are
>>> returned from the svd() anyway, even in the case when I use my
>>> new 'rank.' argument which only returns a "few" PCs instead of
>>> all.
>>> 
>>> Would you think the current  summary() output is good enough or
>>> rather misleading?
>>> 
>>> I think I would want to see (possibly in addition) proportions
>>> with respect to the full variance and not just to the variance
>>> of those few components selected.
>>> 
>>> Opinions?
>>> 
>>> Martin Maechler
>>> ETH Zurich
>>> 
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>> 
>> 
>>        [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From jari.oksanen at oulu.fi  Fri Mar 25 10:08:38 2016
From: jari.oksanen at oulu.fi (Jari Oksanen)
Date: Fri, 25 Mar 2016 09:08:38 +0000
Subject: [Rd] summary( prcomp(*, tol = .) ) -- and 'rank.'
In-Reply-To: <2F82767A-47E8-4181-BE1F-179D23F37931@gmail.com>
References: <6F13CD7F-B11B-4D8B-A0AE-47A438A3A196@noaa.gov>
	<22257.31275.659023.572089@stat.math.ethz.ch>
	<22260.8007.313385.414830@stat.math.ethz.ch>
	<CAC2h7uspi2uzATUEPUVPJ7OOJWdAf276rVUf_0DqLfBkRGZ9Jg@mail.gmail.com>
	<CAAVP=anLKjKX9-tS6v3geo9SSOqxz2tEv11BSbk9er9znmSzFw@mail.gmail.com>
	<2F82767A-47E8-4181-BE1F-179D23F37931@gmail.com>
Message-ID: <E8DA8672-27BF-4497-B2C2-F92197FEA017@oulu.fi>


> On 25 Mar 2016, at 10:41 am, peter dalgaard <pdalgd at gmail.com> wrote:
> 
> As I see it, the display showing the first p << n PCs adding up to 100% of the variance is plainly wrong. 
> 
> I suspect it comes about via a mental short-circuit: If we try to control p using a tolerance, then that amounts to saying that the remaining PCs are effectively zero-variance, but that is (usually) not the intention at all. 
> 
> The common case is that the remainder terms have a roughly _constant_, small-ish variance and are interpreted as noise. Of course the magnitude of the noise is important information.  
> 
But then you should use Factor Analysis which has that concept of ?noise? (unlike PCA).

Cheers, Jari Oksanen

>> On 25 Mar 2016, at 00:02 , Steve Bronder <sbronder at stevebronder.com> wrote:
>> 
>> I agree with Kasper, this is a 'big' issue. Does your method of taking only
>> n PCs reduce the load on memory?
>> 
>> The new addition to the summary looks like a good idea, but Proportion of
>> Variance as you describe it may be confusing to new users. Am I correct in
>> saying Proportion of variance describes the amount of variance with respect
>> to the number of components the user chooses to show? So if I only choose
>> one I will explain 100% of the variance? I think showing 'Total Proportion
>> of Variance' is important if that is the case.
>> 
>> 
>> Regards,
>> 
>> Steve Bronder
>> Website: stevebronder.com
>> Phone: 412-719-1282
>> Email: sbronder at stevebronder.com
>> 
>> 
>> On Thu, Mar 24, 2016 at 2:58 PM, Kasper Daniel Hansen <
>> kasperdanielhansen at gmail.com> wrote:
>> 
>>> Martin, I fully agree.  This becomes an issue when you have big matrices.
>>> 
>>> (Note that there are awesome methods for actually only computing a small
>>> number of PCs (unlike your code which uses svn which gets all of them);
>>> these are available in various CRAN packages).
>>> 
>>> Best,
>>> Kasper
>>> 
>>> On Thu, Mar 24, 2016 at 1:09 PM, Martin Maechler <
>>> maechler at stat.math.ethz.ch
>>>> wrote:
>>> 
>>>> Following from the R-help thread of March 22 on "Memory usage in prcomp",
>>>> 
>>>> I've started looking into adding an optional   'rank.'  argument
>>>> to prcomp  allowing to more efficiently get only a few PCs
>>>> instead of the full p PCs, say when p = 1000 and you know you
>>>> only want 5 PCs.
>>>> 
>>>> (https://stat.ethz.ch/pipermail/r-help/2016-March/437228.html
>>>> 
>>>> As it was mentioned, we already have an optional 'tol' argument
>>>> which allows *not* to choose all PCs.
>>>> 
>>>> When I do that,
>>>> say
>>>> 
>>>>    C <- chol(S <- toeplitz(.9 ^ (0:31))) # Cov.matrix and its root
>>>>    all.equal(S, crossprod(C))
>>>>    set.seed(17)
>>>>    X <- matrix(rnorm(32000), 1000, 32)
>>>>    Z <- X %*% C  ## ==>  cov(Z) ~=  C'C = S
>>>>    all.equal(cov(Z), S, tol = 0.08)
>>>>    pZ <- prcomp(Z, tol = 0.1)
>>>>    summary(pZ) # only ~14 PCs (out of 32)
>>>> 
>>>> I get for the last line, the   summary.prcomp(.) call :
>>>> 
>>>>> summary(pZ) # only ~14 PCs (out of 32)
>>>> Importance of components:
>>>>                         PC1    PC2    PC3    PC4     PC5     PC6
>>>> PC7     PC8
>>>> Standard deviation     3.6415 2.7178 1.8447 1.3943 1.10207 0.90922
>>> 0.76951
>>>> 0.67490
>>>> Proportion of Variance 0.4352 0.2424 0.1117 0.0638 0.03986 0.02713
>>> 0.01943
>>>> 0.01495
>>>> Cumulative Proportion  0.4352 0.6775 0.7892 0.8530 0.89288 0.92001
>>> 0.93944
>>>> 0.95439
>>>>                          PC9    PC10    PC11    PC12    PC13   PC14
>>>> Standard deviation     0.60833 0.51638 0.49048 0.44452 0.40326 0.3904
>>>> Proportion of Variance 0.01214 0.00875 0.00789 0.00648 0.00534 0.0050
>>>> Cumulative Proportion  0.96653 0.97528 0.98318 0.98966 0.99500 1.0000
>>>>> 
>>>> 
>>>> which computes the *proportions* as if there were only 14 PCs in
>>>> total (but there were 32 originally).
>>>> 
>>>> I would think that the summary should  or could in addition show
>>>> the usual  "proportion of variance explained"  like result which
>>>> does involve all 32  variances or std.dev.s ... which are
>>>> returned from the svd() anyway, even in the case when I use my
>>>> new 'rank.' argument which only returns a "few" PCs instead of
>>>> all.
>>>> 
>>>> Would you think the current  summary() output is good enough or
>>>> rather misleading?
>>>> 
>>>> I think I would want to see (possibly in addition) proportions
>>>> with respect to the full variance and not just to the variance
>>>> of those few components selected.
>>>> 
>>>> Opinions?
>>>> 
>>>> Martin Maechler
>>>> ETH Zurich
>>>> 
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>> 
>>> 
>>>       [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>> 
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> -- 
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Office: A 4.23
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From pdalgd at gmail.com  Fri Mar 25 10:45:28 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 25 Mar 2016 10:45:28 +0100
Subject: [Rd] summary( prcomp(*, tol = .) ) -- and 'rank.'
In-Reply-To: <E8DA8672-27BF-4497-B2C2-F92197FEA017@oulu.fi>
References: <6F13CD7F-B11B-4D8B-A0AE-47A438A3A196@noaa.gov>
	<22257.31275.659023.572089@stat.math.ethz.ch>
	<22260.8007.313385.414830@stat.math.ethz.ch>
	<CAC2h7uspi2uzATUEPUVPJ7OOJWdAf276rVUf_0DqLfBkRGZ9Jg@mail.gmail.com>
	<CAAVP=anLKjKX9-tS6v3geo9SSOqxz2tEv11BSbk9er9znmSzFw@mail.gmail.com>
	<2F82767A-47E8-4181-BE1F-179D23F37931@gmail.com>
	<E8DA8672-27BF-4497-B2C2-F92197FEA017@oulu.fi>
Message-ID: <E4E00FB3-91D1-4D11-BD89-91791C3391D6@gmail.com>


> On 25 Mar 2016, at 10:08 , Jari Oksanen <jari.oksanen at oulu.fi> wrote:
> 
>> 
>> On 25 Mar 2016, at 10:41 am, peter dalgaard <pdalgd at gmail.com> wrote:
>> 
>> As I see it, the display showing the first p << n PCs adding up to 100% of the variance is plainly wrong. 
>> 
>> I suspect it comes about via a mental short-circuit: If we try to control p using a tolerance, then that amounts to saying that the remaining PCs are effectively zero-variance, but that is (usually) not the intention at all. 
>> 
>> The common case is that the remainder terms have a roughly _constant_, small-ish variance and are interpreted as noise. Of course the magnitude of the noise is important information.  
>> 
> But then you should use Factor Analysis which has that concept of ?noise? (unlike PCA).

Actually, FA has a slightly different concept of noise. PCA can be interpreted as a purely technical operation, but also as an FA variant with same variance for all components.

Specifically, FA is 

Sigma = LL' + Psi

with Psi a diagonal matrix. If Psi = sigma^2 I , then L can be determined (up to rotation) as the first p components of PCA. (This is used in ML algorithms for FA since it allows you to concentrate the likelihood to be a function of Psi.)

Methods like PC regression are not being very specific about the model, but the underlying line of thought is that PCs with small variances are "uninformative", so that you can make do with only the first handful regressors. I tend to interpret "uninformative" as "noise-like" in these contexts.

-pd

> 
> Cheers, Jari Oksanen
> 
>>> On 25 Mar 2016, at 00:02 , Steve Bronder <sbronder at stevebronder.com> wrote:
>>> 
>>> I agree with Kasper, this is a 'big' issue. Does your method of taking only
>>> n PCs reduce the load on memory?
>>> 
>>> The new addition to the summary looks like a good idea, but Proportion of
>>> Variance as you describe it may be confusing to new users. Am I correct in
>>> saying Proportion of variance describes the amount of variance with respect
>>> to the number of components the user chooses to show? So if I only choose
>>> one I will explain 100% of the variance? I think showing 'Total Proportion
>>> of Variance' is important if that is the case.
>>> 
>>> 
>>> Regards,
>>> 
>>> Steve Bronder
>>> Website: stevebronder.com
>>> Phone: 412-719-1282
>>> Email: sbronder at stevebronder.com
>>> 
>>> 
>>> On Thu, Mar 24, 2016 at 2:58 PM, Kasper Daniel Hansen <
>>> kasperdanielhansen at gmail.com> wrote:
>>> 
>>>> Martin, I fully agree.  This becomes an issue when you have big matrices.
>>>> 
>>>> (Note that there are awesome methods for actually only computing a small
>>>> number of PCs (unlike your code which uses svn which gets all of them);
>>>> these are available in various CRAN packages).
>>>> 
>>>> Best,
>>>> Kasper
>>>> 
>>>> On Thu, Mar 24, 2016 at 1:09 PM, Martin Maechler <
>>>> maechler at stat.math.ethz.ch
>>>>> wrote:
>>>> 
>>>>> Following from the R-help thread of March 22 on "Memory usage in prcomp",
>>>>> 
>>>>> I've started looking into adding an optional   'rank.'  argument
>>>>> to prcomp  allowing to more efficiently get only a few PCs
>>>>> instead of the full p PCs, say when p = 1000 and you know you
>>>>> only want 5 PCs.
>>>>> 
>>>>> (https://stat.ethz.ch/pipermail/r-help/2016-March/437228.html
>>>>> 
>>>>> As it was mentioned, we already have an optional 'tol' argument
>>>>> which allows *not* to choose all PCs.
>>>>> 
>>>>> When I do that,
>>>>> say
>>>>> 
>>>>>   C <- chol(S <- toeplitz(.9 ^ (0:31))) # Cov.matrix and its root
>>>>>   all.equal(S, crossprod(C))
>>>>>   set.seed(17)
>>>>>   X <- matrix(rnorm(32000), 1000, 32)
>>>>>   Z <- X %*% C  ## ==>  cov(Z) ~=  C'C = S
>>>>>   all.equal(cov(Z), S, tol = 0.08)
>>>>>   pZ <- prcomp(Z, tol = 0.1)
>>>>>   summary(pZ) # only ~14 PCs (out of 32)
>>>>> 
>>>>> I get for the last line, the   summary.prcomp(.) call :
>>>>> 
>>>>>> summary(pZ) # only ~14 PCs (out of 32)
>>>>> Importance of components:
>>>>>                        PC1    PC2    PC3    PC4     PC5     PC6
>>>>> PC7     PC8
>>>>> Standard deviation     3.6415 2.7178 1.8447 1.3943 1.10207 0.90922
>>>> 0.76951
>>>>> 0.67490
>>>>> Proportion of Variance 0.4352 0.2424 0.1117 0.0638 0.03986 0.02713
>>>> 0.01943
>>>>> 0.01495
>>>>> Cumulative Proportion  0.4352 0.6775 0.7892 0.8530 0.89288 0.92001
>>>> 0.93944
>>>>> 0.95439
>>>>>                         PC9    PC10    PC11    PC12    PC13   PC14
>>>>> Standard deviation     0.60833 0.51638 0.49048 0.44452 0.40326 0.3904
>>>>> Proportion of Variance 0.01214 0.00875 0.00789 0.00648 0.00534 0.0050
>>>>> Cumulative Proportion  0.96653 0.97528 0.98318 0.98966 0.99500 1.0000
>>>>>> 
>>>>> 
>>>>> which computes the *proportions* as if there were only 14 PCs in
>>>>> total (but there were 32 originally).
>>>>> 
>>>>> I would think that the summary should  or could in addition show
>>>>> the usual  "proportion of variance explained"  like result which
>>>>> does involve all 32  variances or std.dev.s ... which are
>>>>> returned from the svd() anyway, even in the case when I use my
>>>>> new 'rank.' argument which only returns a "few" PCs instead of
>>>>> all.
>>>>> 
>>>>> Would you think the current  summary() output is good enough or
>>>>> rather misleading?
>>>>> 
>>>>> I think I would want to see (possibly in addition) proportions
>>>>> with respect to the full variance and not just to the variance
>>>>> of those few components selected.
>>>>> 
>>>>> Opinions?
>>>>> 
>>>>> Martin Maechler
>>>>> ETH Zurich
>>>>> 
>>>>> ______________________________________________
>>>>> R-devel at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>> 
>>>> 
>>>>      [[alternative HTML version deleted]]
>>>> 
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>> 
>>> 
>>> 	[[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> 
>> -- 
>> Peter Dalgaard, Professor,
>> Center for Statistics, Copenhagen Business School
>> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
>> Phone: (+45)38153501
>> Office: A 4.23
>> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From jari.oksanen at oulu.fi  Fri Mar 25 13:53:47 2016
From: jari.oksanen at oulu.fi (Jari Oksanen)
Date: Fri, 25 Mar 2016 12:53:47 +0000
Subject: [Rd] summary( prcomp(*, tol = .) ) -- and 'rank.'
In-Reply-To: <E4E00FB3-91D1-4D11-BD89-91791C3391D6@gmail.com>
References: <6F13CD7F-B11B-4D8B-A0AE-47A438A3A196@noaa.gov>
	<22257.31275.659023.572089@stat.math.ethz.ch>
	<22260.8007.313385.414830@stat.math.ethz.ch>
	<CAC2h7uspi2uzATUEPUVPJ7OOJWdAf276rVUf_0DqLfBkRGZ9Jg@mail.gmail.com>
	<CAAVP=anLKjKX9-tS6v3geo9SSOqxz2tEv11BSbk9er9znmSzFw@mail.gmail.com>
	<2F82767A-47E8-4181-BE1F-179D23F37931@gmail.com>
	<E8DA8672-27BF-4497-B2C2-F92197FEA017@oulu.fi>
	<E4E00FB3-91D1-4D11-BD89-91791C3391D6@gmail.com>
Message-ID: <77E48F56-8AED-408C-B27E-D34F47111083@oulu.fi>


> On 25 Mar 2016, at 11:45 am, peter dalgaard <pdalgd at gmail.com> wrote:
> 
>> 
>> On 25 Mar 2016, at 10:08 , Jari Oksanen <jari.oksanen at oulu.fi> wrote:
>> 
>>> 
>>> On 25 Mar 2016, at 10:41 am, peter dalgaard <pdalgd at gmail.com> wrote:
>>> 
>>> As I see it, the display showing the first p << n PCs adding up to 100% of the variance is plainly wrong. 
>>> 
>>> I suspect it comes about via a mental short-circuit: If we try to control p using a tolerance, then that amounts to saying that the remaining PCs are effectively zero-variance, but that is (usually) not the intention at all. 
>>> 
>>> The common case is that the remainder terms have a roughly _constant_, small-ish variance and are interpreted as noise. Of course the magnitude of the noise is important information.  
>>> 
>> But then you should use Factor Analysis which has that concept of ?noise? (unlike PCA).
> 
> Actually, FA has a slightly different concept of noise. PCA can be interpreted as a purely technical operation, but also as an FA variant with same variance for all components.
> 
> Specifically, FA is 
> 
> Sigma = LL' + Psi
> 
> with Psi a diagonal matrix. If Psi = sigma^2 I , then L can be determined (up to rotation) as the first p components of PCA. (This is used in ML algorithms for FA since it allows you to concentrate the likelihood to be a function of Psi.)
> 
If I remember correctly, we took a correlation matrix and replaced the diagonal elements with variable ?communalities? < 1 estimated by some trick, and then chunked that matrix into PCA and called the result FA. A more advanced way was to do this iteratively: take some first axes of PCA/FA, calculate diagonal elements from them & re-feed them into PCA. It was done like that because algorithms & computers were not strong enough for real FA. Now they are, and I think it would be better to treat PCA like PCA, at least in the default output of standard stats::summary function. So summary should show proportion of total variance (for people who think this is a cool thing to know) instead of showing a proportion of an unspecified part of the variance.

Cheers, Jari Oksanen (who now switches to listening to today?s Passion instead of continuing with PCA)


> Methods like PC regression are not being very specific about the model, but the underlying line of thought is that PCs with small variances are "uninformative", so that you can make do with only the first handful regressors. I tend to interpret "uninformative" as "noise-like" in these contexts.
> 
> -pd
> 
>> 
>> Cheers, Jari Oksanen
>> 
>>>> On 25 Mar 2016, at 00:02 , Steve Bronder <sbronder at stevebronder.com> wrote:
>>>> 
>>>> I agree with Kasper, this is a 'big' issue. Does your method of taking only
>>>> n PCs reduce the load on memory?
>>>> 
>>>> The new addition to the summary looks like a good idea, but Proportion of
>>>> Variance as you describe it may be confusing to new users. Am I correct in
>>>> saying Proportion of variance describes the amount of variance with respect
>>>> to the number of components the user chooses to show? So if I only choose
>>>> one I will explain 100% of the variance? I think showing 'Total Proportion
>>>> of Variance' is important if that is the case.
>>>> 
>>>> 
>>>> Regards,
>>>> 
>>>> Steve Bronder
>>>> Website: stevebronder.com
>>>> Phone: 412-719-1282
>>>> Email: sbronder at stevebronder.com
>>>> 
>>>> 
>>>> On Thu, Mar 24, 2016 at 2:58 PM, Kasper Daniel Hansen <
>>>> kasperdanielhansen at gmail.com> wrote:
>>>> 
>>>>> Martin, I fully agree.  This becomes an issue when you have big matrices.
>>>>> 
>>>>> (Note that there are awesome methods for actually only computing a small
>>>>> number of PCs (unlike your code which uses svn which gets all of them);
>>>>> these are available in various CRAN packages).
>>>>> 
>>>>> Best,
>>>>> Kasper
>>>>> 
>>>>> On Thu, Mar 24, 2016 at 1:09 PM, Martin Maechler <
>>>>> maechler at stat.math.ethz.ch
>>>>>> wrote:
>>>>> 
>>>>>> Following from the R-help thread of March 22 on "Memory usage in prcomp",
>>>>>> 
>>>>>> I've started looking into adding an optional   'rank.'  argument
>>>>>> to prcomp  allowing to more efficiently get only a few PCs
>>>>>> instead of the full p PCs, say when p = 1000 and you know you
>>>>>> only want 5 PCs.
>>>>>> 
>>>>>> (https://stat.ethz.ch/pipermail/r-help/2016-March/437228.html
>>>>>> 
>>>>>> As it was mentioned, we already have an optional 'tol' argument
>>>>>> which allows *not* to choose all PCs.
>>>>>> 
>>>>>> When I do that,
>>>>>> say
>>>>>> 
>>>>>>  C <- chol(S <- toeplitz(.9 ^ (0:31))) # Cov.matrix and its root
>>>>>>  all.equal(S, crossprod(C))
>>>>>>  set.seed(17)
>>>>>>  X <- matrix(rnorm(32000), 1000, 32)
>>>>>>  Z <- X %*% C  ## ==>  cov(Z) ~=  C'C = S
>>>>>>  all.equal(cov(Z), S, tol = 0.08)
>>>>>>  pZ <- prcomp(Z, tol = 0.1)
>>>>>>  summary(pZ) # only ~14 PCs (out of 32)
>>>>>> 
>>>>>> I get for the last line, the   summary.prcomp(.) call :
>>>>>> 
>>>>>>> summary(pZ) # only ~14 PCs (out of 32)
>>>>>> Importance of components:
>>>>>>                       PC1    PC2    PC3    PC4     PC5     PC6
>>>>>> PC7     PC8
>>>>>> Standard deviation     3.6415 2.7178 1.8447 1.3943 1.10207 0.90922
>>>>> 0.76951
>>>>>> 0.67490
>>>>>> Proportion of Variance 0.4352 0.2424 0.1117 0.0638 0.03986 0.02713
>>>>> 0.01943
>>>>>> 0.01495
>>>>>> Cumulative Proportion  0.4352 0.6775 0.7892 0.8530 0.89288 0.92001
>>>>> 0.93944
>>>>>> 0.95439
>>>>>>                        PC9    PC10    PC11    PC12    PC13   PC14
>>>>>> Standard deviation     0.60833 0.51638 0.49048 0.44452 0.40326 0.3904
>>>>>> Proportion of Variance 0.01214 0.00875 0.00789 0.00648 0.00534 0.0050
>>>>>> Cumulative Proportion  0.96653 0.97528 0.98318 0.98966 0.99500 1.0000
>>>>>>> 
>>>>>> 
>>>>>> which computes the *proportions* as if there were only 14 PCs in
>>>>>> total (but there were 32 originally).
>>>>>> 
>>>>>> I would think that the summary should  or could in addition show
>>>>>> the usual  "proportion of variance explained"  like result which
>>>>>> does involve all 32  variances or std.dev.s ... which are
>>>>>> returned from the svd() anyway, even in the case when I use my
>>>>>> new 'rank.' argument which only returns a "few" PCs instead of
>>>>>> all.
>>>>>> 
>>>>>> Would you think the current  summary() output is good enough or
>>>>>> rather misleading?
>>>>>> 
>>>>>> I think I would want to see (possibly in addition) proportions
>>>>>> with respect to the full variance and not just to the variance
>>>>>> of those few components selected.
>>>>>> 
>>>>>> Opinions?
>>>>>> 
>>>>>> Martin Maechler
>>>>>> ETH Zurich
>>>>>> 
>>>>>> ______________________________________________
>>>>>> R-devel at r-project.org mailing list
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>>> 
>>>>> 
>>>>>     [[alternative HTML version deleted]]
>>>>> 
>>>>> ______________________________________________
>>>>> R-devel at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>> 
>>>> 
>>>> 	[[alternative HTML version deleted]]
>>>> 
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>> 
>>> -- 
>>> Peter Dalgaard, Professor,
>>> Center for Statistics, Copenhagen Business School
>>> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
>>> Phone: (+45)38153501
>>> Office: A 4.23
>>> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>>> 
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> -- 
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Office: A 4.23
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From therneau at mayo.edu  Fri Mar 25 14:20:34 2016
From: therneau at mayo.edu (Therneau, Terry M., Ph.D.)
Date: Fri, 25 Mar 2016 08:20:34 -0500
Subject: [Rd] library.dynam.unload
Message-ID: <519743$2n80ni@ironport10.mayo.edu>

The survival package has a firstlib.R file that I had forgotton and just reviewed.  After 
deleting several bits which had a use 10 years ago during my Splus to R transition, the 
only thing remaining is

.onUnload <- function(libpath)
     library.dynam.unload("survival", libpath)

Does this bit of code still serve a purpose?  Can I toss it?

Terry T.


From bbolker at gmail.com  Sun Mar 20 23:24:54 2016
From: bbolker at gmail.com (Ben Bolker)
Date: Sun, 20 Mar 2016 18:24:54 -0400
Subject: [Rd] trivial typo in ?colorRampPalette
Message-ID: <56EF2336.1050504@gmail.com>


The help page for colorRampPalette reads in part

    alpha: logical: should alpha channel (opacity) values should be
           returned?

which should probably be

     alpha: logical: should alpha channel (opacity) values be returned?

This is in (2016-02-09 r70138) -- sorry if I missed an update.

   cheers
     Ben Bolker


From murdoch.duncan at gmail.com  Fri Mar 25 20:00:00 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 25 Mar 2016 15:00:00 -0400
Subject: [Rd] trivial typo in ?colorRampPalette
In-Reply-To: <56EF2336.1050504@gmail.com>
References: <56EF2336.1050504@gmail.com>
Message-ID: <56F58AB0.4030309@gmail.com>

On 20/03/2016 6:24 PM, Ben Bolker wrote:
>
> The help page for colorRampPalette reads in part
>
>      alpha: logical: should alpha channel (opacity) values should be
>             returned?
>
> which should probably be
>
>       alpha: logical: should alpha channel (opacity) values be returned?
>
> This is in (2016-02-09 r70138) -- sorry if I missed an update.
>

Thanks, will fix.

Duncan Murdoch


From nilsson.henric at gmail.com  Sat Mar 26 14:46:32 2016
From: nilsson.henric at gmail.com (Henric Winell)
Date: Sat, 26 Mar 2016 14:46:32 +0100
Subject: [Rd] library.dynam.unload
In-Reply-To: <519743$2n80ni@ironport10.mayo.edu>
References: <519743$2n80ni@ironport10.mayo.edu>
Message-ID: <56F692B8.3050703@gmail.com>

Den 2016-03-25 kl. 14:20, skrev Therneau, Terry M., Ph.D.:

> The survival package has a firstlib.R file that I had forgotton and just
> reviewed.  After deleting several bits which had a use 10 years ago
> during my Splus to R transition, the only thing remaining is
>
> .onUnload <- function(libpath)
>      library.dynam.unload("survival", libpath)
>
> Does this bit of code still serve a purpose?  Can I toss it?

This is still relevant.  For example, WRE Section 1.5.3. says that

"Compiled code should be loaded in .onLoad (or via a useDynLb directive: 
see below) and unloaded in .onUnload."


Henric



>
> Terry T.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From mick.jordan at oracle.com  Sun Mar 27 22:05:08 2016
From: mick.jordan at oracle.com (Mick Jordan)
Date: Sun, 27 Mar 2016 13:05:08 -0700
Subject: [Rd] sys.function(0)
Message-ID: <56F83CF4.3050900@oracle.com>

As I understand 
https://stat.ethz.ch/R-manual/R-devel/library/base/html/sys.parent.html
sys.function(n) returns the function associated with stack frame n. 
Since frame 0 is defined as .GlobalEnv which is not associated with a 
function, I would expect this to always return NULL. However, it does not:

 > sys.function()
NULL
 > f <- function(x) sys.function(x)
 > f(0)
function(x) sys.function(x)
 > f(1)
function(x) sys.function(x)
 > f(2)
Error in sys.function(x) : not that many frames on the stack

Why the different behavior when sys.function(0) is called inside another 
function?

Mick Jordan


	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Sun Mar 27 23:46:32 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Sun, 27 Mar 2016 23:46:32 +0200
Subject: [Rd] sys.function(0)
In-Reply-To: <56F83CF4.3050900@oracle.com>
References: <56F83CF4.3050900@oracle.com>
Message-ID: <74C577BC-7127-4D7A-A839-0ADFBB569A30@gmail.com>


> On 27 Mar 2016, at 22:05 , Mick Jordan <mick.jordan at oracle.com> wrote:
> 
> As I understand 
> https://stat.ethz.ch/R-manual/R-devel/library/base/html/sys.parent.html
> sys.function(n) returns the function associated with stack frame n. 
> Since frame 0 is defined as .GlobalEnv which is not associated with a 
> function, I would expect this to always return NULL. However, it does not:
> 
>> sys.function()
> NULL
>> f <- function(x) sys.function(x)
>> f(0)
> function(x) sys.function(x)
>> f(1)
> function(x) sys.function(x)
>> f(2)
> Error in sys.function(x) : not that many frames on the stack
> 
> Why the different behavior when sys.function(0) is called inside another 
> function?

This is a documentation bug. The case "which = 0" differs between sys.frame() and sys.call()/sys.function(). For the latter, it means the current call/function, whereas sys.frame(0) is always the global envir. It is pretty clear from the underlying C code that the three functions treat their argument differently:

R_sysframe has

    if (n == 0)
        return(R_GlobalEnv);

    if (n > 0)
        n = framedepth(cptr) - n;
    else
        n = -n;

whereas the other two (R_syscall and R_sysfunction) omit the special treatment for n==0. Without this, n==0, comes out unchanged from the if-construct, indicating that one should go 0 frames up the stack (same as n==framedepth(cptr)).

Obviously, it won't work to document the "which" argument identically for all three functions...  

-pd


> 
> Mick Jordan
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From mick.jordan at oracle.com  Mon Mar 28 00:08:44 2016
From: mick.jordan at oracle.com (Mick Jordan)
Date: Sun, 27 Mar 2016 15:08:44 -0700
Subject: [Rd] sys.function(0)
In-Reply-To: <74C577BC-7127-4D7A-A839-0ADFBB569A30@gmail.com>
References: <56F83CF4.3050900@oracle.com>
	<74C577BC-7127-4D7A-A839-0ADFBB569A30@gmail.com>
Message-ID: <56F859EC.20602@oracle.com>

On 3/27/16 2:46 PM, peter dalgaard wrote:
>> On 27 Mar 2016, at 22:05 , Mick Jordan <mick.jordan at oracle.com> wrote:
>>
>> As I understand
>> https://stat.ethz.ch/R-manual/R-devel/library/base/html/sys.parent.html
>> sys.function(n) returns the function associated with stack frame n.
>> Since frame 0 is defined as .GlobalEnv which is not associated with a
>> function, I would expect this to always return NULL. However, it does not:
>>
>>> sys.function()
>> NULL
>>> f <- function(x) sys.function(x)
>>> f(0)
>> function(x) sys.function(x)
>>> f(1)
>> function(x) sys.function(x)
>>> f(2)
>> Error in sys.function(x) : not that many frames on the stack
>>
>> Why the different behavior when sys.function(0) is called inside another
>> function?
> This is a documentation bug. The case "which = 0" differs between sys.frame() and sys.call()/sys.function(). For the latter, it means the current call/function, whereas sys.frame(0) is always the global envir. It is pretty clear from the underlying C code that the three functions treat their argument differently:
>
> R_sysframe has
>
>      if (n == 0)
>          return(R_GlobalEnv);
>
>      if (n > 0)
>          n = framedepth(cptr) - n;
>      else
>          n = -n;
>
> whereas the other two (R_syscall and R_sysfunction) omit the special treatment for n==0. Without this, n==0, comes out unchanged from the if-construct, indicating that one should go 0 frames up the stack (same as n==framedepth(cptr)).
>
> Obviously, it won't work to document the "which" argument identically for all three functions...
>
>
Thanks. I didn't look at the C code this time trusting the documentation ;-)

A related question is why are sys.parent/parent.frame so permissive in 
their error checking? E.g:

 > sys.parent(-1)
[1] 0
 > sys.parent(-2)
[1] 0
 > sys.parent(1)
[1] 0
 > sys.parent(2)
[1] 0
 > parent.frame(4)
<environment: R_GlobalEnv>
 >


From maechler at stat.math.ethz.ch  Mon Mar 28 10:06:12 2016
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 28 Mar 2016 10:06:12 +0200
Subject: [Rd] summary( prcomp(*, tol = .) ) -- and 'rank.'
In-Reply-To: <2F82767A-47E8-4181-BE1F-179D23F37931@gmail.com>
References: <6F13CD7F-B11B-4D8B-A0AE-47A438A3A196@noaa.gov>
	<22257.31275.659023.572089@stat.math.ethz.ch>
	<22260.8007.313385.414830@stat.math.ethz.ch>
	<CAC2h7uspi2uzATUEPUVPJ7OOJWdAf276rVUf_0DqLfBkRGZ9Jg@mail.gmail.com>
	<CAAVP=anLKjKX9-tS6v3geo9SSOqxz2tEv11BSbk9er9znmSzFw@mail.gmail.com>
	<2F82767A-47E8-4181-BE1F-179D23F37931@gmail.com>
Message-ID: <22264.58868.732325.100385@stat.math.ethz.ch>

>>>>> peter dalgaard <pdalgd at gmail.com>
>>>>>     on Fri, 25 Mar 2016 09:41:00 +0100 writes:

    > As I see it, the display showing the first p << n PCs
    > adding up to 100% of the variance is plainly wrong.  I
    > suspect it comes about via a mental short-circuit: If we
    > try to control p using a tolerance, then that amounts to
    > saying that the remaining PCs are effectively
    > zero-variance, but that is (usually) not the intention at
    > all.

    > The common case is that the remainder terms have a roughly
    > _constant_, small-ish variance and are interpreted as
    > noise. Of course the magnitude of the noise is important
    > information.

Thank you, Peter, Kasper, Steve.

@Kasper, I've known about *approximate* first few PC methods.
(Are there also exact ones which are more efficient than those
 based on LAPACK'S DGESDD ?)
... and so indeed, prcomp() will not be the method of choice for
really large problems.  Still, of course, we should try to "do our best".

Given your sentiments, notably Peter's, I now envisage to
do the non-backcompatible change to *summary.prcomp()* and
compute "importances" based on all proportions up to 'p' (= 100%).
What I think would be nice is for the print.summary.prcomp()
method to only show the first 'k' (my notation), i.e., those
which were chosen by 'tol' and/or 'rank.'.

Martin

    >> On 25 Mar 2016, at 00:02 , Steve Bronder
    >> <sbronder at stevebronder.com> wrote:
    >> 
    >> I agree with Kasper, this is a 'big' issue. Does your
    >> method of taking only n PCs reduce the load on memory?
    >> 
    >> The new addition to the summary looks like a good idea,
    >> but Proportion of Variance as you describe it may be
    >> confusing to new users. Am I correct in saying Proportion
    >> of variance describes the amount of variance with respect
    >> to the number of components the user chooses to show? So
    >> if I only choose one I will explain 100% of the variance?
    >> I think showing 'Total Proportion of Variance' is
    >> important if that is the case.
    >> 
    >> 
    >> Regards,
    >> 
    >> Steve Bronder Website: stevebronder.com Phone:
    >> 412-719-1282 Email: sbronder at stevebronder.com
    >> 
    >> 
    >> On Thu, Mar 24, 2016 at 2:58 PM, Kasper Daniel Hansen <
    >> kasperdanielhansen at gmail.com> wrote:
    >> 
    >>> Martin, I fully agree.  This becomes an issue when you
    >>> have big matrices.
    >>> 
    >>> (Note that there are awesome methods for actually only
    >>> computing a small number of PCs (unlike your code which
    >>> uses svn which gets all of them); these are available in
    >>> various CRAN packages).
    >>> 
    >>> Best, Kasper
    >>> 
    >>> On Thu, Mar 24, 2016 at 1:09 PM, Martin Maechler <
    >>> maechler at stat.math.ethz.ch
    >>>> wrote:
    >>> 
    >>>> Following from the R-help thread of March 22 on "Memory
    >>>> usage in prcomp",
    >>>> 
    >>>> I've started looking into adding an optional 'rank.'
    >>>> argument to prcomp allowing to more efficiently get
    >>>> only a few PCs instead of the full p PCs, say when p =
    >>>> 1000 and you know you only want 5 PCs.
    >>>> 
    >>>> (https://stat.ethz.ch/pipermail/r-help/2016-March/437228.html
    >>>> 
    >>>> As it was mentioned, we already have an optional 'tol'
    >>>> argument which allows *not* to choose all PCs.
    >>>> 
    >>>> When I do that, say
    >>>> 
    >>>> C <- chol(S <- toeplitz(.9 ^ (0:31))) # Cov.matrix and
    >>>> its root all.equal(S, crossprod(C)) set.seed(17) X <-
    >>>> matrix(rnorm(32000), 1000, 32) Z <- X %*% C ## ==>
    >>>> cov(Z) ~= C'C = S all.equal(cov(Z), S, tol = 0.08) pZ
    >>>> <- prcomp(Z, tol = 0.1) summary(pZ) # only ~14 PCs (out
    >>>> of 32)
    >>>> 
    >>>> I get for the last line, the summary.prcomp(.) call :
    >>>> 
    >>>>> summary(pZ) # only ~14 PCs (out of 32)
    >>>> Importance of components: PC1 PC2 PC3 PC4 PC5 PC6 PC7
    >>>> PC8 Standard deviation 3.6415 2.7178 1.8447 1.3943
    >>>> 1.10207 0.90922
    >>> 0.76951
    >>>> 0.67490 Proportion of Variance 0.4352 0.2424 0.1117
    >>>> 0.0638 0.03986 0.02713
    >>> 0.01943
    >>>> 0.01495 Cumulative Proportion 0.4352 0.6775 0.7892
    >>>> 0.8530 0.89288 0.92001
    >>> 0.93944
    >>>> 0.95439 PC9 PC10 PC11 PC12 PC13 PC14 Standard deviation
    >>>> 0.60833 0.51638 0.49048 0.44452 0.40326 0.3904
    >>>> Proportion of Variance 0.01214 0.00875 0.00789 0.00648
    >>>> 0.00534 0.0050 Cumulative Proportion 0.96653 0.97528
    >>>> 0.98318 0.98966 0.99500 1.0000
    >>>>> 
    >>>> 
    >>>> which computes the *proportions* as if there were only
    >>>> 14 PCs in total (but there were 32 originally).
    >>>> 
    >>>> I would think that the summary should or could in
    >>>> addition show the usual "proportion of variance
    >>>> explained" like result which does involve all 32
    >>>> variances or std.dev.s ... which are returned from the
    >>>> svd() anyway, even in the case when I use my new
    >>>> 'rank.' argument which only returns a "few" PCs instead
    >>>> of all.
    >>>> 
    >>>> Would you think the current summary() output is good
    >>>> enough or rather misleading?
    >>>> 
    >>>> I think I would want to see (possibly in addition)
    >>>> proportions with respect to the full variance and not
    >>>> just to the variance of those few components selected.
    >>>> 
    >>>> Opinions?
    >>>> 
    >>>> Martin Maechler ETH Zurich
    >>>> 
    >>>> ______________________________________________
    >>>> R-devel at r-project.org mailing list
    >>>> https://stat.ethz.ch/mailman/listinfo/r-devel
    >>>> 
    >>> 
    >>> [[alternative HTML version deleted]]
    >>> 
    >>> ______________________________________________
    >>> R-devel at r-project.org mailing list
    >>> https://stat.ethz.ch/mailman/listinfo/r-devel
    >>> 
    >> 
    >> [[alternative HTML version deleted]]
    >> 
    >> ______________________________________________
    >> R-devel at r-project.org mailing list
    >> https://stat.ethz.ch/mailman/listinfo/r-devel

    > -- 
    > Peter Dalgaard, Professor, Center for Statistics,
    > Copenhagen Business School Solbjerg Plads 3, 2000
    > Frederiksberg, Denmark Phone: (+45)38153501 Office: A 4.23
    > Email: pd.mes at cbs.dk Priv: PDalgd at gmail.com


From pdalgd at gmail.com  Mon Mar 28 14:30:18 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Mon, 28 Mar 2016 14:30:18 +0200
Subject: [Rd] sys.function(0)
In-Reply-To: <56F859EC.20602@oracle.com>
References: <56F83CF4.3050900@oracle.com>
	<74C577BC-7127-4D7A-A839-0ADFBB569A30@gmail.com>
	<56F859EC.20602@oracle.com>
Message-ID: <ED002551-0D7E-4D0C-91D8-3D04F38367BC@gmail.com>

Dunno, really. Some strange things can happen with nonstandard evaluation, like having a function designed to evaluate something in the parent of its caller, but nonetheless sometimes being called from the command line. So things are sometimes defensively coded.

-pd

> On 28 Mar 2016, at 00:08 , Mick Jordan <mick.jordan at oracle.com> wrote:
> 
> A related question is why are sys.parent/parent.frame so permissive in their error checking? E.g:
> 
> > sys.parent(-1)
> [1] 0
> > sys.parent(-2)
> [1] 0
> > sys.parent(1)
> [1] 0
> > sys.parent(2)
> [1] 0
> > parent.frame(4)
> <environment: R_GlobalEnv>
> >

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From baptiste.auguie at gmail.com  Tue Mar 29 08:31:02 2016
From: baptiste.auguie at gmail.com (Baptiste Auguie)
Date: Tue, 29 Mar 2016 19:31:02 +1300
Subject: [Rd] documentation / warning when passing a vector as lower/upper
	bound in stats::integrate()
Message-ID: <CANLFJPqvvakRJDL7yL+47UD34sicsBWBBAmJi0mSMz7oqRGuTA@mail.gmail.com>

Dear R-dev list,

I wonder if stats::integrate shouldn't warn the user when a numeric vector
of length > 1 is passed as lower or upper bounds. If a vector is passed,
only the first value is used and the others are silently ignored:

integrate(sin, lower=0, upper=pi)
integrate(sin, lower=0:10, upper=pi)

?integrate doesn't appear to mention explicitly that the function is not
vectorised over those arguments.

It's probably not a common mistake, but it can have unfortunate
consequences in the iterative calculation of multiple integrals. Someone
was puzzled by this today (http://stackoverflow.com/q/36275909/471093) and
it wasn't immediately obvious what had led to incorrect results (and worse,
it could have gone unnoticed).

Best regards,

baptiste

	[[alternative HTML version deleted]]


From kirill.mueller at ivt.baug.ethz.ch  Tue Mar 29 15:44:10 2016
From: kirill.mueller at ivt.baug.ethz.ch (=?UTF-8?Q?Kirill_M=c3=bcller?=)
Date: Tue, 29 Mar 2016 15:44:10 +0200
Subject: [Rd] DESCRIPTION file: Space after colon mandatory?
Message-ID: <56FA86AA.9000308@ivt.baug.ethz.ch>

According to R-exts, DESCRIPTION is a DCF variant, and " Fields start 
with an ASCII name immediately followed by a colon: the value starts 
after the colon and a space." However, according to the linked 
https://www.debian.org/doc/debian-policy/ch-controlfields.html, 
horizontal space before and after a value are trimmed, this is also the 
behavior of read.dcf().

Is this an omission in the documentation, or is the space after the 
colon actually required? Thanks.


Best regards

Kirill


From hpages at fredhutch.org  Tue Mar 29 21:19:12 2016
From: hpages at fredhutch.org (=?UTF-8?B?SGVydsOpIFBhZ8Oocw==?=)
Date: Tue, 29 Mar 2016 12:19:12 -0700
Subject: [Rd] body(NULL) <- something; ditto formals() -- should not work
In-Reply-To: <22237.47553.217160.571753@stat.math.ethz.ch>
References: <22237.47553.217160.571753@stat.math.ethz.ch>
Message-ID: <56FAD530.50104@fredhutch.org>

Hi,

On 03/07/2016 09:26 AM, Martin Maechler wrote:
> I'm proposing to signal an error (from R >= 3.3.0) in such
> examples -- which do "work" in R 3.2.x and earlier :
>
>> f <- NULL; body(f) <- quote(sin(a+1)); f
> function ()
> sin(a + 1)
> <environment: 0x48f9798>
>

This works because formals() (the getter) works on things that are
not a function.

>> g <- NULL; formals(g) <- alist(x = pi, y=); g
> function (x = pi, y)
> NULL
> <environment: 0x4e6dfe8>
>>

And this works because body() (the getter) also works on things that
are not a function.

>
> The proposal is that the underlying C code will signal an error
> when such replacement functions would create a function out of
> "something not a function".

Why modify the C code for this?

This is how formals() and body() are defined at the moment:

 > formals
function (fun = sys.function(sys.parent()))
{
     if (is.character(fun))
         fun <- get(fun, mode = "function", envir = parent.frame())
     .Internal(formals(fun))
}
<bytecode: 0x153cde0>
<environment: namespace:base>

 > body
function (fun = sys.function(sys.parent()))
{
     if (is.character(fun))
         fun <- get(fun, mode = "function", envir = parent.frame())
     .Internal(body(fun))
}
<bytecode: 0xb452e8>
<environment: namespace:base>

Not sure why they are not simply doing fun <- match.fun(fun) but if
they were, then they would signal an error when called on something
that is not a function.

H.

>
> Martin Maechler, ETH Zurich
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fredhutch.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From maechler at stat.math.ethz.ch  Wed Mar 30 09:55:54 2016
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 30 Mar 2016 09:55:54 +0200
Subject: [Rd] body(NULL) <- something; ditto formals() -- should not work
In-Reply-To: <56FAD530.50104@fredhutch.org>
References: <22237.47553.217160.571753@stat.math.ethz.ch>
	<56FAD530.50104@fredhutch.org>
Message-ID: <22267.34442.773963.56719@stat.math.ethz.ch>

>>>>> Herv? Pag?s <hpages at fredhutch.org>
>>>>>     on Tue, 29 Mar 2016 12:19:12 -0700 writes:

    > Hi,
    > On 03/07/2016 09:26 AM, Martin Maechler wrote:
    >> I'm proposing to signal an error (from R >= 3.3.0) in such
    >> examples -- which do "work" in R 3.2.x and earlier :
    >> 
    >>> f <- NULL; body(f) <- quote(sin(a+1)); f
    >> function ()
    >> sin(a + 1)
    >> <environment: 0x48f9798>
    >> 

    > This works because formals() (the getter) works on things that are
    > not a function.

    >>> g <- NULL; formals(g) <- alist(x = pi, y=); g
    >> function (x = pi, y)
    >> NULL
    >> <environment: 0x4e6dfe8>
    >>> 

    > And this works because body() (the getter) also works on things that
    > are not a function.

of course (twice).


    >> The proposal is that the underlying C code will signal an error
    >> when such replacement functions would create a function out of
    >> "something not a function".

    > Why modify the C code for this?

My current proposal would change both the C code *and* the following.

    > This is how formals() and body() are defined at the moment:

    >> formals
    > function (fun = sys.function(sys.parent()))
    > {
    > if (is.character(fun))
    > fun <- get(fun, mode = "function", envir = parent.frame())
    > .Internal(formals(fun))
    > }
    > <bytecode: 0x153cde0>
    > <environment: namespace:base>

    >> body
    > function (fun = sys.function(sys.parent()))
    > {
    > if (is.character(fun))
    > fun <- get(fun, mode = "function", envir = parent.frame())
    > .Internal(body(fun))
    > }
    > <bytecode: 0xb452e8>
    > <environment: namespace:base>

    > Not sure why they are not simply doing fun <- match.fun(fun) but if
    > they were, then they would signal an error when called on something
    > that is not a function.

Using match.fun() will probably be "the right thing" in the
future.

However, as this has been an unchanged part of R for very many years,
my current proposal would only signal *warnings* for now.

Thank you, Herve, for the reminder about this.  Indeed, I *have*
been wanting to commit my proposal to R-devel  for a long time
and somehow have always been anxious to produce too many
negative effects with CRAN / Bioconductor packages producing
warning (or errors) after the change and me not having the time
to send e-mails to all the package maintainers.

As I won't have time for that anyway, and as "good package
maintainers" should at least browse, if not read the R-devel
mailing list (;-),
your prompting now makes me commit my proposal (to R-devel only;
*not* R 3.4.0 alpha) and leave the resulting "problems" to the
package maintainers affected. 

Martin


From hkawakat at gmail.com  Wed Mar 30 10:27:16 2016
From: hkawakat at gmail.com (Hiroyuki Kawakatsu)
Date: Wed, 30 Mar 2016 09:27:16 +0100
Subject: [Rd] reg-tests-1a fails with r70391
Message-ID: <20160330082706.GA3251@erdos>

Hi,

This may be a `transitional' bug but I am reporting a make check
fail with R-devel r70391 in reg-tests-1a.Rout. The tail of
reg-tests-1a.Rout.fail is

> ## prcomp(tol=1e-6)
> x <- matrix(runif(30),ncol=10)
> s <- prcomp(x, tol=1e-6)
> stopifnot(length(s$sdev) == ncol(s$rotation))
Error: length(s$sdev) == ncol(s$rotation) is not TRUE
Execution halted

Looking at stats:::prcomp.default(), it appears that s$v is
truncated but not s$d (unlike in the code before r70391) for the
reduced rank case.

h.

-- 
+---
| Hiroyuki Kawakatsu
| Business School, Dublin City University
| Dublin 9, Ireland. Tel +353 (0)1 700 7496


From maechler at stat.math.ethz.ch  Wed Mar 30 11:16:15 2016
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 30 Mar 2016 11:16:15 +0200
Subject: [Rd] reg-tests-1a fails with r70391
In-Reply-To: <20160330082706.GA3251@erdos>
References: <20160330082706.GA3251@erdos>
Message-ID: <22267.39263.559600.267224@stat.math.ethz.ch>

>>>>> Hiroyuki Kawakatsu <hkawakat at gmail.com>
>>>>>     on Wed, 30 Mar 2016 09:27:16 +0100 writes:

    > Hi, This may be a `transitional' bug but I am reporting a
    > make check fail with R-devel r70391 in
    > reg-tests-1a.Rout. The tail of reg-tests-1a.Rout.fail is

    >> ## prcomp(tol=1e-6) x <- matrix(runif(30),ncol=10) s <-
    >> prcomp(x, tol=1e-6) stopifnot(length(s$sdev) ==
    >> ncol(s$rotation))
    > Error: length(s$sdev) == ncol(s$rotation) is not TRUE
    > Execution halted

    > Looking at stats:::prcomp.default(), it appears that s$v
    > is truncated but not s$d (unlike in the code before
    > r70391) for the reduced rank case.

Exactly.  I had this in the list of changes to be committed in
r70391, but not on the computer I did commit.

The 'transitional' period (above) has terminated 2 minutes ago.
Thank you, Hiroyuki for the reminder.

Martin


From maechler at stat.math.ethz.ch  Wed Mar 30 11:22:13 2016
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 30 Mar 2016 11:22:13 +0200
Subject: [Rd] documentation / warning when passing a vector as
	lower/upper	bound in stats::integrate()
In-Reply-To: <CANLFJPqvvakRJDL7yL+47UD34sicsBWBBAmJi0mSMz7oqRGuTA@mail.gmail.com>
References: <CANLFJPqvvakRJDL7yL+47UD34sicsBWBBAmJi0mSMz7oqRGuTA@mail.gmail.com>
Message-ID: <22267.39621.324830.264920@stat.math.ethz.ch>

>>>>> Baptiste Auguie <baptiste.auguie at gmail.com>
>>>>>     on Tue, 29 Mar 2016 19:31:02 +1300 writes:

    > Dear R-dev list,
    > I wonder if stats::integrate shouldn't warn the user when a numeric vector
    > of length > 1 is passed as lower or upper bounds. If a vector is passed,
    > only the first value is used and the others are silently ignored:

    > integrate(sin, lower=0, upper=pi)
    > integrate(sin, lower=0:10, upper=pi)

    > ?integrate doesn't appear to mention explicitly that the function is not
    > vectorised over those arguments.

well, that's not true:  Almost the very first text on the help
is the description and that already *does* say so :

> Description:

>      Adaptive quadrature of functions of one variable over a finite or
>      infinite interval.

"a .. interval"  is singular, ...

and then there are 14 examples, all using one interval...
*AND* one of them showing that you need to use *integrands*
which are vectorized.

So to me, it seems pretty bizarre that anyone assumes lower or upper
should be allowed to be vectors after reading the help page.
R users not reading the help page of a function after having problems or being
puzzled about it should not be allowed to post anywhere publicly on the
internet ;-)

    > It's probably not a common mistake, 
I think so, too !!     

    > consequences in the iterative calculation of multiple integrals. Someone
    > was puzzled by this today (http://stackoverflow.com/q/36275909/471093) and
    > it wasn't immediately obvious what had led to incorrect results (and worse,
    > it could have gone unnoticed).

I agree here.

Note however that checking for user errors always comes with a small
performance penalty and so, programmers traditionally have liked
to deal with such problems by keeping the code optimally fast...

If I remember the many silly performance comparisons of R with X
(notably with 'X' being a compiled language) and all the bad
propaganda of "R is slow", when much of that relative slowness
is because S and R have always aimed to be safe rather than
fast, I am sometimes reluctant to add yet another test for user
error..  but of course still agree we should do it.
Just think about the issue, next time someone tells you how much
faster his C++ / ... code is compared to plain R..

Martin


    > Best regards,
    > baptiste


