From h@nk|n@rob|n @end|ng |rom gm@||@com  Fri Mar  1 07:10:36 2019
From: h@nk|n@rob|n @end|ng |rom gm@||@com (robin hankin)
Date: Fri, 1 Mar 2019 19:10:36 +1300
Subject: [Rd] pcre problems
In-Reply-To: <2a6d5ab9-ccfd-c522-5718-baf270e098b5@gmail.com>
References: <CAHHjBM7CJa6un7Up6nM4NHZjn17MdXFjRPxkYvkv+V2F6d4hDA@mail.gmail.com>
 <2a6d5ab9-ccfd-c522-5718-baf270e098b5@gmail.com>
Message-ID: <CAHHjBM5hQ0bmFNaO3QOOO7napLDM5n+5PvJxgG275K07JwL9tg@mail.gmail.com>

thanks for this guys.

I only compiled pcre myself as a last resort,  because of the
./configure failure.  But AFAICS  apt-get reports correct
installation:

OK~/Downloads/R-devel sudo apt-get install r-base-dev
Reading package lists... Done
Building dependency tree
Reading state information... Done
r-base-dev is already the newest version (3.5.2-1cosmic).
0 upgraded, 0 newly installed, 0 to remove and 1 not upgraded.
OK~/Downloads/R-devel

config.log gives me:

configure:42208: $? = 0
configure:42208: result: yes
configure:42208: checking for pcre.h
configure:42208: result: yes
configure:42208: checking pcre/pcre.h usability
configure:42208: gcc -c  -g -O2 -I/usr/local/include  conftest.c >&5
conftest.c:289:10: fatal error: pcre/pcre.h: No such file or directory
 #include <pcre/pcre.h>
          ^~~~~~~~~~~~~
compilation terminated.
configure:42208: $? = 1
configure: failed program was:
| /* confdefs.h */
| #define PACKAGE_NAME "R"
| #define PACKAGE_TARNAME "R"
| #define PACKAGE_VERSION "3

and

HAVE_UNISTD_H
| # include <unistd.h>
| #endif
| #include <pcre/pcre.h>
configure:42208: result: no
configure:42208: checking pcre/pcre.h presence
configure:42208: gcc -E -I/usr/local/include  conftest.c
conftest.c:256:10: fatal error: pcre/pcre.h: No such file or directory
 #include <pcre/pcre.h>
          ^~~~~~~~~~~~~
compilation terminated.
configure:42208: $? = 1
configure: failed program was:
| /* confdefs.h */
| #define PACKAGE_NAME "R"
| #define PACKAGE_TARNAME "R"
| #define PACKAGE_VERSION "3.6.0"
| #define PACKAGE_STRING "R 3.6.0"
| #define PACKAGE_BUGREPOR



hankin.robin at gmail.com




On Mon, Feb 25, 2019 at 9:39 PM Tomas Kalibera <tomas.kalibera at gmail.com> wrote:
>
> On 2/25/19 6:25 AM, robin hankin wrote:
> > Hi there, ubuntu 18.04.2, trying to compile R-devel  3.6.0,  svn 76155.
> >
> > I am having difficulty compiling R. I think I have pcre installed correctly:
>
> You can use
>
> apt-get build-dep r-base
>
> to install binary Ubuntu packages needed to build R from source,
> including PCRE, so there should be no need to compile PCRE from source.
> If you need for some special reason to compile PCRE from source, please
> see R Admin Manual, section A.1 on how to configure PCRE. The manual
> also says how to set compilation flags for R to look for headers in
> other directories. Sometimes it helps to search the config.log when
> configure fails. If still in trouble, please report how you built PCRE
> and how you told R where to find it, and the relevant part of
> config.log, to maximize chances people could offer useful advice.
>
> Best,
> Tomas
>
> >
> > OK~/Downloads/R-devel pcretest -C
> > PCRE version 8.41 2017-07-05
> > Compiled with
> >    8-bit support
> >    UTF-8 support
> >    No Unicode properties support
> >    No just-in-time compiler support
> >    Newline sequence is LF
> >    \R matches all Unicode newlines
> >    Internal link size = 2
> >    POSIX malloc threshold = 10
> >    Parentheses nest limit = 250
> >    Default match limit = 10000000
> >    Default recursion depth limit = 10000000
> >    Match recursion uses stack
> > OK~/Downloads/R-devel
> >
> >
> > But ./configure gives me this:
> >
> > [snip]
> > checking for pcre.h... yes
> > checking pcre/pcre.h usability... no
> > checking pcre/pcre.h presence... no
> > checking for pcre/pcre.h... no
> > checking if PCRE version >= 8.20, < 10.0 and has UTF-8 support... no
> > checking whether PCRE support suffices... configure: error: pcre >=
> > 8.20 library and headers are required
> > OK~/Downloads/R-devel
> >
> > can anyone advise?
> >
> >
> >
> >
> >
> >
> > hankin.robin at gmail.com
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From tom@@@k@||ber@ @end|ng |rom gm@||@com  Fri Mar  1 08:47:36 2019
From: tom@@@k@||ber@ @end|ng |rom gm@||@com (Tomas Kalibera)
Date: Fri, 1 Mar 2019 08:47:36 +0100
Subject: [Rd] pcre problems
In-Reply-To: <CAHHjBM5hQ0bmFNaO3QOOO7napLDM5n+5PvJxgG275K07JwL9tg@mail.gmail.com>
References: <CAHHjBM7CJa6un7Up6nM4NHZjn17MdXFjRPxkYvkv+V2F6d4hDA@mail.gmail.com>
 <2a6d5ab9-ccfd-c522-5718-baf270e098b5@gmail.com>
 <CAHHjBM5hQ0bmFNaO3QOOO7napLDM5n+5PvJxgG275K07JwL9tg@mail.gmail.com>
Message-ID: <db7ce85b-50a9-1745-10f9-b88b2252a150@gmail.com>

On 3/1/19 7:10 AM, robin hankin wrote:
> thanks for this guys.
>
> I only compiled pcre myself as a last resort,  because of the
> ./configure failure.  But AFAICS  apt-get reports correct
> installation:
>
> OK~/Downloads/R-devel sudo apt-get install r-base-dev
> Reading package lists... Done
> Building dependency tree
> Reading state information... Done
> r-base-dev is already the newest version (3.5.2-1cosmic).
> 0 upgraded, 0 newly installed, 0 to remove and 1 not upgraded.
> OK~/Downloads/R-devel

I would just run this

apt-get build-dep r-base

that will install all packages needed to _build_ r-base, so including PCRE.

Best
Tomas

>
> config.log gives me:
>
> configure:42208: $? = 0
> configure:42208: result: yes
> configure:42208: checking for pcre.h
> configure:42208: result: yes
> configure:42208: checking pcre/pcre.h usability
> configure:42208: gcc -c  -g -O2 -I/usr/local/include  conftest.c >&5
> conftest.c:289:10: fatal error: pcre/pcre.h: No such file or directory
>   #include <pcre/pcre.h>
>            ^~~~~~~~~~~~~
> compilation terminated.
> configure:42208: $? = 1
> configure: failed program was:
> | /* confdefs.h */
> | #define PACKAGE_NAME "R"
> | #define PACKAGE_TARNAME "R"
> | #define PACKAGE_VERSION "3
>
> and
>
> HAVE_UNISTD_H
> | # include <unistd.h>
> | #endif
> | #include <pcre/pcre.h>
> configure:42208: result: no
> configure:42208: checking pcre/pcre.h presence
> configure:42208: gcc -E -I/usr/local/include  conftest.c
> conftest.c:256:10: fatal error: pcre/pcre.h: No such file or directory
>   #include <pcre/pcre.h>
>            ^~~~~~~~~~~~~
> compilation terminated.
> configure:42208: $? = 1
> configure: failed program was:
> | /* confdefs.h */
> | #define PACKAGE_NAME "R"
> | #define PACKAGE_TARNAME "R"
> | #define PACKAGE_VERSION "3.6.0"
> | #define PACKAGE_STRING "R 3.6.0"
> | #define PACKAGE_BUGREPOR
>
>
>
> hankin.robin at gmail.com
>
>
>
>
> On Mon, Feb 25, 2019 at 9:39 PM Tomas Kalibera <tomas.kalibera at gmail.com> wrote:
>> On 2/25/19 6:25 AM, robin hankin wrote:
>>> Hi there, ubuntu 18.04.2, trying to compile R-devel  3.6.0,  svn 76155.
>>>
>>> I am having difficulty compiling R. I think I have pcre installed correctly:
>> You can use
>>
>> apt-get build-dep r-base
>>
>> to install binary Ubuntu packages needed to build R from source,
>> including PCRE, so there should be no need to compile PCRE from source.
>> If you need for some special reason to compile PCRE from source, please
>> see R Admin Manual, section A.1 on how to configure PCRE. The manual
>> also says how to set compilation flags for R to look for headers in
>> other directories. Sometimes it helps to search the config.log when
>> configure fails. If still in trouble, please report how you built PCRE
>> and how you told R where to find it, and the relevant part of
>> config.log, to maximize chances people could offer useful advice.
>>
>> Best,
>> Tomas
>>
>>> OK~/Downloads/R-devel pcretest -C
>>> PCRE version 8.41 2017-07-05
>>> Compiled with
>>>     8-bit support
>>>     UTF-8 support
>>>     No Unicode properties support
>>>     No just-in-time compiler support
>>>     Newline sequence is LF
>>>     \R matches all Unicode newlines
>>>     Internal link size = 2
>>>     POSIX malloc threshold = 10
>>>     Parentheses nest limit = 250
>>>     Default match limit = 10000000
>>>     Default recursion depth limit = 10000000
>>>     Match recursion uses stack
>>> OK~/Downloads/R-devel
>>>
>>>
>>> But ./configure gives me this:
>>>
>>> [snip]
>>> checking for pcre.h... yes
>>> checking pcre/pcre.h usability... no
>>> checking pcre/pcre.h presence... no
>>> checking for pcre/pcre.h... no
>>> checking if PCRE version >= 8.20, < 10.0 and has UTF-8 support... no
>>> checking whether PCRE support suffices... configure: error: pcre >=
>>> 8.20 library and headers are required
>>> OK~/Downloads/R-devel
>>>
>>> can anyone advise?
>>>
>>>
>>>
>>>
>>>
>>>
>>> hankin.robin at gmail.com
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>


From h@nk|n@rob|n @end|ng |rom gm@||@com  Fri Mar  1 09:03:28 2019
From: h@nk|n@rob|n @end|ng |rom gm@||@com (robin hankin)
Date: Fri, 1 Mar 2019 21:03:28 +1300
Subject: [Rd] pcre problems
In-Reply-To: <db7ce85b-50a9-1745-10f9-b88b2252a150@gmail.com>
References: <CAHHjBM7CJa6un7Up6nM4NHZjn17MdXFjRPxkYvkv+V2F6d4hDA@mail.gmail.com>
 <2a6d5ab9-ccfd-c522-5718-baf270e098b5@gmail.com>
 <CAHHjBM5hQ0bmFNaO3QOOO7napLDM5n+5PvJxgG275K07JwL9tg@mail.gmail.com>
 <db7ce85b-50a9-1745-10f9-b88b2252a150@gmail.com>
Message-ID: <CAHHjBM4OoWRukaS_u=F6ecVmWi3Kqz=8QRA4nNGCtzSOJHOxOg@mail.gmail.com>

OK thanks Tomas, but I get


OK~ sudo apt-get build-dep r-base
Reading package lists... Done
E: Unable to find a source package for r-base
OK~


hankin.robin at gmail.com


On Fri, Mar 1, 2019 at 8:47 PM Tomas Kalibera <tomas.kalibera at gmail.com> wrote:
>
> On 3/1/19 7:10 AM, robin hankin wrote:
> > thanks for this guys.
> >
> > I only compiled pcre myself as a last resort,  because of the
> > ./configure failure.  But AFAICS  apt-get reports correct
> > installation:
> >
> > OK~/Downloads/R-devel sudo apt-get install r-base-dev
> > Reading package lists... Done
> > Building dependency tree
> > Reading state information... Done
> > r-base-dev is already the newest version (3.5.2-1cosmic).
> > 0 upgraded, 0 newly installed, 0 to remove and 1 not upgraded.
> > OK~/Downloads/R-devel
>
> I would just run this
>
> apt-get build-dep r-base
>
> that will install all packages needed to _build_ r-base, so including PCRE.
>
> Best
> Tomas
>
> >
> > config.log gives me:
> >
> > configure:42208: $? = 0
> > configure:42208: result: yes
> > configure:42208: checking for pcre.h
> > configure:42208: result: yes
> > configure:42208: checking pcre/pcre.h usability
> > configure:42208: gcc -c  -g -O2 -I/usr/local/include  conftest.c >&5
> > conftest.c:289:10: fatal error: pcre/pcre.h: No such file or directory
> >   #include <pcre/pcre.h>
> >            ^~~~~~~~~~~~~
> > compilation terminated.
> > configure:42208: $? = 1
> > configure: failed program was:
> > | /* confdefs.h */
> > | #define PACKAGE_NAME "R"
> > | #define PACKAGE_TARNAME "R"
> > | #define PACKAGE_VERSION "3
> >
> > and
> >
> > HAVE_UNISTD_H
> > | # include <unistd.h>
> > | #endif
> > | #include <pcre/pcre.h>
> > configure:42208: result: no
> > configure:42208: checking pcre/pcre.h presence
> > configure:42208: gcc -E -I/usr/local/include  conftest.c
> > conftest.c:256:10: fatal error: pcre/pcre.h: No such file or directory
> >   #include <pcre/pcre.h>
> >            ^~~~~~~~~~~~~
> > compilation terminated.
> > configure:42208: $? = 1
> > configure: failed program was:
> > | /* confdefs.h */
> > | #define PACKAGE_NAME "R"
> > | #define PACKAGE_TARNAME "R"
> > | #define PACKAGE_VERSION "3.6.0"
> > | #define PACKAGE_STRING "R 3.6.0"
> > | #define PACKAGE_BUGREPOR
> >
> >
> >
> > hankin.robin at gmail.com
> >
> >
> >
> >
> > On Mon, Feb 25, 2019 at 9:39 PM Tomas Kalibera <tomas.kalibera at gmail.com> wrote:
> >> On 2/25/19 6:25 AM, robin hankin wrote:
> >>> Hi there, ubuntu 18.04.2, trying to compile R-devel  3.6.0,  svn 76155.
> >>>
> >>> I am having difficulty compiling R. I think I have pcre installed correctly:
> >> You can use
> >>
> >> apt-get build-dep r-base
> >>
> >> to install binary Ubuntu packages needed to build R from source,
> >> including PCRE, so there should be no need to compile PCRE from source.
> >> If you need for some special reason to compile PCRE from source, please
> >> see R Admin Manual, section A.1 on how to configure PCRE. The manual
> >> also says how to set compilation flags for R to look for headers in
> >> other directories. Sometimes it helps to search the config.log when
> >> configure fails. If still in trouble, please report how you built PCRE
> >> and how you told R where to find it, and the relevant part of
> >> config.log, to maximize chances people could offer useful advice.
> >>
> >> Best,
> >> Tomas
> >>
> >>> OK~/Downloads/R-devel pcretest -C
> >>> PCRE version 8.41 2017-07-05
> >>> Compiled with
> >>>     8-bit support
> >>>     UTF-8 support
> >>>     No Unicode properties support
> >>>     No just-in-time compiler support
> >>>     Newline sequence is LF
> >>>     \R matches all Unicode newlines
> >>>     Internal link size = 2
> >>>     POSIX malloc threshold = 10
> >>>     Parentheses nest limit = 250
> >>>     Default match limit = 10000000
> >>>     Default recursion depth limit = 10000000
> >>>     Match recursion uses stack
> >>> OK~/Downloads/R-devel
> >>>
> >>>
> >>> But ./configure gives me this:
> >>>
> >>> [snip]
> >>> checking for pcre.h... yes
> >>> checking pcre/pcre.h usability... no
> >>> checking pcre/pcre.h presence... no
> >>> checking for pcre/pcre.h... no
> >>> checking if PCRE version >= 8.20, < 10.0 and has UTF-8 support... no
> >>> checking whether PCRE support suffices... configure: error: pcre >=
> >>> 8.20 library and headers are required
> >>> OK~/Downloads/R-devel
> >>>
> >>> can anyone advise?
> >>>
> >>>
> >>>
> >>>
> >>>
> >>>
> >>> hankin.robin at gmail.com
> >>>
> >>> ______________________________________________
> >>> R-devel at r-project.org mailing list
> >>> https://stat.ethz.ch/mailman/listinfo/r-devel
> >>
>


From tom@@@k@||ber@ @end|ng |rom gm@||@com  Fri Mar  1 09:19:13 2019
From: tom@@@k@||ber@ @end|ng |rom gm@||@com (Tomas Kalibera)
Date: Fri, 1 Mar 2019 09:19:13 +0100
Subject: [Rd] pcre problems
In-Reply-To: <CAHHjBM4OoWRukaS_u=F6ecVmWi3Kqz=8QRA4nNGCtzSOJHOxOg@mail.gmail.com>
References: <CAHHjBM7CJa6un7Up6nM4NHZjn17MdXFjRPxkYvkv+V2F6d4hDA@mail.gmail.com>
 <2a6d5ab9-ccfd-c522-5718-baf270e098b5@gmail.com>
 <CAHHjBM5hQ0bmFNaO3QOOO7napLDM5n+5PvJxgG275K07JwL9tg@mail.gmail.com>
 <db7ce85b-50a9-1745-10f9-b88b2252a150@gmail.com>
 <CAHHjBM4OoWRukaS_u=F6ecVmWi3Kqz=8QRA4nNGCtzSOJHOxOg@mail.gmail.com>
Message-ID: <cdbe3889-53df-be5b-3e33-86487070623e@gmail.com>

On 3/1/19 9:03 AM, robin hankin wrote:
> OK thanks Tomas, but I get
>
>
> OK~ sudo apt-get build-dep r-base
> Reading package lists... Done
> E: Unable to find a source package for r-base
> OK~

It seems you need to enable source code? repositories on your system 
(and then run apt-get update).
You can enable them in /etc/apt/sources.list, uncomment all lines 
starting with deb-src.

Best
Tomas

>
>
> hankin.robin at gmail.com
>
>
> On Fri, Mar 1, 2019 at 8:47 PM Tomas Kalibera <tomas.kalibera at gmail.com> wrote:
>> On 3/1/19 7:10 AM, robin hankin wrote:
>>> thanks for this guys.
>>>
>>> I only compiled pcre myself as a last resort,  because of the
>>> ./configure failure.  But AFAICS  apt-get reports correct
>>> installation:
>>>
>>> OK~/Downloads/R-devel sudo apt-get install r-base-dev
>>> Reading package lists... Done
>>> Building dependency tree
>>> Reading state information... Done
>>> r-base-dev is already the newest version (3.5.2-1cosmic).
>>> 0 upgraded, 0 newly installed, 0 to remove and 1 not upgraded.
>>> OK~/Downloads/R-devel
>> I would just run this
>>
>> apt-get build-dep r-base
>>
>> that will install all packages needed to _build_ r-base, so including PCRE.
>>
>> Best
>> Tomas
>>
>>> config.log gives me:
>>>
>>> configure:42208: $? = 0
>>> configure:42208: result: yes
>>> configure:42208: checking for pcre.h
>>> configure:42208: result: yes
>>> configure:42208: checking pcre/pcre.h usability
>>> configure:42208: gcc -c  -g -O2 -I/usr/local/include  conftest.c >&5
>>> conftest.c:289:10: fatal error: pcre/pcre.h: No such file or directory
>>>    #include <pcre/pcre.h>
>>>             ^~~~~~~~~~~~~
>>> compilation terminated.
>>> configure:42208: $? = 1
>>> configure: failed program was:
>>> | /* confdefs.h */
>>> | #define PACKAGE_NAME "R"
>>> | #define PACKAGE_TARNAME "R"
>>> | #define PACKAGE_VERSION "3
>>>
>>> and
>>>
>>> HAVE_UNISTD_H
>>> | # include <unistd.h>
>>> | #endif
>>> | #include <pcre/pcre.h>
>>> configure:42208: result: no
>>> configure:42208: checking pcre/pcre.h presence
>>> configure:42208: gcc -E -I/usr/local/include  conftest.c
>>> conftest.c:256:10: fatal error: pcre/pcre.h: No such file or directory
>>>    #include <pcre/pcre.h>
>>>             ^~~~~~~~~~~~~
>>> compilation terminated.
>>> configure:42208: $? = 1
>>> configure: failed program was:
>>> | /* confdefs.h */
>>> | #define PACKAGE_NAME "R"
>>> | #define PACKAGE_TARNAME "R"
>>> | #define PACKAGE_VERSION "3.6.0"
>>> | #define PACKAGE_STRING "R 3.6.0"
>>> | #define PACKAGE_BUGREPOR
>>>
>>>
>>>
>>> hankin.robin at gmail.com
>>>
>>>
>>>
>>>
>>> On Mon, Feb 25, 2019 at 9:39 PM Tomas Kalibera <tomas.kalibera at gmail.com> wrote:
>>>> On 2/25/19 6:25 AM, robin hankin wrote:
>>>>> Hi there, ubuntu 18.04.2, trying to compile R-devel  3.6.0,  svn 76155.
>>>>>
>>>>> I am having difficulty compiling R. I think I have pcre installed correctly:
>>>> You can use
>>>>
>>>> apt-get build-dep r-base
>>>>
>>>> to install binary Ubuntu packages needed to build R from source,
>>>> including PCRE, so there should be no need to compile PCRE from source.
>>>> If you need for some special reason to compile PCRE from source, please
>>>> see R Admin Manual, section A.1 on how to configure PCRE. The manual
>>>> also says how to set compilation flags for R to look for headers in
>>>> other directories. Sometimes it helps to search the config.log when
>>>> configure fails. If still in trouble, please report how you built PCRE
>>>> and how you told R where to find it, and the relevant part of
>>>> config.log, to maximize chances people could offer useful advice.
>>>>
>>>> Best,
>>>> Tomas
>>>>
>>>>> OK~/Downloads/R-devel pcretest -C
>>>>> PCRE version 8.41 2017-07-05
>>>>> Compiled with
>>>>>      8-bit support
>>>>>      UTF-8 support
>>>>>      No Unicode properties support
>>>>>      No just-in-time compiler support
>>>>>      Newline sequence is LF
>>>>>      \R matches all Unicode newlines
>>>>>      Internal link size = 2
>>>>>      POSIX malloc threshold = 10
>>>>>      Parentheses nest limit = 250
>>>>>      Default match limit = 10000000
>>>>>      Default recursion depth limit = 10000000
>>>>>      Match recursion uses stack
>>>>> OK~/Downloads/R-devel
>>>>>
>>>>>
>>>>> But ./configure gives me this:
>>>>>
>>>>> [snip]
>>>>> checking for pcre.h... yes
>>>>> checking pcre/pcre.h usability... no
>>>>> checking pcre/pcre.h presence... no
>>>>> checking for pcre/pcre.h... no
>>>>> checking if PCRE version >= 8.20, < 10.0 and has UTF-8 support... no
>>>>> checking whether PCRE support suffices... configure: error: pcre >=
>>>>> 8.20 library and headers are required
>>>>> OK~/Downloads/R-devel
>>>>>
>>>>> can anyone advise?
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>> hankin.robin at gmail.com
>>>>>
>>>>> ______________________________________________
>>>>> R-devel at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel


From h@nk|n@rob|n @end|ng |rom gm@||@com  Fri Mar  1 09:43:07 2019
From: h@nk|n@rob|n @end|ng |rom gm@||@com (robin hankin)
Date: Fri, 1 Mar 2019 21:43:07 +1300
Subject: [Rd] pcre problems
In-Reply-To: <cdbe3889-53df-be5b-3e33-86487070623e@gmail.com>
References: <CAHHjBM7CJa6un7Up6nM4NHZjn17MdXFjRPxkYvkv+V2F6d4hDA@mail.gmail.com>
 <2a6d5ab9-ccfd-c522-5718-baf270e098b5@gmail.com>
 <CAHHjBM5hQ0bmFNaO3QOOO7napLDM5n+5PvJxgG275K07JwL9tg@mail.gmail.com>
 <db7ce85b-50a9-1745-10f9-b88b2252a150@gmail.com>
 <CAHHjBM4OoWRukaS_u=F6ecVmWi3Kqz=8QRA4nNGCtzSOJHOxOg@mail.gmail.com>
 <cdbe3889-53df-be5b-3e33-86487070623e@gmail.com>
Message-ID: <CAHHjBM71_c8Gi+OcJVnhxO8JLNceGY5fgNoWVT9dtxEm_gCDVQ@mail.gmail.com>

Still something wrong.  I've uncommented the deb-src lines in
sources.list as you suggested (and I thought it couldn't hurt to try
--allow-unauthenticated as well) and:

root at limpet:/etc/apt# apt-get update --allow-unauthenticated
Hit:1 http://nz.archive.ubuntu.com/ubuntu bionic InRelease
Hit:2 http://repo.steampowered.com/steam precise InRelease
Hit:3 http://nz.archive.ubuntu.com/ubuntu bionic-updates InRelease
Hit:4 http://nz.archive.ubuntu.com/ubuntu bionic-backports InRelease
Ign:5 http://cran.rstudio.com/bin/linux/ubuntu bionic/ InRelease
Err:6 http://cran.rstudio.com/bin/linux/ubuntu bionic/ Release
  404  Not Found [IP: 13.35.146.80 80]
Hit:7 https://cloud.r-project.org/bin/linux/ubuntu cosmic-cran35/
InRelease
Hit:8 http://ppa.launchpad.net/edd/misc/ubuntu bionic InRelease
Hit:9 http://security.ubuntu.com/ubuntu bionic-security InRelease
Hit:10 http://ppa.launchpad.net/marutter/c2d4u/ubuntu bionic InRelease
Ign:11 http://ppa.launchpad.net/marutter/rdev/ubuntu bionic InRelease
Hit:12 http://ppa.launchpad.net/marutter/rrutter3.5/ubuntu bionic InRelease
Hit:13 http://ppa.launchpad.net/teejee2008/ppa/ubuntu bionic InRelease
Err:14 http://ppa.launchpad.net/marutter/rdev/ubuntu bionic Release
  404  Not Found [IP: 91.189.95.83 80]
Ign:15 http://dl.google.com/linux/chrome/deb stable InRelease
Hit:16 http://dl.google.com/linux/chrome/deb stable Release
Reading package lists... Done
E: The repository 'http://cran.rstudio.com/bin/linux/ubuntu bionic/
Release' does not have a Release file.
N: Updating from such a repository can't be done securely, and is
therefore disabled by default.
N: See apt-secure(8) manpage for repository creation and user
configuration details.
E: The repository 'http://ppa.launchpad.net/marutter/rdev/ubuntu
bionic Release' does not have a Release file.
N: Updating from such a repository can't be done securely, and is
therefore disabled by default.
N: See apt-secure(8) manpage for repository creation and user
configuration details.
root at limpet:/etc/apt#



hankin.robin at gmail.com



hankin.robin at gmail.com




On Fri, Mar 1, 2019 at 9:19 PM Tomas Kalibera <tomas.kalibera at gmail.com> wrote:
>
> On 3/1/19 9:03 AM, robin hankin wrote:
> > OK thanks Tomas, but I get
> >
> >
> > OK~ sudo apt-get build-dep r-base
> > Reading package lists... Done
> > E: Unable to find a source package for r-base
> > OK~
>
> It seems you need to enable source code  repositories on your system
> (and then run apt-get update).
> You can enable them in /etc/apt/sources.list, uncomment all lines
> starting with deb-src.
>
> Best
> Tomas
>
> >
> >
> > hankin.robin at gmail.com
> >
> >
> > On Fri, Mar 1, 2019 at 8:47 PM Tomas Kalibera <tomas.kalibera at gmail.com> wrote:
> >> On 3/1/19 7:10 AM, robin hankin wrote:
> >>> thanks for this guys.
> >>>
> >>> I only compiled pcre myself as a last resort,  because of the
> >>> ./configure failure.  But AFAICS  apt-get reports correct
> >>> installation:
> >>>
> >>> OK~/Downloads/R-devel sudo apt-get install r-base-dev
> >>> Reading package lists... Done
> >>> Building dependency tree
> >>> Reading state information... Done
> >>> r-base-dev is already the newest version (3.5.2-1cosmic).
> >>> 0 upgraded, 0 newly installed, 0 to remove and 1 not upgraded.
> >>> OK~/Downloads/R-devel
> >> I would just run this
> >>
> >> apt-get build-dep r-base
> >>
> >> that will install all packages needed to _build_ r-base, so including PCRE.
> >>
> >> Best
> >> Tomas
> >>
> >>> config.log gives me:
> >>>
> >>> configure:42208: $? = 0
> >>> configure:42208: result: yes
> >>> configure:42208: checking for pcre.h
> >>> configure:42208: result: yes
> >>> configure:42208: checking pcre/pcre.h usability
> >>> configure:42208: gcc -c  -g -O2 -I/usr/local/include  conftest.c >&5
> >>> conftest.c:289:10: fatal error: pcre/pcre.h: No such file or directory
> >>>    #include <pcre/pcre.h>
> >>>             ^~~~~~~~~~~~~
> >>> compilation terminated.
> >>> configure:42208: $? = 1
> >>> configure: failed program was:
> >>> | /* confdefs.h */
> >>> | #define PACKAGE_NAME "R"
> >>> | #define PACKAGE_TARNAME "R"
> >>> | #define PACKAGE_VERSION "3
> >>>
> >>> and
> >>>
> >>> HAVE_UNISTD_H
> >>> | # include <unistd.h>
> >>> | #endif
> >>> | #include <pcre/pcre.h>
> >>> configure:42208: result: no
> >>> configure:42208: checking pcre/pcre.h presence
> >>> configure:42208: gcc -E -I/usr/local/include  conftest.c
> >>> conftest.c:256:10: fatal error: pcre/pcre.h: No such file or directory
> >>>    #include <pcre/pcre.h>
> >>>             ^~~~~~~~~~~~~
> >>> compilation terminated.
> >>> configure:42208: $? = 1
> >>> configure: failed program was:
> >>> | /* confdefs.h */
> >>> | #define PACKAGE_NAME "R"
> >>> | #define PACKAGE_TARNAME "R"
> >>> | #define PACKAGE_VERSION "3.6.0"
> >>> | #define PACKAGE_STRING "R 3.6.0"
> >>> | #define PACKAGE_BUGREPOR
> >>>
> >>>
> >>>
> >>> hankin.robin at gmail.com
> >>>
> >>>
> >>>
> >>>
> >>> On Mon, Feb 25, 2019 at 9:39 PM Tomas Kalibera <tomas.kalibera at gmail.com> wrote:
> >>>> On 2/25/19 6:25 AM, robin hankin wrote:
> >>>>> Hi there, ubuntu 18.04.2, trying to compile R-devel  3.6.0,  svn 76155.
> >>>>>
> >>>>> I am having difficulty compiling R. I think I have pcre installed correctly:
> >>>> You can use
> >>>>
> >>>> apt-get build-dep r-base
> >>>>
> >>>> to install binary Ubuntu packages needed to build R from source,
> >>>> including PCRE, so there should be no need to compile PCRE from source.
> >>>> If you need for some special reason to compile PCRE from source, please
> >>>> see R Admin Manual, section A.1 on how to configure PCRE. The manual
> >>>> also says how to set compilation flags for R to look for headers in
> >>>> other directories. Sometimes it helps to search the config.log when
> >>>> configure fails. If still in trouble, please report how you built PCRE
> >>>> and how you told R where to find it, and the relevant part of
> >>>> config.log, to maximize chances people could offer useful advice.
> >>>>
> >>>> Best,
> >>>> Tomas
> >>>>
> >>>>> OK~/Downloads/R-devel pcretest -C
> >>>>> PCRE version 8.41 2017-07-05
> >>>>> Compiled with
> >>>>>      8-bit support
> >>>>>      UTF-8 support
> >>>>>      No Unicode properties support
> >>>>>      No just-in-time compiler support
> >>>>>      Newline sequence is LF
> >>>>>      \R matches all Unicode newlines
> >>>>>      Internal link size = 2
> >>>>>      POSIX malloc threshold = 10
> >>>>>      Parentheses nest limit = 250
> >>>>>      Default match limit = 10000000
> >>>>>      Default recursion depth limit = 10000000
> >>>>>      Match recursion uses stack
> >>>>> OK~/Downloads/R-devel
> >>>>>
> >>>>>
> >>>>> But ./configure gives me this:
> >>>>>
> >>>>> [snip]
> >>>>> checking for pcre.h... yes
> >>>>> checking pcre/pcre.h usability... no
> >>>>> checking pcre/pcre.h presence... no
> >>>>> checking for pcre/pcre.h... no
> >>>>> checking if PCRE version >= 8.20, < 10.0 and has UTF-8 support... no
> >>>>> checking whether PCRE support suffices... configure: error: pcre >=
> >>>>> 8.20 library and headers are required
> >>>>> OK~/Downloads/R-devel
> >>>>>
> >>>>> can anyone advise?
> >>>>>
> >>>>>
> >>>>>
> >>>>>
> >>>>>
> >>>>>
> >>>>> hankin.robin at gmail.com
> >>>>>
> >>>>> ______________________________________________
> >>>>> R-devel at r-project.org mailing list
> >>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From tom@@@k@||ber@ @end|ng |rom gm@||@com  Fri Mar  1 09:58:16 2019
From: tom@@@k@||ber@ @end|ng |rom gm@||@com (Tomas Kalibera)
Date: Fri, 1 Mar 2019 09:58:16 +0100
Subject: [Rd] pcre problems
In-Reply-To: <CAHHjBM71_c8Gi+OcJVnhxO8JLNceGY5fgNoWVT9dtxEm_gCDVQ@mail.gmail.com>
References: <CAHHjBM7CJa6un7Up6nM4NHZjn17MdXFjRPxkYvkv+V2F6d4hDA@mail.gmail.com>
 <2a6d5ab9-ccfd-c522-5718-baf270e098b5@gmail.com>
 <CAHHjBM5hQ0bmFNaO3QOOO7napLDM5n+5PvJxgG275K07JwL9tg@mail.gmail.com>
 <db7ce85b-50a9-1745-10f9-b88b2252a150@gmail.com>
 <CAHHjBM4OoWRukaS_u=F6ecVmWi3Kqz=8QRA4nNGCtzSOJHOxOg@mail.gmail.com>
 <cdbe3889-53df-be5b-3e33-86487070623e@gmail.com>
 <CAHHjBM71_c8Gi+OcJVnhxO8JLNceGY5fgNoWVT9dtxEm_gCDVQ@mail.gmail.com>
Message-ID: <528fb3dd-7e91-b1a0-e372-ffd86cf9129d@gmail.com>

On 3/1/19 9:43 AM, robin hankin wrote:
> Still something wrong.  I've uncommented the deb-src lines in
> sources.list as you suggested (and I thought it couldn't hurt to try
> --allow-unauthenticated as well) and:

So you can try commenting again the sources that are failing, R should 
be in universe (and --allow-unauthenticated should not be necessary for 
that).

If you still have problems please take it offline, these are already 
Ubuntu/Debain topics, not R (you can also try ubuntu-users). Some 
documentation is here: 
https://help.ubuntu.com/community/Repositories/CommandLine

Best
Tomas

>
> root at limpet:/etc/apt# apt-get update --allow-unauthenticated
> Hit:1 http://nz.archive.ubuntu.com/ubuntu bionic InRelease
> Hit:2 http://repo.steampowered.com/steam precise InRelease
> Hit:3 http://nz.archive.ubuntu.com/ubuntu bionic-updates InRelease
> Hit:4 http://nz.archive.ubuntu.com/ubuntu bionic-backports InRelease
> Ign:5 http://cran.rstudio.com/bin/linux/ubuntu bionic/ InRelease
> Err:6 http://cran.rstudio.com/bin/linux/ubuntu bionic/ Release
>    404  Not Found [IP: 13.35.146.80 80]
> Hit:7 https://cloud.r-project.org/bin/linux/ubuntu cosmic-cran35/
> InRelease
> Hit:8 http://ppa.launchpad.net/edd/misc/ubuntu bionic InRelease
> Hit:9 http://security.ubuntu.com/ubuntu bionic-security InRelease
> Hit:10 http://ppa.launchpad.net/marutter/c2d4u/ubuntu bionic InRelease
> Ign:11 http://ppa.launchpad.net/marutter/rdev/ubuntu bionic InRelease
> Hit:12 http://ppa.launchpad.net/marutter/rrutter3.5/ubuntu bionic InRelease
> Hit:13 http://ppa.launchpad.net/teejee2008/ppa/ubuntu bionic InRelease
> Err:14 http://ppa.launchpad.net/marutter/rdev/ubuntu bionic Release
>    404  Not Found [IP: 91.189.95.83 80]
> Ign:15 http://dl.google.com/linux/chrome/deb stable InRelease
> Hit:16 http://dl.google.com/linux/chrome/deb stable Release
> Reading package lists... Done
> E: The repository 'http://cran.rstudio.com/bin/linux/ubuntu bionic/
> Release' does not have a Release file.
> N: Updating from such a repository can't be done securely, and is
> therefore disabled by default.
> N: See apt-secure(8) manpage for repository creation and user
> configuration details.
> E: The repository 'http://ppa.launchpad.net/marutter/rdev/ubuntu
> bionic Release' does not have a Release file.
> N: Updating from such a repository can't be done securely, and is
> therefore disabled by default.
> N: See apt-secure(8) manpage for repository creation and user
> configuration details.
> root at limpet:/etc/apt#
>
>
>
> hankin.robin at gmail.com
>
>
>
> hankin.robin at gmail.com
>
>
>
>
> On Fri, Mar 1, 2019 at 9:19 PM Tomas Kalibera <tomas.kalibera at gmail.com> wrote:
>> On 3/1/19 9:03 AM, robin hankin wrote:
>>> OK thanks Tomas, but I get
>>>
>>>
>>> OK~ sudo apt-get build-dep r-base
>>> Reading package lists... Done
>>> E: Unable to find a source package for r-base
>>> OK~
>> It seems you need to enable source code  repositories on your system
>> (and then run apt-get update).
>> You can enable them in /etc/apt/sources.list, uncomment all lines
>> starting with deb-src.
>>
>> Best
>> Tomas
>>
>>>
>>> hankin.robin at gmail.com
>>>
>>>
>>> On Fri, Mar 1, 2019 at 8:47 PM Tomas Kalibera <tomas.kalibera at gmail.com> wrote:
>>>> On 3/1/19 7:10 AM, robin hankin wrote:
>>>>> thanks for this guys.
>>>>>
>>>>> I only compiled pcre myself as a last resort,  because of the
>>>>> ./configure failure.  But AFAICS  apt-get reports correct
>>>>> installation:
>>>>>
>>>>> OK~/Downloads/R-devel sudo apt-get install r-base-dev
>>>>> Reading package lists... Done
>>>>> Building dependency tree
>>>>> Reading state information... Done
>>>>> r-base-dev is already the newest version (3.5.2-1cosmic).
>>>>> 0 upgraded, 0 newly installed, 0 to remove and 1 not upgraded.
>>>>> OK~/Downloads/R-devel
>>>> I would just run this
>>>>
>>>> apt-get build-dep r-base
>>>>
>>>> that will install all packages needed to _build_ r-base, so including PCRE.
>>>>
>>>> Best
>>>> Tomas
>>>>
>>>>> config.log gives me:
>>>>>
>>>>> configure:42208: $? = 0
>>>>> configure:42208: result: yes
>>>>> configure:42208: checking for pcre.h
>>>>> configure:42208: result: yes
>>>>> configure:42208: checking pcre/pcre.h usability
>>>>> configure:42208: gcc -c  -g -O2 -I/usr/local/include  conftest.c >&5
>>>>> conftest.c:289:10: fatal error: pcre/pcre.h: No such file or directory
>>>>>     #include <pcre/pcre.h>
>>>>>              ^~~~~~~~~~~~~
>>>>> compilation terminated.
>>>>> configure:42208: $? = 1
>>>>> configure: failed program was:
>>>>> | /* confdefs.h */
>>>>> | #define PACKAGE_NAME "R"
>>>>> | #define PACKAGE_TARNAME "R"
>>>>> | #define PACKAGE_VERSION "3
>>>>>
>>>>> and
>>>>>
>>>>> HAVE_UNISTD_H
>>>>> | # include <unistd.h>
>>>>> | #endif
>>>>> | #include <pcre/pcre.h>
>>>>> configure:42208: result: no
>>>>> configure:42208: checking pcre/pcre.h presence
>>>>> configure:42208: gcc -E -I/usr/local/include  conftest.c
>>>>> conftest.c:256:10: fatal error: pcre/pcre.h: No such file or directory
>>>>>     #include <pcre/pcre.h>
>>>>>              ^~~~~~~~~~~~~
>>>>> compilation terminated.
>>>>> configure:42208: $? = 1
>>>>> configure: failed program was:
>>>>> | /* confdefs.h */
>>>>> | #define PACKAGE_NAME "R"
>>>>> | #define PACKAGE_TARNAME "R"
>>>>> | #define PACKAGE_VERSION "3.6.0"
>>>>> | #define PACKAGE_STRING "R 3.6.0"
>>>>> | #define PACKAGE_BUGREPOR
>>>>>
>>>>>
>>>>>
>>>>> hankin.robin at gmail.com
>>>>>
>>>>>
>>>>>
>>>>>
>>>>> On Mon, Feb 25, 2019 at 9:39 PM Tomas Kalibera <tomas.kalibera at gmail.com> wrote:
>>>>>> On 2/25/19 6:25 AM, robin hankin wrote:
>>>>>>> Hi there, ubuntu 18.04.2, trying to compile R-devel  3.6.0,  svn 76155.
>>>>>>>
>>>>>>> I am having difficulty compiling R. I think I have pcre installed correctly:
>>>>>> You can use
>>>>>>
>>>>>> apt-get build-dep r-base
>>>>>>
>>>>>> to install binary Ubuntu packages needed to build R from source,
>>>>>> including PCRE, so there should be no need to compile PCRE from source.
>>>>>> If you need for some special reason to compile PCRE from source, please
>>>>>> see R Admin Manual, section A.1 on how to configure PCRE. The manual
>>>>>> also says how to set compilation flags for R to look for headers in
>>>>>> other directories. Sometimes it helps to search the config.log when
>>>>>> configure fails. If still in trouble, please report how you built PCRE
>>>>>> and how you told R where to find it, and the relevant part of
>>>>>> config.log, to maximize chances people could offer useful advice.
>>>>>>
>>>>>> Best,
>>>>>> Tomas
>>>>>>
>>>>>>> OK~/Downloads/R-devel pcretest -C
>>>>>>> PCRE version 8.41 2017-07-05
>>>>>>> Compiled with
>>>>>>>       8-bit support
>>>>>>>       UTF-8 support
>>>>>>>       No Unicode properties support
>>>>>>>       No just-in-time compiler support
>>>>>>>       Newline sequence is LF
>>>>>>>       \R matches all Unicode newlines
>>>>>>>       Internal link size = 2
>>>>>>>       POSIX malloc threshold = 10
>>>>>>>       Parentheses nest limit = 250
>>>>>>>       Default match limit = 10000000
>>>>>>>       Default recursion depth limit = 10000000
>>>>>>>       Match recursion uses stack
>>>>>>> OK~/Downloads/R-devel
>>>>>>>
>>>>>>>
>>>>>>> But ./configure gives me this:
>>>>>>>
>>>>>>> [snip]
>>>>>>> checking for pcre.h... yes
>>>>>>> checking pcre/pcre.h usability... no
>>>>>>> checking pcre/pcre.h presence... no
>>>>>>> checking for pcre/pcre.h... no
>>>>>>> checking if PCRE version >= 8.20, < 10.0 and has UTF-8 support... no
>>>>>>> checking whether PCRE support suffices... configure: error: pcre >=
>>>>>>> 8.20 library and headers are required
>>>>>>> OK~/Downloads/R-devel
>>>>>>>
>>>>>>> can anyone advise?
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>> hankin.robin at gmail.com
>>>>>>>
>>>>>>> ______________________________________________
>>>>>>> R-devel at r-project.org mailing list
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Fri Mar  1 12:40:45 2019
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Fri, 1 Mar 2019 12:40:45 +0100
Subject: [Rd] stopifnot
In-Reply-To: <164850320.6530706.1551307564070@mail.yahoo.com>
References: <164850320.6530706.1551307564070.ref@mail.yahoo.com>
 <164850320.6530706.1551307564070@mail.yahoo.com>
Message-ID: <23673.6717.153375.978125@stat.math.ethz.ch>

>>>>> Suharto Anggono Suharto Anggono 
>>>>>     on Wed, 27 Feb 2019 22:46:04 +0000 writes:

    > My points:
    > - The 'withCallingHandlers' construct that is used in current 'stopifnot' code has no effect. Without it, the warning message is the same. The overridden warning is not raised. The original warning stays.

    > - Overriding call in error and warning to 'cl.i' doesn't always give better outcome. The original call may be "narrower" than 'cl.i'.

I see.  Thank you for stating the summary.

    > I have found these examples.
    > identity(is.na(log()))
    > identity(is.na(log("a")))

    > Error message from the first contains full call. Error message from the second doesn't.

    > So, how about being "natural", not using 'withCallingHandlers' and 'tryCatch' in 'stopifnot'?

If we can achieve good (or better) messages as before, I
entirely agree.

Originally, one "design principle" for stopifnot() had been to
create a relatively simple "self explaining" (for code readers)
function with that functionality.

The all.equal() special treatment has really added an extra
level of usefulness, and the somewhat recent ensuring of careful
sequential eval() is also important.

Somewhere there I found I'd need the sophisticated error
catching [tryCatch() ..], but if turns that it is unneeded, I
think we'd all be more than happy.


    > Another thing: currently,
    > stopifnot(exprs=TRUE)
    > fails.

good catch - indeed!

I've started to carefully test and try the interesting nice
patch you've provided below.

Thank you very much for your careful and constructive
suggestions!  I'll get back after some testing {and fulfilling
quite a few other jobs/duties I've got these days ...}

Martin

    > A patch:
    > --- stop.R	2019-02-27 16:15:45.324167577 +0000
    > +++ stop_new.R	2019-02-27 16:22:15.936203541 +0000
    > @@ -1,7 +1,7 @@
    > #  File src/library/base/R/stop.R
    > #  Part of the R package, https://www.R-project.org
    > #
    > -#  Copyright (C) 1995-2018 The R Core Team
    > +#  Copyright (C) 1995-2019 The R Core Team
    > #
    > #  This program is free software; you can redistribute it and/or modify
    > #  it under the terms of the GNU General Public License as published by
    > @@ -33,25 +33,27 @@
 
    > stopifnot <- function(..., exprs, local = TRUE)
    > {
    > +    n <- ...length()
    > missE <- missing(exprs)
    > -    cl <-
    > if(missE) {  ## use '...' instead of exprs
    > -	    match.call(expand.dots=FALSE)$...
    > } else {
    > -	    if(...length())
    > +	    if(n)
    > stop("Must use 'exprs' or unnamed expressions, but not both")
    > envir <- if (isTRUE(local)) parent.frame()
    > else if(isFALSE(local)) .GlobalEnv
    > else if (is.environment(local)) local
    > else stop("'local' must be TRUE, FALSE or an environment")
    > exprs <- substitute(exprs) # protect from evaluation
    > -	    E1 <- exprs[[1]]
    > +	    E1 <- if(is.call(exprs)) exprs[[1]]
    > +	    cl <-
    > if(identical(quote(`{`), E1)) # { ... }
    > -		do.call(expression, as.list(exprs[-1]))
    > +		exprs[-1]
    > else if(identical(quote(expression), E1))
    > eval(exprs, envir=envir)
    > else
    > as.expression(exprs) # or fail ..
    > +	    if(!is.null(names(cl))) names(cl) <- NULL
    > +	    return(eval(as.call(c(sys.call()[[1]], as.list(cl))), envir=envir))
    > }
    > Dparse <- function(call, cutoff = 60L) {
    > ch <- deparse(call, width.cutoff = cutoff)
    > @@ -62,14 +64,10 @@
    > abbrev <- function(ae, n = 3L)
    > paste(c(head(ae, n), if(length(ae) > n) "...."), collapse="\n  ")
    > ##
    > -    for (i in seq_along(cl)) {
    > -	cl.i <- cl[[i]]
    > -	## r <- eval(cl.i, ..)   # with correct warn/err messages:
    > -	r <- withCallingHandlers(
    > -		tryCatch(if(missE) ...elt(i) else eval(cl.i, envir=envir),
    > -			 error = function(e) { e$call <- cl.i; stop(e) }),
    > -		warning = function(w) { w$call <- cl.i; w })
    > +    for (i in seq_len(n)) {
    > +	r <- ...elt(i)
    > if (!(is.logical(r) && !anyNA(r) && all(r))) {
    > +	    cl.i <- match.call(expand.dots=FALSE)$...[[i]]
    > msg <- ## special case for decently written 'all.equal(*)':
    > if(is.call(cl.i) && identical(cl.i[[1]], quote(all.equal)) &&
    > (is.null(ni <- names(cl.i)) || length(cl.i) == 3L ||
    > @@ -84,7 +82,11 @@
    > "%s are not all TRUE"),
    > Dparse(cl.i))
 
    > -	    stop(simpleError(msg, call = sys.call(-1)))
    > +	    p <- sys.parent()
    > +	    if(p && identical(sys.function(p), stopifnot) &&
    > +	       !eval(expression(missE), p)) # originally stopifnot(exprs=*)
    > +		p <- sys.parent(2)
    > +	    stop(simpleError(msg, call = if(p) sys.call(p)))
    > }
    > }
    > invisible()

    > --------------------------------------------
    > On Wed, 27/2/19, Martin Maechler <maechler at stat.math.ethz.ch> wrote:

    > Subject: Re: [Rd] stopifnot
    > To: "Suharto Anggono Suharto Anggono" <suharto_anggono at yahoo.com>
    > Cc: r-devel at r-project.org
    > Date: Wednesday, 27 February, 2019, 5:36 PM
 
>>>>> Suharto Anggono Suharto Anggono via R-devel 
    >>>>>> ? ? on Sun, 24 Feb 2019 14:22:48 +0000 writes:

    > ? ? >> From https://github.com/HenrikBengtsson/Wishlist-for-R/issues/70 :
    > ? ? > ... and follow up note from 2018-03-15: Ouch... in R-devel, stopifnot() has become yet 4-5 times slower;

    > ? ? > ...
    > ? ? > which is due to a complete rewrite using tryCatch() and withCallingHandlers().


    > ? ? >> From https://stat.ethz.ch/pipermail/r-devel/2017-May/074256.html , it seems that 'tryCatch' was used to avoid the following example from giving error message with 'eval' call and 'withCallingHandlers' was meant to handle similar case for warning.
    > ? ? > tst <- function(y) { stopifnot(is.numeric(y)); y+ 1 }
    > ? ? > try(tst())

    > ? ? > However,
    > ? ? > withCallingHandlers(<something>,
    > ? ? > warning = function(w) { w$call <- cl.i; w })
    > ? ? > actally has no effect. In current code of function 'stopifnot', 'eval' is used only in handling stopifnot(exprs=) . The warning message from
    > ? ? > stopifnot(exprs={warning()})
    > ? ? > has 'eval' call:
    > ? ? > In eval(cl.i, envir = envir) : 

    > ? ? > This may work.
    > ? ? > withCallingHandlers(<something>,
    > ? ? > warning = function(w) {
    > ? ? > w$call <- cl.i; warning(w); invokeRestart("muffleWarning") })


    > ? ? > Current documentation says:
    > ? ? > Since R version 3.5.0, expressions are evaluated sequentially, and hence evaluation stops as soon as there is a "non-TRUE", asnindicated by the above conceptual equivalence statement. Further, when such an expression signals an error or warning, its conditionCall() no longer contains the full stopifnot call, but just the erroneous expression.

    > ? ? > I assume that "no longer contains ..." is supposed to be the effect of the use of 'withCallingHandlers' and 'tryCatch' in 'stopifnot'.

    > ? ? > Actually, "contains the full stopifnot call" is not always the case in R before version 3.5.0. Normally, the call is the "innermost context".

    > Thank you Suharto, for thinking about these issues and being
    > constructive, trying to improve the current state.

    > Unfortunately, I do not quite understand what you are trying to
    > say here.

    > The main somewhat recent changes to stopifnot() have been (in
    > inverse time ordering)

    > 1) Do what the documentation always promised, namely eval() the
    > ? expressions one by one, and stop evaluation as soon as one of
    > ? them is not all(.) TRUE.
    > ? For that reason, the previously used idiom? 'list(...)'
    > ? is a no go, as "of course", it evaluates all the expressions in '...'

    > 2) Try to ensure that warning() and stop()/error messages are
    > ? shown the same {as closely as feasible}? to how they are
    > ? shown outside of stopifnot(.)
    > ? ? ? ? ? ? ==> partly the topic of this e-mail.

    > 3) [2.5 years ago:] stopifnot() became smart about all.equal(.) expressions,
    > ? showing the all.equal() string if it was not TRUE:
    > ? In older R versions (<= 3.3.x ?), we had

    > ? ? ? > stopifnot(all.equal(pi, 3.1415))
    > ? ? Error: all.equal(pi, 3.1415) is not TRUE

    > ? where as in R (>= 3.4.0 at least):

    > ? ? ? > stopifnot(all.equal(pi, 3.1415)) 
    > ? ? ? Error: pi and 3.1415 are not equal:
    > ? ? Mean relative difference: 2.949255e-05


    > One example of what I meant with the above documentation ("no
    > longer contains")? is the following:

    > In R 3.5.x, 

    > ? > lf <- list(fm = y ~ f(x), osf = ~ sin(x))
    > ? > stopifnot(identical(deparse(lf), deparse(lf, control="all")))
    > ? Warning message:
    > ? In deparse(lf, control = "all") : deparse may be incomplete
    > ? > 

    > If I change the calling handler to use the
    > invokeRestart("muffleWarning") which I understand you are
    > proposing, then the message becomes

    > ? Warning message:
    > ? In identical(deparse(lf, control = "all"), deparse(lf)) :
    > ? ? deparse may be incomplete

    > which is less useful as I can no longer see directly which of
    > the deparse() produced the warning.

    > ? ? > Example:
    > ? ? > stopifnot((1:2) + (1:3) > 0)
    > ? ? > Warning message:
    > ? ? > In (1:2) + (1:3) :
    > ? ? >?? longer object length is not a multiple of shorter object length

    > Which is the good answer
    > (whereas also showing "> 0" in the warning is slightly off).

    > Again, if I'd use the? ..muffleWarning.. code instead, the above
    > would change to the worse

    > ? ? Warning message:
    > ? ? In (1:2) + (1:3) > 0 :
    > ? ? ? longer object length is not a multiple of shorter object length

    > which "wrongly includes the '> 0'.
    > So I guess I really don't understand what you are proposing, or
    > would like to change? ...


    > ? ? > Example that gives error:
    > ? ? > stopifnot(is.na(log("a")))
    > ? ? > R 3.5.0:
    > ? ? > R 3.3.2:

    > That's a good one: we want the error message *not to* mention
    > is.na(.) but just 'log': i.e.,

    > We'd like? [ R versions <= 3.4.4 ] :

    >> stopifnot(is.na(log("a")))
    > Error in log("a") : non-numeric argument to mathematical function

    > as opposed to [ R version >= 3.5.0 ] :

    >> stopifnot(is.na(log("a")))
    > Error in is.na(log("a")) : non-numeric argument to mathematical function

    > -----------------------------------------

    > Again, I'm sure I partly failed to understand what you said in
    > your e-mail and apologize for that.

    > Of course, I'm happy and glad to discuss improvements to
    > stopifnot() which improve speed (while retaining important
    > current functionality)? or also just improve current
    > functionality
    > -- e.g. get the "better" error message in the stopifnot(is.na(log("a")))

    > ? example.


    > High regards,
    > Martin Maechler


From r@||@@tubner @end|ng |rom d@q@n@@com  Fri Mar  1 13:52:43 2019
From: r@||@@tubner @end|ng |rom d@q@n@@com (Ralf Stubner)
Date: Fri, 1 Mar 2019 13:52:43 +0100
Subject: [Rd] Surprising results from INTEGER_GET_REGION with ALTREP object
Message-ID: <e2a61102-ac26-8b55-47da-f66eb334d899@daqana.com>

Dear Listmembers,

wanting to learn more about ALTREP I wrote the following function to
extract a subsequence from an integer vector:

#include <Rinternals.h>

SEXP integer_get_region(SEXP _x, SEXP _i, SEXP _n) {
  int i = INTEGER(_i)[0];
  int n = INTEGER(_n)[0];
  SEXP result = PROTECT(Rf_allocVector(INTSXP, n));
  INTEGER_GET_REGION(_x, i, n, INTEGER(result));
  UNPROTECT(1);
  return result;
}

For "shorter" vectors, the result is as expected:

> dyn.load("altrep_int_region.so")
> .Call("integer_get_region", 1:1e9, 0L, 10L)
 [1]  1  2  3  4  5  6  7  8  9 10

But not for "longer" vectors:

> .Call("integer_get_region", 1:1e10, 0L, 10L)
 [1]          0 1072693248          0 1073741824          0 1074266112
 [7]          0 1074790400          0 1075052544


Am I doing something wrong or is this a bug? I am using

> R.version.string
[1] "R version 3.5.2 (2018-12-20)"

Thanks
Ralf

-- 
Ralf Stubner
Senior Software Engineer / Trainer

daqana GmbH
Dortustra?e 48
14467 Potsdam

T: +49 331 23 61 93 11
F: +49 331 23 61 93 90
M: +49 162 20 91 196
Mail: ralf.stubner at daqana.com

Sitz: Potsdam
Register: AG Potsdam HRB 27966
Ust.-IdNr.: DE300072622
Gesch?ftsf?hrer: Dr.-Ing. Stefan Knirsch, Prof. Dr. Dr. Karl-Kuno Kunze


-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: OpenPGP digital signature
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20190301/c60d0a1a/attachment.sig>

From tom@@@k@||ber@ @end|ng |rom gm@||@com  Fri Mar  1 14:17:01 2019
From: tom@@@k@||ber@ @end|ng |rom gm@||@com (Tomas Kalibera)
Date: Fri, 1 Mar 2019 14:17:01 +0100
Subject: [Rd] 
 Surprising results from INTEGER_GET_REGION with ALTREP object
In-Reply-To: <e2a61102-ac26-8b55-47da-f66eb334d899@daqana.com>
References: <e2a61102-ac26-8b55-47da-f66eb334d899@daqana.com>
Message-ID: <4adce5a0-1bf2-5f6c-9190-49153ed322e5@gmail.com>

On 3/1/19 1:52 PM, Ralf Stubner wrote:
> Dear Listmembers,
>
> wanting to learn more about ALTREP I wrote the following function to
> extract a subsequence from an integer vector:
>
> #include <Rinternals.h>
>
> SEXP integer_get_region(SEXP _x, SEXP _i, SEXP _n) {
>    int i = INTEGER(_i)[0];
>    int n = INTEGER(_n)[0];
>    SEXP result = PROTECT(Rf_allocVector(INTSXP, n));
>    INTEGER_GET_REGION(_x, i, n, INTEGER(result));
>    UNPROTECT(1);
>    return result;
> }
>
> For "shorter" vectors, the result is as expected:
>
>> dyn.load("altrep_int_region.so")
>> .Call("integer_get_region", 1:1e9, 0L, 10L)
>   [1]  1  2  3  4  5  6  7  8  9 10
>
> But not for "longer" vectors:
>
>> .Call("integer_get_region", 1:1e10, 0L, 10L)
>   [1]          0 1072693248          0 1073741824          0 1074266112
>   [7]          0 1074790400          0 1075052544
>
>
> Am I doing something wrong or is this a bug? I am using

The problem is that 1:1e10 is a vector of doubles, not integers. See ?colon

"
For numeric arguments, a numeric vector.? This will be of type
?integer? if ?from? is integer-valued and the result is
representable in the R integer type, otherwise of type ?"double"?
(aka ?mode? ?"numeric"?).
"

Best
Tomas

>
>> R.version.string
> [1] "R version 3.5.2 (2018-12-20)"
>
> Thanks
> Ralf
>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel



	[[alternative HTML version deleted]]


From jwood000 @end|ng |rom gm@||@com  Fri Mar  1 18:06:47 2019
From: jwood000 @end|ng |rom gm@||@com (Joseph Wood)
Date: Fri, 1 Mar 2019 12:06:47 -0500
Subject: [Rd] issue with sample in R 3.6.0.
Message-ID: <CAKDcrSjJ6nsudEct9LW+0UC477uT2baJDCvzXm744W6Txon0bA@mail.gmail.com>

Hello,

I think there is an issue in the sampling rejection algorithm in R 3.6.0.

The do_sample2 function in src/main/unique.c still has 4.5e15 as an
upper limit, implying that numbers greater than INT_MAX are still to
be supported by sample in base R.

Please review the examples below:

set.seed(123)
max(sample(2^31, 1e5))
[1] 2147430096

set.seed(123)
max(sample(2^31 + 1, 1e5))
[1] 1

set.seed(123)
max(sample(2^32, 1e5))
[1] 1

set.seed(123)
max(sample(2^35, 1e5))
[1] 8

set.seed(123)
max(sample(2^38, 1e5))
[1] 64

set.seed(123)
max(sample(2^38, 1e5))
[1] 64

set.seed(123)
max(sample(2^42, 1e5))
[1] 1024

>From the above, we see that if N is greater than 2^31, then N is
bounded by (2^(ceiling(log2(N)) ? 32)).

Looking at the source code to src/main/RNG.c, we have the following:

static double rbits(int bits)
{
    int_least64_t v = 0;
    for (int n = 0; n <= bits; n += 16) {
                int v1 = (int) floor(unif_rand() * 65536);
                v = 65536 * v + v1;
    }
    // mask out the bits in the result that are not needed
    return (double) (v & ((1L << bits) - 1));
}

The last line has (v & ((1L << bits) - 1)) where v is declared as
int_least64_t. If you notice, we are operating on v with the long
integer literal 1L. I?m pretty sure this is the source of the issue.
By changing 1L to at least a 64 bit integer, it appears that we
correct the problem:

double rbits(int bits)
{
    int_least64_t v = 0;
    for (int n = 0; n <= bits; n += 16) {
                int v1 = (int) floor(unif_rand() * 65536);
                v = 65536 * v + v1;
    }

    int_least64_t one64 = 1L;
    // mask out the bits in the result that are not needed
    return (double) (v & ((one64 << bits) - 1));
}

Regards,
Joseph Wood


From er|nm@hodge@@ @end|ng |rom gm@||@com  Fri Mar  1 20:30:35 2019
From: er|nm@hodge@@ @end|ng |rom gm@||@com (Erin Hodgess)
Date: Fri, 1 Mar 2019 12:30:35 -0700
Subject: [Rd] Problem with compiling OpenBLAS to work with R
In-Reply-To: <CAL6gwn+hEg8BJBFOuksEQyvQXknzdFpTpHmTZ080wrAeoWA-Hw@mail.gmail.com>
References: <CACxE24kZSEVgfah=fGXqx0jzrGoc6RBwUSgBWTMgoyi4q0z84A@mail.gmail.com>
 <CAPekMCkox-bmcVjZbn2uNE5AipWkbdVg7-C=QddEhDhNUU830w@mail.gmail.com>
 <CAL6gwn+hEg8BJBFOuksEQyvQXknzdFpTpHmTZ080wrAeoWA-Hw@mail.gmail.com>
Message-ID: <CACxE24=hVLA8gUucL=d09SV7eY-E7s6RH6AeTKFjdddNYU70pw@mail.gmail.com>

Yay!  I re-installed everything and got through "Make distribution"!

I have one more question, please:  I am running the make check-all.  I have
an error at reg-1d.  It stops the process.  However, the mean difference
(as per the file) is 2.0e-12.  I'm ok with that.  How do I bypass this,
please?

Thanks,
Erin

Erin Hodgess, PhD
mailto: erinm.hodgess at gmail.com


On Wed, Feb 27, 2019 at 10:22 PM Avraham Adler <avraham.adler at gmail.com>
wrote:

> I believe that repo just follows the directions on my blog. Without seeing
> Dr. Hodges?s code, my initial concern is the many references to Cygwin. My
> method specifically does not use Cygwin but MSYS2 and Mingw64/Rtools35.
> That will likely change to solely Rtools40 once R3.6 is released due to the
> Msys system being built in to it.
>
> There may be some library conflicts between Cygwin and msys2/mingw64. If
> possible, my suggestion would be uninstall everything and then just install
> msys2 (and add in make after you to the first msys update) and rtools35.
> Then there should be no conflicting libraries.
>
> Thanks,
>
> Avi
>
> On Thu, Feb 28, 2019 at 12:11 AM Kenny Bell <kmbell56 at gmail.com> wrote:
>
>> This person has had apparent success - you could follow what they did or
>> just download their product (with appropriate caution downloading a random
>> .exe).
>>
>> https://github.com/thequackdaddy/R-OpenBLAS
>>
>> On Thu, Feb 28, 2019 at 6:28 AM Erin Hodgess <erinm.hodgess at gmail.com>
>> wrote:
>>
>> > Hello!
>> >
>> > I'm not sure if this is the right place to post this, so apologies
>> > in advance if I'm not in the right list.
>> >
>> > I downloaded the OpenBLAS and am following Avraham Adler's great
>> > instructions.  However, when I run make, things go well to a certain
>> point,
>> > and then go bad:
>> >
>> > make
>> > [snip]
>> >
>> > touch cygopenblas_haswellp-r0.3.5.a
>> > make -j 1 -C test all
>> > make[1]: Entering directory
>> > '/home/erinm/OPB_HOME/xianyi-OpenBLAS-eebc189/test'
>> > gfortran -O2 -Wall -frecursive -m64 -mavx2   -o sblat1 sblat1.o
>> > ../cygopenblas_haswellp-r0.3.5.a  -L/usr/lib/gcc/x86_64-pc-msys/7.3.0
>> >
>> -L/usr/lib/gcc/x86_64-pc-msys/7.3.0/../../../../x86_64-pc-msys/lib/../lib
>> > -L/usr/lib/../lib
>> > -L/usr/lib/gcc/x86_64-pc-msys/7.3.0/../../../../x86_64-pc-msys/lib
>> > -L/usr/lib/w32api  -lmsys-2.0
>> > D:/msys64/usr/lib/../lib/libpthread.a(t-d001088.o):fake:(.text+0x2):
>> > undefined reference to `__imp_pthread_mutex_destroy'
>> > D:/msys64/usr/lib/../lib/libpthread.a(t-d001090.o):fake:(.text+0x2):
>> > undefined reference to `__imp_pthread_mutex_init'
>> > D:/msys64/usr/lib/../lib/libpthread.a(t-d001091.o):fake:(.text+0x2):
>> > undefined reference to `__imp_pthread_mutex_lock'
>> > D:/msys64/usr/lib/../lib/libpthread.a(t-d001094.o):fake:(.text+0x2):
>> > undefined reference to `__imp_pthread_mutex_trylock'
>> > D:/msys64/usr/lib/../lib/libpthread.a(t-d001095.o):fake:(.text+0x2):
>> > undefined reference to `__imp_pthread_mutex_unlock'
>> > collect2.exe: error: ld returned 1 exit status
>> > make[1]: *** [Makefile:134: sblat1] Error 1
>> > make[1]: Leaving directory
>> > '/home/erinm/OPB_HOME/xianyi-OpenBLAS-eebc189/test'
>> > make: *** [Makefile:124: tests] Error 2
>> >
>> >
>> > I think it has something to do with the threads/pthreads but am not sure
>> > how to fix it.  Any suggestions much appreciated.
>> >
>> > Thanks,
>> > Sincerely,
>> > Erin
>> >
>> > Erin Hodgess, PhD
>> > mailto: erinm.hodgess at gmail.com
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-devel at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-devel
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
> --
> Sent from Gmail Mobile
>

	[[alternative HTML version deleted]]


From |uke-t|erney @end|ng |rom u|ow@@edu  Fri Mar  1 21:39:29 2019
From: |uke-t|erney @end|ng |rom u|ow@@edu (Tierney, Luke)
Date: Fri, 1 Mar 2019 20:39:29 +0000
Subject: [Rd] issue with sample in R 3.6.0.
In-Reply-To: <CAKDcrSjJ6nsudEct9LW+0UC477uT2baJDCvzXm744W6Txon0bA@mail.gmail.com>
References: <CAKDcrSjJ6nsudEct9LW+0UC477uT2baJDCvzXm744W6Txon0bA@mail.gmail.com>
Message-ID: <alpine.LFD.2.21.1903011435330.1168@itasca.stat.uiowa.edu>

Thanks; fixed now in R-devel. Not an issue on Linux/Mac OS but is on
64-bit Windows, where sizeof(long) is 4.

Best,

luke

On Fri, 1 Mar 2019, Joseph Wood wrote:

> Hello,
>
> I think there is an issue in the sampling rejection algorithm in R 3.6.0.
>
> The do_sample2 function in src/main/unique.c still has 4.5e15 as an
> upper limit, implying that numbers greater than INT_MAX are still to
> be supported by sample in base R.
>
> Please review the examples below:
>
> set.seed(123)
> max(sample(2^31, 1e5))
> [1] 2147430096
>
> set.seed(123)
> max(sample(2^31 + 1, 1e5))
> [1] 1
>
> set.seed(123)
> max(sample(2^32, 1e5))
> [1] 1
>
> set.seed(123)
> max(sample(2^35, 1e5))
> [1] 8
>
> set.seed(123)
> max(sample(2^38, 1e5))
> [1] 64
>
> set.seed(123)
> max(sample(2^38, 1e5))
> [1] 64
>
> set.seed(123)
> max(sample(2^42, 1e5))
> [1] 1024
>
> From the above, we see that if N is greater than 2^31, then N is
> bounded by (2^(ceiling(log2(N)) ? 32)).
>
> Looking at the source code to src/main/RNG.c, we have the following:
>
> static double rbits(int bits)
> {
>    int_least64_t v = 0;
>    for (int n = 0; n <= bits; n += 16) {
>                int v1 = (int) floor(unif_rand() * 65536);
>                v = 65536 * v + v1;
>    }
>    // mask out the bits in the result that are not needed
>    return (double) (v & ((1L << bits) - 1));
> }
>
> The last line has (v & ((1L << bits) - 1)) where v is declared as
> int_least64_t. If you notice, we are operating on v with the long
> integer literal 1L. I?m pretty sure this is the source of the issue.
> By changing 1L to at least a 64 bit integer, it appears that we
> correct the problem:
>
> double rbits(int bits)
> {
>    int_least64_t v = 0;
>    for (int n = 0; n <= bits; n += 16) {
>                int v1 = (int) floor(unif_rand() * 65536);
>                v = 65536 * v + v1;
>    }
>
>    int_least64_t one64 = 1L;
>    // mask out the bits in the result that are not needed
>    return (double) (v & ((one64 << bits) - 1));
> }
>
> Regards,
> Joseph Wood
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Luke Tierney
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu

From @uh@rto_@nggono @end|ng |rom y@hoo@com  Sat Mar  2 09:28:23 2019
From: @uh@rto_@nggono @end|ng |rom y@hoo@com (Suharto Anggono Suharto Anggono)
Date: Sat, 2 Mar 2019 08:28:23 +0000 (UTC)
Subject: [Rd] stopifnot
References: <599003614.8032805.1551515303841.ref@mail.yahoo.com>
Message-ID: <599003614.8032805.1551515303841@mail.yahoo.com>

A private reply by Martin made me realize that I was wrong about
stopifnot(exprs=TRUE) .
It actually works fine. I apologize. What I tried and was failed was
stopifnot(exprs=T) .
Error in exprs[[1]] : object of type 'symbol' is not subsettable

The shortcut
assert <- function(exprs) stopifnot(exprs = exprs)
mentioned in "Warning" section of the documentation similarly fails when called, for example
assert({})

About shortcut, a definition that rather works:
assert <- function(exprs) eval.parent(substitute(stopifnot(exprs = exprs)))

Looking at https://stat.ethz.ch/pipermail/r-devel/2017-May/074227.html , using sys.parent() may be not good. For example, in
f <- function() stopifnot(exprs={FALSE}, local=FALSE); f()

A revised patch (also with simpler 'cl'):
--- stop.R	2019-02-27 16:15:45.324167577 +0000
+++ stop_new.R	2019-03-02 06:21:35.919471080 +0000
@@ -1,7 +1,7 @@
 #  File src/library/base/R/stop.R
 #  Part of the R package, https://www.R-project.org
 #
-#  Copyright (C) 1995-2018 The R Core Team
+#  Copyright (C) 1995-2019 The R Core Team
 #
 #  This program is free software; you can redistribute it and/or modify
 #  it under the terms of the GNU General Public License as published by
@@ -33,25 +33,28 @@
 
 stopifnot <- function(..., exprs, local = TRUE)
 {
+    n <- ...length()
     missE <- missing(exprs)
-    cl <-
 	if(missE) {  ## use '...' instead of exprs
-	    match.call(expand.dots=FALSE)$...
 	} else {
-	    if(...length())
+	    if(n)
 		stop("Must use 'exprs' or unnamed expressions, but not both")
 	    envir <- if (isTRUE(local)) parent.frame()
 		     else if(isFALSE(local)) .GlobalEnv
 		     else if (is.environment(local)) local
 		     else stop("'local' must be TRUE, FALSE or an environment")
 	    exprs <- substitute(exprs) # protect from evaluation
-	    E1 <- exprs[[1]]
+	    E1 <- if(is.call(exprs)) exprs[[1]]
+	    cl <-
 	    if(identical(quote(`{`), E1)) # { ... }
-		do.call(expression, as.list(exprs[-1]))
+		exprs
 	    else if(identical(quote(expression), E1))
-		eval(exprs, envir=envir)
+		exprs
 	    else
-		as.expression(exprs) # or fail ..
+		call("expression", exprs) # or fail ..
+	    if(!is.null(names(cl))) names(cl) <- NULL
+	    cl[[1]] <- sys.call()[[1]]
+	    return(eval(cl, envir=envir))
 	}
     Dparse <- function(call, cutoff = 60L) {
 	ch <- deparse(call, width.cutoff = cutoff)
@@ -62,14 +65,10 @@
     abbrev <- function(ae, n = 3L)
 	paste(c(head(ae, n), if(length(ae) > n) "...."), collapse="\n  ")
     ##
-    for (i in seq_along(cl)) {
-	cl.i <- cl[[i]]
-	## r <- eval(cl.i, ..)   # with correct warn/err messages:
-	r <- withCallingHandlers(
-		tryCatch(if(missE) ...elt(i) else eval(cl.i, envir=envir),
-			 error = function(e) { e$call <- cl.i; stop(e) }),
-		warning = function(w) { w$call <- cl.i; w })
+    for (i in seq_len(n)) {
+	r <- ...elt(i)
 	if (!(is.logical(r) && !anyNA(r) && all(r))) {
+	    cl.i <- match.call(expand.dots=FALSE)$...[[i]]
 	    msg <- ## special case for decently written 'all.equal(*)':
 		if(is.call(cl.i) && identical(cl.i[[1]], quote(all.equal)) &&
 		   (is.null(ni <- names(cl.i)) || length(cl.i) == 3L ||
@@ -84,7 +83,12 @@
 				     "%s are not all TRUE"),
 			    Dparse(cl.i))
 
-	    stop(simpleError(msg, call = sys.call(-1)))
+	    n <- sys.nframe()
+	    if((p <- n-3) > 0 &&
+	       identical(sys.function(p), sys.function(n)) &&
+	       eval(expression(!missE), p)) # originally stopifnot(exprs=*)
+		n <- p
+	    stop(simpleError(msg, call = if(n > 1) sys.call(n-1)))
 	}
     }
     invisible()

--------------------------------------------
On Fri, 1/3/19, Martin Maechler <maechler at stat.math.ethz.ch> wrote:

 Subject: Re: [Rd] stopifnot

 Cc: "Martin Maechler" <maechler at stat.math.ethz.ch>, r-devel at r-project.org
 Date: Friday, 1 March, 2019, 6:40 PM

>>>>> Suharto Anggono Suharto Anggono 
>>>>>? ? on Wed, 27 Feb 2019 22:46:04 +0000 writes:

[...]

? ? > Another thing: currently,
? ? > stopifnot(exprs=TRUE)
? ? > fails.

good catch - indeed!

I've started to carefully test and try the interesting nice
patch you've provided below.

[...]

Martin


? ? > A patch:
? ? > --- stop.R? ? 2019-02-27 16:15:45.324167577 +0000
? ? > +++ stop_new.R? ? 2019-02-27 16:22:15.936203541 +0000
? ? > @@ -1,7 +1,7 @@
? ? > #? File src/library/base/R/stop.R
? ? > #? Part of the R package, https://www.R-project.org
? ? > #
? ? > -#? Copyright (C) 1995-2018 The R Core Team
? ? > +#? Copyright (C) 1995-2019 The R Core Team
? ? > #
? ? > #? This program is free software; you can redistribute it and/or modify
? ? > #? it under the terms of the GNU General Public License as published by
? ? > @@ -33,25 +33,27 @@

? ? > stopifnot <- function(..., exprs, local = TRUE)
? ? > {
? ? > +? ? n <- ...length()
? ? > missE <- missing(exprs)
? ? > -? ? cl <-
? ? > if(missE) {? ## use '...' instead of exprs
? ? > -? ? ? ? match.call(expand.dots=FALSE)$...
? ? > } else {
? ? > -? ? ? ? if(...length())
? ? > +? ? ? ? if(n)
? ? > stop("Must use 'exprs' or unnamed expressions, but not both")
? ? > envir <- if (isTRUE(local)) parent.frame()
? ? > else if(isFALSE(local)) .GlobalEnv
? ? > else if (is.environment(local)) local
? ? > else stop("'local' must be TRUE, FALSE or an environment")
? ? > exprs <- substitute(exprs) # protect from evaluation
? ? > -? ? ? ? E1 <- exprs[[1]]
? ? > +? ? ? ? E1 <- if(is.call(exprs)) exprs[[1]]
? ? > +? ? ? ? cl <-
? ? > if(identical(quote(`{`), E1)) # { ... }
? ? > -? ? ? ? do.call(expression, as.list(exprs[-1]))
? ? > +? ? ? ? exprs[-1]
? ? > else if(identical(quote(expression), E1))
? ? > eval(exprs, envir=envir)
? ? > else
? ? > as.expression(exprs) # or fail ..
? ? > +? ? ? ? if(!is.null(names(cl))) names(cl) <- NULL
? ? > +? ? ? ? return(eval(as.call(c(sys.call()[[1]], as.list(cl))), envir=envir))
? ? > }
? ? > Dparse <- function(call, cutoff = 60L) {
? ? > ch <- deparse(call, width.cutoff = cutoff)
? ? > @@ -62,14 +64,10 @@
? ? > abbrev <- function(ae, n = 3L)
? ? > paste(c(head(ae, n), if(length(ae) > n) "...."), collapse="\n? ")
? ? > ##
? ? > -? ? for (i in seq_along(cl)) {
? ? > -? ? cl.i <- cl[[i]]
? ? > -? ? ## r <- eval(cl.i, ..)? # with correct warn/err messages:
? ? > -? ? r <- withCallingHandlers(
? ? > -? ? ? ? tryCatch(if(missE) ...elt(i) else eval(cl.i, envir=envir),
? ? > -? ? ? ? ? ? error = function(e) { e$call <- cl.i; stop(e) }),
? ? > -? ? ? ? warning = function(w) { w$call <- cl.i; w })
? ? > +? ? for (i in seq_len(n)) {
? ? > +? ? r <- ...elt(i)
? ? > if (!(is.logical(r) && !anyNA(r) && all(r))) {
? ? > +? ? ? ? cl.i <- match.call(expand.dots=FALSE)$...[[i]]
? ? > msg <- ## special case for decently written 'all.equal(*)':
? ? > if(is.call(cl.i) && identical(cl.i[[1]], quote(all.equal)) &&
? ? > (is.null(ni <- names(cl.i)) || length(cl.i) == 3L ||
? ? > @@ -84,7 +82,11 @@
? ? > "%s are not all TRUE"),
? ? > Dparse(cl.i))

? ? > -? ? ? ? stop(simpleError(msg, call = sys.call(-1)))
? ? > +? ? ? ? p <- sys.parent()
? ? > +? ? ? ? if(p && identical(sys.function(p), stopifnot) &&
? ? > +? ? ? ? ? !eval(expression(missE), p)) # originally stopifnot(exprs=*)
? ? > +? ? ? ? p <- sys.parent(2)
? ? > +? ? ? ? stop(simpleError(msg, call = if(p) sys.call(p)))
? ? > }
? ? > }
? ? > invisible()


From @uh@rto_@nggono @end|ng |rom y@hoo@com  Sat Mar  2 13:58:29 2019
From: @uh@rto_@nggono @end|ng |rom y@hoo@com (Suharto Anggono Suharto Anggono)
Date: Sat, 2 Mar 2019 12:58:29 +0000 (UTC)
Subject: [Rd] stopifnot
References: <2125739835.8093864.1551531509689.ref@mail.yahoo.com>
Message-ID: <2125739835.8093864.1551531509689@mail.yahoo.com>

Instead of
if(!is.null(names(cl))) names(cl) <- NULL ,
just
names(cl) <- NULL
looks simpler and the memory usage and speed is not bad in my little experiment.

--------------------------------------------


 Subject: Re: [Rd] stopifnot
 To: r-devel at r-project.org
 Date: Saturday, 2 March, 2019, 3:28 PM
 
[...]

A revised patch (also with simpler 'cl'):
--- stop.R    2019-02-27 16:15:45.324167577 +0000
+++ stop_new.R    2019-03-02 06:21:35.919471080 +0000
@@ -1,7 +1,7 @@
#  File src/library/base/R/stop.R
#  Part of the R package, https://www.R-project.org
#
-#  Copyright (C) 1995-2018 The R Core Team
+#  Copyright (C) 1995-2019 The R Core Team
#
#  This program is free software; you can redistribute it and/or modify
#  it under the terms of the GNU General Public License as published by
@@ -33,25 +33,28 @@

stopifnot <- function(..., exprs, local = TRUE)
{
+    n <- ...length()
    missE <- missing(exprs)
-    cl <-
    if(missE) {  ## use '...' instead of exprs
-        match.call(expand.dots=FALSE)$...
    } else {
-        if(...length())
+        if(n)
        stop("Must use 'exprs' or unnamed expressions, but not both")
        envir <- if (isTRUE(local)) parent.frame()
            else if(isFALSE(local)) .GlobalEnv
            else if (is.environment(local)) local
            else stop("'local' must be TRUE, FALSE or an environment")
        exprs <- substitute(exprs) # protect from evaluation
-        E1 <- exprs[[1]]
+        E1 <- if(is.call(exprs)) exprs[[1]]
+        cl <-
        if(identical(quote(`{`), E1)) # { ... }
-        do.call(expression, as.list(exprs[-1]))
+        exprs
        else if(identical(quote(expression), E1))
-        eval(exprs, envir=envir)
+        exprs
        else
-        as.expression(exprs) # or fail ..
+        call("expression", exprs) # or fail ..
+        if(!is.null(names(cl))) names(cl) <- NULL
+        cl[[1]] <- sys.call()[[1]]
+        return(eval(cl, envir=envir))
    }
    Dparse <- function(call, cutoff = 60L) {
    ch <- deparse(call, width.cutoff = cutoff)
@@ -62,14 +65,10 @@
    abbrev <- function(ae, n = 3L)
    paste(c(head(ae, n), if(length(ae) > n) "...."), collapse="\n  ")
    ##
-    for (i in seq_along(cl)) {
-    cl.i <- cl[[i]]
-    ## r <- eval(cl.i, ..)  # with correct warn/err messages:
-    r <- withCallingHandlers(
-        tryCatch(if(missE) ...elt(i) else eval(cl.i, envir=envir),
-            error = function(e) { e$call <- cl.i; stop(e) }),
-        warning = function(w) { w$call <- cl.i; w })
+    for (i in seq_len(n)) {
+    r <- ...elt(i)
    if (!(is.logical(r) && !anyNA(r) && all(r))) {
+        cl.i <- match.call(expand.dots=FALSE)$...[[i]]
        msg <- ## special case for decently written 'all.equal(*)':
        if(is.call(cl.i) && identical(cl.i[[1]], quote(all.equal)) &&
          (is.null(ni <- names(cl.i)) || length(cl.i) == 3L ||
@@ -84,7 +83,12 @@
                    "%s are not all TRUE"),
                Dparse(cl.i))

-        stop(simpleError(msg, call = sys.call(-1)))
+        n <- sys.nframe()
+        if((p <- n-3) > 0 &&
+          identical(sys.function(p), sys.function(n)) &&
+          eval(expression(!missE), p)) # originally stopifnot(exprs=*)
+        n <- p
+        stop(simpleError(msg, call = if(n > 1) sys.call(n-1)))
    }
    }
    invisible()


From er|nm@hodge@@ @end|ng |rom gm@||@com  Sat Mar  2 14:11:50 2019
From: er|nm@hodge@@ @end|ng |rom gm@||@com (Erin Hodgess)
Date: Sat, 2 Mar 2019 06:11:50 -0700
Subject: [Rd] Using a different compiler when creating a package on Windows
Message-ID: <CACxE24k8sbM=-hp5mS9G2bq5VxaEBDAUwGML89to0h69hnxc2A@mail.gmail.com>

Hello!

I am updating to the R-devel version as of 2/28 and recompiling with
OpenBLAS.   I got that to compile nicely.

I am now updating a package that uses the OpenBLAS and the PGI compiler,
which has changed too.

I just changed the path names in Makevars.  Here is the Makevars file.

FC= d:/PGI/win64/18.10/bin/pgf90
F77= d:/PGI/win64/18.10/bin/pgf90
CC = d:/PGI/win64/18.10/bin/pgcc
FFLAGS= -Ld:/PGI/win64/18.10/bin/pgf90.dll
-Ld:/PGI/win64/18.10/bin/pgc14.dll
FLIBS= -Ld:/PGI/win64/18.10/bin/pgf90.dll
-Ld:/PGI/win64/18.10/bin/pgc14.dll
PKG_LIBS = $(LAPACK_LIBS) $(BLAS_LIBS) $(FLIBS)
MPI_FFLAGS= -Mmpi=msmpi
SHLIB_FFLAGS= -Mmakedll
CUDA_FFLAGS=-acc -Minfo=accel -Mlarge_arrays
-Ld:/PGI/win64/18.10/bin/pgf90.dll -Ld:/PGI/win64/18.10/bin/pgc14.dll
DLLCUDA_FFLAGS=-ta=tesla:nordc
 -Ld:/PGI/win64/18.10/lib/acc_init_link_cuda.obj
-Ld:/PGI/win64/18.10/lib/libaccapi.lib
 -Ld:/PGI/win64/18.10/lib/libaccg.lib
 -Ld:/PGI/win64/18.10/lib/libaccn.lib
 -Ld:/PGI/win64/18.10/lib/libaccg2.lib
 -Ld:/PGI/win64/18.10/lib/libcudadevice.lib
 -Ld:/PGI/win64/18.10/lib/pgc14.lib
 -Ld:/PGI/win64/18.10/lib/libnspgc.lib
-defaultlib:legacy_stdio_definitions -defaultlib:oldnames
-Ld:/PGI/win64/18.10/bin/pgf90.dll -Ld:/PGI/win64/18.10/bin/pgc14.dll


rmpiFort.obj: rmpiFort.f90
$(FC) $(FFLAGS) $(MPI_FFLAGS) -c rmpiFort.f90 -o rmpiFort.obj  -m64
$(FC) $(CUDA_FFLAGS) $(DLLCUDA_FFLAGS) -c test4.f90 -o test4.obj -m64
$(FC) $(SHLIB_FFLAGS) $(FFLAGS) $(MPI_FFLAGS) $(CUDA_FFLAGS) -o
rmpiFort.dll test4.obj rmpiFort.obj  -m64


When I do Make check, I get the following:
* installing *source* package 'rmpiFort' ...

** libs

d:/Rtools/mingw_64/bin/gfortran  -O2  -march=native -pipe -Mmpi=msmpi -c
rmpiFort.f90 -o rmpiFort.obj  -m64
gfortran.exe: error: unrecognized command line option '-Mmpi=msmpi'

make: *** [Makevars:14: rmpiFort.obj] Error 1
ERROR: compilation failed for package 'rmpiFort'

* removing 'D:/rnew/rmpiFort.Rcheck/rmpiFort'

So it is still trying to use the gfortran compiler rather than the PGI
compiler.

The PGI libraries are first in the PATH.

Since it worked fine before, I am at a loss as to why it doesn't work now.
Any suggestions much appreciated.

Thanks,
Erin



Erin Hodgess, PhD
mailto: erinm.hodgess at gmail.com

	[[alternative HTML version deleted]]


From ccberry @end|ng |rom uc@d@edu  Sun Mar  3 21:20:25 2019
From: ccberry @end|ng |rom uc@d@edu (Berry, Charles)
Date: Sun, 3 Mar 2019 20:20:25 +0000
Subject: [Rd] bug: sample( x, size, replace = TRUE,
 prob= skewed.probs) produces uniform sample
Message-ID: <6504F2C9-FF26-4017-9470-BE11A3953028@ucsd.edu>

When  `length( skewed.probs ) > 200' uniform samples are generated in R-devel.

R-3.5.1 behaves as expected.

`epsilon` can be a lot bigger than illustrated and still the uniform distribution is produced.


Chuck

> set.seed(123)
> 
> epsilon <- 1e-10
> 
> ## uniform to 200 then small
> p200 <- prop.table( rep( c(1, epsilon), c(200, 999-200)))
> ## uniform to 201 then small
> p201 <- prop.table( rep( c(1, epsilon), c(201, 999-201)))
> 
> brks  <- c(0,99,199,200,201,Inf)
> tab200 <- sample( length(p200), 10000, prob=p200, replace=TRUE)
> tab201 <- sample( length(p201), 10000, prob=p201, replace=TRUE)
> 
> cbind(
+   s200=table(cut(tab200, brks)),
+   p200=round(xtabs(p200 ~ cut( seq_along(p200), brks)) * 10000 ,1),
+   s201=table(cut(tab201, brks )),
+   p201=round(xtabs(p201 ~ cut( seq_along(p201), brks)) * 10000 ,1))
          s200 p200 s201   p201
(0,99]    5017 4950  984 4925.4
(99,199]  4925 5000  959 4975.1
(199,200]   58   50    9   49.8
(200,201]    0    0    6   49.8
(201,Inf]    0    0 8042    0.0
> 
> 
> 
> 
> sessionInfo()
R Under development (unstable) (2019-03-02 r76189)
Platform: x86_64-apple-darwin18.2.0 (64-bit)
Running under: macOS Mojave 10.14.3

Matrix products: default
BLAS: /Users/cberry/projects/R/R-devel/lib/libRblas.dylib
LAPACK: /Users/cberry/projects/R/R-devel/lib/libRlapack.dylib

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

loaded via a namespace (and not attached):
[1] compiler_3.6.0
> 


From |uke-t|erney @end|ng |rom u|ow@@edu  Sun Mar  3 22:44:33 2019
From: |uke-t|erney @end|ng |rom u|ow@@edu (Tierney, Luke)
Date: Sun, 3 Mar 2019 21:44:33 +0000
Subject: [Rd] bug: sample( x, size, replace = TRUE,
 prob= skewed.probs) produces uniform sample
In-Reply-To: <6504F2C9-FF26-4017-9470-BE11A3953028@ucsd.edu>
References: <6504F2C9-FF26-4017-9470-BE11A3953028@ucsd.edu>
Message-ID: <alpine.DEB.2.21.1903031543520.4951@luke-Latitude-7480>

Thanks. We'll need to look into how best to address this.

Best,

luke

On Sun, 3 Mar 2019, Berry, Charles wrote:

> When  `length( skewed.probs ) > 200' uniform samples are generated in R-devel.
>
> R-3.5.1 behaves as expected.
>
> `epsilon` can be a lot bigger than illustrated and still the uniform distribution is produced.
>
>
> Chuck
>
>> set.seed(123)
>>
>> epsilon <- 1e-10
>>
>> ## uniform to 200 then small
>> p200 <- prop.table( rep( c(1, epsilon), c(200, 999-200)))
>> ## uniform to 201 then small
>> p201 <- prop.table( rep( c(1, epsilon), c(201, 999-201)))
>>
>> brks  <- c(0,99,199,200,201,Inf)
>> tab200 <- sample( length(p200), 10000, prob=p200, replace=TRUE)
>> tab201 <- sample( length(p201), 10000, prob=p201, replace=TRUE)
>>
>> cbind(
> +   s200=table(cut(tab200, brks)),
> +   p200=round(xtabs(p200 ~ cut( seq_along(p200), brks)) * 10000 ,1),
> +   s201=table(cut(tab201, brks )),
> +   p201=round(xtabs(p201 ~ cut( seq_along(p201), brks)) * 10000 ,1))
>          s200 p200 s201   p201
> (0,99]    5017 4950  984 4925.4
> (99,199]  4925 5000  959 4975.1
> (199,200]   58   50    9   49.8
> (200,201]    0    0    6   49.8
> (201,Inf]    0    0 8042    0.0
>>
>>
>>
>>
>> sessionInfo()
> R Under development (unstable) (2019-03-02 r76189)
> Platform: x86_64-apple-darwin18.2.0 (64-bit)
> Running under: macOS Mojave 10.14.3
>
> Matrix products: default
> BLAS: /Users/cberry/projects/R/R-devel/lib/libRblas.dylib
> LAPACK: /Users/cberry/projects/R/R-devel/lib/libRlapack.dylib
>
> locale:
> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> loaded via a namespace (and not attached):
> [1] compiler_3.6.0
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Luke Tierney
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From @k@||nder @end|ng |rom w|@c@edu  Fri Mar  1 23:04:27 2019
From: @k@||nder @end|ng |rom w|@c@edu (David Skalinder)
Date: Fri, 1 Mar 2019 22:04:27 +0000
Subject: [Rd] Bug: as.matrix.data.frame() treats numeric vectors with
 "levels" attribute as factors
Message-ID: <54006fe1-01d2-3269-effc-a73aa6c246f5@wisc.edu>

Hello,

I think I've found a bug in as.matrix.data.frame().? The function's 
documentation says: "The method for data frames will return a character 
matrix if there is only atomic columns and any 
non-(numeric/logical/complex) column, applying as.vector to factors and 
format to other non-character columns. Otherwise, the usual coercion 
hierarchy (logical < integer < double < complex) will be used..."

However, when the function checks for non-numeric columns, it includes 
the following check for each column xj:

length(levels(xj)) > 0L

This means that any atomic, numeric, non-factor column with a "levels" 
attribute will cause as.matrix.data.frame() to return a character 
matrix, not use the usual coercion hierarchy as documented.? This means, 
for example, that columns that are unclassed factors will unexpectedly 
force as.matrix.data.frame() to return a character matrix.

To reproduce:

-----

df <- data.frame(v1 = 1:2, v2 = 3:4)

typeof(as.matrix(df)) # integer, as documented

attr(df[[1]], "levels") <- "test"
class(df[[1]]) # integer
typeof(as.matrix(df)) # character, despite all atomic, numeric, 
non-factor cols

df2 <- data.frame(v1 = unclass(factor(c("a", "b"))), v2 = 1:2)
typeof(as.matrix(df2)) # character, despite unclassing factor

attr(df2[[1]], "levels") <- NULL
typeof(as.matrix(df2)) # integer, even though no types changed
-----

I can reproduce this in 3.5.1 and 3.5.2, and I can't see anything 
related in the upcoming changes or in Bugzilla, so I thought I'd report 
it here.? I don't know what the cleanest fix will be, but it seems that 
either the function or the documentation should be changed so that they 
align.

Please let me know if you need any additional info!

Thanks

David


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Mon Mar  4 10:06:11 2019
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Mon, 4 Mar 2019 10:06:11 +0100
Subject: [Rd] Problem with compiling OpenBLAS to work with R
In-Reply-To: <CACxE24=hVLA8gUucL=d09SV7eY-E7s6RH6AeTKFjdddNYU70pw@mail.gmail.com>
References: <CACxE24kZSEVgfah=fGXqx0jzrGoc6RBwUSgBWTMgoyi4q0z84A@mail.gmail.com>
 <CAPekMCkox-bmcVjZbn2uNE5AipWkbdVg7-C=QddEhDhNUU830w@mail.gmail.com>
 <CAL6gwn+hEg8BJBFOuksEQyvQXknzdFpTpHmTZ080wrAeoWA-Hw@mail.gmail.com>
 <CACxE24=hVLA8gUucL=d09SV7eY-E7s6RH6AeTKFjdddNYU70pw@mail.gmail.com>
Message-ID: <23676.60035.254296.166127@stat.math.ethz.ch>

>>>>> Erin Hodgess 
>>>>>     on Fri, 1 Mar 2019 12:30:35 -0700 writes:

    > Yay!  I re-installed everything and got through "Make
    > distribution"!  I have one more question, please: I am
    > running the make check-all.  I have an error at reg-1d.
    > It stops the process.  However, the mean difference (as
    > per the file) is 2.0e-12.  I'm ok with that.  How do I
    > bypass this, please?

If you'd be really precise in your report (use correct file
names; show the exact error message + context lines of the *.Rout.fail
file) I could help you.

Note (by the way) that this may be yet another example showing
that OpenBLAS may be faster but less accurate than the
(plain+ minor tweaks) version of BLAS that ships with R.

Martin

    > Thanks, Erin

    > Erin Hodgess, PhD mailto: erinm.hodgess at gmail.com


    > On Wed, Feb 27, 2019 at 10:22 PM Avraham Adler
    > <avraham.adler at gmail.com> wrote:

    >> I believe that repo just follows the directions on my
    >> blog. Without seeing Dr. Hodges?s code, my initial
    >> concern is the many references to Cygwin. My method
    >> specifically does not use Cygwin but MSYS2 and
    >> Mingw64/Rtools35.  That will likely change to solely
    >> Rtools40 once R3.6 is released due to the Msys system
    >> being built in to it.
    >> 
    >> There may be some library conflicts between Cygwin and
    >> msys2/mingw64. If possible, my suggestion would be
    >> uninstall everything and then just install msys2 (and add
    >> in make after you to the first msys update) and rtools35.
    >> Then there should be no conflicting libraries.
    >> 
    >> Thanks,
    >> 
    >> Avi
    >> 
    >> On Thu, Feb 28, 2019 at 12:11 AM Kenny Bell
    >> <kmbell56 at gmail.com> wrote:
    >> 
    >>> This person has had apparent success - you could follow
    >>> what they did or just download their product (with
    >>> appropriate caution downloading a random .exe).
    >>> 
    >>> https://github.com/thequackdaddy/R-OpenBLAS
    >>> 
    >>> On Thu, Feb 28, 2019 at 6:28 AM Erin Hodgess
    >>> <erinm.hodgess at gmail.com> wrote:
    >>> 
    >>> > Hello!
    >>> >
    >>> > I'm not sure if this is the right place to post this,
    >>> so apologies > in advance if I'm not in the right list.
    >>> >
    >>> > I downloaded the OpenBLAS and am following Avraham
    >>> Adler's great > instructions.  However, when I run make,
    >>> things go well to a certain point, > and then go bad:
    >>> >
    >>> > make > [snip]
    >>> >
    >>> > touch cygopenblas_haswellp-r0.3.5.a > make -j 1 -C
    >>> test all > make[1]: Entering directory >
    >>> '/home/erinm/OPB_HOME/xianyi-OpenBLAS-eebc189/test' >
    >>> gfortran -O2 -Wall -frecursive -m64 -mavx2 -o sblat1
    >>> sblat1.o > ../cygopenblas_haswellp-r0.3.5.a
    >>> -L/usr/lib/gcc/x86_64-pc-msys/7.3.0
    >>> >
    >>> -L/usr/lib/gcc/x86_64-pc-msys/7.3.0/../../../../x86_64-pc-msys/lib/../lib
    >>> > -L/usr/lib/../lib >
    >>> -L/usr/lib/gcc/x86_64-pc-msys/7.3.0/../../../../x86_64-pc-msys/lib
    >>> > -L/usr/lib/w32api -lmsys-2.0 >
    >>> D:/msys64/usr/lib/../lib/libpthread.a(t-d001088.o):fake:(.text+0x2):
    >>> > undefined reference to `__imp_pthread_mutex_destroy' >
    >>> D:/msys64/usr/lib/../lib/libpthread.a(t-d001090.o):fake:(.text+0x2):
    >>> > undefined reference to `__imp_pthread_mutex_init' >
    >>> D:/msys64/usr/lib/../lib/libpthread.a(t-d001091.o):fake:(.text+0x2):
    >>> > undefined reference to `__imp_pthread_mutex_lock' >
    >>> D:/msys64/usr/lib/../lib/libpthread.a(t-d001094.o):fake:(.text+0x2):
    >>> > undefined reference to `__imp_pthread_mutex_trylock' >
    >>> D:/msys64/usr/lib/../lib/libpthread.a(t-d001095.o):fake:(.text+0x2):
    >>> > undefined reference to `__imp_pthread_mutex_unlock' >
    >>> collect2.exe: error: ld returned 1 exit status >
    >>> make[1]: *** [Makefile:134: sblat1] Error 1 > make[1]:
    >>> Leaving directory >
    >>> '/home/erinm/OPB_HOME/xianyi-OpenBLAS-eebc189/test' >
    >>> make: *** [Makefile:124: tests] Error 2
    >>> >
    >>> >
    >>> > I think it has something to do with the
    >>> threads/pthreads but am not sure > how to fix it.  Any
    >>> suggestions much appreciated.
    >>> >
    >>> > Thanks, > Sincerely, > Erin
    >>> >
    >>> > Erin Hodgess, PhD > mailto: erinm.hodgess at gmail.com
    >>> >
    >>> > [[alternative HTML version deleted]]
    >>> >
    >>> > ______________________________________________ >
    >>> R-devel at r-project.org mailing list >
    >>> https://stat.ethz.ch/mailman/listinfo/r-devel
    >>> >
    >>> 
    >>> [[alternative HTML version deleted]]
    >>> 
    >>> ______________________________________________
    >>> R-devel at r-project.org mailing list
    >>> https://stat.ethz.ch/mailman/listinfo/r-devel
    >>> 
    >> --
    >> Sent from Gmail Mobile
    >> 

    > 	[[alternative HTML version deleted]]

    > ______________________________________________
    > R-devel at r-project.org mailing list
    > https://stat.ethz.ch/mailman/listinfo/r-devel


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Mon Mar  4 10:59:46 2019
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Mon, 4 Mar 2019 10:59:46 +0100
Subject: [Rd] stopifnot
In-Reply-To: <599003614.8032805.1551515303841@mail.yahoo.com>
References: <599003614.8032805.1551515303841.ref@mail.yahoo.com>
 <599003614.8032805.1551515303841@mail.yahoo.com>
Message-ID: <23676.63250.565531.226864@stat.math.ethz.ch>

>>>>> Suharto Anggono Suharto Anggono via R-devel 
>>>>>     on Sat, 2 Mar 2019 08:28:23 +0000 writes:
>>>>> Suharto Anggono Suharto Anggono via R-devel 
>>>>>     on Sat, 2 Mar 2019 08:28:23 +0000 writes:

    > A private reply by Martin made me realize that I was wrong about
    > stopifnot(exprs=TRUE) .
    > It actually works fine. I apologize. What I tried and was failed was

    > stopifnot(exprs=T) .
    > Error in exprs[[1]] : object of type 'symbol' is not subsettable

indeed! .. and your patch below does address that, too.

    > The shortcut
    > assert <- function(exprs) stopifnot(exprs = exprs)
    > mentioned in "Warning" section of the documentation similarly fails when called, for example
    > assert({})

    > About shortcut, a definition that rather works:
    > assert <- function(exprs) eval.parent(substitute(stopifnot(exprs = exprs)))

Interesting... thank you for the suggestion!  I plan to add it
to the help page and then use it a bit .. before considering more.

    > Looking at https://stat.ethz.ch/pipermail/r-devel/2017-May/074227.html , using sys.parent() may be not good. For example, in
    > f <- function() stopifnot(exprs={FALSE}, local=FALSE); f()

I'm glad you found this too.. I did have "uneasy feelings" about
using sys.parent(2) to find the correct call ..  and I'm still
not 100% sure about the smart computation of 'n' for
sys.call(n-1) ... but I agree we should move in that direction
as it is so much faster than using withCallingHandlers() + tryCatch()
for all the expressions.

In my tests your revised patch (including the simplificationn
you sent 4 hours later) seems good and indeed does have very
good timing in simple experiments.

It will lead to some error messages being changed,
but in the examples I've seen,  the few changes were acceptable
(sometimes slightly less helpful, sometimes easier to read).

Martin

    > A revised patch (also with simpler 'cl'):
    > --- stop.R	2019-02-27 16:15:45.324167577 +0000
    > +++ stop_new.R	2019-03-02 06:21:35.919471080 +0000
    > @@ -1,7 +1,7 @@
    > #  File src/library/base/R/stop.R
    > #  Part of the R package, https://www.R-project.org
    > #
    > -#  Copyright (C) 1995-2018 The R Core Team
    > +#  Copyright (C) 1995-2019 The R Core Team
    > #
    > #  This program is free software; you can redistribute it and/or modify
    > #  it under the terms of the GNU General Public License as published by
    > @@ -33,25 +33,28 @@
 
    > stopifnot <- function(..., exprs, local = TRUE)
    > {
    > +    n <- ...length()
    > missE <- missing(exprs)
    > -    cl <-
    > if(missE) {  ## use '...' instead of exprs
    > -	    match.call(expand.dots=FALSE)$...
    > } else {
    > -	    if(...length())
    > +	    if(n)
    > stop("Must use 'exprs' or unnamed expressions, but not both")
    > envir <- if (isTRUE(local)) parent.frame()
    > else if(isFALSE(local)) .GlobalEnv
    > else if (is.environment(local)) local
    > else stop("'local' must be TRUE, FALSE or an environment")
    > exprs <- substitute(exprs) # protect from evaluation
    > -	    E1 <- exprs[[1]]
    > +	    E1 <- if(is.call(exprs)) exprs[[1]]
    > +	    cl <-
    > if(identical(quote(`{`), E1)) # { ... }
    > -		do.call(expression, as.list(exprs[-1]))
    > +		exprs
    > else if(identical(quote(expression), E1))
    > -		eval(exprs, envir=envir)
    > +		exprs
    > else
    > -		as.expression(exprs) # or fail ..
    > +		call("expression", exprs) # or fail ..
    > +	    if(!is.null(names(cl))) names(cl) <- NULL
    > +	    cl[[1]] <- sys.call()[[1]]
    > +	    return(eval(cl, envir=envir))
    > }
    > Dparse <- function(call, cutoff = 60L) {
    > ch <- deparse(call, width.cutoff = cutoff)
    > @@ -62,14 +65,10 @@
    > abbrev <- function(ae, n = 3L)
    > paste(c(head(ae, n), if(length(ae) > n) "...."), collapse="\n  ")
    > ##
    > -    for (i in seq_along(cl)) {
    > -	cl.i <- cl[[i]]
    > -	## r <- eval(cl.i, ..)   # with correct warn/err messages:
    > -	r <- withCallingHandlers(
    > -		tryCatch(if(missE) ...elt(i) else eval(cl.i, envir=envir),
    > -			 error = function(e) { e$call <- cl.i; stop(e) }),
    > -		warning = function(w) { w$call <- cl.i; w })
    > +    for (i in seq_len(n)) {
    > +	r <- ...elt(i)
    > if (!(is.logical(r) && !anyNA(r) && all(r))) {
    > +	    cl.i <- match.call(expand.dots=FALSE)$...[[i]]
    > msg <- ## special case for decently written 'all.equal(*)':
    > if(is.call(cl.i) && identical(cl.i[[1]], quote(all.equal)) &&
    > (is.null(ni <- names(cl.i)) || length(cl.i) == 3L ||
    > @@ -84,7 +83,12 @@
    > "%s are not all TRUE"),
    > Dparse(cl.i))
 
    > -	    stop(simpleError(msg, call = sys.call(-1)))
    > +	    n <- sys.nframe()
    > +	    if((p <- n-3) > 0 &&
    > +	       identical(sys.function(p), sys.function(n)) &&
    > +	       eval(expression(!missE), p)) # originally stopifnot(exprs=*)
    > +		n <- p
    > +	    stop(simpleError(msg, call = if(n > 1) sys.call(n-1)))
    > }
    > }
    > invisible()

    > --------------------------------------------
    > On Fri, 1/3/19, Martin Maechler <maechler at stat.math.ethz.ch> wrote:

    > Subject: Re: [Rd] stopifnot

    > Cc: "Martin Maechler" <maechler at stat.math.ethz.ch>, r-devel at r-project.org
    > Date: Friday, 1 March, 2019, 6:40 PM

>>>>> Suharto Anggono Suharto Anggono 
    >>>>>> ? ? on Wed, 27 Feb 2019 22:46:04 +0000 writes:

    > [...]

    > ? ? > Another thing: currently,
    > ? ? > stopifnot(exprs=TRUE)
    > ? ? > fails.

    > good catch - indeed!

    > I've started to carefully test and try the interesting nice
    > patch you've provided below.

    > [...]

    > Martin


    > ? ? > A patch:
    > ? ? > --- stop.R? ? 2019-02-27 16:15:45.324167577 +0000
    > ? ? > +++ stop_new.R? ? 2019-02-27 16:22:15.936203541 +0000
    > ? ? > @@ -1,7 +1,7 @@
    > ? ? > #? File src/library/base/R/stop.R
    > ? ? > #? Part of the R package, https://www.R-project.org
    > ? ? > #
    > ? ? > -#? Copyright (C) 1995-2018 The R Core Team
    > ? ? > +#? Copyright (C) 1995-2019 The R Core Team
    > ? ? > #
    > ? ? > #? This program is free software; you can redistribute it and/or modify
    > ? ? > #? it under the terms of the GNU General Public License as published by
    > ? ? > @@ -33,25 +33,27 @@

    > ? ? > stopifnot <- function(..., exprs, local = TRUE)
    > ? ? > {
    > ? ? > +? ? n <- ...length()
    > ? ? > missE <- missing(exprs)
    > ? ? > -? ? cl <-
    > ? ? > if(missE) {? ## use '...' instead of exprs
    > ? ? > -? ? ? ? match.call(expand.dots=FALSE)$...
    > ? ? > } else {
    > ? ? > -? ? ? ? if(...length())
    > ? ? > +? ? ? ? if(n)
    > ? ? > stop("Must use 'exprs' or unnamed expressions, but not both")
    > ? ? > envir <- if (isTRUE(local)) parent.frame()
    > ? ? > else if(isFALSE(local)) .GlobalEnv
    > ? ? > else if (is.environment(local)) local
    > ? ? > else stop("'local' must be TRUE, FALSE or an environment")
    > ? ? > exprs <- substitute(exprs) # protect from evaluation
    > ? ? > -? ? ? ? E1 <- exprs[[1]]
    > ? ? > +? ? ? ? E1 <- if(is.call(exprs)) exprs[[1]]
    > ? ? > +? ? ? ? cl <-
    > ? ? > if(identical(quote(`{`), E1)) # { ... }
    > ? ? > -? ? ? ? do.call(expression, as.list(exprs[-1]))
    > ? ? > +? ? ? ? exprs[-1]
    > ? ? > else if(identical(quote(expression), E1))
    > ? ? > eval(exprs, envir=envir)
    > ? ? > else
    > ? ? > as.expression(exprs) # or fail ..
    > ? ? > +? ? ? ? if(!is.null(names(cl))) names(cl) <- NULL
    > ? ? > +? ? ? ? return(eval(as.call(c(sys.call()[[1]], as.list(cl))), envir=envir))
    > ? ? > }
    > ? ? > Dparse <- function(call, cutoff = 60L) {
    > ? ? > ch <- deparse(call, width.cutoff = cutoff)
    > ? ? > @@ -62,14 +64,10 @@
    > ? ? > abbrev <- function(ae, n = 3L)
    > ? ? > paste(c(head(ae, n), if(length(ae) > n) "...."), collapse="\n? ")
    > ? ? > ##
    > ? ? > -? ? for (i in seq_along(cl)) {
    > ? ? > -? ? cl.i <- cl[[i]]
    > ? ? > -? ? ## r <- eval(cl.i, ..)? # with correct warn/err messages:
    > ? ? > -? ? r <- withCallingHandlers(
    > ? ? > -? ? ? ? tryCatch(if(missE) ...elt(i) else eval(cl.i, envir=envir),
    > ? ? > -? ? ? ? ? ? error = function(e) { e$call <- cl.i; stop(e) }),
    > ? ? > -? ? ? ? warning = function(w) { w$call <- cl.i; w })
    > ? ? > +? ? for (i in seq_len(n)) {
    > ? ? > +? ? r <- ...elt(i)
    > ? ? > if (!(is.logical(r) && !anyNA(r) && all(r))) {
    > ? ? > +? ? ? ? cl.i <- match.call(expand.dots=FALSE)$...[[i]]
    > ? ? > msg <- ## special case for decently written 'all.equal(*)':
    > ? ? > if(is.call(cl.i) && identical(cl.i[[1]], quote(all.equal)) &&
    > ? ? > (is.null(ni <- names(cl.i)) || length(cl.i) == 3L ||
    > ? ? > @@ -84,7 +82,11 @@
    > ? ? > "%s are not all TRUE"),
    > ? ? > Dparse(cl.i))

    > ? ? > -? ? ? ? stop(simpleError(msg, call = sys.call(-1)))
    > ? ? > +? ? ? ? p <- sys.parent()
    > ? ? > +? ? ? ? if(p && identical(sys.function(p), stopifnot) &&
    > ? ? > +? ? ? ? ? !eval(expression(missE), p)) # originally stopifnot(exprs=*)
    > ? ? > +? ? ? ? p <- sys.parent(2)
    > ? ? > +? ? ? ? stop(simpleError(msg, call = if(p) sys.call(p)))
    > ? ? > }
    > ? ? > }
    > ? ? > invisible()

    > ______________________________________________
    > R-devel at r-project.org mailing list
    > https://stat.ethz.ch/mailman/listinfo/r-devel


From er|nm@hodge@@ @end|ng |rom gm@||@com  Mon Mar  4 11:03:03 2019
From: er|nm@hodge@@ @end|ng |rom gm@||@com (Erin Hodgess)
Date: Mon, 4 Mar 2019 03:03:03 -0700
Subject: [Rd] Problem with compiling OpenBLAS to work with R
In-Reply-To: <23676.60035.254296.166127@stat.math.ethz.ch>
References: <CACxE24kZSEVgfah=fGXqx0jzrGoc6RBwUSgBWTMgoyi4q0z84A@mail.gmail.com>
 <CAPekMCkox-bmcVjZbn2uNE5AipWkbdVg7-C=QddEhDhNUU830w@mail.gmail.com>
 <CAL6gwn+hEg8BJBFOuksEQyvQXknzdFpTpHmTZ080wrAeoWA-Hw@mail.gmail.com>
 <CACxE24=hVLA8gUucL=d09SV7eY-E7s6RH6AeTKFjdddNYU70pw@mail.gmail.com>
 <23676.60035.254296.166127@stat.math.ethz.ch>
Message-ID: <CACxE24ndEWQyMAaztNFR8mnOp-=p9a_3510r_j27em3i_qFOAg@mail.gmail.com>

I actually figured it out.  I went back in any changed the mean difference
from 2-e12 to 5e-12.

Thanks,
Erin

Erin Hodgess, PhD
mailto: erinm.hodgess at gmail.com


On Mon, Mar 4, 2019 at 2:10 AM Martin Maechler <maechler at stat.math.ethz.ch>
wrote:

> >>>>> Erin Hodgess
> >>>>>     on Fri, 1 Mar 2019 12:30:35 -0700 writes:
>
>     > Yay!  I re-installed everything and got through "Make
>     > distribution"!  I have one more question, please: I am
>     > running the make check-all.  I have an error at reg-1d.
>     > It stops the process.  However, the mean difference (as
>     > per the file) is 2.0e-12.  I'm ok with that.  How do I
>     > bypass this, please?
>
> If you'd be really precise in your report (use correct file
> names; show the exact error message + context lines of the *.Rout.fail
> file) I could help you.
>
> Note (by the way) that this may be yet another example showing
> that OpenBLAS may be faster but less accurate than the
> (plain+ minor tweaks) version of BLAS that ships with R.
>
> Martin
>
>     > Thanks, Erin
>
>     > Erin Hodgess, PhD mailto: erinm.hodgess at gmail.com
>
>
>     > On Wed, Feb 27, 2019 at 10:22 PM Avraham Adler
>     > <avraham.adler at gmail.com> wrote:
>
>     >> I believe that repo just follows the directions on my
>     >> blog. Without seeing Dr. Hodges?s code, my initial
>     >> concern is the many references to Cygwin. My method
>     >> specifically does not use Cygwin but MSYS2 and
>     >> Mingw64/Rtools35.  That will likely change to solely
>     >> Rtools40 once R3.6 is released due to the Msys system
>     >> being built in to it.
>     >>
>     >> There may be some library conflicts between Cygwin and
>     >> msys2/mingw64. If possible, my suggestion would be
>     >> uninstall everything and then just install msys2 (and add
>     >> in make after you to the first msys update) and rtools35.
>     >> Then there should be no conflicting libraries.
>     >>
>     >> Thanks,
>     >>
>     >> Avi
>     >>
>     >> On Thu, Feb 28, 2019 at 12:11 AM Kenny Bell
>     >> <kmbell56 at gmail.com> wrote:
>     >>
>     >>> This person has had apparent success - you could follow
>     >>> what they did or just download their product (with
>     >>> appropriate caution downloading a random .exe).
>     >>>
>     >>> https://github.com/thequackdaddy/R-OpenBLAS
>     >>>
>     >>> On Thu, Feb 28, 2019 at 6:28 AM Erin Hodgess
>     >>> <erinm.hodgess at gmail.com> wrote:
>     >>>
>     >>> > Hello!
>     >>> >
>     >>> > I'm not sure if this is the right place to post this,
>     >>> so apologies > in advance if I'm not in the right list.
>     >>> >
>     >>> > I downloaded the OpenBLAS and am following Avraham
>     >>> Adler's great > instructions.  However, when I run make,
>     >>> things go well to a certain point, > and then go bad:
>     >>> >
>     >>> > make > [snip]
>     >>> >
>     >>> > touch cygopenblas_haswellp-r0.3.5.a > make -j 1 -C
>     >>> test all > make[1]: Entering directory >
>     >>> '/home/erinm/OPB_HOME/xianyi-OpenBLAS-eebc189/test' >
>     >>> gfortran -O2 -Wall -frecursive -m64 -mavx2 -o sblat1
>     >>> sblat1.o > ../cygopenblas_haswellp-r0.3.5.a
>     >>> -L/usr/lib/gcc/x86_64-pc-msys/7.3.0
>     >>> >
>     >>>
> -L/usr/lib/gcc/x86_64-pc-msys/7.3.0/../../../../x86_64-pc-msys/lib/../lib
>     >>> > -L/usr/lib/../lib >
>     >>> -L/usr/lib/gcc/x86_64-pc-msys/7.3.0/../../../../x86_64-pc-msys/lib
>     >>> > -L/usr/lib/w32api -lmsys-2.0 >
>     >>>
> D:/msys64/usr/lib/../lib/libpthread.a(t-d001088.o):fake:(.text+0x2):
>     >>> > undefined reference to `__imp_pthread_mutex_destroy' >
>     >>>
> D:/msys64/usr/lib/../lib/libpthread.a(t-d001090.o):fake:(.text+0x2):
>     >>> > undefined reference to `__imp_pthread_mutex_init' >
>     >>>
> D:/msys64/usr/lib/../lib/libpthread.a(t-d001091.o):fake:(.text+0x2):
>     >>> > undefined reference to `__imp_pthread_mutex_lock' >
>     >>>
> D:/msys64/usr/lib/../lib/libpthread.a(t-d001094.o):fake:(.text+0x2):
>     >>> > undefined reference to `__imp_pthread_mutex_trylock' >
>     >>>
> D:/msys64/usr/lib/../lib/libpthread.a(t-d001095.o):fake:(.text+0x2):
>     >>> > undefined reference to `__imp_pthread_mutex_unlock' >
>     >>> collect2.exe: error: ld returned 1 exit status >
>     >>> make[1]: *** [Makefile:134: sblat1] Error 1 > make[1]:
>     >>> Leaving directory >
>     >>> '/home/erinm/OPB_HOME/xianyi-OpenBLAS-eebc189/test' >
>     >>> make: *** [Makefile:124: tests] Error 2
>     >>> >
>     >>> >
>     >>> > I think it has something to do with the
>     >>> threads/pthreads but am not sure > how to fix it.  Any
>     >>> suggestions much appreciated.
>     >>> >
>     >>> > Thanks, > Sincerely, > Erin
>     >>> >
>     >>> > Erin Hodgess, PhD > mailto: erinm.hodgess at gmail.com
>     >>> >
>     >>> > [[alternative HTML version deleted]]
>     >>> >
>     >>> > ______________________________________________ >
>     >>> R-devel at r-project.org mailing list >
>     >>> https://stat.ethz.ch/mailman/listinfo/r-devel
>     >>> >
>     >>>
>     >>> [[alternative HTML version deleted]]
>     >>>
>     >>> ______________________________________________
>     >>> R-devel at r-project.org mailing list
>     >>> https://stat.ethz.ch/mailman/listinfo/r-devel
>     >>>
>     >> --
>     >> Sent from Gmail Mobile
>     >>
>
>     >   [[alternative HTML version deleted]]
>
>     > ______________________________________________
>     > R-devel at r-project.org mailing list
>     > https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From j@me@@|@he@ter @end|ng |rom gm@||@com  Mon Mar  4 13:59:57 2019
From: j@me@@|@he@ter @end|ng |rom gm@||@com (Jim Hester)
Date: Mon, 4 Mar 2019 07:59:57 -0500
Subject: [Rd] Package inclusion in R core implementation
In-Reply-To: <CAL0QV_Pgbif3=Hf1sw-O7Fy685N9upyYPyUK7c7FhgUd6yLMjg@mail.gmail.com>
References: <CAL0QV_MRORtsqzXbbY69-v2CUEy8Nmd6gk3VJPBvSt=sa=v8uQ@mail.gmail.com>
 <CAL0QV_Pgbif3=Hf1sw-O7Fy685N9upyYPyUK7c7FhgUd6yLMjg@mail.gmail.com>
Message-ID: <CAD6tx95tn82NE=TFAoaOyYxV1_QBgBSfLzNSWMa+nrL77C23gQ@mail.gmail.com>

Conversely, what is the process to remove a package from core R? It seems
to me some (many?) of the packages included are there more out of
historical accident rather than any technical need to be in the core
distribution. Having them as a core (or recommended) package makes them
harder update independently to R and makes testing, development and
contribution more cumbersome.

On Fri, Mar 1, 2019 at 4:35 AM Morgan Morgan <morgan.emailbox at gmail.com>
wrote:

> Hi,
>
> It sometimes happens that some packages get included to R like for example
> the parallel package.
>
> I was wondering if there is a process to decide whether or not to include a
> package in the core implementation of R?
>
> For example, why not include the Rcpp package, which became for a lot of
> user the main tool to extend R?
>
> What is our view on the (not so well known) dotCall64 package which is an
> interesting alternative for extending R?
>
> Thank you
> Best regards,
> Morgan
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From pro|jcn@@h @end|ng |rom gm@||@com  Mon Mar  4 15:01:26 2019
From: pro|jcn@@h @end|ng |rom gm@||@com (J C Nash)
Date: Mon, 4 Mar 2019 09:01:26 -0500
Subject: [Rd] Package inclusion in R core implementation
In-Reply-To: <CAD6tx95tn82NE=TFAoaOyYxV1_QBgBSfLzNSWMa+nrL77C23gQ@mail.gmail.com>
References: <CAL0QV_MRORtsqzXbbY69-v2CUEy8Nmd6gk3VJPBvSt=sa=v8uQ@mail.gmail.com>
 <CAL0QV_Pgbif3=Hf1sw-O7Fy685N9upyYPyUK7c7FhgUd6yLMjg@mail.gmail.com>
 <CAD6tx95tn82NE=TFAoaOyYxV1_QBgBSfLzNSWMa+nrL77C23gQ@mail.gmail.com>
Message-ID: <7eebb4c5-71d9-503e-c107-fafdc4eb601b@gmail.com>

As the original coder (in mid 1970s) of BFGS, CG and Nelder-Mead in optim(), I've
been pushing for some time for their deprecation. They aren't "bad", but we have
better tools, and they are in CRAN packages. Similarly, I believe other optimization
tools in the core (optim::L-BFGS-B, nlm, nlminb) can and should be moved to
packages (there are already 2 versions at least of LBFGS that I and Matt Fidler
are merging). And optim::SANN does not match any usual expectations of users.

I'm sure there are other tools for other tasks that can and should move to packages
to streamline the work of our core team. However, I can understand that there is this
awkward issue of actually doing this. I know I'm willing to help with preparing
"Transition Guide" documentation and scripts, and would be surprised if there are
not others. R already has a policy of full support only for current version, so
hanging on to antique tools (the three codes at the top are based on papers all
of which now qualify for >50 years old) seems inconsistent with other messages.

For information: I'm coordinating a project to build understanding of what
older algorithms are in R as the histoRicalg project. See
https://gitlab.com/nashjc/histoRicalg. We welcome participation.

Best, JN

On 2019-03-04 7:59 a.m., Jim Hester wrote:
> Conversely, what is the process to remove a package from core R? It seems
> to me some (many?) of the packages included are there more out of
> historical accident rather than any technical need to be in the core
> distribution. Having them as a core (or recommended) package makes them
> harder update independently to R and makes testing, development and
> contribution more cumbersome.
> 
> On Fri, Mar 1, 2019 at 4:35 AM Morgan Morgan <morgan.emailbox at gmail.com>
> wrote:
> 
>> Hi,
>>
>> It sometimes happens that some packages get included to R like for example
>> the parallel package.
>>
>> I was wondering if there is a process to decide whether or not to include a
>> package in the core implementation of R?
>>
>> For example, why not include the Rcpp package, which became for a lot of
>> user the main tool to extend R?
>>
>> What is our view on the (not so well known) dotCall64 package which is an
>> interesting alternative for extending R?
>>
>> Thank you
>> Best regards,
>> Morgan
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From @vr@h@m@@d|er @end|ng |rom gm@||@com  Mon Mar  4 15:12:34 2019
From: @vr@h@m@@d|er @end|ng |rom gm@||@com (Avraham Adler)
Date: Mon, 4 Mar 2019 17:12:34 +0300
Subject: [Rd] Package inclusion in R core implementation
In-Reply-To: <7eebb4c5-71d9-503e-c107-fafdc4eb601b@gmail.com>
References: <CAL0QV_MRORtsqzXbbY69-v2CUEy8Nmd6gk3VJPBvSt=sa=v8uQ@mail.gmail.com>
 <CAL0QV_Pgbif3=Hf1sw-O7Fy685N9upyYPyUK7c7FhgUd6yLMjg@mail.gmail.com>
 <CAD6tx95tn82NE=TFAoaOyYxV1_QBgBSfLzNSWMa+nrL77C23gQ@mail.gmail.com>
 <7eebb4c5-71d9-503e-c107-fafdc4eb601b@gmail.com>
Message-ID: <CAL6gwnLkxsNoh098+-Y6qEEup6xcvFv1+LNsA6Hr+5BSijKifA@mail.gmail.com>

On Mon, Mar 4, 2019 at 5:01 PM J C Nash <profjcnash at gmail.com> wrote:

> As the original coder (in mid 1970s) of BFGS, CG and Nelder-Mead in
> optim(), I've
> been pushing for some time for their deprecation. They aren't "bad", but
> we have
> better tools, and they are in CRAN packages. Similarly, I believe other
> optimization
> tools in the core (optim::L-BFGS-B, nlm, nlminb) can and should be moved to
> packages (there are already 2 versions at least of LBFGS that I and Matt
> Fidler
> are merging). And optim::SANN does not match any usual expectations of
> users.
>
> I'm sure there are other tools for other tasks that can and should move to
> packages
> to streamline the work of our core team. However, I can understand that
> there is this
> awkward issue of actually doing this. I know I'm willing to help with
> preparing
> "Transition Guide" documentation and scripts, and would be surprised if
> there are
> not others. R already has a policy of full support only for current
> version, so
> hanging on to antique tools (the three codes at the top are based on
> papers all
> of which now qualify for >50 years old) seems inconsistent with other
> messages.
>
> For information: I'm coordinating a project to build understanding of what
> older algorithms are in R as the histoRicalg project. See
> https://gitlab.com/nashjc/histoRicalg. We welcome participation.
>
> Best, JN
>
> On 2019-03-04 7:59 a.m., Jim Hester wrote:
> > Conversely, what is the process to remove a package from core R? It seems
> > to me some (many?) of the packages included are there more out of
> > historical accident rather than any technical need to be in the core
> > distribution. Having them as a core (or recommended) package makes them
> > harder update independently to R and makes testing, development and
> > contribution more cumbersome.
> >
> > On Fri, Mar 1, 2019 at 4:35 AM Morgan Morgan <morgan.emailbox at gmail.com>
> > wrote:
> >
> >> Hi,
> >>
> >> It sometimes happens that some packages get included to R like for
> example
> >> the parallel package.
> >>
> >> I was wondering if there is a process to decide whether or not to
> include a
> >> package in the core implementation of R?
> >>
> >> For example, why not include the Rcpp package, which became for a lot of
> >> user the main tool to extend R?
> >>
> >> What is our view on the (not so well known) dotCall64 package which is
> an
> >> interesting alternative for extending R?
> >>
> >> Thank you
> >> Best regards,
> >> Morgan
> >>
>

I have No arguments with updating code to more correct or modern versions,
but I think that as a design decision, base R should have optimization
routines as opposed to it being an external package which conceptually
could be orphaned. Or at least some package gets made recommended and
adopted by R core.

Thank you,

Avi
-- 
Sent from Gmail Mobile

	[[alternative HTML version deleted]]


From pro|jcn@@h @end|ng |rom gm@||@com  Mon Mar  4 15:20:16 2019
From: pro|jcn@@h @end|ng |rom gm@||@com (J C Nash)
Date: Mon, 4 Mar 2019 09:20:16 -0500
Subject: [Rd] Package inclusion in R core implementation
In-Reply-To: <CAL6gwnLkxsNoh098+-Y6qEEup6xcvFv1+LNsA6Hr+5BSijKifA@mail.gmail.com>
References: <CAL0QV_MRORtsqzXbbY69-v2CUEy8Nmd6gk3VJPBvSt=sa=v8uQ@mail.gmail.com>
 <CAL0QV_Pgbif3=Hf1sw-O7Fy685N9upyYPyUK7c7FhgUd6yLMjg@mail.gmail.com>
 <CAD6tx95tn82NE=TFAoaOyYxV1_QBgBSfLzNSWMa+nrL77C23gQ@mail.gmail.com>
 <7eebb4c5-71d9-503e-c107-fafdc4eb601b@gmail.com>
 <CAL6gwnLkxsNoh098+-Y6qEEup6xcvFv1+LNsA6Hr+5BSijKifA@mail.gmail.com>
Message-ID: <c1a724ba-27b4-d00f-9335-972bc600c2b0@gmail.com>

I concur with Avraham that capabilities need to be ensured e.g., in recommended
packages. I should have mentioned that. My concern is that the core should be
focused on the programming language aspects. The computational math and some of the more
intricate data management could better be handled by folk outside the core.

JN

On 2019-03-04 9:12 a.m., Avraham Adler wrote:
> On Mon, Mar 4, 2019 at 5:01 PM J C Nash <profjcnash at gmail.com <mailto:profjcnash at gmail.com>> wrote:
> 
>     As the original coder (in mid 1970s) of BFGS, CG and Nelder-Mead in optim(), I've
>     been pushing for some time for their deprecation. They aren't "bad", but we have
>     better tools, and they are in CRAN packages. Similarly, I believe other optimization
>     tools in the core (optim::L-BFGS-B, nlm, nlminb) can and should be moved to
>     packages (there are already 2 versions at least of LBFGS that I and Matt Fidler
>     are merging). And optim::SANN does not match any usual expectations of users.
> 
>     I'm sure there are other tools for other tasks that can and should move to packages
>     to streamline the work of our core team. However, I can understand that there is this
>     awkward issue of actually doing this. I know I'm willing to help with preparing
>     "Transition Guide" documentation and scripts, and would be surprised if there are
>     not others. R already has a policy of full support only for current version, so
>     hanging on to antique tools (the three codes at the top are based on papers all
>     of which now qualify for >50 years old) seems inconsistent with other messages.
> 
>     For information: I'm coordinating a project to build understanding of what
>     older algorithms are in R as the histoRicalg project. See
>     https://gitlab.com/nashjc/histoRicalg. We welcome participation.
> 
>     Best, JN
> 
>     On 2019-03-04 7:59 a.m., Jim Hester wrote:
>     > Conversely, what is the process to remove a package from core R? It seems
>     > to me some (many?) of the packages included are there more out of
>     > historical accident rather than any technical need to be in the core
>     > distribution. Having them as a core (or recommended) package makes them
>     > harder update independently to R and makes testing, development and
>     > contribution more cumbersome.
>     >
>     > On Fri, Mar 1, 2019 at 4:35 AM Morgan Morgan <morgan.emailbox at gmail.com <mailto:morgan.emailbox at gmail.com>>
>     > wrote:
>     >
>     >> Hi,
>     >>
>     >> It sometimes happens that some packages get included to R like for example
>     >> the parallel package.
>     >>
>     >> I was wondering if there is a process to decide whether or not to include a
>     >> package in the core implementation of R?
>     >>
>     >> For example, why not include the Rcpp package, which became for a lot of
>     >> user the main tool to extend R?
>     >>
>     >> What is our view on the (not so well known) dotCall64 package which is an
>     >> interesting alternative for extending R?
>     >>
>     >> Thank you
>     >> Best regards,
>     >> Morgan
>     >>
> 
> 
> I have No arguments with updating code to more correct or modern versions, but I think that as a design decision, base R
> should have optimization routines as opposed to it being an external package which conceptually could be orphaned. Or at
> least some package gets made recommended and adopted by R core.
> 
> Thank you,
> 
> Avi
> -- 
> Sent from Gmail Mobile


From murdoch@dunc@n @end|ng |rom gm@||@com  Mon Mar  4 15:39:54 2019
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Mon, 4 Mar 2019 09:39:54 -0500
Subject: [Rd] Package inclusion in R core implementation
In-Reply-To: <CAD6tx95tn82NE=TFAoaOyYxV1_QBgBSfLzNSWMa+nrL77C23gQ@mail.gmail.com>
References: <CAL0QV_MRORtsqzXbbY69-v2CUEy8Nmd6gk3VJPBvSt=sa=v8uQ@mail.gmail.com>
 <CAL0QV_Pgbif3=Hf1sw-O7Fy685N9upyYPyUK7c7FhgUd6yLMjg@mail.gmail.com>
 <CAD6tx95tn82NE=TFAoaOyYxV1_QBgBSfLzNSWMa+nrL77C23gQ@mail.gmail.com>
Message-ID: <16897159-3db3-5255-7f17-4fb8f66ea4eb@gmail.com>

On 04/03/2019 7:59 a.m., Jim Hester wrote:
> Conversely, what is the process to remove a package from core R? It seems
> to me some (many?) of the packages included are there more out of
> historical accident rather than any technical need to be in the core
> distribution. Having them as a core (or recommended) package makes them
> harder update independently to R and makes testing, development and
> contribution more cumbersome.

You are conflating base and recommended packages.  Base packages can't 
be updated independently of R because they provide or make use of R 
internals, so they couldn't be distributed separately.  The list of base 
packages is

  [1] "base"      "compiler"  "datasets"  "graphics"  "grDevices" "grid" 
      "methods"   "parallel"  "splines"   "stats"     "stats4"
[12] "tcltk"     "tools"     "utils"

The other packages distributed with R are recommended packages:

  [1] "boot"       "class"      "cluster"    "codetools"  "foreign" 
"KernSmooth" "lattice"    "MASS"       "Matrix"     "mgcv"
[11] "nlme"       "nnet"       "rpart"      "spatial"    "survival"

Those ones have no particular connection to the internals, but they are 
distributed with R, and suffer through somewhat more rigorous testing 
than most contributed packages.  Some of them are used in R's own tests. 
  They can be updated at any time, but their authors are asked not to 
update them near R releases.  In many cases (but not all) their current 
maintainers are R Core members.

In answer to your question and Morgan's:  the process is completely 
opaque.  R Core will add or remove a package if they think it makes 
sense from their point of view.  Generally that happens very rarely, 
because it can be a lot of work, and usually there's not much to be gained.


> 
> On Fri, Mar 1, 2019 at 4:35 AM Morgan Morgan <morgan.emailbox at gmail.com>
> wrote:
> 
>> Hi,
>>
>> It sometimes happens that some packages get included to R like for example
>> the parallel package.
>>
>> I was wondering if there is a process to decide whether or not to include a
>> package in the core implementation of R?
>>
>> For example, why not include the Rcpp package, which became for a lot of
>> user the main tool to extend R?
>>
>> What is our view on the (not so well known) dotCall64 package which is an
>> interesting alternative for extending R?
>>
>> Thank you
>> Best regards,
>> Morgan
>>
>>          [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From c@@rd|@g@bor @end|ng |rom gm@||@com  Mon Mar  4 16:19:49 2019
From: c@@rd|@g@bor @end|ng |rom gm@||@com (=?UTF-8?B?R8OhYm9yIENzw6FyZGk=?=)
Date: Mon, 4 Mar 2019 15:19:49 +0000
Subject: [Rd] R CMD build installing the package to process help pages
Message-ID: <CABtg=K=FNbVtgZ0pYp9ddhuGsf0z0D=Y92oiCMg=zNmEVFffcg@mail.gmail.com>

Dear All,

If a package has dynamic manual pages (i.e. `\Sexpr{} macros), then R
CMD build installs the package, and (by default) creates the PDF
manual.

I understand that this is needed for build-time Sexprs. Could anyone
explain me why `R CMD  build` needs to install the package if all the
Sexprs are install-time and/or render-time? I must be missing
something here.

Thanks much,
Gabor


From pro|jcn@@h @end|ng |rom gm@||@com  Mon Mar  4 17:20:05 2019
From: pro|jcn@@h @end|ng |rom gm@||@com (J C Nash)
Date: Mon, 4 Mar 2019 11:20:05 -0500
Subject: [Rd] Fwd:  Package inclusion in R core implementation
In-Reply-To: <c1a724ba-27b4-d00f-9335-972bc600c2b0@gmail.com>
References: <c1a724ba-27b4-d00f-9335-972bc600c2b0@gmail.com>
Message-ID: <fc3e48c9-db7f-117b-8839-880fddda6753@gmail.com>

Rereading my post below, I realize scope for misinterpretation. As I have said earlier,
I recognize the workload in doing any streamlining, and also the immense service to us
all by r-core. The issue is how to manage the workload efficiently while maintaining
and modernizing the capability. That is likely as challenging as doing the work itself.

JN


> I concur with Avraham that capabilities need to be ensured e.g., in recommended
> packages. I should have mentioned that. My concern is that the core should be
> focused on the programming language aspects. The computational math and some of the more
> intricate data management could better be handled by folk outside the core.
> 
> JN
>


From @purd|e@@ @end|ng |rom gm@||@com  Tue Mar  5 00:28:05 2019
From: @purd|e@@ @end|ng |rom gm@||@com (Abs Spurdle)
Date: Tue, 5 Mar 2019 12:28:05 +1300
Subject: [Rd] Should CRAN accept packages with non-R code that transcompiles
 into R code?
Message-ID: <CAB8pepx3d3faRfPTDo97ebOKA1f4v=GO6_dbL7QC2DtkqZV0=w@mail.gmail.com>

It may be possible to create an R-like programming language that
transcompiles into R code (or otherwise constructs R objects and calls
R functions).

I'm not sure whether it would pass R check or not, I will probably try...

But the bigger question is:
Should CRAN accept packages written in such a way?

I could email Kurt Hornik or Uwe Ligges, and ask them.
However, I thought that I would ask here first.


From g@bembecker @end|ng |rom gm@||@com  Tue Mar  5 00:52:24 2019
From: g@bembecker @end|ng |rom gm@||@com (Gabriel Becker)
Date: Mon, 4 Mar 2019 15:52:24 -0800
Subject: [Rd] 
 Should CRAN accept packages with non-R code that transcompiles
 into R code?
In-Reply-To: <CAB8pepx3d3faRfPTDo97ebOKA1f4v=GO6_dbL7QC2DtkqZV0=w@mail.gmail.com>
References: <CAB8pepx3d3faRfPTDo97ebOKA1f4v=GO6_dbL7QC2DtkqZV0=w@mail.gmail.com>
Message-ID: <CAD4oTHFhp1qUfFhLeCh_jBXBYH30mDjvFSeGhW5OBbnkC1t13g@mail.gmail.com>

Abs (?),

I have thought about and have (somewhere "up near the top" of my todo list)
prototyping a preprocessor for R, and I have relevant code that emits
(transpiles, in a way) structured comments into S4 code in
https://github.com/gmbecker/S4Coffee.

All that said, until/unless the preprocessor is officially part of the R
CMD build step, what putting code like that on CRAN would look like is you
keep the raw code in /inst somewhere, and you do the emitting of R code
into R/ before building the tarball for submitting. And if you do that CRAN
will hav eno problem accepting such a package provided it isn't disallowed
in some other way.

Best,
~G

On Mon, Mar 4, 2019 at 3:28 PM Abs Spurdle <spurdle.a at gmail.com> wrote:

> It may be possible to create an R-like programming language that
> transcompiles into R code (or otherwise constructs R objects and calls
> R functions).
>
> I'm not sure whether it would pass R check or not, I will probably try...
>
> But the bigger question is:
> Should CRAN accept packages written in such a way?
>
> I could email Kurt Hornik or Uwe Ligges, and ask them.
> However, I thought that I would ask here first.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From p@u| @end|ng |rom @t@t@@uck|@nd@@c@nz  Tue Mar  5 01:58:26 2019
From: p@u| @end|ng |rom @t@t@@uck|@nd@@c@nz (Paul Murrell)
Date: Tue, 5 Mar 2019 13:58:26 +1300
Subject: [Rd] 
 [FORGED] [R] R cairo_pdf function does not respect plotting
 boundaries
In-Reply-To: <CAO0anGmxEwS2VtAqT-i6701QrkFCL90cOneB+c_y3uJ_40aG9w@mail.gmail.com>
References: <CAO0anGmxEwS2VtAqT-i6701QrkFCL90cOneB+c_y3uJ_40aG9w@mail.gmail.com>
Message-ID: <581bf016-0b51-977b-200d-bbeef95f9046@stat.auckland.ac.nz>

Hi

(cc'ed to r-devel where further discussion should probably take place)

Thanks Lee.  I see that problem.

There is a "+ 1" in the Cairo device code for setting the clipping region
(https://github.com/wch/r-source/blob/ba600867f2a94e46cf9eb75dc8b37f12b08a4561/src/library/grDevices/src/cairo/cairoFns.c#L156) 


Remove the "+ 1" and the problem goes away (for your example at least).

The comment on the line above that code suggests that the "+ 1" was 
modelled on the X11 device code, but X11 deals in integer pixels and 
Cairo (at the API level) does not, so it would seem that the "+ 1" is 
just unnecessary.

However, I have a slight nagging worry that we have been here before, so 
I would like to do some more testing before committing that change.

Paul

On 1/03/19 8:13 AM, Lee Steven Kelvin wrote:
> Hello all,
> 
> When producing a plot in R using the cairo_pdf device, the resultant plot does not respect the plotting boundaries. Lines and shaded regions will spill over the lower x-axis and the right-side y-axis (sides 1 and 4). I would like to know if it is possible to fix this behaviour when using 'cairo_pdf' in R?
> 
> As an example, see the image at this web link: https://i.stack.imgur.com/0lfZd.png
> 
> This image is a screenshot of a PDF file constructed using the following minimum working example code:
> 
> cairo_pdf(file="test.pdf", width=0.5, height=0.5)
> par("mar"=c(0.25,0.25,0.25,0.25))
> plot(NA, xlim=c(0,1), ylim=c(0,1), axes=FALSE)
> polygon(x=c(-1,-1,2,2), y=c(-1,2,2,-1), density=5, col="green3", lwd=10)
> abline(h=0.25, col="red", lwd=5)
> abline(h=0.75, col="hotpink", lwd=5, lend=1)
> abline(v=0.25, col="blue", lwd=5)
> abline(v=0.75, col="cyan", lwd=5, lend=1)
> box()
> dev.off()
> 
> Here I'm plotting a shaded region in green using 'polygon', with boundaries that lie outside the plot. I'm also drawing two sets of horizontal/vertical lines using 'abline'. The first in each pair uses standard rounded line caps, whilst the second in each pair uses butt line caps.
> 
> As you can see, the shading lines and the default rounded-end ablines all extend beyond the plotting region along the lower and right-hand side axes. Only when using 'lend=1' am I able to contain the ablines to the plotting region. I know of no such fix for the shading lines however.
> 
> I would naively expect the R plotting region to be respected, and for it to be impossible to plot outside of this region unless explicitly specified by the user.
> 
> I have tested this on the other cairo devices (SVG and PS), and also reproduce the same behaviour, indicating that this is an issue with the cairo graphics API, or its implementation within R.
> 
> This behaviour does not occur when using the standard R 'pdf' graphics device. I would switch to 'pdf' in general, however, 'cairo_pdf' has several advantages over 'pdf', notably, reduced output file sizes on occasion and support for a larger array of UTF-8 characters, so ideally I would prefer to use cairo_pdf.
> 
> I should note that I have also posted this message on StackOverflow at this web link: https://stackoverflow.com/questions/54892809/r-cairo-pdf-function-does-not-respect-plotting-boundaries
> 
> Thank you in advance for any insights into this issue.
> 
> Sincerely,
> Lee Kelvin
> 
> 
> 
> --
> Dr Lee Kelvin
> Department of Physics
> UC Davis
> One Shields Avenue
> Davis, CA 95616
> USA
> 
> Ph: +1 (530) 752-1500
> Fax: +1 (530) 752-4717
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/


From berw|n@tur|@ch @end|ng |rom gm@||@com  Tue Mar  5 09:54:09 2019
From: berw|n@tur|@ch @end|ng |rom gm@||@com (Berwin A Turlach)
Date: Tue, 5 Mar 2019 16:54:09 +0800
Subject: [Rd] Development version of R fails tests and is not installed
Message-ID: <20190305165409.02d8d09f@ECM-DTC-716.uniwa.uwa.edu.au>

G'day all,

I have daily scripts running to install the patched version of the
current R version and the development version of R on my linux box
(Ubuntu 18.04.2 LTS).

The last development version that was successfully compiled and
installed was "R Under development (unstable) (2019-02-25 r76159)" on
26 February.  Since then the script always fails as a regression test
seems to fail.  Specifically, in the tests/ subdirectory of my build
directory I have a file reg-tests-1d.Rout.fail which ends with:

> ## checking ar.yw.default() multivariate case
> estd <- ar(unclass(y) , aic = FALSE, order.max = 2) ## Estimate VAR(2)
> es.d <- ar(unclass(y.), aic = FALSE, order.max = 2, na.action=na.pass)
> stopifnot(exprs = {
+     all.equal(est$ar[1,,], diag(0.8, 2), tol = 0.08)# seen 0.0038
+     all.equal(est[1:6], es.[1:6], tol = 5e-3)
+     all.equal(estd$x.mean, es.d$x.mean, tol = 0.01) # seen 0.0023
+     all.equal(estd[c(1:3,5:6)],
+               es.d[c(1:3,5:6)], tol = 1e-3)## seen {1,3,8}e-4
+     all.equal(lapply(estd[1:6],unname),
+               lapply(est [1:6],unname), tol = 2e-12)# almost identical
+     all.equal(lapply(es.d[1:6],unname),
+               lapply(es. [1:6],unname), tol = 2e-12)
+ })
Error: lapply(es.d[1:6], unname) and lapply(es.[1:6], unname) are not equal:
  Component "aic": Mean relative difference: 3.297178e-12
Execution halted

Would it be possible to make this tolerance more lenient?  In case it
matters, I am configuring R to be compiled using Openblas and this test
fails for the 64 bit installation, the 32 bit installation seems to
pass all tests.

Happy to provide any more information/context that might be needed.

Cheers,

	Berwin


From wo||g@ng@v|echtb@uer @end|ng |rom m@@@tr|chtun|ver@|ty@n|  Tue Mar  5 12:20:36 2019
From: wo||g@ng@v|echtb@uer @end|ng |rom m@@@tr|chtun|ver@|ty@n| (Viechtbauer, Wolfgang (SP))
Date: Tue, 5 Mar 2019 11:20:36 +0000
Subject: [Rd] Weird problem / bug with augPred() from nlme
Message-ID: <693cd31f6f384beda6457808a24063c0@UM-MAIL3214.unimaas.nl>

Posted this to r-sig-mixed-models (https://stat.ethz.ch/pipermail/r-sig-mixed-models/2019q1/027620.html) but this might rather need to go to r-devel anyway, so reposting here:

I came across a weird problem / bug with augPred() from nlme (nlme_3.1-137). Here is a reproducible example to illustrate the issue (tested on R 3.5.2 and R-devel 2019-03-03 r76192):

library(nlme)

dat <- data.frame(id = c(1,1,1,2,3,3,4,4,4,4),
                  xi = c(1,2,3,1,1,2,1,2,3,4),
                  yi = c(2,1,4,2,3,2,5,4,6,8),
                  zi = c(rep("a",9), NA))

res1 <- lme(yi ~ xi, random = ~ 1 | id, data=dat)
sav1 <- augPred(res1, primary = ~ xi) # WORKS

dat$zi <- "a"

res2 <- lme(yi ~ xi, random = ~ 1 | id, data=dat)
sav2 <- augPred(res2, primary = ~ xi) # WORKS

dat$zi[10] <- NA

res3 <- lme(yi ~ xi, random = ~ 1 | id, data=dat)
sav3 <- augPred(res3, primary = ~ xi) # ERROR

The error message:

Error in `[[<-.data.frame`(`*tmp*`, nm, value = c(1L, 1L, 1L, 2L, 3L,  : 
  replacement has 10 rows, data has 4

So, if 'zi' is a factor, then a missing value causes no problems (sav1). Or if 'zi' is a character variable without any missings, then augPred() also runs (sav2). But if 'zi' is a character variable and there is at least one missing value, then augPred() fails (sav3).

This aside, why does 'zi' even play a role here? It isn't used at all in the model fit.

Best,
Wolfgang


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Tue Mar  5 12:45:36 2019
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Tue, 5 Mar 2019 12:45:36 +0100
Subject: [Rd] Development version of R fails tests and is not installed
In-Reply-To: <20190305165409.02d8d09f@ECM-DTC-716.uniwa.uwa.edu.au>
References: <20190305165409.02d8d09f@ECM-DTC-716.uniwa.uwa.edu.au>
Message-ID: <23678.24928.267076.259252@stat.math.ethz.ch>

>>>>> Berwin A Turlach 
>>>>>     on Tue, 5 Mar 2019 16:54:09 +0800 writes:

    > G'day all,
    > I have daily scripts running to install the patched version of the
    > current R version and the development version of R on my linux box
    > (Ubuntu 18.04.2 LTS).

    > The last development version that was successfully compiled and
    > installed was "R Under development (unstable) (2019-02-25 r76159)" on
    > 26 February.  Since then the script always fails as a regression test
    > seems to fail.  Specifically, in the tests/ subdirectory of my build
    > directory I have a file reg-tests-1d.Rout.fail which ends with:

    >> ## checking ar.yw.default() multivariate case
    >> estd <- ar(unclass(y) , aic = FALSE, order.max = 2) ## Estimate VAR(2)
    >> es.d <- ar(unclass(y.), aic = FALSE, order.max = 2, na.action=na.pass)
    >> stopifnot(exprs = {
    > +     all.equal(est$ar[1,,], diag(0.8, 2), tol = 0.08)# seen 0.0038
    > +     all.equal(est[1:6], es.[1:6], tol = 5e-3)
    > +     all.equal(estd$x.mean, es.d$x.mean, tol = 0.01) # seen 0.0023
    > +     all.equal(estd[c(1:3,5:6)],
    > +               es.d[c(1:3,5:6)], tol = 1e-3)## seen {1,3,8}e-4
    > +     all.equal(lapply(estd[1:6],unname),
    > +               lapply(est [1:6],unname), tol = 2e-12)# almost identical
    > +     all.equal(lapply(es.d[1:6],unname),
    > +               lapply(es. [1:6],unname), tol = 2e-12)
    > + })
    > Error: lapply(es.d[1:6], unname) and lapply(es.[1:6], unname) are not equal:
    > Component "aic": Mean relative difference: 3.297178e-12
    > Execution halted

    > Would it be possible to make this tolerance more lenient?  In case it
    > matters, I am configuring R to be compiled using Openblas and this test
    > fails for the 64 bit installation, the 32 bit installation seems to
    > pass all tests.

Interesting. But we had another report (on this mailing list!) by
Er. Ho., also using OpenBLAS, but then in combination with Cygwin.
After Cygwin related problems were solved, on March 1 he said

> I have an error at reg-1d.  It stops the process.  However, the mean difference
> (as per the file) is 2.0e-12. 

and when I asked him to be more precise.. he wasn't but did
"solve" the problem by changing the test file.
Now we know from you Berwin (thank you for providing the details!)
what it has been.

==> I could investigate and -- lo and behold! --  the solution
is probably the fact that the RNGkind(sample.kind = *) was
introduced *and* the default was to differ from previous
versions of R.

    > Happy to provide any more information/context that might be needed.

Can you please try adding

    suppressWarnings(RNGversion("3.5.0"))

e.g. at the very beginning of the   tests/reg-tests-1d.R
file or just a few lines above the code you show above,
replace in line 1470

	set.seed(42)
by
	set.seed(42); suppressWarnings(RNGversion("3.5.0"))

It will use a different missingness pattern for that
multivariate AR example, i.e., different data.

Best, Martin


From r|p|ey @end|ng |rom @t@t@@ox@@c@uk  Tue Mar  5 13:01:30 2019
From: r|p|ey @end|ng |rom @t@t@@ox@@c@uk (Prof Brian Ripley)
Date: Tue, 5 Mar 2019 12:01:30 +0000
Subject: [Rd] Development version of R fails tests and is not installed
In-Reply-To: <20190305165409.02d8d09f@ECM-DTC-716.uniwa.uwa.edu.au>
References: <20190305165409.02d8d09f@ECM-DTC-716.uniwa.uwa.edu.au>
Message-ID: <edc6a753-9e46-c079-e2c0-d032b9b04e46@stats.ox.ac.uk>

On 05/03/2019 08:54, Berwin A Turlach wrote:
> G'day all,
> 
> I have daily scripts running to install the patched version of the
> current R version and the development version of R on my linux box
> (Ubuntu 18.04.2 LTS).
> 
> The last development version that was successfully compiled and
> installed was "R Under development (unstable) (2019-02-25 r76159)" on
> 26 February.  Since then the script always fails as a regression test
> seems to fail.  Specifically, in the tests/ subdirectory of my build
> directory I have a file reg-tests-1d.Rout.fail which ends with:
> 
>> ## checking ar.yw.default() multivariate case
>> estd <- ar(unclass(y) , aic = FALSE, order.max = 2) ## Estimate VAR(2)
>> es.d <- ar(unclass(y.), aic = FALSE, order.max = 2, na.action=na.pass)
>> stopifnot(exprs = {
> +     all.equal(est$ar[1,,], diag(0.8, 2), tol = 0.08)# seen 0.0038
> +     all.equal(est[1:6], es.[1:6], tol = 5e-3)
> +     all.equal(estd$x.mean, es.d$x.mean, tol = 0.01) # seen 0.0023
> +     all.equal(estd[c(1:3,5:6)],
> +               es.d[c(1:3,5:6)], tol = 1e-3)## seen {1,3,8}e-4
> +     all.equal(lapply(estd[1:6],unname),
> +               lapply(est [1:6],unname), tol = 2e-12)# almost identical
> +     all.equal(lapply(es.d[1:6],unname),
> +               lapply(es. [1:6],unname), tol = 2e-12)
> + })
> Error: lapply(es.d[1:6], unname) and lapply(es.[1:6], unname) are not equal:
>    Component "aic": Mean relative difference: 3.297178e-12
> Execution halted
> 
> Would it be possible to make this tolerance more lenient?  In case it
> matters, I am configuring R to be compiled using Openblas and this test
> fails for the 64 bit installation, the 32 bit installation seems to
> pass all tests.
> 
> Happy to provide any more information/context that might be needed.

The version of OpenBLAS is always helpful (a couple of bugs were fixed 
recently that impacted the checks in R packages).

I have a x86_64 Linux build with OpenBLAS 0.3.5 that I use for the 
'Additional issues' in package checking, and that passes its checks (and 
has ca weekly for years, even with the buggy versions of OpenBLAS).

Some aspects of the RNG were changed in r76160: to isolate change that 
you can (with current R-devel) use

setenv _R_RNG_VERSION_ 3.5.0

and re-check.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Tue Mar  5 18:03:08 2019
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Tue, 5 Mar 2019 18:03:08 +0100
Subject: [Rd] Development version of R fails tests and is not installed
In-Reply-To: <23678.24928.267076.259252@stat.math.ethz.ch>
References: <20190305165409.02d8d09f@ECM-DTC-716.uniwa.uwa.edu.au>
 <23678.24928.267076.259252@stat.math.ethz.ch>
Message-ID: <23678.43980.390797.760000@stat.math.ethz.ch>

>>>>> Martin Maechler 
>>>>>     on Tue, 5 Mar 2019 12:45:36 +0100 writes:

>>>>> Berwin A Turlach 
>>>>>     on Tue, 5 Mar 2019 16:54:09 +0800 writes:

    >> G'day all,
    >> I have daily scripts running to install the patched version of the
    >> current R version and the development version of R on my linux box
    >> (Ubuntu 18.04.2 LTS).

    >> The last development version that was successfully compiled and
    >> installed was "R Under development (unstable) (2019-02-25 r76159)" on
    >> 26 February.  Since then the script always fails as a regression test
    >> seems to fail.  Specifically, in the tests/ subdirectory of my build
    >> directory I have a file reg-tests-1d.Rout.fail which ends with:

    >>> ## checking ar.yw.default() multivariate case
    >>> estd <- ar(unclass(y) , aic = FALSE, order.max = 2) ## Estimate VAR(2)
    >>> es.d <- ar(unclass(y.), aic = FALSE, order.max = 2, na.action=na.pass)
    >>> stopifnot(exprs = {
    >> +     all.equal(est$ar[1,,], diag(0.8, 2), tol = 0.08)# seen 0.0038
    >> +     all.equal(est[1:6], es.[1:6], tol = 5e-3)
    >> +     all.equal(estd$x.mean, es.d$x.mean, tol = 0.01) # seen 0.0023
    >> +     all.equal(estd[c(1:3,5:6)],
    >> +               es.d[c(1:3,5:6)], tol = 1e-3)## seen {1,3,8}e-4
    >> +     all.equal(lapply(estd[1:6],unname),
    >> +               lapply(est [1:6],unname), tol = 2e-12)# almost identical
    >> +     all.equal(lapply(es.d[1:6],unname),
    >> +               lapply(es. [1:6],unname), tol = 2e-12)
    >> + })
    >> Error: lapply(es.d[1:6], unname) and lapply(es.[1:6], unname) are not equal:
    >> Component "aic": Mean relative difference: 3.297178e-12
    >> Execution halted

    >> Would it be possible to make this tolerance more lenient?  In case it
    >> matters, I am configuring R to be compiled using Openblas and this test
    >> fails for the 64 bit installation, the 32 bit installation seems to
    >> pass all tests.

    > Interesting. But we had another report (on this mailing list!) by
    > Er. Ho., also using OpenBLAS, but then in combination with Cygwin.
    > After Cygwin related problems were solved, on March 1 he said

    >> I have an error at reg-1d.  It stops the process.  However, the mean difference
    >> (as per the file) is 2.0e-12. 

    > and when I asked him to be more precise.. he wasn't but did
    > "solve" the problem by changing the test file.
    > Now we know from you Berwin (thank you for providing the details!)
    > what it has been.

    > ==> I could investigate and -- lo and behold! --  the solution
    > is probably the fact that the RNGkind(sample.kind = *) was
    > introduced *and* the default was to differ from previous
    > versions of R.

    >> Happy to provide any more information/context that might be needed.

    > Can you please try adding

    > suppressWarnings(RNGversion("3.5.0"))

    > e.g. at the very beginning of the   tests/reg-tests-1d.R
    > file or just a few lines above the code you show above,
    > replace in line 1470

    > set.seed(42)
    > by
    > set.seed(42); suppressWarnings(RNGversion("3.5.0"))

oops!  That was a thinko (enticed by my "esthetics"):   Of
course you must *first* set the RNG version and *then* the seed,
so *only* this is correct

   suppressWarnings(RNGversion("3.5.0")); set.seed(42)

where I really would go for

   suppressWarnings(RNGversion("3.5.0")) # back compatibility for now
   set.seed(42)

Note that Brian's advice with an environment variable currently
works "more thoroughly", but it has been labeled "temporary" as it
is not functional / language-explicit [i.e. not visible from
your own R code] ...
and you really should only use it when checking R, *not* otherwise.

Martin


From @uh@rto_@nggono @end|ng |rom y@hoo@com  Tue Mar  5 18:29:20 2019
From: @uh@rto_@nggono @end|ng |rom y@hoo@com (Suharto Anggono Suharto Anggono)
Date: Tue, 5 Mar 2019 17:29:20 +0000 (UTC)
Subject: [Rd] stopifnot
References: <625268441.9734255.1551806960886.ref@mail.yahoo.com>
Message-ID: <625268441.9734255.1551806960886@mail.yahoo.com>

Another possible shortcut definition:
assert <- function(exprs)
do.call("stopifnot", list(exprs = substitute(exprs), local = parent.frame()))


After thinking again, I propose to use
??? ? ? stop(simpleError(msg, call = if(p <- sys.parent()) sys.call(p)))

- It seems that the call is the call of the frame where stopifnot(...) is evaluated. Because that is the correct context, I think it is good.
- It is simpler and also works for call that originally comes from stopifnot(exprs=*) .
- It allows shortcut ('assert') to have the same call in error message as stopifnot(exprs=*) .


Another thing: Is it intended that
do.call("stopifnot", list(exprs = expression()))
evaluates each element of the expression object? If so, maybe add a case for 'cl', like
??? ? ? else if(is.expression(exprs))
??? ??? as.call(c(quote(expression), exprs))

--------------------------------------------
On Mon, 4/3/19, Martin Maechler <maechler at stat.math.ethz.ch> wrote:

 Subject: Re: [Rd] stopifnot

 Cc: r-devel at r-project.org
 Date: Monday, 4 March, 2019, 4:59 PM

>>>>> Suharto Anggono Suharto Anggono via R-devel 
>>>>>? ? on Sat, 2 Mar 2019 08:28:23 +0000 writes:
>>>>> Suharto Anggono Suharto Anggono via R-devel 
>>>>>? ? on Sat, 2 Mar 2019 08:28:23 +0000 writes:

? ? > A private reply by Martin made me realize that I was wrong about
? ? > stopifnot(exprs=TRUE) .
? ? > It actually works fine. I apologize. What I tried and was failed was

? ? > stopifnot(exprs=T) .
? ? > Error in exprs[[1]] : object of type 'symbol' is not subsettable

indeed! .. and your patch below does address that, too.

? ? > The shortcut
? ? > assert <- function(exprs) stopifnot(exprs = exprs)
? ? > mentioned in "Warning" section of the documentation similarly fails when called, for example
? ? > assert({})

? ? > About shortcut, a definition that rather works:
? ? > assert <- function(exprs) eval.parent(substitute(stopifnot(exprs = exprs)))

Interesting... thank you for the suggestion!? I plan to add it
to the help page and then use it a bit .. before considering more.

? ? > Looking at https://stat.ethz.ch/pipermail/r-devel/2017-May/074227.html , using sys.parent() may be not good. For example, in
? ? > f <- function() stopifnot(exprs={FALSE}, local=FALSE); f()

I'm glad you found this too.. I did have "uneasy feelings" about
using sys.parent(2) to find the correct call ..? and I'm still
not 100% sure about the smart computation of 'n' for
sys.call(n-1) ... but I agree we should move in that direction
as it is so much faster than using withCallingHandlers() + tryCatch()
for all the expressions.

In my tests your revised patch (including the simplificationn
you sent 4 hours later) seems good and indeed does have very
good timing in simple experiments.

It will lead to some error messages being changed,
but in the examples I've seen,? the few changes were acceptable
(sometimes slightly less helpful, sometimes easier to read).


Martin

? ? > A revised patch (also with simpler 'cl'):
? ? > --- stop.R? ? 2019-02-27 16:15:45.324167577 +0000
? ? > +++ stop_new.R? ? 2019-03-02 06:21:35.919471080 +0000
? ? > @@ -1,7 +1,7 @@
? ? > #? File src/library/base/R/stop.R
? ? > #? Part of the R package, https://www.R-project.org
? ? > #
? ? > -#? Copyright (C) 1995-2018 The R Core Team
? ? > +#? Copyright (C) 1995-2019 The R Core Team
? ? > #
? ? > #? This program is free software; you can redistribute it and/or modify
? ? > #? it under the terms of the GNU General Public License as published by
? ? > @@ -33,25 +33,28 @@

? ? > stopifnot <- function(..., exprs, local = TRUE)
? ? > {
? ? > +? ? n <- ...length()
? ? > missE <- missing(exprs)
? ? > -? ? cl <-
? ? > if(missE) {? ## use '...' instead of exprs
? ? > -? ? ? ? match.call(expand.dots=FALSE)$...
? ? > } else {
? ? > -? ? ? ? if(...length())
? ? > +? ? ? ? if(n)
? ? > stop("Must use 'exprs' or unnamed expressions, but not both")
? ? > envir <- if (isTRUE(local)) parent.frame()
? ? > else if(isFALSE(local)) .GlobalEnv
? ? > else if (is.environment(local)) local
? ? > else stop("'local' must be TRUE, FALSE or an environment")
? ? > exprs <- substitute(exprs) # protect from evaluation
? ? > -? ? ? ? E1 <- exprs[[1]]
? ? > +? ? ? ? E1 <- if(is.call(exprs)) exprs[[1]]
? ? > +? ? ? ? cl <-
? ? > if(identical(quote(`{`), E1)) # { ... }
? ? > -? ? ? ? do.call(expression, as.list(exprs[-1]))
? ? > +? ? ? ? exprs
? ? > else if(identical(quote(expression), E1))
? ? > -? ? ? ? eval(exprs, envir=envir)
? ? > +? ? ? ? exprs
? ? > else
? ? > -? ? ? ? as.expression(exprs) # or fail ..
? ? > +? ? ? ? call("expression", exprs) # or fail ..
? ? > +? ? ? ? if(!is.null(names(cl))) names(cl) <- NULL
? ? > +? ? ? ? cl[[1]] <- sys.call()[[1]]
? ? > +? ? ? ? return(eval(cl, envir=envir))
? ? > }
? ? > Dparse <- function(call, cutoff = 60L) {
? ? > ch <- deparse(call, width.cutoff = cutoff)
? ? > @@ -62,14 +65,10 @@
? ? > abbrev <- function(ae, n = 3L)
? ? > paste(c(head(ae, n), if(length(ae) > n) "...."), collapse="\n? ")
? ? > ##
? ? > -? ? for (i in seq_along(cl)) {
? ? > -? ? cl.i <- cl[[i]]
? ? > -? ? ## r <- eval(cl.i, ..)? # with correct warn/err messages:
? ? > -? ? r <- withCallingHandlers(
? ? > -? ? ? ? tryCatch(if(missE) ...elt(i) else eval(cl.i, envir=envir),
? ? > -? ? ? ? ? ? error = function(e) { e$call <- cl.i; stop(e) }),
? ? > -? ? ? ? warning = function(w) { w$call <- cl.i; w })
? ? > +? ? for (i in seq_len(n)) {
? ? > +? ? r <- ...elt(i)
? ? > if (!(is.logical(r) && !anyNA(r) && all(r))) {
? ? > +? ? ? ? cl.i <- match.call(expand.dots=FALSE)$...[[i]]
? ? > msg <- ## special case for decently written 'all.equal(*)':
? ? > if(is.call(cl.i) && identical(cl.i[[1]], quote(all.equal)) &&
? ? > (is.null(ni <- names(cl.i)) || length(cl.i) == 3L ||
? ? > @@ -84,7 +83,12 @@
? ? > "%s are not all TRUE"),
? ? > Dparse(cl.i))

? ? > -? ? ? ? stop(simpleError(msg, call = sys.call(-1)))
? ? > +? ? ? ? n <- sys.nframe()
? ? > +? ? ? ? if((p <- n-3) > 0 &&
? ? > +? ? ? ? ? identical(sys.function(p), sys.function(n)) &&
? ? > +? ? ? ? ? eval(expression(!missE), p)) # originally stopifnot(exprs=*)
? ? > +? ? ? ? n <- p
? ? > +? ? ? ? stop(simpleError(msg, call = if(n > 1) sys.call(n-1)))
? ? > }
? ? > }
? ? > invisible()

? ? > --------------------------------------------
? ? > On Fri, 1/3/19, Martin Maechler <maechler at stat.math.ethz.ch> wrote:

? ? > Subject: Re: [Rd] stopifnot

? ? > Cc: "Martin Maechler" <maechler at stat.math.ethz.ch>, r-devel at r-project.org
? ? > Date: Friday, 1 March, 2019, 6:40 PM

>>>>> Suharto Anggono Suharto Anggono 
? ? >>>>>>? ?? on Wed, 27 Feb 2019 22:46:04 +0000 writes:

? ? > [...]

? ? >? ?? > Another thing: currently,
? ? >? ?? > stopifnot(exprs=TRUE)
? ? >? ?? > fails.

[[elided Yahoo spam]]

? ? > I've started to carefully test and try the interesting nice
? ? > patch you've provided below.

? ? > [...]

? ? > Martin


? ? >? ?? > A patch:
? ? >? ?? > --- stop.R? ? 2019-02-27 16:15:45.324167577 +0000
? ? >? ?? > +++ stop_new.R? ? 2019-02-27 16:22:15.936203541 +0000
? ? >? ?? > @@ -1,7 +1,7 @@
? ? >? ?? > #? File src/library/base/R/stop.R
? ? >? ?? > #? Part of the R package, https://www.R-project.org
? ? >? ?? > #
? ? >? ?? > -#? Copyright (C) 1995-2018 The R Core Team
? ? >? ?? > +#? Copyright (C) 1995-2019 The R Core Team
? ? >? ?? > #
? ? >? ?? > #? This program is free software; you can redistribute it and/or modify
? ? >? ?? > #? it under the terms of the GNU General Public License as published by
? ? >? ?? > @@ -33,25 +33,27 @@

? ? >? ?? > stopifnot <- function(..., exprs, local = TRUE)
? ? >? ?? > {
? ? >? ?? > +? ? n <- ...length()
? ? >? ?? > missE <- missing(exprs)
? ? >? ?? > -? ? cl <-
? ? >? ?? > if(missE) {? ## use '...' instead of exprs
? ? >? ?? > -? ? ? ? match.call(expand.dots=FALSE)$...
? ? >? ?? > } else {
? ? >? ?? > -? ? ? ? if(...length())
? ? >? ?? > +? ? ? ? if(n)
? ? >? ?? > stop("Must use 'exprs' or unnamed expressions, but not both")
? ? >? ?? > envir <- if (isTRUE(local)) parent.frame()
? ? >? ?? > else if(isFALSE(local)) .GlobalEnv
? ? >? ?? > else if (is.environment(local)) local
? ? >? ?? > else stop("'local' must be TRUE, FALSE or an environment")
? ? >? ?? > exprs <- substitute(exprs) # protect from evaluation
? ? >? ?? > -? ? ? ? E1 <- exprs[[1]]
? ? >? ?? > +? ? ? ? E1 <- if(is.call(exprs)) exprs[[1]]
? ? >? ?? > +? ? ? ? cl <-
? ? >? ?? > if(identical(quote(`{`), E1)) # { ... }
? ? >? ?? > -? ? ? ? do.call(expression, as.list(exprs[-1]))
? ? >? ?? > +? ? ? ? exprs[-1]
? ? >? ?? > else if(identical(quote(expression), E1))
? ? >? ?? > eval(exprs, envir=envir)
? ? >? ?? > else
? ? >? ?? > as.expression(exprs) # or fail ..
? ? >? ?? > +? ? ? ? if(!is.null(names(cl))) names(cl) <- NULL
? ? >? ?? > +? ? ? ? return(eval(as.call(c(sys.call()[[1]], as.list(cl))), envir=envir))
? ? >? ?? > }
? ? >? ?? > Dparse <- function(call, cutoff = 60L) {
? ? >? ?? > ch <- deparse(call, width.cutoff = cutoff)
? ? >? ?? > @@ -62,14 +64,10 @@
? ? >? ?? > abbrev <- function(ae, n = 3L)
? ? >? ?? > paste(c(head(ae, n), if(length(ae) > n) "...."), collapse="\n? ")
? ? >? ?? > ##
? ? >? ?? > -? ? for (i in seq_along(cl)) {
? ? >? ?? > -? ? cl.i <- cl[[i]]
? ? >? ?? > -? ? ## r <- eval(cl.i, ..)? # with correct warn/err messages:
? ? >? ?? > -? ? r <- withCallingHandlers(
? ? >? ?? > -? ? ? ? tryCatch(if(missE) ...elt(i) else eval(cl.i, envir=envir),
? ? >? ?? > -? ? ? ? ? ? error = function(e) { e$call <- cl.i; stop(e) }),
? ? >? ?? > -? ? ? ? warning = function(w) { w$call <- cl.i; w })
? ? >? ?? > +? ? for (i in seq_len(n)) {
? ? >? ?? > +? ? r <- ...elt(i)
? ? >? ?? > if (!(is.logical(r) && !anyNA(r) && all(r))) {
? ? >? ?? > +? ? ? ? cl.i <- match.call(expand.dots=FALSE)$...[[i]]
? ? >? ?? > msg <- ## special case for decently written 'all.equal(*)':
? ? >? ?? > if(is.call(cl.i) && identical(cl.i[[1]], quote(all.equal)) &&
? ? >? ?? > (is.null(ni <- names(cl.i)) || length(cl.i) == 3L ||
? ? >? ?? > @@ -84,7 +82,11 @@
? ? >? ?? > "%s are not all TRUE"),
? ? >? ?? > Dparse(cl.i))

? ? >? ?? > -? ? ? ? stop(simpleError(msg, call = sys.call(-1)))
? ? >? ?? > +? ? ? ? p <- sys.parent()
? ? >? ?? > +? ? ? ? if(p && identical(sys.function(p), stopifnot) &&
? ? >? ?? > +? ? ? ? ? !eval(expression(missE), p)) # originally stopifnot(exprs=*)
? ? >? ?? > +? ? ? ? p <- sys.parent(2)
? ? >? ?? > +? ? ? ? stop(simpleError(msg, call = if(p) sys.call(p)))
? ? >? ?? > }
? ? >? ?? > }
? ? >? ?? > invisible()


? ? > ______________________________________________
? ? > R-devel at r-project.org mailing list
? ? > https://stat.ethz.ch/mailman/listinfo/r-devel


From v|tekj @end|ng |rom |c|oud@com  Tue Mar  5 00:49:40 2019
From: v|tekj @end|ng |rom |c|oud@com (jan Vitek)
Date: Mon, 4 Mar 2019 18:49:40 -0500
Subject: [Rd] 
 Should CRAN accept packages with non-R code that transcompiles
 into R code?
In-Reply-To: <CAB8pepx3d3faRfPTDo97ebOKA1f4v=GO6_dbL7QC2DtkqZV0=w@mail.gmail.com>
References: <CAB8pepx3d3faRfPTDo97ebOKA1f4v=GO6_dbL7QC2DtkqZV0=w@mail.gmail.com>
Message-ID: <34031A85-4458-4DA4-89D7-B30EEC94CED7@icloud.com>

Everything is possible. One can compile C++ into JavaScript.

But why?

> On Mar 4, 2019, at 6:28 PM, Abs Spurdle <spurdle.a at gmail.com> wrote:
> 
> It may be possible to create an R-like programming language that
> transcompiles into R code (or otherwise constructs R objects and calls
> R functions).
> 
> I'm not sure whether it would pass R check or not, I will probably try...
> 
> But the bigger question is:
> Should CRAN accept packages written in such a way?
> 
> I could email Kurt Hornik or Uwe Ligges, and ask them.
> However, I thought that I would ask here first.
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://na01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-devel&amp;data=02%7C01%7Cj.vitek%40northeastern.edu%7C65c14d53fbc44634f88508d6a0f9151d%7Ca8eec281aaa34daeac9b9a398b9215e7%7C0%7C0%7C636873389038367455&amp;sdata=vrZX4jUoakFB%2FRBG6aTjpYsw4fv4NfvIszOxNLhb7Rs%3D&amp;reserved=0


From |@ke|v|n @end|ng |rom ucd@v|@@edu  Tue Mar  5 08:22:29 2019
From: |@ke|v|n @end|ng |rom ucd@v|@@edu (Lee Steven Kelvin)
Date: Tue, 5 Mar 2019 07:22:29 +0000
Subject: [Rd] R cairo_pdf function does not respect plotting boundaries
In-Reply-To: <581bf016-0b51-977b-200d-bbeef95f9046@stat.auckland.ac.nz>
References: <CAO0anGmxEwS2VtAqT-i6701QrkFCL90cOneB+c_y3uJ_40aG9w@mail.gmail.com>
 <581bf016-0b51-977b-200d-bbeef95f9046@stat.auckland.ac.nz>
Message-ID: <CAO0anGmLgRSFJWaRmYbAnKL-8EwaZXyUjBCu+dBnLMV39wTwGA@mail.gmail.com>

Hi Paul,

Great, thank you for looking in to this, and I'm glad that you're able to reproduce it at your end too.

From your reply, I'm happy that it seems like the fix may be fairly trivial, but I understand the necessity for caution.

If there's anything else I can do to help, please do let me know.

Thank you again,
Best,
Lee


On Monday, 4 March 2019, Paul Murrell <paul at stat.auckland.ac.nz<mailto:paul at stat.auckland.ac.nz>> wrote:
Hi

(cc'ed to r-devel where further discussion should probably take place)

Thanks Lee.  I see that problem.

There is a "+ 1" in the Cairo device code for setting the clipping region
(https://github.com/wch/r-source/blob/ba600867f2a94e46cf9eb75dc8b37f12b08a4561/src/library/grDevices/src/cairo/cairoFns.c#L156)

Remove the "+ 1" and the problem goes away (for your example at least).

The comment on the line above that code suggests that the "+ 1" was modelled on the X11 device code, but X11 deals in integer pixels and Cairo (at the API level) does not, so it would seem that the "+ 1" is just unnecessary.

However, I have a slight nagging worry that we have been here before, so I would like to do some more testing before committing that change.

Paul

On 1/03/19 8:13 AM, Lee Steven Kelvin wrote:
Hello all,

When producing a plot in R using the cairo_pdf device, the resultant plot does not respect the plotting boundaries. Lines and shaded regions will spill over the lower x-axis and the right-side y-axis (sides 1 and 4). I would like to know if it is possible to fix this behaviour when using 'cairo_pdf' in R?

As an example, see the image at this web link: https://i.stack.imgur.com/0lfZd.png

This image is a screenshot of a PDF file constructed using the following minimum working example code:

cairo_pdf(file="test.pdf", width=0.5, height=0.5)
par("mar"=c(0.25,0.25,0.25,0.25))
plot(NA, xlim=c(0,1), ylim=c(0,1), axes=FALSE)
polygon(x=c(-1,-1,2,2), y=c(-1,2,2,-1), density=5, col="green3", lwd=10)
abline(h=0.25, col="red", lwd=5)
abline(h=0.75, col="hotpink", lwd=5, lend=1)
abline(v=0.25, col="blue", lwd=5)
abline(v=0.75, col="cyan", lwd=5, lend=1)
box()
dev.off()

Here I'm plotting a shaded region in green using 'polygon', with boundaries that lie outside the plot. I'm also drawing two sets of horizontal/vertical lines using 'abline'. The first in each pair uses standard rounded line caps, whilst the second in each pair uses butt line caps.

As you can see, the shading lines and the default rounded-end ablines all extend beyond the plotting region along the lower and right-hand side axes. Only when using 'lend=1' am I able to contain the ablines to the plotting region. I know of no such fix for the shading lines however.

I would naively expect the R plotting region to be respected, and for it to be impossible to plot outside of this region unless explicitly specified by the user.

I have tested this on the other cairo devices (SVG and PS), and also reproduce the same behaviour, indicating that this is an issue with the cairo graphics API, or its implementation within R.

This behaviour does not occur when using the standard R 'pdf' graphics device. I would switch to 'pdf' in general, however, 'cairo_pdf' has several advantages over 'pdf', notably, reduced output file sizes on occasion and support for a larger array of UTF-8 characters, so ideally I would prefer to use cairo_pdf.

I should note that I have also posted this message on StackOverflow at this web link: https://stackoverflow.com/questions/54892809/r-cairo-pdf-function-does-not-respect-plotting-boundaries

Thank you in advance for any insights into this issue.

Sincerely,
Lee Kelvin



--
Dr Lee Kelvin
Department of Physics
UC Davis
One Shields Avenue
Davis, CA 95616
USA

Ph: +1 (530) 752-1500
Fax: +1 (530) 752-4717


        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


--
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz<mailto:paul at stat.auckland.ac.nz>
http://www.stat.auckland.ac.nz/~paul/


--
Dr Lee Kelvin
Department of Physics
UC Davis
One Shields Avenue
Davis, CA 95616
USA

Ph: +1 (530) 752-1500
Fax: +1 (530) 752-4717


	[[alternative HTML version deleted]]


From w @end|ng |rom rwh|te@no  Tue Mar  5 08:31:18 2019
From: w @end|ng |rom rwh|te@no (Richard White)
Date: Tue, 5 Mar 2019 09:31:18 +0200
Subject: [Rd] as.Date(Inf) displays as 'NA' but is actually 'Inf'
Message-ID: <6d06f8f8-828b-4510-6024-908bc6f5336f@rwhite.no>

Hi,

I think I've discovered a bug in base R.

Basically, when using 'Inf' as as 'Date', is is visually displayed as 
'NA', but R still treats it as 'Inf'. So it is very confusing to work 
with, and can easily lead to errors:

# Visually displays as NA
 > as.Date(Inf, origin="2018-01-01")
[1] NA

# Visually displays as NA
 > str(as.Date(Inf, origin="2018-01-01"))
Date[1:1], format: NA

# Is NOT NA
 > is.na(as.Date(Inf, origin="2018-01-01"))
[1] FALSE

# Is still Inf
 > is.infinite(as.Date(Inf, origin="2018-01-01"))
[1] TRUE

This gets really problematic when you are collapsing dates over groups 
and you want to find the first date of a group. Because min() returns 
Inf if there is no data:

# Visually displays as NA
 > as.Date(min(), origin="2018-01-01")
[1] NA
Warning message: In min() : no non-missing arguments to min; returning Inf

# Visually displays as NA
 > str(as.Date(min(), origin="2018-01-01"))
Date[1:1], format: NA
Warning message: In min() : no non-missing arguments to min; returning Inf

# Is not NA
 > is.na(as.Date(min(), origin="2018-01-01"))
[1] FALSE
Warning message: In min() : no non-missing arguments to min; returning Inf

# This is bad!
 > as.Date(min(), origin="2018-01-01") > "2018-01-01"
[1] TRUE
Warning message: In min() : no non-missing arguments to min; returning Inf

Here is my sessionInfo():

 > sessionInfo()
R version 3.5.0 (2018-04-23)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Debian GNU/Linux 9 (stretch)
Matrix products: default
BLAS: /usr/lib/openblas-base/libblas.so.3
LAPACK: /usr/lib/libopenblasp-r0.2.19.so

locale:
[1] LC_CTYPE=C.UTF-8 LC_NUMERIC=C LC_TIME=C.UTF-8 LC_COLLATE=C.UTF-8 
LC_MONETARY=C.UTF-8
[6] LC_MESSAGES=C LC_PAPER=C.UTF-8 LC_NAME=C LC_ADDRESS=C LC_TELEPHONE=C
[11] LC_MEASUREMENT=C.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats graphics grDevices utils datasets methods base loaded via a 
namespace (and not attached):
[1] compiler_3.5.0 tools_3.5.0 yaml_2.1.19

 > Sys.getlocale()
[1] 
"LC_CTYPE=C.UTF-8;LC_NUMERIC=C;LC_TIME=C.UTF-8;LC_COLLATE=C.UTF-8;LC_MONETARY=C.UTF-8;LC_MESSAGES=C;LC_PAPER=C.UTF-8;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=C.UTF-8;LC_IDENTIFICATION=C"


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Tue Mar  5 21:04:08 2019
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Tue, 5 Mar 2019 21:04:08 +0100
Subject: [Rd] stopifnot
In-Reply-To: <625268441.9734255.1551806960886@mail.yahoo.com>
References: <625268441.9734255.1551806960886.ref@mail.yahoo.com>
 <625268441.9734255.1551806960886@mail.yahoo.com>
Message-ID: <23678.54840.452841.851948@stat.math.ethz.ch>

>>>>> Suharto Anggono Suharto Anggono 
>>>>>     on Tue, 5 Mar 2019 17:29:20 +0000 writes:

    > Another possible shortcut definition:

    > assert <- function(exprs)
    > do.call("stopifnot", list(exprs = substitute(exprs), local = parent.frame()))

Thank you.  I think this is mostly a matter of taste, but I
liked your version using eval() & substitute() a bit more.  For
me, do.call() is a heavy hammer I only like to use when needed..

Or would there be advantages of this version?
Indeed (as you note below) one important consideration is the exact
message that is produced when one assertion fails.

    > After thinking again, I propose to use
    > ??? ? ? stop(simpleError(msg, call = if(p <- sys.parent()) sys.call(p)))

That would of course be considerably simpler indeed,  part "2 a" of these:

    > - It seems that the call is the call of the frame where stopifnot(...) is evaluated. Because that is the correct context, I think it is good.
    > - It is simpler and also works for call that originally comes from stopifnot(exprs=*) .

    > - It allows shortcut ('assert') to have the same call in error message as stopifnot(exprs=*) .

That may be another good reason in addition to code simplicity.

I will have to see if this extra simplification does not loose
more than I'd want.


    > Another thing: Is it intended that
    >     do.call("stopifnot", list(exprs = expression()))
    > evaluates each element of the expression object?

??  I really don't know.  Even though such a case looks
"unusual" (to say the least), in principle I'd like that
expressions are evaluated sequentially until the first non-TRUE
result.  With a concrete example, I do like what we have
currently in unchanged R-devel, but also in R 3.5.x, i.e., in
the following, not any "NOT GOOD" should pop up:

> stopifnot(exprs = expression(1==1, 2 < 1, stop("NOT GOOD!\n")))
Error: 2 < 1 is not TRUE
> do.call(stopifnot, list(exprs = expression(1==1, 2 < 1, stop("NOT GOOD!\n"))))
Error in do.call(stopifnot, list(exprs = expression(1 == 1, 2 < 1, cat("NOT GOOD!\n")))) : 
  2 < 1 is not TRUE
> 

Hmm, it seems I do not understand what you ask above in your
"Another thing: .."


    >  If so, maybe add a case for 'cl', like
    > ??? ? ? else if(is.expression(exprs))
    > ??? ??? as.call(c(quote(expression), exprs))

that seems simple indeed, but at the moment, I cannot see one example
where it makes a difference ... or then I'm "blind" .. ???

Best,
Martin

    > --------------------------------------------
    > On Mon, 4/3/19, Martin Maechler <maechler at stat.math.ethz.ch> wrote:

    > Subject: Re: [Rd] stopifnot
    > To: "Suharto Anggono Suharto Anggono" <suharto_anggono at yahoo.com>
    > Cc: r-devel at r-project.org
    > Date: Monday, 4 March, 2019, 4:59 PM
 
>>>>> Suharto Anggono Suharto Anggono via R-devel 
    >>>>>> ? ? on Sat, 2 Mar 2019 08:28:23 +0000 writes:
>>>>> Suharto Anggono Suharto Anggono via R-devel 
    >>>>>> ? ? on Sat, 2 Mar 2019 08:28:23 +0000 writes:

    > ? ? > A private reply by Martin made me realize that I was wrong about
    > ? ? > stopifnot(exprs=TRUE) .
    > ? ? > It actually works fine. I apologize. What I tried and was failed was

    > ? ? > stopifnot(exprs=T) .
    > ? ? > Error in exprs[[1]] : object of type 'symbol' is not subsettable

    > indeed! .. and your patch below does address that, too.

    > ? ? > The shortcut
    > ? ? > assert <- function(exprs) stopifnot(exprs = exprs)
    > ? ? > mentioned in "Warning" section of the documentation similarly fails when called, for example
    > ? ? > assert({})

    > ? ? > About shortcut, a definition that rather works:
    > ? ? > assert <- function(exprs) eval.parent(substitute(stopifnot(exprs = exprs)))

    > Interesting... thank you for the suggestion!? I plan to add it
    > to the help page and then use it a bit .. before considering more.

    > ? ? > Looking at https://stat.ethz.ch/pipermail/r-devel/2017-May/074227.html , using sys.parent() may be not good. For example, in
    > ? ? > f <- function() stopifnot(exprs={FALSE}, local=FALSE); f()

    > I'm glad you found this too.. I did have "uneasy feelings" about
    > using sys.parent(2) to find the correct call ..? and I'm still
    > not 100% sure about the smart computation of 'n' for
    > sys.call(n-1) ... but I agree we should move in that direction
    > as it is so much faster than using withCallingHandlers() + tryCatch()
    > for all the expressions.

    > In my tests your revised patch (including the simplificationn
    > you sent 4 hours later) seems good and indeed does have very
    > good timing in simple experiments.

    > It will lead to some error messages being changed,
    > but in the examples I've seen,? the few changes were acceptable
    > (sometimes slightly less helpful, sometimes easier to read).


    > Martin

    > ? ? > A revised patch (also with simpler 'cl'):
    > ? ? > --- stop.R? ? 2019-02-27 16:15:45.324167577 +0000
    > ? ? > +++ stop_new.R? ? 2019-03-02 06:21:35.919471080 +0000
    > ? ? > @@ -1,7 +1,7 @@
    > ? ? > #? File src/library/base/R/stop.R
    > ? ? > #? Part of the R package, https://www.R-project.org
    > ? ? > #
    > ? ? > -#? Copyright (C) 1995-2018 The R Core Team
    > ? ? > +#? Copyright (C) 1995-2019 The R Core Team
    > ? ? > #
    > ? ? > #? This program is free software; you can redistribute it and/or modify
    > ? ? > #? it under the terms of the GNU General Public License as published by
    > ? ? > @@ -33,25 +33,28 @@

    > ? ? > stopifnot <- function(..., exprs, local = TRUE)
    > ? ? > {
    > ? ? > +? ? n <- ...length()
    > ? ? > missE <- missing(exprs)
    > ? ? > -? ? cl <-
    > ? ? > if(missE) {? ## use '...' instead of exprs
    > ? ? > -? ? ? ? match.call(expand.dots=FALSE)$...
    > ? ? > } else {
    > ? ? > -? ? ? ? if(...length())
    > ? ? > +? ? ? ? if(n)
    > ? ? > stop("Must use 'exprs' or unnamed expressions, but not both")
    > ? ? > envir <- if (isTRUE(local)) parent.frame()
    > ? ? > else if(isFALSE(local)) .GlobalEnv
    > ? ? > else if (is.environment(local)) local
    > ? ? > else stop("'local' must be TRUE, FALSE or an environment")
    > ? ? > exprs <- substitute(exprs) # protect from evaluation
    > ? ? > -? ? ? ? E1 <- exprs[[1]]
    > ? ? > +? ? ? ? E1 <- if(is.call(exprs)) exprs[[1]]
    > ? ? > +? ? ? ? cl <-
    > ? ? > if(identical(quote(`{`), E1)) # { ... }
    > ? ? > -? ? ? ? do.call(expression, as.list(exprs[-1]))
    > ? ? > +? ? ? ? exprs
    > ? ? > else if(identical(quote(expression), E1))
    > ? ? > -? ? ? ? eval(exprs, envir=envir)
    > ? ? > +? ? ? ? exprs
    > ? ? > else
    > ? ? > -? ? ? ? as.expression(exprs) # or fail ..
    > ? ? > +? ? ? ? call("expression", exprs) # or fail ..
    > ? ? > +? ? ? ? if(!is.null(names(cl))) names(cl) <- NULL
    > ? ? > +? ? ? ? cl[[1]] <- sys.call()[[1]]
    > ? ? > +? ? ? ? return(eval(cl, envir=envir))
    > ? ? > }
    > ? ? > Dparse <- function(call, cutoff = 60L) {
    > ? ? > ch <- deparse(call, width.cutoff = cutoff)
    > ? ? > @@ -62,14 +65,10 @@
    > ? ? > abbrev <- function(ae, n = 3L)
    > ? ? > paste(c(head(ae, n), if(length(ae) > n) "...."), collapse="\n? ")
    > ? ? > ##
    > ? ? > -? ? for (i in seq_along(cl)) {
    > ? ? > -? ? cl.i <- cl[[i]]
    > ? ? > -? ? ## r <- eval(cl.i, ..)? # with correct warn/err messages:
    > ? ? > -? ? r <- withCallingHandlers(
    > ? ? > -? ? ? ? tryCatch(if(missE) ...elt(i) else eval(cl.i, envir=envir),
    > ? ? > -? ? ? ? ? ? error = function(e) { e$call <- cl.i; stop(e) }),
    > ? ? > -? ? ? ? warning = function(w) { w$call <- cl.i; w })
    > ? ? > +? ? for (i in seq_len(n)) {
    > ? ? > +? ? r <- ...elt(i)
    > ? ? > if (!(is.logical(r) && !anyNA(r) && all(r))) {
    > ? ? > +? ? ? ? cl.i <- match.call(expand.dots=FALSE)$...[[i]]
    > ? ? > msg <- ## special case for decently written 'all.equal(*)':
    > ? ? > if(is.call(cl.i) && identical(cl.i[[1]], quote(all.equal)) &&
    > ? ? > (is.null(ni <- names(cl.i)) || length(cl.i) == 3L ||
    > ? ? > @@ -84,7 +83,12 @@
    > ? ? > "%s are not all TRUE"),
    > ? ? > Dparse(cl.i))

    > ? ? > -? ? ? ? stop(simpleError(msg, call = sys.call(-1)))
    > ? ? > +? ? ? ? n <- sys.nframe()
    > ? ? > +? ? ? ? if((p <- n-3) > 0 &&
    > ? ? > +? ? ? ? ? identical(sys.function(p), sys.function(n)) &&
    > ? ? > +? ? ? ? ? eval(expression(!missE), p)) # originally stopifnot(exprs=*)
    > ? ? > +? ? ? ? n <- p
    > ? ? > +? ? ? ? stop(simpleError(msg, call = if(n > 1) sys.call(n-1)))
    > ? ? > }
    > ? ? > }
    > ? ? > invisible()

    > ? ? > --------------------------------------------
    > ? ? > On Fri, 1/3/19, Martin Maechler <maechler at stat.math.ethz.ch> wrote:

    > ? ? > Subject: Re: [Rd] stopifnot

    > ? ? > Cc: "Martin Maechler" <maechler at stat.math.ethz.ch>, r-devel at r-project.org
    > ? ? > Date: Friday, 1 March, 2019, 6:40 PM

>>>>> Suharto Anggono Suharto Anggono 
    > ? ? >>>>>>? ?? on Wed, 27 Feb 2019 22:46:04 +0000 writes:

    > ? ? > [...]

    > ? ? >? ?? > Another thing: currently,
    > ? ? >? ?? > stopifnot(exprs=TRUE)
    > ? ? >? ?? > fails.

    > ? ? > good catch - indeed!

    > ? ? > I've started to carefully test and try the interesting nice
    > ? ? > patch you've provided below.

    > ? ? > [...]

    > ? ? > Martin


    > ? ? >? ?? > A patch:
    > ? ? >? ?? > --- stop.R? ? 2019-02-27 16:15:45.324167577 +0000
    > ? ? >? ?? > +++ stop_new.R? ? 2019-02-27 16:22:15.936203541 +0000
    > ? ? >? ?? > @@ -1,7 +1,7 @@
    > ? ? >? ?? > #? File src/library/base/R/stop.R
    > ? ? >? ?? > #? Part of the R package, https://www.R-project.org
    > ? ? >? ?? > #
    > ? ? >? ?? > -#? Copyright (C) 1995-2018 The R Core Team
    > ? ? >? ?? > +#? Copyright (C) 1995-2019 The R Core Team
    > ? ? >? ?? > #
    > ? ? >? ?? > #? This program is free software; you can redistribute it and/or modify
    > ? ? >? ?? > #? it under the terms of the GNU General Public License as published by
    > ? ? >? ?? > @@ -33,25 +33,27 @@

    > ? ? >? ?? > stopifnot <- function(..., exprs, local = TRUE)
    > ? ? >? ?? > {
    > ? ? >? ?? > +? ? n <- ...length()
    > ? ? >? ?? > missE <- missing(exprs)
    > ? ? >? ?? > -? ? cl <-
    > ? ? >? ?? > if(missE) {? ## use '...' instead of exprs
    > ? ? >? ?? > -? ? ? ? match.call(expand.dots=FALSE)$...
    > ? ? >? ?? > } else {
    > ? ? >? ?? > -? ? ? ? if(...length())
    > ? ? >? ?? > +? ? ? ? if(n)
    > ? ? >? ?? > stop("Must use 'exprs' or unnamed expressions, but not both")
    > ? ? >? ?? > envir <- if (isTRUE(local)) parent.frame()
    > ? ? >? ?? > else if(isFALSE(local)) .GlobalEnv
    > ? ? >? ?? > else if (is.environment(local)) local
    > ? ? >? ?? > else stop("'local' must be TRUE, FALSE or an environment")
    > ? ? >? ?? > exprs <- substitute(exprs) # protect from evaluation
    > ? ? >? ?? > -? ? ? ? E1 <- exprs[[1]]
    > ? ? >? ?? > +? ? ? ? E1 <- if(is.call(exprs)) exprs[[1]]
    > ? ? >? ?? > +? ? ? ? cl <-
    > ? ? >? ?? > if(identical(quote(`{`), E1)) # { ... }
    > ? ? >? ?? > -? ? ? ? do.call(expression, as.list(exprs[-1]))
    > ? ? >? ?? > +? ? ? ? exprs[-1]
    > ? ? >? ?? > else if(identical(quote(expression), E1))
    > ? ? >? ?? > eval(exprs, envir=envir)
    > ? ? >? ?? > else
    > ? ? >? ?? > as.expression(exprs) # or fail ..
    > ? ? >? ?? > +? ? ? ? if(!is.null(names(cl))) names(cl) <- NULL
    > ? ? >? ?? > +? ? ? ? return(eval(as.call(c(sys.call()[[1]], as.list(cl))), envir=envir))
    > ? ? >? ?? > }
    > ? ? >? ?? > Dparse <- function(call, cutoff = 60L) {
    > ? ? >? ?? > ch <- deparse(call, width.cutoff = cutoff)
    > ? ? >? ?? > @@ -62,14 +64,10 @@
    > ? ? >? ?? > abbrev <- function(ae, n = 3L)
    > ? ? >? ?? > paste(c(head(ae, n), if(length(ae) > n) "...."), collapse="\n? ")
    > ? ? >? ?? > ##
    > ? ? >? ?? > -? ? for (i in seq_along(cl)) {
    > ? ? >? ?? > -? ? cl.i <- cl[[i]]
    > ? ? >? ?? > -? ? ## r <- eval(cl.i, ..)? # with correct warn/err messages:
    > ? ? >? ?? > -? ? r <- withCallingHandlers(
    > ? ? >? ?? > -? ? ? ? tryCatch(if(missE) ...elt(i) else eval(cl.i, envir=envir),
    > ? ? >? ?? > -? ? ? ? ? ? error = function(e) { e$call <- cl.i; stop(e) }),
    > ? ? >? ?? > -? ? ? ? warning = function(w) { w$call <- cl.i; w })
    > ? ? >? ?? > +? ? for (i in seq_len(n)) {
    > ? ? >? ?? > +? ? r <- ...elt(i)
    > ? ? >? ?? > if (!(is.logical(r) && !anyNA(r) && all(r))) {
    > ? ? >? ?? > +? ? ? ? cl.i <- match.call(expand.dots=FALSE)$...[[i]]
    > ? ? >? ?? > msg <- ## special case for decently written 'all.equal(*)':
    > ? ? >? ?? > if(is.call(cl.i) && identical(cl.i[[1]], quote(all.equal)) &&
    > ? ? >? ?? > (is.null(ni <- names(cl.i)) || length(cl.i) == 3L ||
    > ? ? >? ?? > @@ -84,7 +82,11 @@
    > ? ? >? ?? > "%s are not all TRUE"),
    > ? ? >? ?? > Dparse(cl.i))

    > ? ? >? ?? > -? ? ? ? stop(simpleError(msg, call = sys.call(-1)))
    > ? ? >? ?? > +? ? ? ? p <- sys.parent()
    > ? ? >? ?? > +? ? ? ? if(p && identical(sys.function(p), stopifnot) &&
    > ? ? >? ?? > +? ? ? ? ? !eval(expression(missE), p)) # originally stopifnot(exprs=*)
    > ? ? >? ?? > +? ? ? ? p <- sys.parent(2)
    > ? ? >? ?? > +? ? ? ? stop(simpleError(msg, call = if(p) sys.call(p)))
    > ? ? >? ?? > }
    > ? ? >? ?? > }
    > ? ? >? ?? > invisible()


    > ? ? > ______________________________________________
    > ? ? > R-devel at r-project.org mailing list
    > ? ? > https://stat.ethz.ch/mailman/listinfo/r-devel


From @purd|e@@ @end|ng |rom gm@||@com  Tue Mar  5 21:34:23 2019
From: @purd|e@@ @end|ng |rom gm@||@com (Abs Spurdle)
Date: Wed, 6 Mar 2019 09:34:23 +1300
Subject: [Rd] 
 Should CRAN accept packages with non-R code that transcompiles
 into R code?
In-Reply-To: <34031A85-4458-4DA4-89D7-B30EEC94CED7@icloud.com>
References: <CAB8pepx3d3faRfPTDo97ebOKA1f4v=GO6_dbL7QC2DtkqZV0=w@mail.gmail.com>
 <34031A85-4458-4DA4-89D7-B30EEC94CED7@icloud.com>
Message-ID: <CAB8pepyoR_UdCq2djH4FSaGrJM0VP1+0ZzDTK8rCDfffyMr4=w@mail.gmail.com>

On Tue, Mar 5, 2019 at 12:49 PM jan Vitek <vitekj at icloud.com> wrote:

> Everything is possible. One can compile C++ into JavaScript.
>
> But why?
>
>
I would like to support Java style syntax for class definitions.
(Then it could transcompile into either S3 or S4).

And possibly change some other things while I'm at it.
Maybe, integers (rather than numerics) as defaults, and * for standard
matrix multiplication (and ** for R style vectorized multiplication).

	[[alternative HTML version deleted]]


From @purd|e@@ @end|ng |rom gm@||@com  Tue Mar  5 21:41:10 2019
From: @purd|e@@ @end|ng |rom gm@||@com (Abs Spurdle)
Date: Wed, 6 Mar 2019 09:41:10 +1300
Subject: [Rd] 
 Should CRAN accept packages with non-R code that transcompiles
 into R code?
In-Reply-To: <CAD4oTHFhp1qUfFhLeCh_jBXBYH30mDjvFSeGhW5OBbnkC1t13g@mail.gmail.com>
References: <CAB8pepx3d3faRfPTDo97ebOKA1f4v=GO6_dbL7QC2DtkqZV0=w@mail.gmail.com>
 <CAD4oTHFhp1qUfFhLeCh_jBXBYH30mDjvFSeGhW5OBbnkC1t13g@mail.gmail.com>
Message-ID: <CAB8pepzNadqgsHP-tbhAaBj5RNK12hFQHChQiRG=36me6G-Ybg@mail.gmail.com>

On Tue, Mar 5, 2019 at 12:52 PM Gabriel Becker <gabembecker at gmail.com>
wrote:

> I have thought about and have (somewhere "up near the top" of my todo
> list) prototyping a preprocessor for R, and I have relevant code that emits
> (transpiles, in a way) structured comments into S4 code in
> https://github.com/gmbecker/S4Coffee.
>
> All that said, until/unless the preprocessor is officially part of the R
> CMD build step, what putting code like that on CRAN would look like is you
> keep the raw code in /inst somewhere, and you do the emitting of R code
> into R/ before building the tarball for submitting. And if you do that CRAN
> will hav eno problem accepting such a package provided it isn't disallowed
> in some other way.
>

I think that I would prefer to generate (and run) the R code during
.onLoad(), rather than pre-generate it and put it in the R subdirectory.
If it's in the R subdirectory, then we have two copies of the same thing,
plus it would need to be documented using the rd format, which I would like
to minimize, in favor other documentation formats.
Which is where CRAN may not like it...

In regards to S4Coffee, it sounds promising.
I hope you get in finished in the near future.
And I will take a closer look at it.

	[[alternative HTML version deleted]]


From v|tekj @end|ng |rom |c|oud@com  Tue Mar  5 21:43:34 2019
From: v|tekj @end|ng |rom |c|oud@com (jan Vitek)
Date: Tue, 5 Mar 2019 15:43:34 -0500
Subject: [Rd] 
 Should CRAN accept packages with non-R code that transcompiles
 into R code?
In-Reply-To: <CAB8pepyoR_UdCq2djH4FSaGrJM0VP1+0ZzDTK8rCDfffyMr4=w@mail.gmail.com>
References: <CAB8pepx3d3faRfPTDo97ebOKA1f4v=GO6_dbL7QC2DtkqZV0=w@mail.gmail.com>
 <34031A85-4458-4DA4-89D7-B30EEC94CED7@icloud.com>
 <CAB8pepyoR_UdCq2djH4FSaGrJM0VP1+0ZzDTK8rCDfffyMr4=w@mail.gmail.com>
Message-ID: <0FCB9AF8-2907-433A-900A-0B7C6479DB72@icloud.com>

As long as the semantic models are close, then such a translation is
possible and not even very difficult. Syntactic sugar is cheap. 
The challenge that you will run into is that there is a temptation
to change the semantics when designing a new language. R has many
warts that, if one were to start today, one could imagine removing.
But any change to semantics is really hard to implement by 
source to source translation. My guess is that before you know it
you will have a very different language that runs extremely slowly.




Jan Vitek, Professor 
Computer Science, 
Northeastern University

> On Mar 5, 2019, at 3:34 PM, Abs Spurdle <spurdle.a at gmail.com> wrote:
> 
> On Tue, Mar 5, 2019 at 12:49 PM jan Vitek <vitekj at icloud.com> wrote:
> 
>> Everything is possible. One can compile C++ into JavaScript.
>> 
>> But why?
>> 
>> 
> I would like to support Java style syntax for class definitions.
> (Then it could transcompile into either S3 or S4).
> 
> And possibly change some other things while I'm at it.
> Maybe, integers (rather than numerics) as defaults, and * for standard
> matrix multiplication (and ** for R style vectorized multiplication).
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://na01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-devel&amp;data=02%7C01%7Cj.vitek%40northeastern.edu%7Ca94a44aafef146067cc208d6a1aa5dd8%7Ca8eec281aaa34daeac9b9a398b9215e7%7C0%7C0%7C636874150443008540&amp;sdata=%2B%2Bxg06eGYgC64vfJIy%2BJeBYKZvCD1LiK5HIGFN2XrP4%3D&amp;reserved=0


	[[alternative HTML version deleted]]


From g@bembecker @end|ng |rom gm@||@com  Tue Mar  5 21:45:44 2019
From: g@bembecker @end|ng |rom gm@||@com (Gabriel Becker)
Date: Tue, 5 Mar 2019 12:45:44 -0800
Subject: [Rd] 
 Should CRAN accept packages with non-R code that transcompiles
 into R code?
In-Reply-To: <CAB8pepzNadqgsHP-tbhAaBj5RNK12hFQHChQiRG=36me6G-Ybg@mail.gmail.com>
References: <CAB8pepx3d3faRfPTDo97ebOKA1f4v=GO6_dbL7QC2DtkqZV0=w@mail.gmail.com>
 <CAD4oTHFhp1qUfFhLeCh_jBXBYH30mDjvFSeGhW5OBbnkC1t13g@mail.gmail.com>
 <CAB8pepzNadqgsHP-tbhAaBj5RNK12hFQHChQiRG=36me6G-Ybg@mail.gmail.com>
Message-ID: <CAD4oTHHfZS915ggJCg9w-PLWgdu+pqE5TPQ2f7xFaB8Xw7EXTw@mail.gmail.com>

On Tue, Mar 5, 2019 at 12:41 PM Abs Spurdle <spurdle.a at gmail.com> wrote:

>
>
> On Tue, Mar 5, 2019 at 12:52 PM Gabriel Becker <gabembecker at gmail.com>
> wrote:
>
>> I have thought about and have (somewhere "up near the top" of my todo
>> list) prototyping a preprocessor for R, and I have relevant code that emits
>> (transpiles, in a way) structured comments into S4 code in
>> https://github.com/gmbecker/S4Coffee.
>>
>> All that said, until/unless the preprocessor is officially part of the R
>> CMD build step, what putting code like that on CRAN would look like is you
>> keep the raw code in /inst somewhere, and you do the emitting of R code
>> into R/ before building the tarball for submitting. And if you do that CRAN
>> will hav eno problem accepting such a package provided it isn't disallowed
>> in some other way.
>>
>
> I think that I would prefer to generate (and run) the R code during
> .onLoad(), rather than pre-generate it and put it in the R subdirectory.
> If it's in the R subdirectory, then we have two copies of the same thing,
> plus it would need to be documented using the rd format, which I would like
> to minimize, in favor other documentation formats.
> Which is where CRAN may not like it...
>

Hmm, I disagree with this pretty strongly. From a debugging perspective, I
want the source templates available, at least optionally, in addition to
the resulting R code.

Also, while not on the CRAN team, large amounts of code generation during
.onLoad seems liek it would be out of bounds, as I'm pretty certain that
would bypass all of the R CMD check tests, which seems like it would be a
nonon.


> In regards to S4Coffee, it sounds promising.
> I hope you get in finished in the near future.
> And I will take a closer look at it.
>

It does work now, I think, but I may get back to it and do some more. If
you take a look, definitely let me know what you think and if you feel like
anything is missing/could do with a different approach/syntax in your
opinion.  Great to hear that . someone is interested in it, that's
certainly motivating :).

Best,
~G

>
>

	[[alternative HTML version deleted]]


From g@bembecker @end|ng |rom gm@||@com  Tue Mar  5 23:33:28 2019
From: g@bembecker @end|ng |rom gm@||@com (Gabriel Becker)
Date: Tue, 5 Mar 2019 14:33:28 -0800
Subject: [Rd] as.Date(Inf) displays as 'NA' but is actually 'Inf'
In-Reply-To: <6d06f8f8-828b-4510-6024-908bc6f5336f@rwhite.no>
References: <6d06f8f8-828b-4510-6024-908bc6f5336f@rwhite.no>
Message-ID: <CAD4oTHF0m1taDehMuo6B01L0SyFxjRGBJfFr55QSn0cLfkfuMQ@mail.gmail.com>

Richard,

Well others may chime in here, but from a mathematical point of view, the
concept of "infinite days from right now" is well-defined, so it maybe a
"valid" date in that sense, but what day and month it will be (year will be
Inf) are indeterminate/not well defined. Those are rightfully, NA, it
seems?

I mean you could disallow dates to take Inf at all, ever. I don't feel
strongly one way or the other about that, personally. That said, if inf
dates are allowed, its not clear to me that displaying the "Formatted" date
string as NA, even if the value isn't,  is wrong given it can't be
determined for that "date" is. It could be displayed differently, I
suppose, but all the ones I can think of off the top of my head would be
problematic and probably break lots of formatted-dates parsing code out
there in the wild (and in R, I would guess). Things like displaying
"Inf-NA-NA", or just "Inf". Neither of those are going to handle a
read-write round-trip well, I think.

So my personal don't-really-have-a-hat-in-the-ring opinion would be to
either leave it as is, or force as.Date(Inf, bla) to actually be NA.

Best,
~G

On Tue, Mar 5, 2019 at 12:06 PM Richard White <w at rwhite.no> wrote:

> Hi,
>
> I think I've discovered a bug in base R.
>
> Basically, when using 'Inf' as as 'Date', is is visually displayed as
> 'NA', but R still treats it as 'Inf'. So it is very confusing to work
> with, and can easily lead to errors:
>
> # Visually displays as NA
>  > as.Date(Inf, origin="2018-01-01")
> [1] NA
>
> # Visually displays as NA
>  > str(as.Date(Inf, origin="2018-01-01"))
> Date[1:1], format: NA
>
> # Is NOT NA
>  > is.na(as.Date(Inf, origin="2018-01-01"))
> [1] FALSE
>
> # Is still Inf
>  > is.infinite(as.Date(Inf, origin="2018-01-01"))
> [1] TRUE
>
> This gets really problematic when you are collapsing dates over groups
> and you want to find the first date of a group. Because min() returns
> Inf if there is no data:
>
> # Visually displays as NA
>  > as.Date(min(), origin="2018-01-01")
> [1] NA
> Warning message: In min() : no non-missing arguments to min; returning Inf
>
> # Visually displays as NA
>  > str(as.Date(min(), origin="2018-01-01"))
> Date[1:1], format: NA
> Warning message: In min() : no non-missing arguments to min; returning Inf
>
> # Is not NA
>  > is.na(as.Date(min(), origin="2018-01-01"))
> [1] FALSE
> Warning message: In min() : no non-missing arguments to min; returning Inf
>
> # This is bad!
>  > as.Date(min(), origin="2018-01-01") > "2018-01-01"
> [1] TRUE
> Warning message: In min() : no non-missing arguments to min; returning Inf
>
> Here is my sessionInfo():
>
>  > sessionInfo()
> R version 3.5.0 (2018-04-23)
> Platform: x86_64-pc-linux-gnu (64-bit)
> Running under: Debian GNU/Linux 9 (stretch)
> Matrix products: default
> BLAS: /usr/lib/openblas-base/libblas.so.3
> LAPACK: /usr/lib/libopenblasp-r0.2.19.so
>
> locale:
> [1] LC_CTYPE=C.UTF-8 LC_NUMERIC=C LC_TIME=C.UTF-8 LC_COLLATE=C.UTF-8
> LC_MONETARY=C.UTF-8
> [6] LC_MESSAGES=C LC_PAPER=C.UTF-8 LC_NAME=C LC_ADDRESS=C LC_TELEPHONE=C
> [11] LC_MEASUREMENT=C.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats graphics grDevices utils datasets methods base loaded via a
> namespace (and not attached):
> [1] compiler_3.5.0 tools_3.5.0 yaml_2.1.19
>
>  > Sys.getlocale()
> [1]
>
> "LC_CTYPE=C.UTF-8;LC_NUMERIC=C;LC_TIME=C.UTF-8;LC_COLLATE=C.UTF-8;LC_MONETARY=C.UTF-8;LC_MESSAGES=C;LC_PAPER=C.UTF-8;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=C.UTF-8;LC_IDENTIFICATION=C"
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From wdun|@p @end|ng |rom t|bco@com  Tue Mar  5 23:49:38 2019
From: wdun|@p @end|ng |rom t|bco@com (William Dunlap)
Date: Tue, 5 Mar 2019 14:49:38 -0800
Subject: [Rd] as.Date(Inf) displays as 'NA' but is actually 'Inf'
In-Reply-To: <CAD4oTHF0m1taDehMuo6B01L0SyFxjRGBJfFr55QSn0cLfkfuMQ@mail.gmail.com>
References: <6d06f8f8-828b-4510-6024-908bc6f5336f@rwhite.no>
 <CAD4oTHF0m1taDehMuo6B01L0SyFxjRGBJfFr55QSn0cLfkfuMQ@mail.gmail.com>
Message-ID: <CAF8bMcbHM4DxHqDWkUCUCZYeq1O6Yd5CGXqR+gmLKLE=w8c9Fw@mail.gmail.com>

format.Date runs into trouble long before Inf:
  > as.Date("2018-03-05") + c(2147466052, 2147466053)
  [1] "5881580-07-11"  "-5877641-06-23"

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Tue, Mar 5, 2019 at 2:33 PM Gabriel Becker <gabembecker at gmail.com> wrote:

> Richard,
>
> Well others may chime in here, but from a mathematical point of view, the
> concept of "infinite days from right now" is well-defined, so it maybe a
> "valid" date in that sense, but what day and month it will be (year will be
> Inf) are indeterminate/not well defined. Those are rightfully, NA, it
> seems?
>
> I mean you could disallow dates to take Inf at all, ever. I don't feel
> strongly one way or the other about that, personally. That said, if inf
> dates are allowed, its not clear to me that displaying the "Formatted" date
> string as NA, even if the value isn't,  is wrong given it can't be
> determined for that "date" is. It could be displayed differently, I
> suppose, but all the ones I can think of off the top of my head would be
> problematic and probably break lots of formatted-dates parsing code out
> there in the wild (and in R, I would guess). Things like displaying
> "Inf-NA-NA", or just "Inf". Neither of those are going to handle a
> read-write round-trip well, I think.
>
> So my personal don't-really-have-a-hat-in-the-ring opinion would be to
> either leave it as is, or force as.Date(Inf, bla) to actually be NA.
>
> Best,
> ~G
>
> On Tue, Mar 5, 2019 at 12:06 PM Richard White <w at rwhite.no> wrote:
>
> > Hi,
> >
> > I think I've discovered a bug in base R.
> >
> > Basically, when using 'Inf' as as 'Date', is is visually displayed as
> > 'NA', but R still treats it as 'Inf'. So it is very confusing to work
> > with, and can easily lead to errors:
> >
> > # Visually displays as NA
> >  > as.Date(Inf, origin="2018-01-01")
> > [1] NA
> >
> > # Visually displays as NA
> >  > str(as.Date(Inf, origin="2018-01-01"))
> > Date[1:1], format: NA
> >
> > # Is NOT NA
> >  > is.na(as.Date(Inf, origin="2018-01-01"))
> > [1] FALSE
> >
> > # Is still Inf
> >  > is.infinite(as.Date(Inf, origin="2018-01-01"))
> > [1] TRUE
> >
> > This gets really problematic when you are collapsing dates over groups
> > and you want to find the first date of a group. Because min() returns
> > Inf if there is no data:
> >
> > # Visually displays as NA
> >  > as.Date(min(), origin="2018-01-01")
> > [1] NA
> > Warning message: In min() : no non-missing arguments to min; returning
> Inf
> >
> > # Visually displays as NA
> >  > str(as.Date(min(), origin="2018-01-01"))
> > Date[1:1], format: NA
> > Warning message: In min() : no non-missing arguments to min; returning
> Inf
> >
> > # Is not NA
> >  > is.na(as.Date(min(), origin="2018-01-01"))
> > [1] FALSE
> > Warning message: In min() : no non-missing arguments to min; returning
> Inf
> >
> > # This is bad!
> >  > as.Date(min(), origin="2018-01-01") > "2018-01-01"
> > [1] TRUE
> > Warning message: In min() : no non-missing arguments to min; returning
> Inf
> >
> > Here is my sessionInfo():
> >
> >  > sessionInfo()
> > R version 3.5.0 (2018-04-23)
> > Platform: x86_64-pc-linux-gnu (64-bit)
> > Running under: Debian GNU/Linux 9 (stretch)
> > Matrix products: default
> > BLAS: /usr/lib/openblas-base/libblas.so.3
> > LAPACK: /usr/lib/libopenblasp-r0.2.19.so
> >
> > locale:
> > [1] LC_CTYPE=C.UTF-8 LC_NUMERIC=C LC_TIME=C.UTF-8 LC_COLLATE=C.UTF-8
> > LC_MONETARY=C.UTF-8
> > [6] LC_MESSAGES=C LC_PAPER=C.UTF-8 LC_NAME=C LC_ADDRESS=C LC_TELEPHONE=C
> > [11] LC_MEASUREMENT=C.UTF-8 LC_IDENTIFICATION=C
> >
> > attached base packages:
> > [1] stats graphics grDevices utils datasets methods base loaded via a
> > namespace (and not attached):
> > [1] compiler_3.5.0 tools_3.5.0 yaml_2.1.19
> >
> >  > Sys.getlocale()
> > [1]
> >
> >
> "LC_CTYPE=C.UTF-8;LC_NUMERIC=C;LC_TIME=C.UTF-8;LC_COLLATE=C.UTF-8;LC_MONETARY=C.UTF-8;LC_MESSAGES=C;LC_PAPER=C.UTF-8;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=C.UTF-8;LC_IDENTIFICATION=C"
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From w @end|ng |rom rwh|te@no  Wed Mar  6 06:54:51 2019
From: w @end|ng |rom rwh|te@no (Richard White)
Date: Wed, 6 Mar 2019 07:54:51 +0200
Subject: [Rd] as.Date(Inf) displays as 'NA' but is actually 'Inf'
In-Reply-To: <CAD4oTHF0m1taDehMuo6B01L0SyFxjRGBJfFr55QSn0cLfkfuMQ@mail.gmail.com>
References: <6d06f8f8-828b-4510-6024-908bc6f5336f@rwhite.no>
 <CAD4oTHF0m1taDehMuo6B01L0SyFxjRGBJfFr55QSn0cLfkfuMQ@mail.gmail.com>
Message-ID: <939a8ef7-7020-4247-24b5-c9d59b87a9b5@rwhite.no>

Hi Gabriel,

The point is that it *visually* displays as NA, but is.na() still 
responds as FALSE.

When I (and I am sure many people) see an NA, we then use is.na(). If we 
see Inf displayed, we then use is.infinite(). With as.Date() this breaks 
down.

I'm not arguing that as.Date(Inf) should be coerced to NA. I'm arguing 
that as.Date(Inf) should be *visually* displayed as Inf (i.e. the 
truth!). I doubt this would break any existing code, because 
as.Date(Inf) acts as Inf in every way possible, except for when you 
visually look at the output printed on the screen.

William - For all the other Date bugs, they don't visually display false 
information about the variable's contents. They might give wrong output, 
but the output displayed is what exists inside the variable.

If we can't trust the R console to display the truth, then we are in a 
lot of trouble.

 > a <- as.Date(Inf, origin="2018-01-01")
 > a
[1] NA
 > is.na(a)
[1] FALSE

Richard

Gabriel Becker wrote on 06/03/2019 00:33:
> Richard,
>
> Well others may chime in here, but from a mathematical point of view, 
> the concept of "infinite days from right now" is well-defined, so it 
> maybe a "valid" date in that sense, but what day and month it will be 
> (year will be Inf) are indeterminate/not well defined. Those are 
> rightfully, NA, it seems?
>
> I mean you could disallow dates to take Inf at all, ever. I don't feel 
> strongly one way or the other about that, personally. That said, if 
> inf dates are allowed, its not clear to me that displaying the 
> "Formatted" date string as NA, even if the value isn't,? is wrong 
> given it can't be determined for that "date" is. It could be displayed 
> differently, I suppose, but all the ones I can think of off the top of 
> my head would be problematic and probably break lots of 
> formatted-dates parsing code out there in the wild (and in R, I would 
> guess). Things like displaying "Inf-NA-NA", or just "Inf". Neither of 
> those are going to handle a read-write round-trip well, I think.
>
> So my personal don't-really-have-a-hat-in-the-ring opinion would be to 
> either leave it as is, or force as.Date(Inf, bla) to actually be NA.
>
> Best,
> ~G
>
> On Tue, Mar 5, 2019 at 12:06 PM Richard White <w at rwhite.no 
> <mailto:w at rwhite.no>> wrote:
>
>     Hi,
>
>     I think I've discovered a bug in base R.
>
>     Basically, when using 'Inf' as as 'Date', is is visually displayed as
>     'NA', but R still treats it as 'Inf'. So it is very confusing to work
>     with, and can easily lead to errors:
>
>     # Visually displays as NA
>     ?> as.Date(Inf, origin="2018-01-01")
>     [1] NA
>
>     # Visually displays as NA
>     ?> str(as.Date(Inf, origin="2018-01-01"))
>     Date[1:1], format: NA
>
>     # Is NOT NA
>     ?> is.na <http://is.na>(as.Date(Inf, origin="2018-01-01"))
>     [1] FALSE
>
>     # Is still Inf
>     ?> is.infinite(as.Date(Inf, origin="2018-01-01"))
>     [1] TRUE
>
>     This gets really problematic when you are collapsing dates over
>     groups
>     and you want to find the first date of a group. Because min() returns
>     Inf if there is no data:
>
>     # Visually displays as NA
>     ?> as.Date(min(), origin="2018-01-01")
>     [1] NA
>     Warning message: In min() : no non-missing arguments to min;
>     returning Inf
>
>     # Visually displays as NA
>     ?> str(as.Date(min(), origin="2018-01-01"))
>     Date[1:1], format: NA
>     Warning message: In min() : no non-missing arguments to min;
>     returning Inf
>
>     # Is not NA
>     ?> is.na <http://is.na>(as.Date(min(), origin="2018-01-01"))
>     [1] FALSE
>     Warning message: In min() : no non-missing arguments to min;
>     returning Inf
>
>     # This is bad!
>     ?> as.Date(min(), origin="2018-01-01") > "2018-01-01"
>     [1] TRUE
>     Warning message: In min() : no non-missing arguments to min;
>     returning Inf
>
>     Here is my sessionInfo():
>
>     ?> sessionInfo()
>     R version 3.5.0 (2018-04-23)
>     Platform: x86_64-pc-linux-gnu (64-bit)
>     Running under: Debian GNU/Linux 9 (stretch)
>     Matrix products: default
>     BLAS: /usr/lib/openblas-base/libblas.so.3
>     LAPACK: /usr/lib/libopenblasp-r0.2.19.so
>     <http://libopenblasp-r0.2.19.so>
>
>     locale:
>     [1] LC_CTYPE=C.UTF-8 LC_NUMERIC=C LC_TIME=C.UTF-8 LC_COLLATE=C.UTF-8
>     LC_MONETARY=C.UTF-8
>     [6] LC_MESSAGES=C LC_PAPER=C.UTF-8 LC_NAME=C LC_ADDRESS=C
>     LC_TELEPHONE=C
>     [11] LC_MEASUREMENT=C.UTF-8 LC_IDENTIFICATION=C
>
>     attached base packages:
>     [1] stats graphics grDevices utils datasets methods base loaded via a
>     namespace (and not attached):
>     [1] compiler_3.5.0 tools_3.5.0 yaml_2.1.19
>
>     ?> Sys.getlocale()
>     [1]
>     "LC_CTYPE=C.UTF-8;LC_NUMERIC=C;LC_TIME=C.UTF-8;LC_COLLATE=C.UTF-8;LC_MONETARY=C.UTF-8;LC_MESSAGES=C;LC_PAPER=C.UTF-8;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=C.UTF-8;LC_IDENTIFICATION=C"
>
>     ______________________________________________
>     R-devel at r-project.org <mailto:R-devel at r-project.org> mailing list
>     https://stat.ethz.ch/mailman/listinfo/r-devel
>


	[[alternative HTML version deleted]]


From g@bembecker @end|ng |rom gm@||@com  Wed Mar  6 07:01:37 2019
From: g@bembecker @end|ng |rom gm@||@com (Gabriel Becker)
Date: Tue, 5 Mar 2019 22:01:37 -0800
Subject: [Rd] as.Date(Inf) displays as 'NA' but is actually 'Inf'
In-Reply-To: <939a8ef7-7020-4247-24b5-c9d59b87a9b5@rwhite.no>
References: <6d06f8f8-828b-4510-6024-908bc6f5336f@rwhite.no>
 <CAD4oTHF0m1taDehMuo6B01L0SyFxjRGBJfFr55QSn0cLfkfuMQ@mail.gmail.com>
 <939a8ef7-7020-4247-24b5-c9d59b87a9b5@rwhite.no>
Message-ID: <CAD4oTHFJwqC3VhVBuv1CnWcuM=z7iLgFB-JSoE9Cdqsf1E84eg@mail.gmail.com>

On Tue, Mar 5, 2019 at 9:54 PM Richard White <w at rwhite.no> wrote:

> Hi Gabriel,
>
> The point is that it *visually* displays as NA, but is.na() still
> responds as FALSE.
>
> When I (and I am sure many people) see an NA, we then use is.na(). If we
> see Inf displayed, we then use is.infinite(). With as.Date() this breaks
> down.
>
> I'm not arguing that as.Date(Inf) should be coerced to NA. I'm arguing
> that as.Date(Inf) should be *visually* displayed as Inf (i.e. the truth!).
> I doubt this would break any existing code, because as.Date(Inf) acts as
> Inf in every way possible, except for when you visually look at the output
> printed on the screen.
>
> William - For all the other Date bugs, they don't visually display false
> information about the variable's contents. They might give wrong output,
> but the output displayed is what exists inside the variable.
>
> If we can't trust the R console to display the truth, then we are in a lot
> of trouble.
>

Well, I think it (subtly) actually is the truth though. What is displayed
when you print a date is the *formatted date string, not the numeric value
stored within the date*. The formatted date string of the infinite date, is
actually, correctly,  NA, because, for the reasons I pointed out in my last
post, it is indeterminate.

> x = as.Date(Inf, origin = "2018-01-01")

> format(x)

[1] NA


So that is what is happening, both technically, but also conceptually. For
the record, I'd be surprised by that too, but I think its a situation of
pieces working correctly individually, but together having a correct but
unintuitive behavior.

Others may feel differently though, thats just my read on it.

Best,
~G



> > a <- as.Date(Inf, origin="2018-01-01")
> > a
> [1] NA
> > is.na(a)
> [1] FALSE
>
> Richard
>
> Gabriel Becker wrote on 06/03/2019 00:33:
>
> Richard,
>
> Well others may chime in here, but from a mathematical point of view, the
> concept of "infinite days from right now" is well-defined, so it maybe a
> "valid" date in that sense, but what day and month it will be (year will be
> Inf) are indeterminate/not well defined. Those are rightfully, NA, it
> seems?
>
> I mean you could disallow dates to take Inf at all, ever. I don't feel
> strongly one way or the other about that, personally. That said, if inf
> dates are allowed, its not clear to me that displaying the "Formatted" date
> string as NA, even if the value isn't,  is wrong given it can't be
> determined for that "date" is. It could be displayed differently, I
> suppose, but all the ones I can think of off the top of my head would be
> problematic and probably break lots of formatted-dates parsing code out
> there in the wild (and in R, I would guess). Things like displaying
> "Inf-NA-NA", or just "Inf". Neither of those are going to handle a
> read-write round-trip well, I think.
>
> So my personal don't-really-have-a-hat-in-the-ring opinion would be to
> either leave it as is, or force as.Date(Inf, bla) to actually be NA.
>
> Best,
> ~G
>
> On Tue, Mar 5, 2019 at 12:06 PM Richard White <w at rwhite.no> wrote:
>
>> Hi,
>>
>> I think I've discovered a bug in base R.
>>
>> Basically, when using 'Inf' as as 'Date', is is visually displayed as
>> 'NA', but R still treats it as 'Inf'. So it is very confusing to work
>> with, and can easily lead to errors:
>>
>> # Visually displays as NA
>>  > as.Date(Inf, origin="2018-01-01")
>> [1] NA
>>
>> # Visually displays as NA
>>  > str(as.Date(Inf, origin="2018-01-01"))
>> Date[1:1], format: NA
>>
>> # Is NOT NA
>>  > is.na(as.Date(Inf, origin="2018-01-01"))
>> [1] FALSE
>>
>> # Is still Inf
>>  > is.infinite(as.Date(Inf, origin="2018-01-01"))
>> [1] TRUE
>>
>> This gets really problematic when you are collapsing dates over groups
>> and you want to find the first date of a group. Because min() returns
>> Inf if there is no data:
>>
>> # Visually displays as NA
>>  > as.Date(min(), origin="2018-01-01")
>> [1] NA
>> Warning message: In min() : no non-missing arguments to min; returning Inf
>>
>> # Visually displays as NA
>>  > str(as.Date(min(), origin="2018-01-01"))
>> Date[1:1], format: NA
>> Warning message: In min() : no non-missing arguments to min; returning Inf
>>
>> # Is not NA
>>  > is.na(as.Date(min(), origin="2018-01-01"))
>> [1] FALSE
>> Warning message: In min() : no non-missing arguments to min; returning Inf
>>
>> # This is bad!
>>  > as.Date(min(), origin="2018-01-01") > "2018-01-01"
>> [1] TRUE
>> Warning message: In min() : no non-missing arguments to min; returning Inf
>>
>> Here is my sessionInfo():
>>
>>  > sessionInfo()
>> R version 3.5.0 (2018-04-23)
>> Platform: x86_64-pc-linux-gnu (64-bit)
>> Running under: Debian GNU/Linux 9 (stretch)
>> Matrix products: default
>> BLAS: /usr/lib/openblas-base/libblas.so.3
>> LAPACK: /usr/lib/libopenblasp-r0.2.19.so
>>
>> locale:
>> [1] LC_CTYPE=C.UTF-8 LC_NUMERIC=C LC_TIME=C.UTF-8 LC_COLLATE=C.UTF-8
>> LC_MONETARY=C.UTF-8
>> [6] LC_MESSAGES=C LC_PAPER=C.UTF-8 LC_NAME=C LC_ADDRESS=C LC_TELEPHONE=C
>> [11] LC_MEASUREMENT=C.UTF-8 LC_IDENTIFICATION=C
>>
>> attached base packages:
>> [1] stats graphics grDevices utils datasets methods base loaded via a
>> namespace (and not attached):
>> [1] compiler_3.5.0 tools_3.5.0 yaml_2.1.19
>>
>>  > Sys.getlocale()
>> [1]
>>
>> "LC_CTYPE=C.UTF-8;LC_NUMERIC=C;LC_TIME=C.UTF-8;LC_COLLATE=C.UTF-8;LC_MONETARY=C.UTF-8;LC_MESSAGES=C;LC_PAPER=C.UTF-8;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=C.UTF-8;LC_IDENTIFICATION=C"
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
>

	[[alternative HTML version deleted]]


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Wed Mar  6 09:50:18 2019
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Wed, 6 Mar 2019 09:50:18 +0100
Subject: [Rd] stopifnot
In-Reply-To: <23678.54840.452841.851948@stat.math.ethz.ch>
References: <625268441.9734255.1551806960886.ref@mail.yahoo.com>
 <625268441.9734255.1551806960886@mail.yahoo.com>
 <23678.54840.452841.851948@stat.math.ethz.ch>
Message-ID: <23679.35274.508559.20674@stat.math.ethz.ch>

>>>>> Martin Maechler 
>>>>>     on Tue, 5 Mar 2019 21:04:08 +0100 writes:

>>>>> Suharto Anggono Suharto Anggono 
>>>>>     on Tue, 5 Mar 2019 17:29:20 +0000 writes:

    >> Another possible shortcut definition:

    >> assert <- function(exprs)
    >> do.call("stopifnot", list(exprs = substitute(exprs), local = parent.frame()))

    > Thank you.  I think this is mostly a matter of taste, but I
    > liked your version using eval() & substitute() a bit more.  For
    > me, do.call() is a heavy hammer I only like to use when needed..

    > Or would there be advantages of this version?
    > Indeed (as you note below) one important consideration is the exact
    > message that is produced when one assertion fails.

    >> After thinking again, I propose to use
    >> ??? ? ? stop(simpleError(msg, call = if(p <- sys.parent()) sys.call(p)))

    > That would of course be considerably simpler indeed,  part "2 a" of these:

    >> - It seems that the call is the call of the frame where stopifnot(...) is evaluated. Because that is the correct context, I think it is good.
    >> - It is simpler and also works for call that originally comes from stopifnot(exprs=*) .

    >> - It allows shortcut ('assert') to have the same call in error message as stopifnot(exprs=*) .

    > That may be another good reason in addition to code simplicity.

    > I will have to see if this extra simplification does not loose
    > more than I'd want.


    >> Another thing: Is it intended that
    >> do.call("stopifnot", list(exprs = expression()))
    >> evaluates each element of the expression object?

    > ??  I really don't know.  Even though such a case looks
    > "unusual" (to say the least), in principle I'd like that
    > expressions are evaluated sequentially until the first non-TRUE
    > result.  With a concrete example, I do like what we have
    > currently in unchanged R-devel, but also in R 3.5.x, i.e., in
    > the following, not any "NOT GOOD" should pop up:

    >> stopifnot(exprs = expression(1==1, 2 < 1, stop("NOT GOOD!\n")))
    > Error: 2 < 1 is not TRUE
    >> do.call(stopifnot, list(exprs = expression(1==1, 2 < 1, stop("NOT GOOD!\n"))))
    > Error in do.call(stopifnot, list(exprs = expression(1 == 1, 2 < 1, cat("NOT GOOD!\n")))) : 
    > 2 < 1 is not TRUE
    >> 

    > Hmm, it seems I do not understand what you ask above in your
    > "Another thing: .."


    >> If so, maybe add a case for 'cl', like
    >> ??? ? ? else if(is.expression(exprs))
    >> ??? ??? as.call(c(quote(expression), exprs))

    > that seems simple indeed, but at the moment, I cannot see one example
    > where it makes a difference ... or then I'm "blind" .. ???

    > Best,
    > Martin

Some more testing of examples lead me to keep the more
sophisticated "computation" of 'n'  for the  sys.call(n-1).

Main reason:  If one of the expression is not all TRUE, I really
don't want to see the full 'stopifnot(....)' call in the printed
error message.
I do want to encourage that  stopifnot()  asserts many things
and so its own call should really not be shown.

Also I really wanted to commit something, notably also fixing
the   stopifnot(exprs = T)  bug,  so R-devel (rev >= 76203 ) now
contains a simpler and much faster  stopifnot() than previously
[and than the R 3.5.x series].

I agree that the final decisions on getting a call (or not --
which was a very good idea by you!) and which parent's call
should be used  may deserve some future tinkering..

Thank you again, Suharto Anggono,
for your contributions to making R better !

Martin


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Wed Mar  6 11:51:33 2019
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Wed, 6 Mar 2019 11:51:33 +0100
Subject: [Rd] as.Date(Inf) displays as 'NA' but is actually 'Inf'
In-Reply-To: <CAD4oTHFJwqC3VhVBuv1CnWcuM=z7iLgFB-JSoE9Cdqsf1E84eg@mail.gmail.com>
References: <6d06f8f8-828b-4510-6024-908bc6f5336f@rwhite.no>
 <CAD4oTHF0m1taDehMuo6B01L0SyFxjRGBJfFr55QSn0cLfkfuMQ@mail.gmail.com>
 <939a8ef7-7020-4247-24b5-c9d59b87a9b5@rwhite.no>
 <CAD4oTHFJwqC3VhVBuv1CnWcuM=z7iLgFB-JSoE9Cdqsf1E84eg@mail.gmail.com>
Message-ID: <23679.42549.903608.101073@stat.math.ethz.ch>

>>>>> Gabriel Becker 
>>>>>     on Tue, 5 Mar 2019 22:01:37 -0800 writes:

    > On Tue, Mar 5, 2019 at 9:54 PM Richard White <w at rwhite.no> wrote:
    >> Hi Gabriel,
    >> 
    >> The point is that it *visually* displays as NA, but is.na() still
    >> responds as FALSE.
    >> 
    >> When I (and I am sure many people) see an NA, we then use is.na(). If we
    >> see Inf displayed, we then use is.infinite(). With as.Date() this breaks
    >> down.
    >> 
    >> I'm not arguing that as.Date(Inf) should be coerced to NA. I'm arguing
    >> that as.Date(Inf) should be *visually* displayed as Inf (i.e. the truth!).
    >> I doubt this would break any existing code, because as.Date(Inf) acts as
    >> Inf in every way possible, except for when you visually look at the output
    >> printed on the screen.
    >> 
    >> William - For all the other Date bugs, they don't visually display false
    >> information about the variable's contents. They might give wrong output,
    >> but the output displayed is what exists inside the variable.
    >> 
    >> If we can't trust the R console to display the truth, then we are in a lot
    >> of trouble.
    >> 

    > Well, I think it (subtly) actually is the truth though. What is displayed
    > when you print a date is the *formatted date string, not the numeric value
    > stored within the date*. The formatted date string of the infinite date, is
    > actually, correctly,  NA, because, for the reasons I pointed out in my last
    > post, it is indeterminate.

    >> x = as.Date(Inf, origin = "2018-01-01")

    >> format(x)

    > [1] NA


    > So that is what is happening, both technically, but also conceptually. For
    > the record, I'd be surprised by that too, but I think its a situation of
    > pieces working correctly individually, but together having a correct but
    > unintuitive behavior.

    > Others may feel differently though, thats just my read on it.

    > Best,
    > ~G

Thank you Richard and Gabe and Bill (Dunlap),
I agree with both of you that the behavior is suprising (to > 99.9% of useRs).

Gabe very nicely explains how it happens and also why it does
make some sense *and* that a change may be problematic.

However, the "principle of least surprise" I've learned very long ago
from Doug Bates is good "guiding" principle for software design
(if you allow to weight it with other principles, etc).

Here is a bit of slightly more principled code to show the
phenomenon, including the fact noticed by Bill that both
as.Date() and format.Date() should probably be tweaked such as
to signal warnings (e.g. on integer overflow for too large numbers).

## -------------------------------------------------------------------------
xDates <- lapply(c(-Inf, Inf, NA, NaN,
                   1e9, 4e9, 1e100, .Machine$double.xmax),
                 as.Date, origin = "2000-01-01")
str(xDates) # --> first 4 *all* show as  NA
sapply(xDates, is.na) # the two +-Inf are not NA
(f.D <- sapply(xDates, format))# 1..4: NA, then "negative" but all the same (?!)
stopifnot(is.na(f.D)[1:4]) # the formats (of 1..4) *are* all NA !!
## show their true internals -- still contain what was put there :
for(d in xDates) dput(d)
## -------------------------------------------------------------------------

produces

> xDates <- lapply(c(-Inf, Inf, NA, NaN,
+                    1e9, 4e9, 1e100, .Machine$double.xmax),
+                  as.Date, origin = "2000-01-01")
> str(xDates) # --> first 4 *all* show as  NA
List of 8
 $ : Date[1:1], format: NA
 $ : Date[1:1], format: NA
 $ : Date[1:1], format: NA
 $ : Date[1:1], format: NA
 $ : Date[1:1], format: "2739907-01-04"
 $ : Date[1:1], format: "-5877641-06-23"
 $ : Date[1:1], format: "-5877641-06-23"
 $ : Date[1:1], format: "-5877641-06-23"
> sapply(xDates, is.na) # the two +-Inf are not NA
[1] FALSE FALSE  TRUE  TRUE FALSE FALSE FALSE FALSE
> (f.D <- sapply(xDates, format))# 1..4: NA, then "negative" but all the same (?!)
[1] NA               NA               NA               NA               "2739907-01-04"  "-5877641-06-23"
[7] "-5877641-06-23" "-5877641-06-23"
> stopifnot(is.na(f.D)[1:4]) # the formats (of 1..4) *are* all NA !!
> ## show their true internals -- still contain what was put there :
> for(d in xDates) dput(d)
structure(-Inf, class = "Date")
structure(Inf, class = "Date")
structure(NA_real_, class = "Date")
structure(NaN, class = "Date")
structure(1000010957, class = "Date")
structure(4000010957, class = "Date")
structure(1e+100, class = "Date")
structure(1.79769313486232e+308, class = "Date")
> 

---------

What if we left NA ( NA_character_ specifically ) as result for format(),
but changed the print() method so it gives better information
here ?

I would argue that -Inf and Inf should show differently than
true NA's or NaN's .. not the least because infinitely past and
infinitely into the future are different concepts.

Martin Maechler
ETH Zurich (and R Core team)


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Wed Mar  6 12:58:00 2019
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Wed, 6 Mar 2019 12:58:00 +0100
Subject: [Rd] as.Date(Inf) displays as 'NA' but is actually 'Inf'
In-Reply-To: <23679.42549.903608.101073@stat.math.ethz.ch>
References: <6d06f8f8-828b-4510-6024-908bc6f5336f@rwhite.no>
 <CAD4oTHF0m1taDehMuo6B01L0SyFxjRGBJfFr55QSn0cLfkfuMQ@mail.gmail.com>
 <939a8ef7-7020-4247-24b5-c9d59b87a9b5@rwhite.no>
 <CAD4oTHFJwqC3VhVBuv1CnWcuM=z7iLgFB-JSoE9Cdqsf1E84eg@mail.gmail.com>
 <23679.42549.903608.101073@stat.math.ethz.ch>
Message-ID: <23679.46536.590846.622411@stat.math.ethz.ch>

>>>>> Martin Maechler 
>>>>>     on Wed, 6 Mar 2019 11:51:33 +0100 writes:

>>>>> Gabriel Becker 
>>>>>     on Tue, 5 Mar 2019 22:01:37 -0800 writes:

    >> On Tue, Mar 5, 2019 at 9:54 PM Richard White <w at rwhite.no> wrote:
    >>> Hi Gabriel,
    >>> 
    >>> The point is that it *visually* displays as NA, but is.na() still
    >>> responds as FALSE.
    >>> 
    >>> When I (and I am sure many people) see an NA, we then use is.na(). If we
    >>> see Inf displayed, we then use is.infinite(). With as.Date() this breaks
    >>> down.
    >>> 
    >>> I'm not arguing that as.Date(Inf) should be coerced to NA. I'm arguing
    >>> that as.Date(Inf) should be *visually* displayed as Inf (i.e. the truth!).
    >>> I doubt this would break any existing code, because as.Date(Inf) acts as
    >>> Inf in every way possible, except for when you visually look at the output
    >>> printed on the screen.
    >>> 
    >>> William - For all the other Date bugs, they don't visually display false
    >>> information about the variable's contents. They might give wrong output,
    >>> but the output displayed is what exists inside the variable.
    >>> 
    >>> If we can't trust the R console to display the truth, then we are in a lot
    >>> of trouble.
    >>> 

    >> Well, I think it (subtly) actually is the truth though. What is displayed
    >> when you print a date is the *formatted date string, not the numeric value
    >> stored within the date*. The formatted date string of the infinite date, is
    >> actually, correctly,  NA, because, for the reasons I pointed out in my last
    >> post, it is indeterminate.

    >>> x = as.Date(Inf, origin = "2018-01-01")

    >>> format(x)

    >> [1] NA


    >> So that is what is happening, both technically, but also conceptually. For
    >> the record, I'd be surprised by that too, but I think its a situation of
    >> pieces working correctly individually, but together having a correct but
    >> unintuitive behavior.

    >> Others may feel differently though, thats just my read on it.

    >> Best,
    >> ~G

    > Thank you Richard and Gabe and Bill (Dunlap),
    > I agree with both of you that the behavior is suprising (to > 99.9% of useRs).

    > Gabe very nicely explains how it happens and also why it does
    > make some sense *and* that a change may be problematic.

    > However, the "principle of least surprise" I've learned very long ago
    > from Doug Bates is good "guiding" principle for software design
    > (if you allow to weight it with other principles, etc).

    > Here is a bit of slightly more principled code to show the
    > phenomenon, including the fact noticed by Bill that both
    > as.Date() and format.Date() should probably be tweaked such as
    > to signal warnings (e.g. on integer overflow for too large numbers).

    > ## -------------------------------------------------------------------------
    > xDates <- lapply(c(-Inf, Inf, NA, NaN,
    > 1e9, 4e9, 1e100, .Machine$double.xmax),
    > as.Date, origin = "2000-01-01")
    > str(xDates) # --> first 4 *all* show as  NA
    > sapply(xDates, is.na) # the two +-Inf are not NA
    > (f.D <- sapply(xDates, format))# 1..4: NA, then "negative" but all the same (?!)
    > stopifnot(is.na(f.D)[1:4]) # the formats (of 1..4) *are* all NA !!
    > ## show their true internals -- still contain what was put there :
    > for(d in xDates) dput(d)
    > ## -------------------------------------------------------------------------

    > produces

    >> xDates <- lapply(c(-Inf, Inf, NA, NaN,
    > +                    1e9, 4e9, 1e100, .Machine$double.xmax),
    > +                  as.Date, origin = "2000-01-01")
    >> str(xDates) # --> first 4 *all* show as  NA
    > List of 8
    > $ : Date[1:1], format: NA
    > $ : Date[1:1], format: NA
    > $ : Date[1:1], format: NA
    > $ : Date[1:1], format: NA
    > $ : Date[1:1], format: "2739907-01-04"
    > $ : Date[1:1], format: "-5877641-06-23"
    > $ : Date[1:1], format: "-5877641-06-23"
    > $ : Date[1:1], format: "-5877641-06-23"
    >> sapply(xDates, is.na) # the two +-Inf are not NA
    > [1] FALSE FALSE  TRUE  TRUE FALSE FALSE FALSE FALSE
    >> (f.D <- sapply(xDates, format))# 1..4: NA, then "negative" but all the same (?!)
    > [1] NA               NA               NA               NA               "2739907-01-04"  "-5877641-06-23"
    > [7] "-5877641-06-23" "-5877641-06-23"
    >> stopifnot(is.na(f.D)[1:4]) # the formats (of 1..4) *are* all NA !!
    >> ## show their true internals -- still contain what was put there :
    >> for(d in xDates) dput(d)
    > structure(-Inf, class = "Date")
    > structure(Inf, class = "Date")
    > structure(NA_real_, class = "Date")
    > structure(NaN, class = "Date")
    > structure(1000010957, class = "Date")
    > structure(4000010957, class = "Date")
    > structure(1e+100, class = "Date")
    > structure(1.79769313486232e+308, class = "Date")
    >> 

    > ---------

    > What if we left NA ( NA_character_ specifically ) as result for format(),
    > but changed the print() method so it gives better information
    > here ?

    > I would argue that -Inf and Inf should show differently than
    > true NA's or NaN's .. not the least because infinitely past and
    > infinitely into the future are different concepts.

    > Martin Maechler
    > ETH Zurich (and R Core team)


One change that would solve these problems would be to allow
<POSIXlt> [["year"]]  to become "double" instead of "integer".
Then  as.POSIXlt()  would return different things, no integer
overflow and still contain the correct numbers which it
currently cannot (but should at least warn for integer overflow !).

Martin


From |uke-t|erney @end|ng |rom u|ow@@edu  Thu Mar  7 00:17:17 2019
From: |uke-t|erney @end|ng |rom u|ow@@edu (Tierney, Luke)
Date: Wed, 6 Mar 2019 23:17:17 +0000
Subject: [Rd] bug: sample( x, size, replace = TRUE,
 prob= skewed.probs) produces uniform sample
In-Reply-To: <6504F2C9-FF26-4017-9470-BE11A3953028@ucsd.edu>
References: <6504F2C9-FF26-4017-9470-BE11A3953028@ucsd.edu>
Message-ID: <alpine.DEB.2.21.1903061716480.3003@luke-Latitude-7480>

This is now fixed in R-devel.

Best,

luke

On Sun, 3 Mar 2019, Berry, Charles wrote:

> When  `length( skewed.probs ) > 200' uniform samples are generated in R-devel.
>
> R-3.5.1 behaves as expected.
>
> `epsilon` can be a lot bigger than illustrated and still the uniform distribution is produced.
>
>
> Chuck
>
>> set.seed(123)
>>
>> epsilon <- 1e-10
>>
>> ## uniform to 200 then small
>> p200 <- prop.table( rep( c(1, epsilon), c(200, 999-200)))
>> ## uniform to 201 then small
>> p201 <- prop.table( rep( c(1, epsilon), c(201, 999-201)))
>>
>> brks  <- c(0,99,199,200,201,Inf)
>> tab200 <- sample( length(p200), 10000, prob=p200, replace=TRUE)
>> tab201 <- sample( length(p201), 10000, prob=p201, replace=TRUE)
>>
>> cbind(
> +   s200=table(cut(tab200, brks)),
> +   p200=round(xtabs(p200 ~ cut( seq_along(p200), brks)) * 10000 ,1),
> +   s201=table(cut(tab201, brks )),
> +   p201=round(xtabs(p201 ~ cut( seq_along(p201), brks)) * 10000 ,1))
>          s200 p200 s201   p201
> (0,99]    5017 4950  984 4925.4
> (99,199]  4925 5000  959 4975.1
> (199,200]   58   50    9   49.8
> (200,201]    0    0    6   49.8
> (201,Inf]    0    0 8042    0.0
>>
>>
>>
>>
>> sessionInfo()
> R Under development (unstable) (2019-03-02 r76189)
> Platform: x86_64-apple-darwin18.2.0 (64-bit)
> Running under: macOS Mojave 10.14.3
>
> Matrix products: default
> BLAS: /Users/cberry/projects/R/R-devel/lib/libRblas.dylib
> LAPACK: /Users/cberry/projects/R/R-devel/lib/libRlapack.dylib
>
> locale:
> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> loaded via a namespace (and not attached):
> [1] compiler_3.6.0
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Luke Tierney
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From @uh@rto_@nggono @end|ng |rom y@hoo@com  Thu Mar  7 09:43:20 2019
From: @uh@rto_@nggono @end|ng |rom y@hoo@com (Suharto Anggono Suharto Anggono)
Date: Thu, 7 Mar 2019 08:43:20 +0000 (UTC)
Subject: [Rd] stopifnot
References: <1951983319.809910.1551948200561.ref@mail.yahoo.com>
Message-ID: <1951983319.809910.1551948200561@mail.yahoo.com>

By not using 'withCallingHandler' or 'tryCatch', the state is like 'stopifnot' in R 3.4.x. If 'stopifnot' becomes faster than in R 3.4.x when the expressions given to 'stopifnot' are all TRUE, it is because 'match.call' is not called. Credit is to https://github.com/HenrikBengtsson/Wishlist-for-R/issues/70 for the idea.

Speaking about 'match.call',
match.call()[[i+1L]]
can replace
match.call(expand.dots=FALSE)$...[[i]] .
Result of match.call() follows argument order in function definition. In 'stopifnot', '...' comes first.


Note that what I proposed lately was not merely
sys.call(sys.parent()) ,
but
if(p <- sys.parent()) sys.call(p) .
When sys.parent() is 0, which is the frame number of .GlobalEnv, the result is NULL. The result is never the current call. I believe that it is the call of sys.frame(sys.parent()) or parent.frame(), which is the frame where stopifnot(...) is evaluated, like I said before.
sys.frame(0) is .GlobalEnv, but sys.call(0) is current call, the same as sys.call() or sys.call(sys.nframe()). See https://stat.ethz.ch/pipermail/r-devel/2016-March/072511.html .

As far as I can see, full stopifnot(...) call can only appear from an error that happens during evaluation of an argument of 'stopifnot'. Because the error is not raised by 'stopifnot', the call in the error has nothing to do with how 'n' is computed in sys.call(n-1) , or even with use of sys.call(n-1) itself.

if(n > 1) sys.call(n-1)
that I proposed previously was aimed to be like
sys.call(-1)
in 'stopifnot' in R 3.5.x. Negative number counts back from current frame. The value of 'n' is sys.nframe() or (sys.nframe()-3). In my patch, stopifnot(exprs=*) drives stopifnot(...) call via 'eval'. I found that frames were generated for
stopifnot (exprs) -> eval -> eval (.Internal) -> stopifnot (...)
>From stopifnot (...) , reaching stopifnot (exprs) takes 3 steps back.


Showing full call in error is not unique to 'stopifnot'. In my E-mail in https://stat.ethz.ch/pipermail/r-devel/2019-February/077386.html , I gave
identity(is.na(log()))
as an example. It gives
Error in identity(is.na(log())) : 
? argument "x" is missing, with no default

Expanding further,
identity(identity(is.na(log())))
has the same error message, with only one call to 'identity'.

I guess that it is because 'log' and 'is.na' are primitive functions, but 'identity' is not. I guess that a primitive function doesn't have its own context, doesn't generate frame, so the innermost non-primitive function is taken as context.

However,
identity(is.na(log("a")))
gives
Error in log("a") : non-numeric argument to mathematical function

I guess that some primitive functions in some cases modify call to be shown in error or warning message.

options(error = expression(NULL))
library(compiler)
enableJIT(0)
f <- function(x) for (i in 1) x
f(is.numeric(y))
# Error: object 'y' not found
fc <- cmpfun(f)
fc(is.numeric(y))
# Error in fc(is.numeric(y)) : object 'y' not found

The above illustrates what happens in current 'stopifnot' without 'withCallingHandlers' or 'tryCatch'. For error during 'for', non-compiled and compiled versions are different. It surprised me.

'stopifnot' without 'withCallingHandlers' and 'tryCatch' is like in R 3.4.x. I had expected error from
stopifnot(is.numeric(y))
when 'y' doesn't exist to contain full 'stopifnot' call, as in R 3.4.x. My idea of calling 'stopifnot' again for stopifnot(exprs=*) was to avoid seeing 'eval' in error message of
stopifnot(exprs = { is.numeric(y) })
when 'y' doesn't exist, assuming that seeing
stopifnot(is.numeric(y))
in error message was OK. As an aside, calling 'eval' is faster than calling 'eval' multiple times.

If it is really wanted that error from
stopifnot(is.numeric(y))
when 'y' doesn't exist doesn't give full stopifnot(...) call, I think use of 'tryCatch' is unavoidable.


A minor advantage of 'assert' with 'do.call' is smaller traceback() .


With my revised patch, the 'else' clause for 'cl' gives
call("expression", exprs) .
For
do.call(stopifnot, list(exprs = expression())) ,
the whole expression object is taken as one.

do.call(stopifnot, list(exprs = expression(1==1, 2 < 1, stop("NOT GOOD!\n"))))
Error in do.call(stopifnot, list(exprs = expression(1 == 1, 2 < 1, stop("NOT GOOD!\n")))) : 
  expression(1 == 1, 2 < 1, stop("NOT GOOD!\n")) are not all TRUE

To be the same as in R 3.5.x, the 'else' can be
as.call(c(quote(expression), as.expression(exprs)))

--------------------------------------------
On Wed, 6/3/19, Martin Maechler <maechler at stat.math.ethz.ch> wrote:

 Subject: Re: [Rd] stopifnot

@r-project.org
 Cc: "Martin Maechler" <maechler at stat.math.ethz.ch>
 Date: Wednesday, 6 March, 2019, 3:50 PM

>>>>> Martin Maechler 
>>>>>? ? on Tue, 5 Mar 2019 21:04:08 +0100 writes:

>>>>> Suharto Anggono Suharto Anggono 
>>>>>? ? on Tue, 5 Mar 2019 17:29:20 +0000 writes:

? ? >> Another possible shortcut definition:

? ? >> assert <- function(exprs)
? ? >> do.call("stopifnot", list(exprs = substitute(exprs), local = parent.frame()))

? ? > Thank you.? I think this is mostly a matter of taste, but I
? ? > liked your version using eval() & substitute() a bit more.? For
? ? > me, do.call() is a heavy hammer I only like to use when needed..

? ? > Or would there be advantages of this version?
? ? > Indeed (as you note below) one important consideration is the exact
? ? > message that is produced when one assertion fails.

? ? >> After thinking again, I propose to use
? ? >>? ? ? ?? stop(simpleError(msg, call = if(p <- sys.parent()) sys.call(p)))

? ? > That would of course be considerably simpler indeed,? part "2 a" of these:

? ? >> - It seems that the call is the call of the frame where stopifnot(...) is evaluated. Because that is the correct context, I think it is good.
? ? >> - It is simpler and also works for call that originally comes from stopifnot(exprs=*) .

? ? >> - It allows shortcut ('assert') to have the same call in error message as stopifnot(exprs=*) .

? ? > That may be another good reason in addition to code simplicity.

? ? > I will have to see if this extra simplification does not loose
? ? > more than I'd want.


? ? >> Another thing: Is it intended that
? ? >> do.call("stopifnot", list(exprs = expression()))
? ? >> evaluates each element of the expression object?

? ? > ??? I really don't know.? Even though such a case looks
? ? > "unusual" (to say the least), in principle I'd like that
? ? > expressions are evaluated sequentially until the first non-TRUE
? ? > result.? With a concrete example, I do like what we have
? ? > currently in unchanged R-devel, but also in R 3.5.x, i.e., in
? ? > the following, not any "NOT GOOD" should pop up:

? ? >> stopifnot(exprs = expression(1==1, 2 < 1, stop("NOT GOOD!\n")))
? ? > Error: 2 < 1 is not TRUE
? ? >> do.call(stopifnot, list(exprs = expression(1==1, 2 < 1, stop("NOT GOOD!\n"))))
? ? > Error in do.call(stopifnot, list(exprs = expression(1 == 1, 2 < 1, cat("NOT GOOD!\n")))) : 
? ? > 2 < 1 is not TRUE
? ? >> 

? ? > Hmm, it seems I do not understand what you ask above in your
? ? > "Another thing: .."


? ? >> If so, maybe add a case for 'cl', like
? ? >>? ? ? ?? else if(is.expression(exprs))
? ? >>? ? ? ?? as.call(c(quote(expression), exprs))

? ? > that seems simple indeed, but at the moment, I cannot see one example
? ? > where it makes a difference ... or then I'm "blind" .. ???

? ? > Best,
? ? > Martin

Some more testing of examples lead me to keep the more
sophisticated "computation" of 'n'? for the? sys.call(n-1).

Main reason:? If one of the expression is not all TRUE, I really
don't want to see the full 'stopifnot(....)' call in the printed
error message.
I do want to encourage that? stopifnot()? asserts many things
and so its own call should really not be shown.

Also I really wanted to commit something, notably also fixing
the? stopifnot(exprs = T)? bug,? so R-devel (rev >= 76203 ) now
contains a simpler and much faster? stopifnot() than previously
[and than the R 3.5.x series].

I agree that the final decisions on getting a call (or not --
which was a very good idea by you!) and which parent's call
should be used? may deserve some future tinkering..

Thank you again, Suharto Anggono,
[[elided Yahoo spam]]


Martin


From c@@rd|@g@bor @end|ng |rom gm@||@com  Thu Mar  7 23:57:14 2019
From: c@@rd|@g@bor @end|ng |rom gm@||@com (=?UTF-8?B?R8OhYm9yIENzw6FyZGk=?=)
Date: Thu, 7 Mar 2019 22:57:14 +0000
Subject: [Rd] package installation needs the file utility on Unix
Message-ID: <CABtg=Kneq7Uh6_wyzj9OPTgLPpCYJDqjsawCabzgOkc3x89-OA@mail.gmail.com>

The new staged package installation shells out to the 'file' utility
on Unix systems:
https://github.com/wch/r-source/blob/31ee14c620eb1b939acd322f3b5617f998aab8e8/src/library/tools/R/install.R#L578

Although 'file' is usually present on most Unix systems, it might be
missing from small Docker containers, where the aim is to make the
container as small possible. The magic file of 'file' is about 5MB, so
that is significant in this case.

R uses 'file' to decide if a .so, .dll, etc. file is indeed a shared
library, and (as I understand) if it is, it then goes on to try to fix
the hardcoded installation path in it, using an os specific tool.

As the second part needs to handle errors anyway, I wonder if it would
make sense to skip the 'file' call completely, after all it is quite
unlikely that a .dll or .so, etc. file is _not_ a shared library, and
even if it is not, the errors will be caught later.

Thanks, Gabor


From tom@@@k@||ber@ @end|ng |rom gm@||@com  Fri Mar  8 14:44:41 2019
From: tom@@@k@||ber@ @end|ng |rom gm@||@com (Tomas Kalibera)
Date: Fri, 8 Mar 2019 14:44:41 +0100
Subject: [Rd] package installation needs the file utility on Unix
In-Reply-To: <CABtg=Kneq7Uh6_wyzj9OPTgLPpCYJDqjsawCabzgOkc3x89-OA@mail.gmail.com>
References: <CABtg=Kneq7Uh6_wyzj9OPTgLPpCYJDqjsawCabzgOkc3x89-OA@mail.gmail.com>
Message-ID: <e8cf95d1-1393-7199-7222-533f22eb6baa@gmail.com>

Well, this only applies to source installs of packages that have some 
files with the special extension, so on systems where a compiler 
toolchain needs to be installed, so the image cannot be really tiny, 
anyway. But ok, I've made stage install use "file" only when it is 
available. When it isn't and some file with extension sl, so, dylib or 
dll in the package installation is not in fact a shared object, one will 
get a number of error messages from the respective tools, but the 
installation passes. Currently on Linux this is the case of RcppParallel 
and FastRWeb.

Tomas

On 3/7/19 11:57 PM, G?bor Cs?rdi wrote:
> The new staged package installation shells out to the 'file' utility
> on Unix systems:
> https://github.com/wch/r-source/blob/31ee14c620eb1b939acd322f3b5617f998aab8e8/src/library/tools/R/install.R#L578
>
> Although 'file' is usually present on most Unix systems, it might be
> missing from small Docker containers, where the aim is to make the
> container as small possible. The magic file of 'file' is about 5MB, so
> that is significant in this case.
>
> R uses 'file' to decide if a .so, .dll, etc. file is indeed a shared
> library, and (as I understand) if it is, it then goes on to try to fix
> the hardcoded installation path in it, using an os specific tool.
>
> As the second part needs to handle errors anyway, I wonder if it would
> make sense to skip the 'file' call completely, after all it is quite
> unlikely that a .dll or .so, etc. file is _not_ a shared library, and
> even if it is not, the errors will be caught later.
>
> Thanks, Gabor
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From c@@rd|@g@bor @end|ng |rom gm@||@com  Fri Mar  8 14:57:50 2019
From: c@@rd|@g@bor @end|ng |rom gm@||@com (=?UTF-8?B?R8OhYm9yIENzw6FyZGk=?=)
Date: Fri, 8 Mar 2019 13:57:50 +0000
Subject: [Rd] package installation needs the file utility on Unix
In-Reply-To: <e8cf95d1-1393-7199-7222-533f22eb6baa@gmail.com>
References: <CABtg=Kneq7Uh6_wyzj9OPTgLPpCYJDqjsawCabzgOkc3x89-OA@mail.gmail.com>
 <e8cf95d1-1393-7199-7222-533f22eb6baa@gmail.com>
Message-ID: <CABtg=K=zjQ4ha2nzNS1iv_uGubYYPEKNyasracwmk+jYeGhbMA@mail.gmail.com>

Thanks! Good point about the compiler toolchain.....on Alpine Linux,
which tends to be small, gcc can be less than 100MB, so still might
matter a bit....

Gabor

On Fri, Mar 8, 2019 at 1:44 PM Tomas Kalibera <tomas.kalibera at gmail.com> wrote:
>
> Well, this only applies to source installs of packages that have some
> files with the special extension, so on systems where a compiler
> toolchain needs to be installed, so the image cannot be really tiny,
> anyway. But ok, I've made stage install use "file" only when it is
> available. When it isn't and some file with extension sl, so, dylib or
> dll in the package installation is not in fact a shared object, one will
> get a number of error messages from the respective tools, but the
> installation passes. Currently on Linux this is the case of RcppParallel
> and FastRWeb.
>
> Tomas
>
> On 3/7/19 11:57 PM, G?bor Cs?rdi wrote:
> > The new staged package installation shells out to the 'file' utility
> > on Unix systems:
> > https://github.com/wch/r-source/blob/31ee14c620eb1b939acd322f3b5617f998aab8e8/src/library/tools/R/install.R#L578
> >
> > Although 'file' is usually present on most Unix systems, it might be
> > missing from small Docker containers, where the aim is to make the
> > container as small possible. The magic file of 'file' is about 5MB, so
> > that is significant in this case.
> >
> > R uses 'file' to decide if a .so, .dll, etc. file is indeed a shared
> > library, and (as I understand) if it is, it then goes on to try to fix
> > the hardcoded installation path in it, using an os specific tool.
> >
> > As the second part needs to handle errors anyway, I wonder if it would
> > make sense to skip the 'file' call completely, after all it is quite
> > unlikely that a .dll or .so, etc. file is _not_ a shared library, and
> > even if it is not, the errors will be caught later.
> >
> > Thanks, Gabor
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From kr|m|r+m| @end|ng |rom m@||box@org  Fri Mar  8 22:26:17 2019
From: kr|m|r+m| @end|ng |rom m@||box@org (=?UTF-8?Q?Kirill_M=c3=bcller?=)
Date: Fri, 8 Mar 2019 22:26:17 +0100
Subject: [Rd] Ellipsis and dot-dot-number [Re: Dots are not fixed by
 make.names()]
In-Reply-To: <d5abef06-2724-ab99-16e2-0f40ad34ed3d@mailbox.org>
References: <d5abef06-2724-ab99-16e2-0f40ad34ed3d@mailbox.org>
Message-ID: <3cb0688c-2ef3-bb0e-c5db-c9c8df1c0d6e@mailbox.org>

Hi


In addition to the inconsistency in make.names(), the text in ?Reserved 
seems incomplete:

"Reserved words outside quotes are always parsed to be references to the 
objects linked to in the ?Description?, and hence they are not allowed 
as syntactic names (see make.names). They **are** allowed as 
non-syntactic names, e.g. inside backtick quotes."

`..1` and `...` are allowed for assigning, but these symbols cannot be 
used in the context of a variable. Example:

`..1` <- 1
`..13` <- 13
`...` <- "dots"
`..1`
#> Error: ..1 used in an incorrect context, no ... to look in
`..13`
#> Error: ..13 used in an incorrect context, no ... to look in
`...`
#> Error in eval(expr, envir, enclos): '...' used in an incorrect context

Does the ?Reserved help page need to mention this oddity, or link to 
more detailed documentation?


Best regards

Kirill


On 05.10.18 11:27, Kirill M?ller wrote:
> Hi
>
>
> It seems that names of the form "..#" and "..." are not fixed by 
> make.names(), even though they are reserved words. The documentation 
> reads:
>
> > [...] Names such as ".2way" are not valid, and neither are the 
> reserved words.
>
> > Reserved words in R: [...] ... and ..1, ..2 etc, which are used to 
> refer to arguments passed down from a calling function, see ?... .
>
> I have pasted a reproducible example below.
>
> I'd like to suggest to convert these to "...#" and "....", 
> respectively. Happy to contribute PR.
>
>
> Best regards
>
> Kirill
>
>
> make.names(c("..1", "..13", "..."))
> #> [1] "..1"? "..13" "..."
> `..1` <- 1
> `..13` <- 13
> `...` <- "dots"
>
> mget(c("..1", "..13", "..."))
> #> $..1
> #> [1] 1
> #>
> #> $..13
> #> [1] 13
> #>
> #> $...
> #> [1] "dots"
> `..1`
> #> Error in eval(expr, envir, enclos): the ... list does not contain 
> any elements
> `..13`
> #> Error in eval(expr, envir, enclos): the ... list does not contain 
> 13 elements
> `...`
> #> Error in eval(expr, envir, enclos): '...' used in an incorrect context
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From wdun|@p @end|ng |rom t|bco@com  Sat Mar  9 01:46:06 2019
From: wdun|@p @end|ng |rom t|bco@com (William Dunlap)
Date: Fri, 8 Mar 2019 16:46:06 -0800
Subject: [Rd] POSIXlt$zone and $gmtoff questions
Message-ID: <CAF8bMcb-ef1kx-M_5yhGEAPU2nAmHZPpHjh3kFCmfxTn0dxiJQ@mail.gmail.com>

I've been searching for patterns in why some POSIXlt objects have the zone
and gmtoff components and some don't and why gmtoff is sometimes NA when
the zone is known.  Is there a pattern or is it just that the additional
fields and workarounds were added in an ad hoc way?

E.g.,  as.POSIXlt adds the zone and gmtoff components for all strings and
logical NA inputs if the time zone is not GMT or UTC

f <- function (lt)  {
    stopifnot(inherits(lt, "POSIXlt"))
    cat(format(lt), ", $zone=", deparse(lt$zone), ", $gmtoff=",
        deparse(lt$gmtoff), "\n", sep = "")
}
f(as.POSIXlt("2018-03-08 16:31", tz="US/Pacific"))
# 2018-03-08 16:31:00, $zone="PST", $gmtoff=NA_integer_
f(as.POSIXlt(NA, tz="US/Pacific"))
# NA, $zone="", $gmtoff=NA_integer_
f(as.POSIXlt(NA_character_, tz="US/Pacific"))
# NA, $zone="", $gmtoff=NA_integer_


But in GMT or UTF it omits the zone and gmtoff components unless you give
it a single character NA

f(as.POSIXlt("2018-03-08 16:31", tz="GMT"))
# 2018-03-08 16:31:00, $zone=NULL, $gmtoff=NULL
f(as.POSIXlt(NA, tz="GMT"))
# NA, $zone=NULL, $gmtoff=NULL
f(as.POSIXlt(NA_character_, tz="GMT"))
# NA, $zone="", $gmtoff=NA_integer_


Another oddity is that as.POSIXlt(characterData, tz="not-GMT") fills the
gmtoff component with NAs even though the zone and isdst components give
the information required to figure out the gmtoff.  as.POSIXlt(POSIXctData)
does give proper values to gmtoff

f(as.POSIXlt("2019-03-08", tz="US/Pacific"))
# 2019-03-08, $zone="PST", $gmtoff=NA_integer_
f(as.POSIXlt(as.POSIXct("2019-03-08", tz="US/Pacific")))
# 2019-03-08, $zone="PST", $gmtoff=-28800L


Is this last an efficiency issue?

Bill Dunlap
TIBCO Software
wdunlap tibco.com

	[[alternative HTML version deleted]]


From hugh@p@r@on@ge @end|ng |rom gm@||@com  Sat Mar  9 11:53:53 2019
From: hugh@p@r@on@ge @end|ng |rom gm@||@com (Hugh Parsonage)
Date: Sat, 9 Mar 2019 21:53:53 +1100
Subject: [Rd] Spurious warning from checkReplaceFuns about a non-replacement
 function
Message-ID: <CAJmOi+PXJcXrf+e=mWeiPj=TTaxjB7trUTyUBOF0FqfCfY0_xw@mail.gmail.com>

If a function contains the pattern `<-` it is (with a few exceptions)
deemed to be a replacement function and in particular must have second
argument `value` to pass R CMD check.

Consider the function %<->% or any other function containing <- within
grapes. I claim that such functions should not be considered
replacement functions and thus the R CMD check should not require its
second argument to be `value`.

Recommend in the function tools::checkReplaceFuns

grep("<-", objects_in_code,
        value = TRUE)

be changed to

grep("<-$", objects_in_code,
        value = TRUE)


Hugh.


From com|c|@n@44 @end|ng |rom gm@||@com  Sun Mar 10 04:15:50 2019
From: com|c|@n@44 @end|ng |rom gm@||@com (comic fans)
Date: Sun, 10 Mar 2019 11:15:50 +0800
Subject: [Rd] Exit status of Rscript when setting
 options(error=utils::recover)
Message-ID: <CAKzW8ok4mRyb5MwAAkaN==9qcq+NrqNv8vj5YsWU_AhZM_gFMg@mail.gmail.com>

Hello, I've noticed that Rscript didn't exit with error code if I set
options error = utils::recover in .Rprofile . for example

Rscript -e "asdf"

Error: object 'asdf' not found
No suitable frames for recover()

echo $?
0

if didn't set options in .Rprofile, Rscript exit with error code 1, is
this expected behavior ?


From @u@@ @end|ng |rom weh|@edu@@u  Fri Mar  8 00:06:43 2019
From: @u@@ @end|ng |rom weh|@edu@@u (Shian Su)
Date: Thu, 7 Mar 2019 23:06:43 +0000
Subject: [Rd] Discrepancy between is.list() and is(x, "list")
Message-ID: <F35BFD5E-8487-485C-B6F6-7A8BBA353F40@wehi.edu.au>

Hi R-devel,

I have noticed a discrepancy between is.list() and is(x, ?list?), which I previously believed to be synonymous. On R version 3.5.2 (2018-12-20):

data(iris)
is.list(iris)    # TRUE
is(iris, ?list?) # FALSE

Is this discrepancy intentional?

Kind regards,
Shian Su

_______________________________________________

The information in this email is confidential and intended solely for the addressee.
You must not disclose, forward, print or use it without the permission of the sender.

The Walter and Eliza Hall Institute acknowledges the Wurundjeri people of the Kulin
Nation as the traditional owners of the land where our campuses are located and
the continuing connection to country and community.
_______________________________________________

	[[alternative HTML version deleted]]


From pd@me@ @end|ng |rom cb@@dk  Mon Mar 11 09:35:49 2019
From: pd@me@ @end|ng |rom cb@@dk (Peter Dalgaard)
Date: Mon, 11 Mar 2019 08:35:49 +0000
Subject: [Rd] R 3.5.3 is released
Message-ID: <9FF9937D-3F09-4AB2-8502-E622266A440F@cbs.dk>

The build system rolled up R-3.5.3.tar.gz (codename "Great Truth") this morning.

The list below details the changes in this release. This is the wrap-up release for the 3.5.x series, so actually, not much has happened.

You can get the source code from

http://cran.r-project.org/src/base/R-3/R-3.5.3.tar.gz

or wait for it to be mirrored at a CRAN site nearer to you.

Binaries for various platforms will appear in due course.


For the R Core Team,

Peter Dalgaard


These are the checksums (md5 and SHA-256) for the freshly created files, in case you wish
to check that they are uncorrupted:

MD5 (AUTHORS) = b9c44f9f78cab3184ad9898bebc854b4
MD5 (COPYING) = eb723b61539feef013de476e68b5c50a
MD5 (COPYING.LIB) = a6f89e2100d9b6cdffcea4f398e37343
MD5 (FAQ) = 3bba37aa1dd06de3f781200a8081302f
MD5 (INSTALL) = 7893f754308ca31f1ccf62055090ad7b
MD5 (NEWS) = ab129f42b1d5ca25122db6b1bda0fcd9
MD5 (NEWS.0) = bfcd7c147251b5474d96848c6f57e5a8
MD5 (NEWS.1) = eb78c4d053ec9c32b815cf0c2ebea801
MD5 (NEWS.2) = 591dcf615162127f904e4e461f330ce9
MD5 (R-latest.tar.gz) = 525e902dd331c387f271692a1537aff8
MD5 (README) = f468f281c919665e276a1b691decbbe6
MD5 (RESOURCES) = 529223fd3ffef95731d0a87353108435
MD5 (THANKS) = 08158353102084599797db8c9ccf8e2a
MD5 (VERSION-INFO.dcf) = cb61b0eb560efcbbec47128abf3fb761
MD5 (R-3/R-3.5.3.tar.gz) = 525e902dd331c387f271692a1537aff8

2cde824a7b18958e5f06b391c801c8288be0f84fa8934b7ddefef23c67e60c09  AUTHORS
e6d6a009505e345fe949e1310334fcb0747f28dae2856759de102ab66b722cb4  COPYING
6095e9ffa777dd22839f7801aa845b31c9ed07f3d6bf8a26dc5d2dec8ccc0ef3  COPYING.LIB
98df47801c33cc4f4a4de98447cb2bd40e09c0920195f540a981ceed874714f2  FAQ
f87461be6cbaecc4dce44ac58e5bd52364b0491ccdadaf846cb9b452e9550f31  INSTALL
4c6eb7cd9d8f4c1858a8f853698d2954d42d5d8b71c5c4d20bc6bd970f034bfe  NEWS
4e21b62f515b749f80997063fceab626d7258c7d650e81a662ba8e0640f12f62  NEWS.0
12b30c724117b1b2b11484673906a6dcd48a361f69fc420b36194f9218692d01  NEWS.1
ca04f78ffe54afa326fe3ed40e7e1411aca0000ed2fa5ead97ddf51c6aa5b7bc  NEWS.2
2bfa37b7bd709f003d6b8a172ddfb6d03ddd2d672d6096439523039f7a8e678c  R-latest.tar.gz
2fdd3e90f23f32692d4b3a0c0452f2c219a10882033d1774f8cadf25886c3ddc  README
408737572ecc6e1135fdb2cf7a9dbb1a6cb27967c757f1771b8c39d1fd2f1ab9  RESOURCES
2d2e85e85574c4430951f6b070c08cd5aff1602abfd1bb162bed6d89c436b11f  THANKS
1ce83e7a843f95e8b0d5abf6ced7426cc337cc607f9862f99d46a7d05793ac15  VERSION-INFO.dcf
2bfa37b7bd709f003d6b8a172ddfb6d03ddd2d672d6096439523039f7a8e678c  R-3/R-3.5.3.tar.gz

This is the relevant part of the NEWS file:

CHANGES IN R 3.5.3:

  INSTALLATION on a UNIX-ALIKE:

    * Detection of flags for C++98/11/14/17 has been improved: in
      particular if CXX??STD is set, it is tried first with no
      additional flags.

  PACKAGE INSTALLATION:

    * New macro F_VISIBILITY as an alternative to F77_VISIBILITY.  This
      will become the preferred form in R 3.6.0.

  BUG FIXES:

    * writeLines(readLines(fnam), fnam) now works as expected, thanks
      to Peter Meissner's PR#17528.

    * setClassUnion() no longer warns, but uses message() for now, when
      encountering "non local" subclasses of class members.

    * stopifnot(exprs = T) no longer fails.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Tue Mar 12 12:07:29 2019
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Tue, 12 Mar 2019 12:07:29 +0100
Subject: [Rd] Ellipsis and dot-dot-number [Re: Dots are not fixed by
 make.names()]
In-Reply-To: <3cb0688c-2ef3-bb0e-c5db-c9c8df1c0d6e@mailbox.org>
References: <d5abef06-2724-ab99-16e2-0f40ad34ed3d@mailbox.org>
 <3cb0688c-2ef3-bb0e-c5db-c9c8df1c0d6e@mailbox.org>
Message-ID: <23687.37617.333089.494259@stat.math.ethz.ch>

>>>>> Kirill M?ller 
>>>>>     on Fri, 8 Mar 2019 22:26:17 +0100 writes:
>>>>> Kirill M?ller 
>>>>>     on Fri, 8 Mar 2019 22:26:17 +0100 writes:

    > Hi


    > In addition to the inconsistency in make.names(), the text in ?Reserved 
    > seems incomplete:

    >  "Reserved words outside quotes are always parsed to be references to the 
    >   objects linked to in the ?Description?, and hence they are not allowed 
    >   as syntactic names (see make.names). They **are** allowed as 
    >   non-syntactic names, e.g. inside backtick quotes."

    > `..1` and `...` are allowed for assigning, but these symbols cannot be 
    > used in the context of a variable. Example:

    > `..1` <- 1
    > `..13` <- 13
    > `...` <- "dots"
    > `..1`
    > #> Error: ..1 used in an incorrect context, no ... to look in
    > `..13`
    > #> Error: ..13 used in an incorrect context, no ... to look in
    > `...`
    > #> Error in eval(expr, envir, enclos): '...' used in an incorrect context

    > Does the ?Reserved help page need to mention this oddity, or link to 
    > more detailed documentation?

    > Best regards
    > Kirill

I see

> `..9` <- 999
> get("..9")
[1] 999
> `..9`
Error: ..9 used in an incorrect context, no ... to look in

> `...` <- "3 dots"
> `...`
Error: '...' used in an incorrect context
> get("...")
[1] "3 dots"
> 

> assign("...", "3 DOTS")
> assign("..1", "1st dot arg")


So get() works for these, but `...` does not for getting but for
assignment.
OTOH,  assign() works for all, reserved words or not, so that
should not count.

Honestly, I'm not sure if the current behavior is necessary in
some sense or just a coincidence.

I do see that the C-internal isValidName()  [defined in the
grammar: gram.y (=> gram.c)] does say that "..." and "..1" etc
are valid names and that's what the C code of make.names() uses.

Also, as you know they *are* valid names as one does and should use them
unquoted although only to "get" and only inside functions.

So, no conclusion from here for now for the latter part.

For the first, about your make.names()  "inconsistency", I'd say
it *is* consistent because e.g.  ...  can be used without quotes
and hence is a valid name (mostly ;-).

OTOH,  make.names() being used to construct "valid" data frame
column names, maybe make.names() could be changed, probably via
a new optional logical argument say 'dotsValid = TRUE' which
when set to FALSE would also treat '...' and '..1' etc.

Unfortunately the code changes needed may be a bit ugly
as the consistency between  make.names() and {C level}  isValidName()
would be broken for  'dotsValid = FALSE'.

Martin



    > On 05.10.18 11:27, Kirill M?ller wrote:
    >> Hi
    >> 
    >> 
    >> It seems that names of the form "..#" and "..." are not fixed by 
    >> make.names(), even though they are reserved words. The documentation 
    >> reads:
    >> 
    >> > [...] Names such as ".2way" are not valid, and neither are the 
    >> reserved words.
    >> 
    >> > Reserved words in R: [...] ... and ..1, ..2 etc, which are used to 
    >> refer to arguments passed down from a calling function, see ?... .
    >> 
    >> I have pasted a reproducible example below.
    >> 
    >> I'd like to suggest to convert these to "...#" and "....", 
    >> respectively. Happy to contribute PR.
    >> 
    >> 
    >> Best regards
    >> 
    >> Kirill
    >> 
    >> 
    >> make.names(c("..1", "..13", "..."))
    >> #> [1] "..1"? "..13" "..."
    >> `..1` <- 1
    >> `..13` <- 13
    >> `...` <- "dots"
    >> 
    >> mget(c("..1", "..13", "..."))
    >> #> $..1
    >> #> [1] 1
    >> #>
    >> #> $..13
    >> #> [1] 13
    >> #>
    >> #> $...
    >> #> [1] "dots"
    >> `..1`
    >> #> Error in eval(expr, envir, enclos): the ... list does not contain 
    >> any elements
    >> `..13`
    >> #> Error in eval(expr, envir, enclos): the ... list does not contain 
    >> 13 elements
    >> `...`
    >> #> Error in eval(expr, envir, enclos): '...' used in an incorrect context
    >> 
    >> ______________________________________________
    >> R-devel at r-project.org mailing list
    >> https://stat.ethz.ch/mailman/listinfo/r-devel

    > ______________________________________________
    > R-devel at r-project.org mailing list
    > https://stat.ethz.ch/mailman/listinfo/r-devel


From Kurt@Horn|k @end|ng |rom wu@@c@@t  Tue Mar 12 16:52:37 2019
From: Kurt@Horn|k @end|ng |rom wu@@c@@t (Kurt Hornik)
Date: Tue, 12 Mar 2019 16:52:37 +0100
Subject: [Rd] 
 Spurious warning from checkReplaceFuns about a non-replacement
 function
In-Reply-To: <CAJmOi+PXJcXrf+e=mWeiPj=TTaxjB7trUTyUBOF0FqfCfY0_xw@mail.gmail.com>
References: <CAJmOi+PXJcXrf+e=mWeiPj=TTaxjB7trUTyUBOF0FqfCfY0_xw@mail.gmail.com>
Message-ID: <23687.54725.494402.883738@hornik.net>

>>>>> Hugh Parsonage writes:

> If a function contains the pattern `<-` it is (with a few exceptions)
> deemed to be a replacement function and in particular must have second
> argument `value` to pass R CMD check.

> Consider the function %<->% or any other function containing <- within
> grapes. I claim that such functions should not be considered
> replacement functions and thus the R CMD check should not require its
> second argument to be `value`.

I just committed c76224 which drops %xxx% binops from the list of
(probable) replacement functions.

Thanks for spotting this!

Best
-k

> Recommend in the function tools::checkReplaceFuns

> grep("<-", objects_in_code,
>         value = TRUE)

> be changed to

> grep("<-$", objects_in_code,
>         value = TRUE)


> Hugh.

> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From p@u| @end|ng |rom @t@t@@uck|@nd@@c@nz  Tue Mar 12 23:53:42 2019
From: p@u| @end|ng |rom @t@t@@uck|@nd@@c@nz (Paul Murrell)
Date: Wed, 13 Mar 2019 11:53:42 +1300
Subject: [Rd] R cairo_pdf function does not respect plotting boundaries
In-Reply-To: <CAO0anGmLgRSFJWaRmYbAnKL-8EwaZXyUjBCu+dBnLMV39wTwGA@mail.gmail.com>
References: <CAO0anGmxEwS2VtAqT-i6701QrkFCL90cOneB+c_y3uJ_40aG9w@mail.gmail.com>
 <581bf016-0b51-977b-200d-bbeef95f9046@stat.auckland.ac.nz>
 <CAO0anGmLgRSFJWaRmYbAnKL-8EwaZXyUjBCu+dBnLMV39wTwGA@mail.gmail.com>
Message-ID: <87534dc5-c21c-8eee-649d-f43c77d4c399@stat.auckland.ac.nz>

Hi

I have committed this fix to r-devel (r76226).

Please let me know if this does not fix things for you.

Paul

On 5/03/19 8:22 PM, Lee Steven Kelvin wrote:
> Hi Paul,
> 
> Great, thank you for looking in to this, and I'm glad that you're able 
> to reproduce it at your end too.
> 
>  From your reply, I'm happy that it seems like the fix may be fairly 
> trivial, but I understand the necessity for caution.
> 
> If there's anything else I can do to help, please do let me know.
> 
> Thank you again,
> Best,
> Lee
> 
> 
> On Monday, 4 March 2019, Paul Murrell <paul at stat.auckland.ac.nz 
> <mailto:paul at stat.auckland.ac.nz>> wrote:
> 
>     Hi
> 
>     (cc'ed to r-devel where further discussion should probably take place)
> 
>     Thanks Lee.? I see that problem.
> 
>     There is a "+ 1" in the Cairo device code for setting the clipping
>     region
>     (https://github.com/wch/r-source/blob/ba600867f2a94e46cf9eb75dc8b37f12b08a4561/src/library/grDevices/src/cairo/cairoFns.c#L156
>     <https://github.com/wch/r-source/blob/ba600867f2a94e46cf9eb75dc8b37f12b08a4561/src/library/grDevices/src/cairo/cairoFns.c#L156>)
> 
> 
>     Remove the "+ 1" and the problem goes away (for your example at least).
> 
>     The comment on the line above that code suggests that the "+ 1" was
>     modelled on the X11 device code, but X11 deals in integer pixels and
>     Cairo (at the API level) does not, so it would seem that the "+ 1"
>     is just unnecessary.
> 
>     However, I have a slight nagging worry that we have been here
>     before, so I would like to do some more testing before committing
>     that change.
> 
>     Paul
> 
>     On 1/03/19 8:13 AM, Lee Steven Kelvin wrote:
> 
>         Hello all,
> 
>         When producing a plot in R using the cairo_pdf device, the
>         resultant plot does not respect the plotting boundaries. Lines
>         and shaded regions will spill over the lower x-axis and the
>         right-side y-axis (sides 1 and 4). I would like to know if it is
>         possible to fix this behaviour when using 'cairo_pdf' in R?
> 
>         As an example, see the image at this web link:
>         https://i.stack.imgur.com/0lfZd.png
>         <https://i.stack.imgur.com/0lfZd.png>
> 
>         This image is a screenshot of a PDF file constructed using the
>         following minimum working example code:
> 
>         cairo_pdf(file="test.pdf", width=0.5, height=0.5)
>         par("mar"=c(0.25,0.25,0.25,0.25))
>         plot(NA, xlim=c(0,1), ylim=c(0,1), axes=FALSE)
>         polygon(x=c(-1,-1,2,2), y=c(-1,2,2,-1), density=5, col="green3",
>         lwd=10)
>         abline(h=0.25, col="red", lwd=5)
>         abline(h=0.75, col="hotpink", lwd=5, lend=1)
>         abline(v=0.25, col="blue", lwd=5)
>         abline(v=0.75, col="cyan", lwd=5, lend=1)
>         box()
>         dev.off()
> 
>         Here I'm plotting a shaded region in green using 'polygon', with
>         boundaries that lie outside the plot. I'm also drawing two sets
>         of horizontal/vertical lines using 'abline'. The first in each
>         pair uses standard rounded line caps, whilst the second in each
>         pair uses butt line caps.
> 
>         As you can see, the shading lines and the default rounded-end
>         ablines all extend beyond the plotting region along the lower
>         and right-hand side axes. Only when using 'lend=1' am I able to
>         contain the ablines to the plotting region. I know of no such
>         fix for the shading lines however.
> 
>         I would naively expect the R plotting region to be respected,
>         and for it to be impossible to plot outside of this region
>         unless explicitly specified by the user.
> 
>         I have tested this on the other cairo devices (SVG and PS), and
>         also reproduce the same behaviour, indicating that this is an
>         issue with the cairo graphics API, or its implementation within R.
> 
>         This behaviour does not occur when using the standard R 'pdf'
>         graphics device. I would switch to 'pdf' in general, however,
>         'cairo_pdf' has several advantages over 'pdf', notably, reduced
>         output file sizes on occasion and support for a larger array of
>         UTF-8 characters, so ideally I would prefer to use cairo_pdf.
> 
>         I should note that I have also posted this message on
>         StackOverflow at this web link:
>         https://stackoverflow.com/questions/54892809/r-cairo-pdf-function-does-not-respect-plotting-boundaries
>         <https://stackoverflow.com/questions/54892809/r-cairo-pdf-function-does-not-respect-plotting-boundaries>
> 
>         Thank you in advance for any insights into this issue.
> 
>         Sincerely,
>         Lee Kelvin
> 
> 
> 
>         --
>         Dr Lee Kelvin
>         Department of Physics
>         UC Davis
>         One Shields Avenue
>         Davis, CA 95616
>         USA
> 
>         Ph: +1 (530) 752-1500
>         Fax: +1 (530) 752-4717
> 
> 
>          ? ? ? ? [[alternative HTML version deleted]]
> 
>         ______________________________________________
>         R-help at r-project.org <mailto:R-help at r-project.org>?mailing list
>         -- To UNSUBSCRIBE and more, see
>         https://stat.ethz.ch/mailman/listinfo/r-help
>         <https://stat.ethz.ch/mailman/listinfo/r-help>
>         PLEASE do read the posting guide
>         http://www.R-project.org/posting-guide.html
>         <http://www.R-project.org/posting-guide.html>
>         and provide commented, minimal, self-contained, reproducible code.
> 
> 
>     -- 
>     Dr Paul Murrell
>     Department of Statistics
>     The University of Auckland
>     Private Bag 92019
>     Auckland
>     New Zealand
>     64 9 3737599 x85392
>     paul at stat.auckland.ac.nz <mailto:paul at stat.auckland.ac.nz>
>     http://www.stat.auckland.ac.nz/~paul/
>     <http://www.stat.auckland.ac.nz/~paul/>
> 
> 
> 
> -- 
> Dr Lee Kelvin
> Department of Physics
> UC Davis
> One Shields Avenue
> Davis, CA 95616
> USA
> 
> Ph: +1 (530) 752-1500
> Fax: +1 (530) 752-4717
> 

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/


From jcm6t @end|ng |rom v|rg|n|@@edu  Tue Mar 12 21:39:31 2019
From: jcm6t @end|ng |rom v|rg|n|@@edu (Mychaleckyj, Josyf C (jcm6t))
Date: Tue, 12 Mar 2019 20:39:31 +0000
Subject: [Rd] as.data.frame.table() does not recognize
 default.stringsAsFactors()
Message-ID: <A27D36B8-A7D4-4347-ABC5-7214E0170213@virginia.edu>

Reporting a possible inconsistency or bug in handling stringsAsFactors in as.data.frame.table()

Here is a simple test

> options()$stringsAsFactors
[1] TRUE
> x<-c("a","b","c","a","b")
> d<-as.data.frame(table(x))
> d
  x Freq
1 a    2
2 b    2
3 c    1
> class(d$x)
[1] "factor"
> d2<-as.data.frame(table(x),stringsAsFactors=F)
> class(d2$x)
[1] ?character"
> options(stringsAsFactors=F)
> options()$stringsAsFactors
[1] FALSE
> d3<-as.data.frame(table(x))
> d3
  x Freq
1 a    2
2 b    2
3 c    1
> class(d3$x)
[1] ?factor"
> d4<-as.data.frame(table(x),stringsAsFactors=F)
> class(d4$x)
[1] ?character"


# Display the code showing the different  stringsAsFactors handling in table and matrix:

> as.data.frame.table
function (x, row.names = NULL, ..., responseName = "Freq", stringsAsFactors = TRUE,
    sep = "", base = list(LETTERS))
{
    ex <- quote(data.frame(do.call("expand.grid", c(dimnames(provideDimnames(x,
        sep = sep, base = base)), KEEP.OUT.ATTRS = FALSE, stringsAsFactors = stringsAsFactors)),
        Freq = c(x), row.names = row.names))
    names(ex)[3L] <- responseName
    eval(ex)
}
<bytecode: 0x28769f8>
<environment: namespace:base>

> as.data.frame.matrix
function (x, row.names = NULL, optional = FALSE, make.names = TRUE,
    ..., stringsAsFactors = default.stringsAsFactors())
{
    d <- dim(x)
    nrows <- d[[1L]]
    ncols <- d[[2L]]
    ic <- seq_len(ncols)
    dn <- dimnames(x)
    if (is.null(row.names))
        row.names <- dn[[1L]]
    collabs <- dn[[2L]]
    if (any(empty <- !nzchar(collabs)))
        collabs[empty] <- paste0("V", ic)[empty]
    value <- vector("list", ncols)
    if (mode(x) == "character" && stringsAsFactors) {
        for (i in ic) value[[i]] <- as.factor(x[, i])
    }
    else {
        for (i in ic) value[[i]] <- as.vector(x[, i])
    }
    autoRN <- (is.null(row.names) || length(row.names) != nrows)
    if (length(collabs) == ncols)
        names(value) <- collabs
    else if (!optional)
        names(value) <- paste0("V", ic)
    class(value) <- "data.frame"
    if (autoRN)
        attr(value, "row.names") <- .set_row_names(nrows)
    else .rowNamesDF(value, make.names = make.names) <- row.names
    value
}
<bytecode: 0x29995c0>
<environment: namespace:base>


> sessionInfo()
R version 3.5.2 (2018-12-20)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: CentOS Linux 7 (Core)

Matrix products: default
BLAS: /usr/lib64/libblas.so.3.4.2
LAPACK: /usr/lib64/liblapack.so.3.4.2

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
 [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] compiler_3.5.2 tools_3.5.2

Thanks,
Joe



	[[alternative HTML version deleted]]


From pd@|gd @end|ng |rom gm@||@com  Thu Mar 14 16:18:55 2019
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Thu, 14 Mar 2019 16:18:55 +0100
Subject: [Rd] as.data.frame.table() does not recognize
 default.stringsAsFactors()
In-Reply-To: <A27D36B8-A7D4-4347-ABC5-7214E0170213@virginia.edu>
References: <A27D36B8-A7D4-4347-ABC5-7214E0170213@virginia.edu>
Message-ID: <F28ED2D7-3280-4515-A47A-0C2C4B47E9BA@gmail.com>

I have no recollection of the original rationale for as.data.frame.table, but I actually think it is fine as it is: 

The classifying _factors_ of a crosstable should be factors unless very specifically directed otherwise and that should not depend on the setting of an option that controls the conversion of character data. 

For as.data.frame.matrix, in contrast, it is the _content_ of the matrix that is being converted, and it seems much more reasonable to follow the same path as for other character data.

-pd

> On 12 Mar 2019, at 21:39 , Mychaleckyj, Josyf C (jcm6t) <jcm6t at virginia.edu> wrote:
> 
> Reporting a possible inconsistency or bug in handling stringsAsFactors in as.data.frame.table()
> 
> Here is a simple test
> 
>> options()$stringsAsFactors
> [1] TRUE
>> x<-c("a","b","c","a","b")
>> d<-as.data.frame(table(x))
>> d
>  x Freq
> 1 a    2
> 2 b    2
> 3 c    1
>> class(d$x)
> [1] "factor"
>> d2<-as.data.frame(table(x),stringsAsFactors=F)
>> class(d2$x)
> [1] ?character"
>> options(stringsAsFactors=F)
>> options()$stringsAsFactors
> [1] FALSE
>> d3<-as.data.frame(table(x))
>> d3
>  x Freq
> 1 a    2
> 2 b    2
> 3 c    1
>> class(d3$x)
> [1] ?factor"
>> d4<-as.data.frame(table(x),stringsAsFactors=F)
>> class(d4$x)
> [1] ?character"
> 
> 
> # Display the code showing the different  stringsAsFactors handling in table and matrix:
> 
>> as.data.frame.table
> function (x, row.names = NULL, ..., responseName = "Freq", stringsAsFactors = TRUE,
>    sep = "", base = list(LETTERS))
> {
>    ex <- quote(data.frame(do.call("expand.grid", c(dimnames(provideDimnames(x,
>        sep = sep, base = base)), KEEP.OUT.ATTRS = FALSE, stringsAsFactors = stringsAsFactors)),
>        Freq = c(x), row.names = row.names))
>    names(ex)[3L] <- responseName
>    eval(ex)
> }
> <bytecode: 0x28769f8>
> <environment: namespace:base>
> 
>> as.data.frame.matrix
> function (x, row.names = NULL, optional = FALSE, make.names = TRUE,
>    ..., stringsAsFactors = default.stringsAsFactors())
> {
>    d <- dim(x)
>    nrows <- d[[1L]]
>    ncols <- d[[2L]]
>    ic <- seq_len(ncols)
>    dn <- dimnames(x)
>    if (is.null(row.names))
>        row.names <- dn[[1L]]
>    collabs <- dn[[2L]]
>    if (any(empty <- !nzchar(collabs)))
>        collabs[empty] <- paste0("V", ic)[empty]
>    value <- vector("list", ncols)
>    if (mode(x) == "character" && stringsAsFactors) {
>        for (i in ic) value[[i]] <- as.factor(x[, i])
>    }
>    else {
>        for (i in ic) value[[i]] <- as.vector(x[, i])
>    }
>    autoRN <- (is.null(row.names) || length(row.names) != nrows)
>    if (length(collabs) == ncols)
>        names(value) <- collabs
>    else if (!optional)
>        names(value) <- paste0("V", ic)
>    class(value) <- "data.frame"
>    if (autoRN)
>        attr(value, "row.names") <- .set_row_names(nrows)
>    else .rowNamesDF(value, make.names = make.names) <- row.names
>    value
> }
> <bytecode: 0x29995c0>
> <environment: namespace:base>
> 
> 
>> sessionInfo()
> R version 3.5.2 (2018-12-20)
> Platform: x86_64-pc-linux-gnu (64-bit)
> Running under: CentOS Linux 7 (Core)
> 
> Matrix products: default
> BLAS: /usr/lib64/libblas.so.3.4.2
> LAPACK: /usr/lib64/liblapack.so.3.4.2
> 
> locale:
> [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
> [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
> [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
> [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
> [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> loaded via a namespace (and not attached):
> [1] compiler_3.5.2 tools_3.5.2
> 
> Thanks,
> Joe
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From d@v|dhughjone@ @end|ng |rom gm@||@com  Thu Mar 14 16:48:57 2019
From: d@v|dhughjone@ @end|ng |rom gm@||@com (David Hugh-Jones)
Date: Thu, 14 Mar 2019 15:48:57 +0000
Subject: [Rd] Possible bug in requireNamespace
Message-ID: <CAARY7kgfpUbvg714PbVSONbfixqpkO+zxpnU6KDMY-9m3Gthow@mail.gmail.com>

At least, unexpected behaviour. The documentation says:

 quietly: logical: should progress and error messages be suppressed?

But if you do e.g.

requireNamespace("broom", quietly = TRUE)
requireNamespace("broom.mixed", quietly = TRUE)

You will get messages when broom.mixed overrides broom's methods.

David


From hp@ge@ @end|ng |rom |redhutch@org  Thu Mar 14 17:32:30 2019
From: hp@ge@ @end|ng |rom |redhutch@org (Pages, Herve)
Date: Thu, 14 Mar 2019 16:32:30 +0000
Subject: [Rd] selectMethod() can fail to find methods in situations of
 multiple dispatch
Message-ID: <1abb17e0-12ee-57bb-b762-128552806fab@fredhutch.org>

Here is an example:

  setGeneric("foo", function(x, y) standardGeneric("foo"))

  setMethod("foo", c("numeric", "ANY"),
    function(x, y) cat("I'm the foo#numeric#ANY method\n")
  )


Dispatch works as expected but selectMethod() fails to find the method:


  > foo(1, TRUE)
  I'm the foo#numeric#ANY method

  > selectMethod("foo", c("numeric", "logical"))
  Error in selectMethod("foo", c("numeric", "logical")) :
    no method found for signature numeric, logical

Adding an arbitrary method that doesn't have ANY in the signature "fixes" selectMethod():

  setMethod("foo", c("complex", "integer"),
    function(x, y) cat("I'm the foo#complex#integer method\n")
  )

Then:

  > selectMethod("foo", c("numeric", "logical"))
  Method Definition:

  function (x, y)
  cat("I'm the foo#numeric#ANY method\n")

  Signatures:
        x         y
  target  "numeric" "logical"
  defined "numeric" "ANY"


Thanks,

H.


--
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fredhutch.org<mailto:hpages at fredhutch.org>
Phone:  (206) 667-5791
Fax:    (206) 667-1319


	[[alternative HTML version deleted]]


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Thu Mar 14 17:40:53 2019
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Thu, 14 Mar 2019 17:40:53 +0100
Subject: [Rd] as.data.frame.table() does not recognize
 default.stringsAsFactors()
In-Reply-To: <F28ED2D7-3280-4515-A47A-0C2C4B47E9BA@gmail.com>
References: <A27D36B8-A7D4-4347-ABC5-7214E0170213@virginia.edu>
 <F28ED2D7-3280-4515-A47A-0C2C4B47E9BA@gmail.com>
Message-ID: <23690.33813.791094.918044@stat.math.ethz.ch>

>>>>> peter dalgaard 
>>>>>     on Thu, 14 Mar 2019 16:18:55 +0100 writes:

    > I have no recollection of the original rationale for as.data.frame.table, but I actually think it is fine as it is: 
    > The classifying _factors_ of a crosstable should be factors unless very specifically directed otherwise and that should not depend on the setting of an option that controls the conversion of character data. 

    > For as.data.frame.matrix, in contrast, it is the _content_ of the matrix that is being converted, and it seems much more reasonable to follow the same path as for other character data.

    > -pd

I very strongly agree that as.data.frame.table() should not be
changed to follow a global option.

To the contrary: I've repeatedly mentioned that in my view it
has been a design mistake to allow data.frame() and as.data.frame() be influenced
by a global option
 [and we should've tried harder to keep things purely functional
   (R remaining as closely as possible a "functional language"), 
  e.g. by providing wrapper functions the same way we have such
  wrappers for versions of read.table() with different defaults
  for some of the arguments
 ]

Martin


    >> On 12 Mar 2019, at 21:39 , Mychaleckyj, Josyf C (jcm6t) <jcm6t at virginia.edu> wrote:
    >> 
    >> Reporting a possible inconsistency or bug in handling stringsAsFactors in as.data.frame.table()
    >> 
    >> Here is a simple test
    >> 
    >>> options()$stringsAsFactors
    >> [1] TRUE
    >>> x<-c("a","b","c","a","b")
    >>> d<-as.data.frame(table(x))
    >>> d
    >> x Freq
    >> 1 a    2
    >> 2 b    2
    >> 3 c    1
    >>> class(d$x)
    >> [1] "factor"
    >>> d2<-as.data.frame(table(x),stringsAsFactors=F)
    >>> class(d2$x)
    >> [1] ?character"
    >>> options(stringsAsFactors=F)
    >>> options()$stringsAsFactors
    >> [1] FALSE
    >>> d3<-as.data.frame(table(x))
    >>> d3
    >> x Freq
    >> 1 a    2
    >> 2 b    2
    >> 3 c    1
    >>> class(d3$x)
    >> [1] ?factor"
    >>> d4<-as.data.frame(table(x),stringsAsFactors=F)
    >>> class(d4$x)
    >> [1] ?character"
    >> 
    >> 
    >> # Display the code showing the different  stringsAsFactors handling in table and matrix:
    >> 
    >>> as.data.frame.table
    >> function (x, row.names = NULL, ..., responseName = "Freq", stringsAsFactors = TRUE,
    >> sep = "", base = list(LETTERS))
    >> {
    >> ex <- quote(data.frame(do.call("expand.grid", c(dimnames(provideDimnames(x,
    >> sep = sep, base = base)), KEEP.OUT.ATTRS = FALSE, stringsAsFactors = stringsAsFactors)),
    >> Freq = c(x), row.names = row.names))
    >> names(ex)[3L] <- responseName
    >> eval(ex)
    >> }
    >> <bytecode: 0x28769f8>
    >> <environment: namespace:base>
    >> 
    >>> as.data.frame.matrix
    >> function (x, row.names = NULL, optional = FALSE, make.names = TRUE,
    >> ..., stringsAsFactors = default.stringsAsFactors())
    >> {
    >> d <- dim(x)
    >> nrows <- d[[1L]]
    >> ncols <- d[[2L]]
    >> ic <- seq_len(ncols)
    >> dn <- dimnames(x)
    >> if (is.null(row.names))
    >> row.names <- dn[[1L]]
    >> collabs <- dn[[2L]]
    >> if (any(empty <- !nzchar(collabs)))
    >> collabs[empty] <- paste0("V", ic)[empty]
    >> value <- vector("list", ncols)
    >> if (mode(x) == "character" && stringsAsFactors) {
    >> for (i in ic) value[[i]] <- as.factor(x[, i])
    >> }
    >> else {
    >> for (i in ic) value[[i]] <- as.vector(x[, i])
    >> }
    >> autoRN <- (is.null(row.names) || length(row.names) != nrows)
    >> if (length(collabs) == ncols)
    >> names(value) <- collabs
    >> else if (!optional)
    >> names(value) <- paste0("V", ic)
    >> class(value) <- "data.frame"
    >> if (autoRN)
    >> attr(value, "row.names") <- .set_row_names(nrows)
    >> else .rowNamesDF(value, make.names = make.names) <- row.names
    >> value
    >> }
    >> <bytecode: 0x29995c0>
    >> <environment: namespace:base>
    >> 
    >> 
    >>> sessionInfo()
    >> R version 3.5.2 (2018-12-20)
    >> Platform: x86_64-pc-linux-gnu (64-bit)
    >> Running under: CentOS Linux 7 (Core)
    >> 
    >> Matrix products: default
    >> BLAS: /usr/lib64/libblas.so.3.4.2
    >> LAPACK: /usr/lib64/liblapack.so.3.4.2
    >> 
    >> locale:
    >> [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
    >> [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
    >> [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
    >> [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
    >> [9] LC_ADDRESS=C               LC_TELEPHONE=C
    >> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
    >> 
    >> attached base packages:
    >> [1] stats     graphics  grDevices utils     datasets  methods   base
    >> 
    >> loaded via a namespace (and not attached):
    >> [1] compiler_3.5.2 tools_3.5.2
    >> 
    >> Thanks,
    >> Joe
    >> 
    >> 
    >> 
    >> [[alternative HTML version deleted]]
    >> 
    >> ______________________________________________
    >> R-devel at r-project.org mailing list
    >> https://stat.ethz.ch/mailman/listinfo/r-devel

    > -- 
    > Peter Dalgaard, Professor,
    > Center for Statistics, Copenhagen Business School
    > Solbjerg Plads 3, 2000 Frederiksberg, Denmark
    > Phone: (+45)38153501
    > Office: A 4.23
    > Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com

    > ______________________________________________
    > R-devel at r-project.org mailing list
    > https://stat.ethz.ch/mailman/listinfo/r-devel


From bbo|ker @end|ng |rom gm@||@com  Thu Mar 14 20:57:54 2019
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Thu, 14 Mar 2019 15:57:54 -0400
Subject: [Rd] r76237 broken?
Message-ID: <c9447ca7-178e-2d9f-34a3-dcf212878a85@gmail.com>

    It looks like the most recent SVN commit changed line 1068 of
src/library/tools/R/admin.R to include a call to "shQuotee" (sic), which
is now breaking Travis r-devel builds ... ('checking sizes of PDF files
under ?inst/doc?: .Error in shQuotee(tf) : could not find function
"shQuotee"')

The new line reads:

        res <- system2(qpdf, c(qpdf_flags, shQuote(p), shQuotee(tf)),
FALSE, FALSE)

see:

svn diff -r76237:76236 src/library/tools/R/admin.R

 Seems like a straight-up typo?

  cheers
    Ben Bolker


From bbo|ker @end|ng |rom gm@||@com  Thu Mar 14 20:59:32 2019
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Thu, 14 Mar 2019 15:59:32 -0400
Subject: [Rd] r76237 broken?
In-Reply-To: <c9447ca7-178e-2d9f-34a3-dcf212878a85@gmail.com>
References: <c9447ca7-178e-2d9f-34a3-dcf212878a85@gmail.com>
Message-ID: <974e61a7-cd4a-2e97-e278-a65246a3633a@gmail.com>

PS there's also a "shQoute(tf2)" on line 1063 that will presumably also
cause trouble at some point ...

On 2019-03-14 3:57 p.m., Ben Bolker wrote:
>     It looks like the most recent SVN commit changed line 1068 of
> src/library/tools/R/admin.R to include a call to "shQuotee" (sic), which
> is now breaking Travis r-devel builds ... ('checking sizes of PDF files
> under ?inst/doc?: .Error in shQuotee(tf) : could not find function
> "shQuotee"')
> 
> The new line reads:
> 
>         res <- system2(qpdf, c(qpdf_flags, shQuote(p), shQuotee(tf)),
> FALSE, FALSE)
> 
> see:
> 
> svn diff -r76237:76236 src/library/tools/R/admin.R
> 
>  Seems like a straight-up typo?
> 
>   cheers
>     Ben Bolker
>


From @purd|e@@ @end|ng |rom gm@||@com  Fri Mar 15 04:18:40 2019
From: @purd|e@@ @end|ng |rom gm@||@com (Abs Spurdle)
Date: Fri, 15 Mar 2019 16:18:40 +1300
Subject: [Rd] as.data.frame.table() does not recognize
 default.stringsAsFactors()
Message-ID: <CAB8pepz6J+rX3tc1FU+1571gFaEMQvTupfzma+Nt6xWyReCW6w@mail.gmail.com>

Martin Maechler Wrote:
and we should've tried harder to keep things purely functional (R remaining
as closely as possible a "functional language")

This is diverging from the original post.
However, isn't R a multiparadigm programming language (by design)?

	[[alternative HTML version deleted]]


From jcm6t @end|ng |rom v|rg|n|@@edu  Thu Mar 14 17:33:07 2019
From: jcm6t @end|ng |rom v|rg|n|@@edu (Mychaleckyj, Josyf C (jcm6t))
Date: Thu, 14 Mar 2019 16:33:07 +0000
Subject: [Rd] as.data.frame.table() does not recognize
 default.stringsAsFactors()
In-Reply-To: <F28ED2D7-3280-4515-A47A-0C2C4B47E9BA@gmail.com>
References: <A27D36B8-A7D4-4347-ABC5-7214E0170213@virginia.edu>
 <F28ED2D7-3280-4515-A47A-0C2C4B47E9BA@gmail.com>
Message-ID: <0A7DCD85-2B6D-4D22-B0A7-5BD947385AEF@virginia.edu>

Peter,
Thanks for the response. I have no wish to prolong this and have no axe to grind. I?m sure you were delighted to see another stringsAsFactors issue.

Perhaps we talking about the conflation of two steps: the first is the language ?pure' conversion of the table to a data.frame with the cross-tab factor, followed by an optional  subsequent step with programmatic utility for a specific application, of conversion of that factor to a character column.

As my toy example shows, the as.data.frame.table() function permits passing the inline stringsAsFactors argument and returns a data.frame with a factor cross-tab column coerced as a character column, permitting these two steps to be accomplished in a single function.

If you intend the function to only meet the first step, then I would suggest you remove stringsAsFactors as an argument to this function and amend the documentation.  
Following this, if an application needed a coercion to a character, then it should be accomplished in a second step. 

If you are implying that the core team intended options(stringsAsFactors) to be a ?selective? global option then I am guess I am confused and have not seen documentation about a limited scope of the session-wide options(). 

?options
  ?stringsAsFactors?: The default setting for arguments of
          ?data.frame? and ?read.table?.

As a practical programming matter this inconsistency created a bug in our code that was very insidious and cost hours of debugging and a lot of head scratching. Chars and factors are always prime candidates, but we never even considered that the session option would not have been respected by a low level core function in which the function call in the documentation explicitly included the inline argument.

?as.data.frame.table() 

From the Usage section of as.data.frame.table()

     ## S3 method for class 'table'
     as.data.frame(x, row.names = NULL, ...,
                   responseName = "Freq", stringsAsFactors = TRUE,
                   sep = "", base = list(LETTERS))


Thanks,  Joe.


> On Mar 14, 2019, at 11:18 AM, peter dalgaard <pdalgd at gmail.com> wrote:
> 
> I have no recollection of the original rationale for as.data.frame.table, but I actually think it is fine as it is: 
> 
> The classifying _factors_ of a crosstable should be factors unless very specifically directed otherwise and that should not depend on the setting of an option that controls the conversion of character data. 
> 
> For as.data.frame.matrix, in contrast, it is the _content_ of the matrix that is being converted, and it seems much more reasonable to follow the same path as for other character data.
> 
> -pd
> 
>> On 12 Mar 2019, at 21:39 , Mychaleckyj, Josyf C (jcm6t) <jcm6t at virginia.edu> wrote:
>> 
>> Reporting a possible inconsistency or bug in handling stringsAsFactors in as.data.frame.table()
>> 
>> Here is a simple test
>> 
>>> options()$stringsAsFactors
>> [1] TRUE
>>> x<-c("a","b","c","a","b")
>>> d<-as.data.frame(table(x))
>>> d
>> x Freq
>> 1 a    2
>> 2 b    2
>> 3 c    1
>>> class(d$x)
>> [1] "factor"
>>> d2<-as.data.frame(table(x),stringsAsFactors=F)
>>> class(d2$x)
>> [1] ?character"
>>> options(stringsAsFactors=F)
>>> options()$stringsAsFactors
>> [1] FALSE
>>> d3<-as.data.frame(table(x))
>>> d3
>> x Freq
>> 1 a    2
>> 2 b    2
>> 3 c    1
>>> class(d3$x)
>> [1] ?factor"
>>> d4<-as.data.frame(table(x),stringsAsFactors=F)
>>> class(d4$x)
>> [1] ?character"
>> 
>> 
>> # Display the code showing the different  stringsAsFactors handling in table and matrix:
>> 
>>> as.data.frame.table
>> function (x, row.names = NULL, ..., responseName = "Freq", stringsAsFactors = TRUE,
>>   sep = "", base = list(LETTERS))
>> {
>>   ex <- quote(data.frame(do.call("expand.grid", c(dimnames(provideDimnames(x,
>>       sep = sep, base = base)), KEEP.OUT.ATTRS = FALSE, stringsAsFactors = stringsAsFactors)),
>>       Freq = c(x), row.names = row.names))
>>   names(ex)[3L] <- responseName
>>   eval(ex)
>> }
>> <bytecode: 0x28769f8>
>> <environment: namespace:base>
>> 
>>> as.data.frame.matrix
>> function (x, row.names = NULL, optional = FALSE, make.names = TRUE,
>>   ..., stringsAsFactors = default.stringsAsFactors())
>> {
>>   d <- dim(x)
>>   nrows <- d[[1L]]
>>   ncols <- d[[2L]]
>>   ic <- seq_len(ncols)
>>   dn <- dimnames(x)
>>   if (is.null(row.names))
>>       row.names <- dn[[1L]]
>>   collabs <- dn[[2L]]
>>   if (any(empty <- !nzchar(collabs)))
>>       collabs[empty] <- paste0("V", ic)[empty]
>>   value <- vector("list", ncols)
>>   if (mode(x) == "character" && stringsAsFactors) {
>>       for (i in ic) value[[i]] <- as.factor(x[, i])
>>   }
>>   else {
>>       for (i in ic) value[[i]] <- as.vector(x[, i])
>>   }
>>   autoRN <- (is.null(row.names) || length(row.names) != nrows)
>>   if (length(collabs) == ncols)
>>       names(value) <- collabs
>>   else if (!optional)
>>       names(value) <- paste0("V", ic)
>>   class(value) <- "data.frame"
>>   if (autoRN)
>>       attr(value, "row.names") <- .set_row_names(nrows)
>>   else .rowNamesDF(value, make.names = make.names) <- row.names
>>   value
>> }
>> <bytecode: 0x29995c0>
>> <environment: namespace:base>
>> 
>> 
>>> sessionInfo()
>> R version 3.5.2 (2018-12-20)
>> Platform: x86_64-pc-linux-gnu (64-bit)
>> Running under: CentOS Linux 7 (Core)
>> 
>> Matrix products: default
>> BLAS: /usr/lib64/libblas.so.3.4.2
>> LAPACK: /usr/lib64/liblapack.so.3.4.2
>> 
>> locale:
>> [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>> [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>> [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>> [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>> [9] LC_ADDRESS=C               LC_TELEPHONE=C
>> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>> 
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>> 
>> loaded via a namespace (and not attached):
>> [1] compiler_3.5.2 tools_3.5.2
>> 
>> Thanks,
>> Joe
>> 
>> 
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> -- 
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Office: A 4.23
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
> 
> 
> 
> 
> 
> 
> 
> 
> 


From therne@u @end|ng |rom m@yo@edu  Fri Mar 15 13:13:43 2019
From: therne@u @end|ng |rom m@yo@edu (Therneau, Terry M., Ph.D.)
Date: Fri, 15 Mar 2019 07:13:43 -0500
Subject: [Rd] as.data.frame.table() does not recognize
 default.stringsAsFactors()
In-Reply-To: <mailman.48347.7.1552647633.52245.r-devel@r-project.org>
References: <mailman.48347.7.1552647633.52245.r-devel@r-project.org>
Message-ID: <b23057$ba833r@ironport10.mayo.edu>

I have to disagree with both Peter and Martin on this.

The underneath issue is that the automatic conversion of characters to factors by the 
data.frame functions was the single most egregious design blunder in the Statistical 
Models in S book, and we are still living with it.? The stringsAsFactors option was a 
compromise to let users opt out of that mistake (one I had to fight hard for).??? In that 
light I read Peter's defense as "but in this case we really DO know better than the user, 
and won't let them opt out", and Martin's as "they shouldn't have been able to opt out in 
the first place, so weaken it at every opportunity".

I generally agree that global options should be minimal.? But if one exists, let's be 
consistent and listen to it.

(Footnote: In the Mayo Biostat group, stringsAsFactors=FALSE is the recommended global 
option for all users.? It's a pure cost/productivity thing.? We work on thousands of data 
sets in a year, and the errors and misunderstandings that silent conversions generate far 
outweigh any benefits. )

Terry T.


On 3/15/19 6:00 AM, r-devel-request at r-project.org wrote:
>      > I have no recollection of the original rationale for as.data.frame.table, but I actually think it is fine as it is:
>      > The classifying_factors_  of a crosstable should be factors unless very specifically directed otherwise and that should not depend on the setting of an option that controls the conversion of character data.
>
>      > For as.data.frame.matrix, in contrast, it is the_content_  of the matrix that is being converted, and it seems much more reasonable to follow the same path as for other character data.
>
>      > -pd
>
> I very strongly agree that as.data.frame.table() should not be
> changed to follow a global option.
>
> To the contrary: I've repeatedly mentioned that in my view it
> has been a design mistake to allow data.frame() and as.data.frame() be influenced
> by a global option
>   [and we should've tried harder to keep things purely functional
>     (R remaining as closely as possible a "functional language"),
>    e.g. by providing wrapper functions the same way we have such
>    wrappers for versions of read.table() with different defaults
>    for some of the arguments
>   ]


	[[alternative HTML version deleted]]


From pd@|gd @end|ng |rom gm@||@com  Fri Mar 15 14:31:08 2019
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Fri, 15 Mar 2019 14:31:08 +0100
Subject: [Rd] as.data.frame.table() does not recognize
 default.stringsAsFactors()
In-Reply-To: <b23057$ba833r@ironport10.mayo.edu>
References: <mailman.48347.7.1552647633.52245.r-devel@r-project.org>
 <b23057$ba833r@ironport10.mayo.edu>
Message-ID: <F52D139E-2B9A-4810-89E2-54F4B09839EE@gmail.com>

My point was that, in a table, the row and columns usually have a well-defined order. If you convert the table to data frame form, typically in order to fit a Poisson GLM, you do want to preserve that order, and not have the levels converted to a locale-dependent alphabetical order in your analyses. Or at least, if you do want conversion to character, you should say so very explicitly. That is the way it currently works: You can override, just not via the global option.

Notice also that it is very easy to do as.character(factor) if you need it, whereas it is rather more painful to convert a character vector to a factor with level names determined by the dimension names of the appropriate extent of the original table.

-pd

> On 15 Mar 2019, at 13:13 , Therneau, Terry M., Ph.D. via R-devel <r-devel at r-project.org> wrote:
> 
> I have to disagree with both Peter and Martin on this.
> 
> The underneath issue is that the automatic conversion of characters to factors by the 
> data.frame functions was the single most egregious design blunder in the Statistical 
> Models in S book, and we are still living with it.  The stringsAsFactors option was a 
> compromise to let users opt out of that mistake (one I had to fight hard for).    In that 
> light I read Peter's defense as "but in this case we really DO know better than the user, 
> and won't let them opt out", and Martin's as "they shouldn't have been able to opt out in 
> the first place, so weaken it at every opportunity".
> 
> I generally agree that global options should be minimal.  But if one exists, let's be 
> consistent and listen to it.
> 
> (Footnote: In the Mayo Biostat group, stringsAsFactors=FALSE is the recommended global 
> option for all users.  It's a pure cost/productivity thing.  We work on thousands of data 
> sets in a year, and the errors and misunderstandings that silent conversions generate far 
> outweigh any benefits. )
> 
> Terry T.
> 
> 
> On 3/15/19 6:00 AM, r-devel-request at r-project.org wrote:
>>> I have no recollection of the original rationale for as.data.frame.table, but I actually think it is fine as it is:
>>> The classifying_factors_  of a crosstable should be factors unless very specifically directed otherwise and that should not depend on the setting of an option that controls the conversion of character data.
>> 
>>> For as.data.frame.matrix, in contrast, it is the_content_  of the matrix that is being converted, and it seems much more reasonable to follow the same path as for other character data.
>> 
>>> -pd
>> 
>> I very strongly agree that as.data.frame.table() should not be
>> changed to follow a global option.
>> 
>> To the contrary: I've repeatedly mentioned that in my view it
>> has been a design mistake to allow data.frame() and as.data.frame() be influenced
>> by a global option
>>  [and we should've tried harder to keep things purely functional
>>    (R remaining as closely as possible a "functional language"),
>>   e.g. by providing wrapper functions the same way we have such
>>   wrappers for versions of read.table() with different defaults
>>   for some of the arguments
>>  ]
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From tom@@@k@||ber@ @end|ng |rom gm@||@com  Fri Mar 15 15:10:10 2019
From: tom@@@k@||ber@ @end|ng |rom gm@||@com (Tomas Kalibera)
Date: Fri, 15 Mar 2019 15:10:10 +0100
Subject: [Rd] Exit status of Rscript when setting
 options(error=utils::recover)
In-Reply-To: <CAKzW8ok4mRyb5MwAAkaN==9qcq+NrqNv8vj5YsWU_AhZM_gFMg@mail.gmail.com>
References: <CAKzW8ok4mRyb5MwAAkaN==9qcq+NrqNv8vj5YsWU_AhZM_gFMg@mail.gmail.com>
Message-ID: <c5bef2f7-677b-cbdb-914a-1316a21cfe0c@gmail.com>


Please refer to the documentation (?stop, ?recover, ?dump.frames). In 
non-interactive use, recover() works as dump.frames(). dump.frames() is 
documented not to quit R, and the examples show how to quit the R 
session with a given status automatically after dump.frames(). So in 
line with the documentation, R continues after the error, it reaches the 
end of the input, and returns 0.

When you run the example with the NULL default error handler (not 
setting the error option), the exit status is 1 as documented in ?stop.

To avoid surprise wrt to the exit status or where execution continues, 
it is best not to set default error handlers in non-interactive use (or 
set them so that they exit the session with a given exit status).

Tomas

On 3/10/19 4:15 AM, comic fans wrote:
> Hello, I've noticed that Rscript didn't exit with error code if I set
> options error = utils::recover in .Rprofile . for example
>
> Rscript -e "asdf"
>
> Error: object 'asdf' not found
> No suitable frames for recover()
>
> echo $?
> 0
>
> if didn't set options in .Rprofile, Rscript exit with error code 1, is
> this expected behavior ?
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From therne@u @end|ng |rom m@yo@edu  Fri Mar 15 17:27:30 2019
From: therne@u @end|ng |rom m@yo@edu (Therneau, Terry M., Ph.D.)
Date: Fri, 15 Mar 2019 11:27:30 -0500
Subject: [Rd] as.data.frame.table() does not recognize
 default.stringsAsFactors()
In-Reply-To: <F52D139E-2B9A-4810-89E2-54F4B09839EE@gmail.com>
References: <mailman.48347.7.1552647633.52245.r-devel@r-project.org>
 <b23057$ba833r@ironport10.mayo.edu>
 <F52D139E-2B9A-4810-89E2-54F4B09839EE@gmail.com>
Message-ID: <b23057$baaqrm@ironport10.mayo.edu>

Peter, we are arguing at cross purposes.? My point was that if I have specified 
options(stringsAsFactors=FALSE) that is a statement to R to NOT DO THIS.?? Your argument 
in return is that "yes, Therneau said that, but in this case he almost certainly doesn't 
really mean it, so ignore him".? Now the first part of your sentence may quite possibly be 
true.? I still don't like the second.

Of course, the best would be consistency from the start.? If I want a data frame form of 
table(a, b), what some packages call list mode, have the class of a, b in the result match 
the class of a,b at the start: character to character, factor to factor, numeric to 
numeric, etc.? The fact that all of them ended up as character in the intermediate 
dimnames takes much of the wind out my argument above: when converting a table to a 
dataframe the best R can do is guess what the original class was. ? Factor might indeed be 
the best guess, lacking a data.frame=TRUE argument for table().

Here, though I hate to say it, is an argument for your side: data.frame(table( rep(1:10, 
length=15)))
"10" should be after "9".

Terry T.


On 3/15/19 8:31 AM, peter dalgaard wrote:
> My point was that, in a table, the row and columns usually have a well-defined order. If you convert the table to data frame form, typically in order to fit a Poisson GLM, you do want to preserve that order, and not have the levels converted to a locale-dependent alphabetical order in your analyses. Or at least, if you do want conversion to character, you should say so very explicitly. That is the way it currently works: You can override, just not via the global option.
>
> Notice also that it is very easy to do as.character(factor) if you need it, whereas it is rather more painful to convert a character vector to a factor with level names determined by the dimension names of the appropriate extent of the original table.
>
> -pd
>
>> On 15 Mar 2019, at 13:13 , Therneau, Terry M., Ph.D. via R-devel <r-devel at r-project.org> wrote:
>>
>> I have to disagree with both Peter and Martin on this.
>>
>> The underneath issue is that the automatic conversion of characters to factors by the
>> data.frame functions was the single most egregious design blunder in the Statistical
>> Models in S book, and we are still living with it.  The stringsAsFactors option was a
>> compromise to let users opt out of that mistake (one I had to fight hard for).    In that
>> light I read Peter's defense as "but in this case we really DO know better than the user,
>> and won't let them opt out", and Martin's as "they shouldn't have been able to opt out in
>> the first place, so weaken it at every opportunity".
>>
>> I generally agree that global options should be minimal.  But if one exists, let's be
>> consistent and listen to it.
>>
>> (Footnote: In the Mayo Biostat group, stringsAsFactors=FALSE is the recommended global
>> option for all users.  It's a pure cost/productivity thing.  We work on thousands of data
>> sets in a year, and the errors and misunderstandings that silent conversions generate far
>> outweigh any benefits. )
>>
>> Terry T.
>>
>>
>> On 3/15/19 6:00 AM, r-devel-request at r-project.org wrote:
>>>> I have no recollection of the original rationale for as.data.frame.table, but I actually think it is fine as it is:
>>>> The classifying_factors_  of a crosstable should be factors unless very specifically directed otherwise and that should not depend on the setting of an option that controls the conversion of character data.
>>>> For as.data.frame.matrix, in contrast, it is the_content_  of the matrix that is being converted, and it seems much more reasonable to follow the same path as for other character data.
>>>> -pd
>>> I very strongly agree that as.data.frame.table() should not be
>>> changed to follow a global option.
>>>
>>> To the contrary: I've repeatedly mentioned that in my view it
>>> has been a design mistake to allow data.frame() and as.data.frame() be influenced
>>> by a global option
>>>   [and we should've tried harder to keep things purely functional
>>>     (R remaining as closely as possible a "functional language"),
>>>    e.g. by providing wrapper functions the same way we have such
>>>    wrappers for versions of read.table() with different defaults
>>>    for some of the arguments
>>>   ]
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel


	[[alternative HTML version deleted]]


From @purd|e@@ @end|ng |rom gm@||@com  Fri Mar 15 22:43:43 2019
From: @purd|e@@ @end|ng |rom gm@||@com (Abs Spurdle)
Date: Sat, 16 Mar 2019 10:43:43 +1300
Subject: [Rd] Could we make filled.contour() more suitable for PDF viewers?
Message-ID: <CAB8pepxs9HEx=4C3kW6xKuu9febFUT=DsQ-his2=EecD61CvZA@mail.gmail.com>

Note that I sent this to r-devel, yesterday.
However, it didn't appear on the mailing list.
So, I'm resending it.

Today, I plotted the following:
> filled.contour (,,z, color.palette=terrain.colors)

It looked OK, in R.
However, when I created a PDF document, the plot (and other similar plots)
had grid (and other) lines in it, that shouldn't be there.
Note that this problem is more obvious with terrain.colors than cm.colors,
which is the default.

I found this in the help file for the pdf() function:
"the problem is much more likely to be in your viewer than in R... apparent
grids on image plots (turn off graphics anti-aliasing in your viewer if you
can)..."

Later, I found (in Acrobat Reader XI) the following option:
Edit > Preferences... > Page Display > Smooth line art

I unticked this option and it corrected the problem.

In principle, this is a problem with the PDF viewer, and not R.
However, it would be better if filled.contour() didn't have this result.
And I've decided not to use filled.contour() because of this.

Note that filled.contour() calls .filled.contour(), which calls:
+ .External.graphics(C_filledcontour, x, y, z, levels, col)

Also note that I had a similar plot with a similar problem.
It contained the following line:
+ polygon (xsub, ysub, border=NA, col=colstr)
But the problem was corrected after changing it to:
+ polygon (xsub, ysub, border=colstr, col=colstr)

I'm assuming that an equally simple change to C_filledcontour, could
correct the problem above.

	[[alternative HTML version deleted]]


From p@u| @end|ng |rom @t@t@@uck|@nd@@c@nz  Sun Mar 17 23:49:26 2019
From: p@u| @end|ng |rom @t@t@@uck|@nd@@c@nz (Paul Murrell)
Date: Mon, 18 Mar 2019 11:49:26 +1300
Subject: [Rd] 
 [FORGED] Could we make filled.contour() more suitable for PDF
 viewers?
In-Reply-To: <CAB8pepxs9HEx=4C3kW6xKuu9febFUT=DsQ-his2=EecD61CvZA@mail.gmail.com>
References: <CAB8pepxs9HEx=4C3kW6xKuu9febFUT=DsQ-his2=EecD61CvZA@mail.gmail.com>
Message-ID: <66de79fc-9aef-60d6-5473-fa8afb7dcf92@stat.auckland.ac.nz>

Hi

One problem with that solution is that it is drawing the wrong thing.
The border of the polygonal regions is drawn centred on the edge of the 
region, so it overlaps adjacent regions.  The following code exaggerates 
the problem ...

pdf("demo.pdf")
dev.control("enable")
image(x=1:2, y=1:2, z=matrix(1:4, ncol=2))
library(gridGraphics)
grid.echo()
rect <- grid.get("rect", grep=TRUE)
grid.edit("rect", grep=TRUE,
           gp=gpar(col=adjustcolor(1:4, alpha=.5), lwd=10,
                   fill=adjustcolor(rect$gp$fill, alpha=.5)))
dev.off()

Paul

On 16/03/19 10:43 AM, Abs Spurdle wrote:
> Note that I sent this to r-devel, yesterday.
> However, it didn't appear on the mailing list.
> So, I'm resending it.
> 
> Today, I plotted the following:
>> filled.contour (,,z, color.palette=terrain.colors)
> 
> It looked OK, in R.
> However, when I created a PDF document, the plot (and other similar plots)
> had grid (and other) lines in it, that shouldn't be there.
> Note that this problem is more obvious with terrain.colors than cm.colors,
> which is the default.
> 
> I found this in the help file for the pdf() function:
> "the problem is much more likely to be in your viewer than in R... apparent
> grids on image plots (turn off graphics anti-aliasing in your viewer if you
> can)..."
> 
> Later, I found (in Acrobat Reader XI) the following option:
> Edit > Preferences... > Page Display > Smooth line art
> 
> I unticked this option and it corrected the problem.
> 
> In principle, this is a problem with the PDF viewer, and not R.
> However, it would be better if filled.contour() didn't have this result.
> And I've decided not to use filled.contour() because of this.
> 
> Note that filled.contour() calls .filled.contour(), which calls:
> + .External.graphics(C_filledcontour, x, y, z, levels, col)
> 
> Also note that I had a similar plot with a similar problem.
> It contained the following line:
> + polygon (xsub, ysub, border=NA, col=colstr)
> But the problem was corrected after changing it to:
> + polygon (xsub, ysub, border=colstr, col=colstr)
> 
> I'm assuming that an equally simple change to C_filledcontour, could
> correct the problem above.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/


From henr|k@bengt@@on @end|ng |rom gm@||@com  Mon Mar 18 02:23:56 2019
From: henr|k@bengt@@on @end|ng |rom gm@||@com (Henrik Bengtsson)
Date: Sun, 17 Mar 2019 18:23:56 -0700
Subject: [Rd] SUGGESTION: Proposal to mitigate problem with stray processes
 left behind by parallel::makeCluster()
Message-ID: <CAFDcVCQ5H_5EDrEKy+ZGaBHQNSn0saHbg2VtDVc7j39GoRNnQA@mail.gmail.com>

(Bcc: CRAN)

This is a proposal helping CRAN and alike as well as individual
developers to avoid stray R processes being left behind that might be
produced when an example or a package test fails to set up a
parallel::makeCluster().


ISSUE

If a package test sets up a PSOCK cluster and then the master process
dies for one reason or the other, the PSOCK worker processes will
remain running for 30 days ('timeout') until they timeout and
terminate that way.  When this happens on CRAN servers, where many
packages are checked all the time, this will result in a lot of stray
R processes.

Here is an example illustrating how R leaves behind stray R processes
if fails to establish a connection to one or more background R
processes launched by 'parallel::makeCluster()'.  First, let's make
sure there are no other R processes running:

  $ ps aux | grep -E "exec[/]R"

Then, lets create a PSOCK cluster for which connection will fail
(because port 80 is reserved):

  $ Rscript -e 'parallel::makeCluster(1L, port=80)'
  Error in socketConnection("localhost", port = port, server = TRUE,
blocking = TRUE,  :
    cannot open the connection
  Calls: <Anonymous> ... makePSOCKcluster -> newPSOCKnode -> socketConnection
  In addition: Warning message:
  In socketConnection("localhost", port = port, server = TRUE,
blocking = TRUE,  :
    port 80 cannot be opened

The launched R worker is still running:

  $ ps aux | grep -E "exec[/]R"
  hb       20778 37.0  0.4 283092 70624 pts/0    S    17:50   0:00
/usr/lib/R/bin/exec/R --slave --no-restore -e parallel:::.slaveRSOCK()
--args MASTER=localhost PORT=80 OUT=/dev/null SETUPTIMEOUT=120
TIMEOUT=2 592000 XDR=TRUE

This process will keep running for 'TIMEOUT=2592000' seconds (= 30
days).  The reason for this is that it is currently in the state where
it attempts to set up a connection to the main R process:

  > parallel:::.slaveRSOCK
  function ()
  {
      makeSOCKmaster <- function(master, port, setup_timeout, timeout,
          useXDR) {
   ...
          repeat {
              con <- tryCatch({
                  socketConnection(master, port = port, blocking = TRUE,
                    open = "a+b", timeout = timeout)
              }, error = identity)
      ...
  }

In other words, it is stuck in 'socketConnection()' and it won't time
out until 'timeout' seconds.


SUGGESTION

To mitigate the problem with above stray processes from running 'R CMD
check', we could shorten the 'timeout' which is currently hardcoded to
30 days (src/library/parallel/R/snow.R).  By making it possible to
control the default via environment variables, e.g.

  setup_timeout = as.numeric(Sys.getenv("R_PARALLEL_SETUP_TIMEOUT", 60
* 2)),      # 2 minutes
  timeout = as.numeric(Sys.getenv("R_PARALLEL_SETUP_TIMEOUT", 60 * 60
* 24 * 30)), # 30 days

it would be straightforward to adjust `R CMD check` to use, say,

  R_PARALLEL_SETUP_TIMEOUT=60

by default.  This would cause any stray processes to time out after 60
seconds (instead of 30 days as now).

/Henrik


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Mon Mar 18 10:16:32 2019
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Mon, 18 Mar 2019 10:16:32 +0100
Subject: [Rd] broken link in docs for Binormial functions
In-Reply-To: <A418E98B-80C3-4544-913F-9740EEF2DE5A@gmail.com>
References: <CA+MmmT+Tf0yT8_MBdj=wXtUQv4ubz6sq56oM-YgD5YuKUrC_dg@mail.gmail.com>
 <52068237.9060103@stats.ox.ac.uk>
 <A418E98B-80C3-4544-913F-9740EEF2DE5A@gmail.com>
Message-ID: <23695.25072.558662.493303@stat.math.ethz.ch>

As the topic came up on R-help
  (as side issue in 'density vs. mass for discrete probability functions')
and Rui mentioned this old thread:
   https://stat.ethz.ch/pipermail/r-help/2019-March/461989.html

I'm taking up this 5.5 years old thread from R-devel:

>>>>> peter dalgaard 
>>>>>     on Sat, 10 Aug 2013 20:34:04 +0200 writes:

    > On Aug 10, 2013, at 20:11 , Prof Brian Ripley wrote:

    >> On 10/08/2013 14:48, Sean O'Riordain wrote:
    >>> On the local documentation page for Binomial, i.e.
    >>> http://127.0.0.1:xxxx/library/stats/html/Binomial.html
    >>> 
    >>> The link to Catherine Loader's paper
    >>> "Catherine Loader (2000). *Fast and Accurate Computation of Binomial
    >>> Probabilities*; available from
    >>> http://www.herine.net/stat/software/dbinom.html."
    >>> 
    >>> appears to be broken.
    >> 
    >> And what should it be replaced by?  (We've fixed this up at least once before.)
    >> 
    >> As Berners-Lee says, URIs should be permanent ....

    > It can be dug up via Google Scholar fairly easily, but the link goes to an attachment to an Octave enhancement request!

Fortunately, it's still true that googling still finds the pdf
(made from an original postscript (which I also have)).
However, there's a slightly more current version I've been
keeping in my personal collection which is from 2002 as a Bell
Labs "tech report".
I've put it up here for now:
     https://stat.ethz.ch/~maechler/doc/CLoader-dbinom-2002.pdf

    > Perhaps we should ask permission to nail the thing down somewhere on r-project.org?

Yes, I think we should do so now, somewhere on  *.r-project.org .

    > -pd

    > (Berners-Lee et al. never foresaw the chaos created by the commercialization of the web, or indeed of other academic infrastructures. Try locating Catherine herself or even the stats department at CWRU to see what I mean.)

    > -- 
    > Peter Dalgaard, Professor,
    > Center for Statistics, Copenhagen Business School
    > Solbjerg Plads 3, 2000 Frederiksberg, Denmark
    > Phone: (+45)38153501
    > Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com

    > ______________________________________________
    > R-devel at r-project.org mailing list
    > https://stat.ethz.ch/mailman/listinfo/r-devel


From com|c|@n@44 @end|ng |rom gm@||@com  Mon Mar 18 04:44:08 2019
From: com|c|@n@44 @end|ng |rom gm@||@com (comic fans)
Date: Mon, 18 Mar 2019 11:44:08 +0800
Subject: [Rd] Exit status of Rscript when setting
 options(error=utils::recover)
In-Reply-To: <c5bef2f7-677b-cbdb-914a-1316a21cfe0c@gmail.com>
References: <CAKzW8ok4mRyb5MwAAkaN==9qcq+NrqNv8vj5YsWU_AhZM_gFMg@mail.gmail.com>
 <c5bef2f7-677b-cbdb-914a-1316a21cfe0c@gmail.com>
Message-ID: <CAKzW8o=RJEZ5oiiM2uyRuonKkvQ-h2jdLNcOHboJF9nzwVxy0A@mail.gmail.com>

Thanks for explanation,  so recover in non-interactive session exit
with 0 is expected behavior .
dump.frames said that it always write to file (workspace , or specified file).
I have a R script run as a auto build stage, so I want to print detail
backtrace to console
 (with source file, line number)  for quickly debug, without saving any dump.
I tried

options(error= quote({utils::recover;q(status=1)}))

it do exit with 1 when script has error, but it only shows a stripped
call trace like

Calls: a ... a -> a -> a -> a -> a -> a -> a -> a -> a -> a -> apply

instead of
...
99: rec.R#5: a(v, depth - 1)
100: rec.R#5: a(v, depth - 1)
101: rec.R#5: a(v, depth - 1)
102: rec.R#5: a(v, depth - 1)
103: rec.R#5: a(v, depth - 1)

How can I resolve this ? Thanks for advise


On Fri, Mar 15, 2019 at 10:10 PM Tomas Kalibera
<tomas.kalibera at gmail.com> wrote:
>
>
> Please refer to the documentation (?stop, ?recover, ?dump.frames). In
> non-interactive use, recover() works as dump.frames(). dump.frames() is
> documented not to quit R, and the examples show how to quit the R
> session with a given status automatically after dump.frames(). So in
> line with the documentation, R continues after the error, it reaches the
> end of the input, and returns 0.
>
> When you run the example with the NULL default error handler (not
> setting the error option), the exit status is 1 as documented in ?stop.
>
> To avoid surprise wrt to the exit status or where execution continues,
> it is best not to set default error handlers in non-interactive use (or
> set them so that they exit the session with a given exit status).
>
> Tomas
>
> On 3/10/19 4:15 AM, comic fans wrote:
> > Hello, I've noticed that Rscript didn't exit with error code if I set
> > options error = utils::recover in .Rprofile . for example
> >
> > Rscript -e "asdf"
> >
> > Error: object 'asdf' not found
> > No suitable frames for recover()
> >
> > echo $?
> > 0
> >
> > if didn't set options in .Rprofile, Rscript exit with error code 1, is
> > this expected behavior ?
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From @tep@n@@|nde|@r @end|ng |rom or@c|e@com  Mon Mar 18 09:31:56 2019
From: @tep@n@@|nde|@r @end|ng |rom or@c|e@com (Stepan)
Date: Mon, 18 Mar 2019 09:31:56 +0100
Subject: [Rd] RIOT 2019
Message-ID: <00155d89-23f9-cfe0-a267-6d29bb18e754@oracle.com>

I hope you don?t mind us using this mailing list for a small 
advertisement, but we think it is most relevant for this group:

We'd like to invite you to RIOT 2019 - the 4rd workshop on R 
Implementation, Optimization and Tooling [1].

It will take place co-located with, and during, useR! 2019 in Toulouse 
on July 11th. RIOT is an excellent venue for deep technical discussions 
about R implementations, tools, optimizations and extension, and will be 
very interesting for anyone interested in what?s under the hood of R 
implementations.

Regards,
Stepan Sindelar, Lukas Stadler (Oracle), Jan Vitek (Northeastern), 
Alexander Bertram (BeDataDriven)

[1] http://riotworkshop.github.io/


From @|mon@urb@nek @end|ng |rom R-project@org  Mon Mar 18 15:15:46 2019
From: @|mon@urb@nek @end|ng |rom R-project@org (Simon Urbanek)
Date: Mon, 18 Mar 2019 10:15:46 -0400
Subject: [Rd] Exit status of Rscript when setting
 options(error=utils::recover)
In-Reply-To: <CAKzW8o=RJEZ5oiiM2uyRuonKkvQ-h2jdLNcOHboJF9nzwVxy0A@mail.gmail.com>
References: <CAKzW8ok4mRyb5MwAAkaN==9qcq+NrqNv8vj5YsWU_AhZM_gFMg@mail.gmail.com>
 <c5bef2f7-677b-cbdb-914a-1316a21cfe0c@gmail.com>
 <CAKzW8o=RJEZ5oiiM2uyRuonKkvQ-h2jdLNcOHboJF9nzwVxy0A@mail.gmail.com>
Message-ID: <8D648AB0-CEC4-491C-B888-54356F864C12@R-project.org>

As Tomas pointed out, it may be helpful to read the R documentation. The error option expects a function, so I suppose you intended something like
options(error=function() {recover(); q(status=1)})
which corresponds to calling dump.frames()

Cheers,
Simon


> On Mar 17, 2019, at 23:44, comic fans <comicfans44 at gmail.com> wrote:
> 
> Thanks for explanation,  so recover in non-interactive session exit
> with 0 is expected behavior .
> dump.frames said that it always write to file (workspace , or specified file).
> I have a R script run as a auto build stage, so I want to print detail
> backtrace to console
> (with source file, line number)  for quickly debug, without saving any dump.
> I tried
> 
> options(error= quote({utils::recover;q(status=1)}))
> 
> it do exit with 1 when script has error, but it only shows a stripped
> call trace like
> 
> Calls: a ... a -> a -> a -> a -> a -> a -> a -> a -> a -> a -> apply
> 
> instead of
> ...
> 99: rec.R#5: a(v, depth - 1)
> 100: rec.R#5: a(v, depth - 1)
> 101: rec.R#5: a(v, depth - 1)
> 102: rec.R#5: a(v, depth - 1)
> 103: rec.R#5: a(v, depth - 1)
> 
> How can I resolve this ? Thanks for advise
> 
> 
> On Fri, Mar 15, 2019 at 10:10 PM Tomas Kalibera
> <tomas.kalibera at gmail.com> wrote:
>> 
>> 
>> Please refer to the documentation (?stop, ?recover, ?dump.frames). In
>> non-interactive use, recover() works as dump.frames(). dump.frames() is
>> documented not to quit R, and the examples show how to quit the R
>> session with a given status automatically after dump.frames(). So in
>> line with the documentation, R continues after the error, it reaches the
>> end of the input, and returns 0.
>> 
>> When you run the example with the NULL default error handler (not
>> setting the error option), the exit status is 1 as documented in ?stop.
>> 
>> To avoid surprise wrt to the exit status or where execution continues,
>> it is best not to set default error handlers in non-interactive use (or
>> set them so that they exit the session with a given exit status).
>> 
>> Tomas
>> 
>> On 3/10/19 4:15 AM, comic fans wrote:
>>> Hello, I've noticed that Rscript didn't exit with error code if I set
>>> options error = utils::recover in .Rprofile . for example
>>> 
>>> Rscript -e "asdf"
>>> 
>>> Error: object 'asdf' not found
>>> No suitable frames for recover()
>>> 
>>> echo $?
>>> 0
>>> 
>>> if didn't set options in .Rprofile, Rscript exit with error code 1, is
>>> this expected behavior ?
>>> 
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> 
>> 
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 


From @uh@rto_@nggono @end|ng |rom y@hoo@com  Mon Mar 18 17:04:54 2019
From: @uh@rto_@nggono @end|ng |rom y@hoo@com (Suharto Anggono Suharto Anggono)
Date: Mon, 18 Mar 2019 16:04:54 +0000 (UTC)
Subject: [Rd] Inappropriate "Unix-alike platforms" in txtProgressBar.Rd in R
 devel
References: <761463299.6785431.1552925094373.ref@mail.yahoo.com>
Message-ID: <761463299.6785431.1552925094373@mail.yahoo.com>

In current R devel (r76247), "See Also" section of help page on 'txtProgressBar' (https://svn.r-project.org/R/trunk/src/library/utils/man/txtProgressBar.Rd) has "Unix-alike platforms" as a detail on 'tkProgressBar':
\seealso{
  \code{\link{winProgressBar}} (Windows only),
  \code{\link{tkProgressBar}} (Unix-alike platforms).
}

In fact, 'tkProgressBar' also exists in R on Windows.


From h@brede| @end|ng |rom gmx@de  Mon Mar 18 17:28:52 2019
From: h@brede| @end|ng |rom gmx@de (Henning Bredel)
Date: Mon, 18 Mar 2019 17:28:52 +0100
Subject: [Rd] Possibly broken system2 env-option
Message-ID: <f38d1b55-c8f8-dbe4-94c4-bf15bb32c052@gmx.de>

Hey all,

what is wrong with this command:

  system2("echo", env = c(VAR = "Hello World"), args = c("$VAR"))

I am a bit confused, as help("system2") writes about the env option:

> character vector of name=value strings to set environment variables.

Is this option buggy, or am I using it just wrong?

Thanks for your help

  Henning


From c@@rd|@g@bor @end|ng |rom gm@||@com  Tue Mar 19 10:48:16 2019
From: c@@rd|@g@bor @end|ng |rom gm@||@com (=?UTF-8?B?R8OhYm9yIENzw6FyZGk=?=)
Date: Tue, 19 Mar 2019 09:48:16 +0000
Subject: [Rd] Possibly broken system2 env-option
In-Reply-To: <f38d1b55-c8f8-dbe4-94c4-bf15bb32c052@gmx.de>
References: <f38d1b55-c8f8-dbe4-94c4-bf15bb32c052@gmx.de>
Message-ID: <CABtg=KkHmtMK5hLGJe52fyQkMe7tYN3Jj8KivPMdopQp4MyLJQ@mail.gmail.com>

Probably not broken, just hard to get the quoting right? Or it does
not work with echo?

It is surely hard to get it right, I have been trying for 15 minutes.I
am pretty sure that the correct form is env = "VAR='Hello-World'" but
spaces and other special characters might cause trouble. E.g. this
works, but only without spaces (px is an internal tool for testing,
that can get an env var, and it is portable):

? px <- processx:::get_tool("px")
? system2(px, c("getenv", "VAR"), env = "VAR=foo")
foo

? system2(px, c("getenv", "VAR"), env = c(VAR="Hello World"))
sh: Hello: command not found
Warning message:
In system2(px, c("getenv", "VAR"), env = c(VAR = "Hello World")) :
  error in running command

Somebody with more system2() experience can probably fix this, but
here is an alternative, using the processx package:

? processx::run(px, c("getenv", "VAR"), env = c(Sys.getenv(), VAR =
"Hello World"))
$status
[1] 0

$stdout
[1] "Hello World\n"

$stderr
[1] ""

$timeout
[1] FALSE

For processx, you don't need to quote anything (i.e. command,
arguments or env vars), because it does not
use an intermediate shell.

Disclaimer: I am an author of processx.

Gabor

On Tue, Mar 19, 2019 at 9:28 AM Henning Bredel <h.bredel at gmx.de> wrote:
>
> Hey all,
>
> what is wrong with this command:
>
>   system2("echo", env = c(VAR = "Hello World"), args = c("$VAR"))
>
> I am a bit confused, as help("system2") writes about the env option:
>
> > character vector of name=value strings to set environment variables.
>
> Is this option buggy, or am I using it just wrong?
>
> Thanks for your help
>
>   Henning
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From pd@|gd @end|ng |rom gm@||@com  Tue Mar 19 10:51:36 2019
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Tue, 19 Mar 2019 10:51:36 +0100
Subject: [Rd] Possibly broken system2 env-option
In-Reply-To: <f38d1b55-c8f8-dbe4-94c4-bf15bb32c052@gmx.de>
References: <f38d1b55-c8f8-dbe4-94c4-bf15bb32c052@gmx.de>
Message-ID: <3244E2B3-3E44-4469-919B-4E5768F06F23@gmail.com>

You are using it wrong. It wants strings of the form "name=value", not a character vector with names as labels. So this is closer to the mark:

> system2("echo", env = c("VAR='Hello World'"), args = c("$VAR"))

>

However, as you see it doesn't work as intended. The problem is that the $-substitution refers to the environment of the shell executing the command. I.e. this does not work from a terminal command line either:

pd$ VAR="foo" echo $VAR

pd$

Or even

pd$ VAR="bar"
pd$ VAR="foo" echo $VAR
bar

What you need is something like (NB: single quotes!)

pd$ VAR="foo" sh -c 'echo $VAR'
foo

So:

> system2("sh", env = c("VAR='Hello World'"), args = c("-c 'echo $VAR'"))
Hello World

-pd

> On 18 Mar 2019, at 17:28 , Henning Bredel <h.bredel at gmx.de> wrote:
> 
> Hey all,
> 
> what is wrong with this command:
> 
>  system2("echo", env = c(VAR = "Hello World"), args = c("$VAR"))
> 
> I am a bit confused, as help("system2") writes about the env option:
> 
>> character vector of name=value strings to set environment variables.
> 
> Is this option buggy, or am I using it just wrong?
> 
> Thanks for your help
> 
>  Henning
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From c@@rd|@g@bor @end|ng |rom gm@||@com  Tue Mar 19 11:09:50 2019
From: c@@rd|@g@bor @end|ng |rom gm@||@com (=?UTF-8?B?R8OhYm9yIENzw6FyZGk=?=)
Date: Tue, 19 Mar 2019 10:09:50 +0000
Subject: [Rd] Possibly broken system2 env-option
In-Reply-To: <3244E2B3-3E44-4469-919B-4E5768F06F23@gmail.com>
References: <f38d1b55-c8f8-dbe4-94c4-bf15bb32c052@gmx.de>
 <3244E2B3-3E44-4469-919B-4E5768F06F23@gmail.com>
Message-ID: <CABtg=K=RUYOXkgUgMmMKxYcmDTm9ZUNt2bErKLrs9wiMx1B50w@mail.gmail.com>

On Tue, Mar 19, 2019 at 9:59 AM peter dalgaard <pdalgd at gmail.com> wrote:
[...]
> What you need is something like (NB: single quotes!)
> > system2("sh", env = c("VAR='Hello World'"), args = c("-c 'echo $VAR'"))
> Hello World

Just out of curiosity, do you think it is possible to make this
portable, assuming sh is available? On Windows it gives

> system2("sh", env = c("VAR='Hello World'"), args = c("-c 'echo $VAR'"))
/rtools34/bin/sh: VAR=Hello World: No such file or directory
Warning message:
running command '"sh" VAR='Hello World' -c 'echo $VAR'' had status 127

G.


From pd@|gd @end|ng |rom gm@||@com  Tue Mar 19 11:44:40 2019
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Tue, 19 Mar 2019 11:44:40 +0100
Subject: [Rd] Possibly broken system2 env-option
In-Reply-To: <CABtg=K=RUYOXkgUgMmMKxYcmDTm9ZUNt2bErKLrs9wiMx1B50w@mail.gmail.com>
References: <f38d1b55-c8f8-dbe4-94c4-bf15bb32c052@gmx.de>
 <3244E2B3-3E44-4469-919B-4E5768F06F23@gmail.com>
 <CABtg=K=RUYOXkgUgMmMKxYcmDTm9ZUNt2bErKLrs9wiMx1B50w@mail.gmail.com>
Message-ID: <A5278CAD-D8BD-45B2-A14C-709BDB8FFDB0@gmail.com>

     On Windows, ?env? is only supported for commands such as ?R? and
     ?make? which accept environment variables on their command line.

So I suppose that would be tricky. 

The basic issue is that on Unix-alikes, system2 constructs a command like

FOO=bar cmd args

and passes that to sh via system(). On windoes, system() does not call sh, so system2() does (effectively)

cmd FOO=bar args

and hopes that cmd knows what to do with the env setting.

-pd

> On 19 Mar 2019, at 11:09 , G?bor Cs?rdi <csardi.gabor at gmail.com> wrote:
> 
> On Tue, Mar 19, 2019 at 9:59 AM peter dalgaard <pdalgd at gmail.com> wrote:
> [...]
>> What you need is something like (NB: single quotes!)
>>> system2("sh", env = c("VAR='Hello World'"), args = c("-c 'echo $VAR'"))
>> Hello World
> 
> Just out of curiosity, do you think it is possible to make this
> portable, assuming sh is available? On Windows it gives
> 
>> system2("sh", env = c("VAR='Hello World'"), args = c("-c 'echo $VAR'"))
> /rtools34/bin/sh: VAR=Hello World: No such file or directory
> Warning message:
> running command '"sh" VAR='Hello World' -c 'echo $VAR'' had status 127
> 
> G.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From c@@rd|@g@bor @end|ng |rom gm@||@com  Tue Mar 19 11:51:10 2019
From: c@@rd|@g@bor @end|ng |rom gm@||@com (=?UTF-8?B?R8OhYm9yIENzw6FyZGk=?=)
Date: Tue, 19 Mar 2019 10:51:10 +0000
Subject: [Rd] Possibly broken system2 env-option
In-Reply-To: <A5278CAD-D8BD-45B2-A14C-709BDB8FFDB0@gmail.com>
References: <f38d1b55-c8f8-dbe4-94c4-bf15bb32c052@gmx.de>
 <3244E2B3-3E44-4469-919B-4E5768F06F23@gmail.com>
 <CABtg=K=RUYOXkgUgMmMKxYcmDTm9ZUNt2bErKLrs9wiMx1B50w@mail.gmail.com>
 <A5278CAD-D8BD-45B2-A14C-709BDB8FFDB0@gmail.com>
Message-ID: <CABtg=Kn_1-2thZSfb+UFrpYx=ukWFKy3Un7qTkv1k1-mgb5eWg@mail.gmail.com>

Right. I suppose, one thing you can do is setting the env var in the
current process, call system2() and then unset/restore the env var.
This is unlikely to cause problems, unless your R process is
multi-threaded, and the env var causes troubles in the other threads.
The withr package makes setting the temporary env var convenient, but
it is easy to write your own with_envvar() function:

withr::with_envvar(
  c(VAR = "Hello world"),
  system2("sh", "-c 'echo $VAR'"))

This seems to be portable, at least it works on macOS and Windows.

G.


On Tue, Mar 19, 2019 at 10:44 AM peter dalgaard <pdalgd at gmail.com> wrote:
>
>      On Windows, ?env? is only supported for commands such as ?R? and
>      ?make? which accept environment variables on their command line.
>
> So I suppose that would be tricky.
>
> The basic issue is that on Unix-alikes, system2 constructs a command like
>
> FOO=bar cmd args
>
> and passes that to sh via system(). On windoes, system() does not call sh, so system2() does (effectively)
>
> cmd FOO=bar args
>
> and hopes that cmd knows what to do with the env setting.
>
> -pd
>
> > On 19 Mar 2019, at 11:09 , G?bor Cs?rdi <csardi.gabor at gmail.com> wrote:
> >
> > On Tue, Mar 19, 2019 at 9:59 AM peter dalgaard <pdalgd at gmail.com> wrote:
> > [...]
> >> What you need is something like (NB: single quotes!)
> >>> system2("sh", env = c("VAR='Hello World'"), args = c("-c 'echo $VAR'"))
> >> Hello World
> >
> > Just out of curiosity, do you think it is possible to make this
> > portable, assuming sh is available? On Windows it gives
> >
> >> system2("sh", env = c("VAR='Hello World'"), args = c("-c 'echo $VAR'"))
> > /rtools34/bin/sh: VAR=Hello World: No such file or directory
> > Warning message:
> > running command '"sh" VAR='Hello World' -c 'echo $VAR'' had status 127
> >
> > G.
>
> --
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Office: A 4.23
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>
>
>
>
>
>
>
>
>


From h@brede| @end|ng |rom gmx@de  Tue Mar 19 12:33:46 2019
From: h@brede| @end|ng |rom gmx@de (Henning Bredel)
Date: Tue, 19 Mar 2019 12:33:46 +0100
Subject: [Rd] Possibly broken system2 env-option
In-Reply-To: <3244E2B3-3E44-4469-919B-4E5768F06F23@gmail.com>
References: <f38d1b55-c8f8-dbe4-94c4-bf15bb32c052@gmx.de>
 <3244E2B3-3E44-4469-919B-4E5768F06F23@gmail.com>
Message-ID: <8ec75b7c-722a-3d03-5976-db3e9b5e69fb@gmx.de>

Okay, thanks for clarification.

On 3/19/19 10:51 AM, peter dalgaard wrote:
> You are using it wrong. It wants strings of the form "name=value", not a character vector with names as labels. So this is closer to the mark:
>
>> system2("echo", env = c("VAR='Hello World'"), args = c("$VAR"))
>
>>
>
> However, as you see it doesn't work as intended. The problem is that the $-substitution refers to the environment of the shell executing the command. I.e. this does not work from a terminal command line either:
>
> pd$ VAR="foo" echo $VAR
>
> pd$
>
> Or even
>
> pd$ VAR="bar"
> pd$ VAR="foo" echo $VAR
> bar
>
> What you need is something like (NB: single quotes!)
>
> pd$ VAR="foo" sh -c 'echo $VAR'
> foo
>
> So:
>
>> system2("sh", env = c("VAR='Hello World'"), args = c("-c 'echo $VAR'"))
> Hello World
>
> -pd
>
>> On 18 Mar 2019, at 17:28 , Henning Bredel <h.bredel at gmx.de> wrote:
>>
>> Hey all,
>>
>> what is wrong with this command:
>>
>>  system2("echo", env = c(VAR = "Hello World"), args = c("$VAR"))
>>
>> I am a bit confused, as help("system2") writes about the env option:
>>
>>> character vector of name=value strings to set environment variables.
>>
>> Is this option buggy, or am I using it just wrong?
>>
>> Thanks for your help
>>
>>  Henning
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From |@wrence@m|ch@e| @end|ng |rom gene@com  Tue Mar 19 18:12:16 2019
From: |@wrence@m|ch@e| @end|ng |rom gene@com (Michael Lawrence)
Date: Tue, 19 Mar 2019 10:12:16 -0700
Subject: [Rd] selectMethod() can fail to find methods in situations of
 multiple dispatch
In-Reply-To: <1abb17e0-12ee-57bb-b762-128552806fab@fredhutch.org>
References: <1abb17e0-12ee-57bb-b762-128552806fab@fredhutch.org>
Message-ID: <CAOQ5NyfqSZjr-MqHzYaaWoimZVYkt18oP-bZvFXpf4rNm+OZPQ@mail.gmail.com>

This is due to the intentional truncation of ANY suffixes from method
signatures. I've hacked selectMethod() to be robust to that and will commit
soon. Thanks for the report.

Michael

On Thu, Mar 14, 2019 at 9:32 AM Pages, Herve <hpages at fredhutch.org> wrote:

> Here is an example:
>
>   setGeneric("foo", function(x, y) standardGeneric("foo"))
>
>   setMethod("foo", c("numeric", "ANY"),
>     function(x, y) cat("I'm the foo#numeric#ANY method\n")
>   )
>
>
> Dispatch works as expected but selectMethod() fails to find the method:
>
>
>   > foo(1, TRUE)
>   I'm the foo#numeric#ANY method
>
>   > selectMethod("foo", c("numeric", "logical"))
>   Error in selectMethod("foo", c("numeric", "logical")) :
>     no method found for signature numeric, logical
>
> Adding an arbitrary method that doesn't have ANY in the signature "fixes"
> selectMethod():
>
>   setMethod("foo", c("complex", "integer"),
>     function(x, y) cat("I'm the foo#complex#integer method\n")
>   )
>
> Then:
>
>   > selectMethod("foo", c("numeric", "logical"))
>   Method Definition:
>
>   function (x, y)
>   cat("I'm the foo#numeric#ANY method\n")
>
>   Signatures:
>         x         y
>   target  "numeric" "logical"
>   defined "numeric" "ANY"
>
>
> Thanks,
>
> H.
>
>
> --
> Herv? Pag?s
>
> Program in Computational Biology
> Division of Public Health Sciences
> Fred Hutchinson Cancer Research Center
> 1100 Fairview Ave. N, M1-B514
> P.O. Box 19024
> Seattle, WA 98109-1024
>
> E-mail: hpages at fredhutch.org<mailto:hpages at fredhutch.org>
> Phone:  (206) 667-5791
> Fax:    (206) 667-1319
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From |ukemo|@on @end|ng |rom gm@||@com  Wed Mar 20 01:00:21 2019
From: |ukemo|@on @end|ng |rom gm@||@com (l o)
Date: Tue, 19 Mar 2019 20:00:21 -0400
Subject: [Rd] Possibly broken system2 env-option
Message-ID: <CANprkZ_37Uu3CNr=M_sYemLWDsskcsU2gX7O7d51VyyvqO14GA@mail.gmail.com>

Studying Professor Dalgaard's code a bit, here is a little hack that
returns the desired result on Unix-alikes:

From

>* system2("echo", env = c("VAR='Hello World'"), args = c("$VAR"))*

to

>* system2("echo", env = c("VAR='Hello World';"), args = c("$VAR"))*
Hello World

That is, adding the semi-colon effectively transforms

pd$ VAR="foo" echo $VAR

to

pd$ VAR="foo"; echo $VAR


Maybe this doesn't apply to more complicated situations,though.

luke

	[[alternative HTML version deleted]]


From rmcgehee @end|ng |rom w@||eyetr@d|ng@net  Thu Mar 21 21:56:19 2019
From: rmcgehee @end|ng |rom w@||eyetr@d|ng@net (Robert McGehee)
Date: Thu, 21 Mar 2019 20:56:19 +0000
Subject: [Rd] prettyNum digits=0 not compatible with scientific notation
Message-ID: <30D28A63376088428E8318DD67FD407FCADD67@ny-mailstore1.walleyetrading.net>

R developers,
Seems I get a bad result ("%#4.0-1e" in particular) when trying to use prettyNum digits=0 with scientific notation. I tried on both my Linux box and on an online R evaluator and saw the same problem, so it's not limited to my box at least. I see the problem in both R 3.5.3 and R 3.3.2.

options(scipen=-100)
prettyNum(1, digits=0)
[1] "%#4.0-1e"
prettyNum(2, digits=0)
[1] "%#4.0-1e"
prettyNum(1, digits=0, scientific=FALSE) # Works
[1] "1"
prettyNum(1:2, digits=0) # Works
[1] "1" "2"
prettyNum(c(1.1, 2.1), digits=0)
[1] "%#4.0-1e" "%#4.0-1e"
prettyNum(c(1.1, 2.1), digits=1) # Works
[1] "1e+00" "2e+00"

> R.version
               _                           
platform       x86_64-pc-linux-gnu         
arch           x86_64                      
os             linux-gnu                   
system         x86_64, linux-gnu           
status                                     
major          3                           
minor          5.3                         
year           2019                        
month          03                          
day            11                          
svn rev        76217                       
language       R                           
version.string R version 3.5.3 (2019-03-11)
nickname       Great Truth                 


From hp@ge@ @end|ng |rom |redhutch@org  Fri Mar 22 04:14:45 2019
From: hp@ge@ @end|ng |rom |redhutch@org (Pages, Herve)
Date: Fri, 22 Mar 2019 03:14:45 +0000
Subject: [Rd] selectMethod() can fail to find methods in situations of
 multiple dispatch
In-Reply-To: <CAOQ5NyfqSZjr-MqHzYaaWoimZVYkt18oP-bZvFXpf4rNm+OZPQ@mail.gmail.com>
References: <1abb17e0-12ee-57bb-b762-128552806fab@fredhutch.org>
 <CAOQ5NyfqSZjr-MqHzYaaWoimZVYkt18oP-bZvFXpf4rNm+OZPQ@mail.gmail.com>
Message-ID: <866d727c-709a-5bc7-c9ea-b3459c780966@fredhutch.org>

Hi Michael,

Thanks for looking into this. I suspect that truncation of ANY suffixes from method signatures is also the culprit behind the sudden breakage of aliases of the form \alias{foo,numeric-method} when a method without the ANY suffix in its signature gets added to the ecosystem. See my post about this to the Bioc-devel mailing list a couple of months ago: https://stat.ethz.ch/pipermail/bioc-devel/2019-January/014603.html

So overall isn't this truncation more trouble than it's worth?

H.

On 3/19/19 10:12, Michael Lawrence wrote:
This is due to the intentional truncation of ANY suffixes from method signatures. I've hacked selectMethod() to be robust to that and will commit soon. Thanks for the report.

Michael

On Thu, Mar 14, 2019 at 9:32 AM Pages, Herve <hpages at fredhutch.org<mailto:hpages at fredhutch.org>> wrote:
Here is an example:

  setGeneric("foo", function(x, y) standardGeneric("foo"))

  setMethod("foo", c("numeric", "ANY"),
    function(x, y) cat("I'm the foo#numeric#ANY method\n")
  )


Dispatch works as expected but selectMethod() fails to find the method:


  > foo(1, TRUE)
  I'm the foo#numeric#ANY method

  > selectMethod("foo", c("numeric", "logical"))
  Error in selectMethod("foo", c("numeric", "logical")) :
    no method found for signature numeric, logical

Adding an arbitrary method that doesn't have ANY in the signature "fixes" selectMethod():

  setMethod("foo", c("complex", "integer"),
    function(x, y) cat("I'm the foo#complex#integer method\n")
  )

Then:

  > selectMethod("foo", c("numeric", "logical"))
  Method Definition:

  function (x, y)
  cat("I'm the foo#numeric#ANY method\n")

  Signatures:
        x         y
  target  "numeric" "logical"
  defined "numeric" "ANY"


Thanks,

H.


--
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fredhutch.org<mailto:hpages at fredhutch.org><mailto:hpages at fredhutch.org<mailto:hpages at fredhutch.org>>
Phone:  (206) 667-5791
Fax:    (206) 667-1319


        [[alternative HTML version deleted]]

______________________________________________
R-devel at r-project.org<mailto:R-devel at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-devel<https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Ddevel&d=DwMFaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=BK7q3XeAvimeWdGbWY_wJYbW0WYiZvSXAJJKaaPhzWA&m=4e2MsIBoF9YnF3BCkiOk1m2kFgKBe24FwU28c-wuAyc&s=ydXNxAwEa5eG9lTu27sx-8KsT6gU66TbmJLcaYEaleg&e=>

--
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fredhutch.org<mailto:hpages at fredhutch.org>
Phone:  (206) 667-5791
Fax:    (206) 667-1319


	[[alternative HTML version deleted]]


From |@wrence@m|ch@e| @end|ng |rom gene@com  Fri Mar 22 05:29:46 2019
From: |@wrence@m|ch@e| @end|ng |rom gene@com (Michael Lawrence)
Date: Thu, 21 Mar 2019 21:29:46 -0700
Subject: [Rd] selectMethod() can fail to find methods in situations of
 multiple dispatch
In-Reply-To: <866d727c-709a-5bc7-c9ea-b3459c780966@fredhutch.org>
References: <1abb17e0-12ee-57bb-b762-128552806fab@fredhutch.org>
 <CAOQ5NyfqSZjr-MqHzYaaWoimZVYkt18oP-bZvFXpf4rNm+OZPQ@mail.gmail.com>
 <866d727c-709a-5bc7-c9ea-b3459c780966@fredhutch.org>
Message-ID: <CAOQ5Nydv7BFv-kqcyO6zLn5P9-vbtwnL75yRGzB9=-RuAmzsWQ@mail.gmail.com>

If we started over, I'd try to avoid this sort of complexity, but "ANY"
truncation has been happening since at least 2003.

> matchSignature(c("numeric", "ANY"), foo)
        x
"numeric"

So I'm not sure we want to mess with it.

Michael

On Thu, Mar 21, 2019 at 8:14 PM Pages, Herve <hpages at fredhutch.org> wrote:

> Hi Michael,
>
> Thanks for looking into this. I suspect that truncation of ANY suffixes
> from method signatures is also the culprit behind the sudden breakage of
> aliases of the form \alias{foo,numeric-method} when a method without the
> ANY suffix in its signature gets added to the ecosystem. See my post about
> this to the Bioc-devel mailing list a couple of months ago:
> https://stat.ethz.ch/pipermail/bioc-devel/2019-January/014603.html
>
> So overall isn't this truncation more trouble than it's worth?
>
> H.
> On 3/19/19 10:12, Michael Lawrence wrote:
>
> This is due to the intentional truncation of ANY suffixes from method
> signatures. I've hacked selectMethod() to be robust to that and will commit
> soon. Thanks for the report.
>
> Michael
>
> On Thu, Mar 14, 2019 at 9:32 AM Pages, Herve <hpages at fredhutch.org> wrote:
>
>> Here is an example:
>>
>>   setGeneric("foo", function(x, y) standardGeneric("foo"))
>>
>>   setMethod("foo", c("numeric", "ANY"),
>>     function(x, y) cat("I'm the foo#numeric#ANY method\n")
>>   )
>>
>>
>> Dispatch works as expected but selectMethod() fails to find the method:
>>
>>
>>   > foo(1, TRUE)
>>   I'm the foo#numeric#ANY method
>>
>>   > selectMethod("foo", c("numeric", "logical"))
>>   Error in selectMethod("foo", c("numeric", "logical")) :
>>     no method found for signature numeric, logical
>>
>> Adding an arbitrary method that doesn't have ANY in the signature "fixes"
>> selectMethod():
>>
>>   setMethod("foo", c("complex", "integer"),
>>     function(x, y) cat("I'm the foo#complex#integer method\n")
>>   )
>>
>> Then:
>>
>>   > selectMethod("foo", c("numeric", "logical"))
>>   Method Definition:
>>
>>   function (x, y)
>>   cat("I'm the foo#numeric#ANY method\n")
>>
>>   Signatures:
>>         x         y
>>   target  "numeric" "logical"
>>   defined "numeric" "ANY"
>>
>>
>> Thanks,
>>
>> H.
>>
>>
>> --
>> Herv? Pag?s
>>
>> Program in Computational Biology
>> Division of Public Health Sciences
>> Fred Hutchinson Cancer Research Center
>> 1100 Fairview Ave. N, M1-B514
>> P.O. Box 19024
>> Seattle, WA 98109-1024
>>
>> E-mail: hpages at fredhutch.org<mailto:hpages at fredhutch.org>
>> Phone:  (206) 667-5791
>> Fax:    (206) 667-1319
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> <https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Ddevel&d=DwMFaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=BK7q3XeAvimeWdGbWY_wJYbW0WYiZvSXAJJKaaPhzWA&m=4e2MsIBoF9YnF3BCkiOk1m2kFgKBe24FwU28c-wuAyc&s=ydXNxAwEa5eG9lTu27sx-8KsT6gU66TbmJLcaYEaleg&e=>
>>
> --
> Herv? Pag?s
>
> Program in Computational Biology
> Division of Public Health Sciences
> Fred Hutchinson Cancer Research Center
> 1100 Fairview Ave. N, M1-B514
> P.O. Box 19024
> Seattle, WA 98109-1024
>
> E-mail: hpages at fredhutch.org
> Phone:  (206) 667-5791
> Fax:    (206) 667-1319
>
>

	[[alternative HTML version deleted]]


From hp@ge@ @end|ng |rom |redhutch@org  Fri Mar 22 05:52:13 2019
From: hp@ge@ @end|ng |rom |redhutch@org (Pages, Herve)
Date: Fri, 22 Mar 2019 04:52:13 +0000
Subject: [Rd] selectMethod() can fail to find methods in situations of
 multiple dispatch
In-Reply-To: <CAOQ5Nydv7BFv-kqcyO6zLn5P9-vbtwnL75yRGzB9=-RuAmzsWQ@mail.gmail.com>
References: <1abb17e0-12ee-57bb-b762-128552806fab@fredhutch.org>
 <CAOQ5NyfqSZjr-MqHzYaaWoimZVYkt18oP-bZvFXpf4rNm+OZPQ@mail.gmail.com>
 <866d727c-709a-5bc7-c9ea-b3459c780966@fredhutch.org>
 <CAOQ5Nydv7BFv-kqcyO6zLn5P9-vbtwnL75yRGzB9=-RuAmzsWQ@mail.gmail.com>
Message-ID: <30953b8d-37ef-40d1-8fb1-a4e7be0a7a46@fredhutch.org>

Fine with me as long as eliminating the inconveniences associated with it can be put on the roadmap. The alias instability and the fact that the user has no way to know if s/he should do ?`foo,numeric-method` or ?`foo,numeric,ANY-method` to find the method has been a long-standing problem.

H.

On 3/21/19 21:29, Michael Lawrence wrote:
If we started over, I'd try to avoid this sort of complexity, but "ANY" truncation has been happening since at least 2003.

> matchSignature(c("numeric", "ANY"), foo)
        x
"numeric"

So I'm not sure we want to mess with it.

Michael

On Thu, Mar 21, 2019 at 8:14 PM Pages, Herve <hpages at fredhutch.org<mailto:hpages at fredhutch.org>> wrote:

Hi Michael,

Thanks for looking into this. I suspect that truncation of ANY suffixes from method signatures is also the culprit behind the sudden breakage of aliases of the form \alias{foo,numeric-method} when a method without the ANY suffix in its signature gets added to the ecosystem. See my post about this to the Bioc-devel mailing list a couple of months ago: https://stat.ethz.ch/pipermail/bioc-devel/2019-January/014603.html<https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_pipermail_bioc-2Ddevel_2019-2DJanuary_014603.html&d=DwMFaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=BK7q3XeAvimeWdGbWY_wJYbW0WYiZvSXAJJKaaPhzWA&m=kjmNpPtpGtaMCrw8ubpy0siyz1xl8WY9gONjtL65IxE&s=R9Hi4Rm4nk-izYC8vDCj0NiuFdUMG4vZVbdQgsvxkDM&e=>

So overall isn't this truncation more trouble than it's worth?

H.

On 3/19/19 10:12, Michael Lawrence wrote:
This is due to the intentional truncation of ANY suffixes from method signatures. I've hacked selectMethod() to be robust to that and will commit soon. Thanks for the report.

Michael

On Thu, Mar 14, 2019 at 9:32 AM Pages, Herve <hpages at fredhutch.org<mailto:hpages at fredhutch.org>> wrote:
Here is an example:

  setGeneric("foo", function(x, y) standardGeneric("foo"))

  setMethod("foo", c("numeric", "ANY"),
    function(x, y) cat("I'm the foo#numeric#ANY method\n")
  )


Dispatch works as expected but selectMethod() fails to find the method:


  > foo(1, TRUE)
  I'm the foo#numeric#ANY method

  > selectMethod("foo", c("numeric", "logical"))
  Error in selectMethod("foo", c("numeric", "logical")) :
    no method found for signature numeric, logical

Adding an arbitrary method that doesn't have ANY in the signature "fixes" selectMethod():

  setMethod("foo", c("complex", "integer"),
    function(x, y) cat("I'm the foo#complex#integer method\n")
  )

Then:

  > selectMethod("foo", c("numeric", "logical"))
  Method Definition:

  function (x, y)
  cat("I'm the foo#numeric#ANY method\n")

  Signatures:
        x         y
  target  "numeric" "logical"
  defined "numeric" "ANY"


Thanks,

H.


--
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fredhutch.org<mailto:hpages at fredhutch.org><mailto:hpages at fredhutch.org<mailto:hpages at fredhutch.org>>
Phone:  (206) 667-5791
Fax:    (206) 667-1319


        [[alternative HTML version deleted]]

______________________________________________
R-devel at r-project.org<mailto:R-devel at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-devel<https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Ddevel&d=DwMFaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=BK7q3XeAvimeWdGbWY_wJYbW0WYiZvSXAJJKaaPhzWA&m=4e2MsIBoF9YnF3BCkiOk1m2kFgKBe24FwU28c-wuAyc&s=ydXNxAwEa5eG9lTu27sx-8KsT6gU66TbmJLcaYEaleg&e=>

--
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fredhutch.org<mailto:hpages at fredhutch.org>
Phone:  (206) 667-5791
Fax:    (206) 667-1319


--
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fredhutch.org<mailto:hpages at fredhutch.org>
Phone:  (206) 667-5791
Fax:    (206) 667-1319


	[[alternative HTML version deleted]]


From |@wrence@m|ch@e| @end|ng |rom gene@com  Fri Mar 22 06:05:05 2019
From: |@wrence@m|ch@e| @end|ng |rom gene@com (Michael Lawrence)
Date: Thu, 21 Mar 2019 22:05:05 -0700
Subject: [Rd] selectMethod() can fail to find methods in situations of
 multiple dispatch
In-Reply-To: <30953b8d-37ef-40d1-8fb1-a4e7be0a7a46@fredhutch.org>
References: <1abb17e0-12ee-57bb-b762-128552806fab@fredhutch.org>
 <CAOQ5NyfqSZjr-MqHzYaaWoimZVYkt18oP-bZvFXpf4rNm+OZPQ@mail.gmail.com>
 <866d727c-709a-5bc7-c9ea-b3459c780966@fredhutch.org>
 <CAOQ5Nydv7BFv-kqcyO6zLn5P9-vbtwnL75yRGzB9=-RuAmzsWQ@mail.gmail.com>
 <30953b8d-37ef-40d1-8fb1-a4e7be0a7a46@fredhutch.org>
Message-ID: <CAOQ5Nyd0hM+jYwDMApk5ZSHGRTaA3Pw9nmxQoZg24p4r8Dk3yg@mail.gmail.com>

Agreed but I'm not sure we want users accessing documentation with those
types of aliases. One option is the method?foo("numeric") syntax.

On Thu, Mar 21, 2019 at 9:52 PM Pages, Herve <hpages at fredhutch.org> wrote:

> Fine with me as long as eliminating the inconveniences associated with it
> can be put on the roadmap. The alias instability and the fact that the user
> has no way to know if s/he should do ?`foo,numeric-method` or
> ?`foo,numeric,ANY-method` to find the method has been a long-standing
> problem.
>
> H.
> On 3/21/19 21:29, Michael Lawrence wrote:
>
> If we started over, I'd try to avoid this sort of complexity, but "ANY"
> truncation has been happening since at least 2003.
>
> > matchSignature(c("numeric", "ANY"), foo)
>         x
> "numeric"
>
> So I'm not sure we want to mess with it.
>
> Michael
>
> On Thu, Mar 21, 2019 at 8:14 PM Pages, Herve <hpages at fredhutch.org> wrote:
>
>> Hi Michael,
>>
>> Thanks for looking into this. I suspect that truncation of ANY suffixes
>> from method signatures is also the culprit behind the sudden breakage of
>> aliases of the form \alias{foo,numeric-method} when a method without the
>> ANY suffix in its signature gets added to the ecosystem. See my post about
>> this to the Bioc-devel mailing list a couple of months ago:
>> https://stat.ethz.ch/pipermail/bioc-devel/2019-January/014603.html
>> <https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_pipermail_bioc-2Ddevel_2019-2DJanuary_014603.html&d=DwMFaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=BK7q3XeAvimeWdGbWY_wJYbW0WYiZvSXAJJKaaPhzWA&m=kjmNpPtpGtaMCrw8ubpy0siyz1xl8WY9gONjtL65IxE&s=R9Hi4Rm4nk-izYC8vDCj0NiuFdUMG4vZVbdQgsvxkDM&e=>
>>
>> So overall isn't this truncation more trouble than it's worth?
>>
>> H.
>> On 3/19/19 10:12, Michael Lawrence wrote:
>>
>> This is due to the intentional truncation of ANY suffixes from method
>> signatures. I've hacked selectMethod() to be robust to that and will commit
>> soon. Thanks for the report.
>>
>> Michael
>>
>> On Thu, Mar 14, 2019 at 9:32 AM Pages, Herve <hpages at fredhutch.org>
>> wrote:
>>
>>> Here is an example:
>>>
>>>   setGeneric("foo", function(x, y) standardGeneric("foo"))
>>>
>>>   setMethod("foo", c("numeric", "ANY"),
>>>     function(x, y) cat("I'm the foo#numeric#ANY method\n")
>>>   )
>>>
>>>
>>> Dispatch works as expected but selectMethod() fails to find the method:
>>>
>>>
>>>   > foo(1, TRUE)
>>>   I'm the foo#numeric#ANY method
>>>
>>>   > selectMethod("foo", c("numeric", "logical"))
>>>   Error in selectMethod("foo", c("numeric", "logical")) :
>>>     no method found for signature numeric, logical
>>>
>>> Adding an arbitrary method that doesn't have ANY in the signature
>>> "fixes" selectMethod():
>>>
>>>   setMethod("foo", c("complex", "integer"),
>>>     function(x, y) cat("I'm the foo#complex#integer method\n")
>>>   )
>>>
>>> Then:
>>>
>>>   > selectMethod("foo", c("numeric", "logical"))
>>>   Method Definition:
>>>
>>>   function (x, y)
>>>   cat("I'm the foo#numeric#ANY method\n")
>>>
>>>   Signatures:
>>>         x         y
>>>   target  "numeric" "logical"
>>>   defined "numeric" "ANY"
>>>
>>>
>>> Thanks,
>>>
>>> H.
>>>
>>>
>>> --
>>> Herv? Pag?s
>>>
>>> Program in Computational Biology
>>> Division of Public Health Sciences
>>> Fred Hutchinson Cancer Research Center
>>> 1100 Fairview Ave. N, M1-B514
>>> P.O. Box 19024
>>> Seattle, WA 98109-1024
>>>
>>> E-mail: hpages at fredhutch.org<mailto:hpages at fredhutch.org>
>>> Phone:  (206) 667-5791
>>> Fax:    (206) 667-1319
>>>
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>> <https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Ddevel&d=DwMFaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=BK7q3XeAvimeWdGbWY_wJYbW0WYiZvSXAJJKaaPhzWA&m=4e2MsIBoF9YnF3BCkiOk1m2kFgKBe24FwU28c-wuAyc&s=ydXNxAwEa5eG9lTu27sx-8KsT6gU66TbmJLcaYEaleg&e=>
>>>
>> --
>> Herv? Pag?s
>>
>> Program in Computational Biology
>> Division of Public Health Sciences
>> Fred Hutchinson Cancer Research Center
>> 1100 Fairview Ave. N, M1-B514
>> P.O. Box 19024
>> Seattle, WA 98109-1024
>>
>> E-mail: hpages at fredhutch.org
>> Phone:  (206) 667-5791
>> Fax:    (206) 667-1319
>>
>> --
> Herv? Pag?s
>
> Program in Computational Biology
> Division of Public Health Sciences
> Fred Hutchinson Cancer Research Center
> 1100 Fairview Ave. N, M1-B514
> P.O. Box 19024
> Seattle, WA 98109-1024
>
> E-mail: hpages at fredhutch.org
> Phone:  (206) 667-5791
> Fax:    (206) 667-1319
>
>

	[[alternative HTML version deleted]]


From hp@ge@ @end|ng |rom |redhutch@org  Fri Mar 22 06:52:51 2019
From: hp@ge@ @end|ng |rom |redhutch@org (Pages, Herve)
Date: Fri, 22 Mar 2019 05:52:51 +0000
Subject: [Rd] selectMethod() can fail to find methods in situations of
 multiple dispatch
In-Reply-To: <CAOQ5Nyd0hM+jYwDMApk5ZSHGRTaA3Pw9nmxQoZg24p4r8Dk3yg@mail.gmail.com>
References: <1abb17e0-12ee-57bb-b762-128552806fab@fredhutch.org>
 <CAOQ5NyfqSZjr-MqHzYaaWoimZVYkt18oP-bZvFXpf4rNm+OZPQ@mail.gmail.com>
 <866d727c-709a-5bc7-c9ea-b3459c780966@fredhutch.org>
 <CAOQ5Nydv7BFv-kqcyO6zLn5P9-vbtwnL75yRGzB9=-RuAmzsWQ@mail.gmail.com>
 <30953b8d-37ef-40d1-8fb1-a4e7be0a7a46@fredhutch.org>
 <CAOQ5Nyd0hM+jYwDMApk5ZSHGRTaA3Pw9nmxQoZg24p4r8Dk3yg@mail.gmail.com>
Message-ID: <8434c9a0-e79f-6fe3-f803-831416281015@fredhutch.org>

Good to know about the method?foo("numeric") syntax. And apparently it knows about inheritance! Thanks for mentioning that. I see it's documented in ?`?`... Darn! How could I miss it for so many years!

Note however that this syntax doesn't seem to work in case of "ANY" truncation so I won't be able to fully adopt this syntax for now:

> library(Matrix)

> showMethods("colSums")
Function: colSums (package base)
x="ANY"
x="CsparseMatrix"
x="ddenseMatrix"
x="denseMatrix"
x="dgCMatrix"
x="dgeMatrix"
x="diagonalMatrix"
x="igCMatrix"
x="indMatrix"
x="lgCMatrix"
x="ngCMatrix"
x="RsparseMatrix"
x="TsparseMatrix"

> method?colSums("dgCMatrix")
Error in .helpForCall(topicExpr, parent.frame(), FALSE) :
  no documentation for function ?colSums? and signature ?x = "dgCMatrix", na.rm = "logical", dims = "numeric"?
In addition: Warning message:
In .helpForCall(topicExpr, parent.frame(), FALSE) :
  no method defined for function ?colSums? and signature ?x = "dgCMatrix", na.rm = "logical", dims = "numeric"?

But maybe it uses selectMethod() behind the seen so will work once selectMethod() gets fixed?

Thanks,

H.


On 3/21/19 22:05, Michael Lawrence wrote:
Agreed but I'm not sure we want users accessing documentation with those types of aliases. One option is the method?foo("numeric") syntax.

On Thu, Mar 21, 2019 at 9:52 PM Pages, Herve <hpages at fredhutch.org<mailto:hpages at fredhutch.org>> wrote:

Fine with me as long as eliminating the inconveniences associated with it can be put on the roadmap. The alias instability and the fact that the user has no way to know if s/he should do ?`foo,numeric-method` or ?`foo,numeric,ANY-method` to find the method has been a long-standing problem.

H.

On 3/21/19 21:29, Michael Lawrence wrote:
If we started over, I'd try to avoid this sort of complexity, but "ANY" truncation has been happening since at least 2003.

> matchSignature(c("numeric", "ANY"), foo)
        x
"numeric"

So I'm not sure we want to mess with it.

Michael

On Thu, Mar 21, 2019 at 8:14 PM Pages, Herve <hpages at fredhutch.org<mailto:hpages at fredhutch.org>> wrote:

Hi Michael,

Thanks for looking into this. I suspect that truncation of ANY suffixes from method signatures is also the culprit behind the sudden breakage of aliases of the form \alias{foo,numeric-method} when a method without the ANY suffix in its signature gets added to the ecosystem. See my post about this to the Bioc-devel mailing list a couple of months ago: https://stat.ethz.ch/pipermail/bioc-devel/2019-January/014603.html<https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_pipermail_bioc-2Ddevel_2019-2DJanuary_014603.html&d=DwMFaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=BK7q3XeAvimeWdGbWY_wJYbW0WYiZvSXAJJKaaPhzWA&m=kjmNpPtpGtaMCrw8ubpy0siyz1xl8WY9gONjtL65IxE&s=R9Hi4Rm4nk-izYC8vDCj0NiuFdUMG4vZVbdQgsvxkDM&e=>

So overall isn't this truncation more trouble than it's worth?

H.

On 3/19/19 10:12, Michael Lawrence wrote:
This is due to the intentional truncation of ANY suffixes from method signatures. I've hacked selectMethod() to be robust to that and will commit soon. Thanks for the report.

Michael

On Thu, Mar 14, 2019 at 9:32 AM Pages, Herve <hpages at fredhutch.org<mailto:hpages at fredhutch.org>> wrote:
Here is an example:

  setGeneric("foo", function(x, y) standardGeneric("foo"))

  setMethod("foo", c("numeric", "ANY"),
    function(x, y) cat("I'm the foo#numeric#ANY method\n")
  )


Dispatch works as expected but selectMethod() fails to find the method:


  > foo(1, TRUE)
  I'm the foo#numeric#ANY method

  > selectMethod("foo", c("numeric", "logical"))
  Error in selectMethod("foo", c("numeric", "logical")) :
    no method found for signature numeric, logical

Adding an arbitrary method that doesn't have ANY in the signature "fixes" selectMethod():

  setMethod("foo", c("complex", "integer"),
    function(x, y) cat("I'm the foo#complex#integer method\n")
  )

Then:

  > selectMethod("foo", c("numeric", "logical"))
  Method Definition:

  function (x, y)
  cat("I'm the foo#numeric#ANY method\n")

  Signatures:
        x         y
  target  "numeric" "logical"
  defined "numeric" "ANY"


Thanks,

H.


--
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fredhutch.org<mailto:hpages at fredhutch.org><mailto:hpages at fredhutch.org<mailto:hpages at fredhutch.org>>
Phone:  (206) 667-5791
Fax:    (206) 667-1319


        [[alternative HTML version deleted]]

______________________________________________
R-devel at r-project.org<mailto:R-devel at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-devel<https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Ddevel&d=DwMFaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=BK7q3XeAvimeWdGbWY_wJYbW0WYiZvSXAJJKaaPhzWA&m=4e2MsIBoF9YnF3BCkiOk1m2kFgKBe24FwU28c-wuAyc&s=ydXNxAwEa5eG9lTu27sx-8KsT6gU66TbmJLcaYEaleg&e=>

--
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fredhutch.org<mailto:hpages at fredhutch.org>
Phone:  (206) 667-5791
Fax:    (206) 667-1319


--
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fredhutch.org<mailto:hpages at fredhutch.org>
Phone:  (206) 667-5791
Fax:    (206) 667-1319


--
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fredhutch.org<mailto:hpages at fredhutch.org>
Phone:  (206) 667-5791
Fax:    (206) 667-1319


	[[alternative HTML version deleted]]


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Fri Mar 22 10:10:50 2019
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Fri, 22 Mar 2019 10:10:50 +0100
Subject: [Rd] prettyNum digits=0 not compatible with scientific notation
In-Reply-To: <30D28A63376088428E8318DD67FD407FCADD67@ny-mailstore1.walleyetrading.net>
References: <30D28A63376088428E8318DD67FD407FCADD67@ny-mailstore1.walleyetrading.net>
Message-ID: <23700.42650.645514.620943@stat.math.ethz.ch>

Thank you, Robert for raising this here !

>>>>> Robert McGehee 
>>>>>     on Thu, 21 Mar 2019 20:56:19 +0000 writes:

    > R developers,
    > Seems I get a bad result ("%#4.0-1e" in particular) when trying to use prettyNum digits=0 with scientific notation. I tried on both my Linux box and on an online R evaluator and saw the same problem, so it's not limited to my box at least. I see the problem in both R 3.5.3 and R 3.3.2.

    > options(scipen= -100)

The above is extreme: You're basically setting an option to
always see non-integer numbers in "scientific" format ..
But read below about what 'digits' means in this case.

    > prettyNum(1, digits=0)
    > [1] "%#4.0-1e"
    > prettyNum(2, digits=0)
    > [1] "%#4.0-1e"
    > prettyNum(1, digits=0, scientific=FALSE) # Works
    > [1] "1"
    > prettyNum(1:2, digits=0) # Works
    > [1] "1" "2"
    > prettyNum(c(1.1, 2.1), digits=0)
    > [1] "%#4.0-1e" "%#4.0-1e"
    > prettyNum(c(1.1, 2.1), digits=1) # Works
    > [1] "1e+00" "2e+00"

I'm the scape goat / culprit /.. : I have worked on tweaking the
formatting of (non integer) numbers in R for a long time, on the
way introducing prettyNum(), also already long ago...
but then it's actually not prettyNum() but rather format() here :

Have you read its help page - *with* care?

If you do, you'd notice that 'digits' is not among the formal arguments
of prettyNum() *and* that prettyNum() passes all its  `...`  to format().
And if you read  ?format [which then you should to understand 'digits' !]
you see

  > digits: how many significant digits are to be used for numeric and
  >      complex ?x?.  The default, NULL, uses ?getOption("digits")?.
>      This is a suggestion: enough decimal places will be used so that
  >      the smallest (in magnitude) number has this many significant 
  >      digits, and also to satisfy ?nsmall?.

  > 	  [.....]

So, for the real numbers you use in your example, digits are
*significant* digits as in  'options(digits= *)' or
'print(.., digits= *)'

------ Excursion about 'integer' and format()ing ------------
-- and you now may also understand why   prettyNum(1:2, digits=0)  works
 as you expect: integer formatting behaves differently   ....
 but I acknowledge that the  ?format   help page does not say so
 explicitly yet:  it 'real and complex' numbers for the
 'scientific' argument,  and 'numeric and complex' numbers for
 the 'format' argument.
 If you replac numeric by reald, what this entails (by logic)
 that 'integer' numbers are *not* affected by 'digits' nor  'scientific'.

 But there's yet more subtlety: 'integer' here means class/type "integer"
 and not just an integer number, i.e., the difference of  1L and 1 :

  > str(1)
   num 1
  > str(1L)
   int 1
  > str(1:3)
   int [1:3] 1 2 3
  > str(1:3 + 0)
   num [1:3] 1 2 3
  > 
------ end of Excursion{'integer' ..} -------------------------------

Back to real numbers : 'digits' are used as *significant* digits
(and are only a suggestion: format() and prettyNum() ensure
 a common width for their resulting strings so printing will be
nicely aligned), see e.g.

   > format(3.14, scientific=FALSE)
   [1] "3.14"
   > format(3.14*c(1, 1e-7),   scientific=FALSE)
   [1] "3.140000000" "0.000000314"
   > 

So back to your examples : What would you mean with
``0 significant digits'' ? 
It really does not make sense to show *no* significant digits ..

Intuitively, without spending enough time, I'd say that the bug
in format.default() -- which is called by prettyNum() in
this case -- is that it does *not* treat
'digits = 0'  as 'digits = 1'  in this case.  

NB:  digits = 0 has been valid in    options(digits = 0)  etc,
 "forever" I think, possibly inherited from S,  but I don't
 really know and I wonder if we should not  make it invalid eventually
 requiring at least 1.
So we could make it raise a *warning* (and set it to '1') for  now.
What do others think? 

Anyone with S(-PLUS) or Terr or .. who can report if  digits=0
is allowed there and what it does in a simple situation like

  > format(as.integer(2^30), digits=0) # digits not used at all
  [1] "1073741824"
  > format(2^30, digits=0)
  [1] "%#4.0-1e"
  > 


Last but not least:  If you really want to use exponential
format, you should typically use  sprintf() or formatC()  where
you can tweak to get what you want.


From pd@me@ @end|ng |rom cb@@dk  Fri Mar 22 11:10:18 2019
From: pd@me@ @end|ng |rom cb@@dk (Peter Dalgaard)
Date: Fri, 22 Mar 2019 10:10:18 +0000
Subject: [Rd] R 3.6.0 scheduled for April 26
Message-ID: <E4634839-B3B1-4BDB-BB20-73C442364285@cbs.dk>

Full schedule is available on developer.r-project.org.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From r@||@@tubner @end|ng |rom d@q@n@@com  Fri Mar 22 15:26:14 2019
From: r@||@@tubner @end|ng |rom d@q@n@@com (Ralf Stubner)
Date: Fri, 22 Mar 2019 15:26:14 +0100
Subject: [Rd] Status of R_unif_index
Message-ID: <fd9b4542-ac8d-5ef7-5338-f767703524b5@daqana.com>

Dear List,

section "6.3 Random number generation" of WRE [1] lists unif_rand(),
norm_rand() and exp_rand() as the interface to R's RNG. Now
R_ext/Random.h also has

    double R_unif_index(double);

Can this be also treated as an official API function that may be called
from a package?

Thanks
Ralf

[1]
https://cran.r-project.org/doc/manuals/r-release/R-exts.html#Random-numbers

-- 
Ralf Stubner
Senior Software Engineer / Trainer

daqana GmbH
Dortustra?e 48
14467 Potsdam

T: +49 331 23 61 93 11
F: +49 331 23 61 93 90
M: +49 162 20 91 196
Mail: ralf.stubner at daqana.com

Sitz: Potsdam
Register: AG Potsdam HRB 27966
Ust.-IdNr.: DE300072622
Gesch?ftsf?hrer: Dr.-Ing. Stefan Knirsch, Prof. Dr. Dr. Karl-Kuno Kunze


-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: OpenPGP digital signature
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20190322/af42fffb/attachment.sig>

From rmcgehee @end|ng |rom w@||eyetr@d|ng@net  Fri Mar 22 16:14:49 2019
From: rmcgehee @end|ng |rom w@||eyetr@d|ng@net (Robert McGehee)
Date: Fri, 22 Mar 2019 15:14:49 +0000
Subject: [Rd] prettyNum digits=0 not compatible with scientific notation
In-Reply-To: <23700.42650.645514.620943@stat.math.ethz.ch>
References: <30D28A63376088428E8318DD67FD407FCADD67@ny-mailstore1.walleyetrading.net>
 <23700.42650.645514.620943@stat.math.ethz.ch>
Message-ID: <30D28A63376088428E8318DD67FD407FCAECF1@ny-mailstore1.walleyetrading.net>

Hi,
Thanks for this. To be clear, I did not intend to use scientific notation, I just happened to stumble upon this when using prettyNum on numbers large enough that R switched to scientific notation and I noticed the problem. I just made this artificial example just to show with an example using smaller numbers (and in case someone on this list redefined their options(scipen) in their .Rprofile as I do).

Specifically, here's what I wanted to see:
> prettyNum(30000000.9, big.marks=",", digits=0)
[1] "30,000,001"
But got "%#4.0-1e" instead. I was intending to use digits=0 as a way of rounding at the same time as adding commas, and was meaning to have a zero significant digit scientific notation thing, which I agree probably doesn't make sense.

Also, even smaller numbers that don't normally trigger scientific notation cause the odd output, so maybe this isn't strictly a scientific notation problem? 
> options(scipen=0)
> 12345.6
[1] 12345.6 # No scientific notation here
> prettyNum(12345.6, digits=0)
[1] "%#4.0-1e"

My "fix" is just to add scientific=FALSE to my prettyNum calls as this seems to make the problem disappear for me in all cases. However, the odd output I encountered along the way seemed worthy of comment.

HTH, Robert

-----Original Message-----
From: Martin Maechler [mailto:maechler at stat.math.ethz.ch] 
Sent: Friday, March 22, 2019 5:11 AM
To: Robert McGehee <rmcgehee at walleyetrading.net>
Cc: r-devel at r-project.org
Subject: Re: [Rd] prettyNum digits=0 not compatible with scientific notation

Thank you, Robert for raising this here !

>>>>> Robert McGehee 
>>>>>     on Thu, 21 Mar 2019 20:56:19 +0000 writes:

    > R developers,
    > Seems I get a bad result ("%#4.0-1e" in particular) when trying to use prettyNum digits=0 with scientific notation. I tried on both my Linux box and on an online R evaluator and saw the same problem, so it's not limited to my box at least. I see the problem in both R 3.5.3 and R 3.3.2.

    > options(scipen= -100)

The above is extreme: You're basically setting an option to
always see non-integer numbers in "scientific" format ..
But read below about what 'digits' means in this case.

    > prettyNum(1, digits=0)
    > [1] "%#4.0-1e"
    > prettyNum(2, digits=0)
    > [1] "%#4.0-1e"
    > prettyNum(1, digits=0, scientific=FALSE) # Works
    > [1] "1"
    > prettyNum(1:2, digits=0) # Works
    > [1] "1" "2"
    > prettyNum(c(1.1, 2.1), digits=0)
    > [1] "%#4.0-1e" "%#4.0-1e"
    > prettyNum(c(1.1, 2.1), digits=1) # Works
    > [1] "1e+00" "2e+00"

I'm the scape goat / culprit /.. : I have worked on tweaking the
formatting of (non integer) numbers in R for a long time, on the
way introducing prettyNum(), also already long ago...
but then it's actually not prettyNum() but rather format() here :

Have you read its help page - *with* care?

If you do, you'd notice that 'digits' is not among the formal arguments
of prettyNum() *and* that prettyNum() passes all its  `...`  to format().
And if you read  ?format [which then you should to understand 'digits' !]
you see

  > digits: how many significant digits are to be used for numeric and
  >      complex ?x?.  The default, NULL, uses ?getOption("digits")?.
>      This is a suggestion: enough decimal places will be used so that
  >      the smallest (in magnitude) number has this many significant 
  >      digits, and also to satisfy ?nsmall?.

  > 	  [.....]

So, for the real numbers you use in your example, digits are
*significant* digits as in  'options(digits= *)' or
'print(.., digits= *)'

------ Excursion about 'integer' and format()ing ------------
-- and you now may also understand why   prettyNum(1:2, digits=0)  works
 as you expect: integer formatting behaves differently   ....
 but I acknowledge that the  ?format   help page does not say so
 explicitly yet:  it 'real and complex' numbers for the
 'scientific' argument,  and 'numeric and complex' numbers for
 the 'format' argument.
 If you replac numeric by reald, what this entails (by logic)
 that 'integer' numbers are *not* affected by 'digits' nor  'scientific'.

 But there's yet more subtlety: 'integer' here means class/type "integer"
 and not just an integer number, i.e., the difference of  1L and 1 :

  > str(1)
   num 1
  > str(1L)
   int 1
  > str(1:3)
   int [1:3] 1 2 3
  > str(1:3 + 0)
   num [1:3] 1 2 3
  > 
------ end of Excursion{'integer' ..} -------------------------------

Back to real numbers : 'digits' are used as *significant* digits
(and are only a suggestion: format() and prettyNum() ensure
 a common width for their resulting strings so printing will be
nicely aligned), see e.g.

   > format(3.14, scientific=FALSE)
   [1] "3.14"
   > format(3.14*c(1, 1e-7),   scientific=FALSE)
   [1] "3.140000000" "0.000000314"
   > 

So back to your examples : What would you mean with
``0 significant digits'' ? 
It really does not make sense to show *no* significant digits ..

Intuitively, without spending enough time, I'd say that the bug
in format.default() -- which is called by prettyNum() in
this case -- is that it does *not* treat
'digits = 0'  as 'digits = 1'  in this case.  

NB:  digits = 0 has been valid in    options(digits = 0)  etc,
 "forever" I think, possibly inherited from S,  but I don't
 really know and I wonder if we should not  make it invalid eventually
 requiring at least 1.
So we could make it raise a *warning* (and set it to '1') for  now.
What do others think? 

Anyone with S(-PLUS) or Terr or .. who can report if  digits=0
is allowed there and what it does in a simple situation like

  > format(as.integer(2^30), digits=0) # digits not used at all
  [1] "1073741824"
  > format(2^30, digits=0)
  [1] "%#4.0-1e"
  > 


Last but not least:  If you really want to use exponential
format, you should typically use  sprintf() or formatC()  where
you can tweak to get what you want.

From pd@|gd @end|ng |rom gm@||@com  Fri Mar 22 17:30:19 2019
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Fri, 22 Mar 2019 17:30:19 +0100
Subject: [Rd] prettyNum digits=0 not compatible with scientific notation
In-Reply-To: <23700.42650.645514.620943@stat.math.ethz.ch>
References: <30D28A63376088428E8318DD67FD407FCADD67@ny-mailstore1.walleyetrading.net>
 <23700.42650.645514.620943@stat.math.ethz.ch>
Message-ID: <AAF25F95-1DDD-4C41-8132-54259D09679C@gmail.com>

FWIW, it doesn't seem to be happening on Mac OS:

> format(2^30, digits=0)
[1] "1.e+09"
> prettyNum(12345.6, digits=0)
[1] "1.e+04"

A glibc misfeature?

-pd

> On 22 Mar 2019, at 10:10 , Martin Maechler <maechler at stat.math.ethz.ch> wrote:
> 
> Thank you, Robert for raising this here !
> 
>>>>>> Robert McGehee 
>>>>>>    on Thu, 21 Mar 2019 20:56:19 +0000 writes:
> 
>> R developers,
>> Seems I get a bad result ("%#4.0-1e" in particular) when trying to use prettyNum digits=0 with scientific notation. I tried on both my Linux box and on an online R evaluator and saw the same problem, so it's not limited to my box at least. I see the problem in both R 3.5.3 and R 3.3.2.
> 
>> options(scipen= -100)
> 
> The above is extreme: You're basically setting an option to
> always see non-integer numbers in "scientific" format ..
> But read below about what 'digits' means in this case.
> 
>> prettyNum(1, digits=0)
>> [1] "%#4.0-1e"
>> prettyNum(2, digits=0)
>> [1] "%#4.0-1e"
>> prettyNum(1, digits=0, scientific=FALSE) # Works
>> [1] "1"
>> prettyNum(1:2, digits=0) # Works
>> [1] "1" "2"
>> prettyNum(c(1.1, 2.1), digits=0)
>> [1] "%#4.0-1e" "%#4.0-1e"
>> prettyNum(c(1.1, 2.1), digits=1) # Works
>> [1] "1e+00" "2e+00"
> 
> I'm the scape goat / culprit /.. : I have worked on tweaking the
> formatting of (non integer) numbers in R for a long time, on the
> way introducing prettyNum(), also already long ago...
> but then it's actually not prettyNum() but rather format() here :
> 
> Have you read its help page - *with* care?
> 
> If you do, you'd notice that 'digits' is not among the formal arguments
> of prettyNum() *and* that prettyNum() passes all its  `...`  to format().
> And if you read  ?format [which then you should to understand 'digits' !]
> you see
> 
>> digits: how many significant digits are to be used for numeric and
>>     complex ?x?.  The default, NULL, uses ?getOption("digits")?.
>>     This is a suggestion: enough decimal places will be used so that
>>     the smallest (in magnitude) number has this many significant 
>>     digits, and also to satisfy ?nsmall?.
> 
>> 	  [.....]
> 
> So, for the real numbers you use in your example, digits are
> *significant* digits as in  'options(digits= *)' or
> 'print(.., digits= *)'
> 
> ------ Excursion about 'integer' and format()ing ------------
> -- and you now may also understand why   prettyNum(1:2, digits=0)  works
> as you expect: integer formatting behaves differently   ....
> but I acknowledge that the  ?format   help page does not say so
> explicitly yet:  it 'real and complex' numbers for the
> 'scientific' argument,  and 'numeric and complex' numbers for
> the 'format' argument.
> If you replac numeric by reald, what this entails (by logic)
> that 'integer' numbers are *not* affected by 'digits' nor  'scientific'.
> 
> But there's yet more subtlety: 'integer' here means class/type "integer"
> and not just an integer number, i.e., the difference of  1L and 1 :
> 
>> str(1)
>   num 1
>> str(1L)
>   int 1
>> str(1:3)
>   int [1:3] 1 2 3
>> str(1:3 + 0)
>   num [1:3] 1 2 3
>> 
> ------ end of Excursion{'integer' ..} -------------------------------
> 
> Back to real numbers : 'digits' are used as *significant* digits
> (and are only a suggestion: format() and prettyNum() ensure
> a common width for their resulting strings so printing will be
> nicely aligned), see e.g.
> 
>> format(3.14, scientific=FALSE)
>   [1] "3.14"
>> format(3.14*c(1, 1e-7),   scientific=FALSE)
>   [1] "3.140000000" "0.000000314"
>> 
> 
> So back to your examples : What would you mean with
> ``0 significant digits'' ? 
> It really does not make sense to show *no* significant digits ..
> 
> Intuitively, without spending enough time, I'd say that the bug
> in format.default() -- which is called by prettyNum() in
> this case -- is that it does *not* treat
> 'digits = 0'  as 'digits = 1'  in this case.  
> 
> NB:  digits = 0 has been valid in    options(digits = 0)  etc,
> "forever" I think, possibly inherited from S,  but I don't
> really know and I wonder if we should not  make it invalid eventually
> requiring at least 1.
> So we could make it raise a *warning* (and set it to '1') for  now.
> What do others think? 
> 
> Anyone with S(-PLUS) or Terr or .. who can report if  digits=0
> is allowed there and what it does in a simple situation like
> 
>> format(as.integer(2^30), digits=0) # digits not used at all
>  [1] "1073741824"
>> format(2^30, digits=0)
>  [1] "%#4.0-1e"
>> 
> 
> 
> Last but not least:  If you really want to use exponential
> format, you should typically use  sprintf() or formatC()  where
> you can tweak to get what you want.
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Fri Mar 22 18:07:26 2019
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Fri, 22 Mar 2019 18:07:26 +0100
Subject: [Rd] prettyNum digits=0 not compatible with scientific notation
In-Reply-To: <AAF25F95-1DDD-4C41-8132-54259D09679C@gmail.com>
References: <30D28A63376088428E8318DD67FD407FCADD67@ny-mailstore1.walleyetrading.net>
 <23700.42650.645514.620943@stat.math.ethz.ch>
 <AAF25F95-1DDD-4C41-8132-54259D09679C@gmail.com>
Message-ID: <23701.5710.730216.751381@stat.math.ethz.ch>

>>>>> peter dalgaard 
>>>>>     on Fri, 22 Mar 2019 17:30:19 +0100 writes:

    > FWIW, it doesn't seem to be happening on Mac OS:
    >> format(2^30, digits=0)
    > [1] "1.e+09"
    >> prettyNum(12345.6, digits=0)
    > [1] "1.e+04"

    > A glibc misfeature?

It seems (and note we are talking about format.default() here,
   	  of which prettyNum() is only a wrapper in this case):

Here's an example that shows that  'digits=0'  actually can make
"sense" contrary to what I've claimed previously::

nn <- 123456*10^(0:-8); dd <- c(10, 7, 2:0); names(dd) <- paste0("d=",dd)
sapply(dd, function(dig) sapply(nn, format, digits=dig))

gives (on Linux R 3.5.3, Fedora 28)

       d=10         d=7          d=2      d=1     d=0       
 [1,] "123456"     "123456"     "123456" "1e+05" "%#4.0-1e"
 [2,] "12345.6"    "12345.6"    "12346"  "12346" "%#4.0-1e"
 [3,] "1234.56"    "1234.56"    "1235"   "1235"  "1235"    
 [4,] "123.456"    "123.456"    "123"    "123"   "123"     
 [5,] "12.3456"    "12.3456"    "12"     "12"    "12"      
 [6,] "1.23456"    "1.23456"    "1.2"    "1"     "1"       
 [7,] "0.123456"   "0.123456"   "0.12"   "0.1"   "0"       
 [8,] "0.0123456"  "0.0123456"  "0.012"  "0.01"  "0"       
 [9,] "0.00123456" "0.00123456" "0.0012" "0.001" "0"       

but probably looks better on Mac

and on our  "Windows Server x64 (build 14393)",
		    for both Platforms
		 	i386-w64-mingw32/i386 (32-bit)
                       x86_64-w64-mingw32/x64 (64-bit)

is slightly "better":

      d=10         d=7          d=2      d=1     d=0
 [1,] "123456"     "123456"     "123456" "1e+05" "1.234560e+05"
 [2,] "12345.6"    "12345.6"    "12346"  "12346" "1.234560e+04"
 [3,] "1234.56"    "1234.56"    "1235"   "1235"  "1235"
 [4,] "123.456"    "123.456"    "123"    "123"   "123"
 [5,] "12.3456"    "12.3456"    "12"     "12"    "12"
 [6,] "1.23456"    "1.23456"    "1.2"    "1"     "1"
 [7,] "0.123456"   "0.123456"   "0.12"   "0.1"   "0"
 [8,] "0.0123456"  "0.0123456"  "0.012"  "0.01"  "0"
 [9,] "0.00123456" "0.00123456" "0.0012" "0.001" "0"

... interesting ...

Martin


    >> On 22 Mar 2019, at 10:10 , Martin Maechler <maechler at stat.math.ethz.ch> wrote:
    >> 
    >> Thank you, Robert for raising this here !
    >> 
    >>>>>>> Robert McGehee 
    >>>>>>> on Thu, 21 Mar 2019 20:56:19 +0000 writes:
    >> 
    >>> R developers,
    >>> Seems I get a bad result ("%#4.0-1e" in particular) when trying to use prettyNum digits=0 with scientific notation. I tried on both my Linux box and on an online R evaluator and saw the same problem, so it's not limited to my box at least. I see the problem in both R 3.5.3 and R 3.3.2.
    >> 
    >>> options(scipen= -100)
    >> 
    >> The above is extreme: You're basically setting an option to
    >> always see non-integer numbers in "scientific" format ..
    >> But read below about what 'digits' means in this case.
    >> 
    >>> prettyNum(1, digits=0)
    >>> [1] "%#4.0-1e"
    >>> prettyNum(2, digits=0)
    >>> [1] "%#4.0-1e"
    >>> prettyNum(1, digits=0, scientific=FALSE) # Works
    >>> [1] "1"
    >>> prettyNum(1:2, digits=0) # Works
    >>> [1] "1" "2"
    >>> prettyNum(c(1.1, 2.1), digits=0)
    >>> [1] "%#4.0-1e" "%#4.0-1e"
    >>> prettyNum(c(1.1, 2.1), digits=1) # Works
    >>> [1] "1e+00" "2e+00"
    >> 
    >> I'm the scape goat / culprit /.. : I have worked on tweaking the
    >> formatting of (non integer) numbers in R for a long time, on the
    >> way introducing prettyNum(), also already long ago...
    >> but then it's actually not prettyNum() but rather format() here :
    >> 
    >> Have you read its help page - *with* care?
    >> 
    >> If you do, you'd notice that 'digits' is not among the formal arguments
    >> of prettyNum() *and* that prettyNum() passes all its  `...`  to format().
    >> And if you read  ?format [which then you should to understand 'digits' !]
    >> you see
    >> 
    >>> digits: how many significant digits are to be used for numeric and
    >>> complex ?x?.  The default, NULL, uses ?getOption("digits")?.
    >>> This is a suggestion: enough decimal places will be used so that
    >>> the smallest (in magnitude) number has this many significant 
    >>> digits, and also to satisfy ?nsmall?.
    >> 
    >>> [.....]
    >> 
    >> So, for the real numbers you use in your example, digits are
    >> *significant* digits as in  'options(digits= *)' or
    >> 'print(.., digits= *)'
    >> 
    >> ------ Excursion about 'integer' and format()ing ------------
    >> -- and you now may also understand why   prettyNum(1:2, digits=0)  works
    >> as you expect: integer formatting behaves differently   ....
    >> but I acknowledge that the  ?format   help page does not say so
    >> explicitly yet:  it 'real and complex' numbers for the
    >> 'scientific' argument,  and 'numeric and complex' numbers for
    >> the 'format' argument.
    >> If you replac numeric by reald, what this entails (by logic)
    >> that 'integer' numbers are *not* affected by 'digits' nor  'scientific'.
    >> 
    >> But there's yet more subtlety: 'integer' here means class/type "integer"
    >> and not just an integer number, i.e., the difference of  1L and 1 :
    >> 
    >>> str(1)
    >> num 1
    >>> str(1L)
    >> int 1
    >>> str(1:3)
    >> int [1:3] 1 2 3
    >>> str(1:3 + 0)
    >> num [1:3] 1 2 3
    >>> 
    >> ------ end of Excursion{'integer' ..} -------------------------------
    >> 
    >> Back to real numbers : 'digits' are used as *significant* digits
    >> (and are only a suggestion: format() and prettyNum() ensure
    >> a common width for their resulting strings so printing will be
    >> nicely aligned), see e.g.
    >> 
    >>> format(3.14, scientific=FALSE)
    >> [1] "3.14"
    >>> format(3.14*c(1, 1e-7),   scientific=FALSE)
    >> [1] "3.140000000" "0.000000314"
    >>> 
    >> 
    >> So back to your examples : What would you mean with
    >> ``0 significant digits'' ? 
    >> It really does not make sense to show *no* significant digits ..
    >> 
    >> Intuitively, without spending enough time, I'd say that the bug
    >> in format.default() -- which is called by prettyNum() in
    >> this case -- is that it does *not* treat
    >> 'digits = 0'  as 'digits = 1'  in this case.  
    >> 
    >> NB:  digits = 0 has been valid in    options(digits = 0)  etc,
    >> "forever" I think, possibly inherited from S,  but I don't
    >> really know and I wonder if we should not  make it invalid eventually
    >> requiring at least 1.
    >> So we could make it raise a *warning* (and set it to '1') for  now.
    >> What do others think? 
    >> 
    >> Anyone with S(-PLUS) or Terr or .. who can report if  digits=0
    >> is allowed there and what it does in a simple situation like
    >> 
    >>> format(as.integer(2^30), digits=0) # digits not used at all
    >> [1] "1073741824"
    >>> format(2^30, digits=0)
    >> [1] "%#4.0-1e"
    >>> 
    >> 
    >> 
    >> Last but not least:  If you really want to use exponential
    >> format, you should typically use  sprintf() or formatC()  where
    >> you can tweak to get what you want.
    >> 
    >> ______________________________________________
    >> R-devel at r-project.org mailing list
    >> https://stat.ethz.ch/mailman/listinfo/r-devel

    > -- 
    > Peter Dalgaard, Professor,
    > Center for Statistics, Copenhagen Business School
    > Solbjerg Plads 3, 2000 Frederiksberg, Denmark
    > Phone: (+45)38153501
    > Office: A 4.23
    > Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From pd@|gd @end|ng |rom gm@||@com  Sat Mar 23 00:25:14 2019
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Sat, 23 Mar 2019 00:25:14 +0100
Subject: [Rd] prettyNum digits=0 not compatible with scientific notation
In-Reply-To: <23701.5710.730216.751381@stat.math.ethz.ch>
References: <30D28A63376088428E8318DD67FD407FCADD67@ny-mailstore1.walleyetrading.net>
 <23700.42650.645514.620943@stat.math.ethz.ch>
 <AAF25F95-1DDD-4C41-8132-54259D09679C@gmail.com>
 <23701.5710.730216.751381@stat.math.ethz.ch>
Message-ID: <C5DDCC68-3180-44B2-941C-E1C58E86491B@gmail.com>



> On 22 Mar 2019, at 18:07 , Martin Maechler <maechler at stat.math.ethz.ch> wrote:
> 
> gives (on Linux R 3.5.3, Fedora 28)
> 
>       d=10         d=7          d=2      d=1     d=0       
> [1,] "123456"     "123456"     "123456" "1e+05" "%#4.0-1e"
> [2,] "12345.6"    "12345.6"    "12346"  "12346" "%#4.0-1e"
> [3,] "1234.56"    "1234.56"    "1235"   "1235"  "1235"    
> [4,] "123.456"    "123.456"    "123"    "123"   "123"     
> [5,] "12.3456"    "12.3456"    "12"     "12"    "12"      
> [6,] "1.23456"    "1.23456"    "1.2"    "1"     "1"       
> [7,] "0.123456"   "0.123456"   "0.12"   "0.1"   "0"       
> [8,] "0.0123456"  "0.0123456"  "0.012"  "0.01"  "0"       
> [9,] "0.00123456" "0.00123456" "0.0012" "0.001" "0"       
> 
> but probably looks better on Mac


Yes (3.5.1 though)

> nn <- 123456*10^(0:-8); dd <- c(10, 7, 2:0); names(dd) <- paste0("d=",dd)
> sapply(dd, function(dig) sapply(nn, format, digits=dig))
      d=10         d=7          d=2      d=1     d=0     
 [1,] "123456"     "123456"     "123456" "1e+05" "1.e+05"
 [2,] "12345.6"    "12345.6"    "12346"  "12346" "1.e+04"
 [3,] "1234.56"    "1234.56"    "1235"   "1235"  "1235"  
 [4,] "123.456"    "123.456"    "123"    "123"   "123"   
 [5,] "12.3456"    "12.3456"    "12"     "12"    "12"    
 [6,] "1.23456"    "1.23456"    "1.2"    "1"     "1"     
 [7,] "0.123456"   "0.123456"   "0.12"   "0.1"   "0"     
 [8,] "0.0123456"  "0.0123456"  "0.012"  "0.01"  "0"     
 [9,] "0.00123456" "0.00123456" "0.0012" "0.001" "0"  


   
-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From m@rc_@chw@rtz @end|ng |rom me@com  Sat Mar 23 01:06:20 2019
From: m@rc_@chw@rtz @end|ng |rom me@com (Marc Schwartz)
Date: Fri, 22 Mar 2019 20:06:20 -0400
Subject: [Rd] prettyNum digits=0 not compatible with scientific notation
In-Reply-To: <C5DDCC68-3180-44B2-941C-E1C58E86491B@gmail.com>
References: <30D28A63376088428E8318DD67FD407FCADD67@ny-mailstore1.walleyetrading.net>
 <23700.42650.645514.620943@stat.math.ethz.ch>
 <AAF25F95-1DDD-4C41-8132-54259D09679C@gmail.com>
 <23701.5710.730216.751381@stat.math.ethz.ch>
 <C5DDCC68-3180-44B2-941C-E1C58E86491B@gmail.com>
Message-ID: <3B191511-B121-4BEC-9E11-8900E38F8706@me.com>



> On Mar 22, 2019, at 7:25 PM, peter dalgaard <pdalgd at gmail.com> wrote:
> 
> 
> 
>> On 22 Mar 2019, at 18:07 , Martin Maechler <maechler at stat.math.ethz.ch> wrote:
>> 
>> gives (on Linux R 3.5.3, Fedora 28)
>> 
>>      d=10         d=7          d=2      d=1     d=0       
>> [1,] "123456"     "123456"     "123456" "1e+05" "%#4.0-1e"
>> [2,] "12345.6"    "12345.6"    "12346"  "12346" "%#4.0-1e"
>> [3,] "1234.56"    "1234.56"    "1235"   "1235"  "1235"    
>> [4,] "123.456"    "123.456"    "123"    "123"   "123"     
>> [5,] "12.3456"    "12.3456"    "12"     "12"    "12"      
>> [6,] "1.23456"    "1.23456"    "1.2"    "1"     "1"       
>> [7,] "0.123456"   "0.123456"   "0.12"   "0.1"   "0"       
>> [8,] "0.0123456"  "0.0123456"  "0.012"  "0.01"  "0"       
>> [9,] "0.00123456" "0.00123456" "0.0012" "0.001" "0"       
>> 
>> but probably looks better on Mac
> 
> 
> Yes (3.5.1 though)
> 
>> nn <- 123456*10^(0:-8); dd <- c(10, 7, 2:0); names(dd) <- paste0("d=",dd)
>> sapply(dd, function(dig) sapply(nn, format, digits=dig))
>      d=10         d=7          d=2      d=1     d=0     
> [1,] "123456"     "123456"     "123456" "1e+05" "1.e+05"
> [2,] "12345.6"    "12345.6"    "12346"  "12346" "1.e+04"
> [3,] "1234.56"    "1234.56"    "1235"   "1235"  "1235"  
> [4,] "123.456"    "123.456"    "123"    "123"   "123"   
> [5,] "12.3456"    "12.3456"    "12"     "12"    "12"    
> [6,] "1.23456"    "1.23456"    "1.2"    "1"     "1"     
> [7,] "0.123456"   "0.123456"   "0.12"   "0.1"   "0"     
> [8,] "0.0123456"  "0.0123456"  "0.012"  "0.01"  "0"     
> [9,] "0.00123456" "0.00123456" "0.0012" "0.001" "0"  
> 


Here is 3.5.3 on macOS:

> nn <- 123456*10^(0:-8); dd <- c(10, 7, 2:0); names(dd) <- paste0("d=",dd)
> sapply(dd, function(dig) sapply(nn, format, digits=dig))
      d=10         d=7          d=2      d=1     d=0     
 [1,] "123456"     "123456"     "123456" "1e+05" "1.e+05"
 [2,] "12345.6"    "12345.6"    "12346"  "12346" "1.e+04"
 [3,] "1234.56"    "1234.56"    "1235"   "1235"  "1235"  
 [4,] "123.456"    "123.456"    "123"    "123"   "123"   
 [5,] "12.3456"    "12.3456"    "12"     "12"    "12"    
 [6,] "1.23456"    "1.23456"    "1.2"    "1"     "1"     
 [7,] "0.123456"   "0.123456"   "0.12"   "0.1"   "0"     
 [8,] "0.0123456"  "0.0123456"  "0.012"  "0.01"  "0"     
 [9,] "0.00123456" "0.00123456" "0.0012" "0.001" "0"     


Regards,

Marc Schwartz


From konr@d@rudo|ph @end|ng |rom gm@||@com  Sat Mar 23 15:26:40 2019
From: konr@d@rudo|ph @end|ng |rom gm@||@com (Konrad Rudolph)
Date: Sat, 23 Mar 2019 14:26:40 +0000
Subject: [Rd] topenv of emptyenv
Message-ID: <CAM2gKPaSjQp3Eq4Gy+B7RO-LgwgUoo8RV3JrA452f2v2FZAgLg@mail.gmail.com>

I was surprised just now to find out that `topenv(emptyenv())` equals
? `.GlobalEnv`, not `emptyenv()`. From my understanding of the
description of `topenv`, it should walk up the chain of enclosing
environments (as if by calling `e = parent.env(e)` repeatedly; in
fact, that is almost exactly its implementation in envir.c) until it
hits a top level. However, `emptyenv()` has no enclosing environments
so it should be its own top-level environment (I thought).
Unfortunately the documentation on environments is relatively sparse,
and the R Internals document doesn?t mention top-level environments.

Concretely, I encountered this in the following code, which signals an
error if `env` is the empty environment:

while (! some_complex_condition(env) && ! identical(env, toplevel(env))) {
    env = parent.env(env)
}

Of course there?s a trivial workaround (add an identity check for
`emptyenv()` in the while loop condition) but it got me wondering if
there?s a rationale for this result or if it?s ?accidental?/arbitrary:
the C `topenv` implementation defaults to returning R_GlobalEnv for an
empty environment. Is this effect actually useful (and used anywhere)?

This is in R 3.4.4 but I can?t find an indication that this behaviour
was ever changed.

Cheers

-- 
Konrad Rudolph


From dev@kurt @end|ng |rom v@nd|jck-|@ur|j@@en@be  Fri Mar 22 18:16:22 2019
From: dev@kurt @end|ng |rom v@nd|jck-|@ur|j@@en@be (Kurt Van Dijck)
Date: Fri, 22 Mar 2019 18:16:22 +0100
Subject: [Rd] [PATCH 1/2] readtable: add hook for type conversions per column
Message-ID: <1553274983-15970-1-git-send-email-dev.kurt@vandijck-laurijssen.be>

This commit adds a function parameter to readtable. The function is called
for every column.
The goal is to allow specific (non-standard) type conversions depending on the input.
When the parameter is not given, or the function returns NULL, the legacy default applies.
The colClasses parameter still takes precedence, i.e. the colConvertFn only applies to
the default conversions.
This allows to properly load a .csv with timestamps expressed in the (quite common) %d/%m/%y %H:%M format,
which was impossible since overruling as.POSIXlt makes a copy in the users namespace, and
read.table would still take the base version of as.POSIXlt.
Rather than fixing my specific requirement, this hook allows to probe for any custom format
and do smart things with little syntax.

Signed-off-by: Kurt Van Dijck <dev.kurt at vandijck-laurijssen.be>
---
 src/library/utils/R/readtable.R | 12 +++++++++++-
 1 file changed, 11 insertions(+), 1 deletion(-)

diff --git a/src/library/utils/R/readtable.R b/src/library/utils/R/readtable.R
index 238542e..076a707 100644
--- a/src/library/utils/R/readtable.R
+++ b/src/library/utils/R/readtable.R
@@ -65,6 +65,7 @@ function(file, header = FALSE, sep = "", quote = "\"'", dec = ".",
          strip.white = FALSE, blank.lines.skip = TRUE,
          comment.char = "#", allowEscapes = FALSE, flush = FALSE,
          stringsAsFactors = default.stringsAsFactors(),
+         colConvert = NULL,
          fileEncoding = "", encoding = "unknown", text, skipNul = FALSE)
 {
     if (missing(file) && !missing(text)) {
@@ -226,9 +227,18 @@ function(file, header = FALSE, sep = "", quote = "\"'", dec = ".",
     if(rlabp) do[1L] <- FALSE # don't convert "row.names"
     for (i in (1L:cols)[do]) {
         data[[i]] <-
-            if (is.na(colClasses[i]))
+            if (is.na(colClasses[i])) {
+                tmp <- NULL
+                if (!is.null(colConvert))
+                    # attempt to convert from user provided hook
+                    tmp <- colConvert(data[[i]])
+                if (!is.null(tmp))
+                    (tmp)
+                else
+                    # fallback, default
                 type.convert(data[[i]], as.is = as.is[i], dec=dec,
 			     numerals=numerals, na.strings = character(0L))
+            }
         ## as na.strings have already been converted to <NA>
             else if (colClasses[i] == "factor") as.factor(data[[i]])
             else if (colClasses[i] == "Date") as.Date(data[[i]])
-- 
1.8.5.rc3


From dev@kurt @end|ng |rom v@nd|jck-|@ur|j@@en@be  Fri Mar 22 18:16:23 2019
From: dev@kurt @end|ng |rom v@nd|jck-|@ur|j@@en@be (Kurt Van Dijck)
Date: Fri, 22 Mar 2019 18:16:23 +0100
Subject: [Rd] [PATCH 2/2] readtable: add test for type conversion hook
 'colConvert'
In-Reply-To: <1553274983-15970-1-git-send-email-dev.kurt@vandijck-laurijssen.be>
References: <1553274983-15970-1-git-send-email-dev.kurt@vandijck-laurijssen.be>
Message-ID: <1553274983-15970-2-git-send-email-dev.kurt@vandijck-laurijssen.be>

Signed-off-by: Kurt Van Dijck <dev.kurt at vandijck-laurijssen.be>
---
 tests/reg-tests-2.R         | 21 +++++++++++++++++++++
 tests/reg-tests-2.Rout.save | 27 +++++++++++++++++++++++++++
 2 files changed, 48 insertions(+)

diff --git a/tests/reg-tests-2.R b/tests/reg-tests-2.R
index 9fd5242..5026fe7 100644
--- a/tests/reg-tests-2.R
+++ b/tests/reg-tests-2.R
@@ -1329,6 +1329,27 @@ unlink(foo)
 ## added in 2.0.0
 
 
+## colConvert in read.table
+probecol <- function(col) {
+	tmp <- as.POSIXlt(col, optional=TRUE, tryFormats=c("%d/%m/%Y %H:%M"));
+	if (all(!is.na(tmp)))
+		return (tmp)
+	tmp <- as.POSIXlt(col, optional=TRUE, tryFormats=c("%d/%m/%Y"));
+	if (all(!is.na(tmp)))
+		return (tmp)
+}
+
+Mat <- matrix(c(1:3, letters[1:3], 1:3, LETTERS[1:3],
+                c("22/4/1969", "8/4/1971", "23/9/1973"),
+                c("22/4/1969 6:01", " 8/4/1971 7:23", "23/9/1973 8:45")),
+              3, 6)
+foo <- tempfile()
+write.table(Mat, foo, sep = ",", col.names = FALSE, row.names = FALSE)
+read.table(foo, sep = ",", colConvert=probecol)
+unlist(sapply(.Last.value, class))
+unlink(foo)
+
+
 ## write.table with complex columns (PR#7260, in part)
 write.table(data.frame(x = 0.5+1:4, y = 1:4 + 1.5i), file = "")
 # printed all as complex in 2.0.0.
diff --git a/tests/reg-tests-2.Rout.save b/tests/reg-tests-2.Rout.save
index 598dd71..668898e 100644
--- a/tests/reg-tests-2.Rout.save
+++ b/tests/reg-tests-2.Rout.save
@@ -4206,6 +4206,33 @@ Warning message:
 > ## added in 2.0.0
 > 
 > 
+> ## colConvert in read.table
+> probecol <- function(col) {
++ 	tmp <- as.POSIXlt(col, optional=TRUE, tryFormats=c("%d/%m/%Y %H:%M"));
++ 	if (all(!is.na(tmp)))
++ 		return (tmp)
++ 	tmp <- as.POSIXlt(col, optional=TRUE, tryFormats=c("%d/%m/%Y"));
++ 	if (all(!is.na(tmp)))
++ 		return (tmp)
++ }
+> 
+> Mat <- matrix(c(1:3, letters[1:3], 1:3, LETTERS[1:3],
++                 c("22/4/1969", "8/4/1971", "23/9/1973"),
++                 c("22/4/1969 6:01", " 8/4/1971 7:23", "23/9/1973 8:45")),
++               3, 6)
+> foo <- tempfile()
+> write.table(Mat, foo, sep = ",", col.names = FALSE, row.names = FALSE)
+> read.table(foo, sep = ",", colConvert=probecol)
+  V1 V2 V3 V4         V5                  V6
+1  1  a  1  A 1969-04-22 1969-04-22 06:01:00
+2  2  b  2  B 1971-04-08 1971-04-08 07:23:00
+3  3  c  3  C 1973-09-23 1973-09-23 08:45:00
+> unlist(sapply(.Last.value, class))
+       V1        V2        V3        V4       V51       V52       V61       V62 
+"integer"  "factor" "integer"  "factor" "POSIXlt"  "POSIXt" "POSIXlt"  "POSIXt" 
+> unlink(foo)
+> 
+> 
 > ## write.table with complex columns (PR#7260, in part)
 > write.table(data.frame(x = 0.5+1:4, y = 1:4 + 1.5i), file = "")
 "x" "y"
-- 
1.8.5.rc3


From @@m@@|ber@ @end|ng |rom gm@||@com  Mon Mar 25 16:00:56 2019
From: @@m@@|ber@ @end|ng |rom gm@||@com (Sam Albers)
Date: Mon, 25 Mar 2019 08:00:56 -0700
Subject: [Rd] R 3.5.3 having trouble spawning a new process on my Windows 10
 machine
Message-ID: <CAKru3ADYab+Z5nELDNX=LaPWCTE5Cumd57sbp6jKmRA7S3U=fA@mail.gmail.com>

Hi all,

I am noticing some strange behaviour so I am bringing to this list. In the
past when I have submitted bugs to bugzilla, I have come here first for
confirmation/advice. Hopefully this is appropriate.

Upgrading from R 3.5.2 to R 3.5.3 seems to have elicited some strange
behaviour on my Windows machine. R seems to have trouble spawning a new
process on my machine. You can noticing with all sort of packages, like
devtools, which try to spawn new R processes. Here is the replication of
the beahviour:



## On R 3.5.3
Open a command prompt:

H:\>R
'"C:\PROGRA~1\R\R-35~1.3/bin/x64/Rterm.exe"' is not recognized as an
internal or external command,
operable program or batch file.

H:\>Rscript -e "sessionInfo()"
R version 3.5.3 (2019-03-11)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 10 x64 (build 17134)

Matrix products: default

locale:
[1] LC_COLLATE=English_Canada.1252  LC_CTYPE=English_Canada.1252
[3] LC_MONETARY=English_Canada.1252 LC_NUMERIC=C
[5] LC_TIME=English_Canada.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] compiler_3.5.3



## On 3.5.2
H:\>R

R version 3.5.2 (2018-12-20) -- "Eggshell Igloo"
Copyright (C) 2018 The R Foundation for Statistical Computing
Platform: x86_64-w64-mingw32/x64 (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> q()
Save workspace image? [y/n/c]: n

H:\>Rscript -e "sessionInfo()"
R version 3.5.2 (2018-12-20)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 10 x64 (build 17134)

Matrix products: default

locale:
[1] LC_COLLATE=English_Canada.1252  LC_CTYPE=English_Canada.1252
[3] LC_MONETARY=English_Canada.1252 LC_NUMERIC=C
[5] LC_TIME=English_Canada.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] compiler_3.5.2



## Considerations
- I have manually removed both my .Renviron and .Rprofile files just to
ensure those weren't muddling up anything.
- I have my PATH set like this "C:\Program Files\R\R-3.5.3\bin"  for 3.5.3
and "C:\Program Files\R\R-3.5.2\bin" for 3.5.2
- R 3.5.3 works final if I just open the default console that ships with R.
But then anytime I try to launch a new process I get the above error.

A similar issue has been raised up before
https://stat.ethz.ch/pipermail/r-devel/2017-September/074921.html
https://stat.ethz.ch/pipermail/r-devel/2015-September/071714.html

Am I missing something obvious here? Many thanks in advance for taking a
look.

Regards,

Sam

	[[alternative HTML version deleted]]


From jor|@mey@ @end|ng |rom gm@||@com  Mon Mar 25 17:15:10 2019
From: jor|@mey@ @end|ng |rom gm@||@com (Joris Meys)
Date: Mon, 25 Mar 2019 17:15:10 +0100
Subject: [Rd] 
 R 3.5.3 having trouble spawning a new process on my Windows 10
 machine
In-Reply-To: <CAKru3ADYab+Z5nELDNX=LaPWCTE5Cumd57sbp6jKmRA7S3U=fA@mail.gmail.com>
References: <CAKru3ADYab+Z5nELDNX=LaPWCTE5Cumd57sbp6jKmRA7S3U=fA@mail.gmail.com>
Message-ID: <CAO1zAVaSwxMyAoKXStFtd-PtAXSaFS+m5MMrp5sRarTYcpa1MA@mail.gmail.com>

Hi Sam,

Is your PATH set on your user environment variables or on the system?
Did you try to remove the entry for R-3.5.2 ?

I have tested with a standard install, and I can't reproduce your error. I
have the exact same path in my system PATH environment variable for 3.5.3,
and nothing for other versions.

Sorry I can't be of any more help.
Cheers
Joris

On Mon, Mar 25, 2019 at 4:54 PM Sam Albers <sam.albers at gmail.com> wrote:

> Hi all,
>
> I am noticing some strange behaviour so I am bringing to this list. In the
> past when I have submitted bugs to bugzilla, I have come here first for
> confirmation/advice. Hopefully this is appropriate.
>
> Upgrading from R 3.5.2 to R 3.5.3 seems to have elicited some strange
> behaviour on my Windows machine. R seems to have trouble spawning a new
> process on my machine. You can noticing with all sort of packages, like
> devtools, which try to spawn new R processes. Here is the replication of
> the beahviour:
>
>
>
> ## On R 3.5.3
> Open a command prompt:
>
> H:\>R
> '"C:\PROGRA~1\R\R-35~1.3/bin/x64/Rterm.exe"' is not recognized as an
> internal or external command,
> operable program or batch file.
>
> H:\>Rscript -e "sessionInfo()"
> R version 3.5.3 (2019-03-11)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Running under: Windows 10 x64 (build 17134)
>
> Matrix products: default
>
> locale:
> [1] LC_COLLATE=English_Canada.1252  LC_CTYPE=English_Canada.1252
> [3] LC_MONETARY=English_Canada.1252 LC_NUMERIC=C
> [5] LC_TIME=English_Canada.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> loaded via a namespace (and not attached):
> [1] compiler_3.5.3
>
>
>
> ## On 3.5.2
> H:\>R
>
> R version 3.5.2 (2018-12-20) -- "Eggshell Igloo"
> Copyright (C) 2018 The R Foundation for Statistical Computing
> Platform: x86_64-w64-mingw32/x64 (64-bit)
>
> R is free software and comes with ABSOLUTELY NO WARRANTY.
> You are welcome to redistribute it under certain conditions.
> Type 'license()' or 'licence()' for distribution details.
>
>   Natural language support but running in an English locale
>
> R is a collaborative project with many contributors.
> Type 'contributors()' for more information and
> 'citation()' on how to cite R or R packages in publications.
>
> Type 'demo()' for some demos, 'help()' for on-line help, or
> 'help.start()' for an HTML browser interface to help.
> Type 'q()' to quit R.
>
> > q()
> Save workspace image? [y/n/c]: n
>
> H:\>Rscript -e "sessionInfo()"
> R version 3.5.2 (2018-12-20)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Running under: Windows 10 x64 (build 17134)
>
> Matrix products: default
>
> locale:
> [1] LC_COLLATE=English_Canada.1252  LC_CTYPE=English_Canada.1252
> [3] LC_MONETARY=English_Canada.1252 LC_NUMERIC=C
> [5] LC_TIME=English_Canada.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> loaded via a namespace (and not attached):
> [1] compiler_3.5.2
>
>
>
> ## Considerations
> - I have manually removed both my .Renviron and .Rprofile files just to
> ensure those weren't muddling up anything.
> - I have my PATH set like this "C:\Program Files\R\R-3.5.3\bin"  for 3.5.3
> and "C:\Program Files\R\R-3.5.2\bin" for 3.5.2
> - R 3.5.3 works final if I just open the default console that ships with R.
> But then anytime I try to launch a new process I get the above error.
>
> A similar issue has been raised up before
> https://stat.ethz.ch/pipermail/r-devel/2017-September/074921.html
> https://stat.ethz.ch/pipermail/r-devel/2015-September/071714.html
>
> Am I missing something obvious here? Many thanks in advance for taking a
> look.
>
> Regards,
>
> Sam
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


-- 
Joris Meys
Statistical consultant

Department of Data Analysis and Mathematical Modelling
Ghent University
Coupure Links 653, B-9000 Gent (Belgium)
<https://maps.google.com/?q=Coupure+links+653,%C2%A0B-9000+Gent,%C2%A0Belgium&entry=gmail&source=g>

-----------
Biowiskundedagen 2018-2019
http://www.biowiskundedagen.ugent.be/

-------------------------------
Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php

	[[alternative HTML version deleted]]


From @purd|e@@ @end|ng |rom gm@||@com  Tue Mar 26 04:27:55 2019
From: @purd|e@@ @end|ng |rom gm@||@com (Abs Spurdle)
Date: Tue, 26 Mar 2019 16:27:55 +1300
Subject: [Rd] Discrepancy between is.list() and is(x, "list")
Message-ID: <CAB8pepyU2qbU7fd1J9J6kyr_657PHFYHoJV6fnvNiHqqjq-24w@mail.gmail.com>

> I have noticed a discrepancy between is.list() and is(x, ?list?)

There's a similar problem with inherits().

On R 3.5.3:

> f = function () 1
> class (f) = "f"

> is.function (f)
[1] TRUE
> inherits (f, "function")
[1] FALSE

I didn't check what happens with:
> class (f) = c ("f", "function")

However, they should have the same result, regardless.

> Is this discrepancy intentional?

I hope not.

	[[alternative HTML version deleted]]


From @purd|e@@ @end|ng |rom gm@||@com  Tue Mar 26 04:43:47 2019
From: @purd|e@@ @end|ng |rom gm@||@com (Abs Spurdle)
Date: Tue, 26 Mar 2019 16:43:47 +1300
Subject: [Rd] bugs in head() and tail()
Message-ID: <CAB8pepwajebtmzuGyMzd7ak_PhMakSwkXS-JEqV4VFW_2kh7sw@mail.gmail.com>

(Using R 3.5.3).

I found bugs in head() and tail().

The following works:

> f = function () 1
> head (f)
1 function ()
2 1

However, the following does not:

> class (f) = "f"
> head (f)
Error in x[seq_len(n)] : object of type 'closure' is not subsettable

	[[alternative HTML version deleted]]


From g@bembecker @end|ng |rom gm@||@com  Tue Mar 26 05:58:37 2019
From: g@bembecker @end|ng |rom gm@||@com (Gabriel Becker)
Date: Mon, 25 Mar 2019 21:58:37 -0700
Subject: [Rd] bugs in head() and tail()
In-Reply-To: <CAB8pepwajebtmzuGyMzd7ak_PhMakSwkXS-JEqV4VFW_2kh7sw@mail.gmail.com>
References: <CAB8pepwajebtmzuGyMzd7ak_PhMakSwkXS-JEqV4VFW_2kh7sw@mail.gmail.com>
Message-ID: <CAD4oTHFbbRs5GvhyR33+0mvXmsHFsBAK8hL_2CBDC_eeEA0e_w@mail.gmail.com>

Hi Abs,

This is because the class is "f", not c("f", "function") in your second
example. S3 method dispatch is doing what you (unintentionally, I presume)
asked it to do.

The S3 method which allows head to take functions is utils:::head.function.
S3 can only be expected to  understand inheritance if the value of class(f)
is multivalued. It doesn't have any way of knowing  f is still a function
after the class assignment because "function" does not appear anywhere in
the class vector, so instead of hitting utils:::head.function, it hits
utils:::head.default, which uses [ on the argument, causing the error.

I'd say this is "expected" behavior within the context of the S3 system.

I also see this behavior at least as far aback as 3.5.1, so its not new to
3.5.3.

Best,
~G

On Mon, Mar 25, 2019 at 8:44 PM Abs Spurdle <spurdle.a at gmail.com> wrote:

> (Using R 3.5.3).
>
> I found bugs in head() and tail().
>
> The following works:
>
> > f = function () 1
> > head (f)
> 1 function ()
> 2 1
>
> However, the following does not:
>
> > class (f) = "f"
> > head (f)
> Error in x[seq_len(n)] : object of type 'closure' is not subsettable
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From @@m@@|ber@ @end|ng |rom gm@||@com  Mon Mar 25 17:14:42 2019
From: @@m@@|ber@ @end|ng |rom gm@||@com (Sam Albers)
Date: Mon, 25 Mar 2019 09:14:42 -0700
Subject: [Rd] 
 R 3.5.3 having trouble spawning a new process on my Windows 10
 machine
In-Reply-To: <CAO1zAVaSwxMyAoKXStFtd-PtAXSaFS+m5MMrp5sRarTYcpa1MA@mail.gmail.com>
References: <CAKru3ADYab+Z5nELDNX=LaPWCTE5Cumd57sbp6jKmRA7S3U=fA@mail.gmail.com>
 <CAO1zAVaSwxMyAoKXStFtd-PtAXSaFS+m5MMrp5sRarTYcpa1MA@mail.gmail.com>
Message-ID: <CAKru3ADJvp1ygRDYUs9vMv4o4dQXEJQ-RNz6vm8tON7aX8u4Ow@mail.gmail.com>

Hi Joris,

Thanks for trying.

> Is your PATH set on your user environment variables or on the system?

It is set as a system variable

> Did you try to remove the entry for R-3.5.2 ?
For each version iteration in the above example, I only had the path of the
version that I was working with. So yes.

Sam


On Mon, Mar 25, 2019 at 9:11 AM Joris Meys <jorismeys at gmail.com> wrote:

> Hi Sam,
>
> Is your PATH set on your user environment variables or on the system?
> Did you try to remove the entry for R-3.5.2 ?
>
> I have tested with a standard install, and I can't reproduce your error. I
> have the exact same path in my system PATH environment variable for 3.5.3,
> and nothing for other versions.
>
> Sorry I can't be of any more help.
> Cheers
> Joris
>
> On Mon, Mar 25, 2019 at 4:54 PM Sam Albers <sam.albers at gmail.com> wrote:
>
>> Hi all,
>>
>> I am noticing some strange behaviour so I am bringing to this list. In the
>> past when I have submitted bugs to bugzilla, I have come here first for
>> confirmation/advice. Hopefully this is appropriate.
>>
>> Upgrading from R 3.5.2 to R 3.5.3 seems to have elicited some strange
>> behaviour on my Windows machine. R seems to have trouble spawning a new
>> process on my machine. You can noticing with all sort of packages, like
>> devtools, which try to spawn new R processes. Here is the replication of
>> the beahviour:
>>
>>
>>
>> ## On R 3.5.3
>> Open a command prompt:
>>
>> H:\>R
>> '"C:\PROGRA~1\R\R-35~1.3/bin/x64/Rterm.exe"' is not recognized as an
>> internal or external command,
>> operable program or batch file.
>>
>> H:\>Rscript -e "sessionInfo()"
>> R version 3.5.3 (2019-03-11)
>> Platform: x86_64-w64-mingw32/x64 (64-bit)
>> Running under: Windows 10 x64 (build 17134)
>>
>> Matrix products: default
>>
>> locale:
>> [1] LC_COLLATE=English_Canada.1252  LC_CTYPE=English_Canada.1252
>> [3] LC_MONETARY=English_Canada.1252 LC_NUMERIC=C
>> [5] LC_TIME=English_Canada.1252
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> loaded via a namespace (and not attached):
>> [1] compiler_3.5.3
>>
>>
>>
>> ## On 3.5.2
>> H:\>R
>>
>> R version 3.5.2 (2018-12-20) -- "Eggshell Igloo"
>> Copyright (C) 2018 The R Foundation for Statistical Computing
>> Platform: x86_64-w64-mingw32/x64 (64-bit)
>>
>> R is free software and comes with ABSOLUTELY NO WARRANTY.
>> You are welcome to redistribute it under certain conditions.
>> Type 'license()' or 'licence()' for distribution details.
>>
>>   Natural language support but running in an English locale
>>
>> R is a collaborative project with many contributors.
>> Type 'contributors()' for more information and
>> 'citation()' on how to cite R or R packages in publications.
>>
>> Type 'demo()' for some demos, 'help()' for on-line help, or
>> 'help.start()' for an HTML browser interface to help.
>> Type 'q()' to quit R.
>>
>> > q()
>> Save workspace image? [y/n/c]: n
>>
>> H:\>Rscript -e "sessionInfo()"
>> R version 3.5.2 (2018-12-20)
>> Platform: x86_64-w64-mingw32/x64 (64-bit)
>> Running under: Windows 10 x64 (build 17134)
>>
>> Matrix products: default
>>
>> locale:
>> [1] LC_COLLATE=English_Canada.1252  LC_CTYPE=English_Canada.1252
>> [3] LC_MONETARY=English_Canada.1252 LC_NUMERIC=C
>> [5] LC_TIME=English_Canada.1252
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> loaded via a namespace (and not attached):
>> [1] compiler_3.5.2
>>
>>
>>
>> ## Considerations
>> - I have manually removed both my .Renviron and .Rprofile files just to
>> ensure those weren't muddling up anything.
>> - I have my PATH set like this "C:\Program Files\R\R-3.5.3\bin"  for 3.5.3
>> and "C:\Program Files\R\R-3.5.2\bin" for 3.5.2
>> - R 3.5.3 works final if I just open the default console that ships with
>> R.
>> But then anytime I try to launch a new process I get the above error.
>>
>> A similar issue has been raised up before
>> https://stat.ethz.ch/pipermail/r-devel/2017-September/074921.html
>> https://stat.ethz.ch/pipermail/r-devel/2015-September/071714.html
>>
>> Am I missing something obvious here? Many thanks in advance for taking a
>> look.
>>
>> Regards,
>>
>> Sam
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
>
> --
> Joris Meys
> Statistical consultant
>
> Department of Data Analysis and Mathematical Modelling
> Ghent University
> Coupure Links 653, B-9000 Gent (Belgium)
>
> <https://maps.google.com/?q=Coupure+links+653,%C2%A0B-9000+Gent,%C2%A0Belgium&entry=gmail&source=g>
>
> -----------
> Biowiskundedagen 2018-2019
> http://www.biowiskundedagen.ugent.be/
>
> -------------------------------
> Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php
>

	[[alternative HTML version deleted]]


From |uked@n@m| @end|ng |rom @bcg|ob@|@net  Tue Mar 26 02:03:43 2019
From: |uked@n@m| @end|ng |rom @bcg|ob@|@net (Luke Smith)
Date: Tue, 26 Mar 2019 01:03:43 +0000 (UTC)
Subject: [Rd] [Enhancement] New argument for dirname() -- dirname(path,
 depth = 1L)
References: <458052379.10980352.1553562223213.ref@mail.yahoo.com>
Message-ID: <458052379.10980352.1553562223213@mail.yahoo.com>

The new argument 'depth' would specify the depth to recurse up the file path.? As in:
> dirname("path/to/some/where", depth = 3L)[1] "path"
The new argument would take on the default value of 1L, since this is the current behavior of the function.

 Problems will arise when 'depth' is unusually large (i.e. dirname(path, depth = 1e5)).

During execution, a warning could be issued to the user indicating an unusually large value for 'depth'.

	[[alternative HTML version deleted]]


From ccberry @end|ng |rom uc@d@edu  Tue Mar 26 17:30:58 2019
From: ccberry @end|ng |rom uc@d@edu (Berry, Charles)
Date: Tue, 26 Mar 2019 16:30:58 +0000
Subject: [Rd] Discrepancy between is.list() and is(x, "list")
In-Reply-To: <CAB8pepyU2qbU7fd1J9J6kyr_657PHFYHoJV6fnvNiHqqjq-24w@mail.gmail.com>
References: <CAB8pepyU2qbU7fd1J9J6kyr_657PHFYHoJV6fnvNiHqqjq-24w@mail.gmail.com>
Message-ID: <EB8494AA-8DAA-4B9A-B636-7E979251EF0C@ucsd.edu>

In the case of inherits (at least) this seems intended.

The help page says:

"If the object does not have a class attribute, it has an implicit class..."

which I take to mean that if an object does have a class attribute it does not also have an implicit class.

The behavior you noted below will apply to other types bearing implicit classes. For example:

> inherits(1.0, "numeric")
[1] TRUE
> inherits(structure(1.0, class="myclass"), "numeric")
[1] FALSE
> 

I think this is reasonable behavior. Consider the "Date" class, which stores values as "numeric":

> class(Sys.Date())
[1] "Date"
> inherits(Sys.Date(),"numeric")
[1] FALSE
> class(unclass(Sys.Date()))
[1] "numeric"
> Sys.Date()%%2
Error in Ops.Date(Sys.Date(), 2) : %% not defined for "Date" objects
> 

Letting the modulus operator (as one example) inherit the numeric class here could create problems.

Of course for classes that should inherit the implicit type, it can be explicitly added to the end of the class() vector by its constructor.

HTH,

Chuck



> On Mar 25, 2019, at 8:27 PM, Abs Spurdle <spurdle.a at gmail.com> wrote:
> 
>> I have noticed a discrepancy between is.list() and is(x, ?list?)
> 
> There's a similar problem with inherits().
> 
> On R 3.5.3:
> 
>> f = function () 1
>> class (f) = "f"
> 
>> is.function (f)
> [1] TRUE
>> inherits (f, "function")
> [1] FALSE
> 
> I didn't check what happens with:
>> class (f) = c ("f", "function")
> 
> However, they should have the same result, regardless.
> 
>> Is this discrepancy intentional?
> 
> I hope not.
> 
> 	[[alternative HTML version deleted]]
> 


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Tue Mar 26 18:51:40 2019
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Tue, 26 Mar 2019 17:51:40 +0000
Subject: [Rd] Discrepancy between is.list() and is(x, "list")
In-Reply-To: <EB8494AA-8DAA-4B9A-B636-7E979251EF0C@ucsd.edu>
References: <CAB8pepyU2qbU7fd1J9J6kyr_657PHFYHoJV6fnvNiHqqjq-24w@mail.gmail.com>
 <EB8494AA-8DAA-4B9A-B636-7E979251EF0C@ucsd.edu>
Message-ID: <c30f3775-d8ec-b1b6-569d-ec897f082a97@sapo.pt>

Hello,

Here is another example.

df1 <- data.frame(a = 1:3, b = 4:6)

inherits(df1, "data.frame")
#[1] TRUE
class(df1)
#[1] "data.frame"

inherits(df1, "list")
#[1] FALSE


This is documented behavior, the help page ?inherits says

The function class prints the vector of names of classes an object 
inherits from.


So far, so good. But now comes the part I don't like.

is.list(df1)
#[1] TRUE


Strictly speaking this is not unexpected behavior (because it's 
documented) but isn't it *inconsistent* behavior?


Rui Barradas

?s 16:30 de 26/03/2019, Berry, Charles escreveu:
> In the case of inherits (at least) this seems intended.
> 
> The help page says:
> 
> "If the object does not have a class attribute, it has an implicit class..."
> 
> which I take to mean that if an object does have a class attribute it does not also have an implicit class.
> 
> The behavior you noted below will apply to other types bearing implicit classes. For example:
> 
>> inherits(1.0, "numeric")
> [1] TRUE
>> inherits(structure(1.0, class="myclass"), "numeric")
> [1] FALSE
>>
> 
> I think this is reasonable behavior. Consider the "Date" class, which stores values as "numeric":
> 
>> class(Sys.Date())
> [1] "Date"
>> inherits(Sys.Date(),"numeric")
> [1] FALSE
>> class(unclass(Sys.Date()))
> [1] "numeric"
>> Sys.Date()%%2
> Error in Ops.Date(Sys.Date(), 2) : %% not defined for "Date" objects
>>
> 
> Letting the modulus operator (as one example) inherit the numeric class here could create problems.
> 
> Of course for classes that should inherit the implicit type, it can be explicitly added to the end of the class() vector by its constructor.
> 
> HTH,
> 
> Chuck
> 
> 
> 
>> On Mar 25, 2019, at 8:27 PM, Abs Spurdle <spurdle.a at gmail.com> wrote:
>>
>>> I have noticed a discrepancy between is.list() and is(x, ?list?)
>>
>> There's a similar problem with inherits().
>>
>> On R 3.5.3:
>>
>>> f = function () 1
>>> class (f) = "f"
>>
>>> is.function (f)
>> [1] TRUE
>>> inherits (f, "function")
>> [1] FALSE
>>
>> I didn't check what happens with:
>>> class (f) = c ("f", "function")
>>
>> However, they should have the same result, regardless.
>>
>>> Is this discrepancy intentional?
>>
>> I hope not.
>>
>> 	[[alternative HTML version deleted]]
>>
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From dev@kurt @end|ng |rom v@nd|jck-|@ur|j@@en@be  Tue Mar 26 19:52:29 2019
From: dev@kurt @end|ng |rom v@nd|jck-|@ur|j@@en@be (Kurt Van Dijck)
Date: Tue, 26 Mar 2019 19:52:29 +0100
Subject: [Rd] [PATCH 1/2] readtable: add hook for type conversions per
 column
In-Reply-To: <1553274983-15970-1-git-send-email-dev.kurt@vandijck-laurijssen.be>
References: <1553274983-15970-1-git-send-email-dev.kurt@vandijck-laurijssen.be>
Message-ID: <20190326185229.GA26161@x1.vandijck-laurijssen.be>

Hello,

I want to find out if this patch is ok or not, and if not, what should
change.

Kind regards,
Kurt


From |@wrence@m|ch@e| @end|ng |rom gene@com  Tue Mar 26 20:48:12 2019
From: |@wrence@m|ch@e| @end|ng |rom gene@com (Michael Lawrence)
Date: Tue, 26 Mar 2019 12:48:12 -0700
Subject: [Rd] [PATCH 1/2] readtable: add hook for type conversions per
 column
In-Reply-To: <20190326185229.GA26161@x1.vandijck-laurijssen.be>
References: <1553274983-15970-1-git-send-email-dev.kurt@vandijck-laurijssen.be>
 <20190326185229.GA26161@x1.vandijck-laurijssen.be>
Message-ID: <CAOQ5NyenGa23Nreqhmp-==9z5NXjEQ4LD99URC3BkqAeKHadnQ@mail.gmail.com>

Please file a bug on bugzilla so we can discuss this further.

On Tue, Mar 26, 2019 at 11:53 AM Kurt Van Dijck <
dev.kurt at vandijck-laurijssen.be> wrote:

> Hello,
>
> I want to find out if this patch is ok or not, and if not, what should
> change.
>
> Kind regards,
> Kurt
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From dev@kurt @end|ng |rom v@nd|jck-|@ur|j@@en@be  Tue Mar 26 21:20:07 2019
From: dev@kurt @end|ng |rom v@nd|jck-|@ur|j@@en@be (Kurt Van Dijck)
Date: Tue, 26 Mar 2019 21:20:07 +0100
Subject: [Rd] [PATCH 1/2] readtable: add hook for type conversions per
 column
In-Reply-To: <CAOQ5NyenGa23Nreqhmp-==9z5NXjEQ4LD99URC3BkqAeKHadnQ@mail.gmail.com>
References: <1553274983-15970-1-git-send-email-dev.kurt@vandijck-laurijssen.be>
 <20190326185229.GA26161@x1.vandijck-laurijssen.be>
 <CAOQ5NyenGa23Nreqhmp-==9z5NXjEQ4LD99URC3BkqAeKHadnQ@mail.gmail.com>
Message-ID: <20190326202007.GA29643@x1.vandijck-laurijssen.be>

On di, 26 mrt 2019 12:48:12 -0700, Michael Lawrence wrote:
>    Please file a bug on bugzilla so we can discuss this further.

All fine.
I didn't find a way to create an account on bugs.r-project.org.
Did I just not see it? or do I need administrator assistance?

Kind regards,
Kurt


From bbo|ker @end|ng |rom gm@||@com  Tue Mar 26 21:26:12 2019
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Tue, 26 Mar 2019 16:26:12 -0400
Subject: [Rd] [PATCH 1/2] readtable: add hook for type conversions per
 column
In-Reply-To: <20190326202007.GA29643@x1.vandijck-laurijssen.be>
References: <1553274983-15970-1-git-send-email-dev.kurt@vandijck-laurijssen.be>
 <20190326185229.GA26161@x1.vandijck-laurijssen.be>
 <CAOQ5NyenGa23Nreqhmp-==9z5NXjEQ4LD99URC3BkqAeKHadnQ@mail.gmail.com>
 <20190326202007.GA29643@x1.vandijck-laurijssen.be>
Message-ID: <658850e1-f344-2674-cc7c-c4b5d539eec5@gmail.com>


  You need admin assistance, someone will probably see your request here
and fulfill it.

  It might be helpful to read this question/answer on StackOverflow
discussing the context of proposing patches to base R functionality ...

https://stackoverflow.com/questions/8065835/proposing-feature-requests-to-the-r-core-team

  cheers
    Ben Bolker


On 2019-03-26 4:20 p.m., Kurt Van Dijck wrote:
> On di, 26 mrt 2019 12:48:12 -0700, Michael Lawrence wrote:
>>    Please file a bug on bugzilla so we can discuss this further.
> 
> All fine.
> I didn't find a way to create an account on bugs.r-project.org.
> Did I just not see it? or do I need administrator assistance?
> 
> Kind regards,
> Kurt
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From @purd|e@@ @end|ng |rom gm@||@com  Tue Mar 26 22:07:52 2019
From: @purd|e@@ @end|ng |rom gm@||@com (Abs Spurdle)
Date: Wed, 27 Mar 2019 10:07:52 +1300
Subject: [Rd] Discrepancy between is.list() and is(x, "list")
In-Reply-To: <EB8494AA-8DAA-4B9A-B636-7E979251EF0C@ucsd.edu>
References: <CAB8pepyU2qbU7fd1J9J6kyr_657PHFYHoJV6fnvNiHqqjq-24w@mail.gmail.com>
 <EB8494AA-8DAA-4B9A-B636-7E979251EF0C@ucsd.edu>
Message-ID: <CAB8pepxp9TL18vvHajvSJBXhJY=E13ZWUjebxv6OdgPXcWVPTQ@mail.gmail.com>

If I can merge this thread with the one I started yesterday...

> "If the object does not have a class attribute, it has an implicit
class..."
> which I take to mean that if an object does have a class attribute it
does not also have an implicit class.
> I think this is reasonable behavior. Consider the "Date" class, which
stores values as "numeric":
> > class(Sys.Date())
> [1] "Date"
> > inherits(Sys.Date(),"numeric")
> [1] FALSE
> > class(unclass(Sys.Date()))
> [1] "numeric"
> > Sys.Date()%%2
> Error in Ops.Date(Sys.Date(), 2) : %% not defined for "Date" objects
> Letting the modulus operator (as one example) inherit the numeric class
here could create problems.

I disagree.
A date object should probably extend integers rather than numerics, in the
first place.
However, if it extends numeric, then it extends numeric, otherwise it's a
contradiction.
So, inherits(Sys.Date(),"numeric") should return true.

Modulo operators should be defined for both dates and numerics.
However, the application of modulo operators to dates, is perhaps unclear,
at least in the general case, anyway.

> so instead of hitting utils:::head.function, it hits utils:::head.default
> I also see this behavior at least as far aback as 3.5.1, so its not new
to 3.5.3.

These seem like significant design flaws.
Implicit classes or whatever you want to call them, are clearly part of the
class hierarchy.

They should be included in inherits(), is() and standard method dispatch,
regardless of whether they are part of the class vector or not.

Also, is this something that was introduced in R 3.5.1?
The only thing worse than a design flaw is a design flaw that isn't
backward compatible.

	[[alternative HTML version deleted]]


From wdun|@p @end|ng |rom t|bco@com  Tue Mar 26 23:00:29 2019
From: wdun|@p @end|ng |rom t|bco@com (William Dunlap)
Date: Tue, 26 Mar 2019 15:00:29 -0700
Subject: [Rd] Discrepancy between is.list() and is(x, "list")
In-Reply-To: <CAB8pepxp9TL18vvHajvSJBXhJY=E13ZWUjebxv6OdgPXcWVPTQ@mail.gmail.com>
References: <CAB8pepyU2qbU7fd1J9J6kyr_657PHFYHoJV6fnvNiHqqjq-24w@mail.gmail.com>
 <EB8494AA-8DAA-4B9A-B636-7E979251EF0C@ucsd.edu>
 <CAB8pepxp9TL18vvHajvSJBXhJY=E13ZWUjebxv6OdgPXcWVPTQ@mail.gmail.com>
Message-ID: <CAF8bMcZD03odP0yriDjoxYNFzfU3Js_bF6OosavyRxtVY6S44g@mail.gmail.com>

I think this goes back to SV4 (c. late 1990's).  The is.<type>  functions
are much older (c. mid 1970's) , from before any class system was in S.
is() and inherits() were introduced with the S4 class system and were meant
to escape from the prison made by ancient design choices.

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Tue, Mar 26, 2019 at 2:11 PM Abs Spurdle <spurdle.a at gmail.com> wrote:

> If I can merge this thread with the one I started yesterday...
>
> > "If the object does not have a class attribute, it has an implicit
> class..."
> > which I take to mean that if an object does have a class attribute it
> does not also have an implicit class.
> > I think this is reasonable behavior. Consider the "Date" class, which
> stores values as "numeric":
> > > class(Sys.Date())
> > [1] "Date"
> > > inherits(Sys.Date(),"numeric")
> > [1] FALSE
> > > class(unclass(Sys.Date()))
> > [1] "numeric"
> > > Sys.Date()%%2
> > Error in Ops.Date(Sys.Date(), 2) : %% not defined for "Date" objects
> > Letting the modulus operator (as one example) inherit the numeric class
> here could create problems.
>
> I disagree.
> A date object should probably extend integers rather than numerics, in the
> first place.
> However, if it extends numeric, then it extends numeric, otherwise it's a
> contradiction.
> So, inherits(Sys.Date(),"numeric") should return true.
>
> Modulo operators should be defined for both dates and numerics.
> However, the application of modulo operators to dates, is perhaps unclear,
> at least in the general case, anyway.
>
> > so instead of hitting utils:::head.function, it hits utils:::head.default
> > I also see this behavior at least as far aback as 3.5.1, so its not new
> to 3.5.3.
>
> These seem like significant design flaws.
> Implicit classes or whatever you want to call them, are clearly part of the
> class hierarchy.
>
> They should be included in inherits(), is() and standard method dispatch,
> regardless of whether they are part of the class vector or not.
>
> Also, is this something that was introduced in R 3.5.1?
> The only thing worse than a design flaw is a design flaw that isn't
> backward compatible.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From g@bembecker @end|ng |rom gm@||@com  Tue Mar 26 23:01:01 2019
From: g@bembecker @end|ng |rom gm@||@com (Gabriel Becker)
Date: Tue, 26 Mar 2019 15:01:01 -0700
Subject: [Rd] Discrepancy between is.list() and is(x, "list")
In-Reply-To: <CAB8pepxp9TL18vvHajvSJBXhJY=E13ZWUjebxv6OdgPXcWVPTQ@mail.gmail.com>
References: <CAB8pepyU2qbU7fd1J9J6kyr_657PHFYHoJV6fnvNiHqqjq-24w@mail.gmail.com>
 <EB8494AA-8DAA-4B9A-B636-7E979251EF0C@ucsd.edu>
 <CAB8pepxp9TL18vvHajvSJBXhJY=E13ZWUjebxv6OdgPXcWVPTQ@mail.gmail.com>
Message-ID: <CAD4oTHFMC=9__Qn=4CVjotHnVDoZii1KBx_ckbZ=74ATgtZYcQ@mail.gmail.com>

Hi Abs,

Lets try to remain civil even when disagreeing about major design
philosophies, ok?

On Tue, Mar 26, 2019 at 2:08 PM Abs Spurdle <spurdle.a at gmail.com> wrote:

> If I can merge this thread with the one I started yesterday...
>
> > "If the object does not have a class attribute, it has an implicit
> class..."
> > which I take to mean that if an object does have a class attribute it
> does not also have an implicit class.
> > I think this is reasonable behavior. Consider the "Date" class, which
> stores values as "numeric":
> > > class(Sys.Date())
> > [1] "Date"
> > > inherits(Sys.Date(),"numeric")
> > [1] FALSE
> > > class(unclass(Sys.Date()))
> > [1] "numeric"
> > > Sys.Date()%%2
> > Error in Ops.Date(Sys.Date(), 2) : %% not defined for "Date" objects
> > Letting the modulus operator (as one example) inherit the numeric class
> here could create problems.
>
> I disagree.
> A date object should probably extend integers rather than numerics, in the
> first place.
> However, if it extends numeric, then it extends numeric, otherwise it's a
> contradiction.
> So, inherits(Sys.Date(),"numeric") should return true.
>

You seem to be approaching the S3 "class"/dispatch system as something that
it is not: a formal class system. S3 dispatch is based, essentially, on
labeling, via the class attribute (or, if you like, the value returned by
class(), this is basically the same with some fiddly bits for S4, judging
by a quick glance at src/main/attrib.c:do_class ). If it is not in the set
of class labels, S3 dispatch *will not* treat it as that class. This is by
design. An S3 object's "class" also has no* bearing on the contents of the
object (* this isn't true for some built in atomic vector classes, as I
Recall, but it is for all user defined classes).


> mylist = list("hi", "what?")

> class(mylist) = "Date"

> mylist

[1] NA NA

*Warning messages:*

*1: In as.POSIXlt.Date(x) : NAs introduced by coercion*


*2: In as.POSIXlt.Date(x) : NAs introduced by coercion*


See? the print method looks at the class attribute of mylist, and says "Oh,
this is a Date, I'll use print.Date" and then it craps out (with NAs
instead of errors, but still) because the data contained within the object
isn't really a "Date". But there is no definition of what it means to be an
S3 "Date" object anywhere, other than that it has the Date class attribute.

All of the above is *by design*. You're welcome to not like the design. I
prefer the formalism of S4, myself, and there are various things I don't
love about how S3 works - including some but not all of the things that
have come up here. That said, the behaviors are not bugs, and any of the
changes you seem to be advocating for would not only break lots of code,
but would also represent fundamental changes to the design of a core aspect
of the R language.

As for doing %% on Dates, I seriously doubt anyone who is operating on Date
objects and thinking about times and dates is looking to do a modulo
operation in number of Days since Jan 1st 1970, which is what that
operation would do. Better to have that fail and if that really, for sure
is what the user actually wants to do, they can uncalss it or otherwise
convert it to a numeridc first.



> Modulo operators should be defined for both dates and numerics.
> However, the application of modulo operators to dates, is perhaps unclear,
> at least in the general case, anyway.
>
> > so instead of hitting utils:::head.function, it hits
> utils:::head.default
> > I also see this behavior at least as far aback as 3.5.1, so its not new
> to 3.5.3.
>

> These seem like significant design flaws.
> Implicit classes or whatever you want to call them, are clearly part of
> the class hierarchy.
>

I'm not sure what is clear about that, or what class hierarchy you're
talking about in the S3 case. Remember that S3 classes *have no formal
definitions at all*. Thats why I rarely if ever use them in software that I
write. But it's an important point here. What something would becomes if
you unclass()ed it has no bearing on what S3 dispatch will do.


>
> They should be included in inherits(), is() and standard method dispatch,
> regardless of whether they are part of the class vector or not.
>

Dispatch is ONLY done on the class vector for S3 (AFAIK). Only. That is how
S3 dispatch is defined and designed.

>
> Also, is this something that was introduced in R 3.5.1?
> The only thing worse than a design flaw is a design flaw that isn't
> backward compatible.
>

No that is just the non-devel R I had handy, and you had seemed to be
presenting it as something new in 3.5.3. I would be surprised if the
behavior doesn't go all the way back to whenever head.function was added.
Before that head() on a function (likely) would have failed just like it
still does on your reclassed function. Because, again, this is how S3 is
supposed to behave when you give it the inputs you are. I fyou want your f
class to hit function S3 methods, you need to do

class(myfun) <- c("f", "function")

Then everything will work.

Best,
~G

	[[alternative HTML version deleted]]


From ru@@e||-|enth @end|ng |rom u|ow@@edu  Wed Mar 27 01:06:08 2019
From: ru@@e||-|enth @end|ng |rom u|ow@@edu (Lenth, Russell V)
Date: Wed, 27 Mar 2019 00:06:08 +0000
Subject: [Rd] default for 'signif.stars'
Message-ID: <DM6PR04MB438095FB858DADCCAE2506A8F1580@DM6PR04MB4380.namprd04.prod.outlook.com>

Dear R-Devel,

As I am sure many of you know, a special issue of The American Statistician just came out, and its theme is the [mis]use of P values and the many common ways in which they are abused. The lead editorial in that issue mentions the 2014 ASA guidelines on P values, and goes one step further, by now recommending that the words "statistically significant" and related simplistic interpretations no longer be used. There is much discussion of the problems with drawing "bright lines" concerning P values.

This is the position of a US society, but my sense is that the statistical community worldwide is pretty much on the same page. 

Meanwhile, functions such as 'print.summary.lm' and 'print.anova' have an argument 'signif.stars' that really does involve drawing bright lines when it is set to TRUE. And the default setting for the "show.signif.stars" option is TRUE. Isn't it time to at least make "show.signif.stars" default to FALSE? And, indeed, to consider deprecating those 'signif.stars' options altogether?

Thanks

Russ

Russell V. Lenth? -? Professor Emeritus
Department of Statistics and Actuarial Science?? 
The University of Iowa ?-? Iowa City, IA 52242? USA?? 
Voice (319)335-0712 (Dept. office)? -? FAX (319)335-3017


From @purd|e@@ @end|ng |rom gm@||@com  Wed Mar 27 02:42:19 2019
From: @purd|e@@ @end|ng |rom gm@||@com (Abs Spurdle)
Date: Wed, 27 Mar 2019 14:42:19 +1300
Subject: [Rd] Discrepancy between is.list() and is(x, "list")
In-Reply-To: <CAD4oTHFMC=9__Qn=4CVjotHnVDoZii1KBx_ckbZ=74ATgtZYcQ@mail.gmail.com>
References: <CAB8pepyU2qbU7fd1J9J6kyr_657PHFYHoJV6fnvNiHqqjq-24w@mail.gmail.com>
 <EB8494AA-8DAA-4B9A-B636-7E979251EF0C@ucsd.edu>
 <CAB8pepxp9TL18vvHajvSJBXhJY=E13ZWUjebxv6OdgPXcWVPTQ@mail.gmail.com>
 <CAD4oTHFMC=9__Qn=4CVjotHnVDoZii1KBx_ckbZ=74ATgtZYcQ@mail.gmail.com>
Message-ID: <CAB8pepznVQ6jG2Lx4sJw3GS5xMS7u3jeVn3BxaR9e122NdV=uA@mail.gmail.com>

> you had seemed to be presenting it as something new in 3.5.3. I would be
surprised if the behavior doesn't go all the way back to whenever
head.function was added.

My bad.
I'm just surprised I've never noticed these problems before.

> S3 classes have no formal definitions at all
> I'm not sure what is clear about that, or what class hierarchy you're
talking about in the S3 case.

That's questionable.
One, because it depends on how you define formal definitions.
And two, because class definitions can exist outside the code itself.
e.g. As part of an object oriented model.
(Being "Object Oriented" is just as much about models as it is about
syntax).

Furthermore, when you change the class of a vector, list or function, much
of the original object's structure and behavior remains.
So, it has "Inherited" or "Extended", in my opinion.
Resulting in a class hierarchy.

> Dispatch is ONLY done on the class vector for S3 (AFAIK)

Incorrect.
We've already mentioned the example of head.function().
In general, this dispatch occurs without the presence of a class attribute.

> You seem to be approaching the S3 "class"/dispatch system as something
that it is not: a formal class system

If I can diverge...

Where did this term "Formal Class System" come from?
I've never seen it used anywhere else.
Is is specific to R?

	[[alternative HTML version deleted]]


From @purd|e@@ @end|ng |rom gm@||@com  Wed Mar 27 02:51:00 2019
From: @purd|e@@ @end|ng |rom gm@||@com (Abs Spurdle)
Date: Wed, 27 Mar 2019 14:51:00 +1300
Subject: [Rd] bugs in head() and tail()
In-Reply-To: <CAD4oTHFbbRs5GvhyR33+0mvXmsHFsBAK8hL_2CBDC_eeEA0e_w@mail.gmail.com>
References: <CAB8pepwajebtmzuGyMzd7ak_PhMakSwkXS-JEqV4VFW_2kh7sw@mail.gmail.com>
 <CAD4oTHFbbRs5GvhyR33+0mvXmsHFsBAK8hL_2CBDC_eeEA0e_w@mail.gmail.com>
Message-ID: <CAB8pepxwQmCbzeQZBuAiWxjSUxL_ZjOKEYozwi7WVY=Dd+kVwg@mail.gmail.com>

> so instead of hitting utils:::head.function, it hits
utils:::head.default, which uses [ on the argument, causing the error.

I've thought about this some more.
And I still think that this is a bug.

If a generic has a default method, then that default method should be
guaranteed to work.
Or at least, provide a useful error message, that makes it obvious to the
user, what he or she has done wrong.

In the case of head.default(), it assumes that the object is a vector, or
something similar.
This assumption is untrue.

>> Error in x[seq_len(n)] : object of type 'closure' is not subsettable

Resulting in the error above, which fails to recognize that the input was
unsuitable.

	[[alternative HTML version deleted]]


From g@bembecker @end|ng |rom gm@||@com  Wed Mar 27 04:46:21 2019
From: g@bembecker @end|ng |rom gm@||@com (Gabriel Becker)
Date: Tue, 26 Mar 2019 20:46:21 -0700
Subject: [Rd] Discrepancy between is.list() and is(x, "list")
In-Reply-To: <CAB8pepznVQ6jG2Lx4sJw3GS5xMS7u3jeVn3BxaR9e122NdV=uA@mail.gmail.com>
References: <CAB8pepyU2qbU7fd1J9J6kyr_657PHFYHoJV6fnvNiHqqjq-24w@mail.gmail.com>
 <EB8494AA-8DAA-4B9A-B636-7E979251EF0C@ucsd.edu>
 <CAB8pepxp9TL18vvHajvSJBXhJY=E13ZWUjebxv6OdgPXcWVPTQ@mail.gmail.com>
 <CAD4oTHFMC=9__Qn=4CVjotHnVDoZii1KBx_ckbZ=74ATgtZYcQ@mail.gmail.com>
 <CAB8pepznVQ6jG2Lx4sJw3GS5xMS7u3jeVn3BxaR9e122NdV=uA@mail.gmail.com>
Message-ID: <CAD4oTHE7gvHrB_WFinvvhTFpNrxyuMBqyjntB58-cu12KprwGA@mail.gmail.com>

Abs et al,

Ok, so I have just gone and re-read the docs again. My language was a more
absolute than it should have been; *however*, I was still correct for the
cases under discussion.

From ?UseMethod (emphasis mine)

An R object is a data object which has a ?class? attribute (and

     this can be tested by ?is.object?).  A class attribute is a

     character vector giving the names of the classes from which the

     object _inherits_.  *If the object does not have a class attribute,*

*     it has an implicit class.*  Matrices and arrays have class

     ?"matrix"? or?"array"? followed by the class of the underlying

     vector.  Most vectors have class the result of ?mode(x)?, except

     that integer vectors have class ?c("integer", "numeric")? and real

     vectors have class ?c("double", "numeric")?.


So, there are implicit classes, but *only when the data object is NOT an "R
object" (ie when it does NOT have a class attribute).* So, what I said was
not correct for certain built in classes: matrices, arrays, and some
atomic vectors but IS true of any object you assign a class attribute to
(e.g. by doing class<-() ) When your code classes an object, you have to
give the full desired vector of inheritence in its class attribute.
Anything you leave out just won't be there.

This is the case with your "f" classed object, so it *does not have an
implicit class.*  That is how S3 is designed and intended to work.


On Tue, Mar 26, 2019 at 6:42 PM Abs Spurdle <spurdle.a at gmail.com> wrote:

> > you had seemed to be presenting it as something new in 3.5.3. I would be
> surprised if the behavior doesn't go all the way back to whenever
> head.function was added.
>
> My bad.
> I'm just surprised I've never noticed these problems before.
>
> > S3 classes have no formal definitions at all
> > I'm not sure what is clear about that, or what class hierarchy you're
> talking about in the S3 case.
>
> That's questionable.
> One, because it depends on how you define formal definitions.
>

I mean, I guess, in the sense that that is true of any argument anyone ever
makes that uses a term.

For the record here, I'm using "Formal class definition" as an explicit
declaration of how valid objects of a particular class are structured, what
data they contain, and how they behave.

S3 does not have that. IT has only *implicit* class structure/content
definitions based on what methods for that class look for in objects passed
to them. There is no where you can look to figure out what it "means to be
a ____ class object" in the S3 sense, beyond a nebulous set of methods
which look for various things within an object that supposedly is of that
class.

> x = "not a date"

> class(x) = "Date"

> is(x, "Date")

[1] TRUE


> y = Sys.Date()

> y

[1] "2019-03-26"

> attr(y, "class")

[1] "Date"

> is.object(y)

[1] TRUE


> class(y) = "NonDate"

> y

[1] 17981

attr(,"class")

[1] "NonDate"

> is(y, "Date")

[1] FALSE

> inherits(y, "Date")

[1] FALSE



> And two, because class definitions can exist outside the code itself.
> e.g. As part of an object oriented model.
> (Being "Object Oriented" is just as much about models as it is about
> syntax).
>

Again, I suppose? In fact they have to S3, as I just pointed out above.
But, I really don't see how this is relevant. I doesn't matter what you
have written down on paper, or in documentation, or in your head as a model
about how your S3 classes relate to eachother, because the S3 dispatch
machinery can't see into any of those places. It can only go by what you
put in the class vector, and that is all it is going to go by (for objects
with a class attribute, ie for any "classes" your code defines)


>
> Furthermore, when you change the class of a vector, list or function, much
> of the original object's structure and behavior remains.
>

Conjecture here, since I don't know what exact behaviors you're referring
to, but if they are ostensibly S3 based (ie they are invoved via an S3
generic), its probably becuse they hit *.default methods which call down to
code internal C which operates based on SEXP type, ie they "escape S3
dispatch" in a sense.


> So, it has "Inherited" or "Extended", in my opinion.
>
Resulting in a class hierarchy.
>

You're welcome to have that opinion, but simply put that is now how
inheritance *for the purposes of S3 dispatch* is defined in S3.


>
> > Dispatch is ONLY done on the class vector for S3 (AFAIK)
>

> Incorrect.
> We've already mentioned the example of head.function().
> In general, this dispatch occurs without the presence of a class attribute.
>

I said the class vector, as in what is returned by class().


 > class(rnorm)

[1] "function"

> attr(rnorm, "class")

NULL


I apologize for not more carefully delineating those two things.

That IS consistent with head hitting head.function for a function but
head.default for a "classed function", because according to the definition
of how S3 behaves, your "classed function" doesn't have any implicit
classes, and you didn't declare that it inherited from the function class.

 The portion that is incorrect with what I said is that if the data object
is NOT an R object, (ie it is an unclassed atomic vector or other built in
type - is.object() returns FALSE ) it MAY have an implicit class which will
affect S3 dispatch. But your "f" classed object does not.


> You seem to be approaching the S3 "class"/dispatch system as something
> that it is not: a formal class system
>
> If I can diverge...
>
> Where did this term "Formal Class System" come from?
> I've never seen it used anywhere else.
> Is is specific to R?
>

No. I'm not using it as a term of art at all, really. I'm using it to mean
explicit, non-implicit, that classes declare formal required internal
structures, etc.

Best,
~G

	[[alternative HTML version deleted]]


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Wed Mar 27 09:52:57 2019
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Wed, 27 Mar 2019 09:52:57 +0100
Subject: [Rd] [PATCH 1/2] readtable: add hook for type conversions per
 column
In-Reply-To: <20190326202007.GA29643@x1.vandijck-laurijssen.be>
References: <1553274983-15970-1-git-send-email-dev.kurt@vandijck-laurijssen.be>
 <20190326185229.GA26161@x1.vandijck-laurijssen.be>
 <CAOQ5NyenGa23Nreqhmp-==9z5NXjEQ4LD99URC3BkqAeKHadnQ@mail.gmail.com>
 <20190326202007.GA29643@x1.vandijck-laurijssen.be>
Message-ID: <23707.14825.998716.854172@stat.math.ethz.ch>

>>>>> Kurt Van Dijck 
>>>>>     on Tue, 26 Mar 2019 21:20:07 +0100 writes:

    > On di, 26 mrt 2019 12:48:12 -0700, Michael Lawrence wrote:
    >> Please file a bug on bugzilla so we can discuss this
    >> further.

    > All fine.  I didn't find a way to create an account on
    > bugs.r-project.org.  Did I just not see it? or do I need
    > administrator assistance?

    > Kind regards, Kurt

--> https://www.r-project.org/bugs.html

Yes, there's some effort involved - for logistic reasons,
but I now find it's a also good thing that you have to read and
understand and then even e-talk to a human in the process.

Martin


From h@w|ckh@m @end|ng |rom gm@||@com  Wed Mar 27 12:38:12 2019
From: h@w|ckh@m @end|ng |rom gm@||@com (Hadley Wickham)
Date: Wed, 27 Mar 2019 06:38:12 -0500
Subject: [Rd] Discrepancy between is.list() and is(x, "list")
In-Reply-To: <CAB8pepyU2qbU7fd1J9J6kyr_657PHFYHoJV6fnvNiHqqjq-24w@mail.gmail.com>
References: <CAB8pepyU2qbU7fd1J9J6kyr_657PHFYHoJV6fnvNiHqqjq-24w@mail.gmail.com>
Message-ID: <CABdHhvGNoPPbzCquiUJo+Q2xgwaqpEoy7q_t_ikAp38hY1zw-Q@mail.gmail.com>

I would recommend reading https://adv-r.hadley.nz/base-types.html and
https://adv-r.hadley.nz/s3.html. Understanding the distinction between
base types and S3 classes is very important to make this sort of
question precise, and in my experience, you'll find R easier to
understand if you carefully distinguish between them. (And hence you
shouldn't expect is.x(), inherits(, "x") and is(, "x") to always
return the same results)

Also note that many of is.*() functions are not testing for types or
classes, but instead often have more complex semantics. For example,
is.vector() tests for objects with an underlying base vector type that
have no attributes (apart from names). is.numeric() tests for objects
with base type integer or double, and that have the same algebraic
properties as numbers.

Hadley

On Mon, Mar 25, 2019 at 10:28 PM Abs Spurdle <spurdle.a at gmail.com> wrote:
>
> > I have noticed a discrepancy between is.list() and is(x, ?list?)
>
> There's a similar problem with inherits().
>
> On R 3.5.3:
>
> > f = function () 1
> > class (f) = "f"
>
> > is.function (f)
> [1] TRUE
> > inherits (f, "function")
> [1] FALSE
>
> I didn't check what happens with:
> > class (f) = c ("f", "function")
>
> However, they should have the same result, regardless.
>
> > Is this discrepancy intentional?
>
> I hope not.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel



-- 
http://hadley.nz


From tom@@@k@||ber@ @end|ng |rom gm@||@com  Wed Mar 27 20:52:21 2019
From: tom@@@k@||ber@ @end|ng |rom gm@||@com (Tomas Kalibera)
Date: Wed, 27 Mar 2019 20:52:21 +0100
Subject: [Rd] 
 SUGGESTION: Proposal to mitigate problem with stray processes
 left behind by parallel::makeCluster()
In-Reply-To: <CAFDcVCQ5H_5EDrEKy+ZGaBHQNSn0saHbg2VtDVc7j39GoRNnQA@mail.gmail.com>
References: <CAFDcVCQ5H_5EDrEKy+ZGaBHQNSn0saHbg2VtDVc7j39GoRNnQA@mail.gmail.com>
Message-ID: <53568475-c7c2-2814-5760-eab4c202863c@gmail.com>


The problem causing the stray worker processes when the master fails to 
open a server socket to listen to connections from workers is not 
related to timeout in socketConnection(), because socketConnection() 
will fail right away. It is caused by a bug in checking the setup 
timeout (PR 17391).

Fixed in 76275.

Best
Tomas

On 3/18/19 2:23 AM, Henrik Bengtsson wrote:
> (Bcc: CRAN)
>
> This is a proposal helping CRAN and alike as well as individual
> developers to avoid stray R processes being left behind that might be
> produced when an example or a package test fails to set up a
> parallel::makeCluster().
>
>
> ISSUE
>
> If a package test sets up a PSOCK cluster and then the master process
> dies for one reason or the other, the PSOCK worker processes will
> remain running for 30 days ('timeout') until they timeout and
> terminate that way.  When this happens on CRAN servers, where many
> packages are checked all the time, this will result in a lot of stray
> R processes.
>
> Here is an example illustrating how R leaves behind stray R processes
> if fails to establish a connection to one or more background R
> processes launched by 'parallel::makeCluster()'.  First, let's make
> sure there are no other R processes running:
>
>    $ ps aux | grep -E "exec[/]R"
>
> Then, lets create a PSOCK cluster for which connection will fail
> (because port 80 is reserved):
>
>    $ Rscript -e 'parallel::makeCluster(1L, port=80)'
>    Error in socketConnection("localhost", port = port, server = TRUE,
> blocking = TRUE,  :
>      cannot open the connection
>    Calls: <Anonymous> ... makePSOCKcluster -> newPSOCKnode -> socketConnection
>    In addition: Warning message:
>    In socketConnection("localhost", port = port, server = TRUE,
> blocking = TRUE,  :
>      port 80 cannot be opened
>
> The launched R worker is still running:
>
>    $ ps aux | grep -E "exec[/]R"
>    hb       20778 37.0  0.4 283092 70624 pts/0    S    17:50   0:00
> /usr/lib/R/bin/exec/R --slave --no-restore -e parallel:::.slaveRSOCK()
> --args MASTER=localhost PORT=80 OUT=/dev/null SETUPTIMEOUT=120
> TIMEOUT=2 592000 XDR=TRUE
>
> This process will keep running for 'TIMEOUT=2592000' seconds (= 30
> days).  The reason for this is that it is currently in the state where
> it attempts to set up a connection to the main R process:
>
>    > parallel:::.slaveRSOCK
>    function ()
>    {
>        makeSOCKmaster <- function(master, port, setup_timeout, timeout,
>            useXDR) {
>     ...
>            repeat {
>                con <- tryCatch({
>                    socketConnection(master, port = port, blocking = TRUE,
>                      open = "a+b", timeout = timeout)
>                }, error = identity)
>        ...
>    }
>
> In other words, it is stuck in 'socketConnection()' and it won't time
> out until 'timeout' seconds.
>
>
> SUGGESTION
>
> To mitigate the problem with above stray processes from running 'R CMD
> check', we could shorten the 'timeout' which is currently hardcoded to
> 30 days (src/library/parallel/R/snow.R).  By making it possible to
> control the default via environment variables, e.g.
>
>    setup_timeout = as.numeric(Sys.getenv("R_PARALLEL_SETUP_TIMEOUT", 60
> * 2)),      # 2 minutes
>    timeout = as.numeric(Sys.getenv("R_PARALLEL_SETUP_TIMEOUT", 60 * 60
> * 24 * 30)), # 30 days
>
> it would be straightforward to adjust `R CMD check` to use, say,
>
>    R_PARALLEL_SETUP_TIMEOUT=60
>
> by default.  This would cause any stray processes to time out after 60
> seconds (instead of 30 days as now).
>
> /Henrik
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From dev@kurt @end|ng |rom v@nd|jck-|@ur|j@@en@be  Wed Mar 27 21:18:34 2019
From: dev@kurt @end|ng |rom v@nd|jck-|@ur|j@@en@be (Kurt Van Dijck)
Date: Wed, 27 Mar 2019 21:18:34 +0100
Subject: [Rd] [RFC] readtable enhancement
In-Reply-To: <658850e1-f344-2674-cc7c-c4b5d539eec5@gmail.com>
References: <1553274983-15970-1-git-send-email-dev.kurt@vandijck-laurijssen.be>
 <20190326185229.GA26161@x1.vandijck-laurijssen.be>
 <CAOQ5NyenGa23Nreqhmp-==9z5NXjEQ4LD99URC3BkqAeKHadnQ@mail.gmail.com>
 <20190326202007.GA29643@x1.vandijck-laurijssen.be>
 <658850e1-f344-2674-cc7c-c4b5d539eec5@gmail.com>
Message-ID: <20190327201834.GB2780@x1.vandijck-laurijssen.be>

Thank you for your answers.
I rather do not file a new bug, since what I coded isn't really a bug.

The problem I (my colleagues) have today is very stupid:
We read .csv files with a lot of columns, of which most contain
date-time stamps, coded in DD/MM/YYYY HH:MM.
This is not exotic, but the base library's readtable (and derivatives)
only accept date-times in a limited number of possible formats (which I
understand very well).

We could specify a format in a rather complicated format, for each
column individually, but this syntax is rather difficult to maintain.

My solution to this specific problem became trivial, yet generic
extension to read.table.
Rather than relying on the built-in type detection, I added a parameter
to a function that will be called for each to-be-type-probed column so I
can overrule the built-in limited default.
If nothing returns from the function, the built-in default is still
used.

This way, I could construct a type-probing function that is
straight-forward, not hard to code, and makes reading my .csv files
acceptible in terms of code (read.table parameters).

I'm sure I'm not the only one dealing with such needs, escpecially
date-time formats exist in enormous amounts, but I want to stress here
that my approach is agnostic to my specific problem.

For those asking to 'show me the code', I redirect to my 2nd patch,
where the tests have been extended with my specific problem.

What are your opinions about this?

Kind regards,
Kurt


From |@wrence@m|ch@e| @end|ng |rom gene@com  Wed Mar 27 22:28:25 2019
From: |@wrence@m|ch@e| @end|ng |rom gene@com (Michael Lawrence)
Date: Wed, 27 Mar 2019 14:28:25 -0700
Subject: [Rd] [RFC] readtable enhancement
In-Reply-To: <20190327201834.GB2780@x1.vandijck-laurijssen.be>
References: <1553274983-15970-1-git-send-email-dev.kurt@vandijck-laurijssen.be>
 <20190326185229.GA26161@x1.vandijck-laurijssen.be>
 <CAOQ5NyenGa23Nreqhmp-==9z5NXjEQ4LD99URC3BkqAeKHadnQ@mail.gmail.com>
 <20190326202007.GA29643@x1.vandijck-laurijssen.be>
 <658850e1-f344-2674-cc7c-c4b5d539eec5@gmail.com>
 <20190327201834.GB2780@x1.vandijck-laurijssen.be>
Message-ID: <CAOQ5NyeXLud_E_V0f01rY995ZkLfKeq-7wdtZoz1VaaVH=6BBw@mail.gmail.com>

This has some nice properties:

1) It self-documents the input expectations in a similar manner to
colClasses.
2) The implementation could eventually "push down" the coercion, e.g.,
calling it on each chunk of an iterative read operation.

The implementation needs work though, and I'm not convinced that coercion
failures should fallback gracefully to the default.

Feature requests fall under a "bug" in bugzilla terminology, so please
submit this there. I think I've made you an account.

Thanks,
Michael

On Wed, Mar 27, 2019 at 1:19 PM Kurt Van Dijck <
dev.kurt at vandijck-laurijssen.be> wrote:

> Thank you for your answers.
> I rather do not file a new bug, since what I coded isn't really a bug.
>
> The problem I (my colleagues) have today is very stupid:
> We read .csv files with a lot of columns, of which most contain
> date-time stamps, coded in DD/MM/YYYY HH:MM.
> This is not exotic, but the base library's readtable (and derivatives)
> only accept date-times in a limited number of possible formats (which I
> understand very well).
>
> We could specify a format in a rather complicated format, for each
> column individually, but this syntax is rather difficult to maintain.
>
> My solution to this specific problem became trivial, yet generic
> extension to read.table.
> Rather than relying on the built-in type detection, I added a parameter
> to a function that will be called for each to-be-type-probed column so I
> can overrule the built-in limited default.
> If nothing returns from the function, the built-in default is still
> used.
>
> This way, I could construct a type-probing function that is
> straight-forward, not hard to code, and makes reading my .csv files
> acceptible in terms of code (read.table parameters).
>
> I'm sure I'm not the only one dealing with such needs, escpecially
> date-time formats exist in enormous amounts, but I want to stress here
> that my approach is agnostic to my specific problem.
>
> For those asking to 'show me the code', I redirect to my 2nd patch,
> where the tests have been extended with my specific problem.
>
> What are your opinions about this?
>
> Kind regards,
> Kurt
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Wed Mar 27 22:33:55 2019
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Wed, 27 Mar 2019 17:33:55 -0400
Subject: [Rd] [RFC] readtable enhancement
In-Reply-To: <CAOQ5NyeXLud_E_V0f01rY995ZkLfKeq-7wdtZoz1VaaVH=6BBw@mail.gmail.com>
References: <1553274983-15970-1-git-send-email-dev.kurt@vandijck-laurijssen.be>
 <20190326185229.GA26161@x1.vandijck-laurijssen.be>
 <CAOQ5NyenGa23Nreqhmp-==9z5NXjEQ4LD99URC3BkqAeKHadnQ@mail.gmail.com>
 <20190326202007.GA29643@x1.vandijck-laurijssen.be>
 <658850e1-f344-2674-cc7c-c4b5d539eec5@gmail.com>
 <20190327201834.GB2780@x1.vandijck-laurijssen.be>
 <CAOQ5NyeXLud_E_V0f01rY995ZkLfKeq-7wdtZoz1VaaVH=6BBw@mail.gmail.com>
Message-ID: <CABghstSKsR9Fuy8FadHOFOVoHHBqP=Bg3N440S+GG7m4O7nf6Q@mail.gmail.com>

   Just to clarify/amplify: on the bug tracking system there's a
drop-down menu to specify severity, and "enhancement" is one of the
choices, so you don't have to worry that you're misrepresenting your
patch as fixing a bug.

  The fact that an R-core member (Michael Lawrence) thinks this is
worth looking at is very encouraging (and somewhat unusual for
feature/enhancement suggestions)!

  Ben Bolker

On Wed, Mar 27, 2019 at 5:29 PM Michael Lawrence via R-devel
<r-devel at r-project.org> wrote:
>
> This has some nice properties:
>
> 1) It self-documents the input expectations in a similar manner to
> colClasses.
> 2) The implementation could eventually "push down" the coercion, e.g.,
> calling it on each chunk of an iterative read operation.
>
> The implementation needs work though, and I'm not convinced that coercion
> failures should fallback gracefully to the default.
>
> Feature requests fall under a "bug" in bugzilla terminology, so please
> submit this there. I think I've made you an account.
>
> Thanks,
> Michael
>
> On Wed, Mar 27, 2019 at 1:19 PM Kurt Van Dijck <
> dev.kurt at vandijck-laurijssen.be> wrote:
>
> > Thank you for your answers.
> > I rather do not file a new bug, since what I coded isn't really a bug.
> >
> > The problem I (my colleagues) have today is very stupid:
> > We read .csv files with a lot of columns, of which most contain
> > date-time stamps, coded in DD/MM/YYYY HH:MM.
> > This is not exotic, but the base library's readtable (and derivatives)
> > only accept date-times in a limited number of possible formats (which I
> > understand very well).
> >
> > We could specify a format in a rather complicated format, for each
> > column individually, but this syntax is rather difficult to maintain.
> >
> > My solution to this specific problem became trivial, yet generic
> > extension to read.table.
> > Rather than relying on the built-in type detection, I added a parameter
> > to a function that will be called for each to-be-type-probed column so I
> > can overrule the built-in limited default.
> > If nothing returns from the function, the built-in default is still
> > used.
> >
> > This way, I could construct a type-probing function that is
> > straight-forward, not hard to code, and makes reading my .csv files
> > acceptible in terms of code (read.table parameters).
> >
> > I'm sure I'm not the only one dealing with such needs, escpecially
> > date-time formats exist in enormous amounts, but I want to stress here
> > that my approach is agnostic to my specific problem.
> >
> > For those asking to 'show me the code', I redirect to my 2nd patch,
> > where the tests have been extended with my specific problem.
> >
> > What are your opinions about this?
> >
> > Kind regards,
> > Kurt
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From @purd|e@@ @end|ng |rom gm@||@com  Thu Mar 28 00:26:36 2019
From: @purd|e@@ @end|ng |rom gm@||@com (Abs Spurdle)
Date: Thu, 28 Mar 2019 12:26:36 +1300
Subject: [Rd] Discrepancy between is.list() and is(x, "list")
In-Reply-To: <CAF8bMcZD03odP0yriDjoxYNFzfU3Js_bF6OosavyRxtVY6S44g@mail.gmail.com>
References: <CAB8pepyU2qbU7fd1J9J6kyr_657PHFYHoJV6fnvNiHqqjq-24w@mail.gmail.com>
 <EB8494AA-8DAA-4B9A-B636-7E979251EF0C@ucsd.edu>
 <CAB8pepxp9TL18vvHajvSJBXhJY=E13ZWUjebxv6OdgPXcWVPTQ@mail.gmail.com>
 <CAF8bMcZD03odP0yriDjoxYNFzfU3Js_bF6OosavyRxtVY6S44g@mail.gmail.com>
Message-ID: <CAB8pepxpqGtxC2s0Zs=ZJqqsKa5GVaei1_4-49w0vafmv8J3pA@mail.gmail.com>

> the prison made by ancient design choices

That prison of ancient design choices isn't so bad.

I have no further comments on object oriented semantics.
However, I'm planning to follow the following design pattern.

If I set the class of an object, I will append the new class to the
existing class.

#good
class (object) = c ("something", class (object) )

#bad
class (object) = "something"

I encourage others to do the same.


From therne@u @end|ng |rom m@yo@edu  Thu Mar 28 04:16:14 2019
From: therne@u @end|ng |rom m@yo@edu (Therneau, Terry M., Ph.D.)
Date: Wed, 27 Mar 2019 23:16:14 -0400
Subject: [Rd] issue with latest release of R-devel
Message-ID: <b23057$bd0b8c@ironport10.mayo.edu>

I'm getting ready to submit an update of survival, and is my habit I run the checks on all 
packages that depend/import/suggest? survival.? I am getting some very odd behaviour wrt 
non-reproducability.? It came to a head when some things failed on one machine and worked 
on another.?? I found that the difference was that the failure was using the 3/27 release 
and the success was still on a late Jan release.?? When I updated R on the latter machine 
it now fails too.

An example is the test cases in genfrail.Rd, in the frailtySurv package.?? (The package 
depends on survival, but I'm fairly sure that this function does not.)?? It's a fairly 
simple function to generate test data sets, with a half dozen calls in the test file.? If 
you cut and paste the whole batch into an R session, the last one of them fails.? But if 
you run that call by itself it works.?? This yes/no behavior is reproducable.

Another puzzler was the ranger package.? In the tests/testthat directory,? 
source('test_maxstat') fails if it is preceeded by source('test_jackknife'), but not 
otherwise.? Again, I don't think the survival package is implicated in either of these tests.

Another package that succeeded under the older r-devel and now fails is arsenal, but I 
haven't looked deeply at that.

Any insight would be be appreciated.

Terry T.
----


Here is the sessionInfo() for one of the machines.? The other is running xubuntu 18 LTS.? 
(It's at the office, and I can send that tomorrow when I get in.)

R Under development (unstable) (2019-03-28 r76277)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 16.04.6 LTS

Matrix products: default
BLAS:?? /usr/local/src/R-devel/lib/libRblas.so
LAPACK: /usr/local/src/R-devel/lib/libRlapack.so

locale:
 ?[1] LC_CTYPE=en_US.UTF-8?????? LC_NUMERIC=C
 ?[3] LC_TIME=en_US.UTF-8??????? LC_COLLATE=C
 ?[5] LC_MONETARY=en_US.UTF-8??? LC_MESSAGES=en_US.UTF-8
 ?[7] LC_PAPER=en_US.UTF-8?????? LC_NAME=C
 ?[9] LC_ADDRESS=C?????????????? LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats???? graphics? grDevices utils???? datasets? methods base

loaded via a namespace (and not attached):
[1] compiler_3.6.0


	[[alternative HTML version deleted]]


From henr|k@bengt@@on @end|ng |rom gm@||@com  Thu Mar 28 04:44:14 2019
From: henr|k@bengt@@on @end|ng |rom gm@||@com (Henrik Bengtsson)
Date: Wed, 27 Mar 2019 20:44:14 -0700
Subject: [Rd] issue with latest release of R-devel
In-Reply-To: <b23057$bd0b8c@ironport10.mayo.edu>
References: <b23057$bd0b8c@ironport10.mayo.edu>
Message-ID: <CAFDcVCQaHRXJkNaMo7UfU47ysOKdf7pB8uVD5aC9EMKnsNvXdQ@mail.gmail.com>

Could this be related to

"SIGNIFICANT USER-VISIBLE CHANGES

The default method for generating from a discrete uniform distribution
(used in sample(), for instance) has been changed. This addresses the
fact, pointed out by Ottoboni and Stark, that the previous method made
sample() noticeably non-uniform on large populations. See PR#17494 for
a discussion. The previous method can be requested using RNGkind() or
RNGversion() if necessary for reproduction of old results. Thanks to
Duncan Murdoch for contributing the patch and Gabe Becker for further
assistance."

If so, testing with

   export _R_RNG_VERSION_=3.5.0

might remove/explain those errors.

Just a thought

Henrik

On Wed, Mar 27, 2019 at 8:16 PM Therneau, Terry M., Ph.D. via R-devel
<r-devel at r-project.org> wrote:
>
> I'm getting ready to submit an update of survival, and is my habit I run the checks on all
> packages that depend/import/suggest  survival.  I am getting some very odd behaviour wrt
> non-reproducability.  It came to a head when some things failed on one machine and worked
> on another.   I found that the difference was that the failure was using the 3/27 release
> and the success was still on a late Jan release.   When I updated R on the latter machine
> it now fails too.
>
> An example is the test cases in genfrail.Rd, in the frailtySurv package.   (The package
> depends on survival, but I'm fairly sure that this function does not.)   It's a fairly
> simple function to generate test data sets, with a half dozen calls in the test file.  If
> you cut and paste the whole batch into an R session, the last one of them fails.  But if
> you run that call by itself it works.   This yes/no behavior is reproducable.
>
> Another puzzler was the ranger package.  In the tests/testthat directory,
> source('test_maxstat') fails if it is preceeded by source('test_jackknife'), but not
> otherwise.  Again, I don't think the survival package is implicated in either of these tests.
>
> Another package that succeeded under the older r-devel and now fails is arsenal, but I
> haven't looked deeply at that.
>
> Any insight would be be appreciated.
>
> Terry T.
> ----
>
>
> Here is the sessionInfo() for one of the machines.  The other is running xubuntu 18 LTS.
> (It's at the office, and I can send that tomorrow when I get in.)
>
> R Under development (unstable) (2019-03-28 r76277)
> Platform: x86_64-pc-linux-gnu (64-bit)
> Running under: Ubuntu 16.04.6 LTS
>
> Matrix products: default
> BLAS:   /usr/local/src/R-devel/lib/libRblas.so
> LAPACK: /usr/local/src/R-devel/lib/libRlapack.so
>
> locale:
>   [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>   [3] LC_TIME=en_US.UTF-8        LC_COLLATE=C
>   [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>   [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>   [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods base
>
> loaded via a namespace (and not attached):
> [1] compiler_3.6.0
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From henr|k@bengt@@on @end|ng |rom gm@||@com  Thu Mar 28 05:20:36 2019
From: henr|k@bengt@@on @end|ng |rom gm@||@com (Henrik Bengtsson)
Date: Wed, 27 Mar 2019 21:20:36 -0700
Subject: [Rd] 
 SUGGESTION: Proposal to mitigate problem with stray processes
 left behind by parallel::makeCluster()
In-Reply-To: <53568475-c7c2-2814-5760-eab4c202863c@gmail.com>
References: <CAFDcVCQ5H_5EDrEKy+ZGaBHQNSn0saHbg2VtDVc7j39GoRNnQA@mail.gmail.com>
 <53568475-c7c2-2814-5760-eab4c202863c@gmail.com>
Message-ID: <CAFDcVCQEpetNyvFAOv24DNdcWGH_kvCTY7YN4CzfHcO1mwDuvQ@mail.gmail.com>

Thank you Tomas.

For the record, I'm confirming that the stray background R worker
process now times out properly after 'setup_timeout' (= 120) seconds:

{0s}$ Rscript -e 'parallel::makeCluster(1L, port=80)'
Error in socketConnection("localhost", port = port, server = TRUE,
blocking = TRUE,  :
  cannot open the connection
Calls: <Anonymous> ... makePSOCKcluster -> newPSOCKnode -> socketConnection
In addition: Warning message:
In socketConnection("localhost", port = port, server = TRUE, blocking = TRUE,  :
  port 80 cannot be opened
Execution halted
{1s}$ ps aux | grep -E "exec[/]R"
hb       17645  2.0  0.3 259104 55144 pts/5    S    20:58   0:00
/home/hb/software/R-devel/trunk/lib/R/bin/exec/R --slave --no-restore
-e parallel:::.slaveRSOCK() --args MASTER=localhost PORT=80
OUT=/dev/null SETUPTIMEOUT=120 TIMEOUT=2592000 XDR=TRUE
{2s}$ sleep 120
{122s}$ ps aux | grep -E "exec[/]R"
{122s}$

Good spotting of the bug:

-  if (Sys.time() - t0 > setup_timeout) break
+  if (difftime(Sys.time(), t0, units="secs") > setup_timeout) break

For those who find this thread, I think what's going on here is that
'setup_timeout = 120' is a numeric that is compared a 'difftime' than
keeps changing unit as times goes by.  When compared as 'Sys.time() -
t0 > setup_timeout' the LHS would be in units of seconds as long as
less than 60 seconds had passed:

> Sys.time() - t0
Time difference of 59 secs
> as.numeric(Sys.time() - t0)
[1] 59

However, as soon as more than 60 seconds has passed, the unit turns
into minutes and we're comparing minutes to seconds:

> Sys.time() - t0
Time difference of 1.016667 mins
> as.numeric(Sys.time() - t0)
[1] 1.016667

which is now compared to 'setup_timeout'.  If the unit remained to be
minutes it would timeout after 120 [minutes]. However, after 120
minutes, the unit of Sys.time() - t0 is in hours, and we're comparing
hours to seconds, and so on.  It would only timeout if we used
'setup_timeout' < 60 seconds.

/Henrik

On Wed, Mar 27, 2019 at 12:52 PM Tomas Kalibera
<tomas.kalibera at gmail.com> wrote:
>
>
> The problem causing the stray worker processes when the master fails to
> open a server socket to listen to connections from workers is not
> related to timeout in socketConnection(), because socketConnection()
> will fail right away. It is caused by a bug in checking the setup
> timeout (PR 17391).
>
> Fixed in 76275.
>
> Best
> Tomas
>
> On 3/18/19 2:23 AM, Henrik Bengtsson wrote:
> > (Bcc: CRAN)
> >
> > This is a proposal helping CRAN and alike as well as individual
> > developers to avoid stray R processes being left behind that might be
> > produced when an example or a package test fails to set up a
> > parallel::makeCluster().
> >
> >
> > ISSUE
> >
> > If a package test sets up a PSOCK cluster and then the master process
> > dies for one reason or the other, the PSOCK worker processes will
> > remain running for 30 days ('timeout') until they timeout and
> > terminate that way.  When this happens on CRAN servers, where many
> > packages are checked all the time, this will result in a lot of stray
> > R processes.
> >
> > Here is an example illustrating how R leaves behind stray R processes
> > if fails to establish a connection to one or more background R
> > processes launched by 'parallel::makeCluster()'.  First, let's make
> > sure there are no other R processes running:
> >
> >    $ ps aux | grep -E "exec[/]R"
> >
> > Then, lets create a PSOCK cluster for which connection will fail
> > (because port 80 is reserved):
> >
> >    $ Rscript -e 'parallel::makeCluster(1L, port=80)'
> >    Error in socketConnection("localhost", port = port, server = TRUE,
> > blocking = TRUE,  :
> >      cannot open the connection
> >    Calls: <Anonymous> ... makePSOCKcluster -> newPSOCKnode -> socketConnection
> >    In addition: Warning message:
> >    In socketConnection("localhost", port = port, server = TRUE,
> > blocking = TRUE,  :
> >      port 80 cannot be opened
> >
> > The launched R worker is still running:
> >
> >    $ ps aux | grep -E "exec[/]R"
> >    hb       20778 37.0  0.4 283092 70624 pts/0    S    17:50   0:00
> > /usr/lib/R/bin/exec/R --slave --no-restore -e parallel:::.slaveRSOCK()
> > --args MASTER=localhost PORT=80 OUT=/dev/null SETUPTIMEOUT=120
> > TIMEOUT=2 592000 XDR=TRUE
> >
> > This process will keep running for 'TIMEOUT=2592000' seconds (= 30
> > days).  The reason for this is that it is currently in the state where
> > it attempts to set up a connection to the main R process:
> >
> >    > parallel:::.slaveRSOCK
> >    function ()
> >    {
> >        makeSOCKmaster <- function(master, port, setup_timeout, timeout,
> >            useXDR) {
> >     ...
> >            repeat {
> >                con <- tryCatch({
> >                    socketConnection(master, port = port, blocking = TRUE,
> >                      open = "a+b", timeout = timeout)
> >                }, error = identity)
> >        ...
> >    }
> >
> > In other words, it is stuck in 'socketConnection()' and it won't time
> > out until 'timeout' seconds.
> >
> >
> > SUGGESTION
> >
> > To mitigate the problem with above stray processes from running 'R CMD
> > check', we could shorten the 'timeout' which is currently hardcoded to
> > 30 days (src/library/parallel/R/snow.R).  By making it possible to
> > control the default via environment variables, e.g.
> >
> >    setup_timeout = as.numeric(Sys.getenv("R_PARALLEL_SETUP_TIMEOUT", 60
> > * 2)),      # 2 minutes
> >    timeout = as.numeric(Sys.getenv("R_PARALLEL_SETUP_TIMEOUT", 60 * 60
> > * 24 * 30)), # 30 days
> >
> > it would be straightforward to adjust `R CMD check` to use, say,
> >
> >    R_PARALLEL_SETUP_TIMEOUT=60
> >
> > by default.  This would cause any stray processes to time out after 60
> > seconds (instead of 30 days as now).
> >
> > /Henrik
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From @purd|e@@ @end|ng |rom gm@||@com  Thu Mar 28 06:19:06 2019
From: @purd|e@@ @end|ng |rom gm@||@com (Abs Spurdle)
Date: Thu, 28 Mar 2019 18:19:06 +1300
Subject: [Rd] default for 'signif.stars'
Message-ID: <CAB8pepwzwgQ80b-sZOrx__b1Dhhh6AQs8gyztnx_8MbJ86YEdQ@mail.gmail.com>

I read through the editorial.
This is the one of the most mega-ultra-super-biased articles I've ever read.

e.g.
The authors encourage Baysian methods, and literally encourage subjective
approaches.
However, there's only one reference to robust methods and one reference to
nonparametric methods, both of which are labelled as purely exploratory
methods, which I regard as extremely offensive.
And there don't appear to be any references to semiparameric methods, or
machine learning.

Surprisingly, they encourage multiple testing, however, don't mention the
multiple comparison problem.
Something I can't understand at all.

So, maybe we should replace signif.stars with emoji...?

	[[alternative HTML version deleted]]


From dev@kurt @end|ng |rom v@nd|jck-|@ur|j@@en@be  Thu Mar 28 06:33:18 2019
From: dev@kurt @end|ng |rom v@nd|jck-|@ur|j@@en@be (Kurt Van Dijck)
Date: Thu, 28 Mar 2019 06:33:18 +0100
Subject: [Rd] [RFC] readtable enhancement
In-Reply-To: <CAOQ5NyeXLud_E_V0f01rY995ZkLfKeq-7wdtZoz1VaaVH=6BBw@mail.gmail.com>
References: <1553274983-15970-1-git-send-email-dev.kurt@vandijck-laurijssen.be>
 <20190326185229.GA26161@x1.vandijck-laurijssen.be>
 <CAOQ5NyenGa23Nreqhmp-==9z5NXjEQ4LD99URC3BkqAeKHadnQ@mail.gmail.com>
 <20190326202007.GA29643@x1.vandijck-laurijssen.be>
 <658850e1-f344-2674-cc7c-c4b5d539eec5@gmail.com>
 <20190327201834.GB2780@x1.vandijck-laurijssen.be>
 <CAOQ5NyeXLud_E_V0f01rY995ZkLfKeq-7wdtZoz1VaaVH=6BBw@mail.gmail.com>
Message-ID: <20190328053318.GA9759@x1.vandijck-laurijssen.be>

Hey,

In the meantime, I submitted a bug. Thanks for the assistence on that.

>    and I'm not convinced that
>    coercion failures should fallback gracefully to the default.

the gracefull fallback:
- makes the code more complex
+ keeps colConvert implementations limited
+ requires the user to only implement what changed from the default
+ seemed to me to smallest overall effort

In my opinion, gracefull fallback makes the thing better,
but without it, the colConvert parameter remains usefull, it would still
fill a gap.

>    The implementation needs work though,

Other than to remove the gracefull fallback?

Kind regards,
Kurt

On wo, 27 mrt 2019 14:28:25 -0700, Michael Lawrence wrote:
>    This has some nice properties:
>    1) It self-documents the input expectations in a similar manner to
>    colClasses.
>    2) The implementation could eventually "push down" the coercion, e.g.,
>    calling it on each chunk of an iterative read operation.
>    The implementation needs work though, and I'm not convinced that
>    coercion failures should fallback gracefully to the default.
>    Feature requests fall under a "bug" in bugzilla terminology, so please
>    submit this there. I think I've made you an account.
>    Thanks,
>    Michael
> 
>    On Wed, Mar 27, 2019 at 1:19 PM Kurt Van Dijck
>    <[1]dev.kurt at vandijck-laurijssen.be> wrote:
> 
>      Thank you for your answers.
>      I rather do not file a new bug, since what I coded isn't really a
>      bug.
>      The problem I (my colleagues) have today is very stupid:
>      We read .csv files with a lot of columns, of which most contain
>      date-time stamps, coded in DD/MM/YYYY HH:MM.
>      This is not exotic, but the base library's readtable (and
>      derivatives)
>      only accept date-times in a limited number of possible formats
>      (which I
>      understand very well).
>      We could specify a format in a rather complicated format, for each
>      column individually, but this syntax is rather difficult to
>      maintain.
>      My solution to this specific problem became trivial, yet generic
>      extension to read.table.
>      Rather than relying on the built-in type detection, I added a
>      parameter
>      to a function that will be called for each to-be-type-probed column
>      so I
>      can overrule the built-in limited default.
>      If nothing returns from the function, the built-in default is still
>      used.
>      This way, I could construct a type-probing function that is
>      straight-forward, not hard to code, and makes reading my .csv files
>      acceptible in terms of code (read.table parameters).
>      I'm sure I'm not the only one dealing with such needs, escpecially
>      date-time formats exist in enormous amounts, but I want to stress
>      here
>      that my approach is agnostic to my specific problem.
>      For those asking to 'show me the code', I redirect to my 2nd patch,
>      where the tests have been extended with my specific problem.
>      What are your opinions about this?
>      Kind regards,
>      Kurt


From g@bembecker @end|ng |rom gm@||@com  Thu Mar 28 06:55:06 2019
From: g@bembecker @end|ng |rom gm@||@com (Gabriel Becker)
Date: Wed, 27 Mar 2019 22:55:06 -0700
Subject: [Rd] [RFC] readtable enhancement
In-Reply-To: <20190328053318.GA9759@x1.vandijck-laurijssen.be>
References: <1553274983-15970-1-git-send-email-dev.kurt@vandijck-laurijssen.be>
 <20190326185229.GA26161@x1.vandijck-laurijssen.be>
 <CAOQ5NyenGa23Nreqhmp-==9z5NXjEQ4LD99URC3BkqAeKHadnQ@mail.gmail.com>
 <20190326202007.GA29643@x1.vandijck-laurijssen.be>
 <658850e1-f344-2674-cc7c-c4b5d539eec5@gmail.com>
 <20190327201834.GB2780@x1.vandijck-laurijssen.be>
 <CAOQ5NyeXLud_E_V0f01rY995ZkLfKeq-7wdtZoz1VaaVH=6BBw@mail.gmail.com>
 <20190328053318.GA9759@x1.vandijck-laurijssen.be>
Message-ID: <CAD4oTHEVpxdTANijnozOex11_qvuEVgTFgcNCBtSpBTkd_K_HQ@mail.gmail.com>

Kurt,

Cool idea and great "seeing new faces" on here proposing things on here and
engaging with R-core on here.

Some comments on the issue of fallbacks below.


On Wed, Mar 27, 2019 at 10:33 PM Kurt Van Dijck <
dev.kurt at vandijck-laurijssen.be> wrote:

> Hey,
>
> In the meantime, I submitted a bug. Thanks for the assistence on that.
>
> >    and I'm not convinced that
> >    coercion failures should fallback gracefully to the default.
>
> the gracefull fallback:
> - makes the code more complex
> + keeps colConvert implementations limited
> + requires the user to only implement what changed from the default
> + seemed to me to smallest overall effort
>
> In my opinion, gracefull fallback makes the thing better,
> but without it, the colConvert parameter remains usefull, it would still
> fill a gap.
>

Another way of viewing coercion failure, I think, is that either the
user-supplied converter has a bug in it or was mistakenly applied in a
situation where it shouldn't have been. If thats the case the fail early
and loud paradigm might ultimately be more helpful to users there.

Another thought in the same vein is that if fallback occurs, the returned
result will not be what the user asked for and is expecting. So either
their code which assumes (e.g., that a column has correctly parsed as a
date) is going to break in mysterious (to them) ways, or they have to put a
bunch of their own checking logic after the call to see if their converters
actually worked in order to protect themselves from that.  Neither really
seems ideal to me; I think an error would be better, myself. I'm more of a
software developer than a script writer/analyst though, so its possible
others' opinions would differ (though I'd be a bit surprised by that in
this particular case given the danger).

Best,
~G

> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From dev@kurt @end|ng |rom v@nd|jck-|@ur|j@@en@be  Thu Mar 28 09:34:42 2019
From: dev@kurt @end|ng |rom v@nd|jck-|@ur|j@@en@be (Kurt Van Dijck)
Date: Thu, 28 Mar 2019 09:34:42 +0100
Subject: [Rd] [RFC] readtable enhancement
In-Reply-To: <CAD4oTHEVpxdTANijnozOex11_qvuEVgTFgcNCBtSpBTkd_K_HQ@mail.gmail.com>
References: <1553274983-15970-1-git-send-email-dev.kurt@vandijck-laurijssen.be>
 <20190326185229.GA26161@x1.vandijck-laurijssen.be>
 <CAOQ5NyenGa23Nreqhmp-==9z5NXjEQ4LD99URC3BkqAeKHadnQ@mail.gmail.com>
 <20190326202007.GA29643@x1.vandijck-laurijssen.be>
 <658850e1-f344-2674-cc7c-c4b5d539eec5@gmail.com>
 <20190327201834.GB2780@x1.vandijck-laurijssen.be>
 <CAOQ5NyeXLud_E_V0f01rY995ZkLfKeq-7wdtZoz1VaaVH=6BBw@mail.gmail.com>
 <20190328053318.GA9759@x1.vandijck-laurijssen.be>
 <CAD4oTHEVpxdTANijnozOex11_qvuEVgTFgcNCBtSpBTkd_K_HQ@mail.gmail.com>
Message-ID: <20190328083442.GC9759@x1.vandijck-laurijssen.be>

On wo, 27 mrt 2019 22:55:06 -0700, Gabriel Becker wrote:
>    Kurt,
>    Cool idea and great "seeing new faces" on here proposing things on here
>    and engaging with R-core on here.
>    Some comments on the issue of fallbacks below.
>    On Wed, Mar 27, 2019 at 10:33 PM Kurt Van Dijck
>    <[1]dev.kurt at vandijck-laurijssen.be> wrote:
> 
>      Hey,
>      In the meantime, I submitted a bug. Thanks for the assistence on
>      that.
>      >    and I'm not convinced that
>      >    coercion failures should fallback gracefully to the default.
>      the gracefull fallback:
>      - makes the code more complex
>      + keeps colConvert implementations limited
>      + requires the user to only implement what changed from the default
>      + seemed to me to smallest overall effort
>      In my opinion, gracefull fallback makes the thing better,
>      but without it, the colConvert parameter remains usefull, it would
>      still
>      fill a gap.
> 
>    Another way of viewing coercion failure, I think, is that either the
>    user-supplied converter has a bug in it or was mistakenly applied in a
>    situation where it shouldn't have been. If thats the case the fail
>    early and loud paradigm might ultimately be more helpful to users
>    there.
>    Another thought in the same vein is that if fallback occurs, the
>    returned result will not be what the user asked for and is expecting.
>    So either their code which assumes (e.g., that a column has correctly
>    parsed as a date) is going to break in mysterious (to them) ways, or
>    they have to put a bunch of their own checking logic after the call to
>    see if their converters actually worked in order to protect themselves
>    from that.  Neither really seems ideal to me; I think an error would be
>    better, myself. I'm more of a software developer than a script
>    writer/analyst though, so its possible others' opinions would differ
>    (though I'd be a bit surprised by that in this particular case given
>    the danger).

I see.
So if we provide a default colConvert, named e.g. colConvertBuiltin,
which is used if colConvert is not given?
1) This respects the 'fail early and loud'.
2) The user would get what he asks for
3) A colConvert implementation would be able to call colConvertBuiltin
manually if desired, so have colConvert limited to adding on top of the
default implementation.

If this is acceptable, I'll prepare a new patch.

Kind regards,
Kurt


From b@row||ng@on @end|ng |rom gm@||@com  Wed Mar 27 09:28:04 2019
From: b@row||ng@on @end|ng |rom gm@||@com (Barry Rowlingson)
Date: Wed, 27 Mar 2019 08:28:04 +0000
Subject: [Rd] bugs in head() and tail()
In-Reply-To: <c98362642aea41abb3c43090bf5693b2@CWXP265MB0775.GBRP265.PROD.OUTLOOK.COM>
References: <CAB8pepwajebtmzuGyMzd7ak_PhMakSwkXS-JEqV4VFW_2kh7sw@mail.gmail.com>
 <CAD4oTHFbbRs5GvhyR33+0mvXmsHFsBAK8hL_2CBDC_eeEA0e_w@mail.gmail.com>
 <c98362642aea41abb3c43090bf5693b2@CWXP265MB0775.GBRP265.PROD.OUTLOOK.COM>
Message-ID: <CANVKczMFJyZwm7LPiEnYk1mtU6_rzx0L4SeCbhVmHz+KBTLRNA@mail.gmail.com>

On Wed, Mar 27, 2019 at 1:52 AM Abs Spurdle <spurdle.a at gmail.com> wrote:

>
> In the case of head.default(), it assumes that the object is a vector, or
> something similar.
>

No it doesn't. It assumes (ultimately) that x[seq_len(n)] is the correct
way to generate a "head" of something. Which is reasonable. That's
dependent on the implementation of the `[` method on object `x`.


> Resulting in the error above, which fails to recognize that the input was
> unsuitable.
>
> Because the object you fed it didn't have a method for `head` or for `[`.
Its the object designer's responsibility to do that. And by creating a
function that doesn't have the "function" class - that means *you*.

There's no way that head.default can inspect everything it might get fed,
including classes that have yet to be made, to see if it can do anything
meaningful with it. So it uses what looks like a reasonable approach -
apply `[` on the object with the first `n` elements. Let the class decide
what to do with it.

You might think generics should trap errors and give meaningful errors, but
the error isn't in the generic here - its in the `[` method of the class it
was fed. `head` doesn't know or care about that - again, its the class
designers responsibility to handle that, and the users responsibility to
*not* call generics on objects for which there's no meaningful behaviour.
It's really the error message of `[.default` seeming obscure to you that is
your issue here. If it said "cannot create subsets of this object with ["
would that please you? Again, that's not a bug in `head` or anything to do
with method dispatch.

So lets take a look at your choices here:

 "If a generic has a default method, then that default method should be
guaranteed to work."

 - as demonstrated, the default here does its job. it does "work".

"Or at least, provide a useful error message, that makes it obvious to the
user, what he or she has done wrong."

 and that error message is the responsibility of methods of the object, in
this case `[`.

therefore its not a bug.

Barry





>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Thu Mar 28 10:18:10 2019
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Thu, 28 Mar 2019 10:18:10 +0100
Subject: [Rd] default for 'signif.stars'
In-Reply-To: <DM6PR04MB438095FB858DADCCAE2506A8F1580@DM6PR04MB4380.namprd04.prod.outlook.com>
References: <DM6PR04MB438095FB858DADCCAE2506A8F1580@DM6PR04MB4380.namprd04.prod.outlook.com>
Message-ID: <23708.37202.165520.41963@stat.math.ethz.ch>

>>>>> Lenth, Russell V 
>>>>>     on Wed, 27 Mar 2019 00:06:08 +0000 writes:

    > Dear R-Devel, As I am sure many of you know, a special
    > issue of The American Statistician just came out, and its
    > theme is the [mis]use of P values and the many common ways
    > in which they are abused. The lead editorial in that issue
    > mentions the 2014 ASA guidelines on P values, and goes one
    > step further, by now recommending that the words
    > "statistically significant" and related simplistic
    > interpretations no longer be used. There is much
    > discussion of the problems with drawing "bright lines"
    > concerning P values.

    > This is the position of a US society, but my sense is that
    > the statistical community worldwide is pretty much on the
    > same page.

    > Meanwhile, functions such as 'print.summary.lm' and
    > 'print.anova' have an argument 'signif.stars' that really
    > does involve drawing bright lines when it is set to
    > TRUE. And the default setting for the "show.signif.stars"
    > option is TRUE. Isn't it time to at least make
    > "show.signif.stars" default to FALSE? And, indeed, to
    > consider deprecating those 'signif.stars' options
    > altogether?

Dear Russ,
Abs has already given good reasons why this article may well be
considered problematic.

However, I think you and (many but not all) others who've raised
this issue before you, slightly miss the following point.

If p-values are misleading they should not be shown (and hence
the signif.stars neither.
That has been the approach adopted e.g., in the lme4 package
*AND* has been an approach originally used in S and I think
parts of R as well, in more places than now, notably, e.g., for
print( summary(<glm>) ).

Fact is that users will write wrappers and their own packages
just to get to p values, even in very doubtful cases...
But anyway that (p values or not) is a different discussion
which has some value.

You however focus on the "significance stars".  I've argued for
years why they are useful, as they are just a simple
visualization of p values, and saving a lot of human time when
there are many (fixed) effects looked at simultaneously.
Why should users have to visually scan 20 or 50 numbers?  In
modern Data analysis they should never have to but rather look
at a visualization of those numbers. ... and that's what
significance stars are, not more, nor less.

Martin


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Thu Mar 28 10:35:57 2019
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Thu, 28 Mar 2019 10:35:57 +0100
Subject: [Rd] Discrepancy between is.list() and is(x, "list")
In-Reply-To: <CAB8pepxpqGtxC2s0Zs=ZJqqsKa5GVaei1_4-49w0vafmv8J3pA@mail.gmail.com>
References: <CAB8pepyU2qbU7fd1J9J6kyr_657PHFYHoJV6fnvNiHqqjq-24w@mail.gmail.com>
 <EB8494AA-8DAA-4B9A-B636-7E979251EF0C@ucsd.edu>
 <CAB8pepxp9TL18vvHajvSJBXhJY=E13ZWUjebxv6OdgPXcWVPTQ@mail.gmail.com>
 <CAF8bMcZD03odP0yriDjoxYNFzfU3Js_bF6OosavyRxtVY6S44g@mail.gmail.com>
 <CAB8pepxpqGtxC2s0Zs=ZJqqsKa5GVaei1_4-49w0vafmv8J3pA@mail.gmail.com>
Message-ID: <23708.38269.817417.238096@stat.math.ethz.ch>

>>>>> Abs Spurdle 
>>>>>     on Thu, 28 Mar 2019 12:26:36 +1300 writes:

    >> the prison made by ancient design choices
    > That prison of ancient design choices isn't so bad.

    > I have no further comments on object oriented semantics.
    > However, I'm planning to follow the following design
    > pattern.

    > If I set the class of an object, I will append the new
    > class to the existing class.

    > #good class (object) = c ("something", class (object) )

#even better ;-)
      
      class(object) <- c("something", class(object))

    > #bad class (object) = "something"

    > I encourage others to do the same.
Indeed.

BUT also tell the thousands of people who do it -- including
somewhat famous R package authors --

*NOT* to use things such as

      if(class(x) == "Date")

or
      switch(class(x),  
             "Date" = ...... ,
  	     "POSIXct" = ...... ,
	     ....
	     ...
	     stop("invalid class: ", class(x)))

BUT to always use

    inherits(x, "....")

There may be rare exceptions where using   class(x)[1]   is
good, but I have seen many cases where     class(x)[1]  was used
and the R programmers found it smart they knew that
class(x) can be of length more than one, but really their code
would fail *exactly* because good R programmers do *prepend*
their S3 class extension/specialization to the already existing
class.

---

... and then, I do agree with Gabe that (in some cases), using
 formal (aka "S4") classes is really what one should do in order
to get a clean interface.


Martin Maechler
ETH Zurich and R Core Team


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Thu Mar 28 12:42:49 2019
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Thu, 28 Mar 2019 12:42:49 +0100
Subject: [Rd] topenv of emptyenv
In-Reply-To: <CAM2gKPaSjQp3Eq4Gy+B7RO-LgwgUoo8RV3JrA452f2v2FZAgLg@mail.gmail.com>
References: <CAM2gKPaSjQp3Eq4Gy+B7RO-LgwgUoo8RV3JrA452f2v2FZAgLg@mail.gmail.com>
Message-ID: <23708.45881.551325.849739@stat.math.ethz.ch>

>>>>> Konrad Rudolph 
>>>>>     on Sat, 23 Mar 2019 14:26:40 +0000 writes:
>>>>> Konrad Rudolph 
>>>>>     on Sat, 23 Mar 2019 14:26:40 +0000 writes:

    > I was surprised just now to find out that `topenv(emptyenv())` equals
    > ? `.GlobalEnv`, not `emptyenv()`. From my understanding of the
    > description of `topenv`, it should walk up the chain of enclosing
    > environments (as if by calling `e = parent.env(e)` repeatedly; in
    > fact, that is almost exactly its implementation in envir.c) until it
    > hits a top level. However, `emptyenv()` has no enclosing environments
    > so it should be its own top-level environment (I thought).
    > Unfortunately the documentation on environments is relatively sparse,
    > and the R Internals document doesn?t mention top-level environments.

    > Concretely, I encountered this in the following code, which signals an
    > error if `env` is the empty environment:

    > while (! some_complex_condition(env) && ! identical(env, toplevel(env))) {
    > 	    env = parent.env(env)
    > }

I guess the above 'toplevel(env)' should be replaced by 'topenv(env)' ?

    > Of course there?s a trivial workaround (add an identity check for
    > `emptyenv()` in the while loop condition) but it got me wondering if
    > there?s a rationale for this result or if it?s ?accidental?/arbitrary:
    > the C `topenv` implementation defaults to returning R_GlobalEnv for an
    > empty environment. Is this effect actually useful (and used anywhere)?

I don't know if it's useful or used anywhere.
I've not seen topenv() used a lot at all ...  contrary to parent.env(),
and as we know,

  > parent.env(emptyenv())
  Error in parent.env(emptyenv()) : the empty environment has no parent

very much on purpose.

Note that you should not directly be surprised.  If you were you
did not read   ?topenv  carefully enough:

It says that the value returned must be "top level environment" (=: TLE)
and then defines TLE as

>  An environment is considered top level if it is the internal environment of a
>  namespace, a package environment in the search path, or .GlobalEnv .

So from that definition it must return .Globalenv in this
particular case.

On the other hand, if you want a test of

   identical(env, topenv(env))

to make sense I understand that you'd want to allow  topenv() to
return emptyenv() in your case, i.e., you'd want the above
identical(..) to be true in this case...

Still, with the definition of  TLE  as it has been on the help
page forever,  emptyenv() really does not belong

    > This is in R 3.4.4 but I can?t find an indication that this behaviour
    > was ever changed.

Indeed... and as I mentioned I had never actively noticed the
use of topenv() at all...

Martin


    > Cheers

    > -- 
    > Konrad Rudolph

    > ______________________________________________
    > R-devel at r-project.org mailing list
    > https://stat.ethz.ch/mailman/listinfo/r-devel


From c@@rd|@g@bor @end|ng |rom gm@||@com  Thu Mar 28 12:48:23 2019
From: c@@rd|@g@bor @end|ng |rom gm@||@com (=?UTF-8?B?R8OhYm9yIENzw6FyZGk=?=)
Date: Thu, 28 Mar 2019 11:48:23 +0000
Subject: [Rd] topenv of emptyenv
In-Reply-To: <23708.45881.551325.849739@stat.math.ethz.ch>
References: <CAM2gKPaSjQp3Eq4Gy+B7RO-LgwgUoo8RV3JrA452f2v2FZAgLg@mail.gmail.com>
 <23708.45881.551325.849739@stat.math.ethz.ch>
Message-ID: <CABtg=Kk7V-toHO_Dm-cPMgPcoEnAS9nbgraaurG67Hi47g58BA@mail.gmail.com>

On Thu, Mar 28, 2019 at 11:43 AM Martin Maechler
<maechler at stat.math.ethz.ch> wrote:
[...]
>
> Indeed... and as I mentioned I had never actively noticed the
> use of topenv() at all...

FWIW topenv() is used in a couple of packages, although some of these
are false positives:
https://github.com/search?q=org%3Acran+topenv&type=Code

Gabor

[...]


From konr@d@rudo|ph @end|ng |rom gm@||@com  Thu Mar 28 12:59:59 2019
From: konr@d@rudo|ph @end|ng |rom gm@||@com (Konrad Rudolph)
Date: Thu, 28 Mar 2019 11:59:59 +0000
Subject: [Rd] topenv of emptyenv
In-Reply-To: <23708.45881.551325.849739@stat.math.ethz.ch>
References: <CAM2gKPaSjQp3Eq4Gy+B7RO-LgwgUoo8RV3JrA452f2v2FZAgLg@mail.gmail.com>
 <23708.45881.551325.849739@stat.math.ethz.ch>
Message-ID: <CAM2gKPYz4uqwfTBUnHM=X0dHHH-VfJB=+ZeegDVKhRo3J2hWGQ@mail.gmail.com>

On Thu, Mar 28, 2019 at 11:42 AM Martin Maechler
<maechler at stat.math.ethz.ch> wrote:
> So from that definition it must return .Globalenv in this
> particular case.

Indeed, that makes sense. Apparently the note wasn?t explicit enough
for me to make the connection.

-- 
Konrad Rudolph


From therne@u @end|ng |rom m@yo@edu  Thu Mar 28 14:27:53 2019
From: therne@u @end|ng |rom m@yo@edu (Therneau, Terry M., Ph.D.)
Date: Thu, 28 Mar 2019 08:27:53 -0500
Subject: [Rd] default for 'signif.stars'
Message-ID: <b23057$bd1u96@ironport10.mayo.edu>

The addition of significant stars was, in my opinion, one of the worst defaults ever added 
to R.?? I would be delighted to see it removed, or at least change the default.? It is one 
of the few overrides that I have argued to add to our site-wide defaults file.

My bias comes from 30+ years in a medical statistics career where fighting the disease of 
"dichotomania" has been an eternal struggle.? Continuous covariates are split in two, 
nuanced risk scores are thresholded, decisions become yes/no, ....??? Adding stars to 
output is, to me, simply a gateway drug to this pernicous addiction.?? We shouldn't 
encourage it.

Wrt Abe's rant about the Nature article:? I've read the article and found it to be well 
reasoned, and I can't say the same about the rant.?? The issue in biomedical science is 
that the p-value has fallen victim to Goodhart's law: "When a measure becomes a target, it 
ceases to be a good measure."? The article argues, and I would agree, that the .05 yes/no 
decision rule is currently doing more harm than good in biomedical research.?? What to do 
instead of this is a tough question, but it is fairly clear that the current plan isn't 
working.?? I have seen many cases of two papers which both found a risk increase of 1.9 
for something where one paper claimed "smoking gun" and the other "completely 
exonerated".?? Do YOU want to take a drug with 2x risk and a p= 0.2 'proof' that it is 
okay??? Of course, if there is too much to do and too little time, people will find a way 
to create a shortcut yes/no rule no matter what we preach.?? (We statisticians will do it 
too.)

Terry T.




	[[alternative HTML version deleted]]


From therne@u @end|ng |rom m@yo@edu  Thu Mar 28 15:22:10 2019
From: therne@u @end|ng |rom m@yo@edu (Therneau, Terry M., Ph.D.)
Date: Thu, 28 Mar 2019 09:22:10 -0500
Subject: [Rd] [EXTERNAL] Re:  issue with latest release of R-devel
In-Reply-To: <CAFDcVCQaHRXJkNaMo7UfU47ysOKdf7pB8uVD5aC9EMKnsNvXdQ@mail.gmail.com>
References: <b23057$bd0b8c@ironport10.mayo.edu>
 <CAFDcVCQaHRXJkNaMo7UfU47ysOKdf7pB8uVD5aC9EMKnsNvXdQ@mail.gmail.com>
Message-ID: <b23057$bd2h5o@ironport10.mayo.edu>

I have not yet checked all instances, but Henrik's suggestion is 3 for 3 so far.
Should I send notes to the packages in question, or will they get some from CRAN?

Terry


On 3/27/19 10:44 PM, Henrik Bengtsson wrote:
> Could this be related to
>
> "SIGNIFICANT USER-VISIBLE CHANGES
>
> The default method for generating from a discrete uniform distribution
> (used in sample(), for instance) has been changed. This addresses the
> fact, pointed out by Ottoboni and Stark, that the previous method made
> sample() noticeably non-uniform on large populations. See PR#17494 for
> a discussion. The previous method can be requested using RNGkind() or
> RNGversion() if necessary for reproduction of old results. Thanks to
> Duncan Murdoch for contributing the patch and Gabe Becker for further
> assistance."
>
> If so, testing with
>
>     export _R_RNG_VERSION_=3.5.0
>
> might remove/explain those errors.
>
> Just a thought
>
> Henrik
>
> On Wed, Mar 27, 2019 at 8:16 PM Therneau, Terry M., Ph.D. via R-devel
> <r-devel at r-project.org> wrote:
>> I'm getting ready to submit an update of survival, and is my habit I run the checks on all
>> packages that depend/import/suggest  survival.  I am getting some very odd behaviour wrt
>> non-reproducability.  It came to a head when some things failed on one machine and worked
>> on another.   I found that the difference was that the failure was using the 3/27 release
>> and the success was still on a late Jan release.   When I updated R on the latter machine
>> it now fails too.
>>
>> An example is the test cases in genfrail.Rd, in the frailtySurv package.   (The package
>> depends on survival, but I'm fairly sure that this function does not.)   It's a fairly
>> simple function to generate test data sets, with a half dozen calls in the test file.  If
>> you cut and paste the whole batch into an R session, the last one of them fails.  But if
>> you run that call by itself it works.   This yes/no behavior is reproducable.
>>
>> Another puzzler was the ranger package.  In the tests/testthat directory,
>> source('test_maxstat') fails if it is preceeded by source('test_jackknife'), but not
>> otherwise.  Again, I don't think the survival package is implicated in either of these tests.
>>
>> Another package that succeeded under the older r-devel and now fails is arsenal, but I
>> haven't looked deeply at that.
>>
>> Any insight would be be appreciated.
>>
>> Terry T.
>> ----
>>
>>
>> Here is the sessionInfo() for one of the machines.  The other is running xubuntu 18 LTS.
>> (It's at the office, and I can send that tomorrow when I get in.)
>>
>> R Under development (unstable) (2019-03-28 r76277)
>> Platform: x86_64-pc-linux-gnu (64-bit)
>> Running under: Ubuntu 16.04.6 LTS
>>
>> Matrix products: default
>> BLAS:   /usr/local/src/R-devel/lib/libRblas.so
>> LAPACK: /usr/local/src/R-devel/lib/libRlapack.so
>>
>> locale:
>>    [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>>    [3] LC_TIME=en_US.UTF-8        LC_COLLATE=C
>>    [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>>    [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>>    [9] LC_ADDRESS=C               LC_TELEPHONE=C
>> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods base
>>
>> loaded via a namespace (and not attached):
>> [1] compiler_3.6.0
>>
>>
>>          [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel


	[[alternative HTML version deleted]]


From |@wrence@m|ch@e| @end|ng |rom gene@com  Thu Mar 28 15:23:46 2019
From: |@wrence@m|ch@e| @end|ng |rom gene@com (Michael Lawrence)
Date: Thu, 28 Mar 2019 07:23:46 -0700
Subject: [Rd] [RFC] readtable enhancement
In-Reply-To: <20190328083442.GC9759@x1.vandijck-laurijssen.be>
References: <1553274983-15970-1-git-send-email-dev.kurt@vandijck-laurijssen.be>
 <20190326185229.GA26161@x1.vandijck-laurijssen.be>
 <CAOQ5NyenGa23Nreqhmp-==9z5NXjEQ4LD99URC3BkqAeKHadnQ@mail.gmail.com>
 <20190326202007.GA29643@x1.vandijck-laurijssen.be>
 <658850e1-f344-2674-cc7c-c4b5d539eec5@gmail.com>
 <20190327201834.GB2780@x1.vandijck-laurijssen.be>
 <CAOQ5NyeXLud_E_V0f01rY995ZkLfKeq-7wdtZoz1VaaVH=6BBw@mail.gmail.com>
 <20190328053318.GA9759@x1.vandijck-laurijssen.be>
 <CAD4oTHEVpxdTANijnozOex11_qvuEVgTFgcNCBtSpBTkd_K_HQ@mail.gmail.com>
 <20190328083442.GC9759@x1.vandijck-laurijssen.be>
Message-ID: <CAOQ5NyeGVj+bQNZS9LMsdMt9D5_5Kn6N1fE=Md-tqwi2mWC3ug@mail.gmail.com>

Gabe described my main concern. Specifying a coercion function asserts that
the data (1) were what was expected and (2) were converted into what was
expected. Allowing a coercer to delegate to a "next method" is a good idea,
but keep in mind that any function that did that would not confer the
beneficial constraints mentioned above.

We can continue the discussion at:
https://bugs.r-project.org/bugzilla/show_bug.cgi?id=17546

Michael

On Thu, Mar 28, 2019 at 1:35 AM Kurt Van Dijck <
dev.kurt at vandijck-laurijssen.be> wrote:

> On wo, 27 mrt 2019 22:55:06 -0700, Gabriel Becker wrote:
> >    Kurt,
> >    Cool idea and great "seeing new faces" on here proposing things on
> here
> >    and engaging with R-core on here.
> >    Some comments on the issue of fallbacks below.
> >    On Wed, Mar 27, 2019 at 10:33 PM Kurt Van Dijck
> >    <[1]dev.kurt at vandijck-laurijssen.be> wrote:
> >
> >      Hey,
> >      In the meantime, I submitted a bug. Thanks for the assistence on
> >      that.
> >      >    and I'm not convinced that
> >      >    coercion failures should fallback gracefully to the default.
> >      the gracefull fallback:
> >      - makes the code more complex
> >      + keeps colConvert implementations limited
> >      + requires the user to only implement what changed from the default
> >      + seemed to me to smallest overall effort
> >      In my opinion, gracefull fallback makes the thing better,
> >      but without it, the colConvert parameter remains usefull, it would
> >      still
> >      fill a gap.
> >
> >    Another way of viewing coercion failure, I think, is that either the
> >    user-supplied converter has a bug in it or was mistakenly applied in a
> >    situation where it shouldn't have been. If thats the case the fail
> >    early and loud paradigm might ultimately be more helpful to users
> >    there.
> >    Another thought in the same vein is that if fallback occurs, the
> >    returned result will not be what the user asked for and is expecting.
> >    So either their code which assumes (e.g., that a column has correctly
> >    parsed as a date) is going to break in mysterious (to them) ways, or
> >    they have to put a bunch of their own checking logic after the call to
> >    see if their converters actually worked in order to protect themselves
> >    from that.  Neither really seems ideal to me; I think an error would
> be
> >    better, myself. I'm more of a software developer than a script
> >    writer/analyst though, so its possible others' opinions would differ
> >    (though I'd be a bit surprised by that in this particular case given
> >    the danger).
>
> I see.
> So if we provide a default colConvert, named e.g. colConvertBuiltin,
> which is used if colConvert is not given?
> 1) This respects the 'fail early and loud'.
> 2) The user would get what he asks for
> 3) A colConvert implementation would be able to call colConvertBuiltin
> manually if desired, so have colConvert limited to adding on top of the
> default implementation.
>
> If this is acceptable, I'll prepare a new patch.
>
> Kind regards,
> Kurt
>

	[[alternative HTML version deleted]]


From |@wrence@m|ch@e| @end|ng |rom gene@com  Thu Mar 28 15:25:21 2019
From: |@wrence@m|ch@e| @end|ng |rom gene@com (Michael Lawrence)
Date: Thu, 28 Mar 2019 07:25:21 -0700
Subject: [Rd] topenv of emptyenv
In-Reply-To: <CABtg=Kk7V-toHO_Dm-cPMgPcoEnAS9nbgraaurG67Hi47g58BA@mail.gmail.com>
References: <CAM2gKPaSjQp3Eq4Gy+B7RO-LgwgUoo8RV3JrA452f2v2FZAgLg@mail.gmail.com>
 <23708.45881.551325.849739@stat.math.ethz.ch>
 <CABtg=Kk7V-toHO_Dm-cPMgPcoEnAS9nbgraaurG67Hi47g58BA@mail.gmail.com>
Message-ID: <CAOQ5NyckycSF58epm032Po2LCDJ9LKbMtbvep80_gA60t+csJg@mail.gmail.com>

And it is used profusely by the methods package.

On Thu, Mar 28, 2019 at 4:53 AM G?bor Cs?rdi <csardi.gabor at gmail.com> wrote:

> On Thu, Mar 28, 2019 at 11:43 AM Martin Maechler
> <maechler at stat.math.ethz.ch> wrote:
> [...]
> >
> > Indeed... and as I mentioned I had never actively noticed the
> > use of topenv() at all...
>
> FWIW topenv() is used in a couple of packages, although some of these
> are false positives:
> https://github.com/search?q=org%3Acran+topenv&type=Code
>
> Gabor
>
> [...]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

	[[alternative HTML version deleted]]


From h@w|ckh@m @end|ng |rom gm@||@com  Thu Mar 28 16:12:11 2019
From: h@w|ckh@m @end|ng |rom gm@||@com (Hadley Wickham)
Date: Thu, 28 Mar 2019 10:12:11 -0500
Subject: [Rd] Discrepancy between is.list() and is(x, "list")
In-Reply-To: <CAB8pepxpqGtxC2s0Zs=ZJqqsKa5GVaei1_4-49w0vafmv8J3pA@mail.gmail.com>
References: <CAB8pepyU2qbU7fd1J9J6kyr_657PHFYHoJV6fnvNiHqqjq-24w@mail.gmail.com>
 <EB8494AA-8DAA-4B9A-B636-7E979251EF0C@ucsd.edu>
 <CAB8pepxp9TL18vvHajvSJBXhJY=E13ZWUjebxv6OdgPXcWVPTQ@mail.gmail.com>
 <CAF8bMcZD03odP0yriDjoxYNFzfU3Js_bF6OosavyRxtVY6S44g@mail.gmail.com>
 <CAB8pepxpqGtxC2s0Zs=ZJqqsKa5GVaei1_4-49w0vafmv8J3pA@mail.gmail.com>
Message-ID: <CABdHhvGi0zvSxvs07qXbxR29Yu8XHRYSWg7Y-L+2sXXuwYcumw@mail.gmail.com>

On Wed, Mar 27, 2019 at 6:27 PM Abs Spurdle <spurdle.a at gmail.com> wrote:
>
> > the prison made by ancient design choices
>
> That prison of ancient design choices isn't so bad.
>
> I have no further comments on object oriented semantics.
> However, I'm planning to follow the following design pattern.
>
> If I set the class of an object, I will append the new class to the
> existing class.
>
> #good
> class (object) = c ("something", class (object) )
>
> #bad
> class (object) = "something"
>
> I encourage others to do the same.

I don't think this is a good pattern. It's better to clearly define a
constructor function that checks that `object` is the correct
underlying base type for your class -
https://adv-r.hadley.nz/s3.html#s3-classes.

Hadley

-- 
http://hadley.nz


From j|ox @end|ng |rom mcm@@ter@c@  Thu Mar 28 17:18:40 2019
From: j|ox @end|ng |rom mcm@@ter@c@ (Fox, John)
Date: Thu, 28 Mar 2019 16:18:40 +0000
Subject: [Rd] default for 'signif.stars'
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC836B2CD34@FHSDB2D11-2.csu.mcmaster.ca>

Dear all,

I agree with both Russ and Terry that the significance stars option should default to FALSE. Here's what Sandy Weisberg and I say about significance starts in the current edition of the R Companion to Applied Regression:

	'If you find the ?statistical-significance? asterisks that R prints to the right of the p-values annoying, as we do, you can suppress them, as we will in the remainder of the R Companion, by entering the command: options(show.signif.stars=FALSE).'

This is a rare case in which I find myself disagreeing with Martin, whose arguments are almost invariably careful and considered. In particular, the crude discretization of p-values into several categories seems a poor visualization to me, and in any event "scanning" many p-values quickly, which is the use-case that Martin cites, avoids serious issues of simultaneous inference.

Best,
 John

> -----Original Message-----
> From: R-devel [mailto:r-devel-bounces at r-project.org] On Behalf Of 
> Therneau, Terry M., Ph.D. via R-devel
> Sent: Thursday, March 28, 2019 9:28 AM
> To: r-devel at r-project.org
> Subject: Re: [Rd] default for 'signif.stars'
> 
> The addition of significant stars was, in my opinion, one of the worst 
> defaults ever added to R.?? I would be delighted to see it removed, or 
> at least change the default.? It is one of the few overrides that I 
> have argued to add to our site- wide defaults file.
> 
> My bias comes from 30+ years in a medical statistics career where 
> fighting the disease of "dichotomania" has been an eternal struggle.? 
> Continuous covariates are split in two, nuanced risk scores are 
> thresholded, decisions become yes/no, ....??? Adding stars to output 
> is, to me, simply a gateway drug to this pernicous addiction.?? We shouldn't encourage it.
> 
> Wrt Abe's rant about the Nature article:? I've read the article and 
> found it to be well reasoned, and I can't say the same about the rant.?? 
> The issue in biomedical science is that the p-value has fallen victim to Goodhart's law:
> "When a measure becomes a target, it ceases to be a good measure."? 
> The article argues, and I would agree, that the .05 yes/no decision 
> rule is currently doing more harm than good in biomedical research.?? 
> What to do instead of this is a tough question, but it is fairly clear 
> that the current plan isn't working.?? I have seen many cases of two 
> papers which both found a risk increase of 1.9 for something where one 
> paper claimed "smoking gun" and the other "completely exonerated".?? 
> Do YOU want to take a drug with 2x risk and a p= 0.2 'proof' that it 
> is okay??? Of course, if there is too much to do and too little time, 
> people will find a way to create a shortcut yes/no rule no matter what 
> we preach.?? (We statisticians will do it
> too.)
> 
> Terry T.
> 
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

From @purd|e@@ @end|ng |rom gm@||@com  Fri Mar 29 04:09:51 2019
From: @purd|e@@ @end|ng |rom gm@||@com (Abs Spurdle)
Date: Fri, 29 Mar 2019 16:09:51 +1300
Subject: [Rd] Discrepancy between is.list() and is(x, "list")
In-Reply-To: <CAD4oTHE7gvHrB_WFinvvhTFpNrxyuMBqyjntB58-cu12KprwGA@mail.gmail.com>
References: <CAB8pepyU2qbU7fd1J9J6kyr_657PHFYHoJV6fnvNiHqqjq-24w@mail.gmail.com>
 <EB8494AA-8DAA-4B9A-B636-7E979251EF0C@ucsd.edu>
 <CAB8pepxp9TL18vvHajvSJBXhJY=E13ZWUjebxv6OdgPXcWVPTQ@mail.gmail.com>
 <CAD4oTHFMC=9__Qn=4CVjotHnVDoZii1KBx_ckbZ=74ATgtZYcQ@mail.gmail.com>
 <CAB8pepznVQ6jG2Lx4sJw3GS5xMS7u3jeVn3BxaR9e122NdV=uA@mail.gmail.com>
 <CAD4oTHE7gvHrB_WFinvvhTFpNrxyuMBqyjntB58-cu12KprwGA@mail.gmail.com>
Message-ID: <CAB8pepy8cyQ1pyN72kG2tta+kq9HUMU6XZy=aP8x9LyJOvehzA@mail.gmail.com>

I know I said that I had no further comments on object oriented semantics.
However, I found a contradiction in the R documentation.


Gabriel Becker wrote:
> So, there are implicit classes, but *only when the data object is NOT an
"R object"

In the R Language Definition:
> The R specific function typeof returns the type of an R object.
> Lists have elements, each of which can contain any type of R object
> Symbols refer to R objects.
> Unlike most other R objects, environments are not copied

So, according the the R Language Defintion, all objects in R, are R objects.

However, in the help page for UseMethod(), which you've already mentioned:
> An R object is a data object which has a class attribute (and this can be
tested by is.object).

So, according to this, an object in R, isn't necessarily an R object.

These are contradictory to each other.
And I believe that the R Language Definition is correct.
So, the help page for UseMethod() should be changed to match the language
definition.


Hadley Wickham wrote:
> Understanding the distinction between base types and S3 classes
> is very important to make this sort of question precise

Note that the R Language Definition does not mention either "base types" or
"S3 classes".
So, should I be understanding *your* distinction between them?


Martin Maechler wrote:
> I do agree with Gabe that (in some cases), using
> formal (aka "S4") classes is really what one should do

S4 doesn't always do intuitive things, either.

Try the following example:
> library (Matrix)
> m = Matrix (1:24, 4, 6)

> #expected output
> print (m)

> #not expected output
> print (m, quote=FALSE)

However, I still may consider using S4, especially where I would otherwise
use a named list.

	[[alternative HTML version deleted]]


From g@bembecker @end|ng |rom gm@||@com  Fri Mar 29 05:05:40 2019
From: g@bembecker @end|ng |rom gm@||@com (Gabriel Becker)
Date: Thu, 28 Mar 2019 21:05:40 -0700
Subject: [Rd] Discrepancy between is.list() and is(x, "list")
In-Reply-To: <CAB8pepy8cyQ1pyN72kG2tta+kq9HUMU6XZy=aP8x9LyJOvehzA@mail.gmail.com>
References: <CAB8pepyU2qbU7fd1J9J6kyr_657PHFYHoJV6fnvNiHqqjq-24w@mail.gmail.com>
 <EB8494AA-8DAA-4B9A-B636-7E979251EF0C@ucsd.edu>
 <CAB8pepxp9TL18vvHajvSJBXhJY=E13ZWUjebxv6OdgPXcWVPTQ@mail.gmail.com>
 <CAD4oTHFMC=9__Qn=4CVjotHnVDoZii1KBx_ckbZ=74ATgtZYcQ@mail.gmail.com>
 <CAB8pepznVQ6jG2Lx4sJw3GS5xMS7u3jeVn3BxaR9e122NdV=uA@mail.gmail.com>
 <CAD4oTHE7gvHrB_WFinvvhTFpNrxyuMBqyjntB58-cu12KprwGA@mail.gmail.com>
 <CAB8pepy8cyQ1pyN72kG2tta+kq9HUMU6XZy=aP8x9LyJOvehzA@mail.gmail.com>
Message-ID: <CAD4oTHEX2xiY3KCtwo0k7FeegA-hxXtQsoOUDxp+hX=Gr3-MeQ@mail.gmail.com>

Abs,

Inline.

On Thu, Mar 28, 2019 at 8:10 PM Abs Spurdle <spurdle.a at gmail.com> wrote:

> I know I said that I had no further comments on object oriented semantics.
> However, I found a contradiction in the R documentation.
>
>
> Gabriel Becker wrote:
> > So, there are implicit classes, but *only when the data object is NOT an
> "R object"
>
> In the R Language Definition:
> > The R specific function typeof returns the type of an R object.
> > Lists have elements, each of which can contain any type of R object
> > Symbols refer to R objects.
> > Unlike most other R objects, environments are not copied
>
> So, according the the R Language Defintion, all objects in R, are R
> objects.
>
> However, in the help page for UseMethod(), which you've already mentioned:
> > An R object is a data object which has a class attribute (and this can
> be tested by is.object).
>
> So, according to this, an object in R, isn't necessarily an R object.
>
> These are contradictory to each other.
> And I believe that the R Language Definition is correct.
> So, the help page for UseMethod() should be changed to match the language
> definition.
>

This could be changed, but it seems largely semantic. Its clear from the
UseMethod documentation that it has a specific definition of "R Object",
that it explicitly defines, that it will use throughout that piece of
documentation. Unfortunate, perhaps, but clearly scoped and unambiguous, in
my opinion.

Also, note that if this was changed, its the documentation that would be
changed, to simply use, for example "classed object" instead of "R Object".
The behavior would be identical and would not change so that all "R
objects" (in the language definition sense) would be treated the same by S3
dispatch.


>
> Hadley Wickham wrote:
> > Understanding the distinction between base types and S3 classes
> > is very important to make this sort of question precise
>
> Note that the R Language Definition does not mention either "base types"
> or "S3 classes".
> So, should I be understanding *your* distinction between them?
>

They are not Hadley's distinction, or mine. We (he in more detail and
covering the corner cases like internal and group generics better) are
describing to you how the system actually works, and why you got the
results which so surprised you.

I think we've done so at this point however, and your phrasing makes it
seem like you're looking for an argument, which I (and I suspect others on
this list) have no interest in, rather than to learn, which I was happy to
try to help you with, so with respect I'll not be engaging you more on this
topic.


>
> Martin Maechler wrote:
> > I do agree with Gabe that (in some cases), using
> > formal (aka "S4") classes is really what one should do
>
> S4 doesn't always do intuitive things, either.
>
> Try the following example:
> > library (Matrix)
> > m = Matrix (1:24, 4, 6)
>
> > #expected output
> > print (m)
>
> > #not expected output
> > print (m, quote=FALSE)
>

So the correct way to print S4 objects is with show(), not print. A
cursory, non-comprehensive look at print.c (do_defaultprint) suggests to me
that print (or rather the c code called by print.default) handles S4
objects when the print call can essentially be transformed in-place to a
show call and then evaluated. That is the case where no additional
arguments are passed to print:

  if (*noParam*s && IS_S4_OBJECT(x) && isMethodsDispatchOn())
PrintObject(x, &data);
 else
PrintValueRec(x, &data);


So it has nothing to do with what argument is used, or the quote argument
in particular, at all:

>* print(x, quote = TRUE)*

<S4 Type Object>

attr(,"x")

 [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24

attr(,"Dim")

[1] 4 6

attr(,"Dimnames")

attr(,"Dimnames")[[1]]

NULL


attr(,"Dimnames")[[2]]

NULL


attr(,"factors")

list()

attr(,"class")

[1] "dgeMatrix"

attr(,"class")attr(,"package")

[1] "Matrix"


> *print(x, quote = FALSE)*

<S4 Type Object>

attr(,"x")

 [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24

attr(,"Dim")

[1] 4 6

attr(,"Dimnames")

attr(,"Dimnames")[[1]]

NULL


attr(,"Dimnames")[[2]]

NULL


attr(,"factors")

list()

attr(,"class")

[1] dgeMatrix

attr(,"class")attr(,"package")

[1] Matrix


> *print(x, digits = 5)*

<S4 Type Object>

attr(,"x")

 [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24

attr(,"Dim")

[1] 4 6

attr(,"Dimnames")

attr(,"Dimnames")[[1]]

NULL


attr(,"Dimnames")[[2]]

NULL


attr(,"factors")

list()

attr(,"class")

[1] "dgeMatrix"

attr(,"class")attr(,"package")

[1] "Matrix"


But basically, don't call print on S4 objects, call show, and everything
should work fine.

Best,
~G




> However, I still may consider using S4, especially where I would otherwise
> use a named list.
>
>
>

	[[alternative HTML version deleted]]


From @@ren@t@@c|y@n @end|ng |rom |@t@@c@@t  Thu Mar 28 17:02:10 2019
From: @@ren@t@@c|y@n @end|ng |rom |@t@@c@@t (Saren Tasciyan)
Date: Thu, 28 Mar 2019 17:02:10 +0100
Subject: [Rd] Bug in the "reformulate" function in stats package
In-Reply-To: <ac491662-1aad-3775-1936-9e2694da50e6@ist.ac.at>
References: <ac491662-1aad-3775-1936-9e2694da50e6@ist.ac.at>
Message-ID: <9409b485-7a3b-0f2c-201e-7ef2bde1de86@ist.ac.at>

Hi,

I have found a bug in reformulate function and have a solution for it. I 
was wondering, where I can submit it?

Best,

Saren

-- 
Saren Tasciyan
/PhD Student / Sixt Group/
Institute of Science and Technology Austria
Am Campus 1
3400 Klosterneuburg, Austria


From men@ur@t|on|@t @end|ng |rom gm@||@com  Thu Mar 28 21:03:43 2019
From: men@ur@t|on|@t @end|ng |rom gm@||@com (Andrew Robinson)
Date: Fri, 29 Mar 2019 07:03:43 +1100
Subject: [Rd] default for 'signif.stars'
In-Reply-To: <4367c6f6156d4a0cb64549e7003c39e4@ME2PR01MB3922.ausprd01.prod.outlook.com>
References: <DM6PR04MB438095FB858DADCCAE2506A8F1580@DM6PR04MB4380.namprd04.prod.outlook.com>
 <4367c6f6156d4a0cb64549e7003c39e4@ME2PR01MB3922.ausprd01.prod.outlook.com>
Message-ID: <CAHyGmd6aorJpd4nCXvFicM-JCLFDZWDyxFxSpcR4x95pZnLeMQ@mail.gmail.com>

Hi Martin,

I take your point - but I'd argue that significance stars are a clumsy
solution to the very real problem that you outline, and their inclusion as
a default sends a signal about their appropriateness that I would prefer R
not to endorse.

My preference (to the extent that it matters) would be to see the
significance stars be an option but not a default one, and the addition of
different functionality to handle the many-predictor problem, perhaps a new
summary that more efficiently provides more useful information.

If we were to invent lm() now, how would we solve the problem of big P?  I
don't think we would use stars.

Cheers,

Andrew




On Thu, 28 Mar 2019 at 20:19, Martin Maechler <maechler at stat.math.ethz.ch>
wrote:

> >>>>> Lenth, Russell V
> >>>>>     on Wed, 27 Mar 2019 00:06:08 +0000 writes:
>
>     > Dear R-Devel, As I am sure many of you know, a special
>     > issue of The American Statistician just came out, and its
>     > theme is the [mis]use of P values and the many common ways
>     > in which they are abused. The lead editorial in that issue
>     > mentions the 2014 ASA guidelines on P values, and goes one
>     > step further, by now recommending that the words
>     > "statistically significant" and related simplistic
>     > interpretations no longer be used. There is much
>     > discussion of the problems with drawing "bright lines"
>     > concerning P values.
>
>     > This is the position of a US society, but my sense is that
>     > the statistical community worldwide is pretty much on the
>     > same page.
>
>     > Meanwhile, functions such as 'print.summary.lm' and
>     > 'print.anova' have an argument 'signif.stars' that really
>     > does involve drawing bright lines when it is set to
>     > TRUE. And the default setting for the "show.signif.stars"
>     > option is TRUE. Isn't it time to at least make
>     > "show.signif.stars" default to FALSE? And, indeed, to
>     > consider deprecating those 'signif.stars' options
>     > altogether?
>
> Dear Russ,
> Abs has already given good reasons why this article may well be
> considered problematic.
>
> However, I think you and (many but not all) others who've raised
> this issue before you, slightly miss the following point.
>
> If p-values are misleading they should not be shown (and hence
> the signif.stars neither.
> That has been the approach adopted e.g., in the lme4 package
> *AND* has been an approach originally used in S and I think
> parts of R as well, in more places than now, notably, e.g., for
> print( summary(<glm>) ).
>
> Fact is that users will write wrappers and their own packages
> just to get to p values, even in very doubtful cases...
> But anyway that (p values or not) is a different discussion
> which has some value.
>
> You however focus on the "significance stars".  I've argued for
> years why they are useful, as they are just a simple
> visualization of p values, and saving a lot of human time when
> there are many (fixed) effects looked at simultaneously.
> Why should users have to visually scan 20 or 50 numbers?  In
> modern Data analysis they should never have to but rather look
> at a visualization of those numbers. ... and that's what
> significance stars are, not more, nor less.
>
> Martin
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

	[[alternative HTML version deleted]]


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Fri Mar 29 09:29:03 2019
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Fri, 29 Mar 2019 09:29:03 +0100
Subject: [Rd] Bug in the "reformulate" function in stats package
In-Reply-To: <9409b485-7a3b-0f2c-201e-7ef2bde1de86@ist.ac.at>
References: <ac491662-1aad-3775-1936-9e2694da50e6@ist.ac.at>
 <9409b485-7a3b-0f2c-201e-7ef2bde1de86@ist.ac.at>
Message-ID: <23709.55119.213555.244342@stat.math.ethz.ch>

>>>>> Saren Tasciyan 
>>>>>     on Thu, 28 Mar 2019 17:02:10 +0100 writes:

    > Hi,
    > I have found a bug in reformulate function and have a solution for it. I 
    > was wondering, where I can submit it?

    > Best,
    > Saren


Well, you could have given a small reproducible example
depicting the bug, notably when posting here: 
Just a prose text with no R code or other technical content is
almost always not really appropriate fo the R-devel mailing list.

Further, in such a case you should google a bit and hopefully
have found
		https://www.r-project.org/bugs.html

which also mention reproducibility (and many more useful things).

Then it also tells you about R's bug repository, also called
"R's bugzilla" at https://bugs.r-project.org/

and if you are diligent (but here, I'd say bugzilla is
(configured?) far from ideal), you'd also find bug PR#17359

   https://bugs.r-project.org/bugzilla/show_bug.cgi?id=17359

which was reported already on Nov 2017 .. and only fixed
yesterday (in the "cleanup old bugs" process that happens
often before the big new spring release of R).

So is your bug the same as that one?

Martin

    > -- 
    > Saren Tasciyan
    > /PhD Student / Sixt Group/
    > Institute of Science and Technology Austria
    > Am Campus 1
    > 3400 Klosterneuburg, Austria

    > ______________________________________________
    > R-devel at r-project.org mailing list
    > https://stat.ethz.ch/mailman/listinfo/r-devel


From j@me@@|@he@ter @end|ng |rom gm@||@com  Fri Mar 29 16:19:19 2019
From: j@me@@|@he@ter @end|ng |rom gm@||@com (Jim Hester)
Date: Fri, 29 Mar 2019 11:19:19 -0400
Subject: [Rd] Use of C++ in Packages
Message-ID: <CAD6tx97B3zHikY9Cs+DnMXdOFFUn76ONoTupZT8QTaqo7+xZCA@mail.gmail.com>

First, thank you to Tomas for writing his recent post[0] on the R
developer blog. It raised important issues in interfacing R's C API
and C++ code.

However I do _not_ think the conclusion reached in the post is helpful
  > don?t use C++ to interface with R

There are now more than 1,600 packages on CRAN using C++, the time is
long past when that type of warning is going to be useful to the R
community.

These same issues will also occur with any newer language (such as
Rust or Julia[1]) which uses RAII to manage resources and tries to
interface with R. It doesn't seem a productive way forward for R to
say it can't interface with these languages without first doing
expensive copies into an intermediate heap.

The advice to avoid C++ is also antithetical to John Chambers vision
of first S and R as a interface language (from Extending R [2])

  > The *interface* principle has always been central to R and to S
before. An interface to subroutines was _the_ way to extend the first
version of S. Subroutine interfaces have continued to be central to R.

The book also has extensive sections on both C++ (via Rcpp) and Julia,
so clearly John thinks these are legitimate ways to extend R.

So if 'don't use C++' is not realistic and the current R API does not
allow safe use of C++ exceptions what are the alternatives?

One thing we could do is look how this is handled in other languages
written in C which also use longjmp for errors.

Lua is one example, they provide an alternative interface;
lua_pcall[3] and lua_cpcall[4] which wrap a normal lua call and return
an error code rather long jumping. These interfaces can then be safely
wrapped by RAII - exception based languages.

This alternative error code interface is not just useful for C++, but
also for resource cleanup in C, it is currently non-trivial to handle
cleanup in all the possible cases a longjmp can occur (interrupts,
warnings, custom conditions, timeouts any allocation etc.) even with R
finalizers.

It is past time for R to consider a non-jumpy C interface, so it can
continue to be used as an effective interface to programming routines
in the years to come.

[0]: https://developer.r-project.org/Blog/public/2019/03/28/use-of-c---in-packages/
[1]: https://github.com/JuliaLang/julia/issues/28606
[2]: https://doi.org/10.1201/9781315381305
[3]: http://www.lua.org/manual/5.1/manual.html#lua_pcall
[4]: http://www.lua.org/manual/5.1/manual.html#lua_cpcall


From @@ren@t@@c|y@n @end|ng |rom |@t@@c@@t  Fri Mar 29 16:38:05 2019
From: @@ren@t@@c|y@n @end|ng |rom |@t@@c@@t (Saren Tasciyan)
Date: Fri, 29 Mar 2019 16:38:05 +0100
Subject: [Rd] Bug in the "reformulate" function in stats package
In-Reply-To: <23709.55119.213555.244342@stat.math.ethz.ch>
References: <ac491662-1aad-3775-1936-9e2694da50e6@ist.ac.at>
 <9409b485-7a3b-0f2c-201e-7ef2bde1de86@ist.ac.at>
 <23709.55119.213555.244342@stat.math.ethz.ch>
Message-ID: <765cd87b-98d6-b23f-9a58-ad817fa5c6e5@ist.ac.at>

Well, first I can't sign in bugzilla myself, that is why I wrote here 
first. Also, I don't know if I have the time at the moment to provide 
tests, multiple examples or more. If that is not ok or welcomed, that is 
fine, I can come back, whenever I have more time to properly report the bug.

I didn't find the existing bug report, sorry for that.

Yes, it is related. My problem was that I have column names with spaces 
and current solution doesn't solve it. I have a solution, which works 
for me and maybe also for others.

Either, someone can register me to bugzilla or I can post it here, which 
could give some direction to developers. I don't mind whichever is 
preferred here.

Best,

Saren


On 29.03.19 09:29, Martin Maechler wrote:
>>>>>> Saren Tasciyan
>>>>>>      on Thu, 28 Mar 2019 17:02:10 +0100 writes:
>      > Hi,
>      > I have found a bug in reformulate function and have a solution for it. I
>      > was wondering, where I can submit it?
>
>      > Best,
>      > Saren
>
>
> Well, you could have given a small reproducible example
> depicting the bug, notably when posting here:
> Just a prose text with no R code or other technical content is
> almost always not really appropriate fo the R-devel mailing list.
>
> Further, in such a case you should google a bit and hopefully
> have found
> 		https://www.r-project.org/bugs.html
>
> which also mention reproducibility (and many more useful things).
>
> Then it also tells you about R's bug repository, also called
> "R's bugzilla" at https://bugs.r-project.org/
>
> and if you are diligent (but here, I'd say bugzilla is
> (configured?) far from ideal), you'd also find bug PR#17359
>
>     https://bugs.r-project.org/bugzilla/show_bug.cgi?id=17359
>
> which was reported already on Nov 2017 .. and only fixed
> yesterday (in the "cleanup old bugs" process that happens
> often before the big new spring release of R).
>
> So is your bug the same as that one?
>
> Martin
>
>      > --
>      > Saren Tasciyan
>      > /PhD Student / Sixt Group/
>      > Institute of Science and Technology Austria
>      > Am Campus 1
>      > 3400 Klosterneuburg, Austria
>
>      > ______________________________________________
>      > R-devel at r-project.org mailing list
>      > https://stat.ethz.ch/mailman/listinfo/r-devel
-- 
Saren Tasciyan
/PhD Student / Sixt Group/
Institute of Science and Technology Austria
Am Campus 1
3400 Klosterneuburg, Austria



From pro|jcn@@h @end|ng |rom gm@||@com  Fri Mar 29 16:54:47 2019
From: pro|jcn@@h @end|ng |rom gm@||@com (J C Nash)
Date: Fri, 29 Mar 2019 11:54:47 -0400
Subject: [Rd] Bug in the "reformulate" function in stats package
In-Reply-To: <765cd87b-98d6-b23f-9a58-ad817fa5c6e5@ist.ac.at>
References: <ac491662-1aad-3775-1936-9e2694da50e6@ist.ac.at>
 <9409b485-7a3b-0f2c-201e-7ef2bde1de86@ist.ac.at>
 <23709.55119.213555.244342@stat.math.ethz.ch>
 <765cd87b-98d6-b23f-9a58-ad817fa5c6e5@ist.ac.at>
Message-ID: <bad24743-b6e1-f4cd-97a5-8047c27c6707@gmail.com>

The main thing is to post the "small reproducible example".

My (rather long term experience) can be written

  if (exists("reproducible example") ) {
     DeveloperFixHappens()
  } else {
     NULL
  }

JN

On 2019-03-29 11:38 a.m., Saren Tasciyan wrote:
> Well, first I can't sign in bugzilla myself, that is why I wrote here first. Also, I don't know if I have the time at
> the moment to provide tests, multiple examples or more. If that is not ok or welcomed, that is fine, I can come back,
> whenever I have more time to properly report the bug.
> 
> I didn't find the existing bug report, sorry for that.
> 
> Yes, it is related. My problem was that I have column names with spaces and current solution doesn't solve it. I have a
> solution, which works for me and maybe also for others.
> 
> Either, someone can register me to bugzilla or I can post it here, which could give some direction to developers. I
> don't mind whichever is preferred here.
> 
> Best,
> 
> Saren
> 
> 
> On 29.03.19 09:29, Martin Maechler wrote:
>>>>>>> Saren Tasciyan
>>>>>>> ???? on Thu, 28 Mar 2019 17:02:10 +0100 writes:
>> ???? > Hi,
>> ???? > I have found a bug in reformulate function and have a solution for it. I
>> ???? > was wondering, where I can submit it?
>>
>> ???? > Best,
>> ???? > Saren
>>
>>
>> Well, you could have given a small reproducible example
>> depicting the bug, notably when posting here:
>> Just a prose text with no R code or other technical content is
>> almost always not really appropriate fo the R-devel mailing list.
>>
>> Further, in such a case you should google a bit and hopefully
>> have found
>> ??????? https://www.r-project.org/bugs.html
>>
>> which also mention reproducibility (and many more useful things).
>>
>> Then it also tells you about R's bug repository, also called
>> "R's bugzilla" at https://bugs.r-project.org/
>>
>> and if you are diligent (but here, I'd say bugzilla is
>> (configured?) far from ideal), you'd also find bug PR#17359
>>
>> ??? https://bugs.r-project.org/bugzilla/show_bug.cgi?id=17359
>>
>> which was reported already on Nov 2017 .. and only fixed
>> yesterday (in the "cleanup old bugs" process that happens
>> often before the big new spring release of R).
>>
>> So is your bug the same as that one?
>>
>> Martin
>>
>> ???? > --
>> ???? > Saren Tasciyan
>> ???? > /PhD Student / Sixt Group/
>> ???? > Institute of Science and Technology Austria
>> ???? > Am Campus 1
>> ???? > 3400 Klosterneuburg, Austria
>>
>> ???? > ______________________________________________
>> ???? > R-devel at r-project.org mailing list
>> ???? > https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel


From bbo|ker @end|ng |rom gm@||@com  Fri Mar 29 17:34:50 2019
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Fri, 29 Mar 2019 12:34:50 -0400
Subject: [Rd] Bug in the "reformulate" function in stats package
In-Reply-To: <bad24743-b6e1-f4cd-97a5-8047c27c6707@gmail.com>
References: <ac491662-1aad-3775-1936-9e2694da50e6@ist.ac.at>
 <9409b485-7a3b-0f2c-201e-7ef2bde1de86@ist.ac.at>
 <23709.55119.213555.244342@stat.math.ethz.ch>
 <765cd87b-98d6-b23f-9a58-ad817fa5c6e5@ist.ac.at>
 <bad24743-b6e1-f4cd-97a5-8047c27c6707@gmail.com>
Message-ID: <0c567c84-5c27-128c-584c-022d8d1f6892@gmail.com>

  I suspect that the issue is addressed (obliquely) in the examples,
which shows that variables with spaces in them (or otherwise
'non-syntactic', i.e. not satisfying the constraints of legal R symbols)
can be handled by protecting them with backticks  (``)

 ## using non-syntactic names:
     reformulate(c("`P/E`", "`% Growth`"), response = as.name("+-"))

It seems to me there could be room for a *documentation* patch (stating
explicitly that if termlabels has length > 1 its elements are
concatenated with "+", and explicitly stating that non-syntactic names
must be protected with back-ticks).  (There is a little bit of obscurity
in the fact that the elements of termlabels don't have to be
syntactically valid names: many will be included in formulas if they can
be interpreted as *parseable* expressions, e.g. reformulate("x<2"))

  I would be happy to give it a shot if the consensus is that it would
be worthwhile.

   One workaround to the OP's problem is below (may be worth including
as an example in docs)

> z <- c("a variable","another variable")
> reformulate(z)
Error in parse(text = termtext, keep.source = FALSE) :
  <text>:1:6: unexpected symbol
1:  ~ a variable
         ^
> reformulate(sprintf("`%s`",z))
~`a variable` + `another variable`




On 2019-03-29 11:54 a.m., J C Nash wrote:
> The main thing is to post the "small reproducible example".
> 
> My (rather long term experience) can be written
> 
>   if (exists("reproducible example") ) {
>      DeveloperFixHappens()
>   } else {
>      NULL
>   }
> 
> JN
> 
> On 2019-03-29 11:38 a.m., Saren Tasciyan wrote:
>> Well, first I can't sign in bugzilla myself, that is why I wrote here first. Also, I don't know if I have the time at
>> the moment to provide tests, multiple examples or more. If that is not ok or welcomed, that is fine, I can come back,
>> whenever I have more time to properly report the bug.
>>
>> I didn't find the existing bug report, sorry for that.
>>
>> Yes, it is related. My problem was that I have column names with spaces and current solution doesn't solve it. I have a
>> solution, which works for me and maybe also for others.
>>
>> Either, someone can register me to bugzilla or I can post it here, which could give some direction to developers. I
>> don't mind whichever is preferred here.
>>
>> Best,
>>
>> Saren
>>
>>
>> On 29.03.19 09:29, Martin Maechler wrote:
>>>>>>>> Saren Tasciyan
>>>>>>>> ???? on Thu, 28 Mar 2019 17:02:10 +0100 writes:
>>> ???? > Hi,
>>> ???? > I have found a bug in reformulate function and have a solution for it. I
>>> ???? > was wondering, where I can submit it?
>>>
>>> ???? > Best,
>>> ???? > Saren
>>>
>>>
>>> Well, you could have given a small reproducible example
>>> depicting the bug, notably when posting here:
>>> Just a prose text with no R code or other technical content is
>>> almost always not really appropriate fo the R-devel mailing list.
>>>
>>> Further, in such a case you should google a bit and hopefully
>>> have found
>>> ??????? https://www.r-project.org/bugs.html
>>>
>>> which also mention reproducibility (and many more useful things).
>>>
>>> Then it also tells you about R's bug repository, also called
>>> "R's bugzilla" at https://bugs.r-project.org/
>>>
>>> and if you are diligent (but here, I'd say bugzilla is
>>> (configured?) far from ideal), you'd also find bug PR#17359
>>>
>>> ??? https://bugs.r-project.org/bugzilla/show_bug.cgi?id=17359
>>>
>>> which was reported already on Nov 2017 .. and only fixed
>>> yesterday (in the "cleanup old bugs" process that happens
>>> often before the big new spring release of R).
>>>
>>> So is your bug the same as that one?
>>>
>>> Martin
>>>
>>> ???? > --
>>> ???? > Saren Tasciyan
>>> ???? > /PhD Student / Sixt Group/
>>> ???? > Institute of Science and Technology Austria
>>> ???? > Am Campus 1
>>> ???? > 3400 Klosterneuburg, Austria
>>>
>>> ???? > ______________________________________________
>>> ???? > R-devel at r-project.org mailing list
>>> ???? > https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From @|mon@urb@nek @end|ng |rom R-project@org  Fri Mar 29 18:15:53 2019
From: @|mon@urb@nek @end|ng |rom R-project@org (Simon Urbanek)
Date: Fri, 29 Mar 2019 13:15:53 -0400
Subject: [Rd] Use of C++ in Packages
In-Reply-To: <CAD6tx97B3zHikY9Cs+DnMXdOFFUn76ONoTupZT8QTaqo7+xZCA@mail.gmail.com>
References: <CAD6tx97B3zHikY9Cs+DnMXdOFFUn76ONoTupZT8QTaqo7+xZCA@mail.gmail.com>
Message-ID: <DA086757-A81C-4E25-AE4D-2E4BCA187941@R-project.org>

Jim,

I think the main point of Tomas' post was to alert R users to the fact that there are very serious issues that you have to understand when interfacing R from C++. Using C++ code from R is fine, in many cases you only want to access R data, use some library or compute in C++ and return results. Such use-cases are completely fine in C++ as they don't need to trigger the issues mentioned and it should be made clear that it was not what Tomas' blog was about.

I agree with Tomas that it is safer to give an advice to not use C++ to call R API since C++ may give a false impression that you don't need to know what you're doing. Note that it is possible to avoid longjmps by using R_ExecWithCleanup() which can catch any longjmps from the called function. So if you know what you're doing you can make things work. I think the issue here is not necessarily lack of tools, it is lack of knowledge - which is why I think Tomas' post is so important.

Cheers,
Simon


> On Mar 29, 2019, at 11:19 AM, Jim Hester <james.f.hester at gmail.com> wrote:
> 
> First, thank you to Tomas for writing his recent post[0] on the R
> developer blog. It raised important issues in interfacing R's C API
> and C++ code.
> 
> However I do _not_ think the conclusion reached in the post is helpful
>> don?t use C++ to interface with R
> 
> There are now more than 1,600 packages on CRAN using C++, the time is
> long past when that type of warning is going to be useful to the R
> community.
> 
> These same issues will also occur with any newer language (such as
> Rust or Julia[1]) which uses RAII to manage resources and tries to
> interface with R. It doesn't seem a productive way forward for R to
> say it can't interface with these languages without first doing
> expensive copies into an intermediate heap.
> 
> The advice to avoid C++ is also antithetical to John Chambers vision
> of first S and R as a interface language (from Extending R [2])
> 
>> The *interface* principle has always been central to R and to S
> before. An interface to subroutines was _the_ way to extend the first
> version of S. Subroutine interfaces have continued to be central to R.
> 
> The book also has extensive sections on both C++ (via Rcpp) and Julia,
> so clearly John thinks these are legitimate ways to extend R.
> 
> So if 'don't use C++' is not realistic and the current R API does not
> allow safe use of C++ exceptions what are the alternatives?
> 
> One thing we could do is look how this is handled in other languages
> written in C which also use longjmp for errors.
> 
> Lua is one example, they provide an alternative interface;
> lua_pcall[3] and lua_cpcall[4] which wrap a normal lua call and return
> an error code rather long jumping. These interfaces can then be safely
> wrapped by RAII - exception based languages.
> 
> This alternative error code interface is not just useful for C++, but
> also for resource cleanup in C, it is currently non-trivial to handle
> cleanup in all the possible cases a longjmp can occur (interrupts,
> warnings, custom conditions, timeouts any allocation etc.) even with R
> finalizers.
> 
> It is past time for R to consider a non-jumpy C interface, so it can
> continue to be used as an effective interface to programming routines
> in the years to come.
> 
> [0]: https://developer.r-project.org/Blog/public/2019/03/28/use-of-c---in-packages/
> [1]: https://github.com/JuliaLang/julia/issues/28606
> [2]: https://doi.org/10.1201/9781315381305
> [3]: http://www.lua.org/manual/5.1/manual.html#lua_pcall
> [4]: http://www.lua.org/manual/5.1/manual.html#lua_cpcall
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 


From kev|nu@hey @end|ng |rom gm@||@com  Fri Mar 29 22:01:44 2019
From: kev|nu@hey @end|ng |rom gm@||@com (Kevin Ushey)
Date: Fri, 29 Mar 2019 14:01:44 -0700
Subject: [Rd] Use of C++ in Packages
In-Reply-To: <DA086757-A81C-4E25-AE4D-2E4BCA187941@R-project.org>
References: <CAD6tx97B3zHikY9Cs+DnMXdOFFUn76ONoTupZT8QTaqo7+xZCA@mail.gmail.com>
 <DA086757-A81C-4E25-AE4D-2E4BCA187941@R-project.org>
Message-ID: <CAJXgQP2OuQ98zzj-8CNSFVBTv4OU0tsA12HH++x=r4vpxi7Osw@mail.gmail.com>

I think it's also worth saying that some of these issues affect C code
as well; e.g. this is not safe:

    FILE* f = fopen(...);
    Rf_eval(...);
    fclose(f);

whereas the C++ equivalent would likely handle closing of the file in
the destructor. In other words, I think many users just may not be
cognizant of the fact that most R APIs can longjmp, and what that
implies for cleanup of allocated resources. R_alloc() may help solve
the issue specifically for memory allocations, but for any library
interface that has a 'open' and 'close' step, the same sort of issue
will arise.

What I believe we should do, and what Rcpp has made steps towards, is
make it possible to interact with some subset of the R API safely from
C++ contexts. This has always been possible with e.g. R_ToplevelExec()
and R_ExecWithCleanup(), and now things are even better with
R_UnwindProtect(). In theory, as a prototype, an R package could
provide a 'safe' C++ interface to the R API using R_UnwindProtect()
and friends as appropriate, and client packages could import and link
to that package to gain access to the interface. Code generators (as
Rcpp Attributes does) can handle some of the pain in these interfaces,
so that users are mostly insulated from the nitty gritty details.

I agree that the content of Tomas's post is very helpful, especially
since I expect many R programmers who dip their toes into the C++
world are not aware of the caveats of talking to R from C++. However,
I don't think it's helpful to recommend "don't use C++"; rather, I
believe the question should be, "what can we do to make it possible to
easily and safely interact with R from C++?". Because, as I understand
it, all of the problems raised are solvable: either through a
well-defined C++ interface, or through better education.

I'll add my own opinion: writing correct C code is an incredibly
difficult task. C++, while obviously not perfect, makes things
substantially easier with tools like RAII, the STL, smart pointers,
and so on. And I strongly believe that C++ (with Rcpp) is still a
better choice than C for new users who want to interface with R from
compiled code.

tl;dr: I (and I think most others) just wish the summary had a more
positive outlook for the future of C++ with R.

Best,
Kevin

On Fri, Mar 29, 2019 at 10:16 AM Simon Urbanek
<simon.urbanek at r-project.org> wrote:
>
> Jim,
>
> I think the main point of Tomas' post was to alert R users to the fact that there are very serious issues that you have to understand when interfacing R from C++. Using C++ code from R is fine, in many cases you only want to access R data, use some library or compute in C++ and return results. Such use-cases are completely fine in C++ as they don't need to trigger the issues mentioned and it should be made clear that it was not what Tomas' blog was about.
>
> I agree with Tomas that it is safer to give an advice to not use C++ to call R API since C++ may give a false impression that you don't need to know what you're doing. Note that it is possible to avoid longjmps by using R_ExecWithCleanup() which can catch any longjmps from the called function. So if you know what you're doing you can make things work. I think the issue here is not necessarily lack of tools, it is lack of knowledge - which is why I think Tomas' post is so important.
>
> Cheers,
> Simon
>
>
> > On Mar 29, 2019, at 11:19 AM, Jim Hester <james.f.hester at gmail.com> wrote:
> >
> > First, thank you to Tomas for writing his recent post[0] on the R
> > developer blog. It raised important issues in interfacing R's C API
> > and C++ code.
> >
> > However I do _not_ think the conclusion reached in the post is helpful
> >> don?t use C++ to interface with R
> >
> > There are now more than 1,600 packages on CRAN using C++, the time is
> > long past when that type of warning is going to be useful to the R
> > community.
> >
> > These same issues will also occur with any newer language (such as
> > Rust or Julia[1]) which uses RAII to manage resources and tries to
> > interface with R. It doesn't seem a productive way forward for R to
> > say it can't interface with these languages without first doing
> > expensive copies into an intermediate heap.
> >
> > The advice to avoid C++ is also antithetical to John Chambers vision
> > of first S and R as a interface language (from Extending R [2])
> >
> >> The *interface* principle has always been central to R and to S
> > before. An interface to subroutines was _the_ way to extend the first
> > version of S. Subroutine interfaces have continued to be central to R.
> >
> > The book also has extensive sections on both C++ (via Rcpp) and Julia,
> > so clearly John thinks these are legitimate ways to extend R.
> >
> > So if 'don't use C++' is not realistic and the current R API does not
> > allow safe use of C++ exceptions what are the alternatives?
> >
> > One thing we could do is look how this is handled in other languages
> > written in C which also use longjmp for errors.
> >
> > Lua is one example, they provide an alternative interface;
> > lua_pcall[3] and lua_cpcall[4] which wrap a normal lua call and return
> > an error code rather long jumping. These interfaces can then be safely
> > wrapped by RAII - exception based languages.
> >
> > This alternative error code interface is not just useful for C++, but
> > also for resource cleanup in C, it is currently non-trivial to handle
> > cleanup in all the possible cases a longjmp can occur (interrupts,
> > warnings, custom conditions, timeouts any allocation etc.) even with R
> > finalizers.
> >
> > It is past time for R to consider a non-jumpy C interface, so it can
> > continue to be used as an effective interface to programming routines
> > in the years to come.
> >
> > [0]: https://developer.r-project.org/Blog/public/2019/03/28/use-of-c---in-packages/
> > [1]: https://github.com/JuliaLang/julia/issues/28606
> > [2]: https://doi.org/10.1201/9781315381305
> > [3]: http://www.lua.org/manual/5.1/manual.html#lua_pcall
> > [4]: http://www.lua.org/manual/5.1/manual.html#lua_cpcall
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From @purd|e@@ @end|ng |rom gm@||@com  Fri Mar 29 22:54:17 2019
From: @purd|e@@ @end|ng |rom gm@||@com (Abs Spurdle)
Date: Sat, 30 Mar 2019 10:54:17 +1300
Subject: [Rd] default for 'signif.stars'
Message-ID: <CAB8pepzC96WWVErdVTLNAs-2cj_HQ9jSP3QrYR63J_XGHXQtZQ@mail.gmail.com>

> If we were to invent lm() now, how would we solve the problem of big P?
> I don't think we would use stars.

Assuming that this is a good idea in the first place, here's a simple
solution, in the context of backward selection.

One could sort the terms, from lowest p-value to highest p-value.
If each variable is associated with more than one parameter (e.g.
interactions), then it complicates things, however, the same principle
applies.

It would be possible to group terms, based on their significance level,
however, this is unlikely to be popular. You could also use a head() and
tail() approach, something I've been using a lot, in other contexts.

However, I think a better solution is to automate the backward selection
process, however, that requires decision rules, and we're back to the
original problem.

	[[alternative HTML version deleted]]


From g@bembecker @end|ng |rom gm@||@com  Fri Mar 29 23:20:07 2019
From: g@bembecker @end|ng |rom gm@||@com (Gabriel Becker)
Date: Fri, 29 Mar 2019 15:20:07 -0700
Subject: [Rd] Use of C++ in Packages
In-Reply-To: <CAD6tx97B3zHikY9Cs+DnMXdOFFUn76ONoTupZT8QTaqo7+xZCA@mail.gmail.com>
References: <CAD6tx97B3zHikY9Cs+DnMXdOFFUn76ONoTupZT8QTaqo7+xZCA@mail.gmail.com>
Message-ID: <CAD4oTHEHfqZ=O849XVqWXHzkS9VCMFepkwo8i49TuOAUEsFEFA@mail.gmail.com>

Hi Jim (et al.),

Comments inline (and assume any offense was unintended, these kinds of
things can be tricky to talk about).

On Fri, Mar 29, 2019 at 8:19 AM Jim Hester <james.f.hester at gmail.com> wrote:

> First, thank you to Tomas for writing his recent post[0] on the R
> developer blog. It raised important issues in interfacing R's C API
> and C++ code.
>
> However I do _not_ think the conclusion reached in the post is helpful
>   > don?t use C++ to interface with R
>

I was a bit surprised a the the strength of this too but its understandable
given the content/motivation of the post.

My personal take away, without putting any words in Tomas' or R-core's
mouths at all, is that the crux here is that using c++ in R packages safely
is a LOT less trivial than people in the wider R community think it is,
these days. Or rather, there are things you can do safely quite easily when
using c++ in an R package, and things you can't, but that distincton a)
isn't really on many people's radar, and b) isn't super trivial to identify
at any given time, and c) depends on internal implementation details so
isn't stable / safe to rely on across time anyway. There are a lot of
reasons for a), and none of them, nor anything else I'm about to say,
constitute criticisms of Rcpp or its developers.

I've always thought that we as tool/software developers in this space
should make things seem as easy and convenient to users as they
can/intrinsically are, *but not easier*. I don't know how popular that
second part I put in there is generally, but personally I think its true
and pretty important not to leave off. I read Tomas' past as suggesting
that as a community, without pointing fingers or laying any individual
blame,  have unintentionally crossed "as easy as it actually is/can be to
do right" line when it comes to the impression we give to novice/journeyman
package developers regarding using c++to interact with the R internals. I
honestly claim little familiarity with c++ but it seems like Tomas is the
relevant expert on both it and hard-core details about how aspects of the R
internals work so if he tells us that that has happened, we should probably
listen.


> There are now more than 1,600 packages on CRAN using C++, the time is
> long past when that type of warning is going to be useful to the R
> community.
>

Here I disagree here pretty strongly. I think the warning is very useful -
unless these issues were widely known before the post (my impression is
that they weren't) - and ignoring its contents or encouraging others to do
so as influential members of the R community would be irresponsible.

I mean, the reality of the situation as it exists now is more or less (I'd
assume a great deal 'more' than 'less', personally) what Tomas described,
right? Furthermore, regardless of what changes may come in the future, it
seems very unlikely any of them will be in this coming release (since grand
feature freeze is like, today?) so we're talking a year out, at LEAST.
Given that, this advice, or at least a more nuanced stance that gives the
information from the post proper weight and is different from the
prevailing sentiment now, basically has to be realistic in the short term.

At the very least I think the post tells us that we need to be really
careful as a community with the "you want speed throw some c++ in your
package at it, you can learn how in a day and it's super easy and basically
free" messaging. The reality is more nuanced than that, at best, even if
ultimately in many situations that is a valid/reasonable approach.


>
> These same issues will also occur with any newer language (such as
> Rust or Julia[1]) which uses RAII to manage resources and tries to
> interface with R. It doesn't seem a productive way forward for R to
> say it can't interface with these languages without first doing
> expensive copies into an intermediate heap.
>
> The advice to avoid C++ is also antithetical to John Chambers vision
> of first S and R as a interface language (from Extending R [2])
>
>   > The *interface* principle has always been central to R and to S
> before. An interface to subroutines was _the_ way to extend the first
> version of S. Subroutine interfaces have continued to be central to R.
>
> The book also has extensive sections on both C++ (via Rcpp) and Julia,
> so clearly John thinks these are legitimate ways to extend R.
>
> So if 'don't use C++' is not realistic and the current R API does not
> allow safe use of C++ exceptions what are the alternatives?
>

Again, nothing is going to change about this for a year*, at least *(AFAIK,
not on R-core) so we have to make it at least somewhat realistic; perhaps
not the blanket moratorium that Tomas advocated - though IMHO statements
from R-core about what is safe/supported when operating in R arena should
be granted *a lot *of weight - but certainly not the prevailing sentiment
it was responding to, either. That is true even if we commit to also
looking for ways to improve the situation in the longer term.


>
> One thing we could do is look how this is handled in other languages
> written in C which also use longjmp for errors.
>
> Lua is one example, they provide an alternative interface;
> lua_pcall[3] and lua_cpcall[4] which wrap a normal lua call and return
> an error code rather long jumping. These interfaces can then be safely
> wrapped by RAII - exception based languages.
>

So there's the function that Simon mentioned, which would work at least for
evaluating R code, though it doesn't necessarily help when you want to hit
the C api directly I think. Because of ALTREP, a LOT of things can
allocate, and thus error, now. That was necessary to get what we needed
without an amount of work/refactoring that would have tanked the whole
project (I think), but it is a thing.


>
> This alternative error code interface is not just useful for C++, but
> also for resource cleanup in C, it is currently non-trivial to handle
> cleanup in all the possible cases a longjmp can occur (interrupts,
> warnings, custom conditions, timeouts any allocation etc.) even with R
> finalizers.
>
> It is past time for R to consider a non-jumpy C interface, so it can
> continue to be used as an effective interface to programming routines
> in the years to come.
>

I mean I totally get this desire, and don't even disagree necessarily in
principle, but that's a pretty easy thing to say, right? My impression,
without really knowing the details of what all that would entail is that it
would/will be a seriously non-trivial amount of work for a group of people
who are already very busy maintaining an extremely widely used, extremely
complex piece of software.

Best,
~G

>
>

	[[alternative HTML version deleted]]


From @|mon@urb@nek @end|ng |rom r-project@org  Sat Mar 30 00:58:24 2019
From: @|mon@urb@nek @end|ng |rom r-project@org (Simon Urbanek)
Date: Fri, 29 Mar 2019 19:58:24 -0400
Subject: [Rd] Use of C++ in Packages
In-Reply-To: <CAJXgQP2OuQ98zzj-8CNSFVBTv4OU0tsA12HH++x=r4vpxi7Osw@mail.gmail.com>
References: <CAD6tx97B3zHikY9Cs+DnMXdOFFUn76ONoTupZT8QTaqo7+xZCA@mail.gmail.com>
 <DA086757-A81C-4E25-AE4D-2E4BCA187941@R-project.org>
 <CAJXgQP2OuQ98zzj-8CNSFVBTv4OU0tsA12HH++x=r4vpxi7Osw@mail.gmail.com>
Message-ID: <F68C848D-AE93-4CA9-9314-1ACDB23B87F6@r-project.org>

Kevin,


> On Mar 29, 2019, at 17:01, Kevin Ushey <kevinushey at gmail.com> wrote:
> 
> I think it's also worth saying that some of these issues affect C code
> as well; e.g. this is not safe:
> 
>    FILE* f = fopen(...);
>    Rf_eval(...);
>    fclose(f);
> 

I fully agree, but developers using C are well aware of the necessity of handling lifespan of objects explicitly, so at least there are no surprises.


> whereas the C++ equivalent would likely handle closing of the file in the destructor. In other words, I think many users just may not be cognizant of the fact that most R APIs can longjmp, and what that implies for cleanup of allocated resources. R_alloc() may help solve the issue specifically for memory allocations, but for any library interface that has a 'open' and 'close' step, the same sort of issue will arise.
> 

Well, I hope that anyone writing native code in package is well aware of that and will use an external pointer with finalizer to clean up native objects in any 3rd party library that are created during the call.


> What I believe we should do, and what Rcpp has made steps towards, is make it possible to interact with some subset of the R API safely from C++ contexts. This has always been possible with e.g. R_ToplevelExec() and R_ExecWithCleanup(), and now things are even better with R_UnwindProtect(). In theory, as a prototype, an R package could provide a 'safe' C++ interface to the R API using R_UnwindProtect() and friends as appropriate, and client packages could import and link to that package to gain access to the interface. Code generators (as Rcpp Attributes does) can handle some of the pain in these interfaces, so that users are mostly insulated from the nitty gritty details.
> 

I agree that we should strive to provide tools that make it safer, but note that it still requires participation of the users - they have to use such facilities or else they hit the same problem. So we can only fix this for the future, but let's start now.


> I agree that the content of Tomas's post is very helpful, especially since I expect many R programmers who dip their toes into the C++ world are not aware of the caveats of talking to R from C++. However, I don't think it's helpful to recommend "don't use C++"; rather, I believe the question should be, "what can we do to make it possible to easily and safely interact with R from C++?". Because, as I understand it, all of the problems raised are solvable: either through a well-defined C++ interface, or through better education.
> 

I think the recommendation would be different if such tools existed, but they don't. It was based on the current reality which is not so rosy.  Apparently the post had its effect of mobilizing C++ proponents to do something about it, which is great, because if this leads to some solution, the recommendation in the future may change to "use C++ using tools XYZ".


> I'll add my own opinion: writing correct C code is an incredibly difficult task. C++, while obviously not perfect, makes things substantially easier with tools like RAII, the STL, smart pointers, and so on. And I strongly believe that C++ (with Rcpp) is still a better choice than C for new users who want to interface with R from compiled code.
> 

My take is that Rcpp makes the interface *look* easier, but you still have to understand more about the R API that you think. Hence it much easier to write buggy code. Personally, that's why I don't like it (apart from the code bloat), because things are hidden that will get you into trouble, whereas using the C API is at least very clear - you have to understand what it's doing when you use it. That said, I'm obviously biased since I know a lot about R internals ;) so this doesn't necessarily generalize.


> tl;dr: I (and I think most others) just wish the summary had a more positive outlook for the future of C++ with R.
> 

Well, unless someone actually takes the initiative there is no reason to believe in a bright future of C++. As we have seen with the lack of adoption of CXXR (which I thought was an incredible achievement), not enough people seem to really care about C++. If that is not true, then let's come out of hiding, get together and address it (it seems that this thread is a good start).

Cheers,
Simon



> Best,
> Kevin
> 
> On Fri, Mar 29, 2019 at 10:16 AM Simon Urbanek
> <simon.urbanek at r-project.org> wrote:
>> 
>> Jim,
>> 
>> I think the main point of Tomas' post was to alert R users to the fact that there are very serious issues that you have to understand when interfacing R from C++. Using C++ code from R is fine, in many cases you only want to access R data, use some library or compute in C++ and return results. Such use-cases are completely fine in C++ as they don't need to trigger the issues mentioned and it should be made clear that it was not what Tomas' blog was about.
>> 
>> I agree with Tomas that it is safer to give an advice to not use C++ to call R API since C++ may give a false impression that you don't need to know what you're doing. Note that it is possible to avoid longjmps by using R_ExecWithCleanup() which can catch any longjmps from the called function. So if you know what you're doing you can make things work. I think the issue here is not necessarily lack of tools, it is lack of knowledge - which is why I think Tomas' post is so important.
>> 
>> Cheers,
>> Simon
>> 
>> 
>>> On Mar 29, 2019, at 11:19 AM, Jim Hester <james.f.hester at gmail.com> wrote:
>>> 
>>> First, thank you to Tomas for writing his recent post[0] on the R
>>> developer blog. It raised important issues in interfacing R's C API
>>> and C++ code.
>>> 
>>> However I do _not_ think the conclusion reached in the post is helpful
>>>> don?t use C++ to interface with R
>>> 
>>> There are now more than 1,600 packages on CRAN using C++, the time is
>>> long past when that type of warning is going to be useful to the R
>>> community.
>>> 
>>> These same issues will also occur with any newer language (such as
>>> Rust or Julia[1]) which uses RAII to manage resources and tries to
>>> interface with R. It doesn't seem a productive way forward for R to
>>> say it can't interface with these languages without first doing
>>> expensive copies into an intermediate heap.
>>> 
>>> The advice to avoid C++ is also antithetical to John Chambers vision
>>> of first S and R as a interface language (from Extending R [2])
>>> 
>>>> The *interface* principle has always been central to R and to S
>>> before. An interface to subroutines was _the_ way to extend the first
>>> version of S. Subroutine interfaces have continued to be central to R.
>>> 
>>> The book also has extensive sections on both C++ (via Rcpp) and Julia,
>>> so clearly John thinks these are legitimate ways to extend R.
>>> 
>>> So if 'don't use C++' is not realistic and the current R API does not
>>> allow safe use of C++ exceptions what are the alternatives?
>>> 
>>> One thing we could do is look how this is handled in other languages
>>> written in C which also use longjmp for errors.
>>> 
>>> Lua is one example, they provide an alternative interface;
>>> lua_pcall[3] and lua_cpcall[4] which wrap a normal lua call and return
>>> an error code rather long jumping. These interfaces can then be safely
>>> wrapped by RAII - exception based languages.
>>> 
>>> This alternative error code interface is not just useful for C++, but
>>> also for resource cleanup in C, it is currently non-trivial to handle
>>> cleanup in all the possible cases a longjmp can occur (interrupts,
>>> warnings, custom conditions, timeouts any allocation etc.) even with R
>>> finalizers.
>>> 
>>> It is past time for R to consider a non-jumpy C interface, so it can
>>> continue to be used as an effective interface to programming routines
>>> in the years to come.
>>> 
>>> [0]: https://developer.r-project.org/Blog/public/2019/03/28/use-of-c---in-packages/
>>> [1]: https://github.com/JuliaLang/julia/issues/28606
>>> [2]: https://doi.org/10.1201/9781315381305
>>> [3]: http://www.lua.org/manual/5.1/manual.html#lua_pcall
>>> [4]: http://www.lua.org/manual/5.1/manual.html#lua_cpcall
>>> 
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>> 
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 


From rom@|n @end|ng |rom r@tud|o@com  Sat Mar 30 08:59:46 2019
From: rom@|n @end|ng |rom r@tud|o@com (Romain Francois)
Date: Sat, 30 Mar 2019 08:59:46 +0100
Subject: [Rd] Use of C++ in Packages
In-Reply-To: <F68C848D-AE93-4CA9-9314-1ACDB23B87F6@r-project.org>
References: <CAD6tx97B3zHikY9Cs+DnMXdOFFUn76ONoTupZT8QTaqo7+xZCA@mail.gmail.com>
 <DA086757-A81C-4E25-AE4D-2E4BCA187941@R-project.org>
 <CAJXgQP2OuQ98zzj-8CNSFVBTv4OU0tsA12HH++x=r4vpxi7Osw@mail.gmail.com>
 <F68C848D-AE93-4CA9-9314-1ACDB23B87F6@r-project.org>
Message-ID: <5A14862F-729A-484C-A196-CA5F1D91B524@rstudio.com>

tl;dr: we need better C++ tools and documentation. 

We collectively know more now with the rise of tools like rchk and improved documentation such as Tomas?s post. That?s a start, but it appears that there still is a lot of knowledge that would deserve to be promoted to actual documentation of best practices. 

I think it is important to not equate C++ as a language, and Rcpp. 

Also, C++ is not just RAII. 

RAII is an important part of how Rcpp was conceived for sure, but it?s not the only thing C++ can bring as a language. Templates, lambdas, the stl are examples of things that can be used for expressiveness when just accessing data without interfering with R, calling R api functions ... 

It would be nice that the usual ? you should do that only if you know what you?re doing ? be transformed to precise documentation, and maybe become part of some better tool. If precautions have to be taken before calling such and such functions: that?s ok. What are they ? Can we embed that in some tool.

 It is easy enough to enscope code that uses potentially jumpy code into a c++ lambda. This could be together with recommendations such as the body of the lambda shall only use POC data structures. 

This is similar to precautions you?d take when writing concurrent code. 

Romain

> Le 30 mars 2019 ? 00:58, Simon Urbanek <simon.urbanek at r-project.org> a ?crit :
> 
> Kevin,
> 
> 
>> On Mar 29, 2019, at 17:01, Kevin Ushey <kevinushey at gmail.com> wrote:
>> 
>> I think it's also worth saying that some of these issues affect C code
>> as well; e.g. this is not safe:
>> 
>>   FILE* f = fopen(...);
>>   Rf_eval(...);
>>   fclose(f);
> 
> I fully agree, but developers using C are well aware of the necessity of handling lifespan of objects explicitly, so at least there are no surprises.
> 
> 
>> whereas the C++ equivalent would likely handle closing of the file in the destructor. In other words, I think many users just may not be cognizant of the fact that most R APIs can longjmp, and what that implies for cleanup of allocated resources. R_alloc() may help solve the issue specifically for memory allocations, but for any library interface that has a 'open' and 'close' step, the same sort of issue will arise.
> 
> Well, I hope that anyone writing native code in package is well aware of that and will use an external pointer with finalizer to clean up native objects in any 3rd party library that are created during the call.
> 
> 
>> What I believe we should do, and what Rcpp has made steps towards, is make it possible to interact with some subset of the R API safely from C++ contexts. This has always been possible with e.g. R_ToplevelExec() and R_ExecWithCleanup(), and now things are even better with R_UnwindProtect(). In theory, as a prototype, an R package could provide a 'safe' C++ interface to the R API using R_UnwindProtect() and friends as appropriate, and client packages could import and link to that package to gain access to the interface. Code generators (as Rcpp Attributes does) can handle some of the pain in these interfaces, so that users are mostly insulated from the nitty gritty details.
> 
> I agree that we should strive to provide tools that make it safer, but note that it still requires participation of the users - they have to use such facilities or else they hit the same problem. So we can only fix this for the future, but let's start now.
> 
> 
>> I agree that the content of Tomas's post is very helpful, especially since I expect many R programmers who dip their toes into the C++ world are not aware of the caveats of talking to R from C++. However, I don't think it's helpful to recommend "don't use C++"; rather, I believe the question should be, "what can we do to make it possible to easily and safely interact with R from C++?". Because, as I understand it, all of the problems raised are solvable: either through a well-defined C++ interface, or through better education.
> 
> I think the recommendation would be different if such tools existed, but they don't. It was based on the current reality which is not so rosy.  Apparently the post had its effect of mobilizing C++ proponents to do something about it, which is great, because if this leads to some solution, the recommendation in the future may change to "use C++ using tools XYZ".
> 
> 
>> I'll add my own opinion: writing correct C code is an incredibly difficult task. C++, while obviously not perfect, makes things substantially easier with tools like RAII, the STL, smart pointers, and so on. And I strongly believe that C++ (with Rcpp) is still a better choice than C for new users who want to interface with R from compiled code.
> 
> My take is that Rcpp makes the interface *look* easier, but you still have to understand more about the R API that you think. Hence it much easier to write buggy code. Personally, that's why I don't like it (apart from the code bloat), because things are hidden that will get you into trouble, whereas using the C API is at least very clear - you have to understand what it's doing when you use it. That said, I'm obviously biased since I know a lot about R internals ;) so this doesn't necessarily generalize.
> 
> 
>> tl;dr: I (and I think most others) just wish the summary had a more positive outlook for the future of C++ with R.
> 
> Well, unless someone actually takes the initiative there is no reason to believe in a bright future of C++. As we have seen with the lack of adoption of CXXR (which I thought was an incredible achievement), not enough people seem to really care about C++. If that is not true, then let's come out of hiding, get together and address it (it seems that this thread is a good start).
> 
> Cheers,
> Simon
> 
> 
> 
>> Best,
>> Kevin
>> 
>> On Fri, Mar 29, 2019 at 10:16 AM Simon Urbanek
>> <simon.urbanek at r-project.org> wrote:
>>> 
>>> Jim,
>>> 
>>> I think the main point of Tomas' post was to alert R users to the fact that there are very serious issues that you have to understand when interfacing R from C++. Using C++ code from R is fine, in many cases you only want to access R data, use some library or compute in C++ and return results. Such use-cases are completely fine in C++ as they don't need to trigger the issues mentioned and it should be made clear that it was not what Tomas' blog was about.
>>> 
>>> I agree with Tomas that it is safer to give an advice to not use C++ to call R API since C++ may give a false impression that you don't need to know what you're doing. Note that it is possible to avoid longjmps by using R_ExecWithCleanup() which can catch any longjmps from the called function. So if you know what you're doing you can make things work. I think the issue here is not necessarily lack of tools, it is lack of knowledge - which is why I think Tomas' post is so important.
>>> 
>>> Cheers,
>>> Simon
>>> 
>>> 
>>>> On Mar 29, 2019, at 11:19 AM, Jim Hester <james.f.hester at gmail.com> wrote:
>>>> 
>>>> First, thank you to Tomas for writing his recent post[0] on the R
>>>> developer blog. It raised important issues in interfacing R's C API
>>>> and C++ code.
>>>> 
>>>> However I do _not_ think the conclusion reached in the post is helpful
>>>>> don?t use C++ to interface with R
>>>> 
>>>> There are now more than 1,600 packages on CRAN using C++, the time is
>>>> long past when that type of warning is going to be useful to the R
>>>> community.
>>>> 
>>>> These same issues will also occur with any newer language (such as
>>>> Rust or Julia[1]) which uses RAII to manage resources and tries to
>>>> interface with R. It doesn't seem a productive way forward for R to
>>>> say it can't interface with these languages without first doing
>>>> expensive copies into an intermediate heap.
>>>> 
>>>> The advice to avoid C++ is also antithetical to John Chambers vision
>>>> of first S and R as a interface language (from Extending R [2])
>>>> 
>>>>> The *interface* principle has always been central to R and to S
>>>> before. An interface to subroutines was _the_ way to extend the first
>>>> version of S. Subroutine interfaces have continued to be central to R.
>>>> 
>>>> The book also has extensive sections on both C++ (via Rcpp) and Julia,
>>>> so clearly John thinks these are legitimate ways to extend R.
>>>> 
>>>> So if 'don't use C++' is not realistic and the current R API does not
>>>> allow safe use of C++ exceptions what are the alternatives?
>>>> 
>>>> One thing we could do is look how this is handled in other languages
>>>> written in C which also use longjmp for errors.
>>>> 
>>>> Lua is one example, they provide an alternative interface;
>>>> lua_pcall[3] and lua_cpcall[4] which wrap a normal lua call and return
>>>> an error code rather long jumping. These interfaces can then be safely
>>>> wrapped by RAII - exception based languages.
>>>> 
>>>> This alternative error code interface is not just useful for C++, but
>>>> also for resource cleanup in C, it is currently non-trivial to handle
>>>> cleanup in all the possible cases a longjmp can occur (interrupts,
>>>> warnings, custom conditions, timeouts any allocation etc.) even with R
>>>> finalizers.
>>>> 
>>>> It is past time for R to consider a non-jumpy C interface, so it can
>>>> continue to be used as an effective interface to programming routines
>>>> in the years to come.
>>>> 
>>>> [0]: https://developer.r-project.org/Blog/public/2019/03/28/use-of-c---in-packages/
>>>> [1]: https://github.com/JuliaLang/julia/issues/28606
>>>> [2]: https://doi.org/10.1201/9781315381305
>>>> [3]: http://www.lua.org/manual/5.1/manual.html#lua_pcall
>>>> [4]: http://www.lua.org/manual/5.1/manual.html#lua_cpcall
>>>> 
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>> 
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From c@tr@to @end|ng |rom @on@@t  Sat Mar 30 15:08:33 2019
From: c@tr@to @end|ng |rom @on@@t (cstrato)
Date: Sat, 30 Mar 2019 15:08:33 +0100
Subject: [Rd] Use of C++ in Packages
In-Reply-To: <F68C848D-AE93-4CA9-9314-1ACDB23B87F6@r-project.org>
References: <F68C848D-AE93-4CA9-9314-1ACDB23B87F6@r-project.org>
Message-ID: <fa25579c-80e0-e143-5100-1779871a1e7e@aon.at>

Hi,

It may or may not be of interest to you but an example how to access R 
functions from C++ can be found in the ROOT C++ framework, ROOT Version 
6, see e.g.:
https://root.cern/doc/master/classROOT_1_1R_1_1TRInterface.html
with an example shown in:
https://root.cern/doc/master/r_2example_8C.html

BTW, I strongly disagree that C++ does not have? a bright future!

Best regards,
Christian
_._._._._._._._._._._._._._._._._._
C.h.r.i.s.t.i.a.n?? S.t.r.a.t.o.w.a
V.i.e.n.n.a?????????? A.u.s.t.r.i.a
e.m.a.i.l:??????? cstrato at aon.at
_._._._._._._._._._._._._._._._._._


P.S.: Accessing a complete C++ program (based on ROOT Version 5) from R 
is shown in my Bioconductor package 'xps'


From ru@@e||-|enth @end|ng |rom u|ow@@edu  Sat Mar 30 18:03:05 2019
From: ru@@e||-|enth @end|ng |rom u|ow@@edu (Lenth, Russell V)
Date: Sat, 30 Mar 2019 17:03:05 +0000
Subject: [Rd] [External] re:  default for 'signif.stars'
In-Reply-To: <CAB8pepwzwgQ80b-sZOrx__b1Dhhh6AQs8gyztnx_8MbJ86YEdQ@mail.gmail.com>
References: <CAB8pepwzwgQ80b-sZOrx__b1Dhhh6AQs8gyztnx_8MbJ86YEdQ@mail.gmail.com>
Message-ID: <DM6PR04MB438090E2DFA05971E9641B20F15B0@DM6PR04MB4380.namprd04.prod.outlook.com>

Abs,

There are definitely problems with the editorial, but I think "most mega-ultra-super-biased" is an overreaction. It appears that you have overlooked some of the points made there, and the fact that it does not pretend to be an exhaustive list of alternative methods. The editorial attempts to digest what is in 43 articles in that special issue. Some of those articles do promote Bayesian methods ? not a surprise ? and some advocate using P values but without ascribing magical properties to P < 0.05. My own emmeans package does present P values (sans stars, or emojis either) in a lot of contexts.

More to the point, the criticisms you offer have to do with later sections of the editorial ? not the initial part, which is largely a repeat of an earlier ASA statement on interpretation of P values with the added recommendation that people should never say "statistically significant." It is that initial part that I think does describe a consensus of a large and growing proportion of statisticians and other scientists that placing undue emphasis on "statistical significance" is a bad thing. Emphasizing P values by adding stars encourages that kind of misdirected emphasis.

It seems fairly harmless to change the default for "show.signif.stars" to FALSE. However, I do recognize that no change to R's defaults should be taken lightly or done without careful consideration. I only ask that such careful consideration take place, and hope in fact that a plan can be made to phase-in such a change. 

Thanks,

Russ

Russell V. Lenth? -? Professor Emeritus
Department of Statistics and Actuarial Science?? 
The University of Iowa ?-? Iowa City, IA 52242? USA?? 
Voice (319)335-0712 (Dept. office)? -? FAX (319)335-3017



From: Abs Spurdle <spurdle.a at gmail.com> 
Sent: Thursday, March 28, 2019 12:19 AM
To: Lenth, Russell V <russell-lenth at uiowa.edu>; r-devel <r-devel at r-project.org>
Subject: [External] re: [Rd] default for 'signif.stars'

I read through the editorial.
This is the one of the most mega-ultra-super-biased articles I've ever read.

e.g.
The authors encourage Baysian methods, and literally encourage subjective approaches.
However, there's only one reference to robust methods and one reference to nonparametric methods, both of which are labelled as purely exploratory methods, which I regard as extremely offensive.
And there don't appear to be any references to semiparameric methods, or machine learning.

Surprisingly, they encourage multiple testing, however, don't mention the multiple comparison problem.
Something I can't understand at all.

So, maybe we should replace signif.stars with emoji...?



From brod|e@g@@|@m @end|ng |rom y@hoo@com  Sun Mar 31 03:18:20 2019
From: brod|e@g@@|@m @end|ng |rom y@hoo@com (Brodie Gaslam)
Date: Sat, 30 Mar 2019 21:18:20 -0400
Subject: [Rd] Use of C++ in Packages
In-Reply-To: <5A14862F-729A-484C-A196-CA5F1D91B524@rstudio.com>
References: <CAD6tx97B3zHikY9Cs+DnMXdOFFUn76ONoTupZT8QTaqo7+xZCA@mail.gmail.com>
 <DA086757-A81C-4E25-AE4D-2E4BCA187941@R-project.org>
 <CAJXgQP2OuQ98zzj-8CNSFVBTv4OU0tsA12HH++x=r4vpxi7Osw@mail.gmail.com>
 <F68C848D-AE93-4CA9-9314-1ACDB23B87F6@r-project.org>
 <5A14862F-729A-484C-A196-CA5F1D91B524@rstudio.com>
Message-ID: <37e00f05-2e86-2d32-d0f7-1910b484f6ca@yahoo.com>

It's great to see the community mobilize to try to resolve this issue. 
Obviously C++ has become a big part of R extensions, so it would be nice 
to have clear guidelines and tools to be able to use C++ safely with the 
R API.

Unfortunately doing this will probably require a fair bit of work.  If 
R-core where to do this it would take away from other valuable 
improvements they could be making on R itself.  Given there is already a 
supported and documented extension mechanism with access to the R API 
via C, I can see why R-core might be reluctant to divert resources from 
R development to add the same level of support for C++.

Obviously it would be impossible to try to provide better documentation 
and/or mechanisms for C++ extensions without some R-core involvement, 
but it seems like much of the grunt work could be done by others.  I 
unfortunately have no C++ experience so cannot help here, but hopefully 
there are others that have the experience and the recognition in the 
community to offer to help and have their offer accepted.  Perhaps 
R-consortium can even fund, although given the level of expertise 
required here the funding may need to be meaningful.

That seems like the natural step here.  Someone with the qualifications 
to do so either volunteers or is funded to do this, and hopefully R-core 
agrees to provide input and final stamp of approval.  The documentation 
is probably more straightforward, as tools will need more work from 
R-core to integrate.  It is possible R-core may decline to do this, but 
absent someone actually offering to put in the hard work it's all 
theoretical.

Respectfully,

Brodie.

On 3/30/19 3:59 AM, Romain Francois wrote:
> tl;dr: we need better C++ tools and documentation.
> 
> We collectively know more now with the rise of tools like rchk and improved documentation such as Tomas?s post. That?s a start, but it appears that there still is a lot of knowledge that would deserve to be promoted to actual documentation of best practices.
> 
> I think it is important to not equate C++ as a language, and Rcpp.
> 
> Also, C++ is not just RAII.
> 
> RAII is an important part of how Rcpp was conceived for sure, but it?s not the only thing C++ can bring as a language. Templates, lambdas, the stl are examples of things that can be used for expressiveness when just accessing data without interfering with R, calling R api functions ...
> 
> It would be nice that the usual ? you should do that only if you know what you?re doing ? be transformed to precise documentation, and maybe become part of some better tool. If precautions have to be taken before calling such and such functions: that?s ok. What are they ? Can we embed that in some tool.
> 
>   It is easy enough to enscope code that uses potentially jumpy code into a c++ lambda. This could be together with recommendations such as the body of the lambda shall only use POC data structures.
> 
> This is similar to precautions you?d take when writing concurrent code.
> 
> Romain
> 
>> Le 30 mars 2019 ? 00:58, Simon Urbanek <simon.urbanek at r-project.org> a ?crit :
>>
>> Kevin,
>>
>>
>>> On Mar 29, 2019, at 17:01, Kevin Ushey <kevinushey at gmail.com> wrote:
>>>
>>> I think it's also worth saying that some of these issues affect C code
>>> as well; e.g. this is not safe:
>>>
>>>    FILE* f = fopen(...);
>>>    Rf_eval(...);
>>>    fclose(f);
>>
>> I fully agree, but developers using C are well aware of the necessity of handling lifespan of objects explicitly, so at least there are no surprises.
>>
>>
>>> whereas the C++ equivalent would likely handle closing of the file in the destructor. In other words, I think many users just may not be cognizant of the fact that most R APIs can longjmp, and what that implies for cleanup of allocated resources. R_alloc() may help solve the issue specifically for memory allocations, but for any library interface that has a 'open' and 'close' step, the same sort of issue will arise.
>>
>> Well, I hope that anyone writing native code in package is well aware of that and will use an external pointer with finalizer to clean up native objects in any 3rd party library that are created during the call.
>>
>>
>>> What I believe we should do, and what Rcpp has made steps towards, is make it possible to interact with some subset of the R API safely from C++ contexts. This has always been possible with e.g. R_ToplevelExec() and R_ExecWithCleanup(), and now things are even better with R_UnwindProtect(). In theory, as a prototype, an R package could provide a 'safe' C++ interface to the R API using R_UnwindProtect() and friends as appropriate, and client packages could import and link to that package to gain access to the interface. Code generators (as Rcpp Attributes does) can handle some of the pain in these interfaces, so that users are mostly insulated from the nitty gritty details.
>>
>> I agree that we should strive to provide tools that make it safer, but note that it still requires participation of the users - they have to use such facilities or else they hit the same problem. So we can only fix this for the future, but let's start now.
>>
>>
>>> I agree that the content of Tomas's post is very helpful, especially since I expect many R programmers who dip their toes into the C++ world are not aware of the caveats of talking to R from C++. However, I don't think it's helpful to recommend "don't use C++"; rather, I believe the question should be, "what can we do to make it possible to easily and safely interact with R from C++?". Because, as I understand it, all of the problems raised are solvable: either through a well-defined C++ interface, or through better education.
>>
>> I think the recommendation would be different if such tools existed, but they don't. It was based on the current reality which is not so rosy.  Apparently the post had its effect of mobilizing C++ proponents to do something about it, which is great, because if this leads to some solution, the recommendation in the future may change to "use C++ using tools XYZ".
>>
>>
>>> I'll add my own opinion: writing correct C code is an incredibly difficult task. C++, while obviously not perfect, makes things substantially easier with tools like RAII, the STL, smart pointers, and so on. And I strongly believe that C++ (with Rcpp) is still a better choice than C for new users who want to interface with R from compiled code.
>>
>> My take is that Rcpp makes the interface *look* easier, but you still have to understand more about the R API that you think. Hence it much easier to write buggy code. Personally, that's why I don't like it (apart from the code bloat), because things are hidden that will get you into trouble, whereas using the C API is at least very clear - you have to understand what it's doing when you use it. That said, I'm obviously biased since I know a lot about R internals ;) so this doesn't necessarily generalize.
>>
>>
>>> tl;dr: I (and I think most others) just wish the summary had a more positive outlook for the future of C++ with R.
>>
>> Well, unless someone actually takes the initiative there is no reason to believe in a bright future of C++. As we have seen with the lack of adoption of CXXR (which I thought was an incredible achievement), not enough people seem to really care about C++. If that is not true, then let's come out of hiding, get together and address it (it seems that this thread is a good start).
>>
>> Cheers,
>> Simon
>>
>>
>>
>>> Best,
>>> Kevin
>>>
>>> On Fri, Mar 29, 2019 at 10:16 AM Simon Urbanek
>>> <simon.urbanek at r-project.org> wrote:
>>>>
>>>> Jim,
>>>>
>>>> I think the main point of Tomas' post was to alert R users to the fact that there are very serious issues that you have to understand when interfacing R from C++. Using C++ code from R is fine, in many cases you only want to access R data, use some library or compute in C++ and return results. Such use-cases are completely fine in C++ as they don't need to trigger the issues mentioned and it should be made clear that it was not what Tomas' blog was about.
>>>>
>>>> I agree with Tomas that it is safer to give an advice to not use C++ to call R API since C++ may give a false impression that you don't need to know what you're doing. Note that it is possible to avoid longjmps by using R_ExecWithCleanup() which can catch any longjmps from the called function. So if you know what you're doing you can make things work. I think the issue here is not necessarily lack of tools, it is lack of knowledge - which is why I think Tomas' post is so important.
>>>>
>>>> Cheers,
>>>> Simon
>>>>
>>>>
>>>>> On Mar 29, 2019, at 11:19 AM, Jim Hester <james.f.hester at gmail.com> wrote:
>>>>>
>>>>> First, thank you to Tomas for writing his recent post[0] on the R
>>>>> developer blog. It raised important issues in interfacing R's C API
>>>>> and C++ code.
>>>>>
>>>>> However I do _not_ think the conclusion reached in the post is helpful
>>>>>> don?t use C++ to interface with R
>>>>>
>>>>> There are now more than 1,600 packages on CRAN using C++, the time is
>>>>> long past when that type of warning is going to be useful to the R
>>>>> community.
>>>>>
>>>>> These same issues will also occur with any newer language (such as
>>>>> Rust or Julia[1]) which uses RAII to manage resources and tries to
>>>>> interface with R. It doesn't seem a productive way forward for R to
>>>>> say it can't interface with these languages without first doing
>>>>> expensive copies into an intermediate heap.
>>>>>
>>>>> The advice to avoid C++ is also antithetical to John Chambers vision
>>>>> of first S and R as a interface language (from Extending R [2])
>>>>>
>>>>>> The *interface* principle has always been central to R and to S
>>>>> before. An interface to subroutines was _the_ way to extend the first
>>>>> version of S. Subroutine interfaces have continued to be central to R.
>>>>>
>>>>> The book also has extensive sections on both C++ (via Rcpp) and Julia,
>>>>> so clearly John thinks these are legitimate ways to extend R.
>>>>>
>>>>> So if 'don't use C++' is not realistic and the current R API does not
>>>>> allow safe use of C++ exceptions what are the alternatives?
>>>>>
>>>>> One thing we could do is look how this is handled in other languages
>>>>> written in C which also use longjmp for errors.
>>>>>
>>>>> Lua is one example, they provide an alternative interface;
>>>>> lua_pcall[3] and lua_cpcall[4] which wrap a normal lua call and return
>>>>> an error code rather long jumping. These interfaces can then be safely
>>>>> wrapped by RAII - exception based languages.
>>>>>
>>>>> This alternative error code interface is not just useful for C++, but
>>>>> also for resource cleanup in C, it is currently non-trivial to handle
>>>>> cleanup in all the possible cases a longjmp can occur (interrupts,
>>>>> warnings, custom conditions, timeouts any allocation etc.) even with R
>>>>> finalizers.
>>>>>
>>>>> It is past time for R to consider a non-jumpy C interface, so it can
>>>>> continue to be used as an effective interface to programming routines
>>>>> in the years to come.
>>>>>
>>>>> [0]: https://developer.r-project.org/Blog/public/2019/03/28/use-of-c---in-packages/
>>>>> [1]: https://github.com/JuliaLang/julia/issues/28606
>>>>> [2]: https://doi.org/10.1201/9781315381305
>>>>> [3]: http://www.lua.org/manual/5.1/manual.html#lua_pcall
>>>>> [4]: http://www.lua.org/manual/5.1/manual.html#lua_cpcall
>>>>>
>>>>> ______________________________________________
>>>>> R-devel at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From @uh@rto_@nggono @end|ng |rom y@hoo@com  Sun Mar 31 17:26:13 2019
From: @uh@rto_@nggono @end|ng |rom y@hoo@com (Suharto Anggono Suharto Anggono)
Date: Sun, 31 Mar 2019 15:26:13 +0000 (UTC)
Subject: [Rd] stopifnot
References: <789570515.14008055.1554045973573.ref@mail.yahoo.com>
Message-ID: <789570515.14008055.1554045973573@mail.yahoo.com>

Ah, with R 3.5.0 or R 3.4.2, but not with R 3.3.1, 'eval' inside 'for' makes compiled version behave like non-compiled version.

options(error = expression(NULL))
library(compiler)
enableJIT(0)
f <- function(x) for (i in 1) {x; eval(expression(i))}
f(is.numeric(y))
# Error: object 'y' not found
fc <- cmpfun(f)
fc(is.numeric(y))
# Error: object 'y' not found

Is this accidental feature going to be relied upon?


"Details" section of 'stopifnot' documentation in current R 3.6.0 alpha (https://svn.r-project.org/R/branches/R-3-6-branch/src/library/base/man/stopifnot.Rd) has this.

? Since \R version 3.6.0, \code{stopifnot()} no longer handles potential
? errors or warnings (by \code{\link{tryCatch}()} etc) for each single
? expression but rather aims at using the correct
? \code{\link{sys.call}(<n>)} to get the most meaningful error message in
? case of an error.? This provides considerably less overhead.

I think part of the first sentence starting from "but rather" should be removed because it is not true.


The next paragraph:

? Since \R version 3.5.0, expressions \emph{are} evaluated sequentially,
? and hence evaluation stops as soon as there is a \dQuote{non-TRUE}, as
? indicated by the above conceptual equivalence statement.
? Further, when such an expression signals an error or
? \code{\link{warning}}, its \code{\link{conditionCall}()} no longer
? contains the full \code{stopifnot} call, but just the erroneous
? expression.

As I said earlier (https://stat.ethz.ch/pipermail/r-devel/2019-February/077386.html), the last sentence above is not entirely true. It may say something like:
Furher, when such an expression signals an error, stopifnot() in R 3.5.x makes its conditionCall() the erroneous expression, but no longer since R 3.6.0.


Is it OK that, for
do.call(stopifnot, list(exprs = expression())) ,
the whole expression object is taken as one?


End portion from running
example(stopifnot)
in R 3.5.0:
stpfnt> stopifnot(all.equal(pi, 3.141593),? 2 < 2, all(1:10 < 12), "a" < "b")
Error in eval(ei, envir) : pi and 3.141593 are not equal:
? Mean relative difference: 1.102658e-07

To me, "in eval(*)" is rather surprising and annoying and doesn't add clarity. Yes, stop() gives the same. But, in this case, just "Error", like in R before?version 3.5.0, feels better to me. If
stop(simpleError(msg, call = if(p <- sys.parent()) sys.call(p)))
were used in 'stopifnot', just "Error" would be given in this case.

--------------------------------------------

 wrote:

 Subject: Re: [Rd] stopifnot
 To: r-devel at r-project.org
 Date: Thursday, 7 March, 2019, 3:43 PM

[...]

As far as I can see, full stopifnot(...) call can only appear from an error that happens during evaluation of an argument of 'stopifnot'. Because the error is not raised by 'stopifnot', the call in the error has nothing to do with how 'n' is computed in sys.call(n-1) , or even with use of sys.call(n-1) itself.

if(n > 1) sys.call(n-1)
that I proposed previously was aimed to be like
sys.call(-1)
in 'stopifnot' in R 3.5.x. Negative number counts back from current frame. The value of 'n' is sys.nframe() or (sys.nframe()-3). In my patch, stopifnot(exprs=*) drives stopifnot(...) call via 'eval'. I found that frames were generated for
stopifnot (exprs) -> eval -> eval (.Internal) -> stopifnot (...)
>From stopifnot (...) , reaching stopifnot (exprs) takes 3 steps back.


[...]

options(error = expression(NULL))
library(compiler)
enableJIT(0)
f <- function(x) for (i in 1) x
f(is.numeric(y))
# Error: object 'y' not found
fc <- cmpfun(f)
fc(is.numeric(y))
# Error in fc(is.numeric(y)) : object 'y' not found

The above illustrates what happens in current 'stopifnot' without 'withCallingHandlers' or 'tryCatch'. For error during 'for', non-compiled and compiled versions are different. It surprised me.

[...]


With my revised patch, the 'else' clause for 'cl' gives
call("expression", exprs) .
For
do.call(stopifnot, list(exprs = expression())) ,
the whole expression object is taken as one.

do.call(stopifnot, list(exprs = expression(1==1, 2 < 1, stop("NOT GOOD!\n"))))
Error in do.call(stopifnot, list(exprs = expression(1 == 1, 2 < 1, stop("NOT GOOD!\n")))) : 
? expression(1 == 1, 2 < 1, stop("NOT GOOD!\n")) are not all TRUE

To be the same as in R 3.5.x, the 'else' can be
as.call(c(quote(expression), as.expression(exprs)))

--------------------------------------------
On Wed, 6/3/19, Martin Maechler <maechler at stat.math.ethz.ch> wrote:

Subject: Re: [Rd] stopifnot

r-project.org
Cc: "Martin Maechler" <maechler at stat.math.ethz.ch>
Date: Wednesday, 6 March, 2019, 3:50 PM

>>>>> Martin Maechler 
>>>>>? ? on Tue, 5 Mar 2019 21:04:08 +0100 writes:

>>>>> Suharto Anggono Suharto Anggono 
>>>>>? ? on Tue, 5 Mar 2019 17:29:20 +0000 writes:

[...]

? ? >> After thinking again, I propose to use
? ? >>? ? ? ?? stop(simpleError(msg, call = if(p <- sys.parent()) sys.call(p)))

? ? > That would of course be considerably simpler indeed,? part "2 a" of these:

? ? >> - It seems that the call is the call of the frame where stopifnot(...) is evaluated. Because that is the correct context, I think it is good.
? ? >> - It is simpler and also works for call that originally comes from stopifnot(exprs=*) .

? ? >> - It allows shortcut ('assert') to have the same call in error message as stopifnot(exprs=*) .

? ? > That may be another good reason in addition to code simplicity.

? ? > I will have to see if this extra simplification does not loose
? ? > more than I'd want.


? ? >> Another thing: Is it intended that
? ? >> do.call("stopifnot", list(exprs = expression()))
? ? >> evaluates each element of the expression object?

? ? > ??? I really don't know.? Even though such a case looks
? ? > "unusual" (to say the least), in principle I'd like that
? ? > expressions are evaluated sequentially until the first non-TRUE
? ? > result.? With a concrete example, I do like what we have
? ? > currently in unchanged R-devel, but also in R 3.5.x, i.e., in
? ? > the following, not any "NOT GOOD" should pop up:

? ? >> stopifnot(exprs = expression(1==1, 2 < 1, stop("NOT GOOD!\n")))
? ? > Error: 2 < 1 is not TRUE
? ? >> do.call(stopifnot, list(exprs = expression(1==1, 2 < 1, stop("NOT GOOD!\n"))))
? ? > Error in do.call(stopifnot, list(exprs = expression(1 == 1, 2 < 1, cat("NOT GOOD!\n")))) : 
? ? > 2 < 1 is not TRUE
? ? >> 

? ? > Hmm, it seems I do not understand what you ask above in your
? ? > "Another thing: .."


? ? >> If so, maybe add a case for 'cl', like
? ? >>? ? ? ?? else if(is.expression(exprs))
? ? >>? ? ? ?? as.call(c(quote(expression), exprs))

? ? > that seems simple indeed, but at the moment, I cannot see one example
? ? > where it makes a difference ... or then I'm "blind" .. ???

? ? > Best,
? ? > Martin

Some more testing of examples lead me to keep the more
sophisticated "computation" of 'n'? for the? sys.call(n-1).

Main reason:? If one of the expression is not all TRUE, I really
don't want to see the full 'stopifnot(....)' call in the printed
error message.
I do want to encourage that? stopifnot()? asserts many things
and so its own call should really not be shown.

Also I really wanted to commit something, notably also fixing
the? stopifnot(exprs = T)? bug,? so R-devel (rev >= 76203 ) now
contains a simpler and much faster? stopifnot() than previously
[and than the R 3.5.x series].

I agree that the final decisions on getting a call (or not --
which was a very good idea by you!) and which parent's call
should be used? may deserve some future tinkering..

Thank you again, Suharto Anggono,
[[elided Yahoo spam]]


Martin


