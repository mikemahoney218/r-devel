From rksh1 at cam.ac.uk  Fri May  1 10:25:56 2009
From: rksh1 at cam.ac.uk (Robin Hankin)
Date: Fri, 01 May 2009 09:25:56 +0100
Subject: [Rd] parsing Rd files and \deqn{}
Message-ID: <49FAB214.2080802@cam.ac.uk>

Hi

[R-2.9.0]

I am having difficulty including a LaTeX formula in an Rd
file.

The example given in section 2.7 in 'Parsing Rd files' is:


    \deqn{ f(x) = \left\{
      \begin{array}{ll}
      0 & x<0 \\
      1 & x\ge 0
      \end{array}
      \right. }{non latex}


For me, this gives:

\deqn{ f(x) = \left\{
\begin{array}{ll}
0 \& x<0 \bsl{}
1 \& x\ge 0
\end{array}
\right. }{}

in the tex file, which is not  desired because the ampersand
is escaped; the '&' symbol appears in the dvi file, and I
want an ampersand  to indicate  alignment.

Also, the '\\' appears as \bsl{}, which is undesired; the
 resulting dvi file (made by R CMD Rd2dvi) looks wrong.

How do I write the Rd file so as to produce non-escaped
ampersands?


-- 
Robin K. S. Hankin
Uncertainty Analyst
University of Cambridge
19 Silver Street
Cambridge CB3 9EP
01223-764877


From maechler at stat.math.ethz.ch  Fri May  1 14:14:58 2009
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 1 May 2009 14:14:58 +0200
Subject: [Rd] NA_real_ <op> NaN -> NA or NaN, should we care?
In-Reply-To: <77EB52C6DD32BA4D87471DCD70C8D700011DF636@NA-PA-VBE03.na.tibco.com>
References: <77EB52C6DD32BA4D87471DCD70C8D700011DF636@NA-PA-VBE03.na.tibco.com>
Message-ID: <18938.59330.930913.863408@cmath-5.math.ethz.ch>

>>>>> William Dunlap <wdunlap at tibco.com>
>>>>>     on Thu, 30 Apr 2009 10:51:43 -0700 writes:

    > On Linux when I compile R 2.10.0(devel) (src/main/arithmetic.c in
    > particular)
    > with gcc 3.4.5 using the flags -g -O2 I get noncommutative behavior when

is this really gcc 3.4.5  (which is quite old) ?

Without being an expert, I'd tend to claim this to be a
compiler (optimization) bug ....  but most probably the ANSI /
ISO  C (and libc ?) standards would not define the exact
behavior of arithmetic with NaNs.

    > adding NA and NaN:
    >> NA_real_ + NaN
    > [1] NaN
    >> NaN + NA_real_
    > [1] NA
    > If I compile src/main/arithmetic.c without optimization (just -g)
    > then both of those return NA.

    > On Windows, using a precompiled R 2.8.1 from CRAN I get
    > NA for both answers.

    > On Linux, after compiling src/main/arithmetic.c with -g -O2 the bit
    > patterns for NA_real_ and as.numeric(NA) are different:
    >> my_numeric_NA <- as.numeric(NA)
    >> writeBin(my_numeric_NA, ptmp<-pipe("od -x", open="wb"));close(ptmp)
    > 0000000 07a2 0000 0000 7ff8
    > 0000010
    >> writeBin(NA_real_, ptmp<-pipe("od -x", open="wb"));close(ptmp)
    > 0000000 07a2 0000 0000 7ff0
    > 0000010 
    > On Linux, after compiling with -g the bit patterns for NA_real_
    > and as.numeric(NA) are identical.
    >> my_numeric_NA <- as.numeric(NA)
    >> writeBin(my_numeric_NA, ptmp<-pipe("od -x", open="wb"));close(ptmp)
    > 0000000 07a2 0000 0000 7ff8
    > 0000010
    >> writeBin(NA_real_, ptmp<-pipe("od -x", open="wb"));close(ptmp)
    > 0000000 07a2 0000 0000 7ff8
    > 0000010

    > On Windows, using precompiled R 2.8.1 and cygwin/bin/od, both of those
    > gave the 7ff8 version.

    > Is this confounding of NA and NaN of concern or does R not promise to
    > keep NA and NaN distinct? 

Hmm, I'd say it *is* of some concern that "+" is not commutative
in the narrow sense, even if I don't know what exactly "R promises".

    > I haven't followed all the macros, but it looks like arithmetic.c just
    > does
    > result[i]=x[i]+y[i]
    > and lets the compiler/floating point unit decide what to do when x[i]
    > and y[i]
    > are different NaN values (NA is a NaN value).  I haven't looked at the C
    > code
    > for the initialization of NA_real_.  Adding explicit tests for NA-ness
    > in the
    > binary operators (as S+ does) adds a fairly significant cost.

Yes, I would be quite reluctant to add such
tests, because such costs are to be expected.

Maybe we ("R" :-) should explicitly state that operations mixing
NA & NaN give a result which is NA in the sense of fulfilling is.na(.) 
but *not* promise anything further.

Martin Maechler, ETH Zurich

    > Bill Dunlap
    > TIBCO Software Inc - Spotfire Division
    > wdunlap tibco.com


From maechler at stat.math.ethz.ch  Fri May  1 15:14:26 2009
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 1 May 2009 15:14:26 +0200
Subject: [Rd] NA_real_ <op> NaN -> NA or NaN, should we care?
In-Reply-To: <18938.59330.930913.863408@cmath-5.math.ethz.ch>
References: <77EB52C6DD32BA4D87471DCD70C8D700011DF636@NA-PA-VBE03.na.tibco.com>
	<18938.59330.930913.863408@cmath-5.math.ethz.ch>
Message-ID: <18938.62898.115837.418384@cmath-5.math.ethz.ch>

>>>>> "MM" == Martin Maechler <maechler at stat.math.ethz.ch>
>>>>>     on Fri, 1 May 2009 14:14:58 +0200 writes:

>>>>> William Dunlap <wdunlap at tibco.com>
>>>>>     on Thu, 30 Apr 2009 10:51:43 -0700 writes:

    >> On Linux when I compile R 2.10.0(devel) (src/main/arithmetic.c in
    >> particular)
    >> with gcc 3.4.5 using the flags -g -O2 I get noncommutative behavior when

    MM> is this really gcc 3.4.5  (which is quite old) ?

    MM> Without being an expert, I'd tend to claim this to be a
    MM> compiler (optimization) bug ....  but most probably the ANSI /
    MM> ISO  C (and libc ?) standards would not define the exact
    MM> behavior of arithmetic with NaNs.

    >> adding NA and NaN:
    >>> NA_real_ + NaN
    >> [1] NaN
    >>> NaN + NA_real_
    >> [1] NA
    >> If I compile src/main/arithmetic.c without optimization (just -g)
    >> then both of those return NA.

    >> On Windows, using a precompiled R 2.8.1 from CRAN I get
    >> NA for both answers.

    >> On Linux, after compiling src/main/arithmetic.c with -g -O2 the bit
    >> patterns for NA_real_ and as.numeric(NA) are different:
    >>> my_numeric_NA <- as.numeric(NA)
    >>> writeBin(my_numeric_NA, ptmp<-pipe("od -x", open="wb"));close(ptmp)
    >> 0000000 07a2 0000 0000 7ff8
    >> 0000010
    >>> writeBin(NA_real_, ptmp<-pipe("od -x", open="wb"));close(ptmp)
    >> 0000000 07a2 0000 0000 7ff0
    >> 0000010 
    >> On Linux, after compiling with -g the bit patterns for NA_real_
    >> and as.numeric(NA) are identical.
    >>> my_numeric_NA <- as.numeric(NA)
    >>> writeBin(my_numeric_NA, ptmp<-pipe("od -x", open="wb"));close(ptmp)
    >> 0000000 07a2 0000 0000 7ff8
    >> 0000010
    >>> writeBin(NA_real_, ptmp<-pipe("od -x", open="wb"));close(ptmp)
    >> 0000000 07a2 0000 0000 7ff8
    >> 0000010

    >> On Windows, using precompiled R 2.8.1 and cygwin/bin/od, both of those
    >> gave the 7ff8 version.


I've run a couple of 

     echo 'c(NA+NaN, NaN+NA)' | R --slave --vanilla

on 3 different platforms, all Linux, and many installed versions
of R -- all of which compiled with defaults, i.e. '-O2', 
        and depending on its release date, compiled with
	different versions of gcc {I can still check these
	because I run R from the installation directory, with
	all configure results ..}
on a given platform, and have observed the following:

The result is always "NA NA" (as desired!)  iff the platform is 32-bit,

whereas it is        "NaN NA" for the 64-bit platform and older
	   	     	      versions of R (R <= 2.3.1)

	   	 and "NA NaN" for versions of R (>= 2.4.1)

{{but note: the versions of R are confounded with the versions of gcc ...}}

Further, as the 64-bit platform can also use the 32-bit versions of R,
I've tested a few and found that indeed, the 32-bit version of R
would return "NA NA" also on the 64-bit platform.

Martin


    >> Is this confounding of NA and NaN of concern or does R not promise to
    >> keep NA and NaN distinct? 

    MM> Hmm, I'd say it *is* of some concern that "+" is not commutative
    MM> in the narrow sense, even if I don't know what exactly "R promises".

    >> I haven't followed all the macros, but it looks like arithmetic.c just
    >> does
    >> result[i]=x[i]+y[i]
    >> and lets the compiler/floating point unit decide what to do when x[i]
    >> and y[i]
    >> are different NaN values (NA is a NaN value).  I haven't looked at the C
    >> code
    >> for the initialization of NA_real_.  Adding explicit tests for NA-ness
    >> in the
    >> binary operators (as S+ does) adds a fairly significant cost.

    MM> Yes, I would be quite reluctant to add such
    MM> tests, because such costs are to be expected.

    MM> Maybe we ("R" :-) should explicitly state that operations mixing
    MM> NA & NaN give a result which is NA in the sense of fulfilling is.na(.) 
    MM> but *not* promise anything further.

    MM> Martin Maechler, ETH Zurich

    >> Bill Dunlap
    >> TIBCO Software Inc - Spotfire Division
    >> wdunlap tibco.com

    MM> ______________________________________________
    MM> R-devel at r-project.org mailing list
    MM> https://stat.ethz.ch/mailman/listinfo/r-devel


From murdoch at stats.uwo.ca  Fri May  1 15:38:55 2009
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri, 01 May 2009 09:38:55 -0400
Subject: [Rd] NA_real_ <op> NaN -> NA or NaN, should we care?
In-Reply-To: <18938.59330.930913.863408@cmath-5.math.ethz.ch>
References: <77EB52C6DD32BA4D87471DCD70C8D700011DF636@NA-PA-VBE03.na.tibco.com>
	<18938.59330.930913.863408@cmath-5.math.ethz.ch>
Message-ID: <49FAFB6F.3060901@stats.uwo.ca>

On 5/1/2009 8:14 AM, Martin Maechler wrote:
>>>>>> William Dunlap <wdunlap at tibco.com>
>>>>>>     on Thu, 30 Apr 2009 10:51:43 -0700 writes:
> 
>     > On Linux when I compile R 2.10.0(devel) (src/main/arithmetic.c in
>     > particular)
>     > with gcc 3.4.5 using the flags -g -O2 I get noncommutative behavior when
> 
> is this really gcc 3.4.5  (which is quite old) ?
> 
> Without being an expert, I'd tend to claim this to be a
> compiler (optimization) bug ....  but most probably the ANSI /
> ISO  C (and libc ?) standards would not define the exact
> behavior of arithmetic with NaNs.

Here are a few bits of information, not particularly well organized:

I don't know if the IEEE 754 (or the ISO equivalent) specifies the 
behaviour, but the hardware handling of NaNs is inconsistent on Intel 
chips.  If two NaNs are involved in an operation, it returns the one 
with the larger significand when operations are done in the FPU, it 
returns the first one when they are done in the SSE.

Our NA has a bigger significand than the default NaN, but there are NaNs 
that are bigger.  (We're unlikely to see those in the results of 
arithmetic under our control, but there's nothing to stop external code 
from returning one, or getting one via readBin from a file.)

The type can be either quiet or signalling; our NA is a signalling NaN, 
and the one Bill was getting from the as.numeric conversion is a quiet 
NaN.  However, our IsNA test doesn't look at the bits determining that 
status, it only looks at the 07a2 0000 part, so both are displayed as 
NA.  I haven't traced the coercion code to know why they aren't 
identical, but I think it doesn't matter:  the FPU and SSE methods are 
inconsistent for most pairs of operands.

All of which leads me to conclude that we should either say we don't 
guarantee what happens when you mix NA with NaN, or we should add an 
explicit test to every operation.  I'd prefer the "no guarantees" solution.

Duncan Murdoch



> 
>     > adding NA and NaN:
>     >> NA_real_ + NaN
>     > [1] NaN
>     >> NaN + NA_real_
>     > [1] NA
>     > If I compile src/main/arithmetic.c without optimization (just -g)
>     > then both of those return NA.
> 
>     > On Windows, using a precompiled R 2.8.1 from CRAN I get
>     > NA for both answers.
> 
>     > On Linux, after compiling src/main/arithmetic.c with -g -O2 the bit
>     > patterns for NA_real_ and as.numeric(NA) are different:
>     >> my_numeric_NA <- as.numeric(NA)
>     >> writeBin(my_numeric_NA, ptmp<-pipe("od -x", open="wb"));close(ptmp)
>     > 0000000 07a2 0000 0000 7ff8
>     > 0000010
>     >> writeBin(NA_real_, ptmp<-pipe("od -x", open="wb"));close(ptmp)
>     > 0000000 07a2 0000 0000 7ff0
>     > 0000010 
>     > On Linux, after compiling with -g the bit patterns for NA_real_
>     > and as.numeric(NA) are identical.
>     >> my_numeric_NA <- as.numeric(NA)
>     >> writeBin(my_numeric_NA, ptmp<-pipe("od -x", open="wb"));close(ptmp)
>     > 0000000 07a2 0000 0000 7ff8
>     > 0000010
>     >> writeBin(NA_real_, ptmp<-pipe("od -x", open="wb"));close(ptmp)
>     > 0000000 07a2 0000 0000 7ff8
>     > 0000010
> 
>     > On Windows, using precompiled R 2.8.1 and cygwin/bin/od, both of those
>     > gave the 7ff8 version.
> 
>     > Is this confounding of NA and NaN of concern or does R not promise to
>     > keep NA and NaN distinct? 
> 
> Hmm, I'd say it *is* of some concern that "+" is not commutative
> in the narrow sense, even if I don't know what exactly "R promises".
> 
>     > I haven't followed all the macros, but it looks like arithmetic.c just
>     > does
>     > result[i]=x[i]+y[i]
>     > and lets the compiler/floating point unit decide what to do when x[i]
>     > and y[i]
>     > are different NaN values (NA is a NaN value).  I haven't looked at the C
>     > code
>     > for the initialization of NA_real_.  Adding explicit tests for NA-ness
>     > in the
>     > binary operators (as S+ does) adds a fairly significant cost.
> 
> Yes, I would be quite reluctant to add such
> tests, because such costs are to be expected.
> 
> Maybe we ("R" :-) should explicitly state that operations mixing
> NA & NaN give a result which is NA in the sense of fulfilling is.na(.) 
> but *not* promise anything further.
> 
> Martin Maechler, ETH Zurich
> 
>     > Bill Dunlap
>     > TIBCO Software Inc - Spotfire Division
>     > wdunlap tibco.com
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From wdunlap at tibco.com  Fri May  1 16:50:10 2009
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 1 May 2009 07:50:10 -0700
Subject: [Rd] NA_real_ <op> NaN -> NA or NaN, should we care?
In-Reply-To: <18938.59330.930913.863408@cmath-5.math.ethz.ch>
References: <77EB52C6DD32BA4D87471DCD70C8D700011DF636@NA-PA-VBE03.na.tibco.com>
	<18938.59330.930913.863408@cmath-5.math.ethz.ch>
Message-ID: <77EB52C6DD32BA4D87471DCD70C8D700011DF87F@NA-PA-VBE03.na.tibco.com>

> From: Martin Maechler [mailto:maechler at stat.math.ethz.ch] 
> Sent: Friday, May 01, 2009 5:15 AM
> To: William Dunlap
> Cc: r-devel at r-project.org
> Subject: Re: [Rd] NA_real_ <op> NaN -> NA or NaN, should we care?
> 
> >>>>> William Dunlap <wdunlap at tibco.com>
> >>>>>     on Thu, 30 Apr 2009 10:51:43 -0700 writes:
> 
>     > On Linux when I compile R 2.10.0(devel) 
> (src/main/arithmetic.c in
>     > particular)
>     > with gcc 3.4.5 using the flags -g -O2 I get 
> noncommutative behavior when
> 
> is this really gcc 3.4.5  (which is quite old) ?

Yes, it was 3.4.5, but here is a self-contained example of the same
issue using gcc 4.1.3 on an Ubuntu Linux machine:

% gcc -O2 t.c -o a.out ; ./a.out
NA : 7ff00000000007a2
NaN: fff8000000000000
NA+NaN: 7ff80000000007a2
NaN+NA: fff8000000000000
% gcc  t.c -o a.out ; ./a.out
NA : 7ff00000000007a2
NaN: fff8000000000000
NA+NaN: 7ff80000000007a2
NaN+NA: 7ff80000000007a2
% gcc -v
Using built-in specs.
Target: i486-linux-gnu
Configured with: ../src/configure -v --enable-languages=c,c++,fortran,objc,obj-c++,treelang --prefix=/usr --enable-shared --with-system-zlib --libexecdir=/usr/lib --without-included-gettext --enable-threads=posix --enable-nls --with-gxx-include-dir=/usr/include/c++/4.1.3 --program-suffix=-4.1 --enable-__cxa_atexit --enable-clocale=gnu --enable-libstdcxx-debug --enable-mpfr --enable-checking=release i486-linux-gnu
Thread model: posix
gcc version 4.1.3 20070929 (prerelease) (Ubuntu 4.1.2-16ubuntu2)
% cat t.c
#include <stdio.h>
#include <stdint.h>
#include <string.h>

int main(int argc, char *argv[])
{
    int64_t NA_int64 = 0x7ff00000000007a2LL ;
    int64_t NaN_int64 = 0xfff8000000000000LL ;
    int64_t sum_int64 ;
    double NA_double, NaN_double, sum_double ;

    memcpy((void*)&NA_double, (void*)&NA_int64, 8) ;
    memcpy((void*)&NaN_double, (void*)&NaN_int64, 8) ;

    NaN_double = 1/0.0 - 1/0.0 ;

    printf("NA : %Lx\n", *(int64_t*)&NA_double);
    printf("NaN: %Lx\n", *(int64_t*)&NaN_double);
    sum_double = NA_double + NaN_double ;
    memcpy((void*)&sum_int64, (void*)&sum_double, 8) ;
    printf("NA+NaN: %Lx\n", sum_int64) ;
    sum_double = NaN_double + NA_double ;
    memcpy((void*)&sum_int64, (void*)&sum_double, 8) ;
    printf("NaN+NA: %Lx\n", sum_int64);
    return 0 ;
}

When I add -Wall to the -O2 then it gives me some warnings about the
*(int64_t)&doubleVal in the printf statements for the inputs, but I used
memcpy() to avoid the warnings when printing the outputs.

% gcc -Wall -O2 t.c -o a.out ; ./a.out
t.c: In function ?main?:
t.c:17: warning: dereferencing type-punned pointer will break strict-aliasing rules
t.c:18: warning: dereferencing type-punned pointer will break strict-aliasing rules
NA : 7ff00000000007a2
NaN: fff8000000000000
NA+NaN: 7ff80000000007a2
NaN+NA: fff8000000000000

Bill Dunlap
TIBCO Software Inc - Spotfire Division
wdunlap tibco.com  


From robjgoedman at me.com  Fri May  1 17:01:19 2009
From: robjgoedman at me.com (Rob Goedman)
Date: Fri, 01 May 2009 08:01:19 -0700
Subject: [Rd] crash after using graphics in Rcmdr (PR#13679)
In-Reply-To: <003501c9c997$b32cc470$19864d50$@ca>
References: <20090428172515.2E4E928321A2@mail.pubhealth.ku.dk>
	<003501c9c997$b32cc470$19864d50$@ca>
Message-ID: <49848470-CCA0-4105-A817-4E365BB378E3@me.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090501/16b2ea25/attachment.pl>

From wdunlap at tibco.com  Fri May  1 17:25:42 2009
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 1 May 2009 08:25:42 -0700
Subject: [Rd] NA_real_ <op> NaN -> NA or NaN, should we care?
In-Reply-To: <77EB52C6DD32BA4D87471DCD70C8D700011DF87F@NA-PA-VBE03.na.tibco.com>
References: <77EB52C6DD32BA4D87471DCD70C8D700011DF636@NA-PA-VBE03.na.tibco.com><18938.59330.930913.863408@cmath-5.math.ethz.ch>
	<77EB52C6DD32BA4D87471DCD70C8D700011DF87F@NA-PA-VBE03.na.tibco.com>
Message-ID: <77EB52C6DD32BA4D87471DCD70C8D700011DF89A@NA-PA-VBE03.na.tibco.com>

The optimizer in gcc 4.2 (but not 4.1) on Linux seems to get this
issue "right" on one of my test machines (a 32-bit Ubuntu box).
4.1 fails on a 64-bit Linux but I don't have a newer gcc on any
64-bit Linux machine I can find.

A cleaner version of the test is:
% cat t.c
#include <stdio.h>
#include <stdint.h>
#include <string.h>

void print_double(char *text, double x_double)
{
    int64_t x_int64 ;
    memcpy((void*)&x_int64, (void*)&x_double, 8) ;
    printf("%s: %Lx (%g)\n", text, x_int64, x_double) ;
}
int main(int argc, char *argv[])
{
    int64_t NA_int64 = 0x7ff00000000007a2LL ;
    int64_t NaN_int64 = 0xfff8000000000000LL ;
    double NA_double, NaN_double, sum_double ;

    memcpy((void*)&NA_double, (void*)&NA_int64, 8) ;
    memcpy((void*)&NaN_double, (void*)&NaN_int64, 8) ;

    print_double(" NA", NA_double);
    print_double("NaN", NaN_double);
    sum_double = NA_double + NaN_double ;
    print_double("NA+NaN", sum_double) ;
    sum_double = NaN_double + NA_double ;
    print_double("NaN+NA", sum_double);
    return 0 ;
}

Bill Dunlap
TIBCO Software Inc - Spotfire Division
wdunlap tibco.com  

> -----Original Message-----
> From: r-devel-bounces at r-project.org 
> [mailto:r-devel-bounces at r-project.org] On Behalf Of William Dunlap
> Sent: Friday, May 01, 2009 7:50 AM
> To: Martin Maechler
> Cc: r-devel at r-project.org
> Subject: Re: [Rd] NA_real_ <op> NaN -> NA or NaN, should we care?
> 
> > From: Martin Maechler [mailto:maechler at stat.math.ethz.ch] 
> > Sent: Friday, May 01, 2009 5:15 AM
> > To: William Dunlap
> > Cc: r-devel at r-project.org
> > Subject: Re: [Rd] NA_real_ <op> NaN -> NA or NaN, should we care?
> > 
> > >>>>> William Dunlap <wdunlap at tibco.com>
> > >>>>>     on Thu, 30 Apr 2009 10:51:43 -0700 writes:
> > 
> >     > On Linux when I compile R 2.10.0(devel) 
> > (src/main/arithmetic.c in
> >     > particular)
> >     > with gcc 3.4.5 using the flags -g -O2 I get 
> > noncommutative behavior when
> > 
> > is this really gcc 3.4.5  (which is quite old) ?
> 
> Yes, it was 3.4.5, but here is a self-contained example of the same
> issue using gcc 4.1.3 on an Ubuntu Linux machine:
> 
> % gcc -O2 t.c -o a.out ; ./a.out
> NA : 7ff00000000007a2
> NaN: fff8000000000000
> NA+NaN: 7ff80000000007a2
> NaN+NA: fff8000000000000
> % gcc  t.c -o a.out ; ./a.out
> NA : 7ff00000000007a2
> NaN: fff8000000000000
> NA+NaN: 7ff80000000007a2
> NaN+NA: 7ff80000000007a2
> % gcc -v
> Using built-in specs.
> Target: i486-linux-gnu
> Configured with: ../src/configure -v 
> --enable-languages=c,c++,fortran,objc,obj-c++,treelang 
> --prefix=/usr --enable-shared --with-system-zlib 
> --libexecdir=/usr/lib --without-included-gettext 
> --enable-threads=posix --enable-nls 
> --with-gxx-include-dir=/usr/include/c++/4.1.3 
> --program-suffix=-4.1 --enable-__cxa_atexit 
> --enable-clocale=gnu --enable-libstdcxx-debug --enable-mpfr 
> --enable-checking=release i486-linux-gnu
> Thread model: posix
> gcc version 4.1.3 20070929 (prerelease) (Ubuntu 4.1.2-16ubuntu2)
> % cat t.c
> #include <stdio.h>
> #include <stdint.h>
> #include <string.h>
> 
> int main(int argc, char *argv[])
> {
>     int64_t NA_int64 = 0x7ff00000000007a2LL ;
>     int64_t NaN_int64 = 0xfff8000000000000LL ;
>     int64_t sum_int64 ;
>     double NA_double, NaN_double, sum_double ;
> 
>     memcpy((void*)&NA_double, (void*)&NA_int64, 8) ;
>     memcpy((void*)&NaN_double, (void*)&NaN_int64, 8) ;
> 
>     NaN_double = 1/0.0 - 1/0.0 ;
> 
>     printf("NA : %Lx\n", *(int64_t*)&NA_double);
>     printf("NaN: %Lx\n", *(int64_t*)&NaN_double);
>     sum_double = NA_double + NaN_double ;
>     memcpy((void*)&sum_int64, (void*)&sum_double, 8) ;
>     printf("NA+NaN: %Lx\n", sum_int64) ;
>     sum_double = NaN_double + NA_double ;
>     memcpy((void*)&sum_int64, (void*)&sum_double, 8) ;
>     printf("NaN+NA: %Lx\n", sum_int64);
>     return 0 ;
> }
> 
> When I add -Wall to the -O2 then it gives me some warnings about the
> *(int64_t)&doubleVal in the printf statements for the inputs, 
> but I used
> memcpy() to avoid the warnings when printing the outputs.
> 
> % gcc -Wall -O2 t.c -o a.out ; ./a.out
> t.c: In function ?main?:
> t.c:17: warning: dereferencing type-punned pointer will break 
> strict-aliasing rules
> t.c:18: warning: dereferencing type-punned pointer will break 
> strict-aliasing rules
> NA : 7ff00000000007a2
> NaN: fff8000000000000
> NA+NaN: 7ff80000000007a2
> NaN+NA: fff8000000000000
> 
> Bill Dunlap
> TIBCO Software Inc - Spotfire Division
> wdunlap tibco.com  
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 


From rgentlem at fhcrc.org  Fri May  1 18:50:40 2009
From: rgentlem at fhcrc.org (Robert Gentleman)
Date: Fri, 01 May 2009 09:50:40 -0700
Subject: [Rd] a statement about package licenses
Message-ID: <49FB2860.60108@fhcrc.org>

We are writing on behalf of the R Foundation, to clarify our position on
the licenses under which developers may distribute R packages.
Readers should also see FAQ 2.11: this message is not legal advice,
which we never offer.  Readers should also be aware that besides
the R Foundation, R has many other copyright holders, listed in the
copyright notices in the source.  Each of those copyright holders may
have a different opinion on the issues discussed here.

We welcome packages that extend the capabilities of R, and believe
that their value to the community is increased if they can be offered
with open-source licenses.  At the same time, we have no desire to
discourage other license forms that developers feel are required. Of
course, such licenses as well as the contents of the package and the
way in which it is distributed must respect the rights of the copyright
holders and the terms of the R license.

When we think that a package is in violation of these rights, we
contact the author directly, and so far package authors have always agreed to
comply with our license (or convinced us that they are already in compliance).
We have no desire to be involved in legal actions---our interest is in providing
good software.  However, everyone should understand that there are conceivable
circumstances in which we would be obliged to take action. Our experience to
date and the assurances of some fine commercial developers make us optimistic
that these circumstances will not arise.

The R Foundation


From nashjc at uottawa.ca  Fri May  1 19:52:33 2009
From: nashjc at uottawa.ca (John C Nash)
Date: Fri, 01 May 2009 13:52:33 -0400
Subject: [Rd] nlminb - Port library codes
Message-ID: <49FB36E1.8090106@uottawa.ca>

Having looked at documentation and codes, I'm still looking to find out 
who did the installation of the Port libraries. As I work on 
optimization code improvements, there are often choices of settings 
(tolerances etc.), and I'd prefer to learn if there are particular 
reasons for choices before diving in and making any adjustments.

It is also worth giving credit where it is due. Given the complexity of 
the Port code structure, adapting them to R must have been a lot of work.

JN


From devin.johnson at noaa.gov  Fri May  1 19:48:10 2009
From: devin.johnson at noaa.gov (DevinJ)
Date: Fri, 1 May 2009 10:48:10 -0700 (PDT)
Subject: [Rd] crash after using graphics in Rcmdr (PR#13679)
In-Reply-To: <49848470-CCA0-4105-A817-4E365BB378E3@me.com>
References: <20090428172515.2E4E928321A2@mail.pubhealth.ku.dk>
	<003501c9c997$b32cc470$19864d50$@ca>
	<49848470-CCA0-4105-A817-4E365BB378E3@me.com>
Message-ID: <23337174.post@talk.nabble.com>


This happens to me every time I try a plot command from TextWrangler with the
following applescript

tell application "TextWrangler"
	set the_selection to (selection of front window as string)
	if (the_selection) is "" then
		set the_selection to line (get startLine of selection) of front window as
string
	end if
end tell
tell application "R64"
	cmd the_selection
end tell

I don't know if that sheds any light on the situation. I do like
TextWrangler but can't use it because any time I send a plot command over it
plots fine with Quartz, but when I close the window (manually or with
dev.off()) I get the segfault. 


Rob Goedman-3 wrote:
> 
> John,
> 
> To the best of my knowledge this problem in R.app has been around at  
> least since the R-2.8 days, but likely much longer. I never use R from  
> a Terminal, so don't know if it occurs or not outside R.app.
> 
> It's not related to Rcmdr and you're observation is indeed one of the  
> better ways to kind of reproduce the issue. Not sure if it always does  
> though. If you have a 'hard' way of crashing R.app, please let me know  
> the sequence. In cases when no output is written to the console of  
> R.app I tend to make sure I enter an empty line before closing the  
> graphics window.
> 
> This issue and sometimes very long sequences of plots (never have been  
> able to make that reproducible, sometimes the crash happens up to a  
> minute after R finishes a series of plots and I'm working in an  
> external editor like TextMate) are hard to pin down.
> 
> Regards,
> Rob
> 
> Note: Hope you don't mind I've removed the R-bugs & R-devel Cc's.
> 
> On Apr 30, 2009, at 6:29 AM, John Fox wrote:
> 
>> Dear Neil,
>>
>> I had R 2.8.0 installed on my Mac Book, also with OS X 10.5.6, and was
>> unable to duplicate this problem. I then installed R 2.9.0 and  
>> observed the
>> same problem that you did. In both cases, I used the latest version  
>> of the
>> Rcmdr package, 1.4-10.
>>
>> I also observed the following: (1) The problem occurred only if I  
>> closed the
>> Quartz graphics device after the first graph was plotted; if I plotted
>> another graph and then closed the device, the problem did not occur.  
>> (2) The
>> problem did not occur if I ran R from a terminal with an X11  
>> graphics device
>> rather than using R.app.
>>
>> I'm afraid that there's not much more that I can do at this point,  
>> since my
>> familiarity with Macs is minimal. I'm copying this message to Rob  
>> Goedman,
>> who has proven helpful in the past. Of course, if there's something  
>> in the
>> Rcmdr that's causing the problem and I can fix it, I will.
>>
>> Regards,
>> John
>>
>>
>>> -----Original Message-----
>>> From: r-devel-bounces at r-project.org
>>> [mailto:r-devel-bounces at r-project.org 
>>> ]
>> On
>>> Behalf Of nhepburn at ualberta.ca
>>> Sent: April-28-09 1:25 PM
>>> To: r-devel at stat.math.ethz.ch
>>> Cc: R-bugs at r-project.org
>>> Subject: [Rd] crash after using graphics in Rcmdr (PR#13679)
>>>
>>> Full_Name: Neil Hepburn
>>> Version: 2.81 and 2.90
>>> OS: OS-X 10.5.6
>>> Submission from: (NULL) (142.244.28.93)
>>>
>>>
>>> When I create graphs using Rcmdr and then close the quartz display, R
>> blows
>>> up
>>> and tells me of a segmentation fault. It then gives me
>>> *** caught segfault ***
>>> address 0xc0000023, cause 'memory not mapped'
>>>
>>> Possible actions:
>>> 1: abort (with core dump, if enabled)
>>> 2: normal R exit
>>> 3: exit R without saving workspace
>>> 4: exit R saving workspace
>>>>
>>> Selection:
>>>
>>> This only happens if I create the graphics from within Rcmdr. If I  
>>> create
>> the
>>> graphics manually, there is no problem. This occurs on my laptop  
>>> with R
>> 2.8.1
>>> (I
>>> uninstalled 2.9 and reinstall 2.8.1 to see if the problem existed  
>>> there)
>> and
>>> also on my iMac with R2.9.
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 

-- 
View this message in context: http://www.nabble.com/crash-after-using-graphics-in-Rcmdr-%28PR-13679%29-tp23312961p23337174.html
Sent from the R devel mailing list archive at Nabble.com.


From payam.minoofar at meissner.com  Sat May  2 00:55:11 2009
From: payam.minoofar at meissner.com (payam.minoofar at meissner.com)
Date: Sat,  2 May 2009 00:55:11 +0200 (CEST)
Subject: [Rd] Workspace Browser doesn't refresh (PR#13684)
Message-ID: <20090501225511.A0513283219C@mail.pubhealth.ku.dk>

Full_Name: Payam Minoofar
Version: R 2.9.0 GUI 1.28 Tiger build 32-bit (5395)
OS: 10.5.6
Submission from: (NULL) (173.51.1.126)


Hi,

This bug happens when I have the workspace browser open, then issue the "clear
workspace" command from the "workspace" menu, and then click the "refresh"
button in the workspace browser. All the objects in the workspace persist in the
browser even though the console echoes "empty workspace, nothing to be done". 

The same behavior persists if I manually remove an object via the console with
rm.

Payam


From daniel.sabanesbove at gmx.net  Sat May  2 13:30:09 2009
From: daniel.sabanesbove at gmx.net (daniel.sabanesbove at gmx.net)
Date: Sat,  2 May 2009 13:30:09 +0200 (CEST)
Subject: [Rd] installation of source package with empty man directory fails
	(PR#13685)
Message-ID: <20090502113009.0D0332832187@mail.pubhealth.ku.dk>

Full_Name: Daniel Sabanes Bove
Version: 2.9.0
OS: openSUSE 11.1 (2.6.27.21)
Submission from: (NULL) (91.13.255.113)


- Situation:
Checking or installing an R package with existing but empty man directory fails.
Perhaps this is a feature, but then a nice error message like
"Subdirectory 'man' contains no help pages!"
would be great.

- Error:
* Installing *source* package ?test? ...
** R
** preparing package for lazy loading
** help
*** installing help indices
Fehler in `[.data.frame`(M, , 4) : undefined columns selected

- Reproduce:
Start an R session, create (at least) one test object and run package.skeleton.
Then R CMD check the test package.


From r.hijmans at gmail.com  Sat May  2 14:10:09 2009
From: r.hijmans at gmail.com (r.hijmans at gmail.com)
Date: Sat,  2 May 2009 14:10:09 +0200 (CEST)
Subject: [Rd] dir.create does not return a value (PR#13686)
Message-ID: <20090502121009.A88EC2832187@mail.pubhealth.ku.dk>

?dir.create  (part of the base package) says that:
"dir.create and Sys.chmod return a logical vector indicating which
operation succeeded for each of the files attempted"

However, on my system it returns nothing  (whether successful or not):

> dir.create(":::@!#!::")
> dir.create('b')


> sessionInfo()
R version 2.9.0 (2009-04-17)
i386-pc-mingw32

locale:
LC_COLLATE=English_United States.1252;LC_CTYPE=English_United
States.1252;LC_MONETARY=English_United
States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base
>

HTH, Robert


From sdorairaj at gmail.com  Sat May  2 14:27:33 2009
From: sdorairaj at gmail.com (Sundar Dorai-Raj)
Date: Sat, 2 May 2009 05:27:33 -0700
Subject: [Rd] dir.create does not return a value (PR#13686)
In-Reply-To: <20090502121009.A88EC2832187@mail.pubhealth.ku.dk>
References: <20090502121009.A88EC2832187@mail.pubhealth.ku.dk>
Message-ID: <c9ce82b00905020527m39eeb461q5b388d685f0690d0@mail.gmail.com>

Not a bug. Try:

print(dir.create("foo"))

or

foo <- dir.create("foo")
foo

HTH,

--sundar

On Sat, May 2, 2009 at 5:10 AM,  <r.hijmans at gmail.com> wrote:
> ?dir.create ?(part of the base package) says that:
> "dir.create and Sys.chmod return a logical vector indicating which
> operation succeeded for each of the files attempted"
>
> However, on my system it returns nothing ?(whether successful or not):
>
>> dir.create(":::@!#!::")
>> dir.create('b')
>
>
>> sessionInfo()
> R version 2.9.0 (2009-04-17)
> i386-pc-mingw32
>
> locale:
> LC_COLLATE=English_United States.1252;LC_CTYPE=English_United
> States.1252;LC_MONETARY=English_United
> States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252
>
> attached base packages:
> [1] stats ? ? graphics ?grDevices utils ? ? datasets ?methods ? base
>>
>
> HTH, Robert
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From sdorairaj at gmail.com  Sat May  2 14:30:32 2009
From: sdorairaj at gmail.com (Sundar Dorai-Raj)
Date: Sat, 2 May 2009 05:30:32 -0700
Subject: [Rd] dir.create does not return a value (PR#13686)
In-Reply-To: <c9ce82b00905020527m39eeb461q5b388d685f0690d0@mail.gmail.com>
References: <20090502121009.A88EC2832187@mail.pubhealth.ku.dk> 
	<c9ce82b00905020527m39eeb461q5b388d685f0690d0@mail.gmail.com>
Message-ID: <c9ce82b00905020530r39c3cd2n4ca110373cc4a116@mail.gmail.com>

However, there is a bug in ?dir.create:

"'dir.create' indicates failure if the dirwctory already  exiss."

> sessionInfo()
R version 2.9.0 (2009-04-17)
i386-apple-darwin8.11.1

locale:
en_US.UTF-8/en_US.UTF-8/C/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

On Sat, May 2, 2009 at 5:27 AM, Sundar Dorai-Raj <sdorairaj at gmail.com> wrote:
> Not a bug. Try:
>
> print(dir.create("foo"))
>
> or
>
> foo <- dir.create("foo")
> foo
>
> HTH,
>
> --sundar
>
> On Sat, May 2, 2009 at 5:10 AM, ?<r.hijmans at gmail.com> wrote:
>> ?dir.create ?(part of the base package) says that:
>> "dir.create and Sys.chmod return a logical vector indicating which
>> operation succeeded for each of the files attempted"
>>
>> However, on my system it returns nothing ?(whether successful or not):
>>
>>> dir.create(":::@!#!::")
>>> dir.create('b')
>>
>>
>>> sessionInfo()
>> R version 2.9.0 (2009-04-17)
>> i386-pc-mingw32
>>
>> locale:
>> LC_COLLATE=English_United States.1252;LC_CTYPE=English_United
>> States.1252;LC_MONETARY=English_United
>> States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252
>>
>> attached base packages:
>> [1] stats ? ? graphics ?grDevices utils ? ? datasets ?methods ? base
>>>
>>
>> HTH, Robert
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>


From r.hijmans at gmail.com  Sat May  2 14:41:37 2009
From: r.hijmans at gmail.com (Robert Hijmans)
Date: Sat, 2 May 2009 20:41:37 +0800
Subject: [Rd] dir.create does not return a value (PR#13686)
In-Reply-To: <c9ce82b00905020527m39eeb461q5b388d685f0690d0@mail.gmail.com>
References: <20090502121009.A88EC2832187@mail.pubhealth.ku.dk>
	<c9ce82b00905020527m39eeb461q5b388d685f0690d0@mail.gmail.com>
Message-ID: <dc22b2570905020541n1941e631h683d2f1c457cb8e0@mail.gmail.com>

Thanks, I am not sure if this is desirable (a function returning a
value only when 'asked' to do so), but I am intrigued. How can one put
such behaviour in an R function?

Robert


On Sat, May 2, 2009 at 8:27 PM, Sundar Dorai-Raj <sdorairaj at gmail.com> wrote:
> Not a bug. Try:
>
> print(dir.create("foo"))
>
> or
>
> foo <- dir.create("foo")
> foo
>
> HTH,
>
> --sundar
>
> On Sat, May 2, 2009 at 5:10 AM, ?<r.hijmans at gmail.com> wrote:
>> ?dir.create ?(part of the base package) says that:
>> "dir.create and Sys.chmod return a logical vector indicating which
>> operation succeeded for each of the files attempted"
>>
>> However, on my system it returns nothing ?(whether successful or not):
>>
>>> dir.create(":::@!#!::")
>>> dir.create('b')
>>
>>
>>> sessionInfo()
>> R version 2.9.0 (2009-04-17)
>> i386-pc-mingw32
>>
>> locale:
>> LC_COLLATE=English_United States.1252;LC_CTYPE=English_United
>> States.1252;LC_MONETARY=English_United
>> States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252
>>
>> attached base packages:
>> [1] stats ? ? graphics ?grDevices utils ? ? datasets ?methods ? base
>>>
>>
>> HTH, Robert
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>


From josh.m.ulrich at gmail.com  Sat May  2 15:47:31 2009
From: josh.m.ulrich at gmail.com (Josh Ulrich)
Date: Sat, 2 May 2009 08:47:31 -0500
Subject: [Rd] dir.create does not return a value (PR#13686)
In-Reply-To: <dc22b2570905020541n1941e631h683d2f1c457cb8e0@mail.gmail.com>
References: <20090502121009.A88EC2832187@mail.pubhealth.ku.dk>
	<c9ce82b00905020527m39eeb461q5b388d685f0690d0@mail.gmail.com>
	<dc22b2570905020541n1941e631h683d2f1c457cb8e0@mail.gmail.com>
Message-ID: <8cca69990905020647n2d558402odaea8949e0e26a89@mail.gmail.com>

Robert,

The function always returns a value, but it doesn't print the value.
Look at the source code for dir.create(), then read ?invisible.

Best,
Josh
--
http://www.fosstrading.com



On Sat, May 2, 2009 at 7:41 AM, Robert Hijmans <r.hijmans at gmail.com> wrote:
> Thanks, I am not sure if this is desirable (a function returning a
> value only when 'asked' to do so), but I am intrigued. How can one put
> such behaviour in an R function?
>
> Robert
>
>
> On Sat, May 2, 2009 at 8:27 PM, Sundar Dorai-Raj <sdorairaj at gmail.com> wrote:
>> Not a bug. Try:
>>
>> print(dir.create("foo"))
>>
>> or
>>
>> foo <- dir.create("foo")
>> foo
>>
>> HTH,
>>
>> --sundar
>>
>> On Sat, May 2, 2009 at 5:10 AM, ?<r.hijmans at gmail.com> wrote:
>>> ?dir.create ?(part of the base package) says that:
>>> "dir.create and Sys.chmod return a logical vector indicating which
>>> operation succeeded for each of the files attempted"
>>>
>>> However, on my system it returns nothing ?(whether successful or not):
>>>
>>>> dir.create(":::@!#!::")
>>>> dir.create('b')
>>>
>>>
>>>> sessionInfo()
>>> R version 2.9.0 (2009-04-17)
>>> i386-pc-mingw32
>>>
>>> locale:
>>> LC_COLLATE=English_United States.1252;LC_CTYPE=English_United
>>> States.1252;LC_MONETARY=English_United
>>> States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252
>>>
>>> attached base packages:
>>> [1] stats ? ? graphics ?grDevices utils ? ? datasets ?methods ? base
>>>>
>>>
>>> HTH, Robert
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From ligges at statistik.tu-dortmund.de  Sat May  2 17:31:48 2009
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sat, 02 May 2009 17:31:48 +0200
Subject: [Rd] installation of source package with empty man directory
 fails	(PR#13685)
In-Reply-To: <20090502113009.0D0332832187@mail.pubhealth.ku.dk>
References: <20090502113009.0D0332832187@mail.pubhealth.ku.dk>
Message-ID: <49FC6764.8030501@statistik.tu-dortmund.de>

This is already fixed in R-patched.

Please read the FAQs about bugs and try the recent R-patched or R-devel 
version.

Best,
Uwe Ligges



daniel.sabanesbove at gmx.net wrote:
> Full_Name: Daniel Sabanes Bove
> Version: 2.9.0
> OS: openSUSE 11.1 (2.6.27.21)
> Submission from: (NULL) (91.13.255.113)
> 
> 
> - Situation:
> Checking or installing an R package with existing but empty man directory fails.
> Perhaps this is a feature, but then a nice error message like
> "Subdirectory 'man' contains no help pages!"
> would be great.
> 
> - Error:
> * Installing *source* package ?test? ...
> ** R
> ** preparing package for lazy loading
> ** help
> *** installing help indices
> Fehler in `[.data.frame`(M, , 4) : undefined columns selected
> 
> - Reproduce:
> Start an R session, create (at least) one test object and run package.skeleton.
> Then R CMD check the test package.
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From ligges at statistik.tu-dortmund.de  Sat May  2 17:35:10 2009
From: ligges at statistik.tu-dortmund.de (ligges at statistik.tu-dortmund.de)
Date: Sat,  2 May 2009 17:35:10 +0200 (CEST)
Subject: [Rd] installation of source package with empty man directory
	(PR#13687)
Message-ID: <20090502153510.4BAB22832188@mail.pubhealth.ku.dk>

This is already fixed in R-patched.

Please read the FAQs about bugs and try the recent R-patched or R-devel 
version.

Best,
Uwe Ligges



daniel.sabanesbove at gmx.net wrote:
> Full_Name: Daniel Sabanes Bove
> Version: 2.9.0
> OS: openSUSE 11.1 (2.6.27.21)
> Submission from: (NULL) (91.13.255.113)
> 
> 
> - Situation:
> Checking or installing an R package with existing but empty man directory fails.
> Perhaps this is a feature, but then a nice error message like
> "Subdirectory 'man' contains no help pages!"
> would be great.
> 
> - Error:
> * Installing *source* package ?test? ...
> ** R
> ** preparing package for lazy loading
> ** help
> *** installing help indices
> Fehler in `[.data.frame`(M, , 4) : undefined columns selected
> 
> - Reproduce:
> Start an R session, create (at least) one test object and run package.skeleton.
> Then R CMD check the test package.
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From saptarshi.guha at gmail.com  Sun May  3 00:53:17 2009
From: saptarshi.guha at gmail.com (Saptarshi Guha)
Date: Sat, 2 May 2009 18:53:17 -0400
Subject: [Rd] set.seed and /dev/random
Message-ID: <1e7471d50905021553s57857f87gbfcbdabedc006b79@mail.gmail.com>

Hello,
In ?set.seed I notice that a seed is created from the system time.
Thus if two machines were (hypothetically) running for the same time
and R was started simultaneously on both, the would have the same
seeds (correct?).

I assume reading from /dev/random would be different for both of these
machines, so my question is why not use an integer read from
/dev/random to create the seed?

Would it be a portability issue?
I must admit I have very little idea about RNGs, so my question is
possibly very naive.

Thank you
Saptarshi


From edd at debian.org  Sun May  3 01:21:01 2009
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sat, 2 May 2009 18:21:01 -0500
Subject: [Rd] set.seed and /dev/random
In-Reply-To: <1e7471d50905021553s57857f87gbfcbdabedc006b79@mail.gmail.com>
References: <1e7471d50905021553s57857f87gbfcbdabedc006b79@mail.gmail.com>
Message-ID: <18940.54621.1986.309356@ron.nulle.part>


On 2 May 2009 at 18:53, Saptarshi Guha wrote:
| Hello,
| In ?set.seed I notice that a seed is created from the system time.
| Thus if two machines were (hypothetically) running for the same time
| and R was started simultaneously on both, the would have the same
| seeds (correct?).
| 
| I assume reading from /dev/random would be different for both of these
| machines, so my question is why not use an integer read from
| /dev/random to create the seed?

Some folks do. But do read the fine print about entropy etc.  

An alternnative is provided by the random package on CRAN (slightly
re-indented below).

Dirk


R> library(help=random)

		Information on package 'random'

Description:

Package:       random
Version:       0.2.0
Date:          $Date: 2009-01-03 11:45:17 -0600 (Sat, 03 Jan 2009) $
Author:        Dirk Eddelbuettel <edd at debian.org>
Maintainer:    Dirk Eddelbuettel <edd at debian.org>
Title:         True random numbers using random.org
Description:   This package provides an interface to the true random number
	       service provided by the random.org website created by Mads
	       Haahr.  The random.org web service samples atmospheric noise
	       via radio tuned to an unused broadcasting frequency together
	       with a skew correction algorithm due to John von Neumann.
	       More background is available in the included vignette based on
	       an essay by Mads Haahr. In its current form, the package
	       offers functions to retrieve random integers, randomized
	       sequences and random strings.
Depends:       R (>= 2.8.0)
License:       GPL Version 2
URL:           http://www.random.org
Built:         R 2.8.1; ; 2009-01-03 11:46:25; unix

Index:

random                  True random numbers from random.org

Further information is available in the following vignettes in directory
'/usr/local/lib/R/site-library/random/doc':

random-essay: random.org: Introduction to Randomness and Random Numbers (source, pdf)
random-intro: random: An R package for true random numbers (source, pdf)

R> 

 
| Would it be a portability issue?
| I must admit I have very little idea about RNGs, so my question is
| possibly very naive.
| 
| Thank you
| Saptarshi
| 
| ______________________________________________
| R-devel at r-project.org mailing list
| https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Three out of two people have difficulties with fractions.


From saptarshi.guha at gmail.com  Sun May  3 16:54:58 2009
From: saptarshi.guha at gmail.com (Saptarshi Guha)
Date: Sun, 3 May 2009 10:54:58 -0400
Subject: [Rd] set.seed and /dev/random
In-Reply-To: <18940.54621.1986.309356@ron.nulle.part>
References: <1e7471d50905021553s57857f87gbfcbdabedc006b79@mail.gmail.com>
	<18940.54621.1986.309356@ron.nulle.part>
Message-ID: <1e7471d50905030754pc194825v51d8b0ab16548097@mail.gmail.com>

Interesting stuff.
Thank you

Saptarshi



On Sat, May 2, 2009 at 7:21 PM, Dirk Eddelbuettel <edd at debian.org> wrote:
>
> On 2 May 2009 at 18:53, Saptarshi Guha wrote:
> | Hello,
> | In ?set.seed I notice that a seed is created from the system time.
> | Thus if two machines were (hypothetically) running for the same time
> | and R was started simultaneously on both, the would have the same
> | seeds (correct?).
> |
> | I assume reading from /dev/random would be different for both of these
> | machines, so my question is why not use an integer read from
> | /dev/random to create the seed?
>
> Some folks do. But do read the fine print about entropy etc.
>
> An alternnative is provided by the random package on CRAN (slightly
> re-indented below).
>
> Dirk
>
>
> R> library(help=random)
>
> ? ? ? ? ? ? ? ?Information on package 'random'
>
> Description:
>
> Package: ? ? ? random
> Version: ? ? ? 0.2.0
> Date: ? ? ? ? ?$Date: 2009-01-03 11:45:17 -0600 (Sat, 03 Jan 2009) $
> Author: ? ? ? ?Dirk Eddelbuettel <edd at debian.org>
> Maintainer: ? ?Dirk Eddelbuettel <edd at debian.org>
> Title: ? ? ? ? True random numbers using random.org
> Description: ? This package provides an interface to the true random number
> ? ? ? ? ? ? ? service provided by the random.org website created by Mads
> ? ? ? ? ? ? ? Haahr. ?The random.org web service samples atmospheric noise
> ? ? ? ? ? ? ? via radio tuned to an unused broadcasting frequency together
> ? ? ? ? ? ? ? with a skew correction algorithm due to John von Neumann.
> ? ? ? ? ? ? ? More background is available in the included vignette based on
> ? ? ? ? ? ? ? an essay by Mads Haahr. In its current form, the package
> ? ? ? ? ? ? ? offers functions to retrieve random integers, randomized
> ? ? ? ? ? ? ? sequences and random strings.
> Depends: ? ? ? R (>= 2.8.0)
> License: ? ? ? GPL Version 2
> URL: ? ? ? ? ? http://www.random.org
> Built: ? ? ? ? R 2.8.1; ; 2009-01-03 11:46:25; unix
>
> Index:
>
> random ? ? ? ? ? ? ? ? ?True random numbers from random.org
>
> Further information is available in the following vignettes in directory
> '/usr/local/lib/R/site-library/random/doc':
>
> random-essay: random.org: Introduction to Randomness and Random Numbers (source, pdf)
> random-intro: random: An R package for true random numbers (source, pdf)
>
> R>
>
>
> | Would it be a portability issue?
> | I must admit I have very little idea about RNGs, so my question is
> | possibly very naive.
> |
> | Thank you
> | Saptarshi
> |
> | ______________________________________________
> | R-devel at r-project.org mailing list
> | https://stat.ethz.ch/mailman/listinfo/r-devel
>
> --
> Three out of two people have difficulties with fractions.
>


From tlumley at u.washington.edu  Sun May  3 21:46:26 2009
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Sun, 3 May 2009 12:46:26 -0700 (PDT)
Subject: [Rd] set.seed and /dev/random
In-Reply-To: <1e7471d50905021553s57857f87gbfcbdabedc006b79@mail.gmail.com>
Message-ID: <Pine.LNX.4.43.0905031246260.28507@hymn14.u.washington.edu>

On Sat, 2 May 2009, Saptarshi Guha wrote:

> Hello,
> In ?set.seed I notice that a seed is created from the system time.
> Thus if two machines were (hypothetically) running for the same time
> and R was started simultaneously on both, the would have the same
> seeds (correct?).

Yes. This could in principle be a problem for clusters, though that level of synchronization is unlikely.

> I assume reading from /dev/random would be different for both of these
> machines, so my question is why not use an integer read from
> /dev/random to create the seed?
>
> Would it be a portability issue?

Yes. Most R users probably don't have /dev/random

    -thomas

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle


From savicky at cs.cas.cz  Sun May  3 22:32:04 2009
From: savicky at cs.cas.cz (Petr Savicky)
Date: Sun, 3 May 2009 22:32:04 +0200
Subject: [Rd] suggestion for extending ?as.factor
Message-ID: <20090503203204.GB29507@cs.cas.cz>

In R-2.10.0, the development version, function as.factor() uses 17 digit
precision for conversion of numeric values to character type. This
is very good for the consistency of the resulting factor, however,
i expect that people will complain about, for example, as.factor(0.3)
being
  [1] 0.29999999999999999
  Levels: 0.29999999999999999

I suggest to extend the "Warning" section of ?as.factor by the following
paragraph.

If as.factor() is used for a numeric vector, then the numbers are
converted to character strings with 17 digit precision using their
machine representation. This guarantees that different numbers are
converted to different levels, but may produce unwanted results, if
the numbers are expected to have limited number of decimal positions.
For example, as.factor(c(0.1, 0.2, 0.3)) produces
  [1] 0.10000000000000001 0.20000000000000001 0.29999999999999999
  Levels: 0.10000000000000001 0.20000000000000001 0.29999999999999999
In order to avoid this, convert the numbers to a character vector
using formatC() or a similar function before using as.factor().

Petr.


From maechler at stat.math.ethz.ch  Mon May  4 10:40:12 2009
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 4 May 2009 10:40:12 +0200
Subject: [Rd] suggestion for extending ?as.factor
In-Reply-To: <20090503203204.GB29507@cs.cas.cz>
References: <20090503203204.GB29507@cs.cas.cz>
Message-ID: <18942.43500.862186.878365@lynne.math.ethz.ch>

>>>>> "PS" == Petr Savicky <savicky at cs.cas.cz>
>>>>>     on Sun, 3 May 2009 22:32:04 +0200 writes:
>>>>> "PS" == Petr Savicky <savicky at cs.cas.cz>
>>>>>     on Sun, 3 May 2009 22:32:04 +0200 writes:

    PS> In R-2.10.0, the development version, function as.factor() uses 17 digit
    PS> precision for conversion of numeric values to character type. This
    PS> is very good for the consistency of the resulting factor, however,
    PS> i expect that people will complain about, for example, as.factor(0.3)
    PS> being
    PS> [1] 0.29999999999999999
    PS> Levels: 0.29999999999999999

    PS> I suggest to extend the "Warning" section of ?as.factor by the following
    PS> paragraph.

    PS> If as.factor() is used for a numeric vector, then the numbers are
    PS> converted to character strings with 17 digit precision using their
    PS> machine representation. This guarantees that different numbers are
    PS> converted to different levels, but may produce unwanted results, if
    PS> the numbers are expected to have limited number of decimal positions.
    PS> For example, as.factor(c(0.1, 0.2, 0.3)) produces
    PS> [1] 0.10000000000000001 0.20000000000000001 0.29999999999999999
    PS> Levels: 0.10000000000000001 0.20000000000000001 0.29999999999999999
    PS> In order to avoid this, convert the numbers to a character vector
    PS> using formatC() or a similar function before using as.factor().

    PS> Petr.

Thank you, Petr, for the good suggestion.

I have added a (shorter) paragraph, though to the 'Details' not the
'Warning' section, and also one to the 'Examples' :

## Converting (non-integer) numbers:
as.factor(c(0.1, 0.2, 0.3)) # maybe not what you'd expect, so rather use
factor(format(c(0.1, 0.2, 0.3)))

Martin Maechler, ETH Zurich


From fabio.ufla at yahoo.com.br  Mon May  4 14:10:55 2009
From: fabio.ufla at yahoo.com.br (Fabio Mathias)
Date: Mon, 4 May 2009 05:10:55 -0700 (PDT)
Subject: [Rd] how to change nlme() contrast parametrization?
Message-ID: <589228.29407.qm@web59704.mail.ac4.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090504/705f1470/attachment.pl>

From fabio.ufla at yahoo.com.br  Mon May  4 14:27:48 2009
From: fabio.ufla at yahoo.com.br (Fabio Mathias)
Date: Mon, 4 May 2009 05:27:48 -0700 (PDT)
Subject: [Rd] how to change nlme() contrast parametrization?
Message-ID: <773703.31441.qm@web59707.mail.ac4.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090504/2c32e223/attachment.pl>

From P.Dalgaard at biostat.ku.dk  Mon May  4 15:34:09 2009
From: P.Dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Mon, 04 May 2009 15:34:09 +0200
Subject: [Rd] suggestion for extending ?as.factor
In-Reply-To: <18942.43500.862186.878365@lynne.math.ethz.ch>
References: <20090503203204.GB29507@cs.cas.cz>
	<18942.43500.862186.878365@lynne.math.ethz.ch>
Message-ID: <49FEEED1.8000808@biostat.ku.dk>

Martin Maechler wrote:
>>>>>> "PS" == Petr Savicky <savicky at cs.cas.cz>
>>>>>>     on Sun, 3 May 2009 22:32:04 +0200 writes:
>>>>>> "PS" == Petr Savicky <savicky at cs.cas.cz>
>>>>>>     on Sun, 3 May 2009 22:32:04 +0200 writes:
> 
>     PS> In R-2.10.0, the development version, function as.factor() uses 17 digit
>     PS> precision for conversion of numeric values to character type. This
>     PS> is very good for the consistency of the resulting factor, however,
>     PS> i expect that people will complain about, for example, as.factor(0.3)
>     PS> being
>     PS> [1] 0.29999999999999999
>     PS> Levels: 0.29999999999999999
> 
>     PS> I suggest to extend the "Warning" section of ?as.factor by the following
>     PS> paragraph.
> 
>     PS> If as.factor() is used for a numeric vector, then the numbers are
>     PS> converted to character strings with 17 digit precision using their
>     PS> machine representation. This guarantees that different numbers are
>     PS> converted to different levels, but may produce unwanted results, if
>     PS> the numbers are expected to have limited number of decimal positions.
>     PS> For example, as.factor(c(0.1, 0.2, 0.3)) produces
>     PS> [1] 0.10000000000000001 0.20000000000000001 0.29999999999999999
>     PS> Levels: 0.10000000000000001 0.20000000000000001 0.29999999999999999
>     PS> In order to avoid this, convert the numbers to a character vector
>     PS> using formatC() or a similar function before using as.factor().
> 
>     PS> Petr.
> 
> Thank you, Petr, for the good suggestion.
> 
> I have added a (shorter) paragraph, though to the 'Details' not the
> 'Warning' section, and also one to the 'Examples' :
> 
> ## Converting (non-integer) numbers:
> as.factor(c(0.1, 0.2, 0.3)) # maybe not what you'd expect, so rather use
> factor(format(c(0.1, 0.2, 0.3)))

Martin,

I tend to consider this a bug, plain and simple. We might as well have
abolished conversion of numerics to factor altogether. (Notice, BTW,
that conversions to mode "character" changes the sort order so format()
is not a universal fix. IIRC, we did consider the 1 10 2 3 4 5 6 7 8 9
issue when designing R's version factor().)

The current R-devel behaviour is silly and we should just get rid of it
before a final release. It should be the other way around: If people
rely on whether numerical factor levels differ with 17 digits precision,
THEN they should use format with suitable arguments.

If we have issues with numeric values that are very slightly different
but round to get the same level name, how about putting something like

if (is.numeric(x)) x <- zapsmall(x)

somewhere at the start of the factor() function?

-p


-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark      Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)              FAX: (+45) 35327907


From maechler at stat.math.ethz.ch  Mon May  4 17:39:52 2009
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 4 May 2009 17:39:52 +0200
Subject: [Rd] suggestion for extending ?as.factor
In-Reply-To: <49FEEED1.8000808@biostat.ku.dk>
References: <20090503203204.GB29507@cs.cas.cz>
	<18942.43500.862186.878365@lynne.math.ethz.ch>
	<49FEEED1.8000808@biostat.ku.dk>
Message-ID: <18943.3144.768738.188706@lynne.math.ethz.ch>

>>>>> "PD" == Peter Dalgaard <P.Dalgaard at biostat.ku.dk>
>>>>>     on Mon, 04 May 2009 15:34:09 +0200 writes:

    PD> Martin Maechler wrote:
    >>>>>>> "PS" == Petr Savicky <savicky at cs.cas.cz>
    >>>>>>> on Sun, 3 May 2009 22:32:04 +0200 writes:
    >>>>>>> "PS" == Petr Savicky <savicky at cs.cas.cz>
    >>>>>>> on Sun, 3 May 2009 22:32:04 +0200 writes:
    >> 
    PS> In R-2.10.0, the development version, function as.factor() uses 17 digit
    PS> precision for conversion of numeric values to character type. This
    PS> is very good for the consistency of the resulting factor, however,
    PS> i expect that people will complain about, for example, as.factor(0.3)
    PS> being
    PS> [1] 0.29999999999999999
    PS> Levels: 0.29999999999999999
    >> 
    PS> I suggest to extend the "Warning" section of ?as.factor by the following
    PS> paragraph.
    >> 
    PS> If as.factor() is used for a numeric vector, then the numbers are
    PS> converted to character strings with 17 digit precision using their
    PS> machine representation. This guarantees that different numbers are
    PS> converted to different levels, but may produce unwanted results, if
    PS> the numbers are expected to have limited number of decimal positions.
    PS> For example, as.factor(c(0.1, 0.2, 0.3)) produces
    PS> [1] 0.10000000000000001 0.20000000000000001 0.29999999999999999
    PS> Levels: 0.10000000000000001 0.20000000000000001 0.29999999999999999
    PS> In order to avoid this, convert the numbers to a character vector
    PS> using formatC() or a similar function before using as.factor().
    >> 
    PS> Petr.
    >> 
    >> Thank you, Petr, for the good suggestion.
    >> 
    >> I have added a (shorter) paragraph, though to the 'Details' not the
    >> 'Warning' section, and also one to the 'Examples' :
    >> 
    >> ## Converting (non-integer) numbers:
    >> as.factor(c(0.1, 0.2, 0.3)) # maybe not what you'd expect, so rather use
    >> factor(format(c(0.1, 0.2, 0.3)))

    PD> Martin,

    PD> I tend to consider this a bug, plain and simple. We might as well have
    PD> abolished conversion of numerics to factor altogether.

hmm, that comparison *is* an exaggeration ((Much code would have
stopped working had we implemented the latter !!))

    PD> (Notice, BTW, that conversions to mode "character"
    PD> changes the sort order so format() is not a universal
    PD> fix. IIRC, we did consider the 1 10 2 3 4 5 6 7 8 9
    PD> issue when designing R's version factor().)

yes, but I did not understand why this is relevant here;
as
  > factor(c(10,1:9, 8:2,1:5))
   [1] 10 1  2  3  4  5  6  7  8  9  8  7  6  5  4  3  2  1  2  3  4  5 
  Levels: 1 2 3 4 5 6 7 8 9 10

also in earlier versions of R.

    PD> The current R-devel behaviour is silly and we should just get rid of it
    PD> before a final release. It should be the other way around: If people
    PD> rely on whether numerical factor levels differ with 17 digits precision,
    PD> THEN they should use format with suitable arguments.

Hmm, I know tend to agree that we must further change some of
the R-devel behavior.

    PD> If we have issues with numeric values that are very slightly different
    PD> but round to get the same level name, how about putting something like

    PD> if (is.numeric(x)) x <- zapsmall(x)

well, rather  

      if (is.numeric(x)) x <- signif(x, 15)

where '15' could be replaced by 7 or other values in 5:20

    PD> somewhere at the start of the factor() function?

Let me quickly expand the tasks we have wanted to address, when
I started changing factor() for R-devel.

1) R-core had unanimously decided that R 2.10.0 should not allow
   duplicated levels in factors anymore.

When working on that, I had realized that quite a few bits of code
were implicitly relying on duplicated levels (or something
related), see below, so the current version of R-devel only
*warns* in some cases where duplicated levels are produced
instead of giving an error.

What I had also found was that basically, even our own (!) code
and quite a bit of user code has more or less relied on other
things that were not true (even though "almost always" fulfilled):

2) if x contains no duplicated values, then  factor(x) should neither

3) factor(x) constructs a factor object with *unique* levels

  {This is what our decision "1)" implies and now enforces}

4) as.numeric(names(table(x))) should be  identical to unique(x)

  where "4)" is basically ensured by "3)" as table() calls
  factor() for non-factor args.

As mentioned the bad thing is that "2) - 4)" are typically
fulfilled in all tests package writers would use.

Concerning '3)' [and '1)'], as you know, inside R-core we have
proposed to at least ensure that  `levels<-` 
should not allow duplicated levels, 
and I had concluded that
a) factor() really should use  `levels<-` instead of the low-level	
   attr(., "levels") <- ....
b) factor() itself must make sure that the default levels became unique.

---

Given Petr's (and more) examples and the strong requirement of
"user convenience" and back-compatibility,
I now tend to agree (with Peter) that we cannot ensure all of 2)
and 4) still allow factor() to behave as it did for "rounded
decimal numbers",
and consequently would have to (continue to) not ensuring
properties (2) and (4).
Something quite unfortunate, since, as I said, much useR code
implicitly relies on these, and so that code is buggy even
though the bug will only show in exceptional cases.


Best,
Martin


From savicky at cs.cas.cz  Mon May  4 18:34:03 2009
From: savicky at cs.cas.cz (Petr Savicky)
Date: Mon, 4 May 2009 18:34:03 +0200
Subject: [Rd] suggestion for extending ?as.factor
In-Reply-To: <18943.3144.768738.188706@lynne.math.ethz.ch>
References: <20090503203204.GB29507@cs.cas.cz>
	<18942.43500.862186.878365@lynne.math.ethz.ch>
	<49FEEED1.8000808@biostat.ku.dk>
	<18943.3144.768738.188706@lynne.math.ethz.ch>
Message-ID: <20090504163403.GA10640@cs.cas.cz>

On Mon, May 04, 2009 at 05:39:52PM +0200, Martin Maechler wrote:
[snip]
> Let me quickly expand the tasks we have wanted to address, when
> I started changing factor() for R-devel.
> 
> 1) R-core had unanimously decided that R 2.10.0 should not allow
>    duplicated levels in factors anymore.
> 
> When working on that, I had realized that quite a few bits of code
> were implicitly relying on duplicated levels (or something
> related), see below, so the current version of R-devel only
> *warns* in some cases where duplicated levels are produced
> instead of giving an error.
> 
> What I had also found was that basically, even our own (!) code
> and quite a bit of user code has more or less relied on other
> things that were not true (even though "almost always" fulfilled):
> 
> 2) if x contains no duplicated values, then  factor(x) should neither
> 
> 3) factor(x) constructs a factor object with *unique* levels
> 
>   {This is what our decision "1)" implies and now enforces}
> 
> 4) as.numeric(names(table(x))) should be  identical to unique(x)
> 
>   where "4)" is basically ensured by "3)" as table() calls
>   factor() for non-factor args.
> 
> As mentioned the bad thing is that "2) - 4)" are typically
> fulfilled in all tests package writers would use.
> 
> Concerning '3)' [and '1)'], as you know, inside R-core we have
> proposed to at least ensure that  `levels<-` 
> should not allow duplicated levels, 
> and I had concluded that
> a) factor() really should use  `levels<-` instead of the low-level	
>    attr(., "levels") <- ....
> b) factor() itself must make sure that the default levels became unique.
> 
> ---
> 
> Given Petr's (and more) examples and the strong requirement of
> "user convenience" and back-compatibility,
> I now tend to agree (with Peter) that we cannot ensure all of 2)
> and 4) still allow factor() to behave as it did for "rounded
> decimal numbers",
> and consequently would have to (continue to) not ensuring
> properties (2) and (4).
> Something quite unfortunate, since, as I said, much useR code
> implicitly relies on these, and so that code is buggy even
> though the bug will only show in exceptional cases.

Let me suggest to consider also the following algorithm: determine
the number of digits needed to preserve the double value exactly for
each number separately. An R code prototype demonstrating the 
algorithm could be as follows

  convert <- function(x) # x should be a single number
  {
      for (d in 1:16) {
          y <- sprintf(paste("%.", d, "g", sep=""), x)
          if (x == as.numeric(y)) {
              return(y)
          }
      }
      return(sprintf("%.17g", x))
  }

For this, we get

  > convert(0.3)
  [1] "0.3"
  > convert(1/3)
  [1] "0.3333333333333333" # 16 digits suffice
  > convert(0.12345)
  [1] "0.12345"
  > convert(0.12345678901234567)
  [1] "0.12345678901234566"
  > 0.12345678901234567 == as.numeric("0.12345678901234566")
  [1] TRUE

This algorithm is slower than a single call to sprintf("%.17g", x), but it
produces nicer numbers, if possible, and guarantees that the value is
always preserved.

Petr.


From P.Dalgaard at biostat.ku.dk  Mon May  4 19:28:06 2009
From: P.Dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Mon, 04 May 2009 19:28:06 +0200
Subject: [Rd] suggestion for extending ?as.factor
In-Reply-To: <20090504163403.GA10640@cs.cas.cz>
References: <20090503203204.GB29507@cs.cas.cz>	<18942.43500.862186.878365@lynne.math.ethz.ch>	<49FEEED1.8000808@biostat.ku.dk>	<18943.3144.768738.188706@lynne.math.ethz.ch>
	<20090504163403.GA10640@cs.cas.cz>
Message-ID: <49FF25A6.3070907@biostat.ku.dk>

Petr Savicky wrote:
> On Mon, May 04, 2009 at 05:39:52PM +0200, Martin Maechler wrote:
> [snip]
>> Let me quickly expand the tasks we have wanted to address, when
>> I started changing factor() for R-devel.
>>
>> 1) R-core had unanimously decided that R 2.10.0 should not allow
>>    duplicated levels in factors anymore.
>>
>> When working on that, I had realized that quite a few bits of code
>> were implicitly relying on duplicated levels (or something
>> related), see below, so the current version of R-devel only
>> *warns* in some cases where duplicated levels are produced
>> instead of giving an error.
>>
>> What I had also found was that basically, even our own (!) code
>> and quite a bit of user code has more or less relied on other
>> things that were not true (even though "almost always" fulfilled):
>>
>> 2) if x contains no duplicated values, then  factor(x) should neither
>>
>> 3) factor(x) constructs a factor object with *unique* levels
>>
>>   {This is what our decision "1)" implies and now enforces}
>>
>> 4) as.numeric(names(table(x))) should be  identical to unique(x)
>>
>>   where "4)" is basically ensured by "3)" as table() calls
>>   factor() for non-factor args.
>>
>> As mentioned the bad thing is that "2) - 4)" are typically
>> fulfilled in all tests package writers would use.
>>
>> Concerning '3)' [and '1)'], as you know, inside R-core we have
>> proposed to at least ensure that  `levels<-` 
>> should not allow duplicated levels, 
>> and I had concluded that
>> a) factor() really should use  `levels<-` instead of the low-level	
>>    attr(., "levels") <- ....
>> b) factor() itself must make sure that the default levels became unique.
>>
>> ---
>>
>> Given Petr's (and more) examples and the strong requirement of
>> "user convenience" and back-compatibility,
>> I now tend to agree (with Peter) that we cannot ensure all of 2)
>> and 4) still allow factor() to behave as it did for "rounded
>> decimal numbers",
>> and consequently would have to (continue to) not ensuring
>> properties (2) and (4).
>> Something quite unfortunate, since, as I said, much useR code
>> implicitly relies on these, and so that code is buggy even
>> though the bug will only show in exceptional cases.
> 
> Let me suggest to consider also the following algorithm: determine
> the number of digits needed to preserve the double value exactly for
> each number separately. An R code prototype demonstrating the 
> algorithm could be as follows
> 
>   convert <- function(x) # x should be a single number
>   {
>       for (d in 1:16) {
>           y <- sprintf(paste("%.", d, "g", sep=""), x)
>           if (x == as.numeric(y)) {
>               return(y)
>           }
>       }
>       return(sprintf("%.17g", x))
>   }
> 
> For this, we get
> 
>   > convert(0.3)
>   [1] "0.3"
>   > convert(1/3)
>   [1] "0.3333333333333333" # 16 digits suffice
>   > convert(0.12345)
>   [1] "0.12345"
>   > convert(0.12345678901234567)
>   [1] "0.12345678901234566"
>   > 0.12345678901234567 == as.numeric("0.12345678901234566")
>   [1] TRUE
> 
> This algorithm is slower than a single call to sprintf("%.17g", x), but it
> produces nicer numbers, if possible, and guarantees that the value is
> always preserved.

Yes, but....

> convert(0.2+0.1)
[1] "0.30000000000000004"


I think that the real issue is that we actually do want almost-equal
numbers to be folded together. The most relevant case I can conjure up
is this (permutation testing):

> zz <- replicate(20000,sum(sample(sleep$extra,10)))
> length(table(zz))
[1] 427
> length(table(signif(zz,7)))
[1] 281

Notice that the discrepancy comes from sums that really are identical
values (in decimal arithmetic), but where the binary FP inaccuracy makes
them slightly different.

[for a nice picture, continue the example with

> tt <- table(signif(zz,7))
> plot(as.numeric(names(tt)),tt, type="h")

]

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark      Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)              FAX: (+45) 35327907


From bates at stat.wisc.edu  Mon May  4 20:16:52 2009
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 4 May 2009 13:16:52 -0500
Subject: [Rd] nlminb - Port library codes
In-Reply-To: <49FB36E1.8090106@uottawa.ca>
References: <49FB36E1.8090106@uottawa.ca>
Message-ID: <40e66e0b0905041116j693839dag1edcf704ffef6f7f@mail.gmail.com>

You could always look in the SVN logs but I'll save you the trouble.
I did the initial installation of the nlminb function.

On Fri, May 1, 2009 at 12:52 PM, John C Nash <nashjc at uottawa.ca> wrote:
> Having looked at documentation and codes, I'm still looking to find out who
> did the installation of the Port libraries. As I work on optimization code
> improvements, there are often choices of settings (tolerances etc.), and I'd
> prefer to learn if there are particular reasons for choices before diving in
> and making any adjustments.
>
> It is also worth giving credit where it is due. Given the complexity of the
> Port code structure, adapting them to R must have been a lot of work.
>
> JN
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From lobry at biomserv.univ-lyon1.fr  Tue May  5 00:40:21 2009
From: lobry at biomserv.univ-lyon1.fr (Jean lobry)
Date: Tue, 5 May 2009 00:40:21 +0200
Subject: [Rd] whish stars.Rd
In-Reply-To: <mailman.23.1241431204.11500.r-devel@r-project.org>
References: <mailman.23.1241431204.11500.r-devel@r-project.org>
Message-ID: <p06002005c6251911d3ef@[134.214.233.216]>

Dear Rdev,

in R 2.9.0 the doc of function stars() does not state that it
returns invisibly the location of atomic graphs. This is a
valuable information as it may help to set a value for the key.loc
parameter of this function.

My whish is just that the "value" section in stars.Rd should be
documented.

Best,

Pr. Jean R. Lobry

BTW, the URL:,
http://www.udallas.edu:8080/~andrews/software/software.html.
in the "Note" section does not work for me.

-- 
Jean R. Lobry            (lobry at biomserv.univ-lyon1.fr)
Laboratoire BBE-CNRS-UMR-5558, Univ. C. Bernard - LYON I,
43 Bd 11/11/1918, F-69622 VILLEURBANNE CEDEX, FRANCE
allo  : +33 472 43 27 56     fax    : +33 472 43 13 88
http://pbil.univ-lyon1.fr/members/lobry/


From murdoch at stats.uwo.ca  Tue May  5 01:47:43 2009
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Mon, 04 May 2009 19:47:43 -0400
Subject: [Rd] whish stars.Rd
In-Reply-To: <p06002005c6251911d3ef@[134.214.233.216]>
References: <mailman.23.1241431204.11500.r-devel@r-project.org>
	<p06002005c6251911d3ef@[134.214.233.216]>
Message-ID: <49FF7E9F.4020106@stats.uwo.ca>

On 04/05/2009 6:40 PM, Jean lobry wrote:
> Dear Rdev,
> 
> in R 2.9.0 the doc of function stars() does not state that it
> returns invisibly the location of atomic graphs. This is a
> valuable information as it may help to set a value for the key.loc
> parameter of this function.
> 
> My whish is just that the "value" section in stars.Rd should be
> documented.
> 
> Best,
> 
> Pr. Jean R. Lobry
> 
> BTW, the URL:,
> http://www.udallas.edu:8080/~andrews/software/software.html.
> in the "Note" section does not work for me.
> 

That's a good suggestion.  The function doesn't always return the 
locations; I'll change it so it does, and document it.

I've written to David Andrews to ask for an update to his URL.

Duncan Murdoch


From savicky at cs.cas.cz  Tue May  5 09:48:20 2009
From: savicky at cs.cas.cz (Petr Savicky)
Date: Tue, 5 May 2009 09:48:20 +0200
Subject: [Rd] suggestion for extending ?as.factor
In-Reply-To: <49FF25A6.3070907@biostat.ku.dk>
References: <20090503203204.GB29507@cs.cas.cz>
	<18942.43500.862186.878365@lynne.math.ethz.ch>
	<49FEEED1.8000808@biostat.ku.dk>
	<18943.3144.768738.188706@lynne.math.ethz.ch>
	<20090504163403.GA10640@cs.cas.cz> <49FF25A6.3070907@biostat.ku.dk>
Message-ID: <20090505074820.GA24516@cs.cas.cz>

On Mon, May 04, 2009 at 07:28:06PM +0200, Peter Dalgaard wrote:
> Petr Savicky wrote:
> > For this, we get
> > 
> >   > convert(0.3)
> >   [1] "0.3"
> >   > convert(1/3)
> >   [1] "0.3333333333333333" # 16 digits suffice
> >   > convert(0.12345)
> >   [1] "0.12345"
> >   > convert(0.12345678901234567)
> >   [1] "0.12345678901234566"
> >   > 0.12345678901234567 == as.numeric("0.12345678901234566")
> >   [1] TRUE
> > 
> > This algorithm is slower than a single call to sprintf("%.17g", x), but it
> > produces nicer numbers, if possible, and guarantees that the value is
> > always preserved.
> 
> Yes, but....
> 
> > convert(0.2+0.1)
> [1] "0.30000000000000004"

I am not sure whether this should be considered an error. Computing with decimal
numbers requires some care. If we want to get the result, which is the closest
to 0.3, it is better to use round(0.1+0.2, digits=1).
 
> I think that the real issue is that we actually do want almost-equal
> numbers to be folded together.

Yes, this is frequently needed. A related question of an approximate match
in a numeric sequence was discussed in R-devel thread "Match .3 in a sequence"
from March. In order to fold almost-equal numbers together, we need to specify
a tolerance to use. The tolerance depends on application. In my opinion, it is
hard to choose a tolerance, which could be a good default.

> The most relevant case I can conjure up
> is this (permutation testing):
> 
> > zz <- replicate(20000,sum(sample(sleep$extra,10)))
> > length(table(zz))
> [1] 427
> > length(table(signif(zz,7)))
> [1] 281

In order to obtain the correct result in this example, it is possible to use
  zz <- signif(zz,7)
as you suggest or
  zz <- round(zz, digits=1)
and use the resulting zz for all further calculations.

> Notice that the discrepancy comes from sums that really are identical
> values (in decimal arithmetic), but where the binary FP inaccuracy makes
> them slightly different.
> 
> [for a nice picture, continue the example with
> 
> > tt <- table(signif(zz,7))
> > plot(as.numeric(names(tt)),tt, type="h")

The form of this picture is not due to rounding errors. The picture may be
obtained even within an integer arithmetic as follows.

  ss <- round(10*sleep$extra)
  zz <- replicate(20000,sum(sample(ss,10)))
  tt <- table(zz)
  plot(as.numeric(names(tt)),tt, type="h")

The variation of the frequencies is due to two effects.

First, each individual value of the sum occurs with low probability, so 20000
replications do not suffice to get low variance of individual frequencies. Using
1000 repetitions of the code above, i obtained estimate of some of the probabilities.
The most frequent sums have probability approximately p=0.0089 for a single sample.
With n=20000 replications, we get the mean frequency p*n = 178 and standard deviation
sqrt(p*(1-p)*n) = 13.28216.

The other cause of variation of the frequencies is that even the true distribution of
the sums has a lot of local minima and maxima. The mean of 1000 repetitions of the above
table restricted to values of the sum in the interval 140:168 produced the estimates

  value mean frequency (over 1000 tables)
  140   172.411
  141   172.090
  142   174.297
  143   166.039
  144   159.260
  145   163.891
  146   162.317
  147   165.460
  148   177.870
  149   177.971
  150   177.754
  151   178.525 local maximum
  152   169.851
  153   164.443 local minimum
  154   168.488 the mean value of the sum
  155   164.816 local minimum
  156   169.297
  157   179.248 local maximum
  158   177.799
  159   176.743
  160   177.777
  161   164.173
  162   162.585
  163   164.641
  164   159.913
  165   165.932
  166   173.014
  167   172.276
  168   171.612
The local minima and maxima are visible here. The mean value 154 is approximately
the center of the histogram.

Petr.


From maechler at stat.math.ethz.ch  Tue May  5 10:35:42 2009
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 5 May 2009 10:35:42 +0200
Subject: [Rd] suggestion for extending ?as.factor
In-Reply-To: <49FF25A6.3070907@biostat.ku.dk>
References: <20090503203204.GB29507@cs.cas.cz>
	<18942.43500.862186.878365@lynne.math.ethz.ch>
	<49FEEED1.8000808@biostat.ku.dk>
	<18943.3144.768738.188706@lynne.math.ethz.ch>
	<20090504163403.GA10640@cs.cas.cz> <49FF25A6.3070907@biostat.ku.dk>
Message-ID: <18943.64094.648164.476070@lynne.math.ethz.ch>

>>>>> "PD" == Peter Dalgaard <P.Dalgaard at biostat.ku.dk>
>>>>>     on Mon, 04 May 2009 19:28:06 +0200 writes:

    PD> Petr Savicky wrote:
    >> On Mon, May 04, 2009 at 05:39:52PM +0200, Martin Maechler wrote:
    >> [snip]
    >>> Let me quickly expand the tasks we have wanted to address, when
    >>> I started changing factor() for R-devel.
    >>> 
    >>> 1) R-core had unanimously decided that R 2.10.0 should not allow
    >>> duplicated levels in factors anymore.
    >>> 
    >>> When working on that, I had realized that quite a few bits of code
    >>> were implicitly relying on duplicated levels (or something
    >>> related), see below, so the current version of R-devel only
    >>> *warns* in some cases where duplicated levels are produced
    >>> instead of giving an error.
    >>> 
    >>> What I had also found was that basically, even our own (!) code
    >>> and quite a bit of user code has more or less relied on other
    >>> things that were not true (even though "almost always" fulfilled):
    >>> 
    >>> 2) if x contains no duplicated values, then  factor(x) should neither
    >>> 
    >>> 3) factor(x) constructs a factor object with *unique* levels
    >>> 
    >>> {This is what our decision "1)" implies and now enforces}
    >>> 
    >>> 4) as.numeric(names(table(x))) should be  identical to unique(x)
    >>> 
    >>> where "4)" is basically ensured by "3)" as table() calls
    >>> factor() for non-factor args.
    >>> 
    >>> As mentioned the bad thing is that "2) - 4)" are typically
    >>> fulfilled in all tests package writers would use.
    >>> 
    >>> Concerning '3)' [and '1)'], as you know, inside R-core we have
    >>> proposed to at least ensure that  `levels<-` 
    >>> should not allow duplicated levels, 
    >>> and I had concluded that
    >>> a) factor() really should use  `levels<-` instead of the low-level	
    >>> attr(., "levels") <- ....
    >>> b) factor() itself must make sure that the default levels became unique.
    >>> 
    >>> ---
    >>> 
    >>> Given Petr's (and more) examples and the strong requirement of
    >>> "user convenience" and back-compatibility,
    >>> I now tend to agree (with Peter) that we cannot ensure all of 2)
    >>> and 4) still allow factor() to behave as it did for "rounded
    >>> decimal numbers",
    >>> and consequently would have to (continue to) not ensuring
    >>> properties (2) and (4).
    >>> Something quite unfortunate, since, as I said, much useR code
    >>> implicitly relies on these, and so that code is buggy even
    >>> though the bug will only show in exceptional cases.
    >> 
    >> Let me suggest to consider also the following algorithm: determine
    >> the number of digits needed to preserve the double value exactly for
    >> each number separately. An R code prototype demonstrating the 
    >> algorithm could be as follows
    >> 
    >> convert <- function(x) # x should be a single number
    >> {
    >> for (d in 1:16) {
    >> y <- sprintf(paste("%.", d, "g", sep=""), x)
    >> if (x == as.numeric(y)) {
    >> return(y)
    >> }
    >> }
    >> return(sprintf("%.17g", x))
    >> }
    >> 
    >> For this, we get
    >> 
    >> > convert(0.3)
    >> [1] "0.3"
    >> > convert(1/3)
    >> [1] "0.3333333333333333" # 16 digits suffice
    >> > convert(0.12345)
    >> [1] "0.12345"
    >> > convert(0.12345678901234567)
    >> [1] "0.12345678901234566"
    >> > 0.12345678901234567 == as.numeric("0.12345678901234566")
    >> [1] TRUE
    >> 
    >> This algorithm is slower than a single call to sprintf("%.17g", x), but it
    >> produces nicer numbers, if possible, and guarantees that the value is
    >> always preserved.

    PD> Yes, but....

    >> convert(0.2+0.1)
    PD> [1] "0.30000000000000004"


    PD> I think that the real issue is that we actually do want almost-equal
    PD> numbers to be folded together. 

in most cases, but not all {*when*  levels is not specified},
but useR's code sometimes *does* rely on  factor()  /  table()
using exact values.

Also, what should happen when the user explicitly calls

      factor(x, levels = sort(unique(x)))

at least in that case we really should *not* fold almost equals.
and the "old" code (<= R 2.9.0) did fold them in border cases,
and lead non-unique levels.

Can we agree that any rounding etc - if needed - will only
happen when
  1) missing(levels)
  2) is.numeric(x) || is.complex(x)

I'm also thinking of at least keeping the current behavior as an
option, e.g. by  factor(x, ...., keepUniqueness = TRUE, ....)
where the default would be keepUniqueness = FALSE.

    PD> The most relevant case I can conjure up is this (permutation testing):

    >> zz <- replicate(20000,sum(sample(sleep$extra,10)))
    >> length(table(zz))
    PD> [1] 427
    >> length(table(signif(zz,7)))
    PD> [1] 281

    PD> Notice that the discrepancy comes from sums that really are identical
    PD> values (in decimal arithmetic), but where the binary FP inaccuracy makes
    PD> them slightly different.

Yes, that's a good example.

However, I now think it would be helpful to slightly separate
the issue from what factor() should do from 
how table() should call factor() in those cases it does.

Also, you originally said

 >> We might as well have abolished conversion of numerics to
 >> factor altogether.

and I now tend to think that there's something in that:
The conversion of non-integer numerics to factors could indeed
be something the user should be urged to with care,
but yes, I agree that a direct   factor(format(x), ...)  is too
cheap.


    PD> [for a nice picture, continue the example with

    >> tt <- table(signif(zz,7))
    >> plot(as.numeric(names(tt)),tt, type="h")

    PD> ]

    PD> -- 
    PD> O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
    PD> c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
    PD> (*) \(*) -- University of Copenhagen   Denmark      Ph:  (+45) 35327918
    PD> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)              FAX: (+45) 35327907


From murdoch at stats.uwo.ca  Tue May  5 11:24:18 2009
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue, 05 May 2009 05:24:18 -0400
Subject: [Rd] Rd parsing
In-Reply-To: <bf5b734c0905050204h33189d3dodf0bc6d4d7697145@mail.gmail.com>
References: <bf5b734c0905050204h33189d3dodf0bc6d4d7697145@mail.gmail.com>
Message-ID: <4A0005C2.6080909@stats.uwo.ca>

On 05/05/2009 5:04 AM, robin hankin wrote:
> Hi Duncan
> 
> I asked this question to R-devel, and there was no reply, so I thought
> I'd ask you
> directly.  Any ideas?
> 
> best wishes
> 
> Robin
> 
> 
> 
> 
> I am having difficulty including a LaTeX formula in an Rd
> file.
> 
> The example given in section 2.7 in 'Parsing Rd files' is:
> 
> 
>     \deqn{ f(x) = \left\{
>       \begin{array}{ll}
>       0 & x<0 \\
>       1 & x\ge 0
>       \end{array}
>       \right. }{non latex}
> 
> 
> For me, this gives:
> 
> \deqn{ f(x) = \left\{
> \begin{array}{ll}
> 0 \& x<0 \bsl{}
> 1 \& x\ge 0
> \end{array}
> \right. }{}
> 
> in the tex file, which is not  desired because the ampersand
> is escaped; the '&' symbol appears in the dvi file, and I
> want an ampersand  to indicate  alignment.
> 
> Also, the '\\' appears as \bsl{}, which is undesired; the
>  resulting dvi file (made by R CMD Rd2dvi) looks wrong.
> 
> How do I write the Rd file so as to produce non-escaped
> ampersands?

I think the way the docs show it should work but there's a bug in the 
conversion.  If you use the new converter tools::Rd2latex, it comes out 
as expected.  So there's a bug in the Perl version of Rdconv, presumably 
in share/perl/R/Rdconv.pm, and you might want to try to track it down 
and fix it if you know Perl well enough.  An alternative might be some 
kludge involving \input{}:  put the equation in its own file where 
Rdconv will ignore it.

I've cc'd R-devel on this again; maybe someone else can jump in with a 
better idea.

Duncan Murdoch


From P.Dalgaard at biostat.ku.dk  Tue May  5 11:27:36 2009
From: P.Dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Tue, 05 May 2009 11:27:36 +0200
Subject: [Rd] suggestion for extending ?as.factor
In-Reply-To: <20090505074820.GA24516@cs.cas.cz>
References: <20090503203204.GB29507@cs.cas.cz>	<18942.43500.862186.878365@lynne.math.ethz.ch>	<49FEEED1.8000808@biostat.ku.dk>	<18943.3144.768738.188706@lynne.math.ethz.ch>	<20090504163403.GA10640@cs.cas.cz>
	<49FF25A6.3070907@biostat.ku.dk> <20090505074820.GA24516@cs.cas.cz>
Message-ID: <4A000688.6060006@biostat.ku.dk>

Petr Savicky wrote:


> 
>> Notice that the discrepancy comes from sums that really are identical
>> values (in decimal arithmetic), but where the binary FP inaccuracy makes
>> them slightly different.
>>
>> [for a nice picture, continue the example with
>>
>>> tt <- table(signif(zz,7))
>>> plot(as.numeric(names(tt)),tt, type="h")
> 
> The form of this picture is not due to rounding errors. The picture may be
> obtained even within an integer arithmetic as follows.
> 
>   ss <- round(10*sleep$extra)
>   zz <- replicate(20000,sum(sample(ss,10)))
>   tt <- table(zz)
>   plot(as.numeric(names(tt)),tt, type="h")

I know. The point was rather that if you are not careful with rounding,
you get the some of the bars wrong (you get 2 or 3 small bars very close
to each other instead of one longer one). Computed p values from
permutation tests (as in mean(sim>=obs)) also need care for the same reason.

> 
> The variation of the frequencies is due to two effects.
> 
> First, each individual value of the sum occurs with low probability, so 20000
....

> 
> The other cause of variation of the frequencies is that even the true distribution of
> the sums has a lot of local minima and maxima. 

Yes. You can actually generate the exact distribution easily using

d <- combn(sleep$extra, 10, sum)
d <- signif(d,7)
tt <- table(d)
plot(as.numeric(names(tt)),tt, type="h")

and if you omit the signif() bit (not with R-devel):

> table(table(names(table(d))))

  1   2   3
137 161  17

i.e. 315 distinct values but over half occur in duplicate or triplicate
versions.


-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark      Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)              FAX: (+45) 35327907


From andy_liaw at merck.com  Tue May  5 15:39:42 2009
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue, 5 May 2009 09:39:42 -0400
Subject: [Rd] unexpected behavior of rpart 3.1-43, loss matrix
In-Reply-To: <49F9D526.5070302@gmx.de>
References: <49F9D526.5070302@gmx.de>
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFA07380C1B@usctmx1106.merck.com>

Just expressing MHO:  The  algorithm cannot give predictions in classes
that never appear in the training data, so any entries in the loss
matrix related to such classes are irrelevant w.r.t. the training data.
They should be removed before feeding to rpart (or any other algorithm
that can make use of a loss matrix).  As I see it, it's the
responsibility of the data analyst to take care of such things.  The
current error message may not make it obvious what the problem is, but
if I were the developer, I would not write the code to accept such
disparate input without issuing error.

Andy 

> -----Original Message-----
> From: r-devel-bounces at r-project.org 
> [mailto:r-devel-bounces at r-project.org] On Behalf Of Lars
> Sent: Thursday, April 30, 2009 12:43 PM
> To: r-devel at r-project.org
> Subject: [Rd] unexpected behavior of rpart 3.1-43, loss matrix
> 
> Hi,
> 
> I just noticed that rpart behaves unexpectecly, when performing
> classification learning and specifying a loss matrix.
> if the response variable y is a factor and if not all levels of the
> factor  occur in the observations, rpart exits with an error:
> 
> 
> > df=data.frame(attr=1:5,class=factor(c(2,3,1,5,3),levels=1:6))
> > rpart(class~attr,df,parms=list(loss=matrix(0,6,6)))
> Error in (get(paste("rpart", method, sep = ".")))(Y, offset, 
> parms, wt)
> :   Wrong length for loss matrix
> 
> 
> note that while the levels of the factor range from 1:6, for the
> concrete obseration data, only levels 1, 2, 3, 5 do occur.
> 
> the error is caused by the code of rpart.class:
> 
>  fy <- as.factor(y)
>  y <- as.integer(fy)
>  numclass <- max(y[!is.na(y)])
> ...
> 
> temp2 <- parms$loss
> if (length(temp2) != numclass^2)
>   stop("Wrong length for loss matrix")
> 
> 
> for the example, numclass is set to 5 instead of 6.
> 
> 
> while for that small example, it may be discussable whether or not
> numclass should be 6, consider a set of data for that the response
> variable has a certain range. Then, it may be the case that for some
> data, not all levels of the response variable do occur. at the same
> time, it is desirable to use the same loss matrix when training a
> deicision tree from the data.
> 
> 
> having said that, i am very happy with the rpart package and with its
> high configurability.
> 
> best regards
> lars
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
Notice:  This e-mail message, together with any attachme...{{dropped:12}}


From michal2992 at gmail.com  Tue May  5 18:43:07 2009
From: michal2992 at gmail.com (Michal Bojanowski)
Date: Tue, 5 May 2009 16:43:07 +0000 (UTC)
Subject: [Rd] script window background and text color (PR#13446)
References: <20090114183016.5FDC5282EFF8@mail.pubhealth.ku.dk>
Message-ID: <loom.20090505T163852-265@post.gmane.org>

<alexios <at> 4dscape.com> writes:
> Full_Name: alexios galanos
> Version: 2.8.1
> OS: windows/vista
> Submission from: (NULL) (81.100.160.71)
> 
> While the script editor now respects user preferences for the background color
> in 2.8.1, it does not do so for the user text color defaulting to black. So my
> preference of having for example black background with green text fails (it is
> all black) in the script editor (the console is ok).

I believe this is not a bug, at least not in R 2.9.0. I did not check it
in 2.8.1 to which you refer. Perhaps it is just the lack of
documentation: I could not find any documentation for the options below.

The colors in the Windows GUI console, pager, data editor and syntax
editor can be set under Windows both using the GUI and with appropriate
entries in Rprofile. 

In Rprofile you can use settings:

For the console:
background
normaltext
usertext

For pager:
pagerbg
pagertext
highlight

Data editor:
dataeditbg
dataedittext
dataedituser

Syntax editor:
editorbg
editortext

For example you can get black background and green text in the syntax
editor by adding the following to your Rprofile:

editorbg = black
editortext = green

I'm not sure whether all but the initial three were available in earlier
versions of R. Perhaps they were but they inherited the values from the
first three...

Perhaps this should be documented somwhere? In the Windows Rd file for
file.show, data.entry?

Best,
Michal

___________________________________________
Michal Bojanowski
Department of Sociology, Utrecht University
m.j.bojanowski at uu.nl
http://bojan.3e.pl/weblog


From savicky at cs.cas.cz  Tue May  5 20:43:33 2009
From: savicky at cs.cas.cz (Petr Savicky)
Date: Tue, 5 May 2009 20:43:33 +0200
Subject: [Rd] suggestion for extending ?as.factor
In-Reply-To: <4A000688.6060006@biostat.ku.dk>
References: <20090503203204.GB29507@cs.cas.cz>
	<18942.43500.862186.878365@lynne.math.ethz.ch>
	<49FEEED1.8000808@biostat.ku.dk>
	<18943.3144.768738.188706@lynne.math.ethz.ch>
	<20090504163403.GA10640@cs.cas.cz> <49FF25A6.3070907@biostat.ku.dk>
	<20090505074820.GA24516@cs.cas.cz> <4A000688.6060006@biostat.ku.dk>
Message-ID: <20090505184333.GA4402@cs.cas.cz>

On Tue, May 05, 2009 at 11:27:36AM +0200, Peter Dalgaard wrote:
> I know. The point was rather that if you are not careful with rounding,
> you get the some of the bars wrong (you get 2 or 3 small bars very close
> to each other instead of one longer one). Computed p values from
> permutation tests (as in mean(sim>=obs)) also need care for the same reason.

OK. Now, i understand the point of the example. I think that it is
the responsibility of the user to find the right way to eliminate the
influence of the rounding errors, since this may require a different
approach in different situations. However, i can also accept the
point of view that as.factor() should do this to some extent by default.

For example, we may require that as.factor() is consistent with 
as.character() in the way how to map different numbers to the same
string.

At the first glance, one could expect that to implement this, it is 
sufficient if as.factor(x) performs
  x <- as.numeric(as.character(x))
  levels <- as.character(sort(unique(x)))

Unfortunately, on some platforms (tested on Intel with SSE, R-2.10.0,
2009-05-02 r48453), this may produce repeated levels.

  x <- c(0.6807853176681814000304, 0.6807853176681809559412)
  x <- as.numeric(as.character(x))
  levels <- as.character(sort(unique(x)))
  levels # "0.68078531766818" "0.68078531766818"
  levels[1] == levels[2] # TRUE

Using the default Intel arithmetic, we get a single level, namely "0.680785317668181".

Petr.


From maechler at stat.math.ethz.ch  Wed May  6 10:41:58 2009
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 6 May 2009 10:41:58 +0200
Subject: [Rd] suggestion for extending ?as.factor
In-Reply-To: <18943.64094.648164.476070@lynne.math.ethz.ch>
References: <20090503203204.GB29507@cs.cas.cz>
	<18942.43500.862186.878365@lynne.math.ethz.ch>
	<49FEEED1.8000808@biostat.ku.dk>
	<18943.3144.768738.188706@lynne.math.ethz.ch>
	<20090504163403.GA10640@cs.cas.cz> <49FF25A6.3070907@biostat.ku.dk>
	<18943.64094.648164.476070@lynne.math.ethz.ch>
Message-ID: <18945.19798.782710.936788@lynne.math.ethz.ch>

>>>>> "MM" == Martin Maechler <maechler at stat.math.ethz.ch>
>>>>>     on Tue, 5 May 2009 10:35:42 +0200 writes:

>>>>> "PD" == Peter Dalgaard <P.Dalgaard at biostat.ku.dk>
>>>>>     on Mon, 04 May 2009 19:28:06 +0200 writes:

    PD> Petr Savicky wrote:
    >>> On Mon, May 04, 2009 at 05:39:52PM +0200, Martin Maechler wrote:
    >>> [snip]
    >>>> Let me quickly expand the tasks we have wanted to address, when
    >>>> I started changing factor() for R-devel.
    >>>> 
    >>>> 1) R-core had unanimously decided that R 2.10.0 should not allow
    >>>> duplicated levels in factors anymore.
    >>>> 
    >>>> When working on that, I had realized that quite a few bits of code
    >>>> were implicitly relying on duplicated levels (or something
    >>>> related), see below, so the current version of R-devel only
    >>>> *warns* in some cases where duplicated levels are produced
    >>>> instead of giving an error.
    >>>> 
    >>>> What I had also found was that basically, even our own (!) code
    >>>> and quite a bit of user code has more or less relied on other
    >>>> things that were not true (even though "almost always" fulfilled):
    >>>> 
    >>>> 2) if x contains no duplicated values, then  factor(x) should neither
    >>>> 
    >>>> 3) factor(x) constructs a factor object with *unique* levels
    >>>> 
    >>>> {This is what our decision "1)" implies and now enforces}
    >>>> 
    >>>> 4) as.numeric(names(table(x))) should be  identical to unique(x)
    >>>> 
    >>>> where "4)" is basically ensured by "3)" as table() calls
    >>>> factor() for non-factor args.
    >>>> 
    >>>> As mentioned the bad thing is that "2) - 4)" are typically
    >>>> fulfilled in all tests package writers would use.
    >>>> 
    >>>> Concerning '3)' [and '1)'], as you know, inside R-core we have
    >>>> proposed to at least ensure that  `levels<-` 
    >>>> should not allow duplicated levels, 
    >>>> and I had concluded that
    >>>> a) factor() really should use  `levels<-` instead of the low-level	
    >>>> attr(., "levels") <- ....
    >>>> b) factor() itself must make sure that the default levels became unique.
    >>>> 
    >>>> ---
    >>>> 
    >>>> Given Petr's (and more) examples and the strong requirement of
    >>>> "user convenience" and back-compatibility,
    >>>> I now tend to agree (with Peter) that we cannot ensure all of 2)
    >>>> and 4) still allow factor() to behave as it did for "rounded
    >>>> decimal numbers",
    >>>> and consequently would have to (continue to) not ensuring
    >>>> properties (2) and (4).
    >>>> Something quite unfortunate, since, as I said, much useR code
    >>>> implicitly relies on these, and so that code is buggy even
    >>>> though the bug will only show in exceptional cases.

[................................]    

     PD> I think that the real issue is that we actually do want almost-equal
     PD> numbers to be folded together. 

yes, this now (revision 48469) will happen by default, using  signif(x, 15) 
where '15' is the default for the new optional argument 'digitsLabels'
{better argument name? (but must nost start with 'label')}

Why '15': Because this is most back-compatible and sufficient to
    	  solve simple arithmetic (0.1 + 0.2) issues.

    MM> in most cases, but not all {*when*  levels is not specified},
    MM> but useR's code sometimes *does* rely on  factor()  /  table()
    MM> using exact values.

    MM> Also, what should happen when the user explicitly calls

    MM> factor(x, levels = sort(unique(x)))

    MM> at least in that case we really should *not* fold almost equals.
    MM> and the "old" code (<= R 2.9.0) did fold them in border cases,
    MM> and lead non-unique levels.

    MM> Can we agree that any rounding etc - if needed - will only
    MM> happen when
    MM> 1) missing(levels)
    MM> 2) is.numeric(x) || is.complex(x)

The code I've committed (revision 48469) now does that..

    MM> I'm also thinking of at least keeping the current behavior as an
    MM> option, e.g. by  factor(x, ...., keepUniqueness = TRUE, ....)
    MM> where the default would be keepUniqueness = FALSE.

current argument name is 'keepUnique'.

    PD> The most relevant case I can conjure up is this (permutation testing):

    >>> zz <- replicate(20000,sum(sample(sleep$extra,10)))
    >>> length(table(zz))
    PD> [1] 427
    >>> length(table(signif(zz,7)))
    PD> [1] 281

    PD> Notice that the discrepancy comes from sums that really are identical
    PD> values (in decimal arithmetic), but where the binary FP inaccuracy makes
    PD> them slightly different.

    MM> Yes, that's a good example.

    MM> However, I now think it would be helpful to slightly separate
    MM> the issue from what factor() should do from 
    MM> how table() should call factor() in those cases it does.

I still believe that.
Currently,  table()  calls    " factor(a, exclude = exclude) "
when 'a' is not a factor, e.g., when it is numeric.
I propose that  table() should also gain some of the new
optional factor() arguments, and maybe even using a different
default than 15

Note that the new R-devel now gives

> set.seed(7); zz <- replicate(20000,sum(sample(sleep$extra,10)))
> length(tz <- table(zz))
[1] 283

whereas R <= 2.9.0 gives
....
[1] 422

so that at least for this examples, '15' is good enough
i.e., '7' is not needed. As mentioned above, the advantage of
'15' is that it is much closer to previous R (and S+ !) behavior
than a smaller value.

Martin


From pulaskite at yahoo.com  Wed May  6 02:05:13 2009
From: pulaskite at yahoo.com (pulaskite at yahoo.com)
Date: Wed,  6 May 2009 02:05:13 +0200 (CEST)
Subject: [Rd] 2.9.0 configure failure on Solaris 10 U6 (PR#13689)
Message-ID: <20090506000513.731EF2832187@mail.pubhealth.ku.dk>

Full_Name: Reginald Beardsley
Version: 2.9.0
OS: Solaris 10 U6
Submission from: (NULL) (74.194.114.227)





The configure file in the 2.9.0 tarball I downloaded from CRAN today is munged.


Here's the relevant excerpt from the config.log file:


configure:38961: cc -xc99 -o conftest -O -xlibmieee  -I/app/include  -L/app/lib

conftest.c -lnsl -lsocket -ldl -lm  >&5
Undefined                       first referenced
 symbol                             in file
libiconv_close                      conftest.o
libiconv_open                       conftest.o
libiconv                            conftest.o
ld: fatal: Symbol referencing errors. No output written to conftest
configure:38967: $? = 1
configure: failed program was:

The Gnu libiconv library is installed in /app/lib, but w/o "-liconv" it will
never be linked.  Unfortunately the configure script is difficult to read making
it hard to fix by hand.  I'm using Studio 12.

Hints appreciated.

Thanks,
Reg


From charpent at bacbuc.dyndns.org  Wed May  6 15:25:13 2009
From: charpent at bacbuc.dyndns.org (charpent at bacbuc.dyndns.org)
Date: Wed,  6 May 2009 15:25:13 +0200 (CEST)
Subject: [Rd] Buglet in rml (VR) (PR#13690)
Message-ID: <20090506132514.08AF628320A8@mail.pubhealth.ku.dk>

Full_Name: Emmanuel Charpentier
Version: R version 2.9.0 (2009-04-17) - i486-pc-linux-gnu 
OS: Linux xxxxxx 2.6.28-11-generic #42-Ubuntu SMP Fri Apr 17 01:57:59 UTC 2009 i686 GNU/Linux
Submission from: (NULL) (164.2.255.244)


The "df.residual" component of an rlm object exists but carries NA. Curiously,
the "df" component of a summary.rlm object exists, and carries 3 values (the
manpage made me expect two : model and residual DFs).


As usual :
sessionInfo()
R version 2.9.0 (2009-04-17) 
i486-pc-linux-gnu 

locale:
LC_CTYPE=fr_FR.UTF-8;LC_NUMERIC=C;LC_TIME=fr_FR.UTF-8;LC_COLLATE=fr_FR.UTF-8;LC_MONETARY=C;LC_MESSAGES=fr_FR.UTF-8;LC_PAPER=fr_FR.UTF-8;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=fr_FR.UTF-8;LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices datasets  utils     methods   base     

other attached packages:
[1] mice_1.21          nnet_7.2-46        lme4_0.999375-28   Matrix_0.999375-26
[5] MASS_7.2-46        odfWeave_0.7.10    XML_2.3-0          lattice_0.17-22   

loaded via a namespace (and not attached):
[1] grid_2.9.0  tools_2.9.0

Self-contained reproductible example :
> set.seed(1066) # and all that..
> p1<-rlm(y~f1 * f2 + x
,data=within(data.frame(f1=as.factor(sample(c("a","b","c"),200,TRUE)),
f2=as.factor(c("x","y","z","t")[sample(1:4,20,TRUE)]),
x=runif(200,0,4)),{y=2*(f1=="b")-3*(f2=="y")+20*((f1=="b")&(f2=="y"))+rchisq(200,3)}))
> p1$df.residual
[1] NA # Ouch !
> summary(p1)$df
[1]  13 187  13 # Aiieeee !


From kyzyl at his.com  Wed May  6 18:18:12 2009
From: kyzyl at his.com (Terrence Ireland)
Date: Wed, 06 May 2009 12:18:12 -0400
Subject: [Rd] Scope question concerning calls within a user defined function
Message-ID: <4A01B844.2000400@his.com>

The following is a simple example with a poor solution that shows my
difficulties with scope.  The function /logit.test /has 3 arguments:  
/model.start,/
an initial model; /model.finish/, an all-inclusive model, /my.data/, a 
dataset, in
this case trivial. 

There are 2 function calls in l/ogit.test,/ first to /glm/ to get an 
initial fit (local variable
/logit/) using /model.start;/ then a call to /stepAIC/ using the initial 
fit.

I had thought that l/ogit/ would carry along the dataset, /test.data/ 
for use in
the call to /stepAIC/.  Instead it complains that it cannot find 
/my.data/.  It seems
to have found the name, not the value in the /call/ attribute. 

I fixed the problem by creating a global variable /my.data/ within the 
function,
naming it l/ogit.test.global,/ not a very good solution.

My question is:  How do I handle scope correctly?

Thanks,

Terry Ireland

Script of Experiment:

 > library(MASS)

 > test.data
  Approve Score OldScore
1     Yes     1       12
2     Yes     3       10
3     Yes     5        8
4      No     4        9
5      No     6        7
6      No     8        5
 > test.start
Approve ~ 1
 > test.finish
Approve ~ Score + OldScore
 > logit.test
function(model.start,model.finish,my.data)
  {
    logit <- glm(model.start,binomial(link = 
"logit"),my.data,control=glm.control(epsilon=0.0001),x=TRUE,y=TRUE);
    Table <- stepAIC(logit,scope=model.finish,direction="both",trace=1,k=2);
  }
 > logit.test.global
function(model.start,model.finish,my.data)
  {
    my.data <<- my.data
    logit <- glm(model.start,binomial(link = 
"logit"),my.data,control=glm.control(epsilon=0.0001),x=TRUE,y=TRUE);
    Table <- stepAIC(logit,scope=model.finish,direction="both",trace=1,k=2);
  }

 > logit.test(test.start,test.finish,test.data)
Start:  AIC=10.32
Approve ~ 1

Error in inherits(x, "data.frame") : object "my.data" not found
 > logit.test.global(test.start,test.finish,test.data)
Start:  AIC=10.32
Approve ~ 1

           Df Deviance     AIC
+ Score     1   4.8089  8.8089
+ OldScore  1   4.8089  8.8089
<none>          8.3178 10.3178

Step:  AIC=8.81
Approve ~ Score

        Df Deviance     AIC
<none>       4.8089  8.8089
- Score  1   8.3178 10.3178
 >


From murdoch at stats.uwo.ca  Wed May  6 18:47:33 2009
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Wed, 06 May 2009 12:47:33 -0400
Subject: [Rd] Scope question concerning calls within a user defined
	function
In-Reply-To: <4A01B844.2000400@his.com>
References: <4A01B844.2000400@his.com>
Message-ID: <4A01BF25.8060400@stats.uwo.ca>

On 5/6/2009 12:18 PM, Terrence Ireland wrote:
> The following is a simple example with a poor solution that shows my
> difficulties with scope.  The function /logit.test /has 3 arguments:  
> /model.start,/
> an initial model; /model.finish/, an all-inclusive model, /my.data/, a 
> dataset, in
> this case trivial. 
> 
> There are 2 function calls in l/ogit.test,/ first to /glm/ to get an 
> initial fit (local variable
> /logit/) using /model.start;/ then a call to /stepAIC/ using the initial 
> fit.
> 
> I had thought that l/ogit/ would carry along the dataset, /test.data/ 
> for use in
> the call to /stepAIC/.  Instead it complains that it cannot find 
> /my.data/.  It seems
> to have found the name, not the value in the /call/ attribute. 
> 
> I fixed the problem by creating a global variable /my.data/ within the 
> function,
> naming it l/ogit.test.global,/ not a very good solution.
> 
> My question is:  How do I handle scope correctly?

The general principle is this:

Variables in formulas are looked up in the data= argument of a modelling 
function; if that is missing (or the variable was not found), then in 
the environment where the formula was created.

I haven't traced through the code, but I believe stepAIC also uses the 
environment of the formula to find the dataset (i.e. it assumes the 
dataset and formula were created in the same place.

Since you didn't do that, you need some trickery.  You want my.data to 
be found in the environment of the formula.  my.data is local to your 
logit.test function, so changing logit.test to look like this:

logit.test <- function(model.start,model.finish,my.data)
   {
     environment(model.start) <- environment()
     environment(model.finish) <- environment()
     logit <- glm(model.start,binomial(link =
"logit"),my.data,control=glm.control(epsilon=0.0001),x=TRUE,y=TRUE)
     Table <- stepAIC(logit,scope=model.finish,direction="both",trace=1,k=2)
   }

should work.  The only potential problem is if your formulas have 
variables named model.start, model.finish, my.data, logit, or Table: 
those will be found before global variables of the same name.

I would avoid <<- in logit.test.global, and use the same technique there.

Duncan Murdoch

> 
> Thanks,
> 
> Terry Ireland
> 
> Script of Experiment:
> 
>  > library(MASS)
> 
>  > test.data
>   Approve Score OldScore
> 1     Yes     1       12
> 2     Yes     3       10
> 3     Yes     5        8
> 4      No     4        9
> 5      No     6        7
> 6      No     8        5
>  > test.start
> Approve ~ 1
>  > test.finish
> Approve ~ Score + OldScore
>  > logit.test
> function(model.start,model.finish,my.data)
>   {
>     logit <- glm(model.start,binomial(link = 
> "logit"),my.data,control=glm.control(epsilon=0.0001),x=TRUE,y=TRUE);
>     Table <- stepAIC(logit,scope=model.finish,direction="both",trace=1,k=2);
>   }
>  > logit.test.global
> function(model.start,model.finish,my.data)
>   {
>     my.data <<- my.data
>     logit <- glm(model.start,binomial(link = 
> "logit"),my.data,control=glm.control(epsilon=0.0001),x=TRUE,y=TRUE);
>     Table <- stepAIC(logit,scope=model.finish,direction="both",trace=1,k=2);
>   }
> 
>  > logit.test(test.start,test.finish,test.data)

In this call, test.start gets assigned to model.start in the function, 
test.finish to model.finish, and test.data to my.data.  Within 
logit.test, the glm() call looks fine, because you pass my.data to it.  But

> Start:  AIC=10.32
> Approve ~ 1
> 
> Error in inherits(x, "data.frame") : object "my.data" not found
>  > logit.test.global(test.start,test.finish,test.data)
> Start:  AIC=10.32
> Approve ~ 1
> 
>            Df Deviance     AIC
> + Score     1   4.8089  8.8089
> + OldScore  1   4.8089  8.8089
> <none>          8.3178 10.3178
> 
> Step:  AIC=8.81
> Approve ~ Score
> 
>         Df Deviance     AIC
> <none>       4.8089  8.8089
> - Score  1   8.3178 10.3178
>  >
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From chessxm at gmail.com  Thu May  7 01:45:40 2009
From: chessxm at gmail.com (Chessxm)
Date: Wed, 6 May 2009 19:45:40 -0400
Subject: [Rd] Can we generate exe file using R? What is the maximum file
	size valid?
Message-ID: <9dddb5a60905061645u764d319dhbb5d3e5489e8aa8d@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090506/2fe327af/attachment.pl>

From savicky at cs.cas.cz  Thu May  7 09:20:26 2009
From: savicky at cs.cas.cz (Petr Savicky)
Date: Thu, 7 May 2009 09:20:26 +0200
Subject: [Rd] suggestion for extending ?as.factor
In-Reply-To: <18945.19798.782710.936788@lynne.math.ethz.ch>
References: <20090503203204.GB29507@cs.cas.cz>
	<18942.43500.862186.878365@lynne.math.ethz.ch>
	<49FEEED1.8000808@biostat.ku.dk>
	<18943.3144.768738.188706@lynne.math.ethz.ch>
	<20090504163403.GA10640@cs.cas.cz> <49FF25A6.3070907@biostat.ku.dk>
	<18943.64094.648164.476070@lynne.math.ethz.ch>
	<18945.19798.782710.936788@lynne.math.ethz.ch>
Message-ID: <20090507072026.GA20492@cs.cas.cz>

On Wed, May 06, 2009 at 10:41:58AM +0200, Martin Maechler wrote:
>      PD> I think that the real issue is that we actually do want almost-equal
>      PD> numbers to be folded together. 
> 
> yes, this now (revision 48469) will happen by default, using  signif(x, 15) 
> where '15' is the default for the new optional argument 'digitsLabels'

On some platforms, the function factor() in the current R 2.10.0
(2009-05-06 r48478) may produce duplicated levels. The examples are
in general platform dependent. The following one produces duplicated
(in fact triplicated) levels on both Intel default arithmetic and
on Intel with SSE.

  x <- 9.7738826945424 + c(-1, 0, 1) * 1e-14
  x <- signif(x, 15)
  factor(x)
  # [1] 9.7738826945424 9.7738826945424 9.7738826945424
  # Levels: 9.7738826945424 9.7738826945424 9.7738826945424
  # Warning message:
  # In `levels<-`(`*tmp*`, value = c("9.7738826945424", "9.7738826945424",  :
  #   duplicated levels will not be allowed in factors anymore

The reason is that the three numbers remain different in signif(x, 15),
but are mapped to the same string in as.character(x).

  length(unique(x)) # [1] 3
  length(unique(as.character(x))) # 1

Further examples may be found using

  x <- as.character(9 + runif(5000))
  x <- as.numeric(x[nchar(x)==15]) # select numbers with 14 digits
  x <- signif(cbind(x - 1e-14, x, x + 1e-14), 15)
  y <- array(as.character(x), dim=dim(x))
  x <- x[which(y[,1] == y[,3]),]
  factor(x[1,])

Petr.


From ligges at statistik.tu-dortmund.de  Thu May  7 13:23:27 2009
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Thu, 07 May 2009 13:23:27 +0200
Subject: [Rd] Can we generate exe file using R? What is the maximum file
 size valid?
In-Reply-To: <9dddb5a60905061645u764d319dhbb5d3e5489e8aa8d@mail.gmail.com>
References: <9dddb5a60905061645u764d319dhbb5d3e5489e8aa8d@mail.gmail.com>
Message-ID: <4A02C4AF.3090203@statistik.tu-dortmund.de>



Chessxm wrote:
> Dear all,
> 
> I have two questions.
> 
> First, I am wondering whether we are able to use R to generate an exe file,
> or sth that can be executable outside R?

No, there is no compiler for R.


> Second, I am wondering whether read.csv can read a csv file with size of
> 300-400 gigabytes?


No. You won't find many machines around that support more than 400 Gb 
for a single process.

Uwe Ligges







> 
> Thank you very much!
> 
> Min
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From macrakis at alum.mit.edu  Thu May  7 15:26:43 2009
From: macrakis at alum.mit.edu (Stavros Macrakis)
Date: Thu, 7 May 2009 09:26:43 -0400
Subject: [Rd] Can we generate exe file using R? What is the maximum file
	size valid?
In-Reply-To: <9dddb5a60905061645u764d319dhbb5d3e5489e8aa8d@mail.gmail.com>
References: <9dddb5a60905061645u764d319dhbb5d3e5489e8aa8d@mail.gmail.com>
Message-ID: <8b356f880905070626o3412777n5c10d0bee75fc27f@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090507/44c1c948/attachment.pl>

From andy_liaw at merck.com  Thu May  7 16:05:27 2009
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 7 May 2009 10:05:27 -0400
Subject: [Rd] proposed changes to RSiteSearch
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFA07381973@usctmx1106.merck.com>

Can someone in R Core please take a look at the attached patches to
RSiteSearch() and its help page?  I guess Jon is planning some changes
on his site.  Jon:  could you elaborate on what the patch does?

Best,
Andy


Notice:  This e-mail message, together with any attachments, contains
information of Merck & Co., Inc. (One Merck Drive, Whitehouse Station,
New Jersey, USA 08889), and/or its affiliates (which may be known
outside the United States as Merck Frosst, Merck Sharp & Dohme or
MSD and in Japan, as Banyu - direct contact information for affiliates is
available at http://www.merck.com/contact/contacts.html) that may be
confidential, proprietary copyrighted and/or legally privileged. It is
intended solely for the use of the individual or entity named on this
message. If you are not the intended recipient, and have received this
message in error, please notify us immediately by reply e-mail and
then delete it from your system.

From andy_liaw at merck.com  Thu May  7 16:53:02 2009
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 7 May 2009 10:53:02 -0400
Subject: [Rd] proposed changes to RSiteSearch
In-Reply-To: <39B6DDB9048D0F4DAD42CB26AAFF0AFA07381973@usctmx1106.merck.com>
References: <39B6DDB9048D0F4DAD42CB26AAFF0AFA07381973@usctmx1106.merck.com>
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFA073819EC@usctmx1106.merck.com>

From: Liaw, Andy
> 
> Can someone in R Core please take a look at the attached patches to
> RSiteSearch() and its help page?  I guess Jon is planning some changes
> on his site. 

Apparently the attachments were stripped off the first time.  Here's a
second try.  

I've already set "format" to "plain text" in Outlook, even in that first
post.  If this still doesn't work, can some one explain to me what I
have to do in Outlook to get the attachment through?

Best,
Andy
Notice:  This e-mail message, together with any attachments, contains
information of Merck & Co., Inc. (One Merck Drive, Whitehouse Station,
New Jersey, USA 08889), and/or its affiliates (which may be known
outside the United States as Merck Frosst, Merck Sharp & Dohme or
MSD and in Japan, as Banyu - direct contact information for affiliates is
available at http://www.merck.com/contact/contacts.html) that may be
confidential, proprietary copyrighted and/or legally privileged. It is
intended solely for the use of the individual or entity named on this
message. If you are not the intended recipient, and have received this
message in error, please notify us immediately by reply e-mail and
then delete it from your system.

From baron at psych.upenn.edu  Thu May  7 16:18:12 2009
From: baron at psych.upenn.edu (Jonathan Baron)
Date: Thu, 7 May 2009 10:18:12 -0400
Subject: [Rd] proposed changes to RSiteSearch
In-Reply-To: <39B6DDB9048D0F4DAD42CB26AAFF0AFA07381973@usctmx1106.merck.com>
References: <39B6DDB9048D0F4DAD42CB26AAFF0AFA07381973@usctmx1106.merck.com>
Message-ID: <20090507141812.GB25422@psych.upenn.edu>

On 05/07/09 10:05, Liaw, Andy wrote:
> Can someone in R Core please take a look at the attached patches to
> RSiteSearch() and its help page?  I guess Jon is planning some changes
> on his site.  Jon:  could you elaborate on what the patch does?

The idea is simply to remove the mail archives, so the search will be
only of functions' help pages.  Eventually I will also add package
vignettes, but I don't think we need anything special for that.  I
can't imagine that someone would want to search just vignettes and not
help pages, or the reverse.

The reasons are: 1. The mail archives are becoming increasingly
difficult and time consuming for me to maintain.  2. There are now
three other ways of searching mail archives, all of which seem much
better than mine, but there seem to be no other good ways to search
help pages for functions, and, indeed, the new RSiteSearch packages
does only functions.  3. With only functions it would be much easier
for someone to set up a complete mirror of my site, which seems like a
good idea.

Jon
-- 
Jonathan Baron, Professor of Psychology, University of Pennsylvania
Home page: http://www.sas.upenn.edu/~baron
Editor: Judgment and Decision Making (http://journal.sjdm.org)


From sharpsteen at mac.com  Thu May  7 06:38:58 2009
From: sharpsteen at mac.com (cls59)
Date: Wed, 6 May 2009 21:38:58 -0700 (PDT)
Subject: [Rd] Can we generate exe file using R? What is the maximum file
 size valid?
In-Reply-To: <9dddb5a60905061645u764d319dhbb5d3e5489e8aa8d@mail.gmail.com>
References: <9dddb5a60905061645u764d319dhbb5d3e5489e8aa8d@mail.gmail.com>
Message-ID: <23420090.post@talk.nabble.com>



Chessxm wrote:
> 
> Dear all,
> 
> I have two questions.
> 
> First, I am wondering whether we are able to use R to generate an exe
> file,
> or sth that can be executable outside R?
> 
> 
> 

It sounds as though you are looking for something similar to Matlab's mcc
compiler that allows Matlab code to be compiled and run independently from
the program by translating a script into C code.

To my knowledge there are only two projects that have attempted something
similar and both never progressed much past the experimental phase. The
first was called Scompile and was created by a fellow named Matt Calder. The
project has been defunct for a long time, but you might find some info at:

http://www.stat.cmu.edu/~hseltman/Scompile.html

Another recent project is r2c hosted at http://www.rforge.net . Both of
these programs are extremely limited in the types of scripts they can
convert and are probably wouldn't provide workable solution for a set of
general R scripts.

Your best shot at portability is probably to pack your code and/or data up
into an R package- that way it can be easily loaded on to any computer which
has R installed. Creating a package from an existing collection of R scripts
and data objects is very, very easy- see ?package.skeleton() and the
"Writing R Extensions" manual for starting points.



Chessxm wrote:
> 
> Second, I am wondering whether read.csv can read a csv file with size of
> 300-400 gigabytes?
> 
> Thank you very much!
> 
> Min
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 

The problem here is that R likes to store all of it's variables in local
RAM- allocating a data frame for 300+ gigabytes worth of information is
likely to exceed your machine capacity. Many good workarounds exist for
this- most of them function by storing the variable in a database file and
only loading and accessing the parts that are needed at a given moment.

See the package "filehash" for an example of how to do this.

Hope this helps!

-Charlie


-----
Charlie Sharpsteen
Undergraduate
Environmental Resources Engineering
Humboldt State University
-- 
View this message in context: http://www.nabble.com/Can-we-generate-exe-file-using-R--What-is-the-maximum-file-size-valid--tp23417745p23420090.html
Sent from the R devel mailing list archive at Nabble.com.


From dsimcha at yahoo.com  Thu May  7 15:35:14 2009
From: dsimcha at yahoo.com (dsimcha at yahoo.com)
Date: Thu,  7 May 2009 15:35:14 +0200 (CEST)
Subject: [Rd] Kendall's Tau should use Continuity Correction (PR#13691)
Message-ID: <20090507133514.4F50528320BE@mail.pubhealth.ku.dk>

Full_Name: David Simcha
Version: 2.9.0
OS: WinXP
Submission from: (NULL) (96.234.244.142)


> cor.test(c(1,2,3,4,5), c(8,6,7,5,3), method = "kendall")

        Kendall's rank correlation tau

data:  c(1, 2, 3, 4, 5) and c(8, 6, 7, 5, 3) 
T = 1, p-value = 0.08333
alternative hypothesis: true tau is not equal to 0 
sample estimates:
 tau 
-0.8 

> cor.test(c(1,2,3,4,5), c(8,6,7,5,3), method = "kendall", exact = FALSE)

        Kendall's rank correlation tau

data:  c(1, 2, 3, 4, 5) and c(8, 6, 7, 5, 3) 
z = -1.9596, p-value = 0.05004
alternative hypothesis: true tau is not equal to 0 
sample estimates:
 tau 
-0.8 

It appears that R's implementation of Kendall's Tau does not use any type of
continuity correction, producing very bad results when exact P-values are not
used.


From andy_liaw at merck.com  Thu May  7 18:44:20 2009
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 7 May 2009 12:44:20 -0400
Subject: [Rd] proposed changes to RSiteSearch
References: <39B6DDB9048D0F4DAD42CB26AAFF0AFA07381973@usctmx1106.merck.com> 
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFA073C4663@usctmx1106.merck.com>

From: Liaw, Andy 
> 
> From: Liaw, Andy
> > 
> > Can someone in R Core please take a look at the attached patches to
> > RSiteSearch() and its help page?  I guess Jon is planning 
> some changes
> > on his site. 
> 
> Apparently the attachments were stripped off the first time.  
> Here's a second try.  
> 
> I've already set "format" to "plain text" in Outlook, even in 
> that first post.  If this still doesn't work, can some one 
> explain to me what I have to do in Outlook to get the 
> attachment through?

OK, as suggested by Bill Dunlap and Spencer Graves, I've renamed .diff
to .diff.txt.  Hopefully the third time is charm...

Apologies for the wasted bandwidth.
Notice:  This e-mail message, together with any attachments, contains
information of Merck & Co., Inc. (One Merck Drive, Whitehouse Station,
New Jersey, USA 08889), and/or its affiliates (which may be known
outside the United States as Merck Frosst, Merck Sharp & Dohme or
MSD and in Japan, as Banyu - direct contact information for affiliates is
available at http://www.merck.com/contact/contacts.html) that may be
confidential, proprietary copyrighted and/or legally privileged. It is
intended solely for the use of the individual or entity named on this
message. If you are not the intended recipient, and have received this
message in error, please notify us immediately by reply e-mail and
then delete it from your system.
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: RSiteSearch.Rd.diff.txt
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090507/b2ba2a31/attachment.txt>
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: RSiteSearch.R.diff.txt
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090507/b2ba2a31/attachment-0001.txt>

From murdoch at stats.uwo.ca  Thu May  7 19:28:02 2009
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 07 May 2009 13:28:02 -0400
Subject: [Rd] proposed changes to RSiteSearch
In-Reply-To: <20090507141812.GB25422@psych.upenn.edu>
References: <39B6DDB9048D0F4DAD42CB26AAFF0AFA07381973@usctmx1106.merck.com>
	<20090507141812.GB25422@psych.upenn.edu>
Message-ID: <4A031A22.7080702@stats.uwo.ca>

On 5/7/2009 10:18 AM, Jonathan Baron wrote:
> On 05/07/09 10:05, Liaw, Andy wrote:
>> Can someone in R Core please take a look at the attached patches to
>> RSiteSearch() and its help page?  I guess Jon is planning some changes
>> on his site.  Jon:  could you elaborate on what the patch does?
> 
> The idea is simply to remove the mail archives, so the search will be
> only of functions' help pages.  Eventually I will also add package
> vignettes, but I don't think we need anything special for that.  I
> can't imagine that someone would want to search just vignettes and not
> help pages, or the reverse.
> 
> The reasons are: 1. The mail archives are becoming increasingly
> difficult and time consuming for me to maintain.  2. There are now
> three other ways of searching mail archives, all of which seem much
> better than mine, but there seem to be no other good ways to search
> help pages for functions, and, indeed, the new RSiteSearch packages
> does only functions.  3. With only functions it would be much easier
> for someone to set up a complete mirror of my site, which seems like a
> good idea.

I'll incorporate the changes if you like.  What do you think of the idea 
of adding a gmane (or other archive) search to your results page?  Then 
if someone doesn't like what the man pages show, you can send them 
somewhere else, rather than leaving them to find out the other resources 
themselves.

gmane has sample code for this on their search page search.gmane.org, so 
it looks reasonably easy.  I'd suggest following their last example, 
with a drop-down box to select mailing lists, with comp.lang.r.* as an 
option for "all lists".

Duncan Murdoch


From andy_liaw at merck.com  Thu May  7 19:48:06 2009
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 7 May 2009 13:48:06 -0400
Subject: [Rd] proposed changes to RSiteSearch
In-Reply-To: <4A031A22.7080702@stats.uwo.ca>
References: <39B6DDB9048D0F4DAD42CB26AAFF0AFA07381973@usctmx1106.merck.com>
	<20090507141812.GB25422@psych.upenn.edu>
	<4A031A22.7080702@stats.uwo.ca>
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFA073C46FD@usctmx1106.merck.com>

From: Duncan Murdoch 
> 
> On 5/7/2009 10:18 AM, Jonathan Baron wrote:
> > On 05/07/09 10:05, Liaw, Andy wrote:
> >> Can someone in R Core please take a look at the attached patches to
> >> RSiteSearch() and its help page?  I guess Jon is planning 
> some changes
> >> on his site.  Jon:  could you elaborate on what the patch does?
> > 
> > The idea is simply to remove the mail archives, so the 
> search will be
> > only of functions' help pages.  Eventually I will also add package
> > vignettes, but I don't think we need anything special for that.  I
> > can't imagine that someone would want to search just 
> vignettes and not
> > help pages, or the reverse.
> > 
> > The reasons are: 1. The mail archives are becoming increasingly
> > difficult and time consuming for me to maintain.  2. There are now
> > three other ways of searching mail archives, all of which seem much
> > better than mine, but there seem to be no other good ways to search
> > help pages for functions, and, indeed, the new RSiteSearch packages
> > does only functions.  3. With only functions it would be much easier
> > for someone to set up a complete mirror of my site, which 
> seems like a
> > good idea.
> 
> I'll incorporate the changes if you like.  What do you think 
> of the idea 
> of adding a gmane (or other archive) search to your results 
> page?  Then 
> if someone doesn't like what the man pages show, you can send them 
> somewhere else, rather than leaving them to find out the 
> other resources 
> themselves.
> 
> gmane has sample code for this on their search page 
> search.gmane.org, so 
> it looks reasonably easy.  I'd suggest following their last example, 
> with a drop-down box to select mailing lists, with 
> comp.lang.r.* as an 
> option for "all lists".
> 
> Duncan Murdoch

Actually, I was thinking about a possible RHelpSearch() in addition, if
Jon is no longer going to include the R-help archive in the search.  I
used the current RSiteSearch() a lot more for searching R-help archive
than functions in packages.  Ideas?  comments?

Andy 
Notice:  This e-mail message, together with any attachme...{{dropped:12}}


From romain.francois at dbmail.com  Thu May  7 19:59:14 2009
From: romain.francois at dbmail.com (Romain Francois)
Date: Thu, 07 May 2009 19:59:14 +0200
Subject: [Rd] proposed changes to RSiteSearch
In-Reply-To: <39B6DDB9048D0F4DAD42CB26AAFF0AFA073C46FD@usctmx1106.merck.com>
References: <39B6DDB9048D0F4DAD42CB26AAFF0AFA07381973@usctmx1106.merck.com>	<20090507141812.GB25422@psych.upenn.edu>	<4A031A22.7080702@stats.uwo.ca>
	<39B6DDB9048D0F4DAD42CB26AAFF0AFA073C46FD@usctmx1106.merck.com>
Message-ID: <4A032172.3020008@dbmail.com>

About this:

gmaneSearch <- function( string,
    group = "gmane.comp.lang.r.*", author = "", sort = c("relevance", 
"date", "revdate"),
    op = c("and", "or") ){
   
    sort <- match.arg(sort)
    op <- match.arg( op )
   
    url <- sprintf(
        
'http://search.gmane.org/?query=%s&author=%s&group=%s&sort=%s&DEFAULTOP=%s', 

            gsub( ' +', '+', string),  author,  group,  sort, op )
    url <- URLencode( url )
    browseURL( url )
}


Liaw, Andy wrote:
> From: Duncan Murdoch 
>   
>> On 5/7/2009 10:18 AM, Jonathan Baron wrote:
>>     
>>> On 05/07/09 10:05, Liaw, Andy wrote:
>>>       
>>>> Can someone in R Core please take a look at the attached patches to
>>>> RSiteSearch() and its help page?  I guess Jon is planning 
>>>>         
>> some changes
>>     
>>>> on his site.  Jon:  could you elaborate on what the patch does?
>>>>         
>>> The idea is simply to remove the mail archives, so the 
>>>       
>> search will be
>>     
>>> only of functions' help pages.  Eventually I will also add package
>>> vignettes, but I don't think we need anything special for that.  I
>>> can't imagine that someone would want to search just 
>>>       
>> vignettes and not
>>     
>>> help pages, or the reverse.
>>>
>>> The reasons are: 1. The mail archives are becoming increasingly
>>> difficult and time consuming for me to maintain.  2. There are now
>>> three other ways of searching mail archives, all of which seem much
>>> better than mine, but there seem to be no other good ways to search
>>> help pages for functions, and, indeed, the new RSiteSearch packages
>>> does only functions.  3. With only functions it would be much easier
>>> for someone to set up a complete mirror of my site, which 
>>>       
>> seems like a
>>     
>>> good idea.
>>>       
>> I'll incorporate the changes if you like.  What do you think 
>> of the idea 
>> of adding a gmane (or other archive) search to your results 
>> page?  Then 
>> if someone doesn't like what the man pages show, you can send them 
>> somewhere else, rather than leaving them to find out the 
>> other resources 
>> themselves.
>>
>> gmane has sample code for this on their search page 
>> search.gmane.org, so 
>> it looks reasonably easy.  I'd suggest following their last example, 
>> with a drop-down box to select mailing lists, with 
>> comp.lang.r.* as an 
>> option for "all lists".
>>
>> Duncan Murdoch
>>     
>
> Actually, I was thinking about a possible RHelpSearch() in addition, if
> Jon is no longer going to include the R-help archive in the search.  I
> used the current RSiteSearch() a lot more for searching R-help archive
> than functions in packages.  Ideas?  comments?
>
> Andy 
> Notice:  This e-mail message, together with any attachme...{{dropped:12}}
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>
>   


-- 
Romain Francois
Independent R Consultant
+33(0) 6 28 91 30 30
http://romainfrancois.blog.free.fr


From andy_liaw at merck.com  Thu May  7 20:16:52 2009
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 7 May 2009 14:16:52 -0400
Subject: [Rd] proposed changes to RSiteSearch
In-Reply-To: <20090507180930.GA1619@psych.upenn.edu>
References: <39B6DDB9048D0F4DAD42CB26AAFF0AFA07381973@usctmx1106.merck.com>
	<20090507141812.GB25422@psych.upenn.edu>
	<4A031A22.7080702@stats.uwo.ca>
	<39B6DDB9048D0F4DAD42CB26AAFF0AFA073C46FD@usctmx1106.merck.com>
	<20090507180930.GA1619@psych.upenn.edu>
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFA073C4758@usctmx1106.merck.com>

From: Jonathan Baron
> 
> On 05/07/09 13:48, Liaw, Andy wrote:
> > From: Duncan Murdoch 
> > > I'll incorporate the changes if you like.
> 
> Yes.  Please do.  I understand that it won't take effect for a while.
> When it does, I'll change my site.
> 
>   What do you think 
> > > of the idea 
> > > of adding a gmane (or other archive) search to your results 
> > > page?  Then 
> > > if someone doesn't like what the man pages show, you can 
> send them 
> > > somewhere else, rather than leaving them to find out the 
> > > other resources 
> > > themselves.
> > > 
> > > gmane has sample code for this on their search page 
> > > search.gmane.org, so 
> > > it looks reasonably easy.  I'd suggest following their 
> last example, 
> > > with a drop-down box to select mailing lists, with 
> > > comp.lang.r.* as an 
> > > option for "all lists".
> > > 
> > > Duncan Murdoch
> 
> Good idea.  I will do this.  But there are also two other good search
> engines.  Maybe I'll add all three search alternatives.  But then,
> according to Sheena Iyengar, people won't choose any!  Hmm.
> 
> > Actually, I was thinking about a possible RHelpSearch() in 
> addition, if
> > Jon is no longer going to include the R-help archive in the 
> search.  I
> > used the current RSiteSearch() a lot more for searching 
> R-help archive
> > than functions in packages.  Ideas?  comments?
> 
> This is OK with me, but I don't want to do it.  I guess it would
> search gmane.  MarkMail is also pretty good, as is
> http://tolstoy.newcastle.edu.au/R/ All these are much better than
> Namazu for searching the R-help list.

Sorry I didn't make it clear:  I meant something like the gmaneSearcg()
that Romain posted, not hitting your site.

Best,
Andy
 
> Jon
Notice:  This e-mail message, together with any attachme...{{dropped:12}}


From romain.francois at dbmail.com  Thu May  7 20:54:39 2009
From: romain.francois at dbmail.com (Romain Francois)
Date: Thu, 07 May 2009 20:54:39 +0200
Subject: [Rd] proposed changes to RSiteSearch
In-Reply-To: <39B6DDB9048D0F4DAD42CB26AAFF0AFA073C4758@usctmx1106.merck.com>
References: <39B6DDB9048D0F4DAD42CB26AAFF0AFA07381973@usctmx1106.merck.com>	<20090507141812.GB25422@psych.upenn.edu>	<4A031A22.7080702@stats.uwo.ca>	<39B6DDB9048D0F4DAD42CB26AAFF0AFA073C46FD@usctmx1106.merck.com>	<20090507180930.GA1619@psych.upenn.edu>
	<39B6DDB9048D0F4DAD42CB26AAFF0AFA073C4758@usctmx1106.merck.com>
Message-ID: <4A032E6F.8010001@dbmail.com>

We could have a few functions similar to RSiteSearch or gmaneSearch I 
just posted and then cook a summary html page with R ...

Here is a function that grabs relevant groups from gmane:

gmaneGroups <- function( prefix = "gmane.comp.lang.r." ){
    url <- URLencode( sprintf( 
"http://dir.gmane.org/index.php?prefix=%s", prefix) )
    txt <- grep( '^<tr.*<td align=right.*<a', readLines( url ), value = 
TRUE )
   
    rx <- '^.*?<a href="(.*?)">(.*?)</a>.*<td>(.*?)</td>.*$'
    out <- data.frame(
        url = gsub( rx, "\\1", txt ),
        group = gsub( rx, "\\2", txt ),
        description = gsub( rx, "\\3", txt ),
        stringsAsFactors = FALSE
        )
    out$group <- sub( "...", ".*", out$group, fixed = TRUE )
    out
}

I'll clean this up and write a man page if there is interest in adding 
this to R, but this might be more appropriate in a package, for example: 
http://r-forge.r-project.org/projects/rsitesearch/

Romain

Liaw, Andy wrote:
> From: Jonathan Baron
>   
>> On 05/07/09 13:48, Liaw, Andy wrote:
>>     
>>> From: Duncan Murdoch 
>>>       
>>>> I'll incorporate the changes if you like
>>>>         
>> Yes.  Please do.  I understand that it won't take effect for a while.
>> When it does, I'll change my site.
>>
>>   What do you think 
>>     
>>>> of the idea 
>>>> of adding a gmane (or other archive) search to your results 
>>>> page?  Then 
>>>> if someone doesn't like what the man pages show, you can 
>>>>         
>> send them 
>>     
>>>> somewhere else, rather than leaving them to find out the 
>>>> other resources 
>>>> themselves.
>>>>
>>>> gmane has sample code for this on their search page 
>>>> search.gmane.org, so 
>>>> it looks reasonably easy.  I'd suggest following their 
>>>>         
>> last example, 
>>     
>>>> with a drop-down box to select mailing lists, with 
>>>> comp.lang.r.* as an 
>>>> option for "all lists".
>>>>
>>>> Duncan Murdoch
>>>>         
>> Good idea.  I will do this.  But there are also two other good search
>> engines.  Maybe I'll add all three search alternatives.  But then,
>> according to Sheena Iyengar, people won't choose any!  Hmm.
>>
>>     
>>> Actually, I was thinking about a possible RHelpSearch() in 
>>>       
>> addition, if
>>     
>>> Jon is no longer going to include the R-help archive in the 
>>>       
>> search.  I
>>     
>>> used the current RSiteSearch() a lot more for searching 
>>>       
>> R-help archive
>>     
>>> than functions in packages.  Ideas?  comments?
>>>       
>> This is OK with me, but I don't want to do it.  I guess it would
>> search gmane.  MarkMail is also pretty good, as is
>> http://tolstoy.newcastle.edu.au/R/ All these are much better than
>> Namazu for searching the R-help list.
>>     
>
> Sorry I didn't make it clear:  I meant something like the gmaneSearcg()
> that Romain posted, not hitting your site.
>
> Best,
> Andy
>  
>   
>> Jon
>>     


-- 
Romain Francois
Independent R Consultant
+33(0) 6 28 91 30 30
http://romainfrancois.blog.free.fr


From andy_liaw at merck.com  Thu May  7 22:02:19 2009
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 7 May 2009 16:02:19 -0400
Subject: [Rd] proposed changes to RSiteSearch
In-Reply-To: <20090507192632.GA4723@psych.upenn.edu>
References: <39B6DDB9048D0F4DAD42CB26AAFF0AFA07381973@usctmx1106.merck.com>
	<20090507141812.GB25422@psych.upenn.edu>
	<4A031A22.7080702@stats.uwo.ca>
	<39B6DDB9048D0F4DAD42CB26AAFF0AFA073C46FD@usctmx1106.merck.com>
	<20090507180930.GA1619@psych.upenn.edu>
	<39B6DDB9048D0F4DAD42CB26AAFF0AFA073C4758@usctmx1106.merck.com>
	<4A032E6F.8010001@dbmail.com>
	<20090507192632.GA4723@psych.upenn.edu>
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFA073C4844@usctmx1106.merck.com>


 I agree!  Recall, though, I had added the RSiteSearch() functionality
to the Rgui under Windows (Help / search.r-project.org...), so if
RSiteSearch() is taken out, this need to go, too.

Best,
Andy

From: Jonathan Baron
> 
> There is something to be said for taking all of these functions,
> including the original RSiteSearch, out of utils and putting them in
> the new RSiteSearch package.  These are the sorts of things that will
> get revised frequently, and this way (I think) we won't have to bother
> whoever takes care of utils, which is part of the regular R
> distribution.
> 
> I'm adding Spencer Graves to the cc list.  Maybe he is interested in
> doing this.
> 
> Jon
> 
> On 05/07/09 20:54, Romain Francois wrote:
> > We could have a few functions similar to RSiteSearch or 
> gmaneSearch I 
> > just posted and then cook a summary html page with R ...
> > 
> > Here is a function that grabs relevant groups from gmane:
> > 
> > gmaneGroups <- function( prefix = "gmane.comp.lang.r." ){
> >     url <- URLencode( sprintf( 
> > "http://dir.gmane.org/index.php?prefix=%s", prefix) )
> >     txt <- grep( '^<tr.*<td align=right.*<a', readLines( 
> url ), value = 
> > TRUE )
> >    
> >     rx <- '^.*?<a href="(.*?)">(.*?)</a>.*<td>(.*?)</td>.*$'
> >     out <- data.frame(
> >         url = gsub( rx, "\\1", txt ),
> >         group = gsub( rx, "\\2", txt ),
> >         description = gsub( rx, "\\3", txt ),
> >         stringsAsFactors = FALSE
> >         )
> >     out$group <- sub( "...", ".*", out$group, fixed = TRUE )
> >     out
> > }
> > 
> > I'll clean this up and write a man page if there is 
> interest in adding 
> > this to R, but this might be more appropriate in a package, 
> for example: 
> > http://r-forge.r-project.org/projects/rsitesearch/
> > 
> > Romain
> > 
> > Liaw, Andy wrote:
> > > From: Jonathan Baron
> > >   
> > >> On 05/07/09 13:48, Liaw, Andy wrote:
> > >>     
> > >>> From: Duncan Murdoch 
> > >>>       
> > >>>> I'll incorporate the changes if you like
> > >>>>         
> > >> Yes.  Please do.  I understand that it won't take effect 
> for a while.
> > >> When it does, I'll change my site.
> > >>
> > >>   What do you think 
> > >>     
> > >>>> of the idea 
> > >>>> of adding a gmane (or other archive) search to your results 
> > >>>> page?  Then 
> > >>>> if someone doesn't like what the man pages show, you can 
> > >>>>         
> > >> send them 
> > >>     
> > >>>> somewhere else, rather than leaving them to find out the 
> > >>>> other resources 
> > >>>> themselves.
> > >>>>
> > >>>> gmane has sample code for this on their search page 
> > >>>> search.gmane.org, so 
> > >>>> it looks reasonably easy.  I'd suggest following their 
> > >>>>         
> > >> last example, 
> > >>     
> > >>>> with a drop-down box to select mailing lists, with 
> > >>>> comp.lang.r.* as an 
> > >>>> option for "all lists".
> > >>>>
> > >>>> Duncan Murdoch
> > >>>>         
> > >> Good idea.  I will do this.  But there are also two 
> other good search
> > >> engines.  Maybe I'll add all three search alternatives.  
> But then,
> > >> according to Sheena Iyengar, people won't choose any!  Hmm.
> > >>
> > >>     
> > >>> Actually, I was thinking about a possible RHelpSearch() in 
> > >>>       
> > >> addition, if
> > >>     
> > >>> Jon is no longer going to include the R-help archive in the 
> > >>>       
> > >> search.  I
> > >>     
> > >>> used the current RSiteSearch() a lot more for searching 
> > >>>       
> > >> R-help archive
> > >>     
> > >>> than functions in packages.  Ideas?  comments?
> > >>>       
> > >> This is OK with me, but I don't want to do it.  I guess it would
> > >> search gmane.  MarkMail is also pretty good, as is
> > >> http://tolstoy.newcastle.edu.au/R/ All these are much better than
> > >> Namazu for searching the R-help list.
> > >>     
> > >
> > > Sorry I didn't make it clear:  I meant something like the 
> gmaneSearcg()
> > > that Romain posted, not hitting your site.
> > >
> > > Best,
> > > Andy
> > >  
> > >   
> > >> Jon
> > >>     
> > 
> > 
> > -- 
> > Romain Francois
> > Independent R Consultant
> > +33(0) 6 28 91 30 30
> > http://romainfrancois.blog.free.fr
> > 
> 
> -- 
> Jonathan Baron, Professor of Psychology, University of Pennsylvania
> Home page: http://www.sas.upenn.edu/~baron
> Editor: Judgment and Decision Making (http://journal.sjdm.org)
> 
Notice:  This e-mail message, together with any attachme...{{dropped:12}}


From ggrothendieck at gmail.com  Thu May  7 23:08:15 2009
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 7 May 2009 17:08:15 -0400
Subject: [Rd] proposed changes to RSiteSearch
In-Reply-To: <39B6DDB9048D0F4DAD42CB26AAFF0AFA073C4844@usctmx1106.merck.com>
References: <39B6DDB9048D0F4DAD42CB26AAFF0AFA07381973@usctmx1106.merck.com> 
	<20090507141812.GB25422@psych.upenn.edu>
	<4A031A22.7080702@stats.uwo.ca> 
	<39B6DDB9048D0F4DAD42CB26AAFF0AFA073C46FD@usctmx1106.merck.com> 
	<20090507180930.GA1619@psych.upenn.edu>
	<39B6DDB9048D0F4DAD42CB26AAFF0AFA073C4758@usctmx1106.merck.com>
	<4A032E6F.8010001@dbmail.com> <20090507192632.GA4723@psych.upenn.edu> 
	<39B6DDB9048D0F4DAD42CB26AAFF0AFA073C4844@usctmx1106.merck.com>
Message-ID: <971536df0905071408q481806ben4737b6f1d314d6c2@mail.gmail.com>

But help really needs to be delivered with R, not an addon.
It should not be necessary to know how to install packages
just to get this level of help. I think it needs to be where it
is now.

On Thu, May 7, 2009 at 4:02 PM, Liaw, Andy <andy_liaw at merck.com> wrote:
>
> ?I agree! ?Recall, though, I had added the RSiteSearch() functionality
> to the Rgui under Windows (Help / search.r-project.org...), so if
> RSiteSearch() is taken out, this need to go, too.
>
> Best,
> Andy
>
> From: Jonathan Baron
>>
>> There is something to be said for taking all of these functions,
>> including the original RSiteSearch, out of utils and putting them in
>> the new RSiteSearch package. ?These are the sorts of things that will
>> get revised frequently, and this way (I think) we won't have to bother
>> whoever takes care of utils, which is part of the regular R
>> distribution.
>>
>> I'm adding Spencer Graves to the cc list. ?Maybe he is interested in
>> doing this.
>>
>> Jon
>>
>> On 05/07/09 20:54, Romain Francois wrote:
>> > We could have a few functions similar to RSiteSearch or
>> gmaneSearch I
>> > just posted and then cook a summary html page with R ...
>> >
>> > Here is a function that grabs relevant groups from gmane:
>> >
>> > gmaneGroups <- function( prefix = "gmane.comp.lang.r." ){
>> > ? ? url <- URLencode( sprintf(
>> > "http://dir.gmane.org/index.php?prefix=%s", prefix) )
>> > ? ? txt <- grep( '^<tr.*<td align=right.*<a', readLines(
>> url ), value =
>> > TRUE )
>> >
>> > ? ? rx <- '^.*?<a href="(.*?)">(.*?)</a>.*<td>(.*?)</td>.*$'
>> > ? ? out <- data.frame(
>> > ? ? ? ? url = gsub( rx, "\\1", txt ),
>> > ? ? ? ? group = gsub( rx, "\\2", txt ),
>> > ? ? ? ? description = gsub( rx, "\\3", txt ),
>> > ? ? ? ? stringsAsFactors = FALSE
>> > ? ? ? ? )
>> > ? ? out$group <- sub( "...", ".*", out$group, fixed = TRUE )
>> > ? ? out
>> > }
>> >
>> > I'll clean this up and write a man page if there is
>> interest in adding
>> > this to R, but this might be more appropriate in a package,
>> for example:
>> > http://r-forge.r-project.org/projects/rsitesearch/
>> >
>> > Romain
>> >
>> > Liaw, Andy wrote:
>> > > From: Jonathan Baron
>> > >
>> > >> On 05/07/09 13:48, Liaw, Andy wrote:
>> > >>
>> > >>> From: Duncan Murdoch
>> > >>>
>> > >>>> I'll incorporate the changes if you like
>> > >>>>
>> > >> Yes. ?Please do. ?I understand that it won't take effect
>> for a while.
>> > >> When it does, I'll change my site.
>> > >>
>> > >> ? What do you think
>> > >>
>> > >>>> of the idea
>> > >>>> of adding a gmane (or other archive) search to your results
>> > >>>> page? ?Then
>> > >>>> if someone doesn't like what the man pages show, you can
>> > >>>>
>> > >> send them
>> > >>
>> > >>>> somewhere else, rather than leaving them to find out the
>> > >>>> other resources
>> > >>>> themselves.
>> > >>>>
>> > >>>> gmane has sample code for this on their search page
>> > >>>> search.gmane.org, so
>> > >>>> it looks reasonably easy. ?I'd suggest following their
>> > >>>>
>> > >> last example,
>> > >>
>> > >>>> with a drop-down box to select mailing lists, with
>> > >>>> comp.lang.r.* as an
>> > >>>> option for "all lists".
>> > >>>>
>> > >>>> Duncan Murdoch
>> > >>>>
>> > >> Good idea. ?I will do this. ?But there are also two
>> other good search
>> > >> engines. ?Maybe I'll add all three search alternatives.
>> But then,
>> > >> according to Sheena Iyengar, people won't choose any! ?Hmm.
>> > >>
>> > >>
>> > >>> Actually, I was thinking about a possible RHelpSearch() in
>> > >>>
>> > >> addition, if
>> > >>
>> > >>> Jon is no longer going to include the R-help archive in the
>> > >>>
>> > >> search. ?I
>> > >>
>> > >>> used the current RSiteSearch() a lot more for searching
>> > >>>
>> > >> R-help archive
>> > >>
>> > >>> than functions in packages. ?Ideas? ?comments?
>> > >>>
>> > >> This is OK with me, but I don't want to do it. ?I guess it would
>> > >> search gmane. ?MarkMail is also pretty good, as is
>> > >> http://tolstoy.newcastle.edu.au/R/ All these are much better than
>> > >> Namazu for searching the R-help list.
>> > >>
>> > >
>> > > Sorry I didn't make it clear: ?I meant something like the
>> gmaneSearcg()
>> > > that Romain posted, not hitting your site.
>> > >
>> > > Best,
>> > > Andy
>> > >
>> > >
>> > >> Jon
>> > >>
>> >
>> >
>> > --
>> > Romain Francois
>> > Independent R Consultant
>> > +33(0) 6 28 91 30 30
>> > http://romainfrancois.blog.free.fr
>> >
>>
>> --
>> Jonathan Baron, Professor of Psychology, University of Pennsylvania
>> Home page: http://www.sas.upenn.edu/~baron
>> Editor: Judgment and Decision Making (http://journal.sjdm.org)
>>
> Notice: ?This e-mail message, together with any attachme...{{dropped:12}}
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From landronimirc at gmail.com  Thu May  7 23:39:44 2009
From: landronimirc at gmail.com (Liviu Andronic)
Date: Thu, 7 May 2009 23:39:44 +0200
Subject: [Rd] proposed changes to RSiteSearch
In-Reply-To: <20090507141812.GB25422@psych.upenn.edu>
References: <39B6DDB9048D0F4DAD42CB26AAFF0AFA07381973@usctmx1106.merck.com> 
	<20090507141812.GB25422@psych.upenn.edu>
Message-ID: <68b1e2610905071439n1748eeeckf7ac755ff743c9a8@mail.gmail.com>

Dear Jonathan,

On Thu, May 7, 2009 at 4:18 PM, Jonathan Baron <baron at psych.upenn.edu> wrote:
> can't imagine that someone would want to search just vignettes and not
> help pages, or the reverse.
>
Searching vignettes only can be of interest to users. If someone is
interested in (full-fledged) code examples, and not in various
descriptions of functions, a "search vignette" facility would come in
handy.
As a personal example, recently I wanted to search all vignettes for
"mle" examples, but could find no way to do this. I had already
searched the help pages and was unable to find something of obvious
use to me.

Best regards,
Liviu


From spencer.graves at prodsyse.com  Thu May  7 23:42:27 2009
From: spencer.graves at prodsyse.com (spencerg)
Date: Thu, 07 May 2009 14:42:27 -0700
Subject: [Rd] proposed changes to RSiteSearch
In-Reply-To: <971536df0905071408q481806ben4737b6f1d314d6c2@mail.gmail.com>
References: <39B6DDB9048D0F4DAD42CB26AAFF0AFA07381973@usctmx1106.merck.com>
	<20090507141812.GB25422@psych.upenn.edu>	<4A031A22.7080702@stats.uwo.ca>
	<39B6DDB9048D0F4DAD42CB26AAFF0AFA073C46FD@usctmx1106.merck.com>
	<20090507180930.GA1619@psych.upenn.edu>	<39B6DDB9048D0F4DAD42CB26AAFF0AFA073C4758@usctmx1106.merck.com>	<4A032E6F.8010001@dbmail.com>
	<20090507192632.GA4723@psych.upenn.edu>
	<39B6DDB9048D0F4DAD42CB26AAFF0AFA073C4844@usctmx1106.merck.com>
	<971536df0905071408q481806ben4737b6f1d314d6c2@mail.gmail.com>
Message-ID: <4A0355C3.9070006@prodsyse.com>

      1.  Whatever we do with the "RSiteSearch" function, it should 
still be available every time R starts.  If we put it in its own 
package, it should still be autoloaded with "base", "utils", "stats", etc. 


      2.  Sundar indicated to me that, "if Jonathan would like to remove 
the search capability, it would be rather simple to move RSiteSearch to 
nabble" for the listserve archives.  The "RSiteSearch" function could be 
modified to combine that with a separate search of only the help pages 
on Jonathan's server. 


      3.  However, I can't volunteer to do much more on this at least 
until late June and probably not before late August.  If you wanted to 
move the "RSiteSearch" function to the "RSiteSearch" package on R-Forge, 
Romain, Sundar and I would be happy to have other developers and let 
them implement the group consensus. 


      Best Wishes,
      Spencer

Gabor Grothendieck wrote:
> But help really needs to be delivered with R, not an addon.
> It should not be necessary to know how to install packages
> just to get this level of help. I think it needs to be where it
> is now.
>
> On Thu, May 7, 2009 at 4:02 PM, Liaw, Andy <andy_liaw at merck.com> wrote:
>   
>>  I agree!  Recall, though, I had added the RSiteSearch() functionality
>> to the Rgui under Windows (Help / search.r-project.org...), so if
>> RSiteSearch() is taken out, this need to go, too.
>>
>> Best,
>> Andy
>>
>> From: Jonathan Baron
>>     
>>> There is something to be said for taking all of these functions,
>>> including the original RSiteSearch, out of utils and putting them in
>>> the new RSiteSearch package.  These are the sorts of things that will
>>> get revised frequently, and this way (I think) we won't have to bother
>>> whoever takes care of utils, which is part of the regular R
>>> distribution.
>>>
>>> I'm adding Spencer Graves to the cc list.  Maybe he is interested in
>>> doing this.
>>>
>>> Jon
>>>
>>> On 05/07/09 20:54, Romain Francois wrote:
>>>       
>>>> We could have a few functions similar to RSiteSearch or
>>>>         
>>> gmaneSearch I
>>>       
>>>> just posted and then cook a summary html page with R ...
>>>>
>>>> Here is a function that grabs relevant groups from gmane:
>>>>
>>>> gmaneGroups <- function( prefix = "gmane.comp.lang.r." ){
>>>>     url <- URLencode( sprintf(
>>>> "http://dir.gmane.org/index.php?prefix=%s", prefix) )
>>>>     txt <- grep( '^<tr.*<td align=right.*<a', readLines(
>>>>         
>>> url ), value =
>>>       
>>>> TRUE )
>>>>
>>>>     rx <- '^.*?<a href="(.*?)">(.*?)</a>.*<td>(.*?)</td>.*$'
>>>>     out <- data.frame(
>>>>         url = gsub( rx, "\\1", txt ),
>>>>         group = gsub( rx, "\\2", txt ),
>>>>         description = gsub( rx, "\\3", txt ),
>>>>         stringsAsFactors = FALSE
>>>>         )
>>>>     out$group <- sub( "...", ".*", out$group, fixed = TRUE )
>>>>     out
>>>> }
>>>>
>>>> I'll clean this up and write a man page if there is
>>>>         
>>> interest in adding
>>>       
>>>> this to R, but this might be more appropriate in a package,
>>>>         
>>> for example:
>>>       
>>>> http://r-forge.r-project.org/projects/rsitesearch/
>>>>
>>>> Romain
>>>>
>>>> Liaw, Andy wrote:
>>>>         
>>>>> From: Jonathan Baron
>>>>>
>>>>>           
>>>>>> On 05/07/09 13:48, Liaw, Andy wrote:
>>>>>>
>>>>>>             
>>>>>>> From: Duncan Murdoch
>>>>>>>
>>>>>>>               
>>>>>>>> I'll incorporate the changes if you like
>>>>>>>>
>>>>>>>>                 
>>>>>> Yes.  Please do.  I understand that it won't take effect
>>>>>>             
>>> for a while.
>>>       
>>>>>> When it does, I'll change my site.
>>>>>>
>>>>>>   What do you think
>>>>>>
>>>>>>             
>>>>>>>> of the idea
>>>>>>>> of adding a gmane (or other archive) search to your results
>>>>>>>> page?  Then
>>>>>>>> if someone doesn't like what the man pages show, you can
>>>>>>>>
>>>>>>>>                 
>>>>>> send them
>>>>>>
>>>>>>             
>>>>>>>> somewhere else, rather than leaving them to find out the
>>>>>>>> other resources
>>>>>>>> themselves.
>>>>>>>>
>>>>>>>> gmane has sample code for this on their search page
>>>>>>>> search.gmane.org, so
>>>>>>>> it looks reasonably easy.  I'd suggest following their
>>>>>>>>
>>>>>>>>                 
>>>>>> last example,
>>>>>>
>>>>>>             
>>>>>>>> with a drop-down box to select mailing lists, with
>>>>>>>> comp.lang.r.* as an
>>>>>>>> option for "all lists".
>>>>>>>>
>>>>>>>> Duncan Murdoch
>>>>>>>>
>>>>>>>>                 
>>>>>> Good idea.  I will do this.  But there are also two
>>>>>>             
>>> other good search
>>>       
>>>>>> engines.  Maybe I'll add all three search alternatives.
>>>>>>             
>>> But then,
>>>       
>>>>>> according to Sheena Iyengar, people won't choose any!  Hmm.
>>>>>>
>>>>>>
>>>>>>             
>>>>>>> Actually, I was thinking about a possible RHelpSearch() in
>>>>>>>
>>>>>>>               
>>>>>> addition, if
>>>>>>
>>>>>>             
>>>>>>> Jon is no longer going to include the R-help archive in the
>>>>>>>
>>>>>>>               
>>>>>> search.  I
>>>>>>
>>>>>>             
>>>>>>> used the current RSiteSearch() a lot more for searching
>>>>>>>
>>>>>>>               
>>>>>> R-help archive
>>>>>>
>>>>>>             
>>>>>>> than functions in packages.  Ideas?  comments?
>>>>>>>
>>>>>>>               
>>>>>> This is OK with me, but I don't want to do it.  I guess it would
>>>>>> search gmane.  MarkMail is also pretty good, as is
>>>>>> http://tolstoy.newcastle.edu.au/R/ All these are much better than
>>>>>> Namazu for searching the R-help list.
>>>>>>
>>>>>>             
>>>>> Sorry I didn't make it clear:  I meant something like the
>>>>>           
>>> gmaneSearcg()
>>>       
>>>>> that Romain posted, not hitting your site.
>>>>>
>>>>> Best,
>>>>> Andy
>>>>>
>>>>>
>>>>>           
>>>>>> Jon
>>>>>>
>>>>>>             
>>>> --
>>>> Romain Francois
>>>> Independent R Consultant
>>>> +33(0) 6 28 91 30 30
>>>> http://romainfrancois.blog.free.fr
>>>>
>>>>         
>>> --
>>> Jonathan Baron, Professor of Psychology, University of Pennsylvania
>>> Home page: http://www.sas.upenn.edu/~baron
>>> Editor: Judgment and Decision Making (http://journal.sjdm.org)
>>>
>>>       
>> Notice:  This e-mail message, together with any attachme...{{dropped:12}}
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>     
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From savicky at cs.cas.cz  Fri May  8 11:01:55 2009
From: savicky at cs.cas.cz (Petr Savicky)
Date: Fri, 8 May 2009 11:01:55 +0200
Subject: [Rd] suggestion for extending ?as.factor
In-Reply-To: <18945.19798.782710.936788@lynne.math.ethz.ch>
References: <20090503203204.GB29507@cs.cas.cz>
	<18942.43500.862186.878365@lynne.math.ethz.ch>
	<49FEEED1.8000808@biostat.ku.dk>
	<18943.3144.768738.188706@lynne.math.ethz.ch>
	<20090504163403.GA10640@cs.cas.cz> <49FF25A6.3070907@biostat.ku.dk>
	<18943.64094.648164.476070@lynne.math.ethz.ch>
	<18945.19798.782710.936788@lynne.math.ethz.ch>
Message-ID: <20090508090155.GA18486@cs.cas.cz>

On Wed, May 06, 2009 at 10:41:58AM +0200, Martin Maechler wrote:
>      PD> I think that the real issue is that we actually do want almost-equal
>      PD> numbers to be folded together. 
> 
> yes, this now (revision 48469) will happen by default, using  signif(x, 15) 
> where '15' is the default for the new optional argument 'digitsLabels'
> {better argument name? (but must nost start with 'label')}

Let me analyze the current behavior of factor(x) for numeric x with missing(levels)
and missing(labels). In this situation, levels are computed as sort(unique(x))
from possibly transformed x. Then, labels are constructed by a conversion of the
levels to strings.

I understand the current (R 2.10.0, 2009-05-07 r48492) behavior as follows.

  If keepUnique is FALSE (the default), then
    - values x are transformed by signif(x, digitsLabels)
    - labels are computed using as.character(levels)
    - digitsLabels defaults to 15, but may be set to any integer value

  If keepUnique is TRUE, then
    - values x are preserved
    - labels are computed using sprintf("%.*g", digitsLabels, levels)
    - digitsLabels defaults to 17, but may be set to any integer value

There are several situations, when this approach produces duplicated levels.
Besides the one described in my previous email, there are also others
     factor(c(0.3, 0.1+0.2), keepUnique=TRUE, digitsLabels=15)
     factor(1 + 0:5 * 1e-16, digitsLabels=17)

I would like to suggest a modification. It eliminates most of the cases, where
we get duplicated levels. It would eliminate all such cases, if the function
signif() works as expected. Unfortunately, if signif() works as it does in the
current versions of R, we still get duplicated levels.

The suggested modification is as follows.

  If keepUnique is FALSE (the default), then
    - values x are transformed by signif(x, digitsLabels)
    - labels are computed using sprintf("%.*g", digitsLabels, levels)
    - digitsLabels defaults to 15, but may be set to any integer value

  If keepUnique is TRUE, then
    - values x are preserved
    - labels are computed using sprintf("%.*g", 17, levels)
    - digitsLabels is ignored

Arguments for the modification are the following.

1. If keepUnique is FALSE, then computing labels using as.character() leads
   to duplicated labels as demonstrated in my previous email. So, i suggest to
   use sprintf("%.*g", digitsLabels, levels) instead of as.character().

2. If keepUnique is TRUE and we allow digitsLabels less than 17, then we get
   duplicated labels. So, i suggest to force digitsLabels=17, if keepUnique=TRUE.

If signif(,digitsLabels) works as expected, than the above approach should not
produce duplicated labels. Unfortunately, this is not the case.
There are numbers, which remain different in signif(x, 16), but are mapped
to the same string in sprintf("%.*g", 16, x). Examples of this kind may be
found using the script

   for (i in 1:50) {
       x <- 10^runif(1, 38, 50)
       y <- x * (1 + 0:500 * 1e-16)
       y <- unique(signif(y, 16))
       z <- unique(sprintf("%.16g", y))
       stopifnot(length(y) == length(z))
   }

This script is tested on Intel default arithmetic and on Intel with SSE.

Perhaps, digitsLabels = 16 could be forbidden, if keepUnique is FALSE.

Unfortunately, a similar problem occurs even for digitsLabels = 15, although for
much larger numbers.

   for (i in 1:200) {
       x <- 10^runif(1, 250, 300)
       y <- x * (1 + 0:500 * 1e-16)
       y <- unique(signif(y, 15))
       z <- unique(sprintf("%.15g", y))
       stopifnot(length(y) == length(z))
   }

This script finds collisions, if SSE is enabled, on two Intel computers, where i did
the test. Without SSE, it finds collisions only on one of them. May be, it depends
also on the compiler, which is different.

Petr.


From baron at psych.upenn.edu  Thu May  7 20:09:30 2009
From: baron at psych.upenn.edu (Jonathan Baron)
Date: Thu, 7 May 2009 14:09:30 -0400
Subject: [Rd] proposed changes to RSiteSearch
In-Reply-To: <39B6DDB9048D0F4DAD42CB26AAFF0AFA073C46FD@usctmx1106.merck.com>
References: <39B6DDB9048D0F4DAD42CB26AAFF0AFA07381973@usctmx1106.merck.com>
	<20090507141812.GB25422@psych.upenn.edu>
	<4A031A22.7080702@stats.uwo.ca>
	<39B6DDB9048D0F4DAD42CB26AAFF0AFA073C46FD@usctmx1106.merck.com>
Message-ID: <20090507180930.GA1619@psych.upenn.edu>

On 05/07/09 13:48, Liaw, Andy wrote:
> From: Duncan Murdoch 
> > I'll incorporate the changes if you like.

Yes.  Please do.  I understand that it won't take effect for a while.
When it does, I'll change my site.

  What do you think 
> > of the idea 
> > of adding a gmane (or other archive) search to your results 
> > page?  Then 
> > if someone doesn't like what the man pages show, you can send them 
> > somewhere else, rather than leaving them to find out the 
> > other resources 
> > themselves.
> > 
> > gmane has sample code for this on their search page 
> > search.gmane.org, so 
> > it looks reasonably easy.  I'd suggest following their last example, 
> > with a drop-down box to select mailing lists, with 
> > comp.lang.r.* as an 
> > option for "all lists".
> > 
> > Duncan Murdoch

Good idea.  I will do this.  But there are also two other good search
engines.  Maybe I'll add all three search alternatives.  But then,
according to Sheena Iyengar, people won't choose any!  Hmm.

> Actually, I was thinking about a possible RHelpSearch() in addition, if
> Jon is no longer going to include the R-help archive in the search.  I
> used the current RSiteSearch() a lot more for searching R-help archive
> than functions in packages.  Ideas?  comments?

This is OK with me, but I don't want to do it.  I guess it would
search gmane.  MarkMail is also pretty good, as is
http://tolstoy.newcastle.edu.au/R/ All these are much better than
Namazu for searching the R-help list.

Jon
 
> Andy 
> Notice:  This e-mail message, together with any attach...{{dropped:18}}


From baron at psych.upenn.edu  Thu May  7 21:26:32 2009
From: baron at psych.upenn.edu (Jonathan Baron)
Date: Thu, 7 May 2009 15:26:32 -0400
Subject: [Rd] proposed changes to RSiteSearch
In-Reply-To: <4A032E6F.8010001@dbmail.com>
References: <39B6DDB9048D0F4DAD42CB26AAFF0AFA07381973@usctmx1106.merck.com>
	<20090507141812.GB25422@psych.upenn.edu>
	<4A031A22.7080702@stats.uwo.ca>
	<39B6DDB9048D0F4DAD42CB26AAFF0AFA073C46FD@usctmx1106.merck.com>
	<20090507180930.GA1619@psych.upenn.edu>
	<39B6DDB9048D0F4DAD42CB26AAFF0AFA073C4758@usctmx1106.merck.com>
	<4A032E6F.8010001@dbmail.com>
Message-ID: <20090507192632.GA4723@psych.upenn.edu>

There is something to be said for taking all of these functions,
including the original RSiteSearch, out of utils and putting them in
the new RSiteSearch package.  These are the sorts of things that will
get revised frequently, and this way (I think) we won't have to bother
whoever takes care of utils, which is part of the regular R
distribution.

I'm adding Spencer Graves to the cc list.  Maybe he is interested in
doing this.

Jon

On 05/07/09 20:54, Romain Francois wrote:
> We could have a few functions similar to RSiteSearch or gmaneSearch I 
> just posted and then cook a summary html page with R ...
> 
> Here is a function that grabs relevant groups from gmane:
> 
> gmaneGroups <- function( prefix = "gmane.comp.lang.r." ){
>     url <- URLencode( sprintf( 
> "http://dir.gmane.org/index.php?prefix=%s", prefix) )
>     txt <- grep( '^<tr.*<td align=right.*<a', readLines( url ), value = 
> TRUE )
>    
>     rx <- '^.*?<a href="(.*?)">(.*?)</a>.*<td>(.*?)</td>.*$'
>     out <- data.frame(
>         url = gsub( rx, "\\1", txt ),
>         group = gsub( rx, "\\2", txt ),
>         description = gsub( rx, "\\3", txt ),
>         stringsAsFactors = FALSE
>         )
>     out$group <- sub( "...", ".*", out$group, fixed = TRUE )
>     out
> }
> 
> I'll clean this up and write a man page if there is interest in adding 
> this to R, but this might be more appropriate in a package, for example: 
> http://r-forge.r-project.org/projects/rsitesearch/
> 
> Romain
> 
> Liaw, Andy wrote:
> > From: Jonathan Baron
> >   
> >> On 05/07/09 13:48, Liaw, Andy wrote:
> >>     
> >>> From: Duncan Murdoch 
> >>>       
> >>>> I'll incorporate the changes if you like
> >>>>         
> >> Yes.  Please do.  I understand that it won't take effect for a while.
> >> When it does, I'll change my site.
> >>
> >>   What do you think 
> >>     
> >>>> of the idea 
> >>>> of adding a gmane (or other archive) search to your results 
> >>>> page?  Then 
> >>>> if someone doesn't like what the man pages show, you can 
> >>>>         
> >> send them 
> >>     
> >>>> somewhere else, rather than leaving them to find out the 
> >>>> other resources 
> >>>> themselves.
> >>>>
> >>>> gmane has sample code for this on their search page 
> >>>> search.gmane.org, so 
> >>>> it looks reasonably easy.  I'd suggest following their 
> >>>>         
> >> last example, 
> >>     
> >>>> with a drop-down box to select mailing lists, with 
> >>>> comp.lang.r.* as an 
> >>>> option for "all lists".
> >>>>
> >>>> Duncan Murdoch
> >>>>         
> >> Good idea.  I will do this.  But there are also two other good search
> >> engines.  Maybe I'll add all three search alternatives.  But then,
> >> according to Sheena Iyengar, people won't choose any!  Hmm.
> >>
> >>     
> >>> Actually, I was thinking about a possible RHelpSearch() in 
> >>>       
> >> addition, if
> >>     
> >>> Jon is no longer going to include the R-help archive in the 
> >>>       
> >> search.  I
> >>     
> >>> used the current RSiteSearch() a lot more for searching 
> >>>       
> >> R-help archive
> >>     
> >>> than functions in packages.  Ideas?  comments?
> >>>       
> >> This is OK with me, but I don't want to do it.  I guess it would
> >> search gmane.  MarkMail is also pretty good, as is
> >> http://tolstoy.newcastle.edu.au/R/ All these are much better than
> >> Namazu for searching the R-help list.
> >>     
> >
> > Sorry I didn't make it clear:  I meant something like the gmaneSearcg()
> > that Romain posted, not hitting your site.
> >
> > Best,
> > Andy
> >  
> >   
> >> Jon
> >>     
> 
> 
> -- 
> Romain Francois
> Independent R Consultant
> +33(0) 6 28 91 30 30
> http://romainfrancois.blog.free.fr
> 

-- 
Jonathan Baron, Professor of Psychology, University of Pennsylvania
Home page: http://www.sas.upenn.edu/~baron
Editor: Judgment and Decision Making (http://journal.sjdm.org)


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Fri May  8 12:37:26 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Fri, 08 May 2009 12:37:26 +0200
Subject: [Rd] proposed changes to RSiteSearch
In-Reply-To: <4A032E6F.8010001@dbmail.com>
References: <39B6DDB9048D0F4DAD42CB26AAFF0AFA07381973@usctmx1106.merck.com>	<20090507141812.GB25422@psych.upenn.edu>	<4A031A22.7080702@stats.uwo.ca>	<39B6DDB9048D0F4DAD42CB26AAFF0AFA073C46FD@usctmx1106.merck.com>	<20090507180930.GA1619@psych.upenn.edu>	<39B6DDB9048D0F4DAD42CB26AAFF0AFA073C4758@usctmx1106.merck.com>
	<4A032E6F.8010001@dbmail.com>
Message-ID: <4A040B66.3090803@idi.ntnu.no>

Romain Francois wrote:
>
>    txt <- grep( '^<tr.*<td align=right.*<a', readLines( url ), value =
> TRUE )
>      rx <- '^.*?<a href="(.*?)">(.*?)</a>.*<td>(.*?)</td>.*$'
>    out <- data.frame(
>        url = gsub( rx, "\\1", txt ),
>        group = gsub( rx, "\\2", txt ),
>        description = gsub( rx, "\\3", txt ),

looking at this bit of your code, i wonder why gsub is not vectorized
for the pattern and replacement arguments, although it is for the x
argument.  the three lines above could be collapsed to just one with a
vectorized gsub:

    gsubm = function(pattern, replacement, x, ...)
       mapply(USE.NAMES=FALSE, SIMPLIFY=FALSE,
           gsub, pattern=pattern, replacement=replacement, x=x, ...)

for example, given the sample data

    txt = '<foo>foo</foo><bar>bar</bar>'
    rx = '<(.*?)>(.*?)</(.*?)>'

the sequence

    open = gsub(rx, '\\1', txt, perl=TRUE)
    content = gsub(rx, '\\2', txt, perl=TRUE)
    close = gsub(rx, '\\3', txt, perl=TRUE)

    print(list(open, content, close))
   
could be replaced with

    data = structure(names=c('open', 'content', 'close'),
        gsubm(rx, paste('\\', 1:3, sep=''), txt, perl=TRUE))

    print(data)

surely, a call to mapply does not improve performance, but a
source-level fix should not be too difficult;  unfortunately, i can't
find myself willing to struggle with r sources right now.


note also that .*? does not work as a non-greedy .* with the default
regex engine, e.g.,

    txt = "foo='FOO' bar='BAR'"
    gsub("(.*?)='(.*?)'", '\\1', txt)
    # "foo='FOO' bar"
    gsub("(.*?)='(.*?)'", '\\2', txt)
    # "BAR"

because the first .*? matches everyithng up to and exclusive of the
second, *not* the first, '='.  for a non-greedy match, you'd need pcre
(and using pcre generally improves performance anyway):

    txt = "foo='FOO' bar='BAR'"
    gsub("(.*?)='(.*?)'", '\\1', txt, perl=TRUE)
    # "foo bar"
    gsub("(.*?)='(.*?)'", '\\2', txt, perl=TRUE)
    # "FOO BAR"

vQ


From baron at psych.upenn.edu  Fri May  8 12:40:38 2009
From: baron at psych.upenn.edu (Jonathan Baron)
Date: Fri, 8 May 2009 06:40:38 -0400
Subject: [Rd] proposed changes to RSiteSearch
In-Reply-To: <4A0355C3.9070006@prodsyse.com>
References: <20090507141812.GB25422@psych.upenn.edu>
	<4A031A22.7080702@stats.uwo.ca>
	<39B6DDB9048D0F4DAD42CB26AAFF0AFA073C46FD@usctmx1106.merck.com>
	<20090507180930.GA1619@psych.upenn.edu>
	<39B6DDB9048D0F4DAD42CB26AAFF0AFA073C4758@usctmx1106.merck.com>
	<4A032E6F.8010001@dbmail.com>
	<20090507192632.GA4723@psych.upenn.edu>
	<39B6DDB9048D0F4DAD42CB26AAFF0AFA073C4844@usctmx1106.merck.com>
	<971536df0905071408q481806ben4737b6f1d314d6c2@mail.gmail.com>
	<4A0355C3.9070006@prodsyse.com>
Message-ID: <20090508104038.GA643@psych.upenn.edu>

After reading all this, I favor doing one of two things:

1. Put all the search stuff, including the proposed gmane function, in
   Spencer's new package but make it one of the default packages, like
   utils, etc., or,

2. Put everything in utils, including Spencer's new package and the
   gmane function.

I do not know enough to choose between these.

On 05/07/09 14:42, spencerg wrote:
>       1.  Whatever we do with the "RSiteSearch" function, it should 
> still be available every time R starts.  If we put it in its own 
> package, it should still be autoloaded with "base", "utils", "stats", etc. 

Good point.

>       2.  Sundar indicated to me that, "if Jonathan would like to remove 
> the search capability, it would be rather simple to move RSiteSearch to 
> nabble" for the listserve archives.  The "RSiteSearch" function could be 
> modified to combine that with a separate search of only the help pages 
> on Jonathan's server. 

I do not understand "rather simple" at all.  For those who are
interested, I've put my notes on how to manage my site (which still
need a bit of revision, but this will give you some idea of what is
involved) in

http://finzi.psych.upenn.edu/~baron/notes.namazu.txt

The problem is that I have not found a way to automate this, so I
still spend several hours each month doing it by hand.  Too many
little glitches come up along the way, and the main problem is the
mailing lists.  Moreover, Namazu just doesn't work all that well for
mailing lists of this size, because of the page footers in each post.
(Now I remove them.  That was a bad idea.  But if we're going to get
rid of this anyway I will not take the time to figure out how to put
them back properly.)

Also, Liviu Androic argued that vignettes should be searchable
separately from help pages.  This makes sense, but I would strongly
prefer to move ahead on other changes and leave this until later.
The need for this sort of modification is what makes me favor option
#1 at the beginning (separate package) on the theory that it would be
easier for me to make changes than if it were part of utils, but I
don't know how this works.

So, if someone can make a decision about how to proceed, I'll do what
I can, as soon as I can.

Jon
-- 
Jonathan Baron, Professor of Psychology, University of Pennsylvania
Home page: http://www.sas.upenn.edu/~baron


From maechler at stat.math.ethz.ch  Fri May  8 15:18:01 2009
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 8 May 2009 15:18:01 +0200
Subject: [Rd] suggestion for extending ?as.factor
In-Reply-To: <20090508090155.GA18486@cs.cas.cz>
References: <20090503203204.GB29507@cs.cas.cz>
	<18942.43500.862186.878365@lynne.math.ethz.ch>
	<49FEEED1.8000808@biostat.ku.dk>
	<18943.3144.768738.188706@lynne.math.ethz.ch>
	<20090504163403.GA10640@cs.cas.cz> <49FF25A6.3070907@biostat.ku.dk>
	<18943.64094.648164.476070@lynne.math.ethz.ch>
	<18945.19798.782710.936788@lynne.math.ethz.ch>
	<20090508090155.GA18486@cs.cas.cz>
Message-ID: <18948.12553.265256.981657@lynne.math.ethz.ch>

>>>>> "PS" == Petr Savicky <savicky at cs.cas.cz>
>>>>>     on Fri, 8 May 2009 11:01:55 +0200 writes:

    PS> On Wed, May 06, 2009 at 10:41:58AM +0200, Martin Maechler wrote:
    PD> I think that the real issue is that we actually do want almost-equal
    PD> numbers to be folded together. 
    >> 
    >> yes, this now (revision 48469) will happen by default, using  signif(x, 15) 
    >> where '15' is the default for the new optional argument 'digitsLabels'
    >> {better argument name? (but must nost start with 'label')}

    PS> Let me analyze the current behavior of factor(x) for numeric x with missing(levels)
    PS> and missing(labels). In this situation, levels are computed as sort(unique(x))
    PS> from possibly transformed x. Then, labels are constructed by a conversion of the
    PS> levels to strings.

    PS> I understand the current (R 2.10.0, 2009-05-07 r48492) behavior as follows.

    PS> If keepUnique is FALSE (the default), then
    PS> - values x are transformed by signif(x, digitsLabels)
    PS> - labels are computed using as.character(levels)
    PS> - digitsLabels defaults to 15, but may be set to any integer value

    PS> If keepUnique is TRUE, then
    PS> - values x are preserved
    PS> - labels are computed using sprintf("%.*g", digitsLabels, levels)
    PS> - digitsLabels defaults to 17, but may be set to any integer value

(in theory; in practice, I think I've suggested somewhere that
 it should be  >= 17;  but see below.)

Your summary seems correct to me.

    PS> There are several situations, when this approach produces duplicated levels.
    PS> Besides the one described in my previous email, there are also others
    PS> factor(c(0.3, 0.1+0.2), keepUnique=TRUE, digitsLabels=15)

yes, but this is not much sensical; I've already contemplated
to produce a warning in such cases, something like
   
   if(keepUnique && digitsLabels < 17)
     warning(gettextf(
     "'digitsLabels = %d' is typically too small when 'keepUnique' is true",
     digitsLabels))


    PS> factor(1 + 0:5 * 1e-16, digitsLabels=17)

again, this does not make much sense; but why disallow the useR
to shoot into his foot?

    PS> I would like to suggest a modification. It eliminates most of the cases, where
    PS> we get duplicated levels. It would eliminate all such cases, if the function
    PS> signif() works as expected. Unfortunately, if signif() works as it does in the
    PS> current versions of R, we still get duplicated levels.

    PS> The suggested modification is as follows.

    PS> If keepUnique is FALSE (the default), then
    PS> - values x are transformed by signif(x, digitsLabels)
    PS> - labels are computed using sprintf("%.*g", digitsLabels, levels)
    PS> - digitsLabels defaults to 15, but may be set to any integer value

I tend like this change, given -- as you found yesterday -- that
as.character() is not even preserving 15 digits.
OTOH,  as.character() has been in use for a very long history of
S (and R), whereas using sprintf() is not back compatible with
it and actually depends on the LIBC implementation of the system-sprintf.
For that reason as.character() would be preferable.
Hmm....

    PS> If keepUnique is TRUE, then
    PS> - values x are preserved
    PS> - labels are computed using sprintf("%.*g", 17, levels)
    PS> - digitsLabels is ignored

I had originally planned to do exactly the above.
However, e.g.,  digitsLabels = 18  may be desired in some cases,
and that's why I also left the possibility to apply it in the
keepUnique case.


    PS> Arguments for the modification are the following.

    PS> 1. If keepUnique is FALSE, then computing labels using as.character() leads
    PS> to duplicated labels as demonstrated in my previous email. So, i suggest to
    PS> use sprintf("%.*g", digitsLabels, levels) instead of as.character().

{as said above, that seems sensible, though unfurtunately quite
 a bit less back-compatible!}

    PS> 2. If keepUnique is TRUE and we allow digitsLabels less than 17, then we get
    PS> duplicated labels. So, i suggest to force digitsLabels=17, if keepUnique=TRUE.

    PS> If signif(,digitsLabels) works as expected, than the above approach should not
    PS> produce duplicated labels. Unfortunately, this is not the case.
    PS> There are numbers, which remain different in signif(x, 16), but are mapped
    PS> to the same string in sprintf("%.*g", 16, x). Examples of this kind may be
    PS> found using the script

    PS> for (i in 1:50) {
    PS> x <- 10^runif(1, 38, 50)
    PS> y <- x * (1 + 0:500 * 1e-16)
    PS> y <- unique(signif(y, 16))
    PS> z <- unique(sprintf("%.16g", y))
    PS> stopifnot(length(y) == length(z))
    PS> }

    PS> This script is tested on Intel default arithmetic and on Intel with SSE.

    PS> Perhaps, digitsLabels = 16 could be forbidden, if keepUnique is FALSE.

    PS> Unfortunately, a similar problem occurs even for digitsLabels = 15, although for
    PS> much larger numbers.

    PS> for (i in 1:200) {
    PS> x <- 10^runif(1, 250, 300)
    PS> y <- x * (1 + 0:500 * 1e-16)
    PS> y <- unique(signif(y, 15))
    PS> z <- unique(sprintf("%.15g", y))
    PS> stopifnot(length(y) == length(z))
    PS> }

    PS> This script finds collisions, if SSE is enabled, on two
    PS> Intel computers, where i did the test. Without SSE, it
    PS> finds collisions only on one of them. May be, it depends
    PS> also on the compiler, which is different.

probably rather on the exact implementation of the underlying C
library ("LIBC").

Thank you, Petr, for your investigations.
We all see that the simple requirement of  
   *no more duplicate factor levels !*
leads to considerable programming efforts for the case of
factor(<numeric>, .).

One prominent R-devel reader actually proposed to me in private,
that  factor(<numeric>, .)  should give a *warning* by default,
since he considered it unsafe practice.

Note that your last investigations show that your (two) proposed
changes actually do *not* solve the problem entirely;
further note that (at least inside the sources), we now say that
duplicate levels will not just signal a warning, but an error in
the future.
As long as we don't want to allow  factor(<numeric>) to fail --rarely -- 
I think (and that actually has been a recurring daunting thought
for quite a few days) that we probably need an
extra step of checking for duplicate levels, and if we find
some, recode "everything". This will blow up the body of the
factor() function even more.

What alternatives do you (all R-devel readers!) see?

Martin


From romain.francois at dbmail.com  Fri May  8 16:47:33 2009
From: romain.francois at dbmail.com (Romain Francois)
Date: Fri, 08 May 2009 16:47:33 +0200
Subject: [Rd] proposed changes to RSiteSearch
In-Reply-To: <20090508104038.GA643@psych.upenn.edu>
References: <20090507141812.GB25422@psych.upenn.edu>	<4A031A22.7080702@stats.uwo.ca>	<39B6DDB9048D0F4DAD42CB26AAFF0AFA073C46FD@usctmx1106.merck.com>	<20090507180930.GA1619@psych.upenn.edu>	<39B6DDB9048D0F4DAD42CB26AAFF0AFA073C4758@usctmx1106.merck.com>	<4A032E6F.8010001@dbmail.com>	<20090507192632.GA4723@psych.upenn.edu>	<39B6DDB9048D0F4DAD42CB26AAFF0AFA073C4844@usctmx1106.merck.com>	<971536df0905071408q481806ben4737b6f1d314d6c2@mail.gmail.com>	<4A0355C3.9070006@prodsyse.com>
	<20090508104038.GA643@psych.upenn.edu>
Message-ID: <4A044605.1020800@dbmail.com>

Jonathan Baron wrote:
> After reading all this, I favor doing one of two things:
>
> 1. Put all the search stuff, including the proposed gmane function, in
>    Spencer's new package but make it one of the default packages, like
>    utils, etc., or,
>
> 2. Put everything in utils, including Spencer's new package and the
>    gmane function.
>
> I do not know enough to choose between these.
>   
I would tend to prefer #1 so that the functionality can incubate in a 
separate package, and then when it is mature enough, we can make a call 
about what to do with it.

Something like this:
- a generic abstract function that sets up the interface to query a 
search engine.

- implementations of this, here are what I can think of:
+ jon's RSiteSearch for help pages
+ r graphical manuals
+ gmane, markmail for mail archives
+ classic help.search
+ R news (not clear how to do this right now)
+ vignettes (not clear how to do this right now)
+ JSS articles (not clear how to this right now)
+ FAQ (not clear how to this right now)
+ ... add your own by simply register your implementation

The point about having some sort of central generic function is that it 
can be responsible for asking all engines and bring all results back in 
a single format.

This somehow duplicates work I have been doing with the rsitesearch 
firefox extension, but doing it in R has several advantages.

This I think is enough design to be a separate package.

I am not sure what are the requirements for a package to be shipped with 
the distribution of R (QA, documentation, ...), but I am sure whoever 
steps me (maybe me) can make it compliant.

There is precedent for functionality that was in a package and was 
merged into utils afterwards (rcompgen), but I think it was included 
because this was necessary, don't think these search engines __have__ to 
be in utils.

> On 05/07/09 14:42, spencerg wrote:
>   
>>       1.  Whatever we do with the "RSiteSearch" function, it should 
>> still be available every time R starts.  If we put it in its own 
>> package, it should still be autoloaded with "base", "utils", "stats", etc. 
>>     
>
> Good point.
>
>   
>>       2.  Sundar indicated to me that, "if Jonathan would like to remove 
>> the search capability, it would be rather simple to move RSiteSearch to 
>> nabble" for the listserve archives.  The "RSiteSearch" function could be 
>> modified to combine that with a separate search of only the help pages 
>> on Jonathan's server. 
>>     
>
> I do not understand "rather simple" at all.  For those who are
> interested, I've put my notes on how to manage my site (which still
> need a bit of revision, but this will give you some idea of what is
> involved) in
>
> http://finzi.psych.upenn.edu/~baron/notes.namazu.txt
>
> The problem is that I have not found a way to automate this, so I
> still spend several hours each month doing it by hand.  Too many
> little glitches come up along the way, and the main problem is the
> mailing lists.  Moreover, Namazu just doesn't work all that well for
> mailing lists of this size, because of the page footers in each post.
> (Now I remove them.  That was a bad idea.  But if we're going to get
> rid of this anyway I will not take the time to figure out how to put
> them back properly.)
>
> Also, Liviu Androic argued that vignettes should be searchable
> separately from help pages.  This makes sense, but I would strongly
> prefer to move ahead on other changes and leave this until later.
> The need for this sort of modification is what makes me favor option
> #1 at the beginning (separate package) on the theory that it would be
> easier for me to make changes than if it were part of utils, but I
> don't know how this works.
>
> So, if someone can make a decision about how to proceed, I'll do what
> I can, as soon as I can.
>
> Jon
>   


-- 
Romain Francois
Independent R Consultant
+33(0) 6 28 91 30 30
http://romainfrancois.blog.free.fr


From phgrosjean at sciviews.org  Fri May  8 17:03:13 2009
From: phgrosjean at sciviews.org (Philippe Grosjean)
Date: Fri, 08 May 2009 17:03:13 +0200
Subject: [Rd] proposed changes to RSiteSearch
In-Reply-To: <4A044605.1020800@dbmail.com>
References: <20090507141812.GB25422@psych.upenn.edu>	<4A031A22.7080702@stats.uwo.ca>	<39B6DDB9048D0F4DAD42CB26AAFF0AFA073C46FD@usctmx1106.merck.com>	<20090507180930.GA1619@psych.upenn.edu>	<39B6DDB9048D0F4DAD42CB26AAFF0AFA073C4758@usctmx1106.merck.com>	<4A032E6F.8010001@dbmail.com>	<20090507192632.GA4723@psych.upenn.edu>	<39B6DDB9048D0F4DAD42CB26AAFF0AFA073C4844@usctmx1106.merck.com>	<971536df0905071408q481806ben4737b6f1d314d6c2@mail.gmail.com>	<4A0355C3.9070006@prodsyse.com>	<20090508104038.GA643@psych.upenn.edu>
	<4A044605.1020800@dbmail.com>
Message-ID: <4A0449B1.3090909@sciviews.org>

Don't forget R wiki in the list.
Best,

Philippe
..............................................<?}))><........
  ) ) ) ) )
( ( ( ( (    Prof. Philippe Grosjean
  ) ) ) ) )
( ( ( ( (    Numerical Ecology of Aquatic Systems
  ) ) ) ) )   Mons-Hainaut University, Belgium
( ( ( ( (
..............................................................

Romain Francois wrote:
> Jonathan Baron wrote:
>> After reading all this, I favor doing one of two things:
>>
>> 1. Put all the search stuff, including the proposed gmane function, in
>>    Spencer's new package but make it one of the default packages, like
>>    utils, etc., or,
>>
>> 2. Put everything in utils, including Spencer's new package and the
>>    gmane function.
>>
>> I do not know enough to choose between these.
>>   
> I would tend to prefer #1 so that the functionality can incubate in a 
> separate package, and then when it is mature enough, we can make a call 
> about what to do with it.
> 
> Something like this:
> - a generic abstract function that sets up the interface to query a 
> search engine.
> 
> - implementations of this, here are what I can think of:
> + jon's RSiteSearch for help pages
> + r graphical manuals
> + gmane, markmail for mail archives
> + classic help.search
> + R news (not clear how to do this right now)
> + vignettes (not clear how to do this right now)
> + JSS articles (not clear how to this right now)
> + FAQ (not clear how to this right now)
> + ... add your own by simply register your implementation
> 
> The point about having some sort of central generic function is that it 
> can be responsible for asking all engines and bring all results back in 
> a single format.
> 
> This somehow duplicates work I have been doing with the rsitesearch 
> firefox extension, but doing it in R has several advantages.
> 
> This I think is enough design to be a separate package.
> 
> I am not sure what are the requirements for a package to be shipped with 
> the distribution of R (QA, documentation, ...), but I am sure whoever 
> steps me (maybe me) can make it compliant.
> 
> There is precedent for functionality that was in a package and was 
> merged into utils afterwards (rcompgen), but I think it was included 
> because this was necessary, don't think these search engines __have__ to 
> be in utils.
> 
>> On 05/07/09 14:42, spencerg wrote:
>>  
>>>       1.  Whatever we do with the "RSiteSearch" function, it should 
>>> still be available every time R starts.  If we put it in its own 
>>> package, it should still be autoloaded with "base", "utils", "stats", 
>>> etc.     
>>
>> Good point.
>>
>>  
>>>       2.  Sundar indicated to me that, "if Jonathan would like to 
>>> remove the search capability, it would be rather simple to move 
>>> RSiteSearch to nabble" for the listserve archives.  The "RSiteSearch" 
>>> function could be modified to combine that with a separate search of 
>>> only the help pages on Jonathan's server.     
>>
>> I do not understand "rather simple" at all.  For those who are
>> interested, I've put my notes on how to manage my site (which still
>> need a bit of revision, but this will give you some idea of what is
>> involved) in
>>
>> http://finzi.psych.upenn.edu/~baron/notes.namazu.txt
>>
>> The problem is that I have not found a way to automate this, so I
>> still spend several hours each month doing it by hand.  Too many
>> little glitches come up along the way, and the main problem is the
>> mailing lists.  Moreover, Namazu just doesn't work all that well for
>> mailing lists of this size, because of the page footers in each post.
>> (Now I remove them.  That was a bad idea.  But if we're going to get
>> rid of this anyway I will not take the time to figure out how to put
>> them back properly.)
>>
>> Also, Liviu Androic argued that vignettes should be searchable
>> separately from help pages.  This makes sense, but I would strongly
>> prefer to move ahead on other changes and leave this until later.
>> The need for this sort of modification is what makes me favor option
>> #1 at the beginning (separate package) on the theory that it would be
>> easier for me to make changes than if it were part of utils, but I
>> don't know how this works.
>>
>> So, if someone can make a decision about how to proceed, I'll do what
>> I can, as soon as I can.
>>
>> Jon
>>   
> 
>


From romain.francois at dbmail.com  Fri May  8 17:09:05 2009
From: romain.francois at dbmail.com (Romain Francois)
Date: Fri, 08 May 2009 17:09:05 +0200
Subject: [Rd] proposed changes to RSiteSearch
In-Reply-To: <4A0449B1.3090909@sciviews.org>
References: <20090507141812.GB25422@psych.upenn.edu>	<4A031A22.7080702@stats.uwo.ca>	<39B6DDB9048D0F4DAD42CB26AAFF0AFA073C46FD@usctmx1106.merck.com>	<20090507180930.GA1619@psych.upenn.edu>	<39B6DDB9048D0F4DAD42CB26AAFF0AFA073C4758@usctmx1106.merck.com>	<4A032E6F.8010001@dbmail.com>	<20090507192632.GA4723@psych.upenn.edu>	<39B6DDB9048D0F4DAD42CB26AAFF0AFA073C4844@usctmx1106.merck.com>	<971536df0905071408q481806ben4737b6f1d314d6c2@mail.gmail.com>	<4A0355C3.9070006@prodsyse.com>	<20090508104038.GA643@psych.upenn.edu>
	<4A044605.1020800@dbmail.com> <4A0449B1.3090909@sciviews.org>
Message-ID: <4A044B11.5060300@dbmail.com>

yes, and r graph gallery. those two would be easy to implement once the 
system is up.

Philippe Grosjean wrote:
> Don't forget R wiki in the list.
> Best,
>
> Philippe
> ..............................................<?}))><........
>  ) ) ) ) )
> ( ( ( ( (    Prof. Philippe Grosjean
>  ) ) ) ) )
> ( ( ( ( (    Numerical Ecology of Aquatic Systems
>  ) ) ) ) )   Mons-Hainaut University, Belgium
> ( ( ( ( (
> ..............................................................
>
> Romain Francois wrote:
>> Jonathan Baron wrote:
>>> After reading all this, I favor doing one of two things:
>>>
>>> 1. Put all the search stuff, including the proposed gmane function, in
>>>    Spencer's new package but make it one of the default packages, like
>>>    utils, etc., or,
>>>
>>> 2. Put everything in utils, including Spencer's new package and the
>>>    gmane function.
>>>
>>> I do not know enough to choose between these.
>>>   
>> I would tend to prefer #1 so that the functionality can incubate in a 
>> separate package, and then when it is mature enough, we can make a 
>> call about what to do with it.
>>
>> Something like this:
>> - a generic abstract function that sets up the interface to query a 
>> search engine.
>>
>> - implementations of this, here are what I can think of:
>> + jon's RSiteSearch for help pages
>> + r graphical manuals
>> + gmane, markmail for mail archives
>> + classic help.search
>> + R news (not clear how to do this right now)
>> + vignettes (not clear how to do this right now)
>> + JSS articles (not clear how to this right now)
>> + FAQ (not clear how to this right now)
>> + ... add your own by simply register your implementation
>>
>> The point about having some sort of central generic function is that 
>> it can be responsible for asking all engines and bring all results 
>> back in a single format.
>>
>> This somehow duplicates work I have been doing with the rsitesearch 
>> firefox extension, but doing it in R has several advantages.
>>
>> This I think is enough design to be a separate package.
>>
>> I am not sure what are the requirements for a package to be shipped 
>> with the distribution of R (QA, documentation, ...), but I am sure 
>> whoever steps me (maybe me) can make it compliant.
>>
>> There is precedent for functionality that was in a package and was 
>> merged into utils afterwards (rcompgen), but I think it was included 
>> because this was necessary, don't think these search engines __have__ 
>> to be in utils.
>>
>>> On 05/07/09 14:42, spencerg wrote:
>>>  
>>>>       1.  Whatever we do with the "RSiteSearch" function, it should 
>>>> still be available every time R starts.  If we put it in its own 
>>>> package, it should still be autoloaded with "base", "utils", 
>>>> "stats", etc.     
>>>
>>> Good point.
>>>
>>>  
>>>>       2.  Sundar indicated to me that, "if Jonathan would like to 
>>>> remove the search capability, it would be rather simple to move 
>>>> RSiteSearch to nabble" for the listserve archives.  The 
>>>> "RSiteSearch" function could be modified to combine that with a 
>>>> separate search of only the help pages on Jonathan's server.     
>>>
>>> I do not understand "rather simple" at all.  For those who are
>>> interested, I've put my notes on how to manage my site (which still
>>> need a bit of revision, but this will give you some idea of what is
>>> involved) in
>>>
>>> http://finzi.psych.upenn.edu/~baron/notes.namazu.txt
>>>
>>> The problem is that I have not found a way to automate this, so I
>>> still spend several hours each month doing it by hand.  Too many
>>> little glitches come up along the way, and the main problem is the
>>> mailing lists.  Moreover, Namazu just doesn't work all that well for
>>> mailing lists of this size, because of the page footers in each post.
>>> (Now I remove them.  That was a bad idea.  But if we're going to get
>>> rid of this anyway I will not take the time to figure out how to put
>>> them back properly.)
>>>
>>> Also, Liviu Androic argued that vignettes should be searchable
>>> separately from help pages.  This makes sense, but I would strongly
>>> prefer to move ahead on other changes and leave this until later.
>>> The need for this sort of modification is what makes me favor option
>>> #1 at the beginning (separate package) on the theory that it would be
>>> easier for me to make changes than if it were part of utils, but I
>>> don't know how this works.
>>>
>>> So, if someone can make a decision about how to proceed, I'll do what
>>> I can, as soon as I can.
>>>
>>> Jon
>>>   
>>
>>
>
>


-- 
Romain Francois
Independent R Consultant
+33(0) 6 28 91 30 30
http://romainfrancois.blog.free.fr


From romain.francois at dbmail.com  Fri May  8 17:11:55 2009
From: romain.francois at dbmail.com (Romain Francois)
Date: Fri, 08 May 2009 17:11:55 +0200
Subject: [Rd] proposed changes to RSiteSearch
In-Reply-To: <4A040B66.3090803@idi.ntnu.no>
References: <39B6DDB9048D0F4DAD42CB26AAFF0AFA07381973@usctmx1106.merck.com>	<20090507141812.GB25422@psych.upenn.edu>	<4A031A22.7080702@stats.uwo.ca>	<39B6DDB9048D0F4DAD42CB26AAFF0AFA073C46FD@usctmx1106.merck.com>	<20090507180930.GA1619@psych.upenn.edu>	<39B6DDB9048D0F4DAD42CB26AAFF0AFA073C4758@usctmx1106.merck.com>
	<4A032E6F.8010001@dbmail.com> <4A040B66.3090803@idi.ntnu.no>
Message-ID: <4A044BBB.7060304@dbmail.com>

strapply in package gsubfn brings elegance here:

 > txt <- '<foo>bar</foo>'
 > rx <- "<(.*?)>(.*?)</(.*?)>"
 > strapply( txt, rx, c , perl = T )
[[1]]
[1] "foo" "bar" "foo"

Too bad you have to pay this on performance:

 > txt <- rep( '<foo>bar</foo>', 1000 )
 > rx <- "<(.*?)>(.*?)</(.*?)>"
 > system.time( out <- strapply( txt, rx, c , perl = T ) )
   user  system elapsed
  2.923   0.005   3.063
 > system.time( out2 <- sapply( paste('\\', 1:3, sep=''), function(x){
+ gsub(rx, x, txt, perl=TRUE)
+ } ) )
   user  system elapsed
  0.011   0.000   0.011

Not sure what the right play is


Wacek Kusnierczyk wrote:
> Romain Francois wrote:
>   
>>    txt <- grep( '^<tr.*<td align=right.*<a', readLines( url ), value =
>> TRUE )
>>      rx <- '^.*?<a href="(.*?)">(.*?)</a>.*<td>(.*?)</td>.*$'
>>    out <- data.frame(
>>        url = gsub( rx, "\\1", txt ),
>>        group = gsub( rx, "\\2", txt ),
>>        description = gsub( rx, "\\3", txt ),
>>     
>
> looking at this bit of your code, i wonder why gsub is not vectorized
> for the pattern and replacement arguments, although it is for the x
> argument.  the three lines above could be collapsed to just one with a
> vectorized gsub:
>
>     gsubm = function(pattern, replacement, x, ...)
>        mapply(USE.NAMES=FALSE, SIMPLIFY=FALSE,
>            gsub, pattern=pattern, replacement=replacement, x=x, ...)
>
> for example, given the sample data
>
>     txt = '<foo>foo</foo><bar>bar</bar>'
>     rx = '<(.*?)>(.*?)</(.*?)>'
>
> the sequence
>
>     open = gsub(rx, '\\1', txt, perl=TRUE)
>     content = gsub(rx, '\\2', txt, perl=TRUE)
>     close = gsub(rx, '\\3', txt, perl=TRUE)
>
>     print(list(open, content, close))
>    
> could be replaced with
>
>     data = structure(names=c('open', 'content', 'close'),
>         gsubm(rx, paste('\\', 1:3, sep=''), txt, perl=TRUE))
>
>     print(data)
>
> surely, a call to mapply does not improve performance, but a
> source-level fix should not be too difficult;  unfortunately, i can't
> find myself willing to struggle with r sources right now.
>
>
> note also that .*? does not work as a non-greedy .* with the default
> regex engine, e.g.,
>
>     txt = "foo='FOO' bar='BAR'"
>     gsub("(.*?)='(.*?)'", '\\1', txt)
>     # "foo='FOO' bar"
>     gsub("(.*?)='(.*?)'", '\\2', txt)
>     # "BAR"
>
> because the first .*? matches everyithng up to and exclusive of the
> second, *not* the first, '='.  for a non-greedy match, you'd need pcre
> (and using pcre generally improves performance anyway):
>
>     txt = "foo='FOO' bar='BAR'"
>     gsub("(.*?)='(.*?)'", '\\1', txt, perl=TRUE)
>     # "foo bar"
>     gsub("(.*?)='(.*?)'", '\\2', txt, perl=TRUE)
>     # "FOO BAR"
>
> vQ
>
>
>   


-- 
Romain Francois
Independent R Consultant
+33(0) 6 28 91 30 30
http://romainfrancois.blog.free.fr


From savicky at cs.cas.cz  Fri May  8 17:14:48 2009
From: savicky at cs.cas.cz (Petr Savicky)
Date: Fri, 8 May 2009 17:14:48 +0200
Subject: [Rd] suggestion for extending ?as.factor
In-Reply-To: <18948.12553.265256.981657@lynne.math.ethz.ch>
References: <20090503203204.GB29507@cs.cas.cz>
	<18942.43500.862186.878365@lynne.math.ethz.ch>
	<49FEEED1.8000808@biostat.ku.dk>
	<18943.3144.768738.188706@lynne.math.ethz.ch>
	<20090504163403.GA10640@cs.cas.cz> <49FF25A6.3070907@biostat.ku.dk>
	<18943.64094.648164.476070@lynne.math.ethz.ch>
	<18945.19798.782710.936788@lynne.math.ethz.ch>
	<20090508090155.GA18486@cs.cas.cz>
	<18948.12553.265256.981657@lynne.math.ethz.ch>
Message-ID: <20090508151448.GA6692@cs.cas.cz>

On Fri, May 08, 2009 at 03:18:01PM +0200, Martin Maechler wrote:
> As long as we don't want to allow  factor(<numeric>) to fail --rarely -- 
> I think (and that actually has been a recurring daunting thought
> for quite a few days) that we probably need an
> extra step of checking for duplicate levels, and if we find
> some, recode "everything". This will blow up the body of the
> factor() function even more.
> 
> What alternatives do you (all R-devel readers!) see?

The command 
  f <- match(x, levels)
in factor() uses the original values and not their string representations.
I think that the main reason to do so is that we loose the ordering, if the
conversion to character is done before levels are sorted.

Let me suggest to consider the following modification, where match() is done
on the strings, not on the original values.
  levels <- unique(as.character(sort(unique(x))))
  x <- as.character(x)
  f <- match(x, levels)

Since unique() preserves the order, we will get the levels correctly
ordered. Due to using unique() twice, we will not have duplicated levels.

Is it correct?

Petr.


From h.wickham at gmail.com  Fri May  8 17:28:20 2009
From: h.wickham at gmail.com (hadley wickham)
Date: Fri, 8 May 2009 10:28:20 -0500
Subject: [Rd] proposed changes to RSiteSearch
In-Reply-To: <4A044BBB.7060304@dbmail.com>
References: <39B6DDB9048D0F4DAD42CB26AAFF0AFA07381973@usctmx1106.merck.com>
	<20090507141812.GB25422@psych.upenn.edu>
	<4A031A22.7080702@stats.uwo.ca>
	<39B6DDB9048D0F4DAD42CB26AAFF0AFA073C46FD@usctmx1106.merck.com>
	<20090507180930.GA1619@psych.upenn.edu>
	<39B6DDB9048D0F4DAD42CB26AAFF0AFA073C4758@usctmx1106.merck.com>
	<4A032E6F.8010001@dbmail.com> <4A040B66.3090803@idi.ntnu.no>
	<4A044BBB.7060304@dbmail.com>
Message-ID: <f8e6ff050905080828o3bbe9d0w147f26c5fdc1677b@mail.gmail.com>

On Fri, May 8, 2009 at 10:11 AM, Romain Francois
<romain.francois at dbmail.com> wrote:
> strapply in package gsubfn brings elegance here:
>
>> txt <- '<foo>bar</foo>'
>> rx <- "<(.*?)>(.*?)</(.*?)>"
>> strapply( txt, rx, c , perl = T )
> [[1]]
> [1] "foo" "bar" "foo"
>
> Too bad you have to pay this on performance:
>
>> txt <- rep( '<foo>bar</foo>', 1000 )
>> rx <- "<(.*?)>(.*?)</(.*?)>"
>> system.time( out <- strapply( txt, rx, c , perl = T ) )
> ?user ?system elapsed
> ?2.923 ? 0.005 ? 3.063
>> system.time( out2 <- sapply( paste('\\', 1:3, sep=''), function(x){
> + gsub(rx, x, txt, perl=TRUE)
> + } ) )
> ?user ?system elapsed
> ?0.011 ? 0.000 ? 0.011
>
> Not sure what the right play i

For me:

> system.time( out <- strapply( txt, rx, c , perl = T ) )
   user  system elapsed
  0.004   0.000   0.004

> system.time( out2 <- sapply( paste('\\', 1:3, sep=''), function(x){
+ gsub(rx, x, txt, perl=TRUE)
+ } ) )
   user  system elapsed
      0       0       0

Hadley

-- 
http://had.co.nz/


From phgrosjean at sciviews.org  Fri May  8 18:07:06 2009
From: phgrosjean at sciviews.org (Philippe Grosjean)
Date: Fri, 08 May 2009 18:07:06 +0200
Subject: [Rd] proposed changes to RSiteSearch
In-Reply-To: <4A044BBB.7060304@dbmail.com>
References: <39B6DDB9048D0F4DAD42CB26AAFF0AFA07381973@usctmx1106.merck.com>	<20090507141812.GB25422@psych.upenn.edu>	<4A031A22.7080702@stats.uwo.ca>	<39B6DDB9048D0F4DAD42CB26AAFF0AFA073C46FD@usctmx1106.merck.com>	<20090507180930.GA1619@psych.upenn.edu>	<39B6DDB9048D0F4DAD42CB26AAFF0AFA073C4758@usctmx1106.merck.com>	<4A032E6F.8010001@dbmail.com>
	<4A040B66.3090803@idi.ntnu.no> <4A044BBB.7060304@dbmail.com>
Message-ID: <4A0458AA.3030104@sciviews.org>


..............................................<?}))><........
  ) ) ) ) )
( ( ( ( (    Prof. Philippe Grosjean
  ) ) ) ) )
( ( ( ( (    Numerical Ecology of Aquatic Systems
  ) ) ) ) )   Mons-Hainaut University, Belgium
( ( ( ( (
..............................................................

Romain Francois wrote:
> strapply in package gsubfn brings elegance here:

Don't! If you write functions to be used in a package to be included 
somehow in the base or recommended packages, then, your package should 
only depends on... base (preferably), or recommended packages itself!

So, forget about gsubfn, unless it is itself incorporated in base or utils.
Best,

Philippe

>  > txt <- '<foo>bar</foo>'
>  > rx <- "<(.*?)>(.*?)</(.*?)>"
>  > strapply( txt, rx, c , perl = T )
> [[1]]
> [1] "foo" "bar" "foo"
> 
> Too bad you have to pay this on performance:
> 
>  > txt <- rep( '<foo>bar</foo>', 1000 )
>  > rx <- "<(.*?)>(.*?)</(.*?)>"
>  > system.time( out <- strapply( txt, rx, c , perl = T ) )
>   user  system elapsed
>  2.923   0.005   3.063
>  > system.time( out2 <- sapply( paste('\\', 1:3, sep=''), function(x){
> + gsub(rx, x, txt, perl=TRUE)
> + } ) )
>   user  system elapsed
>  0.011   0.000   0.011
> 
> Not sure what the right play is
> 
> 
> Wacek Kusnierczyk wrote:
>> Romain Francois wrote:
>>  
>>>    txt <- grep( '^<tr.*<td align=right.*<a', readLines( url ), value =
>>> TRUE )
>>>      rx <- '^.*?<a href="(.*?)">(.*?)</a>.*<td>(.*?)</td>.*$'
>>>    out <- data.frame(
>>>        url = gsub( rx, "\\1", txt ),
>>>        group = gsub( rx, "\\2", txt ),
>>>        description = gsub( rx, "\\3", txt ),
>>>     
>>
>> looking at this bit of your code, i wonder why gsub is not vectorized
>> for the pattern and replacement arguments, although it is for the x
>> argument.  the three lines above could be collapsed to just one with a
>> vectorized gsub:
>>
>>     gsubm = function(pattern, replacement, x, ...)
>>        mapply(USE.NAMES=FALSE, SIMPLIFY=FALSE,
>>            gsub, pattern=pattern, replacement=replacement, x=x, ...)
>>
>> for example, given the sample data
>>
>>     txt = '<foo>foo</foo><bar>bar</bar>'
>>     rx = '<(.*?)>(.*?)</(.*?)>'
>>
>> the sequence
>>
>>     open = gsub(rx, '\\1', txt, perl=TRUE)
>>     content = gsub(rx, '\\2', txt, perl=TRUE)
>>     close = gsub(rx, '\\3', txt, perl=TRUE)
>>
>>     print(list(open, content, close))
>>    could be replaced with
>>
>>     data = structure(names=c('open', 'content', 'close'),
>>         gsubm(rx, paste('\\', 1:3, sep=''), txt, perl=TRUE))
>>
>>     print(data)
>>
>> surely, a call to mapply does not improve performance, but a
>> source-level fix should not be too difficult;  unfortunately, i can't
>> find myself willing to struggle with r sources right now.
>>
>>
>> note also that .*? does not work as a non-greedy .* with the default
>> regex engine, e.g.,
>>
>>     txt = "foo='FOO' bar='BAR'"
>>     gsub("(.*?)='(.*?)'", '\\1', txt)
>>     # "foo='FOO' bar"
>>     gsub("(.*?)='(.*?)'", '\\2', txt)
>>     # "BAR"
>>
>> because the first .*? matches everyithng up to and exclusive of the
>> second, *not* the first, '='.  for a non-greedy match, you'd need pcre
>> (and using pcre generally improves performance anyway):
>>
>>     txt = "foo='FOO' bar='BAR'"
>>     gsub("(.*?)='(.*?)'", '\\1', txt, perl=TRUE)
>>     # "foo bar"
>>     gsub("(.*?)='(.*?)'", '\\2', txt, perl=TRUE)
>>     # "FOO BAR"
>>
>> vQ
>>
>>
>>   
> 
>


From savicky at cs.cas.cz  Fri May  8 18:10:56 2009
From: savicky at cs.cas.cz (Petr Savicky)
Date: Fri, 8 May 2009 18:10:56 +0200
Subject: [Rd] suggestion for extending ?as.factor
In-Reply-To: <20090508151448.GA6692@cs.cas.cz>
References: <18942.43500.862186.878365@lynne.math.ethz.ch>
	<49FEEED1.8000808@biostat.ku.dk>
	<18943.3144.768738.188706@lynne.math.ethz.ch>
	<20090504163403.GA10640@cs.cas.cz> <49FF25A6.3070907@biostat.ku.dk>
	<18943.64094.648164.476070@lynne.math.ethz.ch>
	<18945.19798.782710.936788@lynne.math.ethz.ch>
	<20090508090155.GA18486@cs.cas.cz>
	<18948.12553.265256.981657@lynne.math.ethz.ch>
	<20090508151448.GA6692@cs.cas.cz>
Message-ID: <20090508161056.GB6692@cs.cas.cz>

On Fri, May 08, 2009 at 05:14:48PM +0200, Petr Savicky wrote:
> Let me suggest to consider the following modification, where match() is done
> on the strings, not on the original values.
>   levels <- unique(as.character(sort(unique(x))))
>   x <- as.character(x)
>   f <- match(x, levels)

An alternative solution is
  ind <- order(x)
  x <- as.character(x) # or any other conversion to character
  levels <- unique(x[ind]) # get unique levels ordered by the original values
  f <- match(x, levels)

The advantage of this over the suggestion from my previous email is that
the string conversion is applied only once. The conversion need not be only
as.character(). There may be other choices specified by a parametr. I have
strong objections against the existing implementation of as.character(),
but still i think that as.character() should be the default for factor()
for the sake of consistency of the R language.

Petr.


From maechler at stat.math.ethz.ch  Fri May  8 18:48:40 2009
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 8 May 2009 18:48:40 +0200
Subject: [Rd] suggestion for extending ?as.factor
In-Reply-To: <20090508161056.GB6692@cs.cas.cz>
References: <18942.43500.862186.878365@lynne.math.ethz.ch>
	<49FEEED1.8000808@biostat.ku.dk>
	<18943.3144.768738.188706@lynne.math.ethz.ch>
	<20090504163403.GA10640@cs.cas.cz> <49FF25A6.3070907@biostat.ku.dk>
	<18943.64094.648164.476070@lynne.math.ethz.ch>
	<18945.19798.782710.936788@lynne.math.ethz.ch>
	<20090508090155.GA18486@cs.cas.cz>
	<18948.12553.265256.981657@lynne.math.ethz.ch>
	<20090508151448.GA6692@cs.cas.cz> <20090508161056.GB6692@cs.cas.cz>
Message-ID: <18948.25192.935452.678430@lynne.math.ethz.ch>

>>>>> "PS" == Petr Savicky <savicky at cs.cas.cz>
>>>>>     on Fri, 8 May 2009 18:10:56 +0200 writes:

    PS> On Fri, May 08, 2009 at 05:14:48PM +0200, Petr Savicky wrote:
    >> Let me suggest to consider the following modification, where match() is done
    >> on the strings, not on the original values.
    >> levels <- unique(as.character(sort(unique(x))))
    >> x <- as.character(x)
    >> f <- match(x, levels)

    PS> An alternative solution is

    > ind <- order(x)
    > x <- as.character(x) # or any other conversion to character
    > levels <- unique(x[ind]) # get unique levels ordered by the original values
    > f <- match(x, levels)

Yes, that's an interesting quite different and simple approach.

    PS> The advantage of this over the suggestion from my previous email is that
    PS> the string conversion is applied only once. The conversion need not be only
    PS> as.character(). There may be other choices specified by a parametr. I have
    PS> strong objections against the existing implementation of as.character(),

{(because it is not *accurate* enough, right ?)}

    PS> but still i think that as.character() should be the default for factor()
    PS> for the sake of consistency of the R language.

Hmm...  Peter Dalgaard very early in this thread
remarked that at least in the use of  table(..),
factor() should not be extremely accurate, and that's what
R-devel's factor has been doing recently.

But then, table(.) could be changed to explicitly call
    factor(signif(x, 15), ...)
for the case of numeric x.

BTW: I found that practically all the remaining border cases you
     had, are "solved" by using  14 instead of 15.

I'm currently testing a version of factor() that uses 14, 
*and* adds an extra final level test, removing duplicated ones.

Martin


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Fri May  8 19:02:11 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Fri, 08 May 2009 19:02:11 +0200
Subject: [Rd] proposed changes to RSiteSearch
In-Reply-To: <4A044BBB.7060304@dbmail.com>
References: <39B6DDB9048D0F4DAD42CB26AAFF0AFA07381973@usctmx1106.merck.com>	<20090507141812.GB25422@psych.upenn.edu>	<4A031A22.7080702@stats.uwo.ca>	<39B6DDB9048D0F4DAD42CB26AAFF0AFA073C46FD@usctmx1106.merck.com>	<20090507180930.GA1619@psych.upenn.edu>	<39B6DDB9048D0F4DAD42CB26AAFF0AFA073C4758@usctmx1106.merck.com>	<4A032E6F.8010001@dbmail.com>
	<4A040B66.3090803@idi.ntnu.no> <4A044BBB.7060304@dbmail.com>
Message-ID: <4A046593.8050501@idi.ntnu.no>

Romain Francois wrote:
> strapply in package gsubfn brings elegance here:
>
> > txt <- '<foo>bar</foo>'
> > rx <- "<(.*?)>(.*?)</(.*?)>"
> > strapply( txt, rx, c , perl = T )
> [[1]]
> [1] "foo" "bar" "foo"
>

sure, but this does not, in any way, make it less strange that gsub is
not vectorized. 


> Too bad you have to pay this on performance:
>
> > txt <- rep( '<foo>bar</foo>', 1000 )
> > rx <- "<(.*?)>(.*?)</(.*?)>"
> > system.time( out <- strapply( txt, rx, c , perl = T ) )
>   user  system elapsed
>  2.923   0.005   3.063
> > system.time( out2 <- sapply( paste('\\', 1:3, sep=''), function(x){
> + gsub(rx, x, txt, perl=TRUE)
> + } ) )
>   user  system elapsed
>  0.011   0.000   0.011

    strapply

and you know why.


vQ


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Fri May  8 19:25:29 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Fri, 08 May 2009 19:25:29 +0200
Subject: [Rd] proposed changes to RSiteSearch
In-Reply-To: <f8e6ff050905080828o3bbe9d0w147f26c5fdc1677b@mail.gmail.com>
References: <39B6DDB9048D0F4DAD42CB26AAFF0AFA07381973@usctmx1106.merck.com>	<20090507141812.GB25422@psych.upenn.edu>	<4A031A22.7080702@stats.uwo.ca>	<39B6DDB9048D0F4DAD42CB26AAFF0AFA073C46FD@usctmx1106.merck.com>	<20090507180930.GA1619@psych.upenn.edu>	<39B6DDB9048D0F4DAD42CB26AAFF0AFA073C4758@usctmx1106.merck.com>	<4A032E6F.8010001@dbmail.com>
	<4A040B66.3090803@idi.ntnu.no>	<4A044BBB.7060304@dbmail.com>
	<f8e6ff050905080828o3bbe9d0w147f26c5fdc1677b@mail.gmail.com>
Message-ID: <4A046B09.5040308@idi.ntnu.no>

hadley wickham wrote:
> On Fri, May 8, 2009 at 10:11 AM, Romain Francois
> <romain.francois at dbmail.com> wrote:
>   
>> strapply in package gsubfn brings elegance here:
>>
>>     
>>> txt <- '<foo>bar</foo>'
>>> rx <- "<(.*?)>(.*?)</(.*?)>"
>>> strapply( txt, rx, c , perl = T )
>>>       
>> [[1]]
>> [1] "foo" "bar" "foo"
>>
>> Too bad you have to pay this on performance:
>>
>>     
>>> txt <- rep( '<foo>bar</foo>', 1000 )
>>> rx <- "<(.*?)>(.*?)</(.*?)>"
>>> system.time( out <- strapply( txt, rx, c , perl = T ) )
>>>       
>>  user  system elapsed
>>  2.923   0.005   3.063
>>     
>>> system.time( out2 <- sapply( paste('\\', 1:3, sep=''), function(x){
>>>       
>> + gsub(rx, x, txt, perl=TRUE)
>> + } ) )
>>  user  system elapsed
>>  0.011   0.000   0.011
>>
>> Not sure what the right play i
>>     
>
> For me:
>
>   
>> system.time( out <- strapply( txt, rx, c , perl = T ) )
>>     
>    user  system elapsed
>   0.004   0.000   0.004
>
>   
>> system.time( out2 <- sapply( paste('\\', 1:3, sep=''), function(x){
>>     
> + gsub(rx, x, txt, perl=TRUE)
> + } ) )
>    user  system elapsed
>       0       0       0
>   

for me:

    txt <- '<foo>bar</foo>'
    rx <- '<(.*?)>(.*?)</(.*?)>'

    library(rbenchmark)
    benchmark(replications=1000, columns=c('test', 'elapsed'),
order='elapsed',
       sapply=sapply(paste('\\', 1:3, sep=''), function(x) gsub(rx, x,
txt, perl=TRUE)),
       mapply=mapply(gsub, rx, paste('\\', 1:3, sep=''), txt, perl=TRUE),
       strapply=strapply(txt, rx, c, perl=TRUE))
    # 2   mapply   0.151
    # 1   sapply   0.166
    # 3 strapply   1.917

vQ


From romain.francois at dbmail.com  Fri May  8 19:25:42 2009
From: romain.francois at dbmail.com (Romain Francois)
Date: Fri, 08 May 2009 19:25:42 +0200
Subject: [Rd] proposed changes to RSiteSearch
In-Reply-To: <4A0458AA.3030104@sciviews.org>
References: <39B6DDB9048D0F4DAD42CB26AAFF0AFA07381973@usctmx1106.merck.com>	<20090507141812.GB25422@psych.upenn.edu>	<4A031A22.7080702@stats.uwo.ca>	<39B6DDB9048D0F4DAD42CB26AAFF0AFA073C46FD@usctmx1106.merck.com>	<20090507180930.GA1619@psych.upenn.edu>	<39B6DDB9048D0F4DAD42CB26AAFF0AFA073C4758@usctmx1106.merck.com>	<4A032E6F.8010001@dbmail.com>
	<4A040B66.3090803@idi.ntnu.no> <4A044BBB.7060304@dbmail.com>
	<4A0458AA.3030104@sciviews.org>
Message-ID: <4A046B16.3000906@dbmail.com>

Philippe Grosjean wrote:
>
> ..............................................<?}))><........
>  ) ) ) ) )
> ( ( ( ( (    Prof. Philippe Grosjean
>  ) ) ) ) )
> ( ( ( ( (    Numerical Ecology of Aquatic Systems
>  ) ) ) ) )   Mons-Hainaut University, Belgium
> ( ( ( ( (
> ..............................................................
>
> Romain Francois wrote:
>> strapply in package gsubfn brings elegance here:
>
> Don't! If you write functions to be used in a package to be included 
> somehow in the base or recommended packages, then, your package should 
> only depends on... base (preferably), or recommended packages itself!

Definitely.

>
> So, forget about gsubfn, unless it is itself incorporated in base or 
> utils.
> Best,
>
> Philippe
>
>>  > txt <- '<foo>bar</foo>'
>>  > rx <- "<(.*?)>(.*?)</(.*?)>"
>>  > strapply( txt, rx, c , perl = T )
>> [[1]]
>> [1] "foo" "bar" "foo"
>>
>> Too bad you have to pay this on performance:
>>
>>  > txt <- rep( '<foo>bar</foo>', 1000 )
>>  > rx <- "<(.*?)>(.*?)</(.*?)>"
>>  > system.time( out <- strapply( txt, rx, c , perl = T ) )
>>   user  system elapsed
>>  2.923   0.005   3.063
>>  > system.time( out2 <- sapply( paste('\\', 1:3, sep=''), function(x){
>> + gsub(rx, x, txt, perl=TRUE)
>> + } ) )
>>   user  system elapsed
>>  0.011   0.000   0.011
>>
>> Not sure what the right play is
>>
>>
>> Wacek Kusnierczyk wrote:
>>> Romain Francois wrote:
>>>  
>>>>    txt <- grep( '^<tr.*<td align=right.*<a', readLines( url ), value =
>>>> TRUE )
>>>>      rx <- '^.*?<a href="(.*?)">(.*?)</a>.*<td>(.*?)</td>.*$'
>>>>    out <- data.frame(
>>>>        url = gsub( rx, "\\1", txt ),
>>>>        group = gsub( rx, "\\2", txt ),
>>>>        description = gsub( rx, "\\3", txt ),
>>>>     
>>>
>>> looking at this bit of your code, i wonder why gsub is not vectorized
>>> for the pattern and replacement arguments, although it is for the x
>>> argument.  the three lines above could be collapsed to just one with a
>>> vectorized gsub:
>>>
>>>     gsubm = function(pattern, replacement, x, ...)
>>>        mapply(USE.NAMES=FALSE, SIMPLIFY=FALSE,
>>>            gsub, pattern=pattern, replacement=replacement, x=x, ...)
>>>
>>> for example, given the sample data
>>>
>>>     txt = '<foo>foo</foo><bar>bar</bar>'
>>>     rx = '<(.*?)>(.*?)</(.*?)>'
>>>
>>> the sequence
>>>
>>>     open = gsub(rx, '\\1', txt, perl=TRUE)
>>>     content = gsub(rx, '\\2', txt, perl=TRUE)
>>>     close = gsub(rx, '\\3', txt, perl=TRUE)
>>>
>>>     print(list(open, content, close))
>>>    could be replaced with
>>>
>>>     data = structure(names=c('open', 'content', 'close'),
>>>         gsubm(rx, paste('\\', 1:3, sep=''), txt, perl=TRUE))
>>>
>>>     print(data)
>>>
>>> surely, a call to mapply does not improve performance, but a
>>> source-level fix should not be too difficult;  unfortunately, i can't
>>> find myself willing to struggle with r sources right now.
>>>
>>>
>>> note also that .*? does not work as a non-greedy .* with the default
>>> regex engine, e.g.,
>>>
>>>     txt = "foo='FOO' bar='BAR'"
>>>     gsub("(.*?)='(.*?)'", '\\1', txt)
>>>     # "foo='FOO' bar"
>>>     gsub("(.*?)='(.*?)'", '\\2', txt)
>>>     # "BAR"
>>>
>>> because the first .*? matches everyithng up to and exclusive of the
>>> second, *not* the first, '='.  for a non-greedy match, you'd need pcre
>>> (and using pcre generally improves performance anyway):
>>>
>>>     txt = "foo='FOO' bar='BAR'"
>>>     gsub("(.*?)='(.*?)'", '\\1', txt, perl=TRUE)
>>>     # "foo bar"
>>>     gsub("(.*?)='(.*?)'", '\\2', txt, perl=TRUE)
>>>     # "FOO BAR"
>>>
>>> vQ
>>>
>>>
>>>   
>>
>>
>
>


-- 
Romain Francois
Independent R Consultant
+33(0) 6 28 91 30 30
http://romainfrancois.blog.free.fr


From savicky at cs.cas.cz  Fri May  8 20:53:13 2009
From: savicky at cs.cas.cz (Petr Savicky)
Date: Fri, 8 May 2009 20:53:13 +0200
Subject: [Rd] suggestion for extending ?as.factor
In-Reply-To: <18948.25192.935452.678430@lynne.math.ethz.ch>
References: <18943.3144.768738.188706@lynne.math.ethz.ch>
	<20090504163403.GA10640@cs.cas.cz> <49FF25A6.3070907@biostat.ku.dk>
	<18943.64094.648164.476070@lynne.math.ethz.ch>
	<18945.19798.782710.936788@lynne.math.ethz.ch>
	<20090508090155.GA18486@cs.cas.cz>
	<18948.12553.265256.981657@lynne.math.ethz.ch>
	<20090508151448.GA6692@cs.cas.cz> <20090508161056.GB6692@cs.cas.cz>
	<18948.25192.935452.678430@lynne.math.ethz.ch>
Message-ID: <20090508185313.GA26872@cs.cas.cz>

On Fri, May 08, 2009 at 06:48:40PM +0200, Martin Maechler wrote:
> >>>>> "PS" == Petr Savicky <savicky at cs.cas.cz>
> >>>>>     on Fri, 8 May 2009 18:10:56 +0200 writes:
[...]
>     PS> ... I have
>     PS> strong objections against the existing implementation of as.character(),
> 
> {(because it is not *accurate* enough, right ?)}

The problem is not exactly low accuracy. The problem is unpredictable
accuracy. If the accuracy is systematically 15 or 14 digits, it would be
fine and suitable for most purposes.

However the accuracy ranges between 14 and 20 digits and may be different
on different platforms. For example, on my old Xeon comupter, the same
numbers may be converted to strings representing different values:

  with SSE               without SSE

  "8459184.47742229"     "8459184.4774223"     
  "84307700406756081664" "8.4307700406756e+19" 
  "9262815.27852281"     "9262815.2785228"     
  "2.1006742758024e+19"  "21006742758023974912"
  "7.07078598983389e+25" "7.0707859898339e+25" 
  "8.0808066145628e+28"  "8.08080661456281e+28"
  "9180932974.85929"     "9180932974.8593"     
  "72.4923408890729"     "72.492340889073"     

Sometimes there are differences in trailing zeros.

  with SSE               without SSE

  "1.97765325859480e+25" "1.9776532585948e+25" 
  "21762633836.0360"     "21762633836.036"     
  "2018960238339.80"     "2018960238339.8"     
  "239567.78053486"      "239567.780534860"    
  "2571116684765.50"     "2571116684765.5"     
  "3989945.2102949"      "3989945.21029490"    
  "1.1259245205867e+23"  "1.12592452058670e+23"
  "3.2867033904477e+29"  "3.28670339044770e+29"
  "2.8271117654895e+29"  "2.82711176548950e+29"
  "26854166.6173020"     "26854166.617302"     
  "4.85247217360750"     "4.8524721736075"     
  "345123.247838540"     "345123.24783854"     

For random numbers in the sample generated as 10^runif(100000, 0, 30),
from which i selected the first 20 examples above, the probability of
different results was almost 0.01 (978 differences among 100000 numbers).

I think that the platform dependence even limits the advantage
of backward compatibility.

Petr.


From w.gray at vanderbilt.edu  Fri May  8 17:09:49 2009
From: w.gray at vanderbilt.edu (Will Gray)
Date: Fri, 08 May 2009 10:09:49 -0500
Subject: [Rd] unsplit list of data.frames with one column
Message-ID: <4A044B3D.7010506@vanderbilt.edu>


Perhaps this is the intended behavior, but I discovered that unsplit 
throws an error when it tries to set rownames of a variable that has 
no dimension.  This occurs when unsplit is passed a list of 
data.frames that have only a single column.

An example:

df <- data.frame(letters[seq(25)])
fac <- rep(seq(5), 5)
unsplit(split(df, fac), fac)

For reference, I'm using R version 2.9.0 (2009-04-17), subversion 
revision 48333, on Ubuntu 8.10.

-- 
William H. Gray, III                          Computer Systems Analyst
Biostatistics Shared Resource          Vanderbilt-Ingram Cancer Center
571 Preston Building                          Nashville, TN 37232-6848
Ph. 615.936.0563                                      Fax 615.936.2602


From maninalift at googlemail.com  Fri May  8 14:19:52 2009
From: maninalift at googlemail.com (Casper Clemence)
Date: Fri, 8 May 2009 13:19:52 +0100
Subject: [Rd] dqrdc2_ dqrsl_ dtrsl_ missing from libs? compiling earth
	standalone
Message-ID: <4c1964560905080519rd70c5efjc7edd27a0860e817@mail.gmail.com>

I have been trying to compile the earth Multivariate Adaptive
Regression of Splines package as a standalone application under Linux
(x86_64 kernel-2.6.27.21 openSUSE 11.1) with gcc 4.3.2.

The package compiles without problems from within R as an R module and
I get the following linker error:

    earth.c:(.text+0x1a14): undefined reference to `dqrdc2_'
    earth.c:(.text+0x1ae4): undefined reference to `dqrsl_'
    earth.c:(.text+0x1d99): undefined reference to `dtrsl_'

earth.c includes:

   extern _C_ int dqrdc2_(...
   extern _C_ int dqrsl_(...
   extern _C_ void dtrsl_(..
   extern _C_ void daxpy_(...
   extern _C_ double ddot_(...

I'm linking against libRblas.so and libRlapack.so so I did "nm
libRblas.so libRlapack.so" and found that there were no symbols for
dqrdc2_, dqrsl_, dqrsl_ and dtrsl_.

The functions are declared in "R_ext/Applic.h" and implemented in
separate f77 files.

I find that libR.a appears to contain the symbols but there is no libR.so

I'm compiling earth using:

   gcc -DSTANDALONE -DMAIN -Wall -pedantic -Wextra -O3 -std=gnu99
-I/home/badbear/Documents/code/localpackages/lib64/R/include
-I../src/tests ../src/earth.c -L. -lblas -lRblas -lRlapack -o
earthMain

(I have placed libRblas.so and libRlapack.so in the local folder
because I was having problems with linking to them in another
location)

Do I need to create a shared-object from libR.a? Do I need to link
agains libR.a directly?

Many thanks,

Casper


From maninalift at googlemail.com  Fri May  8 16:42:16 2009
From: maninalift at googlemail.com (Casper Clemence)
Date: Fri, 8 May 2009 15:42:16 +0100
Subject: [Rd] dqrdc2_ dqrsl_ dtrsl_ missing from libs? compiling earth
	standalone
In-Reply-To: <4c1964560905080519rd70c5efjc7edd27a0860e817@mail.gmail.com>
References: <4c1964560905080519rd70c5efjc7edd27a0860e817@mail.gmail.com>
Message-ID: <4c1964560905080742m2d376bd4j8f4330041a67b104@mail.gmail.com>

solved

I just linked to the libR.a :?/

2009/5/8 Casper Clemence <maninalift at googlemail.com>:
> I have been trying to compile the earth Multivariate Adaptive
> Regression of Splines package as a standalone application under Linux
> (x86_64 kernel-2.6.27.21 openSUSE 11.1) with gcc 4.3.2.
>
> The package compiles without problems from within R as an R module and
> I get the following linker error:
>
> ? ?earth.c:(.text+0x1a14): undefined reference to `dqrdc2_'
> ? ?earth.c:(.text+0x1ae4): undefined reference to `dqrsl_'
> ? ?earth.c:(.text+0x1d99): undefined reference to `dtrsl_'
>
> earth.c includes:
>
> ? extern _C_ int dqrdc2_(...
> ? extern _C_ int dqrsl_(...
> ? extern _C_ void dtrsl_(..
> ? extern _C_ void daxpy_(...
> ? extern _C_ double ddot_(...
>
> I'm linking against libRblas.so and libRlapack.so so I did "nm
> libRblas.so libRlapack.so" and found that there were no symbols for
> dqrdc2_, dqrsl_, dqrsl_ and dtrsl_.
>
> The functions are declared in "R_ext/Applic.h" and implemented in
> separate f77 files.
>
> I find that libR.a appears to contain the symbols but there is no libR.so
>
> I'm compiling earth using:
>
> ? gcc -DSTANDALONE -DMAIN -Wall -pedantic -Wextra -O3 -std=gnu99
> -I/home/badbear/Documents/code/localpackages/lib64/R/include
> -I../src/tests ../src/earth.c -L. -lblas -lRblas -lRlapack -o
> earthMain
>
> (I have placed libRblas.so and libRlapack.so in the local folder
> because I was having problems with linking to them in another
> location)
>
> Do I need to create a shared-object from libR.a? Do I need to link
> agains libR.a directly?
>
> Many thanks,
>
> Casper
>


From kelley.dan at gmail.com  Sat May  9 00:31:22 2009
From: kelley.dan at gmail.com (Dan Kelley)
Date: Fri, 8 May 2009 15:31:22 -0700 (PDT)
Subject: [Rd] patch for axis.POSIXct (related to timezones)
In-Reply-To: <alpine.LFD.2.00.0903050746270.22802@gannet.stats.ox.ac.uk>
References: <22338700.post@talk.nabble.com>
	<alpine.LFD.2.00.0903050746270.22802@gannet.stats.ox.ac.uk>
Message-ID: <23454737.post@talk.nabble.com>


Some time ago, I posted a note about what I considered to be a bug in
axis.POSIXt() for R 2.8.x, relating to whether timezones in the data are
obeyed on the axes.  A link to that note, and to a quick and helpful
response, is at the following URL

http://www.nabble.com/patch-for-axis.POSIXct-%28related-to-timezones%29-td22338700.html#a22338700

and I note that R 2.9.0 has been adjusted to help with this.  However, there
are still problems.  I do apologize for not having performed a test build
prior to the 2.9.0 release; this was partly because I find test builds
difficult on my OSX box, and partly because I have written replacement code
and mostly use that.  But today I tried R 2.9.0, and the problem persists
... sometimes.  Test code is given below.  The top panel is correct, but the
bottom one is incorrect.  The problem relates to the time interval.

# test code (top panel, OK; bottom panel, incorrect times on x axis)


par(mar=c(2,2,2,1))
par(mfrow=c(2,1))
start <- as.POSIXct("2008-05-01 00:00:00", tz="UTC")
end   <- as.POSIXct("2008-05-01 00:10:00", tz="UTC")
plot(c(start, end), c(0, 1), ylab="")
mtext(paste(start, "to", end), side=3)

start <- as.POSIXct("2008-05-01 00:00:00", tz="UTC")
end   <- as.POSIXct("2008-05-01 01:10:00", tz="UTC")
plot(c(start, end), c(0, 1), ylab="")
mtext(paste(start, "to", end), side=3)




-- 
View this message in context: http://www.nabble.com/patch-for-axis.POSIXct-%28related-to-timezones%29-tp22338700p23454737.html
Sent from the R devel mailing list archive at Nabble.com.


From wdunlap at tibco.com  Sat May  9 01:16:56 2009
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 8 May 2009 16:16:56 -0700
Subject: [Rd] anyDuplicated(incomp=NA) fails
Message-ID: <77EB52C6DD32BA4D87471DCD70C8D70001297167@NA-PA-VBE03.na.tibco.com>

With today's R 2.10.0(devel) I get:

> anyDuplicated(c(1,NA,3,NA,5), incomp=NA) # expect 0
Warning: stack imbalance in 'anyDuplicated', 20 then 21
Warning: stack imbalance in '.Internal', 19 then 20
Warning: stack imbalance in '{', 17 then 18
[1] 0
> anyDuplicated(c(1,NA,3,NA,3), incomp=NA) # expect 5
Warning: stack imbalance in 'anyDuplicated', 20 then 21
Warning: stack imbalance in '.Internal', 19 then 20
Warning: stack imbalance in '{', 17 then 18
[1] 0
> anyDuplicated(c(1,NA,3,NA,3), incomp=3) # expect 4
Warning: stack imbalance in 'anyDuplicated', 20 then 21
Warning: stack imbalance in '.Internal', 19 then 20
Warning: stack imbalance in '{', 17 then 18
[1] 0
> anyDuplicated(c(1,NA,3,NA,3), incomp=c(3,NA)) # exect 0
Warning: stack imbalance in 'anyDuplicated', 20 then 21
Warning: stack imbalance in '.Internal', 19 then 20
Warning: stack imbalance in '{', 17 then 18
[1] 0
> version$svn
[1] "48493"

After applying the attached patch I get

> anyDuplicated(c(1,NA,3,NA,5), incomp=NA)
[1] 0
> anyDuplicated(c(1,NA,3,NA,3), incomp=NA)
[1] 5
> anyDuplicated(c(1,NA,3,NA,3), incomp=3)
[1] 4
> anyDuplicated(c(1,NA,3,NA,3), incomp=c(3,NA))
[1] 0

Calls to UNPROTECT() were missing an a macro definition
did nothing because there were no backslashes at the ends
of lines.  I didn't check the results very carefully.

Bill Dunlap
TIBCO Software Inc - Spotfire Division
wdunlap tibco.com 

-------------------------------------------------------

Index: unique.c
===================================================================
--- unique.c	(revision 48503)
+++ unique.c	(working copy)
@@ -462,16 +462,18 @@
     for (i = 0; i < data.M; i++) h[i] = NIL;
     if(from_last)
 	for (i = n-1; i >= 0; i--) {
-#define IS_DUPLICATED_CHECK
-	    if(isDuplicated(x, i, &data)) {
-		Rboolean isDup = TRUE;
-		for(j = 0; j < m; j++)
-		    if(data.equal(x, i, incomp, j)) {
-			isDup = FALSE; break;
-		    }
-		if(isDup)
-		    return ++i;
-		/* else continue */
+#define IS_DUPLICATED_CHECK \
+	    if(isDuplicated(x, i, &data)) { \
+		Rboolean isDup = TRUE; \
+		for(j = 0; j < m; j++) \
+		    if(data.equal(x, i, incomp, j)) { \
+			isDup = FALSE; break; \
+		    } \
+		if(isDup) { \
+		    UNPROTECT(1); \
+		    return ++i; \
+                } \
+		/* else continue */ \
 	    }
 	    IS_DUPLICATED_CHECK;
 	}
@@ -480,6 +482,7 @@
             IS_DUPLICATED_CHECK;
     }

+    UNPROTECT(1) ;
     return 0;
 }

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: unique.c.diff.txt
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090508/e8a54ebb/attachment.txt>

From chung at engr.orst.edu  Sat May  9 05:30:35 2009
From: chung at engr.orst.edu (chung at engr.orst.edu)
Date: Fri, 08 May 2009 20:30:35 -0700
Subject: [Rd] need help for open source and diagramming research
Message-ID: <20090508203035.14436usqcq67p5wk@webmail.oregonstate.edu>

Dear open source contributors,

I am Eunyoung Chung, a Masters student working with Dr. Jensen at
Oregon State University. We are currently doing a research project in
collaboration with Dr.
Truong and Ph.D student Koji Yatani at University of Toronto. Our goal
is to understand how contributors communicate and collaborate in Open
Source Software (OSS) projects, including diagramming practices.

We are seeking volunteers for a quick survey on this topic. Any person
who is actively working on a OSS project is eligible. The survey takes
approximately 10-15 minutes, and the 5 volunteers will be picked to
receive a $30 Amazon gift certificate. Your participation is anonymous
(unless you consent to have us contact you)

Here is the survey address.

https://secure.engr.oregonstate.edu/limesurvey/58564/lang-en

We really appreciate your help!


From p.dalgaard at biostat.ku.dk  Sat May  9 14:00:13 2009
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Sat, 09 May 2009 14:00:13 +0200
Subject: [Rd] unsplit list of data.frames with one column
In-Reply-To: <4A044B3D.7010506@vanderbilt.edu>
References: <4A044B3D.7010506@vanderbilt.edu>
Message-ID: <4A05704D.7080708@biostat.ku.dk>

Will Gray wrote:
> 
> Perhaps this is the intended behavior, but I discovered that unsplit 
> throws an error when it tries to set rownames of a variable that has no 
> dimension.  This occurs when unsplit is passed a list of data.frames 
> that have only a single column.
> 
> An example:
> 
> df <- data.frame(letters[seq(25)])
> fac <- rep(seq(5), 5)
> unsplit(split(df, fac), fac)
> 
> For reference, I'm using R version 2.9.0 (2009-04-17), subversion 
> revision 48333, on Ubuntu 8.10.
> 

That's a bug. The line

         x <- value[[1L]][rep(NA, len), ]

should be

         x <- value[[1L]][rep(NA, len), , drop=FALSE]


-- 
    O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
   c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
  (*) \(*) -- University of Copenhagen   Denmark      Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)              FAX: (+45) 35327907


From gavin.simpson at ucl.ac.uk  Sat May  9 14:14:16 2009
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Sat, 09 May 2009 13:14:16 +0100
Subject: [Rd] Improve aggregate.default ...?
Message-ID: <1241871256.3461.14.camel@localhost.localdomain>

Hi,

I find it a bit annoying that aggregate.default forces the returned
object to loose the 'name' of the variable aggregated, replacing it with
'x'.

A brief example:

> dat <- data.frame(A = runif(100), B = rnorm(100), 
+                   Group = gl(4, 25))
> with(dat, aggregate(A, by = list(Group = Group), FUN = mean))
  Group         x
1     1 0.6523228
2     2 0.4544317
3     3 0.4619624
4     4 0.4703156

This arises because aggregate default has:

function (x, ...) 
{
    if (is.ts(x)) 
        aggregate.ts(as.ts(x), ...)
    else aggregate.data.frame(as.data.frame(x), ...)
}

which recasts x as a data frame, but doesn't make any effort to supply a
name. Can we do a better job of supplying a useful name?

My first attempt is:

aggregate.default <- function(x, ...) {
    if (is.ts(x))
        aggregate.ts(as.ts(x), ...)
    else {
        nam <- deparse(substitute(x))
        x <- as.data.frame(x)
        names(x) <- nam
        aggregate.data.frame(x, ...)
    }
}

Which works for the brief example above:

> with(dat, aggregate(A, by = list(Group = Group), FUN = mean))
  Group         A
1     1 0.4269715
2     2 0.5479352
3     3 0.5091543
4     4 0.4926412

However, it fails make check-all because examples have relied on
returned object having 'x'. I also note that this might have the
annoying side effect of producing odd names if we use the following
incantation:

> res <- aggregate(dat$A, by = list(Group = dat$Group), FUN = mean)
> str(res)
'data.frame':	4 obs. of  2 variables:
 $ Group: Factor w/ 4 levels "1","2","3","4": 1 2 3 4
 $ dat$A: num  0.427 0.548 0.509 0.493
> res$dat$A
Error in res$dat$A : $ operator is invalid for atomic vectors
> res$`dat$A`
[1] 0.4269715 0.5479352 0.5091543 0.4926412

Is there a way of coming up with a better way to name the aggregated
variable? Would a change of this kind be something R Core would consider
making to aggregate.default if a good solution is found?

Thanks in advance,

G
-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
 Dr. Gavin Simpson             [t] +44 (0)20 7679 0522
 ECRC, UCL Geography,          [f] +44 (0)20 7679 0565
 Pearson Building,             [e] gavin.simpsonATNOSPAMucl.ac.uk
 Gower Street, London          [w] http://www.ucl.ac.uk/~ucfagls/
 UK. WC1E 6BT.                 [w] http://www.freshwaters.org.uk
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%


From ggrothendieck at gmail.com  Sat May  9 14:23:49 2009
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 9 May 2009 08:23:49 -0400
Subject: [Rd] Improve aggregate.default ...?
In-Reply-To: <1241871256.3461.14.camel@localhost.localdomain>
References: <1241871256.3461.14.camel@localhost.localdomain>
Message-ID: <971536df0905090523u2610bbe1l7f795cbbd385c9a3@mail.gmail.com>

Try this:

> aggregate(dat["A"], dat["Group"], mean)
  Group         A
1     1 0.4944810
2     2 0.4765412
3     3 0.4521068
4     4 0.4989000

On Sat, May 9, 2009 at 8:14 AM, Gavin Simpson <gavin.simpson at ucl.ac.uk> wrote:
> Hi,
>
> I find it a bit annoying that aggregate.default forces the returned
> object to loose the 'name' of the variable aggregated, replacing it with
> 'x'.
>
> A brief example:
>
>> dat <- data.frame(A = runif(100), B = rnorm(100),
> + ? ? ? ? ? ? ? ? ? Group = gl(4, 25))
>> with(dat, aggregate(A, by = list(Group = Group), FUN = mean))
> ?Group ? ? ? ? x
> 1 ? ? 1 0.6523228
> 2 ? ? 2 0.4544317
> 3 ? ? 3 0.4619624
> 4 ? ? 4 0.4703156
>
> This arises because aggregate default has:
>
> function (x, ...)
> {
> ? ?if (is.ts(x))
> ? ? ? ?aggregate.ts(as.ts(x), ...)
> ? ?else aggregate.data.frame(as.data.frame(x), ...)
> }
>
> which recasts x as a data frame, but doesn't make any effort to supply a
> name. Can we do a better job of supplying a useful name?
>
> My first attempt is:
>
> aggregate.default <- function(x, ...) {
> ? ?if (is.ts(x))
> ? ? ? ?aggregate.ts(as.ts(x), ...)
> ? ?else {
> ? ? ? ?nam <- deparse(substitute(x))
> ? ? ? ?x <- as.data.frame(x)
> ? ? ? ?names(x) <- nam
> ? ? ? ?aggregate.data.frame(x, ...)
> ? ?}
> }
>
> Which works for the brief example above:
>
>> with(dat, aggregate(A, by = list(Group = Group), FUN = mean))
> ?Group ? ? ? ? A
> 1 ? ? 1 0.4269715
> 2 ? ? 2 0.5479352
> 3 ? ? 3 0.5091543
> 4 ? ? 4 0.4926412
>
> However, it fails make check-all because examples have relied on
> returned object having 'x'. I also note that this might have the
> annoying side effect of producing odd names if we use the following
> incantation:
>
>> res <- aggregate(dat$A, by = list(Group = dat$Group), FUN = mean)
>> str(res)
> 'data.frame': ? 4 obs. of ?2 variables:
> ?$ Group: Factor w/ 4 levels "1","2","3","4": 1 2 3 4
> ?$ dat$A: num ?0.427 0.548 0.509 0.493
>> res$dat$A
> Error in res$dat$A : $ operator is invalid for atomic vectors
>> res$`dat$A`
> [1] 0.4269715 0.5479352 0.5091543 0.4926412
>
> Is there a way of coming up with a better way to name the aggregated
> variable? Would a change of this kind be something R Core would consider
> making to aggregate.default if a good solution is found?
>
> Thanks in advance,
>
> G
> --
> %~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
> ?Dr. Gavin Simpson ? ? ? ? ? ? [t] +44 (0)20 7679 0522
> ?ECRC, UCL Geography, ? ? ? ? ?[f] +44 (0)20 7679 0565
> ?Pearson Building, ? ? ? ? ? ? [e] gavin.simpsonATNOSPAMucl.ac.uk
> ?Gower Street, London ? ? ? ? ?[w] http://www.ucl.ac.uk/~ucfagls/
> ?UK. WC1E 6BT. ? ? ? ? ? ? ? ? [w] http://www.freshwaters.org.uk
> %~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From gavin.simpson at ucl.ac.uk  Sat May  9 14:55:20 2009
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Sat, 09 May 2009 13:55:20 +0100
Subject: [Rd] Improve aggregate.default ...?
In-Reply-To: <971536df0905090523u2610bbe1l7f795cbbd385c9a3@mail.gmail.com>
References: <1241871256.3461.14.camel@localhost.localdomain>
	<971536df0905090523u2610bbe1l7f795cbbd385c9a3@mail.gmail.com>
Message-ID: <1241873720.3461.26.camel@localhost.localdomain>

On Sat, 2009-05-09 at 08:23 -0400, Gabor Grothendieck wrote:
> Try this:
> 
> > aggregate(dat["A"], dat["Group"], mean)
>   Group         A
> 1     1 0.4944810
> 2     2 0.4765412
> 3     3 0.4521068
> 4     4 0.4989000

Thanks Gabor. Ideally, aggregate.default should "work" whatever indexing
one uses - here you are using the fact that a data.frame is a special
case of a list, and is not the way most help resources introduce
subsetting for data frames.

For personal use, I can use my own version of aggregate.default and as I
dislike using `$`, prefering with(), I don't run the risk of non
syntactic names being produced.

I was really looking for ideas for improving aggregate.default in
general. The solution I posted has its own infelicities...

Cheers,

G

> 
> On Sat, May 9, 2009 at 8:14 AM, Gavin Simpson <gavin.simpson at ucl.ac.uk> wrote:
> > Hi,
> >
> > I find it a bit annoying that aggregate.default forces the returned
> > object to loose the 'name' of the variable aggregated, replacing it with
> > 'x'.
> >
> > A brief example:
> >
> >> dat <- data.frame(A = runif(100), B = rnorm(100),
> > +                   Group = gl(4, 25))
> >> with(dat, aggregate(A, by = list(Group = Group), FUN = mean))
> >  Group         x
> > 1     1 0.6523228
> > 2     2 0.4544317
> > 3     3 0.4619624
> > 4     4 0.4703156
> >
> > This arises because aggregate default has:
> >
> > function (x, ...)
> > {
> >    if (is.ts(x))
> >        aggregate.ts(as.ts(x), ...)
> >    else aggregate.data.frame(as.data.frame(x), ...)
> > }
> >
> > which recasts x as a data frame, but doesn't make any effort to supply a
> > name. Can we do a better job of supplying a useful name?
> >
> > My first attempt is:
> >
> > aggregate.default <- function(x, ...) {
> >    if (is.ts(x))
> >        aggregate.ts(as.ts(x), ...)
> >    else {
> >        nam <- deparse(substitute(x))
> >        x <- as.data.frame(x)
> >        names(x) <- nam
> >        aggregate.data.frame(x, ...)
> >    }
> > }
> >
> > Which works for the brief example above:
> >
> >> with(dat, aggregate(A, by = list(Group = Group), FUN = mean))
> >  Group         A
> > 1     1 0.4269715
> > 2     2 0.5479352
> > 3     3 0.5091543
> > 4     4 0.4926412
> >
> > However, it fails make check-all because examples have relied on
> > returned object having 'x'. I also note that this might have the
> > annoying side effect of producing odd names if we use the following
> > incantation:
> >
> >> res <- aggregate(dat$A, by = list(Group = dat$Group), FUN = mean)
> >> str(res)
> > 'data.frame':   4 obs. of  2 variables:
> >  $ Group: Factor w/ 4 levels "1","2","3","4": 1 2 3 4
> >  $ dat$A: num  0.427 0.548 0.509 0.493
> >> res$dat$A
> > Error in res$dat$A : $ operator is invalid for atomic vectors
> >> res$`dat$A`
> > [1] 0.4269715 0.5479352 0.5091543 0.4926412
> >
> > Is there a way of coming up with a better way to name the aggregated
> > variable? Would a change of this kind be something R Core would consider
> > making to aggregate.default if a good solution is found?
> >
> > Thanks in advance,
> >
> > G
> > --
> > %~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
> >  Dr. Gavin Simpson             [t] +44 (0)20 7679 0522
> >  ECRC, UCL Geography,          [f] +44 (0)20 7679 0565
> >  Pearson Building,             [e] gavin.simpsonATNOSPAMucl.ac.uk
> >  Gower Street, London          [w] http://www.ucl.ac.uk/~ucfagls/
> >  UK. WC1E 6BT.                 [w] http://www.freshwaters.org.uk
> > %~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
 Dr. Gavin Simpson             [t] +44 (0)20 7679 0522
 ECRC, UCL Geography,          [f] +44 (0)20 7679 0565
 Pearson Building,             [e] gavin.simpsonATNOSPAMucl.ac.uk
 Gower Street, London          [w] http://www.ucl.ac.uk/~ucfagls/
 UK. WC1E 6BT.                 [w] http://www.freshwaters.org.uk
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%


From info at aghmed.fsnet.co.uk  Sat May  9 15:54:40 2009
From: info at aghmed.fsnet.co.uk (Michael Dewey)
Date: Sat, 09 May 2009 14:54:40 +0100
Subject: [Rd] suggestion for extending ?as.factor
In-Reply-To: <18948.12553.265256.981657@lynne.math.ethz.ch>
References: <20090503203204.GB29507@cs.cas.cz>
	<18942.43500.862186.878365@lynne.math.ethz.ch>
	<49FEEED1.8000808@biostat.ku.dk>
	<18943.3144.768738.188706@lynne.math.ethz.ch>
	<20090504163403.GA10640@cs.cas.cz> <49FF25A6.3070907@biostat.ku.dk>
	<18943.64094.648164.476070@lynne.math.ethz.ch>
	<18945.19798.782710.936788@lynne.math.ethz.ch>
	<20090508090155.GA18486@cs.cas.cz>
	<18948.12553.265256.981657@lynne.math.ethz.ch>
Message-ID: <Zen-1M2n0t-00083G-0T@smarthost03.mail.zen.net.uk>

At 14:18 08/05/2009, Martin Maechler wrote:

> >>>>> "PS" == Petr Savicky <savicky at cs.cas.cz>
> >>>>>     on Fri, 8 May 2009 11:01:55 +0200 writes:

Somewhere below Martin asks for alternatives from list readers. I do 
not have alternatives, but I do have two comments, one immediately 
below this, the other embedded in-line.

This whole thread reminds me just why I have spent the best part of a 
decade climbing the virtual Matterhorn called 'Learning R' and why it 
is such a pleasure to use. It is the fact that somebody, somewhere 
cares enough about consistency, usability and accuracy to devote 
hours to getting even obscure details just right.


>     PS> On Wed, May 06, 2009 at 10:41:58AM +0200, Martin Maechler wrote:
>     PD> I think that the real issue is that we actually do want almost-equal
>     PD> numbers to be folded together.
>     >>
>     >> yes, this now (revision 48469) will happen by default, 
> using  signif(x, 15)
>     >> where '15' is the default for the new optional argument 'digitsLabels'
>     >> {better argument name? (but must nost start with 'label')}
>
>     PS> Let me analyze the current behavior of factor(x) for 
> numeric x with missing(levels)
>     PS> and missing(labels). In this situation, levels are computed 
> as sort(unique(x))
>     PS> from possibly transformed x. Then, labels are constructed 
> by a conversion of the
>     PS> levels to strings.
>
>     PS> I understand the current (R 2.10.0, 2009-05-07 r48492) 
> behavior as follows.
>
>     PS> If keepUnique is FALSE (the default), then
>     PS> - values x are transformed by signif(x, digitsLabels)
>     PS> - labels are computed using as.character(levels)
>     PS> - digitsLabels defaults to 15, but may be set to any integer value
>
>     PS> If keepUnique is TRUE, then
>     PS> - values x are preserved
>     PS> - labels are computed using sprintf("%.*g", digitsLabels, levels)
>     PS> - digitsLabels defaults to 17, but may be set to any integer value
>
>(in theory; in practice, I think I've suggested somewhere that
>  it should be  >= 17;  but see below.)
>
>Your summary seems correct to me.
>
>     PS> There are several situations, when this approach produces 
> duplicated levels.
>     PS> Besides the one described in my previous email, there are also others
>     PS> factor(c(0.3, 0.1+0.2), keepUnique=TRUE, digitsLabels=15)
>
>yes, but this is not much sensical; I've already contemplated
>to produce a warning in such cases, something like
>
>    if(keepUnique && digitsLabels < 17)
>      warning(gettextf(
>      "'digitsLabels = %d' is typically too small when 'keepUnique' is true",
>      digitsLabels))
>
>
>     PS> factor(1 + 0:5 * 1e-16, digitsLabels=17)
>
>again, this does not make much sense; but why disallow the useR
>to shoot into his foot?

I agree. As a useR I do not want to be stopped from doing anything. I 
would appreciate a warning just before I shoot myself in the foot and 
I definitely want one if it looks like I am going to aim for my head.

>     PS> I would like to suggest a modification. It eliminates most 
> of the cases, where
>     PS> we get duplicated levels. It would eliminate all such 
> cases, if the function
>     PS> signif() works as expected. Unfortunately, if signif() 
> works as it does in the
>     PS> current versions of R, we still get duplicated levels.
>
>     PS> The suggested modification is as follows.
>
>     PS> If keepUnique is FALSE (the default), then
>     PS> - values x are transformed by signif(x, digitsLabels)
>     PS> - labels are computed using sprintf("%.*g", digitsLabels, levels)
>     PS> - digitsLabels defaults to 15, but may be set to any integer value
>
>I tend like this change, given -- as you found yesterday -- that
>as.character() is not even preserving 15 digits.
>OTOH,  as.character() has been in use for a very long history of
>S (and R), whereas using sprintf() is not back compatible with
>it and actually depends on the LIBC implementation of the system-sprintf.
>For that reason as.character() would be preferable.
>Hmm....
>
>     PS> If keepUnique is TRUE, then
>     PS> - values x are preserved
>     PS> - labels are computed using sprintf("%.*g", 17, levels)
>     PS> - digitsLabels is ignored
>
>I had originally planned to do exactly the above.
>However, e.g.,  digitsLabels = 18  may be desired in some cases,
>and that's why I also left the possibility to apply it in the
>keepUnique case.
>
>
>     PS> Arguments for the modification are the following.
>
>     PS> 1. If keepUnique is FALSE, then computing labels using 
> as.character() leads
>     PS> to duplicated labels as demonstrated in my previous email. 
> So, i suggest to
>     PS> use sprintf("%.*g", digitsLabels, levels) instead of as.character().
>
>{as said above, that seems sensible, though unfurtunately quite
>  a bit less back-compatible!}
>
>     PS> 2. If keepUnique is TRUE and we allow digitsLabels less 
> than 17, then we get
>     PS> duplicated labels. So, i suggest to force digitsLabels=17, 
> if keepUnique=TRUE.
>
>     PS> If signif(,digitsLabels) works as expected, than the above 
> approach should not
>     PS> produce duplicated labels. Unfortunately, this is not the case.
>     PS> There are numbers, which remain different in signif(x, 16), 
> but are mapped
>     PS> to the same string in sprintf("%.*g", 16, x). Examples of 
> this kind may be
>     PS> found using the script
>
>     PS> for (i in 1:50) {
>     PS> x <- 10^runif(1, 38, 50)
>     PS> y <- x * (1 + 0:500 * 1e-16)
>     PS> y <- unique(signif(y, 16))
>     PS> z <- unique(sprintf("%.16g", y))
>     PS> stopifnot(length(y) == length(z))
>     PS> }
>
>     PS> This script is tested on Intel default arithmetic and on 
> Intel with SSE.
>
>     PS> Perhaps, digitsLabels = 16 could be forbidden, if 
> keepUnique is FALSE.
>
>     PS> Unfortunately, a similar problem occurs even for 
> digitsLabels = 15, although for
>     PS> much larger numbers.
>
>     PS> for (i in 1:200) {
>     PS> x <- 10^runif(1, 250, 300)
>     PS> y <- x * (1 + 0:500 * 1e-16)
>     PS> y <- unique(signif(y, 15))
>     PS> z <- unique(sprintf("%.15g", y))
>     PS> stopifnot(length(y) == length(z))
>     PS> }
>
>     PS> This script finds collisions, if SSE is enabled, on two
>     PS> Intel computers, where i did the test. Without SSE, it
>     PS> finds collisions only on one of them. May be, it depends
>     PS> also on the compiler, which is different.
>
>probably rather on the exact implementation of the underlying C
>library ("LIBC").
>
>Thank you, Petr, for your investigations.
>We all see that the simple requirement of
>    *no more duplicate factor levels !*
>leads to considerable programming efforts for the case of
>factor(<numeric>, .).
>
>One prominent R-devel reader actually proposed to me in private,
>that  factor(<numeric>, .)  should give a *warning* by default,
>since he considered it unsafe practice.
>
>Note that your last investigations show that your (two) proposed
>changes actually do *not* solve the problem entirely;
>further note that (at least inside the sources), we now say that
>duplicate levels will not just signal a warning, but an error in
>the future.
>As long as we don't want to allow  factor(<numeric>) to fail --rarely --
>I think (and that actually has been a recurring daunting thought
>for quite a few days) that we probably need an
>extra step of checking for duplicate levels, and if we find
>some, recode "everything". This will blow up the body of the
>factor() function even more.
>
>What alternatives do you (all R-devel readers!) see?
>
>Martin
>
>______________________________________________
>R-devel at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-devel

Michael Dewey
http://www.aghmed.fsnet.co.uk


From maechler at stat.math.ethz.ch  Sat May  9 17:24:02 2009
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Sat, 9 May 2009 17:24:02 +0200
Subject: [Rd] anyDuplicated(incomp=NA) fails
In-Reply-To: <77EB52C6DD32BA4D87471DCD70C8D70001297167@NA-PA-VBE03.na.tibco.com>
References: <77EB52C6DD32BA4D87471DCD70C8D70001297167@NA-PA-VBE03.na.tibco.com>
Message-ID: <18949.40978.656999.160462@cmath-5.math.ethz.ch>

>>>>> William Dunlap <wdunlap at tibco.com>
>>>>>     on Fri, 8 May 2009 16:16:56 -0700 writes:

    > With today's R 2.10.0(devel) I get:
    >> anyDuplicated(c(1,NA,3,NA,5), incomp=NA) # expect 0
    > Warning: stack imbalance in 'anyDuplicated', 20 then 21
    > Warning: stack imbalance in '.Internal', 19 then 20
    > Warning: stack imbalance in '{', 17 then 18 [1] 0
    >> anyDuplicated(c(1,NA,3,NA,3), incomp=NA) # expect 5
    > Warning: stack imbalance in 'anyDuplicated', 20 then 21
    > Warning: stack imbalance in '.Internal', 19 then 20
    > Warning: stack imbalance in '{', 17 then 18 [1] 0
    >> anyDuplicated(c(1,NA,3,NA,3), incomp=3) # expect 4
    > Warning: stack imbalance in 'anyDuplicated', 20 then 21
    > Warning: stack imbalance in '.Internal', 19 then 20
    > Warning: stack imbalance in '{', 17 then 18 [1] 0
    >> anyDuplicated(c(1,NA,3,NA,3), incomp=c(3,NA)) # exect 0
    > Warning: stack imbalance in 'anyDuplicated', 20 then 21
    > Warning: stack imbalance in '.Internal', 19 then 20
    > Warning: stack imbalance in '{', 17 then 18 [1] 0
    >> version$svn
    > [1] "48493"

    > After applying the attached patch I get

    >> anyDuplicated(c(1,NA,3,NA,5), incomp=NA)
    > [1] 0
    >> anyDuplicated(c(1,NA,3,NA,3), incomp=NA)
    > [1] 5
    >> anyDuplicated(c(1,NA,3,NA,3), incomp=3)
    > [1] 4
    >> anyDuplicated(c(1,NA,3,NA,3), incomp=c(3,NA))
    > [1] 0

    > Calls to UNPROTECT() were missing an a macro definition
    > did nothing because there were no backslashes at the ends
    > of lines.  I didn't check the results very carefully.

Thank you, very much Bill!   Somewhat embarrassing...
Note that the patch "in theory" needs to be modified to only
UNPROTECT() when PROTECT() was called, which "in practice" is
always ;-), but in any case, I've slightly modified your patch
and also applied to R-patched.

Thanks once more,
Martin

    > Bill Dunlap TIBCO Software Inc - Spotfire Division wdunlap
    > tibco.com


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Sat May  9 18:47:40 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Sat, 09 May 2009 18:47:40 +0200
Subject: [Rd] unsplit list of data.frames with one column
In-Reply-To: <4A05704D.7080708@biostat.ku.dk>
References: <4A044B3D.7010506@vanderbilt.edu> <4A05704D.7080708@biostat.ku.dk>
Message-ID: <4A05B3AC.8060104@idi.ntnu.no>

Peter Dalgaard wrote:
> Will Gray wrote:
>>
>> Perhaps this is the intended behavior, but I discovered that unsplit
>> throws an error when it tries to set rownames of a variable that has
>> no dimension.  This occurs when unsplit is passed a list of
>> data.frames that have only a single column.
>>
>> An example:
>>
>> df <- data.frame(letters[seq(25)])
>> fac <- rep(seq(5), 5)
>> unsplit(split(df, fac), fac)
>>
>> For reference, I'm using R version 2.9.0 (2009-04-17), subversion
>> revision 48333, on Ubuntu 8.10.
>>
>
> That's a bug. The line
>
>         x <- value[[1L]][rep(NA, len), ]
>
> should be
>
>         x <- value[[1L]][rep(NA, len), , drop=FALSE]
>

looks like someone got caught by the drop=TRUE design...?

vQ


From maechler at stat.math.ethz.ch  Sat May  9 22:55:17 2009
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Sat, 9 May 2009 22:55:17 +0200
Subject: [Rd] suggestion for extending ?as.factor
In-Reply-To: <20090508161056.GB6692@cs.cas.cz>
References: <18942.43500.862186.878365@lynne.math.ethz.ch>
	<49FEEED1.8000808@biostat.ku.dk>
	<18943.3144.768738.188706@lynne.math.ethz.ch>
	<20090504163403.GA10640@cs.cas.cz> <49FF25A6.3070907@biostat.ku.dk>
	<18943.64094.648164.476070@lynne.math.ethz.ch>
	<18945.19798.782710.936788@lynne.math.ethz.ch>
	<20090508090155.GA18486@cs.cas.cz>
	<18948.12553.265256.981657@lynne.math.ethz.ch>
	<20090508151448.GA6692@cs.cas.cz> <20090508161056.GB6692@cs.cas.cz>
Message-ID: <18949.60853.709036.388905@cmath-5.math.ethz.ch>

>>>>> "PS" == Petr Savicky <savicky at cs.cas.cz>
>>>>>     on Fri, 8 May 2009 18:10:56 +0200 writes:

    PS> On Fri, May 08, 2009 at 05:14:48PM +0200, Petr Savicky wrote:
    >> Let me suggest to consider the following modification, where match() is done
    >> on the strings, not on the original values.
    >> levels <- unique(as.character(sort(unique(x))))
    >> x <- as.character(x)
    >> f <- match(x, levels)

    PS> An alternative solution is

    PS> ind <- order(x)
    PS> x <- as.character(x) # or any other conversion to character
    PS> levels <- unique(x[ind]) # get unique levels ordered by the original values
    PS> f <- match(x, levels)

(slightly but not much more complicated though).

Yes, indeed that brings us back to (something like) the original
"use  factor(format(x))  ..."  suggestion which would have been
fine if there hadn't been the issue of ordering,
exactly what you've addressed before.


    PS> The advantage of this over the suggestion from my previous email is that
    PS> the string conversion is applied only once. The conversion need not be only
    PS> as.character(). There may be other choices specified by a parametr. I have
    PS> strong objections against the existing implementation of as.character(),
    PS> but still i think that as.character() should be the default for factor()
    PS> for the sake of consistency of the R language.

The biggest advantage to reverting to something simple like
that, would be that it is really simple.

My first tests with (a variation of) the above indicate
favorable results.  More on this on Monday.
If'd revert to such a solution,
we'd have to get back to Peter's point about the issue that
he'd think  table(.) should be more tolerant than as.character()
about "almost equality".
For compatibility reasons, we could also return back to the
reasoning that useR should use {something like}
    table(signif(x, 14)) 
instead of
    table(x) 
for numeric x in "typical" cases.

Martin


From dutangc at gmail.com  Sun May 10 11:52:17 2009
From: dutangc at gmail.com (Christophe Dutang)
Date: Sun, 10 May 2009 11:52:17 +0200
Subject: [Rd] Vignettes with missing or empty \VignetteIndexEntry:
Message-ID: <CA867439-9FA3-4D44-A5AB-AFFB49F0F5D1@gmail.com>

Hi,

I have a problem when checking the package 'probdistr' (on probability  
distributions).
I got this warning

* checking index information ... WARNING
Vignettes with missing or empty \VignetteIndexEntry:
  [1] "probdistr-chi"        "probdistr-contextra"  "probdistr-discrete"
  [4] "probdistr-discrextra" "probdistr-exp"        "probdistr- 
finitesupp"
  [7] "probdistr-gaussian"   "probdistr-general"    "probdistr-gumbel"
[10] "probdistr-intro"      "probdistr-logis"      "probdistr-math"
[13] "probdistr-misc"       "probdistr-mult"       "probdistr-pareto"
[16] "probdistr-student"
See the information on INDEX files and package subdirectories in the
chapter 'Creating R packages' of the 'Writing R Extensions' manual.

The warning tells me \VignetteIndexEntry is missing however there is  
one in probdistr-main.Rnw (Sweave file calling all other files via  
\SweaveInput{probdistr-XXXXX}). Let us note this file is not listed in  
the above files...

But the build is ok

* checking for file 'pkg/DESCRIPTION' ... OK
* preparing 'pkg':
* checking DESCRIPTION meta-information ... OK
* installing the package to re-build vignettes
* Installing *source* package ?probdistr? ...
** R
** inst
** help
*** installing help indices
  >>> Building/Updating help pages for package 'probdistr'
      Formats: text html latex example
   codeforplot                       text    html    latex   example
** building package indices ...
* DONE (probdistr)
* creating vignettes ... OK
* removing junk files
* checking for LF line-endings in source and make files
* checking for empty or unneeded directories
* building 'probdistr_1.00.tar.gz'

Does someone have an idea about this?

Thanks in advance

Christophe

PS : files are available on R-forge

--
Christophe Dutang
Ph. D. student at ISFA, Lyon, France
website: http://dutangc.free.fr


From dutangc at gmail.com  Sun May 10 12:08:15 2009
From: dutangc at gmail.com (Christophe Dutang)
Date: Sun, 10 May 2009 12:08:15 +0200
Subject: [Rd] Fwd: Vignettes with missing or empty \VignetteIndexEntry:
References: <CA867439-9FA3-4D44-A5AB-AFFB49F0F5D1@gmail.com>
Message-ID: <5023232F-56BB-493B-AB81-E4DE62126EB3@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090510/cefb5db0/attachment.pl>

From savicky at cs.cas.cz  Sun May 10 13:52:53 2009
From: savicky at cs.cas.cz (Petr Savicky)
Date: Sun, 10 May 2009 13:52:53 +0200
Subject: [Rd] suggestion for extending ?as.factor
In-Reply-To: <18949.60853.709036.388905@cmath-5.math.ethz.ch>
References: <18943.3144.768738.188706@lynne.math.ethz.ch>
	<20090504163403.GA10640@cs.cas.cz> <49FF25A6.3070907@biostat.ku.dk>
	<18943.64094.648164.476070@lynne.math.ethz.ch>
	<18945.19798.782710.936788@lynne.math.ethz.ch>
	<20090508090155.GA18486@cs.cas.cz>
	<18948.12553.265256.981657@lynne.math.ethz.ch>
	<20090508151448.GA6692@cs.cas.cz> <20090508161056.GB6692@cs.cas.cz>
	<18949.60853.709036.388905@cmath-5.math.ethz.ch>
Message-ID: <20090510115253.GA26160@cs.cas.cz>

On Sat, May 09, 2009 at 10:55:17PM +0200, Martin Maechler wrote:
[...]
> If'd revert to such a solution,
> we'd have to get back to Peter's point about the issue that
> he'd think  table(.) should be more tolerant than as.character()
> about "almost equality".
> For compatibility reasons, we could also return back to the
> reasoning that useR should use {something like}
>     table(signif(x, 14)) 
> instead of
>     table(x) 
> for numeric x in "typical" cases.

In the released versions 2.8.1 and 2.9.0, function factor() satisfies
  identical(as.character(factor(x)), as.character(x))    (*)
for all numeric x. This follows from the code (levels are computed by
as.character() from unmodified input values) and may be verified
even for the problematic cases, for example
  x <- (0.3 + 2e-16 * c(-2,-1,1,2))
  factor(x)
  # [1] 0.300000000000000 0.3               0.3               0.300000000000000
  # Levels: 0.300000000000000 0.3 0.3 0.300000000000000
  as.character(x)
  # [1] "0.300000000000000" "0.3"               "0.3"              
  # [4] "0.300000000000000"
  identical(as.character(factor(x)), as.character(x))
  # [1] TRUE

In my opinion, it is reasonable to require that (*) be preserved also in future
versions of R.

Function as.character(x) has disadvantages. Besides of the platform dependence,
it also does not always perform rounding needed to eliminate FP errors. Usually,
as.character(x) rounds to at most 15 digits, so, we get, for example
  as.character(0.1 + 0.2) # [1] "0.3"
as required. However, there are also exceptions, for example
  as.character(1e19 + 1e5) # [1] "10000000000000100352"

Here, the number is printed exactly, so the resulting string contains the FP error
caused by the fact that 1e19 + 1e5 has more than 53 significant digits in binary
representation, namely 59.

  binary representation of 1e19 + 1e5 is
  1000101011000111001000110000010010001001111010011000011010100000

  binary representation of 10000000000000100352 is
  1000101011000111001000110000010010001001111010011000100000000000

However, as.character(x) seems to do enough rounding for most purposes, otherwise
it would not be suitable as the basic numeric to character conversion. If table() needs
factor() with a different conversion than as.character(x), it may be done explicitly
as discussed by Martin above.

So, i suggest to use as.character() as the default conversion in factor(), so that 
  identical(as.character(factor(x)), as.character(x))
is satisfied for the default usage of factor().

Of course, i appreciate, if factor() has parameters, which allow better control
of the underlying conversion, as it is done in the current development versions.

Petr.


From saptarshi.guha at gmail.com  Sun May 10 17:49:24 2009
From: saptarshi.guha at gmail.com (Saptarshi Guha)
Date: Sun, 10 May 2009 11:49:24 -0400
Subject: [Rd] In C, a fast way to slice a vector?
Message-ID: <1e7471d50905100849w75e5d388p2413e8c18b3821bd@mail.gmail.com>

Hello,
Suppose in the following code,
PROTECT(sr = R_tryEval( .... ))

sr is a RAWSXP vector. I wish to return another RAWSXP starting at
position 13 onwards (base=0).

I could create another RAWSXP of the correct length and then memcpy
the required bytes and length to this new one.

However is there a more efficient method?

Regards
Saptarshi Guha


From paboyoun at fhcrc.org  Mon May 11 06:37:42 2009
From: paboyoun at fhcrc.org (Patrick Aboyoun)
Date: Sun, 10 May 2009 21:37:42 -0700
Subject: [Rd] In C, a fast way to slice a vector?
In-Reply-To: <1e7471d50905100849w75e5d388p2413e8c18b3821bd@mail.gmail.com>
References: <1e7471d50905100849w75e5d388p2413e8c18b3821bd@mail.gmail.com>
Message-ID: <20090510213742.tax0sr9bksw8kw8w@webmail.fhcrc.org>

Saptarshi,
I know of two alternatives you can use to do fast extraction of  
consecutive subsequences of a vector:

1) Fast copy:  The method you mentioned of creating a memcpy'd vector
2) Pointer management: Creating an externalptr object in R and manage  
the start and end of your data

If you are looking for a prototyping environment to try, I recommend  
using the IRanges and Biostrings packages from the Bioconductor  
project. The IRanges package contains a function called subseq for  
performing 1) on all basic vector types (raw, logical, integer, etc.)  
and Biostrings package contains a subseq method on an externalptr  
based class that implements 2.

I was going to lobby R core members quietly about adding something  
akin to subseq from IRanges into base R since it is extremely useful  
for all long vectors and could replace all a:b calls with a <= b in R  
code, but this publicity can't hurt.

Here is an example:

> source("http://bioconductor.org/biocLite.R")
> biocLite(c("IRanges", "Biostrings"))
<< download output omitted >>
> suppressMessages(library(Biostrings))
> x <- rep(charToRaw("a"), 1e7)
> y <- BString(rawToChar(x))
> suppressMessages(library(Biostrings))
> x <- rep(charToRaw("a"), 1e7)
> y <- BString(rawToChar(x))
> system.time(x[13:1e7])
    user  system elapsed
   0.304   0.073   0.378
> system.time(subseq(x, 13))
    user  system elapsed
   0.011   0.007   0.019
> system.time(subseq(y, 13))
    user  system elapsed
   0.003   0.000   0.004
> identical(x[13:1e7], subseq(x, 13))
[1] TRUE
> identical(x[13:1e7], charToRaw(as.character(subseq(y, 13))))
[1] TRUE
> sessionInfo()
R version 2.10.0 Under development (unstable) (2009-05-08 r48504)
i386-apple-darwin9.6.0

locale:
[1] en_US.UTF-8/en_US.UTF-8/C/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] Biostrings_2.13.5 IRanges_1.3.5

loaded via a namespace (and not attached):
[1] Biobase_2.5.2



Quoting Saptarshi Guha <saptarshi.guha at gmail.com>:

> Hello,
> Suppose in the following code,
> PROTECT(sr = R_tryEval( .... ))
>
> sr is a RAWSXP vector. I wish to return another RAWSXP starting at
> position 13 onwards (base=0).
>
> I could create another RAWSXP of the correct length and then memcpy
> the required bytes and length to this new one.
>
> However is there a more efficient method?
>
> Regards
> Saptarshi Guha
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From dsstoffer at gmail.com  Sat May  9 22:38:19 2009
From: dsstoffer at gmail.com (David Stoffer)
Date: Sat, 9 May 2009 13:38:19 -0700 (PDT)
Subject: [Rd] arima
In-Reply-To: <49EF2D17.9060709@uqam.ca>
References: <49EF2D17.9060709@uqam.ca>
Message-ID: <23464456.post@talk.nabble.com>


Pierre-  I wonder how many people have to submit this concern before someone
takes care of the problem.  I may have been the first to point this out
because I got a reply from an R core member that was rude, to say the least.
Now there are no responses to this query. I set up a page to keep track of R
problems with time series ... spread the word:
http://www.stat.pitt.edu/stoffer/tsa2/Rissues.htm .  You will also find some
fixes there, and you will  see that I point out some inconsistencies [e.g.,
if you use ar(), the term intercept is used differently than in arima()]. 
Unfortunately, that won't help with the fGarch problem - you should write
the maintainers: Rmetrics-core at r-project.org.






Pierre Chauss? wrote:
> 
> Hi,
> 
> I have a suggestion for the fonction arima and arima0. I think you 
> should not call the constant an intercept because it creates confusion.  
> It is not really an intercept but a mean. For an AR(1) the intercept mu 
> should be defined as:
> 
> X(t)=mu + phi X(t-1) + e(t)
> 
> What you call intercept mu is rather defined as
> 
> (X(t)-mu) = phi (X(t-1)-mu)) + e(t)
> 
> which is not a common way to define an intercept. There is an error in 
> the fGarch's predict() because of that. I think you should just be more 
> explicit.
> 
> thank you
> 
> Pierre Chauss?
> economics department
> UQ?M
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


-----
The power of accurate observation is commonly called cynicism 
by those who have not got it.  George Bernard Shaw
-- 
View this message in context: http://www.nabble.com/arima-tp23179485p23464456.html
Sent from the R devel mailing list archive at Nabble.com.


From Kurt.Hornik at wu.ac.at  Mon May 11 15:10:04 2009
From: Kurt.Hornik at wu.ac.at (Kurt Hornik)
Date: Mon, 11 May 2009 15:10:04 +0200
Subject: [Rd] Vignettes with missing or empty \VignetteIndexEntry:
In-Reply-To: <CA867439-9FA3-4D44-A5AB-AFFB49F0F5D1@gmail.com>
References: <CA867439-9FA3-4D44-A5AB-AFFB49F0F5D1@gmail.com>
Message-ID: <18952.9132.66301.808260@fangorn.hornik.net>

>>>>> Christophe Dutang writes:

> Hi,
> I have a problem when checking the package 'probdistr' (on probability  
> distributions).
> I got this warning

> * checking index information ... WARNING
> Vignettes with missing or empty \VignetteIndexEntry:
>   [1] "probdistr-chi"        "probdistr-contextra"  "probdistr-discrete"
>   [4] "probdistr-discrextra" "probdistr-exp"        "probdistr- 
> finitesupp"
>   [7] "probdistr-gaussian"   "probdistr-general"    "probdistr-gumbel"
> [10] "probdistr-intro"      "probdistr-logis"      "probdistr-math"
> [13] "probdistr-misc"       "probdistr-mult"       "probdistr-pareto"
> [16] "probdistr-student"
> See the information on INDEX files and package subdirectories in the
> chapter 'Creating R packages' of the 'Writing R Extensions' manual.

> The warning tells me \VignetteIndexEntry is missing however there is  
> one in probdistr-main.Rnw (Sweave file calling all other files via  
> \SweaveInput{probdistr-XXXXX}). Let us note this file is not listed in  
> the above files...

> But the build is ok

> * checking for file 'pkg/DESCRIPTION' ... OK
> * preparing 'pkg':
> * checking DESCRIPTION meta-information ... OK
> * installing the package to re-build vignettes
> * Installing *source* package ?probdistr? ...
> ** R
> ** inst
> ** help
> *** installing help indices
>>>> Building/Updating help pages for package 'probdistr'
>       Formats: text html latex example
>    codeforplot                       text    html    latex   example
> ** building package indices ...
> * DONE (probdistr)
> * creating vignettes ... OK
> * removing junk files
> * checking for LF line-endings in source and make files
> * checking for empty or unneeded directories
> * building 'probdistr_1.00.tar.gz'

> Does someone have an idea about this?

Sure.  The QC tools have no idea about \SweaveInput, and think that each
.Rnw should have a \VignetteIndexEntry.

-k

> Thanks in advance

> Christophe

> PS : files are available on R-forge

> --
> Christophe Dutang
> Ph. D. student at ISFA, Lyon, France
> website: http://dutangc.free.fr

> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From saptarshi.guha at gmail.com  Mon May 11 16:25:50 2009
From: saptarshi.guha at gmail.com (Saptarshi Guha)
Date: Mon, 11 May 2009 10:25:50 -0400
Subject: [Rd] In C, a fast way to slice a vector?
In-Reply-To: <20090510213742.tax0sr9bksw8kw8w@webmail.fhcrc.org>
References: <1e7471d50905100849w75e5d388p2413e8c18b3821bd@mail.gmail.com>
	<20090510213742.tax0sr9bksw8kw8w@webmail.fhcrc.org>
Message-ID: <1e7471d50905110725v64799ff6jbe267f456cf0f3e0@mail.gmail.com>

Impressive stuff. Nice to see people giving some though to this.
I will explore the packages you mentioned.

Thank you

Saptarshi Guha



On Mon, May 11, 2009 at 12:37 AM, Patrick Aboyoun <paboyoun at fhcrc.org> wrote:
> Saptarshi,
> I know of two alternatives you can use to do fast extraction of consecutive
> subsequences of a vector:
>
> 1) Fast copy: ?The method you mentioned of creating a memcpy'd vector
> 2) Pointer management: Creating an externalptr object in R and manage the
> start and end of your data
>
> If you are looking for a prototyping environment to try, I recommend using
> the IRanges and Biostrings packages from the Bioconductor project. The
> IRanges package contains a function called subseq for performing 1) on all
> basic vector types (raw, logical, integer, etc.) and Biostrings package
> contains a subseq method on an externalptr based class that implements 2.
>
> I was going to lobby R core members quietly about adding something akin to
> subseq from IRanges into base R since it is extremely useful for all long
> vectors and could replace all a:b calls with a <= b in R code, but this
> publicity can't hurt.
>
> Here is an example:
>
>> source("http://bioconductor.org/biocLite.R")
>> biocLite(c("IRanges", "Biostrings"))
>
> << download output omitted >>
>>
>> suppressMessages(library(Biostrings))
>> x <- rep(charToRaw("a"), 1e7)
>> y <- BString(rawToChar(x))
>> suppressMessages(library(Biostrings))
>> x <- rep(charToRaw("a"), 1e7)
>> y <- BString(rawToChar(x))
>> system.time(x[13:1e7])
>
> ? user ?system elapsed
> ?0.304 ? 0.073 ? 0.378
>>
>> system.time(subseq(x, 13))
>
> ? user ?system elapsed
> ?0.011 ? 0.007 ? 0.019
>>
>> system.time(subseq(y, 13))
>
> ? user ?system elapsed
> ?0.003 ? 0.000 ? 0.004
>>
>> identical(x[13:1e7], subseq(x, 13))
>
> [1] TRUE
>>
>> identical(x[13:1e7], charToRaw(as.character(subseq(y, 13))))
>
> [1] TRUE
>>
>> sessionInfo()
>
> R version 2.10.0 Under development (unstable) (2009-05-08 r48504)
> i386-apple-darwin9.6.0
>
> locale:
> [1] en_US.UTF-8/en_US.UTF-8/C/C/en_US.UTF-8/en_US.UTF-8
>
> attached base packages:
> [1] stats ? ? graphics ?grDevices utils ? ? datasets ?methods ? base
>
> other attached packages:
> [1] Biostrings_2.13.5 IRanges_1.3.5
>
> loaded via a namespace (and not attached):
> [1] Biobase_2.5.2
>
>
>
> Quoting Saptarshi Guha <saptarshi.guha at gmail.com>:
>
>> Hello,
>> Suppose in the following code,
>> PROTECT(sr = R_tryEval( .... ))
>>
>> sr is a RAWSXP vector. I wish to return another RAWSXP starting at
>> position 13 onwards (base=0).
>>
>> I could create another RAWSXP of the correct length and then memcpy
>> the required bytes and length to this new one.
>>
>> However is there a more efficient method?
>>
>> Regards
>> Saptarshi Guha
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
>
>
>


From maechler at stat.math.ethz.ch  Mon May 11 17:06:38 2009
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 11 May 2009 17:06:38 +0200
Subject: [Rd] suggestion for extending ?as.factor
In-Reply-To: <20090510115253.GA26160@cs.cas.cz>
References: <18943.3144.768738.188706@lynne.math.ethz.ch>
	<20090504163403.GA10640@cs.cas.cz> <49FF25A6.3070907@biostat.ku.dk>
	<18943.64094.648164.476070@lynne.math.ethz.ch>
	<18945.19798.782710.936788@lynne.math.ethz.ch>
	<20090508090155.GA18486@cs.cas.cz>
	<18948.12553.265256.981657@lynne.math.ethz.ch>
	<20090508151448.GA6692@cs.cas.cz> <20090508161056.GB6692@cs.cas.cz>
	<18949.60853.709036.388905@cmath-5.math.ethz.ch>
	<20090510115253.GA26160@cs.cas.cz>
Message-ID: <18952.16126.640019.723302@lynne.math.ethz.ch>

>>>>> "PS" == Petr Savicky <savicky at cs.cas.cz>
>>>>>     on Sun, 10 May 2009 13:52:53 +0200 writes:

    PS> On Sat, May 09, 2009 at 10:55:17PM +0200, Martin Maechler wrote:
    PS> [...]
    >> If'd revert to such a solution,
    >> we'd have to get back to Peter's point about the issue that
    >> he'd think  table(.) should be more tolerant than as.character()
    >> about "almost equality".
    >> For compatibility reasons, we could also return back to the
    >> reasoning that useR should use {something like}
    >> table(signif(x, 14)) 
    >> instead of
    >> table(x) 
    >> for numeric x in "typical" cases.

    PS> In the released versions 2.8.1 and 2.9.0, function factor() satisfies
    PS> identical(as.character(factor(x)), as.character(x))    (*)
    PS> for all numeric x. This follows from the code (levels are computed by
    PS> as.character() from unmodified input values) and may be verified
    PS> even for the problematic cases, for example
    PS> x <- (0.3 + 2e-16 * c(-2,-1,1,2))
    PS> factor(x)
    PS> # [1] 0.300000000000000 0.3  0.3  0.300000000000000
    PS> # Levels: 0.300000000000000 0.3 0.3 0.300000000000000
    PS> as.character(x)
    PS> # [1] "0.300000000000000" "0.3"               "0.3"              
    PS> # [4] "0.300000000000000"
    PS> identical(as.character(factor(x)), as.character(x))
    PS> # [1] TRUE

    PS> In my opinion, it is reasonable to require that (*) be
    PS> preserved also in future versions of R.

    PS> Function as.character(x) has disadvantages. Besides of
    PS> the platform dependence, it also does not always perform
    PS> rounding needed to eliminate FP errors. Usually,
    PS> as.character(x) rounds to at most 15 digits, so, we get,
    PS> for example

    PS> as.character(0.1 + 0.2) # [1] "0.3"
    PS> as required. However, there are also exceptions, for example
    PS> as.character(1e19 + 1e5) # [1] "10000000000000100352"

    PS> Here, the number is printed exactly, so the resulting
    PS> string contains the FP error caused by the fact that
    PS> 1e19 + 1e5 has more than 53 significant digits in binary
    PS> representation, namely 59.

    PS> binary representation of 1e19 + 1e5 is
    PS> 1000101011000111001000110000010010001001111010011000011010100000

    PS> binary representation of 10000000000000100352 is
    PS> 1000101011000111001000110000010010001001111010011000100000000000

    PS> However, as.character(x) seems to do enough rounding for
    PS> most purposes, otherwise it would not be suitable as the
    PS> basic numeric to character conversion. If table() needs
    PS> factor() with a different conversion than
    PS> as.character(x), it may be done explicitly as discussed
    PS> by Martin above.

    PS> So, i suggest to use as.character() as the default
    PS> conversion in factor(), so that
    PS> identical(as.character(factor(x)), as.character(x)) is
    PS> satisfied for the default usage of factor().

    PS> Of course, i appreciate, if factor() has parameters,
    PS> which allow better control of the underlying conversion,
    PS> as it is done in the current development versions.

The version I have committed a few hours ago is indeed a much
re-simplified version, using  as.character(.) explicitly
and consequently no longer providing the extra optional
arguments that we have had for a couple of days.

Keeping such a basic function   factor()  as simple as possible 
seems a good strategy to me.

Martin Maechler


From savicky at cs.cas.cz  Mon May 11 21:03:52 2009
From: savicky at cs.cas.cz (Petr Savicky)
Date: Mon, 11 May 2009 21:03:52 +0200
Subject: [Rd] suggestion for extending ?as.factor
In-Reply-To: <18952.16126.640019.723302@lynne.math.ethz.ch>
References: <49FF25A6.3070907@biostat.ku.dk>
	<18943.64094.648164.476070@lynne.math.ethz.ch>
	<18945.19798.782710.936788@lynne.math.ethz.ch>
	<20090508090155.GA18486@cs.cas.cz>
	<18948.12553.265256.981657@lynne.math.ethz.ch>
	<20090508151448.GA6692@cs.cas.cz> <20090508161056.GB6692@cs.cas.cz>
	<18949.60853.709036.388905@cmath-5.math.ethz.ch>
	<20090510115253.GA26160@cs.cas.cz>
	<18952.16126.640019.723302@lynne.math.ethz.ch>
Message-ID: <20090511190352.GA13229@cs.cas.cz>

On Mon, May 11, 2009 at 05:06:38PM +0200, Martin Maechler wrote:
[...]
> The version I have committed a few hours ago is indeed a much
> re-simplified version, using  as.character(.) explicitly
> and consequently no longer providing the extra optional
> arguments that we have had for a couple of days.
> 
> Keeping such a basic function   factor()  as simple as possible 
> seems a good strategy to me.

OK. I understand the argument of simplicity. So, factor(x) is just
a compressed encoding of as.character(x), where each value is stored
only once. This sounds good to me.

Let me go back to the original purpose of this thread: suggestion for
extending ?as.factor

I think that somewhere in the help page, we could have something like

  Using factor() to a numeric vector should be done with caution. The
  information in x is preserved to the extent to which it is preserved
  in as.character(x). If this leads to too many different levels due to minor
  differences among the input numbers, it is suggested to use something like 
  factor(signif(x, digits)) or factor(round(x, digits)), where the number of 
  decimal digits appropriate for a given application should be used.

Let me point out that the following sentence from Warning is not exactly correct
as it is in svn at the moment. So, i suggest to add the word "approximately" to
the place marked with square brackets and add one more sentence of explanation
marked also by square brackets.

  To transform a factor \code{f} to [approximately]
  its original numeric values, \code{as.numeric(levels(f))[f]} is
  recommended and slightly more efficient than
  \code{as.numeric(as.character(f))}.
  [Note that the original values may be extracted only to the precision
  used in as.character(x), which is typically 15 decimal digits.]

Petr.


From maxime.to at ensae.fr  Mon May 11 23:50:11 2009
From: maxime.to at ensae.fr (maxime.to at ensae.fr)
Date: Mon, 11 May 2009 23:50:11 +0200 (CEST)
Subject: [Rd] Predict function npindex and npindexbw (PR#13695)
Message-ID: <20090511215011.0E27028320D8@mail.pubhealth.ku.dk>

Full_Name: Maxime To
Version: 2.9
OS: WIndows
Submission from: (NULL) (81.57.236.122)


I am using the npindex and npindexbw fubctions of the NP package. I would like
to compute the predicted values of the model and tried to use the predict
function for this purpose but the function only gives me the summary of the
model but no vector of predicted values as with any other model.

Simply using the code of the example, it gives:

set.seed(12345)
n <- 100
x1 <- runif(n, min=-1, max=1)
x2 <- runif(n, min=-1, max=1)
y <- x1 - x2 + rnorm(n)
bw <- npindexbw(formula=y~x1+x2)

summary(bw)
predict(bw)

You will see that the results of the summary and the predict function are the
same.


From rjvbertin at gmail.com  Mon May 11 16:17:37 2009
From: rjvbertin at gmail.com (=?ISO-8859-1?Q?Ren=E9_J=2EV=2E_Bertin?=)
Date: Mon, 11 May 2009 16:17:37 +0200
Subject: [Rd] [macosx] improving quartz & Aqua Tk behaviour outside of
	RGui
In-Reply-To: <797664590904281028m18ff5ff0te2e2502efacbca48@mail.gmail.com>
References: <797664590904281028m18ff5ff0te2e2502efacbca48@mail.gmail.com>
Message-ID: <797664590905110717t8fd92c8w25c7aa3cabedded0@mail.gmail.com>

A couple of weeks ago I posted a trick in R-help on improving Quartz
behaviour in the command line version of R:
http://tolstoy.newcastle.edu.au/R/e6/help/09/04/12948.html .

Works with Aqua Tcl/Tk 8.5 too, but I discovered one annoying
side-effect. After having a Tk dialog open (and using it) for a while,
the R process starts eating more than 50% cpu on my PPC G4, using
either the 8.4 or the 8.5 Tcl/Tk libraries. (I'm currently running R
2.8.1 .)

This does NOT happen when running the exact same code in the same
commandline R version with the 8.4 X11 Tcl/Tk libraries, nor when I
run the Quartz version in R-GUI.

For completeness, here's the Tcl/Tk function:

dialog.test <- function(wait=FALSE)
{
	with3 <- function( data1, data2=.GlobalEnv, expr )
	{
		attach(data1)
		attach(data2)
		on.exit( detach(data1), add= FALSE )
		on.exit( detach(data2), add= TRUE )
	
		try( eval( substitute(expr), parent.frame() ) )
	}

	require(tcltk) || stop("tcltk support is absent")

	tt <- tktoplevel()
	tkwm.title(tt,"VG1 tests")
	tt.done <- tclVar("0")

	name <- paste('dialog.test',as.character(tt$ID), sep='')
	assign( name, tt, env=tdialog.env )

	dialogVals<-get("dialogVals", env=RJVB.env)
	data<-tclVar(dialogVals[1])
	crit<-tclVar(dialogVals[2])
	eval1st<-tclVar(dialogVals[9])
	func<-tclVar(dialogVals[3])
	args<-tclVar(dialogVals[4])
	args2<-tclVar(dialogVals[5])
	acomm<-tclVar(dialogVals[8])
	sumvar <- tclVar(dialogVals[7])
	done <- tclVar(0)
	savecmd<-tclVar(dialogVals[6]);
	devvar <- tclVar( dev.cur() )
	theData <- ""

	reset <- function()
	{
		tclvalue(data)<-""
		tclvalue(crit)<-""
		tclvalue(eval1st)<-""
		tclvalue(func)<-""
		tclvalue(args)<-""
		tclvalue(args2)<-""
		tclvalue(acomm)<-""
		tclvalue(sumvar)<-"0"
	}

	doSource <- function()
	{
		fileN <- tclvalue( tkgetOpenFile() )
		if( fileN != "" ){
			try( source(fileN) )
		}
	}

	dfInfo <- function(fnc)
	{
	## notice that tclvalue() is correct here, since it is the
	## string representation of xvar and yvar that is being
	## displayed in the entry fields

		dataf  <- tclvalue(data)
		crit  <- tclvalue(crit)
		eval1st  <- tclvalue(eval1st)

		if( is.null(crit) | !strlen(crit) ){
			theData <- paste( dataf )
			assign( "Selected.Cases", "", env=RJVB.env )
		}
		else{
			theData <- paste( "SelectCases(", dataf, ",\"", crit, "\")" )
		}
		cmd<-paste( fnc, "( ", theData, " )" )
		try(
			cmd<-parse( text=cmd )
		);
		print( paste( "###", cmd ) )
		print( try( eval(cmd, envir=.GlobalEnv) ) )
		cmd
	}

	build <- function()
	{
	## notice that tclvalue() is correct here, since it is the
	## string representation of xvar and yvar that is being
	## displayed in the entry fields

		dataf  <- tclvalue(data)
		crit  <- tclvalue(crit)
		eval1st  <- tclvalue(eval1st)
		func  <- tclvalue(func)
		args  <- tclvalue(args)
		args2  <- tclvalue(args2)
		acomm  <- tclvalue(acomm)
		summ <- as.logical(tclObj(sumvar))

		assign( "dialogVals",
c(dataf,crit,func,args,args2,dialogVals[6],tclvalue(sumvar), acomm,
eval1st ), env=RJVB.env )

		if( is.null(crit) | !strlen(crit) ){
			theData <- paste( dataf )
			assign( "Selected.Cases", "", env=RJVB.env )
		}
		else{
			theData <- paste( "SelectCases(", dataf, ",\"", crit, "\")" )
		}
		if( is.null(acomm) | is.na(acomm) | !strlen(acomm) ){
			acomm <- ""
		}
		else{
			acomm <- paste( ", add.comment=\"", acomm, "\"" )
		}
		if( summ ){
			cmd<-paste( "with3( ", theData, ", tkdial.env, summary(
last.dialog.result<-", func, "(", args, ",", args2, acomm, ") ) )" )
# 			cmd<-paste( "with2( ", theData, ", summary(
last.dialog.result<-", func, "(", args, ",", args2, acomm, ") ) )" )
		}
		else{
			cmd<-paste( "with3( ", theData, ", tkdial.env,
last.dialog.result<-", func, "(", args, ",", args2, acomm, ") )" )
# 			cmd<-paste( "with2( ", theData, ", last.dialog.result<-", func,
"(", args, ",", args2, acomm, ") )" )
		}
		assign( "Selected.Data", theData, env=RJVB.env )
		try(
			cmd<-parse( text=cmd )
		);
		cmd
	}

	saveIt <- function()
	{
		cmd<-savecmd  <- tclvalue(savecmd)

		assign( "dialogVals",
c(dialogVals[1],dialogVals[2],dialogVals[3],dialogVals[4],dialogVals[5],cmd,dialogVals[7],
dialogVals[9]), env=RJVB.env )
		try(
			cmd<-parse( text=savecmd )
		);
		cmd
	}

	doIt <- function(cmd="")
	{
		orgDev <- dev.cur()
		try( dev.set( tclvalue(devvar) ) )
		func  <- tclvalue(func)
		eval1st  <- tclvalue(eval1st)

		eval( parse( text="tkdial.env <- new.env()"), env=.GlobalEnv )

		if( !is.null(eval1st) & strlen(eval1st) ){
			try(
				eval1st <- parse( text=eval1st )
			);
			cat(deparse(eval1st,width=500),sep="\n")
			print(
				try( eval(eval1st, env=tkdial.env) )
			);
			ls( env=tkdial.env )
		}

		cat("### Command executed via Tk ###\n")
		cat(deparse(cmd,width=500),sep="\n")
		cat("### Output:\n")
		dialogVals<-get("dialogVals", env=RJVB.env)
		print( system.time( print( try( res<-eval(cmd, envir=.GlobalEnv) ) ) ) )
		if( func == 'aov' | func == 'aov.VG1' ){
			cat('\n')
			try( print( TukeyHSD(res, ordered=TRUE) ), silent=TRUE)
		}
		cat( paste( "### ----------- (", deparse(tclvalue(data),width=132),
") ----------- ###\n", sep="" ) )

		try( dev.set(orgDev) )

		eval( parse( text="rm(tkdial.env)" ), env=.GlobalEnv )
	}

	doQuit <- function()
	{
		dQ <- function()
		{
			tclvalue(done)<-"cancel"
			tkdestroy(tt)
			tt.done<-"1"
		}

		 # if the window is referenced in the windowlist environment, remove
the reference and then close
		if( exists(name, env=tdialog.env) ){
			w <- get(name, env=tdialog.env)
			if( !is.null(w) && class(w) == "tkwin" ){
				try( assign( name, NULL, env=tdialog.env ) )
				try( rm( list=name, envir=tdialog.env ) )
				dQ()
			}
		}
		else{
		 # if not, close too. Probably means that dQ() can sstill be called
recursively...
			dQ()
		}
		return(0)
	}

	data.entry <- tkentry(tt, textvariable=data, width=100)
	crit.entry <- tkentry(tt, textvariable=crit, width=100)
	eval1st.entry <- tkentry(tt, textvariable=eval1st, width=100)
	func.entry <- tkentry(tt, textvariable=func, width=100)
	args.entry <- tkentry(tt, textvariable=args, width=100)
	args2.entry <- tkentry(tt, textvariable=args2, width=100)
	acomm.entry <- tkentry(tt, textvariable=acomm, width=100)
	dev.entry <- tkentry(tt, textvariable=devvar, width=2)

	summ.cbut <- tkcheckbutton(tt,text="Print summary()", variable=sumvar)

	submit.but <- tkbutton(tt, text="submit",
				 command=function()doIt(build()) )

	savecmd.entry <- tkentry(tt, textvariable=savecmd, width=100)
	save.but <- tkbutton(tt, text="save",
				command=function()doIt(saveIt()) )

	reset.but <- tkbutton(tt, text="Reset", command=reset)
	source.but <- tkbutton(tt, text="Source", command=function()doSource() )
	cancel.but <- tkbutton(tt, text="Cancel", command=doQuit )
	
	names.but <- tkbutton(tt, text="names", command=function()dfInfo("names") )
	summary.but <- tkbutton(tt, text="summary",
command=function()dfInfo("summary") )

	tkgrid(tklabel(tt,text="Dataframe"), data.entry, names.but, columnspan=3 )
	tkgrid(tklabel(tt,text="Sel.Crit"), crit.entry, summary.but, columnspan=3 )
	tkgrid(tklabel(tt,text="Eval.1st"), eval1st.entry, columnspan=3 )
	tkgrid(tklabel(tt,text="Analysis"), func.entry, columnspan=3 )
	tkgrid(tklabel(tt,text="Variables"), args.entry, columnspan=3 )
	tkgrid(tklabel(tt,text="Options"), args2.entry, columnspan=3 )
	tkgrid(tklabel(tt,text="Comment"), acomm.entry, columnspan=3 )
	tkgrid(summ.cbut, tklabel(tt,text="Device"), dev.entry, sticky="e" ,
columnspan=3 )
	tkgrid(tklabel(tt,text="Save cmd"), savecmd.entry, columnspan=3 )
	tkgrid(submit.but, save.but, reset.but, source.but, cancel.but,
columnspan=2, sticky="w")

## capture destroy (e.g. from window controls
## otherwise the tkwait hangs with nowhere to go)
#	tkbind(tt, "<Destroy>", function()tclvalue(done)<-"quit")
	tkbind(tt, "<Destroy>", function()doQuit())
	tkbind(tt, "<Return>", function()doIt(build()) )
	tkbind(tt, "<Control-s>", function()doIt(saveIt()) )
	tkbind(tt, "<Control-S>", function()doSource() )

	.Tcl("update idletasks")

	if( wait ){
		while( tclvalue(done) != "cancel" ){
			tkwait.variable(done)
			doQuit()
		}
	}
# 	else{
# 		return(tt)
# 	}

## not necessary: button handlers do all the work, until tkdestroy().
# 	tkwait.variable(done)
#
# 	while( tclvalue(done)!= "cancel" ){
# 		if(tclvalue(done)=="quit") stop("aborted")
#
# 		if( tclvalue(done)=="save"){
# 			cmd <- saveIt()
# 		}
# 		else{
# 			cmd <- build()
# 		}
# 		cat("### Command executed via Tk ###\n")
# 		cat(deparse(cmd,width=132),sep="\n")
# 		cat("### Output:\n")
# 		dialogVals<-get("dialogVals", env=RJVB.env)
# 		print( try( eval.parent(cmd) ) )
# 		cat("### ----------------------- ###\n")
#
# 		tkwait.variable(done)
# 	}

# 	return(NULL)

}

On 2009-04-28, Ren? J.V. Bertin <rjvbertin at gmail.com> wrote:

>  mkApp /Library/Frameworks/R.framework/Resources/bin/exec/R
<snip>
>  improves the behaviour of Quartz graphics windows, and of dialogs made
>  with TclTk (Aqua version 8.4), which for me now behave like under X11.
>  (i.e. as if controlled by a separate thread while the prompt remains
>  usable.)


From p.dalgaard at biostat.ku.dk  Tue May 12 08:47:23 2009
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Tue, 12 May 2009 08:47:23 +0200
Subject: [Rd] Predict function npindex and npindexbw (PR#13695)
In-Reply-To: <20090511215011.0E27028320D8@mail.pubhealth.ku.dk>
References: <20090511215011.0E27028320D8@mail.pubhealth.ku.dk>
Message-ID: <4A091B7B.3090901@biostat.ku.dk>

maxime.to at ensae.fr wrote:
> Full_Name: Maxime To
> Version: 2.9
> OS: WIndows
> Submission from: (NULL) (81.57.236.122)
> 
> 
> I am using the npindex and npindexbw fubctions of the NP package. I would like
> to compute the predicted values of the model and tried to use the predict
> function for this purpose but the function only gives me the summary of the
> model but no vector of predicted values as with any other model.
> 
> Simply using the code of the example, it gives:
> 
> set.seed(12345)
> n <- 100
> x1 <- runif(n, min=-1, max=1)
> x2 <- runif(n, min=-1, max=1)
> y <- x1 - x2 + rnorm(n)
> bw <- npindexbw(formula=y~x1+x2)
> 
> summary(bw)
> predict(bw)
> 
> You will see that the results of the summary and the predict function are the
> same.

You need to take this up with the package maintainer. This is not a bug 
in R itself and cannot be handled via the bug report system.

-- 
    O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
   c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
  (*) \(*) -- University of Copenhagen   Denmark      Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)              FAX: (+45) 35327907


From kelley.dan at gmail.com  Tue May 12 11:55:12 2009
From: kelley.dan at gmail.com (kelley.dan at gmail.com)
Date: Tue, 12 May 2009 11:55:12 +0200 (CEST)
Subject: [Rd] bug in axis.POSIXct relating to tz (PR#13696)
Message-ID: <20090512095512.BD3F128320B5@mail.pubhealth.ku.dk>

Full_Name: Dan Kelley
Version: 2.8.0
OS: OS X
Submission from: (NULL) (142.177.154.193)


Some time ago, I posted a note about what I considered to be a bug in
axis.POSIXt() for R 2.8.x, relating to whether timezones in the data are obeyed
on the axes.  A link to that note, and to a quick and helpful response, is at
the following URL 

http://www.nabble.com/patch-for-axis.POSIXct-%28related-to-timezones%29-td22338700.html#a22338700

Note that R 2.9.0 has been adjusted to help with this.  However, there are still
problems.  Test code is given below:

<pre>
# test code (top panel, OK; bottom panel, incorrect times on x axis) 
par(mar=c(2,2,2,1)) 
par(mfrow=c(2,1)) 
start <- as.POSIXct("2008-05-01 00:00:00", tz="UTC") 
end   <- as.POSIXct("2008-05-01 00:10:00", tz="UTC") 
plot(c(start, end), c(0, 1), ylab="") 
mtext(paste(start, "to", end), side=3) 

start <- as.POSIXct("2008-05-01 00:00:00", tz="UTC") 
end   <- as.POSIXct("2008-05-01 01:10:00", tz="UTC") 
plot(c(start, end), c(0, 1), ylab="") 
mtext(paste(start, "to", end), side=3)
</pre>


From savicky at cs.cas.cz  Tue May 12 13:17:15 2009
From: savicky at cs.cas.cz (Petr Savicky)
Date: Tue, 12 May 2009 13:17:15 +0200
Subject: [Rd] suggestion for extending ?as.factor
In-Reply-To: <18952.16126.640019.723302@lynne.math.ethz.ch>
References: <49FF25A6.3070907@biostat.ku.dk>
	<18943.64094.648164.476070@lynne.math.ethz.ch>
	<18945.19798.782710.936788@lynne.math.ethz.ch>
	<20090508090155.GA18486@cs.cas.cz>
	<18948.12553.265256.981657@lynne.math.ethz.ch>
	<20090508151448.GA6692@cs.cas.cz> <20090508161056.GB6692@cs.cas.cz>
	<18949.60853.709036.388905@cmath-5.math.ethz.ch>
	<20090510115253.GA26160@cs.cas.cz>
	<18952.16126.640019.723302@lynne.math.ethz.ch>
Message-ID: <20090512111715.GB5761@cs.cas.cz>

On Mon, May 11, 2009 at 05:06:38PM +0200, Martin Maechler wrote:
> The version I have committed a few hours ago is indeed a much
> re-simplified version, using  as.character(.) explicitly

The current development version (2009-05-11 r48528) contains
in ?factor a description of levels parametr

  levels: an optional vector of the values that 'x' might have taken. 
          The default is the unique set of values taken by
          'character(x)', sorted into increasing order _of 'x'_.  Note
          that this set can be smaller than 'sort(unique(x))'.

I think that 'character(x)' should be 'as.character(x)'.

Petr.


From lgautier at gmail.com  Tue May 12 13:19:43 2009
From: lgautier at gmail.com (Laurent Gautier)
Date: Tue, 12 May 2009 13:19:43 +0200
Subject: [Rd] In C, a fast way to slice a vector?
In-Reply-To: <mailman.27.1242122408.30389.r-devel@r-project.org>
References: <mailman.27.1242122408.30389.r-devel@r-project.org>
Message-ID: <4A095B4F.1080800@gmail.com>



r-devel-request at r-project.org wrote:
> 
> Impressive stuff. Nice to see people giving some though to this.
> I will explore the packages you mentioned.
> 
> Thank you
> 
> Saptarshi Guha
> 
> 
> 
> On Mon, May 11, 2009 at 12:37 AM, Patrick Aboyoun <paboyoun at fhcrc.org> wrote:
>> Saptarshi,
>> I know of two alternatives you can use to do fast extraction of consecutive
>> subsequences of a vector:
>>
>> 1) Fast copy: ?The method you mentioned of creating a memcpy'd vector
>> 2) Pointer management: Creating an externalptr object in R and manage the
>> start and end of your data
>>
>> If you are looking for a prototyping environment to try, I recommend using
>> the IRanges and Biostrings packages from the Bioconductor project. The
>> IRanges package contains a function called subseq for performing 1) on all
>> basic vector types (raw, logical, integer, etc.) and Biostrings package
>> contains a subseq method on an externalptr based class that implements 2.
>>
>> I was going to lobby R core members quietly about adding something akin to
>> subseq from IRanges into base R since it is extremely useful for all long
>> vectors and could replace all a:b calls with a <= b in R code, but this
>> publicity can't hurt.


The Python development team has been developing something similar for 
python 3.0 (Buffer and Memoryview), and they are backporting it to the 
latest 2.x releases.
I have just started toying with it, and it seems looking very nice. 
There might be good ideas to take from there into a possible R built-in 
capability.



L.




>> Here is an example:
>>
>>> source("http://bioconductor.org/biocLite.R")
>>> biocLite(c("IRanges", "Biostrings"))
>> << download output omitted >>
>>> suppressMessages(library(Biostrings))
>>> x <- rep(charToRaw("a"), 1e7)
>>> y <- BString(rawToChar(x))
>>> suppressMessages(library(Biostrings))
>>> x <- rep(charToRaw("a"), 1e7)
>>> y <- BString(rawToChar(x))
>>> system.time(x[13:1e7])
>> ? user ?system elapsed
>> ?0.304 ? 0.073 ? 0.378
>>> system.time(subseq(x, 13))
>> ? user ?system elapsed
>> ?0.011 ? 0.007 ? 0.019
>>> system.time(subseq(y, 13))
>> ? user ?system elapsed
>> ?0.003 ? 0.000 ? 0.004
>>> identical(x[13:1e7], subseq(x, 13))
>> [1] TRUE
>>> identical(x[13:1e7], charToRaw(as.character(subseq(y, 13))))
>> [1] TRUE
>>> sessionInfo()
>> R version 2.10.0 Under development (unstable) (2009-05-08 r48504)
>> i386-apple-darwin9.6.0
>>
>> locale:
>> [1] en_US.UTF-8/en_US.UTF-8/C/C/en_US.UTF-8/en_US.UTF-8
>>
>> attached base packages:
>> [1] stats ? ? graphics ?grDevices utils ? ? datasets ?methods ? base
>>
>> other attached packages:
>> [1] Biostrings_2.13.5 IRanges_1.3.5
>>
>> loaded via a namespace (and not attached):
>> [1] Biobase_2.5.2
>>
>>
>>
>> Quoting Saptarshi Guha <saptarshi.guha at gmail.com>:
>>
>>> Hello,
>>> Suppose in the following code,
>>> PROTECT(sr = R_tryEval( .... ))
>>>
>>> sr is a RAWSXP vector. I wish to return another RAWSXP starting at
>>> position 13 onwards (base=0).
>>>
>>> I could create another RAWSXP of the correct length and then memcpy
>>> the required bytes and length to this new one.
>>>
>>> However is there a more efficient method?
>>>
>>> Regards
>>> Saptarshi Guha
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>
>>


From maechler at stat.math.ethz.ch  Tue May 12 16:00:39 2009
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 12 May 2009 16:00:39 +0200
Subject: [Rd] suggestion for extending ?as.factor
In-Reply-To: <20090512111715.GB5761@cs.cas.cz>
References: <49FF25A6.3070907@biostat.ku.dk>
	<18943.64094.648164.476070@lynne.math.ethz.ch>
	<18945.19798.782710.936788@lynne.math.ethz.ch>
	<20090508090155.GA18486@cs.cas.cz>
	<18948.12553.265256.981657@lynne.math.ethz.ch>
	<20090508151448.GA6692@cs.cas.cz> <20090508161056.GB6692@cs.cas.cz>
	<18949.60853.709036.388905@cmath-5.math.ethz.ch>
	<20090510115253.GA26160@cs.cas.cz>
	<18952.16126.640019.723302@lynne.math.ethz.ch>
	<20090512111715.GB5761@cs.cas.cz>
Message-ID: <18953.33031.570628.552074@lynne.math.ethz.ch>

>>>>> "PS" == Petr Savicky <savicky at cs.cas.cz>
>>>>>     on Tue, 12 May 2009 13:17:15 +0200 writes:

    PS> On Mon, May 11, 2009 at 05:06:38PM +0200, Martin Maechler wrote:
    >> The version I have committed a few hours ago is indeed a much
    >> re-simplified version, using  as.character(.) explicitly

    PS> The current development version (2009-05-11 r48528) contains
    PS> in ?factor a description of levels parametr

    PS> levels: an optional vector of the values that 'x' might have taken. 
    PS> The default is the unique set of values taken by
    PS> 'character(x)', sorted into increasing order _of 'x'_.  Note
    PS> that this set can be smaller than 'sort(unique(x))'.

    PS> I think that 'character(x)' should be 'as.character(x)'.

Definitely; thank you.
Thanks as well to suggestions from yesterday, of which I have at
least added the "approximately".

Martin


From bolker at ufl.edu  Wed May 13 01:46:44 2009
From: bolker at ufl.edu (Ben Bolker)
Date: Tue, 12 May 2009 19:46:44 -0400
Subject: [Rd] View() crashy on Ubuntu 9.04
Message-ID: <4A0A0A64.6030706@ufl.edu>


  It's my vague impression that View() is workable on Windows and maybe
on MacOS, but on Ubuntu Linux 9.04 (intrepid) it seems completely
unstable.  I can reliably crash R by trying to look  at a very small,
simple data frame ...

   I was going to try to run with debug turned on, but my installed
version (2.9.0) doesn't have debugging symbols, and I'm having trouble
building the latest SVN version (./configure gives "checking for
recommended packages... ls: cannot access
./src/library/Recommended/boot_*.tar.gz: No such file or directory")


   Can anyone confirm?

  cheers
    Ben Bolker


R --vanilla

> v <- data.frame(1:3,2:4)
> sessionInfo()
R version 2.9.0 (2009-04-17)
i486-pc-linux-gnu

locale:
LC_CTYPE=en_US.UTF-8;LC_NUMERIC=C;LC_TIME=en_US.UTF-8;LC_COLLATE=en_US.UTF-8;LC_MONETARY=C;LC_MESSAGES=en_US.UTF-8;LC_PAPER=en_US.UTF-8;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=en_US.UTF-8;LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

> View(v)

  [change focus to the view window, hit "down arrow"]

>
 *** caught segfault ***
address 0x4, cause 'memory not mapped'

Possible actions:
1: abort (with core dump, if enabled)
2: normal R exit
3: exit R without saving workspace
4: exit R saving workspace
Selection: 3


-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 260 bytes
Desc: OpenPGP digital signature
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090512/2ddf4ab7/attachment.bin>

From edd at debian.org  Wed May 13 03:59:16 2009
From: edd at debian.org (Dirk Eddelbuettel)
Date: Tue, 12 May 2009 20:59:16 -0500
Subject: [Rd] View() crashy on Ubuntu 9.04
In-Reply-To: <4A0A0A64.6030706@ufl.edu>
References: <4A0A0A64.6030706@ufl.edu>
Message-ID: <18954.10612.51851.692033@ron.nulle.part>


On 12 May 2009 at 19:46, Ben Bolker wrote:
|   It's my vague impression that View() is workable on Windows and maybe
| on MacOS, but on Ubuntu Linux 9.04 (intrepid) it seems completely
| unstable.  I can reliably crash R by trying to look  at a very small,
| simple data frame ...
| 
|    I was going to try to run with debug turned on, but my installed
| version (2.9.0) doesn't have debugging symbols, and I'm having trouble

Good news: just run
     
     sudo apt-get install r-base-core-dbg

Most (library) packages (lib)foo now also ship (lib)foo-dbg which is provide
something close to pure magic -- just by installing these the already
instrumented gdb knows where to look for them.  See, no more recompiling.
Debug symbols appear out of thin air.  (I have used it only on Debian at home
when debugging R stuff, but it should really work the same for you there on
Ubuntu.)

| building the latest SVN version (./configure gives "checking for
| recommended packages... ls: cannot access
| ./src/library/Recommended/boot_*.tar.gz: No such file or directory")

It's moot as per the above but you need to either run the script to rsync
those in, or configure using 

		    --without-recommended-packages	

As for x11 instability, I happen to spend my daytime hours in from of
Cygwin/X connected to a few Ubuntu machines running R, and of late the
display has been unstable.  I tend to blame the other software first, but
indeed, the most recent change was probably R.  Did anybody experience that?

|    Can anyone confirm?
| 
|   cheers
|     Ben Bolker
| 
| 
| R --vanilla
| 
| > v <- data.frame(1:3,2:4)
| > sessionInfo()
| R version 2.9.0 (2009-04-17)
| i486-pc-linux-gnu
| 
| locale:
| LC_CTYPE=en_US.UTF-8;LC_NUMERIC=C;LC_TIME=en_US.UTF-8;LC_COLLATE=en_US.UTF-8;LC_MONETARY=C;LC_MESSAGES=en_US.UTF-8;LC_PAPER=en_US.UTF-8;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=en_US.UTF-8;LC_IDENTIFICATION=C
| 
| attached base packages:
| [1] stats     graphics  grDevices utils     datasets  methods   base
| 
| > View(v)
| 
|   [change focus to the view window, hit "down arrow"]
| 
| >
|  *** caught segfault ***
| address 0x4, cause 'memory not mapped'
| 
| Possible actions:
| 1: abort (with core dump, if enabled)
| 2: normal R exit
| 3: exit R without saving workspace
| 4: exit R saving workspace
| Selection: 3

Confirmed. Dies for me too, but from Debian and Ubuntu connected to the same
display (Ubuntu 9.04).

Dirk

-- 
Three out of two people have difficulties with fractions.


From kjetilbrinchmannhalvorsen at gmail.com  Wed May 13 04:43:38 2009
From: kjetilbrinchmannhalvorsen at gmail.com (Kjetil Halvorsen)
Date: Tue, 12 May 2009 22:43:38 -0400
Subject: [Rd] View() crashy on Ubuntu 9.04
In-Reply-To: <18954.10612.51851.692033@ron.nulle.part>
References: <4A0A0A64.6030706@ufl.edu>
	<18954.10612.51851.692033@ron.nulle.part>
Message-ID: <556e90a80905121943o85a6d7et8862c940fafda773@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090512/56f632a2/attachment.pl>

From bolker at ufl.edu  Wed May 13 04:58:54 2009
From: bolker at ufl.edu (Ben Bolker)
Date: Tue, 12 May 2009 22:58:54 -0400
Subject: [Rd] View() crashy on Ubuntu 9.04
In-Reply-To: <556e90a80905121943o85a6d7et8862c940fafda773@mail.gmail.com>
References: <4A0A0A64.6030706@ufl.edu>	
	<18954.10612.51851.692033@ron.nulle.part>
	<556e90a80905121943o85a6d7et8862c940fafda773@mail.gmail.com>
Message-ID: <4A0A376E.8020305@ufl.edu>

  Actually, gdb seems not to want to debug this -- in either the
Debian-magic version or the one I configured/made on my own system, I
get to the View() command and get

>> View(v)
> [Thread debugging using libthread_db enabled]
> Error while reading shared library symbols:
> Cannot find new threads: generic error
> Cannot find new threads: generic error

  ??

  cheers
   Ben Bolker


Kjetil Halvorsen wrote:
> I can reproduce this too.
> Run  from within emacs:
> 
>> v <- data.frame(1:3,2:4)
>> sessionInfo()
> R version 2.9.0 (2009-04-17)
> i686-pc-linux-gnu
> 
> locale:
> LC_CTYPE=en_US.UTF-8;LC_NUMERIC=C;LC_TIME=en_US.UTF-8;LC_COLLATE=en_US.UTF-8;LC_MONETARY=C;LC_MESSAGES=en_US.UTF-8;LC_PAPER=en_US.UTF-8;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=en_US.UTF-8;LC_IDENTIFICATION=C
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>> View(v)
>>
>  *** caught segfault ***
> address 0x4, cause 'memory not mapped'
> 
> Possible actions:
> 1: abort (with core dump, if enabled)
> 2: normal R exit
> 3: exit R without saving workspace
> 4: exit R saving workspace
> Selection: 3
> 
> Process R exited abnormally with code 70 at Tue May 12 22:41:55 2009
> 
> Kjetil
> 
> 
> On Tue, May 12, 2009 at 9:59 PM, Dirk Eddelbuettel <edd at debian.org<mailto:edd at debian.org>> wrote:
> 
> On 12 May 2009 at 19:46, Ben Bolker wrote:
> |   It's my vague impression that View() is workable on Windows and maybe
> | on MacOS, but on Ubuntu Linux 9.04 (intrepid) it seems completely
> | unstable.  I can reliably crash R by trying to look  at a very small,
> | simple data frame ...
> |
> |    I was going to try to run with debug turned on, but my installed
> | version (2.9.0) doesn't have debugging symbols, and I'm having trouble
> 
> Good news: just run
> 
>     sudo apt-get install r-base-core-dbg
> 
> Most (library) packages (lib)foo now also ship (lib)foo-dbg which is provide
> something close to pure magic -- just by installing these the already
> instrumented gdb knows where to look for them.  See, no more recompiling.
> Debug symbols appear out of thin air.  (I have used it only on Debian at home
> when debugging R stuff, but it should really work the same for you there on
> Ubuntu.)
> 
> | building the latest SVN version (./configure gives "checking for
> | recommended packages... ls: cannot access
> | ./src/library/Recommended/boot_*.tar.gz: No such file or directory")
> 
> It's moot as per the above but you need to either run the script to rsync
> those in, or configure using
> 
>                    --without-recommended-packages
> 
> As for x11 instability, I happen to spend my daytime hours in from of
> Cygwin/X connected to a few Ubuntu machines running R, and of late the
> display has been unstable.  I tend to blame the other software first, but
> indeed, the most recent change was probably R.  Did anybody experience that?
> 
> |    Can anyone confirm?
> |
> |   cheers
> |     Ben Bolker
> |
> |
> | R --vanilla
> |
> | > v <- data.frame(1:3,2:4)
> | > sessionInfo()
> | R version 2.9.0 (2009-04-17)
> | i486-pc-linux-gnu
> |
> | locale:
> | LC_CTYPE=en_US.UTF-8;LC_NUMERIC=C;LC_TIME=en_US.UTF-8;LC_COLLATE=en_US.UTF-8;LC_MONETARY=C;LC_MESSAGES=en_US.UTF-8;LC_PAPER=en_US.UTF-8;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=en_US.UTF-8;LC_IDENTIFICATION=C
> |
> | attached base packages:
> | [1] stats     graphics  grDevices utils     datasets  methods   base
> |
> | > View(v)
> |
> |   [change focus to the view window, hit "down arrow"]
> |
> | >
> |  *** caught segfault ***
> | address 0x4, cause 'memory not mapped'
> |
> | Possible actions:
> | 1: abort (with core dump, if enabled)
> | 2: normal R exit
> | 3: exit R without saving workspace
> | 4: exit R saving workspace
> | Selection: 3
> 
> Confirmed. Dies for me too, but from Debian and Ubuntu connected to the same
> display (Ubuntu 9.04).
> 
> Dirk
> 
> --
> Three out of two people have difficulties with fractions.
> 
> ______________________________________________
> R-devel at r-project.org<mailto:R-devel at r-project.org> mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 


-- 
Ben Bolker
Associate professor, Biology Dep't, Univ. of Florida
bolker at ufl.edu / www.zoology.ufl.edu/bolker
GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 260 bytes
Desc: OpenPGP digital signature
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090512/fbbca754/attachment.bin>

From edd at debian.org  Wed May 13 05:04:13 2009
From: edd at debian.org (Dirk Eddelbuettel)
Date: Tue, 12 May 2009 22:04:13 -0500
Subject: [Rd] View() crashy on Ubuntu 9.04
In-Reply-To: <556e90a80905121943o85a6d7et8862c940fafda773@mail.gmail.com>
References: <4A0A0A64.6030706@ufl.edu>
	<18954.10612.51851.692033@ron.nulle.part>
	<556e90a80905121943o85a6d7et8862c940fafda773@mail.gmail.com>
Message-ID: <18954.14509.928285.317516@ron.nulle.part>


And to push the ball a little downcourt:

edd at joe:~$ wajig install r-base-core-dbg
Reading package lists... Done
Building dependency tree
Reading state information... Done
The following NEW packages will be installed:
  r-base-core-dbg
0 upgraded, 1 newly installed, 0 to remove and 0 not upgraded.
Need to get 2431kB of archives.
After this operation, 6132kB of additional disk space will be used.
WARNING: The following packages cannot be authenticated!
  r-base-core-dbg
Install these packages without verification [y/N]? y
Get:1 http://ron jaunty/ r-base-core-dbg 2.9.0-1jaunty0 [2431kB]
Fetched 2431kB in 8s (276kB/s)
Selecting previously deselected package r-base-core-dbg.
(Reading database ... 345934 files and directories currently installed.)
Unpacking r-base-core-dbg (from .../r-base-core-dbg_2.9.0-1jaunty0_i386.deb) ...
Setting up r-base-core-dbg (2.9.0-1jaunty0) ...
edd at joe:~$ R -d gdb
GNU gdb 6.8-debian
Copyright (C) 2008 Free Software Foundation, Inc.
License GPLv3+: GNU GPL version 3 or later <http://gnu.org/licenses/gpl.html>
This is free software: you are free to change and redistribute it.
There is NO WARRANTY, to the extent permitted by law.  Type "show copying"
and "show warranty" for details.
This GDB was configured as "i486-linux-gnu"...
(gdb) run
Starting program: /usr/lib/R/bin/exec/R

R version 2.9.0 (2009-04-17)
Copyright (C) 2009 The R Foundation for Statistical Computing
ISBN 3-900051-07-0

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> v <- data.frame(1:3,2:4)
> View(v)
[Thread debugging using libthread_db enabled]
Error while reading shared library symbols:
Cannot find new threads: generic error
Cannot find new threads: generic error
(gdb) c
Continuing.
> [New Thread 0xb77026c0 (LWP 15067)]

Program received signal SIGSEGV, Segmentation fault.
[Switching to Thread 0xb77026c0 (LWP 15067)]
0xb70e685e in XmbLookupString () from /usr/lib/libX11.so.6
(gdb) where
#0  0xb70e685e in XmbLookupString () from /usr/lib/libX11.so.6
#1  0xb73a9d48 in doSpreadKey (DE=0x8bfd040, key=<value optimized out>, event=0xbfed68d8) at dataentry.c:1828
#2  0xb73aa51e in R_ProcessX11Events (data=0x0) at dataentry.c:1649
#3  0xb7f85b1f in R_runHandlers (handlers=0xb8024060, readMask=0xb80ba2e0) at sys-std.c:378
#4  0xb7f874b9 in Rstd_ReadConsole (prompt=0x8b51398 "> ", buf=0xbfed7a80 "View(v)\n", len=4096, addtohistory=1) at sys-std.c:913
#5  0xb7f83d95 in R_ReadConsole (prompt=0x8b51398 "> ", buf=0xbfed7a80 "View(v)\n", len=4096, addtohistory=1) at system.c:73
#6  0xb7eb1853 in Rf_ReplIteration (rho=0x8b52874, savestack=0, browselevel=0, state=0xbfed7a74) at main.c:205
#7  0xb7eb1c13 in R_ReplConsole (rho=0x8b52874, savestack=0, browselevel=0) at main.c:306
#8  0xb7eb1cb5 in run_Rmainloop () at main.c:966
#9  0xb7eb1cdc in Rf_mainloop () at main.c:973
#10 0x080487c6 in main (ac=65364, av=0x3a9cad) at Rmain.c:33
#11 0xb7c42775 in __libc_start_main () from /lib/tls/i686/cmov/libc.so.6
#12 0x080486b1 in _start () at ../sysdeps/i386/elf/start.S:119
(gdb)

Dirk

On 12 May 2009 at 22:43, Kjetil Halvorsen wrote:
| I can reproduce this too.
| Run  from within emacs:
| 
| > v <- data.frame(1:3,2:4)
| > sessionInfo()
| R version 2.9.0 (2009-04-17)
| i686-pc-linux-gnu
| 
| locale:
| LC_CTYPE=en_US.UTF-8;LC_NUMERIC=C;LC_TIME=en_US.UTF-8;LC_COLLATE=en_US.UTF-8;LC_MONETARY=C;LC_MESSAGES=en_US.UTF-8;LC_PAPER=en_US.UTF-8;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=en_US.UTF-8;LC_IDENTIFICATION=C
| 
| attached base packages:
| [1] stats     graphics  grDevices utils     datasets  methods   base
| > View(v)
| >
|  *** caught segfault ***
| address 0x4, cause 'memory not mapped'
| 
| Possible actions:
| 1: abort (with core dump, if enabled)
| 2: normal R exit
| 3: exit R without saving workspace
| 4: exit R saving workspace
| Selection: 3
| 
| Process R exited abnormally with code 70 at Tue May 12 22:41:55 2009
| 
| Kjetil
| 
| 
| On Tue, May 12, 2009 at 9:59 PM, Dirk Eddelbuettel <edd at debian.org> wrote:
| 
| >
| > On 12 May 2009 at 19:46, Ben Bolker wrote:
| > |   It's my vague impression that View() is workable on Windows and maybe
| > | on MacOS, but on Ubuntu Linux 9.04 (intrepid) it seems completely
| > | unstable.  I can reliably crash R by trying to look  at a very small,
| > | simple data frame ...
| > |
| > |    I was going to try to run with debug turned on, but my installed
| > | version (2.9.0) doesn't have debugging symbols, and I'm having trouble
| >
| > Good news: just run
| >
| >     sudo apt-get install r-base-core-dbg
| >
| > Most (library) packages (lib)foo now also ship (lib)foo-dbg which is
| > provide
| > something close to pure magic -- just by installing these the already
| > instrumented gdb knows where to look for them.  See, no more recompiling.
| > Debug symbols appear out of thin air.  (I have used it only on Debian at
| > home
| > when debugging R stuff, but it should really work the same for you there on
| > Ubuntu.)
| >
| > | building the latest SVN version (./configure gives "checking for
| > | recommended packages... ls: cannot access
| > | ./src/library/Recommended/boot_*.tar.gz: No such file or directory")
| >
| > It's moot as per the above but you need to either run the script to rsync
| > those in, or configure using
| >
| >                    --without-recommended-packages
| >
| > As for x11 instability, I happen to spend my daytime hours in from of
| > Cygwin/X connected to a few Ubuntu machines running R, and of late the
| > display has been unstable.  I tend to blame the other software first, but
| > indeed, the most recent change was probably R.  Did anybody experience
| > that?
| >
| > |    Can anyone confirm?
| > |
| > |   cheers
| > |     Ben Bolker
| > |
| > |
| > | R --vanilla
| > |
| > | > v <- data.frame(1:3,2:4)
| > | > sessionInfo()
| > | R version 2.9.0 (2009-04-17)
| > | i486-pc-linux-gnu
| > |
| > | locale:
| > |
| > LC_CTYPE=en_US.UTF-8;LC_NUMERIC=C;LC_TIME=en_US.UTF-8;LC_COLLATE=en_US.UTF-8;LC_MONETARY=C;LC_MESSAGES=en_US.UTF-8;LC_PAPER=en_US.UTF-8;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=en_US.UTF-8;LC_IDENTIFICATION=C
| > |
| > | attached base packages:
| > | [1] stats     graphics  grDevices utils     datasets  methods   base
| > |
| > | > View(v)
| > |
| > |   [change focus to the view window, hit "down arrow"]
| > |
| > | >
| > |  *** caught segfault ***
| > | address 0x4, cause 'memory not mapped'
| > |
| > | Possible actions:
| > | 1: abort (with core dump, if enabled)
| > | 2: normal R exit
| > | 3: exit R without saving workspace
| > | 4: exit R saving workspace
| > | Selection: 3
| >
| > Confirmed. Dies for me too, but from Debian and Ubuntu connected to the
| > same
| > display (Ubuntu 9.04).
| >
| > Dirk
| >
| > --
| > Three out of two people have difficulties with fractions.
| >
| > ______________________________________________
| > R-devel at r-project.org mailing list
| > https://stat.ethz.ch/mailman/listinfo/r-devel
| >

-- 
Three out of two people have difficulties with fractions.


From edd at debian.org  Wed May 13 05:13:00 2009
From: edd at debian.org (Dirk Eddelbuettel)
Date: Tue, 12 May 2009 22:13:00 -0500
Subject: [Rd] View() crashy on Ubuntu 9.04
In-Reply-To: <4A0A376E.8020305@ufl.edu>
References: <4A0A0A64.6030706@ufl.edu>
	<18954.10612.51851.692033@ron.nulle.part>
	<556e90a80905121943o85a6d7et8862c940fafda773@mail.gmail.com>
	<4A0A376E.8020305@ufl.edu>
Message-ID: <18954.15036.62887.669206@ron.nulle.part>


On 12 May 2009 at 22:58, Ben Bolker wrote:
|   Actually, gdb seems not to want to debug this -- in either the
| Debian-magic version or the one I configured/made on my own system, I
| get to the View() command and get
| 
| >> View(v)
| > [Thread debugging using libthread_db enabled]
| > Error while reading shared library symbols:
| > Cannot find new threads: generic error
| > Cannot find new threads: generic error

Just type 'c' to continue; see the mail I must have sent essentially at the
same time.  Threading can be dicey. I am not sure if this first stop in gdb is
indicative of anything.

Dirk

-- 
Three out of two people have difficulties with fractions.


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Wed May 13 09:33:48 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Wed, 13 May 2009 09:33:48 +0200
Subject: [Rd] View() crashy on Ubuntu 9.04
In-Reply-To: <4A0A0A64.6030706@ufl.edu>
References: <4A0A0A64.6030706@ufl.edu>
Message-ID: <4A0A77DC.3010506@idi.ntnu.no>

Ben Bolker wrote:
>   It's my vague impression that View() is workable on Windows and maybe
> on MacOS, but on Ubuntu Linux 9.04 (intrepid) it seems completely
> unstable.  I can reliably crash R by trying to look  at a very small,
> simple data frame ...
>   

on my 8.04, r is reliable at crashing with, e.g.,

    View(1)

with a subsequent attempt to move through the spreadsheet with an arrow
key.  this always causes a segfault.

>    I was going to try to run with debug turned on, but my installed
> version (2.9.0) doesn't have debugging symbols, and I'm having trouble
> building the latest SVN version (./configure gives "checking for
> recommended packages... ls: cannot access
> ./src/library/Recommended/boot_*.tar.gz: No such file or directory")
>   

    tools/rsync-recommended


vQ


From nakama at ki.rim.or.jp  Wed May 13 09:55:30 2009
From: nakama at ki.rim.or.jp (Ei-ji Nakama)
Date: Wed, 13 May 2009 16:55:30 +0900
Subject: [Rd] View() crashy on Ubuntu 9.04
In-Reply-To: <18954.14509.928285.317516@ron.nulle.part>
References: <4A0A0A64.6030706@ufl.edu>
	<18954.10612.51851.692033@ron.nulle.part>
	<556e90a80905121943o85a6d7et8862c940fafda773@mail.gmail.com>
	<18954.14509.928285.317516@ron.nulle.part>
Message-ID: <dc41e1260905130055h2c7761bdv7608657be5fa479f@mail.gmail.com>

Hi

2009/5/13 Dirk Eddelbuettel <edd at debian.org>:
<snip>
> #0 ?0xb70e685e in XmbLookupString () from /usr/lib/libX11.so.6
> #1 ?0xb73a9d48 in doSpreadKey (DE=0x8bfd040, key=<value optimized out>, event=0xbfed68d8) at dataentry.c:1828

It is generated by XmbLookupString and Xutf8LookupString because
this doesn't make Input context of X11 when dataeditor is View.

static char *GetCharP(DEEvent * event)
{
     <snip>
            XmbLookupString(ioic, (XKeyEvent *)event, /* ioic at view
time is NULL*/
                            text, sizeof(text) - clength,
                            &iokey, &status);
     <snip>
}

I think that this only has to limit GetCharP to isEditor=TRUE.
moreover View() was strange operation of  "page down".


http://prs.ism.ac.jp/~nakama/working/dataentry.patch

I think that I improve the above-mentioned by this patch.

-- 
EI-JI Nakama  <nakama (a) ki.rim.or.jp>
"\u4e2d\u9593\u6804\u6cbb"  <nakama (a) ki.rim.or.jp>


From bolker at ufl.edu  Wed May 13 16:12:10 2009
From: bolker at ufl.edu (Ben Bolker)
Date: Wed, 13 May 2009 10:12:10 -0400
Subject: [Rd] View() crashy on Ubuntu 9.04
In-Reply-To: <dc41e1260905130055h2c7761bdv7608657be5fa479f@mail.gmail.com>
References: <4A0A0A64.6030706@ufl.edu>	
	<18954.10612.51851.692033@ron.nulle.part>	
	<556e90a80905121943o85a6d7et8862c940fafda773@mail.gmail.com>	
	<18954.14509.928285.317516@ron.nulle.part>
	<dc41e1260905130055h2c7761bdv7608657be5fa479f@mail.gmail.com>
Message-ID: <4A0AD53A.10502@ufl.edu>

  This patch fixes the problem for me with latest R-devel.  Thanks!
(This kind of X-hacking would take me hours if not days to figure out ...)

  cheers
    Ben Bolker


Ei-ji Nakama wrote:
> Hi
> 
> 2009/5/13 Dirk Eddelbuettel <edd at debian.org>:
> <snip>
>> #0  0xb70e685e in XmbLookupString () from /usr/lib/libX11.so.6
>> #1  0xb73a9d48 in doSpreadKey (DE=0x8bfd040, key=<value optimized out>, event=0xbfed68d8) at dataentry.c:1828
> 
> It is generated by XmbLookupString and Xutf8LookupString because
> this doesn't make Input context of X11 when dataeditor is View.
> 
> static char *GetCharP(DEEvent * event)
> {
>      <snip>
>             XmbLookupString(ioic, (XKeyEvent *)event, /* ioic at view
> time is NULL*/
>                             text, sizeof(text) - clength,
>                             &iokey, &status);
>      <snip>
> }
> 
> I think that this only has to limit GetCharP to isEditor=TRUE.
> moreover View() was strange operation of  "page down".
> 
> 
> http://prs.ism.ac.jp/~nakama/working/dataentry.patch
> 
> I think that I improve the above-mentioned by this patch.
> 


-- 
Ben Bolker
Associate professor, Biology Dep't, Univ. of Florida
bolker at ufl.edu / www.zoology.ufl.edu/bolker
GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 260 bytes
Desc: OpenPGP digital signature
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090513/61120f08/attachment.bin>

From rapatel0 at gmail.com  Wed May 13 18:48:35 2009
From: rapatel0 at gmail.com (Ravi Patel)
Date: Wed, 13 May 2009 12:48:35 -0400
Subject: [Rd] [R] rmath.h functions reentrant
Message-ID: <a99ff03f0905130948p317f861er125000ad6c170772@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090513/fc06c3cc/attachment.pl>

From mdowle at mdowle.plus.com  Wed May 13 22:17:17 2009
From: mdowle at mdowle.plus.com (Matthew Dowle)
Date: Wed, 13 May 2009 21:17:17 +0100
Subject: [Rd] Can we generate exe file using R? What is the maximum file
	size valid?
References: <9dddb5a60905061645u764d319dhbb5d3e5489e8aa8d@mail.gmail.com>
	<4A02C4AF.3090203@statistik.tu-dortmund.de>
Message-ID: <guf9tn$s60$1@ger.gmane.org>


Does Ra get close to compiled R ?   "The R code is compiled on the fly to 
bytecode which is executed internally by an interpreter in C."  The timing 
tests look impressive.
http://www.milbo.users.sonic.net/ra/


From macrakis at gmail.com  Wed May 13 22:40:09 2009
From: macrakis at gmail.com (Stavros Macrakis)
Date: Wed, 13 May 2009 16:40:09 -0400
Subject: [Rd] Can we generate exe file using R? What is the maximum file
	size valid?
In-Reply-To: <guf9tn$s60$1@ger.gmane.org>
References: <9dddb5a60905061645u764d319dhbb5d3e5489e8aa8d@mail.gmail.com>
	<4A02C4AF.3090203@statistik.tu-dortmund.de>
	<guf9tn$s60$1@ger.gmane.org>
Message-ID: <8b356f880905131340t7d83c21fr47ce2cac0b17a86c@mail.gmail.com>

There are two distinct and orthogonal questions here:

1) Is it possible to package an R program/system in such a way that it
can be distributed as a single executable file (including the R
system, any necessary loaded packages, plus the application program)
and run without an installation of R (which sets up library
directories etc.)?

2) Is it possible to compile R to bytecodes or machine language?

The answers to these questions are independent.  It is perfectly
possible to have an interpreted system which is distributed as a
single executable file (using e.g. unexec to save the fully-loaded
state).  It is also perfectly possible to have a compiled system which
requires configuration of library directories etc.

I believe the original question on this thread was about (1), but I am
not certain.  It also appears that the answer to (1) is 'no', but I am
not certain about that either.  I wouldn't think that it would be
impossible to add 'unexec' to R, but I don't know R's internals.

           -s

On Wed, May 13, 2009 at 4:17 PM, Matthew Dowle <mdowle at mdowle.plus.com> wrote:
>
> Does Ra get close to compiled R ? ? "The R code is compiled on the fly to
> bytecode which is executed internally by an interpreter in C." ?The timing
> tests look impressive.
> http://www.milbo.users.sonic.net/ra/
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From gostan at igmm.cnrs.fr  Wed May 13 14:35:12 2009
From: gostan at igmm.cnrs.fr (gostan at igmm.cnrs.fr)
Date: Wed, 13 May 2009 14:35:12 +0200 (CEST)
Subject: [Rd] simple add error (PR#13699)
Message-ID: <20090513123512.32DFE282C768@mail.pubhealth.ku.dk>

Full_Name: Gostan Thierry
Version: 2.6.1 (2007-11-26)
OS: Windows XP
Submission from: (NULL) (193.49.190.42)


I cannot explain why R seems to have problems adding two big numbers.

sprintf("%f",10^4+10^19) gives "10000000000000010240.000000" 
                    instead of "10000000000000010000.000000"

problems seems to arrive when i'm trying to add a big and a small number...


From klaus.nordhausen at uta.fi  Tue May 12 12:30:21 2009
From: klaus.nordhausen at uta.fi (Klaus Nordhausen)
Date: Tue, 12 May 2009 13:30:21 +0300
Subject: [Rd] different results on linux and windows
Message-ID: <4A094FBD.3080709@uta.fi>

Dear R experts,

we are preparing an R-package to compute the Oja Median which contains
some C++ code in which random numbers are needed. To generate the random
numbers we use the following Mersenne-Twister implementation:

// MersenneTwister.h
// Mersenne Twister random number generator -- a C++ class MTRand
// Based on code by Makoto Matsumoto, Takuji Nishimura, and Shawn Cokus
// Richard J. Wagner  v1.0  15 May 2003  rjwagner at writeme.com

the random seed for the Mersenne-Twister is provided by our R-function
which gives an (random) integer to  the C++ function srand() which in
turn sets the seed in the code.

Using the set.seed in R makes now the results reproducible, but the
results differ between windows and linux.

Does anyone know what the problem there is?

Our suspicion is that the reason is that some libraries are different
implemented on linux and windows (XP) compilers.

After the program start we set the seed in row 447(vkm.cpp) with srand(int);

When the median will be calculated, an intern seed is set with unsigned
  int seed = rand();   ( in row 100 (vkm.cpp)). This seed will be used
to calculate some random subsets and to
create a Mersenne Twister object with MTRand rr(seed);  (row 156, vkm.cpp).

The MTRand Object rr is called with an unsigned Integer, so the
important function in the mersenneTwister.h class is in line 87:
MTRand( const uint32& oneSeed );

According to that the Random Number Generator uses the methods
initialize(oneSeed); and reload();  (inside the method, beginning in
line 215)

This both methods (line 283 and line 301) are using beside others
registers. Could it be that there is a different behavior between
Windows and Linux?

We do not want to use only srand() since we might need more then the
number of pseudo random numbers that algorithm can provide.

For those interested and which would like to see the code, a first
version of the package, called OjaMedian, is available as source file
and windows binary on my homepage:
http://www.uta.fi/~klaus.nordhausen/down.html

The problem is in the ojaMedian function when the evolutionary algorithm
is used. Involved C++-files are mainly vkm.cpp and MersenneTwister.h.

We would be very grateful for any advice on how to solve this problem.
(below is also a demonstration)

Thank you very much in advance,

Klaus

Results on windows XP:

Compiler used: gcc version 4.2.1-sjlj (mingw32-2)

> library(OjaMedian)
> set.seed(1)
> testD <- rmvnorm(20,c(0,0))
> summary(testD)
        V1                V2
  Min.   :-2.2147   Min.   :-1.989352
  1st Qu.:-0.3844   1st Qu.:-0.399466
  Median : 0.3597   Median :-0.054967
  Mean   : 0.1905   Mean   :-0.006472
  3rd Qu.: 0.7590   3rd Qu.: 0.655663
  Max.   : 1.5953   Max.   : 1.358680
> set.seed(1)
> ojaMedian(testD)
[1]  0.21423705 -0.05799643
> sessionInfo()
R version 2.9.0 (2009-04-17)
i386-pc-mingw32

locale:
LC_COLLATE=Finnish_Finland.1252;LC_CTYPE=Finnish_Finland.1252;LC_MONETARY=Finnish_Finland.1252;LC_NUMERIC=C;LC_TIME=Finnish_Finland.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] OjaMedian_0.0-14 ICSNP_1.0-3      ICS_1.2-1        survey_3.14
[5] mvtnorm_0.9-5

loaded via a namespace (and not attached):
[1] tools_2.9.0
>

Results on Linux Kubuntu 8.10
result of: cat /proc/version:
Linux version 2.6.28-11-generic (buildd at palmer) (gcc version 4.3.3
(Ubuntu 4.3.3-5ubuntu4) ) #42-Ubuntu SMP Fri Apr 17 01:57:59 UTC 2009

> library(OjaMedian)
>  set.seed(1)
>  testD <- rmvnorm(20,c(0,0))
>  summary(testD)

        V1                V2
  Min.   :-2.2147   Min.   :-1.989352
  1st Qu.:-0.3844   1st Qu.:-0.399466
  Median : 0.3597   Median :-0.054967
  Mean   : 0.1905   Mean   :-0.006472
  3rd Qu.: 0.7590   3rd Qu.: 0.655663
  Max.   : 1.5953   Max.   : 1.358680

> set.seed(1)
>  ojaMedian(testD)

(-0.501381, 0.193929)[1] 0.119149071 0.002732100

> sessionInfo()

R version 2.8.1 (2008-12-22)
i486-pc-linux-gnu

locale:
LC_CTYPE=en_US.UTF-8;LC_NUMERIC=C;LC_TIME=en_US.UTF-8;LC_COLLATE=en_US.UTF-8;LC_MONETARY=C;LC_MESSAGES=en_US.UTF-8;LC_PAPER=en_US.UTF-8;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=en_US.UTF-8;LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] OjaMedian_0.0-14 ICSNP_1.0-3      ICS_1.2-1        survey_3.14
[5] mvtnorm_0.9-5





-- 
Klaus Nordhausen
Researcher
Tampere School of Public Health
FIN-33014 University of Tampere

phone:	+358 3 3551 4153
fax:	+358 3 3551 4150
e-mail:	Klaus.Nordhausen at uta.fi


From josh.m.ulrich at gmail.com  Thu May 14 00:08:28 2009
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Wed, 13 May 2009 17:08:28 -0500
Subject: [Rd] simple add error (PR#13699)
In-Reply-To: <20090513123512.32DFE282C768@mail.pubhealth.ku.dk>
References: <20090513123512.32DFE282C768@mail.pubhealth.ku.dk>
Message-ID: <8cca69990905131508ve1b96d7h67ce7ffadfbf5745@mail.gmail.com>

Gostan,

This is not a bug.  You're asking for 20 decimal digits of precision,
which is impossible with double-precision floating point arithmetic.

http://fr.wikipedia.org/wiki/Virgule_flottante

Best,
Josh
--
http://www.fosstrading.com



On Wed, May 13, 2009 at 7:35 AM,  <gostan at igmm.cnrs.fr> wrote:
> Full_Name: Gostan Thierry
> Version: 2.6.1 (2007-11-26)
> OS: Windows XP
> Submission from: (NULL) (193.49.190.42)
>
>
> I cannot explain why R seems to have problems adding two big numbers.
>
> sprintf("%f",10^4+10^19) gives "10000000000000010240.000000"
> ? ? ? ? ? ? ? ? ? ?instead of "10000000000000010000.000000"
>
> problems seems to arrive when i'm trying to add a big and a small number...
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From bolker at ufl.edu  Thu May 14 00:20:33 2009
From: bolker at ufl.edu (Ben Bolker)
Date: Wed, 13 May 2009 15:20:33 -0700 (PDT)
Subject: [Rd] simple add error (PR#13699)
In-Reply-To: <20090513123512.32DFE282C768@mail.pubhealth.ku.dk>
References: <20090513123512.32DFE282C768@mail.pubhealth.ku.dk>
Message-ID: <23531057.post@talk.nabble.com>




gostan wrote:
> 
> Full_Name: Gostan Thierry
> Version: 2.6.1 (2007-11-26)
> OS: Windows XP
> Submission from: (NULL) (193.49.190.42)
> 
> I cannot explain why R seems to have problems adding two big numbers.
> 
> sprintf("%f",10^4+10^19) gives "10000000000000010240.000000" 
>                     instead of "10000000000000010000.000000"
> 
> problems seems to arrive when i'm trying to add a big and a small
> number...
> 

  I can't give you the exact answer here -- someone else may chime in with
more details -- but the basic problem is that you are reaching the limits of
double precision arithmetic -- see ?.Machine , which gives 

double.eps: the smallest positive floating-point number 'x' such that
          '1 + x != 1'.  It equals 'base^ulp.digits' if either 'base'
          is 2 or 'rounding' is 0;  otherwise, it is '(base^ulp.digits)
          / 2'.  Normally '2.220446e-16'.

  I can't say exactly why things get wonky at 10^4+10^18 (I would have
guessed you 
would be good for another order of magnitude), but that's just my
ignorance/unwilling
to think about numerical computation more carefully at the moment.

Check out various threads on the mailing lists about bc and yacas (although
I'm not sure if yacas runs on Windows or not).

  Ben Bolker

-- 
View this message in context: http://www.nabble.com/simple-add-error-%28PR-13699%29-tp23530242p23531057.html
Sent from the R devel mailing list archive at Nabble.com.


From savicky at cs.cas.cz  Thu May 14 08:35:21 2009
From: savicky at cs.cas.cz (Petr Savicky)
Date: Thu, 14 May 2009 08:35:21 +0200
Subject: [Rd] simple add error (PR#13699)
In-Reply-To: <20090513123512.32DFE282C768@mail.pubhealth.ku.dk>
References: <20090513123512.32DFE282C768@mail.pubhealth.ku.dk>
Message-ID: <20090514063521.GB16502@cs.cas.cz>

On Wed, May 13, 2009 at 02:35:12PM +0200, gostan at igmm.cnrs.fr wrote:
> I cannot explain why R seems to have problems adding two big numbers.
> 
> sprintf("%f",10^4+10^19) gives "10000000000000010240.000000" 
>                     instead of "10000000000000010000.000000"
> 
> problems seems to arrive when i'm trying to add a big and a small number...

There are already two correct answers to your problem. If you are interested
in more detail, it is as follows. The number 10^4+10^19 is in binary
  1000101011000111001000110000010010001001111010000010011100010000
It has 60 significant binary digits. Machine representation (double precision)
rounds numbers to 53 significant digits, so in binary representation, it becomes
  1000101011000111001000110000010010001001111010000010100000000000
which is 10000000000000010240 in decimal.

So, the problem is not specific to R, but to floating point numbers in general.
Floating point numbers with 53 digits are used for efficiency. If you need more
accurate arithmetic on the cost of a remarkable slow down, use a computer
algebra system. Some of them are even accessible from R, see
  http://wiki.r-project.org/rwiki/doku.php?id=misc:r_accuracy

Petr.


From friedrich.leisch at stat.uni-muenchen.de  Thu May 14 09:33:08 2009
From: friedrich.leisch at stat.uni-muenchen.de (Friedrich Leisch)
Date: Thu, 14 May 2009 09:33:08 +0200
Subject: [Rd] different results on linux and windows
In-Reply-To: <4A094FBD.3080709@uta.fi>
References: <4A094FBD.3080709@uta.fi>
Message-ID: <18955.51508.342442.705944@lxh5.stat.uni-muenchen.de>

>>>>> On Tue, 12 May 2009 13:30:21 +0300,
>>>>> Klaus Nordhausen (KN) wrote:

  > Dear R experts,
  > we are preparing an R-package to compute the Oja Median which contains
  > some C++ code in which random numbers are needed. To generate the random
  > numbers we use the following Mersenne-Twister implementation:

  > // MersenneTwister.h
  > // Mersenne Twister random number generator -- a C++ class MTRand
  > // Based on code by Makoto Matsumoto, Takuji Nishimura, and Shawn Cokus
  > // Richard J. Wagner  v1.0  15 May 2003  rjwagner at writeme.com

  > the random seed for the Mersenne-Twister is provided by our R-function
  > which gives an (random) integer to  the C++ function srand() which in
  > turn sets the seed in the code.

  > Using the set.seed in R makes now the results reproducible, but the
  > results differ between windows and linux.

  > Does anyone know what the problem there is?

[...]

I cannot directly help with the problem, but one quick question: Why
do you ship your own random number generator rather than use the one
that ships with R (which by default is Mersenne Twister anyway)? The
API is documented in "Writing R Extensions".

The advantage in using R's RNG is that the user can change it, e.g.,
to take care of streams for parallel processing on clusters etc

Best,
Fritz

-- 
-----------------------------------------------------------------------
Prof. Dr. Friedrich Leisch 

Institut f?r Statistik                          Tel: (+49 89) 2180 3165
Ludwig-Maximilians-Universit?t                  Fax: (+49 89) 2180 5308
Ludwigstra?e 33
D-80539 M?nchen                     http://www.statistik.lmu.de/~leisch
-----------------------------------------------------------------------
   Journal Computational Statistics --- http://www.springer.com/180 
          M?nchner R Kurse --- http://www.statistik.lmu.de/R


From kjell.konis at epfl.ch  Thu May 14 09:39:25 2009
From: kjell.konis at epfl.ch (Kjell Konis)
Date: Thu, 14 May 2009 09:39:25 +0200
Subject: [Rd] different results on linux and windows
In-Reply-To: <4A094FBD.3080709@uta.fi>
References: <4A094FBD.3080709@uta.fi>
Message-ID: <A3BD9DEB-46D7-4047-B89C-9050294A47C9@epfl.ch>

Hi Klaus,

Why not just use R's random number generator? See section 6.3 of  
Writing R Extensions. It should give you the same sequence of  
pseudorandom numbers on all platforms.

HTH,
Kjell

On 12 mai 09, at 12:30, Klaus Nordhausen wrote:

> Dear R experts,
>
> we are preparing an R-package to compute the Oja Median which contains
> some C++ code in which random numbers are needed. To generate the  
> random
> numbers we use the following Mersenne-Twister implementation:
>
> // MersenneTwister.h
> // Mersenne Twister random number generator -- a C++ class MTRand
> // Based on code by Makoto Matsumoto, Takuji Nishimura, and Shawn  
> Cokus
> // Richard J. Wagner  v1.0  15 May 2003  rjwagner at writeme.com
>
> the random seed for the Mersenne-Twister is provided by our R-function
> which gives an (random) integer to  the C++ function srand() which in
> turn sets the seed in the code.
>
> Using the set.seed in R makes now the results reproducible, but the
> results differ between windows and linux.
>
> Does anyone know what the problem there is?
>
> Our suspicion is that the reason is that some libraries are different
> implemented on linux and windows (XP) compilers.
>
> After the program start we set the seed in row 447(vkm.cpp) with  
> srand(int);
>
> When the median will be calculated, an intern seed is set with  
> unsigned
>  int seed = rand();   ( in row 100 (vkm.cpp)). This seed will be used
> to calculate some random subsets and to
> create a Mersenne Twister object with MTRand rr(seed);  (row 156,  
> vkm.cpp).
>
> The MTRand Object rr is called with an unsigned Integer, so the
> important function in the mersenneTwister.h class is in line 87:
> MTRand( const uint32& oneSeed );
>
> According to that the Random Number Generator uses the methods
> initialize(oneSeed); and reload();  (inside the method, beginning in
> line 215)
>
> This both methods (line 283 and line 301) are using beside others
> registers. Could it be that there is a different behavior between
> Windows and Linux?
>
> We do not want to use only srand() since we might need more then the
> number of pseudo random numbers that algorithm can provide.
>
> For those interested and which would like to see the code, a first
> version of the package, called OjaMedian, is available as source file
> and windows binary on my homepage:
> http://www.uta.fi/~klaus.nordhausen/down.html
>
> The problem is in the ojaMedian function when the evolutionary  
> algorithm
> is used. Involved C++-files are mainly vkm.cpp and MersenneTwister.h.
>
> We would be very grateful for any advice on how to solve this problem.
> (below is also a demonstration)
>
> Thank you very much in advance,
>
> Klaus
>
> Results on windows XP:
>
> Compiler used: gcc version 4.2.1-sjlj (mingw32-2)
>
>> library(OjaMedian)
>> set.seed(1)
>> testD <- rmvnorm(20,c(0,0))
>> summary(testD)
>        V1                V2
>  Min.   :-2.2147   Min.   :-1.989352
>  1st Qu.:-0.3844   1st Qu.:-0.399466
>  Median : 0.3597   Median :-0.054967
>  Mean   : 0.1905   Mean   :-0.006472
>  3rd Qu.: 0.7590   3rd Qu.: 0.655663
>  Max.   : 1.5953   Max.   : 1.358680
>> set.seed(1)
>> ojaMedian(testD)
> [1]  0.21423705 -0.05799643
>> sessionInfo()
> R version 2.9.0 (2009-04-17)
> i386-pc-mingw32
>
> locale:
> LC_COLLATE=Finnish_Finland.1252;LC_CTYPE=Finnish_Finland. 
> 1252;LC_MONETARY=Finnish_Finland. 
> 1252;LC_NUMERIC=C;LC_TIME=Finnish_Finland.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] OjaMedian_0.0-14 ICSNP_1.0-3      ICS_1.2-1        survey_3.14
> [5] mvtnorm_0.9-5
>
> loaded via a namespace (and not attached):
> [1] tools_2.9.0
>>
>
> Results on Linux Kubuntu 8.10
> result of: cat /proc/version:
> Linux version 2.6.28-11-generic (buildd at palmer) (gcc version 4.3.3
> (Ubuntu 4.3.3-5ubuntu4) ) #42-Ubuntu SMP Fri Apr 17 01:57:59 UTC 2009
>
>> library(OjaMedian)
>> set.seed(1)
>> testD <- rmvnorm(20,c(0,0))
>> summary(testD)
>
>        V1                V2
>  Min.   :-2.2147   Min.   :-1.989352
>  1st Qu.:-0.3844   1st Qu.:-0.399466
>  Median : 0.3597   Median :-0.054967
>  Mean   : 0.1905   Mean   :-0.006472
>  3rd Qu.: 0.7590   3rd Qu.: 0.655663
>  Max.   : 1.5953   Max.   : 1.358680
>
>> set.seed(1)
>> ojaMedian(testD)
>
> (-0.501381, 0.193929)[1] 0.119149071 0.002732100
>
>> sessionInfo()
>
> R version 2.8.1 (2008-12-22)
> i486-pc-linux-gnu
>
> locale:
> LC_CTYPE 
> = 
> en_US 
> .UTF 
> -8 
> ;LC_NUMERIC 
> = 
> C 
> ;LC_TIME 
> = 
> en_US 
> .UTF 
> -8 
> ;LC_COLLATE 
> = 
> en_US 
> .UTF 
> -8 
> ;LC_MONETARY 
> = 
> C 
> ;LC_MESSAGES 
> = 
> en_US 
> .UTF 
> -8 
> ;LC_PAPER 
> = 
> en_US 
> .UTF 
> -8 
> ;LC_NAME 
> = 
> C 
> ;LC_ADDRESS 
> =C;LC_TELEPHONE=C;LC_MEASUREMENT=en_US.UTF-8;LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] OjaMedian_0.0-14 ICSNP_1.0-3      ICS_1.2-1        survey_3.14
> [5] mvtnorm_0.9-5
>
>
>
>
>
> -- 
> Klaus Nordhausen
> Researcher
> Tampere School of Public Health
> FIN-33014 University of Tampere
>
> phone:	+358 3 3551 4153
> fax:	+358 3 3551 4150
> e-mail:	Klaus.Nordhausen at uta.fi
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From nakama at ki.rim.or.jp  Thu May 14 09:49:28 2009
From: nakama at ki.rim.or.jp (Ei-ji Nakama)
Date: Thu, 14 May 2009 16:49:28 +0900
Subject: [Rd] different results on linux and windows
In-Reply-To: <4A094FBD.3080709@uta.fi>
References: <4A094FBD.3080709@uta.fi>
Message-ID: <dc41e1260905140049j25aa9df9j9663700cc24659f9@mail.gmail.com>

Hi

2009/5/12 Klaus Nordhausen <klaus.nordhausen at uta.fi>:
> Our suspicion is that the reason is that some libraries are different
> implemented on linux and windows (XP) compilers.

If useful.

http://www.derkeiler.com/Newsgroups/sci.crypt/2004-10/1325.html

I think that you do not like to use rand and srand.
-- 
EI-JI Nakama  <nakama (a) ki.rim.or.jp>
"\u4e2d\u9593\u6804\u6cbb"  <nakama (a) ki.rim.or.jp>


From pgilbert at bank-banque-canada.ca  Thu May 14 16:20:20 2009
From: pgilbert at bank-banque-canada.ca (Paul Gilbert)
Date: Thu, 14 May 2009 10:20:20 -0400
Subject: [Rd] different results on linux and windows
In-Reply-To: <4A094FBD.3080709@uta.fi>
References: <4A094FBD.3080709@uta.fi>
Message-ID: <4A0C28A4.2040208@bank-banque-canada.ca>

I cannot say what the problem is in your code, but in general it is 
possible to get the same random sequences from Linux and Windows with 
R's Mersenne Twister generator.  If you generate long sequences (say 10s 
of thousands) and then start doing comparisons involving remainders, 
like differencing the sums of two mean zero sequences, then differences 
between libraries will show up. I have found bigger differences between 
Linux variants than I have between Windows and most Linuxes.

Paul Gilbert

Klaus Nordhausen wrote:
> Dear R experts,
> 
> we are preparing an R-package to compute the Oja Median which contains
> some C++ code in which random numbers are needed. To generate the random
> numbers we use the following Mersenne-Twister implementation:
> 
> // MersenneTwister.h
> // Mersenne Twister random number generator -- a C++ class MTRand
> // Based on code by Makoto Matsumoto, Takuji Nishimura, and Shawn Cokus
> // Richard J. Wagner  v1.0  15 May 2003  rjwagner at writeme.com
> 
> the random seed for the Mersenne-Twister is provided by our R-function
> which gives an (random) integer to  the C++ function srand() which in
> turn sets the seed in the code.
> 
> Using the set.seed in R makes now the results reproducible, but the
> results differ between windows and linux.
> 
> Does anyone know what the problem there is?
> 
> Our suspicion is that the reason is that some libraries are different
> implemented on linux and windows (XP) compilers.
> 
> After the program start we set the seed in row 447(vkm.cpp) with 
> srand(int);
> 
> When the median will be calculated, an intern seed is set with unsigned
>  int seed = rand();   ( in row 100 (vkm.cpp)). This seed will be used
> to calculate some random subsets and to
> create a Mersenne Twister object with MTRand rr(seed);  (row 156, vkm.cpp).
> 
> The MTRand Object rr is called with an unsigned Integer, so the
> important function in the mersenneTwister.h class is in line 87:
> MTRand( const uint32& oneSeed );
> 
> According to that the Random Number Generator uses the methods
> initialize(oneSeed); and reload();  (inside the method, beginning in
> line 215)
> 
> This both methods (line 283 and line 301) are using beside others
> registers. Could it be that there is a different behavior between
> Windows and Linux?
> 
> We do not want to use only srand() since we might need more then the
> number of pseudo random numbers that algorithm can provide.
> 
> For those interested and which would like to see the code, a first
> version of the package, called OjaMedian, is available as source file
> and windows binary on my homepage:
> http://www.uta.fi/~klaus.nordhausen/down.html
> 
> The problem is in the ojaMedian function when the evolutionary algorithm
> is used. Involved C++-files are mainly vkm.cpp and MersenneTwister.h.
> 
> We would be very grateful for any advice on how to solve this problem.
> (below is also a demonstration)
> 
> Thank you very much in advance,
> 
> Klaus
> 
> Results on windows XP:
> 
> Compiler used: gcc version 4.2.1-sjlj (mingw32-2)
> 
>> library(OjaMedian)
>> set.seed(1)
>> testD <- rmvnorm(20,c(0,0))
>> summary(testD)
>        V1                V2
>  Min.   :-2.2147   Min.   :-1.989352
>  1st Qu.:-0.3844   1st Qu.:-0.399466
>  Median : 0.3597   Median :-0.054967
>  Mean   : 0.1905   Mean   :-0.006472
>  3rd Qu.: 0.7590   3rd Qu.: 0.655663
>  Max.   : 1.5953   Max.   : 1.358680
>> set.seed(1)
>> ojaMedian(testD)
> [1]  0.21423705 -0.05799643
>> sessionInfo()
> R version 2.9.0 (2009-04-17)
> i386-pc-mingw32
> 
> locale:
> LC_COLLATE=Finnish_Finland.1252;LC_CTYPE=Finnish_Finland.1252;LC_MONETARY=Finnish_Finland.1252;LC_NUMERIC=C;LC_TIME=Finnish_Finland.1252 
> 
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> other attached packages:
> [1] OjaMedian_0.0-14 ICSNP_1.0-3      ICS_1.2-1        survey_3.14
> [5] mvtnorm_0.9-5
> 
> loaded via a namespace (and not attached):
> [1] tools_2.9.0
>>
> 
> Results on Linux Kubuntu 8.10
> result of: cat /proc/version:
> Linux version 2.6.28-11-generic (buildd at palmer) (gcc version 4.3.3
> (Ubuntu 4.3.3-5ubuntu4) ) #42-Ubuntu SMP Fri Apr 17 01:57:59 UTC 2009
> 
>> library(OjaMedian)
>>  set.seed(1)
>>  testD <- rmvnorm(20,c(0,0))
>>  summary(testD)
> 
>        V1                V2
>  Min.   :-2.2147   Min.   :-1.989352
>  1st Qu.:-0.3844   1st Qu.:-0.399466
>  Median : 0.3597   Median :-0.054967
>  Mean   : 0.1905   Mean   :-0.006472
>  3rd Qu.: 0.7590   3rd Qu.: 0.655663
>  Max.   : 1.5953   Max.   : 1.358680
> 
>> set.seed(1)
>>  ojaMedian(testD)
> 
> (-0.501381, 0.193929)[1] 0.119149071 0.002732100
> 
>> sessionInfo()
> 
> R version 2.8.1 (2008-12-22)
> i486-pc-linux-gnu
> 
> locale:
> LC_CTYPE=en_US.UTF-8;LC_NUMERIC=C;LC_TIME=en_US.UTF-8;LC_COLLATE=en_US.UTF-8;LC_MONETARY=C;LC_MESSAGES=en_US.UTF-8;LC_PAPER=en_US.UTF-8;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=en_US.UTF-8;LC_IDENTIFICATION=C 
> 
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> other attached packages:
> [1] OjaMedian_0.0-14 ICSNP_1.0-3      ICS_1.2-1        survey_3.14
> [5] mvtnorm_0.9-5
> 
> 
> 
> 
> 
====================================================================================

La version fran?aise suit le texte anglais.

------------------------------------------------------------------------------------

This email may contain privileged and/or confidential in...{{dropped:26}}


From plamote at its.jnj.com  Thu May 14 16:39:58 2009
From: plamote at its.jnj.com (Philippe Lamote)
Date: Thu, 14 May 2009 16:39:58 +0200
Subject: [Rd] R & Java
Message-ID: <C631F9DE.5B5A%plamote@its.jnj.com>

Hey guys, 

I'm a (Java) integration architect.
We are currently stuck with SAS but I'd be happy to switch that to R! (of
course ;-).
Now, a big argument for the latter, is that we can integrate it seamlessly
with all our existing (java) apps.
Therefore: has anyone heard of a java API (like SAS has it's Java API for
enterprise integration) or a Service we can call (e.g. a web service, a http
invoker service , ...), ... ?

The ideal solution -to my view- would be to integrate it with ESB
functionality (e.g. Mule: http://www.mulesource.org/display/COMMUNITY/Home).
It allows you to stitch/knit/... together what/how/where you want.

Has anyone ever done such a thing?
Thx for advice, 

Regards, 
Philippe

__________________________________________________

Philippe Lamote
Technology Lead @TSSC - Johnson & Johnson Pharmaceutical R&D
<Software Architect && System Design/>
<Tel (32 +14)60-5735 | Loc: Beerse-1 ~ B073-R006/>


From spencer.graves at prodsyse.com  Thu May 14 18:03:22 2009
From: spencer.graves at prodsyse.com (spencerg)
Date: Thu, 14 May 2009 09:03:22 -0700
Subject: [Rd] R & Java
In-Reply-To: <C631F9DE.5B5A%plamote@its.jnj.com>
References: <C631F9DE.5B5A%plamote@its.jnj.com>
Message-ID: <4A0C40CA.7060803@prodsyse.com>

      I don't have an answer, but I suspect that if you 
install.packages("RSiteSearch"), you might find information relevant to 
your question from the following: 


 library(RSiteSearch)
java <- RSiteSearch.function('Java')
summary(java)
# Reports that 136 help pages contained "Java", 23 of which are in a 
package "rJava", 16 in "R.utils", etc. 
HTML(java)
# Opens a table with 136 rows in a browser,
# with the "rJava" pages first, followed by those in "R.utils", etc.,
# the last column of which contains links to the HTML versions of the 
help pages. 


      Hope this helps. 
      Spencer Graves


Philippe Lamote wrote:
> Hey guys, 
>
> I'm a (Java) integration architect.
> We are currently stuck with SAS but I'd be happy to switch that to R! (of
> course ;-).
> Now, a big argument for the latter, is that we can integrate it seamlessly
> with all our existing (java) apps.
> Therefore: has anyone heard of a java API (like SAS has it's Java API for
> enterprise integration) or a Service we can call (e.g. a web service, a http
> invoker service , ...), ... ?
>
> The ideal solution -to my view- would be to integrate it with ESB
> functionality (e.g. Mule: http://www.mulesource.org/display/COMMUNITY/Home).
> It allows you to stitch/knit/... together what/how/where you want.
>
> Has anyone ever done such a thing?
> Thx for advice, 
>
> Regards, 
> Philippe
>
> __________________________________________________
>
> Philippe Lamote
> Technology Lead @TSSC - Johnson & Johnson Pharmaceutical R&D
> <Software Architect && System Design/>
> <Tel (32 +14)60-5735 | Loc: Beerse-1 ~ B073-R006/>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From edd at debian.org  Thu May 14 18:05:45 2009
From: edd at debian.org (Dirk Eddelbuettel)
Date: Thu, 14 May 2009 11:05:45 -0500
Subject: [Rd] R & Java
In-Reply-To: <C631F9DE.5B5A%plamote@its.jnj.com>
References: <C631F9DE.5B5A%plamote@its.jnj.com>
Message-ID: <18956.16729.329889.805062@ron.nulle.part>


On 14 May 2009 at 16:39, Philippe Lamote wrote:
| I'm a (Java) integration architect.
| We are currently stuck with SAS but I'd be happy to switch that to R! (of
| course ;-).
| Now, a big argument for the latter, is that we can integrate it seamlessly
| with all our existing (java) apps.
| Therefore: has anyone heard of a java API (like SAS has it's Java API for
| enterprise integration) or a Service we can call (e.g. a web service, a http
| invoker service , ...), ... ?

http://lmgtfy.com/?q=R+Java+rJava

I don't do Java personally but there is a lot out there (and I do support
rJava for Debian and hence indirectly on Ubuntu). See the links above and
also google for BioCep which a lot of people dig.

Dirk

-- 
Three out of two people have difficulties with fractions.


From seija.sirkia at metla.fi  Thu May 14 13:59:27 2009
From: seija.sirkia at metla.fi (=?ISO-8859-1?Q?Seija_Sirki=E4?=)
Date: Thu, 14 May 2009 14:59:27 +0300
Subject: [Rd] using a "third party" DLL in my package
Message-ID: <4A0C079F.7080101@metla.fi>

Hello all,

it seems my efforts in reading the manuals and help files aren't enough 
so here I am. The question is, how would I go about linking a 
pre-compiled DLL in to my package? I have previously successfully built 
packages with Fortran and C source code, but now I'd like to take this 
ready made DLL and call its routines from R.

My collegue was brave enough to simply try and put the DLL in src folder 
of the package and proceed with building and installing the same way as 
if it had been source code. And it works, on my computer and his. 
Clearly this isn't exactly portable, and while that's ok for the use we 
have in mind (we both work on Windows XP) I have a nagging feeling this 
is somehow criminal or unwise at least.

Why I want to do this might explain it a bit further but in fact the 
background contains another problem and I welcome anyone to give hints 
about that too.

So, we have some Fortran code from way back which deals with fitting 
taper curves for tree boles, and some other functions related to that. 
We wanted to make these available for use in R and I made a package with 
simple wrapper functions for the .Fortran calls, and built it with the 
help of the compiler in Rtools. All was fine until my collegue managed 
to bump in to a combination of parameters (tree species, height and 
breast height diameter) with which the computation freezes. We traced it 
to a certain very simple iteration in the Fortran code that finds the 
height at which the tree has a given diameter. I could give more details 
on that, but the point is that the very same computation goes through 
just fine when executed "fully" in Fortran, with the routines and an 
interface compiled with another Fortran compiler. And also when that 
compiler is used to make a DLL and that DLL is used within the R package 
in the way I described above.

In summary, what we seem to have here is a compiler dependent 
convergence problem. Possible solutions are to figure out what's wrong 
with the computation - and I've pretty much exhausted my skills on that 
- or to figure out how to use a working DLL, as was my first question.

Great big thanks in advance to anyone with advice!

Seija Sirki?,
senior researcher (statistics), Finnish forestry research institute


From michael.m.spiegel at gmail.com  Thu May 14 15:45:09 2009
From: michael.m.spiegel at gmail.com (michael.m.spiegel at gmail.com)
Date: Thu, 14 May 2009 15:45:09 +0200 (CEST)
Subject: [Rd] diag() has a bug (PR#13702)
Message-ID: <20090514134509.58502282BE82@mail.pubhealth.ku.dk>

Full_Name: Michael Spiegel
Version: 2.9.0
OS: linux
Submission from: (NULL) (204.111.252.142)


The diag() function appears to reject the first argument when it is a matrix,
and nrow and ncol arguments are also provided.

> foo <- matrix(c(1:4),2,2)
> foo
     [,1] [,2]
[1,]    1    3
[2,]    2    4
> diag(foo)
[1] 1 4
> diag(foo, 2, 2)
Error in diag(foo, 2, 2) : first argument is array, but not matrix.
> is.matrix(foo)
[1] TRUE


From RVaradhan at jhmi.edu  Thu May 14 16:04:32 2009
From: RVaradhan at jhmi.edu (Ravi Varadhan)
Date: Thu, 14 May 2009 10:04:32 -0400
Subject: [Rd] Homotopy package in R - Developmental help needed. Was: RE:
	[R] newtons method
In-Reply-To: <23535875.post@talk.nabble.com>
References: <BLU141-W99CD55B1136A29102C958CD600@phx.gbl>
	<4A09725B.3070209@uottawa.ca>
	<4A09784E.70108@statistik.tu-dortmund.de>
	<003701c9d31d$35447140$7c94100a@win.ad.jhu.edu>
	<23535875.post@talk.nabble.com>
Message-ID: <002801c9d49c$e7826940$7c94100a@win.ad.jhu.edu>

Dear Hans,

Thanks for your interest in homotopy methods.  I have been looking at L.T.
Watson's HOMPACK suite (written in Fortran) for solving nonlinear systems
(finding all the roots).  This is available in netlib, and since it is
written in Fortran, it should be relatively easily interfaceable with R.  

http://www.netlib.org/hompack/

I have been meaning to ask for help from the R development group for help
with creating this package, but due to severe time constraints, have not
been able to do that.  But here it is now!  Hence, I am moving this to
r-develop mailing list.

I would love to get help from you and anyone else on translating HOMPACK
into an R package.  If you or anyone else is interested, please send me an
email.

Best,
Ravi.

----------------------------------------------------------------------------
-------

Ravi Varadhan, Ph.D.

Assistant Professor, The Center on Aging and Health

Division of Geriatric Medicine and Gerontology 

Johns Hopkins University

Ph: (410) 502-2619

Fax: (410) 614-9625

Email: rvaradhan at jhmi.edu

Webpage:  http://www.jhsph.edu/agingandhealth/People/Faculty/Varadhan.html

 

----------------------------------------------------------------------------
--------


-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On
Behalf Of Hans W. Borchers
Sent: Thursday, May 14, 2009 3:46 AM
To: r-help at r-project.org
Subject: Re: [R] newtons method


Dear Ravi:

Thanks for pointing out the homotopy methods. Coming from Mathematics I was
always considering SINGULAR for such a task which is also providing results
when the solution set is not isolated points, but an algebraic variety. 

For single points, homotopy methods appear to be an effective approach. I am
wondering if it will be worth to integrate Jan Verschelde's free PHCpack
algorithm, see <http://www.math.uic.edu/~jan/>, as a package into R -- if
there would be enough interest.

Best regards,  Hans Werner Borchers



Ravi Varadhan wrote:
> 
> Uwe,
> 
> John's comment about the difficulties with finding polynomial roots is 
> even more forceful for a system of polynomials.  There are likely 
> numerous roots, some possibly real, and some possibly multiple.  
> Homotopy methods are currrently the state-of-art for finding "all" the 
> roots, but beware that
> they are very time-consuming.   For locating the real roots, I have found
> that a relatively simple approach like "multiple random starts" works 
> failrly well with a root-finder such as dfsane() in the "BB" package.
> However, I don't know of any tests to check whether I have found all 
> the roots.
> 
> Ravi.
> 
> ----------------------------------------------------------------------
> ------
> -------
> 
> Ravi Varadhan, Ph.D.
> 
> Assistant Professor, The Center on Aging and Health
> 
> Division of Geriatric Medicine and Gerontology
> 
> Johns Hopkins University
> 
> Ph: (410) 502-2619
> 
> Fax: (410) 614-9625
> 
> Email: rvaradhan at jhmi.edu
> 
> Webpage:  
> http://www.jhsph.edu/agingandhealth/People/Faculty/Varadhan.html
> 
> 

--
View this message in context:
http://www.nabble.com/newtons-method-tp23498698p23535875.html
Sent from the R help mailing list archive at Nabble.com.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From alexdamour at gmail.com  Thu May 14 17:26:43 2009
From: alexdamour at gmail.com (Alex D'Amour)
Date: Thu, 14 May 2009 11:26:43 -0400
Subject: [Rd] R & Java
In-Reply-To: <C631F9DE.5B5A%plamote@its.jnj.com>
References: <C631F9DE.5B5A%plamote@its.jnj.com>
Message-ID: <2ffd32cb0905140826w32a9b1aay1cfc15a358179bac@mail.gmail.com>

I think you are looking for something like RServe. http://rosuda.org/Rserve/.

It sets up R as a server which you talk to via TCP/IP. It has client
APIs for Java and a number of other languages.

Alex

On Thu, May 14, 2009 at 10:39 AM, Philippe Lamote <plamote at its.jnj.com> wrote:
> Hey guys,
>
> I'm a (Java) integration architect.
> We are currently stuck with SAS but I'd be happy to switch that to R! (of
> course ;-).
> Now, a big argument for the latter, is that we can integrate it seamlessly
> with all our existing (java) apps.
> Therefore: has anyone heard of a java API (like SAS has it's Java API for
> enterprise integration) or a Service we can call (e.g. a web service, a http
> invoker service , ...), ... ?
>
> The ideal solution -to my view- would be to integrate it with ESB
> functionality (e.g. Mule: http://www.mulesource.org/display/COMMUNITY/Home).
> It allows you to stitch/knit/... together what/how/where you want.
>
> Has anyone ever done such a thing?
> Thx for advice,
>
> Regards,
> Philippe
>
> __________________________________________________
>
> Philippe Lamote
> Technology Lead @TSSC - Johnson & Johnson Pharmaceutical R&D
> <Software Architect && System Design/>
> <Tel (32 +14)60-5735 | Loc: Beerse-1 ~ B073-R006/>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From bcarvalh at jhsph.edu  Thu May 14 21:24:06 2009
From: bcarvalh at jhsph.edu (Benilton Carvalho)
Date: Thu, 14 May 2009 16:24:06 -0300
Subject: [Rd] diag() has a bug (PR#13702)
In-Reply-To: <20090514134509.58502282BE82@mail.pubhealth.ku.dk>
References: <20090514134509.58502282BE82@mail.pubhealth.ku.dk>
Message-ID: <47C259F5-83A3-4476-8E23-D67018FE91A8@jhsph.edu>

My understanding is that providing nrow and ncol, you want to create a  
diagonal matrix with those dimensions.

diag(pi, 6, 6)

and that by

diag(foo, 2, 2)

you really meant

diag(foo)[2]

Apologies if I misunderstood.

b

On May 14, 2009, at 10:45 AM, michael.m.spiegel at gmail.com wrote:

> Full_Name: Michael Spiegel
> Version: 2.9.0
> OS: linux
> Submission from: (NULL) (204.111.252.142)
>
>
> The diag() function appears to reject the first argument when it is  
> a matrix,
> and nrow and ncol arguments are also provided.
>
>> foo <- matrix(c(1:4),2,2)
>> foo
>     [,1] [,2]
> [1,]    1    3
> [2,]    2    4
>> diag(foo)
> [1] 1 4
>> diag(foo, 2, 2)
> Error in diag(foo, 2, 2) : first argument is array, but not matrix.
>> is.matrix(foo)
> [1] TRUE
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From bcarvalh at jhsph.edu  Thu May 14 21:35:14 2009
From: bcarvalh at jhsph.edu (Benilton Carvalho)
Date: Thu, 14 May 2009 16:35:14 -0300
Subject: [Rd] diag() has a bug (PR#13702)
In-Reply-To: <1901f69e0905141230l79d71494ra985e767b08b828d@mail.gmail.com>
References: <20090514134509.58502282BE82@mail.pubhealth.ku.dk>
	<47C259F5-83A3-4476-8E23-D67018FE91A8@jhsph.edu>
	<1901f69e0905141230l79d71494ra985e767b08b828d@mail.gmail.com>
Message-ID: <CBE46617-5AFB-4EA5-AA67-C1D07FFB0052@jhsph.edu>

in that case, wouldn't

diag(diag(foo))

suffice?

b

On May 14, 2009, at 4:30 PM, Michael Spiegel wrote:

> The intent of diag(foo, 2, 2) was to return a matrix that is a 2 x 2  
> matrix which contains only the diagonal entries of the matrix foo.   
> I can't do diag(foo) because this returns a vector.  I could reach  
> my goal with matrix(diag(foo), nrow = nrow(foo), ncol = ncol(foo)).   
> If this is not a reasonable thing for diag(<matrix>, <numeric>,  
> <numeric>) to return, then at the very least the error message  
> should be changed, as the first argument is in fact a matrix.
>
> On Thu, May 14, 2009 at 3:24 PM, Benilton Carvalho  
> <bcarvalh at jhsph.edu> wrote:
> My understanding is that providing nrow and ncol, you want to create  
> a diagonal matrix with those dimensions.
>
> diag(pi, 6, 6)
>
> and that by
>
> diag(foo, 2, 2)
>
> you really meant
>
> diag(foo)[2]
>
> Apologies if I misunderstood.
>
> b
>
> On May 14, 2009, at 10:45 AM, michael.m.spiegel at gmail.com wrote:
>
> Full_Name: Michael Spiegel
> Version: 2.9.0
> OS: linux
> Submission from: (NULL) (204.111.252.142)
>
>
> The diag() function appears to reject the first argument when it is  
> a matrix,
> and nrow and ncol arguments are also provided.
>
> foo <- matrix(c(1:4),2,2)
> foo
>    [,1] [,2]
> [1,]    1    3
> [2,]    2    4
> diag(foo)
> [1] 1 4
> diag(foo, 2, 2)
> Error in diag(foo, 2, 2) : first argument is array, but not matrix.
> is.matrix(foo)
> [1] TRUE
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From p.dalgaard at biostat.ku.dk  Thu May 14 22:42:11 2009
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Thu, 14 May 2009 22:42:11 +0200
Subject: [Rd] diag() has a bug (PR#13702)
In-Reply-To: <CBE46617-5AFB-4EA5-AA67-C1D07FFB0052@jhsph.edu>
References: <20090514134509.58502282BE82@mail.pubhealth.ku.dk>	<47C259F5-83A3-4476-8E23-D67018FE91A8@jhsph.edu>	<1901f69e0905141230l79d71494ra985e767b08b828d@mail.gmail.com>
	<CBE46617-5AFB-4EA5-AA67-C1D07FFB0052@jhsph.edu>
Message-ID: <4A0C8223.2000604@biostat.ku.dk>

Benilton Carvalho wrote:
> in that case, wouldn't
> 
> diag(diag(foo))
> 
> suffice?

Yes (beware the length 1 case, though).

However, don't delete the bug report. That error message is just wrong:

     if (is.array(x) && length(dim(x)) != 1L)
         stop("first argument is array, but not matrix.")


> 
> b
> 
> On May 14, 2009, at 4:30 PM, Michael Spiegel wrote:
> 
>> The intent of diag(foo, 2, 2) was to return a matrix that is a 2 x 2 
>> matrix which contains only the diagonal entries of the matrix foo.  I 
>> can't do diag(foo) because this returns a vector.  I could reach my 
>> goal with matrix(diag(foo), nrow = nrow(foo), ncol = ncol(foo)).  If 
>> this is not a reasonable thing for diag(<matrix>, <numeric>, 
>> <numeric>) to return, then at the very least the error message should 
>> be changed, as the first argument is in fact a matrix.
>>
>> On Thu, May 14, 2009 at 3:24 PM, Benilton Carvalho 
>> <bcarvalh at jhsph.edu> wrote:
>> My understanding is that providing nrow and ncol, you want to create a 
>> diagonal matrix with those dimensions.
>>
>> diag(pi, 6, 6)
>>
>> and that by
>>
>> diag(foo, 2, 2)
>>
>> you really meant
>>
>> diag(foo)[2]
>>
>> Apologies if I misunderstood.
>>
>> b
>>
>> On May 14, 2009, at 10:45 AM, michael.m.spiegel at gmail.com wrote:
>>
>> Full_Name: Michael Spiegel
>> Version: 2.9.0
>> OS: linux
>> Submission from: (NULL) (204.111.252.142)
>>
>>
>> The diag() function appears to reject the first argument when it is a 
>> matrix,
>> and nrow and ncol arguments are also provided.
>>
>> foo <- matrix(c(1:4),2,2)
>> foo
>>    [,1] [,2]
>> [1,]    1    3
>> [2,]    2    4
>> diag(foo)
>> [1] 1 4
>> diag(foo, 2, 2)
>> Error in diag(foo, 2, 2) : first argument is array, but not matrix.
>> is.matrix(foo)
>> [1] TRUE
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
> 
> 
> ------------------------------------------------------------------------
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
    O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
   c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
  (*) \(*) -- University of Copenhagen   Denmark      Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)              FAX: (+45) 35327907


From pauljohn32 at gmail.com  Thu May 14 23:10:08 2009
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Thu, 14 May 2009 16:10:08 -0500
Subject: [Rd] will one of you help me advocate a change in t.test (patch
	attached)
Message-ID: <13e802630905141410q52461e05q7f7c0e291ce3b5e2@mail.gmail.com>

I wish the t.test function in stats would return the standard error.
It would be nicer for students if R simply reported the standard error
used to calculate the t value.  I trolled for this in r-help and got
no answers, which I interpreted to mean that this is boring but
possibly not wrong.  Hopefully.

I believe only simple changes are needed.

In the source code src/library/stats/t.test.R file:

at the bottom of the first function,  where the return value list is set:

  rval <- list(statistic = tstat, parameter = df, p.value = pval,
        conf.int = cint, estimate = estimate, null.value = mu,
        alternative = alternative, method = method, data.name = dname)

I wish that   "stderr = stderr" could be inserted after "estimate = estimate".

I *believe* after studying the source code it is necessary to
introduce a name for the stderr element in the list.

names(stderr) <- "standard error"

If I could get that much put in, I would be happy. But to make this
really helpful, the htest.R file's "print.htest" function needs to
check for the presence of stderr. Based on what htest.R has now, I
think it needs:


  if(!is.null(x$stderr))
	out <- c(out, paste(names(x$stderr), "=",
			    format(round(x$stderr, 3))))


I am attaching a patch file that will make these changes if it is
applied to the R-2.9.0 tree.

pj


-- 
Paul E. Johnson
Professor, Political Science
1541 Lilac Lane, Room 504
University of Kansas
-------------- next part --------------
A non-text attachment was scrubbed...
Name: t.test-patch.diff
Type: text/x-patch
Size: 1886 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090514/14b13e28/attachment.bin>

From michael.m.spiegel at gmail.com  Thu May 14 21:30:09 2009
From: michael.m.spiegel at gmail.com (Michael Spiegel)
Date: Thu, 14 May 2009 15:30:09 -0400
Subject: [Rd] diag() has a bug (PR#13702)
In-Reply-To: <47C259F5-83A3-4476-8E23-D67018FE91A8@jhsph.edu>
References: <20090514134509.58502282BE82@mail.pubhealth.ku.dk>
	<47C259F5-83A3-4476-8E23-D67018FE91A8@jhsph.edu>
Message-ID: <1901f69e0905141230l79d71494ra985e767b08b828d@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090514/83e0eb06/attachment.pl>

From pauljohn at ku.edu  Thu May 14 21:35:15 2009
From: pauljohn at ku.edu (pauljohn at ku.edu)
Date: Thu, 14 May 2009 21:35:15 +0200 (CEST)
Subject: [Rd] plot ignores type= "n" when x is factor (PR#13703)
Message-ID: <20090514193515.9BC3528320DF@mail.pubhealth.ku.dk>

Full_Name: Paul E. Johnson
Version: 2.9.1
OS: Linux (Ubuntu 9.04)
Submission from: (NULL) (129.237.61.25)


x <- gl(2,50)
y <- rnorm(100)
plot(x,y)
plot(x,y, type="n")


I *wish* the last one would draw a blank plot box w/axes, but it does not. It
fills in the middle with a box plot. I've not seen this problem when x is
numeric.


From michael.m.spiegel at gmail.com  Thu May 14 21:41:07 2009
From: michael.m.spiegel at gmail.com (Michael Spiegel)
Date: Thu, 14 May 2009 15:41:07 -0400
Subject: [Rd] diag() has a bug (PR#13702)
In-Reply-To: <CBE46617-5AFB-4EA5-AA67-C1D07FFB0052@jhsph.edu>
References: <20090514134509.58502282BE82@mail.pubhealth.ku.dk>
	<47C259F5-83A3-4476-8E23-D67018FE91A8@jhsph.edu>
	<1901f69e0905141230l79d71494ra985e767b08b828d@mail.gmail.com>
	<CBE46617-5AFB-4EA5-AA67-C1D07FFB0052@jhsph.edu>
Message-ID: <1901f69e0905141241n31efd292hc6ba3b9be15663a2@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090514/d441dab5/attachment.pl>

From ripley at stats.ox.ac.uk  Fri May 15 10:23:38 2009
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 15 May 2009 09:23:38 +0100 (BST)
Subject: [Rd] using a "third party" DLL in my package
In-Reply-To: <4A0C079F.7080101@metla.fi>
References: <4A0C079F.7080101@metla.fi>
Message-ID: <alpine.LFD.2.00.0905150905560.4378@gannet.stats.ox.ac.uk>

On Thu, 14 May 2009, Seija Sirki? wrote:

> Hello all,
>
> it seems my efforts in reading the manuals and help files aren't enough so 
> here I am. The question is, how would I go about linking a pre-compiled DLL 
> in to my package? I have previously successfully built packages with Fortran 
> and C source code, but now I'd like to take this ready made DLL and call its 
> routines from R.
>
> My collegue was brave enough to simply try and put the DLL in src folder of 
> the package and proceed with building and installing the same way as if it 
> had been source code. And it works, on my computer and his. Clearly this 
> isn't exactly portable, and while that's ok for the use we have in mind (we 
> both work on Windows XP) I have a nagging feeling this is somehow criminal or 
> unwise at least.

Unwise, since it is unsupported and might stop working at any time. 
Actually, you don't mention the version of R you used and (without 
checking) I think this may not work in all recent versions of R.

What you can so is to have an 'inst/libs' directory in your package 
sources, and put the DLL you want to use there.  Another approach 
(used in a few CRAN packages) is to use 'configure.win' to copy the 
DLL to a 'libs' directory in the installed package.  A third approach 
is to have a 'src/Makefile.win' that creates the DLL you want 
(possibly by just checking it is present in 'src', but also possiby by 
calling the mysterious Fortran compiler X you obliquely mention 
below).

> Why I want to do this might explain it a bit further but in fact the 
> background contains another problem and I welcome anyone to give hints about 
> that too.
>
> So, we have some Fortran code from way back which deals with fitting taper 
> curves for tree boles, and some other functions related to that. We wanted to 
> make these available for use in R and I made a package with simple wrapper 
> functions for the .Fortran calls, and built it with the help of the compiler 
> in Rtools. All was fine until my collegue managed to bump in to a combination 
> of parameters (tree species, height and breast height diameter) with which 
> the computation freezes. We traced it to a certain very simple iteration in 
> the Fortran code that finds the height at which the tree has a given 
> diameter. I could give more details on that, but the point is that the very 
> same computation goes through just fine when executed "fully" in Fortran, 
> with the routines and an interface compiled with another Fortran compiler. 
> And also when that compiler is used to make a DLL and that DLL is used within 
> the R package in the way I described above.
>
> In summary, what we seem to have here is a compiler dependent convergence 
> problem. Possible solutions are to figure out what's wrong with the 
> computation - and I've pretty much exhausted my skills on that - or to figure 
> out how to use a working DLL, as was my first question.

My concern would be that there are different cases that fail under 
Fortran compiler X and you are just sweeping the problem under the 
carpet.

>
> Great big thanks in advance to anyone with advice!
>
> Seija Sirki?,
> senior researcher (statistics), Finnish forestry research institute

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From peter.ruckdeschel at web.de  Fri May 15 14:10:21 2009
From: peter.ruckdeschel at web.de (Peter Ruckdeschel)
Date: Fri, 15 May 2009 14:10:21 +0200
Subject: [Rd] Problem building (binary) packages for Windows
Message-ID: <4A0D5BAD.9050608@web.de>

Hi,

I am having a problem building binary packages for
Windows recently.

Normally, I use the "Murdoch-Sutherland" tool set,
       http://www.murdoch-sutherland.com/Rtools/
just build source packages by
       R CMD build <pkgname>
and install these with
       R CMD INSTALL <pkgname>

But now, for someone without having this tool set installed,
under Win XP, with R-2.10dev (details below), I tried
building a binary version with
       R CMD build --binary <pkgname>
which used to work for me until recently (unfortunately I
cannot specify "recently" here...)

Trying to install the created .zip file with
       utils:::menuInstallLocal()

I get an error message
"
package 'distr' successfully unpacked and MD5 sums checked
Error in unpackPkg(pkgs[i], pkgnames[i], lib) :
  malformed bundle DESCRIPTION file, no Contains field
"

Now AFAICS I have not tried to build a bundle ...

Searching the help archives, I found a posting by Uwe Ligges,
       http://article.gmane.org/gmane.comp.lang.r.general/64574/
saying that
       R CMD INSTALL --build
was preferable to
       R CMD build --binary
--- in which respect? Would this avoid the error message?

So far I have not come across this error message, and
packages I built with
       R CMD build --binary
installed correctly with
       utils:::menuInstallLocal()

Actually, the corresponding zip-file containes
a second DESCRIPTION file in the top folder, like a
bundle, which I think is the culpit, and after
deleting this installation worked out fine.

Could you please check what caused this second
DESCRIPTION file to be generated?

Any suggestions welcome,

Best, Peter

--------------------------------------------------
platform       i386-pc-mingw32

arch           i386

os             mingw32

system         i386, mingw32

status         Under development (unstable)

major          2

minor          10.0

year           2009

month          04

day            26

svn rev        48404

language       R

version.string R version 2.10.0 Under development (unstable) (2009-04-26
r48404)


From murdoch at stats.uwo.ca  Fri May 15 14:50:05 2009
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri, 15 May 2009 08:50:05 -0400
Subject: [Rd] Problem building (binary) packages for Windows
In-Reply-To: <4A0D5BAD.9050608@web.de>
References: <4A0D5BAD.9050608@web.de>
Message-ID: <4A0D64FD.9030200@stats.uwo.ca>

On 5/15/2009 8:10 AM, Peter Ruckdeschel wrote:
> Hi,
> 
> I am having a problem building binary packages for
> Windows recently.
> 
> Normally, I use the "Murdoch-Sutherland" tool set,
>        http://www.murdoch-sutherland.com/Rtools/
> just build source packages by
>        R CMD build <pkgname>
> and install these with
>        R CMD INSTALL <pkgname>
> 
> But now, for someone without having this tool set installed,
> under Win XP, with R-2.10dev (details below), I tried
> building a binary version with
>        R CMD build --binary <pkgname>
> which used to work for me until recently (unfortunately I
> cannot specify "recently" here...)
> 
> Trying to install the created .zip file with
>        utils:::menuInstallLocal()
> 
> I get an error message
> "
> package 'distr' successfully unpacked and MD5 sums checked
> Error in unpackPkg(pkgs[i], pkgnames[i], lib) :
>   malformed bundle DESCRIPTION file, no Contains field
> "
> 
> Now AFAICS I have not tried to build a bundle ...
> 
> Searching the help archives, I found a posting by Uwe Ligges,
>        http://article.gmane.org/gmane.comp.lang.r.general/64574/
> saying that
>        R CMD INSTALL --build
> was preferable to
>        R CMD build --binary
> --- in which respect? Would this avoid the error message?

The main benefit is that links between help pages will be more likely to 
be set correctly.

> 
> So far I have not come across this error message, and
> packages I built with
>        R CMD build --binary
> installed correctly with
>        utils:::menuInstallLocal()
> 
> Actually, the corresponding zip-file containes
> a second DESCRIPTION file in the top folder, like a
> bundle, which I think is the culpit, and after
> deleting this installation worked out fine.
> 
> Could you please check what caused this second
> DESCRIPTION file to be generated?

You can't have two files with the same name in the same folder in 
Windows.  However, Windows Explorer by default hides file extensions, so 
it may look as though you do.  Was the file you deleted called 
DESCRIPTION.in?

I use Rcmd INSTALL --build most of the time and have never seen your 
error.  I just tried Rcmd build --binary and the file installed okay. 
Can you give a recipe to reproduce the error?

Duncan Murdoch

> 
> Any suggestions welcome,
> 
> Best, Peter
> 
> --------------------------------------------------
> platform       i386-pc-mingw32
> 
> arch           i386
> 
> os             mingw32
> 
> system         i386, mingw32
> 
> status         Under development (unstable)
> 
> major          2
> 
> minor          10.0
> 
> year           2009
> 
> month          04
> 
> day            26
> 
> svn rev        48404
> 
> language       R
> 
> version.string R version 2.10.0 Under development (unstable) (2009-04-26
> r48404)
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From ggrothendieck at gmail.com  Fri May 15 15:11:49 2009
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 15 May 2009 09:11:49 -0400
Subject: [Rd] Mac and tcltk
Message-ID: <971536df0905150611ta03d7a3y7b82a3558e7589ff@mail.gmail.com>

Does the Mac version of R include tcltk?   There is a section in the R Mac FAQ:
http://cran.r-project.org/bin/macosx/RMacOSX-FAQ.html#TclTk-issues
about tcltk issues on R for Mac but its not clear to me from this
whether tcltk is
or is not included and I don't have a Mac to try it out.


From marc_schwartz at me.com  Fri May 15 15:24:37 2009
From: marc_schwartz at me.com (Marc Schwartz)
Date: Fri, 15 May 2009 08:24:37 -0500
Subject: [Rd] Mac and tcltk
In-Reply-To: <971536df0905150611ta03d7a3y7b82a3558e7589ff@mail.gmail.com>
References: <971536df0905150611ta03d7a3y7b82a3558e7589ff@mail.gmail.com>
Message-ID: <97014337-E777-4028-90AF-00CBA43FE4FF@me.com>

On May 15, 2009, at 8:11 AM, Gabor Grothendieck wrote:

> Does the Mac version of R include tcltk?   There is a section in the  
> R Mac FAQ:
> http://cran.r-project.org/bin/macosx/RMacOSX-FAQ.html#TclTk-issues
> about tcltk issues on R for Mac but its not clear to me from this
> whether tcltk is
> or is not included and I don't have a Mac to try it out.


Gabor, the full universal binary disk image (.dmg) does include tcl/tk  
if the user installs R that way. The 'mini' image does not, so would  
require the user to install tcl/tk separately.

More info here:

   http://cran.r-project.org/bin/macosx/

Supplemental tools for OSX, including tcl/tk, are available from:

   http://cran.r-project.org/bin/macosx/tools/

One can of course also build from source code on OSX, which is what I  
do. More information on that approach is at:

   http://r.research.att.com/building.html

and

   http://r.research.att.com/tools/


HTH,

Marc Schwartz


From ripley at stats.ox.ac.uk  Fri May 15 15:53:49 2009
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 15 May 2009 14:53:49 +0100 (BST)
Subject: [Rd] Problem building (binary) packages for Windows
In-Reply-To: <4A0D5BAD.9050608@web.de>
References: <4A0D5BAD.9050608@web.de>
Message-ID: <alpine.OSX.1.00.0905151445270.59770@tystie.local>

That version of R-devel is not current, so please update it.  I think 
it might have been in an interval where we tried out verious fixes for 
building bundles and some of them broke other things.

In general if you use R-devel or R-patched you need to update before 
reporting any difficulties.  'Under development' needs to be taken 
seriously.

On Fri, 15 May 2009, Peter Ruckdeschel wrote:

> Hi,
>
> I am having a problem building binary packages for
> Windows recently.
>
> Normally, I use the "Murdoch-Sutherland" tool set,
>       http://www.murdoch-sutherland.com/Rtools/
> just build source packages by
>       R CMD build <pkgname>
> and install these with
>       R CMD INSTALL <pkgname>
>
> But now, for someone without having this tool set installed,
> under Win XP, with R-2.10dev (details below), I tried
> building a binary version with
>       R CMD build --binary <pkgname>
> which used to work for me until recently (unfortunately I
> cannot specify "recently" here...)
>
> Trying to install the created .zip file with
>       utils:::menuInstallLocal()
>
> I get an error message
> "
> package 'distr' successfully unpacked and MD5 sums checked
> Error in unpackPkg(pkgs[i], pkgnames[i], lib) :
>  malformed bundle DESCRIPTION file, no Contains field
> "
>
> Now AFAICS I have not tried to build a bundle ...
>
> Searching the help archives, I found a posting by Uwe Ligges,
>       http://article.gmane.org/gmane.comp.lang.r.general/64574/
> saying that
>       R CMD INSTALL --build
> was preferable to
>       R CMD build --binary
> --- in which respect? Would this avoid the error message?

That's rather old as well: now the second calls the first on Windows. 
What may matter is whether you specify -l on R CMD INSTALL --build (R 
CMD build --binary does), as installing into the main library does a 
better job of resolving HTML cross links.

So the advice is to use R CMD INSTALL --build *and* install into the 
main library (or the library where you install all your add-on 
packages).

> So far I have not come across this error message, and
> packages I built with
>       R CMD build --binary
> installed correctly with
>       utils:::menuInstallLocal()
>
> Actually, the corresponding zip-file containes
> a second DESCRIPTION file in the top folder, like a
> bundle, which I think is the culpit, and after
> deleting this installation worked out fine.
>
> Could you please check what caused this second
> DESCRIPTION file to be generated?
>
> Any suggestions welcome,
>
> Best, Peter
>
> --------------------------------------------------
> platform       i386-pc-mingw32
>
> arch           i386
>
> os             mingw32
>
> system         i386, mingw32
>
> status         Under development (unstable)
>
> major          2
>
> minor          10.0
>
> year           2009
>
> month          04
>
> day            26
>
> svn rev        48404
>
> language       R
>
> version.string R version 2.10.0 Under development (unstable) (2009-04-26
> r48404)
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From peter.ruckdeschel at web.de  Fri May 15 16:34:46 2009
From: peter.ruckdeschel at web.de (Peter Ruckdeschel)
Date: Fri, 15 May 2009 16:34:46 +0200
Subject: [Rd] Problem building (binary) packages for Windows / resolved
In-Reply-To: <4A0D64FD.9030200@stats.uwo.ca>
References: <4A0D5BAD.9050608@web.de> <4A0D64FD.9030200@stats.uwo.ca>
Message-ID: <4A0D7D86.8000005@web.de>

Hi Dunchan,

thanks for your quick answer.

>> Searching the help archives, I found a posting by Uwe Ligges,
>>        http://article.gmane.org/gmane.comp.lang.r.general/64574/
>> saying that
>>        R CMD INSTALL --build
>> was preferable to
>>        R CMD build --binary
>> --- in which respect? Would this avoid the error message?
>
> The main benefit is that links between help pages will be more likely
> to be set correctly.
Thank you for clarifying this; in fact
          R CMD INSTALL --build
produced the same problem for me (see below).

[snip]
>> Actually, the corresponding zip-file containes
>> a second DESCRIPTION file in the top folder, like a
>> bundle, which I think is the culpit, and after
>> deleting this installation worked out fine.
[snip]
> You can't have two files with the same name in the same folder in
> Windows. 
Yes, but this is not what happened:

The zip file produced by either
            R CMD build --binary    or     R CMD INSTALL --build
had the following folder structure
(below the top folder, "+" indicating subfolder)

+<pkgname>
++chtml
++demo
.....
++R
++R-ex

The two DESCRIPTION files were in different folders:
the first one in the top folder (at the wrong place), the second
one in the <pkgname> folder (at the right place).
Both DESCRIPTION files were identical.
> I use Rcmd INSTALL --build most of the time and have never seen your
> error. 
so did I....

> I just tried Rcmd build --binary and the file installed okay.
> Can you give a recipe to reproduce the error?
In fact --- as Brian Ripley pointed out in another
reply --- this was a transient effect of R-2.10.0dev between
April 26 (my "old" devel version) and today.

It appeared for both
          R CMD build --binary mypkg
and
          R CMD INSTALL --build  mypkg

The problem did not happen for an older
devel version ---
R version 2.9.0 Under development (unstable) (2009-02-18 r47956)

So apologies for stirring you up with something that had been
fixed in the mean-time already.

Best, Peter


From peter.ruckdeschel at web.de  Fri May 15 16:35:50 2009
From: peter.ruckdeschel at web.de (Peter Ruckdeschel)
Date: Fri, 15 May 2009 16:35:50 +0200
Subject: [Rd] Problem building (binary) packages for Windows
In-Reply-To: <alpine.OSX.1.00.0905151445270.59770@tystie.local>
References: <4A0D5BAD.9050608@web.de>
	<alpine.OSX.1.00.0905151445270.59770@tystie.local>
Message-ID: <4A0D7DC6.50009@web.de>

Prof Brian Ripley schrieb:
> That version of R-devel is not current, so please update it.
> I think it might have been in an interval where we tried out
> verious fixes for building bundles and some of them broke
> other things.
Yes, I really should have updated; in fact the error re-disappeared
again using the most recent version.

--- But the fix must have happened within the last two weeks ....

In fact, before posting, I had a look at
                http://developer.r-project.org/blosxom.cgi/R-devel
but did not find anything that was pointing to the direction
that the problem had been solved in the period April 26
(release date of my "old" R-devel version) and
today.
Nor had I found anything pointing to either R CMD build
nor to bundles changed in the interval Feb 09 -- April 26,
but the error-causing changes must have happened within
this period ---

So my fault not having updated gratefully ackowledged, it would
also be nice to be somewhat more detailed in filling the
NEWS file then...

> In general if you use R-devel or R-patched you need to update before
> reporting any difficulties.  'Under development' needs to be taken
> seriously.
>
> On Fri, 15 May 2009, Peter Ruckdeschel wrote:
>
>> Hi,
>>
>> I am having a problem building binary packages for
>> Windows recently.
>>
>> Normally, I use the "Murdoch-Sutherland" tool set,
>>       http://www.murdoch-sutherland.com/Rtools/
>> just build source packages by
>>       R CMD build <pkgname>
>> and install these with
>>       R CMD INSTALL <pkgname>
>>
>> But now, for someone without having this tool set installed,
>> under Win XP, with R-2.10dev (details below), I tried
>> building a binary version with
>>       R CMD build --binary <pkgname>
>> which used to work for me until recently (unfortunately I
>> cannot specify "recently" here...)
>>
>> Trying to install the created .zip file with
>>       utils:::menuInstallLocal()
>>
>> I get an error message
>> "
>> package 'distr' successfully unpacked and MD5 sums checked
>> Error in unpackPkg(pkgs[i], pkgnames[i], lib) :
>>  malformed bundle DESCRIPTION file, no Contains field
>> "
>>
>> Now AFAICS I have not tried to build a bundle ...
>>
>> Searching the help archives, I found a posting by Uwe Ligges,
>>       http://article.gmane.org/gmane.comp.lang.r.general/64574/
>> saying that
>>       R CMD INSTALL --build
>> was preferable to
>>       R CMD build --binary
>> --- in which respect? Would this avoid the error message?
>
> That's rather old as well: now the second calls the first on Windows.
> What may matter is whether you specify -l on R CMD INSTALL --build
> (R CMD build --binary does), as installing into the main library does a
> better job of resolving HTML cross links.
>
> So the advice is to use R CMD INSTALL --build *and* install into the
> main library (or the library where you install all your add-on packages).
>
Thank you for clarifying this and once again apologies for stirring you
up with something that had been fixed in the mean-time already.

Best, Peter


From ripley at stats.ox.ac.uk  Fri May 15 17:42:40 2009
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 15 May 2009 16:42:40 +0100 (BST)
Subject: [Rd] View() crashy on Ubuntu 9.04
In-Reply-To: <dc41e1260905130055h2c7761bdv7608657be5fa479f@mail.gmail.com>
References: <4A0A0A64.6030706@ufl.edu>
	<18954.10612.51851.692033@ron.nulle.part>
	<556e90a80905121943o85a6d7et8862c940fafda773@mail.gmail.com>
	<18954.14509.928285.317516@ron.nulle.part>
	<dc41e1260905130055h2c7761bdv7608657be5fa479f@mail.gmail.com>
Message-ID: <alpine.LFD.2.00.0905151627240.5829@gannet.stats.ox.ac.uk>

Thank you, included in R-patched and R-devel now.

BTW, it looks like the original problem is in MBCS locales only, which 
postdate the X11 View() code (but we had patches from Mr Nakama: 
input contexts are needed for entering CJK languages).

I do wonder sometimes if people who only work with data in ASCII or in 
a Western European language covered by Latin-1 realize the extent of 
the overhead that using a UTF-8 locale implies, especially for the X11 
functionality.  I still use a Latin-1 locale on Linux much of the 
time.  There are a lot of optimizations in the R code for ASCII-only 
data, but rather fewer in the I/O areas.

On Wed, 13 May 2009, Ei-ji Nakama wrote:

> Hi
>
> 2009/5/13 Dirk Eddelbuettel <edd at debian.org>:
> <snip>
>> #0 ?0xb70e685e in XmbLookupString () from /usr/lib/libX11.so.6
>> #1 ?0xb73a9d48 in doSpreadKey (DE=0x8bfd040, key=<value optimized out>, event=0xbfed68d8) at dataentry.c:1828
>
> It is generated by XmbLookupString and Xutf8LookupString because
> this doesn't make Input context of X11 when dataeditor is View.
>
> static char *GetCharP(DEEvent * event)
> {
>     <snip>
>            XmbLookupString(ioic, (XKeyEvent *)event, /* ioic at view
> time is NULL*/
>                            text, sizeof(text) - clength,
>                            &iokey, &status);
>     <snip>
> }
>
> I think that this only has to limit GetCharP to isEditor=TRUE.
> moreover View() was strange operation of  "page down".
>
>
> http://prs.ism.ac.jp/~nakama/working/dataentry.patch
>
> I think that I improve the above-mentioned by this patch.
>
> -- 
> EI-JI Nakama  <nakama (a) ki.rim.or.jp>
> "\u4e2d\u9593\u6804\u6cbb"  <nakama (a) ki.rim.or.jp>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From pauljohn32 at gmail.com  Fri May 15 18:38:02 2009
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Fri, 15 May 2009 11:38:02 -0500
Subject: [Rd] will one of you help me advocate a change in t.test (patch
	attached)
In-Reply-To: <5c62e0070905150805t199452f7h46313020d8c2de91@mail.gmail.com>
References: <13e802630905141410q52461e05q7f7c0e291ce3b5e2@mail.gmail.com>
	<5c62e0070905150805t199452f7h46313020d8c2de91@mail.gmail.com>
Message-ID: <13e802630905150938o4acb940cqabcc621eb48009c0@mail.gmail.com>

On Fri, May 15, 2009 at 10:05 AM, Kevin W <kw.statr at gmail.com> wrote:
> My view from the sidelines....
>
> I think you have done the right thing to include a patch, but you have
> provided no justification for the patch in terms of why it would be useful.
>
> Sincerely,
>
> Kevin
>

Ah, I see. I thought it was obvious.  I think users should be able to
easily know the standard error when they do t.tests.

People who do t-tests sometimes need to discuss their findings, and
the standard error may be an important consideration.  While one can
(of course) recover the standard error by doing some division, it is
inconvenient and, at least in the classroom, on the border of tedious.

We allow regression printouts with several layers of redundant information--

b  se t p

We should not make it difficult for users to discern the standard
error that is actually used in the t.test procedure?

pj

-- 
Paul E. Johnson
Professor, Political Science
1541 Lilac Lane, Room 504
University of Kansas


From klaus.nordhausen at uta.fi  Fri May 15 13:23:07 2009
From: klaus.nordhausen at uta.fi (Klaus Nordhausen)
Date: Fri, 15 May 2009 14:23:07 +0300
Subject: [Rd] different results on linux and windows
In-Reply-To: <4A0C28A4.2040208@bank-banque-canada.ca>
References: <4A094FBD.3080709@uta.fi> <4A0C28A4.2040208@bank-banque-canada.ca>
Message-ID: <4A0D509B.9060200@uta.fi>

Thanks a lot for all the replies! We managed now to solve our problem by
replacing the rand / srand functions by R's random number generator and 
now the results on windows and linux agree.

Thanks again!

Klaus

Paul Gilbert wrote:
> I cannot say what the problem is in your code, but in general it is 
> possible to get the same random sequences from Linux and Windows with 
> R's Mersenne Twister generator.  If you generate long sequences (say 10s 
> of thousands) and then start doing comparisons involving remainders, 
> like differencing the sums of two mean zero sequences, then differences 
> between libraries will show up. I have found bigger differences between 
> Linux variants than I have between Windows and most Linuxes.
> 
> Paul Gilbert
> 
> Klaus Nordhausen wrote:
>> Dear R experts,
>>
>> we are preparing an R-package to compute the Oja Median which contains
>> some C++ code in which random numbers are needed. To generate the random
>> numbers we use the following Mersenne-Twister implementation:
>>
>> // MersenneTwister.h
>> // Mersenne Twister random number generator -- a C++ class MTRand
>> // Based on code by Makoto Matsumoto, Takuji Nishimura, and Shawn Cokus
>> // Richard J. Wagner  v1.0  15 May 2003  rjwagner at writeme.com
>>
>> the random seed for the Mersenne-Twister is provided by our R-function
>> which gives an (random) integer to  the C++ function srand() which in
>> turn sets the seed in the code.
>>
>> Using the set.seed in R makes now the results reproducible, but the
>> results differ between windows and linux.
>>
>> Does anyone know what the problem there is?
>>
>> Our suspicion is that the reason is that some libraries are different
>> implemented on linux and windows (XP) compilers.
>>
>> After the program start we set the seed in row 447(vkm.cpp) with 
>> srand(int);
>>
>> When the median will be calculated, an intern seed is set with unsigned
>>  int seed = rand();   ( in row 100 (vkm.cpp)). This seed will be used
>> to calculate some random subsets and to
>> create a Mersenne Twister object with MTRand rr(seed);  (row 156, 
>> vkm.cpp).
>>
>> The MTRand Object rr is called with an unsigned Integer, so the
>> important function in the mersenneTwister.h class is in line 87:
>> MTRand( const uint32& oneSeed );
>>
>> According to that the Random Number Generator uses the methods
>> initialize(oneSeed); and reload();  (inside the method, beginning in
>> line 215)
>>
>> This both methods (line 283 and line 301) are using beside others
>> registers. Could it be that there is a different behavior between
>> Windows and Linux?
>>
>> We do not want to use only srand() since we might need more then the
>> number of pseudo random numbers that algorithm can provide.
>>
>> For those interested and which would like to see the code, a first
>> version of the package, called OjaMedian, is available as source file
>> and windows binary on my homepage:
>> http://www.uta.fi/~klaus.nordhausen/down.html
>>
>> The problem is in the ojaMedian function when the evolutionary algorithm
>> is used. Involved C++-files are mainly vkm.cpp and MersenneTwister.h.
>>
>> We would be very grateful for any advice on how to solve this problem.
>> (below is also a demonstration)
>>
>> Thank you very much in advance,
>>
>> Klaus
>>
>> Results on windows XP:
>>
>> Compiler used: gcc version 4.2.1-sjlj (mingw32-2)
>>
>>> library(OjaMedian)
>>> set.seed(1)
>>> testD <- rmvnorm(20,c(0,0))
>>> summary(testD)
>>        V1                V2
>>  Min.   :-2.2147   Min.   :-1.989352
>>  1st Qu.:-0.3844   1st Qu.:-0.399466
>>  Median : 0.3597   Median :-0.054967
>>  Mean   : 0.1905   Mean   :-0.006472
>>  3rd Qu.: 0.7590   3rd Qu.: 0.655663
>>  Max.   : 1.5953   Max.   : 1.358680
>>> set.seed(1)
>>> ojaMedian(testD)
>> [1]  0.21423705 -0.05799643
>>> sessionInfo()
>> R version 2.9.0 (2009-04-17)
>> i386-pc-mingw32
>>
>> locale:
>> LC_COLLATE=Finnish_Finland.1252;LC_CTYPE=Finnish_Finland.1252;LC_MONETARY=Finnish_Finland.1252;LC_NUMERIC=C;LC_TIME=Finnish_Finland.1252 
>>
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> other attached packages:
>> [1] OjaMedian_0.0-14 ICSNP_1.0-3      ICS_1.2-1        survey_3.14
>> [5] mvtnorm_0.9-5
>>
>> loaded via a namespace (and not attached):
>> [1] tools_2.9.0
>>>
>>
>> Results on Linux Kubuntu 8.10
>> result of: cat /proc/version:
>> Linux version 2.6.28-11-generic (buildd at palmer) (gcc version 4.3.3
>> (Ubuntu 4.3.3-5ubuntu4) ) #42-Ubuntu SMP Fri Apr 17 01:57:59 UTC 2009
>>
>>> library(OjaMedian)
>>>  set.seed(1)
>>>  testD <- rmvnorm(20,c(0,0))
>>>  summary(testD)
>>
>>        V1                V2
>>  Min.   :-2.2147   Min.   :-1.989352
>>  1st Qu.:-0.3844   1st Qu.:-0.399466
>>  Median : 0.3597   Median :-0.054967
>>  Mean   : 0.1905   Mean   :-0.006472
>>  3rd Qu.: 0.7590   3rd Qu.: 0.655663
>>  Max.   : 1.5953   Max.   : 1.358680
>>
>>> set.seed(1)
>>>  ojaMedian(testD)
>>
>> (-0.501381, 0.193929)[1] 0.119149071 0.002732100
>>
>>> sessionInfo()
>>
>> R version 2.8.1 (2008-12-22)
>> i486-pc-linux-gnu
>>
>> locale:
>> LC_CTYPE=en_US.UTF-8;LC_NUMERIC=C;LC_TIME=en_US.UTF-8;LC_COLLATE=en_US.UTF-8;LC_MONETARY=C;LC_MESSAGES=en_US.UTF-8;LC_PAPER=en_US.UTF-8;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=en_US.UTF-8;LC_IDENTIFICATION=C 
>>
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> other attached packages:
>> [1] OjaMedian_0.0-14 ICSNP_1.0-3      ICS_1.2-1        survey_3.14
>> [5] mvtnorm_0.9-5
>>
>>
>>
>>
>>
> ==================================================================================== 
> 
> 
> La version fran?aise suit le texte anglais.
> 
> ------------------------------------------------------------------------------------ 
> 
> 
> This email may contain privileged and/or confidential information, and 
> the Bank of
> Canada does not waive any related rights. Any distribution, use, or 
> copying of this
> email or the information it contains by other than the intended 
> recipient is
> unauthorized. If you received this email in error please delete it 
> immediately from
> your system and notify the sender promptly by email that you have done so.
> ------------------------------------------------------------------------------------ 
> 
> 
> Le pr?sent courriel peut contenir de l'information privil?gi?e ou 
> confidentielle.
> La Banque du Canada ne renonce pas aux droits qui s'y rapportent. Toute 
> diffusion,
> utilisation ou copie de ce courriel ou des renseignements qu'il contient 
> par une
> personne autre que le ou les destinataires d?sign?s est interdite. Si 
> vous recevez
> ce courriel par erreur, veuillez le supprimer imm?diatement et envoyer 
> sans d?lai ?
> l'exp?diteur un message ?lectronique pour l'aviser que vous avez ?limin? 
> de votre
> ordinateur toute copie du courriel re?u.

-- 
Klaus Nordhausen
Researcher
Tampere School of Public Health
FIN-33014 University of Tampere

phone:	+358 3 3551 4153
fax:	+358 3 3551 4150
e-mail:	Klaus.Nordhausen at uta.fi


From ligges at statistik.tu-dortmund.de  Fri May 15 20:48:03 2009
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Fri, 15 May 2009 20:48:03 +0200
Subject: [Rd] Problem building (binary) packages for Windows
In-Reply-To: <4A0D7DC6.50009@web.de>
References: <4A0D5BAD.9050608@web.de>	<alpine.OSX.1.00.0905151445270.59770@tystie.local>
	<4A0D7DC6.50009@web.de>
Message-ID: <4A0DB8E3.9090107@statistik.tu-dortmund.de>



Peter Ruckdeschel wrote:
> Prof Brian Ripley schrieb:
>> That version of R-devel is not current, so please update it.
>> I think it might have been in an interval where we tried out
>> verious fixes for building bundles and some of them broke
>> other things.
> Yes, I really should have updated; in fact the error re-disappeared
> again using the most recent version.
> 
> --- But the fix must have happened within the last two weeks ....
> 
> In fact, before posting, I had a look at
>                 http://developer.r-project.org/blosxom.cgi/R-devel
> but did not find anything that was pointing to the direction
> that the problem had been solved in the period April 26
> (release date of my "old" R-devel version) and
> today.
> Nor had I found anything pointing to either R CMD build
> nor to bundles changed in the interval Feb 09 -- April 26,
> but the error-causing changes must have happened within
> this period ---
> 
> So my fault not having updated gratefully ackowledged, it would
> also be nice to be somewhat more detailed in filling the
> NEWS file then...
> 
>> In general if you use R-devel or R-patched you need to update before
>> reporting any difficulties.  'Under development' needs to be taken
>> seriously.
>>
>> On Fri, 15 May 2009, Peter Ruckdeschel wrote:
>>
>>> Hi,
>>>
>>> I am having a problem building binary packages for
>>> Windows recently.
>>>
>>> Normally, I use the "Murdoch-Sutherland" tool set,
>>>       http://www.murdoch-sutherland.com/Rtools/
>>> just build source packages by
>>>       R CMD build <pkgname>
>>> and install these with
>>>       R CMD INSTALL <pkgname>
>>>
>>> But now, for someone without having this tool set installed,
>>> under Win XP, with R-2.10dev (details below), I tried
>>> building a binary version with
>>>       R CMD build --binary <pkgname>
>>> which used to work for me until recently (unfortunately I
>>> cannot specify "recently" here...)
>>>
>>> Trying to install the created .zip file with
>>>       utils:::menuInstallLocal()
>>>
>>> I get an error message
>>> "
>>> package 'distr' successfully unpacked and MD5 sums checked
>>> Error in unpackPkg(pkgs[i], pkgnames[i], lib) :
>>>  malformed bundle DESCRIPTION file, no Contains field
>>> "
>>>
>>> Now AFAICS I have not tried to build a bundle ...
>>>
>>> Searching the help archives, I found a posting by Uwe Ligges,
>>>       http://article.gmane.org/gmane.comp.lang.r.general/64574/
>>> saying that
>>>       R CMD INSTALL --build
>>> was preferable to
>>>       R CMD build --binary
>>> --- in which respect? Would this avoid the error message?
>> That's rather old as well: now the second calls the first on Windows.
>> What may matter is whether you specify -l on R CMD INSTALL --build
>> (R CMD build --binary does), as installing into the main library does a
>> better job of resolving HTML cross links.
>>
>> So the advice is to use R CMD INSTALL --build *and* install into the
>> main library (or the library where you install all your add-on packages).
>>
> Thank you for clarifying this and once again apologies for stirring you
> up with something that had been fixed in the mean-time already.

For R-devel, it is in the svn logs. Since it may change again, NEWS is 
not always edited while things are tested.

Uwe Ligges



> Best, Peter
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From savicky at cs.cas.cz  Fri May 15 21:22:57 2009
From: savicky at cs.cas.cz (Petr Savicky)
Date: Fri, 15 May 2009 21:22:57 +0200
Subject: [Rd] Spearman's rank correlation test (PR#13574)
In-Reply-To: <20090305162504.70C6A2832191@mail.pubhealth.ku.dk>
References: <20090305162504.70C6A2832191@mail.pubhealth.ku.dk>
Message-ID: <20090515192257.GH12159@cs.cas.cz>

Bug report "Spearman's rank correlation test (PR#13574)" was moved
to trashcan with empty Notes field. I would like to learn, what was wrong
with this bug report. Can i ask the developers to add a note to it?

Thank you in advance.

Petr.


From bolker at ufl.edu  Fri May 15 23:24:02 2009
From: bolker at ufl.edu (Ben Bolker)
Date: Fri, 15 May 2009 14:24:02 -0700 (PDT)
Subject: [Rd] View() crashy on Ubuntu 9.04
In-Reply-To: <alpine.LFD.2.00.0905151627240.5829@gannet.stats.ox.ac.uk>
References: <4A0A0A64.6030706@ufl.edu>
	<18954.10612.51851.692033@ron.nulle.part>
	<556e90a80905121943o85a6d7et8862c940fafda773@mail.gmail.com>
	<18954.14509.928285.317516@ron.nulle.part>
	<dc41e1260905130055h2c7761bdv7608657be5fa479f@mail.gmail.com>
	<alpine.LFD.2.00.0905151627240.5829@gannet.stats.ox.ac.uk>
Message-ID: <23567509.post@talk.nabble.com>




Prof Brian Ripley wrote:
> 
> Thank you, included in R-patched and R-devel now.
> 

[snip]

 thanks!



> I do wonder sometimes if people who only work with data in ASCII or in 
> a Western European language covered by Latin-1 realize the extent of 
> the overhead that using a UTF-8 locale implies, especially for the X11 
> functionality.  I still use a Latin-1 locale on Linux much of the 
> time.  There are a lot of optimizations in the R code for ASCII-only 
> data, but rather fewer in the I/O areas.
> 

Speaking for myself, I certainly don't -- but even as a fairly long-time
Linux user it
would rarely occur to me to change the default locale set by my OS for the
purposes
of working with R (maybe it will now) ...

-- 
View this message in context: http://www.nabble.com/View%28%29-crashy-on-Ubuntu-9.04-tp23512874p23567509.html
Sent from the R devel mailing list archive at Nabble.com.


From ripley at stats.ox.ac.uk  Sat May 16 08:30:56 2009
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 16 May 2009 07:30:56 +0100 (BST)
Subject: [Rd] Spearman's rank correlation test (PR#13574)
In-Reply-To: <20090515192257.GH12159@cs.cas.cz>
References: <20090305162504.70C6A2832191@mail.pubhealth.ku.dk>
	<20090515192257.GH12159@cs.cas.cz>
Message-ID: <alpine.LFD.2.00.0905160724500.27424@gannet.stats.ox.ac.uk>

On Fri, 15 May 2009, Petr Savicky wrote:

> Bug report "Spearman's rank correlation test (PR#13574)" was moved
> to trashcan with empty Notes field. I would like to learn, what was wrong
> with this bug report. Can i ask the developers to add a note to it?

The move was not intended: JitterBug does sometimes do unexpected 
things with its GUI interface.  I've moved it back.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From maechler at stat.math.ethz.ch  Sat May 16 15:49:40 2009
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Sat, 16 May 2009 15:49:40 +0200
Subject: [Rd] Problem building (binary) packages for Windows
In-Reply-To: <4A0DB8E3.9090107@statistik.tu-dortmund.de>
References: <4A0D5BAD.9050608@web.de>
	<alpine.OSX.1.00.0905151445270.59770@tystie.local>
	<4A0D7DC6.50009@web.de> <4A0DB8E3.9090107@statistik.tu-dortmund.de>
Message-ID: <18958.50292.789860.647778@cmath-5.math.ethz.ch>

>>>>> "UweL" == Uwe Ligges <ligges at statistik.tu-dortmund.de>
>>>>>     on Fri, 15 May 2009 20:48:03 +0200 writes:

[.............]   

    >> Thank you for clarifying this and once again apologies for stirring you
    >> up with something that had been fixed in the mean-time already.

    UweL> For R-devel, it is in the svn logs. Since it may change again, NEWS is 
    UweL> not always edited while things are tested.

well, and if a new feature is introduced, it gets a NEWS entry
(hopefully), but if the new feature contains bugs, these will be
fixed of course with*OUT* another NEWS entry.

Indeed, the NEWS apply to (eventually) released versions of R,
so fixing transient bugs is *never* documented in NEWS.

... leading us back to what Brian already said:
  >>  'Under development' needs to be taken seriously.

Martin Maechler, ETH Zurich


From ripley at stats.ox.ac.uk  Sat May 16 16:19:29 2009
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 16 May 2009 15:19:29 +0100 (BST)
Subject: [Rd] Problem building (binary) packages for Windows
In-Reply-To: <18958.50292.789860.647778@cmath-5.math.ethz.ch>
References: <4A0D5BAD.9050608@web.de>
	<alpine.OSX.1.00.0905151445270.59770@tystie.local>
	<4A0D7DC6.50009@web.de> <4A0DB8E3.9090107@statistik.tu-dortmund.de>
	<18958.50292.789860.647778@cmath-5.math.ethz.ch>
Message-ID: <alpine.LFD.2.00.0905161502190.8212@gannet.stats.ox.ac.uk>

On Sat, 16 May 2009, Martin Maechler wrote:

>>>>>> "UweL" == Uwe Ligges <ligges at statistik.tu-dortmund.de>
>>>>>>     on Fri, 15 May 2009 20:48:03 +0200 writes:
>
> [.............]
>
>    >> Thank you for clarifying this and once again apologies for stirring you
>    >> up with something that had been fixed in the mean-time already.
>
>    UweL> For R-devel, it is in the svn logs. Since it may change again, NEWS is
>    UweL> not always edited while things are tested.
>
> well, and if a new feature is introduced, it gets a NEWS entry
> (hopefully), but if the new feature contains bugs, these will be
> fixed of course with*OUT* another NEWS entry.
>
> Indeed, the NEWS apply to (eventually) released versions of R,
> so fixing transient bugs is *never* documented in NEWS.
>
> ... leading us back to what Brian already said:
>  >>  'Under development' needs to be taken seriously.

This was a Windows-only issue, so the final version was reported in 
the May 1 entry in src/gnuwin32/CHANGES, not NEWS:

     o   Rcmd INSTALL --build in 2.9.0 did not make _bundles_ in the
         format install.packages() expected.

[When I looked that was missing from the RSS feed for R-devel, so 
perhaps another message is to look at the NEWS/CHANGES files 
directly.]

As far as I can see from the svn logs, the first attempt at a fix was 
on April 25 and that was changed to the more successful current 
solution on April 27 (well over two weeks ago, _pace_ claims earlier 
in the thread).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From lbraglia at gmail.com  Sat May 16 22:46:39 2009
From: lbraglia at gmail.com (Luca Braglia)
Date: Sat, 16 May 2009 22:46:39 +0200
Subject: [Rd] typos
Message-ID: <20090516204639.GA8182@Host-001>

Hi

few typos i've found


?.C

Specifying 'ENCODING' overrrides any declared encodings (see
     'link{Encoding}')

\link{Encoding}

--------------------

writing R extensions, pag 73 (pdf version), note 1, 

and we provided an emulation on Windows 2000): see ?dyn.oad
                                            ^          ^^
                                            1          2 

cut ")" and dyn.load

--------------------

writing R extensions
5.2 Interface functions .C and .Fortran

For .C only you can specify an ENCODING argument 
^^^^^^^^^^^

now also for .Fortran ;)

--------------------

R Installation and Administration
1.2 Getting patched and development versions

A patched version of the current release, `r-patched' and the current
                                                    ^^

a comma after `r-patched'


-----------------------

I also would like to close bug/wishlist #9613 ... It was a
juvenile mistake!  :)


Thank you, 
   Luca


From goodrich at fas.harvard.edu  Sun May 17 23:50:12 2009
From: goodrich at fas.harvard.edu (goodrich at fas.harvard.edu)
Date: Sun, 17 May 2009 23:50:12 +0200 (CEST)
Subject: [Rd] [wishlist,
	patch] make row() and col() preserve dimnames (PR#13705)
Message-ID: <20090517215012.ECE2D28320A7@mail.pubhealth.ku.dk>

Full_Name: Ben Goodrich
Version: 2.9.0
OS: Linux (Debian unstable)
Submission from: (NULL) (128.103.220.16)


row(x), col(x), and functions that call them like lower.tri(x) and upper.tri(x)
do not retain the rownames or colnames of x in the matrix that is returned.
Example from R version 2.9.0 :

x <- matrix(1:9, nrow = 3, ncol = 3)
rownames(x) <- LETTERS[1:3]
colnames(x) <- letters[1:3]

dimnames(row(x)) # NULL
dimnames(col(x)) # NULL

Is there anyone for whom the expected behavior is to drop the dimnames of x ? It
is not consistent with other functions of matrices. By default, row(x) already
returns the row numbers of x (and similarly for col()), so how would seeing
integers in the rownames be helpful?

Without patch:
> row(x)
     [,1] [,2] [,3]
[1,]    1    1    1
[2,]    2    2    2
[3,]    3    3    3

With patch:
> row(x)
  a b c
A 1 1 1
B 2 2 2
C 3 3 3

Patch:
Index: src/library/base/R/matrix.R
===================================================================
--- src/library/base/R/matrix.R (revision 48553)
+++ src/library/base/R/matrix.R (working copy)
@@ -104,8 +104,9 @@
         labs <- rownames(x, do.NULL=FALSE, prefix="")
         res <- factor(.Internal(row(dim(x))), labels=labs)
         dim(res) <- dim(x)
-        res
-    } else .Internal(row(dim(x)))
+    } else res <- .Internal(row(dim(x)))
+    dimnames(res) <- dimnames(x)
+    res
 }

 col <- function(x, as.factor=FALSE)
@@ -114,8 +115,9 @@
         labs <- colnames(x, do.NULL=FALSE, prefix="")
         res <- factor(.Internal(col(dim(x))), labels=labs)
         dim(res) <- dim(x)
-        res
-    } else .Internal(col(dim(x)))
+    } else res <- .Internal(col(dim(x)))
+    dimnames(res) <- dimnames(x)
+    res
 }

 crossprod <- function(x, y=NULL) .Internal(crossprod(x,y))


From nakama at ki.rim.or.jp  Mon May 18 08:40:55 2009
From: nakama at ki.rim.or.jp (Ei-ji Nakama)
Date: Mon, 18 May 2009 15:40:55 +0900
Subject: [Rd] [R] sprintf() question
In-Reply-To: <C474D7D640144C34A7BE353F065102BD@Aragorn>
References: <993B311E57784D70BE4BDF3BAA154A27@Aragorn>
	<XFMail.090517233222.Ted.Harding@manchester.ac.uk>
	<C474D7D640144C34A7BE353F065102BD@Aragorn>
Message-ID: <dc41e1260905172340hefd20f0h7c23c9a07e86391f@mail.gmail.com>

Hi

The result of Windows is clearly strange.

================ my Linux machine =?good =======================
> sessionInfo()
R version 2.9.0 (2009-04-17)
x86_64-pc-linux-gnu

locale:
LC_CTYPE=ja_JP.EUC-JP;LC_NUMERIC=C;LC_TIME=ja_JP.EUC-JP;LC_COLLATE=ja_JP.EUC-JP;
LC_MONETARY=C;LC_MESSAGES=ja_JP.EUC-JP;LC_PAPER=ja_JP.EUC-JP;LC_NAME=C;LC_ADDRES
S=C;LC_TELEPHONE=C;LC_MEASUREMENT=ja_JP.EUC-JP;LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base
> sprintf("%a",1:8)
[1] "0x1p+0"   "0x1p+1"   "0x1.8p+1" "0x1p+2"   "0x1.4p+2" "0x1.8p+2" "0x1.cp+2"
[8] "0x1p+3"

================ my Windows machine = OMG ======================
> sessionInfo()
R version 2.9.0 (2009-04-17)
i386-pc-mingw32

locale:
LC_COLLATE=Japanese_Japan.932;LC_CTYPE=Japanese_Japan.932;LC_MONETARY=Japanese_Japan.932;LC_NUMERIC=C;LC_TIME=Japanese_Japan.932

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base
> sprintf("%a",1:8)
[1] "0x1p+0"            "0x1"               "0x1.8"
"0x1p+4294967294"
[5] "0x1.4p+4294967294" "0x1.8p+4294967294" "0x1.cp+4294967294"
"0x1p+4294967293"

The result improved when I changed handling of uExponent as follows

http://prs.ism.ac.jp/~nakama/working/sprintf_format_a.patch



2009/5/18 Daniel Nordlund <djnordlund at verizon.net>:
>> -----Original Message-----
>> From: Ted Harding [mailto:Ted.Harding at manchester.ac.uk]
>> Sent: Sunday, May 17, 2009 3:32 PM
>> To: Daniel Nordlund
>> Cc: r-help at r-project.org
>> Subject: RE: [R] sprintf() question
>>
>> On 17-May-09 22:03:19, Daniel Nordlund wrote:
>> > When I type the following, I get results different from what I
>> > expected.
>> >
>> >> sprintf('%a',3)
>> > [1] "0x1.8"
>> >
>> > Shouldn't the result be
>> >
>> > [1] "0x1.8p+2"
>>
>> Well, not "p+2" but "p+1"
>>   (0x1.8 = 1.1000[2] ; *2 = 11.000[2] = 3[10]) ;
>> however, I get:
>>
>>   sprintf('%a',3)
>>   # [1] "0x1.8p+1"
>>
>> which is indeed correct.
>>
>>   R version 2.9.0 (2009-04-17) ## Same as yours
>>   platform  i486-pc-linux-gnu  ## Different from yours ...
>>
>> which perhaps suggests that there may be a mis-compilation in the
>> Windows version.
>>
>> Ted.
>>
>> > I read through the help ?sprintf and didn't find anything
>> that changed
>> > my expectation.  What am I misunderstanding?  I am using
>> R-2.9.0 binary
>> > from CRAN on Windows XP Pro, and my session info is
>> >
>> >
>> >> sessionInfo()
>> > R version 2.9.0 (2009-04-17)
>> > i386-pc-mingw32
>> >
>> > locale:
>> > LC_COLLATE=English_United States.1252;LC_CTYPE=English_United
>> > States.1252;LC_MONETARY=English_United
>> > States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252
>> >
>> > attached base packages:
>> > [1] stats     graphics  grDevices utils     datasets
>> methods   base
>> >>
>> >
>> > Thanks for any enlightenment.
>> >
>
> Thanks Ted!
>
> Enlightenment is what I asked for, and it is what I got.  I was having a
> senior moment I guess.  I was picturing 8 as binary 0100, when obviously it
> is binary 1000.  So yes, the required power of 2 is 1, and it is fine with
> me that Windows implementation does not display it.  Thanks again.
>
> Dan
>
> Daniel Nordlund
> Bothell, WA  USA
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>

-- 
EI-JI Nakama  <nakama (a) ki.rim.or.jp>
"\u4e2d\u9593\u6804\u6cbb"  <nakama (a) ki.rim.or.jp>


From maechler at stat.math.ethz.ch  Mon May 18 10:26:42 2009
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 18 May 2009 10:26:42 +0200
Subject: [Rd] typos
In-Reply-To: <20090516204639.GA8182@Host-001>
References: <20090516204639.GA8182@Host-001>
Message-ID: <18961.7106.604990.62080@lynne.math.ethz.ch>

>>>>> "LB" == Luca Braglia <lbraglia at gmail.com>
>>>>>     on Sat, 16 May 2009 22:46:39 +0200 writes:

    LB> Hi few typos i've found

Thank you, Luca,

I've fixed all of them {and also moved your "juvenile" :-) bug
report to "*-fulfilled"}.

Regards,
Martin Maechler, ETH Zurich

    LB> ?.C

    LB> Specifying 'ENCODING' overrrides any declared encodings
    LB> (see 'link{Encoding}')

    LB> \link{Encoding}

    LB> --------------------

    LB> writing R extensions, pag 73 (pdf version), note 1,

    LB> and we provided an emulation on Windows 2000): see
    LB> ?dyn.oad ^ ^^ 1 2

    LB> cut ")" and dyn.load

    LB> --------------------

    LB> writing R extensions 5.2 Interface functions .C and
    LB> .Fortran

    LB> For .C only you can specify an ENCODING argument
    LB> ^^^^^^^^^^^

    LB> now also for .Fortran ;)

    LB> --------------------

    LB> R Installation and Administration 1.2 Getting patched
    LB> and development versions

    LB> A patched version of the current release, `r-patched'
    LB> and the current ^^

    LB> a comma after `r-patched'


    LB> -----------------------

    LB> I also would like to close bug/wishlist #9613 ... It was
    LB> a juvenile mistake!  :)


    LB> Thank you, Luca

    LB> ______________________________________________
    LB> R-devel at r-project.org mailing list
    LB> https://stat.ethz.ch/mailman/listinfo/r-devel


From peter.ruckdeschel at web.de  Mon May 18 11:47:11 2009
From: peter.ruckdeschel at web.de (Peter Ruckdeschel)
Date: Mon, 18 May 2009 11:47:11 +0200
Subject: [Rd] was: Problem building (binary) packages for Windows
In-Reply-To: <18958.50292.789860.647778@cmath-5.math.ethz.ch>
References: <4A0D5BAD.9050608@web.de>	<alpine.OSX.1.00.0905151445270.59770@tystie.local>	<4A0D7DC6.50009@web.de>	<4A0DB8E3.9090107@statistik.tu-dortmund.de>
	<18958.50292.789860.647778@cmath-5.math.ethz.ch>
Message-ID: <4A112E9F.3070109@web.de>

Dear Martin, Uwe and Brian

thanks for your comments --- point taken:

On Sat, 16 May 2009, Martin Maechler wrote:

>>>>>> "UweL" == Uwe Ligges <ligges at statistik.tu-dortmund.de>
>>>>>>     on Fri, 15 May 2009 20:48:03 +0200 writes:
>>>>>>             
>
> [.............]   
>
>     >> Thank you for clarifying this and once again apologies for stirring you
>     >> up with something that had been fixed in the mean-time already.
>
>     UweL> For R-devel, it is in the svn logs. Since it may change again, NEWS is 
>     UweL> not always edited while things are tested.
>
> well, and if a new feature is introduced, it gets a NEWS entry
> (hopefully), but if the new feature contains bugs, these will be
> fixed of course with*OUT* another NEWS entry.
>
> Indeed, the NEWS apply to (eventually) released versions of R,
> so fixing transient bugs is *never* documented in NEWS.
>   
Convinced.

And to make this clear:
I did not mean at all to criticize any development undertaken in R-devel
---
you are all doing a great job in enhancing R, and you deserve all due
acknowledgement for this.

My point was rather that instead of keeping one's own checkout
repository of the R project's svn archives, it would help somehow
to make changes visible / accesible more easily ---
of course without bothering R core developers to actively maintain
this, but rather do this in an automatic way.

Embarrasingly enough, now that you have explained to me the
different purposes of NEWS and svn logs, I realized that there
already  is

    http://developer.r-project.org/R.svnlog.2008

(the name of which might get updated to
   ..../R.svnlog.2009, though)

Still, one might improve upon this without to much effort,
I think. Possible starting points could be

(1) webSVN + trac access to the R subversion repository
(2) using some r-forge type architecture for R core as well,
     --- in particular for the source code management provided there
(3) setting up an RSS feed for the svn logs ---- not unlike
     http://developer.r-project.org/blosxom.cgi/R-devel

As one more step ahead one could think of

(4) merging corresponding RSS feeds for CHANGES, NEWS,
and the svn logs in order to see all changes on one spot.

Do you think setting up any of these items would be hard
to establish?

Maybe this is already done; but I have not been aware of this.
> ... leading us back to what Brian already said:
>   >>  'Under development' needs to be taken seriously.
>   
if asked, I would have agreed before, and surely now do
even more so...

Thanks again, best
Peter


From peter.ruckdeschel at web.de  Mon May 18 11:47:24 2009
From: peter.ruckdeschel at web.de (Peter Ruckdeschel)
Date: Mon, 18 May 2009 11:47:24 +0200
Subject: [Rd] Problem building (binary) packages for Windows
In-Reply-To: <alpine.LFD.2.00.0905161502190.8212@gannet.stats.ox.ac.uk>
References: <4A0D5BAD.9050608@web.de>
	<alpine.OSX.1.00.0905151445270.59770@tystie.local>
	<4A0D7DC6.50009@web.de> <4A0DB8E3.9090107@statistik.tu-dortmund.de>
	<18958.50292.789860.647778@cmath-5.math.ethz.ch>
	<alpine.LFD.2.00.0905161502190.8212@gannet.stats.ox.ac.uk>
Message-ID: <4A112EAC.1070200@web.de>

Dear Brian, Martin, and Uwe,

thanks for your explanations; I have already replied to you in another
mail; so I would only like to add some points here.

On Sat, 16 May 2009, Martin Maechler wrote:
> On Sat, 16 May 2009, Martin Maechler wrote:
>
>>>>>>> "UweL" == Uwe Ligges <ligges at statistik.tu-dortmund.de>
>>>>>>>     on Fri, 15 May 2009 20:48:03 +0200 writes:
>>
>> [.............]
>>
>>    >> Thank you for clarifying this and once again apologies for
>> stirring you
>>    >> up with something that had been fixed in the mean-time already.
>>
>>    UweL> For R-devel, it is in the svn logs. Since it may change
>> again, NEWS is
>>    UweL> not always edited while things are tested.
>>
>> well, and if a new feature is introduced, it gets a NEWS entry
>> (hopefully), but if the new feature contains bugs, these will be
>> fixed of course with*OUT* another NEWS entry.
>>
>> Indeed, the NEWS apply to (eventually) released versions of R,
>> so fixing transient bugs is *never* documented in NEWS.
>>
>> ... leading us back to what Brian already said:
>>  >>  'Under development' needs to be taken seriously.
>
> This was a Windows-only issue, so the final version was reported in the
> May 1 entry in src/gnuwin32/CHANGES, not NEWS:
>
>     o   Rcmd INSTALL --build in 2.9.0 did not make _bundles_ in the
>         format install.packages() expected.
Touch?:  I have not been aware of this; and at first glance I would
not have seen the connection to the double DESCRIPTION file
either; sorry for this.
> [When I looked that was missing from the RSS feed for R-devel, so perhaps
> another message is to look at the NEWS/CHANGES files directly.]
Point taken; see also my other reply to all of you.
> As far as I can see from the svn logs, the first attempt at a fix was
> on April 25
> and that was changed to the more successful current solution on April
> 27 (well over two
> weeks ago, _pace_ claims earlier in the thread).
Obviously, my fault was not to look into the CHANGES and the svn log
files.

Actually, looking through the svn logs, I have now spotted the changes 
in r48400 to have caused the double DESCRIPTION file I was complaining
about in my initial posting (in a non-bundle package, btw).
This effect must have survived until r48404, the revision that I was using
when posting the initial question.

So once again: Sorry for taking your time with this
unnecessary posting --- hopefully I have learnt my lesson.

Best, Peter


From michal2992 at gmail.com  Mon May 18 15:31:40 2009
From: michal2992 at gmail.com (=?ISO-8859-2?Q?Micha=B3_Bojanowski?=)
Date: Mon, 18 May 2009 15:31:40 +0200
Subject: [Rd] S4 method dispatch and namespaces: why is default method
	selected
Message-ID: <e1fa237d0905180631h5a6144ao5cf5c65b22bb9fce@mail.gmail.com>

Hi,

I ran into the following peculiarity involving S4 method dispatch and
namespaces.

I develop a package which have a namespace and which depends on 'pixmap'
package, which itself does not have a namespace.

Now, in my package I have a class which has a slot for objects from
class "pixmap" and I
want to have a "plot" method for this new class. Not to clutter the point with
my original code here is a stylized example:


# library(pixmap) # so that the class pixmap is available

# class
setClass("myclass", representation(img="pixmap", title="character",
other="numeric"))

# method to plot
setMethod("plot", signature(x="myclass", y="missing"),
function(x, main=x at title, ...)
{
    # plot using the method from pixmap package
    plot(x=x at img, ...)
    title(main=main)
    points(seq(along=x at other), other)
} )


Now, if you try to do this:

library(pixmap)
f <- system.file(file.path("pictures", "logo.ppm"), package="pixmap")
o <- new("myclass", img=read.pnm(f), title="some title", other=Inf)
o

# now this works as the plot method for signature x="pixmap" y="ANY" is
# dispatched correctly
plot(o)



However, when I put all these in a package with Depends field in
DESCRIPTION having: methods, pixmap, and with the following namespace:


importFrom("graphics", "plot")
exportClasses("myclass")
exportMethods("plot")


things stop working (this is from package test):


> f <- system.file(file.path("pictures", "logo.ppm"), package="pixmap")
> o <- new("myclass", a=read.pnm(f), title="tytul")
> plot(o)
Error in as.double(y) :
  cannot coerce type 'S4' to vector of type 'double'
Calls: plot ... plot -> .local -> plot -> plot.default -> xy.coords
Execution halted



So apparently calling 'plot' dispatches the default method instead of using the
one from package 'pixmap'. Why?

As far as I understand the documentation and section 10.6 of "Software for Data
Analysis" the default method should never be selected as far as there are other
candidates. And there seems to be other candidates, and they seem to be properly
selected if checked using 'selectMethod' (this is from results from
package tests):




> showMethods("plot")
Function: plot (package graphics)
x="ANY", y="ANY"
x="myclass", y="missing"
x="pixmap", y="ANY"


> selectMethod("plot", signature(x="pixmap", y="missing"))
Method Definition:

function (x, y, ...)
{
    .local <- function (x, y, xlab = "", ylab = "", axes = FALSE,
        asp = 1, ...)
    {
        x = as(x, "pixmapIndexed")
        X <- seq(x at bbox[1], x at bbox[3], by = x at cellres[1])
        Y <- seq(x at bbox[2], x at bbox[4], by = x at cellres[2])
        image(x = X, y = Y, z = t(x at index[nrow(x at index):1, ,
            drop = FALSE]), col = x at col, xlab = xlab, ylab = ylab,
            axes = axes, asp = asp, ...)
    }
    .local(x, y, ...)
}
<environment: 0x01844e60>

Signatures:
        x        y
target  "pixmap" "missing"
defined "pixmap" "ANY"





> sessionInfo()
R version 2.9.0 (2009-04-17)
i386-pc-mingw32

locale:
LC_COLLATE=Polish_Poland.1250;LC_CTYPE=Polish_Poland.1250;LC_MONETARY=Polish_Poland.1250;LC_NUMERIC=C;LC_TIME=Polish_Poland.1250

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] pixmap_0.4-9

loaded via a namespace (and not attached):
[1] tools_2.9.0




Thanks in advance!

Best,
Micha?



_________________________
Michal Bojanowski
http://bojan.3e.pl/weblog
http://www.fss.uu.nl/soc/bojanowski
http://www.ifispan.waw.pl/socnierowno


From maechler at stat.math.ethz.ch  Mon May 18 18:04:29 2009
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 18 May 2009 18:04:29 +0200
Subject: [Rd] tcrossprod() inconsistency ?!
Message-ID: <18961.34573.831240.524707@lynne.math.ethz.ch>

The current behavior of  tcrossprod() is not 
consistent with its documentation (*).

crossprod() and tcrossprod() are documented on the same page
(...../base/library/man/crossprod.Rd )

which says {lines broken by me} :

 > Description:

 >      Given matrices 'x' and 'y' as arguments, return a matrix
 >      cross-product.  This is formally equivalent to (but usually
 >      slightly faster than) the call 
 >
 >   't(x) %*% y' ('crossprod')   or
 >   'x %*% t(y)' ('tcrossprod').

and crossprod()  does really work like  t(x) %*% y  in all cases
AFAIK, but  tcrossprod() fails to do so e.g. in

  > m <- matrix(1:6, 2,3) 
  > (1:3) %*% t(m)
       [,1] [,2]
  [1,]   22   28
  > tcrossprod(1:3, m)
  Error in tcrossprod(1:3, m) : non-conformable arguments
  > 

I would like to change tcrossprod() both in 'base' and in 'Matrix'.
Does anyone see reasons why I should not ?
Martin Maechler, ETH Zurich

---
(*) Note that tcrossprod() has been a relatively late addition
    to R, not present in S;  so this inconsistency might seem 
    somewhat excusable.


From Philippe.Hupe at curie.fr  Mon May 18 18:24:25 2009
From: Philippe.Hupe at curie.fr (=?ISO-8859-1?Q?Philippe_Hup=E9?=)
Date: Mon, 18 May 2009 18:24:25 +0200
Subject: [Rd] R 2.9.0 slower than R 2.8.1 for the data.frame function
Message-ID: <4A118BB9.4050007@curie.fr>

Dear developers,


I have noticed difference in computation time for the data.frame
function between R2.9.0 and R2.8.1. The older release is more efficient:
typically, R2.9.0 spends three more time in the data.frame function.
Therefore, when many calls of this kind is done inside a function, the
additional time spent with R2.9.0 may be several minutes.

Looking at the profiling results (see file below), it seems that R2.9.0
spends time in nchar function while it was not the case with R2.8.1.

I am runing R under debian stable on 64-bits architecture (see the
cpuinfo file for details). Both R2.9.0 and R2.8.0 have been compiled
from source with the same default options.

The data I use can and the R script can be retrieved (see below) for
people who are interested in doing some benchmark.

I am looking forward to have your feedback for this problem.


Best,

Philippe


profiling with R2.8.1:
http://xfer.curie.fr/get/X3oSg7VO81F/profiling-2.8.1.txt

profiling with R2.9.0:
http://xfer.curie.fr/get/he4A8yQfe3j/profiling-2.9.0.txt

RData:
http://xfer.curie.fr/get/SOOaBe5nMz3/mydata.RData

R script:
http://xfer.curie.fr/get/w64axb61KPt/comparison-2.9.0-vs-2.8.1.R

computer information:
http://xfer.curie.fr/get/xRS9VfMqA5l/cpuinfo.txt

-- 
Philippe Hup?
Institut Curie, CNRS UMR 144, INSERM U900
26 rue d'Ulm
75005 Paris - France
 	
Email :  Philippe.Hupe at curie.fr
T?l :	 +33 (0)1 56 24 69 91
Fax:     +33 (0)1 56 24 69 11
website : http://bioinfo.curie.fr


From jeff.a.ryan at gmail.com  Mon May 18 19:40:14 2009
From: jeff.a.ryan at gmail.com (Jeff Ryan)
Date: Mon, 18 May 2009 12:40:14 -0500
Subject: [Rd] readBin on binary non-blocking connections (Windows & Unix
	differences/bugs)
Message-ID: <e8e755250905181040k593e8b5al4725972d109c4d8a@mail.gmail.com>

R-devel:

I am encountering a consistency issue using socketConnection and
readBin with *non-blocking* connections on Unix and Windows XP (no
Vista to test).

I am a bit confused by the behavior of *non-blocking* connections
under Windows specifically.  When calling readBin on a non-blocking
connection when there is no data to read on the socket, the connection
under Unix will return a vector of zero-length matching the type of
the 'what' argument to the readBin call.

The same call under Windows returns random data unless called with
what=raw(), which instead returns an error.


A simple example using two R processes to illustrate on one machine:


#########################################################################
# PROCESS 1 (Windows/Unix -- the same code for both):
#########################################################################

# Open the connection and don't write anything

s <- socketConnection(port=7777, server=TRUE, blocking=TRUE,open="ab")

#########################################################################
# PROCESS 2 (Windows) use this to read:
#########################################################################

s <- socketConnection(port=7777,blocking=FALSE,open="ab")
readBin(s, character())
readBin(s, character())
readBin(s, double())
readBin(s, raw())

# > readBin(s, character())
# [1] "\020??\001@??\001 $?\001 $?\001 $?\001 $?\001 $?\001 $?\001
$?\001 $?\001 ...
# > readBin(s, character())
# [1] "X\n"
# > readBin(s, double())
# [1] 1.255609e-316
# > readBin(s, raw())
# Error in readBin(s, raw()) : negative length vectors are not allowed

##########################################################################
# Using a *nix, the above works as I would expect
#
# PROCESS 2 (Unixes -- this example OSX 10.4, but is consistent on
other flavors)
#########################################################################

s <- socketConnection(port=7777,blocking=FALSE, open="ab")
readBin(s, character())
readBin(s, raw())
readBin(s, double())

# > readBin(s, character())
# character(0)
# > readBin(s, raw())
# raw(0)
# > readBin(s, double())
# numeric(0)

Is this a bug in R or Windows?  Is there a workaround?  I would like
to have readBin on non-blocking connections work consistently across
platforms.  When data is present, both platforms behave consistently.
Incidentally, the readBin calls in my program are not using R as the
server, the above code is simply to illustrate the problem.

The fact that the raw() returns an error on Windows seems to indicate
that the error is able to be caught, and could be tested for.

One other interesting point of note; the character() calls on Windows
will return not just random data, but very non-random R type strings.
Somehow non-allocated memory is being read.

> readBin(s, character(),100)
  [1] "X\n"
  [2] "spatch"
  [3] ""
  [4] ""
  [5] "X\n"
  [6] "ssion"
  [7] "\002"
  [8] "?$?\001?|?\001\030[?\001?N?\001?N?\001?$?\001\004"
  [9] "H\024?\001\f\025?\001,??\001\002\002"
 [10] "?\026?\001?$?\001\005"
 [11] ""
 [12] "s.logical"
...
 [75] "8}?\001?~?\001\020??\001?$?\001?}?\001?$?\001???\001
$?\001???\001?~?\0014~?\001???\001?|?\001???\001???\001\034}?\001???\001
$?\001?|?\001?\177?\001"
 [76] "?$?\001?$?\001???\001\030??\001T??\001?$?\001?$?\001
$?\001???\0010??\001?$?\001?$?\001???\0014??\001
\177?\001X??\001\034??\001?$?\001???\001???\001
|?\001\004??\001???\0010\177?\001???\001?{?\001<??\001
$?\001???\001?}?\001 ??\001?$?\001?$?\001\024\177?\001
$?\001t??\001???\001?}?\001?$?\001?$?\001t|?\001?$?\001
$?\001?\177?\001???\001?|?\001 |?\001?$?\001d??\001
$?\001???\001x{?\001?$?\001"
 [77] "' must be of length 1"

This behavior has been noticed by me at least as early as 2.6, and is
currently seen under 2.9.0.

Thanks for any pointers,
Jeff Ryan


-- 
Jeffrey Ryan
jeffrey.ryan at insightalgo.com

ia: insight algorithmics
www.insightalgo.com


From ggrothendieck at gmail.com  Mon May 18 20:01:20 2009
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 18 May 2009 14:01:20 -0400
Subject: [Rd] readBin on binary non-blocking connections (Windows & Unix
	differences/bugs)
In-Reply-To: <e8e755250905181040k593e8b5al4725972d109c4d8a@mail.gmail.com>
References: <e8e755250905181040k593e8b5al4725972d109c4d8a@mail.gmail.com>
Message-ID: <971536df0905181101n76cc8730u9fd9680ea404d7f3@mail.gmail.com>

Ryacas uses non-blocking sockets and works across all platforms
but uses readLines/writeLines, rather than readBin, to communicate with
yacas.  You could look at its source code in case it brings anything to mind.

On Mon, May 18, 2009 at 1:40 PM, Jeff Ryan <jeff.a.ryan at gmail.com> wrote:
> R-devel:
>
> I am encountering a consistency issue using socketConnection and
> readBin with *non-blocking* connections on Unix and Windows XP (no
> Vista to test).
>
> I am a bit confused by the behavior of *non-blocking* connections
> under Windows specifically. ?When calling readBin on a non-blocking
> connection when there is no data to read on the socket, the connection
> under Unix will return a vector of zero-length matching the type of
> the 'what' argument to the readBin call.
>
> The same call under Windows returns random data unless called with
> what=raw(), which instead returns an error.
>
>
> A simple example using two R processes to illustrate on one machine:
>
>
> #########################################################################
> # PROCESS 1 (Windows/Unix -- the same code for both):
> #########################################################################
>
> # Open the connection and don't write anything
>
> s <- socketConnection(port=7777, server=TRUE, blocking=TRUE,open="ab")
>
> #########################################################################
> # PROCESS 2 (Windows) use this to read:
> #########################################################################
>
> s <- socketConnection(port=7777,blocking=FALSE,open="ab")
> readBin(s, character())
> readBin(s, character())
> readBin(s, double())
> readBin(s, raw())
>
> # > readBin(s, character())
> # [1] "\020??\001@??\001 $?\001 $?\001 $?\001 $?\001 $?\001 $?\001
> $?\001 $?\001 ...
> # > readBin(s, character())
> # [1] "X\n"
> # > readBin(s, double())
> # [1] 1.255609e-316
> # > readBin(s, raw())
> # Error in readBin(s, raw()) : negative length vectors are not allowed
>
> ##########################################################################
> # Using a *nix, the above works as I would expect
> #
> # PROCESS 2 (Unixes -- this example OSX 10.4, but is consistent on
> other flavors)
> #########################################################################
>
> s <- socketConnection(port=7777,blocking=FALSE, open="ab")
> readBin(s, character())
> readBin(s, raw())
> readBin(s, double())
>
> # > readBin(s, character())
> # character(0)
> # > readBin(s, raw())
> # raw(0)
> # > readBin(s, double())
> # numeric(0)
>
> Is this a bug in R or Windows? ?Is there a workaround? ?I would like
> to have readBin on non-blocking connections work consistently across
> platforms. ?When data is present, both platforms behave consistently.
> Incidentally, the readBin calls in my program are not using R as the
> server, the above code is simply to illustrate the problem.
>
> The fact that the raw() returns an error on Windows seems to indicate
> that the error is able to be caught, and could be tested for.
>
> One other interesting point of note; the character() calls on Windows
> will return not just random data, but very non-random R type strings.
> Somehow non-allocated memory is being read.
>
>> readBin(s, character(),100)
> ?[1] "X\n"
> ?[2] "spatch"
> ?[3] ""
> ?[4] ""
> ?[5] "X\n"
> ?[6] "ssion"
> ?[7] "\002"
> ?[8] "?$?\001?|?\001\030[?\001?N?\001?N?\001?$?\001\004"
> ?[9] "H\024?\001\f\025?\001,??\001\002\002"
> ?[10] "?\026?\001?$?\001\005"
> ?[11] ""
> ?[12] "s.logical"
> ...
> ?[75] "8}?\001?~?\001\020??\001?$?\001?}?\001?$?\001???\001
> $?\001???\001?~?\0014~?\001???\001?|?\001???\001???\001\034}?\001???\001
> $?\001?|?\001?\177?\001"
> ?[76] "?$?\001?$?\001???\001\030??\001T??\001?$?\001?$?\001
> $?\001???\0010??\001?$?\001?$?\001???\0014??\001
> \177?\001X??\001\034??\001?$?\001???\001???\001
> |?\001\004??\001???\0010\177?\001???\001?{?\001<??\001
> $?\001???\001?}?\001 ??\001?$?\001?$?\001\024\177?\001
> $?\001t??\001???\001?}?\001?$?\001?$?\001t|?\001?$?\001
> $?\001?\177?\001???\001?|?\001 |?\001?$?\001d??\001
> $?\001???\001x{?\001?$?\001"
> ?[77] "' must be of length 1"
>
> This behavior has been noticed by me at least as early as 2.6, and is
> currently seen under 2.9.0.
>
> Thanks for any pointers,
> Jeff Ryan
>
>
> --
> Jeffrey Ryan
> jeffrey.ryan at insightalgo.com
>
> ia: insight algorithmics
> www.insightalgo.com
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From jeff.a.ryan at gmail.com  Mon May 18 21:01:21 2009
From: jeff.a.ryan at gmail.com (Jeff Ryan)
Date: Mon, 18 May 2009 14:01:21 -0500
Subject: [Rd] readBin on binary non-blocking connections (Windows & Unix
	differences/bugs)
In-Reply-To: <971536df0905181101n76cc8730u9fd9680ea404d7f3@mail.gmail.com>
References: <e8e755250905181040k593e8b5al4725972d109c4d8a@mail.gmail.com>
	<971536df0905181101n76cc8730u9fd9680ea404d7f3@mail.gmail.com>
Message-ID: <e8e755250905181201y11d698afj57cb5b54a1321057@mail.gmail.com>

Thanks Gabor.

Unfortunately read/writeLines won't work in this particular
application.  Nor does readChar, as the returned values are not of a
fixed size.  I need to read each unknown length "character" up until
an embedded null.  readBin does this (almost) perfectly.

My current workaround is to simply force blocking=TRUE on Windows
users, but that seems not to be the right answer.

An alternate approach may be to rewrite readBin to allow for some sort
of buffering mechanism.  If readBin first reads in data as raw(), it
would be possible to test for an error and return via some switch
statement the appropriate length zero vector.

The main issue is that by reading in raw bytes I have to explicitly
convert to the appropriate data types (nul terminated character
strings in this case).

The second (bigger?) issue is that all readBin calls would have to
first look to the buffer before reading from the connection again.
This would require the buffer to be available --- either as an R
connection addition, or as a global variable.

The best option of course is for readBin to correctly catch the error
cases, but without guidance from those who know the full details of
sockets in R, I am afraid that option isn't realistic at this moment.

Jeff





On Mon, May 18, 2009 at 1:01 PM, Gabor Grothendieck
<ggrothendieck at gmail.com> wrote:
> Ryacas uses non-blocking sockets and works across all platforms
> but uses readLines/writeLines, rather than readBin, to communicate with
> yacas. ?You could look at its source code in case it brings anything to mind.
>
> On Mon, May 18, 2009 at 1:40 PM, Jeff Ryan <jeff.a.ryan at gmail.com> wrote:
>> R-devel:
>>
>> I am encountering a consistency issue using socketConnection and
>> readBin with *non-blocking* connections on Unix and Windows XP (no
>> Vista to test).
>>
>> I am a bit confused by the behavior of *non-blocking* connections
>> under Windows specifically. ?When calling readBin on a non-blocking
>> connection when there is no data to read on the socket, the connection
>> under Unix will return a vector of zero-length matching the type of
>> the 'what' argument to the readBin call.
>>
>> The same call under Windows returns random data unless called with
>> what=raw(), which instead returns an error.
>>
>>
>> A simple example using two R processes to illustrate on one machine:
>>
>>
>> #########################################################################
>> # PROCESS 1 (Windows/Unix -- the same code for both):
>> #########################################################################
>>
>> # Open the connection and don't write anything
>>
>> s <- socketConnection(port=7777, server=TRUE, blocking=TRUE,open="ab")
>>
>> #########################################################################
>> # PROCESS 2 (Windows) use this to read:
>> #########################################################################
>>
>> s <- socketConnection(port=7777,blocking=FALSE,open="ab")
>> readBin(s, character())
>> readBin(s, character())
>> readBin(s, double())
>> readBin(s, raw())
>>
>> # > readBin(s, character())
>> # [1] "\020??\001@??\001 $?\001 $?\001 $?\001 $?\001 $?\001 $?\001
>> $?\001 $?\001 ...
>> # > readBin(s, character())
>> # [1] "X\n"
>> # > readBin(s, double())
>> # [1] 1.255609e-316
>> # > readBin(s, raw())
>> # Error in readBin(s, raw()) : negative length vectors are not allowed
>>
>> ##########################################################################
>> # Using a *nix, the above works as I would expect
>> #
>> # PROCESS 2 (Unixes -- this example OSX 10.4, but is consistent on
>> other flavors)
>> #########################################################################
>>
>> s <- socketConnection(port=7777,blocking=FALSE, open="ab")
>> readBin(s, character())
>> readBin(s, raw())
>> readBin(s, double())
>>
>> # > readBin(s, character())
>> # character(0)
>> # > readBin(s, raw())
>> # raw(0)
>> # > readBin(s, double())
>> # numeric(0)
>>
>> Is this a bug in R or Windows? ?Is there a workaround? ?I would like
>> to have readBin on non-blocking connections work consistently across
>> platforms. ?When data is present, both platforms behave consistently.
>> Incidentally, the readBin calls in my program are not using R as the
>> server, the above code is simply to illustrate the problem.
>>
>> The fact that the raw() returns an error on Windows seems to indicate
>> that the error is able to be caught, and could be tested for.
>>
>> One other interesting point of note; the character() calls on Windows
>> will return not just random data, but very non-random R type strings.
>> Somehow non-allocated memory is being read.
>>
>>> readBin(s, character(),100)
>> ?[1] "X\n"
>> ?[2] "spatch"
>> ?[3] ""
>> ?[4] ""
>> ?[5] "X\n"
>> ?[6] "ssion"
>> ?[7] "\002"
>> ?[8] "?$?\001?|?\001\030[?\001?N?\001?N?\001?$?\001\004"
>> ?[9] "H\024?\001\f\025?\001,??\001\002\002"
>> ?[10] "?\026?\001?$?\001\005"
>> ?[11] ""
>> ?[12] "s.logical"
>> ...
>> ?[75] "8}?\001?~?\001\020??\001?$?\001?}?\001?$?\001???\001
>> $?\001???\001?~?\0014~?\001???\001?|?\001???\001???\001\034}?\001???\001
>> $?\001?|?\001?\177?\001"
>> ?[76] "?$?\001?$?\001???\001\030??\001T??\001?$?\001?$?\001
>> $?\001???\0010??\001?$?\001?$?\001???\0014??\001
>> \177?\001X??\001\034??\001?$?\001???\001???\001
>> |?\001\004??\001???\0010\177?\001???\001?{?\001<??\001
>> $?\001???\001?}?\001 ??\001?$?\001?$?\001\024\177?\001
>> $?\001t??\001???\001?}?\001?$?\001?$?\001t|?\001?$?\001
>> $?\001?\177?\001???\001?|?\001 |?\001?$?\001d??\001
>> $?\001???\001x{?\001?$?\001"
>> ?[77] "' must be of length 1"
>>
>> This behavior has been noticed by me at least as early as 2.6, and is
>> currently seen under 2.9.0.
>>
>> Thanks for any pointers,
>> Jeff Ryan
>>
>>
>> --
>> Jeffrey Ryan
>> jeffrey.ryan at insightalgo.com
>>
>> ia: insight algorithmics
>> www.insightalgo.com
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>



-- 
Jeffrey Ryan
jeffrey.ryan at insightalgo.com

ia: insight algorithmics
www.insightalgo.com


From orcaforge at googlemail.com  Mon May 18 21:05:36 2009
From: orcaforge at googlemail.com (Stephan (orcaforge@gtalk))
Date: Mon, 18 May 2009 21:05:36 +0200
Subject: [Rd] Interrupting R when embedded in Java
Message-ID: <1ae51efd0905181205u7f3f1687offf1de596c525f10@mail.gmail.com>

Dear list,

we would like to add support to interrupt R to StatET (the Eclipse
plug-in for R) on any platform. StatET uses JRI of rJava to embed R
into the Java application. But JRI currently supports canceling of R
commands only on Windows. So we are looking for a way to add support
for other platforms too. It is not a specific problem of StatET but of
all JRI based GUIs, e.g. of JGR.

On Windows, JRI sets the flag "UserBreak" to interrupt R. If I
understand the extension manual and postings on this list correctly,
there is no similar easy way on Linux?

The second way to interrupt R supported also on Linux seems to be
sending signals (SIGINT) to the R process. This is tricky in mixed
environment (java + native code), but perhaps it works. The rough idea
is, to enabled reduced usage of signals by Java (argument -Xrs) and
then let R install its signal handlers. I would like to know if
somebody already tried that or the like (with success or with which
problems)?

Best,
Stephan


From edd at debian.org  Mon May 18 21:55:13 2009
From: edd at debian.org (Dirk Eddelbuettel)
Date: Mon, 18 May 2009 14:55:13 -0500
Subject: [Rd] Auto-upgrading a package under Windows ?
Message-ID: <18961.48417.945981.635658@ron.nulle.part>


I was trying to be cute with a company-internal package and used

    if (Sys.info()["sysname"]=="Windows") {
        update.packages(repos="http://some.where.internal/R", ask=FALSE)
    }

but that of course fails as the package itself is loaded and cannot be
upgraded (as it contains a dll) when loaded.  Smart move by the OS.

Can anybody suggest a workaround, other than introducing a dll-free wrapper
package that can in fact test for the local packages before it would load
them? 

Placing the test into Rprofile.site is not a valid answer as that file is
hiding on each user's drive and out of my reach.

Dirk

-- 
Three out of two people have difficulties with fractions.


From murdoch at stats.uwo.ca  Mon May 18 23:03:03 2009
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Mon, 18 May 2009 17:03:03 -0400
Subject: [Rd] was: Problem building (binary) packages for Windows
In-Reply-To: <4A112E9F.3070109@web.de>
References: <4A0D5BAD.9050608@web.de>	<alpine.OSX.1.00.0905151445270.59770@tystie.local>	<4A0D7DC6.50009@web.de>	<4A0DB8E3.9090107@statistik.tu-dortmund.de>	<18958.50292.789860.647778@cmath-5.math.ethz.ch>
	<4A112E9F.3070109@web.de>
Message-ID: <4A11CD07.3070102@stats.uwo.ca>

On 18/05/2009 5:47 AM, Peter Ruckdeschel wrote:
> Dear Martin, Uwe and Brian
> 
> thanks for your comments --- point taken:
> 
> On Sat, 16 May 2009, Martin Maechler wrote:
> 
>>>>>>> "UweL" == Uwe Ligges <ligges at statistik.tu-dortmund.de>
>>>>>>>     on Fri, 15 May 2009 20:48:03 +0200 writes:
>>>>>>>             
>> [.............]   
>>
>>     >> Thank you for clarifying this and once again apologies for stirring you
>>     >> up with something that had been fixed in the mean-time already.
>>
>>     UweL> For R-devel, it is in the svn logs. Since it may change again, NEWS is 
>>     UweL> not always edited while things are tested.
>>
>> well, and if a new feature is introduced, it gets a NEWS entry
>> (hopefully), but if the new feature contains bugs, these will be
>> fixed of course with*OUT* another NEWS entry.
>>
>> Indeed, the NEWS apply to (eventually) released versions of R,
>> so fixing transient bugs is *never* documented in NEWS.
>>   
> Convinced.
> 
> And to make this clear:
> I did not mean at all to criticize any development undertaken in R-devel
> ---
> you are all doing a great job in enhancing R, and you deserve all due
> acknowledgement for this.
> 
> My point was rather that instead of keeping one's own checkout
> repository of the R project's svn archives, it would help somehow
> to make changes visible / accesible more easily ---
> of course without bothering R core developers to actively maintain
> this, but rather do this in an automatic way.
> 
> Embarrasingly enough, now that you have explained to me the
> different purposes of NEWS and svn logs, I realized that there
> already  is
> 
>     http://developer.r-project.org/R.svnlog.2008
> 
> (the name of which might get updated to
>    ..../R.svnlog.2009, though)

Thanks for noticing that; it's now done.

Duncan Murdoch

> 
> Still, one might improve upon this without to much effort,
> I think. Possible starting points could be
> 
> (1) webSVN + trac access to the R subversion repository
> (2) using some r-forge type architecture for R core as well,
>      --- in particular for the source code management provided there
> (3) setting up an RSS feed for the svn logs ---- not unlike
>      http://developer.r-project.org/blosxom.cgi/R-devel
> 
> As one more step ahead one could think of
> 
> (4) merging corresponding RSS feeds for CHANGES, NEWS,
> and the svn logs in order to see all changes on one spot.
> 
> Do you think setting up any of these items would be hard
> to establish?
> 
> Maybe this is already done; but I have not been aware of this.
>> ... leading us back to what Brian already said:
>>   >>  'Under development' needs to be taken seriously.
>>   
> if asked, I would have agreed before, and surely now do
> even more so...
> 
> Thanks again, best
> Peter
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From murdoch at stats.uwo.ca  Tue May 19 01:48:48 2009
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Mon, 18 May 2009 19:48:48 -0400
Subject: [Rd] Problem building (binary) packages for Windows
In-Reply-To: <alpine.LFD.2.00.0905161502190.8212@gannet.stats.ox.ac.uk>
References: <4A0D5BAD.9050608@web.de>	<alpine.OSX.1.00.0905151445270.59770@tystie.local>	<4A0D7DC6.50009@web.de>
	<4A0DB8E3.9090107@statistik.tu-dortmund.de>	<18958.50292.789860.647778@cmath-5.math.ethz.ch>
	<alpine.LFD.2.00.0905161502190.8212@gannet.stats.ox.ac.uk>
Message-ID: <4A11F3E0.1010303@stats.uwo.ca>

On 16/05/2009 10:19 AM, Prof Brian Ripley wrote:
> On Sat, 16 May 2009, Martin Maechler wrote:
> 
>>>>>>> "UweL" == Uwe Ligges <ligges at statistik.tu-dortmund.de>
>>>>>>>     on Fri, 15 May 2009 20:48:03 +0200 writes:
>> [.............]
>>
>>    >> Thank you for clarifying this and once again apologies for stirring you
>>    >> up with something that had been fixed in the mean-time already.
>>
>>    UweL> For R-devel, it is in the svn logs. Since it may change again, NEWS is
>>    UweL> not always edited while things are tested.
>>
>> well, and if a new feature is introduced, it gets a NEWS entry
>> (hopefully), but if the new feature contains bugs, these will be
>> fixed of course with*OUT* another NEWS entry.
>>
>> Indeed, the NEWS apply to (eventually) released versions of R,
>> so fixing transient bugs is *never* documented in NEWS.
>>
>> ... leading us back to what Brian already said:
>>  >>  'Under development' needs to be taken seriously.
> 
> This was a Windows-only issue, so the final version was reported in 
> the May 1 entry in src/gnuwin32/CHANGES, not NEWS:
> 
>      o   Rcmd INSTALL --build in 2.9.0 did not make _bundles_ in the
>          format install.packages() expected.
> 
> [When I looked that was missing from the RSS feed for R-devel, so 
> perhaps another message is to look at the NEWS/CHANGES files 
> directly.]

I think it arrived on May 2; in any case, it's there now:

http://developer.r-project.org/blosxom.cgi/R-devel/2009/05/02#c2009-05-02

Duncan Murdoch

> 
> As far as I can see from the svn logs, the first attempt at a fix was 
> on April 25 and that was changed to the more successful current 
> solution on April 27 (well over two weeks ago, _pace_ claims earlier 
> in the thread).
>


From goon83 at 126.com  Tue May 19 04:30:01 2009
From: goon83 at 126.com (goon83)
Date: Tue, 19 May 2009 10:30:01 +0800 (CST)
Subject: [Rd] About " Error: C stack usage is too close to the limit"
Message-ID: <23586493.100621242700201570.JavaMail.coremail@bj126app62.126.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090519/ff13499c/attachment.pl>

From mtmorgan at fhcrc.org  Tue May 19 05:59:52 2009
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Mon, 18 May 2009 20:59:52 -0700
Subject: [Rd] S4 method dispatch and namespaces: why is default method
 selected
In-Reply-To: <e1fa237d0905180631h5a6144ao5cf5c65b22bb9fce@mail.gmail.com> 
	=?utf-8?q?=28Micha=C5=82?= Bojanowski's message of "Mon,
	18 May 2009 15:31:40 +0200")
References: <e1fa237d0905180631h5a6144ao5cf5c65b22bb9fce@mail.gmail.com>
Message-ID: <6phr5ylagjr.fsf@gopher4.fhcrc.org>

Hi Micha? --

Micha? Bojanowski <michal2992 at gmail.com> writes:

> Hi,
>
> I ran into the following peculiarity involving S4 method dispatch and
> namespaces.
>
> I develop a package which have a namespace and which depends on 'pixmap'
> package, which itself does not have a namespace.
>
> Now, in my package I have a class which has a slot for objects from
> class "pixmap" and I
> want to have a "plot" method for this new class. Not to clutter the point with
> my original code here is a stylized example:
>
>
> # library(pixmap) # so that the class pixmap is available
>
> # class
> setClass("myclass", representation(img="pixmap", title="character",
> other="numeric"))
>
> # method to plot
> setMethod("plot", signature(x="myclass", y="missing"),
> function(x, main=x at title, ...)
> {
>     # plot using the method from pixmap package
>     plot(x=x at img, ...)
>     title(main=main)
>     points(seq(along=x at other), other)
> } )
>
>
> Now, if you try to do this:
>
> library(pixmap)
> f <- system.file(file.path("pictures", "logo.ppm"), package="pixmap")
> o <- new("myclass", img=read.pnm(f), title="some title", other=Inf)
> o
>
> # now this works as the plot method for signature x="pixmap" y="ANY" is
> # dispatched correctly
> plot(o)
>
>
>
> However, when I put all these in a package with Depends field in
> DESCRIPTION having: methods, pixmap, and with the following namespace:
>
>
> importFrom("graphics", "plot")
> exportClasses("myclass")
> exportMethods("plot")
>
>
> things stop working (this is from package test):
>
>
>> f <- system.file(file.path("pictures", "logo.ppm"), package="pixmap")
>> o <- new("myclass", a=read.pnm(f), title="tytul")
>> plot(o)
> Error in as.double(y) :
>   cannot coerce type 'S4' to vector of type 'double'
> Calls: plot ... plot -> .local -> plot -> plot.default -> xy.coords
> Execution halted
>
>
>
> So apparently calling 'plot' dispatches the default method instead of using the
> one from package 'pixmap'. Why?

Not speaking authoritatively, but plot,myclass,missing-method is
defined in your name space, and so has access only to symbols defined
or imported into the name space. The plot,pixmap,ANY-method is not in
your name space (even though it's on the search path), and so is not
found. Clever of the methods package to keep track of this. I think
the only solution is

  pixmap::plot(x=x at img, ...)

Martin

> As far as I understand the documentation and section 10.6 of "Software for Data
> Analysis" the default method should never be selected as far as there are other
> candidates. And there seems to be other candidates, and they seem to be properly
> selected if checked using 'selectMethod' (this is from results from
> package tests):
>
>
>
>
>> showMethods("plot")
> Function: plot (package graphics)
> x="ANY", y="ANY"
> x="myclass", y="missing"
> x="pixmap", y="ANY"
>
>
>> selectMethod("plot", signature(x="pixmap", y="missing"))
> Method Definition:
>
> function (x, y, ...)
> {
>     .local <- function (x, y, xlab = "", ylab = "", axes = FALSE,
>         asp = 1, ...)
>     {
>         x = as(x, "pixmapIndexed")
>         X <- seq(x at bbox[1], x at bbox[3], by = x at cellres[1])
>         Y <- seq(x at bbox[2], x at bbox[4], by = x at cellres[2])
>         image(x = X, y = Y, z = t(x at index[nrow(x at index):1, ,
>             drop = FALSE]), col = x at col, xlab = xlab, ylab = ylab,
>             axes = axes, asp = asp, ...)
>     }
>     .local(x, y, ...)
> }
> <environment: 0x01844e60>
>
> Signatures:
>         x        y
> target  "pixmap" "missing"
> defined "pixmap" "ANY"
>
>
>
>
>
>> sessionInfo()
> R version 2.9.0 (2009-04-17)
> i386-pc-mingw32
>
> locale:
> LC_COLLATE=Polish_Poland.1250;LC_CTYPE=Polish_Poland.1250;LC_MONETARY=Polish_Poland.1250;LC_NUMERIC=C;LC_TIME=Polish_Poland.1250
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] pixmap_0.4-9
>
> loaded via a namespace (and not attached):
> [1] tools_2.9.0
>
>
>
>
> Thanks in advance!
>
> Best,
> Micha?
>
>
>
> _________________________
> Michal Bojanowski
> http://bojan.3e.pl/weblog
> http://www.fss.uu.nl/soc/bojanowski
> http://www.ifispan.waw.pl/socnierowno
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Martin Morgan
Computational Biology / Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N.
PO Box 19024 Seattle, WA 98109

Location: Arnold Building M1 B861
Phone: (206) 667-2793


From maechler at stat.math.ethz.ch  Tue May 19 09:51:44 2009
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 19 May 2009 09:51:44 +0200
Subject: [Rd] was: Problem building (binary) packages for Windows
In-Reply-To: <4A112E9F.3070109@web.de>
References: <4A0D5BAD.9050608@web.de>
	<alpine.OSX.1.00.0905151445270.59770@tystie.local>
	<4A0D7DC6.50009@web.de> <4A0DB8E3.9090107@statistik.tu-dortmund.de>
	<18958.50292.789860.647778@cmath-5.math.ethz.ch>
	<4A112E9F.3070109@web.de>
Message-ID: <18962.25872.878865.525325@lynne.math.ethz.ch>

>>>>> "PetRd" == Peter Ruckdeschel <peter.ruckdeschel at web.de>
>>>>>     on Mon, 18 May 2009 11:47:11 +0200 writes:

    PetRd> Dear Martin, Uwe and Brian
    PetRd> thanks for your comments --- point taken:

    PetRd> On Sat, 16 May 2009, Martin Maechler wrote:

    >>>>>>> "UweL" == Uwe Ligges <ligges at statistik.tu-dortmund.de>
    >>>>>>> on Fri, 15 May 2009 20:48:03 +0200 writes:
    >>>>>>> 
    >> 
    >> [.............]   
    >> 
    >> >> Thank you for clarifying this and once again apologies for stirring you
    >> >> up with something that had been fixed in the mean-time already.
    >> 
    UweL> For R-devel, it is in the svn logs. Since it may change again, NEWS is 
    UweL> not always edited while things are tested.
    >> 
    >> well, and if a new feature is introduced, it gets a NEWS entry
    >> (hopefully), but if the new feature contains bugs, these will be
    >> fixed of course with*OUT* another NEWS entry.
    >> 
    >> Indeed, the NEWS apply to (eventually) released versions of R,
    >> so fixing transient bugs is *never* documented in NEWS.
    >> 
    PetRd> Convinced.

    PetRd> And to make this clear:
    PetRd> I did not mean at all to criticize any development undertaken in R-devel
    PetRd> ---
    PetRd> you are all doing a great job in enhancing R, and you deserve all due
    PetRd> acknowledgement for this.

    PetRd> My point was rather that instead of keeping one's own checkout
    PetRd> repository of the R project's svn archives, it would help somehow
    PetRd> to make changes visible / accesible more easily ---
    PetRd> of course without bothering R core developers to actively maintain
    PetRd> this, but rather do this in an automatic way.

    PetRd> Embarrasingly enough, now that you have explained to me the
    PetRd> different purposes of NEWS and svn logs, I realized that there
    PetRd> already  is

    PetRd> http://developer.r-project.org/R.svnlog.2008

    PetRd> (the name of which might get updated to
    PetRd> ..../R.svnlog.2009, though)

    PetRd> Still, one might improve upon this without to much effort,
    PetRd> I think. Possible starting points could be

    PetRd> (1) webSVN + trac access to the R subversion repository
    PetRd> (2) using some r-forge type architecture for R core as well,
    PetRd> --- in particular for the source code management provided there
    PetRd> (3) setting up an RSS feed for the svn logs ---- not unlike
    PetRd> http://developer.r-project.org/blosxom.cgi/R-devel

    PetRd> As one more step ahead one could think of

    PetRd> (4) merging corresponding RSS feeds for CHANGES, NEWS,
    PetRd> and the svn logs in order to see all changes on one spot.

    PetRd> Do you think setting up any of these items would be hard
    PetRd> to establish?

not so hard.

However  I personally would not really want any of these, for at
least two reasons :

1.   For (1), (2) : This needs more ("interactive") web modules
     enabled on  svn.r-project.org.
     When we move the R sources there, one of the reason was
     that the previous R source server(s) had been broken in
     (yes, hackers; ssh identity theft, ... whatever); and one
     of my goals has been to keep the system as secure as
     possible; one part of this was to have as little apache
     modules as necessary, another to have *no* users
     (contrary to R-forge, e.g.)

2.   Only speaking for myself, I think most R-corers prefer not
     to be watched by paparazzi and the mob at large.  Hence,
     *not* providing dashboards or GUIs, but just "good ole"
     programmer's tools is somewhat intentional.


    PetRd> Maybe this is already done; but I have not been aware of this.
    >> ... leading us back to what Brian already said:
    >> >>  'Under development' needs to be taken seriously.
    >> 
    PetRd> if asked, I would have agreed before, and surely now do
    PetRd> even more so...

Good! Thank you, Peter.

Martin Maechler, ETH Zurich


From simon.urbanek at r-project.org  Tue May 19 12:23:08 2009
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Tue, 19 May 2009 12:23:08 +0200
Subject: [Rd] About " Error: C stack usage is too close to the limit"
In-Reply-To: <23586493.100621242700201570.JavaMail.coremail@bj126app62.126.com>
References: <23586493.100621242700201570.JavaMail.coremail@bj126app62.126.com>
Message-ID: <30EB9D3C-9124-4C56-95D4-8A3DBDC19AF2@r-project.org>


On May 19, 2009, at 4:30 AM, goon83 wrote:

> Hi everyone!
>   I meet one problem when embedding R in C code, when I run the the  
> R code in one child thread ,
>   it always print error info:
>    Error: C stack usage is too close to the limit
>
>   I also try to set R_CStackLimit = (uintptr_t)-1 to disable the C  
> stack check as the R-exts doc say,
>   but it still does not work, the error info still exist.
>

That is the way to do it (and other project use it successfully) - the  
fact that it doesn't work means that you probably do it at the wrong  
place (you must set it *after* Rf_initialize_R).

Cheers,
Simon


>   Besides it is interesting that if i put the R code in the main  
> thread(don't create any thread), it work,  and the E-exts doc say  
> that  "Embedded R is designed to be run in the main thread, and all  
> the testing is done in that context." so i wonder is it that  
> Embedded R can not run in the child thread ?
>
>   so, can anybody give some help or suggestion about this problem,
>   any response will be appreciated, tks in advance.
>
> ***********************
> Bin Dong
> BUAA, Beijing PR China
> goon83 at 126.com
> ***********************
>
>   ps: my code, system info and error information list behand
>
>   -----------------------------
>   1, my example code lists here:
>   -----------------------------
>   #include ....
>
>   void *ts_thread(){
>         SEXP e, tmp;
>         int  hadError;
>         int argc = 0;
>         char *argv[1];
>         ParseStatus status;
>
>         init_R(argc, argv);
>
>        PROTECT(tmp = mkString("{print(lh)}"));
>        PROTECT(e = R_ParseVector(tmp, 1, &status, R_NilValue));
>        PrintValue(e);
>        R_tryEval(VECTOR_ELT(e,0), R_GlobalEnv, &hadError);
>
>       UNPROTECT(2);
>       end_R();
> }
>
> int main(int argc, char *argv[]){
>    pthread_t th1;
>    int iret1;
>
>    iret1 = pthread_create(&th1, NULL, ts_thread,NULL);
>    pthread_join(th1, NULL);
>    printf("Thread 1 return:%d\n", iret1);
>
>    return 0;
> }
> -----------------------------------
> 2, My os and compiler is:
> -----------------------------------
> Linux debian 2.6.26-1-686 #1 SMP Sat Jan 10 18:29:31 UTC 2009 i686  
> GNU/Linux
> gcc version 4.3.2 (Debian 4.3.2-1.1)
>
> -----------------------------------
> 3, the error info:
> ------------------------------------
> goon at debian:~/library/R-source/R-2.9.0/tests/Embedding$ ./Rar
> Error: C stack usage is too close to the limit
> Error: C stack usage is too close to the limit
>
> R version 2.7.1 (2008-06-23)
> Copyright (C) 2008 The R Foundation for Statistical Computing
> ISBN 3-900051-07-0
>
> R is free software and comes with ABSOLUTELY NO WARRANTY.
> You are welcome to redistribute it under certain conditions.
> Type 'license()' or 'licence()' for distribution details.
>
> R is a collaborative project with many contributors.
> Type 'contributors()' for more information and
> 'citation()' on how to cite R or R packages in publications.
>
> Type 'demo()' for some demos, 'help()' for on-line help, or
> 'help.start()' for an HTML browser interface to help.
> Type 'q()' to quit R.
>
> expression({
>    print(lh)
> })
> Error: C stack usage is too close to the limit
> Thread 1 return:0
> ------------------------------------------
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From murdoch at stats.uwo.ca  Tue May 19 12:32:54 2009
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue, 19 May 2009 06:32:54 -0400
Subject: [Rd] was: Problem building (binary) packages for Windows
In-Reply-To: <4A112E9F.3070109@web.de>
References: <4A0D5BAD.9050608@web.de>	<alpine.OSX.1.00.0905151445270.59770@tystie.local>	<4A0D7DC6.50009@web.de>	<4A0DB8E3.9090107@statistik.tu-dortmund.de>	<18958.50292.789860.647778@cmath-5.math.ethz.ch>
	<4A112E9F.3070109@web.de>
Message-ID: <4A128AD6.8040102@stats.uwo.ca>

On 18/05/2009 5:47 AM, Peter Ruckdeschel wrote:
> Dear Martin, Uwe and Brian
> 
> thanks for your comments --- point taken:
> 
> On Sat, 16 May 2009, Martin Maechler wrote:
> 
>>>>>>> "UweL" == Uwe Ligges <ligges at statistik.tu-dortmund.de>
>>>>>>>     on Fri, 15 May 2009 20:48:03 +0200 writes:
>>>>>>>             
>> [.............]   
>>
>>     >> Thank you for clarifying this and once again apologies for stirring you
>>     >> up with something that had been fixed in the mean-time already.
>>
>>     UweL> For R-devel, it is in the svn logs. Since it may change again, NEWS is 
>>     UweL> not always edited while things are tested.
>>
>> well, and if a new feature is introduced, it gets a NEWS entry
>> (hopefully), but if the new feature contains bugs, these will be
>> fixed of course with*OUT* another NEWS entry.
>>
>> Indeed, the NEWS apply to (eventually) released versions of R,
>> so fixing transient bugs is *never* documented in NEWS.
>>   
> Convinced.
> 
> And to make this clear:
> I did not mean at all to criticize any development undertaken in R-devel
> ---
> you are all doing a great job in enhancing R, and you deserve all due
> acknowledgement for this.
> 
> My point was rather that instead of keeping one's own checkout
> repository of the R project's svn archives, it would help somehow
> to make changes visible / accesible more easily ---
> of course without bothering R core developers to actively maintain
> this, but rather do this in an automatic way.
> 
> Embarrasingly enough, now that you have explained to me the
> different purposes of NEWS and svn logs, I realized that there
> already  is
> 
>     http://developer.r-project.org/R.svnlog.2008
> 
> (the name of which might get updated to
>    ..../R.svnlog.2009, though)
> 
> Still, one might improve upon this without to much effort,
> I think. Possible starting points could be
> 
> (1) webSVN + trac access to the R subversion repository
> (2) using some r-forge type architecture for R core as well,
>      --- in particular for the source code management provided there
> (3) setting up an RSS feed for the svn logs ---- not unlike
>      http://developer.r-project.org/blosxom.cgi/R-devel
> 
> As one more step ahead one could think of
> 
> (4) merging corresponding RSS feeds for CHANGES, NEWS,
> and the svn logs in order to see all changes on one spot.
> 
> Do you think setting up any of these items would be hard
> to establish?

(3) would be easy if R had a package that gave access to the svn API, 
which would be a nice thing for lots of other reasons too. (Other 
languages have bindings, but then it would have to be someone other than 
me to do the work...)

(4) doesn't really make sense:  CHANGES and NEWS are basically the same 
thing, but the svn logs have a completely different character.

Re (1), svn now allows easy mirroring of a repository, so anyone who was 
interested could set up such access to a mirror.

Duncan Murdoch

> 
> Maybe this is already done; but I have not been aware of this.
>> ... leading us back to what Brian already said:
>>   >>  'Under development' needs to be taken seriously.
>>   
> if asked, I would have agreed before, and surely now do
> even more so...
> 
> Thanks again, best
> Peter
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From michal2992 at gmail.com  Tue May 19 14:57:43 2009
From: michal2992 at gmail.com (=?ISO-8859-2?Q?Micha=B3_Bojanowski?=)
Date: Tue, 19 May 2009 14:57:43 +0200
Subject: [Rd] S4 method dispatch and namespaces: why is default method
	selected
In-Reply-To: <6phr5ylagjr.fsf@gopher4.fhcrc.org>
References: <e1fa237d0905180631h5a6144ao5cf5c65b22bb9fce@mail.gmail.com> 
	<6phr5ylagjr.fsf@gopher4.fhcrc.org>
Message-ID: <e1fa237d0905190557o32c84b60u6ee83058220a4c71@mail.gmail.com>

Hi Martin,

>> However, when I put all these in a package with Depends field in
>> DESCRIPTION having: methods, pixmap, and with the following namespace:
>>
>>
>> importFrom("graphics", "plot")
>> exportClasses("myclass")
>> exportMethods("plot")
>>
>>
>> things stop working (this is from package test):
>>
>>
>>> f <- system.file(file.path("pictures", "logo.ppm"), package="pixmap")
>>> o <- new("myclass", a=read.pnm(f), title="tytul")
>>> plot(o)
>> Error in as.double(y) :
>>   cannot coerce type 'S4' to vector of type 'double'
>> Calls: plot ... plot -> .local -> plot -> plot.default -> xy.coords
>> Execution halted
>>
>>
>>
>> So apparently calling 'plot' dispatches the default method instead of using the
>> one from package 'pixmap'. Why?
>
> Not speaking authoritatively, but plot,myclass,missing-method is
> defined in your name space, and so has access only to symbols defined
> or imported into the name space. The plot,pixmap,ANY-method is not in
> your name space (even though it's on the search path), and so is not
> found. Clever of the methods package to keep track of this.

Thanks a lot, I was not aware of that. Given that 'pixmap' package does not
have a namespace I was somehow convinced that all the classes and methods
provided by this package will be visible for other packages. In fact, I was
also convinced that the '::' operator applies only to packages with namespaces.
Which is not the case and the help page for :: is clear about that.

> the only solution is
>
>  pixmap::plot(x=x at img, ...)

And this works, thanks again.


Micha?


From maechler at stat.math.ethz.ch  Tue May 19 15:08:07 2009
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 19 May 2009 15:08:07 +0200
Subject: [Rd] Automatic Differentiation for R
In-Reply-To: <971536df0904150653v3680b512x44d9c2987e69628b@mail.gmail.com>
References: <mailman.23.1239789606.8943.r-devel@r-project.org>
	<49E5E171.6030603@uottawa.ca>
	<971536df0904150653v3680b512x44d9c2987e69628b@mail.gmail.com>
Message-ID: <18962.44855.753611.51326@lynne.math.ethz.ch>

[MM stumbling over on old thread ... he'd be interested]

>>>>> "GaGr" == Gabor Grothendieck <ggrothendieck at gmail.com>
>>>>>     on Wed, 15 Apr 2009 09:53:18 -0400 writes:

    GaGr> Not sure if this is sufficient for your needs but R does include symbolic
    GaGr> differentiation, see ?D, and the Ryacas and rSymPy
    GaGr> packages interface R to the yacas and sympy computer algebra
    GaGr> systems (CAS) and those system include symbolic differentiation.

No, symbolic differentiation is not enough.
Automatic Differentiation (AD) is something much more general (in one
way) and much less mathematical from  a classical view point:
But then, AD is much more generally useful for minimization as, basically,
the input is an R function 
    f(x)     	       {with x multidimensional}
or  f(x1,x2, ..., xp)  {with scalar x1, x2, ..}
and the output is again an R function
which computes f() and all {or just selected} partial
derivatives  d f / d{xi}.

Now consider that the function f()  can contain if() and while()
clauses and conceptually ever language feature of R.
In practice, I'm pretty sure the list of features would have to
be restricted, similarly as they'd have to for an R compiler to
be feasible.

I agree that  AD for R would be very nice and could be very
useful.
I'd also be interested to help AD people learn the S4 classes
and methods (hoping that it's close enough to what they call
"operator overloading" something I'd presume to be less general
than the powerful S4 class/methods system).

Martin Maechler, ETH Zurich

    GaGr> http://ryacas.googlecode.com
    GaGr> http://rsympy.googlecode.com
    
    [.............]

    GaGr> On Wed, Apr 15, 2009 at 9:30 AM, John C Nash <nashjc at uottawa.ca> wrote:
    >> In efforts to improve optimization tools for R, one of my
    >> interests has been getting automatic differentiation capabilities
    >> so that analytic rather than numerical derivatives can be used. They
    >> would be helpful in several other areas besides optimization, My timings
    >> show
    >> factors of the order of 1000s in time improvements by avoiding
    >> numerical derivatives in some cases.
    >> 
    >> There has been some work in this e.g.,
    >> http://code.google.com/p/pbs-software/
    >> is an R interface to ADMB (Automatic Differentiation Model Builder).
    >> However,
    >> as far as I can see, this is directed essentially to nonlinear least squares
    >> modelling,
    >> an important but not general problem.
    >> 
    >> Tom Coleman of Waterloo responded favourably with some advice, but the most
    >> enthusiastic answer came from Shaun Forth, which I have included below. I
    >> read
    >> this as an opportunity to develop what could be a profitable collaboration
    >> with
    >> the AD community. Unfortunately, I cannot take up the invitation to join the
    >> AD
    >> folk in Oxford due to a pre-existing obligation. Nor am I more than a
    >> complete
    >> novice with S3 and S4 classes etc. I am, nevertheless, willing to help
    >> organize
    >> the effort e.g., do some of the communications, chasing grant money, getting
    >> Google Summer of Code applications filled in etc.
    >> 
    >> Can the R community come up with a few people who can provide the AD
    >> workers with appropriate information? If so, is there a reasonable chance to
    >> generate sufficient funding for a student? I suspect the answer in both
    >> cases
    >> is yes, but that we need some form of "booster cables" to get things going.
    >> (In Canada, booster cables are used to get cars started in winter by
    >> connecting
    >> a running vehicle's battery to that of a dead one.)
    >> 
    >> I suggest communications off-list until there is progress to report.
    >> Possibly
    >> there is a better forum for this -- suggestions welcome.
    >> 
    >> John Nash
    >> 
    >> ---- included msg from Shaun Forth ---
    >> 
    >> Hi John,
    >> My computational statistics colleague Trevor Ringrose has asked me to
    >> consider AD in R in the past. As you may or may not be aware AD is
    >> implemented in one of two ways: overloading using OO features of the
    >> target language, or source transformation using compiler tools (after
    >> several man years of development) to read in the target code and spit
    >> out the differentiated code. Last time I looked I didn't think the
    >> object oriented features of R were up to overloading but on checking
    >> today I can see that this might now be possible (I can see overloading
    >> of arithmetic operators and functions for example now which I didn't see
    >> last time).
    >> I'd certainly be interested in following this up particularly on the
    >> overloading side but would need to get funding for a PhD student to do
    >> the graft. It would be particularly interesting doing this in an open
    >> source language because we could then perhaps tweak some of the core
    >> language features if they didn't seamlessly support the AD (we can't do
    >> this in Matlab and that is a pain!).
    >> 
    >> My immediate suggestion is that you, or some other more local (to UK) R
    >> expert talks at the next European AD workshop in Oxford
    >> http://www.autodiff.org/?module=Workshops&submenu=EuroAD/8/main
    >> We're a very friendly group and I'm sure there are others who might like
    >> to tackle R or perhaps we could put together a multigroup project. If
    >> someone could give a talk on R, its language features including the OO
    >> aspects, and some optimisation examples with associated code, the group
    >> there would be able to give you the best feedback on the planet on the
    >> possibilities.
    >> 
    >> Please do treat this as a positive response and let's keep in touch on
    >> this.
    >> 
    >> Regards
    >> 
    >> Shaun
    >> 
    >> 
    >> ####################################################################
    >> Dr Shaun Forth
    >> Applied Mathematics & Scientific Computation
    >> Cranfield Defence and Security Cranfield University, Shrivenham Campus
    >> Swindon SN6 8LA, England
    >> tel: +44 (0)1793 785311
    >> fax: +44 (0)1793 784196
    >> email: S.A.Forth at cranfield.ac.uk
    >> http://www.amorg.co.uk
    >> #####################################################################
    >>


From nashjc at uottawa.ca  Tue May 19 15:18:08 2009
From: nashjc at uottawa.ca (John C Nash)
Date: Tue, 19 May 2009 09:18:08 -0400
Subject: [Rd] Automatic Differentiation for R
Message-ID: <4A12B190.3070709@uottawa.ca>

Martin (see below) gives a good explanation of the difference between AD and symbolic
differentiations. I'm of the opinion we can use both. However, the real issue as far
as I'm concerned (from an optimizer's point of view, which may also be that of ODE and
PDE folk) is that right now none of the offerings that we have are easy to use. Indeed,
usability is one of the key issues in my current efforts to improve optimization tools.

There are several people in UK from both AD and R sides who are communicating,
an initiative that Shaun F. helped get going. I'm copying the folk I think are
involved -- forgive omissions and pass things along please. The main purpose of this
message is to ensure Martin's offer is noted, as in my opinion his knowledge of the
R internals is very valuable.

Cheers, JN






[MM stumbling over on old thread ... he'd be interested]


>>>>> >>>>> "GaGr" == Gabor Grothendieck <ggrothendieck at gmail.com>
>>>>> >>>>>     on Wed, 15 Apr 2009 09:53:18 -0400 writes:
>>>>>           

    GaGr> Not sure if this is sufficient for your needs but R does include symbolic
    GaGr> differentiation, see ?D, and the Ryacas and rSymPy
    GaGr> packages interface R to the yacas and sympy computer algebra
    GaGr> systems (CAS) and those system include symbolic differentiation.

No, symbolic differentiation is not enough.
Automatic Differentiation (AD) is something much more general (in one
way) and much less mathematical from  a classical view point:
But then, AD is much more generally useful for minimization as, basically,
the input is an R function 
    f(x)     	       {with x multidimensional}
or  f(x1,x2, ..., xp)  {with scalar x1, x2, ..}
and the output is again an R function
which computes f() and all {or just selected} partial
derivatives  d f / d{xi}.

Now consider that the function f()  can contain if() and while()
clauses and conceptually ever language feature of R.
In practice, I'm pretty sure the list of features would have to
be restricted, similarly as they'd have to for an R compiler to
be feasible.

I agree that  AD for R would be very nice and could be very
useful.
I'd also be interested to help AD people learn the S4 classes
and methods (hoping that it's close enough to what they call
"operator overloading" something I'd presume to be less general
than the powerful S4 class/methods system).

Martin Maechler, ETH Zurich


From maechler at stat.math.ethz.ch  Tue May 19 15:49:13 2009
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 19 May 2009 15:49:13 +0200
Subject: [Rd] stringsAsFactors .... in expand.grid() etc
In-Reply-To: <421CD833-3D4B-4C8B-8DD9-24A1A6965BF5@auckland.ac.nz>
References: <loom.20090518T220645-789@post.gmane.org>
	<421CD833-3D4B-4C8B-8DD9-24A1A6965BF5@auckland.ac.nz>
Message-ID: <18962.47321.715556.689459@lynne.math.ethz.ch>

>>>>> "RT" == Rolf Turner <r.turner at auckland.ac.nz>
>>>>>     on Tue, 19 May 2009 11:02:08 +1200 writes:

    RT> On 19/05/2009, at 10:20 AM, Steve Lianoglou wrote:

    >> Hi all,
    >> 
    >> I've (tried) to look through the bug tracker, and gmane-search the  
    >> R list to
    >> see if this has been mentioned before, and it looks like it hasn't.
    >> 
    >> According to the R 2.9.0 release notes[1], the expand.grid function  
    >> should now
    >> take a stringsAsFactor=LOGICAL argument which controls whether or  
    >> not the
    >> function coerces strings as factors. While the parameter is indeed  
    >> in the
    >> function, a quick examination of the function's source shows that  
    >> the value
    >> of this argument is never checked, and all strings are converted to  
    >> factors
    >> as a matter of course.
    >> 
    >> The fix is pretty easy, and I believe only requires changing the  
    >> `if` check
    >> here:
    >> 
    >> if (!is.factor(x) && is.character(x))
    >> x <- factor(x, levels = unique(x))
    >> 
    >> To:
    >> 
    >> if (!is.factor(x) && is.character(x) && stringsAsFactors)
    >> x <- factor(x, levels = unique(x))
    >> 
    >> I can open a ticket regarding this issue and add this there if  
    >> necessary.

Thank you, but it's  not necessary anymore;   we (R Core Team)
have already opened a ticket...

    >> Thanks,
    >> -steve
    >> 
    >> [1] http://article.gmane.org/gmane.comp.lang.r.general/146891

    RT> While we're at it --- would it not make sense to have the  
    RT> stringsAsFactors
    RT> argument (once it's working) of expand.grid() default to options() 
    RT> $stringsAsFactors,
    RT> rather than to FALSE?

NNNNNNNNNNNNNNNOOOOOOOOOOOOOOOOOOOOOOO !!!!!

    RT> This would make no difference to me personally, since I set
    RT> options(stringsAsFactors=FALSE) in my .Rprofile.  But it might make some
    RT> people happier ....

As I have said several times (on R-devel rather than R-help),
I strongly believe that the introduction of such an option has
been one of very few very bad choices we (the R core team) have
made in the recent past.
Setting an option should *never* influence (basic) R
computational functionality; options() typically should only
influence print()ing, maybe plotting() and similar I/O.

I still hope that I'll find the stamina in the not so distant
future to convince a majority within R-core to abolish this
abominational option, of course with transitional help for the
stringsAsFactors_=_FALSE junkies.

Martin Maechler


From ggrothendieck at gmail.com  Tue May 19 15:57:34 2009
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 19 May 2009 09:57:34 -0400
Subject: [Rd] Automatic Differentiation for R
In-Reply-To: <18962.44855.753611.51326@lynne.math.ethz.ch>
References: <mailman.23.1239789606.8943.r-devel@r-project.org> 
	<49E5E171.6030603@uottawa.ca>
	<971536df0904150653v3680b512x44d9c2987e69628b@mail.gmail.com> 
	<18962.44855.753611.51326@lynne.math.ethz.ch>
Message-ID: <971536df0905190657t168a4be2w4887c8308dd50810@mail.gmail.com>

On Tue, May 19, 2009 at 9:08 AM, Martin Maechler
<maechler at stat.math.ethz.ch> wrote:
> [MM stumbling over on old thread ... he'd be interested]
>
>>>>>> "GaGr" == Gabor Grothendieck <ggrothendieck at gmail.com>
>>>>>> ? ? on Wed, 15 Apr 2009 09:53:18 -0400 writes:
>
> ? ?GaGr> Not sure if this is sufficient for your needs but R does include symbolic
> ? ?GaGr> differentiation, see ?D, and the Ryacas and rSymPy
> ? ?GaGr> packages interface R to the yacas and sympy computer algebra
> ? ?GaGr> systems (CAS) and those system include symbolic differentiation.
>
> No, symbolic differentiation is not enough.
> Automatic Differentiation (AD) is something much more general (in one
> way) and much less mathematical from ?a classical view point:
> But then, AD is much more generally useful for minimization as, basically,
> the input is an R function
> ? ?f(x) ? ? ? ? ? ? ? {with x multidimensional}
> or ?f(x1,x2, ..., xp) ?{with scalar x1, x2, ..}
> and the output is again an R function
> which computes f() and all {or just selected} partial
> derivatives ?d f / d{xi}.
>
> Now consider that the function f() ?can contain if() and while()
> clauses and conceptually ever language feature of R.
> In practice, I'm pretty sure the list of features would have to
> be restricted, similarly as they'd have to for an R compiler to
> be feasible.
>
> I agree that ?AD for R would be very nice and could be very
> useful.
> I'd also be interested to help AD people learn the S4 classes
> and methods (hoping that it's close enough to what they call
> "operator overloading" something I'd presume to be less general
> than the powerful S4 class/methods system).

The overloading facilities present have already been discussed in
this thread including a complete illustration of using them for the
problem at hand.

rSymPy and Ryacas both support overloading.

Ryacas also supports automatic differentiation
of one line R functions but its not fully developed and very limited.
See demo("Ryacas-Function") which shows differentiation of the
Burr CDF to get the PDF.

Here are a few more simpler examples to illustrate overloading in
these packages.

> library(Ryacas)
Loading required package: XML
> x <- Sym("x")
> x+x
[1] "Starting Yacas!"
expression(2 * x)

> library(rSymPy)
Loading required package: rJava
> source("http://rsympy.googlecode.com/svn/trunk/R/Sym.R")
> y <- Sym(sympy("var('y')"))
> y+y
[1] "2*y"

Check the home pages of the packages for more info.


From goon83 at 126.com  Tue May 19 17:02:26 2009
From: goon83 at 126.com (goon83)
Date: Tue, 19 May 2009 23:02:26 +0800 (CST)
Subject: [Rd] About " Error: C stack usage is too close to the limit"
In-Reply-To: <30EB9D3C-9124-4C56-95D4-8A3DBDC19AF2@r-project.org>
References: <30EB9D3C-9124-4C56-95D4-8A3DBDC19AF2@r-project.org>
	<23586493.100621242700201570.JavaMail.coremail@bj126app62.126.com>
Message-ID: <8709504.432751242745346733.JavaMail.coremail@bj126app15.126.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090519/f5912ea8/attachment.pl>

From s.a.forth at cranfield.ac.uk  Tue May 19 18:24:14 2009
From: s.a.forth at cranfield.ac.uk (Forth, Shaun)
Date: Tue, 19 May 2009 17:24:14 +0100
Subject: [Rd] Automatic Differentiation for R
In-Reply-To: <971536df0905190657t168a4be2w4887c8308dd50810@mail.gmail.com>
References: <mailman.23.1239789606.8943.r-devel@r-project.org>
	<49E5E171.6030603@uottawa.ca>
	<971536df0904150653v3680b512x44d9c2987e69628b@mail.gmail.com>
	<18962.44855.753611.51326@lynne.math.ethz.ch>
	<971536df0905190657t168a4be2w4887c8308dd50810@mail.gmail.com>
Message-ID: <B4EC2F0829368F43B9D603A3F207EAD750992A@exchange1.cds.cranfield.ac.uk>

Thanks for your interest in this topic.  

In the AD community we are used to dealing with essentially arbitrarily complex computer code.  Some Fortran and C activities have looked at applications such as global climate models and computational fluid dynamics codes for aerospace design.  Fortran and C have relatively small intrinsic operations and function set.  I've done quite of lot or work with Matlab and had to consider "intrinsics" such as linear solves and determinants; this is probably more like the R approach. Matlab software is used by industry and commerce for involved computations with loops, branches and some collaborators have considered OO programs.

I look forward to hearing about R at the Oxford AD meeting and perhaps seeing if we can start to explore some efficient AD implementations.

Shaun





##################################################################### 
Dr Shaun Forth 
Applied Mathematics & Scientific Computation
Cranfield Defence and Security 
Cranfield University, Shrivenham Campus
Swindon SN6 8LA, England 
tel: +44 (0)1793 785311 
fax: +44 (0)1793 784196 
email: S.A.Forth at cranfield.ac.uk 
http://www.amorg.co.uk 
##################################################################### 

>-----Original Message-----
>From: Gabor Grothendieck [mailto:ggrothendieck at gmail.com] 
>Sent: Tuesday, May 19, 2009 2:58 PM
>To: Martin Maechler
>Cc: John C Nash; r-devel at r-project.org; Forth, Shaun
>Subject: Re: [Rd] Automatic Differentiation for R
>
>On Tue, May 19, 2009 at 9:08 AM, Martin Maechler
><maechler at stat.math.ethz.ch> wrote:
>> [MM stumbling over on old thread ... he'd be interested]
>>
>>>>>>> "GaGr" == Gabor Grothendieck <ggrothendieck at gmail.com>
>>>>>>> ? ? on Wed, 15 Apr 2009 09:53:18 -0400 writes:
>>
>> ? ?GaGr> Not sure if this is sufficient for your needs but R 
>does include symbolic
>> ? ?GaGr> differentiation, see ?D, and the Ryacas and rSymPy
>> ? ?GaGr> packages interface R to the yacas and sympy computer algebra
>> ? ?GaGr> systems (CAS) and those system include symbolic 
>differentiation.
>>
>> No, symbolic differentiation is not enough.
>> Automatic Differentiation (AD) is something much more general (in one
>> way) and much less mathematical from ?a classical view point:
>> But then, AD is much more generally useful for minimization 
>as, basically,
>> the input is an R function
>> ? ?f(x) ? ? ? ? ? ? ? {with x multidimensional}
>> or ?f(x1,x2, ..., xp) ?{with scalar x1, x2, ..}
>> and the output is again an R function
>> which computes f() and all {or just selected} partial
>> derivatives ?d f / d{xi}.
>>
>> Now consider that the function f() ?can contain if() and while()
>> clauses and conceptually ever language feature of R.
>> In practice, I'm pretty sure the list of features would have to
>> be restricted, similarly as they'd have to for an R compiler to
>> be feasible.
>>
>> I agree that ?AD for R would be very nice and could be very
>> useful.
>> I'd also be interested to help AD people learn the S4 classes
>> and methods (hoping that it's close enough to what they call
>> "operator overloading" something I'd presume to be less general
>> than the powerful S4 class/methods system).
>
>The overloading facilities present have already been discussed in
>this thread including a complete illustration of using them for the
>problem at hand.
>
>rSymPy and Ryacas both support overloading.
>
>Ryacas also supports automatic differentiation
>of one line R functions but its not fully developed and very limited.
>See demo("Ryacas-Function") which shows differentiation of the
>Burr CDF to get the PDF.
>
>Here are a few more simpler examples to illustrate overloading in
>these packages.
>
>> library(Ryacas)
>Loading required package: XML
>> x <- Sym("x")
>> x+x
>[1] "Starting Yacas!"
>expression(2 * x)
>
>> library(rSymPy)
>Loading required package: rJava
>> source("http://rsympy.googlecode.com/svn/trunk/R/Sym.R")
>> y <- Sym(sympy("var('y')"))
>> y+y
>[1] "2*y"
>
>Check the home pages of the packages for more info.
>


From romain.francois at dbmail.com  Tue May 19 20:31:14 2009
From: romain.francois at dbmail.com (Romain Francois)
Date: Tue, 19 May 2009 20:31:14 +0200
Subject: [Rd] package level connection API
Message-ID: <4A12FAF2.5010305@dbmail.com>

Hello,

In 2006 Jeffrey Horner proposed [1,2] a patch to allow package level 
access to the connection API from C code. As I'm involved in a few 
packages that would benefit from this exposure, I felt I would warm the 
discussion up.

Does this stand a chance of happening ?

Romain

[1] http://tolstoy.newcastle.edu.au/R/e2/devel/06/10/0565.html

[2] http://wiki.r-project.org/rwiki/doku.php?id=developers:r_connections_api


-- 
Romain Francois
Independent R Consultant
+33(0) 6 28 91 30 30
http://romainfrancois.blog.free.fr


From jeff.a.ryan at gmail.com  Tue May 19 21:26:29 2009
From: jeff.a.ryan at gmail.com (Jeff Ryan)
Date: Tue, 19 May 2009 14:26:29 -0500
Subject: [Rd] readBin on binary non-blocking connections (Windows & Unix
	differences/bugs)
In-Reply-To: <e8e755250905181040k593e8b5al4725972d109c4d8a@mail.gmail.com>
References: <e8e755250905181040k593e8b5al4725972d109c4d8a@mail.gmail.com>
Message-ID: <e8e755250905191226x76a415d3h790ba2f4540379bb@mail.gmail.com>

R-devel:

I'll escalate this to a bug report once I can fully document, but
something is seriously wrong with readBin on non-blocking connections.

>From ?readBin

Value:

     For 'readBin', a vector of appropriate mode and length the number
     of items read (which might be less than 'n').

On Windows, 'n' elements are always returned.  If 'n' < items waiting
to be read, then the vector of length 'n' will be returned with the
expected items.

If n > items, a vector of length n (yes, n) will be returned, padded
with random values taken from (somewhere???) in memory.

As expressed in a previous email, if what=raw() and n > items, the
entire process fails with an error.  The items are effectively read
and discarded.

I would be interested in assisting further with a patch, but I would
hope that someone (R-core or otherwise) who knows a bit more about the
internals of socket connections in R (w.r.t Windows - as *nix works
fine) could provide some much needed insight.

Best,
Jeff Ryan

On Mon, May 18, 2009 at 12:40 PM, Jeff Ryan <jeff.a.ryan at gmail.com> wrote:
> R-devel:
>
> I am encountering a consistency issue using socketConnection and
> readBin with *non-blocking* connections on Unix and Windows XP (no
> Vista to test).
>
> I am a bit confused by the behavior of *non-blocking* connections
> under Windows specifically. ?When calling readBin on a non-blocking
> connection when there is no data to read on the socket, the connection
> under Unix will return a vector of zero-length matching the type of
> the 'what' argument to the readBin call.
>
> The same call under Windows returns random data unless called with
> what=raw(), which instead returns an error.
>
>
> A simple example using two R processes to illustrate on one machine:
>
>
> #########################################################################
> # PROCESS 1 (Windows/Unix -- the same code for both):
> #########################################################################
>
> # Open the connection and don't write anything
>
> s <- socketConnection(port=7777, server=TRUE, blocking=TRUE,open="ab")
>
> #########################################################################
> # PROCESS 2 (Windows) use this to read:
> #########################################################################
>
> s <- socketConnection(port=7777,blocking=FALSE,open="ab")
> readBin(s, character())
> readBin(s, character())
> readBin(s, double())
> readBin(s, raw())
>
> # > readBin(s, character())
> # [1] "\020??\001@??\001 $?\001 $?\001 $?\001 $?\001 $?\001 $?\001
> $?\001 $?\001 ...
> # > readBin(s, character())
> # [1] "X\n"
> # > readBin(s, double())
> # [1] 1.255609e-316
> # > readBin(s, raw())
> # Error in readBin(s, raw()) : negative length vectors are not allowed
>
> ##########################################################################
> # Using a *nix, the above works as I would expect
> #
> # PROCESS 2 (Unixes -- this example OSX 10.4, but is consistent on
> other flavors)
> #########################################################################
>
> s <- socketConnection(port=7777,blocking=FALSE, open="ab")
> readBin(s, character())
> readBin(s, raw())
> readBin(s, double())
>
> # > readBin(s, character())
> # character(0)
> # > readBin(s, raw())
> # raw(0)
> # > readBin(s, double())
> # numeric(0)
>
> Is this a bug in R or Windows? ?Is there a workaround? ?I would like
> to have readBin on non-blocking connections work consistently across
> platforms. ?When data is present, both platforms behave consistently.
> Incidentally, the readBin calls in my program are not using R as the
> server, the above code is simply to illustrate the problem.
>
> The fact that the raw() returns an error on Windows seems to indicate
> that the error is able to be caught, and could be tested for.
>
> One other interesting point of note; the character() calls on Windows
> will return not just random data, but very non-random R type strings.
> Somehow non-allocated memory is being read.
>
>> readBin(s, character(),100)
> ?[1] "X\n"
> ?[2] "spatch"
> ?[3] ""
> ?[4] ""
> ?[5] "X\n"
> ?[6] "ssion"
> ?[7] "\002"
> ?[8] "?$?\001?|?\001\030[?\001?N?\001?N?\001?$?\001\004"
> ?[9] "H\024?\001\f\025?\001,??\001\002\002"
> ?[10] "?\026?\001?$?\001\005"
> ?[11] ""
> ?[12] "s.logical"
> ...
> ?[75] "8}?\001?~?\001\020??\001?$?\001?}?\001?$?\001???\001
> $?\001???\001?~?\0014~?\001???\001?|?\001???\001???\001\034}?\001???\001
> $?\001?|?\001?\177?\001"
> ?[76] "?$?\001?$?\001???\001\030??\001T??\001?$?\001?$?\001
> $?\001???\0010??\001?$?\001?$?\001???\0014??\001
> \177?\001X??\001\034??\001?$?\001???\001???\001
> |?\001\004??\001???\0010\177?\001???\001?{?\001<??\001
> $?\001???\001?}?\001 ??\001?$?\001?$?\001\024\177?\001
> $?\001t??\001???\001?}?\001?$?\001?$?\001t|?\001?$?\001
> $?\001?\177?\001???\001?|?\001 |?\001?$?\001d??\001
> $?\001???\001x{?\001?$?\001"
> ?[77] "' must be of length 1"
>
> This behavior has been noticed by me at least as early as 2.6, and is
> currently seen under 2.9.0.
>
> Thanks for any pointers,
> Jeff Ryan
>
>
> --
> Jeffrey Ryan
> jeffrey.ryan at insightalgo.com
>
> ia: insight algorithmics
> www.insightalgo.com
>



-- 
Jeffrey Ryan
jeffrey.ryan at insightalgo.com

ia: insight algorithmics
www.insightalgo.com


From kynnjo at gmail.com  Tue May 19 22:22:18 2009
From: kynnjo at gmail.com (Kynn Jones)
Date: Tue, 19 May 2009 16:22:18 -0400
Subject: [Rd] Qs: The list of arguments, wrapping functions...
Message-ID: <c2350ba40905191322y2bffbfdu79f4cb480732252e@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090519/f67afe37/attachment.pl>

From steve at revolution-computing.com  Tue May 19 23:05:26 2009
From: steve at revolution-computing.com (Steve Weston)
Date: Tue, 19 May 2009 17:05:26 -0400
Subject: [Rd] Qs: The list of arguments, wrapping functions...
In-Reply-To: <c2350ba40905191322y2bffbfdu79f4cb480732252e@mail.gmail.com>
References: <c2350ba40905191322y2bffbfdu79f4cb480732252e@mail.gmail.com>
Message-ID: <4f7bf0100905191405t750fddfbrf5258788d5c1a390@mail.gmail.com>

On Tue, May 19, 2009 at 4:22 PM, Kynn Jones <kynnjo at gmail.com> wrote:

> 2. I have a package in which most of the functions have the form:
>
> the.function <- function(some, list, of, params) {
> ? ?return( some.other.function(the.list.of.params.to.this.function));
> }
>
> Is there a way that I can use a loop to define all these functions?

How about something like this:

    funnames <- c('f1', 'f2', 'f3')

    funfactory <- function(n) {
      f <- function(...) NULL
      body(f) <- substitute(REPLACE(...), list(REPLACE=as.name(n)))
      f
    }

    funlist <- lapply(funnames, funfactory)

"funlist" is a list of function objects that wrap calls to the
named functions.

> In general, I'm looking for all the information I can find on the subject of
> dynamic function definition (i.e. using code to automate the definition of
> functions at runtime). ?I'm most interested in introspection facilities and
> dynamic code generation. ?E.g. is it possible to write a module that
> "redefines itself" when sourced? ?Or can a function redefine itself when
> first run? ?Or how can a function find out about how it was called?

You should read chapter 6 of the "R Language Definition" manual, which is
titled "Computing on the language".

-- 
Steve Weston
REvolution Computing
One Century Tower | 265 Church Street, Suite 1006
New Haven, CT  06510
P: 203-777-7442 x266 | www.revolution-computing.com


From h.wickham at gmail.com  Tue May 19 23:38:19 2009
From: h.wickham at gmail.com (hadley wickham)
Date: Tue, 19 May 2009 14:38:19 -0700
Subject: [Rd] Qs: The list of arguments, wrapping functions...
In-Reply-To: <c2350ba40905191322y2bffbfdu79f4cb480732252e@mail.gmail.com>
References: <c2350ba40905191322y2bffbfdu79f4cb480732252e@mail.gmail.com>
Message-ID: <f8e6ff050905191438o19d7f9afr67a0dd3ccd41e935@mail.gmail.com>

> 1. Is there a way for a function to refer generically to all its actual
> arguments as a list? ?I'm thinking of something like the @_ array in Perl or
> the arguments variable in JavaScript. ?(By "actual" I mean the ones that
> were actually passed, as opposed to its formal arguments, as returned by
> formals()).

match.call ?

Hadley

-- 
http://had.co.nz/


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Tue May 19 23:42:06 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Tue, 19 May 2009 23:42:06 +0200
Subject: [Rd] Qs: The list of arguments, wrapping functions...
In-Reply-To: <c2350ba40905191322y2bffbfdu79f4cb480732252e@mail.gmail.com>
References: <c2350ba40905191322y2bffbfdu79f4cb480732252e@mail.gmail.com>
Message-ID: <4A1327AE.4040000@idi.ntnu.no>

Kynn Jones wrote:
> Hi.  I'm pretty new to R, but I've been programming in other languages for
> some time.  I have a couple of questions regarding programming with function
> objects.
> 1. Is there a way for a function to refer generically to all its actual
> arguments as a list?  I'm thinking of something like the @_ array in Perl or
> the arguments variable in JavaScript.  (By "actual" I mean the ones that
> were actually passed, as opposed to its formal arguments, as returned by
> formals()).
>   

a quick shot from a naive r user:

    f = function(a=1, b, ...)
        as.list(match.call()[-1])

    f(2)
    f(b=2)
    f(1,2,3)


> 2. I have a package in which most of the functions have the form:
>
> the.function <- function(some, list, of, params) {
>     return( some.other.function(the.list.of.params.to.this.function));
> }
>
> Is there a way that I can use a loop to define all these functions?
>   

what do you mean, precisely?

> In general, I'm looking for all the information I can find on the subject of
> dynamic function definition (i.e. using code to automate the definition of
> functions at runtime).  I'm most interested in introspection facilities and
> dynamic code generation.  E.g. is it possible to write a module that
> "redefines itself" when sourced?  Or can a function redefine itself when
> first run?  Or how can a function find out about how it was called?
>   

another quick shot from a naive r user:

    f = function()
       assign(
           as.character(match.call()[[1]]),
           function() evil(),
           envir=parent.frame())
      
    f
    f()
    f

you can then use stuff like formals, body, match.call, parent.frame,
etc. to have your function reimplement itself based on how and where it
is called.

> FWIW, Some of the things I'd like to do are in the spirit of a decorator in
> Python, which is a function that take a function f an argument and return
> another function g that is somehow based on f.  For example, this makes it
> very easy to write functions as wrappers to other simpler functions.
>   

recall that decorators, when applied using the @syntax, do not just
return a new function, but rather redefine the one to which they are
applied.  so in r it would not be enough to write a function that takes
a function and returns another one;  it'd have to establish the input
function's name and the environment it resides in, and then replace that
entry in that environment with the new function.

yet another quick shot from the same naive r user:

    # the decorator operator
    '%@%' = function(decorator, definition) {
       definition = substitute(definition)
       name = definition[[2]][[2]]
       definition = definition[[2]][[3]]
       assign(
           as.character(name),
           decorator(eval(definition, envir=parent.frame())),
           envir=parent.frame()) }

    # a decorator
    twice = function(f)
       function(...)
           do.call(f, as.list(f(...)))

    # a function
    inv = function(a, b)
       c(b, a)

    inv(1,2)
    # 2 1
    twice(inv)(1,2)
    # 1 2

    # a decorated function
    twice %@% {
       square = function(x) x^2 }

    square(2)
    # 16

    # another decorator
    verbose = function(f)
       function(...) {
          cat('computing...\n')
          f(...) }

    # another decorated function
    verbose %@% {
       square = function(x) x^2 }

    square(2)
    # computing...
    # 4

there is certainly a lot of space for improvements, and there are
possibly bugs in the code above, but i hope it helps a little.

vQ


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Wed May 20 00:03:16 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Wed, 20 May 2009 00:03:16 +0200
Subject: [Rd] Qs: The list of arguments, wrapping functions...
In-Reply-To: <4A1327AE.4040000@idi.ntnu.no>
References: <c2350ba40905191322y2bffbfdu79f4cb480732252e@mail.gmail.com>
	<4A1327AE.4040000@idi.ntnu.no>
Message-ID: <4A132CA4.3020707@idi.ntnu.no>

Wacek Kusnierczyk wrote:
> Kynn Jones wrote:
>   
>
>> In general, I'm looking for all the information I can find on the subject of
>> dynamic function definition (i.e. using code to automate the definition of
>> functions at runtime).  I'm most interested in introspection facilities and
>> dynamic code generation.  E.g. is it possible to write a module that
>> "redefines itself" when sourced?  Or can a function redefine itself when
>> first run?  Or how can a function find out about how it was called?
>>   
>>     
>
> another quick shot from a naive r user:
>
>     f = function()
>        assign(
>            as.character(match.call()[[1]]),
>            function() evil(),
>            envir=parent.frame())
>   
or maybe

    f = function()
       body(f) <<- expression(evil())


>       
>     f
>     f()
>     f
>   

vQ


From kynnjo at gmail.com  Wed May 20 00:08:16 2009
From: kynnjo at gmail.com (Kynn Jones)
Date: Tue, 19 May 2009 18:08:16 -0400
Subject: [Rd] Qs: The list of arguments, wrapping functions...
In-Reply-To: <4A132CA4.3020707@idi.ntnu.no>
References: <c2350ba40905191322y2bffbfdu79f4cb480732252e@mail.gmail.com>
	<4A1327AE.4040000@idi.ntnu.no> <4A132CA4.3020707@idi.ntnu.no>
Message-ID: <c2350ba40905191508q36c1be43wfeca66a4f4f9175a@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090519/5396eb4a/attachment.pl>

From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Wed May 20 00:10:45 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Wed, 20 May 2009 00:10:45 +0200
Subject: [Rd] Qs: The list of arguments, wrapping functions...
In-Reply-To: <4A132CA4.3020707@idi.ntnu.no>
References: <c2350ba40905191322y2bffbfdu79f4cb480732252e@mail.gmail.com>	<4A1327AE.4040000@idi.ntnu.no>
	<4A132CA4.3020707@idi.ntnu.no>
Message-ID: <4A132E65.3000607@idi.ntnu.no>

Wacek Kusnierczyk wrote:
> Wacek Kusnierczyk wrote:
>   
>> Kynn Jones wrote:
>>   
>>
>>     
>>> In general, I'm looking for all the information I can find on the subject of
>>> dynamic function definition (i.e. using code to automate the definition of
>>> functions at runtime).  I'm most interested in introspection facilities and
>>> dynamic code generation.  E.g. is it possible to write a module that
>>> "redefines itself" when sourced?  Or can a function redefine itself when
>>> first run?  Or how can a function find out about how it was called?
>>>   
>>>     
>>>       
>> another quick shot from a naive r user:
>>
>>     f = function()
>>        assign(
>>            as.character(match.call()[[1]]),
>>            function() evil(),
>>            envir=parent.frame())
>>   
>>     
> or maybe
>
>     f = function()
>        body(f) <<- expression(evil())
>
>   

though, 'of course', these two versions are not effectively equivalent; try

    g = f
    f()
    c(g, f)

with both definitions.

vQ


From ggrothendieck at gmail.com  Wed May 20 01:14:00 2009
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 19 May 2009 19:14:00 -0400
Subject: [Rd] Qs: The list of arguments, wrapping functions...
In-Reply-To: <c2350ba40905191322y2bffbfdu79f4cb480732252e@mail.gmail.com>
References: <c2350ba40905191322y2bffbfdu79f4cb480732252e@mail.gmail.com>
Message-ID: <971536df0905191614k8a43022me95bc311f8aed792@mail.gmail.com>

match.call() will return the call.   merge.zoo in the zoo package
uses it if you need an example.  as.list(match.call()) will return
a list.

list(...) will return the ... arguments as a list.

$.proto in the proto package allows one to write p$f where p
is a proto object and f is a function and p$f is the function
f(p, ...), i.e. it provides a currying operation.

The Defaults package allows one to dynamically change the
default arguments of functions.

On Tue, May 19, 2009 at 4:22 PM, Kynn Jones <kynnjo at gmail.com> wrote:
> Hi. ?I'm pretty new to R, but I've been programming in other languages for
> some time. ?I have a couple of questions regarding programming with function
> objects.
> 1. Is there a way for a function to refer generically to all its actual
> arguments as a list? ?I'm thinking of something like the @_ array in Perl or
> the arguments variable in JavaScript. ?(By "actual" I mean the ones that
> were actually passed, as opposed to its formal arguments, as returned by
> formals()).
>
> 2. I have a package in which most of the functions have the form:
>
> the.function <- function(some, list, of, params) {
> ? ?return( some.other.function(the.list.of.params.to.this.function));
> }
>
> Is there a way that I can use a loop to define all these functions?
>
> In general, I'm looking for all the information I can find on the subject of
> dynamic function definition (i.e. using code to automate the definition of
> functions at runtime). ?I'm most interested in introspection facilities and
> dynamic code generation. ?E.g. is it possible to write a module that
> "redefines itself" when sourced? ?Or can a function redefine itself when
> first run? ?Or how can a function find out about how it was called?
>
> FWIW, Some of the things I'd like to do are in the spirit of a decorator in
> Python, which is a function that take a function f an argument and return
> another function g that is somehow based on f. ?For example, this makes it
> very easy to write functions as wrappers to other simpler functions.
>
> TIA!
>
> KJ
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From ripley at stats.ox.ac.uk  Wed May 20 14:54:27 2009
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 20 May 2009 13:54:27 +0100 (BST)
Subject: [Rd] Auto-upgrading a package under Windows ?
In-Reply-To: <18961.48417.945981.635658@ron.nulle.part>
References: <18961.48417.945981.635658@ron.nulle.part>
Message-ID: <alpine.LFD.2.00.0905190808200.24633@gannet.stats.ox.ac.uk>

On Mon, 18 May 2009, Dirk Eddelbuettel wrote:

>
> I was trying to be cute with a company-internal package and used
>
>    if (Sys.info()["sysname"]=="Windows") {
>        update.packages(repos="http://some.where.internal/R", ask=FALSE)
>    }

The commonly used test is .Platform$OS.type == "windows": that value 
is computed at installation so will be marginally faster.

> but that of course fails as the package itself is loaded and cannot be
> upgraded (as it contains a dll) when loaded.  Smart move by the OS.

It's not only Windows that has that problem, but it does at least 
report it.  Some Unixen used (at least) to let you replace a DSO which 
is in use, and then crash the process using the DSO.

That's an issue with automated updating of R packages in a centrally 
managed system, so we do it during 'at risk' periods when activity is 
expected to be low.

> Can anybody suggest a workaround, other than introducing a dll-free wrapper
> package that can in fact test for the local packages before it would load
> them?

Can you not run a check of up-to-date-ness in the .onLoad hook for the 
package?  If you load the DLL in that hook, this can be run before the 
DLL is loaded.  This would need either each package only to update 
itself or the check to be in all packages that might get updated.

You could unload the loaded namespace, provided it has a .onUnload() 
action that calls library.dynam.unload(), re-install then re-load. 
However, we've seen instances where unloading and re-loading a DLL in 
a session did not work (crashes etc) for various reasons -- it does 
not for example re-load and hence re-initialize any dependendent DLLs.

> Placing the test into Rprofile.site is not a valid answer as that file is
> hiding on each user's drive and out of my reach.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From mtmorgan at fhcrc.org  Thu May 21 01:50:15 2009
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Wed, 20 May 2009 16:50:15 -0700
Subject: [Rd] install.packages now intentionally references .Rprofile?
Message-ID: <6ph4ovf1gi0.fsf@gopher4.fhcrc.org>

A post on the Bioconductor mailing list

  https://stat.ethz.ch/pipermail/bioconductor/2009-May/027700.html  

suggests that install.packages now references .Rprofile (?), whereas
in R-2-8 it did not. Is this intentional?

The example is, in .Rprofile

  library(utils)
  install.packages("Biobase",
                   repos="http://bioconductor.org/packages/2.4/bioc")

then starting R from the command line results in repeated downloads
of Biobase

mtmorgan at mm:~/tmp> R --quiet
trying URL
'http://bioconductor.org/packages/2.4/bioc/src/contrib/Biobase_2.4.1.tar.gz'
Content type 'application/x-gzip' length 1973533 bytes (1.9 Mb)
opened URL
==================================================
downloaded 1.9 Mb

trying URL
'http://bioconductor.org/packages/2.4/bioc/src/contrib/Biobase_2.4.1.tar.gz'
Content type 'application/x-gzip' length 1973533 bytes (1.9 Mb)
opened URL
==================================================
downloaded 1.9 Mb

^C
Execution halted

> sessionInfo()
R version 2.9.0 Patched (2009-05-20 r48588)
x86_64-unknown-linux-gnu

locale:
LC_CTYPE=en_US.UTF-8;LC_NUMERIC=C;LC_TIME=en_US.UTF-8;LC_COLLATE=en_US.UTF-8;LC_MONETARY=C;LC_MESSAGES=en_US.UTF-8;LC_PAPER=en_US.UTF-8;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=en_US.UTF-8;LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base
 
Martin
-- 
Martin Morgan
Computational Biology / Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N.
PO Box 19024 Seattle, WA 98109

Location: Arnold Building M1 B861
Phone: (206) 667-2793


From edd at debian.org  Thu May 21 03:07:46 2009
From: edd at debian.org (Dirk Eddelbuettel)
Date: Wed, 20 May 2009 20:07:46 -0500
Subject: [Rd] Auto-upgrading a package under Windows ?
In-Reply-To: <alpine.LFD.2.00.0905190808200.24633@gannet.stats.ox.ac.uk>
References: <18961.48417.945981.635658@ron.nulle.part>
	<alpine.LFD.2.00.0905190808200.24633@gannet.stats.ox.ac.uk>
Message-ID: <18964.43362.572242.261641@ron.nulle.part>


On 20 May 2009 at 13:54, Prof Brian Ripley wrote:
| On Mon, 18 May 2009, Dirk Eddelbuettel wrote:
| 
| >
| > I was trying to be cute with a company-internal package and used
| >
| >    if (Sys.info()["sysname"]=="Windows") {
| >        update.packages(repos="http://some.where.internal/R", ask=FALSE)
| >    }
| 
| The commonly used test is .Platform$OS.type == "windows": that value 
| is computed at installation so will be marginally faster.

Thanks. I once knew about, yet I always forget it. Somehow the Sys.*
connotation wins. 

| > but that of course fails as the package itself is loaded and cannot be
| > upgraded (as it contains a dll) when loaded.  Smart move by the OS.
| 
| It's not only Windows that has that problem, but it does at least 
| report it.  Some Unixen used (at least) to let you replace a DSO which 
| is in use, and then crash the process using the DSO.
| 
| That's an issue with automated updating of R packages in a centrally 
| managed system, so we do it during 'at risk' periods when activity is 
| expected to be low.
| 
| > Can anybody suggest a workaround, other than introducing a dll-free wrapper
| > package that can in fact test for the local packages before it would load
| > them?
| 
| Can you not run a check of up-to-date-ness in the .onLoad hook for the 
| package?  If you load the DLL in that hook, this can be run before the 
| DLL is loaded.  This would need either each package only to update 
| itself or the check to be in all packages that might get updated.

That is exactly what I tried: R/zzz.R using the .onLoad function, before any
actual package code is used.  But (maybe because of the NAMESPACE) this seems
to be after the dll is loaded, and I am in a deadlock.

| You could unload the loaded namespace, provided it has a .onUnload() 
| action that calls library.dynam.unload(), re-install then re-load. 
| However, we've seen instances where unloading and re-loading a DLL in 
| a session did not work (crashes etc) for various reasons -- it does 
| not for example re-load and hence re-initialize any dependendent DLLs.

That never worked for me.

| > Placing the test into Rprofile.site is not a valid answer as that file is
| > hiding on each user's drive and out of my reach.

I will (at least for now) recommend to people to copy the upgrade statement
into their ~/.Rprofile files. 

Thanks, Dirk

-- 
Three out of two people have difficulties with fractions.


From seija.sirkia at metla.fi  Wed May 20 13:32:02 2009
From: seija.sirkia at metla.fi (=?ISO-8859-15?Q?Seija_Sirki=E4?=)
Date: Wed, 20 May 2009 14:32:02 +0300
Subject: [Rd] using a "third party" DLL in my package
In-Reply-To: <alpine.LFD.2.00.0905150905560.4378@gannet.stats.ox.ac.uk>
References: <4A0C079F.7080101@metla.fi>
	<alpine.LFD.2.00.0905150905560.4378@gannet.stats.ox.ac.uk>
Message-ID: <4A13EA32.5010309@metla.fi>

Hello again,

thank you for the comments, especially this one:

Prof Brian Ripley wrote:

 > My concern would be that there are different cases that fail under
 > Fortran compiler X and you are just sweeping the problem under the
 > carpet.

It inspired us to go back to search the cause, and we've made some 
progress: it's not the compiler, it's the compiler options. Simple, but 
it took a while to figure that out since my experience in these things 
is limited. When I build the package with default options using INSTALL 
--build the dll is built with option -O3 as per R's Makeconfig file. If 
I build the dll by hand, using gfortran with no additional options and 
dyn.load it, everything works, and also with -O and -Os. (No, I don't 
fully understand what the differences between all these are, but that's 
another question).

I'm looking at chapter 5.5 in Writing R Extensions and also 6.3.3 in R 
Installation and Administration but I can't figure out how to tell 
"inside" my package that it is not to be built -O3 but with, say, -O. I 
can see how to add flags in the package (and as far as I can tell, if 
there are several optimization level flags the last in line is used and 
that's the wrong one from my point of view), and also how to override 
flags but only on my computer. Am I blind or am I again attempting 
something I shouldn't?

Best regards,
Seija S.


Prof Brian Ripley wrote:
> On Thu, 14 May 2009, Seija Sirki? wrote:
> 
>> Hello all,
>>
>> it seems my efforts in reading the manuals and help files aren't 
>> enough so here I am. The question is, how would I go about linking a 
>> pre-compiled DLL in to my package? I have previously successfully 
>> built packages with Fortran and C source code, but now I'd like to 
>> take this ready made DLL and call its routines from R.
>>
>> My collegue was brave enough to simply try and put the DLL in src 
>> folder of the package and proceed with building and installing the 
>> same way as if it had been source code. And it works, on my computer 
>> and his. Clearly this isn't exactly portable, and while that's ok for 
>> the use we have in mind (we both work on Windows XP) I have a nagging 
>> feeling this is somehow criminal or unwise at least.
> 
> Unwise, since it is unsupported and might stop working at any time. 
> Actually, you don't mention the version of R you used and (without 
> checking) I think this may not work in all recent versions of R.
> 
> What you can so is to have an 'inst/libs' directory in your package 
> sources, and put the DLL you want to use there.  Another approach (used 
> in a few CRAN packages) is to use 'configure.win' to copy the DLL to a 
> 'libs' directory in the installed package.  A third approach is to have 
> a 'src/Makefile.win' that creates the DLL you want (possibly by just 
> checking it is present in 'src', but also possiby by calling the 
> mysterious Fortran compiler X you obliquely mention below).
> 
>> Why I want to do this might explain it a bit further but in fact the 
>> background contains another problem and I welcome anyone to give hints 
>> about that too.
>>
>> So, we have some Fortran code from way back which deals with fitting 
>> taper curves for tree boles, and some other functions related to that. 
>> We wanted to make these available for use in R and I made a package 
>> with simple wrapper functions for the .Fortran calls, and built it 
>> with the help of the compiler in Rtools. All was fine until my 
>> collegue managed to bump in to a combination of parameters (tree 
>> species, height and breast height diameter) with which the computation 
>> freezes. We traced it to a certain very simple iteration in the 
>> Fortran code that finds the height at which the tree has a given 
>> diameter. I could give more details on that, but the point is that the 
>> very same computation goes through just fine when executed "fully" in 
>> Fortran, with the routines and an interface compiled with another 
>> Fortran compiler. And also when that compiler is used to make a DLL 
>> and that DLL is used within the R package in the way I described above.
>>
>> In summary, what we seem to have here is a compiler dependent 
>> convergence problem. Possible solutions are to figure out what's wrong 
>> with the computation - and I've pretty much exhausted my skills on 
>> that - or to figure out how to use a working DLL, as was my first 
>> question.
> 
> My concern would be that there are different cases that fail under 
> Fortran compiler X and you are just sweeping the problem under the carpet.
> 
>>
>> Great big thanks in advance to anyone with advice!
>>
>> Seija Sirki?,
>> senior researcher (statistics), Finnish forestry research institute
>


From r.turner at auckland.ac.nz  Tue May 19 23:23:37 2009
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Wed, 20 May 2009 09:23:37 +1200
Subject: [Rd] stringsAsFactors .... in expand.grid() etc
In-Reply-To: <18962.47321.715556.689459@lynne.math.ethz.ch>
References: <loom.20090518T220645-789@post.gmane.org>
	<421CD833-3D4B-4C8B-8DD9-24A1A6965BF5@auckland.ac.nz>
	<18962.47321.715556.689459@lynne.math.ethz.ch>
Message-ID: <7214F63D-C619-4C9F-ABCE-6DE28259D940@auckland.ac.nz>


On 20/05/2009, at 1:49 AM, Martin Maechler wrote:

>>>>>> "RT" == Rolf Turner <r.turner at auckland.ac.nz>
>>>>>>     on Tue, 19 May 2009 11:02:08 +1200 writes:

	<snip>

>     RT> While we're at it --- would it not make sense to have the
>     RT> stringsAsFactors
>     RT> argument (once it's working) of expand.grid() default to  
> options()
>     RT> $stringsAsFactors,
>     RT> rather than to FALSE?
>
> NNNNNNNNNNNNNNNOOOOOOOOOOOOOOOOOOOOOOO !!!!!

	Oh, alright! :-)

		cheers,

			Rolf

######################################################################
Attention:\ This e-mail message is privileged and confid...{{dropped:9}}


From r.d.morey at rug.nl  Wed May 20 14:00:13 2009
From: r.d.morey at rug.nl (r.d.morey at rug.nl)
Date: Wed, 20 May 2009 14:00:13 +0200 (CEST)
Subject: [Rd] setWinProgressBar() on closed bar crashes R (PR#13709)
Message-ID: <20090520120013.A29DE28320DF@mail.pubhealth.ku.dk>

Full_Name: Richard D. Morey
Version: 2.8.1
OS: Windows XP
Submission from: (NULL) (129.125.139.114)


The following code will crash Rgui in Windows XP. Of course, I know the code
shouldn't work, but something more graceful than a Windows application error
would be better.

#########Start R Code
bar = winProgressBar(min = 0, max = 100, width = 300)
setWinProgressBar(bar, 25)
close(bar)
setWinProgressBar(bar, 50)
######### End R code

It crashes R with the following Windows error:
RGui: Rgui.exe - Application Error
The instruction at "0x6c715843" referenced memory at "0x000000020". The memory
could not be "read".


From wolfgang.resch at gmail.com  Wed May 20 23:10:11 2009
From: wolfgang.resch at gmail.com (wolfgang.resch at gmail.com)
Date: Wed, 20 May 2009 23:10:11 +0200 (CEST)
Subject: [Rd] qbinom (PR#13711)
Message-ID: <20090520211011.0C04E283031D@mail.pubhealth.ku.dk>

Full_Name: Wolfgang Resch
Version: R 2.8.1 GUI 1.27
OS: OS X 10.4.11
Submission from: (NULL) (137.187.89.14)


Strange behavior of qbinom:


> qbinom(0.01, 5016279, 1e-07)
[1] 0
> qbinom(0.01, 5016279, 2e-07)
[1] 16
> qbinom(0.01, 5016279, 3e-07)
[1] 16
> qbinom(0.01, 5016279, 4e-07)
[1] 16
> qbinom(0.01, 5016279, 5e-07)
[1] 0


From ripley at stats.ox.ac.uk  Thu May 21 08:11:10 2009
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 21 May 2009 07:11:10 +0100 (BST)
Subject: [Rd] Auto-upgrading a package under Windows ?
In-Reply-To: <18964.43362.572242.261641@ron.nulle.part>
References: <18961.48417.945981.635658@ron.nulle.part>
	<alpine.LFD.2.00.0905190808200.24633@gannet.stats.ox.ac.uk>
	<18964.43362.572242.261641@ron.nulle.part>
Message-ID: <alpine.LFD.2.00.0905210709460.30721@gannet.stats.ox.ac.uk>

On Wed, 20 May 2009, Dirk Eddelbuettel wrote:

>
> On 20 May 2009 at 13:54, Prof Brian Ripley wrote:
> | On Mon, 18 May 2009, Dirk Eddelbuettel wrote:
> |
> | >
> | > I was trying to be cute with a company-internal package and used
> | >
> | >    if (Sys.info()["sysname"]=="Windows") {
> | >        update.packages(repos="http://some.where.internal/R", ask=FALSE)
> | >    }
> |
> | The commonly used test is .Platform$OS.type == "windows": that value
> | is computed at installation so will be marginally faster.
>
> Thanks. I once knew about, yet I always forget it. Somehow the Sys.*
> connotation wins.
>
> | > but that of course fails as the package itself is loaded and cannot be
> | > upgraded (as it contains a dll) when loaded.  Smart move by the OS.
> |
> | It's not only Windows that has that problem, but it does at least
> | report it.  Some Unixen used (at least) to let you replace a DSO which
> | is in use, and then crash the process using the DSO.
> |
> | That's an issue with automated updating of R packages in a centrally
> | managed system, so we do it during 'at risk' periods when activity is
> | expected to be low.
> |
> | > Can anybody suggest a workaround, other than introducing a dll-free wrapper
> | > package that can in fact test for the local packages before it would load
> | > them?
> |
> | Can you not run a check of up-to-date-ness in the .onLoad hook for the
> | package?  If you load the DLL in that hook, this can be run before the
> | DLL is loaded.  This would need either each package only to update
> | itself or the check to be in all packages that might get updated.
>
> That is exactly what I tried: R/zzz.R using the .onLoad function, before any
> actual package code is used.  But (maybe because of the NAMESPACE) this seems
> to be after the dll is loaded, and I am in a deadlock.

You would need not to use UseDynLib in the NAMESPACE, but load the DLL 
in the .onLoad via library.dynam.

> | You could unload the loaded namespace, provided it has a .onUnload()
> | action that calls library.dynam.unload(), re-install then re-load.
> | However, we've seen instances where unloading and re-loading a DLL in
> | a session did not work (crashes etc) for various reasons -- it does
> | not for example re-load and hence re-initialize any dependendent DLLs.
>
> That never worked for me.
>
> | > Placing the test into Rprofile.site is not a valid answer as that file is
> | > hiding on each user's drive and out of my reach.
>
> I will (at least for now) recommend to people to copy the upgrade statement
> into their ~/.Rprofile files.
>
> Thanks, Dirk
>
> -- 
> Three out of two people have difficulties with fractions.
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Thu May 21 08:17:29 2009
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 21 May 2009 07:17:29 +0100 (BST)
Subject: [Rd] install.packages now intentionally references .Rprofile?
In-Reply-To: <6ph4ovf1gi0.fsf@gopher4.fhcrc.org>
References: <6ph4ovf1gi0.fsf@gopher4.fhcrc.org>
Message-ID: <alpine.LFD.2.00.0905210715100.30855@gannet.stats.ox.ac.uk>

On Wed, 20 May 2009, Martin Morgan wrote:

> A post on the Bioconductor mailing list
>
>  https://stat.ethz.ch/pipermail/bioconductor/2009-May/027700.html
>
> suggests that install.packages now references .Rprofile (?), whereas
> in R-2-8 it did not. Is this intentional?

Yes.  And in fact it did in earlier versions, to find the default 
library into which to install.

>
> The example is, in .Rprofile
>
>  library(utils)
>  install.packages("Biobase",
>                   repos="http://bioconductor.org/packages/2.4/bioc")
>
> then starting R from the command line results in repeated downloads
> of Biobase
>
> mtmorgan at mm:~/tmp> R --quiet
> trying URL
> 'http://bioconductor.org/packages/2.4/bioc/src/contrib/Biobase_2.4.1.tar.gz'
> Content type 'application/x-gzip' length 1973533 bytes (1.9 Mb)
> opened URL
> ==================================================
> downloaded 1.9 Mb
>
> trying URL
> 'http://bioconductor.org/packages/2.4/bioc/src/contrib/Biobase_2.4.1.tar.gz'
> Content type 'application/x-gzip' length 1973533 bytes (1.9 Mb)
> opened URL
> ==================================================
> downloaded 1.9 Mb
>
> ^C
> Execution halted
>
>> sessionInfo()
> R version 2.9.0 Patched (2009-05-20 r48588)
> x86_64-unknown-linux-gnu
>
> locale:
> LC_CTYPE=en_US.UTF-8;LC_NUMERIC=C;LC_TIME=en_US.UTF-8;LC_COLLATE=en_US.UTF-8;LC_MONETARY=C;LC_MESSAGES=en_US.UTF-8;LC_PAPER=en_US.UTF-8;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=en_US.UTF-8;LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> Martin
> -- 
> Martin Morgan
> Computational Biology / Fred Hutchinson Cancer Research Center
> 1100 Fairview Ave. N.
> PO Box 19024 Seattle, WA 98109
>
> Location: Arnold Building M1 B861
> Phone: (206) 667-2793
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From p.dalgaard at biostat.ku.dk  Thu May 21 10:29:33 2009
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Thu, 21 May 2009 10:29:33 +0200
Subject: [Rd] qbinom (PR#13711)
In-Reply-To: <20090520211011.0C04E283031D@mail.pubhealth.ku.dk>
References: <20090520211011.0C04E283031D@mail.pubhealth.ku.dk>
Message-ID: <4A1510ED.60405@biostat.ku.dk>

wolfgang.resch at gmail.com wrote:
> Full_Name: Wolfgang Resch
> Version: R 2.8.1 GUI 1.27
> OS: OS X 10.4.11
> Submission from: (NULL) (137.187.89.14)
> 
> 
> Strange behavior of qbinom:
> 
> 
>> qbinom(0.01, 5016279, 1e-07)
> [1] 0
>> qbinom(0.01, 5016279, 2e-07)
> [1] 16
>> qbinom(0.01, 5016279, 3e-07)
> [1] 16
>> qbinom(0.01, 5016279, 4e-07)
> [1] 16
>> qbinom(0.01, 5016279, 5e-07)
> [1] 0

Confirmed with 2.9.0 patched (r48590) on Fedora 32bit.

-- 
    O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
   c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
  (*) \(*) -- University of Copenhagen   Denmark      Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)              FAX: (+45) 35327907


From b.rowlingson at lancaster.ac.uk  Thu May 21 13:44:41 2009
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Thu, 21 May 2009 12:44:41 +0100
Subject: [Rd] Colour Schemes
Message-ID: <d8ad40b50905210444q406e1a2ak8313d495975d1919@mail.gmail.com>

I've been thinking hard about generating colour schemes for data.
There's quite a bit of existing code scattered in various packages for
playing with colours and colour palettes, but I can't find the sort of
thing I'm after for applying colours to data...

To my mind a colour scheme is a mapping from data values to colours.
There's a multitude of such mappings depending on the nature of the
data. For example, for a factor you might want to map levels to unique
colours. For numbers that run from -4 to +2 you might want to use a
diverging colour palette centred on zero. This might be continuous in
some colour space or composed of a small number of discrete colours,
each of which covers a range of values. Or it could be piecewise
continuous as used in topographic maps - less than zero is blue, zero
to 400 goes from sandy yellow to grassy green, 400 to 1000 goes from
grassy green to rocky brown, then suddenly you hit the ice and 1000
and upwards is white.  Or you could have a multivariate mapping where
(x,y,z) -> (r,g,b,a) in complex and non-linear ways.

I see a set of factory functions that return colour scheme mapping
functions that map data to colours, so you'd do:

 # unique colour for each factor level
 scheme1 = exactColours(data$f,someColours)  # data$f is a factor,
someColours is a vector of colour values
 plot(data$x,data$y,col=scheme1(data$f))

 # topological map colouring
 scheme2 = continuousColours(list(-1000,"blue",0,"sandYellow",400,"grassGreen",1000,"rockBrown",1000,"white",10000))
# or something...
 plot(data$x,data$y,col=scheme2(data$height))

Now just because I can't find existing functions like this doesn't
mean they don't exist. There's stuff in plotrix, colorspace,
RColorBrewer etc for creating palettes but then the user is left to
their own devices to map colours to data values.

 Does this kind of thing sound useful? Has it been done? Is it worth
doing? Anybody got any better ideas?

Barry


From Richard.Cotton at hsl.gov.uk  Thu May 21 15:18:04 2009
From: Richard.Cotton at hsl.gov.uk (Richard.Cotton at hsl.gov.uk)
Date: Thu, 21 May 2009 14:18:04 +0100
Subject: [Rd] Colour Schemes
In-Reply-To: <d8ad40b50905210444q406e1a2ak8313d495975d1919@mail.gmail.com>
Message-ID: <OFDAD6BC3C.A2BA778D-ON802575BD.004783B8-802575BD.00491507@hsl.gov.uk>

> I've been thinking hard about generating colour schemes for data.
> There's quite a bit of existing code scattered in various packages for
> playing with colours and colour palettes, but I can't find the sort of
> thing I'm after for applying colours to data...
> 
> To my mind a colour scheme is a mapping from data values to colours.
> There's a multitude of such mappings depending on the nature of the
> data. For example, for a factor you might want to map levels to unique
> colours. For numbers that run from -4 to +2 you might want to use a
> diverging colour palette centred on zero. This might be continuous in
> some colour space or composed of a small number of discrete colours,
> each of which covers a range of values. Or it could be piecewise
> continuous as used in topographic maps - less than zero is blue, zero
> to 400 goes from sandy yellow to grassy green, 400 to 1000 goes from
> grassy green to rocky brown, then suddenly you hit the ice and 1000
> and upwards is white.  Or you could have a multivariate mapping where
> (x,y,z) -> (r,g,b,a) in complex and non-linear ways.
> 
> I see a set of factory functions that return colour scheme mapping
> functions that map data to colours, so you'd do:
> 
>  # unique colour for each factor level
>  scheme1 = exactColours(data$f,someColours)  # data$f is a factor,
> someColours is a vector of colour values
>  plot(data$x,data$y,col=scheme1(data$f))
> 
>  # topological map colouring
>  scheme2 = continuousColours(list(-1000,"blue",0,"sandYellow",
> 400,"grassGreen",1000,"rockBrown",1000,"white",10000))
> # or something...
>  plot(data$x,data$y,col=scheme2(data$height))
> 
> Now just because I can't find existing functions like this doesn't
> mean they don't exist. There's stuff in plotrix, colorspace,
> RColorBrewer etc for creating palettes but then the user is left to
> their own devices to map colours to data values.
> 
>  Does this kind of thing sound useful? Has it been done? Is it worth
> doing? Anybody got any better ideas?

Most of the plots where colour is typically used to signify a variable 
already do map colours to data values.  Take a look at help pages for 
levelplot/contourplot/wireframe from the lattice package, and image from 
base graphics.

(The format is typically slightly different to your suggested 
specification, though the principle is the same.  The functions take a 
vector of cut points, and a vector of colours.)

There may be some utility in creating functions to generate these colour 
maps outside of the plotting functions, if only so that the code can be 
recycled for new functions.

Regards,
Richie.

Mathematical Sciences Unit
HSL



------------------------------------------------------------------------
ATTENTION:

This message contains privileged and confidential inform...{{dropped:20}}


From edd at debian.org  Thu May 21 15:46:40 2009
From: edd at debian.org (Dirk Eddelbuettel)
Date: Thu, 21 May 2009 08:46:40 -0500
Subject: [Rd] Auto-upgrading a package under Windows ?
In-Reply-To: <alpine.LFD.2.00.0905210709460.30721@gannet.stats.ox.ac.uk>
References: <18961.48417.945981.635658@ron.nulle.part>
	<alpine.LFD.2.00.0905190808200.24633@gannet.stats.ox.ac.uk>
	<18964.43362.572242.261641@ron.nulle.part>
	<alpine.LFD.2.00.0905210709460.30721@gannet.stats.ox.ac.uk>
Message-ID: <18965.23360.670177.706079@ron.nulle.part>


On 21 May 2009 at 07:11, Prof Brian Ripley wrote:
| You would need not to use UseDynLib in the NAMESPACE, but load the DLL 
| in the .onLoad via library.dynam.

Martin Morgan had suggested the same in private mail, and that is indeed the
solution: do not load the dynamic library via NAMESPACE, compare and possibly
upgrage from .onLoad in R/zzz.R and only load the dynamic library the
old-school way via library.dynam.  That works in some initial testing, and
I'll give it some 'field testing'.

Thanks for the help and follow-up.

Dirk

-- 
Three out of two people have difficulties with fractions.


From b.rowlingson at lancaster.ac.uk  Thu May 21 16:12:54 2009
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Thu, 21 May 2009 15:12:54 +0100
Subject: [Rd] Colour Schemes
In-Reply-To: <OFDAD6BC3C.A2BA778D-ON802575BD.004783B8-802575BD.00491507@hsl.gov.uk>
References: <d8ad40b50905210444q406e1a2ak8313d495975d1919@mail.gmail.com>
	<OFDAD6BC3C.A2BA778D-ON802575BD.004783B8-802575BD.00491507@hsl.gov.uk>
Message-ID: <d8ad40b50905210712k128ecfa2vff2dd178f946680d@mail.gmail.com>

On Thu, May 21, 2009 at 2:18 PM,  <Richard.Cotton at hsl.gov.uk> wrote:

> Most of the plots where colour is typically used to signify a variable
> already do map colours to data values. ?Take a look at help pages for
> levelplot/contourplot/wireframe from the lattice package, and image from
> base graphics.
>
> (The format is typically slightly different to your suggested
> specification, though the principle is the same. ?The functions take a
> vector of cut points, and a vector of colours.)

 The problem here is that the user doesn't have exact control of the
mapping from value to colour. For example (using a slightly more
safe-for-use-after-lunch version of the levelplot example grid):

     x <- seq(pi/4, 5 * pi, length.out = 100)
     y <- seq(pi/4, 5 * pi, length.out = 100)
     r <- as.vector(sqrt(outer(x^2, y^2, "+")))
     grid <- expand.grid(x=x, y=y)
     grid$z <- r
     grid$z2 = r *0.5


Then I do:

  levelplot(z~x*y, grid, cuts = 5, col.regions=rainbow(5))

 very nice, but suppose I want to show $r2 on the same colour scale, I
can't just do:

 levelplot(z2~x*y, grid, cuts = 5, col.regions=rainbow(5))

 because that looks the same as the first one since levelplot uses the
whole colour range.


 The base graphics "image" function has zlim arguments which let you do:

 z=outer(1:10,1:10,"*")
 image(z)
 image(z/2, zlim=range(z))

 but again, not obvious, and complex/impossible when using more
sophisticated colour mappings.

> There may be some utility in creating functions to generate these colour
> maps outside of the plotting functions, if only so that the code can be
> recycled for new functions.

 Exactly, it would make a new package.

Barry


From Richard.Cotton at hsl.gov.uk  Thu May 21 18:28:22 2009
From: Richard.Cotton at hsl.gov.uk (Richard.Cotton at hsl.gov.uk)
Date: Thu, 21 May 2009 17:28:22 +0100
Subject: [Rd] Colour Schemes
In-Reply-To: <d8ad40b50905210712k128ecfa2vff2dd178f946680d@mail.gmail.com>
Message-ID: <OF8F030E35.855338DD-ON802575BD.00574782-802575BD.005A7CF2@hsl.gov.uk>

I'm going to take your second example first.

>  The base graphics "image" function has zlim arguments which let you do:
> 
>  z=outer(1:10,1:10,"*")
>  image(z)
>  image(z/2, zlim=range(z))
> 
>  but again, not obvious, and complex/impossible when using more
> sophisticated colour mappings.

The way to do more complex examples, similar to the manner you suggested 
originally, is use the breaks and col arguments, e.g.

breaks <- c(0,25,75,100)
col <- c("red", "blue", "green")
image(z, breaks=breaks, col=col)
image(z/2, breaks=breaks, col=col)

So it is possible here, though perhaps not obvious.

With your first example ...
>  The problem here is that the user doesn't have exact control of the
> mapping from value to colour. For example (using a slightly more
> safe-for-use-after-lunch version of the levelplot example grid):
> 
>      x <- seq(pi/4, 5 * pi, length.out = 100)
>      y <- seq(pi/4, 5 * pi, length.out = 100)
>      r <- as.vector(sqrt(outer(x^2, y^2, "+")))
>      grid <- expand.grid(x=x, y=y)
>      grid$z <- r
>      grid$z2 = r *0.5
> 
> 
> Then I do:
> 
>   levelplot(z~x*y, grid, cuts = 5, col.regions=rainbow(5))
> 
>  very nice, but suppose I want to show $r2 on the same colour scale, I
> can't just do:
> 
>  levelplot(z2~x*y, grid, cuts = 5, col.regions=rainbow(5))
> 
>  because that looks the same as the first one since levelplot uses the
> whole colour range.

... I agree that the inability to specify a vector of cut points ruins 
your chances of doing what you want.

> > There may be some utility in creating functions to generate these 
colour
> > maps outside of the plotting functions, if only so that the code can 
be
> > recycled for new functions.
> 
>  Exactly, it would make a new package.

Excellent.  I reckon keeping the cut vector/colour vector input format 
would be sensible, e.g.

continuousColours <- function(x, breaks, col)
{
   if(length(breaks) != length(col)+1) stop("must have one more break than 
colour") 
   col[as.numeric(cut(x, breaks))]
}

x <- runif(10, 0, 5)
breaks <- 0:5
col <- c("red", "blue", "green", "cyan", "magenta")
plot(1:10, x, col=continuousColours(x, breaks, col))

Regards,
Richie.

Mathematical Sciences Unit
HSL


------------------------------------------------------------------------
ATTENTION:

This message contains privileged and confidential inform...{{dropped:20}}


From deepayan.sarkar at gmail.com  Thu May 21 18:29:58 2009
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Thu, 21 May 2009 09:29:58 -0700
Subject: [Rd] Colour Schemes
In-Reply-To: <d8ad40b50905210712k128ecfa2vff2dd178f946680d@mail.gmail.com>
References: <d8ad40b50905210444q406e1a2ak8313d495975d1919@mail.gmail.com>
	<OFDAD6BC3C.A2BA778D-ON802575BD.004783B8-802575BD.00491507@hsl.gov.uk>
	<d8ad40b50905210712k128ecfa2vff2dd178f946680d@mail.gmail.com>
Message-ID: <eb555e660905210929l13c59870v13c4e17cafa7f90f@mail.gmail.com>

On 5/21/09, Barry Rowlingson <b.rowlingson at lancaster.ac.uk> wrote:
> On Thu, May 21, 2009 at 2:18 PM,  <Richard.Cotton at hsl.gov.uk> wrote:
>
>  > Most of the plots where colour is typically used to signify a variable
>  > already do map colours to data values.  Take a look at help pages for
>  > levelplot/contourplot/wireframe from the lattice package, and image from
>  > base graphics.
>  >
>  > (The format is typically slightly different to your suggested
>  > specification, though the principle is the same.  The functions take a
>  > vector of cut points, and a vector of colours.)
>
>
>  The problem here is that the user doesn't have exact control of the
>  mapping from value to colour. For example (using a slightly more
>  safe-for-use-after-lunch version of the levelplot example grid):
>
>      x <- seq(pi/4, 5 * pi, length.out = 100)
>      y <- seq(pi/4, 5 * pi, length.out = 100)
>      r <- as.vector(sqrt(outer(x^2, y^2, "+")))
>      grid <- expand.grid(x=x, y=y)
>      grid$z <- r
>      grid$z2 = r *0.5
>
>
>  Then I do:
>
>   levelplot(z~x*y, grid, cuts = 5, col.regions=rainbow(5))
>
>   very nice, but suppose I want to show $r2 on the same colour scale, I
>  can't just do:
>
>   levelplot(z2~x*y, grid, cuts = 5, col.regions=rainbow(5))
>
>   because that looks the same as the first one since levelplot uses the
>  whole colour range.

But you could specify an explicit 'at' vector specifying the color
breakpoints: effectively, you want at = do.breaks(zlim, 5).

lattice does have a function called 'level.colors' that factors out
the color assignment computation.

-Deepayan

>
>
>   The base graphics "image" function has zlim arguments which let you do:
>
>   z=outer(1:10,1:10,"*")
>   image(z)
>   image(z/2, zlim=range(z))
>
>   but again, not obvious, and complex/impossible when using more
>  sophisticated colour mappings.
>
>
>  > There may be some utility in creating functions to generate these colour
>  > maps outside of the plotting functions, if only so that the code can be
>  > recycled for new functions.
>
>
>  Exactly, it would make a new package.
>
>
>  Barry
>
>
>  ______________________________________________
>  R-devel at r-project.org mailing list
>  https://stat.ethz.ch/mailman/listinfo/r-devel
>


From b.rowlingson at lancaster.ac.uk  Thu May 21 19:53:46 2009
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Thu, 21 May 2009 18:53:46 +0100
Subject: [Rd] Colour Schemes
In-Reply-To: <eb555e660905210929l13c59870v13c4e17cafa7f90f@mail.gmail.com>
References: <d8ad40b50905210444q406e1a2ak8313d495975d1919@mail.gmail.com>
	<OFDAD6BC3C.A2BA778D-ON802575BD.004783B8-802575BD.00491507@hsl.gov.uk>
	<d8ad40b50905210712k128ecfa2vff2dd178f946680d@mail.gmail.com>
	<eb555e660905210929l13c59870v13c4e17cafa7f90f@mail.gmail.com>
Message-ID: <d8ad40b50905211053p3ced543fy7bcc03d7ba19946a@mail.gmail.com>

On Thu, May 21, 2009 at 5:29 PM, Deepayan Sarkar
<deepayan.sarkar at gmail.com> wrote:

[oops I didnt reply-to-all]

> But you could specify an explicit 'at' vector specifying the color
> breakpoints: effectively, you want at = do.breaks(zlim, 5).
>
> lattice does have a function called 'level.colors' that factors out
> the color assignment computation.
>
 Yes, but these things are all at the wrong conceptual level. What you
are constructing here is a function that maps value to colour, but
keeping it as breaks and cut values and colours instead of
representing it as a function. Wouldn't it be nicer to build a real
function object and have that to pass around?

 ggplot uses a different approach, for example in
?scale_fill_gradient, but ggplot uses "+" to add the layer objects
together to create a plot. Nice. ggplot does things pretty well.
Perhaps if we scrap all the other graphics systems.... :)

Barry


From wdunlap at tibco.com  Thu May 21 20:17:22 2009
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 21 May 2009 11:17:22 -0700
Subject: [Rd] file descriptor leak in getSrcLines in R 2.10.0 svn 48590
Message-ID: <77EB52C6DD32BA4D87471DCD70C8D70001336538@NA-PA-VBE03.na.tibco.com>

I noticed the following file descriptor leak when I couldn't remove
a package unless I shut down the R session that had loaded and
used it.  The function that triggered the problem printed the output
of a call to parse().  Each time one prints a srcref a connection is
opened and not closed.  It looks like it happens in
as.character.srcref's
call to getSrcLines, which has some logic I don't understand about
closing 'srcfile' on exit only if !.is.Open(srcfile):

> getSrcLines
function (srcfile, first, last)
{
    if (first > last)
        return(character(0L))
    if (!.isOpen(srcfile))
        on.exit(close(srcfile))
    conn <- open(srcfile, first)
    lines <- readLines(conn, n = last - first + 1L, warn = FALSE)
    srcfile$line <- first + length(lines)
    return(lines)
}

(It looks like the srcref stuff is not finished yet, as there are other
problems, like print(parse(file)) not showing what it used to.)

This is on Linux, compiled by me with an ancient version of gcc.

% R
R version 2.10.0 Under development (unstable) (2009-05-21 r48590)
...
> showConnections()
     description class mode text isopen can read can write
> tf<-tempfile()
> cat(file=tf, "1:7\nlog(pi)\n")
> showConnections()
     description class mode text isopen can read can write
> p<-parse(tf)
> showConnections()
     description class mode text isopen can read can write
> p
expression(<srcref: file "/tmp/RtmpZ1llo5/file327b23c6" chars 1:1 to
1:3>,
    <srcref: file "/tmp/RtmpZ1llo5/file327b23c6" chars 2:1 to 2:7>)
attr(,"srcfile")
/tmp/RtmpZ1llo5/file327b23c6
> showConnections()
  description                    class  mode text   isopen   can read
can write
3 "/tmp/RtmpZ1llo5/file327b23c6" "file" "rt" "text" "opened" "yes"
"no"
4 "/tmp/RtmpZ1llo5/file327b23c6" "file" "rt" "text" "opened" "yes"
"no"
5 "/tmp/RtmpZ1llo5/file327b23c6" "file" "rt" "text" "opened" "yes"
"no"
6 "/tmp/RtmpZ1llo5/file327b23c6" "file" "rt" "text" "opened" "yes"
"no"
> tf
[1] "/tmp/RtmpZ1llo5/file327b23c6"
> z<-attr(p,"srcref")[[2]]
> showConnections()
  description                    class  mode text   isopen   can read
can write
3 "/tmp/RtmpZ1llo5/file327b23c6" "file" "rt" "text" "opened" "yes"
"no"
4 "/tmp/RtmpZ1llo5/file327b23c6" "file" "rt" "text" "opened" "yes"
"no"
5 "/tmp/RtmpZ1llo5/file327b23c6" "file" "rt" "text" "opened" "yes"
"no"
6 "/tmp/RtmpZ1llo5/file327b23c6" "file" "rt" "text" "opened" "yes"
"no"
> zz<-as.character(z)
> showConnections()
  description                    class  mode text   isopen   can read
can write
3 "/tmp/RtmpZ1llo5/file327b23c6" "file" "rt" "text" "opened" "yes"
"no"
4 "/tmp/RtmpZ1llo5/file327b23c6" "file" "rt" "text" "opened" "yes"
"no"
5 "/tmp/RtmpZ1llo5/file327b23c6" "file" "rt" "text" "opened" "yes"
"no"
6 "/tmp/RtmpZ1llo5/file327b23c6" "file" "rt" "text" "opened" "yes"
"no"
7 "/tmp/RtmpZ1llo5/file327b23c6" "file" "rt" "text" "opened" "yes"
"no"
> zz
[1] "<srcref: file \"/tmp/RtmpZ1llo5/file327b23c6\" chars 2:1 to 2:7>"

Bill Dunlap
TIBCO Software Inc - Spotfire Division
wdunlap tibco.com 


From murdoch at stats.uwo.ca  Thu May 21 20:47:10 2009
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 21 May 2009 14:47:10 -0400
Subject: [Rd] file descriptor leak in getSrcLines in R 2.10.0 svn 48590
In-Reply-To: <77EB52C6DD32BA4D87471DCD70C8D70001336538@NA-PA-VBE03.na.tibco.com>
References: <77EB52C6DD32BA4D87471DCD70C8D70001336538@NA-PA-VBE03.na.tibco.com>
Message-ID: <4A15A1AE.4000507@stats.uwo.ca>

On 5/21/2009 2:17 PM, William Dunlap wrote:
> I noticed the following file descriptor leak when I couldn't remove
> a package unless I shut down the R session that had loaded and
> used it.  The function that triggered the problem printed the output
> of a call to parse().  Each time one prints a srcref a connection is
> opened and not closed.  It looks like it happens in
> as.character.srcref's
> call to getSrcLines, which has some logic I don't understand about
> closing 'srcfile' on exit only if !.is.Open(srcfile):

Thanks, will look into it.

Duncan Murdoch

> 
>> getSrcLines
> function (srcfile, first, last)
> {
>     if (first > last)
>         return(character(0L))
>     if (!.isOpen(srcfile))
>         on.exit(close(srcfile))
>     conn <- open(srcfile, first)
>     lines <- readLines(conn, n = last - first + 1L, warn = FALSE)
>     srcfile$line <- first + length(lines)
>     return(lines)
> }
> 
> (It looks like the srcref stuff is not finished yet, as there are other
> problems, like print(parse(file)) not showing what it used to.)
> 
> This is on Linux, compiled by me with an ancient version of gcc.
> 
> % R
> R version 2.10.0 Under development (unstable) (2009-05-21 r48590)
> ...
>> showConnections()
>      description class mode text isopen can read can write
>> tf<-tempfile()
>> cat(file=tf, "1:7\nlog(pi)\n")
>> showConnections()
>      description class mode text isopen can read can write
>> p<-parse(tf)
>> showConnections()
>      description class mode text isopen can read can write
>> p
> expression(<srcref: file "/tmp/RtmpZ1llo5/file327b23c6" chars 1:1 to
> 1:3>,
>     <srcref: file "/tmp/RtmpZ1llo5/file327b23c6" chars 2:1 to 2:7>)
> attr(,"srcfile")
> /tmp/RtmpZ1llo5/file327b23c6
>> showConnections()
>   description                    class  mode text   isopen   can read
> can write
> 3 "/tmp/RtmpZ1llo5/file327b23c6" "file" "rt" "text" "opened" "yes"
> "no"
> 4 "/tmp/RtmpZ1llo5/file327b23c6" "file" "rt" "text" "opened" "yes"
> "no"
> 5 "/tmp/RtmpZ1llo5/file327b23c6" "file" "rt" "text" "opened" "yes"
> "no"
> 6 "/tmp/RtmpZ1llo5/file327b23c6" "file" "rt" "text" "opened" "yes"
> "no"
>> tf
> [1] "/tmp/RtmpZ1llo5/file327b23c6"
>> z<-attr(p,"srcref")[[2]]
>> showConnections()
>   description                    class  mode text   isopen   can read
> can write
> 3 "/tmp/RtmpZ1llo5/file327b23c6" "file" "rt" "text" "opened" "yes"
> "no"
> 4 "/tmp/RtmpZ1llo5/file327b23c6" "file" "rt" "text" "opened" "yes"
> "no"
> 5 "/tmp/RtmpZ1llo5/file327b23c6" "file" "rt" "text" "opened" "yes"
> "no"
> 6 "/tmp/RtmpZ1llo5/file327b23c6" "file" "rt" "text" "opened" "yes"
> "no"
>> zz<-as.character(z)
>> showConnections()
>   description                    class  mode text   isopen   can read
> can write
> 3 "/tmp/RtmpZ1llo5/file327b23c6" "file" "rt" "text" "opened" "yes"
> "no"
> 4 "/tmp/RtmpZ1llo5/file327b23c6" "file" "rt" "text" "opened" "yes"
> "no"
> 5 "/tmp/RtmpZ1llo5/file327b23c6" "file" "rt" "text" "opened" "yes"
> "no"
> 6 "/tmp/RtmpZ1llo5/file327b23c6" "file" "rt" "text" "opened" "yes"
> "no"
> 7 "/tmp/RtmpZ1llo5/file327b23c6" "file" "rt" "text" "opened" "yes"
> "no"
>> zz
> [1] "<srcref: file \"/tmp/RtmpZ1llo5/file327b23c6\" chars 2:1 to 2:7>"
> 
> Bill Dunlap
> TIBCO Software Inc - Spotfire Division
> wdunlap tibco.com 
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From h.wickham at gmail.com  Thu May 21 21:11:06 2009
From: h.wickham at gmail.com (hadley wickham)
Date: Fri, 22 May 2009 07:11:06 +1200
Subject: [Rd] Colour Schemes
In-Reply-To: <d8ad40b50905211053p3ced543fy7bcc03d7ba19946a@mail.gmail.com>
References: <d8ad40b50905210444q406e1a2ak8313d495975d1919@mail.gmail.com>
	<OFDAD6BC3C.A2BA778D-ON802575BD.004783B8-802575BD.00491507@hsl.gov.uk>
	<d8ad40b50905210712k128ecfa2vff2dd178f946680d@mail.gmail.com>
	<eb555e660905210929l13c59870v13c4e17cafa7f90f@mail.gmail.com>
	<d8ad40b50905211053p3ced543fy7bcc03d7ba19946a@mail.gmail.com>
Message-ID: <f8e6ff050905211211r1ad7ce3ak356f753785030bca@mail.gmail.com>

> ?Yes, but these things are all at the wrong conceptual level. What you
> are constructing here is a function that maps value to colour, but
> keeping it as breaks and cut values and colours instead of
> representing it as a function. Wouldn't it be nicer to build a real
> function object and have that to pass around?

This is basically what ggplot2 does behind the scenes, with the slight
addition that scales also know how to be "trained", so that the domain
can be learned from the data:

sc <- scale_colour_gradient()
sc$train(1:10)
sc$map(1:10)

Hadley

-- 
http://had.co.nz/


From deepayan.sarkar at gmail.com  Thu May 21 21:45:30 2009
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Thu, 21 May 2009 12:45:30 -0700
Subject: [Rd] Colour Schemes
In-Reply-To: <d8ad40b50905211053p3ced543fy7bcc03d7ba19946a@mail.gmail.com>
References: <d8ad40b50905210444q406e1a2ak8313d495975d1919@mail.gmail.com>
	<OFDAD6BC3C.A2BA778D-ON802575BD.004783B8-802575BD.00491507@hsl.gov.uk>
	<d8ad40b50905210712k128ecfa2vff2dd178f946680d@mail.gmail.com>
	<eb555e660905210929l13c59870v13c4e17cafa7f90f@mail.gmail.com>
	<d8ad40b50905211053p3ced543fy7bcc03d7ba19946a@mail.gmail.com>
Message-ID: <eb555e660905211245o5147580bu3553ab1626c0d087@mail.gmail.com>

On Thu, May 21, 2009 at 10:53 AM, Barry Rowlingson
<b.rowlingson at lancaster.ac.uk> wrote:
> On Thu, May 21, 2009 at 5:29 PM, Deepayan Sarkar
> <deepayan.sarkar at gmail.com> wrote:
>
> [oops I didnt reply-to-all]
>
>> But you could specify an explicit 'at' vector specifying the color
>> breakpoints: effectively, you want at = do.breaks(zlim, 5).
>>
>> lattice does have a function called 'level.colors' that factors out
>> the color assignment computation.
>>
> ?Yes, but these things are all at the wrong conceptual level. What you
> are constructing here is a function that maps value to colour, but
> keeping it as breaks and cut values and colours instead of
> representing it as a function. Wouldn't it be nicer to build a real
> function object and have that to pass around?

If that tickles your fancy, it's not a big stretch to get to

----
library(lattice)

continuousColours <- function(at, col.regions, ...)
{
    function(x) {
        level.colors(x, at = at, col.regions = col.regions, ...)
    }
}

## caveat: level.colors requires 'at' values to be unique, hence the 999,1001
scheme2 <-
    continuousColours(at = list(-1000, 0, 400, 999, 1001, 10000),
                      col.regions = c("blue", "sandYellow",
"grassGreen", "rockBrown", "white"))

## you could do something similar with your list format too, of course.

---

which gives

> scheme2(c(-500, -200, 200, 2000))
[1] "blue"       "blue"       "sandYellow" "white"

But generally speaking, I wouldn't presume to dictate that any given
approach is universally "nicer" than another; I don't expect others to
have the same tastes as me, and conversely, don't expect to be told
what my tastes should be (if I did, I would probably be using Excel).

-Deepayan


From mwkimpel at gmail.com  Thu May 21 23:28:49 2009
From: mwkimpel at gmail.com (Mark Kimpel)
Date: Thu, 21 May 2009 17:28:49 -0400
Subject: [Rd] install.packages now intentionally references .Rprofile?
In-Reply-To: <alpine.LFD.2.00.0905210715100.30855@gannet.stats.ox.ac.uk>
References: <6ph4ovf1gi0.fsf@gopher4.fhcrc.org>
	<alpine.LFD.2.00.0905210715100.30855@gannet.stats.ox.ac.uk>
Message-ID: <6b93d1830905211428h6f5d0e66hdebfb9a3c70984f8@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090521/a47f834c/attachment.pl>

From fernandomayer at gmail.com  Fri May 22 05:27:14 2009
From: fernandomayer at gmail.com (Fernando Mayer)
Date: Fri, 22 May 2009 00:27:14 -0300
Subject: [Rd] Trivial typo in sample help file
Message-ID: <1242962834.4270.16.camel@deep-house>

Hi,

just found a small typo in help(sample). In 'Arguments' section, where
says

	n: a non-negaiive integer, the number of items to choose from.

should be

	n: a non-negative integer, the number of items to choose from.

I didn't filled a bug report because this is very trivial.

Thanks,

-- 
Fernando Mayer
Programa de P?s-Gradua??o em Ecologia (PPGE)
Universidade Federal de Santa Catarina (UFSC)
URL: http://fernandomayer.googlepages.com
e-mail: fernandomayer [@] gmail.com


From fernandomayer at gmail.com  Fri May 22 05:31:47 2009
From: fernandomayer at gmail.com (Fernando Mayer)
Date: Fri, 22 May 2009 00:31:47 -0300
Subject: [Rd] Trivial typo in sample help file
Message-ID: <1242963107.4270.19.camel@deep-house>

[Sorry, forget the version below...]


Hi,

just found a small typo in help(sample). In 'Arguments' section, where
says

	n: a non-negaiive integer, the number of items to choose from.

should be

	n: a non-negative integer, the number of items to choose from.

I didn't filled a bug report because this is very trivial.

version()

platform       i686-pc-linux-gnu           
arch           i686                        
os             linux-gnu                   
system         i686, linux-gnu             
status                                     
major          2                           
minor          9.0                         
year           2009                        
month          04                          
day            17                          
svn rev        48333                       
language       R                           
version.string R version 2.9.0 (2009-04-17)

Thanks,

-- 
Fernando Mayer
Programa de P?s-Gradua??o em Ecologia (PPGE)
Universidade Federal de Santa Catarina (UFSC)
URL: http://fernandomayer.googlepages.com
e-mail: fernandomayer [@] gmail.com


From Heather.Turner at warwick.ac.uk  Fri May 22 12:13:03 2009
From: Heather.Turner at warwick.ac.uk (Heather Turner)
Date: Fri, 22 May 2009 11:13:03 +0100
Subject: [Rd] install.packages now intentionally references .Rprofile?
In-Reply-To: <6b93d1830905211428h6f5d0e66hdebfb9a3c70984f8@mail.gmail.com>
References: <6ph4ovf1gi0.fsf@gopher4.fhcrc.org>	<alpine.LFD.2.00.0905210715100.30855@gannet.stats.ox.ac.uk>
	<6b93d1830905211428h6f5d0e66hdebfb9a3c70984f8@mail.gmail.com>
Message-ID: <4A167AAF.2040803@warwick.ac.uk>

I had a similar problem when moving to R-2.9.0 as my .Rprofile called
update.packages(). The solution was to use

if(interactive()) {
	utils:::update.packages(ask = FALSE)
}

HTH,

Heather

Mark Kimpel wrote:
> This was my original post, with the code example only slightly modified by
> Martin for clarity. Prior to R-2.9.0, this repeated downloading did not
> occur, the code worked as intended. In fact, if memory serves me correctly,
> it even worked at least during the first 3 months of R-2.0.0 in its
> development stage, before release as a numbered version. Is there a reason
> for that? Is there a work-around? As I mentioned in my original post, the
> code is actually wrapped in a function that checks the date and the date of
> the last update, and proceeds to update package once per week. It was quite
> handy when it was working, hence my desire for a fix for my code.
> 
> Thanks,
> Mark
> ------------------------------------------------------------
> Mark W. Kimpel MD  ** Neuroinformatics ** Dept. of Psychiatry
> Indiana University School of Medicine
> 
> 15032 Hunter Court, Westfield, IN  46074
> 
> (317) 490-5129 Work, & Mobile & VoiceMail
> (317) 399-1219  Home
> Skype:  mkimpel
> 
> "The real problem is not whether machines think but whether men do." -- B.
> F. Skinner
> ******************************************************************
> 
> 
> On Thu, May 21, 2009 at 2:17 AM, Prof Brian Ripley <ripley at stats.ox.ac.uk>wrote:
> 
>> On Wed, 20 May 2009, Martin Morgan wrote:
>>
>>  A post on the Bioconductor mailing list
>>>  https://stat.ethz.ch/pipermail/bioconductor/2009-May/027700.html
>>>
>>> suggests that install.packages now references .Rprofile (?), whereas
>>> in R-2-8 it did not. Is this intentional?
>>>
>> Yes.  And in fact it did in earlier versions, to find the default library
>> into which to install.
>>
>>
>>
>>> The example is, in .Rprofile
>>>
>>>  library(utils)
>>>  install.packages("Biobase",
>>>                  repos="http://bioconductor.org/packages/2.4/bioc")
>>>
>>> then starting R from the command line results in repeated downloads
>>> of Biobase
>>>
>>> mtmorgan at mm:~/tmp> R --quiet
>>> trying URL
>>> '
>>> http://bioconductor.org/packages/2.4/bioc/src/contrib/Biobase_2.4.1.tar.gz
>>> '
>>> Content type 'application/x-gzip' length 1973533 bytes (1.9 Mb)
>>> opened URL
>>> ==================================================
>>> downloaded 1.9 Mb
>>>
>>> trying URL
>>> '
>>> http://bioconductor.org/packages/2.4/bioc/src/contrib/Biobase_2.4.1.tar.gz
>>> '
>>> Content type 'application/x-gzip' length 1973533 bytes (1.9 Mb)
>>> opened URL
>>> ==================================================
>>> downloaded 1.9 Mb
>>>
>>> ^C
>>> Execution halted
>>>
>>>  sessionInfo()
>>> R version 2.9.0 Patched (2009-05-20 r48588)
>>> x86_64-unknown-linux-gnu
>>>
>>> locale:
>>>
>>> LC_CTYPE=en_US.UTF-8;LC_NUMERIC=C;LC_TIME=en_US.UTF-8;LC_COLLATE=en_US.UTF-8;LC_MONETARY=C;LC_MESSAGES=en_US.UTF-8;LC_PAPER=en_US.UTF-8;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=en_US.UTF-8;LC_IDENTIFICATION=C
>>>
>>> attached base packages:
>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>
>>> Martin
>>> --
>>> Martin Morgan
>>> Computational Biology / Fred Hutchinson Cancer Research Center
>>> 1100 Fairview Ave. N.
>>> PO Box 19024 Seattle, WA 98109
>>>
>>> Location: Arnold Building M1 B861
>>> Phone: (206) 667-2793
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>>
>> --
>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/<http://www.stats.ox.ac.uk/%7Eripley/>
>> University of Oxford,             Tel:  +44 1865 272861 (self)
>> 1 South Parks Road,                     +44 1865 272866 (PA)
>> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>>
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From murdoch at stats.uwo.ca  Fri May 22 14:38:55 2009
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri, 22 May 2009 08:38:55 -0400
Subject: [Rd] file descriptor leak in getSrcLines in R 2.10.0 svn 48590
In-Reply-To: <77EB52C6DD32BA4D87471DCD70C8D70001336538@NA-PA-VBE03.na.tibco.com>
References: <77EB52C6DD32BA4D87471DCD70C8D70001336538@NA-PA-VBE03.na.tibco.com>
Message-ID: <4A169CDF.7070007@stats.uwo.ca>

On 5/21/2009 2:17 PM, William Dunlap wrote:
> I noticed the following file descriptor leak when I couldn't remove
> a package unless I shut down the R session that had loaded and
> used it.  The function that triggered the problem printed the output
> of a call to parse().  Each time one prints a srcref a connection is
> opened and not closed.  It looks like it happens in
> as.character.srcref's
> call to getSrcLines, which has some logic I don't understand about
> closing 'srcfile' on exit only if !.is.Open(srcfile):
> 
>> getSrcLines
> function (srcfile, first, last)
> {
>     if (first > last)
>         return(character(0L))
>     if (!.isOpen(srcfile))
>         on.exit(close(srcfile))
>     conn <- open(srcfile, first)
>     lines <- readLines(conn, n = last - first + 1L, warn = FALSE)
>     srcfile$line <- first + length(lines)
>     return(lines)
> }

The idea is that if the srcfile is already open, then it should be left 
open; but if it is not open, it should be closed at the end.  open() on 
an open srcfile is supposed to make no change to the srcfile, just 
return the already open connection.


> (It looks like the srcref stuff is not finished yet, as there are other
> problems, like print(parse(file)) not showing what it used to.)


This is an encoding problem, which looks easy to fix.  I think the leak 
was caused by this:  because of the encoding problem, the connections 
got opened but open.srcfile aborted before completion, so close.srcfile 
didn't think the srcfile was open at all, and it left the connections in 
existence.

The encoding problem came because "unknown" is not a legal encoding to 
pass to file().  It needs to be changed to "" or "native.enc".

Thanks for the report; I'll commit a fix after some more testing.

Duncan Murdoch

> This is on Linux, compiled by me with an ancient version of gcc.
> 
> % R
> R version 2.10.0 Under development (unstable) (2009-05-21 r48590)
> ...
>> showConnections()
>      description class mode text isopen can read can write
>> tf<-tempfile()
>> cat(file=tf, "1:7\nlog(pi)\n")
>> showConnections()
>      description class mode text isopen can read can write
>> p<-parse(tf)
>> showConnections()
>      description class mode text isopen can read can write
>> p
> expression(<srcref: file "/tmp/RtmpZ1llo5/file327b23c6" chars 1:1 to
> 1:3>,
>     <srcref: file "/tmp/RtmpZ1llo5/file327b23c6" chars 2:1 to 2:7>)
> attr(,"srcfile")
> /tmp/RtmpZ1llo5/file327b23c6
>> showConnections()
>   description                    class  mode text   isopen   can read
> can write
> 3 "/tmp/RtmpZ1llo5/file327b23c6" "file" "rt" "text" "opened" "yes"
> "no"
> 4 "/tmp/RtmpZ1llo5/file327b23c6" "file" "rt" "text" "opened" "yes"
> "no"
> 5 "/tmp/RtmpZ1llo5/file327b23c6" "file" "rt" "text" "opened" "yes"
> "no"
> 6 "/tmp/RtmpZ1llo5/file327b23c6" "file" "rt" "text" "opened" "yes"
> "no"
>> tf
> [1] "/tmp/RtmpZ1llo5/file327b23c6"
>> z<-attr(p,"srcref")[[2]]
>> showConnections()
>   description                    class  mode text   isopen   can read
> can write
> 3 "/tmp/RtmpZ1llo5/file327b23c6" "file" "rt" "text" "opened" "yes"
> "no"
> 4 "/tmp/RtmpZ1llo5/file327b23c6" "file" "rt" "text" "opened" "yes"
> "no"
> 5 "/tmp/RtmpZ1llo5/file327b23c6" "file" "rt" "text" "opened" "yes"
> "no"
> 6 "/tmp/RtmpZ1llo5/file327b23c6" "file" "rt" "text" "opened" "yes"
> "no"
>> zz<-as.character(z)
>> showConnections()
>   description                    class  mode text   isopen   can read
> can write
> 3 "/tmp/RtmpZ1llo5/file327b23c6" "file" "rt" "text" "opened" "yes"
> "no"
> 4 "/tmp/RtmpZ1llo5/file327b23c6" "file" "rt" "text" "opened" "yes"
> "no"
> 5 "/tmp/RtmpZ1llo5/file327b23c6" "file" "rt" "text" "opened" "yes"
> "no"
> 6 "/tmp/RtmpZ1llo5/file327b23c6" "file" "rt" "text" "opened" "yes"
> "no"
> 7 "/tmp/RtmpZ1llo5/file327b23c6" "file" "rt" "text" "opened" "yes"
> "no"
>> zz
> [1] "<srcref: file \"/tmp/RtmpZ1llo5/file327b23c6\" chars 2:1 to 2:7>"
> 
> Bill Dunlap
> TIBCO Software Inc - Spotfire Division
> wdunlap tibco.com 
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From wdunlap at tibco.com  Fri May 22 17:17:08 2009
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 22 May 2009 08:17:08 -0700
Subject: [Rd] file descriptor leak in getSrcLines in R 2.10.0 svn 48590
In-Reply-To: <4A169CDF.7070007@stats.uwo.ca>
References: <77EB52C6DD32BA4D87471DCD70C8D70001336538@NA-PA-VBE03.na.tibco.com>
	<4A169CDF.7070007@stats.uwo.ca>
Message-ID: <77EB52C6DD32BA4D87471DCD70C8D700013DB5FD@NA-PA-VBE03.na.tibco.com>

> ... 
> The idea is that if the srcfile is already open, then it 
> should be left 
> open; but if it is not open, it should be closed at the end.  
> open() on 
> an open srcfile is supposed to make no change to the srcfile, just 
> return the already open connection.
> 
> > (It looks like the srcref stuff is not finished yet, as 
> there are other
> > problems, like print(parse(file)) not showing what it used to.)
> 
> 
> This is an encoding problem, which looks easy to fix.  I 
> think the leak 
> was caused by this:  because of the encoding problem, the connections 
> got opened but open.srcfile aborted before completion, so 
> close.srcfile 
> didn't think the srcfile was open at all, and it left the 
> connections in 
> existence.

That incompletely opened connection may be why after doing
this test closeAllConnections crashed R because the ex_ptr
component of an Rconnection object was a nil pointer:

> tf<-tempfile()
> cat(file=tf, "1:10\nlog(log(pi))\n")
> p<-parse(tf)
> p
expression(<srcref: file "/tmp/RtmpazU79B/file327b23c6" chars 1:1 to 1:4>,
    <srcref: file "/tmp/RtmpazU79B/file327b23c6" chars 2:1 to 2:12>)
attr(,"srcfile")
/tmp/RtmpazU79B/file327b23c6
> showConnections()
  description                    class  mode text   isopen   can read can write
3 "/tmp/RtmpazU79B/file327b23c6" "file" "rt" "text" "opened" "yes"    "no"
4 "/tmp/RtmpazU79B/file327b23c6" "file" "rt" "text" "opened" "yes"    "no"
5 "/tmp/RtmpazU79B/file327b23c6" "file" "rt" "text" "opened" "yes"    "no"
6 "/tmp/RtmpazU79B/file327b23c6" "file" "rt" "text" "opened" "yes"    "no"
> closeAllConnections()

Program received signal SIGSEGV, Segmentation fault.
0x08118eff in Rf_setAttrib (vec=0x883f278, name=0x8621948, val=0x0)
    at attrib.c:226
226         if (NAMED(val)) val = duplicate(val);
(gdb) up
#1  0x08146c7b in do_getconnection (call=0x87a3b74, op=0x85f6fd8,
    args=0x87a3ca8, env=0x87a3c1c) at connections.c:4166
4166            setAttrib(ans, install("conn_id"), con->ex_ptr);
(gdb) list
4161        PROTECT(class = allocVector(STRSXP, 2));
4162        SET_STRING_ELT(class, 0, mkChar(con->class));
4163        SET_STRING_ELT(class, 1, mkChar("connection"));
4164        classgets(ans, class);
4165        if (what > 2)
4166            setAttrib(ans, install("conn_id"), con->ex_ptr);
4167        UNPROTECT(2);
4168        return ans;
4169    }
4170

(gdb) print con->ex_ptr
$3 = (void *) 0x0
(gdb) print *con
$4 = {class = 0x90c8940 "file",
  description = 0x89c5878 "/tmp/RtmpazU79B/file327b23c6", enc = 0,
  mode = "rt\000\000", text = TRUE, isopen = TRUE, incomplete = FALSE,
  canread = TRUE, canwrite = FALSE, canseek = TRUE, blocking = TRUE,
  isGzcon = FALSE, open = 0x813c4f2 <file_open>,
  close = 0x813c77b <file_close>, destroy = 0x813bcf9 <null_destroy>,
  vfprintf = 0x813c7c3 <file_vfprintf>, fgetc = 0x813bfef <dummy_fgetc>,
  fgetc_internal = 0x813c860 <file_fgetc_internal>,
  seek = 0x813c8f9 <file_seek>, truncate = 0x813caa1 <file_truncate>,
  fflush = 0x813cb8a <file_fflush>, read = 0x813cbae <file_read>,
  write = 0x813cc26 <file_write>, nPushBack = 0, posPushBack = 64256,
  PushBack = 0x204, save = -1000, save2 = -1000,
  encname = "unknown", '\0' <repeats 93 times>, "A", inconv = 0x0,
  outconv = 0x0,
  iconvbuff = "?\036\022\tE\001\000\000F\001\000\000G\001\000\000H\001\000\000I\001\000\000J",
  oconvbuff = "\001\000\000K\001\000\000L\001\000\000M\001\000\000N\001\000\000O\001\000\000P\001\000\000Q\001\000\000R\001\000\000S\001\000\000T\001\000\000U\001\000\000V\001", next = 0x157 <Address 0x157 out of bounds>,
  init_out = "X\001\000\000Y\001\000\000Z\001\000\000[\001\000\000\\\001\000\000]\001\000\000^", navail = 0, inavail = 351, EOF_signalled = 352,
  UTF8out = FALSE, id = 0x23, ex_ptr = 0x0, private = 0x908ec78}


From murdoch at stats.uwo.ca  Fri May 22 17:25:22 2009
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri, 22 May 2009 11:25:22 -0400
Subject: [Rd] file descriptor leak in getSrcLines in R 2.10.0 svn 48590
In-Reply-To: <77EB52C6DD32BA4D87471DCD70C8D700013DB5FD@NA-PA-VBE03.na.tibco.com>
References: <77EB52C6DD32BA4D87471DCD70C8D70001336538@NA-PA-VBE03.na.tibco.com>
	<4A169CDF.7070007@stats.uwo.ca>
	<77EB52C6DD32BA4D87471DCD70C8D700013DB5FD@NA-PA-VBE03.na.tibco.com>
Message-ID: <4A16C3E2.1000405@stats.uwo.ca>

On 5/22/2009 11:17 AM, William Dunlap wrote:
>> ... 
>> The idea is that if the srcfile is already open, then it 
>> should be left 
>> open; but if it is not open, it should be closed at the end.  
>> open() on 
>> an open srcfile is supposed to make no change to the srcfile, just 
>> return the already open connection.
>> 
>> > (It looks like the srcref stuff is not finished yet, as 
>> there are other
>> > problems, like print(parse(file)) not showing what it used to.)
>> 
>> 
>> This is an encoding problem, which looks easy to fix.  I 
>> think the leak 
>> was caused by this:  because of the encoding problem, the connections 
>> got opened but open.srcfile aborted before completion, so 
>> close.srcfile 
>> didn't think the srcfile was open at all, and it left the 
>> connections in 
>> existence.
> 
> That incompletely opened connection may be why after doing
> this test closeAllConnections crashed R because the ex_ptr
> component of an Rconnection object was a nil pointer:

I saw a crash like that once, but then couldn't reproduce it.  I'll see 
if I can do so with your code.

Duncan Murdoch

> 
>> tf<-tempfile()
>> cat(file=tf, "1:10\nlog(log(pi))\n")
>> p<-parse(tf)
>> p
> expression(<srcref: file "/tmp/RtmpazU79B/file327b23c6" chars 1:1 to 1:4>,
>     <srcref: file "/tmp/RtmpazU79B/file327b23c6" chars 2:1 to 2:12>)
> attr(,"srcfile")
> /tmp/RtmpazU79B/file327b23c6
>> showConnections()
>   description                    class  mode text   isopen   can read can write
> 3 "/tmp/RtmpazU79B/file327b23c6" "file" "rt" "text" "opened" "yes"    "no"
> 4 "/tmp/RtmpazU79B/file327b23c6" "file" "rt" "text" "opened" "yes"    "no"
> 5 "/tmp/RtmpazU79B/file327b23c6" "file" "rt" "text" "opened" "yes"    "no"
> 6 "/tmp/RtmpazU79B/file327b23c6" "file" "rt" "text" "opened" "yes"    "no"
>> closeAllConnections()
> 
> Program received signal SIGSEGV, Segmentation fault.
> 0x08118eff in Rf_setAttrib (vec=0x883f278, name=0x8621948, val=0x0)
>     at attrib.c:226
> 226         if (NAMED(val)) val = duplicate(val);
> (gdb) up
> #1  0x08146c7b in do_getconnection (call=0x87a3b74, op=0x85f6fd8,
>     args=0x87a3ca8, env=0x87a3c1c) at connections.c:4166
> 4166            setAttrib(ans, install("conn_id"), con->ex_ptr);
> (gdb) list
> 4161        PROTECT(class = allocVector(STRSXP, 2));
> 4162        SET_STRING_ELT(class, 0, mkChar(con->class));
> 4163        SET_STRING_ELT(class, 1, mkChar("connection"));
> 4164        classgets(ans, class);
> 4165        if (what > 2)
> 4166            setAttrib(ans, install("conn_id"), con->ex_ptr);
> 4167        UNPROTECT(2);
> 4168        return ans;
> 4169    }
> 4170
> 
> (gdb) print con->ex_ptr
> $3 = (void *) 0x0
> (gdb) print *con
> $4 = {class = 0x90c8940 "file",
>   description = 0x89c5878 "/tmp/RtmpazU79B/file327b23c6", enc = 0,
>   mode = "rt\000\000", text = TRUE, isopen = TRUE, incomplete = FALSE,
>   canread = TRUE, canwrite = FALSE, canseek = TRUE, blocking = TRUE,
>   isGzcon = FALSE, open = 0x813c4f2 <file_open>,
>   close = 0x813c77b <file_close>, destroy = 0x813bcf9 <null_destroy>,
>   vfprintf = 0x813c7c3 <file_vfprintf>, fgetc = 0x813bfef <dummy_fgetc>,
>   fgetc_internal = 0x813c860 <file_fgetc_internal>,
>   seek = 0x813c8f9 <file_seek>, truncate = 0x813caa1 <file_truncate>,
>   fflush = 0x813cb8a <file_fflush>, read = 0x813cbae <file_read>,
>   write = 0x813cc26 <file_write>, nPushBack = 0, posPushBack = 64256,
>   PushBack = 0x204, save = -1000, save2 = -1000,
>   encname = "unknown", '\0' <repeats 93 times>, "A", inconv = 0x0,
>   outconv = 0x0,
>   iconvbuff = " \036\022\tE\001\000\000F\001\000\000G\001\000\000H\001\000\000I\001\000\000J",
>   oconvbuff = "\001\000\000K\001\000\000L\001\000\000M\001\000\000N\001\000\000O\001\000\000P\001\000\000Q\001\000\000R\001\000\000S\001\000\000T\001\000\000U\001\000\000V\001", next = 0x157 <Address 0x157 out of bounds>,
>   init_out = "X\001\000\000Y\001\000\000Z\001\000\000[\001\000\000\\\001\000\000]\001\000\000^", navail = 0, inavail = 351, EOF_signalled = 352,
>   UTF8out = FALSE, id = 0x23, ex_ptr = 0x0, private = 0x908ec78}


From murdoch at stats.uwo.ca  Fri May 22 17:29:10 2009
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri, 22 May 2009 11:29:10 -0400
Subject: [Rd] file descriptor leak in getSrcLines in R 2.10.0 svn 48590
In-Reply-To: <77EB52C6DD32BA4D87471DCD70C8D70001336538@NA-PA-VBE03.na.tibco.com>
References: <77EB52C6DD32BA4D87471DCD70C8D70001336538@NA-PA-VBE03.na.tibco.com>
Message-ID: <4A16C4C6.8010100@stats.uwo.ca>

On 5/21/2009 2:17 PM, William Dunlap wrote:
> I noticed the following file descriptor leak when I couldn't remove
> a package unless I shut down the R session that had loaded and
> used it.  The function that triggered the problem printed the output
> of a call to parse().  Each time one prints a srcref a connection is
> opened and not closed.  It looks like it happens in
> as.character.srcref's
> call to getSrcLines, which has some logic I don't understand about
> closing 'srcfile' on exit only if !.is.Open(srcfile):

I have a simpler recipe to reproduce the crash now:

tf <- tempfile()
con <- file(tf, open="w", encoding="unknown")

This gives an error message about an unsupported conversion
and leaves the con object only partially built. closeAllConnections() 
will then crash.

Should be relatively easy to fix...I'll take a look.

Duncan Murdoch

> 
>> getSrcLines
> function (srcfile, first, last)
> {
>     if (first > last)
>         return(character(0L))
>     if (!.isOpen(srcfile))
>         on.exit(close(srcfile))
>     conn <- open(srcfile, first)
>     lines <- readLines(conn, n = last - first + 1L, warn = FALSE)
>     srcfile$line <- first + length(lines)
>     return(lines)
> }
> 
> (It looks like the srcref stuff is not finished yet, as there are other
> problems, like print(parse(file)) not showing what it used to.)
> 
> This is on Linux, compiled by me with an ancient version of gcc.
> 
> % R
> R version 2.10.0 Under development (unstable) (2009-05-21 r48590)
> ...
>> showConnections()
>      description class mode text isopen can read can write
>> tf<-tempfile()
>> cat(file=tf, "1:7\nlog(pi)\n")
>> showConnections()
>      description class mode text isopen can read can write
>> p<-parse(tf)
>> showConnections()
>      description class mode text isopen can read can write
>> p
> expression(<srcref: file "/tmp/RtmpZ1llo5/file327b23c6" chars 1:1 to
> 1:3>,
>     <srcref: file "/tmp/RtmpZ1llo5/file327b23c6" chars 2:1 to 2:7>)
> attr(,"srcfile")
> /tmp/RtmpZ1llo5/file327b23c6
>> showConnections()
>   description                    class  mode text   isopen   can read
> can write
> 3 "/tmp/RtmpZ1llo5/file327b23c6" "file" "rt" "text" "opened" "yes"
> "no"
> 4 "/tmp/RtmpZ1llo5/file327b23c6" "file" "rt" "text" "opened" "yes"
> "no"
> 5 "/tmp/RtmpZ1llo5/file327b23c6" "file" "rt" "text" "opened" "yes"
> "no"
> 6 "/tmp/RtmpZ1llo5/file327b23c6" "file" "rt" "text" "opened" "yes"
> "no"
>> tf
> [1] "/tmp/RtmpZ1llo5/file327b23c6"
>> z<-attr(p,"srcref")[[2]]
>> showConnections()
>   description                    class  mode text   isopen   can read
> can write
> 3 "/tmp/RtmpZ1llo5/file327b23c6" "file" "rt" "text" "opened" "yes"
> "no"
> 4 "/tmp/RtmpZ1llo5/file327b23c6" "file" "rt" "text" "opened" "yes"
> "no"
> 5 "/tmp/RtmpZ1llo5/file327b23c6" "file" "rt" "text" "opened" "yes"
> "no"
> 6 "/tmp/RtmpZ1llo5/file327b23c6" "file" "rt" "text" "opened" "yes"
> "no"
>> zz<-as.character(z)
>> showConnections()
>   description                    class  mode text   isopen   can read
> can write
> 3 "/tmp/RtmpZ1llo5/file327b23c6" "file" "rt" "text" "opened" "yes"
> "no"
> 4 "/tmp/RtmpZ1llo5/file327b23c6" "file" "rt" "text" "opened" "yes"
> "no"
> 5 "/tmp/RtmpZ1llo5/file327b23c6" "file" "rt" "text" "opened" "yes"
> "no"
> 6 "/tmp/RtmpZ1llo5/file327b23c6" "file" "rt" "text" "opened" "yes"
> "no"
> 7 "/tmp/RtmpZ1llo5/file327b23c6" "file" "rt" "text" "opened" "yes"
> "no"
>> zz
> [1] "<srcref: file \"/tmp/RtmpZ1llo5/file327b23c6\" chars 2:1 to 2:7>"
> 
> Bill Dunlap
> TIBCO Software Inc - Spotfire Division
> wdunlap tibco.com 
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From b.rowlingson at lancaster.ac.uk  Fri May 22 18:28:42 2009
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Fri, 22 May 2009 17:28:42 +0100
Subject: [Rd] Scope problem?
Message-ID: <d8ad40b50905220928p5235b38fi69361e4c7f7cd91d@mail.gmail.com>

I've just spent today trying to fix a Heisenbug...

this function returns a linear interpolator function:

interpOne <- function(xl,yl){
  f = function(data){
    t = (data-min(xl))/(max(xl)-min(xl))
    return(min(yl)+t*(max(yl)-min(yl)))
  }
  return(f)
}

> k=interpOne(c(0,1),c(4,5))
> k(0.5)
[1] 4.5

and this function uses the above to return a function that returns a
piece-wise linear interpolator function:

mr <- function(){
  parts = list()
  ranges =  rbind(c(0,1),c(1,2),c(2,3))
  domains = rbind(c(3,4),c(5,6),c(2,8))
  for(i in 1:length(ranges[,1])){
    parts[[i]] = interpOne(ranges[i,],domains[i,])
  }

  f = function(d){
    pos = sum(d>ranges[,1])
    cat("using pos = ",pos,"\n")
    return(parts[[pos]](d))
  }
  return(f)
}

m = mr()

 The 'ranges' and 'domains' vectors describe the pieces. But this doesn't work:
> m(0.5)
using pos =  1
[1] -7

 - but it should be 3.5 (since 0.5 is in the first piece, and that
then interpolates between 3 and 4). What about the other pieces:

> m(1.5)
using pos =  2
[1] -1
> m(2.5)
using pos =  3
[1] 5

 - which looks like it's using the last set of range/domain pairs each
time. Curious, I thought.

 So I thought I'd evaluate the functions as they are created in the
list to see what's going on. Change the loop to print out:

  for(i in 1:length(ranges[,1])){
    parts[[i]] = interpOne(ranges[i,],domains[i,])
    cat("part ",i," at zero = ",parts[[i]](0),"\n")
  }

and try:

 > m=mr()
 part  1  at zero =  3
 part  2  at zero =  4
 part  3  at zero =  -10

 looks good, those are the intercepts of my pieces... but now:

 > m(0.5)
 using pos =  1
 [1] 3.5
> m(1.5)
using pos =  2
[1] 5.5
> m(2.5)
using pos =  3
[1] 5

 Woah! It's now working!  Trying to observe the thing changes it? A Heisenbug!

 I can only think it's my misunderstanding of some aspect of R's
scoping and evaluation rules. Does evaluating the functions within
that loop cause a copy of some environment to be made, or a 'lazy
evaluation' to be evaluated? Or a 'promise' to be fulfilled? I don't
really understand those terms, I'd just hoped functions ran in the
environment they were created in. Seems sometimes they do, sometimes
they dont... What's going on?

 R 2.9.0 on Ubuntu.

Barry


From murdoch at stats.uwo.ca  Fri May 22 19:04:56 2009
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri, 22 May 2009 13:04:56 -0400
Subject: [Rd] Scope problem?
In-Reply-To: <d8ad40b50905220928p5235b38fi69361e4c7f7cd91d@mail.gmail.com>
References: <d8ad40b50905220928p5235b38fi69361e4c7f7cd91d@mail.gmail.com>
Message-ID: <4A16DB38.5010803@stats.uwo.ca>

On 5/22/2009 12:28 PM, Barry Rowlingson wrote:
> I've just spent today trying to fix a Heisenbug...
> 
> this function returns a linear interpolator function:
> 
> interpOne <- function(xl,yl){
>   f = function(data){
>     t = (data-min(xl))/(max(xl)-min(xl))
>     return(min(yl)+t*(max(yl)-min(yl)))
>   }
>   return(f)
> }
> 
>> k=interpOne(c(0,1),c(4,5))
>> k(0.5)
> [1] 4.5
> 
> and this function uses the above to return a function that returns a
> piece-wise linear interpolator function:
> 
> mr <- function(){
>   parts = list()
>   ranges =  rbind(c(0,1),c(1,2),c(2,3))
>   domains = rbind(c(3,4),c(5,6),c(2,8))
>   for(i in 1:length(ranges[,1])){
>     parts[[i]] = interpOne(ranges[i,],domains[i,])
>   }
> 
>   f = function(d){
>     pos = sum(d>ranges[,1])
>     cat("using pos = ",pos,"\n")
>     return(parts[[pos]](d))
>   }
>   return(f)
> }
> 
> m = mr()
> 
>  The 'ranges' and 'domains' vectors describe the pieces. But this doesn't work:
>> m(0.5)
> using pos =  1
> [1] -7
> 
>  - but it should be 3.5 (since 0.5 is in the first piece, and that
> then interpolates between 3 and 4). What about the other pieces:
> 
>> m(1.5)
> using pos =  2
> [1] -1
>> m(2.5)
> using pos =  3
> [1] 5
> 
>  - which looks like it's using the last set of range/domain pairs each
> time. Curious, I thought.
> 
>  So I thought I'd evaluate the functions as they are created in the
> list to see what's going on. Change the loop to print out:
> 
>   for(i in 1:length(ranges[,1])){
>     parts[[i]] = interpOne(ranges[i,],domains[i,])
>     cat("part ",i," at zero = ",parts[[i]](0),"\n")
>   }
> 
> and try:
> 
>  > m=mr()
>  part  1  at zero =  3
>  part  2  at zero =  4
>  part  3  at zero =  -10
> 
>  looks good, those are the intercepts of my pieces... but now:
> 
>  > m(0.5)
>  using pos =  1
>  [1] 3.5
>> m(1.5)
> using pos =  2
> [1] 5.5
>> m(2.5)
> using pos =  3
> [1] 5
> 
>  Woah! It's now working!  Trying to observe the thing changes it? A Heisenbug!
> 
>  I can only think it's my misunderstanding of some aspect of R's
> scoping and evaluation rules. Does evaluating the functions within
> that loop cause a copy of some environment to be made, or a 'lazy
> evaluation' to be evaluated? Or a 'promise' to be fulfilled? I don't
> really understand those terms, I'd just hoped functions ran in the
> environment they were created in. Seems sometimes they do, sometimes
> they dont... What's going on?

I think it's lazy evaluation that gets you. I haven't stepped through 
your code, but have done a similar one recently, and this is my guess 
about what happens:

- interpOne creates the function, but never evaluates xl or yl.

- You call it several times, to create a number of functions, but still 
never evaluate xl or yl.  They are left as promises to evaluate 
ranges[i,] and domains[i,] in the environment of that loop.

- Finally, you start evaluating those created functions, and it's at 
that point that xl and yl get forced.  Since i is now on the last value, 
they get the wrong values set.


Putting force(xl); force(yl) into your interpOne definition (so they get 
executed when interpOne is called, not just when the returned function 
is called) should work.

Duncan Murdoch


From b.rowlingson at lancaster.ac.uk  Fri May 22 21:02:19 2009
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Fri, 22 May 2009 20:02:19 +0100
Subject: [Rd] Scope problem?
In-Reply-To: <4A16DB38.5010803@stats.uwo.ca>
References: <d8ad40b50905220928p5235b38fi69361e4c7f7cd91d@mail.gmail.com>
	<4A16DB38.5010803@stats.uwo.ca>
Message-ID: <d8ad40b50905221202n42292738q73cdec9e9db65c5e@mail.gmail.com>

On Fri, May 22, 2009 at 6:04 PM, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:

> Putting force(xl); force(yl) into your interpOne definition (so they get
> executed when interpOne is called, not just when the returned function is
> called) should work.

 *sigh* yes, that looks like it. The help for "force" gives a more
concise example. What I'd posted was actually a cut-down version of my
original problem!

 I've not tested it yet, but other things I'd tried had removed the
bug without me understanding why - such as reassinging the args to
interpOne inside the function.

 Do any other languages work like this?

 Thanks

Barry


From ggrothendieck at gmail.com  Fri May 22 23:12:01 2009
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 22 May 2009 17:12:01 -0400
Subject: [Rd] Strange install key for R
Message-ID: <971536df0905221412g2d703064ub4d704e9a7a23bbc@mail.gmail.com>

One user of my batchfiles
http://batchfiles.googlecode.com
found they did not find the R registry key because it mysteriously
was at hklm\software\wow6432Node.   The system
was a 64 bit system. I've always seen the key at
hklm\software\R-core\R which is what the batchfiles assume.
Has there been some change in where the installer puts the key
or are there situations in which the location of the key in the
registry is somehow changed?

(Note that the batchfiles do have two workarounds in case the
user cannot or wishes not to access the registry but it would
be better not to have to rely on those.)


From murdoch at stats.uwo.ca  Sat May 23 01:32:49 2009
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri, 22 May 2009 19:32:49 -0400
Subject: [Rd] Scope problem?
In-Reply-To: <d8ad40b50905221202n42292738q73cdec9e9db65c5e@mail.gmail.com>
References: <d8ad40b50905220928p5235b38fi69361e4c7f7cd91d@mail.gmail.com>	<4A16DB38.5010803@stats.uwo.ca>
	<d8ad40b50905221202n42292738q73cdec9e9db65c5e@mail.gmail.com>
Message-ID: <4A173621.7050707@stats.uwo.ca>

On 22/05/2009 3:02 PM, Barry Rowlingson wrote:
> On Fri, May 22, 2009 at 6:04 PM, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> 
>> Putting force(xl); force(yl) into your interpOne definition (so they get
>> executed when interpOne is called, not just when the returned function is
>> called) should work.
> 
>  *sigh* yes, that looks like it. The help for "force" gives a more
> concise example. What I'd posted was actually a cut-down version of my
> original problem!
> 
>  I've not tested it yet, but other things I'd tried had removed the
> bug without me understanding why - such as reassinging the args to
> interpOne inside the function.
> 
>  Do any other languages work like this?


According to Wikipedia (http://en.wikipedia.org/wiki/Lazy_evaluation), 
functional languages tend to do this; examples they give are Haskell, 
Miranda, and it's optional in Scheme and Ocaml.

Duncan Murdoch


From romain.francois at dbmail.com  Sat May 23 09:33:11 2009
From: romain.francois at dbmail.com (Romain Francois)
Date: Sat, 23 May 2009 09:33:11 +0200
Subject: [Rd] [R] step by step debugger in R?
In-Reply-To: <4A16FBD1.9050909@fhcrc.org>
References: <b1f16d9d0905211600ke8a595ct1971b6e9a560dff4@mail.gmail.com>	<4A167A71.6070601@statistik.tu-dortmund.de>	<b1f16d9d0905220759qbf699b8hc5559b789e0ae43d@mail.gmail.com>
	<4A16C235.9050908@stats.uwo.ca> <4A16E236.1060905@dbmail.com>
	<4A16FBD1.9050909@fhcrc.org>
Message-ID: <4A17A6B7.7090404@dbmail.com>

[moving this to r-devel]

Robert Gentleman wrote:
> Hi,
>
> Romain Francois wrote:
>   
>> Duncan Murdoch wrote:
>>     
>>> On 5/22/2009 10:59 AM, Michael wrote:
>>>       
>>>> Really I think if there is a Visual Studio strength debugger, our
>>>> collective time spent in developing R code will be greatly reduced.
>>>>         
>>> If someone who knows how to write a debugger plugin for Eclipse wants
>>> to help, we could have that fairly easily.  All the infrastructure is
>>> there; it's the UI part that's missing.
>>>
>>> Duncan Murdoch
>>>       
>> [I've copied Mark Bravington and Robert Gentleman to the list as they
>> are likely to have views here, and I am not sure they monitor R-help]
>>
>> Hello,
>>
>> Making a front-end to debugging was one of the proposed google summer of
>> code for this year [1], it was not retained eventually, but I am still
>> motivated.
>>
>> Pretty much all infrastructure is there, and some work has been done
>> __very recently__ in R's debugging internals (ability to step up). As I
>> see it, the ability to call some sort of hook each time the debugger
>> waits for input would make it much easier for someone to write
>>     
>
>  I have still not come to an understanding of what this is supposed to do? When
> you have the browser prompt you can call any function or code you want to. There
> is no need for something special to allow you to do that.
>   
Sure. What I have in mind is something that gets __automatically__ 
called, similar to the task callback but happening right before the user 
is given the browser prompt.

>> front-ends. A recent post of mine (patch included) [2] on R-devel
>> suggested a custom prompt for browser which would do the trick, but I
>> now think that a hook would be more appropriate. Without something
>> similar to that, there is no way that I know of for making a front-end,
>> unless maybe if you embed R ... (please let me know how I am wrong)
>>     
>
>  I think you are wrong. I can't see why it is needed. The external debugger has
> lots of options for handling debugging. It can rewrite code (see examples in
> trace for how John Chambers has done this to support tracing at a location),
> which is AFAIK a pretty standard approach to writing debuggers. It can figure
> out where the break point is (made a bit easier by allowing it to put in pieces
> of text in the call to browser).  These are things the internal debugger can't do.
>
>   
Thanks. I'll have another look into that.

>> There is also the debug package [3,4] which does __not__ work with R
>> internals but rather works with instrumenting tricks at the R level.
>> debug provides a tcl/tk front-end. It is my understanding that it does
>> not work using R internals (do_browser, ...) because it was not possible
>> at the time, and I believe this is still not possible today, but I might
>> be wrong. I'd prefer to be wrong actually.
>>     
>
>   I don't understand this statement. It has always been possible to work with
> the internal version - but one can also take the approach of rewriting code.
> There are some difficulties supporting all the operations that one would like by
> rewriting code and I think a combination of external controls and the internal
> debugger will get most of the functionality that anyone wants.
>
>   There are somethings that are hard and once I have a more complete list I will
> be adding this to the appropriate manual. I will also be documenting the changes
> that I have been making, but that project is in flux and won't be done until the
> end of August, so people who want to look at it are welcome (it is in R-devel),
> but it is in development and could change pretty much without notice.
>   Romain noted that we now support stepping out from one place to another
> function.  We also have a debugonce flag that lets you get close to step in, but
> step in is very hard in R.
>
>   I am mostly interested in writing tools in R that can be used by anyone that
> wants to write an external debugger and am not that interested in any particular
> external debugger. I would be happy to listen to feature requests or issues that
> arise - but the discussion should probably be on R-devel mailing list.
>
>   best wishes
>     Robert
>
>
>   
>> Romain
>>
>> [1] : http://www.r-project.org/soc09/ideas.html#p5
>> [2] : https://stat.ethz.ch/pipermail/r-devel/2009-April/053128.html
>> [3] : http://cran.r-project.org/web/packages/debug/index.html
>> [4] : http://cran.r-project.org/doc/Rnews/Rnews_2003-3.pdf
>>
>>     
>
>   


-- 
Romain Francois
Independent R Consultant
+33(0) 6 28 91 30 30
http://romainfrancois.blog.free.fr


From savicky at cs.cas.cz  Sat May 23 09:44:54 2009
From: savicky at cs.cas.cz (Petr Savicky)
Date: Sat, 23 May 2009 09:44:54 +0200
Subject: [Rd] as.numeric(levels(factor(x))) may be a decreasing sequence
Message-ID: <20090523074454.GA17112@cs.cas.cz>

Function factor() in the current development version (2009-05-22)
guarantees that levels are different character strings. However, they
may represent the same decimal number. The following example is derived
from a posting by Stavros Macrakis in thread "Match .3 in a sequence"
in March

  nums <- 0.3 + 2e-16 * c(-2,-1,1,2)
  f <- factor(nums)
  levels(f)
  # [1] "0.300000000000000" "0.3"              

The levels differ in trailing zeros, but represent the same decimal number.
Besides that this is not really meaningful, it may cause a problem, when
using as.numeric(levels(f)).

In the above case, as.numeric() works fine and maps the two levels to the same
number. However, there are cases, where the difference in trailing zeros
implies different values in as.numeric(levels(f)) and these values may even
form a decreasing sequence although levels were constructed from an increasing
sequence of numbers.

Examples are platform dependent, but may be found by the following code.
Tested on Intel under Linux (both with and without SSE) and also under Windows
with an older version of R.

  for (i in 1:100000) {
      x <- 10^(floor(runif(1, 61, 63)) + runif(1)/2)
      x <- as.numeric(sprintf("%.14g", x))
      eps <- 2^(floor(log2(x)) - 52)
      k <- round(x * c(5e-16, 1e-15) / eps)
      if (x > 1e62) { k <- rev( - k) }
      y <- x + k[1]:k[2] * eps
      ind <- which(diff(as.numeric(as.character(y))) < 0)
      for (j in ind) {
          u1 <- y[c(j, j+1)]
          u2 <- factor(u1)
          print(levels(u2))
          print(diff(as.numeric(levels(u2))))
          aux <- readline("next")
      }
  }

An example of the output is

  [1] "1.2296427920313e+61"  "1.22964279203130e+61"
  [1] -1.427248e+45
  next
  [1] "1.82328862326830e+62" "1.8232886232683e+62" 
  [1] -2.283596e+46
  next

The negative number in diff(as.numeric(levels(u2))) demonstrates cases,
when as.numeric(levels(u2)) is decreasing. We can also see that the reason
is that the two strings in levels(u2) differ in the trailing zeros.

I did quite intensive search for such examples for all possible exponents
(not only 61 and 62 and a week of CPU on three processors) and all the obtained
examples were caused by a difference in trailing zeros. So, i believe that
removing trailing zeros from the output of as.character(x) solves the problem
with the reversed order in as.numeric(levels(factor(x))) entirely.

A patch against R-devel_2009-05-22, which eliminates trailing zeros
from as.character(x), but makes no other changes to as.character(x),
is in an attachment. Using the patch, we obtain a better result also
in the following.

  nums <- 0.3 + 2e-16 * c(-2,-1,1,2)
  factor(nums)
  # [1] 0.3 0.3 0.3 0.3
  # Levels: 0.3

Petr.

-------------- next part --------------
--- R-devel/src/main/coerce.c	2009-04-17 17:53:35.000000000 +0200
+++ R-devel-elim-trailing/src/main/coerce.c	2009-05-23 08:39:03.914774176 +0200
@@ -294,12 +294,33 @@
     else return mkChar(EncodeInteger(x, w));
 }
 
+const char *elim_trailing(const char *s, char cdec)
+{
+    const char *p;
+    char *replace;
+    for (p = s; *p; p++) {
+        if (*p == cdec) {
+            replace = (char *) p++;
+            while ('0' <= *p & *p <= '9') {
+                if (*(p++) != '0') {
+                    replace = (char *) p;
+                }
+            }
+            while (*(replace++) = *(p++)) {
+                ;
+            }
+            break;
+        }
+    }
+    return s;
+}
+
 SEXP attribute_hidden StringFromReal(double x, int *warn)
 {
     int w, d, e;
     formatReal(&x, 1, &w, &d, &e, 0);
     if (ISNA(x)) return NA_STRING;
-    else return mkChar(EncodeReal(x, w, d, e, OutDec));
+    else return mkChar(elim_trailing(EncodeReal(x, w, d, e, OutDec), OutDec));
 }
 
 SEXP attribute_hidden StringFromComplex(Rcomplex x, int *warn)

From ligges at statistik.tu-dortmund.de  Sat May 23 13:41:01 2009
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sat, 23 May 2009 13:41:01 +0200
Subject: [Rd] Strange install key for R
In-Reply-To: <971536df0905221412g2d703064ub4d704e9a7a23bbc@mail.gmail.com>
References: <971536df0905221412g2d703064ub4d704e9a7a23bbc@mail.gmail.com>
Message-ID: <4A17E0CD.70804@statistik.tu-dortmund.de>



Gabor Grothendieck wrote:
> One user of my batchfiles
> http://batchfiles.googlecode.com
> found they did not find the R registry key because it mysteriously
> was at hklm\software\wow6432Node.   The system
> was a 64 bit system. I've always seen the key at
> hklm\software\R-core\R which is what the batchfiles assume.

So you have not been on 64-bit Windows before - and you still you those 
batchfiles? Anyway, it does redirect the entries for (almost?) all 
32-bit Software. You might want to read MS Documentation if you feel 
this is an important issue.

Best,
Uwe Ligges


> Has there been some change in where the installer puts the key
> or are there situations in which the location of the key in the
> registry is somehow changed?
> 
> (Note that the batchfiles do have two workarounds in case the
> user cannot or wishes not to access the registry but it would
> be better not to have to rely on those.)
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From ggrothendieck at gmail.com  Sat May 23 14:11:09 2009
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 23 May 2009 08:11:09 -0400
Subject: [Rd] Strange install key for R
In-Reply-To: <4A17E0CD.70804@statistik.tu-dortmund.de>
References: <971536df0905221412g2d703064ub4d704e9a7a23bbc@mail.gmail.com> 
	<4A17E0CD.70804@statistik.tu-dortmund.de>
Message-ID: <971536df0905230511k36d0dcecyf99fa9dc5e10aec@mail.gmail.com>

2009/5/23 Uwe Ligges <ligges at statistik.tu-dortmund.de>:
>
>
> Gabor Grothendieck wrote:
>>
>> One user of my batchfiles
>> http://batchfiles.googlecode.com
>> found they did not find the R registry key because it mysteriously
>> was at hklm\software\wow6432Node. ? The system
>> was a 64 bit system. I've always seen the key at
>> hklm\software\R-core\R which is what the batchfiles assume.
>
> So you have not been on 64-bit Windows before - and you still you those
> batchfiles? Anyway, it does redirect the entries for (almost?) all 32-bit
> Software. You might want to read MS Documentation if you feel this is an
> important issue.

For architectures I don't have I rely on users to provide feedback.
On 64 bit Windows, the key is not being redirected by Windows.
I assume that this is dependent on how one accesses the key.  Perhaps
redirection is supported through certain APIs and not others.  At any rate,
I am assuming from your answer that R is not involved in such redirection
and am adding code to handle both sets of keys.


From murdoch at stats.uwo.ca  Sat May 23 17:14:33 2009
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sat, 23 May 2009 11:14:33 -0400
Subject: [Rd] file descriptor leak in getSrcLines in R 2.10.0 svn 48590
In-Reply-To: <4A16C4C6.8010100@stats.uwo.ca>
References: <77EB52C6DD32BA4D87471DCD70C8D70001336538@NA-PA-VBE03.na.tibco.com>
	<4A16C4C6.8010100@stats.uwo.ca>
Message-ID: <4A1812D9.3000707@stats.uwo.ca>

On 22/05/2009 11:29 AM, Duncan Murdoch wrote:
> On 5/21/2009 2:17 PM, William Dunlap wrote:
>> I noticed the following file descriptor leak when I couldn't remove
>> a package unless I shut down the R session that had loaded and
>> used it.  The function that triggered the problem printed the output
>> of a call to parse().  Each time one prints a srcref a connection is
>> opened and not closed.  It looks like it happens in
>> as.character.srcref's
>> call to getSrcLines, which has some logic I don't understand about
>> closing 'srcfile' on exit only if !.is.Open(srcfile):
> 
> I have a simpler recipe to reproduce the crash now:
> 
> tf <- tempfile()
> con <- file(tf, open="w", encoding="unknown")
> 
> This gives an error message about an unsupported conversion
> and leaves the con object only partially built. closeAllConnections() 
> will then crash.
> 
> Should be relatively easy to fix...I'll take a look.

Fixed now in R-devel and R-patched.

Duncan Murdoch


From atkocsis at iqrs.hu  Fri May 22 00:50:14 2009
From: atkocsis at iqrs.hu (atkocsis at iqrs.hu)
Date: Fri, 22 May 2009 00:50:14 +0200 (CEST)
Subject: [Rd] remez (signal) causes unhandled exception (PR#13713)
Message-ID: <20090521225015.029CE282C768@mail.pubhealth.ku.dk>

Full_Name: Attila Kocsis
Version: 2.9.0
OS: windows
Submission from: (NULL) (91.120.153.114)


I have installed R 2.9.0 on Windows.
Then installed signal package.
Then I issue the following commands in RGUI or rterm:

require("signal")
f1 = remez(17,c(0,0.00001,0.0625,1),c(1,1,0.001,0.001))

and the R clashes.

The possible cause of the problem is that no solution with given parameters is
possible. Maybe it runs into infinite loop.

With the command

f1 = remez(17,c(0,0.00001,0.2,1),c(1,1,0.001,0.001))

it is OK.


From jayoung at fhcrc.org  Thu May 21 23:44:30 2009
From: jayoung at fhcrc.org (Janet Young)
Date: Thu, 21 May 2009 14:44:30 -0700
Subject: [Rd] problems building R-2.9.0 on solaris
Message-ID: <629ED978-FBAC-4DF3-BF24-D63E0736D20B@fhcrc.org>

Hi,

I've successfully updated our linux version of R to 2.9.0 but am  
having trouble on our solaris machine.  I had previously installed  
2.8.1 and earlier versions without trouble.

I'm using R-patched_2009-05-20.tar.gz (I had also tried the 2009-05-10  
version).  Here's some info on our machine (I'm not the sysadmin):
[2] bedrock:/home/jayoung> uname -a
SunOS bedrock 5.10 Generic_118833-36 sun4v sparc SUNW,Sun-Fire-T200

Here's how I have been successfully installing the last few versions  
of R:

setenv LD_LIBRARY_PATH /home/jayoung/mysql/mysql-5.0.45-solaris10- 
sparc-64bit/lib:/opt/SUNWspro/lib:/usr/lib:/usr/openwin/lib
setenv PATH /home/jayoung/mysql/mysql-5.0.45-solaris10-sparc-64bit/lib/ 
bin:/bin:/sbin:/usr/sbin:/etc:/opt/SUNWspro/bin:/usr/ccs/bin
unsetenv R_HOME
./configure --enable-R-shlib R_PAPERSIZE='letter' --prefix='/home/ 
btrask/traskdata'
make
make install

Now, when I do that, configure looks like it completes OK, but during  
"make" it fails.  It also fails if I omit the "--enable-R-shlib"  
during configure.

It fails in a different way if I use my regular environment (i.e.  
start a new terminal, and use the commands as above but omitting the  
two setenv lines) - but that has never worked, so I won't bother you  
with the details of that (unless it seems like useful information to  
someone?). The setenvs I'm using (PATH and LD_LIBRARY_PATH) were given  
to me by the syadmin people here as a suggestion to get R installation  
working.

Below I have pasted the last part of the output from make:

 >>> Building/Updating help pages for package 'tcltk'
      Formats: text html latex example
   TclInterface                      text    html    latex   example
   TkCommands                        text    html    latex   example
   TkWidgetcmds                      text    html    latex   example
   TkWidgets                         text    html    latex   example
   tclServiceMode                    text    html    latex   example
   tcltk-defunct                     text    html    latex
   tcltk-package                     text    html    latex
   tkProgressBar                     text    html    latex   example
   tkStartGUI                        text    html    latex
   tk_choose.dir                     text    html    latex   example
   tk_choose.files                   text    html    latex   example
   tk_messageBox                     text    html    latex
   tk_select.list                    text    html    latex
   tkpager                           text    html    latex
begin installing recommended package VR
ERROR unable to create '/home/jayoung/source_codes/R/R-2.9.0/ 
unpack_solaris3/R-patched/library/MASS'
*** Error code 1
The following command caused the error:
MAKE="make" R_LIBS= ../../../bin/R CMD INSTALL --no-lock -l "../../../ 
library" VR.tgz > VR.ts.out 2>&1 || (cat VR.ts.out && exit 1)
make: Fatal error: Command failed for target `VR.ts'
Current working directory /home/jayoung/source_codes/R/R-2.9.0/ 
unpack_solaris3/R-patched/src/library/Recommended
*** Error code 1
The following command caused the error:
make stamp-recommended
make: Fatal error: Command failed for target `recommended-packages'
Current working directory /home/jayoung/source_codes/R/R-2.9.0/ 
unpack_solaris3/R-patched/src/library/Recommended
*** Error code 1
The following command caused the error:
(cd src/library/Recommended && make)
make: Fatal error: Command failed for target `stamp-recommended'


I'm not sure if this is a bug, or something screwy about the way our  
system is set up (I suspect the latter).  I'd be grateful for any  
ideas you might have to help me figure this out.

thanks in advance,

Janet Young

-------------------------------------------------------------------

Dr. Janet Young (Trask lab)

Fred Hutchinson Cancer Research Center
1100 Fairview Avenue N., C3-168,
P.O. Box 19024, Seattle, WA 98109-1024, USA.

tel: (206) 667 1471 fax: (206) 667 6524
email: jayoung  ...at...  fhcrc.org

http://www.fhcrc.org/labs/trask/


From ligges at statistik.tu-dortmund.de  Sat May 23 18:07:47 2009
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sat, 23 May 2009 18:07:47 +0200
Subject: [Rd] remez (signal) causes unhandled exception (PR#13713)
In-Reply-To: <20090521225015.029CE282C768@mail.pubhealth.ku.dk>
References: <20090521225015.029CE282C768@mail.pubhealth.ku.dk>
Message-ID: <4A181F53.4000106@statistik.tu-dortmund.de>



atkocsis at iqrs.hu wrote:
> Full_Name: Attila Kocsis
> Version: 2.9.0
> OS: windows
> Submission from: (NULL) (91.120.153.114)
> 
> 
> I have installed R 2.9.0 on Windows.
> Then installed signal package.
> Then I issue the following commands in RGUI or rterm:

Well, this happens in the remez() function that calls an entry point in 
compiled code of the package signal. Please report bugs of contributed 
packages to the package maintainer rather than to R-bugs.

Uwe Ligges





> require("signal")
> f1 = remez(17,c(0,0.00001,0.0625,1),c(1,1,0.001,0.001))
> 
> and the R clashes.
> 
> The possible cause of the problem is that no solution with given parameters is
> possible. Maybe it runs into infinite loop.
> 
> With the command
> 
> f1 = remez(17,c(0,0.00001,0.2,1),c(1,1,0.001,0.001))
> 
> it is OK.
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From savicky at cs.cas.cz  Sat May 23 18:22:26 2009
From: savicky at cs.cas.cz (Petr Savicky)
Date: Sat, 23 May 2009 18:22:26 +0200
Subject: [Rd] qbinom (PR#13711)
In-Reply-To: <20090520211011.0C04E283031D@mail.pubhealth.ku.dk>
References: <20090520211011.0C04E283031D@mail.pubhealth.ku.dk>
Message-ID: <20090523162226.GA28276@cs.cas.cz>

On Wed, May 20, 2009 at 11:10:11PM +0200, wolfgang.resch at gmail.com wrote:
...
> Strange behavior of qbinom:
> 
> > qbinom(0.01, 5016279, 1e-07)
> [1] 0
> > qbinom(0.01, 5016279, 2e-07)
> [1] 16
> > qbinom(0.01, 5016279, 3e-07)
> [1] 16
> > qbinom(0.01, 5016279, 4e-07)
> [1] 16
> > qbinom(0.01, 5016279, 5e-07)
> [1] 0
> 

There is a bug in function do_search() in file src/nmath/qbinom.c. This
function contains a cycle
        for(;;) {
            if(y == 0 ||
               (*z = pbinom(y - incr, n, pr, /*l._t.*/TRUE, /*log_p*/FALSE)) < p)
                return y;
            y = fmax2(0, y - incr);
        }
When this cycle stops, *z contains pbinom(y - incr, ...), but is used
as if it is pbinom(y, ...) for the resulting y.

In the example qbinom(p=0.01, size=5016279, prob=4e-07), we get at 
some step y=15 as a result of a search left with incr=50, so we have
*z=pbinom(-35, ...)=0. Hence, y=15 is treated as too low and is increased
to 16. Since 16 is detected to be sufficient, the search stops with y=16,
which is wrong.

A possible correction is to replace the code above by
    double newz;
        for(;;) {
            if(y == 0 ||
               (newz = pbinom(y - incr, n, pr, /*l._t.*/TRUE, /*log_p*/FALSE)) < p)
                return y;
            y = fmax2(0, y - incr);
            *z = newz;
        }

Patch against R-devel_2009-05-22 is in an attachment.

Verification may be done using the following examples.
  b1 <- qbinom(p=0.01, size=5016279, prob=(1:20)*1e-07)
  b2 <- qbinom(p=0.01, size=5006279, prob=(1:20)*1e-07)
  b3 <- qbinom(p=0.01, size=5000279, prob=(1:20)*1e-07)
  p1 <- qpois(p=0.01, lambda=5016279*(1:20)*1e-07)
  p2 <- qpois(p=0.01, lambda=5006279*(1:20)*1e-07)
  p3 <- qpois(p=0.01, lambda=5000279*(1:20)*1e-07)
  cbind(b1, b2, b3, p1, p2, p3)

Wrong
        b1 b2 b3 p1 p2 p3
   [1,]  0  0  0  0  0  0
   [2,] 16  6 50  0  0  0
   [3,] 16  6 50  0  0  0
   [4,] 16  6 50  0  0  0
   [5,]  0  0  0  0  0  0
   [6,]  0  0  0  0  0  0
   [7,]  0  0  0  0  0  0
   [8,]  0  0  0  0  0  0
   [9,]  0  0  0  0  0  0
  [10,]  1  1  1  1  1  1
  [11,]  1  1  1  1  1  1
  [12,]  1  1  1  1  1  1
  [13,]  1  1  1  1  1  1
  [14,]  2  2  2  2  2  2
  [15,]  2  2  2  2  2  2
  [16,]  2  2  2  2  2  2
  [17,] 19  9 53  3  3  3
  [18,]  3  3  3  3  3  3
  [19,]  3  3  3  3  3  3
  [20,]  3  3  3  3  3  3

Correct
        b1 b2 b3 p1 p2 p3
   [1,]  0  0  0  0  0  0
   [2,]  0  0  0  0  0  0
   [3,]  0  0  0  0  0  0
   [4,]  0  0  0  0  0  0
   [5,]  0  0  0  0  0  0
   [6,]  0  0  0  0  0  0
   [7,]  0  0  0  0  0  0
   [8,]  0  0  0  0  0  0
   [9,]  0  0  0  0  0  0
  [10,]  1  1  1  1  1  1
  [11,]  1  1  1  1  1  1
  [12,]  1  1  1  1  1  1
  [13,]  1  1  1  1  1  1
  [14,]  2  2  2  2  2  2
  [15,]  2  2  2  2  2  2
  [16,]  2  2  2  2  2  2
  [17,]  3  3  3  3  3  3
  [18,]  3  3  3  3  3  3
  [19,]  3  3  3  3  3  3
  [20,]  3  3  3  3  3  3

Petr.

-------------- next part --------------
--- R-devel/src/nmath/qbinom.c	2007-07-25 17:54:27.000000000 +0200
+++ R-devel-qbinom/src/nmath/qbinom.c	2009-05-23 17:22:43.538566976 +0200
@@ -36,6 +36,7 @@
 static double 
 do_search(double y, double *z, double p, double n, double pr, double incr)
 {
+    double newz;
     if(*z >= p) {
 			/* search to the left */
 #ifdef DEBUG_qbinom
@@ -43,9 +44,10 @@
 #endif
 	for(;;) {
 	    if(y == 0 ||
-	       (*z = pbinom(y - incr, n, pr, /*l._t.*/TRUE, /*log_p*/FALSE)) < p)
+	       (newz = pbinom(y - incr, n, pr, /*l._t.*/TRUE, /*log_p*/FALSE)) < p)
 		return y;
 	    y = fmax2(0, y - incr);
+	    *z = newz;
 	}
     }
     else {		/* search to the right */

From rgentlem at fhcrc.org  Sat May 23 18:55:19 2009
From: rgentlem at fhcrc.org (Robert Gentleman)
Date: Sat, 23 May 2009 09:55:19 -0700
Subject: [Rd] [R] step by step debugger in R?
In-Reply-To: <4A17A6B7.7090404@dbmail.com>
References: <b1f16d9d0905211600ke8a595ct1971b6e9a560dff4@mail.gmail.com>	<4A167A71.6070601@statistik.tu-dortmund.de>	<b1f16d9d0905220759qbf699b8hc5559b789e0ae43d@mail.gmail.com>
	<4A16C235.9050908@stats.uwo.ca> <4A16E236.1060905@dbmail.com>
	<4A16FBD1.9050909@fhcrc.org> <4A17A6B7.7090404@dbmail.com>
Message-ID: <4A182A77.1050503@fhcrc.org>

Hi,
  I stripped the cc's as I believe that all read this list.

Romain Francois wrote:
> [moving this to r-devel]
> 
> Robert Gentleman wrote:
>> Hi,
>>
>> Romain Francois wrote:
>>  
>>> Duncan Murdoch wrote:
>>>    
>>>> On 5/22/2009 10:59 AM, Michael wrote:
>>>>      
>>>>> Really I think if there is a Visual Studio strength debugger, our
>>>>> collective time spent in developing R code will be greatly reduced.
>>>>>         
>>>> If someone who knows how to write a debugger plugin for Eclipse wants
>>>> to help, we could have that fairly easily.  All the infrastructure is
>>>> there; it's the UI part that's missing.
>>>>
>>>> Duncan Murdoch
>>>>       
>>> [I've copied Mark Bravington and Robert Gentleman to the list as they
>>> are likely to have views here, and I am not sure they monitor R-help]
>>>
>>> Hello,
>>>
>>> Making a front-end to debugging was one of the proposed google summer of
>>> code for this year [1], it was not retained eventually, but I am still
>>> motivated.
>>>
>>> Pretty much all infrastructure is there, and some work has been done
>>> __very recently__ in R's debugging internals (ability to step up). As I
>>> see it, the ability to call some sort of hook each time the debugger
>>> waits for input would make it much easier for someone to write
>>>     
>>
>>  I have still not come to an understanding of what this is supposed to
>> do? When
>> you have the browser prompt you can call any function or code you want
>> to. There
>> is no need for something special to allow you to do that.
>>   
> Sure. What I have in mind is something that gets __automatically__
> called, similar to the task callback but happening right before the user
> is given the browser prompt.

 I am trying to understand the scenario you have in mind. Is it that the user is
running R directly and your debugger is essentially a helper function that gets
updated etc as R runs?

 If so, then I don't think that works very well and given the constraints we
have with R I don't think it will be able to solve many of the problems that an
IDE should.  The hook you want will give you some functionality, but no where
near enough.

 Let me suggest instead that the IDE should be running the show. It should
initialize an instance of R, but it controls all communication and hence
controls what is rendered on the client side.  If that is what you mean by
embedding R, then yes that is what is needed. There is no way that I can see to
support most of the things that IDE type debuggers support without the IDE
controlling the communication with R.

 And if I am wrong about what your debugger will look like please let me know.

 best wishes
   Robert


> 
>>> front-ends. A recent post of mine (patch included) [2] on R-devel
>>> suggested a custom prompt for browser which would do the trick, but I
>>> now think that a hook would be more appropriate. Without something
>>> similar to that, there is no way that I know of for making a front-end,
>>> unless maybe if you embed R ... (please let me know how I am wrong)
>>>     
>>
>>  I think you are wrong. I can't see why it is needed. The external
>> debugger has
>> lots of options for handling debugging. It can rewrite code (see
>> examples in
>> trace for how John Chambers has done this to support tracing at a
>> location),
>> which is AFAIK a pretty standard approach to writing debuggers. It can
>> figure
>> out where the break point is (made a bit easier by allowing it to put
>> in pieces
>> of text in the call to browser).  These are things the internal
>> debugger can't do.
>>
>>   
> Thanks. I'll have another look into that.
> 
>>> There is also the debug package [3,4] which does __not__ work with R
>>> internals but rather works with instrumenting tricks at the R level.
>>> debug provides a tcl/tk front-end. It is my understanding that it does
>>> not work using R internals (do_browser, ...) because it was not possible
>>> at the time, and I believe this is still not possible today, but I might
>>> be wrong. I'd prefer to be wrong actually.
>>>     
>>
>>   I don't understand this statement. It has always been possible to
>> work with
>> the internal version - but one can also take the approach of rewriting
>> code.
>> There are some difficulties supporting all the operations that one
>> would like by
>> rewriting code and I think a combination of external controls and the
>> internal
>> debugger will get most of the functionality that anyone wants.
>>
>>   There are somethings that are hard and once I have a more complete
>> list I will
>> be adding this to the appropriate manual. I will also be documenting
>> the changes
>> that I have been making, but that project is in flux and won't be done
>> until the
>> end of August, so people who want to look at it are welcome (it is in
>> R-devel),
>> but it is in development and could change pretty much without notice.
>>   Romain noted that we now support stepping out from one place to another
>> function.  We also have a debugonce flag that lets you get close to
>> step in, but
>> step in is very hard in R.
>>
>>   I am mostly interested in writing tools in R that can be used by
>> anyone that
>> wants to write an external debugger and am not that interested in any
>> particular
>> external debugger. I would be happy to listen to feature requests or
>> issues that
>> arise - but the discussion should probably be on R-devel mailing list.
>>
>>   best wishes
>>     Robert
>>
>>
>>  
>>> Romain
>>>
>>> [1] : http://www.r-project.org/soc09/ideas.html#p5
>>> [2] : https://stat.ethz.ch/pipermail/r-devel/2009-April/053128.html
>>> [3] : http://cran.r-project.org/web/packages/debug/index.html
>>> [4] : http://cran.r-project.org/doc/Rnews/Rnews_2003-3.pdf
>>>
>>>     
>>
>>   
> 
> 

-- 
Robert Gentleman, PhD
Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
PO Box 19024
Seattle, Washington 98109-1024
206-667-7700
rgentlem at fhcrc.org


From kynnjo at gmail.com  Sat May 23 22:37:14 2009
From: kynnjo at gmail.com (Kynn Jones)
Date: Sat, 23 May 2009 16:37:14 -0400
Subject: [Rd] Can a function know what other function called it?
Message-ID: <c2350ba40905231337u5ead6f97o95ee24f2faea081e@mail.gmail.com>

Suppose function foo calls function bar.  Is there any way in which
bar can find out the name of the function that called it, "foo"?

There are two generalization to this question that interest me.
First, can this query go farther up the call stack?  I.e. if bar now
calls baz, can baz find out the name of the function that called the
function that called it, i.e. "foo"?  Second, what other information,
beside its name, can bar find about the environment where it was
called?  E.g. can it find out the file name and line number of the
function call?

Thanks!


From rgentlem at fhcrc.org  Sat May 23 22:55:09 2009
From: rgentlem at fhcrc.org (Robert Gentleman)
Date: Sat, 23 May 2009 13:55:09 -0700
Subject: [Rd] Can a function know what other function called it?
In-Reply-To: <c2350ba40905231337u5ead6f97o95ee24f2faea081e@mail.gmail.com>
References: <c2350ba40905231337u5ead6f97o95ee24f2faea081e@mail.gmail.com>
Message-ID: <4A1862AD.2070600@fhcrc.org>

Hi Kynn,


Kynn Jones wrote:
> Suppose function foo calls function bar.  Is there any way in which
> bar can find out the name of the function that called it, "foo"?

 essentially yes. You can find out about the call stack by using sys.calls and
sys.parents etc. The man page plus additional manuals should be sufficient, but
let us know if there are things that are not clear.

> 
> There are two generalization to this question that interest me.
> First, can this query go farther up the call stack?  I.e. if bar now
> calls baz, can baz find out the name of the function that called the
> function that called it, i.e. "foo"?  Second, what other information,

 yes - you can (at least currently) get access to the entire calling stack and
some manipulations can be performed.


> beside its name, can bar find about the environment where it was
> called?  E.g. can it find out the file name and line number of the

 there is no real concept of file and line number associated with a function
definition (nor need their even be a name - functions can be anonymous).

 If you want to map back to source files then I think that currently we do not
keep quite enough information when a function is sourced. Others may be able to
elaborate more (or correct my mistakes).  I think we currently store the actual
text for the body of the function so that it can be used for printing, but we
don't store a file name/location/line number or anything of that sort. It could
probably be added, but would be a lot of work, so it would need someone who
really wanted it to do that.

 However, you can find out lots of other things if you want.  Do note that while
 it is possible to determine which function initiated the call, it is not
necessarily possible to figure out which of the calls (if there is more than one
in the body of the function) is active.  R does not keep track of things in that
way. To be clear if foo looks like:

  foo <- function(x) {
    bar(x)
    x = sqrt(x)
    bar(x)
  }
  and you have a breakpoint in bar, you could not (easily) distinguish which of
the two calls to bar was active. There is no line counter or anything of that
sort available.

 best wishes
   Robert

> function call?
> 
> Thanks!
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 

-- 
Robert Gentleman, PhD
Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
PO Box 19024
Seattle, Washington 98109-1024
206-667-7700
rgentlem at fhcrc.org


From kynnjo at gmail.com  Sat May 23 23:50:11 2009
From: kynnjo at gmail.com (Kynn Jones)
Date: Sat, 23 May 2009 17:50:11 -0400
Subject: [Rd] Can a function know what other function called it?
In-Reply-To: <4A1862AD.2070600@fhcrc.org>
References: <c2350ba40905231337u5ead6f97o95ee24f2faea081e@mail.gmail.com>
	<4A1862AD.2070600@fhcrc.org>
Message-ID: <c2350ba40905231450x344bb6f6j748d5a18c4af41b9@mail.gmail.com>

On Sat, May 23, 2009 at 4:55 PM, Robert Gentleman <rgentlem at fhcrc.org> wrote:
> Hi Kynn,
>
>
> Kynn Jones wrote:
>> Suppose function foo calls function bar. ?Is there any way in which
>> bar can find out the name of the function that called it, "foo"?
>
> ?essentially yes. You can find out about the call stack by using sys.calls and
> sys.parents etc. The man page plus additional manuals should be sufficient, but
> let us know if there are things that are not clear.

Thanks a lot!  That was very helpful.

This is the best I was able to come up with:

bar <- function() {
  caller <- sub("\\(.*", "", rev(sys.calls())[[2]])
  cat(sprintf("bar: i was called by \"%s\"\n", caller))
}

foo <- function() bar()

> foo()
bar: i was called by "foo"
>

So it works, but I'm a n00b with R.  If there's a less labored way to
achieve this, please let me know.

And thanks again for your response.  It was very instructive.

KJ


From khansen at stat.berkeley.edu  Sun May 24 00:45:19 2009
From: khansen at stat.berkeley.edu (Kasper Daniel Hansen)
Date: Sat, 23 May 2009 15:45:19 -0700
Subject: [Rd] using a "third party" DLL in my package
In-Reply-To: <4A13EA32.5010309@metla.fi>
References: <4A0C079F.7080101@metla.fi>
	<alpine.LFD.2.00.0905150905560.4378@gannet.stats.ox.ac.uk>
	<4A13EA32.5010309@metla.fi>
Message-ID: <0A2C49D8-9EDA-432B-B3CD-04A395EBBAC4@stat.berkeley.edu>


On May 20, 2009, at 4:32 , Seija Sirki? wrote:

> Hello again,
>
> thank you for the comments, especially this one:
>
> Prof Brian Ripley wrote:
>
> > My concern would be that there are different cases that fail under
> > Fortran compiler X and you are just sweeping the problem under the
> > carpet.
>
> It inspired us to go back to search the cause, and we've made some  
> progress: it's not the compiler, it's the compiler options. Simple,  
> but it took a while to figure that out since my experience in these  
> things is limited. When I build the package with default options  
> using INSTALL --build the dll is built with option -O3 as per R's  
> Makeconfig file. If I build the dll by hand, using gfortran with no  
> additional options and dyn.load it, everything works, and also with - 
> O and -Os. (No, I don't fully understand what the differences  
> between all these are, but that's another question).
>
> I'm looking at chapter 5.5 in Writing R Extensions and also 6.3.3 in  
> R Installation and Administration but I can't figure out how to tell  
> "inside" my package that it is not to be built -O3 but with, say, - 
> O. I can see how to add flags in the package (and as far as I can  
> tell, if there are several optimization level flags the last in line  
> is used and that's the wrong one from my point of view), and also  
> how to override flags but only on my computer. Am I blind or am I  
> again attempting something I shouldn't?


This is not trivial, and how you do it is compiler dependent. A quick  
fix was provided by Simon Urbanek a while back and it is _not_  
portable, it assumes you are using GCC. It would be nice to have a  
configure file that detects the compiler and optimization setting and  
then re-sets the optimization level. I have thought about writing one,  
but have never got around to do it.

Anyway, the fix is in the Makevars file from affxparser from  
Bioconductor. Essentially, you use a Makevars file placed in the src  
directory, containing

MYCXXFLAGS=-O0 -Wall

%.o: %.cpp
         $(CXX) $(ALL_CPPFLAGS) $(ALL_CXXFLAGS) $(MYCXXFLAGS) -c $< -o  
$@

Essentially this makes sure that -O0 (indicating no optimization) is  
placed at the _end_ of the call to the compiler (this is for C++ files  
btw), using the fact that if you have two -O* settings, the last one  
overrides the first.

This ought to be easily adaptable to FORTRAN.

Kasper


From ripley at stats.ox.ac.uk  Sun May 24 08:31:18 2009
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 24 May 2009 07:31:18 +0100 (BST)
Subject: [Rd] using a "third party" DLL in my package
In-Reply-To: <0A2C49D8-9EDA-432B-B3CD-04A395EBBAC4@stat.berkeley.edu>
References: <4A0C079F.7080101@metla.fi>
	<alpine.LFD.2.00.0905150905560.4378@gannet.stats.ox.ac.uk>
	<4A13EA32.5010309@metla.fi>
	<0A2C49D8-9EDA-432B-B3CD-04A395EBBAC4@stat.berkeley.edu>
Message-ID: <alpine.LFD.2.00.0905240727150.32603@gannet.stats.ox.ac.uk>

It is likely that this is related to using higher-precision FPU 
registers, in which case there is a portable solution: look up 
SAFE_FFLAGS in 'Writing R Extensions'.

But if that is the cause, the real solution is to write the code using 
proper convergence tests.

On Sat, 23 May 2009, Kasper Daniel Hansen wrote:

>
> On May 20, 2009, at 4:32 , Seija Sirki? wrote:
>
>> Hello again,
>> 
>> thank you for the comments, especially this one:
>> 
>> Prof Brian Ripley wrote:
>> 
>>> My concern would be that there are different cases that fail under
>>> Fortran compiler X and you are just sweeping the problem under the
>>> carpet.
>> 
>> It inspired us to go back to search the cause, and we've made some 
>> progress: it's not the compiler, it's the compiler options. Simple, but it 
>> took a while to figure that out since my experience in these things is 
>> limited. When I build the package with default options using INSTALL 
>> --build the dll is built with option -O3 as per R's Makeconfig file. If I 
>> build the dll by hand, using gfortran with no additional options and 
>> dyn.load it, everything works, and also with -O and -Os. (No, I don't fully 
>> understand what the differences between all these are, but that's another 
>> question).
>> 
>> I'm looking at chapter 5.5 in Writing R Extensions and also 6.3.3 in R 
>> Installation and Administration but I can't figure out how to tell "inside" 
>> my package that it is not to be built -O3 but with, say, -O. I can see how 
>> to add flags in the package (and as far as I can tell, if there are several 
>> optimization level flags the last in line is used and that's the wrong one 
>> from my point of view), and also how to override flags but only on my 
>> computer. Am I blind or am I again attempting something I shouldn't?
>
>
> This is not trivial, and how you do it is compiler dependent. A quick fix was 
> provided by Simon Urbanek a while back and it is _not_ portable, it assumes 
> you are using GCC. It would be nice to have a configure file that detects the 
> compiler and optimization setting and then re-sets the optimization level. I 
> have thought about writing one, but have never got around to do it.
>
> Anyway, the fix is in the Makevars file from affxparser from Bioconductor. 
> Essentially, you use a Makevars file placed in the src directory, containing
>
> MYCXXFLAGS=-O0 -Wall
>
> %.o: %.cpp
>       $(CXX) $(ALL_CPPFLAGS) $(ALL_CXXFLAGS) $(MYCXXFLAGS) -c $< -o $@
>
> Essentially this makes sure that -O0 (indicating no optimization) is placed 
> at the _end_ of the call to the compiler (this is for C++ files btw), using 
> the fact that if you have two -O* settings, the last one overrides the first.
>
> This ought to be easily adaptable to FORTRAN.
>
> Kasper
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From romain.francois at dbmail.com  Sun May 24 10:18:17 2009
From: romain.francois at dbmail.com (Romain Francois)
Date: Sun, 24 May 2009 10:18:17 +0200
Subject: [Rd] [R] step by step debugger in R?
In-Reply-To: <4A182A77.1050503@fhcrc.org>
References: <b1f16d9d0905211600ke8a595ct1971b6e9a560dff4@mail.gmail.com>	<4A167A71.6070601@statistik.tu-dortmund.de>	<b1f16d9d0905220759qbf699b8hc5559b789e0ae43d@mail.gmail.com>
	<4A16C235.9050908@stats.uwo.ca> <4A16E236.1060905@dbmail.com>
	<4A16FBD1.9050909@fhcrc.org> <4A17A6B7.7090404@dbmail.com>
	<4A182A77.1050503@fhcrc.org>
Message-ID: <4A1902C9.3000705@dbmail.com>

Robert Gentleman wrote:
> Hi,
>   I stripped the cc's as I believe that all read this list.
>
> Romain Francois wrote:
>   
>> [moving this to r-devel]
>>
>> Robert Gentleman wrote:
>>     
>>> Hi,
>>>
>>> Romain Francois wrote:
>>>  
>>>       
>>>> Duncan Murdoch wrote:
>>>>    
>>>>         
>>>>> On 5/22/2009 10:59 AM, Michael wrote:
>>>>>      
>>>>>           
>>>>>> Really I think if there is a Visual Studio strength debugger, our
>>>>>> collective time spent in developing R code will be greatly reduced.
>>>>>>         
>>>>>>             
>>>>> If someone who knows how to write a debugger plugin for Eclipse wants
>>>>> to help, we could have that fairly easily.  All the infrastructure is
>>>>> there; it's the UI part that's missing.
>>>>>
>>>>> Duncan Murdoch
>>>>>       
>>>>>           
>>>> [I've copied Mark Bravington and Robert Gentleman to the list as they
>>>> are likely to have views here, and I am not sure they monitor R-help]
>>>>
>>>> Hello,
>>>>
>>>> Making a front-end to debugging was one of the proposed google summer of
>>>> code for this year [1], it was not retained eventually, but I am still
>>>> motivated.
>>>>
>>>> Pretty much all infrastructure is there, and some work has been done
>>>> __very recently__ in R's debugging internals (ability to step up). As I
>>>> see it, the ability to call some sort of hook each time the debugger
>>>> waits for input would make it much easier for someone to write
>>>>     
>>>>         
>>>  I have still not come to an understanding of what this is supposed to
>>> do? When
>>> you have the browser prompt you can call any function or code you want
>>> to. There
>>> is no need for something special to allow you to do that.
>>>   
>>>       
>> Sure. What I have in mind is something that gets __automatically__
>> called, similar to the task callback but happening right before the user
>> is given the browser prompt.
>>     
>
>  I am trying to understand the scenario you have in mind. Is it that the user is
> running R directly and your debugger is essentially a helper function that gets
> updated etc as R runs?
>   
yes. there are now several ui toolkits that could be use to give some 
sort of graphical representation of what is being debugged.

I agree with you that and IDE should command R and not the other way 
around, but I am not (yet) here talking about a fully featured IDE, but 
simply a debugger.

I need to read more about embedding R (as in section 8 of WRE). I know 
you can supply your own implementation of the REPL, but I am not sure 
this includes the one that goes on once trapped into the browser. For 
example littler ships its own REPL, but this does not seem to fool/deal 
with browser:

$ r -e "print(1:10); browser(); print(1:5) "
 [1]  1  2  3  4  5  6  7  8  9 10
Called from: NULL
c
 [1]  1  2  3  4  5

Not sure this is an omission of Jeffrey and Dirk or something else.

>  If so, then I don't think that works very well and given the constraints we
> have with R I don't think it will be able to solve many of the problems that an
> IDE should.  The hook you want will give you some functionality, but no where
> near enough.
>   

In the long run, I do agree. In the short run, I'd prefer taking the bus 
to the airport rather than walk.

>  Let me suggest instead that the IDE should be running the show. It should
> initialize an instance of R, but it controls all communication and hence
> controls what is rendered on the client side.  If that is what you mean by
> embedding R, then yes that is what is needed. There is no way that I can see to
> support most of the things that IDE type debuggers support without the IDE
> controlling the communication with R.
>
>  And if I am wrong about what your debugger will look like please let me know.
>
>  best wishes
>    Robert
>
>
>   
>>>> front-ends. A recent post of mine (patch included) [2] on R-devel
>>>> suggested a custom prompt for browser which would do the trick, but I
>>>> now think that a hook would be more appropriate. Without something
>>>> similar to that, there is no way that I know of for making a front-end,
>>>> unless maybe if you embed R ... (please let me know how I am wrong)
>>>>     
>>>>         
>>>  I think you are wrong. I can't see why it is needed. The external
>>> debugger has
>>> lots of options for handling debugging. It can rewrite code (see
>>> examples in
>>> trace for how John Chambers has done this to support tracing at a
>>> location),
>>> which is AFAIK a pretty standard approach to writing debuggers. It can
>>> figure
>>> out where the break point is (made a bit easier by allowing it to put
>>> in pieces
>>> of text in the call to browser).  These are things the internal
>>> debugger can't do.
>>>
>>>   
>>>       
>> Thanks. I'll have another look into that.
>>
>>     
>>>> There is also the debug package [3,4] which does __not__ work with R
>>>> internals but rather works with instrumenting tricks at the R level.
>>>> debug provides a tcl/tk front-end. It is my understanding that it does
>>>> not work using R internals (do_browser, ...) because it was not possible
>>>> at the time, and I believe this is still not possible today, but I might
>>>> be wrong. I'd prefer to be wrong actually.
>>>>     
>>>>         
>>>   I don't understand this statement. It has always been possible to
>>> work with
>>> the internal version - but one can also take the approach of rewriting
>>> code.
>>> There are some difficulties supporting all the operations that one
>>> would like by
>>> rewriting code and I think a combination of external controls and the
>>> internal
>>> debugger will get most of the functionality that anyone wants.
>>>
>>>   There are somethings that are hard and once I have a more complete
>>> list I will
>>> be adding this to the appropriate manual. I will also be documenting
>>> the changes
>>> that I have been making, but that project is in flux and won't be done
>>> until the
>>> end of August, so people who want to look at it are welcome (it is in
>>> R-devel),
>>> but it is in development and could change pretty much without notice.
>>>   Romain noted that we now support stepping out from one place to another
>>> function.  We also have a debugonce flag that lets you get close to
>>> step in, but
>>> step in is very hard in R.
>>>
>>>   I am mostly interested in writing tools in R that can be used by
>>> anyone that
>>> wants to write an external debugger and am not that interested in any
>>> particular
>>> external debugger. I would be happy to listen to feature requests or
>>> issues that
>>> arise - but the discussion should probably be on R-devel mailing list.
>>>
>>>   best wishes
>>>     Robert
>>>
>>>
>>>  
>>>       
>>>> Romain
>>>>
>>>> [1] : http://www.r-project.org/soc09/ideas.html#p5
>>>> [2] : https://stat.ethz.ch/pipermail/r-devel/2009-April/053128.html
>>>> [3] : http://cran.r-project.org/web/packages/debug/index.html
>>>> [4] : http://cran.r-project.org/doc/Rnews/Rnews_2003-3.pdf
>>>>
>>>>     
>>>>         
>>>   
>>>       
>>     
>
>   


-- 
Romain Francois
Independent R Consultant
+33(0) 6 28 91 30 30
http://romainfrancois.blog.free.fr


From murdoch at stats.uwo.ca  Sun May 24 13:58:39 2009
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sun, 24 May 2009 07:58:39 -0400
Subject: [Rd] Can a function know what other function called it?
In-Reply-To: <4A1862AD.2070600@fhcrc.org>
References: <c2350ba40905231337u5ead6f97o95ee24f2faea081e@mail.gmail.com>
	<4A1862AD.2070600@fhcrc.org>
Message-ID: <4A19366F.5080402@stats.uwo.ca>

On 23/05/2009 4:55 PM, Robert Gentleman wrote:
> Hi Kynn,
> 
> 
> Kynn Jones wrote:
>> Suppose function foo calls function bar.  Is there any way in which
>> bar can find out the name of the function that called it, "foo"?
> 
>  essentially yes. You can find out about the call stack by using sys.calls and
> sys.parents etc. The man page plus additional manuals should be sufficient, but
> let us know if there are things that are not clear.
> 
>> There are two generalization to this question that interest me.
>> First, can this query go farther up the call stack?  I.e. if bar now
>> calls baz, can baz find out the name of the function that called the
>> function that called it, i.e. "foo"?  Second, what other information,
> 
>  yes - you can (at least currently) get access to the entire calling stack and
> some manipulations can be performed.
> 
> 
>> beside its name, can bar find about the environment where it was
>> called?  E.g. can it find out the file name and line number of the
> 
>  there is no real concept of file and line number associated with a function
> definition (nor need their even be a name - functions can be anonymous).
> 
>  If you want to map back to source files then I think that currently we do not
> keep quite enough information when a function is sourced. Others may be able to
> elaborate more (or correct my mistakes).  I think we currently store the actual
> text for the body of the function so that it can be used for printing, but we
> don't store a file name/location/line number or anything of that sort. It could
> probably be added, but would be a lot of work, so it would need someone who
> really wanted it to do that.

By default we don't store either a copy of the source or the references 
to the source file for functions in a package, but those options can be 
enabled, and are enabled by default for users working at the console. 
For example, with this source in c:/temp/test.R:

g <- function(x) {
   x <- 1
   y <- 4
}

You can do the following:

 > getOption("keep.source")
[1] TRUE
 > source("c:/temp/test.R")
 > as.list(g)[[2]]
{
     x <- 1
     y <- 4
}
attr(,"srcfile")
c:/temp/test.R

You can also find out which part of the file corresponds to each 
statement of the function definition.  For example,

 > attributes(as.list(g)[[2]])
$srcref
$srcref[[1]]
{

$srcref[[2]]
x <- 1

$srcref[[3]]
y <- 4


$srcfile
c:/temp/test.R

 > print(attr(as.list(g)[[2]], "srcref")[[2]])
x <- 1
 > print(attr(as.list(g)[[2]], "srcref")[[2]], useSource=FALSE)
<srcref: file "c:/temp/test.R" chars 2:3 to 2:8>


> 
>  However, you can find out lots of other things if you want.  Do note that while
>  it is possible to determine which function initiated the call, it is not
> necessarily possible to figure out which of the calls (if there is more than one
> in the body of the function) is active.  R does not keep track of things in that
> way. To be clear if foo looks like:
> 
>   foo <- function(x) {
>     bar(x)
>     x = sqrt(x)
>     bar(x)
>   }
>   and you have a breakpoint in bar, you could not (easily) distinguish which of
> the two calls to bar was active. There is no line counter or anything of that
> sort available.

The evaluator doesn't pay any attention to srcref records, so this is 
still true, but it would be possible to keep the srcref on the stack as 
well as all the other info there.

I've written code (and I think I sent it to you last year) that can do 
things like replacing the statement coming from a particular line of a 
file with whatever code you like; this could be used in writing a nice 
source-level debugger.

Duncan Murdoch

> 
>  best wishes
>    Robert
> 
>> function call?
>>
>> Thanks!
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>


From romain.francois at dbmail.com  Sun May 24 16:23:46 2009
From: romain.francois at dbmail.com (Romain Francois)
Date: Sun, 24 May 2009 16:23:46 +0200
Subject: [Rd] Can a function know what other function called it?
In-Reply-To: <4A19366F.5080402@stats.uwo.ca>
References: <c2350ba40905231337u5ead6f97o95ee24f2faea081e@mail.gmail.com>	<4A1862AD.2070600@fhcrc.org>
	<4A19366F.5080402@stats.uwo.ca>
Message-ID: <4A195872.5030507@dbmail.com>

Duncan Murdoch wrote:
> On 23/05/2009 4:55 PM, Robert Gentleman wrote:
>> Kynn Jones wrote:
>>
[snip]
>>
>>   and you have a breakpoint in bar, you could not (easily) 
>> distinguish which of
>> the two calls to bar was active. There is no line counter or anything 
>> of that
>> sort available.
>
> The evaluator doesn't pay any attention to srcref records, so this is 
> still true, but it would be possible to keep the srcref on the stack 
> as well as all the other info there.

Please

>
> I've written code (and I think I sent it to you last year) that can do 
> things like replacing the statement coming from a particular line of a 
> file with whatever code you like; this could be used in writing a nice 
> source-level debugger.

yes

>
> Duncan Murdoch
>
>>
>>  best wishes
>>    Robert
>>
>


-- 
Romain Francois
Independent R Consultant
+33(0) 6 28 91 30 30
http://romainfrancois.blog.free.fr


From ted.dunning at gmail.com  Sun May 24 06:35:12 2009
From: ted.dunning at gmail.com (ted.dunning at gmail.com)
Date: Sun, 24 May 2009 06:35:12 +0200 (CEST)
Subject: [Rd] Bad values obtained from digamma implementation (PR#13714)
Message-ID: <20090524043512.B3708282BE83@mail.pubhealth.ku.dk>

I was writing and testing an implementation of digamma and discovered that
the values produced by R are very poor for some arguments.

For example:

> print(digamma(1e-15),20)
[1] -562949953421312.5

whereas the correct value to 20 places as computed by Mathematica (and my
own independent implementation) is

-1.0000000000000005772e15

This is about a factor of 2 different from the correct value.

Here is a reference implementation in Java of the algorithm by Bernardo as
published as AS103 that does not suffer this problem.  I hope it helps.

/**
 * Computes gamma related functions.
 * <p/>
 * This is an independently written implementation of the algorithm
described in
 * <p/>
 * Jose Bernardo, Algorithm AS 103: Psi (Digamma) Function, Applied
Statistics, 1976
 * <p/>
 *
 * I have changed some of the constants to increase accuracy at the moderate
expense
 * of run-time.  The result should be accurate to within 10^-8 absolute
tolerance for
 * x >= 10^-5 and within 10^-8 relative tolerance for x > 0.
 *
 * Performance for large negative values of x will be quite expensive
(proportional to
 * |x|.  Accuracy for negative values of x should be about 10^-8 absolute
for results
 * less than 10^5 and 10^-8 relative for results larger than that. */
public class Gamma {
    public static final double GAMMA = 0.577215664901532860606512090082;

    private static final double C = 49;
    private static final double S = 1e-5;

    public static double digamma(double x) {
        if (x > 0 && x <= S) {
            // use method 5 from Bernardo AS103
            // accurate to O(x)
            return -GAMMA - 1 / x;
        }

        if (x >= C) {
            // use method 4 (accurate to O(1/x^8)
            double inv = 1 / (x * x);
            //            1       1        1         1
            // log(x) -  --- - ------ - ------- - -------
            //           2 x   12 x^2   120 x^4   252 x^6
            return Math.log(x) - 0.5 / x - inv * ((1.0 / 12) + inv * (1.0 /
120 - inv / 252));
        }

        return digamma(x + 1) - 1 / x;
    }
}

And here are some test cases:

public class TestGamma {
    @Test
    public void digammaLargeArgs() {
        double eps = 1e-8;
        Assert.assertEquals(4.6001618527380874002, Gamma.digamma(100), eps);
        Assert.assertEquals(3.9019896734278921970, Gamma.digamma(50), eps);
        Assert.assertEquals(2.9705239922421490509, Gamma.digamma(20), eps);
        Assert.assertEquals(2.9958363947076465821, Gamma.digamma(20.5),
eps);
        Assert.assertEquals(2.2622143570941481605, Gamma.digamma(10.1),
eps);
        Assert.assertEquals(2.1168588189004379233, Gamma.digamma(8.8), eps);
        Assert.assertEquals(1.8727843350984671394, Gamma.digamma(7), eps);
        Assert.assertEquals(0.42278433509846713939, Gamma.digamma(2), eps);
        Assert.assertEquals(-100.56088545786867450, Gamma.digamma(0.01),
eps);
        Assert.assertEquals(-4.0390398965921882955, Gamma.digamma(-0.8),
eps);
        Assert.assertEquals(4.2003210041401844726, Gamma.digamma(-6.3),
eps);
    }

    @Test
    public void digammaSmallArgs() {
        // values for negative powers of 10 from 1 to 30 as computed by
webMathematica with 20 digits
        // see functions.wolfram.com
        double[] expected = {-10.423754940411076795, -100.56088545786867450,
-1000.5755719318103005,
                -10000.577051183514335, -100000.57719921568107,
-1.0000005772140199687e6, -1.0000000577215500408e7,
                -1.0000000057721564845e8, -1.0000000005772156633e9,
-1.0000000000577215665e10, -1.0000000000057721566e11,
                -1.0000000000005772157e12, -1.0000000000000577216e13,
-1.0000000000000057722e14, -1.0000000000000005772e15, -1e+16,
                -1e+17, -1e+18, -1e+19, -1e+20, -1e+21, -1e+22, -1e+23,
-1e+24, -1e+25, -1e+26,
                -1e+27, -1e+28, -1e+29, -1e+30};
        for (double n = 1; n < 30; n++) {
            System.out.printf("10^-n = %.10f\n", Math.pow(10, -n));
            checkRelativeError(String.format("Test %.0f: ", n),
expected[(int) (n - 1)], Gamma.digamma(Math.pow(10.0, -n)), 1e-8);
        }

    private void checkRelativeError(String msg, double expected, double
actual, double tolerance) {
        System.out.printf("%s = %.2f (%s)\n", msg, Math.abs(expected -
actual) / actual, Math.abs(expected - actual) > Math.abs(tolerance *
actual));
        Assert.assertEquals(msg, expected, actual, Math.abs(tolerance *
actual));
    }
}

Feel free to use this code in any way you like.  I wrote it and granted it
to the Apache Software Foundation; I will grant it
to the R community under the same terms if useful.

My contact information is Ted Dunning, ted.dunning at gmail.com




--please do not edit the information below--

Version:
 platform = i386-apple-darwin8.11.1
 arch = i386
 os = darwin8.11.1
 system = i386, darwin8.11.1
 status =
 major = 2
 minor = 9.0
 year = 2009
 month = 04
 day = 17
 svn rev = 48333
 language = R
 version.string = R version 2.9.0 (2009-04-17)

Locale:
en_US.UTF-8/en_US.UTF-8/C/C/en_US.UTF-8/en_US.UTF-8

Search Path:
 .GlobalEnv, package:stats, package:graphics, package:grDevices,
package:utils, package:datasets, package:methods, Autoloads, package:base

	[[alternative HTML version deleted]]


From xiehb at mail.kiz.ac.cn  Sun May 24 10:25:08 2009
From: xiehb at mail.kiz.ac.cn (xiehb at mail.kiz.ac.cn)
Date: Sun, 24 May 2009 10:25:08 +0200 (CEST)
Subject: [Rd] utf8towcs -- margin is too wide for a plot (PR#13716)
Message-ID: <20090524082508.13109282EFF6@mail.pubhealth.ku.dk>

Full_Name: Haibing Xie
Version: 2.9.0
OS: Windows XP
Submission from: (NULL) (221.3.149.10)


>a=seq(1:10);
>plot(a);

Then I narrowed down the plot window, and got an error message. It always
repeated that error when doing the same operation. 

Because it was given in Chinese and I never installed the English version, I
cannot give the exact error messge. The error message contains the word
"utf8towcs", and it was complaining about the marginal region is too wide for
the plot. More badly, Alt+Ctrl+Del press is needed to move mouse into the screen
region outside RGui. After the error, RGui cannot be resized anymore unless R is
restarted.


From savicky at cs.cas.cz  Mon May 25 09:04:14 2009
From: savicky at cs.cas.cz (Petr Savicky)
Date: Mon, 25 May 2009 09:04:14 +0200
Subject: [Rd] inconsistency in ?factor
Message-ID: <20090525070414.GA9602@cs.cas.cz>

In the almost current development version (2009-05-22 r48594) and also in 
  https://svn.r-project.org/R/trunk/src/library/base/man/factor.Rd
?factor contains (compare the formulations marked by ^^^^^^)

\section{Warning}{
  The interpretation of a factor depends on both the codes and the
  \code{"levels"} attribute.  Be careful only to compare factors with
  the same set of levels (in the same order).  
                          ^^^^^^^^^^^^^^^^^

\section{Comparison operators and group generic methods}{
  ...

  Only \code{==} and \code{!=} can be used for factors: a factor can
  only be compared to another factor with an identical set of levels
  (not necessarily in the same ordering) or to a character vector.
   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

In the development version 2009-05-22 r48594, the latter formulation
"not necessarily in the same ordering" is correct.

  f1 <- factor(c("a", "b", "c", "c", "b", "a", "a"), levels=c("a", "b", "c"))
  f2 <- factor(c("a", "b", "c", "c", "b", "a", "c"), levels=c("c", "b", "a"))
  f1 == f2 # [1]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE

The first formulation "Be careful to compare ... levels in the same order" may
be just a warning against a potential problem if the levels have different order,
however this is not clear.

Petr.


From berwin at maths.uwa.edu.au  Mon May 25 09:58:06 2009
From: berwin at maths.uwa.edu.au (Berwin A Turlach)
Date: Mon, 25 May 2009 15:58:06 +0800
Subject: [Rd] inconsistency in ?factor
In-Reply-To: <20090525070414.GA9602@cs.cas.cz>
References: <20090525070414.GA9602@cs.cas.cz>
Message-ID: <20090525155806.52c19122@absentia>

G'day Petr,

On Mon, 25 May 2009 09:04:14 +0200
Petr Savicky <savicky at cs.cas.cz> wrote:

> The first formulation "Be careful to compare ... levels in the same
> order" may be just a warning against a potential problem if the
> levels have different order, however this is not clear.

Well, the first statement is a remark on comparison in general while
the second statement is specific to "comparison operators and generic
methods".  There are other ways of comparing objects; note:

R> f1 <- factor(c("a", "b", "c", "c", "b", "a"), levels=c("a", "b", "c"))
R> f2 <- factor(c("a", "b", "c", "c", "b", "a"), levels=c("c", "b", "a"))
R> f1==f2
[1] TRUE TRUE TRUE TRUE TRUE TRUE
R> identical(f1,f2)
[1] FALSE
R> all.equal(f1,f2)
[1] "Attributes: < Component 2: 2 string mismatches >"

Just my 2c.

Cheers,

	Berwin

=========================== Full address =============================
Berwin A Turlach                            Tel.: +65 6516 4416 (secr)
Dept of Statistics and Applied Probability        +65 6516 6650 (self)
Faculty of Science                          FAX : +65 6872 3919       
National University of Singapore     
6 Science Drive 2, Blk S16, Level 7          e-mail: statba at nus.edu.sg
Singapore 117546                    http://www.stat.nus.edu.sg/~statba


From simon.urbanek at r-project.org  Mon May 25 11:19:28 2009
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Mon, 25 May 2009 11:19:28 +0200
Subject: [Rd] [R] step by step debugger in R?
In-Reply-To: <4A1902C9.3000705@dbmail.com>
References: <b1f16d9d0905211600ke8a595ct1971b6e9a560dff4@mail.gmail.com>	<4A167A71.6070601@statistik.tu-dortmund.de>	<b1f16d9d0905220759qbf699b8hc5559b789e0ae43d@mail.gmail.com>
	<4A16C235.9050908@stats.uwo.ca> <4A16E236.1060905@dbmail.com>
	<4A16FBD1.9050909@fhcrc.org> <4A17A6B7.7090404@dbmail.com>
	<4A182A77.1050503@fhcrc.org> <4A1902C9.3000705@dbmail.com>
Message-ID: <5E9E03AF-797D-4CA2-9DD4-B5F8A1D01713@r-project.org>


On May 24, 2009, at 10:18 AM, Romain Francois wrote:

> Robert Gentleman wrote:
>> Hi,
>>  I stripped the cc's as I believe that all read this list.
>>
>> Romain Francois wrote:
>>
>>> [moving this to r-devel]
>>>
>>> Robert Gentleman wrote:
>>>
>>>> Hi,
>>>>
>>>> Romain Francois wrote:
>>>>
>>>>> Duncan Murdoch wrote:
>>>>>
>>>>>> On 5/22/2009 10:59 AM, Michael wrote:
>>>>>>
>>>>>>> Really I think if there is a Visual Studio strength debugger,  
>>>>>>> our
>>>>>>> collective time spent in developing R code will be greatly  
>>>>>>> reduced.
>>>>>>>
>>>>>> If someone who knows how to write a debugger plugin for Eclipse  
>>>>>> wants
>>>>>> to help, we could have that fairly easily.  All the  
>>>>>> infrastructure is
>>>>>> there; it's the UI part that's missing.
>>>>>>
>>>>>> Duncan Murdoch
>>>>>>
>>>>> [I've copied Mark Bravington and Robert Gentleman to the list as  
>>>>> they
>>>>> are likely to have views here, and I am not sure they monitor R- 
>>>>> help]
>>>>>
>>>>> Hello,
>>>>>
>>>>> Making a front-end to debugging was one of the proposed google  
>>>>> summer of
>>>>> code for this year [1], it was not retained eventually, but I am  
>>>>> still
>>>>> motivated.
>>>>>
>>>>> Pretty much all infrastructure is there, and some work has been  
>>>>> done
>>>>> __very recently__ in R's debugging internals (ability to step  
>>>>> up). As I
>>>>> see it, the ability to call some sort of hook each time the  
>>>>> debugger
>>>>> waits for input would make it much easier for someone to write
>>>>>
>>>> I have still not come to an understanding of what this is  
>>>> supposed to
>>>> do? When
>>>> you have the browser prompt you can call any function or code you  
>>>> want
>>>> to. There
>>>> is no need for something special to allow you to do that.
>>>>
>>> Sure. What I have in mind is something that gets __automatically__
>>> called, similar to the task callback but happening right before  
>>> the user
>>> is given the browser prompt.
>>>
>>
>> I am trying to understand the scenario you have in mind. Is it that  
>> the user is
>> running R directly and your debugger is essentially a helper  
>> function that gets
>> updated etc as R runs?
>>
> yes. there are now several ui toolkits that could be use to give  
> some sort of graphical representation of what is being debugged.
>
> I agree with you that and IDE should command R and not the other way  
> around, but I am not (yet) here talking about a fully featured IDE,  
> but simply a debugger.
>
> I need to read more about embedding R (as in section 8 of WRE). I  
> know you can supply your own implementation of the REPL, but I am  
> not sure this includes the one that goes on once trapped into the  
> browser.

Yes - it would be quite useless otherwise ;)  there are many examples  
of GUIs that use it (including the built-in ones [Windows, MAc, ..] or  
external ones e.g JGR).

Cheers,
S


> For example littler ships its own REPL, but this does not seem to  
> fool/deal with browser:
>
> $ r -e "print(1:10); browser(); print(1:5) "
> [1]  1  2  3  4  5  6  7  8  9 10
> Called from: NULL
> c
> [1]  1  2  3  4  5
>
> Not sure this is an omission of Jeffrey and Dirk or something else.
>
>> If so, then I don't think that works very well and given the  
>> constraints we
>> have with R I don't think it will be able to solve many of the  
>> problems that an
>> IDE should.  The hook you want will give you some functionality,  
>> but no where
>> near enough.
>>
>
> In the long run, I do agree. In the short run, I'd prefer taking the  
> bus to the airport rather than walk.
>
>> Let me suggest instead that the IDE should be running the show. It  
>> should
>> initialize an instance of R, but it controls all communication and  
>> hence
>> controls what is rendered on the client side.  If that is what you  
>> mean by
>> embedding R, then yes that is what is needed. There is no way that  
>> I can see to
>> support most of the things that IDE type debuggers support without  
>> the IDE
>> controlling the communication with R.
>>
>> And if I am wrong about what your debugger will look like please  
>> let me know.
>>
>> best wishes
>>   Robert
>>
>>
>>
>>>>> front-ends. A recent post of mine (patch included) [2] on R-devel
>>>>> suggested a custom prompt for browser which would do the trick,  
>>>>> but I
>>>>> now think that a hook would be more appropriate. Without something
>>>>> similar to that, there is no way that I know of for making a  
>>>>> front-end,
>>>>> unless maybe if you embed R ... (please let me know how I am  
>>>>> wrong)
>>>>>
>>>> I think you are wrong. I can't see why it is needed. The external
>>>> debugger has
>>>> lots of options for handling debugging. It can rewrite code (see
>>>> examples in
>>>> trace for how John Chambers has done this to support tracing at a
>>>> location),
>>>> which is AFAIK a pretty standard approach to writing debuggers.  
>>>> It can
>>>> figure
>>>> out where the break point is (made a bit easier by allowing it to  
>>>> put
>>>> in pieces
>>>> of text in the call to browser).  These are things the internal
>>>> debugger can't do.
>>>>
>>>>
>>> Thanks. I'll have another look into that.
>>>
>>>
>>>>> There is also the debug package [3,4] which does __not__ work  
>>>>> with R
>>>>> internals but rather works with instrumenting tricks at the R  
>>>>> level.
>>>>> debug provides a tcl/tk front-end. It is my understanding that  
>>>>> it does
>>>>> not work using R internals (do_browser, ...) because it was not  
>>>>> possible
>>>>> at the time, and I believe this is still not possible today, but  
>>>>> I might
>>>>> be wrong. I'd prefer to be wrong actually.
>>>>>
>>>>  I don't understand this statement. It has always been possible to
>>>> work with
>>>> the internal version - but one can also take the approach of  
>>>> rewriting
>>>> code.
>>>> There are some difficulties supporting all the operations that one
>>>> would like by
>>>> rewriting code and I think a combination of external controls and  
>>>> the
>>>> internal
>>>> debugger will get most of the functionality that anyone wants.
>>>>
>>>>  There are somethings that are hard and once I have a more complete
>>>> list I will
>>>> be adding this to the appropriate manual. I will also be  
>>>> documenting
>>>> the changes
>>>> that I have been making, but that project is in flux and won't be  
>>>> done
>>>> until the
>>>> end of August, so people who want to look at it are welcome (it  
>>>> is in
>>>> R-devel),
>>>> but it is in development and could change pretty much without  
>>>> notice.
>>>>  Romain noted that we now support stepping out from one place to  
>>>> another
>>>> function.  We also have a debugonce flag that lets you get close to
>>>> step in, but
>>>> step in is very hard in R.
>>>>
>>>>  I am mostly interested in writing tools in R that can be used by
>>>> anyone that
>>>> wants to write an external debugger and am not that interested in  
>>>> any
>>>> particular
>>>> external debugger. I would be happy to listen to feature requests  
>>>> or
>>>> issues that
>>>> arise - but the discussion should probably be on R-devel mailing  
>>>> list.
>>>>
>>>>  best wishes
>>>>    Robert
>>>>
>>>>
>>>>
>>>>> Romain
>>>>>
>>>>> [1] : http://www.r-project.org/soc09/ideas.html#p5
>>>>> [2] : https://stat.ethz.ch/pipermail/r-devel/2009-April/ 
>>>>> 053128.html
>>>>> [3] : http://cran.r-project.org/web/packages/debug/index.html
>>>>> [4] : http://cran.r-project.org/doc/Rnews/Rnews_2003-3.pdf
>>>>>
>>>>>
>>>>
>>>
>>
>>
>
>
> -- 
> Romain Francois
> Independent R Consultant
> +33(0) 6 28 91 30 30
> http://romainfrancois.blog.free.fr
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From savicky at cs.cas.cz  Mon May 25 12:27:17 2009
From: savicky at cs.cas.cz (Petr Savicky)
Date: Mon, 25 May 2009 12:27:17 +0200
Subject: [Rd] inconsistency in ?factor
In-Reply-To: <20090525155806.52c19122@absentia>
References: <20090525070414.GA9602@cs.cas.cz>
	<20090525155806.52c19122@absentia>
Message-ID: <20090525102717.GA30112@cs.cas.cz>

On Mon, May 25, 2009 at 03:58:06PM +0800, Berwin A Turlach wrote:
> Well, the first statement is a remark on comparison in general while
> the second statement is specific to "comparison operators and generic
> methods".  There are other ways of comparing objects; note:
> 
> R> f1 <- factor(c("a", "b", "c", "c", "b", "a"), levels=c("a", "b", "c"))
> R> f2 <- factor(c("a", "b", "c", "c", "b", "a"), levels=c("c", "b", "a"))
> R> f1==f2
> [1] TRUE TRUE TRUE TRUE TRUE TRUE
> R> identical(f1,f2)
> [1] FALSE
> R> all.equal(f1,f2)
> [1] "Attributes: < Component 2: 2 string mismatches >"

I see. We have to distinguish comparison of the objects and their components.

Let me propose the following formulation
  Two factors may be identical only if they have the same set of
  levels (in the same order).
instead of
  Be careful only to compare factors with the same set of
  levels (in the same order).

Petr.


From maechler at stat.math.ethz.ch  Mon May 25 14:15:23 2009
From: maechler at stat.math.ethz.ch (maechler at stat.math.ethz.ch)
Date: Mon, 25 May 2009 14:15:23 +0200 (CEST)
Subject: [Rd] qbinom (PR#13711)
Message-ID: <20090525121523.9EB0A282C765@mail.pubhealth.ku.dk>

>>>>> "PS" == Petr Savicky <savicky at cs.cas.cz>
>>>>>     on Sat, 23 May 2009 18:22:26 +0200 writes:

    PS> On Wed, May 20, 2009 at 11:10:11PM +0200, wolfgang.resch at gmail.com wrote:
    PS> ...
    >> Strange behavior of qbinom:
    >> 
    >> > qbinom(0.01, 5016279, 1e-07)
    >> [1] 0
    >> > qbinom(0.01, 5016279, 2e-07)
    >> [1] 16
    >> > qbinom(0.01, 5016279, 3e-07)
    >> [1] 16
    >> > qbinom(0.01, 5016279, 4e-07)
    >> [1] 16
    >> > qbinom(0.01, 5016279, 5e-07)
    >> [1] 0
    >> 

    PS> There is a bug in function do_search() in file src/nmath/qbinom.c. This
    PS> function contains a cycle
    PS> for(;;) {
    PS>   if(y == 0 ||
    PS>   (*z = pbinom(y - incr, n, pr, /*l._t.*/TRUE, /*log_p*/FALSE)) < p)
    PS>   return y;
    PS>   y = fmax2(0, y - incr);
    PS> }
    PS> When this cycle stops, *z contains pbinom(y - incr, ...), but is used
    PS> as if it is pbinom(y, ...) for the resulting y.

    PS> In the example qbinom(p=0.01, size=5016279, prob=4e-07), we get at 
    PS> some step y=15 as a result of a search left with incr=50, so we have
    PS> *z=pbinom(-35, ...)=0. Hence, y=15 is treated as too low and is increased
    PS> to 16. Since 16 is detected to be sufficient, the search stops with y=16,
    PS> which is wrong.

    [............]

Thanks to Wolfgang and Petr,

Petr's analysis of the problem seems right on spot to me,
and I'm currently testing the patch (and will also add some
regression tests along Petr's example)
which will make it into R-patched (to be R 2.9.1 in a while) and
R-devel.

Gratefully,
Martin Maechler, ETH Zurich


From ripley at stats.ox.ac.uk  Mon May 25 14:32:23 2009
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 25 May 2009 13:32:23 +0100 (BST)
Subject: [Rd] (PR#13705)  [wishlist,
 patch] make row() and col() preserve dimnames
In-Reply-To: <20090517215012.ECE2D28320A7@mail.pubhealth.ku.dk>
References: <20090517215012.ECE2D28320A7@mail.pubhealth.ku.dk>
Message-ID: <alpine.LFD.2.00.0905191059040.23025@toucan.stats.ox.ac.uk>

On Sun, 17 May 2009, goodrich at fas.harvard.edu wrote:

> Full_Name: Ben Goodrich
> Version: 2.9.0
> OS: Linux (Debian unstable)
> Submission from: (NULL) (128.103.220.16)
>
>
> row(x), col(x), and functions that call them like lower.tri(x) and 
> upper.tri(x) do not retain the rownames or colnames of x in the 
> matrix that is returned. Example from R version 2.9.0 :
>
> x <- matrix(1:9, nrow = 3, ncol = 3)
> rownames(x) <- LETTERS[1:3]
> colnames(x) <- letters[1:3]
>
> dimnames(row(x)) # NULL
> dimnames(col(x)) # NULL
>
> Is there anyone for whom the expected behavior is to drop the 
> dimnames of x ? It is not consistent with other functions of 
> matrices.

I suspect everyone who reads the help page carefully.

This is not a 'function of a matrix' x but of dim(x) for a 
'matrix-like' object.  The help page makes this clear to me (I am not 
the author), so I think you have misread it.  There is no question of 
'drop the dimames' nor 'retaining the rownames': it is a new object, 
an integer matrix whatever x was.

These functions are mainly for use in programming, and need to be 
efficient -- so adding dimnames that will never be needed by all the 
existing code is a non-trivial overhead.

> By default, row(x) already
> returns the row numbers of x (and similarly for col()), so how would seeing
> integers in the rownames be helpful?
>
> Without patch:
>> row(x)
>     [,1] [,2] [,3]
> [1,]    1    1    1
> [2,]    2    2    2
> [3,]    3    3    3
>
> With patch:
>> row(x)
>  a b c
> A 1 1 1
> B 2 2 2
> C 3 3 3
>
> Patch:
> Index: src/library/base/R/matrix.R
> ===================================================================
> --- src/library/base/R/matrix.R (revision 48553)
> +++ src/library/base/R/matrix.R (working copy)
> @@ -104,8 +104,9 @@
>         labs <- rownames(x, do.NULL=FALSE, prefix="")
>         res <- factor(.Internal(row(dim(x))), labels=labs)
>         dim(res) <- dim(x)
> -        res
> -    } else .Internal(row(dim(x)))
> +    } else res <- .Internal(row(dim(x)))
> +    dimnames(res) <- dimnames(x)
> +    res
> }

Lots of issues here: dimnames() is generic and may not be compatible 
with the object produced, so checks are needed.  And for efficiency 
this should be done in the C-level code that creates the object if 
done at all.

> col <- function(x, as.factor=FALSE)
> @@ -114,8 +115,9 @@
>         labs <- colnames(x, do.NULL=FALSE, prefix="")
>         res <- factor(.Internal(col(dim(x))), labels=labs)
>         dim(res) <- dim(x)
> -        res
> -    } else .Internal(col(dim(x)))
> +    } else res <- .Internal(col(dim(x)))
> +    dimnames(res) <- dimnames(x)
> +    res
> }
>
> crossprod <- function(x, y=NULL) .Internal(crossprod(x,y))
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From romain.francois at dbmail.com  Mon May 25 16:54:26 2009
From: romain.francois at dbmail.com (Romain Francois)
Date: Mon, 25 May 2009 16:54:26 +0200
Subject: [Rd] [R] step by step debugger in R?
In-Reply-To: <5E9E03AF-797D-4CA2-9DD4-B5F8A1D01713@r-project.org>
References: <b1f16d9d0905211600ke8a595ct1971b6e9a560dff4@mail.gmail.com>	<4A167A71.6070601@statistik.tu-dortmund.de>	<b1f16d9d0905220759qbf699b8hc5559b789e0ae43d@mail.gmail.com>
	<4A16C235.9050908@stats.uwo.ca> <4A16E236.1060905@dbmail.com>
	<4A16FBD1.9050909@fhcrc.org> <4A17A6B7.7090404@dbmail.com>
	<4A182A77.1050503@fhcrc.org> <4A1902C9.3000705@dbmail.com>
	<5E9E03AF-797D-4CA2-9DD4-B5F8A1D01713@r-project.org>
Message-ID: <4A1AB122.2080402@dbmail.com>

Simon Urbanek wrote:
>
> [snip]
>>
>> I need to read more about embedding R (as in section 8 of WRE). I 
>> know you can supply your own implementation of the REPL, but I am not 
>> sure this includes the one that goes on once trapped into the browser.
>
> Yes - it would be quite useless otherwise ;)  there are many examples 
> of GUIs that use it (including the built-in ones [Windows, MAc, ..] or 
> external ones e.g JGR).
>
> Cheers,
> S
>
Hi Simon,

Do you mean the rReadConsole callback ? I managed to make some minor 
modifications to the rtest.java example that comes with JRI to somewhat 
emulate automatically call some code (ls.str()) in this example at the 
browser prompt, before giving the prompt to the user.

    static boolean browse_first = true ;  
      public String rReadConsole(Rengine re, String prompt, int 
addToHistory) {
        System.out.print(prompt);
                if( prompt.startsWith( "Browse[") ){
                        if( browse_first ){
                            System.out.println( "\n>>>> re.eval( \" 
print( ls.str() )\" ); " ) ;
                            re.eval( "print( ls.str() )" ) ;
                            browse_first = false ;
                            System.out.println( "\n>>>> return 
\"ls.str()\"" ) ;
                            return "ls.str()\n" ;
                        } else{
                            browse_first = true ;
                        }
                       
                }
...
}

It seems to work and could get me somewhere, although it has a "it 
works, but it does not feel right" taste. Basically the code pretends 
the user typed "ls.str\n" at the browse prompt, so that the R evaluator 
evaluates it, and then comes back to the browse prompt.

There is also the re.eval( "print( ls.str() )" ) part which was my first 
attempt, but apparently this gets evaluated in the global environment, 
which is no good. I can get around that by returning some sort of 
"record the sys.frames and sys.calls somewhere and do something with 
them" function, but I was wondering if you meant something else.

Romain

Here is the transcript of a simple session of ./run rtest (with the 
small adjustement above)

 > f <- function( x= 5) browser()
rBusy(1)
rBusy(0)
 > f()
rBusy(1)
Called from: f()
rBusy(0)
Browse[1]>
 >>>> re.eval( " print( ls.str() )" );
a :  chr "hello"
b : 'data.frame':    3 obs. of  2 variables:
 $ a: num  1.2 2.3 4.5
 $ b: num  1.4 2.6 4.2
bool :  logi [1:3] TRUE FALSE FALSE
f : function (x = 5) 
iris : 'data.frame':    150 obs. of  5 variables:
 $ Sepal.Length: num  5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...
 $ Sepal.Width : num  3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...
 $ Petal.Length: num  1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...
 $ Petal.Width : num  0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...
 $ Species     : Factor w/ 3 levels "setosa","versicolor",..: 1 1 1 1 1 
1 1 1 1 1 ...

 >>>> return "ls.str()"
rBusy(1)
x :  num 5
rBusy(0)
Browse[1]>
rBusy(0)
 >



-- 
Romain Francois
Independent R Consultant
+33(0) 6 28 91 30 30
http://romainfrancois.blog.free.fr


From maechler at stat.math.ethz.ch  Mon May 25 17:08:11 2009
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 25 May 2009 17:08:11 +0200
Subject: [Rd] "interpolator constructor";  was "Scope problem?"
In-Reply-To: <d8ad40b50905220928p5235b38fi69361e4c7f7cd91d@mail.gmail.com>
References: <d8ad40b50905220928p5235b38fi69361e4c7f7cd91d@mail.gmail.com>
Message-ID: <18970.46171.458268.471243@lynne.math.ethz.ch>

Hi Barry,

this is just a side-remark, probably not at all something you
were interested in, but to be put along this thread in the list
archives, in case some readers are side-tracked there ...

>>>>> "BaRow" == Barry Rowlingson <b.rowlingson at lancaster.ac.uk>
>>>>>     on Fri, 22 May 2009 17:28:42 +0100 writes:

    BaRow> I've just spent today trying to fix a Heisenbug...
    BaRow> this function returns a linear interpolator function:

    BaRow> interpOne <- function(xl,yl){
    BaRow> f = function(data){
    BaRow> t = (data-min(xl))/(max(xl)-min(xl))
    BaRow> return(min(yl)+t*(max(yl)-min(yl)))
    BaRow> }
    BaRow> return(f)
    BaRow> }

    >> k=interpOne(c(0,1),c(4,5))
    >> k(0.5)
    BaRow> [1] 4.5

Note that "base R" has already two such functions,
namely	  
	  splinefun() 
and       approxfun(),
both returning a *function* as in your examples.

Best,
Martin Maechler, ETH Zurich

    BaRow> and this function uses the above to return a function that returns a
    BaRow> piece-wise linear interpolator function:

    BaRow> mr <- function(){
    BaRow> parts = list()
    BaRow> ranges =  rbind(c(0,1),c(1,2),c(2,3))
    BaRow> domains = rbind(c(3,4),c(5,6),c(2,8))
    BaRow> for(i in 1:length(ranges[,1])){
    BaRow> parts[[i]] = interpOne(ranges[i,],domains[i,])
    BaRow> }

    BaRow> f = function(d){
    BaRow> pos = sum(d>ranges[,1])
    BaRow> cat("using pos = ",pos,"\n")
    BaRow> return(parts[[pos]](d))
    BaRow> }
    BaRow> return(f)
    BaRow> }

    BaRow> m = mr()

    BaRow> The 'ranges' and 'domains' vectors describe the pieces. But this doesn't work:
    >> m(0.5)
    BaRow> using pos =  1
    BaRow> [1] -7

    BaRow> - but it should be 3.5 (since 0.5 is in the first piece, and that
    BaRow> then interpolates between 3 and 4). What about the other pieces:

    >> m(1.5)
    BaRow> using pos =  2
    BaRow> [1] -1
    >> m(2.5)
    BaRow> using pos =  3
    BaRow> [1] 5

    BaRow> - which looks like it's using the last set of range/domain pairs each
    BaRow> time. Curious, I thought.

    BaRow> So I thought I'd evaluate the functions as they are created in the
    BaRow> list to see what's going on. Change the loop to print out:

    BaRow> for(i in 1:length(ranges[,1])){
    BaRow> parts[[i]] = interpOne(ranges[i,],domains[i,])
    BaRow> cat("part ",i," at zero = ",parts[[i]](0),"\n")
    BaRow> }

    BaRow> and try:

    >> m=mr()
    BaRow> part  1  at zero =  3
    BaRow> part  2  at zero =  4
    BaRow> part  3  at zero =  -10

    BaRow> looks good, those are the intercepts of my pieces... but now:

    >> m(0.5)
    BaRow> using pos =  1
    BaRow> [1] 3.5
    >> m(1.5)
    BaRow> using pos =  2
    BaRow> [1] 5.5
    >> m(2.5)
    BaRow> using pos =  3
    BaRow> [1] 5

    BaRow> Woah! It's now working!  Trying to observe the thing changes it? A Heisenbug!

    BaRow> I can only think it's my misunderstanding of some aspect of R's
    BaRow> scoping and evaluation rules. Does evaluating the functions within
    BaRow> that loop cause a copy of some environment to be made, or a 'lazy
    BaRow> evaluation' to be evaluated? Or a 'promise' to be fulfilled? I don't
    BaRow> really understand those terms, I'd just hoped functions ran in the
    BaRow> environment they were created in. Seems sometimes they do, sometimes
    BaRow> they dont... What's going on?

    BaRow> R 2.9.0 on Ubuntu.

    BaRow> Barry

    BaRow> ______________________________________________
    BaRow> R-devel at r-project.org mailing list
    BaRow> https://stat.ethz.ch/mailman/listinfo/r-devel


From simon.urbanek at r-project.org  Mon May 25 17:31:52 2009
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Mon, 25 May 2009 17:31:52 +0200
Subject: [Rd] [R] step by step debugger in R?
In-Reply-To: <4A1AB122.2080402@dbmail.com>
References: <b1f16d9d0905211600ke8a595ct1971b6e9a560dff4@mail.gmail.com>	<4A167A71.6070601@statistik.tu-dortmund.de>	<b1f16d9d0905220759qbf699b8hc5559b789e0ae43d@mail.gmail.com>
	<4A16C235.9050908@stats.uwo.ca> <4A16E236.1060905@dbmail.com>
	<4A16FBD1.9050909@fhcrc.org> <4A17A6B7.7090404@dbmail.com>
	<4A182A77.1050503@fhcrc.org> <4A1902C9.3000705@dbmail.com>
	<5E9E03AF-797D-4CA2-9DD4-B5F8A1D01713@r-project.org>
	<4A1AB122.2080402@dbmail.com>
Message-ID: <8AEACE3D-8B20-4741-AAE2-8C7A0A21D30F@r-project.org>


On May 25, 2009, at 4:54 PM, Romain Francois wrote:

> Simon Urbanek wrote:
>>
>> [snip]
>>>
>>> I need to read more about embedding R (as in section 8 of WRE). I  
>>> know you can supply your own implementation of the REPL, but I am  
>>> not sure this includes the one that goes on once trapped into the  
>>> browser.
>>
>> Yes - it would be quite useless otherwise ;)  there are many  
>> examples of GUIs that use it (including the built-in ones [Windows,  
>> MAc, ..] or external ones e.g JGR).
>>
>> Cheers,
>> S
>>
> Hi Simon,
>
> Do you mean the rReadConsole callback ? I managed to make some minor  
> modifications to the rtest.java example that comes with JRI to  
> somewhat emulate automatically call some code (ls.str()) in this  
> example at the browser prompt, before giving the prompt to the user.
>
>   static boolean browse_first = true ;       public String  
> rReadConsole(Rengine re, String prompt, int addToHistory) {
>       System.out.print(prompt);
>               if( prompt.startsWith( "Browse[") ){
>                       if( browse_first ){
>                           System.out.println( "\n>>>> re.eval( \"  
> print( ls.str() )\" ); " ) ;
>                           re.eval( "print( ls.str() )" ) ;
>                           browse_first = false ;
>                           System.out.println( "\n>>>> return  
> \"ls.str()\"" ) ;
>                           return "ls.str()\n" ;
>                       } else{
>                           browse_first = true ;
>                       }
>                                     }
> ...
> }
>
> It seems to work and could get me somewhere, although it has a "it  
> works, but it does not feel right" taste. Basically the code  
> pretends the user typed "ls.str\n" at the browse prompt, so that the  
> R evaluator evaluates it, and then comes back to the browse prompt.
>
> There is also the re.eval( "print( ls.str() )" ) part which was my  
> first attempt, but apparently this gets evaluated in the global  
> environment, which is no good. I can get around that by returning  
> some sort of "record the sys.frames and sys.calls somewhere and do  
> something with them" function, but I was wondering if you meant  
> something else.
>

Well, it's entirely up to you - the REPL is working. I wasn't  
suggesting you have to use JRI for the debugger, I was just pointing  
out that browsing is treated as a regular prompt on the REPL, so any  
embedding has access to it.
The JRI eval() command has nothing to do with this directly - you can  
evaluate in any environment, just not specifying anything will throw  
you in the global environment - it's really up to you (it just  
abstracts out the direct access to parse and eval part of R - you can  
(ab)use it any way you see fit).

Cheers,
Simon


> Romain
>
> Here is the transcript of a simple session of ./run rtest (with the  
> small adjustement above)
>
> > f <- function( x= 5) browser()
> rBusy(1)
> rBusy(0)
> > f()
> rBusy(1)
> Called from: f()
> rBusy(0)
> Browse[1]>
> >>>> re.eval( " print( ls.str() )" );
> a :  chr "hello"
> b : 'data.frame':    3 obs. of  2 variables:
> $ a: num  1.2 2.3 4.5
> $ b: num  1.4 2.6 4.2
> bool :  logi [1:3] TRUE FALSE FALSE
> f : function (x = 5) iris : 'data.frame':    150 obs. of  5 variables:
> $ Sepal.Length: num  5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...
> $ Sepal.Width : num  3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...
> $ Petal.Length: num  1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...
> $ Petal.Width : num  0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...
> $ Species     : Factor w/ 3 levels "setosa","versicolor",..: 1 1 1 1  
> 1 1 1 1 1 1 ...
>
> >>>> return "ls.str()"
> rBusy(1)
> x :  num 5
> rBusy(0)
> Browse[1]>
> rBusy(0)
> >
>
>
>
> -- 
> Romain Francois
> Independent R Consultant
> +33(0) 6 28 91 30 30
> http://romainfrancois.blog.free.fr
>
>
>


From romain.francois at dbmail.com  Mon May 25 17:39:01 2009
From: romain.francois at dbmail.com (Romain Francois)
Date: Mon, 25 May 2009 17:39:01 +0200
Subject: [Rd] [R] step by step debugger in R?
In-Reply-To: <8AEACE3D-8B20-4741-AAE2-8C7A0A21D30F@r-project.org>
References: <b1f16d9d0905211600ke8a595ct1971b6e9a560dff4@mail.gmail.com>	<4A167A71.6070601@statistik.tu-dortmund.de>	<b1f16d9d0905220759qbf699b8hc5559b789e0ae43d@mail.gmail.com>
	<4A16C235.9050908@stats.uwo.ca> <4A16E236.1060905@dbmail.com>
	<4A16FBD1.9050909@fhcrc.org> <4A17A6B7.7090404@dbmail.com>
	<4A182A77.1050503@fhcrc.org> <4A1902C9.3000705@dbmail.com>
	<5E9E03AF-797D-4CA2-9DD4-B5F8A1D01713@r-project.org>
	<4A1AB122.2080402@dbmail.com>
	<8AEACE3D-8B20-4741-AAE2-8C7A0A21D30F@r-project.org>
Message-ID: <4A1ABB95.7010104@dbmail.com>

Simon Urbanek wrote:
>
>
> On May 25, 2009, at 4:54 PM, Romain Francois wrote:
>
>> Simon Urbanek wrote:
>>>
>>> [snip]
>>>>
>>>> I need to read more about embedding R (as in section 8 of WRE). I 
>>>> know you can supply your own implementation of the REPL, but I am 
>>>> not sure this includes the one that goes on once trapped into the 
>>>> browser.
>>>
>>> Yes - it would be quite useless otherwise ;)  there are many 
>>> examples of GUIs that use it (including the built-in ones [Windows, 
>>> MAc, ..] or external ones e.g JGR).
>>>
>>> Cheers,
>>> S
>>>
>> Hi Simon,
>>
>> Do you mean the rReadConsole callback ? I managed to make some minor 
>> modifications to the rtest.java example that comes with JRI to 
>> somewhat emulate automatically call some code (ls.str()) in this 
>> example at the browser prompt, before giving the prompt to the user.
>>
>>   static boolean browse_first = true ;       public String 
>> rReadConsole(Rengine re, String prompt, int addToHistory) {
>>       System.out.print(prompt);
>>               if( prompt.startsWith( "Browse[") ){
>>                       if( browse_first ){
>>                           System.out.println( "\n>>>> re.eval( \" 
>> print( ls.str() )\" ); " ) ;
>>                           re.eval( "print( ls.str() )" ) ;
>>                           browse_first = false ;
>>                           System.out.println( "\n>>>> return 
>> \"ls.str()\"" ) ;
>>                           return "ls.str()\n" ;
>>                       } else{
>>                           browse_first = true ;
>>                       }
>>                                     }
>> ...
>> }
>>
>> It seems to work and could get me somewhere, although it has a "it 
>> works, but it does not feel right" taste. Basically the code pretends 
>> the user typed "ls.str\n" at the browse prompt, so that the R 
>> evaluator evaluates it, and then comes back to the browse prompt.
>>
>> There is also the re.eval( "print( ls.str() )" ) part which was my 
>> first attempt, but apparently this gets evaluated in the global 
>> environment, which is no good. I can get around that by returning 
>> some sort of "record the sys.frames and sys.calls somewhere and do 
>> something with them" function, but I was wondering if you meant 
>> something else.

Thank you for these comments. It confirms what I was thinking.

>
> Well, it's entirely up to you - the REPL is working. I wasn't 
> suggesting you have to use JRI for the debugger, I was just pointing 
> out that browsing is treated as a regular prompt on the REPL, so any 
> embedding has access to it.

I understand that. It was the quickest way for me to get an example 
going. java/JRI is one option, but there are others (Qt, ...)

> The JRI eval() command has nothing to do with this directly - you can 
> evaluate in any environment, just not specifying anything will throw 
> you in the global environment - it's really up to you (it just 
> abstracts out the direct access to parse and eval part of R - you can 
> (ab)use it any way you see fit).

... and I surely will.

Romain

>
> Cheers,
> Simon
>
>
>> Romain
>>
>> Here is the transcript of a simple session of ./run rtest (with the 
>> small adjustement above)
>>
>> > f <- function( x= 5) browser()
>> rBusy(1)
>> rBusy(0)
>> > f()
>> rBusy(1)
>> Called from: f()
>> rBusy(0)
>> Browse[1]>
>> >>>> re.eval( " print( ls.str() )" );
>> a :  chr "hello"
>> b : 'data.frame':    3 obs. of  2 variables:
>> $ a: num  1.2 2.3 4.5
>> $ b: num  1.4 2.6 4.2
>> bool :  logi [1:3] TRUE FALSE FALSE
>> f : function (x = 5) iris : 'data.frame':    150 obs. of  5 variables:
>> $ Sepal.Length: num  5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...
>> $ Sepal.Width : num  3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...
>> $ Petal.Length: num  1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...
>> $ Petal.Width : num  0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...
>> $ Species     : Factor w/ 3 levels "setosa","versicolor",..: 1 1 1 1 
>> 1 1 1 1 1 1 ...
>>
>> >>>> return "ls.str()"
>> rBusy(1)
>> x :  num 5
>> rBusy(0)
>> Browse[1]>
>> rBusy(0)
>> >
>>
>>
>>
>> -- 
>> Romain Francois
>> Independent R Consultant
>> +33(0) 6 28 91 30 30
>> http://romainfrancois.blog.free.fr
>>
>>
>>
>
>
>


-- 
Romain Francois
Independent R Consultant
+33(0) 6 28 91 30 30
http://romainfrancois.blog.free.fr


From ba208 at exeter.ac.uk  Mon May 25 15:11:46 2009
From: ba208 at exeter.ac.uk (baptiste auguie)
Date: Mon, 25 May 2009 15:11:46 +0200
Subject: [Rd] Fwd: [R] size of point symbols
References: <119525F2-0C93-40B5-A219-2456793692ED@exeter.ac.uk>
Message-ID: <D0ABBB0D-0421-4B51-ABDF-90E2FD0FBB7B@exeter.ac.uk>

Dear all,


Having received no answer in r-help I'm trying r-devel (hoping this is  
not a stupid question).

I don't understand the rationale behind the absolute sizes of the point
symbols, and I couldn't find it documented (I got lost in the C code  
graphics.c and gave up). The example below uses
Grid to check the size of the symbols against a square of 10mm x 10mm.

> checkOneSymbol <- function(pch=0){
>    gTree(children=gList(
>        rectGrob(0.5, 0.5, width=unit(10, "mm"), height=unit(10,
> "mm"),
>                gp=gpar(lty=2, fill=NA, col=alpha("black", 0.5))),
>    pointsGrob(0.5, 0.5, size=unit(10, "mm"),pch=pch,
>        gp=gpar(col=alpha("red", 0.5)))
>    ))
>
> }
> all.symbols <- lapply(0:23, checkOneSymbol)
>
> pdf("symbols.pdf", height=1.2/2.54, width=24.2/2.54)
>
> vp <- viewport(width=0.5, height=0.5, name="main")
> pushViewport(vp)
>
> pushViewport(viewport(layout=grid.layout(1, 24,
>                        widths=unit(10, "mm"),
>                        heights=unit(10, "mm"),
>                        just="center")))
>
> for(ii in 0:23){
> pushViewport(viewport(layout.pos.col=ii+1, layout.pos.row=1))
> grid.draw(all.symbols[[ii+1]])
> upViewport(1)
> }
> dev.off()


What dictates the size of each symbol? (in other words, why is pch=21
a circle of radius given in inches, while pch=2 is a triangle of base
length specified  in mm and offset vertically?, etc.)

I'm trying to develop a new symbol for the ggplot2 package where the  
size is to be accurately mapped onto the data either in linear size or  
area. I was expecting a similar idea behind the choice of base  
symbols. Is this documented?

Best regards,

baptiste

_____________________________

Baptiste Augui?

School of Physics
University of Exeter
Stocker Road,
Exeter, Devon,
EX4 4QL, UK

Phone: +44 1392 264187

http://newton.ex.ac.uk/research/emag


From dpkesling at juno.com  Mon May 25 18:00:08 2009
From: dpkesling at juno.com (dpkesling at juno.com)
Date: Mon, 25 May 2009 18:00:08 +0200 (CEST)
Subject: [Rd] Vista authorization issues (PR#13718)
Message-ID: <20090525160008.E0D23282BE82@mail.pubhealth.ku.dk>

Full_Name: David Kesling
Version: 2.9.0
OS: Windows Vista & XP sp2
Submission from: (NULL) (65.166.169.237)


I upgraded to 2.9.0 on my desktop (XP) and my laptop (Vista Home Basic). The XP
machine (with both Tinn-R and JGR) is running just fine... very happy. The
laptop is NOT doing too well. I've had to activate the XP-compatability mode AND
run Rgui as administrator... and there still seem to be issues. Tinn-R, even
after reinstallation, will not properly communicate with Rgui. JGR can't even
FIND R 2.9.

Again, 2.9 seems to run fine under XP and, with much struggling, under Vista.
But registry issues on the Vista platform have broken Tinn-R and JGR IDEs.


From ripley at stats.ox.ac.uk  Tue May 26 08:35:42 2009
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 26 May 2009 07:35:42 +0100 (BST)
Subject: [Rd] Fwd: [R] size of point symbols
In-Reply-To: <D0ABBB0D-0421-4B51-ABDF-90E2FD0FBB7B@exeter.ac.uk>
References: <119525F2-0C93-40B5-A219-2456793692ED@exeter.ac.uk>
	<D0ABBB0D-0421-4B51-ABDF-90E2FD0FBB7B@exeter.ac.uk>
Message-ID: <alpine.LFD.2.00.0905260711260.7401@gannet.stats.ox.ac.uk>

I don't know where you get your claims from.  R graphics is handled 
internally in inches, with a device-specific mapping to pixels/points 
etc (which is documented for each device on its help page).  This has 
to be done carefully, as pixels may not be square.

What the meaning of pch=1:23 is in terms of coordinates is not 
documented except via the sources.  The source is function GESymbol in 
file src/main/engine.c, so for example pch = 2 is

 	case 2:	/* S triangle - point up */
 	    xc = RADIUS * GSTR_0;
 	    r = toDeviceHeight(TRC0 * xc, GE_INCHES, dd);
 	    yc = toDeviceHeight(TRC2 * xc, GE_INCHES, dd);
 	    xc = toDeviceWidth(TRC1 * xc, GE_INCHES, dd);
 	    xx[0] = x; yy[0] = y+r;
 	    xx[1] = x+xc; yy[1] = y-yc;
 	    xx[2] = x-xc; yy[2] = y-yc;
 	    gc->fill = R_TRANWHITE;
 	    GEPolygon(3, xx, yy, gc, dd);
 	    break;

which as you see is in inches, not mm as you asserted.  The first line 
sets xc to 0.375 inches for cex=1, for example.

You need to take the stroke width (as set by lty) into account when 
assessing the visual size of symbols

On Mon, 25 May 2009, baptiste auguie wrote:

> Dear all,
>
>
> Having received no answer in r-help I'm trying r-devel (hoping this is not a 
> stupid question).
>
> I don't understand the rationale behind the absolute sizes of the point
> symbols, and I couldn't find it documented (I got lost in the C code 
> graphics.c and gave up).

You are expected to study the sources for yourself.  That's part of 
the price of R.

There is a manual, 'R Internals', that would have explained to you 
that graphics.c is part of base graphics and hence not of grid 
graphics.

> The example below uses
> Grid to check the size of the symbols against a square of 10mm x 10mm.
>
>> checkOneSymbol <- function(pch=0){
>>   gTree(children=gList(
>>       rectGrob(0.5, 0.5, width=unit(10, "mm"), height=unit(10,
>> "mm"),
>>               gp=gpar(lty=2, fill=NA, col=alpha("black", 0.5))),
>>   pointsGrob(0.5, 0.5, size=unit(10, "mm"),pch=pch,
>>       gp=gpar(col=alpha("red", 0.5)))
>>   ))
>> 
>> }
>> all.symbols <- lapply(0:23, checkOneSymbol)
>> 
>> pdf("symbols.pdf", height=1.2/2.54, width=24.2/2.54)
>> 
>> vp <- viewport(width=0.5, height=0.5, name="main")
>> pushViewport(vp)
>> 
>> pushViewport(viewport(layout=grid.layout(1, 24,
>>                       widths=unit(10, "mm"),
>>                       heights=unit(10, "mm"),
>>                       just="center")))
>> 
>> for(ii in 0:23){
>> pushViewport(viewport(layout.pos.col=ii+1, layout.pos.row=1))
>> grid.draw(all.symbols[[ii+1]])
>> upViewport(1)
>> }
>> dev.off()
>
>
> What dictates the size of each symbol? (in other words, why is pch=21
> a circle of radius given in inches, while pch=2 is a triangle of base
> length specified  in mm and offset vertically?, etc.)
>
> I'm trying to develop a new symbol for the ggplot2 package where the size is 
> to be accurately mapped onto the data either in linear size or area. I was 
> expecting a similar idea behind the choice of base symbols. Is this 
> documented?
>
> Best regards,
>
> baptiste
>
> _____________________________
>
> Baptiste Augui?
>
> School of Physics
> University of Exeter
> Stocker Road,
> Exeter, Devon,
> EX4 4QL, UK
>
> Phone: +44 1392 264187
>
> http://newton.ex.ac.uk/research/emag
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From ripley at stats.ox.ac.uk  Tue May 26 10:11:30 2009
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 26 May 2009 09:11:30 +0100 (BST)
Subject: [Rd] plot ignores type= "n" when x is factor (PR#13703)
In-Reply-To: <20090514193515.9BC3528320DF@mail.pubhealth.ku.dk>
References: <20090514193515.9BC3528320DF@mail.pubhealth.ku.dk>
Message-ID: <alpine.LFD.2.00.0905260852140.22101@gannet.stats.ox.ac.uk>

On Thu, 14 May 2009, pauljohn at ku.edu wrote:

> Full_Name: Paul E. Johnson
> Version: 2.9.1

Where did you get that?  Time travel?

> OS: Linux (Ubuntu 9.04)
> Submission from: (NULL) (129.237.61.25)
>
>
> x <- gl(2,50)
> y <- rnorm(100)
> plot(x,y)
> plot(x,y, type="n")
>
>
> I *wish* the last one would draw a blank plot box w/axes, but it does not. It
> fills in the middle with a box plot. I've not seen this problem when x is
> numeric.

Because this is a call to the 'factor' (see ?plot.factor).  Although 
?plot says

      ...: Arguments to be passed to methods, such as graphical
           parameters (see 'par'). Many methods will accept the
           following arguments:

           'type' what type of plot should be drawn.  Possible types are

'many' does not mean 'all' and all the other values of 'type' would be 
inappropriate for plot.factor.  Note that plot.factor is a wrapper for 
a call to barplot(), spineplot() or (in your case) boxplot(), which do 
not take a 'type' argument.

If plot.factor() or barplot() or boxplot() allowed a 'type' argument, 
what value would be appropriate to give the usual plot?  Not as far as 
I can see any of those listed in ?plot, and that says all other values 
are errors.


So, this is not a bug, it was not marked for the wishlist (see the R 
FAQ), and there seems no simple way to accommodate the implicit wish.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Tue May 26 12:01:40 2009
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 26 May 2009 11:01:40 +0100 (BST)
Subject: [Rd] [R] sprintf() question
In-Reply-To: <dc41e1260905172340hefd20f0h7c23c9a07e86391f@mail.gmail.com>
References: <993B311E57784D70BE4BDF3BAA154A27@Aragorn>
	<XFMail.090517233222.Ted.Harding@manchester.ac.uk>
	<C474D7D640144C34A7BE353F065102BD@Aragorn>
	<dc41e1260905172340hefd20f0h7c23c9a07e86391f@mail.gmail.com>
Message-ID: <alpine.LFD.2.00.0905261052570.25521@gannet.stats.ox.ac.uk>

Thank you, incorporated now.

As the help page says, %a is a C99 feature that is not available on 
all platforms.  The *printf in msvcrt.dll is a long way from 
C99-compatible (it dates from ca 10 years ago, but later VC runtimes 
are also incompatible).  Recently MinGW has attempted to supplement 
it, not very comprehensively.

Quite a while ago we switched R for Windows to use the trio emulation 
of *printf, which is intended to be compatible with C99.  This was a 
bug in a bugfix to trio (there have been quite a few bugfixes).


On Mon, 18 May 2009, Ei-ji Nakama wrote:

> Hi
>
> The result of Windows is clearly strange.
>
> ================ my Linux machine =?good =======================
>> sessionInfo()
> R version 2.9.0 (2009-04-17)
> x86_64-pc-linux-gnu
>
> locale:
> LC_CTYPE=ja_JP.EUC-JP;LC_NUMERIC=C;LC_TIME=ja_JP.EUC-JP;LC_COLLATE=ja_JP.EUC-JP;
> LC_MONETARY=C;LC_MESSAGES=ja_JP.EUC-JP;LC_PAPER=ja_JP.EUC-JP;LC_NAME=C;LC_ADDRES
> S=C;LC_TELEPHONE=C;LC_MEASUREMENT=ja_JP.EUC-JP;LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>> sprintf("%a",1:8)
> [1] "0x1p+0"   "0x1p+1"   "0x1.8p+1" "0x1p+2"   "0x1.4p+2" "0x1.8p+2" "0x1.cp+2"
> [8] "0x1p+3"
>
> ================ my Windows machine = OMG ======================
>> sessionInfo()
> R version 2.9.0 (2009-04-17)
> i386-pc-mingw32
>
> locale:
> LC_COLLATE=Japanese_Japan.932;LC_CTYPE=Japanese_Japan.932;LC_MONETARY=Japanese_Japan.932;LC_NUMERIC=C;LC_TIME=Japanese_Japan.932
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>> sprintf("%a",1:8)
> [1] "0x1p+0"            "0x1"               "0x1.8"
> "0x1p+4294967294"
> [5] "0x1.4p+4294967294" "0x1.8p+4294967294" "0x1.cp+4294967294"
> "0x1p+4294967293"
>
> The result improved when I changed handling of uExponent as follows
>
> http://prs.ism.ac.jp/?nakama/working/sprintf_format_a.patch
>
>
>
> 2009/5/18 Daniel Nordlund <djnordlund at verizon.net>:
>>> -----Original Message-----
>>> From: Ted Harding [mailto:Ted.Harding at manchester.ac.uk]
>>> Sent: Sunday, May 17, 2009 3:32 PM
>>> To: Daniel Nordlund
>>> Cc: r-help at r-project.org
>>> Subject: RE: [R] sprintf() question
>>>
>>> On 17-May-09 22:03:19, Daniel Nordlund wrote:
>>>> When I type the following, I get results different from what I
>>>> expected.
>>>>
>>>>> sprintf('%a',3)
>>>> [1] "0x1.8"
>>>>
>>>> Shouldn't the result be
>>>>
>>>> [1] "0x1.8p+2"
>>>
>>> Well, not "p+2" but "p+1"
>>>   (0x1.8 = 1.1000[2] ; *2 = 11.000[2] = 3[10]) ;
>>> however, I get:
>>>
>>>   sprintf('%a',3)
>>>   # [1] "0x1.8p+1"
>>>
>>> which is indeed correct.
>>>
>>>   R version 2.9.0 (2009-04-17) ## Same as yours
>>>   platform  i486-pc-linux-gnu  ## Different from yours ...
>>>
>>> which perhaps suggests that there may be a mis-compilation in the
>>> Windows version.
>>>
>>> Ted.
>>>
>>>> I read through the help ?sprintf and didn't find anything
>>> that changed
>>>> my expectation.  What am I misunderstanding?  I am using
>>> R-2.9.0 binary
>>>> from CRAN on Windows XP Pro, and my session info is
>>>>
>>>>
>>>>> sessionInfo()
>>>> R version 2.9.0 (2009-04-17)
>>>> i386-pc-mingw32
>>>>
>>>> locale:
>>>> LC_COLLATE=English_United States.1252;LC_CTYPE=English_United
>>>> States.1252;LC_MONETARY=English_United
>>>> States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252
>>>>
>>>> attached base packages:
>>>> [1] stats     graphics  grDevices utils     datasets
>>> methods   base
>>>>>
>>>>
>>>> Thanks for any enlightenment.
>>>>
>>
>> Thanks Ted!
>>
>> Enlightenment is what I asked for, and it is what I got.  I was having a
>> senior moment I guess.  I was picturing 8 as binary 0100, when obviously it
>> is binary 1000.  So yes, the required power of 2 is 1, and it is fine with
>> me that Windows implementation does not display it.  Thanks again.
>>
>> Dan
>>
>> Daniel Nordlund
>> Bothell, WA  USA
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>
> -- 
> EI-JI Nakama  <nakama (a) ki.rim.or.jp>
> "?u4e2d?u9593?u6804?u6cbb"  <nakama (a) ki.rim.or.jp>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/?ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From ligges at statistik.tu-dortmund.de  Tue May 26 16:11:53 2009
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Tue, 26 May 2009 16:11:53 +0200
Subject: [Rd] Vista authorization issues (PR#13718)
In-Reply-To: <20090525160008.E0D23282BE82@mail.pubhealth.ku.dk>
References: <20090525160008.E0D23282BE82@mail.pubhealth.ku.dk>
Message-ID: <4A1BF8A9.8080401@statistik.tu-dortmund.de>

There is no bug in R, or can you tell us what is not working in R? You 
just told us that JGR and Tinn-R are not working. But you need to report 
that to the corresponding maintainers.

Uwe Ligges


dpkesling at juno.com wrote:
> Full_Name: David Kesling
> Version: 2.9.0
> OS: Windows Vista & XP sp2
> Submission from: (NULL) (65.166.169.237)
> 
> 
> I upgraded to 2.9.0 on my desktop (XP) and my laptop (Vista Home Basic). The XP
> machine (with both Tinn-R and JGR) is running just fine... very happy. The
> laptop is NOT doing too well. I've had to activate the XP-compatability mode AND
> run Rgui as administrator... and there still seem to be issues. Tinn-R, even
> after reinstallation, will not properly communicate with Rgui. JGR can't even
> FIND R 2.9.
> 
> Again, 2.9 seems to run fine under XP and, with much struggling, under Vista.
> But registry issues on the Vista platform have broken Tinn-R and JGR IDEs.
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From murdoch at stats.uwo.ca  Tue May 26 17:50:29 2009
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue, 26 May 2009 11:50:29 -0400
Subject: [Rd] Can a function know what other function called it?
In-Reply-To: <4A195872.5030507@dbmail.com>
References: <c2350ba40905231337u5ead6f97o95ee24f2faea081e@mail.gmail.com>	<4A1862AD.2070600@fhcrc.org>
	<4A19366F.5080402@stats.uwo.ca> <4A195872.5030507@dbmail.com>
Message-ID: <4A1C0FC5.9010602@stats.uwo.ca>

On 5/24/2009 10:23 AM, Romain Francois wrote:
> Duncan Murdoch wrote:
>> On 23/05/2009 4:55 PM, Robert Gentleman wrote:
>>> Kynn Jones wrote:
>>>
> [snip]
>>>
>>>   and you have a breakpoint in bar, you could not (easily) 
>>> distinguish which of
>>> the two calls to bar was active. There is no line counter or anything 
>>> of that
>>> sort available.
>>
>> The evaluator doesn't pay any attention to srcref records, so this is 
>> still true, but it would be possible to keep the srcref on the stack 
>> as well as all the other info there.
> 
> Please

Here's a patch file that does this.  (Will it make it through to the 
mailing list?  We'll see.)  It's still in progress, so I'm not even 
ready to put it into R-devel, but you're welcome to try it out.

The basic idea is that it attaches srcref attributes to the values 
returned from sys.calls (which won't be displayed, but if you want to 
play with them you can) and to .Traceback (which traceback() will 
display).  debug() will also show them.

Not sure what bad side effects (e.g. on execution time) this has.

Duncan Murdoch

> 
>>
>> I've written code (and I think I sent it to you last year) that can do 
>> things like replacing the statement coming from a particular line of a 
>> file with whatever code you like; this could be used in writing a nice 
>> source-level debugger.
> 
> yes
> 
>>
>> Duncan Murdoch
>>
>>>
>>>  best wishes
>>>    Robert
>>>
>>
> 
> 

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: srcref.patch
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090526/252500d2/attachment.pl>

From christian.ledergerber at comerge.net  Tue May 26 17:50:55 2009
From: christian.ledergerber at comerge.net (Christian Ledergerber)
Date: Tue, 26 May 2009 17:50:55 +0200
Subject: [Rd] R Embedded waring and error callbacks
Message-ID: <606c04234da51893244cf11281a5fca0@comerge.net>

Hi,

I would like to display error messages and warnings which are generated in
R in my own GUI. For normal output we simply had to assign a callback
function to ptr_R_WriteConsole and  ptr_R_ShowMessage. According to google
there should be similar function pointers for error messages. Such as
ptr_R_WriteErrConsole. However, I could not find this function pointer in
my current R installation (R version 2.8.1 (2008-12-22)). Do I need to
install a different R version or is there by now a different way to receive
those callbacks?

Your help will be greatly appreciated!

Thanks, Christian


From romain.francois at dbmail.com  Tue May 26 18:57:17 2009
From: romain.francois at dbmail.com (Romain Francois)
Date: Tue, 26 May 2009 18:57:17 +0200
Subject: [Rd] Can a function know what other function called it?
In-Reply-To: <4A1C0FC5.9010602@stats.uwo.ca>
References: <c2350ba40905231337u5ead6f97o95ee24f2faea081e@mail.gmail.com>	<4A1862AD.2070600@fhcrc.org>
	<4A19366F.5080402@stats.uwo.ca> <4A195872.5030507@dbmail.com>
	<4A1C0FC5.9010602@stats.uwo.ca>
Message-ID: <4A1C1F6D.8090103@dbmail.com>

Duncan Murdoch wrote:
> On 5/24/2009 10:23 AM, Romain Francois wrote:
>> Duncan Murdoch wrote:
>>> On 23/05/2009 4:55 PM, Robert Gentleman wrote:
>>>> Kynn Jones wrote:
>>>>
>> [snip]
>>>>
>>>>   and you have a breakpoint in bar, you could not (easily) 
>>>> distinguish which of
>>>> the two calls to bar was active. There is no line counter or 
>>>> anything of that
>>>> sort available.
>>>
>>> The evaluator doesn't pay any attention to srcref records, so this 
>>> is still true, but it would be possible to keep the srcref on the 
>>> stack as well as all the other info there.
>>
>> Please
>
> Here's a patch file that does this.  (Will it make it through to the 
> mailing list?  We'll see.)  It's still in progress, so I'm not even 
> ready to put it into R-devel, but you're welcome to try it out.
>
> The basic idea is that it attaches srcref attributes to the values 
> returned from sys.calls (which won't be displayed, but if you want to 
> play with them you can) and to .Traceback (which traceback() will 
> display).  debug() will also show them.
>
> Not sure what bad side effects (e.g. on execution time) this has.
>
> Duncan Murdoch

Many thanks. I'll play with this right now. My guess is that since these 
"srcref" records are calculated anyway by the parser, this won't affect 
too much the execution time.

>
>>
>>>
>>> I've written code (and I think I sent it to you last year) that can 
>>> do things like replacing the statement coming from a particular line 
>>> of a file with whatever code you like; this could be used in writing 
>>> a nice source-level debugger.
>>
>> yes
>>
>>>
>>> Duncan Murdoch
>>>
>>>>
>>>>  best wishes
>>>>    Robert
>>>>
>>>
>>
>>
>


-- 
Romain Francois
Independent R Consultant
+33(0) 6 28 91 30 30
http://romainfrancois.blog.free.fr


From pauljohn32 at gmail.com  Tue May 26 18:58:18 2009
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Tue, 26 May 2009 11:58:18 -0500
Subject: [Rd] plot ignores type= "n" when x is factor (PR#13703)
In-Reply-To: <alpine.LFD.2.00.0905260852140.22101@gannet.stats.ox.ac.uk>
References: <20090514193515.9BC3528320DF@mail.pubhealth.ku.dk>
	<alpine.LFD.2.00.0905260852140.22101@gannet.stats.ox.ac.uk>
Message-ID: <13e802630905260958j3ab9e060rec4695697f024c6a@mail.gmail.com>

On Tue, May 26, 2009 at 3:11 AM, Prof Brian Ripley
<ripley at stats.ox.ac.uk> wrote:
> On Thu, 14 May 2009, pauljohn at ku.edu wrote:
>
>> Full_Name: Paul E. Johnson
>> Version: 2.9.1
>
> Where did you get that? ?Time travel?
>
No, actually.  I used time travel to return to the present and
pre-maturely file the bug report :)

I knew the problem would still be there in 2.9.1 and I came back to
try to warn you about it.


>>
>> x <- gl(2,50)
>> y <- rnorm(100)
>> plot(x,y)
>> plot(x,y, type="n")
>>
>>
>> I *wish* the last one would draw a blank plot box w/axes, but it does not.
>> It
>> fills in the middle with a box plot. I've not seen this problem when x is
>> numeric.
>
> Because this is a call to the 'factor' (see ?plot.factor). ?Although ?plot
> says
>
> ? ? ...: Arguments to be passed to methods, such as graphical
> ? ? ? ? ?parameters (see 'par'). Many methods will accept the
> ? ? ? ? ?following arguments:
>
> ? ? ? ? ?'type' what type of plot should be drawn. ?Possible types are
>
> 'many' does not mean 'all' and all the other values of 'type' would be
> inappropriate for plot.factor. ?Note that plot.factor is a wrapper for a
> call to barplot(), spineplot() or (in your case) boxplot(), which do not
> take a 'type' argument.
>
> If plot.factor() or barplot() or boxplot() allowed a 'type' argument, what
> value would be appropriate to give the usual plot? ?Not as far as I can see
> any of those listed in ?plot, and that says all other values are errors.
>
>
> So, this is not a bug, it was not marked for the wishlist (see the R FAQ),
> and there seems no simple way to accommodate the implicit wish.
>
> -

Please look at this from the user's point of view.

There's no mention of plot.factor in the plot help page.  Aside from
reading the source code of the plot function (or your email), I don't
think a user would know that plot.factor is even involved in plot.

How about inserting this at the top of the help page for plot:

If either x or y is a factor variable, the plot.factor method is
called to determine the sort of graph to be drawn. If x and y are both
numeric, the type argument determines the sort of graph to be drawn.

If you did that, then you could answer my bug report with the
criticism that I did not read ?plot.factor or that plot.factor can't
do what I want. Otherwise, your response seems unkind and somewhat
unreasonable.  I have no way of knowing that plot.factor is even
involved when I try to use the plot function.

pj
-- 
Paul E. Johnson
Professor, Political Science
1541 Lilac Lane, Room 504
University of Kansas


From b.rowlingson at lancaster.ac.uk  Tue May 26 19:38:15 2009
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Tue, 26 May 2009 18:38:15 +0100
Subject: [Rd] plot ignores type= "n" when x is factor (PR#13703)
In-Reply-To: <13e802630905260958j3ab9e060rec4695697f024c6a@mail.gmail.com>
References: <20090514193515.9BC3528320DF@mail.pubhealth.ku.dk>
	<alpine.LFD.2.00.0905260852140.22101@gannet.stats.ox.ac.uk>
	<13e802630905260958j3ab9e060rec4695697f024c6a@mail.gmail.com>
Message-ID: <d8ad40b50905261038i2a8e9ad7v93ec798320e19d87@mail.gmail.com>

On Tue, May 26, 2009 at 5:58 PM, Paul Johnson <pauljohn32 at gmail.com> wrote:

> There's no mention of plot.factor in the plot help page.

Yes there is, but hidden slightly more than the planning application
for the destruction of the Earth ("It was on display in the bottom of
a locked filing cabinet stuck in a disused lavatory with a sign on the
door saying 'Beware of the Leopard'"[1]). Here it is:

See Also:

     'plot.default', 'plot.formula' and other methods; 'points',
     'lines', 'par'.

 see that 'other methods'? That's it. That's a clue. That's our
'beware of the leopard'. So you need to know about methods...

> How about inserting this at the top of the help page for plot:
>
> If either x or y is a factor variable, the plot.factor method is
> called to determine the sort of graph to be drawn. If x and y are both
> numeric, the type argument determines the sort of graph to be drawn.

 Ah, but something like that would need inserting at the top of just
about every function. R has 'generic' functions that call specific
functions for specific types of object. In two (or more) different
ways. I'm not sure if there's an easy way to say 'get me the help for
the specific method for this thing X when I do foo(X)'.

 You can try: methods(class=class(factor(c(1,2,3,1)))) which will show
'plot.factor' as one of the possible things you can do with factor
objects. Then you can do help(plot.factor). You can also do
methods(plot) to show all the different classes that the generic plot
function can work on. But note these are 'S3' methods - once you hit
"S4" methods you'll need something else.

 And you can hit S4 methods in cruel and unusual ways. For example:

 > library(sp)
 > plot
 standardGeneric for "plot" defined from package "graphics"

function (x, y, ...)
standardGeneric("plot")
<environment: 0x842c6d8>
Methods may be defined for arguments: x, y
Use  showMethods("plot")  for currently available ones.

 Ooh, let's try that:

 > showMethods("plot")
 Function: plot (package graphics)
 x="ANY", y="ANY"
 x="SpatialLines", y="missing"
 x="Spatial", y="missing"
 x="SpatialPoints", y="missing"
 x="SpatialPolygons", y="missing"

 - no mention of factor there. That's because the sp package has
fiddled with the generic plot function to make it S4-compatible. The
S3 methods still work, but now you get added S4 method goodness.

 Yes, the plot function has changed in the middle of your R session.
And this isn't "mostly harmless[1]". Some code I wrote broke because
the new definition of 'plot' was evaluating the 'y' when I didn't want
it to. The previous definition didn't evaluate y until it got to my
generic function.

> If you did that, then you could answer my bug report with the
> criticism that I did not read ?plot.factor or that plot.factor can't
> do what I want. Otherwise, your response seems unkind and somewhat
> unreasonable. ?I have no way of knowing that plot.factor is even
> involved when I try to use the plot function.

 Perhaps an unkind and unreasonable response serves to shock people
into remembering these things -  people on the end of such treatment
don't seem to return to ask very many more questions...

Barry

[1] Hitchhikers' Guide To The Galaxy, Douglas Adams


From murdoch at stats.uwo.ca  Tue May 26 21:18:19 2009
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue, 26 May 2009 15:18:19 -0400
Subject: [Rd] Can a function know what other function called it?
In-Reply-To: <4A1C1F6D.8090103@dbmail.com>
References: <c2350ba40905231337u5ead6f97o95ee24f2faea081e@mail.gmail.com>	<4A1862AD.2070600@fhcrc.org>
	<4A19366F.5080402@stats.uwo.ca> <4A195872.5030507@dbmail.com>
	<4A1C0FC5.9010602@stats.uwo.ca> <4A1C1F6D.8090103@dbmail.com>
Message-ID: <4A1C407B.1090103@stats.uwo.ca>

On 5/26/2009 12:57 PM, Romain Francois wrote:
> Duncan Murdoch wrote:
>> On 5/24/2009 10:23 AM, Romain Francois wrote:
>>> Duncan Murdoch wrote:
>>>> On 23/05/2009 4:55 PM, Robert Gentleman wrote:
>>>>> Kynn Jones wrote:
>>>>>
>>> [snip]
>>>>>
>>>>>   and you have a breakpoint in bar, you could not (easily) 
>>>>> distinguish which of
>>>>> the two calls to bar was active. There is no line counter or 
>>>>> anything of that
>>>>> sort available.
>>>>
>>>> The evaluator doesn't pay any attention to srcref records, so this 
>>>> is still true, but it would be possible to keep the srcref on the 
>>>> stack as well as all the other info there.
>>>
>>> Please
>>
>> Here's a patch file that does this.  (Will it make it through to the 
>> mailing list?  We'll see.)  It's still in progress, so I'm not even 
>> ready to put it into R-devel, but you're welcome to try it out.
>>
>> The basic idea is that it attaches srcref attributes to the values 
>> returned from sys.calls (which won't be displayed, but if you want to 
>> play with them you can) and to .Traceback (which traceback() will 
>> display).  debug() will also show them.
>>
>> Not sure what bad side effects (e.g. on execution time) this has.
>>
>> Duncan Murdoch
> 
> Many thanks. I'll play with this right now. My guess is that since these 
> "srcref" records are calculated anyway by the parser, this won't affect 
> too much the execution time.

It does add a little extra execution time to every statement, and more 
to lines that have source references.  Whether enough to matter, I don't 
know.

Duncan Murdoch


> 
>>
>>>
>>>>
>>>> I've written code (and I think I sent it to you last year) that can 
>>>> do things like replacing the statement coming from a particular line 
>>>> of a file with whatever code you like; this could be used in writing 
>>>> a nice source-level debugger.
>>>
>>> yes
>>>
>>>>
>>>> Duncan Murdoch
>>>>
>>>>>
>>>>>  best wishes
>>>>>    Robert
>>>>>
>>>>
>>>
>>>
>>
> 
>


From thomas.friedrichsmeier at ruhr-uni-bochum.de  Tue May 26 21:29:57 2009
From: thomas.friedrichsmeier at ruhr-uni-bochum.de (Thomas Friedrichsmeier)
Date: 26 May 2009 21:29:57 +0200
Subject: [Rd] R Embedded waring and error callbacks
In-Reply-To: <606c04234da51893244cf11281a5fca0@comerge.net>
References: <606c04234da51893244cf11281a5fca0@comerge.net>
Message-ID: <200905262130.01622.thomas.friedrichsmeier@ruhr-uni-bochum.de>

On Tuesday 26 May 2009, Christian Ledergerber wrote:
> I would like to display error messages and warnings which are generated in
> R in my own GUI. For normal output we simply had to assign a callback
> function to ptr_R_WriteConsole and  ptr_R_ShowMessage. According to google
> there should be similar function pointers for error messages. Such as
> ptr_R_WriteErrConsole. However, I could not find this function pointer in
> my current R installation (R version 2.8.1 (2008-12-22)). Do I need to
> install a different R version or is there by now a different way to receive
> those callbacks?

ptr_R_WriteConsoleEx is what you are looking for. And this is the manual you 
want to look at: http://cran.r-project.org/doc/manuals/R-exts.html .

Regards
Thomas
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 197 bytes
Desc: This is a digitally signed message part.
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090526/dbbecbd8/attachment.bin>

From murdoch at stats.uwo.ca  Tue May 26 21:30:10 2009
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue, 26 May 2009 15:30:10 -0400
Subject: [Rd] plot ignores type= "n" when x is factor (PR#13703)
In-Reply-To: <d8ad40b50905261038i2a8e9ad7v93ec798320e19d87@mail.gmail.com>
References: <20090514193515.9BC3528320DF@mail.pubhealth.ku.dk>	<alpine.LFD.2.00.0905260852140.22101@gannet.stats.ox.ac.uk>	<13e802630905260958j3ab9e060rec4695697f024c6a@mail.gmail.com>
	<d8ad40b50905261038i2a8e9ad7v93ec798320e19d87@mail.gmail.com>
Message-ID: <4A1C4342.1000107@stats.uwo.ca>

On 5/26/2009 1:38 PM, Barry Rowlingson wrote:
> On Tue, May 26, 2009 at 5:58 PM, Paul Johnson <pauljohn32 at gmail.com> wrote:
> 
>> There's no mention of plot.factor in the plot help page.
> 
> Yes there is, but hidden slightly more than the planning application
> for the destruction of the Earth ("It was on display in the bottom of
> a locked filing cabinet stuck in a disused lavatory with a sign on the
> door saying 'Beware of the Leopard'"[1]). Here it is:
> 
> See Also:
> 
>      'plot.default', 'plot.formula' and other methods; 'points',
>      'lines', 'par'.
> 
>  see that 'other methods'? That's it. That's a clue. That's our
> 'beware of the leopard'. So you need to know about methods...
> 
>> How about inserting this at the top of the help page for plot:
>>
>> If either x or y is a factor variable, the plot.factor method is
>> called to determine the sort of graph to be drawn. If x and y are both
>> numeric, the type argument determines the sort of graph to be drawn.
> 
>  Ah, but something like that would need inserting at the top of just
> about every function. R has 'generic' functions that call specific
> functions for specific types of object. In two (or more) different
> ways. I'm not sure if there's an easy way to say 'get me the help for
> the specific method for this thing X when I do foo(X)'.

There is, though it only works if X has an S4 class, so it doesn't work 
in this particular case.  You just use

?foo(X)

The mechanism could be extended to S3 classes by guessing that functions 
always dispatch on the class of the first argument, and that might be 
better than what we have now, but there's a lot of guesswork involved.

Duncan Murdoch

> 
>  You can try: methods(class=class(factor(c(1,2,3,1)))) which will show
> 'plot.factor' as one of the possible things you can do with factor
> objects. Then you can do help(plot.factor). You can also do
> methods(plot) to show all the different classes that the generic plot
> function can work on. But note these are 'S3' methods - once you hit
> "S4" methods you'll need something else.
> 
>  And you can hit S4 methods in cruel and unusual ways. For example:
> 
>  > library(sp)
>  > plot
>  standardGeneric for "plot" defined from package "graphics"
> 
> function (x, y, ...)
> standardGeneric("plot")
> <environment: 0x842c6d8>
> Methods may be defined for arguments: x, y
> Use  showMethods("plot")  for currently available ones.
> 
>  Ooh, let's try that:
> 
>  > showMethods("plot")
>  Function: plot (package graphics)
>  x="ANY", y="ANY"
>  x="SpatialLines", y="missing"
>  x="Spatial", y="missing"
>  x="SpatialPoints", y="missing"
>  x="SpatialPolygons", y="missing"
> 
>  - no mention of factor there. That's because the sp package has
> fiddled with the generic plot function to make it S4-compatible. The
> S3 methods still work, but now you get added S4 method goodness.
> 
>  Yes, the plot function has changed in the middle of your R session.
> And this isn't "mostly harmless[1]". Some code I wrote broke because
> the new definition of 'plot' was evaluating the 'y' when I didn't want
> it to. The previous definition didn't evaluate y until it got to my
> generic function.
> 
>> If you did that, then you could answer my bug report with the
>> criticism that I did not read ?plot.factor or that plot.factor can't
>> do what I want. Otherwise, your response seems unkind and somewhat
>> unreasonable.  I have no way of knowing that plot.factor is even
>> involved when I try to use the plot function.
> 
>  Perhaps an unkind and unreasonable response serves to shock people
> into remembering these things -  people on the end of such treatment
> don't seem to return to ask very many more questions...
> 
> Barry
> 
> [1] Hitchhikers' Guide To The Galaxy, Douglas Adams
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From murdoch at stats.uwo.ca  Tue May 26 22:52:16 2009
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue, 26 May 2009 16:52:16 -0400
Subject: [Rd] Can a function know what other function called it?
In-Reply-To: <4A1C1F6D.8090103@dbmail.com>
References: <c2350ba40905231337u5ead6f97o95ee24f2faea081e@mail.gmail.com>	<4A1862AD.2070600@fhcrc.org>
	<4A19366F.5080402@stats.uwo.ca> <4A195872.5030507@dbmail.com>
	<4A1C0FC5.9010602@stats.uwo.ca> <4A1C1F6D.8090103@dbmail.com>
Message-ID: <4A1C5680.9060707@stats.uwo.ca>

On 5/26/2009 12:57 PM, Romain Francois wrote:
> Duncan Murdoch wrote:
>> On 5/24/2009 10:23 AM, Romain Francois wrote:
>>> Duncan Murdoch wrote:
>>>> On 23/05/2009 4:55 PM, Robert Gentleman wrote:
>>>>> Kynn Jones wrote:
>>>>>
>>> [snip]
>>>>>
>>>>>   and you have a breakpoint in bar, you could not (easily) 
>>>>> distinguish which of
>>>>> the two calls to bar was active. There is no line counter or 
>>>>> anything of that
>>>>> sort available.
>>>>
>>>> The evaluator doesn't pay any attention to srcref records, so this 
>>>> is still true, but it would be possible to keep the srcref on the 
>>>> stack as well as all the other info there.
>>>
>>> Please
>>
>> Here's a patch file that does this.  (Will it make it through to the 
>> mailing list?  We'll see.)  It's still in progress, so I'm not even 
>> ready to put it into R-devel, but you're welcome to try it out.
>>
>> The basic idea is that it attaches srcref attributes to the values 
>> returned from sys.calls (which won't be displayed, but if you want to 
>> play with them you can) and to .Traceback (which traceback() will 
>> display).  debug() will also show them.
>>
>> Not sure what bad side effects (e.g. on execution time) this has.
>>
>> Duncan Murdoch
> 
> Many thanks. I'll play with this right now. My guess is that since these 
> "srcref" records are calculated anyway by the parser, this won't affect 
> too much the execution time.

I have now committed a more complete version of the code to R-devel. 
It's still "experimental"; formats of the displays are likely to change, 
and the internal structures might.

This is likely to disrupt front-ends that expect a particular format 
from tracebacks or the debugger; hopefully the added information will 
make up for the inconvenience.

Duncan Murdoch

> 
>>
>>>
>>>>
>>>> I've written code (and I think I sent it to you last year) that can 
>>>> do things like replacing the statement coming from a particular line 
>>>> of a file with whatever code you like; this could be used in writing 
>>>> a nice source-level debugger.
>>>
>>> yes
>>>
>>>>
>>>> Duncan Murdoch
>>>>
>>>>>
>>>>>  best wishes
>>>>>    Robert
>>>>>
>>>>
>>>
>>>
>>
> 
>


From r.d.morey at rug.nl  Tue May 26 23:13:41 2009
From: r.d.morey at rug.nl (Richard Morey)
Date: Tue, 26 May 2009 23:13:41 +0200
Subject: [Rd] passing "..." arguments to a function called by eval()
Message-ID: <4A1C5B85.7040208@rug.nl>

Hi everyone,

I am starting learn to call C code from within R. So far, I've been 
trying toy problems to see if I can get them to work. One of the things 
I'd like to do is pass an arbitrary R function to C, evaluate the value 
in the C code using eval, and then return it. I also want to allow an 
arbitrary number of arguments to the function using "...".

The code for my toy package looks like this:
########## R code, in pkg/R directory
dTest <-
function(x,...){
    retVal    = .Call("dTestC",x[1],dnorm,...,rho=new.env(),PACKAGE="pkg")
    return(retVal)
}

########## C code, in pkg/src directory

SEXP dTestC(SEXP dblX, SEXP funFn, SEXP dots, SEXP rho);

/*--------------------------*/


SEXP dTestC(SEXP dblX, SEXP funFn, SEXP dots, SEXP rho){

  SEXP retVal;
  SEXP R_fcall;

  PROTECT(retVal = NEW_NUMERIC(1));
  PROTECT(R_fcall = lang3(funFn, R_NilValue, R_NilValue));
  SETCADR(R_fcall, dblX);
  SETCADDR(R_fcall, dots);
  retVal = eval(R_fcall, rho);
  UNPROTECT(2);

  return(retVal);

}

########################

When I call the dTest() function, the first required argument and the 
first optional argument are both used, but not the ones after that.

I'm modeling this after what I found in the 'HI' package. I don't 
understand a few few things. First, the C code used by the arms() 
function in the HI package somehow manages to evaluate an R function, 
with "..." arguments, without passing the SEXP dots argument. I haven't 
been able to figure out how, looking at the source.

Second, in the Rinternal documents it mentions that  "..." is one 
argument.  So, I figured I could get away with doing what I've done 
above, and the SETCADDR function would set all the arguments in "..." in 
one go. This is evidently wrong.

How can I do what I want to do? I know the HI package does it, but I 
don't know how. I might pass all the arguments as members of one list, 
but that seems like a waste. What am I doing/thinking wrong here? What's 
the best way to do what I want to do?

Thanks for your help,

Richard


From smckinney at bccrc.ca  Wed May 27 00:50:11 2009
From: smckinney at bccrc.ca (smckinney at bccrc.ca)
Date: Wed, 27 May 2009 00:50:11 +0200 (CEST)
Subject: [Rd] Bug in "$<-.data.frame" yields corrupt data frame (PR#13724)
Message-ID: <20090526225011.3635B28320BC@mail.pubhealth.ku.dk>

Full_Name: Steven McKinney
Version: 2.9.0
OS: Mac OS X 10.5.6 
Submission from: (NULL) (142.103.207.10)



A corrupt data frame can be constructed as follows:
foo <- matrix(1:12, nrow = 3)
bar <- data.frame(foo)
bar$NewCol <- foo[foo[, 1] == 4, 4]
bar
lapply(bar, length)




> foo <- matrix(1:12, nrow = 3)
> bar <- data.frame(foo)
> bar$NewCol <- foo[foo[, 1] == 4, 4] bar
   X1 X2 X3 X4 NewCol
 1  1  4  7 10   <NA>
 2  2  5  8 11   <NA>
 3  3  6  9 12   <NA>
 Warning message:
 In format.data.frame(x, digits = digits, na.encode = FALSE) :
   corrupt data frame: columns will be truncated or padded with NAs
> lapply(bar, length)
 $X1
 [1] 3

 $X2
 [1] 3

 $X3
 [1] 3

 $X4
 [1] 3

 $NewCol
 [1] 0


The data.frame method is

> getAnywhere("$<-.data.frame" )
A single object matching '$<-.data.frame' was found It was found in the
following places
  package:base
  registered S3 method for $<- from namespace base
  namespace:base
with value

function (x, i, value)
{
    cl <- oldClass(x)
    class(x) <- NULL
    nrows <- .row_names_info(x, 2L)
    if (!is.null(value)) {
        N <- NROW(value)
        if (N > nrows) 
            stop(gettextf("replacement has %d rows, data has %d", 
                N, nrows), domain = NA)
        if (N < nrows && N > 0L) 
            if (nrows%%N == 0L && length(dim(value)) <= 1L) 
                value <- rep(value, length.out = nrows)
            else stop(gettextf("replacement has %d rows, data has %d", 
                N, nrows), domain = NA)
        if (is.atomic(value)) 
            names(value) <- NULL
    }
    x[[i]] <- value
    class(x) <- cl
    return(x)
}<environment: namespace:base>
>


I placed a browser() command before return(x) and did some poking
around.  The issue is that the example above creates an object with
N < nrows but N == 0L, so either an else clause to check for this
condition is needed, or, it appears to me, the N > 0L part of the
conditional clause needs to be moved to the next if clause.

I modified the rows
          if (N < nrows && N > 0L) 
            if (nrows%%N == 0L && length(dim(value)) <= 1L)
to read
           if (N < nrows) 
            if (N > 0L && nrows%%N == 0L && length(dim(value)) <= 1L)

as in

"$<-.data.frame" <-
function (x, i, value) 
{
    cl <- oldClass(x)
    class(x) <- NULL
    nrows <- .row_names_info(x, 2L)
    if (!is.null(value)) {
        N <- NROW(value)
        if (N > nrows) 
            stop(gettextf("replacement has %d rows, data has %d", 
                N, nrows), domain = NA)
        if (N < nrows) 
            if (N > 0L && nrows%%N == 0L && length(dim(value)) <= 1L) 
                value <- rep(value, length.out = nrows)
            else stop(gettextf("replacement has %d rows, data has %d", 
                N, nrows), domain = NA)
        if (is.atomic(value)) 
            names(value) <- NULL
    }
    x[[i]] <- value
    class(x) <- cl
    return(x)
} 

Now it detects the problem above:

> foo <- matrix(1:12, nrow = 3)
> bar <- data.frame(foo)
> bar$NewCol <- foo[foo[, 1] == 4, 4]
Error in `$<-.data.frame`(`*tmp*`, "NewCol", value = integer(0)) : 
  replacement has 0 rows, data has 3

It doesn't appear to stumble on weird data frames (these from the
?data.frame help page)


> L3 <- LETTERS[1:3]
> (d <- data.frame(cbind(x=1, y=1:10), fac=sample(L3, 10,
replace=TRUE)))
> (d0  <- d[, FALSE]) # NULL data frame with 10 rows
 
> (d.0 <- d[FALSE, ]) # <0 rows> data frame  (3 cols)

> (d00 <- d0[FALSE,])  # NULL data frame with 0 rows
 
> d0$NewCol <- foo[foo[, 1] == 4, 4]
Error in `$<-.data.frame`(`*tmp*`, "NewCol", value = integer(0)) : 
  replacement has 0 rows, data has 10

### Catches this problem above alright.

> d.0$NewCol <- foo[foo[, 1] == 4, 4]
> d.0
[1] x      y      fac    NewCol
<0 rows> (or 0-length row.names)

### Lets the above one through alright.

> d00$NewCol <- foo[foo[, 1] == 4, 4]
> 
> d00
[1] NewCol
<0 rows> (or 0-length row.names)
### Lets the above one through alright.


Would the above modification work to fix this problem?






> sessionInfo()
 R version 2.9.0 (2009-04-17)
 powerpc-apple-darwin8.11.1

 locale:
 en_CA.UTF-8/en_CA.UTF-8/C/C/en_CA.UTF-8/en_CA.UTF-8

 attached base packages:
 [1] stats     graphics  grDevices utils     datasets  methods   base

 other attached packages:
 [1] nlme_3.1-90

 loaded via a namespace (and not attached):
 [1] grid_2.9.0      lattice_0.17-22 tools_2.9.0


 Also occurs on Windows box with R 2.8.1



 Steven McKinney

 Statistician
 Molecular Oncology and Breast Cancer Program British Columbia Cancer
 Research Centre

 email: smckinney +at+ bccrc +dot+ ca

 tel: 604-675-8000 x7561

 BCCRC
 Molecular Oncology
 675 West 10th Ave, Floor 4
 Vancouver B.C.
 V5Z 1L3
 Canada


From murdoch at stats.uwo.ca  Wed May 27 02:06:18 2009
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue, 26 May 2009 20:06:18 -0400
Subject: [Rd] passing "..." arguments to a function called by eval()
In-Reply-To: <4A1C5B85.7040208@rug.nl>
References: <4A1C5B85.7040208@rug.nl>
Message-ID: <4A1C83FA.9010204@stats.uwo.ca>

On 26/05/2009 5:13 PM, Richard Morey wrote:
> Hi everyone,
> 
> I am starting learn to call C code from within R. So far, I've been 
> trying toy problems to see if I can get them to work. One of the things 
> I'd like to do is pass an arbitrary R function to C, evaluate the value 
> in the C code using eval, and then return it. I also want to allow an 
> arbitrary number of arguments to the function using "...".
> 
> The code for my toy package looks like this:
> ########## R code, in pkg/R directory
> dTest <-
> function(x,...){
>     retVal    = .Call("dTestC",x[1],dnorm,...,rho=new.env(),PACKAGE="pkg")
>     return(retVal)
> }
> 
> ########## C code, in pkg/src directory
> 
> SEXP dTestC(SEXP dblX, SEXP funFn, SEXP dots, SEXP rho);

I wouldn't expect that to work, though it might if .Call is doing fancy 
things with the args.  The way I'd do it is to pass list(...) as a 
single argument to .Call, and within your C code, extract the elements. 
  It would make the call to funFn more complicated (it wants a pairlist 
of arguments, list(...) will be a vector list), but it looks safer than 
what you did.

There's an example in the Writing R Externals manual at the end of 
section 5.10.2 using ... with .External.  (It mentions using list(...) 
with .Call.)

Duncan Murdoch

> 
> /*--------------------------*/
> 
> 
> SEXP dTestC(SEXP dblX, SEXP funFn, SEXP dots, SEXP rho){
> 
>   SEXP retVal;
>   SEXP R_fcall;
> 
>   PROTECT(retVal = NEW_NUMERIC(1));
>   PROTECT(R_fcall = lang3(funFn, R_NilValue, R_NilValue));
>   SETCADR(R_fcall, dblX);
>   SETCADDR(R_fcall, dots);
>   retVal = eval(R_fcall, rho);
>   UNPROTECT(2);
> 
>   return(retVal);
> 
> }
> 
> ########################
> 
> When I call the dTest() function, the first required argument and the 
> first optional argument are both used, but not the ones after that.
> 
> I'm modeling this after what I found in the 'HI' package. I don't 
> understand a few few things. First, the C code used by the arms() 
> function in the HI package somehow manages to evaluate an R function, 
> with "..." arguments, without passing the SEXP dots argument. I haven't 
> been able to figure out how, looking at the source.
> 
> Second, in the Rinternal documents it mentions that  "..." is one 
> argument.  So, I figured I could get away with doing what I've done 
> above, and the SETCADDR function would set all the arguments in "..." in 
> one go. This is evidently wrong.
> 
> How can I do what I want to do? I know the HI package does it, but I 
> don't know how. I might pass all the arguments as members of one list, 
> but that seems like a waste. What am I doing/thinking wrong here? What's 
> the best way to do what I want to do?
> 
> Thanks for your help,
> 
> Richard
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From apw at us.ibm.com  Tue May 26 11:50:10 2009
From: apw at us.ibm.com (apw at us.ibm.com)
Date: Tue, 26 May 2009 11:50:10 +0200 (CEST)
Subject: [Rd] Covariance calculation gives different answer than Excel
	(PR#13720)
Message-ID: <20090526095010.9272028320AF@mail.pubhealth.ku.dk>

Full_Name: Amos Waterland
Version: 2.8.1
OS: Ubuntu Linux
Submission from: (NULL) (68.175.8.163)


I calculated the covariance for a small data set as follows:

X <- c(1,2,3,4)
Y <- c(3,3,4,3)
cov(X,Y)
[1] 0.1666667

But when doing the computation with pencil and paper I get:

((-1.5)*(-0.25) + (-0.5)*(-0.25) + (0.5)*(0.75) + (1.5)*(-0.25))/4
[1] 0.125

Microsoft Excel 2003 covar() also gives 0.125.  I suspect that you guys are
doing something like this:

((-1.5)*(-0.25) + (-0.5)*(-0.25) + (0.5)*(0.75) + (1.5)*(-0.25))/3
[1] 0.1666667

That is, you are dividing by N minus 1 rather than N.  So who is correct?


From astokes at esica.com  Tue May 26 19:00:15 2009
From: astokes at esica.com (astokes at esica.com)
Date: Tue, 26 May 2009 19:00:15 +0200 (CEST)
Subject: [Rd] omission col as vector argument in hist documentation
	(PR#13722)
Message-ID: <20090526170015.DC19928320AA@mail.pubhealth.ku.dk>

Full_Name: Allan Stokes
Version: 2.8.1
OS: XP
Submission from: (NULL) (24.108.0.245)


Concerning the "col" argument, doc states only that col is "a colour to be used
to fill the bars. The default of NULL yields unfilled bars." 

It omits to mention that the col argument takes a vector which applies to the
bars in left to right order with recycling.


From r.d.morey at rug.nl  Wed May 27 09:55:13 2009
From: r.d.morey at rug.nl (Richard Morey)
Date: Wed, 27 May 2009 09:55:13 +0200
Subject: [Rd] passing "..." arguments to a function called by eval()
In-Reply-To: <4A1C83FA.9010204@stats.uwo.ca>
References: <4A1C5B85.7040208@rug.nl> <4A1C83FA.9010204@stats.uwo.ca>
Message-ID: <4A1CF1E1.8080207@rug.nl>

I was still puzzled by the fact that HI managed to do it without using 
complicated lists, so recombed the HI source to see what I missed the 
first time.

HI defines a second function f=function(x) passedFun(x,...) and then 
passes that to the C code using .Call. I had missed something subtle, 
and was using

f=function(x,...) passedFun(x,...)

and passing that to .Call. That, of course, didn't work, leading me to 
try to find the solution below. It is critical that you don't have ... 
as an argument to the dummy function you define. That way, ... will be 
in scope in the dummy function and you don't have to pass it to .Call.

Richard


Duncan Murdoch wrote:
> On 26/05/2009 5:13 PM, Richard Morey wrote:
>> Hi everyone,
>>
>> I am starting learn to call C code from within R. So far, I've been 
>> trying toy problems to see if I can get them to work. One of the 
>> things I'd like to do is pass an arbitrary R function to C, evaluate 
>> the value in the C code using eval, and then return it. I also want 
>> to allow an arbitrary number of arguments to the function using "...".
>>
>> The code for my toy package looks like this:
>> ########## R code, in pkg/R directory
>> dTest <-
>> function(x,...){
>>     retVal    = 
>> .Call("dTestC",x[1],dnorm,...,rho=new.env(),PACKAGE="pkg")
>>     return(retVal)
>> }
>>
>> ########## C code, in pkg/src directory
>>
>> SEXP dTestC(SEXP dblX, SEXP funFn, SEXP dots, SEXP rho);
>
> I wouldn't expect that to work, though it might if .Call is doing 
> fancy things with the args.  The way I'd do it is to pass list(...) as 
> a single argument to .Call, and within your C code, extract the 
> elements.  It would make the call to funFn more complicated (it wants 
> a pairlist of arguments, list(...) will be a vector list), but it 
> looks safer than what you did.
>
> There's an example in the Writing R Externals manual at the end of 
> section 5.10.2 using ... with .External.  (It mentions using list(...) 
> with .Call.)
>
> Duncan Murdoch
>
>>
>> /*--------------------------*/
>>
>>
>> SEXP dTestC(SEXP dblX, SEXP funFn, SEXP dots, SEXP rho){
>>
>>   SEXP retVal;
>>   SEXP R_fcall;
>>
>>   PROTECT(retVal = NEW_NUMERIC(1));
>>   PROTECT(R_fcall = lang3(funFn, R_NilValue, R_NilValue));
>>   SETCADR(R_fcall, dblX);
>>   SETCADDR(R_fcall, dots);
>>   retVal = eval(R_fcall, rho);
>>   UNPROTECT(2);
>>
>>   return(retVal);
>>
>> }
>>
>> ########################
>>
>> When I call the dTest() function, the first required argument and the 
>> first optional argument are both used, but not the ones after that.
>>
>> I'm modeling this after what I found in the 'HI' package. I don't 
>> understand a few few things. First, the C code used by the arms() 
>> function in the HI package somehow manages to evaluate an R function, 
>> with "..." arguments, without passing the SEXP dots argument. I 
>> haven't been able to figure out how, looking at the source.
>>
>> Second, in the Rinternal documents it mentions that  "..." is one 
>> argument.  So, I figured I could get away with doing what I've done 
>> above, and the SETCADDR function would set all the arguments in "..." 
>> in one go. This is evidently wrong.
>>
>> How can I do what I want to do? I know the HI package does it, but I 
>> don't know how. I might pass all the arguments as members of one 
>> list, but that seems like a waste. What am I doing/thinking wrong 
>> here? What's the best way to do what I want to do?
>>
>> Thanks for your help,
>>
>> Richard
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From murdoch at stats.uwo.ca  Wed May 27 09:58:21 2009
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Wed, 27 May 2009 03:58:21 -0400
Subject: [Rd] Covariance calculation gives different answer than Excel
 (PR#13720)
In-Reply-To: <20090526095010.9272028320AF@mail.pubhealth.ku.dk>
References: <20090526095010.9272028320AF@mail.pubhealth.ku.dk>
Message-ID: <4A1CF29D.3070202@stats.uwo.ca>

On 26/05/2009 5:50 AM, apw at us.ibm.com wrote:
> Full_Name: Amos Waterland
> Version: 2.8.1
> OS: Ubuntu Linux
> Submission from: (NULL) (68.175.8.163)
> 
> 
> I calculated the covariance for a small data set as follows:
> 
> X <- c(1,2,3,4)
> Y <- c(3,3,4,3)
> cov(X,Y)
> [1] 0.1666667
> 
> But when doing the computation with pencil and paper I get:
> 
> ((-1.5)*(-0.25) + (-0.5)*(-0.25) + (0.5)*(0.75) + (1.5)*(-0.25))/4
> [1] 0.125
> 
> Microsoft Excel 2003 covar() also gives 0.125.  I suspect that you guys are
> doing something like this:
> 
> ((-1.5)*(-0.25) + (-0.5)*(-0.25) + (0.5)*(0.75) + (1.5)*(-0.25))/3
> [1] 0.1666667
> 
> That is, you are dividing by N minus 1 rather than N.  So who is correct?

Please don't claim something is a bug when you are not sure.  cov() is 
clearly documented to use n-1 in the denominator.  Excel (for their own 
reasons) uses n, which leads to surprises like var(x) != covar(x, x), 
because they use n-1 in their variance calculation.

Duncan Murdoch


From murdoch at stats.uwo.ca  Wed May 27 10:00:15 2009
From: murdoch at stats.uwo.ca (murdoch at stats.uwo.ca)
Date: Wed, 27 May 2009 10:00:15 +0200 (CEST)
Subject: [Rd] Covariance calculation gives different answer than Excel
	(PR#13725)
Message-ID: <20090527080015.846B228320AB@mail.pubhealth.ku.dk>

On 26/05/2009 5:50 AM, apw at us.ibm.com wrote:
> Full_Name: Amos Waterland
> Version: 2.8.1
> OS: Ubuntu Linux
> Submission from: (NULL) (68.175.8.163)
> 
> 
> I calculated the covariance for a small data set as follows:
> 
> X <- c(1,2,3,4)
> Y <- c(3,3,4,3)
> cov(X,Y)
> [1] 0.1666667
> 
> But when doing the computation with pencil and paper I get:
> 
> ((-1.5)*(-0.25) + (-0.5)*(-0.25) + (0.5)*(0.75) + (1.5)*(-0.25))/4
> [1] 0.125
> 
> Microsoft Excel 2003 covar() also gives 0.125.  I suspect that you guys are
> doing something like this:
> 
> ((-1.5)*(-0.25) + (-0.5)*(-0.25) + (0.5)*(0.75) + (1.5)*(-0.25))/3
> [1] 0.1666667
> 
> That is, you are dividing by N minus 1 rather than N.  So who is correct?

Please don't claim something is a bug when you are not sure.  cov() is 
clearly documented to use n-1 in the denominator.  Excel (for their own 
reasons) uses n, which leads to surprises like var(x) != covar(x, x), 
because they use n-1 in their variance calculation.

Duncan Murdoch


From andy_liaw at merck.com  Wed May 27 14:58:42 2009
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 27 May 2009 08:58:42 -0400
Subject: [Rd] using a "third party" DLL in my package
In-Reply-To: <alpine.LFD.2.00.0905240727150.32603@gannet.stats.ox.ac.uk>
References: <4A0C079F.7080101@metla.fi><alpine.LFD.2.00.0905150905560.4378@gannet.stats.ox.ac.uk><4A13EA32.5010309@metla.fi><0A2C49D8-9EDA-432B-B3CD-04A395EBBAC4@stat.berkeley.edu>
	<alpine.LFD.2.00.0905240727150.32603@gannet.stats.ox.ac.uk>
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFA074CEF36@usctmx1106.merck.com>

I don't know if this applies to Seija's case, but one instance that I've ran into when problem arose only with -O3 is uninitialized variables/arrays.  Adding the initialization fixed the problem.  Just one thing to check, I guess.

Best,
Andy

From: Prof Brian Ripley
> 
> It is likely that this is related to using higher-precision FPU 
> registers, in which case there is a portable solution: look up 
> SAFE_FFLAGS in 'Writing R Extensions'.
> 
> But if that is the cause, the real solution is to write the 
> code using 
> proper convergence tests.
> 
> On Sat, 23 May 2009, Kasper Daniel Hansen wrote:
> 
> >
> > On May 20, 2009, at 4:32 , Seija Sirki? wrote:
> >
> >> Hello again,
> >> 
> >> thank you for the comments, especially this one:
> >> 
> >> Prof Brian Ripley wrote:
> >> 
> >>> My concern would be that there are different cases that fail under
> >>> Fortran compiler X and you are just sweeping the problem under the
> >>> carpet.
> >> 
> >> It inspired us to go back to search the cause, and we've made some 
> >> progress: it's not the compiler, it's the compiler 
> options. Simple, but it 
> >> took a while to figure that out since my experience in 
> these things is 
> >> limited. When I build the package with default options 
> using INSTALL 
> >> --build the dll is built with option -O3 as per R's 
> Makeconfig file. If I 
> >> build the dll by hand, using gfortran with no additional 
> options and 
> >> dyn.load it, everything works, and also with -O and -Os. 
> (No, I don't fully 
> >> understand what the differences between all these are, but 
> that's another 
> >> question).
> >> 
> >> I'm looking at chapter 5.5 in Writing R Extensions and 
> also 6.3.3 in R 
> >> Installation and Administration but I can't figure out how 
> to tell "inside" 
> >> my package that it is not to be built -O3 but with, say, 
> -O. I can see how 
> >> to add flags in the package (and as far as I can tell, if 
> there are several 
> >> optimization level flags the last in line is used and 
> that's the wrong one 
> >> from my point of view), and also how to override flags but 
> only on my 
> >> computer. Am I blind or am I again attempting something I 
> shouldn't?
> >
> >
> > This is not trivial, and how you do it is compiler 
> dependent. A quick fix was 
> > provided by Simon Urbanek a while back and it is _not_ 
> portable, it assumes 
> > you are using GCC. It would be nice to have a configure 
> file that detects the 
> > compiler and optimization setting and then re-sets the 
> optimization level. I 
> > have thought about writing one, but have never got around to do it.
> >
> > Anyway, the fix is in the Makevars file from affxparser 
> from Bioconductor. 
> > Essentially, you use a Makevars file placed in the src 
> directory, containing
> >
> > MYCXXFLAGS=-O0 -Wall
> >
> > %.o: %.cpp
> >       $(CXX) $(ALL_CPPFLAGS) $(ALL_CXXFLAGS) $(MYCXXFLAGS) 
> -c $< -o $@
> >
> > Essentially this makes sure that -O0 (indicating no 
> optimization) is placed 
> > at the _end_ of the call to the compiler (this is for C++ 
> files btw), using 
> > the fact that if you have two -O* settings, the last one 
> overrides the first.
> >
> > This ought to be easily adaptable to FORTRAN.
> >
> > Kasper
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 
Notice:  This e-mail message, together with any attachme...{{dropped:12}}


From l.bartnik at gmail.com  Wed May 27 11:35:10 2009
From: l.bartnik at gmail.com (l.bartnik at gmail.com)
Date: Wed, 27 May 2009 11:35:10 +0200 (CEST)
Subject: [Rd] R package installation (PR#13726)
Message-ID: <20090527093510.E70DB2832188@mail.pubhealth.ku.dk>

Full_Name: Lukasz Andrzej Bartnik
Version: 2.8.1
OS: RHELS 5.2
Submission from: (NULL) (194.181.94.250)


Compile R for 32 bit on a 64 bit machine:

unset LD_LIBRARY_PATH
unset R_LD_LIBRARY_PATH
export CC="gcc -m32"
export CXXFLAGS="-m32 -O2 -g"
export FFLAGS="-m32 -O2 -g"
export FCFLAGS="-m32 -O2 -g"
export OBJCFLAGS="-m32 -O2 -g"
export LIBnn=lib

./configure --with-x=no --enable-R-shlib --prefix=/prefix

Now try to install a package which has Fortran files inside:

/prefix/bin/R CMD INSTALL crawl_1.0-4.tar.gz

* Installing to library '/prefix/lib/R/library'
* Installing *source* package 'crawl' ...
** libs
gfortran  -fpic -m32 -O2 -g -c  crwDriftN2ll.f90 -o crwDriftN2ll.o
gfortran  -fpic -m32 -O2 -g -c  crwDriftPredict.f90 -o crwDriftPredict.o
gfortran  -fpic -m32 -O2 -g -c  crwN2ll.f90 -o crwN2ll.o
gfortran  -fpic -m32 -O2 -g -c  crwPredict.f90 -o crwPredict.o
gfortran -shared -L/usr/local/lib -o crawl.so crwDriftN2ll.o crwDriftPredict.o
crwN2ll.o crwPredict.o   -L/prefix/lib/R/lib -lR
/usr/bin/ld: skipping incompatible /prefix/lib/R/lib/libR.so when searching for
-lR
/usr/bin/ld: cannot find -lR
collect2: ld returned 1 exit status
make: *** [crawl.so] Error 1
ERROR: compilation failed for package 'crawl'
** Removing '/prefix/lib/R/library/crawl'
** Restoring previous '/prefix/lib/R/library/crawl'

This error can be avoided if /prefix/lib/R/etc/Makeconf is modified:

Remove: SHLIB_FCLD = gfortran
Insert: SHLIB_FCLD = gfortran -m32


From ripley at stats.ox.ac.uk  Wed May 27 18:58:48 2009
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 27 May 2009 17:58:48 +0100 (BST)
Subject: [Rd] R package installation (PR#13726)
In-Reply-To: <20090527093510.E70DB2832188@mail.pubhealth.ku.dk>
References: <20090527093510.E70DB2832188@mail.pubhealth.ku.dk>
Message-ID: <alpine.LFD.2.00.0905271732590.21872@gannet.stats.ox.ac.uk>

This is a problem in your specification to R of the peculiarities of 
your system, not in R itself.  You have only specified some of the 
settings you need, and in particular as you are using Fortran 90 code 
and a shared R library you need more than a typical user would.

On Wed, 27 May 2009, l.bartnik at gmail.com wrote:

> Full_Name: Lukasz Andrzej Bartnik
> Version: 2.8.1

Not current.

> OS: RHELS 5.2
> Submission from: (NULL) (194.181.94.250)
>
>
> Compile R for 32 bit on a 64 bit machine:
>
> unset LD_LIBRARY_PATH
> unset R_LD_LIBRARY_PATH
> export CC="gcc -m32"
> export CXXFLAGS="-m32 -O2 -g"
> export FFLAGS="-m32 -O2 -g"
> export FCFLAGS="-m32 -O2 -g"
> export OBJCFLAGS="-m32 -O2 -g"
> export LIBnn=lib

Copied I suppose from the R-admin manual (without credit)?  The 
current version suggests

CC="gcc -m32"
F77="gfortran -m32"
FC=$(F77)
CXX="gcc -m32"
OBJC=$(CC)
LIBnn=lib

which I suspect you will find more successful.  However, you seem not 
to have studied the file config.site, which lists many settings you 
may need to specify.  Reading there, it seems that either 
SHLIB_FCLD="gfortran -m32" or SHLIB_FCLDFLAGS="-shared -m32" would be 
appropriate.

> ./configure --with-x=no --enable-R-shlib --prefix=/prefix
>
> Now try to install a package which has Fortran files inside:

Hmm, has Fortran 90 files inside: these do not use the same settings 
as 'Fortran'.

> /prefix/bin/R CMD INSTALL crawl_1.0-4.tar.gz
>
> * Installing to library '/prefix/lib/R/library'
> * Installing *source* package 'crawl' ...
> ** libs
> gfortran  -fpic -m32 -O2 -g -c  crwDriftN2ll.f90 -o crwDriftN2ll.o
> gfortran  -fpic -m32 -O2 -g -c  crwDriftPredict.f90 -o crwDriftPredict.o
> gfortran  -fpic -m32 -O2 -g -c  crwN2ll.f90 -o crwN2ll.o
> gfortran  -fpic -m32 -O2 -g -c  crwPredict.f90 -o crwPredict.o
> gfortran -shared -L/usr/local/lib -o crawl.so crwDriftN2ll.o crwDriftPredict.o
> crwN2ll.o crwPredict.o   -L/prefix/lib/R/lib -lR
> /usr/bin/ld: skipping incompatible /prefix/lib/R/lib/libR.so when searching for
> -lR
> /usr/bin/ld: cannot find -lR
> collect2: ld returned 1 exit status
> make: *** [crawl.so] Error 1
> ERROR: compilation failed for package 'crawl'
> ** Removing '/prefix/lib/R/library/crawl'
> ** Restoring previous '/prefix/lib/R/library/crawl'
>
> This error can be avoided if /prefix/lib/R/etc/Makeconf is modified:
>
> Remove: SHLIB_FCLD = gfortran
> Insert: SHLIB_FCLD = gfortran -m32
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From maechler at stat.math.ethz.ch  Wed May 27 22:51:38 2009
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 27 May 2009 22:51:38 +0200
Subject: [Rd] as.numeric(levels(factor(x))) may be a decreasing sequence
In-Reply-To: <20090523074454.GA17112@cs.cas.cz>
References: <20090523074454.GA17112@cs.cas.cz>
Message-ID: <18973.42970.826686.173830@cmath-5.math.ethz.ch>

>>>>> "PS" == Petr Savicky <savicky at cs.cas.cz>
>>>>>     on Sat, 23 May 2009 09:44:54 +0200 writes:

    PS> Function factor() in the current development version
    PS> (2009-05-22) guarantees that levels are different
    PS> character strings. However, they may represent the same
    PS> decimal number. The following example is derived from a
    PS> posting by Stavros Macrakis in thread "Match .3 in a
    PS> sequence" in March

    PS>   nums <- 0.3 + 2e-16 * c(-2,-1,1,2) f <- factor(nums)
    PS> levels(f) # [1] "0.300000000000000" "0.3"

    PS> The levels differ in trailing zeros, but represent the
    PS> same decimal number.  Besides that this is not really
    PS> meaningful, it may cause a problem, when using
    PS> as.numeric(levels(f)).

    PS> In the above case, as.numeric() works fine and maps the
    PS> two levels to the same number. However, there are cases,
    PS> where the difference in trailing zeros implies different
    PS> values in as.numeric(levels(f)) and these values may
    PS> even form a decreasing sequence although levels were
    PS> constructed from an increasing sequence of numbers.

    PS> Examples are platform dependent, but may be found by the
    PS> following code.  Tested on Intel under Linux (both with
    PS> and without SSE) and also under Windows with an older
    PS> version of R.

    PS> for (i in 1:100000) {
    PS> x <- 10^(floor(runif(1, 61, 63)) + runif(1)/2)
    PS> x <- as.numeric(sprintf("%.14g", x))
    PS> eps <- 2^(floor(log2(x)) - 52)
    PS> k <- round(x * c(5e-16, 1e-15) / eps)
    PS> if (x > 1e62) { k <- rev( - k) }
    PS> y <- x + k[1]:k[2] * eps
    PS> ind <- which(diff(as.numeric(as.character(y))) < 0)
    PS> for (j in ind) {
    PS> u1 <- y[c(j, j+1)]
    PS> u2 <- factor(u1)
    PS> print(levels(u2))
    PS> print(diff(as.numeric(levels(u2))))
    PS> aux <- readline("next")
    PS> }
    PS> }

    PS> An example of the output is

    PS> [1] "1.2296427920313e+61"  "1.22964279203130e+61"
    PS> [1] -1.427248e+45
    PS> next
    PS> [1] "1.82328862326830e+62" "1.8232886232683e+62" 
    PS> [1] -2.283596e+46
    PS> next

    PS> The negative number in diff(as.numeric(levels(u2))) demonstrates cases,
    PS> when as.numeric(levels(u2)) is decreasing. We can also see that the reason
    PS> is that the two strings in levels(u2) differ in the trailing zeros.

    PS> I did quite intensive search for such examples for all possible exponents
    PS> (not only 61 and 62 and a week of CPU on three processors) and all the obtained
    PS> examples were caused by a difference in trailing zeros. So, i believe that
    PS> removing trailing zeros from the output of as.character(x) solves the problem
    PS> with the reversed order in as.numeric(levels(factor(x))) entirely.

    PS> A patch against R-devel_2009-05-22, which eliminates trailing zeros
    PS> from as.character(x), but makes no other changes to as.character(x),
    PS> is in an attachment. Using the patch, we obtain a better result also
    PS> in the following.

    PS> nums <- 0.3 + 2e-16 * c(-2,-1,1,2)
    PS> factor(nums)
    PS> # [1] 0.3 0.3 0.3 0.3
    PS> # Levels: 0.3

yes, of course.

    PS> Petr.

[.....]

I have very slightly  modified the changes (to get rid of -Wall
warnings) and also exported the function as Rf_dropTrailing0(),
and tested the result with 'make check-all' .
As the change seems reasonable and consequent, and as
it seems not to produce any problems in our tests, 
I'm hereby proposing to commit it (my version of it),
[to R-devel only] within a few days,
unless someone speaks up.

Martin Maechler, ETH Zurich

   PS> --- R-devel/src/main/coerce.c	2009-04-17 17:53:35.000000000 +0200
    PS> +++ R-devel-elim-trailing/src/main/coerce.c	2009-05-23 08:39:03.914774176 +0200
    PS> @@ -294,12 +294,33 @@
    PS> else return mkChar(EncodeInteger(x, w));
    PS> }
 
    PS> +const char *elim_trailing(const char *s, char cdec)
    PS> +{
    PS> +    const char *p;
    PS> +    char *replace;
    PS> +    for (p = s; *p; p++) {
    PS> +        if (*p == cdec) {
    PS> +            replace = (char *) p++;
    PS> +            while ('0' <= *p & *p <= '9') {
    PS> +                if (*(p++) != '0') {
    PS> +                    replace = (char *) p;
    PS> +                }
    PS> +            }
    PS> +            while (*(replace++) = *(p++)) {
    PS> +                ;
    PS> +            }
    PS> +            break;
    PS> +        }
    PS> +    }
    PS> +    return s;
    PS> +}
    PS> +
    PS> SEXP attribute_hidden StringFromReal(double x, int *warn)
    PS> {
    PS> int w, d, e;
    PS> formatReal(&x, 1, &w, &d, &e, 0);
    PS> if (ISNA(x)) return NA_STRING;
    PS> -    else return mkChar(EncodeReal(x, w, d, e, OutDec));
    PS> +    else return mkChar(elim_trailing(EncodeReal(x, w, d, e, OutDec), OutDec));
    PS> }
 
    PS> SEXP attribute_hidden StringFromComplex(Rcomplex x, int *warn)


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Wed May 27 22:54:05 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Wed, 27 May 2009 22:54:05 +0200
Subject: [Rd] minor correction to the r internals manual
Message-ID: <4A1DA86D.3080806@idi.ntnu.no>

sec. 1.1 says:

"both types of node structure have as their first three fields a 32-bit
sxpinfo header and then three pointers [...]"

that's *four* fields, as seen in src/include/Rinternals.h:208+:

#define SEXPREC_HEADER \
    struct sxpinfo_struct sxpinfo; \
    struct SEXPREC *attrib; \
    struct SEXPREC *gengc_next_node, *gengc_prev_node

vQ


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Thu May 28 00:36:07 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Thu, 28 May 2009 00:36:07 +0200
Subject: [Rd] as.numeric(levels(factor(x))) may be a decreasing sequence
In-Reply-To: <18973.42970.826686.173830@cmath-5.math.ethz.ch>
References: <20090523074454.GA17112@cs.cas.cz>
	<18973.42970.826686.173830@cmath-5.math.ethz.ch>
Message-ID: <4A1DC057.80401@idi.ntnu.no>

Martin Maechler wrote:
>
> I have very slightly  modified the changes (to get rid of -Wall
> warnings) and also exported the function as Rf_dropTrailing0(),
> and tested the result with 'make check-all' .
> As the change seems reasonable and consequent, and as
> it seems not to produce any problems in our tests, 
> I'm hereby proposing to commit it (my version of it),
> [to R-devel only] within a few days,
> unless someone speaks up.
>
>   

i may be misunderstanding the code, but:


> Martin Maechler, ETH Zurich
>
>    PS> --- R-devel/src/main/coerce.c	2009-04-17 17:53:35.000000000 +0200
>     PS> +++ R-devel-elim-trailing/src/main/coerce.c	2009-05-23 08:39:03.914774176 +0200
>     PS> @@ -294,12 +294,33 @@
>     PS> else return mkChar(EncodeInteger(x, w));
>     PS> }
>  
>     PS> +const char *elim_trailing(const char *s, char cdec)
>   

the first argument is const char*, which usually means a contract
promising not to change the content of the pointed-to object

>     PS> +{
>     PS> +    const char *p;
>     PS> +    char *replace;
>     PS> +    for (p = s; *p; p++) {
>     PS> +        if (*p == cdec) {
>     PS> +            replace = (char *) p++;
>   

const char* p is cast to non-const char* replace

>     PS> +            while ('0' <= *p & *p <= '9') {
>     PS> +                if (*(p++) != '0') {
>     PS> +                    replace = (char *) p;
>   

likewise

>     PS> +                }
>     PS> +            }
>     PS> +            while (*(replace++) = *(p++)) {
>   

the char* replace is assigned to -- effectively, the content of the
promised-to-be-constant string s is modified, and the modification may
involve any character in the string.  (it's a no-compile-error contract
violation;  not an uncommon pattern, but not good practice either.)

>     PS> +                ;
>     PS> +            }
>     PS> +            break;
>     PS> +        }
>     PS> +    }
>     PS> +    return s;
>   

you return s, which should be the same pointer value (given the actual
code that does not modify the local variable s) with the same pointed-to
string value (given the signature of the function).

was perhaps

    char *elim_trailing(char* const s, char cdec)

intended?  anyway, having the pointer s itself declared as const does
make sense, as the code seems to assume that exactly the input pointer
value should be returned.  or maybe the argument to elim_trailing should
not be declared as const, since elim_trailing violates the declaration. 

one way out is to drop the violated const in both the actual argument
and in elim_trailing, which would then be simplified by removing all
const qualifiers and (char*) casts.  another way out is to make
elim_trailing actually allocate and return a new string, keeping the
input truly constant, at a performance cost    .  yet another way is to
ignore the issue, of course.

the original (martin/petr) version may quietly pass -Wall, but the
compiler would complain (rightfully) with -Wcast-qual.


vQ


From Mark.Bravington at csiro.au  Thu May 28 07:45:22 2009
From: Mark.Bravington at csiro.au (Mark.Bravington at csiro.au)
Date: Thu, 28 May 2009 15:45:22 +1000
Subject: [Rd] internal and external debugging [was: [R] step by step
 debugger in R?]
Message-ID: <62C82B39B8A85E4B95A18F7F7B852F87053E3738F5@exvic-mbx03.nexus.csiro.au>

Hello all

I'm coming late to this discussion, and my comments may now be beside the point-- but I have been intending to ask what people think of the pros & cons of internal and external (e.g. 'debug' package) debuggers. When I wrote 'debug', the internal debugger just didn't do what I wanted, but maybe things have changed-- hence this email, to find out. The particular facilities in 'debug' that I'm thinking of, are

   - Graceful error trapping. In 'debug', I can just run til it crashes, then figure out what's up and carry on if desired-- often in conjunction with...
   
   - 'skip', to move the execution point around. I use this all the time, often after a graceful error trap, to replace a dodgy bit of code with the correct version, and then skip round the bad version to carry on.
   
   - the conditional breakpoint facilities, including debugging of on-exit code.
 
Can these be done with internal debugging?
 
The main negative issues I have seen with 'debug' are:

   - very clunky tcl/tk interface, and inability to see proper source code;

   - (occasionally) speed-- although this can often be gotten round with a bit of ingenuity;

   - some more "special cases" that I should add, e.g. to trace into 'try' statements;

   - a few maggots in the code barrel due to changes in R over the years.
   
I try to catch up with the 3rd & 4th from time to time, and would be very happy if anyone can help with the 1st (Romain did already offer as part of summer-of-code, though the project didn't get up).

If anyone has other thoughts on bad things in, or good things not in, 'debug', then I would consider adding them.
   
Finally, my 2c from experience with 'debug': writing it was very hard work. Debugger-writing seems to be a case where one can one can get *something* working quite quickly-- and then get sucked in to a very long and painful process. The effort I spent has been repaid many times over, but...

Mark Bravington

CSIRO, Hobart, Australia

> >> There is also the debug package [3,4] which does __not__ work with R
> >> internals but rather works with instrumenting tricks at the R level.
> >> debug provides a tcl/tk front-end. It is my understanding that it does
> >> not work using R internals (do_browser, ...) because it was not possible
> >> at the time, and I believe this is still not possible today, but I might
> >> be wrong. I'd prefer to be wrong actually.
> >>    
> >
> >   I don't understand this statement. It has always been possible to work with
> > the internal version - but one can also take the approach of rewriting code.
> > There are some difficulties supporting all the operations that one would like by
> > rewriting code and I think a combination of external controls and the internal
> > debugger will get most of the functionality that anyone wants.
> >  
> 
> I understand now the confusion. I meant that the debug package does not
> use functions like debug and browser. I think this is because once you
> enter into "browser", only the user gets the right to type commands in,
> and there is a need for (for example) automatically updating the editor
> when a given breakpoint is reached, ...
> 
> I did not mean that R internal debugging failed to work.
> 
> >   There are somethings that are hard and once I have a more complete list I will
> > be adding this to the appropriate manual. I will also be documenting the changes
> > that I have been making, but that project is in flux and won't be done until the
> > end of August, so people who want to look at it are welcome (it is in R-devel),
> > but it is in development and could change pretty much without notice.
> >   Romain noted that we now support stepping out from one place to another
> > function.  We also have a debugonce flag that lets you get close to step in, but
> > step in is very hard in R.
> >
> >   I am mostly interested in writing tools in R that can be used by anyone that
> > wants to write an external debugger and am not that interested in any particular
> > external debugger. I would be happy to listen to feature requests or issues that
> > arise - but the discussion should probably be on R-devel mailing list.
> >  
> I am very interested in making one (or very likely several) front-ends
> using these tools.
> 
> 
> >   best wishes
> >     Robert
> >
> >
> >  
> >> Romain
> >>
> >> [1] : http://www.r-project.org/soc09/ideas.html#p5
> >> [2] : https://stat.ethz.ch/pipermail/r-devel/2009-April/053128.html
> >> [3] : http://cran.r-project.org/web/packages/debug/index.html
> >> [4] : http://cran.r-project.org/doc/Rnews/Rnews_2003-3.pdf
> >>
> >>    
> >
> >  
> 
> 
> -- 
> Romain Francois
> Independent R Consultant
> +33(0) 6 28 91 30 30
> http://romainfrancois.blog.free.fr
> 


From ripley at stats.ox.ac.uk  Thu May 28 08:50:09 2009
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 28 May 2009 07:50:09 +0100 (BST)
Subject: [Rd] Bug in "$<-.data.frame" yields corrupt data frame
 (PR#13724)
In-Reply-To: <20090526225011.3635B28320BC@mail.pubhealth.ku.dk>
References: <20090526225011.3635B28320BC@mail.pubhealth.ku.dk>
Message-ID: <alpine.LFD.2.00.0905280744580.17493@gannet.stats.ox.ac.uk>

> Would the above modification work to fix this problem?

Yes thank you, and I've incorporated it in R-patched and R-devel.

It does catch 3 packages, DescribeDisplay, rgcvpack and BioC:rHVDM.

On Wed, 27 May 2009, smckinney at bccrc.ca wrote:

> Full_Name: Steven McKinney
> Version: 2.9.0
> OS: Mac OS X 10.5.6
> Submission from: (NULL) (142.103.207.10)
>
>
>
> A corrupt data frame can be constructed as follows:
> foo <- matrix(1:12, nrow = 3)
> bar <- data.frame(foo)
> bar$NewCol <- foo[foo[, 1] == 4, 4]
> bar
> lapply(bar, length)
>
>
>
>
>> foo <- matrix(1:12, nrow = 3)
>> bar <- data.frame(foo)
>> bar$NewCol <- foo[foo[, 1] == 4, 4] bar
>   X1 X2 X3 X4 NewCol
> 1  1  4  7 10   <NA>
> 2  2  5  8 11   <NA>
> 3  3  6  9 12   <NA>
> Warning message:
> In format.data.frame(x, digits = digits, na.encode = FALSE) :
>   corrupt data frame: columns will be truncated or padded with NAs
>> lapply(bar, length)
> $X1
> [1] 3
>
> $X2
> [1] 3
>
> $X3
> [1] 3
>
> $X4
> [1] 3
>
> $NewCol
> [1] 0
>
>
> The data.frame method is
>
>> getAnywhere("$<-.data.frame" )
> A single object matching '$<-.data.frame' was found It was found in the
> following places
>  package:base
>  registered S3 method for $<- from namespace base
>  namespace:base
> with value
>
> function (x, i, value)
> {
>    cl <- oldClass(x)
>    class(x) <- NULL
>    nrows <- .row_names_info(x, 2L)
>    if (!is.null(value)) {
>        N <- NROW(value)
>        if (N > nrows)
>            stop(gettextf("replacement has %d rows, data has %d",
>                N, nrows), domain = NA)
>        if (N < nrows && N > 0L)
>            if (nrows%%N == 0L && length(dim(value)) <= 1L)
>                value <- rep(value, length.out = nrows)
>            else stop(gettextf("replacement has %d rows, data has %d",
>                N, nrows), domain = NA)
>        if (is.atomic(value))
>            names(value) <- NULL
>    }
>    x[[i]] <- value
>    class(x) <- cl
>    return(x)
> }<environment: namespace:base>
>>
>
>
> I placed a browser() command before return(x) and did some poking
> around.  The issue is that the example above creates an object with
> N < nrows but N == 0L, so either an else clause to check for this
> condition is needed, or, it appears to me, the N > 0L part of the
> conditional clause needs to be moved to the next if clause.
>
> I modified the rows
>          if (N < nrows && N > 0L)
>            if (nrows%%N == 0L && length(dim(value)) <= 1L)
> to read
>           if (N < nrows)
>            if (N > 0L && nrows%%N == 0L && length(dim(value)) <= 1L)
>
> as in
>
> "$<-.data.frame" <-
> function (x, i, value)
> {
>    cl <- oldClass(x)
>    class(x) <- NULL
>    nrows <- .row_names_info(x, 2L)
>    if (!is.null(value)) {
>        N <- NROW(value)
>        if (N > nrows)
>            stop(gettextf("replacement has %d rows, data has %d",
>                N, nrows), domain = NA)
>        if (N < nrows)
>            if (N > 0L && nrows%%N == 0L && length(dim(value)) <= 1L)
>                value <- rep(value, length.out = nrows)
>            else stop(gettextf("replacement has %d rows, data has %d",
>                N, nrows), domain = NA)
>        if (is.atomic(value))
>            names(value) <- NULL
>    }
>    x[[i]] <- value
>    class(x) <- cl
>    return(x)
> }
>
> Now it detects the problem above:
>
>> foo <- matrix(1:12, nrow = 3)
>> bar <- data.frame(foo)
>> bar$NewCol <- foo[foo[, 1] == 4, 4]
> Error in `$<-.data.frame`(`*tmp*`, "NewCol", value = integer(0)) :
>  replacement has 0 rows, data has 3
>
> It doesn't appear to stumble on weird data frames (these from the
> ?data.frame help page)
>
>
>> L3 <- LETTERS[1:3]
>> (d <- data.frame(cbind(x=1, y=1:10), fac=sample(L3, 10,
> replace=TRUE)))
>> (d0  <- d[, FALSE]) # NULL data frame with 10 rows
>
>> (d.0 <- d[FALSE, ]) # <0 rows> data frame  (3 cols)
>
>> (d00 <- d0[FALSE,])  # NULL data frame with 0 rows
>
>> d0$NewCol <- foo[foo[, 1] == 4, 4]
> Error in `$<-.data.frame`(`*tmp*`, "NewCol", value = integer(0)) :
>  replacement has 0 rows, data has 10
>
> ### Catches this problem above alright.
>
>> d.0$NewCol <- foo[foo[, 1] == 4, 4]
>> d.0
> [1] x      y      fac    NewCol
> <0 rows> (or 0-length row.names)
>
> ### Lets the above one through alright.
>
>> d00$NewCol <- foo[foo[, 1] == 4, 4]
>>
>> d00
> [1] NewCol
> <0 rows> (or 0-length row.names)
> ### Lets the above one through alright.
>
>
> Would the above modification work to fix this problem?
>
>
>
>
>
>
>> sessionInfo()
> R version 2.9.0 (2009-04-17)
> powerpc-apple-darwin8.11.1
>
> locale:
> en_CA.UTF-8/en_CA.UTF-8/C/C/en_CA.UTF-8/en_CA.UTF-8
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] nlme_3.1-90
>
> loaded via a namespace (and not attached):
> [1] grid_2.9.0      lattice_0.17-22 tools_2.9.0
>
>
> Also occurs on Windows box with R 2.8.1
>
>
>
> Steven McKinney
>
> Statistician
> Molecular Oncology and Breast Cancer Program British Columbia Cancer
> Research Centre
>
> email: smckinney +at+ bccrc +dot+ ca
>
> tel: 604-675-8000 x7561
>
> BCCRC
> Molecular Oncology
> 675 West 10th Ave, Floor 4
> Vancouver B.C.
> V5Z 1L3
> Canada
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From romain.francois at dbmail.com  Thu May 28 09:32:00 2009
From: romain.francois at dbmail.com (Romain Francois)
Date: Thu, 28 May 2009 09:32:00 +0200
Subject: [Rd] internal and external debugging [was: [R] step by step
 debugger in R?]
In-Reply-To: <62C82B39B8A85E4B95A18F7F7B852F87053E3738F5@exvic-mbx03.nexus.csiro.au>
References: <62C82B39B8A85E4B95A18F7F7B852F87053E3738F5@exvic-mbx03.nexus.csiro.au>
Message-ID: <4A1E3DF0.9090808@dbmail.com>


Hi,

Thank you for these comments. I think it does indeed add to the 
discussion and provides a good reference. I have added a few comments below.

Mark.Bravington at csiro.au wrote:
> Hello all
>
> I'm coming late to this discussion, and my comments may now be beside the point-- but I have been intending to ask what people think of the pros & cons of internal and external (e.g. 'debug' package) debuggers. When I wrote 'debug', the internal debugger just didn't do what I wanted, but maybe things have changed-- hence this email, to find out. The particular facilities in 'debug' that I'm thinking of, are
>
>    - Graceful error trapping. In 'debug', I can just run til it crashes, then figure out what's up and carry on if desired-- often in conjunction with...
>   

options( error = recover ) lets you examine what did cause the crash. 
AFAIK, it does not let you carry on.

>    
>    - 'skip', to move the execution point around. I use this all the time, often after a graceful error trap, to replace a dodgy bit of code with the correct version, and then skip round the bad version to carry on.
>   

I am not sure I understand completely here, but I think the new 
facilities implemented by Robert Gentleman are going in this direction. 
once in a browser, you can use browserSetDebug to jump up one or more 
frames in the stack.

>    
>    - the conditional breakpoint facilities, including debugging of on-exit code.
>   

browser now (in R-devel) has a "expr" argument that I think controls 
whether to actually enter the browser or not.

Also, with the work Duncan Murdoch has been doing recently on keeping 
the srcref records as part of the stack, we are not too far from the 
ability to create breakpoints without actually typing in "browser()" in 
the code, i.e. something similar to trace(...,at=) where at would not be 
a step in the list of expressions of the function but a srcref record. 
This would great from a visual debugger point of view.

Romain

>  
> Can these be done with internal debugging?
>  
> The main negative issues I have seen with 'debug' are:
>
>    - very clunky tcl/tk interface, and inability to see proper source code;
>
>    - (occasionally) speed-- although this can often be gotten round with a bit of ingenuity;
>
>    - some more "special cases" that I should add, e.g. to trace into 'try' statements;
>
>    - a few maggots in the code barrel due to changes in R over the years.
>    
> I try to catch up with the 3rd & 4th from time to time, and would be very happy if anyone can help with the 1st (Romain did already offer as part of summer-of-code, though the project didn't get up).
>
> If anyone has other thoughts on bad things in, or good things not in, 'debug', then I would consider adding them.
>    
> Finally, my 2c from experience with 'debug': writing it was very hard work. Debugger-writing seems to be a case where one can one can get *something* working quite quickly-- and then get sucked in to a very long and painful process. The effort I spent has been repaid many times over, but...
>
> Mark Bravington
>
> CSIRO, Hobart, Australia
>
>   
>>>> There is also the debug package [3,4] which does __not__ work with R
>>>> internals but rather works with instrumenting tricks at the R level.
>>>> debug provides a tcl/tk front-end. It is my understanding that it does
>>>> not work using R internals (do_browser, ...) because it was not possible
>>>> at the time, and I believe this is still not possible today, but I might
>>>> be wrong. I'd prefer to be wrong actually.
>>>>    
>>>>         
>>>   I don't understand this statement. It has always been possible to work with
>>> the internal version - but one can also take the approach of rewriting code.
>>> There are some difficulties supporting all the operations that one would like by
>>> rewriting code and I think a combination of external controls and the internal
>>> debugger will get most of the functionality that anyone wants.
>>>  
>>>       
>> I understand now the confusion. I meant that the debug package does not
>> use functions like debug and browser. I think this is because once you
>> enter into "browser", only the user gets the right to type commands in,
>> and there is a need for (for example) automatically updating the editor
>> when a given breakpoint is reached, ...
>>
>> I did not mean that R internal debugging failed to work.
>>
>>     
>>>   There are somethings that are hard and once I have a more complete list I will
>>> be adding this to the appropriate manual. I will also be documenting the changes
>>> that I have been making, but that project is in flux and won't be done until the
>>> end of August, so people who want to look at it are welcome (it is in R-devel),
>>> but it is in development and could change pretty much without notice.
>>>   Romain noted that we now support stepping out from one place to another
>>> function.  We also have a debugonce flag that lets you get close to step in, but
>>> step in is very hard in R.
>>>
>>>   I am mostly interested in writing tools in R that can be used by anyone that
>>> wants to write an external debugger and am not that interested in any particular
>>> external debugger. I would be happy to listen to feature requests or issues that
>>> arise - but the discussion should probably be on R-devel mailing list.
>>>  
>>>       
>> I am very interested in making one (or very likely several) front-ends
>> using these tools.
>>
>>
>>     
>>>   best wishes
>>>     Robert
>>>
>>>
>>>  
>>>       
>>>> Romain
>>>>
>>>> [1] : http://www.r-project.org/soc09/ideas.html#p5
>>>> [2] : https://stat.ethz.ch/pipermail/r-devel/2009-April/053128.html
>>>> [3] : http://cran.r-project.org/web/packages/debug/index.html
>>>> [4] : http://cran.r-project.org/doc/Rnews/Rnews_2003-3.pdf
>>>>
>>>>    
>>>>         
>>>  
>>>       
>> -- 
>> Romain Francois
>> Independent R Consultant
>> +33(0) 6 28 91 30 30
>> http://romainfrancois.blog.free.fr
>>
>>     
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>
>   


-- 
Romain Francois
Independent R Consultant
+33(0) 6 28 91 30 30
http://romainfrancois.blog.free.fr


From savicky at cs.cas.cz  Thu May 28 09:36:48 2009
From: savicky at cs.cas.cz (Petr Savicky)
Date: Thu, 28 May 2009 09:36:48 +0200
Subject: [Rd] as.numeric(levels(factor(x))) may be a decreasing sequence
In-Reply-To: <18973.42970.826686.173830@cmath-5.math.ethz.ch>
References: <20090523074454.GA17112@cs.cas.cz>
	<18973.42970.826686.173830@cmath-5.math.ethz.ch>
Message-ID: <20090528073648.GA18207@cs.cas.cz>

On Wed, May 27, 2009 at 10:51:38PM +0200, Martin Maechler wrote:
> I have very slightly  modified the changes (to get rid of -Wall
> warnings) and also exported the function as Rf_dropTrailing0(),
> and tested the result with 'make check-all' .

Thank you very much for considering the patch. -Wall indeed requires to add 
parentheses
  warning: suggest parentheses around comparison in operand of &
  warning: suggest parentheses around assignment used as truth value

If there are also other changes, i would like to ask you to make your modification
available, mainly due to a possible further discussion.

Let me also suggest a modification of my original proposal. It contains a cycle
           while (*(replace++) = *(p++)) {
               ;
           }
If the number has no trailing zeros, but contains an exponent, this cycle
shifts the exponent by 0 positions, which means that it copies each of its
characters to itself. This may be eliminated as follows
           if (replace != p) {
               while (*(replace++) = *(p++)) {
                   ;
               }
           }

Petr.


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Thu May 28 14:30:14 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Thu, 28 May 2009 14:30:14 +0200
Subject: [Rd] [R] split strings
In-Reply-To: <4A1CF4CE.8040306@idi.ntnu.no>
References: <BAY130-W260FD8C24AA6B865027A0BC3520@phx.gbl>	<4A1BF2AD.7040902@idi.ntnu.no>	<BAY130-W2070E9FB3B7C8A08D2A64BC3520@phx.gbl>	<4A1C501B.8020103@idi.ntnu.no>	<971536df0905261340q2a1df85av7a272f30b5230b87@mail.gmail.com>	<4A1CDEE6.40104@cybaea.com>
	<4A1CF4CE.8040306@idi.ntnu.no>
Message-ID: <4A1E83D6.1020602@idi.ntnu.no>

(diverted to r-devel, a source code patch attached)

Wacek Kusnierczyk wrote:
> Allan Engelhardt wrote:
>   
>> Immaterial, yes, but it is always good to test :) and your solution
>> *is* faster and it is even faster if you can assume byte strings:
>>     
>
> :)
>
> indeed;  though if the speed is immaterial (and in this case it
> supposedly was), it's probably not worth risking fixed=TRUE removing
> '.tif' from the middle of the name, however unlikely this might be (cf
> murphy's laws).
>
> but if you can assume that each string ends with a '.tif' (or any other
> \..{3} substring), then substr is marginally faster than sub, even as a
> three-pass approach, while avoiding the risk of removing '.tif' from the
> middle:
>
>     strings = sprintf('f:/foo/bar//%s.tif', replicate(1000,
> paste(sample(letters, 10), collapse='')))
>     library(rbenchmark)
>     benchmark(columns=c('test', 'elapsed'), replications=1000, order=NULL,
>        substr={basenames=basename(strings); substr(basenames, 1,
> nchar(basenames)-4)},
>        sub=sub('.tif', '', basename(strings), fixed=TRUE, useBytes=TRUE))
>     #     test elapsed
>     # 1 substr   3.176
>     # 2    sub   3.296
>   

btw., i wonder why negative indices default to 1 in substr:

    substr('foobar', -5, 5)
    # "fooba"
    # substr('foobar', 1, 5)
    substr('foobar', 2, -2)
    # ""
    # substr('foobar', 2, 1)

this does not seem to be documented in ?substr.  there are ways to make
negative indices meaningful, e.g., by taking them as indexing from
behind (as in, e.g., perl):

    # hypothetical
    substr('foobar', -5, 5)
    # "ooba"
    # substr('foobar', 6-5+1, 5)
    substr('foobar', 2, -2)
    # "ooba"
    # substr('foobar', 2, 6-2+1)

there is a trivial fix to src/main/character.c that gives substr the
extended functionality -- see the attached patch.  the patch has been
created and tested as follows:

    svn co https://svn.r-project.org/R/trunk r-devel
    cd r-devel
    # modifications made to src/main/character.c
    svn diff > character.c.diff
    svn revert -R .
    patch -p0 < character.c.diff
   
    ./configure
    make
    make check-all
    # no problems reported

with the patched substr, the original problem can now be solved more
concisely, using a two-pass approach, with performance still better than
the sub/fixed/bytes one, as follows:

    strings = sprintf('f:/foo/bar//%s.tif', replicate(1000,
    paste(sample(letters, 10), collapse='')))
    library(rbenchmark)
    benchmark(columns=c('test', 'elapsed'), replications=1000, order=NULL,
        substr=substr(basename(strings), 1, -5),
        'substr-nchar'={
            basenames=basename(strings)
            substr(basenames, 1, nchar(basenames)-4) },
        sub=sub('.tif', '', basename(strings), fixed=TRUE, useBytes=TRUE))
    #     test elapsed
    # 1       substr   2.981
    # 2 substr-nchar   3.206
    # 3          sub   3.273

if this sounds interesting, i can update the docs accordingly.

vQ
-------------- next part --------------
A non-text attachment was scrubbed...
Name: character.c.diff
Type: text/x-diff
Size: 597 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090528/d1381eb7/attachment.bin>

From wdunlap at tibco.com  Thu May 28 15:23:17 2009
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 28 May 2009 06:23:17 -0700
Subject: [Rd] [R] split strings
In-Reply-To: <4A1E83D6.1020602@idi.ntnu.no>
References: <BAY130-W260FD8C24AA6B865027A0BC3520@phx.gbl>	<4A1BF2AD.7040902@idi.ntnu.no>	<BAY130-W2070E9FB3B7C8A08D2A64BC3520@phx.gbl>	<4A1C501B.8020103@idi.ntnu.no>	<971536df0905261340q2a1df85av7a272f30b5230b87@mail.gmail.com>	<4A1CDEE6.40104@cybaea.com><4A1CF4CE.8040306@idi.ntnu.no>
	<4A1E83D6.1020602@idi.ntnu.no>
Message-ID: <77EB52C6DD32BA4D87471DCD70C8D700013DBE67@NA-PA-VBE03.na.tibco.com>



Bill Dunlap
TIBCO Software Inc - Spotfire Division
wdunlap tibco.com  

> -----Original Message-----
> From: r-devel-bounces at r-project.org 
> [mailto:r-devel-bounces at r-project.org] On Behalf Of Wacek Kusnierczyk
> Sent: Thursday, May 28, 2009 5:30 AM
> Cc: R help project; r-devel at r-project.org; Allan Engelhardt
> Subject: Re: [Rd] [R] split strings
> 
> (diverted to r-devel, a source code patch attached)
> 
> Wacek Kusnierczyk wrote:
> > Allan Engelhardt wrote:
> >   
> >> Immaterial, yes, but it is always good to test :) and your solution
> >> *is* faster and it is even faster if you can assume byte strings:
> >>     
> >
> > :)
> >
> > indeed;  though if the speed is immaterial (and in this case it
> > supposedly was), it's probably not worth risking fixed=TRUE removing
> > '.tif' from the middle of the name, however unlikely this 
> might be (cf
> > murphy's laws).
> >
> > but if you can assume that each string ends with a '.tif' 
> (or any other
> > \..{3} substring), then substr is marginally faster than 
> sub, even as a
> > three-pass approach, while avoiding the risk of removing 
> '.tif' from the
> > middle:
> >
> >     strings = sprintf('f:/foo/bar//%s.tif', replicate(1000,
> > paste(sample(letters, 10), collapse='')))
> >     library(rbenchmark)
> >     benchmark(columns=c('test', 'elapsed'), 
> replications=1000, order=NULL,
> >        substr={basenames=basename(strings); substr(basenames, 1,
> > nchar(basenames)-4)},
> >        sub=sub('.tif', '', basename(strings), fixed=TRUE, 
> useBytes=TRUE))
> >     #     test elapsed
> >     # 1 substr   3.176
> >     # 2    sub   3.296
> >   
> 
> btw., i wonder why negative indices default to 1 in substr:
> 
>     substr('foobar', -5, 5)
>     # "fooba"
>     # substr('foobar', 1, 5)
>     substr('foobar', 2, -2)
>     # ""
>     # substr('foobar', 2, 1)
> 
> this does not seem to be documented in ?substr.

Would your patched code affect the following
use of regexpr's output as input to substr, to
pull out the matched text from the string?
   > x<-c("ooo","good food","bad")
   > r<-regexpr("o+", x)
   > substring(x,r,attr(r,"match.length")+r-1)
   [1] "ooo" "oo"  ""   
   > substr(x,r,attr(r,"match.length")+r-1)
   [1] "ooo" "oo"  ""   
   > r
   [1]  1  2 -1
   attr(,"match.length")
   [1]  3  2 -1
   > attr(r,"match.length")+r-1
   [1]  3  3 -3
   attr(,"match.length")
   [1]  3  2 -1

>  there are 
> ways to make
> negative indices meaningful, e.g., by taking them as indexing from
> behind (as in, e.g., perl):
> 
>     # hypothetical
>     substr('foobar', -5, 5)
>     # "ooba"
>     # substr('foobar', 6-5+1, 5)
>     substr('foobar', 2, -2)
>     # "ooba"
>     # substr('foobar', 2, 6-2+1)
> 
> there is a trivial fix to src/main/character.c that gives substr the
> extended functionality -- see the attached patch.  the patch has been
> created and tested as follows:
> 
>     svn co https://svn.r-project.org/R/trunk r-devel
>     cd r-devel
>     # modifications made to src/main/character.c
>     svn diff > character.c.diff
>     svn revert -R .
>     patch -p0 < character.c.diff
>    
>     ./configure
>     make
>     make check-all
>     # no problems reported
> 
> with the patched substr, the original problem can now be solved more
> concisely, using a two-pass approach, with performance still 
> better than
> the sub/fixed/bytes one, as follows:
> 
>     strings = sprintf('f:/foo/bar//%s.tif', replicate(1000,
>     paste(sample(letters, 10), collapse='')))
>     library(rbenchmark)
>     benchmark(columns=c('test', 'elapsed'), 
> replications=1000, order=NULL,
>         substr=substr(basename(strings), 1, -5),
>         'substr-nchar'={
>             basenames=basename(strings)
>             substr(basenames, 1, nchar(basenames)-4) },
>         sub=sub('.tif', '', basename(strings), fixed=TRUE, 
> useBytes=TRUE))
>     #     test elapsed
>     # 1       substr   2.981
>     # 2 substr-nchar   3.206
>     # 3          sub   3.273
> 
> if this sounds interesting, i can update the docs accordingly.
> 
> vQ
> 


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Thu May 28 15:50:33 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Thu, 28 May 2009 15:50:33 +0200
Subject: [Rd] [R]   split strings
In-Reply-To: <77EB52C6DD32BA4D87471DCD70C8D700013DBE67@NA-PA-VBE03.na.tibco.com>
References: <BAY130-W260FD8C24AA6B865027A0BC3520@phx.gbl>	<4A1BF2AD.7040902@idi.ntnu.no>	<BAY130-W2070E9FB3B7C8A08D2A64BC3520@phx.gbl>	<4A1C501B.8020103@idi.ntnu.no>	<971536df0905261340q2a1df85av7a272f30b5230b87@mail.gmail.com>	<4A1CDEE6.40104@cybaea.com><4A1CF4CE.8040306@idi.ntnu.no>	<4A1E83D6.1020602@idi.ntnu.no>
	<77EB52C6DD32BA4D87471DCD70C8D700013DBE67@NA-PA-VBE03.na.tibco.com>
Message-ID: <4A1E96A9.6080802@idi.ntnu.no>

William Dunlap wrote:
>
> Would your patched code affect the following
> use of regexpr's output as input to substr, to
> pull out the matched text from the string?
>    > x<-c("ooo","good food","bad")
>    > r<-regexpr("o+", x)
>    > substring(x,r,attr(r,"match.length")+r-1)
>    [1] "ooo" "oo"  ""   
>   

no; same output

>    > substr(x,r,attr(r,"match.length")+r-1)
>    [1] "ooo" "oo"  ""   
>   

no; same output

>    > r
>    [1]  1  2 -1
>    attr(,"match.length")
>    [1]  3  2 -1
>    > attr(r,"match.length")+r-1
>    [1]  3  3 -3
>    attr(,"match.length")
>    [1]  3  2 -1
>   

for the positive indices there is no change, as you might expect.

if i understand your concern, the issue is that regexpr returns -1 (with
the corresponding attribute -1) where there is no match.  in this case,
you expect "" as the substring. 

if there is no match, we have:

    start = r = -1 (the start you index provide)
    stop = attr(r) + r - 1 = -1 + -1 -1 = -3 (the stop index you provide)

for a string of length n, my patch computes the final indices as follows:

    start' = n + start - 1
    stop' = n + stop - 1

whatever the value of n, stop' - start' = stop - start = -3 - 1 = -4. 
that is, stop' < start', hence an empty string is returned, by virtue of
the original code.  (see the sources for details.)

does this answer your question?

vQ


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Thu May 28 16:05:28 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Thu, 28 May 2009 16:05:28 +0200
Subject: [Rd] [R]   split strings
In-Reply-To: <4A1E96A9.6080802@idi.ntnu.no>
References: <BAY130-W260FD8C24AA6B865027A0BC3520@phx.gbl>	<4A1BF2AD.7040902@idi.ntnu.no>	<BAY130-W2070E9FB3B7C8A08D2A64BC3520@phx.gbl>	<4A1C501B.8020103@idi.ntnu.no>	<971536df0905261340q2a1df85av7a272f30b5230b87@mail.gmail.com>	<4A1CDEE6.40104@cybaea.com><4A1CF4CE.8040306@idi.ntnu.no>	<4A1E83D6.1020602@idi.ntnu.no>	<77EB52C6DD32BA4D87471DCD70C8D700013DBE67@NA-PA-VBE03.na.tibco.com>
	<4A1E96A9.6080802@idi.ntnu.no>
Message-ID: <4A1E9A28.6070206@idi.ntnu.no>

Wacek Kusnierczyk wrote:
> William Dunlap wrote:
>   
>> Would your patched code affect the following
>> use of regexpr's output as input to substr, to
>> pull out the matched text from the string?
>>    > x<-c("ooo","good food","bad")
>>    > r<-regexpr("o+", x)
>>    > substring(x,r,attr(r,"match.length")+r-1)
>>    [1] "ooo" "oo"  ""   
>>   
>>     
>
> no; same output
>
>   
>>    > substr(x,r,attr(r,"match.length")+r-1)
>>    [1] "ooo" "oo"  ""   
>>   
>>     
>
> no; same output
>
>   
>>    > r
>>    [1]  1  2 -1
>>    attr(,"match.length")
>>    [1]  3  2 -1
>>    > attr(r,"match.length")+r-1
>>    [1]  3  3 -3
>>    attr(,"match.length")
>>    [1]  3  2 -1
>>   
>>     
>
> for the positive indices there is no change, as you might expect.
>
> if i understand your concern, the issue is that regexpr returns -1 (with
> the corresponding attribute -1) where there is no match.  in this case,
> you expect "" as the substring. 
>
> if there is no match, we have:
>
>     start = r = -1 (the start you index provide)
>     stop = attr(r) + r - 1 = -1 + -1 -1 = -3 (the stop index you provide)
>
> for a string of length n, my patch computes the final indices as follows:
>
>     start' = n + start - 1
>     stop' = n + stop - 1
>
> whatever the value of n, stop' - start' = stop - start = -3 - 1 = -4. 
>   

except for that stop - start = -3 - -1 = -2, but that's still negative,
i.e., stop' < start'.
silly me, sorry.

vQ

> that is, stop' < start', hence an empty string is returned, by virtue of
> the original code.  (see the sources for details.)
>
> does this answer your question?
>
>


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Fri May 29 09:49:43 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Fri, 29 May 2009 09:49:43 +0200
Subject: [Rd] bug in strsplit?
Message-ID: <4A1F9397.5050809@idi.ntnu.no>

src/main/character.c:435-438 (do_strsplit) contains the following code:

    for (i = 0; i < tlen; i++)
        if (getCharCE(STRING_ELT(tok, 0)) == CE_UTF8) use_UTF8 = TRUE;
    for (i = 0; i < len; i++)
        if (getCharCE(STRING_ELT(x, 0)) == CE_UTF8) use_UTF8 = TRUE;

since both loops iterate over loop-invariant expressions and statements,
either the loops are redundant, or the fixed index '0' was meant to
actually be the variable i.  i guess it's the latter, hence 'bug?' in
the subject.

it also appears that if *any* element of tok (or x) positively passes
the test, use_UTF8 is set to TRUE;  in such a case, further checks make
no sense.  the following rewrite cuts the inessential computation:

    for (i = 0; i < tlen; i++)
        if (getCharCE(STRING_ELT(tok, i)) == CE_UTF8) {
            use_UTF8 = TRUE;
            break; }
    for (i = 0; i < len; i++)
        if (getCharCE(STRING_ELT(x, i)) == CE_UTF8) {
            use_UTF8 = TRUE;
            break; }
            
since the pattern is repetitive, the following generic approach would
help (and the macro could possibly be reused in other places):

#define CHECK_CE(CHARACTER, LENGTH, USEUTF8) \
    for (i = 0; i < (LENGTH); i++) \
        if (getCharCE(STRING_ELT((CHARACTER), i)) == CE_UTF8) { \
            (USEUTF8) = TRUE; \
            break; }
CHECK_CE(tok, tlen, use_UTF8)
CHECK_CE(x, len, use_UTF8)
            
if you like it, i can provide a patch.

vQ


From astokes at esica.com  Fri May 29 02:35:12 2009
From: astokes at esica.com (astokes at esica.com)
Date: Fri, 29 May 2009 02:35:12 +0200 (CEST)
Subject: [Rd] edge case concerning NA in dim() (PR#13729)
Message-ID: <20090529003512.5EB7828320A1@mail.pubhealth.ku.dk>

Full_Name: Allan Stokes
Version: 28.1
OS: XP
Submission from: (NULL) (24.108.0.245)


I'm trying to use package HDF5 and have discovered some round-trip errors: save,
load, save is not idempotent.  I started digging into the type system to figure
out what type graffiti is fouling this up.  

Soon I discovered that comparisons with NULL produce zero length vectors, which
I hadn't known was possible, and I started to wonder about the properties of
zero length objects.  

L0 <- logical (0) 
dim(L0) <- c(0)  # OK 
dim(L0) <- c(1)  # error 
dim(L0) <- c(0,1) # OK 
dim(L0) <- c(0,-1) # OK 
dim(L0) <- c(0,3.14) # OK, c(0,3) results 
dim(L0) <- c(0,FALSE) # OK c(0,0) results 
dim(L0) <- c(0,NA) # OK 
dim(L0) <- c(1,NA) # error
dim(L0) <- c(1,NA,NA) # OK, SURPRISE!!   

NA*NA is normally NA, but in the test for dim() assignment, it appears that
NA*NA == 0, which is then allowed.  If the list contains more than one NA
elements, the product seems to evaluate to zero. 

I can see making a case for 0*NA == 0 in this context, but not for NA*NA == 0. 
As an aside, I'm not sure why 0*NA does not equal 0 in general evaluation,
unless NA is considered to possibly represent +/-inf.


From ba208 at exeter.ac.uk  Wed May 27 19:22:30 2009
From: ba208 at exeter.ac.uk (baptiste auguie)
Date: Wed, 27 May 2009 19:22:30 +0200
Subject: [Rd] Fwd: [R] size of point symbols
In-Reply-To: <alpine.LFD.2.00.0905260711260.7401@gannet.stats.ox.ac.uk>
References: <119525F2-0C93-40B5-A219-2456793692ED@exeter.ac.uk>
	<D0ABBB0D-0421-4B51-ABDF-90E2FD0FBB7B@exeter.ac.uk>
	<alpine.LFD.2.00.0905260711260.7401@gannet.stats.ox.ac.uk>
Message-ID: <24805CEA-1A8A-43C7-BA42-45CC8CE8B2CA@exeter.ac.uk>

Dear Prof. Ripley and all,


Thank you very much for the pointers and the always insightful  
comments. I'd like to add a few further comments below for the sake of  
discussion,

On 26 May 2009, at 08:35, Prof Brian Ripley wrote:

> I don't know where you get your claims from.  R graphics is handled
> internally in inches, with a device-specific mapping to pixels/points
> etc (which is documented for each device on its help page).  This has
> to be done carefully, as pixels may not be square.

I saw hints of this use of inches in the code but I started off with  
the wrong assumption that symbols would be in mm (partly because  
ggplot2 suggested it would be so, partly because it's the natural unit  
I was taught to use throughout french technical education).

>
> What the meaning of pch=1:23 is in terms of coordinates is not
> documented except via the sources.

  I own Paul Murrell's R graphics book but I don't think the precise  
description of the symbols' size is presented in there. Perhaps a  
useful addition for the next edition?

> The source is function GESymbol in
> file src/main/engine.c, so for example pch = 2 is

Thank you, I failed to pinpoint this.

>
> 	case 2:	/* S triangle - point up */
> 	    xc = RADIUS * GSTR_0;
> 	    r = toDeviceHeight(TRC0 * xc, GE_INCHES, dd);
> 	    yc = toDeviceHeight(TRC2 * xc, GE_INCHES, dd);
> 	    xc = toDeviceWidth(TRC1 * xc, GE_INCHES, dd);
> 	    xx[0] = x; yy[0] = y+r;
> 	    xx[1] = x+xc; yy[1] = y-yc;
> 	    xx[2] = x-xc; yy[2] = y-yc;
> 	    gc->fill = R_TRANWHITE;
> 	    GEPolygon(3, xx, yy, gc, dd);
> 	    break;
>
> which as you see is in inches, not mm as you asserted.  The first line
> sets xc to 0.375 inches for cex=1, for example.
>
> You need to take the stroke width (as set by lty) into account when
> assessing the visual size of symbols
>

Altering the implementation is definitely way out of my league, but  
I'm glad I learned where to find this piece of information should the  
need come in the future.

> On Mon, 25 May 2009, baptiste auguie wrote:
>
>> Dear all,
>>
>>
>> Having received no answer in r-help I'm trying r-devel (hoping this  
>> is not a
>> stupid question).
>>
>> I don't understand the rationale behind the absolute sizes of the  
>> point
>> symbols, and I couldn't find it documented (I got lost in the C code
>> graphics.c and gave up).
>
> You are expected to study the sources for yourself.  That's part of
> the price of R.
>
> There is a manual, 'R Internals', that would have explained to you
> that graphics.c is part of base graphics and hence not of grid
> graphics.

R is a big project, and these implementation details can be hard to  
track down for non-programmers of my sort. That's why I was hoping for  
some hints on r-help first. In particular, it's not clear to me  
whether base graphics and grid graphics share these sort of  
"primitive" pieces of code. I'll have to read R internals.


As a last note, I'd like to share this idea I've contemplated recently  
(currently implementing it at the R level for ggplot2),

The points() symbols (well, rather the par() function, presumably)  
could gain an attribute 'type', say, with a few options:

- 'old' for backward compatibility, this choice would set the symbols  
to use to the current values in the same way that palette() provides a  
default set of colours.

- 'polygons', could provide the user with a set of regular polygons  
ordered by the number of vertices (3 to 6 and circle, for instance)  
with a consistent set of attributes (all having col and fill  
parameters). These could be complemented by starred versions of the  
polygons to make for a larger set of shapes.

Such a design could provide several benefits over the current  
situation, 1) the possible mapping between symbols and data could be  
more straight-forward (in the spirit of the ggplot2 package), 2) the  
symbol size could be made consistent either with a constant area or a  
constant circumscribing circle, thereby conforming with the idea that  
information should minimise visual artefacts in displaying the data  
(I'm not saying this is the case currently, but I feel it may not be  
optimum.).

- perhaps something else --- TeachingDemos has some interesting  
examples in the my.symbols help page.


Thanks again,

baptiste


>
>> The example below uses
>> Grid to check the size of the symbols against a square of 10mm x  
>> 10mm.
>>
>>> checkOneSymbol <- function(pch=0){
>>>  gTree(children=gList(
>>>      rectGrob(0.5, 0.5, width=unit(10, "mm"), height=unit(10,
>>> "mm"),
>>>              gp=gpar(lty=2, fill=NA, col=alpha("black", 0.5))),
>>>  pointsGrob(0.5, 0.5, size=unit(10, "mm"),pch=pch,
>>>      gp=gpar(col=alpha("red", 0.5)))
>>>  ))
>>>
>>> }
>>> all.symbols <- lapply(0:23, checkOneSymbol)
>>>
>>> pdf("symbols.pdf", height=1.2/2.54, width=24.2/2.54)
>>>
>>> vp <- viewport(width=0.5, height=0.5, name="main")
>>> pushViewport(vp)
>>>
>>> pushViewport(viewport(layout=grid.layout(1, 24,
>>>                      widths=unit(10, "mm"),
>>>                      heights=unit(10, "mm"),
>>>                      just="center")))
>>>
>>> for(ii in 0:23){
>>> pushViewport(viewport(layout.pos.col=ii+1, layout.pos.row=1))
>>> grid.draw(all.symbols[[ii+1]])
>>> upViewport(1)
>>> }
>>> dev.off()
>>
>>
>> What dictates the size of each symbol? (in other words, why is pch=21
>> a circle of radius given in inches, while pch=2 is a triangle of base
>> length specified  in mm and offset vertically?, etc.)
>>
>> I'm trying to develop a new symbol for the ggplot2 package where  
>> the size is
>> to be accurately mapped onto the data either in linear size or  
>> area. I was
>> expecting a similar idea behind the choice of base symbols. Is this
>> documented?
>>
>> Best regards,
>>
>> baptiste
>>
>> _____________________________
>>
>> Baptiste Augui?
>>
>> School of Physics
>> University of Exeter
>> Stocker Road,
>> Exeter, Devon,
>> EX4 4QL, UK
>>
>> Phone: +44 1392 264187
>>
>> http://newton.ex.ac.uk/research/emag
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From chajewski at fordham.edu  Thu May 28 09:30:13 2009
From: chajewski at fordham.edu (chajewski at fordham.edu)
Date: Thu, 28 May 2009 09:30:13 +0200 (CEST)
Subject: [Rd] Bug in base function sample ( ) (PR#13727)
Message-ID: <20090528073013.3C3D8282BE85@mail.pubhealth.ku.dk>

Full_Name: Michael Chajewski
Version: 2.9.0
OS: Windows XP
Submission from: (NULL) (150.108.71.185)


I was programming a routine which kept reducing the array from which a random
sample was taken, resulting in a single number. I discovered that when R
attempts to sample from an object with only one number it does not
reproduce/report the number but instead chooses a random number between 1 and
that number. 

Example 1:

# I am assigning a single number
gg <- 7

# Creating an array to store sampled values
ggtrack <- 0

# I am sampling 10,000 observations from my single value
# object and storing them
for (i in 1:10000) {
	g0 <- sample(gg, (i/i))
	ggtrack <- c(ggtrack,g0)
}

# Deleting the initial value in the array
ggtrack <- ggtrack[-1]

# The array ought to be 10,000 samples long (and it is)
length(ggtrack)

# The array should contain 10,000 "7", but it does not
# See the histogram of sampled values
hist(ggtrack)

Example 2:

# Here is the same example, but now with
# two number. Note that now the function performs
# as expected and only samples between the two.

gg <- c(7,2)
ggtrack <- 0
for (i in 1:10000) {
	g0 <- sample(gg, (i/i))
	ggtrack <- c(ggtrack,g0)
}

ggtrack <- ggtrack[-1]
length(ggtrack)
hist(ggtrack)


Highest Regards,
Michael Chajewski


From gavin.simpson at ucl.ac.uk  Fri May 29 12:11:45 2009
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Fri, 29 May 2009 11:11:45 +0100
Subject: [Rd] Bug in base function sample ( ) (PR#13727)
In-Reply-To: <20090528073013.3C3D8282BE85@mail.pubhealth.ku.dk>
References: <20090528073013.3C3D8282BE85@mail.pubhealth.ku.dk>
Message-ID: <1243591905.2587.18.camel@desktop.localhost>

On Thu, 2009-05-28 at 09:30 +0200, chajewski at fordham.edu wrote:
> Full_Name: Michael Chajewski
> Version: 2.9.0
> OS: Windows XP
> Submission from: (NULL) (150.108.71.185)
> 
> 
> I was programming a routine which kept reducing the array from which a random
> sample was taken, resulting in a single number. I discovered that when R
> attempts to sample from an object with only one number it does not
> reproduce/report the number but instead chooses a random number between 1 and
> that number. 

This is working as documented/intended in ?sample. 'x' is of length 1,
so it is interpreted as 1:x (if x >=1), resulting in the behaviour you
have encountered.

That help page even goes so far as to warn you that this "convenience
feature may lead to undesired behaviour..." and gives an example
function (in Examples) that handles the sort of use case you have. See
the Examples section and the resample() function created there.

HTH

G

> 
> Example 1:
> 
> # I am assigning a single number
> gg <- 7
> # Creating an array to store sampled values
> ggtrack <- 0
> 
> # I am sampling 10,000 observations from my single value
> # object and storing them
> for (i in 1:10000) {
> 	g0 <- sample(gg, (i/i))
> 	ggtrack <- c(ggtrack,g0)
> }
> 
> # Deleting the initial value in the array
> ggtrack <- ggtrack[-1]
> 
> # The array ought to be 10,000 samples long (and it is)
> length(ggtrack)
> 
> # The array should contain 10,000 "7", but it does not
> # See the histogram of sampled values
> hist(ggtrack)
> 
> Example 2:
> 
> # Here is the same example, but now with
> # two number. Note that now the function performs
> # as expected and only samples between the two.
> 
> gg <- c(7,2)
> ggtrack <- 0
> for (i in 1:10000) {
> 	g0 <- sample(gg, (i/i))
> 	ggtrack <- c(ggtrack,g0)
> }
> 
> ggtrack <- ggtrack[-1]
> length(ggtrack)
> hist(ggtrack)
> 
> 
> Highest Regards,
> Michael Chajewski
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
 Dr. Gavin Simpson             [t] +44 (0)20 7679 0522
 ECRC, UCL Geography,          [f] +44 (0)20 7679 0565
 Pearson Building,             [e] gavin.simpsonATNOSPAMucl.ac.uk
 Gower Street, London          [w] http://www.ucl.ac.uk/~ucfagls/
 UK. WC1E 6BT.                 [w] http://www.freshwaters.org.uk
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%

-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 197 bytes
Desc: This is a digitally signed message part
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090529/b5830f54/attachment.bin>

From maechler at stat.math.ethz.ch  Fri May 29 15:22:35 2009
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 29 May 2009 15:22:35 +0200
Subject: [Rd] as.numeric(levels(factor(x))) may be a decreasing sequence
In-Reply-To: <20090528073648.GA18207@cs.cas.cz>
References: <20090523074454.GA17112@cs.cas.cz>
	<18973.42970.826686.173830@cmath-5.math.ethz.ch>
	<20090528073648.GA18207@cs.cas.cz>
Message-ID: <18975.57755.161884.893418@lynne.math.ethz.ch>

>>>>> "PS" == Petr Savicky <savicky at cs.cas.cz>
>>>>>     on Thu, 28 May 2009 09:36:48 +0200 writes:

    PS> On Wed, May 27, 2009 at 10:51:38PM +0200, Martin Maechler wrote:
    >> I have very slightly  modified the changes (to get rid of -Wall
    >> warnings) and also exported the function as Rf_dropTrailing0(),
    >> and tested the result with 'make check-all' .

    PS> Thank you very much for considering the patch. -Wall indeed requires to add 
    PS> parentheses
    PS> warning: suggest parentheses around comparison in operand of &
    PS> warning: suggest parentheses around assignment used as truth value

    PS> If there are also other changes, i would like to ask you to make your modification
    PS> available, mainly due to a possible further discussion.

    PS> Let me also suggest a modification of my original proposal. It contains a cycle
    PS> while (*(replace++) = *(p++)) {
    PS> ;
    PS> }
    PS> If the number has no trailing zeros, but contains an exponent, this cycle
    PS> shifts the exponent by 0 positions, which means that it copies each of its
    PS> characters to itself. This may be eliminated as follows
    PS> if (replace != p) {
    PS>    while (*(replace++) = *(p++)) {
    PS>       ;
    PS>    }
    PS> }

yes, that's a simple improvement, thank you.
Martin


From ripley at stats.ox.ac.uk  Fri May 29 15:22:54 2009
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 29 May 2009 14:22:54 +0100 (BST)
Subject: [Rd] edge case concerning NA in dim() (PR#13729)
In-Reply-To: <20090529003512.5EB7828320A1@mail.pubhealth.ku.dk>
References: <20090529003512.5EB7828320A1@mail.pubhealth.ku.dk>
Message-ID: <alpine.LFD.2.00.0905291406050.14633@toucan.stats.ox.ac.uk>

On Fri, 29 May 2009, astokes at esica.com wrote:

> Full_Name: Allan Stokes
> Version: 28.1
> OS: XP
> Submission from: (NULL) (24.108.0.245)
>
>
> I'm trying to use package HDF5 and have discovered some round-trip errors: save,
> load, save is not idempotent.  I started digging into the type system to figure
> out what type graffiti is fouling this up.
>
> Soon I discovered that comparisons with NULL produce zero length vectors, which
> I hadn't known was possible, and I started to wonder about the properties of
> zero length objects.
>
> L0 <- logical (0)
> dim(L0) <- c(0)  # OK
> dim(L0) <- c(1)  # error
> dim(L0) <- c(0,1) # OK
> dim(L0) <- c(0,-1) # OK
> dim(L0) <- c(0,3.14) # OK, c(0,3) results
> dim(L0) <- c(0,FALSE) # OK c(0,0) results
> dim(L0) <- c(0,NA) # OK
> dim(L0) <- c(1,NA) # error
> dim(L0) <- c(1,NA,NA) # OK, SURPRISE!!
>
> NA*NA is normally NA, but in the test for dim() assignment, it appears that
> NA*NA == 0, which is then allowed.  If the list contains more than one NA
> elements, the product seems to evaluate to zero.

The calculation was done in C and failed to take NAs (and indeed 
negative values) into account.  So

> L <- logical(1)
> dim(L) <- c(1, -1, -1)

succeeded.

Thank you for the report, changed in R 2.9.0 patched.  (Since the 
representation of an integer NA is negative, a test for positivity 
would have caught this.)

> I can see making a case for 0*NA == 0 in this context, but not for NA*NA == 0.
> As an aside, I'm not sure why 0*NA does not equal 0 in general evaluation,
> unless NA is considered to possibly represent +/-inf.

In fact NA as used here is logical but is coerced to a numeric NA, and 
a 'missing' numeric could take any possible value including Inf, -Inf 
and NaN.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From murdoch at stats.uwo.ca  Fri May 29 15:28:37 2009
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri, 29 May 2009 09:28:37 -0400
Subject: [Rd] [R] custom sort?
In-Reply-To: <8b356f880905281717o34922d10m58e5da1d4ea04538@mail.gmail.com>
References: <23770565.post@talk.nabble.com> <4A1F06BC.3040802@stats.uwo.ca>
	<8b356f880905281717o34922d10m58e5da1d4ea04538@mail.gmail.com>
Message-ID: <4A1FE305.4030008@stats.uwo.ca>

I've moved this to R-devel...

On 5/28/2009 8:17 PM, Stavros Macrakis wrote:
> I couldn't get your suggested method to work:
> 
>   `==.foo` <- function(a,b) unclass(a)==unclass(b)
>   `>.foo` <- function(a,b) unclass(a) < unclass(b)     # invert comparison
>   is.na.foo <- function(a)is.na(unclass(a))
> 
>   sort(structure(sample(5),class="foo"))  #-> 1:5  -- not reversed
> 
> What am I missing?

There are two problems.  First, I didn't mention that you need a method 
for indexing as well.  The code needs to evaluate things like x[i] > 
x[j], and by default x[i] will not be of class "foo", so the custom 
comparison methods won't be called.

Second, I think there's a bug in the internal code, specifically in 
do_rank or orderVector1 in sort.c:  orderVector1 ignores the class of x. 
  do_rank pays attention when breaking ties, so I think this is an 
oversight.

So I'd say two things should be done:

  1.  the bug should be fixed.  Even if this isn't the most obvious 
approach, it should work.

  2.  we should look for ways to make all of this simpler, e.g. allowing 
a comparison function to be used.

I'll take on 1, but not 2.  It's hard to work out the right place for 
the comparison function to appear, and it would require a lot of work to 
implement, because all of this stuff (sort, rank, order, xtfrm, 
sort.int, etc.) is closely interrelated, some but not all of the 
functions are S3 generics, some implemented internally, etc.  In the 
end, I'd guess the results won't be very satisfactory from a performance 
point of view:  all those calls out to R to do the comparisons are going 
to be really slow.

I think your advice to use order() with multiple keys is likely to be 
much faster in most instances.  It's just a better approach in R.

Duncan Murdoch

> 
>            -s
> 
> On Thu, May 28, 2009 at 5:48 PM, Duncan Murdoch <murdoch at stats.uwo.ca>wrote:
> 
>> On 28/05/2009 5:34 PM, Steve Jaffe wrote:
>>
>>> Sounds simple but haven't been able to find it in docs: is it possible to
>>> sort a vector using a user-defined comparison function? Seems it must be,
>>> but "sort" doesn't seem to provide that option, nor does "order" sfaics
>>>
>>
>> You put a class on the vector (e.g. using class(x) <- "myvector"), then
>> define a conversion to numeric (e.g. xtfrm.myvector) or actual comparison
>> methods (you'll need ==.myvector, >.myvector, and is.na.myvector).
>>
>> Duncan Murdoch
>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From maechler at stat.math.ethz.ch  Fri May 29 15:53:02 2009
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 29 May 2009 15:53:02 +0200
Subject: [Rd] as.numeric(levels(factor(x))) may be a decreasing sequence
In-Reply-To: <4A1DC057.80401@idi.ntnu.no>
References: <20090523074454.GA17112@cs.cas.cz>
	<18973.42970.826686.173830@cmath-5.math.ethz.ch>
	<4A1DC057.80401@idi.ntnu.no>
Message-ID: <18975.59582.885300.549159@lynne.math.ethz.ch>

>>>>> "vQ" == Wacek Kusnierczyk <Waclaw.Marcin.Kusnierczyk at idi.ntnu.no>
>>>>>     on Thu, 28 May 2009 00:36:07 +0200 writes:

    vQ> Martin Maechler wrote:
    >> 
    >> I have very slightly  modified the changes (to get rid of -Wall
    >> warnings) and also exported the function as Rf_dropTrailing0(),
    >> and tested the result with 'make check-all' .
    >> As the change seems reasonable and consequent, and as
    >> it seems not to produce any problems in our tests, 
    >> I'm hereby proposing to commit it (my version of it),
    >> [to R-devel only] within a few days, unless someone speaks up.



    vQ> i may be misunderstanding the code, but:


    >> Martin Maechler, ETH Zurich
    >> 
    PS> --- R-devel/src/main/coerce.c	2009-04-17 17:53:35.000000000 +0200
    PS> +++ R-devel-elim-trailing/src/main/coerce.c	2009-05-23 08:39:03.914774176 +0200
    PS> @@ -294,12 +294,33 @@
    PS> else return mkChar(EncodeInteger(x, w));
    PS> }
    >> 
    PS> +const char *elim_trailing(const char *s, char cdec)
    >> 

    vQ> the first argument is const char*, which usually means a contract
    vQ> promising not to change the content of the pointed-to object

    PS> +{
    PS> +    const char *p;
    PS> +    char *replace;
    PS> +    for (p = s; *p; p++) {
    PS> +        if (*p == cdec) {
    PS> +            replace = (char *) p++;

  vQ> const char* p is cast to non-const char* replace

    PS> +            while ('0' <= *p & *p <= '9') {
    PS> +                if (*(p++) != '0') {
    PS> +                    replace = (char *) p;

  vQ> likewise

    PS> +                }
    PS> +            }
    PS> +            while (*(replace++) = *(p++)) {
    >> 

    vQ> the char* replace is assigned to -- effectively, the content of the
    vQ> promised-to-be-constant string s is modified, and the modification may
    vQ> involve any character in the string.  (it's a no-compile-error contract
    vQ> violation;  not an uncommon pattern, but not good practice either.)

    PS> +                ;
    PS> +            }
    PS> +            break;
    PS> +        }
    PS> +    }
    PS> +    return s;
    >> 

    vQ> you return s, which should be the same pointer value (given the actual
    vQ> code that does not modify the local variable s) with the same pointed-to
    vQ> string value (given the signature of the function).

    vQ> was perhaps

    vQ> char *elim_trailing(char* const s, char cdec)

    vQ> intended?

yes that would seem slightly more "logical" to my eyes, 
and "in principle" I also agree with the other remarks you make above,
...

    vQ> anyway, having the pointer s itself declared as const does
    vQ> make sense, as the code seems to assume that exactly the input pointer
    vQ> value should be returned.  or maybe the argument to elim_trailing should
    vQ> not be declared as const, since elim_trailing violates the declaration. 

    vQ> one way out is to drop the violated const in both the actual argument
    vQ> and in elim_trailing, which would then be simplified by removing all
    vQ> const qualifiers and (char*) casts.  

I've tried that, but   ``it does not work'' later:
{after having renamed  'elim_trailing'  to  'dropTrailing0' }
my version of *using* the function was

1 SEXP attribute_hidden StringFromReal(double x, int *warn)
2 {
3   int w, d, e;
4   formatReal(&x, 1, &w, &d, &e, 0);
5   if (ISNA(x)) return NA_STRING;
6   else return mkChar(dropTrailing0(EncodeReal(x, w, d, e, OutDec), OutDec));
7 }

where you need to consider that mkChar() expects a 'const char*' 
and EncodeReal(.) returns one, and I am pretty sure this was the
main reason why Petr had used the two 'const char*' in (the
now-named) dropTrailing0() definition. 
If I use your proposed signature

char* dropTrailing0(char *s, char cdec);

line 6 above gives warnings in all of several incantations I've tried
including this one :

    else return mkChar((const char *) dropTrailing0((char *)EncodeReal(x, w, d, e, OutDec), OutDec));

which (the warnings) leave me somewhat clue-less or rather
unmotivated to dig further, though I must say that I'm not the
expert on the subject char*  / const char* ..

    vQ>   another way out is to make
    vQ> elim_trailing actually allocate and return a new string, keeping the
    vQ> input truly constant, at a performance cost    .  yet another way is to
    vQ> ignore the issue, of course.

    vQ> the original (martin/petr) version may quietly pass -Wall, but the
    vQ> compiler would complain (rightfully) with -Wcast-qual.

hmm, yes, but actually I haven't found a solution along your
proposition that even passes   -pedantic -Wall -Wcast-align
(the combination I've personally been using for a long time).

Maybe we can try to solve this more esthetically
in private e-mail exchange?

Regards,
Martin


From savicky at cs.cas.cz  Fri May 29 17:48:50 2009
From: savicky at cs.cas.cz (Petr Savicky)
Date: Fri, 29 May 2009 17:48:50 +0200
Subject: [Rd] as.numeric(levels(factor(x))) may be a decreasing sequence
In-Reply-To: <18975.59582.885300.549159@lynne.math.ethz.ch>
References: <20090523074454.GA17112@cs.cas.cz>
	<18973.42970.826686.173830@cmath-5.math.ethz.ch>
	<4A1DC057.80401@idi.ntnu.no>
	<18975.59582.885300.549159@lynne.math.ethz.ch>
Message-ID: <20090529154850.GC5939@cs.cas.cz>

On Fri, May 29, 2009 at 03:53:02PM +0200, Martin Maechler wrote:
> my version of *using* the function was
> 
> 1 SEXP attribute_hidden StringFromReal(double x, int *warn)
> 2 {
> 3   int w, d, e;
> 4   formatReal(&x, 1, &w, &d, &e, 0);
> 5   if (ISNA(x)) return NA_STRING;
> 6   else return mkChar(dropTrailing0(EncodeReal(x, w, d, e, OutDec), OutDec));
> 7 }
> 
> where you need to consider that mkChar() expects a 'const char*' 
> and EncodeReal(.) returns one, and I am pretty sure this was the
> main reason why Petr had used the two 'const char*' in (the
> now-named) dropTrailing0() definition. 

Yes, the goal was to accept the output of EncodeReal() with exactly the
same type, which EncodeReal() produces. A question is, whether the
output type of EncodeReal() could be changed to (char *). Then, changing
the output string could be done without casting const to non-const.

This solution may be in conflict with the structure of the rest of R code,
so i cannot evaluate, whether this is possible.

Petr.


From zhengxin at mail.nih.gov  Fri May 29 18:50:15 2009
From: zhengxin at mail.nih.gov (zhengxin at mail.nih.gov)
Date: Fri, 29 May 2009 18:50:15 +0200 (CEST)
Subject: [Rd] 'mean' is not reverted in median() as NEWS says (PR#13731)
Message-ID: <20090529165015.24A212831FF6@mail.pubhealth.ku.dk>

Full_Name: 
Version: 2.9.0
OS: windows, linux
Submission from: (NULL) (128.231.21.125)


In NEWS, it says "median.default() was altered in 2.8.1 to use sum() rather
	than mean(), although it was still documented to use mean().
	This caused problems for POSIXt objects, for which mean() but
	not sum() makes sense, so the change has been reverted."

But it's not reverted yet.


From murdoch at stats.uwo.ca  Fri May 29 19:02:48 2009
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri, 29 May 2009 13:02:48 -0400
Subject: [Rd] [R] custom sort?
In-Reply-To: <4A1FE305.4030008@stats.uwo.ca>
References: <23770565.post@talk.nabble.com> <4A1F06BC.3040802@stats.uwo.ca>
	<8b356f880905281717o34922d10m58e5da1d4ea04538@mail.gmail.com>
	<4A1FE305.4030008@stats.uwo.ca>
Message-ID: <4A201538.4090503@stats.uwo.ca>

On 5/29/2009 9:28 AM, Duncan Murdoch wrote:
> I've moved this to R-devel...
> 
> On 5/28/2009 8:17 PM, Stavros Macrakis wrote:
>> I couldn't get your suggested method to work:
>> 
>>   `==.foo` <- function(a,b) unclass(a)==unclass(b)
>>   `>.foo` <- function(a,b) unclass(a) < unclass(b)     # invert comparison
>>   is.na.foo <- function(a)is.na(unclass(a))
>> 
>>   sort(structure(sample(5),class="foo"))  #-> 1:5  -- not reversed
>> 
>> What am I missing?
> 
> There are two problems.  First, I didn't mention that you need a method 
> for indexing as well.  The code needs to evaluate things like x[i] > 
> x[j], and by default x[i] will not be of class "foo", so the custom 
> comparison methods won't be called.
> 
> Second, I think there's a bug in the internal code, specifically in 
> do_rank or orderVector1 in sort.c:  orderVector1 ignores the class of x. 
>   do_rank pays attention when breaking ties, so I think this is an 
> oversight.
> 
> So I'd say two things should be done:
> 
>   1.  the bug should be fixed.  Even if this isn't the most obvious 
> approach, it should work.

I've now fixed the bug, and clarified the documentation to say

   The default method will make use of == and > methods
   for the class of x[i] (for integers i), and the
   is.na method for the class of x, but might be rather
   slow when doing so.

You don't actually need a custom indexing method, you just need to be 
aware that it's the class of x[i] that is important for comparisons.

This will make it into R-patched and R-devel.

Duncan Murdoch

> 
>   2.  we should look for ways to make all of this simpler, e.g. allowing 
> a comparison function to be used.
> 
> I'll take on 1, but not 2.  It's hard to work out the right place for 
> the comparison function to appear, and it would require a lot of work to 
> implement, because all of this stuff (sort, rank, order, xtfrm, 
> sort.int, etc.) is closely interrelated, some but not all of the 
> functions are S3 generics, some implemented internally, etc.  In the 
> end, I'd guess the results won't be very satisfactory from a performance 
> point of view:  all those calls out to R to do the comparisons are going 
> to be really slow.
> 
> I think your advice to use order() with multiple keys is likely to be 
> much faster in most instances.  It's just a better approach in R.
> 
> Duncan Murdoch
> 
>> 
>>            -s
>> 
>> On Thu, May 28, 2009 at 5:48 PM, Duncan Murdoch <murdoch at stats.uwo.ca>wrote:
>> 
>>> On 28/05/2009 5:34 PM, Steve Jaffe wrote:
>>>
>>>> Sounds simple but haven't been able to find it in docs: is it possible to
>>>> sort a vector using a user-defined comparison function? Seems it must be,
>>>> but "sort" doesn't seem to provide that option, nor does "order" sfaics
>>>>
>>>
>>> You put a class on the vector (e.g. using class(x) <- "myvector"), then
>>> define a conversion to numeric (e.g. xtfrm.myvector) or actual comparison
>>> methods (you'll need ==.myvector, >.myvector, and is.na.myvector).
>>>
>>> Duncan Murdoch
>>>
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
>


From p.dalgaard at biostat.ku.dk  Fri May 29 19:05:42 2009
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Fri, 29 May 2009 19:05:42 +0200
Subject: [Rd] 'mean' is not reverted in median() as NEWS says (PR#13731)
In-Reply-To: <20090529165015.24A212831FF6@mail.pubhealth.ku.dk>
References: <20090529165015.24A212831FF6@mail.pubhealth.ku.dk>
Message-ID: <4A2015E6.9010804@biostat.ku.dk>

zhengxin at mail.nih.gov wrote:
> Full_Name: 
> Version: 2.9.0
> OS: windows, linux
> Submission from: (NULL) (128.231.21.125)
> 
> 
> In NEWS, it says "median.default() was altered in 2.8.1 to use sum() rather
> 	than mean(), although it was still documented to use mean().
> 	This caused problems for POSIXt objects, for which mean() but
> 	not sum() makes sense, so the change has been reverted."
> 
> But it's not reverted yet.

That text is not in the NEWS file for 2.9.0. And the NEWS file that it 
is in is not for 2.9.0, and does not list that change under "CHANGES IN 
R VERSION 2.9.0".

-- 
    O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
   c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
  (*) \(*) -- University of Copenhagen   Denmark      Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)              FAX: (+45) 35327907


From macrakis at alum.mit.edu  Fri May 29 20:08:37 2009
From: macrakis at alum.mit.edu (Stavros Macrakis)
Date: Fri, 29 May 2009 14:08:37 -0400
Subject: [Rd] Bug in base function sample ( ) (PR#13727)
In-Reply-To: <20090528073013.3C3D8282BE85@mail.pubhealth.ku.dk>
References: <20090528073013.3C3D8282BE85@mail.pubhealth.ku.dk>
Message-ID: <8b356f880905291108j1ca39d64x79790dd79868db83@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090529/4f84f098/attachment.pl>

From macrakis at alum.mit.edu  Fri May 29 20:09:52 2009
From: macrakis at alum.mit.edu (Stavros Macrakis)
Date: Fri, 29 May 2009 14:09:52 -0400
Subject: [Rd] [R] custom sort?
In-Reply-To: <4A201538.4090503@stats.uwo.ca>
References: <23770565.post@talk.nabble.com> <4A1F06BC.3040802@stats.uwo.ca>
	<8b356f880905281717o34922d10m58e5da1d4ea04538@mail.gmail.com>
	<4A1FE305.4030008@stats.uwo.ca> <4A201538.4090503@stats.uwo.ca>
Message-ID: <8b356f880905291109g6362077do1247d2a4fde24c94@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090529/3e38e2f6/attachment.pl>

From Robert.McGehee at geodecapital.com  Fri May 29 20:45:39 2009
From: Robert.McGehee at geodecapital.com (McGehee, Robert)
Date: Fri, 29 May 2009 14:45:39 -0400
Subject: [Rd] install.packages now intentionally references .Rprofile?
References: <6ph4ovf1gi0.fsf@gopher4.fhcrc.org>	<alpine.LFD.2.00.0905210715100.30855@gannet.stats.ox.ac.uk><6b93d1830905211428h6f5d0e66hdebfb9a3c70984f8@mail.gmail.com>
	<4A167AAF.2040803@warwick.ac.uk>
Message-ID: <EEBC169715EB8C438D3C9283AF0F201C055EA984@MSGBOSCLM2WIN.DMN1.FMR.COM>

I see that related to this thread, 'R CMD INSTALL' (like
'install.packages') also reads the .Rprofile before beginning. This
caused package installation headaches for me that developers should be
aware (as it was very difficult to debug).

I added a setwd() to my .Rprofile [for example: setwd("/tmp")] to keep
.Rhistory files from popping up in directories throughout my computer.
This causes package installation to fail completely with an unhelpful
error message. For example (any package will do here):
> R CMD INSTALL zoo_1.5-6.tar.gz
Warning: invalid package 'zoo_1.5-6.tar.gz'
Error: ERROR: no packages specified

Removing 'setwd(...)' from the .Rprofile restores normal package
installation behavior.

I'd like to request that either setwd() not break installation, or the
user can disable .Rprofile reading on R CMD INSTALL (for instance with
an option such as --no-init-file). I'll use Heather's solution below for
the short-term, but would rather not have to completely turn off my
.Rprofile for non-interactive scripts.

Thanks, Robert


-----Original Message-----
From: r-devel-bounces at r-project.org
[mailto:r-devel-bounces at r-project.org] On Behalf Of Heather Turner
Sent: Friday, May 22, 2009 6:13 AM
To: Mark Kimpel
Cc: Prof Brian Ripley; r-devel at stat.math.ethz.ch
Subject: Re: [Rd] install.packages now intentionally references
.Rprofile?

I had a similar problem when moving to R-2.9.0 as my .Rprofile called
update.packages(). The solution was to use

if(interactive()) {
	utils:::update.packages(ask = FALSE)
}

HTH,

Heather

Mark Kimpel wrote:
> This was my original post, with the code example only slightly
modified by
> Martin for clarity. Prior to R-2.9.0, this repeated downloading did
not
> occur, the code worked as intended. In fact, if memory serves me
correctly,
> it even worked at least during the first 3 months of R-2.0.0 in its
> development stage, before release as a numbered version. Is there a
reason
> for that? Is there a work-around? As I mentioned in my original post,
the
> code is actually wrapped in a function that checks the date and the
date of
> the last update, and proceeds to update package once per week. It was
quite
> handy when it was working, hence my desire for a fix for my code.
> 
> Thanks,
> Mark
> ------------------------------------------------------------
> Mark W. Kimpel MD  ** Neuroinformatics ** Dept. of Psychiatry
> Indiana University School of Medicine
> 
> 15032 Hunter Court, Westfield, IN  46074
> 
> (317) 490-5129 Work, & Mobile & VoiceMail
> (317) 399-1219  Home
> Skype:  mkimpel
> 
> "The real problem is not whether machines think but whether men do."
-- B.
> F. Skinner
> ******************************************************************
> 
> 
> On Thu, May 21, 2009 at 2:17 AM, Prof Brian Ripley
<ripley at stats.ox.ac.uk>wrote:
> 
>> On Wed, 20 May 2009, Martin Morgan wrote:
>>
>>  A post on the Bioconductor mailing list
>>>  https://stat.ethz.ch/pipermail/bioconductor/2009-May/027700.html
>>>
>>> suggests that install.packages now references .Rprofile (?), whereas
>>> in R-2-8 it did not. Is this intentional?
>>>
>> Yes.  And in fact it did in earlier versions, to find the default
library
>> into which to install.
>>
>>
>>
>>> The example is, in .Rprofile
>>>
>>>  library(utils)
>>>  install.packages("Biobase",
>>>                  repos="http://bioconductor.org/packages/2.4/bioc")
>>>
>>> then starting R from the command line results in repeated downloads
>>> of Biobase
>>>
>>> mtmorgan at mm:~/tmp> R --quiet
>>> trying URL
>>> '
>>>
http://bioconductor.org/packages/2.4/bioc/src/contrib/Biobase_2.4.1.tar.
gz
>>> '
>>> Content type 'application/x-gzip' length 1973533 bytes (1.9 Mb)
>>> opened URL
>>> ==================================================
>>> downloaded 1.9 Mb
>>>
>>> trying URL
>>> '
>>>
http://bioconductor.org/packages/2.4/bioc/src/contrib/Biobase_2.4.1.tar.
gz
>>> '
>>> Content type 'application/x-gzip' length 1973533 bytes (1.9 Mb)
>>> opened URL
>>> ==================================================
>>> downloaded 1.9 Mb
>>>
>>> ^C
>>> Execution halted
>>>
>>>  sessionInfo()
>>> R version 2.9.0 Patched (2009-05-20 r48588)
>>> x86_64-unknown-linux-gnu
>>>
>>> locale:
>>>
>>>
LC_CTYPE=en_US.UTF-8;LC_NUMERIC=C;LC_TIME=en_US.UTF-8;LC_COLLATE=en_US.U
TF-8;LC_MONETARY=C;LC_MESSAGES=en_US.UTF-8;LC_PAPER=en_US.UTF-8;LC_NAME=
C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=en_US.UTF-8;LC_IDENTIFICATI
ON=C
>>>
>>> attached base packages:
>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>
>>> Martin
>>> --
>>> Martin Morgan
>>> Computational Biology / Fred Hutchinson Cancer Research Center
>>> 1100 Fairview Ave. N.
>>> PO Box 19024 Seattle, WA 98109
>>>
>>> Location: Arnold Building M1 B861
>>> Phone: (206) 667-2793
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>>
>> --
>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>> Professor of Applied Statistics,
http://www.stats.ox.ac.uk/~ripley/<http://www.stats.ox.ac.uk/%7Eripley/>
>> University of Oxford,             Tel:  +44 1865 272861 (self)
>> 1 South Parks Road,                     +44 1865 272866 (PA)
>> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>>
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

______________________________________________
R-devel at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-devel


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Fri May 29 21:03:31 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Fri, 29 May 2009 21:03:31 +0200
Subject: [Rd] as.numeric(levels(factor(x))) may be a decreasing sequence
In-Reply-To: <20090529154850.GC5939@cs.cas.cz>
References: <20090523074454.GA17112@cs.cas.cz>	<18973.42970.826686.173830@cmath-5.math.ethz.ch>	<4A1DC057.80401@idi.ntnu.no>	<18975.59582.885300.549159@lynne.math.ethz.ch>
	<20090529154850.GC5939@cs.cas.cz>
Message-ID: <4A203183.30600@idi.ntnu.no>

Petr Savicky wrote:
> On Fri, May 29, 2009 at 03:53:02PM +0200, Martin Maechler wrote:
>   
>> my version of *using* the function was
>>
>> 1 SEXP attribute_hidden StringFromReal(double x, int *warn)
>> 2 {
>> 3   int w, d, e;
>> 4   formatReal(&x, 1, &w, &d, &e, 0);
>> 5   if (ISNA(x)) return NA_STRING;
>> 6   else return mkChar(dropTrailing0(EncodeReal(x, w, d, e, OutDec), OutDec));
>> 7 }
>>
>> where you need to consider that mkChar() expects a 'const char*' 
>> and EncodeReal(.) returns one, and I am pretty sure this was the
>> main reason why Petr had used the two 'const char*' in (the
>> now-named) dropTrailing0() definition. 
>>     
>
> Yes, the goal was to accept the output of EncodeReal() with exactly the
> same type, which EncodeReal() produces. A question is, whether the
> output type of EncodeReal() could be changed to (char *). Then, changing
> the output string could be done without casting const to non-const.
>
>   
exactly.  my suggestion was to modify your function so that no modify a
constant string-cheating is done, by either (a) keeping the const but
returning a *new* string (hence no const-to-nonconst cast would be
needed), or (b) modify your function to accept a non-const string *and*
modify the code that connects to your function via the input and output
strings. 

note, if a solution in which your function serves as a destructive
filter is just fine (martin seems to have accepted it already), then
EncodeReal probably can produce just a string, with no const qualifier,
and analogously for mkChar.  on the other hand, if EncodeReal is
purposefully designed to return a const string (i.e., there is an
important reason for doing so), and analogously for mkChar, then your
function violates the assumptions and can potentially be harmful to the
rest of the code.


> This solution may be in conflict with the structure of the rest of R code,
> so i cannot evaluate, whether this is possible.
>
>   

well, either the rest of the code does *not* need const, and it can be
safely removed, or it *does* rely on const, and your solution ciolates
the expectation.

vQ


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Fri May 29 21:54:15 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Fri, 29 May 2009 21:54:15 +0200
Subject: [Rd] as.numeric(levels(factor(x))) may be a decreasing sequence
In-Reply-To: <18975.59582.885300.549159@lynne.math.ethz.ch>
References: <20090523074454.GA17112@cs.cas.cz>	<18973.42970.826686.173830@cmath-5.math.ethz.ch>	<4A1DC057.80401@idi.ntnu.no>
	<18975.59582.885300.549159@lynne.math.ethz.ch>
Message-ID: <4A203D67.8000007@idi.ntnu.no>

Martin Maechler wrote:

[...]
>     vQ> you return s, which should be the same pointer value (given the actual
>     vQ> code that does not modify the local variable s) with the same pointed-to
>     vQ> string value (given the signature of the function).
>
>     vQ> was perhaps
>
>     vQ> char *elim_trailing(char* const s, char cdec)
>
>     vQ> intended?
>
> yes that would seem slightly more "logical" to my eyes, 
> and "in principle" I also agree with the other remarks you make above,
>   

what does ' "in principle" ' mean, as opposed to 'in principle'?  (is it
emphasis, or sneer quotes?)

> ...
>
>     vQ> anyway, having the pointer s itself declared as const does
>     vQ> make sense, as the code seems to assume that exactly the input pointer
>     vQ> value should be returned.  or maybe the argument to elim_trailing should
>     vQ> not be declared as const, since elim_trailing violates the declaration. 
>
>     vQ> one way out is to drop the violated const in both the actual argument
>     vQ> and in elim_trailing, which would then be simplified by removing all
>     vQ> const qualifiers and (char*) casts.  
>
> I've tried that, but   ``it does not work'' later:
> {after having renamed  'elim_trailing'  to  'dropTrailing0' }
> my version of *using* the function was
>
> 1 SEXP attribute_hidden StringFromReal(double x, int *warn)
> 2 {
> 3   int w, d, e;
> 4   formatReal(&x, 1, &w, &d, &e, 0);
> 5   if (ISNA(x)) return NA_STRING;
> 6   else return mkChar(dropTrailing0(EncodeReal(x, w, d, e, OutDec), OutDec));
> 7 }
>
> where you need to consider that mkChar() expects a 'const char*' 
> and EncodeReal(.) returns one, and I am pretty sure this was the
> main reason why Petr had used the two 'const char*' in (the
> now-named) dropTrailing0() definition. 
> If I use your proposed signature
>
> char* dropTrailing0(char *s, char cdec);
>
> line 6 above gives warnings in all of several incantations I've tried
> including this one :
>
>     else return mkChar((const char *) dropTrailing0((char *)EncodeReal(x, w, d, e, OutDec), OutDec));
>
> which (the warnings) leave me somewhat clue-less or rather
> unmotivated to dig further, though I must say that I'm not the
> expert on the subject char*  / const char* ..
>   

of course, if the input *is* const and the output is expected to be
const, you should get an error/warning in the first case, and at least a
warning in the other (depending on the level of verbosity/pedanticity
you choose).

but my point was not to light-headedly change the signature/return of
elim_trailing and its implementation and use it in the original
context;  it was to either modify the context as well (if const is
inessential), or drop modifying the const string if the const is in fact
essential.


>     vQ>   another way out is to make
>     vQ> elim_trailing actually allocate and return a new string, keeping the
>     vQ> input truly constant, at a performance cost    .  yet another way is to
>     vQ> ignore the issue, of course.
>
>     vQ> the original (martin/petr) version may quietly pass -Wall, but the
>     vQ> compiler would complain (rightfully) with -Wcast-qual.
>
> hmm, yes, but actually I haven't found a solution along your
> proposition that even passes   -pedantic -Wall -Wcast-align
> (the combination I've personally been using for a long time).
>   

one way is to return from elim_trailing a new, const copy of the const
string.  using memcpy should be efficient enough.  care should be taken
to deallocate s when no longer needed.  (my guess is that using the
approach suggested here, s can be deallocated as soon as it is copied,
which means pretty much that it does not really have to be const.)

> Maybe we can try to solve this more esthetically
> in private e-mail exchange?
>   

sure, we can discuss aesthetics offline.  as long as we do not discuss
aesthetics (do we?), it seems appropriate to me to keep the discussion
online.

i will experiment with a patch to solve this issue, and let you know
when i have something reasonable.

best,
vQ


From jv at cs.dartmouth.edu  Fri May 29 23:33:47 2009
From: jv at cs.dartmouth.edu (Jason Vertrees)
Date: Fri, 29 May 2009 17:33:47 -0400
Subject: [Rd] Why change data type when dropping to one-dimension?
Message-ID: <4A2054BB.3010900@cs.dartmouth.edu>

Hello,

First, let me say I'm an avid fan of R--it's incredibly powerful and I
use it all the time.  I appreciate all the hard work that the many
developers have undergone.

My question is: why does the paradigm of changing the type of a 1D
return value to an unlisted array exist?  This introduces boundary
conditions where none need exist, thus making the coding harder and
confusing.

For example, consider:
  > d = data.frame(a=rnorm(10), b=rnorm(10));
  > typeof(d);			# OK;
  > typeof(d[,1]);  		# Unexpected;
  > typeof(d[,1,drop=F]);	# Oh, now I see.

This is indeed documented in the R Language specification, but why is it
there in the first place?  It doesn't make sense to the average
programmer to change the return type based on dimension.

Here it is again in 'sapply':
  > sapply
  > function (X, FUN, ..., simplify = TRUE, USE.NAMES = TRUE)
  > {
  >	[...snip...]
  >        if (common.len == 1)
  >            unlist(answer, recursive = FALSE)
  >        else if (common.len > 1)
  >            array(unlist(answer, recursive = FALSE),
  >			dim = c(common.len,
  >                length(X)), dimnames = if (!(is.null(n1 <-
  >			names(answer[[1]])) &
  >                is.null(n2 <- names(answer))))
  >                list(n1, n2))
  >	[...snip...]
  >  }

So, in 'sapply', if your return value is one-dimensional be careful,
because the return type will not the be same as if it were otherwise.

Is this legacy or a valid, rational design decision which I'm not yet a
sophisticated enough R coder to enjoy?

Thanks,

-- Jason

-- 

Jason Vertrees, PhD

Dartmouth College : jv at cs.dartmouth.edu
Boston University : jasonv at bu.edu

PyMOLWiki : http://www.pymolwiki.org/


From maechler at stat.math.ethz.ch  Fri May 29 23:48:30 2009
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 29 May 2009 23:48:30 +0200
Subject: [Rd] as.numeric(levels(factor(x))) may be a decreasing sequence
In-Reply-To: <4A203D67.8000007@idi.ntnu.no>
References: <20090523074454.GA17112@cs.cas.cz>
	<18973.42970.826686.173830@cmath-5.math.ethz.ch>
	<4A1DC057.80401@idi.ntnu.no>
	<18975.59582.885300.549159@lynne.math.ethz.ch>
	<4A203D67.8000007@idi.ntnu.no>
Message-ID: <3f1d2410905291448y271fa484te82b8dbaa547017f@mail.gmail.com>

Hi Waclav (and other interested parties),

I have committed my working version of src/main/coerce.c
so you can prepare your patch against that.

Thank you in advance!
Martin

On Fri, May 29, 2009 at 21:54, Wacek Kusnierczyk
<Waclaw.Marcin.Kusnierczyk at idi.ntnu.no> wrote:
> Martin Maechler wrote:
>
> [...]
>> ? ? vQ> you return s, which should be the same pointer value (given the actual
>> ? ? vQ> code that does not modify the local variable s) with the same pointed-to
>> ? ? vQ> string value (given the signature of the function).
>>
>> ? ? vQ> was perhaps
>>
>> ? ? vQ> char *elim_trailing(char* const s, char cdec)
>>
>> ? ? vQ> intended?
>>
>> yes that would seem slightly more "logical" to my eyes,
>> and "in principle" I also agree with the other remarks you make above,
>>
>
> what does ' "in principle" ' mean, as opposed to 'in principle'? ?(is it
> emphasis, or sneer quotes?)
>
>> ...
>>
>> ? ? vQ> anyway, having the pointer s itself declared as const does
>> ? ? vQ> make sense, as the code seems to assume that exactly the input pointer
>> ? ? vQ> value should be returned. ?or maybe the argument to elim_trailing should
>> ? ? vQ> not be declared as const, since elim_trailing violates the declaration.
>>
>> ? ? vQ> one way out is to drop the violated const in both the actual argument
>> ? ? vQ> and in elim_trailing, which would then be simplified by removing all
>> ? ? vQ> const qualifiers and (char*) casts.
>>
>> I've tried that, but ? ``it does not work'' later:
>> {after having renamed ?'elim_trailing' ?to ?'dropTrailing0' }
>> my version of *using* the function was
>>
>> 1 SEXP attribute_hidden StringFromReal(double x, int *warn)
>> 2 {
>> 3 ? int w, d, e;
>> 4 ? formatReal(&x, 1, &w, &d, &e, 0);
>> 5 ? if (ISNA(x)) return NA_STRING;
>> 6 ? else return mkChar(dropTrailing0(EncodeReal(x, w, d, e, OutDec), OutDec));
>> 7 }
>>
>> where you need to consider that mkChar() expects a 'const char*'
>> and EncodeReal(.) returns one, and I am pretty sure this was the
>> main reason why Petr had used the two 'const char*' in (the
>> now-named) dropTrailing0() definition.
>> If I use your proposed signature
>>
>> char* dropTrailing0(char *s, char cdec);
>>
>> line 6 above gives warnings in all of several incantations I've tried
>> including this one :
>>
>> ? ? else return mkChar((const char *) dropTrailing0((char *)EncodeReal(x, w, d, e, OutDec), OutDec));
>>
>> which (the warnings) leave me somewhat clue-less or rather
>> unmotivated to dig further, though I must say that I'm not the
>> expert on the subject char* ?/ const char* ..
>>
>
> of course, if the input *is* const and the output is expected to be
> const, you should get an error/warning in the first case, and at least a
> warning in the other (depending on the level of verbosity/pedanticity
> you choose).
>
> but my point was not to light-headedly change the signature/return of
> elim_trailing and its implementation and use it in the original
> context; ?it was to either modify the context as well (if const is
> inessential), or drop modifying the const string if the const is in fact
> essential.
>
>
>> ? ? vQ> ? another way out is to make
>> ? ? vQ> elim_trailing actually allocate and return a new string, keeping the
>> ? ? vQ> input truly constant, at a performance cost ? ?. ?yet another way is to
>> ? ? vQ> ignore the issue, of course.
>>
>> ? ? vQ> the original (martin/petr) version may quietly pass -Wall, but the
>> ? ? vQ> compiler would complain (rightfully) with -Wcast-qual.
>>
>> hmm, yes, but actually I haven't found a solution along your
>> proposition that even passes ? -pedantic -Wall -Wcast-align
>> (the combination I've personally been using for a long time).
>>
>
> one way is to return from elim_trailing a new, const copy of the const
> string. ?using memcpy should be efficient enough. ?care should be taken
> to deallocate s when no longer needed. ?(my guess is that using the
> approach suggested here, s can be deallocated as soon as it is copied,
> which means pretty much that it does not really have to be const.)
>
>> Maybe we can try to solve this more esthetically
>> in private e-mail exchange?
>>
>
> sure, we can discuss aesthetics offline. ?as long as we do not discuss
> aesthetics (do we?), it seems appropriate to me to keep the discussion
> online.
>
> i will experiment with a patch to solve this issue, and let you know
> when i have something reasonable.
>
> best,
> vQ
>
>


From tlumley at u.washington.edu  Fri May 29 23:54:32 2009
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Fri, 29 May 2009 14:54:32 -0700 (PDT)
Subject: [Rd] Why change data type when dropping to one-dimension?
In-Reply-To: <4A2054BB.3010900@cs.dartmouth.edu>
Message-ID: <Pine.LNX.4.43.0905291454320.7202@hymn11.u.washington.edu>

On Fri, 29 May 2009, Jason Vertrees wrote:

> My question is: why does the paradigm of changing the type of a 1D
> return value to an unlisted array exist?  This introduces boundary
> conditions where none need exist, thus making the coding harder and
> confusing.
>
> For example, consider:
>  > d = data.frame(a=rnorm(10), b=rnorm(10));
>  > typeof(d);			# OK;
>  > typeof(d[,1]);  		# Unexpected;
>  > typeof(d[,1,drop=F]);	# Oh, now I see.

It does make it harder for programmers, but it makes it easier for non-programmers.  In particular, it is convenient to be able to do d[1,1] to extract a number from a matrix, rather than having to explicitly coerce the result to stop it being a matrix.

At least the last two times this was discussed, there ended up being a reasonable level of agreement that if someone's life had to be made harder the programmers were better able to cope and that dropping dimensions was preferable.

     -thomas

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle


From macrakis at alum.mit.edu  Sat May 30 00:17:31 2009
From: macrakis at alum.mit.edu (Stavros Macrakis)
Date: Fri, 29 May 2009 18:17:31 -0400
Subject: [Rd] Why change data type when dropping to one-dimension?
In-Reply-To: <4A2054BB.3010900@cs.dartmouth.edu>
References: <4A2054BB.3010900@cs.dartmouth.edu>
Message-ID: <8b356f880905291517q49573f79v84f60b93c3906572@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090529/61c4fa82/attachment.pl>

From jv at cs.dartmouth.edu  Sat May 30 00:17:28 2009
From: jv at cs.dartmouth.edu (Jason Vertrees)
Date: Fri, 29 May 2009 18:17:28 -0400
Subject: [Rd] Why change data type when dropping to one-dimension?
In-Reply-To: <Pine.LNX.4.43.0905291454320.7202@hymn11.u.washington.edu>
References: <Pine.LNX.4.43.0905291454320.7202@hymn11.u.washington.edu>
Message-ID: <4A205EF8.5010604@cs.dartmouth.edu>

Thomas Lumley wrote:
> On Fri, 29 May 2009, Jason Vertrees wrote:
> 
>> My question is: why does the paradigm of changing the type of a 1D
>> return value to an unlisted array exist?  This introduces boundary
>> conditions where none need exist, thus making the coding harder and
>> confusing.
>>
>> For example, consider:
>>  > d = data.frame(a=rnorm(10), b=rnorm(10));
>>  > typeof(d);            # OK;
>>  > typeof(d[,1]);          # Unexpected;
>>  > typeof(d[,1,drop=F]);    # Oh, now I see.
> 
> It does make it harder for programmers, but it makes it easier for
> non-programmers.  In particular, it is convenient to be able to do
> d[1,1] to extract a number from a matrix, rather than having to
> explicitly coerce the result to stop it being a matrix.
> 
> At least the last two times this was discussed, there ended up being a
> reasonable level of agreement that if someone's life had to be made
> harder the programmers were better able to cope and that dropping
> dimensions was preferable.
> 
>     -thomas
> 
> Thomas Lumley            Assoc. Professor, Biostatistics
> tlumley at u.washington.edu    University of Washington, Seattle


Thomas,

Thanks for the quick response.  I agree that extracting a number from a
matrix/frame should result in a number not a matrix/frame.  But, why do
that for a 1D array of numbers?  In my example,
  > d[,1];
is an array, not a single number.  How does that help the novice user?

I guess I just don't like the idea that the default result is to act
unexpectedly and that a flag or boundary-conditional code is needed to
"do the right thing".

Regardless that's how it is, so I just need to learn the pitfalls for
where that occurs.

Thanks again,

-- Jason

-- 

Jason Vertrees, PhD

Dartmouth College : jv at cs.dartmouth.edu
Boston University : jasonv at bu.edu

PyMOLWiki : http://www.pymolwiki.org/


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Sat May 30 00:25:26 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Sat, 30 May 2009 00:25:26 +0200
Subject: [Rd] Why change data type when dropping to one-dimension?
In-Reply-To: <8b356f880905291517q49573f79v84f60b93c3906572@mail.gmail.com>
References: <4A2054BB.3010900@cs.dartmouth.edu>
	<8b356f880905291517q49573f79v84f60b93c3906572@mail.gmail.com>
Message-ID: <4A2060D6.3020401@idi.ntnu.no>

Stavros Macrakis wrote:
> This is another example of the general preference of the designers of R for
> convenience over consistency.
>
> In my opinion, this is a design flaw even for non-programmers, because I
> find that inconsistencies make the system harder to learn.  Yes, the naive
> user may stumble over the difference between m[[1,1]] and m[1,1] a few times
> before getting it, but once he or she understands the principle, it is
> general.
>   

+1

vQ


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Sat May 30 00:28:35 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Sat, 30 May 2009 00:28:35 +0200
Subject: [Rd] as.numeric(levels(factor(x))) may be a decreasing sequence
In-Reply-To: <3f1d2410905291448y271fa484te82b8dbaa547017f@mail.gmail.com>
References: <20090523074454.GA17112@cs.cas.cz>	<18973.42970.826686.173830@cmath-5.math.ethz.ch>	<4A1DC057.80401@idi.ntnu.no>	<18975.59582.885300.549159@lynne.math.ethz.ch>	<4A203D67.8000007@idi.ntnu.no>
	<3f1d2410905291448y271fa484te82b8dbaa547017f@mail.gmail.com>
Message-ID: <4A206193.8070807@idi.ntnu.no>

Martin Maechler wrote:
> Hi Waclav (and other interested parties),
>
> I have committed my working version of src/main/coerce.c
> so you can prepare your patch against that.
>   

Hi Martin,

One quick reaction (which does not resolve my original complaint):  you
can have p non-const, and cast s to char* on the first occasion its
value is assigned to p, thus being able to copy from p to replace
without repetitive casts.  make check-ed patch atatched.

vQ
-------------- next part --------------
A non-text attachment was scrubbed...
Name: dropTrailing.patch
Type: text/x-diff
Size: 593 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090530/f6b8cc02/attachment.bin>

From tlumley at u.washington.edu  Sat May 30 00:50:31 2009
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Fri, 29 May 2009 15:50:31 -0700 (PDT)
Subject: [Rd] Why change data type when dropping to one-dimension?
In-Reply-To: <8b356f880905291517q49573f79v84f60b93c3906572@mail.gmail.com>
Message-ID: <Pine.LNX.4.43.0905291550310.7202@hymn11.u.washington.edu>

On Fri, 29 May 2009, Stavros Macrakis wrote:

> This is another example of the general preference of the designers of R for
> convenience over consistency.
>
> In my opinion, this is a design flaw even for non-programmers, because I
> find that inconsistencies make the system harder to learn.  Yes, the naive
> user may stumble over the difference between m[[1,1]] and m[1,1] a few times
> before getting it, but once he or she understands the principle, it is
> general.

I was on your side of this argument the first time it came up, but ended up being convinced the other way.

In contrast to sample(n) or the non-standard evaluation of weights= and subset= arguments to modelling functions, or various other conveniences that I think we are stuck with despite them being a bad idea, I think dropping dimensions is useful.

      -thomas




>                 -s
>
> On Fri, May 29, 2009 at 5:33 PM, Jason Vertrees <jv at cs.dartmouth.edu> wrote:
>
>> Hello,
>>
>> First, let me say I'm an avid fan of R--it's incredibly powerful and I
>> use it all the time.  I appreciate all the hard work that the many
>> developers have undergone.
>>
>> My question is: why does the paradigm of changing the type of a 1D
>> return value to an unlisted array exist?  This introduces boundary
>> conditions where none need exist, thus making the coding harder and
>> confusing.
>>
>> For example, consider:
>> > d = data.frame(a=rnorm(10), b=rnorm(10));
>> > typeof(d);                  # OK;
>> > typeof(d[,1]);              # Unexpected;
>> > typeof(d[,1,drop=F]);       # Oh, now I see.
>>
>> This is indeed documented in the R Language specification, but why is it
>> there in the first place?  It doesn't make sense to the average
>> programmer to change the return type based on dimension.
>>
>> Here it is again in 'sapply':
>> > sapply
>> > function (X, FUN, ..., simplify = TRUE, USE.NAMES = TRUE)
>> > {
>> >     [...snip...]
>> >        if (common.len == 1)
>> >            unlist(answer, recursive = FALSE)
>> >        else if (common.len > 1)
>> >            array(unlist(answer, recursive = FALSE),
>> >                     dim = c(common.len,
>> >                length(X)), dimnames = if (!(is.null(n1 <-
>> >                     names(answer[[1]])) &
>> >                is.null(n2 <- names(answer))))
>> >                list(n1, n2))
>> >     [...snip...]
>> >  }
>>
>> So, in 'sapply', if your return value is one-dimensional be careful,
>> because the return type will not the be same as if it were otherwise.
>>
>> Is this legacy or a valid, rational design decision which I'm not yet a
>> sophisticated enough R coder to enjoy?
>>
>> Thanks,
>>
>> -- Jason
>>
>> --
>>
>> Jason Vertrees, PhD
>>
>> Dartmouth College : jv at cs.dartmouth.edu
>> Boston University : jasonv at bu.edu
>>
>> PyMOLWiki : http://www.pymolwiki.org/
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle


From hpages at fhcrc.org  Sat May 30 01:32:01 2009
From: hpages at fhcrc.org (=?ISO-8859-1?Q?Herv=E9_Pag=E8s?=)
Date: Fri, 29 May 2009 16:32:01 -0700
Subject: [Rd] png() error in recent R-devel on Windows
Message-ID: <4A207071.8040003@fhcrc.org>

Hi,

Tested with the latest r-devel snapshot build for Windows (2009-05-28 r48663):

 > png("test.png")
Error in png("test.png") : invalid value of 'fillOddEven'

The png() function is defined like this:

 > png
function (filename = "Rplot%03d.png", width = 480, height = 480,
     units = "px", pointsize = 12, bg = "white", res = NA, restoreConsole = TRUE)
{
     if (!checkIntFormat(filename))
         stop("invalid 'filename'")
     filename <- path.expand(filename)
     units <- match.arg(units, c("in", "px", "cm", "mm"))
     if (units != "px" && is.na(res))
         stop("'res' must be specified unless 'units = \"px\"'")
     height <- switch(units, `in` = res, cm = res/2.54, mm = res/25.4,
         px = 1) * height
     width <- switch(units, `in` = res, cm = res/2.54, mm = 1/25.4,
         px = 1) * width
     invisible(.External(Cdevga, paste("png:", filename, sep = ""),
         width, height, pointsize, FALSE, 1L, NA_real_, NA_real_,
         bg, 1, as.integer(res), NA_integer_, FALSE, .PSenv, NA,
         restoreConsole, "", FALSE))
}

Note that the call to .External has 19 arguments, the last 2 of them being
"" and FALSE but the devga() function defined in src/library/grDevices/src/init.c
expects 1 more argument (19 + the entry point name), the last 3 of them
being expected to be string (title), logical (clickToConfirm), and
logical (fillOddEven). So it seems like the recently added 'fillOddEven'
argument (r48294) is omitted in the .External call, hence the error.

 > sessionInfo()
R version 2.10.0 Under development (unstable) (2009-05-28 r48663)
i386-pc-mingw32

locale:
[1] LC_COLLATE=English_United States.1252
[2] LC_CTYPE=English_United States.1252
[3] LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C
[5] LC_TIME=English_United States.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

Cheers,
H.


-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M2-B876
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fhcrc.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From murdoch at stats.uwo.ca  Sat May 30 01:42:58 2009
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri, 29 May 2009 19:42:58 -0400
Subject: [Rd] png() error in recent R-devel on Windows
In-Reply-To: <4A207071.8040003@fhcrc.org>
References: <4A207071.8040003@fhcrc.org>
Message-ID: <4A207302.5040103@stats.uwo.ca>

Thanks, will fix.

Duncan Murdoch

On 29/05/2009 7:32 PM, Herv? Pag?s wrote:
> Hi,
> 
> Tested with the latest r-devel snapshot build for Windows (2009-05-28 r48663):
> 
>  > png("test.png")
> Error in png("test.png") : invalid value of 'fillOddEven'
> 
> The png() function is defined like this:
> 
>  > png
> function (filename = "Rplot%03d.png", width = 480, height = 480,
>      units = "px", pointsize = 12, bg = "white", res = NA, restoreConsole = TRUE)
> {
>      if (!checkIntFormat(filename))
>          stop("invalid 'filename'")
>      filename <- path.expand(filename)
>      units <- match.arg(units, c("in", "px", "cm", "mm"))
>      if (units != "px" && is.na(res))
>          stop("'res' must be specified unless 'units = \"px\"'")
>      height <- switch(units, `in` = res, cm = res/2.54, mm = res/25.4,
>          px = 1) * height
>      width <- switch(units, `in` = res, cm = res/2.54, mm = 1/25.4,
>          px = 1) * width
>      invisible(.External(Cdevga, paste("png:", filename, sep = ""),
>          width, height, pointsize, FALSE, 1L, NA_real_, NA_real_,
>          bg, 1, as.integer(res), NA_integer_, FALSE, .PSenv, NA,
>          restoreConsole, "", FALSE))
> }
> 
> Note that the call to .External has 19 arguments, the last 2 of them being
> "" and FALSE but the devga() function defined in src/library/grDevices/src/init.c
> expects 1 more argument (19 + the entry point name), the last 3 of them
> being expected to be string (title), logical (clickToConfirm), and
> logical (fillOddEven). So it seems like the recently added 'fillOddEven'
> argument (r48294) is omitted in the .External call, hence the error.
> 
>  > sessionInfo()
> R version 2.10.0 Under development (unstable) (2009-05-28 r48663)
> i386-pc-mingw32
> 
> locale:
> [1] LC_COLLATE=English_United States.1252
> [2] LC_CTYPE=English_United States.1252
> [3] LC_MONETARY=English_United States.1252
> [4] LC_NUMERIC=C
> [5] LC_TIME=English_United States.1252
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> Cheers,
> H.
> 
>


From gkerns at ysu.edu  Sat May 30 06:35:22 2009
From: gkerns at ysu.edu (G. Jay Kerns)
Date: Sat, 30 May 2009 00:35:22 -0400
Subject: [Rd] setdiff bizarre (was: odd behavior out of setdiff)
Message-ID: <a695148b0905292135g1c1bee38xb70687a43ccaa934@mail.gmail.com>

Dear R-devel,

Please see the recent thread on R-help, "Odd Behavior Out of
setdiff(...) - addition of duplicate entries is not identified" posted
by Jason Rupert.  I gave an answer, then read David Winsemius' answer,
and then did some follow-up investigation.

I would like to change my answer.

My current version of setdiff() is acting in a way that I do not
understand, and a way that I suspect  has changed.  Consider the
following, derived from Jason's OP:

The base package setdiff(), atomic vectors:

x <- 1:100
y <- c(x,x)

setdiff(x, y)  # integer(0)
setdiff(y, x)  # integer(0)

z <- 1:25

setdiff(x,z)   # 26:100
setdiff(z,x)   # integer(0)


Everything is fine.

Now look at base package setdiff(), data frames???

################################
A <- data.frame(x = 1:100)
B <- rbind(A, A)

setdiff(A, B)               # df 1:100?
setdiff(B, A)               # df 1:100?

C <- data.frame(x = 1:25)

setdiff(A, C)               # df 1:100?
setdiff(C, A)               # df 1:25?

############################


I have read ?setdiff 37 times now, and I cannot divine any
interpretation that matches the above output.  From the source, it
appears that

match(x, y, 0L) == 0L

is evaluating to TRUE, of length equal to the columns of x, and then

x[match(x, y, 0L) == 0L]

is returning the entire data frame.

Compare with the output from package "prob", which uses a setdiff that
operates row-wise:


###########################
library(prob)
A <- data.frame(x = 1:100)
B <- rbind(A, A)

setdiff(A, B)               # integer(0)
setdiff(B, A)               # integer(0)

C <- data.frame(x = 1:25)

setdiff(A, C)               # 26:100
setdiff(C, A)               # integer(0)



IMHO, the entire notion of "set" and "element" is problematic in the
df case, so I am not advocating the adoption of the prob:::setdiff
approach;  rather, setdiff is behaving in a way that I cannot believe
with my own eyes, and I would like to alert those who can speak as to
why this may be happening.

Thanks to Jason for bringing this up, and to David for catching the discrepancy.

Session info is below.  I use the binaries prepared by the Debian
group so I do not have the latest patched-revision-4440986745343b.
This must have been related to something which has been fixed since
April 17, and in that case, please disregard my message.

Yours truly,
Jay






> sessionInfo()
R version 2.9.0 (2009-04-17)
x86_64-pc-linux-gnu

locale:
LC_CTYPE=en_US.UTF-8;LC_NUMERIC=C;LC_TIME=en_US.UTF-8;LC_COLLATE=en_US.UTF-8;LC_MONETARY=C;LC_MESSAGES=en_US.UTF-8;LC_PAPER=en_US.UTF-8;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=en_US.UTF-8;LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] prob_0.9-1

















-- 

***************************************************
G. Jay Kerns, Ph.D.
Associate Professor
Department of Mathematics & Statistics
Youngstown State University
Youngstown, OH 44555-0002 USA
Office: 1035 Cushwa Hall
Phone: (330) 941-3310 Office (voice mail)
-3302 Department
-3170 FAX
E-mail: gkerns at ysu.edu
http://www.cc.ysu.edu/~gjkerns/


From hb at stat.berkeley.edu  Sat May 30 08:08:39 2009
From: hb at stat.berkeley.edu (Henrik Bengtsson)
Date: Fri, 29 May 2009 23:08:39 -0700
Subject: [Rd] socketConnection() + Ctrl-C + closeAllConnections() => core
	dump
Message-ID: <59d7961d0905292308o4bbf588hc4d72c4aff4f56a9@mail.gmail.com>

Doing the following in R v2.9.0 on Windows Vista core dumps R:

0. Rterm --vanilla
1. con <- socketConnection(port=6011);
2. User interrupt, i.e. Ctrl-C
3. closeAllConnections();

R crashes immediately after calling that last command.

sessionInfo():

R version 2.9.0 Patched (2009-05-28 r48680)
i386-pc-mingw32

locale:
LC_COLLATE=English_United States.1252;LC_CTYPE=English_United States.1252;LC_MON
ETARY=English_United States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

/Henrik


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Sat May 30 11:16:43 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Sat, 30 May 2009 11:16:43 +0200
Subject: [Rd] as.numeric(levels(factor(x))) may be a decreasing sequence
In-Reply-To: <3f1d2410905291448y271fa484te82b8dbaa547017f@mail.gmail.com>
References: <20090523074454.GA17112@cs.cas.cz>	<18973.42970.826686.173830@cmath-5.math.ethz.ch>	<4A1DC057.80401@idi.ntnu.no>	<18975.59582.885300.549159@lynne.math.ethz.ch>	<4A203D67.8000007@idi.ntnu.no>
	<3f1d2410905291448y271fa484te82b8dbaa547017f@mail.gmail.com>
Message-ID: <4A20F97B.1090406@idi.ntnu.no>

Martin Maechler wrote:
> Hi Waclav (and other interested parties),
>
> I have committed my working version of src/main/coerce.c
> so you can prepare your patch against that.
>   

some further investigation and reflections on the code in StringFromReal
(henceforth SFR), src/main/coerce.c:315 (as in the patched version, now
in r-devel).

petr's elim_trailing (renamed to dropTrailing, henceforth referred to as
DT) takes as input a const char*, and returns a const char*.

const-ness of the return is not a problem;  it is fed into mkChar, which
(via mkCharLenCE) makes a local memcpy of the string, and there's no
violation of the contract here.

const-ness of the input is a consequence of the return type of
EncodeReal (henceforth EC).  however, it is hardly ever, "in principle",
a good idea to destructively modify const input (as DT does) if it comes
from a function that explicitly provides it as const (as ER does).

the first question is, why does ER return the string as const?  it
appears that the returned pointer provides the address of a buffer used
internally in ER, which is allocated *statically*.  that is, each call
to ER operates on the same memory location, and each call to ER returns
the address of that same location.  i suspect this is intended to be a
smart optimization, to avoid heap- or stack-allocating a new buffer in
each call to ER, and deallocating it after use.  however, this appraoch
is problematic, in that any two calls to ER return the address of the
same piece of memory, and this may easily lead to data corruption. 

under the assumption that the content of this piece of memory is copied
before any destructive use, and that after the string is copied the
address is not further distributed, the hack is relatively harmless. 
this is what mkChar (via mkCharLenCE) does;  in SFR it copies the
content of s with memcpy, and wraps it into a SEXP that becomes the
return value from SFR.

the original author of this hack seems to have had some concern about
exporting (from ER) the address of a static buffer, hence the returned
buffer is const.  in principle, this should prevent corruption of the
buffer's content in situations such as

    // hypothetical
    char *p1 = ER(...);
    // p1 is some string returned from ER
    char p2 = ER(...);
    // p2 is some other string returned from ER

    // some modifications performed on the string referred to by p1
    p1[0] = 'x';
    // p2[0] is 'x' -- possible data corruption

still worse in a scenario with concurrent calls to ER.
  
however, since the output from ER is const, this is no longer possible
-- at least, not without a deconstifying cast the petr style.  the
problem with petr's solution is not only that it modifies shared memory
purposefully qualified as const (by virtue of ER's return type), but
also that it effectively distributes the address for further use. 

unfortunately, like most of the r source code, ER is not appropriately
commented at the declaration and the definition, and without looking at
the code, one can hardly have any clue that ER always return the same
address of a static location.  while the original developer might be
careful enough not to misuse ER, in a large multideveloper project it's
hard expect that from others.  petr's function is precisely an example
of such misuse, and as it adds (again, without an appropriate comment) a
step of indirection; any use of petr's function other than what you have
in SFR (and can you guarantee no one will ever use DT for other
purposes?) is even more likely to end up in data corruption.

one simple way to improve the code is as follows;  instead of (simplified)

    const char* dropTrailing(const char* s, ...) {
       const char *p = s;
       char *replace;
       ...
       replace = (char*) p;
       ...
       return s; }

    ...mkChar(dropTrailing(EncodeReal(...), ...) ...

you can have something like

    const char* dropTrailing(char* s, ...) {
       char *p = s, *replace;
       ...
       replace = p;
       ...
       return s; }

    ...mkChar(dropTrailing((char*)EncodeReal(...), ...) ...
  
where it is clear, from DT's signature, that it may (as it purposefully
does, in fact) modify the content of s.  that is, you drop the
promise-not-to-modify contract in DT, and move the need for
deconstifying ER's return out of DT, making it more explicit.

however, this is still an ad hoc hack;  it still breaks the original
developer's assumption (if i'm correct) that the return from ER
(pointing to its internal buffer) should not be destructively modified
outside of ER.

another issue is that even making the return from ER const does not
protect against data corruption.  for example,

    const char *p1 = ER(...)
    // p1 is some string returned from ER
    const char *p2 = ER(...)
    // p2 is some other string returned from ER
    // but p1 == p2

if p1 is used after the second call to ER, it's likely to lead to data
corruption problems.  frankly, i'd consider the design of ER essentially
flawed.  removing const from ER's return is obviously not an option;  it
would certainly be safer to have it return a pointer to a heap-allocated
buffer, but then the returned buffer would have to be freed at some
point in the client code, and this would require a whole cascade of
modifications to the r source code.  since it usually is more funny to
introduce new bugs than repair old ones, i'd not expect r core to be
ever willing to invest time in this.

the following seem acceptable and relatively reasonable ways to address
the issue:

(1) noop:  leave as is.

(2) minimal:  adopt the (inessential) changes suggested in my previous post:

    const char* dropTrailing(const char* s, ...) {
       char *p = (char*) s;
       // no further need for (char*) casting from p to replace
       ... }

(3) modify petr's solution along the lines above, i.e., have the input
in the signature non-const and deconst-cast the output from ER outside
of the call to DT.

(4) modify petr's solution to operate on a local, non-const copy of s:

    const char* dropTrailing(const char* s, ...) {
       int length = strlen(s);
       char *ss = malloc((length+1)*sizeof(char));
       memcpy(ss, s, length+1);
       // work on ss rather than on s
       ...
       return ss; }

and don't forget to deallocate the return from DT after mkChar (or
whoever calls DT) has no more need for it.  (an alternative is to use
the allocCharsxp approach of mkCharLenCE, but that would be overdoing
the job.)


to sum up:  for a clean solution, i find (4) preferable.  for
efficiency, (3) seems better, provided that you add a clear comment to
the effect that the assumption of non-modifiable output from ER is
purposefully violated.  (2) is acceptable provided that DT is
appropriately documented (i.e., that it does not really treat s as const
char*, but effectively as non-const char*), and with a note as above.

a final, bitter remark:  i'm surprised that it's so easy to have an r
core developer submit to r-devel a patch that violates an explicit
demand on the immutability of a shared, statically allocated piece of
memory. (even if it's the already existing code that actually is
problematic.)

no patch attached, you need to consider your options.  hope this helps
anyway.

best,
vQ


From macrakis at alum.mit.edu  Sat May 30 14:50:09 2009
From: macrakis at alum.mit.edu (Stavros Macrakis)
Date: Sat, 30 May 2009 08:50:09 -0400
Subject: [Rd] setdiff bizarre (was: odd behavior out of setdiff)
In-Reply-To: <a695148b0905292135g1c1bee38xb70687a43ccaa934@mail.gmail.com>
References: <a695148b0905292135g1c1bee38xb70687a43ccaa934@mail.gmail.com>
Message-ID: <8b356f880905300550y39c76b02h2d908b1c6b0ef0e4@mail.gmail.com>

It seems to me that, abstractly, a dataframe is just as
straightforwardly a sequence of tuples/observations as a vector is a
sequence of scalars. R's convention is that a 1-vector represents a
scalar, and similarly, a 1-dataframe can represent a tuple (though it
can also be represented as a list). Of course, a dataframe can *also*
be interpreted as a list of vectors.

Just as a sequence of scalars can be interpreted as a set of scalars
by the order- and repetition-ignoring homomophism, so can a sequence
of tuples. It seems to me natural that set operations should follow
that interpretation.

          -s

On 5/30/09, G. Jay Kerns <gkerns at ysu.edu> wrote:
> Dear R-devel,
>
> Please see the recent thread on R-help, "Odd Behavior Out of
> setdiff(...) - addition of duplicate entries is not identified" posted
> by Jason Rupert.  I gave an answer, then read David Winsemius' answer,
> and then did some follow-up investigation.
>
> I would like to change my answer.
>
> My current version of setdiff() is acting in a way that I do not
> understand, and a way that I suspect  has changed.  Consider the
> following, derived from Jason's OP:
>
> The base package setdiff(), atomic vectors:
>
> x <- 1:100
> y <- c(x,x)
>
> setdiff(x, y)  # integer(0)
> setdiff(y, x)  # integer(0)
>
> z <- 1:25
>
> setdiff(x,z)   # 26:100
> setdiff(z,x)   # integer(0)
>
>
> Everything is fine.
>
> Now look at base package setdiff(), data frames???
>
> ################################
> A <- data.frame(x = 1:100)
> B <- rbind(A, A)
>
> setdiff(A, B)               # df 1:100?
> setdiff(B, A)               # df 1:100?
>
> C <- data.frame(x = 1:25)
>
> setdiff(A, C)               # df 1:100?
> setdiff(C, A)               # df 1:25?
>
> ############################
>
>
> I have read ?setdiff 37 times now, and I cannot divine any
> interpretation that matches the above output.  From the source, it
> appears that
>
> match(x, y, 0L) == 0L
>
> is evaluating to TRUE, of length equal to the columns of x, and then
>
> x[match(x, y, 0L) == 0L]
>
> is returning the entire data frame.
>
> Compare with the output from package "prob", which uses a setdiff that
> operates row-wise:
>
>
> ###########################
> library(prob)
> A <- data.frame(x = 1:100)
> B <- rbind(A, A)
>
> setdiff(A, B)               # integer(0)
> setdiff(B, A)               # integer(0)
>
> C <- data.frame(x = 1:25)
>
> setdiff(A, C)               # 26:100
> setdiff(C, A)               # integer(0)
>
>
>
> IMHO, the entire notion of "set" and "element" is problematic in the
> df case, so I am not advocating the adoption of the prob:::setdiff
> approach;  rather, setdiff is behaving in a way that I cannot believe
> with my own eyes, and I would like to alert those who can speak as to
> why this may be happening.
>
> Thanks to Jason for bringing this up, and to David for catching the
> discrepancy.
>
> Session info is below.  I use the binaries prepared by the Debian
> group so I do not have the latest patched-revision-4440986745343b.
> This must have been related to something which has been fixed since
> April 17, and in that case, please disregard my message.
>
> Yours truly,
> Jay
>
>
>
>
>
>
>> sessionInfo()
> R version 2.9.0 (2009-04-17)
> x86_64-pc-linux-gnu
>
> locale:
> LC_CTYPE=en_US.UTF-8;LC_NUMERIC=C;LC_TIME=en_US.UTF-8;LC_COLLATE=en_US.UTF-8;LC_MONETARY=C;LC_MESSAGES=en_US.UTF-8;LC_PAPER=en_US.UTF-8;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=en_US.UTF-8;LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] prob_0.9-1
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
> --
>
> ***************************************************
> G. Jay Kerns, Ph.D.
> Associate Professor
> Department of Mathematics & Statistics
> Youngstown State University
> Youngstown, OH 44555-0002 USA
> Office: 1035 Cushwa Hall
> Phone: (330) 941-3310 Office (voice mail)
> -3302 Department
> -3170 FAX
> E-mail: gkerns at ysu.edu
> http://www.cc.ysu.edu/~gjkerns/
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From ligges at statistik.tu-dortmund.de  Sat May 30 15:24:46 2009
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sat, 30 May 2009 15:24:46 +0200
Subject: [Rd] as.numeric(levels(factor(x))) may be a decreasing sequence
In-Reply-To: <4A20F97B.1090406@idi.ntnu.no>
References: <20090523074454.GA17112@cs.cas.cz>	<18973.42970.826686.173830@cmath-5.math.ethz.ch>	<4A1DC057.80401@idi.ntnu.no>	<18975.59582.885300.549159@lynne.math.ethz.ch>	<4A203D67.8000007@idi.ntnu.no>	<3f1d2410905291448y271fa484te82b8dbaa547017f@mail.gmail.com>
	<4A20F97B.1090406@idi.ntnu.no>
Message-ID: <4A21339E.80801@statistik.tu-dortmund.de>



Wacek Kusnierczyk wrote:
> Martin Maechler wrote:
>> Hi Waclav (and other interested parties),
>>
>> I have committed my working version of src/main/coerce.c
>> so you can prepare your patch against that.
>>   
> 
> some further investigation and reflections on the code in StringFromReal
> (henceforth SFR), src/main/coerce.c:315 (as in the patched version, now
> in r-devel).
> 
> petr's elim_trailing (renamed to dropTrailing, henceforth referred to as
> DT) takes as input a const char*, and returns a const char*.
> 
> const-ness of the return is not a problem;  it is fed into mkChar, which
> (via mkCharLenCE) makes a local memcpy of the string, and there's no
> violation of the contract here.
> 
> const-ness of the input is a consequence of the return type of
> EncodeReal (henceforth EC).  however, it is hardly ever, "in principle",
> a good idea to destructively modify const input (as DT does) if it comes
> from a function that explicitly provides it as const (as ER does).
> 
> the first question is, why does ER return the string as const?  it
> appears that the returned pointer provides the address of a buffer used
> internally in ER, which is allocated *statically*.  that is, each call
> to ER operates on the same memory location, and each call to ER returns
> the address of that same location.  i suspect this is intended to be a
> smart optimization, to avoid heap- or stack-allocating a new buffer in
> each call to ER, and deallocating it after use.  however, this appraoch
> is problematic, in that any two calls to ER return the address of the
> same piece of memory, and this may easily lead to data corruption. 
> 
> under the assumption that the content of this piece of memory is copied
> before any destructive use, and that after the string is copied the
> address is not further distributed, the hack is relatively harmless. 
> this is what mkChar (via mkCharLenCE) does;  in SFR it copies the
> content of s with memcpy, and wraps it into a SEXP that becomes the
> return value from SFR.
> 
> the original author of this hack seems to have had some concern about
> exporting (from ER) the address of a static buffer, hence the returned
> buffer is const.  in principle, this should prevent corruption of the
> buffer's content in situations such as
> 
>     // hypothetical
>     char *p1 = ER(...);
>     // p1 is some string returned from ER
>     char p2 = ER(...);
>     // p2 is some other string returned from ER
> 
>     // some modifications performed on the string referred to by p1
>     p1[0] = 'x';
>     // p2[0] is 'x' -- possible data corruption
> 
> still worse in a scenario with concurrent calls to ER.
>   
> however, since the output from ER is const, this is no longer possible
> -- at least, not without a deconstifying cast the petr style.  the
> problem with petr's solution is not only that it modifies shared memory
> purposefully qualified as const (by virtue of ER's return type), but
> also that it effectively distributes the address for further use. 
> 
> unfortunately, like most of the r source code, ER is not appropriately
> commented at the declaration and the definition, and without looking at
> the code, one can hardly have any clue that ER always return the same
> address of a static location.  while the original developer might be
> careful enough not to misuse ER, in a large multideveloper project it's
> hard expect that from others.  petr's function is precisely an example
> of such misuse, and as it adds (again, without an appropriate comment) a
> step of indirection; any use of petr's function other than what you have
> in SFR (and can you guarantee no one will ever use DT for other
> purposes?) is even more likely to end up in data corruption.
> 
> one simple way to improve the code is as follows;  instead of (simplified)
> 
>     const char* dropTrailing(const char* s, ...) {
>        const char *p = s;
>        char *replace;
>        ...
>        replace = (char*) p;
>        ...
>        return s; }
> 
>     ...mkChar(dropTrailing(EncodeReal(...), ...) ...
> 
> you can have something like
> 
>     const char* dropTrailing(char* s, ...) {
>        char *p = s, *replace;
>        ...
>        replace = p;
>        ...
>        return s; }
> 
>     ...mkChar(dropTrailing((char*)EncodeReal(...), ...) ...
>   
> where it is clear, from DT's signature, that it may (as it purposefully
> does, in fact) modify the content of s.  that is, you drop the
> promise-not-to-modify contract in DT, and move the need for
> deconstifying ER's return out of DT, making it more explicit.
> 
> however, this is still an ad hoc hack;  it still breaks the original
> developer's assumption (if i'm correct) that the return from ER
> (pointing to its internal buffer) should not be destructively modified
> outside of ER.
> 
> another issue is that even making the return from ER const does not
> protect against data corruption.  for example,
> 
>     const char *p1 = ER(...)
>     // p1 is some string returned from ER
>     const char *p2 = ER(...)
>     // p2 is some other string returned from ER
>     // but p1 == p2
> 
> if p1 is used after the second call to ER, it's likely to lead to data
> corruption problems.  frankly, i'd consider the design of ER essentially
> flawed.  removing const from ER's return is obviously not an option;  it
> would certainly be safer to have it return a pointer to a heap-allocated
> buffer, but then the returned buffer would have to be freed at some
> point in the client code, and this would require a whole cascade of
> modifications to the r source code.  since it usually is more funny to
> introduce new bugs than repair old ones, i'd not expect r core to be
> ever willing to invest time in this.
> 
> the following seem acceptable and relatively reasonable ways to address
> the issue:
> 
> (1) noop:  leave as is.
> 
> (2) minimal:  adopt the (inessential) changes suggested in my previous post:
> 
>     const char* dropTrailing(const char* s, ...) {
>        char *p = (char*) s;
>        // no further need for (char*) casting from p to replace
>        ... }
> 
> (3) modify petr's solution along the lines above, i.e., have the input
> in the signature non-const and deconst-cast the output from ER outside
> of the call to DT.
> 
> (4) modify petr's solution to operate on a local, non-const copy of s:
> 
>     const char* dropTrailing(const char* s, ...) {
>        int length = strlen(s);
>        char *ss = malloc((length+1)*sizeof(char));
>        memcpy(ss, s, length+1);
>        // work on ss rather than on s
>        ...
>        return ss; }
> 
> and don't forget to deallocate the return from DT after mkChar (or
> whoever calls DT) has no more need for it.  (an alternative is to use
> the allocCharsxp approach of mkCharLenCE, but that would be overdoing
> the job.)
> 
> 
> to sum up:  for a clean solution, i find (4) preferable.  for
> efficiency, (3) seems better, provided that you add a clear comment to
> the effect that the assumption of non-modifiable output from ER is
> purposefully violated.  (2) is acceptable provided that DT is
> appropriately documented (i.e., that it does not really treat s as const
> char*, but effectively as non-const char*), and with a note as above.
> 
> a final, bitter remark:  i'm surprised that it's so easy to have an r
> core developer submit to r-devel a patch that violates an explicit
> demand on the immutability of a shared, statically allocated piece of
> memory. (even if it's the already existing code that actually is
> problematic.)


Well, I am not surprised at all: everybody is working hard (even on 
saturdays and sundays) and R is a thing that is also done, beside the 
real job as a recognized statistician (not a job as computer scientist, 
by the way). And I think we can be very happy with this status, because 
if the language was written by computer scientists only, it wouldn't 
have its best strengths where we need it: in statistics.

Please, we do not need the perfectly designed language (which does not 
exist anyway), but what we need is a language that is very easy to use 
in order to cope with all the actual problems in the world of statistics 
and beyond.

It is nice to see people submitting bug reports and even better to 
submit patches. Thank you very much for that! But I think it is not fair 
to blame the inventors and developers of the language again and again. I 
mean the language that has become so famous and indispensable among 
statisticians for some very good reasons.

Best,
Uwe Ligges



> no patch attached, you need to consider your options.  hope this helps
> anyway.
> 
> best,
> vQ
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From maechler at stat.math.ethz.ch  Sat May 30 16:11:18 2009
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Sat, 30 May 2009 16:11:18 +0200
Subject: [Rd] as.numeric(levels(factor(x))) may be a decreasing sequence
In-Reply-To: <4A206193.8070807@idi.ntnu.no>
References: <20090523074454.GA17112@cs.cas.cz>
	<18973.42970.826686.173830@cmath-5.math.ethz.ch>
	<4A1DC057.80401@idi.ntnu.no>
	<18975.59582.885300.549159@lynne.math.ethz.ch>
	<4A203D67.8000007@idi.ntnu.no>
	<3f1d2410905291448y271fa484te82b8dbaa547017f@mail.gmail.com>
	<4A206193.8070807@idi.ntnu.no>
Message-ID: <3f1d2410905300711k71a05880x8c5d42b2f2842f5b@mail.gmail.com>

2009/5/30 Wacek Kusnierczyk <Waclaw.Marcin.Kusnierczyk at idi.ntnu.no>:
> Martin Maechler wrote:
>> Hi Waclav (and other interested parties),
>>
>> I have committed my working version of src/main/coerce.c
>> so you can prepare your patch against that.
>>
>
> Hi Martin,
>
> One quick reaction (which does not resolve my original complaint): ?you
> can have p non-const, and cast s to char* on the first occasion its
> value is assigned to p, thus being able to copy from p to replace
> without repetitive casts. ?make check-ed patch atatched.

yes, thank you,
that's definitely more esthetically appealing (and as you said, does
not solve your original complaint).

(I'll wait a bit before further commits on this; notably I'll also
want to commit a corresponding entry to
 PrtUtil.h)

Martin


From gkerns at ysu.edu  Sat May 30 16:21:20 2009
From: gkerns at ysu.edu (G. Jay Kerns)
Date: Sat, 30 May 2009 10:21:20 -0400
Subject: [Rd] setdiff bizarre (was: odd behavior out of setdiff)
In-Reply-To: <8b356f880905300550y39c76b02h2d908b1c6b0ef0e4@mail.gmail.com>
References: <a695148b0905292135g1c1bee38xb70687a43ccaa934@mail.gmail.com> 
	<8b356f880905300550y39c76b02h2d908b1c6b0ef0e4@mail.gmail.com>
Message-ID: <a695148b0905300721x6e291e0bg66fefcf0931f2ce2@mail.gmail.com>

On Sat, May 30, 2009 at 8:50 AM, Stavros Macrakis <macrakis at alum.mit.edu> wrote:
> It seems to me that, abstractly, a dataframe is just as
> straightforwardly a sequence of tuples/observations as a vector is a
> sequence of scalars. R's convention is that a 1-vector represents a
> scalar, and similarly, a 1-dataframe can represent a tuple (though it
> can also be represented as a list). Of course, a dataframe can *also*
> be interpreted as a list of vectors.
>
> Just as a sequence of scalars can be interpreted as a set of scalars
> by the order- and repetition-ignoring homomophism, so can a sequence
> of tuples. It seems to me natural that set operations should follow
> that interpretation.
>
> ? ? ? ? ?-s


After a good night's sleep, the documentation says clearly that
setdiff() operates on two vectors (of the same mode), so my message
would be an example of "garbage in, garbage out".

It would be nice if there were an error thrown, but surely there are
more mission critical problems than this one.

Thanks anyway.
Jay


From macrakis at alum.mit.edu  Sat May 30 17:59:32 2009
From: macrakis at alum.mit.edu (Stavros Macrakis)
Date: Sat, 30 May 2009 11:59:32 -0400
Subject: [Rd] setdiff bizarre (was: odd behavior out of setdiff)
In-Reply-To: <a695148b0905300721x6e291e0bg66fefcf0931f2ce2@mail.gmail.com>
References: <a695148b0905292135g1c1bee38xb70687a43ccaa934@mail.gmail.com>
	<8b356f880905300550y39c76b02h2d908b1c6b0ef0e4@mail.gmail.com>
	<a695148b0905300721x6e291e0bg66fefcf0931f2ce2@mail.gmail.com>
Message-ID: <8b356f880905300859i5ba5800q5594bfce659373fe@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090530/b88b135a/attachment.pl>

From maechler at stat.math.ethz.ch  Sat May 30 19:32:52 2009
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Sat, 30 May 2009 19:32:52 +0200
Subject: [Rd] as.numeric(levels(factor(x))) may be a decreasing sequence
In-Reply-To: <4A20F97B.1090406@idi.ntnu.no>
References: <20090523074454.GA17112@cs.cas.cz>
	<18973.42970.826686.173830@cmath-5.math.ethz.ch>
	<4A1DC057.80401@idi.ntnu.no>
	<18975.59582.885300.549159@lynne.math.ethz.ch>
	<4A203D67.8000007@idi.ntnu.no>
	<3f1d2410905291448y271fa484te82b8dbaa547017f@mail.gmail.com>
	<4A20F97B.1090406@idi.ntnu.no>
Message-ID: <18977.28100.532043.734122@cmath-4.math.ethz.ch>

>>>>> "vQ" == Wacek Kusnierczyk <Waclaw.Marcin.Kusnierczyk at idi.ntnu.no>
>>>>>     on Sat, 30 May 2009 11:16:43 +0200 writes:

    vQ> Martin Maechler wrote:
    >> Hi Waclav (and other interested parties),
    >> 
    >> I have committed my working version of src/main/coerce.c
    >> so you can prepare your patch against that.
    >> 

    vQ> some further investigation and reflections on the code in StringFromReal
    vQ> (henceforth SFR), src/main/coerce.c:315 (as in the
    vQ> patched version, now in r-devel).

    vQ> petr's elim_trailing (renamed to dropTrailing,
    vQ> henceforth referred to as DT) takes as input a const
    vQ> char*, and returns a const char*.

    vQ> const-ness of the return is not a problem; it is fed
    vQ> into mkChar, which (via mkCharLenCE) makes a local
    vQ> memcpy of the string, and there's no violation of the
    vQ> contract here.

    vQ> const-ness of the input is a consequence of the return
    vQ> type of EncodeReal (henceforth EC).  however, it is
    vQ> hardly ever, "in principle", a good idea to
    vQ> destructively modify const input (as DT does) if it
    vQ> comes from a function that explicitly provides it as
    vQ> const (as ER does).

yes, I think we've alway agreed on that "in principle".

    vQ> the first question is, why does ER return the string as const?  it
    vQ> appears that the returned pointer provides the address of a buffer used
    vQ> internally in ER, which is allocated *statically*.  that is, each call
    vQ> to ER operates on the same memory location, and each call to ER returns
    vQ> the address of that same location.  i suspect this is intended to be a
    vQ> smart optimization, to avoid heap- or stack-allocating a new buffer in
    vQ> each call to ER, and deallocating it after use.  however, this appraoch
    vQ> is problematic, in that any two calls to ER return the address of the
    vQ> same piece of memory, and this may easily lead to data corruption. 

Well, that would be ok if R could be used "threaded" / parallel / ...
and we all know that there are many other pieces of code {not
just R's "own", but also in Fortran/C algorithms ..} that are
not thread-safe.
"Yes, of course", R looks like a horrible piece of software to
some,  because of that

    vQ> under the assumption that the content of this piece of memory is copied
    vQ> before any destructive use, and that after the string is copied the
    vQ> address is not further distributed, the hack is relatively harmless. 
    vQ> this is what mkChar (via mkCharLenCE) does;  in SFR it copies the
    vQ> content of s with memcpy, and wraps it into a SEXP that becomes the
    vQ> return value from SFR.

exactly.

    vQ> the original author of this hack seems to have had some concern about
    vQ> exporting (from ER) the address of a static buffer, hence the returned
    vQ> buffer is const.  in principle, this should prevent corruption of the
    vQ> buffer's content in situations such as

    vQ> // hypothetical
    vQ> char *p1 = ER(...);
    vQ> // p1 is some string returned from ER
    vQ> char p2 = ER(...);
    vQ> // p2 is some other string returned from ER

    vQ> // some modifications performed on the string referred to by p1
    vQ> p1[0] = 'x';
    vQ> // p2[0] is 'x' -- possible data corruption

    vQ> still worse in a scenario with concurrent calls to ER.
  
(which will not happen in the near future)

    vQ> however, since the output from ER is const, this is no longer possible
    vQ> -- at least, not without a deconstifying cast the petr style.  the
    vQ> problem with petr's solution is not only that it modifies shared memory
    vQ> purposefully qualified as const (by virtue of ER's return type), but
    vQ> also that it effectively distributes the address for further use. 

    vQ> unfortunately, like most of the r source code, ER is not appropriately
    vQ> commented at the declaration and the definition, and without looking at
    vQ> the code, one can hardly have any clue that ER always return the same
    vQ> address of a static location.  while the original developer might be
    vQ> careful enough not to misuse ER, in a large multideveloper project it's
    vQ> hard expect that from others.  petr's function is precisely an example
    vQ> of such misuse, and as it adds (again, without an appropriate comment) a
    vQ> step of indirection; any use of petr's function other than what you have
    vQ> in SFR (and can you guarantee no one will ever use DT for other
    vQ> purposes?) is even more likely to end up in data corruption.

you have a point here, and as a consequence, I'm proposing to
put the following version of DT  into the source :
------------------------------------------------------------------------

/* Note that we modify a  'const char*'  which is unsafe in general,
 * but ok in the context of filtering an Encode*() value into mkChar(): */
static const char* dropTrailing0(char *s, char cdec)
{
    char *p = s;
    for (p = s; *p; p++) {
	if(*p == cdec) {
	    char *replace = p++;
	    while ('0' <= *p  &&  *p <= '9')
		if(*(p++) != '0')
		    replace = p;
	    while((*(replace++) = *(p++)))
		;
	    break;
	}
    }
    return s;
}

------------------------------------------------------------------------

so it has a comment along the lines you suggest, *and* as static
is not callable from outside coerce.c


    vQ> one simple way to improve the code is as follows;  instead of (simplified)

    vQ> const char* dropTrailing(const char* s, ...) {
    vQ> const char *p = s;
    vQ> char *replace;
    vQ> ...
    vQ> replace = (char*) p;
    vQ> ...
    vQ> return s; }

    vQ> ...mkChar(dropTrailing(EncodeReal(...), ...) ...

    vQ> you can have something like

    vQ> const char* dropTrailing(char* s, ...) {
    vQ> char *p = s, *replace;
    vQ> ...
    vQ> replace = p;
    vQ> ...
    vQ> return s; }

    vQ> ...mkChar(dropTrailing((char*)EncodeReal(...), ...) ...
  
    vQ> where it is clear, from DT's signature, that it may (as it purposefully
    vQ> does, in fact) modify the content of s.  that is, you drop the
    vQ> promise-not-to-modify contract in DT, and move the need for
    vQ> deconstifying ER's return out of DT, making it more explicit.

    vQ> however, this is still an ad hoc hack;  it still breaks the original
    vQ> developer's assumption (if i'm correct) that the return from ER
    vQ> (pointing to its internal buffer) should not be destructively modified
    vQ> outside of ER.

I think that's a misinterpretation of the history of ER. 
IIRC, the main issue when changing from 'char*' to 'const char*'
in *many* places "simultaneously"
was the introduction of hashes / cashes of strings (in
mkChar(.)) in order to make R-level character handling (and
storage of STRSXP/CHARSXP) much more efficient.

    vQ> another issue is that even making the return from ER const does not
    vQ> protect against data corruption.  for example,

    vQ> const char *p1 = ER(...)
    vQ> // p1 is some string returned from ER
    vQ> const char *p2 = ER(...)
    vQ> // p2 is some other string returned from ER
    vQ> // but p1 == p2

    vQ> if p1 is used after the second call to ER, it's likely to lead to data
    vQ> corruption problems.  frankly, i'd consider the design of ER essentially
    vQ> flawed.  removing const from ER's return is obviously not an option;  it
    vQ> would certainly be safer to have it return a pointer to a heap-allocated
    vQ> buffer, but then the returned buffer would have to be freed at some
    vQ> point in the client code, and this would require a whole cascade of
    vQ> modifications to the r source code.  since it usually is more funny to
    vQ> introduce new bugs than repair old ones, i'd not expect r core to be
    vQ> ever willing to invest time in this.

    vQ> the following seem acceptable and relatively reasonable ways to address
    vQ> the issue:

    vQ> (1) noop:  leave as is.

    vQ> (2) minimal:  adopt the (inessential) changes suggested in my previous post:

    vQ> const char* dropTrailing(const char* s, ...) {
    vQ> char *p = (char*) s;
    vQ> // no further need for (char*) casting from p to replace
    vQ> ... }

    vQ> (3) modify petr's solution along the lines above, i.e., have the input
    vQ> in the signature non-const and deconst-cast the output from ER outside
    vQ> of the call to DT.

that's what I have adopted, as I'm sure you've noticed when you
saw the code above.

So, let's get to something more interesting,
"Happy Pentecoste!"
Martin


    vQ> (4) modify petr's solution to operate on a local, non-const copy of s:

    vQ> const char* dropTrailing(const char* s, ...) {
    vQ> int length = strlen(s);
    vQ> char *ss = malloc((length+1)*sizeof(char));
    vQ> memcpy(ss, s, length+1);
    vQ> // work on ss rather than on s
    vQ> ...
    vQ> return ss; }

    vQ> and don't forget to deallocate the return from DT after mkChar (or
    vQ> whoever calls DT) has no more need for it.  (an alternative is to use
    vQ> the allocCharsxp approach of mkCharLenCE, but that would be overdoing
    vQ> the job.)


    vQ> to sum up:  for a clean solution, i find (4) preferable.  for
    vQ> efficiency, (3) seems better, provided that you add a clear comment to
    vQ> the effect that the assumption of non-modifiable output from ER is
    vQ> purposefully violated.  (2) is acceptable provided that DT is
    vQ> appropriately documented (i.e., that it does not really treat s as const
    vQ> char*, but effectively as non-const char*), and with a note as above.

    vQ> a final, bitter remark:  i'm surprised that it's so easy to have an r
    vQ> core developer submit to r-devel a patch that violates an explicit
    vQ> demand on the immutability of a shared, statically allocated piece of
    vQ> memory. (even if it's the already existing code that actually is
    vQ> problematic.)

    vQ> no patch attached, you need to consider your options.  hope this helps
    vQ> anyway.

    vQ> best,
    vQ> vQ


From cernmach01 at gmail.com  Sat May 30 13:56:38 2009
From: cernmach01 at gmail.com (minime234)
Date: Sat, 30 May 2009 04:56:38 -0700 (PDT)
Subject: [Rd] Rtools28 - undefined references with gfortran
In-Reply-To: <OF6B6AE998.718395DA-ON8525750D.005F0106-8525750D.005F011D@american.edu>
References: <OF6B6AE998.718395DA-ON8525750D.005F0106-8525750D.005F011D@american.edu>
Message-ID: <23792687.post@talk.nabble.com>


use the option -lgfortran



John Nolan-3 wrote:
> 
> 
> I recently upgraded to Rtools28 to build a package under
> Windows.  I see that g77 is no longer in Rtools, but it
> does have gfortran, and it uses version:
>    GNU Fortran (GCC) 4.2.1-sjlj (mingw32-2)
> 
> I am compiling some old fortran code as part of a larger
> project.  When I do that, I get undefined references:
> 
> gcc.exe: s_cmp.o: No such file or directory
> gcc.exe: s_copy.o: No such file or directory
> gcc.exe: s_cat.o: No such file or directory
> gcc.exe: F77_aloc.o: No such file or directory
> 
> I don't see these entry points in any of the accompanying
> library files.   I hunted around and found the above
> functions in an old MinGW library libg2c.lib
> When I link them in, I get different undefined references:
> 
> ilaenv.o:ilaenv.f:(.text+0x55): undefined reference to
> `_gfortran_compare_string
> dlamch.o:dlamch.f:(.text+0x3bf): undefined reference to
> `_gfortran_pow_r8_i4'
> dormlq.o:dormlq.f:(.text+0x281): undefined reference to
> `_gfortran_concat_string
> 
> 
> Any guidance on how to solve this problem?
> 
> John Nolan
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 

-- 
View this message in context: http://www.nabble.com/Rtools28---undefined-references-with-gfortran-tp20705479p23792687.html
Sent from the R devel mailing list archive at Nabble.com.


From timb at metrumrg.com  Sat May 30 16:58:23 2009
From: timb at metrumrg.com (Tim Bergsma)
Date: Sat, 30 May 2009 10:58:23 -0400
Subject: [Rd] degraded performance with rank()
Message-ID: <ccac61760905300758y456d11c7i56f481ebb0e99063@mail.gmail.com>

Hi.

I'm maintaining a package that creates an object that is essentially a
classed version of numeric.  I updated recently from 2.7.1 to 2.9.0,
and merges involving my class suddenly took a huge performance hit.
I've traced the problem to something near rank().  From NEWS, it seems
rank() etc. changed in 2.8.0.  Methods for xtfrm() are supposed to
help, but I've had no success.  There was some chatter about this in
the archives back in Sept 08 (though apparently regarding S4), with a
suggestion that it is related to `[.` methods.  That has been my
experience.  In the toy example below, the problem disappears if
`[.my` is not defined.  Under R 2.7.1 on Mac, both cat() statements
take the same amount of time, and that time depends very little on the
length of x.  Under 2.9.0, the classed version takes much longer, and
the time grows (more than?) exponentially with length(x).

Is there something I can do to xtfrm.my() or [.my(), etc. to restore
the performance?

Thanks in advance,

Tim.

rm(list=ls())
as.my <- function(x,...)UseMethod('as.my')
as.my.default <- function(x,...)structure(x, class=c('my',class(x)))
`[.my` <- function (x, ...) structure(NextMethod("["), class = class(x))
xtfrm.my <- function(x)as.numeric(x)
x <- 1:10000
cat(system.time(rank(x))[3]);cat(' ')
cat(system.time(rank(as.my(x)))[3]);cat('\n')


From ggrothendieck at gmail.com  Sat May 30 20:31:18 2009
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 30 May 2009 14:31:18 -0400
Subject: [Rd] degraded performance with rank()
In-Reply-To: <ccac61760905300758y456d11c7i56f481ebb0e99063@mail.gmail.com>
References: <ccac61760905300758y456d11c7i56f481ebb0e99063@mail.gmail.com>
Message-ID: <971536df0905301131g4a15fd6eq65de8889304c3074@mail.gmail.com>

On Sat, May 30, 2009 at 10:58 AM, Tim Bergsma <timb at metrumrg.com> wrote:
> Hi.
>
> I'm maintaining a package that creates an object that is essentially a
> classed version of numeric. ?I updated recently from 2.7.1 to 2.9.0,
> and merges involving my class suddenly took a huge performance hit.
> I've traced the problem to something near rank(). ?From NEWS, it seems
> rank() etc. changed in 2.8.0. ?Methods for xtfrm() are supposed to
> help, but I've had no success. ?There was some chatter about this in
> the archives back in Sept 08 (though apparently regarding S4), with a
> suggestion that it is related to `[.` methods. ?That has been my
> experience. ?In the toy example below, the problem disappears if
> `[.my` is not defined. ?Under R 2.7.1 on Mac, both cat() statements
> take the same amount of time, and that time depends very little on the
> length of x. ?Under 2.9.0, the classed version takes much longer, and
> the time grows (more than?) exponentially with length(x).
>
> Is there something I can do to xtfrm.my() or [.my(), etc. to restore
> the performance?
>
> Thanks in advance,
>
> Tim.
>
> rm(...deleted rest of line...

OUCH!!!

Please don't post code like that.  Someone may wipe out valuable
objects in their workspace.


From gkerns at ysu.edu  Sat May 30 21:03:17 2009
From: gkerns at ysu.edu (G. Jay Kerns)
Date: Sat, 30 May 2009 15:03:17 -0400
Subject: [Rd] setdiff bizarre (was: odd behavior out of setdiff)
In-Reply-To: <8b356f880905300859i5ba5800q5594bfce659373fe@mail.gmail.com>
References: <a695148b0905292135g1c1bee38xb70687a43ccaa934@mail.gmail.com> 
	<8b356f880905300550y39c76b02h2d908b1c6b0ef0e4@mail.gmail.com> 
	<a695148b0905300721x6e291e0bg66fefcf0931f2ce2@mail.gmail.com> 
	<8b356f880905300859i5ba5800q5594bfce659373fe@mail.gmail.com>
Message-ID: <a695148b0905301203n7cb1199fgab149602a5959f7a@mail.gmail.com>

Dear Stavros,

On Sat, May 30, 2009 at 11:59 AM, Stavros Macrakis
<macrakis at alum.mit.edu> wrote:
> The current implementation is column-wise...

Thanks for pointing that out, and solving the mystery for me.  :-)

Jay


From murdoch at stats.uwo.ca  Sat May 30 23:11:59 2009
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sat, 30 May 2009 17:11:59 -0400
Subject: [Rd] degraded performance with rank()
In-Reply-To: <ccac61760905300758y456d11c7i56f481ebb0e99063@mail.gmail.com>
References: <ccac61760905300758y456d11c7i56f481ebb0e99063@mail.gmail.com>
Message-ID: <4A21A11F.8050706@stats.uwo.ca>

Tim Bergsma wrote:
> Hi.
>
> I'm maintaining a package that creates an object that is essentially a
> classed version of numeric.  I updated recently from 2.7.1 to 2.9.0,
> and merges involving my class suddenly took a huge performance hit.
> I've traced the problem to something near rank().  From NEWS, it seems
> rank() etc. changed in 2.8.0.  Methods for xtfrm() are supposed to
> help, but I've had no success.  There was some chatter about this in
> the archives back in Sept 08 (though apparently regarding S4), with a
> suggestion that it is related to `[.` methods.  That has been my
> experience.  In the toy example below, the problem disappears if
> `[.my` is not defined.  Under R 2.7.1 on Mac, both cat() statements
> take the same amount of time, and that time depends very little on the
> length of x.  Under 2.9.0, the classed version takes much longer, and
> the time grows (more than?) exponentially with length(x).
>
> Is there something I can do to xtfrm.my() or [.my(), etc. to restore
> the performance?
>   

If the object  x you pass to xtfrm evaluates is.object(x) as false, 
you'll get fast behaviour, because it will use internal methods.  If you 
have a class on it, you'll get dispatch to your method for every 
comparison, which will be slow.

So if speed matters, I would not define an xtfrm.my, I would unclass 
things before sorting.

Prior to a day or so ago, the dispatch for comparison methods was 
broken, and you would get a mix of internal and external comparisons.  I 
suspect fixing that bug has made it even slower if you choose to try to 
sort a classed object.

Duncan Murdoch
> Thanks in advance,
>
> Tim.
>
> rm(list=ls())
> as.my <- function(x,...)UseMethod('as.my')
> as.my.default <- function(x,...)structure(x, class=c('my',class(x)))
> `[.my` <- function (x, ...) structure(NextMethod("["), class = class(x))
> xtfrm.my <- function(x)as.numeric(x)
> x <- 1:10000
> cat(system.time(rank(x))[3]);cat(' ')
> cat(system.time(rank(as.my(x)))[3]);cat('\n')
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Sun May 31 00:22:58 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Sun, 31 May 2009 00:22:58 +0200
Subject: [Rd] as.numeric(levels(factor(x))) may be a decreasing sequence
In-Reply-To: <18977.28100.532043.734122@cmath-4.math.ethz.ch>
References: <20090523074454.GA17112@cs.cas.cz>	<18973.42970.826686.173830@cmath-5.math.ethz.ch>	<4A1DC057.80401@idi.ntnu.no>	<18975.59582.885300.549159@lynne.math.ethz.ch>	<4A203D67.8000007@idi.ntnu.no>	<3f1d2410905291448y271fa484te82b8dbaa547017f@mail.gmail.com>	<4A20F97B.1090406@idi.ntnu.no>
	<18977.28100.532043.734122@cmath-4.math.ethz.ch>
Message-ID: <4A21B1C2.5020904@idi.ntnu.no>

Martin Maechler wrote:

[...]

>     vQ> the first question is, why does ER return the string as const?  it
>     vQ> appears that the returned pointer provides the address of a buffer used
>     vQ> internally in ER, which is allocated *statically*.  that is, each call
>     vQ> to ER operates on the same memory location, and each call to ER returns
>     vQ> the address of that same location.  i suspect this is intended to be a
>     vQ> smart optimization, to avoid heap- or stack-allocating a new buffer in
>     vQ> each call to ER, and deallocating it after use.  however, this appraoch
>     vQ> is problematic, in that any two calls to ER return the address of the
>     vQ> same piece of memory, and this may easily lead to data corruption. 
>
> Well, that would be ok if R could be used "threaded" / parallel / ...
>   

this can cause severe problems even without concurrency, as one of my
examples hinted.


> and we all know that there are many other pieces of code {not
> just R's "own", but also in Fortran/C algorithms ..} that are
> not thread-safe.
>   

absolutely.  again, ER is unsafe even in a sequential execution environment.

> "Yes, of course", R looks like a horrible piece of software 

telepathy?


> to
> some,  because of that
>
>     vQ> under the assumption that the content of this piece of memory is copied
>     vQ> before any destructive use, and that after the string is copied the
>     vQ> address is not further distributed, the hack is relatively harmless. 
>     vQ> this is what mkChar (via mkCharLenCE) does;  in SFR it copies the
>     vQ> content of s with memcpy, and wraps it into a SEXP that becomes the
>     vQ> return value from SFR.
>
> exactly.
>   

but it should be made clear, by means of a comment, that ER is supposed
to be used in this way.  there is no hint at the interface level.


>     vQ> the original author of this hack seems to have had some concern about
>     vQ> exporting (from ER) the address of a static buffer, hence the returned
>     vQ> buffer is const.  in principle, this should prevent corruption of the
>     vQ> buffer's content in situations such as
>
>     vQ> // hypothetical
>     vQ> char *p1 = ER(...);
>     vQ> // p1 is some string returned from ER
>     vQ> char p2 = ER(...);
>     vQ> // p2 is some other string returned from ER
>
>     vQ> // some modifications performed on the string referred to by p1
>     vQ> p1[0] = 'x';
>     vQ> // p2[0] is 'x' -- possible data corruption
>
>     vQ> still worse in a scenario with concurrent calls to ER.
>   
> (which will not happen in the near future)
>   

unless you know a powerful and willing magician.


>     vQ> however, since the output from ER is const, this is no longer possible
>     vQ> -- at least, not without a deconstifying cast the petr style.  the
>     vQ> problem with petr's solution is not only that it modifies shared memory
>     vQ> purposefully qualified as const (by virtue of ER's return type), but
>     vQ> also that it effectively distributes the address for further use. 
>
>     vQ> unfortunately, like most of the r source code, ER is not appropriately
>     vQ> commented at the declaration and the definition, and without looking at
>     vQ> the code, one can hardly have any clue that ER always return the same
>     vQ> address of a static location.  while the original developer might be
>     vQ> careful enough not to misuse ER, in a large multideveloper project it's
>     vQ> hard expect that from others.  petr's function is precisely an example
>     vQ> of such misuse, and as it adds (again, without an appropriate comment) a
>     vQ> step of indirection; any use of petr's function other than what you have
>     vQ> in SFR (and can you guarantee no one will ever use DT for other
>     vQ> purposes?) is even more likely to end up in data corruption.
>
> you have a point here, and as a consequence, I'm proposing to
> put the following version of DT  into the source :
> ------------------------------------------------------------------------
>
> /* Note that we modify a  'const char*'  which is unsafe in general,
>  * but ok in the context of filtering an Encode*() value into mkChar(): */
> static const char* dropTrailing0(char *s, char cdec)
> {
>     char *p = s;
>     for (p = s; *p; p++) {
> 	if(*p == cdec) {
> 	    char *replace = p++;
> 	    while ('0' <= *p  &&  *p <= '9')
> 		if(*(p++) != '0')
> 		    replace = p;
> 	    while((*(replace++) = *(p++)))
> 		;
> 	    break;
> 	}
>     }
>     return s;
> }
>
>   

the first line appears inessential;  to an informed programmer, taking a
string as char* (as opposed to const char*) means that it *may* be
modified within the call, irrespectively of whether it actually is, and
on what occasions, and one should not assume the string is not
destructively modified.

i think it is much more appropriate to comment (a) ER, with a warning to
the effect that it always returns the same address, hence the output
should be used immediately and never written to, (b) the use of ER in
SFR where it's output is cast to char* precisely for the purpose of
destructive modification, to the contrary of what (a) says.

i've attached a patch with an alternative comment.


> ------------------------------------------------------------------------
>
> so it has a comment along the lines you suggest, 

almost


> *and* as static
> is not callable from outside coerce.c
>   

indeed.  unfortunately, ER is callable from throughout the place.


>
>     vQ> one simple way to improve the code is as follows;  instead of (simplified)
>
>     vQ> const char* dropTrailing(const char* s, ...) {
>     vQ> const char *p = s;
>     vQ> char *replace;
>     vQ> ...
>     vQ> replace = (char*) p;
>     vQ> ...
>     vQ> return s; }
>
>     vQ> ...mkChar(dropTrailing(EncodeReal(...), ...) ...
>
>     vQ> you can have something like
>
>     vQ> const char* dropTrailing(char* s, ...) {
>     vQ> char *p = s, *replace;
>     vQ> ...
>     vQ> replace = p;
>     vQ> ...
>     vQ> return s; }
>
>     vQ> ...mkChar(dropTrailing((char*)EncodeReal(...), ...) ...
>   
>     vQ> where it is clear, from DT's signature, that it may (as it purposefully
>     vQ> does, in fact) modify the content of s.  that is, you drop the
>     vQ> promise-not-to-modify contract in DT, and move the need for
>     vQ> deconstifying ER's return out of DT, making it more explicit.
>
>     vQ> however, this is still an ad hoc hack;  it still breaks the original
>     vQ> developer's assumption (if i'm correct) that the return from ER
>     vQ> (pointing to its internal buffer) should not be destructively modified
>     vQ> outside of ER.
>
> I think that's a misinterpretation of the history of ER. 
>   

"if i'm correct"


> IIRC, the main issue when changing from 'char*' to 'const char*'
> in *many* places "simultaneously"
> was the introduction of hashes / cashes of strings (in
> mkChar(.)) in order to make R-level character handling (and
> storage of STRSXP/CHARSXP) much more efficient.
>   

what does it have to do with ER returning a pointer to a static location?

>     vQ> (3) modify petr's solution along the lines above, i.e., have the input
>     vQ> in the signature non-const and deconst-cast the output from ER outside
>     vQ> of the call to DT.
>
> that's what I have adopted, as I'm sure you've noticed when you
> saw the code above.
>   

surprisingly, sometimes i'm able to notice ;)

best,
vQ
-------------- next part --------------
A non-text attachment was scrubbed...
Name: coerce.diff
Type: text/x-diff
Size: 1106 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090531/f692e569/attachment.bin>

From seanpor at acm.org  Sun May 31 08:02:56 2009
From: seanpor at acm.org (Sean O'Riordain)
Date: Sun, 31 May 2009 07:02:56 +0100
Subject: [Rd] spelling buglet - files.Rd
Message-ID: <8ed68eed0905302302x54ccb30sc668906d7601588c@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090531/86b0ea15/attachment.pl>

From savicky at cs.cas.cz  Sun May 31 10:29:41 2009
From: savicky at cs.cas.cz (Petr Savicky)
Date: Sun, 31 May 2009 10:29:41 +0200
Subject: [Rd] as.numeric(levels(factor(x))) may be a decreasing sequence
In-Reply-To: <18977.28100.532043.734122@cmath-4.math.ethz.ch>
References: <20090523074454.GA17112@cs.cas.cz>
	<18973.42970.826686.173830@cmath-5.math.ethz.ch>
	<4A1DC057.80401@idi.ntnu.no>
	<18975.59582.885300.549159@lynne.math.ethz.ch>
	<4A203D67.8000007@idi.ntnu.no>
	<3f1d2410905291448y271fa484te82b8dbaa547017f@mail.gmail.com>
	<4A20F97B.1090406@idi.ntnu.no>
	<18977.28100.532043.734122@cmath-4.math.ethz.ch>
Message-ID: <20090531082941.GA12517@cs.cas.cz>

On Sat, May 30, 2009 at 07:32:52PM +0200, Martin Maechler wrote:
> >>>>> "vQ" == Wacek Kusnierczyk <Waclaw.Marcin.Kusnierczyk at idi.ntnu.no>
> >>>>>     on Sat, 30 May 2009 11:16:43 +0200 writes:

[...]

>     vQ> one simple way to improve the code is as follows;  instead of (simplified)
> 
>     vQ> const char* dropTrailing(const char* s, ...) {
>     vQ> const char *p = s;
>     vQ> char *replace;
>     vQ> ...
>     vQ> replace = (char*) p;
>     vQ> ...
>     vQ> return s; }
> 
>     vQ> ...mkChar(dropTrailing(EncodeReal(...), ...) ...
> 
>     vQ> you can have something like
> 
>     vQ> const char* dropTrailing(char* s, ...) {
>     vQ> char *p = s, *replace;
>     vQ> ...
>     vQ> replace = p;
>     vQ> ...
>     vQ> return s; }
> 
>     vQ> ...mkChar(dropTrailing((char*)EncodeReal(...), ...) ...
>   
>     vQ> where it is clear, from DT's signature, that it may (as it purposefully
>     vQ> does, in fact) modify the content of s.  that is, you drop the
>     vQ> promise-not-to-modify contract in DT, and move the need for
>     vQ> deconstifying ER's return out of DT, making it more explicit.

[...]

>     vQ> (3) modify petr's solution along the lines above, i.e., have the input
>     vQ> in the signature non-const and deconst-cast the output from ER outside
>     vQ> of the call to DT.
> 
> that's what I have adopted, as I'm sure you've noticed when you
> saw the code above.

I appreciate the current version, which contains
  static const char* dropTrailing0(char *s, char cdec)
  ...
  mkChar(dropTrailing0((char *)EncodeReal(x, w, d, e, OutDec), ...

Here, is better visible that the cast (char *) is used than if it was hidden
inside dropTrailing0(). Also, it makes dropTrailing0() more consistent.

I would like to recall the already discussed modification
            if (replace != p)
                while((*(replace++) = *(p++)))
                    ;
which saves a few instructions in the more frequent case that there are no
trailing zeros.

Petr.


From murdoch at stats.uwo.ca  Sun May 31 12:13:39 2009
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sun, 31 May 2009 06:13:39 -0400
Subject: [Rd] spelling buglet - files.Rd
In-Reply-To: <8ed68eed0905302302x54ccb30sc668906d7601588c@mail.gmail.com>
References: <8ed68eed0905302302x54ccb30sc668906d7601588c@mail.gmail.com>
Message-ID: <4A225853.1060904@stats.uwo.ca>

Sean O'Riordain wrote:
> Good morning,
>
> A minor spelling buglet in files.Rd
>
>
> Index: trunk/src/library/base/man/files.Rd
> ===================================================================
> --- trunk/src/library/base/man/files.Rd (revision 48691)
> +++ trunk/src/library/base/man/files.Rd (working copy)
> @@ -100,7 +100,7 @@
>  }
>  #ifdef windows
>  \note{
> -  There is no guarantee that these fcuntions will handle Windows
> +  There is no guarantee that these functions will handle Windows
>    relative paths of the form \file{d:path}: try \file{d:./path}
>    instead.  In particular, \file{d:} is not recognized as a directory.
>  }
>
>   

Thanks, now fixed.

Duncan Murdoch


From astokes at esica.com  Sun May 31 06:45:09 2009
From: astokes at esica.com (astokes at esica.com)
Date: Sun, 31 May 2009 06:45:09 +0200 (CEST)
Subject: [Rd] install.packages hangs RGui with frozen rpwd process at bottom
	of process tree (PR#13734)
Message-ID: <20090531044509.BA68C2830319@mail.pubhealth.ku.dk>

Full_Name: Allan Stokes
Version: 2.8.1
OS: XP
Submission from: (NULL) (24.108.0.245)


I've just spent a hellish six hours trying to create my own R package with a
bare bones "hello world" R function inside.  I was able to create a
package.tar.gz file eventually with much perseverance.  

My remaining problem is that when I try to install my simple package under RGui,
it hangs.  

install.packages("c:/testR/scupper_1.0.tar.gz", repos=NULL, type="source",
lib="c:/allanR")

The hung process tree as shown by SysInternals Process Explorer.  

1. Rgui.exe
cmd="C:\Program Files\R\R-2.8.1\bin\Rgui.exe" 
cd=Z:\ 
2. R.exe
cmd=C:\PROGRA~1\R\R-28~1.1\bin\R.exe CMD INSTALL -l "c:/allanR" 
"c:/allanR/scupper_1.0.tar.gz"
cd=Z:\
3. cmd.exe
cmd=C:\WINDOWS\system32\cmd.exe /c perl C:\PROGRA~1\R\R-28~1.1/bin/INSTALL -l
c:/allanR c:/allanR/scupper_1.0.tar.gz
cd=Z:\
4. perl.exe
cmd=perl C:\PROGRA~1\R\R-28~1.1/bin/INSTALL -l c:/allanR
c:/allanR/scupper_1.0.tar.gz
Z:\
5. make.exe
cmd=make --no-print-directory -C C:/PROGRA~1/R/R-28~1.1/src/gnuwin32
PKGDIR=Z:/R.INSTALL.5532 PKGNAME=scupper RLIB=c:/allanR DPKG=c:/allanR/scupper
scupper-LAZY=true HELP=YES WINHELP=CHM pkg-scupper
dir=C:\Program Files\R\R-2.8.1\src\gnuwin32\
6. make.exe
cmd=c:\Rtools\bin\make.exe
dir=C:\WINDOWS\system32\
7. Rpwd.exe 
cmd=c:\PROGRA~1\R\R-28~1.1\src\gnuwin32\Rpwd.exe ../..
dir=C:\Program Files\R\R-2.8.1\src\gnuwin32\

First, one stupid thing is that one time I ran the make cmd under the CMD prompt
and it successfully generated a CHM file, as shown by this fragment of the
output I captured: 

 >>> Building/Updating help pages for package 'scupper'
     Formats: text html latex example chm
Microsoft HTML Help Compiler 4.74.8702

Compiling z:\R.INSTALL.6416\scupper\chm\scupper.chm

Compile time: 0 minutes, 0 seconds
1       Topic
0       Local links
0       Internet links
1       Graphic

Created z:\R.INSTALL.6416\scupper\chm\scupper.chm, 14,448 bytes
Compression increased file by 9,624 bytes.

That didn't work when I tried it again, but the R temp directories sometimes
vanish in the meantime.  

Using System Internals File Monitor, I can see the last access to the file
system by rpwd.exe 

9:25:26 PM	Rpwd.exe:6328	QUERY INFORMATION
C:\PROGRA~1\R\R-28~1.1\src\gnuwin32\Rpwd.exe	SUCCESS	FileNameInformation	
9:25:26 PM	Rpwd.exe:6328	OPEN	C:\WINDOWS\Prefetch\RPWD.EXE-1615C3C8.pf	SUCCESS
Options: Open  Access: Read	
9:25:26 PM	Rpwd.exe:6328	QUERY INFORMATION
C:\WINDOWS\Prefetch\RPWD.EXE-1615C3C8.pf	SUCCESS	Length: 3882	
9:25:26 PM	Rpwd.exe:6328	READ 	C:\WINDOWS\Prefetch\RPWD.EXE-1615C3C8.pf	SUCCESS
Offset: 0 Length: 3882	
9:25:26 PM	Rpwd.exe:6328	OPEN	C:	SUCCESS	Options: Open  Access: 00100180	
9:25:26 PM	Rpwd.exe:6328	QUERY INFORMATION	C:	SUCCESS	FileFsVolumeInformation	
9:25:26 PM	Rpwd.exe:6328	OPEN	C:\	SUCCESS	Options: Open Directory  Access:
00100001	
9:25:26 PM	Rpwd.exe:6328	DIRECTORY	C:\	SUCCESS	FileNamesInformation	
9:25:26 PM	Rpwd.exe:6328	DIRECTORY	C:\	NO MORE FILES	FileNamesInformation	
9:25:26 PM	Rpwd.exe:6328	OPEN	C:\PROGRA~1\	SUCCESS	Options: Open Directory 
Access: 00100001	
9:25:26 PM	Rpwd.exe:6328	DIRECTORY	C:\PROGRA~1\	SUCCESS	FileNamesInformation	
9:25:26 PM	Rpwd.exe:6328	DIRECTORY	C:\PROGRA~1\	NO MORE FILES
FileNamesInformation	
9:25:26 PM	Rpwd.exe:6328	OPEN	C:\PROGRA~1\R\	SUCCESS	Options: Open Directory 
Access: 00100001	
9:25:26 PM	Rpwd.exe:6328	DIRECTORY	C:\PROGRA~1\R\	SUCCESS	FileNamesInformation	
9:25:26 PM	Rpwd.exe:6328	DIRECTORY	C:\PROGRA~1\R\	NO MORE FILES
FileNamesInformation	
9:25:26 PM	Rpwd.exe:6328	OPEN	C:\PROGRA~1\R\R-28~1.1\	SUCCESS	Options: Open
Directory  Access: 00100001	
9:25:26 PM	Rpwd.exe:6328	DIRECTORY	C:\PROGRA~1\R\R-28~1.1\	SUCCESS
FileNamesInformation	
9:25:26 PM	Rpwd.exe:6328	DIRECTORY	C:\PROGRA~1\R\R-28~1.1\	NO MORE FILES
FileNamesInformation	
9:25:26 PM	Rpwd.exe:6328	OPEN	C:\PROGRA~1\R\R-28~1.1\SRC\	SUCCESS	Options: Open
Directory  Access: 00100001	
9:25:26 PM	Rpwd.exe:6328	DIRECTORY	C:\PROGRA~1\R\R-28~1.1\SRC\	SUCCESS
FileNamesInformation	
9:25:26 PM	Rpwd.exe:6328	DIRECTORY	C:\PROGRA~1\R\R-28~1.1\SRC\	NO MORE FILES
FileNamesInformation	
9:25:26 PM	Rpwd.exe:6328	OPEN	C:\PROGRA~1\R\R-28~1.1\SRC\GNUWIN32\	SUCCESS
Options: Open Directory  Access: 00100001	
9:25:26 PM	Rpwd.exe:6328	DIRECTORY	C:\PROGRA~1\R\R-28~1.1\SRC\GNUWIN32\	SUCCESS
FileNamesInformation	
9:25:26 PM	Rpwd.exe:6328	DIRECTORY	C:\PROGRA~1\R\R-28~1.1\SRC\GNUWIN32\	NO MORE
FILES	FileNamesInformation	
9:25:26 PM	Rpwd.exe:6328	OPEN	C:\WINDOWS\	SUCCESS	Options: Open Directory 
Access: 00100001	
9:25:26 PM	Rpwd.exe:6328	DIRECTORY	C:\WINDOWS\	SUCCESS	FileNamesInformation	
9:25:26 PM	Rpwd.exe:6328	DIRECTORY	C:\WINDOWS\	SUCCESS	FileNamesInformation	
9:25:26 PM	Rpwd.exe:6328	DIRECTORY	C:\WINDOWS\	NO MORE FILES
FileNamesInformation	
9:25:26 PM	Rpwd.exe:6328	OPEN	C:\WINDOWS\SYSTEM32\	SUCCESS	Options: Open
Directory  Access: 00100001	
9:25:26 PM	Rpwd.exe:6328	DIRECTORY	C:\WINDOWS\SYSTEM32\	SUCCESS
FileNamesInformation	
9:25:26 PM	Rpwd.exe:6328	DIRECTORY	C:\WINDOWS\SYSTEM32\	SUCCESS
FileNamesInformation	
9:25:26 PM	Rpwd.exe:6328	DIRECTORY	C:\WINDOWS\SYSTEM32\	SUCCESS
FileNamesInformation	
9:25:26 PM	Rpwd.exe:6328	DIRECTORY	C:\WINDOWS\SYSTEM32\	SUCCESS
FileNamesInformation	
9:25:26 PM	Rpwd.exe:6328	DIRECTORY	C:\WINDOWS\SYSTEM32\	SUCCESS
FileNamesInformation	
9:25:26 PM	Rpwd.exe:6328	DIRECTORY	C:\WINDOWS\SYSTEM32\	SUCCESS
FileNamesInformation	
9:25:26 PM	Rpwd.exe:6328	DIRECTORY	C:\WINDOWS\SYSTEM32\	NO MORE FILES
FileNamesInformation	
9:25:26 PM	Rpwd.exe:6328	OPEN	C:\WINDOWS\SYSTEM32\NTDLL.DLL	SUCCESS	Options:
Open  Access: 00000081	
9:25:26 PM	Rpwd.exe:6328	QUERY INFORMATION	C:\WINDOWS\SYSTEM32\NTDLL.DLL	SUCCESS
Length: 714752	
9:25:26 PM	Rpwd.exe:6328	OPEN	C:\WINDOWS\SYSTEM32\KERNEL32.DLL	SUCCESS	Options:
Open  Access: 00000081	
9:25:26 PM	Rpwd.exe:6328	QUERY INFORMATION	C:\WINDOWS\SYSTEM32\KERNEL32.DLL
SUCCESS	Length: 989696	
9:25:26 PM	Rpwd.exe:6328	OPEN	C:\WINDOWS\SYSTEM32\UNICODE.NLS	SUCCESS	Options:
Open  Access: 00000081	
9:25:26 PM	Rpwd.exe:6328	QUERY INFORMATION	C:\WINDOWS\SYSTEM32\UNICODE.NLS
SUCCESS	Length: 89588	
9:25:26 PM	Rpwd.exe:6328	OPEN	C:\WINDOWS\SYSTEM32\LOCALE.NLS	SUCCESS	Options:
Open  Access: 00000081	
9:25:26 PM	Rpwd.exe:6328	QUERY INFORMATION	C:\WINDOWS\SYSTEM32\LOCALE.NLS
SUCCESS	Length: 265948	
9:25:26 PM	Rpwd.exe:6328	OPEN	C:\WINDOWS\SYSTEM32\SORTTBLS.NLS	SUCCESS	Options:
Open  Access: 00000081	
9:25:26 PM	Rpwd.exe:6328	QUERY INFORMATION	C:\WINDOWS\SYSTEM32\SORTTBLS.NLS
SUCCESS	Length: 23044	
9:25:26 PM	Rpwd.exe:6328	OPEN	C:\PROGRA~1\R\R-28~1.1\SRC\GNUWIN32\RPWD.EXE
SUCCESS	Options: Open  Access: 00000081	
9:25:26 PM	Rpwd.exe:6328	QUERY INFORMATION
C:\PROGRA~1\R\R-28~1.1\SRC\GNUWIN32\RPWD.EXE	SUCCESS	Length: 9216	
9:25:26 PM	Rpwd.exe:6328	OPEN	C:\WINDOWS\SYSTEM32\MSVCRT.DLL	SUCCESS	Options:
Open  Access: 00000081	
9:25:26 PM	Rpwd.exe:6328	QUERY INFORMATION	C:\WINDOWS\SYSTEM32\MSVCRT.DLL
SUCCESS	Length: 343040	
9:25:26 PM	Rpwd.exe:6328	OPEN	C:\WINDOWS\SYSTEM32\NTDLL.DLL	SUCCESS	Options:
Open  Access: Execute	
9:25:26 PM	Rpwd.exe:6328	OPEN	C:\WINDOWS\SYSTEM32\KERNEL32.DLL	SUCCESS	Options:
Open  Access: Execute	
9:25:26 PM	Rpwd.exe:6328	OPEN	C:\PROGRA~1\R\R-28~1.1\SRC\GNUWIN32\RPWD.EXE
SUCCESS	Options: Open  Access: Execute	
9:25:26 PM	Rpwd.exe:6328	OPEN	C:\WINDOWS\SYSTEM32\MSVCRT.DLL	SUCCESS	Options:
Open  Access: Execute	

I've tried this under Rtools 2.9 and then 2.8.  I also updated my Cygwin config
(which was pretty current).  

No dice.  

My little package contains an R function as such: 

`ahoy` <-
function () { cat ("Shiver me timbers!\n")}

And a DESCRIPTION file like this: 

Package: scupper
Type: Package
Title: Ship ahoy
Version: 1.0
Date: 2009-05-30
Author: Allan Stokes
Maintainer: <astokes at esica.com>
Description: Responds to ahoy() greeting.  
License: internal use only
LazyLoad: yes

There are empty data, man, and test directories.  

I would reboot my system and try again, but I'd have to shut down 30 programs on
nine desktops, and I haven't got that many lives.  I have been sure to restart
RGui with the correct PATH env. for each test run.


From jasonkrupert at yahoo.com  Sat May 30 21:30:30 2009
From: jasonkrupert at yahoo.com (Jason Rupert)
Date: Sat, 30 May 2009 12:30:30 -0700 (PDT)
Subject: [Rd] setdiff bizarre (was: odd behavior out of setdiff)
Message-ID: <157742.14855.qm@web56005.mail.re3.yahoo.com>


Jay, 


I really appreciate all your help help.  

I posted to Nabble an R file and input CSV files more accurately demonstrating what I am seeing and the output I desire to achieve when I difference two dataframes.  
http://n2.nabble.com/Support-SetDiff-Discussion-Items...-td2999739.html


It may be that "setdiff" as intended in the base R functionality and "prob" was never intended to provide the type of result I desire.  If that is the case then I will need to ask the "Ninjas" for help to produce the out come I seek.  

That is, when I different the data within RSetDiffEntry.csv and RSetDuplicatesRemoved.csv, I desire to get the result shown in  RDesired.csv. 

Note that, it would not be enough to just work to remove duplicate "CostPerSquareFoot" values, since that variable is tied to "EntryDate" and "HouseNumber".  

Any further help and insights are much appreciated. 

Thanks again, 
Jason 





--- On Fri, 5/29/09, G. Jay Kerns <gkerns at ysu.edu> wrote:

> From: G. Jay Kerns <gkerns at ysu.edu>
> Subject: setdiff bizarre (was: odd behavior out of setdiff)
> To: r-devel at r-project.org
> Cc: dwinsemius at comcast.net, jasonkrupert at yahoo.com
> Date: Friday, May 29, 2009, 11:35 PM
> Dear R-devel,
> 
> Please see the recent thread on R-help, "Odd Behavior Out
> of
> setdiff(...) - addition of duplicate entries is not
> identified" posted
> by Jason Rupert.? I gave an answer, then read David
> Winsemius' answer,
> and then did some follow-up investigation.
> 
> I would like to change my answer.
> 
> My current version of setdiff() is acting in a way that I
> do not
> understand, and a way that I suspect? has
> changed.? Consider the
> following, derived from Jason's OP:
> 
> The base package setdiff(), atomic vectors:
> 
> x <- 1:100
> y <- c(x,x)
> 
> setdiff(x, y)? # integer(0)
> setdiff(y, x)? # integer(0)
> 
> z <- 1:25
> 
> setdiff(x,z)???# 26:100
> setdiff(z,x)???# integer(0)
> 
> 
> Everything is fine.
> 
> Now look at base package setdiff(), data frames???
> 
> ################################
> A <- data.frame(x = 1:100)
> B <- rbind(A, A)
> 
> setdiff(A, B)? ? ? ? ? ?
> ???# df 1:100?
> setdiff(B, A)? ? ? ? ? ?
> ???# df 1:100?
> 
> C <- data.frame(x = 1:25)
> 
> setdiff(A, C)? ? ? ? ? ?
> ???# df 1:100?
> setdiff(C, A)? ? ? ? ? ?
> ???# df 1:25?
> 
> ############################
> 
> 
> I have read ?setdiff 37 times now, and I cannot divine any
> interpretation that matches the above output.? From
> the source, it
> appears that
> 
> match(x, y, 0L) == 0L
> 
> is evaluating to TRUE, of length equal to the columns of x,
> and then
> 
> x[match(x, y, 0L) == 0L]
> 
> is returning the entire data frame.
> 
> Compare with the output from package "prob", which uses a
> setdiff that
> operates row-wise:
> 
> 
> ###########################
> library(prob)
> A <- data.frame(x = 1:100)
> B <- rbind(A, A)
> 
> setdiff(A, B)? ? ? ? ? ?
> ???# integer(0)
> setdiff(B, A)? ? ? ? ? ?
> ???# integer(0)
> 
> C <- data.frame(x = 1:25)
> 
> setdiff(A, C)? ? ? ? ? ?
> ???# 26:100
> setdiff(C, A)? ? ? ? ? ?
> ???# integer(0)
> 
> 
> 
> IMHO, the entire notion of "set" and "element" is
> problematic in the
> df case, so I am not advocating the adoption of the
> prob:::setdiff
> approach;? rather, setdiff is behaving in a way that I
> cannot believe
> with my own eyes, and I would like to alert those who can
> speak as to
> why this may be happening.
> 
> Thanks to Jason for bringing this up, and to David for
> catching the discrepancy.
> 
> Session info is below.? I use the binaries prepared by
> the Debian
> group so I do not have the latest
> patched-revision-4440986745343b.
> This must have been related to something which has been
> fixed since
> April 17, and in that case, please disregard my message.
> 
> Yours truly,
> Jay
> 
> 
> 
> 
> 
> 
> > sessionInfo()
> R version 2.9.0 (2009-04-17)
> x86_64-pc-linux-gnu
> 
> locale:
> LC_CTYPE=en_US.UTF-8;LC_NUMERIC=C;LC_TIME=en_US.UTF-8;LC_COLLATE=en_US.UTF-8;LC_MONETARY=C;LC_MESSAGES=en_US.UTF-8;LC_PAPER=en_US.UTF-8;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=en_US.UTF-8;LC_IDENTIFICATION=C
> 
> attached base packages:
> [1] stats? ???graphics? grDevices
> utils? ???datasets?
> methods???base
> 
> other attached packages:
> [1] prob_0.9-1
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> -- 
> 
> ***************************************************
> G. Jay Kerns, Ph.D.
> Associate Professor
> Department of Mathematics & Statistics
> Youngstown State University
> Youngstown, OH 44555-0002 USA
> Office: 1035 Cushwa Hall
> Phone: (330) 941-3310 Office (voice mail)
> -3302 Department
> -3170 FAX
> E-mail: gkerns at ysu.edu
> http://www.cc.ysu.edu/~gjkerns/
> 





