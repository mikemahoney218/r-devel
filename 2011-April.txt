From dtenenba at fhcrc.org  Fri Apr  1 00:11:54 2011
From: dtenenba at fhcrc.org (Dan Tenenbaum)
Date: Thu, 31 Mar 2011 15:11:54 -0700
Subject: [Rd] Problem running "make bitmapdll" with R-2.13 beta r55221
	on Windows
In-Reply-To: <AANLkTikhCWOR7d0PLjUF2PkqsST9wjnaB8D+py0oF4aA@mail.gmail.com>
References: <AANLkTikhCWOR7d0PLjUF2PkqsST9wjnaB8D+py0oF4aA@mail.gmail.com>
Message-ID: <AANLkTikTr8Yb7B3yNVg9_ZX7t0huHAcfMPuMCqgnW0Ce@mail.gmail.com>

On Thu, Mar 31, 2011 at 2:01 PM, Dan Tenenbaum <dtenenba at fhcrc.org> wrote:
> Hello,
>
> I am building R r55221 according to
> http://cran.r-project.org/doc/manuals/R-admin.html#Building-from-source
>
> After I have done "make all && make recommended", "make bitmapdll"
> returns the following:

I am sorry to have to do this twice in one day. I will make a better
effort to do my homework before posting.

We notice the change in r55118, and that the libpng version has changed too.

You may disregard this posting.
Dan



>
> E:\sandbox\R-2.13.r55221\src\gnuwin32>make bitmapdll
> make[1]: Entering directory
> `/cygdrive/e/sandbox/R-2.13.r55221/src/gnuwin32/bitmap'
> make CC='gcc -std=gnu99' AR='ar' AR_RC='ar rcs' \
> ?CFLAGS="-O3 -I../../../extra/zlib -DPNG_NO_MMX_CODE" \
> ?RANLIB=ranlib ZLIBLIB=../../../extra/zlib -C libpng \
> ?-f scripts/makefile.gcc prefix=foo libpng.a
> gcc -std=gnu99 -c -O3 -I../../../extra/zlib -DPNG_NO_MMX_CODE -I../zlib png.c
> gcc -std=gnu99 -c -O3 -I../../../extra/zlib -DPNG_NO_MMX_CODE
> -I../zlib pngerror.c
> gcc -std=gnu99 -c -O3 -I../../../extra/zlib -DPNG_NO_MMX_CODE -I../zlib pngget.c
> gcc -std=gnu99 -c -O3 -I../../../extra/zlib -DPNG_NO_MMX_CODE -I../zlib pngmem.c
> gcc -std=gnu99 -c -O3 -I../../../extra/zlib -DPNG_NO_MMX_CODE
> -I../zlib pngpread.c
> gcc -std=gnu99 -c -O3 -I../../../extra/zlib -DPNG_NO_MMX_CODE
> -I../zlib pngread.c
> gcc -std=gnu99 -c -O3 -I../../../extra/zlib -DPNG_NO_MMX_CODE -I../zlib pngrio.c
> gcc -std=gnu99 -c -O3 -I../../../extra/zlib -DPNG_NO_MMX_CODE
> -I../zlib pngrtran.c
> gcc -std=gnu99 -c -O3 -I../../../extra/zlib -DPNG_NO_MMX_CODE
> -I../zlib pngrutil.c
> gcc -std=gnu99 -c -O3 -I../../../extra/zlib -DPNG_NO_MMX_CODE -I../zlib pngset.c
> gcc -std=gnu99 -c -O3 -I../../../extra/zlib -DPNG_NO_MMX_CODE
> -I../zlib pngtrans.c
> gcc -std=gnu99 -c -O3 -I../../../extra/zlib -DPNG_NO_MMX_CODE -I../zlib pngwio.c
> gcc -std=gnu99 -c -O3 -I../../../extra/zlib -DPNG_NO_MMX_CODE
> -I../zlib pngwrite.c
> gcc -std=gnu99 -c -O3 -I../../../extra/zlib -DPNG_NO_MMX_CODE
> -I../zlib pngwtran.c
> gcc -std=gnu99 -c -O3 -I../../../extra/zlib -DPNG_NO_MMX_CODE
> -I../zlib pngwutil.c
> ar rcs libpng.a png.o pngerror.o pngget.o pngmem.o pngpread.o
> pngread.o pngrio.o pngrtran.
> o pngrutil.o pngset.o pngtrans.o pngwio.o pngwrite.o pngwtran.o pngwutil.o
> ranlib libpng.a
> cp jconfig.h jpeg-8c/jconfig.h
> cp: cannot create regular file `jpeg-8c/jconfig.h': No such file or directory
> make[2]: *** [jpeg-8c/jconfig.h] Error 1
> make[1]: *** [all] Error 2
> make[1]: Leaving directory
> `/cygdrive/e/sandbox/R-2.13.r55221/src/gnuwin32/bitmap'
> make: *** [bitmapdll] Error 2
>
> Thanks
> Dan
>


From nakama at ki.rim.or.jp  Fri Apr  1 04:27:05 2011
From: nakama at ki.rim.or.jp (Ei-ji Nakama)
Date: Fri, 1 Apr 2011 11:27:05 +0900
Subject: [Rd] SurviveGotoBLAS2 for Win64 (RC release)
In-Reply-To: <A7211836-7401-47D8-BE88-763DDA6A7538@gmail.com>
References: <AANLkTinYxjmGQvf-G8X1jBa3W7oF5N36d833jB6P7txz@mail.gmail.com>
	<AANLkTimTBmFvG1H+b4PPg=qfAQ8GJFHyRfPOjjqx_=Wu@mail.gmail.com>
	<A7211836-7401-47D8-BE88-763DDA6A7538@gmail.com>
Message-ID: <AANLkTik8Fgxd2BGuXk=bCmhhZQUzmjoiC077dVGGiyCK@mail.gmail.com>

> Good to see that at least someone is doing business as usual in Japan these days.

Some people can't download it, can know the rolling blackouts in Tokyo area...
Today is no plan of blackout.

Best Regards,
--
EI-JI Nakama? <nakama (a) ki.rim.or.jp>
"\u4e2d\u9593\u6804\u6cbb"? <nakama (a) ki.rim.or.jp>


From tal.galili at gmail.com  Fri Apr  1 08:49:55 2011
From: tal.galili at gmail.com (Tal Galili)
Date: Fri, 1 Apr 2011 09:49:55 +0300
Subject: [Rd] Adding a "description" meta-tag to the R homepage
Message-ID: <AANLkTinkJyMfygHcvyxX4_Gkrq8vJjtURGFOohN2KF=p@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110401/1bbc021f/attachment.pl>

From hintak_leung at yahoo.co.uk  Fri Apr  1 16:19:14 2011
From: hintak_leung at yahoo.co.uk (Hin-Tak Leung)
Date: Fri, 1 Apr 2011 15:19:14 +0100 (BST)
Subject: [Rd] "R CMD check" accepts but "R CMD INSTALL" rejects a tar ball.
Message-ID: <343859.12417.qm@web29507.mail.ird.yahoo.com>

I have somehow managed to made a source tar ball which "R CMD check" accepts but "R CMD INSTALL" rejects with:

------------------
Warning in untar2(tarfile, files, list, exdir) :
  checksum error for entry 'pax_global_header'
Error in untar2(tarfile, files, list, exdir) : unsupported entry type ?g?
------------------

This happens with both R 2.12.2 (x86 linux) and R svn (x86_64 linux). Since R CMD check does install as part of the check process, there is probably a bug somewhere. The tar ball is uploaded at:

http://htl10.users.sourceforge.net/tmp/Matrix_0.999375-48.tar.gz

and tar -xzpvf works. It is possible to do R CMD INSTALL from the untar'ed data, so I am a bit lost at where the problem is.

The tar ball was generated with 
   git archive ... | gzip > package.tar.gz
similar to the example at the bottom of git-archive.

It is the result of git cherry-pick trunk at 2658 + Matrix-for-R-2.13 at 2657 .


From hintak_leung at yahoo.co.uk  Fri Apr  1 16:21:50 2011
From: hintak_leung at yahoo.co.uk (Hin-Tak Leung)
Date: Fri, 1 Apr 2011 15:21:50 +0100 (BST)
Subject: [Rd] Fw: Re: core Matrix package segfaulted on R CMD check --use-gct
Message-ID: <36771.73678.qm@web29517.mail.ird.yahoo.com>

repost from the subscribed address...

--- On Fri, 1/4/11, Hin-Tak Leung <htl10 at users.sourceforge.net> wrote:

> --- On Wed, 30/3/11, Douglas Bates
> <bates at stat.wisc.edu>
> wrote:
> 
> > I isolated the problem and tested then committed a
> fix. I
> > am going to
> > ask Martin to upload the new release as I have gotten
> out
> > of sync with
> > some of his recent changes and he will, I hope,
> reconcile
> > the branches
> > and trunk.? If you need the fixed version
> immediately,
> > say for
> > testing, the changes are in the file
> > Matrix/src/chm_common.c? You can
> > visit the SVN archive for the project,
> > https://r-forge.r-project.org/scm/?group_id=61, click
> > on the link to
> > Browse Subversion Repository and go to
> > pkg/Matrix/src/chm_common.c
> > 
> > I made the mistake that I chastised others for
> making,
> > performing an
> > operation on the result of a call to install and
> another
> > value that
> > may have required allocation of memory.? The first
> > time install is
> > called on a particular string it allocates and
> SEXPREC,
> > which may
> > cause a garbage collection.
> 
> Have a different (but similiar) problem git cherry-picking
> 
> trunk at 2658 on top of Matrix-for-R-2.13 at 2657.?
> trunk at 2658 + Matrix-for-R-2.13 at 2657 should be identical to
> Matrix-for-R-2.13 at 2659 which you committed earlier
> (according to git svn rebase): 
> 
> > pkgname <- "Matrix"
> > source(file.path(R.home("share"), "R",
> "examples-header.R"))
> > gctorture(TRUE)
> > options(warn = 1)
> > library('Matrix')
> Loading required package: lattice
> Error in regexpr("package:", envName, fixed = TRUE) : 
> ? unprotected object (0x3a52538) encountered (was
> INTSXP)
> Error: package/namespace load failed for 'Matrix'
> Execution halted
> 
> I also found a different problem, but it looks like it is a
> different part of R and possibly in utils. I'll write
> separately and CC' you (the Matrix authors) on it. 
> 
> 
>


From simon.urbanek at r-project.org  Fri Apr  1 17:53:31 2011
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Fri, 1 Apr 2011 11:53:31 -0400
Subject: [Rd] "R CMD check" accepts but "R CMD INSTALL" rejects a tar
	ball.
In-Reply-To: <343859.12417.qm@web29507.mail.ird.yahoo.com>
References: <343859.12417.qm@web29507.mail.ird.yahoo.com>
Message-ID: <1D86E8A0-1ECC-4B6F-9F64-0947F0298295@r-project.org>

?untar:

     You may see warnings from the internal implementation such as
     
     unsupported entry type 'x'

     This often indicates an invalid archive: entry types ?"A-Z"? are
     allowed as extensions, but other types are reserved (this example
     is from Mac OS 10.6.3).  The only thing you can do with such an
     archive is to find a ?tar? program that handles it, and look
     carefully at the resulting files.


So the difference is whether you use external or internal tar. 'g' is the global pax header extension so the format you created is really pax and not tar (pax defines two new types 'x' and 'g').

Cheers,
Simon


On Apr 1, 2011, at 10:19 AM, Hin-Tak Leung wrote:

> I have somehow managed to made a source tar ball which "R CMD check" accepts but "R CMD INSTALL" rejects with:
> 
> ------------------
> Warning in untar2(tarfile, files, list, exdir) :
>  checksum error for entry 'pax_global_header'
> Error in untar2(tarfile, files, list, exdir) : unsupported entry type ?g?
> ------------------
> 
> This happens with both R 2.12.2 (x86 linux) and R svn (x86_64 linux). Since R CMD check does install as part of the check process, there is probably a bug somewhere. The tar ball is uploaded at:
> 
> http://htl10.users.sourceforge.net/tmp/Matrix_0.999375-48.tar.gz
> 
> and tar -xzpvf works. It is possible to do R CMD INSTALL from the untar'ed data, so I am a bit lost at where the problem is.
> 
> The tar ball was generated with 
>   git archive ... | gzip > package.tar.gz
> similar to the example at the bottom of git-archive.
> 
> It is the result of git cherry-pick trunk at 2658 + Matrix-for-R-2.13 at 2657 .
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From hintak_leung at yahoo.co.uk  Fri Apr  1 18:16:05 2011
From: hintak_leung at yahoo.co.uk (Hin-Tak Leung)
Date: Fri, 1 Apr 2011 17:16:05 +0100 (BST)
Subject: [Rd] "R CMD check" accepts but "R CMD INSTALL" rejects a tar
	ball.
In-Reply-To: <1D86E8A0-1ECC-4B6F-9F64-0947F0298295@r-project.org>
Message-ID: <239872.58915.qm@web29501.mail.ird.yahoo.com>

--- On Fri, 1/4/11, Simon Urbanek <simon.urbanek at r-project.org> wrote:

> ?untar:
> 
> ? ???You may see warnings from the
> internal implementation such as
> ? ???
> ? ???unsupported entry type 'x'
> 
> ? ???This often indicates an invalid
> archive: entry types ?"A-Z"? are
> ? ???allowed as extensions, but other
> types are reserved (this example
> ? ???is from Mac OS 10.6.3).? The
> only thing you can do with such an
> ? ???archive is to find a ?tar?
> program that handles it, and look
> ? ???carefully at the resulting files.
> 
> 
> So the difference is whether you use external or internal
> tar. 'g' is the global pax header extension so the format
> you created is really pax and not tar (pax defines two new
> types 'x' and 'g').
> 
> Cheers,
> Simon

Okay, thanks. So I guess git-archive --format=tar uses GNU tar extensions (not too surprising). So this is documented... and a documented incompatibilities between different tar/tar extensions. But this behavior of R is a bit unexpected - When R CMD check (which involves installing to a temporary location then loads it and runs various things) works and R CMD INSTALL itself does not.
 
OTOH, should this be reported to the GIT people?


> 
> 
> On Apr 1, 2011, at 10:19 AM, Hin-Tak Leung wrote:
> 
> > I have somehow managed to made a source tar ball which
> "R CMD check" accepts but "R CMD INSTALL" rejects with:
> > 
> > ------------------
> > Warning in untar2(tarfile, files, list, exdir) :
> >? checksum error for entry 'pax_global_header'
> > Error in untar2(tarfile, files, list, exdir) :
> unsupported entry type ?g?
> > ------------------
> > 
> > This happens with both R 2.12.2 (x86 linux) and R svn
> (x86_64 linux). Since R CMD check does install as part of
> the check process, there is probably a bug somewhere. The
> tar ball is uploaded at:
> > 
> > http://htl10.users.sourceforge.net/tmp/Matrix_0.999375-48.tar.gz
> > 
> > and tar -xzpvf works. It is possible to do R CMD
> INSTALL from the untar'ed data, so I am a bit lost at where
> the problem is.
> > 
> > The tar ball was generated with 
> >???git archive ... | gzip >
> package.tar.gz
> > similar to the example at the bottom of git-archive.
> > 
> > It is the result of git cherry-pick trunk at 2658 +
> Matrix-for-R-2.13 at 2657 .
> > 
> > ______________________________________________
> > R-devel at r-project.org
> mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> 
>


From simon.urbanek at r-project.org  Fri Apr  1 18:37:18 2011
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Fri, 1 Apr 2011 12:37:18 -0400
Subject: [Rd] "R CMD check" accepts but "R CMD INSTALL" rejects a tar
	ball.
In-Reply-To: <239872.58915.qm@web29501.mail.ird.yahoo.com>
References: <239872.58915.qm@web29501.mail.ird.yahoo.com>
Message-ID: <0A7CA201-501F-4C5F-B24E-51781C854F29@r-project.org>


On Apr 1, 2011, at 12:16 PM, Hin-Tak Leung wrote:

> --- On Fri, 1/4/11, Simon Urbanek <simon.urbanek at r-project.org> wrote:
> 
>> ?untar:
>> 
>>      You may see warnings from the
>> internal implementation such as
>>      
>>      unsupported entry type 'x'
>> 
>>      This often indicates an invalid
>> archive: entry types ?"A-Z"? are
>>      allowed as extensions, but other
>> types are reserved (this example
>>      is from Mac OS 10.6.3).  The
>> only thing you can do with such an
>>      archive is to find a ?tar?
>> program that handles it, and look
>>      carefully at the resulting files.
>> 
>> 
>> So the difference is whether you use external or internal
>> tar. 'g' is the global pax header extension so the format
>> you created is really pax and not tar (pax defines two new
>> types 'x' and 'g').
>> 
>> Cheers,
>> Simon
> 
> Okay, thanks. So I guess git-archive --format=tar uses GNU tar extensions (not too surprising). So this is documented... and a documented incompatibilities between different tar/tar extensions. But this behavior of R is a bit unexpected - When R CMD check (which involves installing to a temporary location then loads it and runs various things) works and R CMD INSTALL itself does not.
> 
> OTOH, should this be reported to the GIT people?
> 

I think you should re-read my e-mail more carefully -- those are not GNU extensions, those are headers used by pax, not tar. pax is a format inspired by tar and introduced in POSIX.1-2001, see
http://en.wikipedia.org/wiki/Pax_(Unix)

Cheers,
Simon


>> 
>> 
>> On Apr 1, 2011, at 10:19 AM, Hin-Tak Leung wrote:
>> 
>>> I have somehow managed to made a source tar ball which
>> "R CMD check" accepts but "R CMD INSTALL" rejects with:
>>> 
>>> ------------------
>>> Warning in untar2(tarfile, files, list, exdir) :
>>>   checksum error for entry 'pax_global_header'
>>> Error in untar2(tarfile, files, list, exdir) :
>> unsupported entry type ?g?
>>> ------------------
>>> 
>>> This happens with both R 2.12.2 (x86 linux) and R svn
>> (x86_64 linux). Since R CMD check does install as part of
>> the check process, there is probably a bug somewhere. The
>> tar ball is uploaded at:
>>> 
>>> http://htl10.users.sourceforge.net/tmp/Matrix_0.999375-48.tar.gz
>>> 
>>> and tar -xzpvf works. It is possible to do R CMD
>> INSTALL from the untar'ed data, so I am a bit lost at where
>> the problem is.
>>> 
>>> The tar ball was generated with 
>>>    git archive ... | gzip >
>> package.tar.gz
>>> similar to the example at the bottom of git-archive.
>>> 
>>> It is the result of git cherry-pick trunk at 2658 +
>> Matrix-for-R-2.13 at 2657 .
>>> 
>>> ______________________________________________
>>> R-devel at r-project.org
>> mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> 
>> 
> 
> 


From cubranic at stat.ubc.ca  Fri Apr  1 20:22:40 2011
From: cubranic at stat.ubc.ca (Davor Cubranic)
Date: Fri, 1 Apr 2011 11:22:40 -0700
Subject: [Rd] Phrase "package writer" in R-exts
Message-ID: <CCD49859-DA7D-439B-B75A-06082BDFF57D@stat.ubc.ca>

In a conversation with a programmer new to writing R packages, he mentioned that he was very confused by phrase "package writer" used in the document, and said that he "[was] literally imagining some sort of function that writes something related to packages".

I can see his point: not only is it confusing, but I think it's also bad English (one wouldn't say "the novel's writer"). Can this be changed to "package author"?

Davor

From pdalgd at gmail.com  Fri Apr  1 20:38:27 2011
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 1 Apr 2011 20:38:27 +0200
Subject: [Rd] Adding a "description" meta-tag to the R homepage
In-Reply-To: <AANLkTinkJyMfygHcvyxX4_Gkrq8vJjtURGFOohN2KF=p@mail.gmail.com>
References: <AANLkTinkJyMfygHcvyxX4_Gkrq8vJjtURGFOohN2KF=p@mail.gmail.com>
Message-ID: <AF9DA5E4-BC67-4F34-935C-5B48017EF33B@gmail.com>


On Apr 1, 2011, at 08:49 , Tal Galili wrote:

> Hello all,
> I hope I'm writing to the correct place.
> 
> I believe that the R homepage will benefit from including the "description"
> meta tag in it's homepage.
> The reason is that google uses that tag to decide what to show when the R
> homepage shows up on a search result.
> The current description of the first result of searching "R" in google is:
> 
> "*R*, also called GNU S, is a strongly functional language and environment
> to statistically explore data sets, make many graphical displays of data
> from custom *..."*
> *
> *
> This defention is truncated.


Interesting. What's odd is that although that phrasing is used in multiple places on the net, it is not in the actual www.r-project.org/index.html, nor in any other "official" places that I can spot.

However, what gets displayed for SAS and Stata is not what is in their description tags?

SAS:
<meta content="SAS Business Analytics software -- 30+ years of experience and 50,000+ customer sites worldwide. View success stories, analyst reports &amp; demos." name="description" />

Stata:
<meta name="description" content="Data Analysis and Statistical Software for Professionals" />

What gives?


> 
> 
> It seems that other statistical packages (and some known open source
> projects) already noticed this.  Here is what they write about themselves
> (when searching for their name on google):
> 
>   - SAS: 50,000 Customer Sites Use SAS for CRM, BI, Analytics & More-Get
>   Info
>   - SPSS: Analytical Software at SPSS.com. Specializing in data mining,
>   customer relationship management, business intelligence and data analysis.
>   - JMP: JMP is statistical software for expert data analysis, DOE, and Six
>   Sigma, from SAS. For Mac, Windows, and Linux.
>   - Stata: Integrated statistical package for data analysis, data
>   management and graphics.
>   - Perl: The Perl Programming Language at Perl.org. Links and other
>   helpful resources for new and experienced Perl programmers.
>   - Matematica: Wolfram Research, makers of Mathematica, the only fully
>   integrated technical computing software.
>   - It seems that Python, Ruby, and Matlab are not using any description
>   tag (and their google description is also truncated)
> 
> 
> I hope this helps.
> 
> Best,
> Tal
> 
> 
> ----------------Contact
> Details:-------------------------------------------------------
> Contact me: Tal.Galili at gmail.com |  972-52-7275845
> Read me: www.talgalili.com (Hebrew) | www.biostatistics.co.il (Hebrew) |
> www.r-statistics.com (English)
> ----------------------------------------------------------------------------------------------
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Peter Dalgaard
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From r.ted.byers at gmail.com  Fri Apr  1 21:17:05 2011
From: r.ted.byers at gmail.com (Ted Byers)
Date: Fri, 1 Apr 2011 15:17:05 -0400
Subject: [Rd] Phrase "package writer" in R-exts
In-Reply-To: <CCD49859-DA7D-439B-B75A-06082BDFF57D@stat.ubc.ca>
References: <CCD49859-DA7D-439B-B75A-06082BDFF57D@stat.ubc.ca>
Message-ID: <06cc01cbf0a1$63fff1f0$2bffd5d0$@gmail.com>

> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-
> project.org] On Behalf Of Davor Cubranic
> Sent: April-01-11 2:23 PM
>
> In a conversation with a programmer new to writing R packages, he
> mentioned that he was very confused by phrase "package writer" used in
> the document, and said that he "[was] literally imagining some sort of
> function that writes something related to packages".
> 
> I can see his point: not only is it confusing, but I think it's also bad
English (one
> wouldn't say "the novel's writer"). Can this be changed to "package
author"?
> 

No, it is not "bad English."   Neither would I regard it as being confusing.

To my eye, it is unambiguous.  

This reminds me of a conversation I had a few years ago with a well educated
individual who claimed that the sentence "He was hit by the ball" was
grammatically wrong, and that the correct way to express that idea was "The
ball hit him."  Needless to say, we ended up agreeing to disagree.  Of
course, obviously, BOTH are correct.  This individual had an earned Ph.D.
from a prominent north american university.  The English langage is
beautifully large and complex, having drawn both vocabulary and grammatical
structures from a wide variety of languages.  That makes it hard to learn to
use well, but it is arguably the most expressive language on the planet
(what oher language has a vocabulary as large as that in english or grammar
as flexible as is english).  I spent a little time working in India, and
found that ordinary working people, who happen to speak as many as 5 local
and regional languages in addition to english, and found that they use such
a different subset if standard english vocabulary from what the same sort of
people would normally use in Toronto (where I was born), that I had to
listen carefully in order to understand what they meant.  I even found
myself translating from standard english into standard english, for two
bright people with very different ethic backgrounds and who had learned
english after they turned 30.  The influences of their respective mother
tongues so distorted their use of english that they were mutually
incomprehensible even though it was obvious to me what each was saying.  One
sweet lady I met in Singapore (a waitress) told me she liked servicing me,
but didn't like serving the Australians next to me.  She said she found it
easy to understand me but she couldn't understand anything the Aussies at
the next table were saying.  I would never have noticed a significan
difference between how we spoke, but she had plenty of trouble trying to
figure out what they were saying.  One of my best friends spent 6 months of
his Ph.D. program just watching TV.  That was because even though his
grammar was perfect and his written english was beautiful, he had never hear
english spoken by a native english speaker.  Thus his diction was so
distorted by habits developed in speaking perfect Mandarin (his mother
tongue), that his spoken english was incomprehensible to everyone outside
China.

This is actually a major problem for any author that aspires to a global
market.  How do you write in such a way that you will be understood by
everyone in your target market?  I won't presume to offer writing advice to
the authors in question, in part because I don't know a good solution.

However, Davor, I notice you are at one of the finest universities in
Canada, so might I suggest you approach someone in the english department
there for insight into the evolution of english in the context of a
multicultural society,  and how that can help make our writing more readily
understood by a global  audience?  Note, while I see the author's
responsibility to write perfectly (or at least try), the reader also has a
responsibility to work at determining what the author meant by what he or
she wrote.

Cheers,

Ted


From proebuck at mdanderson.org  Fri Apr  1 21:36:55 2011
From: proebuck at mdanderson.org (Roebuck,Paul L)
Date: Fri, 1 Apr 2011 14:36:55 -0500
Subject: [Rd] Adding a "description" meta-tag to the R homepage
In-Reply-To: <AF9DA5E4-BC67-4F34-935C-5B48017EF33B@gmail.com>
Message-ID: <C9BB9387.172A2%proebuck@mdanderson.org>

On 4/1/11 1:38 PM, "peter dalgaard" <pdalgd at gmail.com> wrote:

> On Apr 1, 2011, at 08:49 , Tal Galili wrote:
> 
>> I believe that the R homepage will benefit from including the "description"
>> meta tag in it's homepage.
>> The reason is that google uses that tag to decide what to show when the R
>> homepage shows up on a search result.
>> The current description of the first result of searching "R" in google is:
>> 
>> "*R*, also called GNU S, is a strongly functional language and environment
>> to statistically explore data sets, make many graphical displays of data
>> from custom *..."*
>> *
>> *
>> This defention is truncated.
> 
> 
> Interesting. What's odd is that although that phrasing is used in multiple
> places on the net, it is not in the actual www.r-project.org/index.html, nor
> in any other "official" places that I can spot.
> 
> However, what gets displayed for SAS and Stata is not what is in their
> description tags?
> 
> SAS:
> <meta content="SAS Business Analytics software -- 30+ years of experience and
> 50,000+ customer sites worldwide. View success stories, analyst reports &amp;
> demos." name="description" />
> 
> Stata:
> <meta name="description" content="Data Analysis and Statistical Software for
> Professionals" />
> 
> What gives?

Preferences then?

R:
<meta name="description"
      content="Data Analysis and Statistical Software for the
Intelligentsia" />

    - or - 

<meta name="description"
      content="Not Your Father's Data Analysis and Statistical Software..."
/>


>> It seems that other statistical packages (and some known open source
>> projects) already noticed this.  Here is what they write about themselves
>> (when searching for their name on google):
>> 
>>   - SAS: 50,000 Customer Sites Use SAS for CRM, BI, Analytics & More-Get
>>   Info
>>   - SPSS: Analytical Software at SPSS.com. Specializing in data mining,
>>   customer relationship management, business intelligence and data analysis.
>>   - JMP: JMP is statistical software for expert data analysis, DOE, and Six
>>   Sigma, from SAS. For Mac, Windows, and Linux.
>>   - Stata: Integrated statistical package for data analysis, data
>>   management and graphics.
>>   - Perl: The Perl Programming Language at Perl.org. Links and other
>>   helpful resources for new and experienced Perl programmers.
>>   - Matematica: Wolfram Research, makers of Mathematica, the only fully
>>   integrated technical computing software.
>>   - It seems that Python, Ruby, and Matlab are not using any description
>>   tag (and their google description is also truncated)
>> 


From hadley at rice.edu  Fri Apr  1 21:57:06 2011
From: hadley at rice.edu (Hadley Wickham)
Date: Fri, 1 Apr 2011 14:57:06 -0500
Subject: [Rd] Adding a "description" meta-tag to the R homepage
In-Reply-To: <AF9DA5E4-BC67-4F34-935C-5B48017EF33B@gmail.com>
References: <AANLkTinkJyMfygHcvyxX4_Gkrq8vJjtURGFOohN2KF=p@mail.gmail.com>
	<AF9DA5E4-BC67-4F34-935C-5B48017EF33B@gmail.com>
Message-ID: <AANLkTimQBVPQxpJin2rO+FwiGWLNT4s_Xep0KBWszvV9@mail.gmail.com>

> Interesting. What's odd is that although that phrasing is used in multiple places on the net, it is not in the actual www.r-project.org/index.html, nor in any other "official" places that I can spot.
>
> However, what gets displayed for SAS and Stata is not what is in their description tags?

Google takes the description tag as advice, but if it thinks the page
is actually about something else, it will write its own summary.

Hadley


-- 
Assistant Professor / Dobelman Family Junior Chair
Department of Statistics / Rice University
http://had.co.nz/


From hintak_leung at yahoo.co.uk  Fri Apr  1 22:01:33 2011
From: hintak_leung at yahoo.co.uk (Hin-Tak Leung)
Date: Fri, 1 Apr 2011 21:01:33 +0100 (BST)
Subject: [Rd] "R CMD check" accepts but "R CMD INSTALL" rejects a tar
	ball.
In-Reply-To: <0A7CA201-501F-4C5F-B24E-51781C854F29@r-project.org>
Message-ID: <656588.10292.qm@web29515.mail.ird.yahoo.com>

--- On Fri, 1/4/11, Simon Urbanek <simon.urbanek at r-project.org> wrote:
> >> So the difference is whether you use external or
> internal
> >> tar. 'g' is the global pax header extension so the
> format
> >> you created is really pax and not tar (pax defines
> two new
> >> types 'x' and 'g').
> >> 
> >> Cheers,
> >> Simon
> > 
> > Okay, thanks. So I guess git-archive --format=tar uses
> GNU tar extensions (not too surprising). So this is
> documented... and a documented incompatibilities between
> different tar/tar extensions. But this behavior of R is a
> bit unexpected - When R CMD check (which involves installing
> to a temporary location then loads it and runs various
> things) works and R CMD INSTALL itself does not.
> > 
> > OTOH, should this be reported to the GIT people?
> > 
> 
> I think you should re-read my e-mail more carefully --
> those are not GNU extensions, those are headers used by pax,
> not tar. pax is a format inspired by tar and introduced in
> POSIX.1-2001, see
> http://en.wikipedia.org/wiki/Pax_(Unix)
> 
> Cheers,
> Simon


Argh, got it. The more informative page is in GNU tar's man page, but even GNU tar doesn't write pax by default. I happened to have git's git repository in my hard disc, and you are correct, git-archive, according to its source code, does write pax header, and refers to pax in several places. So git-archive's documentation (and its '--format=tar' option) is misleading; although even GNU fileutils says the ungzip'ed bundle is "posix tar". Go figure...

OTOH, "R CMD check" extracts the content (and does an install) and 'R CMD INSTALL' itself does not, that's a bit inconsistent.


> 
> 
> >> 
> >> 
> >> On Apr 1, 2011, at 10:19 AM, Hin-Tak Leung wrote:
> >> 
> >>> I have somehow managed to made a source tar
> ball which
> >> "R CMD check" accepts but "R CMD INSTALL" rejects
> with:
> >>> 
> >>> ------------------
> >>> Warning in untar2(tarfile, files, list, exdir)
> :
> >>>???checksum error for entry
> 'pax_global_header'
> >>> Error in untar2(tarfile, files, list, exdir)
> :
> >> unsupported entry type ?g?
> >>> ------------------
> >>> 
> >>> This happens with both R 2.12.2 (x86 linux)
> and R svn
> >> (x86_64 linux). Since R CMD check does install as
> part of
> >> the check process, there is probably a bug
> somewhere. The
> >> tar ball is uploaded at:
> >>> 
> >>> http://htl10.users.sourceforge.net/tmp/Matrix_0.999375-48.tar.gz
> >>> 
> >>> and tar -xzpvf works. It is possible to do R
> CMD
> >> INSTALL from the untar'ed data, so I am a bit lost
> at where
> >> the problem is.
> >>> 
> >>> The tar ball was generated with 
> >>>? ? git archive ... | gzip >
> >> package.tar.gz
> >>> similar to the example at the bottom of
> git-archive.
> >>> 
> >>> It is the result of git cherry-pick trunk at 2658
> +
> >> Matrix-for-R-2.13 at 2657 .
> >>> 
> >>>
> ______________________________________________
> >>> R-devel at r-project.org
> >> mailing list
> >>> https://stat.ethz.ch/mailman/listinfo/r-devel
> >> 
> >> 
> > 
> > 
> 
>


From kw.stat at gmail.com  Fri Apr  1 22:02:24 2011
From: kw.stat at gmail.com (Kevin Wright)
Date: Fri, 1 Apr 2011 15:02:24 -0500
Subject: [Rd] Phrase "package writer" in R-exts
In-Reply-To: <CCD49859-DA7D-439B-B75A-06082BDFF57D@stat.ubc.ca>
References: <CCD49859-DA7D-439B-B75A-06082BDFF57D@stat.ubc.ca>
Message-ID: <BANLkTimuAoVvw2AP+euXwfrRjswghjDy=w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110401/b5ea5a72/attachment.pl>

From cbeleites at units.it  Fri Apr  1 22:42:56 2011
From: cbeleites at units.it (Claudia Beleites)
Date: Fri, 01 Apr 2011 22:42:56 +0200
Subject: [Rd] logos
Message-ID: <4D9638D0.9030700@units.it>

Dear all,

I'd like to link one of the logos in our Google Summer of Code Profile. 
If I remember correctly, behind the logo link at 
http://developer.r-project.org/ (i.e. 
http://developer.r-project.org/Logo) also small versions can be found. 
However, I'm not allowed to access that directory.
I have no problem with putting a small version of the "normal" logo 
somewhere online, but I'm wondering whether the logo directory really 
isn't supposed to be accessed by the public.

Thanks,

Claudia


From simon.urbanek at r-project.org  Fri Apr  1 22:53:29 2011
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Fri, 1 Apr 2011 16:53:29 -0400
Subject: [Rd] logos
In-Reply-To: <4D9638D0.9030700@units.it>
References: <4D9638D0.9030700@units.it>
Message-ID: <0E54D019-1231-46F4-A83F-1941328DFD97@r-project.org>


On Apr 1, 2011, at 4:42 PM, Claudia Beleites wrote:

> Dear all,
> 
> I'd like to link one of the logos in our Google Summer of Code Profile. If I remember correctly, behind the logo link at http://developer.r-project.org/ (i.e. http://developer.r-project.org/Logo) also small versions can be found. However, I'm not allowed to access that directory.
> I have no problem with putting a small version of the "normal" logo somewhere online, but I'm wondering whether the logo directory really isn't supposed to be accessed by the public.
> 

Thanks, yes, the developer pages had indexes disabled by default, I have enabled them now (which was the case way back before we switched servers if I remember correctly).

Thanks,
Simon


From cubranic at stat.ubc.ca  Sat Apr  2 02:13:21 2011
From: cubranic at stat.ubc.ca (Davor Cubranic)
Date: Fri, 1 Apr 2011 17:13:21 -0700
Subject: [Rd] Phrase "package writer" in R-exts
In-Reply-To: <06cc01cbf0a1$63fff1f0$2bffd5d0$@gmail.com>
References: <CCD49859-DA7D-439B-B75A-06082BDFF57D@stat.ubc.ca>
	<06cc01cbf0a1$63fff1f0$2bffd5d0$@gmail.com>
Message-ID: <0214C4D0-E848-4F91-9245-AA2F12E4C1E2@stat.ubc.ca>

On 2011-04-01, at 12:17 PM, Ted Byers wrote:

> Note, while I see the author's
> responsibility to write perfectly (or at least try), the reader also has a
> responsibility to work at determining what the author meant by what he or
> she wrote.

Most people don't read reference manuals to engage with the author (writer?) and analyze the subtext, but to find relevant information quickly.

For the programmer I was talking to at least (a native English speaker, BTW), R-exts fell short in that respect. When I first heard about his confusion I also thought "how can you miss that?", but now believe that the manual would be improved by replacing "writer" with "author". It is already dense enough with real information, why make it more obscure ?

Davor

From tal.galili at gmail.com  Sat Apr  2 16:24:10 2011
From: tal.galili at gmail.com (Tal Galili)
Date: Sat, 2 Apr 2011 17:24:10 +0300
Subject: [Rd] Adding a "description" meta-tag to the R homepage
In-Reply-To: <AF9DA5E4-BC67-4F34-935C-5B48017EF33B@gmail.com>
References: <AANLkTinkJyMfygHcvyxX4_Gkrq8vJjtURGFOohN2KF=p@mail.gmail.com>
	<AF9DA5E4-BC67-4F34-935C-5B48017EF33B@gmail.com>
Message-ID: <AANLkTinKSSJUCeYuu4GSKwh9-NUiNWYc51YpQUdbWgz9@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110402/05fa0fd2/attachment.pl>

From hb at biostat.ucsf.edu  Sat Apr  2 23:34:20 2011
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Sat, 2 Apr 2011 14:34:20 -0700
Subject: [Rd] reg.finalizer(): Multiple finalizers?
Message-ID: <BANLkTin2soPo6kAeUJwW6sD5jiVvft7i6A@mail.gmail.com>

Hi,

I've got some questions regarding finalizers registered using
reg.finalizer().  I have a setup where in certain cases I wish to set
a new finalizer to an object that already got one.  Since there is no
API for removing/replacing already registered finalizers (have been
"requested" previously on this list), I have basically just added a
new finalizer by calling reg.finalizer() a second time.  This seems to
work (from being used for years), but it is not a documented property,
so it got me wondering.


Q1. Is it ok to register multiple finalizers this way, i.e. calling
reg.finalizer() multiple times on the same object?

Q2. If so, is the order in which the finalizers are called deterministic?

Q3. Is there a particular reason for not being able to replace/remove
existing finalizers?  I've tried to backtrack the code for
reg.finalizer() and I see a FINALIZE_ON_EXIT_MASK flag being set.
Could this be unset equally easy as setting it, or is there more to
it?


Regarding Q2: When running the below tests on Windows with R v2.12.2
patched, v2.13.0 beta, v2.14.0 devel, it seems that there is a
last-in-first-out ordering of how the finalizers are called - is that
an intended property?


# Clean up
rm(env); gc();

for (kk in 1:100) {
  s <- c();

  # Create a new environment
  env <- new.env();

  # Register Finalizer A
  reg.finalizer(env, function(env) s <<- c(s, "A"));

  # Register Finalizer B
  reg.finalizer(env, function(env) s <<- c(s, "B"));

  # Register Finalizer C
  reg.finalizer(env, function(env) s <<- c(s, "C"));

  # Trigger cleanup
  rm(env); gc();

  # Display order
  print(s);

  # Test hypothesis
  stopifnot(all.equal(s, c("C", "B", "A")));
} # for (kk ...)


Thanks

Henrik


From jayemerson at gmail.com  Sun Apr  3 19:31:07 2011
From: jayemerson at gmail.com (Jay Emerson)
Date: Sun, 3 Apr 2011 13:31:07 -0400
Subject: [Rd] Suggests and examples
Message-ID: <AANLkTim44NPkxsUf4CYuERs2hQPFc3aH+XkiGSFamS3E@mail.gmail.com>

I apologize in advance for probably missing something obvious, but if
someone could point me in the right direction I'd be grateful.  This
NOTE is not unique to our package (I list a few others, below).

Package bcp has several Suggests (strucchange, for example).

Then in an Rd file, we have

if (require(strucchange)) {

  # Doing some examples making use of strucchange

}

The CRAN check results reports the following NOTE:

checking for unstated dependencies in examples ... NOTE
'library' or 'require' calls not declared from:
DNAcopy coda strucchange

I note the same problems in other packages (e1071, Deducer, diveMOVE,
gplots, ...)

Any hints?  I'm pretty confident that Suggests: is preferable to
Depends: in such a case, but I can't seem to address this note.
Thanks,

Jay


-- 
John W. Emerson (Jay)
Associate Professor of Statistics
Department of Statistics
Yale University
http://www.stat.yale.edu/~jay


From ligges at statistik.tu-dortmund.de  Sun Apr  3 19:57:47 2011
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sun, 03 Apr 2011 19:57:47 +0200
Subject: [Rd] Suggests and examples
In-Reply-To: <AANLkTim44NPkxsUf4CYuERs2hQPFc3aH+XkiGSFamS3E@mail.gmail.com>
References: <AANLkTim44NPkxsUf4CYuERs2hQPFc3aH+XkiGSFamS3E@mail.gmail.com>
Message-ID: <4D98B51B.6000809@statistik.tu-dortmund.de>



On 03.04.2011 19:31, Jay Emerson wrote:
> I apologize in advance for probably missing something obvious, but if
> someone could point me in the right direction I'd be grateful.  This
> NOTE is not unique to our package (I list a few others, below).
>
> Package bcp has several Suggests (strucchange, for example).


Well, at least the version ion CRAN does not have any Suggests entry in 
its DESCRIPTION file...

Uwe



> Then in an Rd file, we have
>
> if (require(strucchange)) {
>
>    # Doing some examples making use of strucchange
>
> }
>
> The CRAN check results reports the following NOTE:
>
> checking for unstated dependencies in examples ... NOTE
> 'library' or 'require' calls not declared from:
> DNAcopy coda strucchange
>
> I note the same problems in other packages (e1071, Deducer, diveMOVE,
> gplots, ...)
>
> Any hints?  I'm pretty confident that Suggests: is preferable to
> Depends: in such a case, but I can't seem to address this note.
> Thanks,
>
> Jay
>
>


From jayemerson at gmail.com  Sun Apr  3 20:30:02 2011
From: jayemerson at gmail.com (Jay Emerson)
Date: Sun, 3 Apr 2011 14:30:02 -0400
Subject: [Rd] Suggests and examples
In-Reply-To: <4D98B51B.6000809@statistik.tu-dortmund.de>
References: <AANLkTim44NPkxsUf4CYuERs2hQPFc3aH+XkiGSFamS3E@mail.gmail.com>
	<4D98B51B.6000809@statistik.tu-dortmund.de>
Message-ID: <AANLkTinz7NHdr+LTzfcqnCmQsEJ_9_UW9GiJss=45Gno@mail.gmail.com>

That must be it.  Our new 3.0.0 has then added the Suggests, and as
the changes from 2.2.0 to 3.0.0 were unrelated I assumed we had been
properly suggesting previously; apparently not.

Thanks,

Jay

On Sun, Apr 3, 2011 at 1:57 PM, Uwe Ligges
<ligges at statistik.tu-dortmund.de> wrote:
>
>
> On 03.04.2011 19:31, Jay Emerson wrote:
>>
>> I apologize in advance for probably missing something obvious, but if
>> someone could point me in the right direction I'd be grateful. ?This
>> NOTE is not unique to our package (I list a few others, below).
>>
>> Package bcp has several Suggests (strucchange, for example).
>
>
> Well, at least the version ion CRAN does not have any Suggests entry in its
> DESCRIPTION file...
>
> Uwe
>
>
>
>> Then in an Rd file, we have
>>
>> if (require(strucchange)) {
>>
>> ? # Doing some examples making use of strucchange
>>
>> }
>>
>> The CRAN check results reports the following NOTE:
>>
>> checking for unstated dependencies in examples ... NOTE
>> 'library' or 'require' calls not declared from:
>> DNAcopy coda strucchange
>>
>> I note the same problems in other packages (e1071, Deducer, diveMOVE,
>> gplots, ...)
>>
>> Any hints? ?I'm pretty confident that Suggests: is preferable to
>> Depends: in such a case, but I can't seem to address this note.
>> Thanks,
>>
>> Jay
>>
>>
>



-- 
John W. Emerson (Jay)
Associate Professor of Statistics
Department of Statistics
Yale University
http://www.stat.yale.edu/~jay


From hb at biostat.ucsf.edu  Mon Apr  4 06:11:26 2011
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Sun, 3 Apr 2011 21:11:26 -0700
Subject: [Rd] Inconsistency: sort(NULL)/sort.int(NULL) does not throw an
 error, cf. order(NULL), sort.int(NULL, index.return=TRUE), ...
Message-ID: <BANLkTimE=h-hYbHH5TS5K6x+Fu0LtRwYFQ@mail.gmail.com>

Hi,

while backtracking why sort(NULL) gives a warning, and acknowledging
that NULL is not the same as an empty vector and sort(NULL) is bad
coding, I discovered the following inconsistency of sort.int():

> x <- NULL

> sort(x)
Warning in is.na(x) :
  is.na() applied to non-(list or vector) of type 'NULL'
NULL

> sort.int(x)
Warning in is.na(x) :
  is.na() applied to non-(list or vector) of type 'NULL'
NULL

> sort.int(x, index.return=TRUE)
Warning in is.na(x) :
  is.na() applied to non-(list or vector) of type 'NULL'
Error in sort.list(x, decreasing = decreasing) :
  argument 1 is not a vector

> sort.int(x, partial=1)
Warning in is.na(x) :
  is.na() applied to non-(list or vector) of type 'NULL'
Error in sort.int(NULL, partial = 1) : only atomic vectors can be sorted

> order(x)
Error in order(x) : argument 1 is not a vector


Using an empty vector behaves correctly, e.g. x <- character(0).

For consistency, should sort.int(NULL) also give an error?  If so,
that would result in sort(NULL) throwing an error too, which might
have lots of implications to code/package using NULL as an empty
vector.


Alternatively, if leaving sort.int(NULL) as is, maybe it would make
sense to remove the non-informative warning, e.g. by having sort.int()
testing for:

if (is.null(x) && (!is.null(partial) && !index.return)) {
  return(NULL);
}

or replace it with an informative warning on trying to use sort.int()
to sort NULL.

The above is the case for R version 2.13.0 beta (2011-03-31 r55221)
and R version 2.14.0 Under development (unstable) (2011-04-02 r55254).

/Henrik


From ronggui.huang at gmail.com  Mon Apr  4 08:09:02 2011
From: ronggui.huang at gmail.com (Wincent)
Date: Mon, 4 Apr 2011 14:09:02 +0800
Subject: [Rd] [R-sig-ME] Documentation for the glm module in jags/rjags?
In-Reply-To: <BANLkTi=u+ZBZvij9UgSYaZi0QdqSwy9ztw@mail.gmail.com>
References: <AANLkTik4iX-dYPeGtjSZP22ts=M1gpSWKyFtjfUAt63V@mail.gmail.com>
	<1301601658.503.46.camel@braque.iarc.fr>
	<BANLkTintLF-BRhczDP+uenKzq3mevw3N5g@mail.gmail.com>
	<BANLkTikE1dwPE48iMe9QS+DSWwuRG_gCPQ@mail.gmail.com>
	<BANLkTi=u+ZBZvij9UgSYaZi0QdqSwy9ztw@mail.gmail.com>
Message-ID: <BANLkTi=hV146+sH57yKqL+nRggnGLuiXyg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110404/058b1da1/attachment.pl>

From thomasmang.ng at googlemail.com  Sun Apr  3 21:36:20 2011
From: thomasmang.ng at googlemail.com (Thomas Mang)
Date: Sun, 03 Apr 2011 21:36:20 +0200
Subject: [Rd] Rtools and MinGW
Message-ID: <4D98CC34.5080802@gmail.com>

Hi,

I have R version 2.8.1 and Rtools 28 installed (as you might guess, set 
up years ago). In Rtools the MinGW GCC 4.2 compiler toolset is included.

For my regular C/C++ programs I have also installed, separately, the 
full MinGW bundle with the latest GCC 4.5 compiler tools. So I have two 
g++ variants on the same machine.

According to the Rtools documentation, the bin directory of it shall be 
in the system PATH, and very early in the PATH (first elements). 
Presently the bin directory of the Rtools-MinGW is front.
Fine but Ok for my daily C++ work I actually prefer that the regular 
(non-Rtools) MinGW compiler is invoked, hence I would prefer putting 
that in front. But then, of course, invoking g++ from R development 
would refer to the regular MinGW compiler toolset. When I do R 
development, would you expect it to cause problems if actually the 
regular MinGW (gcc 4.5) is invoked, and not the version that came 
bundled with Rtools (4.2) ? Or is this something I should better stay 
away from ?
If not likely to work, what would you suggest to do instead ?

thanks and best,
Thomas


From ripley at stats.ox.ac.uk  Mon Apr  4 11:04:47 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 4 Apr 2011 10:04:47 +0100 (BST)
Subject: [Rd] Rtools and MinGW
In-Reply-To: <4D98CC34.5080802@gmail.com>
References: <4D98CC34.5080802@gmail.com>
Message-ID: <alpine.LFD.2.02.1104041002020.32350@gannet.stats.ox.ac.uk>

On Sun, 3 Apr 2011, Thomas Mang wrote:

> Hi,
>
> I have R version 2.8.1 and Rtools 28 installed (as you might guess, set up 
> years ago). In Rtools the MinGW GCC 4.2 compiler toolset is included.
>
> For my regular C/C++ programs I have also installed, separately, the full 
> MinGW bundle with the latest GCC 4.5 compiler tools. So I have two g++ 
> variants on the same machine.
>
> According to the Rtools documentation, the bin directory of it shall be in 
> the system PATH, and very early in the PATH (first elements). Presently the 
> bin directory of the Rtools-MinGW is front.
> Fine but Ok for my daily C++ work I actually prefer that the regular 
> (non-Rtools) MinGW compiler is invoked, hence I would prefer putting that in 
> front. But then, of course, invoking g++ from R development would refer to 
> the regular MinGW compiler toolset. When I do R development, would you expect 
> it to cause problems if actually the regular MinGW (gcc 4.5) is invoked, and 
> not the version that came bundled with Rtools (4.2) ? Or is this something I 
> should better stay away from ?
> If not likely to work, what would you suggest to do instead ?

Follow the posting guide and update your R before posting ....

We do not support ancient versions of R, and it is very likely that R 
2.8.1 does not work correctly with gcc 4.5.2: there are 
incompatibilities in the argument passing.

> thanks and best,
> Thomas

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From thomasmang.ng at gmail.com  Mon Apr  4 12:34:19 2011
From: thomasmang.ng at gmail.com (Thomas Mang)
Date: Mon, 4 Apr 2011 12:34:19 +0200
Subject: [Rd] Rtools and MinGW
In-Reply-To: <alpine.LFD.2.02.1104041002020.32350@gannet.stats.ox.ac.uk>
References: <4D98CC34.5080802@gmail.com>
	<alpine.LFD.2.02.1104041002020.32350@gannet.stats.ox.ac.uk>
Message-ID: <inc6r9$qnl$1@dough.gmane.org>

On 04.04.2011 11:04, Prof Brian Ripley wrote:
> On Sun, 3 Apr 2011, Thomas Mang wrote:
>
>> Hi,
>>
>> I have R version 2.8.1 and Rtools 28 installed (as you might guess,
>> set up years ago). In Rtools the MinGW GCC 4.2 compiler toolset is
>> included.
>>
>> For my regular C/C++ programs I have also installed, separately, the
>> full MinGW bundle with the latest GCC 4.5 compiler tools. So I have
>> two g++ variants on the same machine.
>>
>> According to the Rtools documentation, the bin directory of it shall
>> be in the system PATH, and very early in the PATH (first elements).
>> Presently the bin directory of the Rtools-MinGW is front.
>> Fine but Ok for my daily C++ work I actually prefer that the regular
>> (non-Rtools) MinGW compiler is invoked, hence I would prefer putting
>> that in front. But then, of course, invoking g++ from R development
>> would refer to the regular MinGW compiler toolset. When I do R
>> development, would you expect it to cause problems if actually the
>> regular MinGW (gcc 4.5) is invoked, and not the version that came
>> bundled with Rtools (4.2) ? Or is this something I should better stay
>> away from ?
>> If not likely to work, what would you suggest to do instead ?
>
> Follow the posting guide and update your R before posting ....
>
> We do not support ancient versions of R, and it is very likely that R
> 2.8.1 does not work correctly with gcc 4.5.2: there are
> incompatibilities in the argument passing.

OK I can update but in general I think it's unlikely that the MinGW 
version bundled with Rtools will ever be the same as the regular MinGW 
version (even if just by update cycle delays).
Is there any other way to tell Rtools where to search for MinGW-bin 
except of setting the globally applicable PATH variable ? Some 
configuration file or so ?

thanks,
Thomas


From murdoch.duncan at gmail.com  Mon Apr  4 15:28:22 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 4 Apr 2011 09:28:22 -0400
Subject: [Rd] Rtools and MinGW
In-Reply-To: <inc6r9$qnl$1@dough.gmane.org>
References: <4D98CC34.5080802@gmail.com>	<alpine.LFD.2.02.1104041002020.32350@gannet.stats.ox.ac.uk>
	<inc6r9$qnl$1@dough.gmane.org>
Message-ID: <4D99C776.1050300@gmail.com>

On 04/04/2011 6:34 AM, Thomas Mang wrote:
> On 04.04.2011 11:04, Prof Brian Ripley wrote:
> >  On Sun, 3 Apr 2011, Thomas Mang wrote:
> >
> >>  Hi,
> >>
> >>  I have R version 2.8.1 and Rtools 28 installed (as you might guess,
> >>  set up years ago). In Rtools the MinGW GCC 4.2 compiler toolset is
> >>  included.
> >>
> >>  For my regular C/C++ programs I have also installed, separately, the
> >>  full MinGW bundle with the latest GCC 4.5 compiler tools. So I have
> >>  two g++ variants on the same machine.
> >>
> >>  According to the Rtools documentation, the bin directory of it shall
> >>  be in the system PATH, and very early in the PATH (first elements).
> >>  Presently the bin directory of the Rtools-MinGW is front.
> >>  Fine but Ok for my daily C++ work I actually prefer that the regular
> >>  (non-Rtools) MinGW compiler is invoked, hence I would prefer putting
> >>  that in front. But then, of course, invoking g++ from R development
> >>  would refer to the regular MinGW compiler toolset. When I do R
> >>  development, would you expect it to cause problems if actually the
> >>  regular MinGW (gcc 4.5) is invoked, and not the version that came
> >>  bundled with Rtools (4.2) ? Or is this something I should better stay
> >>  away from ?
> >>  If not likely to work, what would you suggest to do instead ?
> >
> >  Follow the posting guide and update your R before posting ....
> >
> >  We do not support ancient versions of R, and it is very likely that R
> >  2.8.1 does not work correctly with gcc 4.5.2: there are
> >  incompatibilities in the argument passing.
>
> OK I can update but in general I think it's unlikely that the MinGW
> version bundled with Rtools will ever be the same as the regular MinGW
> version (even if just by update cycle delays).
> Is there any other way to tell Rtools where to search for MinGW-bin
> except of setting the globally applicable PATH variable ? Some
> configuration file or so ?

Why not just keep two PATH variables, and put one in place before R 
builds, the other in place the rest of the time?

Duncan Murdoch


From ggrothendieck at gmail.com  Mon Apr  4 15:46:54 2011
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 4 Apr 2011 09:46:54 -0400
Subject: [Rd] Rtools and MinGW
In-Reply-To: <4D98CC34.5080802@gmail.com>
References: <4D98CC34.5080802@gmail.com>
Message-ID: <BANLkTinjFxw82YM2TtQM8BwAeW6qi2eDkg@mail.gmail.com>

On Sun, Apr 3, 2011 at 3:36 PM, Thomas Mang
<thomasmang.ng at googlemail.com> wrote:
> Hi,
>
> I have R version 2.8.1 and Rtools 28 installed (as you might guess, set up
> years ago). In Rtools the MinGW GCC 4.2 compiler toolset is included.
>
> For my regular C/C++ programs I have also installed, separately, the full
> MinGW bundle with the latest GCC 4.5 compiler tools. So I have two g++
> variants on the same machine.
>
> According to the Rtools documentation, the bin directory of it shall be in
> the system PATH, and very early in the PATH (first elements). Presently the
> bin directory of the Rtools-MinGW is front.
> Fine but Ok for my daily C++ work I actually prefer that the regular
> (non-Rtools) MinGW compiler is invoked, hence I would prefer putting that in
> front. But then, of course, invoking g++ from R development would refer to
> the regular MinGW compiler toolset. When I do R development, would you
> expect it to cause problems if actually the regular MinGW (gcc 4.5) is
> invoked, and not the version that came bundled with Rtools (4.2) ? Or is
> this something I should better stay away from ?
> If not likely to work, what would you suggest to do instead ?
>
> thanks and best,
> Thomas
>

If you use Rcmd.bat from http://batchfiles.googlecode.com to build
your packages then it will find Rtools using the registry rather than
the path so if your other processing uses the path you can be using
two different versions of Rtools transparently.

(Alternately, in the same collection there is rtools.bat which will
add the rtools bin directory to your path for the remainder of the
current console session only so other console sessions can be using
other versions of Rtools.)

Also both of these will look for an R_TOOLS environment variable and
use that instead of the registry if present so you could set that for
even further customization (although from your description you won't
likely need to do that).

You might need to use a back version of Rcmd.bat since your version of
R is pretty old but all back versions are still available.

-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From wdunlap at tibco.com  Mon Apr  4 17:54:19 2011
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 4 Apr 2011 08:54:19 -0700
Subject: [Rd] [[.data.frame oddity
Message-ID: <77EB52C6DD32BA4D87471DCD70C8D700041250DD@NA-PA-VBE03.na.tibco.com>

data.frame[[row,col]] unclasses its output.  Is that proper?

> d <- data.frame(num=1:4,
          fac=factor(letters[11:14],levels=letters[1:15]),
          date=as.Date("2011-04-01") + (0:3),
          lt=as.POSIXlt("2011-04-01") + (0:3)*1e5,
          pv=package_version(c("1.2-3", "4.5","6.7", "8.9-10")))
> d
  num fac       date                  lt     pv
1   1   k 2011-04-01 2011-04-01 00:00:00  1.2.3
2   2   l 2011-04-02 2011-04-02 03:46:40    4.5
3   3   m 2011-04-03 2011-04-03 07:33:20    6.7
4   4   n 2011-04-04 2011-04-04 11:20:00 8.9.10
> str(d)
'data.frame':   4 obs. of  5 variables:
 $ num : int  1 2 3 4
 $ fac : Factor w/ 15 levels "a","b","c","d",..: 11 12 13 14
 $ date:Class 'Date'  num [1:4] 15065 15066 15067 15068
 $ lt  : POSIXct, format: "2011-04-01 00:00:00" "2011-04-02 03:46:40"
...
 $ pv  :List of 4
  ..$ :Classes 'package_version', 'numeric_version'  hidden list of 1
  .. ..$ : int  1 2 3
  ..$ :Classes 'package_version', 'numeric_version'  hidden list of 1
  .. ..$ : int  4 5
  ..$ :Classes 'package_version', 'numeric_version'  hidden list of 1
  .. ..$ : int  6 7
  ..$ :Classes 'package_version', 'numeric_version'  hidden list of 1
  .. ..$ : int  8 9 10
  ..- attr(*, "class")= chr  "package_version" "numeric_version"

> d[[1,1]]
[1] 1
> d[[1,2]] # d[1,2] gives factor("k",levels=letters[1:15])
[1] 11
> d[[1,3]] # d[1,3] gives as.Date("2011-04-01")
[1] 15065
> d[[1,4]]  # d[1,4] gives as.POSIXct("2011-04-01")
[1] 1301641200
> d[[1,5]] # d[1,5] gives package_version("1.2.3")
[1] 1 2 3

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com 


From Greg.Snow at imail.org  Mon Apr  4 21:19:42 2011
From: Greg.Snow at imail.org (Greg Snow)
Date: Mon, 4 Apr 2011 13:19:42 -0600
Subject: [Rd] Use keep.source for function in package with lazy loading
Message-ID: <B37C0A15B8FB3C468B5BC7EBC7DA14CC63457AC07C@LP-EXMBVS10.CO.IHC.COM>

I have a function in one of my packages that I would like to print using the original source rather than the deparse of the function.  The package uses lazy loading and the help page for library (under keep.source) says that keep.source does not apply to packages that use lazy loading and that whether those functions keep the source depends on when they are installed.

This package is on R-forge and is being built there (and will eventually be used to submit the next version of the package to CRAN).

I am not sure what the help means by 'installed', I have set the options to keep the source to TRUE before calling install.package, but that does not seem to work.  

Is there a way to "strongly encourage" the source to be kept for this function (or the entire package)?

Thanks,

-- 
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at imail.org
801.408.8111


From ripley at stats.ox.ac.uk  Mon Apr  4 23:41:12 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 4 Apr 2011 22:41:12 +0100 (BST)
Subject: [Rd] Use keep.source for function in package with lazy loading
In-Reply-To: <B37C0A15B8FB3C468B5BC7EBC7DA14CC63457AC07C@LP-EXMBVS10.CO.IHC.COM>
References: <B37C0A15B8FB3C468B5BC7EBC7DA14CC63457AC07C@LP-EXMBVS10.CO.IHC.COM>
Message-ID: <alpine.LFD.2.02.1104042214300.1530@gannet.stats.ox.ac.uk>

On Mon, 4 Apr 2011, Greg Snow wrote:

> I have a function in one of my packages that I would like to print 
> using the original source rather than the deparse of the function. 
> The package uses lazy loading and the help page for library (under 
> keep.source) says that keep.source does not apply to packages that 
> use lazy loading and that whether those functions keep the source 
> depends on when they are installed.

Not quite: it is says it is 'determined when it is installed'.

For a package that does not use lazy loading, what is installed is a 
file of R code.  When library() loads such a package, it sources() the 
R code, and at that point has the option to keep the source or not 
(for that R session).

For a package which uses lazy loading, the source()ing happens when 
the package is installed: the objects created are then dumped into a 
database.  Whether the source attribute is retained at that point 
depends on the setting of the option "keep.source.pkgs". So if you can 
arrange to install the package with that option set to true, in 
principle (and in my experiments) the source attributes are retained.

The easiest way to do this would seem to be to set the environment 
variable R_KEEP_PKG_SOURCE to "yes" whilst installing the package.

> This package is on R-forge and is being built there (and will 
> eventually be used to submit the next version of the package to 
> CRAN).
>
> I am not sure what the help means by 'installed', I have set the 
> options to keep the source to TRUE before calling install.package, 
> but that does not seem to work.

I presume you mean keep.source.pkgs, not keep.source?  That needs to 
be set in the process which is installing the package: 
install.packages() calls R CMD INSTALL in a separate process.

> Is there a way to "strongly encourage" the source to be kept for 
> this function (or the entire package)?
>
> Thanks,
>
> -- 
> Gregory (Greg) L. Snow Ph.D.
> Statistical Data Center
> Intermountain Healthcare
> greg.snow at imail.org
> 801.408.8111

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From gavin.simpson at ucl.ac.uk  Tue Apr  5 13:33:06 2011
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Tue, 5 Apr 2011 12:33:06 +0100
Subject: [Rd] Inconsistency between rowMeans documentation and reality?
Message-ID: <1302003186.2870.7.camel@chrysothemis.geog.ucl.ac.uk>

Dear List,

I'm not even sure this is an issue or not, but ?rowMeans has:

Value:

     A numeric or complex array of suitable size, or a vector if the
     result is one-dimensional.  The ?dimnames? (or ?names? for a
     vector result) are taken from the original array.

     If there are no values in a range to be summed over (after
     removing missing values with ?na.rm = TRUE?), that component of
     the output is set to ?0? (?*Sums?) or ?NA? (?*Means?), consistent
     with ?sum? and ?mean?.

However the output of mean() and rowMeans() is not exactly the same when
all supplied values are missing.

> mean(NA, na.rm = TRUE)
[1] NaN
> mean(rep(NA, 5), na.rm = TRUE)
[1] NaN
> rowMeans(matrix(rep(NA, 5), ncol = 5), na.rm = TRUE)
[1] NA

So in one sense, the outputs are not consistent:

> is.nan(mean(rep(NA, 5), na.rm = TRUE))
[1] TRUE
> is.nan(rowMeans(matrix(rep(NA, 5), ncol = 5), na.rm = TRUE))
[1] FALSE

but in another they are:

> is.na(mean(rep(NA, 5), na.rm = TRUE))
[1] TRUE
> is.na(rowMeans(matrix(rep(NA, 5), ncol = 5), na.rm = TRUE))
[1] TRUE

I'm not familiar enough with the details to know if this even matters,
but wonder if something in the documentation needs a change or tweak to
clarify what is returned. As I say, in one sense the outputs are not
consistent.

> sessionInfo()
R version 2.13.0 beta (2011-04-04 r55298)
Platform: x86_64-unknown-linux-gnu (64-bit)

locale:
 [1] LC_CTYPE=en_GB.utf8       LC_NUMERIC=C             
 [3] LC_TIME=en_GB.utf8        LC_COLLATE=en_GB.utf8    
 [5] LC_MONETARY=C             LC_MESSAGES=en_GB.utf8   
 [7] LC_PAPER=en_GB.utf8       LC_NAME=C                
 [9] LC_ADDRESS=C              LC_TELEPHONE=C           
[11] LC_MEASUREMENT=en_GB.utf8 LC_IDENTIFICATION=C      

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods  
[7] base     

loaded via a namespace (and not attached):
[1] tools_2.13.0

Thanks,

Gavin
-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
 Dr. Gavin Simpson             [t] +44 (0)20 7679 0522
 ECRC, UCL Geography,          [f] +44 (0)20 7679 0565
 Pearson Building,             [e] gavin.simpsonATNOSPAMucl.ac.uk
 Gower Street, London          [w] http://www.ucl.ac.uk/~ucfagls/
 UK. WC1E 6BT.                 [w] http://www.freshwaters.org.uk
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%


From hadley at rice.edu  Tue Apr  5 16:31:19 2011
From: hadley at rice.edu (Hadley Wickham)
Date: Tue, 5 Apr 2011 09:31:19 -0500
Subject: [Rd] Bug in as.data.frame.POSIXct?
In-Reply-To: <AANLkTimtW4Tu-q06TYsh2NAUW_eiuVsnAY_xZUL5Gqgj@mail.gmail.com>
References: <AANLkTimtW4Tu-q06TYsh2NAUW_eiuVsnAY_xZUL5Gqgj@mail.gmail.com>
Message-ID: <BANLkTikqDb6Ub73VR7ngEgkYvzzzPW+9TA@mail.gmail.com>

Any comments on this? Otherwise I will just submit a bug report.
Hadley

On Thu, Mar 31, 2011 at 10:30 AM, Hadley Wickham <hadley at rice.edu> wrote:
>> a <- as.POSIXct(1:2, origin="2011-01-01")
>> dim(a) <- c(1, 2)
>> as.data.frame(a)
> ? ? ? ? ? ? ? ? ? ?a
> 1 2011-01-01 00:00:01
> 2 2011-01-01 00:00:02
>>
>> dim(a) <- c(2, 1)
>> as.data.frame(a)
> ? ? ? ? ? ? ? ? ? ?a
> 1 2011-01-01 00:00:01
> 2 2011-01-01 00:00:02
>
> I think this is because in as.data.frame.POSIXct we have
>
> ?nrows <- length(x)
>
> instead of
>
> ?nrows <- NROW(x)
>
> Hadley
>
>
> --
> Assistant Professor / Dobelman Family Junior Chair
> Department of Statistics / Rice University
> http://had.co.nz/
>



-- 
Assistant Professor / Dobelman Family Junior Chair
Department of Statistics / Rice University
http://had.co.nz/


From gb at stat.umu.se  Tue Apr  5 16:52:02 2011
From: gb at stat.umu.se (=?ISO-8859-1?Q?G=F6ran_Brostr=F6m?=)
Date: Tue, 5 Apr 2011 16:52:02 +0200
Subject: [Rd] Names of a data set in a package
Message-ID: <4D9B2C92.4000707@stat.umu.se>

For some reason I want to let one data set in a package be known under 
two different names.  Is that possible, and if so, how? I do not want to 
have two copies of the data set in the package.

Thanks,

G?ran
-- 
G?ran Brostr?m
Department of Statistics
Ume? University
SE-90187 Ume?, Sweden


From ggrothendieck at gmail.com  Tue Apr  5 18:25:19 2011
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 5 Apr 2011 12:25:19 -0400
Subject: [Rd] Names of a data set in a package
In-Reply-To: <4D9B2C92.4000707@stat.umu.se>
References: <4D9B2C92.4000707@stat.umu.se>
Message-ID: <BANLkTimfM4V4X=F2xgSs2VskdhrMmGQjPQ@mail.gmail.com>

2011/4/5 G?ran Brostr?m <gb at stat.umu.se>:
> For some reason I want to let one data set in a package be known under two
> different names. ?Is that possible, and if so, how? I do not want to have
> two copies of the data set in the package.
>

This will allow you to read the data frame under a different name but
you won't be able to modify it under the different name.  We make use
of the built in data frame BOD and create the alternate name BOD2:

> makeActiveBinding("BOD2", function() BOD, .GlobalEnv)
> BOD$Time
[1] 1 2 3 4 5 7
> BOD2$Time
[1] 1 2 3 4 5 7
> # changing BOD also changes BOD2
> BOD$Time[1] <- 99
> BOD2$Time
[1] 99  2  3  4  5  7


-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From Greg.Snow at imail.org  Tue Apr  5 18:39:13 2011
From: Greg.Snow at imail.org (Greg Snow)
Date: Tue, 5 Apr 2011 10:39:13 -0600
Subject: [Rd] Use keep.source for function in package with lazy loading
In-Reply-To: <alpine.LFD.2.02.1104042214300.1530@gannet.stats.ox.ac.uk>
References: <B37C0A15B8FB3C468B5BC7EBC7DA14CC63457AC07C@LP-EXMBVS10.CO.IHC.COM>
	<alpine.LFD.2.02.1104042214300.1530@gannet.stats.ox.ac.uk>
Message-ID: <B37C0A15B8FB3C468B5BC7EBC7DA14CC63457AC389@LP-EXMBVS10.CO.IHC.COM>

Prof. Ripley,

Thanks for the explanation.  I had set both keep.source and keep.source.packages to TRUE for my experiments, but had not realized that a new R process would be involved, so did not try the environmental variable approach.

>From what you say below, I don't think I am going to accomplish what I wanted, since I want the source to show for users other than myself and there does not seem to be a reasonable way to change the users environment before installing my package (that is getting a bit too big brother to even think about).  I was hoping that there might be some switch somewhere that I had missed that would say keep the source for this function even though the default is not to.  But, it does not look like there is anything like that, and it is not worth implementing just for my one little use.

Hmm, maybe I can set the source manually using .onAttach, I'll have to experiment some more.

Thanks,

-- 
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at imail.org
801.408.8111


> -----Original Message-----
> From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk]
> Sent: Monday, April 04, 2011 3:41 PM
> To: Greg Snow
> Cc: R-devel at r-project.org
> Subject: Re: [Rd] Use keep.source for function in package with lazy
> loading
> 
> On Mon, 4 Apr 2011, Greg Snow wrote:
> 
> > I have a function in one of my packages that I would like to print
> > using the original source rather than the deparse of the function.
> > The package uses lazy loading and the help page for library (under
> > keep.source) says that keep.source does not apply to packages that
> > use lazy loading and that whether those functions keep the source
> > depends on when they are installed.
> 
> Not quite: it is says it is 'determined when it is installed'.
> 
> For a package that does not use lazy loading, what is installed is a
> file of R code.  When library() loads such a package, it sources() the
> R code, and at that point has the option to keep the source or not
> (for that R session).
> 
> For a package which uses lazy loading, the source()ing happens when
> the package is installed: the objects created are then dumped into a
> database.  Whether the source attribute is retained at that point
> depends on the setting of the option "keep.source.pkgs". So if you can
> arrange to install the package with that option set to true, in
> principle (and in my experiments) the source attributes are retained.
> 
> The easiest way to do this would seem to be to set the environment
> variable R_KEEP_PKG_SOURCE to "yes" whilst installing the package.
> 
> > This package is on R-forge and is being built there (and will
> > eventually be used to submit the next version of the package to
> > CRAN).
> >
> > I am not sure what the help means by 'installed', I have set the
> > options to keep the source to TRUE before calling install.package,
> > but that does not seem to work.
> 
> I presume you mean keep.source.pkgs, not keep.source?  That needs to
> be set in the process which is installing the package:
> install.packages() calls R CMD INSTALL in a separate process.
> 
> > Is there a way to "strongly encourage" the source to be kept for
> > this function (or the entire package)?
> >
> > Thanks,
> >
> > --
> > Gregory (Greg) L. Snow Ph.D.
> > Statistical Data Center
> > Intermountain Healthcare
> > greg.snow at imail.org
> > 801.408.8111
> 
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From andre.zege at gmail.com  Tue Apr  5 18:47:23 2011
From: andre.zege at gmail.com (A Zege)
Date: Tue, 5 Apr 2011 11:47:23 -0500 (CDT)
Subject: [Rd] super basic questions about S4 classes
Message-ID: <1302022043304-3428591.post@n4.nabble.com>

Apologies for asking something that is probably super obvious, i just started
with S4 classes and i guess i am not finding documentation that layout the
grammar rules and give enough examples. Some questions i am having are these

1. I understand that main method of writing a member function is to write a
generic function and setMethod for this particular object. This, however,
presumes that there is "virtuality" for this function, i.e. it could be used
with other inherited classes . Truth is, many, if not most of my functions
don't have virtuality in mind. I want to write them inside classes to
achieve incapsulaton only -- use class member data without passing it as
parameters or making global to a bunch of functions and have some specific
class member functions that don't pollute a global namespace and can be
called only for a particular class. This is what i know how to do with
enclosures in R. Is there some obvious way of setting this environment local
to a class without writing generic functions that i am missing?

2. Is it possible to overload functions in other ways than having default
parameter values and prototypes?
For example, can i have  two constructors with completely different sets of
parameters?

3. Is there some good way to debug S4 classes? I am very fond of mtrace()
from debug package, but the simple set of commands i normally use doesn't
take me into class methods. 


Would appreciate any pointers on these..


--
View this message in context: http://r.789695.n4.nabble.com/super-basic-questions-about-S4-classes-tp3428591p3428591.html
Sent from the R devel mailing list archive at Nabble.com.


From mcarlson at fhcrc.org  Tue Apr  5 19:51:39 2011
From: mcarlson at fhcrc.org (Marc Carlson)
Date: Tue, 05 Apr 2011 10:51:39 -0700
Subject: [Rd] question about assignment warnings for replacement methods
Message-ID: <4D9B56AB.2020403@fhcrc.org>

Hi,

I have seen several packages that with the most recent version of R are 
giving a warning like this:

Assignments in \usage in documentation object 'marginalData-methods':
marginalData(object) = value

I assume that this is to prevent people from making assignments in their 
usage statements (which seems completely understandable).  But what 
about the case above?  This is a person who just wants to show the 
proper usage for a replacement method.  IOW they just want to write 
something that looks like what you actually do when you use a 
replacement method.  They just want to show users how to do something 
like this:

replacementMethod(object) <- newValue


So is that really something that should not be allowed in a usage 
statement?


   Marc


From murdoch.duncan at gmail.com  Tue Apr  5 20:15:55 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 05 Apr 2011 14:15:55 -0400
Subject: [Rd] question about assignment warnings for replacement methods
In-Reply-To: <4D9B56AB.2020403@fhcrc.org>
References: <4D9B56AB.2020403@fhcrc.org>
Message-ID: <4D9B5C5B.2020209@gmail.com>

On 05/04/2011 1:51 PM, Marc Carlson wrote:
> Hi,
>
> I have seen several packages that with the most recent version of R are
> giving a warning like this:
>
> Assignments in \usage in documentation object 'marginalData-methods':
> marginalData(object) = value
>
> I assume that this is to prevent people from making assignments in their
> usage statements (which seems completely understandable).  But what
> about the case above?  This is a person who just wants to show the
> proper usage for a replacement method.  IOW they just want to write
> something that looks like what you actually do when you use a
> replacement method.  They just want to show users how to do something
> like this:
>
> replacementMethod(object)<- newValue
>
>
> So is that really something that should not be allowed in a usage
> statement?

If replacementMethod was a replacement function, then

replacementMethod(object)<- newValue

is supposed to be fine.  But if it is an S3 method, it should be

\method{replacementMethod}{class}(object)<- newValue

and if it is an S4 method I think it should be

\S4method{replacementMethod}{signature_list}(object)<- newValue

(though the manual suggests using the S3 style, I'm not sure how literally to take it).

Duncan Murdoch


From gb at stat.umu.se  Tue Apr  5 20:50:00 2011
From: gb at stat.umu.se (=?iso-8859-1?Q?G=F6ran_Brostr=F6m?=)
Date: Tue, 5 Apr 2011 20:50:00 +0200
Subject: [Rd] Names of a data set in a package
In-Reply-To: <BANLkTimfM4V4X=F2xgSs2VskdhrMmGQjPQ@mail.gmail.com>
References: <4D9B2C92.4000707@stat.umu.se>
	<BANLkTimfM4V4X=F2xgSs2VskdhrMmGQjPQ@mail.gmail.com>
Message-ID: <211B9B55-CC70-4AC0-8DDE-98C808055921@stat.umu.se>


5 apr 2011 kl. 18.25 skrev Gabor Grothendieck:

> 2011/4/5 G?ran Brostr?m <gb at stat.umu.se>:
>> For some reason I want to let one data set in a package be known under two
>> different names.  Is that possible, and if so, how? I do not want to have
>> two copies of the data set in the package.
>> 
> 
> This will allow you to read the data frame under a different name but
> you won't be able to modify it under the different name.  We make use
> of the built in data frame BOD and create the alternate name BOD2:
> 
>> makeActiveBinding("BOD2", function() BOD, .GlobalEnv)
>> BOD$Time
> [1] 1 2 3 4 5 7
>> BOD2$Time
> [1] 1 2 3 4 5 7
>> # changing BOD also changes BOD2
>> BOD$Time[1] <- 99
>> BOD2$Time
> [1] 99  2  3  4  5  7
> 
Thanks Gabor, but where do I put this in my package? To clarify, I want

> data(B, package = "A")

and 

> data(C, package = "A")

refer to the same data set.

G?ran
> 
> -- 
> Statistics & Software Consulting
> GKX Group, GKX Associates Inc.
> tel: 1-877-GKX-GROUP
> email: ggrothendieck at gmail.com


From ggrothendieck at gmail.com  Tue Apr  5 21:01:26 2011
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 5 Apr 2011 15:01:26 -0400
Subject: [Rd] Names of a data set in a package
In-Reply-To: <211B9B55-CC70-4AC0-8DDE-98C808055921@stat.umu.se>
References: <4D9B2C92.4000707@stat.umu.se>
	<BANLkTimfM4V4X=F2xgSs2VskdhrMmGQjPQ@mail.gmail.com>
	<211B9B55-CC70-4AC0-8DDE-98C808055921@stat.umu.se>
Message-ID: <BANLkTi=bf2wpvhDKFSeukGFvTixW-CoLbA@mail.gmail.com>

2011/4/5 G?ran Brostr?m <gb at stat.umu.se>:
>
> 5 apr 2011 kl. 18.25 skrev Gabor Grothendieck:
>
>> 2011/4/5 G?ran Brostr?m <gb at stat.umu.se>:
>>> For some reason I want to let one data set in a package be known under two
>>> different names. ?Is that possible, and if so, how? I do not want to have
>>> two copies of the data set in the package.
>>>
>>
>> This will allow you to read the data frame under a different name but
>> you won't be able to modify it under the different name. ?We make use
>> of the built in data frame BOD and create the alternate name BOD2:
>>
>>> makeActiveBinding("BOD2", function() BOD, .GlobalEnv)
>>> BOD$Time
>> [1] 1 2 3 4 5 7
>>> BOD2$Time
>> [1] 1 2 3 4 5 7
>>> # changing BOD also changes BOD2
>>> BOD$Time[1] <- 99
>>> BOD2$Time
>> [1] 99 ?2 ?3 ?4 ?5 ?7
>>
> Thanks Gabor, but where do I put this in my package? To clarify, I want
>
>> data(B, package = "A")
>
> and
>
>> data(C, package = "A")
>
> refer to the same data set.
>

Implement your datasets as .R files.  See ?data and the source to the
quantreg package, say, as it uses .R files for its data.

-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From mcarlson at fhcrc.org  Tue Apr  5 23:10:33 2011
From: mcarlson at fhcrc.org (Marc Carlson)
Date: Tue, 05 Apr 2011 14:10:33 -0700
Subject: [Rd] question about assignment warnings for replacement methods
In-Reply-To: <4D9B5C5B.2020209@gmail.com>
References: <4D9B56AB.2020403@fhcrc.org> <4D9B5C5B.2020209@gmail.com>
Message-ID: <4D9B8549.20406@fhcrc.org>

Thank you for the clarifications Duncan.

   Marc


On 04/05/2011 11:15 AM, Duncan Murdoch wrote:
> On 05/04/2011 1:51 PM, Marc Carlson wrote:
>> Hi,
>>
>> I have seen several packages that with the most recent version of R are
>> giving a warning like this:
>>
>> Assignments in \usage in documentation object 'marginalData-methods':
>> marginalData(object) = value
>>
>> I assume that this is to prevent people from making assignments in their
>> usage statements (which seems completely understandable).  But what
>> about the case above?  This is a person who just wants to show the
>> proper usage for a replacement method.  IOW they just want to write
>> something that looks like what you actually do when you use a
>> replacement method.  They just want to show users how to do something
>> like this:
>>
>> replacementMethod(object)<- newValue
>>
>>
>> So is that really something that should not be allowed in a usage
>> statement?
>
> If replacementMethod was a replacement function, then
>
> replacementMethod(object)<- newValue
>
> is supposed to be fine.  But if it is an S3 method, it should be
>
> \method{replacementMethod}{class}(object)<- newValue
>
> and if it is an S4 method I think it should be
>
> \S4method{replacementMethod}{signature_list}(object)<- newValue
>
> (though the manual suggests using the S3 style, I'm not sure how 
> literally to take it).
>
> Duncan Murdoch
>
>


From spencer.graves at structuremonitoring.com  Wed Apr  6 00:22:54 2011
From: spencer.graves at structuremonitoring.com (Spencer Graves)
Date: Tue, 05 Apr 2011 15:22:54 -0700
Subject: [Rd] Rtools questions
Message-ID: <4D9B963E.9070501@structuremonitoring.com>

Hello:


       1.  How can I tell when the development version of Rtools has 
changed?  For the past few years, I've installed the development version 
of R tools with each new release of R.  I encountered problems with this 
a few days ago, so I rolled back to Rtools212.exe.  Unfortunately, I 
seem to have more problems with that version.  My latest install was 
under Windows 7 Home Edition.  My previous problems were on Vista, but I 
also have access to Fedora 13 Linux.


       2.  "R CMD check" ends with the following:


* checking examples ... OK
* checking PDF version of manual ... WARNING
LaTeX errors when creating PDF version.
This typically indicates Rd problems.
* checking PDF version of manual without hyperrefs or index ... ERROR
Re-running with no redirection of stdout/stderr.
Hmm ... looks like a package
Error in texi2dvi("Rd2.tex", pdf = (out_ext == "pdf"), quiet = FALSE,  :
   unable to run 'pdflatex' on 'Rd2.tex'
Error in running tools::texi2dvi
You may want to clean up by 'rm -rf 
C:/Users/sgraves/AppData/Local/Temp/Rtmpr6z3
r6/Rd2pdf55b96c9a'


       This is using Rtools213, downloaded April 4 from 
"www.murdoch-sutherland.com/Rtools" with R installed as follows:


> sessionInfo()
R version 2.12.2 (2011-02-25)
Platform: x86_64-pc-mingw32/x64 (64-bit)

locale:
[1] LC_COLLATE=English_United States.1252
[2] LC_CTYPE=English_United States.1252
[3] LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C
[5] LC_TIME=English_United States.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base



       Thanks,
       Spencer


-- 
Spencer Graves, PE, PhD
President and Chief Operating Officer
Structure Inspection and Monitoring, Inc.
751 Emerson Ct.
San Jos?, CA 95126
ph:  408-655-4567


From gb at stat.umu.se  Wed Apr  6 00:23:01 2011
From: gb at stat.umu.se (=?iso-8859-1?Q?G=F6ran_Brostr=F6m?=)
Date: Wed, 6 Apr 2011 00:23:01 +0200
Subject: [Rd] Names of a data set in a package
In-Reply-To: <BANLkTi=bf2wpvhDKFSeukGFvTixW-CoLbA@mail.gmail.com>
References: <4D9B2C92.4000707@stat.umu.se>
	<BANLkTimfM4V4X=F2xgSs2VskdhrMmGQjPQ@mail.gmail.com>
	<211B9B55-CC70-4AC0-8DDE-98C808055921@stat.umu.se>
	<BANLkTi=bf2wpvhDKFSeukGFvTixW-CoLbA@mail.gmail.com>
Message-ID: <0F12BA3D-89A0-441A-95CB-9B20D2EA529E@stat.umu.se>


5 apr 2011 kl. 21.01 skrev Gabor Grothendieck:

> 2011/4/5 G?ran Brostr?m <gb at stat.umu.se>:
>> 
>> 5 apr 2011 kl. 18.25 skrev Gabor Grothendieck:
>> 
>>> 2011/4/5 G?ran Brostr?m <gb at stat.umu.se>:
>>>> For some reason I want to let one data set in a package be known under two
>>>> different names.  Is that possible, and if so, how? I do not want to have
>>>> two copies of the data set in the package.
>>>> 
>>> 
>>> This will allow you to read the data frame under a different name but
>>> you won't be able to modify it under the different name.  We make use
>>> of the built in data frame BOD and create the alternate name BOD2:
>>> 
>>>> makeActiveBinding("BOD2", function() BOD, .GlobalEnv)
>>>> BOD$Time
>>> [1] 1 2 3 4 5 7
>>>> BOD2$Time
>>> [1] 1 2 3 4 5 7
>>>> # changing BOD also changes BOD2
>>>> BOD$Time[1] <- 99
>>>> BOD2$Time
>>> [1] 99  2  3  4  5  7
>>> 
>> Thanks Gabor, but where do I put this in my package? To clarify, I want
>> 
>>> data(B, package = "A")
>> 
>> and
>> 
>>> data(C, package = "A")
>> 
>> refer to the same data set.
>> 
> 
> Implement your datasets as .R files.  See ?data and the source to the
> quantreg package, say, as it uses .R files for its data.

Gabor, thanks again, I got it! Note though that quantreg nowadays uses .rda files for its data. But in an old version I found the way to do it.

G?ran 
> 
> -- 
> Statistics & Software Consulting
> GKX Group, GKX Associates Inc.
> tel: 1-877-GKX-GROUP
> email: ggrothendieck at gmail.com


From simon.urbanek at r-project.org  Wed Apr  6 00:29:57 2011
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Tue, 5 Apr 2011 18:29:57 -0400
Subject: [Rd] Rtools questions
In-Reply-To: <4D9B963E.9070501@structuremonitoring.com>
References: <4D9B963E.9070501@structuremonitoring.com>
Message-ID: <A6F8AA43-8986-4BB6-9899-504ECA8FB34F@r-project.org>

Rtools don't provide TeX - that's entirely up to you - so I suspect it may not have anything to do with the Rtools version but rather your TeX installation...
Cheers,
Simon

On Apr 5, 2011, at 6:22 PM, Spencer Graves wrote:

> Hello:
> 
> 
>      1.  How can I tell when the development version of Rtools has changed?  For the past few years, I've installed the development version of R tools with each new release of R.  I encountered problems with this a few days ago, so I rolled back to Rtools212.exe.  Unfortunately, I seem to have more problems with that version.  My latest install was under Windows 7 Home Edition.  My previous problems were on Vista, but I also have access to Fedora 13 Linux.
> 
> 
>      2.  "R CMD check" ends with the following:
> 
> 
> * checking examples ... OK
> * checking PDF version of manual ... WARNING
> LaTeX errors when creating PDF version.
> This typically indicates Rd problems.
> * checking PDF version of manual without hyperrefs or index ... ERROR
> Re-running with no redirection of stdout/stderr.
> Hmm ... looks like a package
> Error in texi2dvi("Rd2.tex", pdf = (out_ext == "pdf"), quiet = FALSE,  :
>  unable to run 'pdflatex' on 'Rd2.tex'
> Error in running tools::texi2dvi
> You may want to clean up by 'rm -rf C:/Users/sgraves/AppData/Local/Temp/Rtmpr6z3
> r6/Rd2pdf55b96c9a'
> 
> 
>      This is using Rtools213, downloaded April 4 from "www.murdoch-sutherland.com/Rtools" with R installed as follows:
> 
> 
>> sessionInfo()
> R version 2.12.2 (2011-02-25)
> Platform: x86_64-pc-mingw32/x64 (64-bit)
> 
> locale:
> [1] LC_COLLATE=English_United States.1252
> [2] LC_CTYPE=English_United States.1252
> [3] LC_MONETARY=English_United States.1252
> [4] LC_NUMERIC=C
> [5] LC_TIME=English_United States.1252
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> 
> 
>      Thanks,
>      Spencer
> 
> 
> -- 
> Spencer Graves, PE, PhD
> President and Chief Operating Officer
> Structure Inspection and Monitoring, Inc.
> 751 Emerson Ct.
> San Jos?, CA 95126
> ph:  408-655-4567
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From murdoch.duncan at gmail.com  Wed Apr  6 00:44:17 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 05 Apr 2011 18:44:17 -0400
Subject: [Rd] Rtools questions
In-Reply-To: <4D9B963E.9070501@structuremonitoring.com>
References: <4D9B963E.9070501@structuremonitoring.com>
Message-ID: <4D9B9B41.5070401@gmail.com>

On 11-04-05 6:22 PM, Spencer Graves wrote:
> Hello:
>
>
>         1.  How can I tell when the development version of Rtools has
> changed?

I don't make announcements of the changes, you just need to check the 
web site.  There are online tools that can do this for you 
automatically, but I don't know which one to recommend.  Google suggests 
lots of them.


  For the past few years, I've installed the development version
> of R tools with each new release of R.  I encountered problems with this
> a few days ago, so I rolled back to Rtools212.exe.  Unfortunately, I
> seem to have more problems with that version.  My latest install was
> under Windows 7 Home Edition.  My previous problems were on Vista, but I
> also have access to Fedora 13 Linux.

I know that Windows 7 64 bit has problems with Rtools.  Brian Ripley has 
had some luck using the tools (the bin directory) and Cygwin DLLs from 
last summer, along with the current compilers.  I'm reluctant to back 
out the new versions, because I use Cygwin for other things (including 
OpenSSH) and don't want to get locked out of updates.

I haven't heard of problems with other Windows 7 versions, but I haven't 
tried them.

>
>
>         2.  "R CMD check" ends with the following:
>
>
> * checking examples ... OK
> * checking PDF version of manual ... WARNING
> LaTeX errors when creating PDF version.
> This typically indicates Rd problems.
> * checking PDF version of manual without hyperrefs or index ... ERROR
> Re-running with no redirection of stdout/stderr.
> Hmm ... looks like a package
> Error in texi2dvi("Rd2.tex", pdf = (out_ext == "pdf"), quiet = FALSE,  :
>     unable to run 'pdflatex' on 'Rd2.tex'
> Error in running tools::texi2dvi
> You may want to clean up by 'rm -rf
> C:/Users/sgraves/AppData/Local/Temp/Rtmpr6z3
> r6/Rd2pdf55b96c9a'
>
>
>         This is using Rtools213, downloaded April 4 from
> "www.murdoch-sutherland.com/Rtools" with R installed as follows:
>
>
>> sessionInfo()
> R version 2.12.2 (2011-02-25)
> Platform: x86_64-pc-mingw32/x64 (64-bit)
>
> locale:
> [1] LC_COLLATE=English_United States.1252
> [2] LC_CTYPE=English_United States.1252
> [3] LC_MONETARY=English_United States.1252
> [4] LC_NUMERIC=C
> [5] LC_TIME=English_United States.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base


Do you have pdflatex?  It's not part of Rtools, it's part of LaTeX, as 
described in Rtools.txt.

Duncan Murdoch


From hb at biostat.ucsf.edu  Wed Apr  6 01:51:56 2011
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Tue, 5 Apr 2011 16:51:56 -0700
Subject: [Rd] Rtools questions
In-Reply-To: <4D9B9B41.5070401@gmail.com>
References: <4D9B963E.9070501@structuremonitoring.com>
	<4D9B9B41.5070401@gmail.com>
Message-ID: <BANLkTi=tnhAEqOtun=yVUD=fp0KOaatWQg@mail.gmail.com>

On Tue, Apr 5, 2011 at 3:44 PM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> On 11-04-05 6:22 PM, Spencer Graves wrote:
>>
>> Hello:
>>
>>
>> ? ? ? ?1. ?How can I tell when the development version of Rtools has
>> changed?
>
> I don't make announcements of the changes, you just need to check the web
> site. ?There are online tools that can do this for you automatically, but I
> don't know which one to recommend. ?Google suggests lots of them.

I also asked myself this before and I must admit it took me a while to
interpret the contents of the webpage.  There are multiple sections,
e.g. 'Changes since R 2.12.2', 'Changes since R 2.11.1', 'Changes
since R 2.11.0', and so on.  Then within each section there are some
dates mentioned.  Given my current R version (say R 2.13.0 beta) and
Rtools (Rtools213.exe), it not fully clear to me which section to look
at, e.g. 'Changes since R 2.12.2'?  It might be more clear if there
instead the sections would be 'Changes in Rtools213', 'Changes in
Rtools212' and so on, and within each maybe list updates by
dates/version.  More like a NEWS file.  Then it would be easier to see
if there is an updated available or not.  Even a NEWS file only
available as part of the installation will help decide whether the
version you have installed differ from the one available online.
Something like the following:

== Changes in Rtools213 ==

[...]


== Changes in Rtools212 ==

2011-03-25:
- Rtools 2.12 has been frozen.
- We have updated all of the tools to current Cygwin versions as of
March 25, 2011. We added the "du" utility from Cygwin. We have dropped
Vanilla Perl. The libjpeg version has been updated to 8c, and libpng
has been updated to 1.5.1.

2010-10-18: [v2.12.0.1892] <== Is this an Rtools version?!?
- Prior to October 18, 2010, builds of Rtools212.exe did not correctly
install the "extras" required to build R. Version 2.12.0.1892 or later
should fix this.
- We have now updated all of the tools to current Cygwin versions, and
have updated the compilers, and included the 64 bit compilers into
Rtools. See Prof. Ripley's page for the details.
- Perl is rarely needed in R since R 2.12.0, so it is by default not installed.

2010-??-??:
- The 32 bit version of R-devel (to become R 2.12.0 in fall, 2010)
will be built with gcc 4.5.x, so Rtools212 contains a completely new
MinGW toolchain based on gcc 4.5.0.

== Changes in Rtools211 ==

[...]


Just a suggestion ...and thanks for providing Rtools!

/Henrik

>
>
> ?For the past few years, I've installed the development version
>>
>> of R tools with each new release of R. ?I encountered problems with this
>> a few days ago, so I rolled back to Rtools212.exe. ?Unfortunately, I
>> seem to have more problems with that version. ?My latest install was
>> under Windows 7 Home Edition. ?My previous problems were on Vista, but I
>> also have access to Fedora 13 Linux.
>
> I know that Windows 7 64 bit has problems with Rtools. ?Brian Ripley has had
> some luck using the tools (the bin directory) and Cygwin DLLs from last
> summer, along with the current compilers. ?I'm reluctant to back out the new
> versions, because I use Cygwin for other things (including OpenSSH) and
> don't want to get locked out of updates.
>
> I haven't heard of problems with other Windows 7 versions, but I haven't
> tried them.
>
>>
>>
>> ? ? ? ?2. ?"R CMD check" ends with the following:
>>
>>
>> * checking examples ... OK
>> * checking PDF version of manual ... WARNING
>> LaTeX errors when creating PDF version.
>> This typically indicates Rd problems.
>> * checking PDF version of manual without hyperrefs or index ... ERROR
>> Re-running with no redirection of stdout/stderr.
>> Hmm ... looks like a package
>> Error in texi2dvi("Rd2.tex", pdf = (out_ext == "pdf"), quiet = FALSE, ?:
>> ? ?unable to run 'pdflatex' on 'Rd2.tex'
>> Error in running tools::texi2dvi
>> You may want to clean up by 'rm -rf
>> C:/Users/sgraves/AppData/Local/Temp/Rtmpr6z3
>> r6/Rd2pdf55b96c9a'
>>
>>
>> ? ? ? ?This is using Rtools213, downloaded April 4 from
>> "www.murdoch-sutherland.com/Rtools" with R installed as follows:
>>
>>
>>> sessionInfo()
>>
>> R version 2.12.2 (2011-02-25)
>> Platform: x86_64-pc-mingw32/x64 (64-bit)
>>
>> locale:
>> [1] LC_COLLATE=English_United States.1252
>> [2] LC_CTYPE=English_United States.1252
>> [3] LC_MONETARY=English_United States.1252
>> [4] LC_NUMERIC=C
>> [5] LC_TIME=English_United States.1252
>>
>> attached base packages:
>> [1] stats ? ? graphics ?grDevices utils ? ? datasets ?methods ? base
>
>
> Do you have pdflatex? ?It's not part of Rtools, it's part of LaTeX, as
> described in Rtools.txt.
>
> Duncan Murdoch
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From D.Strbenac at garvan.org.au  Wed Apr  6 02:00:08 2011
From: D.Strbenac at garvan.org.au (Dario Strbenac)
Date: Wed,  6 Apr 2011 10:00:08 +1000 (EST)
Subject: [Rd] R CMD check for 2.13 rc
Message-ID: <20110406100008.BLL11522@gimr.garvan.unsw.edu.au>

Hi,

I have a couple of new errors in our package when I check it on R 2.13-rc (r55310). The first one that's mystifying me is

* checking R code for possible problems ... NOTE
Error : object normalizePath is not exported by 'namespace:utils'
Error : object normalizePath is not exported by 'namespace:utils'

Firstly, it's strange to see NOTE and Error being used interchangeably here. The package is being developed by a couple of us, so I checked that there were no calls to normalizePath in any of our code, and there aren't:

darstr at clark-lab:~/Repitools_github/pkg$ grep -r normalizePath .
./Repitools.Rcheck/00check.log:Error : object normalizePath is not exported by 'namespace:utils'
./Repitools.Rcheck/00check.log:Error : object normalizePath is not exported by 'namespace:utils'
./Repitools.Rcheck/tests/tests.Rout.fail:Error : object 'normlizePath' is not exported by 'namespace:utils'

I haven't got a clue where to look next.

My second concern is that I have used the code:

setOldClass("AffymetrixCelSet")

to make an S3 class be S4 dispatchable on. But R 2.13 wants me to document this class that I don't own:

* checking for missing documentation entries ... WARNING
Undocumented S4 classes:
  AffymetrixCelSet

Is this truly necessary ?

--------------------------------------
Dario Strbenac
Research Assistant
Cancer Epigenetics
Garvan Institute of Medical Research
Darlinghurst NSW 2010
Australia


From ggrothendieck at gmail.com  Wed Apr  6 02:01:23 2011
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 5 Apr 2011 20:01:23 -0400
Subject: [Rd] Rtools questions
In-Reply-To: <BANLkTi=tnhAEqOtun=yVUD=fp0KOaatWQg@mail.gmail.com>
References: <4D9B963E.9070501@structuremonitoring.com>
	<4D9B9B41.5070401@gmail.com>
	<BANLkTi=tnhAEqOtun=yVUD=fp0KOaatWQg@mail.gmail.com>
Message-ID: <BANLkTikP9mQ_22q+77pLeWBedbfbre_3PQ@mail.gmail.com>

On Tue, Apr 5, 2011 at 7:51 PM, Henrik Bengtsson <hb at biostat.ucsf.edu> wrote:
> On Tue, Apr 5, 2011 at 3:44 PM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>> On 11-04-05 6:22 PM, Spencer Graves wrote:
>>>
>>> Hello:
>>>
>>>
>>> ? ? ? ?1. ?How can I tell when the development version of Rtools has
>>> changed?
>>
>> I don't make announcements of the changes, you just need to check the web
>> site. ?There are online tools that can do this for you automatically, but I
>> don't know which one to recommend. ?Google suggests lots of them.
>
> I also asked myself this before and I must admit it took me a while to
> interpret the contents of the webpage. ?There are multiple sections,
> e.g. 'Changes since R 2.12.2', 'Changes since R 2.11.1', 'Changes
> since R 2.11.0', and so on. ?Then within each section there are some
> dates mentioned. ?Given my current R version (say R 2.13.0 beta) and
> Rtools (Rtools213.exe), it not fully clear to me which section to look
> at, e.g. 'Changes since R 2.12.2'? ?It might be more clear if there
> instead the sections would be 'Changes in Rtools213', 'Changes in
> Rtools212' and so on, and within each maybe list updates by
> dates/version. ?More like a NEWS file. ?Then it would be easier to see
> if there is an updated available or not. ?Even a NEWS file only
> available as part of the installation will help decide whether the
> version you have installed differ from the one available online.
> Something like the following:
>
> == Changes in Rtools213 ==
>
> [...]
>
>
> == Changes in Rtools212 ==
>
> 2011-03-25:
> - Rtools 2.12 has been frozen.
> - We have updated all of the tools to current Cygwin versions as of
> March 25, 2011. We added the "du" utility from Cygwin. We have dropped
> Vanilla Perl. The libjpeg version has been updated to 8c, and libpng
> has been updated to 1.5.1.
>
> 2010-10-18: [v2.12.0.1892] <== Is this an Rtools version?!?
> - Prior to October 18, 2010, builds of Rtools212.exe did not correctly
> install the "extras" required to build R. Version 2.12.0.1892 or later
> should fix this.
> - We have now updated all of the tools to current Cygwin versions, and
> have updated the compilers, and included the 64 bit compilers into
> Rtools. See Prof. Ripley's page for the details.
> - Perl is rarely needed in R since R 2.12.0, so it is by default not installed.
>
> 2010-??-??:
> - The 32 bit version of R-devel (to become R 2.12.0 in fall, 2010)
> will be built with gcc 4.5.x, so Rtools212 contains a completely new
> MinGW toolchain based on gcc 4.5.0.
>
> == Changes in Rtools211 ==
>
> [...]
>
>
> Just a suggestion ...and thanks for providing Rtools!
>
> /Henrik

If a NEWS file were included in the Rtools distribution itself (and
not just on the web site) it would be helpful since its not always
clear which version you have on your system in the first place.

-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From hb at biostat.ucsf.edu  Wed Apr  6 02:21:55 2011
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Tue, 5 Apr 2011 17:21:55 -0700
Subject: [Rd] R CMD check for 2.13 rc
In-Reply-To: <20110406100008.BLL11522@gimr.garvan.unsw.edu.au>
References: <20110406100008.BLL11522@gimr.garvan.unsw.edu.au>
Message-ID: <BANLkTimjpYPE+Gd2XQJMuj7uX6Eb8SuE1Q@mail.gmail.com>

I think normalizePath() has been moved to 'base' very++ recently.  /H

On Tue, Apr 5, 2011 at 5:00 PM, Dario Strbenac <D.Strbenac at garvan.org.au> wrote:
> Hi,
>
> I have a couple of new errors in our package when I check it on R 2.13-rc (r55310). The first one that's mystifying me is
>
> * checking R code for possible problems ... NOTE
> Error : object normalizePath is not exported by 'namespace:utils'
> Error : object normalizePath is not exported by 'namespace:utils'
>
> Firstly, it's strange to see NOTE and Error being used interchangeably here. The package is being developed by a couple of us, so I checked that there were no calls to normalizePath in any of our code, and there aren't:
>
> darstr at clark-lab:~/Repitools_github/pkg$ grep -r normalizePath .
> ./Repitools.Rcheck/00check.log:Error : object normalizePath is not exported by 'namespace:utils'
> ./Repitools.Rcheck/00check.log:Error : object normalizePath is not exported by 'namespace:utils'
> ./Repitools.Rcheck/tests/tests.Rout.fail:Error : object 'normlizePath' is not exported by 'namespace:utils'
>
> I haven't got a clue where to look next.
>
> My second concern is that I have used the code:
>
> setOldClass("AffymetrixCelSet")
>
> to make an S3 class be S4 dispatchable on. But R 2.13 wants me to document this class that I don't own:
>
> * checking for missing documentation entries ... WARNING
> Undocumented S4 classes:
> ?AffymetrixCelSet
>
> Is this truly necessary ?
>
> --------------------------------------
> Dario Strbenac
> Research Assistant
> Cancer Epigenetics
> Garvan Institute of Medical Research
> Darlinghurst NSW 2010
> Australia
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From spencer.graves at structuremonitoring.com  Wed Apr  6 03:00:04 2011
From: spencer.graves at structuremonitoring.com (Spencer Graves)
Date: Tue, 05 Apr 2011 18:00:04 -0700
Subject: [Rd] Rtools questions
In-Reply-To: <BANLkTikP9mQ_22q+77pLeWBedbfbre_3PQ@mail.gmail.com>
References: <4D9B963E.9070501@structuremonitoring.com>	<4D9B9B41.5070401@gmail.com>	<BANLkTi=tnhAEqOtun=yVUD=fp0KOaatWQg@mail.gmail.com>
	<BANLkTikP9mQ_22q+77pLeWBedbfbre_3PQ@mail.gmail.com>
Message-ID: <4D9BBB14.6030200@structuremonitoring.com>

On 4/5/2011 5:01 PM, Gabor Grothendieck wrote:
> On Tue, Apr 5, 2011 at 7:51 PM, Henrik Bengtsson<hb at biostat.ucsf.edu>  wrote:
>> On Tue, Apr 5, 2011 at 3:44 PM, Duncan Murdoch<murdoch.duncan at gmail.com>  wrote:
>>> On 11-04-05 6:22 PM, Spencer Graves wrote:
>>>> Hello:
>>>>
>>>>
>>>>         1.  How can I tell when the development version of Rtools has
>>>> changed?
>>> I don't make announcements of the changes, you just need to check the web
>>> site.  There are online tools that can do this for you automatically, but I
>>> don't know which one to recommend.  Google suggests lots of them.
>> I also asked myself this before and I must admit it took me a while to
>> interpret the contents of the webpage.  There are multiple sections,
>> e.g. 'Changes since R 2.12.2', 'Changes since R 2.11.1', 'Changes
>> since R 2.11.0', and so on.  Then within each section there are some
>> dates mentioned.  Given my current R version (say R 2.13.0 beta) and
>> Rtools (Rtools213.exe), it not fully clear to me which section to look
>> at, e.g. 'Changes since R 2.12.2'?  It might be more clear if there
>> instead the sections would be 'Changes in Rtools213', 'Changes in
>> Rtools212' and so on, and within each maybe list updates by
>> dates/version.  More like a NEWS file.  Then it would be easier to see
>> if there is an updated available or not.  Even a NEWS file only
>> available as part of the installation will help decide whether the
>> version you have installed differ from the one available online.
>> Something like the following:
>>
>> == Changes in Rtools213 ==
>>
>> [...]
>>
>>
>> == Changes in Rtools212 ==
>>
>> 2011-03-25:
>> - Rtools 2.12 has been frozen.
>> - We have updated all of the tools to current Cygwin versions as of
>> March 25, 2011. We added the "du" utility from Cygwin. We have dropped
>> Vanilla Perl. The libjpeg version has been updated to 8c, and libpng
>> has been updated to 1.5.1.
>>
>> 2010-10-18: [v2.12.0.1892]<== Is this an Rtools version?!?
>> - Prior to October 18, 2010, builds of Rtools212.exe did not correctly
>> install the "extras" required to build R. Version 2.12.0.1892 or later
>> should fix this.
>> - We have now updated all of the tools to current Cygwin versions, and
>> have updated the compilers, and included the 64 bit compilers into
>> Rtools. See Prof. Ripley's page for the details.
>> - Perl is rarely needed in R since R 2.12.0, so it is by default not installed.
>>
>> 2010-??-??:
>> - The 32 bit version of R-devel (to become R 2.12.0 in fall, 2010)
>> will be built with gcc 4.5.x, so Rtools212 contains a completely new
>> MinGW toolchain based on gcc 4.5.0.
>>
>> == Changes in Rtools211 ==
>>
>> [...]
>>
>>
>> Just a suggestion ...and thanks for providing Rtools!
>>
>> /Henrik
> If a NEWS file were included in the Rtools distribution itself (and
> not just on the web site) it would be helpful since its not always
> clear which version you have on your system in the first place.

       However, adding a NEWS file increases the labor, and I'd be happy 
letting Duncan and others continue doing what they do without asking 
them to take the time to tell the rest of us what they did.


       Something simpler would suffice for my needs, e.g., a revision 
number in the name of the download file, like Rtools213.5107.exe for SVN 
revision number 5107.  Windows 7 gives me the date my copy was 
downloaded, not the date of the last patch.  On March 31, I downloaded 
and installed basic-miktex-2.9.3972.exe from 
"http://miktex.org/2.9/setup".  Today, I downloaded
basic-miktex-2.9.4106.exe and basic-miktex-2.9.4106-x64.exe.  From 
comparing names, I inferred (a) the first was a newer version of what I 
had previously installed, and (b) that was 32 bit and the other is 64 
bit.  I installed the latter, and the problem with pdflatex disappeared.


       Spencer

-- 
Spencer Graves, PE, PhD
President and Chief Operating Officer
Structure Inspection and Monitoring, Inc.
751 Emerson Ct.
San Jos?, CA 95126
ph:  408-655-4567


From ggrothendieck at gmail.com  Wed Apr  6 03:03:13 2011
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 5 Apr 2011 21:03:13 -0400
Subject: [Rd] Rtools questions
In-Reply-To: <4D9BBACE.2070604@prodsyse.com>
References: <4D9B963E.9070501@structuremonitoring.com>
	<4D9B9B41.5070401@gmail.com>
	<BANLkTi=tnhAEqOtun=yVUD=fp0KOaatWQg@mail.gmail.com>
	<BANLkTikP9mQ_22q+77pLeWBedbfbre_3PQ@mail.gmail.com>
	<4D9BBACE.2070604@prodsyse.com>
Message-ID: <BANLkTikjXqMB8nikJgCR2cKETG7+-sCJ6w@mail.gmail.com>

On Tue, Apr 5, 2011 at 8:58 PM, Spencer Graves
<spencer.graves at prodsyse.com> wrote:
> On 4/5/2011 5:01 PM, Gabor Grothendieck wrote:
>>
>> On Tue, Apr 5, 2011 at 7:51 PM, Henrik Bengtsson<hb at biostat.ucsf.edu>
>> ?wrote:
>>>
>>> On Tue, Apr 5, 2011 at 3:44 PM, Duncan Murdoch<murdoch.duncan at gmail.com>
>>> ?wrote:
>>>>
>>>> On 11-04-05 6:22 PM, Spencer Graves wrote:
>>>>>
>>>>> Hello:
>>>>>
>>>>>
>>>>> ? ? ? ?1. ?How can I tell when the development version of Rtools has
>>>>> changed?
>>>>
>>>> I don't make announcements of the changes, you just need to check the
>>>> web
>>>> site. ?There are online tools that can do this for you automatically,
>>>> but I
>>>> don't know which one to recommend. ?Google suggests lots of them.
>>>
>>> I also asked myself this before and I must admit it took me a while to
>>> interpret the contents of the webpage. ?There are multiple sections,
>>> e.g. 'Changes since R 2.12.2', 'Changes since R 2.11.1', 'Changes
>>> since R 2.11.0', and so on. ?Then within each section there are some
>>> dates mentioned. ?Given my current R version (say R 2.13.0 beta) and
>>> Rtools (Rtools213.exe), it not fully clear to me which section to look
>>> at, e.g. 'Changes since R 2.12.2'? ?It might be more clear if there
>>> instead the sections would be 'Changes in Rtools213', 'Changes in
>>> Rtools212' and so on, and within each maybe list updates by
>>> dates/version. ?More like a NEWS file. ?Then it would be easier to see
>>> if there is an updated available or not. ?Even a NEWS file only
>>> available as part of the installation will help decide whether the
>>> version you have installed differ from the one available online.
>>> Something like the following:
>>>
>>> == Changes in Rtools213 ==
>>>
>>> [...]
>>>
>>>
>>> == Changes in Rtools212 ==
>>>
>>> 2011-03-25:
>>> - Rtools 2.12 has been frozen.
>>> - We have updated all of the tools to current Cygwin versions as of
>>> March 25, 2011. We added the "du" utility from Cygwin. We have dropped
>>> Vanilla Perl. The libjpeg version has been updated to 8c, and libpng
>>> has been updated to 1.5.1.
>>>
>>> 2010-10-18: [v2.12.0.1892]<== Is this an Rtools version?!?
>>> - Prior to October 18, 2010, builds of Rtools212.exe did not correctly
>>> install the "extras" required to build R. Version 2.12.0.1892 or later
>>> should fix this.
>>> - We have now updated all of the tools to current Cygwin versions, and
>>> have updated the compilers, and included the 64 bit compilers into
>>> Rtools. See Prof. Ripley's page for the details.
>>> - Perl is rarely needed in R since R 2.12.0, so it is by default not
>>> installed.
>>>
>>> 2010-??-??:
>>> - The 32 bit version of R-devel (to become R 2.12.0 in fall, 2010)
>>> will be built with gcc 4.5.x, so Rtools212 contains a completely new
>>> MinGW toolchain based on gcc 4.5.0.
>>>
>>> == Changes in Rtools211 ==
>>>
>>> [...]
>>>
>>>
>>> Just a suggestion ...and thanks for providing Rtools!
>>>
>>> /Henrik
>>
>> If a NEWS file were included in the Rtools distribution itself (and
>> not just on the web site) it would be helpful since its not always
>> clear which version you have on your system in the first place.
>
> ? ? ?However, adding a NEWS file increases the labor, and I'd be happy
> letting Duncan and others continue doing what they do without asking them to
> take the time to tell the rest of us what they did.
>
>
> ? ? ?Something simpler would suffice for my needs, e.g., a revision number

That wouldn't let you know what version has been installed after installation.

-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From spencer.graves at structuremonitoring.com  Wed Apr  6 03:17:50 2011
From: spencer.graves at structuremonitoring.com (Spencer Graves)
Date: Tue, 05 Apr 2011 18:17:50 -0700
Subject: [Rd] Rtools questions
In-Reply-To: <BANLkTikjXqMB8nikJgCR2cKETG7+-sCJ6w@mail.gmail.com>
References: <4D9B963E.9070501@structuremonitoring.com>	<4D9B9B41.5070401@gmail.com>	<BANLkTi=tnhAEqOtun=yVUD=fp0KOaatWQg@mail.gmail.com>	<BANLkTikP9mQ_22q+77pLeWBedbfbre_3PQ@mail.gmail.com>	<4D9BBACE.2070604@prodsyse.com>
	<BANLkTikjXqMB8nikJgCR2cKETG7+-sCJ6w@mail.gmail.com>
Message-ID: <4D9BBF3E.5040506@structuremonitoring.com>

On 4/5/2011 6:03 PM, Gabor Grothendieck wrote:
> On Tue, Apr 5, 2011 at 8:58 PM, Spencer Graves
> <spencer.graves at prodsyse.com>  wrote:
>> On 4/5/2011 5:01 PM, Gabor Grothendieck wrote:
>>> On Tue, Apr 5, 2011 at 7:51 PM, Henrik Bengtsson<hb at biostat.ucsf.edu>
>>>   wrote:
>>>> On Tue, Apr 5, 2011 at 3:44 PM, Duncan Murdoch<murdoch.duncan at gmail.com>
>>>>   wrote:
>>>>> On 11-04-05 6:22 PM, Spencer Graves wrote:
>>>>>> Hello:
>>>>>>
>>>>>>
>>>>>>         1.  How can I tell when the development version of Rtools has
>>>>>> changed?
>>>>> I don't make announcements of the changes, you just need to check the
>>>>> web
>>>>> site.  There are online tools that can do this for you automatically,
>>>>> but I
>>>>> don't know which one to recommend.  Google suggests lots of them.
>>>> I also asked myself this before and I must admit it took me a while to
>>>> interpret the contents of the webpage.  There are multiple sections,
>>>> e.g. 'Changes since R 2.12.2', 'Changes since R 2.11.1', 'Changes
>>>> since R 2.11.0', and so on.  Then within each section there are some
>>>> dates mentioned.  Given my current R version (say R 2.13.0 beta) and
>>>> Rtools (Rtools213.exe), it not fully clear to me which section to look
>>>> at, e.g. 'Changes since R 2.12.2'?  It might be more clear if there
>>>> instead the sections would be 'Changes in Rtools213', 'Changes in
>>>> Rtools212' and so on, and within each maybe list updates by
>>>> dates/version.  More like a NEWS file.  Then it would be easier to see
>>>> if there is an updated available or not.  Even a NEWS file only
>>>> available as part of the installation will help decide whether the
>>>> version you have installed differ from the one available online.
>>>> Something like the following:
>>>>
>>>> == Changes in Rtools213 ==
>>>>
>>>> [...]
>>>>
>>>>
>>>> == Changes in Rtools212 ==
>>>>
>>>> 2011-03-25:
>>>> - Rtools 2.12 has been frozen.
>>>> - We have updated all of the tools to current Cygwin versions as of
>>>> March 25, 2011. We added the "du" utility from Cygwin. We have dropped
>>>> Vanilla Perl. The libjpeg version has been updated to 8c, and libpng
>>>> has been updated to 1.5.1.
>>>>
>>>> 2010-10-18: [v2.12.0.1892]<== Is this an Rtools version?!?
>>>> - Prior to October 18, 2010, builds of Rtools212.exe did not correctly
>>>> install the "extras" required to build R. Version 2.12.0.1892 or later
>>>> should fix this.
>>>> - We have now updated all of the tools to current Cygwin versions, and
>>>> have updated the compilers, and included the 64 bit compilers into
>>>> Rtools. See Prof. Ripley's page for the details.
>>>> - Perl is rarely needed in R since R 2.12.0, so it is by default not
>>>> installed.
>>>>
>>>> 2010-??-??:
>>>> - The 32 bit version of R-devel (to become R 2.12.0 in fall, 2010)
>>>> will be built with gcc 4.5.x, so Rtools212 contains a completely new
>>>> MinGW toolchain based on gcc 4.5.0.
>>>>
>>>> == Changes in Rtools211 ==
>>>>
>>>> [...]
>>>>
>>>>
>>>> Just a suggestion ...and thanks for providing Rtools!
>>>>
>>>> /Henrik
>>> If a NEWS file were included in the Rtools distribution itself (and
>>> not just on the web site) it would be helpful since its not always
>>> clear which version you have on your system in the first place.
>>       However, adding a NEWS file increases the labor, and I'd be happy
>> letting Duncan and others continue doing what they do without asking them to
>> take the time to tell the rest of us what they did.
>>
>>
>>       Something simpler would suffice for my needs, e.g., a revision number
> That wouldn't let you know what version has been installed after installation.

It worked for me today with MiKTeX, because I kept the previous 
installer in a place where I could identify it with what I installed.  
That's not as user friendly as NEWS, but it doesn't ask Duncan and 
anyone else who works on Rtools to rearrange their priorities to 
document something that I rarely read.  (Even if I RTFM 24/7, I can't 
read fast enough to keep up with the changes and additions to TFM.)


       Spencer


From D.Strbenac at garvan.org.au  Wed Apr  6 04:00:08 2011
From: D.Strbenac at garvan.org.au (Dario Strbenac)
Date: Wed,  6 Apr 2011 12:00:08 +1000 (EST)
Subject: [Rd] Rcheck Directory
Message-ID: <20110406120008.BLL14202@gimr.garvan.unsw.edu.au>

Hello,

There seems to be a minor conflict of interesting in R CMD check. It creates a log directory, then gives a WARNING about it being there:

* using log directory /home/darstr/Repitools_github/pkg/Repitools.Rcheck
* using R version 2.13.0 RC (2011-04-05 r55310)
* using platform: x86_64-unknown-linux-gnu (64-bit)
* using session charset: UTF-8
     ...                        ...

* checking package subdirectories ... WARNING
Found the following directory(s) with names of check directories:
  ./Repitools.Rcheck
Most likely, these were included erroneously.
     ...                        ...

--------------------------------------
Dario Strbenac
Research Assistant
Cancer Epigenetics
Garvan Institute of Medical Research
Darlinghurst NSW 2010
Australia


From edd at debian.org  Wed Apr  6 05:11:59 2011
From: edd at debian.org (Dirk Eddelbuettel)
Date: Tue, 5 Apr 2011 22:11:59 -0500
Subject: [Rd] Rcheck Directory
In-Reply-To: <20110406120008.BLL14202@gimr.garvan.unsw.edu.au>
References: <20110406120008.BLL14202@gimr.garvan.unsw.edu.au>
Message-ID: <19867.55807.64313.543006@max.nulle.part>


On 6 April 2011 at 12:00, Dario Strbenac wrote:
| Hello,
| 
| There seems to be a minor conflict of interesting in R CMD check. It creates a log directory, then gives a WARNING about it being there:
| 
| * using log directory /home/darstr/Repitools_github/pkg/Repitools.Rcheck
| * using R version 2.13.0 RC (2011-04-05 r55310)
| * using platform: x86_64-unknown-linux-gnu (64-bit)
| * using session charset: UTF-8
|      ...                        ...
| 
| * checking package subdirectories ... WARNING
| Found the following directory(s) with names of check directories:
|   ./Repitools.Rcheck
| Most likely, these were included erroneously.
|      ...                        ...

It usually means that you ran 'R CMD check' once before _inside_ directory,
which usually fails, and you then went up a directory and did it again.
Folks used to upload archives like that to CRAN which is why this is now
checked for.

Warnings are your friends.  And, just like good friends, they sometimes go in
misterious ways...

Dirk


-- 
Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com


From spencer.graves at prodsyse.com  Tue Apr  5 23:20:52 2011
From: spencer.graves at prodsyse.com (Spencer Graves)
Date: Tue, 05 Apr 2011 14:20:52 -0700
Subject: [Rd] Rtools questions
Message-ID: <4D9B87B4.10502@prodsyse.com>

Hello:


       1.  How can I tell when the development version of Rtools has 
changed?  For the past few years, I've installed the development version 
of R tools with each new release of R.  I encountered problems with this 
a few days ago, so I rolled back to Rtools212.exe.  Unfortunately, I 
seem to have more problems with that version.  My latest install was 
under Windows 7 Home Edition.  My previous problems were on Vista, but I 
also have access to Fedora 13 Linux.


       2.  "R CMD check" ends with the following:


* checking examples ... OK
* checking PDF version of manual ... WARNING
LaTeX errors when creating PDF version.
This typically indicates Rd problems.
* checking PDF version of manual without hyperrefs or index ... ERROR
Re-running with no redirection of stdout/stderr.
Hmm ... looks like a package
Error in texi2dvi("Rd2.tex", pdf = (out_ext == "pdf"), quiet = FALSE,  :
   unable to run 'pdflatex' on 'Rd2.tex'
Error in running tools::texi2dvi
You may want to clean up by 'rm -rf 
C:/Users/sgraves/AppData/Local/Temp/Rtmpr6z3
r6/Rd2pdf55b96c9a'


       This is using Rtools213, downloaded April 4 from 
"www.murdoch-sutherland.com/Rtools" with R installed as follows:


 > sessionInfo()
R version 2.12.2 (2011-02-25)
Platform: x86_64-pc-mingw32/x64 (64-bit)

locale:
[1] LC_COLLATE=English_United States.1252
[2] LC_CTYPE=English_United States.1252
[3] LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C
[5] LC_TIME=English_United States.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base



       Thanks,
       Spencer


From spencer.graves at prodsyse.com  Wed Apr  6 02:58:54 2011
From: spencer.graves at prodsyse.com (Spencer Graves)
Date: Tue, 05 Apr 2011 17:58:54 -0700
Subject: [Rd] Rtools questions
In-Reply-To: <BANLkTikP9mQ_22q+77pLeWBedbfbre_3PQ@mail.gmail.com>
References: <4D9B963E.9070501@structuremonitoring.com>	<4D9B9B41.5070401@gmail.com>	<BANLkTi=tnhAEqOtun=yVUD=fp0KOaatWQg@mail.gmail.com>
	<BANLkTikP9mQ_22q+77pLeWBedbfbre_3PQ@mail.gmail.com>
Message-ID: <4D9BBACE.2070604@prodsyse.com>

On 4/5/2011 5:01 PM, Gabor Grothendieck wrote:
> On Tue, Apr 5, 2011 at 7:51 PM, Henrik Bengtsson<hb at biostat.ucsf.edu>  wrote:
>> On Tue, Apr 5, 2011 at 3:44 PM, Duncan Murdoch<murdoch.duncan at gmail.com>  wrote:
>>> On 11-04-05 6:22 PM, Spencer Graves wrote:
>>>> Hello:
>>>>
>>>>
>>>>         1.  How can I tell when the development version of Rtools has
>>>> changed?
>>> I don't make announcements of the changes, you just need to check the web
>>> site.  There are online tools that can do this for you automatically, but I
>>> don't know which one to recommend.  Google suggests lots of them.
>> I also asked myself this before and I must admit it took me a while to
>> interpret the contents of the webpage.  There are multiple sections,
>> e.g. 'Changes since R 2.12.2', 'Changes since R 2.11.1', 'Changes
>> since R 2.11.0', and so on.  Then within each section there are some
>> dates mentioned.  Given my current R version (say R 2.13.0 beta) and
>> Rtools (Rtools213.exe), it not fully clear to me which section to look
>> at, e.g. 'Changes since R 2.12.2'?  It might be more clear if there
>> instead the sections would be 'Changes in Rtools213', 'Changes in
>> Rtools212' and so on, and within each maybe list updates by
>> dates/version.  More like a NEWS file.  Then it would be easier to see
>> if there is an updated available or not.  Even a NEWS file only
>> available as part of the installation will help decide whether the
>> version you have installed differ from the one available online.
>> Something like the following:
>>
>> == Changes in Rtools213 ==
>>
>> [...]
>>
>>
>> == Changes in Rtools212 ==
>>
>> 2011-03-25:
>> - Rtools 2.12 has been frozen.
>> - We have updated all of the tools to current Cygwin versions as of
>> March 25, 2011. We added the "du" utility from Cygwin. We have dropped
>> Vanilla Perl. The libjpeg version has been updated to 8c, and libpng
>> has been updated to 1.5.1.
>>
>> 2010-10-18: [v2.12.0.1892]<== Is this an Rtools version?!?
>> - Prior to October 18, 2010, builds of Rtools212.exe did not correctly
>> install the "extras" required to build R. Version 2.12.0.1892 or later
>> should fix this.
>> - We have now updated all of the tools to current Cygwin versions, and
>> have updated the compilers, and included the 64 bit compilers into
>> Rtools. See Prof. Ripley's page for the details.
>> - Perl is rarely needed in R since R 2.12.0, so it is by default not installed.
>>
>> 2010-??-??:
>> - The 32 bit version of R-devel (to become R 2.12.0 in fall, 2010)
>> will be built with gcc 4.5.x, so Rtools212 contains a completely new
>> MinGW toolchain based on gcc 4.5.0.
>>
>> == Changes in Rtools211 ==
>>
>> [...]
>>
>>
>> Just a suggestion ...and thanks for providing Rtools!
>>
>> /Henrik
> If a NEWS file were included in the Rtools distribution itself (and
> not just on the web site) it would be helpful since its not always
> clear which version you have on your system in the first place.

       However, adding a NEWS file increases the labor, and I'd be happy 
letting Duncan and others continue doing what they do without asking 
them to take the time to tell the rest of us what they did.


       Something simpler would suffice for my needs, e.g., a revision 
number in the name of the download file, like Rtools213.5107.exe for SVN 
revision number 5107.  Windows 7 gives me the date my copy was 
downloaded, not the date of the last patch.  On March 31, I downloaded 
and installed basic-miktex-2.9.3972.exe from 
"http://miktex.org/2.9/setup".  Today, I downloaded
basic-miktex-2.9.4106.exe and basic-miktex-2.9.4106-x64.exe.  From 
comparing names, I inferred (a) the first was a newer version of what I 
had previously installed, and (b) that was 32 bit and the other is 64 
bit.  I installed the latter, and the problem with pdflatex disappeared.


       Spencer


From murdoch.duncan at gmail.com  Wed Apr  6 13:54:23 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 06 Apr 2011 07:54:23 -0400
Subject: [Rd] Rtools questions
In-Reply-To: <BANLkTi=tnhAEqOtun=yVUD=fp0KOaatWQg@mail.gmail.com>
References: <4D9B963E.9070501@structuremonitoring.com>
	<4D9B9B41.5070401@gmail.com>
	<BANLkTi=tnhAEqOtun=yVUD=fp0KOaatWQg@mail.gmail.com>
Message-ID: <4D9C546F.5030706@gmail.com>

On 11-04-05 7:51 PM, Henrik Bengtsson wrote:
 > On Tue, Apr 5, 2011 at 3:44 PM, Duncan 
Murdoch<murdoch.duncan at gmail.com>  wrote:
 >> On 11-04-05 6:22 PM, Spencer Graves wrote:
 >>>
 >>> Hello:
 >>>
 >>>
 >>>         1.  How can I tell when the development version of Rtools has
 >>> changed?
 >>
 >> I don't make announcements of the changes, you just need to check 
the web
 >> site.  There are online tools that can do this for you 
automatically, but I
 >> don't know which one to recommend.  Google suggests lots of them.
 >
 > I also asked myself this before and I must admit it took me a while to
 > interpret the contents of the webpage.  There are multiple sections,
 > e.g. 'Changes since R 2.12.2', 'Changes since R 2.11.1', 'Changes
 > since R 2.11.0', and so on.  Then within each section there are some
 > dates mentioned.  Given my current R version (say R 2.13.0 beta) and
 > Rtools (Rtools213.exe), it not fully clear to me which section to look
 > at, e.g. 'Changes since R 2.12.2'?

Well, that depends on when you downloaded it.  I use the R version 
releases as bookmarks.  If you last downloaded Rtools after the release 
of R 2.12.2, then you only need to look at the last section.

The problem with collecting changes into those that apply to each Rtools 
version is just that the change lists would be longer:  Rtools212 will 
get changes through several R releases.  When there are compiler 
changes, RtoolsXYZ generally comes out during the previous R version, 
because the compiler may only work with the R-devel version.  For 
instance, Rtools212 was introduced between R 2.11.0 and 2.11.1 and was 
updated a number of times up to quite recently.  (It is now frozen, so 
if you download it now and are working with the R versions it supports 
you never need to worry about updates to it.)

However, if you want to reformat the page, go ahead, and send me the new 
version.  It's a hand edited HTML page so I'd be happy to incorporate 
changes that make it more readable, as long as it's still easy to edit 
by hand.

Gabor asked how to know which version was downloaded.  If you have the 
installer file you can tell:  right click on it, choose Properties, look 
at the Version tab.  If you didn't keep the installer, I don't know a 
way to find out, but it might be recorded in the unins000.dat file that 
the uninstaller uses.  Of course, without downloading the new one you 
can't find out its version:  so back to my original suggestion to 
monitor changes to the web page.  I'll see if there's a way to 
automatically include the revision number in the filename.

Duncan Murdoch





  It might be more clear if there
 > instead the sections would be 'Changes in Rtools213', 'Changes in
 > Rtools212' and so on, and within each maybe list updates by
 > dates/version.  More like a NEWS file.  Then it would be easier to see
 > if there is an updated available or not.  Even a NEWS file only
 > available as part of the installation will help decide whether the
 > version you have installed differ from the one available online.
 > Something like the following:
 >
 > == Changes in Rtools213 ==
 >
 > [...]
 >
 >
 > == Changes in Rtools212 ==
 >
 > 2011-03-25:
 > - Rtools 2.12 has been frozen.
 > - We have updated all of the tools to current Cygwin versions as of
 > March 25, 2011. We added the "du" utility from Cygwin. We have dropped
 > Vanilla Perl. The libjpeg version has been updated to 8c, and libpng
 > has been updated to 1.5.1.
 >
 > 2010-10-18: [v2.12.0.1892]<== Is this an Rtools version?!?
 > - Prior to October 18, 2010, builds of Rtools212.exe did not correctly
 > install the "extras" required to build R. Version 2.12.0.1892 or later
 > should fix this.
 > - We have now updated all of the tools to current Cygwin versions, and
 > have updated the compilers, and included the 64 bit compilers into
 > Rtools. See Prof. Ripley's page for the details.
 > - Perl is rarely needed in R since R 2.12.0, so it is by default not 
installed.
 >
 > 2010-??-??:
 > - The 32 bit version of R-devel (to become R 2.12.0 in fall, 2010)
 > will be built with gcc 4.5.x, so Rtools212 contains a completely new
 > MinGW toolchain based on gcc 4.5.0.
 >
 > == Changes in Rtools211 ==
 >
 > [...]
 >
 >
 > Just a suggestion ...and thanks for providing Rtools!
 >
 > /Henrik
 >
 >>
 >>
 >>   For the past few years, I've installed the development version
 >>>
 >>> of R tools with each new release of R.  I encountered problems with 
this
 >>> a few days ago, so I rolled back to Rtools212.exe.  Unfortunately, I
 >>> seem to have more problems with that version.  My latest install was
 >>> under Windows 7 Home Edition.  My previous problems were on Vista, 
but I
 >>> also have access to Fedora 13 Linux.
 >>
 >> I know that Windows 7 64 bit has problems with Rtools.  Brian Ripley 
has had
 >> some luck using the tools (the bin directory) and Cygwin DLLs from last
 >> summer, along with the current compilers.  I'm reluctant to back out 
the new
 >> versions, because I use Cygwin for other things (including OpenSSH) and
 >> don't want to get locked out of updates.
 >>
 >> I haven't heard of problems with other Windows 7 versions, but I haven't
 >> tried them.
 >>
 >>>
 >>>
 >>>         2.  "R CMD check" ends with the following:
 >>>
 >>>
 >>> * checking examples ... OK
 >>> * checking PDF version of manual ... WARNING
 >>> LaTeX errors when creating PDF version.
 >>> This typically indicates Rd problems.
 >>> * checking PDF version of manual without hyperrefs or index ... ERROR
 >>> Re-running with no redirection of stdout/stderr.
 >>> Hmm ... looks like a package
 >>> Error in texi2dvi("Rd2.tex", pdf = (out_ext == "pdf"), quiet = 
FALSE,  :
 >>>     unable to run 'pdflatex' on 'Rd2.tex'
 >>> Error in running tools::texi2dvi
 >>> You may want to clean up by 'rm -rf
 >>> C:/Users/sgraves/AppData/Local/Temp/Rtmpr6z3
 >>> r6/Rd2pdf55b96c9a'
 >>>
 >>>
 >>>         This is using Rtools213, downloaded April 4 from
 >>> "www.murdoch-sutherland.com/Rtools" with R installed as follows:
 >>>
 >>>
 >>>> sessionInfo()
 >>>
 >>> R version 2.12.2 (2011-02-25)
 >>> Platform: x86_64-pc-mingw32/x64 (64-bit)
 >>>
 >>> locale:
 >>> [1] LC_COLLATE=English_United States.1252
 >>> [2] LC_CTYPE=English_United States.1252
 >>> [3] LC_MONETARY=English_United States.1252
 >>> [4] LC_NUMERIC=C
 >>> [5] LC_TIME=English_United States.1252
 >>>
 >>> attached base packages:
 >>> [1] stats     graphics  grDevices utils     datasets  methods   base
 >>
 >>
 >> Do you have pdflatex?  It's not part of Rtools, it's part of LaTeX, as
 >> described in Rtools.txt.
 >>
 >> Duncan Murdoch
 >>
 >> ______________________________________________
 >> R-devel at r-project.org mailing list
 >> https://stat.ethz.ch/mailman/listinfo/r-devel
 >>


From ggrothendieck at gmail.com  Wed Apr  6 14:16:28 2011
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Wed, 6 Apr 2011 08:16:28 -0400
Subject: [Rd] Rtools questions
In-Reply-To: <4D9C546F.5030706@gmail.com>
References: <4D9B963E.9070501@structuremonitoring.com>
	<4D9B9B41.5070401@gmail.com>
	<BANLkTi=tnhAEqOtun=yVUD=fp0KOaatWQg@mail.gmail.com>
	<4D9C546F.5030706@gmail.com>
Message-ID: <BANLkTimR4LeYPwDJpNeX3gM2Uy+rUwZ8qw@mail.gmail.com>

On Wed, Apr 6, 2011 at 7:54 AM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> On 11-04-05 7:51 PM, Henrik Bengtsson wrote:
>> On Tue, Apr 5, 2011 at 3:44 PM, Duncan Murdoch<murdoch.duncan at gmail.com>
>> ?wrote:
>>> On 11-04-05 6:22 PM, Spencer Graves wrote:
>>>>
>>>> Hello:
>>>>
>>>>
>>>> ? ? ? ? 1. ?How can I tell when the development version of Rtools has
>>>> changed?
>>>
>>> I don't make announcements of the changes, you just need to check the web
>>> site. ?There are online tools that can do this for you automatically, but
>>> I
>>> don't know which one to recommend. ?Google suggests lots of them.
>>
>> I also asked myself this before and I must admit it took me a while to
>> interpret the contents of the webpage. ?There are multiple sections,
>> e.g. 'Changes since R 2.12.2', 'Changes since R 2.11.1', 'Changes
>> since R 2.11.0', and so on. ?Then within each section there are some
>> dates mentioned. ?Given my current R version (say R 2.13.0 beta) and
>> Rtools (Rtools213.exe), it not fully clear to me which section to look
>> at, e.g. 'Changes since R 2.12.2'?
>
> Well, that depends on when you downloaded it. ?I use the R version releases
> as bookmarks. ?If you last downloaded Rtools after the release of R 2.12.2,
> then you only need to look at the last section.
>
> The problem with collecting changes into those that apply to each Rtools
> version is just that the change lists would be longer: ?Rtools212 will get
> changes through several R releases. ?When there are compiler changes,
> RtoolsXYZ generally comes out during the previous R version, because the
> compiler may only work with the R-devel version. ?For instance, Rtools212
> was introduced between R 2.11.0 and 2.11.1 and was updated a number of times
> up to quite recently. ?(It is now frozen, so if you download it now and are
> working with the R versions it supports you never need to worry about
> updates to it.)
>
> However, if you want to reformat the page, go ahead, and send me the new
> version. ?It's a hand edited HTML page so I'd be happy to incorporate
> changes that make it more readable, as long as it's still easy to edit by
> hand.
>
> Gabor asked how to know which version was downloaded. ?If you have the
> installer file you can tell: ?right click on it, choose Properties, look at
> the Version tab. ?If you didn't keep the installer, I don't know a way to
> find out, but it might be recorded in the unins000.dat file that the
> uninstaller uses. ?Of course, without downloading the new one you can't find
> out its version: ?so back to my original suggestion to monitor changes to
> the web page. ?I'll see if there's a way to automatically include the
> revision number in the filename.

The situation is that you have several versions of Rtools installers
and have experimented with several of them to see which one seems to
work and now can't remember which one you installed.  If you keep
multiple versions of R as many people do this is particularly
problematic.

Using strings on unins000.dat did not reveal anything although there
was so much text it would be easy to miss.

-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From andre.zege at gmail.com  Wed Apr  6 16:54:45 2011
From: andre.zege at gmail.com (A Zege)
Date: Wed, 6 Apr 2011 07:54:45 -0700 (PDT)
Subject: [Rd] S4 generic functions/methods vs enclosures
Message-ID: <1302101685181-3430950.post@n4.nabble.com>

Apologies for asking something that is probably very obvious, i just started
with S4 classes and i guess i am not finding documentation that lays out the
grammar rules and gives enough examples. 

I understand that main method of writing a member function is to write a
generic function and setMethod for this particular class. This, however,
presumes that there is "virtuality" for this function, i.e. it could be used
with other inherited classes . Truth is, many, if not most of my functions
don't have virtuality in mind. I want to write them inside classes to
achieve incapsulaton only -- use class member data without passing it as
parameters or making global to a bunch of functions and have some specific
class member functions that don't pollute a global namespace and can be
called only for a particular class. This is what enclosured do in R. Is
there some obvious way of setting this environment local to a class and 
without writing generic functions that i am missing?


Would appreciate any pointers 


--
View this message in context: http://r.789695.n4.nabble.com/S4-generic-functions-methods-vs-enclosures-tp3430950p3430950.html
Sent from the R devel mailing list archive at Nabble.com.


From murdoch.duncan at gmail.com  Wed Apr  6 17:07:57 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 06 Apr 2011 11:07:57 -0400
Subject: [Rd] Rtools questions
In-Reply-To: <BANLkTimR4LeYPwDJpNeX3gM2Uy+rUwZ8qw@mail.gmail.com>
References: <4D9B963E.9070501@structuremonitoring.com>
	<4D9B9B41.5070401@gmail.com>
	<BANLkTi=tnhAEqOtun=yVUD=fp0KOaatWQg@mail.gmail.com>
	<4D9C546F.5030706@gmail.com>
	<BANLkTimR4LeYPwDJpNeX3gM2Uy+rUwZ8qw@mail.gmail.com>
Message-ID: <4D9C81CD.9080901@gmail.com>

On 06/04/2011 8:16 AM, Gabor Grothendieck wrote:
> On Wed, Apr 6, 2011 at 7:54 AM, Duncan Murdoch<murdoch.duncan at gmail.com>  wrote:
> >  On 11-04-05 7:51 PM, Henrik Bengtsson wrote:
> >>  On Tue, Apr 5, 2011 at 3:44 PM, Duncan Murdoch<murdoch.duncan at gmail.com>
> >>    wrote:
> >>>  On 11-04-05 6:22 PM, Spencer Graves wrote:
> >>>>
> >>>>  Hello:
> >>>>
> >>>>
> >>>>           1.  How can I tell when the development version of Rtools has
> >>>>  changed?
> >>>
> >>>  I don't make announcements of the changes, you just need to check the web
> >>>  site.  There are online tools that can do this for you automatically, but
> >>>  I
> >>>  don't know which one to recommend.  Google suggests lots of them.
> >>
> >>  I also asked myself this before and I must admit it took me a while to
> >>  interpret the contents of the webpage.  There are multiple sections,
> >>  e.g. 'Changes since R 2.12.2', 'Changes since R 2.11.1', 'Changes
> >>  since R 2.11.0', and so on.  Then within each section there are some
> >>  dates mentioned.  Given my current R version (say R 2.13.0 beta) and
> >>  Rtools (Rtools213.exe), it not fully clear to me which section to look
> >>  at, e.g. 'Changes since R 2.12.2'?
> >
> >  Well, that depends on when you downloaded it.  I use the R version releases
> >  as bookmarks.  If you last downloaded Rtools after the release of R 2.12.2,
> >  then you only need to look at the last section.
> >
> >  The problem with collecting changes into those that apply to each Rtools
> >  version is just that the change lists would be longer:  Rtools212 will get
> >  changes through several R releases.  When there are compiler changes,
> >  RtoolsXYZ generally comes out during the previous R version, because the
> >  compiler may only work with the R-devel version.  For instance, Rtools212
> >  was introduced between R 2.11.0 and 2.11.1 and was updated a number of times
> >  up to quite recently.  (It is now frozen, so if you download it now and are
> >  working with the R versions it supports you never need to worry about
> >  updates to it.)
> >
> >  However, if you want to reformat the page, go ahead, and send me the new
> >  version.  It's a hand edited HTML page so I'd be happy to incorporate
> >  changes that make it more readable, as long as it's still easy to edit by
> >  hand.
> >
> >  Gabor asked how to know which version was downloaded.  If you have the
> >  installer file you can tell:  right click on it, choose Properties, look at
> >  the Version tab.  If you didn't keep the installer, I don't know a way to
> >  find out, but it might be recorded in the unins000.dat file that the
> >  uninstaller uses.  Of course, without downloading the new one you can't find
> >  out its version:  so back to my original suggestion to monitor changes to
> >  the web page.  I'll see if there's a way to automatically include the
> >  revision number in the filename.
>
> The situation is that you have several versions of Rtools installers
> and have experimented with several of them to see which one seems to
> work and now can't remember which one you installed.  If you keep
> multiple versions of R as many people do this is particularly
> problematic.
>

Sure, I understand the problem.  I've taken a look at the installer, and 
it looks as though I can put the revision number in the filename and not 
the installer version number or vice versa (as current), but not both, 
without typing it twice, or adding an extra layer of scripting to insert 
it twice, or some other ugly solution.  I've left a query on the Inno 
Setup newsgroup to see if I missed something, but it looks to me as 
though I'm likely to leave it as is.  If you are installing multiple 
versions of Rtools, you should remember to name them so you don't forget 
which is which.

Duncan Murdoch

> Using strings on unins000.dat did not reveal anything although there
> was so much text it would be easy to miss.
>


From jmc at r-project.org  Wed Apr  6 18:50:39 2011
From: jmc at r-project.org (John Chambers)
Date: Wed, 06 Apr 2011 09:50:39 -0700
Subject: [Rd] S4 generic functions/methods vs enclosures
In-Reply-To: <1302101685181-3430950.post@n4.nabble.com>
References: <1302101685181-3430950.post@n4.nabble.com>
Message-ID: <4D9C99DF.3060506@r-project.org>

Look at ?ReferenceClasses for this OOP paradigm in R, which is quite 
different from the functional paradigm of S4 methods.

On 4/6/11 7:54 AM, A Zege wrote:
> Apologies for asking something that is probably very obvious, i just started
> with S4 classes and i guess i am not finding documentation that lays out the
> grammar rules and gives enough examples.
>
> I understand that main method of writing a member function is to write a
> generic function and setMethod for this particular class. This, however,
> presumes that there is "virtuality" for this function, i.e. it could be used
> with other inherited classes . Truth is, many, if not most of my functions
> don't have virtuality in mind. I want to write them inside classes to
> achieve incapsulaton only -- use class member data without passing it as
> parameters or making global to a bunch of functions and have some specific
> class member functions that don't pollute a global namespace and can be
> called only for a particular class. This is what enclosured do in R. Is
> there some obvious way of setting this environment local to a class and
> without writing generic functions that i am missing?
>
>
> Would appreciate any pointers
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/S4-generic-functions-methods-vs-enclosures-tp3430950p3430950.html
> Sent from the R devel mailing list archive at Nabble.com.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From hb at biostat.ucsf.edu  Wed Apr  6 20:45:31 2011
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Wed, 6 Apr 2011 11:45:31 -0700
Subject: [Rd] Rtools questions
In-Reply-To: <4D9C546F.5030706@gmail.com>
References: <4D9B963E.9070501@structuremonitoring.com>
	<4D9B9B41.5070401@gmail.com>
	<BANLkTi=tnhAEqOtun=yVUD=fp0KOaatWQg@mail.gmail.com>
	<4D9C546F.5030706@gmail.com>
Message-ID: <BANLkTinf8=4N7Fsff757NEi77Jor4yGD5A@mail.gmail.com>

On Wed, Apr 6, 2011 at 4:54 AM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> On 11-04-05 7:51 PM, Henrik Bengtsson wrote:
>> On Tue, Apr 5, 2011 at 3:44 PM, Duncan Murdoch<murdoch.duncan at gmail.com>
>> ?wrote:
>>> On 11-04-05 6:22 PM, Spencer Graves wrote:
>>>>
>>>> Hello:
>>>>
>>>>
>>>> ? ? ? ? 1. ?How can I tell when the development version of Rtools has
>>>> changed?
>>>
>>> I don't make announcements of the changes, you just need to check the web
>>> site. ?There are online tools that can do this for you automatically, but
>>> I
>>> don't know which one to recommend. ?Google suggests lots of them.
>>
>> I also asked myself this before and I must admit it took me a while to
>> interpret the contents of the webpage. ?There are multiple sections,
>> e.g. 'Changes since R 2.12.2', 'Changes since R 2.11.1', 'Changes
>> since R 2.11.0', and so on. ?Then within each section there are some
>> dates mentioned. ?Given my current R version (say R 2.13.0 beta) and
>> Rtools (Rtools213.exe), it not fully clear to me which section to look
>> at, e.g. 'Changes since R 2.12.2'?
>
> Well, that depends on when you downloaded it. ?I use the R version releases
> as bookmarks. ?If you last downloaded Rtools after the release of R 2.12.2,
> then you only need to look at the last section.
>
> The problem with collecting changes into those that apply to each Rtools
> version is just that the change lists would be longer: ?Rtools212 will get
> changes through several R releases. ?When there are compiler changes,
> RtoolsXYZ generally comes out during the previous R version, because the
> compiler may only work with the R-devel version. ?For instance, Rtools212
> was introduced between R 2.11.0 and 2.11.1 and was updated a number of times
> up to quite recently. ?(It is now frozen, so if you download it now and are
> working with the R versions it supports you never need to worry about
> updates to it.)

I understand, and I suspected this was the reason too.

>
> However, if you want to reformat the page, go ahead, and send me the new
> version. ?It's a hand edited HTML page so I'd be happy to incorporate
> changes that make it more readable, as long as it's still easy to edit by
> hand.
>
> Gabor asked how to know which version was downloaded. ?If you have the
> installer file you can tell: ?right click on it, choose Properties, look at
> the Version tab. ?If you didn't keep the installer, I don't know a way to
> find out, but it might be recorded in the unins000.dat file that the
> uninstaller uses. ?Of course, without downloading the new one you can't find
> out its version: ?so back to my original suggestion to monitor changes to
> the web page. ?I'll see if there's a way to automatically include the
> revision number in the filename.

This is useful - I didn't know about this version number of InnoSetup.
 I've browsed the online InnoSetup help, but I couldn't locate what
the version parameter is called.  With it, would it be possible to use
a [Code] block having InnoSetup write the version number to a VERSION
file in the Rtools installation directory?  That would make it
possible to compare what's online and what's installed.

Another alternative for figuring out if Rtools have changed would be
to compare the timestamp of the installed Rtools directory (because
you typically install immediately after download) and the
Rtools213.exe timestamp on the web server.  This could be achieved by
moving the files to, say,
http://www.murdoch-sutherland.com/Rtools/download/ and enable indexing
of files in that directory.

Either way, know about the version number is certainly good enough for
me.  After installing Rtools, I can simply put the installer file in
the Rtools directory to allow me to compare to it later. (I kind of
did this before by comparing file sizes.)

Thanks

Henrik

>
> Duncan Murdoch
>
>
>
>
>
> ?It might be more clear if there
>> instead the sections would be 'Changes in Rtools213', 'Changes in
>> Rtools212' and so on, and within each maybe list updates by
>> dates/version. ?More like a NEWS file. ?Then it would be easier to see
>> if there is an updated available or not. ?Even a NEWS file only
>> available as part of the installation will help decide whether the
>> version you have installed differ from the one available online.
>> Something like the following:
>>
>> == Changes in Rtools213 ==
>>
>> [...]
>>
>>
>> == Changes in Rtools212 ==
>>
>> 2011-03-25:
>> - Rtools 2.12 has been frozen.
>> - We have updated all of the tools to current Cygwin versions as of
>> March 25, 2011. We added the "du" utility from Cygwin. We have dropped
>> Vanilla Perl. The libjpeg version has been updated to 8c, and libpng
>> has been updated to 1.5.1.
>>
>> 2010-10-18: [v2.12.0.1892]<== Is this an Rtools version?!?
>> - Prior to October 18, 2010, builds of Rtools212.exe did not correctly
>> install the "extras" required to build R. Version 2.12.0.1892 or later
>> should fix this.
>> - We have now updated all of the tools to current Cygwin versions, and
>> have updated the compilers, and included the 64 bit compilers into
>> Rtools. See Prof. Ripley's page for the details.
>> - Perl is rarely needed in R since R 2.12.0, so it is by default not
>> installed.
>>
>> 2010-??-??:
>> - The 32 bit version of R-devel (to become R 2.12.0 in fall, 2010)
>> will be built with gcc 4.5.x, so Rtools212 contains a completely new
>> MinGW toolchain based on gcc 4.5.0.
>>
>> == Changes in Rtools211 ==
>>
>> [...]
>>
>>
>> Just a suggestion ...and thanks for providing Rtools!
>>
>> /Henrik
>>
>>>
>>>
>>> ? For the past few years, I've installed the development version
>>>>
>>>> of R tools with each new release of R. ?I encountered problems with this
>>>> a few days ago, so I rolled back to Rtools212.exe. ?Unfortunately, I
>>>> seem to have more problems with that version. ?My latest install was
>>>> under Windows 7 Home Edition. ?My previous problems were on Vista, but I
>>>> also have access to Fedora 13 Linux.
>>>
>>> I know that Windows 7 64 bit has problems with Rtools. ?Brian Ripley has
>>> had
>>> some luck using the tools (the bin directory) and Cygwin DLLs from last
>>> summer, along with the current compilers. ?I'm reluctant to back out the
>>> new
>>> versions, because I use Cygwin for other things (including OpenSSH) and
>>> don't want to get locked out of updates.
>>>
>>> I haven't heard of problems with other Windows 7 versions, but I haven't
>>> tried them.
>>>
>>>>
>>>>
>>>> ? ? ? ? 2. ?"R CMD check" ends with the following:
>>>>
>>>>
>>>> * checking examples ... OK
>>>> * checking PDF version of manual ... WARNING
>>>> LaTeX errors when creating PDF version.
>>>> This typically indicates Rd problems.
>>>> * checking PDF version of manual without hyperrefs or index ... ERROR
>>>> Re-running with no redirection of stdout/stderr.
>>>> Hmm ... looks like a package
>>>> Error in texi2dvi("Rd2.tex", pdf = (out_ext == "pdf"), quiet = FALSE, ?:
>>>> ? ? unable to run 'pdflatex' on 'Rd2.tex'
>>>> Error in running tools::texi2dvi
>>>> You may want to clean up by 'rm -rf
>>>> C:/Users/sgraves/AppData/Local/Temp/Rtmpr6z3
>>>> r6/Rd2pdf55b96c9a'
>>>>
>>>>
>>>> ? ? ? ? This is using Rtools213, downloaded April 4 from
>>>> "www.murdoch-sutherland.com/Rtools" with R installed as follows:
>>>>
>>>>
>>>>> sessionInfo()
>>>>
>>>> R version 2.12.2 (2011-02-25)
>>>> Platform: x86_64-pc-mingw32/x64 (64-bit)
>>>>
>>>> locale:
>>>> [1] LC_COLLATE=English_United States.1252
>>>> [2] LC_CTYPE=English_United States.1252
>>>> [3] LC_MONETARY=English_United States.1252
>>>> [4] LC_NUMERIC=C
>>>> [5] LC_TIME=English_United States.1252
>>>>
>>>> attached base packages:
>>>> [1] stats ? ? graphics ?grDevices utils ? ? datasets ?methods ? base
>>>
>>>
>>> Do you have pdflatex? ?It's not part of Rtools, it's part of LaTeX, as
>>> described in Rtools.txt.
>>>
>>> Duncan Murdoch
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From andre.zege at gmail.com  Wed Apr  6 22:41:42 2011
From: andre.zege at gmail.com (A Zege)
Date: Wed, 6 Apr 2011 13:41:42 -0700 (PDT)
Subject: [Rd] S4 generic functions/methods vs enclosures
In-Reply-To: <1302101685181-3430950.post@n4.nabble.com>
References: <1302101685181-3430950.post@n4.nabble.com>
Message-ID: <1302122502129-3431755.post@n4.nabble.com>

This looks awesome -- it is precisely what i wanted. I have started hacking
with passing around environments  to simulate behavior of classes i was
after, but this is so much neater. Reference classes seem to do precisely
what i wanted. Thank you very much.

--
View this message in context: http://r.789695.n4.nabble.com/S4-generic-functions-methods-vs-enclosures-tp3430950p3431755.html
Sent from the R devel mailing list archive at Nabble.com.


From gmbecker at ucdavis.edu  Thu Apr  7 01:20:18 2011
From: gmbecker at ucdavis.edu (Gabriel Becker)
Date: Wed, 6 Apr 2011 16:20:18 -0700
Subject: [Rd] Activating a Regular Binding
Message-ID: <BANLkTi=rt1ph4cgfkjXok8_moW0y+7sx2A@mail.gmail.com>

Greeting R-devel,

I find myself wanting to attach an active binding to an existing
object in the global environment (R 2.12.2), but there doesn't seem to
be an easy way to do this:

> x = 5
> makeActiveBinding("x", function(d) "hi", .GlobalEnv)
Error in makeActiveBinding("x", function(d) "hi", .GlobalEnv) :
  symbol already has a regular binding

Now I can get around this with some fancy assignment, but this seems
ugly and underhanded:

> x = 5
> y = x
> rm(x)
> makeActiveBinding("x", function(d) print("hi"), .GlobalEnv)
> x = y
[1] "hi"

So my question is: is there a legitimate way to do this?

Thanks,
Gabe

P.S. sessionInfo:

> sessionInfo()
R version 2.12.2 (2011-02-25)
Platform: x86_64-pc-linux-gnu (64-bit)

locale:
 [1] LC_CTYPE=en_US.utf8       LC_NUMERIC=C
 [3] LC_TIME=en_US.utf8        LC_COLLATE=en_US.utf8
 [5] LC_MONETARY=C             LC_MESSAGES=en_US.utf8
 [7] LC_PAPER=en_US.utf8       LC_NAME=C
 [9] LC_ADDRESS=C              LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.utf8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] tools_2.12.2

--
Gabriel Becker
Graduate Student
Statistics Department
University of California, Davis


From D.Strbenac at garvan.org.au  Thu Apr  7 08:00:06 2011
From: D.Strbenac at garvan.org.au (Dario Strbenac)
Date: Thu,  7 Apr 2011 16:00:06 +1000 (EST)
Subject: [Rd] R CMD check for 2.13 rc
In-Reply-To: <BANLkTimjpYPE+Gd2XQJMuj7uX6Eb8SuE1Q@mail.gmail.com>
References: <20110406100008.BLL11522@gimr.garvan.unsw.edu.au>
	<BANLkTimjpYPE+Gd2XQJMuj7uX6Eb8SuE1Q@mail.gmail.com>
Message-ID: <20110407160006.BLL39463@gimr.garvan.unsw.edu.au>

---- Original message ----
>Date: Tue, 5 Apr 2011 17:21:55 -0700
>From: henrik.bengtsson at gmail.com (on behalf of Henrik Bengtsson <hb at biostat.ucsf.edu>)
>Subject: Re: [Rd] R CMD check for 2.13 rc  
>To: D.Strbenac at garvan.org.au
>Cc: r-devel at r-project.org

Yes, I think the warning about normalizePath will be fine when packages ours depends on get updated.

Has anyone got a comment yet, about why setOldClass() classes must now be documented ?

- Dario.


From htl10 at users.sourceforge.net  Thu Apr  7 08:51:44 2011
From: htl10 at users.sourceforge.net (Hin-Tak Leung)
Date: Thu, 07 Apr 2011 07:51:44 +0100
Subject: [Rd] core Matrix package segfaulted on R CMD check --use-gct
In-Reply-To: <AANLkTi=Tjjq9JtuzYp8x4Pp=gtg2eGT7C6RoaXehmX_W@mail.gmail.com>
References: <255683.81856.qm@web29515.mail.ird.yahoo.com>	<AANLkTimDJbJ-u3wXOyvPB0EePf98AZ-R5duKVr+Guh-v@mail.gmail.com>	<19856.40809.236979.731769@stat.math.ethz.ch>	<4D91B5CC.1040500@users.sourceforge.net>	<AANLkTimuxb199-32D+043u9fNp7VsDjf5QD2qX3_Zjof@mail.gmail.com>
	<AANLkTi=Tjjq9JtuzYp8x4Pp=gtg2eGT7C6RoaXehmX_W@mail.gmail.com>
Message-ID: <4D9D5F00.9040200@users.sourceforge.net>

Douglas Bates wrote:
> I isolated the problem and tested then committed a fix. I am going to
> ask Martin to upload the new release as I have gotten out of sync with
> some of his recent changes and he will, I hope, reconcile the branches
> and trunk.  If you need the fixed version immediately, say for
> testing, the changes are in the file Matrix/src/chm_common.c  You can
> visit the SVN archive for the project,
> https://r-forge.r-project.org/scm/?group_id=61, click on the link to
> Browse Subversion Repository and go to pkg/Matrix/src/chm_common.c
> 
> I made the mistake that I chastised others for making, performing an
> operation on the result of a call to install and another value that
> may have required allocation of memory.  The first time install is
> called on a particular string it allocates and SEXPREC, which may
> cause a garbage collection.

Matrix-for-R-2.13 at 2659 (0.999375-49) has the problem at a different place:
 > pkgname <- "Matrix"
 > source(file.path(R.home("share"), "R", "examples-header.R"))
 > gctorture(TRUE)
 > options(warn = 1)
 > options(error=dump.frames)
 > library('Matrix')
Loading required package: lattice
Error in regexpr("package:", envName, fixed = TRUE) :
   unprotected object (0x2fe5818) encountered (was INTSXP)
Error: package/namespace load failed for 'Matrix'

That aside - with R 2.13 only about a week to go, which version of Matrix will 
it ship?

Either way, since this problem causes dependent packages to crash on load, I 
have made some local changes to load Matrix only on demand and not on library 
initialization, since only one routine needs it. I thought I'd add a warning as 
well, but if R crashes, the warning may not come out in time so there is little 
incentive of emitting a warning which may not be seen.


From Rob.Hyndman at monash.edu  Wed Apr  6 09:55:58 2011
From: Rob.Hyndman at monash.edu (Rob J Hyndman)
Date: Wed, 06 Apr 2011 17:55:58 +1000
Subject: [Rd] Proposed modification to decompose() and plot.decomposed.ts()
In-Reply-To: <BANLkTinSWY-1571uHtx43RHLjS1F9+ABbQ@mail.gmail.com>
References: <BANLkTinSWY-1571uHtx43RHLjS1F9+ABbQ@mail.gmail.com>
Message-ID: <BANLkTi=rfo+akqVCr0yUHDsz7dP2uegAFQ@mail.gmail.com>

The decompose() function truncates the seasonal component
unnecessarily. I've modified the function to fix this problem, and
also added the original data to the object returned (to enable better
plotting).

I've also modified the plot.decomposed.ts() function so that it plots
the original data in the top panel rather than the reconstructed data.
The difference between the two is that the reconstructed data has
missing values at the two ends whereas the original data does not.

Please find the revised code below. I hope this can find its way into
the stats package in a future release.

Regards,
Rob Hyndman


# Replacement for decompose function in the stats package
# Only changes are (1) the seasonal component is complete instead of truncated
# and (2) the original data is included in the returned object.

decompose <- function (x, type = c("additive", "multiplicative"),
filter = NULL)
{
? ?type <- match.arg(type)
? ?l <- length(x)
? ?f <- frequency(x)
? ?if (f <= 1 || length(na.omit(x)) < 2 * f)
? ? ? ?stop("time series has no or less than 2 periods")
? ?if (is.null(filter))
? ? ? ?filter <- if (!f%%2)
? ? ? ? ? ?c(0.5, rep(1, f - 1), 0.5)/f
? ? ? ?else rep(1, f)/f
? ?trend <- filter(x, filter)
? ?season <- if (type == "additive")
? ? ? ?x - trend
? ?else x/trend
? ?season <- na.omit(c(as.numeric(window(season, start(x) +
? ? ? ?c(1, 0), end(x))), as.numeric(window(season, start(x),
? ? ? ?start(x) + c(0, f)))))
? ?periods <- l%/%f
? ?index <- c(0, cumsum(rep(f, periods - 2)))
? ?figure <- numeric(f)
? ?for (i in 1L:f) figure[i] <- mean(season[index + i])
? ?figure <- if (type == "additive")
? ? ? ?figure - mean(figure)
? ?else figure/mean(figure)
? ?# Following lines are only changes
? ?seasonal <- ts(rep(figure, periods+1)[1:l], start = start(x), frequency = f)
? ?structure(list(x=x, seasonal = seasonal, trend = trend, random =
if (type ==
? ? ? ?"additive") x - seasonal - trend else x/seasonal/trend,
? ? ? ?figure = figure, type = type), class = "decomposed.ts")
}

# Changed definition of observed to use passed data rather than construct on fly

plot.decomposed.ts <- function (x, ...)
{
? ?plot(cbind(observed = x$x, trend = x$trend, seasonal = x$seasonal,
random = x$random),
? ? ? ?main = paste("Decomposition of", x$type, "time series"), ...)
}



-- 
-------------------------------------------------------------
Rob J Hyndman
Professor of Statistics, Monash University
www.robjhyndman.com


From maechler at stat.math.ethz.ch  Thu Apr  7 12:24:32 2011
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 7 Apr 2011 12:24:32 +0200
Subject: [Rd] core Matrix package segfaulted on R CMD check --use-gct
In-Reply-To: <4D9D5F00.9040200@users.sourceforge.net>
References: <255683.81856.qm@web29515.mail.ird.yahoo.com>
	<AANLkTimDJbJ-u3wXOyvPB0EePf98AZ-R5duKVr+Guh-v@mail.gmail.com>
	<19856.40809.236979.731769@stat.math.ethz.ch>
	<4D91B5CC.1040500@users.sourceforge.net>
	<AANLkTimuxb199-32D+043u9fNp7VsDjf5QD2qX3_Zjof@mail.gmail.com>
	<AANLkTi=Tjjq9JtuzYp8x4Pp=gtg2eGT7C6RoaXehmX_W@mail.gmail.com>
	<4D9D5F00.9040200@users.sourceforge.net>
Message-ID: <19869.37088.323145.396106@stat.math.ethz.ch>

>>>>> "HL" == Hin-Tak Leung <htl10 at users.sourceforge.net>
>>>>>     on Thu, 7 Apr 2011 07:51:44 +0100 writes:

    HL> Douglas Bates wrote:
    >> I isolated the problem and tested then committed a fix. I am going to
    >> ask Martin to upload the new release as I have gotten out of sync with
    >> some of his recent changes and he will, I hope, reconcile the branches
    >> and trunk.  If you need the fixed version immediately, say for
    >> testing, the changes are in the file Matrix/src/chm_common.c  You can
    >> visit the SVN archive for the project,
    >> https://r-forge.r-project.org/scm/?group_id=61, click on the link to
    >> Browse Subversion Repository and go to pkg/Matrix/src/chm_common.c
    >> 
    >> I made the mistake that I chastised others for making, performing an
    >> operation on the result of a call to install and another value that
    >> may have required allocation of memory.  The first time install is
    >> called on a particular string it allocates and SEXPREC, which may
    >> cause a garbage collection.

    HL> Matrix-for-R-2.13 at 2659 (0.999375-49) has the problem at a different place:
    >> pkgname <- "Matrix"
    >> source(file.path(R.home("share"), "R", "examples-header.R"))
    >> gctorture(TRUE)
    >> options(warn = 1)
    >> options(error=dump.frames)
    >> library('Matrix')

    HL> Loading required package: lattice
    HL> Error in regexpr("package:", envName, fixed = TRUE) :
    HL> unprotected object (0x2fe5818) encountered (was INTSXP)
    HL> Error: package/namespace load failed for 'Matrix'

    HL> That aside - with R 2.13 only about a week to go, which version of Matrix will 
    HL> it ship?

Well, R-2.13.0 is in "Release Candidate" ('RC') stage, after having
passed the alpha and beta stages.

So, almost surely, the current CRAN version of Matrix, also part
of all recent R-2.13.0 tarballs will be shipped along.

If we can reproduce your problem, we will fix it, hopefully
pretty soon, and release a version of Matrix,  0.9996875-0
close to the release time of R-2.13.0;
but for stability reasons (of R-2.13.0 and all its testing on
all platforms), it would not ship with 2.13.0 and only people
who explicitly update.packages(...) [after R-2.13.0
installation] will get it.

Martin


From maechler at stat.math.ethz.ch  Thu Apr  7 19:45:24 2011
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 7 Apr 2011 19:45:24 +0200
Subject: [Rd] core Matrix package segfaulted on R CMD check --use-gct
In-Reply-To: <19869.37088.323145.396106@stat.math.ethz.ch>
References: <255683.81856.qm@web29515.mail.ird.yahoo.com>
	<AANLkTimDJbJ-u3wXOyvPB0EePf98AZ-R5duKVr+Guh-v@mail.gmail.com>
	<19856.40809.236979.731769@stat.math.ethz.ch>
	<4D91B5CC.1040500@users.sourceforge.net>
	<AANLkTimuxb199-32D+043u9fNp7VsDjf5QD2qX3_Zjof@mail.gmail.com>
	<AANLkTi=Tjjq9JtuzYp8x4Pp=gtg2eGT7C6RoaXehmX_W@mail.gmail.com>
	<4D9D5F00.9040200@users.sourceforge.net>
	<19869.37088.323145.396106@stat.math.ethz.ch>
Message-ID: <19869.63540.370576.208443@stat.math.ethz.ch>

>>>>> Martin Maechler <maechler at stat.math.ethz.ch>
>>>>>     on Thu, 7 Apr 2011 12:24:32 +0200 writes:

>>>>> "HL" == Hin-Tak Leung <htl10 at users.sourceforge.net>
>>>>>     on Thu, 7 Apr 2011 07:51:44 +0100 writes:

    HL> Douglas Bates wrote:
    >>> I isolated the problem and tested then committed a fix. I am
    >>> going to ask Martin to upload the new release as I have gotten
    >>> out of sync with some of his recent changes and he will, I
    >>> hope, reconcile the branches and trunk.  If you need the fixed
    >>> version immediately, say for testing, the changes are in the
    >>> file Matrix/src/chm_common.c You can visit the SVN archive for
    >>> the project, https://r-forge.r-project.org/scm/?group_id=61,
    >>> click on the link to Browse Subversion Repository and go to
    >>> pkg/Matrix/src/chm_common.c
    >>> 
    >>> I made the mistake that I chastised others for making,
    >>> performing an operation on the result of a call to install and
    >>> another value that may have required allocation of memory.
    >>> The first time install is called on a particular string it
    >>> allocates and SEXPREC, which may cause a garbage collection.

    HL> Matrix-for-R-2.13 at 2659 (0.999375-49) has the problem at a different place:

Are you sure that you really took  0.999375-49  and not its
predecessor ???

I haven't been able to reproduce the problem (on 32-bit Linux,
R-2.13.0 RC, after running your code snippet below for a couple
 of hours, I got the prompt back, and things continued working..)
and Doug Bates has had a strong suspicion that the error message
below looks like the problem that he fixed just between *-48 and *-49.

    >>> pkgname <- "Matrix"
    >>> source(file.path(R.home("share"), "R", "examples-header.R"))
    >>> gctorture(TRUE)
    >>> options(warn = 1)
    >>> options(error=dump.frames)
    >>> library('Matrix')

    HL> Loading required package: lattice
    HL> Error in regexpr("package:", envName, fixed = TRUE) :
    HL> unprotected object (0x2fe5818) encountered (was INTSXP)
    HL> Error: package/namespace load failed for 'Matrix'

Can you give more exact info about the platform ?

Martin


From htl10 at users.sourceforge.net  Thu Apr  7 20:31:35 2011
From: htl10 at users.sourceforge.net (Hin-Tak Leung)
Date: Thu, 07 Apr 2011 19:31:35 +0100
Subject: [Rd] core Matrix package segfaulted on R CMD check --use-gct
In-Reply-To: <19869.63540.370576.208443@stat.math.ethz.ch>
References: <255683.81856.qm@web29515.mail.ird.yahoo.com>	<AANLkTimDJbJ-u3wXOyvPB0EePf98AZ-R5duKVr+Guh-v@mail.gmail.com>	<19856.40809.236979.731769@stat.math.ethz.ch>	<4D91B5CC.1040500@users.sourceforge.net>	<AANLkTimuxb199-32D+043u9fNp7VsDjf5QD2qX3_Zjof@mail.gmail.com>	<AANLkTi=Tjjq9JtuzYp8x4Pp=gtg2eGT7C6RoaXehmX_W@mail.gmail.com>	<4D9D5F00.9040200@users.sourceforge.net>	<19869.37088.323145.396106@stat.math.ethz.ch>
	<19869.63540.370576.208443@stat.math.ethz.ch>
Message-ID: <4D9E0307.7070802@users.sourceforge.net>

Martin Maechler wrote:
>>>>>> Martin Maechler <maechler at stat.math.ethz.ch>
>>>>>>     on Thu, 7 Apr 2011 12:24:32 +0200 writes:
> 
>>>>>> "HL" == Hin-Tak Leung <htl10 at users.sourceforge.net>
>>>>>>     on Thu, 7 Apr 2011 07:51:44 +0100 writes:
> 
>     HL> Douglas Bates wrote:
>     >>> I isolated the problem and tested then committed a fix. I am
>     >>> going to ask Martin to upload the new release as I have gotten
>     >>> out of sync with some of his recent changes and he will, I
>     >>> hope, reconcile the branches and trunk.  If you need the fixed
>     >>> version immediately, say for testing, the changes are in the
>     >>> file Matrix/src/chm_common.c You can visit the SVN archive for
>     >>> the project, https://r-forge.r-project.org/scm/?group_id=61,
>     >>> click on the link to Browse Subversion Repository and go to
>     >>> pkg/Matrix/src/chm_common.c
>     >>> 
>     >>> I made the mistake that I chastised others for making,
>     >>> performing an operation on the result of a call to install and
>     >>> another value that may have required allocation of memory.
>     >>> The first time install is called on a particular string it
>     >>> allocates and SEXPREC, which may cause a garbage collection.
> 
>     HL> Matrix-for-R-2.13 at 2659 (0.999375-49) has the problem at a different place:
> 
> Are you sure that you really took  0.999375-49  and not its
> predecessor ???

The two errors look similiar but different (the previous one was about a 
REALSXP), and both are fairly reproducible.

As much as I can be sure, I guess. I overwrote src/library/Recommended and
library/Matrix to be sure.

> I haven't been able to reproduce the problem (on 32-bit Linux,
> R-2.13.0 RC, after running your code snippet below for a couple
>  of hours, I got the prompt back, and things continued working..)
> and Doug Bates has had a strong suspicion that the error message
> below looks like the problem that he fixed just between *-48 and *-49.
> 
>     >>> pkgname <- "Matrix"
>     >>> source(file.path(R.home("share"), "R", "examples-header.R"))
>     >>> gctorture(TRUE)
>     >>> options(warn = 1)
>     >>> options(error=dump.frames)
>     >>> library('Matrix')
> 
>     HL> Loading required package: lattice
>     HL> Error in regexpr("package:", envName, fixed = TRUE) :
>     HL> unprotected object (0x2fe5818) encountered (was INTSXP)
>     HL> Error: package/namespace load failed for 'Matrix'
> 
> Can you give more exact info about the platform ?

fedora 14 x86_64.

export DEFS='-DUSE_TYPE_CHECKING_STRICT -DR_MEMORY_PROFILING'
  ./configure  --enable-memory-profiling --enable-strict-barrier \ 
--enable-byte-compiled-packages --with-valgrind-instrumentation=2

Matrix-for-R-2.13 at 2659 was the one I was playing with.
I am currently testing Matrix trunk at 2666, since you seems to have put something 
relevant in r2661.


From andre.zege at gmail.com  Thu Apr  7 21:00:52 2011
From: andre.zege at gmail.com (A Zege)
Date: Thu, 7 Apr 2011 12:00:52 -0700 (PDT)
Subject: [Rd] How to debug reference classes?
Message-ID: <1302202852028-3434269.post@n4.nabble.com>

How do you debug methods of a reference class? I've been using mtrace, which
is excellent, but i cannot figure out how to mtrace a reference class
method. Maybe there is some other way to debug these, for example with
ordinary trace? for now i am only able to use options(error=recover), which
is not giving me idea where exactly in the code i am once i am stopped on an
error. 

--
View this message in context: http://r.789695.n4.nabble.com/How-to-debug-reference-classes-tp3434269p3434269.html
Sent from the R devel mailing list archive at Nabble.com.


From maechler at stat.math.ethz.ch  Thu Apr  7 22:16:29 2011
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 7 Apr 2011 22:16:29 +0200
Subject: [Rd] core Matrix package segfaulted on R CMD check --use-gct
In-Reply-To: <4D9E0307.7070802@users.sourceforge.net>
References: <255683.81856.qm@web29515.mail.ird.yahoo.com>
	<AANLkTimDJbJ-u3wXOyvPB0EePf98AZ-R5duKVr+Guh-v@mail.gmail.com>
	<19856.40809.236979.731769@stat.math.ethz.ch>
	<4D91B5CC.1040500@users.sourceforge.net>
	<AANLkTimuxb199-32D+043u9fNp7VsDjf5QD2qX3_Zjof@mail.gmail.com>
	<AANLkTi=Tjjq9JtuzYp8x4Pp=gtg2eGT7C6RoaXehmX_W@mail.gmail.com>
	<4D9D5F00.9040200@users.sourceforge.net>
	<19869.37088.323145.396106@stat.math.ethz.ch>
	<19869.63540.370576.208443@stat.math.ethz.ch>
	<4D9E0307.7070802@users.sourceforge.net>
Message-ID: <19870.7069.369052.277553@stat.math.ethz.ch>

>>>>> "HL" == Hin-Tak Leung <htl10 at users.sourceforge.net>
>>>>>     on Thu, 07 Apr 2011 19:31:35 +0100 writes:

    HL> Martin Maechler wrote:
    >>>>>>> Martin Maechler <maechler at stat.math.ethz.ch> on Thu,
    >>>>>>> 7 Apr 2011 12:24:32 +0200 writes:
    >> 
    >>>>>>> "HL" == Hin-Tak Leung <htl10 at users.sourceforge.net>
    >>>>>>> on Thu, 7 Apr 2011 07:51:44 +0100 writes:
    >> 
    HL> Douglas Bates wrote:
    >> >>> I isolated the problem and tested then committed a
    >> fix. I am >>> going to ask Martin to upload the new
    >> release as I have gotten >>> out of sync with some of his
    >> recent changes and he will, I >>> hope, reconcile the
    >> branches and trunk.  If you need the fixed >>> version
    >> immediately, say for testing, the changes are in the >>>
    >> file Matrix/src/chm_common.c You can visit the SVN
    >> archive for >>> the project,
    >> https://r-forge.r-project.org/scm/?group_id=61, >>> click
    >> on the link to Browse Subversion Repository and go to >>>
    >> pkg/Matrix/src/chm_common.c
    >> >>> 
    >> >>> I made the mistake that I chastised others for
    >> making, >>> performing an operation on the result of a
    >> call to install and >>> another value that may have
    >> required allocation of memory.  >>> The first time
    >> install is called on a particular string it >>> allocates
    >> and SEXPREC, which may cause a garbage collection.
    >> 
    HL> Matrix-for-R-2.13 at 2659 (0.999375-49) has the problem at
    HL> a different place:
    >> 
    >> Are you sure that you really took 0.999375-49 and not its
    >> predecessor ???

    HL> The two errors look similiar but different (the previous
    HL> one was about a REALSXP), and both are fairly
    HL> reproducible.

well, in my experience such problems typically don't show
exactly at the same place, and so the exact instance at which
an unprotected object is GC'ed also changes, and
hence I guesed it could be a REALSXP once and an INTSXP next
time.

    HL> As much as I can be sure, I guess. I overwrote
    HL> src/library/Recommended and library/Matrix to be sure.

???  But  the prerelease version of R-2.13.0 *contains* already
Matrix_0.999375-49  the one you claim has the bug.

[[and you still haven't told use the exact R version you were using]]

    >> I haven't been able to reproduce the problem (on 32-bit
    >> Linux, R-2.13.0 RC, after running your code snippet below
    >> for a couple of hours, I got the prompt back, and things
    >> continued working..)  and Doug Bates has had a strong
    >> suspicion that the error message below looks like the
    >> problem that he fixed just between *-48 and *-49.
    >> 
    >> >>> pkgname <- "Matrix" >>>
    >> source(file.path(R.home("share"), "R",
    >> "examples-header.R")) >>> gctorture(TRUE) >>>
    >> options(warn = 1) >>> options(error=dump.frames) >>>
    >> library('Matrix')
    >> 
    HL> Loading required package: lattice Error in
    HL> regexpr("package:", envName, fixed = TRUE) : unprotected
    HL> object (0x2fe5818) encountered (was INTSXP) Error:
    HL> package/namespace load failed for 'Matrix'
    >> 
    >> Can you give more exact info about the platform ?

    HL> fedora 14 x86_64.

 > export DEFS='-DUSE_TYPE_CHECKING_STRICT -DR_MEMORY_PROFILING'
 > ./configure --enable-memory-profiling --enable-strict-barrier \
 >   --enable-byte-compiled-packages --with-valgrind-instrumentation=2

aah, ok.  Well of course that's not an R version I just have at
my disposal ... ... but I'm building it now 
(for R-2.13.0 "RC", i.e. the R-2-13-branch in R's subversion
tree, revision 55350), and start your test - with R's  own
(=CRAN's) "Matrix" before finishing for today.


    HL> Matrix-for-R-2.13 at 2659 was the one I was playing with.
    HL> I am currently testing Matrix trunk at 2666, since you
    HL> seems to have put something relevant in r2661.

That was really something else, also an important clean up step,
but entirely unrelated to protection and garbage collection...
and ... that version will definitely not make it into R-2.13.0
since it has too many changes compared with the one R-2.13.0
"RC" has been shipping with.

Martin


From chuck at sharpsteen.net  Thu Apr  7 22:59:02 2011
From: chuck at sharpsteen.net (Sharpie)
Date: Thu, 7 Apr 2011 13:59:02 -0700 (PDT)
Subject: [Rd] R 2.13.0-beta for Windows,
 file.copy() throws suspicious errors due to default value of
 copy.mode
Message-ID: <1302209942002-3434559.post@n4.nabble.com>

While checking packages against R 2.13.0-beta on Windows, I have run into a
few strange error messages related to copying files. The errors all relate
to file.copy() and have the form of:

Error in Sys.chmod(to[okay], file.info(from[okay])$mode, TRUE) : 
  'mode' must be of length at least one

After half a day of tinkering, the best reproducible example I can come up
with involves using Roxygen to generate man files for the tikzDevice:

# Install roxygen from CRAN and grab tikzDevice source code
R --vanilla --slave -e "install.packages('roxygen')"
git clone git://github.com/Sharpie/RTikZDevice.git

# Generate documentation, first run succeeds:
R --vanilla --slave -e "require(roxygen); roxygenize('RTikZDevice',
'RTikZDevice.build', overwrite = TRUE)"

Loading required package: roxygen
Loading required package: digest
Writing anyMultibyteUTF8Characters to
RTikZDevice.copy/man/anyMultibyteUTF8Characters.Rd
Warning in parse.name(partitum) :
  No name found for the following expression in RTikZDevice/R/cacheMetrics.R
line 3:
  `NULL . . .'
Writing queryMetricsDictionary to
RTikZDevice.copy/man/queryMetricsDictionary.Rd
...
Writing namespace directives to RTikZDevice.copy/NAMESPACE 
Merging collate directive with RTikZDevice/DESCRIPTION to
RTikZDevice.copy/DESCRIPTION 

# Try running it again, and it bombs:
R --vanilla --slave -e "require(roxygen); roxygenize('RTikZDevice',
'RTikZDevice.build', overwrite = TRUE)"

Loading required package: roxygen
Loading required package: digest
Error in Sys.chmod(to[okay], file.info(from[okay])$mode, TRUE) : 
  'mode' must be of length at least one
Calls: roxygenize -> copy.dir -> file.copy -> Sys.chmod
In addition: Warning message:
In file.create(to[okay]) :
  cannot create file
'RTikZDevice.copy/.git/objects/pack/pack-cc0dd1e2622e87f86f8c5a8e617fbf77e253cea1.idx',
reason 'Permission denied'
Execution halted


If I replace all calls to file.copy(...) in the roxygen package with
file.copy(..., copy.mode = FALSE) and reinstall it, then I can regenerate
package documentation all day long without errors. I also get no errors when
I perform the same task with R 2.12.2 on Windows or R 2.13.0-beta on OS X
and Linux.

Maybe roxygenize() is abusing file.copy() somehow, but I find the "'mode'
must be of length at least one" error suspicious.

Any ideas?

Using:
Windows 7 x86_64
R 2.13.0-beta
Rtools 2.13

-Charlie


-----
Charlie Sharpsteen
Undergraduate-- Environmental Resources Engineering
Humboldt State University
--
View this message in context: http://r.789695.n4.nabble.com/R-2-13-0-beta-for-Windows-file-copy-throws-suspicious-errors-due-to-default-value-of-copy-mode-tp3434559p3434559.html
Sent from the R devel mailing list archive at Nabble.com.


From zhengxin at mail.nih.gov  Thu Apr  7 23:18:53 2011
From: zhengxin at mail.nih.gov (Zheng, Xin (NIH) [C])
Date: Thu, 7 Apr 2011 17:18:53 -0400
Subject: [Rd] anyway to get R unevaluated expr independent on arguments
Message-ID: <E068E36B85D57D449ECEC6894C0F3DCB02A143AB56@NIHMLBX01.nih.gov>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110407/ef9b3064/attachment.pl>

From simon.urbanek at r-project.org  Thu Apr  7 23:42:00 2011
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Thu, 7 Apr 2011 17:42:00 -0400
Subject: [Rd] anyway to get R unevaluated expr independent on arguments
In-Reply-To: <E068E36B85D57D449ECEC6894C0F3DCB02A143AB56@NIHMLBX01.nih.gov>
References: <E068E36B85D57D449ECEC6894C0F3DCB02A143AB56@NIHMLBX01.nih.gov>
Message-ID: <94F14593-CC2D-4EB5-A81B-E69B32E05AE0@r-project.org>


On Apr 7, 2011, at 5:18 PM, Zheng, Xin (NIH) [C] wrote:

> Hi there,
> 
> Suppose the cmd is "a<-3", I can parse the cmd sexp with R_ParseVector and eval it. My question is - is it possible to parse a cmd like "a <- ?", afterwards evaluation will give corresponding result depend on different argument? In other words, '?' is just a placeholder.
> 

Well, you can use a dummy symbol and replace it later, e.g. parse "a <- `*dummy*`" and then before you evaluate you simply replace all occurrences of the "*dummy*" symbol with any value you want. 

That said, we are in a functional language, so you can actually do it more natively by using a closure like "function(.var1){ a <- .var1 }"  - that saves you the substitution part and is more clean.

Cheers,
Simon


From zhengxin at mail.nih.gov  Thu Apr  7 23:47:36 2011
From: zhengxin at mail.nih.gov (Zheng, Xin (NIH) [C])
Date: Thu, 7 Apr 2011 17:47:36 -0400
Subject: [Rd] anyway to get R unevaluated expr independent on arguments
In-Reply-To: <94F14593-CC2D-4EB5-A81B-E69B32E05AE0@r-project.org>
References: <E068E36B85D57D449ECEC6894C0F3DCB02A143AB56@NIHMLBX01.nih.gov>
	<94F14593-CC2D-4EB5-A81B-E69B32E05AE0@r-project.org>
Message-ID: <E068E36B85D57D449ECEC6894C0F3DCB02A143AB5C@NIHMLBX01.nih.gov>

Thank you very much. I learned a lot.

Regards,
Xin

-----Original Message-----
From: Simon Urbanek [mailto:simon.urbanek at r-project.org] 
Sent: Thursday, April 07, 2011 5:42 PM
To: Zheng, Xin (NIH) [C]
Cc: r-devel at r-project.org
Subject: Re: [Rd] anyway to get R unevaluated expr independent on arguments


On Apr 7, 2011, at 5:18 PM, Zheng, Xin (NIH) [C] wrote:

> Hi there,
> 
> Suppose the cmd is "a<-3", I can parse the cmd sexp with R_ParseVector and eval it. My question is - is it possible to parse a cmd like "a <- ?", afterwards evaluation will give corresponding result depend on different argument? In other words, '?' is just a placeholder.
> 

Well, you can use a dummy symbol and replace it later, e.g. parse "a <- `*dummy*`" and then before you evaluate you simply replace all occurrences of the "*dummy*" symbol with any value you want. 

That said, we are in a functional language, so you can actually do it more natively by using a closure like "function(.var1){ a <- .var1 }"  - that saves you the substitution part and is more clean.

Cheers,
Simon


From jmc at r-project.org  Thu Apr  7 23:50:26 2011
From: jmc at r-project.org (John Chambers)
Date: Thu, 07 Apr 2011 14:50:26 -0700
Subject: [Rd] How to debug reference classes?
In-Reply-To: <1302202852028-3434269.post@n4.nabble.com>
References: <1302202852028-3434269.post@n4.nabble.com>
Message-ID: <4D9E31A2.1070108@r-project.org>

This is a good wish-list item.  The natural mechanism would be a version 
of the standard trace() function as a reference method with the same 
arguments as the current trace(), minus those that make no sense.  So:
    xx$trace(edit, browser)
for example, to trace execution of the reference method "edit" defined 
in the class of xx.  The mechanism does not exist now, and will require 
some modifications or extensions to the existing trace() implementation.

Meanwhile, the following slightly ugly workaround seems to apply trace() 
to a reference method.  Here, xx is the object created in the example 
for ReferenceClasses, with method $edit().  [Actually running the 
example removes the class definition, so this was done from a copy of 
the source code for the example.]

The steps in the workaround:

- make a copy of the method,
   edit <- xx$edit

- arrange to trace it in xx:
   trace(edit, browser, where = xx)
(this produces a note and a warning, but they seem harmless)

- remove the copy (just to be safe)
   rm(edit)

- now run things with whatever trace action you speficied.

- if needed after debugging, untrace() the method.
   untrace("edit", where = xx)

An example is below.

Of course, one could also just define xx$edit to call a regular 
function, say myEdit() and trace that.  But the workaround doesn't 
require changing the existing definition.

Suggestions for a better or less ugly workaround are welcome.  I'll look 
at fixing up a trace() method for 2.13.1

John

==============================
 > edit <- xx$edit
 > trace(edit, browser, where = xx)
Constructing traceable class "refMethodDefWithTrace"
Environment of class "refMethodDef" is locked; using global environment 
for new class
Tracing function "edit" in package "2011-04-07 14:34:43"
[1] "edit"
Warning message:
In getPackageName(whereF) :
   Created a package name, "2011-04-07 14:34:43", when none found
 > rm(edit)
 > xx$edit(1,2,3)
Tracing xx$edit(1, 2, 3) on entry
Called from: eval(expr, envir, enclos)
Browse[1]> objects()
[1] "i"     "j"     "value"
Browse[1]> j
[1] 2
Browse[1]> j <- 3
Browse[1]>
 > xx$data
      [,1] [,2] [,3]
[1,]    1    5    3
[2,]    2    6   10
[3,]    3    7   11
[4,]    4    8   12
 > untrace("edit", where = xx)
Untracing function "edit" in package "2011-04-07 14:34:43"
 > xx$edit(1,2,-1)
 > xx$data
      [,1] [,2] [,3]
[1,]    1   -1    3
[2,]    2    6   10
[3,]    3    7   11
[4,]    4    8   12

============================================

On 4/7/11 12:00 PM, A Zege wrote:
> How do you debug methods of a reference class? I've been using mtrace, which
> is excellent, but i cannot figure out how to mtrace a reference class
> method. Maybe there is some other way to debug these, for example with
> ordinary trace? for now i am only able to use options(error=recover), which
> is not giving me idea where exactly in the code i am once i am stopped on an
> error.
>
> --
> View this message in context: http://r.789695.n4.nabble.com/How-to-debug-reference-classes-tp3434269p3434269.html
> Sent from the R devel mailing list archive at Nabble.com.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From htl10 at users.sourceforge.net  Thu Apr  7 23:57:32 2011
From: htl10 at users.sourceforge.net (Hin-Tak Leung)
Date: Thu, 7 Apr 2011 22:57:32 +0100 (BST)
Subject: [Rd] core Matrix package segfaulted on R CMD check --use-gct
In-Reply-To: <19870.7069.369052.277553@stat.math.ethz.ch>
Message-ID: <633463.74929.qm@web29502.mail.ird.yahoo.com>


--- On Thu, 7/4/11, Martin Maechler <maechler at stat.math.ethz.ch> wrote:

> ???? But? the prerelease version of R-2.13.0
> *contains* already
> Matrix_0.999375-49? the one you claim has the bug.
> 
> [[and you still haven't told use the exact R version you
> were using]]

Oh, I am tracking both R and Matrix via git-svn and retrieves all revisions to all branches daily (or at least, regularly). I.e. R svn head.  2.13.0 only forked off recently and most of the trunk<->2.13.0rc differences are so far mostly documentation-related. I could switch to track R 2.13.x branch if you insist.




From hintak_leung at yahoo.co.uk  Thu Apr  7 22:11:26 2011
From: hintak_leung at yahoo.co.uk (Hin-Tak Leung)
Date: Thu, 07 Apr 2011 21:11:26 +0100
Subject: [Rd] core Matrix package segfaulted on R CMD check --use-gct
In-Reply-To: <4D9E0307.7070802@users.sourceforge.net>
References: <255683.81856.qm@web29515.mail.ird.yahoo.com>	<AANLkTimDJbJ-u3wXOyvPB0EePf98AZ-R5duKVr+Guh-v@mail.gmail.com>	<19856.40809.236979.731769@stat.math.ethz.ch>	<4D91B5CC.1040500@users.sourceforge.net>	<AANLkTimuxb199-32D+043u9fNp7VsDjf5QD2qX3_Zjof@mail.gmail.com>	<AANLkTi=Tjjq9JtuzYp8x4Pp=gtg2eGT7C6RoaXehmX_W@mail.gmail.com>	<4D9D5F00.9040200@users.sourceforge.net>	<19869.37088.323145.396106@stat.math.ethz.ch>
	<19869.63540.370576.208443@stat.math.ethz.ch>
	<4D9E0307.7070802@users.sourceforge.net>
Message-ID: <4D9E1A6E.9040600@yahoo.co.uk>

Hin-Tak Leung wrote:
> Martin Maechler wrote:
>>>>>>> Martin Maechler <maechler at stat.math.ethz.ch>
>>>>>>>     on Thu, 7 Apr 2011 12:24:32 +0200 writes:
>>
>>>>>>> "HL" == Hin-Tak Leung <htl10 at users.sourceforge.net>
>>>>>>>     on Thu, 7 Apr 2011 07:51:44 +0100 writes:
>>
>>     HL> Douglas Bates wrote:
>>     >>> I isolated the problem and tested then committed a fix. I am
>>     >>> going to ask Martin to upload the new release as I have gotten
>>     >>> out of sync with some of his recent changes and he will, I
>>     >>> hope, reconcile the branches and trunk.  If you need the fixed
>>     >>> version immediately, say for testing, the changes are in the
>>     >>> file Matrix/src/chm_common.c You can visit the SVN archive for
>>     >>> the project, https://r-forge.r-project.org/scm/?group_id=61,
>>     >>> click on the link to Browse Subversion Repository and go to
>>     >>> pkg/Matrix/src/chm_common.c
>>     >>>     >>> I made the mistake that I chastised others for making,
>>     >>> performing an operation on the result of a call to install and
>>     >>> another value that may have required allocation of memory.
>>     >>> The first time install is called on a particular string it
>>     >>> allocates and SEXPREC, which may cause a garbage collection.
>>
>>     HL> Matrix-for-R-2.13 at 2659 (0.999375-49) has the problem at a 
>> different place:
>>
>> Are you sure that you really took  0.999375-49  and not its
>> predecessor ???
> 
> The two errors look similiar but different (the previous one was about a 
> REALSXP), and both are fairly reproducible.
> 
> As much as I can be sure, I guess. I overwrote src/library/Recommended and
> library/Matrix to be sure.
> 
>> I haven't been able to reproduce the problem (on 32-bit Linux,
>> R-2.13.0 RC, after running your code snippet below for a couple
>>  of hours, I got the prompt back, and things continued working..)
>> and Doug Bates has had a strong suspicion that the error message
>> below looks like the problem that he fixed just between *-48 and *-49.
>>
>>     >>> pkgname <- "Matrix"
>>     >>> source(file.path(R.home("share"), "R", "examples-header.R"))
>>     >>> gctorture(TRUE)
>>     >>> options(warn = 1)
>>     >>> options(error=dump.frames)
>>     >>> library('Matrix')
>>
>>     HL> Loading required package: lattice
>>     HL> Error in regexpr("package:", envName, fixed = TRUE) :
>>     HL> unprotected object (0x2fe5818) encountered (was INTSXP)
>>     HL> Error: package/namespace load failed for 'Matrix'
>>
>> Can you give more exact info about the platform ?
> 
> fedora 14 x86_64.
> 
> export DEFS='-DUSE_TYPE_CHECKING_STRICT -DR_MEMORY_PROFILING'
>  ./configure  --enable-memory-profiling --enable-strict-barrier \ 
> --enable-byte-compiled-packages --with-valgrind-instrumentation=2
> 
> Matrix-for-R-2.13 at 2659 was the one I was playing with.
> I am currently testing Matrix trunk at 2666, since you seems to have put 
> something relevant in r2661.
> 

finished testing trunk r2666 (0.9996875-0). It takes about 3.5 hours (with 
gctorture(TRUE)) to get to:

 > pkgname <- "Matrix"
 > source(file.path(R.home("share"), "R", "examples-header.R"))
 > gctorture(TRUE)
 > options(warn = 1)
 > library('Matrix')
Loading required package: lattice
Error in regexpr("package:", envName, fixed = TRUE) :
   unprotected object (0x3a37878) encountered (was INTSXP)
Error: package/namespace load failed for 'Matrix'
Execution halted


From Mark.Bravington at csiro.au  Fri Apr  8 01:56:26 2011
From: Mark.Bravington at csiro.au (Mark.Bravington at csiro.au)
Date: Fri, 8 Apr 2011 09:56:26 +1000
Subject: [Rd] How to debug reference classes?
In-Reply-To: <1302202852028-3434269.post@n4.nabble.com>
References: <1302202852028-3434269.post@n4.nabble.com>
Message-ID: <3D59DF35E7CF3E42BA70C23BD5CBE6A85F42B80C69@exvic-mbx04.nexus.csiro.au>

'mtrace' will work with reference classes, at least after an object is instantiated. I'm not familiar with the guts of reference classes, but the following quick experiment was successful.. If you run the example in '?ReferenceClasses' up to & including this line :

xx <- mEditor$new(data = xMat)

and then do this:

mtrace( edit, from=attr( xx, '.xData'))

and then run the next line of the example, which is

xx$edit(2, 2, 0)

then the debug window will come up as normal.

Now, what about if you want to mtrace 'edit' before objects are instantiated? Here the S4 structure defeated me temporarily, but I probably would have been able to beat it if I'd had more time... There are some notes on debugging S4 methods in 'package?debug' (note that '?mtrace' itself is out-of-date on S4-- I have gotten S4 debugging to work, but it's only described in 'package?debug') and that might be enough to get you going.

HTH

Mark ('debug' package author)

Mark Bravington
CSIRO CMIS
Marine Lab
Hobart
Australia
________________________________________
From: r-devel-bounces at r-project.org [r-devel-bounces at r-project.org] On Behalf Of A Zege [andre.zege at gmail.com]
Sent: 08 April 2011 05:00
To: r-devel at r-project.org
Subject: [Rd] How to debug reference classes?

How do you debug methods of a reference class? I've been using mtrace, which
is excellent, but i cannot figure out how to mtrace a reference class
method. Maybe there is some other way to debug these, for example with
ordinary trace? for now i am only able to use options(error=recover), which
is not giving me idea where exactly in the code i am once i am stopped on an
error.

--
View this message in context: http://r.789695.n4.nabble.com/How-to-debug-reference-classes-tp3434269p3434269.html
Sent from the R devel mailing list archive at Nabble.com.

______________________________________________
R-devel at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-devel


From jmc at r-project.org  Fri Apr  8 03:12:17 2011
From: jmc at r-project.org (John Chambers)
Date: Thu, 07 Apr 2011 18:12:17 -0700
Subject: [Rd] How to debug reference classes?
In-Reply-To: <3D59DF35E7CF3E42BA70C23BD5CBE6A85F42B80C69@exvic-mbx04.nexus.csiro.au>
References: <1302202852028-3434269.post@n4.nabble.com>
	<3D59DF35E7CF3E42BA70C23BD5CBE6A85F42B80C69@exvic-mbx04.nexus.csiro.au>
Message-ID: <4D9E60F1.7090708@r-project.org>

Good to know.  However, _please_ don't use the horrible kludge in the 
attr(..) expression.  From my experimenting, it worked fine just to say:

mtrace(edit, from = xx)

and even if that did not work, from = as.environment(xx) is identical in 
effect to the attr() expression and means something.  (Usually the 
coercion to "environment" happens automatically.)

The attr() expression is strongly deprecated and very much not 
guaranteed to work.  First, it's discouraged to use the .xData slot, 
which is part of the implementation and not part of the API.  And ditto 
to access _any_ slot by attr(), for the same reason.

However, in my experimenting the technique required xx$edit to have been 
evaluated at some point before the call to mtrace(). Reference methods 
are copied to the object when first required (for efficiency).  Because 
my workaround explicitly used xx$edit, the problem didn't arise.  Just 
evaluating xx$edit should be enough.

On the "before instantiated" point.  I assume you mean in order to trace 
the method in all objects generated from the reference class.  I had 
thought about that too.  The same mechanism I described in my previous 
mail works for this as well, but requires a kludge to get the 
environment containing the methods.  The steps I outlined are as before 
but modified (in the example) as follows:

 > mm =  mEditor$def at refMethods
 > edit = mm$edit
 > trace(edit, browser, where = mm)

(mm is the environment with the methods).  Then the objects generated by 
mEditor$new() will have the traced version.

The same technique didn't seem to work for mtrace(), but a modification 
might.

John


On 4/7/11 4:56 PM, Mark.Bravington at csiro.au wrote:
> 'mtrace' will work with reference classes, at least after an object is instantiated. I'm not familiar with the guts of reference classes, but the following quick experiment was successful.. If you run the example in '?ReferenceClasses' up to&  including this line :
>
> xx<- mEditor$new(data = xMat)
>
> and then do this:
>
> mtrace( edit, from=attr( xx, '.xData'))
>
> and then run the next line of the example, which is
>
> xx$edit(2, 2, 0)
>
> then the debug window will come up as normal.
>
> Now, what about if you want to mtrace 'edit' before objects are instantiated? Here the S4 structure defeated me temporarily, but I probably would have been able to beat it if I'd had more time... There are some notes on debugging S4 methods in 'package?debug' (note that '?mtrace' itself is out-of-date on S4-- I have gotten S4 debugging to work, but it's only described in 'package?debug') and that might be enough to get you going.
>
> HTH
>
> Mark ('debug' package author)
>
> Mark Bravington
> CSIRO CMIS
> Marine Lab
> Hobart
> Australia
> ________________________________________
> From: r-devel-bounces at r-project.org [r-devel-bounces at r-project.org] On Behalf Of A Zege [andre.zege at gmail.com]
> Sent: 08 April 2011 05:00
> To: r-devel at r-project.org
> Subject: [Rd] How to debug reference classes?
>
> How do you debug methods of a reference class? I've been using mtrace, which
> is excellent, but i cannot figure out how to mtrace a reference class
> method. Maybe there is some other way to debug these, for example with
> ordinary trace? for now i am only able to use options(error=recover), which
> is not giving me idea where exactly in the code i am once i am stopped on an
> error.
>
> --
> View this message in context: http://r.789695.n4.nabble.com/How-to-debug-reference-classes-tp3434269p3434269.html
> Sent from the R devel mailing list archive at Nabble.com.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From Mark.Bravington at csiro.au  Fri Apr  8 07:33:16 2011
From: Mark.Bravington at csiro.au (Mark.Bravington at csiro.au)
Date: Fri, 8 Apr 2011 15:33:16 +1000
Subject: [Rd] How to debug reference classes?
In-Reply-To: <4D9E60F1.7090708@r-project.org>
References: <1302202852028-3434269.post@n4.nabble.com>
	<3D59DF35E7CF3E42BA70C23BD5CBE6A85F42B80C69@exvic-mbx04.nexus.csiro.au>,
	<4D9E60F1.7090708@r-project.org>
Message-ID: <3D59DF35E7CF3E42BA70C23BD5CBE6A85F42B80C6C@exvic-mbx04.nexus.csiro.au>

Righto, thanks-- got it. When it comes to debugging, I'm no purist-- the 'debug' package has to work thru all sorts of undocumented "features" in R, so those of a sensitive disposition are advised _never_ to look at its internal code!

Seems like the following works for mtracing refclass methods (based on completely inadequate experimentation, though):

To 'mtrace' a refclass method 'edit' in a particular object 'xx', after 'xx' has been created:

xx$edit <- xx$edit # a "force"; JC's point that methods are . I will sort this out in 'mtrace' eventually
mtrace( edit, from=xx) # now eg xx$edit( 1, 1, 99) will launch debugger
mtrace( edit, from=xx, FALSE) # to clear the mtrace-- mtrace.off won't work properly here

To 'mtrace' all subsequent invocations of a method 'edit' in class 'mEditor', in whatever objects of class 'mEditor' subsequently get created:

mtrace( edit, from=mEditor$def at refMethods)
# now eg xx <- mEditor$new( data=xMat); xx$edit( 5, 5, 99) will launch debugger
mtrace( edit, from=mEditor$def at refMethods, FALSE) # to clear the mtrace

bye
Mark

Mark Bravington
CSIRO CMIS
Marine Lab
Hobart
Australia
________________________________________
From: r-devel-bounces at r-project.org [r-devel-bounces at r-project.org] On Behalf Of John Chambers [jmc at r-project.org]
Sent: 08 April 2011 11:12
To: r-devel at r-project.org
Subject: Re: [Rd] How to debug reference classes?

Good to know.  However, _please_ don't use the horrible kludge in the
attr(..) expression.  From my experimenting, it worked fine just to say:

mtrace(edit, from = xx)

and even if that did not work, from = as.environment(xx) is identical in
effect to the attr() expression and means something.  (Usually the
coercion to "environment" happens automatically.)

The attr() expression is strongly deprecated and very much not
guaranteed to work.  First, it's discouraged to use the .xData slot,
which is part of the implementation and not part of the API.  And ditto
to access _any_ slot by attr(), for the same reason.

However, in my experimenting the technique required xx$edit to have been
evaluated at some point before the call to mtrace(). Reference methods
are copied to the object when first required (for efficiency).  Because
my workaround explicitly used xx$edit, the problem didn't arise.  Just
evaluating xx$edit should be enough.

On the "before instantiated" point.  I assume you mean in order to trace
the method in all objects generated from the reference class.  I had
thought about that too.  The same mechanism I described in my previous
mail works for this as well, but requires a kludge to get the
environment containing the methods.  The steps I outlined are as before
but modified (in the example) as follows:

 > mm =  mEditor$def at refMethods
 > edit = mm$edit
 > trace(edit, browser, where = mm)

(mm is the environment with the methods).  Then the objects generated by
mEditor$new() will have the traced version.

The same technique didn't seem to work for mtrace(), but a modification
might.

John


On 4/7/11 4:56 PM, Mark.Bravington at csiro.au wrote:
> 'mtrace' will work with reference classes, at least after an object is instantiated. I'm not familiar with the guts of reference classes, but the following quick experiment was successful.. If you run the example in '?ReferenceClasses' up to&  including this line :
>
> xx<- mEditor$new(data = xMat)
>
> and then do this:
>
> mtrace( edit, from=attr( xx, '.xData'))
>
> and then run the next line of the example, which is
>
> xx$edit(2, 2, 0)
>
> then the debug window will come up as normal.
>
> Now, what about if you want to mtrace 'edit' before objects are instantiated? Here the S4 structure defeated me temporarily, but I probably would have been able to beat it if I'd had more time... There are some notes on debugging S4 methods in 'package?debug' (note that '?mtrace' itself is out-of-date on S4-- I have gotten S4 debugging to work, but it's only described in 'package?debug') and that might be enough to get you going.
>
> HTH
>
> Mark ('debug' package author)
>
> Mark Bravington
> CSIRO CMIS
> Marine Lab
> Hobart
> Australia
> ________________________________________
> From: r-devel-bounces at r-project.org [r-devel-bounces at r-project.org] On Behalf Of A Zege [andre.zege at gmail.com]
> Sent: 08 April 2011 05:00
> To: r-devel at r-project.org
> Subject: [Rd] How to debug reference classes?
>
> How do you debug methods of a reference class? I've been using mtrace, which
> is excellent, but i cannot figure out how to mtrace a reference class
> method. Maybe there is some other way to debug these, for example with
> ordinary trace? for now i am only able to use options(error=recover), which
> is not giving me idea where exactly in the code i am once i am stopped on an
> error.
>
> --
> View this message in context: http://r.789695.n4.nabble.com/How-to-debug-reference-classes-tp3434269p3434269.html
> Sent from the R devel mailing list archive at Nabble.com.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

______________________________________________
R-devel at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-devel


From pdalgd at gmail.com  Fri Apr  8 08:50:02 2011
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 8 Apr 2011 08:50:02 +0200
Subject: [Rd] core Matrix package segfaulted on R CMD check --use-gct
In-Reply-To: <191025.59368.qm@web29508.mail.ird.yahoo.com>
References: <191025.59368.qm@web29508.mail.ird.yahoo.com>
Message-ID: <3DEDAFF8-5C66-425D-AF4E-256A4BBB3382@gmail.com>

(Resending with fewer recipients...)

On Apr 8, 2011, at 07:09 , Hin-Tak Leung wrote:

> --- On Fri, 8/4/11, peter dalgaard <pdalgd at gmail.com> wrote:
> 
>> On Apr 7, 2011, at 23:57 , Hin-Tak Leung wrote:
>> 
>>> 
>>> Oh, I am tracking both R and Matrix via git-svn and
>> retrieves all revisions to all branches daily (or at least,
>> regularly). I.e. R svn head.  2.13.0 only forked off
>> recently and most of the trunk<->2.13.0rc differences
>> are so far mostly documentation-related. I could switch to
>> track R 2.13.x branch if you insist.
>>> 
>> 
>> Please do. It's the branch that is supposed to stabilize
>> during prerelease times.
>> 
>> Also, please check the prerelease tarballs, errors in "make
>> dist" are not caught when building from svn.
> 
> Just so that there is no doubt, here is the recipe with the latest rc tar ball, cutting-and-pasting from my command history:

Thanks. I wasn't expecting things to be different, just making a point about checking the right object. In principle, we could be putting in unstable development code in the trunk as soon as the branch was made.

> wget -m http://cran.r-project.org/src/base-prerelease/R-rc_2011-04-07_r55373.tar.gz
> cd /tmp
> tar -zxpvf ~/cran.r-project.org/src/base-prerelease/R-rc_2011-04-07_r55373.tar.gz
> cd R-rc/
> export DEFS='-DUSE_TYPE_CHECKING_STRICT -DR_MEMORY_PROFILING' ; ./configure  --enable-memory-profiling --enable-strict-barrier --enable-byte-compiled-packages

Aha... Does it happen without --enable-byte-compiled-packages? To quote NEWS:

"by default the compiler is not used in this release"

so bugs in the compiler are interesting, but not release-critical.

> --with-valgrind-instrumentation=2  ; make
> cd src/library/
> cd Recommended/
> ../../../bin/R CMD check --use-gct Matrix_0.999375-49.tar.gz
> 
> ------------------------------
> ...
> Running examples in ?Matrix-Ex.R? failed
> The error occurred in:
> 
> 
> R version 2.13.0 RC (2011-04-07 r55373)
> Copyright (C) 2011 The R Foundation for Statistical Computing
> ISBN 3-900051-07-0
> Platform: x86_64-unknown-linux-gnu (64-bit)
> ...
>> pkgname <- "Matrix"
>> source(file.path(R.home("share"), "R", "examples-header.R"))
>> gctorture(TRUE)
>> options(warn = 1)
>> library('Matrix')
> Loading required package: lattice
> Error in regexpr("package:", envName, fixed = TRUE) : 
> unprotected object (0x3be2ba8) encountered (was INTSXP)
> Error: package/namespace load failed for 'Matrix'
> Execution halted
> -------------------------
> 

-- 
Peter Dalgaard
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From andreas.borg at unimedizin-mainz.de  Fri Apr  8 09:06:03 2011
From: andreas.borg at unimedizin-mainz.de (Andreas Borg)
Date: Fri, 08 Apr 2011 09:06:03 +0200
Subject: [Rd] super basic questions about S4 classes
In-Reply-To: <1302022043304-3428591.post@n4.nabble.com>
References: <1302022043304-3428591.post@n4.nabble.com>
Message-ID: <4D9EB3DB.7000700@unimedizin-mainz.de>

Hi Andre,

1. Keep in mind that a S4 method belongs to a specific generic function,
not to a specific object or class. There is none such thing as a "class
member function" in the S4 system. As an example for illustration,
consider the following class definitions in Java:

class myClassA
{
    int a;
    int myMethod();
}

class myClassB
{
    double b;
     int myMethod()
}

Assuming that myClassA and myClassB are not related by inheritance, the
two instances of "myMethod" have nothing to do with each other. With S4
classes, you would have something like:

setClass("myClassA", representation(a="integer"))
setClass("myClassB", representation(b="numeric"))

setGeneric("myMethod", function(x) standardGeneric("myMethod"))
setMethod("myMethod", "myClassA", function(x) {"myMethodA"})
setMethod("myMethod", "myClassB", function(x) {"myMethodB"})

where the instances of myMethod belong to the same generic function.
Note that because the methods do not belong to a specific class /
object, the object on which to call must be passed as argument.
Futhermore, it is impossible to have a method with a different argument
list than the generic. Based on the code above, the following gives an
error:

setClass("myClassC", representation(c="character"))
setMethod("myMethod", "myClassC", function(x,y) {"myMethodC"})

while in Java it is no problem to have

class myClassC
{
    char c[];
    int myMethod(int x, int y)
}

with a different argument list for myMethod.

(Of course, different argument lists in methods are possible if one uses
"..." in the generic, this example was just meant as an illustration of
the conceptual difference between class methods and generic functions.)

There is a new approach in R called "reference classes", which might
provide what you are looking for. But I am not familiar with this
paradigm. See ?ReferenceClasses.

2. A function in R is stored in a variable of the same name - as there
can be only one variable with a distinct name (within the same scope),
no overloading is possible. What I usually do is to provide all possible
arguments and check which ones are missing (via missing()) to determine
which to use to construct the object. Another possibility would be to
make the constructor a method which dispatches on the parameter types.

3. S4 methods can be debugged with trace(), to which a method name and a
signature can be passed. I think there is an item in the FAQ about this.
There is one peculiarity with debugging if you have a method that has
additional arguments compared to the generic, for example:

setGeneric("myMethod", function(x, ...) standardGeneric("myMethod"))
setMethod("myMethod", "myClassA", function(x,y) {"myMethodA"})

In this case, the implementation for myMethod will define and call an
inner function ".local". In order to trace into this function, you have
to call debug(.local) from the browser once the method has been traced.


Hope this helps,

Andreas



A Zege schrieb:
> Apologies for asking something that is probably super obvious, i just started
> with S4 classes and i guess i am not finding documentation that layout the
> grammar rules and give enough examples. Some questions i am having are these
>
> 1. I understand that main method of writing a member function is to write a
> generic function and setMethod for this particular object. This, however,
> presumes that there is "virtuality" for this function, i.e. it could be used
> with other inherited classes . Truth is, many, if not most of my functions
> don't have virtuality in mind. I want to write them inside classes to
> achieve incapsulaton only -- use class member data without passing it as
> parameters or making global to a bunch of functions and have some specific
> class member functions that don't pollute a global namespace and can be
> called only for a particular class. This is what i know how to do with
> enclosures in R. Is there some obvious way of setting this environment local
> to a class without writing generic functions that i am missing?
>
> 2. Is it possible to overload functions in other ways than having default
> parameter values and prototypes?
> For example, can i have  two constructors with completely different sets of
> parameters?
>
> 3. Is there some good way to debug S4 classes? I am very fond of mtrace()
> from debug package, but the simple set of commands i normally use doesn't
> take me into class methods. 
>
>
> Would appreciate any pointers on these..
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/super-basic-questions-about-S4-classes-tp3428591p3428591.html
> Sent from the R devel mailing list archive at Nabble.com.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>   


-- 
Andreas Borg
Medizinische Informatik

UNIVERSIT?TSMEDIZIN
der Johannes Gutenberg-Universit?t
Institut f?r Medizinische Biometrie, Epidemiologie und Informatik
Obere Zahlbacher Stra?e 69, 55131 Mainz
www.imbei.uni-mainz.de

Telefon +49 (0) 6131 175062
E-Mail: borg at imbei.uni-mainz.de

Diese E-Mail enth?lt vertrauliche und/oder rechtlich gesch?tzte 
Informationen. Wenn Sie nicht der
richtige Adressat sind oder diese E-Mail irrt?mlich erhalten haben, 
informieren Sie bitte sofort den
Absender und l?schen Sie diese Mail. Das unerlaubte Kopieren sowie die 
unbefugte Weitergabe
dieser Mail und der darin enthaltenen Informationen ist nicht gestattet.


From ripley at stats.ox.ac.uk  Fri Apr  8 13:14:40 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 8 Apr 2011 12:14:40 +0100 (BST)
Subject: [Rd] core Matrix package segfaulted on R CMD check --use-gct
In-Reply-To: <3DEDAFF8-5C66-425D-AF4E-256A4BBB3382@gmail.com>
References: <191025.59368.qm@web29508.mail.ird.yahoo.com>
	<3DEDAFF8-5C66-425D-AF4E-256A4BBB3382@gmail.com>
Message-ID: <alpine.LFD.2.02.1104080834290.5199@gannet.stats.ox.ac.uk>

On Fri, 8 Apr 2011, peter dalgaard wrote:

> (Resending with fewer recipients...)
>
> On Apr 8, 2011, at 07:09 , Hin-Tak Leung wrote:
>
>> --- On Fri, 8/4/11, peter dalgaard <pdalgd at gmail.com> wrote:
>>
>>> On Apr 7, 2011, at 23:57 , Hin-Tak Leung wrote:
>>>
>>>>
>>>> Oh, I am tracking both R and Matrix via git-svn and
>>> retrieves all revisions to all branches daily (or at least,
>>> regularly). I.e. R svn head.  2.13.0 only forked off
>>> recently and most of the trunk<->2.13.0rc differences
>>> are so far mostly documentation-related. I could switch to
>>> track R 2.13.x branch if you insist.
>>>>
>>>
>>> Please do. It's the branch that is supposed to stabilize
>>> during prerelease times.
>>>
>>> Also, please check the prerelease tarballs, errors in "make
>>> dist" are not caught when building from svn.
>>
>> Just so that there is no doubt, here is the recipe with the latest rc tar ball, cutting-and-pasting from my command history:
>
> Thanks. I wasn't expecting things to be different, just making a 
> point about checking the right object. In principle, we could be 
> putting in unstable development code in the trunk as soon as the 
> branch was made.

And despite claims to the contrary earlier in this thread, we 
certainly did.  (One example was in regexpr, although not AFAICS in a 
code branch used in this issue.)  Once 2.x.0 branches, the trunk 
becomes a playpen for ideas considered too radical/experimental for a 
release a month or two off.

>> wget -m http://cran.r-project.org/src/base-prerelease/R-rc_2011-04-07_r55373.tar.gz
>> cd /tmp
>> tar -zxpvf ~/cran.r-project.org/src/base-prerelease/R-rc_2011-04-07_r55373.tar.gz
>> cd R-rc/

>> export DEFS='-DUSE_TYPE_CHECKING_STRICT -DR_MEMORY_PROFILING' ; 
>> ./configure --enable-memory-profiling --enable-strict-barrier 
>> --enable-byte-compiled-packages

Note that the first define does nothing and the second just repeats 
what --enable-memory-profiling does.  Neither are documented in 
current R AFAICS.

> Aha... Does it happen without --enable-byte-compiled-packages? To quote NEWS:
>
> "by default the compiler is not used in this release"
>
> so bugs in the compiler are interesting, but not release-critical.

But --enable-byte-compiled-packages does nothing, as configure --help 
says in 2.13.0 RC (and AFAICS it is documented nowhere else).

You really can't asumme that things not described in the R-admin 
manual are actually relevant to R (or current R).  autoconf puts 
things in configure that are boilerplate code we do not use (and I've 
tried to indicate which ones come from libtool or libintl).

>> --with-valgrind-instrumentation=2  ; make
>> cd src/library/
>> cd Recommended/
>> ../../../bin/R CMD check --use-gct Matrix_0.999375-49.tar.gz
>>
>> ------------------------------
>> ...
>> Running examples in ?Matrix-Ex.R? failed
>> The error occurred in:
>>
>>
>> R version 2.13.0 RC (2011-04-07 r55373)
>> Copyright (C) 2011 The R Foundation for Statistical Computing
>> ISBN 3-900051-07-0
>> Platform: x86_64-unknown-linux-gnu (64-bit)
>> ...
>>> pkgname <- "Matrix"
>>> source(file.path(R.home("share"), "R", "examples-header.R"))
>>> gctorture(TRUE)
>>> options(warn = 1)
>>> library('Matrix')
>> Loading required package: lattice
>> Error in regexpr("package:", envName, fixed = TRUE) :
>> unprotected object (0x3be2ba8) encountered (was INTSXP)
>> Error: package/namespace load failed for 'Matrix'
>> Execution halted
>> -------------------------
>>
>
> -- 
> Peter Dalgaard
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From jorismeys at gmail.com  Fri Apr  8 16:56:16 2011
From: jorismeys at gmail.com (Joris Meys)
Date: Fri, 8 Apr 2011 16:56:16 +0200
Subject: [Rd] Invalid connection after closing?
Message-ID: <BANLkTin3MO-f_dLz4RnCRnj_EXP-Bd=c3Q@mail.gmail.com>

Dear all,

I do not completely understand following behaviour :

> con <- file("test.txt")
> isOpen(con)
[1] FALSE
> open(con)
> isOpen(con)
[1] TRUE
> close(con)
> isOpen(con)
Error in isOpen(con) : invalid connection
> str(con)
Classes 'file', 'connection'  atomic [1:1] 3
  ..- attr(*, "conn_id")=<externalptr>

Why do I get an error, indicating an invalid connection, after I
closed a connection? Is this to be expected?
Cheers
Joris

-- 
Joris Meys
Statistical consultant

Ghent University
Faculty of Bioscience Engineering
Department of Applied mathematics, biometrics and process control

tel : +32 9 264 59 87
Joris.Meys at Ugent.be
-------------------------------
Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php


From murdoch.duncan at gmail.com  Fri Apr  8 16:59:10 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 08 Apr 2011 10:59:10 -0400
Subject: [Rd] duplicates() function
In-Reply-To: <B722DD6C-3B97-46EC-B369-8316F0F65D1F@cbs.dk>
References: <bug-14552-16@http.bugs.r-project.org/bugzilla3/>	<20110408142610.88AEC970477@ix.urbanek.info>
	<B722DD6C-3B97-46EC-B369-8316F0F65D1F@cbs.dk>
Message-ID: <4D9F22BE.5000502@gmail.com>

I need a function which is similar to duplicated(), but instead of 
returning TRUE/FALSE, returns indices of which element was duplicated.  
That is,

 > x <- c(9,7,9,3,7)
 > duplicated(x)
[1] FALSE FALSE  TRUE FALSE TRUE

 > duplicates(x)
[1] NA NA  1 NA  2

(so that I know that element 3 is a duplicate of element 1, and element 
5 is a duplicate of element 2, whereas the others were not duplicated 
according to our definition.)

Is there a simple way to write this function?  I have  an ugly 
implementation in R that loops over all the values; it would make more 
sense to redo it in C, if there isn't a simple implementation I missed.

Duncan Murdoch


From josh.m.ulrich at gmail.com  Fri Apr  8 17:08:12 2011
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Fri, 8 Apr 2011 10:08:12 -0500
Subject: [Rd] duplicates() function
In-Reply-To: <4D9F22BE.5000502@gmail.com>
References: <bug-14552-16@http.bugs.r-project.org/bugzilla3/>
	<20110408142610.88AEC970477@ix.urbanek.info>
	<B722DD6C-3B97-46EC-B369-8316F0F65D1F@cbs.dk>
	<4D9F22BE.5000502@gmail.com>
Message-ID: <BANLkTimQEeXMPCjWaHuQZ74t8d0A_9XeyQ@mail.gmail.com>

How about:

y <- rep(NA,length(x))
y[duplicated(x)] <- match(x[duplicated(x)] ,x)

--
Joshua Ulrich ?| ?FOSS Trading: www.fosstrading.com



On Fri, Apr 8, 2011 at 9:59 AM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> I need a function which is similar to duplicated(), but instead of returning
> TRUE/FALSE, returns indices of which element was duplicated. ?That is,
>
>> x <- c(9,7,9,3,7)
>> duplicated(x)
> [1] FALSE FALSE ?TRUE FALSE TRUE
>
>> duplicates(x)
> [1] NA NA ?1 NA ?2
>
> (so that I know that element 3 is a duplicate of element 1, and element 5 is
> a duplicate of element 2, whereas the others were not duplicated according
> to our definition.)
>
> Is there a simple way to write this function? ?I have ?an ugly
> implementation in R that loops over all the values; it would make more sense
> to redo it in C, if there isn't a simple implementation I missed.
>
> Duncan Murdoch
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From murdoch.duncan at gmail.com  Fri Apr  8 17:09:30 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 08 Apr 2011 11:09:30 -0400
Subject: [Rd] Invalid connection after closing?
In-Reply-To: <BANLkTin3MO-f_dLz4RnCRnj_EXP-Bd=c3Q@mail.gmail.com>
References: <BANLkTin3MO-f_dLz4RnCRnj_EXP-Bd=c3Q@mail.gmail.com>
Message-ID: <4D9F252A.3020702@gmail.com>

On 08/04/2011 10:56 AM, Joris Meys wrote:
> Dear all,
>
> I do not completely understand following behaviour :
>
> >  con<- file("test.txt")
> >  isOpen(con)
> [1] FALSE
> >  open(con)
> >  isOpen(con)
> [1] TRUE
> >  close(con)
> >  isOpen(con)
> Error in isOpen(con) : invalid connection
> >  str(con)
> Classes 'file', 'connection'  atomic [1:1] 3
>    ..- attr(*, "conn_id")=<externalptr>
>
> Why do I get an error, indicating an invalid connection, after I
> closed a connection? Is this to be expected?

Quoting ?close: " ?close? closes and destroys a connection. " In the 
current implementation, connections are a finite resource, and you need 
to be able to get rid of them when you are done. close(con) is the way 
to do that. If you want to re-open it, you need to remember the filename 
(or extract it before calling close()), and issue another call to file().

Duncan Murdoch


From hadley at rice.edu  Fri Apr  8 17:13:26 2011
From: hadley at rice.edu (Hadley Wickham)
Date: Fri, 8 Apr 2011 10:13:26 -0500
Subject: [Rd] duplicates() function
In-Reply-To: <4D9F22BE.5000502@gmail.com>
References: <bug-14552-16@http.bugs.r-project.org/bugzilla3/>
	<20110408142610.88AEC970477@ix.urbanek.info>
	<B722DD6C-3B97-46EC-B369-8316F0F65D1F@cbs.dk>
	<4D9F22BE.5000502@gmail.com>
Message-ID: <BANLkTi=nBqgHRJeLWva_XpJZYph63wZt9Q@mail.gmail.com>

On Fri, Apr 8, 2011 at 9:59 AM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> I need a function which is similar to duplicated(), but instead of returning
> TRUE/FALSE, returns indices of which element was duplicated. ?That is,
>
>> x <- c(9,7,9,3,7)
>> duplicated(x)
> [1] FALSE FALSE ?TRUE FALSE TRUE
>
>> duplicates(x)
> [1] NA NA ?1 NA ?2
>
> (so that I know that element 3 is a duplicate of element 1, and element 5 is
> a duplicate of element 2, whereas the others were not duplicated according
> to our definition.)
>
> Is there a simple way to write this function? ?I have ?an ugly
> implementation in R that loops over all the values; it would make more sense
> to redo it in C, if there isn't a simple implementation I missed.

I'd think of making it a lookup table.  The basic idea is

split(seq_along(x), x)

but there are probably much faster ways of doing it, depending on what
you need.  But for efficiency, you probably need a hashtable
somewhere.

Hadley

-- 
Assistant Professor / Dobelman Family Junior Chair
Department of Statistics / Rice University
http://had.co.nz/


From jorismeys at gmail.com  Fri Apr  8 17:14:08 2011
From: jorismeys at gmail.com (Joris Meys)
Date: Fri, 8 Apr 2011 17:14:08 +0200
Subject: [Rd] Invalid connection after closing?
In-Reply-To: <4D9F252A.3020702@gmail.com>
References: <BANLkTin3MO-f_dLz4RnCRnj_EXP-Bd=c3Q@mail.gmail.com>
	<4D9F252A.3020702@gmail.com>
Message-ID: <BANLkTikazPA34K0BjONF5tBv_0DAkbMMfQ@mail.gmail.com>

Thx for the information. I read it, but I wasn't sure what was going
on inside. Is there a way to close a connection without destroying it?
Guess not, but you never know...

Cheers
Joris

On Fri, Apr 8, 2011 at 5:09 PM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> On 08/04/2011 10:56 AM, Joris Meys wrote:
>>
>> Dear all,
>>
>> I do not completely understand following behaviour :
>>
>> > ?con<- file("test.txt")
>> > ?isOpen(con)
>> [1] FALSE
>> > ?open(con)
>> > ?isOpen(con)
>> [1] TRUE
>> > ?close(con)
>> > ?isOpen(con)
>> Error in isOpen(con) : invalid connection
>> > ?str(con)
>> Classes 'file', 'connection' ?atomic [1:1] 3
>> ? ..- attr(*, "conn_id")=<externalptr>
>>
>> Why do I get an error, indicating an invalid connection, after I
>> closed a connection? Is this to be expected?
>
> Quoting ?close: " ?close? closes and destroys a connection. " In the current
> implementation, connections are a finite resource, and you need to be able
> to get rid of them when you are done. close(con) is the way to do that. If
> you want to re-open it, you need to remember the filename (or extract it
> before calling close()), and issue another call to file().
>
> Duncan Murdoch
>



-- 
Joris Meys
Statistical consultant

Ghent University
Faculty of Bioscience Engineering
Department of Applied mathematics, biometrics and process control

tel : +32 9 264 59 87
Joris.Meys at Ugent.be
-------------------------------
Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php


From murdoch.duncan at gmail.com  Fri Apr  8 17:15:47 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 08 Apr 2011 11:15:47 -0400
Subject: [Rd] duplicates() function
In-Reply-To: <BANLkTimQEeXMPCjWaHuQZ74t8d0A_9XeyQ@mail.gmail.com>
References: <bug-14552-16@http.bugs.r-project.org/bugzilla3/>
	<20110408142610.88AEC970477@ix.urbanek.info>
	<B722DD6C-3B97-46EC-B369-8316F0F65D1F@cbs.dk>
	<4D9F22BE.5000502@gmail.com>
	<BANLkTimQEeXMPCjWaHuQZ74t8d0A_9XeyQ@mail.gmail.com>
Message-ID: <4D9F26A3.6060609@gmail.com>

On 08/04/2011 11:08 AM, Joshua Ulrich wrote:
> How about:
>
> y<- rep(NA,length(x))
> y[duplicated(x)]<- match(x[duplicated(x)] ,x)

That's a nice solution for vectors.  Unfortunately for me, I have a 
matrix (which duplicated() handles by checking whole rows).  So a better 
example that I should have posted would be

x <-  cbind(1, c(9,7,9,3,7) )

and I'd still like the same output

>  duplicated(x)
[1] FALSE FALSE  TRUE FALSE TRUE

>  duplicates(x)
[1] NA NA  1 NA  2


Duncan Murdoch

> --
> Joshua Ulrich  |  FOSS Trading: www.fosstrading.com
>
>
>
> On Fri, Apr 8, 2011 at 9:59 AM, Duncan Murdoch<murdoch.duncan at gmail.com>  wrote:
> >  I need a function which is similar to duplicated(), but instead of returning
> >  TRUE/FALSE, returns indices of which element was duplicated.  That is,
> >
> >>  x<- c(9,7,9,3,7)
> >>  duplicated(x)
> >  [1] FALSE FALSE  TRUE FALSE TRUE
> >
> >>  duplicates(x)
> >  [1] NA NA  1 NA  2
> >
> >  (so that I know that element 3 is a duplicate of element 1, and element 5 is
> >  a duplicate of element 2, whereas the others were not duplicated according
> >  to our definition.)
> >
> >  Is there a simple way to write this function?  I have  an ugly
> >  implementation in R that loops over all the values; it would make more sense
> >  to redo it in C, if there isn't a simple implementation I missed.
> >
> >  Duncan Murdoch
> >
> >  ______________________________________________
> >  R-devel at r-project.org mailing list
> >  https://stat.ethz.ch/mailman/listinfo/r-devel
> >


From kasperdanielhansen at gmail.com  Fri Apr  8 17:21:00 2011
From: kasperdanielhansen at gmail.com (Kasper Daniel Hansen)
Date: Fri, 8 Apr 2011 11:21:00 -0400
Subject: [Rd] duplicates() function
In-Reply-To: <BANLkTimQEeXMPCjWaHuQZ74t8d0A_9XeyQ@mail.gmail.com>
References: <bug-14552-16@http.bugs.r-project.org/bugzilla3/>
	<20110408142610.88AEC970477@ix.urbanek.info>
	<B722DD6C-3B97-46EC-B369-8316F0F65D1F@cbs.dk>
	<4D9F22BE.5000502@gmail.com>
	<BANLkTimQEeXMPCjWaHuQZ74t8d0A_9XeyQ@mail.gmail.com>
Message-ID: <BANLkTin1iSGkxtb0w+gaDc8e2Cw4oTHBTQ@mail.gmail.com>

On Fri, Apr 8, 2011 at 11:08 AM, Joshua Ulrich <josh.m.ulrich at gmail.com> wrote:
> How about:
>
> y <- rep(NA,length(x))
> y[duplicated(x)] <- match(x[duplicated(x)] ,x)
>

I use Joshua's trick all the time.  But it might still be nice with a
C implementation.

While we are discussing duplication, I would also like to see
something like duplicated() but which returns TRUE whenever a value is
later duplicated, so I can easily select the values of a vector which
has are never duplicated.  Right now I need to do something like
  y [ ! y %in% y[duplicated(y)] ]
I am only bringing this up because of Duncan's request.

Kasper






> --
> Joshua Ulrich ?| ?FOSS Trading: www.fosstrading.com
>
>
>
> On Fri, Apr 8, 2011 at 9:59 AM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>> I need a function which is similar to duplicated(), but instead of returning
>> TRUE/FALSE, returns indices of which element was duplicated. ?That is,
>>
>>> x <- c(9,7,9,3,7)
>>> duplicated(x)
>> [1] FALSE FALSE ?TRUE FALSE TRUE
>>
>>> duplicates(x)
>> [1] NA NA ?1 NA ?2
>>
>> (so that I know that element 3 is a duplicate of element 1, and element 5 is
>> a duplicate of element 2, whereas the others were not duplicated according
>> to our definition.)
>>
>> Is there a simple way to write this function? ?I have ?an ugly
>> implementation in R that loops over all the values; it would make more sense
>> to redo it in C, if there isn't a simple implementation I missed.
>>
>> Duncan Murdoch
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From andre.zege at gmail.com  Fri Apr  8 17:38:12 2011
From: andre.zege at gmail.com (A Zege)
Date: Fri, 8 Apr 2011 08:38:12 -0700 (PDT)
Subject: [Rd] How to debug reference classes?
In-Reply-To: <3D59DF35E7CF3E42BA70C23BD5CBE6A85F42B80C69@exvic-mbx04.nexus.csiro.au>
References: <1302202852028-3434269.post@n4.nabble.com>
	<3D59DF35E7CF3E42BA70C23BD5CBE6A85F42B80C69@exvic-mbx04.nexus.csiro.au>
Message-ID: <1302277092995-3436674.post@n4.nabble.com>

Thank you very much, gentlemen. It seems reference classes will make my life
much easier. I won't pretend that i fully understand the wizardry with
environments that you do, but it works :). Namely the steps to mtrace a
class method by doing what John and Mark outlined
   xx$edit<-xx$edit
   mtrace(edit, from=xx)
   xx$edit(1,1,99)

do the magic of starting mtrace which solves my problem for practical
purposes. I was not able to make the second part of prescription related to
debugging unconstructed objects work. Namely, whenever i do 

 mtrace( edit, from=mEditor$def at refMethods) 

I get 
Error in parent.env(from) : the empty environment has no parent. Must be
doing something wrong, but haven't yet figured what.

--
View this message in context: http://r.789695.n4.nabble.com/How-to-debug-reference-classes-tp3434269p3436674.html
Sent from the R devel mailing list archive at Nabble.com.


From josh.m.ulrich at gmail.com  Fri Apr  8 17:39:01 2011
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Fri, 8 Apr 2011 10:39:01 -0500
Subject: [Rd] duplicates() function
In-Reply-To: <4D9F26A3.6060609@gmail.com>
References: <bug-14552-16@http.bugs.r-project.org/bugzilla3/>
	<20110408142610.88AEC970477@ix.urbanek.info>
	<B722DD6C-3B97-46EC-B369-8316F0F65D1F@cbs.dk>
	<4D9F22BE.5000502@gmail.com>
	<BANLkTimQEeXMPCjWaHuQZ74t8d0A_9XeyQ@mail.gmail.com>
	<4D9F26A3.6060609@gmail.com>
Message-ID: <BANLkTinVqU+yZ0JgQzJfvDW6GQKk0kAG_A@mail.gmail.com>

On Fri, Apr 8, 2011 at 10:15 AM, Duncan Murdoch
<murdoch.duncan at gmail.com> wrote:
> On 08/04/2011 11:08 AM, Joshua Ulrich wrote:
>>
>> How about:
>>
>> y<- rep(NA,length(x))
>> y[duplicated(x)]<- match(x[duplicated(x)] ,x)
>
> That's a nice solution for vectors. ?Unfortunately for me, I have a matrix
> (which duplicated() handles by checking whole rows). ?So a better example
> that I should have posted would be
>
> x <- ?cbind(1, c(9,7,9,3,7) )
>
> and I'd still like the same output
>
For a matrix, could you apply the same strategy used in duplicated()?

y <- rep(NA,NROW(x))
temp <- apply(x, 1, function(x) paste(x, collapse="\r"))
y[duplicated(temp)] <- match(temp[duplicated(temp)], temp)

>> ?duplicated(x)
>
> [1] FALSE FALSE ?TRUE FALSE TRUE
>
>> ?duplicates(x)
>
> [1] NA NA ?1 NA ?2
>
>
> Duncan Murdoch
>
>> --
>> Joshua Ulrich ?| ?FOSS Trading: www.fosstrading.com
>>
>>
>>
>> On Fri, Apr 8, 2011 at 9:59 AM, Duncan Murdoch<murdoch.duncan at gmail.com>
>> ?wrote:
>> > ?I need a function which is similar to duplicated(), but instead of
>> > returning
>> > ?TRUE/FALSE, returns indices of which element was duplicated. ?That is,
>> >
>> >> ?x<- c(9,7,9,3,7)
>> >> ?duplicated(x)
>> > ?[1] FALSE FALSE ?TRUE FALSE TRUE
>> >
>> >> ?duplicates(x)
>> > ?[1] NA NA ?1 NA ?2
>> >
>> > ?(so that I know that element 3 is a duplicate of element 1, and element
>> > 5 is
>> > ?a duplicate of element 2, whereas the others were not duplicated
>> > according
>> > ?to our definition.)
>> >
>> > ?Is there a simple way to write this function? ?I have ?an ugly
>> > ?implementation in R that loops over all the values; it would make more
>> > sense
>> > ?to redo it in C, if there isn't a simple implementation I missed.
>> >
>> > ?Duncan Murdoch
>> >
>> > ?______________________________________________
>> > ?R-devel at r-project.org mailing list
>> > ?https://stat.ethz.ch/mailman/listinfo/r-devel
>> >
>
>


From ripley at stats.ox.ac.uk  Fri Apr  8 18:19:42 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 8 Apr 2011 17:19:42 +0100 (BST)
Subject: [Rd] Invalid connection after closing?
In-Reply-To: <BANLkTikazPA34K0BjONF5tBv_0DAkbMMfQ@mail.gmail.com>
References: <BANLkTin3MO-f_dLz4RnCRnj_EXP-Bd=c3Q@mail.gmail.com>
	<4D9F252A.3020702@gmail.com>
	<BANLkTikazPA34K0BjONF5tBv_0DAkbMMfQ@mail.gmail.com>
Message-ID: <alpine.LFD.2.02.1104081717210.12610@gannet.stats.ox.ac.uk>

On Fri, 8 Apr 2011, Joris Meys wrote:

> Thx for the information. I read it, but I wasn't sure what was going
> on inside.

Then perhaps you needed to do your homework: the references on the 
help page would have explained it to you.

> Is there a way to close a connection without destroying it?
> Guess not, but you never know...

Not from R code.

>
> Cheers
> Joris
>
> On Fri, Apr 8, 2011 at 5:09 PM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>> On 08/04/2011 10:56 AM, Joris Meys wrote:
>>>
>>> Dear all,
>>>
>>> I do not completely understand following behaviour :
>>>
>>>> ?con<- file("test.txt")
>>>> ?isOpen(con)
>>> [1] FALSE
>>>> ?open(con)
>>>> ?isOpen(con)
>>> [1] TRUE
>>>> ?close(con)
>>>> ?isOpen(con)
>>> Error in isOpen(con) : invalid connection
>>>> ?str(con)
>>> Classes 'file', 'connection' ?atomic [1:1] 3
>>> ? ..- attr(*, "conn_id")=<externalptr>
>>>
>>> Why do I get an error, indicating an invalid connection, after I
>>> closed a connection? Is this to be expected?
>>
>> Quoting ?close: " ?close? closes and destroys a connection. " In the current
>> implementation, connections are a finite resource, and you need to be able
>> to get rid of them when you are done. close(con) is the way to do that. If
>> you want to re-open it, you need to remember the filename (or extract it
>> before calling close()), and issue another call to file().
>>
>> Duncan Murdoch
>>
>
>
>
> -- 
> Joris Meys
> Statistical consultant
>
> Ghent University
> Faculty of Bioscience Engineering
> Department of Applied mathematics, biometrics and process control
>
> tel : +32 9 264 59 87
> Joris.Meys at Ugent.be
> -------------------------------
> Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From wdunlap at tibco.com  Fri Apr  8 18:22:08 2011
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 8 Apr 2011 09:22:08 -0700
Subject: [Rd] duplicates() function
In-Reply-To: <4D9F26A3.6060609@gmail.com>
References: <bug-14552-16@http.bugs.r-project.org/bugzilla3/><20110408142610.88AEC970477@ix.urbanek.info><B722DD6C-3B97-46EC-B369-8316F0F65D1F@cbs.dk><4D9F22BE.5000502@gmail.com><BANLkTimQEeXMPCjWaHuQZ74t8d0A_9XeyQ@mail.gmail.com>
	<4D9F26A3.6060609@gmail.com>
Message-ID: <77EB52C6DD32BA4D87471DCD70C8D700041B2D45@NA-PA-VBE03.na.tibco.com>

> -----Original Message-----
> From: r-devel-bounces at r-project.org 
> [mailto:r-devel-bounces at r-project.org] On Behalf Of Duncan Murdoch
> Sent: Friday, April 08, 2011 8:16 AM
> To: Joshua Ulrich
> Cc: R-devel at r-project.org
> Subject: Re: [Rd] duplicates() function
> 
> On 08/04/2011 11:08 AM, Joshua Ulrich wrote:
> > How about:
> >
> > y<- rep(NA,length(x))
> > y[duplicated(x)]<- match(x[duplicated(x)] ,x)
> 
> That's a nice solution for vectors.  Unfortunately for me, I have a 
> matrix (which duplicated() handles by checking whole rows).  

Does R have a function like match() that treats matrices
and data.frames row-wise, as duplicated() and unique() do?
duplicated() and match() do related things and I've been
annoyed that their methods for non-vectors do not match up
with each other.  (For historical reasons match cannot be
changed, but perhaps a new generic is in order.)

JU's code still would not work on matrices, but a variant could.

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com 


> So a better 
> example that I should have posted would be
> 
> x <-  cbind(1, c(9,7,9,3,7) )
> 
> and I'd still like the same output
> 
> >  duplicated(x)
> [1] FALSE FALSE  TRUE FALSE TRUE
> 
> >  duplicates(x)
> [1] NA NA  1 NA  2
> 
> 
> Duncan Murdoch
> 
> > --
> > Joshua Ulrich  |  FOSS Trading: www.fosstrading.com
> >
> >
> >
> > On Fri, Apr 8, 2011 at 9:59 AM, Duncan 
> Murdoch<murdoch.duncan at gmail.com>  wrote:
> > >  I need a function which is similar to duplicated(), but 
> instead of returning
> > >  TRUE/FALSE, returns indices of which element was 
> duplicated.  That is,
> > >
> > >>  x<- c(9,7,9,3,7)
> > >>  duplicated(x)
> > >  [1] FALSE FALSE  TRUE FALSE TRUE
> > >
> > >>  duplicates(x)
> > >  [1] NA NA  1 NA  2
> > >
> > >  (so that I know that element 3 is a duplicate of element 
> 1, and element 5 is
> > >  a duplicate of element 2, whereas the others were not 
> duplicated according
> > >  to our definition.)
> > >
> > >  Is there a simple way to write this function?  I have  an ugly
> > >  implementation in R that loops over all the values; it 
> would make more sense
> > >  to redo it in C, if there isn't a simple implementation I missed.
> > >
> > >  Duncan Murdoch
> > >
> > >  ______________________________________________
> > >  R-devel at r-project.org mailing list
> > >  https://stat.ethz.ch/mailman/listinfo/r-devel
> > >
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 


From pdalgd at gmail.com  Fri Apr  8 01:42:23 2011
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 8 Apr 2011 01:42:23 +0200
Subject: [Rd] core Matrix package segfaulted on R CMD check --use-gct
In-Reply-To: <633463.74929.qm@web29502.mail.ird.yahoo.com>
References: <633463.74929.qm@web29502.mail.ird.yahoo.com>
Message-ID: <73B98426-75BC-404C-922B-549EEB6DCF94@gmail.com>


On Apr 7, 2011, at 23:57 , Hin-Tak Leung wrote:

> 
> Oh, I am tracking both R and Matrix via git-svn and retrieves all revisions to all branches daily (or at least, regularly). I.e. R svn head.  2.13.0 only forked off recently and most of the trunk<->2.13.0rc differences are so far mostly documentation-related. I could switch to track R 2.13.x branch if you insist.
> 

Please do. It's the branch that is supposed to stabilize during prerelease times.

Also, please check the prerelease tarballs, errors in "make dist" are not caught when building from svn.

-pd


-- 
Peter Dalgaard
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From htl10 at users.sourceforge.net  Fri Apr  8 07:09:49 2011
From: htl10 at users.sourceforge.net (Hin-Tak Leung)
Date: Fri, 8 Apr 2011 06:09:49 +0100 (BST)
Subject: [Rd] core Matrix package segfaulted on R CMD check --use-gct
In-Reply-To: <73B98426-75BC-404C-922B-549EEB6DCF94@gmail.com>
Message-ID: <191025.59368.qm@web29508.mail.ird.yahoo.com>

--- On Fri, 8/4/11, peter dalgaard <pdalgd at gmail.com> wrote:

> On Apr 7, 2011, at 23:57 , Hin-Tak Leung wrote:
> 
> > 
> > Oh, I am tracking both R and Matrix via git-svn and
> retrieves all revisions to all branches daily (or at least,
> regularly). I.e. R svn head.? 2.13.0 only forked off
> recently and most of the trunk<->2.13.0rc differences
> are so far mostly documentation-related. I could switch to
> track R 2.13.x branch if you insist.
> > 
> 
> Please do. It's the branch that is supposed to stabilize
> during prerelease times.
> 
> Also, please check the prerelease tarballs, errors in "make
> dist" are not caught when building from svn.

Just so that there is no doubt, here is the recipe with the latest rc tar ball, cutting-and-pasting from my command history:

wget -m http://cran.r-project.org/src/base-prerelease/R-rc_2011-04-07_r55373.tar.gz
cd /tmp
tar -zxpvf ~/cran.r-project.org/src/base-prerelease/R-rc_2011-04-07_r55373.tar.gz
cd R-rc/
export DEFS='-DUSE_TYPE_CHECKING_STRICT -DR_MEMORY_PROFILING' ; ./configure  --enable-memory-profiling --enable-strict-barrier --enable-byte-compiled-packages --with-valgrind-instrumentation=2  ; make
cd src/library/
cd Recommended/
../../../bin/R CMD check --use-gct Matrix_0.999375-49.tar.gz

------------------------------
...
Running examples in ?Matrix-Ex.R? failed
The error occurred in:


R version 2.13.0 RC (2011-04-07 r55373)
Copyright (C) 2011 The R Foundation for Statistical Computing
ISBN 3-900051-07-0
Platform: x86_64-unknown-linux-gnu (64-bit)
...
> pkgname <- "Matrix"
> source(file.path(R.home("share"), "R", "examples-header.R"))
> gctorture(TRUE)
> options(warn = 1)
> library('Matrix')
Loading required package: lattice
Error in regexpr("package:", envName, fixed = TRUE) : 
  unprotected object (0x3be2ba8) encountered (was INTSXP)
Error: package/namespace load failed for 'Matrix'
Execution halted
-------------------------



From hpages at fhcrc.org  Fri Apr  8 20:55:58 2011
From: hpages at fhcrc.org (=?ISO-8859-1?Q?Herv=E9_Pag=E8s?=)
Date: Fri, 08 Apr 2011 11:55:58 -0700
Subject: [Rd] question about assignment warnings for replacement methods
In-Reply-To: <4D9B5C5B.2020209@gmail.com>
References: <4D9B56AB.2020403@fhcrc.org> <4D9B5C5B.2020209@gmail.com>
Message-ID: <4D9F5A3E.7030305@fhcrc.org>

Hi Duncan, Marc,

On 11-04-05 11:15 AM, Duncan Murdoch wrote:
> On 05/04/2011 1:51 PM, Marc Carlson wrote:
>> Hi,
>>
>> I have seen several packages that with the most recent version of R are
>> giving a warning like this:
>>
>> Assignments in \usage in documentation object 'marginalData-methods':
>> marginalData(object) = value
>>
>> I assume that this is to prevent people from making assignments in their
>> usage statements (which seems completely understandable). But what
>> about the case above? This is a person who just wants to show the
>> proper usage for a replacement method. IOW they just want to write
>> something that looks like what you actually do when you use a
>> replacement method. They just want to show users how to do something
>> like this:
>>
>> replacementMethod(object)<- newValue
>>
>>
>> So is that really something that should not be allowed in a usage
>> statement?
>
> If replacementMethod was a replacement function, then
>
> replacementMethod(object)<- newValue
>
> is supposed to be fine.

Yes, 'replacementMethod(object) <- newValue' vorks indeed, but
not 'replacementMethod(object) = newValue'.

> But if it is an S3 method, it should be
>
> \method{replacementMethod}{class}(object)<- newValue
>
> and if it is an S4 method I think it should be
>
> \S4method{replacementMethod}{signature_list}(object)<- newValue

In the case reported by Marc, replacementMethod was both: a
replacement (generic) function and a replacement method. And the
man page had an alias for both. Marc replaced

   replacementMethod(object) = newValue

with

   \S4method{replacementMethod}{signature_list}(object)<- newValue

and that solved the problem. But replacing '=' with '<-' solves it too.

Shouldn't 'R CMD check' treat the 2 assignment operators the same way
since they are equivalent?

Thanks!
H.

>
> (though the manual suggests using the S3 style, I'm not sure how
> literally to take it).
>
> Duncan Murdoch
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M2-B876
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fhcrc.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From simon.urbanek at r-project.org  Fri Apr  8 22:05:25 2011
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Fri, 8 Apr 2011 16:05:25 -0400
Subject: [Rd] question about assignment warnings for replacement methods
In-Reply-To: <4D9F5A3E.7030305@fhcrc.org>
References: <4D9B56AB.2020403@fhcrc.org> <4D9B5C5B.2020209@gmail.com>
	<4D9F5A3E.7030305@fhcrc.org>
Message-ID: <A47FDE88-AC38-4CFC-B588-204F61283ABC@r-project.org>


On Apr 8, 2011, at 2:55 PM, Herv? Pag?s wrote:

> Hi Duncan, Marc,
> 
> On 11-04-05 11:15 AM, Duncan Murdoch wrote:
>> On 05/04/2011 1:51 PM, Marc Carlson wrote:
>>> Hi,
>>> 
>>> I have seen several packages that with the most recent version of R are
>>> giving a warning like this:
>>> 
>>> Assignments in \usage in documentation object 'marginalData-methods':
>>> marginalData(object) = value
>>> 
>>> I assume that this is to prevent people from making assignments in their
>>> usage statements (which seems completely understandable). But what
>>> about the case above? This is a person who just wants to show the
>>> proper usage for a replacement method. IOW they just want to write
>>> something that looks like what you actually do when you use a
>>> replacement method. They just want to show users how to do something
>>> like this:
>>> 
>>> replacementMethod(object)<- newValue
>>> 
>>> 
>>> So is that really something that should not be allowed in a usage
>>> statement?
>> 
>> If replacementMethod was a replacement function, then
>> 
>> replacementMethod(object)<- newValue
>> 
>> is supposed to be fine.
> 
> Yes, 'replacementMethod(object) <- newValue' vorks indeed, but
> not 'replacementMethod(object) = newValue'.
> 
>> But if it is an S3 method, it should be
>> 
>> \method{replacementMethod}{class}(object)<- newValue
>> 
>> and if it is an S4 method I think it should be
>> 
>> \S4method{replacementMethod}{signature_list}(object)<- newValue
> 
> In the case reported by Marc, replacementMethod was both: a
> replacement (generic) function and a replacement method. And the
> man page had an alias for both. Marc replaced
> 
>  replacementMethod(object) = newValue
> 
> with
> 
>  \S4method{replacementMethod}{signature_list}(object)<- newValue
> 
> and that solved the problem. But replacing '=' with '<-' solves it too.
> 
> Shouldn't 'R CMD check' treat the 2 assignment operators the same way
> since they are equivalent?
> 

They are not equivalent (you can't use = in many places where you can use <-).

Also my understanding is that it is considered bad practice by some to use = as assignment outside of the command prompt (interactive use) -- but opinions vary and I don't want to start a flame war here ;).

Cheers,
Simon



> Thanks!
> H.
> 
>> 
>> (though the manual suggests using the S3 style, I'm not sure how
>> literally to take it).
>> 
>> Duncan Murdoch
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 
> -- 
> Herv? Pag?s
> 
> Program in Computational Biology
> Division of Public Health Sciences
> Fred Hutchinson Cancer Research Center
> 1100 Fairview Ave. N, M2-B876
> P.O. Box 19024
> Seattle, WA 98109-1024
> 
> E-mail: hpages at fhcrc.org
> Phone:  (206) 667-5791
> Fax:    (206) 667-1319
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From friendly at yorku.ca  Fri Apr  8 22:39:11 2011
From: friendly at yorku.ca (Michael Friendly)
Date: Fri, 08 Apr 2011 16:39:11 -0400
Subject: [Rd] Consistency of messages from R CMD {check,build,install}
Message-ID: <4D9F726F.2020600@yorku.ca>

A minor gripe/request:  Could all R CMD package tools not at the very 
least be consistent in indicating when
they are done, as in
* DONE (packagename)
or at least
* DONE

R CMD build leaves one hanging, not knowing whether it has completed or 
it is time to get another coffee.

* checking for file 'C:/Documents/workspace/heplots/DESCRIPTION' ... OK
* preparing 'heplots':
* checking DESCRIPTION meta-information ... OK
* installing the package to re-build vignettes
* creating vignettes ... OK
* checking for LF line-endings in source and make files
* checking for empty or unneeded directories
* building 'heplots_0.9-8.tar.gz'

Some checking/building processes take a while, so it would also be nice 
if more of the info lines
ended with ... OK

tia,
-Michael


-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept.
York University      Voice: 416 736-5115 x66249 Fax: 416 736-5814
4700 Keele Street    Web:   http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA


From john.maindonald at anu.edu.au  Sat Apr  9 07:38:28 2011
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Sat, 9 Apr 2011 15:38:28 +1000
Subject: [Rd] Compression of largish expression array files in the
	DAAGbio/inst/doc directory?
Message-ID: <51284363-243E-40B3-933A-B28F05986CBD@anu.edu.au>

The inst/doc directory of the DAAG package has 6 files coral551.spot, ... that
are around 0.85 MB each.  It would be useful to be able to zip then, but that
as matters stand interferes with the use of the Sweave file that uses them to
demonstrate input of expression array data that is in the "spot" format.  They
do not automatically get unzipped when required.  I have checked that 
read.maimages (in limma) does not, unless I have missed something, have 
an option for reading zipped files.  Is there any way to get around this without
substantially complicating the exposition in marray-notes.pdf (also in the
inst/doc subdirectory)?

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.
http://www.maths.anu.edu.au/~johnm


From ripley at stats.ox.ac.uk  Sat Apr  9 08:58:41 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 9 Apr 2011 07:58:41 +0100 (BST)
Subject: [Rd] Compression of largish expression array files in the
 DAAGbio/inst/doc directory?
In-Reply-To: <51284363-243E-40B3-933A-B28F05986CBD@anu.edu.au>
References: <51284363-243E-40B3-933A-B28F05986CBD@anu.edu.au>
Message-ID: <alpine.LFD.2.02.1104090748410.21478@gannet.stats.ox.ac.uk>

As far as I can see read.maimages is built on top of R's own 
file-reading facilties, and they all read compressed (but not zipped) 
files as from R 2.10.0.

So simply use

gzip -9 coral55?.spot

and rename the files back to *.spot.

If you need more compression, use xz -9e.  (You can also do this in R: 
readLines() on the file, writeLines() using gzfile or xzfile.)

You will need to make the package 'Depends: R (>= 2.10)'.

On Sat, 9 Apr 2011, John Maindonald wrote:

> The inst/doc directory of the DAAG package has 6 files coral551.spot, ... that
> are around 0.85 MB each.  It would be useful to be able to zip then, but that
> as matters stand interferes with the use of the Sweave file that uses them to
> demonstrate input of expression array data that is in the "spot" format.  They
> do not automatically get unzipped when required.  I have checked that
> read.maimages (in limma) does not, unless I have missed something, have
> an option for reading zipped files.  Is there any way to get around this without
> substantially complicating the exposition in marray-notes.pdf (also in the
> inst/doc subdirectory)?
>
> John Maindonald             email: john.maindonald at anu.edu.au
> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
> Centre for Mathematics & Its Applications, Room 1194,
> John Dedman Mathematical Sciences Building (Building 27)
> Australian National University, Canberra ACT 0200.
> http://www.maths.anu.edu.au/~johnm
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From john.maindonald at anu.edu.au  Sat Apr  9 10:17:21 2011
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Sat, 9 Apr 2011 18:17:21 +1000
Subject: [Rd] Compression of largish expression array files in the
	DAAGbio/inst/doc directory?
In-Reply-To: <alpine.LFD.2.02.1104090748410.21478@gannet.stats.ox.ac.uk>
References: <51284363-243E-40B3-933A-B28F05986CBD@anu.edu.au>
	<alpine.LFD.2.02.1104090748410.21478@gannet.stats.ox.ac.uk>
Message-ID: <D8631AAC-09D4-4995-92BF-CF9A0F9D93D0@anu.edu.au>

Thanks.  That seems to work.

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.
http://www.maths.anu.edu.au/~johnm

On 09/04/2011, at 4:58 PM, Prof Brian Ripley wrote:

> As far as I can see read.maimages is built on top of R's own file-reading facilties, and they all read compressed (but not zipped) files as from R 2.10.0.
> 
> So simply use
> 
> gzip -9 coral55?.spot
> 
> and rename the files back to *.spot.
> 
> If you need more compression, use xz -9e.  (You can also do this in R: readLines() on the file, writeLines() using gzfile or xzfile.)
> 
> You will need to make the package 'Depends: R (>= 2.10)'.
> 
> On Sat, 9 Apr 2011, John Maindonald wrote:
> 
>> The inst/doc directory of the DAAG package has 6 files coral551.spot, ... that
>> are around 0.85 MB each.  It would be useful to be able to zip then, but that
>> as matters stand interferes with the use of the Sweave file that uses them to
>> demonstrate input of expression array data that is in the "spot" format.  They
>> do not automatically get unzipped when required.  I have checked that
>> read.maimages (in limma) does not, unless I have missed something, have
>> an option for reading zipped files.  Is there any way to get around this without
>> substantially complicating the exposition in marray-notes.pdf (also in the
>> inst/doc subdirectory)?
>> 
>> John Maindonald             email: john.maindonald at anu.edu.au
>> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
>> Centre for Mathematics & Its Applications, Room 1194,
>> John Dedman Mathematical Sciences Building (Building 27)
>> Australian National University, Canberra ACT 0200.
>> http://www.maths.anu.edu.au/~johnm
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> 
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From matteo at naufraghi.net  Sat Apr  9 12:25:24 2011
From: matteo at naufraghi.net (Matteo Bertini)
Date: Sat, 9 Apr 2011 12:25:24 +0200
Subject: [Rd] stats/arima.c memory allocation
Message-ID: <BANLkTinAQFOy+BUkqKtwZs2OyofiZ5iedQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110409/64f9714b/attachment.pl>

From savicky at cs.cas.cz  Sat Apr  9 20:09:34 2011
From: savicky at cs.cas.cz (Petr Savicky)
Date: Sat, 9 Apr 2011 20:09:34 +0200
Subject: [Rd] duplicates() function
In-Reply-To: <4D9F22BE.5000502@gmail.com>
References: <bug-14552-16@http.bugs.r-project.org/bugzilla3/>
	<20110408142610.88AEC970477@ix.urbanek.info>
	<B722DD6C-3B97-46EC-B369-8316F0F65D1F@cbs.dk>
	<4D9F22BE.5000502@gmail.com>
Message-ID: <20110409180934.GA27481@cs.cas.cz>

On Fri, Apr 08, 2011 at 10:59:10AM -0400, Duncan Murdoch wrote:
> I need a function which is similar to duplicated(), but instead of 
> returning TRUE/FALSE, returns indices of which element was duplicated.  
> That is,
> 
> > x <- c(9,7,9,3,7)
> > duplicated(x)
> [1] FALSE FALSE  TRUE FALSE TRUE
> 
> > duplicates(x)
> [1] NA NA  1 NA  2
> 
> (so that I know that element 3 is a duplicate of element 1, and element 
> 5 is a duplicate of element 2, whereas the others were not duplicated 
> according to our definition.)
> 
> Is there a simple way to write this function?

A possible strategy is to use sorting. In a sorted matrix
or data frame, the elements, which are duplicates of the
same element, form consecutive blocks. These blocks may
be identified using !duplicated(), which determines the
first elements of these blocks. Since sorting is stable,
when we map these blocks back to the original order, the
first element of each block is mapped to the first ocurrence
of the given row in the original order.

An implementation may be done as follows.

  duplicates <- function(dat)
  {
      s <- do.call("order", as.data.frame(dat))
      non.dup <- !duplicated(dat[s, ])
      orig.ind <- s[non.dup]
      first.occ <- orig.ind[cumsum(non.dup)]
      first.occ[non.dup] <- NA
      first.occ[order(s)]
  }
 
  x <-  cbind(1, c(9,7,9,3,7) )
  duplicates(x)
  [1] NA NA  1 NA  2

The line

      orig.ind <- s[non.dup]

creates a vector, whose length is the number of non-duplicated
rows in the sorted "dat". Its components are indices of the
corresponding first occurrences of these rows in the original
order. For this, the stability of the order is needed.

The lines

      first.occ <- orig.ind[cumsum(non.dup)]
      first.occ[non.dup] <- NA

expand orig.ind to a vector, which satisfies: If i-th row of the
sorted "dat" is duplicated, then first.occ[i] is the index of the
first row in the original "dat", which is equal to this row. So, the
values in first.occ are those, which are required for the output
of duplicates(), but they are in the order of the sorted "dat". The
last line 

  first.occ[order(s)]

reorders the vector to the original order of the rows.

Petr Savicky.


From pauljohn32 at gmail.com  Sat Apr  9 21:51:34 2011
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Sat, 9 Apr 2011 14:51:34 -0500
Subject: [Rd] Wish there were a "strict mode" for R interpreter. What about
	You?
Message-ID: <BANLkTim=6ae2huv+GYQLMtgs2P+GD8_WtA@mail.gmail.com>

Years ago, I did lots of Perl programming. Perl will let you be lazy
and write functions that refer to undefined variables (like R does),
but there is also a strict mode so the interpreter will block anything
when a variable is mentioned that has not been defined. I wish there
were a strict mode for checking R functions.

Here's why. We have a lot of students writing R functions around here
and they run into trouble because they use the same name for things
inside and outside of functions. When they call functions that have
mistaken or undefined references to names that they use elsewhere,
then variables that are in the environment are accidentally used. Know
what I mean?

dat <- whatever

someNewFunction <- function(z, w){
   #do something with z and w and create a new "dat"
   # but forget to name it "dat"
    lm (y, x, data=dat)
   # lm just used wrong data
}

I wish R had a strict mode to return an error in that case. Users
don't realize they are getting nonsense because R finds things to fill
in for their mistakes.

Is this possible?  Does anybody agree it would be good?

-- 
Paul E. Johnson
Professor, Political Science
1541 Lilac Lane, Room 504
University of Kansas


From murdoch.duncan at gmail.com  Sat Apr  9 22:37:28 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 09 Apr 2011 16:37:28 -0400
Subject: [Rd] Wish there were a "strict mode" for R interpreter. What
 about You?
In-Reply-To: <BANLkTim=6ae2huv+GYQLMtgs2P+GD8_WtA@mail.gmail.com>
References: <BANLkTim=6ae2huv+GYQLMtgs2P+GD8_WtA@mail.gmail.com>
Message-ID: <4DA0C388.8080401@gmail.com>

On 11-04-09 3:51 PM, Paul Johnson wrote:
> Years ago, I did lots of Perl programming. Perl will let you be lazy
> and write functions that refer to undefined variables (like R does),
> but there is also a strict mode so the interpreter will block anything
> when a variable is mentioned that has not been defined. I wish there
> were a strict mode for checking R functions.
>
> Here's why. We have a lot of students writing R functions around here
> and they run into trouble because they use the same name for things
> inside and outside of functions. When they call functions that have
> mistaken or undefined references to names that they use elsewhere,
> then variables that are in the environment are accidentally used. Know
> what I mean?
>
> dat<- whatever
>
> someNewFunction<- function(z, w){
>     #do something with z and w and create a new "dat"
>     # but forget to name it "dat"
>      lm (y, x, data=dat)
>     # lm just used wrong data
> }
>
> I wish R had a strict mode to return an error in that case. Users
> don't realize they are getting nonsense because R finds things to fill
> in for their mistakes.
>
> Is this possible?  Does anybody agree it would be good?
>

It would be really bad, unless done carefully.

In your function the free (undefined) variables are dat and lm.  You 
want to be warned about dat, but you don't want to be warned about lm. 
What rule should R use to determine that?

(One possible rule would work in a package with a namespace.  In that 
case, all variables must be found in declared dependencies, the search 
could stop before it got to globalenv().  But it seems unlikely that 
your students are writing packages with namespaces.)

Duncan Murdoch


From murdoch.duncan at gmail.com  Sat Apr  9 22:40:59 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 09 Apr 2011 16:40:59 -0400
Subject: [Rd] Rtools questions
In-Reply-To: <BANLkTinf8=4N7Fsff757NEi77Jor4yGD5A@mail.gmail.com>
References: <4D9B963E.9070501@structuremonitoring.com>
	<4D9B9B41.5070401@gmail.com>
	<BANLkTi=tnhAEqOtun=yVUD=fp0KOaatWQg@mail.gmail.com>
	<4D9C546F.5030706@gmail.com>
	<BANLkTinf8=4N7Fsff757NEi77Jor4yGD5A@mail.gmail.com>
Message-ID: <4DA0C45B.6080809@gmail.com>

On 11-04-06 2:45 PM, Henrik Bengtsson wrote:
> On Wed, Apr 6, 2011 at 4:54 AM, Duncan Murdoch<murdoch.duncan at gmail.com>  wrote:
>> On 11-04-05 7:51 PM, Henrik Bengtsson wrote:
>>> On Tue, Apr 5, 2011 at 3:44 PM, Duncan Murdoch<murdoch.duncan at gmail.com>
>>>   wrote:
>>>> On 11-04-05 6:22 PM, Spencer Graves wrote:
>>>>>
>>>>> Hello:
>>>>>
>>>>>
>>>>>          1.  How can I tell when the development version of Rtools has
>>>>> changed?
>>>>
>>>> I don't make announcements of the changes, you just need to check the web
>>>> site.  There are online tools that can do this for you automatically, but
>>>> I
>>>> don't know which one to recommend.  Google suggests lots of them.
>>>
>>> I also asked myself this before and I must admit it took me a while to
>>> interpret the contents of the webpage.  There are multiple sections,
>>> e.g. 'Changes since R 2.12.2', 'Changes since R 2.11.1', 'Changes
>>> since R 2.11.0', and so on.  Then within each section there are some
>>> dates mentioned.  Given my current R version (say R 2.13.0 beta) and
>>> Rtools (Rtools213.exe), it not fully clear to me which section to look
>>> at, e.g. 'Changes since R 2.12.2'?
>>
>> Well, that depends on when you downloaded it.  I use the R version releases
>> as bookmarks.  If you last downloaded Rtools after the release of R 2.12.2,
>> then you only need to look at the last section.
>>
>> The problem with collecting changes into those that apply to each Rtools
>> version is just that the change lists would be longer:  Rtools212 will get
>> changes through several R releases.  When there are compiler changes,
>> RtoolsXYZ generally comes out during the previous R version, because the
>> compiler may only work with the R-devel version.  For instance, Rtools212
>> was introduced between R 2.11.0 and 2.11.1 and was updated a number of times
>> up to quite recently.  (It is now frozen, so if you download it now and are
>> working with the R versions it supports you never need to worry about
>> updates to it.)
>
> I understand, and I suspected this was the reason too.
>
>>
>> However, if you want to reformat the page, go ahead, and send me the new
>> version.  It's a hand edited HTML page so I'd be happy to incorporate
>> changes that make it more readable, as long as it's still easy to edit by
>> hand.
>>
>> Gabor asked how to know which version was downloaded.  If you have the
>> installer file you can tell:  right click on it, choose Properties, look at
>> the Version tab.  If you didn't keep the installer, I don't know a way to
>> find out, but it might be recorded in the unins000.dat file that the
>> uninstaller uses.  Of course, without downloading the new one you can't find
>> out its version:  so back to my original suggestion to monitor changes to
>> the web page.  I'll see if there's a way to automatically include the
>> revision number in the filename.
>
> This is useful - I didn't know about this version number of InnoSetup.
>   I've browsed the online InnoSetup help, but I couldn't locate what
> the version parameter is called.  With it, would it be possible to use
> a [Code] block having InnoSetup write the version number to a VERSION
> file in the Rtools installation directory?  That would make it
> possible to compare what's online and what's installed.
>
> Another alternative for figuring out if Rtools have changed would be
> to compare the timestamp of the installed Rtools directory (because
> you typically install immediately after download) and the
> Rtools213.exe timestamp on the web server.  This could be achieved by
> moving the files to, say,
> http://www.murdoch-sutherland.com/Rtools/download/ and enable indexing
> of files in that directory.
>
> Either way, know about the version number is certainly good enough for
> me.  After installing Rtools, I can simply put the installer file in
> the Rtools directory to allow me to compare to it later. (I kind of
> did this before by comparing file sizes.)

I've just uploaded a small change:  now Rtools.txt records the version 
number (and if I remember to update it, you can download only that file 
to see if you are up to date).  There's also a VERSION.txt file that 
contains the version number, which is likely to maintain its format more 
consistently, so if you want an automatic check, you should look at that 
file.  It's also on the web site.

Duncan Murdoch


From ted.harding at wlandres.net  Sat Apr  9 23:08:13 2011
From: ted.harding at wlandres.net ( (Ted Harding))
Date: Sat, 09 Apr 2011 22:08:13 +0100 (BST)
Subject: [Rd] Wish there were a "strict mode" for R interpreter. What
In-Reply-To: <4DA0C388.8080401@gmail.com>
Message-ID: <XFMail.110409220813.ted.harding@wlandres.net>

On 09-Apr-11 20:37:28, Duncan Murdoch wrote:
> On 11-04-09 3:51 PM, Paul Johnson wrote:
>> Years ago, I did lots of Perl programming. Perl will let you be lazy
>> and write functions that refer to undefined variables (like R does),
>> but there is also a strict mode so the interpreter will block anything
>> when a variable is mentioned that has not been defined. I wish there
>> were a strict mode for checking R functions.
>>
>> Here's why. We have a lot of students writing R functions around here
>> and they run into trouble because they use the same name for things
>> inside and outside of functions. When they call functions that have
>> mistaken or undefined references to names that they use elsewhere,
>> then variables that are in the environment are accidentally used. Know
>> what I mean?
>>
>> dat<- whatever
>>
>> someNewFunction<- function(z, w){
>>     #do something with z and w and create a new "dat"
>>     # but forget to name it "dat"
>>      lm (y, x, data=dat)
>>     # lm just used wrong data
>> }
>>
>> I wish R had a strict mode to return an error in that case. Users
>> don't realize they are getting nonsense because R finds things to fill
>> in for their mistakes.
>>
>> Is this possible?  Does anybody agree it would be good?
>>
> 
> It would be really bad, unless done carefully.
> 
> In your function the free (undefined) variables are dat and lm.  You 
> want to be warned about dat, but you don't want to be warned about lm. 
> What rule should R use to determine that?
> 
> (One possible rule would work in a package with a namespace.  In that 
> case, all variables must be found in declared dependencies, the search 
> could stop before it got to globalenv().  But it seems unlikely that 
> your students are writing packages with namespaces.)
> 
> Duncan Murdoch

I'm with Duncan on this one! On the other hand, I can understand the
issues that Paul's students might encounter.

I think the right thing to so is to introduce the students to the
basics of scoping, early in the process of learning R.

Thus, when there is a variable (such as 'lm' in the example) which
you *expect* to already be out there (since 'lm' is in 'stats'
which is pre-loaded by default), then you can go ahead and use it.

But when your function uses a variable (e.g. 'dat') which just
*happened* to be out there when you first wrote the function,
then when you re-use the same function definition in a different
context things are likely to go wrong. So teach them that variables
which occur in functions, which might have any meaning in whatever
the context of use may be, should either be named arguments in
the argument list, or should be specifically defined within the
function, and not assumed to already exist unless that is already
guaranteed in every context in which the function would be used.

This is basic good practice which, once routinely adopted, should
ensure that the right thing is done every time!

Ted.

--------------------------------------------------------------------
E-Mail: (Ted Harding) <ted.harding at wlandres.net>
Fax-to-email: +44 (0)870 094 0861
Date: 09-Apr-11                                       Time: 22:08:10
------------------------------ XFMail ------------------------------


From hadley at rice.edu  Sat Apr  9 23:31:07 2011
From: hadley at rice.edu (Hadley Wickham)
Date: Sat, 9 Apr 2011 16:31:07 -0500
Subject: [Rd] Wish there were a "strict mode" for R interpreter. What
 about You?
In-Reply-To: <BANLkTim=6ae2huv+GYQLMtgs2P+GD8_WtA@mail.gmail.com>
References: <BANLkTim=6ae2huv+GYQLMtgs2P+GD8_WtA@mail.gmail.com>
Message-ID: <BANLkTinJO=3Epmq_2zH+3vbGmZgPp_gFGA@mail.gmail.com>

On Sat, Apr 9, 2011 at 2:51 PM, Paul Johnson <pauljohn32 at gmail.com> wrote:
> Years ago, I did lots of Perl programming. Perl will let you be lazy
> and write functions that refer to undefined variables (like R does),
> but there is also a strict mode so the interpreter will block anything
> when a variable is mentioned that has not been defined. I wish there
> were a strict mode for checking R functions.
>
> Here's why. We have a lot of students writing R functions around here
> and they run into trouble because they use the same name for things
> inside and outside of functions. When they call functions that have
> mistaken or undefined references to names that they use elsewhere,
> then variables that are in the environment are accidentally used. Know
> what I mean?
>
> dat <- whatever
>
> someNewFunction <- function(z, w){
> ? #do something with z and w and create a new "dat"
> ? # but forget to name it "dat"
> ? ?lm (y, x, data=dat)
> ? # lm just used wrong data
> }
>
> I wish R had a strict mode to return an error in that case. Users
> don't realize they are getting nonsense because R finds things to fill
> in for their mistakes.
>
> Is this possible? ?Does anybody agree it would be good?


> library(codetools)
> checkUsage(someNewFunction)
<anonymous>: no visible binding for global variable ?y?
<anonymous>: no visible binding for global variable ?x?
<anonymous>: no visible binding for global variable ?dat?

Which also picks up another bug in your function ;)

Hadley

-- 
Assistant Professor / Dobelman Family Junior Chair
Department of Statistics / Rice University
http://had.co.nz/


From spencer.graves at prodsyse.com  Sun Apr 10 01:02:42 2011
From: spencer.graves at prodsyse.com (Spencer Graves)
Date: Sat, 09 Apr 2011 16:02:42 -0700
Subject: [Rd] Wish there were a "strict mode" for R interpreter. What
 about You?
In-Reply-To: <BANLkTinJO=3Epmq_2zH+3vbGmZgPp_gFGA@mail.gmail.com>
References: <BANLkTim=6ae2huv+GYQLMtgs2P+GD8_WtA@mail.gmail.com>
	<BANLkTinJO=3Epmq_2zH+3vbGmZgPp_gFGA@mail.gmail.com>
Message-ID: <4DA0E592.1040507@prodsyse.com>

On 4/9/2011 2:31 PM, Hadley Wickham wrote:
> On Sat, Apr 9, 2011 at 2:51 PM, Paul Johnson<pauljohn32 at gmail.com>  wrote:
>> Years ago, I did lots of Perl programming. Perl will let you be lazy
>> and write functions that refer to undefined variables (like R does),
>> but there is also a strict mode so the interpreter will block anything
>> when a variable is mentioned that has not been defined. I wish there
>> were a strict mode for checking R functions.
>>
>> Here's why. We have a lot of students writing R functions around here
>> and they run into trouble because they use the same name for things
>> inside and outside of functions. When they call functions that have
>> mistaken or undefined references to names that they use elsewhere,
>> then variables that are in the environment are accidentally used. Know
>> what I mean?
>>
>> dat<- whatever
>>
>> someNewFunction<- function(z, w){
>>    #do something with z and w and create a new "dat"
>>    # but forget to name it "dat"
>>     lm (y, x, data=dat)
>>    # lm just used wrong data
>> }
>>
>> I wish R had a strict mode to return an error in that case. Users
>> don't realize they are getting nonsense because R finds things to fill
>> in for their mistakes.
>>
>> Is this possible?  Does anybody agree it would be good?
>
>> library(codetools)
>> checkUsage(someNewFunction)
> <anonymous>: no visible binding for global variable ?y?
> <anonymous>: no visible binding for global variable ?x?
> <anonymous>: no visible binding for global variable ?dat?
>
> Which also picks up another bug in your function ;)

       Is this run by "R CMD check"?  I've seen this message.


       "R CMD check" will give this message sometimes when I don't feel 
it's appropriate.  For example, I define a data object ETB in a package, 
then give that as the default in a function call like 
f(data.=ETB){if(missing(data.))data(ETB);  data.}.  When I run "R CMD 
check", I get "no visible binding for global variable 'ETB'", even 
though the function is tested and works during R CMD check.


       Spencer

> Hadley
>


-- 
Spencer Graves, PE, PhD
President and Chief Operating Officer
Structure Inspection and Monitoring, Inc.
751 Emerson Ct.
San Jos?, CA 95126
ph:  408-655-4567


From murdoch.duncan at gmail.com  Sun Apr 10 03:12:48 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 09 Apr 2011 21:12:48 -0400
Subject: [Rd] Wish there were a "strict mode" for R interpreter. What
 about You?
In-Reply-To: <4DA0E592.1040507@prodsyse.com>
References: <BANLkTim=6ae2huv+GYQLMtgs2P+GD8_WtA@mail.gmail.com>	<BANLkTinJO=3Epmq_2zH+3vbGmZgPp_gFGA@mail.gmail.com>
	<4DA0E592.1040507@prodsyse.com>
Message-ID: <4DA10410.2040909@gmail.com>

On 11-04-09 7:02 PM, Spencer Graves wrote:
> On 4/9/2011 2:31 PM, Hadley Wickham wrote:
>> On Sat, Apr 9, 2011 at 2:51 PM, Paul Johnson<pauljohn32 at gmail.com>   wrote:
>>> Years ago, I did lots of Perl programming. Perl will let you be lazy
>>> and write functions that refer to undefined variables (like R does),
>>> but there is also a strict mode so the interpreter will block anything
>>> when a variable is mentioned that has not been defined. I wish there
>>> were a strict mode for checking R functions.
>>>
>>> Here's why. We have a lot of students writing R functions around here
>>> and they run into trouble because they use the same name for things
>>> inside and outside of functions. When they call functions that have
>>> mistaken or undefined references to names that they use elsewhere,
>>> then variables that are in the environment are accidentally used. Know
>>> what I mean?
>>>
>>> dat<- whatever
>>>
>>> someNewFunction<- function(z, w){
>>>     #do something with z and w and create a new "dat"
>>>     # but forget to name it "dat"
>>>      lm (y, x, data=dat)
>>>     # lm just used wrong data
>>> }
>>>
>>> I wish R had a strict mode to return an error in that case. Users
>>> don't realize they are getting nonsense because R finds things to fill
>>> in for their mistakes.
>>>
>>> Is this possible?  Does anybody agree it would be good?
>>
>>> library(codetools)
>>> checkUsage(someNewFunction)
>> <anonymous>: no visible binding for global variable ?y?
>> <anonymous>: no visible binding for global variable ?x?
>> <anonymous>: no visible binding for global variable ?dat?
>>
>> Which also picks up another bug in your function ;)
>
>         Is this run by "R CMD check"?  I've seen this message.
>
>
>         "R CMD check" will give this message sometimes when I don't feel
> it's appropriate.  For example, I define a data object ETB in a package,
> then give that as the default in a function call like
> f(data.=ETB){if(missing(data.))data(ETB);  data.}.  When I run "R CMD
> check", I get "no visible binding for global variable 'ETB'", even
> though the function is tested and works during R CMD check.

What is ETB?  Your code is looking for a global variable by that name, 
and that's what codetools is telling you.

Duncan Murdoch


From spencer.graves at prodsyse.com  Sun Apr 10 03:21:32 2011
From: spencer.graves at prodsyse.com (Spencer Graves)
Date: Sat, 09 Apr 2011 18:21:32 -0700
Subject: [Rd] Wish there were a "strict mode" for R interpreter. What
 about You?
In-Reply-To: <4DA10410.2040909@gmail.com>
References: <BANLkTim=6ae2huv+GYQLMtgs2P+GD8_WtA@mail.gmail.com>	<BANLkTinJO=3Epmq_2zH+3vbGmZgPp_gFGA@mail.gmail.com>
	<4DA0E592.1040507@prodsyse.com> <4DA10410.2040909@gmail.com>
Message-ID: <4DA1061C.50405@prodsyse.com>

On 4/9/2011 6:12 PM, Duncan Murdoch wrote:
> On 11-04-09 7:02 PM, Spencer Graves wrote:
>> On 4/9/2011 2:31 PM, Hadley Wickham wrote:
>>> On Sat, Apr 9, 2011 at 2:51 PM, Paul Johnson<pauljohn32 at gmail.com>   
>>> wrote:
>>>> Years ago, I did lots of Perl programming. Perl will let you be lazy
>>>> and write functions that refer to undefined variables (like R does),
>>>> but there is also a strict mode so the interpreter will block anything
>>>> when a variable is mentioned that has not been defined. I wish there
>>>> were a strict mode for checking R functions.
>>>>
>>>> Here's why. We have a lot of students writing R functions around here
>>>> and they run into trouble because they use the same name for things
>>>> inside and outside of functions. When they call functions that have
>>>> mistaken or undefined references to names that they use elsewhere,
>>>> then variables that are in the environment are accidentally used. Know
>>>> what I mean?
>>>>
>>>> dat<- whatever
>>>>
>>>> someNewFunction<- function(z, w){
>>>>     #do something with z and w and create a new "dat"
>>>>     # but forget to name it "dat"
>>>>      lm (y, x, data=dat)
>>>>     # lm just used wrong data
>>>> }
>>>>
>>>> I wish R had a strict mode to return an error in that case. Users
>>>> don't realize they are getting nonsense because R finds things to fill
>>>> in for their mistakes.
>>>>
>>>> Is this possible?  Does anybody agree it would be good?
>>>
>>>> library(codetools)
>>>> checkUsage(someNewFunction)
>>> <anonymous>: no visible binding for global variable ?y?
>>> <anonymous>: no visible binding for global variable ?x?
>>> <anonymous>: no visible binding for global variable ?dat?
>>>
>>> Which also picks up another bug in your function ;)
>>
>>         Is this run by "R CMD check"?  I've seen this message.
>>
>>
>>         "R CMD check" will give this message sometimes when I don't feel
>> it's appropriate.  For example, I define a data object ETB in a package,
>> then give that as the default in a function call like
>> f(data.=ETB){if(missing(data.))data(ETB);  data.}.  When I run "R CMD
>> check", I get "no visible binding for global variable 'ETB'", even
>> though the function is tested and works during R CMD check.
>
> What is ETB?  Your code is looking for a global variable by that name, 
> and that's what codetools is telling you.

Duncan:  Thanks for the question.


ETB is a data object in my package.  codetools can't find it because 
data(ETB) is needed before ETB becomes available.  codetools is not 
smart enough to check to see if ETB is a data object in the package.


Spencer

>
> Duncan Murdoch


-- 
Spencer Graves, PE, PhD
President and Chief Operating Officer
Structure Inspection and Monitoring, Inc.
751 Emerson Ct.
San Jos?, CA 95126
ph:  408-655-4567


From spencer.graves at structuremonitoring.com  Sun Apr 10 03:22:14 2011
From: spencer.graves at structuremonitoring.com (Spencer Graves)
Date: Sat, 09 Apr 2011 18:22:14 -0700
Subject: [Rd] Wish there were a "strict mode" for R interpreter. What
 about You?
In-Reply-To: <4DA10410.2040909@gmail.com>
References: <BANLkTim=6ae2huv+GYQLMtgs2P+GD8_WtA@mail.gmail.com>	<BANLkTinJO=3Epmq_2zH+3vbGmZgPp_gFGA@mail.gmail.com>
	<4DA0E592.1040507@prodsyse.com> <4DA10410.2040909@gmail.com>
Message-ID: <4DA10646.6040202@structuremonitoring.com>

On 4/9/2011 6:12 PM, Duncan Murdoch wrote:
> On 11-04-09 7:02 PM, Spencer Graves wrote:
>> On 4/9/2011 2:31 PM, Hadley Wickham wrote:
>>> On Sat, Apr 9, 2011 at 2:51 PM, Paul Johnson<pauljohn32 at gmail.com>
>>> wrote:
>>>> Years ago, I did lots of Perl programming. Perl will let you be lazy
>>>> and write functions that refer to undefined variables (like R does),
>>>> but there is also a strict mode so the interpreter will block anything
>>>> when a variable is mentioned that has not been defined. I wish there
>>>> were a strict mode for checking R functions.
>>>>
>>>> Here's why. We have a lot of students writing R functions around here
>>>> and they run into trouble because they use the same name for things
>>>> inside and outside of functions. When they call functions that have
>>>> mistaken or undefined references to names that they use elsewhere,
>>>> then variables that are in the environment are accidentally used. Know
>>>> what I mean?
>>>>
>>>> dat<- whatever
>>>>
>>>> someNewFunction<- function(z, w){
>>>>     #do something with z and w and create a new "dat"
>>>>     # but forget to name it "dat"
>>>>      lm (y, x, data=dat)
>>>>     # lm just used wrong data
>>>> }
>>>>
>>>> I wish R had a strict mode to return an error in that case. Users
>>>> don't realize they are getting nonsense because R finds things to fill
>>>> in for their mistakes.
>>>>
>>>> Is this possible?  Does anybody agree it would be good?
>>>
>>>> library(codetools)
>>>> checkUsage(someNewFunction)
>>> <anonymous>: no visible binding for global variable ?y?
>>> <anonymous>: no visible binding for global variable ?x?
>>> <anonymous>: no visible binding for global variable ?dat?
>>>
>>> Which also picks up another bug in your function ;)
>>
>>         Is this run by "R CMD check"?  I've seen this message.
>>
>>
>>         "R CMD check" will give this message sometimes when I don't feel
>> it's appropriate.  For example, I define a data object ETB in a package,
>> then give that as the default in a function call like
>> f(data.=ETB){if(missing(data.))data(ETB);  data.}.  When I run "R CMD
>> check", I get "no visible binding for global variable 'ETB'", even
>> though the function is tested and works during R CMD check.
>
> What is ETB?  Your code is looking for a global variable by that name,
> and that's what codetools is telling you.

Duncan:  Thanks for the question.


ETB is a data object in my package.  codetools can't find it because 
data(ETB) is needed before ETB becomes available.  codetools is not 
smart enough to check to see if ETB is a data object in the package.


Spencer

>
> Duncan Murdoch


-- 
Spencer Graves, PE, PhD
President and Chief Operating Officer
Structure Inspection and Monitoring, Inc.
751 Emerson Ct.
San Jos?, CA 95126
ph:  408-655-4567


From xie at yihui.name  Sun Apr 10 03:43:00 2011
From: xie at yihui.name (Yihui Xie)
Date: Sat, 9 Apr 2011 20:43:00 -0500
Subject: [Rd] deparse operators in expressions
Message-ID: <BANLkTimQLeAeinPnK8JK6nrxANT_knUn0Q@mail.gmail.com>

Hi,

I observed a slight problem in deparse(): it will add spaces around
most operators except /. I wonder if this is easy to fix. I know this
is quite trivial, but I will appreciate if / is not treated as an
exception. Examples:

> deparse(expression(1/1))
[1] "expression(1/1)"
> deparse(expression(1+1))
[1] "expression(1 + 1)"
> deparse(expression(1%in%1))
[1] "expression(1 %in% 1)"

> sessionInfo()
R version 2.12.2 (2011-02-25)
Platform: x86_64-pc-linux-gnu (64-bit)

locale:
 [1] LC_CTYPE=en_US.utf8       LC_NUMERIC=C
 [3] LC_TIME=en_US.utf8        LC_COLLATE=en_US.utf8
 [5] LC_MONETARY=C             LC_MESSAGES=en_US.utf8
 [7] LC_PAPER=en_US.utf8       LC_NAME=C
 [9] LC_ADDRESS=C              LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.utf8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base



Regards,
Yihui
--
Yihui Xie <xieyihui at gmail.com>
Phone: 515-294-2465 Web: http://yihui.name
Department of Statistics, Iowa State University
2215 Snedecor Hall, Ames, IA


From ripley at stats.ox.ac.uk  Sun Apr 10 12:51:55 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 10 Apr 2011 11:51:55 +0100 (BST)
Subject: [Rd] Use keep.source for function in package with lazy loading
In-Reply-To: <B37C0A15B8FB3C468B5BC7EBC7DA14CC63457AC389@LP-EXMBVS10.CO.IHC.COM>
References: <B37C0A15B8FB3C468B5BC7EBC7DA14CC63457AC07C@LP-EXMBVS10.CO.IHC.COM>
	<alpine.LFD.2.02.1104042214300.1530@gannet.stats.ox.ac.uk>
	<B37C0A15B8FB3C468B5BC7EBC7DA14CC63457AC389@LP-EXMBVS10.CO.IHC.COM>
Message-ID: <alpine.LFD.2.02.1104101151210.13800@gannet.stats.ox.ac.uk>

R-devel now has a KeepSource DESCRIPTION field to accomplish what I 
think you are seeking.

On Tue, 5 Apr 2011, Greg Snow wrote:

> Prof. Ripley,
>
> Thanks for the explanation.  I had set both keep.source and keep.source.packages to TRUE for my experiments, but had not realized that a new R process would be involved, so did not try the environmental variable approach.
>
>> From what you say below, I don't think I am going to accomplish what I wanted, since I want the source to show for users other than myself and there does not seem to be a reasonable way to change the users environment before installing my package (that is getting a bit too big brother to even think about).  I was hoping that there might be some switch somewhere that I had missed that would say keep the source for this function even though the default is not to.  But, it does not look like there is anything like that, and it is not worth implementing just for my one little use.
>
> Hmm, maybe I can set the source manually using .onAttach, I'll have to experiment some more.
>
> Thanks,
>
> -- 
> Gregory (Greg) L. Snow Ph.D.
> Statistical Data Center
> Intermountain Healthcare
> greg.snow at imail.org
> 801.408.8111
>
>
>> -----Original Message-----
>> From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk]
>> Sent: Monday, April 04, 2011 3:41 PM
>> To: Greg Snow
>> Cc: R-devel at r-project.org
>> Subject: Re: [Rd] Use keep.source for function in package with lazy
>> loading
>>
>> On Mon, 4 Apr 2011, Greg Snow wrote:
>>
>>> I have a function in one of my packages that I would like to print
>>> using the original source rather than the deparse of the function.
>>> The package uses lazy loading and the help page for library (under
>>> keep.source) says that keep.source does not apply to packages that
>>> use lazy loading and that whether those functions keep the source
>>> depends on when they are installed.
>>
>> Not quite: it is says it is 'determined when it is installed'.
>>
>> For a package that does not use lazy loading, what is installed is a
>> file of R code.  When library() loads such a package, it sources() the
>> R code, and at that point has the option to keep the source or not
>> (for that R session).
>>
>> For a package which uses lazy loading, the source()ing happens when
>> the package is installed: the objects created are then dumped into a
>> database.  Whether the source attribute is retained at that point
>> depends on the setting of the option "keep.source.pkgs". So if you can
>> arrange to install the package with that option set to true, in
>> principle (and in my experiments) the source attributes are retained.
>>
>> The easiest way to do this would seem to be to set the environment
>> variable R_KEEP_PKG_SOURCE to "yes" whilst installing the package.
>>
>>> This package is on R-forge and is being built there (and will
>>> eventually be used to submit the next version of the package to
>>> CRAN).
>>>
>>> I am not sure what the help means by 'installed', I have set the
>>> options to keep the source to TRUE before calling install.package,
>>> but that does not seem to work.
>>
>> I presume you mean keep.source.pkgs, not keep.source?  That needs to
>> be set in the process which is installing the package:
>> install.packages() calls R CMD INSTALL in a separate process.
>>
>>> Is there a way to "strongly encourage" the source to be kept for
>>> this function (or the entire package)?
>>>
>>> Thanks,
>>>
>>> --
>>> Gregory (Greg) L. Snow Ph.D.
>>> Statistical Data Center
>>> Intermountain Healthcare
>>> greg.snow at imail.org
>>> 801.408.8111
>>
>> --
>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>> University of Oxford,             Tel:  +44 1865 272861 (self)
>> 1 South Parks Road,                     +44 1865 272866 (PA)
>> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From murdoch.duncan at gmail.com  Sun Apr 10 15:10:52 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 10 Apr 2011 09:10:52 -0400
Subject: [Rd] Wish there were a "strict mode" for R interpreter. What
 about You?
In-Reply-To: <4DA10646.6040202@structuremonitoring.com>
References: <BANLkTim=6ae2huv+GYQLMtgs2P+GD8_WtA@mail.gmail.com>	<BANLkTinJO=3Epmq_2zH+3vbGmZgPp_gFGA@mail.gmail.com>
	<4DA0E592.1040507@prodsyse.com> <4DA10410.2040909@gmail.com>
	<4DA10646.6040202@structuremonitoring.com>
Message-ID: <4DA1AC5C.7060005@gmail.com>

On 11-04-09 9:22 PM, Spencer Graves wrote:
> On 4/9/2011 6:12 PM, Duncan Murdoch wrote:
>> On 11-04-09 7:02 PM, Spencer Graves wrote:
>>> On 4/9/2011 2:31 PM, Hadley Wickham wrote:
>>>> On Sat, Apr 9, 2011 at 2:51 PM, Paul Johnson<pauljohn32 at gmail.com>
>>>> wrote:
>>>>> Years ago, I did lots of Perl programming. Perl will let you be lazy
>>>>> and write functions that refer to undefined variables (like R does),
>>>>> but there is also a strict mode so the interpreter will block anything
>>>>> when a variable is mentioned that has not been defined. I wish there
>>>>> were a strict mode for checking R functions.
>>>>>
>>>>> Here's why. We have a lot of students writing R functions around here
>>>>> and they run into trouble because they use the same name for things
>>>>> inside and outside of functions. When they call functions that have
>>>>> mistaken or undefined references to names that they use elsewhere,
>>>>> then variables that are in the environment are accidentally used. Know
>>>>> what I mean?
>>>>>
>>>>> dat<- whatever
>>>>>
>>>>> someNewFunction<- function(z, w){
>>>>>      #do something with z and w and create a new "dat"
>>>>>      # but forget to name it "dat"
>>>>>       lm (y, x, data=dat)
>>>>>      # lm just used wrong data
>>>>> }
>>>>>
>>>>> I wish R had a strict mode to return an error in that case. Users
>>>>> don't realize they are getting nonsense because R finds things to fill
>>>>> in for their mistakes.
>>>>>
>>>>> Is this possible?  Does anybody agree it would be good?
>>>>
>>>>> library(codetools)
>>>>> checkUsage(someNewFunction)
>>>> <anonymous>: no visible binding for global variable ?y?
>>>> <anonymous>: no visible binding for global variable ?x?
>>>> <anonymous>: no visible binding for global variable ?dat?
>>>>
>>>> Which also picks up another bug in your function ;)
>>>
>>>          Is this run by "R CMD check"?  I've seen this message.
>>>
>>>
>>>          "R CMD check" will give this message sometimes when I don't feel
>>> it's appropriate.  For example, I define a data object ETB in a package,
>>> then give that as the default in a function call like
>>> f(data.=ETB){if(missing(data.))data(ETB);  data.}.  When I run "R CMD
>>> check", I get "no visible binding for global variable 'ETB'", even
>>> though the function is tested and works during R CMD check.
>>
>> What is ETB?  Your code is looking for a global variable by that name,
>> and that's what codetools is telling you.
>
> Duncan:  Thanks for the question.
>
>
> ETB is a data object in my package.  codetools can't find it because
> data(ETB) is needed before ETB becomes available.  codetools is not
> smart enough to check to see if ETB is a data object in the package.

Okay, I understand what you are trying to do.  Yes, you have fooled 
codetools in this instance.

Duncan Murdoch


From murdoch.duncan at gmail.com  Sun Apr 10 15:20:21 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 10 Apr 2011 09:20:21 -0400
Subject: [Rd] deparse operators in expressions
In-Reply-To: <BANLkTimQLeAeinPnK8JK6nrxANT_knUn0Q@mail.gmail.com>
References: <BANLkTimQLeAeinPnK8JK6nrxANT_knUn0Q@mail.gmail.com>
Message-ID: <4DA1AE95.8040300@gmail.com>

On 11-04-09 9:43 PM, Yihui Xie wrote:
> Hi,
>
> I observed a slight problem in deparse(): it will add spaces around
> most operators except /. I wonder if this is easy to fix. I know this
> is quite trivial, but I will appreciate if / is not treated as an
> exception. Examples:

It's easy to change:  take a look at src/main/deparse.c.  The operators 
that are labelled as PP_BINARY2 get no spaces.  Looking in 
src/main/names.c, we see those are /, ^, %%, %/% and :.

But clearly this is by design, and I think it's unlikely to change.

Duncan Murdoch


>> deparse(expression(1/1))
> [1] "expression(1/1)"
>> deparse(expression(1+1))
> [1] "expression(1 + 1)"
>> deparse(expression(1%in%1))
> [1] "expression(1 %in% 1)"
>
>> sessionInfo()
> R version 2.12.2 (2011-02-25)
> Platform: x86_64-pc-linux-gnu (64-bit)
>
> locale:
>   [1] LC_CTYPE=en_US.utf8       LC_NUMERIC=C
>   [3] LC_TIME=en_US.utf8        LC_COLLATE=en_US.utf8
>   [5] LC_MONETARY=C             LC_MESSAGES=en_US.utf8
>   [7] LC_PAPER=en_US.utf8       LC_NAME=C
>   [9] LC_ADDRESS=C              LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.utf8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
>
>
> Regards,
> Yihui
> --
> Yihui Xie<xieyihui at gmail.com>
> Phone: 515-294-2465 Web: http://yihui.name
> Department of Statistics, Iowa State University
> 2215 Snedecor Hall, Ames, IA
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From ggrothendieck at gmail.com  Sun Apr 10 15:26:27 2011
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sun, 10 Apr 2011 09:26:27 -0400
Subject: [Rd] Rtools questions
In-Reply-To: <4DA0C45B.6080809@gmail.com>
References: <4D9B963E.9070501@structuremonitoring.com>
	<4D9B9B41.5070401@gmail.com>
	<BANLkTi=tnhAEqOtun=yVUD=fp0KOaatWQg@mail.gmail.com>
	<4D9C546F.5030706@gmail.com>
	<BANLkTinf8=4N7Fsff757NEi77Jor4yGD5A@mail.gmail.com>
	<4DA0C45B.6080809@gmail.com>
Message-ID: <BANLkTim=+hb9BzfrkU8rGMu+90dj8xmvqg@mail.gmail.com>

On Sat, Apr 9, 2011 at 4:40 PM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> On 11-04-06 2:45 PM, Henrik Bengtsson wrote:
>>
>> On Wed, Apr 6, 2011 at 4:54 AM, Duncan Murdoch<murdoch.duncan at gmail.com>
>> ?wrote:
>>>
>>> On 11-04-05 7:51 PM, Henrik Bengtsson wrote:
>>>>
>>>> On Tue, Apr 5, 2011 at 3:44 PM, Duncan Murdoch<murdoch.duncan at gmail.com>
>>>> ?wrote:
>>>>>
>>>>> On 11-04-05 6:22 PM, Spencer Graves wrote:
>>>>>>
>>>>>> Hello:
>>>>>>
>>>>>>
>>>>>> ? ? ? ? 1. ?How can I tell when the development version of Rtools has
>>>>>> changed?
>>>>>
>>>>> I don't make announcements of the changes, you just need to check the
>>>>> web
>>>>> site. ?There are online tools that can do this for you automatically,
>>>>> but
>>>>> I
>>>>> don't know which one to recommend. ?Google suggests lots of them.
>>>>
>>>> I also asked myself this before and I must admit it took me a while to
>>>> interpret the contents of the webpage. ?There are multiple sections,
>>>> e.g. 'Changes since R 2.12.2', 'Changes since R 2.11.1', 'Changes
>>>> since R 2.11.0', and so on. ?Then within each section there are some
>>>> dates mentioned. ?Given my current R version (say R 2.13.0 beta) and
>>>> Rtools (Rtools213.exe), it not fully clear to me which section to look
>>>> at, e.g. 'Changes since R 2.12.2'?
>>>
>>> Well, that depends on when you downloaded it. ?I use the R version
>>> releases
>>> as bookmarks. ?If you last downloaded Rtools after the release of R
>>> 2.12.2,
>>> then you only need to look at the last section.
>>>
>>> The problem with collecting changes into those that apply to each Rtools
>>> version is just that the change lists would be longer: ?Rtools212 will
>>> get
>>> changes through several R releases. ?When there are compiler changes,
>>> RtoolsXYZ generally comes out during the previous R version, because the
>>> compiler may only work with the R-devel version. ?For instance, Rtools212
>>> was introduced between R 2.11.0 and 2.11.1 and was updated a number of
>>> times
>>> up to quite recently. ?(It is now frozen, so if you download it now and
>>> are
>>> working with the R versions it supports you never need to worry about
>>> updates to it.)
>>
>> I understand, and I suspected this was the reason too.
>>
>>>
>>> However, if you want to reformat the page, go ahead, and send me the new
>>> version. ?It's a hand edited HTML page so I'd be happy to incorporate
>>> changes that make it more readable, as long as it's still easy to edit by
>>> hand.
>>>
>>> Gabor asked how to know which version was downloaded. ?If you have the
>>> installer file you can tell: ?right click on it, choose Properties, look
>>> at
>>> the Version tab. ?If you didn't keep the installer, I don't know a way to
>>> find out, but it might be recorded in the unins000.dat file that the
>>> uninstaller uses. ?Of course, without downloading the new one you can't
>>> find
>>> out its version: ?so back to my original suggestion to monitor changes to
>>> the web page. ?I'll see if there's a way to automatically include the
>>> revision number in the filename.
>>
>> This is useful - I didn't know about this version number of InnoSetup.
>> ?I've browsed the online InnoSetup help, but I couldn't locate what
>> the version parameter is called. ?With it, would it be possible to use
>> a [Code] block having InnoSetup write the version number to a VERSION
>> file in the Rtools installation directory? ?That would make it
>> possible to compare what's online and what's installed.
>>
>> Another alternative for figuring out if Rtools have changed would be
>> to compare the timestamp of the installed Rtools directory (because
>> you typically install immediately after download) and the
>> Rtools213.exe timestamp on the web server. ?This could be achieved by
>> moving the files to, say,
>> http://www.murdoch-sutherland.com/Rtools/download/ and enable indexing
>> of files in that directory.
>>
>> Either way, know about the version number is certainly good enough for
>> me. ?After installing Rtools, I can simply put the installer file in
>> the Rtools directory to allow me to compare to it later. (I kind of
>> did this before by comparing file sizes.)
>
> I've just uploaded a small change: ?now Rtools.txt records the version
> number (and if I remember to update it, you can download only that file to
> see if you are up to date). ?There's also a VERSION.txt file that contains
> the version number, which is likely to maintain its format more
> consistently, so if you want an automatic check, you should look at that
> file. ?It's also on the web site.
>

Thanks. I have added a batch file to the batchfiles distribution
(http://batchfiles.googlecode.com) which locates Rtools and then
displays VERSION.txt .   If placed on the Windows PATH then issuing
this command from the Windows console with no arguments will display
the VERSION.txt file:

   RtoolsVersion

A direct link is to the file is here:

http://batchfiles.googlecode.com/svn/trunk/RtoolsVersion.bat

It finds Rtools from the registry or if not found there looks in C:\Rtools .

-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From spencer.graves at structuremonitoring.com  Sun Apr 10 16:18:28 2011
From: spencer.graves at structuremonitoring.com (Spencer Graves)
Date: Sun, 10 Apr 2011 07:18:28 -0700
Subject: [Rd] Wish there were a "strict mode" for R interpreter. What
 about You?
In-Reply-To: <4DA1AC5C.7060005@gmail.com>
References: <BANLkTim=6ae2huv+GYQLMtgs2P+GD8_WtA@mail.gmail.com>	<BANLkTinJO=3Epmq_2zH+3vbGmZgPp_gFGA@mail.gmail.com>
	<4DA0E592.1040507@prodsyse.com> <4DA10410.2040909@gmail.com>
	<4DA10646.6040202@structuremonitoring.com>
	<4DA1AC5C.7060005@gmail.com>
Message-ID: <4DA1BC34.1030406@structuremonitoring.com>

On 4/10/2011 6:10 AM, Duncan Murdoch wrote:
> On 11-04-09 9:22 PM, Spencer Graves wrote:
>> On 4/9/2011 6:12 PM, Duncan Murdoch wrote:
>>> On 11-04-09 7:02 PM, Spencer Graves wrote:
>>>> On 4/9/2011 2:31 PM, Hadley Wickham wrote:
>>>>> On Sat, Apr 9, 2011 at 2:51 PM, Paul Johnson<pauljohn32 at gmail.com>
>>>>> wrote:
>>>>>> Years ago, I did lots of Perl programming. Perl will let you be lazy
>>>>>> and write functions that refer to undefined variables (like R does),
>>>>>> but there is also a strict mode so the interpreter will block 
>>>>>> anything
>>>>>> when a variable is mentioned that has not been defined. I wish there
>>>>>> were a strict mode for checking R functions.
>>>>>>
>>>>>> Here's why. We have a lot of students writing R functions around 
>>>>>> here
>>>>>> and they run into trouble because they use the same name for things
>>>>>> inside and outside of functions. When they call functions that have
>>>>>> mistaken or undefined references to names that they use elsewhere,
>>>>>> then variables that are in the environment are accidentally used. 
>>>>>> Know
>>>>>> what I mean?
>>>>>>
>>>>>> dat<- whatever
>>>>>>
>>>>>> someNewFunction<- function(z, w){
>>>>>>      #do something with z and w and create a new "dat"
>>>>>>      # but forget to name it "dat"
>>>>>>       lm (y, x, data=dat)
>>>>>>      # lm just used wrong data
>>>>>> }
>>>>>>
>>>>>> I wish R had a strict mode to return an error in that case. Users
>>>>>> don't realize they are getting nonsense because R finds things to 
>>>>>> fill
>>>>>> in for their mistakes.
>>>>>>
>>>>>> Is this possible?  Does anybody agree it would be good?
>>>>>
>>>>>> library(codetools)
>>>>>> checkUsage(someNewFunction)
>>>>> <anonymous>: no visible binding for global variable ?y?
>>>>> <anonymous>: no visible binding for global variable ?x?
>>>>> <anonymous>: no visible binding for global variable ?dat?
>>>>>
>>>>> Which also picks up another bug in your function ;)
>>>>
>>>>          Is this run by "R CMD check"?  I've seen this message.
>>>>
>>>>
>>>>          "R CMD check" will give this message sometimes when I 
>>>> don't feel
>>>> it's appropriate.  For example, I define a data object ETB in a 
>>>> package,
>>>> then give that as the default in a function call like
>>>> f(data.=ETB){if(missing(data.))data(ETB);  data.}.  When I run "R CMD
>>>> check", I get "no visible binding for global variable 'ETB'", even
>>>> though the function is tested and works during R CMD check.
>>>
>>> What is ETB?  Your code is looking for a global variable by that name,
>>> and that's what codetools is telling you.
>>
>> Duncan:  Thanks for the question.
>>
>>
>> ETB is a data object in my package.  codetools can't find it because
>> data(ETB) is needed before ETB becomes available.  codetools is not
>> smart enough to check to see if ETB is a data object in the package.
>
> Okay, I understand what you are trying to do.  Yes, you have fooled 
> codetools in this instance.


       I'm sorry:  I did not intend to fool codetools.  ;-)


       I just wanted to provide sensible defaults in a way that seemed 
obvious to me.


       Thanks again for all your work on Rtools and the R project more 
generally.  Spencer

>
> Duncan Murdoch
>


-- 
Spencer Graves, PE, PhD
President and Chief Operating Officer
Structure Inspection and Monitoring, Inc.
751 Emerson Ct.
San Jos?, CA 95126
ph:  408-655-4567


From pdalgd at gmail.com  Sun Apr 10 18:18:09 2011
From: pdalgd at gmail.com (peter dalgaard)
Date: Sun, 10 Apr 2011 18:18:09 +0200
Subject: [Rd] Wish there were a "strict mode" for R interpreter. What
	about You?
In-Reply-To: <4DA1AC5C.7060005@gmail.com>
References: <BANLkTim=6ae2huv+GYQLMtgs2P+GD8_WtA@mail.gmail.com>	<BANLkTinJO=3Epmq_2zH+3vbGmZgPp_gFGA@mail.gmail.com>
	<4DA0E592.1040507@prodsyse.com> <4DA10410.2040909@gmail.com>
	<4DA10646.6040202@structuremonitoring.com>
	<4DA1AC5C.7060005@gmail.com>
Message-ID: <FFDCD3C8-D7F3-44E9-B443-7B263EB70D60@gmail.com>


On Apr 10, 2011, at 15:10 , Duncan Murdoch wrote:

> On 11-04-09 9:22 PM, Spencer Graves wrote:
>> On 4/9/2011 6:12 PM, Duncan Murdoch wrote:
>>> On 11-04-09 7:02 PM, Spencer Graves wrote:
....
>>>> 
>>>>         "R CMD check" will give this message sometimes when I don't feel
>>>> it's appropriate.  For example, I define a data object ETB in a package,
>>>> then give that as the default in a function call like
>>>> f(data.=ETB){if(missing(data.))data(ETB);  data.}.  When I run "R CMD
>>>> check", I get "no visible binding for global variable 'ETB'", even
>>>> though the function is tested and works during R CMD check.
>>> 
>>> What is ETB?  Your code is looking for a global variable by that name,
>>> and that's what codetools is telling you.
>> 
>> Duncan:  Thanks for the question.
>> 
>> 
>> ETB is a data object in my package.  codetools can't find it because
>> data(ETB) is needed before ETB becomes available.  codetools is not
>> smart enough to check to see if ETB is a data object in the package.
> 
> Okay, I understand what you are trying to do.  Yes, you have fooled codetools in this instance.

...but notice that the codetools warning is just that: It _is_ acknowledged that these things occasionally happen by design. There are a couple of cases in base R too:

* checking R code for possible problems ... NOTE
glm.fit: no visible binding for global variable ?n?
quantile.ecdf: no visible binding for global variable ?y?

I can't seem to spot the 'n' just now, though...

-- 
Peter Dalgaard
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From hadley at rice.edu  Sun Apr 10 19:26:57 2011
From: hadley at rice.edu (Hadley Wickham)
Date: Sun, 10 Apr 2011 12:26:57 -0500
Subject: [Rd] Wish there were a "strict mode" for R interpreter. What
 about You?
In-Reply-To: <FFDCD3C8-D7F3-44E9-B443-7B263EB70D60@gmail.com>
References: <BANLkTim=6ae2huv+GYQLMtgs2P+GD8_WtA@mail.gmail.com>
	<BANLkTinJO=3Epmq_2zH+3vbGmZgPp_gFGA@mail.gmail.com>
	<4DA0E592.1040507@prodsyse.com>
	<4DA10410.2040909@gmail.com> <4DA10646.6040202@structuremonitoring.com>
	<4DA1AC5C.7060005@gmail.com>
	<FFDCD3C8-D7F3-44E9-B443-7B263EB70D60@gmail.com>
Message-ID: <BANLkTi=GjefwhzQEPTojNkOWq8MT2nN82g@mail.gmail.com>

>> Okay, I understand what you are trying to do. ?Yes, you have fooled codetools in this instance.
>
> ...but notice that the codetools warning is just that: It _is_ acknowledged that these things occasionally happen by design. There are a couple of cases in base R too:
>
> * checking R code for possible problems ... NOTE
> glm.fit: no visible binding for global variable ?n?

Are you sure that's not a bug?  There's:

aic.model <- aic(y, n, mu, weights, dev) + 2 * rank

and n.ok is defined, but n isn't defined anywhere.

> quantile.ecdf: no visible binding for global variable ?y?

I wonder why it warns on y, but not nobs.

Hadley


-- 
Assistant Professor / Dobelman Family Junior Chair
Department of Statistics / Rice University
http://had.co.nz/


From luke-tierney at uiowa.edu  Sun Apr 10 19:54:38 2011
From: luke-tierney at uiowa.edu (luke-tierney at uiowa.edu)
Date: Sun, 10 Apr 2011 12:54:38 -0500
Subject: [Rd] Wish there were a "strict mode" for R interpreter. What
 about You?
In-Reply-To: <BANLkTi=GjefwhzQEPTojNkOWq8MT2nN82g@mail.gmail.com>
References: <BANLkTim=6ae2huv+GYQLMtgs2P+GD8_WtA@mail.gmail.com>
	<BANLkTinJO=3Epmq_2zH+3vbGmZgPp_gFGA@mail.gmail.com>
	<4DA0E592.1040507@prodsyse.com> <4DA10410.2040909@gmail.com>
	<4DA10646.6040202@structuremonitoring.com>
	<4DA1AC5C.7060005@gmail.com>
	<FFDCD3C8-D7F3-44E9-B443-7B263EB70D60@gmail.com>
	<BANLkTi=GjefwhzQEPTojNkOWq8MT2nN82g@mail.gmail.com>
Message-ID: <alpine.DEB.2.00.1104101251530.26884@luke-inspiron>

On Sun, 10 Apr 2011, Hadley Wickham wrote:

>>> Okay, I understand what you are trying to do. ?Yes, you have fooled codetools in this instance.
>>
>> ...but notice that the codetools warning is just that: It _is_ acknowledged that these things occasionally happen by design. There are a couple of cases in base R too:
>>
>> * checking R code for possible problems ... NOTE
>> glm.fit: no visible binding for global variable ?n?
>
> Are you sure that's not a bug?  There's:
>
> aic.model <- aic(y, n, mu, weights, dev) + 2 * rank
>
> and n.ok is defined, but n isn't defined anywhere.

It is (or should be) defined by the call to

         eval(family$initialize)

>
>> quantile.ecdf: no visible binding for global variable ?y?
>
> I wonder why it warns on y, but not nobs.

It does when run on stats:::quantile.ecdf directly:

> codetools::checkUsage(stats:::quantile.ecdf)
<anonymous>: no visible binding for global variable ?nobs?
<anonymous>: no visible binding for global variable ?y?

Maybe in the context where you saw this nobs is defined in an
enclosing environment.

luke

>
> Hadley
>
>
>

-- 
Luke Tierney
Statistics and Actuarial Science
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu

From xie at yihui.name  Sun Apr 10 20:08:14 2011
From: xie at yihui.name (Yihui Xie)
Date: Sun, 10 Apr 2011 13:08:14 -0500
Subject: [Rd] deparse operators in expressions
In-Reply-To: <4DA1AE95.8040300@gmail.com>
References: <BANLkTimQLeAeinPnK8JK6nrxANT_knUn0Q@mail.gmail.com>
	<4DA1AE95.8040300@gmail.com>
Message-ID: <BANLkTimWSBBd_we+FUcCREW_sVKimdjyig@mail.gmail.com>

Thanks for pointing out the direction. Since this is unlikely to
change in base R, is it possible to change from an add-on package?

I think it is reasonable to eliminate spaces around ^ and :, but I
don't understand why /, %% and %/% should be different with other
arithmetic operators like +, - and *.

Regards,
Yihui
--
Yihui Xie <xieyihui at gmail.com>
Phone: 515-294-2465 Web: http://yihui.name
Department of Statistics, Iowa State University
2215 Snedecor Hall, Ames, IA



On Sun, Apr 10, 2011 at 8:20 AM, Duncan Murdoch
<murdoch.duncan at gmail.com> wrote:
> On 11-04-09 9:43 PM, Yihui Xie wrote:
>>
>> Hi,
>>
>> I observed a slight problem in deparse(): it will add spaces around
>> most operators except /. I wonder if this is easy to fix. I know this
>> is quite trivial, but I will appreciate if / is not treated as an
>> exception. Examples:
>
> It's easy to change: ?take a look at src/main/deparse.c. ?The operators that
> are labelled as PP_BINARY2 get no spaces. ?Looking in src/main/names.c, we
> see those are /, ^, %%, %/% and :.
>
> But clearly this is by design, and I think it's unlikely to change.
>
> Duncan Murdoch
>


From pdalgd at gmail.com  Sun Apr 10 20:11:11 2011
From: pdalgd at gmail.com (peter dalgaard)
Date: Sun, 10 Apr 2011 20:11:11 +0200
Subject: [Rd] Wish there were a "strict mode" for R interpreter. What
	about You?
In-Reply-To: <alpine.DEB.2.00.1104101251530.26884@luke-inspiron>
References: <BANLkTim=6ae2huv+GYQLMtgs2P+GD8_WtA@mail.gmail.com>
	<BANLkTinJO=3Epmq_2zH+3vbGmZgPp_gFGA@mail.gmail.com>
	<4DA0E592.1040507@prodsyse.com> <4DA10410.2040909@gmail.com>
	<4DA10646.6040202@structuremonitoring.com>
	<4DA1AC5C.7060005@gmail.com>
	<FFDCD3C8-D7F3-44E9-B443-7B263EB70D60@gmail.com>
	<BANLkTi=GjefwhzQEPTojNkOWq8MT2nN82g@mail.gmail.com>
	<alpine.DEB.2.00.1104101251530.26884@luke-inspiron>
Message-ID: <99A44FBB-2A24-43C2-88E6-226CC001C2E0@gmail.com>


On Apr 10, 2011, at 19:54 , <luke-tierney at uiowa.edu> wrote:

> On Sun, 10 Apr 2011, Hadley Wickham wrote:
> 
>>>> Okay, I understand what you are trying to do.  Yes, you have fooled codetools in this instance.
>>> 
>>> ...but notice that the codetools warning is just that: It _is_ acknowledged that these things occasionally happen by design. There are a couple of cases in base R too:
>>> 
>>> * checking R code for possible problems ... NOTE
>>> glm.fit: no visible binding for global variable ?n?
>> 
>> Are you sure that's not a bug?  There's:
>> 
>> aic.model <- aic(y, n, mu, weights, dev) + 2 * rank
>> 
>> and n.ok is defined, but n isn't defined anywhere.
> 
> It is (or should be) defined by the call to
> 
>        eval(family$initialize)
> 

...iff actually used by family$aic. And, it is a different n from n.ok (a vector, the per-element size parameter of the binomial)



>> 
>>> quantile.ecdf: no visible binding for global variable ?y?
>> 
>> I wonder why it warns on y, but not nobs.
> 
> It does when run on stats:::quantile.ecdf directly:
> 
>> codetools::checkUsage(stats:::quantile.ecdf)
> <anonymous>: no visible binding for global variable ?nobs?
> <anonymous>: no visible binding for global variable ?y?
> 
> Maybe in the context where you saw this nobs is defined in an
> enclosing environment.
> 

It came from make check-devel, so I suspect that it picks up stats:::nobs() (which would be horribly wrong, but, well...)


> luke
> 
>> 
>> Hadley

-- 
Peter Dalgaard
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From murdoch.duncan at gmail.com  Sun Apr 10 20:26:09 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 10 Apr 2011 14:26:09 -0400
Subject: [Rd] deparse operators in expressions
In-Reply-To: <BANLkTimWSBBd_we+FUcCREW_sVKimdjyig@mail.gmail.com>
References: <BANLkTimQLeAeinPnK8JK6nrxANT_knUn0Q@mail.gmail.com>
	<4DA1AE95.8040300@gmail.com>
	<BANLkTimWSBBd_we+FUcCREW_sVKimdjyig@mail.gmail.com>
Message-ID: <4DA1F641.3050502@gmail.com>

On 10/04/2011 2:08 PM, Yihui Xie wrote:
> Thanks for pointing out the direction. Since this is unlikely to
> change in base R, is it possible to change from an add-on package?

Of course.  Just write your own deparse function.  You can start with 
the code from the standard one, and make any changes you like.

Alternatively, just type your code the way you like it, and use 
keep.source to have it displayed as you entered it.


> I think it is reasonable to eliminate spaces around ^ and :, but I
> don't understand why /, %% and %/% should be different with other
> arithmetic operators like +, - and *.

I looked it up, and it has been like that since revision 2 when this 
code was first committed to our repository in 1997.   I imagine whoever 
wrote it was following the pattern of some other language (maybe S), or 
maybe just their own personal taste.

Duncan Murdoch


>
> Regards,
> Yihui
> --
> Yihui Xie<xieyihui at gmail.com>
> Phone: 515-294-2465 Web: http://yihui.name
> Department of Statistics, Iowa State University
> 2215 Snedecor Hall, Ames, IA
>
>
>
> On Sun, Apr 10, 2011 at 8:20 AM, Duncan Murdoch
> <murdoch.duncan at gmail.com>  wrote:
>> On 11-04-09 9:43 PM, Yihui Xie wrote:
>>>
>>> Hi,
>>>
>>> I observed a slight problem in deparse(): it will add spaces around
>>> most operators except /. I wonder if this is easy to fix. I know this
>>> is quite trivial, but I will appreciate if / is not treated as an
>>> exception. Examples:
>>
>> It's easy to change:  take a look at src/main/deparse.c.  The operators that
>> are labelled as PP_BINARY2 get no spaces.  Looking in src/main/names.c, we
>> see those are /, ^, %%, %/% and :.
>>
>> But clearly this is by design, and I think it's unlikely to change.
>>
>> Duncan Murdoch
>>


From hpages at fhcrc.org  Mon Apr 11 01:40:14 2011
From: hpages at fhcrc.org (=?ISO-8859-1?Q?Herv=E9_Pag=E8s?=)
Date: Sun, 10 Apr 2011 16:40:14 -0700
Subject: [Rd] question about assignment warnings for replacement methods
In-Reply-To: <A47FDE88-AC38-4CFC-B588-204F61283ABC@r-project.org>
References: <4D9B56AB.2020403@fhcrc.org> <4D9B5C5B.2020209@gmail.com>
	<4D9F5A3E.7030305@fhcrc.org>
	<A47FDE88-AC38-4CFC-B588-204F61283ABC@r-project.org>
Message-ID: <4DA23FDE.8090603@fhcrc.org>

Hi Simon,

On 11-04-08 01:05 PM, Simon Urbanek wrote:
>
> On Apr 8, 2011, at 2:55 PM, Herv? Pag?s wrote:
>
>> Hi Duncan, Marc,
>>
>> On 11-04-05 11:15 AM, Duncan Murdoch wrote:
>>> On 05/04/2011 1:51 PM, Marc Carlson wrote:
>>>> Hi,
>>>>
>>>> I have seen several packages that with the most recent version of R are
>>>> giving a warning like this:
>>>>
>>>> Assignments in \usage in documentation object 'marginalData-methods':
>>>> marginalData(object) = value
>>>>
>>>> I assume that this is to prevent people from making assignments in their
>>>> usage statements (which seems completely understandable). But what
>>>> about the case above? This is a person who just wants to show the
>>>> proper usage for a replacement method. IOW they just want to write
>>>> something that looks like what you actually do when you use a
>>>> replacement method. They just want to show users how to do something
>>>> like this:
>>>>
>>>> replacementMethod(object)<- newValue
>>>>
>>>>
>>>> So is that really something that should not be allowed in a usage
>>>> statement?
>>>
>>> If replacementMethod was a replacement function, then
>>>
>>> replacementMethod(object)<- newValue
>>>
>>> is supposed to be fine.
>>
>> Yes, 'replacementMethod(object)<- newValue' vorks indeed, but
>> not 'replacementMethod(object) = newValue'.
>>
>>> But if it is an S3 method, it should be
>>>
>>> \method{replacementMethod}{class}(object)<- newValue
>>>
>>> and if it is an S4 method I think it should be
>>>
>>> \S4method{replacementMethod}{signature_list}(object)<- newValue
>>
>> In the case reported by Marc, replacementMethod was both: a
>> replacement (generic) function and a replacement method. And the
>> man page had an alias for both. Marc replaced
>>
>>   replacementMethod(object) = newValue
>>
>> with
>>
>>   \S4method{replacementMethod}{signature_list}(object)<- newValue
>>
>> and that solved the problem. But replacing '=' with '<-' solves it too.
>>
>> Shouldn't 'R CMD check' treat the 2 assignment operators the same way
>> since they are equivalent?
>>
>
> They are not equivalent (you can't use = in many places where you can use<-).

I tried to lower the chance of getting a comment like this by saying
"the 2 *assignment* operators are equivalent" but apparently I
failed :-/

Seems to me that the places where I can't replace <- by = are exactly
the places where I would be replacing an assignment operator by
something that is not an assignment operator anymore.

>
> Also my understanding is that it is considered bad practice by some to use = as assignment outside of the command prompt (interactive use) -- but opinions vary and I don't want to start a flame war here ;).

I agree with you. I like to be able to directly copy/paste

   a <- foo()

into

   system.time(... paste it here ...)

and press <return> and have it work. But as you said, opinions may
vary...

Anyway, if 'R CMD check' wants to encourage good practice, fine with
me, but then the warning for 'replacementMethod(object) = newValue'
should be something else and also maybe for consistency the code in
the examples and in the vignette should be checked to detect when =
is used instead of <-

Otherwise, 'R CMD check' should just treat

   replacementMethod(object) = newValue

the same way it treats

   replacementMethod(object) <- newValue

Thanks,
H.


>
> Cheers,
> Simon
>
>
>
>> Thanks!
>> H.
>>
>>>
>>> (though the manual suggests using the S3 style, I'm not sure how
>>> literally to take it).
>>>
>>> Duncan Murdoch
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>> --
>> Herv? Pag?s
>>
>> Program in Computational Biology
>> Division of Public Health Sciences
>> Fred Hutchinson Cancer Research Center
>> 1100 Fairview Ave. N, M2-B876
>> P.O. Box 19024
>> Seattle, WA 98109-1024
>>
>> E-mail: hpages at fhcrc.org
>> Phone:  (206) 667-5791
>> Fax:    (206) 667-1319
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>


-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M2-B876
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fhcrc.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From hpages at fhcrc.org  Mon Apr 11 02:05:25 2011
From: hpages at fhcrc.org (=?ISO-8859-1?Q?Herv=E9_Pag=E8s?=)
Date: Sun, 10 Apr 2011 17:05:25 -0700
Subject: [Rd] R CMD build now removes empty dirs
In-Reply-To: <BANLkTim9+O=B+hUwExw_1Af5+ojEO1w5pA@mail.gmail.com>
References: <1705062143.2814.1301464854707.JavaMail.root@zimbra4.fhcrc.org>	<849792884.2828.1301468207385.JavaMail.root@zimbra4.fhcrc.org>
	<BANLkTim9+O=B+hUwExw_1Af5+ojEO1w5pA@mail.gmail.com>
Message-ID: <4DA245C5.2060604@fhcrc.org>

Hi Henrik,

Just to clarify, you still have the ability of installing directory
structures that are partly empty. Actually 'R CMD INSTALL pkgpath/'
does this. And if srctarball.tar.gz contains empty dirs,
'R CMD INSTALL srctarball.tar.gz' will also keep them.

The problem is that *by default* 'R CMD build' removes those empty
dirs, unless you specify --keep-empty-dirs

The fact that 'R CMD build' and 'R CMD INSTALL' now have different
default behaviors is really a bad thing since when I'm working on
a package I typically do not use 'R CMD build' before I install it.
I use 'R CMD INSTALL' directly on the package source tree.
So everything looks ok to me because then empty dirs are installed.
It's only later when I build the source tarball that it will be
broken.

It's not just --keep-empty-dirs, it's also --resave-data. These
new options don't do the right thing by default and they are not
even consistent between 'R CMD build' and 'R CMD INSTALL'.

Cheers,
H.


On 11-03-30 08:04 PM, Henrik Bengtsson wrote:
> I am also in favor for keeping the ability of installing directory
> structures that are partly empty.  I've used it before to setup
> templates that can conveniently be copied recursively to a local path.
>   I did noticed that R CMD INSTALL gave a warning about empty
> directories before (or was it a NOTE by R CMD check?).
>
> /Henrik
>
> On Tue, Mar 29, 2011 at 11:56 PM, Pages, Herve<hpages at fhcrc.org>  wrote:
>> Hi,
>>
>> It's unfortunate that with recent revisions of R 2.13 (this
>> appeared in revision 54640, March 2), 'R CMD build' now removes
>> empty dirs in the package. People might have good reasons for
>> having empty dirs in their packages. For example, in Bioconductor,
>> we have some tools to automatically generate annotation packages
>> and those tools are implemented in software packages that use
>> templates for the annotation packages to be generated. Those
>> package templates are stored under the inst/ folder of the
>> software package. One of those software packages is the
>> AnnotationDbi package: it contains 41 package templates under
>> inst/:
>>
>> [hpages at latitude Rpacks]$ ls AnnotationDbi/inst/AnnDbPkg-templates/
>> AFFYHUEX.DB         CHIMP.DB       MALARIA.DB    WORM.DB
>> ANOPHELES.DB        COELICOLOR.DB  MOUSECHIP.DB  XENOPUSCHIP.DB
>> ARABIDOPSISCHIP.DB  ECOLICHIP.DB   MOUSE.DB      XENOPUS.DB
>> ARABIDOPSIS.DB      ECOLI.DB       ORGANISM.DB   YEASTCHIP.DB
>> BASEPKG.DB          FLYCHIP.DB     PFAM.DB       YEAST.DB
>> BOVINECHIP.DB       FLY.DB         PIGCHIP.DB    YEASTNCBI.DB
>> BOVINE.DB           GO.DB          PIG.DB        ZEBRAFISHCHIP.DB
>> CANINECHIP.DB       HUMANCHIP.DB   RATCHIP.DB    ZEBRAFISH.DB
>> CANINE.DB           HUMAN.DB       RAT.DB
>> CHICKENCHIP.DB      INPARANOID.DB  RHESUS.DB
>> CHICKEN.DB          KEGG.DB        WORMCHIP.DB
>>
>> Those package templates are just the skeletons of the hundreds of
>> annotation packages that we generate. Of course, each of them contains
>> empty subfolders.
>>
>> Having 'R CMD build' remove those empty subfolders breaks all the
>> tools that make use of those package templates.
>>
>> Maybe I've missed it but I didn't see any mention of this "feature"
>> on this list and the fact that it was added only 6 weeks before the
>> next R and Bioconductor releases is only making this worse.
>>
>> I hope this "feature" can be reverted. Why would people or our build
>> system need to start using R CMD build --keep-empty-dirs just to get
>> a source tarball right?
>>
>> Thanks,
>> H.
>>
>> PS: This page
>>
>>   http://stat.ethz.ch/R-manual/R-devel/doc/html/NEWS.html
>>
>> (referenced from http://developer.r-project.org/) has not been
>> updated for months.
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>


-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M2-B876
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fhcrc.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From hpages at fhcrc.org  Mon Apr 11 02:47:06 2011
From: hpages at fhcrc.org (=?ISO-8859-1?Q?Herv=E9_Pag=E8s?=)
Date: Sun, 10 Apr 2011 17:47:06 -0700
Subject: [Rd] R CMD build --resave-data
Message-ID: <4DA24F8A.7030405@fhcrc.org>

Hi,

More about the new --resave-data option

As mentioned previously here

   https://stat.ethz.ch/pipermail/r-devel/2011-April/060511.html

'R CMD build' and 'R CMD INSTALL' handle this new option
inconsistently. The former does --resave-data="gzip" by default.
The latter doesn't seem to support the --resave-data= syntax:
the --resave-data flag must either be present or not. And by
default 'R CMD INSTALL' won't resave the data.

Also, because now 'R CMD build' is resaving the data, shouldn't it
reinstall the package in order to be able to do this correctly?

Here is why. There is this new warning in 'R CMD check' that complains
about files not of a type allowed in a 'data' directory:

 
http://bioconductor.org/checkResults/2.8/bioc-LATEST/Icens/lamb1-checksrc.html

The Icens package also has .R files under data/ with things like:

   bet <- matrix(scan("CMVdata", quiet=TRUE),nc=5,byr=TRUE)

i.e. the R code needs to access some of the text files located
in the data/ folder. So in order to get rid of this warning I
tried to move those text files to inst/extdata/ and I modified
the code in the .R file so it does:

   CMVdata_filepath <- system.file("extdata", "CMVdata", package="Icens")
   bet <- matrix(scan(CMVdata_filepath, quiet=TRUE),nc=5,byr=TRUE)

But now 'R CMD build' fails to resave the data because the package
was not installed first and the CMVdata file could not be found.

Unfortunately, for a lot of people that means that the safe way to
build a source tarball now is with

   R CMD build --keep-empty-dirs --no-resave-data

I hope the list of options/flags that we need to use to "fix" 'R CMD
build' (and make it consistent with R CMD INSTALL) is not going to
grow too much ;-)

Thanks,
H.


-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M2-B876
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fhcrc.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From b.rowlingson at lancaster.ac.uk  Mon Apr 11 11:28:28 2011
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Mon, 11 Apr 2011 10:28:28 +0100
Subject: [Rd] Wish there were a "strict mode" for R interpreter. What
In-Reply-To: <XFMail.110409220813.ted.harding@wlandres.net>
References: <4DA0C388.8080401@gmail.com>
	<XFMail.110409220813.ted.harding@wlandres.net>
Message-ID: <BANLkTi=6VEYK9nTEysNMn6PpASc+384YFQ@mail.gmail.com>

On Sat, Apr 9, 2011 at 10:08 PM, Ted Harding <ted.harding at wlandres.net> wrote:

> I'm with Duncan on this one! On the other hand, I can understand the
> issues that Paul's students might encounter.
>
> I think the right thing to so is to introduce the students to the
> basics of scoping, early in the process of learning R.

 Would that be before or after you introduce them to the basics of
testing? Hint: AFTER!

Barry


From maechler at stat.math.ethz.ch  Mon Apr 11 12:00:04 2011
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 11 Apr 2011 12:00:04 +0200
Subject: [Rd] R CMD build now removes empty dirs
In-Reply-To: <849792884.2828.1301468207385.JavaMail.root@zimbra4.fhcrc.org>
References: <1705062143.2814.1301464854707.JavaMail.root@zimbra4.fhcrc.org>
	<849792884.2828.1301468207385.JavaMail.root@zimbra4.fhcrc.org>
Message-ID: <19874.53540.989258.136667@stat.math.ethz.ch>

>>>>> Pages, Herve <hpages at fhcrc.org>
>>>>>     on Tue, 29 Mar 2011 23:56:47 -0700 (PDT) writes:

    > Hi, It's unfortunate that with recent revisions of R 2.13
    > (this appeared in revision 54640, March 2), 'R CMD build'
    > now removes empty dirs in the package. People might have
    > good reasons for having empty dirs in their packages. For
    > example, in Bioconductor, we have some tools to
    > automatically generate annotation packages and those tools
    > are implemented in software packages that use templates
    > for the annotation packages to be generated. Those package
    > templates are stored under the inst/ folder of the
    > software package. One of those software packages is the
    > AnnotationDbi package: it contains 41 package templates
    > under inst/:

    > [hpages at latitude Rpacks]$ ls
    > AnnotationDbi/inst/AnnDbPkg-templates/ AFFYHUEX.DB
    > CHIMP.DB MALARIA.DB WORM.DB ANOPHELES.DB COELICOLOR.DB
    > MOUSECHIP.DB XENOPUSCHIP.DB ARABIDOPSISCHIP.DB
    > ECOLICHIP.DB MOUSE.DB XENOPUS.DB ARABIDOPSIS.DB ECOLI.DB
    > ORGANISM.DB YEASTCHIP.DB BASEPKG.DB FLYCHIP.DB PFAM.DB
    > YEAST.DB BOVINECHIP.DB FLY.DB PIGCHIP.DB YEASTNCBI.DB
    > BOVINE.DB GO.DB PIG.DB ZEBRAFISHCHIP.DB CANINECHIP.DB
    > HUMANCHIP.DB RATCHIP.DB ZEBRAFISH.DB CANINE.DB HUMAN.DB
    > RAT.DB CHICKENCHIP.DB INPARANOID.DB RHESUS.DB CHICKEN.DB
    > KEGG.DB WORMCHIP.DB

    > Those package templates are just the skeletons of the
    > hundreds of annotation packages that we generate. Of
    > course, each of them contains empty subfolders.

    > Having 'R CMD build' remove those empty subfolders breaks
    > all the tools that make use of those package templates.
 
    > Maybe I've missed it but I didn't see any mention of this
    > "feature" on this list and the fact that it was added only
    > 6 weeks before the next R and Bioconductor releases is
    > only making this worse.

    > I hope this "feature" can be reverted. Why would people or
    > our build system need to start using R CMD build
    > --keep-empty-dirs just to get a source tarball right?

    > Thanks, H.

    > PS: This page

    >   http://stat.ethz.ch/R-manual/R-devel/doc/html/NEWS.html

    > (referenced from http://developer.r-project.org/) has not
    > been updated for months.

Thank you, Herve.
I've only now read your e-mail.
(and I now also agree that --keep-empty-dirs should *not* be needed
 to keep an empty inst/ !)

Thanks for the heads up about NEWS.html.
It's finally current again, and hopefully remains so:
It got outdated accidentally, as it was removed from the default
'make' target, and now needs an extra make call.

Martin Maechler, ETH Zurich


From costas.vorlow at gmail.com  Sun Apr 10 09:43:15 2011
From: costas.vorlow at gmail.com (Costas Vorlow)
Date: Sun, 10 Apr 2011 10:43:15 +0300
Subject: [Rd] open.exe Virus W32.ATRAPS
Message-ID: <BANLkTi=+v3eXeTBz5nveWN9YxJrRgFaeTA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110410/d4943637/attachment.pl>

From luke-tierney at uiowa.edu  Fri Apr  8 19:42:35 2011
From: luke-tierney at uiowa.edu (luke-tierney at uiowa.edu)
Date: Fri, 8 Apr 2011 12:42:35 -0500
Subject: [Rd] core Matrix package segfaulted on R CMD check --use-gct
In-Reply-To: <191025.59368.qm@web29508.mail.ird.yahoo.com>
References: <191025.59368.qm@web29508.mail.ird.yahoo.com>
Message-ID: <alpine.DEB.2.00.1104081240160.1770@luke-inspiron>

Given the configure settings this looks like its probably an issue in
regexpr's internals rather than in Matrix per se. I can confirm that
with

> gctorture()
> for (i in 1:100) regexpr("package:", "package:lattice", fixed = TRUE)
Error in regexpr("package:", "package:lattice", fixed = TRUE) :
   unprotected object (0x26b30a8) encountered (was INTSXP)

run in r55347 with --enable-strict-barrier.  I'll see if I can spot anyting.

luke

On Fri, 8 Apr 2011, Hin-Tak Leung wrote:

> --- On Fri, 8/4/11, peter dalgaard <pdalgd at gmail.com> wrote:
>
>> On Apr 7, 2011, at 23:57 , Hin-Tak Leung wrote:
>> 
>> > 
>> > Oh, I am tracking both R and Matrix via git-svn and
>> retrieves all revisions to all branches daily (or at least,
>> regularly). I.e. R svn head.? 2.13.0 only forked off
>> recently and most of the trunk<->2.13.0rc differences
>> are so far mostly documentation-related. I could switch to
>> track R 2.13.x branch if you insist.
>> > 
>> 
>> Please do. It's the branch that is supposed to stabilize
>> during prerelease times.
>> 
>> Also, please check the prerelease tarballs, errors in "make
>> dist" are not caught when building from svn.
>
> Just so that there is no doubt, here is the recipe with the latest rc tar ball, cutting-and-pasting from my command history:
>
> wget -m http://cran.r-project.org/src/base-prerelease/R-rc_2011-04-07_r55373.tar.gz
> cd /tmp
> tar -zxpvf ~/cran.r-project.org/src/base-prerelease/R-rc_2011-04-07_r55373.tar.gz
> cd R-rc/
> export DEFS='-DUSE_TYPE_CHECKING_STRICT -DR_MEMORY_PROFILING' ; ./configure  --enable-memory-profiling --enable-strict-barrier --enable-byte-compiled-packages --with-valgrind-instrumentation=2  ; make
> cd src/library/
> cd Recommended/
> ../../../bin/R CMD check --use-gct Matrix_0.999375-49.tar.gz
>
> ------------------------------
> ...
> Running examples in ?Matrix-Ex.R? failed
> The error occurred in:
>
>
> R version 2.13.0 RC (2011-04-07 r55373)
> Copyright (C) 2011 The R Foundation for Statistical Computing
> ISBN 3-900051-07-0
> Platform: x86_64-unknown-linux-gnu (64-bit)
> ...
>> pkgname <- "Matrix"
>> source(file.path(R.home("share"), "R", "examples-header.R"))
>> gctorture(TRUE)
>> options(warn = 1)
>> library('Matrix')
> Loading required package: lattice
> Error in regexpr("package:", envName, fixed = TRUE) :
>  unprotected object (0x3be2ba8) encountered (was INTSXP)
> Error: package/namespace load failed for 'Matrix'
> Execution halted
> -------------------------
>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Luke Tierney
Statistics and Actuarial Science
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu

From luke-tierney at uiowa.edu  Fri Apr  8 20:48:49 2011
From: luke-tierney at uiowa.edu (luke-tierney at uiowa.edu)
Date: Fri, 8 Apr 2011 13:48:49 -0500
Subject: [Rd] core Matrix package segfaulted on R CMD check --use-gct
In-Reply-To: <191025.59368.qm@web29508.mail.ird.yahoo.com>
References: <191025.59368.qm@web29508.mail.ird.yahoo.com>
Message-ID: <alpine.DEB.2.00.1104081339440.1770@luke-inspiron>

Fixed in R-devel by 55385 and R-2-113-branch by 55386.

The problem was a call to install() in the C srouce code without
protecting another value before the install call. This particular
issue was very unlikely to cause a problem outside of a gctorture
context, but in that context with the memory checking enabled by the
strict barrier it will get caught.

Quick notes in case someone else needs to track this sort of thing
down: When gctorture is used in conjuction with the memory checks
enabled by the strict barrier it is very likely that an error will be
detected and signaled very close to where the problem in the C code
actually is, which is why I tried an example using only regexpr when
the error was being signaled there. Once a reproducable example is
found, setting a breakpoint in memory.c:CHK on the line that signals
the error gives a stack trace of the C calls involved, and in this
case the culprit was pretty easy to find at that point.

luke

On Fri, 8 Apr 2011, Hin-Tak Leung wrote:

> --- On Fri, 8/4/11, peter dalgaard <pdalgd at gmail.com> wrote:
>
>> On Apr 7, 2011, at 23:57 , Hin-Tak Leung wrote:
>> 
>> > 
>> > Oh, I am tracking both R and Matrix via git-svn and
>> retrieves all revisions to all branches daily (or at least,
>> regularly). I.e. R svn head.? 2.13.0 only forked off
>> recently and most of the trunk<->2.13.0rc differences
>> are so far mostly documentation-related. I could switch to
>> track R 2.13.x branch if you insist.
>> > 
>> 
>> Please do. It's the branch that is supposed to stabilize
>> during prerelease times.
>> 
>> Also, please check the prerelease tarballs, errors in "make
>> dist" are not caught when building from svn.
>
> Just so that there is no doubt, here is the recipe with the latest rc tar ball, cutting-and-pasting from my command history:
>
> wget -m http://cran.r-project.org/src/base-prerelease/R-rc_2011-04-07_r55373.tar.gz
> cd /tmp
> tar -zxpvf ~/cran.r-project.org/src/base-prerelease/R-rc_2011-04-07_r55373.tar.gz
> cd R-rc/
> export DEFS='-DUSE_TYPE_CHECKING_STRICT -DR_MEMORY_PROFILING' ; ./configure  --enable-memory-profiling --enable-strict-barrier --enable-byte-compiled-packages --with-valgrind-instrumentation=2  ; make
> cd src/library/
> cd Recommended/
> ../../../bin/R CMD check --use-gct Matrix_0.999375-49.tar.gz
>
> ------------------------------
> ...
> Running examples in ?Matrix-Ex.R? failed
> The error occurred in:
>
>
> R version 2.13.0 RC (2011-04-07 r55373)
> Copyright (C) 2011 The R Foundation for Statistical Computing
> ISBN 3-900051-07-0
> Platform: x86_64-unknown-linux-gnu (64-bit)
> ...
>> pkgname <- "Matrix"
>> source(file.path(R.home("share"), "R", "examples-header.R"))
>> gctorture(TRUE)
>> options(warn = 1)
>> library('Matrix')
> Loading required package: lattice
> Error in regexpr("package:", envName, fixed = TRUE) :
>  unprotected object (0x3be2ba8) encountered (was INTSXP)
> Error: package/namespace load failed for 'Matrix'
> Execution halted
> -------------------------
>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Luke Tierney
Statistics and Actuarial Science
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu

From maechler at stat.math.ethz.ch  Fri Apr  8 23:09:34 2011
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 8 Apr 2011 23:09:34 +0200
Subject: [Rd] core Matrix package segfaulted on R CMD check --use-gct
In-Reply-To: <alpine.DEB.2.00.1104081339440.1770@luke-inspiron>
References: <191025.59368.qm@web29508.mail.ird.yahoo.com>
	<alpine.DEB.2.00.1104081339440.1770@luke-inspiron>
Message-ID: <BANLkTim_X4xuNkttJ=nxxQ6iSFLAQi8r7w@mail.gmail.com>

Fantastic.  Thanks a lot, Luke!

 .... I can close the thread just to say the final    "it wasn't
Matrix after all!"
;-)


On Fri, Apr 8, 2011 at 20:48,  <luke-tierney at uiowa.edu> wrote:
> Fixed in R-devel by 55385 and R-2-113-branch by 55386.
>
> The problem was a call to install() in the C srouce code without
> protecting another value before the install call. This particular
> issue was very unlikely to cause a problem outside of a gctorture
> context, but in that context with the memory checking enabled by the
> strict barrier it will get caught.
>
> Quick notes in case someone else needs to track this sort of thing
> down: When gctorture is used in conjuction with the memory checks
> enabled by the strict barrier it is very likely that an error will be
> detected and signaled very close to where the problem in the C code
> actually is, which is why I tried an example using only regexpr when
> the error was being signaled there. Once a reproducable example is
> found, setting a breakpoint in memory.c:CHK on the line that signals
> the error gives a stack trace of the C calls involved, and in this
> case the culprit was pretty easy to find at that point.
>
> luke
>
> On Fri, 8 Apr 2011, Hin-Tak Leung wrote:
>
>> --- On Fri, 8/4/11, peter dalgaard <pdalgd at gmail.com> wrote:
>>
>>> On Apr 7, 2011, at 23:57 , Hin-Tak Leung wrote:
>>>
>>> > > Oh, I am tracking both R and Matrix via git-svn and
>>> retrieves all revisions to all branches daily (or at least,
>>> regularly). I.e. R svn head.? 2.13.0 only forked off
>>> recently and most of the trunk<->2.13.0rc differences
>>> are so far mostly documentation-related. I could switch to
>>> track R 2.13.x branch if you insist.
>>> >
>>> Please do. It's the branch that is supposed to stabilize
>>> during prerelease times.
>>>
>>> Also, please check the prerelease tarballs, errors in "make
>>> dist" are not caught when building from svn.
>>
>> Just so that there is no doubt, here is the recipe with the latest rc tar
>> ball, cutting-and-pasting from my command history:
>>
>> wget -m
>> http://cran.r-project.org/src/base-prerelease/R-rc_2011-04-07_r55373.tar.gz
>> cd /tmp
>> tar -zxpvf
>> ~/cran.r-project.org/src/base-prerelease/R-rc_2011-04-07_r55373.tar.gz
>> cd R-rc/
>> export DEFS='-DUSE_TYPE_CHECKING_STRICT -DR_MEMORY_PROFILING' ;
>> ./configure ?--enable-memory-profiling --enable-strict-barrier
>> --enable-byte-compiled-packages --with-valgrind-instrumentation=2 ?; make
>> cd src/library/
>> cd Recommended/
>> ../../../bin/R CMD check --use-gct Matrix_0.999375-49.tar.gz
>>
>> ------------------------------
>> ...
>> Running examples in ?Matrix-Ex.R? failed
>> The error occurred in:
>>
>>
>> R version 2.13.0 RC (2011-04-07 r55373)
>> Copyright (C) 2011 The R Foundation for Statistical Computing
>> ISBN 3-900051-07-0
>> Platform: x86_64-unknown-linux-gnu (64-bit)
>> ...
>>>
>>> pkgname <- "Matrix"
>>> source(file.path(R.home("share"), "R", "examples-header.R"))
>>> gctorture(TRUE)
>>> options(warn = 1)
>>> library('Matrix')
>>
>> Loading required package: lattice
>> Error in regexpr("package:", envName, fixed = TRUE) :
>> ?unprotected object (0x3be2ba8) encountered (was INTSXP)
>> Error: package/namespace load failed for 'Matrix'
>> Execution halted
>> -------------------------
>>
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> --
> Luke Tierney
> Statistics and Actuarial Science
> Ralph E. Wareham Professor of Mathematical Sciences
> University of Iowa ? ? ? ? ? ? ? ? ?Phone: ? ? ? ? ? ? 319-335-3386
> Department of Statistics and ? ? ? ?Fax: ? ? ? ? ? ? ? 319-335-3017
> ? Actuarial Science
> 241 Schaeffer Hall ? ? ? ? ? ? ? ? ?email: ? ? ?luke at stat.uiowa.edu
> Iowa City, IA 52242 ? ? ? ? ? ? ? ? WWW: ?http://www.stat.uiowa.edu


From htl10 at users.sourceforge.net  Fri Apr  8 23:22:36 2011
From: htl10 at users.sourceforge.net (Hin-Tak Leung)
Date: Fri, 8 Apr 2011 22:22:36 +0100 (BST)
Subject: [Rd] core Matrix package segfaulted on R CMD check --use-gct
In-Reply-To: <BANLkTim_X4xuNkttJ=nxxQ6iSFLAQi8r7w@mail.gmail.com>
Message-ID: <456228.47846.qm@web29517.mail.ird.yahoo.com>

--- On Fri, 8/4/11, Martin Maechler <maechler at stat.math.ethz.ch> wrote:

> Fantastic.? Thanks a lot, Luke!
> 
>  .... I can close the thread just to say the final?
> ? "it wasn't
> Matrix after all!"
> ;-)

I am glad it is all working out - I have spent way too much time on this, having gone through about 4 different packages to get to the bottom.
finger-cross gctorture(TRUE) works - and continue to :-)... until next time. 

Cheers,
Hin-Tak


> 
> 
> On Fri, Apr 8, 2011 at 20:48,? <luke-tierney at uiowa.edu>
> wrote:
> > Fixed in R-devel by 55385 and R-2-113-branch by
> 55386.
> >
> > The problem was a call to install() in the C srouce
> code without
> > protecting another value before the install call. This
> particular
> > issue was very unlikely to cause a problem outside of
> a gctorture
> > context, but in that context with the memory checking
> enabled by the
> > strict barrier it will get caught.
> >
> > Quick notes in case someone else needs to track this
> sort of thing
> > down: When gctorture is used in conjuction with the
> memory checks
> > enabled by the strict barrier it is very likely that
> an error will be
> > detected and signaled very close to where the problem
> in the C code
> > actually is, which is why I tried an example using
> only regexpr when
> > the error was being signaled there. Once a
> reproducable example is
> > found, setting a breakpoint in memory.c:CHK on the
> line that signals
> > the error gives a stack trace of the C calls involved,
> and in this
> > case the culprit was pretty easy to find at that
> point.
> >
> > luke
> >
> > On Fri, 8 Apr 2011, Hin-Tak Leung wrote:
> >
> >> --- On Fri, 8/4/11, peter dalgaard <pdalgd at gmail.com>
> wrote:
> >>
> >>> On Apr 7, 2011, at 23:57 , Hin-Tak Leung
> wrote:
> >>>
> >>> > > Oh, I am tracking both R and Matrix
> via git-svn and
> >>> retrieves all revisions to all branches daily
> (or at least,
> >>> regularly). I.e. R svn head.? 2.13.0 only
> forked off
> >>> recently and most of the
> trunk<->2.13.0rc differences
> >>> are so far mostly documentation-related. I
> could switch to
> >>> track R 2.13.x branch if you insist.
> >>> >
> >>> Please do. It's the branch that is supposed to
> stabilize
> >>> during prerelease times.
> >>>
> >>> Also, please check the prerelease tarballs,
> errors in "make
> >>> dist" are not caught when building from svn.
> >>
> >> Just so that there is no doubt, here is the recipe
> with the latest rc tar
> >> ball, cutting-and-pasting from my command
> history:
> >>
> >> wget -m
> >> http://cran.r-project.org/src/base-prerelease/R-rc_2011-04-07_r55373.tar.gz
> >> cd /tmp
> >> tar -zxpvf
> >>
> ~/cran.r-project.org/src/base-prerelease/R-rc_2011-04-07_r55373.tar.gz
> >> cd R-rc/
> >> export DEFS='-DUSE_TYPE_CHECKING_STRICT
> -DR_MEMORY_PROFILING' ;
> >> ./configure ?--enable-memory-profiling
> --enable-strict-barrier
> >> --enable-byte-compiled-packages
> --with-valgrind-instrumentation=2 ?; make
> >> cd src/library/
> >> cd Recommended/
> >> ../../../bin/R CMD check --use-gct
> Matrix_0.999375-49.tar.gz
> >>
> >> ------------------------------
> >> ...
> >> Running examples in ?Matrix-Ex.R? failed
> >> The error occurred in:
> >>
> >>
> >> R version 2.13.0 RC (2011-04-07 r55373)
> >> Copyright (C) 2011 The R Foundation for
> Statistical Computing
> >> ISBN 3-900051-07-0
> >> Platform: x86_64-unknown-linux-gnu (64-bit)
> >> ...
> >>>
> >>> pkgname <- "Matrix"
> >>> source(file.path(R.home("share"), "R",
> "examples-header.R"))
> >>> gctorture(TRUE)
> >>> options(warn = 1)
> >>> library('Matrix')
> >>
> >> Loading required package: lattice
> >> Error in regexpr("package:", envName, fixed =
> TRUE) :
> >> ?unprotected object (0x3be2ba8) encountered (was
> INTSXP)
> >> Error: package/namespace load failed for 'Matrix'
> >> Execution halted
> >> -------------------------
> >>
> >>
> >> ______________________________________________
> >> R-devel at r-project.org
> mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-devel
> >
> > --
> > Luke Tierney
> > Statistics and Actuarial Science
> > Ralph E. Wareham Professor of Mathematical Sciences
> > University of Iowa ? ? ? ? ? ? ? ? ?Phone: ?
> ? ? ? ? ? 319-335-3386
> > Department of Statistics and ? ? ? ?Fax: ? ? ?
> ? ? ? ? 319-335-3017
> > ? Actuarial Science
> > 241 Schaeffer Hall ? ? ? ? ? ? ? ? ?email: ?
> ? ?luke at stat.uiowa.edu
> > Iowa City, IA 52242 ? ? ? ? ? ? ? ? WWW: ?http://www.stat.uiowa.edu
>


From bps0002 at auburn.edu  Sat Apr  9 01:05:28 2011
From: bps0002 at auburn.edu (B77S)
Date: Fri, 8 Apr 2011 16:05:28 -0700 (PDT)
Subject: [Rd] duplicates() function
In-Reply-To: <4D9F22BE.5000502@gmail.com>
References: <4D9F22BE.5000502@gmail.com>
Message-ID: <1302303928862-3437614.post@n4.nabble.com>

which(duplicated(x)=="TRUE")

--
View this message in context: http://r.789695.n4.nabble.com/duplicates-function-tp3436584p3437614.html
Sent from the R devel mailing list archive at Nabble.com.


From mk04 at tlb.sympatico.ca  Sun Apr 10 00:05:20 2011
From: mk04 at tlb.sympatico.ca (marc rousseau)
Date: Sat, 9 Apr 2011 18:05:20 -0400
Subject: [Rd] pd
Message-ID: <0FADEE07EF074EB580AA8A4133A03919@CPQ71292329354>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110409/2e0dc07f/attachment.pl>

From lFsdBDYr at cxpxw.gnway.net  Sun Apr 10 10:05:25 2011
From: lFsdBDYr at cxpxw.gnway.net (=?GB2312?B?uanTpsnMudzA7Q==?=)
Date: Sun, 10 Apr 2011 16:05:25 +0800
Subject: [Rd] =?gb2312?b?ssm5usH3s8zTxbuvvLC5qdOmyczGwLnA0+u53MDt?=
Message-ID: <20110410080525269.wlwtJAZujgoyVpJuejhe@vphil1.ethz.ch>


???????????????
?
?? ?? ?? ??

???????????????????????????????????????

? ? ? ? ? ? ? ? ? ? ?!

From PDalgd at gmail.com  Mon Apr 11 13:57:35 2011
From: PDalgd at gmail.com (peter dalgaard)
Date: Mon, 11 Apr 2011 13:57:35 +0200
Subject: [Rd] open.exe Virus W32.ATRAPS
In-Reply-To: <BANLkTi=+v3eXeTBz5nveWN9YxJrRgFaeTA@mail.gmail.com>
References: <BANLkTi=+v3eXeTBz5nveWN9YxJrRgFaeTA@mail.gmail.com>
Message-ID: <57D377EE-047C-4299-9A67-E80354C16F23@gmail.com>


On Apr 10, 2011, at 09:43 , Costas Vorlow wrote:

> Hello,
> 
> I am not sure if this is the correct mailing list to send this email...
> 
> I was trying to install on windows XP latest R-2.12.2 and my unvirus program
> (Immunet 3.0) reports a virus at open.exe while  this is unpacked:
> 
> W32.ATRAPS
> 
> Has anyone come across the same problem?
> 

What was wrong with the reply I sent you yesterday on R-help???



> Best,
> Costas
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Peter Dalgaard
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From bbolker at gmail.com  Mon Apr 11 14:31:21 2011
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 11 Apr 2011 12:31:21 +0000
Subject: [Rd] pd
References: <0FADEE07EF074EB580AA8A4133A03919@CPQ71292329354>
Message-ID: <loom.20110411T142931-615@post.gmane.org>

marc rousseau <mk04 <at> tlb.sympatico.ca> writes:

> 
> Hi
>   I'd like to know what does the letter in pd stand for ?
> thx

  In what context?

  The only R-context answers I can think of are "Peter Dalgaard"
(an R-core member) or "positive definite" (see ?pdClasses in
the nlme package).

   You're probably not looking for <http://en.wikipedia.org/wiki/PD>

  good luck -- if you give more context you might get a more
useful answer.

  Ben Bolker


From ripley at stats.ox.ac.uk  Mon Apr 11 16:57:32 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 11 Apr 2011 15:57:32 +0100
Subject: [Rd] Inconsistency between rowMeans documentation and reality?
In-Reply-To: <1302003186.2870.7.camel@chrysothemis.geog.ucl.ac.uk>
References: <1302003186.2870.7.camel@chrysothemis.geog.ucl.ac.uk>
Message-ID: <alpine.LFD.2.02.1104111553570.32033@gannet.stats.ox.ac.uk>

I suspect you omitted some of the help page:

   As they are written for speed, they blur over some of the subtleties
   of ?NaN? and ?NA?.

So, given that (and that real NA is a specific NaN) I think it is 
perfectly reasonable to claim they are consistent with mean.

On Tue, 5 Apr 2011, Gavin Simpson wrote:

> Dear List,
>
> I'm not even sure this is an issue or not, but ?rowMeans has:
>
> Value:
>
>     A numeric or complex array of suitable size, or a vector if the
>     result is one-dimensional.  The ?dimnames? (or ?names? for a
>     vector result) are taken from the original array.
>
>     If there are no values in a range to be summed over (after
>     removing missing values with ?na.rm = TRUE?), that component of
>     the output is set to ?0? (?*Sums?) or ?NA? (?*Means?), consistent
>     with ?sum? and ?mean?.
>
> However the output of mean() and rowMeans() is not exactly the same when
> all supplied values are missing.
>
>> mean(NA, na.rm = TRUE)
> [1] NaN
>> mean(rep(NA, 5), na.rm = TRUE)
> [1] NaN
>> rowMeans(matrix(rep(NA, 5), ncol = 5), na.rm = TRUE)
> [1] NA
>
> So in one sense, the outputs are not consistent:
>
>> is.nan(mean(rep(NA, 5), na.rm = TRUE))
> [1] TRUE
>> is.nan(rowMeans(matrix(rep(NA, 5), ncol = 5), na.rm = TRUE))
> [1] FALSE
>
> but in another they are:
>
>> is.na(mean(rep(NA, 5), na.rm = TRUE))
> [1] TRUE
>> is.na(rowMeans(matrix(rep(NA, 5), ncol = 5), na.rm = TRUE))
> [1] TRUE
>
> I'm not familiar enough with the details to know if this even matters,
> but wonder if something in the documentation needs a change or tweak to
> clarify what is returned. As I say, in one sense the outputs are not
> consistent.
>
>> sessionInfo()
> R version 2.13.0 beta (2011-04-04 r55298)
> Platform: x86_64-unknown-linux-gnu (64-bit)
>
> locale:
> [1] LC_CTYPE=en_GB.utf8       LC_NUMERIC=C
> [3] LC_TIME=en_GB.utf8        LC_COLLATE=en_GB.utf8
> [5] LC_MONETARY=C             LC_MESSAGES=en_GB.utf8
> [7] LC_PAPER=en_GB.utf8       LC_NAME=C
> [9] LC_ADDRESS=C              LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_GB.utf8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods
> [7] base
>
> loaded via a namespace (and not attached):
> [1] tools_2.13.0
>
> Thanks,
>
> Gavin
> -- 
> %~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
> Dr. Gavin Simpson             [t] +44 (0)20 7679 0522
> ECRC, UCL Geography,          [f] +44 (0)20 7679 0565
> Pearson Building,             [e] gavin.simpsonATNOSPAMucl.ac.uk
> Gower Street, London          [w] http://www.ucl.ac.uk/~ucfagls/
> UK. WC1E 6BT.                 [w] http://www.freshwaters.org.uk
> %~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From gavin.simpson at ucl.ac.uk  Mon Apr 11 17:11:29 2011
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Mon, 11 Apr 2011 16:11:29 +0100
Subject: [Rd] Inconsistency between rowMeans documentation and reality?
In-Reply-To: <alpine.LFD.2.02.1104111553570.32033@gannet.stats.ox.ac.uk>
References: <1302003186.2870.7.camel@chrysothemis.geog.ucl.ac.uk>
	<alpine.LFD.2.02.1104111553570.32033@gannet.stats.ox.ac.uk>
Message-ID: <1302534689.22559.23.camel@prometheus.geog.ucl.ac.uk>

On Mon, 2011-04-11 at 15:57 +0100, Prof Brian Ripley wrote:
> I suspect you omitted some of the help page:

Yes. My apologies, I don't know how I missed that - I did read it
several times aware that I might be overlooking something sensible such
as the sentence you quote.

Sorry for the noise.

G

>    As they are written for speed, they blur over some of the subtleties
>    of ?NaN? and ?NA?.
> 
> So, given that (and that real NA is a specific NaN) I think it is 
> perfectly reasonable to claim they are consistent with mean.
> 
> On Tue, 5 Apr 2011, Gavin Simpson wrote:
> 
> > Dear List,
> >
> > I'm not even sure this is an issue or not, but ?rowMeans has:
> >
> > Value:
> >
> >     A numeric or complex array of suitable size, or a vector if the
> >     result is one-dimensional.  The ?dimnames? (or ?names? for a
> >     vector result) are taken from the original array.
> >
> >     If there are no values in a range to be summed over (after
> >     removing missing values with ?na.rm = TRUE?), that component of
> >     the output is set to ?0? (?*Sums?) or ?NA? (?*Means?), consistent
> >     with ?sum? and ?mean?.
> >
> > However the output of mean() and rowMeans() is not exactly the same when
> > all supplied values are missing.
> >
> >> mean(NA, na.rm = TRUE)
> > [1] NaN
> >> mean(rep(NA, 5), na.rm = TRUE)
> > [1] NaN
> >> rowMeans(matrix(rep(NA, 5), ncol = 5), na.rm = TRUE)
> > [1] NA
> >
> > So in one sense, the outputs are not consistent:
> >
> >> is.nan(mean(rep(NA, 5), na.rm = TRUE))
> > [1] TRUE
> >> is.nan(rowMeans(matrix(rep(NA, 5), ncol = 5), na.rm = TRUE))
> > [1] FALSE
> >
> > but in another they are:
> >
> >> is.na(mean(rep(NA, 5), na.rm = TRUE))
> > [1] TRUE
> >> is.na(rowMeans(matrix(rep(NA, 5), ncol = 5), na.rm = TRUE))
> > [1] TRUE
> >
> > I'm not familiar enough with the details to know if this even matters,
> > but wonder if something in the documentation needs a change or tweak to
> > clarify what is returned. As I say, in one sense the outputs are not
> > consistent.
> >
> >> sessionInfo()
> > R version 2.13.0 beta (2011-04-04 r55298)
> > Platform: x86_64-unknown-linux-gnu (64-bit)
> >
> > locale:
> > [1] LC_CTYPE=en_GB.utf8       LC_NUMERIC=C
> > [3] LC_TIME=en_GB.utf8        LC_COLLATE=en_GB.utf8
> > [5] LC_MONETARY=C             LC_MESSAGES=en_GB.utf8
> > [7] LC_PAPER=en_GB.utf8       LC_NAME=C
> > [9] LC_ADDRESS=C              LC_TELEPHONE=C
> > [11] LC_MEASUREMENT=en_GB.utf8 LC_IDENTIFICATION=C
> >
> > attached base packages:
> > [1] stats     graphics  grDevices utils     datasets  methods
> > [7] base
> >
> > loaded via a namespace (and not attached):
> > [1] tools_2.13.0
> >
> > Thanks,
> >
> > Gavin
> > -- 
> > %~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
> > Dr. Gavin Simpson             [t] +44 (0)20 7679 0522
> > ECRC, UCL Geography,          [f] +44 (0)20 7679 0565
> > Pearson Building,             [e] gavin.simpsonATNOSPAMucl.ac.uk
> > Gower Street, London          [w] http://www.ucl.ac.uk/~ucfagls/
> > UK. WC1E 6BT.                 [w] http://www.freshwaters.org.uk
> > %~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
 Dr. Gavin Simpson             [t] +44 (0)20 7679 0522
 ECRC, UCL Geography,          [f] +44 (0)20 7679 0565
 Pearson Building,             [e] gavin.simpsonATNOSPAMucl.ac.uk
 Gower Street, London          [w] http://www.ucl.ac.uk/~ucfagls/
 UK. WC1E 6BT.                 [w] http://www.freshwaters.org.uk
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%


From ligges at statistik.tu-dortmund.de  Mon Apr 11 17:13:36 2011
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Mon, 11 Apr 2011 17:13:36 +0200
Subject: [Rd] R CMD build --resave-data
In-Reply-To: <4DA24F8A.7030405@fhcrc.org>
References: <4DA24F8A.7030405@fhcrc.org>
Message-ID: <4DA31AA0.2050209@statistik.tu-dortmund.de>



On 11.04.2011 02:47, Herv? Pag?s wrote:
> Hi,
>
> More about the new --resave-data option
>
> As mentioned previously here
>
> https://stat.ethz.ch/pipermail/r-devel/2011-April/060511.html
>
> 'R CMD build' and 'R CMD INSTALL' handle this new option
> inconsistently. The former does --resave-data="gzip" by default.
> The latter doesn't seem to support the --resave-data= syntax:
> the --resave-data flag must either be present or not. And by
> default 'R CMD INSTALL' won't resave the data.
>
> Also, because now 'R CMD build' is resaving the data, shouldn't it
> reinstall the package in order to be able to do this correctly?
>
> Here is why. There is this new warning in 'R CMD check' that complains
> about files not of a type allowed in a 'data' directory:
>
>
> http://bioconductor.org/checkResults/2.8/bioc-LATEST/Icens/lamb1-checksrc.html
>
>
> The Icens package also has .R files under data/ with things like:
>
> bet <- matrix(scan("CMVdata", quiet=TRUE),nc=5,byr=TRUE)
>
> i.e. the R code needs to access some of the text files located
> in the data/ folder. So in order to get rid of this warning I
> tried to move those text files to inst/extdata/ and I modified
> the code in the .R file so it does:
>
> CMVdata_filepath <- system.file("extdata", "CMVdata", package="Icens")
> bet <- matrix(scan(CMVdata_filepath, quiet=TRUE),nc=5,byr=TRUE)
>
> But now 'R CMD build' fails to resave the data because the package
> was not installed first and the CMVdata file could not be found.
>
> Unfortunately, for a lot of people that means that the safe way to
> build a source tarball now is with
>
> R CMD build --keep-empty-dirs --no-resave-data


Herv?,

actually is makes some sense to have these defaults from a CRAN 
maintainer's point of view:

--keep-empty-dirs:
we found many packages containing empty dirs unnecessarily and the idea 
is to exclude them at the build state rather than at the later 
installation stage. Note that the package maintainer is supposed to run 
build (and knows if the empty dirs are to be included, the user who runs 
INSTALL does not).

--no-resave-data:
We found many packages with unsufficiently compressed data. This should 
be fixed when building the package, not later when installing it, since 
the reduces size is useful in the source tarball already.

So it does make some sense to have different defaults in build as 
opposed to INSTALL from my point of view (although I could live with 
different, tough).

If you need further arguments for the discussion: I also tend to use 
--no-vignettes nowadays if my code does not change considerably. ;-)

Best wishes,
Uwe



> I hope the list of options/flags that we need to use to "fix" 'R CMD
> build' (and make it consistent with R CMD INSTALL) is not going to
> grow too much ;-)
>
> Thanks,
> H.
>
>


From ligges at statistik.tu-dortmund.de  Mon Apr 11 17:25:40 2011
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Mon, 11 Apr 2011 17:25:40 +0200
Subject: [Rd] duplicates() function
In-Reply-To: <1302303928862-3437614.post@n4.nabble.com>
References: <4D9F22BE.5000502@gmail.com>
	<1302303928862-3437614.post@n4.nabble.com>
Message-ID: <4DA31D74.6030504@statistik.tu-dortmund.de>

Thanks for your answer, but:
1. can you please cite the question? It is hard for mailing list readers 
to follow now.
2. I think
    which(duplicated(x))
should be simpler, faster and less confusing, if your code would be the 
solution - which is not.
3. Please read the original question carefuly and find that your code 
and my optimization of it above gives a different undesired answer.

Best,
Uwe Ligges






On 09.04.2011 01:05, B77S wrote:
> which(duplicated(x)=="TRUE")
>
> --
> View this message in context: http://r.789695.n4.nabble.com/duplicates-function-tp3436584p3437614.html
> Sent from the R devel mailing list archive at Nabble.com.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From cubranic at stat.ubc.ca  Mon Apr 11 17:28:29 2011
From: cubranic at stat.ubc.ca (Davor Cubranic)
Date: Mon, 11 Apr 2011 08:28:29 -0700
Subject: [Rd] Wish there were a "strict mode" for R interpreter. What
In-Reply-To: <XFMail.110409220813.ted.harding@wlandres.net>
References: <XFMail.110409220813.ted.harding@wlandres.net>
Message-ID: <EDD2DF2D-1D22-4650-9366-B915B2C79ADB@stat.ubc.ca>

On 2011-04-09, at 2:08 PM, Ted Harding wrote:

> I think the right thing to so is to introduce the students to the
> basics of scoping, early in the process of learning R.

I know the basics of scoping perfectly well, but that doesn't stop me from occasionally misspelling a variable name that only causes an error much later.

OTOH, I think with Perl you can start declaring your variables "local" and keep the interpreter happy. But in R's context you then have to also start declaring what you expect to inherit from parent environments, and pretty soon the code is so encrusted with annotation barnacles that it loses the simplicity that  makes R so nice in the interactive mode. 

What would be really nice is if we had a smart R editor/IDE that would "DWIM" and put a red underline under a misspelled name, but leave it alone when, as Duncan said, it's in the environment. 

Davor

From simon.urbanek at r-project.org  Mon Apr 11 17:46:20 2011
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Mon, 11 Apr 2011 11:46:20 -0400
Subject: [Rd] Wish there were a "strict mode" for R interpreter. What
In-Reply-To: <EDD2DF2D-1D22-4650-9366-B915B2C79ADB@stat.ubc.ca>
References: <XFMail.110409220813.ted.harding@wlandres.net>
	<EDD2DF2D-1D22-4650-9366-B915B2C79ADB@stat.ubc.ca>
Message-ID: <C6D0A838-2ED1-49B5-84BB-2FA05D79F84F@r-project.org>


On Apr 11, 2011, at 11:28 AM, Davor Cubranic wrote:

> On 2011-04-09, at 2:08 PM, Ted Harding wrote:
> 
>> I think the right thing to so is to introduce the students to the
>> basics of scoping, early in the process of learning R.
> 
> I know the basics of scoping perfectly well, but that doesn't stop me from occasionally misspelling a variable name that only causes an error much later.
> 
> OTOH, I think with Perl you can start declaring your variables "local" and keep the interpreter happy. But in R's context you then have to also start declaring what you expect to inherit from parent environments, and pretty soon the code is so encrusted with annotation barnacles that it loses the simplicity that  makes R so nice in the interactive mode. 
> 
> What would be really nice is if we had a smart R editor/IDE that would "DWIM" and put a red underline under a misspelled name, but leave it alone when, as Duncan said, it's in the environment. 
> 

... which is, of course, impossible since the editor has no idea what environment you will evaluate the function in ... It can make assumptions but they may as wrong as the spurious warnings discussed so people will complain either way ;)

Cheers,
Simon


From spencer.graves at prodsyse.com  Mon Apr 11 18:04:59 2011
From: spencer.graves at prodsyse.com (Spencer Graves)
Date: Mon, 11 Apr 2011 09:04:59 -0700
Subject: [Rd] Wish there were a "strict mode" for R interpreter. What
In-Reply-To: <C6D0A838-2ED1-49B5-84BB-2FA05D79F84F@r-project.org>
References: <XFMail.110409220813.ted.harding@wlandres.net>	<EDD2DF2D-1D22-4650-9366-B915B2C79ADB@stat.ubc.ca>
	<C6D0A838-2ED1-49B5-84BB-2FA05D79F84F@r-project.org>
Message-ID: <4DA326AB.2010107@prodsyse.com>

On 4/11/2011 8:46 AM, Simon Urbanek wrote:
> On Apr 11, 2011, at 11:28 AM, Davor Cubranic wrote:
>
>> On 2011-04-09, at 2:08 PM, Ted Harding wrote:
>>
>>> I think the right thing to so is to introduce the students to the
>>> basics of scoping, early in the process of learning R.
>> I know the basics of scoping perfectly well, but that doesn't stop me from occasionally misspelling a variable name that only causes an error much later.
>>
>> OTOH, I think with Perl you can start declaring your variables "local" and keep the interpreter happy. But in R's context you then have to also start declaring what you expect to inherit from parent environments, and pretty soon the code is so encrusted with annotation barnacles that it loses the simplicity that  makes R so nice in the interactive mode.
>>
>> What would be really nice is if we had a smart R editor/IDE that would "DWIM" and put a red underline under a misspelled name, but leave it alone when, as Duncan said, it's in the environment.
>>
> ... which is, of course, impossible since the editor has no idea what environment you will evaluate the function in ... It can make assumptions but they may as wrong as the spurious warnings discussed so people will complain either way ;)

       For the record, my "complaint" stemmed from my inability to see a 
way to get rid of that message in that context.  In most cases, I've 
found that message to be very valuable in identifying latent bugs in 
code.  In that context, however, the message seemed inappropriate.  
Duncan privately suggested I add "LazyData:  yes" to the package 
DESCRIPTION file.  I did that, and the offending message disappeared!


       Thanks again to Duncan.


       Best Wishes,
       Spencer

> Cheers,
> Simon
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


-- 
Spencer Graves, PE, PhD
President and Chief Operating Officer
Structure Inspection and Monitoring, Inc.
751 Emerson Ct.
San Jos?, CA 95126
ph:  408-655-4567


From wdunlap at tibco.com  Mon Apr 11 19:10:07 2011
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 11 Apr 2011 10:10:07 -0700
Subject: [Rd] sort.int(S3object) strips class but not the is.object flag
Message-ID: <77EB52C6DD32BA4D87471DCD70C8D700041B2FC4@NA-PA-VBE03.na.tibco.com>

If x has an S3 class then sort.int(x) returns a value
without an S3 class but which has the is.object flag set,
which, I think, causes identical() give a false/misleading
report:
 
  > x <- structure(1:3, class="unrecognizedClass")
  > y <- sort.int(x)
  > t <- 1:3
  > identical(y, t) # expect TRUE
  [1] FALSE
  > identical(as.vector(y), as.vector(t)) # expect TRUE
  [1] FALSE
  > dput(y)
  1:3
  > dput(t)
  1:3
  > class(y)
  [1] "integer"
  > class(t)
  [1] "integer"
  > is.object(y)
  [1] TRUE
  > is.object(t)
  [1] FALSE

The files made by
  save(t, file="t.Rdata", compress=FALSE)
  save(y, file="y.Rdata", compress=FALSE)
differ in 2 places, where the first is presumably
the name of the object:
  % cmp -l y.Rdata t.Rdata
  36 171 164
  39   1   0
(The problem persists after a save/load cycle.)

This is on R 2.12.2 on Linux.  Sorry, I don't have 2.13.0
yet installed.

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com 


From wdunlap at tibco.com  Mon Apr 11 19:28:22 2011
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 11 Apr 2011 10:28:22 -0700
Subject: [Rd] sort.int(S3object) strips class but not the is.object flag
In-Reply-To: <77EB52C6DD32BA4D87471DCD70C8D700041B2FC4@NA-PA-VBE03.na.tibco.com>
References: <77EB52C6DD32BA4D87471DCD70C8D700041B2FC4@NA-PA-VBE03.na.tibco.com>
Message-ID: <77EB52C6DD32BA4D87471DCD70C8D700041B2FD5@NA-PA-VBE03.na.tibco.com>

> -----Original Message-----
> From: r-devel-bounces at r-project.org 
> [mailto:r-devel-bounces at r-project.org] On Behalf Of William Dunlap
> Sent: Monday, April 11, 2011 10:10 AM
> To: R-devel at r-project.org
> Subject: [Rd] sort.int(S3object) strips class but not the 
> is.object flag
> 
> If x has an S3 class then sort.int(x) returns a value
> without an S3 class but which has the is.object flag set,
> which, I think, causes identical() give a false/misleading
> report:
>  
>   > x <- structure(1:3, class="unrecognizedClass")
>   > y <- sort.int(x)
>   > t <- 1:3
>   > identical(y, t) # expect TRUE
>   [1] FALSE

The misleading is.object flag can also affect
the time it takes to sort objects (it looks like
xtfrm is only called when is.object reports TRUE):
  > system.time(for(i in 1:1e5) order(y)) # is.object(y) is TRUE
     user  system elapsed 
    12.07    0.00   11.28 
  > system.time(for(i in 1:1e5) order(t)) # is.object(t) is FALSE
     user  system elapsed 
     1.98    0.01    2.01

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com 
 
>   > identical(as.vector(y), as.vector(t)) # expect TRUE
>   [1] FALSE
>   > dput(y)
>   1:3
>   > dput(t)
>   1:3
>   > class(y)
>   [1] "integer"
>   > class(t)
>   [1] "integer"
>   > is.object(y)
>   [1] TRUE
>   > is.object(t)
>   [1] FALSE
> 
> The files made by
>   save(t, file="t.Rdata", compress=FALSE)
>   save(y, file="y.Rdata", compress=FALSE)
> differ in 2 places, where the first is presumably
> the name of the object:
>   % cmp -l y.Rdata t.Rdata
>   36 171 164
>   39   1   0
> (The problem persists after a save/load cycle.)
> 
> This is on R 2.12.2 on Linux.  Sorry, I don't have 2.13.0
> yet installed.
> 
> Bill Dunlap
> Spotfire, TIBCO Software
> wdunlap tibco.com 
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 


From murdoch.duncan at gmail.com  Mon Apr 11 19:34:05 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 11 Apr 2011 13:34:05 -0400
Subject: [Rd] sort.int(S3object) strips class but not the is.object flag
In-Reply-To: <77EB52C6DD32BA4D87471DCD70C8D700041B2FC4@NA-PA-VBE03.na.tibco.com>
References: <77EB52C6DD32BA4D87471DCD70C8D700041B2FC4@NA-PA-VBE03.na.tibco.com>
Message-ID: <4DA33B8D.60006@gmail.com>

On 11/04/2011 1:10 PM, William Dunlap wrote:
> If x has an S3 class then sort.int(x) returns a value
> without an S3 class but which has the is.object flag set,
> which, I think, causes identical() give a false/misleading
> report:

I think your analysis is correct.  It's too late for 2.13.0, but I'll 
fix this in R-devel, and backport it to 2.13.0-patched.

Duncan Murdoch

>
>    >  x<- structure(1:3, class="unrecognizedClass")
>    >  y<- sort.int(x)
>    >  t<- 1:3
>    >  identical(y, t) # expect TRUE
>    [1] FALSE
>    >  identical(as.vector(y), as.vector(t)) # expect TRUE
>    [1] FALSE
>    >  dput(y)
>    1:3
>    >  dput(t)
>    1:3
>    >  class(y)
>    [1] "integer"
>    >  class(t)
>    [1] "integer"
>    >  is.object(y)
>    [1] TRUE
>    >  is.object(t)
>    [1] FALSE
>
> The files made by
>    save(t, file="t.Rdata", compress=FALSE)
>    save(y, file="y.Rdata", compress=FALSE)
> differ in 2 places, where the first is presumably
> the name of the object:
>    % cmp -l y.Rdata t.Rdata
>    36 171 164
>    39   1   0
> (The problem persists after a save/load cycle.)
>
> This is on R 2.12.2 on Linux.  Sorry, I don't have 2.13.0
> yet installed.
>
> Bill Dunlap
> Spotfire, TIBCO Software
> wdunlap tibco.com
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From murdoch.duncan at gmail.com  Mon Apr 11 20:05:11 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 11 Apr 2011 14:05:11 -0400
Subject: [Rd] duplicates() function
In-Reply-To: <BANLkTinVqU+yZ0JgQzJfvDW6GQKk0kAG_A@mail.gmail.com>
References: <bug-14552-16@http.bugs.r-project.org/bugzilla3/>
	<20110408142610.88AEC970477@ix.urbanek.info>
	<B722DD6C-3B97-46EC-B369-8316F0F65D1F@cbs.dk>
	<4D9F22BE.5000502@gmail.com>
	<BANLkTimQEeXMPCjWaHuQZ74t8d0A_9XeyQ@mail.gmail.com>
	<4D9F26A3.6060609@gmail.com>
	<BANLkTinVqU+yZ0JgQzJfvDW6GQKk0kAG_A@mail.gmail.com>
Message-ID: <4DA342D7.5000403@gmail.com>

On 08/04/2011 11:39 AM, Joshua Ulrich wrote:
> On Fri, Apr 8, 2011 at 10:15 AM, Duncan Murdoch
> <murdoch.duncan at gmail.com>  wrote:
> >  On 08/04/2011 11:08 AM, Joshua Ulrich wrote:
> >>
> >>  How about:
> >>
> >>  y<- rep(NA,length(x))
> >>  y[duplicated(x)]<- match(x[duplicated(x)] ,x)
> >
> >  That's a nice solution for vectors.  Unfortunately for me, I have a matrix
> >  (which duplicated() handles by checking whole rows).  So a better example
> >  that I should have posted would be
> >
> >  x<-  cbind(1, c(9,7,9,3,7) )
> >
> >  and I'd still like the same output
> >
> For a matrix, could you apply the same strategy used in duplicated()?
>
> y<- rep(NA,NROW(x))
> temp<- apply(x, 1, function(x) paste(x, collapse="\r"))
> y[duplicated(temp)]<- match(temp[duplicated(temp)], temp)

Since this thread hasn't ended, I will say that I think this solution is 
the best I've seen for my specific problem.  I was actually surprised 
that duplicated() did the string concatenation trick, but since it does, 
it makes a lot of sense to do the same in duplicates().

I think a good general purpose solution that worked wherever 
duplicated() works would likely be harder, because we don't really have 
the right primitives to make it work.

Duncan Murdoch
> >>    duplicated(x)
> >
> >  [1] FALSE FALSE  TRUE FALSE TRUE
> >
> >>    duplicates(x)
> >
> >  [1] NA NA  1 NA  2
> >
> >
> >  Duncan Murdoch
> >
> >>  --
> >>  Joshua Ulrich  |  FOSS Trading: www.fosstrading.com
> >>
> >>
> >>
> >>  On Fri, Apr 8, 2011 at 9:59 AM, Duncan Murdoch<murdoch.duncan at gmail.com>
> >>    wrote:
> >>  >    I need a function which is similar to duplicated(), but instead of
> >>  >  returning
> >>  >    TRUE/FALSE, returns indices of which element was duplicated.  That is,
> >>  >
> >>  >>    x<- c(9,7,9,3,7)
> >>  >>    duplicated(x)
> >>  >    [1] FALSE FALSE  TRUE FALSE TRUE
> >>  >
> >>  >>    duplicates(x)
> >>  >    [1] NA NA  1 NA  2
> >>  >
> >>  >    (so that I know that element 3 is a duplicate of element 1, and element
> >>  >  5 is
> >>  >    a duplicate of element 2, whereas the others were not duplicated
> >>  >  according
> >>  >    to our definition.)
> >>  >
> >>  >    Is there a simple way to write this function?  I have  an ugly
> >>  >    implementation in R that loops over all the values; it would make more
> >>  >  sense
> >>  >    to redo it in C, if there isn't a simple implementation I missed.
> >>  >
> >>  >    Duncan Murdoch
> >>  >
> >>  >    ______________________________________________
> >>  >    R-devel at r-project.org mailing list
> >>  >    https://stat.ethz.ch/mailman/listinfo/r-devel
> >>  >
> >
> >


From murdoch.duncan at gmail.com  Mon Apr 11 20:07:36 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 11 Apr 2011 14:07:36 -0400
Subject: [Rd] sort.int(S3object) strips class but not the is.object flag
In-Reply-To: <77EB52C6DD32BA4D87471DCD70C8D700041B2FC4@NA-PA-VBE03.na.tibco.com>
References: <77EB52C6DD32BA4D87471DCD70C8D700041B2FC4@NA-PA-VBE03.na.tibco.com>
Message-ID: <4DA34368.1090503@gmail.com>

On 11/04/2011 1:10 PM, William Dunlap wrote:
> If x has an S3 class then sort.int(x) returns a value
> without an S3 class but which has the is.object flag set,
> which, I think, causes identical() give a false/misleading
> report:

Fixed in R-devel as of r55409.

Duncan Murdoch

>
>    >  x<- structure(1:3, class="unrecognizedClass")
>    >  y<- sort.int(x)
>    >  t<- 1:3
>    >  identical(y, t) # expect TRUE
>    [1] FALSE
>    >  identical(as.vector(y), as.vector(t)) # expect TRUE
>    [1] FALSE
>    >  dput(y)
>    1:3
>    >  dput(t)
>    1:3
>    >  class(y)
>    [1] "integer"
>    >  class(t)
>    [1] "integer"
>    >  is.object(y)
>    [1] TRUE
>    >  is.object(t)
>    [1] FALSE
>
> The files made by
>    save(t, file="t.Rdata", compress=FALSE)
>    save(y, file="y.Rdata", compress=FALSE)
> differ in 2 places, where the first is presumably
> the name of the object:
>    % cmp -l y.Rdata t.Rdata
>    36 171 164
>    39   1   0
> (The problem persists after a save/load cycle.)
>
> This is on R 2.12.2 on Linux.  Sorry, I don't have 2.13.0
> yet installed.
>
> Bill Dunlap
> Spotfire, TIBCO Software
> wdunlap tibco.com
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From geoffjentry at hexdump.org  Mon Apr 11 20:34:06 2011
From: geoffjentry at hexdump.org (Geoff Jentry)
Date: Mon, 11 Apr 2011 11:34:06 -0700
Subject: [Rd] Conditional "Suggests"
Message-ID: <Pine.LNX.4.64.1104111128300.9064@cardinals.dreamhost.com>

Hi ...

I came across an old post on R-devel that describes a situation very 
similar to one I find myself in:
https://stat.ethz.ch/pipermail/r-devel/2006-December/043917.html

As you can see in Gregor's example, the situation is that if I am writing 
Pkg A, I want to detect if Pkg B exists - if so use some functionality 
from there, otherwise do something else.

To me this reads as being in the wheelhouse of what 'Suggests' is supposed 
to imply, as per the R Extensions manual.  The problem here is that if 
PkgB is put down as 'Suggests', it is required for R CMD check to pass 
which seems to defeat the purpose of this exercise a bit.

If one puts it as 'Enhances' one gets a NOTE earlier in check but then the 
WARNING described in this post due to the require() call.

Is there a good way around this situation, such that the PkgA can pass a R 
CMD check if PkgB doesn't exist on the system, for instance a case where 
PkgB isn't available for a particular OS?  If there are multiple methods 
around this problem, is one more blessed by the powers that be than 
others?

Thanks
-J


From spencer.graves at prodsyse.com  Mon Apr 11 20:53:33 2011
From: spencer.graves at prodsyse.com (Spencer Graves)
Date: Mon, 11 Apr 2011 11:53:33 -0700
Subject: [Rd] Wish there were a "strict mode" for R interpreter. What
In-Reply-To: <4DA326AB.2010107@prodsyse.com>
References: <XFMail.110409220813.ted.harding@wlandres.net>	<EDD2DF2D-1D22-4650-9366-B915B2C79ADB@stat.ubc.ca>	<C6D0A838-2ED1-49B5-84BB-2FA05D79F84F@r-project.org>
	<4DA326AB.2010107@prodsyse.com>
Message-ID: <4DA34E2D.2060705@prodsyse.com>

Another example:


plot.landsurveydata: no visible binding for global variable 'value'
plot.landsurveydata: no visible binding for global variable 'variable'


plot.landsurveydata <- function(...){
# ...
qplot(time., value, data=X, color=variable, ...)
# where value and variable are columns of the data.frame X


       Is there a way to tell "R CMD check" that qplot looks for time., 
value and variable as columns of X?


       Thanks,
       Spencer


On 4/11/2011 9:04 AM, Spencer Graves wrote:
> On 4/11/2011 8:46 AM, Simon Urbanek wrote:
>> On Apr 11, 2011, at 11:28 AM, Davor Cubranic wrote:
>>
>>> On 2011-04-09, at 2:08 PM, Ted Harding wrote:
>>>
>>>> I think the right thing to so is to introduce the students to the
>>>> basics of scoping, early in the process of learning R.
>>> I know the basics of scoping perfectly well, but that doesn't stop 
>>> me from occasionally misspelling a variable name that only causes an 
>>> error much later.
>>>
>>> OTOH, I think with Perl you can start declaring your variables 
>>> "local" and keep the interpreter happy. But in R's context you then 
>>> have to also start declaring what you expect to inherit from parent 
>>> environments, and pretty soon the code is so encrusted with 
>>> annotation barnacles that it loses the simplicity that  makes R so 
>>> nice in the interactive mode.
>>>
>>> What would be really nice is if we had a smart R editor/IDE that 
>>> would "DWIM" and put a red underline under a misspelled name, but 
>>> leave it alone when, as Duncan said, it's in the environment.
>>>
>> ... which is, of course, impossible since the editor has no idea what 
>> environment you will evaluate the function in ... It can make 
>> assumptions but they may as wrong as the spurious warnings discussed 
>> so people will complain either way ;)
>
>       For the record, my "complaint" stemmed from my inability to see 
> a way to get rid of that message in that context.  In most cases, I've 
> found that message to be very valuable in identifying latent bugs in 
> code.  In that context, however, the message seemed inappropriate.  
> Duncan privately suggested I add "LazyData:  yes" to the package 
> DESCRIPTION file.  I did that, and the offending message disappeared!
>
>
>       Thanks again to Duncan.
>
>
>       Best Wishes,
>       Spencer
>
>> Cheers,
>> Simon
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
>


-- 
Spencer Graves, PE, PhD
President and Chief Operating Officer
Structure Inspection and Monitoring, Inc.
751 Emerson Ct.
San Jos?, CA 95126
ph:  408-655-4567


From proebuck at mdanderson.org  Mon Apr 11 21:41:26 2011
From: proebuck at mdanderson.org (Roebuck,Paul L)
Date: Mon, 11 Apr 2011 14:41:26 -0500
Subject: [Rd] Wish there were a "strict mode" for R interpreter. What
In-Reply-To: <4DA326AB.2010107@prodsyse.com>
Message-ID: <C9C8C396.17BDF%proebuck@mdanderson.org>




On 4/11/11 11:04 AM, "Spencer Graves" <spencer.graves at prodsyse.com> wrote:

> On 4/11/2011 8:46 AM, Simon Urbanek wrote:
>> On Apr 11, 2011, at 11:28 AM, Davor Cubranic wrote:
>> 
>>> On 2011-04-09, at 2:08 PM, Ted Harding wrote:
>>> 
>>>> I think the right thing to so is to introduce the students to the
>>>> basics of scoping, early in the process of learning R.
>>> I know the basics of scoping perfectly well, but that doesn't stop me from
>>> occasionally misspelling a variable name that only causes an error much
>>> later.
>>> 
>>> OTOH, I think with Perl you can start declaring your variables "local" and
>>> keep the interpreter happy. But in R's context you then have to also start
>>> declaring what you expect to inherit from parent environments, and pretty
>>> soon the code is so encrusted with annotation barnacles that it loses the
>>> simplicity that  makes R so nice in the interactive mode.
>>> 
>>> What would be really nice is if we had a smart R editor/IDE that would
>>> "DWIM" and put a red underline under a misspelled name, but leave it alone
>>> when, as Duncan said, it's in the environment.
>>> 
>> ... which is, of course, impossible since the editor has no idea what
>> environment you will evaluate the function in ... It can make assumptions but
>> they may as wrong as the spurious warnings discussed so people will complain
>> either way ;)
> 
>        For the record, my "complaint" stemmed from my inability to see a
> way to get rid of that message in that context.  In most cases, I've
> found that message to be very valuable in identifying latent bugs in
> code.  In that context, however, the message seemed inappropriate.
> Duncan privately suggested I add "LazyData:  yes" to the package
> DESCRIPTION file.  I did that, and the offending message disappeared!

So would it be possible to have something akin to lint comment directives
to allow specific "errors" to be ignored by codetools?


From murdoch.duncan at gmail.com  Mon Apr 11 22:16:54 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 11 Apr 2011 16:16:54 -0400
Subject: [Rd] Wish there were a "strict mode" for R interpreter. What
In-Reply-To: <C9C8C396.17BDF%proebuck@mdanderson.org>
References: <C9C8C396.17BDF%proebuck@mdanderson.org>
Message-ID: <4DA361B6.6050304@gmail.com>

On 11/04/2011 3:41 PM, Roebuck,Paul L wrote:
>
>
> On 4/11/11 11:04 AM, "Spencer Graves"<spencer.graves at prodsyse.com>  wrote:
>
> >  On 4/11/2011 8:46 AM, Simon Urbanek wrote:
> >>  On Apr 11, 2011, at 11:28 AM, Davor Cubranic wrote:
> >>
> >>>  On 2011-04-09, at 2:08 PM, Ted Harding wrote:
> >>>
> >>>>  I think the right thing to so is to introduce the students to the
> >>>>  basics of scoping, early in the process of learning R.
> >>>  I know the basics of scoping perfectly well, but that doesn't stop me from
> >>>  occasionally misspelling a variable name that only causes an error much
> >>>  later.
> >>>
> >>>  OTOH, I think with Perl you can start declaring your variables "local" and
> >>>  keep the interpreter happy. But in R's context you then have to also start
> >>>  declaring what you expect to inherit from parent environments, and pretty
> >>>  soon the code is so encrusted with annotation barnacles that it loses the
> >>>  simplicity that  makes R so nice in the interactive mode.
> >>>
> >>>  What would be really nice is if we had a smart R editor/IDE that would
> >>>  "DWIM" and put a red underline under a misspelled name, but leave it alone
> >>>  when, as Duncan said, it's in the environment.
> >>>
> >>  ... which is, of course, impossible since the editor has no idea what
> >>  environment you will evaluate the function in ... It can make assumptions but
> >>  they may as wrong as the spurious warnings discussed so people will complain
> >>  either way ;)
> >
> >         For the record, my "complaint" stemmed from my inability to see a
> >  way to get rid of that message in that context.  In most cases, I've
> >  found that message to be very valuable in identifying latent bugs in
> >  code.  In that context, however, the message seemed inappropriate.
> >  Duncan privately suggested I add "LazyData:  yes" to the package
> >  DESCRIPTION file.  I did that, and the offending message disappeared!
>
> So would it be possible to have something akin to lint comment directives
> to allow specific "errors" to be ignored by codetools?

Of course it would.  Codetools is GPL licensed, so just do it.

Duncan Murdoch


From hadley at rice.edu  Mon Apr 11 22:23:32 2011
From: hadley at rice.edu (Hadley Wickham)
Date: Mon, 11 Apr 2011 15:23:32 -0500
Subject: [Rd] Conditional "Suggests"
In-Reply-To: <Pine.LNX.4.64.1104111128300.9064@cardinals.dreamhost.com>
References: <Pine.LNX.4.64.1104111128300.9064@cardinals.dreamhost.com>
Message-ID: <BANLkTinTW_eSHahN3+a+MKON4XJ_MMeT3A@mail.gmail.com>

On Mon, Apr 11, 2011 at 1:34 PM, Geoff Jentry <geoffjentry at hexdump.org> wrote:
> Hi ...
>
> I came across an old post on R-devel that describes a situation very similar
> to one I find myself in:
> https://stat.ethz.ch/pipermail/r-devel/2006-December/043917.html
>
> As you can see in Gregor's example, the situation is that if I am writing
> Pkg A, I want to detect if Pkg B exists - if so use some functionality from
> there, otherwise do something else.
>
> To me this reads as being in the wheelhouse of what 'Suggests' is supposed
> to imply, as per the R Extensions manual. ?The problem here is that if PkgB
> is put down as 'Suggests', it is required for R CMD check to pass which
> seems to defeat the purpose of this exercise a bit.

No, because R CMD check is only run by the developer, not the user.

Hadley

-- 
Assistant Professor / Dobelman Family Junior Chair
Department of Statistics / Rice University
http://had.co.nz/


From geoffjentry at hexdump.org  Mon Apr 11 22:30:24 2011
From: geoffjentry at hexdump.org (Geoff Jentry)
Date: Mon, 11 Apr 2011 13:30:24 -0700
Subject: [Rd] Conditional "Suggests"
In-Reply-To: <BANLkTinTW_eSHahN3+a+MKON4XJ_MMeT3A@mail.gmail.com>
References: <Pine.LNX.4.64.1104111128300.9064@cardinals.dreamhost.com>
	<BANLkTinTW_eSHahN3+a+MKON4XJ_MMeT3A@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.1104111328460.9064@cardinals.dreamhost.com>

On Mon, 11 Apr 2011, Hadley Wickham wrote:
>> To me this reads as being in the wheelhouse of what 'Suggests' is supposed
>> to imply, as per the R Extensions manual. ?The problem here is that if PkgB
>> is put down as 'Suggests', it is required for R CMD check to pass which
>> seems to defeat the purpose of this exercise a bit.
> No, because R CMD check is only run by the developer, not the user.

It's not only run by the developer, it's also run by CRAN.  The situation 
might happen where for a particular platform (e.g. Windows) that PkgB 
doesn't exist.  It'd be nice to be able to avoid a situation where PkgA 
can't exist for that platform simply because PkgB - which isn't even 
necessarily required for PkgA to be used - doesn't exist for it.

-J


From jorismeys at gmail.com  Mon Apr 11 23:53:52 2011
From: jorismeys at gmail.com (Joris Meys)
Date: Mon, 11 Apr 2011 23:53:52 +0200
Subject: [Rd] proposal for adapting code of function gl()
Message-ID: <BANLkTikrm_7YnT02jA5fNGrJkF8vh9xEPw@mail.gmail.com>

Based on a discussion on SO I ran some tests and found that converting
to a factor is best done early in the process. Hence, I propose to
rewrite the gl() function as :

gl2 <- function(n, k, length = n * k, labels = 1:n, ordered = FALSE){
  rep(
      rep(
        factor(1:n,levels=1:n,labels=labels, ordered=ordered),rep.int(k,n)
      ),length.out=length
  )
}

Some test results  :

> system.time(X1 <- gl(5,1e7))
   user  system elapsed
  29.21    0.30   29.58

> system.time(X2 <- gl2(5,1e7))
   user  system elapsed
   1.87    0.45    2.37

> all.equal(X1,X2)
[1] TRUE

> system.time(X1 <- gl(5,100,1e7))
   user  system elapsed
   5.98    0.05    6.05

> system.time(X2 <- gl2(5,100,1e7))
   user  system elapsed
   0.21    0.03    0.25

> all.equal(X1,X2)
[1] TRUE

> system.time(X1 <- gl(5,100,1e7,labels=letters[1:5]))
   user  system elapsed
   5.88    0.02    5.98

> system.time(X2 <- gl2(5,100,1e7,labels=letters[1:5]))
   user  system elapsed
   0.20    0.05    0.25

> all.equal(X1,X2)
[1] TRUE

> system.time(X1 <- gl(5,100,1e7,labels=letters[1:5],ordered=T))
   user  system elapsed
   5.82    0.03    5.89

> system.time(X2 <- gl2(5,100,1e7,labels=letters[1:5],ordered=T))
   user  system elapsed
   0.22    0.04    0.25

> all.equal(X1,X2)
[1] TRUE

reference to SO :
http://stackoverflow.com/questions/5627264/how-can-i-efficiently-construct-a-very-long-factor-with-few-levels

-- 
Joris Meys
Statistical consultant

Ghent University
Faculty of Bioscience Engineering
Department of Applied mathematics, biometrics and process control

tel : +32 9 264 59 87
Joris.Meys at Ugent.be
-------------------------------
Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php


From pdalgd at gmail.com  Tue Apr 12 08:51:36 2011
From: pdalgd at gmail.com (peter dalgaard)
Date: Tue, 12 Apr 2011 08:51:36 +0200
Subject: [Rd] proposal for adapting code of function gl()
In-Reply-To: <BANLkTikrm_7YnT02jA5fNGrJkF8vh9xEPw@mail.gmail.com>
References: <BANLkTikrm_7YnT02jA5fNGrJkF8vh9xEPw@mail.gmail.com>
Message-ID: <CDFA6915-54EC-47D8-8C77-DA02BD13BA7C@gmail.com>


On Apr 11, 2011, at 23:53 , Joris Meys wrote:

> Based on a discussion on SO I ran some tests and found that converting
> to a factor is best done early in the process. Hence, I propose to
> rewrite the gl() function as :
> 
> gl2 <- function(n, k, length = n * k, labels = 1:n, ordered = FALSE){
>  rep(
>      rep(
>        factor(1:n,levels=1:n,labels=labels, ordered=ordered),rep.int(k,n)
>      ),length.out=length
>  )
> }
> 

That's bizarre! You are relying on an optimization in rep.factor whereby it replicates the internal codes and exploits that the result has the same structure as the input. I.e., it just tacks on class and levels attributes rather than call match() as factor() does internally. 

However, you can do the same thing straight away: 

> gl2
function (n, k, length = n * k, labels = 1:n, ordered = FALSE) 
{
   y <- rep(rep.int(1:n, rep.int(k, n)), length.out = length) 
   structure(y, levels=as.character(labels), class=c(if(ordered)"ordered","factor"))
}

I get this to be a bit faster than your version, although with a smaller speedup factor, which probably just indicates that match() is faster on this machine.

> Some test results  :
> 
>> system.time(X1 <- gl(5,1e7))
>   user  system elapsed
>  29.21    0.30   29.58
> 
>> system.time(X2 <- gl2(5,1e7))
>   user  system elapsed
>   1.87    0.45    2.37
> 
>> all.equal(X1,X2)
> [1] TRUE
> 
>> system.time(X1 <- gl(5,100,1e7))
>   user  system elapsed
>   5.98    0.05    6.05
> 
>> system.time(X2 <- gl2(5,100,1e7))
>   user  system elapsed
>   0.21    0.03    0.25
> 
>> all.equal(X1,X2)
> [1] TRUE
> 
>> system.time(X1 <- gl(5,100,1e7,labels=letters[1:5]))
>   user  system elapsed
>   5.88    0.02    5.98
> 
>> system.time(X2 <- gl2(5,100,1e7,labels=letters[1:5]))
>   user  system elapsed
>   0.20    0.05    0.25
> 
>> all.equal(X1,X2)
> [1] TRUE
> 
>> system.time(X1 <- gl(5,100,1e7,labels=letters[1:5],ordered=T))
>   user  system elapsed
>   5.82    0.03    5.89
> 
>> system.time(X2 <- gl2(5,100,1e7,labels=letters[1:5],ordered=T))
>   user  system elapsed
>   0.22    0.04    0.25
> 
>> all.equal(X1,X2)
> [1] TRUE
> 
> reference to SO :
> http://stackoverflow.com/questions/5627264/how-can-i-efficiently-construct-a-very-long-factor-with-few-levels
> 
> -- 
> Joris Meys
> Statistical consultant
> 
> Ghent University
> Faculty of Bioscience Engineering
> Department of Applied mathematics, biometrics and process control
> 
> tel : +32 9 264 59 87
> Joris.Meys at Ugent.be
> -------------------------------
> Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Peter Dalgaard
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From jorismeys at gmail.com  Tue Apr 12 10:33:46 2011
From: jorismeys at gmail.com (Joris Meys)
Date: Tue, 12 Apr 2011 10:33:46 +0200
Subject: [Rd] proposal for adapting code of function gl()
In-Reply-To: <CDFA6915-54EC-47D8-8C77-DA02BD13BA7C@gmail.com>
References: <BANLkTikrm_7YnT02jA5fNGrJkF8vh9xEPw@mail.gmail.com>
	<CDFA6915-54EC-47D8-8C77-DA02BD13BA7C@gmail.com>
Message-ID: <BANLkTimVHtxYJZDspKzmT7Ua8gcswjFBSg@mail.gmail.com>

Thanks for the explanation, I wasn't fully aware of which optimization
I was using. I reckon your solution is more R-sound, so no reason to
keep with my bizarre workaround. It would be nice though if gl() got
optimized. Thank you for the example too, I'm learning every day.

Cheers
Joris

On Tue, Apr 12, 2011 at 8:51 AM, peter dalgaard <pdalgd at gmail.com> wrote:
>
> On Apr 11, 2011, at 23:53 , Joris Meys wrote:
>
>> Based on a discussion on SO I ran some tests and found that converting
>> to a factor is best done early in the process. Hence, I propose to
>> rewrite the gl() function as :
>>
>> gl2 <- function(n, k, length = n * k, labels = 1:n, ordered = FALSE){
>> ?rep(
>> ? ? ?rep(
>> ? ? ? ?factor(1:n,levels=1:n,labels=labels, ordered=ordered),rep.int(k,n)
>> ? ? ?),length.out=length
>> ?)
>> }
>>
>
> That's bizarre! You are relying on an optimization in rep.factor whereby it replicates the internal codes and exploits that the result has the same structure as the input. I.e., it just tacks on class and levels attributes rather than call match() as factor() does internally.
>
> However, you can do the same thing straight away:
>
>> gl2
> function (n, k, length = n * k, labels = 1:n, ordered = FALSE)
> {
> ? y <- rep(rep.int(1:n, rep.int(k, n)), length.out = length)
> ? structure(y, levels=as.character(labels), class=c(if(ordered)"ordered","factor"))
> }
>
> I get this to be a bit faster than your version, although with a smaller speedup factor, which probably just indicates that match() is faster on this machine.
>
>> Some test results ?:
>>
>>> system.time(X1 <- gl(5,1e7))
>> ? user ?system elapsed
>> ?29.21 ? ?0.30 ? 29.58
>>
>>> system.time(X2 <- gl2(5,1e7))
>> ? user ?system elapsed
>> ? 1.87 ? ?0.45 ? ?2.37
>>
>>> all.equal(X1,X2)
>> [1] TRUE
>>
>>> system.time(X1 <- gl(5,100,1e7))
>> ? user ?system elapsed
>> ? 5.98 ? ?0.05 ? ?6.05
>>
>>> system.time(X2 <- gl2(5,100,1e7))
>> ? user ?system elapsed
>> ? 0.21 ? ?0.03 ? ?0.25
>>
>>> all.equal(X1,X2)
>> [1] TRUE
>>
>>> system.time(X1 <- gl(5,100,1e7,labels=letters[1:5]))
>> ? user ?system elapsed
>> ? 5.88 ? ?0.02 ? ?5.98
>>
>>> system.time(X2 <- gl2(5,100,1e7,labels=letters[1:5]))
>> ? user ?system elapsed
>> ? 0.20 ? ?0.05 ? ?0.25
>>
>>> all.equal(X1,X2)
>> [1] TRUE
>>
>>> system.time(X1 <- gl(5,100,1e7,labels=letters[1:5],ordered=T))
>> ? user ?system elapsed
>> ? 5.82 ? ?0.03 ? ?5.89
>>
>>> system.time(X2 <- gl2(5,100,1e7,labels=letters[1:5],ordered=T))
>> ? user ?system elapsed
>> ? 0.22 ? ?0.04 ? ?0.25
>>
>>> all.equal(X1,X2)
>> [1] TRUE
>>
>> reference to SO :
>> http://stackoverflow.com/questions/5627264/how-can-i-efficiently-construct-a-very-long-factor-with-few-levels
>>
>> --
>> Joris Meys
>> Statistical consultant
>>
>> Ghent University
>> Faculty of Bioscience Engineering
>> Department of Applied mathematics, biometrics and process control
>>
>> tel : +32 9 264 59 87
>> Joris.Meys at Ugent.be
>> -------------------------------
>> Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> --
> Peter Dalgaard
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Email: pd.mes at cbs.dk ?Priv: PDalgd at gmail.com
>
>



-- 
Joris Meys
Statistical consultant

Ghent University
Faculty of Bioscience Engineering
Department of Applied mathematics, biometrics and process control

tel : +32 9 264 59 87
Joris.Meys at Ugent.be
-------------------------------
Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php


From Friedrich.Leisch at boku.ac.at  Tue Apr 12 10:48:55 2011
From: Friedrich.Leisch at boku.ac.at (Friedrich Leisch)
Date: Tue, 12 Apr 2011 10:48:55 +0200
Subject: [Rd] Conditional "Suggests"
In-Reply-To: <Pine.LNX.4.64.1104111328460.9064@cardinals.dreamhost.com>
References: <Pine.LNX.4.64.1104111128300.9064@cardinals.dreamhost.com>
	<BANLkTinTW_eSHahN3+a+MKON4XJ_MMeT3A@mail.gmail.com>
	<Pine.LNX.4.64.1104111328460.9064@cardinals.dreamhost.com>
Message-ID: <19876.4599.689171.773231@ridcully.stat.uni-muenchen.de>

>>>>> On Mon, 11 Apr 2011 13:30:24 -0700,
>>>>> Geoff Jentry (GJ) wrote:

  > On Mon, 11 Apr 2011, Hadley Wickham wrote:
  >>> To me this reads as being in the wheelhouse of what 'Suggests' is supposed
  >>> to imply, as per the R Extensions manual. ?The problem here is that if PkgB
  >>> is put down as 'Suggests', it is required for R CMD check to pass which
  >>> seems to defeat the purpose of this exercise a bit.
  >> No, because R CMD check is only run by the developer, not the user.

  > It's not only run by the developer, it's also run by CRAN.  The situation 
  > might happen where for a particular platform (e.g. Windows) that PkgB 
  > doesn't exist.  It'd be nice to be able to avoid a situation where PkgA 
  > can't exist for that platform simply because PkgB - which isn't even 
  > necessarily required for PkgA to be used - doesn't exist for it.

That is not the case, the checks will only get a NOTE that PkgB
doesn't exist. E.g., my package flexclust suggests multicore, which is
not available for windows. Still both live happily on CRAN, and of
course there is a windows version of flexclust available from CRAN.

Best,
Fritz

From savicky at cs.cas.cz  Tue Apr 12 15:26:49 2011
From: savicky at cs.cas.cz (Petr Savicky)
Date: Tue, 12 Apr 2011 15:26:49 +0200
Subject: [Rd] duplicates() function
In-Reply-To: <4DA342D7.5000403@gmail.com>
References: <bug-14552-16@http.bugs.r-project.org/bugzilla3/>
	<20110408142610.88AEC970477@ix.urbanek.info>
	<B722DD6C-3B97-46EC-B369-8316F0F65D1F@cbs.dk>
	<4D9F22BE.5000502@gmail.com>
	<BANLkTimQEeXMPCjWaHuQZ74t8d0A_9XeyQ@mail.gmail.com>
	<4D9F26A3.6060609@gmail.com>
	<BANLkTinVqU+yZ0JgQzJfvDW6GQKk0kAG_A@mail.gmail.com>
	<4DA342D7.5000403@gmail.com>
Message-ID: <20110412132649.GA11248@cs.cas.cz>

On Mon, Apr 11, 2011 at 02:05:11PM -0400, Duncan Murdoch wrote:
> On 08/04/2011 11:39 AM, Joshua Ulrich wrote:
> >On Fri, Apr 8, 2011 at 10:15 AM, Duncan Murdoch
> ><murdoch.duncan at gmail.com>  wrote:
> >>  On 08/04/2011 11:08 AM, Joshua Ulrich wrote:
> >>>
> >>>  How about:
> >>>
> >>>  y<- rep(NA,length(x))
> >>>  y[duplicated(x)]<- match(x[duplicated(x)] ,x)
> >>
> >>  That's a nice solution for vectors.  Unfortunately for me, I have a 
> >matrix
> >>  (which duplicated() handles by checking whole rows).  So a better 
> >example
> >>  that I should have posted would be
> >>
> >>  x<-  cbind(1, c(9,7,9,3,7) )
> >>
> >>  and I'd still like the same output
> >>
> >For a matrix, could you apply the same strategy used in duplicated()?
> >
> >y<- rep(NA,NROW(x))
> >temp<- apply(x, 1, function(x) paste(x, collapse="\r"))
> >y[duplicated(temp)]<- match(temp[duplicated(temp)], temp)
> 
> Since this thread hasn't ended, I will say that I think this solution is 
> the best I've seen for my specific problem.  I was actually surprised 
> that duplicated() did the string concatenation trick, but since it does, 
> it makes a lot of sense to do the same in duplicates().

Consistency with duplicated() is a good argument.

Let me point out, although it goes beyond the original question, that
sorting may be used to compute duplicated() in a way, which is more
efficient than the paste() approach according to the test below.

  duplicatedSort <- function(df)
  {
      n <- nrow(df)
      if (n == 1) {
          return(FALSE)
      } else {
          s <- do.call(order, as.data.frame(df))
          equal <- df[s[2:n], , drop=FALSE] == df[s[1:(n-1)], , drop=FALSE]
          dup <- c(FALSE, rowSums(equal) == ncol(df))
          return(dup[order(s)])
      }
  }

The following tests efficiency for a character matrix.
 
  m <- 1000
  n <- 4
  a <- matrix(as.character(sample(10, m*n, replace=TRUE)), nrow=m, ncol=n)
  system.time(out1 <- duplicatedSort(a))
  system.time(out2 <- duplicated(a))
  identical(out1, out2)
  table(out1)

I obtained, for example,

     user  system elapsed 
    0.003   0.000   0.003 
  
     user  system elapsed 
    0.012   0.000   0.011 
  
  [1] TRUE

  out1
  FALSE  TRUE 
    942    58 

For a numeric matrix, the ratio of the running times is larger in
the same direction.

Petr Savicky.


From geoffjentry at hexdump.org  Tue Apr 12 15:52:44 2011
From: geoffjentry at hexdump.org (Geoff Jentry)
Date: Tue, 12 Apr 2011 06:52:44 -0700
Subject: [Rd] Conditional "Suggests"
In-Reply-To: <19876.4599.689171.773231@ridcully.stat.uni-muenchen.de>
References: <Pine.LNX.4.64.1104111128300.9064@cardinals.dreamhost.com>
	<BANLkTinTW_eSHahN3+a+MKON4XJ_MMeT3A@mail.gmail.com>
	<Pine.LNX.4.64.1104111328460.9064@cardinals.dreamhost.com>
	<19876.4599.689171.773231@ridcully.stat.uni-muenchen.de>
Message-ID: <Pine.LNX.4.64.1104120650450.23342@cardinals.dreamhost.com>

On Tue, 12 Apr 2011, Friedrich Leisch wrote:
> That is not the case, the checks will only get a NOTE that PkgB doesn't 
> exist. E.g., my package flexclust suggests multicore, which is not 
> available for windows. Still both live happily on CRAN, and of course 
> there is a windows version of flexclust available from CRAN.

Right, there's a big mea culpa on my part here - Uwe managed to wake me up 
to my own idiocy.  Obviously I had a case where PkgA Suggests PkgB and 
PkgB didn't exist for Windows.  When I saw that PkgA failed to install on 
Windows, I always quickly assumed that was the case, but there was another 
goofy linkage between the two packages that I didn't intend to be there. 
PkgA fails to install in the absense of PkgB no matter what the platform.

Considering that my use case for this has been debunked and it's the only 
valid one I can think of, I'll shut up now :)

Thanks
-J


From murdoch.duncan at gmail.com  Tue Apr 12 17:03:45 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 12 Apr 2011 11:03:45 -0400
Subject: [Rd] Text differencing code in R?
Message-ID: <4DA469D1.5070105@gmail.com>

I've been running the R daily news feeds 
(http://developer.r-project.org/RSSfeeds.html) using some Java code 
called from R to compute and display differences in the NEWS.Rd file 
from day to day.  (The code was taken from 
http://code.google.com/p/google-diff-match-patch/).  Using Java has 
meant that the process is somewhat fragile and hard to debug, and I'd 
like to switch to pure R code (or at least self-contained code in a 
package).

Does anyone know of an R package that provides text differencing and 
display in HTML?

Duncan Murdoch


From wdunlap at tibco.com  Tue Apr 12 17:32:41 2011
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 12 Apr 2011 08:32:41 -0700
Subject: [Rd] all.equal(data.frame(package_version()),
	...) infinite recursion
Message-ID: <77EB52C6DD32BA4D87471DCD70C8D700041B3195@NA-PA-VBE03.na.tibco.com>

With R-2.12.2 on Linux:

  > z <- data.frame(Version=package_version(c("0.1")),
row.names=c("pkgA"))
  > all.equal(z, z) # expect TRUE
  Error: evaluation nested too deeply: infinite recursion /
options(expressions=)?
  > traceback()
  ... lots of lines in a 3-cycle ...
  6: all.equal.list(target, current, ...)
  5: all.equal.default(target[[i]], current[[i]], check.attributes =
check.attributes,
         ...)
  4: all.equal(target[[i]], current[[i]], check.attributes =
check.attributes,
         ...)
  3: all.equal.list(target, current, ...)
  2: all.equal.default(z, z)
  1: all.equal(z, z)

This is probably because the [[ method for package_version
([[.numeric_version)
acts like a typical [ method, not a [[ method, so all.equal's call to [[
does
not burrow into the list:
  > is.list(z$Version)
  [1] TRUE
  > identical(z$Version[[1]], z$Version)
  [1] TRUE

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com 


From pdalgd at gmail.com  Tue Apr 12 18:12:13 2011
From: pdalgd at gmail.com (peter dalgaard)
Date: Tue, 12 Apr 2011 18:12:13 +0200
Subject: [Rd] proposal for adapting code of function gl()
In-Reply-To: <BANLkTimVHtxYJZDspKzmT7Ua8gcswjFBSg@mail.gmail.com>
References: <BANLkTikrm_7YnT02jA5fNGrJkF8vh9xEPw@mail.gmail.com>
	<CDFA6915-54EC-47D8-8C77-DA02BD13BA7C@gmail.com>
	<BANLkTimVHtxYJZDspKzmT7Ua8gcswjFBSg@mail.gmail.com>
Message-ID: <7D793AF7-9074-43FF-B47E-518F854B9391@gmail.com>


On Apr 12, 2011, at 10:33 , Joris Meys wrote:

> Thanks for the explanation, I wasn't fully aware of which optimization
> I was using. I reckon your solution is more R-sound, so no reason to
> keep with my bizarre workaround. It would be nice though if gl() got
> optimized. Thank you for the example too, I'm learning every day.
> 

I have now committed a version of the below to r-devel. (A couple of demons turned out to be lurking in the details, so not exactly the same code.)

-pd

> Cheers
> Joris
> 
> On Tue, Apr 12, 2011 at 8:51 AM, peter dalgaard <pdalgd at gmail.com> wrote:
>> 
>> On Apr 11, 2011, at 23:53 , Joris Meys wrote:
>> 
>>> Based on a discussion on SO I ran some tests and found that converting
>>> to a factor is best done early in the process. Hence, I propose to
>>> rewrite the gl() function as :
>>> 
>>> gl2 <- function(n, k, length = n * k, labels = 1:n, ordered = FALSE){
>>>  rep(
>>>      rep(
>>>        factor(1:n,levels=1:n,labels=labels, ordered=ordered),rep.int(k,n)
>>>      ),length.out=length
>>>  )
>>> }
>>> 
>> 
>> That's bizarre! You are relying on an optimization in rep.factor whereby it replicates the internal codes and exploits that the result has the same structure as the input. I.e., it just tacks on class and levels attributes rather than call match() as factor() does internally.
>> 
>> However, you can do the same thing straight away:
>> 
>>> gl2
>> function (n, k, length = n * k, labels = 1:n, ordered = FALSE)
>> {
>>   y <- rep(rep.int(1:n, rep.int(k, n)), length.out = length)
>>   structure(y, levels=as.character(labels), class=c(if(ordered)"ordered","factor"))
>> }
>> 
>> I get this to be a bit faster than your version, although with a smaller speedup factor, which probably just indicates that match() is faster on this machine.
>> 
>>> Some test results  :
>>> 
>>>> system.time(X1 <- gl(5,1e7))
>>>   user  system elapsed
>>>  29.21    0.30   29.58
>>> 
>>>> system.time(X2 <- gl2(5,1e7))
>>>   user  system elapsed
>>>   1.87    0.45    2.37
>>> 
>>>> all.equal(X1,X2)
>>> [1] TRUE
>>> 
>>>> system.time(X1 <- gl(5,100,1e7))
>>>   user  system elapsed
>>>   5.98    0.05    6.05
>>> 
>>>> system.time(X2 <- gl2(5,100,1e7))
>>>   user  system elapsed
>>>   0.21    0.03    0.25
>>> 
>>>> all.equal(X1,X2)
>>> [1] TRUE
>>> 
>>>> system.time(X1 <- gl(5,100,1e7,labels=letters[1:5]))
>>>   user  system elapsed
>>>   5.88    0.02    5.98
>>> 
>>>> system.time(X2 <- gl2(5,100,1e7,labels=letters[1:5]))
>>>   user  system elapsed
>>>   0.20    0.05    0.25
>>> 
>>>> all.equal(X1,X2)
>>> [1] TRUE
>>> 
>>>> system.time(X1 <- gl(5,100,1e7,labels=letters[1:5],ordered=T))
>>>   user  system elapsed
>>>   5.82    0.03    5.89
>>> 
>>>> system.time(X2 <- gl2(5,100,1e7,labels=letters[1:5],ordered=T))
>>>   user  system elapsed
>>>   0.22    0.04    0.25
>>> 
>>>> all.equal(X1,X2)
>>> [1] TRUE
>>> 
>>> reference to SO :
>>> http://stackoverflow.com/questions/5627264/how-can-i-efficiently-construct-a-very-long-factor-with-few-levels
>>> 
>>> --
>>> Joris Meys
>>> Statistical consultant
>>> 
>>> Ghent University
>>> Faculty of Bioscience Engineering
>>> Department of Applied mathematics, biometrics and process control
>>> 
>>> tel : +32 9 264 59 87
>>> Joris.Meys at Ugent.be
>>> -------------------------------
>>> Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php
>>> 
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> 
>> --
>> Peter Dalgaard
>> Center for Statistics, Copenhagen Business School
>> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
>> Phone: (+45)38153501
>> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>> 
>> 
> 
> 
> 
> -- 
> Joris Meys
> Statistical consultant
> 
> Ghent University
> Faculty of Bioscience Engineering
> Department of Applied mathematics, biometrics and process control
> 
> tel : +32 9 264 59 87
> Joris.Meys at Ugent.be
> -------------------------------
> Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php

-- 
Peter Dalgaard
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From jeffrey.horner at gmail.com  Tue Apr 12 18:24:10 2011
From: jeffrey.horner at gmail.com (Jeffrey Horner)
Date: Tue, 12 Apr 2011 11:24:10 -0500
Subject: [Rd] parse_Rd raises error when example section contains a quoted
	percent character
Message-ID: <BANLkTikscO28Ey+uJ0+-yL4m5kedBFeHdg@mail.gmail.com>

I was writing Rd documentation for a new package when I came across
this issue. Here's the smallest example:

> library(tools)
> cat("\\examples{x <- '<%=rnorm(1)%>'}\n",file=file.path(tempdir(),'test.Rd'))
> readLines(file.path(tempdir(),'test.Rd'))
[1] "\\examples{x <- '<%=rnorm(1)%>'}"
> parse_Rd(file.path(tempdir(),'test.Rd'))
Error in parse_Rd(file.path(tempdir(), "test.Rd")) :
  Unexpected end of input (in ' quoted string opened at test.Rd:1:17)
In addition: Warning message:
In parse_Rd(file.path(tempdir(), "test.Rd")) :
  newline within quoted string at test.Rd:1

If I take out the percent characters, parse_Rd succeeds:

> cat("\\examples{x <- '<=rnorm(1)>'}\n",file=file.path(tempdir(),'test.Rd'))
> parse_Rd(file.path(tempdir(),'test.Rd'))
\examples{x <- '<=rnorm(1)>'}

So is this intended behavior or a bug? I would like to use the percent
sign in a quoted string as it is part of brew syntax, and I'm writing
example code to demonstrate such.

> sessionInfo()
R version 2.13.0 RC (2011-04-12 r55422)
Platform: i686-pc-linux-gnu (32-bit)

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
 [5] LC_MONETARY=C              LC_MESSAGES=en_US.UTF-8
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
 [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] tools     stats     graphics  grDevices datasets  utils     methods
[8] base

Jeff
-- 
http://biostat.mc.vanderbilt.edu/JeffreyHorner


From jeffrey.horner at gmail.com  Tue Apr 12 18:32:31 2011
From: jeffrey.horner at gmail.com (Jeffrey Horner)
Date: Tue, 12 Apr 2011 11:32:31 -0500
Subject: [Rd] parse_Rd raises error when example section contains a
 quoted percent character
In-Reply-To: <19876.32219.593228.213020@fangorn.hornik.net>
References: <BANLkTikscO28Ey+uJ0+-yL4m5kedBFeHdg@mail.gmail.com>
	<19876.32219.593228.213020@fangorn.hornik.net>
Message-ID: <BANLkTin-u5ZKqtTekTmtQvdbOA93JNBZkA@mail.gmail.com>

Thanks for setting me straight, Kurt.

Problem solved.

Jeff

On Tue, Apr 12, 2011 at 11:29 AM, Kurt Hornik <Kurt.Hornik at wu.ac.at> wrote:
>>>>>> Jeffrey Horner writes:
>
> % is the Rd comment character, and almost always needs to be escaped.
>
> Best
> -k
>
>> I was writing Rd documentation for a new package when I came across
>> this issue. Here's the smallest example:
>
>>> library(tools)
>>> cat("\\examples{x <- '<%=rnorm(1)%>'}\n",file=file.path(tempdir(),'test.Rd'))
>>> readLines(file.path(tempdir(),'test.Rd'))
>> [1] "\\examples{x <- '<%=rnorm(1)%>'}"
>>> parse_Rd(file.path(tempdir(),'test.Rd'))
>> Error in parse_Rd(file.path(tempdir(), "test.Rd")) :
>> ? Unexpected end of input (in ' quoted string opened at test.Rd:1:17)
>> In addition: Warning message:
>> In parse_Rd(file.path(tempdir(), "test.Rd")) :
>> ? newline within quoted string at test.Rd:1
>
>> If I take out the percent characters, parse_Rd succeeds:
>
>>> cat("\\examples{x <- '<=rnorm(1)>'}\n",file=file.path(tempdir(),'test.Rd'))
>>> parse_Rd(file.path(tempdir(),'test.Rd'))
>> \examples{x <- '<=rnorm(1)>'}
>
>> So is this intended behavior or a bug? I would like to use the percent
>> sign in a quoted string as it is part of brew syntax, and I'm writing
>> example code to demonstrate such.
>
>>> sessionInfo()
>> R version 2.13.0 RC (2011-04-12 r55422)
>> Platform: i686-pc-linux-gnu (32-bit)
>
>> locale:
>> ?[1] LC_CTYPE=en_US.UTF-8 ? ? ? LC_NUMERIC=C
>> ?[3] LC_TIME=en_US.UTF-8 ? ? ? ?LC_COLLATE=en_US.UTF-8
>> ?[5] LC_MONETARY=C ? ? ? ? ? ? ?LC_MESSAGES=en_US.UTF-8
>> ?[7] LC_PAPER=en_US.UTF-8 ? ? ? LC_NAME=C
>> ?[9] LC_ADDRESS=C ? ? ? ? ? ? ? LC_TELEPHONE=C
>> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>
>> attached base packages:
>> [1] tools ? ? stats ? ? graphics ?grDevices datasets ?utils ? ? methods
>> [8] base
>
>> Jeff
>> --
>> http://biostat.mc.vanderbilt.edu/JeffreyHorner
>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>



-- 
http://biostat.mc.vanderbilt.edu/JeffreyHorner


From PDalgd at gmail.com  Tue Apr 12 18:38:58 2011
From: PDalgd at gmail.com (peter dalgaard)
Date: Tue, 12 Apr 2011 18:38:58 +0200
Subject: [Rd] parse_Rd raises error when example section contains a
	quoted percent character
In-Reply-To: <BANLkTikscO28Ey+uJ0+-yL4m5kedBFeHdg@mail.gmail.com>
References: <BANLkTikscO28Ey+uJ0+-yL4m5kedBFeHdg@mail.gmail.com>
Message-ID: <B1BE2F36-9927-45DD-B8A0-88F2501D3EF7@gmail.com>


On Apr 12, 2011, at 18:24 , Jeffrey Horner wrote:

> I was writing Rd documentation for a new package when I came across
> this issue. Here's the smallest example:
> 
>> library(tools)
>> cat("\\examples{x <- '<%=rnorm(1)%>'}\n",file=file.path(tempdir(),'test.Rd'))
>> readLines(file.path(tempdir(),'test.Rd'))
> [1] "\\examples{x <- '<%=rnorm(1)%>'}"
>> parse_Rd(file.path(tempdir(),'test.Rd'))
> Error in parse_Rd(file.path(tempdir(), "test.Rd")) :
>  Unexpected end of input (in ' quoted string opened at test.Rd:1:17)
> In addition: Warning message:
> In parse_Rd(file.path(tempdir(), "test.Rd")) :
>  newline within quoted string at test.Rd:1
> 
> If I take out the percent characters, parse_Rd succeeds:
> 
>> cat("\\examples{x <- '<=rnorm(1)>'}\n",file=file.path(tempdir(),'test.Rd'))
>> parse_Rd(file.path(tempdir(),'test.Rd'))
> \examples{x <- '<=rnorm(1)>'}
> 
> So is this intended behavior or a bug? I would like to use the percent
> sign in a quoted string as it is part of brew syntax, and I'm writing
> example code to demonstrate such.

Semi-intended. % is the comment character in .Rd files, and there is no exception for verbatim code in \examples{} et al. So you need \% when it is not a comment. 


> 
>> sessionInfo()
> R version 2.13.0 RC (2011-04-12 r55422)
> Platform: i686-pc-linux-gnu (32-bit)
> 
> locale:
> [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
> [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
> [5] LC_MONETARY=C              LC_MESSAGES=en_US.UTF-8
> [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
> [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
> 
> attached base packages:
> [1] tools     stats     graphics  grDevices datasets  utils     methods
> [8] base
> 
> Jeff
> -- 
> http://biostat.mc.vanderbilt.edu/JeffreyHorner
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Peter Dalgaard
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From murray at stokely.org  Wed Apr 13 00:58:32 2011
From: murray at stokely.org (Murray Stokely)
Date: Tue, 12 Apr 2011 15:58:32 -0700
Subject: [Rd] Signal handling / alarm timeouts
Message-ID: <BANLkTim5yAHWgj9N4de19TOn1=oe0NkujA@mail.gmail.com>

What are the ramifications of setting up user signal handling to allow
the use of e.g. alarm(2) to send a SIGALRM to the R process at some
number of seconds in the future to e.g. interrupt a routine that is
taking too long to complete.

I can't find any R language support for this (e.g. a timeout argument
to tryCatch() would be ideal), so am wondering what kinds of problems
are to be expected if I do this with native C code in a package.

Are there other ways to accomplish timeouts for blocks of R code like this?

               - Murray


From hb at biostat.ucsf.edu  Wed Apr 13 01:22:05 2011
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Tue, 12 Apr 2011 16:22:05 -0700
Subject: [Rd] Signal handling / alarm timeouts
In-Reply-To: <BANLkTim5yAHWgj9N4de19TOn1=oe0NkujA@mail.gmail.com>
References: <BANLkTim5yAHWgj9N4de19TOn1=oe0NkujA@mail.gmail.com>
Message-ID: <BANLkTinzkT_Ooa5CzWNr+PB2onmCQ2M0ug@mail.gmail.com>

On Tue, Apr 12, 2011 at 3:58 PM, Murray Stokely <murray at stokely.org> wrote:
> What are the ramifications of setting up user signal handling to allow
> the use of e.g. alarm(2) to send a SIGALRM to the R process at some
> number of seconds in the future to e.g. interrupt a routine that is
> taking too long to complete.
>
> I can't find any R language support for this (e.g. a timeout argument
> to tryCatch() would be ideal), so am wondering what kinds of problems
> are to be expected if I do this with native C code in a package.
>
> Are there other ways to accomplish timeouts for blocks of R code like this?

See R help thread 'Time out for a R Function' on 2010-12-06
[http://www.mail-archive.com/r-help at r-project.org/msg119344.html].  As
explained there, R provides setTimeLimit(), which is cross platform so
you don't have to rely on OS-specific signals.  In R.utils there is
evalWithTimeout(), which utilizes setTimeLimit().

/Henrik

>
> ? ? ? ? ? ? ? - Murray
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From hpages at fhcrc.org  Wed Apr 13 02:53:32 2011
From: hpages at fhcrc.org (=?ISO-8859-1?Q?Herv=E9_Pag=E8s?=)
Date: Tue, 12 Apr 2011 17:53:32 -0700
Subject: [Rd] R CMD build --resave-data
In-Reply-To: <4DA31AA0.2050209@statistik.tu-dortmund.de>
References: <4DA24F8A.7030405@fhcrc.org>
	<4DA31AA0.2050209@statistik.tu-dortmund.de>
Message-ID: <4DA4F40C.7000409@fhcrc.org>

Hi Uwe,

On 11-04-11 08:13 AM, Uwe Ligges wrote:
>
>
> On 11.04.2011 02:47, Herv? Pag?s wrote:
>> Hi,
>>
>> More about the new --resave-data option
>>
>> As mentioned previously here
>>
>> https://stat.ethz.ch/pipermail/r-devel/2011-April/060511.html
>>
>> 'R CMD build' and 'R CMD INSTALL' handle this new option
>> inconsistently. The former does --resave-data="gzip" by default.
>> The latter doesn't seem to support the --resave-data= syntax:
>> the --resave-data flag must either be present or not. And by
>> default 'R CMD INSTALL' won't resave the data.
>>
>> Also, because now 'R CMD build' is resaving the data, shouldn't it
>> reinstall the package in order to be able to do this correctly?
>>
>> Here is why. There is this new warning in 'R CMD check' that complains
>> about files not of a type allowed in a 'data' directory:
>>
>>
>> http://bioconductor.org/checkResults/2.8/bioc-LATEST/Icens/lamb1-checksrc.html
>>
>>
>>
>> The Icens package also has .R files under data/ with things like:
>>
>> bet <- matrix(scan("CMVdata", quiet=TRUE),nc=5,byr=TRUE)
>>
>> i.e. the R code needs to access some of the text files located
>> in the data/ folder. So in order to get rid of this warning I
>> tried to move those text files to inst/extdata/ and I modified
>> the code in the .R file so it does:
>>
>> CMVdata_filepath <- system.file("extdata", "CMVdata", package="Icens")
>> bet <- matrix(scan(CMVdata_filepath, quiet=TRUE),nc=5,byr=TRUE)
>>
>> But now 'R CMD build' fails to resave the data because the package
>> was not installed first and the CMVdata file could not be found.
>>
>> Unfortunately, for a lot of people that means that the safe way to
>> build a source tarball now is with
>>
>> R CMD build --keep-empty-dirs --no-resave-data
>
>
> Herv?,
>
> actually is makes some sense to have these defaults from a CRAN
> maintainer's point of view:
>
> --keep-empty-dirs:
> we found many packages containing empty dirs unnecessarily and the idea
> is to exclude them at the build state rather than at the later
> installation stage. Note that the package maintainer is supposed to run
> build (and knows if the empty dirs are to be included, the user who runs
> INSTALL does not).
>
> --no-resave-data:
> We found many packages with unsufficiently compressed data. This should
> be fixed when building the package, not later when installing it, since
> the reduces size is useful in the source tarball already.
>
> So it does make some sense to have different defaults in build as
> opposed to INSTALL from my point of view (although I could live with
> different, tough).

If you deliberately ignore the fact that 'R CMD INSTALL' is also used
by developers to install from the *package source tree* (by opposition
to end users who use it to install from a *source tarball*, even though
they don't use it directly), then you have a point. So maybe I should
have been more explicit about the problem that it can be for the
*developer* to have 'R CMD build' and 'R CMD INSTALL' behave
differently by default.

Of course I'm not suggesting that 'R CMD INSTALL' should behave
differently (by default) depending on whether it's used on a source
tarball (mode 1) or a package source tree (mode 2).

I'm suggesting that, by default, the 3 commands (R CMD build +
R CMD INSTALL in mode 1 and 2) behave consistently.

With the latest changes, and by default, 'R CMD INSTALL' is still doing
the right thing, but not 'R CMD build' anymore.

I perfectly understand the intention behind those new flags, which is
to try to "optimize" the resulting source tarball but what would you
think if 'gcc' had some optimization flags that can generate broken
executables (under some circumstances) and if these flags were enabled
by default?

Note that I would have no problem with 'R CMD build' trying to resave
the data by default if the current implementation of that feature
was working properly, but unfortunately it's broken (see my previous
email for the details).

Thanks,
H.

>
> If you need further arguments for the discussion: I also tend to use
> --no-vignettes nowadays if my code does not change considerably. ;-)
>
> Best wishes,
> Uwe
>
>
>
>> I hope the list of options/flags that we need to use to "fix" 'R CMD
>> build' (and make it consistent with R CMD INSTALL) is not going to
>> grow too much ;-)
>>
>> Thanks,
>> H.
>>
>>


-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M2-B876
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fhcrc.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From simon.urbanek at r-project.org  Wed Apr 13 04:06:10 2011
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Tue, 12 Apr 2011 22:06:10 -0400
Subject: [Rd] R CMD build --resave-data
In-Reply-To: <4DA4F40C.7000409@fhcrc.org>
References: <4DA24F8A.7030405@fhcrc.org>
	<4DA31AA0.2050209@statistik.tu-dortmund.de>
	<4DA4F40C.7000409@fhcrc.org>
Message-ID: <AD95DA9D-5887-4C59-AB6F-3AA400689306@r-project.org>


On Apr 12, 2011, at 8:53 PM, Herv? Pag?s wrote:

> Hi Uwe,
> 
> On 11-04-11 08:13 AM, Uwe Ligges wrote:
>> 
>> 
>> On 11.04.2011 02:47, Herv? Pag?s wrote:
>>> Hi,
>>> 
>>> More about the new --resave-data option
>>> 
>>> As mentioned previously here
>>> 
>>> https://stat.ethz.ch/pipermail/r-devel/2011-April/060511.html
>>> 
>>> 'R CMD build' and 'R CMD INSTALL' handle this new option
>>> inconsistently. The former does --resave-data="gzip" by default.
>>> The latter doesn't seem to support the --resave-data= syntax:
>>> the --resave-data flag must either be present or not. And by
>>> default 'R CMD INSTALL' won't resave the data.
>>> 
>>> Also, because now 'R CMD build' is resaving the data, shouldn't it
>>> reinstall the package in order to be able to do this correctly?
>>> 
>>> Here is why. There is this new warning in 'R CMD check' that complains
>>> about files not of a type allowed in a 'data' directory:
>>> 
>>> 
>>> http://bioconductor.org/checkResults/2.8/bioc-LATEST/Icens/lamb1-checksrc.html
>>> 
>>> 
>>> 
>>> The Icens package also has .R files under data/ with things like:
>>> 
>>> bet <- matrix(scan("CMVdata", quiet=TRUE),nc=5,byr=TRUE)
>>> 
>>> i.e. the R code needs to access some of the text files located
>>> in the data/ folder. So in order to get rid of this warning I
>>> tried to move those text files to inst/extdata/ and I modified
>>> the code in the .R file so it does:
>>> 
>>> CMVdata_filepath <- system.file("extdata", "CMVdata", package="Icens")
>>> bet <- matrix(scan(CMVdata_filepath, quiet=TRUE),nc=5,byr=TRUE)
>>> 
>>> But now 'R CMD build' fails to resave the data because the package
>>> was not installed first and the CMVdata file could not be found.
>>> 
>>> Unfortunately, for a lot of people that means that the safe way to
>>> build a source tarball now is with
>>> 
>>> R CMD build --keep-empty-dirs --no-resave-data
>> 
>> 
>> Herv?,
>> 
>> actually is makes some sense to have these defaults from a CRAN
>> maintainer's point of view:
>> 
>> --keep-empty-dirs:
>> we found many packages containing empty dirs unnecessarily and the idea
>> is to exclude them at the build state rather than at the later
>> installation stage. Note that the package maintainer is supposed to run
>> build (and knows if the empty dirs are to be included, the user who runs
>> INSTALL does not).
>> 
>> --no-resave-data:
>> We found many packages with unsufficiently compressed data. This should
>> be fixed when building the package, not later when installing it, since
>> the reduces size is useful in the source tarball already.
>> 
>> So it does make some sense to have different defaults in build as
>> opposed to INSTALL from my point of view (although I could live with
>> different, tough).
> 
> If you deliberately ignore the fact that 'R CMD INSTALL' is also used
> by developers to install from the *package source tree* (by opposition
> to end users who use it to install from a *source tarball*,

.. for a good reason, IMHO no serious developer would do that for obvious reasons - you'd be working on a dirty copy creating many unnecessary problems and polluting your sources. The first time you'll spend an hour chasing a non-existent problem due to stale binary objects in your tree you'll learn that lesson ;). The fraction of a second spent in R CMD build is well worth the hours saved. IMHO the only valid reason to run INSTALL on a (freshly unpacked tar ball) directory is to capture config.log.

Cheers,
Simon



> even though
> they don't use it directly), then you have a point. So maybe I should
> have been more explicit about the problem that it can be for the
> *developer* to have 'R CMD build' and 'R CMD INSTALL' behave
> differently by default.
> 
> Of course I'm not suggesting that 'R CMD INSTALL' should behave
> differently (by default) depending on whether it's used on a source
> tarball (mode 1) or a package source tree (mode 2).
> 
> I'm suggesting that, by default, the 3 commands (R CMD build +
> R CMD INSTALL in mode 1 and 2) behave consistently.
> 
> With the latest changes, and by default, 'R CMD INSTALL' is still doing
> the right thing, but not 'R CMD build' anymore.
> 
> I perfectly understand the intention behind those new flags, which is
> to try to "optimize" the resulting source tarball but what would you
> think if 'gcc' had some optimization flags that can generate broken
> executables (under some circumstances) and if these flags were enabled
> by default?
> 
> Note that I would have no problem with 'R CMD build' trying to resave
> the data by default if the current implementation of that feature
> was working properly, but unfortunately it's broken (see my previous
> email for the details).
> 
> Thanks,
> H.
> 
>> 
>> If you need further arguments for the discussion: I also tend to use
>> --no-vignettes nowadays if my code does not change considerably. ;-)
>> 
>> Best wishes,
>> Uwe
>> 
>> 
>> 
>>> I hope the list of options/flags that we need to use to "fix" 'R CMD
>>> build' (and make it consistent with R CMD INSTALL) is not going to
>>> grow too much ;-)
>>> 
>>> Thanks,
>>> H.
>>> 
>>> 
> 
> 
> -- 
> Herv? Pag?s
> 
> Program in Computational Biology
> Division of Public Health Sciences
> Fred Hutchinson Cancer Research Center
> 1100 Fairview Ave. N, M2-B876
> P.O. Box 19024
> Seattle, WA 98109-1024
> 
> E-mail: hpages at fhcrc.org
> Phone:  (206) 667-5791
> Fax:    (206) 667-1319
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From hadley at rice.edu  Wed Apr 13 04:26:46 2011
From: hadley at rice.edu (Hadley Wickham)
Date: Tue, 12 Apr 2011 21:26:46 -0500
Subject: [Rd] R CMD build --resave-data
In-Reply-To: <AD95DA9D-5887-4C59-AB6F-3AA400689306@r-project.org>
References: <4DA24F8A.7030405@fhcrc.org>
	<4DA31AA0.2050209@statistik.tu-dortmund.de>
	<4DA4F40C.7000409@fhcrc.org>
	<AD95DA9D-5887-4C59-AB6F-3AA400689306@r-project.org>
Message-ID: <BANLkTim00CqwGUbtaKN7j0As8Nchdb+ryw@mail.gmail.com>

>> If you deliberately ignore the fact that 'R CMD INSTALL' is also used
>> by developers to install from the *package source tree* (by opposition
>> to end users who use it to install from a *source tarball*,
>
> .. for a good reason, IMHO no serious developer would do that for obvious reasons - you'd be working on a dirty copy creating many unnecessary problems and polluting your sources. The first time you'll spend an hour chasing a non-existent problem due to stale binary objects in your tree you'll learn that lesson ;). The fraction of a second spent in R CMD build is well worth the hours saved. IMHO the only valid reason to run INSTALL on a (freshly unpacked tar ball) directory is to capture config.log.

This is news to me!  I know that you're supposed to run R CMD check on
the built package, but you're supposed to run install on it too?  (And
if it's so important, why doesn't R do it for you automatically?)

Do you have any convenient shortcuts to overcome the fact that the
binary package contains the package name?  i.e. how can I build and
install/check in a single line without having to specify the full file
name?

How can I go from:

R CMD build plyr && R CMD install plyr_1.5.tar.gz

to

R CMD build-and-install plyr ?

Hadley


-- 
Assistant Professor / Dobelman Family Junior Chair
Department of Statistics / Rice University
http://had.co.nz/


From simon.urbanek at r-project.org  Wed Apr 13 04:49:17 2011
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Tue, 12 Apr 2011 22:49:17 -0400
Subject: [Rd] R CMD build --resave-data
In-Reply-To: <BANLkTim00CqwGUbtaKN7j0As8Nchdb+ryw@mail.gmail.com>
References: <4DA24F8A.7030405@fhcrc.org>
	<4DA31AA0.2050209@statistik.tu-dortmund.de>
	<4DA4F40C.7000409@fhcrc.org>
	<AD95DA9D-5887-4C59-AB6F-3AA400689306@r-project.org>
	<BANLkTim00CqwGUbtaKN7j0As8Nchdb+ryw@mail.gmail.com>
Message-ID: <8CBD2FB8-6F31-4930-8658-0EFE221747EC@r-project.org>


On Apr 12, 2011, at 10:26 PM, Hadley Wickham wrote:

>>> If you deliberately ignore the fact that 'R CMD INSTALL' is also used
>>> by developers to install from the *package source tree* (by opposition
>>> to end users who use it to install from a *source tarball*,
>> 
>> .. for a good reason, IMHO no serious developer would do that for obvious reasons - you'd be working on a dirty copy creating many unnecessary problems and polluting your sources. The first time you'll spend an hour chasing a non-existent problem due to stale binary objects in your tree you'll learn that lesson ;). The fraction of a second spent in R CMD build is well worth the hours saved. IMHO the only valid reason to run INSTALL on a (freshly unpacked tar ball) directory is to capture config.log.
> 
> This is news to me!  I know that you're supposed to run R CMD check on
> the built package, but you're supposed to run install on it too?  (And
> if it's so important, why doesn't R do it for you automatically?)
> 

I'm not saying "supposed to" I'm saying wise to. And the "IMHO"s above were what I really meant. By all means, you're free to do anything as long as you don't ask on the mailing list that something doesn't work because you ran it on a stale directory ;).


> Do you have any convenient shortcuts to overcome the fact that the
> binary package contains the package name?  i.e. how can I build and
> install/check in a single line without having to specify the full file
> name?
> 
> How can I go from:
> 
> R CMD build plyr && R CMD install plyr_1.5.tar.gz
> 

Some will argue that's an invalid command to start with ;). But other than that I see nothing wrong with it ... it's what I do to be honest ... (except where I don't, but that has to do with my custom build script legacy which has a defined way to get versions on the shell, long story...).


> to
> 
> R CMD build-and-install plyr ?
> 

R CMD build plyr && R CMD INSTALL plyr_*

... if you don't keep too many version in the same directory ;) - but it's not something I would use. For the paranoid

R CMD build plyr && R CMD INSTALL plyr_`sed -n 's/Version: *//p' plyr/DESCRIPTION`.tar.gz

But, seriously, that is the least problem I see - you'd have to advance your version numbers very quickly to get the version command out of your shell history...


Cheers,
Simon


From hpages at fhcrc.org  Wed Apr 13 07:21:58 2011
From: hpages at fhcrc.org (=?ISO-8859-1?Q?Herv=E9_Pag=E8s?=)
Date: Tue, 12 Apr 2011 22:21:58 -0700
Subject: [Rd] R CMD build --resave-data
In-Reply-To: <AD95DA9D-5887-4C59-AB6F-3AA400689306@r-project.org>
References: <4DA24F8A.7030405@fhcrc.org>
	<4DA31AA0.2050209@statistik.tu-dortmund.de>
	<4DA4F40C.7000409@fhcrc.org>
	<AD95DA9D-5887-4C59-AB6F-3AA400689306@r-project.org>
Message-ID: <4DA532F6.5080407@fhcrc.org>

On 11-04-12 07:06 PM, Simon Urbanek wrote:
>
> On Apr 12, 2011, at 8:53 PM, Herv? Pag?s wrote:
>
>> Hi Uwe,
>>
>> On 11-04-11 08:13 AM, Uwe Ligges wrote:
>>>
>>>
>>> On 11.04.2011 02:47, Herv? Pag?s wrote:
>>>> Hi,
>>>>
>>>> More about the new --resave-data option
>>>>
>>>> As mentioned previously here
>>>>
>>>> https://stat.ethz.ch/pipermail/r-devel/2011-April/060511.html
>>>>
>>>> 'R CMD build' and 'R CMD INSTALL' handle this new option
>>>> inconsistently. The former does --resave-data="gzip" by default.
>>>> The latter doesn't seem to support the --resave-data= syntax:
>>>> the --resave-data flag must either be present or not. And by
>>>> default 'R CMD INSTALL' won't resave the data.
>>>>
>>>> Also, because now 'R CMD build' is resaving the data, shouldn't it
>>>> reinstall the package in order to be able to do this correctly?
>>>>
>>>> Here is why. There is this new warning in 'R CMD check' that complains
>>>> about files not of a type allowed in a 'data' directory:
>>>>
>>>>
>>>> http://bioconductor.org/checkResults/2.8/bioc-LATEST/Icens/lamb1-checksrc.html
>>>>
>>>>
>>>>
>>>> The Icens package also has .R files under data/ with things like:
>>>>
>>>> bet<- matrix(scan("CMVdata", quiet=TRUE),nc=5,byr=TRUE)
>>>>
>>>> i.e. the R code needs to access some of the text files located
>>>> in the data/ folder. So in order to get rid of this warning I
>>>> tried to move those text files to inst/extdata/ and I modified
>>>> the code in the .R file so it does:
>>>>
>>>> CMVdata_filepath<- system.file("extdata", "CMVdata", package="Icens")
>>>> bet<- matrix(scan(CMVdata_filepath, quiet=TRUE),nc=5,byr=TRUE)
>>>>
>>>> But now 'R CMD build' fails to resave the data because the package
>>>> was not installed first and the CMVdata file could not be found.
>>>>
>>>> Unfortunately, for a lot of people that means that the safe way to
>>>> build a source tarball now is with
>>>>
>>>> R CMD build --keep-empty-dirs --no-resave-data
>>>
>>>
>>> Herv?,
>>>
>>> actually is makes some sense to have these defaults from a CRAN
>>> maintainer's point of view:
>>>
>>> --keep-empty-dirs:
>>> we found many packages containing empty dirs unnecessarily and the idea
>>> is to exclude them at the build state rather than at the later
>>> installation stage. Note that the package maintainer is supposed to run
>>> build (and knows if the empty dirs are to be included, the user who runs
>>> INSTALL does not).
>>>
>>> --no-resave-data:
>>> We found many packages with unsufficiently compressed data. This should
>>> be fixed when building the package, not later when installing it, since
>>> the reduces size is useful in the source tarball already.
>>>
>>> So it does make some sense to have different defaults in build as
>>> opposed to INSTALL from my point of view (although I could live with
>>> different, tough).
>>
>> If you deliberately ignore the fact that 'R CMD INSTALL' is also used
>> by developers to install from the *package source tree* (by opposition
>> to end users who use it to install from a *source tarball*,
>
> .. for a good reason, IMHO no serious developer would do that for obvious reasons -

This sounds like saying that no serious developer working on a big
project involving a lot of files to compile should use 'make'.
I mean, serious developers like you *always* do 'make clean' before
they do 'make' on the R tree when they need to test a change, even
a small one? And this only takes a "fraction of second" for them?
Hey, I'd love to be able to do that too! ;-)

H.

> you'd be working on a dirty copy creating many unnecessary problems and polluting your sources. The first time you'll spend an hour chasing a non-existent problem due to stale binary objects in your tree you'll learn that lesson ;). The fraction of a second spent in R CMD build is well worth the hours saved. IMHO the only valid reason to run INSTALL on a (freshly unpacked tar ball) directory is to capture config.log.
>
> Cheers,
> Simon
>
>
>
>> even though
>> they don't use it directly), then you have a point. So maybe I should
>> have been more explicit about the problem that it can be for the
>> *developer* to have 'R CMD build' and 'R CMD INSTALL' behave
>> differently by default.
>>
>> Of course I'm not suggesting that 'R CMD INSTALL' should behave
>> differently (by default) depending on whether it's used on a source
>> tarball (mode 1) or a package source tree (mode 2).
>>
>> I'm suggesting that, by default, the 3 commands (R CMD build +
>> R CMD INSTALL in mode 1 and 2) behave consistently.
>>
>> With the latest changes, and by default, 'R CMD INSTALL' is still doing
>> the right thing, but not 'R CMD build' anymore.
>>
>> I perfectly understand the intention behind those new flags, which is
>> to try to "optimize" the resulting source tarball but what would you
>> think if 'gcc' had some optimization flags that can generate broken
>> executables (under some circumstances) and if these flags were enabled
>> by default?
>>
>> Note that I would have no problem with 'R CMD build' trying to resave
>> the data by default if the current implementation of that feature
>> was working properly, but unfortunately it's broken (see my previous
>> email for the details).
>>
>> Thanks,
>> H.
>>
>>>
>>> If you need further arguments for the discussion: I also tend to use
>>> --no-vignettes nowadays if my code does not change considerably. ;-)
>>>
>>> Best wishes,
>>> Uwe
>>>
>>>
>>>
>>>> I hope the list of options/flags that we need to use to "fix" 'R CMD
>>>> build' (and make it consistent with R CMD INSTALL) is not going to
>>>> grow too much ;-)
>>>>
>>>> Thanks,
>>>> H.
>>>>
>>>>
>>
>>
>> --
>> Herv? Pag?s
>>
>> Program in Computational Biology
>> Division of Public Health Sciences
>> Fred Hutchinson Cancer Research Center
>> 1100 Fairview Ave. N, M2-B876
>> P.O. Box 19024
>> Seattle, WA 98109-1024
>>
>> E-mail: hpages at fhcrc.org
>> Phone:  (206) 667-5791
>> Fax:    (206) 667-1319
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>


-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M2-B876
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fhcrc.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From maechler at stat.math.ethz.ch  Wed Apr 13 14:45:37 2011
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 13 Apr 2011 14:45:37 +0200
Subject: [Rd] R CMD build --resave-data
In-Reply-To: <4DA532F6.5080407@fhcrc.org>
References: <4DA24F8A.7030405@fhcrc.org>
	<4DA31AA0.2050209@statistik.tu-dortmund.de>
	<4DA4F40C.7000409@fhcrc.org>
	<AD95DA9D-5887-4C59-AB6F-3AA400689306@r-project.org>
	<4DA532F6.5080407@fhcrc.org>
Message-ID: <19877.39665.850196.376907@stat.math.ethz.ch>

>>>>> Herv? Pag?s <hpages at fhcrc.org>
>>>>>     on Tue, 12 Apr 2011 22:21:58 -0700 writes:

    > On 11-04-12 07:06 PM, Simon Urbanek wrote:
    >> 
    >> On Apr 12, 2011, at 8:53 PM, Herv? Pag?s wrote:
    >> 
    >>> Hi Uwe,
    >>> 
    >>> On 11-04-11 08:13 AM, Uwe Ligges wrote:
    >>>> 
    >>>> 
    >>>> On 11.04.2011 02:47, Herv? Pag?s wrote:
    >>>>> Hi,
    >>>>> 
    >>>>> More about the new --resave-data option
    >>>>> 
    >>>>> As mentioned previously here
    >>>>> 
    >>>>> https://stat.ethz.ch/pipermail/r-devel/2011-April/060511.html
    >>>>> 
    >>>>> 'R CMD build' and 'R CMD INSTALL' handle this new option
    >>>>> inconsistently. The former does --resave-data="gzip" by
    >>>>> default.  The latter doesn't seem to support the
    >>>>> --resave-data= syntax: the --resave-data flag must either be
    >>>>> present or not. And by default 'R CMD INSTALL' won't resave
    >>>>> the data.
    >>>>> 
    >>>>> Also, because now 'R CMD build' is resaving the data,
    >>>>> shouldn't it reinstall the package in order to be able to do
    >>>>> this correctly?
    >>>>> 
    >>>>> Here is why. There is this new warning in 'R CMD check' that
    >>>>> complains about files not of a type allowed in a 'data'
    >>>>> directory:
    >>>>> 
    >>>>> 
    >>>>> http://bioconductor.org/checkResults/2.8/bioc-LATEST/Icens/lamb1-checksrc.html
    >>>>> 
    >>>>> 
    >>>>> 
    >>>>> The Icens package also has .R files under data/ with things
    >>>>> like:
    >>>>> 
    >>>>> bet<- matrix(scan("CMVdata", quiet=TRUE),nc=5,byr=TRUE)
    >>>>> 
    >>>>> i.e. the R code needs to access some of the text files
    >>>>> located in the data/ folder. So in order to get rid of this
    >>>>> warning I tried to move those text files to inst/extdata/
    >>>>> and I modified the code in the .R file so it does:
    >>>>> 
    >>>>> CMVdata_filepath<- system.file("extdata", "CMVdata",
    >>>>> package="Icens") bet<- matrix(scan(CMVdata_filepath,
    >>>>> quiet=TRUE),nc=5,byr=TRUE)
    >>>>> 
    >>>>> But now 'R CMD build' fails to resave the data because the
    >>>>> package was not installed first and the CMVdata file could
    >>>>> not be found.
    >>>>> 
    >>>>> Unfortunately, for a lot of people that means that the safe
    >>>>> way to build a source tarball now is with
    >>>>> 
    >>>>> R CMD build --keep-empty-dirs --no-resave-data
    >>>> 
    >>>> 
    >>>> Herv?,
    >>>> 
    >>>> actually is makes some sense to have these defaults from a
    >>>> CRAN maintainer's point of view:
    >>>> 
    >>>> --keep-empty-dirs: we found many packages containing empty
    >>>> dirs unnecessarily and the idea is to exclude them at the
    >>>> build state rather than at the later installation stage. Note
    >>>> that the package maintainer is supposed to run build (and
    >>>> knows if the empty dirs are to be included, the user who runs
    >>>> INSTALL does not).
    >>>> 
    >>>> --no-resave-data: We found many packages with unsufficiently
    >>>> compressed data. This should be fixed when building the
    >>>> package, not later when installing it, since the reduces size
    >>>> is useful in the source tarball already.
    >>>> 
    >>>> So it does make some sense to have different defaults in
    >>>> build as opposed to INSTALL from my point of view (although I
    >>>> could live with different, tough).
    >>> 
    >>> If you deliberately ignore the fact that 'R CMD INSTALL' is
    >>> also used by developers to install from the *package source
    >>> tree* (by opposition to end users who use it to install from a
    >>> *source tarball*,
    >> 
    >> .. for a good reason, IMHO no serious developer would do that
    >> for obvious reasons -

    > This sounds like saying that no serious developer working on a
    > big project involving a lot of files to compile should use
    > 'make'.  I mean, serious developers like you *always* do 'make
    > clean' before they do 'make' on the R tree when they need to
    > test a change, even a small one? And this only takes a "fraction
    > of second" for them?  Hey, I'd love to be able to do that too!
    > ;-)

    > H.

    >> you'd be working on a dirty copy creating many unnecessary
    >> problems and polluting your sources. The first time you'll
    >> spend an hour chasing a non-existent problem due to stale
    >> binary objects in your tree you'll learn that lesson ;). The
    >> fraction of a second spent in R CMD build is well worth the
    >> hours saved. IMHO the only valid reason to run INSTALL on a
    >> (freshly unpacked tar ball) directory is to capture config.log.
    >> 
    >> Cheers, Simon
    >> 
    >> 
    >> 
    >>> even though they don't use it directly), then you have a
    >>> point. So maybe I should have been more explicit about the
    >>> problem that it can be for the *developer* to have 'R CMD
    >>> build' and 'R CMD INSTALL' behave differently by default.
    >>> 
    >>> Of course I'm not suggesting that 'R CMD INSTALL' should
    >>> behave differently (by default) depending on whether it's used
    >>> on a source tarball (mode 1) or a package source tree (mode
    >>> 2).
    >>> 
    >>> I'm suggesting that, by default, the 3 commands (R CMD build +
    >>> R CMD INSTALL in mode 1 and 2) behave consistently.
    >>> 
    >>> With the latest changes, and by default, 'R CMD INSTALL' is
    >>> still doing the right thing, but not 'R CMD build' anymore.
    >>> 
    >>> I perfectly understand the intention behind those new flags,
    >>> which is to try to "optimize" the resulting source tarball but
    >>> what would you think if 'gcc' had some optimization flags that
    >>> can generate broken executables (under some circumstances) and
    >>> if these flags were enabled by default?
    >>> 
    >>> Note that I would have no problem with 'R CMD build' trying to
    >>> resave the data by default if the current implementation of
    >>> that feature was working properly, but unfortunately it's
    >>> broken (see my previous email for the details).
    >>> 
    >>> Thanks, H.
    >>> 
    >>>> 
    >>>> If you need further arguments for the discussion: I also tend to use
    >>>> --no-vignettes nowadays if my code does not change considerably. ;-)
    >>>> 
    >>>> Best wishes,
    >>>> Uwe
    >>>> 
    >>>> 
    >>>> 
    >>>>> I hope the list of options/flags that we need to use to "fix" 'R CMD
    >>>>> build' (and make it consistent with R CMD INSTALL) is not going to
    >>>>> grow too much ;-)
;-)

I'm with Herve here.
I almost always use  R CMD INSTALL on a directory rather than a
tarball... though most of the time the directory is freshly
untarred.
Other times, however one of the reasons is exactly that I can
keep things around (*.o, ...) which are only rebuilt very
rarely.

Martin


From hb at biostat.ucsf.edu  Wed Apr 13 15:16:09 2011
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Wed, 13 Apr 2011 06:16:09 -0700
Subject: [Rd] Excited about the near future...
In-Reply-To: <AANLkTi=+e4NCjjhsJUxQtegbT_=GUZ-BEFo+hftdkj3w@mail.gmail.com>
References: <AANLkTi=+e4NCjjhsJUxQtegbT_=GUZ-BEFo+hftdkj3w@mail.gmail.com>
Message-ID: <BANLkTin_bKP93wbj49Bw5FBLWmakhJr3VQ@mail.gmail.com>

Since I've posted this a month ago, several persons have been emailing
me offline asking what I'm referring to.  From the NEWS of R v2.13.0
(released today):

Package 'compiler' is now provided as a standard package. See
?compiler::compile for information on how to use the compiler. This
package implements a byte code compiler for R: by default the compiler
is not used in this release. See the ?R Installation and
Administration Manual? for how to compile the base and recommended
packages.

The fact that it is now a standard package means everyone will have it
installed by default, which means it is much more likely to get lots
of real CPU mileage.

The 'compiler' package has been a long-term effort by Luke Tierney.
He has some nice talks/slides on this:

http://www.stat.uiowa.edu/~luke/


Yesterday, Dirk Eddelbuettel wrote a piece about the compiler on his
blog 'Thinking inside the box':

http://dirk.eddelbuettel.com/blog/2011/04/12/


/Henrik

PS. Stephen Milborrow's package 'jit' provides a just-in-time compiler
iff used with his Ra build of R.  It seems to be a discontinued
project though.

On Sat, Mar 12, 2011 at 9:45 PM, Henrik Bengtsson <hb at biostat.ucsf.edu> wrote:
> Some already know, but I think it deserves a bit of a attention here as well:
>
> It looks like we're about to get new features in R that will be very powerful!
>
> That should be a good enough teaser for now...
>
> /Henrik
>
> PS ...and thanks for making it available plus credits to similar
> efforts by others.
>


From jorismeys at gmail.com  Wed Apr 13 15:38:14 2011
From: jorismeys at gmail.com (Joris Meys)
Date: Wed, 13 Apr 2011 15:38:14 +0200
Subject: [Rd] bug in hist.POSIXt , hist.Date
Message-ID: <BANLkTi=z-6kitC+uojrq-uKGH15fXLVS2Q@mail.gmail.com>

The behaviour of hist.POSIXt when using the col argument is different
from the default hist, in the respect that it colors the axes as well.
I think this is due to the ... argument, which is passed to the
axis.POSIXct() function. In the default hist, col is set as a fixed
argument, and hence cannot be passed unwantedly to other functions.
Maybe this should be done with hist.POSIXt as well. The same goes for
hist.Date

Cheers
Joris

-- 
Joris Meys
Statistical consultant

Ghent University
Faculty of Bioscience Engineering
Department of Applied mathematics, biometrics and process control

tel : +32 9 264 59 87
Joris.Meys at Ugent.be
-------------------------------
Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php


From bbolker at gmail.com  Wed Apr 13 15:57:13 2011
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 13 Apr 2011 13:57:13 +0000
Subject: [Rd] bug in hist.POSIXt , hist.Date
References: <BANLkTi=z-6kitC+uojrq-uKGH15fXLVS2Q@mail.gmail.com>
Message-ID: <loom.20110413T155347-464@post.gmane.org>

Joris Meys <jorismeys <at> gmail.com> writes:

> 
> The behaviour of hist.POSIXt when using the col argument is different
> from the default hist, in the respect that it colors the axes as well.
> I think this is due to the ... argument, which is passed to the
> axis.POSIXct() function. In the default hist, col is set as a fixed
> argument, and hence cannot be passed unwantedly to other functions.
> Maybe this should be done with hist.POSIXt as well. The same goes for
> hist.Date

  Reproducible example:

 hist(.leap.seconds, "years", freq = TRUE,col=2)


From jon.clayden at gmail.com  Wed Apr 13 16:05:08 2011
From: jon.clayden at gmail.com (Jon Clayden)
Date: Wed, 13 Apr 2011 15:05:08 +0100
Subject: [Rd] Reading 64-bit integers
In-Reply-To: <ADCFBA31-C69C-4424-B55C-E130D91AE22F@r-project.org>
References: <AANLkTinndjFuoV17Th4PRUdpbrY-7RjTbyXwY6T6n+cd@mail.gmail.com>
	<10962CE3-2F14-4BCE-8E78-AE18814C3F81@r-project.org>
	<AANLkTimSWMqXM90Zg7WKYPbddk9zfQZhXXQif6eeLaGX@mail.gmail.com>
	<5544174B-A567-4126-B99C-D39542260503@r-project.org>
	<AANLkTinfH__3foy9oex9+Eq-84pr_i9M6PfKay8R4i9T@mail.gmail.com>
	<4D927DAD.7070203@gmail.com>
	<A1631B10-DB4D-4914-8FCA-C1A97178F02F@r-project.org>
	<77EB52C6DD32BA4D87471DCD70C8D70004124A5D@NA-PA-VBE03.na.tibco.com>
	<ADCFBA31-C69C-4424-B55C-E130D91AE22F@r-project.org>
Message-ID: <BANLkTim3_k1rBT1CRKZAz5=C8zO4G7XbAA@mail.gmail.com>

Simon (et al.),

I was just wondering if anything further came of this... I would be
willing to help put together an updated patch, if the semantics can be
decided upon.

All the best,
Jon


On 30 March 2011 19:22, Simon Urbanek <simon.urbanek at r-project.org> wrote:
> Bill,
>
> thanks. I like that idea of the output parameter better, especially if we ever add different scalar vector types. Admittedly, what=integer() is the most useful case. What I was worried about is things like what=double(), output=integer() which could be legal, but are more conveniently dealt with via as.integer(readBin()) instead.
> I won't have more time today, but I'll have a look tomorrow.
>
> Thanks,
> Simon
>
>
> On Mar 30, 2011, at 1:38 PM, William Dunlap wrote:
>
>>
>>> -----Original Message-----
>>> From: r-devel-bounces at r-project.org
>>> [mailto:r-devel-bounces at r-project.org] On Behalf Of Simon Urbanek
>>> Sent: Tuesday, March 29, 2011 6:49 PM
>>> To: Duncan Murdoch
>>> Cc: r-devel at r-project.org
>>> Subject: Re: [Rd] Reading 64-bit integers
>>>
>>>
>>> On Mar 29, 2011, at 8:47 PM, Duncan Murdoch wrote:
>>>
>>>> On 29/03/2011 7:01 PM, Jon Clayden wrote:
>>>>> Dear Simon,
>>>>>
>>>>> On 29 March 2011 22:40, Simon
>>> Urbanek<simon.urbanek at r-project.org> ?wrote:
>>>>>> Jon,
>>>>>>
>>>>>> On Mar 29, 2011, at 1:33 PM, Jon Clayden wrote:
>>>>>>
>>>>>>> Dear Simon,
>>>>>>>
>>>>>>> Thank you for the response.
>>>>>>>
>>>>>>> On 29 March 2011 15:06, Simon
>>> Urbanek<simon.urbanek at r-project.org> ?wrote:
>>>>>>>>
>>>>>>>> On Mar 29, 2011, at 8:46 AM, Jon Clayden wrote:
>>>>>>>>
>>>>>>>>> Dear all,
>>>>>>>>>
>>>>>>>>> I see from some previous threads that support for
>>> 64-bit integers in R
>>>>>>>>> may be an aim for future versions, but in the meantime
>>> I'm wondering
>>>>>>>>> whether it is possible to read in integers of greater
>>> than 32 bits at
>>>>>>>>> all. Judging from ?readBin, it should be possible to
>>> read 8-byte
>>>>>>>>> integers to some degree, but it is clearly limited in
>>> practice by R's
>>>>>>>>> internally 32-bit integer type:
>>>>>>>>>
>>>>>>>>>> x<- as.raw(c(0,0,0,0,1,0,0,0))
>>>>>>>>>> (readBin(x,"integer",n=1,size=8,signed=F,endian="big"))
>>>>>>>>> [1] 16777216
>>>>>>>>>> x<- as.raw(c(0,0,0,1,0,0,0,0))
>>>>>>>>>> (readBin(x,"integer",n=1,size=8,signed=F,endian="big"))
>>>>>>>>> [1] 0
>>>>>>>>>
>>>>>>>>> For values that fit into 32 bits it works fine, but
>>> for larger values
>>>>>>>>> it fails. (I'm a bit surprised by the zero - should
>>> the value not be
>>>>>>>>> NA if it is out of range?
>>>>>>>>
>>>>>>>> No, it's not out of range - int is only 4 bytes so only
>>> 4 first bytes (respecting endianness order, hence LSB) are used.
>>>>>>>
>>>>>>> The fact remains that I ask for the value of an 8-byte
>>> integer and
>>>>>>> don't get it.
>>>>>>
>>>>>> I think you're misinterpreting the documentation:
>>>>>>
>>>>>> ? ?If 'size' is specified and not the natural size of the object,
>>>>>> ? ?each element of the vector is coerced to an appropriate type
>>>>>> ? ?before being written or as it is read.
>>>>>>
>>>>>> The "integer" object type is defined as signed 32-bit in
>>> R, so if you ask for "8 bytes into object type integer", you
>>> get a coercion into that object type -- 32-bit signed integer
>>> -- as documented. I think the issue may come from the
>>> confusion of the object type "integer" with general "integer
>>> number" in mathematical sense that has no representation
>>> restrictions. (FWIW in C the "integer" type is "int" and it
>>> is 32-bit on all modern OSes regardless of platform - that's
>>> where the limitation comes from, it's not something R has made up).
>>>>>
>>>>> OK, but it still seems like there is a case for raising a
>>> warning. As
>>>>> it is there is no way to tell when reading an 8-byte integer from a
>>>>> file whether its value is really 0, or if it merely has 0 in its
>>>>> least-significant 4 bytes. If 99% of such stored numbers are below
>>>>> 2^31, one is going to need some extra logic to catch the other 1%
>>>>> where you (silently) get the wrong value. In essence, unless you're
>>>>> certain that you will never come across a number that actually uses
>>>>> the upper 4 bytes, you will always have to read it as two 4-byte
>>>>> numbers and check that the high-order one (which is endianness
>>>>> dependent, of course) is zero. A C-level sanity check seems more
>>>>> efficient and more helpful to me.
>>>>
>>>> Seems to me that the S-PLUS solution (output="double")
>>> would be a lot more useful. ?I'd commit that if you write it;
>>> I don't think I'd commit the warning.
>>>>
>>>
>>> I was going to write some thing similar (idea = good, patch
>>> welcome ;)). My only worry is that the "output" argument is a
>>> bit misleading in that one could expect to use any
>>> combination of "input"/"output" which may be a maintenance
>>> nightmare. If I understand it correctly it's only a special
>>> case for integer input. I don't have S+ so can't say how they
>>> deal with that.
>>
>> In S+'s readBin the output argument can be
>> only double() or single() when what is double()
>> or single() (S+ still ?has a real single
>> precision storage mode) and can be any
>> numeric type or logical when what is integer().
>>
>> The output=double() seemed like the only useful case.
>>
>> It does not warn when precision is lost in the 8-byte
>> integer to double conversion. ?Perhaps it should.
>>
>> Bill Dunlap
>> Spotfire, TIBCO Software
>> wdunlap tibco.com
>>
>>>
>>> Cheers,
>>> Simon
>>>
>>>
>>>>
>>>>>
>>>>>>> Pretending that it's really only four bytes because of
>>>>>>> the limits of R's integer type isn't all that helpful. Perhaps a
>>>>>>> warning should be put out if the cast will affect the
>>> value of the
>>>>>>> result? It looks like the relevant lines in
>>> src/main/connections.c are
>>>>>>> 3689-3697 in the current alpha:
>>>>>>>
>>>>>>> #if SIZEOF_LONG == 8
>>>>>>> ? ? ? ? ? ? ? ? ?case sizeof(long):
>>>>>>> ? ? ? ? ? ? ? ? ? ? ?INTEGER(ans)[i] = (int)*((long *)buf);
>>>>>>> ? ? ? ? ? ? ? ? ? ? ?break;
>>>>>>> #elif SIZEOF_LONG_LONG == 8
>>>>>>> ? ? ? ? ? ? ? ? ?case sizeof(_lli_t):
>>>>>>> ? ? ? ? ? ? ? ? ? ? ?INTEGER(ans)[i] = (int)*((_lli_t *)buf);
>>>>>>> ? ? ? ? ? ? ? ? ? ? ?break;
>>>>>>> #endif
>>>>>>>
>>>>>>>>> ) The value can be represented as a double,
>>>>>>>>> though:
>>>>>>>>>
>>>>>>>>>> 4294967296
>>>>>>>>> [1] 4294967296
>>>>>>>>>
>>>>>>>>> I wouldn't expect readBin() to return a double if an
>>> integer was
>>>>>>>>> requested, but is there any way to get the correct
>>> value out of it?
>>>>>>>>
>>>>>>>> Trivially (for your unsigned big-endian case):
>>>>>>>>
>>>>>>>> y<- readBin(x, "integer", n=length(x)/4L, endian="big")
>>>>>>>> y<- ifelse(y< ?0, 2^32 + y, y)
>>>>>>>> i<- seq(1,length(y),2)
>>>>>>>> y<- y[i] * 2^32 + y[i + 1L]
>>>>>>>
>>>>>>> Thanks for the code, but I'm not sure I would call that trivial,
>>>>>>> especially if one needs to cater for little endian and
>>> signed cases as
>>>>>>> well!
>>>>>>
>>>>>> I was saying for your case and it's trivial as in read as
>>> integers, convert to double precision and add.
>>>>>>
>>>>>>
>>>>>>> This is what I meant by reconstructing the number manually...
>>>>>>>
>>>>>>
>>>>>> You didn't say so - you were talking about reconstructing
>>> it from a raw vector which seems a lot more painful since you
>>> can't compute with enough precision on raw vectors.
>>>>>
>>>>> True - I should have been more specific. Sorry.
>>>>>
>>>>> Jon
>>>>>
>>>>> ______________________________________________
>>>>> R-devel at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>
>>>>
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From ligges at statistik.tu-dortmund.de  Wed Apr 13 19:50:49 2011
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Wed, 13 Apr 2011 19:50:49 +0200
Subject: [Rd] R CMD build --resave-data
In-Reply-To: <4DA4F40C.7000409@fhcrc.org>
References: <4DA24F8A.7030405@fhcrc.org>
	<4DA31AA0.2050209@statistik.tu-dortmund.de>
	<4DA4F40C.7000409@fhcrc.org>
Message-ID: <4DA5E279.7090508@statistik.tu-dortmund.de>



On 13.04.2011 02:53, Herv? Pag?s wrote:
> Hi Uwe,
>
> On 11-04-11 08:13 AM, Uwe Ligges wrote:
>>
>>
>> On 11.04.2011 02:47, Herv? Pag?s wrote:
>>> Hi,
>>>
>>> More about the new --resave-data option
>>>
>>> As mentioned previously here
>>>
>>> https://stat.ethz.ch/pipermail/r-devel/2011-April/060511.html
>>>
>>> 'R CMD build' and 'R CMD INSTALL' handle this new option
>>> inconsistently. The former does --resave-data="gzip" by default.
>>> The latter doesn't seem to support the --resave-data= syntax:
>>> the --resave-data flag must either be present or not. And by
>>> default 'R CMD INSTALL' won't resave the data.
>>>
>>> Also, because now 'R CMD build' is resaving the data, shouldn't it
>>> reinstall the package in order to be able to do this correctly?
>>>
>>> Here is why. There is this new warning in 'R CMD check' that complains
>>> about files not of a type allowed in a 'data' directory:
>>>
>>>
>>> http://bioconductor.org/checkResults/2.8/bioc-LATEST/Icens/lamb1-checksrc.html
>>>
>>>
>>>
>>>
>>> The Icens package also has .R files under data/ with things like:
>>>
>>> bet <- matrix(scan("CMVdata", quiet=TRUE),nc=5,byr=TRUE)
>>>
>>> i.e. the R code needs to access some of the text files located
>>> in the data/ folder. So in order to get rid of this warning I
>>> tried to move those text files to inst/extdata/ and I modified
>>> the code in the .R file so it does:
>>>
>>> CMVdata_filepath <- system.file("extdata", "CMVdata", package="Icens")
>>> bet <- matrix(scan(CMVdata_filepath, quiet=TRUE),nc=5,byr=TRUE)
>>>
>>> But now 'R CMD build' fails to resave the data because the package
>>> was not installed first and the CMVdata file could not be found.
>>>
>>> Unfortunately, for a lot of people that means that the safe way to
>>> build a source tarball now is with
>>>
>>> R CMD build --keep-empty-dirs --no-resave-data
>>
>>
>> Herv?,
>>
>> actually is makes some sense to have these defaults from a CRAN
>> maintainer's point of view:
>>
>> --keep-empty-dirs:
>> we found many packages containing empty dirs unnecessarily and the idea
>> is to exclude them at the build state rather than at the later
>> installation stage. Note that the package maintainer is supposed to run
>> build (and knows if the empty dirs are to be included, the user who runs
>> INSTALL does not).
>>
>> --no-resave-data:
>> We found many packages with unsufficiently compressed data. This should
>> be fixed when building the package, not later when installing it, since
>> the reduces size is useful in the source tarball already.
>>
>> So it does make some sense to have different defaults in build as
>> opposed to INSTALL from my point of view (although I could live with
>> different, tough).
>
> If you deliberately ignore the fact that 'R CMD INSTALL' is also used
> by developers to install from the *package source tree* (by opposition
> to end users who use it to install from a *source tarball*, even though
> they don't use it directly), then you have a point. So maybe I should
> have been more explicit about the problem that it can be for the
> *developer* to have 'R CMD build' and 'R CMD INSTALL' behave
> differently by default.
>
> Of course I'm not suggesting that 'R CMD INSTALL' should behave
> differently (by default) depending on whether it's used on a source
> tarball (mode 1) or a package source tree (mode 2).
>
> I'm suggesting that, by default, the 3 commands (R CMD build +
> R CMD INSTALL in mode 1 and 2) behave consistently.
>
> With the latest changes, and by default, 'R CMD INSTALL' is still doing
> the right thing, but not 'R CMD build' anymore.
>
> I perfectly understand the intention behind those new flags, which is
> to try to "optimize" the resulting source tarball but what would you
> think if 'gcc' had some optimization flags that can generate broken
> executables (under some circumstances) and if these flags were enabled
> by default?
>
> Note that I would have no problem with 'R CMD build' trying to resave
> the data by default if the current implementation of that feature
> was working properly, but unfortunately it's broken (see my previous
> email for the details).

It is one thing to talk about sensible defaults and another thing to 
talk about bugs. I just talked about sensible defaults. And I have not 
had the time to look iunto details. I just arrived in Dortmund 15 
minutes ago and I the first thing I have to do is repairing some 
winbuilder stuff and get 2.13.0 ready on it. I may look into other 
details later this week or at the beginning of next week.

Uwe



> Thanks,
> H.
>
>>
>> If you need further arguments for the discussion: I also tend to use
>> --no-vignettes nowadays if my code does not change considerably. ;-)
>>
>> Best wishes,
>> Uwe
>>
>>
>>
>>> I hope the list of options/flags that we need to use to "fix" 'R CMD
>>> build' (and make it consistent with R CMD INSTALL) is not going to
>>> grow too much ;-)
>>>
>>> Thanks,
>>> H.
>>>
>>>
>
>


From hpages at fhcrc.org  Wed Apr 13 19:54:41 2011
From: hpages at fhcrc.org (=?ISO-8859-1?Q?Herv=E9_Pag=E8s?=)
Date: Wed, 13 Apr 2011 10:54:41 -0700
Subject: [Rd] R CMD build --resave-data
In-Reply-To: <4DA5E279.7090508@statistik.tu-dortmund.de>
References: <4DA24F8A.7030405@fhcrc.org>
	<4DA31AA0.2050209@statistik.tu-dortmund.de>
	<4DA4F40C.7000409@fhcrc.org>
	<4DA5E279.7090508@statistik.tu-dortmund.de>
Message-ID: <4DA5E361.50806@fhcrc.org>

Hi Uwe,

On 11-04-13 10:50 AM, Uwe Ligges wrote:
>
>
> On 13.04.2011 02:53, Herv? Pag?s wrote:
>> Hi Uwe,
>>
>> On 11-04-11 08:13 AM, Uwe Ligges wrote:
>>>
>>>
>>> On 11.04.2011 02:47, Herv? Pag?s wrote:
>>>> Hi,
>>>>
>>>> More about the new --resave-data option
>>>>
>>>> As mentioned previously here
>>>>
>>>> https://stat.ethz.ch/pipermail/r-devel/2011-April/060511.html
>>>>
>>>> 'R CMD build' and 'R CMD INSTALL' handle this new option
>>>> inconsistently. The former does --resave-data="gzip" by default.
>>>> The latter doesn't seem to support the --resave-data= syntax:
>>>> the --resave-data flag must either be present or not. And by
>>>> default 'R CMD INSTALL' won't resave the data.
>>>>
>>>> Also, because now 'R CMD build' is resaving the data, shouldn't it
>>>> reinstall the package in order to be able to do this correctly?
>>>>
>>>> Here is why. There is this new warning in 'R CMD check' that complains
>>>> about files not of a type allowed in a 'data' directory:
>>>>
>>>>
>>>> http://bioconductor.org/checkResults/2.8/bioc-LATEST/Icens/lamb1-checksrc.html
>>>>
>>>>
>>>>
>>>>
>>>>
>>>> The Icens package also has .R files under data/ with things like:
>>>>
>>>> bet <- matrix(scan("CMVdata", quiet=TRUE),nc=5,byr=TRUE)
>>>>
>>>> i.e. the R code needs to access some of the text files located
>>>> in the data/ folder. So in order to get rid of this warning I
>>>> tried to move those text files to inst/extdata/ and I modified
>>>> the code in the .R file so it does:
>>>>
>>>> CMVdata_filepath <- system.file("extdata", "CMVdata", package="Icens")
>>>> bet <- matrix(scan(CMVdata_filepath, quiet=TRUE),nc=5,byr=TRUE)
>>>>
>>>> But now 'R CMD build' fails to resave the data because the package
>>>> was not installed first and the CMVdata file could not be found.
>>>>
>>>> Unfortunately, for a lot of people that means that the safe way to
>>>> build a source tarball now is with
>>>>
>>>> R CMD build --keep-empty-dirs --no-resave-data
>>>
>>>
>>> Herv?,
>>>
>>> actually is makes some sense to have these defaults from a CRAN
>>> maintainer's point of view:
>>>
>>> --keep-empty-dirs:
>>> we found many packages containing empty dirs unnecessarily and the idea
>>> is to exclude them at the build state rather than at the later
>>> installation stage. Note that the package maintainer is supposed to run
>>> build (and knows if the empty dirs are to be included, the user who runs
>>> INSTALL does not).
>>>
>>> --no-resave-data:
>>> We found many packages with unsufficiently compressed data. This should
>>> be fixed when building the package, not later when installing it, since
>>> the reduces size is useful in the source tarball already.
>>>
>>> So it does make some sense to have different defaults in build as
>>> opposed to INSTALL from my point of view (although I could live with
>>> different, tough).
>>
>> If you deliberately ignore the fact that 'R CMD INSTALL' is also used
>> by developers to install from the *package source tree* (by opposition
>> to end users who use it to install from a *source tarball*, even though
>> they don't use it directly), then you have a point. So maybe I should
>> have been more explicit about the problem that it can be for the
>> *developer* to have 'R CMD build' and 'R CMD INSTALL' behave
>> differently by default.
>>
>> Of course I'm not suggesting that 'R CMD INSTALL' should behave
>> differently (by default) depending on whether it's used on a source
>> tarball (mode 1) or a package source tree (mode 2).
>>
>> I'm suggesting that, by default, the 3 commands (R CMD build +
>> R CMD INSTALL in mode 1 and 2) behave consistently.
>>
>> With the latest changes, and by default, 'R CMD INSTALL' is still doing
>> the right thing, but not 'R CMD build' anymore.
>>
>> I perfectly understand the intention behind those new flags, which is
>> to try to "optimize" the resulting source tarball but what would you
>> think if 'gcc' had some optimization flags that can generate broken
>> executables (under some circumstances) and if these flags were enabled
>> by default?
>>
>> Note that I would have no problem with 'R CMD build' trying to resave
>> the data by default if the current implementation of that feature
>> was working properly, but unfortunately it's broken (see my previous
>> email for the details).
>
> It is one thing to talk about sensible defaults and another thing to
> talk about bugs. I just talked about sensible defaults. And I have not
> had the time to look iunto details. I just arrived in Dortmund 15
> minutes ago and I the first thing I have to do is repairing some
> winbuilder stuff and get 2.13.0 ready on it. I may look into other
> details later this week or at the beginning of next week.

No problem. I understand perfectly. Release times are very busy time
on the Bioconductor side too. Thanks for looking into this!

H.

>
> Uwe
>
>
>
>> Thanks,
>> H.
>>
>>>
>>> If you need further arguments for the discussion: I also tend to use
>>> --no-vignettes nowadays if my code does not change considerably. ;-)
>>>
>>> Best wishes,
>>> Uwe
>>>
>>>
>>>
>>>> I hope the list of options/flags that we need to use to "fix" 'R CMD
>>>> build' (and make it consistent with R CMD INSTALL) is not going to
>>>> grow too much ;-)
>>>>
>>>> Thanks,
>>>> H.
>>>>
>>>>
>>
>>


-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M2-B876
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fhcrc.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From therneau at mayo.edu  Wed Apr 13 20:00:05 2011
From: therneau at mayo.edu (Terry Therneau)
Date: Wed, 13 Apr 2011 13:00:05 -0500
Subject: [Rd] Problem with dyn.load in R 2.13.0
Message-ID: <1302717605.12894.28.camel@nemo>

I have a test directory for the survival suite, and dyn.load has ceased
to work in it.  Below shows the log:

tmt1075% R --vanilla

R version 2.12.2 (2011-02-25)
Copyright (C) 2011 The R Foundation for Statistical Computing
ISBN 3-900051-07-0
Platform: x86_64-unknown-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> dyn.load('survival.so')
> q()

tmt1076% R13 --vanilla

R version 2.13.0 RC (2011-04-11 r55409)
Copyright (C) 2011 The R Foundation for Statistical Computing
ISBN 3-900051-07-0
Platform: x86_64-unknown-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> dyn.load('survival.so')
Error in dyn.load("survival.so") : 
  unable to load shared object
'/people/biostat2/therneau/research/surv/Rtest/survival.so':
  libR.so: cannot open shared object file: No such file or directory
> q()

--------------------------

 Is the issue that the .so file must have been created with the R2.13
script?  That's not what the error message says, however.  It almost
looks like it is ignoring my first argument and looking instead for
"libR".

Terry Therneau


From edd at debian.org  Wed Apr 13 20:34:36 2011
From: edd at debian.org (Dirk Eddelbuettel)
Date: Wed, 13 Apr 2011 13:34:36 -0500
Subject: [Rd] Problem with dyn.load in R 2.13.0
In-Reply-To: <1302717605.12894.28.camel@nemo>
References: <1302717605.12894.28.camel@nemo>
Message-ID: <19877.60604.384710.321827@max.nulle.part>


On 13 April 2011 at 13:00, Terry Therneau wrote:
| I have a test directory for the survival suite, and dyn.load has ceased
| to work in it.  Below shows the log:
| 
| tmt1075% R --vanilla
| 
| R version 2.12.2 (2011-02-25)
| Copyright (C) 2011 The R Foundation for Statistical Computing
| ISBN 3-900051-07-0
| Platform: x86_64-unknown-linux-gnu (64-bit)
[...]
| > dyn.load('survival.so')
| > q()
[...]
| 
| tmt1076% R13 --vanilla
| 
| R version 2.13.0 RC (2011-04-11 r55409)
| Copyright (C) 2011 The R Foundation for Statistical Computing
| ISBN 3-900051-07-0
| Platform: x86_64-unknown-linux-gnu (64-bit)
[...]
| > dyn.load('survival.so')
| Error in dyn.load("survival.so") : 
|   unable to load shared object
| '/people/biostat2/therneau/research/surv/Rtest/survival.so':
|   libR.so: cannot open shared object file: No such file or directory
| > q()
| 
| --------------------------
| 
|  Is the issue that the .so file must have been created with the R2.13
| script?  That's not what the error message says, however.  It almost
| looks like it is ignoring my first argument and looking instead for
| "libR".

What does 'ldd /path/to/your/survial.so' say?  Does the system find libR.so?

I have no issues whatsoever on my Ubuntu box with the packages distributed
via CRAN (and now also a PPA if you want alpha/beta/rc builds) based on the
underlying Debian package I maintain.

I have a (pretty visible) hourly cronjob that drives our littler /usr/bin/r
frontend to do the CRANberries summaries---and even while /usr/bin/r was last
built under R 2.11.1, it continued to work merrily under R 2.12.0, 2.12.1,
2.12.2, and 2.13.0 prereleases:

edd at max:~$ r --version | head -4
r ('littler') version 0.1.3
        svn revision 178 as of 2010-01-05 20:57:41
        built at 20:08:17 on Oct 11 2010
        using GNU R Version 2.11.1 (2010-05-31)
edd at max:~$ 

edd at max:~$ R --version | head -1
R version 2.13.0 RC (2011-04-07 r55373)
edd at max:~$ 

Both use the same shared library version libR.so from whichever current
r-base-core is installed.

So I see no particular breakage.   Recompiling your project may also be a start.

Hth, Dirk

-- 
Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com


From mtmorgan at fhcrc.org  Wed Apr 13 22:38:07 2011
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Wed, 13 Apr 2011 13:38:07 -0700
Subject: [Rd] Problem with dyn.load in R 2.13.0
In-Reply-To: <19877.60604.384710.321827@max.nulle.part>
References: <1302717605.12894.28.camel@nemo>
	<19877.60604.384710.321827@max.nulle.part>
Message-ID: <4DA609AF.4000108@fhcrc.org>

On 04/13/2011 11:34 AM, Dirk Eddelbuettel wrote:
>
> On 13 April 2011 at 13:00, Terry Therneau wrote:
> | I have a test directory for the survival suite, and dyn.load has ceased
> | to work in it.  Below shows the log:
> |
> | tmt1075% R --vanilla
> |
> | R version 2.12.2 (2011-02-25)
> | Copyright (C) 2011 The R Foundation for Statistical Computing
> | ISBN 3-900051-07-0
> | Platform: x86_64-unknown-linux-gnu (64-bit)
> [...]
> |>  dyn.load('survival.so')
> |>  q()
> [...]
> |
> | tmt1076% R13 --vanilla
> |
> | R version 2.13.0 RC (2011-04-11 r55409)
> | Copyright (C) 2011 The R Foundation for Statistical Computing
> | ISBN 3-900051-07-0
> | Platform: x86_64-unknown-linux-gnu (64-bit)
> [...]
> |>  dyn.load('survival.so')
> | Error in dyn.load("survival.so") :
> |   unable to load shared object
> | '/people/biostat2/therneau/research/surv/Rtest/survival.so':
> |   libR.so: cannot open shared object file: No such file or directory
> |>  q()
> |
> | --------------------------
> |
> |  Is the issue that the .so file must have been created with the R2.13
> | script?  That's not what the error message says, however.  It almost
> | looks like it is ignoring my first argument and looking instead for
> | "libR".
>
> What does 'ldd /path/to/your/survial.so' say?  Does the system find libR.so?

Maybe R CMD ldd /path/to/your/survival.so to pick up whatever 
environment R configures.

Martin

>
> I have no issues whatsoever on my Ubuntu box with the packages distributed
> via CRAN (and now also a PPA if you want alpha/beta/rc builds) based on the
> underlying Debian package I maintain.
>
> I have a (pretty visible) hourly cronjob that drives our littler /usr/bin/r
> frontend to do the CRANberries summaries---and even while /usr/bin/r was last
> built under R 2.11.1, it continued to work merrily under R 2.12.0, 2.12.1,
> 2.12.2, and 2.13.0 prereleases:
>
> edd at max:~$ r --version | head -4
> r ('littler') version 0.1.3
>          svn revision 178 as of 2010-01-05 20:57:41
>          built at 20:08:17 on Oct 11 2010
>          using GNU R Version 2.11.1 (2010-05-31)
> edd at max:~$
>
> edd at max:~$ R --version | head -1
> R version 2.13.0 RC (2011-04-07 r55373)
> edd at max:~$
>
> Both use the same shared library version libR.so from whichever current
> r-base-core is installed.
>
> So I see no particular breakage.   Recompiling your project may also be a start.
>
> Hth, Dirk
>


-- 
Computational Biology
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N. PO Box 19024 Seattle, WA 98109

Location: M1-B861
Telephone: 206 667-2793


From simon.urbanek at r-project.org  Wed Apr 13 22:45:42 2011
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Wed, 13 Apr 2011 16:45:42 -0400
Subject: [Rd] Problem with dyn.load in R 2.13.0
In-Reply-To: <1302717605.12894.28.camel@nemo>
References: <1302717605.12894.28.camel@nemo>
Message-ID: <A3CD0094-9331-49C1-B46C-1564FA3C9718@r-project.org>

We have no details, but my wild guess would be that you did not re-build the package for 2.13.0 and you have static libR in 2.13.0 yet dynamic in 2.12.2.

Cheers,
Simon


On Apr 13, 2011, at 2:00 PM, Terry Therneau wrote:

> I have a test directory for the survival suite, and dyn.load has ceased
> to work in it.  Below shows the log:
> 
> tmt1075% R --vanilla
> 
> R version 2.12.2 (2011-02-25)
> Copyright (C) 2011 The R Foundation for Statistical Computing
> ISBN 3-900051-07-0
> Platform: x86_64-unknown-linux-gnu (64-bit)
> 
> R is free software and comes with ABSOLUTELY NO WARRANTY.
> You are welcome to redistribute it under certain conditions.
> Type 'license()' or 'licence()' for distribution details.
> 
>  Natural language support but running in an English locale
> 
> R is a collaborative project with many contributors.
> Type 'contributors()' for more information and
> 'citation()' on how to cite R or R packages in publications.
> 
> Type 'demo()' for some demos, 'help()' for on-line help, or
> 'help.start()' for an HTML browser interface to help.
> Type 'q()' to quit R.
> 
>> dyn.load('survival.so')
>> q()
> 
> tmt1076% R13 --vanilla
> 
> R version 2.13.0 RC (2011-04-11 r55409)
> Copyright (C) 2011 The R Foundation for Statistical Computing
> ISBN 3-900051-07-0
> Platform: x86_64-unknown-linux-gnu (64-bit)
> 
> R is free software and comes with ABSOLUTELY NO WARRANTY.
> You are welcome to redistribute it under certain conditions.
> Type 'license()' or 'licence()' for distribution details.
> 
>  Natural language support but running in an English locale
> 
> R is a collaborative project with many contributors.
> Type 'contributors()' for more information and
> 'citation()' on how to cite R or R packages in publications.
> 
> Type 'demo()' for some demos, 'help()' for on-line help, or
> 'help.start()' for an HTML browser interface to help.
> Type 'q()' to quit R.
> 
>> dyn.load('survival.so')
> Error in dyn.load("survival.so") : 
>  unable to load shared object
> '/people/biostat2/therneau/research/surv/Rtest/survival.so':
>  libR.so: cannot open shared object file: No such file or directory
>> q()
> 
> --------------------------
> 
> Is the issue that the .so file must have been created with the R2.13
> script?  That's not what the error message says, however.  It almost
> looks like it is ignoring my first argument and looking instead for
> "libR".
> 
> Terry Therneau
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From therneau at mayo.edu  Wed Apr 13 22:47:07 2011
From: therneau at mayo.edu (Terry Therneau)
Date: Wed, 13 Apr 2011 15:47:07 -0500
Subject: [Rd] Problem with dyn.load in R 2.13.0 -- the real problem
In-Reply-To: <19878.2128.292065.275960@max.nulle.part>
References: <1302717605.12894.28.camel@nemo>
	<19877.60604.384710.321827@max.nulle.part>
	<1302724885.12894.61.camel@nemo>
	<19878.2128.292065.275960@max.nulle.part>
Message-ID: <1302727627.12894.79.camel@nemo>


On Wed, 2011-04-13 at 15:32 -0500, Dirk Eddelbuettel wrote:
> Terry,
> 
> You replied to
>  
>   From: Terry Therneau <therneau at mayo.edu>
>   To: Dirk Eddelbuettel <edd at debian.org>
>   Cc: cran at r-project.org
>   Subject: Re: [Rd] Problem with dyn.load in R 2.13.0 -- the real problem
> 
> but dropped r-devel. On purpose?

No, not on purpose.  Corrected.

> This still looks like a local config issue about local libraries to me.
> 
> Dirk

I fail to see how.  Running the newest release of R 2.13, if I issue a
library() command for something installed earlier in R_LIBS_USER,
something I expect lots of people to do, and that library has a .so file
with reference to the now-nonexistent Rlib.so file, an error ensues.
This is easy to test elsewhere. 
  I don't anticipate that every user will erase all libraries and
reinstall with each new R release.  At work particularly, the default R
release changes without user intervention; the system admin is not going
to go looking for all local downloads.  (A lot of people use
R_LIBS_USER, as they don't have permission to put things elsewhere --
this includes me.)
  The error message for logspline is great as it tells them what to do.
I'm only looking for a better one in the case I found.

> 
> On 13 April 2011 at 15:01, Terry Therneau wrote:
> | Dirk's comment made it clearer:
> | 
> | On Wed, 2011-04-13 at 13:34 -0500, Dirk Eddelbuettel wrote:
> | > What does 'ldd /path/to/your/survial.so' say?  Does the system find
> | > libR.so?
> | > 
> | 
> | tmt1077% pwd
> | /people/biostat2/therneau/research/surv/Rtest
> | tmt1078% ldd survival.so
> |         libR.so => not found
> |         libc.so.6 => /lib64/libc.so.6 (0x00002aede2d94000)
> |         /lib64/ld-linux-x86-64.so.2 (0x00000033cd800000)
> | 
> | However, this is a survival.so file created by R12, and that version has
> | a libR.so in RHOME/lib.  Version R2.13 has no such file.  If I remake
> | the .so file using R 2.13: then I get
> | 
> | tmt1084% ldd survival.so
> |         libc.so.6 => /lib64/libc.so.6 (0x00002b656a2f1000)
> |         /lib64/ld-linux-x86-64.so.2 (0x00000033cd800000)
> | 
> | And R
> | 
> | --------------
> | 
> | So, the real problem is a misleading error message.  I have several
> | pacakges loaded into my own ~/Rlib.  When I access one of these from
> | version 2.13 I get variable errors, or success.
> | 
> | tmt1087% R13 --vanilla
> | 
> | R version 2.13.0 RC (2011-04-11 r55409)
> | Copyright (C) 2011 The R Foundation for Statistical Computing
> | ISBN 3-900051-07-0
> | Platform: x86_64-unknown-linux-gnu (64-bit)
> | ...
> | 
> | > library(logspline)
> | Error: package 'logspline' was built before R 2.10.0: please re-install
> | it
> | 
> | > library(quadprog)
> | Error in dyn.load(file, DLLpath = DLLpath, ...) : 
> |   unable to load shared object
> | '/people/biostat2/therneau/Rlib/quadprog/libs/quadprog.so':
> |   libR.so: cannot open shared object file: No such file or directory
> | Error: package/namespace load failed for 'quadprog'
> | 
> | > library(xtable)
> | >
> | 
> | My problem is solved, but is this a "user confuser" issue that should be
> | addressed in the release?
> | 
> | Terry T.
> | 
> | 
>


From simon.urbanek at r-project.org  Wed Apr 13 23:05:23 2011
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Wed, 13 Apr 2011 17:05:23 -0400
Subject: [Rd] Problem with dyn.load in R 2.13.0 -- the real problem
In-Reply-To: <1302727627.12894.79.camel@nemo>
References: <1302717605.12894.28.camel@nemo>
	<19877.60604.384710.321827@max.nulle.part>
	<1302724885.12894.61.camel@nemo>
	<19878.2128.292065.275960@max.nulle.part>
	<1302727627.12894.79.camel@nemo>
Message-ID: <C59AB7F2-AC95-4710-9580-C8E43095B71F@r-project.org>


On Apr 13, 2011, at 4:47 PM, Terry Therneau wrote:

> 
> On Wed, 2011-04-13 at 15:32 -0500, Dirk Eddelbuettel wrote:
>> Terry,
>> 
>> You replied to
>> 
>>  From: Terry Therneau <therneau at mayo.edu>
>>  To: Dirk Eddelbuettel <edd at debian.org>
>>  Cc: cran at r-project.org
>>  Subject: Re: [Rd] Problem with dyn.load in R 2.13.0 -- the real problem
>> 
>> but dropped r-devel. On purpose?
> 
> No, not on purpose.  Corrected.
> 
>> This still looks like a local config issue about local libraries to me.
>> 
>> Dirk
> 
> I fail to see how.  Running the newest release of R 2.13, if I issue a library() command for something installed earlier in R_LIBS_USER, something I expect lots of people to do, and that library has a .so file with reference to the now-nonexistent Rlib.so file, an error ensues.

This depends on the OS - on Linux the path to libR is not embedded in the package's .so, so R will happily try to load whatever libR is current - regardless whether that breaks or not. Again, this is entirely OS-dependent. Also in your case you have an entirely different build of R so your issue is independent of R version - you'd get exactly the same issue if both R builds were 2.12.2.


> This is easy to test elsewhere. 
>  I don't anticipate that every user will erase all libraries and
> reinstall with each new R release.  

Well, then they are entirely on their own. Major releases are not guaranteed to be binary compatible and often they are not. Depending on the subset of the features a package may use it may or may not work, but it is never guaranteed. The first thing any user should do after R upgrade is to run update.packages. But, again, this is not really related to your problem ;). I suppose your admin has forgotten to use --enable-R-shlib when building 2.13.0.

Cheers,
Simon


> At work particularly, the default R
> release changes without user intervention; the system admin is not going
> to go looking for all local downloads.  (A lot of people use
> R_LIBS_USER, as they don't have permission to put things elsewhere --
> this includes me.)
>  The error message for logspline is great as it tells them what to do.
> I'm only looking for a better one in the case I found.
> 
>> 
>> On 13 April 2011 at 15:01, Terry Therneau wrote:
>> | Dirk's comment made it clearer:
>> | 
>> | On Wed, 2011-04-13 at 13:34 -0500, Dirk Eddelbuettel wrote:
>> | > What does 'ldd /path/to/your/survial.so' say?  Does the system find
>> | > libR.so?
>> | > 
>> | 
>> | tmt1077% pwd
>> | /people/biostat2/therneau/research/surv/Rtest
>> | tmt1078% ldd survival.so
>> |         libR.so => not found
>> |         libc.so.6 => /lib64/libc.so.6 (0x00002aede2d94000)
>> |         /lib64/ld-linux-x86-64.so.2 (0x00000033cd800000)
>> | 
>> | However, this is a survival.so file created by R12, and that version has
>> | a libR.so in RHOME/lib.  Version R2.13 has no such file.  If I remake
>> | the .so file using R 2.13: then I get
>> | 
>> | tmt1084% ldd survival.so
>> |         libc.so.6 => /lib64/libc.so.6 (0x00002b656a2f1000)
>> |         /lib64/ld-linux-x86-64.so.2 (0x00000033cd800000)
>> | 
>> | And R
>> | 
>> | --------------
>> | 
>> | So, the real problem is a misleading error message.  I have several
>> | pacakges loaded into my own ~/Rlib.  When I access one of these from
>> | version 2.13 I get variable errors, or success.
>> | 
>> | tmt1087% R13 --vanilla
>> | 
>> | R version 2.13.0 RC (2011-04-11 r55409)
>> | Copyright (C) 2011 The R Foundation for Statistical Computing
>> | ISBN 3-900051-07-0
>> | Platform: x86_64-unknown-linux-gnu (64-bit)
>> | ...
>> | 
>> | > library(logspline)
>> | Error: package 'logspline' was built before R 2.10.0: please re-install
>> | it
>> | 
>> | > library(quadprog)
>> | Error in dyn.load(file, DLLpath = DLLpath, ...) : 
>> |   unable to load shared object
>> | '/people/biostat2/therneau/Rlib/quadprog/libs/quadprog.so':
>> |   libR.so: cannot open shared object file: No such file or directory
>> | Error: package/namespace load failed for 'quadprog'
>> | 
>> | > library(xtable)
>> | >
>> | 
>> | My problem is solved, but is this a "user confuser" issue that should be
>> | addressed in the release?
>> | 
>> | Terry T.
>> | 
>> | 
>> 
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From therneau at mayo.edu  Wed Apr 13 23:12:23 2011
From: therneau at mayo.edu (Terry Therneau)
Date: Wed, 13 Apr 2011 16:12:23 -0500
Subject: [Rd] Problem with dyn.load in R 2.13.0
In-Reply-To: <A3CD0094-9331-49C1-B46C-1564FA3C9718@r-project.org>
References: <1302717605.12894.28.camel@nemo>
	<A3CD0094-9331-49C1-B46C-1564FA3C9718@r-project.org>
Message-ID: <1302729143.12894.97.camel@nemo>


On Wed, 2011-04-13 at 16:45 -0400, Simon Urbanek wrote:
> We have no details, but my wild guess would be that you did not
> re-build the package for 2.13.0 and you have static libR in 2.13.0 yet
> dynamic in 2.12.2.
> 
> Cheers,
> Simon
> 

Per my prior note, my guess at the root of the issue is use of user
libraries, which is common here.

Here are futher details if that helps.

 R2.13 was downloaded and built this AM in my ~/temp directory, using
the standard 
  ./configure
  make
Then a copy of the shell script was copied to in ~therneau/bin/R13 for
my convenience.  I paid very little attention to the output of
configure.

This is running on a shared server using CentOS release 5.5 (98 users at
the moment).
R2.12.2 is centrally available.

> sessionInfo()
R version 2.13.0 RC (2011-04-11 r55409)
Platform: x86_64-unknown-linux-gnu (64-bit)

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=C              
 [5] LC_MONETARY=C              LC_MESSAGES=en_US.UTF-8   
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                 
 [9] LC_ADDRESS=C               LC_TELEPHONE=C            
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base   

I can't find a libR.so anywhere -- perhaps it's static.

tmt1119% pwd
/people/biostat2/therneau/temp/R-rc
tmt1120% find . -name 'libR*'
./src/extra/blas/libRblas.so
./src/main/libR.a
./src/modules/lapack/libRlapack.so
./src/nmath/standalone/libRmath.pc.in
./src/unix/libR.pc.in
./lib/libRblas.so
./lib/libRlapack.so


Thanks for everyone's help.

Terry


From kasperdanielhansen at gmail.com  Thu Apr 14 02:53:41 2011
From: kasperdanielhansen at gmail.com (Kasper Daniel Hansen)
Date: Wed, 13 Apr 2011 20:53:41 -0400
Subject: [Rd] Problem with dyn.load in R 2.13.0 -- the real problem
In-Reply-To: <C59AB7F2-AC95-4710-9580-C8E43095B71F@r-project.org>
References: <1302717605.12894.28.camel@nemo>
	<19877.60604.384710.321827@max.nulle.part>
	<1302724885.12894.61.camel@nemo>
	<19878.2128.292065.275960@max.nulle.part>
	<1302727627.12894.79.camel@nemo>
	<C59AB7F2-AC95-4710-9580-C8E43095B71F@r-project.org>
Message-ID: <BANLkTi=qWneA+hK1S2Xmv5YZbDobcv5V3A@mail.gmail.com>

Terry

You may not be aware of this, but the "new" default in R is to use a
user library which is architecture and R-version dependent.  Ie. if
you do not play around with R_USER_LIBS or .Rprofile, functions like R
CMD INSTALL or install.packages will default to something like (from
my current version)
   "/home/bst/student/khansen/R/x86_64-unknown-linux-gnu-library/2.12"
My home is /home/bst/student/khansen so it puts it inside
  R / ARCHITECTURE / VERSION
Ok, it requires that you accept an R directory in your top level home,
but this is in almost all cases much preferred to playing with
R_USER_LIBS yourself (in my humble opinion).

Of course, this requires a re-install of all packages when you switch
R version and it also requires that you install each package
separately under each R you are using.

But it highly minimize the possibility of errors.  I don't think
installed packages are assured to be compatible across R versions in
any way.

Kasper

On Wed, Apr 13, 2011 at 5:05 PM, Simon Urbanek
<simon.urbanek at r-project.org> wrote:
>
> On Apr 13, 2011, at 4:47 PM, Terry Therneau wrote:
>
>>
>> On Wed, 2011-04-13 at 15:32 -0500, Dirk Eddelbuettel wrote:
>>> Terry,
>>>
>>> You replied to
>>>
>>> ?From: Terry Therneau <therneau at mayo.edu>
>>> ?To: Dirk Eddelbuettel <edd at debian.org>
>>> ?Cc: cran at r-project.org
>>> ?Subject: Re: [Rd] Problem with dyn.load in R 2.13.0 -- the real problem
>>>
>>> but dropped r-devel. On purpose?
>>
>> No, not on purpose. ?Corrected.
>>
>>> This still looks like a local config issue about local libraries to me.
>>>
>>> Dirk
>>
>> I fail to see how. ?Running the newest release of R 2.13, if I issue a library() command for something installed earlier in R_LIBS_USER, something I expect lots of people to do, and that library has a .so file with reference to the now-nonexistent Rlib.so file, an error ensues.
>
> This depends on the OS - on Linux the path to libR is not embedded in the package's .so, so R will happily try to load whatever libR is current - regardless whether that breaks or not. Again, this is entirely OS-dependent. Also in your case you have an entirely different build of R so your issue is independent of R version - you'd get exactly the same issue if both R builds were 2.12.2.
>
>
>> This is easy to test elsewhere.
>> ?I don't anticipate that every user will erase all libraries and
>> reinstall with each new R release.
>
> Well, then they are entirely on their own. Major releases are not guaranteed to be binary compatible and often they are not. Depending on the subset of the features a package may use it may or may not work, but it is never guaranteed. The first thing any user should do after R upgrade is to run update.packages. But, again, this is not really related to your problem ;). I suppose your admin has forgotten to use --enable-R-shlib when building 2.13.0.
>
> Cheers,
> Simon
>
>
>> At work particularly, the default R
>> release changes without user intervention; the system admin is not going
>> to go looking for all local downloads. ?(A lot of people use
>> R_LIBS_USER, as they don't have permission to put things elsewhere --
>> this includes me.)
>> ?The error message for logspline is great as it tells them what to do.
>> I'm only looking for a better one in the case I found.
>>
>>>
>>> On 13 April 2011 at 15:01, Terry Therneau wrote:
>>> | Dirk's comment made it clearer:
>>> |
>>> | On Wed, 2011-04-13 at 13:34 -0500, Dirk Eddelbuettel wrote:
>>> | > What does 'ldd /path/to/your/survial.so' say? ?Does the system find
>>> | > libR.so?
>>> | >
>>> |
>>> | tmt1077% pwd
>>> | /people/biostat2/therneau/research/surv/Rtest
>>> | tmt1078% ldd survival.so
>>> | ? ? ? ? libR.so => not found
>>> | ? ? ? ? libc.so.6 => /lib64/libc.so.6 (0x00002aede2d94000)
>>> | ? ? ? ? /lib64/ld-linux-x86-64.so.2 (0x00000033cd800000)
>>> |
>>> | However, this is a survival.so file created by R12, and that version has
>>> | a libR.so in RHOME/lib. ?Version R2.13 has no such file. ?If I remake
>>> | the .so file using R 2.13: then I get
>>> |
>>> | tmt1084% ldd survival.so
>>> | ? ? ? ? libc.so.6 => /lib64/libc.so.6 (0x00002b656a2f1000)
>>> | ? ? ? ? /lib64/ld-linux-x86-64.so.2 (0x00000033cd800000)
>>> |
>>> | And R
>>> |
>>> | --------------
>>> |
>>> | So, the real problem is a misleading error message. ?I have several
>>> | pacakges loaded into my own ~/Rlib. ?When I access one of these from
>>> | version 2.13 I get variable errors, or success.
>>> |
>>> | tmt1087% R13 --vanilla
>>> |
>>> | R version 2.13.0 RC (2011-04-11 r55409)
>>> | Copyright (C) 2011 The R Foundation for Statistical Computing
>>> | ISBN 3-900051-07-0
>>> | Platform: x86_64-unknown-linux-gnu (64-bit)
>>> | ...
>>> |
>>> | > library(logspline)
>>> | Error: package 'logspline' was built before R 2.10.0: please re-install
>>> | it
>>> |
>>> | > library(quadprog)
>>> | Error in dyn.load(file, DLLpath = DLLpath, ...) :
>>> | ? unable to load shared object
>>> | '/people/biostat2/therneau/Rlib/quadprog/libs/quadprog.so':
>>> | ? libR.so: cannot open shared object file: No such file or directory
>>> | Error: package/namespace load failed for 'quadprog'
>>> |
>>> | > library(xtable)
>>> | >
>>> |
>>> | My problem is solved, but is this a "user confuser" issue that should be
>>> | addressed in the release?
>>> |
>>> | Terry T.
>>> |
>>> |
>>>
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From ken.sensei at gmail.com  Thu Apr 14 07:49:57 2011
From: ken.sensei at gmail.com (Mohit Dayal)
Date: Thu, 14 Apr 2011 11:19:57 +0530
Subject: [Rd] Using GSL Routines
Message-ID: <BANLkTimacZbmyyqsL6052W_1Y2Y_rob3ZQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110414/619875f7/attachment.pl>

From hankin.robin at gmail.com  Thu Apr 14 08:07:32 2011
From: hankin.robin at gmail.com (robin hankin)
Date: Thu, 14 Apr 2011 18:07:32 +1200
Subject: [Rd] Using GSL Routines
In-Reply-To: <BANLkTimacZbmyyqsL6052W_1Y2Y_rob3ZQ@mail.gmail.com>
References: <BANLkTimacZbmyyqsL6052W_1Y2Y_rob3ZQ@mail.gmail.com>
Message-ID: <BANLkTi=WXkQf8YUbt8XGpLXf0SZFr0vPKw@mail.gmail.com>

Hi

the gsl R package includes many wrappers which you may find useful,
but if you write new ones please let me know and I'll include them
in a future release.

best wishes

Robin

On Thu, Apr 14, 2011 at 5:49 PM, Mohit Dayal <ken.sensei at gmail.com> wrote:
> Dear R-programmers,
>
> I am trying out certain methods in R, and the statistics require me to
> calculate n-(sample size) dimensional equations. They are not really very
> hard to solve - my home-brew implentation of Newton-Raphson in R succeeds
> most of time with simulated data. (Note that I am assured of a unique
> solution by theory). Problem comes in with real data, for which I should
> really implement a good line search (convergence issues). Being lazy, i
> would like to link to the GSL routines which are of course faster and more
> reliable.
>
> My question is should i use the C - GSL routines or the Python ones in
> NumPy? My major concern is the portability of the code i write: really dont
> want users to have to install a bunch of software just to use my package.
> (Im looking at Windows here)
>
> Alternatively, should i just hack out the code (fsolve) and put it in my
> package?
>
> Thanks for the advice,
> Mohit Dayal
> Applied Statistics & Computing Lab
> ISB
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>



-- 
Robin Hankin
Uncertainty Analyst
hankin.robin at gmail.com


From jperkins at biochem.ucl.ac.uk  Thu Apr 14 14:54:00 2011
From: jperkins at biochem.ucl.ac.uk (James Perkins)
Date: Thu, 14 Apr 2011 13:54:00 +0100
Subject: [Rd] S4 plus <tab>
Message-ID: <BANLkTi=er3TAD=r9kpO1Uj=xftFufhWrwg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110414/e62aa1f1/attachment.pl>

From milbo at sonic.net  Thu Apr 14 14:56:36 2011
From: milbo at sonic.net (Stephen Milborrow)
Date: Thu, 14 Apr 2011 14:56:36 +0200
Subject: [Rd] Postscript can be very slow in R 2.13-0
Message-ID: <4AA6907846944843A2CEAF679DF5231C@Studio17>

Viewing certain postscript files under R 2.13-0 is very slow, at least using
GSview on my 64 bit Windows 7 system.  To see this, compare how long it 
takes to display these two files (fast.ps was created by removing the /srgb 
stuff in .ps.prolog):

    www.milbo.org/postscript/slow.ps

    www.milbo.org/postscript/fast.ps

The code to produce the above two files is here:

    www.milbo.org/postscript/slow-postscript.R

This is not exactly a bug, but is it a known issue?  The hack used to
produce fast.ps above is fragile and not suitable for regular use.  Is there
a option to the postscript() function (or could one be added) that would
sacrifice sRGB support for speed?

Stephen Milborrow
www.milbo.users.sonic.net

Version info:

I'm using GSview 4.9 and Ghostscript 8.64.

> R.version
               _
platform       x86_64-pc-mingw32
arch           x86_64
os             mingw32
system         x86_64, mingw32
status
major          2
minor          13.0
year           2011
month          04
day            13
svn rev        55427
language       R
version.string R version 2.13.0 (2011-04-13)


From janko.thyson.rstuff at googlemail.com  Thu Apr 14 23:13:43 2011
From: janko.thyson.rstuff at googlemail.com (Janko Thyson)
Date: Thu, 14 Apr 2011 23:13:43 +0200
Subject: [Rd] Possible bug in 'relist()' and/or 'as.relistable()'
Message-ID: <4da76321.017b0e0a.123e.4d54@mx.google.com>

Dear list,

I think I just stumbled across a bug in either 'relist()' and/or
'as.relistable()'. It seems that 'pairlists' can only be un- and relisted as
long as they're not nested:

Good:
a <- as.relistable(as.pairlist(list(a=1, b=2)))
a <- unlist(a)
relist(a)# Works

Bad:
a <- as.relistable(as.pairlist(list(a=1, b=2, c=list(c.1=1, c.2=2))))
a <- unlist(a)
relist(a)

The help page didn't say anything about pairlists and I don't know if
they're at all relevant, but I'm using them whenever I want my functions to
recognize a clear 'name-value' structure (e.g. for batch assigning
variables) as opposed to standard list structures.

Cheers,
Janko

>     sessionInfo()
R version 2.12.1 (2010-12-16)
Platform: i386-pc-mingw32/i386 (32-bit)

locale:
[1] LC_COLLATE=German_Germany.1252  LC_CTYPE=German_Germany.1252   
[3] LC_MONETARY=German_Germany.1252 LC_NUMERIC=C                   
[5] LC_TIME=German_Germany.1252    

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

loaded via a namespace (and not attached):
[1] codetools_0.2-8 tools_2.12.1


From simon.urbanek at r-project.org  Thu Apr 14 23:45:45 2011
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Thu, 14 Apr 2011 17:45:45 -0400
Subject: [Rd] Possible bug in 'relist()' and/or 'as.relistable()'
In-Reply-To: <4da76321.017b0e0a.123e.4d54@mx.google.com>
References: <4da76321.017b0e0a.123e.4d54@mx.google.com>
Message-ID: <1F2871B3-E2A8-4F35-83FD-ECF0B5A97CAF@r-project.org>


On Apr 14, 2011, at 5:13 PM, Janko Thyson wrote:

> Dear list,
> 
> I think I just stumbled across a bug in either 'relist()' and/or
> 'as.relistable()'. It seems that 'pairlists' can only be un- and relisted as
> long as they're not nested:
> 
> Good:
> a <- as.relistable(as.pairlist(list(a=1, b=2)))
> a <- unlist(a)
> relist(a)# Works
> 
> Bad:
> a <- as.relistable(as.pairlist(list(a=1, b=2, c=list(c.1=1, c.2=2))))

Technically, you're not nesting pairlists - you' are putting a generic vector in a parilist ... (not that it matters here).


> a <- unlist(a)
> relist(a)
> 

relist() has no method for pairlists - but you can actually use the "list" method as-is:

> relist.pairlist <- utils:::relist.list
> str(src <- as.pairlist(list(a=1, b=2, c=list(c.1=1, c.2=2))))
Dotted pair list of 3
 $ a: num 1
 $ b: num 2
 $ c:List of 2
  ..$ c.1: num 1
  ..$ c.2: num 2
> str(relist(unlist(as.relistable(src))))
Dotted pair list of 3
 $ a: num 1
 $ b: num 2
 $ c:List of 2
  ..$ c.1: num 1
  ..$ c.2: num 2
 - attr(*, "class")= chr [1:2] "relistable" "pairlist"

and that will also support actual nested pairlists:

> str(src <- pairlist(a=1, b=2, c=pairlist(c.1=1, c.2=2)))
Dotted pair list of 3
 $ a: num 1
 $ b: num 2
 $ c:Dotted pair list of 2
  ..$ c.1: num 1
  ..$ c.2: num 2
> str(relist(unlist(as.relistable(src))))
Dotted pair list of 3
 $ a: num 1
 $ b: num 2
 $ c:Dotted pair list of 2
  ..$ c.1: num 1
  ..$ c.2: num 2
 - attr(*, "class")= chr [1:2] "relistable" "pairlist"


so I guess it should be easy to add relist.pairlist to utils ... I'm not sure about the implications, but it does sound appealing.

Cheers,
Simon



> The help page didn't say anything about pairlists and I don't know if
> they're at all relevant, but I'm using them whenever I want my functions to
> recognize a clear 'name-value' structure (e.g. for batch assigning
> variables) as opposed to standard list structures.
> 
> Cheers,
> Janko
> 
>>    sessionInfo()
> R version 2.12.1 (2010-12-16)
> Platform: i386-pc-mingw32/i386 (32-bit)
> 
> locale:
> [1] LC_COLLATE=German_Germany.1252  LC_CTYPE=German_Germany.1252   
> [3] LC_MONETARY=German_Germany.1252 LC_NUMERIC=C                   
> [5] LC_TIME=German_Germany.1252    
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base     
> 
> loaded via a namespace (and not attached):
> [1] codetools_0.2-8 tools_2.12.1
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From D.Strbenac at garvan.org.au  Fri Apr 15 05:00:21 2011
From: D.Strbenac at garvan.org.au (Dario Strbenac)
Date: Fri, 15 Apr 2011 13:00:21 +1000 (EST)
Subject: [Rd] DESCRIPTION file and Rd examples
Message-ID: <20110415130021.BLM73721@gimr.garvan.unsw.edu.au>

I have a confusing error from R CMD check that I don't get when running the example manually by hand.

In the \examples section of an Rd file, I create a GRanges object, then I call a function with the GRanges object, whose first 2 lines are

    require(GenomicRanges)
    annoDF <- as.data.frame(anno) # anno is the GRanges object.

and that second line gives:

Error in as.data.frame.default(anno) : 
  cannot coerce class 'structure("GRanges", package = "GenomicRanges")' into a data.frame
Calls: annoGR2DF ... annoGR2DF -> .local -> as.data.frame -> as.data.frame.default

I have GenomicRanges listed in my Imports: field, and IRanges in the Suggests: of the DESCRIPTION file (it's require()d elsewhere). I'm trying to avoid putting packages in Depends: , so my package loads fast. Any tips of what I'm not understanding properly ?

Thanks.

--------------------------------------
Dario Strbenac
Research Assistant
Cancer Epigenetics
Garvan Institute of Medical Research
Darlinghurst NSW 2010
Australia


From pdalgd at gmail.com  Fri Apr 15 09:10:25 2011
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 15 Apr 2011 09:10:25 +0200
Subject: [Rd] [R] predict()
In-Reply-To: <713640.46077.qm@web36904.mail.mud.yahoo.com>
References: <713640.46077.qm@web36904.mail.mud.yahoo.com>
Message-ID: <CE50B2DD-6BEB-4D59-ABD9-3F983CD0EAE4@gmail.com>


On Apr 14, 2011, at 16:52 , Ivo Shterev wrote:

> Dear Dr. Therneau,
> 
> Thank you for your response. Just to point out that we didn't experience any problems with the lm() function under R version 2.12.2 (2011-02-25):

I couldn't reproduce it from Terry's description either, but there _is_ an issue which parallels the coxph one: In model.frame.lm, we have

function (formula, ...) 
{
    dots <- list(...)
    nargs <- dots[match(c("data", "na.action", "subset"), names(dots), 
        0)]
    if (length(nargs) || is.null(formula$model)) {
        fcall <- formula$call
        fcall$method <- "model.frame"
        fcall[[1L]] <- as.name("lm")
        fcall[names(nargs)] <- nargs
        env <- environment(formula$terms)
        if (is.null(env)) 
            env <- parent.frame()
        eval(fcall, env, parent.frame())
    }
    else formula$model
}
<environment: namespace:stats>

So under some circumstances, we evaluate formula$call (where "formula" is actually an "lm" object --- and age-old design infelicity) with modified arguments. This evaluation takes place in the environment of the model formula, nested in the parent frame, but neither necessarily contains the arguments to formula$call:

> t3
function(dat,fm)
 {
   model.frame(lm(fm,data=dat),subset=1:5)
 }
> testdat
        otime event          x
1  0.84345726     0 -0.4456620
2  0.57661027     0  1.2240818
3  1.32905487     0  0.3598138
4  0.03157736     0  0.4007715
5  0.05621098     0  0.1106827
6  0.31650122     1 -0.5558411
7  0.31422729     1  1.7869131
8  0.14526680     1  0.4978505
9  2.72623646     1 -1.9666172
10 0.02915345     1  0.7013559
> fm2
otime ~ x
> t3(testdat,fm2)
Error in model.frame(formula = fm, data = dat, subset = 1:5, drop.unused.levels = TRUE) : 
  object 'fm' not found

It looks more than a bit iffy to try and set this right. One suggestion could be to explicitly replace the formula part of fcall with the formula contained in the model object. Or, the original evaluation frame should be kept with the model object and used rather than parent.frame(). 

This should probably move to r-devel.



> 
>> set.seed(123)
>> testdat=data.frame(y=rexp(10),event=rep(0:1,each=5),x=rnorm(10))
>> testfm=as.formula('y~x')
>> 
>> testfun=function(dat,fm)
> +   {
> +     predict(lm(fm,data=dat),newdata=dat)
> +   }
>> testfun(testdat,testfm)
>          1           2           3           4           5           6 
> 1.00414971  0.07061335  0.55381658  0.53091759  0.69310319  1.06574974 
>          7           8           9          10 
> -0.24405980  0.47664172  1.85449993  0.36286396 
>> sessionInfo()
> R version 2.12.2 (2011-02-25)
> Platform: x86_64-pc-linux-gnu (64-bit)
> 
> locale:
> [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              
> [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    
> [5] LC_MONETARY=C              LC_MESSAGES=en_US.UTF-8   
> [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                 
> [9] LC_ADDRESS=C               LC_TELEPHONE=C            
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base     
> 
> loaded via a namespace (and not attached):
> [1] tools_2.12.2
>> 
> 
> 
> Regards
> Ivo
> 
> 
> 
> --- On Thu, 4/14/11, Terry Therneau <therneau at mayo.edu> wrote:
> 
>> From: Terry Therneau <therneau at mayo.edu>
>> Subject: Re: predict()
>> To: "Ivo Shterev" <idc318 at yahoo.com>
>> Cc: r-help at r-project.org
>> Date: Thursday, April 14, 2011, 2:59 PM
>> --- begin included message ---
>> I am experimenting with the function predict() in two
>> versions of R and
>> the R extension package "survival".
>> 
>> library(survival)
>> 
>> set.seed(123)
>> testdat=data.frame(otime=rexp(10),event=rep(0:1,each=5),x=rnorm(10))
>> testfm=as.formula('Surv(otime,event)~x')
>> 
>> testfun=function(dat,fm)
>>   {
>>    
>> predict(coxph(fm,data=dat),type='lp',newdata=dat)
>>   }
>> 
>> -- end inclusion ----
>> 
>> The question was: this works under survival 2.35-8, but
>> not survival
>> 2.36-5
>> 
>> Answer: The predict and underlying model.frame functions
>> for coxph were
>> brought into line with lm and other models.  The major
>> advantage is that
>> I now deal with factors and data dependent predictors like
>> ns()
>> correctly.
>>   You've shown a disadvantage of which I was not
>> aware.  Using your
>> example but replacing coxph() by lm() with otime ~x as the
>> model I get a
>> similar failure.  I'd like to ask a wider audience of
>> R-devel since it
>> is bigger than coxph.
>> 
>> Terry Therneau
>> 
>> 
>> 
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From therneau at mayo.edu  Fri Apr 15 13:41:12 2011
From: therneau at mayo.edu (Terry Therneau)
Date: Fri, 15 Apr 2011 06:41:12 -0500
Subject: [Rd] predict()
Message-ID: <201104151141.p3FBfCsa023490@nemo.mayo.edu>


On Fri, 2011-04-15 at 09:10 +0200, peter dalgaard wrote:
> I couldn't reproduce it from Terry's description either, but there
> _is_ an issue which parallels the ....

I'll start with an apology: as a first guess to understand the problem
with predict.coxph I tried something parallel to Ivo's example using lm,
during a 5 minute slice of time between meetings.  I got a similar error
message, posted a query based on that, and ran off.  The real root of my
error message, however, was a simple typographical mistake.  My
apologies for the premature note, whose error was gently pointed out by
all three of you.  I should have waited till I had more time.

 Now for the real problem, which is an oversight in my design.  When
updating the predict.coxph, residuals.coxph, survfit.coxph and
survexp.coxph functions to more modern processing of the newdata
argument (proper handling of factors, etc), I made a decision to have
all of them call model.frame.coxph and model.matrix.coxph.  Model.matrix
in particular has some special steps, and it would be better to have
only one point of modification.
  However, this introduces one more level of indirection
        predict >- model.frame.coxph -> model.frame
and the parent.frame() reference in model.frame.coxph now points to
predict when we actually want it to point to the parent of predict.  In
predict.lm the parent.frame() argument lives in the predict.lm code.

 I see three paths to correction:
1. Make model.frame.coxph smarter.  Peter's example seems to show that
this is hard.

2. Change the line in predict.coxph (and the others)
        mf <- model.frame(object)
to some form of eval() that causes the parent.frame() operation to reach
back properly.  I'm not yet sure what variant of eval or do.call or ...
this is; the effect I'm looking for is similar to what NextMethod()
does.

3. Change my call to
        mf <- model.frame(object$terms, ...  mimic the call in lm
This may be the simplest, since model.frame.coxph does not do anything
special.

Last, I need to check whether any of the above issues affect
model.matrix calls.

Any comments on which is the better path would be welcomed.

Terry T.


From therneau at mayo.edu  Fri Apr 15 13:45:28 2011
From: therneau at mayo.edu (Terry Therneau)
Date: Fri, 15 Apr 2011 06:45:28 -0500
Subject: [Rd] predict()
Message-ID: <201104151145.p3FBjSh8024024@nemo.mayo.edu>

An addition to my prior post: my option 3 is not as attractive as
I thought.  
  In several cases predict.coxph needs to reconstruct the original data
frame, for things that were not saved in the coxph object.  The half
dozen lines to redo the orignal call with the same data, na.action, etc
options is simple, but a nuisance to reproduce in multiple spots.

Terry


From ligges at statistik.tu-dortmund.de  Fri Apr 15 17:42:45 2011
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Fri, 15 Apr 2011 17:42:45 +0200
Subject: [Rd] DESCRIPTION file and Rd examples
In-Reply-To: <20110415130021.BLM73721@gimr.garvan.unsw.edu.au>
References: <20110415130021.BLM73721@gimr.garvan.unsw.edu.au>
Message-ID: <4DA86775.6050604@statistik.tu-dortmund.de>

It would probably be helpful if you could point us to the source version 
of your package so that we can take a look what happens.
Which version of R, and the other required packages are you talking about?

Uwe Ligges




On 15.04.2011 05:00, Dario Strbenac wrote:
> I have a confusing error from R CMD check that I don't get when running the example manually by hand.
>
> In the \examples section of an Rd file, I create a GRanges object, then I call a function with the GRanges object, whose first 2 lines are
>
>      require(GenomicRanges)
>      annoDF<- as.data.frame(anno) # anno is the GRanges object.
>
> and that second line gives:
>
> Error in as.data.frame.default(anno) :
>    cannot coerce class 'structure("GRanges", package = "GenomicRanges")' into a data.frame
> Calls: annoGR2DF ... annoGR2DF ->  .local ->  as.data.frame ->  as.data.frame.default
>
> I have GenomicRanges listed in my Imports: field, and IRanges in the Suggests: of the DESCRIPTION file (it's require()d elsewhere). I'm trying to avoid putting packages in Depends: , so my package loads fast. Any tips of what I'm not understanding properly ?
>
> Thanks.
>
> --------------------------------------
> Dario Strbenac
> Research Assistant
> Cancer Epigenetics
> Garvan Institute of Medical Research
> Darlinghurst NSW 2010
> Australia
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From simon.urbanek at r-project.org  Fri Apr 15 20:18:24 2011
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Fri, 15 Apr 2011 14:18:24 -0400
Subject: [Rd] DESCRIPTION file and Rd examples
In-Reply-To: <20110415130021.BLM73721@gimr.garvan.unsw.edu.au>
References: <20110415130021.BLM73721@gimr.garvan.unsw.edu.au>
Message-ID: <13B22E72-633B-452F-8F9C-1BB16A444EEB@r-project.org>


On Apr 14, 2011, at 11:00 PM, Dario Strbenac wrote:

> I have a confusing error from R CMD check that I don't get when running the example manually by hand.
> 
> In the \examples section of an Rd file, I create a GRanges object, then I call a function with the GRanges object, whose first 2 lines are
> 
>    require(GenomicRanges)

require() is doesn't guarantee that the package will load, so I think what you meant to write was more

if (require(GenomicRanges, quietly=TRUE)) {
 ...

>    annoDF <- as.data.frame(anno) # anno is the GRanges object.
> 
> and that second line gives:
> 
> Error in as.data.frame.default(anno) : 
>  cannot coerce class 'structure("GRanges", package = "GenomicRanges")' into a data.frame
> Calls: annoGR2DF ... annoGR2DF -> .local -> as.data.frame -> as.data.frame.default
> 
> I have GenomicRanges listed in my Imports: field, and IRanges in the Suggests: of the DESCRIPTION file (it's require()d elsewhere). I'm trying to avoid putting packages in Depends: , so my package loads fast. Any tips of what I'm not understanding properly ?
> 
> Thanks.
> 
> --------------------------------------
> Dario Strbenac
> Research Assistant
> Cancer Epigenetics
> Garvan Institute of Medical Research
> Darlinghurst NSW 2010
> Australia
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From mtmorgan at fhcrc.org  Sat Apr 16 05:34:54 2011
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Fri, 15 Apr 2011 20:34:54 -0700
Subject: [Rd] DESCRIPTION file and Rd examples
In-Reply-To: <13B22E72-633B-452F-8F9C-1BB16A444EEB@r-project.org>
References: <20110415130021.BLM73721@gimr.garvan.unsw.edu.au>
	<13B22E72-633B-452F-8F9C-1BB16A444EEB@r-project.org>
Message-ID: <4DA90E5E.9020109@fhcrc.org>

On 04/15/2011 11:18 AM, Simon Urbanek wrote:
>
> On Apr 14, 2011, at 11:00 PM, Dario Strbenac wrote:
>
>> I have a confusing error from R CMD check that I don't get when running the example manually by hand.
>>
>> In the \examples section of an Rd file, I create a GRanges object, then I call a function with the GRanges object, whose first 2 lines are
>>
>>     require(GenomicRanges)
>
> require() is doesn't guarantee that the package will load, so I think what you meant to write was more
>
> if (require(GenomicRanges, quietly=TRUE)) {
>   ...
>
>>     annoDF<- as.data.frame(anno) # anno is the GRanges object.
>>
>> and that second line gives:
>>
>> Error in as.data.frame.default(anno) :
>>   cannot coerce class 'structure("GRanges", package = "GenomicRanges")' into a data.frame
>> Calls: annoGR2DF ... annoGR2DF ->  .local ->  as.data.frame ->  as.data.frame.default

Try IRanges::as.data.frame(anno)

I'm guessing that your call finds base::as.data.frame, perhaps because 
some earlier example has already require'd GenomicRanges, and that it's 
definition of as.data.frame has been masked some time in between.

It's too complicated to debug in detail; R CMD check produces a file 
<pkg>.Rcheck/<pkg>-Ex.R that contains the compiled example code, and it 
is in the evaluation of this file that the error occurs. So you could 
dissect it to discover the gory details.

Martin

>>
>> I have GenomicRanges listed in my Imports: field, and IRanges in the Suggests: of the DESCRIPTION file (it's require()d elsewhere). I'm trying to avoid putting packages in Depends: , so my package loads fast. Any tips of what I'm not understanding properly ?
>>
>> Thanks.
>>
>> --------------------------------------
>> Dario Strbenac
>> Research Assistant
>> Cancer Epigenetics
>> Garvan Institute of Medical Research
>> Darlinghurst NSW 2010
>> Australia
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
Computational Biology
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N. PO Box 19024 Seattle, WA 98109

Location: M1-B861
Telephone: 206 667-2793


From ken.sensei at gmail.com  Sun Apr 17 07:34:32 2011
From: ken.sensei at gmail.com (Mohit Dayal)
Date: Sun, 17 Apr 2011 11:04:32 +0530
Subject: [Rd] Tail Call Elimination?
Message-ID: <BANLkTim3Y+zfNBBjGTXE4PijRqv41Cs-nw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110417/368d2120/attachment.pl>

From djsamperi at gmail.com  Sun Apr 17 18:46:12 2011
From: djsamperi at gmail.com (Dominick Samperi)
Date: Sun, 17 Apr 2011 12:46:12 -0400
Subject: [Rd] Tail Call Elimination?
In-Reply-To: <BANLkTim3Y+zfNBBjGTXE4PijRqv41Cs-nw@mail.gmail.com>
References: <BANLkTim3Y+zfNBBjGTXE4PijRqv41Cs-nw@mail.gmail.com>
Message-ID: <BANLkTinPoL897QO7jRAvv-JfVz3KzSO-MQ@mail.gmail.com>

The Scheme-inspired function callCC may support this to some extent, but
the R man page on this function is very sketchy. Examples have been
posted by the author of callCC, so you might want to search the archives.

Dominick

On Sun, Apr 17, 2011 at 1:34 AM, Mohit Dayal <ken.sensei at gmail.com> wrote:
> Dear R-programmers,
>
> I am trying to program a Newton-Raphson in R (yes, i will try GSL, not right
> now), and it would be a real boon if R had tail call elimination, so that a
> recursive program has a guarantee not to fail due to stack overflows, given
> how slow loops in R are. I did look at the documentation, but could not find
> a reason for it.
>
> Regards,
> Mohit Dayal
> Researcher
> Applied Statistics & Computing Lab
> ISB
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From D.Strbenac at garvan.org.au  Mon Apr 18 04:00:06 2011
From: D.Strbenac at garvan.org.au (Dario Strbenac)
Date: Mon, 18 Apr 2011 12:00:06 +1000 (EST)
Subject: [Rd] DESCRIPTION file and Rd examples
Message-ID: <20110418120006.BLN05010@gimr.garvan.unsw.edu.au>

It turns out what I needed was IRanges in the Imports: field. I assumed that require(GenomicRanges) at the top of my function would, as a result of loading GenomicRanges, implicitly already know about all the IRanges classes, because GenomicRanges itself depends on them.

---- Original message ----
>Date: Fri, 15 Apr 2011 20:34:54 -0700
>From: Martin Morgan <mtmorgan at fhcrc.org>  
>Subject: Re: [Rd] DESCRIPTION file and Rd examples  
>To: Simon Urbanek <simon.urbanek at r-project.org>
>Cc: D.Strbenac at garvan.org.au, r-devel at r-project.org
>
>On 04/15/2011 11:18 AM, Simon Urbanek wrote:
>>
>> On Apr 14, 2011, at 11:00 PM, Dario Strbenac wrote:
>>
>>> I have a confusing error from R CMD check that I don't get when running the example manually by hand.
>>>
>>> In the \examples section of an Rd file, I create a GRanges object, then I call a function with the GRanges object, whose first 2 lines are
>>>
>>>     require(GenomicRanges)
>>
>> require() is doesn't guarantee that the package will load, so I think what you meant to write was more
>>
>> if (require(GenomicRanges, quietly=TRUE)) {
>>   ...
>>
>>>     annoDF<- as.data.frame(anno) # anno is the GRanges object.
>>>
>>> and that second line gives:
>>>
>>> Error in as.data.frame.default(anno) :
>>>   cannot coerce class 'structure("GRanges", package = "GenomicRanges")' into a data.frame
>>> Calls: annoGR2DF ... annoGR2DF ->  .local ->  as.data.frame ->  as.data.frame.default
>
>Try IRanges::as.data.frame(anno)
>
>I'm guessing that your call finds base::as.data.frame, perhaps because 
>some earlier example has already require'd GenomicRanges, and that it's 
>definition of as.data.frame has been masked some time in between.
>
>It's too complicated to debug in detail; R CMD check produces a file 
><pkg>.Rcheck/<pkg>-Ex.R that contains the compiled example code, and it 
>is in the evaluation of this file that the error occurs. So you could 
>dissect it to discover the gory details.
>
>Martin
>
>>>
>>> I have GenomicRanges listed in my Imports: field, and IRanges in the Suggests: of the DESCRIPTION file (it's require()d elsewhere). I'm trying to avoid putting packages in Depends: , so my package loads fast. Any tips of what I'm not understanding properly ?
>>>
>>> Thanks.
>>>
>>> --------------------------------------
>>> Dario Strbenac
>>> Research Assistant
>>> Cancer Epigenetics
>>> Garvan Institute of Medical Research
>>> Darlinghurst NSW 2010
>>> Australia
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>>
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>
>-- 
>Computational Biology
>Fred Hutchinson Cancer Research Center
>1100 Fairview Ave. N. PO Box 19024 Seattle, WA 98109
>
>Location: M1-B861
>Telephone: 206 667-2793


--------------------------------------
Dario Strbenac
Research Assistant
Cancer Epigenetics
Garvan Institute of Medical Research
Darlinghurst NSW 2010
Australia


From tlumley at uw.edu  Mon Apr 18 06:55:11 2011
From: tlumley at uw.edu (Thomas Lumley)
Date: Mon, 18 Apr 2011 16:55:11 +1200
Subject: [Rd] DESCRIPTION file and Rd examples
In-Reply-To: <20110418120006.BLN05010@gimr.garvan.unsw.edu.au>
References: <20110418120006.BLN05010@gimr.garvan.unsw.edu.au>
Message-ID: <BANLkTinvhqYfu5-wfe0G-GFH7JRngbKwgg@mail.gmail.com>

On Mon, Apr 18, 2011 at 2:00 PM, Dario Strbenac
<D.Strbenac at garvan.org.au> wrote:
> It turns out what I needed was IRanges in the Imports: field. I assumed that require(GenomicRanges) at the top of my function would, as a result of loading GenomicRanges, implicitly already know about all the IRanges classes, because GenomicRanges itself depends on them.

If GenomicRanges just imports IRanges (rather than using
library()/require()) then the IRanges functions won't be exported to
your package.  This is a Good Thing -- you only get the function
redefinitions you ask for, rather than everything in the dependency
tree.

    -thomas

-- 
Thomas Lumley
Professor of Biostatistics
University of Auckland


From jusce at hotmail.com  Mon Apr 18 04:29:37 2011
From: jusce at hotmail.com (jusce)
Date: Sun, 17 Apr 2011 19:29:37 -0700 (PDT)
Subject: [Rd] R script in batch mode
Message-ID: <1303093777169-3456471.post@n4.nabble.com>

Hello All!

I'm a new R user, with no much experience.
I have a R script (downloaded from internet) which has user interaction
using "readline()" function.
So as I have to run it repeatdly (with some different options) I was
planning to do it on a BATCH mode.

Is there any way to answer the "readline()" questions from a batch file?

How do I do that?

I'm using R under Linux.

Thanks,
Jose

--
View this message in context: http://r.789695.n4.nabble.com/R-script-in-batch-mode-tp3456471p3456471.html
Sent from the R devel mailing list archive at Nabble.com.


From tal.galili at gmail.com  Mon Apr 18 08:51:04 2011
From: tal.galili at gmail.com (Tal Galili)
Date: Mon, 18 Apr 2011 09:51:04 +0300
Subject: [Rd] Patching "update.packages" to enable updating of only a user
 defined subset of packages
Message-ID: <BANLkTinvjw3n4QUV+v1m-U9ojdwdh7mBDA@mail.gmail.com>

Hello dear R developers,

I recently found out that it is not possible to limit update.packages() to
update only a few packages at a time.

The patch offered simply adds a 'subset' parameter and the statement bounded
within "if(!missing(subset))" to implement it.
The code is pasted bellow (and also attached as an .r file).

Might this patch be considered valuable to be added to R?


(in the code bellow I called the function "update.packages.2" so to not mask
the original update.packages)


With much respect,
Tal

###############################


update.packages.2 <-
function (lib.loc = NULL, repos = getOption("repos"), contriburl =
contrib.url(repos,
    type), method, instlib = NULL, ask = TRUE, available = NULL,
    oldPkgs = NULL, ..., checkBuilt = FALSE, type = getOption("pkgType"),
subset)
{
    force(ask)
    text.select <- function(old) {
        update <- NULL
        for (k in seq_len(nrow(old))) {
            cat(old[k, "Package"], ":\n", "Version", old[k, "Installed"],
                "installed in", old[k, "LibPath"], if (checkBuilt)
                  paste("built under R", old[k, "Built"]), "\n",
                "Version", old[k, "ReposVer"], "available at",
                simplifyRepos(old[k, "Repository"], type))
            cat("\n")
            answer <- substr(readline("Update (y/N/c)?  "), 1L,
                1L)
            if (answer == "c" | answer == "C") {
                cat("cancelled by user\n")
                return(invisible())
            }
            if (answer == "y" | answer == "Y")
                update <- rbind(update, old[k, ])
        }
        update
    }
    if (is.null(lib.loc))
        lib.loc <- .libPaths()
    if (is.null(available))
        available <- available.packages(contriburl = contriburl,
            method = method)
    if (is.null(oldPkgs)) {
        oldPkgs <- old.packages(lib.loc = lib.loc, contriburl = contriburl,
            method = method, available = available, checkBuilt = checkBuilt)
        if (is.null(oldPkgs))
            return(invisible())
    }
    else if (!(is.matrix(oldPkgs) && is.character(oldPkgs)))
        stop("invalid 'oldPkgs'; must be a result from old.packages()")
 if(!missing(subset)) # if the user uses 'subset'
 {
if(mode(subset) != "character") stop("'subset' must be a character vector
(with names of packages)")
 ss <- oldPkgs[,"Package"] %in% subset # are there any old packages that the
user would have liked to update?
 if(!any(ss)) {
cat("There are no available new updates for the packages you have entered \n
")
 return(invisible())
} # if not - then we can end the function here
 oldPkgs <- oldPkgs[ss,] # else - we can go on, but this time only use a
subset of the oldPkgs.
 if(sum(ss)==1) oldPkgs <- t(oldPkgs) # in case there is only 1 package to
update, make sure the object "oldPkgs" is of the correct form (6 columns
instead of 1 vector)
 }
    update <- if (is.character(ask) && ask == "graphics") {
        if (.Platform$OS.type == "windows" || .Platform$GUI ==
            "AQUA" || (capabilities("tcltk") && capabilities("X11"))) {
            k <- select.list(oldPkgs[, 1L], oldPkgs[, 1L], multiple = TRUE,
                title = "Packages to be updated", graphics = TRUE)
            oldPkgs[match(k, oldPkgs[, 1L]), , drop = FALSE]
        }
        else text.select(oldPkgs)
    }
    else if (isTRUE(ask))
        text.select(oldPkgs)
    else oldPkgs
    if (length(update)) {
        if (is.null(instlib))
            instlib <- update[, "LibPath"]
        libs <- unique(instlib)
        for (l in libs) install.packages(update[instlib == l,
            "Package"], l, contriburl = contriburl, method = method,
            available = available, ..., type = type)
    }
}

# Example:
# old.packages()
# update.packages.2(subset = "MASS")








----------------Contact
Details:-------------------------------------------------------
Contact me: Tal.Galili at gmail.com |  972-52-7275845
Read me: www.talgalili.com (Hebrew) | www.biostatistics.co.il (Hebrew) |
www.r-statistics.com (English)
----------------------------------------------------------------------------------------------

From ripley at stats.ox.ac.uk  Mon Apr 18 09:42:17 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 18 Apr 2011 08:42:17 +0100 (BST)
Subject: [Rd] R script in batch mode
In-Reply-To: <1303093777169-3456471.post@n4.nabble.com>
References: <1303093777169-3456471.post@n4.nabble.com>
Message-ID: <alpine.LFD.2.02.1104180840000.5848@gannet.stats.ox.ac.uk>

On Sun, 17 Apr 2011, jusce wrote:

> Hello All!
>
> I'm a new R user, with no much experience.
> I have a R script (downloaded from internet) which has user interaction
> using "readline()" function.
> So as I have to run it repeatdly (with some different options) I was
> planning to do it on a BATCH mode.
>
> Is there any way to answer the "readline()" questions from a batch file?

No.  Please do read its help before posting (as the posting guide 
asked you to).

      In non-interactive use the result is as if the response was RETURN
      and the value is ?""?.

library(fortunes); fortune('WTFM') applies (and I have no idea why you 
asked this R-help question on R-devel).

>
> How do I do that?
>
> I'm using R under Linux.

Which is not the 'at a minimum' information the posting guide asked 
you for.

> Thanks,
> Jose
>
> --
> View this message in context: http://r.789695.n4.nabble.com/R-script-in-batch-mode-tp3456471p3456471.html
> Sent from the R devel mailing list archive at Nabble.com.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From allane at cybaea.com  Mon Apr 18 10:36:10 2011
From: allane at cybaea.com (Allan Engelhardt)
Date: Mon, 18 Apr 2011 09:36:10 +0100
Subject: [Rd] sessionInfo() and byte compiler
Message-ID: <4DABF7FA.1030006@cybaea.com>

For troubleshooting purposes, should utils::sessionInfo() show if the 
attached packages (especially base packages) are byte compiled (with 
make bytecode and/or R_COMPILE_PKGS set and not zero)?

Allan


From luke-tierney at uiowa.edu  Mon Apr 18 16:41:58 2011
From: luke-tierney at uiowa.edu (luke-tierney at uiowa.edu)
Date: Mon, 18 Apr 2011 09:41:58 -0500
Subject: [Rd] Tail Call Elimination?
In-Reply-To: <BANLkTim3Y+zfNBBjGTXE4PijRqv41Cs-nw@mail.gmail.com>
References: <BANLkTim3Y+zfNBBjGTXE4PijRqv41Cs-nw@mail.gmail.com>
Message-ID: <alpine.DEB.2.00.1104180941470.1955@luke-inspiron>

The premise of your post is false: contrary to popular belief, R's
looping constructs are not particularly inefficient. Slowness of loops
relative to vectorized code comes from the cost of interpreting the
body of the loop.  That exact same interpreter would be used to
interpret the bodies of functions used to express loops using
recursion, so it is not reasonable to expect this to improve
performance. In fact, due to the inefficiency of the current function
call mechanism in R, quite the opposite is true.

As to the question: tail call optimization cannot be applied in R, at
least not in a simple way, because the semantics of R provide access
to the call stack via the sys.xyz functions and parent.frame and such.
It might be possible to make some semantic changes, such as only
guaranteeing access to the immediate caller, but there isn't much
point unless/until the performance of the function calling mechanism is
improved.

Best,

luke

On Sun, 17 Apr 2011, Mohit Dayal wrote:

> Dear R-programmers,
>
> I am trying to program a Newton-Raphson in R (yes, i will try GSL, not right
> now), and it would be a real boon if R had tail call elimination, so that a
> recursive program has a guarantee not to fail due to stack overflows, given
> how slow loops in R are. I did look at the documentation, but could not find
> a reason for it.
>
> Regards,
> Mohit Dayal
> Researcher
> Applied Statistics & Computing Lab
> ISB
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Luke Tierney
Statistics and Actuarial Science
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From djsamperi at gmail.com  Mon Apr 18 17:41:30 2011
From: djsamperi at gmail.com (Dominick Samperi)
Date: Mon, 18 Apr 2011 11:41:30 -0400
Subject: [Rd] Tail Call Elimination?
In-Reply-To: <alpine.DEB.2.00.1104180941470.1955@luke-inspiron>
References: <BANLkTim3Y+zfNBBjGTXE4PijRqv41Cs-nw@mail.gmail.com>
	<alpine.DEB.2.00.1104180941470.1955@luke-inspiron>
Message-ID: <BANLkTinPucAOmqLBtZtLQ+YzQ7VsYmUT9A@mail.gmail.com>

On Mon, Apr 18, 2011 at 10:41 AM,  <luke-tierney at uiowa.edu> wrote:
> The premise of your post is false: contrary to popular belief, R's
> looping constructs are not particularly inefficient. Slowness of loops
> relative to vectorized code comes from the cost of interpreting the
> body of the loop. ?That exact same interpreter would be used to
> interpret the bodies of functions used to express loops using
> recursion, so it is not reasonable to expect this to improve
> performance. In fact, due to the inefficiency of the current function
> call mechanism in R, quite the opposite is true.
>
> As to the question: tail call optimization cannot be applied in R, at
> least not in a simple way, because the semantics of R provide access
> to the call stack via the sys.xyz functions and parent.frame and such.
> It might be possible to make some semantic changes, such as only
> guaranteeing access to the immediate caller, but there isn't much
> point unless/until the performance of the function calling mechanism is
> improved.
>
> Best,
>
> luke

To what extent does the recently introduced byte-code compilation
help here?

> On Sun, 17 Apr 2011, Mohit Dayal wrote:
>
>> Dear R-programmers,
>>
>> I am trying to program a Newton-Raphson in R (yes, i will try GSL, not
>> right
>> now), and it would be a real boon if R had tail call elimination, so that
>> a
>> recursive program has a guarantee not to fail due to stack overflows,
>> given
>> how slow loops in R are. I did look at the documentation, but could not
>> find
>> a reason for it.
>>
>> Regards,
>> Mohit Dayal
>> Researcher
>> Applied Statistics & Computing Lab
>> ISB
>>
>> ? ? ? ?[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
> --
> Luke Tierney
> Statistics and Actuarial Science
> Ralph E. Wareham Professor of Mathematical Sciences
> University of Iowa ? ? ? ? ? ? ? ? ?Phone: ? ? ? ? ? ? 319-335-3386
> Department of Statistics and ? ? ? ?Fax: ? ? ? ? ? ? ? 319-335-3017
> ? Actuarial Science
> 241 Schaeffer Hall ? ? ? ? ? ? ? ? ?email: ? ? ?luke at stat.uiowa.edu
> Iowa City, IA 52242 ? ? ? ? ? ? ? ? WWW: ?http://www.stat.uiowa.edu
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From kcrisman at gmail.com  Mon Apr 18 17:48:40 2011
From: kcrisman at gmail.com (Karl-Dieter Crisman)
Date: Mon, 18 Apr 2011 11:48:40 -0400
Subject: [Rd] How to get R to compile with PNG support
Message-ID: <BANLkTinQz7eOE7b-GpBRcNRhcY0-bdc4Eg@mail.gmail.com>

Dear R devel list,

Good morning; I'm with the Sage (http://www.sagemath.org) project.
(Some of you might have seen my talk on this at last summer's useR
conference).

We have some rudimentary support for using R graphics in various
cases, which has proved useful to many of our users who want to go
back and forth between R and other capabilities within Sage.
Unfortunately, the way we originally implemented this was using the
png and plot functions in R itself, which perhaps isn't the best
(i.e., everyone uses ggplot now? but I digress).

That means that when people download a binary of ours, or compile
their own, whether R's plot and png functions work depends heavily on
the rather obscure (to users) issue of exactly what headers are
present on the compiling machine.

Unfortunately, it is *very* unclear what actually needs to be present!
 There are innumerable places where this has come up for us, but
http://trac.sagemath.org/sage_trac/ticket/8868 and
http://ask.sagemath.org/question/192/compiling-r-with-png-support are
two of the current places where people have compiled information.

The FAQ says, "Unless you do not want to view graphs on-screen you
need ?X11? installed, including its headers and client libraries. For
recent Fedora distributions it means (at least) ?libX11?,
?libX11-devel?, ?libXt? and ?libXt-devel?. On Debian we recommend the
meta-package ?xorg-dev?. If you really do not want these you will need
to explicitly configure R without X11, using --with-x=no."

Well, we don't actually need to view graphs on-screen, but we do need
to be able to generate them and save them (as pngs, for instance) to
the correct directory in Sage for viewing.  But we have people who've
tried to do this in Ubuntu, with libpng and xorg-dev installed, and
the file /usr/include/X11/Xwindows.h exists, but all to no avail.
There are almost as many solutions people have found as there are
computers out there, it seems - slight hyperbole, but that's what it
feels like.

We've posted more than once (I think) to the r-help list, but have
gotten no useful feedback.  Is there *anywhere* that the *exact*
requirements R has for having

capabilities("png")
  png
FALSE

come out TRUE are documented?

Then, not only could we be smarter in how we compile R (currently
somewhat naively searching for /usr/include/X11/Xwindows.h to
determine whether we'll try for png support), but we would be able to
tell users something very precise to do (e.g., apt-get foo) if they
currently have R without PNG support in Sage.  Again, I emphasize that
apparently getting xorg-dev doesn't always do the trick.

We do realize that for most people wanting to use just R, it's best to
download a binary, which will behave nicely; Sage's "batteries
included" philosophy means that we are asking for more specialized
info from upstream, and for that I apologize in advance.  I also
apologize if I said something silly above, because I don't actually
know what all these files are - I've just looked into enough support
requests to have a decent idea of what's required.    We are trying
not to have to parse the makefile to figure all this out, and possibly
making some mistake there as well.

Thank you SO much for any help with this,
Karl-Dieter Crisman
for the Sage team


From salmajj at softhome.net  Mon Apr 18 18:12:41 2011
From: salmajj at softhome.net (salmajj)
Date: Mon, 18 Apr 2011 09:12:41 -0700 (PDT)
Subject: [Rd] Dangerous Bug with IF function of R
Message-ID: <1303143161471-3457976.post@n4.nabble.com>

hi!
there is a bug with the IF operator that is really dangerous!
please try the code below and if someone could explain to me why when (q is
equal to 0.8, 0.9 or 1) R do not print it?

q=0
for (j in 1:11){

if ((q==1)){
print(q)
	}			
q=q+0.1
}

so in this code q is incremented from 0 to 1.1. but R do not capture print
the value 1, 0.8 and 0.9 !! try to change (q==0.4) it gonna print 0.4. but
if you put q==0.8 or 0.9 or 1 it doesn't work!!!
please try it it is amazing!!!

--
View this message in context: http://r.789695.n4.nabble.com/Dangerous-Bug-with-IF-function-of-R-tp3457976p3457976.html
Sent from the R devel mailing list archive at Nabble.com.


From diggsb at ohsu.edu  Mon Apr 18 18:36:38 2011
From: diggsb at ohsu.edu (Brian Diggs)
Date: Mon, 18 Apr 2011 09:36:38 -0700
Subject: [Rd] Dangerous Bug with IF function of R
In-Reply-To: <1303143161471-3457976.post@n4.nabble.com>
References: <1303143161471-3457976.post@n4.nabble.com>
Message-ID: <4DAC6896.4050103@ohsu.edu>

On 4/18/2011 9:12 AM, salmajj wrote:
> hi!
> there is a bug with the IF operator that is really dangerous!
> please try the code below and if someone could explain to me why when (q is
> equal to 0.8, 0.9 or 1) R do not print it?
>
> q=0
> for (j in 1:11){
>
> if ((q==1)){
> print(q)
> 	}			
> q=q+0.1
> }
>
> so in this code q is incremented from 0 to 1.1. but R do not capture print
> the value 1, 0.8 and 0.9 !! try to change (q==0.4) it gonna print 0.4. but
> if you put q==0.8 or 0.9 or 1 it doesn't work!!!
> please try it it is amazing!!!

It is not a bug.  It a misunderstanding on your part of the limits of 
floating point arithmetic.  See FAQ 7.31 (and multiple previous 
discussions on this and the r-help list).

http://cran.r-project.org/doc/FAQ/R-FAQ.html#Why-doesn_0027t-R-think-these-numbers-are-equal_003f

> --
> View this message in context: http://r.789695.n4.nabble.com/Dangerous-Bug-with-IF-function-of-R-tp3457976p3457976.html
> Sent from the R devel mailing list archive at Nabble.com.
>


-- 
Brian S. Diggs, PhD
Senior Research Associate, Department of Surgery
Oregon Health & Science University


From shawna.job at state.or.us  Mon Apr 18 18:53:08 2011
From: shawna.job at state.or.us (Shawna JOB)
Date: Mon, 18 Apr 2011 09:53:08 -0700
Subject: [Rd]  R fails on Windows 2008 Server
In-Reply-To: <13B22E72-633B-452F-8F9C-1BB16A444EEB@r-project.org>
References: <20110415130021.BLM73721@gimr.garvan.unsw.edu.au>
	<13B22E72-633B-452F-8F9C-1BB16A444EEB@r-project.org>
Message-ID: <4DAC0A03.B534.0047.0@DHS.STATE.OR.US>

Does anyone have any pointers on troubleshooting an R installation on a Windows 2008 server?  I had it running on a Windows 2003 server after many permissions updates to the server, but I'm stumped on getting it to run on 2008.

--The error I'm getting when I run the StatConnector Test is:
Loading StatConnector Server... Done
Initializing R...Function call failed
  Code: -2147221485
  Text: installation problem: unable to load connector
Releasing StatConnector Server...Done

--With a popup that just says:   "Method '~' of object '~' failed"

--I've run through all the documented troubleshooting I can find - no change.   I've verified the %R_HOME%, registry key corresponding to your R installation, and %PATH% mentioned in the documentation already.
--I've also tried reinstalling from scratch twice just in case.


Any suggestions would be appreciated


Shawna Job
Sr. Systems Analyst
PSOB Desk: 971-673-0128
OIS/AMS


From savicky at cs.cas.cz  Mon Apr 18 19:25:36 2011
From: savicky at cs.cas.cz (Petr Savicky)
Date: Mon, 18 Apr 2011 19:25:36 +0200
Subject: [Rd] Dangerous Bug with IF function of R
In-Reply-To: <1303143161471-3457976.post@n4.nabble.com>
References: <1303143161471-3457976.post@n4.nabble.com>
Message-ID: <20110418172536.GB11313@cs.cas.cz>

On Mon, Apr 18, 2011 at 09:12:41AM -0700, salmajj wrote:
> hi!
> there is a bug with the IF operator that is really dangerous!
> please try the code below and if someone could explain to me why when (q is
> equal to 0.8, 0.9 or 1) R do not print it?
> 
> q=0
> for (j in 1:11){
> 
> if ((q==1)){
> print(q)
> 	}			
> q=q+0.1
> }
> 
> so in this code q is incremented from 0 to 1.1. but R do not capture print
> the value 1, 0.8 and 0.9 !! try to change (q==0.4) it gonna print 0.4. but
> if you put q==0.8 or 0.9 or 1 it doesn't work!!!
> please try it it is amazing!!!

Incrementing a number by 0.1 produces numbers, which are not exactly
representable in binary, so this operation involves a rounding error.
Try the following

  q=0
  for (j in 1:11){
    if ((q==1)){
       print(q)
    }                             
    q=round(q+0.1, digits=7)
  }

Petr Savicky.


From salmajj at softhome.net  Mon Apr 18 20:11:28 2011
From: salmajj at softhome.net (salmajj)
Date: Mon, 18 Apr 2011 11:11:28 -0700 (PDT)
Subject: [Rd] Dangerous Bug with IF function of R
In-Reply-To: <20110418172536.GB11313@cs.cas.cz>
References: <1303143161471-3457976.post@n4.nabble.com>
	<20110418172536.GB11313@cs.cas.cz>
Message-ID: <1303150288440-3458300.post@n4.nabble.com>

Thanks a lot Petr it works!!!
You know for someone who is used to work with matlab it is not so obvious:)

--
View this message in context: http://r.789695.n4.nabble.com/Dangerous-Bug-with-IF-function-of-R-tp3457976p3458300.html
Sent from the R devel mailing list archive at Nabble.com.


From ripley at stats.ox.ac.uk  Mon Apr 18 20:24:04 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 18 Apr 2011 19:24:04 +0100 (BST)
Subject: [Rd] Statonnector fails (was Re: R fails on Windows 2008 Server)
In-Reply-To: <4DAC0A03.B534.0047.0@DHS.STATE.OR.US>
References: <20110415130021.BLM73721@gimr.garvan.unsw.edu.au>
	<13B22E72-633B-452F-8F9C-1BB16A444EEB@r-project.org>
	<4DAC0A03.B534.0047.0@DHS.STATE.OR.US>
Message-ID: <alpine.LFD.2.02.1104181921160.8482@gannet.stats.ox.ac.uk>

This isn't 'R fails', it is 'StatConnector' fails.  That project is 
nothing to do with this list, so please don't ask here for free 
consultancy on it (and fail to give any of the information asked for 
in our posting guide).

On Mon, 18 Apr 2011, Shawna JOB wrote:

> Does anyone have any pointers on troubleshooting an R installation on a Windows 2008 server?  I had it running on a Windows 2003 server after many permissions updates to the server, but I'm stumped on getting it to run on 2008.
>
> --The error I'm getting when I run the StatConnector Test is:
> Loading StatConnector Server... Done
> Initializing R...Function call failed
>  Code: -2147221485
>  Text: installation problem: unable to load connector
> Releasing StatConnector Server...Done
>
> --With a popup that just says:   "Method '~' of object '~' failed"
>
> --I've run through all the documented troubleshooting I can find - no change.   I've verified the %R_HOME%, registry key corresponding to your R installation, and %PATH% mentioned in the documentation already.
> --I've also tried reinstalling from scratch twice just in case.
>
>
> Any suggestions would be appreciated
>
>
> Shawna Job
> Sr. Systems Analyst
> PSOB Desk: 971-673-0128
> OIS/AMS
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From Greg.Snow at imail.org  Mon Apr 18 22:01:25 2011
From: Greg.Snow at imail.org (Greg Snow)
Date: Mon, 18 Apr 2011 14:01:25 -0600
Subject: [Rd] Use keep.source for function in package with lazy loading
In-Reply-To: <alpine.LFD.2.02.1104101151210.13800@gannet.stats.ox.ac.uk>
References: <B37C0A15B8FB3C468B5BC7EBC7DA14CC63457AC07C@LP-EXMBVS10.CO.IHC.COM>
	<alpine.LFD.2.02.1104042214300.1530@gannet.stats.ox.ac.uk>
	<B37C0A15B8FB3C468B5BC7EBC7DA14CC63457AC389@LP-EXMBVS10.CO.IHC.COM>
	<alpine.LFD.2.02.1104101151210.13800@gannet.stats.ox.ac.uk>
Message-ID: <B37C0A15B8FB3C468B5BC7EBC7DA14CC634592EEDE@LP-EXMBVS10.CO.IHC.COM>

Thanks, that looks great.  

Looking for other options I found a way to do something I had not originally considered, but like even better now.  My original purpose on this was a string with some tabs in it that when the function was viewed without the source were turned into "\t" which looked ugly and partly countered what I was trying to do.

My current attempt can be seen by looking at the 'petals' function in the development version of the TeachingDemos package on R-Forge.  It works great on windows, now I just need to find some people to test it on Mac and Linux to make sure that everything is doing what it should there.

-- 
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at imail.org
801.408.8111


> -----Original Message-----
> From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk]
> Sent: Sunday, April 10, 2011 4:52 AM
> To: Greg Snow
> Cc: R-devel at r-project.org
> Subject: RE: [Rd] Use keep.source for function in package with lazy
> loading
> 
> R-devel now has a KeepSource DESCRIPTION field to accomplish what I
> think you are seeking.
> 
> On Tue, 5 Apr 2011, Greg Snow wrote:
> 
> > Prof. Ripley,
> >
> > Thanks for the explanation.  I had set both keep.source and
> keep.source.packages to TRUE for my experiments, but had not realized
> that a new R process would be involved, so did not try the
> environmental variable approach.
> >
> >> From what you say below, I don't think I am going to accomplish what
> I wanted, since I want the source to show for users other than myself
> and there does not seem to be a reasonable way to change the users
> environment before installing my package (that is getting a bit too big
> brother to even think about).  I was hoping that there might be some
> switch somewhere that I had missed that would say keep the source for
> this function even though the default is not to.  But, it does not look
> like there is anything like that, and it is not worth implementing just
> for my one little use.
> >
> > Hmm, maybe I can set the source manually using .onAttach, I'll have
> to experiment some more.
> >
> > Thanks,
> >
> > --
> > Gregory (Greg) L. Snow Ph.D.
> > Statistical Data Center
> > Intermountain Healthcare
> > greg.snow at imail.org
> > 801.408.8111
> >
> >
> >> -----Original Message-----
> >> From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk]
> >> Sent: Monday, April 04, 2011 3:41 PM
> >> To: Greg Snow
> >> Cc: R-devel at r-project.org
> >> Subject: Re: [Rd] Use keep.source for function in package with lazy
> >> loading
> >>
> >> On Mon, 4 Apr 2011, Greg Snow wrote:
> >>
> >>> I have a function in one of my packages that I would like to print
> >>> using the original source rather than the deparse of the function.
> >>> The package uses lazy loading and the help page for library (under
> >>> keep.source) says that keep.source does not apply to packages that
> >>> use lazy loading and that whether those functions keep the source
> >>> depends on when they are installed.
> >>
> >> Not quite: it is says it is 'determined when it is installed'.
> >>
> >> For a package that does not use lazy loading, what is installed is a
> >> file of R code.  When library() loads such a package, it sources()
> the
> >> R code, and at that point has the option to keep the source or not
> >> (for that R session).
> >>
> >> For a package which uses lazy loading, the source()ing happens when
> >> the package is installed: the objects created are then dumped into a
> >> database.  Whether the source attribute is retained at that point
> >> depends on the setting of the option "keep.source.pkgs". So if you
> can
> >> arrange to install the package with that option set to true, in
> >> principle (and in my experiments) the source attributes are
> retained.
> >>
> >> The easiest way to do this would seem to be to set the environment
> >> variable R_KEEP_PKG_SOURCE to "yes" whilst installing the package.
> >>
> >>> This package is on R-forge and is being built there (and will
> >>> eventually be used to submit the next version of the package to
> >>> CRAN).
> >>>
> >>> I am not sure what the help means by 'installed', I have set the
> >>> options to keep the source to TRUE before calling install.package,
> >>> but that does not seem to work.
> >>
> >> I presume you mean keep.source.pkgs, not keep.source?  That needs to
> >> be set in the process which is installing the package:
> >> install.packages() calls R CMD INSTALL in a separate process.
> >>
> >>> Is there a way to "strongly encourage" the source to be kept for
> >>> this function (or the entire package)?
> >>>
> >>> Thanks,
> >>>
> >>> --
> >>> Gregory (Greg) L. Snow Ph.D.
> >>> Statistical Data Center
> >>> Intermountain Healthcare
> >>> greg.snow at imail.org
> >>> 801.408.8111
> >>
> >> --
> >> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> >> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> >> University of Oxford,             Tel:  +44 1865 272861 (self)
> >> 1 South Parks Road,                     +44 1865 272866 (PA)
> >> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> >
> 
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From luke-tierney at uiowa.edu  Mon Apr 18 22:42:51 2011
From: luke-tierney at uiowa.edu (luke-tierney at uiowa.edu)
Date: Mon, 18 Apr 2011 15:42:51 -0500
Subject: [Rd] Tail Call Elimination?
In-Reply-To: <BANLkTinPucAOmqLBtZtLQ+YzQ7VsYmUT9A@mail.gmail.com>
References: <BANLkTim3Y+zfNBBjGTXE4PijRqv41Cs-nw@mail.gmail.com>
	<alpine.DEB.2.00.1104180941470.1955@luke-inspiron>
	<BANLkTinPucAOmqLBtZtLQ+YzQ7VsYmUT9A@mail.gmail.com>
Message-ID: <alpine.DEB.2.00.1104181542170.1955@luke-inspiron>

On Mon, 18 Apr 2011, Dominick Samperi wrote:

> On Mon, Apr 18, 2011 at 10:41 AM,  <luke-tierney at uiowa.edu> wrote:
>> The premise of your post is false: contrary to popular belief, R's
>> looping constructs are not particularly inefficient. Slowness of loops
>> relative to vectorized code comes from the cost of interpreting the
>> body of the loop. ?That exact same interpreter would be used to
>> interpret the bodies of functions used to express loops using
>> recursion, so it is not reasonable to expect this to improve
>> performance. In fact, due to the inefficiency of the current function
>> call mechanism in R, quite the opposite is true.
>>
>> As to the question: tail call optimization cannot be applied in R, at
>> least not in a simple way, because the semantics of R provide access
>> to the call stack via the sys.xyz functions and parent.frame and such.
>> It might be possible to make some semantic changes, such as only
>> guaranteeing access to the immediate caller, but there isn't much
>> point unless/until the performance of the function calling mechanism is
>> improved.
>>
>> Best,
>>
>> luke
>
> To what extent does the recently introduced byte-code compilation
> help here?

It can help quite a bit if the loop body is such that its evaluation
is dominated by interpreter overhead.  If the body involves calls to
computationally expensive fucntons then compiling the loop itself may
not help very much, but compiling those functions might.

Best,

luke

>
>> On Sun, 17 Apr 2011, Mohit Dayal wrote:
>>
>>> Dear R-programmers,
>>>
>>> I am trying to program a Newton-Raphson in R (yes, i will try GSL, not
>>> right
>>> now), and it would be a real boon if R had tail call elimination, so that
>>> a
>>> recursive program has a guarantee not to fail due to stack overflows,
>>> given
>>> how slow loops in R are. I did look at the documentation, but could not
>>> find
>>> a reason for it.
>>>
>>> Regards,
>>> Mohit Dayal
>>> Researcher
>>> Applied Statistics & Computing Lab
>>> ISB
>>>
>>> ? ? ? ?[[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>
>> --
>> Luke Tierney
>> Statistics and Actuarial Science
>> Ralph E. Wareham Professor of Mathematical Sciences
>> University of Iowa ? ? ? ? ? ? ? ? ?Phone: ? ? ? ? ? ? 319-335-3386
>> Department of Statistics and ? ? ? ?Fax: ? ? ? ? ? ? ? 319-335-3017
>> ? Actuarial Science
>> 241 Schaeffer Hall ? ? ? ? ? ? ? ? ?email: ? ? ?luke at stat.uiowa.edu
>> Iowa City, IA 52242 ? ? ? ? ? ? ? ? WWW: ?http://www.stat.uiowa.edu
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>

-- 
Luke Tierney
Statistics and Actuarial Science
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu

From therneau at mayo.edu  Mon Apr 18 23:51:50 2011
From: therneau at mayo.edu (Terry Therneau)
Date: Mon, 18 Apr 2011 16:51:50 -0500
Subject: [Rd] help with eval()
Message-ID: <1303163510.29484.82.camel@nemo>

I've narrowed my scope problems with predict.coxph further.
Here is a condensed example:

fcall3 <- as.formula("time ~ age")
dfun3 <- function(dcall) {
    fit <- lm(dcall, data=lung, model=FALSE)
    model.frame(fit)
}
dfun3(fcall3)

The final call fails: it can't find 'dcall'.

The relevant code in model.frame.lm is:
       env <- environment(formula$terms)
       if (is.null(env)) 
            env <- parent.frame()        
	eval(fcall, env, parent.frame())

If the environment of the formula is .Globalenv, as it is here, the
contents of parent.frame() are ignored.  Adding a
           print(ls(parent.frame())) 
statement just above the  final call shows that it isn't a scope issue:
the variables we want are there.

  I don't understand the logic behind looking for variables in the place
the formula was first typed (this is not a complaint).  The inability to
look elsewhere however has stymied my efforts to fix the scoping problem
in predict.coxph, unless I drop the env(formula) argument alltogether.
But I assume there must be good reasons for it's inclusion and am
reluctant to do so.

Terry Therneau

> sessionInfo()
R version 2.13.0 RC (2011-04-12 r55424)
Platform: x86_64-unknown-linux-gnu (64-bit)

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=C              
 [5] LC_MONETARY=C              LC_MESSAGES=en_US.UTF-8   
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                 
 [9] LC_ADDRESS=C               LC_TELEPHONE=C            
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods
base     

PS. This also fails
dfun3 <- function(dcall) {
    fit <- lm(dcall, data=lung)
    model.frame(fit, subset=1:10)
}
You just need to force model.frame.lm to recreate data.


From murdoch.duncan at gmail.com  Tue Apr 19 02:00:41 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 18 Apr 2011 20:00:41 -0400
Subject: [Rd] help with eval()
In-Reply-To: <1303163510.29484.82.camel@nemo>
References: <1303163510.29484.82.camel@nemo>
Message-ID: <4DACD0A9.6070904@gmail.com>

On 11-04-18 5:51 PM, Terry Therneau wrote:
> I've narrowed my scope problems with predict.coxph further.
> Here is a condensed example:
>
> fcall3<- as.formula("time ~ age")
> dfun3<- function(dcall) {
>      fit<- lm(dcall, data=lung, model=FALSE)
>      model.frame(fit)
> }
> dfun3(fcall3)
>
> The final call fails: it can't find 'dcall'.
>
> The relevant code in model.frame.lm is:
>         env<- environment(formula$terms)
>         if (is.null(env))
>              env<- parent.frame()
> 	eval(fcall, env, parent.frame())
>
> If the environment of the formula is .Globalenv, as it is here, the
> contents of parent.frame() are ignored.  Adding a
>             print(ls(parent.frame()))
> statement just above the  final call shows that it isn't a scope issue:
> the variables we want are there.
>
>    I don't understand the logic behind looking for variables in the place
> the formula was first typed (this is not a complaint).  The inability to
> look elsewhere however has stymied my efforts to fix the scoping problem
> in predict.coxph, unless I drop the env(formula) argument alltogether.
> But I assume there must be good reasons for it's inclusion and am
> reluctant to do so.


The reason is that when a formula is created, the variables in it are 
assumed to have meaning in that context.  Where you work with the 
formula after that should not be relevant:  that's why formulas carry 
environments with them.  When you create the formula before the 
variables, things go wrong.

There's probably a way to associate the lung dataframe with the formula, 
or create the formula in such a way that things work, but I can't spot it.

Duncan Murdoch

> Terry Therneau
>
>> sessionInfo()
> R version 2.13.0 RC (2011-04-12 r55424)
> Platform: x86_64-unknown-linux-gnu (64-bit)
>
> locale:
>   [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>   [3] LC_TIME=en_US.UTF-8        LC_COLLATE=C
>   [5] LC_MONETARY=C              LC_MESSAGES=en_US.UTF-8
>   [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>   [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods
> base
>
> PS. This also fails
> dfun3<- function(dcall) {
>      fit<- lm(dcall, data=lung)
>      model.frame(fit, subset=1:10)
> }
> You just need to force model.frame.lm to recreate data.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From ggrothendieck at gmail.com  Tue Apr 19 02:17:57 2011
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 18 Apr 2011 20:17:57 -0400
Subject: [Rd] help with eval()
In-Reply-To: <1303163510.29484.82.camel@nemo>
References: <1303163510.29484.82.camel@nemo>
Message-ID: <BANLkTi=WGsh=YdpW1rcCRY9p9oNs9s2M_Q@mail.gmail.com>

On Mon, Apr 18, 2011 at 5:51 PM, Terry Therneau <therneau at mayo.edu> wrote:
> I've narrowed my scope problems with predict.coxph further.
> Here is a condensed example:
>
> fcall3 <- as.formula("time ~ age")
> dfun3 <- function(dcall) {
> ? ?fit <- lm(dcall, data=lung, model=FALSE)
> ? ?model.frame(fit)
> }
> dfun3(fcall3)
>
> The final call fails: it can't find 'dcall'.
>
> The relevant code in model.frame.lm is:
> ? ? ? env <- environment(formula$terms)
> ? ? ? if (is.null(env))
> ? ? ? ? ? ?env <- parent.frame()
> ? ? ? ?eval(fcall, env, parent.frame())
>
> If the environment of the formula is .Globalenv, as it is here, the
> contents of parent.frame() are ignored. ?Adding a
> ? ? ? ? ? print(ls(parent.frame()))
> statement just above the ?final call shows that it isn't a scope issue:
> the variables we want are there.
>
> ?I don't understand the logic behind looking for variables in the place
> the formula was first typed (this is not a complaint). ?The inability to
> look elsewhere however has stymied my efforts to fix the scoping problem
> in predict.coxph, unless I drop the env(formula) argument alltogether.
> But I assume there must be good reasons for it's inclusion and am
> reluctant to do so.
>

Try using do.call.  Using the built in BOD to illustrate, we first try
the posted code to view the error:

> fcall3 <- as.formula("demand ~ Time")
> dfun3 <- function(dcall) {
+     fit <- lm(dcall, data=BOD, model=FALSE)
+     model.frame(fit)
+ }
> dfun3(fcall3)
Error in model.frame(formula = dcall, data = BOD, drop.unused.levels = TRUE) :
  object 'dcall' not found
>
> # now replace the lm call with a do.call("lm" ...)
> # so that dcall gets substituted before the call to lm:
>
> fcall3 <- as.formula("demand ~ Time")
> dfun3 <- function(dcall) {
+     fit <- do.call("lm", list(dcall, data = BOD, model = FALSE))
+     model.frame(fit)
+ }
> dfun3(fcall3)
  demand Time
1    8.3    1
2   10.3    2
3   19.0    3
4   16.0    4
5   15.6    5
6   19.8    7



-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From ripley at stats.ox.ac.uk  Tue Apr 19 07:16:24 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 19 Apr 2011 06:16:24 +0100 (BST)
Subject: [Rd] help with eval()
In-Reply-To: <4DACD0A9.6070904@gmail.com>
References: <1303163510.29484.82.camel@nemo> <4DACD0A9.6070904@gmail.com>
Message-ID: <alpine.LFD.2.02.1104190614140.25620@gannet.stats.ox.ac.uk>

On Mon, 18 Apr 2011, Duncan Murdoch wrote:

> On 11-04-18 5:51 PM, Terry Therneau wrote:
>> I've narrowed my scope problems with predict.coxph further.
>> Here is a condensed example:
>> 
>> fcall3<- as.formula("time ~ age")
>> dfun3<- function(dcall) {
>>      fit<- lm(dcall, data=lung, model=FALSE)
>>      model.frame(fit)
>> }
>> dfun3(fcall3)
>> 
>> The final call fails: it can't find 'dcall'.
>> 
>> The relevant code in model.frame.lm is:
>>         env<- environment(formula$terms)
>>         if (is.null(env))
>>              env<- parent.frame()
>> 	eval(fcall, env, parent.frame())
>> 
>> If the environment of the formula is .Globalenv, as it is here, the
>> contents of parent.frame() are ignored.  Adding a
>>             print(ls(parent.frame()))
>> statement just above the  final call shows that it isn't a scope issue:
>> the variables we want are there.
>>
>>    I don't understand the logic behind looking for variables in the place
>> the formula was first typed (this is not a complaint).  The inability to
>> look elsewhere however has stymied my efforts to fix the scoping problem
>> in predict.coxph, unless I drop the env(formula) argument alltogether.
>> But I assume there must be good reasons for it's inclusion and am
>> reluctant to do so.
>
>
> The reason is that when a formula is created, the variables in it are assumed 
> to have meaning in that context.  Where you work with the formula after that 
> should not be relevant:  that's why formulas carry environments with them. 
> When you create the formula before the variables, things go wrong.
>
> There's probably a way to associate the lung dataframe with the formula, or 
> create the formula in such a way that things work, but I can't spot it.

This is why model=FALSE is not the default.  It avoids trying to find 
the data at a later date (and even if you can solve the scoping 
issues, the data may have been changed).

>
> Duncan Murdoch
>
>> Terry Therneau
>> 
>>> sessionInfo()
>> R version 2.13.0 RC (2011-04-12 r55424)
>> Platform: x86_64-unknown-linux-gnu (64-bit)
>> 
>> locale:
>>   [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>>   [3] LC_TIME=en_US.UTF-8        LC_COLLATE=C
>>   [5] LC_MONETARY=C              LC_MESSAGES=en_US.UTF-8
>>   [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>>   [9] LC_ADDRESS=C               LC_TELEPHONE=C
>> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>> 
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods
>> base
>> 
>> PS. This also fails
>> dfun3<- function(dcall) {
>>      fit<- lm(dcall, data=lung)
>>      model.frame(fit, subset=1:10)
>> }
>> You just need to force model.frame.lm to recreate data.
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From pdalgd at gmail.com  Tue Apr 19 09:37:33 2011
From: pdalgd at gmail.com (peter dalgaard)
Date: Tue, 19 Apr 2011 09:37:33 +0200
Subject: [Rd] help with eval()
In-Reply-To: <alpine.LFD.2.02.1104190614140.25620@gannet.stats.ox.ac.uk>
References: <1303163510.29484.82.camel@nemo> <4DACD0A9.6070904@gmail.com>
	<alpine.LFD.2.02.1104190614140.25620@gannet.stats.ox.ac.uk>
Message-ID: <F82FF2CF-4A99-4986-ADBC-170209D94D3D@gmail.com>


On Apr 19, 2011, at 07:16 , Prof Brian Ripley wrote:

> On Mon, 18 Apr 2011, Duncan Murdoch wrote:
> 
>> On 11-04-18 5:51 PM, Terry Therneau wrote:
>>> I've narrowed my scope problems with predict.coxph further.
>>> Here is a condensed example:
>>> fcall3<- as.formula("time ~ age")
>>> dfun3<- function(dcall) {
>>>     fit<- lm(dcall, data=lung, model=FALSE)
>>>     model.frame(fit)
>>> }
>>> dfun3(fcall3)
>>> [.....]
>>>   I don't understand the logic behind looking for variables in the place
>>> the formula was first typed (this is not a complaint).  The inability to
>>> look elsewhere however has stymied my efforts to fix the scoping problem
>>> in predict.coxph, unless I drop the env(formula) argument alltogether.
>>> But I assume there must be good reasons for it's inclusion and am
>>> reluctant to do so.
>> 
>> 
>> The reason is that when a formula is created, the variables in it are assumed to have meaning in that context.  Where you work with the formula after that should not be relevant:  that's why formulas carry environments with them. When you create the formula before the variables, things go wrong.
>> 
>> There's probably a way to associate the lung dataframe with the formula, or create the formula in such a way that things work, but I can't spot it.
> 
> This is why model=FALSE is not the default.  It avoids trying to find the data at a later date (and even if you can solve the scoping issues, the data may have been changed).

Yes, but there are other cases where a reevaluation is triggered. The example I found earlier involved doing model.frame on a subset, in which case the length(nargs) clause in model.frame.lm gets chosen.

So something is not right: Either we should arrange that reevaluations are never necessary, or we there should be a mechanism to get them reevaluated in the same scope as the original call. 

An obvious way would be to add the evaluation environment as an attribute to the $call component, but what would the memory management and serialization consequences be?

One workaround is, as Gabor points out, effectively to substitute the value of the arguments to lm() at the point of the call, using do.call(lm, list(.....)) or some eval(substitute(.....)) construct to the same effect. However, the result of do.call() will look awkward in the cases where the $call gets deparsed, though. E.g. in Gabor's example, if we modify it to show the actual fit, we get the result below (I'm sure you can imagine what would happen if a data frame with more than 7 rows got used!). On the other hand, NOT substituting such arguments leaves the scoping issues.

Another possible workaround is to make sure that functions that call modelling code internally will do the evaluation in the frame of the caller (like the call to model.matrix inside lm does). However, that seems to defeat the purpose of adding environments to formulas in the first place.  

-pd

> dfun3 <- function(dcall) {
+      fit <- do.call("lm", list(dcall, data = BOD, model = FALSE))
+ print(model.frame(fit))
+ fit}
> dfun3(fcall3)
  demand Time
1    8.3    1
2   10.3    2
3   19.0    3
4   16.0    4
5   15.6    5
6   19.8    7

Call:
lm(formula = demand ~ Time, data = structure(list(Time = c(1, 
2, 3, 4, 5, 7), demand = c(8.3, 10.3, 19, 16, 15.6, 19.8)), .Names = c("Time", 
"demand"), row.names = c(NA, -6L), class = "data.frame", reference = "A1.4, p. 270"), 
    model = FALSE)

Coefficients:
(Intercept)         Time  
      8.521        1.721  

> 

 

-- 
Peter Dalgaard
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From maechler at stat.math.ethz.ch  Tue Apr 19 10:07:37 2011
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 19 Apr 2011 10:07:37 +0200
Subject: [Rd] Dangerous Bug with IF function of R
In-Reply-To: <1303150288440-3458300.post@n4.nabble.com>
References: <1303143161471-3457976.post@n4.nabble.com>
	<20110418172536.GB11313@cs.cas.cz>
	<1303150288440-3458300.post@n4.nabble.com>
Message-ID: <19885.17097.95228.926788@stat.math.ethz.ch>

>>>>> salmajj  <salmajj at softhome.net>
>>>>>     on Mon, 18 Apr 2011 11:11:28 -0700 (PDT) writes:

    > Thanks a lot Petr it works!!!  
of course ..

    > You know for someone who is used to work with matlab it is not so obvious:)

well, what do you mean with that?

I'm intrigued. After such a blatantly wrong claim about a bug in
R...  what exactly are you claiming about Matlab here?
That it implements (software) decimal arithmetic on top of the
cpu-internal binary arithmetic ?   probably rather not ...

So?


From ral64 at cam.ac.uk  Tue Apr 19 11:02:31 2011
From: ral64 at cam.ac.uk (Robert Lowe)
Date: Tue, 19 Apr 2011 10:02:31 +0100
Subject: [Rd] Dangerous Bug with IF function of R
In-Reply-To: <19885.17097.95228.926788@stat.math.ethz.ch>
References: <1303143161471-3457976.post@n4.nabble.com>
	<20110418172536.GB11313@cs.cas.cz>
	<1303150288440-3458300.post@n4.nabble.com>
	<19885.17097.95228.926788@stat.math.ethz.ch>
Message-ID: <C9F16187-169D-4771-B5C7-3FA9AD56848E@cam.ac.uk>


> 
> I'm intrigued. After such a blatantly wrong claim about a bug in
> R...  what exactly are you claiming about Matlab here?
> That it implements (software) decimal arithmetic on top of the
> cpu-internal binary arithmetic ?   probably rather not ...
> 

Just for confirmation the same thing doesn't work in MATLAB as one would expect.

i=0;
for j=1:11
i=i+0.1;
if i==1
i
end
end


From therneau at mayo.edu  Tue Apr 19 14:21:12 2011
From: therneau at mayo.edu (Terry Therneau)
Date: Tue, 19 Apr 2011 07:21:12 -0500
Subject: [Rd] R-devel Digest, Vol 98, Issue 19
In-Reply-To: <mailman.25.1303207206.22796.r-devel@r-project.org>
References: <mailman.25.1303207206.22796.r-devel@r-project.org>
Message-ID: <1303215672.10706.39.camel@nemo>

 The replies so far have helped me see the issues more clearly.
Further comments:

1. This issue started with a bug report from a user:

library(survival)
fform <- as.formula(Surv(time, status) ~ age)
myfun <- function(dform, ddata) {
   predict(coxph(dform, data=ddata), newdata=ddata)
   }

 Gabor's suggestion to change the call is a useful idea but not
completely relevant: I'm trying to make their code work.  
  If work-arounds are the solution, then adding model=TRUE to the coxph
call is sufficient.  (That is why the same code with lm() does work).

2. Duncan argues that one should not expect the construct to work.  I
respectfully disagree.  Returning to my simpler lm example, an
expression is present in a context where all the variables are known, it
is a surprise that it does not work.  Maybe not a surprise to the inner
circle of developers, but to most users.
  Looking at model.frame.lm, the final result is
	eval(fcall, environment of the formula, parent.frame())
The terms we need are in the parent frame, why does eval ignore the
third argument?  (I haven't looked at the R source to see if it is on
purpose).  Is there a way to persuade it to use that arg?

  A careful reading of ?model.frame backs up Duncan's argument: it is
documented not to work.  I still don't like it -- too much a reprise of
the old Unix argument "That's not a bug it's a feature".
(Minor note: The next to last sentence before Value has
   "containing the variables used in formula plus those specified ...
Unlike model.frame.default, it returns the "
  Is the ... a reminder to finish the sentence?  It doesn't quite parse
as is.)

3. Brian R notes that adding model=TRUE is safer.  Agreed.  The original
S version of lm etc did not, in order to keep objects smaller and the
survival code still contains that legacy --- how time changes our
perceptions of "big".  Should I take this as a formal suggestion to
change the default in coxph and survreg?  (If I further change the
default to y=FALSE it will break at least 1 package (survey), and I'd
guess several others.)

4. Peter D: thanks for agreeing that there is a problem.
 I spent a lot of time and energy fixing model frame evaluation issues
in Splus, only to be to told at the end that they didn't dare implement
it "because it might break something".  That made me turn my back on the
whole debate and I haven't participated or kept up with the discussion.
The heart of my fix then --and it did fix a lot of problems without
breaking anything I could find -- was that the data= argument should be
an additional place to look rather than an alternate one.


From dutangc at gmail.com  Tue Apr 19 16:03:06 2011
From: dutangc at gmail.com (Christophe Dutang)
Date: Tue, 19 Apr 2011 16:03:06 +0200
Subject: [Rd] An update of the Distribustions man page
Message-ID: <BANLkTi=YfjuY-AwnhrMXhsVtgAENz5Or9g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110419/83d665cc/attachment.pl>

From murdoch.duncan at gmail.com  Tue Apr 19 20:18:14 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 19 Apr 2011 14:18:14 -0400
Subject: [Rd] Sweave support added to rgl package
Message-ID: <4DADD1E6.5040905@gmail.com>

I have just committed some code to the rgl package on 
https://r-forge.r-project.org/projects/rgl/ to allow rgl images to be 
inserted into Sweave documents.  (This is not in the CRAN version yet.)  
It makes use of the custom graphics driver support added by Brian Ripley.

In R-devel (which will become R 2.14.0 next spring in New Zealand, next 
fall in most other places), usage is quite straightforward.  For
example, code like this in a Sweave document:

<<fig=true, grdevice=rgl.Sweave, pdf=false, stayopen=TRUE>>=
x <- rnorm(100); y <- rnorm(100); z <- rnorm(100)
plot3d(x, y, z)
@

will insert a .png snapshot of the figure.  Because that chunk has 
"stayopen=TRUE", it can be followed by another chunk to add
to the figure, e.g.

<<fig=true, grdevice=rgl.Sweave, pdf=false>>=
lines3d(x[1:10], y[1:10], z[1:10], col="red")
@

All of this is possible in R 2.13.0, but it takes more work:  see the 
?rgl.Sweave help page.

I will eventually add postscript and PDF output options as well, and 
perhaps some support for the LaTeX movie15 package, but those are not 
there yet.  Comments or bug reports are welcome.

Duncan Murdoch


From David.Epstein at warwick.ac.uk  Tue Apr 19 22:59:44 2011
From: David.Epstein at warwick.ac.uk (David.Epstein)
Date: Tue, 19 Apr 2011 13:59:44 -0700 (PDT)
Subject: [Rd] Sweave tokens not in column 1: enhancement request
Message-ID: <1303246784050-3461527.post@n4.nabble.com>

When I re-use a code chunk in Sweave, together with keep.source=TRUE, I would
like to follow usual programming conventions in which the amount of white
space on the left indicates logical structure. It seems that one can't do
this in Sweave, or am I wrong?

for (i in ind) {
    do such-and-such and then
    <<code chunk 20>>
    do something-else
}

Sweave will say that << is an error. Would it be difficult to change Sweave
so that formatting in the conventional way becomes possible? I'm thinking
both of the .Rnw file and of the final output in the .pdf or .ps file.

Thanks
David

--
View this message in context: http://r.789695.n4.nabble.com/Sweave-tokens-not-in-column-1-enhancement-request-tp3461527p3461527.html
Sent from the R devel mailing list archive at Nabble.com.


From bullard at stat.berkeley.edu  Wed Apr 20 00:10:00 2011
From: bullard at stat.berkeley.edu (James Bullard)
Date: Tue, 19 Apr 2011 15:10:00 -0700
Subject: [Rd] self-referential representations in S4
Message-ID: <0c6f04c806de1e12a3f782774fa9f286.squirrel@www.stat.berkeley.edu>


I'm trying to do the following:

> setClass("MyNode", representation(parent = "MyNode"))
[1] "MyNode"
Warning message:
undefined slot classes in definition of "MyNode": parent(class "MyNode")

I scanned the docs, but found nothing. The representation function has no
problem, it's the setClass function which gives the warning.

What I'm trying to understand is why have the warning - it seems to work
just fine when I instantiate the class. Can we add an argument to the
setClass to suppress the warning?

This question was asked previously, but not answered in any satisfactory way:

http://r.789695.n4.nabble.com/Linked-List-in-R-td3303021.html

thanks, jim




R version 2.12.2 Patched (2011-03-09 r54717)
Platform: x86_64-unknown-linux-gnu (64-bit)

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
 [5] LC_MONETARY=C              LC_MESSAGES=en_US.UTF-8
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
 [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] h5r_1.1

loaded via a namespace (and not attached):
[1] tools_2.12.2


From D.Strbenac at garvan.org.au  Wed Apr 20 02:00:14 2011
From: D.Strbenac at garvan.org.au (Dario Strbenac)
Date: Wed, 20 Apr 2011 10:00:14 +1000 (EST)
Subject: [Rd] Package Name Not Found Warning
Message-ID: <20110420100014.BLN40994@gimr.garvan.unsw.edu.au>

Hello,

I've got a DESCRIPTION file with a the first line:

Package: Repitools

But, when I run R CMD INSTALL Repitools I get:

* installing *source* package Repitools ...
** R
** data
** inst
** preparing package for lazy loading
Warning in FUN(X[[1L]], ...) :
  Created a package name, "2011-04-20 09:05:40", when none found
** help
*** installing help indices
** building package indices ...
** testing if installed package can be loaded

* DONE (Repitools)

It looks like it knows about the package name at the start and end of the process, but not in the middle of it.

Loading the packing in an R session and looking at the sessionInfo shows the package name was properly processed. Is this a spurious warning ?

I'm using:
R version 2.13.0 (2011-04-13)
Platform: x86_64-unknown-linux-gnu (64-bit) (actually Ubuntu 10.10)

--------------------------------------
Dario Strbenac
Research Assistant
Cancer Epigenetics
Garvan Institute of Medical Research
Darlinghurst NSW 2010
Australia


From mtmorgan at fhcrc.org  Wed Apr 20 04:23:20 2011
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Tue, 19 Apr 2011 19:23:20 -0700
Subject: [Rd] Package Name Not Found Warning
In-Reply-To: <20110420100014.BLN40994@gimr.garvan.unsw.edu.au>
References: <20110420100014.BLN40994@gimr.garvan.unsw.edu.au>
Message-ID: <4DAE4398.4060805@fhcrc.org>

On 04/19/2011 05:00 PM, Dario Strbenac wrote:
> Hello,
>
> I've got a DESCRIPTION file with a the first line:
>
> Package: Repitools
>
> But, when I run R CMD INSTALL Repitools I get:
>
> * installing *source* package Repitools ...
> ** R
> ** data
> ** inst
> ** preparing package for lazy loading
> Warning in FUN(X[[1L]], ...) :
>    Created a package name, "2011-04-20 09:05:40", when none found

For what it's worth, this comes up when a class is being created in an 
environment that is not the global environment or does not have a 
variable .packageName, apparently added early in the name space creation 
process. You can mimic this with

   setClass("A", where=new.env())

or

   local({ setClass("A", where=environment()) })

Kind of doubt whether you've actually done something like that in your 
package, but maybe it twigs something...

Also, if you add

   trace(methods::getPacakgeName, quote(print(where)))

or

   trace(warning, quote(print(sys.calls())))

somewhere early in your package (the top of the first file to be 
collated) you'll get messages that might point to where things are going 
wrong.

Hope that helps,

Martin

> ** help
> *** installing help indices
> ** building package indices ...
> ** testing if installed package can be loaded
>
> * DONE (Repitools)
>
> It looks like it knows about the package name at the start and end of the process, but not in the middle of it.
>
> Loading the packing in an R session and looking at the sessionInfo shows the package name was properly processed. Is this a spurious warning ?
>
> I'm using:
> R version 2.13.0 (2011-04-13)
> Platform: x86_64-unknown-linux-gnu (64-bit) (actually Ubuntu 10.10)
>
> --------------------------------------
> Dario Strbenac
> Research Assistant
> Cancer Epigenetics
> Garvan Institute of Medical Research
> Darlinghurst NSW 2010
> Australia
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
Computational Biology
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N. PO Box 19024 Seattle, WA 98109

Location: M1-B861
Telephone: 206 667-2793


From D.Strbenac at garvan.org.au  Wed Apr 20 05:00:38 2011
From: D.Strbenac at garvan.org.au (Dario Strbenac)
Date: Wed, 20 Apr 2011 13:00:38 +1000 (EST)
Subject: [Rd] Package Name Not Found Warning
In-Reply-To: <4DAE4398.4060805@fhcrc.org>
References: <20110420100014.BLN40994@gimr.garvan.unsw.edu.au>
	<4DAE4398.4060805@fhcrc.org>
Message-ID: <20110420130038.BLN45351@gimr.garvan.unsw.edu.au>

Ah, I think it's happening because I have 

setOldClass(AffymetrixCelSet) in my package.

I guess I need to use there where argument. But how do I have this call outside any S4 functions, but without having to load aroma.affymetrix when my package loads ?

---- Original message ----
>Date: Tue, 19 Apr 2011 19:23:20 -0700
>From: Martin Morgan <mtmorgan at fhcrc.org>  
>Subject: Re: [Rd] Package Name Not Found Warning  
>To: D.Strbenac at garvan.org.au
>Cc: r-devel at r-project.org
>
>On 04/19/2011 05:00 PM, Dario Strbenac wrote:
>> Hello,
>>
>> I've got a DESCRIPTION file with a the first line:
>>
>> Package: Repitools
>>
>> But, when I run R CMD INSTALL Repitools I get:
>>
>> * installing *source* package Repitools ...
>> ** R
>> ** data
>> ** inst
>> ** preparing package for lazy loading
>> Warning in FUN(X[[1L]], ...) :
>>    Created a package name, "2011-04-20 09:05:40", when none found
>
>For what it's worth, this comes up when a class is being created in an 
>environment that is not the global environment or does not have a 
>variable .packageName, apparently added early in the name space creation 
>process. You can mimic this with
>
>   setClass("A", where=new.env())
>
>or
>
>   local({ setClass("A", where=environment()) })
>
>Kind of doubt whether you've actually done something like that in your 
>package, but maybe it twigs something...
>
>Also, if you add
>
>   trace(methods::getPacakgeName, quote(print(where)))
>
>or
>
>   trace(warning, quote(print(sys.calls())))
>
>somewhere early in your package (the top of the first file to be 
>collated) you'll get messages that might point to where things are going 
>wrong.
>
>Hope that helps,
>
>Martin
>
>> ** help
>> *** installing help indices
>> ** building package indices ...
>> ** testing if installed package can be loaded
>>
>> * DONE (Repitools)
>>
>> It looks like it knows about the package name at the start and end of the process, but not in the middle of it.
>>
>> Loading the packing in an R session and looking at the sessionInfo shows the package name was properly processed. Is this a spurious warning ?
>>
>> I'm using:
>> R version 2.13.0 (2011-04-13)
>> Platform: x86_64-unknown-linux-gnu (64-bit) (actually Ubuntu 10.10)
>>
>> --------------------------------------
>> Dario Strbenac
>> Research Assistant
>> Cancer Epigenetics
>> Garvan Institute of Medical Research
>> Darlinghurst NSW 2010
>> Australia
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>
>-- 
>Computational Biology
>Fred Hutchinson Cancer Research Center
>1100 Fairview Ave. N. PO Box 19024 Seattle, WA 98109
>
>Location: M1-B861
>Telephone: 206 667-2793


--------------------------------------
Dario Strbenac
Research Assistant
Cancer Epigenetics
Garvan Institute of Medical Research
Darlinghurst NSW 2010
Australia


From mtmorgan at fhcrc.org  Wed Apr 20 05:29:40 2011
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Tue, 19 Apr 2011 20:29:40 -0700
Subject: [Rd] Package Name Not Found Warning
In-Reply-To: <20110420130038.BLN45351@gimr.garvan.unsw.edu.au>
References: <20110420100014.BLN40994@gimr.garvan.unsw.edu.au>
	<4DAE4398.4060805@fhcrc.org>
	<20110420130038.BLN45351@gimr.garvan.unsw.edu.au>
Message-ID: <4DAE5324.1050805@fhcrc.org>

On 04/19/2011 08:00 PM, Dario Strbenac wrote:
> Ah, I think it's happening because I have
>
> setOldClass(AffymetrixCelSet) in my package.

if AffymetrixCelSet is from aroma.affymetrix, then the line above results in

 > setOldClass(AffymetrixCelSet)
Error in x[length(x):1L] : object of type 'closure' is not subsettable

maybe you meant

setOldClass("AffymetrixCelSet")

but if I put that in a package that either Depends: or not on 
aroma.affymetrix then I don't see the warning in your original report. 
I'm not sure you've diagnosed the problem correctly?

Martin

>
> I guess I need to use there where argument. But how do I have this call outside any S4 functions, but without having to load aroma.affymetrix when my package loads ?
>
> ---- Original message ----
>> Date: Tue, 19 Apr 2011 19:23:20 -0700
>> From: Martin Morgan<mtmorgan at fhcrc.org>
>> Subject: Re: [Rd] Package Name Not Found Warning
>> To: D.Strbenac at garvan.org.au
>> Cc: r-devel at r-project.org
>>
>> On 04/19/2011 05:00 PM, Dario Strbenac wrote:
>>> Hello,
>>>
>>> I've got a DESCRIPTION file with a the first line:
>>>
>>> Package: Repitools
>>>
>>> But, when I run R CMD INSTALL Repitools I get:
>>>
>>> * installing *source* package Repitools ...
>>> ** R
>>> ** data
>>> ** inst
>>> ** preparing package for lazy loading
>>> Warning in FUN(X[[1L]], ...) :
>>>     Created a package name, "2011-04-20 09:05:40", when none found
>>
>> For what it's worth, this comes up when a class is being created in an
>> environment that is not the global environment or does not have a
>> variable .packageName, apparently added early in the name space creation
>> process. You can mimic this with
>>
>>    setClass("A", where=new.env())
>>
>> or
>>
>>    local({ setClass("A", where=environment()) })
>>
>> Kind of doubt whether you've actually done something like that in your
>> package, but maybe it twigs something...
>>
>> Also, if you add
>>
>>    trace(methods::getPacakgeName, quote(print(where)))
>>
>> or
>>
>>    trace(warning, quote(print(sys.calls())))
>>
>> somewhere early in your package (the top of the first file to be
>> collated) you'll get messages that might point to where things are going
>> wrong.
>>
>> Hope that helps,
>>
>> Martin
>>
>>> ** help
>>> *** installing help indices
>>> ** building package indices ...
>>> ** testing if installed package can be loaded
>>>
>>> * DONE (Repitools)
>>>
>>> It looks like it knows about the package name at the start and end of the process, but not in the middle of it.
>>>
>>> Loading the packing in an R session and looking at the sessionInfo shows the package name was properly processed. Is this a spurious warning ?
>>>
>>> I'm using:
>>> R version 2.13.0 (2011-04-13)
>>> Platform: x86_64-unknown-linux-gnu (64-bit) (actually Ubuntu 10.10)
>>>
>>> --------------------------------------
>>> Dario Strbenac
>>> Research Assistant
>>> Cancer Epigenetics
>>> Garvan Institute of Medical Research
>>> Darlinghurst NSW 2010
>>> Australia
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>> --
>> Computational Biology
>> Fred Hutchinson Cancer Research Center
>> 1100 Fairview Ave. N. PO Box 19024 Seattle, WA 98109
>>
>> Location: M1-B861
>> Telephone: 206 667-2793
>
>
> --------------------------------------
> Dario Strbenac
> Research Assistant
> Cancer Epigenetics
> Garvan Institute of Medical Research
> Darlinghurst NSW 2010
> Australia


-- 
Computational Biology
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N. PO Box 19024 Seattle, WA 98109

Location: M1-B861
Telephone: 206 667-2793


From D.Strbenac at garvan.org.au  Wed Apr 20 06:15:09 2011
From: D.Strbenac at garvan.org.au (Dario Strbenac)
Date: Wed, 20 Apr 2011 14:15:09 +1000 (EST)
Subject: [Rd] Package Name Not Found Warning
Message-ID: <20110420141509.BLN46734@gimr.garvan.unsw.edu.au>

Ah yes, I found it now. I had the exact same setOldClass statement at the top of 2 different R files. Having it in the first collated one solves my problem.

---- Original message ----
>Date: Tue, 19 Apr 2011 20:29:40 -0700
>From: Martin Morgan <mtmorgan at fhcrc.org>  
>Subject: Re: [Rd] Package Name Not Found Warning  
>To: D.Strbenac at garvan.org.au
>Cc: r-devel at r-project.org
>
>On 04/19/2011 08:00 PM, Dario Strbenac wrote:
>> Ah, I think it's happening because I have
>>
>> setOldClass(AffymetrixCelSet) in my package.
>
>if AffymetrixCelSet is from aroma.affymetrix, then the line above results in
>
> > setOldClass(AffymetrixCelSet)
>Error in x[length(x):1L] : object of type 'closure' is not subsettable
>
>maybe you meant
>
>setOldClass("AffymetrixCelSet")
>
>but if I put that in a package that either Depends: or not on 
>aroma.affymetrix then I don't see the warning in your original report. 
>I'm not sure you've diagnosed the problem correctly?
>
>Martin
>
>>
>> I guess I need to use there where argument. But how do I have this call outside any S4 functions, but without having to load aroma.affymetrix when my package loads ?
>>
>> ---- Original message ----
>>> Date: Tue, 19 Apr 2011 19:23:20 -0700
>>> From: Martin Morgan<mtmorgan at fhcrc.org>
>>> Subject: Re: [Rd] Package Name Not Found Warning
>>> To: D.Strbenac at garvan.org.au
>>> Cc: r-devel at r-project.org
>>>
>>> On 04/19/2011 05:00 PM, Dario Strbenac wrote:
>>>> Hello,
>>>>
>>>> I've got a DESCRIPTION file with a the first line:
>>>>
>>>> Package: Repitools
>>>>
>>>> But, when I run R CMD INSTALL Repitools I get:
>>>>
>>>> * installing *source* package Repitools ...
>>>> ** R
>>>> ** data
>>>> ** inst
>>>> ** preparing package for lazy loading
>>>> Warning in FUN(X[[1L]], ...) :
>>>>     Created a package name, "2011-04-20 09:05:40", when none found
>>>
>>> For what it's worth, this comes up when a class is being created in an
>>> environment that is not the global environment or does not have a
>>> variable .packageName, apparently added early in the name space creation
>>> process. You can mimic this with
>>>
>>>    setClass("A", where=new.env())
>>>
>>> or
>>>
>>>    local({ setClass("A", where=environment()) })
>>>
>>> Kind of doubt whether you've actually done something like that in your
>>> package, but maybe it twigs something...
>>>
>>> Also, if you add
>>>
>>>    trace(methods::getPacakgeName, quote(print(where)))
>>>
>>> or
>>>
>>>    trace(warning, quote(print(sys.calls())))
>>>
>>> somewhere early in your package (the top of the first file to be
>>> collated) you'll get messages that might point to where things are going
>>> wrong.
>>>
>>> Hope that helps,
>>>
>>> Martin
>>>
>>>> ** help
>>>> *** installing help indices
>>>> ** building package indices ...
>>>> ** testing if installed package can be loaded
>>>>
>>>> * DONE (Repitools)
>>>>
>>>> It looks like it knows about the package name at the start and end of the process, but not in the middle of it.
>>>>
>>>> Loading the packing in an R session and looking at the sessionInfo shows the package name was properly processed. Is this a spurious warning ?
>>>>
>>>> I'm using:
>>>> R version 2.13.0 (2011-04-13)
>>>> Platform: x86_64-unknown-linux-gnu (64-bit) (actually Ubuntu 10.10)
>>>>
>>>> --------------------------------------
>>>> Dario Strbenac
>>>> Research Assistant
>>>> Cancer Epigenetics
>>>> Garvan Institute of Medical Research
>>>> Darlinghurst NSW 2010
>>>> Australia
>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>>
>>> --
>>> Computational Biology
>>> Fred Hutchinson Cancer Research Center
>>> 1100 Fairview Ave. N. PO Box 19024 Seattle, WA 98109
>>>
>>> Location: M1-B861
>>> Telephone: 206 667-2793
>>
>>
>> --------------------------------------
>> Dario Strbenac
>> Research Assistant
>> Cancer Epigenetics
>> Garvan Institute of Medical Research
>> Darlinghurst NSW 2010
>> Australia
>
>
>-- 
>Computational Biology
>Fred Hutchinson Cancer Research Center
>1100 Fairview Ave. N. PO Box 19024 Seattle, WA 98109
>
>Location: M1-B861
>Telephone: 206 667-2793


--------------------------------------
Dario Strbenac
Research Assistant
Cancer Epigenetics
Garvan Institute of Medical Research
Darlinghurst NSW 2010
Australia


From chuck at sharpsteen.net  Wed Apr 20 11:09:23 2011
From: chuck at sharpsteen.net (Sharpie)
Date: Wed, 20 Apr 2011 02:09:23 -0700 (PDT)
Subject: [Rd] How to get R to compile with PNG support
In-Reply-To: <BANLkTinQz7eOE7b-GpBRcNRhcY0-bdc4Eg@mail.gmail.com>
References: <BANLkTinQz7eOE7b-GpBRcNRhcY0-bdc4Eg@mail.gmail.com>
Message-ID: <1303290563237-3462502.post@n4.nabble.com>


Dear R devel list,

Good morning; I'm with the Sage (http://www.sagemath.org) project.
(Some of you might have seen my talk on this at last summer's useR
conference).

Thanks for stoping by Karl! I have to say that I am a big fan of the Sage
project---it is a very good idea and I really appreciate all the time you
guys put into it. I may not be able to answer all of your questions
concerning PNG support, but hopefully some of the following pointers will be
useful.



Karl-Dieter Crisman wrote:
> 
> We have some rudimentary support for using R graphics in various
> cases, which has proved useful to many of our users who want to go
> back and forth between R and other capabilities within Sage.
> Unfortunately, the way we originally implemented this was using the
> png and plot functions in R itself, which perhaps isn't the best
> (i.e., everyone uses ggplot now? but I digress).
> 

One important distinction to make is between R graphics functions such as
plot and ggplot, and R graphics *devices*, such as png. The devices provide
back ends that take the R-level function calls and actually execute the
low-level "draw line from a to b, clip to rectangle A, insert left-justified
text at x,y" primitives that get written to an output format.

Bottom line for Sage is that as long as you implement at least one device
function, such as png, your users should be able to call plot, ggplot, and
the rest of R's graphics functions to their heart's content, they just won't
have a wide selection of output formats.



Karl-Dieter Crisman wrote:
> 
> That means that when people download a binary of ours, or compile
> their own, whether R's plot and png functions work depends heavily on
> the rather obscure (to users) issue of exactly what headers are
> present on the compiling machine.
> 
> Unfortunately, it is *very* unclear what actually needs to be present!
>  There are innumerable places where this has come up for us, but
> http://trac.sagemath.org/sage_trac/ticket/8868 and
> http://ask.sagemath.org/question/192/compiling-r-with-png-support are
> two of the current places where people have compiled information.
> 
> The FAQ says, "Unless you do not want to view graphs on-screen you
> need ?X11? installed, including its headers and client libraries. For
> recent Fedora distributions it means (at least) ?libX11?,
> ?libX11-devel?, ?libXt? and ?libXt-devel?. On Debian we recommend the
> meta-package ?xorg-dev?. If you really do not want these you will need
> to explicitly configure R without X11, using --with-x=no."
> 
> Well, we don't actually need to view graphs on-screen, but we do need
> to be able to generate them and save them (as pngs, for instance) to
> the correct directory in Sage for viewing.  But we have people who've
> tried to do this in Ubuntu, with libpng and xorg-dev installed, and
> the file /usr/include/X11/Xwindows.h exists, but all to no avail.
> There are almost as many solutions people have found as there are
> computers out there, it seems - slight hyperbole, but that's what it
> feels like.
> 
> We've posted more than once (I think) to the r-help list, but have
> gotten no useful feedback.  Is there *anywhere* that the *exact*
> requirements R has for having
> 
> capabilities("png")
>   png
> FALSE
> 
> come out TRUE are documented?
> 
> Then, not only could we be smarter in how we compile R (currently
> somewhat naively searching for /usr/include/X11/Xwindows.h to
> determine whether we'll try for png support), but we would be able to
> tell users something very precise to do (e.g., apt-get foo) if they
> currently have R without PNG support in Sage.  Again, I emphasize that
> apparently getting xorg-dev doesn't always do the trick.
> 
> We do realize that for most people wanting to use just R, it's best to
> download a binary, which will behave nicely; Sage's "batteries
> included" philosophy means that we are asking for more specialized
> info from upstream, and for that I apologize in advance.  I also
> apologize if I said something silly above, because I don't actually
> know what all these files are - I've just looked into enough support
> requests to have a decent idea of what's required.    We are trying
> not to have to parse the makefile to figure all this out, and possibly
> making some mistake there as well.
> 
> Thank you SO much for any help with this,
> Karl-Dieter Crisman
> for the Sage team
> 


In the trac ticket you linked, the configure output shows PNG is enabled
(I.E. the library was found) but you may be ending up with no support for an
actual png() graphics device due to one of the following

  - configure didn't find Xlib as X11 is not listed under Interfaces
  - configure didn't find cairo as it is not listed under Additional
capabilities

So, although R has the PNG library that is only useful for writing PNG
files. R also needs the Xlib or Cairo libraries to provide drawing
primitives that will create the figures those files will contain.

In the ask.sagemath question the problem appears to be that the user had X11
installed but not libpng.

I hope this helps!

-Charlie

-----
Charlie Sharpsteen
Undergraduate-- Environmental Resources Engineering
Humboldt State University
--
View this message in context: http://r.789695.n4.nabble.com/How-to-get-R-to-compile-with-PNG-support-tp3457938p3462502.html
Sent from the R devel mailing list archive at Nabble.com.


From Friedrich.Leisch at boku.ac.at  Wed Apr 20 12:42:17 2011
From: Friedrich.Leisch at boku.ac.at (Friedrich Leisch)
Date: Wed, 20 Apr 2011 12:42:17 +0200
Subject: [Rd] Sweave tokens not in column 1: enhancement request
In-Reply-To: <1303246784050-3461527.post@n4.nabble.com>
References: <1303246784050-3461527.post@n4.nabble.com>
Message-ID: <19886.47241.204068.966260@ridcully.stat.uni-muenchen.de>

>>>>> On Tue, 19 Apr 2011 13:59:44 -0700 (PDT),
>>>>> David Epstein (DE) wrote:

  > When I re-use a code chunk in Sweave, together with keep.source=TRUE, I would
  > like to follow usual programming conventions in which the amount of white
  > space on the left indicates logical structure. It seems that one can't do
  > this in Sweave, or am I wrong?

  > for (i in ind) {
  >     do such-and-such and then
  >     <<code chunk 20>>
  >     do something-else
  > }

  > Sweave will say that << is an error. Would it be difficult to change Sweave
  > so that formatting in the conventional way becomes possible? I'm thinking
  > both of the .Rnw file and of the final output in the .pdf or .ps file.

Not difficult at all, that's a trivial change:

  MySyntax <- utils::SweaveSyntaxNoweb
  MySyntax$coderef <- "^[[:space:]]*<<(.*)>>.*"
  Sweave("test.Rnw", syntax=MySyntax)

should do what you want. That code references need to start in column 1
is inherited from noweb, not sure if we really need it. Cannot think
of a situation where the above regular expression appears in valid R
code, but perhaps I am overlooking something.

Best,
Fritz


From jmc at r-project.org  Wed Apr 20 18:37:46 2011
From: jmc at r-project.org (John Chambers)
Date: Wed, 20 Apr 2011 09:37:46 -0700
Subject: [Rd] self-referential representations in S4
In-Reply-To: <0c6f04c806de1e12a3f782774fa9f286.squirrel@www.stat.berkeley.edu>
References: <0c6f04c806de1e12a3f782774fa9f286.squirrel@www.stat.berkeley.edu>
Message-ID: <4DAF0BDA.5020203@r-project.org>

The warning is there because all is not "just fine", in general and in 
particular not in your example.

If a superclass is not virtual, the prototype object for the new class 
must have a member of that class in the appropriate slot.  How could it 
do so in this case?  As a result, your class will return an invalid 
object from a call to new().

So one might argue that the current rules are too lax, and this should 
be an error.

The fundamental point is that S4 classes, as opposed to the new 
reference classes, don't deal in "references", self- or other.

Ways to deal with such recursive structures are discussed in section 9.7 
of Software for Data Analysis.

One version of what you were perhaps trying to do might, for a binary 
tree, be:

 > setClassUnion("MyNode", c("NULL", "vector"))
[1] "MyNode"
 >
 > setClass("FullNode", representation(left = "MyNode", right ="MyNode",
+   parent = "MyNode"))
[1] "FullNode"
 > setIs("FullNode", "MyNode")

Nodes can be full, a vector as a leaf, or empty.

John

On 4/19/11 3:10 PM, James Bullard wrote:
>
> I'm trying to do the following:
>
>> setClass("MyNode", representation(parent = "MyNode"))
> [1] "MyNode"
> Warning message:
> undefined slot classes in definition of "MyNode": parent(class "MyNode")
>
> I scanned the docs, but found nothing. The representation function has no
> problem, it's the setClass function which gives the warning.
>
> What I'm trying to understand is why have the warning - it seems to work
> just fine when I instantiate the class. Can we add an argument to the
> setClass to suppress the warning?
>
> This question was asked previously, but not answered in any satisfactory way:
>
> http://r.789695.n4.nabble.com/Linked-List-in-R-td3303021.html
>
> thanks, jim
>
>
>
>
> R version 2.12.2 Patched (2011-03-09 r54717)
> Platform: x86_64-unknown-linux-gnu (64-bit)
>
> locale:
>   [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>   [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>   [5] LC_MONETARY=C              LC_MESSAGES=en_US.UTF-8
>   [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>   [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] h5r_1.1
>
> loaded via a namespace (and not attached):
> [1] tools_2.12.2
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From mtmorgan at fhcrc.org  Wed Apr 20 18:56:03 2011
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Wed, 20 Apr 2011 09:56:03 -0700
Subject: [Rd] Make as.factor an S3 generic?
Message-ID: <4DAF1023.4040002@fhcrc.org>

as.factor / as.ordered is not written as a generic. This differs from 
as.numeric, as.matrix, and other as.*. The following seems to address 
this and does not break make check-all.

FWIW, the patch is against r55563, because with r55564 I see

/home/mtmorgan/src/R-devel/src/main/dounzip.c:75:15: error: storage size 
of ?dt? isn?t known
/home/mtmorgan/src/R-devel/src/main/dounzip.c:88:5: warning: implicit 
declaration of function ?mktime?
make[3]: *** [dounzip.o] Error 1
make[3]: *** Waiting for unfinished jobs....
make[3]: Leaving directory `/home/mtmorgan/bin/R-devel/src/main'
make[2]: *** [R] Error 2
make[2]: Leaving directory `/home/mtmorgan/bin/R-devel/src/main'
make[1]: *** [R] Error 1
make[1]: Leaving directory `/home/mtmorgan/bin/R-devel/src'
make: *** [R] Error 1


Index: src/library/base/R/factor.R
===================================================================
--- src/library/base/R/factor.R (revision 55563)
+++ src/library/base/R/factor.R (working copy)
@@ -45,7 +45,9 @@
  }

  is.factor <- function(x) inherits(x, "factor")
-as.factor <- function(x) if (is.factor(x)) x else factor(x)
+as.factor.default <- function(x, ...)
+    if (is.factor(x)) x else factor(x, ...)
+as.factor <- function(x, ...) UseMethod("as.factor")

  ## Help old S users:
  category <- function(...) .Defunct()
@@ -245,7 +247,10 @@
  ordered <- function(x, ...) factor(x, ..., ordered=TRUE)

  is.ordered <- function(x) inherits(x, "ordered")
-as.ordered <- function(x) if(is.ordered(x)) x else ordered(x)
+as.ordered.default <- function(x, ...)
+    if(is.ordered(x)) x else ordered(x, ...)
+as.ordered <- function(x, ...)
+    UseMethod("as.ordered")

  Ops.ordered <- function (e1, e2)
  {
Index: src/library/base/man/factor.Rd
===================================================================
--- src/library/base/man/factor.Rd      (revision 55563)
+++ src/library/base/man/factor.Rd      (working copy)
@@ -10,7 +10,9 @@
  \alias{is.factor}
  \alias{is.ordered}
  \alias{as.factor}
+\alias{as.factor.default}
  \alias{as.ordered}
+\alias{as.ordered.default}
  \alias{is.na<-.factor}
  \alias{Math.factor}
  \alias{Ops.factor}
@@ -40,8 +42,8 @@
  is.factor(x)
  is.ordered(x)

-as.factor(x)
-as.ordered(x)
+as.factor(x, \dots)
+as.ordered(x, \dots)

  addNA(x, ifany=FALSE)
  }

-- 
Computational Biology
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N. PO Box 19024 Seattle, WA 98109

Location: M1-B861
Telephone: 206 667-2793


From wdunlap at tibco.com  Wed Apr 20 19:13:38 2011
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 20 Apr 2011 10:13:38 -0700
Subject: [Rd] Make as.factor an S3 generic?
In-Reply-To: <4DAF1023.4040002@fhcrc.org>
References: <4DAF1023.4040002@fhcrc.org>
Message-ID: <77EB52C6DD32BA4D87471DCD70C8D700042353AC@NA-PA-VBE03.na.tibco.com>

> -----Original Message-----
> From: r-devel-bounces at r-project.org 
> [mailto:r-devel-bounces at r-project.org] On Behalf Of Martin Morgan
> Sent: Wednesday, April 20, 2011 9:56 AM
> To: R-devel at r-project.org
> Subject: [Rd] Make as.factor an S3 generic?
> 
> as.factor / as.ordered is not written as a generic. This differs from 
> as.numeric, as.matrix, and other as.*. The following seems to address 
> this and does not break make check-all.

Why did you decide to make as.factor() generic instead of factor()?

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


From chuck at sharpsteen.net  Wed Apr 20 19:28:15 2011
From: chuck at sharpsteen.net (Sharpie)
Date: Wed, 20 Apr 2011 10:28:15 -0700 (PDT)
Subject: [Rd] Sweave support added to rgl package
In-Reply-To: <4DADD1E6.5040905@gmail.com>
References: <4DADD1E6.5040905@gmail.com>
Message-ID: <1303320495063-3463653.post@n4.nabble.com>


Duncan Murdoch-2 wrote:
> 
> I have just committed some code to the rgl package on 
> https://r-forge.r-project.org/projects/rgl/ to allow rgl images to be 
> inserted into Sweave documents.  (This is not in the CRAN version yet.)  
> It makes use of the custom graphics driver support added by Brian Ripley.
> 
> In R-devel (which will become R 2.14.0 next spring in New Zealand, next 
> fall in most other places), usage is quite straightforward.  For
> example, code like this in a Sweave document:
> 
> <&lt;fig=true, grdevice=rgl.Sweave, pdf=false, stayopen=TRUE&gt;>=
> x <- rnorm(100); y <- rnorm(100); z <- rnorm(100)
> plot3d(x, y, z)
> @
> 
> will insert a .png snapshot of the figure.  Because that chunk has 
> "stayopen=TRUE", it can be followed by another chunk to add
> to the figure, e.g.
> 
> <&lt;fig=true, grdevice=rgl.Sweave, pdf=false&gt;>=
> lines3d(x[1:10], y[1:10], z[1:10], col="red")
> @
> 
> All of this is possible in R 2.13.0, but it takes more work:  see the 
> ?rgl.Sweave help page.
> 
> I will eventually add postscript and PDF output options as well, and 
> perhaps some support for the LaTeX movie15 package, but those are not 
> there yet.  Comments or bug reports are welcome.
> 
> Duncan Murdoch
> 

This is great news Duncan!

If you do consider adding support for movie15, the Asymptote graphics
language may be handy:

http://asymptote.sourceforge.net/

Asymptote can embed 3D graphs into LaTeX documents that are fully
zoomable/manipulatable. It also uses LaTeX to typeset the figure text.

-Charlie


-----
Charlie Sharpsteen
Undergraduate-- Environmental Resources Engineering
Humboldt State University
--
View this message in context: http://r.789695.n4.nabble.com/Sweave-support-added-to-rgl-package-tp3461163p3463653.html
Sent from the R devel mailing list archive at Nabble.com.


From chuck at sharpsteen.net  Wed Apr 20 19:34:44 2011
From: chuck at sharpsteen.net (Sharpie)
Date: Wed, 20 Apr 2011 10:34:44 -0700 (PDT)
Subject: [Rd] Patching "update.packages" to enable updating of only a
 user defined subset of packages
In-Reply-To: <BANLkTinvjw3n4QUV+v1m-U9ojdwdh7mBDA@mail.gmail.com>
References: <BANLkTinvjw3n4QUV+v1m-U9ojdwdh7mBDA@mail.gmail.com>
Message-ID: <1303320884065-3463670.post@n4.nabble.com>


Tal Galili wrote:
> 
> Hello dear R developers,
> 
> I recently found out that it is not possible to limit update.packages() to
> update only a few packages at a time.
> 
> The patch offered simply adds a 'subset' parameter and the statement
> bounded
> within "if(!missing(subset))" to implement it.
> The code is pasted bellow (and also attached as an .r file).
> 
> Might this patch be considered valuable to be added to R?
> 
> 
> (in the code bellow I called the function "update.packages.2" so to not
> mask
> the original update.packages)
> 
> 
> With much respect,
> Tal
> 

Hi Tal,

I think if you pass a character vector in the `oldPkgs` argument of
update.packages, it will only consider packages in that list for updating.

-Charlie


-----
Charlie Sharpsteen
Undergraduate-- Environmental Resources Engineering
Humboldt State University
--
View this message in context: http://r.789695.n4.nabble.com/Patching-update-packages-to-enable-updating-of-only-a-user-defined-subset-of-packages-tp3456738p3463670.html
Sent from the R devel mailing list archive at Nabble.com.


From djsamperi at gmail.com  Wed Apr 20 19:52:06 2011
From: djsamperi at gmail.com (Dominick Samperi)
Date: Wed, 20 Apr 2011 13:52:06 -0400
Subject: [Rd] Sweave support added to rgl package
In-Reply-To: <4DADD1E6.5040905@gmail.com>
References: <4DADD1E6.5040905@gmail.com>
Message-ID: <BANLkTikDrC1wdzMv+-0c1_t_MjTKx+Svxg@mail.gmail.com>

On Tue, Apr 19, 2011 at 2:18 PM, Duncan Murdoch
<murdoch.duncan at gmail.com> wrote:
> I have just committed some code to the rgl package on
> https://r-forge.r-project.org/projects/rgl/ to allow rgl images to be
> inserted into Sweave documents. ?(This is not in the CRAN version yet.) ?It
> makes use of the custom graphics driver support added by Brian Ripley.
>
> In R-devel (which will become R 2.14.0 next spring in New Zealand, next fall
> in most other places), usage is quite straightforward. ?For
> example, code like this in a Sweave document:
>
> <<fig=true, grdevice=rgl.Sweave, pdf=false, stayopen=TRUE>>=
> x <- rnorm(100); y <- rnorm(100); z <- rnorm(100)
> plot3d(x, y, z)
> @
>
> will insert a .png snapshot of the figure. ?Because that chunk has
> "stayopen=TRUE", it can be followed by another chunk to add
> to the figure, e.g.
>
> <<fig=true, grdevice=rgl.Sweave, pdf=false>>=
> lines3d(x[1:10], y[1:10], z[1:10], col="red")
> @
>
> All of this is possible in R 2.13.0, but it takes more work: ?see the
> ?rgl.Sweave help page.
>
> I will eventually add postscript and PDF output options as well, and perhaps
> some support for the LaTeX movie15 package, but those are not there yet.
> ?Comments or bug reports are welcome.
>
> Duncan Murdoch

I inserted your example into testrgl.Rnw under R 2.13.0, with Sweave.snapshot()
at the end of both chunks, but things did not work as expected.

I used:
$ R CMD Sweave testrgl.Rnw
$ pdflatex tesetrgl
(view testrgl.pdf)

When R CMD Sweave is run the graphics is displayed interactively.

There is no graphics in the PDF file, even though both .png files
are read when pdflatex is run.

Thanks,
Dominick


From murdoch.duncan at gmail.com  Wed Apr 20 20:29:58 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 20 Apr 2011 14:29:58 -0400
Subject: [Rd] Sweave support added to rgl package
In-Reply-To: <BANLkTikDrC1wdzMv+-0c1_t_MjTKx+Svxg@mail.gmail.com>
References: <4DADD1E6.5040905@gmail.com>
	<BANLkTikDrC1wdzMv+-0c1_t_MjTKx+Svxg@mail.gmail.com>
Message-ID: <4DAF2626.6010805@gmail.com>

On 20/04/2011 1:52 PM, Dominick Samperi wrote:
> On Tue, Apr 19, 2011 at 2:18 PM, Duncan Murdoch
> <murdoch.duncan at gmail.com>  wrote:
> >  I have just committed some code to the rgl package on
> >  https://r-forge.r-project.org/projects/rgl/ to allow rgl images to be
> >  inserted into Sweave documents.  (This is not in the CRAN version yet.)  It
> >  makes use of the custom graphics driver support added by Brian Ripley.
> >
> >  In R-devel (which will become R 2.14.0 next spring in New Zealand, next fall
> >  in most other places), usage is quite straightforward.  For
> >  example, code like this in a Sweave document:
> >
> >  <<fig=true, grdevice=rgl.Sweave, pdf=false, stayopen=TRUE>>=
> >  x<- rnorm(100); y<- rnorm(100); z<- rnorm(100)
> >  plot3d(x, y, z)
> >  @
> >
> >  will insert a .png snapshot of the figure.  Because that chunk has
> >  "stayopen=TRUE", it can be followed by another chunk to add
> >  to the figure, e.g.
> >
> >  <<fig=true, grdevice=rgl.Sweave, pdf=false>>=
> >  lines3d(x[1:10], y[1:10], z[1:10], col="red")
> >  @
> >
> >  All of this is possible in R 2.13.0, but it takes more work:  see the
> >  ?rgl.Sweave help page.
> >
> >  I will eventually add postscript and PDF output options as well, and perhaps
> >  some support for the LaTeX movie15 package, but those are not there yet.
> >    Comments or bug reports are welcome.
> >
> >  Duncan Murdoch
>
> I inserted your example into testrgl.Rnw under R 2.13.0, with Sweave.snapshot()
> at the end of both chunks, but things did not work as expected.
>
> I used:
> $ R CMD Sweave testrgl.Rnw
> $ pdflatex tesetrgl
> (view testrgl.pdf)
>
> When R CMD Sweave is run the graphics is displayed interactively.

That's unavoidable as far as I know.  I don't think there's a general 
purpose way to tell OpenGL to render in the background, so it works by 
rendering on screen, then copying a bitmap to the .png file.
> There is no graphics in the PDF file, even though both .png files
> are read when pdflatex is run.

Do they look okay?  One possible problem is that you may have asked for 
a bitmap too big for your hardware to render, in which case those png 
files will end up with junk (probably blank).  Setting resolution=100 in 
the chunk headers will do it more coarsely.  (The default is 300 dpi.)  
The same effect comes from width=1, height=1  (or some other small numbers).

Duncan Murdoch


From murdoch.duncan at gmail.com  Wed Apr 20 20:34:51 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 20 Apr 2011 14:34:51 -0400
Subject: [Rd] Sweave support added to rgl package
In-Reply-To: <1303320495063-3463653.post@n4.nabble.com>
References: <4DADD1E6.5040905@gmail.com>
	<1303320495063-3463653.post@n4.nabble.com>
Message-ID: <4DAF274B.5040608@gmail.com>

On 20/04/2011 1:28 PM, Sharpie wrote:
> Duncan Murdoch-2 wrote:
> >
> >  I have just committed some code to the rgl package on
> >  https://r-forge.r-project.org/projects/rgl/ to allow rgl images to be
> >  inserted into Sweave documents.  (This is not in the CRAN version yet.)
> >  It makes use of the custom graphics driver support added by Brian Ripley.
> >
> >  In R-devel (which will become R 2.14.0 next spring in New Zealand, next
> >  fall in most other places), usage is quite straightforward.  For
> >  example, code like this in a Sweave document:
> >
> >  <&lt;fig=true, grdevice=rgl.Sweave, pdf=false, stayopen=TRUE&gt;>=
> >  x<- rnorm(100); y<- rnorm(100); z<- rnorm(100)
> >  plot3d(x, y, z)
> >  @
> >
> >  will insert a .png snapshot of the figure.  Because that chunk has
> >  "stayopen=TRUE", it can be followed by another chunk to add
> >  to the figure, e.g.
> >
> >  <&lt;fig=true, grdevice=rgl.Sweave, pdf=false&gt;>=
> >  lines3d(x[1:10], y[1:10], z[1:10], col="red")
> >  @
> >
> >  All of this is possible in R 2.13.0, but it takes more work:  see the
> >  ?rgl.Sweave help page.
> >
> >  I will eventually add postscript and PDF output options as well, and
> >  perhaps some support for the LaTeX movie15 package, but those are not
> >  there yet.  Comments or bug reports are welcome.
> >
> >  Duncan Murdoch
> >
>
> This is great news Duncan!
>
> If you do consider adding support for movie15, the Asymptote graphics
> language may be handy:
>
> http://asymptote.sourceforge.net/
>
> Asymptote can embed 3D graphs into LaTeX documents that are fully
> zoomable/manipulatable. It also uses LaTeX to typeset the figure text.

Thanks.  That doesn't look easy, but it would indeed be a nice addition.

Duncan Murdoch


> -Charlie
>
>
> -----
> Charlie Sharpsteen
> Undergraduate-- Environmental Resources Engineering
> Humboldt State University
> --
> View this message in context: http://r.789695.n4.nabble.com/Sweave-support-added-to-rgl-package-tp3461163p3463653.html
> Sent from the R devel mailing list archive at Nabble.com.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From ripley at stats.ox.ac.uk  Wed Apr 20 20:38:59 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 20 Apr 2011 19:38:59 +0100 (BST)
Subject: [Rd] Make as.factor an S3 generic?
In-Reply-To: <4DAF1023.4040002@fhcrc.org>
References: <4DAF1023.4040002@fhcrc.org>
Message-ID: <alpine.LFD.2.02.1104201938080.28636@gannet.stats.ox.ac.uk>

Well, lots of functions are not generic.  We do ask you to give a case 
for such changes ... where is it?

On Wed, 20 Apr 2011, Martin Morgan wrote:

> as.factor / as.ordered is not written as a generic. This differs from 
> as.numeric, as.matrix, and other as.*. The following seems to address this 
> and does not break make check-all.
>
> FWIW, the patch is against r55563, because with r55564 I see

OS-specific ....

> /home/mtmorgan/src/R-devel/src/main/dounzip.c:75:15: error: storage size of 
> ?dt? isn?t known
> /home/mtmorgan/src/R-devel/src/main/dounzip.c:88:5: warning: implicit 
> declaration of function ?mktime?
> make[3]: *** [dounzip.o] Error 1
> make[3]: *** Waiting for unfinished jobs....
> make[3]: Leaving directory `/home/mtmorgan/bin/R-devel/src/main'
> make[2]: *** [R] Error 2
> make[2]: Leaving directory `/home/mtmorgan/bin/R-devel/src/main'
> make[1]: *** [R] Error 1
> make[1]: Leaving directory `/home/mtmorgan/bin/R-devel/src'
> make: *** [R] Error 1
>
>
> Index: src/library/base/R/factor.R
> ===================================================================
> --- src/library/base/R/factor.R (revision 55563)
> +++ src/library/base/R/factor.R (working copy)
> @@ -45,7 +45,9 @@
> }
>
> is.factor <- function(x) inherits(x, "factor")
> -as.factor <- function(x) if (is.factor(x)) x else factor(x)
> +as.factor.default <- function(x, ...)
> +    if (is.factor(x)) x else factor(x, ...)
> +as.factor <- function(x, ...) UseMethod("as.factor")
>
> ## Help old S users:
> category <- function(...) .Defunct()
> @@ -245,7 +247,10 @@
> ordered <- function(x, ...) factor(x, ..., ordered=TRUE)
>
> is.ordered <- function(x) inherits(x, "ordered")
> -as.ordered <- function(x) if(is.ordered(x)) x else ordered(x)
> +as.ordered.default <- function(x, ...)
> +    if(is.ordered(x)) x else ordered(x, ...)
> +as.ordered <- function(x, ...)
> +    UseMethod("as.ordered")
>
> Ops.ordered <- function (e1, e2)
> {
> Index: src/library/base/man/factor.Rd
> ===================================================================
> --- src/library/base/man/factor.Rd      (revision 55563)
> +++ src/library/base/man/factor.Rd      (working copy)
> @@ -10,7 +10,9 @@
> \alias{is.factor}
> \alias{is.ordered}
> \alias{as.factor}
> +\alias{as.factor.default}
> \alias{as.ordered}
> +\alias{as.ordered.default}
> \alias{is.na<-.factor}
> \alias{Math.factor}
> \alias{Ops.factor}
> @@ -40,8 +42,8 @@
> is.factor(x)
> is.ordered(x)
>
> -as.factor(x)
> -as.ordered(x)
> +as.factor(x, \dots)
> +as.ordered(x, \dots)
>
> addNA(x, ifany=FALSE)
> }
>
> -- 
> Computational Biology
> Fred Hutchinson Cancer Research Center
> 1100 Fairview Ave. N. PO Box 19024 Seattle, WA 98109
>
> Location: M1-B861
> Telephone: 206 667-2793
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From mtmorgan at fhcrc.org  Wed Apr 20 20:37:18 2011
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Wed, 20 Apr 2011 11:37:18 -0700
Subject: [Rd] Make as.factor an S3 generic?
In-Reply-To: <77EB52C6DD32BA4D87471DCD70C8D700042353AC@NA-PA-VBE03.na.tibco.com>
References: <4DAF1023.4040002@fhcrc.org>
	<77EB52C6DD32BA4D87471DCD70C8D700042353AC@NA-PA-VBE03.na.tibco.com>
Message-ID: <4DAF27DE.3050503@fhcrc.org>

On 04/20/2011 10:13 AM, William Dunlap wrote:
>> -----Original Message-----
>> From: r-devel-bounces at r-project.org
>> [mailto:r-devel-bounces at r-project.org] On Behalf Of Martin Morgan
>> Sent: Wednesday, April 20, 2011 9:56 AM
>> To: R-devel at r-project.org
>> Subject: [Rd] Make as.factor an S3 generic?
>>
>> as.factor / as.ordered is not written as a generic. This differs from
>> as.numeric, as.matrix, and other as.*. The following seems to address
>> this and does not break make check-all.
>
> Why did you decide to make as.factor() generic instead of factor()?

Hi Bill --

short-sighted consistency with other as.*; implied simplicity of 
coercion rather than construction.

Martin

>
> Bill Dunlap
> Spotfire, TIBCO Software
> wdunlap tibco.com


-- 
Computational Biology
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N. PO Box 19024 Seattle, WA 98109

Location: M1-B861
Telephone: 206 667-2793


From mtmorgan at fhcrc.org  Wed Apr 20 20:40:31 2011
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Wed, 20 Apr 2011 11:40:31 -0700
Subject: [Rd] Make as.factor an S3 generic?
In-Reply-To: <alpine.LFD.2.02.1104201938080.28636@gannet.stats.ox.ac.uk>
References: <4DAF1023.4040002@fhcrc.org>
	<alpine.LFD.2.02.1104201938080.28636@gannet.stats.ox.ac.uk>
Message-ID: <4DAF289F.6090008@fhcrc.org>

On 04/20/2011 11:38 AM, Prof Brian Ripley wrote:
> Well, lots of functions are not generic. We do ask you to give a case
> for such changes ... where is it?

The specific need started with base::lapply, which calls base::as.list. 
An S4 method "as.list,A-method" defined in a name space isn't seen by 
base::as.list, whereas as.list.A is (see discussion in ?Methods around 
/f3.myClass). The question is from this post on a Bioconductor mailing list

https://stat.ethz.ch/pipermail/bioc-sig-sequencing/2011-April/001979.html

[partly answering Bill's question here] A list() constructor could be 
tricky to implement (dealing with variable numbers of arguments and the 
S4 rules for dispatch on ...), whereas as.list.A is trivial (slot 
extraction, in my case). Having arrived at an easy solution, I marched 
through the other coercion functions with only minor set-backs 
(as.double.A instead of as.numeric.A) until factor.

Martin

>
> On Wed, 20 Apr 2011, Martin Morgan wrote:
>
>> as.factor / as.ordered is not written as a generic. This differs from
>> as.numeric, as.matrix, and other as.*. The following seems to address
>> this and does not break make check-all.
>>
>> FWIW, the patch is against r55563, because with r55564 I see
>
> OS-specific ....
>
>> /home/mtmorgan/src/R-devel/src/main/dounzip.c:75:15: error: storage
>> size of ?dt? isn?t known
>> /home/mtmorgan/src/R-devel/src/main/dounzip.c:88:5: warning: implicit
>> declaration of function ?mktime?
>> make[3]: *** [dounzip.o] Error 1
>> make[3]: *** Waiting for unfinished jobs....
>> make[3]: Leaving directory `/home/mtmorgan/bin/R-devel/src/main'
>> make[2]: *** [R] Error 2
>> make[2]: Leaving directory `/home/mtmorgan/bin/R-devel/src/main'
>> make[1]: *** [R] Error 1
>> make[1]: Leaving directory `/home/mtmorgan/bin/R-devel/src'
>> make: *** [R] Error 1
>>
>>
>> Index: src/library/base/R/factor.R
>> ===================================================================
>> --- src/library/base/R/factor.R (revision 55563)
>> +++ src/library/base/R/factor.R (working copy)
>> @@ -45,7 +45,9 @@
>> }
>>
>> is.factor <- function(x) inherits(x, "factor")
>> -as.factor <- function(x) if (is.factor(x)) x else factor(x)
>> +as.factor.default <- function(x, ...)
>> + if (is.factor(x)) x else factor(x, ...)
>> +as.factor <- function(x, ...) UseMethod("as.factor")
>>
>> ## Help old S users:
>> category <- function(...) .Defunct()
>> @@ -245,7 +247,10 @@
>> ordered <- function(x, ...) factor(x, ..., ordered=TRUE)
>>
>> is.ordered <- function(x) inherits(x, "ordered")
>> -as.ordered <- function(x) if(is.ordered(x)) x else ordered(x)
>> +as.ordered.default <- function(x, ...)
>> + if(is.ordered(x)) x else ordered(x, ...)
>> +as.ordered <- function(x, ...)
>> + UseMethod("as.ordered")
>>
>> Ops.ordered <- function (e1, e2)
>> {
>> Index: src/library/base/man/factor.Rd
>> ===================================================================
>> --- src/library/base/man/factor.Rd (revision 55563)
>> +++ src/library/base/man/factor.Rd (working copy)
>> @@ -10,7 +10,9 @@
>> \alias{is.factor}
>> \alias{is.ordered}
>> \alias{as.factor}
>> +\alias{as.factor.default}
>> \alias{as.ordered}
>> +\alias{as.ordered.default}
>> \alias{is.na<-.factor}
>> \alias{Math.factor}
>> \alias{Ops.factor}
>> @@ -40,8 +42,8 @@
>> is.factor(x)
>> is.ordered(x)
>>
>> -as.factor(x)
>> -as.ordered(x)
>> +as.factor(x, \dots)
>> +as.ordered(x, \dots)
>>
>> addNA(x, ifany=FALSE)
>> }
>>
>> --
>> Computational Biology
>> Fred Hutchinson Cancer Research Center
>> 1100 Fairview Ave. N. PO Box 19024 Seattle, WA 98109
>>
>> Location: M1-B861
>> Telephone: 206 667-2793
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>


-- 
Computational Biology
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N. PO Box 19024 Seattle, WA 98109

Location: M1-B861
Telephone: 206 667-2793


From mfay at niaid.nih.gov  Wed Apr 20 21:30:15 2011
From: mfay at niaid.nih.gov (Fay, Michael (NIH/NIAID) [E])
Date: Wed, 20 Apr 2011 15:30:15 -0400
Subject: [Rd] possible minor bug in fisher.test
Message-ID: <E71B6F8FD9DA77498BED796B4E35362C0546F22068@NIHMLBX01.nih.gov>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110420/ab2753a7/attachment.pl>

From pdalgd at gmail.com  Wed Apr 20 22:22:40 2011
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 20 Apr 2011 22:22:40 +0200
Subject: [Rd] possible minor bug in fisher.test
In-Reply-To: <E71B6F8FD9DA77498BED796B4E35362C0546F22068@NIHMLBX01.nih.gov>
References: <E71B6F8FD9DA77498BED796B4E35362C0546F22068@NIHMLBX01.nih.gov>
Message-ID: <57CAEC06-BFF7-4639-BCDC-9B2698C223DF@gmail.com>


On Apr 20, 2011, at 21:30 , Fay, Michael (NIH/NIAID) [E] wrote:

> Hi,
> 
> I received a bug report for my exact2x2 package that seems to apply to fisher.test in the stats package also.
> 
> Here is some code which creates the error:
> 
>> x<-factor(c(0,1,1),levels=c(0,1))
>> y<-factor(c(1,1,1),levels=c(0,1))
>> fisher.test(x,y)
> Error in fisher.test(x, y) : 'x' and 'y' must have at least 2 levels
>> 
> 
> The help says that x and y could be factors, and technically y does have 2 levels, although both are not observed. There is no problem statistically with y not having 2 observed levels,  and
> 
>> fisher.test(table(x,y))
> 
> Produces the correct p-value of 1 and no errors.
> 
> There is an easy solution. In fisher.test replace
> 
>        x <- factor(x[OK])
>        y <- factor(y[OK])
> 
> 
> with
> 
>        x <- as.factor(x[OK])
>        y <- as.factor(y[OK])
> 
> (similar to how it is done in mcnemar.test).
> 
> 

OK. Of course, the test makes little sense statistically either way if one factor has only one level used, but I can imagine that a p value of 1 is preferable to an error, and the consistency is probably worth having too.

Fixed in r-devel.

-- 
Peter Dalgaard
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From djsamperi at gmail.com  Thu Apr 21 01:10:20 2011
From: djsamperi at gmail.com (Dominick Samperi)
Date: Wed, 20 Apr 2011 19:10:20 -0400
Subject: [Rd] Sweave support added to rgl package
In-Reply-To: <4DAF2626.6010805@gmail.com>
References: <4DADD1E6.5040905@gmail.com>
	<BANLkTikDrC1wdzMv+-0c1_t_MjTKx+Svxg@mail.gmail.com>
	<4DAF2626.6010805@gmail.com>
Message-ID: <BANLkTimjXGU+cEGnEsW_=vZ6E50Qby4JtA@mail.gmail.com>

On Wed, Apr 20, 2011 at 2:29 PM, Duncan Murdoch
<murdoch.duncan at gmail.com> wrote:
> On 20/04/2011 1:52 PM, Dominick Samperi wrote:
>>
>> On Tue, Apr 19, 2011 at 2:18 PM, Duncan Murdoch
>> <murdoch.duncan at gmail.com> ?wrote:
>> > ?I have just committed some code to the rgl package on
>> > ?https://r-forge.r-project.org/projects/rgl/ to allow rgl images to be
>> > ?inserted into Sweave documents. ?(This is not in the CRAN version yet.)
>> > ?It
>> > ?makes use of the custom graphics driver support added by Brian Ripley.
>> >
>> > ?In R-devel (which will become R 2.14.0 next spring in New Zealand, next
>> > fall
>> > ?in most other places), usage is quite straightforward. ?For
>> > ?example, code like this in a Sweave document:
>> >
>> > ?<<fig=true, grdevice=rgl.Sweave, pdf=false, stayopen=TRUE>>=
>> > ?x<- rnorm(100); y<- rnorm(100); z<- rnorm(100)
>> > ?plot3d(x, y, z)
>> > ?@
>> >
>> > ?will insert a .png snapshot of the figure. ?Because that chunk has
>> > ?"stayopen=TRUE", it can be followed by another chunk to add
>> > ?to the figure, e.g.
>> >
>> > ?<<fig=true, grdevice=rgl.Sweave, pdf=false>>=
>> > ?lines3d(x[1:10], y[1:10], z[1:10], col="red")
>> > ?@
>> >
>> > ?All of this is possible in R 2.13.0, but it takes more work: ?see the
>> > ??rgl.Sweave help page.
>> >
>> > ?I will eventually add postscript and PDF output options as well, and
>> > perhaps
>> > ?some support for the LaTeX movie15 package, but those are not there
>> > yet.
>> > ? ?Comments or bug reports are welcome.
>> >
>> > ?Duncan Murdoch
>>
>> I inserted your example into testrgl.Rnw under R 2.13.0, with
>> Sweave.snapshot()
>> at the end of both chunks, but things did not work as expected.
>>
>> I used:
>> $ R CMD Sweave testrgl.Rnw
>> $ pdflatex tesetrgl
>> (view testrgl.pdf)
>>
>> When R CMD Sweave is run the graphics is displayed interactively.
>
> That's unavoidable as far as I know. ?I don't think there's a general
> purpose way to tell OpenGL to render in the background, so it works by
> rendering on screen, then copying a bitmap to the .png file.
>>
>> There is no graphics in the PDF file, even though both .png files
>> are read when pdflatex is run.
>
> Do they look okay? ?One possible problem is that you may have asked for a
> bitmap too big for your hardware to render, in which case those png files
> will end up with junk (probably blank). ?Setting resolution=100 in the chunk
> headers will do it more coarsely. ?(The default is 300 dpi.) ?The same
> effect comes from width=1, height=1 ?(or some other small numbers).
>
> Duncan Murdoch
>

The resolution=100 tip fixed the problem, thanks. Now I see the snapshots
in the PDF file. Using this in a package will certainly change the
user experience,
but it moves away from the traditional batch-oriented R package
processing, it seems to me.

The idea of adding support for movies and 3D graphics to Sweave/PDF files
sounds very interesting and revolutionary.

Dominick


From murdoch.duncan at gmail.com  Thu Apr 21 02:56:36 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 20 Apr 2011 20:56:36 -0400
Subject: [Rd] Sweave support added to rgl package
In-Reply-To: <BANLkTimjXGU+cEGnEsW_=vZ6E50Qby4JtA@mail.gmail.com>
References: <4DADD1E6.5040905@gmail.com>	<BANLkTikDrC1wdzMv+-0c1_t_MjTKx+Svxg@mail.gmail.com>	<4DAF2626.6010805@gmail.com>
	<BANLkTimjXGU+cEGnEsW_=vZ6E50Qby4JtA@mail.gmail.com>
Message-ID: <4DAF80C4.7070602@gmail.com>

On 20/04/2011 7:10 PM, Dominick Samperi wrote:
> On Wed, Apr 20, 2011 at 2:29 PM, Duncan Murdoch
> <murdoch.duncan at gmail.com>  wrote:
>> On 20/04/2011 1:52 PM, Dominick Samperi wrote:
>>>
>>> On Tue, Apr 19, 2011 at 2:18 PM, Duncan Murdoch
>>> <murdoch.duncan at gmail.com>    wrote:
>>>>   I have just committed some code to the rgl package on
>>>>   https://r-forge.r-project.org/projects/rgl/ to allow rgl images to be
>>>>   inserted into Sweave documents.  (This is not in the CRAN version yet.)
>>>>   It
>>>>   makes use of the custom graphics driver support added by Brian Ripley.
>>>>
>>>>   In R-devel (which will become R 2.14.0 next spring in New Zealand, next
>>>> fall
>>>>   in most other places), usage is quite straightforward.  For
>>>>   example, code like this in a Sweave document:
>>>>
>>>>   <<fig=true, grdevice=rgl.Sweave, pdf=false, stayopen=TRUE>>=
>>>>   x<- rnorm(100); y<- rnorm(100); z<- rnorm(100)
>>>>   plot3d(x, y, z)
>>>>   @
>>>>
>>>>   will insert a .png snapshot of the figure.  Because that chunk has
>>>>   "stayopen=TRUE", it can be followed by another chunk to add
>>>>   to the figure, e.g.
>>>>
>>>>   <<fig=true, grdevice=rgl.Sweave, pdf=false>>=
>>>>   lines3d(x[1:10], y[1:10], z[1:10], col="red")
>>>>   @
>>>>
>>>>   All of this is possible in R 2.13.0, but it takes more work:  see the
>>>>   ?rgl.Sweave help page.
>>>>
>>>>   I will eventually add postscript and PDF output options as well, and
>>>> perhaps
>>>>   some support for the LaTeX movie15 package, but those are not there
>>>> yet.
>>>>     Comments or bug reports are welcome.
>>>>
>>>>   Duncan Murdoch
>>>
>>> I inserted your example into testrgl.Rnw under R 2.13.0, with
>>> Sweave.snapshot()
>>> at the end of both chunks, but things did not work as expected.
>>>
>>> I used:
>>> $ R CMD Sweave testrgl.Rnw
>>> $ pdflatex tesetrgl
>>> (view testrgl.pdf)
>>>
>>> When R CMD Sweave is run the graphics is displayed interactively.
>>
>> That's unavoidable as far as I know.  I don't think there's a general
>> purpose way to tell OpenGL to render in the background, so it works by
>> rendering on screen, then copying a bitmap to the .png file.
>>>
>>> There is no graphics in the PDF file, even though both .png files
>>> are read when pdflatex is run.
>>
>> Do they look okay?  One possible problem is that you may have asked for a
>> bitmap too big for your hardware to render, in which case those png files
>> will end up with junk (probably blank).  Setting resolution=100 in the chunk
>> headers will do it more coarsely.  (The default is 300 dpi.)  The same
>> effect comes from width=1, height=1  (or some other small numbers).
>>
>> Duncan Murdoch
>>
>
> The resolution=100 tip fixed the problem, thanks.

I'll see if I am skipping over some error message in there.  It would be 
much better for Sweave to fail with an error than generate empty images.


 > Now I see the snapshots
> in the PDF file. Using this in a package will certainly change the
> user experience,
> but it moves away from the traditional batch-oriented R package
> processing, it seems to me.

I don't follow that.

> The idea of adding support for movies and 3D graphics to Sweave/PDF files
> sounds very interesting and revolutionary.

Movies will likely be pretty slow.  I think you'll want caching of some 
sort if you want to produce those.

Duncan Murdoch

>
> Dominick


From David.Epstein at warwick.ac.uk  Wed Apr 20 16:17:25 2011
From: David.Epstein at warwick.ac.uk (David.Epstein)
Date: Wed, 20 Apr 2011 07:17:25 -0700 (PDT)
Subject: [Rd] Sweave tokens not in column 1: enhancement request
In-Reply-To: <19886.47241.204068.966260@ridcully.stat.uni-muenchen.de>
References: <1303246784050-3461527.post@n4.nabble.com>
	<19886.47241.204068.966260@ridcully.stat.uni-muenchen.de>
Message-ID: <1303309045106-3463141.post@n4.nabble.com>


Friedrich Leisch-2 wrote:
> 
>>>>>> On Tue, 19 Apr 2011 13:59:44 -0700 (PDT),
>>>>>> David Epstein (DE) wrote:
> 
>   > When I re-use a code chunk in Sweave, together with keep.source=TRUE,
> I would
>   > like to follow usual programming conventions in which the amount of
> white
>   > space on the left indicates logical structure. It seems that one can't
> do
>   > this in Sweave, or am I wrong?
> 
>   > for (i in ind) {
>   >     do such-and-such and then
>   >     <<code chunk 20>>
>   >     do something-else
>   > }
> 
>   
> Not difficult at all, that's a trivial change:
> 
>   MySyntax <- utils::SweaveSyntaxNoweb
>   MySyntax$coderef <- "^[[:space:]]*<<(.*)>>.*"
>   Sweave("test.Rnw", syntax=MySyntax)
> 
> should do what you want. That code references need to start in column 1
> is inherited from noweb, not sure if we really need it. Cannot think
> of a situation where the above regular expression appears in valid R
> code, but perhaps I am overlooking something.
> 

Thanks. That is indeed very simple. I should have started this thread in
R-help, as I know there are other users who would like to do this, but I
mistakenly thought that code development would be needed. Is it possible to
somehow transfer the thread to R-help?

Would it not be safer to use [:blank:] or [ \t] instead of [:space:]?
[:space:] allows several symbols apart from space and tab, and this might
cause trouble?

Is it possible to put something into the .Rnw file with the same effect, or
do you HAVE to work from outside Sweave?
Thanks
David

--
View this message in context: http://r.789695.n4.nabble.com/Sweave-tokens-not-in-column-1-enhancement-request-tp3461527p3463141.html
Sent from the R devel mailing list archive at Nabble.com.


From kcrisman at gmail.com  Wed Apr 20 14:35:39 2011
From: kcrisman at gmail.com (Karl-Dieter Crisman)
Date: Wed, 20 Apr 2011 08:35:39 -0400
Subject: [Rd] How to get R to compile with PNG support
Message-ID: <BANLkTik8Tr1nucaDUQvNM9socPz6wNhvJg@mail.gmail.com>

> Message: 12
> Date: Wed, 20 Apr 2011 02:09:23 -0700 (PDT)
> From: Sharpie <chuck at sharpsteen.net>
> To: r-devel at r-project.org
> Subject: Re: [Rd] How to get R to compile with PNG support
> Message-ID: <1303290563237-3462502.post at n4.nabble.com>
> Content-Type: text/plain; charset=UTF-8
>
>
> Dear R devel list,
>
> Good morning; I'm with the Sage (http://www.sagemath.org) project.
> (Some of you might have seen my talk on this at last summer's useR
> conference).
>
> Thanks for stoping by Karl! I have to say that I am a big fan of the Sage
> project---it is a very good idea and I really appreciate all the time you
> guys put into it. I may not be able to answer all of your questions
> concerning PNG support, but hopefully some of the following pointers will be
> useful.

Good morning, Charlie et al.,

Thanks for your words.  We like R, too!  We need to advertise it more,
and this thread is part of making sure that happens in the long run.

To the issue at hand.   Our main concern is just not to have to spend
hours reading the configuration and makefile to figure out exactly
where things happen.


>>
>> We have some rudimentary support for using R graphics in various
>> cases, which has proved useful to many of our users who want to go
>> back and forth between R and other capabilities within Sage.
>> Unfortunately, the way we originally implemented this was using the
>> png and plot functions in R itself, which perhaps isn't the best
>> (i.e., everyone uses ggplot now? but I digress).
>>
>
> One important distinction to make is between R graphics functions such as
> plot and ggplot, and R graphics *devices*, such as png. The devices provide
> back ends that take the R-level function calls and actually execute the
> low-level "draw line from a to b, clip to rectangle A, insert left-justified
> text at x,y" primitives that get written to an output format.


True.  It's the device enabling that I'm talking about.  We enable
aqua on Mac, and png on Linux.

We ignore Cairo, and ignore X11 on Mac because it is too touchy (at
least, according to the FAQ on this - different weird instructions for
each type, and of course not everyone has X on Mac).

> Bottom line for Sage is that as long as you implement at least one device
> function, such as png, your users should be able to call plot, ggplot, and
> the rest of R's graphics functions to their heart's content, they just won't
> have a wide selection of output formats.
>

Great.  That is okay with us; we aren't expecting (yet) people to be
able to save R graphics in various output formats.  Our native
(matplotlib) graphics, we do expect this.


>> Then, not only could we be smarter in how we compile R (currently
>> somewhat naively searching for /usr/include/X11/Xwindows.h to
>> determine whether we'll try for png support), but we would be able to
>> tell users something very precise to do (e.g., apt-get foo) if they
>> currently have R without PNG support in Sage. ?Again, I emphasize that
>> apparently getting xorg-dev doesn't always do the trick.
>>


> In the trac ticket you linked, the configure output shows PNG is enabled
> (I.E. the library was found) but you may be ending up with no support for an
> actual png() graphics device due to one of the following
>
> ?- configure didn't find Xlib as X11 is not listed under Interfaces
> ?- configure didn't find cairo as it is not listed under Additional
> capabilities
>
> So, although R has the PNG library that is only useful for writing PNG
> files. R also needs the Xlib or Cairo libraries to provide drawing
> primitives that will create the figures those files will contain.

Gotcha.  I suspect that the X11 not listed under Interfaces is the
problem (again, we ignore Cairo).

What is the *exact* file or directory that the R configure looks for
in trying to list X11 under Interfaces?   And is there any way around
this at all?  That is, is there any way for R to create but not
display a graphic if it has (for instance) png support, like the one
on the Trac ticket did?  We can always just search for the png file
and serve it up in our own viewers.

Note that we already search for /usr/include/X11/Xwindows.h, and
adding xorg-dev didn't help with the latest one (which may not be on
the Trac ticket).


> In the ask.sagemath question the problem appears to be that the user had X11
> installed but not libpng.

Yes, I just referenced that for reference, as it were.

Thank you, and I hope we can get this resolved!

Karl-Dieter


From kcrisman at gmail.com  Wed Apr 20 18:16:11 2011
From: kcrisman at gmail.com (Karl-Dieter Crisman)
Date: Wed, 20 Apr 2011 12:16:11 -0400
Subject: [Rd] How to get R to compile with PNG support
Message-ID: <BANLkTinAtiXhxhSRhEEu0aDZsZuELOQu+g@mail.gmail.com>

Followup with the specific issue in our most recent (non-posted, as of
yet) attempts on a certain box.  We now have xorg-dev, libcairo-dev,
and Xwindows.h and libpng (as below) on this machine, but R is not
compiling with support for any of these things.

Once again, any help knowing *exactly* what to pass to the
configuration script or anything else would be *greatly* appreciated.
We are planning to use R in Sage on several occasions with this
machine this summer if we can get this going (see
http://www.maa.org/prep/2011/sage.html).

++++

R is now configured for i686-pc-linux-gnu
 Source directory:          .
 Installation directory:    /home/sageserver/sage/local
 C compiler:                gcc -std=gnu99
-I/home/sageserver/sage/local/include
-L/home/sageserver/sage/local/lib/   Fortran 77 compiler:
sage_fortran  -g -O2
 C++ compiler:              g++  -g -O2
 Fortran 90/95 compiler:    sage_fortran -g -O2  Obj-C compiler:
 Interfaces supported:      X11
 External libraries:        readline, BLAS(ATLAS), LAPACK(generic)
Additional capabilities:   PNG, NLS
 Options enabled:           shared R library, R profiling
 Recommended packages:      yes


However:


> capabilities()
   jpeg      png     tiff    tcltk      X11     aqua http/ftp  sockets
  FALSE    FALSE    FALSE    FALSE    FALSE    FALSE     TRUE     TRUE

 libxml     fifo   cledit    iconv      NLS  profmem    cairo
   TRUE     TRUE     TRUE     TRUE     TRUE    FALSE    FALSE


From tobias.abenius at chalmers.se  Wed Apr 20 13:30:42 2011
From: tobias.abenius at chalmers.se (Tobias Abenius)
Date: Wed, 20 Apr 2011 13:30:42 +0200
Subject: [Rd] useDynLib in older versions e.g. (2.10)
Message-ID: <4DAEC3E2.4070105@chalmers.se>

Hi,

Has something changed regarding the useDynLib in the NAMESPACE file in 
packages? I've written a package that works in e.g. 2.12/2.13 but simply 
cannot find the dynamic library under windows. The version on CRAN is 
older than the one I'm talking about and depends on a newer version of R 
but I want to make the package available to people with older versions.

 > utils:::menuInstallLocal()
package 'lassoshooting' successfully unpacked and MD5 sums checked
 > require(lassoshooting)
Loading required package: lassoshooting
Error in library.dynam(lib, package, package.lib) :
   shared library 'lassoshooting' not found
In addition: Warning message:
package 'lassoshooting' was built under R version 2.13.0

I'm usually under linux and don't know about the gory details of .dll files.

NAMESPACE file
--------------
useDynLib(lassoshooting)
export(lassoshooting)

happy easter!

regards, Tobias
-- 
Tobias Abenius
Ph.D. Student, M.Sc. in Computer Science

Mathematical Statistics
Mathematical Sciences
University of Gothenburg
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: 00install.out
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110420/0cfb9712/attachment.pl>

From sean.mcguffee at gmail.com  Wed Apr 20 17:33:52 2011
From: sean.mcguffee at gmail.com (Sean Robert McGuffee)
Date: Wed, 20 Apr 2011 11:33:52 -0400
Subject: [Rd] FW: [Rcpp-devel] Question on 5.6 Interfacing C++ code
In-Reply-To: <19886.61133.253659.258729@max.nulle.part>
Message-ID: <C9D47520.3D72%sean.mcguffee@gmail.com>

Hi, apparently I sent my question about using R and C++ to the wrong list,
ironically seeing as that list was called Rcpp. Anyway, I was directed to
post my question here. To summarize my current question, I have found two
commands that I want to be able to put into a package. The commands are 'R
CMD SHLIB X.cc X_main.cc' and
'dyn.load(paste("X",.Platform$dynlib.ext,sep="")),' which I would like to
run when my package is installed and maybe have the second command run again
when my package is to be used. I've been trying to figure out the
documentation and learn through examples, but I'm just not getting it and
have been trying for weeks.
Does anyone on this site have any suggestions for me?
Thanks, Sean

|On 20 April 2011 at 10:20, Sean Robert McGuffee wrote:
| 
| 
| Hi, thanks!
| 
| >On 4/20/11 10:03 AM, "Steve Lianoglou" <mailinglist.honeypot at gmail.com>
wrote:
| > Hi,
| > 
| > On Wed, Apr 20, 2011 at 9:49 AM, Sean Robert McGuffee
| > <sean.mcguffee at gmail.com> wrote:
| >> Hi, I have a quick couple of questions about some of the documentation
on
| >> the web page:
| >> 
http://cran.r-project.org/doc/manuals/R-exts.html#Linking-GUIs-and-other-fro
n
| >> t_002dends-to-R
| >> under the heading:
| >> 5.6 Interfacing C++ code
| >> 
| >> Question 1:
| >> If I?m at a terminal, I can type the instructions they suggest:
| >> R CMD SHLIB X.cc X_main.cc
| >> If I wanted a package to do this, how would I tell the package to do
that
| >> same thing?
| > 
| > Just to make sure we're all on the same page, you want an R package to
| > compile some source code into a shared library/dll from inside R?
| > 
| > Not sure if there's a "baked in" way for that to happen, but maybe you
| > can invoke `R CMD WHATEVER` from inside R using the `system` function:
| > 
| > R> ?system
| > 
| 
| ok, so where in the package would I put the system call in the package to
| have it run when installing the package?

>You don't. As I said, 'R CMD INSTALL' et all do that.
>Download an existing package with source, install it.  Study its sources,
>study the 'Writing R Extensions' manual.  Ask on r-devel.
>Basic R questions are off-topic here.
 
| >> Would I use the same command and just include it in a file somewhere in
the
| >> package?
| >> If so, which file?
| > 
| > Hmm ... I'm curious what you're trying to do, exactly?
| 
| I'm trying to figure out how take commands such as " R CMD SHLIB X.cc
| X_main.cc" followed by "dyn.load(paste("X", .Platform$dynlib.ext, sep =
| ""))," which are commands I can get to work for myself as a human
| interactively, and put the commands into a package to be automatically run
| when installing the package. I mean, it's great if I can compile a c++
file
| and then use it inside R, but I'm only doing that so I can let other
people
| do that via a package. As much as I read this documentation, I keep
missing

>Again, I like working from an existing, working package. As I said, there are
>almost 1000 to pick from.
>Please direct follow-ups that have no bearing on Rcpp to r-devel.
>Dirk

I've tried to figure this out for weeks by looking at other packages and
reading the confusing and nonintegrated documentation, but it hasn't taught
me how to put the two commands into a package so that they are run when the
package is installed. I'm simply trying to find out where in my package I
should put the commands 'R CMD SHLIB X.cc X_main.cc' and
'dyn.load(paste("X",.Platform$dynlib.ext,sep="")),'
in order to have them run when my package is installed.


| the connections between the different sections. This is a section I am
| loving because it works very well. Thus, I want to figure out how to take
| the baby steps I'm doing and combine them into a package. Specifically, I
| want to take these two commands and insert them into a package so that
these
| commands will compile my code and make a dynamic ".so" file where R can
| access its functions when others install my package.
| 
| > 
| >> Question 2:
| >> dyn.load(paste("X", .Platform$dynlib.ext, sep = ""))
| >> 
| >> Where does .Platform$dynlib.ext come from?
| >> What does it mean?
| >> What do it?s components .Platform and $dynlib and .ext mean?
| > 
| > .Platform is lust a normal list -- it is defined internally (I guess).
| > You can access "named" elements of a list with `$`.
| > 
| > .Platform$dynlyb (or .Platform[['dynlib']]) tells you the extension
| > your particular system uses for shared libraries:
| > 
| > R> .Platform
| > $OS.type
| > [1] "unix"
| > 
| > $file.sep
| > [1] "/"
| > 
| > $dynlib.ext
| > [1] ".so"
| > 
| > $GUI
| > [1] "X11"
| > 
| > $endian
| > [1] "little"
| > 
| > $pkgType
| > [1] "mac.binary.leopard"
| > 
| > $path.sep
| > [1] ":"
| > 
| > $r_arch
| > [1] "x86_64"
| > 
| > See ?.Platform for more help.
| 
| Ah, thanks, that clarifies exactly what .Platform$dynlib.ext is, it's
".so"
| on my system. 
| 
| This, the dyn.load(paste("X", .Platform$dynlib.ext, sep = "")) is
equivalent
| to the command dyn.load("X.so) which now makes sense in that context!
| 
| 
| _______________________________________________
| Rcpp-devel mailing list
| Rcpp-devel at lists.r-forge.r-project.org
| https://lists.r-forge.r-project.org/cgi-bin/mailman/listinfo/rcpp-devel

-- 
Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com

------ End of Forwarded Message


From ripley at stats.ox.ac.uk  Thu Apr 21 10:15:50 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 21 Apr 2011 09:15:50 +0100 (BST)
Subject: [Rd] Window binary packages built for R 2.13.0 do not work in
 2.10.0 (was useDynLib in older versions e.g. (2.10))
In-Reply-To: <4DAEC3E2.4070105@chalmers.se>
References: <4DAEC3E2.4070105@chalmers.se>
Message-ID: <alpine.LFD.2.02.1104210859320.20446@gannet.stats.ox.ac.uk>

On Wed, 20 Apr 2011, Tobias Abenius wrote:

> Hi,
>
> Has something changed regarding the useDynLib in the NAMESPACE file in 
> packages?

No.  As the FAQ asked re bug reports, please don't post speculation 
rather than problem description.

> I've written a package that works in e.g. 2.12/2.13 but simply 
> cannot find the dynamic library under windows. The version on CRAN is older 
> than the one I'm talking about and depends on a newer version of R but I want 
> to make the package available to people with older versions.

Do you mean 'make a binary version of the package ....'?
Binary packages are (on all platforms, but specifically on Windows and 
Mac OS X) intended for use only on the same 2.x.[012] versions of R.
That warning was not meant to be ignored!

If you had bothered to read the CHANGES file you would known that the 
location of files on Windows binary installations changed in R 2.12.0: 
of course there is no way that R 2.10.0 (as the posting guide points 
out there is no '2.10') could know that was going to be changed a year 
later.

The solution is for you to prepare a binary package for each version 
of R you want it available with and make it available on your own 
repository.

>> utils:::menuInstallLocal()
> package 'lassoshooting' successfully unpacked and MD5 sums checked
>> require(lassoshooting)
> Loading required package: lassoshooting
> Error in library.dynam(lib, package, package.lib) :
>  shared library 'lassoshooting' not found
> In addition: Warning message:
> package 'lassoshooting' was built under R version 2.13.0
>
> I'm usually under linux and don't know about the gory details of .dll files.
>
> NAMESPACE file
> --------------
> useDynLib(lassoshooting)
> export(lassoshooting)
>
> happy easter!
>
> regards, Tobias
> -- 
> Tobias Abenius
> Ph.D. Student, M.Sc. in Computer Science
>
> Mathematical Statistics
> Mathematical Sciences
> University of Gothenburg
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From tal.galili at gmail.com  Thu Apr 21 10:46:13 2011
From: tal.galili at gmail.com (Tal Galili)
Date: Thu, 21 Apr 2011 11:46:13 +0300
Subject: [Rd] Patching "update.packages" to enable updating of only a
 user defined subset of packages
In-Reply-To: <1303320884065-3463670.post@n4.nabble.com>
References: <BANLkTinvjw3n4QUV+v1m-U9ojdwdh7mBDA@mail.gmail.com>
	<1303320884065-3463670.post@n4.nabble.com>
Message-ID: <BANLkTinDqirQvSYKdoFqsnVG_NB0bGxTFQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110421/4c125acd/attachment.pl>

From ligges at statistik.tu-dortmund.de  Thu Apr 21 11:12:19 2011
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Thu, 21 Apr 2011 11:12:19 +0200
Subject: [Rd] useDynLib in older versions e.g. (2.10)
In-Reply-To: <4DAEC3E2.4070105@chalmers.se>
References: <4DAEC3E2.4070105@chalmers.se>
Message-ID: <4DAFF4F3.1020405@statistik.tu-dortmund.de>



On 20.04.2011 13:30, Tobias Abenius wrote:
> Hi,
>
> Has something changed regarding the useDynLib in the NAMESPACE file in
> packages? I've written a package that works in e.g. 2.12/2.13 but simply
> cannot find the dynamic library under windows. The version on CRAN is
> older than the one I'm talking about and depends on a newer version of R
> but I want to make the package available to people with older versions.
>
>  > utils:::menuInstallLocal()
> package 'lassoshooting' successfully unpacked and MD5 sums checked
>  > require(lassoshooting)
> Loading required package: lassoshooting
> Error in library.dynam(lib, package, package.lib) :
> shared library 'lassoshooting' not found
> In addition: Warning message:
> package 'lassoshooting' was built under R version 2.13.0


Yes, your package was built doe R-2.13.0 but you are using R <= 2.12.0 
where the dll files were located in a different directory.
Hence a) time to upgrade your R version or b) Install the package from 
sources yourself for the (unstated) version of R on your Windows machine.

Uwe Ligges


> I'm usually under linux and don't know about the gory details of .dll
> files.
>
> NAMESPACE file
> --------------
> useDynLib(lassoshooting)
> export(lassoshooting)
>
> happy easter!
>
> regards, Tobias
>
>
> 00install.out
>
>
> * installing *source* package 'lassoshooting' ...
> ** libs
>
> *** arch - i386
> gcc -I"D:/RCompile/recent/R-2.13.0/include"     -I"d:/Rcompile/CRANpkg/extralibs/local/include"     -O3 -Wall  -std=gnu99 -c ccd_common.c -o ccd_common.o
> ccd_common.c: In function 'ccd_common':
> ccd_common.c:118:2: warning: #warning Using R fortran BLAS calls
> gcc -I"D:/RCompile/recent/R-2.13.0/include"     -I"d:/Rcompile/CRANpkg/extralibs/local/include"     -O3 -Wall  -std=gnu99 -c ccd_r.c -o ccd_r.o
> ccd_r.c: In function 'ccd':
> ccd_r.c:163:5: warning: too many arguments for format
> ccd_r.c:156:7: warning: unused variable 'ret'
> ccd_r.c:18:11: warning: 'X' may be used uninitialized in this function
> ccd_r.c:18:14: warning: 'y' may be used uninitialized in this function
> gcc -shared -s -static-libgcc -o lassoshooting.dll tmp.def ccd_common.o ccd_r.o -Ld:/Rcompile/CRANpkg/extralibs/local/lib -LD:/RCompile/recent/R-2.13.0/bin/i386 -lRblas -lgfortran -LD:/RCompile/recent/R-2.13.0/bin/i386 -lR
> installing to d:/RCompile/CRANguest/R-release/lib/lassoshooting/libs/i386
>
> *** arch - x64
> x86_64-w64-mingw32-gcc -I"D:/RCompile/recent/R-2.13.0/include"     -I"d:/Rcompile/CRANpkg/extralibs64new/local/include"     -O2 -Wall  -std=gnu99 -c ccd_common.c -o ccd_common.o
> ccd_common.c: In function 'ccd_common':
> ccd_common.c:118:2: warning: #warning Using R fortran BLAS calls
> x86_64-w64-mingw32-gcc -I"D:/RCompile/recent/R-2.13.0/include"     -I"d:/Rcompile/CRANpkg/extralibs64new/local/include"     -O2 -Wall  -std=gnu99 -c ccd_r.c -o ccd_r.o
> ccd_r.c: In function 'ccd':
> ccd_r.c:163:5: warning: too many arguments for format
> ccd_r.c:156:7: warning: unused variable 'ret'
> ccd_r.c:18:11: warning: 'X' may be used uninitialized in this function
> ccd_r.c:18:14: warning: 'y' may be used uninitialized in this function
> x86_64-w64-mingw32-gcc -shared -s -static-libgcc -o lassoshooting.dll tmp.def ccd_common.o ccd_r.o -Ld:/Rcompile/CRANpkg/extralibs64new/local/lib -LD:/RCompile/recent/R-2.13.0/bin/x64 -lRblas -lgfortran -LD:/RCompile/recent/R-2.13.0/bin/x64 -lR
> installing to d:/RCompile/CRANguest/R-release/lib/lassoshooting/libs/x64
> ** R
> ** preparing package for lazy loading
> ** help
> *** installing help indices
> ** building package indices ...
> ** testing if installed package can be loaded
> * MD5 sums
> packaged installation of 'lassoshooting' as lassoshooting_0.1.3-6.zip
>
> * DONE (lassoshooting)
>
>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From tobias.abenius at chalmers.se  Thu Apr 21 11:30:43 2011
From: tobias.abenius at chalmers.se (Tobias Abenius)
Date: Thu, 21 Apr 2011 11:30:43 +0200
Subject: [Rd] useDynLib in older versions e.g. (2.10)
In-Reply-To: <4DAEC3E2.4070105@chalmers.se>
References: <4DAEC3E2.4070105@chalmers.se>
Message-ID: <4DAFF943.6040801@chalmers.se>

Dear R-devel,

I investigated further by tracing into library.dynam.
The .dll file export a symbol "ccd". In e.g. R 2.8.1 the following 
command succeeds,

dyn.load('/Program 
Files/R/R-2.8.1/library/lassoshooting/libs/i386/lassoshooting.dll')

and the external symbol "ccd" becomes available.

However, inside library.dynam it doesn't add i386 to the path because
  .Platform$r_arch is "". One way would be to re-zip the package with a 
copy of the i386 version outside of the i386 directory, directly under 
libs. That would work, but then I know I cannot commit a binary package 
to CRAN. I guess I'm not the only one having this problem.

Happy easter, Tobias
-- 
Tobias Abenius
Ph.D. Student, M.Sc. in Computer Science

Mathematical Statistics
Mathematical Sciences
University of Gothenburg

On 04/20/2011 01:30 PM, Tobias Abenius wrote:
> Hi,
>
> Has something changed regarding the useDynLib in the NAMESPACE file in
> packages? I've written a package that works in e.g. 2.12/2.13 but simply
> cannot find the dynamic library under windows. The version on CRAN is
> older than the one I'm talking about and depends on a newer version of R
> but I want to make the package available to people with older versions.
>
>  > utils:::menuInstallLocal()
> package 'lassoshooting' successfully unpacked and MD5 sums checked
>  > require(lassoshooting)
> Loading required package: lassoshooting
> Error in library.dynam(lib, package, package.lib) :
> shared library 'lassoshooting' not found
> In addition: Warning message:
> package 'lassoshooting' was built under R version 2.13.0
>
> I'm usually under linux and don't know about the gory details of .dll
> files.
>
> NAMESPACE file
> --------------
> useDynLib(lassoshooting)
> export(lassoshooting)

From ligges at statistik.tu-dortmund.de  Thu Apr 21 11:54:40 2011
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Thu, 21 Apr 2011 11:54:40 +0200
Subject: [Rd] useDynLib in older versions e.g. (2.10)
In-Reply-To: <4DAFF943.6040801@chalmers.se>
References: <4DAEC3E2.4070105@chalmers.se> <4DAFF943.6040801@chalmers.se>
Message-ID: <4DAFFEE0.7040208@statistik.tu-dortmund.de>



On 21.04.2011 11:30, Tobias Abenius wrote:
> Dear R-devel,
>
> I investigated further by tracing into library.dynam.
> The .dll file export a symbol "ccd". In e.g. R 2.8.1 the following
> command succeeds,
>
> dyn.load('/Program
> Files/R/R-2.8.1/library/lassoshooting/libs/i386/lassoshooting.dll')
>
> and the external symbol "ccd" becomes available.
>
> However, inside library.dynam it doesn't add i386 to the path because
> .Platform$r_arch is "". One way would be to re-zip the package with a
> copy of the i386 version outside of the i386 directory, directly under
> libs. That would work, but then I know I cannot commit a binary package
> to CRAN. I guess I'm not the only one having this problem.
>
> Happy easter, Tobias


I think you are mislead:
CRAN accepts source packages only. Binaries are made by CRAN (or more 
particular by myself in Dortmund). For new packages or updates as of 
today, we make binaries for R-2.12.x and R-2.13.x available. Note that 
between major releases of R, you cannot assume that packages will work. 
The help system changed in R-2.10.x (and no binaries are compatible 
before vs. after the R-2.10.0 version) and the location of libraries in 
R-2.12.x changed under Windows.

If you need a binary for R-2.8.x, you will have to INSTALL from sources 
with R-2.8.x, otherwise we cannot guarantee compatibility. Note that 
R-2.8.1 is unsupported and 5 major releases back!

Uwe Ligges


From Bernhard_Pfaff at fra.invesco.com  Thu Apr 21 12:44:45 2011
From: Bernhard_Pfaff at fra.invesco.com (Pfaff, Bernhard Dr.)
Date: Thu, 21 Apr 2011 11:44:45 +0100
Subject: [Rd] R CMD Sweave versus Sweave() on Windows
Message-ID: <B89F0CE41D45644A97CCC93DF548C1C3285775E1@GBHENXMB02.corp.amvescap.net>

Dear list subscriber,

I am quite puzzled by the behaviour of processing Sweave files within an R session, i.e. 
Sweave("foo.Rnw") versus R CMD Sweave foo.Rnw

In the former the environmental variable 'SWEAVE_STYLEPATH_DEFAULT = TRUE' is obeyed (this is set in etc/Renviron.site as well as under the users home directory in .Renviron). That is the hard-coded path to Sweave.sty is included in the resultant tex-file, whereas if the Sweave file is processed from cmd.exe as R CMD Sweave foo.Rnw, only \usepackage{Sweave} is included. 

Any pointers are much appreciated.
Best,
Bernhard

Output of sessionInfo():
> sessionInfo()
R version 2.13.0 (2011-04-13)
Platform: i386-pc-mingw32/i386 (32-bit)

locale:
[1] LC_COLLATE=German_Germany.1252  LC_CTYPE=German_Germany.1252   
[3] LC_MONETARY=German_Germany.1252 LC_NUMERIC=C                   
[5] LC_TIME=German_Germany.1252    

attached base packages:
[1] stats     graphics  datasets  grDevices utils     methods   base     

other attached packages:
[1] fortunes_1.4-1


Dr. Bernhard Pfaff
Director
Global Asset Allocation

Invesco Asset Management Deutschland GmbH
An der Welle 5
D-60322 Frankfurt am Main

Tel: +49 (0)69 29807 230
Fax: +49 (0)69 29807 178
www.institutional.invesco.com
Email: bernhard_pfaff at fra.invesco.com

Gesch?ftsf?hrer: Karl Georg Bayer, Bernhard Langer, Dr. Jens Langewand, Alexander Lehmann, Christian Puschmann
Handelsregister: Frankfurt am Main, HRB 28469
Sitz der Gesellschaft: Frankfurt am Main

 
*****************************************************************
Confidentiality Note: The information contained in this ...{{dropped:10}}


From murdoch.duncan at gmail.com  Thu Apr 21 13:16:03 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 21 Apr 2011 07:16:03 -0400
Subject: [Rd] FW: [Rcpp-devel] Question on 5.6 Interfacing C++ code
In-Reply-To: <C9D47520.3D72%sean.mcguffee@gmail.com>
References: <C9D47520.3D72%sean.mcguffee@gmail.com>
Message-ID: <4DB011F3.80603@gmail.com>

On 11-04-20 11:33 AM, Sean Robert McGuffee wrote:
> Hi, apparently I sent my question about using R and C++ to the wrong list,
> ironically seeing as that list was called Rcpp. Anyway, I was directed to
> post my question here. To summarize my current question, I have found two
> commands that I want to be able to put into a package. The commands are 'R
> CMD SHLIB X.cc X_main.cc' and
> 'dyn.load(paste("X",.Platform$dynlib.ext,sep="")),' which I would like to
> run when my package is installed and maybe have the second command run again
> when my package is to be used. I've been trying to figure out the
> documentation and learn through examples, but I'm just not getting it and
> have been trying for weeks.
> Does anyone on this site have any suggestions for me?

Assuming those lines work on their own, just do the following:

1.  Put those *.cc files into the src directory of your package.  (You 
may need to create it.)

2.  Put useDynLib(foo) into the NAMESPACE file of your foo package.

3.  Call those functions using .C("X", args, PACKAGE="foo").

That's it.

Duncan Murdoch

> Thanks, Sean
>
> |On 20 April 2011 at 10:20, Sean Robert McGuffee wrote:
> |
> |
> | Hi, thanks!
> |
> |>On 4/20/11 10:03 AM, "Steve Lianoglou"<mailinglist.honeypot at gmail.com>
> wrote:
> |>  Hi,
> |>
> |>  On Wed, Apr 20, 2011 at 9:49 AM, Sean Robert McGuffee
> |>  <sean.mcguffee at gmail.com>  wrote:
> |>>  Hi, I have a quick couple of questions about some of the documentation
> on
> |>>  the web page:
> |>>
> http://cran.r-project.org/doc/manuals/R-exts.html#Linking-GUIs-and-other-fro
> n
> |>>  t_002dends-to-R
> |>>  under the heading:
> |>>  5.6 Interfacing C++ code
> |>>
> |>>  Question 1:
> |>>  If I?m at a terminal, I can type the instructions they suggest:
> |>>  R CMD SHLIB X.cc X_main.cc
> |>>  If I wanted a package to do this, how would I tell the package to do
> that
> |>>  same thing?
> |>
> |>  Just to make sure we're all on the same page, you want an R package to
> |>  compile some source code into a shared library/dll from inside R?
> |>
> |>  Not sure if there's a "baked in" way for that to happen, but maybe you
> |>  can invoke `R CMD WHATEVER` from inside R using the `system` function:
> |>
> |>  R>  ?system
> |>
> |
> | ok, so where in the package would I put the system call in the package to
> | have it run when installing the package?
>
>> You don't. As I said, 'R CMD INSTALL' et all do that.
>> Download an existing package with source, install it.  Study its sources,
>> study the 'Writing R Extensions' manual.  Ask on r-devel.
>> Basic R questions are off-topic here.
>
> |>>  Would I use the same command and just include it in a file somewhere in
> the
> |>>  package?
> |>>  If so, which file?
> |>
> |>  Hmm ... I'm curious what you're trying to do, exactly?
> |
> | I'm trying to figure out how take commands such as " R CMD SHLIB X.cc
> | X_main.cc" followed by "dyn.load(paste("X", .Platform$dynlib.ext, sep =
> | ""))," which are commands I can get to work for myself as a human
> | interactively, and put the commands into a package to be automatically run
> | when installing the package. I mean, it's great if I can compile a c++
> file
> | and then use it inside R, but I'm only doing that so I can let other
> people
> | do that via a package. As much as I read this documentation, I keep
> missing
>
>> Again, I like working from an existing, working package. As I said, there are
>> almost 1000 to pick from.
>> Please direct follow-ups that have no bearing on Rcpp to r-devel.
>> Dirk
>
> I've tried to figure this out for weeks by looking at other packages and
> reading the confusing and nonintegrated documentation, but it hasn't taught
> me how to put the two commands into a package so that they are run when the
> package is installed. I'm simply trying to find out where in my package I
> should put the commands 'R CMD SHLIB X.cc X_main.cc' and
> 'dyn.load(paste("X",.Platform$dynlib.ext,sep="")),'
> in order to have them run when my package is installed.
>
>
> | the connections between the different sections. This is a section I am
> | loving because it works very well. Thus, I want to figure out how to take
> | the baby steps I'm doing and combine them into a package. Specifically, I
> | want to take these two commands and insert them into a package so that
> these
> | commands will compile my code and make a dynamic ".so" file where R can
> | access its functions when others install my package.
> |
> |>
> |>>  Question 2:
> |>>  dyn.load(paste("X", .Platform$dynlib.ext, sep = ""))
> |>>
> |>>  Where does .Platform$dynlib.ext come from?
> |>>  What does it mean?
> |>>  What do it?s components .Platform and $dynlib and .ext mean?
> |>
> |>  .Platform is lust a normal list -- it is defined internally (I guess).
> |>  You can access "named" elements of a list with `$`.
> |>
> |>  .Platform$dynlyb (or .Platform[['dynlib']]) tells you the extension
> |>  your particular system uses for shared libraries:
> |>
> |>  R>  .Platform
> |>  $OS.type
> |>  [1] "unix"
> |>
> |>  $file.sep
> |>  [1] "/"
> |>
> |>  $dynlib.ext
> |>  [1] ".so"
> |>
> |>  $GUI
> |>  [1] "X11"
> |>
> |>  $endian
> |>  [1] "little"
> |>
> |>  $pkgType
> |>  [1] "mac.binary.leopard"
> |>
> |>  $path.sep
> |>  [1] ":"
> |>
> |>  $r_arch
> |>  [1] "x86_64"
> |>
> |>  See ?.Platform for more help.
> |
> | Ah, thanks, that clarifies exactly what .Platform$dynlib.ext is, it's
> ".so"
> | on my system.
> |
> | This, the dyn.load(paste("X", .Platform$dynlib.ext, sep = "")) is
> equivalent
> | to the command dyn.load("X.so) which now makes sense in that context!
> |
> |
> | _______________________________________________
> | Rcpp-devel mailing list
> | Rcpp-devel at lists.r-forge.r-project.org
> | https://lists.r-forge.r-project.org/cgi-bin/mailman/listinfo/rcpp-devel
>


From kasperdanielhansen at gmail.com  Thu Apr 21 13:45:24 2011
From: kasperdanielhansen at gmail.com (Kasper Daniel Hansen)
Date: Thu, 21 Apr 2011 07:45:24 -0400
Subject: [Rd] R CMD Sweave versus Sweave() on Windows
In-Reply-To: <B89F0CE41D45644A97CCC93DF548C1C3285775E1@GBHENXMB02.corp.amvescap.net>
References: <B89F0CE41D45644A97CCC93DF548C1C3285775E1@GBHENXMB02.corp.amvescap.net>
Message-ID: <BANLkTikoh5t-+Ny51tCb5PUJNem9RS9Qsw@mail.gmail.com>

Bernd

.Renviron is not being read when you do R CMD ...  This is documented,
but still puzzling to me.  I solved this by using
  Sys.setenv("SWEAVE_STYLEPATH_DEFAULT" = "TRUE")
in my .Rprofile (which is being read by R CMD ...).  If you were on
linux you could also put it inside your shell profile (like ,.bashrc).

Kasper

On Thu, Apr 21, 2011 at 6:44 AM, Pfaff, Bernhard Dr.
<Bernhard_Pfaff at fra.invesco.com> wrote:
> Dear list subscriber,
>
> I am quite puzzled by the behaviour of processing Sweave files within an R session, i.e.
> Sweave("foo.Rnw") versus R CMD Sweave foo.Rnw
>
> In the former the environmental variable 'SWEAVE_STYLEPATH_DEFAULT = TRUE' is obeyed (this is set in etc/Renviron.site as well as under the users home directory in .Renviron). That is the hard-coded path to Sweave.sty is included in the resultant tex-file, whereas if the Sweave file is processed from cmd.exe as R CMD Sweave foo.Rnw, only \usepackage{Sweave} is included.
>
> Any pointers are much appreciated.
> Best,
> Bernhard
>
> Output of sessionInfo():
>> sessionInfo()
> R version 2.13.0 (2011-04-13)
> Platform: i386-pc-mingw32/i386 (32-bit)
>
> locale:
> [1] LC_COLLATE=German_Germany.1252 ?LC_CTYPE=German_Germany.1252
> [3] LC_MONETARY=German_Germany.1252 LC_NUMERIC=C
> [5] LC_TIME=German_Germany.1252
>
> attached base packages:
> [1] stats ? ? graphics ?datasets ?grDevices utils ? ? methods ? base
>
> other attached packages:
> [1] fortunes_1.4-1
>
>
> Dr. Bernhard Pfaff
> Director
> Global Asset Allocation
>
> Invesco Asset Management Deutschland GmbH
> An der Welle 5
> D-60322 Frankfurt am Main
>
> Tel: +49 (0)69 29807 230
> Fax: +49 (0)69 29807 178
> www.institutional.invesco.com
> Email: bernhard_pfaff at fra.invesco.com
>
> Gesch?ftsf?hrer: Karl Georg Bayer, Bernhard Langer, Dr. Jens Langewand, Alexander Lehmann, Christian Puschmann
> Handelsregister: Frankfurt am Main, HRB 28469
> Sitz der Gesellschaft: Frankfurt am Main
>
>
> *****************************************************************
> Confidentiality Note: The information contained in this ...{{dropped:10}}
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From edd at debian.org  Thu Apr 21 13:49:57 2011
From: edd at debian.org (Dirk Eddelbuettel)
Date: Thu, 21 Apr 2011 06:49:57 -0500
Subject: [Rd] How to get R to compile with PNG support
In-Reply-To: <BANLkTinAtiXhxhSRhEEu0aDZsZuELOQu+g@mail.gmail.com>
References: <BANLkTinAtiXhxhSRhEEu0aDZsZuELOQu+g@mail.gmail.com>
Message-ID: <19888.6629.380047.505281@max.nulle.part>


On 20 April 2011 at 12:16, Karl-Dieter Crisman wrote:
| ++++
| 
| R is now configured for i686-pc-linux-gnu
|  Source directory:          .
|  Installation directory:    /home/sageserver/sage/local
|  C compiler:                gcc -std=gnu99
| -I/home/sageserver/sage/local/include
| -L/home/sageserver/sage/local/lib/   Fortran 77 compiler:
| sage_fortran  -g -O2
|  C++ compiler:              g++  -g -O2
|  Fortran 90/95 compiler:    sage_fortran -g -O2  Obj-C compiler:
|  Interfaces supported:      X11
|  External libraries:        readline, BLAS(ATLAS), LAPACK(generic)
| Additional capabilities:   PNG, NLS
|  Options enabled:           shared R library, R profiling
|  Recommended packages:      yes
| 
| 
| However:
| 
| 
| > capabilities()
|    jpeg      png     tiff    tcltk      X11     aqua http/ftp  sockets
|   FALSE    FALSE    FALSE    FALSE    FALSE    FALSE     TRUE     TRUE
| 
|  libxml     fifo   cledit    iconv      NLS  profmem    cairo
|    TRUE     TRUE     TRUE     TRUE     TRUE    FALSE    FALSE

Random guess: did you connect via ssh without x11 forwarding?

I cannot see how configure find png.h and libpng but the binary fails. As all
other X11 related formats are also shown false, methinks you are without a
valid DISPLAY. 

That is actually an issue related to your headless use---which is what Sage
may default too; see the R FAQ on this and the prior discussion on the
xvfb-run wrapper which 'simulates' an x11 environment (which you need for
png).  So maybe you should revisit the Cairo devices---they allow you
plotting without an x11 device (and also give you SVG).

Dirk

-- 
Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com


From edd at debian.org  Thu Apr 21 13:52:22 2011
From: edd at debian.org (Dirk Eddelbuettel)
Date: Thu, 21 Apr 2011 06:52:22 -0500
Subject: [Rd] FW: [Rcpp-devel] Question on 5.6 Interfacing C++ code
In-Reply-To: <4DB011F3.80603@gmail.com>
References: <C9D47520.3D72%sean.mcguffee@gmail.com> <4DB011F3.80603@gmail.com>
Message-ID: <19888.6774.24607.71449@max.nulle.part>


On 21 April 2011 at 07:16, Duncan Murdoch wrote:
| On 11-04-20 11:33 AM, Sean Robert McGuffee wrote:
| > Hi, apparently I sent my question about using R and C++ to the wrong list,
| > ironically seeing as that list was called Rcpp. Anyway, I was directed to
| > post my question here. To summarize my current question, I have found two
| > commands that I want to be able to put into a package. The commands are 'R
| > CMD SHLIB X.cc X_main.cc' and
| > 'dyn.load(paste("X",.Platform$dynlib.ext,sep="")),' which I would like to
| > run when my package is installed and maybe have the second command run again
| > when my package is to be used. I've been trying to figure out the
| > documentation and learn through examples, but I'm just not getting it and
| > have been trying for weeks.
| > Does anyone on this site have any suggestions for me?
| 
| Assuming those lines work on their own, just do the following:
| 
| 1.  Put those *.cc files into the src directory of your package.  (You 
| may need to create it.)
| 
| 2.  Put useDynLib(foo) into the NAMESPACE file of your foo package.
| 
| 3.  Call those functions using .C("X", args, PACKAGE="foo").
| 
| That's it.

We told Sean this twice or three times already over in this thread 

  http://thread.gmane.org/gmane.comp.lang.r.rcpp/1808

but the message does not seem to sink in.  He keeps asking where to put 'R
CMD SHLIB' and doesn't seem to hear when we say there is none in a package...

Dirk 
 
| Duncan Murdoch
| 
| > Thanks, Sean
| >
| > |On 20 April 2011 at 10:20, Sean Robert McGuffee wrote:
| > |
| > |
| > | Hi, thanks!
| > |
| > |>On 4/20/11 10:03 AM, "Steve Lianoglou"<mailinglist.honeypot at gmail.com>
| > wrote:
| > |>  Hi,
| > |>
| > |>  On Wed, Apr 20, 2011 at 9:49 AM, Sean Robert McGuffee
| > |>  <sean.mcguffee at gmail.com>  wrote:
| > |>>  Hi, I have a quick couple of questions about some of the documentation
| > on
| > |>>  the web page:
| > |>>
| > http://cran.r-project.org/doc/manuals/R-exts.html#Linking-GUIs-and-other-fro
| > n
| > |>>  t_002dends-to-R
| > |>>  under the heading:
| > |>>  5.6 Interfacing C++ code
| > |>>
| > |>>  Question 1:
| > |>>  If I?m at a terminal, I can type the instructions they suggest:
| > |>>  R CMD SHLIB X.cc X_main.cc
| > |>>  If I wanted a package to do this, how would I tell the package to do
| > that
| > |>>  same thing?
| > |>
| > |>  Just to make sure we're all on the same page, you want an R package to
| > |>  compile some source code into a shared library/dll from inside R?
| > |>
| > |>  Not sure if there's a "baked in" way for that to happen, but maybe you
| > |>  can invoke `R CMD WHATEVER` from inside R using the `system` function:
| > |>
| > |>  R>  ?system
| > |>
| > |
| > | ok, so where in the package would I put the system call in the package to
| > | have it run when installing the package?
| >
| >> You don't. As I said, 'R CMD INSTALL' et all do that.
| >> Download an existing package with source, install it.  Study its sources,
| >> study the 'Writing R Extensions' manual.  Ask on r-devel.
| >> Basic R questions are off-topic here.
| >
| > |>>  Would I use the same command and just include it in a file somewhere in
| > the
| > |>>  package?
| > |>>  If so, which file?
| > |>
| > |>  Hmm ... I'm curious what you're trying to do, exactly?
| > |
| > | I'm trying to figure out how take commands such as " R CMD SHLIB X.cc
| > | X_main.cc" followed by "dyn.load(paste("X", .Platform$dynlib.ext, sep =
| > | ""))," which are commands I can get to work for myself as a human
| > | interactively, and put the commands into a package to be automatically run
| > | when installing the package. I mean, it's great if I can compile a c++
| > file
| > | and then use it inside R, but I'm only doing that so I can let other
| > people
| > | do that via a package. As much as I read this documentation, I keep
| > missing
| >
| >> Again, I like working from an existing, working package. As I said, there are
| >> almost 1000 to pick from.
| >> Please direct follow-ups that have no bearing on Rcpp to r-devel.
| >> Dirk
| >
| > I've tried to figure this out for weeks by looking at other packages and
| > reading the confusing and nonintegrated documentation, but it hasn't taught
| > me how to put the two commands into a package so that they are run when the
| > package is installed. I'm simply trying to find out where in my package I
| > should put the commands 'R CMD SHLIB X.cc X_main.cc' and
| > 'dyn.load(paste("X",.Platform$dynlib.ext,sep="")),'
| > in order to have them run when my package is installed.
| >
| >
| > | the connections between the different sections. This is a section I am
| > | loving because it works very well. Thus, I want to figure out how to take
| > | the baby steps I'm doing and combine them into a package. Specifically, I
| > | want to take these two commands and insert them into a package so that
| > these
| > | commands will compile my code and make a dynamic ".so" file where R can
| > | access its functions when others install my package.
| > |
| > |>
| > |>>  Question 2:
| > |>>  dyn.load(paste("X", .Platform$dynlib.ext, sep = ""))
| > |>>
| > |>>  Where does .Platform$dynlib.ext come from?
| > |>>  What does it mean?
| > |>>  What do it?s components .Platform and $dynlib and .ext mean?
| > |>
| > |>  .Platform is lust a normal list -- it is defined internally (I guess).
| > |>  You can access "named" elements of a list with `$`.
| > |>
| > |>  .Platform$dynlyb (or .Platform[['dynlib']]) tells you the extension
| > |>  your particular system uses for shared libraries:
| > |>
| > |>  R>  .Platform
| > |>  $OS.type
| > |>  [1] "unix"
| > |>
| > |>  $file.sep
| > |>  [1] "/"
| > |>
| > |>  $dynlib.ext
| > |>  [1] ".so"
| > |>
| > |>  $GUI
| > |>  [1] "X11"
| > |>
| > |>  $endian
| > |>  [1] "little"
| > |>
| > |>  $pkgType
| > |>  [1] "mac.binary.leopard"
| > |>
| > |>  $path.sep
| > |>  [1] ":"
| > |>
| > |>  $r_arch
| > |>  [1] "x86_64"
| > |>
| > |>  See ?.Platform for more help.
| > |
| > | Ah, thanks, that clarifies exactly what .Platform$dynlib.ext is, it's
| > ".so"
| > | on my system.
| > |
| > | This, the dyn.load(paste("X", .Platform$dynlib.ext, sep = "")) is
| > equivalent
| > | to the command dyn.load("X.so) which now makes sense in that context!
| > |
| > |
| > | _______________________________________________
| > | Rcpp-devel mailing list
| > | Rcpp-devel at lists.r-forge.r-project.org
| > | https://lists.r-forge.r-project.org/cgi-bin/mailman/listinfo/rcpp-devel
| >
| 
| ______________________________________________
| R-devel at r-project.org mailing list
| https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com


From ripley at stats.ox.ac.uk  Thu Apr 21 14:17:22 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 21 Apr 2011 13:17:22 +0100 (BST)
Subject: [Rd] R CMD Sweave versus Sweave() on Windows
In-Reply-To: <B89F0CE41D45644A97CCC93DF548C1C3285775E1@GBHENXMB02.corp.amvescap.net>
References: <B89F0CE41D45644A97CCC93DF548C1C3285775E1@GBHENXMB02.corp.amvescap.net>
Message-ID: <alpine.LFD.2.02.1104211315010.4744@gannet.stats.ox.ac.uk>

On Thu, 21 Apr 2011, Pfaff, Bernhard Dr. wrote:

> Dear list subscriber,
>
> I am quite puzzled by the behaviour of processing Sweave files within an R session, i.e.
> Sweave("foo.Rnw") versus R CMD Sweave foo.Rnw
>
> In the former the environmental variable 'SWEAVE_STYLEPATH_DEFAULT = 
> TRUE' is obeyed (this is set in etc/Renviron.site as well as under 
> the users home directory in .Renviron). That is the hard-coded path 
> to Sweave.sty is included in the resultant tex-file, whereas if the 
> Sweave file is processed from cmd.exe as R CMD Sweave foo.Rnw, only 
> \usepackage{Sweave} is included.
>
> Any pointers are much appreciated.

R CMD Sweave does not read the startup files.  Try runnning 
R --vanilla and Sweave("foo.Rnw"): you will see the same.

> Best,
> Bernhard
>
> Output of sessionInfo():
>> sessionInfo()
> R version 2.13.0 (2011-04-13)
> Platform: i386-pc-mingw32/i386 (32-bit)
>
> locale:
> [1] LC_COLLATE=German_Germany.1252  LC_CTYPE=German_Germany.1252
> [3] LC_MONETARY=German_Germany.1252 LC_NUMERIC=C
> [5] LC_TIME=German_Germany.1252
>
> attached base packages:
> [1] stats     graphics  datasets  grDevices utils     methods   base
>
> other attached packages:
> [1] fortunes_1.4-1
>
>
> Dr. Bernhard Pfaff
> Director
> Global Asset Allocation
>
> Invesco Asset Management Deutschland GmbH
> An der Welle 5
> D-60322 Frankfurt am Main
>
> Tel: +49 (0)69 29807 230
> Fax: +49 (0)69 29807 178
> www.institutional.invesco.com
> Email: bernhard_pfaff at fra.invesco.com
>
> Gesch?ftsf?hrer: Karl Georg Bayer, Bernhard Langer, Dr. Jens Langewand, Alexander Lehmann, Christian Puschmann
> Handelsregister: Frankfurt am Main, HRB 28469
> Sitz der Gesellschaft: Frankfurt am Main
>
>
> *****************************************************************
> Confidentiality Note: The information contained in this ...{{dropped:10}}
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From edd at debian.org  Thu Apr 21 14:44:12 2011
From: edd at debian.org (Dirk Eddelbuettel)
Date: Thu, 21 Apr 2011 07:44:12 -0500
Subject: [Rd] BOOST libraries
In-Reply-To: <BANLkTi=PN3MJuoCrakX79eGMPnf-UCCG5g@mail.gmail.com>
References: <BANLkTi=PN3MJuoCrakX79eGMPnf-UCCG5g@mail.gmail.com>
Message-ID: <19888.9884.820518.522934@max.nulle.part>


(Redirected from r-packages, which is supposed to be an annoucements-only
list, to r-devel which is for R development questions.)

On 21 April 2011 at 08:10, Jay Emerson wrote:
| We have used the BOOST interprocess libraries in package bigmemory
| (and synchronicity, and ...) for about 3 years now.  There is also a

RQuantLib switched to using Boost when QuantLib did in June 2004, or almost
seven years ago.

| plan (more than tentative, but yet to actually happen) to provide a
| package on CRAN that will provide these for more efficient use (having
| multiple copies floating around across separate packages seems silly).
| 
| If you are interested in this, please feel free to email me or Dirk
| (and if you are not aware of Rcpp et. al. you should have a look
| there, too).

Cedric is a list member of rcpp-devel.
 
| >I would like to know whether anyone had experience using the C++ Boost
| >library within an R package, and how portable was the resulting package.

Packages are perfectly portable as that is a main goal of Boost.  So in that
sense the question is misdirected; few things are as 'portable' as Boost.

The issue is more about how to ensure _binary libraries_ are found if needed
for linking.  Boost itself is a (vast) collection of libraries (in the
abstract sense of 'packages'), and only a few employ (binary) libraries. Many
can be used in a pure template sense so that only headers are needed at
compile time. 

That is what Jay refers to above:  we are contemplating creating a common
boost headers package to be used by the half dozen packages shipping their
own copies.

| >I am especially thinking of possible compiling problems on Windows and
| >Apple systems.
| 
| >If anyone had any tips on how to render an R package using Boost
| >portable, that would be very much appreciated.

Back to the issue of finding Boost libraries: you can study existing
packages.  RQuantLib for example needs to use a configure snippet and a
special case on Windows.

But in case you just want to use templates, look at RcppBDT --- an example
package using Rcpp and its 'Rcpp modules' feature to easily access Boost
Date_Time.  It by choise does not use Date Time string parsing and formatting
and hence uses only templated headers---and as such is easily buildable on
Windows, OS X, ... as the CRAN page http://cran.r-project.org/package=RcppBDT
and its links show.

Hope this helps, Dirk

-- 
Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com


From Bernhard_Pfaff at fra.invesco.com  Thu Apr 21 15:04:02 2011
From: Bernhard_Pfaff at fra.invesco.com (Pfaff, Bernhard Dr.)
Date: Thu, 21 Apr 2011 14:04:02 +0100
Subject: [Rd] R CMD Sweave versus Sweave() on Windows
In-Reply-To: <alpine.LFD.2.02.1104211315010.4744@gannet.stats.ox.ac.uk>
References: <B89F0CE41D45644A97CCC93DF548C1C3285775E1@GBHENXMB02.corp.amvescap.net>
	<alpine.LFD.2.02.1104211315010.4744@gannet.stats.ox.ac.uk>
Message-ID: <B89F0CE41D45644A97CCC93DF548C1C3285775E2@GBHENXMB02.corp.amvescap.net>

> 
> On Thu, 21 Apr 2011, Pfaff, Bernhard Dr. wrote:
> 
> > Dear list subscriber,
> >
> > I am quite puzzled by the behaviour of processing Sweave 
> files within an R session, i.e.
> > Sweave("foo.Rnw") versus R CMD Sweave foo.Rnw
> >
> > In the former the environmental variable 
> 'SWEAVE_STYLEPATH_DEFAULT = 
> > TRUE' is obeyed (this is set in etc/Renviron.site as well 
> as under the 
> > users home directory in .Renviron). That is the hard-coded path to 
> > Sweave.sty is included in the resultant tex-file, whereas if the 
> > Sweave file is processed from cmd.exe as R CMD Sweave foo.Rnw, only 
> > \usepackage{Sweave} is included.
> >
> > Any pointers are much appreciated.
> 
> R CMD Sweave does not read the startup files.  Try runnning R 
> --vanilla and Sweave("foo.Rnw"): you will see the same.

Dear Prof. Ripley,

many thanks for your swift reply. This is indeed correct and educative --thanks for this; but now I am kind of curious where this different behaviour compared to version 2.12.0 has been announced or can be found? I have read the NEWS file and the Windows specific NEWS of the latest release, but was not able to find any pointer. That is, if I issue 'R CMD Sweave foo.Rnw' in cmd.exe with R version 2.12.0, the hard-coded path to Sweave.sty is included and hence environmental variables contained in the startup files are read.
Asked differently, is there a way such that R CMD Sweave does read the startup files under R 2.13.0? 

re: Kasper, many thanks for your reply. Incidentally, I have had 'Sys.setenv("SWEAVE_STYLEPATH_DEFAULT" = "TRUE")' directive already included in my .Rprofile, but as Prof. Ripley correcly pointed out, these settings are not taken effect.

Best,
Bernhard  



> 
> > Best,
> > Bernhard
> >
> > Output of sessionInfo():
> >> sessionInfo()
> > R version 2.13.0 (2011-04-13)
> > Platform: i386-pc-mingw32/i386 (32-bit)
> >
> > locale:
> > [1] LC_COLLATE=German_Germany.1252  
> LC_CTYPE=German_Germany.1252 [3] 
> > LC_MONETARY=German_Germany.1252 LC_NUMERIC=C [5] 
> > LC_TIME=German_Germany.1252
> >
> > attached base packages:
> > [1] stats     graphics  datasets  grDevices utils     methods   base
> >
> > other attached packages:
> > [1] fortunes_1.4-1
> >
> >
> > Dr. Bernhard Pfaff
> > Director
> > Global Asset Allocation
> >
> > Invesco Asset Management Deutschland GmbH An der Welle 5
> > D-60322 Frankfurt am Main
> >
> > Tel: +49 (0)69 29807 230
> > Fax: +49 (0)69 29807 178
> > www.institutional.invesco.com
> > Email: bernhard_pfaff at fra.invesco.com
> >
> > Gesch?ftsf?hrer: Karl Georg Bayer, Bernhard Langer, Dr. Jens 
> > Langewand, Alexander Lehmann, Christian Puschmann
> > Handelsregister: Frankfurt am Main, HRB 28469 Sitz der 
> Gesellschaft: 
> > Frankfurt am Main
> >
> >
> > *****************************************************************
> > Confidentiality Note: The information contained in this 
> > ...{{dropped:10}}
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 


From Matt.Shotwell at Vanderbilt.Edu  Thu Apr 21 15:21:37 2011
From: Matt.Shotwell at Vanderbilt.Edu (Matt Shotwell)
Date: Thu, 21 Apr 2011 08:21:37 -0500
Subject: [Rd] How to get R to compile with PNG support
In-Reply-To: <mailman.25.1303207206.22796.r-devel@r-project.org>
References: <mailman.25.1303207206.22796.r-devel@r-project.org>
Message-ID: <4DB02F61.1030001@Vanderbilt.edu>

On 04/19/2011 05:00 AM, r-devel-request at r-project.org wrote:
> Date: Mon, 18 Apr 2011 11:48:40 -0400
> From: Karl-Dieter Crisman<kcrisman at gmail.com>
> To:r-devel at r-project.org
> Cc: Jason Grout<jason.grout at drake.edu>
> Subject: [Rd] How to get R to compile with PNG support
> Message-ID:<BANLkTinQz7eOE7b-GpBRcNRhcY0-bdc4Eg at mail.gmail.com>
> Content-Type: text/plain; charset=windows-1252
>
> Dear R devel list,
>
> Good morning; I'm with the Sage (http://www.sagemath.org) project.
> (Some of you might have seen my talk on this at last summer's useR
> conference).
>
> We have some rudimentary support for using R graphics in various
> cases, which has proved useful to many of our users who want to go
> back and forth between R and other capabilities within Sage.
> Unfortunately, the way we originally implemented this was using the
> png and plot functions in R itself, which perhaps isn't the best
> (i.e., everyone uses ggplot now? but I digress).
>
> That means that when people download a binary of ours, or compile
> their own, whether R's plot and png functions work depends heavily on
> the rather obscure (to users) issue of exactly what headers are
> present on the compiling machine.
>
> Unfortunately, it is*very*  unclear what actually needs to be present!
>   There are innumerable places where this has come up for us, but
> http://trac.sagemath.org/sage_trac/ticket/8868  and
> http://ask.sagemath.org/question/192/compiling-r-with-png-support  are
> two of the current places where people have compiled information.
>
> The FAQ says, "Unless you do not want to view graphs on-screen you
> need ?X11? installed, including its headers and client libraries. For
> recent Fedora distributions it means (at least) ?libX11?,
> ?libX11-devel?, ?libXt? and ?libXt-devel?. On Debian we recommend the
> meta-package ?xorg-dev?. If you really do not want these you will need
> to explicitly configure R without X11, using --with-x=no."
>
> Well, we don't actually need to view graphs on-screen, but we do need
> to be able to generate them and save them (as pngs, for instance) to
> the correct directory in Sage for viewing.  But we have people who've
> tried to do this in Ubuntu, with libpng and xorg-dev installed, and
> the file /usr/include/X11/Xwindows.h exists, but all to no avail.
> There are almost as many solutions people have found as there are
> computers out there, it seems - slight hyperbole, but that's what it
> feels like.
>
> We've posted more than once (I think) to the r-help list, but have
> gotten no useful feedback.  Is there*anywhere*  that the*exact*
> requirements R has for having
>
> capabilities("png")
>    png
> FALSE
>
> come out TRUE are documented?

I had a similar question some time ago. The answer (of course) is in the 
code and configure macros. The main logic is in 
src/main/platform.c::do_capabilities:

     SET_STRING_ELT(ansnames, i, mkChar("png"));
#ifdef HAVE_PNG
# if defined Unix && !defined HAVE_WORKING_CAIRO
     LOGICAL(ans)[i++] = X11;
# else /* Windows */
     LOGICAL(ans)[i++] = TRUE;
# endif
#else
     LOGICAL(ans)[i++] = FALSE;
#endif

-------------------------------

 From m4/R.m4:

if test "${use_libpng}" = yes; then
   AC_CHECK_LIB(z, main, [have_png=yes], [have_png=no])
   if test "${have_png}" = yes; then
     _R_HEADER_PNG
     have_png=${r_cv_header_png_h}
   fi
   if test "${have_png}" = yes; then
     AC_CHECK_LIB(png, png_create_write_struct,
                  [have_png=yes],
                  [have_png=no],
                  [-lz ${LIBS}])
   fi
   if test "${have_png}" = yes; then
     BITMAP_LIBS="${BITMAP_LIBS} -lpng -lz"
     AC_DEFINE(HAVE_PNG, 1,
               [Define if you have the PNG headers and libraries.])
   fi
fi

---------------------------------------

HAVE_WORKING_CAIRO is set by m4/cairo.m4. However, the PNG function 
doesn't consult capabilities("png"). Presumably capabilities("png") is 
sufficient, but you'll have to pick up the trail in the png function to 
find out what's really going on.

I've had good outcomes with cairo.

> Then, not only could we be smarter in how we compile R (currently
> somewhat naively searching for /usr/include/X11/Xwindows.h to
> determine whether we'll try for png support), but we would be able to
> tell users something very precise to do (e.g., apt-get foo) if they
> currently have R without PNG support in Sage.  Again, I emphasize that
> apparently getting xorg-dev doesn't always do the trick.
>
> We do realize that for most people wanting to use just R, it's best to
> download a binary, which will behave nicely; Sage's "batteries
> included" philosophy means that we are asking for more specialized
> info from upstream, and for that I apologize in advance.  I also
> apologize if I said something silly above, because I don't actually
> know what all these files are - I've just looked into enough support
> requests to have a decent idea of what's required.    We are trying
> not to have to parse the makefile to figure all this out, and possibly
> making some mistake there as well.
>
> Thank you SO much for any help with this,
> Karl-Dieter Crisman
> for the Sage team
>
>


-- 
Matthew S Shotwell   Assistant Professor           School of Medicine
                      Department of Biostatistics   Vanderbilt University


From ggrothendieck at gmail.com  Thu Apr 21 15:30:56 2011
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 21 Apr 2011 09:30:56 -0400
Subject: [Rd] R CMD Sweave versus Sweave() on Windows
In-Reply-To: <B89F0CE41D45644A97CCC93DF548C1C3285775E1@GBHENXMB02.corp.amvescap.net>
References: <B89F0CE41D45644A97CCC93DF548C1C3285775E1@GBHENXMB02.corp.amvescap.net>
Message-ID: <BANLkTikyJk73Zk9NrNp_Pr8hV4cxbDkrMQ@mail.gmail.com>

On Thu, Apr 21, 2011 at 6:44 AM, Pfaff, Bernhard Dr.
<Bernhard_Pfaff at fra.invesco.com> wrote:
> Dear list subscriber,
>
> I am quite puzzled by the behaviour of processing Sweave files within an R session, i.e.
> Sweave("foo.Rnw") versus R CMD Sweave foo.Rnw
>
> In the former the environmental variable 'SWEAVE_STYLEPATH_DEFAULT = TRUE' is obeyed (this is set in etc/Renviron.site as well as under the users home directory in .Renviron). That is the hard-coded path to Sweave.sty is included in the resultant tex-file, whereas if the Sweave file is processed from cmd.exe as R CMD Sweave foo.Rnw, only \usepackage{Sweave} is included.
>
> Any pointers are much appreciated.
> Best,
> Bernhard
>
> Output of sessionInfo():
>> sessionInfo()
> R version 2.13.0 (2011-04-13)
> Platform: i386-pc-mingw32/i386 (32-bit)
>
> locale:
> [1] LC_COLLATE=German_Germany.1252 ?LC_CTYPE=German_Germany.1252
> [3] LC_MONETARY=German_Germany.1252 LC_NUMERIC=C
> [5] LC_TIME=German_Germany.1252
>
> attached base packages:
> [1] stats ? ? graphics ?datasets ?grDevices utils ? ? methods ? base
>
> other attached packages:
> [1] fortunes_1.4-1
>

SWEAVE_STYLEPATH_DEFAULT is automatically set in Sweave.bat found here
(its part of the batchfiles distribution but does not require any
other batch file in order to run it):

http://batchfiles.googlecode.com/svn/trunk/Sweave.bat

This was only just added and has not been tested yet but if anyone
would like to try it just put it anywhere on your Windows PATH (or
current directory) and issue a command like this from the Windows
console:

   Sweave myfile.Rnw



-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From kcrisman at gmail.com  Thu Apr 21 15:51:57 2011
From: kcrisman at gmail.com (Karl-Dieter Crisman)
Date: Thu, 21 Apr 2011 09:51:57 -0400
Subject: [Rd] How to get R to compile with PNG support
In-Reply-To: <19888.6629.380047.505281@max.nulle.part>
References: <BANLkTinAtiXhxhSRhEEu0aDZsZuELOQu+g@mail.gmail.com>
	<19888.6629.380047.505281@max.nulle.part>
Message-ID: <BANLkTinfcQJtotd4macXNjfmOxfekaDDEA@mail.gmail.com>

Thanks for your replies, Dirk and Matt.

On Thu, Apr 21, 2011 at 7:49 AM, Dirk Eddelbuettel <edd at debian.org> wrote:
>
> On 20 April 2011 at 12:16, Karl-Dieter Crisman wrote:
> | ++++
> |
> | R is now configured for i686-pc-linux-gnu
> | ?Source directory: ? ? ? ? ?.
> | ?Installation directory: ? ?/home/sageserver/sage/local
> | ?C compiler: ? ? ? ? ? ? ? ?gcc -std=gnu99
> | -I/home/sageserver/sage/local/include
> | -L/home/sageserver/sage/local/lib/ ? Fortran 77 compiler:
> | sage_fortran ?-g -O2
> | ?C++ compiler: ? ? ? ? ? ? ?g++ ?-g -O2
> | ?Fortran 90/95 compiler: ? ?sage_fortran -g -O2 ?Obj-C compiler:
> | ?Interfaces supported: ? ? ?X11
> | ?External libraries: ? ? ? ?readline, BLAS(ATLAS), LAPACK(generic)
> | Additional capabilities: ? PNG, NLS
> | ?Options enabled: ? ? ? ? ? shared R library, R profiling
> | ?Recommended packages: ? ? ?yes
> |
> |
> | However:
> |
> |
> | > capabilities()
> | ? ?jpeg ? ? ?png ? ? tiff ? ?tcltk ? ? ?X11 ? ? aqua http/ftp ?sockets
> | ? FALSE ? ?FALSE ? ?FALSE ? ?FALSE ? ?FALSE ? ?FALSE ? ? TRUE ? ? TRUE
> |
> | ?libxml ? ? fifo ? cledit ? ?iconv ? ? ?NLS ?profmem ? ?cairo
> | ? ?TRUE ? ? TRUE ? ? TRUE ? ? TRUE ? ? TRUE ? ?FALSE ? ?FALSE
>
> Random guess: did you connect via ssh without x11 forwarding?

Almost certainly, yes.  (I am an interlocutor right now for someone
who is actually doing this, my apologies.)
But it's a machine we just ssh into, I'm pretty sure, though it does
serve up web pages.

> I cannot see how configure find png.h and libpng but the binary fails. As all
> other X11 related formats are also shown false, methinks you are without a
> valid DISPLAY.

That is quite likely.  So it sounds like for png() to be set to use
the X11 device, there has to (somewhere) be a visual output -
presumably that is the part LOGICAL(ans)[i++] = X11; in Matt's answer.

> That is actually an issue related to your headless use---which is what Sage
> may default too; see the R FAQ on this and the prior discussion on the
> xvfb-run wrapper which 'simulates' an x11 environment (which you need for
> png). ?So maybe you should revisit the Cairo devices---they allow you
> plotting without an x11 device (and also give you SVG).
>

Yeah, and I saw your SO answer on this (after the fact) as well.

In some sense, we are just trying to get graphics on one machine.
Note that we have installed the cairo devel package on this very
machine, but it's not being picked up - maybe it's looking in the
wrong place?  That is one of the reasons this is confusing.

But in a larger sense, because of Sage's "batteries included"
philosophy (which we know not everyone agrees with!), we would like to
have a one-shot way so that *everyone* will see R graphics, not just
people whose binary happens to have been compiled on a machine that
has X and a display.  If that means adding 22.5 MB to our tarball for
Cairo... maybe, maybe not.

I won't copy Matt's message here, but I appreciate the pointers to
exactly where these things are defined very much - without knowing
where to look, it would be a long slog.   Hopefully we'll have some
success!  Thanks for the replies, and for any other ideas.

Karl-Dieter


From edd at debian.org  Thu Apr 21 16:39:49 2011
From: edd at debian.org (Dirk Eddelbuettel)
Date: Thu, 21 Apr 2011 09:39:49 -0500
Subject: [Rd] How to get R to compile with PNG support
In-Reply-To: <BANLkTinfcQJtotd4macXNjfmOxfekaDDEA@mail.gmail.com>
References: <BANLkTinAtiXhxhSRhEEu0aDZsZuELOQu+g@mail.gmail.com>
	<19888.6629.380047.505281@max.nulle.part>
	<BANLkTinfcQJtotd4macXNjfmOxfekaDDEA@mail.gmail.com>
Message-ID: <19888.16821.533699.499469@max.nulle.part>


On 21 April 2011 at 09:51, Karl-Dieter Crisman wrote:
| Thanks for your replies, Dirk and Matt.

My pleasure. 
 
| On Thu, Apr 21, 2011 at 7:49 AM, Dirk Eddelbuettel <edd at debian.org> wrote:
| > Random guess: did you connect via ssh without x11 forwarding?
| 
| Almost certainly, yes.  (I am an interlocutor right now for someone
| who is actually doing this, my apologies.)
| But it's a machine we just ssh into, I'm pretty sure, though it does
| serve up web pages.
[...]
| In some sense, we are just trying to get graphics on one machine.
| Note that we have installed the cairo devel package on this very
| machine, but it's not being picked up - maybe it's looking in the
| wrong place?  That is one of the reasons this is confusing.

You have to understand that even though this problem may seem urgent and
novel to you and the Sage team, it is actually about as old as the web and R
itself.  In a nutshell, we all (in the people reading r-help and r-devel
sense) have been explaining to folks since the late 1990s that in order to
run png() to 'just create some charts for a webserver' ... you need an X11
server because that is where the font metrics come from. Or else no png for
you.

| But in a larger sense, because of Sage's "batteries included"
| philosophy (which we know not everyone agrees with!), we would like to
| have a one-shot way so that *everyone* will see R graphics, not just
| people whose binary happens to have been compiled on a machine that
| has X and a display.  If that means adding 22.5 MB to our tarball for
| Cairo... maybe, maybe not.

As they say: "There is no such thing as a free lunch."  

Pick an X11 server (to be able to launch the 'xvfb-run' wrapper) for font
metrics, or run something else like Cairo. Neither one is real cheap.  Such
is life.  System such as Sage become so large because having things like this
around on all deployment systems implies (at least to some degree)
replicating fundamental OS level features because they unfortunately have
supply things missing or broken across OSs.

Dirk

-- 
Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com


From simon.urbanek at r-project.org  Thu Apr 21 16:46:56 2011
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Thu, 21 Apr 2011 10:46:56 -0400
Subject: [Rd] How to get R to compile with PNG support
In-Reply-To: <BANLkTinfcQJtotd4macXNjfmOxfekaDDEA@mail.gmail.com>
References: <BANLkTinAtiXhxhSRhEEu0aDZsZuELOQu+g@mail.gmail.com>
	<19888.6629.380047.505281@max.nulle.part>
	<BANLkTinfcQJtotd4macXNjfmOxfekaDDEA@mail.gmail.com>
Message-ID: <9DD0B390-3F3A-4BEE-8368-FE78BDE006FC@r-project.org>


On Apr 21, 2011, at 9:51 AM, Karl-Dieter Crisman wrote:

> Thanks for your replies, Dirk and Matt.
> 
> On Thu, Apr 21, 2011 at 7:49 AM, Dirk Eddelbuettel <edd at debian.org> wrote:
>> 
>> On 20 April 2011 at 12:16, Karl-Dieter Crisman wrote:
>> | ++++
>> |
>> | R is now configured for i686-pc-linux-gnu
>> |  Source directory:          .
>> |  Installation directory:    /home/sageserver/sage/local
>> |  C compiler:                gcc -std=gnu99
>> | -I/home/sageserver/sage/local/include
>> | -L/home/sageserver/sage/local/lib/   Fortran 77 compiler:
>> | sage_fortran  -g -O2
>> |  C++ compiler:              g++  -g -O2
>> |  Fortran 90/95 compiler:    sage_fortran -g -O2  Obj-C compiler:
>> |  Interfaces supported:      X11
>> |  External libraries:        readline, BLAS(ATLAS), LAPACK(generic)
>> | Additional capabilities:   PNG, NLS
>> |  Options enabled:           shared R library, R profiling
>> |  Recommended packages:      yes
>> |
>> |
>> | However:
>> |
>> |
>> | > capabilities()
>> |    jpeg      png     tiff    tcltk      X11     aqua http/ftp  sockets
>> |   FALSE    FALSE    FALSE    FALSE    FALSE    FALSE     TRUE     TRUE
>> |
>> |  libxml     fifo   cledit    iconv      NLS  profmem    cairo
>> |    TRUE     TRUE     TRUE     TRUE     TRUE    FALSE    FALSE
>> 
>> Random guess: did you connect via ssh without x11 forwarding?
> 
> Almost certainly, yes.  (I am an interlocutor right now for someone
> who is actually doing this, my apologies.)
> But it's a machine we just ssh into, I'm pretty sure, though it does
> serve up web pages.
> 
>> I cannot see how configure find png.h and libpng but the binary fails. As all
>> other X11 related formats are also shown false, methinks you are without a
>> valid DISPLAY.
> 
> That is quite likely.  So it sounds like for png() to be set to use
> the X11 device, there has to (somewhere) be a visual output -
> presumably that is the part LOGICAL(ans)[i++] = X11; in Matt's answer.
> 
>> That is actually an issue related to your headless use---which is what Sage
>> may default too; see the R FAQ on this and the prior discussion on the
>> xvfb-run wrapper which 'simulates' an x11 environment (which you need for
>> png).  So maybe you should revisit the Cairo devices---they allow you
>> plotting without an x11 device (and also give you SVG).
>> 
> 
> Yeah, and I saw your SO answer on this (after the fact) as well.
> 
> In some sense, we are just trying to get graphics on one machine.
> Note that we have installed the cairo devel package on this very
> machine, but it's not being picked up - maybe it's looking in the
> wrong place?  That is one of the reasons this is confusing.
> 
> But in a larger sense, because of Sage's "batteries included"
> philosophy (which we know not everyone agrees with!), we would like to
> have a one-shot way so that *everyone* will see R graphics, not just
> people whose binary happens to have been compiled on a machine that
> has X and a display.  If that means adding 22.5 MB to our tarball for
> Cairo... maybe, maybe not.
> 

Maybe yes in that case - that's what we do in Mac binaries -- and on Mac users always expect  "batteries included" so we include libcairo statically. (The same applies for R packages like Cairo which provides png support independent of X11).

Cheers,
Simon


> I won't copy Matt's message here, but I appreciate the pointers to
> exactly where these things are defined very much - without knowing
> where to look, it would be a long slog.   Hopefully we'll have some
> success!  Thanks for the replies, and for any other ideas.
> 
> Karl-Dieter
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From sean.mcguffee at gmail.com  Thu Apr 21 16:52:35 2011
From: sean.mcguffee at gmail.com (Sean Robert McGuffee)
Date: Thu, 21 Apr 2011 10:52:35 -0400
Subject: [Rd] FW: [Rcpp-devel] Question on 5.6 Interfacing C++ code
In-Reply-To: <4DB011F3.80603@gmail.com>
Message-ID: <C9D5BCF3.3DC6%sean.mcguffee@gmail.com>

Thanks,
That's great, but I don't know how to determine what foo is. How do I
declare the name of the package?


On 4/21/11 7:16 AM, "Duncan Murdoch" <murdoch.duncan at gmail.com> wrote:

> On 11-04-20 11:33 AM, Sean Robert McGuffee wrote:
>> Hi, apparently I sent my question about using R and C++ to the wrong list,
>> ironically seeing as that list was called Rcpp. Anyway, I was directed to
>> post my question here. To summarize my current question, I have found two
>> commands that I want to be able to put into a package. The commands are 'R
>> CMD SHLIB X.cc X_main.cc' and
>> 'dyn.load(paste("X",.Platform$dynlib.ext,sep="")),' which I would like to
>> run when my package is installed and maybe have the second command run again
>> when my package is to be used. I've been trying to figure out the
>> documentation and learn through examples, but I'm just not getting it and
>> have been trying for weeks.
>> Does anyone on this site have any suggestions for me?
> 
> Assuming those lines work on their own, just do the following:
> 
> 1.  Put those *.cc files into the src directory of your package.  (You
> may need to create it.)
> 
> 2.  Put useDynLib(foo) into the NAMESPACE file of your foo package.
> 
> 3.  Call those functions using .C("X", args, PACKAGE="foo").
> 
> That's it.
> 
> Duncan Murdoch
> 
>> Thanks, Sean
>> 
>> |On 20 April 2011 at 10:20, Sean Robert McGuffee wrote:
>> |
>> |
>> | Hi, thanks!
>> |
>> |>On 4/20/11 10:03 AM, "Steve Lianoglou"<mailinglist.honeypot at gmail.com>
>> wrote:
>> |>  Hi,
>> |>
>> |>  On Wed, Apr 20, 2011 at 9:49 AM, Sean Robert McGuffee
>> |>  <sean.mcguffee at gmail.com>  wrote:
>> |>>  Hi, I have a quick couple of questions about some of the documentation
>> on
>> |>>  the web page:
>> |>>
>> http://cran.r-project.org/doc/manuals/R-exts.html#Linking-GUIs-and-other-fro
>> n
>> |>>  t_002dends-to-R
>> |>>  under the heading:
>> |>>  5.6 Interfacing C++ code
>> |>>
>> |>>  Question 1:
>> |>>  If I?m at a terminal, I can type the instructions they suggest:
>> |>>  R CMD SHLIB X.cc X_main.cc
>> |>>  If I wanted a package to do this, how would I tell the package to do
>> that
>> |>>  same thing?
>> |>
>> |>  Just to make sure we're all on the same page, you want an R package to
>> |>  compile some source code into a shared library/dll from inside R?
>> |>
>> |>  Not sure if there's a "baked in" way for that to happen, but maybe you
>> |>  can invoke `R CMD WHATEVER` from inside R using the `system` function:
>> |>
>> |>  R>  ?system
>> |>
>> |
>> | ok, so where in the package would I put the system call in the package to
>> | have it run when installing the package?
>> 
>>> You don't. As I said, 'R CMD INSTALL' et all do that.
>>> Download an existing package with source, install it.  Study its sources,
>>> study the 'Writing R Extensions' manual.  Ask on r-devel.
>>> Basic R questions are off-topic here.
>> 
>> |>>  Would I use the same command and just include it in a file somewhere in
>> the
>> |>>  package?
>> |>>  If so, which file?
>> |>
>> |>  Hmm ... I'm curious what you're trying to do, exactly?
>> |
>> | I'm trying to figure out how take commands such as " R CMD SHLIB X.cc
>> | X_main.cc" followed by "dyn.load(paste("X", .Platform$dynlib.ext, sep =
>> | ""))," which are commands I can get to work for myself as a human
>> | interactively, and put the commands into a package to be automatically run
>> | when installing the package. I mean, it's great if I can compile a c++
>> file
>> | and then use it inside R, but I'm only doing that so I can let other
>> people
>> | do that via a package. As much as I read this documentation, I keep
>> missing
>> 
>>> Again, I like working from an existing, working package. As I said, there
>>> are
>>> almost 1000 to pick from.
>>> Please direct follow-ups that have no bearing on Rcpp to r-devel.
>>> Dirk
>> 
>> I've tried to figure this out for weeks by looking at other packages and
>> reading the confusing and nonintegrated documentation, but it hasn't taught
>> me how to put the two commands into a package so that they are run when the
>> package is installed. I'm simply trying to find out where in my package I
>> should put the commands 'R CMD SHLIB X.cc X_main.cc' and
>> 'dyn.load(paste("X",.Platform$dynlib.ext,sep="")),'
>> in order to have them run when my package is installed.
>> 
>> 
>> | the connections between the different sections. This is a section I am
>> | loving because it works very well. Thus, I want to figure out how to take
>> | the baby steps I'm doing and combine them into a package. Specifically, I
>> | want to take these two commands and insert them into a package so that
>> these
>> | commands will compile my code and make a dynamic ".so" file where R can
>> | access its functions when others install my package.
>> |
>> |>
>> |>>  Question 2:
>> |>>  dyn.load(paste("X", .Platform$dynlib.ext, sep = ""))
>> |>>
>> |>>  Where does .Platform$dynlib.ext come from?
>> |>>  What does it mean?
>> |>>  What do it?s components .Platform and $dynlib and .ext mean?
>> |>
>> |>  .Platform is lust a normal list -- it is defined internally (I guess).
>> |>  You can access "named" elements of a list with `$`.
>> |>
>> |>  .Platform$dynlyb (or .Platform[['dynlib']]) tells you the extension
>> |>  your particular system uses for shared libraries:
>> |>
>> |>  R>  .Platform
>> |>  $OS.type
>> |>  [1] "unix"
>> |>
>> |>  $file.sep
>> |>  [1] "/"
>> |>
>> |>  $dynlib.ext
>> |>  [1] ".so"
>> |>
>> |>  $GUI
>> |>  [1] "X11"
>> |>
>> |>  $endian
>> |>  [1] "little"
>> |>
>> |>  $pkgType
>> |>  [1] "mac.binary.leopard"
>> |>
>> |>  $path.sep
>> |>  [1] ":"
>> |>
>> |>  $r_arch
>> |>  [1] "x86_64"
>> |>
>> |>  See ?.Platform for more help.
>> |
>> | Ah, thanks, that clarifies exactly what .Platform$dynlib.ext is, it's
>> ".so"
>> | on my system.
>> |
>> | This, the dyn.load(paste("X", .Platform$dynlib.ext, sep = "")) is
>> equivalent
>> | to the command dyn.load("X.so) which now makes sense in that context!
>> |
>> |
>> | _______________________________________________
>> | Rcpp-devel mailing list
>> | Rcpp-devel at lists.r-forge.r-project.org
>> | https://lists.r-forge.r-project.org/cgi-bin/mailman/listinfo/rcpp-devel
>> 
> 


From simon.urbanek at r-project.org  Thu Apr 21 16:57:19 2011
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Thu, 21 Apr 2011 10:57:19 -0400
Subject: [Rd] FW: [Rcpp-devel] Question on 5.6 Interfacing C++ code
In-Reply-To: <C9D5BCF3.3DC6%sean.mcguffee@gmail.com>
References: <C9D5BCF3.3DC6%sean.mcguffee@gmail.com>
Message-ID: <BC806D73-DE3B-424B-8F57-0A2803286439@r-project.org>


On Apr 21, 2011, at 10:52 AM, Sean Robert McGuffee wrote:

> Thanks,
> That's great, but I don't know how to determine what foo is.

It's the name of your package.


> How do I declare the name of the package?
> 

in DESCRIPTION:
Package: name

and the directory of your package has to have the same name - please do read
http://r.research.att.com/man/R-exts.html#Creating-R-packages

Cheers,
Simon


> 
> On 4/21/11 7:16 AM, "Duncan Murdoch" <murdoch.duncan at gmail.com> wrote:
> 
>> On 11-04-20 11:33 AM, Sean Robert McGuffee wrote:
>>> Hi, apparently I sent my question about using R and C++ to the wrong list,
>>> ironically seeing as that list was called Rcpp. Anyway, I was directed to
>>> post my question here. To summarize my current question, I have found two
>>> commands that I want to be able to put into a package. The commands are 'R
>>> CMD SHLIB X.cc X_main.cc' and
>>> 'dyn.load(paste("X",.Platform$dynlib.ext,sep="")),' which I would like to
>>> run when my package is installed and maybe have the second command run again
>>> when my package is to be used. I've been trying to figure out the
>>> documentation and learn through examples, but I'm just not getting it and
>>> have been trying for weeks.
>>> Does anyone on this site have any suggestions for me?
>> 
>> Assuming those lines work on their own, just do the following:
>> 
>> 1.  Put those *.cc files into the src directory of your package.  (You
>> may need to create it.)
>> 
>> 2.  Put useDynLib(foo) into the NAMESPACE file of your foo package.
>> 
>> 3.  Call those functions using .C("X", args, PACKAGE="foo").
>> 
>> That's it.
>> 
>> Duncan Murdoch
>> 
>>> Thanks, Sean
>>> 
>>> |On 20 April 2011 at 10:20, Sean Robert McGuffee wrote:
>>> |
>>> |
>>> | Hi, thanks!
>>> |
>>> |>On 4/20/11 10:03 AM, "Steve Lianoglou"<mailinglist.honeypot at gmail.com>
>>> wrote:
>>> |>  Hi,
>>> |>
>>> |>  On Wed, Apr 20, 2011 at 9:49 AM, Sean Robert McGuffee
>>> |>  <sean.mcguffee at gmail.com>  wrote:
>>> |>>  Hi, I have a quick couple of questions about some of the documentation
>>> on
>>> |>>  the web page:
>>> |>>
>>> http://cran.r-project.org/doc/manuals/R-exts.html#Linking-GUIs-and-other-fro
>>> n
>>> |>>  t_002dends-to-R
>>> |>>  under the heading:
>>> |>>  5.6 Interfacing C++ code
>>> |>>
>>> |>>  Question 1:
>>> |>>  If I?m at a terminal, I can type the instructions they suggest:
>>> |>>  R CMD SHLIB X.cc X_main.cc
>>> |>>  If I wanted a package to do this, how would I tell the package to do
>>> that
>>> |>>  same thing?
>>> |>
>>> |>  Just to make sure we're all on the same page, you want an R package to
>>> |>  compile some source code into a shared library/dll from inside R?
>>> |>
>>> |>  Not sure if there's a "baked in" way for that to happen, but maybe you
>>> |>  can invoke `R CMD WHATEVER` from inside R using the `system` function:
>>> |>
>>> |>  R>  ?system
>>> |>
>>> |
>>> | ok, so where in the package would I put the system call in the package to
>>> | have it run when installing the package?
>>> 
>>>> You don't. As I said, 'R CMD INSTALL' et all do that.
>>>> Download an existing package with source, install it.  Study its sources,
>>>> study the 'Writing R Extensions' manual.  Ask on r-devel.
>>>> Basic R questions are off-topic here.
>>> 
>>> |>>  Would I use the same command and just include it in a file somewhere in
>>> the
>>> |>>  package?
>>> |>>  If so, which file?
>>> |>
>>> |>  Hmm ... I'm curious what you're trying to do, exactly?
>>> |
>>> | I'm trying to figure out how take commands such as " R CMD SHLIB X.cc
>>> | X_main.cc" followed by "dyn.load(paste("X", .Platform$dynlib.ext, sep =
>>> | ""))," which are commands I can get to work for myself as a human
>>> | interactively, and put the commands into a package to be automatically run
>>> | when installing the package. I mean, it's great if I can compile a c++
>>> file
>>> | and then use it inside R, but I'm only doing that so I can let other
>>> people
>>> | do that via a package. As much as I read this documentation, I keep
>>> missing
>>> 
>>>> Again, I like working from an existing, working package. As I said, there
>>>> are
>>>> almost 1000 to pick from.
>>>> Please direct follow-ups that have no bearing on Rcpp to r-devel.
>>>> Dirk
>>> 
>>> I've tried to figure this out for weeks by looking at other packages and
>>> reading the confusing and nonintegrated documentation, but it hasn't taught
>>> me how to put the two commands into a package so that they are run when the
>>> package is installed. I'm simply trying to find out where in my package I
>>> should put the commands 'R CMD SHLIB X.cc X_main.cc' and
>>> 'dyn.load(paste("X",.Platform$dynlib.ext,sep="")),'
>>> in order to have them run when my package is installed.
>>> 
>>> 
>>> | the connections between the different sections. This is a section I am
>>> | loving because it works very well. Thus, I want to figure out how to take
>>> | the baby steps I'm doing and combine them into a package. Specifically, I
>>> | want to take these two commands and insert them into a package so that
>>> these
>>> | commands will compile my code and make a dynamic ".so" file where R can
>>> | access its functions when others install my package.
>>> |
>>> |>
>>> |>>  Question 2:
>>> |>>  dyn.load(paste("X", .Platform$dynlib.ext, sep = ""))
>>> |>>
>>> |>>  Where does .Platform$dynlib.ext come from?
>>> |>>  What does it mean?
>>> |>>  What do it?s components .Platform and $dynlib and .ext mean?
>>> |>
>>> |>  .Platform is lust a normal list -- it is defined internally (I guess).
>>> |>  You can access "named" elements of a list with `$`.
>>> |>
>>> |>  .Platform$dynlyb (or .Platform[['dynlib']]) tells you the extension
>>> |>  your particular system uses for shared libraries:
>>> |>
>>> |>  R>  .Platform
>>> |>  $OS.type
>>> |>  [1] "unix"
>>> |>
>>> |>  $file.sep
>>> |>  [1] "/"
>>> |>
>>> |>  $dynlib.ext
>>> |>  [1] ".so"
>>> |>
>>> |>  $GUI
>>> |>  [1] "X11"
>>> |>
>>> |>  $endian
>>> |>  [1] "little"
>>> |>
>>> |>  $pkgType
>>> |>  [1] "mac.binary.leopard"
>>> |>
>>> |>  $path.sep
>>> |>  [1] ":"
>>> |>
>>> |>  $r_arch
>>> |>  [1] "x86_64"
>>> |>
>>> |>  See ?.Platform for more help.
>>> |
>>> | Ah, thanks, that clarifies exactly what .Platform$dynlib.ext is, it's
>>> ".so"
>>> | on my system.
>>> |
>>> | This, the dyn.load(paste("X", .Platform$dynlib.ext, sep = "")) is
>>> equivalent
>>> | to the command dyn.load("X.so) which now makes sense in that context!
>>> |
>>> |
>>> | _______________________________________________
>>> | Rcpp-devel mailing list
>>> | Rcpp-devel at lists.r-forge.r-project.org
>>> | https://lists.r-forge.r-project.org/cgi-bin/mailman/listinfo/rcpp-devel
>>> 
>> 
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From murdoch.duncan at gmail.com  Thu Apr 21 17:00:32 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 21 Apr 2011 11:00:32 -0400
Subject: [Rd] FW: [Rcpp-devel] Question on 5.6 Interfacing C++ code
In-Reply-To: <C9D5BCF3.3DC6%sean.mcguffee@gmail.com>
References: <C9D5BCF3.3DC6%sean.mcguffee@gmail.com>
Message-ID: <4DB04690.5000101@gmail.com>

On 21/04/2011 10:52 AM, Sean Robert McGuffee wrote:
> Thanks,
> That's great, but I don't know how to determine what foo is. How do I
> declare the name of the package?

See the Writing R Extensions manual, or a tutorial on the topic, e.g. 
the one I gave at UseR 2008, available here:

www.r-project.org/conferences/*useR-2008*/slides/*Murdoch*.pdf
*
*It contains a few things that are no longer true (e.g. you don't need 
Perl any more), but is mostly still accurate.

Duncan Murdoch

> On 4/21/11 7:16 AM, "Duncan Murdoch"<murdoch.duncan at gmail.com>  wrote:
>
> >  On 11-04-20 11:33 AM, Sean Robert McGuffee wrote:
> >>  Hi, apparently I sent my question about using R and C++ to the wrong list,
> >>  ironically seeing as that list was called Rcpp. Anyway, I was directed to
> >>  post my question here. To summarize my current question, I have found two
> >>  commands that I want to be able to put into a package. The commands are 'R
> >>  CMD SHLIB X.cc X_main.cc' and
> >>  'dyn.load(paste("X",.Platform$dynlib.ext,sep="")),' which I would like to
> >>  run when my package is installed and maybe have the second command run again
> >>  when my package is to be used. I've been trying to figure out the
> >>  documentation and learn through examples, but I'm just not getting it and
> >>  have been trying for weeks.
> >>  Does anyone on this site have any suggestions for me?
> >
> >  Assuming those lines work on their own, just do the following:
> >
> >  1.  Put those *.cc files into the src directory of your package.  (You
> >  may need to create it.)
> >
> >  2.  Put useDynLib(foo) into the NAMESPACE file of your foo package.
> >
> >  3.  Call those functions using .C("X", args, PACKAGE="foo").
> >
> >  That's it.
> >
> >  Duncan Murdoch
> >
> >>  Thanks, Sean
> >>
> >>  |On 20 April 2011 at 10:20, Sean Robert McGuffee wrote:
> >>  |
> >>  |
> >>  | Hi, thanks!
> >>  |
> >>  |>On 4/20/11 10:03 AM, "Steve Lianoglou"<mailinglist.honeypot at gmail.com>
> >>  wrote:
> >>  |>   Hi,
> >>  |>
> >>  |>   On Wed, Apr 20, 2011 at 9:49 AM, Sean Robert McGuffee
> >>  |>   <sean.mcguffee at gmail.com>   wrote:
> >>  |>>   Hi, I have a quick couple of questions about some of the documentation
> >>  on
> >>  |>>   the web page:
> >>  |>>
> >>  http://cran.r-project.org/doc/manuals/R-exts.html#Linking-GUIs-and-other-fro
> >>  n
> >>  |>>   t_002dends-to-R
> >>  |>>   under the heading:
> >>  |>>   5.6 Interfacing C++ code
> >>  |>>
> >>  |>>   Question 1:
> >>  |>>   If I?m at a terminal, I can type the instructions they suggest:
> >>  |>>   R CMD SHLIB X.cc X_main.cc
> >>  |>>   If I wanted a package to do this, how would I tell the package to do
> >>  that
> >>  |>>   same thing?
> >>  |>
> >>  |>   Just to make sure we're all on the same page, you want an R package to
> >>  |>   compile some source code into a shared library/dll from inside R?
> >>  |>
> >>  |>   Not sure if there's a "baked in" way for that to happen, but maybe you
> >>  |>   can invoke `R CMD WHATEVER` from inside R using the `system` function:
> >>  |>
> >>  |>   R>   ?system
> >>  |>
> >>  |
> >>  | ok, so where in the package would I put the system call in the package to
> >>  | have it run when installing the package?
> >>
> >>>  You don't. As I said, 'R CMD INSTALL' et all do that.
> >>>  Download an existing package with source, install it.  Study its sources,
> >>>  study the 'Writing R Extensions' manual.  Ask on r-devel.
> >>>  Basic R questions are off-topic here.
> >>
> >>  |>>   Would I use the same command and just include it in a file somewhere in
> >>  the
> >>  |>>   package?
> >>  |>>   If so, which file?
> >>  |>
> >>  |>   Hmm ... I'm curious what you're trying to do, exactly?
> >>  |
> >>  | I'm trying to figure out how take commands such as " R CMD SHLIB X.cc
> >>  | X_main.cc" followed by "dyn.load(paste("X", .Platform$dynlib.ext, sep =
> >>  | ""))," which are commands I can get to work for myself as a human
> >>  | interactively, and put the commands into a package to be automatically run
> >>  | when installing the package. I mean, it's great if I can compile a c++
> >>  file
> >>  | and then use it inside R, but I'm only doing that so I can let other
> >>  people
> >>  | do that via a package. As much as I read this documentation, I keep
> >>  missing
> >>
> >>>  Again, I like working from an existing, working package. As I said, there
> >>>  are
> >>>  almost 1000 to pick from.
> >>>  Please direct follow-ups that have no bearing on Rcpp to r-devel.
> >>>  Dirk
> >>
> >>  I've tried to figure this out for weeks by looking at other packages and
> >>  reading the confusing and nonintegrated documentation, but it hasn't taught
> >>  me how to put the two commands into a package so that they are run when the
> >>  package is installed. I'm simply trying to find out where in my package I
> >>  should put the commands 'R CMD SHLIB X.cc X_main.cc' and
> >>  'dyn.load(paste("X",.Platform$dynlib.ext,sep="")),'
> >>  in order to have them run when my package is installed.
> >>
> >>
> >>  | the connections between the different sections. This is a section I am
> >>  | loving because it works very well. Thus, I want to figure out how to take
> >>  | the baby steps I'm doing and combine them into a package. Specifically, I
> >>  | want to take these two commands and insert them into a package so that
> >>  these
> >>  | commands will compile my code and make a dynamic ".so" file where R can
> >>  | access its functions when others install my package.
> >>  |
> >>  |>
> >>  |>>   Question 2:
> >>  |>>   dyn.load(paste("X", .Platform$dynlib.ext, sep = ""))
> >>  |>>
> >>  |>>   Where does .Platform$dynlib.ext come from?
> >>  |>>   What does it mean?
> >>  |>>   What do it?s components .Platform and $dynlib and .ext mean?
> >>  |>
> >>  |>   .Platform is lust a normal list -- it is defined internally (I guess).
> >>  |>   You can access "named" elements of a list with `$`.
> >>  |>
> >>  |>   .Platform$dynlyb (or .Platform[['dynlib']]) tells you the extension
> >>  |>   your particular system uses for shared libraries:
> >>  |>
> >>  |>   R>   .Platform
> >>  |>   $OS.type
> >>  |>   [1] "unix"
> >>  |>
> >>  |>   $file.sep
> >>  |>   [1] "/"
> >>  |>
> >>  |>   $dynlib.ext
> >>  |>   [1] ".so"
> >>  |>
> >>  |>   $GUI
> >>  |>   [1] "X11"
> >>  |>
> >>  |>   $endian
> >>  |>   [1] "little"
> >>  |>
> >>  |>   $pkgType
> >>  |>   [1] "mac.binary.leopard"
> >>  |>
> >>  |>   $path.sep
> >>  |>   [1] ":"
> >>  |>
> >>  |>   $r_arch
> >>  |>   [1] "x86_64"
> >>  |>
> >>  |>   See ?.Platform for more help.
> >>  |
> >>  | Ah, thanks, that clarifies exactly what .Platform$dynlib.ext is, it's
> >>  ".so"
> >>  | on my system.
> >>  |
> >>  | This, the dyn.load(paste("X", .Platform$dynlib.ext, sep = "")) is
> >>  equivalent
> >>  | to the command dyn.load("X.so) which now makes sense in that context!
> >>  |
> >>  |
> >>  | _______________________________________________
> >>  | Rcpp-devel mailing list
> >>  | Rcpp-devel at lists.r-forge.r-project.org
> >>  | https://lists.r-forge.r-project.org/cgi-bin/mailman/listinfo/rcpp-devel
> >>
> >
>
>


From simon.urbanek at r-project.org  Thu Apr 21 17:09:34 2011
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Thu, 21 Apr 2011 11:09:34 -0400
Subject: [Rd] How to get R to compile with PNG support
In-Reply-To: <BANLkTik8Tr1nucaDUQvNM9socPz6wNhvJg@mail.gmail.com>
References: <BANLkTik8Tr1nucaDUQvNM9socPz6wNhvJg@mail.gmail.com>
Message-ID: <8CA2F126-BCC5-45BB-9E86-8A2BE159F462@r-project.org>


On Apr 20, 2011, at 8:35 AM, Karl-Dieter Crisman wrote:

>> Message: 12
>> Date: Wed, 20 Apr 2011 02:09:23 -0700 (PDT)
>> From: Sharpie <chuck at sharpsteen.net>
>> To: r-devel at r-project.org
>> Subject: Re: [Rd] How to get R to compile with PNG support
>> Message-ID: <1303290563237-3462502.post at n4.nabble.com>
>> Content-Type: text/plain; charset=UTF-8
>> 
>> 
>> Dear R devel list,
>> 
>> Good morning; I'm with the Sage (http://www.sagemath.org) project.
>> (Some of you might have seen my talk on this at last summer's useR
>> conference).
>> 
>> Thanks for stoping by Karl! I have to say that I am a big fan of the Sage
>> project---it is a very good idea and I really appreciate all the time you
>> guys put into it. I may not be able to answer all of your questions
>> concerning PNG support, but hopefully some of the following pointers will be
>> useful.
> 
> Good morning, Charlie et al.,
> 
> Thanks for your words.  We like R, too!  We need to advertise it more,
> and this thread is part of making sure that happens in the long run.
> 
> To the issue at hand.   Our main concern is just not to have to spend
> hours reading the configuration and makefile to figure out exactly
> where things happen.
> 
> 
>>> 
>>> We have some rudimentary support for using R graphics in various
>>> cases, which has proved useful to many of our users who want to go
>>> back and forth between R and other capabilities within Sage.
>>> Unfortunately, the way we originally implemented this was using the
>>> png and plot functions in R itself, which perhaps isn't the best
>>> (i.e., everyone uses ggplot now? but I digress).
>>> 
>> 
>> One important distinction to make is between R graphics functions such as
>> plot and ggplot, and R graphics *devices*, such as png. The devices provide
>> back ends that take the R-level function calls and actually execute the
>> low-level "draw line from a to b, clip to rectangle A, insert left-justified
>> text at x,y" primitives that get written to an output format.
> 
> 
> True.  It's the device enabling that I'm talking about.  We enable
> aqua on Mac, and png on Linux.
> 
> We ignore Cairo, and ignore X11 on Mac because it is too touchy (at
> least, according to the FAQ on this - different weird instructions for
> each type, and of course not everyone has X on Mac).
> 

FWIW this seem a little outdated - all recent OS X come with X11 installed and libcairo is not a problem to build ...


>> Bottom line for Sage is that as long as you implement at least one device
>> function, such as png, your users should be able to call plot, ggplot, and
>> the rest of R's graphics functions to their heart's content, they just won't
>> have a wide selection of output formats.
>> 
> 
> Great.  That is okay with us; we aren't expecting (yet) people to be
> able to save R graphics in various output formats.  Our native
> (matplotlib) graphics, we do expect this.
> 
> 
>>> Then, not only could we be smarter in how we compile R (currently
>>> somewhat naively searching for /usr/include/X11/Xwindows.h to
>>> determine whether we'll try for png support), but we would be able to
>>> tell users something very precise to do (e.g., apt-get foo) if they
>>> currently have R without PNG support in Sage.  Again, I emphasize that
>>> apparently getting xorg-dev doesn't always do the trick.
>>> 
> 
> 
>> In the trac ticket you linked, the configure output shows PNG is enabled
>> (I.E. the library was found) but you may be ending up with no support for an
>> actual png() graphics device due to one of the following
>> 
>>  - configure didn't find Xlib as X11 is not listed under Interfaces
>>  - configure didn't find cairo as it is not listed under Additional
>> capabilities
>> 
>> So, although R has the PNG library that is only useful for writing PNG
>> files. R also needs the Xlib or Cairo libraries to provide drawing
>> primitives that will create the figures those files will contain.
> 
> Gotcha.  I suspect that the X11 not listed under Interfaces is the
> problem (again, we ignore Cairo).
> 
> What is the *exact* file or directory that the R configure looks for
> in trying to list X11 under Interfaces?   And is there any way around
> this at all?  That is, is there any way for R to create but not
> display a graphic if it has (for instance) png support, like the one
> on the Trac ticket did?  We can always just search for the png file
> and serve it up in our own viewers.
> 
> Note that we already search for /usr/include/X11/Xwindows.h, and
> adding xorg-dev didn't help with the latest one (which may not be on
> the Trac ticket).
> 

I missed which distro you're using, but xorg-dev is likely insufficient (by design). For example on Debian you'll also need libxt-dev. Note that your best friend is config.log and the output of configure - that tells *exactly* what you're missing. You will need at least X11, ICE, Xt libraries and X11/Intrinsic.h headers. 

Cheers,
Simon


>> In the ask.sagemath question the problem appears to be that the user had X11
>> installed but not libpng.
> 
> Yes, I just referenced that for reference, as it were.
> 
> Thank you, and I hope we can get this resolved!
> 
> Karl-Dieter
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From sean.mcguffee at gmail.com  Thu Apr 21 17:16:39 2011
From: sean.mcguffee at gmail.com (Sean Robert McGuffee)
Date: Thu, 21 Apr 2011 11:16:39 -0400
Subject: [Rd] FW: [Rcpp-devel] Question on 5.6 Interfacing C++ code
In-Reply-To: <19888.6774.24607.71449@max.nulle.part>
Message-ID: <C9D5C297.3DCA%sean.mcguffee@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110421/590f666b/attachment.pl>

From sean.mcguffee at gmail.com  Thu Apr 21 17:17:19 2011
From: sean.mcguffee at gmail.com (Sean Robert McGuffee)
Date: Thu, 21 Apr 2011 11:17:19 -0400
Subject: [Rd] FW: [Rcpp-devel] Question on 5.6 Interfacing C++ code
In-Reply-To: <BC806D73-DE3B-424B-8F57-0A2803286439@r-project.org>
Message-ID: <C9D5C2BF.3DCC%sean.mcguffee@gmail.com>


Ah, that's simple, thanks!

On 4/21/11 10:57 AM, "Simon Urbanek" <simon.urbanek at r-project.org> wrote:

> 
> On Apr 21, 2011, at 10:52 AM, Sean Robert McGuffee wrote:
> 
>> Thanks,
>> That's great, but I don't know how to determine what foo is.
> 
> It's the name of your package.
> 
> 
>> How do I declare the name of the package?
>> 
> 
> in DESCRIPTION:
> Package: name
> 
> and the directory of your package has to have the same name - please do read
> http://r.research.att.com/man/R-exts.html#Creating-R-packages
> 
> Cheers,
> Simon
> 
> 
>> 
>> On 4/21/11 7:16 AM, "Duncan Murdoch" <murdoch.duncan at gmail.com> wrote:
>> 
>>> On 11-04-20 11:33 AM, Sean Robert McGuffee wrote:
>>>> Hi, apparently I sent my question about using R and C++ to the wrong list,
>>>> ironically seeing as that list was called Rcpp. Anyway, I was directed to
>>>> post my question here. To summarize my current question, I have found two
>>>> commands that I want to be able to put into a package. The commands are 'R
>>>> CMD SHLIB X.cc X_main.cc' and
>>>> 'dyn.load(paste("X",.Platform$dynlib.ext,sep="")),' which I would like to
>>>> run when my package is installed and maybe have the second command run
>>>> again
>>>> when my package is to be used. I've been trying to figure out the
>>>> documentation and learn through examples, but I'm just not getting it and
>>>> have been trying for weeks.
>>>> Does anyone on this site have any suggestions for me?
>>> 
>>> Assuming those lines work on their own, just do the following:
>>> 
>>> 1.  Put those *.cc files into the src directory of your package.  (You
>>> may need to create it.)
>>> 
>>> 2.  Put useDynLib(foo) into the NAMESPACE file of your foo package.
>>> 
>>> 3.  Call those functions using .C("X", args, PACKAGE="foo").
>>> 
>>> That's it.
>>> 
>>> Duncan Murdoch
>>> 
>>>> Thanks, Sean
>>>> 
>>>> |On 20 April 2011 at 10:20, Sean Robert McGuffee wrote:
>>>> |
>>>> |
>>>> | Hi, thanks!
>>>> |
>>>> |>On 4/20/11 10:03 AM, "Steve Lianoglou"<mailinglist.honeypot at gmail.com>
>>>> wrote:
>>>> |>  Hi,
>>>> |>
>>>> |>  On Wed, Apr 20, 2011 at 9:49 AM, Sean Robert McGuffee
>>>> |>  <sean.mcguffee at gmail.com>  wrote:
>>>> |>>  Hi, I have a quick couple of questions about some of the documentation
>>>> on
>>>> |>>  the web page:
>>>> |>>
>>>> 
http://cran.r-project.org/doc/manuals/R-exts.html#Linking-GUIs-and-other-fr>>>>
o
>>>> n
>>>> |>>  t_002dends-to-R
>>>> |>>  under the heading:
>>>> |>>  5.6 Interfacing C++ code
>>>> |>>
>>>> |>>  Question 1:
>>>> |>>  If I?m at a terminal, I can type the instructions they suggest:
>>>> |>>  R CMD SHLIB X.cc X_main.cc
>>>> |>>  If I wanted a package to do this, how would I tell the package to do
>>>> that
>>>> |>>  same thing?
>>>> |>
>>>> |>  Just to make sure we're all on the same page, you want an R package to
>>>> |>  compile some source code into a shared library/dll from inside R?
>>>> |>
>>>> |>  Not sure if there's a "baked in" way for that to happen, but maybe you
>>>> |>  can invoke `R CMD WHATEVER` from inside R using the `system` function:
>>>> |>
>>>> |>  R>  ?system
>>>> |>
>>>> |
>>>> | ok, so where in the package would I put the system call in the package to
>>>> | have it run when installing the package?
>>>> 
>>>>> You don't. As I said, 'R CMD INSTALL' et all do that.
>>>>> Download an existing package with source, install it.  Study its sources,
>>>>> study the 'Writing R Extensions' manual.  Ask on r-devel.
>>>>> Basic R questions are off-topic here.
>>>> 
>>>> |>>  Would I use the same command and just include it in a file somewhere
>>>> in
>>>> the
>>>> |>>  package?
>>>> |>>  If so, which file?
>>>> |>
>>>> |>  Hmm ... I'm curious what you're trying to do, exactly?
>>>> |
>>>> | I'm trying to figure out how take commands such as " R CMD SHLIB X.cc
>>>> | X_main.cc" followed by "dyn.load(paste("X", .Platform$dynlib.ext, sep =
>>>> | ""))," which are commands I can get to work for myself as a human
>>>> | interactively, and put the commands into a package to be automatically
>>>> run
>>>> | when installing the package. I mean, it's great if I can compile a c++
>>>> file
>>>> | and then use it inside R, but I'm only doing that so I can let other
>>>> people
>>>> | do that via a package. As much as I read this documentation, I keep
>>>> missing
>>>> 
>>>>> Again, I like working from an existing, working package. As I said, there
>>>>> are
>>>>> almost 1000 to pick from.
>>>>> Please direct follow-ups that have no bearing on Rcpp to r-devel.
>>>>> Dirk
>>>> 
>>>> I've tried to figure this out for weeks by looking at other packages and
>>>> reading the confusing and nonintegrated documentation, but it hasn't taught
>>>> me how to put the two commands into a package so that they are run when the
>>>> package is installed. I'm simply trying to find out where in my package I
>>>> should put the commands 'R CMD SHLIB X.cc X_main.cc' and
>>>> 'dyn.load(paste("X",.Platform$dynlib.ext,sep="")),'
>>>> in order to have them run when my package is installed.
>>>> 
>>>> 
>>>> | the connections between the different sections. This is a section I am
>>>> | loving because it works very well. Thus, I want to figure out how to take
>>>> | the baby steps I'm doing and combine them into a package. Specifically, I
>>>> | want to take these two commands and insert them into a package so that
>>>> these
>>>> | commands will compile my code and make a dynamic ".so" file where R can
>>>> | access its functions when others install my package.
>>>> |
>>>> |>
>>>> |>>  Question 2:
>>>> |>>  dyn.load(paste("X", .Platform$dynlib.ext, sep = ""))
>>>> |>>
>>>> |>>  Where does .Platform$dynlib.ext come from?
>>>> |>>  What does it mean?
>>>> |>>  What do it?s components .Platform and $dynlib and .ext mean?
>>>> |>
>>>> |>  .Platform is lust a normal list -- it is defined internally (I guess).
>>>> |>  You can access "named" elements of a list with `$`.
>>>> |>
>>>> |>  .Platform$dynlyb (or .Platform[['dynlib']]) tells you the extension
>>>> |>  your particular system uses for shared libraries:
>>>> |>
>>>> |>  R>  .Platform
>>>> |>  $OS.type
>>>> |>  [1] "unix"
>>>> |>
>>>> |>  $file.sep
>>>> |>  [1] "/"
>>>> |>
>>>> |>  $dynlib.ext
>>>> |>  [1] ".so"
>>>> |>
>>>> |>  $GUI
>>>> |>  [1] "X11"
>>>> |>
>>>> |>  $endian
>>>> |>  [1] "little"
>>>> |>
>>>> |>  $pkgType
>>>> |>  [1] "mac.binary.leopard"
>>>> |>
>>>> |>  $path.sep
>>>> |>  [1] ":"
>>>> |>
>>>> |>  $r_arch
>>>> |>  [1] "x86_64"
>>>> |>
>>>> |>  See ?.Platform for more help.
>>>> |
>>>> | Ah, thanks, that clarifies exactly what .Platform$dynlib.ext is, it's
>>>> ".so"
>>>> | on my system.
>>>> |
>>>> | This, the dyn.load(paste("X", .Platform$dynlib.ext, sep = "")) is
>>>> equivalent
>>>> | to the command dyn.load("X.so) which now makes sense in that context!
>>>> |
>>>> |
>>>> | _______________________________________________
>>>> | Rcpp-devel mailing list
>>>> | Rcpp-devel at lists.r-forge.r-project.org
>>>> | https://lists.r-forge.r-project.org/cgi-bin/mailman/listinfo/rcpp-devel
>>>> 
>>> 
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> 
>> 
> 


From josh.m.ulrich at gmail.com  Thu Apr 21 17:21:15 2011
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Thu, 21 Apr 2011 10:21:15 -0500
Subject: [Rd] FW: [Rcpp-devel] Question on 5.6 Interfacing C++ code
In-Reply-To: <C9D5C297.3DCA%sean.mcguffee@gmail.com>
References: <19888.6774.24607.71449@max.nulle.part>
	<C9D5C297.3DCA%sean.mcguffee@gmail.com>
Message-ID: <BANLkTimOXKGN2yUvxF_+-bKZgXQMfOBHHg@mail.gmail.com>

Please, please, please read the documentation before sending more
questions to the list.  You also have the source code, so you can look
at what "R CMD build" and "R CMD INSTALL" are doing.
--
Joshua Ulrich ?| ?FOSS Trading: www.fosstrading.com



On Thu, Apr 21, 2011 at 10:16 AM, Sean Robert McGuffee
<sean.mcguffee at gmail.com> wrote:
>
> So, how is the package turning it's name into those commands?
> Does the installation automatically list the src directory and iteratively
> run a loop over each file and call 'R CMD SHLIB objectOfIterator' ?
> The reason this is so important is because it?s easy to get things to work
> via a terminal command 'R CMD SHLIB someSourceFile.cpp?, so I want to be
> able to take things that work that way and put them inside a package. It
> seems peculiar to me that R needs to access functions through a C wrapper
> too. I?m not sure why it can?t access C++ functions directly. What R is
> doing is over my head because it is calling functions that were not compiled
> into it. I mean, if I want to call a C or C++ function from C++ code, I have
> to convince my compiler that I have a header and all definitions behind the
> declarations in my source files to compile my own programs. I don?t know how
> R works when the program is compiled way in advance and is then somehow
> calling on declarations made later in another place. I think objective C/C++
> allows for this type of thing where you can write code to call something
> that is declared but not yet defined. However, I?m not sure what R is doing?
> Is R doing the same thing a compiler would do and creating it?s own binary
> instructions for the launch of a function, or is it creating a new
> executable and launching that as it?s own application and then somehow
> communicating with it?
> Sean
>
>
> On 4/21/11 7:52 AM, "Dirk Eddelbuettel" <edd at debian.org> wrote:
>
>>
>> On 21 April 2011 at 07:16, Duncan Murdoch wrote:
>> | On 11-04-20 11:33 AM, Sean Robert McGuffee wrote:
>> | > Hi, apparently I sent my question about using R and C++ to the wrong list,
>> | > ironically seeing as that list was called Rcpp. Anyway, I was directed to
>> | > post my question here. To summarize my current question, I have found two
>> | > commands that I want to be able to put into a package. The commands are 'R
>> | > CMD SHLIB X.cc X_main.cc' and
>> | > 'dyn.load(paste("X",.Platform$dynlib.ext,sep="")),' which I would like to
>> | > run when my package is installed and maybe have the second command run
>> again
>> | > when my package is to be used. I've been trying to figure out the
>> | > documentation and learn through examples, but I'm just not getting it and
>> | > have been trying for weeks.
>> | > Does anyone on this site have any suggestions for me?
>> |
>> | Assuming those lines work on their own, just do the following:
>> |
>> | 1. ?Put those *.cc files into the src directory of your package. ?(You
>> | may need to create it.)
>> |
>> | 2. ?Put useDynLib(foo) into the NAMESPACE file of your foo package.
>> |
>> | 3. ?Call those functions using .C("X", args, PACKAGE="foo").
>> |
>> | That's it.
>>
>> We told Sean this twice or three times already over in this thread
>>
>> ? http://thread.gmane.org/gmane.comp.lang.r.rcpp/1808
>>
>> but the message does not seem to sink in. ?He keeps asking where to put 'R
>> CMD SHLIB' and doesn't seem to hear when we say there is none in a package...
>>
>> Dirk
>>
>> | Duncan Murdoch
>> |
>> | > Thanks, Sean
>> | >
>> | > |On 20 April 2011 at 10:20, Sean Robert McGuffee wrote:
>> | > |
>> | > |
>> | > | Hi, thanks!
>> | > |
>> | > |>On 4/20/11 10:03 AM, "Steve Lianoglou"<mailinglist.honeypot at gmail.com>
>> | > wrote:
>> | > |> ?Hi,
>> | > |>
>> | > |> ?On Wed, Apr 20, 2011 at 9:49 AM, Sean Robert McGuffee
>> | > |> ?<sean.mcguffee at gmail.com> ?wrote:
>> | > |>> ?Hi, I have a quick couple of questions about some of the
>> documentation
>> | > on
>> | > |>> ?the web page:
>> | > |>>
>> | >
>> http://cran.r-project.org/doc/manuals/R-exts.html#Linking-GUIs-and-other-fro
>> | > n
>> | > |>> ?t_002dends-to-R
>> | > |>> ?under the heading:
>> | > |>> ?5.6 Interfacing C++ code
>> | > |>>
>> | > |>> ?Question 1:
>> | > |>> ?If I?m at a terminal, I can type the instructions they suggest:
>> | > |>> ?R CMD SHLIB X.cc X_main.cc
>> | > |>> ?If I wanted a package to do this, how would I tell the package to do
>> | > that
>> | > |>> ?same thing?
>> | > |>
>> | > |> ?Just to make sure we're all on the same page, you want an R package to
>> | > |> ?compile some source code into a shared library/dll from inside R?
>> | > |>
>> | > |> ?Not sure if there's a "baked in" way for that to happen, but maybe you
>> | > |> ?can invoke `R CMD WHATEVER` from inside R using the `system` function:
>> | > |>
>> | > |> ?R> ??system
>> | > |>
>> | > |
>> | > | ok, so where in the package would I put the system call in the package
>> to
>> | > | have it run when installing the package?
>> | >
>> | >> You don't. As I said, 'R CMD INSTALL' et all do that.
>> | >> Download an existing package with source, install it. ?Study its sources,
>> | >> study the 'Writing R Extensions' manual. ?Ask on r-devel.
>> | >> Basic R questions are off-topic here.
>> | >
>> | > |>> ?Would I use the same command and just include it in a file somewhere
>> in
>> | > the
>> | > |>> ?package?
>> | > |>> ?If so, which file?
>> | > |>
>> | > |> ?Hmm ... I'm curious what you're trying to do, exactly?
>> | > |
>> | > | I'm trying to figure out how take commands such as " R CMD SHLIB X.cc
>> | > | X_main.cc" followed by "dyn.load(paste("X", .Platform$dynlib.ext, sep =
>> | > | ""))," which are commands I can get to work for myself as a human
>> | > | interactively, and put the commands into a package to be automatically
>> run
>> | > | when installing the package. I mean, it's great if I can compile a c++
>> | > file
>> | > | and then use it inside R, but I'm only doing that so I can let other
>> | > people
>> | > | do that via a package. As much as I read this documentation, I keep
>> | > missing
>> | >
>> | >> Again, I like working from an existing, working package. As I said, there
>> are
>> | >> almost 1000 to pick from.
>> | >> Please direct follow-ups that have no bearing on Rcpp to r-devel.
>> | >> Dirk
>> | >
>> | > I've tried to figure this out for weeks by looking at other packages and
>> | > reading the confusing and nonintegrated documentation, but it hasn't
>> taught
>> | > me how to put the two commands into a package so that they are run when
>> the
>> | > package is installed. I'm simply trying to find out where in my package I
>> | > should put the commands 'R CMD SHLIB X.cc X_main.cc' and
>> | > 'dyn.load(paste("X",.Platform$dynlib.ext,sep="")),'
>> | > in order to have them run when my package is installed.
>> | >
>> | >
>> | > | the connections between the different sections. This is a section I am
>> | > | loving because it works very well. Thus, I want to figure out how to
>> take
>> | > | the baby steps I'm doing and combine them into a package. Specifically,
>> I
>> | > | want to take these two commands and insert them into a package so that
>> | > these
>> | > | commands will compile my code and make a dynamic ".so" file where R can
>> | > | access its functions when others install my package.
>> | > |
>> | > |>
>> | > |>> ?Question 2:
>> | > |>> ?dyn.load(paste("X", .Platform$dynlib.ext, sep = ""))
>> | > |>>
>> | > |>> ?Where does .Platform$dynlib.ext come from?
>> | > |>> ?What does it mean?
>> | > |>> ?What do it?s components .Platform and $dynlib and .ext mean?
>> | > |>
>> | > |> ?.Platform is lust a normal list -- it is defined internally (I guess).
>> | > |> ?You can access "named" elements of a list with `$`.
>> | > |>
>> | > |> ?.Platform$dynlyb (or .Platform[['dynlib']]) tells you the extension
>> | > |> ?your particular system uses for shared libraries:
>> | > |>
>> | > |> ?R> ?.Platform
>> | > |> ?$OS.type
>> | > |> ?[1] "unix"
>> | > |>
>> | > |> ?$file.sep
>> | > |> ?[1] "/"
>> | > |>
>> | > |> ?$dynlib.ext
>> | > |> ?[1] ".so"
>> | > |>
>> | > |> ?$GUI
>> | > |> ?[1] "X11"
>> | > |>
>> | > |> ?$endian
>> | > |> ?[1] "little"
>> | > |>
>> | > |> ?$pkgType
>> | > |> ?[1] "mac.binary.leopard"
>> | > |>
>> | > |> ?$path.sep
>> | > |> ?[1] ":"
>> | > |>
>> | > |> ?$r_arch
>> | > |> ?[1] "x86_64"
>> | > |>
>> | > |> ?See ?.Platform for more help.
>> | > |
>> | > | Ah, thanks, that clarifies exactly what .Platform$dynlib.ext is, it's
>> | > ".so"
>> | > | on my system.
>> | > |
>> | > | This, the dyn.load(paste("X", .Platform$dynlib.ext, sep = "")) is
>> | > equivalent
>> | > | to the command dyn.load("X.so) which now makes sense in that context!
>> | > |
>> | > |
>> | > | _______________________________________________
>> | > | Rcpp-devel mailing list
>> | > | Rcpp-devel at lists.r-forge.r-project.org
>> | > | https://lists.r-forge.r-project.org/cgi-bin/mailman/listinfo/rcpp-devel
>> | >
>> |
>> | ______________________________________________
>> | R-devel at r-project.org mailing list
>> | https://stat.ethz.ch/mailman/listinfo/r-devel
>
>
> ? ? ? ?[[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From sean.mcguffee at gmail.com  Thu Apr 21 17:38:42 2011
From: sean.mcguffee at gmail.com (Sean Robert McGuffee)
Date: Thu, 21 Apr 2011 11:38:42 -0400
Subject: [Rd] FW: [Rcpp-devel] Question on 5.6 Interfacing C++ code
In-Reply-To: <BANLkTimOXKGN2yUvxF_+-bKZgXQMfOBHHg@mail.gmail.com>
Message-ID: <C9D5C7C2.3DD0%sean.mcguffee@gmail.com>

You are right, I looked and I did find the R source code. However, it's
largely written in R! I mean, I don't know how to trace the R code where
INSTALL is recognized and follow it to a c or c++ level command. For example
these are hits in .R files, not c files, and I don't know how to connect
what they do to c or c++ commands that I might understand:
R-2.13.0/src/:$grep '"INSTALL"' */*/*/*
library/tools/R/check.R:            args <- c("INSTALL", "-l",
shQuote(libdir), INSTALL_opts,
library/tools/R/install.R:                     "INSTALL", "--no-multiarch")
library/tools/R/install.R:                         "INSTALL",
"--no-multiarch")
library/utils/R/packages2.R:        if(!file.exists(file.path(R.home("bin"),
"INSTALL")))
in a c file that does recognize install, it runs a separate command, and I
have no idea how to trace that command to a c or c++ source code:
if (!strcmp(argv[cmdarg], "INSTALL")) {
    snprintf(cmd, CMD_LEN,
         "%s/%s/Rterm.exe -e tools:::.install_packages() R_DEFAULT_PACKAGES=
LC_COLLATE=C --no-restore --slave --args ",
         getRHOME(3), BINDIR);
    PROCESS_CMD("nextArg");
    }
If you could point me to the functions that are called a c or c++ level, I'd
love to see what R is doing for myself.
Thanks!
Sean


On 4/21/11 11:21 AM, "Joshua Ulrich" <josh.m.ulrich at gmail.com> wrote:

> Please, please, please read the documentation before sending more
> questions to the list.  You also have the source code, so you can look
> at what "R CMD build" and "R CMD INSTALL" are doing.
> --
> Joshua Ulrich ?| ?FOSS Trading: www.fosstrading.com
> 
> 
> 
> On Thu, Apr 21, 2011 at 10:16 AM, Sean Robert McGuffee
> <sean.mcguffee at gmail.com> wrote:
>> 
>> So, how is the package turning it's name into those commands?
>> Does the installation automatically list the src directory and iteratively
>> run a loop over each file and call 'R CMD SHLIB objectOfIterator' ?
>> The reason this is so important is because it?s easy to get things to work
>> via a terminal command 'R CMD SHLIB someSourceFile.cpp?, so I want to be
>> able to take things that work that way and put them inside a package. It
>> seems peculiar to me that R needs to access functions through a C wrapper
>> too. I?m not sure why it can?t access C++ functions directly. What R is
>> doing is over my head because it is calling functions that were not compiled
>> into it. I mean, if I want to call a C or C++ function from C++ code, I have
>> to convince my compiler that I have a header and all definitions behind the
>> declarations in my source files to compile my own programs. I don?t know how
>> R works when the program is compiled way in advance and is then somehow
>> calling on declarations made later in another place. I think objective C/C++
>> allows for this type of thing where you can write code to call something
>> that is declared but not yet defined. However, I?m not sure what R is doing?
>> Is R doing the same thing a compiler would do and creating it?s own binary
>> instructions for the launch of a function, or is it creating a new
>> executable and launching that as it?s own application and then somehow
>> communicating with it?
>> Sean
>> 
>> 
>> On 4/21/11 7:52 AM, "Dirk Eddelbuettel" <edd at debian.org> wrote:
>> 
>>> 
>>> On 21 April 2011 at 07:16, Duncan Murdoch wrote:
>>> | On 11-04-20 11:33 AM, Sean Robert McGuffee wrote:
>>> | > Hi, apparently I sent my question about using R and C++ to the wrong
>>> list,
>>> | > ironically seeing as that list was called Rcpp. Anyway, I was directed
>>> to
>>> | > post my question here. To summarize my current question, I have found
>>> two
>>> | > commands that I want to be able to put into a package. The commands are
>>> 'R
>>> | > CMD SHLIB X.cc X_main.cc' and
>>> | > 'dyn.load(paste("X",.Platform$dynlib.ext,sep="")),' which I would like
>>> to
>>> | > run when my package is installed and maybe have the second command run
>>> again
>>> | > when my package is to be used. I've been trying to figure out the
>>> | > documentation and learn through examples, but I'm just not getting it
>>> and
>>> | > have been trying for weeks.
>>> | > Does anyone on this site have any suggestions for me?
>>> |
>>> | Assuming those lines work on their own, just do the following:
>>> |
>>> | 1. ?Put those *.cc files into the src directory of your package. ?(You
>>> | may need to create it.)
>>> |
>>> | 2. ?Put useDynLib(foo) into the NAMESPACE file of your foo package.
>>> |
>>> | 3. ?Call those functions using .C("X", args, PACKAGE="foo").
>>> |
>>> | That's it.
>>> 
>>> We told Sean this twice or three times already over in this thread
>>> 
>>> ? http://thread.gmane.org/gmane.comp.lang.r.rcpp/1808
>>> 
>>> but the message does not seem to sink in. ?He keeps asking where to put 'R
>>> CMD SHLIB' and doesn't seem to hear when we say there is none in a
>>> package...
>>> 
>>> Dirk
>>> 
>>> | Duncan Murdoch
>>> |
>>> | > Thanks, Sean
>>> | >
>>> | > |On 20 April 2011 at 10:20, Sean Robert McGuffee wrote:
>>> | > |
>>> | > |
>>> | > | Hi, thanks!
>>> | > |
>>> | > |>On 4/20/11 10:03 AM, "Steve Lianoglou"<mailinglist.honeypot at gmail.com>
>>> | > wrote:
>>> | > |> ?Hi,
>>> | > |>
>>> | > |> ?On Wed, Apr 20, 2011 at 9:49 AM, Sean Robert McGuffee
>>> | > |> ?<sean.mcguffee at gmail.com> ?wrote:
>>> | > |>> ?Hi, I have a quick couple of questions about some of the
>>> documentation
>>> | > on
>>> | > |>> ?the web page:
>>> | > |>>
>>> | >
>>> http://cran.r-project.org/doc/manuals/R-exts.html#Linking-GUIs-and-other-fro
>>> | > n
>>> | > |>> ?t_002dends-to-R
>>> | > |>> ?under the heading:
>>> | > |>> ?5.6 Interfacing C++ code
>>> | > |>>
>>> | > |>> ?Question 1:
>>> | > |>> ?If I?m at a terminal, I can type the instructions they suggest:
>>> | > |>> ?R CMD SHLIB X.cc X_main.cc
>>> | > |>> ?If I wanted a package to do this, how would I tell the package to
>>> do
>>> | > that
>>> | > |>> ?same thing?
>>> | > |>
>>> | > |> ?Just to make sure we're all on the same page, you want an R package
>>> to
>>> | > |> ?compile some source code into a shared library/dll from inside R?
>>> | > |>
>>> | > |> ?Not sure if there's a "baked in" way for that to happen, but maybe
>>> you
>>> | > |> ?can invoke `R CMD WHATEVER` from inside R using the `system`
>>> function:
>>> | > |>
>>> | > |> ?R> ??system
>>> | > |>
>>> | > |
>>> | > | ok, so where in the package would I put the system call in the package
>>> to
>>> | > | have it run when installing the package?
>>> | >
>>> | >> You don't. As I said, 'R CMD INSTALL' et all do that.
>>> | >> Download an existing package with source, install it. ?Study its
>>> sources,
>>> | >> study the 'Writing R Extensions' manual. ?Ask on r-devel.
>>> | >> Basic R questions are off-topic here.
>>> | >
>>> | > |>> ?Would I use the same command and just include it in a file
>>> somewhere
>>> in
>>> | > the
>>> | > |>> ?package?
>>> | > |>> ?If so, which file?
>>> | > |>
>>> | > |> ?Hmm ... I'm curious what you're trying to do, exactly?
>>> | > |
>>> | > | I'm trying to figure out how take commands such as " R CMD SHLIB X.cc
>>> | > | X_main.cc" followed by "dyn.load(paste("X", .Platform$dynlib.ext, sep
>>> =
>>> | > | ""))," which are commands I can get to work for myself as a human
>>> | > | interactively, and put the commands into a package to be automatically
>>> run
>>> | > | when installing the package. I mean, it's great if I can compile a c++
>>> | > file
>>> | > | and then use it inside R, but I'm only doing that so I can let other
>>> | > people
>>> | > | do that via a package. As much as I read this documentation, I keep
>>> | > missing
>>> | >
>>> | >> Again, I like working from an existing, working package. As I said,
>>> there
>>> are
>>> | >> almost 1000 to pick from.
>>> | >> Please direct follow-ups that have no bearing on Rcpp to r-devel.
>>> | >> Dirk
>>> | >
>>> | > I've tried to figure this out for weeks by looking at other packages and
>>> | > reading the confusing and nonintegrated documentation, but it hasn't
>>> taught
>>> | > me how to put the two commands into a package so that they are run when
>>> the
>>> | > package is installed. I'm simply trying to find out where in my package
>>> I
>>> | > should put the commands 'R CMD SHLIB X.cc X_main.cc' and
>>> | > 'dyn.load(paste("X",.Platform$dynlib.ext,sep="")),'
>>> | > in order to have them run when my package is installed.
>>> | >
>>> | >
>>> | > | the connections between the different sections. This is a section I am
>>> | > | loving because it works very well. Thus, I want to figure out how to
>>> take
>>> | > | the baby steps I'm doing and combine them into a package.
>>> Specifically,
>>> I
>>> | > | want to take these two commands and insert them into a package so that
>>> | > these
>>> | > | commands will compile my code and make a dynamic ".so" file where R
>>> can
>>> | > | access its functions when others install my package.
>>> | > |
>>> | > |>
>>> | > |>> ?Question 2:
>>> | > |>> ?dyn.load(paste("X", .Platform$dynlib.ext, sep = ""))
>>> | > |>>
>>> | > |>> ?Where does .Platform$dynlib.ext come from?
>>> | > |>> ?What does it mean?
>>> | > |>> ?What do it?s components .Platform and $dynlib and .ext mean?
>>> | > |>
>>> | > |> ?.Platform is lust a normal list -- it is defined internally (I
>>> guess).
>>> | > |> ?You can access "named" elements of a list with `$`.
>>> | > |>
>>> | > |> ?.Platform$dynlyb (or .Platform[['dynlib']]) tells you the extension
>>> | > |> ?your particular system uses for shared libraries:
>>> | > |>
>>> | > |> ?R> ?.Platform
>>> | > |> ?$OS.type
>>> | > |> ?[1] "unix"
>>> | > |>
>>> | > |> ?$file.sep
>>> | > |> ?[1] "/"
>>> | > |>
>>> | > |> ?$dynlib.ext
>>> | > |> ?[1] ".so"
>>> | > |>
>>> | > |> ?$GUI
>>> | > |> ?[1] "X11"
>>> | > |>
>>> | > |> ?$endian
>>> | > |> ?[1] "little"
>>> | > |>
>>> | > |> ?$pkgType
>>> | > |> ?[1] "mac.binary.leopard"
>>> | > |>
>>> | > |> ?$path.sep
>>> | > |> ?[1] ":"
>>> | > |>
>>> | > |> ?$r_arch
>>> | > |> ?[1] "x86_64"
>>> | > |>
>>> | > |> ?See ?.Platform for more help.
>>> | > |
>>> | > | Ah, thanks, that clarifies exactly what .Platform$dynlib.ext is, it's
>>> | > ".so"
>>> | > | on my system.
>>> | > |
>>> | > | This, the dyn.load(paste("X", .Platform$dynlib.ext, sep = "")) is
>>> | > equivalent
>>> | > | to the command dyn.load("X.so) which now makes sense in that context!
>>> | > |
>>> | > |
>>> | > | _______________________________________________
>>> | > | Rcpp-devel mailing list
>>> | > | Rcpp-devel at lists.r-forge.r-project.org
>>> | > | 
>>> https://lists.r-forge.r-project.org/cgi-bin/mailman/listinfo/rcpp-devel
>>> | >
>>> |
>>> | ______________________________________________
>>> | R-devel at r-project.org mailing list
>>> | https://stat.ethz.ch/mailman/listinfo/r-devel
>> 
>> 
>> ? ? ? ?[[alternative HTML version deleted]]
>> 
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> 
>> 


From kcrisman at gmail.com  Thu Apr 21 17:47:15 2011
From: kcrisman at gmail.com (Karl-Dieter Crisman)
Date: Thu, 21 Apr 2011 11:47:15 -0400
Subject: [Rd] How to get R to compile with PNG support
In-Reply-To: <19888.16821.533699.499469@max.nulle.part>
References: <BANLkTinAtiXhxhSRhEEu0aDZsZuELOQu+g@mail.gmail.com>
	<19888.6629.380047.505281@max.nulle.part>
	<BANLkTinfcQJtotd4macXNjfmOxfekaDDEA@mail.gmail.com>
	<19888.16821.533699.499469@max.nulle.part>
Message-ID: <BANLkTi=uRmogmfLyRj0LMWoweSEVn=61hw@mail.gmail.com>

Thanks for all the feedback.  First, our update, then two responses.

>From Jason Grout:
+++
I finally got it working.  After mucking around in the R configure
file a bit and trying out some of the different tests, as well as
comparing a working system with our broken system, I realized that
`pkg-config --exists pangocairo` was working on the good system and
not working on the broken system.  So I installed libpango1.0-dev, and
now R picks up the cairo package, which in turn means that my
capabilities is now:

> capabilities()
   jpeg      png     tiff    tcltk      X11     aqua http/ftp  sockets
   TRUE     TRUE    FALSE    FALSE    FALSE    FALSE     TRUE     TRUE
 libxml     fifo   cledit    iconv      NLS  profmem    cairo
   TRUE     TRUE     TRUE     TRUE     TRUE    FALSE     TRUE

So in short, I think what I did was install libcairo-dev and
libpango1.0-dev.  There might have been other stuff in there that was
needed; I'm not sure.  When I build a new system again, I'll try just
installing those packages and see if it is sufficient.  For the
record, I had also installed xorg-dev as well.

+++
My comment: As someone who didn't know what configure scripts were a
couple years ago, this is maddening; I don't see anything about
libpango or whatever in the FAQs.  Luckily, Jason knows a lot more
than I do!

@Dirk:

> | Note that we have installed the cairo devel package on this very
> | machine, but it's not being picked up - maybe it's looking in the
> | wrong place? ?That is one of the reasons this is confusing.
>
> You have to understand that even though this problem may seem urgent and
> novel to you and the Sage team,

Novel, yes; urgent only to us, certainly we don't assume it's urgent to you :)

> it is actually about as old as the web and R
> itself. ?In a nutshell, we all (in the people reading r-help and r-devel
> sense) have been explaining to folks since the late 1990s that in order to
> run png() to 'just create some charts for a webserver' ... you need an X11
> server because that is where the font metrics come from. Or else no png for

It's true this is findable, but the difference between having X11 on
the system and having the display is arcane for those who just want to
use R.  But I understand your point.

> is life. ?System such as Sage become so large because having things like this
> around on all deployment systems implies (at least to some degree)
> replicating fundamental OS level features because they unfortunately have
> supply things missing or broken across OSs.

Yes, that is true.  We know of many people who download Sage because
it's the easiest way to install Z, where Z is some specific
mathematical program that is impossible to configure properly without
special knowledge.  Or, until fairly recently, to get Cython.

@Simon:

That's new to me that X11 is installed by default now, but it looks
like you are right.  However, we don't rely on this for Mac; we make
sure to configure for quartz when we build - which I assume is
separate from the other stuff?  But updating the FAQ about this would
be really great for future users :)

Also thanks for the hint on all the other (possibly) needed stuff.
Yikes!  AFAIK this is an Ubuntu machine we're talking about.

To all - if we come up with any more reliable way to make this work
universally, i.e. with *exact* instructions for what to download, we
will definitely pass that upstream. Thank you.


From murdoch.duncan at gmail.com  Thu Apr 21 18:48:30 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 21 Apr 2011 12:48:30 -0400
Subject: [Rd] Sweave support added to rgl package
In-Reply-To: <4DAF80C4.7070602@gmail.com>
References: <4DADD1E6.5040905@gmail.com>	<BANLkTikDrC1wdzMv+-0c1_t_MjTKx+Svxg@mail.gmail.com>	<4DAF2626.6010805@gmail.com>
	<BANLkTimjXGU+cEGnEsW_=vZ6E50Qby4JtA@mail.gmail.com>
	<4DAF80C4.7070602@gmail.com>
Message-ID: <4DB05FDE.4010907@gmail.com>

I've just committed some changes to rgl that will probably detect 
bitmaps that are specified to be too large.  As well, Brian Ripley 
backported some of the R-devel additions to the RweaveLatex driver, so 
now R 2.13.0-patched (revision 55572 or newer) should
work as well as R-devel.

Duncan Murdoch

On 20/04/2011 8:56 PM, Duncan Murdoch wrote:
> On 20/04/2011 7:10 PM, Dominick Samperi wrote:
> >  On Wed, Apr 20, 2011 at 2:29 PM, Duncan Murdoch
> >  <murdoch.duncan at gmail.com>   wrote:
> >>  On 20/04/2011 1:52 PM, Dominick Samperi wrote:
> >>>
> >>>  On Tue, Apr 19, 2011 at 2:18 PM, Duncan Murdoch
> >>>  <murdoch.duncan at gmail.com>     wrote:
> >>>>    I have just committed some code to the rgl package on
> >>>>    https://r-forge.r-project.org/projects/rgl/ to allow rgl images to be
> >>>>    inserted into Sweave documents.  (This is not in the CRAN version yet.)
> >>>>    It
> >>>>    makes use of the custom graphics driver support added by Brian Ripley.
> >>>>
> >>>>    In R-devel (which will become R 2.14.0 next spring in New Zealand, next
> >>>>  fall
> >>>>    in most other places), usage is quite straightforward.  For
> >>>>    example, code like this in a Sweave document:
> >>>>
> >>>>    <<fig=true, grdevice=rgl.Sweave, pdf=false, stayopen=TRUE>>=
> >>>>    x<- rnorm(100); y<- rnorm(100); z<- rnorm(100)
> >>>>    plot3d(x, y, z)
> >>>>    @
> >>>>
> >>>>    will insert a .png snapshot of the figure.  Because that chunk has
> >>>>    "stayopen=TRUE", it can be followed by another chunk to add
> >>>>    to the figure, e.g.
> >>>>
> >>>>    <<fig=true, grdevice=rgl.Sweave, pdf=false>>=
> >>>>    lines3d(x[1:10], y[1:10], z[1:10], col="red")
> >>>>    @
> >>>>
> >>>>    All of this is possible in R 2.13.0, but it takes more work:  see the
> >>>>    ?rgl.Sweave help page.
> >>>>
> >>>>    I will eventually add postscript and PDF output options as well, and
> >>>>  perhaps
> >>>>    some support for the LaTeX movie15 package, but those are not there
> >>>>  yet.
> >>>>      Comments or bug reports are welcome.
> >>>>
> >>>>    Duncan Murdoch
> >>>
> >>>  I inserted your example into testrgl.Rnw under R 2.13.0, with
> >>>  Sweave.snapshot()
> >>>  at the end of both chunks, but things did not work as expected.
> >>>
> >>>  I used:
> >>>  $ R CMD Sweave testrgl.Rnw
> >>>  $ pdflatex tesetrgl
> >>>  (view testrgl.pdf)
> >>>
> >>>  When R CMD Sweave is run the graphics is displayed interactively.
> >>
> >>  That's unavoidable as far as I know.  I don't think there's a general
> >>  purpose way to tell OpenGL to render in the background, so it works by
> >>  rendering on screen, then copying a bitmap to the .png file.
> >>>
> >>>  There is no graphics in the PDF file, even though both .png files
> >>>  are read when pdflatex is run.
> >>
> >>  Do they look okay?  One possible problem is that you may have asked for a
> >>  bitmap too big for your hardware to render, in which case those png files
> >>  will end up with junk (probably blank).  Setting resolution=100 in the chunk
> >>  headers will do it more coarsely.  (The default is 300 dpi.)  The same
> >>  effect comes from width=1, height=1  (or some other small numbers).
> >>
> >>  Duncan Murdoch
> >>
> >
> >  The resolution=100 tip fixed the problem, thanks.
>
> I'll see if I am skipping over some error message in there.  It would be
> much better for Sweave to fail with an error than generate empty images.
>
>
>   >  Now I see the snapshots
> >  in the PDF file. Using this in a package will certainly change the
> >  user experience,
> >  but it moves away from the traditional batch-oriented R package
> >  processing, it seems to me.
>
> I don't follow that.
>
> >  The idea of adding support for movies and 3D graphics to Sweave/PDF files
> >  sounds very interesting and revolutionary.
>
> Movies will likely be pretty slow.  I think you'll want caching of some
> sort if you want to produce those.
>
> Duncan Murdoch
>
> >
> >  Dominick
>


From andre.zege at gmail.com  Thu Apr 21 21:24:11 2011
From: andre.zege at gmail.com (A Zege)
Date: Thu, 21 Apr 2011 12:24:11 -0700 (PDT)
Subject: [Rd] problem subsetting of a reference class
Message-ID: <1303413851743-3466690.post@n4.nabble.com>

I am trying to define subset operator for a reference class and hitting some
problem i am unable to diagnose.To give an example, here is a toy class
generator that is a wrapper around a list




tmpGEN<-setRefClass("TMP", fields=list(
				namelist="list"
		))
tmpGEN$methods('add'=function(obj, name){
	namelist[[name]]<<-obj
})

tmpGEN$methods('['=function(name){
			if(class(name)!="character")
				stop('to return cache element need to pass its name')
			ind<-match(name, names(namelist))
			if(is.na(ind))
				stop('data to remove is not in namelist')
			namelist[[name]]
		})


==============

when i try to use it, the following happens
v<-rnorm(10)
tmp<-tmpGEN$new()
tmp$add(v, 'random')

..... up until here everything is ok, class is generated and vector is
added. Now when i do
tmp['random']

i get error message 

Error in tmp["random"] : object of type 'S4' is not subsettable

Not sure if it means that i cannot define "[" operator for a class or if i
am doing it syntactically wrong


--
View this message in context: http://r.789695.n4.nabble.com/problem-subsetting-of-a-reference-class-tp3466690p3466690.html
Sent from the R devel mailing list archive at Nabble.com.


From jmc at r-project.org  Thu Apr 21 22:36:00 2011
From: jmc at r-project.org (John Chambers)
Date: Thu, 21 Apr 2011 13:36:00 -0700
Subject: [Rd] problem subsetting of a reference class
In-Reply-To: <1303413851743-3466690.post@n4.nabble.com>
References: <1303413851743-3466690.post@n4.nabble.com>
Message-ID: <4DB09530.9010005@r-project.org>

You're confusing functional and OOP-style methods.

Since you define an OOP-style method, you need to invoke it in OOP style.

With your example:


 > tmp$`[`("random")
  [1] -1.439131143 -0.630354726  0.822006263 -0.651707539  0.475332681
  [6]  0.002680224  1.539035675 -0.117609566  2.066227300  1.111270997
 >


You could if you wanted define a functional method via setMethod() to 
allow functional access, by invoking the $`[`() method--preferably after 
changing its name.  It's probably a matter of opinion whether that's a 
good use of OOP-style methods.


On 4/21/11 12:24 PM, A Zege wrote:
> I am trying to define subset operator for a reference class and hitting some
> problem i am unable to diagnose.To give an example, here is a toy class
> generator that is a wrapper around a list
>
>
>
>
> tmpGEN<-setRefClass("TMP", fields=list(
> 				namelist="list"
> 		))
> tmpGEN$methods('add'=function(obj, name){
> 	namelist[[name]]<<-obj
> })
>
> tmpGEN$methods('['=function(name){
> 			if(class(name)!="character")
> 				stop('to return cache element need to pass its name')
> 			ind<-match(name, names(namelist))
> 			if(is.na(ind))
> 				stop('data to remove is not in namelist')
> 			namelist[[name]]
> 		})
>
>
> ==============
>
> when i try to use it, the following happens
> v<-rnorm(10)
> tmp<-tmpGEN$new()
> tmp$add(v, 'random')
>
> ..... up until here everything is ok, class is generated and vector is
> added. Now when i do
> tmp['random']
>
> i get error message
>
> Error in tmp["random"] : object of type 'S4' is not subsettable
>
> Not sure if it means that i cannot define "[" operator for a class or if i
> am doing it syntactically wrong
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/problem-subsetting-of-a-reference-class-tp3466690p3466690.html
> Sent from the R devel mailing list archive at Nabble.com.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From chuck at sharpsteen.net  Fri Apr 22 04:02:27 2011
From: chuck at sharpsteen.net (Sharpie)
Date: Thu, 21 Apr 2011 19:02:27 -0700 (PDT)
Subject: [Rd] FW: [Rcpp-devel] Question on 5.6 Interfacing C++ code
In-Reply-To: <C9D5C7C2.3DD0%sean.mcguffee@gmail.com>
References: <C9D47520.3D72%sean.mcguffee@gmail.com> <4DB011F3.80603@gmail.com>
	<19888.6774.24607.71449@max.nulle.part>
	<C9D5C297.3DCA%sean.mcguffee@gmail.com>
	<BANLkTimOXKGN2yUvxF_+-bKZgXQMfOBHHg@mail.gmail.com>
	<C9D5C7C2.3DD0%sean.mcguffee@gmail.com>
Message-ID: <1303437747451-3467221.post@n4.nabble.com>


smcguffee wrote:
> 
> You are right, I looked and I did find the R source code. However, it's
> largely written in R! I mean, I don't know how to trace the R code where
> INSTALL is recognized and follow it to a c or c++ level command. For
> example
> these are hits in .R files, not c files, and I don't know how to connect
> 
> ...
> 
> If you could point me to the functions that are called a c or c++ level,
> I'd
> love to see what R is doing for myself.
> Thanks!
> Sean
> 

Hi Sean!

Along with many other people in this thread, I would strongly recommend a
top-down approach to this. Build a package, stick some stuff in the src
folder, run R CMD INSTALL on it and see what happens. The reason I recommend
this approach is that it lets you focus on writing a package that does
something useful rather than the nuts and bolts of cross platform
compilation and installation. R CMD INSTALL takes care of this for you
automagically and it is very good at what it does.

I wrote a post some time back about building an example package from scratch
that contains C code:

http://r.789695.n4.nabble.com/Writing-own-simulation-function-in-C-td1580190.html#a1580423

It begins with the using the package.skeleton() function to kickstart
things, discusses how to make sure the compiled code is dynamically loaded
when a user runs library(your_package) and even discusses how to call R
functions from inside of C functions and vice-versa. The example code is
still available and I'm sure it could be generalized to C++ quite easily. 
There are also some other responses in that thread that offer useful advice.


At the beginning it is just best to treat R CMD INSTALL as a magical unicorn
that gets you where you need to go:

http://abstrusegoose.com/120
(keep clicking the images to get the full story)


If you are absolutely, positively dying to know what really happens... well,
the relative files in the R source are `src/library/tools/R/install.R` and
`src/library/tools/R/build.R`.


But seriously. Magical unicorn. Takes care of the hard stuff so you can
build awesome packages.

Hope this helps!

-Charlie

-----
Charlie Sharpsteen
Undergraduate-- Environmental Resources Engineering
Humboldt State University
--
View this message in context: http://r.789695.n4.nabble.com/FW-Rcpp-devel-Question-on-5-6-Interfacing-C-code-tp3465257p3467221.html
Sent from the R devel mailing list archive at Nabble.com.


From sean.mcguffee at gmail.com  Fri Apr 22 20:16:18 2011
From: sean.mcguffee at gmail.com (Sean Robert McGuffee)
Date: Fri, 22 Apr 2011 14:16:18 -0400
Subject: [Rd] FW: [Rcpp-devel] Question on 5.6 Interfacing C++ code
In-Reply-To: <1303437747451-3467221.post@n4.nabble.com>
Message-ID: <C9D73E32.3DFA%sean.mcguffee@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110422/b2ac3b7c/attachment.pl>

From marc_schwartz at me.com  Fri Apr 22 20:24:33 2011
From: marc_schwartz at me.com (Marc Schwartz)
Date: Fri, 22 Apr 2011 13:24:33 -0500
Subject: [Rd] Patch for hist.Date() function in datetime.R
Message-ID: <6DF3F671-849D-48A9-8E2C-F0CE85D3A3A4@me.com>

Hi all,

In follow up to my reply to Terry Therneau on r-help regarding the lack of a check in hist.Date() for a missing 'breaks' argument, attached is a proposed patch which includes such a check, patterned after the same check for hist.POSIXt().

The patch is against the current svn 'trunk' version of datetime.R in package 'graphics'.

Regards,

Marc Schwartz



--- datetime.R	2011-04-22 13:04:29.000000000 -0500
+++ datetime.R.new	2011-04-22 13:18:10.000000000 -0500
@@ -237,6 +237,8 @@
     force(xlab)
     incr <- 1
     ## handle breaks ourselves
+    if(missing(breaks))
+	stop("Must specify 'breaks' in hist(<Date>)")    
     if (inherits(breaks, "Date")) {
         breaks <- as.Date(breaks)
         d <- min(abs(diff(unclass(breaks))))



-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: patch.txt
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110422/2be8ef82/attachment.txt>
-------------- next part --------------



From chuck at sharpsteen.net  Fri Apr 22 21:22:16 2011
From: chuck at sharpsteen.net (Sharpie)
Date: Fri, 22 Apr 2011 12:22:16 -0700 (PDT)
Subject: [Rd] FW: [Rcpp-devel] Question on 5.6 Interfacing C++ code
In-Reply-To: <C9D73E32.3DFA%sean.mcguffee@gmail.com>
References: <C9D47520.3D72%sean.mcguffee@gmail.com> <4DB011F3.80603@gmail.com>
	<19888.6774.24607.71449@max.nulle.part>
	<C9D5C297.3DCA%sean.mcguffee@gmail.com>
	<BANLkTimOXKGN2yUvxF_+-bKZgXQMfOBHHg@mail.gmail.com>
	<C9D5C7C2.3DD0%sean.mcguffee@gmail.com>
	<1303437747451-3467221.post@n4.nabble.com>
	<C9D73E32.3DFA%sean.mcguffee@gmail.com>
Message-ID: <1303500136567-3468640.post@n4.nabble.com>


smcguffee wrote:
> 
> Hi Charlie, 
> 
> Thanks for the help,
> 
> I think some of my story of having been reading the documentation and
> playing with examples for weeks has gotten lost in the switch of threads.
> I
> think most of that confusion also comes from me not figuring out how to
> connect different sections of the documentation. I think I get it now that
> just because I can do 'R CMD SHLIB X.cc X_main.cc' from a command line
> doesn?t mean that I need to put that command into a package directly, and
> even that I can?t explicitly put that line in a package because it?s
> magically done for me. I appreciate folks having patience with me as some
> of
> my questions seem redundant, but it is all starting to come together for
> me.
> 

When I first started out extending R with compiled code, I used R CMD SHLIB
as well. Don't know why exactly, it was probably the first thing I stumbled
across in the manual. Once I learned about making packages and that putting
C, C++ or Fortran code in the `src` directory of the package magically
caused a library to be built, I quit using R CMD SHLIB---probably haven't
touched it in years.

I think R CMD SHLIB may be intended more for compiling external programs
that want to hook into the R libraries rather than things intended to be
loaded by R it's self.



smcguffee wrote:
> 
> At this point I think I am beginning to get a good enough idea of how this
> stuff is working on the R interface side of things. I pretty much just
> have
> one more question:
> 
> How do I let users adjust their system specific paths to non-R libraries
> for
> my package installation but not for everyone else?s package installation?
> I
> get the feeling users can control things in my package somehow through
> their
> R configurations if I use the PKG_LIBS = `$(R_HOME)/bin/Rscript -e
> "Rcpp:::LdFlags()"` command in the src/Makevars file. However, I'm still
> lost as to how this would be customized to my package. I mean, that
> command
> doesn?t specify anything unique to my package and could potentially be
> used
> by other package installations too. That file is inside my package, so I
> don?t think users can modify it directly and explicitly with their system
> specific paths before they install. Maybe if other packages link to extra
> libraries it doesn't hurt anything. Is that the answer? Would users need
> to
> add all my requisite non-R libraries into their R configurations to get
> `$(R_HOME)/bin/Rscript -e "Rcpp:::LdFlags()"` to link my package correctly
> and let all other packages link to way more libraries than necessary?
> 

Well, the best answers to this question lie inside the "Writing R
Extensions" manual---specifically Section 1.2 "Configure and Cleanup".  The
short version is:

 - If the code in your package needs custom compiler flags, add a 
`src/Makevars` file that contains them.

 - If the code in your package dependes on external libraries, add a
Configure script, written using GNU autotools, that will produce
`src/Makevars` from a template `src/Makevars.in` that contains the `-L` and
`-I` flags required to link your code against the external library.

However, I will again suggest taking this one step at a time:

  - Build a toy package that includes C or C++ code that needs to be
compiled. Observe how `R CMD INSTALL` compiles the code for you and how to
use `.onLoad` or `.First.Lib` to `dyn.load` the resulting library when a
user runs `library` on your package.  Bonus points for reading enough of
"Writing R Extensions" to know if having an R NAMESPACE in your package has
any effect on this process.

  - Extend your toy package to include C++ code that needs custom compiler
flags. See how you can achieve this with `src/Makevars`.

  - Extend your package again with an external dependency that requires a
`configure` script. A good example of such a package is `rgdal`---it has to
find both the GDAL and PROJ4 libraries in order to compile operational code.

If you run into any trouble along the way, stop and read "Writing R
Extensions". If you really get stuck, you can then ask the mailing list a
very focused question along with an example that shows what is going wrong
for you. Then you have a good change of getting helpful answers.  Right now
your questions are spanning the entire spectrum from beginning to advanced
package authoring and so the most likely answer you will get from the list
is "slow down and read the manual".




smcguffee wrote:
> 
> Thanks for your help,
> 
> Sean
> 
> P.S.
> 
> The rest of this message is my rambling, so only those interested in my
> thoughts should continue reading. Especially those interested in sparing
> their own time should stop reading here--the question above is my last
> inquiry for the list. What comes below is just my train of thoughts/flow
> of
> consciousness spewing needlessly.
> 
> It was definitely a good idea for me to look in the R source code. It
> seems
> that dynload.c names.c dotcode.c Rdynload.c were of most interest to me in
> understanding that magical unicorn with an adorable animated cartoon
> story.
> I found that link quite enjoyable by they way! Regarding the files I just
> mentioned, I notice that the code is in the form of c files and that quite
> a
> lot of info from library files is used to get function pointers in the
> functions of interest to me. I wonder if making those files into cpp files
> that would get compiled with a c++ compiler would let them call c++
> functions directly or if the info to get the function pointers would be of
> a
> completely different type of syntax and/or if there is more to that story.
> I
> suppose it makes no difference in practice because one would probably
> still
> have to make a c++ wrapper function to interface with R, but I'm just
> curious about this stuff. I mean, in principle, it makes sense to be able
> to
> call a function directly without having to go through the trouble of
> wrapping it in c, especially for hundreds of C++ functions in a library.
> It
> might be that I can write one general argument handling function in C as
> is
> to interface with R and let it call any of my C++ functions in my
> libraries,
> slightly shortening my tasks. Anyway, it was really eye opening to see
> that
> R is actually calling it's own generic pointers to functions and just
> pre-assigning them to function pointers from libraries. I didn't know that
> could be done, and I imagine hackers must love that capacity, a capacity
> that seems to be inherent in c or c++. It does seem a little bit limiting
> that the arguments are limited in number and that each function pointer
> with
> a different number of arguments has to be conditionally called inside the
> R
> code. However, I have the same complaint about bash having a limit on the
> total size of data that can be passed as arguments into an executable. It
> looks to me like fixing that type of thing in bash requires recompiling
> the
> kernel because it's hard wired non-dynamically into the capacity of
> launching executables themselves. I hope this type of thing starts to
> change
> as hardware is way exceeding the original expectations of the
> non-dynamically allocated original design of executable launch and dynamic
> allocation has clearly demonstrated it?s superiority in general. That type
> of thing comes into issue for me on command line scripts when I sometimes
> have lists of files that are longer than the capacity of command line
> arguments. For example, a "grep someText *" or ?ls *? will only work if
> the
> size of the arguments in the * expansion is less than the system's
> capacity
> for arguments passed to executables. I hit that limit all the time, and
> that's annoying because scripts that normally work break in larger
> situations, rendering their applicability useless in what are typically
> more
> interesting cases. Anyway, that's all a tangent from this R interfacing
> stuff. However, it was news to me that R could have a similar type of
> limit
> for functions in packages until I looked into the code. I don't think this
> is an issue in R because I'll just design one Rcpp argument to contain all
> the info I need inside itself. However, it's good to know that I need to
> do
> that. Anyway, I'm also wondering if it might be easier to modify compilers
> themselves and/or incorporate their code into R's code, i.e. easier than
> doing all this work around to fit into their mold. In a way that is sort
> of
> done to access the function pointers from libraries, but I mean, it seems
> logical that a program such as R should be able to call any function with
> any number of arguments abstractly without needing to have the functions
> get
> conditionally called with a given number of arguments at compile time for
> R.
> I can imagine converting a string to a call to a number of arguments that
> is
> determined by the syntax of the string without being defined before the
> compilation of R. That type of idea, if possible, could allow a more
> dynamic
> range of options in packages, at least not limited by a number of
> arguments.
> Like I said, that?s not important because one argument can contain an
> endless amount of info, but it sparked my curiosity. I might peak at GNU's
> gcc compiler collection to see if I can come up with some ideas for that
> type of thing--basically building dynamic compilation and execution
> options,
> but I imagine it would be way over my head, a long time coming, and of
> course potentially unstable. The long and short of it for me is that it
> was
> way cool to see how R is calling C functions from packages or non-R
> libraries.
> 

Quite a brain dump there!  Some things that you may want to look into in the
future:

  - The original mailing list you posted to, Rcpp, is for an R package that
wraps the C API of R into C++ classes.  I would bet it also provides methods
for calling R code and C++ without having to write as many R functions.  I
have not had the pleasure of using Rcpp yet---Fortran was my first compiled
language and I am still moving my way up the food chain :)

  - The inline package may be of interest to you---It allows C, C++ and
Fortran programs to be stored as text strings at the R level and then
dynamically compiled, loaded and interfaced.  Could be along the lines of
what you were thinking about with "building dynamic compilation and
execution options".

  - Also, it is always fun to drop by the Omegahat project
(www.omegahat.org) and see what Duncan Temple Lang has been cooking up. He
has a couple of packages for interfacing R with compiled code via LibFFI
(rather than the built in pointer method you observed) and one package that
has the beginnings of some LLVM bindings.


-Charlie


On 4/21/11 10:02 PM, "Sharpie" &lt;chuck at sharpsteen.net&gt; wrote:

> 
> smcguffee wrote:
>> 
>> You are right, I looked and I did find the R source code. However, it's
>> largely written in R! I mean, I don't know how to trace the R code where
>> INSTALL is recognized and follow it to a c or c++ level command. For
>> example
>> these are hits in .R files, not c files, and I don't know how to connect
>> 
>> ...
>> 
>> If you could point me to the functions that are called a c or c++ level,
>> I'd
>> love to see what R is doing for myself.
>> Thanks!
>> Sean
>> 
> 
> Hi Sean!
> 
> Along with many other people in this thread, I would strongly recommend a
> top-down approach to this. Build a package, stick some stuff in the src
> folder, run R CMD INSTALL on it and see what happens. The reason I
> recommend
> this approach is that it lets you focus on writing a package that does
> something useful rather than the nuts and bolts of cross platform
> compilation and installation. R CMD INSTALL takes care of this for you
> automagically and it is very good at what it does.
> 
> I wrote a post some time back about building an example package from
> scratch
> that contains C code:
> 
> http://r.789695.n4.nabble.com/Writing-own-simulation-function-in-C-td1580190.h
> tml#a1580423
> 
> It begins with the using the package.skeleton() function to kickstart
> things, discusses how to make sure the compiled code is dynamically loaded
> when a user runs library(your_package) and even discusses how to call R
> functions from inside of C functions and vice-versa. The example code is
> still available and I'm sure it could be generalized to C++ quite easily.
> There are also some other responses in that thread that offer useful
> advice.
> 
> 
> At the beginning it is just best to treat R CMD INSTALL as a magical
> unicorn
> that gets you where you need to go:
> 
> http://abstrusegoose.com/120
> (keep clicking the images to get the full story)
> 
> 
> If you are absolutely, positively dying to know what really happens...
> well,
> the relative files in the R source are `src/library/tools/R/install.R` and
> `src/library/tools/R/build.R`.
> 
> 
> But seriously. Magical unicorn. Takes care of the hard stuff so you can
> build awesome packages.
> 
> Hope this helps!
> 
> -Charlie


-----
Charlie Sharpsteen
Undergraduate-- Environmental Resources Engineering
Humboldt State University
--
View this message in context: http://r.789695.n4.nabble.com/FW-Rcpp-devel-Question-on-5-6-Interfacing-C-code-tp3465257p3468640.html
Sent from the R devel mailing list archive at Nabble.com.


From sean.mcguffee at gmail.com  Fri Apr 22 22:31:23 2011
From: sean.mcguffee at gmail.com (Sean Robert McGuffee)
Date: Fri, 22 Apr 2011 16:31:23 -0400
Subject: [Rd] FW: [Rcpp-devel] Question on 5.6 Interfacing C++ code
In-Reply-To: <1303500136567-3468640.post@n4.nabble.com>
Message-ID: <C9D75DDB.3E06%sean.mcguffee@gmail.com>

Hi Charlie,
Thanks so much!
That is very informative and extremely interesting.
I have yet to learn how to setup the GNU autotools Configure script, but
it's time for me to get there. I think that should be my next step and I'll
definitely be checking out that GNU package and the `rgdal` example. Also, I
really appreciate you telling me about the www.omegahat.org stuff. I'll be
looking into that stuff no doubt! That's neat that you started off with
fortran. I just got fortran again when I was playing with GNU's gcc
compilation. I think in some instances it makes the fastest code.
Sean


On 4/22/11 3:22 PM, "Sharpie" <chuck at sharpsteen.net> wrote:

> 
smcguffee wrote:
> 
> Hi Charlie, 
> 
> Thanks for the help,
> 
> I think
> some of my story of having been reading the documentation and
> playing with
> examples for weeks has gotten lost in the switch of threads.
> I
> think most
> of that confusion also comes from me not figuring out how to
> connect
> different sections of the documentation. I think I get it now that
> just
> because I can do 'R CMD SHLIB X.cc X_main.cc' from a command line
> doesn?t
> mean that I need to put that command into a package directly, and
> even that
> I can?t explicitly put that line in a package because it?s
> magically done
> for me. I appreciate folks having patience with me as some
> of
> my questions
> seem redundant, but it is all starting to come together for
> me.
> 

When I
> first started out extending R with compiled code, I used R CMD SHLIB
as well.
> Don't know why exactly, it was probably the first thing I stumbled
across in
> the manual. Once I learned about making packages and that putting
C, C++ or
> Fortran code in the `src` directory of the package magically
caused a library
> to be built, I quit using R CMD SHLIB---probably haven't
touched it in
> years.

I think R CMD SHLIB may be intended more for compiling external
> programs
that want to hook into the R libraries rather than things intended to
> be
loaded by R it's self.



smcguffee wrote:
> 
> At this point I think I am
> beginning to get a good enough idea of how this
> stuff is working on the R
> interface side of things. I pretty much just
> have
> one more question:
> 
>
> How do I let users adjust their system specific paths to non-R libraries
>
> for
> my package installation but not for everyone else?s package
> installation?
> I
> get the feeling users can control things in my package
> somehow through
> their
> R configurations if I use the PKG_LIBS =
> `$(R_HOME)/bin/Rscript -e
> "Rcpp:::LdFlags()"` command in the src/Makevars
> file. However, I'm still
> lost as to how this would be customized to my
> package. I mean, that
> command
> doesn?t specify anything unique to my
> package and could potentially be
> used
> by other package installations too.
> That file is inside my package, so I
> don?t think users can modify it
> directly and explicitly with their system
> specific paths before they
> install. Maybe if other packages link to extra
> libraries it doesn't hurt
> anything. Is that the answer? Would users need
> to
> add all my requisite
> non-R libraries into their R configurations to get
> `$(R_HOME)/bin/Rscript -e
> "Rcpp:::LdFlags()"` to link my package correctly
> and let all other packages
> link to way more libraries than necessary?
> 

Well, the best answers to this
> question lie inside the "Writing R
Extensions" manual---specifically Section
> 1.2 "Configure and Cleanup".  The
short version is:

 - If the code in your
> package needs custom compiler flags, add a 
`src/Makevars` file that contains
> them.

 - If the code in your package dependes on external libraries, add
> a
Configure script, written using GNU autotools, that will
> produce
`src/Makevars` from a template `src/Makevars.in` that contains the
> `-L` and
`-I` flags required to link your code against the external
> library.

However, I will again suggest taking this one step at a time:

  -
> Build a toy package that includes C or C++ code that needs to be
compiled.
> Observe how `R CMD INSTALL` compiles the code for you and how to
use `.onLoad`
> or `.First.Lib` to `dyn.load` the resulting library when a
user runs `library`
> on your package.  Bonus points for reading enough of
"Writing R Extensions" to
> know if having an R NAMESPACE in your package has
any effect on this
> process.

  - Extend your toy package to include C++ code that needs custom
> compiler
flags. See how you can achieve this with `src/Makevars`.

  - Extend
> your package again with an external dependency that requires a
`configure`
> script. A good example of such a package is `rgdal`---it has to
find both the
> GDAL and PROJ4 libraries in order to compile operational code.

If you run
> into any trouble along the way, stop and read "Writing R
Extensions". If you
> really get stuck, you can then ask the mailing list a
very focused question
> along with an example that shows what is going wrong
for you. Then you have a
> good change of getting helpful answers.  Right now
your questions are spanning
> the entire spectrum from beginning to advanced
package authoring and so the
> most likely answer you will get from the list
is "slow down and read the
> manual".




smcguffee wrote:
> 
> Thanks for your help,
> 
> Sean
> 
> P.S.
>
> 
> The rest of this message is my rambling, so only those interested in my
>
> thoughts should continue reading. Especially those interested in sparing
>
> their own time should stop reading here--the question above is my last
>
> inquiry for the list. What comes below is just my train of thoughts/flow
>
> of
> consciousness spewing needlessly.
> 
> It was definitely a good idea for
> me to look in the R source code. It
> seems
> that dynload.c names.c dotcode.c
> Rdynload.c were of most interest to me in
> understanding that magical unicorn
> with an adorable animated cartoon
> story.
> I found that link quite enjoyable
> by they way! Regarding the files I just
> mentioned, I notice that the code is
> in the form of c files and that quite
> a
> lot of info from library files is
> used to get function pointers in the
> functions of interest to me. I wonder
> if making those files into cpp files
> that would get compiled with a c++
> compiler would let them call c++
> functions directly or if the info to get
> the function pointers would be of
> a
> completely different type of syntax
> and/or if there is more to that story.
> I
> suppose it makes no difference in
> practice because one would probably
> still
> have to make a c++ wrapper
> function to interface with R, but I'm just
> curious about this stuff. I mean,
> in principle, it makes sense to be able
> to
> call a function directly
> without having to go through the trouble of
> wrapping it in c, especially for
> hundreds of C++ functions in a library.
> It
> might be that I can write one
> general argument handling function in C as
> is
> to interface with R and let
> it call any of my C++ functions in my
> libraries,
> slightly shortening my
> tasks. Anyway, it was really eye opening to see
> that
> R is actually calling
> it's own generic pointers to functions and just
> pre-assigning them to
> function pointers from libraries. I didn't know that
> could be done, and I
> imagine hackers must love that capacity, a capacity
> that seems to be
> inherent in c or c++. It does seem a little bit limiting
> that the arguments
> are limited in number and that each function pointer
> with
> a different
> number of arguments has to be conditionally called inside the
> R
> code.
> However, I have the same complaint about bash having a limit on the
> total
> size of data that can be passed as arguments into an executable. It
> looks to
> me like fixing that type of thing in bash requires recompiling
> the
> kernel
> because it's hard wired non-dynamically into the capacity of
> launching
> executables themselves. I hope this type of thing starts to
> change
> as
> hardware is way exceeding the original expectations of the
> non-dynamically
> allocated original design of executable launch and dynamic
> allocation has
> clearly demonstrated it?s superiority in general. That type
> of thing comes
> into issue for me on command line scripts when I sometimes
> have lists of
> files that are longer than the capacity of command line
> arguments. For
> example, a "grep someText *" or ?ls *? will only work if
> the
> size of the
> arguments in the * expansion is less than the system's
> capacity
> for
> arguments passed to executables. I hit that limit all the time, and
> that's
> annoying because scripts that normally work break in larger
> situations,
> rendering their applicability useless in what are typically
> more
>
> interesting cases. Anyway, that's all a tangent from this R interfacing
>
> stuff. However, it was news to me that R could have a similar type of
>
> limit
> for functions in packages until I looked into the code. I don't think
> this
> is an issue in R because I'll just design one Rcpp argument to contain
> all
> the info I need inside itself. However, it's good to know that I need
> to
> do
> that. Anyway, I'm also wondering if it might be easier to modify
> compilers
> themselves and/or incorporate their code into R's code, i.e.
> easier than
> doing all this work around to fit into their mold. In a way that
> is sort
> of
> done to access the function pointers from libraries, but I
> mean, it seems
> logical that a program such as R should be able to call any
> function with
> any number of arguments abstractly without needing to have the
> functions
> get
> conditionally called with a given number of arguments at
> compile time for
> R.
> I can imagine converting a string to a call to a
> number of arguments that
> is
> determined by the syntax of the string without
> being defined before the
> compilation of R. That type of idea, if possible,
> could allow a more
> dynamic
> range of options in packages, at least not
> limited by a number of
> arguments.
> Like I said, that?s not important
> because one argument can contain an
> endless amount of info, but it sparked
> my curiosity. I might peak at GNU's
> gcc compiler collection to see if I can
> come up with some ideas for that
> type of thing--basically building dynamic
> compilation and execution
> options,
> but I imagine it would be way over my
> head, a long time coming, and of
> course potentially unstable. The long and
> short of it for me is that it
> was
> way cool to see how R is calling C
> functions from packages or non-R
> libraries.
> 

Quite a brain dump there!
> Some things that you may want to look into in the
future:

  - The original
> mailing list you posted to, Rcpp, is for an R package that
wraps the C API of
> R into C++ classes.  I would bet it also provides methods
for calling R code
> and C++ without having to write as many R functions.  I
have not had the
> pleasure of using Rcpp yet---Fortran was my first compiled
language and I am
> still moving my way up the food chain :)

  - The inline package may be of
> interest to you---It allows C, C++ and
Fortran programs to be stored as text
> strings at the R level and then
dynamically compiled, loaded and interfaced.
> Could be along the lines of
what you were thinking about with "building
> dynamic compilation and
execution options".

  - Also, it is always fun to
> drop by the Omegahat project
(www.omegahat.org) and see what Duncan Temple
> Lang has been cooking up. He
has a couple of packages for interfacing R with
> compiled code via LibFFI
(rather than the built in pointer method you
> observed) and one package that
has the beginnings of some LLVM
> bindings.


-Charlie


On 4/21/11 10:02 PM, "Sharpie"
> &lt;chuck at sharpsteen.net&gt; wrote:

> 
> smcguffee wrote:
>> 
>> You are
> right, I looked and I did find the R source code. However, it's
>> largely
> written in R! I mean, I don't know how to trace the R code where
>> INSTALL is
> recognized and follow it to a c or c++ level command. For
>> example
>> these
> are hits in .R files, not c files, and I don't know how to connect
>> 
>>
> ...
>> 
>> If you could point me to the functions that are called a c or c++
> level,
>> I'd
>> love to see what R is doing for myself.
>> Thanks!
>> Sean
>>
> 
> 
> Hi Sean!
> 
> Along with many other people in this thread, I would
> strongly recommend a
> top-down approach to this. Build a package, stick some
> stuff in the src
> folder, run R CMD INSTALL on it and see what happens. The
> reason I
> recommend
> this approach is that it lets you focus on writing a
> package that does
> something useful rather than the nuts and bolts of cross
> platform
> compilation and installation. R CMD INSTALL takes care of this for
> you
> automagically and it is very good at what it does.
> 
> I wrote a post
> some time back about building an example package from
> scratch
> that
> contains C code:
> 
>
> http://r.789695.n4.nabble.com/Writing-own-simulation-function-in-C-td1580190.h
> 
> tml#a1580423
> 
> It begins with the using the package.skeleton() function
> to kickstart
> things, discusses how to make sure the compiled code is
> dynamically loaded
> when a user runs library(your_package) and even discusses
> how to call R
> functions from inside of C functions and vice-versa. The
> example code is
> still available and I'm sure it could be generalized to C++
> quite easily.
> There are also some other responses in that thread that offer
> useful
> advice.
> 
> 
> At the beginning it is just best to treat R CMD
> INSTALL as a magical
> unicorn
> that gets you where you need to go:
> 
>
> http://abstrusegoose.com/120
> (keep clicking the images to get the full
> story)
> 
> 
> If you are absolutely, positively dying to know what really
> happens...
> well,
> the relative files in the R source are
> `src/library/tools/R/install.R` and
> `src/library/tools/R/build.R`.
> 
> 
>
> But seriously. Magical unicorn. Takes care of the hard stuff so you can
>
> build awesome packages.
> 
> Hope this helps!
> 
> -Charlie


-----
Charlie
> Sharpsteen
Undergraduate-- Environmental Resources Engineering
Humboldt State
> University
--
View this message in context:
> http://r.789695.n4.nabble.com/FW-Rcpp-devel-Question-on-5-6-Interfacing-C-code
> -tp3465257p3468640.html
Sent from the R devel mailing list archive at
> Nabble.com.

______________________________________________
R-devel at r-project.
> org mailing list
https://stat.ethz.ch/mailman/listinfo/r-devel


From simon.urbanek at r-project.org  Sat Apr 23 00:35:33 2011
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Fri, 22 Apr 2011 18:35:33 -0400
Subject: [Rd] using autoconf in packages [Was: Question on 5.6 Interfacing
	C++ code]
In-Reply-To: <1303500136567-3468640.post@n4.nabble.com>
References: <C9D47520.3D72%sean.mcguffee@gmail.com> <4DB011F3.80603@gmail.com>
	<19888.6774.24607.71449@max.nulle.part>
	<C9D5C297.3DCA%sean.mcguffee@gmail.com>
	<BANLkTimOXKGN2yUvxF_+-bKZgXQMfOBHHg@mail.gmail.com>
	<C9D5C7C2.3DD0%sean.mcguffee@gmail.com>
	<1303437747451-3467221.post@n4.nabble.com>
	<C9D73E32.3DFA%sean.mcguffee@gmail.com>
	<1303500136567-3468640.post@n4.nabble.com>
Message-ID: <4E0521A5-C18A-4314-9818-79E225E53C84@r-project.org>

On Apr 22, 2011, at 3:22 PM, Sharpie wrote:

> 
> smcguffee wrote:
>> 
>> Hi Charlie, 
>> 
>> Thanks for the help,
>> 
>> I think some of my story of having been reading the documentation and
>> playing with examples for weeks has gotten lost in the switch of threads.
>> I
>> think most of that confusion also comes from me not figuring out how to
>> connect different sections of the documentation. I think I get it now that
>> just because I can do 'R CMD SHLIB X.cc X_main.cc' from a command line
>> doesn?t mean that I need to put that command into a package directly, and
>> even that I can?t explicitly put that line in a package because it?s
>> magically done for me. I appreciate folks having patience with me as some
>> of
>> my questions seem redundant, but it is all starting to come together for
>> me.
>> 
> 
> When I first started out extending R with compiled code, I used R CMD SHLIB
> as well. Don't know why exactly, it was probably the first thing I stumbled
> across in the manual. Once I learned about making packages and that putting
> C, C++ or Fortran code in the `src` directory of the package magically
> caused a library to be built, I quit using R CMD SHLIB---probably haven't
> touched it in years.
> 
> I think R CMD SHLIB may be intended more for compiling external programs
> that want to hook into the R libraries rather than things intended to be
> loaded by R it's self.
> 
> 
> 
> smcguffee wrote:
>> 
>> At this point I think I am beginning to get a good enough idea of how this
>> stuff is working on the R interface side of things. I pretty much just
>> have
>> one more question:
>> 
>> How do I let users adjust their system specific paths to non-R libraries
>> for
>> my package installation but not for everyone else?s package installation?
>> I
>> get the feeling users can control things in my package somehow through
>> their
>> R configurations if I use the PKG_LIBS = `$(R_HOME)/bin/Rscript -e
>> "Rcpp:::LdFlags()"` command in the src/Makevars file. However, I'm still
>> lost as to how this would be customized to my package. I mean, that
>> command
>> doesn?t specify anything unique to my package and could potentially be
>> used
>> by other package installations too. That file is inside my package, so I
>> don?t think users can modify it directly and explicitly with their system
>> specific paths before they install. Maybe if other packages link to extra
>> libraries it doesn't hurt anything. Is that the answer? Would users need
>> to
>> add all my requisite non-R libraries into their R configurations to get
>> `$(R_HOME)/bin/Rscript -e "Rcpp:::LdFlags()"` to link my package correctly
>> and let all other packages link to way more libraries than necessary?
>> 
> 
> Well, the best answers to this question lie inside the "Writing R
> Extensions" manual---specifically Section 1.2 "Configure and Cleanup".  The
> short version is:
> 
> - If the code in your package needs custom compiler flags, add a 
> `src/Makevars` file that contains them.
> 
> - If the code in your package dependes on external libraries, add a
> Configure script, written using GNU autotools, that will produce
> `src/Makevars` from a template `src/Makevars.in` that contains the `-L` and
> `-I` flags required to link your code against the external library.
> 
> However, I will again suggest taking this one step at a time:
> 
>  - Build a toy package that includes C or C++ code that needs to be
> compiled. Observe how `R CMD INSTALL` compiles the code for you and how to
> use `.onLoad` or `.First.Lib` to `dyn.load` the resulting library when a
> user runs `library` on your package.  Bonus points for reading enough of
> "Writing R Extensions" to know if having an R NAMESPACE in your package has
> any effect on this process.
> 
>  - Extend your toy package to include C++ code that needs custom compiler
> flags. See how you can achieve this with `src/Makevars`.
> 
>  - Extend your package again with an external dependency that requires a
> `configure` script. A good example of such a package is `rgdal`---it has to
> find both the GDAL and PROJ4 libraries in order to compile operational code.
> 

I would just discourage looking at what it does to detect proj4 - that's not how configure should be written - running compilation by hand is very error prone (hard to debug, messes up config.log) and against the idea of autoconf - that's what AC_COMPILE_IFELSE, AC_LINK_IFELSE and friends are for. However, it does get other major things right (such as retrieving basic flags and compilers from R).

This is getting a bit off-topic, but I think it's important. Major points to keep in mind when writing configure scripts (IMHO):

1) always ask R for compiler and flags before using them (i.e.,before AC_PROG_CC).
2) always give the user a way to override defaults (defaults are always wrong at some point by definition) - preferably in a standard way
3) make sure the flags you check with (CPPFLAGS, CFLAGS, LDFLAGS, LIBS, ..) reflect what will be used by R from Makevars
4) make sure you test dependencies - if you don't, static libraries will fail so it's a good habit to test with static libraries

People very often forget about 3) -- all tests in autoconf are run respecting the standard flag environment variables, but if you set let's say PKG_LIBS to only include your additions (like -lfoo) then R will be using entirely different flags than autoconf, rendering the whole test useless.

Cheers,
Simon


> If you run into any trouble along the way, stop and read "Writing R
> Extensions". If you really get stuck, you can then ask the mailing list a
> very focused question along with an example that shows what is going wrong
> for you. Then you have a good change of getting helpful answers.  Right now
> your questions are spanning the entire spectrum from beginning to advanced
> package authoring and so the most likely answer you will get from the list
> is "slow down and read the manual".
> 
> 
> 
> 
> smcguffee wrote:
>> 
>> Thanks for your help,
>> 
>> Sean
>> 
>> P.S.
>> 
>> The rest of this message is my rambling, so only those interested in my
>> thoughts should continue reading. Especially those interested in sparing
>> their own time should stop reading here--the question above is my last
>> inquiry for the list. What comes below is just my train of thoughts/flow
>> of
>> consciousness spewing needlessly.
>> 
>> It was definitely a good idea for me to look in the R source code. It
>> seems
>> that dynload.c names.c dotcode.c Rdynload.c were of most interest to me in
>> understanding that magical unicorn with an adorable animated cartoon
>> story.
>> I found that link quite enjoyable by they way! Regarding the files I just
>> mentioned, I notice that the code is in the form of c files and that quite
>> a
>> lot of info from library files is used to get function pointers in the
>> functions of interest to me. I wonder if making those files into cpp files
>> that would get compiled with a c++ compiler would let them call c++
>> functions directly or if the info to get the function pointers would be of
>> a
>> completely different type of syntax and/or if there is more to that story.
>> I
>> suppose it makes no difference in practice because one would probably
>> still
>> have to make a c++ wrapper function to interface with R, but I'm just
>> curious about this stuff. I mean, in principle, it makes sense to be able
>> to
>> call a function directly without having to go through the trouble of
>> wrapping it in c, especially for hundreds of C++ functions in a library.
>> It
>> might be that I can write one general argument handling function in C as
>> is
>> to interface with R and let it call any of my C++ functions in my
>> libraries,
>> slightly shortening my tasks. Anyway, it was really eye opening to see
>> that
>> R is actually calling it's own generic pointers to functions and just
>> pre-assigning them to function pointers from libraries. I didn't know that
>> could be done, and I imagine hackers must love that capacity, a capacity
>> that seems to be inherent in c or c++. It does seem a little bit limiting
>> that the arguments are limited in number and that each function pointer
>> with
>> a different number of arguments has to be conditionally called inside the
>> R
>> code. However, I have the same complaint about bash having a limit on the
>> total size of data that can be passed as arguments into an executable. It
>> looks to me like fixing that type of thing in bash requires recompiling
>> the
>> kernel because it's hard wired non-dynamically into the capacity of
>> launching executables themselves. I hope this type of thing starts to
>> change
>> as hardware is way exceeding the original expectations of the
>> non-dynamically allocated original design of executable launch and dynamic
>> allocation has clearly demonstrated it?s superiority in general. That type
>> of thing comes into issue for me on command line scripts when I sometimes
>> have lists of files that are longer than the capacity of command line
>> arguments. For example, a "grep someText *" or ?ls *? will only work if
>> the
>> size of the arguments in the * expansion is less than the system's
>> capacity
>> for arguments passed to executables. I hit that limit all the time, and
>> that's annoying because scripts that normally work break in larger
>> situations, rendering their applicability useless in what are typically
>> more
>> interesting cases. Anyway, that's all a tangent from this R interfacing
>> stuff. However, it was news to me that R could have a similar type of
>> limit
>> for functions in packages until I looked into the code. I don't think this
>> is an issue in R because I'll just design one Rcpp argument to contain all
>> the info I need inside itself. However, it's good to know that I need to
>> do
>> that. Anyway, I'm also wondering if it might be easier to modify compilers
>> themselves and/or incorporate their code into R's code, i.e. easier than
>> doing all this work around to fit into their mold. In a way that is sort
>> of
>> done to access the function pointers from libraries, but I mean, it seems
>> logical that a program such as R should be able to call any function with
>> any number of arguments abstractly without needing to have the functions
>> get
>> conditionally called with a given number of arguments at compile time for
>> R.
>> I can imagine converting a string to a call to a number of arguments that
>> is
>> determined by the syntax of the string without being defined before the
>> compilation of R. That type of idea, if possible, could allow a more
>> dynamic
>> range of options in packages, at least not limited by a number of
>> arguments.
>> Like I said, that?s not important because one argument can contain an
>> endless amount of info, but it sparked my curiosity. I might peak at GNU's
>> gcc compiler collection to see if I can come up with some ideas for that
>> type of thing--basically building dynamic compilation and execution
>> options,
>> but I imagine it would be way over my head, a long time coming, and of
>> course potentially unstable. The long and short of it for me is that it
>> was
>> way cool to see how R is calling C functions from packages or non-R
>> libraries.
>> 
> 
> Quite a brain dump there!  Some things that you may want to look into in the
> future:
> 
>  - The original mailing list you posted to, Rcpp, is for an R package that
> wraps the C API of R into C++ classes.  I would bet it also provides methods
> for calling R code and C++ without having to write as many R functions.  I
> have not had the pleasure of using Rcpp yet---Fortran was my first compiled
> language and I am still moving my way up the food chain :)
> 
>  - The inline package may be of interest to you---It allows C, C++ and
> Fortran programs to be stored as text strings at the R level and then
> dynamically compiled, loaded and interfaced.  Could be along the lines of
> what you were thinking about with "building dynamic compilation and
> execution options".
> 
>  - Also, it is always fun to drop by the Omegahat project
> (www.omegahat.org) and see what Duncan Temple Lang has been cooking up. He
> has a couple of packages for interfacing R with compiled code via LibFFI
> (rather than the built in pointer method you observed) and one package that
> has the beginnings of some LLVM bindings.
> 
> 
> -Charlie
> 
> 
> On 4/21/11 10:02 PM, "Sharpie" &lt;chuck at sharpsteen.net&gt; wrote:
> 
>> 
>> smcguffee wrote:
>>> 
>>> You are right, I looked and I did find the R source code. However, it's
>>> largely written in R! I mean, I don't know how to trace the R code where
>>> INSTALL is recognized and follow it to a c or c++ level command. For
>>> example
>>> these are hits in .R files, not c files, and I don't know how to connect
>>> 
>>> ...
>>> 
>>> If you could point me to the functions that are called a c or c++ level,
>>> I'd
>>> love to see what R is doing for myself.
>>> Thanks!
>>> Sean
>>> 
>> 
>> Hi Sean!
>> 
>> Along with many other people in this thread, I would strongly recommend a
>> top-down approach to this. Build a package, stick some stuff in the src
>> folder, run R CMD INSTALL on it and see what happens. The reason I
>> recommend
>> this approach is that it lets you focus on writing a package that does
>> something useful rather than the nuts and bolts of cross platform
>> compilation and installation. R CMD INSTALL takes care of this for you
>> automagically and it is very good at what it does.
>> 
>> I wrote a post some time back about building an example package from
>> scratch
>> that contains C code:
>> 
>> http://r.789695.n4.nabble.com/Writing-own-simulation-function-in-C-td1580190.h
>> tml#a1580423
>> 
>> It begins with the using the package.skeleton() function to kickstart
>> things, discusses how to make sure the compiled code is dynamically loaded
>> when a user runs library(your_package) and even discusses how to call R
>> functions from inside of C functions and vice-versa. The example code is
>> still available and I'm sure it could be generalized to C++ quite easily.
>> There are also some other responses in that thread that offer useful
>> advice.
>> 
>> 
>> At the beginning it is just best to treat R CMD INSTALL as a magical
>> unicorn
>> that gets you where you need to go:
>> 
>> http://abstrusegoose.com/120
>> (keep clicking the images to get the full story)
>> 
>> 
>> If you are absolutely, positively dying to know what really happens...
>> well,
>> the relative files in the R source are `src/library/tools/R/install.R` and
>> `src/library/tools/R/build.R`.
>> 
>> 
>> But seriously. Magical unicorn. Takes care of the hard stuff so you can
>> build awesome packages.
>> 
>> Hope this helps!
>> 
>> -Charlie
> 
> 
> -----
> Charlie Sharpsteen
> Undergraduate-- Environmental Resources Engineering
> Humboldt State University
> --
> View this message in context: http://r.789695.n4.nabble.com/FW-Rcpp-devel-Question-on-5-6-Interfacing-C-code-tp3465257p3468640.html
> Sent from the R devel mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From sean.mcguffee at gmail.com  Sat Apr 23 10:03:36 2011
From: sean.mcguffee at gmail.com (Sean Robert McGuffee)
Date: Sat, 23 Apr 2011 04:03:36 -0400
Subject: [Rd] FW: [Rcpp-devel] Question on 5.6 Interfacing C++ code
In-Reply-To: <BC806D73-DE3B-424B-8F57-0A2803286439@r-project.org>
Message-ID: <C9D80018.3E13%sean.mcguffee@gmail.com>

Hi All,

Just to follow up, I finally figured out a way to make a simple test project
I'm working on to compile and install and have access the code inside of R.
It turns out it was related to this "foo" name. I had to make the name of my
dynamic library output have the same name as the "foo" from the DESCRIPTION
file (and useDynLib(foo) ). I had made changes from a sample Rcpp program
where I liked the way args were passed. However, I didn't keep the name of
my dynamic library the same as the name of my directory and the name of my
functions and the name of my code files and the name of my project, and it
seems to me that it matters in about three places that need to match.
Eventually, after weeks of guessing incorrectly that I was doing something
else wrong altogether, I tried renaming the files and got one permutation to
work. After fiddling around with it to get to the bottom of what was going
on, I got one of my old original directories out and simply changed the
dynamic library name between the src/ and the .so part to match with the
name in the DESCRIPTION and the name inside the useDynLib() inside the
NAMESPACE file. Was this obvious to everyone else from reading the manual?
There were so many things I didn't understand that I missed that part.
Anyway, I've learned something about autoconf out of the whole ordeal, so
sometimes it pays off for me to be so silly. Anyway, I'd just like to
confirm that this is correct:

If I want to name a package "MY_PACKAGE_NAME"
then I have to do three things with this name to get Rcpp and/or my package
calling c++ to install and run correctly. I'll call my package directory TOP
1) put the line "Package: MY_PACKAGE_NAME" inside of TOP/DESCRIPTION
2) put the line "useDynLib(MY_PACKAGE_NAME)" inside of TOP/NAMESPACE
3) make sure the final dynamic library is named TOP/src/MY_PACKAGE_NAME.so
Do the experts agree that this is correct and necessary?

I happen to have named TOP to be MY_PACKAGE_NAME too, is that important too?
I also happen to be naming my function MY_PACKAGE_NAME too, is that
important? If I want to add more functions, I assume I can do that as long
as I link them into the TOP/src/MY_PACKAGE_NAME.so file. Is that correct?

Thanks in advance, 

Sean



On 4/21/11 10:57 AM, "Simon Urbanek" <simon.urbanek at r-project.org> wrote:

> 
> On Apr 21, 2011, at 10:52 AM, Sean Robert McGuffee wrote:
> 
>> Thanks,
>> That's great, but I don't know how to determine what foo is.
> 
> It's the name of your package.
> 
> 
>> How do I declare the name of the package?
>> 
> 
> in DESCRIPTION:
> Package: name
> 
> and the directory of your package has to have the same name - please do read
> http://r.research.att.com/man/R-exts.html#Creating-R-packages
> 
> Cheers,
> Simon
> 
> 
>> 
>> On 4/21/11 7:16 AM, "Duncan Murdoch" <murdoch.duncan at gmail.com> wrote:
>> 
>>> On 11-04-20 11:33 AM, Sean Robert McGuffee wrote:
>>>> Hi, apparently I sent my question about using R and C++ to the wrong list,
>>>> ironically seeing as that list was called Rcpp. Anyway, I was directed to
>>>> post my question here. To summarize my current question, I have found two
>>>> commands that I want to be able to put into a package. The commands are 'R
>>>> CMD SHLIB X.cc X_main.cc' and
>>>> 'dyn.load(paste("X",.Platform$dynlib.ext,sep="")),' which I would like to
>>>> run when my package is installed and maybe have the second command run
>>>> again
>>>> when my package is to be used. I've been trying to figure out the
>>>> documentation and learn through examples, but I'm just not getting it and
>>>> have been trying for weeks.
>>>> Does anyone on this site have any suggestions for me?
>>> 
>>> Assuming those lines work on their own, just do the following:
>>> 
>>> 1.  Put those *.cc files into the src directory of your package.  (You
>>> may need to create it.)
>>> 
>>> 2.  Put useDynLib(foo) into the NAMESPACE file of your foo package.
>>> 
>>> 3.  Call those functions using .C("X", args, PACKAGE="foo").
>>> 
>>> That's it.
>>> 
>>> Duncan Murdoch
>>> 
>>>> Thanks, Sean
>>>> 
>>>> |On 20 April 2011 at 10:20, Sean Robert McGuffee wrote:
>>>> |
>>>> |
>>>> | Hi, thanks!
>>>> |
>>>> |>On 4/20/11 10:03 AM, "Steve Lianoglou"<mailinglist.honeypot at gmail.com>
>>>> wrote:
>>>> |>  Hi,
>>>> |>
>>>> |>  On Wed, Apr 20, 2011 at 9:49 AM, Sean Robert McGuffee
>>>> |>  <sean.mcguffee at gmail.com>  wrote:
>>>> |>>  Hi, I have a quick couple of questions about some of the documentation
>>>> on
>>>> |>>  the web page:
>>>> |>>
>>>> 
http://cran.r-project.org/doc/manuals/R-exts.html#Linking-GUIs-and-other-fr>>>>
o
>>>> n
>>>> |>>  t_002dends-to-R
>>>> |>>  under the heading:
>>>> |>>  5.6 Interfacing C++ code
>>>> |>>
>>>> |>>  Question 1:
>>>> |>>  If I?m at a terminal, I can type the instructions they suggest:
>>>> |>>  R CMD SHLIB X.cc X_main.cc
>>>> |>>  If I wanted a package to do this, how would I tell the package to do
>>>> that
>>>> |>>  same thing?
>>>> |>
>>>> |>  Just to make sure we're all on the same page, you want an R package to
>>>> |>  compile some source code into a shared library/dll from inside R?
>>>> |>
>>>> |>  Not sure if there's a "baked in" way for that to happen, but maybe you
>>>> |>  can invoke `R CMD WHATEVER` from inside R using the `system` function:
>>>> |>
>>>> |>  R>  ?system
>>>> |>
>>>> |
>>>> | ok, so where in the package would I put the system call in the package to
>>>> | have it run when installing the package?
>>>> 
>>>>> You don't. As I said, 'R CMD INSTALL' et all do that.
>>>>> Download an existing package with source, install it.  Study its sources,
>>>>> study the 'Writing R Extensions' manual.  Ask on r-devel.
>>>>> Basic R questions are off-topic here.
>>>> 
>>>> |>>  Would I use the same command and just include it in a file somewhere
>>>> in
>>>> the
>>>> |>>  package?
>>>> |>>  If so, which file?
>>>> |>
>>>> |>  Hmm ... I'm curious what you're trying to do, exactly?
>>>> |
>>>> | I'm trying to figure out how take commands such as " R CMD SHLIB X.cc
>>>> | X_main.cc" followed by "dyn.load(paste("X", .Platform$dynlib.ext, sep =
>>>> | ""))," which are commands I can get to work for myself as a human
>>>> | interactively, and put the commands into a package to be automatically
>>>> run
>>>> | when installing the package. I mean, it's great if I can compile a c++
>>>> file
>>>> | and then use it inside R, but I'm only doing that so I can let other
>>>> people
>>>> | do that via a package. As much as I read this documentation, I keep
>>>> missing
>>>> 
>>>>> Again, I like working from an existing, working package. As I said, there
>>>>> are
>>>>> almost 1000 to pick from.
>>>>> Please direct follow-ups that have no bearing on Rcpp to r-devel.
>>>>> Dirk
>>>> 
>>>> I've tried to figure this out for weeks by looking at other packages and
>>>> reading the confusing and nonintegrated documentation, but it hasn't taught
>>>> me how to put the two commands into a package so that they are run when the
>>>> package is installed. I'm simply trying to find out where in my package I
>>>> should put the commands 'R CMD SHLIB X.cc X_main.cc' and
>>>> 'dyn.load(paste("X",.Platform$dynlib.ext,sep="")),'
>>>> in order to have them run when my package is installed.
>>>> 
>>>> 
>>>> | the connections between the different sections. This is a section I am
>>>> | loving because it works very well. Thus, I want to figure out how to take
>>>> | the baby steps I'm doing and combine them into a package. Specifically, I
>>>> | want to take these two commands and insert them into a package so that
>>>> these
>>>> | commands will compile my code and make a dynamic ".so" file where R can
>>>> | access its functions when others install my package.
>>>> |
>>>> |>
>>>> |>>  Question 2:
>>>> |>>  dyn.load(paste("X", .Platform$dynlib.ext, sep = ""))
>>>> |>>
>>>> |>>  Where does .Platform$dynlib.ext come from?
>>>> |>>  What does it mean?
>>>> |>>  What do it?s components .Platform and $dynlib and .ext mean?
>>>> |>
>>>> |>  .Platform is lust a normal list -- it is defined internally (I guess).
>>>> |>  You can access "named" elements of a list with `$`.
>>>> |>
>>>> |>  .Platform$dynlyb (or .Platform[['dynlib']]) tells you the extension
>>>> |>  your particular system uses for shared libraries:
>>>> |>
>>>> |>  R>  .Platform
>>>> |>  $OS.type
>>>> |>  [1] "unix"
>>>> |>
>>>> |>  $file.sep
>>>> |>  [1] "/"
>>>> |>
>>>> |>  $dynlib.ext
>>>> |>  [1] ".so"
>>>> |>
>>>> |>  $GUI
>>>> |>  [1] "X11"
>>>> |>
>>>> |>  $endian
>>>> |>  [1] "little"
>>>> |>
>>>> |>  $pkgType
>>>> |>  [1] "mac.binary.leopard"
>>>> |>
>>>> |>  $path.sep
>>>> |>  [1] ":"
>>>> |>
>>>> |>  $r_arch
>>>> |>  [1] "x86_64"
>>>> |>
>>>> |>  See ?.Platform for more help.
>>>> |
>>>> | Ah, thanks, that clarifies exactly what .Platform$dynlib.ext is, it's
>>>> ".so"
>>>> | on my system.
>>>> |
>>>> | This, the dyn.load(paste("X", .Platform$dynlib.ext, sep = "")) is
>>>> equivalent
>>>> | to the command dyn.load("X.so) which now makes sense in that context!
>>>> |
>>>> |
>>>> | _______________________________________________
>>>> | Rcpp-devel mailing list
>>>> | Rcpp-devel at lists.r-forge.r-project.org
>>>> | https://lists.r-forge.r-project.org/cgi-bin/mailman/listinfo/rcpp-devel
>>>> 
>>> 
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> 
>> 
> 


From maechler at stat.math.ethz.ch  Sat Apr 23 11:56:12 2011
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Sat, 23 Apr 2011 11:56:12 +0200
Subject: [Rd] FW: [Rcpp-devel] Question on 5.6 Interfacing C++ code
In-Reply-To: <BC806D73-DE3B-424B-8F57-0A2803286439@r-project.org>
References: <C9D5BCF3.3DC6%sean.mcguffee@gmail.com>
	<BC806D73-DE3B-424B-8F57-0A2803286439@r-project.org>
Message-ID: <19890.41532.259448.771432@stat.math.ethz.ch>

>>>>> Simon Urbanek <simon.urbanek at r-project.org>
>>>>>     on Thu, 21 Apr 2011 10:57:19 -0400 writes:

    > On Apr 21, 2011, at 10:52 AM, Sean Robert McGuffee wrote:

    >> Thanks,
    >> That's great, but I don't know how to determine what foo is.

    > It's the name of your package.


    >> How do I declare the name of the package?
    >> 

    > in DESCRIPTION:
    > Package: name

    > and the directory of your package has to have the same name -

that is no longer true ( since .. rough guess ... about two
years).
And that's actually quite an important feature to me.
E.g., I can have a directory, say   lme4_MM_2001-04-18/
with a "particularly hacked" version version,
and then simply  do  
    R CMD check lme4_MM_2001-04-18
which will install and check it in  lme4_MM_2001-04-18.Rcheck/

    > please do read
    > http://r.research.att.com/man/R-exts.html#Creating-R-packages

so indeed, we should cancel the sentence
   The package subdirectory should be given the same name as the package.  
in there, or maybe rather replace it by
   The package subdirectory typically has the same name as the package.  

Martin

    > Cheers,
    > Simon


    >> 
    >> On 4/21/11 7:16 AM, "Duncan Murdoch" <murdoch.duncan at gmail.com>
    >> wrote:
    >> 
    >>> On 11-04-20 11:33 AM, Sean Robert McGuffee wrote:
    >>>> Hi, apparently I sent my question about using R and C++ to
    >>>> the wrong list, ironically seeing as that list was called
    >>>> Rcpp. Anyway, I was directed to post my question here. To
    >>>> summarize my current question, I have found two commands that
    >>>> I want to be able to put into a package. The commands are 'R
    >>>> CMD SHLIB X.cc X_main.cc' and
    >>>> 'dyn.load(paste("X",.Platform$dynlib.ext,sep="")),' which I
    >>>> would like to run when my package is installed and maybe have
    >>>> the second command run again when my package is to be
    >>>> used. I've been trying to figure out the documentation and
    >>>> learn through examples, but I'm just not getting it and have
    >>>> been trying for weeks.  Does anyone on this site have any
    >>>> suggestions for me?
    >>> 
    >>> Assuming those lines work on their own, just do the following:
    >>> 
    >>> 1.  Put those *.cc files into the src directory of your
    >>> package.  (You may need to create it.)
    >>> 
    >>> 2.  Put useDynLib(foo) into the NAMESPACE file of your foo
    >>> package.
    >>> 
    >>> 3.  Call those functions using .C("X", args, PACKAGE="foo").
    >>> 
    >>> That's it.
    >>> 
    >>> Duncan Murdoch
    >>> 
    >>>> Thanks, Sean
    >>>> 
    >>>> |On 20 April 2011 at 10:20, Sean Robert McGuffee wrote:
    >>>> |
    >>>> |
    >>>> | Hi, thanks!
    >>>> |
    >>>> |>On 4/20/11 10:03 AM, "Steve
    >>>> Lianoglou"<mailinglist.honeypot at gmail.com> wrote: |> Hi,
    >>>> |>
    >>>> |> On Wed, Apr 20, 2011 at 9:49 AM, Sean Robert McGuffee |>
    >>>> <sean.mcguffee at gmail.com> wrote: |>> Hi, I have a quick
    >>>> couple of questions about some of the documentation on |>>
    >>>> the web page:
    >>>> |>>
    >>>> http://cran.r-project.org/doc/manuals/R-exts.html#Linking-GUIs-and-other-fro
    >>>> n |>> t_002dends-to-R |>> under the heading: |>> 5.6
    >>>> Interfacing C++ code
    >>>> |>>
    >>>> |>> Question 1: |>> If I?m at a terminal, I can type the
    >>>> instructions they suggest: |>> R CMD SHLIB X.cc X_main.cc |>>
    >>>> If I wanted a package to do this, how would I tell the
    >>>> package to do that |>> same thing?
    >>>> |>
    >>>> |> Just to make sure we're all on the same page, you want an
    >>>> R package to |> compile some source code into a shared
    >>>> library/dll from inside R?
    >>>> |>
    >>>> |> Not sure if there's a "baked in" way for that to happen,
    >>>> but maybe you |> can invoke `R CMD WHATEVER` from inside R
    >>>> using the `system` function:
    >>>> |>
    >>>> |> R> ?system
    >>>> |>
    >>>> |
    >>>> | ok, so where in the package would I put the system call in
    >>>> the package to | have it run when installing the package?
    >>>> 
    >>>>> You don't. As I said, 'R CMD INSTALL' et all do that.
    >>>>> Download an existing package with source, install it.  Study
    >>>>> its sources, study the 'Writing R Extensions' manual.  Ask
    >>>>> on r-devel.  Basic R questions are off-topic here.
    >>>> 
    >>>> |>> Would I use the same command and just include it in a
    >>>> file somewhere in the |>> package?  |>> If so, which file?
    >>>> |>
    >>>> |> Hmm ... I'm curious what you're trying to do, exactly?
    >>>> |
    >>>> | I'm trying to figure out how take commands such as " R CMD
    >>>> SHLIB X.cc | X_main.cc" followed by "dyn.load(paste("X",
    >>>> .Platform$dynlib.ext, sep = | ""))," which are commands I can
    >>>> get to work for myself as a human | interactively, and put
    >>>> the commands into a package to be automatically run | when
    >>>> installing the package. I mean, it's great if I can compile a
    >>>> c++ file | and then use it inside R, but I'm only doing that
    >>>> so I can let other people | do that via a package. As much as
    >>>> I read this documentation, I keep missing
    >>>> 
    >>>>> Again, I like working from an existing, working package. As
    >>>>> I said, there are almost 1000 to pick from.  Please direct
    >>>>> follow-ups that have no bearing on Rcpp to r-devel.  Dirk
    >>>> 
    >>>> I've tried to figure this out for weeks by looking at other
    >>>> packages and reading the confusing and nonintegrated
    >>>> documentation, but it hasn't taught me how to put the two
    >>>> commands into a package so that they are run when the package
    >>>> is installed. I'm simply trying to find out where in my
    >>>> package I should put the commands 'R CMD SHLIB X.cc
    >>>> X_main.cc' and
    >>>> 'dyn.load(paste("X",.Platform$dynlib.ext,sep="")),' in order
    >>>> to have them run when my package is installed.
    >>>> 
    >>>> 
    >>>> | the connections between the different sections. This is a
    >>>> section I am | loving because it works very well. Thus, I
    >>>> want to figure out how to take | the baby steps I'm doing and
    >>>> combine them into a package. Specifically, I | want to take
    >>>> these two commands and insert them into a package so that
    >>>> these | commands will compile my code and make a dynamic
    >>>> ".so" file where R can | access its functions when others
    >>>> install my package.
    >>>> |
    >>>> |>
    >>>> |>> Question 2: |>> dyn.load(paste("X", .Platform$dynlib.ext,
    >>>> sep = ""))
    >>>> |>>
    >>>> |>> Where does .Platform$dynlib.ext come from?  |>> What does
    >>>> it mean?  |>> What do it?s components .Platform and $dynlib
    >>>> and .ext mean?
    >>>> |>
    >>>> |> .Platform is lust a normal list -- it is defined
    >>>> internally (I guess).  |> You can access "named" elements of
    >>>> a list with `$`.
    >>>> |>
    >>>> |> .Platform$dynlyb (or .Platform[['dynlib']]) tells you the
    >>>> extension |> your particular system uses for shared
    >>>> libraries:
    >>>> |>
    >>>> |> R> .Platform |> $OS.type |> [1] "unix"
    >>>> |>
    >>>> |> $file.sep |> [1] "/"
    >>>> |>
    >>>> |> $dynlib.ext |> [1] ".so"
    >>>> |>
    >>>> |> $GUI |> [1] "X11"
    >>>> |>
    >>>> |> $endian |> [1] "little"
    >>>> |>
    >>>> |> $pkgType |> [1] "mac.binary.leopard"
    >>>> |>
    >>>> |> $path.sep |> [1] ":"
    >>>> |>
    >>>> |> $r_arch |> [1] "x86_64"
    >>>> |>
    >>>> |> See ?.Platform for more help.
    >>>> |
    >>>> | Ah, thanks, that clarifies exactly what
    >>>> .Platform$dynlib.ext is, it's ".so" | on my system.
    >>>> |
    >>>> | This, the dyn.load(paste("X", .Platform$dynlib.ext, sep =
    >>>> "")) is equivalent | to the command dyn.load("X.so) which now
    >>>> makes sense in that context!
    >>>> |
    >>>> |
    >>>> | _______________________________________________ |
    >>>> Rcpp-devel mailing list |
    >>>> Rcpp-devel at lists.r-forge.r-project.org |
    >>>> https://lists.r-forge.r-project.org/cgi-bin/mailman/listinfo/rcpp-devel
    >>>> 
    >>> 
    >> 
    >> ______________________________________________
    >> R-devel at r-project.org mailing list
    >> https://stat.ethz.ch/mailman/listinfo/r-devel
    >> 
    >> 

    > ______________________________________________
    > R-devel at r-project.org mailing list
    > https://stat.ethz.ch/mailman/listinfo/r-devel


From maechler at stat.math.ethz.ch  Sat Apr 23 14:12:02 2011
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Sat, 23 Apr 2011 14:12:02 +0200
Subject: [Rd] An update of the Distribustions man page
In-Reply-To: <BANLkTi=YfjuY-AwnhrMXhsVtgAENz5Or9g@mail.gmail.com>
References: <BANLkTi=YfjuY-AwnhrMXhsVtgAENz5Or9g@mail.gmail.com>
Message-ID: <19890.49682.892757.161528@stat.math.ethz.ch>

>>>>> Christophe Dutang <dutangc at gmail.com>
>>>>>     on Tue, 19 Apr 2011 16:03:06 +0200 writes:

    > Dear list, I would like to suggest a small update the
    > ?Distributions man page of the stats package. The current
    > version contains the following line.

    > The CRAN package \pkg{SuppDists} for additional distributions.

    > I think it would be better to put in this man page a link to the
    > CRAN task view on Distributions
    > http://cran.r-project.org/web/views/Distributions.html. It is
    > not true that the SuppDists package alone contains distributions
    > which are not implemented in R base.

    > Could it be possible to modify this sentence?

Yes, I have done so now.
The  Distributions  task view is indeed much more comprehensive
than just the SuppDists package ... which indeed used to be the
first (or one of the..) CRAN package extending distributions
functionality.


    > I don't know if there are other overview man pages in R related
    > to other task views? But a link to the task views on those man
    > pages could increase the popularity of the CRAN task views.

Good point.... Up to now I haven't take time to look through the
R sources for such candidate pages.

Suggestions are welcome.


    > Kind regards
    > Christophe

Thank you for the suggestion, Christophe!

Martin Maechler,
ETH Zurich


    > -- 
    > Christophe DUTANG
    > Ph. D. student at ISFA, Lyon, France


From xie at yihui.name  Sat Apr 23 18:36:01 2011
From: xie at yihui.name (Yihui Xie)
Date: Sat, 23 Apr 2011 11:36:01 -0500
Subject: [Rd] R 2.13.0-beta for Windows,
 file.copy() throws suspicious errors due to default value of
 copy.mode
In-Reply-To: <1302209942002-3434559.post@n4.nabble.com>
References: <1302209942002-3434559.post@n4.nabble.com>
Message-ID: <BANLkTinkYqwkoWk9e3O2+8vFSCwHxq-GLQ@mail.gmail.com>

It seems I can reproduce this error under Windows 7 too; it happens
when a file is copied to a directory:

> dir.create('abc')
> file.create('testfile')
[1] TRUE
> file.copy('testfile','testfile2')
[1] TRUE
> file.copy('testfile','abc/')
Error in Sys.chmod(to[okay], file.info(from[okay])$mode, TRUE) :
  'mode' must be of length at least one
In addition: Warning message:
In file.create(to[okay]) :
  cannot create file 'abc/', reason 'Permission denied'
> sessionInfo()
R version 2.13.0 (2011-04-13)
Platform: i386-pc-mingw32/i386 (32-bit)

locale:
[1] LC_COLLATE=Chinese (Simplified)_People's Republic of China.936
[2] LC_CTYPE=Chinese (Simplified)_People's Republic of China.936
[3] LC_MONETARY=Chinese (Simplified)_People's Republic of China.936
[4] LC_NUMERIC=C
[5] LC_TIME=Chinese (Simplified)_People's Republic of China.936

attached base packages:
[1] tools     stats     graphics  grDevices utils     datasets  methods
[8] base


Regards,
Yihui
--
Yihui Xie <xieyihui at gmail.com>
Phone: 515-294-2465 Web: http://yihui.name
Department of Statistics, Iowa State University
2215 Snedecor Hall, Ames, IA



On Thu, Apr 7, 2011 at 3:59 PM, Sharpie <chuck at sharpsteen.net> wrote:
> While checking packages against R 2.13.0-beta on Windows, I have run into a
> few strange error messages related to copying files. The errors all relate
> to file.copy() and have the form of:
>
> Error in Sys.chmod(to[okay], file.info(from[okay])$mode, TRUE) :
> ?'mode' must be of length at least one
>
> After half a day of tinkering, the best reproducible example I can come up
> with involves using Roxygen to generate man files for the tikzDevice:
>
> # Install roxygen from CRAN and grab tikzDevice source code
> R --vanilla --slave -e "install.packages('roxygen')"
> git clone git://github.com/Sharpie/RTikZDevice.git
>
> # Generate documentation, first run succeeds:
> R --vanilla --slave -e "require(roxygen); roxygenize('RTikZDevice',
> 'RTikZDevice.build', overwrite = TRUE)"
>
> Loading required package: roxygen
> Loading required package: digest
> Writing anyMultibyteUTF8Characters to
> RTikZDevice.copy/man/anyMultibyteUTF8Characters.Rd
> Warning in parse.name(partitum) :
> ?No name found for the following expression in RTikZDevice/R/cacheMetrics.R
> line 3:
> ?`NULL . . .'
> Writing queryMetricsDictionary to
> RTikZDevice.copy/man/queryMetricsDictionary.Rd
> ...
> Writing namespace directives to RTikZDevice.copy/NAMESPACE
> Merging collate directive with RTikZDevice/DESCRIPTION to
> RTikZDevice.copy/DESCRIPTION
>
> # Try running it again, and it bombs:
> R --vanilla --slave -e "require(roxygen); roxygenize('RTikZDevice',
> 'RTikZDevice.build', overwrite = TRUE)"
>
> Loading required package: roxygen
> Loading required package: digest
> Error in Sys.chmod(to[okay], file.info(from[okay])$mode, TRUE) :
> ?'mode' must be of length at least one
> Calls: roxygenize -> copy.dir -> file.copy -> Sys.chmod
> In addition: Warning message:
> In file.create(to[okay]) :
> ?cannot create file
> 'RTikZDevice.copy/.git/objects/pack/pack-cc0dd1e2622e87f86f8c5a8e617fbf77e253cea1.idx',
> reason 'Permission denied'
> Execution halted
>
>
> If I replace all calls to file.copy(...) in the roxygen package with
> file.copy(..., copy.mode = FALSE) and reinstall it, then I can regenerate
> package documentation all day long without errors. I also get no errors when
> I perform the same task with R 2.12.2 on Windows or R 2.13.0-beta on OS X
> and Linux.
>
> Maybe roxygenize() is abusing file.copy() somehow, but I find the "'mode'
> must be of length at least one" error suspicious.
>
> Any ideas?
>
> Using:
> Windows 7 x86_64
> R 2.13.0-beta
> Rtools 2.13
>
> -Charlie
>
>
> -----
> Charlie Sharpsteen
> Undergraduate-- Environmental Resources Engineering
> Humboldt State University


From cstrato at aon.at  Sat Apr 23 21:50:55 2011
From: cstrato at aon.at (cstrato)
Date: Sat, 23 Apr 2011 21:50:55 +0200
Subject: [Rd] How to create vignette.pdf for R-2.13.0?
Message-ID: <4DB32D9F.5010406@aon.at>

Dear all,

While R CMD check and R CMD INSTALL have always created the vignettes on 
R-2.12.1 or any earlier versions of R, I am no longer able to build the 
vignettes on R-2.13.0.

Instead R CMD check gives me the following output:

* checking for unstated dependencies in vignettes ... OK
* checking package vignettes in 'inst/doc' ... WARNING
Package vignette(s) without corresponding PDF:
    APTvsXPS.Rnw
    xps.Rnw
    xpsClasses.Rnw
    xpsPreprocess.Rnw

* checking running R code from vignettes ... OK
* checking re-building of vignettes ... OK
* checking PDF version of manual ... OK


Does someone know what the reason might be?

(R64 CMD check --help says that be default rebuild-vignettes is turned on.)

Interestingly, R CMD check still creates the file "xps-manual.pdf".

Here is my sessionInfo:

 > sessionInfo()
R version 2.13.0 (2011-04-13)
Platform: x86_64-apple-darwin9.8.0/x86_64 (64-bit)

locale:
[1] C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] xps_1.13.1

loaded via a namespace (and not attached):
[1] Biobase_2.12.1        Biostrings_2.20.0     IRanges_1.10.0
[4] affy_1.30.0           affyPLM_1.28.5        affyio_1.20.0
[7] preprocessCore_1.14.0

Thank you in advance.
Best regards
Christian
_._._._._._._._._._._._._._._._._._
C.h.r.i.s.t.i.a.n   S.t.r.a.t.o.w.a
V.i.e.n.n.a           A.u.s.t.r.i.a
e.m.a.i.l:        cstrato at aon.at
_._._._._._._._._._._._._._._._._._


From oowar at yahoo.com  Sun Apr 24 16:08:54 2011
From: oowar at yahoo.com (Orin Richards)
Date: Sun, 24 Apr 2011 15:08:54 +0100 (BST)
Subject: [Rd] Loading a package
In-Reply-To: <4DB32D9F.5010406@aon.at>
References: <4DB32D9F.5010406@aon.at>
Message-ID: <954702.31628.qm@web29713.mail.ird.yahoo.com>



Hello All,
I heard of the First() function in R. but am not sure entirely how it is used. 
 I would like to load an R package at startup, instead of having to manually 
load each time I run R. How is the first() function used to achieve this .

Specifically I would like to tell R at startup to look in a specific folder for 
the package and load it.

Is there a way to do this, and is there any code sample code avail for this.


Thanks for your help.

Orin


From ligges at statistik.tu-dortmund.de  Sun Apr 24 16:12:03 2011
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sun, 24 Apr 2011 16:12:03 +0200
Subject: [Rd] How to create vignette.pdf for R-2.13.0?
In-Reply-To: <4DB32D9F.5010406@aon.at>
References: <4DB32D9F.5010406@aon.at>
Message-ID: <4DB42FB3.9090401@statistik.tu-dortmund.de>



On 23.04.2011 21:50, cstrato wrote:
> Dear all,
>
> While R CMD check and R CMD INSTALL have always created the vignettes on
> R-2.12.1 or any earlier versions of R, I am no longer able to build the
> vignettes on R-2.13.0.
>
> Instead R CMD check gives me the following output:
>
> * checking for unstated dependencies in vignettes ... OK
> * checking package vignettes in 'inst/doc' ... WARNING
> Package vignette(s) without corresponding PDF:
> APTvsXPS.Rnw
> xps.Rnw
> xpsClasses.Rnw
> xpsPreprocess.Rnw
>
> * checking running R code from vignettes ... OK
> * checking re-building of vignettes ... OK
> * checking PDF version of manual ... OK
>
>
> Does someone know what the reason might be?

No, it does for me for other packages.
Perhaps an error when processing the vignettes? Have you tried to build 
them manually?


> (R64 CMD check --help says that be default rebuild-vignettes is turned on.)
>
> Interestingly, R CMD check still creates the file "xps-manual.pdf".

That is the collection of help pages, unrelated to the vignette.


Uwe Ligges



> Here is my sessionInfo:
>
>  > sessionInfo()
> R version 2.13.0 (2011-04-13)
> Platform: x86_64-apple-darwin9.8.0/x86_64 (64-bit)
>
> locale:
> [1] C
>
> attached base packages:
> [1] stats graphics grDevices utils datasets methods base
>
> other attached packages:
> [1] xps_1.13.1
>
> loaded via a namespace (and not attached):
> [1] Biobase_2.12.1 Biostrings_2.20.0 IRanges_1.10.0
> [4] affy_1.30.0 affyPLM_1.28.5 affyio_1.20.0
> [7] preprocessCore_1.14.0
>
> Thank you in advance.
> Best regards
> Christian
> _._._._._._._._._._._._._._._._._._
> C.h.r.i.s.t.i.a.n S.t.r.a.t.o.w.a
> V.i.e.n.n.a A.u.s.t.r.i.a
> e.m.a.i.l: cstrato at aon.at
> _._._._._._._._._._._._._._._._._._
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From ligges at statistik.tu-dortmund.de  Sun Apr 24 16:14:33 2011
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sun, 24 Apr 2011 16:14:33 +0200
Subject: [Rd] Loading a package
In-Reply-To: <954702.31628.qm@web29713.mail.ird.yahoo.com>
References: <4DB32D9F.5010406@aon.at>
	<954702.31628.qm@web29713.mail.ird.yahoo.com>
Message-ID: <4DB43049.40206@statistik.tu-dortmund.de>

See ?Startup

Uwe Ligges

On 24.04.2011 16:08, Orin Richards wrote:
>
>
> Hello All,
> I heard of the First() function in R. but am not sure entirely how it is used.
>   I would like to load an R package at startup, instead of having to manually
> load each time I run R. How is the first() function used to achieve this .
>
> Specifically I would like to tell R at startup to look in a specific folder for
> the package and load it.
>
> Is there a way to do this, and is there any code sample code avail for this.
>
>
> Thanks for your help.
>
> Orin
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From kasperdanielhansen at gmail.com  Sun Apr 24 16:17:36 2011
From: kasperdanielhansen at gmail.com (Kasper Daniel Hansen)
Date: Sun, 24 Apr 2011 10:17:36 -0400
Subject: [Rd] Loading a package
In-Reply-To: <954702.31628.qm@web29713.mail.ird.yahoo.com>
References: <4DB32D9F.5010406@aon.at>
	<954702.31628.qm@web29713.mail.ird.yahoo.com>
Message-ID: <BANLkTik-WhXGDy04PsT95XxmCochvvuySg@mail.gmail.com>

On Sun, Apr 24, 2011 at 10:08 AM, Orin Richards <oowar at yahoo.com> wrote:
>
>
> Hello All,
> I heard of the First() function in R. but am not sure entirely how it is used.
> ?I would like to load an R package at startup, instead of having to manually
> load each time I run R. How is the first() function used to achieve this .
>
> Specifically I would like to tell R at startup to look in a specific folder for
> the package and load it.
>
> Is there a way to do this, and is there any code sample code avail for this.

Orin

Is this for a package (in which case you solve it by using Depends) or
is it in general for your usage?  If the later, you can put code into
~/.Rprofile which is essentially an R script that gets run every time
you start R.  The code in the file would be something like
  library(PKGNAME, lib.loc = "DIR")

Kasper


From ligges at statistik.tu-dortmund.de  Sun Apr 24 18:00:50 2011
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sun, 24 Apr 2011 18:00:50 +0200
Subject: [Rd] R 2.13.0-beta for Windows,
 file.copy() throws suspicious errors due to default value of
 copy.mode
In-Reply-To: <BANLkTinkYqwkoWk9e3O2+8vFSCwHxq-GLQ@mail.gmail.com>
References: <1302209942002-3434559.post@n4.nabble.com>
	<BANLkTinkYqwkoWk9e3O2+8vFSCwHxq-GLQ@mail.gmail.com>
Message-ID: <4DB44932.7020202@statistik.tu-dortmund.de>



On 23.04.2011 18:36, Yihui Xie wrote:
> It seems I can reproduce this error under Windows 7 too; it happens
> when a file is copied to a directory:
>
>> dir.create('abc')
>> file.create('testfile')
> [1] TRUE
>> file.copy('testfile','testfile2')
> [1] TRUE
>> file.copy('testfile','abc/')

You must not use a trailing slash.
file.copy('testfile','abc') should work.



> Error in Sys.chmod(to[okay], file.info(from[okay])$mode, TRUE) :
>    'mode' must be of length at least one

This error message is somewhat misleading and has been analyzed already, 
shortly to be fixed in the sources.

Best wishes,
Uwe




> In addition: Warning message:
> In file.create(to[okay]) :
>    cannot create file 'abc/', reason 'Permission denied'
>> sessionInfo()
> R version 2.13.0 (2011-04-13)
> Platform: i386-pc-mingw32/i386 (32-bit)
>
> locale:
> [1] LC_COLLATE=Chinese (Simplified)_People's Republic of China.936
> [2] LC_CTYPE=Chinese (Simplified)_People's Republic of China.936
> [3] LC_MONETARY=Chinese (Simplified)_People's Republic of China.936
> [4] LC_NUMERIC=C
> [5] LC_TIME=Chinese (Simplified)_People's Republic of China.936
>
> attached base packages:
> [1] tools     stats     graphics  grDevices utils     datasets  methods
> [8] base
>
>
> Regards,
> Yihui
> --
> Yihui Xie<xieyihui at gmail.com>
> Phone: 515-294-2465 Web: http://yihui.name
> Department of Statistics, Iowa State University
> 2215 Snedecor Hall, Ames, IA
>
>
>
> On Thu, Apr 7, 2011 at 3:59 PM, Sharpie<chuck at sharpsteen.net>  wrote:
>> While checking packages against R 2.13.0-beta on Windows, I have run into a
>> few strange error messages related to copying files. The errors all relate
>> to file.copy() and have the form of:
>>
>> Error in Sys.chmod(to[okay], file.info(from[okay])$mode, TRUE) :
>>   'mode' must be of length at least one
>>
>> After half a day of tinkering, the best reproducible example I can come up
>> with involves using Roxygen to generate man files for the tikzDevice:
>>
>> # Install roxygen from CRAN and grab tikzDevice source code
>> R --vanilla --slave -e "install.packages('roxygen')"
>> git clone git://github.com/Sharpie/RTikZDevice.git
>>
>> # Generate documentation, first run succeeds:
>> R --vanilla --slave -e "require(roxygen); roxygenize('RTikZDevice',
>> 'RTikZDevice.build', overwrite = TRUE)"
>>
>> Loading required package: roxygen
>> Loading required package: digest
>> Writing anyMultibyteUTF8Characters to
>> RTikZDevice.copy/man/anyMultibyteUTF8Characters.Rd
>> Warning in parse.name(partitum) :
>>   No name found for the following expression in RTikZDevice/R/cacheMetrics.R
>> line 3:
>>   `NULL . . .'
>> Writing queryMetricsDictionary to
>> RTikZDevice.copy/man/queryMetricsDictionary.Rd
>> ...
>> Writing namespace directives to RTikZDevice.copy/NAMESPACE
>> Merging collate directive with RTikZDevice/DESCRIPTION to
>> RTikZDevice.copy/DESCRIPTION
>>
>> # Try running it again, and it bombs:
>> R --vanilla --slave -e "require(roxygen); roxygenize('RTikZDevice',
>> 'RTikZDevice.build', overwrite = TRUE)"
>>
>> Loading required package: roxygen
>> Loading required package: digest
>> Error in Sys.chmod(to[okay], file.info(from[okay])$mode, TRUE) :
>>   'mode' must be of length at least one
>> Calls: roxygenize ->  copy.dir ->  file.copy ->  Sys.chmod
>> In addition: Warning message:
>> In file.create(to[okay]) :
>>   cannot create file
>> 'RTikZDevice.copy/.git/objects/pack/pack-cc0dd1e2622e87f86f8c5a8e617fbf77e253cea1.idx',
>> reason 'Permission denied'
>> Execution halted
>>
>>
>> If I replace all calls to file.copy(...) in the roxygen package with
>> file.copy(..., copy.mode = FALSE) and reinstall it, then I can regenerate
>> package documentation all day long without errors. I also get no errors when
>> I perform the same task with R 2.12.2 on Windows or R 2.13.0-beta on OS X
>> and Linux.
>>
>> Maybe roxygenize() is abusing file.copy() somehow, but I find the "'mode'
>> must be of length at least one" error suspicious.
>>
>> Any ideas?
>>
>> Using:
>> Windows 7 x86_64
>> R 2.13.0-beta
>> Rtools 2.13
>>
>> -Charlie
>>
>>
>> -----
>> Charlie Sharpsteen
>> Undergraduate-- Environmental Resources Engineering
>> Humboldt State University
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From cstrato at aon.at  Sun Apr 24 20:59:04 2011
From: cstrato at aon.at (cstrato)
Date: Sun, 24 Apr 2011 20:59:04 +0200
Subject: [Rd] How to create vignette.pdf for R-2.13.0?
In-Reply-To: <4DB42FB3.9090401@statistik.tu-dortmund.de>
References: <4DB32D9F.5010406@aon.at>
	<4DB42FB3.9090401@statistik.tu-dortmund.de>
Message-ID: <4DB472F8.9060903@aon.at>

Dear Uwe,

Thank you for your reply.

ad 2, Yes, i know that "xps-manual.pdf" is the collection of help pages, 
I have mentioned it only to show that creating pdf-files does work for 
R-2.13.0.

ad 1, Could it be that this is a Mac-specific problem since I see it on 
both my old MacBook Pro and my new Mac Mini.

Using R CMD check with R-2.12.2 I get:

$ R64 CMD check xps_1.13.1.tar.gz
* using log directory '/Volumes/CoreData/CRAN/xps.Rcheck'
* using R version 2.12.2 (2011-02-25)
* using platform: x86_64-apple-darwin9.8.0 (64-bit)
* using session charset: ASCII
* checking for file 'xps/DESCRIPTION' ... OK
* this is package 'xps' version '1.13.1'
...
...
* checking package vignettes in 'inst/doc' ... WARNING
Package vignettes without corresponding PDF:

/Volumes/CoreData/CRAN/xps.Rcheck/00_pkg_src/xps/inst/doc/APTvsXPS.Rnw
/Volumes/CoreData/CRAN/xps.Rcheck/00_pkg_src/xps/inst/doc/xps.Rnw
/Volumes/CoreData/CRAN/xps.Rcheck/00_pkg_src/xps/inst/doc/xpsClasses.Rnw
/Volumes/CoreData/CRAN/xps.Rcheck/00_pkg_src/xps/inst/doc/xpsPreprocess.Rnw
* checking PDF version of manual ... OK


Using "RSwitch.app" I switch to R-2.13.0, but now I get:

$ R64 CMD check xps_1.13.1.tar.gz
* using log directory '/Volumes/CoreData/CRAN/xps.Rcheck'
* using R version 2.13.0 (2011-04-13)
* using platform: x86_64-apple-darwin9.8.0 (64-bit)
* using session charset: ASCII
* checking for file 'xps/DESCRIPTION' ... OK
* this is package 'xps' version '1.13.1'
...
...
* checking package vignettes in 'inst/doc' ... WARNING
Package vignette(s) without corresponding PDF:
    APTvsXPS.Rnw
    xps.Rnw
    xpsClasses.Rnw
    xpsPreprocess.Rnw

* checking running R code from vignettes ... OK
* checking re-building of vignettes ... OK
* checking PDF version of manual ... OK


I must admit that I have never built the vignettes manually, and I 
cannot find a hint how I can do it from the command line. Is this possible?

However, building the vignettes within R-2.13.0 I get:
 > library(tools)
 > buildVignettes("xps", dir="/Volumes/CoreData/CRAN/xps", quiet=F)

Overfull \vbox (21.68121pt too high) has occurred while \output is 
Writing to file xps.tex
Processing code chunks with options ...
  1 : term verbatim
  2 : echo term hide
  3 : echo term verbatim
  4 : echo term verbatim
  5 : echo term verbatim
SysError in <TFile::TFile>: file 
/tmpdt_DataTest3_cel.root/tmpdt_DataTest3_cel_20110424_201301.root can 
not be opened (No such file or directory)
Error: Could not create file </tmpdt_DataTest3_cel.root>


Here are the two important chunks 4 and 5, which work fine with R-2.12.2 
and earlier versions:

###################################################
### chunk number 4:
###################################################
#line 132 "xps.Rnw"
scheme.test3 <- root.scheme(file.path(.path.package("xps"), "schemes", 
"SchemeTest3.root"))


###################################################
### chunk number 5:
###################################################
#line 137 "xps.Rnw"
celfiles <- c("TestA1.CEL","TestA2.CEL")
data.test3 <- import.data(scheme.test3, "tmpdt_DataTest3", 
celdir=celdir, celfiles=celfiles, verbose=FALSE)


However, in R-2.13.0 chunk 5 crashes!!!
It works only when replacing chunk 5 with:

###################################################
### chunk number 5:
###################################################
#line 137 "xps.Rnw"
celfiles <- c("TestA1.CEL","TestA2.CEL")
scheme.test3 <- root.scheme(file.path(.path.package("xps"), "schemes", 
"SchemeTest3.root"))
data.test3 <- import.data(scheme.test3, "tmpdt_DataTest3", 
celdir=celdir, celfiles=celfiles, verbose=FALSE)


As you see R-2.13.0 does no longer remember the result of chunk 4, i.e. 
"scheme.test3". Now I have to include the line defining "scheme.test3" 
also in chunk 5.

Do you have any idea for this behavior?


An example, which does work in R-2.13.0 are the following two chunks:

#################################################
### chunk number 20:
###################################################
#line 300 "xps.Rnw"
library(xps)
scheme.test3 <- root.scheme(file.path(.path.package("xps"), "schemes", 
"SchemeTest3.root"))
data.test3 <- root.data(scheme.test3, 
file.path(.path.package("xps"),"rootdata", "DataTest3_cel.root"))


###################################################
### chunk number 21:
###################################################
#line 318 "xps.Rnw"
data.rma <- rma(data.test3, "tmpdt_Test3RMA", verbose=FALSE)


In summary it is not quite clear to me what has changed in R-2.13.0 so 
that chunk 5 no longer works.

BTW, the error:
SysError in <TFile::TFile>: file 
/tmpdt_DataTest3_cel.root/tmpdt_DataTest3_cel_20110424_201301.root can 
not be opened
is not clear to me since "/tmpdt_DataTest3_cel.root/" is definitively 
NOT a directory.

Do you have any ideas?

Please note that the vignette "xps.Rnw" did work for the last two years 
w/o problem. Furthermore, the Bioconductor servers are able to build the 
vignette, see:
http://www.bioconductor.org/packages/release/bioc/html/xps.html

Best regards
Christian


On 4/24/11 4:12 PM, Uwe Ligges wrote:
>
>
> On 23.04.2011 21:50, cstrato wrote:
>> Dear all,
>>
>> While R CMD check and R CMD INSTALL have always created the vignettes on
>> R-2.12.1 or any earlier versions of R, I am no longer able to build the
>> vignettes on R-2.13.0.
>>
>> Instead R CMD check gives me the following output:
>>
>> * checking for unstated dependencies in vignettes ... OK
>> * checking package vignettes in 'inst/doc' ... WARNING
>> Package vignette(s) without corresponding PDF:
>> APTvsXPS.Rnw
>> xps.Rnw
>> xpsClasses.Rnw
>> xpsPreprocess.Rnw
>>
>> * checking running R code from vignettes ... OK
>> * checking re-building of vignettes ... OK
>> * checking PDF version of manual ... OK
>>
>>
>> Does someone know what the reason might be?
>
> No, it does for me for other packages.
> Perhaps an error when processing the vignettes? Have you tried to build
> them manually?
>
>
>> (R64 CMD check --help says that be default rebuild-vignettes is turned
>> on.)
>>
>> Interestingly, R CMD check still creates the file "xps-manual.pdf".
>
> That is the collection of help pages, unrelated to the vignette.
>
>
> Uwe Ligges
>
>
>
>> Here is my sessionInfo:
>>
>> > sessionInfo()
>> R version 2.13.0 (2011-04-13)
>> Platform: x86_64-apple-darwin9.8.0/x86_64 (64-bit)
>>
>> locale:
>> [1] C
>>
>> attached base packages:
>> [1] stats graphics grDevices utils datasets methods base
>>
>> other attached packages:
>> [1] xps_1.13.1
>>
>> loaded via a namespace (and not attached):
>> [1] Biobase_2.12.1 Biostrings_2.20.0 IRanges_1.10.0
>> [4] affy_1.30.0 affyPLM_1.28.5 affyio_1.20.0
>> [7] preprocessCore_1.14.0
>>
>> Thank you in advance.
>> Best regards
>> Christian
>> _._._._._._._._._._._._._._._._._._
>> C.h.r.i.s.t.i.a.n S.t.r.a.t.o.w.a
>> V.i.e.n.n.a A.u.s.t.r.i.a
>> e.m.a.i.l: cstrato at aon.at
>> _._._._._._._._._._._._._._._._._._
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From ligges at statistik.tu-dortmund.de  Sun Apr 24 22:37:00 2011
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sun, 24 Apr 2011 22:37:00 +0200
Subject: [Rd] How to create vignette.pdf for R-2.13.0?
In-Reply-To: <4DB472F8.9060903@aon.at>
References: <4DB32D9F.5010406@aon.at>	<4DB42FB3.9090401@statistik.tu-dortmund.de>
	<4DB472F8.9060903@aon.at>
Message-ID: <4DB489EC.9080301@statistik.tu-dortmund.de>



On 24.04.2011 20:59, cstrato wrote:
> Dear Uwe,
>
> Thank you for your reply.
>
> ad 2, Yes, i know that "xps-manual.pdf" is the collection of help pages,
> I have mentioned it only to show that creating pdf-files does work for
> R-2.13.0.
>
> ad 1, Could it be that this is a Mac-specific problem since I see it on
> both my old MacBook Pro and my new Mac Mini.

Have you tried on any other OS? I did not since installing root is a bit 
too much effort.



> Using R CMD check with R-2.12.2 I get:

I thought we are talking about R-2.13.0?

Where is the R CMD build output (since R CMD build is supposed to 
prepare the vignette).



> $ R64 CMD check xps_1.13.1.tar.gz
> * using log directory '/Volumes/CoreData/CRAN/xps.Rcheck'
> * using R version 2.12.2 (2011-02-25)
> * using platform: x86_64-apple-darwin9.8.0 (64-bit)
> * using session charset: ASCII
> * checking for file 'xps/DESCRIPTION' ... OK
> * this is package 'xps' version '1.13.1'
> ...
> ...
> * checking package vignettes in 'inst/doc' ... WARNING
> Package vignettes without corresponding PDF:
>
> /Volumes/CoreData/CRAN/xps.Rcheck/00_pkg_src/xps/inst/doc/APTvsXPS.Rnw
> /Volumes/CoreData/CRAN/xps.Rcheck/00_pkg_src/xps/inst/doc/xps.Rnw
> /Volumes/CoreData/CRAN/xps.Rcheck/00_pkg_src/xps/inst/doc/xpsClasses.Rnw
> /Volumes/CoreData/CRAN/xps.Rcheck/00_pkg_src/xps/inst/doc/xpsPreprocess.Rnw
> * checking PDF version of manual ... OK
>
>
> Using "RSwitch.app" I switch to R-2.13.0, but now I get:
>
> $ R64 CMD check xps_1.13.1.tar.gz
> * using log directory '/Volumes/CoreData/CRAN/xps.Rcheck'
> * using R version 2.13.0 (2011-04-13)
> * using platform: x86_64-apple-darwin9.8.0 (64-bit)
> * using session charset: ASCII
> * checking for file 'xps/DESCRIPTION' ... OK
> * this is package 'xps' version '1.13.1'
> ...
> ...
> * checking package vignettes in 'inst/doc' ... WARNING
> Package vignette(s) without corresponding PDF:
> APTvsXPS.Rnw
> xps.Rnw
> xpsClasses.Rnw
> xpsPreprocess.Rnw
>
> * checking running R code from vignettes ... OK
> * checking re-building of vignettes ... OK
> * checking PDF version of manual ... OK
>
>
> I must admit that I have never built the vignettes manually, and I
> cannot find a hint how I can do it from the command line. Is this possible?
>
> However, building the vignettes within R-2.13.0 I get:
>  > library(tools)
>  > buildVignettes("xps", dir="/Volumes/CoreData/CRAN/xps", quiet=F)
>
> Overfull \vbox (21.68121pt too high) has occurred while \output is
> Writing to file xps.tex
> Processing code chunks with options ...
> 1 : term verbatim
> 2 : echo term hide
> 3 : echo term verbatim
> 4 : echo term verbatim
> 5 : echo term verbatim
> SysError in <TFile::TFile>: file
> /tmpdt_DataTest3_cel.root/tmpdt_DataTest3_cel_20110424_201301.root can
> not be opened (No such file or directory)
> Error: Could not create file </tmpdt_DataTest3_cel.root>
>
>
> Here are the two important chunks 4 and 5, which work fine with R-2.12.2
> and earlier versions:
>
> ###################################################
> ### chunk number 4:
> ###################################################
> #line 132 "xps.Rnw"
> scheme.test3 <- root.scheme(file.path(.path.package("xps"), "schemes",
> "SchemeTest3.root"))
>
>
> ###################################################
> ### chunk number 5:
> ###################################################
> #line 137 "xps.Rnw"
> celfiles <- c("TestA1.CEL","TestA2.CEL")
> data.test3 <- import.data(scheme.test3, "tmpdt_DataTest3",
> celdir=celdir, celfiles=celfiles, verbose=FALSE)
>
>
> However, in R-2.13.0 chunk 5 crashes!!!
> It works only when replacing chunk 5 with:
>
> ###################################################
> ### chunk number 5:
> ###################################################
> #line 137 "xps.Rnw"
> celfiles <- c("TestA1.CEL","TestA2.CEL")
> scheme.test3 <- root.scheme(file.path(.path.package("xps"), "schemes",
> "SchemeTest3.root"))
> data.test3 <- import.data(scheme.test3, "tmpdt_DataTest3",
> celdir=celdir, celfiles=celfiles, verbose=FALSE)
>
>
> As you see R-2.13.0 does no longer remember the result of chunk 4, i.e.
> "scheme.test3". Now I have to include the line defining "scheme.test3"
> also in chunk 5.


How objects generated in one chunk can be reused later on is explained 
in the Sweave manual.


>
> Do you have any idea for this behavior?
>
>
> An example, which does work in R-2.13.0 are the following two chunks:
>
> #################################################
> ### chunk number 20:
> ###################################################
> #line 300 "xps.Rnw"
> library(xps)
> scheme.test3 <- root.scheme(file.path(.path.package("xps"), "schemes",
> "SchemeTest3.root"))
> data.test3 <- root.data(scheme.test3,
> file.path(.path.package("xps"),"rootdata", "DataTest3_cel.root"))
>
>
> ###################################################
> ### chunk number 21:
> ###################################################
> #line 318 "xps.Rnw"
> data.rma <- rma(data.test3, "tmpdt_Test3RMA", verbose=FALSE)
>
>
> In summary it is not quite clear to me what has changed in R-2.13.0 so
> that chunk 5 no longer works.
>
> BTW, the error:
> SysError in <TFile::TFile>: file
> /tmpdt_DataTest3_cel.root/tmpdt_DataTest3_cel_20110424_201301.root can
> not be opened
> is not clear to me since "/tmpdt_DataTest3_cel.root/" is definitively
> NOT a directory.

Time to debug what root.scheme is doing with the supplied path.


> Do you have any ideas?
>
> Please note that the vignette "xps.Rnw" did work for the last two years
> w/o problem. Furthermore, the Bioconductor servers are able to build the
> vignette, see:
> http://www.bioconductor.org/packages/release/bioc/html/xps.html


See 
http://bioconductor.org/checkResults/2.8/bioc-20110225/xps/liverpool-checksrc.html 
and find that their Mac Servers are also fine with it. So maybe it is 
your setup that is corrupted?

Best wishes,
Uwe

> Best regards
> Christian
>
>
> On 4/24/11 4:12 PM, Uwe Ligges wrote:
>>
>>
>> On 23.04.2011 21:50, cstrato wrote:
>>> Dear all,
>>>
>>> While R CMD check and R CMD INSTALL have always created the vignettes on
>>> R-2.12.1 or any earlier versions of R, I am no longer able to build the
>>> vignettes on R-2.13.0.
>>>
>>> Instead R CMD check gives me the following output:
>>>
>>> * checking for unstated dependencies in vignettes ... OK
>>> * checking package vignettes in 'inst/doc' ... WARNING
>>> Package vignette(s) without corresponding PDF:
>>> APTvsXPS.Rnw
>>> xps.Rnw
>>> xpsClasses.Rnw
>>> xpsPreprocess.Rnw
>>>
>>> * checking running R code from vignettes ... OK
>>> * checking re-building of vignettes ... OK
>>> * checking PDF version of manual ... OK
>>>
>>>
>>> Does someone know what the reason might be?
>>
>> No, it does for me for other packages.
>> Perhaps an error when processing the vignettes? Have you tried to build
>> them manually?
>>
>>
>>> (R64 CMD check --help says that be default rebuild-vignettes is turned
>>> on.)
>>>
>>> Interestingly, R CMD check still creates the file "xps-manual.pdf".
>>
>> That is the collection of help pages, unrelated to the vignette.
>>
>>
>> Uwe Ligges
>>
>>
>>
>>> Here is my sessionInfo:
>>>
>>> > sessionInfo()
>>> R version 2.13.0 (2011-04-13)
>>> Platform: x86_64-apple-darwin9.8.0/x86_64 (64-bit)
>>>
>>> locale:
>>> [1] C
>>>
>>> attached base packages:
>>> [1] stats graphics grDevices utils datasets methods base
>>>
>>> other attached packages:
>>> [1] xps_1.13.1
>>>
>>> loaded via a namespace (and not attached):
>>> [1] Biobase_2.12.1 Biostrings_2.20.0 IRanges_1.10.0
>>> [4] affy_1.30.0 affyPLM_1.28.5 affyio_1.20.0
>>> [7] preprocessCore_1.14.0
>>>
>>> Thank you in advance.
>>> Best regards
>>> Christian
>>> _._._._._._._._._._._._._._._._._._
>>> C.h.r.i.s.t.i.a.n S.t.r.a.t.o.w.a
>>> V.i.e.n.n.a A.u.s.t.r.i.a
>>> e.m.a.i.l: cstrato at aon.at
>>> _._._._._._._._._._._._._._._._._._
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From cstrato at aon.at  Sun Apr 24 23:10:22 2011
From: cstrato at aon.at (cstrato)
Date: Sun, 24 Apr 2011 23:10:22 +0200
Subject: [Rd] How to create vignette.pdf for R-2.13.0?
In-Reply-To: <4DB489EC.9080301@statistik.tu-dortmund.de>
References: <4DB32D9F.5010406@aon.at>	<4DB42FB3.9090401@statistik.tu-dortmund.de>
	<4DB472F8.9060903@aon.at>
	<4DB489EC.9080301@statistik.tu-dortmund.de>
Message-ID: <4DB491BE.8080104@aon.at>

Dear Uwe,

On 4/24/11 10:37 PM, Uwe Ligges wrote:
>
>
> On 24.04.2011 20:59, cstrato wrote:
>> Dear Uwe,
>>
>> Thank you for your reply.
>>
>> ad 2, Yes, i know that "xps-manual.pdf" is the collection of help pages,
>> I have mentioned it only to show that creating pdf-files does work for
>> R-2.13.0.
>>
>> ad 1, Could it be that this is a Mac-specific problem since I see it on
>> both my old MacBook Pro and my new Mac Mini.
>
> Have you tried on any other OS? I did not since installing root is a bit
> too much effort.
>
>

No, until now I did not try another OS, but I will, since xps has to 
work on all three OSes.

>
>> Using R CMD check with R-2.12.2 I get:
>
> I thought we are talking about R-2.13.0?
>

I showed you the output of R-2.12.2 first and then the output of 
R-2.13.0, so that you can see that on the same machine with the same 
file it works with one version but not the other.


> Where is the R CMD build output (since R CMD build is supposed to
> prepare the vignette).
>
>
>
>> $ R64 CMD check xps_1.13.1.tar.gz
>> * using log directory '/Volumes/CoreData/CRAN/xps.Rcheck'
>> * using R version 2.12.2 (2011-02-25)
>> * using platform: x86_64-apple-darwin9.8.0 (64-bit)
>> * using session charset: ASCII
>> * checking for file 'xps/DESCRIPTION' ... OK
>> * this is package 'xps' version '1.13.1'
>> ...
>> ...
>> * checking package vignettes in 'inst/doc' ... WARNING
>> Package vignettes without corresponding PDF:
>>
>> /Volumes/CoreData/CRAN/xps.Rcheck/00_pkg_src/xps/inst/doc/APTvsXPS.Rnw
>> /Volumes/CoreData/CRAN/xps.Rcheck/00_pkg_src/xps/inst/doc/xps.Rnw
>> /Volumes/CoreData/CRAN/xps.Rcheck/00_pkg_src/xps/inst/doc/xpsClasses.Rnw
>> /Volumes/CoreData/CRAN/xps.Rcheck/00_pkg_src/xps/inst/doc/xpsPreprocess.Rnw
>>
>> * checking PDF version of manual ... OK
>>
>>
>> Using "RSwitch.app" I switch to R-2.13.0, but now I get:
>>
>> $ R64 CMD check xps_1.13.1.tar.gz
>> * using log directory '/Volumes/CoreData/CRAN/xps.Rcheck'
>> * using R version 2.13.0 (2011-04-13)
>> * using platform: x86_64-apple-darwin9.8.0 (64-bit)
>> * using session charset: ASCII
>> * checking for file 'xps/DESCRIPTION' ... OK
>> * this is package 'xps' version '1.13.1'
>> ...
>> ...
>> * checking package vignettes in 'inst/doc' ... WARNING
>> Package vignette(s) without corresponding PDF:
>> APTvsXPS.Rnw
>> xps.Rnw
>> xpsClasses.Rnw
>> xpsPreprocess.Rnw
>>
>> * checking running R code from vignettes ... OK
>> * checking re-building of vignettes ... OK
>> * checking PDF version of manual ... OK
>>
>>
>> I must admit that I have never built the vignettes manually, and I
>> cannot find a hint how I can do it from the command line. Is this
>> possible?


Is it possible to build the vignettes from the command line?


>>
>> However, building the vignettes within R-2.13.0 I get:
>> > library(tools)
>> > buildVignettes("xps", dir="/Volumes/CoreData/CRAN/xps", quiet=F)
>>
>> Overfull \vbox (21.68121pt too high) has occurred while \output is
>> Writing to file xps.tex
>> Processing code chunks with options ...
>> 1 : term verbatim
>> 2 : echo term hide
>> 3 : echo term verbatim
>> 4 : echo term verbatim
>> 5 : echo term verbatim
>> SysError in <TFile::TFile>: file
>> /tmpdt_DataTest3_cel.root/tmpdt_DataTest3_cel_20110424_201301.root can
>> not be opened (No such file or directory)
>> Error: Could not create file </tmpdt_DataTest3_cel.root>
>>
>>
>> Here are the two important chunks 4 and 5, which work fine with R-2.12.2
>> and earlier versions:
>>
>> ###################################################
>> ### chunk number 4:
>> ###################################################
>> #line 132 "xps.Rnw"
>> scheme.test3 <- root.scheme(file.path(.path.package("xps"), "schemes",
>> "SchemeTest3.root"))
>>
>>
>> ###################################################
>> ### chunk number 5:
>> ###################################################
>> #line 137 "xps.Rnw"
>> celfiles <- c("TestA1.CEL","TestA2.CEL")
>> data.test3 <- import.data(scheme.test3, "tmpdt_DataTest3",
>> celdir=celdir, celfiles=celfiles, verbose=FALSE)
>>
>>
>> However, in R-2.13.0 chunk 5 crashes!!!
>> It works only when replacing chunk 5 with:
>>
>> ###################################################
>> ### chunk number 5:
>> ###################################################
>> #line 137 "xps.Rnw"
>> celfiles <- c("TestA1.CEL","TestA2.CEL")
>> scheme.test3 <- root.scheme(file.path(.path.package("xps"), "schemes",
>> "SchemeTest3.root"))
>> data.test3 <- import.data(scheme.test3, "tmpdt_DataTest3",
>> celdir=celdir, celfiles=celfiles, verbose=FALSE)
>>
>>
>> As you see R-2.13.0 does no longer remember the result of chunk 4, i.e.
>> "scheme.test3". Now I have to include the line defining "scheme.test3"
>> also in chunk 5.
>
>
> How objects generated in one chunk can be reused later on is explained
> in the Sweave manual.
>
>
>>
>> Do you have any idea for this behavior?
>>
>>
>> An example, which does work in R-2.13.0 are the following two chunks:
>>
>> #################################################
>> ### chunk number 20:
>> ###################################################
>> #line 300 "xps.Rnw"
>> library(xps)
>> scheme.test3 <- root.scheme(file.path(.path.package("xps"), "schemes",
>> "SchemeTest3.root"))
>> data.test3 <- root.data(scheme.test3,
>> file.path(.path.package("xps"),"rootdata", "DataTest3_cel.root"))
>>
>>
>> ###################################################
>> ### chunk number 21:
>> ###################################################
>> #line 318 "xps.Rnw"
>> data.rma <- rma(data.test3, "tmpdt_Test3RMA", verbose=FALSE)
>>
>>
>> In summary it is not quite clear to me what has changed in R-2.13.0 so
>> that chunk 5 no longer works.
>>
>> BTW, the error:
>> SysError in <TFile::TFile>: file
>> /tmpdt_DataTest3_cel.root/tmpdt_DataTest3_cel_20110424_201301.root can
>> not be opened
>> is not clear to me since "/tmpdt_DataTest3_cel.root/" is definitively
>> NOT a directory.
>
> Time to debug what root.scheme is doing with the supplied path.
>

Sorry, I do not understand what you mean. root.scheme does not change 
the path, otherwise it would not work on all older versions of R.

>
>> Do you have any ideas?
>>
>> Please note that the vignette "xps.Rnw" did work for the last two years
>> w/o problem. Furthermore, the Bioconductor servers are able to build the
>> vignette, see:
>> http://www.bioconductor.org/packages/release/bioc/html/xps.html
>
>
> See
> http://bioconductor.org/checkResults/2.8/bioc-20110225/xps/liverpool-checksrc.html
> and find that their Mac Servers are also fine with it. So maybe it is
> your setup that is corrupted?


Maybe, you are right that my setup is corrupted, but on two independent 
machines?

Maybe the download of "R-2.13.0.pkg" is corrupted, but then nothing 
should work, or am I wrong?

How can I check if my setup is corrupted?

Best regards
Christian

>
> Best wishes,
> Uwe
>
>> Best regards
>> Christian
>>
>>
>> On 4/24/11 4:12 PM, Uwe Ligges wrote:
>>>
>>>
>>> On 23.04.2011 21:50, cstrato wrote:
>>>> Dear all,
>>>>
>>>> While R CMD check and R CMD INSTALL have always created the
>>>> vignettes on
>>>> R-2.12.1 or any earlier versions of R, I am no longer able to build the
>>>> vignettes on R-2.13.0.
>>>>
>>>> Instead R CMD check gives me the following output:
>>>>
>>>> * checking for unstated dependencies in vignettes ... OK
>>>> * checking package vignettes in 'inst/doc' ... WARNING
>>>> Package vignette(s) without corresponding PDF:
>>>> APTvsXPS.Rnw
>>>> xps.Rnw
>>>> xpsClasses.Rnw
>>>> xpsPreprocess.Rnw
>>>>
>>>> * checking running R code from vignettes ... OK
>>>> * checking re-building of vignettes ... OK
>>>> * checking PDF version of manual ... OK
>>>>
>>>>
>>>> Does someone know what the reason might be?
>>>
>>> No, it does for me for other packages.
>>> Perhaps an error when processing the vignettes? Have you tried to build
>>> them manually?
>>>
>>>
>>>> (R64 CMD check --help says that be default rebuild-vignettes is turned
>>>> on.)
>>>>
>>>> Interestingly, R CMD check still creates the file "xps-manual.pdf".
>>>
>>> That is the collection of help pages, unrelated to the vignette.
>>>
>>>
>>> Uwe Ligges
>>>
>>>
>>>
>>>> Here is my sessionInfo:
>>>>
>>>> > sessionInfo()
>>>> R version 2.13.0 (2011-04-13)
>>>> Platform: x86_64-apple-darwin9.8.0/x86_64 (64-bit)
>>>>
>>>> locale:
>>>> [1] C
>>>>
>>>> attached base packages:
>>>> [1] stats graphics grDevices utils datasets methods base
>>>>
>>>> other attached packages:
>>>> [1] xps_1.13.1
>>>>
>>>> loaded via a namespace (and not attached):
>>>> [1] Biobase_2.12.1 Biostrings_2.20.0 IRanges_1.10.0
>>>> [4] affy_1.30.0 affyPLM_1.28.5 affyio_1.20.0
>>>> [7] preprocessCore_1.14.0
>>>>
>>>> Thank you in advance.
>>>> Best regards
>>>> Christian
>>>> _._._._._._._._._._._._._._._._._._
>>>> C.h.r.i.s.t.i.a.n S.t.r.a.t.o.w.a
>>>> V.i.e.n.n.a A.u.s.t.r.i.a
>>>> e.m.a.i.l: cstrato at aon.at
>>>> _._._._._._._._._._._._._._._._._._
>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From schattenpflanze at arcor.de  Mon Apr 25 11:22:15 2011
From: schattenpflanze at arcor.de (schattenpflanze at arcor.de)
Date: Mon, 25 Apr 2011 11:22:15 +0200
Subject: [Rd] Interrupting C++ code execution
Message-ID: <4DB53D47.7060903@arcor.de>

Hello,

I am writing an R interface for one of my C++ programs. The computations 
in C++ are very time consuming (several hours), so the user needs to be 
able to interrupt them. Currently, the only way I found to do so is 
calling R_CheckUserInterrupt() frequently. Unfortunately, there are 
several problems with that:

1. Calling R_CheckUserInterrupt() interrupts immediately, so I have no 
possibility to exit my code gracefully. In particular, I suppose that 
objects created on the heap (e.g., STL containers) are not destructed 
properly.

2. Calling R_CheckUserInterrupt() within a parallel OpenMP loop causes 
memory corruptions. Even if I do so within a critical section, it 
usually results in segfaults, crashes, or invalid variable contents 
afterwards. I suppose this is due to the threads not being destroyed 
properly. Since most of the time critical computations are done in 
parallel, this means I can hardly interrupt anything.

Having a function similar to R_CheckUserInterrupt() but returning a 
boolean variable (has an interrupt occurred or not?) would solve these 
problems. Is there a way to find out about user interrupt requests (the 
user pressing ctrl+c or maybe a different set of keys) without 
interrupting immediately?

I would appreciate your advice on this topic.


Best regards,
Peter


From simon.urbanek at r-project.org  Mon Apr 25 15:34:45 2011
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Mon, 25 Apr 2011 09:34:45 -0400
Subject: [Rd] Interrupting C++ code execution
In-Reply-To: <4DB53D47.7060903@arcor.de>
References: <4DB53D47.7060903@arcor.de>
Message-ID: <2682842C-1B14-4C32-9D68-F608937C1074@r-project.org>


On Apr 25, 2011, at 5:22 AM, schattenpflanze at arcor.de wrote:

> Hello,
> 
> I am writing an R interface for one of my C++ programs. The computations in C++ are very time consuming (several hours), so the user needs to be able to interrupt them. Currently, the only way I found to do so is calling R_CheckUserInterrupt() frequently. Unfortunately, there are several problems with that:
> 
> 1. Calling R_CheckUserInterrupt() interrupts immediately, so I have no possibility to exit my code gracefully. In particular, I suppose that objects created on the heap (e.g., STL containers) are not destructed properly.
> 

In general, you're responsible for the cleanup. See R-devel archives for discussion on the interactions of C++ and R error handling. Generally, you should not use local objects and you should use on.exit to make sure you clean up.


> 2. Calling R_CheckUserInterrupt() within a parallel OpenMP loop causes memory corruptions. Even if I do so within a critical section, it usually results in segfaults, crashes, or invalid variable contents afterwards. I suppose this is due to the threads not being destroyed properly. Since most of the time critical computations are done in parallel, this means I can hardly interrupt anything.
> 

As you know R is not thread-safe so you cannot call any R API from a thread - including OMP threads - so obviously you can't call R_CheckUserInterrupt(). Since you're using threads the safe way is to perform your computations on a separate thread and let R handle events so that you can abort your computation thread as part of on.exit.


> Having a function similar to R_CheckUserInterrupt() but returning a boolean variable (has an interrupt occurred or not?) would solve these problems. Is there a way to find out about user interrupt requests (the user pressing ctrl+c or maybe a different set of keys) without interrupting immediately?
> 

Checking for interrupts may involve running the OS event loop (to allow the user to interact with R) and thus is not guaranteed to return. There is no general solution - if you're worried only about your, local code, then on unix, for example, you could use custom signal handlers to set a flag and co-operatively interrupt your program. On Windows there is the UserBreak flag which can be set by a separate thread and thus you may check on it. That said, all this is very much platform-specific.

Cheers,
Simon


From ligges at statistik.tu-dortmund.de  Mon Apr 25 16:00:26 2011
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Mon, 25 Apr 2011 16:00:26 +0200
Subject: [Rd] How to create vignette.pdf for R-2.13.0?
In-Reply-To: <4DB491BE.8080104@aon.at>
References: <4DB32D9F.5010406@aon.at>	<4DB42FB3.9090401@statistik.tu-dortmund.de>
	<4DB472F8.9060903@aon.at>
	<4DB489EC.9080301@statistik.tu-dortmund.de>
	<4DB491BE.8080104@aon.at>
Message-ID: <4DB57E7A.1080507@statistik.tu-dortmund.de>



On 24.04.2011 23:10, cstrato wrote:
> Dear Uwe,
>
> On 4/24/11 10:37 PM, Uwe Ligges wrote:
>>
>>
>> On 24.04.2011 20:59, cstrato wrote:
>>> Dear Uwe,
>>>
>>> Thank you for your reply.
>>>
>>> ad 2, Yes, i know that "xps-manual.pdf" is the collection of help pages,
>>> I have mentioned it only to show that creating pdf-files does work for
>>> R-2.13.0.
>>>
>>> ad 1, Could it be that this is a Mac-specific problem since I see it on
>>> both my old MacBook Pro and my new Mac Mini.
>>
>> Have you tried on any other OS? I did not since installing root is a bit
>> too much effort.
>>
>>
>
> No, until now I did not try another OS, but I will, since xps has to
> work on all three OSes.
>
>>
>>> Using R CMD check with R-2.12.2 I get:
>>
>> I thought we are talking about R-2.13.0?
>>
>
> I showed you the output of R-2.12.2 first and then the output of
> R-2.13.0, so that you can see that on the same machine with the same
> file it works with one version but not the other.


But you got a Warning in both cases:
* checking package vignettes in 'inst/doc' ... WARNING
Package vignettes without corresponding PDF: ........




>
>> Where is the R CMD build output (since R CMD build is supposed to
>> prepare the vignette).
>>
>>
>>
>>> $ R64 CMD check xps_1.13.1.tar.gz
>>> * using log directory '/Volumes/CoreData/CRAN/xps.Rcheck'
>>> * using R version 2.12.2 (2011-02-25)
>>> * using platform: x86_64-apple-darwin9.8.0 (64-bit)
>>> * using session charset: ASCII
>>> * checking for file 'xps/DESCRIPTION' ... OK
>>> * this is package 'xps' version '1.13.1'
>>> ...
>>> ...
>>> * checking package vignettes in 'inst/doc' ... WARNING
>>> Package vignettes without corresponding PDF:
>>>
>>> /Volumes/CoreData/CRAN/xps.Rcheck/00_pkg_src/xps/inst/doc/APTvsXPS.Rnw
>>> /Volumes/CoreData/CRAN/xps.Rcheck/00_pkg_src/xps/inst/doc/xps.Rnw
>>> /Volumes/CoreData/CRAN/xps.Rcheck/00_pkg_src/xps/inst/doc/xpsClasses.Rnw
>>> /Volumes/CoreData/CRAN/xps.Rcheck/00_pkg_src/xps/inst/doc/xpsPreprocess.Rnw
>>>
>>>
>>> * checking PDF version of manual ... OK
>>>
>>>
>>> Using "RSwitch.app" I switch to R-2.13.0, but now I get:
>>>
>>> $ R64 CMD check xps_1.13.1.tar.gz
>>> * using log directory '/Volumes/CoreData/CRAN/xps.Rcheck'
>>> * using R version 2.13.0 (2011-04-13)
>>> * using platform: x86_64-apple-darwin9.8.0 (64-bit)
>>> * using session charset: ASCII
>>> * checking for file 'xps/DESCRIPTION' ... OK
>>> * this is package 'xps' version '1.13.1'
>>> ...
>>> ...
>>> * checking package vignettes in 'inst/doc' ... WARNING
>>> Package vignette(s) without corresponding PDF:
>>> APTvsXPS.Rnw
>>> xps.Rnw
>>> xpsClasses.Rnw
>>> xpsPreprocess.Rnw
>>>
>>> * checking running R code from vignettes ... OK
>>> * checking re-building of vignettes ... OK
>>> * checking PDF version of manual ... OK
>>>
>>>
>>> I must admit that I have never built the vignettes manually, and I
>>> cannot find a hint how I can do it from the command line. Is this
>>> possible?
>
>
> Is it possible to build the vignettes from the command line?


R --help suggests there is
R CMD Sweave .....


>
>>>
>>> However, building the vignettes within R-2.13.0 I get:
>>> > library(tools)
>>> > buildVignettes("xps", dir="/Volumes/CoreData/CRAN/xps", quiet=F)
>>>
>>> Overfull \vbox (21.68121pt too high) has occurred while \output is
>>> Writing to file xps.tex
>>> Processing code chunks with options ...
>>> 1 : term verbatim
>>> 2 : echo term hide
>>> 3 : echo term verbatim
>>> 4 : echo term verbatim
>>> 5 : echo term verbatim
>>> SysError in <TFile::TFile>: file
>>> /tmpdt_DataTest3_cel.root/tmpdt_DataTest3_cel_20110424_201301.root can
>>> not be opened (No such file or directory)
>>> Error: Could not create file </tmpdt_DataTest3_cel.root>
>>>
>>>
>>> Here are the two important chunks 4 and 5, which work fine with R-2.12.2
>>> and earlier versions:
>>>
>>> ###################################################
>>> ### chunk number 4:
>>> ###################################################
>>> #line 132 "xps.Rnw"
>>> scheme.test3 <- root.scheme(file.path(.path.package("xps"), "schemes",
>>> "SchemeTest3.root"))
>>>
>>>
>>> ###################################################
>>> ### chunk number 5:
>>> ###################################################
>>> #line 137 "xps.Rnw"
>>> celfiles <- c("TestA1.CEL","TestA2.CEL")
>>> data.test3 <- import.data(scheme.test3, "tmpdt_DataTest3",
>>> celdir=celdir, celfiles=celfiles, verbose=FALSE)
>>>
>>>
>>> However, in R-2.13.0 chunk 5 crashes!!!
>>> It works only when replacing chunk 5 with:
>>>
>>> ###################################################
>>> ### chunk number 5:
>>> ###################################################
>>> #line 137 "xps.Rnw"
>>> celfiles <- c("TestA1.CEL","TestA2.CEL")
>>> scheme.test3 <- root.scheme(file.path(.path.package("xps"), "schemes",
>>> "SchemeTest3.root"))
>>> data.test3 <- import.data(scheme.test3, "tmpdt_DataTest3",
>>> celdir=celdir, celfiles=celfiles, verbose=FALSE)
>>>
>>>
>>> As you see R-2.13.0 does no longer remember the result of chunk 4, i.e.
>>> "scheme.test3". Now I have to include the line defining "scheme.test3"
>>> also in chunk 5.
>>
>>
>> How objects generated in one chunk can be reused later on is explained
>> in the Sweave manual.
>>
>>
>>>
>>> Do you have any idea for this behavior?
>>>
>>>
>>> An example, which does work in R-2.13.0 are the following two chunks:
>>>
>>> #################################################
>>> ### chunk number 20:
>>> ###################################################
>>> #line 300 "xps.Rnw"
>>> library(xps)
>>> scheme.test3 <- root.scheme(file.path(.path.package("xps"), "schemes",
>>> "SchemeTest3.root"))
>>> data.test3 <- root.data(scheme.test3,
>>> file.path(.path.package("xps"),"rootdata", "DataTest3_cel.root"))
>>>
>>>
>>> ###################################################
>>> ### chunk number 21:
>>> ###################################################
>>> #line 318 "xps.Rnw"
>>> data.rma <- rma(data.test3, "tmpdt_Test3RMA", verbose=FALSE)
>>>
>>>
>>> In summary it is not quite clear to me what has changed in R-2.13.0 so
>>> that chunk 5 no longer works.
>>>
>>> BTW, the error:
>>> SysError in <TFile::TFile>: file
>>> /tmpdt_DataTest3_cel.root/tmpdt_DataTest3_cel_20110424_201301.root can
>>> not be opened
>>> is not clear to me since "/tmpdt_DataTest3_cel.root/" is definitively
>>> NOT a directory.
>>
>> Time to debug what root.scheme is doing with the supplied path.
>>
>
> Sorry, I do not understand what you mean. root.scheme does not change
> the path, otherwise it would not work on all older versions of R.


Right, but since something changed obviously, and you tell us the path 
is not a path, it might be a function used by root.scheme .... That's 
why I said time to debug the code in your vignette!



>>
>>> Do you have any ideas?
>>>
>>> Please note that the vignette "xps.Rnw" did work for the last two years
>>> w/o problem. Furthermore, the Bioconductor servers are able to build the
>>> vignette, see:
>>> http://www.bioconductor.org/packages/release/bioc/html/xps.html
>>
>>
>> See
>> http://bioconductor.org/checkResults/2.8/bioc-20110225/xps/liverpool-checksrc.html
>>
>> and find that their Mac Servers are also fine with it. So maybe it is
>> your setup that is corrupted?
>
>
> Maybe, you are right that my setup is corrupted, but on two independent
> machines?
>
> Maybe the download of "R-2.13.0.pkg" is corrupted, but then nothing
> should work, or am I wrong?
>
> How can I check if my setup is corrupted?

By debugging the code in your package's vignette.

Uwe Ligges



> Best regards
> Christian
>
>>
>> Best wishes,
>> Uwe
>>
>>> Best regards
>>> Christian
>>>
>>>
>>> On 4/24/11 4:12 PM, Uwe Ligges wrote:
>>>>
>>>>
>>>> On 23.04.2011 21:50, cstrato wrote:
>>>>> Dear all,
>>>>>
>>>>> While R CMD check and R CMD INSTALL have always created the
>>>>> vignettes on
>>>>> R-2.12.1 or any earlier versions of R, I am no longer able to build
>>>>> the
>>>>> vignettes on R-2.13.0.
>>>>>
>>>>> Instead R CMD check gives me the following output:
>>>>>
>>>>> * checking for unstated dependencies in vignettes ... OK
>>>>> * checking package vignettes in 'inst/doc' ... WARNING
>>>>> Package vignette(s) without corresponding PDF:
>>>>> APTvsXPS.Rnw
>>>>> xps.Rnw
>>>>> xpsClasses.Rnw
>>>>> xpsPreprocess.Rnw
>>>>>
>>>>> * checking running R code from vignettes ... OK
>>>>> * checking re-building of vignettes ... OK
>>>>> * checking PDF version of manual ... OK
>>>>>
>>>>>
>>>>> Does someone know what the reason might be?
>>>>
>>>> No, it does for me for other packages.
>>>> Perhaps an error when processing the vignettes? Have you tried to build
>>>> them manually?
>>>>
>>>>
>>>>> (R64 CMD check --help says that be default rebuild-vignettes is turned
>>>>> on.)
>>>>>
>>>>> Interestingly, R CMD check still creates the file "xps-manual.pdf".
>>>>
>>>> That is the collection of help pages, unrelated to the vignette.
>>>>
>>>>
>>>> Uwe Ligges
>>>>
>>>>
>>>>
>>>>> Here is my sessionInfo:
>>>>>
>>>>> > sessionInfo()
>>>>> R version 2.13.0 (2011-04-13)
>>>>> Platform: x86_64-apple-darwin9.8.0/x86_64 (64-bit)
>>>>>
>>>>> locale:
>>>>> [1] C
>>>>>
>>>>> attached base packages:
>>>>> [1] stats graphics grDevices utils datasets methods base
>>>>>
>>>>> other attached packages:
>>>>> [1] xps_1.13.1
>>>>>
>>>>> loaded via a namespace (and not attached):
>>>>> [1] Biobase_2.12.1 Biostrings_2.20.0 IRanges_1.10.0
>>>>> [4] affy_1.30.0 affyPLM_1.28.5 affyio_1.20.0
>>>>> [7] preprocessCore_1.14.0
>>>>>
>>>>> Thank you in advance.
>>>>> Best regards
>>>>> Christian
>>>>> _._._._._._._._._._._._._._._._._._
>>>>> C.h.r.i.s.t.i.a.n S.t.r.a.t.o.w.a
>>>>> V.i.e.n.n.a A.u.s.t.r.i.a
>>>>> e.m.a.i.l: cstrato at aon.at
>>>>> _._._._._._._._._._._._._._._._._._
>>>>>
>>>>> ______________________________________________
>>>>> R-devel at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>


From seanpor at acm.org  Mon Apr 25 17:47:09 2011
From: seanpor at acm.org (Sean O'Riordain)
Date: Mon, 25 Apr 2011 16:47:09 +0100
Subject: [Rd] possible minor doc clarification?
Message-ID: <BANLkTimax_nSRi+B5fE=0jbA7YDkijmsbQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110425/43e29e9b/attachment.pl>

From simon.urbanek at r-project.org  Mon Apr 25 18:23:26 2011
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Mon, 25 Apr 2011 12:23:26 -0400
Subject: [Rd] Interrupting C++ code execution
In-Reply-To: <4DB58E94.8050304@arcor.de>
References: <4DB53D47.7060903@arcor.de>
	<2682842C-1B14-4C32-9D68-F608937C1074@r-project.org>
	<4DB58E94.8050304@arcor.de>
Message-ID: <85607CA7-D76F-4210-9C6E-F3E9F26F7D0E@r-project.org>


On Apr 25, 2011, at 11:09 AM, schattenpflanze at arcor.de wrote:

> Thank you for your response, Simon.
> 
>>> 1. Calling R_CheckUserInterrupt() interrupts immediately, so I have
>>> no possibility to exit my code gracefully. In particular, I suppose
>>> that objects created on the heap (e.g., STL containers) are not
>>> destructed properly.
>> In general, you're responsible for the cleanup. See R-devel archives
>> for discussion on the interactions of C++ and R error handling.
>> Generally, you should not use local objects and you should use
>> on.exit to make sure you clean up.
> I am using Rcpp (Rcpp-modules, to be precise). This means, I do actually not write any R code. Moreover, the C++ code does not use the R API. My C++ functions are 'exposed' to R via Rcpp, which creates suitable S4 classes. Rcpp does the exception handling.
> In particular, there is no obvious possibility for me to add an 'on.exit' statement to a particular exposed C++ method.
> 
>> Generally, you should not use local objects
> We are talking about large amounts of code, dozens of nested function calls, and even external libraries. So "not using local objects" is definitely no option.
> 

But that would imply that the library calls R! Note that we're talking about the stack at the point of R API call, so you can do what you want until you cal R API. At the moment you touch R API you should have no local C++ objects on the stack (all the way down) - that's what I meant. 


>>> 2. Calling R_CheckUserInterrupt() within a parallel OpenMP loop
>>> causes memory corruptions. Even if I do so within a critical
>>> section, it usually results in segfaults, crashes, or invalid
>>> variable contents afterwards. I suppose this is due to the threads
>>> not being destroyed properly. Since most of the time critical
>>> computations are done in parallel, this means I can hardly
>>> interrupt anything.
>> As you know R is not thread-safe so you cannot call any R API from a
>> thread - including OMP threads - so obviously you can't call
>> R_CheckUserInterrupt().
> That is very interesting. Not being thread safe does not necessarily imply that a function cannot be called from within a thread (as long as it is not done concurrently from several threads). In particular, the main program itself is also a thread, isn't it?

Yes, but each thread has a separate stack, and you can only enter R with the same stack you left (because the stack will be restored to the state of the calling context).


> Since no cleanup is done, however, it is now clear that calling R_CheckUserInterrupt() _anywhere_ in my program, parallel section or not, is a bad idea.
> 
>> Since you're using threads the safe way is to
>> perform your computations on a separate thread and let R handle
>> events so that you can abort your computation thread as part of
>> on.exit.
> Starting the computations in a separate thread is a nice idea. I could then call R_CheckUserInterrupt() every x milliseconds in the function which dispatches the worker thread. Unfortunately, I see no obvious way of adding an "on.exit" statement to an Rcpp module method. So I would probably have to call an R function from C++ (e.g., using RInside) which contains the on.exit statement, which in turn calls again a C++ function setting a global 'abort' flag and waits for the threads to be terminated. Hmmm.
> 
> How does on.exit work?

It sets the conexit object of the current context structure to the closure to be evaluated when the context is left. endcontext() then simply evaluates that closure when the context is left.


> Could I mimic that behaviour directly in C++?
> 

Unfortunately there is no C-level onexit hook and the internal structure of RCNTXT is not revealed to packages. So AFAICS the closest you can get is to use eval to call on.exit().

However, I think it would be useful to have a provision for creating a context with a C-level hook - the question is whether the others have the feeling that it's going to a too low level ...


>>> Having a function similar to R_CheckUserInterrupt() but returning a
>>> boolean variable (has an interrupt occurred or not?) would solve
>>> these problems. Is there a way to find out about user interrupt
>>> requests (the user pressing ctrl+c or maybe a different set of
>>> keys) without interrupting immediately?
>> Checking for interrupts may involve running the OS event loop (to
>> allow the user to interact with R) and thus is not guaranteed to
>> return.
> I see.
> 
>> There is no general solution - if you're worried only about
>> your, local code, then on unix, for example, you could use custom
>> signal handlers to set a flag and co-operatively interrupt your
>> program. On Windows there is the UserBreak flag which can be set by a
>> separate thread and thus you may check on it. That said, all this is
>> very much platform-specific.
> Being able to set a flag is all I need and would be the perfect solution imho. However, I do not yet see how I could achieve that.
> 

It is GUI-specific, unfortunately. AFAIR the Windows GUI does that because it's running on a separate thread. I think the X11-based GUIs use fds so the are synchronous and on OS X runs the OS loop inside the R event loop - so, again, synchronous.


> How can I write a signal handler within C++ code which does not create a GUI and has no dedicated event dispatching thread?

That's simple just use signal() to register your handler.


> Would it be possible to use, e.g., a Qt keyboard event handler within the C++ code? Would a keyboard event be visible to such an event handler? Is it not intercepted by R / the terminal window / the OS?
> 

Meshing R's loop, GUI loop and your own code will be a nightmare. For example, one problem is that if you are running the GUI loop and it triggers an event that R would otherwise handle (e.g. resizing plot window) you're in trouble since you can't let R do anything...


> Does any existing R package contain signal handlers?
> 

I'm not sure - I would definitely not recommend that to be used in packages since it's platform-dependent and changes the semantics of signals defined by R. But you can play with it ;).

Cheers,
Simo


From simon.urbanek at r-project.org  Mon Apr 25 18:51:28 2011
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Mon, 25 Apr 2011 12:51:28 -0400
Subject: [Rd] Interrupting C++ code execution
In-Reply-To: <85607CA7-D76F-4210-9C6E-F3E9F26F7D0E@r-project.org>
References: <4DB53D47.7060903@arcor.de>
	<2682842C-1B14-4C32-9D68-F608937C1074@r-project.org>
	<4DB58E94.8050304@arcor.de>
	<85607CA7-D76F-4210-9C6E-F3E9F26F7D0E@r-project.org>
Message-ID: <F1EAEEC8-7828-403F-BF2D-10A4F925B4E6@r-project.org>

Actually, it just came to me that there is a hack you could use. The problem with it is that it will eat all errors, even if they were not yours (e.g. those resulting from events triggered the event loop), so I would not recommend it for general use. But here we go:

static void chkIntFn(void *dummy) {
  R_CheckUserInterrupt();
}

// this will call the above in a top-level context so it won't longjmp-out of your context
bool checkInterrupt() {
  return (R_ToplevelExec(chkIntFn, NULL) == FALSE);
}

// your code somewhere ...
if (checkInterrupt()) { // user interrupted ... }

You must call it on the main thread and you should be prepared that it may take some time and may interact with the OS...

Cheers,
Simon


On Apr 25, 2011, at 12:23 PM, Simon Urbanek wrote:

> 
> On Apr 25, 2011, at 11:09 AM, schattenpflanze at arcor.de wrote:
> 
>> Thank you for your response, Simon.
>> 
>>>> 1. Calling R_CheckUserInterrupt() interrupts immediately, so I have
>>>> no possibility to exit my code gracefully. In particular, I suppose
>>>> that objects created on the heap (e.g., STL containers) are not
>>>> destructed properly.
>>> In general, you're responsible for the cleanup. See R-devel archives
>>> for discussion on the interactions of C++ and R error handling.
>>> Generally, you should not use local objects and you should use
>>> on.exit to make sure you clean up.
>> I am using Rcpp (Rcpp-modules, to be precise). This means, I do actually not write any R code. Moreover, the C++ code does not use the R API. My C++ functions are 'exposed' to R via Rcpp, which creates suitable S4 classes. Rcpp does the exception handling.
>> In particular, there is no obvious possibility for me to add an 'on.exit' statement to a particular exposed C++ method.
>> 
>>> Generally, you should not use local objects
>> We are talking about large amounts of code, dozens of nested function calls, and even external libraries. So "not using local objects" is definitely no option.
>> 
> 
> But that would imply that the library calls R! Note that we're talking about the stack at the point of R API call, so you can do what you want until you cal R API. At the moment you touch R API you should have no local C++ objects on the stack (all the way down) - that's what I meant. 
> 
> 
>>>> 2. Calling R_CheckUserInterrupt() within a parallel OpenMP loop
>>>> causes memory corruptions. Even if I do so within a critical
>>>> section, it usually results in segfaults, crashes, or invalid
>>>> variable contents afterwards. I suppose this is due to the threads
>>>> not being destroyed properly. Since most of the time critical
>>>> computations are done in parallel, this means I can hardly
>>>> interrupt anything.
>>> As you know R is not thread-safe so you cannot call any R API from a
>>> thread - including OMP threads - so obviously you can't call
>>> R_CheckUserInterrupt().
>> That is very interesting. Not being thread safe does not necessarily imply that a function cannot be called from within a thread (as long as it is not done concurrently from several threads). In particular, the main program itself is also a thread, isn't it?
> 
> Yes, but each thread has a separate stack, and you can only enter R with the same stack you left (because the stack will be restored to the state of the calling context).
> 
> 
>> Since no cleanup is done, however, it is now clear that calling R_CheckUserInterrupt() _anywhere_ in my program, parallel section or not, is a bad idea.
>> 
>>> Since you're using threads the safe way is to
>>> perform your computations on a separate thread and let R handle
>>> events so that you can abort your computation thread as part of
>>> on.exit.
>> Starting the computations in a separate thread is a nice idea. I could then call R_CheckUserInterrupt() every x milliseconds in the function which dispatches the worker thread. Unfortunately, I see no obvious way of adding an "on.exit" statement to an Rcpp module method. So I would probably have to call an R function from C++ (e.g., using RInside) which contains the on.exit statement, which in turn calls again a C++ function setting a global 'abort' flag and waits for the threads to be terminated. Hmmm.
>> 
>> How does on.exit work?
> 
> It sets the conexit object of the current context structure to the closure to be evaluated when the context is left. endcontext() then simply evaluates that closure when the context is left.
> 
> 
>> Could I mimic that behaviour directly in C++?
>> 
> 
> Unfortunately there is no C-level onexit hook and the internal structure of RCNTXT is not revealed to packages. So AFAICS the closest you can get is to use eval to call on.exit().
> 
> However, I think it would be useful to have a provision for creating a context with a C-level hook - the question is whether the others have the feeling that it's going to a too low level ...
> 
> 
>>>> Having a function similar to R_CheckUserInterrupt() but returning a
>>>> boolean variable (has an interrupt occurred or not?) would solve
>>>> these problems. Is there a way to find out about user interrupt
>>>> requests (the user pressing ctrl+c or maybe a different set of
>>>> keys) without interrupting immediately?
>>> Checking for interrupts may involve running the OS event loop (to
>>> allow the user to interact with R) and thus is not guaranteed to
>>> return.
>> I see.
>> 
>>> There is no general solution - if you're worried only about
>>> your, local code, then on unix, for example, you could use custom
>>> signal handlers to set a flag and co-operatively interrupt your
>>> program. On Windows there is the UserBreak flag which can be set by a
>>> separate thread and thus you may check on it. That said, all this is
>>> very much platform-specific.
>> Being able to set a flag is all I need and would be the perfect solution imho. However, I do not yet see how I could achieve that.
>> 
> 
> It is GUI-specific, unfortunately. AFAIR the Windows GUI does that because it's running on a separate thread. I think the X11-based GUIs use fds so the are synchronous and on OS X runs the OS loop inside the R event loop - so, again, synchronous.
> 
> 
>> How can I write a signal handler within C++ code which does not create a GUI and has no dedicated event dispatching thread?
> 
> That's simple just use signal() to register your handler.
> 
> 
>> Would it be possible to use, e.g., a Qt keyboard event handler within the C++ code? Would a keyboard event be visible to such an event handler? Is it not intercepted by R / the terminal window / the OS?
>> 
> 
> Meshing R's loop, GUI loop and your own code will be a nightmare. For example, one problem is that if you are running the GUI loop and it triggers an event that R would otherwise handle (e.g. resizing plot window) you're in trouble since you can't let R do anything...
> 
> 
>> Does any existing R package contain signal handlers?
>> 
> 
> I'm not sure - I would definitely not recommend that to be used in packages since it's platform-dependent and changes the semantics of signals defined by R. But you can play with it ;).
> 
> Cheers,
> Simo
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From ehlers at ucalgary.ca  Mon Apr 25 19:16:32 2011
From: ehlers at ucalgary.ca (Peter Ehlers)
Date: Mon, 25 Apr 2011 10:16:32 -0700
Subject: [Rd] possible minor doc clarification?
In-Reply-To: <BANLkTimax_nSRi+B5fE=0jbA7YDkijmsbQ@mail.gmail.com>
References: <BANLkTimax_nSRi+B5fE=0jbA7YDkijmsbQ@mail.gmail.com>
Message-ID: <4DB5AC70.3040001@ucalgary.ca>

On 2011-04-25 08:47, Sean O'Riordain wrote:
> Good afternoon,
>
> As a clarification does it make sense to remove the second 'not' in the 'See
> Also' documentation for file_test ?

Both versions make sense to me; it's just a question of
whether we think of testing for x 'being a directory'
or for x 'not being a directory'.

The code (for the '-f' op) actually tests !isdir and
so the current wording reflects the code.

Peter Ehlers

>
> Kind regards,
> Sean O'Riordain
>
> -----
> Index: src/library/utils/man/filetest.Rd
> ===================================================================
> --- src/library/utils/man/filetest.Rd   (revision 55639)
> +++ src/library/utils/man/filetest.Rd   (working copy)
> @@ -35,7 +35,7 @@
>   }
>   \seealso{
>     \code{\link{file.exists}} which only tests for existence
> -  (\code{test -e} on some systems) but not for not being a directory.
> +  (\code{test -e} on some systems) but not for being a directory.
>
>     \code{\link{file.path}}, \code{\link{file.info}}
>   }
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From cstrato at aon.at  Mon Apr 25 19:31:00 2011
From: cstrato at aon.at (cstrato)
Date: Mon, 25 Apr 2011 19:31:00 +0200
Subject: [Rd] How to create vignette.pdf for R-2.13.0?
In-Reply-To: <4DB57E7A.1080507@statistik.tu-dortmund.de>
References: <4DB32D9F.5010406@aon.at>	<4DB42FB3.9090401@statistik.tu-dortmund.de>
	<4DB472F8.9060903@aon.at>
	<4DB489EC.9080301@statistik.tu-dortmund.de>
	<4DB491BE.8080104@aon.at>
	<4DB57E7A.1080507@statistik.tu-dortmund.de>
Message-ID: <4DB5AFD4.9020303@aon.at>

Dear Uwe,

Your suggestion to look at the Sweave manual helped me to solve the 
problem. It seems that in R-2.13.0 every chunk can use the code from the 
chunk before but not from an earlier chunk.

Concretely, the following does not work since chunk 5 needs the code 
from chunk 3 and 4:

###################################################
### chunk number 3:
###################################################
#line 126 "xps.Rnw"
celdir <- file.path(.path.package("xps"), "raw")

###################################################
### chunk number 4:
###################################################
#line 132 "xps.Rnw"
scheme.test3 <- root.scheme(file.path(.path.package("xps"), "schemes", 
"SchemeTest3.root"))

###################################################
### chunk number 5:
###################################################
#line 137 "xps.Rnw"
celfiles <- c("TestA1.CEL","TestA2.CEL")
data.test3 <- import.data(scheme.test3, "tmpdt_DataTest3", 
celdir=celdir, celfiles=celfiles, verbose=FALSE)


However, when I add "celdir" to chunk 5 then everything works since now 
chunk 5 needs only the code from chunk 4 but not from chunk 3:

###################################################
### chunk number 5:
###################################################
#line 137 "xps.Rnw"
celdir   <- file.path(.path.package("xps"), "raw")
celfiles <- c("TestA1.CEL","TestA2.CEL")
data.test3 <- import.data(scheme.test3, "tmpdt_DataTest3", 
celdir=celdir, celfiles=celfiles, verbose=FALSE)


Now buildVignettes() is able to create the vignettes, however R CMD 
check still does not build the vignettes.


Yes, I get a Warning in both cases:
* checking package vignettes in 'inst/doc' ... WARNING
Package vignettes without corresponding PDF: ........

However, with R-2.12.2 the following lines are added:

/Volumes/CoreData/CRAN/xps.Rcheck/00_pkg_src/xps/inst/doc/APTvsXPS.Rnw
/Volumes/CoreData/CRAN/xps.Rcheck/00_pkg_src/xps/inst/doc/xps.Rnw
/Volumes/CoreData/CRAN/xps.Rcheck/00_pkg_src/xps/inst/doc/xpsClasses.Rnw
/Volumes/CoreData/CRAN/xps.Rcheck/00_pkg_src/xps/inst/doc/xpsPreprocess.Rnw

and in xps.Rcheck the subdirectory "inst/doc" will be created which 
contains the vignette data such as xps.Rnw, but also xps.tex and xps.pdf.

In contrast, R-2.13.0 does not create the subdirectory "inst/doc" and no 
vignettes are built.

One more issue:
In contrast to my former believe R CMD INSTALL does not build the 
vignettes, neither in R-2.12.2 nor in R-2.13.0. I have to run 
buildVignettes() after installation. Is this the usual case?

Best regards
Christian


On 4/25/11 4:00 PM, Uwe Ligges wrote:
>
>
> On 24.04.2011 23:10, cstrato wrote:
>> Dear Uwe,
>>
>> On 4/24/11 10:37 PM, Uwe Ligges wrote:
>>>
>>>
>>> On 24.04.2011 20:59, cstrato wrote:
>>>> Dear Uwe,
>>>>
>>>> Thank you for your reply.
>>>>
>>>> ad 2, Yes, i know that "xps-manual.pdf" is the collection of help
>>>> pages,
>>>> I have mentioned it only to show that creating pdf-files does work for
>>>> R-2.13.0.
>>>>
>>>> ad 1, Could it be that this is a Mac-specific problem since I see it on
>>>> both my old MacBook Pro and my new Mac Mini.
>>>
>>> Have you tried on any other OS? I did not since installing root is a bit
>>> too much effort.
>>>
>>>
>>
>> No, until now I did not try another OS, but I will, since xps has to
>> work on all three OSes.
>>
>>>
>>>> Using R CMD check with R-2.12.2 I get:
>>>
>>> I thought we are talking about R-2.13.0?
>>>
>>
>> I showed you the output of R-2.12.2 first and then the output of
>> R-2.13.0, so that you can see that on the same machine with the same
>> file it works with one version but not the other.
>
>
> But you got a Warning in both cases:
> * checking package vignettes in 'inst/doc' ... WARNING
> Package vignettes without corresponding PDF: ........
>
>
>
>
>>
>>> Where is the R CMD build output (since R CMD build is supposed to
>>> prepare the vignette).
>>>
>>>
>>>
>>>> $ R64 CMD check xps_1.13.1.tar.gz
>>>> * using log directory '/Volumes/CoreData/CRAN/xps.Rcheck'
>>>> * using R version 2.12.2 (2011-02-25)
>>>> * using platform: x86_64-apple-darwin9.8.0 (64-bit)
>>>> * using session charset: ASCII
>>>> * checking for file 'xps/DESCRIPTION' ... OK
>>>> * this is package 'xps' version '1.13.1'
>>>> ...
>>>> ...
>>>> * checking package vignettes in 'inst/doc' ... WARNING
>>>> Package vignettes without corresponding PDF:
>>>>
>>>> /Volumes/CoreData/CRAN/xps.Rcheck/00_pkg_src/xps/inst/doc/APTvsXPS.Rnw
>>>> /Volumes/CoreData/CRAN/xps.Rcheck/00_pkg_src/xps/inst/doc/xps.Rnw
>>>> /Volumes/CoreData/CRAN/xps.Rcheck/00_pkg_src/xps/inst/doc/xpsClasses.Rnw
>>>>
>>>> /Volumes/CoreData/CRAN/xps.Rcheck/00_pkg_src/xps/inst/doc/xpsPreprocess.Rnw
>>>>
>>>>
>>>>
>>>> * checking PDF version of manual ... OK
>>>>
>>>>
>>>> Using "RSwitch.app" I switch to R-2.13.0, but now I get:
>>>>
>>>> $ R64 CMD check xps_1.13.1.tar.gz
>>>> * using log directory '/Volumes/CoreData/CRAN/xps.Rcheck'
>>>> * using R version 2.13.0 (2011-04-13)
>>>> * using platform: x86_64-apple-darwin9.8.0 (64-bit)
>>>> * using session charset: ASCII
>>>> * checking for file 'xps/DESCRIPTION' ... OK
>>>> * this is package 'xps' version '1.13.1'
>>>> ...
>>>> ...
>>>> * checking package vignettes in 'inst/doc' ... WARNING
>>>> Package vignette(s) without corresponding PDF:
>>>> APTvsXPS.Rnw
>>>> xps.Rnw
>>>> xpsClasses.Rnw
>>>> xpsPreprocess.Rnw
>>>>
>>>> * checking running R code from vignettes ... OK
>>>> * checking re-building of vignettes ... OK
>>>> * checking PDF version of manual ... OK
>>>>
>>>>
>>>> I must admit that I have never built the vignettes manually, and I
>>>> cannot find a hint how I can do it from the command line. Is this
>>>> possible?
>>
>>
>> Is it possible to build the vignettes from the command line?
>
>
> R --help suggests there is
> R CMD Sweave .....
>
>
>>
>>>>
>>>> However, building the vignettes within R-2.13.0 I get:
>>>> > library(tools)
>>>> > buildVignettes("xps", dir="/Volumes/CoreData/CRAN/xps", quiet=F)
>>>>
>>>> Overfull \vbox (21.68121pt too high) has occurred while \output is
>>>> Writing to file xps.tex
>>>> Processing code chunks with options ...
>>>> 1 : term verbatim
>>>> 2 : echo term hide
>>>> 3 : echo term verbatim
>>>> 4 : echo term verbatim
>>>> 5 : echo term verbatim
>>>> SysError in <TFile::TFile>: file
>>>> /tmpdt_DataTest3_cel.root/tmpdt_DataTest3_cel_20110424_201301.root can
>>>> not be opened (No such file or directory)
>>>> Error: Could not create file </tmpdt_DataTest3_cel.root>
>>>>
>>>>
>>>> Here are the two important chunks 4 and 5, which work fine with
>>>> R-2.12.2
>>>> and earlier versions:
>>>>
>>>> ###################################################
>>>> ### chunk number 4:
>>>> ###################################################
>>>> #line 132 "xps.Rnw"
>>>> scheme.test3 <- root.scheme(file.path(.path.package("xps"), "schemes",
>>>> "SchemeTest3.root"))
>>>>
>>>>
>>>> ###################################################
>>>> ### chunk number 5:
>>>> ###################################################
>>>> #line 137 "xps.Rnw"
>>>> celfiles <- c("TestA1.CEL","TestA2.CEL")
>>>> data.test3 <- import.data(scheme.test3, "tmpdt_DataTest3",
>>>> celdir=celdir, celfiles=celfiles, verbose=FALSE)
>>>>
>>>>
>>>> However, in R-2.13.0 chunk 5 crashes!!!
>>>> It works only when replacing chunk 5 with:
>>>>
>>>> ###################################################
>>>> ### chunk number 5:
>>>> ###################################################
>>>> #line 137 "xps.Rnw"
>>>> celfiles <- c("TestA1.CEL","TestA2.CEL")
>>>> scheme.test3 <- root.scheme(file.path(.path.package("xps"), "schemes",
>>>> "SchemeTest3.root"))
>>>> data.test3 <- import.data(scheme.test3, "tmpdt_DataTest3",
>>>> celdir=celdir, celfiles=celfiles, verbose=FALSE)
>>>>
>>>>
>>>> As you see R-2.13.0 does no longer remember the result of chunk 4, i.e.
>>>> "scheme.test3". Now I have to include the line defining "scheme.test3"
>>>> also in chunk 5.
>>>
>>>
>>> How objects generated in one chunk can be reused later on is explained
>>> in the Sweave manual.
>>>
>>>
>>>>
>>>> Do you have any idea for this behavior?
>>>>
>>>>
>>>> An example, which does work in R-2.13.0 are the following two chunks:
>>>>
>>>> #################################################
>>>> ### chunk number 20:
>>>> ###################################################
>>>> #line 300 "xps.Rnw"
>>>> library(xps)
>>>> scheme.test3 <- root.scheme(file.path(.path.package("xps"), "schemes",
>>>> "SchemeTest3.root"))
>>>> data.test3 <- root.data(scheme.test3,
>>>> file.path(.path.package("xps"),"rootdata", "DataTest3_cel.root"))
>>>>
>>>>
>>>> ###################################################
>>>> ### chunk number 21:
>>>> ###################################################
>>>> #line 318 "xps.Rnw"
>>>> data.rma <- rma(data.test3, "tmpdt_Test3RMA", verbose=FALSE)
>>>>
>>>>
>>>> In summary it is not quite clear to me what has changed in R-2.13.0 so
>>>> that chunk 5 no longer works.
>>>>
>>>> BTW, the error:
>>>> SysError in <TFile::TFile>: file
>>>> /tmpdt_DataTest3_cel.root/tmpdt_DataTest3_cel_20110424_201301.root can
>>>> not be opened
>>>> is not clear to me since "/tmpdt_DataTest3_cel.root/" is definitively
>>>> NOT a directory.
>>>
>>> Time to debug what root.scheme is doing with the supplied path.
>>>
>>
>> Sorry, I do not understand what you mean. root.scheme does not change
>> the path, otherwise it would not work on all older versions of R.
>
>
> Right, but since something changed obviously, and you tell us the path
> is not a path, it might be a function used by root.scheme .... That's
> why I said time to debug the code in your vignette!
>
>
>
>>>
>>>> Do you have any ideas?
>>>>
>>>> Please note that the vignette "xps.Rnw" did work for the last two years
>>>> w/o problem. Furthermore, the Bioconductor servers are able to build
>>>> the
>>>> vignette, see:
>>>> http://www.bioconductor.org/packages/release/bioc/html/xps.html
>>>
>>>
>>> See
>>> http://bioconductor.org/checkResults/2.8/bioc-20110225/xps/liverpool-checksrc.html
>>>
>>>
>>> and find that their Mac Servers are also fine with it. So maybe it is
>>> your setup that is corrupted?
>>
>>
>> Maybe, you are right that my setup is corrupted, but on two independent
>> machines?
>>
>> Maybe the download of "R-2.13.0.pkg" is corrupted, but then nothing
>> should work, or am I wrong?
>>
>> How can I check if my setup is corrupted?
>
> By debugging the code in your package's vignette.
>
> Uwe Ligges
>
>
>
>> Best regards
>> Christian
>>
>>>
>>> Best wishes,
>>> Uwe
>>>
>>>> Best regards
>>>> Christian
>>>>
>>>>
>>>> On 4/24/11 4:12 PM, Uwe Ligges wrote:
>>>>>
>>>>>
>>>>> On 23.04.2011 21:50, cstrato wrote:
>>>>>> Dear all,
>>>>>>
>>>>>> While R CMD check and R CMD INSTALL have always created the
>>>>>> vignettes on
>>>>>> R-2.12.1 or any earlier versions of R, I am no longer able to build
>>>>>> the
>>>>>> vignettes on R-2.13.0.
>>>>>>
>>>>>> Instead R CMD check gives me the following output:
>>>>>>
>>>>>> * checking for unstated dependencies in vignettes ... OK
>>>>>> * checking package vignettes in 'inst/doc' ... WARNING
>>>>>> Package vignette(s) without corresponding PDF:
>>>>>> APTvsXPS.Rnw
>>>>>> xps.Rnw
>>>>>> xpsClasses.Rnw
>>>>>> xpsPreprocess.Rnw
>>>>>>
>>>>>> * checking running R code from vignettes ... OK
>>>>>> * checking re-building of vignettes ... OK
>>>>>> * checking PDF version of manual ... OK
>>>>>>
>>>>>>
>>>>>> Does someone know what the reason might be?
>>>>>
>>>>> No, it does for me for other packages.
>>>>> Perhaps an error when processing the vignettes? Have you tried to
>>>>> build
>>>>> them manually?
>>>>>
>>>>>
>>>>>> (R64 CMD check --help says that be default rebuild-vignettes is
>>>>>> turned
>>>>>> on.)
>>>>>>
>>>>>> Interestingly, R CMD check still creates the file "xps-manual.pdf".
>>>>>
>>>>> That is the collection of help pages, unrelated to the vignette.
>>>>>
>>>>>
>>>>> Uwe Ligges
>>>>>
>>>>>
>>>>>
>>>>>> Here is my sessionInfo:
>>>>>>
>>>>>> > sessionInfo()
>>>>>> R version 2.13.0 (2011-04-13)
>>>>>> Platform: x86_64-apple-darwin9.8.0/x86_64 (64-bit)
>>>>>>
>>>>>> locale:
>>>>>> [1] C
>>>>>>
>>>>>> attached base packages:
>>>>>> [1] stats graphics grDevices utils datasets methods base
>>>>>>
>>>>>> other attached packages:
>>>>>> [1] xps_1.13.1
>>>>>>
>>>>>> loaded via a namespace (and not attached):
>>>>>> [1] Biobase_2.12.1 Biostrings_2.20.0 IRanges_1.10.0
>>>>>> [4] affy_1.30.0 affyPLM_1.28.5 affyio_1.20.0
>>>>>> [7] preprocessCore_1.14.0
>>>>>>
>>>>>> Thank you in advance.
>>>>>> Best regards
>>>>>> Christian
>>>>>> _._._._._._._._._._._._._._._._._._
>>>>>> C.h.r.i.s.t.i.a.n S.t.r.a.t.o.w.a
>>>>>> V.i.e.n.n.a A.u.s.t.r.i.a
>>>>>> e.m.a.i.l: cstrato at aon.at
>>>>>> _._._._._._._._._._._._._._._._._._
>>>>>>
>>>>>> ______________________________________________
>>>>>> R-devel at r-project.org mailing list
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>>
>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>


From murdoch.duncan at gmail.com  Mon Apr 25 20:00:16 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 25 Apr 2011 14:00:16 -0400
Subject: [Rd] How to create vignette.pdf for R-2.13.0?
In-Reply-To: <4DB5AFD4.9020303@aon.at>
References: <4DB32D9F.5010406@aon.at>	<4DB42FB3.9090401@statistik.tu-dortmund.de>	<4DB472F8.9060903@aon.at>	<4DB489EC.9080301@statistik.tu-dortmund.de>	<4DB491BE.8080104@aon.at>	<4DB57E7A.1080507@statistik.tu-dortmund.de>
	<4DB5AFD4.9020303@aon.at>
Message-ID: <4DB5B6B0.90607@gmail.com>

cstrato wrote:
> Dear Uwe,
> 
> Your suggestion to look at the Sweave manual helped me to solve the 
> problem. It seems that in R-2.13.0 every chunk can use the code from the 
> chunk before but not from an earlier chunk.

I'm either misreading what you wrote, or it's wrong.  If I have this in 
a Sweave file:

<<>>=
x <- 1
@

<<>>=
y <- 2
@

<<>>=
print(x)
@

I will see the value of x getting printed, even though it came from two 
chunks earlier.

I think Uwe is right:  there is some bug in the code you're running. 
Sweave isn't the problem.

Duncan Murdoch

> 
> Concretely, the following does not work since chunk 5 needs the code 
> from chunk 3 and 4:
> 
> ###################################################
> ### chunk number 3:
> ###################################################
> #line 126 "xps.Rnw"
> celdir <- file.path(.path.package("xps"), "raw")
> 
> ###################################################
> ### chunk number 4:
> ###################################################
> #line 132 "xps.Rnw"
> scheme.test3 <- root.scheme(file.path(.path.package("xps"), "schemes", 
> "SchemeTest3.root"))
> 
> ###################################################
> ### chunk number 5:
> ###################################################
> #line 137 "xps.Rnw"
> celfiles <- c("TestA1.CEL","TestA2.CEL")
> data.test3 <- import.data(scheme.test3, "tmpdt_DataTest3", 
> celdir=celdir, celfiles=celfiles, verbose=FALSE)
> 
> 
> However, when I add "celdir" to chunk 5 then everything works since now 
> chunk 5 needs only the code from chunk 4 but not from chunk 3:
> 
> ###################################################
> ### chunk number 5:
> ###################################################
> #line 137 "xps.Rnw"
> celdir   <- file.path(.path.package("xps"), "raw")
> celfiles <- c("TestA1.CEL","TestA2.CEL")
> data.test3 <- import.data(scheme.test3, "tmpdt_DataTest3", 
> celdir=celdir, celfiles=celfiles, verbose=FALSE)
> 
> 
> Now buildVignettes() is able to create the vignettes, however R CMD 
> check still does not build the vignettes.
> 
> 
> Yes, I get a Warning in both cases:
> * checking package vignettes in 'inst/doc' ... WARNING
> Package vignettes without corresponding PDF: ........
> 
> However, with R-2.12.2 the following lines are added:
> 
> /Volumes/CoreData/CRAN/xps.Rcheck/00_pkg_src/xps/inst/doc/APTvsXPS.Rnw
> /Volumes/CoreData/CRAN/xps.Rcheck/00_pkg_src/xps/inst/doc/xps.Rnw
> /Volumes/CoreData/CRAN/xps.Rcheck/00_pkg_src/xps/inst/doc/xpsClasses.Rnw
> /Volumes/CoreData/CRAN/xps.Rcheck/00_pkg_src/xps/inst/doc/xpsPreprocess.Rnw
> 
> and in xps.Rcheck the subdirectory "inst/doc" will be created which 
> contains the vignette data such as xps.Rnw, but also xps.tex and xps.pdf.
> 
> In contrast, R-2.13.0 does not create the subdirectory "inst/doc" and no 
> vignettes are built.
> 
> One more issue:
> In contrast to my former believe R CMD INSTALL does not build the 
> vignettes, neither in R-2.12.2 nor in R-2.13.0. I have to run 
> buildVignettes() after installation. Is this the usual case?
> 
> Best regards
> Christian
> 
> 
> On 4/25/11 4:00 PM, Uwe Ligges wrote:
>>
>> On 24.04.2011 23:10, cstrato wrote:
>>> Dear Uwe,
>>>
>>> On 4/24/11 10:37 PM, Uwe Ligges wrote:
>>>>
>>>> On 24.04.2011 20:59, cstrato wrote:
>>>>> Dear Uwe,
>>>>>
>>>>> Thank you for your reply.
>>>>>
>>>>> ad 2, Yes, i know that "xps-manual.pdf" is the collection of help
>>>>> pages,
>>>>> I have mentioned it only to show that creating pdf-files does work for
>>>>> R-2.13.0.
>>>>>
>>>>> ad 1, Could it be that this is a Mac-specific problem since I see it on
>>>>> both my old MacBook Pro and my new Mac Mini.
>>>> Have you tried on any other OS? I did not since installing root is a bit
>>>> too much effort.
>>>>
>>>>
>>> No, until now I did not try another OS, but I will, since xps has to
>>> work on all three OSes.
>>>
>>>>> Using R CMD check with R-2.12.2 I get:
>>>> I thought we are talking about R-2.13.0?
>>>>
>>> I showed you the output of R-2.12.2 first and then the output of
>>> R-2.13.0, so that you can see that on the same machine with the same
>>> file it works with one version but not the other.
>>
>> But you got a Warning in both cases:
>> * checking package vignettes in 'inst/doc' ... WARNING
>> Package vignettes without corresponding PDF: ........
>>
>>
>>
>>
>>>> Where is the R CMD build output (since R CMD build is supposed to
>>>> prepare the vignette).
>>>>
>>>>
>>>>
>>>>> $ R64 CMD check xps_1.13.1.tar.gz
>>>>> * using log directory '/Volumes/CoreData/CRAN/xps.Rcheck'
>>>>> * using R version 2.12.2 (2011-02-25)
>>>>> * using platform: x86_64-apple-darwin9.8.0 (64-bit)
>>>>> * using session charset: ASCII
>>>>> * checking for file 'xps/DESCRIPTION' ... OK
>>>>> * this is package 'xps' version '1.13.1'
>>>>> ...
>>>>> ...
>>>>> * checking package vignettes in 'inst/doc' ... WARNING
>>>>> Package vignettes without corresponding PDF:
>>>>>
>>>>> /Volumes/CoreData/CRAN/xps.Rcheck/00_pkg_src/xps/inst/doc/APTvsXPS.Rnw
>>>>> /Volumes/CoreData/CRAN/xps.Rcheck/00_pkg_src/xps/inst/doc/xps.Rnw
>>>>> /Volumes/CoreData/CRAN/xps.Rcheck/00_pkg_src/xps/inst/doc/xpsClasses.Rnw
>>>>>
>>>>> /Volumes/CoreData/CRAN/xps.Rcheck/00_pkg_src/xps/inst/doc/xpsPreprocess.Rnw
>>>>>
>>>>>
>>>>>
>>>>> * checking PDF version of manual ... OK
>>>>>
>>>>>
>>>>> Using "RSwitch.app" I switch to R-2.13.0, but now I get:
>>>>>
>>>>> $ R64 CMD check xps_1.13.1.tar.gz
>>>>> * using log directory '/Volumes/CoreData/CRAN/xps.Rcheck'
>>>>> * using R version 2.13.0 (2011-04-13)
>>>>> * using platform: x86_64-apple-darwin9.8.0 (64-bit)
>>>>> * using session charset: ASCII
>>>>> * checking for file 'xps/DESCRIPTION' ... OK
>>>>> * this is package 'xps' version '1.13.1'
>>>>> ...
>>>>> ...
>>>>> * checking package vignettes in 'inst/doc' ... WARNING
>>>>> Package vignette(s) without corresponding PDF:
>>>>> APTvsXPS.Rnw
>>>>> xps.Rnw
>>>>> xpsClasses.Rnw
>>>>> xpsPreprocess.Rnw
>>>>>
>>>>> * checking running R code from vignettes ... OK
>>>>> * checking re-building of vignettes ... OK
>>>>> * checking PDF version of manual ... OK
>>>>>
>>>>>
>>>>> I must admit that I have never built the vignettes manually, and I
>>>>> cannot find a hint how I can do it from the command line. Is this
>>>>> possible?
>>>
>>> Is it possible to build the vignettes from the command line?
>>
>> R --help suggests there is
>> R CMD Sweave .....
>>
>>
>>>>> However, building the vignettes within R-2.13.0 I get:
>>>>>> library(tools)
>>>>>> buildVignettes("xps", dir="/Volumes/CoreData/CRAN/xps", quiet=F)
>>>>> Overfull \vbox (21.68121pt too high) has occurred while \output is
>>>>> Writing to file xps.tex
>>>>> Processing code chunks with options ...
>>>>> 1 : term verbatim
>>>>> 2 : echo term hide
>>>>> 3 : echo term verbatim
>>>>> 4 : echo term verbatim
>>>>> 5 : echo term verbatim
>>>>> SysError in <TFile::TFile>: file
>>>>> /tmpdt_DataTest3_cel.root/tmpdt_DataTest3_cel_20110424_201301.root can
>>>>> not be opened (No such file or directory)
>>>>> Error: Could not create file </tmpdt_DataTest3_cel.root>
>>>>>
>>>>>
>>>>> Here are the two important chunks 4 and 5, which work fine with
>>>>> R-2.12.2
>>>>> and earlier versions:
>>>>>
>>>>> ###################################################
>>>>> ### chunk number 4:
>>>>> ###################################################
>>>>> #line 132 "xps.Rnw"
>>>>> scheme.test3 <- root.scheme(file.path(.path.package("xps"), "schemes",
>>>>> "SchemeTest3.root"))
>>>>>
>>>>>
>>>>> ###################################################
>>>>> ### chunk number 5:
>>>>> ###################################################
>>>>> #line 137 "xps.Rnw"
>>>>> celfiles <- c("TestA1.CEL","TestA2.CEL")
>>>>> data.test3 <- import.data(scheme.test3, "tmpdt_DataTest3",
>>>>> celdir=celdir, celfiles=celfiles, verbose=FALSE)
>>>>>
>>>>>
>>>>> However, in R-2.13.0 chunk 5 crashes!!!
>>>>> It works only when replacing chunk 5 with:
>>>>>
>>>>> ###################################################
>>>>> ### chunk number 5:
>>>>> ###################################################
>>>>> #line 137 "xps.Rnw"
>>>>> celfiles <- c("TestA1.CEL","TestA2.CEL")
>>>>> scheme.test3 <- root.scheme(file.path(.path.package("xps"), "schemes",
>>>>> "SchemeTest3.root"))
>>>>> data.test3 <- import.data(scheme.test3, "tmpdt_DataTest3",
>>>>> celdir=celdir, celfiles=celfiles, verbose=FALSE)
>>>>>
>>>>>
>>>>> As you see R-2.13.0 does no longer remember the result of chunk 4, i.e.
>>>>> "scheme.test3". Now I have to include the line defining "scheme.test3"
>>>>> also in chunk 5.
>>>>
>>>> How objects generated in one chunk can be reused later on is explained
>>>> in the Sweave manual.
>>>>
>>>>
>>>>> Do you have any idea for this behavior?
>>>>>
>>>>>
>>>>> An example, which does work in R-2.13.0 are the following two chunks:
>>>>>
>>>>> #################################################
>>>>> ### chunk number 20:
>>>>> ###################################################
>>>>> #line 300 "xps.Rnw"
>>>>> library(xps)
>>>>> scheme.test3 <- root.scheme(file.path(.path.package("xps"), "schemes",
>>>>> "SchemeTest3.root"))
>>>>> data.test3 <- root.data(scheme.test3,
>>>>> file.path(.path.package("xps"),"rootdata", "DataTest3_cel.root"))
>>>>>
>>>>>
>>>>> ###################################################
>>>>> ### chunk number 21:
>>>>> ###################################################
>>>>> #line 318 "xps.Rnw"
>>>>> data.rma <- rma(data.test3, "tmpdt_Test3RMA", verbose=FALSE)
>>>>>
>>>>>
>>>>> In summary it is not quite clear to me what has changed in R-2.13.0 so
>>>>> that chunk 5 no longer works.
>>>>>
>>>>> BTW, the error:
>>>>> SysError in <TFile::TFile>: file
>>>>> /tmpdt_DataTest3_cel.root/tmpdt_DataTest3_cel_20110424_201301.root can
>>>>> not be opened
>>>>> is not clear to me since "/tmpdt_DataTest3_cel.root/" is definitively
>>>>> NOT a directory.
>>>> Time to debug what root.scheme is doing with the supplied path.
>>>>
>>> Sorry, I do not understand what you mean. root.scheme does not change
>>> the path, otherwise it would not work on all older versions of R.
>>
>> Right, but since something changed obviously, and you tell us the path
>> is not a path, it might be a function used by root.scheme .... That's
>> why I said time to debug the code in your vignette!
>>
>>
>>
>>>>> Do you have any ideas?
>>>>>
>>>>> Please note that the vignette "xps.Rnw" did work for the last two years
>>>>> w/o problem. Furthermore, the Bioconductor servers are able to build
>>>>> the
>>>>> vignette, see:
>>>>> http://www.bioconductor.org/packages/release/bioc/html/xps.html
>>>>
>>>> See
>>>> http://bioconductor.org/checkResults/2.8/bioc-20110225/xps/liverpool-checksrc.html
>>>>
>>>>
>>>> and find that their Mac Servers are also fine with it. So maybe it is
>>>> your setup that is corrupted?
>>>
>>> Maybe, you are right that my setup is corrupted, but on two independent
>>> machines?
>>>
>>> Maybe the download of "R-2.13.0.pkg" is corrupted, but then nothing
>>> should work, or am I wrong?
>>>
>>> How can I check if my setup is corrupted?
>> By debugging the code in your package's vignette.
>>
>> Uwe Ligges
>>
>>
>>
>>> Best regards
>>> Christian
>>>
>>>> Best wishes,
>>>> Uwe
>>>>
>>>>> Best regards
>>>>> Christian
>>>>>
>>>>>
>>>>> On 4/24/11 4:12 PM, Uwe Ligges wrote:
>>>>>>
>>>>>> On 23.04.2011 21:50, cstrato wrote:
>>>>>>> Dear all,
>>>>>>>
>>>>>>> While R CMD check and R CMD INSTALL have always created the
>>>>>>> vignettes on
>>>>>>> R-2.12.1 or any earlier versions of R, I am no longer able to build
>>>>>>> the
>>>>>>> vignettes on R-2.13.0.
>>>>>>>
>>>>>>> Instead R CMD check gives me the following output:
>>>>>>>
>>>>>>> * checking for unstated dependencies in vignettes ... OK
>>>>>>> * checking package vignettes in 'inst/doc' ... WARNING
>>>>>>> Package vignette(s) without corresponding PDF:
>>>>>>> APTvsXPS.Rnw
>>>>>>> xps.Rnw
>>>>>>> xpsClasses.Rnw
>>>>>>> xpsPreprocess.Rnw
>>>>>>>
>>>>>>> * checking running R code from vignettes ... OK
>>>>>>> * checking re-building of vignettes ... OK
>>>>>>> * checking PDF version of manual ... OK
>>>>>>>
>>>>>>>
>>>>>>> Does someone know what the reason might be?
>>>>>> No, it does for me for other packages.
>>>>>> Perhaps an error when processing the vignettes? Have you tried to
>>>>>> build
>>>>>> them manually?
>>>>>>
>>>>>>
>>>>>>> (R64 CMD check --help says that be default rebuild-vignettes is
>>>>>>> turned
>>>>>>> on.)
>>>>>>>
>>>>>>> Interestingly, R CMD check still creates the file "xps-manual.pdf".
>>>>>> That is the collection of help pages, unrelated to the vignette.
>>>>>>
>>>>>>
>>>>>> Uwe Ligges
>>>>>>
>>>>>>
>>>>>>
>>>>>>> Here is my sessionInfo:
>>>>>>>
>>>>>>>> sessionInfo()
>>>>>>> R version 2.13.0 (2011-04-13)
>>>>>>> Platform: x86_64-apple-darwin9.8.0/x86_64 (64-bit)
>>>>>>>
>>>>>>> locale:
>>>>>>> [1] C
>>>>>>>
>>>>>>> attached base packages:
>>>>>>> [1] stats graphics grDevices utils datasets methods base
>>>>>>>
>>>>>>> other attached packages:
>>>>>>> [1] xps_1.13.1
>>>>>>>
>>>>>>> loaded via a namespace (and not attached):
>>>>>>> [1] Biobase_2.12.1 Biostrings_2.20.0 IRanges_1.10.0
>>>>>>> [4] affy_1.30.0 affyPLM_1.28.5 affyio_1.20.0
>>>>>>> [7] preprocessCore_1.14.0
>>>>>>>
>>>>>>> Thank you in advance.
>>>>>>> Best regards
>>>>>>> Christian
>>>>>>> _._._._._._._._._._._._._._._._._._
>>>>>>> C.h.r.i.s.t.i.a.n S.t.r.a.t.o.w.a
>>>>>>> V.i.e.n.n.a A.u.s.t.r.i.a
>>>>>>> e.m.a.i.l: cstrato at aon.at
>>>>>>> _._._._._._._._._._._._._._._._._._
>>>>>>>
>>>>>>> ______________________________________________
>>>>>>> R-devel at r-project.org mailing list
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>> ______________________________________________
>>>>> R-devel at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From thomas.friedrichsmeier at ruhr-uni-bochum.de  Mon Apr 25 20:17:57 2011
From: thomas.friedrichsmeier at ruhr-uni-bochum.de (Thomas Friedrichsmeier)
Date: 25 Apr 2011 20:17:57 +0200
Subject: [Rd] Interrupting C++ code execution
In-Reply-To: <F1EAEEC8-7828-403F-BF2D-10A4F925B4E6@r-project.org>
References: <4DB53D47.7060903@arcor.de>
	<85607CA7-D76F-4210-9C6E-F3E9F26F7D0E@r-project.org>
	<F1EAEEC8-7828-403F-BF2D-10A4F925B4E6@r-project.org>
Message-ID: <201104252018.01541.thomas.friedrichsmeier@ruhr-uni-bochum.de>

On Monday 25 April 2011, Simon Urbanek wrote:
> Actually, it just came to me that there is a hack you could use. The
> problem with it is that it will eat all errors, even if they were not
> yours (e.g. those resulting from events triggered the event loop), so I
> would not recommend it for general use.

Here's another option which is probably not recommendable for general use, 
since it is not part of the documented API:

On Windows you can look at the variable "UserBreak", available from 
Rembedded.h. Outside of Windows, you can look at R_interrupts_pending, 
available from R_ext/GraphicsDevice.h. R_ext/GraphicsDevice.h also has 
R_interrupts_suspended, which you may or may not want to take into account, 
depending on your use-case.

BTW, being able to check for a pending interrupt or to schedule an interrupt 
from a separate thread is something that can come in handy in GUI development 
as well, and personally, I would appreciate, if there was some slightly more 
official support for this.

Regards
Thomas
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 198 bytes
Desc: This is a digitally signed message part.
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110425/0be7c269/attachment.bin>

From cstrato at aon.at  Mon Apr 25 20:50:46 2011
From: cstrato at aon.at (cstrato)
Date: Mon, 25 Apr 2011 20:50:46 +0200
Subject: [Rd] How to create vignette.pdf for R-2.13.0?
In-Reply-To: <4DB5B6B0.90607@gmail.com>
References: <4DB32D9F.5010406@aon.at>	<4DB42FB3.9090401@statistik.tu-dortmund.de>	<4DB472F8.9060903@aon.at>	<4DB489EC.9080301@statistik.tu-dortmund.de>	<4DB491BE.8080104@aon.at>	<4DB57E7A.1080507@statistik.tu-dortmund.de>
	<4DB5AFD4.9020303@aon.at> <4DB5B6B0.90607@gmail.com>
Message-ID: <4DB5C286.40306@aon.at>

Dear Duncan,

Thank you for your example, however it is different since it does not 
use x and y. What about print(x+y)?

Sorry, I do not believe that there is a bug in my code, since:
1, it worked in all versions from R starting with R-2.6.0 till R-2.12.2.
2, the identical code works in the examples
3, this code (or a similar code) is the starting code which all users of 
xps have to use, and there was never a problem.

Maybe the reason could be that my code has to import
- the CEL-files from the package dir
- the file SchemeTest3.root from the package dir
??

Best regards
Christian

On 4/25/11 8:00 PM, Duncan Murdoch wrote:
> cstrato wrote:
>> Dear Uwe,
>>
>> Your suggestion to look at the Sweave manual helped me to solve the
>> problem. It seems that in R-2.13.0 every chunk can use the code from
>> the chunk before but not from an earlier chunk.
>
> I'm either misreading what you wrote, or it's wrong. If I have this in a
> Sweave file:
>
> <<>>=
> x <- 1
> @
>
> <<>>=
> y <- 2
> @
>
> <<>>=
> print(x)
> @
>
> I will see the value of x getting printed, even though it came from two
> chunks earlier.
>
> I think Uwe is right: there is some bug in the code you're running.
> Sweave isn't the problem.
>
> Duncan Murdoch
>
>>
>> Concretely, the following does not work since chunk 5 needs the code
>> from chunk 3 and 4:
>>
>> ###################################################
>> ### chunk number 3:
>> ###################################################
>> #line 126 "xps.Rnw"
>> celdir <- file.path(.path.package("xps"), "raw")
>>
>> ###################################################
>> ### chunk number 4:
>> ###################################################
>> #line 132 "xps.Rnw"
>> scheme.test3 <- root.scheme(file.path(.path.package("xps"), "schemes",
>> "SchemeTest3.root"))
>>
>> ###################################################
>> ### chunk number 5:
>> ###################################################
>> #line 137 "xps.Rnw"
>> celfiles <- c("TestA1.CEL","TestA2.CEL")
>> data.test3 <- import.data(scheme.test3, "tmpdt_DataTest3",
>> celdir=celdir, celfiles=celfiles, verbose=FALSE)
>>
>>
>> However, when I add "celdir" to chunk 5 then everything works since
>> now chunk 5 needs only the code from chunk 4 but not from chunk 3:
>>
>> ###################################################
>> ### chunk number 5:
>> ###################################################
>> #line 137 "xps.Rnw"
>> celdir <- file.path(.path.package("xps"), "raw")
>> celfiles <- c("TestA1.CEL","TestA2.CEL")
>> data.test3 <- import.data(scheme.test3, "tmpdt_DataTest3",
>> celdir=celdir, celfiles=celfiles, verbose=FALSE)
>>
>>
>> Now buildVignettes() is able to create the vignettes, however R CMD
>> check still does not build the vignettes.
>>
>>
>> Yes, I get a Warning in both cases:
>> * checking package vignettes in 'inst/doc' ... WARNING
>> Package vignettes without corresponding PDF: ........
>>
>> However, with R-2.12.2 the following lines are added:
>>
>> /Volumes/CoreData/CRAN/xps.Rcheck/00_pkg_src/xps/inst/doc/APTvsXPS.Rnw
>> /Volumes/CoreData/CRAN/xps.Rcheck/00_pkg_src/xps/inst/doc/xps.Rnw
>> /Volumes/CoreData/CRAN/xps.Rcheck/00_pkg_src/xps/inst/doc/xpsClasses.Rnw
>> /Volumes/CoreData/CRAN/xps.Rcheck/00_pkg_src/xps/inst/doc/xpsPreprocess.Rnw
>>
>>
>> and in xps.Rcheck the subdirectory "inst/doc" will be created which
>> contains the vignette data such as xps.Rnw, but also xps.tex and xps.pdf.
>>
>> In contrast, R-2.13.0 does not create the subdirectory "inst/doc" and
>> no vignettes are built.
>>
>> One more issue:
>> In contrast to my former believe R CMD INSTALL does not build the
>> vignettes, neither in R-2.12.2 nor in R-2.13.0. I have to run
>> buildVignettes() after installation. Is this the usual case?
>>
>> Best regards
>> Christian
>>
>>
>> On 4/25/11 4:00 PM, Uwe Ligges wrote:
>>>
>>> On 24.04.2011 23:10, cstrato wrote:
>>>> Dear Uwe,
>>>>
>>>> On 4/24/11 10:37 PM, Uwe Ligges wrote:
>>>>>
>>>>> On 24.04.2011 20:59, cstrato wrote:
>>>>>> Dear Uwe,
>>>>>>
>>>>>> Thank you for your reply.
>>>>>>
>>>>>> ad 2, Yes, i know that "xps-manual.pdf" is the collection of help
>>>>>> pages,
>>>>>> I have mentioned it only to show that creating pdf-files does work
>>>>>> for
>>>>>> R-2.13.0.
>>>>>>
>>>>>> ad 1, Could it be that this is a Mac-specific problem since I see
>>>>>> it on
>>>>>> both my old MacBook Pro and my new Mac Mini.
>>>>> Have you tried on any other OS? I did not since installing root is
>>>>> a bit
>>>>> too much effort.
>>>>>
>>>>>
>>>> No, until now I did not try another OS, but I will, since xps has to
>>>> work on all three OSes.
>>>>
>>>>>> Using R CMD check with R-2.12.2 I get:
>>>>> I thought we are talking about R-2.13.0?
>>>>>
>>>> I showed you the output of R-2.12.2 first and then the output of
>>>> R-2.13.0, so that you can see that on the same machine with the same
>>>> file it works with one version but not the other.
>>>
>>> But you got a Warning in both cases:
>>> * checking package vignettes in 'inst/doc' ... WARNING
>>> Package vignettes without corresponding PDF: ........
>>>
>>>
>>>
>>>
>>>>> Where is the R CMD build output (since R CMD build is supposed to
>>>>> prepare the vignette).
>>>>>
>>>>>
>>>>>
>>>>>> $ R64 CMD check xps_1.13.1.tar.gz
>>>>>> * using log directory '/Volumes/CoreData/CRAN/xps.Rcheck'
>>>>>> * using R version 2.12.2 (2011-02-25)
>>>>>> * using platform: x86_64-apple-darwin9.8.0 (64-bit)
>>>>>> * using session charset: ASCII
>>>>>> * checking for file 'xps/DESCRIPTION' ... OK
>>>>>> * this is package 'xps' version '1.13.1'
>>>>>> ...
>>>>>> ...
>>>>>> * checking package vignettes in 'inst/doc' ... WARNING
>>>>>> Package vignettes without corresponding PDF:
>>>>>>
>>>>>> /Volumes/CoreData/CRAN/xps.Rcheck/00_pkg_src/xps/inst/doc/APTvsXPS.Rnw
>>>>>>
>>>>>> /Volumes/CoreData/CRAN/xps.Rcheck/00_pkg_src/xps/inst/doc/xps.Rnw
>>>>>> /Volumes/CoreData/CRAN/xps.Rcheck/00_pkg_src/xps/inst/doc/xpsClasses.Rnw
>>>>>>
>>>>>>
>>>>>> /Volumes/CoreData/CRAN/xps.Rcheck/00_pkg_src/xps/inst/doc/xpsPreprocess.Rnw
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>> * checking PDF version of manual ... OK
>>>>>>
>>>>>>
>>>>>> Using "RSwitch.app" I switch to R-2.13.0, but now I get:
>>>>>>
>>>>>> $ R64 CMD check xps_1.13.1.tar.gz
>>>>>> * using log directory '/Volumes/CoreData/CRAN/xps.Rcheck'
>>>>>> * using R version 2.13.0 (2011-04-13)
>>>>>> * using platform: x86_64-apple-darwin9.8.0 (64-bit)
>>>>>> * using session charset: ASCII
>>>>>> * checking for file 'xps/DESCRIPTION' ... OK
>>>>>> * this is package 'xps' version '1.13.1'
>>>>>> ...
>>>>>> ...
>>>>>> * checking package vignettes in 'inst/doc' ... WARNING
>>>>>> Package vignette(s) without corresponding PDF:
>>>>>> APTvsXPS.Rnw
>>>>>> xps.Rnw
>>>>>> xpsClasses.Rnw
>>>>>> xpsPreprocess.Rnw
>>>>>>
>>>>>> * checking running R code from vignettes ... OK
>>>>>> * checking re-building of vignettes ... OK
>>>>>> * checking PDF version of manual ... OK
>>>>>>
>>>>>>
>>>>>> I must admit that I have never built the vignettes manually, and I
>>>>>> cannot find a hint how I can do it from the command line. Is this
>>>>>> possible?
>>>>
>>>> Is it possible to build the vignettes from the command line?
>>>
>>> R --help suggests there is
>>> R CMD Sweave .....
>>>
>>>
>>>>>> However, building the vignettes within R-2.13.0 I get:
>>>>>>> library(tools)
>>>>>>> buildVignettes("xps", dir="/Volumes/CoreData/CRAN/xps", quiet=F)
>>>>>> Overfull \vbox (21.68121pt too high) has occurred while \output is
>>>>>> Writing to file xps.tex
>>>>>> Processing code chunks with options ...
>>>>>> 1 : term verbatim
>>>>>> 2 : echo term hide
>>>>>> 3 : echo term verbatim
>>>>>> 4 : echo term verbatim
>>>>>> 5 : echo term verbatim
>>>>>> SysError in <TFile::TFile>: file
>>>>>> /tmpdt_DataTest3_cel.root/tmpdt_DataTest3_cel_20110424_201301.root
>>>>>> can
>>>>>> not be opened (No such file or directory)
>>>>>> Error: Could not create file </tmpdt_DataTest3_cel.root>
>>>>>>
>>>>>>
>>>>>> Here are the two important chunks 4 and 5, which work fine with
>>>>>> R-2.12.2
>>>>>> and earlier versions:
>>>>>>
>>>>>> ###################################################
>>>>>> ### chunk number 4:
>>>>>> ###################################################
>>>>>> #line 132 "xps.Rnw"
>>>>>> scheme.test3 <- root.scheme(file.path(.path.package("xps"),
>>>>>> "schemes",
>>>>>> "SchemeTest3.root"))
>>>>>>
>>>>>>
>>>>>> ###################################################
>>>>>> ### chunk number 5:
>>>>>> ###################################################
>>>>>> #line 137 "xps.Rnw"
>>>>>> celfiles <- c("TestA1.CEL","TestA2.CEL")
>>>>>> data.test3 <- import.data(scheme.test3, "tmpdt_DataTest3",
>>>>>> celdir=celdir, celfiles=celfiles, verbose=FALSE)
>>>>>>
>>>>>>
>>>>>> However, in R-2.13.0 chunk 5 crashes!!!
>>>>>> It works only when replacing chunk 5 with:
>>>>>>
>>>>>> ###################################################
>>>>>> ### chunk number 5:
>>>>>> ###################################################
>>>>>> #line 137 "xps.Rnw"
>>>>>> celfiles <- c("TestA1.CEL","TestA2.CEL")
>>>>>> scheme.test3 <- root.scheme(file.path(.path.package("xps"),
>>>>>> "schemes",
>>>>>> "SchemeTest3.root"))
>>>>>> data.test3 <- import.data(scheme.test3, "tmpdt_DataTest3",
>>>>>> celdir=celdir, celfiles=celfiles, verbose=FALSE)
>>>>>>
>>>>>>
>>>>>> As you see R-2.13.0 does no longer remember the result of chunk 4,
>>>>>> i.e.
>>>>>> "scheme.test3". Now I have to include the line defining
>>>>>> "scheme.test3"
>>>>>> also in chunk 5.
>>>>>
>>>>> How objects generated in one chunk can be reused later on is explained
>>>>> in the Sweave manual.
>>>>>
>>>>>
>>>>>> Do you have any idea for this behavior?
>>>>>>
>>>>>>
>>>>>> An example, which does work in R-2.13.0 are the following two chunks:
>>>>>>
>>>>>> #################################################
>>>>>> ### chunk number 20:
>>>>>> ###################################################
>>>>>> #line 300 "xps.Rnw"
>>>>>> library(xps)
>>>>>> scheme.test3 <- root.scheme(file.path(.path.package("xps"),
>>>>>> "schemes",
>>>>>> "SchemeTest3.root"))
>>>>>> data.test3 <- root.data(scheme.test3,
>>>>>> file.path(.path.package("xps"),"rootdata", "DataTest3_cel.root"))
>>>>>>
>>>>>>
>>>>>> ###################################################
>>>>>> ### chunk number 21:
>>>>>> ###################################################
>>>>>> #line 318 "xps.Rnw"
>>>>>> data.rma <- rma(data.test3, "tmpdt_Test3RMA", verbose=FALSE)
>>>>>>
>>>>>>
>>>>>> In summary it is not quite clear to me what has changed in
>>>>>> R-2.13.0 so
>>>>>> that chunk 5 no longer works.
>>>>>>
>>>>>> BTW, the error:
>>>>>> SysError in <TFile::TFile>: file
>>>>>> /tmpdt_DataTest3_cel.root/tmpdt_DataTest3_cel_20110424_201301.root
>>>>>> can
>>>>>> not be opened
>>>>>> is not clear to me since "/tmpdt_DataTest3_cel.root/" is definitively
>>>>>> NOT a directory.
>>>>> Time to debug what root.scheme is doing with the supplied path.
>>>>>
>>>> Sorry, I do not understand what you mean. root.scheme does not change
>>>> the path, otherwise it would not work on all older versions of R.
>>>
>>> Right, but since something changed obviously, and you tell us the path
>>> is not a path, it might be a function used by root.scheme .... That's
>>> why I said time to debug the code in your vignette!
>>>
>>>
>>>
>>>>>> Do you have any ideas?
>>>>>>
>>>>>> Please note that the vignette "xps.Rnw" did work for the last two
>>>>>> years
>>>>>> w/o problem. Furthermore, the Bioconductor servers are able to build
>>>>>> the
>>>>>> vignette, see:
>>>>>> http://www.bioconductor.org/packages/release/bioc/html/xps.html
>>>>>
>>>>> See
>>>>> http://bioconductor.org/checkResults/2.8/bioc-20110225/xps/liverpool-checksrc.html
>>>>>
>>>>>
>>>>>
>>>>> and find that their Mac Servers are also fine with it. So maybe it is
>>>>> your setup that is corrupted?
>>>>
>>>> Maybe, you are right that my setup is corrupted, but on two independent
>>>> machines?
>>>>
>>>> Maybe the download of "R-2.13.0.pkg" is corrupted, but then nothing
>>>> should work, or am I wrong?
>>>>
>>>> How can I check if my setup is corrupted?
>>> By debugging the code in your package's vignette.
>>>
>>> Uwe Ligges
>>>
>>>
>>>
>>>> Best regards
>>>> Christian
>>>>
>>>>> Best wishes,
>>>>> Uwe
>>>>>
>>>>>> Best regards
>>>>>> Christian
>>>>>>
>>>>>>
>>>>>> On 4/24/11 4:12 PM, Uwe Ligges wrote:
>>>>>>>
>>>>>>> On 23.04.2011 21:50, cstrato wrote:
>>>>>>>> Dear all,
>>>>>>>>
>>>>>>>> While R CMD check and R CMD INSTALL have always created the
>>>>>>>> vignettes on
>>>>>>>> R-2.12.1 or any earlier versions of R, I am no longer able to build
>>>>>>>> the
>>>>>>>> vignettes on R-2.13.0.
>>>>>>>>
>>>>>>>> Instead R CMD check gives me the following output:
>>>>>>>>
>>>>>>>> * checking for unstated dependencies in vignettes ... OK
>>>>>>>> * checking package vignettes in 'inst/doc' ... WARNING
>>>>>>>> Package vignette(s) without corresponding PDF:
>>>>>>>> APTvsXPS.Rnw
>>>>>>>> xps.Rnw
>>>>>>>> xpsClasses.Rnw
>>>>>>>> xpsPreprocess.Rnw
>>>>>>>>
>>>>>>>> * checking running R code from vignettes ... OK
>>>>>>>> * checking re-building of vignettes ... OK
>>>>>>>> * checking PDF version of manual ... OK
>>>>>>>>
>>>>>>>>
>>>>>>>> Does someone know what the reason might be?
>>>>>>> No, it does for me for other packages.
>>>>>>> Perhaps an error when processing the vignettes? Have you tried to
>>>>>>> build
>>>>>>> them manually?
>>>>>>>
>>>>>>>
>>>>>>>> (R64 CMD check --help says that be default rebuild-vignettes is
>>>>>>>> turned
>>>>>>>> on.)
>>>>>>>>
>>>>>>>> Interestingly, R CMD check still creates the file "xps-manual.pdf".
>>>>>>> That is the collection of help pages, unrelated to the vignette.
>>>>>>>
>>>>>>>
>>>>>>> Uwe Ligges
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>> Here is my sessionInfo:
>>>>>>>>
>>>>>>>>> sessionInfo()
>>>>>>>> R version 2.13.0 (2011-04-13)
>>>>>>>> Platform: x86_64-apple-darwin9.8.0/x86_64 (64-bit)
>>>>>>>>
>>>>>>>> locale:
>>>>>>>> [1] C
>>>>>>>>
>>>>>>>> attached base packages:
>>>>>>>> [1] stats graphics grDevices utils datasets methods base
>>>>>>>>
>>>>>>>> other attached packages:
>>>>>>>> [1] xps_1.13.1
>>>>>>>>
>>>>>>>> loaded via a namespace (and not attached):
>>>>>>>> [1] Biobase_2.12.1 Biostrings_2.20.0 IRanges_1.10.0
>>>>>>>> [4] affy_1.30.0 affyPLM_1.28.5 affyio_1.20.0
>>>>>>>> [7] preprocessCore_1.14.0
>>>>>>>>
>>>>>>>> Thank you in advance.
>>>>>>>> Best regards
>>>>>>>> Christian
>>>>>>>> _._._._._._._._._._._._._._._._._._
>>>>>>>> C.h.r.i.s.t.i.a.n S.t.r.a.t.o.w.a
>>>>>>>> V.i.e.n.n.a A.u.s.t.r.i.a
>>>>>>>> e.m.a.i.l: cstrato at aon.at
>>>>>>>> _._._._._._._._._._._._._._._._._._
>>>>>>>>
>>>>>>>> ______________________________________________
>>>>>>>> R-devel at r-project.org mailing list
>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>>> ______________________________________________
>>>>>> R-devel at r-project.org mailing list
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From murdoch.duncan at gmail.com  Mon Apr 25 20:55:09 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 25 Apr 2011 14:55:09 -0400
Subject: [Rd] How to create vignette.pdf for R-2.13.0?
In-Reply-To: <4DB5C286.40306@aon.at>
References: <4DB32D9F.5010406@aon.at>	<4DB42FB3.9090401@statistik.tu-dortmund.de>	<4DB472F8.9060903@aon.at>	<4DB489EC.9080301@statistik.tu-dortmund.de>	<4DB491BE.8080104@aon.at>	<4DB57E7A.1080507@statistik.tu-dortmund.de>
	<4DB5AFD4.9020303@aon.at> <4DB5B6B0.90607@gmail.com>
	<4DB5C286.40306@aon.at>
Message-ID: <4DB5C38D.6030400@gmail.com>

cstrato wrote:
> Dear Duncan,
> 
> Thank you for your example, however it is different since it does not 
> use x and y. What about print(x+y)?

Try it.

> 
> Sorry, I do not believe that there is a bug in my code, since:
> 1, it worked in all versions from R starting with R-2.6.0 till R-2.12.2.
> 2, the identical code works in the examples
> 3, this code (or a similar code) is the starting code which all users of 
> xps have to use, and there was never a problem.

This might be a problem in R, or might be a problem in your code.  As 
far as I know, it has only shown up in your code, so I'd guess that's 
where the problem is.  In any case, you're the one in the best position 
to isolate it and debug it.

If it turns out to be a problem in R, put together an example 
illustrating the problem that doesn't involve your code, and I'll take a 
look.

Duncan Murdoch

> 
> Maybe the reason could be that my code has to import
> - the CEL-files from the package dir
> - the file SchemeTest3.root from the package dir
> ??
> 
> Best regards
> Christian
> 
> On 4/25/11 8:00 PM, Duncan Murdoch wrote:
>> cstrato wrote:
>>> Dear Uwe,
>>>
>>> Your suggestion to look at the Sweave manual helped me to solve the
>>> problem. It seems that in R-2.13.0 every chunk can use the code from
>>> the chunk before but not from an earlier chunk.
>> I'm either misreading what you wrote, or it's wrong. If I have this in a
>> Sweave file:
>>
>> <<>>=
>> x <- 1
>> @
>>
>> <<>>=
>> y <- 2
>> @
>>
>> <<>>=
>> print(x)
>> @
>>
>> I will see the value of x getting printed, even though it came from two
>> chunks earlier.
>>
>> I think Uwe is right: there is some bug in the code you're running.
>> Sweave isn't the problem.
>>
>> Duncan Murdoch
>>
>>> Concretely, the following does not work since chunk 5 needs the code
>>> from chunk 3 and 4:
>>>
>>> ###################################################
>>> ### chunk number 3:
>>> ###################################################
>>> #line 126 "xps.Rnw"
>>> celdir <- file.path(.path.package("xps"), "raw")
>>>
>>> ###################################################
>>> ### chunk number 4:
>>> ###################################################
>>> #line 132 "xps.Rnw"
>>> scheme.test3 <- root.scheme(file.path(.path.package("xps"), "schemes",
>>> "SchemeTest3.root"))
>>>
>>> ###################################################
>>> ### chunk number 5:
>>> ###################################################
>>> #line 137 "xps.Rnw"
>>> celfiles <- c("TestA1.CEL","TestA2.CEL")
>>> data.test3 <- import.data(scheme.test3, "tmpdt_DataTest3",
>>> celdir=celdir, celfiles=celfiles, verbose=FALSE)
>>>
>>>
>>> However, when I add "celdir" to chunk 5 then everything works since
>>> now chunk 5 needs only the code from chunk 4 but not from chunk 3:
>>>
>>> ###################################################
>>> ### chunk number 5:
>>> ###################################################
>>> #line 137 "xps.Rnw"
>>> celdir <- file.path(.path.package("xps"), "raw")
>>> celfiles <- c("TestA1.CEL","TestA2.CEL")
>>> data.test3 <- import.data(scheme.test3, "tmpdt_DataTest3",
>>> celdir=celdir, celfiles=celfiles, verbose=FALSE)
>>>
>>>
>>> Now buildVignettes() is able to create the vignettes, however R CMD
>>> check still does not build the vignettes.
>>>
>>>
>>> Yes, I get a Warning in both cases:
>>> * checking package vignettes in 'inst/doc' ... WARNING
>>> Package vignettes without corresponding PDF: ........
>>>
>>> However, with R-2.12.2 the following lines are added:
>>>
>>> /Volumes/CoreData/CRAN/xps.Rcheck/00_pkg_src/xps/inst/doc/APTvsXPS.Rnw
>>> /Volumes/CoreData/CRAN/xps.Rcheck/00_pkg_src/xps/inst/doc/xps.Rnw
>>> /Volumes/CoreData/CRAN/xps.Rcheck/00_pkg_src/xps/inst/doc/xpsClasses.Rnw
>>> /Volumes/CoreData/CRAN/xps.Rcheck/00_pkg_src/xps/inst/doc/xpsPreprocess.Rnw
>>>
>>>
>>> and in xps.Rcheck the subdirectory "inst/doc" will be created which
>>> contains the vignette data such as xps.Rnw, but also xps.tex and xps.pdf.
>>>
>>> In contrast, R-2.13.0 does not create the subdirectory "inst/doc" and
>>> no vignettes are built.
>>>
>>> One more issue:
>>> In contrast to my former believe R CMD INSTALL does not build the
>>> vignettes, neither in R-2.12.2 nor in R-2.13.0. I have to run
>>> buildVignettes() after installation. Is this the usual case?
>>>
>>> Best regards
>>> Christian
>>>
>>>
>>> On 4/25/11 4:00 PM, Uwe Ligges wrote:
>>>> On 24.04.2011 23:10, cstrato wrote:
>>>>> Dear Uwe,
>>>>>
>>>>> On 4/24/11 10:37 PM, Uwe Ligges wrote:
>>>>>> On 24.04.2011 20:59, cstrato wrote:
>>>>>>> Dear Uwe,
>>>>>>>
>>>>>>> Thank you for your reply.
>>>>>>>
>>>>>>> ad 2, Yes, i know that "xps-manual.pdf" is the collection of help
>>>>>>> pages,
>>>>>>> I have mentioned it only to show that creating pdf-files does work
>>>>>>> for
>>>>>>> R-2.13.0.
>>>>>>>
>>>>>>> ad 1, Could it be that this is a Mac-specific problem since I see
>>>>>>> it on
>>>>>>> both my old MacBook Pro and my new Mac Mini.
>>>>>> Have you tried on any other OS? I did not since installing root is
>>>>>> a bit
>>>>>> too much effort.
>>>>>>
>>>>>>
>>>>> No, until now I did not try another OS, but I will, since xps has to
>>>>> work on all three OSes.
>>>>>
>>>>>>> Using R CMD check with R-2.12.2 I get:
>>>>>> I thought we are talking about R-2.13.0?
>>>>>>
>>>>> I showed you the output of R-2.12.2 first and then the output of
>>>>> R-2.13.0, so that you can see that on the same machine with the same
>>>>> file it works with one version but not the other.
>>>> But you got a Warning in both cases:
>>>> * checking package vignettes in 'inst/doc' ... WARNING
>>>> Package vignettes without corresponding PDF: ........
>>>>
>>>>
>>>>
>>>>
>>>>>> Where is the R CMD build output (since R CMD build is supposed to
>>>>>> prepare the vignette).
>>>>>>
>>>>>>
>>>>>>
>>>>>>> $ R64 CMD check xps_1.13.1.tar.gz
>>>>>>> * using log directory '/Volumes/CoreData/CRAN/xps.Rcheck'
>>>>>>> * using R version 2.12.2 (2011-02-25)
>>>>>>> * using platform: x86_64-apple-darwin9.8.0 (64-bit)
>>>>>>> * using session charset: ASCII
>>>>>>> * checking for file 'xps/DESCRIPTION' ... OK
>>>>>>> * this is package 'xps' version '1.13.1'
>>>>>>> ...
>>>>>>> ...
>>>>>>> * checking package vignettes in 'inst/doc' ... WARNING
>>>>>>> Package vignettes without corresponding PDF:
>>>>>>>
>>>>>>> /Volumes/CoreData/CRAN/xps.Rcheck/00_pkg_src/xps/inst/doc/APTvsXPS.Rnw
>>>>>>>
>>>>>>> /Volumes/CoreData/CRAN/xps.Rcheck/00_pkg_src/xps/inst/doc/xps.Rnw
>>>>>>> /Volumes/CoreData/CRAN/xps.Rcheck/00_pkg_src/xps/inst/doc/xpsClasses.Rnw
>>>>>>>
>>>>>>>
>>>>>>> /Volumes/CoreData/CRAN/xps.Rcheck/00_pkg_src/xps/inst/doc/xpsPreprocess.Rnw
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>> * checking PDF version of manual ... OK
>>>>>>>
>>>>>>>
>>>>>>> Using "RSwitch.app" I switch to R-2.13.0, but now I get:
>>>>>>>
>>>>>>> $ R64 CMD check xps_1.13.1.tar.gz
>>>>>>> * using log directory '/Volumes/CoreData/CRAN/xps.Rcheck'
>>>>>>> * using R version 2.13.0 (2011-04-13)
>>>>>>> * using platform: x86_64-apple-darwin9.8.0 (64-bit)
>>>>>>> * using session charset: ASCII
>>>>>>> * checking for file 'xps/DESCRIPTION' ... OK
>>>>>>> * this is package 'xps' version '1.13.1'
>>>>>>> ...
>>>>>>> ...
>>>>>>> * checking package vignettes in 'inst/doc' ... WARNING
>>>>>>> Package vignette(s) without corresponding PDF:
>>>>>>> APTvsXPS.Rnw
>>>>>>> xps.Rnw
>>>>>>> xpsClasses.Rnw
>>>>>>> xpsPreprocess.Rnw
>>>>>>>
>>>>>>> * checking running R code from vignettes ... OK
>>>>>>> * checking re-building of vignettes ... OK
>>>>>>> * checking PDF version of manual ... OK
>>>>>>>
>>>>>>>
>>>>>>> I must admit that I have never built the vignettes manually, and I
>>>>>>> cannot find a hint how I can do it from the command line. Is this
>>>>>>> possible?
>>>>> Is it possible to build the vignettes from the command line?
>>>> R --help suggests there is
>>>> R CMD Sweave .....
>>>>
>>>>
>>>>>>> However, building the vignettes within R-2.13.0 I get:
>>>>>>>> library(tools)
>>>>>>>> buildVignettes("xps", dir="/Volumes/CoreData/CRAN/xps", quiet=F)
>>>>>>> Overfull \vbox (21.68121pt too high) has occurred while \output is
>>>>>>> Writing to file xps.tex
>>>>>>> Processing code chunks with options ...
>>>>>>> 1 : term verbatim
>>>>>>> 2 : echo term hide
>>>>>>> 3 : echo term verbatim
>>>>>>> 4 : echo term verbatim
>>>>>>> 5 : echo term verbatim
>>>>>>> SysError in <TFile::TFile>: file
>>>>>>> /tmpdt_DataTest3_cel.root/tmpdt_DataTest3_cel_20110424_201301.root
>>>>>>> can
>>>>>>> not be opened (No such file or directory)
>>>>>>> Error: Could not create file </tmpdt_DataTest3_cel.root>
>>>>>>>
>>>>>>>
>>>>>>> Here are the two important chunks 4 and 5, which work fine with
>>>>>>> R-2.12.2
>>>>>>> and earlier versions:
>>>>>>>
>>>>>>> ###################################################
>>>>>>> ### chunk number 4:
>>>>>>> ###################################################
>>>>>>> #line 132 "xps.Rnw"
>>>>>>> scheme.test3 <- root.scheme(file.path(.path.package("xps"),
>>>>>>> "schemes",
>>>>>>> "SchemeTest3.root"))
>>>>>>>
>>>>>>>
>>>>>>> ###################################################
>>>>>>> ### chunk number 5:
>>>>>>> ###################################################
>>>>>>> #line 137 "xps.Rnw"
>>>>>>> celfiles <- c("TestA1.CEL","TestA2.CEL")
>>>>>>> data.test3 <- import.data(scheme.test3, "tmpdt_DataTest3",
>>>>>>> celdir=celdir, celfiles=celfiles, verbose=FALSE)
>>>>>>>
>>>>>>>
>>>>>>> However, in R-2.13.0 chunk 5 crashes!!!
>>>>>>> It works only when replacing chunk 5 with:
>>>>>>>
>>>>>>> ###################################################
>>>>>>> ### chunk number 5:
>>>>>>> ###################################################
>>>>>>> #line 137 "xps.Rnw"
>>>>>>> celfiles <- c("TestA1.CEL","TestA2.CEL")
>>>>>>> scheme.test3 <- root.scheme(file.path(.path.package("xps"),
>>>>>>> "schemes",
>>>>>>> "SchemeTest3.root"))
>>>>>>> data.test3 <- import.data(scheme.test3, "tmpdt_DataTest3",
>>>>>>> celdir=celdir, celfiles=celfiles, verbose=FALSE)
>>>>>>>
>>>>>>>
>>>>>>> As you see R-2.13.0 does no longer remember the result of chunk 4,
>>>>>>> i.e.
>>>>>>> "scheme.test3". Now I have to include the line defining
>>>>>>> "scheme.test3"
>>>>>>> also in chunk 5.
>>>>>> How objects generated in one chunk can be reused later on is explained
>>>>>> in the Sweave manual.
>>>>>>
>>>>>>
>>>>>>> Do you have any idea for this behavior?
>>>>>>>
>>>>>>>
>>>>>>> An example, which does work in R-2.13.0 are the following two chunks:
>>>>>>>
>>>>>>> #################################################
>>>>>>> ### chunk number 20:
>>>>>>> ###################################################
>>>>>>> #line 300 "xps.Rnw"
>>>>>>> library(xps)
>>>>>>> scheme.test3 <- root.scheme(file.path(.path.package("xps"),
>>>>>>> "schemes",
>>>>>>> "SchemeTest3.root"))
>>>>>>> data.test3 <- root.data(scheme.test3,
>>>>>>> file.path(.path.package("xps"),"rootdata", "DataTest3_cel.root"))
>>>>>>>
>>>>>>>
>>>>>>> ###################################################
>>>>>>> ### chunk number 21:
>>>>>>> ###################################################
>>>>>>> #line 318 "xps.Rnw"
>>>>>>> data.rma <- rma(data.test3, "tmpdt_Test3RMA", verbose=FALSE)
>>>>>>>
>>>>>>>
>>>>>>> In summary it is not quite clear to me what has changed in
>>>>>>> R-2.13.0 so
>>>>>>> that chunk 5 no longer works.
>>>>>>>
>>>>>>> BTW, the error:
>>>>>>> SysError in <TFile::TFile>: file
>>>>>>> /tmpdt_DataTest3_cel.root/tmpdt_DataTest3_cel_20110424_201301.root
>>>>>>> can
>>>>>>> not be opened
>>>>>>> is not clear to me since "/tmpdt_DataTest3_cel.root/" is definitively
>>>>>>> NOT a directory.
>>>>>> Time to debug what root.scheme is doing with the supplied path.
>>>>>>
>>>>> Sorry, I do not understand what you mean. root.scheme does not change
>>>>> the path, otherwise it would not work on all older versions of R.
>>>> Right, but since something changed obviously, and you tell us the path
>>>> is not a path, it might be a function used by root.scheme .... That's
>>>> why I said time to debug the code in your vignette!
>>>>
>>>>
>>>>
>>>>>>> Do you have any ideas?
>>>>>>>
>>>>>>> Please note that the vignette "xps.Rnw" did work for the last two
>>>>>>> years
>>>>>>> w/o problem. Furthermore, the Bioconductor servers are able to build
>>>>>>> the
>>>>>>> vignette, see:
>>>>>>> http://www.bioconductor.org/packages/release/bioc/html/xps.html
>>>>>> See
>>>>>> http://bioconductor.org/checkResults/2.8/bioc-20110225/xps/liverpool-checksrc.html
>>>>>>
>>>>>>
>>>>>>
>>>>>> and find that their Mac Servers are also fine with it. So maybe it is
>>>>>> your setup that is corrupted?
>>>>> Maybe, you are right that my setup is corrupted, but on two independent
>>>>> machines?
>>>>>
>>>>> Maybe the download of "R-2.13.0.pkg" is corrupted, but then nothing
>>>>> should work, or am I wrong?
>>>>>
>>>>> How can I check if my setup is corrupted?
>>>> By debugging the code in your package's vignette.
>>>>
>>>> Uwe Ligges
>>>>
>>>>
>>>>
>>>>> Best regards
>>>>> Christian
>>>>>
>>>>>> Best wishes,
>>>>>> Uwe
>>>>>>
>>>>>>> Best regards
>>>>>>> Christian
>>>>>>>
>>>>>>>
>>>>>>> On 4/24/11 4:12 PM, Uwe Ligges wrote:
>>>>>>>> On 23.04.2011 21:50, cstrato wrote:
>>>>>>>>> Dear all,
>>>>>>>>>
>>>>>>>>> While R CMD check and R CMD INSTALL have always created the
>>>>>>>>> vignettes on
>>>>>>>>> R-2.12.1 or any earlier versions of R, I am no longer able to build
>>>>>>>>> the
>>>>>>>>> vignettes on R-2.13.0.
>>>>>>>>>
>>>>>>>>> Instead R CMD check gives me the following output:
>>>>>>>>>
>>>>>>>>> * checking for unstated dependencies in vignettes ... OK
>>>>>>>>> * checking package vignettes in 'inst/doc' ... WARNING
>>>>>>>>> Package vignette(s) without corresponding PDF:
>>>>>>>>> APTvsXPS.Rnw
>>>>>>>>> xps.Rnw
>>>>>>>>> xpsClasses.Rnw
>>>>>>>>> xpsPreprocess.Rnw
>>>>>>>>>
>>>>>>>>> * checking running R code from vignettes ... OK
>>>>>>>>> * checking re-building of vignettes ... OK
>>>>>>>>> * checking PDF version of manual ... OK
>>>>>>>>>
>>>>>>>>>
>>>>>>>>> Does someone know what the reason might be?
>>>>>>>> No, it does for me for other packages.
>>>>>>>> Perhaps an error when processing the vignettes? Have you tried to
>>>>>>>> build
>>>>>>>> them manually?
>>>>>>>>
>>>>>>>>
>>>>>>>>> (R64 CMD check --help says that be default rebuild-vignettes is
>>>>>>>>> turned
>>>>>>>>> on.)
>>>>>>>>>
>>>>>>>>> Interestingly, R CMD check still creates the file "xps-manual.pdf".
>>>>>>>> That is the collection of help pages, unrelated to the vignette.
>>>>>>>>
>>>>>>>>
>>>>>>>> Uwe Ligges
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>>> Here is my sessionInfo:
>>>>>>>>>
>>>>>>>>>> sessionInfo()
>>>>>>>>> R version 2.13.0 (2011-04-13)
>>>>>>>>> Platform: x86_64-apple-darwin9.8.0/x86_64 (64-bit)
>>>>>>>>>
>>>>>>>>> locale:
>>>>>>>>> [1] C
>>>>>>>>>
>>>>>>>>> attached base packages:
>>>>>>>>> [1] stats graphics grDevices utils datasets methods base
>>>>>>>>>
>>>>>>>>> other attached packages:
>>>>>>>>> [1] xps_1.13.1
>>>>>>>>>
>>>>>>>>> loaded via a namespace (and not attached):
>>>>>>>>> [1] Biobase_2.12.1 Biostrings_2.20.0 IRanges_1.10.0
>>>>>>>>> [4] affy_1.30.0 affyPLM_1.28.5 affyio_1.20.0
>>>>>>>>> [7] preprocessCore_1.14.0
>>>>>>>>>
>>>>>>>>> Thank you in advance.
>>>>>>>>> Best regards
>>>>>>>>> Christian
>>>>>>>>> _._._._._._._._._._._._._._._._._._
>>>>>>>>> C.h.r.i.s.t.i.a.n S.t.r.a.t.o.w.a
>>>>>>>>> V.i.e.n.n.a A.u.s.t.r.i.a
>>>>>>>>> e.m.a.i.l: cstrato at aon.at
>>>>>>>>> _._._._._._._._._._._._._._._._._._
>>>>>>>>>
>>>>>>>>> ______________________________________________
>>>>>>>>> R-devel at r-project.org mailing list
>>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>>>> ______________________________________________
>>>>>>> R-devel at r-project.org mailing list
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>


From cstrato at aon.at  Mon Apr 25 21:16:12 2011
From: cstrato at aon.at (cstrato)
Date: Mon, 25 Apr 2011 21:16:12 +0200
Subject: [Rd] How to create vignette.pdf for R-2.13.0?
In-Reply-To: <4DB5C38D.6030400@gmail.com>
References: <4DB32D9F.5010406@aon.at>	<4DB42FB3.9090401@statistik.tu-dortmund.de>	<4DB472F8.9060903@aon.at>	<4DB489EC.9080301@statistik.tu-dortmund.de>	<4DB491BE.8080104@aon.at>	<4DB57E7A.1080507@statistik.tu-dortmund.de>
	<4DB5AFD4.9020303@aon.at> <4DB5B6B0.90607@gmail.com>
	<4DB5C286.40306@aon.at> <4DB5C38D.6030400@gmail.com>
Message-ID: <4DB5C87C.5040905@aon.at>

Thank you.

My problem seems to be that at the moment the problem can be seen only 
on my Mac, since e.g. the Bioconductor servers have no problems creating 
the vignettes.

Best regards
Christian

On 4/25/11 8:55 PM, Duncan Murdoch wrote:
> cstrato wrote:
>> Dear Duncan,
>>
>> Thank you for your example, however it is different since it does not
>> use x and y. What about print(x+y)?
>
> Try it.
>
>>
>> Sorry, I do not believe that there is a bug in my code, since:
>> 1, it worked in all versions from R starting with R-2.6.0 till R-2.12.2.
>> 2, the identical code works in the examples
>> 3, this code (or a similar code) is the starting code which all users
>> of xps have to use, and there was never a problem.
>
> This might be a problem in R, or might be a problem in your code. As far
> as I know, it has only shown up in your code, so I'd guess that's where
> the problem is. In any case, you're the one in the best position to
> isolate it and debug it.
>
> If it turns out to be a problem in R, put together an example
> illustrating the problem that doesn't involve your code, and I'll take a
> look.
>
> Duncan Murdoch
>
>>
>> Maybe the reason could be that my code has to import
>> - the CEL-files from the package dir
>> - the file SchemeTest3.root from the package dir
>> ??
>>
>> Best regards
>> Christian
>>
>> On 4/25/11 8:00 PM, Duncan Murdoch wrote:
>>> cstrato wrote:
>>>> Dear Uwe,
>>>>
>>>> Your suggestion to look at the Sweave manual helped me to solve the
>>>> problem. It seems that in R-2.13.0 every chunk can use the code from
>>>> the chunk before but not from an earlier chunk.
>>> I'm either misreading what you wrote, or it's wrong. If I have this in a
>>> Sweave file:
>>>
>>> <<>>=
>>> x <- 1
>>> @
>>>
>>> <<>>=
>>> y <- 2
>>> @
>>>
>>> <<>>=
>>> print(x)
>>> @
>>>
>>> I will see the value of x getting printed, even though it came from two
>>> chunks earlier.
>>>
>>> I think Uwe is right: there is some bug in the code you're running.
>>> Sweave isn't the problem.
>>>
>>> Duncan Murdoch
>>>
>>>> Concretely, the following does not work since chunk 5 needs the code
>>>> from chunk 3 and 4:
>>>>
>>>> ###################################################
>>>> ### chunk number 3:
>>>> ###################################################
>>>> #line 126 "xps.Rnw"
>>>> celdir <- file.path(.path.package("xps"), "raw")
>>>>
>>>> ###################################################
>>>> ### chunk number 4:
>>>> ###################################################
>>>> #line 132 "xps.Rnw"
>>>> scheme.test3 <- root.scheme(file.path(.path.package("xps"), "schemes",
>>>> "SchemeTest3.root"))
>>>>
>>>> ###################################################
>>>> ### chunk number 5:
>>>> ###################################################
>>>> #line 137 "xps.Rnw"
>>>> celfiles <- c("TestA1.CEL","TestA2.CEL")
>>>> data.test3 <- import.data(scheme.test3, "tmpdt_DataTest3",
>>>> celdir=celdir, celfiles=celfiles, verbose=FALSE)
>>>>
>>>>
>>>> However, when I add "celdir" to chunk 5 then everything works since
>>>> now chunk 5 needs only the code from chunk 4 but not from chunk 3:
>>>>
>>>> ###################################################
>>>> ### chunk number 5:
>>>> ###################################################
>>>> #line 137 "xps.Rnw"
>>>> celdir <- file.path(.path.package("xps"), "raw")
>>>> celfiles <- c("TestA1.CEL","TestA2.CEL")
>>>> data.test3 <- import.data(scheme.test3, "tmpdt_DataTest3",
>>>> celdir=celdir, celfiles=celfiles, verbose=FALSE)
>>>>
>>>>
>>>> Now buildVignettes() is able to create the vignettes, however R CMD
>>>> check still does not build the vignettes.
>>>>
>>>>
>>>> Yes, I get a Warning in both cases:
>>>> * checking package vignettes in 'inst/doc' ... WARNING
>>>> Package vignettes without corresponding PDF: ........
>>>>
>>>> However, with R-2.12.2 the following lines are added:
>>>>
>>>> /Volumes/CoreData/CRAN/xps.Rcheck/00_pkg_src/xps/inst/doc/APTvsXPS.Rnw
>>>> /Volumes/CoreData/CRAN/xps.Rcheck/00_pkg_src/xps/inst/doc/xps.Rnw
>>>> /Volumes/CoreData/CRAN/xps.Rcheck/00_pkg_src/xps/inst/doc/xpsClasses.Rnw
>>>>
>>>> /Volumes/CoreData/CRAN/xps.Rcheck/00_pkg_src/xps/inst/doc/xpsPreprocess.Rnw
>>>>
>>>>
>>>>
>>>> and in xps.Rcheck the subdirectory "inst/doc" will be created which
>>>> contains the vignette data such as xps.Rnw, but also xps.tex and
>>>> xps.pdf.
>>>>
>>>> In contrast, R-2.13.0 does not create the subdirectory "inst/doc" and
>>>> no vignettes are built.
>>>>
>>>> One more issue:
>>>> In contrast to my former believe R CMD INSTALL does not build the
>>>> vignettes, neither in R-2.12.2 nor in R-2.13.0. I have to run
>>>> buildVignettes() after installation. Is this the usual case?
>>>>
>>>> Best regards
>>>> Christian
>>>>
>>>>
>>>> On 4/25/11 4:00 PM, Uwe Ligges wrote:
>>>>> On 24.04.2011 23:10, cstrato wrote:
>>>>>> Dear Uwe,
>>>>>>
>>>>>> On 4/24/11 10:37 PM, Uwe Ligges wrote:
>>>>>>> On 24.04.2011 20:59, cstrato wrote:
>>>>>>>> Dear Uwe,
>>>>>>>>
>>>>>>>> Thank you for your reply.
>>>>>>>>
>>>>>>>> ad 2, Yes, i know that "xps-manual.pdf" is the collection of help
>>>>>>>> pages,
>>>>>>>> I have mentioned it only to show that creating pdf-files does work
>>>>>>>> for
>>>>>>>> R-2.13.0.
>>>>>>>>
>>>>>>>> ad 1, Could it be that this is a Mac-specific problem since I see
>>>>>>>> it on
>>>>>>>> both my old MacBook Pro and my new Mac Mini.
>>>>>>> Have you tried on any other OS? I did not since installing root is
>>>>>>> a bit
>>>>>>> too much effort.
>>>>>>>
>>>>>>>
>>>>>> No, until now I did not try another OS, but I will, since xps has to
>>>>>> work on all three OSes.
>>>>>>
>>>>>>>> Using R CMD check with R-2.12.2 I get:
>>>>>>> I thought we are talking about R-2.13.0?
>>>>>>>
>>>>>> I showed you the output of R-2.12.2 first and then the output of
>>>>>> R-2.13.0, so that you can see that on the same machine with the same
>>>>>> file it works with one version but not the other.
>>>>> But you got a Warning in both cases:
>>>>> * checking package vignettes in 'inst/doc' ... WARNING
>>>>> Package vignettes without corresponding PDF: ........
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>>> Where is the R CMD build output (since R CMD build is supposed to
>>>>>>> prepare the vignette).
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>> $ R64 CMD check xps_1.13.1.tar.gz
>>>>>>>> * using log directory '/Volumes/CoreData/CRAN/xps.Rcheck'
>>>>>>>> * using R version 2.12.2 (2011-02-25)
>>>>>>>> * using platform: x86_64-apple-darwin9.8.0 (64-bit)
>>>>>>>> * using session charset: ASCII
>>>>>>>> * checking for file 'xps/DESCRIPTION' ... OK
>>>>>>>> * this is package 'xps' version '1.13.1'
>>>>>>>> ...
>>>>>>>> ...
>>>>>>>> * checking package vignettes in 'inst/doc' ... WARNING
>>>>>>>> Package vignettes without corresponding PDF:
>>>>>>>>
>>>>>>>> /Volumes/CoreData/CRAN/xps.Rcheck/00_pkg_src/xps/inst/doc/APTvsXPS.Rnw
>>>>>>>>
>>>>>>>>
>>>>>>>> /Volumes/CoreData/CRAN/xps.Rcheck/00_pkg_src/xps/inst/doc/xps.Rnw
>>>>>>>> /Volumes/CoreData/CRAN/xps.Rcheck/00_pkg_src/xps/inst/doc/xpsClasses.Rnw
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>> /Volumes/CoreData/CRAN/xps.Rcheck/00_pkg_src/xps/inst/doc/xpsPreprocess.Rnw
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>> * checking PDF version of manual ... OK
>>>>>>>>
>>>>>>>>
>>>>>>>> Using "RSwitch.app" I switch to R-2.13.0, but now I get:
>>>>>>>>
>>>>>>>> $ R64 CMD check xps_1.13.1.tar.gz
>>>>>>>> * using log directory '/Volumes/CoreData/CRAN/xps.Rcheck'
>>>>>>>> * using R version 2.13.0 (2011-04-13)
>>>>>>>> * using platform: x86_64-apple-darwin9.8.0 (64-bit)
>>>>>>>> * using session charset: ASCII
>>>>>>>> * checking for file 'xps/DESCRIPTION' ... OK
>>>>>>>> * this is package 'xps' version '1.13.1'
>>>>>>>> ...
>>>>>>>> ...
>>>>>>>> * checking package vignettes in 'inst/doc' ... WARNING
>>>>>>>> Package vignette(s) without corresponding PDF:
>>>>>>>> APTvsXPS.Rnw
>>>>>>>> xps.Rnw
>>>>>>>> xpsClasses.Rnw
>>>>>>>> xpsPreprocess.Rnw
>>>>>>>>
>>>>>>>> * checking running R code from vignettes ... OK
>>>>>>>> * checking re-building of vignettes ... OK
>>>>>>>> * checking PDF version of manual ... OK
>>>>>>>>
>>>>>>>>
>>>>>>>> I must admit that I have never built the vignettes manually, and I
>>>>>>>> cannot find a hint how I can do it from the command line. Is this
>>>>>>>> possible?
>>>>>> Is it possible to build the vignettes from the command line?
>>>>> R --help suggests there is
>>>>> R CMD Sweave .....
>>>>>
>>>>>
>>>>>>>> However, building the vignettes within R-2.13.0 I get:
>>>>>>>>> library(tools)
>>>>>>>>> buildVignettes("xps", dir="/Volumes/CoreData/CRAN/xps", quiet=F)
>>>>>>>> Overfull \vbox (21.68121pt too high) has occurred while \output is
>>>>>>>> Writing to file xps.tex
>>>>>>>> Processing code chunks with options ...
>>>>>>>> 1 : term verbatim
>>>>>>>> 2 : echo term hide
>>>>>>>> 3 : echo term verbatim
>>>>>>>> 4 : echo term verbatim
>>>>>>>> 5 : echo term verbatim
>>>>>>>> SysError in <TFile::TFile>: file
>>>>>>>> /tmpdt_DataTest3_cel.root/tmpdt_DataTest3_cel_20110424_201301.root
>>>>>>>> can
>>>>>>>> not be opened (No such file or directory)
>>>>>>>> Error: Could not create file </tmpdt_DataTest3_cel.root>
>>>>>>>>
>>>>>>>>
>>>>>>>> Here are the two important chunks 4 and 5, which work fine with
>>>>>>>> R-2.12.2
>>>>>>>> and earlier versions:
>>>>>>>>
>>>>>>>> ###################################################
>>>>>>>> ### chunk number 4:
>>>>>>>> ###################################################
>>>>>>>> #line 132 "xps.Rnw"
>>>>>>>> scheme.test3 <- root.scheme(file.path(.path.package("xps"),
>>>>>>>> "schemes",
>>>>>>>> "SchemeTest3.root"))
>>>>>>>>
>>>>>>>>
>>>>>>>> ###################################################
>>>>>>>> ### chunk number 5:
>>>>>>>> ###################################################
>>>>>>>> #line 137 "xps.Rnw"
>>>>>>>> celfiles <- c("TestA1.CEL","TestA2.CEL")
>>>>>>>> data.test3 <- import.data(scheme.test3, "tmpdt_DataTest3",
>>>>>>>> celdir=celdir, celfiles=celfiles, verbose=FALSE)
>>>>>>>>
>>>>>>>>
>>>>>>>> However, in R-2.13.0 chunk 5 crashes!!!
>>>>>>>> It works only when replacing chunk 5 with:
>>>>>>>>
>>>>>>>> ###################################################
>>>>>>>> ### chunk number 5:
>>>>>>>> ###################################################
>>>>>>>> #line 137 "xps.Rnw"
>>>>>>>> celfiles <- c("TestA1.CEL","TestA2.CEL")
>>>>>>>> scheme.test3 <- root.scheme(file.path(.path.package("xps"),
>>>>>>>> "schemes",
>>>>>>>> "SchemeTest3.root"))
>>>>>>>> data.test3 <- import.data(scheme.test3, "tmpdt_DataTest3",
>>>>>>>> celdir=celdir, celfiles=celfiles, verbose=FALSE)
>>>>>>>>
>>>>>>>>
>>>>>>>> As you see R-2.13.0 does no longer remember the result of chunk 4,
>>>>>>>> i.e.
>>>>>>>> "scheme.test3". Now I have to include the line defining
>>>>>>>> "scheme.test3"
>>>>>>>> also in chunk 5.
>>>>>>> How objects generated in one chunk can be reused later on is
>>>>>>> explained
>>>>>>> in the Sweave manual.
>>>>>>>
>>>>>>>
>>>>>>>> Do you have any idea for this behavior?
>>>>>>>>
>>>>>>>>
>>>>>>>> An example, which does work in R-2.13.0 are the following two
>>>>>>>> chunks:
>>>>>>>>
>>>>>>>> #################################################
>>>>>>>> ### chunk number 20:
>>>>>>>> ###################################################
>>>>>>>> #line 300 "xps.Rnw"
>>>>>>>> library(xps)
>>>>>>>> scheme.test3 <- root.scheme(file.path(.path.package("xps"),
>>>>>>>> "schemes",
>>>>>>>> "SchemeTest3.root"))
>>>>>>>> data.test3 <- root.data(scheme.test3,
>>>>>>>> file.path(.path.package("xps"),"rootdata", "DataTest3_cel.root"))
>>>>>>>>
>>>>>>>>
>>>>>>>> ###################################################
>>>>>>>> ### chunk number 21:
>>>>>>>> ###################################################
>>>>>>>> #line 318 "xps.Rnw"
>>>>>>>> data.rma <- rma(data.test3, "tmpdt_Test3RMA", verbose=FALSE)
>>>>>>>>
>>>>>>>>
>>>>>>>> In summary it is not quite clear to me what has changed in
>>>>>>>> R-2.13.0 so
>>>>>>>> that chunk 5 no longer works.
>>>>>>>>
>>>>>>>> BTW, the error:
>>>>>>>> SysError in <TFile::TFile>: file
>>>>>>>> /tmpdt_DataTest3_cel.root/tmpdt_DataTest3_cel_20110424_201301.root
>>>>>>>> can
>>>>>>>> not be opened
>>>>>>>> is not clear to me since "/tmpdt_DataTest3_cel.root/" is
>>>>>>>> definitively
>>>>>>>> NOT a directory.
>>>>>>> Time to debug what root.scheme is doing with the supplied path.
>>>>>>>
>>>>>> Sorry, I do not understand what you mean. root.scheme does not change
>>>>>> the path, otherwise it would not work on all older versions of R.
>>>>> Right, but since something changed obviously, and you tell us the path
>>>>> is not a path, it might be a function used by root.scheme .... That's
>>>>> why I said time to debug the code in your vignette!
>>>>>
>>>>>
>>>>>
>>>>>>>> Do you have any ideas?
>>>>>>>>
>>>>>>>> Please note that the vignette "xps.Rnw" did work for the last two
>>>>>>>> years
>>>>>>>> w/o problem. Furthermore, the Bioconductor servers are able to
>>>>>>>> build
>>>>>>>> the
>>>>>>>> vignette, see:
>>>>>>>> http://www.bioconductor.org/packages/release/bioc/html/xps.html
>>>>>>> See
>>>>>>> http://bioconductor.org/checkResults/2.8/bioc-20110225/xps/liverpool-checksrc.html
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>> and find that their Mac Servers are also fine with it. So maybe
>>>>>>> it is
>>>>>>> your setup that is corrupted?
>>>>>> Maybe, you are right that my setup is corrupted, but on two
>>>>>> independent
>>>>>> machines?
>>>>>>
>>>>>> Maybe the download of "R-2.13.0.pkg" is corrupted, but then nothing
>>>>>> should work, or am I wrong?
>>>>>>
>>>>>> How can I check if my setup is corrupted?
>>>>> By debugging the code in your package's vignette.
>>>>>
>>>>> Uwe Ligges
>>>>>
>>>>>
>>>>>
>>>>>> Best regards
>>>>>> Christian
>>>>>>
>>>>>>> Best wishes,
>>>>>>> Uwe
>>>>>>>
>>>>>>>> Best regards
>>>>>>>> Christian
>>>>>>>>
>>>>>>>>
>>>>>>>> On 4/24/11 4:12 PM, Uwe Ligges wrote:
>>>>>>>>> On 23.04.2011 21:50, cstrato wrote:
>>>>>>>>>> Dear all,
>>>>>>>>>>
>>>>>>>>>> While R CMD check and R CMD INSTALL have always created the
>>>>>>>>>> vignettes on
>>>>>>>>>> R-2.12.1 or any earlier versions of R, I am no longer able to
>>>>>>>>>> build
>>>>>>>>>> the
>>>>>>>>>> vignettes on R-2.13.0.
>>>>>>>>>>
>>>>>>>>>> Instead R CMD check gives me the following output:
>>>>>>>>>>
>>>>>>>>>> * checking for unstated dependencies in vignettes ... OK
>>>>>>>>>> * checking package vignettes in 'inst/doc' ... WARNING
>>>>>>>>>> Package vignette(s) without corresponding PDF:
>>>>>>>>>> APTvsXPS.Rnw
>>>>>>>>>> xps.Rnw
>>>>>>>>>> xpsClasses.Rnw
>>>>>>>>>> xpsPreprocess.Rnw
>>>>>>>>>>
>>>>>>>>>> * checking running R code from vignettes ... OK
>>>>>>>>>> * checking re-building of vignettes ... OK
>>>>>>>>>> * checking PDF version of manual ... OK
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>> Does someone know what the reason might be?
>>>>>>>>> No, it does for me for other packages.
>>>>>>>>> Perhaps an error when processing the vignettes? Have you tried to
>>>>>>>>> build
>>>>>>>>> them manually?
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>> (R64 CMD check --help says that be default rebuild-vignettes is
>>>>>>>>>> turned
>>>>>>>>>> on.)
>>>>>>>>>>
>>>>>>>>>> Interestingly, R CMD check still creates the file
>>>>>>>>>> "xps-manual.pdf".
>>>>>>>>> That is the collection of help pages, unrelated to the vignette.
>>>>>>>>>
>>>>>>>>>
>>>>>>>>> Uwe Ligges
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>> Here is my sessionInfo:
>>>>>>>>>>
>>>>>>>>>>> sessionInfo()
>>>>>>>>>> R version 2.13.0 (2011-04-13)
>>>>>>>>>> Platform: x86_64-apple-darwin9.8.0/x86_64 (64-bit)
>>>>>>>>>>
>>>>>>>>>> locale:
>>>>>>>>>> [1] C
>>>>>>>>>>
>>>>>>>>>> attached base packages:
>>>>>>>>>> [1] stats graphics grDevices utils datasets methods base
>>>>>>>>>>
>>>>>>>>>> other attached packages:
>>>>>>>>>> [1] xps_1.13.1
>>>>>>>>>>
>>>>>>>>>> loaded via a namespace (and not attached):
>>>>>>>>>> [1] Biobase_2.12.1 Biostrings_2.20.0 IRanges_1.10.0
>>>>>>>>>> [4] affy_1.30.0 affyPLM_1.28.5 affyio_1.20.0
>>>>>>>>>> [7] preprocessCore_1.14.0
>>>>>>>>>>
>>>>>>>>>> Thank you in advance.
>>>>>>>>>> Best regards
>>>>>>>>>> Christian
>>>>>>>>>> _._._._._._._._._._._._._._._._._._
>>>>>>>>>> C.h.r.i.s.t.i.a.n S.t.r.a.t.o.w.a
>>>>>>>>>> V.i.e.n.n.a A.u.s.t.r.i.a
>>>>>>>>>> e.m.a.i.l: cstrato at aon.at
>>>>>>>>>> _._._._._._._._._._._._._._._._._._
>>>>>>>>>>
>>>>>>>>>> ______________________________________________
>>>>>>>>>> R-devel at r-project.org mailing list
>>>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>>>>> ______________________________________________
>>>>>>>> R-devel at r-project.org mailing list
>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>
>


From murdoch.duncan at gmail.com  Mon Apr 25 21:31:09 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 25 Apr 2011 15:31:09 -0400
Subject: [Rd] How to create vignette.pdf for R-2.13.0?
In-Reply-To: <4DB5C87C.5040905@aon.at>
References: <4DB32D9F.5010406@aon.at>	<4DB42FB3.9090401@statistik.tu-dortmund.de>	<4DB472F8.9060903@aon.at>	<4DB489EC.9080301@statistik.tu-dortmund.de>	<4DB491BE.8080104@aon.at>	<4DB57E7A.1080507@statistik.tu-dortmund.de>
	<4DB5AFD4.9020303@aon.at> <4DB5B6B0.90607@gmail.com>
	<4DB5C286.40306@aon.at> <4DB5C38D.6030400@gmail.com>
	<4DB5C87C.5040905@aon.at>
Message-ID: <4DB5CBFD.6050508@gmail.com>

On 25/04/2011 3:16 PM, cstrato wrote:
> Thank you.
>
> My problem seems to be that at the moment the problem can be seen only
> on my Mac, since e.g. the Bioconductor servers have no problems creating
> the vignettes.

Then you are definitely the one in the best position to diagnose the 
problem.  Use the usual approach:  simplify it by cutting out everything 
that looks unrelated.  Verify that the problem still exists, then cut 
some more.  Eventually you'll have isolated the error to a particular 
small snippet of code, and then you can add print() statements, or use 
trace(), or do whatever is necessary to see what's so special about your 
system.

I suspect it will turn out to be an assumption in the code that is not 
true on your system.

If the assumption is being made by code you wrote, then fix it.  If it's 
being made by R, let us know.

Duncan Murdoch

>
> Best regards
> Christian
>
> On 4/25/11 8:55 PM, Duncan Murdoch wrote:
>> cstrato wrote:
>>> Dear Duncan,
>>>
>>> Thank you for your example, however it is different since it does not
>>> use x and y. What about print(x+y)?
>>
>> Try it.
>>
>>>
>>> Sorry, I do not believe that there is a bug in my code, since:
>>> 1, it worked in all versions from R starting with R-2.6.0 till R-2.12.2.
>>> 2, the identical code works in the examples
>>> 3, this code (or a similar code) is the starting code which all users
>>> of xps have to use, and there was never a problem.
>>
>> This might be a problem in R, or might be a problem in your code. As far
>> as I know, it has only shown up in your code, so I'd guess that's where
>> the problem is. In any case, you're the one in the best position to
>> isolate it and debug it.
>>
>> If it turns out to be a problem in R, put together an example
>> illustrating the problem that doesn't involve your code, and I'll take a
>> look.
>>
>> Duncan Murdoch
>>
>>>
>>> Maybe the reason could be that my code has to import
>>> - the CEL-files from the package dir
>>> - the file SchemeTest3.root from the package dir
>>> ??
>>>
>>> Best regards
>>> Christian
>>>
>>> On 4/25/11 8:00 PM, Duncan Murdoch wrote:
>>>> cstrato wrote:
>>>>> Dear Uwe,
>>>>>
>>>>> Your suggestion to look at the Sweave manual helped me to solve the
>>>>> problem. It seems that in R-2.13.0 every chunk can use the code from
>>>>> the chunk before but not from an earlier chunk.
>>>> I'm either misreading what you wrote, or it's wrong. If I have this in a
>>>> Sweave file:
>>>>
>>>> <<>>=
>>>> x<- 1
>>>> @
>>>>
>>>> <<>>=
>>>> y<- 2
>>>> @
>>>>
>>>> <<>>=
>>>> print(x)
>>>> @
>>>>
>>>> I will see the value of x getting printed, even though it came from two
>>>> chunks earlier.
>>>>
>>>> I think Uwe is right: there is some bug in the code you're running.
>>>> Sweave isn't the problem.
>>>>
>>>> Duncan Murdoch
>>>>
>>>>> Concretely, the following does not work since chunk 5 needs the code
>>>>> from chunk 3 and 4:
>>>>>
>>>>> ###################################################
>>>>> ### chunk number 3:
>>>>> ###################################################
>>>>> #line 126 "xps.Rnw"
>>>>> celdir<- file.path(.path.package("xps"), "raw")
>>>>>
>>>>> ###################################################
>>>>> ### chunk number 4:
>>>>> ###################################################
>>>>> #line 132 "xps.Rnw"
>>>>> scheme.test3<- root.scheme(file.path(.path.package("xps"), "schemes",
>>>>> "SchemeTest3.root"))
>>>>>
>>>>> ###################################################
>>>>> ### chunk number 5:
>>>>> ###################################################
>>>>> #line 137 "xps.Rnw"
>>>>> celfiles<- c("TestA1.CEL","TestA2.CEL")
>>>>> data.test3<- import.data(scheme.test3, "tmpdt_DataTest3",
>>>>> celdir=celdir, celfiles=celfiles, verbose=FALSE)
>>>>>
>>>>>
>>>>> However, when I add "celdir" to chunk 5 then everything works since
>>>>> now chunk 5 needs only the code from chunk 4 but not from chunk 3:
>>>>>
>>>>> ###################################################
>>>>> ### chunk number 5:
>>>>> ###################################################
>>>>> #line 137 "xps.Rnw"
>>>>> celdir<- file.path(.path.package("xps"), "raw")
>>>>> celfiles<- c("TestA1.CEL","TestA2.CEL")
>>>>> data.test3<- import.data(scheme.test3, "tmpdt_DataTest3",
>>>>> celdir=celdir, celfiles=celfiles, verbose=FALSE)
>>>>>
>>>>>
>>>>> Now buildVignettes() is able to create the vignettes, however R CMD
>>>>> check still does not build the vignettes.
>>>>>
>>>>>
>>>>> Yes, I get a Warning in both cases:
>>>>> * checking package vignettes in 'inst/doc' ... WARNING
>>>>> Package vignettes without corresponding PDF: ........
>>>>>
>>>>> However, with R-2.12.2 the following lines are added:
>>>>>
>>>>> /Volumes/CoreData/CRAN/xps.Rcheck/00_pkg_src/xps/inst/doc/APTvsXPS.Rnw
>>>>> /Volumes/CoreData/CRAN/xps.Rcheck/00_pkg_src/xps/inst/doc/xps.Rnw
>>>>> /Volumes/CoreData/CRAN/xps.Rcheck/00_pkg_src/xps/inst/doc/xpsClasses.Rnw
>>>>>
>>>>> /Volumes/CoreData/CRAN/xps.Rcheck/00_pkg_src/xps/inst/doc/xpsPreprocess.Rnw
>>>>>
>>>>>
>>>>>
>>>>> and in xps.Rcheck the subdirectory "inst/doc" will be created which
>>>>> contains the vignette data such as xps.Rnw, but also xps.tex and
>>>>> xps.pdf.
>>>>>
>>>>> In contrast, R-2.13.0 does not create the subdirectory "inst/doc" and
>>>>> no vignettes are built.
>>>>>
>>>>> One more issue:
>>>>> In contrast to my former believe R CMD INSTALL does not build the
>>>>> vignettes, neither in R-2.12.2 nor in R-2.13.0. I have to run
>>>>> buildVignettes() after installation. Is this the usual case?
>>>>>
>>>>> Best regards
>>>>> Christian
>>>>>
>>>>>
>>>>> On 4/25/11 4:00 PM, Uwe Ligges wrote:
>>>>>> On 24.04.2011 23:10, cstrato wrote:
>>>>>>> Dear Uwe,
>>>>>>>
>>>>>>> On 4/24/11 10:37 PM, Uwe Ligges wrote:
>>>>>>>> On 24.04.2011 20:59, cstrato wrote:
>>>>>>>>> Dear Uwe,
>>>>>>>>>
>>>>>>>>> Thank you for your reply.
>>>>>>>>>
>>>>>>>>> ad 2, Yes, i know that "xps-manual.pdf" is the collection of help
>>>>>>>>> pages,
>>>>>>>>> I have mentioned it only to show that creating pdf-files does work
>>>>>>>>> for
>>>>>>>>> R-2.13.0.
>>>>>>>>>
>>>>>>>>> ad 1, Could it be that this is a Mac-specific problem since I see
>>>>>>>>> it on
>>>>>>>>> both my old MacBook Pro and my new Mac Mini.
>>>>>>>> Have you tried on any other OS? I did not since installing root is
>>>>>>>> a bit
>>>>>>>> too much effort.
>>>>>>>>
>>>>>>>>
>>>>>>> No, until now I did not try another OS, but I will, since xps has to
>>>>>>> work on all three OSes.
>>>>>>>
>>>>>>>>> Using R CMD check with R-2.12.2 I get:
>>>>>>>> I thought we are talking about R-2.13.0?
>>>>>>>>
>>>>>>> I showed you the output of R-2.12.2 first and then the output of
>>>>>>> R-2.13.0, so that you can see that on the same machine with the same
>>>>>>> file it works with one version but not the other.
>>>>>> But you got a Warning in both cases:
>>>>>> * checking package vignettes in 'inst/doc' ... WARNING
>>>>>> Package vignettes without corresponding PDF: ........
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>>> Where is the R CMD build output (since R CMD build is supposed to
>>>>>>>> prepare the vignette).
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>>> $ R64 CMD check xps_1.13.1.tar.gz
>>>>>>>>> * using log directory '/Volumes/CoreData/CRAN/xps.Rcheck'
>>>>>>>>> * using R version 2.12.2 (2011-02-25)
>>>>>>>>> * using platform: x86_64-apple-darwin9.8.0 (64-bit)
>>>>>>>>> * using session charset: ASCII
>>>>>>>>> * checking for file 'xps/DESCRIPTION' ... OK
>>>>>>>>> * this is package 'xps' version '1.13.1'
>>>>>>>>> ...
>>>>>>>>> ...
>>>>>>>>> * checking package vignettes in 'inst/doc' ... WARNING
>>>>>>>>> Package vignettes without corresponding PDF:
>>>>>>>>>
>>>>>>>>> /Volumes/CoreData/CRAN/xps.Rcheck/00_pkg_src/xps/inst/doc/APTvsXPS.Rnw
>>>>>>>>>
>>>>>>>>>
>>>>>>>>> /Volumes/CoreData/CRAN/xps.Rcheck/00_pkg_src/xps/inst/doc/xps.Rnw
>>>>>>>>> /Volumes/CoreData/CRAN/xps.Rcheck/00_pkg_src/xps/inst/doc/xpsClasses.Rnw
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>> /Volumes/CoreData/CRAN/xps.Rcheck/00_pkg_src/xps/inst/doc/xpsPreprocess.Rnw
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>> * checking PDF version of manual ... OK
>>>>>>>>>
>>>>>>>>>
>>>>>>>>> Using "RSwitch.app" I switch to R-2.13.0, but now I get:
>>>>>>>>>
>>>>>>>>> $ R64 CMD check xps_1.13.1.tar.gz
>>>>>>>>> * using log directory '/Volumes/CoreData/CRAN/xps.Rcheck'
>>>>>>>>> * using R version 2.13.0 (2011-04-13)
>>>>>>>>> * using platform: x86_64-apple-darwin9.8.0 (64-bit)
>>>>>>>>> * using session charset: ASCII
>>>>>>>>> * checking for file 'xps/DESCRIPTION' ... OK
>>>>>>>>> * this is package 'xps' version '1.13.1'
>>>>>>>>> ...
>>>>>>>>> ...
>>>>>>>>> * checking package vignettes in 'inst/doc' ... WARNING
>>>>>>>>> Package vignette(s) without corresponding PDF:
>>>>>>>>> APTvsXPS.Rnw
>>>>>>>>> xps.Rnw
>>>>>>>>> xpsClasses.Rnw
>>>>>>>>> xpsPreprocess.Rnw
>>>>>>>>>
>>>>>>>>> * checking running R code from vignettes ... OK
>>>>>>>>> * checking re-building of vignettes ... OK
>>>>>>>>> * checking PDF version of manual ... OK
>>>>>>>>>
>>>>>>>>>
>>>>>>>>> I must admit that I have never built the vignettes manually, and I
>>>>>>>>> cannot find a hint how I can do it from the command line. Is this
>>>>>>>>> possible?
>>>>>>> Is it possible to build the vignettes from the command line?
>>>>>> R --help suggests there is
>>>>>> R CMD Sweave .....
>>>>>>
>>>>>>
>>>>>>>>> However, building the vignettes within R-2.13.0 I get:
>>>>>>>>>> library(tools)
>>>>>>>>>> buildVignettes("xps", dir="/Volumes/CoreData/CRAN/xps", quiet=F)
>>>>>>>>> Overfull \vbox (21.68121pt too high) has occurred while \output is
>>>>>>>>> Writing to file xps.tex
>>>>>>>>> Processing code chunks with options ...
>>>>>>>>> 1 : term verbatim
>>>>>>>>> 2 : echo term hide
>>>>>>>>> 3 : echo term verbatim
>>>>>>>>> 4 : echo term verbatim
>>>>>>>>> 5 : echo term verbatim
>>>>>>>>> SysError in<TFile::TFile>: file
>>>>>>>>> /tmpdt_DataTest3_cel.root/tmpdt_DataTest3_cel_20110424_201301.root
>>>>>>>>> can
>>>>>>>>> not be opened (No such file or directory)
>>>>>>>>> Error: Could not create file</tmpdt_DataTest3_cel.root>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>> Here are the two important chunks 4 and 5, which work fine with
>>>>>>>>> R-2.12.2
>>>>>>>>> and earlier versions:
>>>>>>>>>
>>>>>>>>> ###################################################
>>>>>>>>> ### chunk number 4:
>>>>>>>>> ###################################################
>>>>>>>>> #line 132 "xps.Rnw"
>>>>>>>>> scheme.test3<- root.scheme(file.path(.path.package("xps"),
>>>>>>>>> "schemes",
>>>>>>>>> "SchemeTest3.root"))
>>>>>>>>>
>>>>>>>>>
>>>>>>>>> ###################################################
>>>>>>>>> ### chunk number 5:
>>>>>>>>> ###################################################
>>>>>>>>> #line 137 "xps.Rnw"
>>>>>>>>> celfiles<- c("TestA1.CEL","TestA2.CEL")
>>>>>>>>> data.test3<- import.data(scheme.test3, "tmpdt_DataTest3",
>>>>>>>>> celdir=celdir, celfiles=celfiles, verbose=FALSE)
>>>>>>>>>
>>>>>>>>>
>>>>>>>>> However, in R-2.13.0 chunk 5 crashes!!!
>>>>>>>>> It works only when replacing chunk 5 with:
>>>>>>>>>
>>>>>>>>> ###################################################
>>>>>>>>> ### chunk number 5:
>>>>>>>>> ###################################################
>>>>>>>>> #line 137 "xps.Rnw"
>>>>>>>>> celfiles<- c("TestA1.CEL","TestA2.CEL")
>>>>>>>>> scheme.test3<- root.scheme(file.path(.path.package("xps"),
>>>>>>>>> "schemes",
>>>>>>>>> "SchemeTest3.root"))
>>>>>>>>> data.test3<- import.data(scheme.test3, "tmpdt_DataTest3",
>>>>>>>>> celdir=celdir, celfiles=celfiles, verbose=FALSE)
>>>>>>>>>
>>>>>>>>>
>>>>>>>>> As you see R-2.13.0 does no longer remember the result of chunk 4,
>>>>>>>>> i.e.
>>>>>>>>> "scheme.test3". Now I have to include the line defining
>>>>>>>>> "scheme.test3"
>>>>>>>>> also in chunk 5.
>>>>>>>> How objects generated in one chunk can be reused later on is
>>>>>>>> explained
>>>>>>>> in the Sweave manual.
>>>>>>>>
>>>>>>>>
>>>>>>>>> Do you have any idea for this behavior?
>>>>>>>>>
>>>>>>>>>
>>>>>>>>> An example, which does work in R-2.13.0 are the following two
>>>>>>>>> chunks:
>>>>>>>>>
>>>>>>>>> #################################################
>>>>>>>>> ### chunk number 20:
>>>>>>>>> ###################################################
>>>>>>>>> #line 300 "xps.Rnw"
>>>>>>>>> library(xps)
>>>>>>>>> scheme.test3<- root.scheme(file.path(.path.package("xps"),
>>>>>>>>> "schemes",
>>>>>>>>> "SchemeTest3.root"))
>>>>>>>>> data.test3<- root.data(scheme.test3,
>>>>>>>>> file.path(.path.package("xps"),"rootdata", "DataTest3_cel.root"))
>>>>>>>>>
>>>>>>>>>
>>>>>>>>> ###################################################
>>>>>>>>> ### chunk number 21:
>>>>>>>>> ###################################################
>>>>>>>>> #line 318 "xps.Rnw"
>>>>>>>>> data.rma<- rma(data.test3, "tmpdt_Test3RMA", verbose=FALSE)
>>>>>>>>>
>>>>>>>>>
>>>>>>>>> In summary it is not quite clear to me what has changed in
>>>>>>>>> R-2.13.0 so
>>>>>>>>> that chunk 5 no longer works.
>>>>>>>>>
>>>>>>>>> BTW, the error:
>>>>>>>>> SysError in<TFile::TFile>: file
>>>>>>>>> /tmpdt_DataTest3_cel.root/tmpdt_DataTest3_cel_20110424_201301.root
>>>>>>>>> can
>>>>>>>>> not be opened
>>>>>>>>> is not clear to me since "/tmpdt_DataTest3_cel.root/" is
>>>>>>>>> definitively
>>>>>>>>> NOT a directory.
>>>>>>>> Time to debug what root.scheme is doing with the supplied path.
>>>>>>>>
>>>>>>> Sorry, I do not understand what you mean. root.scheme does not change
>>>>>>> the path, otherwise it would not work on all older versions of R.
>>>>>> Right, but since something changed obviously, and you tell us the path
>>>>>> is not a path, it might be a function used by root.scheme .... That's
>>>>>> why I said time to debug the code in your vignette!
>>>>>>
>>>>>>
>>>>>>
>>>>>>>>> Do you have any ideas?
>>>>>>>>>
>>>>>>>>> Please note that the vignette "xps.Rnw" did work for the last two
>>>>>>>>> years
>>>>>>>>> w/o problem. Furthermore, the Bioconductor servers are able to
>>>>>>>>> build
>>>>>>>>> the
>>>>>>>>> vignette, see:
>>>>>>>>> http://www.bioconductor.org/packages/release/bioc/html/xps.html
>>>>>>>> See
>>>>>>>> http://bioconductor.org/checkResults/2.8/bioc-20110225/xps/liverpool-checksrc.html
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>> and find that their Mac Servers are also fine with it. So maybe
>>>>>>>> it is
>>>>>>>> your setup that is corrupted?
>>>>>>> Maybe, you are right that my setup is corrupted, but on two
>>>>>>> independent
>>>>>>> machines?
>>>>>>>
>>>>>>> Maybe the download of "R-2.13.0.pkg" is corrupted, but then nothing
>>>>>>> should work, or am I wrong?
>>>>>>>
>>>>>>> How can I check if my setup is corrupted?
>>>>>> By debugging the code in your package's vignette.
>>>>>>
>>>>>> Uwe Ligges
>>>>>>
>>>>>>
>>>>>>
>>>>>>> Best regards
>>>>>>> Christian
>>>>>>>
>>>>>>>> Best wishes,
>>>>>>>> Uwe
>>>>>>>>
>>>>>>>>> Best regards
>>>>>>>>> Christian
>>>>>>>>>
>>>>>>>>>
>>>>>>>>> On 4/24/11 4:12 PM, Uwe Ligges wrote:
>>>>>>>>>> On 23.04.2011 21:50, cstrato wrote:
>>>>>>>>>>> Dear all,
>>>>>>>>>>>
>>>>>>>>>>> While R CMD check and R CMD INSTALL have always created the
>>>>>>>>>>> vignettes on
>>>>>>>>>>> R-2.12.1 or any earlier versions of R, I am no longer able to
>>>>>>>>>>> build
>>>>>>>>>>> the
>>>>>>>>>>> vignettes on R-2.13.0.
>>>>>>>>>>>
>>>>>>>>>>> Instead R CMD check gives me the following output:
>>>>>>>>>>>
>>>>>>>>>>> * checking for unstated dependencies in vignettes ... OK
>>>>>>>>>>> * checking package vignettes in 'inst/doc' ... WARNING
>>>>>>>>>>> Package vignette(s) without corresponding PDF:
>>>>>>>>>>> APTvsXPS.Rnw
>>>>>>>>>>> xps.Rnw
>>>>>>>>>>> xpsClasses.Rnw
>>>>>>>>>>> xpsPreprocess.Rnw
>>>>>>>>>>>
>>>>>>>>>>> * checking running R code from vignettes ... OK
>>>>>>>>>>> * checking re-building of vignettes ... OK
>>>>>>>>>>> * checking PDF version of manual ... OK
>>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>>> Does someone know what the reason might be?
>>>>>>>>>> No, it does for me for other packages.
>>>>>>>>>> Perhaps an error when processing the vignettes? Have you tried to
>>>>>>>>>> build
>>>>>>>>>> them manually?
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>>> (R64 CMD check --help says that be default rebuild-vignettes is
>>>>>>>>>>> turned
>>>>>>>>>>> on.)
>>>>>>>>>>>
>>>>>>>>>>> Interestingly, R CMD check still creates the file
>>>>>>>>>>> "xps-manual.pdf".
>>>>>>>>>> That is the collection of help pages, unrelated to the vignette.
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>> Uwe Ligges
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>>> Here is my sessionInfo:
>>>>>>>>>>>
>>>>>>>>>>>> sessionInfo()
>>>>>>>>>>> R version 2.13.0 (2011-04-13)
>>>>>>>>>>> Platform: x86_64-apple-darwin9.8.0/x86_64 (64-bit)
>>>>>>>>>>>
>>>>>>>>>>> locale:
>>>>>>>>>>> [1] C
>>>>>>>>>>>
>>>>>>>>>>> attached base packages:
>>>>>>>>>>> [1] stats graphics grDevices utils datasets methods base
>>>>>>>>>>>
>>>>>>>>>>> other attached packages:
>>>>>>>>>>> [1] xps_1.13.1
>>>>>>>>>>>
>>>>>>>>>>> loaded via a namespace (and not attached):
>>>>>>>>>>> [1] Biobase_2.12.1 Biostrings_2.20.0 IRanges_1.10.0
>>>>>>>>>>> [4] affy_1.30.0 affyPLM_1.28.5 affyio_1.20.0
>>>>>>>>>>> [7] preprocessCore_1.14.0
>>>>>>>>>>>
>>>>>>>>>>> Thank you in advance.
>>>>>>>>>>> Best regards
>>>>>>>>>>> Christian
>>>>>>>>>>> _._._._._._._._._._._._._._._._._._
>>>>>>>>>>> C.h.r.i.s.t.i.a.n S.t.r.a.t.o.w.a
>>>>>>>>>>> V.i.e.n.n.a A.u.s.t.r.i.a
>>>>>>>>>>> e.m.a.i.l: cstrato at aon.at
>>>>>>>>>>> _._._._._._._._._._._._._._._._._._
>>>>>>>>>>>
>>>>>>>>>>> ______________________________________________
>>>>>>>>>>> R-devel at r-project.org mailing list
>>>>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>>>>>> ______________________________________________
>>>>>>>>> R-devel at r-project.org mailing list
>>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>> ______________________________________________
>>>>> R-devel at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>
>>
>>


From cstrato at aon.at  Mon Apr 25 21:43:10 2011
From: cstrato at aon.at (cstrato)
Date: Mon, 25 Apr 2011 21:43:10 +0200
Subject: [Rd] How to create vignette.pdf for R-2.13.0?
In-Reply-To: <4DB5CBFD.6050508@gmail.com>
References: <4DB32D9F.5010406@aon.at>	<4DB42FB3.9090401@statistik.tu-dortmund.de>	<4DB472F8.9060903@aon.at>	<4DB489EC.9080301@statistik.tu-dortmund.de>	<4DB491BE.8080104@aon.at>	<4DB57E7A.1080507@statistik.tu-dortmund.de>
	<4DB5AFD4.9020303@aon.at> <4DB5B6B0.90607@gmail.com>
	<4DB5C286.40306@aon.at> <4DB5C38D.6030400@gmail.com>
	<4DB5C87C.5040905@aon.at> <4DB5CBFD.6050508@gmail.com>
Message-ID: <4DB5CECE.9050709@aon.at>

Thank you, I will try. Christian


On 4/25/11 9:31 PM, Duncan Murdoch wrote:
> On 25/04/2011 3:16 PM, cstrato wrote:
>> Thank you.
>>
>> My problem seems to be that at the moment the problem can be seen only
>> on my Mac, since e.g. the Bioconductor servers have no problems creating
>> the vignettes.
>
> Then you are definitely the one in the best position to diagnose the
> problem. Use the usual approach: simplify it by cutting out everything
> that looks unrelated. Verify that the problem still exists, then cut
> some more. Eventually you'll have isolated the error to a particular
> small snippet of code, and then you can add print() statements, or use
> trace(), or do whatever is necessary to see what's so special about your
> system.
>
> I suspect it will turn out to be an assumption in the code that is not
> true on your system.
>
> If the assumption is being made by code you wrote, then fix it. If it's
> being made by R, let us know.
>
> Duncan Murdoch
>
>>
>> Best regards
>> Christian
>>
>> On 4/25/11 8:55 PM, Duncan Murdoch wrote:
>>> cstrato wrote:
>>>> Dear Duncan,
>>>>
>>>> Thank you for your example, however it is different since it does not
>>>> use x and y. What about print(x+y)?
>>>
>>> Try it.
>>>
>>>>
>>>> Sorry, I do not believe that there is a bug in my code, since:
>>>> 1, it worked in all versions from R starting with R-2.6.0 till
>>>> R-2.12.2.
>>>> 2, the identical code works in the examples
>>>> 3, this code (or a similar code) is the starting code which all users
>>>> of xps have to use, and there was never a problem.
>>>
>>> This might be a problem in R, or might be a problem in your code. As far
>>> as I know, it has only shown up in your code, so I'd guess that's where
>>> the problem is. In any case, you're the one in the best position to
>>> isolate it and debug it.
>>>
>>> If it turns out to be a problem in R, put together an example
>>> illustrating the problem that doesn't involve your code, and I'll take a
>>> look.
>>>
>>> Duncan Murdoch
>>>
>>>>
>>>> Maybe the reason could be that my code has to import
>>>> - the CEL-files from the package dir
>>>> - the file SchemeTest3.root from the package dir
>>>> ??
>>>>
>>>> Best regards
>>>> Christian
>>>>
>>>> On 4/25/11 8:00 PM, Duncan Murdoch wrote:
>>>>> cstrato wrote:
>>>>>> Dear Uwe,
>>>>>>
>>>>>> Your suggestion to look at the Sweave manual helped me to solve the
>>>>>> problem. It seems that in R-2.13.0 every chunk can use the code from
>>>>>> the chunk before but not from an earlier chunk.
>>>>> I'm either misreading what you wrote, or it's wrong. If I have this
>>>>> in a
>>>>> Sweave file:
>>>>>
>>>>> <<>>=
>>>>> x<- 1
>>>>> @
>>>>>
>>>>> <<>>=
>>>>> y<- 2
>>>>> @
>>>>>
>>>>> <<>>=
>>>>> print(x)
>>>>> @
>>>>>
>>>>> I will see the value of x getting printed, even though it came from
>>>>> two
>>>>> chunks earlier.
>>>>>
>>>>> I think Uwe is right: there is some bug in the code you're running.
>>>>> Sweave isn't the problem.
>>>>>
>>>>> Duncan Murdoch
>>>>>
>>>>>> Concretely, the following does not work since chunk 5 needs the code
>>>>>> from chunk 3 and 4:
>>>>>>
>>>>>> ###################################################
>>>>>> ### chunk number 3:
>>>>>> ###################################################
>>>>>> #line 126 "xps.Rnw"
>>>>>> celdir<- file.path(.path.package("xps"), "raw")
>>>>>>
>>>>>> ###################################################
>>>>>> ### chunk number 4:
>>>>>> ###################################################
>>>>>> #line 132 "xps.Rnw"
>>>>>> scheme.test3<- root.scheme(file.path(.path.package("xps"), "schemes",
>>>>>> "SchemeTest3.root"))
>>>>>>
>>>>>> ###################################################
>>>>>> ### chunk number 5:
>>>>>> ###################################################
>>>>>> #line 137 "xps.Rnw"
>>>>>> celfiles<- c("TestA1.CEL","TestA2.CEL")
>>>>>> data.test3<- import.data(scheme.test3, "tmpdt_DataTest3",
>>>>>> celdir=celdir, celfiles=celfiles, verbose=FALSE)
>>>>>>
>>>>>>
>>>>>> However, when I add "celdir" to chunk 5 then everything works since
>>>>>> now chunk 5 needs only the code from chunk 4 but not from chunk 3:
>>>>>>
>>>>>> ###################################################
>>>>>> ### chunk number 5:
>>>>>> ###################################################
>>>>>> #line 137 "xps.Rnw"
>>>>>> celdir<- file.path(.path.package("xps"), "raw")
>>>>>> celfiles<- c("TestA1.CEL","TestA2.CEL")
>>>>>> data.test3<- import.data(scheme.test3, "tmpdt_DataTest3",
>>>>>> celdir=celdir, celfiles=celfiles, verbose=FALSE)
>>>>>>
>>>>>>
>>>>>> Now buildVignettes() is able to create the vignettes, however R CMD
>>>>>> check still does not build the vignettes.
>>>>>>
>>>>>>
>>>>>> Yes, I get a Warning in both cases:
>>>>>> * checking package vignettes in 'inst/doc' ... WARNING
>>>>>> Package vignettes without corresponding PDF: ........
>>>>>>
>>>>>> However, with R-2.12.2 the following lines are added:
>>>>>>
>>>>>> /Volumes/CoreData/CRAN/xps.Rcheck/00_pkg_src/xps/inst/doc/APTvsXPS.Rnw
>>>>>>
>>>>>> /Volumes/CoreData/CRAN/xps.Rcheck/00_pkg_src/xps/inst/doc/xps.Rnw
>>>>>> /Volumes/CoreData/CRAN/xps.Rcheck/00_pkg_src/xps/inst/doc/xpsClasses.Rnw
>>>>>>
>>>>>>
>>>>>> /Volumes/CoreData/CRAN/xps.Rcheck/00_pkg_src/xps/inst/doc/xpsPreprocess.Rnw
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>> and in xps.Rcheck the subdirectory "inst/doc" will be created which
>>>>>> contains the vignette data such as xps.Rnw, but also xps.tex and
>>>>>> xps.pdf.
>>>>>>
>>>>>> In contrast, R-2.13.0 does not create the subdirectory "inst/doc" and
>>>>>> no vignettes are built.
>>>>>>
>>>>>> One more issue:
>>>>>> In contrast to my former believe R CMD INSTALL does not build the
>>>>>> vignettes, neither in R-2.12.2 nor in R-2.13.0. I have to run
>>>>>> buildVignettes() after installation. Is this the usual case?
>>>>>>
>>>>>> Best regards
>>>>>> Christian
>>>>>>
>>>>>>
>>>>>> On 4/25/11 4:00 PM, Uwe Ligges wrote:
>>>>>>> On 24.04.2011 23:10, cstrato wrote:
>>>>>>>> Dear Uwe,
>>>>>>>>
>>>>>>>> On 4/24/11 10:37 PM, Uwe Ligges wrote:
>>>>>>>>> On 24.04.2011 20:59, cstrato wrote:
>>>>>>>>>> Dear Uwe,
>>>>>>>>>>
>>>>>>>>>> Thank you for your reply.
>>>>>>>>>>
>>>>>>>>>> ad 2, Yes, i know that "xps-manual.pdf" is the collection of help
>>>>>>>>>> pages,
>>>>>>>>>> I have mentioned it only to show that creating pdf-files does
>>>>>>>>>> work
>>>>>>>>>> for
>>>>>>>>>> R-2.13.0.
>>>>>>>>>>
>>>>>>>>>> ad 1, Could it be that this is a Mac-specific problem since I see
>>>>>>>>>> it on
>>>>>>>>>> both my old MacBook Pro and my new Mac Mini.
>>>>>>>>> Have you tried on any other OS? I did not since installing root is
>>>>>>>>> a bit
>>>>>>>>> too much effort.
>>>>>>>>>
>>>>>>>>>
>>>>>>>> No, until now I did not try another OS, but I will, since xps
>>>>>>>> has to
>>>>>>>> work on all three OSes.
>>>>>>>>
>>>>>>>>>> Using R CMD check with R-2.12.2 I get:
>>>>>>>>> I thought we are talking about R-2.13.0?
>>>>>>>>>
>>>>>>>> I showed you the output of R-2.12.2 first and then the output of
>>>>>>>> R-2.13.0, so that you can see that on the same machine with the
>>>>>>>> same
>>>>>>>> file it works with one version but not the other.
>>>>>>> But you got a Warning in both cases:
>>>>>>> * checking package vignettes in 'inst/doc' ... WARNING
>>>>>>> Package vignettes without corresponding PDF: ........
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>>> Where is the R CMD build output (since R CMD build is supposed to
>>>>>>>>> prepare the vignette).
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>> $ R64 CMD check xps_1.13.1.tar.gz
>>>>>>>>>> * using log directory '/Volumes/CoreData/CRAN/xps.Rcheck'
>>>>>>>>>> * using R version 2.12.2 (2011-02-25)
>>>>>>>>>> * using platform: x86_64-apple-darwin9.8.0 (64-bit)
>>>>>>>>>> * using session charset: ASCII
>>>>>>>>>> * checking for file 'xps/DESCRIPTION' ... OK
>>>>>>>>>> * this is package 'xps' version '1.13.1'
>>>>>>>>>> ...
>>>>>>>>>> ...
>>>>>>>>>> * checking package vignettes in 'inst/doc' ... WARNING
>>>>>>>>>> Package vignettes without corresponding PDF:
>>>>>>>>>>
>>>>>>>>>> /Volumes/CoreData/CRAN/xps.Rcheck/00_pkg_src/xps/inst/doc/APTvsXPS.Rnw
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>> /Volumes/CoreData/CRAN/xps.Rcheck/00_pkg_src/xps/inst/doc/xps.Rnw
>>>>>>>>>> /Volumes/CoreData/CRAN/xps.Rcheck/00_pkg_src/xps/inst/doc/xpsClasses.Rnw
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>> /Volumes/CoreData/CRAN/xps.Rcheck/00_pkg_src/xps/inst/doc/xpsPreprocess.Rnw
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>> * checking PDF version of manual ... OK
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>> Using "RSwitch.app" I switch to R-2.13.0, but now I get:
>>>>>>>>>>
>>>>>>>>>> $ R64 CMD check xps_1.13.1.tar.gz
>>>>>>>>>> * using log directory '/Volumes/CoreData/CRAN/xps.Rcheck'
>>>>>>>>>> * using R version 2.13.0 (2011-04-13)
>>>>>>>>>> * using platform: x86_64-apple-darwin9.8.0 (64-bit)
>>>>>>>>>> * using session charset: ASCII
>>>>>>>>>> * checking for file 'xps/DESCRIPTION' ... OK
>>>>>>>>>> * this is package 'xps' version '1.13.1'
>>>>>>>>>> ...
>>>>>>>>>> ...
>>>>>>>>>> * checking package vignettes in 'inst/doc' ... WARNING
>>>>>>>>>> Package vignette(s) without corresponding PDF:
>>>>>>>>>> APTvsXPS.Rnw
>>>>>>>>>> xps.Rnw
>>>>>>>>>> xpsClasses.Rnw
>>>>>>>>>> xpsPreprocess.Rnw
>>>>>>>>>>
>>>>>>>>>> * checking running R code from vignettes ... OK
>>>>>>>>>> * checking re-building of vignettes ... OK
>>>>>>>>>> * checking PDF version of manual ... OK
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>> I must admit that I have never built the vignettes manually,
>>>>>>>>>> and I
>>>>>>>>>> cannot find a hint how I can do it from the command line. Is this
>>>>>>>>>> possible?
>>>>>>>> Is it possible to build the vignettes from the command line?
>>>>>>> R --help suggests there is
>>>>>>> R CMD Sweave .....
>>>>>>>
>>>>>>>
>>>>>>>>>> However, building the vignettes within R-2.13.0 I get:
>>>>>>>>>>> library(tools)
>>>>>>>>>>> buildVignettes("xps", dir="/Volumes/CoreData/CRAN/xps", quiet=F)
>>>>>>>>>> Overfull \vbox (21.68121pt too high) has occurred while
>>>>>>>>>> \output is
>>>>>>>>>> Writing to file xps.tex
>>>>>>>>>> Processing code chunks with options ...
>>>>>>>>>> 1 : term verbatim
>>>>>>>>>> 2 : echo term hide
>>>>>>>>>> 3 : echo term verbatim
>>>>>>>>>> 4 : echo term verbatim
>>>>>>>>>> 5 : echo term verbatim
>>>>>>>>>> SysError in<TFile::TFile>: file
>>>>>>>>>> /tmpdt_DataTest3_cel.root/tmpdt_DataTest3_cel_20110424_201301.root
>>>>>>>>>>
>>>>>>>>>> can
>>>>>>>>>> not be opened (No such file or directory)
>>>>>>>>>> Error: Could not create file</tmpdt_DataTest3_cel.root>
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>> Here are the two important chunks 4 and 5, which work fine with
>>>>>>>>>> R-2.12.2
>>>>>>>>>> and earlier versions:
>>>>>>>>>>
>>>>>>>>>> ###################################################
>>>>>>>>>> ### chunk number 4:
>>>>>>>>>> ###################################################
>>>>>>>>>> #line 132 "xps.Rnw"
>>>>>>>>>> scheme.test3<- root.scheme(file.path(.path.package("xps"),
>>>>>>>>>> "schemes",
>>>>>>>>>> "SchemeTest3.root"))
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>> ###################################################
>>>>>>>>>> ### chunk number 5:
>>>>>>>>>> ###################################################
>>>>>>>>>> #line 137 "xps.Rnw"
>>>>>>>>>> celfiles<- c("TestA1.CEL","TestA2.CEL")
>>>>>>>>>> data.test3<- import.data(scheme.test3, "tmpdt_DataTest3",
>>>>>>>>>> celdir=celdir, celfiles=celfiles, verbose=FALSE)
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>> However, in R-2.13.0 chunk 5 crashes!!!
>>>>>>>>>> It works only when replacing chunk 5 with:
>>>>>>>>>>
>>>>>>>>>> ###################################################
>>>>>>>>>> ### chunk number 5:
>>>>>>>>>> ###################################################
>>>>>>>>>> #line 137 "xps.Rnw"
>>>>>>>>>> celfiles<- c("TestA1.CEL","TestA2.CEL")
>>>>>>>>>> scheme.test3<- root.scheme(file.path(.path.package("xps"),
>>>>>>>>>> "schemes",
>>>>>>>>>> "SchemeTest3.root"))
>>>>>>>>>> data.test3<- import.data(scheme.test3, "tmpdt_DataTest3",
>>>>>>>>>> celdir=celdir, celfiles=celfiles, verbose=FALSE)
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>> As you see R-2.13.0 does no longer remember the result of
>>>>>>>>>> chunk 4,
>>>>>>>>>> i.e.
>>>>>>>>>> "scheme.test3". Now I have to include the line defining
>>>>>>>>>> "scheme.test3"
>>>>>>>>>> also in chunk 5.
>>>>>>>>> How objects generated in one chunk can be reused later on is
>>>>>>>>> explained
>>>>>>>>> in the Sweave manual.
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>> Do you have any idea for this behavior?
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>> An example, which does work in R-2.13.0 are the following two
>>>>>>>>>> chunks:
>>>>>>>>>>
>>>>>>>>>> #################################################
>>>>>>>>>> ### chunk number 20:
>>>>>>>>>> ###################################################
>>>>>>>>>> #line 300 "xps.Rnw"
>>>>>>>>>> library(xps)
>>>>>>>>>> scheme.test3<- root.scheme(file.path(.path.package("xps"),
>>>>>>>>>> "schemes",
>>>>>>>>>> "SchemeTest3.root"))
>>>>>>>>>> data.test3<- root.data(scheme.test3,
>>>>>>>>>> file.path(.path.package("xps"),"rootdata", "DataTest3_cel.root"))
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>> ###################################################
>>>>>>>>>> ### chunk number 21:
>>>>>>>>>> ###################################################
>>>>>>>>>> #line 318 "xps.Rnw"
>>>>>>>>>> data.rma<- rma(data.test3, "tmpdt_Test3RMA", verbose=FALSE)
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>> In summary it is not quite clear to me what has changed in
>>>>>>>>>> R-2.13.0 so
>>>>>>>>>> that chunk 5 no longer works.
>>>>>>>>>>
>>>>>>>>>> BTW, the error:
>>>>>>>>>> SysError in<TFile::TFile>: file
>>>>>>>>>> /tmpdt_DataTest3_cel.root/tmpdt_DataTest3_cel_20110424_201301.root
>>>>>>>>>>
>>>>>>>>>> can
>>>>>>>>>> not be opened
>>>>>>>>>> is not clear to me since "/tmpdt_DataTest3_cel.root/" is
>>>>>>>>>> definitively
>>>>>>>>>> NOT a directory.
>>>>>>>>> Time to debug what root.scheme is doing with the supplied path.
>>>>>>>>>
>>>>>>>> Sorry, I do not understand what you mean. root.scheme does not
>>>>>>>> change
>>>>>>>> the path, otherwise it would not work on all older versions of R.
>>>>>>> Right, but since something changed obviously, and you tell us the
>>>>>>> path
>>>>>>> is not a path, it might be a function used by root.scheme ....
>>>>>>> That's
>>>>>>> why I said time to debug the code in your vignette!
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>>>> Do you have any ideas?
>>>>>>>>>>
>>>>>>>>>> Please note that the vignette "xps.Rnw" did work for the last two
>>>>>>>>>> years
>>>>>>>>>> w/o problem. Furthermore, the Bioconductor servers are able to
>>>>>>>>>> build
>>>>>>>>>> the
>>>>>>>>>> vignette, see:
>>>>>>>>>> http://www.bioconductor.org/packages/release/bioc/html/xps.html
>>>>>>>>> See
>>>>>>>>> http://bioconductor.org/checkResults/2.8/bioc-20110225/xps/liverpool-checksrc.html
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>> and find that their Mac Servers are also fine with it. So maybe
>>>>>>>>> it is
>>>>>>>>> your setup that is corrupted?
>>>>>>>> Maybe, you are right that my setup is corrupted, but on two
>>>>>>>> independent
>>>>>>>> machines?
>>>>>>>>
>>>>>>>> Maybe the download of "R-2.13.0.pkg" is corrupted, but then nothing
>>>>>>>> should work, or am I wrong?
>>>>>>>>
>>>>>>>> How can I check if my setup is corrupted?
>>>>>>> By debugging the code in your package's vignette.
>>>>>>>
>>>>>>> Uwe Ligges
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>> Best regards
>>>>>>>> Christian
>>>>>>>>
>>>>>>>>> Best wishes,
>>>>>>>>> Uwe
>>>>>>>>>
>>>>>>>>>> Best regards
>>>>>>>>>> Christian
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>> On 4/24/11 4:12 PM, Uwe Ligges wrote:
>>>>>>>>>>> On 23.04.2011 21:50, cstrato wrote:
>>>>>>>>>>>> Dear all,
>>>>>>>>>>>>
>>>>>>>>>>>> While R CMD check and R CMD INSTALL have always created the
>>>>>>>>>>>> vignettes on
>>>>>>>>>>>> R-2.12.1 or any earlier versions of R, I am no longer able to
>>>>>>>>>>>> build
>>>>>>>>>>>> the
>>>>>>>>>>>> vignettes on R-2.13.0.
>>>>>>>>>>>>
>>>>>>>>>>>> Instead R CMD check gives me the following output:
>>>>>>>>>>>>
>>>>>>>>>>>> * checking for unstated dependencies in vignettes ... OK
>>>>>>>>>>>> * checking package vignettes in 'inst/doc' ... WARNING
>>>>>>>>>>>> Package vignette(s) without corresponding PDF:
>>>>>>>>>>>> APTvsXPS.Rnw
>>>>>>>>>>>> xps.Rnw
>>>>>>>>>>>> xpsClasses.Rnw
>>>>>>>>>>>> xpsPreprocess.Rnw
>>>>>>>>>>>>
>>>>>>>>>>>> * checking running R code from vignettes ... OK
>>>>>>>>>>>> * checking re-building of vignettes ... OK
>>>>>>>>>>>> * checking PDF version of manual ... OK
>>>>>>>>>>>>
>>>>>>>>>>>>
>>>>>>>>>>>> Does someone know what the reason might be?
>>>>>>>>>>> No, it does for me for other packages.
>>>>>>>>>>> Perhaps an error when processing the vignettes? Have you
>>>>>>>>>>> tried to
>>>>>>>>>>> build
>>>>>>>>>>> them manually?
>>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>>>> (R64 CMD check --help says that be default rebuild-vignettes is
>>>>>>>>>>>> turned
>>>>>>>>>>>> on.)
>>>>>>>>>>>>
>>>>>>>>>>>> Interestingly, R CMD check still creates the file
>>>>>>>>>>>> "xps-manual.pdf".
>>>>>>>>>>> That is the collection of help pages, unrelated to the vignette.
>>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>>> Uwe Ligges
>>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>>>> Here is my sessionInfo:
>>>>>>>>>>>>
>>>>>>>>>>>>> sessionInfo()
>>>>>>>>>>>> R version 2.13.0 (2011-04-13)
>>>>>>>>>>>> Platform: x86_64-apple-darwin9.8.0/x86_64 (64-bit)
>>>>>>>>>>>>
>>>>>>>>>>>> locale:
>>>>>>>>>>>> [1] C
>>>>>>>>>>>>
>>>>>>>>>>>> attached base packages:
>>>>>>>>>>>> [1] stats graphics grDevices utils datasets methods base
>>>>>>>>>>>>
>>>>>>>>>>>> other attached packages:
>>>>>>>>>>>> [1] xps_1.13.1
>>>>>>>>>>>>
>>>>>>>>>>>> loaded via a namespace (and not attached):
>>>>>>>>>>>> [1] Biobase_2.12.1 Biostrings_2.20.0 IRanges_1.10.0
>>>>>>>>>>>> [4] affy_1.30.0 affyPLM_1.28.5 affyio_1.20.0
>>>>>>>>>>>> [7] preprocessCore_1.14.0
>>>>>>>>>>>>
>>>>>>>>>>>> Thank you in advance.
>>>>>>>>>>>> Best regards
>>>>>>>>>>>> Christian
>>>>>>>>>>>> _._._._._._._._._._._._._._._._._._
>>>>>>>>>>>> C.h.r.i.s.t.i.a.n S.t.r.a.t.o.w.a
>>>>>>>>>>>> V.i.e.n.n.a A.u.s.t.r.i.a
>>>>>>>>>>>> e.m.a.i.l: cstrato at aon.at
>>>>>>>>>>>> _._._._._._._._._._._._._._._._._._
>>>>>>>>>>>>
>>>>>>>>>>>> ______________________________________________
>>>>>>>>>>>> R-devel at r-project.org mailing list
>>>>>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>>>>>>> ______________________________________________
>>>>>>>>>> R-devel at r-project.org mailing list
>>>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>>> ______________________________________________
>>>>>> R-devel at r-project.org mailing list
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>>
>>>
>>>
>
>


From schattenpflanze at arcor.de  Mon Apr 25 17:09:08 2011
From: schattenpflanze at arcor.de (schattenpflanze at arcor.de)
Date: Mon, 25 Apr 2011 17:09:08 +0200
Subject: [Rd] Interrupting C++ code execution
In-Reply-To: <2682842C-1B14-4C32-9D68-F608937C1074@r-project.org>
References: <4DB53D47.7060903@arcor.de>
	<2682842C-1B14-4C32-9D68-F608937C1074@r-project.org>
Message-ID: <4DB58E94.8050304@arcor.de>

Thank you for your response, Simon.

>> 1. Calling R_CheckUserInterrupt() interrupts immediately, so I have
>> no possibility to exit my code gracefully. In particular, I suppose
>> that objects created on the heap (e.g., STL containers) are not
>> destructed properly.
> In general, you're responsible for the cleanup. See R-devel archives
> for discussion on the interactions of C++ and R error handling.
> Generally, you should not use local objects and you should use
> on.exit to make sure you clean up.
I am using Rcpp (Rcpp-modules, to be precise). This means, I do actually 
not write any R code. Moreover, the C++ code does not use the R API. My 
C++ functions are 'exposed' to R via Rcpp, which creates suitable S4 
classes. Rcpp does the exception handling.
In particular, there is no obvious possibility for me to add an 
'on.exit' statement to a particular exposed C++ method.

> Generally, you should not use local objects
We are talking about large amounts of code, dozens of nested function 
calls, and even external libraries. So "not using local objects" is 
definitely no option.

>> 2. Calling R_CheckUserInterrupt() within a parallel OpenMP loop
>> causes memory corruptions. Even if I do so within a critical
>> section, it usually results in segfaults, crashes, or invalid
>> variable contents afterwards. I suppose this is due to the threads
>> not being destroyed properly. Since most of the time critical
>> computations are done in parallel, this means I can hardly
>> interrupt anything.
> As you know R is not thread-safe so you cannot call any R API from a
> thread - including OMP threads - so obviously you can't call
> R_CheckUserInterrupt().
That is very interesting. Not being thread safe does not necessarily 
imply that a function cannot be called from within a thread (as long as 
it is not done concurrently from several threads). In particular, the 
main program itself is also a thread, isn't it?
Since no cleanup is done, however, it is now clear that calling 
R_CheckUserInterrupt() _anywhere_ in my program, parallel section or 
not, is a bad idea.

> Since you're using threads the safe way is to
> perform your computations on a separate thread and let R handle
> events so that you can abort your computation thread as part of
> on.exit.
Starting the computations in a separate thread is a nice idea. I could 
then call R_CheckUserInterrupt() every x milliseconds in the function 
which dispatches the worker thread. Unfortunately, I see no obvious way 
of adding an "on.exit" statement to an Rcpp module method. So I would 
probably have to call an R function from C++ (e.g., using RInside) which 
contains the on.exit statement, which in turn calls again a C++ function 
setting a global 'abort' flag and waits for the threads to be 
terminated. Hmmm.

How does on.exit work? Could I mimic that behaviour directly in C++?

>> Having a function similar to R_CheckUserInterrupt() but returning a
>> boolean variable (has an interrupt occurred or not?) would solve
>> these problems. Is there a way to find out about user interrupt
>> requests (the user pressing ctrl+c or maybe a different set of
>> keys) without interrupting immediately?
> Checking for interrupts may involve running the OS event loop (to
> allow the user to interact with R) and thus is not guaranteed to
> return.
I see.

> There is no general solution - if you're worried only about
> your, local code, then on unix, for example, you could use custom
> signal handlers to set a flag and co-operatively interrupt your
> program. On Windows there is the UserBreak flag which can be set by a
> separate thread and thus you may check on it. That said, all this is
> very much platform-specific.
Being able to set a flag is all I need and would be the perfect solution 
imho. However, I do not yet see how I could achieve that.

How can I write a signal handler within C++ code which does not create a 
GUI and has no dedicated event dispatching thread?
Would it be possible to use, e.g., a Qt keyboard event handler within 
the C++ code? Would a keyboard event be visible to such an event 
handler? Is it not intercepted by R / the terminal window / the OS?

Does any existing R package contain signal handlers?


Best regards,
Peter


From schattenpflanze at arcor.de  Mon Apr 25 19:44:34 2011
From: schattenpflanze at arcor.de (schattenpflanze at arcor.de)
Date: Mon, 25 Apr 2011 19:44:34 +0200
Subject: [Rd] Interrupting C++ code execution
In-Reply-To: <F1EAEEC8-7828-403F-BF2D-10A4F925B4E6@r-project.org>
References: <4DB53D47.7060903@arcor.de>
	<2682842C-1B14-4C32-9D68-F608937C1074@r-project.org>
	<4DB58E94.8050304@arcor.de>
	<85607CA7-D76F-4210-9C6E-F3E9F26F7D0E@r-project.org>
	<F1EAEEC8-7828-403F-BF2D-10A4F925B4E6@r-project.org>
Message-ID: <4DB5B302.9090800@arcor.de>

Dear Simon,

thanks again for your explanations. Your previous e-mail clarified 
several points for me.

> Actually, it just came to me that there is a hack you could use. [...]
That actually looks quite nice. At least when compared to my currently 
only alternative of not interrupting at all. I will test it, in 
particular with respect to computational speed. Perhaps I can at least 
call it once per second.

Best regards,
Peter


> The
> problem with it is that it will eat all errors, even if they were not
> yours (e.g. those resulting from events triggered the event loop), so
> I would not recommend it for general use. But here we go:
>
> static void chkIntFn(void *dummy) { R_CheckUserInterrupt(); }
>
> // this will call the above in a top-level context so it won't
> longjmp-out of your context bool checkInterrupt() { return
> (R_ToplevelExec(chkIntFn, NULL) == FALSE); }
>
> // your code somewhere ... if (checkInterrupt()) { // user
> interrupted ... }
>
> You must call it on the main thread and you should be prepared that
> it may take some time and may interact with the OS...
>
> Cheers, Simon
>
>
> On Apr 25, 2011, at 12:23 PM, Simon Urbanek wrote:
>
>>
>> On Apr 25, 2011, at 11:09 AM, schattenpflanze at arcor.de wrote:
>>
>>> Thank you for your response, Simon.
>>>
>>>>> 1. Calling R_CheckUserInterrupt() interrupts immediately, so
>>>>> I have no possibility to exit my code gracefully. In
>>>>> particular, I suppose that objects created on the heap (e.g.,
>>>>> STL containers) are not destructed properly.
>>>> In general, you're responsible for the cleanup. See R-devel
>>>> archives for discussion on the interactions of C++ and R error
>>>> handling. Generally, you should not use local objects and you
>>>> should use on.exit to make sure you clean up.
>>> I am using Rcpp (Rcpp-modules, to be precise). This means, I do
>>> actually not write any R code. Moreover, the C++ code does not
>>> use the R API. My C++ functions are 'exposed' to R via Rcpp,
>>> which creates suitable S4 classes. Rcpp does the exception
>>> handling. In particular, there is no obvious possibility for me
>>> to add an 'on.exit' statement to a particular exposed C++
>>> method.
>>>
>>>> Generally, you should not use local objects
>>> We are talking about large amounts of code, dozens of nested
>>> function calls, and even external libraries. So "not using local
>>> objects" is definitely no option.
>>>
>>
>> But that would imply that the library calls R! Note that we're
>> talking about the stack at the point of R API call, so you can do
>> what you want until you cal R API. At the moment you touch R API
>> you should have no local C++ objects on the stack (all the way
>> down) - that's what I meant.
>>
>>
>>>>> 2. Calling R_CheckUserInterrupt() within a parallel OpenMP
>>>>> loop causes memory corruptions. Even if I do so within a
>>>>> critical section, it usually results in segfaults, crashes,
>>>>> or invalid variable contents afterwards. I suppose this is
>>>>> due to the threads not being destroyed properly. Since most
>>>>> of the time critical computations are done in parallel, this
>>>>> means I can hardly interrupt anything.
>>>> As you know R is not thread-safe so you cannot call any R API
>>>> from a thread - including OMP threads - so obviously you can't
>>>> call R_CheckUserInterrupt().
>>> That is very interesting. Not being thread safe does not
>>> necessarily imply that a function cannot be called from within a
>>> thread (as long as it is not done concurrently from several
>>> threads). In particular, the main program itself is also a
>>> thread, isn't it?
>>
>> Yes, but each thread has a separate stack, and you can only enter R
>> with the same stack you left (because the stack will be restored to
>> the state of the calling context).
>>
>>
>>> Since no cleanup is done, however, it is now clear that calling
>>> R_CheckUserInterrupt() _anywhere_ in my program, parallel section
>>> or not, is a bad idea.
>>>
>>>> Since you're using threads the safe way is to perform your
>>>> computations on a separate thread and let R handle events so
>>>> that you can abort your computation thread as part of on.exit.
>>> Starting the computations in a separate thread is a nice idea. I
>>> could then call R_CheckUserInterrupt() every x milliseconds in
>>> the function which dispatches the worker thread. Unfortunately, I
>>> see no obvious way of adding an "on.exit" statement to an Rcpp
>>> module method. So I would probably have to call an R function
>>> from C++ (e.g., using RInside) which contains the on.exit
>>> statement, which in turn calls again a C++ function setting a
>>> global 'abort' flag and waits for the threads to be terminated.
>>> Hmmm.
>>>
>>> How does on.exit work?
>>
>> It sets the conexit object of the current context structure to the
>> closure to be evaluated when the context is left. endcontext() then
>> simply evaluates that closure when the context is left.
>>
>>
>>> Could I mimic that behaviour directly in C++?
>>>
>>
>> Unfortunately there is no C-level onexit hook and the internal
>> structure of RCNTXT is not revealed to packages. So AFAICS the
>> closest you can get is to use eval to call on.exit().
>>
>> However, I think it would be useful to have a provision for
>> creating a context with a C-level hook - the question is whether
>> the others have the feeling that it's going to a too low level ...
>>
>>
>>>>> Having a function similar to R_CheckUserInterrupt() but
>>>>> returning a boolean variable (has an interrupt occurred or
>>>>> not?) would solve these problems. Is there a way to find out
>>>>> about user interrupt requests (the user pressing ctrl+c or
>>>>> maybe a different set of keys) without interrupting
>>>>> immediately?
>>>> Checking for interrupts may involve running the OS event loop
>>>> (to allow the user to interact with R) and thus is not
>>>> guaranteed to return.
>>> I see.
>>>
>>>> There is no general solution - if you're worried only about
>>>> your, local code, then on unix, for example, you could use
>>>> custom signal handlers to set a flag and co-operatively
>>>> interrupt your program. On Windows there is the UserBreak flag
>>>> which can be set by a separate thread and thus you may check on
>>>> it. That said, all this is very much platform-specific.
>>> Being able to set a flag is all I need and would be the perfect
>>> solution imho. However, I do not yet see how I could achieve
>>> that.
>>>
>>
>> It is GUI-specific, unfortunately. AFAIR the Windows GUI does that
>> because it's running on a separate thread. I think the X11-based
>> GUIs use fds so the are synchronous and on OS X runs the OS loop
>> inside the R event loop - so, again, synchronous.
>>
>>
>>> How can I write a signal handler within C++ code which does not
>>> create a GUI and has no dedicated event dispatching thread?
>>
>> That's simple just use signal() to register your handler.
>>
>>
>>> Would it be possible to use, e.g., a Qt keyboard event handler
>>> within the C++ code? Would a keyboard event be visible to such an
>>> event handler? Is it not intercepted by R / the terminal window /
>>> the OS?
>>>
>>
>> Meshing R's loop, GUI loop and your own code will be a nightmare.
>> For example, one problem is that if you are running the GUI loop
>> and it triggers an event that R would otherwise handle (e.g.
>> resizing plot window) you're in trouble since you can't let R do
>> anything...
>>
>>
>>> Does any existing R package contain signal handlers?
>>>
>>
>> I'm not sure - I would definitely not recommend that to be used in
>> packages since it's platform-dependent and changes the semantics of
>> signals defined by R. But you can play with it ;).
>>
>> Cheers, Simo


From schattenpflanze at arcor.de  Tue Apr 26 13:30:19 2011
From: schattenpflanze at arcor.de (schattenpflanze at arcor.de)
Date: Tue, 26 Apr 2011 13:30:19 +0200
Subject: [Rd] Interrupting C++ code execution
In-Reply-To: <201104252018.01541.thomas.friedrichsmeier@ruhr-uni-bochum.de>
References: <4DB53D47.7060903@arcor.de>
	<85607CA7-D76F-4210-9C6E-F3E9F26F7D0E@r-project.org>
	<F1EAEEC8-7828-403F-BF2D-10A4F925B4E6@r-project.org>
	<201104252018.01541.thomas.friedrichsmeier@ruhr-uni-bochum.de>
Message-ID: <4DB6ACCB.8050606@arcor.de>

I have tested the solutions suggested by Simon and Thomas on a Linux 
machine. These are my findings:

> On Windows you can look at the variable "UserBreak", available from
> Rembedded.h. Outside of Windows, you can look at R_interrupts_pending,
> available from R_ext/GraphicsDevice.h. R_ext/GraphicsDevice.h also has
> R_interrupts_suspended, which you may or may not want to take into account,
> depending on your use-case.
I did not manage to get this to work. Neither R_interrupts_pending nor 
R_interrupts_suspended seem to change when I press ctrl+c. Perhaps this 
is due to the fact that I run R in a terminal without any graphical 
interface?

> static void chkIntFn(void *dummy) {
>   R_CheckUserInterrupt();
> }
> // this will call the above in a top-level context so it won't longjmp-out of your context
> bool checkInterrupt() {
>   return (R_ToplevelExec(chkIntFn, NULL) == FALSE);
> }
> // your code somewhere ...
> if (checkInterrupt()) { // user interrupted ... }
This solution works perfectly! It takes slightly longer to call this 
function than the plan R_CheckUserInterrupt() call, but in any 
reasonable scenario, the additional time is absolutely insignificant.

Inside OpenMP parallel for constructs, one has to make sure that only 
the thread satisfying omp_get_thread_num()==0 makes the call (the 
'master' construct cannot be nested inside a loop). I can then set a 
flag, which is queried by every thread in every loop cycle, causing fast 
termination of the parallel loop. After the loop, I throw an exception. 
Thus, my code is terminated gracefully with minimal effort. I can do 
additional cleanup operations (which usually is not necessary, since I 
use smart pointers), and report details on the interrupt to the user.

With my limited testing, so far I have not noticed any downsides. Of 
course, there is the obvious drawback of not being supported officially 
(and thus maybe being subject to change), the question of portability, 
and the question of interoperability with other errors.

Moreover, I have found an old thread discussing almost the same topic:
http://tolstoy.newcastle.edu.au/R/e4/devel/08/05/1686.html .
The thread was created in 2008, so the issue is not really a new one. 
The solution proposed there is actually the same as the one suggested by 
Simon, namely using R_ToplevelExec().

An officially supported, portable solution would of course be much 
appreciated!


Best regards,
Peter


From simon.urbanek at r-project.org  Tue Apr 26 15:21:32 2011
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Tue, 26 Apr 2011 09:21:32 -0400
Subject: [Rd] Interrupting C++ code execution
In-Reply-To: <4DB6ACCB.8050606@arcor.de>
References: <4DB53D47.7060903@arcor.de>
	<85607CA7-D76F-4210-9C6E-F3E9F26F7D0E@r-project.org>
	<F1EAEEC8-7828-403F-BF2D-10A4F925B4E6@r-project.org>
	<201104252018.01541.thomas.friedrichsmeier@ruhr-uni-bochum.de>
	<4DB6ACCB.8050606@arcor.de>
Message-ID: <EE5FF473-368C-4EEE-893A-33783D462AC5@r-project.org>


On Apr 26, 2011, at 7:30 AM, schattenpflanze at arcor.de wrote:

> I have tested the solutions suggested by Simon and Thomas on a Linux machine. These are my findings:
> 
>> On Windows you can look at the variable "UserBreak", available from
>> Rembedded.h. Outside of Windows, you can look at R_interrupts_pending,
>> available from R_ext/GraphicsDevice.h. R_ext/GraphicsDevice.h also has
>> R_interrupts_suspended, which you may or may not want to take into account,
>> depending on your use-case.
> I did not manage to get this to work. Neither R_interrupts_pending nor R_interrupts_suspended seem to change when I press ctrl+c. Perhaps this is due to the fact that I run R in a terminal without any graphical interface?
> 

Thomas' suggestion was not aimed at your problem - it was sort of the inverse (more at your Qt question). If you want to interrupt R you can mess with those flags and them let R run the event loop. It doesn't work in your (original) case.


>> static void chkIntFn(void *dummy) {
>>  R_CheckUserInterrupt();
>> }
>> // this will call the above in a top-level context so it won't longjmp-out of your context
>> bool checkInterrupt() {
>>  return (R_ToplevelExec(chkIntFn, NULL) == FALSE);
>> }
>> // your code somewhere ...
>> if (checkInterrupt()) { // user interrupted ... }
> This solution works perfectly! It takes slightly longer to call this function than the plan R_CheckUserInterrupt() call, but in any reasonable scenario, the additional time is absolutely insignificant.
> 
> Inside OpenMP parallel for constructs, one has to make sure that only the thread satisfying omp_get_thread_num()==0 makes the call (the 'master' construct cannot be nested inside a loop). I can then set a flag, which is queried by every thread in every loop cycle, causing fast termination of the parallel loop. After the loop, I throw an exception. Thus, my code is terminated gracefully with minimal effort. I can do additional cleanup operations (which usually is not necessary, since I use smart pointers), and report details on the interrupt to the user.
> 
> With my limited testing, so far I have not noticed any downsides. Of course, there is the obvious drawback of not being supported officially (and thus maybe being subject to change),

Actually, it is in the official API (Rinternals.h) so I don't think that is the issue.


> the question of portability, and the question of interoperability with other errors.
> 

It is portable as well, so I'd say the main concern is what happens when events trigger something that is not related to you and you eat those errors. They will act as user-interrupt to you even if it's not what the user intended. One could argue that it's the lesser of the evils, because if you don't do anything R will just block so those events would have to wait until you're done anyway.


> Moreover, I have found an old thread discussing almost the same topic:
> http://tolstoy.newcastle.edu.au/R/e4/devel/08/05/1686.html .
> The thread was created in 2008, so the issue is not really a new one. The solution proposed there is actually the same as the one suggested by Simon, namely using R_ToplevelExec().
> 

Interesting - I'm glad Luke also suggested C-level onexit bac then - it is something I was thinking about before ..

Cheers,
Simon


> An officially supported, portable solution would of course be much appreciated!
> 
> 
> Best regards,
> Peter
> 
> 


From pauljohn32 at gmail.com  Tue Apr 26 17:13:23 2011
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Tue, 26 Apr 2011 10:13:23 -0500
Subject: [Rd] Wish R Core had a standard format (or generic function) for
	"newdata" objects
Message-ID: <BANLkTikCjqUM9YJhYtgLh4Q-z=0mpmgp2A@mail.gmail.com>

Is anybody working on a way to standardize the creation of "newdata"
objects for predict methods?

When using predict, I find it difficult/tedious to create newdata data
frames when there are many variables. It is necessary to set all
variables at the mean/mode/median, and then for some variables of
interest, one has to insert values for which predictions are desired.
I was at a presentation by Scott Long last week and he was discussing
the increasing emphasis in Stata on calculations of marginal
predictions and "Spost" an several other packages, and,
co-incidentally, I had a student visit who is learning to use R MASS's
polr (W.Venables and B. Ripley) and we wrestled for quite a while to
try to make the same calculations that Stata makes automatically.  It
spits out predicted probabilities each independent variable, keeping
other variables at a reference level.

I've found R packages that aim to do essentially the same thing.

In Frank Harrell's Design/rms framework, he uses a "data.dist"
function that generates an object that the user has to put into the R
options.  I think many users trip over the use of "options" there.  If
I don't use that for a month or two, I completely forget the fine
points and have to fight with it.  But it does "work" to give plots
and predict functions the information they require.

In  Zelig ( by Kosuke Imai, Gary King, and Olivia Lau), a function
"setx" does the work of creating "newdata" objects. That appears to be
about right as a candidate for a generic "newdata" function. Perhaps
it could directly generalize to all R regression functions, but right
now it is tailored to the models in Zelig. It has separate methods for
the different types of models, and that is a bit confusing to me,since
the "newdata" in one model should be the same as the newdata in
another, I'm guessing. But his code is all there, I'll keep looking.

In Effects (by John Fox), there are internal functions to create
newdata and plot the marginal effects. If you load effects and run,
for example, "effects:::effect.lm" you see Prof Fox has his own way of
grabbing information from model columns and calculating predictions.

I think it is time the R Core Team would look at this tell "us" what
is the right way to do this. I think the interface to setx in Zelig is
pretty easy to understand, at least for numeric variables.

In R's termplot function, such a thing could be put to use.  As far as
I can tell now, termplot is doing most of the work of creating a
newdata object, but not exactly.

It seems like it would be a shame to proliferate more functions that
do the same function, when it is such a common thing.

-- 
Paul E. Johnson
Professor, Political Science
1541 Lilac Lane, Room 504
University of Kansas


From cstrato at aon.at  Tue Apr 26 21:58:49 2011
From: cstrato at aon.at (cstrato)
Date: Tue, 26 Apr 2011 21:58:49 +0200
Subject: [Rd] How to create vignette.pdf for R-2.13.0?
In-Reply-To: <4DB5CBFD.6050508@gmail.com>
References: <4DB32D9F.5010406@aon.at>	<4DB42FB3.9090401@statistik.tu-dortmund.de>	<4DB472F8.9060903@aon.at>	<4DB489EC.9080301@statistik.tu-dortmund.de>	<4DB491BE.8080104@aon.at>	<4DB57E7A.1080507@statistik.tu-dortmund.de>
	<4DB5AFD4.9020303@aon.at> <4DB5B6B0.90607@gmail.com>
	<4DB5C286.40306@aon.at> <4DB5C38D.6030400@gmail.com>
	<4DB5C87C.5040905@aon.at> <4DB5CBFD.6050508@gmail.com>
Message-ID: <4DB723F9.7090800@aon.at>

Dear Duncan, dear Uwe,

Just now I have re-run everything, and today xps.Rnw can be converted to 
a vignette w/o any problems using:
a, buildVignettes("xps", dir="/Volumes/CoreData/CRAN/xps", quiet=F)
b, R CMD Sweave xps.Rnw

In both cases the vignette xps.pdf is created (maybe my Mac did not like 
to work during eastern holidays).

However, one issue remains:
"R64 CMD check xps_1.13.1.tar.gz" no longer creates any pdf files for 
the vignettes.

Best regards
Christian


On 4/25/11 9:31 PM, Duncan Murdoch wrote:
> On 25/04/2011 3:16 PM, cstrato wrote:
>> Thank you.
>>
>> My problem seems to be that at the moment the problem can be seen only
>> on my Mac, since e.g. the Bioconductor servers have no problems creating
>> the vignettes.
>
> Then you are definitely the one in the best position to diagnose the
> problem. Use the usual approach: simplify it by cutting out everything
> that looks unrelated. Verify that the problem still exists, then cut
> some more. Eventually you'll have isolated the error to a particular
> small snippet of code, and then you can add print() statements, or use
> trace(), or do whatever is necessary to see what's so special about your
> system.
>
> I suspect it will turn out to be an assumption in the code that is not
> true on your system.
>
> If the assumption is being made by code you wrote, then fix it. If it's
> being made by R, let us know.
>
> Duncan Murdoch
>
>>
>> Best regards
>> Christian
>>
>> On 4/25/11 8:55 PM, Duncan Murdoch wrote:
>>> cstrato wrote:
>>>> Dear Duncan,
>>>>
>>>> Thank you for your example, however it is different since it does not
>>>> use x and y. What about print(x+y)?
>>>
>>> Try it.
>>>
>>>>
>>>> Sorry, I do not believe that there is a bug in my code, since:
>>>> 1, it worked in all versions from R starting with R-2.6.0 till
>>>> R-2.12.2.
>>>> 2, the identical code works in the examples
>>>> 3, this code (or a similar code) is the starting code which all users
>>>> of xps have to use, and there was never a problem.
>>>
>>> This might be a problem in R, or might be a problem in your code. As far
>>> as I know, it has only shown up in your code, so I'd guess that's where
>>> the problem is. In any case, you're the one in the best position to
>>> isolate it and debug it.
>>>
>>> If it turns out to be a problem in R, put together an example
>>> illustrating the problem that doesn't involve your code, and I'll take a
>>> look.
>>>
>>> Duncan Murdoch
>>>
>>>>
>>>> Maybe the reason could be that my code has to import
>>>> - the CEL-files from the package dir
>>>> - the file SchemeTest3.root from the package dir
>>>> ??
>>>>
>>>> Best regards
>>>> Christian
>>>>
>>>> On 4/25/11 8:00 PM, Duncan Murdoch wrote:
>>>>> cstrato wrote:
>>>>>> Dear Uwe,
>>>>>>
>>>>>> Your suggestion to look at the Sweave manual helped me to solve the
>>>>>> problem. It seems that in R-2.13.0 every chunk can use the code from
>>>>>> the chunk before but not from an earlier chunk.
>>>>> I'm either misreading what you wrote, or it's wrong. If I have this
>>>>> in a
>>>>> Sweave file:
>>>>>
>>>>> <<>>=
>>>>> x<- 1
>>>>> @
>>>>>
>>>>> <<>>=
>>>>> y<- 2
>>>>> @
>>>>>
>>>>> <<>>=
>>>>> print(x)
>>>>> @
>>>>>
>>>>> I will see the value of x getting printed, even though it came from
>>>>> two
>>>>> chunks earlier.
>>>>>
>>>>> I think Uwe is right: there is some bug in the code you're running.
>>>>> Sweave isn't the problem.
>>>>>
>>>>> Duncan Murdoch
>>>>>
>>>>>> Concretely, the following does not work since chunk 5 needs the code
>>>>>> from chunk 3 and 4:
>>>>>>
>>>>>> ###################################################
>>>>>> ### chunk number 3:
>>>>>> ###################################################
>>>>>> #line 126 "xps.Rnw"
>>>>>> celdir<- file.path(.path.package("xps"), "raw")
>>>>>>
>>>>>> ###################################################
>>>>>> ### chunk number 4:
>>>>>> ###################################################
>>>>>> #line 132 "xps.Rnw"
>>>>>> scheme.test3<- root.scheme(file.path(.path.package("xps"), "schemes",
>>>>>> "SchemeTest3.root"))
>>>>>>
>>>>>> ###################################################
>>>>>> ### chunk number 5:
>>>>>> ###################################################
>>>>>> #line 137 "xps.Rnw"
>>>>>> celfiles<- c("TestA1.CEL","TestA2.CEL")
>>>>>> data.test3<- import.data(scheme.test3, "tmpdt_DataTest3",
>>>>>> celdir=celdir, celfiles=celfiles, verbose=FALSE)
>>>>>>
>>>>>>
>>>>>> However, when I add "celdir" to chunk 5 then everything works since
>>>>>> now chunk 5 needs only the code from chunk 4 but not from chunk 3:
>>>>>>
>>>>>> ###################################################
>>>>>> ### chunk number 5:
>>>>>> ###################################################
>>>>>> #line 137 "xps.Rnw"
>>>>>> celdir<- file.path(.path.package("xps"), "raw")
>>>>>> celfiles<- c("TestA1.CEL","TestA2.CEL")
>>>>>> data.test3<- import.data(scheme.test3, "tmpdt_DataTest3",
>>>>>> celdir=celdir, celfiles=celfiles, verbose=FALSE)
>>>>>>
>>>>>>
>>>>>> Now buildVignettes() is able to create the vignettes, however R CMD
>>>>>> check still does not build the vignettes.
>>>>>>
>>>>>>
>>>>>> Yes, I get a Warning in both cases:
>>>>>> * checking package vignettes in 'inst/doc' ... WARNING
>>>>>> Package vignettes without corresponding PDF: ........
>>>>>>
>>>>>> However, with R-2.12.2 the following lines are added:
>>>>>>
>>>>>> /Volumes/CoreData/CRAN/xps.Rcheck/00_pkg_src/xps/inst/doc/APTvsXPS.Rnw
>>>>>>
>>>>>> /Volumes/CoreData/CRAN/xps.Rcheck/00_pkg_src/xps/inst/doc/xps.Rnw
>>>>>> /Volumes/CoreData/CRAN/xps.Rcheck/00_pkg_src/xps/inst/doc/xpsClasses.Rnw
>>>>>>
>>>>>>
>>>>>> /Volumes/CoreData/CRAN/xps.Rcheck/00_pkg_src/xps/inst/doc/xpsPreprocess.Rnw
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>> and in xps.Rcheck the subdirectory "inst/doc" will be created which
>>>>>> contains the vignette data such as xps.Rnw, but also xps.tex and
>>>>>> xps.pdf.
>>>>>>
>>>>>> In contrast, R-2.13.0 does not create the subdirectory "inst/doc" and
>>>>>> no vignettes are built.
>>>>>>
>>>>>> One more issue:
>>>>>> In contrast to my former believe R CMD INSTALL does not build the
>>>>>> vignettes, neither in R-2.12.2 nor in R-2.13.0. I have to run
>>>>>> buildVignettes() after installation. Is this the usual case?
>>>>>>
>>>>>> Best regards
>>>>>> Christian
>>>>>>
>>>>>>
>>>>>> On 4/25/11 4:00 PM, Uwe Ligges wrote:
>>>>>>> On 24.04.2011 23:10, cstrato wrote:
>>>>>>>> Dear Uwe,
>>>>>>>>
>>>>>>>> On 4/24/11 10:37 PM, Uwe Ligges wrote:
>>>>>>>>> On 24.04.2011 20:59, cstrato wrote:
>>>>>>>>>> Dear Uwe,
>>>>>>>>>>
>>>>>>>>>> Thank you for your reply.
>>>>>>>>>>
>>>>>>>>>> ad 2, Yes, i know that "xps-manual.pdf" is the collection of help
>>>>>>>>>> pages,
>>>>>>>>>> I have mentioned it only to show that creating pdf-files does
>>>>>>>>>> work
>>>>>>>>>> for
>>>>>>>>>> R-2.13.0.
>>>>>>>>>>
>>>>>>>>>> ad 1, Could it be that this is a Mac-specific problem since I see
>>>>>>>>>> it on
>>>>>>>>>> both my old MacBook Pro and my new Mac Mini.
>>>>>>>>> Have you tried on any other OS? I did not since installing root is
>>>>>>>>> a bit
>>>>>>>>> too much effort.
>>>>>>>>>
>>>>>>>>>
>>>>>>>> No, until now I did not try another OS, but I will, since xps
>>>>>>>> has to
>>>>>>>> work on all three OSes.
>>>>>>>>
>>>>>>>>>> Using R CMD check with R-2.12.2 I get:
>>>>>>>>> I thought we are talking about R-2.13.0?
>>>>>>>>>
>>>>>>>> I showed you the output of R-2.12.2 first and then the output of
>>>>>>>> R-2.13.0, so that you can see that on the same machine with the
>>>>>>>> same
>>>>>>>> file it works with one version but not the other.
>>>>>>> But you got a Warning in both cases:
>>>>>>> * checking package vignettes in 'inst/doc' ... WARNING
>>>>>>> Package vignettes without corresponding PDF: ........
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>>> Where is the R CMD build output (since R CMD build is supposed to
>>>>>>>>> prepare the vignette).
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>> $ R64 CMD check xps_1.13.1.tar.gz
>>>>>>>>>> * using log directory '/Volumes/CoreData/CRAN/xps.Rcheck'
>>>>>>>>>> * using R version 2.12.2 (2011-02-25)
>>>>>>>>>> * using platform: x86_64-apple-darwin9.8.0 (64-bit)
>>>>>>>>>> * using session charset: ASCII
>>>>>>>>>> * checking for file 'xps/DESCRIPTION' ... OK
>>>>>>>>>> * this is package 'xps' version '1.13.1'
>>>>>>>>>> ...
>>>>>>>>>> ...
>>>>>>>>>> * checking package vignettes in 'inst/doc' ... WARNING
>>>>>>>>>> Package vignettes without corresponding PDF:
>>>>>>>>>>
>>>>>>>>>> /Volumes/CoreData/CRAN/xps.Rcheck/00_pkg_src/xps/inst/doc/APTvsXPS.Rnw
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>> /Volumes/CoreData/CRAN/xps.Rcheck/00_pkg_src/xps/inst/doc/xps.Rnw
>>>>>>>>>> /Volumes/CoreData/CRAN/xps.Rcheck/00_pkg_src/xps/inst/doc/xpsClasses.Rnw
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>> /Volumes/CoreData/CRAN/xps.Rcheck/00_pkg_src/xps/inst/doc/xpsPreprocess.Rnw
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>> * checking PDF version of manual ... OK
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>> Using "RSwitch.app" I switch to R-2.13.0, but now I get:
>>>>>>>>>>
>>>>>>>>>> $ R64 CMD check xps_1.13.1.tar.gz
>>>>>>>>>> * using log directory '/Volumes/CoreData/CRAN/xps.Rcheck'
>>>>>>>>>> * using R version 2.13.0 (2011-04-13)
>>>>>>>>>> * using platform: x86_64-apple-darwin9.8.0 (64-bit)
>>>>>>>>>> * using session charset: ASCII
>>>>>>>>>> * checking for file 'xps/DESCRIPTION' ... OK
>>>>>>>>>> * this is package 'xps' version '1.13.1'
>>>>>>>>>> ...
>>>>>>>>>> ...
>>>>>>>>>> * checking package vignettes in 'inst/doc' ... WARNING
>>>>>>>>>> Package vignette(s) without corresponding PDF:
>>>>>>>>>> APTvsXPS.Rnw
>>>>>>>>>> xps.Rnw
>>>>>>>>>> xpsClasses.Rnw
>>>>>>>>>> xpsPreprocess.Rnw
>>>>>>>>>>
>>>>>>>>>> * checking running R code from vignettes ... OK
>>>>>>>>>> * checking re-building of vignettes ... OK
>>>>>>>>>> * checking PDF version of manual ... OK
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>> I must admit that I have never built the vignettes manually,
>>>>>>>>>> and I
>>>>>>>>>> cannot find a hint how I can do it from the command line. Is this
>>>>>>>>>> possible?
>>>>>>>> Is it possible to build the vignettes from the command line?
>>>>>>> R --help suggests there is
>>>>>>> R CMD Sweave .....
>>>>>>>
>>>>>>>
>>>>>>>>>> However, building the vignettes within R-2.13.0 I get:
>>>>>>>>>>> library(tools)
>>>>>>>>>>> buildVignettes("xps", dir="/Volumes/CoreData/CRAN/xps", quiet=F)
>>>>>>>>>> Overfull \vbox (21.68121pt too high) has occurred while
>>>>>>>>>> \output is
>>>>>>>>>> Writing to file xps.tex
>>>>>>>>>> Processing code chunks with options ...
>>>>>>>>>> 1 : term verbatim
>>>>>>>>>> 2 : echo term hide
>>>>>>>>>> 3 : echo term verbatim
>>>>>>>>>> 4 : echo term verbatim
>>>>>>>>>> 5 : echo term verbatim
>>>>>>>>>> SysError in<TFile::TFile>: file
>>>>>>>>>> /tmpdt_DataTest3_cel.root/tmpdt_DataTest3_cel_20110424_201301.root
>>>>>>>>>>
>>>>>>>>>> can
>>>>>>>>>> not be opened (No such file or directory)
>>>>>>>>>> Error: Could not create file</tmpdt_DataTest3_cel.root>
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>> Here are the two important chunks 4 and 5, which work fine with
>>>>>>>>>> R-2.12.2
>>>>>>>>>> and earlier versions:
>>>>>>>>>>
>>>>>>>>>> ###################################################
>>>>>>>>>> ### chunk number 4:
>>>>>>>>>> ###################################################
>>>>>>>>>> #line 132 "xps.Rnw"
>>>>>>>>>> scheme.test3<- root.scheme(file.path(.path.package("xps"),
>>>>>>>>>> "schemes",
>>>>>>>>>> "SchemeTest3.root"))
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>> ###################################################
>>>>>>>>>> ### chunk number 5:
>>>>>>>>>> ###################################################
>>>>>>>>>> #line 137 "xps.Rnw"
>>>>>>>>>> celfiles<- c("TestA1.CEL","TestA2.CEL")
>>>>>>>>>> data.test3<- import.data(scheme.test3, "tmpdt_DataTest3",
>>>>>>>>>> celdir=celdir, celfiles=celfiles, verbose=FALSE)
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>> However, in R-2.13.0 chunk 5 crashes!!!
>>>>>>>>>> It works only when replacing chunk 5 with:
>>>>>>>>>>
>>>>>>>>>> ###################################################
>>>>>>>>>> ### chunk number 5:
>>>>>>>>>> ###################################################
>>>>>>>>>> #line 137 "xps.Rnw"
>>>>>>>>>> celfiles<- c("TestA1.CEL","TestA2.CEL")
>>>>>>>>>> scheme.test3<- root.scheme(file.path(.path.package("xps"),
>>>>>>>>>> "schemes",
>>>>>>>>>> "SchemeTest3.root"))
>>>>>>>>>> data.test3<- import.data(scheme.test3, "tmpdt_DataTest3",
>>>>>>>>>> celdir=celdir, celfiles=celfiles, verbose=FALSE)
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>> As you see R-2.13.0 does no longer remember the result of
>>>>>>>>>> chunk 4,
>>>>>>>>>> i.e.
>>>>>>>>>> "scheme.test3". Now I have to include the line defining
>>>>>>>>>> "scheme.test3"
>>>>>>>>>> also in chunk 5.
>>>>>>>>> How objects generated in one chunk can be reused later on is
>>>>>>>>> explained
>>>>>>>>> in the Sweave manual.
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>> Do you have any idea for this behavior?
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>> An example, which does work in R-2.13.0 are the following two
>>>>>>>>>> chunks:
>>>>>>>>>>
>>>>>>>>>> #################################################
>>>>>>>>>> ### chunk number 20:
>>>>>>>>>> ###################################################
>>>>>>>>>> #line 300 "xps.Rnw"
>>>>>>>>>> library(xps)
>>>>>>>>>> scheme.test3<- root.scheme(file.path(.path.package("xps"),
>>>>>>>>>> "schemes",
>>>>>>>>>> "SchemeTest3.root"))
>>>>>>>>>> data.test3<- root.data(scheme.test3,
>>>>>>>>>> file.path(.path.package("xps"),"rootdata", "DataTest3_cel.root"))
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>> ###################################################
>>>>>>>>>> ### chunk number 21:
>>>>>>>>>> ###################################################
>>>>>>>>>> #line 318 "xps.Rnw"
>>>>>>>>>> data.rma<- rma(data.test3, "tmpdt_Test3RMA", verbose=FALSE)
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>> In summary it is not quite clear to me what has changed in
>>>>>>>>>> R-2.13.0 so
>>>>>>>>>> that chunk 5 no longer works.
>>>>>>>>>>
>>>>>>>>>> BTW, the error:
>>>>>>>>>> SysError in<TFile::TFile>: file
>>>>>>>>>> /tmpdt_DataTest3_cel.root/tmpdt_DataTest3_cel_20110424_201301.root
>>>>>>>>>>
>>>>>>>>>> can
>>>>>>>>>> not be opened
>>>>>>>>>> is not clear to me since "/tmpdt_DataTest3_cel.root/" is
>>>>>>>>>> definitively
>>>>>>>>>> NOT a directory.
>>>>>>>>> Time to debug what root.scheme is doing with the supplied path.
>>>>>>>>>
>>>>>>>> Sorry, I do not understand what you mean. root.scheme does not
>>>>>>>> change
>>>>>>>> the path, otherwise it would not work on all older versions of R.
>>>>>>> Right, but since something changed obviously, and you tell us the
>>>>>>> path
>>>>>>> is not a path, it might be a function used by root.scheme ....
>>>>>>> That's
>>>>>>> why I said time to debug the code in your vignette!
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>>>> Do you have any ideas?
>>>>>>>>>>
>>>>>>>>>> Please note that the vignette "xps.Rnw" did work for the last two
>>>>>>>>>> years
>>>>>>>>>> w/o problem. Furthermore, the Bioconductor servers are able to
>>>>>>>>>> build
>>>>>>>>>> the
>>>>>>>>>> vignette, see:
>>>>>>>>>> http://www.bioconductor.org/packages/release/bioc/html/xps.html
>>>>>>>>> See
>>>>>>>>> http://bioconductor.org/checkResults/2.8/bioc-20110225/xps/liverpool-checksrc.html
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>> and find that their Mac Servers are also fine with it. So maybe
>>>>>>>>> it is
>>>>>>>>> your setup that is corrupted?
>>>>>>>> Maybe, you are right that my setup is corrupted, but on two
>>>>>>>> independent
>>>>>>>> machines?
>>>>>>>>
>>>>>>>> Maybe the download of "R-2.13.0.pkg" is corrupted, but then nothing
>>>>>>>> should work, or am I wrong?
>>>>>>>>
>>>>>>>> How can I check if my setup is corrupted?
>>>>>>> By debugging the code in your package's vignette.
>>>>>>>
>>>>>>> Uwe Ligges
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>> Best regards
>>>>>>>> Christian
>>>>>>>>
>>>>>>>>> Best wishes,
>>>>>>>>> Uwe
>>>>>>>>>
>>>>>>>>>> Best regards
>>>>>>>>>> Christian
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>> On 4/24/11 4:12 PM, Uwe Ligges wrote:
>>>>>>>>>>> On 23.04.2011 21:50, cstrato wrote:
>>>>>>>>>>>> Dear all,
>>>>>>>>>>>>
>>>>>>>>>>>> While R CMD check and R CMD INSTALL have always created the
>>>>>>>>>>>> vignettes on
>>>>>>>>>>>> R-2.12.1 or any earlier versions of R, I am no longer able to
>>>>>>>>>>>> build
>>>>>>>>>>>> the
>>>>>>>>>>>> vignettes on R-2.13.0.
>>>>>>>>>>>>
>>>>>>>>>>>> Instead R CMD check gives me the following output:
>>>>>>>>>>>>
>>>>>>>>>>>> * checking for unstated dependencies in vignettes ... OK
>>>>>>>>>>>> * checking package vignettes in 'inst/doc' ... WARNING
>>>>>>>>>>>> Package vignette(s) without corresponding PDF:
>>>>>>>>>>>> APTvsXPS.Rnw
>>>>>>>>>>>> xps.Rnw
>>>>>>>>>>>> xpsClasses.Rnw
>>>>>>>>>>>> xpsPreprocess.Rnw
>>>>>>>>>>>>
>>>>>>>>>>>> * checking running R code from vignettes ... OK
>>>>>>>>>>>> * checking re-building of vignettes ... OK
>>>>>>>>>>>> * checking PDF version of manual ... OK
>>>>>>>>>>>>
>>>>>>>>>>>>
>>>>>>>>>>>> Does someone know what the reason might be?
>>>>>>>>>>> No, it does for me for other packages.
>>>>>>>>>>> Perhaps an error when processing the vignettes? Have you
>>>>>>>>>>> tried to
>>>>>>>>>>> build
>>>>>>>>>>> them manually?
>>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>>>> (R64 CMD check --help says that be default rebuild-vignettes is
>>>>>>>>>>>> turned
>>>>>>>>>>>> on.)
>>>>>>>>>>>>
>>>>>>>>>>>> Interestingly, R CMD check still creates the file
>>>>>>>>>>>> "xps-manual.pdf".
>>>>>>>>>>> That is the collection of help pages, unrelated to the vignette.
>>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>>> Uwe Ligges
>>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>>>> Here is my sessionInfo:
>>>>>>>>>>>>
>>>>>>>>>>>>> sessionInfo()
>>>>>>>>>>>> R version 2.13.0 (2011-04-13)
>>>>>>>>>>>> Platform: x86_64-apple-darwin9.8.0/x86_64 (64-bit)
>>>>>>>>>>>>
>>>>>>>>>>>> locale:
>>>>>>>>>>>> [1] C
>>>>>>>>>>>>
>>>>>>>>>>>> attached base packages:
>>>>>>>>>>>> [1] stats graphics grDevices utils datasets methods base
>>>>>>>>>>>>
>>>>>>>>>>>> other attached packages:
>>>>>>>>>>>> [1] xps_1.13.1
>>>>>>>>>>>>
>>>>>>>>>>>> loaded via a namespace (and not attached):
>>>>>>>>>>>> [1] Biobase_2.12.1 Biostrings_2.20.0 IRanges_1.10.0
>>>>>>>>>>>> [4] affy_1.30.0 affyPLM_1.28.5 affyio_1.20.0
>>>>>>>>>>>> [7] preprocessCore_1.14.0
>>>>>>>>>>>>
>>>>>>>>>>>> Thank you in advance.
>>>>>>>>>>>> Best regards
>>>>>>>>>>>> Christian
>>>>>>>>>>>> _._._._._._._._._._._._._._._._._._
>>>>>>>>>>>> C.h.r.i.s.t.i.a.n S.t.r.a.t.o.w.a
>>>>>>>>>>>> V.i.e.n.n.a A.u.s.t.r.i.a
>>>>>>>>>>>> e.m.a.i.l: cstrato at aon.at
>>>>>>>>>>>> _._._._._._._._._._._._._._._._._._
>>>>>>>>>>>>
>>>>>>>>>>>> ______________________________________________
>>>>>>>>>>>> R-devel at r-project.org mailing list
>>>>>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>>>>>>> ______________________________________________
>>>>>>>>>> R-devel at r-project.org mailing list
>>>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>>> ______________________________________________
>>>>>> R-devel at r-project.org mailing list
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>>
>>>
>>>
>
>


From mdowle at mdowle.plus.com  Tue Apr 26 22:08:27 2011
From: mdowle at mdowle.plus.com (Matthew Dowle)
Date: Tue, 26 Apr 2011 21:08:27 +0100
Subject: [Rd] help.request() for packages?
Message-ID: <1303848507.4824.15.camel@netbook>

Hi,

Have I missed something, or misunderstood?

The r-help posting guide asks users to contact the package maintainer :

   "If the question relates to a contributed package, e.g., one
downloaded from CRAN, try contacting the package maintainer first.
[snip] ONLY [only is bold font] send such questions to R-help or R-devel
if you get no reply or need further assistance. This applies to both
requests for help and to bug reports."

but the R-ext guide contains :

   "The mandatory ?Maintainer? field should give a single name with a
valid (RFC 2822) email address in angle brackets (for sending bug
reports etc.). It should not end in a period or comma. For a public
package it should be a person, not a mailing list and not a corporate 
entity: do ensure that it is valid and will remain valid for the
lifetime of the package."

Currently, data.table contains the datatable-help mailing list in the
'Maintainer' field, with the posting guide in mind (and service levels
for users). This mailing list is where we would like users to ask
questions about the package, not r-help, and not a single person.
However, R-exts says that the 'Maintainer' email address should not be a
mailing list.

There seems to be two requirements:
   i) a non-bouncing email address that CRAN maintainers can use - more
like the 'Administrator' of the package
   ii) a support address for users to send questions and bug reports

The BugReports field in DESCRIPTION is for bugs only, and allows only a
URL, not an email address. bug.reports() has a 'package' argument and
emails the Maintainer field if the BugReports URL is not provided by the
package. So, BugReports seems close, but not quite what we'd like.

help.request() appears to have no package argument (I checked R 2.13.0).

Could a "Support" field (or better name) be added to DESCRIPTION, and a
'package' argument added to help.request() which uses it?  Then the
semantics of the Maintainer field can be closer to what the CRAN
maintainers seem to think of it; i.e., the package 'Administrator'.

Have I misunderstood or missed an option?

Matthew


From jeffrey.ryan at lemnica.com  Tue Apr 26 22:31:52 2011
From: jeffrey.ryan at lemnica.com (Jeffrey Ryan)
Date: Tue, 26 Apr 2011 15:31:52 -0500
Subject: [Rd] help.request() for packages?
In-Reply-To: <1303848507.4824.15.camel@netbook>
References: <1303848507.4824.15.camel@netbook>
Message-ID: <BANLkTinHh-BsFQHkxtyNLj0ci7wW5HX3=w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110426/e81abece/attachment.pl>

From sean.mcguffee at gmail.com  Tue Apr 26 23:06:02 2011
From: sean.mcguffee at gmail.com (Sean Robert McGuffee)
Date: Tue, 26 Apr 2011 17:06:02 -0400
Subject: [Rd] Interrupting C++ code execution
In-Reply-To: <EE5FF473-368C-4EEE-893A-33783D462AC5@r-project.org>
Message-ID: <C9DCABFA.3EB3%sean.mcguffee@gmail.com>

Hi,
I've been thinking about how to handle c++ threads that were started via
Rcpp calls to some of my c++ libraries from R. My main obstacle is trying to
make sure that users don't try to process files that are being generated by
a thread before the thread finishes. One thing I am considering is having my
threaded code return a class to R that contains a pointer that it remembers.
Then maybe I could just change the value at that pointer when my thread
finishes. Does that seem like a reasonable approach? I'm not completely sure
if this is related to your issue or not, but it might be similar enough to
be worth asking...
Thanks,
Sean


On 4/26/11 9:21 AM, "Simon Urbanek" <simon.urbanek at r-project.org> wrote:

> 
> On Apr 26, 2011, at 7:30 AM, schattenpflanze at arcor.de wrote:
> 
>> I have tested the solutions suggested by Simon and Thomas on a Linux machine.
>> These are my findings:
>> 
>>> On Windows you can look at the variable "UserBreak", available from
>>> Rembedded.h. Outside of Windows, you can look at R_interrupts_pending,
>>> available from R_ext/GraphicsDevice.h. R_ext/GraphicsDevice.h also has
>>> R_interrupts_suspended, which you may or may not want to take into account,
>>> depending on your use-case.
>> I did not manage to get this to work. Neither R_interrupts_pending nor
>> R_interrupts_suspended seem to change when I press ctrl+c. Perhaps this is
>> due to the fact that I run R in a terminal without any graphical interface?
>> 
> 
> Thomas' suggestion was not aimed at your problem - it was sort of the inverse
> (more at your Qt question). If you want to interrupt R you can mess with those
> flags and them let R run the event loop. It doesn't work in your (original)
> case.
> 
> 
>>> static void chkIntFn(void *dummy) {
>>>  R_CheckUserInterrupt();
>>> }
>>> // this will call the above in a top-level context so it won't longjmp-out
>>> of your context
>>> bool checkInterrupt() {
>>>  return (R_ToplevelExec(chkIntFn, NULL) == FALSE);
>>> }
>>> // your code somewhere ...
>>> if (checkInterrupt()) { // user interrupted ... }
>> This solution works perfectly! It takes slightly longer to call this function
>> than the plan R_CheckUserInterrupt() call, but in any reasonable scenario,
>> the additional time is absolutely insignificant.
>> 
>> Inside OpenMP parallel for constructs, one has to make sure that only the
>> thread satisfying omp_get_thread_num()==0 makes the call (the 'master'
>> construct cannot be nested inside a loop). I can then set a flag, which is
>> queried by every thread in every loop cycle, causing fast termination of the
>> parallel loop. After the loop, I throw an exception. Thus, my code is
>> terminated gracefully with minimal effort. I can do additional cleanup
>> operations (which usually is not necessary, since I use smart pointers), and
>> report details on the interrupt to the user.
>> 
>> With my limited testing, so far I have not noticed any downsides. Of course,
>> there is the obvious drawback of not being supported officially (and thus
>> maybe being subject to change),
> 
> Actually, it is in the official API (Rinternals.h) so I don't think that is
> the issue.
> 
> 
>> the question of portability, and the question of interoperability with other
>> errors.
>> 
> 
> It is portable as well, so I'd say the main concern is what happens when
> events trigger something that is not related to you and you eat those errors.
> They will act as user-interrupt to you even if it's not what the user
> intended. One could argue that it's the lesser of the evils, because if you
> don't do anything R will just block so those events would have to wait until
> you're done anyway.
> 
> 
>> Moreover, I have found an old thread discussing almost the same topic:
>> http://tolstoy.newcastle.edu.au/R/e4/devel/08/05/1686.html .
>> The thread was created in 2008, so the issue is not really a new one. The
>> solution proposed there is actually the same as the one suggested by Simon,
>> namely using R_ToplevelExec().
>> 
> 
> Interesting - I'm glad Luke also suggested C-level onexit bac then - it is
> something I was thinking about before ..
> 
> Cheers,
> Simon
> 
> 
>> An officially supported, portable solution would of course be much
>> appreciated!
>> 
>> 
>> Best regards,
>> Peter
>> 
>> 
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From baptiste.auguie at googlemail.com  Wed Apr 27 01:06:44 2011
From: baptiste.auguie at googlemail.com (baptiste auguie)
Date: Wed, 27 Apr 2011 11:06:44 +1200
Subject: [Rd] grid stringHeight
Message-ID: <BANLkTik0dL-oC8GzAqAJsNanZDF7LpndsA@mail.gmail.com>

Dear all,

I'm puzzled by the behavior of stringHeight in the grid package.
Consider the following test,

library(grid)

test <- function(lab="dog", ...){
  g1 <- textGrob(lab)
  g2 <- rectGrob(height=grobHeight(g1), width=grobWidth(g1))
  gg <- gTree(children=gList(g1,g2), ...)

  print(c("height:", convertUnit(stringHeight(lab), "mm", "y")))
  grid.draw(gg)
}

grid.newpage()
test()
test(expression(dog), vp=viewport(x=0.6))
## notice how the dog's tail is being cut off, where
## expression yields a snug cage

grid.newpage()
test("aoc")
test(expression(aoc), vp=viewport(x=0.6))

It appears that stringHeight correctly calculates the height for an
expression, but not for a basic string. I think it used to produce the
same output for both.

Best regards,

baptiste

sessionInfo()
R version 2.13.0 alpha (2011-03-27 r55076)
Platform: i386-apple-darwin9.8.0 (32-bit)

locale:
[1] C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  grid      methods
[8] base


From murdoch.duncan at gmail.com  Wed Apr 27 02:39:57 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 26 Apr 2011 20:39:57 -0400
Subject: [Rd] Wish R Core had a standard format (or generic function)
 for "newdata" objects
In-Reply-To: <BANLkTikCjqUM9YJhYtgLh4Q-z=0mpmgp2A@mail.gmail.com>
References: <BANLkTikCjqUM9YJhYtgLh4Q-z=0mpmgp2A@mail.gmail.com>
Message-ID: <4DB765DD.3060900@gmail.com>

On 26/04/2011 11:13 AM, Paul Johnson wrote:
> Is anybody working on a way to standardize the creation of "newdata"
> objects for predict methods?

They're generally just dataframes.  Use the data.frame() function.

> When using predict, I find it difficult/tedious to create newdata data
> frames when there are many variables. It is necessary to set all
> variables at the mean/mode/median, and then for some variables of
> interest, one has to insert values for which predictions are desired.

In most models, all variables are necessary in order to produce 
predictions.  If you want to do predictions for one variable, holding 
the others at particular fixed values, just create a dataframe.

For example, suppose the original data is

X <- data.frame(a=rnorm(100), b=rnorm(100), c=rnorm(100))
y <- with(X, a + 2*b + 3*c + rnorm(100))

# You use lm() to get a fit:

fit <- lm(y ~ ., data=X)

# Compute the means of all the covariates:

means <- lapply(X, mean)

# Replace a by a range of values from -1 to 1:

means$a <- seq(-1, 1, len=11)

# Convert to a data.frame:

newdata <- as.data.frame(means)

# Do the predictions:

predict(fit, newdata=newdata)


That was three lines of code to produce the newdata dataframe.  It's not 
that hard.  I would think it's easier to write those lines than to 
specify how to do this in general.

> I was at a presentation by Scott Long last week and he was discussing
> the increasing emphasis in Stata on calculations of marginal
> predictions and "Spost" an several other packages, and,
> co-incidentally, I had a student visit who is learning to use R MASS's
> polr (W.Venables and B. Ripley) and we wrestled for quite a while to
> try to make the same calculations that Stata makes automatically.  It
> spits out predicted probabilities each independent variable, keeping
> other variables at a reference level.
>
> I've found R packages that aim to do essentially the same thing.
>
> In Frank Harrell's Design/rms framework, he uses a "data.dist"
> function that generates an object that the user has to put into the R
> options.  I think many users trip over the use of "options" there.  If
> I don't use that for a month or two, I completely forget the fine
> points and have to fight with it.  But it does "work" to give plots
> and predict functions the information they require.
>
> In  Zelig ( by Kosuke Imai, Gary King, and Olivia Lau), a function
> "setx" does the work of creating "newdata" objects. That appears to be
> about right as a candidate for a generic "newdata" function. Perhaps
> it could directly generalize to all R regression functions, but right
> now it is tailored to the models in Zelig. It has separate methods for
> the different types of models, and that is a bit confusing to me,since
> the "newdata" in one model should be the same as the newdata in
> another, I'm guessing. But his code is all there, I'll keep looking.
>
> In Effects (by John Fox), there are internal functions to create
> newdata and plot the marginal effects. If you load effects and run,
> for example, "effects:::effect.lm" you see Prof Fox has his own way of
> grabbing information from model columns and calculating predictions.
>
> I think it is time the R Core Team would look at this tell "us" what
> is the right way to do this. I think the interface to setx in Zelig is
> pretty easy to understand, at least for numeric variables.

If you don't like the way this was done in my three lines above, or by 
Frank Harrell, or the Zelig group, or John Fox, why don't you do it 
yourself, and get it right this time?  It's pretty rude to complain 
about things that others have given you for free, and demand they do it 
better.

Duncan Murdoch


>
> In R's termplot function, such a thing could be put to use.  As far as
> I can tell now, termplot is doing most of the work of creating a
> newdata object, but not exactly.
>
> It seems like it would be a shame to proliferate more functions that
> do the same function, when it is such a common thing.
>


From simon.urbanek at r-project.org  Wed Apr 27 02:51:58 2011
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Tue, 26 Apr 2011 20:51:58 -0400
Subject: [Rd] Thread synchronization [Was: Interrupting C++ code execution]
In-Reply-To: <C9DCABFA.3EB3%sean.mcguffee@gmail.com>
References: <C9DCABFA.3EB3%sean.mcguffee@gmail.com>
Message-ID: <E025FC94-D808-4098-AF1F-4A26BBA25A3C@r-project.org>

Sean,

On Apr 26, 2011, at 5:06 PM, Sean Robert McGuffee wrote:

> I've been thinking about how to handle c++ threads that were started via Rcpp calls to some of my c++ libraries from R. My main obstacle is trying to make sure that users don't try to process files that are being generated by a thread before the thread finishes. One thing I am considering is having my threaded code return a class to R that contains a pointer that it remembers. Then maybe I could just change the value at that pointer when my thread finishes. Does that seem like a reasonable approach? I'm not completely sure if this is related to your issue or not, but it might be similar enough to be worth asking...

It depends. For a simple flag it's actually much more simple than that - you can create a boolean vector (make sure you preserve it) and just update its value when it's done - you don't even need an external pointer for that (if your'e careful).

But the slight problem with that approach is rather that you don't have a way to tell R about the status change, so essentially you can only poll on the R side. A more proper way to deal with this is to use the event loop signaling to signal in R that the flag has changed. I'm working on a "threads" package that should help with that, but it's not complete yet (you can spawn threads from R and you can actually even synchronize them with R [so if the result is all you want it's there], but semaphores are not implemented yet  --- your inquiry should shift it further up on my todo stack ;)).

Cheers,
Simon


> 
> On 4/26/11 9:21 AM, "Simon Urbanek" <simon.urbanek at r-project.org> wrote:
> 
>> 
>> On Apr 26, 2011, at 7:30 AM, schattenpflanze at arcor.de wrote:
>> 
>>> I have tested the solutions suggested by Simon and Thomas on a Linux machine.
>>> These are my findings:
>>> 
>>>> On Windows you can look at the variable "UserBreak", available from
>>>> Rembedded.h. Outside of Windows, you can look at R_interrupts_pending,
>>>> available from R_ext/GraphicsDevice.h. R_ext/GraphicsDevice.h also has
>>>> R_interrupts_suspended, which you may or may not want to take into account,
>>>> depending on your use-case.
>>> I did not manage to get this to work. Neither R_interrupts_pending nor
>>> R_interrupts_suspended seem to change when I press ctrl+c. Perhaps this is
>>> due to the fact that I run R in a terminal without any graphical interface?
>>> 
>> 
>> Thomas' suggestion was not aimed at your problem - it was sort of the inverse
>> (more at your Qt question). If you want to interrupt R you can mess with those
>> flags and them let R run the event loop. It doesn't work in your (original)
>> case.
>> 
>> 
>>>> static void chkIntFn(void *dummy) {
>>>> R_CheckUserInterrupt();
>>>> }
>>>> // this will call the above in a top-level context so it won't longjmp-out
>>>> of your context
>>>> bool checkInterrupt() {
>>>> return (R_ToplevelExec(chkIntFn, NULL) == FALSE);
>>>> }
>>>> // your code somewhere ...
>>>> if (checkInterrupt()) { // user interrupted ... }
>>> This solution works perfectly! It takes slightly longer to call this function
>>> than the plan R_CheckUserInterrupt() call, but in any reasonable scenario,
>>> the additional time is absolutely insignificant.
>>> 
>>> Inside OpenMP parallel for constructs, one has to make sure that only the
>>> thread satisfying omp_get_thread_num()==0 makes the call (the 'master'
>>> construct cannot be nested inside a loop). I can then set a flag, which is
>>> queried by every thread in every loop cycle, causing fast termination of the
>>> parallel loop. After the loop, I throw an exception. Thus, my code is
>>> terminated gracefully with minimal effort. I can do additional cleanup
>>> operations (which usually is not necessary, since I use smart pointers), and
>>> report details on the interrupt to the user.
>>> 
>>> With my limited testing, so far I have not noticed any downsides. Of course,
>>> there is the obvious drawback of not being supported officially (and thus
>>> maybe being subject to change),
>> 
>> Actually, it is in the official API (Rinternals.h) so I don't think that is
>> the issue.
>> 
>> 
>>> the question of portability, and the question of interoperability with other
>>> errors.
>>> 
>> 
>> It is portable as well, so I'd say the main concern is what happens when
>> events trigger something that is not related to you and you eat those errors.
>> They will act as user-interrupt to you even if it's not what the user
>> intended. One could argue that it's the lesser of the evils, because if you
>> don't do anything R will just block so those events would have to wait until
>> you're done anyway.
>> 
>> 
>>> Moreover, I have found an old thread discussing almost the same topic:
>>> http://tolstoy.newcastle.edu.au/R/e4/devel/08/05/1686.html .
>>> The thread was created in 2008, so the issue is not really a new one. The
>>> solution proposed there is actually the same as the one suggested by Simon,
>>> namely using R_ToplevelExec().
>>> 
>> 
>> Interesting - I'm glad Luke also suggested C-level onexit bac then - it is
>> something I was thinking about before ..
>> 
>> Cheers,
>> Simon
>> 
>> 
>>> An officially supported, portable solution would of course be much
>>> appreciated!
>>> 
>>> 
>>> Best regards,
>>> Peter
>>> 
>>> 
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 
> 


From pdalgd at gmail.com  Wed Apr 27 09:55:55 2011
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 27 Apr 2011 09:55:55 +0200
Subject: [Rd] Wish R Core had a standard format (or generic function)
	for "newdata" objects
In-Reply-To: <4DB765DD.3060900@gmail.com>
References: <BANLkTikCjqUM9YJhYtgLh4Q-z=0mpmgp2A@mail.gmail.com>
	<4DB765DD.3060900@gmail.com>
Message-ID: <4B37D9F9-B5A5-4B35-BEFF-03F89D45EFE0@gmail.com>


On Apr 27, 2011, at 02:39 , Duncan Murdoch wrote:

> On 26/04/2011 11:13 AM, Paul Johnson wrote:
>> Is anybody working on a way to standardize the creation of "newdata"
>> objects for predict methods?

[snip]

>> I think it is time the R Core Team would look at this tell "us" what
>> is the right way to do this. I think the interface to setx in Zelig is
>> pretty easy to understand, at least for numeric variables.
> 
> If you don't like the way this was done in my three lines above, or by Frank Harrell, or the Zelig group, or John Fox, why don't you do it yourself, and get it right this time?  It's pretty rude to complain about things that others have given you for free, and demand they do it better.

Er... No, I don't think Paul is being particularly rude here (and he has been doing us some substantial favors in the past, notably his useful Rtips page). I know the kind of functionality he is looking for; e.g., SAS JMP has some rather nice interactive displays of regression effects for which you'll need to fill in "something" for the other variables. 

However, that being said, I agree with Duncan that we probably do not want to canonicalize any particular method of filling in "average" values for data frame variables. Whatever you do will be statistically dubious (in particular, using the mode of a factor variable gives me the creeps: Do a subgroup analysis and your "average person" switches from male to female?), so I think it is one of those cases where it is best to provide mechanism, not policy.

-- 
Peter Dalgaard
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From ligges at statistik.tu-dortmund.de  Wed Apr 27 10:16:29 2011
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Wed, 27 Apr 2011 10:16:29 +0200
Subject: [Rd] How to create vignette.pdf for R-2.13.0?
In-Reply-To: <4DB723F9.7090800@aon.at>
References: <4DB32D9F.5010406@aon.at>	<4DB42FB3.9090401@statistik.tu-dortmund.de>	<4DB472F8.9060903@aon.at>	<4DB489EC.9080301@statistik.tu-dortmund.de>	<4DB491BE.8080104@aon.at>	<4DB57E7A.1080507@statistik.tu-dortmund.de>
	<4DB5AFD4.9020303@aon.at> <4DB5B6B0.90607@gmail.com>
	<4DB5C286.40306@aon.at> <4DB5C38D.6030400@gmail.com>
	<4DB5C87C.5040905@aon.at> <4DB5CBFD.6050508@gmail.com>
	<4DB723F9.7090800@aon.at>
Message-ID: <4DB7D0DD.6040201@statistik.tu-dortmund.de>



On 26.04.2011 21:58, cstrato wrote:
> Dear Duncan, dear Uwe,
>
> Just now I have re-run everything, and today xps.Rnw can be converted to
> a vignette w/o any problems using:
> a, buildVignettes("xps", dir="/Volumes/CoreData/CRAN/xps", quiet=F)
> b, R CMD Sweave xps.Rnw
>
> In both cases the vignette xps.pdf is created (maybe my Mac did not like
> to work during eastern holidays).
>
> However, one issue remains:
> "R64 CMD check xps_1.13.1.tar.gz" no longer creates any pdf files for
> the vignettes.


Dioes it give an error or warning? It should check the code. R CMD build 
creates the pdf files.

Uwe Ligges

>
> Best regards
> Christian
>
>
> On 4/25/11 9:31 PM, Duncan Murdoch wrote:
>> On 25/04/2011 3:16 PM, cstrato wrote:
>>> Thank you.
>>>
>>> My problem seems to be that at the moment the problem can be seen only
>>> on my Mac, since e.g. the Bioconductor servers have no problems creating
>>> the vignettes.
>>
>> Then you are definitely the one in the best position to diagnose the
>> problem. Use the usual approach: simplify it by cutting out everything
>> that looks unrelated. Verify that the problem still exists, then cut
>> some more. Eventually you'll have isolated the error to a particular
>> small snippet of code, and then you can add print() statements, or use
>> trace(), or do whatever is necessary to see what's so special about your
>> system.
>>
>> I suspect it will turn out to be an assumption in the code that is not
>> true on your system.
>>
>> If the assumption is being made by code you wrote, then fix it. If it's
>> being made by R, let us know.
>>
>> Duncan Murdoch
>>
>>>
>>> Best regards
>>> Christian
>>>
>>> On 4/25/11 8:55 PM, Duncan Murdoch wrote:
>>>> cstrato wrote:
>>>>> Dear Duncan,
>>>>>
>>>>> Thank you for your example, however it is different since it does not
>>>>> use x and y. What about print(x+y)?
>>>>
>>>> Try it.
>>>>
>>>>>
>>>>> Sorry, I do not believe that there is a bug in my code, since:
>>>>> 1, it worked in all versions from R starting with R-2.6.0 till
>>>>> R-2.12.2.
>>>>> 2, the identical code works in the examples
>>>>> 3, this code (or a similar code) is the starting code which all users
>>>>> of xps have to use, and there was never a problem.
>>>>
>>>> This might be a problem in R, or might be a problem in your code. As
>>>> far
>>>> as I know, it has only shown up in your code, so I'd guess that's where
>>>> the problem is. In any case, you're the one in the best position to
>>>> isolate it and debug it.
>>>>
>>>> If it turns out to be a problem in R, put together an example
>>>> illustrating the problem that doesn't involve your code, and I'll
>>>> take a
>>>> look.
>>>>
>>>> Duncan Murdoch
>>>>
>>>>>
>>>>> Maybe the reason could be that my code has to import
>>>>> - the CEL-files from the package dir
>>>>> - the file SchemeTest3.root from the package dir
>>>>> ??
>>>>>
>>>>> Best regards
>>>>> Christian
>>>>>
>>>>> On 4/25/11 8:00 PM, Duncan Murdoch wrote:
>>>>>> cstrato wrote:
>>>>>>> Dear Uwe,
>>>>>>>
>>>>>>> Your suggestion to look at the Sweave manual helped me to solve the
>>>>>>> problem. It seems that in R-2.13.0 every chunk can use the code from
>>>>>>> the chunk before but not from an earlier chunk.
>>>>>> I'm either misreading what you wrote, or it's wrong. If I have this
>>>>>> in a
>>>>>> Sweave file:
>>>>>>
>>>>>> <<>>=
>>>>>> x<- 1
>>>>>> @
>>>>>>
>>>>>> <<>>=
>>>>>> y<- 2
>>>>>> @
>>>>>>
>>>>>> <<>>=
>>>>>> print(x)
>>>>>> @
>>>>>>
>>>>>> I will see the value of x getting printed, even though it came from
>>>>>> two
>>>>>> chunks earlier.
>>>>>>
>>>>>> I think Uwe is right: there is some bug in the code you're running.
>>>>>> Sweave isn't the problem.
>>>>>>
>>>>>> Duncan Murdoch
>>>>>>
>>>>>>> Concretely, the following does not work since chunk 5 needs the code
>>>>>>> from chunk 3 and 4:
>>>>>>>
>>>>>>> ###################################################
>>>>>>> ### chunk number 3:
>>>>>>> ###################################################
>>>>>>> #line 126 "xps.Rnw"
>>>>>>> celdir<- file.path(.path.package("xps"), "raw")
>>>>>>>
>>>>>>> ###################################################
>>>>>>> ### chunk number 4:
>>>>>>> ###################################################
>>>>>>> #line 132 "xps.Rnw"
>>>>>>> scheme.test3<- root.scheme(file.path(.path.package("xps"),
>>>>>>> "schemes",
>>>>>>> "SchemeTest3.root"))
>>>>>>>
>>>>>>> ###################################################
>>>>>>> ### chunk number 5:
>>>>>>> ###################################################
>>>>>>> #line 137 "xps.Rnw"
>>>>>>> celfiles<- c("TestA1.CEL","TestA2.CEL")
>>>>>>> data.test3<- import.data(scheme.test3, "tmpdt_DataTest3",
>>>>>>> celdir=celdir, celfiles=celfiles, verbose=FALSE)
>>>>>>>
>>>>>>>
>>>>>>> However, when I add "celdir" to chunk 5 then everything works since
>>>>>>> now chunk 5 needs only the code from chunk 4 but not from chunk 3:
>>>>>>>
>>>>>>> ###################################################
>>>>>>> ### chunk number 5:
>>>>>>> ###################################################
>>>>>>> #line 137 "xps.Rnw"
>>>>>>> celdir<- file.path(.path.package("xps"), "raw")
>>>>>>> celfiles<- c("TestA1.CEL","TestA2.CEL")
>>>>>>> data.test3<- import.data(scheme.test3, "tmpdt_DataTest3",
>>>>>>> celdir=celdir, celfiles=celfiles, verbose=FALSE)
>>>>>>>
>>>>>>>
>>>>>>> Now buildVignettes() is able to create the vignettes, however R CMD
>>>>>>> check still does not build the vignettes.
>>>>>>>
>>>>>>>
>>>>>>> Yes, I get a Warning in both cases:
>>>>>>> * checking package vignettes in 'inst/doc' ... WARNING
>>>>>>> Package vignettes without corresponding PDF: ........
>>>>>>>
>>>>>>> However, with R-2.12.2 the following lines are added:
>>>>>>>
>>>>>>> /Volumes/CoreData/CRAN/xps.Rcheck/00_pkg_src/xps/inst/doc/APTvsXPS.Rnw
>>>>>>>
>>>>>>>
>>>>>>> /Volumes/CoreData/CRAN/xps.Rcheck/00_pkg_src/xps/inst/doc/xps.Rnw
>>>>>>> /Volumes/CoreData/CRAN/xps.Rcheck/00_pkg_src/xps/inst/doc/xpsClasses.Rnw
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>> /Volumes/CoreData/CRAN/xps.Rcheck/00_pkg_src/xps/inst/doc/xpsPreprocess.Rnw
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>> and in xps.Rcheck the subdirectory "inst/doc" will be created which
>>>>>>> contains the vignette data such as xps.Rnw, but also xps.tex and
>>>>>>> xps.pdf.
>>>>>>>
>>>>>>> In contrast, R-2.13.0 does not create the subdirectory "inst/doc"
>>>>>>> and
>>>>>>> no vignettes are built.
>>>>>>>
>>>>>>> One more issue:
>>>>>>> In contrast to my former believe R CMD INSTALL does not build the
>>>>>>> vignettes, neither in R-2.12.2 nor in R-2.13.0. I have to run
>>>>>>> buildVignettes() after installation. Is this the usual case?
>>>>>>>
>>>>>>> Best regards
>>>>>>> Christian
>>>>>>>
>>>>>>>
>>>>>>> On 4/25/11 4:00 PM, Uwe Ligges wrote:
>>>>>>>> On 24.04.2011 23:10, cstrato wrote:
>>>>>>>>> Dear Uwe,
>>>>>>>>>
>>>>>>>>> On 4/24/11 10:37 PM, Uwe Ligges wrote:
>>>>>>>>>> On 24.04.2011 20:59, cstrato wrote:
>>>>>>>>>>> Dear Uwe,
>>>>>>>>>>>
>>>>>>>>>>> Thank you for your reply.
>>>>>>>>>>>
>>>>>>>>>>> ad 2, Yes, i know that "xps-manual.pdf" is the collection of
>>>>>>>>>>> help
>>>>>>>>>>> pages,
>>>>>>>>>>> I have mentioned it only to show that creating pdf-files does
>>>>>>>>>>> work
>>>>>>>>>>> for
>>>>>>>>>>> R-2.13.0.
>>>>>>>>>>>
>>>>>>>>>>> ad 1, Could it be that this is a Mac-specific problem since I
>>>>>>>>>>> see
>>>>>>>>>>> it on
>>>>>>>>>>> both my old MacBook Pro and my new Mac Mini.
>>>>>>>>>> Have you tried on any other OS? I did not since installing
>>>>>>>>>> root is
>>>>>>>>>> a bit
>>>>>>>>>> too much effort.
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>> No, until now I did not try another OS, but I will, since xps
>>>>>>>>> has to
>>>>>>>>> work on all three OSes.
>>>>>>>>>
>>>>>>>>>>> Using R CMD check with R-2.12.2 I get:
>>>>>>>>>> I thought we are talking about R-2.13.0?
>>>>>>>>>>
>>>>>>>>> I showed you the output of R-2.12.2 first and then the output of
>>>>>>>>> R-2.13.0, so that you can see that on the same machine with the
>>>>>>>>> same
>>>>>>>>> file it works with one version but not the other.
>>>>>>>> But you got a Warning in both cases:
>>>>>>>> * checking package vignettes in 'inst/doc' ... WARNING
>>>>>>>> Package vignettes without corresponding PDF: ........
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>>>> Where is the R CMD build output (since R CMD build is supposed to
>>>>>>>>>> prepare the vignette).
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>>> $ R64 CMD check xps_1.13.1.tar.gz
>>>>>>>>>>> * using log directory '/Volumes/CoreData/CRAN/xps.Rcheck'
>>>>>>>>>>> * using R version 2.12.2 (2011-02-25)
>>>>>>>>>>> * using platform: x86_64-apple-darwin9.8.0 (64-bit)
>>>>>>>>>>> * using session charset: ASCII
>>>>>>>>>>> * checking for file 'xps/DESCRIPTION' ... OK
>>>>>>>>>>> * this is package 'xps' version '1.13.1'
>>>>>>>>>>> ...
>>>>>>>>>>> ...
>>>>>>>>>>> * checking package vignettes in 'inst/doc' ... WARNING
>>>>>>>>>>> Package vignettes without corresponding PDF:
>>>>>>>>>>>
>>>>>>>>>>> /Volumes/CoreData/CRAN/xps.Rcheck/00_pkg_src/xps/inst/doc/APTvsXPS.Rnw
>>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>>> /Volumes/CoreData/CRAN/xps.Rcheck/00_pkg_src/xps/inst/doc/xps.Rnw
>>>>>>>>>>>
>>>>>>>>>>> /Volumes/CoreData/CRAN/xps.Rcheck/00_pkg_src/xps/inst/doc/xpsClasses.Rnw
>>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>>> /Volumes/CoreData/CRAN/xps.Rcheck/00_pkg_src/xps/inst/doc/xpsPreprocess.Rnw
>>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>>> * checking PDF version of manual ... OK
>>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>>> Using "RSwitch.app" I switch to R-2.13.0, but now I get:
>>>>>>>>>>>
>>>>>>>>>>> $ R64 CMD check xps_1.13.1.tar.gz
>>>>>>>>>>> * using log directory '/Volumes/CoreData/CRAN/xps.Rcheck'
>>>>>>>>>>> * using R version 2.13.0 (2011-04-13)
>>>>>>>>>>> * using platform: x86_64-apple-darwin9.8.0 (64-bit)
>>>>>>>>>>> * using session charset: ASCII
>>>>>>>>>>> * checking for file 'xps/DESCRIPTION' ... OK
>>>>>>>>>>> * this is package 'xps' version '1.13.1'
>>>>>>>>>>> ...
>>>>>>>>>>> ...
>>>>>>>>>>> * checking package vignettes in 'inst/doc' ... WARNING
>>>>>>>>>>> Package vignette(s) without corresponding PDF:
>>>>>>>>>>> APTvsXPS.Rnw
>>>>>>>>>>> xps.Rnw
>>>>>>>>>>> xpsClasses.Rnw
>>>>>>>>>>> xpsPreprocess.Rnw
>>>>>>>>>>>
>>>>>>>>>>> * checking running R code from vignettes ... OK
>>>>>>>>>>> * checking re-building of vignettes ... OK
>>>>>>>>>>> * checking PDF version of manual ... OK
>>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>>> I must admit that I have never built the vignettes manually,
>>>>>>>>>>> and I
>>>>>>>>>>> cannot find a hint how I can do it from the command line. Is
>>>>>>>>>>> this
>>>>>>>>>>> possible?
>>>>>>>>> Is it possible to build the vignettes from the command line?
>>>>>>>> R --help suggests there is
>>>>>>>> R CMD Sweave .....
>>>>>>>>
>>>>>>>>
>>>>>>>>>>> However, building the vignettes within R-2.13.0 I get:
>>>>>>>>>>>> library(tools)
>>>>>>>>>>>> buildVignettes("xps", dir="/Volumes/CoreData/CRAN/xps",
>>>>>>>>>>>> quiet=F)
>>>>>>>>>>> Overfull \vbox (21.68121pt too high) has occurred while
>>>>>>>>>>> \output is
>>>>>>>>>>> Writing to file xps.tex
>>>>>>>>>>> Processing code chunks with options ...
>>>>>>>>>>> 1 : term verbatim
>>>>>>>>>>> 2 : echo term hide
>>>>>>>>>>> 3 : echo term verbatim
>>>>>>>>>>> 4 : echo term verbatim
>>>>>>>>>>> 5 : echo term verbatim
>>>>>>>>>>> SysError in<TFile::TFile>: file
>>>>>>>>>>> /tmpdt_DataTest3_cel.root/tmpdt_DataTest3_cel_20110424_201301.root
>>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>>> can
>>>>>>>>>>> not be opened (No such file or directory)
>>>>>>>>>>> Error: Could not create file</tmpdt_DataTest3_cel.root>
>>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>>> Here are the two important chunks 4 and 5, which work fine with
>>>>>>>>>>> R-2.12.2
>>>>>>>>>>> and earlier versions:
>>>>>>>>>>>
>>>>>>>>>>> ###################################################
>>>>>>>>>>> ### chunk number 4:
>>>>>>>>>>> ###################################################
>>>>>>>>>>> #line 132 "xps.Rnw"
>>>>>>>>>>> scheme.test3<- root.scheme(file.path(.path.package("xps"),
>>>>>>>>>>> "schemes",
>>>>>>>>>>> "SchemeTest3.root"))
>>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>>> ###################################################
>>>>>>>>>>> ### chunk number 5:
>>>>>>>>>>> ###################################################
>>>>>>>>>>> #line 137 "xps.Rnw"
>>>>>>>>>>> celfiles<- c("TestA1.CEL","TestA2.CEL")
>>>>>>>>>>> data.test3<- import.data(scheme.test3, "tmpdt_DataTest3",
>>>>>>>>>>> celdir=celdir, celfiles=celfiles, verbose=FALSE)
>>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>>> However, in R-2.13.0 chunk 5 crashes!!!
>>>>>>>>>>> It works only when replacing chunk 5 with:
>>>>>>>>>>>
>>>>>>>>>>> ###################################################
>>>>>>>>>>> ### chunk number 5:
>>>>>>>>>>> ###################################################
>>>>>>>>>>> #line 137 "xps.Rnw"
>>>>>>>>>>> celfiles<- c("TestA1.CEL","TestA2.CEL")
>>>>>>>>>>> scheme.test3<- root.scheme(file.path(.path.package("xps"),
>>>>>>>>>>> "schemes",
>>>>>>>>>>> "SchemeTest3.root"))
>>>>>>>>>>> data.test3<- import.data(scheme.test3, "tmpdt_DataTest3",
>>>>>>>>>>> celdir=celdir, celfiles=celfiles, verbose=FALSE)
>>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>>> As you see R-2.13.0 does no longer remember the result of
>>>>>>>>>>> chunk 4,
>>>>>>>>>>> i.e.
>>>>>>>>>>> "scheme.test3". Now I have to include the line defining
>>>>>>>>>>> "scheme.test3"
>>>>>>>>>>> also in chunk 5.
>>>>>>>>>> How objects generated in one chunk can be reused later on is
>>>>>>>>>> explained
>>>>>>>>>> in the Sweave manual.
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>>> Do you have any idea for this behavior?
>>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>>> An example, which does work in R-2.13.0 are the following two
>>>>>>>>>>> chunks:
>>>>>>>>>>>
>>>>>>>>>>> #################################################
>>>>>>>>>>> ### chunk number 20:
>>>>>>>>>>> ###################################################
>>>>>>>>>>> #line 300 "xps.Rnw"
>>>>>>>>>>> library(xps)
>>>>>>>>>>> scheme.test3<- root.scheme(file.path(.path.package("xps"),
>>>>>>>>>>> "schemes",
>>>>>>>>>>> "SchemeTest3.root"))
>>>>>>>>>>> data.test3<- root.data(scheme.test3,
>>>>>>>>>>> file.path(.path.package("xps"),"rootdata",
>>>>>>>>>>> "DataTest3_cel.root"))
>>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>>> ###################################################
>>>>>>>>>>> ### chunk number 21:
>>>>>>>>>>> ###################################################
>>>>>>>>>>> #line 318 "xps.Rnw"
>>>>>>>>>>> data.rma<- rma(data.test3, "tmpdt_Test3RMA", verbose=FALSE)
>>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>>> In summary it is not quite clear to me what has changed in
>>>>>>>>>>> R-2.13.0 so
>>>>>>>>>>> that chunk 5 no longer works.
>>>>>>>>>>>
>>>>>>>>>>> BTW, the error:
>>>>>>>>>>> SysError in<TFile::TFile>: file
>>>>>>>>>>> /tmpdt_DataTest3_cel.root/tmpdt_DataTest3_cel_20110424_201301.root
>>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>>> can
>>>>>>>>>>> not be opened
>>>>>>>>>>> is not clear to me since "/tmpdt_DataTest3_cel.root/" is
>>>>>>>>>>> definitively
>>>>>>>>>>> NOT a directory.
>>>>>>>>>> Time to debug what root.scheme is doing with the supplied path.
>>>>>>>>>>
>>>>>>>>> Sorry, I do not understand what you mean. root.scheme does not
>>>>>>>>> change
>>>>>>>>> the path, otherwise it would not work on all older versions of R.
>>>>>>>> Right, but since something changed obviously, and you tell us the
>>>>>>>> path
>>>>>>>> is not a path, it might be a function used by root.scheme ....
>>>>>>>> That's
>>>>>>>> why I said time to debug the code in your vignette!
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>>>>> Do you have any ideas?
>>>>>>>>>>>
>>>>>>>>>>> Please note that the vignette "xps.Rnw" did work for the last
>>>>>>>>>>> two
>>>>>>>>>>> years
>>>>>>>>>>> w/o problem. Furthermore, the Bioconductor servers are able to
>>>>>>>>>>> build
>>>>>>>>>>> the
>>>>>>>>>>> vignette, see:
>>>>>>>>>>> http://www.bioconductor.org/packages/release/bioc/html/xps.html
>>>>>>>>>> See
>>>>>>>>>> http://bioconductor.org/checkResults/2.8/bioc-20110225/xps/liverpool-checksrc.html
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>> and find that their Mac Servers are also fine with it. So maybe
>>>>>>>>>> it is
>>>>>>>>>> your setup that is corrupted?
>>>>>>>>> Maybe, you are right that my setup is corrupted, but on two
>>>>>>>>> independent
>>>>>>>>> machines?
>>>>>>>>>
>>>>>>>>> Maybe the download of "R-2.13.0.pkg" is corrupted, but then
>>>>>>>>> nothing
>>>>>>>>> should work, or am I wrong?
>>>>>>>>>
>>>>>>>>> How can I check if my setup is corrupted?
>>>>>>>> By debugging the code in your package's vignette.
>>>>>>>>
>>>>>>>> Uwe Ligges
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>>> Best regards
>>>>>>>>> Christian
>>>>>>>>>
>>>>>>>>>> Best wishes,
>>>>>>>>>> Uwe
>>>>>>>>>>
>>>>>>>>>>> Best regards
>>>>>>>>>>> Christian
>>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>>> On 4/24/11 4:12 PM, Uwe Ligges wrote:
>>>>>>>>>>>> On 23.04.2011 21:50, cstrato wrote:
>>>>>>>>>>>>> Dear all,
>>>>>>>>>>>>>
>>>>>>>>>>>>> While R CMD check and R CMD INSTALL have always created the
>>>>>>>>>>>>> vignettes on
>>>>>>>>>>>>> R-2.12.1 or any earlier versions of R, I am no longer able to
>>>>>>>>>>>>> build
>>>>>>>>>>>>> the
>>>>>>>>>>>>> vignettes on R-2.13.0.
>>>>>>>>>>>>>
>>>>>>>>>>>>> Instead R CMD check gives me the following output:
>>>>>>>>>>>>>
>>>>>>>>>>>>> * checking for unstated dependencies in vignettes ... OK
>>>>>>>>>>>>> * checking package vignettes in 'inst/doc' ... WARNING
>>>>>>>>>>>>> Package vignette(s) without corresponding PDF:
>>>>>>>>>>>>> APTvsXPS.Rnw
>>>>>>>>>>>>> xps.Rnw
>>>>>>>>>>>>> xpsClasses.Rnw
>>>>>>>>>>>>> xpsPreprocess.Rnw
>>>>>>>>>>>>>
>>>>>>>>>>>>> * checking running R code from vignettes ... OK
>>>>>>>>>>>>> * checking re-building of vignettes ... OK
>>>>>>>>>>>>> * checking PDF version of manual ... OK
>>>>>>>>>>>>>
>>>>>>>>>>>>>
>>>>>>>>>>>>> Does someone know what the reason might be?
>>>>>>>>>>>> No, it does for me for other packages.
>>>>>>>>>>>> Perhaps an error when processing the vignettes? Have you
>>>>>>>>>>>> tried to
>>>>>>>>>>>> build
>>>>>>>>>>>> them manually?
>>>>>>>>>>>>
>>>>>>>>>>>>
>>>>>>>>>>>>> (R64 CMD check --help says that be default
>>>>>>>>>>>>> rebuild-vignettes is
>>>>>>>>>>>>> turned
>>>>>>>>>>>>> on.)
>>>>>>>>>>>>>
>>>>>>>>>>>>> Interestingly, R CMD check still creates the file
>>>>>>>>>>>>> "xps-manual.pdf".
>>>>>>>>>>>> That is the collection of help pages, unrelated to the
>>>>>>>>>>>> vignette.
>>>>>>>>>>>>
>>>>>>>>>>>>
>>>>>>>>>>>> Uwe Ligges
>>>>>>>>>>>>
>>>>>>>>>>>>
>>>>>>>>>>>>
>>>>>>>>>>>>> Here is my sessionInfo:
>>>>>>>>>>>>>
>>>>>>>>>>>>>> sessionInfo()
>>>>>>>>>>>>> R version 2.13.0 (2011-04-13)
>>>>>>>>>>>>> Platform: x86_64-apple-darwin9.8.0/x86_64 (64-bit)
>>>>>>>>>>>>>
>>>>>>>>>>>>> locale:
>>>>>>>>>>>>> [1] C
>>>>>>>>>>>>>
>>>>>>>>>>>>> attached base packages:
>>>>>>>>>>>>> [1] stats graphics grDevices utils datasets methods base
>>>>>>>>>>>>>
>>>>>>>>>>>>> other attached packages:
>>>>>>>>>>>>> [1] xps_1.13.1
>>>>>>>>>>>>>
>>>>>>>>>>>>> loaded via a namespace (and not attached):
>>>>>>>>>>>>> [1] Biobase_2.12.1 Biostrings_2.20.0 IRanges_1.10.0
>>>>>>>>>>>>> [4] affy_1.30.0 affyPLM_1.28.5 affyio_1.20.0
>>>>>>>>>>>>> [7] preprocessCore_1.14.0
>>>>>>>>>>>>>
>>>>>>>>>>>>> Thank you in advance.
>>>>>>>>>>>>> Best regards
>>>>>>>>>>>>> Christian
>>>>>>>>>>>>> _._._._._._._._._._._._._._._._._._
>>>>>>>>>>>>> C.h.r.i.s.t.i.a.n S.t.r.a.t.o.w.a
>>>>>>>>>>>>> V.i.e.n.n.a A.u.s.t.r.i.a
>>>>>>>>>>>>> e.m.a.i.l: cstrato at aon.at
>>>>>>>>>>>>> _._._._._._._._._._._._._._._._._._
>>>>>>>>>>>>>
>>>>>>>>>>>>> ______________________________________________
>>>>>>>>>>>>> R-devel at r-project.org mailing list
>>>>>>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>>>>>>>> ______________________________________________
>>>>>>>>>>> R-devel at r-project.org mailing list
>>>>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>>>> ______________________________________________
>>>>>>> R-devel at r-project.org mailing list
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>>>
>>>>
>>>>
>>
>>


From ggrothendieck at gmail.com  Wed Apr 27 12:46:54 2011
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Wed, 27 Apr 2011 06:46:54 -0400
Subject: [Rd] Wish R Core had a standard format (or generic function)
 for "newdata" objects
In-Reply-To: <4B37D9F9-B5A5-4B35-BEFF-03F89D45EFE0@gmail.com>
References: <BANLkTikCjqUM9YJhYtgLh4Q-z=0mpmgp2A@mail.gmail.com>
	<4DB765DD.3060900@gmail.com>
	<4B37D9F9-B5A5-4B35-BEFF-03F89D45EFE0@gmail.com>
Message-ID: <BANLkTinwYoVVrg4aDDjfFmqdqgRoByDnjw@mail.gmail.com>

On Wed, Apr 27, 2011 at 3:55 AM, peter dalgaard <pdalgd at gmail.com> wrote:
>
> On Apr 27, 2011, at 02:39 , Duncan Murdoch wrote:
>
>> On 26/04/2011 11:13 AM, Paul Johnson wrote:
>>> Is anybody working on a way to standardize the creation of "newdata"
>>> objects for predict methods?
>
> [snip]
>
>>> I think it is time the R Core Team would look at this tell "us" what
>>> is the right way to do this. I think the interface to setx in Zelig is
>>> pretty easy to understand, at least for numeric variables.
>>
>> If you don't like the way this was done in my three lines above, or by Frank Harrell, or the Zelig group, or John Fox, why don't you do it yourself, and get it right this time? ?It's pretty rude to complain about things that others have given you for free, and demand they do it better.
>
> Er... No, I don't think Paul is being particularly rude here (and he has been doing us some substantial favors in the past, notably his useful Rtips page). I know the kind of functionality he is looking for; e.g., SAS JMP has some rather nice interactive displays of regression effects for which you'll need to fill in "something" for the other variables.
>
> However, that being said, I agree with Duncan that we probably do not want to canonicalize any particular method of filling in "average" values for data frame variables. Whatever you do will be statistically dubious (in particular, using the mode of a factor variable gives me the creeps: Do a subgroup analysis and your "average person" switches from male to female?), so I think it is one of those cases where it is best to provide mechanism, not policy.
>

That could be satisfied by defining a generic in the core of R without
any methods.  Then individual packages or analyses could provide those
in the way they see fit.  As long as the packages or analyses are
working with objects of different classes they would not conflict.


-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From therneau at mayo.edu  Wed Apr 27 15:27:20 2011
From: therneau at mayo.edu (Terry Therneau)
Date: Wed, 27 Apr 2011 08:27:20 -0500
Subject: [Rd] standard format for newdata objects
In-Reply-To: <mailman.21.1303898407.22574.r-devel@r-project.org>
References: <mailman.21.1303898407.22574.r-devel@r-project.org>
Message-ID: <1303910840.22086.20.camel@nemo>


On Wed, 2011-04-27 at 12:00 +0200, Peter Dalgaard wrote:
> Er... No, I don't think Paul is being particularly rude here (and he
> has been doing us some substantial favors in the past, notably his
> useful Rtips page). I know the kind of functionality he is looking
> for; e.g., SAS JMP has some rather nice interactive displays of
> regression effects for which you'll need to fill in "something" for
> the other variables. 
> 
> However, that being said, I agree with Duncan that we probably do not
> want to canonicalize any particular method of filling in "average"
> values for data frame variables. Whatever you do will be statistically
> dubious (in particular, using the mode of a factor variable gives me
> the creeps: Do a subgroup analysis and your "average person" switches
> from male to female?), so I think it is one of those cases where it is
> best to provide mechanism, not policy.
> 

  I agree with Peter.  There are two tasks in newdata: deciding what the
default reference levels should be, and building the data frame with
those levels.  It's the first part that is hard. For survival curves
from a Cox model the historical default has been to use the mean of each
covariate, which can be awful (sex coded as 0/1 leads to prediction for
a hermaphrodite?).  Nevertheless, I've not been able to think of a
strategy that would give sensible answers for most of the data I use and
coxph retains the flawed default for lack of a better idea.  When
teaching a class on this, I tell listeners "bite the bullet" and build
the newdata that makes clinical sense, because package defaults are
always unwise for some of the variables.  How can a package possibly
know that it should use bilirubin=1.0 (upper limit of normal) and AST =
45 when the data set is one of my liver transplant studies?
   Frank Harrell would argue that his "sometimes misguided" default in
cph is better than the "almost always wrong" one in coxph though, and
there is certainly some strength in that position.

Terry Therneau


From dutangc at gmail.com  Wed Apr 27 15:52:04 2011
From: dutangc at gmail.com (Christophe Dutang)
Date: Wed, 27 Apr 2011 15:52:04 +0200
Subject: [Rd] on the Distribution task view
Message-ID: <BANLkTinMD1pLgyf35mDMO6xuW3Se5NW67w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110427/329f57be/attachment.pl>

From pauljohn32 at gmail.com  Wed Apr 27 18:20:28 2011
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Wed, 27 Apr 2011 11:20:28 -0500
Subject: [Rd] Wish R Core had a standard format (or generic function)
 for "newdata" objects
In-Reply-To: <4DB765DD.3060900@gmail.com>
References: <BANLkTikCjqUM9YJhYtgLh4Q-z=0mpmgp2A@mail.gmail.com>
	<4DB765DD.3060900@gmail.com>
Message-ID: <BANLkTinj6JPi=gXFuPXrZ9ZGrVv4RDbRCw@mail.gmail.com>

On Tue, Apr 26, 2011 at 7:39 PM, Duncan Murdoch
<murdoch.duncan at gmail.com> wrote:

> If you don't like the way this was done in my three lines above, or by Frank
> Harrell, or the Zelig group, or John Fox, why don't you do it yourself, and
> get it right this time? ?It's pretty rude to complain about things that
> others have given you for free, and demand they do it better.
>
> Duncan Murdoch
>

I offer sincere apology for sounding that way.  I'm not attacking
anybody. I'm just talking, asking don't you agree this were
standardized.  And you disagree, and I respect that since you are
actually doing the work.

>From a "lowly user's point of view", I wish "you experts" out there
would tell us one way to do this, we could follow your example.

When there's a regression model fitted with 20 variables in it, and
half of them are numeric, 4 are unordered factors, 3 are ordinal
factors, and what not, then this is a hard problem for many of us
ordinary users.  Or it is tedious.  They want "keep everything fixed,"
except one variable that takes on different specified values.  And
they want to do that for every variable, one at a time.

Stata has made this easy for many models, R could as well, if we
coalesced on a more-or-less standard way to create newdata objects for
predict.

But, in the end, I agree with your sentiment.  I just have to do this,
show you it is handy.  I think Zelig's setx has it about right, I'll
pursue that strategy.

pj
-- 
Paul E. Johnson
Professor, Political Science
1541 Lilac Lane, Room 504
University of Kansas


From dutangc at gmail.com  Wed Apr 27 18:53:59 2011
From: dutangc at gmail.com (Christophe Dutang)
Date: Wed, 27 Apr 2011 18:53:59 +0200
Subject: [Rd] Wish R Core had a standard format (or generic function)
 for "newdata" objects
In-Reply-To: <BANLkTikCjqUM9YJhYtgLh4Q-z=0mpmgp2A@mail.gmail.com>
References: <BANLkTikCjqUM9YJhYtgLh4Q-z=0mpmgp2A@mail.gmail.com>
Message-ID: <BANLkTinWouqSm=kFioCFO7hVkPU9-nJTig@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110427/0cab5a00/attachment.pl>

From pburns at pburns.seanet.com  Wed Apr 27 19:44:55 2011
From: pburns at pburns.seanet.com (Patrick Burns)
Date: Wed, 27 Apr 2011 18:44:55 +0100
Subject: [Rd] median and data frames
Message-ID: <4DB85617.8090706@pburns.seanet.com>

Here are some data frames:

df3.2 <- data.frame(1:3, 7:9)
df4.2 <- data.frame(1:4, 7:10)
df3.3 <- data.frame(1:3, 7:9, 10:12)
df4.3 <- data.frame(1:4, 7:10, 10:13)
df3.4 <- data.frame(1:3, 7:9, 10:12, 15:17)
df4.4 <- data.frame(1:4, 7:10, 10:13, 15:18)

Now here are some commands and their answers:

 > median(df3.2)
[1] 2 8
 > median(df4.2)
[1] 2.5 8.5
 > median(df3.3)
   NA
1  7
2  8
3  9
 > median(df4.3)
   NA
1  7
2  8
3  9
4 10
 > median(df3.4)
[1]  8 11
 > median(df4.4)
[1]  8.5 11.5
 > median(df3.2[c(1,2,3),])
[1] 2 8
 > median(df3.2[c(1,3,2),])
[1]  2 NA
Warning message:
In mean.default(X[[2L]], ...) :
   argument is not numeric or logical: returning NA



The sessionInfo is below, but it looks
to me like the present behavior started
in 2.10.0.

Sometimes it gets the right answer.  I'd
be grateful to hear how it does that -- I
can't figure it out.

Under the current regime we can get numbers
that are correct, partially correct, or sort
of random (given the intention).

I claim that much better behavior would be
to always get exactly one of the following:

* a numeric answer (that is consistently correct)
* an error

I would think a method in analogy to
'mean.data.frame' would be a logical choice.
But I'm presuming there might be an argument
against that or 'median.data.frame' would already
exist.


 > sessionInfo()
R version 2.13.0 (2011-04-13)
Platform: i386-pc-mingw32/i386 (32-bit)

locale:
[1] LC_COLLATE=English_United Kingdom.1252
[2] LC_CTYPE=English_United Kingdom.1252
[3] LC_MONETARY=English_United Kingdom.1252
[4] LC_NUMERIC=C
[5] LC_TIME=English_United Kingdom.1252

attached base packages:
[1] graphics  grDevices utils     datasets  stats     methods   base

other attached packages:
[1] xts_0.8-0 zoo_1.6-5

loaded via a namespace (and not attached):
[1] grid_2.13.0     lattice_0.19-23 tools_2.13.0

-- 
Patrick Burns
pburns at pburns.seanet.com
twitter: @portfolioprobe
http://www.portfolioprobe.com/blog
http://www.burns-stat.com
(home of 'Some hints for the R beginner'
and 'The R Inferno')


From pdalgd at gmail.com  Wed Apr 27 20:56:17 2011
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 27 Apr 2011 20:56:17 +0200
Subject: [Rd] median and data frames
In-Reply-To: <4DB85617.8090706@pburns.seanet.com>
References: <4DB85617.8090706@pburns.seanet.com>
Message-ID: <5B2235D4-FB9D-4692-8A68-AE5DDC0E2819@gmail.com>


On Apr 27, 2011, at 19:44 , Patrick Burns wrote:

> I would think a method in analogy to
> 'mean.data.frame' would be a logical choice.
> But I'm presuming there might be an argument
> against that or 'median.data.frame' would already
> exist.

Only if someone had a better plan. As you are probably well aware, what you are currently seeing is a rather exquisite mashup of methods getting applied to objects they shouldn't be applied to. Some curious effects are revealed, e.g. this little beauty:

> sort(df3.3)
Error in `[.data.frame`(x, order(x, na.last = na.last, decreasing = decreasing)) : 
  undefined columns selected
> names(df3.3)<-NULL
> sort(df3.3)
  NA NA NA   NA   NA   NA   NA   NA   NA
1  1  7 10 NULL NULL NULL NULL NULL NULL
2  2  8 11 <NA> <NA> <NA> <NA> <NA> <NA>
3  3  9 12 <NA> <NA> <NA> <NA> <NA> <NA>
Warning message:
In format.data.frame(x, digits = digits, na.encode = FALSE) :
  corrupt data frame: columns will be truncated or padded with NAs


-- 
Peter Dalgaard
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From sean.mcguffee at gmail.com  Wed Apr 27 21:21:12 2011
From: sean.mcguffee at gmail.com (Sean Robert McGuffee)
Date: Wed, 27 Apr 2011 15:21:12 -0400
Subject: [Rd] Thread synchronization [Was: Interrupting C++ code
	execution]
In-Reply-To: <E025FC94-D808-4098-AF1F-4A26BBA25A3C@r-project.org>
Message-ID: <C9DDE4E8.3EEC%sean.mcguffee@gmail.com>

Hi Simon,
That makes a lot of sense to me. I'll start reading about R's event loop
signaling. I'm not sure what the best method will be for me to flag the
completeness of a threaded process in my case. In abstract it seems that I
could get R's event loop to look for any type of flag. I think key for me in
this case will be identifying whether a particular file has been completely
produced or not. In principle I could put that type of info into the file
itself, but I think I could also make a temp file somewhere with it's full
path and flag info about it. Then the event loop could look for a particular
pattern of temp file names. On the other hand, if I pass in that info when I
start the event loop, that might work too. Regarding the external pointer
idea, I was thinking about passing an object to R as a return value after
launching the thread, and then I might be able to access a pointer inside
that object to reference it from my thread. That could be a binary vector or
any type of object if I can figure out how to get to it from my thread.
Honestly, I don't know much about dynamic referencing of objects from
separate threads, but in principle memory is shared in this case. I'll let
you know if I come up with anything generic... Please keep me posted on your
package. Are any versions of it available yet? It didn't happen to come up
on my list of R packages. I haven't necessarily been maintaining an
up-to-date version of R though. I don't know if that influences the package
list it shows me.
Sean


On 4/26/11 8:51 PM, "Simon Urbanek" <simon.urbanek at r-project.org> wrote:

> Sean,
> 
> On Apr 26, 2011, at 5:06 PM, Sean Robert McGuffee wrote:
> 
>> I've been thinking about how to handle c++ threads that were started via Rcpp
>> calls to some of my c++ libraries from R. My main obstacle is trying to make
>> sure that users don't try to process files that are being generated by a
>> thread before the thread finishes. One thing I am considering is having my
>> threaded code return a class to R that contains a pointer that it remembers.
>> Then maybe I could just change the value at that pointer when my thread
>> finishes. Does that seem like a reasonable approach? I'm not completely sure
>> if this is related to your issue or not, but it might be similar enough to be
>> worth asking...
> 
> It depends. For a simple flag it's actually much more simple than that - you
> can create a boolean vector (make sure you preserve it) and just update its
> value when it's done - you don't even need an external pointer for that (if
> your'e careful).
> 
> But the slight problem with that approach is rather that you don't have a way
> to tell R about the status change, so essentially you can only poll on the R
> side. A more proper way to deal with this is to use the event loop signaling
> to signal in R that the flag has changed. I'm working on a "threads" package
> that should help with that, but it's not complete yet (you can spawn threads
> from R and you can actually even synchronize them with R [so if the result is
> all you want it's there], but semaphores are not implemented yet  --- your
> inquiry should shift it further up on my todo stack ;)).
> 
> Cheers,
> Simon


From simon.urbanek at r-project.org  Wed Apr 27 21:39:28 2011
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Wed, 27 Apr 2011 15:39:28 -0400
Subject: [Rd] Thread synchronization [Was: Interrupting C++ code
	execution]
In-Reply-To: <C9DDE4E8.3EEC%sean.mcguffee@gmail.com>
References: <C9DDE4E8.3EEC%sean.mcguffee@gmail.com>
Message-ID: <9CEEAAAD-2A4C-411E-9B2D-039CE7237D54@r-project.org>

Sean,

On Apr 27, 2011, at 3:21 PM, Sean Robert McGuffee wrote:

> Hi Simon,
> That makes a lot of sense to me. I'll start reading about R's event loop signaling. I'm not sure what the best method will be for me to flag the completeness of a threaded process in my case. In abstract it seems that I could get R's event loop to look for any type of flag. I think key for me in this case will be identifying whether a particular file has been completely produced or not. In principle I could put that type of info into the file itself, but I think I could also make a temp file somewhere with it's full path and flag info about it. Then the event loop could look for a particular pattern of temp file names. On the other hand, if I pass in that info when I start the event loop, that might work too.

Usually, the easiest on unix is to register a file handle as input handler (addInputHandler) - in practice a pipe - one end is owned by the thread and the other is owned by R. Then all you need is to write anything on the thread's end and it will wake up R's even loop and let you handle the read on that end so you can do anything. You could even have multiple threads share this one pipe since you could distinguish by payload which thread is calling. One example of this is the integrated HTTP server in R - see Rhttpd sources (it has also a variant that works on Windows using synchronization via OS event loop).


> Regarding the external pointer idea, I was thinking about passing an object to R as a return value after launching the thread, and then I might be able to access a pointer inside that object to reference it from my thread. That could be a binary vector or any type of object if I can figure out how to get to it from my thread. Honestly, I don't know much about dynamic referencing of objects from separate threads, but in principle memory is shared in this case. I'll let you know if I come up with anything generic... Please keep me posted on your  package. Are any versions of it available yet?

Yes, it is not released yet since it's not quite complete, but here we go, at your own risk ;):

http://rforge.net/threads

It will work on all platforms, eventually, but currently only unix is supported. The idea is sort of taking the multicore paradigm (parallel + collect) but using threads (threadEval + yield). The documentation it currently non-existent, but I plan to write a vignette for it ... maybe later this week ...

Cheers,
Simon


> It didn't happen to come up on my list of R packages. I haven't necessarily been maintaining an up-to-date version of R though. I don't know if that influences the package list it shows me.
> Sean
> 
> 
> On 4/26/11 8:51 PM, "Simon Urbanek" <simon.urbanek at r-project.org> wrote:
> 
>> Sean,
>> 
>> On Apr 26, 2011, at 5:06 PM, Sean Robert McGuffee wrote:
>> 
>>> I've been thinking about how to handle c++ threads that were started via Rcpp
>>> calls to some of my c++ libraries from R. My main obstacle is trying to make
>>> sure that users don't try to process files that are being generated by a
>>> thread before the thread finishes. One thing I am considering is having my
>>> threaded code return a class to R that contains a pointer that it remembers.
>>> Then maybe I could just change the value at that pointer when my thread
>>> finishes. Does that seem like a reasonable approach? I'm not completely sure
>>> if this is related to your issue or not, but it might be similar enough to be
>>> worth asking...
>> 
>> It depends. For a simple flag it's actually much more simple than that - you
>> can create a boolean vector (make sure you preserve it) and just update its
>> value when it's done - you don't even need an external pointer for that (if
>> your'e careful).
>> 
>> But the slight problem with that approach is rather that you don't have a way
>> to tell R about the status change, so essentially you can only poll on the R
>> side. A more proper way to deal with this is to use the event loop signaling
>> to signal in R that the flag has changed. I'm working on a "threads" package
>> that should help with that, but it's not complete yet (you can spawn threads
>> from R and you can actually even synchronize them with R [so if the result is
>> all you want it's there], but semaphores are not implemented yet  --- your
>> inquiry should shift it further up on my todo stack ;)).
>> 
>> Cheers,
>> Simon
> 
> 
> 


From cstrato at aon.at  Wed Apr 27 21:47:37 2011
From: cstrato at aon.at (cstrato)
Date: Wed, 27 Apr 2011 21:47:37 +0200
Subject: [Rd] How to create vignette.pdf for R-2.13.0?
In-Reply-To: <4DB7D0DD.6040201@statistik.tu-dortmund.de>
References: <4DB32D9F.5010406@aon.at>	<4DB42FB3.9090401@statistik.tu-dortmund.de>	<4DB472F8.9060903@aon.at>	<4DB489EC.9080301@statistik.tu-dortmund.de>	<4DB491BE.8080104@aon.at>	<4DB57E7A.1080507@statistik.tu-dortmund.de>
	<4DB5AFD4.9020303@aon.at> <4DB5B6B0.90607@gmail.com>
	<4DB5C286.40306@aon.at> <4DB5C38D.6030400@gmail.com>
	<4DB5C87C.5040905@aon.at> <4DB5CBFD.6050508@gmail.com>
	<4DB723F9.7090800@aon.at>
	<4DB7D0DD.6040201@statistik.tu-dortmund.de>
Message-ID: <4DB872D9.3070501@aon.at>

Dear Uwe,

As I have already mentioned R CMD check gives the following output:

* checking for unstated dependencies in vignettes ... OK
* checking package vignettes in 'inst/doc' ... WARNING
Package vignette(s) without corresponding PDF:
    APTvsXPS.Rnw
    xps.Rnw
    xpsClasses.Rnw
    xpsPreprocess.Rnw

* checking running R code from vignettes ... OK
* checking re-building of vignettes ... OK
* checking PDF version of manual ... OK

WARNING: There was 1 warning, see
   '/Volumes/CoreData/CRAN/xps.Rcheck/00check.log'
for details


Although the output says "checking PDF version of manual ... OK" I 
cannot find any result in "xps.Rcheck".


When I run "R64 CMD build xps" I get:

* checking for file 'xps/DESCRIPTION' ... OK
* preparing 'xps':
* checking DESCRIPTION meta-information ... OK
* cleaning src
* installing the package to re-build vignettes
* creating vignettes ... OK
* cleaning src
* checking for LF line-endings in source and make files
* checking for empty or unneeded directories
* building 'xps_1.13.1.tar.gz'

However, the resulting file "xps_1.13.1.tgz" does also not contain any 
vignettes.

Best regards
Christian


On 4/27/11 10:16 AM, Uwe Ligges wrote:
>
>
> On 26.04.2011 21:58, cstrato wrote:
>> Dear Duncan, dear Uwe,
>>
>> Just now I have re-run everything, and today xps.Rnw can be converted to
>> a vignette w/o any problems using:
>> a, buildVignettes("xps", dir="/Volumes/CoreData/CRAN/xps", quiet=F)
>> b, R CMD Sweave xps.Rnw
>>
>> In both cases the vignette xps.pdf is created (maybe my Mac did not like
>> to work during eastern holidays).
>>
>> However, one issue remains:
>> "R64 CMD check xps_1.13.1.tar.gz" no longer creates any pdf files for
>> the vignettes.
>
>
> Dioes it give an error or warning? It should check the code. R CMD build
> creates the pdf files.
>
> Uwe Ligges
>
>>
>> Best regards
>> Christian
>>
>>
>> On 4/25/11 9:31 PM, Duncan Murdoch wrote:
>>> On 25/04/2011 3:16 PM, cstrato wrote:
>>>> Thank you.
>>>>
>>>> My problem seems to be that at the moment the problem can be seen only
>>>> on my Mac, since e.g. the Bioconductor servers have no problems
>>>> creating
>>>> the vignettes.
>>>
>>> Then you are definitely the one in the best position to diagnose the
>>> problem. Use the usual approach: simplify it by cutting out everything
>>> that looks unrelated. Verify that the problem still exists, then cut
>>> some more. Eventually you'll have isolated the error to a particular
>>> small snippet of code, and then you can add print() statements, or use
>>> trace(), or do whatever is necessary to see what's so special about your
>>> system.
>>>
>>> I suspect it will turn out to be an assumption in the code that is not
>>> true on your system.
>>>
>>> If the assumption is being made by code you wrote, then fix it. If it's
>>> being made by R, let us know.
>>>
>>> Duncan Murdoch
>>>
>>>>
>>>> Best regards
>>>> Christian
>>>>
>>>> On 4/25/11 8:55 PM, Duncan Murdoch wrote:
>>>>> cstrato wrote:
>>>>>> Dear Duncan,
>>>>>>
>>>>>> Thank you for your example, however it is different since it does not
>>>>>> use x and y. What about print(x+y)?
>>>>>
>>>>> Try it.
>>>>>
>>>>>>
>>>>>> Sorry, I do not believe that there is a bug in my code, since:
>>>>>> 1, it worked in all versions from R starting with R-2.6.0 till
>>>>>> R-2.12.2.
>>>>>> 2, the identical code works in the examples
>>>>>> 3, this code (or a similar code) is the starting code which all users
>>>>>> of xps have to use, and there was never a problem.
>>>>>
>>>>> This might be a problem in R, or might be a problem in your code. As
>>>>> far
>>>>> as I know, it has only shown up in your code, so I'd guess that's
>>>>> where
>>>>> the problem is. In any case, you're the one in the best position to
>>>>> isolate it and debug it.
>>>>>
>>>>> If it turns out to be a problem in R, put together an example
>>>>> illustrating the problem that doesn't involve your code, and I'll
>>>>> take a
>>>>> look.
>>>>>
>>>>> Duncan Murdoch
>>>>>
>>>>>>
>>>>>> Maybe the reason could be that my code has to import
>>>>>> - the CEL-files from the package dir
>>>>>> - the file SchemeTest3.root from the package dir
>>>>>> ??
>>>>>>
>>>>>> Best regards
>>>>>> Christian
>>>>>>
>>>>>> On 4/25/11 8:00 PM, Duncan Murdoch wrote:
>>>>>>> cstrato wrote:
>>>>>>>> Dear Uwe,
>>>>>>>>
>>>>>>>> Your suggestion to look at the Sweave manual helped me to solve the
>>>>>>>> problem. It seems that in R-2.13.0 every chunk can use the code
>>>>>>>> from
>>>>>>>> the chunk before but not from an earlier chunk.
>>>>>>> I'm either misreading what you wrote, or it's wrong. If I have this
>>>>>>> in a
>>>>>>> Sweave file:
>>>>>>>
>>>>>>> <<>>=
>>>>>>> x<- 1
>>>>>>> @
>>>>>>>
>>>>>>> <<>>=
>>>>>>> y<- 2
>>>>>>> @
>>>>>>>
>>>>>>> <<>>=
>>>>>>> print(x)
>>>>>>> @
>>>>>>>
>>>>>>> I will see the value of x getting printed, even though it came from
>>>>>>> two
>>>>>>> chunks earlier.
>>>>>>>
>>>>>>> I think Uwe is right: there is some bug in the code you're running.
>>>>>>> Sweave isn't the problem.
>>>>>>>
>>>>>>> Duncan Murdoch
>>>>>>>
>>>>>>>> Concretely, the following does not work since chunk 5 needs the
>>>>>>>> code
>>>>>>>> from chunk 3 and 4:
>>>>>>>>
>>>>>>>> ###################################################
>>>>>>>> ### chunk number 3:
>>>>>>>> ###################################################
>>>>>>>> #line 126 "xps.Rnw"
>>>>>>>> celdir<- file.path(.path.package("xps"), "raw")
>>>>>>>>
>>>>>>>> ###################################################
>>>>>>>> ### chunk number 4:
>>>>>>>> ###################################################
>>>>>>>> #line 132 "xps.Rnw"
>>>>>>>> scheme.test3<- root.scheme(file.path(.path.package("xps"),
>>>>>>>> "schemes",
>>>>>>>> "SchemeTest3.root"))
>>>>>>>>
>>>>>>>> ###################################################
>>>>>>>> ### chunk number 5:
>>>>>>>> ###################################################
>>>>>>>> #line 137 "xps.Rnw"
>>>>>>>> celfiles<- c("TestA1.CEL","TestA2.CEL")
>>>>>>>> data.test3<- import.data(scheme.test3, "tmpdt_DataTest3",
>>>>>>>> celdir=celdir, celfiles=celfiles, verbose=FALSE)
>>>>>>>>
>>>>>>>>
>>>>>>>> However, when I add "celdir" to chunk 5 then everything works since
>>>>>>>> now chunk 5 needs only the code from chunk 4 but not from chunk 3:
>>>>>>>>
>>>>>>>> ###################################################
>>>>>>>> ### chunk number 5:
>>>>>>>> ###################################################
>>>>>>>> #line 137 "xps.Rnw"
>>>>>>>> celdir<- file.path(.path.package("xps"), "raw")
>>>>>>>> celfiles<- c("TestA1.CEL","TestA2.CEL")
>>>>>>>> data.test3<- import.data(scheme.test3, "tmpdt_DataTest3",
>>>>>>>> celdir=celdir, celfiles=celfiles, verbose=FALSE)
>>>>>>>>
>>>>>>>>
>>>>>>>> Now buildVignettes() is able to create the vignettes, however R CMD
>>>>>>>> check still does not build the vignettes.
>>>>>>>>
>>>>>>>>
>>>>>>>> Yes, I get a Warning in both cases:
>>>>>>>> * checking package vignettes in 'inst/doc' ... WARNING
>>>>>>>> Package vignettes without corresponding PDF: ........
>>>>>>>>
>>>>>>>> However, with R-2.12.2 the following lines are added:
>>>>>>>>
>>>>>>>> /Volumes/CoreData/CRAN/xps.Rcheck/00_pkg_src/xps/inst/doc/APTvsXPS.Rnw
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>> /Volumes/CoreData/CRAN/xps.Rcheck/00_pkg_src/xps/inst/doc/xps.Rnw
>>>>>>>> /Volumes/CoreData/CRAN/xps.Rcheck/00_pkg_src/xps/inst/doc/xpsClasses.Rnw
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>> /Volumes/CoreData/CRAN/xps.Rcheck/00_pkg_src/xps/inst/doc/xpsPreprocess.Rnw
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>> and in xps.Rcheck the subdirectory "inst/doc" will be created which
>>>>>>>> contains the vignette data such as xps.Rnw, but also xps.tex and
>>>>>>>> xps.pdf.
>>>>>>>>
>>>>>>>> In contrast, R-2.13.0 does not create the subdirectory "inst/doc"
>>>>>>>> and
>>>>>>>> no vignettes are built.
>>>>>>>>
>>>>>>>> One more issue:
>>>>>>>> In contrast to my former believe R CMD INSTALL does not build the
>>>>>>>> vignettes, neither in R-2.12.2 nor in R-2.13.0. I have to run
>>>>>>>> buildVignettes() after installation. Is this the usual case?
>>>>>>>>
>>>>>>>> Best regards
>>>>>>>> Christian
>>>>>>>>
>>>>>>>>
>>>>>>>> On 4/25/11 4:00 PM, Uwe Ligges wrote:
>>>>>>>>> On 24.04.2011 23:10, cstrato wrote:
>>>>>>>>>> Dear Uwe,
>>>>>>>>>>
>>>>>>>>>> On 4/24/11 10:37 PM, Uwe Ligges wrote:
>>>>>>>>>>> On 24.04.2011 20:59, cstrato wrote:
>>>>>>>>>>>> Dear Uwe,
>>>>>>>>>>>>
>>>>>>>>>>>> Thank you for your reply.
>>>>>>>>>>>>
>>>>>>>>>>>> ad 2, Yes, i know that "xps-manual.pdf" is the collection of
>>>>>>>>>>>> help
>>>>>>>>>>>> pages,
>>>>>>>>>>>> I have mentioned it only to show that creating pdf-files does
>>>>>>>>>>>> work
>>>>>>>>>>>> for
>>>>>>>>>>>> R-2.13.0.
>>>>>>>>>>>>
>>>>>>>>>>>> ad 1, Could it be that this is a Mac-specific problem since I
>>>>>>>>>>>> see
>>>>>>>>>>>> it on
>>>>>>>>>>>> both my old MacBook Pro and my new Mac Mini.
>>>>>>>>>>> Have you tried on any other OS? I did not since installing
>>>>>>>>>>> root is
>>>>>>>>>>> a bit
>>>>>>>>>>> too much effort.
>>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>> No, until now I did not try another OS, but I will, since xps
>>>>>>>>>> has to
>>>>>>>>>> work on all three OSes.
>>>>>>>>>>
>>>>>>>>>>>> Using R CMD check with R-2.12.2 I get:
>>>>>>>>>>> I thought we are talking about R-2.13.0?
>>>>>>>>>>>
>>>>>>>>>> I showed you the output of R-2.12.2 first and then the output of
>>>>>>>>>> R-2.13.0, so that you can see that on the same machine with the
>>>>>>>>>> same
>>>>>>>>>> file it works with one version but not the other.
>>>>>>>>> But you got a Warning in both cases:
>>>>>>>>> * checking package vignettes in 'inst/doc' ... WARNING
>>>>>>>>> Package vignettes without corresponding PDF: ........
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>>> Where is the R CMD build output (since R CMD build is
>>>>>>>>>>> supposed to
>>>>>>>>>>> prepare the vignette).
>>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>>>> $ R64 CMD check xps_1.13.1.tar.gz
>>>>>>>>>>>> * using log directory '/Volumes/CoreData/CRAN/xps.Rcheck'
>>>>>>>>>>>> * using R version 2.12.2 (2011-02-25)
>>>>>>>>>>>> * using platform: x86_64-apple-darwin9.8.0 (64-bit)
>>>>>>>>>>>> * using session charset: ASCII
>>>>>>>>>>>> * checking for file 'xps/DESCRIPTION' ... OK
>>>>>>>>>>>> * this is package 'xps' version '1.13.1'
>>>>>>>>>>>> ...
>>>>>>>>>>>> ...
>>>>>>>>>>>> * checking package vignettes in 'inst/doc' ... WARNING
>>>>>>>>>>>> Package vignettes without corresponding PDF:
>>>>>>>>>>>>
>>>>>>>>>>>> /Volumes/CoreData/CRAN/xps.Rcheck/00_pkg_src/xps/inst/doc/APTvsXPS.Rnw
>>>>>>>>>>>>
>>>>>>>>>>>>
>>>>>>>>>>>>
>>>>>>>>>>>>
>>>>>>>>>>>>
>>>>>>>>>>>> /Volumes/CoreData/CRAN/xps.Rcheck/00_pkg_src/xps/inst/doc/xps.Rnw
>>>>>>>>>>>>
>>>>>>>>>>>>
>>>>>>>>>>>> /Volumes/CoreData/CRAN/xps.Rcheck/00_pkg_src/xps/inst/doc/xpsClasses.Rnw
>>>>>>>>>>>>
>>>>>>>>>>>>
>>>>>>>>>>>>
>>>>>>>>>>>>
>>>>>>>>>>>>
>>>>>>>>>>>>
>>>>>>>>>>>> /Volumes/CoreData/CRAN/xps.Rcheck/00_pkg_src/xps/inst/doc/xpsPreprocess.Rnw
>>>>>>>>>>>>
>>>>>>>>>>>>
>>>>>>>>>>>>
>>>>>>>>>>>>
>>>>>>>>>>>>
>>>>>>>>>>>>
>>>>>>>>>>>>
>>>>>>>>>>>>
>>>>>>>>>>>> * checking PDF version of manual ... OK
>>>>>>>>>>>>
>>>>>>>>>>>>
>>>>>>>>>>>> Using "RSwitch.app" I switch to R-2.13.0, but now I get:
>>>>>>>>>>>>
>>>>>>>>>>>> $ R64 CMD check xps_1.13.1.tar.gz
>>>>>>>>>>>> * using log directory '/Volumes/CoreData/CRAN/xps.Rcheck'
>>>>>>>>>>>> * using R version 2.13.0 (2011-04-13)
>>>>>>>>>>>> * using platform: x86_64-apple-darwin9.8.0 (64-bit)
>>>>>>>>>>>> * using session charset: ASCII
>>>>>>>>>>>> * checking for file 'xps/DESCRIPTION' ... OK
>>>>>>>>>>>> * this is package 'xps' version '1.13.1'
>>>>>>>>>>>> ...
>>>>>>>>>>>> ...
>>>>>>>>>>>> * checking package vignettes in 'inst/doc' ... WARNING
>>>>>>>>>>>> Package vignette(s) without corresponding PDF:
>>>>>>>>>>>> APTvsXPS.Rnw
>>>>>>>>>>>> xps.Rnw
>>>>>>>>>>>> xpsClasses.Rnw
>>>>>>>>>>>> xpsPreprocess.Rnw
>>>>>>>>>>>>
>>>>>>>>>>>> * checking running R code from vignettes ... OK
>>>>>>>>>>>> * checking re-building of vignettes ... OK
>>>>>>>>>>>> * checking PDF version of manual ... OK
>>>>>>>>>>>>
>>>>>>>>>>>>
>>>>>>>>>>>> I must admit that I have never built the vignettes manually,
>>>>>>>>>>>> and I
>>>>>>>>>>>> cannot find a hint how I can do it from the command line. Is
>>>>>>>>>>>> this
>>>>>>>>>>>> possible?
>>>>>>>>>> Is it possible to build the vignettes from the command line?
>>>>>>>>> R --help suggests there is
>>>>>>>>> R CMD Sweave .....
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>>>> However, building the vignettes within R-2.13.0 I get:
>>>>>>>>>>>>> library(tools)
>>>>>>>>>>>>> buildVignettes("xps", dir="/Volumes/CoreData/CRAN/xps",
>>>>>>>>>>>>> quiet=F)
>>>>>>>>>>>> Overfull \vbox (21.68121pt too high) has occurred while
>>>>>>>>>>>> \output is
>>>>>>>>>>>> Writing to file xps.tex
>>>>>>>>>>>> Processing code chunks with options ...
>>>>>>>>>>>> 1 : term verbatim
>>>>>>>>>>>> 2 : echo term hide
>>>>>>>>>>>> 3 : echo term verbatim
>>>>>>>>>>>> 4 : echo term verbatim
>>>>>>>>>>>> 5 : echo term verbatim
>>>>>>>>>>>> SysError in<TFile::TFile>: file
>>>>>>>>>>>> /tmpdt_DataTest3_cel.root/tmpdt_DataTest3_cel_20110424_201301.root
>>>>>>>>>>>>
>>>>>>>>>>>>
>>>>>>>>>>>>
>>>>>>>>>>>> can
>>>>>>>>>>>> not be opened (No such file or directory)
>>>>>>>>>>>> Error: Could not create file</tmpdt_DataTest3_cel.root>
>>>>>>>>>>>>
>>>>>>>>>>>>
>>>>>>>>>>>> Here are the two important chunks 4 and 5, which work fine with
>>>>>>>>>>>> R-2.12.2
>>>>>>>>>>>> and earlier versions:
>>>>>>>>>>>>
>>>>>>>>>>>> ###################################################
>>>>>>>>>>>> ### chunk number 4:
>>>>>>>>>>>> ###################################################
>>>>>>>>>>>> #line 132 "xps.Rnw"
>>>>>>>>>>>> scheme.test3<- root.scheme(file.path(.path.package("xps"),
>>>>>>>>>>>> "schemes",
>>>>>>>>>>>> "SchemeTest3.root"))
>>>>>>>>>>>>
>>>>>>>>>>>>
>>>>>>>>>>>> ###################################################
>>>>>>>>>>>> ### chunk number 5:
>>>>>>>>>>>> ###################################################
>>>>>>>>>>>> #line 137 "xps.Rnw"
>>>>>>>>>>>> celfiles<- c("TestA1.CEL","TestA2.CEL")
>>>>>>>>>>>> data.test3<- import.data(scheme.test3, "tmpdt_DataTest3",
>>>>>>>>>>>> celdir=celdir, celfiles=celfiles, verbose=FALSE)
>>>>>>>>>>>>
>>>>>>>>>>>>
>>>>>>>>>>>> However, in R-2.13.0 chunk 5 crashes!!!
>>>>>>>>>>>> It works only when replacing chunk 5 with:
>>>>>>>>>>>>
>>>>>>>>>>>> ###################################################
>>>>>>>>>>>> ### chunk number 5:
>>>>>>>>>>>> ###################################################
>>>>>>>>>>>> #line 137 "xps.Rnw"
>>>>>>>>>>>> celfiles<- c("TestA1.CEL","TestA2.CEL")
>>>>>>>>>>>> scheme.test3<- root.scheme(file.path(.path.package("xps"),
>>>>>>>>>>>> "schemes",
>>>>>>>>>>>> "SchemeTest3.root"))
>>>>>>>>>>>> data.test3<- import.data(scheme.test3, "tmpdt_DataTest3",
>>>>>>>>>>>> celdir=celdir, celfiles=celfiles, verbose=FALSE)
>>>>>>>>>>>>
>>>>>>>>>>>>
>>>>>>>>>>>> As you see R-2.13.0 does no longer remember the result of
>>>>>>>>>>>> chunk 4,
>>>>>>>>>>>> i.e.
>>>>>>>>>>>> "scheme.test3". Now I have to include the line defining
>>>>>>>>>>>> "scheme.test3"
>>>>>>>>>>>> also in chunk 5.
>>>>>>>>>>> How objects generated in one chunk can be reused later on is
>>>>>>>>>>> explained
>>>>>>>>>>> in the Sweave manual.
>>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>>>> Do you have any idea for this behavior?
>>>>>>>>>>>>
>>>>>>>>>>>>
>>>>>>>>>>>> An example, which does work in R-2.13.0 are the following two
>>>>>>>>>>>> chunks:
>>>>>>>>>>>>
>>>>>>>>>>>> #################################################
>>>>>>>>>>>> ### chunk number 20:
>>>>>>>>>>>> ###################################################
>>>>>>>>>>>> #line 300 "xps.Rnw"
>>>>>>>>>>>> library(xps)
>>>>>>>>>>>> scheme.test3<- root.scheme(file.path(.path.package("xps"),
>>>>>>>>>>>> "schemes",
>>>>>>>>>>>> "SchemeTest3.root"))
>>>>>>>>>>>> data.test3<- root.data(scheme.test3,
>>>>>>>>>>>> file.path(.path.package("xps"),"rootdata",
>>>>>>>>>>>> "DataTest3_cel.root"))
>>>>>>>>>>>>
>>>>>>>>>>>>
>>>>>>>>>>>> ###################################################
>>>>>>>>>>>> ### chunk number 21:
>>>>>>>>>>>> ###################################################
>>>>>>>>>>>> #line 318 "xps.Rnw"
>>>>>>>>>>>> data.rma<- rma(data.test3, "tmpdt_Test3RMA", verbose=FALSE)
>>>>>>>>>>>>
>>>>>>>>>>>>
>>>>>>>>>>>> In summary it is not quite clear to me what has changed in
>>>>>>>>>>>> R-2.13.0 so
>>>>>>>>>>>> that chunk 5 no longer works.
>>>>>>>>>>>>
>>>>>>>>>>>> BTW, the error:
>>>>>>>>>>>> SysError in<TFile::TFile>: file
>>>>>>>>>>>> /tmpdt_DataTest3_cel.root/tmpdt_DataTest3_cel_20110424_201301.root
>>>>>>>>>>>>
>>>>>>>>>>>>
>>>>>>>>>>>>
>>>>>>>>>>>> can
>>>>>>>>>>>> not be opened
>>>>>>>>>>>> is not clear to me since "/tmpdt_DataTest3_cel.root/" is
>>>>>>>>>>>> definitively
>>>>>>>>>>>> NOT a directory.
>>>>>>>>>>> Time to debug what root.scheme is doing with the supplied path.
>>>>>>>>>>>
>>>>>>>>>> Sorry, I do not understand what you mean. root.scheme does not
>>>>>>>>>> change
>>>>>>>>>> the path, otherwise it would not work on all older versions of R.
>>>>>>>>> Right, but since something changed obviously, and you tell us the
>>>>>>>>> path
>>>>>>>>> is not a path, it might be a function used by root.scheme ....
>>>>>>>>> That's
>>>>>>>>> why I said time to debug the code in your vignette!
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>>>> Do you have any ideas?
>>>>>>>>>>>>
>>>>>>>>>>>> Please note that the vignette "xps.Rnw" did work for the last
>>>>>>>>>>>> two
>>>>>>>>>>>> years
>>>>>>>>>>>> w/o problem. Furthermore, the Bioconductor servers are able to
>>>>>>>>>>>> build
>>>>>>>>>>>> the
>>>>>>>>>>>> vignette, see:
>>>>>>>>>>>> http://www.bioconductor.org/packages/release/bioc/html/xps.html
>>>>>>>>>>> See
>>>>>>>>>>> http://bioconductor.org/checkResults/2.8/bioc-20110225/xps/liverpool-checksrc.html
>>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>>> and find that their Mac Servers are also fine with it. So maybe
>>>>>>>>>>> it is
>>>>>>>>>>> your setup that is corrupted?
>>>>>>>>>> Maybe, you are right that my setup is corrupted, but on two
>>>>>>>>>> independent
>>>>>>>>>> machines?
>>>>>>>>>>
>>>>>>>>>> Maybe the download of "R-2.13.0.pkg" is corrupted, but then
>>>>>>>>>> nothing
>>>>>>>>>> should work, or am I wrong?
>>>>>>>>>>
>>>>>>>>>> How can I check if my setup is corrupted?
>>>>>>>>> By debugging the code in your package's vignette.
>>>>>>>>>
>>>>>>>>> Uwe Ligges
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>> Best regards
>>>>>>>>>> Christian
>>>>>>>>>>
>>>>>>>>>>> Best wishes,
>>>>>>>>>>> Uwe
>>>>>>>>>>>
>>>>>>>>>>>> Best regards
>>>>>>>>>>>> Christian
>>>>>>>>>>>>
>>>>>>>>>>>>
>>>>>>>>>>>> On 4/24/11 4:12 PM, Uwe Ligges wrote:
>>>>>>>>>>>>> On 23.04.2011 21:50, cstrato wrote:
>>>>>>>>>>>>>> Dear all,
>>>>>>>>>>>>>>
>>>>>>>>>>>>>> While R CMD check and R CMD INSTALL have always created the
>>>>>>>>>>>>>> vignettes on
>>>>>>>>>>>>>> R-2.12.1 or any earlier versions of R, I am no longer able to
>>>>>>>>>>>>>> build
>>>>>>>>>>>>>> the
>>>>>>>>>>>>>> vignettes on R-2.13.0.
>>>>>>>>>>>>>>
>>>>>>>>>>>>>> Instead R CMD check gives me the following output:
>>>>>>>>>>>>>>
>>>>>>>>>>>>>> * checking for unstated dependencies in vignettes ... OK
>>>>>>>>>>>>>> * checking package vignettes in 'inst/doc' ... WARNING
>>>>>>>>>>>>>> Package vignette(s) without corresponding PDF:
>>>>>>>>>>>>>> APTvsXPS.Rnw
>>>>>>>>>>>>>> xps.Rnw
>>>>>>>>>>>>>> xpsClasses.Rnw
>>>>>>>>>>>>>> xpsPreprocess.Rnw
>>>>>>>>>>>>>>
>>>>>>>>>>>>>> * checking running R code from vignettes ... OK
>>>>>>>>>>>>>> * checking re-building of vignettes ... OK
>>>>>>>>>>>>>> * checking PDF version of manual ... OK
>>>>>>>>>>>>>>
>>>>>>>>>>>>>>
>>>>>>>>>>>>>> Does someone know what the reason might be?
>>>>>>>>>>>>> No, it does for me for other packages.
>>>>>>>>>>>>> Perhaps an error when processing the vignettes? Have you
>>>>>>>>>>>>> tried to
>>>>>>>>>>>>> build
>>>>>>>>>>>>> them manually?
>>>>>>>>>>>>>
>>>>>>>>>>>>>
>>>>>>>>>>>>>> (R64 CMD check --help says that be default
>>>>>>>>>>>>>> rebuild-vignettes is
>>>>>>>>>>>>>> turned
>>>>>>>>>>>>>> on.)
>>>>>>>>>>>>>>
>>>>>>>>>>>>>> Interestingly, R CMD check still creates the file
>>>>>>>>>>>>>> "xps-manual.pdf".
>>>>>>>>>>>>> That is the collection of help pages, unrelated to the
>>>>>>>>>>>>> vignette.
>>>>>>>>>>>>>
>>>>>>>>>>>>>
>>>>>>>>>>>>> Uwe Ligges
>>>>>>>>>>>>>
>>>>>>>>>>>>>
>>>>>>>>>>>>>
>>>>>>>>>>>>>> Here is my sessionInfo:
>>>>>>>>>>>>>>
>>>>>>>>>>>>>>> sessionInfo()
>>>>>>>>>>>>>> R version 2.13.0 (2011-04-13)
>>>>>>>>>>>>>> Platform: x86_64-apple-darwin9.8.0/x86_64 (64-bit)
>>>>>>>>>>>>>>
>>>>>>>>>>>>>> locale:
>>>>>>>>>>>>>> [1] C
>>>>>>>>>>>>>>
>>>>>>>>>>>>>> attached base packages:
>>>>>>>>>>>>>> [1] stats graphics grDevices utils datasets methods base
>>>>>>>>>>>>>>
>>>>>>>>>>>>>> other attached packages:
>>>>>>>>>>>>>> [1] xps_1.13.1
>>>>>>>>>>>>>>
>>>>>>>>>>>>>> loaded via a namespace (and not attached):
>>>>>>>>>>>>>> [1] Biobase_2.12.1 Biostrings_2.20.0 IRanges_1.10.0
>>>>>>>>>>>>>> [4] affy_1.30.0 affyPLM_1.28.5 affyio_1.20.0
>>>>>>>>>>>>>> [7] preprocessCore_1.14.0
>>>>>>>>>>>>>>
>>>>>>>>>>>>>> Thank you in advance.
>>>>>>>>>>>>>> Best regards
>>>>>>>>>>>>>> Christian
>>>>>>>>>>>>>> _._._._._._._._._._._._._._._._._._
>>>>>>>>>>>>>> C.h.r.i.s.t.i.a.n S.t.r.a.t.o.w.a
>>>>>>>>>>>>>> V.i.e.n.n.a A.u.s.t.r.i.a
>>>>>>>>>>>>>> e.m.a.i.l: cstrato at aon.at
>>>>>>>>>>>>>> _._._._._._._._._._._._._._._._._._
>>>>>>>>>>>>>>
>>>>>>>>>>>>>> ______________________________________________
>>>>>>>>>>>>>> R-devel at r-project.org mailing list
>>>>>>>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>>>>>>>>> ______________________________________________
>>>>>>>>>>>> R-devel at r-project.org mailing list
>>>>>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>>>>> ______________________________________________
>>>>>>>> R-devel at r-project.org mailing list
>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>>>>
>>>>>
>>>>>
>>>
>>>
>


From pauljohn32 at gmail.com  Thu Apr 28 07:20:27 2011
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Thu, 28 Apr 2011 00:20:27 -0500
Subject: [Rd] median and data frames
In-Reply-To: <4DB85617.8090706@pburns.seanet.com>
References: <4DB85617.8090706@pburns.seanet.com>
Message-ID: <BANLkTin6Cic0RhGdV_KWHcSz6JE5vj9igA@mail.gmail.com>

On Wed, Apr 27, 2011 at 12:44 PM, Patrick Burns
<pburns at pburns.seanet.com> wrote:
> Here are some data frames:
>
> df3.2 <- data.frame(1:3, 7:9)
> df4.2 <- data.frame(1:4, 7:10)
> df3.3 <- data.frame(1:3, 7:9, 10:12)
> df4.3 <- data.frame(1:4, 7:10, 10:13)
> df3.4 <- data.frame(1:3, 7:9, 10:12, 15:17)
> df4.4 <- data.frame(1:4, 7:10, 10:13, 15:18)
>
> Now here are some commands and their answers:

>> median(df4.4)
> [1] ?8.5 11.5
>> median(df3.2[c(1,2,3),])
> [1] 2 8
>> median(df3.2[c(1,3,2),])
> [1] ?2 NA
> Warning message:
> In mean.default(X[[2L]], ...) :
> ?argument is not numeric or logical: returning NA
>
>
>
> The sessionInfo is below, but it looks
> to me like the present behavior started
> in 2.10.0.
>
> Sometimes it gets the right answer. ?I'd
> be grateful to hear how it does that -- I
> can't figure it out.
>

Hello, Pat.

Nice poetry there!  I think I have an actual answer, as opposed to the
usual crap I spew.

I would agree if you said median.data.frame ought to be written to
work columnwise, similar to mean.data.frame.

apply and sapply  always give the correct answer

> apply(df3.3, 2, median)
  X1.3   X7.9 X10.12
     2      8     11

> apply(df3.2, 2, median)
X1.3 X7.9
   2    8

> apply(df3.2[c(1,3,2),], 2, median)
X1.3 X7.9
   2    8

mean.data.frame is now implemented as

mean.data.frame <- function(x, ...) sapply(x, mean, ...)

I think we would suggest this for medians:

??????????????????????

median.data.frame <- function(x,...) sapply(x, median, ...)

?????????????????????

It works, see:

> median.data.frame(df3.2[c(1,3,2),])
X1.3 X7.9
   2    8

Would our next step be to enter that somewhere in R bugzilla? (I'm not
joking--I'm that naive).

I think I can explain why the current median works intermittently in
those cases you mention.  Give it a small set of pre-sorted data, all
is well.  median.default uses a sort function, and it is confused when
it is given a data.frame object rather than just a vector.


I put a browser() at the top of median.default

> median(df3.2[c(1,3,2),])
Called from: median.default(df3.2[c(1, 3, 2), ])
Browse[1]> n
debug at <tmp>#4: if (is.factor(x)) stop("need numeric data")
Browse[2]> n
debug at <tmp>#4: NULL
Browse[2]> n
debug at <tmp>#6: if (length(names(x))) names(x) <- NULL
Browse[2]> n
debug at <tmp>#6: names(x) <- NULL
Browse[2]> n
debug at <tmp>#8: if (na.rm) x <- x[!is.na(x)] else if (any(is.na(x)))
return(x[FALSE][NA])
Browse[2]> n
debug at <tmp>#8: if (any(is.na(x))) return(x[FALSE][NA])
Browse[2]> n
debug at <tmp>#8: NULL
Browse[2]> n
debug at <tmp>#12: n <- length(x)
Browse[2]> n
debug at <tmp>#13: if (n == 0L) return(x[FALSE][NA])
Browse[2]> n
debug at <tmp>#13: NULL
Browse[2]> n
debug at <tmp>#15: half <- (n + 1L)%/%2L
Browse[2]> n
debug at <tmp>#16: if (n%%2L == 1L) sort(x, partial = half)[half] else
mean(sort(x,
    partial = half + 0L:1L)[half + 0L:1L])
Browse[2]> n
debug at <tmp>#16: mean(sort(x, partial = half + 0L:1L)[half + 0L:1L])
Browse[2]> n
[1]  2 NA
Warning message:
In mean.default(X[[2L]], ...) :
  argument is not numeric or logical: returning NA


Note the sort there in step 16. I think that's what is killing us.

If you are lucky, give it a small  data frame that is in order, like
df3.2, the sort doesn't produce gibberish. When I get to that point, I
will show you the sort's effect.

First, the case that "works". I moved the browser() down, because I
got tired of looking at the same old not-yet-erroneous output.


> median(df3.2)
Called from: median.default(df3.2)
Browse[1]> n
debug at <tmp>#15: half <- (n + 1L)%/%2L
Browse[2]> n
debug at <tmp>#16: if (n%%2L == 1L) sort(x, partial = half)[half] else
mean(sort(x,
    partial = half + 0L:1L)[half + 0L:1L])
Browse[2]> n
debug at <tmp>#16: mean(sort(x, partial = half + 0L:1L)[half + 0L:1L])

Interactively, type

Browse[2]> sort(x, partial = half + 0L:1L)
  NA NA   NA   NA   NA   NA
1  1  7 NULL NULL NULL NULL
2  2  8 <NA> <NA> <NA> <NA>
3  3  9 <NA> <NA> <NA> <NA>
Warning message:
In format.data.frame(x, digits = digits, na.encode = FALSE) :
  corrupt data frame: columns will be truncated or padded with NAs

But it still gives you a "right" answer:

Browse[2]> n
[1] 2 8


But if  you give it data out of order, the second column turns to NA,
and that causes doom.


> median(df3.2[c(1,3,2),])
Called from: median.default(df3.2[c(1, 3, 2), ])
Browse[1]> n
debug at <tmp>#15: half <- (n + 1L)%/%2L
Browse[2]> n
debug at <tmp>#16: if (n%%2L == 1L) sort(x, partial = half)[half] else
mean(sort(x,
    partial = half + 0L:1L)[half + 0L:1L])
Browse[2]> n
debug at <tmp>#16: mean(sort(x, partial = half + 0L:1L)[half + 0L:1L])

Interactively:

Browse[2]> sort(x, partial = half + 0L:1L)
  NA   NA NA   NA   NA   NA
1  1 NULL  7 NULL NULL NULL
3  3 <NA>  9 <NA> <NA> <NA>
2  2 <NA>  8 <NA> <NA> <NA>
Warning message:
In format.data.frame(x, digits = digits, na.encode = FALSE) :
  corrupt data frame: columns will be truncated or padded with NAs

Browse[2]> n
[1]  2 NA
Warning message:
In mean.default(X[[2L]], ...) :
  argument is not numeric or logical: returning NA


Here's a larger test case. Note columns 1 and 3 turn to NULL

> df8.8 <- data.frame(a=2:8, b=1:7)

median(df8.8)

debug at <tmp>#16: if (n%%2L == 1L) sort(x, partial = half)[half] else
mean(sort(x,
    partial = half + 0L:1L)[half + 0L:1L])
Browse[2]> n
debug at <tmp>#16: mean(sort(x, partial = half + 0L:1L)[half + 0L:1L])
Browse[2]> sort(x, partial = half + 0L:1L)
    NA NA   NA NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA
1 NULL  2 NULL  1 NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL
2 <NA>  3 <NA>  2 <NA> <NA> <NA> <NA> <NA> <NA> <NA> <NA> <NA> <NA>
3 <NA>  4 <NA>  3 <NA> <NA> <NA> <NA> <NA> <NA> <NA> <NA> <NA> <NA>
4 <NA>  5 <NA>  4 <NA> <NA> <NA> <NA> <NA> <NA> <NA> <NA> <NA> <NA>
5 <NA>  6 <NA>  5 <NA> <NA> <NA> <NA> <NA> <NA> <NA> <NA> <NA> <NA>
6 <NA>  7 <NA>  6 <NA> <NA> <NA> <NA> <NA> <NA> <NA> <NA> <NA> <NA>
7 <NA>  8 <NA>  7 <NA> <NA> <NA> <NA> <NA> <NA> <NA> <NA> <NA> <NA>
Warning message:
In format.data.frame(x, digits = digits, na.encode = FALSE) :
  corrupt data frame: columns will be truncated or padded with NAs

Run ?sort and you see it was not intended for data.frames.

In conclusion, I think median applied to a data.frame causes undefined
behavior because median is not intending to deal with several columns
at once.


I don't see any changes in median.default that would explain the
changes you see. Compare:

>From R-2.13, src/library/stats/R/median.R
median.default <- function(x, na.rm = FALSE)
{
    if(is.factor(x)) stop("need numeric data")
    ## all other objects only need sort() & mean() to be working
    if(length(names(x))) names(x) <- NULL # for e.g., c(x = NA_real_)
    if(na.rm) x <- x[!is.na(x)] else if(any(is.na(x))) return(x[FALSE][NA])
    n <- length(x)
    if (n == 0L) return(x[FALSE][NA])
    half <- (n + 1L) %/% 2L
    if(n %% 2L == 1L) sort(x, partial = half)[half]
    else mean(sort(x, partial = half + 0L:1L)[half + 0L:1L])
}


>From R-2.9.2
median.default <- function(x, na.rm = FALSE)
{
    if(is.factor(x)) stop("need numeric data")
    ## all other objects only need sort() & mean() to be working
    if(length(names(x))) names(x) <- NULL # for e.g., c(x = NA_real_)
    if(na.rm) x <- x[!is.na(x)] else if(any(is.na(x))) return(x[FALSE][NA])
    n <- length(x)
    if (n == 0L) return(x[FALSE][NA])
    half <- (n + 1L) %/% 2L
    if(n %% 2L == 1L) sort(x, partial = half)[half]
    else mean(sort(x, partial = half + 0L:1L)[half + 0L:1L])
}



pj




-- 
Paul E. Johnson
Professor, Political Science
1541 Lilac Lane, Room 504
University of Kansas


From A.R.Runnalls at kent.ac.uk  Thu Apr 28 14:55:44 2011
From: A.R.Runnalls at kent.ac.uk (Andrew Runnalls)
Date: Thu, 28 Apr 2011 13:55:44 +0100
Subject: [Rd] Interrupting C++ code execution
In-Reply-To: <4DB53D47.7060903@arcor.de>
References: <4DB53D47.7060903@arcor.de>
Message-ID: <4DB963D0.9020701@kent.ac.uk>

Peter,

On 25/04/11 10:22, schattenpflanze at arcor.de wrote:
> 1. Calling R_CheckUserInterrupt() interrupts immediately, so I have no
> possibility to exit my code gracefully. In particular, I suppose that
> objects created on the heap (e.g., STL containers) are not destructed
> properly.

Sorry not to have seen this thread sooner.

You may like to give CXXR a try 
(http://www.cs.kent.ac.uk/projects/cxxr/).  In CXXR the R interpreter is 
written in C++, and a user interrupt is handled by throwing a C++ 
exception, so the stack is unwound in an orderly fashion, destructors 
are invoked, etc.

However, it's fair to say that in using CXXR with a multi-threaded 
program you'll be on the bleeding edge...

Andrew


From S.Ellison at lgc.co.uk  Thu Apr 28 15:09:12 2011
From: S.Ellison at lgc.co.uk (S Ellison)
Date: Thu, 28 Apr 2011 14:09:12 +0100
Subject: [Rd] median and data frames
Message-ID: <sdb9751a.084@tedmail.lgc.co.uk>

This seems trivially fixable using something like

median.data.frame <- function(x, na.rm=FALSE) {
   sapply(x, function(y, na.rm=FALSE) if(is.factor(y)) NA else
median(y, na.rm=na.rm), na.rm=na.rm)
}


>>> Paul Johnson <pauljohn32 at gmail.com> 28/04/2011 06:20 >>>
On Wed, Apr 27, 2011 at 12:44 PM, Patrick Burns
<pburns at pburns.seanet.com> wrote:
> Here are some data frames:
>
> df3.2 <- data.frame(1:3, 7:9)
> df4.2 <- data.frame(1:4, 7:10)
> df3.3 <- data.frame(1:3, 7:9, 10:12)
> df4.3 <- data.frame(1:4, 7:10, 10:13)
> df3.4 <- data.frame(1:3, 7:9, 10:12, 15:17)
> df4.4 <- data.frame(1:4, 7:10, 10:13, 15:18)
>
> Now here are some commands and their answers:

>> median(df4.4)
> [1]  8.5 11.5
>> median(df3.2[c(1,2,3),])
> [1] 2 8
>> median(df3.2[c(1,3,2),])
> [1]  2 NA
> Warning message:
> In mean.default(X[[2L]], ...) :
>  argument is not numeric or logical: returning NA
>
>
>
> The sessionInfo is below, but it looks
> to me like the present behavior started
> in 2.10.0.
>
> Sometimes it gets the right answer.  I'd
> be grateful to hear how it does that -- I
> can't figure it out.
>

Hello, Pat.

Nice poetry there!  I think I have an actual answer, as opposed to the
usual crap I spew.

I would agree if you said median.data.frame ought to be written to
work columnwise, similar to mean.data.frame.

apply and sapply  always give the correct answer

> apply(df3.3, 2, median)
  X1.3   X7.9 X10.12
     2      8     11

> apply(df3.2, 2, median)
X1.3 X7.9
   2    8

> apply(df3.2[c(1,3,2),], 2, median)
X1.3 X7.9
   2    8

mean.data.frame is now implemented as

mean.data.frame <- function(x, ...) sapply(x, mean, ...)

I think we would suggest this for medians:

??????????????????????

median.data.frame <- function(x,...) sapply(x, median, ...)

?????????????????????

It works, see:

> median.data.frame(df3.2[c(1,3,2),])
X1.3 X7.9
   2    8

Would our next step be to enter that somewhere in R bugzilla? (I'm not
joking--I'm that naive).

I think I can explain why the current median works intermittently in
those cases you mention.  Give it a small set of pre-sorted data, all
is well.  median.default uses a sort function, and it is confused when
it is given a data.frame object rather than just a vector.


I put a browser() at the top of median.default

> median(df3.2[c(1,3,2),])
Called from: median.default(df3.2[c(1, 3, 2), ])
Browse[1]> n
debug at <tmp>#4: if (is.factor(x)) stop("need numeric data")
Browse[2]> n
debug at <tmp>#4: NULL
Browse[2]> n
debug at <tmp>#6: if (length(names(x))) names(x) <- NULL
Browse[2]> n
debug at <tmp>#6: names(x) <- NULL
Browse[2]> n
debug at <tmp>#8: if (na.rm) x <- x[!is.na(x)] else if (any(is.na(x)))
return(x[FALSE][NA])
Browse[2]> n
debug at <tmp>#8: if (any(is.na(x))) return(x[FALSE][NA])
Browse[2]> n
debug at <tmp>#8: NULL
Browse[2]> n
debug at <tmp>#12: n <- length(x)
Browse[2]> n
debug at <tmp>#13: if (n == 0L) return(x[FALSE][NA])
Browse[2]> n
debug at <tmp>#13: NULL
Browse[2]> n
debug at <tmp>#15: half <- (n + 1L)%/%2L
Browse[2]> n
debug at <tmp>#16: if (n%%2L == 1L) sort(x, partial = half)[half] else
mean(sort(x,
    partial = half + 0L:1L)[half + 0L:1L])
Browse[2]> n
debug at <tmp>#16: mean(sort(x, partial = half + 0L:1L)[half + 0L:1L])
Browse[2]> n
[1]  2 NA
Warning message:
In mean.default(X[[2L]], ...) :
  argument is not numeric or logical: returning NA


Note the sort there in step 16. I think that's what is killing us.

If you are lucky, give it a small  data frame that is in order, like
df3.2, the sort doesn't produce gibberish. When I get to that point, I
will show you the sort's effect.

First, the case that "works". I moved the browser() down, because I
got tired of looking at the same old not-yet-erroneous output.


> median(df3.2)
Called from: median.default(df3.2)
Browse[1]> n
debug at <tmp>#15: half <- (n + 1L)%/%2L
Browse[2]> n
debug at <tmp>#16: if (n%%2L == 1L) sort(x, partial = half)[half] else
mean(sort(x,
    partial = half + 0L:1L)[half + 0L:1L])
Browse[2]> n
debug at <tmp>#16: mean(sort(x, partial = half + 0L:1L)[half + 0L:1L])

Interactively, type

Browse[2]> sort(x, partial = half + 0L:1L)
  NA NA   NA   NA   NA   NA
1  1  7 NULL NULL NULL NULL
2  2  8 <NA> <NA> <NA> <NA>
3  3  9 <NA> <NA> <NA> <NA>
Warning message:
In format.data.frame(x, digits = digits, na.encode = FALSE) :
  corrupt data frame: columns will be truncated or padded with NAs

But it still gives you a "right" answer:

Browse[2]> n
[1] 2 8


But if  you give it data out of order, the second column turns to NA,
and that causes doom.


> median(df3.2[c(1,3,2),])
Called from: median.default(df3.2[c(1, 3, 2), ])
Browse[1]> n
debug at <tmp>#15: half <- (n + 1L)%/%2L
Browse[2]> n
debug at <tmp>#16: if (n%%2L == 1L) sort(x, partial = half)[half] else
mean(sort(x,
    partial = half + 0L:1L)[half + 0L:1L])
Browse[2]> n
debug at <tmp>#16: mean(sort(x, partial = half + 0L:1L)[half + 0L:1L])

Interactively:

Browse[2]> sort(x, partial = half + 0L:1L)
  NA   NA NA   NA   NA   NA
1  1 NULL  7 NULL NULL NULL
3  3 <NA>  9 <NA> <NA> <NA>
2  2 <NA>  8 <NA> <NA> <NA>
Warning message:
In format.data.frame(x, digits = digits, na.encode = FALSE) :
  corrupt data frame: columns will be truncated or padded with NAs

Browse[2]> n
[1]  2 NA
Warning message:
In mean.default(X[[2L]], ...) :
  argument is not numeric or logical: returning NA


Here's a larger test case. Note columns 1 and 3 turn to NULL

> df8.8 <- data.frame(a=2:8, b=1:7)

median(df8.8)

debug at <tmp>#16: if (n%%2L == 1L) sort(x, partial = half)[half] else
mean(sort(x,
    partial = half + 0L:1L)[half + 0L:1L])
Browse[2]> n
debug at <tmp>#16: mean(sort(x, partial = half + 0L:1L)[half + 0L:1L])
Browse[2]> sort(x, partial = half + 0L:1L)
    NA NA   NA NA   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA
1 NULL  2 NULL  1 NULL NULL NULL NULL NULL NULL NULL NULL NULL NULL
2 <NA>  3 <NA>  2 <NA> <NA> <NA> <NA> <NA> <NA> <NA> <NA> <NA> <NA>
3 <NA>  4 <NA>  3 <NA> <NA> <NA> <NA> <NA> <NA> <NA> <NA> <NA> <NA>
4 <NA>  5 <NA>  4 <NA> <NA> <NA> <NA> <NA> <NA> <NA> <NA> <NA> <NA>
5 <NA>  6 <NA>  5 <NA> <NA> <NA> <NA> <NA> <NA> <NA> <NA> <NA> <NA>
6 <NA>  7 <NA>  6 <NA> <NA> <NA> <NA> <NA> <NA> <NA> <NA> <NA> <NA>
7 <NA>  8 <NA>  7 <NA> <NA> <NA> <NA> <NA> <NA> <NA> <NA> <NA> <NA>
Warning message:
In format.data.frame(x, digits = digits, na.encode = FALSE) :
  corrupt data frame: columns will be truncated or padded with NAs

Run ?sort and you see it was not intended for data.frames.

In conclusion, I think median applied to a data.frame causes undefined
behavior because median is not intending to deal with several columns
at once.


I don't see any changes in median.default that would explain the
changes you see. Compare:

>From R-2.13, src/library/stats/R/median.R
median.default <- function(x, na.rm = FALSE)
{
    if(is.factor(x)) stop("need numeric data")
    ## all other objects only need sort() & mean() to be working
    if(length(names(x))) names(x) <- NULL # for e.g., c(x = NA_real_)
    if(na.rm) x <- x[!is.na(x)] else if(any(is.na(x)))
return(x[FALSE][NA])
    n <- length(x)
    if (n == 0L) return(x[FALSE][NA])
    half <- (n + 1L) %/% 2L
    if(n %% 2L == 1L) sort(x, partial = half)[half]
    else mean(sort(x, partial = half + 0L:1L)[half + 0L:1L])
}


>From R-2.9.2
median.default <- function(x, na.rm = FALSE)
{
    if(is.factor(x)) stop("need numeric data")
    ## all other objects only need sort() & mean() to be working
    if(length(names(x))) names(x) <- NULL # for e.g., c(x = NA_real_)
    if(na.rm) x <- x[!is.na(x)] else if(any(is.na(x)))
return(x[FALSE][NA])
    n <- length(x)
    if (n == 0L) return(x[FALSE][NA])
    half <- (n + 1L) %/% 2L
    if(n %% 2L == 1L) sort(x, partial = half)[half]
    else mean(sort(x, partial = half + 0L:1L)[half + 0L:1L])
}



pj




-- 
Paul E. Johnson
Professor, Political Science
1541 Lilac Lane, Room 504
University of Kansas

______________________________________________
R-devel at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-devel

*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From bbolker at gmail.com  Thu Apr 28 16:06:01 2011
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 28 Apr 2011 10:06:01 -0400
Subject: [Rd] request for R-exts addition
Message-ID: <4DB97449.7040609@ufl.edu>


  would it be possible / make sense to copy some of the information in
?news into the R-exts manual, where package writers are most likely (?)
to look for it?  The information therein seems more appropriate for the
extensions manual ...

  cheers
    Ben Bolker


From peterhepperger at arcor.de  Thu Apr 28 15:25:08 2011
From: peterhepperger at arcor.de (peterhepperger at arcor.de)
Date: Thu, 28 Apr 2011 15:25:08 +0200
Subject: [Rd] Interrupting C++ code execution
In-Reply-To: <4DB963D0.9020701@kent.ac.uk>
References: <4DB53D47.7060903@arcor.de> <4DB963D0.9020701@kent.ac.uk>
Message-ID: <4DB96AB4.9050901@arcor.de>

Andrew,

> You may like to give CXXR a try 
> (http://www.cs.kent.ac.uk/projects/cxxr/).  In CXXR the R interpreter is 
> written in C++, and a user interrupt is handled by throwing a C++ 
> exception, so the stack is unwound in an orderly fashion, destructors 
> are invoked, etc.
Thank you for this suggestion. CXXR is a very interesting project!

For my current project, however, I aim at distributing the program to
other R users on pre-installed cluster nodes. Thus, I have no choice
with respect to the underlying R interpreter.

Best regards,
Peter


From armgong at yahoo.com  Wed Apr 27 16:08:49 2011
From: armgong at yahoo.com (Gong Yu)
Date: Wed, 27 Apr 2011 07:08:49 -0700 (PDT)
Subject: [Rd] patch about recent cairo device on win32
Message-ID: <370492.10852.qm@web45913.mail.sp1.yahoo.com>

dear all:

now I am happy with cairo  on win32, but  it depends gtk2 for windows and have 
CJK problem.

so I change a litte bit to avoid this two problem.


to apply those two patch, you should build pixman and cairo without gtk2 using 
mingw from source.

Yu Gong

From brett at fsf.org  Wed Apr 27 18:55:31 2011
From: brett at fsf.org (Brett Smith)
Date: Wed, 27 Apr 2011 12:55:31 -0400
Subject: [Rd] GPLv2-only code in R?
Message-ID: <4DB84A83.2090804@fsf.org>

Hello,

I'm sending this to R-devel under the guideline that the ensuing 
discussion would probably be unintelligible to people who aren't 
programmers.  If that's not right, I apologize.

<http://www.r-project.org/Licenses/> says in part: "Some files are 
licensed under 'GPL (version 2 or later)', which includes GPL-3. See the 
comments in the files to see if this applies."  This implies that there 
are files in R that do *not* have the "or later" language, and can only 
be used under GPLv2.

I've done some initial searches for files in the R source code that 
don't have the "or later" language, but haven't turned anything up yet. 
  If anybody knows of any off-hand and could point me to them, I'd 
appreciate it.

Thank you,

-- 
Brett Smith
License Compliance Engineer, Free Software Foundation

Support the FSF by becoming an Associate Member: http://fsf.org/jf


From armgong at yahoo.com  Wed Apr 27 21:29:17 2011
From: armgong at yahoo.com (Gong Yu)
Date: Wed, 27 Apr 2011 12:29:17 -0700 (PDT)
Subject: [Rd] cairo device on win32 without gtk2
Message-ID: <102514.88069.qm@web45906.mail.sp1.yahoo.com>

now  cairo device  work on win32, but  it depends gtk2 for windows and have CJK 
problem.

so I change a litte bit to avoid these two problem.

to apply these two patch, you should build pixman and cairo without gtk2 using 
mingw from source.

Yu Gong

From murdoch.duncan at gmail.com  Thu Apr 28 16:58:38 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 28 Apr 2011 10:58:38 -0400
Subject: [Rd] GPLv2-only code in R?
In-Reply-To: <4DB84A83.2090804@fsf.org>
References: <4DB84A83.2090804@fsf.org>
Message-ID: <4DB9809E.709@gmail.com>

On 27/04/2011 12:55 PM, Brett Smith wrote:
> Hello,
>
> I'm sending this to R-devel under the guideline that the ensuing
> discussion would probably be unintelligible to people who aren't
> programmers.  If that's not right, I apologize.
>
> <http://www.r-project.org/Licenses/>  says in part: "Some files are
> licensed under 'GPL (version 2 or later)', which includes GPL-3. See the
> comments in the files to see if this applies."  This implies that there
> are files in R that do *not* have the "or later" language, and can only
> be used under GPLv2.
>
> I've done some initial searches for files in the R source code that
> don't have the "or later" language, but haven't turned anything up yet.
>    If anybody knows of any off-hand and could point me to them, I'd
> appreciate it.

Package rpart is GPL-2-only in R 2.13.0, but is more liberally licensed 
in R-patched and R-devel.  The survival package was GPL-2-only until R 
2.12.1.

Duncan Murdoch


From ripley at stats.ox.ac.uk  Thu Apr 28 17:07:23 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 28 Apr 2011 16:07:23 +0100 (BST)
Subject: [Rd] GPLv2-only code in R?
In-Reply-To: <4DB9809E.709@gmail.com>
References: <4DB84A83.2090804@fsf.org> <4DB9809E.709@gmail.com>
Message-ID: <alpine.LFD.2.02.1104281606550.12223@toucan.stats.ox.ac.uk>

On Thu, 28 Apr 2011, Duncan Murdoch wrote:

> On 27/04/2011 12:55 PM, Brett Smith wrote:
>> Hello,
>> 
>> I'm sending this to R-devel under the guideline that the ensuing
>> discussion would probably be unintelligible to people who aren't
>> programmers.  If that's not right, I apologize.
>> 
>> <http://www.r-project.org/Licenses/>  says in part: "Some files are
>> licensed under 'GPL (version 2 or later)', which includes GPL-3. See the
>> comments in the files to see if this applies."  This implies that there
>> are files in R that do *not* have the "or later" language, and can only
>> be used under GPLv2.
>> 
>> I've done some initial searches for files in the R source code that
>> don't have the "or later" language, but haven't turned anything up yet.
>>    If anybody knows of any off-hand and could point me to them, I'd
>> appreciate it.
>
> Package rpart is GPL-2-only in R 2.13.0, but is more liberally licensed in 
> R-patched and R-devel.  The survival package was GPL-2-only until R 2.12.1.

And all of this in the COPYRIGHTS file for each version of R.

>
> Duncan Murdoch
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From rkevinburton at charter.net  Thu Apr 28 20:18:15 2011
From: rkevinburton at charter.net (Kevin Burton)
Date: Thu, 28 Apr 2011 13:18:15 -0500
Subject: [Rd] MDX package?
Message-ID: <001801cc05d0$a45322b0$ecf96810$@charter.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110428/45469702/attachment.pl>

From armgong at yahoo.com  Thu Apr 28 20:42:11 2011
From: armgong at yahoo.com (Gong Yu)
Date: Thu, 28 Apr 2011 11:42:11 -0700 (PDT)
Subject: [Rd] problems of new cairo device on win32
Message-ID: <472029.25911.qm@web45912.mail.sp1.yahoo.com>

yesterday i send two email about these problems, but I found the attached patch 
is removed, so i post again.

issue 1 :
  the new cairo device depend on gtk2, but gtk for windows is buggy, and cairo 
can be built without gtk2,
so I propose build  cairo without gtk2 using MinGW, so we can reduce the depend.

issue 2 :
  the default font  Helvetica is not an unicode font, so when plots contain 
 East Asia Char, there will be problem, 
I saw today svn commit,  on win32 now use  Arial font but still have CJK 
problem, I think the best way is using 
"Arial Unicode MS" font.

below is  the patch file, : 

Index: src/library/grDevices/src/cairo/cairoBM.c
===================================================================
--- src/library/grDevices/src/cairo/cairoBM.c(?? 55681)
+++ src/library/grDevices/src/cairo/cairoBM.c(????)
@@ -25,7 +25,7 @@
 /* This module is only compiled if HAVE_WORKING_CAIRO is true */
 
 #ifdef Win32
-#define HAVE_PANGOCAIRO 1
+#define HAVE_PANGOCAIRO 0
 #define HAVE_CAIRO_SVG 1
 #define HAVE_CAIRO_PDF 1
 #define HAVE_CAIRO_PS 1
Index: src/library/grDevices/src/cairo/cairoBM.h
===================================================================
--- src/library/grDevices/src/cairo/cairoBM.h(?? 55681)
+++ src/library/grDevices/src/cairo/cairoBM.h(????)
@@ -39,7 +39,9 @@
 
 
 #include <stdio.h>
-
+#ifdef Win32
+#undef HAVE_PANGOCAIRO
+#endif
 #ifdef HAVE_PANGOCAIRO
 #  include <pango/pango.h>
 #  include <pango/pangocairo.h>
Index: src/library/grDevices/src/cairo/cairoX11.c
===================================================================
--- src/library/grDevices/src/cairo/cairoX11.c(?? 55681)
+++ src/library/grDevices/src/cairo/cairoX11.c(????)
@@ -465,7 +465,11 @@
     return raster;
 }
 #endif
-                         
+
+#ifdef Win32
+ #undef HAVE_PANGOCAIRO  
+#endif
+
 #ifdef HAVE_PANGOCAIRO
 /* ------------- pangocairo section --------------- */
 
@@ -782,7 +786,11 @@
     pX11Desc xd = (pX11Desc) dd->deviceSpecific;
     int face = gc->fontface;
     double size = gc->cex * gc->ps *fs;
-    char *family = "Helvetica";
+    #ifdef Win32 
+      char *family = "Arial Unicode MS";
+    #else 
+     char *family = "Helvetica";
+    #endif
     int slant = CAIRO_FONT_SLANT_NORMAL, wt  = CAIRO_FONT_WEIGHT_NORMAL;
 #ifdef WIN32
     char *times = "Times New Roman", *hv = "Arial";
@@ -792,8 +800,8 @@
 
     char *fm = gc->fontfamily;
     if(streql(fm, "mono")) family = "courier";
-    else if(streql(fm, "serif")) family = times
-    else if(streql(fm, "sans")) family = hv
+    else if(streql(fm, "serif")) family = times;
+    else if(streql(fm, "sans")) family = hv;
     else if(fm[0]) family = fm;
     if (face < 1 || face > 5) face = 1;
     if (face == 5) family = "Symbol";
Index: src/library/grDevices/src/cairo/Makefile.win
===================================================================
--- src/library/grDevices/src/cairo/Makefile.win(?? 55681)
+++ src/library/grDevices/src/cairo/Makefile.win(????)
@@ -18,15 +18,11 @@
 
 
 PKG_CPPFLAGS=-I$(R_HOME)/src/include -I. -I.. -DHAVE_CONFIG_H  $(arch_DEFS)
-PKG_CPPFLAGS+= -I"$(GTK2_HOME)/include/cairo" \
-  -I"$(GTK2_HOME)/include/pango-1.0" \
-  -I"$(GTK2_HOME)/include/glib-2.0" \
-  -I"$(GTK2_HOME)/lib/glib-2.0/include" \
-  -I"$(GTK2_HOME)/include"
+PKG_CPPFLAGS+= -I"/MinGW/include/cairo" \
 
-PKG_LIBS=-L"$(GTK2_HOME)/lib" -lpangocairo-1.0 -lpango-1.0 -lcairo \
-  -lglib-2.0 -lgobject-2.0
+PKG_LIBS=-L"$(GTK2_HOME)/lib" -lcairo 
 
+
 all: winCairo.dll
 @cp winCairo.dll $(R_HOME)/library/grDevices/libs$(R_ARCH)


From Greg.Snow at imail.org  Thu Apr 28 22:31:25 2011
From: Greg.Snow at imail.org (Greg Snow)
Date: Thu, 28 Apr 2011 14:31:25 -0600
Subject: [Rd] Wish R Core had a standard format (or generic function)
 for "newdata" objects
In-Reply-To: <BANLkTinj6JPi=gXFuPXrZ9ZGrVv4RDbRCw@mail.gmail.com>
References: <BANLkTikCjqUM9YJhYtgLh4Q-z=0mpmgp2A@mail.gmail.com>
	<4DB765DD.3060900@gmail.com>
	<BANLkTinj6JPi=gXFuPXrZ9ZGrVv4RDbRCw@mail.gmail.com>
Message-ID: <B37C0A15B8FB3C468B5BC7EBC7DA14CC6346A7A0AA@LP-EXMBVS10.CO.IHC.COM>

Another way to see your plots is the TkPredict function in the TeachingDemos package.  It will default the variables to their medians for numeric predictors and baseline level for factors, but then you can set all of those to something more meaningful one time using the controls, then cycle through the predictors for the plots.  It can also give you a command line version of the commands that you could then run, or loop through to get your plots.

-- 
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at imail.org
801.408.8111


> -----Original Message-----
> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-
> project.org] On Behalf Of Paul Johnson
> Sent: Wednesday, April 27, 2011 10:20 AM
> To: Duncan Murdoch
> Cc: R Devel List
> Subject: Re: [Rd] Wish R Core had a standard format (or generic
> function) for "newdata" objects
> 
> On Tue, Apr 26, 2011 at 7:39 PM, Duncan Murdoch
> <murdoch.duncan at gmail.com> wrote:
> 
> > If you don't like the way this was done in my three lines above, or
> by Frank
> > Harrell, or the Zelig group, or John Fox, why don't you do it
> yourself, and
> > get it right this time? ?It's pretty rude to complain about things
> that
> > others have given you for free, and demand they do it better.
> >
> > Duncan Murdoch
> >
> 
> I offer sincere apology for sounding that way.  I'm not attacking
> anybody. I'm just talking, asking don't you agree this were
> standardized.  And you disagree, and I respect that since you are
> actually doing the work.
> 
> >From a "lowly user's point of view", I wish "you experts" out there
> would tell us one way to do this, we could follow your example.
> 
> When there's a regression model fitted with 20 variables in it, and
> half of them are numeric, 4 are unordered factors, 3 are ordinal
> factors, and what not, then this is a hard problem for many of us
> ordinary users.  Or it is tedious.  They want "keep everything fixed,"
> except one variable that takes on different specified values.  And
> they want to do that for every variable, one at a time.
> 
> Stata has made this easy for many models, R could as well, if we
> coalesced on a more-or-less standard way to create newdata objects for
> predict.
> 
> But, in the end, I agree with your sentiment.  I just have to do this,
> show you it is handy.  I think Zelig's setx has it about right, I'll
> pursue that strategy.
> 
> pj
> --
> Paul E. Johnson
> Professor, Political Science
> 1541 Lilac Lane, Room 504
> University of Kansas
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From ggrothendieck at gmail.com  Fri Apr 29 03:01:49 2011
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 28 Apr 2011 21:01:49 -0400
Subject: [Rd] error while checking package size during Rcmd check
Message-ID: <BANLkTi=2f-CYG1LuRc3Azma=mvDU0fsFoQ@mail.gmail.com>

I am receiving this message during
  Rcmd check proto-3.9.2.tar.gz
using "R version 2.13.0 Patched (2011-04-25 r55638)"

* checking installed package size ...Error in if (total > 1024 * 5) { : missing
value where TRUE/FALSE needed
Execution halted

I don't get this under R.2.12.x.  The size of the tar.gz file is under
600K.  What causes this or if its too hard to tell from the message
how can I investigate it further?

-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From ggrothendieck at gmail.com  Fri Apr 29 03:25:49 2011
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 28 Apr 2011 21:25:49 -0400
Subject: [Rd] error while checking package size during Rcmd check
In-Reply-To: <BANLkTi=2f-CYG1LuRc3Azma=mvDU0fsFoQ@mail.gmail.com>
References: <BANLkTi=2f-CYG1LuRc3Azma=mvDU0fsFoQ@mail.gmail.com>
Message-ID: <BANLkTikjAzkmwW7CGtDVLD16Ko5rj_T1=g@mail.gmail.com>

On Thu, Apr 28, 2011 at 9:01 PM, Gabor Grothendieck
<ggrothendieck at gmail.com> wrote:
> I am receiving this message during
> ?Rcmd check proto-3.9.2.tar.gz
> using "R version 2.13.0 Patched (2011-04-25 r55638)"
>
> * checking installed package size ...Error in if (total > 1024 * 5) { : missing
> value where TRUE/FALSE needed
> Execution halted
>
> I don't get this under R.2.12.x. ?The size of the tar.gz file is under
> 600K. ?What causes this or if its too hard to tell from the message
> how can I investigate it further?
>

Also I am using Windows Vista; however, I just found that by upgrading
to the latest Rtools the problem disappears.

-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From D.Strbenac at garvan.org.au  Fri Apr 29 04:00:16 2011
From: D.Strbenac at garvan.org.au (Dario Strbenac)
Date: Fri, 29 Apr 2011 12:00:16 +1000 (EST)
Subject: [Rd] R CMD check and Suggests Packages
Message-ID: <20110429120016.BLP71069@gimr.garvan.unsw.edu.au>

Hello,

In my description file, I have an example data package in Suggests: that I've deleted from my library to test what the user who doesn't have it will experience.

However, R CMD check won't even pass my package :

* checking package dependencies ... ERROR
Package required but not available: RepitoolsExamples

Why would it have to be installed, if it's only a data package, that isn't needed in any of my code ? The manual also says "In particular, large packages providing ?only? data for examples or vignettes should be listed in ?Suggests? rather than ?Depends? in order to make lean installations possible."

--------------------------------------
Dario Strbenac
Research Assistant
Cancer Epigenetics
Garvan Institute of Medical Research
Darlinghurst NSW 2010
Australia

From ripley at stats.ox.ac.uk  Fri Apr 29 11:29:36 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 29 Apr 2011 10:29:36 +0100 (BST)
Subject: [Rd] R CMD check and Suggests Packages
In-Reply-To: <20110429120016.BLP71069@gimr.garvan.unsw.edu.au>
References: <20110429120016.BLP71069@gimr.garvan.unsw.edu.au>
Message-ID: <alpine.LFD.2.02.1104291026210.21146@gannet.stats.ox.ac.uk>

On Fri, 29 Apr 2011, Dario Strbenac wrote:

> Hello,
>
> In my description file, I have an example data package in Suggests: 
> that I've deleted from my library to test what the user who doesn't 
> have it will experience.
>
> However, R CMD check won't even pass my package :
>
> * checking package dependencies ... ERROR
> Package required but not available: RepitoolsExamples
>
> Why would it have to be installed, if it's only a data package, that 
> isn't needed in any of my code ? The manual also says "In 
> particular, large packages providing ?only? data for examples or 
> vignettes should be listed in ?Suggests? rather than ?Depends? in 
> order to make lean installations possible."

Why suggest a package that 'isn't needed in any of my code'?

I suspect that is a lie, and some of your code does use it: if some it 
is needed to fully check the package.   There is a option to 'R CMD 
check' to enable the check to go ahead without all the dependencies, 
so please do re-read the manuals to find it.


> --------------------------------------
> Dario Strbenac
> Research Assistant
> Cancer Epigenetics
> Garvan Institute of Medical Research
> Darlinghurst NSW 2010
> Australia
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From maechler at stat.math.ethz.ch  Fri Apr 29 16:17:44 2011
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 29 Apr 2011 16:17:44 +0200
Subject: [Rd] request for R-exts addition
In-Reply-To: <4DB97449.7040609@ufl.edu>
References: <4DB97449.7040609@ufl.edu>
Message-ID: <19898.51336.279623.134281@stat.math.ethz.ch>

>>>>> Ben Bolker <bbolker at gmail.com>
>>>>>     on Thu, 28 Apr 2011 10:06:01 -0400 writes:

    >   would it be possible / make sense to copy some of the
    > information in ?news into the R-exts manual, where package
    > writers are most likely (?)  to look for it?  

sure...

    > The information therein seems more appropriate for the
    > extensions manual ...

you mean when we (R core) add extensions to package handling, Rd
syntax, the C API, ... and only report it in NEWS instead of
also updating the  R Extensions  manual?
Well, that happens as you can imagine.

In some cases, the entry in NEWS will say that a feature is
experimental, so we don't want to document it yet "in stone", as
we expect the details to change.

But apart from those, I'm sure it will also happen otherwise,
since most of R core have more fun writing code than manuals ....
but when we are "called to duty" we typically eventually oblige ;-)

So, yes indeed, it makes very much sense to keep the manual as
up-to-date as possible, and some of us  consider the manual to
be an important part of R's source tarball.

So, patches  and even other (concrete!) proposals for
improvement are welcome.
Ideally using texinfo syntax or even better a patch towards
a current version of the manual
	 <Rsource>/doc/manual/R-exts.texi 
from subversion, a nightly tarball, or simply
      https://svn.r-project.org/R/trunk/doc/manual/R-exts.texi

With many thanks in advance,

Martin Maechler, 
ETH Zurich


From mailinglist.honeypot at gmail.com  Fri Apr 29 15:52:43 2011
From: mailinglist.honeypot at gmail.com (Steve Lianoglou)
Date: Fri, 29 Apr 2011 09:52:43 -0400
Subject: [Rd] R CMD check and Suggests Packages
In-Reply-To: <alpine.LFD.2.02.1104291026210.21146@gannet.stats.ox.ac.uk>
References: <20110429120016.BLP71069@gimr.garvan.unsw.edu.au>
	<alpine.LFD.2.02.1104291026210.21146@gannet.stats.ox.ac.uk>
Message-ID: <BANLkTin=OmX99AF=0eRTonUeF7PB9cnrtg@mail.gmail.com>

Hi,

On Fri, Apr 29, 2011 at 5:29 AM, Prof Brian Ripley
<ripley at stats.ox.ac.uk> wrote:
> On Fri, 29 Apr 2011, Dario Strbenac wrote:
>
>> Hello,
>>
>> In my description file, I have an example data package in Suggests: that
>> I've deleted from my library to test what the user who doesn't have it will
>> experience.
>>
>> However, R CMD check won't even pass my package :
>>
>> * checking package dependencies ... ERROR
>> Package required but not available: RepitoolsExamples
>>
>> Why would it have to be installed, if it's only a data package, that isn't
>> needed in any of my code ? The manual also says "In particular, large
>> packages providing ?only? data for examples or vignettes should be listed in
>> ?Suggests? rather than ?Depends? in order to make lean installations
>> possible."
>
> Why suggest a package that 'isn't needed in any of my code'?
>
> I suspect that is a lie, and some of your code does use it: if some it is
> needed to fully check the package. ? There is a option to 'R CMD check' to
> enable the check to go ahead without all the dependencies, so please do
> re-read the manuals to find it.

Here's a stab in the dark:

Perhaps the OP has code in some \examples{} section for some help
(*.Rd) file that then tries to load data from the "suggested" package?

The code in the \examples{} sections of *.Rd files are run during R
CMD check ... so, if you're trying to load data from a suggested
package that may not be installed, perhaps you can wrap those code
blocks with \dontrun{}.

For more info: this is covered in the "Writing R Extensions," but is
also described here:
http://stackoverflow.com/questions/1454211/what-does-not-run-mean-in-r-help-pages

HTH,
-steve

-- 
Steve Lianoglou
Graduate Student: Computational Systems Biology
?| Memorial Sloan-Kettering Cancer Center
?| Weill Medical College of Cornell University
Contact Info: http://cbio.mskcc.org/~lianos/contact


From maechler at stat.math.ethz.ch  Fri Apr 29 16:25:09 2011
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 29 Apr 2011 16:25:09 +0200
Subject: [Rd] median and data frames
In-Reply-To: <BANLkTin6Cic0RhGdV_KWHcSz6JE5vj9igA@mail.gmail.com>
References: <4DB85617.8090706@pburns.seanet.com>
	<BANLkTin6Cic0RhGdV_KWHcSz6JE5vj9igA@mail.gmail.com>
Message-ID: <19898.51781.659704.798338@stat.math.ethz.ch>

>>>>> Paul Johnson <pauljohn32 at gmail.com>
>>>>>     on Thu, 28 Apr 2011 00:20:27 -0500 writes:

    > On Wed, Apr 27, 2011 at 12:44 PM, Patrick Burns
    > <pburns at pburns.seanet.com> wrote:
    >> Here are some data frames:
    >> 
    >> df3.2 <- data.frame(1:3, 7:9)
    >> df4.2 <- data.frame(1:4, 7:10)
    >> df3.3 <- data.frame(1:3, 7:9, 10:12)
    >> df4.3 <- data.frame(1:4, 7:10, 10:13)
    >> df3.4 <- data.frame(1:3, 7:9, 10:12, 15:17)
    >> df4.4 <- data.frame(1:4, 7:10, 10:13, 15:18)
    >> 
    >> Now here are some commands and their answers:

    >>> median(df4.4)
    >> [1] ?8.5 11.5
    >>> median(df3.2[c(1,2,3),])
    >> [1] 2 8
    >>> median(df3.2[c(1,3,2),])
    >> [1] ?2 NA
    >> Warning message:
    >> In mean.default(X[[2L]], ...) :
    >> ?argument is not numeric or logical: returning NA
    >> 
    >> 
    >> 
    >> The sessionInfo is below, but it looks
    >> to me like the present behavior started
    >> in 2.10.0.
    >> 
    >> Sometimes it gets the right answer. ?I'd
    >> be grateful to hear how it does that -- I
    >> can't figure it out.
    >> 

    > Hello, Pat.

    > Nice poetry there!  I think I have an actual answer, as opposed to the
    > usual crap I spew.

    > I would agree if you said median.data.frame ought to be written to
    > work columnwise, similar to mean.data.frame.

    > apply and sapply  always give the correct answer

    >> apply(df3.3, 2, median)
    > X1.3   X7.9 X10.12
    > 2      8     11

    [...........]

exactly

    > mean.data.frame is now implemented as

    > mean.data.frame <- function(x, ...) sapply(x, mean, ...)

exactly.

My personal oppinion is that  mean.data.frame() should never have
been written.
People should know, or learn, to use apply functions for such a
task.

The unfortunate fact that mean.data.frame() exists makes people
think that median.data.frame() should too,
and then  

  var.data.frame()
   sd.data.frame()
  mad.data.frame()
  min.data.frame()
  max.data.frame()
  ...
  ...

all just in order to *not* to have to know  sapply() 
????

No, rather not.

My vote is for deprecating  mean.data.frame().

Martin


From simon.urbanek at r-project.org  Fri Apr 29 16:36:00 2011
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Fri, 29 Apr 2011 10:36:00 -0400
Subject: [Rd] R CMD check and Suggests Packages
In-Reply-To: <BANLkTin=OmX99AF=0eRTonUeF7PB9cnrtg@mail.gmail.com>
References: <20110429120016.BLP71069@gimr.garvan.unsw.edu.au>
	<alpine.LFD.2.02.1104291026210.21146@gannet.stats.ox.ac.uk>
	<BANLkTin=OmX99AF=0eRTonUeF7PB9cnrtg@mail.gmail.com>
Message-ID: <55AB7D33-3717-44EC-82E2-AF0D2C45B977@r-project.org>


On Apr 29, 2011, at 9:52 AM, Steve Lianoglou wrote:

> Hi,
> 
> On Fri, Apr 29, 2011 at 5:29 AM, Prof Brian Ripley
> <ripley at stats.ox.ac.uk> wrote:
>> On Fri, 29 Apr 2011, Dario Strbenac wrote:
>> 
>>> Hello,
>>> 
>>> In my description file, I have an example data package in Suggests: that
>>> I've deleted from my library to test what the user who doesn't have it will
>>> experience.
>>> 
>>> However, R CMD check won't even pass my package :
>>> 
>>> * checking package dependencies ... ERROR
>>> Package required but not available: RepitoolsExamples
>>> 
>>> Why would it have to be installed, if it's only a data package, that isn't
>>> needed in any of my code ? The manual also says "In particular, large
>>> packages providing ?only? data for examples or vignettes should be listed in
>>> ?Suggests? rather than ?Depends? in order to make lean installations
>>> possible."
>> 
>> Why suggest a package that 'isn't needed in any of my code'?
>> 
>> I suspect that is a lie, and some of your code does use it: if some it is
>> needed to fully check the package.   There is a option to 'R CMD check' to
>> enable the check to go ahead without all the dependencies, so please do
>> re-read the manuals to find it.
> 
> Here's a stab in the dark:
> 
> Perhaps the OP has code in some \examples{} section for some help
> (*.Rd) file that then tries to load data from the "suggested" package?
> 

But that is a valid use of Suggests: as long as it is guarded against that package not being present.

The point here is that the default is to check those packages yet Dario doesn't like it and thus should turn it off if he feels so inclined. (That's my interpretation without knowing the package).

Cheers,
Simon



> The code in the \examples{} sections of *.Rd files are run during R
> CMD check ... so, if you're trying to load data from a suggested
> package that may not be installed, perhaps you can wrap those code
> blocks with \dontrun{}.
> 

Not really - that defeats the purpose - it will never be checked int hat case!


> For more info: this is covered in the "Writing R Extensions," but is
> also described here:
> http://stackoverflow.com/questions/1454211/what-does-not-run-mean-in-r-help-pages
> 
> HTH,
> -steve
> 
> -- 
> Steve Lianoglou
> Graduate Student: Computational Systems Biology
>  | Memorial Sloan-Kettering Cancer Center
>  | Weill Medical College of Cornell University
> Contact Info: http://cbio.mskcc.org/~lianos/contact
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From mtmorgan at fhcrc.org  Fri Apr 29 16:50:57 2011
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Fri, 29 Apr 2011 07:50:57 -0700
Subject: [Rd] R CMD check and Suggests Packages
In-Reply-To: <55AB7D33-3717-44EC-82E2-AF0D2C45B977@r-project.org>
References: <20110429120016.BLP71069@gimr.garvan.unsw.edu.au>	<alpine.LFD.2.02.1104291026210.21146@gannet.stats.ox.ac.uk>	<BANLkTin=OmX99AF=0eRTonUeF7PB9cnrtg@mail.gmail.com>
	<55AB7D33-3717-44EC-82E2-AF0D2C45B977@r-project.org>
Message-ID: <4DBAD051.9080902@fhcrc.org>

On 04/29/2011 07:36 AM, Simon Urbanek wrote:
>
> On Apr 29, 2011, at 9:52 AM, Steve Lianoglou wrote:
>
>> Hi,
>>
>> On Fri, Apr 29, 2011 at 5:29 AM, Prof Brian Ripley
>> <ripley at stats.ox.ac.uk>  wrote:
>>> On Fri, 29 Apr 2011, Dario Strbenac wrote:
>>>
>>>> Hello,
>>>>
>>>> In my description file, I have an example data package in Suggests: that
>>>> I've deleted from my library to test what the user who doesn't have it will
>>>> experience.
>>>>
>>>> However, R CMD check won't even pass my package :
>>>>
>>>> * checking package dependencies ... ERROR
>>>> Package required but not available: RepitoolsExamples
>>>>
>>>> Why would it have to be installed, if it's only a data package, that isn't
>>>> needed in any of my code ? The manual also says "In particular, large
>>>> packages providing ?only? data for examples or vignettes should be listed in
>>>> ?Suggests? rather than ?Depends? in order to make lean installations
>>>> possible."
>>>
>>> Why suggest a package that 'isn't needed in any of my code'?
>>>
>>> I suspect that is a lie, and some of your code does use it: if some it is
>>> needed to fully check the package.   There is a option to 'R CMD check' to
>>> enable the check to go ahead without all the dependencies, so please do
>>> re-read the manuals to find it.
>>
>> Here's a stab in the dark:
>>
>> Perhaps the OP has code in some \examples{} section for some help
>> (*.Rd) file that then tries to load data from the "suggested" package?
>>
>
> But that is a valid use of Suggests: as long as it is guarded against that package not being present.
>
> The point here is that the default is to check those packages yet Dario doesn't like it and thus should turn it off if he feels so inclined. (That's my interpretation without knowing the package).
>
> Cheers,
> Simon
>
>
>
>> The code in the \examples{} sections of *.Rd files are run during R
>> CMD check ... so, if you're trying to load data from a suggested
>> package that may not be installed, perhaps you can wrap those code
>> blocks with \dontrun{}.
>>
>
> Not really - that defeats the purpose - it will never be checked int hat case!

Maybe also useful to distinguish between package check and INSTALL, 
where during the former the Suggests: package must be present (modulo 
setting additional flags) but in the latter may not be. The Bioconductor 
build system, for instance, would install RepitoolsExamples  before 
running R CMD check Repitools. A user might successfully install 
Repitools without installing RepitoolsExamples.

"if (require(RepitoolsExamples))" in an example on a man page is much 
preferred to \dontrun{}, as Simon mentions.

Martin Morgan


>
>
>> For more info: this is covered in the "Writing R Extensions," but is
>> also described here:
>> http://stackoverflow.com/questions/1454211/what-does-not-run-mean-in-r-help-pages
>>
>> HTH,
>> -steve
>>
>> --
>> Steve Lianoglou
>> Graduate Student: Computational Systems Biology
>>   | Memorial Sloan-Kettering Cancer Center
>>   | Weill Medical College of Cornell University
>> Contact Info: http://cbio.mskcc.org/~lianos/contact
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
Computational Biology
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N. PO Box 19024 Seattle, WA 98109

Location: M1-B861
Telephone: 206 667-2793


From wdunlap at tibco.com  Fri Apr 29 18:09:14 2011
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 29 Apr 2011 09:09:14 -0700
Subject: [Rd] median and data frames
In-Reply-To: <19898.51781.659704.798338@stat.math.ethz.ch>
References: <4DB85617.8090706@pburns.seanet.com><BANLkTin6Cic0RhGdV_KWHcSz6JE5vj9igA@mail.gmail.com>
	<19898.51781.659704.798338@stat.math.ethz.ch>
Message-ID: <77EB52C6DD32BA4D87471DCD70C8D700042B8FAA@NA-PA-VBE03.na.tibco.com>

> From: r-devel-bounces at r-project.org 
> [mailto:r-devel-bounces at r-project.org] On Behalf Of Martin Maechler
> Sent: Friday, April 29, 2011 7:25 AM
> To: Paul Johnson
> Cc: r-devel
> Subject: Re: [Rd] median and data frames
> [ ... lots of lines elided ... ] 
> My vote is for deprecating  mean.data.frame().

While R's data.frame method for mean(x) returns
the same thing as colMeans(x), Splus's (since 2005)
returns the same thing as mean(as.matrix(x)).  (Really,
it calls numerical.matrix(x), which turns non-numeric
columns into columns of numeric NA's).  I usually favor
making data.frames act more like matrices when possible
(since users often conflate the two classes) and I
like having all the methods of a generic function return
the same sort of thing (a single value in this case).

It is often nonsensical to ask for the mean of an
entire data.frame, as the columns may have different
units even when they are all numeric.  It does make
sense when you use a tool like read.table() or S+'s
importData() to import a matrix and you don't notice
it is stored as a data.frame.  It does make sense when
you have a single-column data.frame or matrix, perhaps
arising from the use of drop=FALSE when subscripting.  

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com 

> Martin
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 


From hadley at rice.edu  Fri Apr 29 18:30:55 2011
From: hadley at rice.edu (Hadley Wickham)
Date: Fri, 29 Apr 2011 11:30:55 -0500
Subject: [Rd] median and data frames
In-Reply-To: <19898.51781.659704.798338@stat.math.ethz.ch>
References: <4DB85617.8090706@pburns.seanet.com>
	<BANLkTin6Cic0RhGdV_KWHcSz6JE5vj9igA@mail.gmail.com>
	<19898.51781.659704.798338@stat.math.ethz.ch>
Message-ID: <BANLkTinJWCnB9wXzsMoUojX1xot_Yq=5KQ@mail.gmail.com>

> My personal oppinion is that ?mean.data.frame() should never have
> been written.
> People should know, or learn, to use apply functions for such a
> task.
>
> The unfortunate fact that mean.data.frame() exists makes people
> think that median.data.frame() should too,
> and then
>
> ?var.data.frame()
> ? sd.data.frame()
> ?mad.data.frame()
> ?min.data.frame()
> ?max.data.frame()
> ?...
> ?...
>
> all just in order to *not* to have to know ?sapply()
> ????
>
> No, rather not.
>
> My vote is for deprecating ?mean.data.frame().

I totally agree!

Hadley

-- 
Assistant Professor / Dobelman Family Junior Chair
Department of Statistics / Rice University
http://had.co.nz/


From hadley at rice.edu  Fri Apr 29 18:33:59 2011
From: hadley at rice.edu (Hadley Wickham)
Date: Fri, 29 Apr 2011 11:33:59 -0500
Subject: [Rd] R CMD check and Suggests Packages
In-Reply-To: <4DBAD051.9080902@fhcrc.org>
References: <20110429120016.BLP71069@gimr.garvan.unsw.edu.au>
	<alpine.LFD.2.02.1104291026210.21146@gannet.stats.ox.ac.uk>
	<BANLkTin=OmX99AF=0eRTonUeF7PB9cnrtg@mail.gmail.com>
	<55AB7D33-3717-44EC-82E2-AF0D2C45B977@r-project.org>
	<4DBAD051.9080902@fhcrc.org>
Message-ID: <BANLkTinKYpOn1wm+eVyf-o1YpVJTWkfQRw@mail.gmail.com>

> Maybe also useful to distinguish between package check and INSTALL, where
> during the former the Suggests: package must be present (modulo setting
> additional flags) but in the latter may not be. The Bioconductor build
> system, for instance, would install RepitoolsExamples ?before running R CMD
> check Repitools. A user might successfully install Repitools without
> installing RepitoolsExamples.

There's also the case a suggested package isn't available for a
specific platform, the CRAN builders will still build it.

Hadley

-- 
Assistant Professor / Dobelman Family Junior Chair
Department of Statistics / Rice University
http://had.co.nz/


From pburns at pburns.seanet.com  Fri Apr 29 20:29:46 2011
From: pburns at pburns.seanet.com (Patrick Burns)
Date: Fri, 29 Apr 2011 19:29:46 +0100
Subject: [Rd] median and data frames
In-Reply-To: <19898.51781.659704.798338@stat.math.ethz.ch>
References: <4DB85617.8090706@pburns.seanet.com>	<BANLkTin6Cic0RhGdV_KWHcSz6JE5vj9igA@mail.gmail.com>
	<19898.51781.659704.798338@stat.math.ethz.ch>
Message-ID: <4DBB039A.70609@pburns.seanet.com>

If Martin's proposal is accepted, does
that mean that the median method for
data frames would be something like:

function (x, ...)
{
         stop(paste("you probably mean to use the command: sapply(",
                 deparse(substitute(x)), ", median)", sep=""))
}

Pat


On 29/04/2011 15:25, Martin Maechler wrote:
>>>>>> Paul Johnson<pauljohn32 at gmail.com>
>>>>>>      on Thu, 28 Apr 2011 00:20:27 -0500 writes:
>
>      >  On Wed, Apr 27, 2011 at 12:44 PM, Patrick Burns
>      >  <pburns at pburns.seanet.com>  wrote:
>      >>  Here are some data frames:
>      >>
>      >>  df3.2<- data.frame(1:3, 7:9)
>      >>  df4.2<- data.frame(1:4, 7:10)
>      >>  df3.3<- data.frame(1:3, 7:9, 10:12)
>      >>  df4.3<- data.frame(1:4, 7:10, 10:13)
>      >>  df3.4<- data.frame(1:3, 7:9, 10:12, 15:17)
>      >>  df4.4<- data.frame(1:4, 7:10, 10:13, 15:18)
>      >>
>      >>  Now here are some commands and their answers:
>
>      >>>  median(df4.4)
>      >>  [1]  8.5 11.5
>      >>>  median(df3.2[c(1,2,3),])
>      >>  [1] 2 8
>      >>>  median(df3.2[c(1,3,2),])
>      >>  [1]  2 NA
>      >>  Warning message:
>      >>  In mean.default(X[[2L]], ...) :
>      >>    argument is not numeric or logical: returning NA
>      >>
>      >>
>      >>
>      >>  The sessionInfo is below, but it looks
>      >>  to me like the present behavior started
>      >>  in 2.10.0.
>      >>
>      >>  Sometimes it gets the right answer.  I'd
>      >>  be grateful to hear how it does that -- I
>      >>  can't figure it out.
>      >>
>
>      >  Hello, Pat.
>
>      >  Nice poetry there!  I think I have an actual answer, as opposed to the
>      >  usual crap I spew.
>
>      >  I would agree if you said median.data.frame ought to be written to
>      >  work columnwise, similar to mean.data.frame.
>
>      >  apply and sapply  always give the correct answer
>
>      >>  apply(df3.3, 2, median)
>      >  X1.3   X7.9 X10.12
>      >  2      8     11
>
>      [...........]
>
> exactly
>
>      >  mean.data.frame is now implemented as
>
>      >  mean.data.frame<- function(x, ...) sapply(x, mean, ...)
>
> exactly.
>
> My personal oppinion is that  mean.data.frame() should never have
> been written.
> People should know, or learn, to use apply functions for such a
> task.
>
> The unfortunate fact that mean.data.frame() exists makes people
> think that median.data.frame() should too,
> and then
>
>    var.data.frame()
>     sd.data.frame()
>    mad.data.frame()
>    min.data.frame()
>    max.data.frame()
>    ...
>    ...
>
> all just in order to *not* to have to know  sapply()
> ????
>
> No, rather not.
>
> My vote is for deprecating  mean.data.frame().
>
> Martin
>

-- 
Patrick Burns
pburns at pburns.seanet.com
twitter: @portfolioprobe
http://www.portfolioprobe.com/blog
http://www.burns-stat.com
(home of 'Some hints for the R beginner'
and 'The R Inferno')


From mtmorgan at fhcrc.org  Sat Apr 30 00:13:50 2011
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Fri, 29 Apr 2011 15:13:50 -0700
Subject: [Rd] Windows Rzlib.dll gzopen and friends
Message-ID: <4DBB381E.7020601@fhcrc.org>

Several Bioconductor packages were expecting Windows Rzlib.dll to 
provide gzopen / gzread / gzseek / gzgets / gzrewind / gzclose. Are 
these gone for good, viz., r55624 ?

Martin
-- 
Computational Biology
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N. PO Box 19024 Seattle, WA 98109

Location: M1-B861
Telephone: 206 667-2793


From hpages at fhcrc.org  Sat Apr 30 00:54:09 2011
From: hpages at fhcrc.org (=?windows-1252?Q?Herv=E9_Pag=E8s?=)
Date: Fri, 29 Apr 2011 15:54:09 -0700
Subject: [Rd] R CMD build processes inst/doc/Makefile only if there are
 vignette files?
In-Reply-To: <alpine.LFD.2.02.1103300946510.20705@gannet.stats.ox.ac.uk>
References: <BANLkTinYAyuKfHy74QKkqOBFfT3tiF8t5g@mail.gmail.com>
	<alpine.LFD.2.02.1103300946510.20705@gannet.stats.ox.ac.uk>
Message-ID: <4DBB4191.80809@fhcrc.org>

On 11-03-30 01:55 AM, Prof Brian Ripley wrote:
> What R CMD build (and check) does is to call tools::buildVignettes.
> That has been true for a while, and buildVignettes() returns if no
> vignettes are found. The docs are out-of-date.
>
> My view is that you are misusing inst/doc: it is intended *only* for
> files which are going to be installed and hence report.tex should not
> really be there. So you should be doing this in another source directory
> and copying report.pdf to inst/doc. Use configure to arrange this.
>
> Shortly vignettes to be built will be moved out of inst/doc.

Could you please elaborate on this? I just found this in the NEWS for
R 2.14.0:

   o The preferred location for vignette sources is now the directory
     ?vignettes? and not ?inst/doc?: R CMD build will now re-build
     vignettes in ?vignettes? and copy the ?.Rnw? (etc) files and
     the corresponding PDFs to ?inst/doc?.

Sounds like an important move. What are the long term plans: keep
both inst/doc/ and vignettes/ as places for vignettes to be built?
Or drop inst/doc/ at some point?

Thanks!
H.


>
> On Tue, 29 Mar 2011, Henrik Bengtsson wrote:
>
>> Hi,
>>
>> in Section 'Writing package vignettes' of 'Writing R Extensions' it says:
>>
>> "Whenever a Makefile is found, then R CMD build will try to run make
>> after the Sweave runs, so PDF manuals can be created from arbitrary
>> source formats (plain LaTeX files, ...). [...] Note that the make step
>> is executed even if there are no files in Sweave format, [...]".
>>
>> In my package, inst/doc/ file contains two files: Makefile, and
>> report.tex. However, when running 'Rcmd build' on Windows with R
>> v2.13.0 alpha (2011-03-27 r55091) I can only get 'make' to run
>> (process inst/doc/Makefile) if I add a inst/doc/dummy.Rnw file,
>> otherwise nothing happens. My Makefile contains:
>>
>> all: pdf
>>
>> pdf: report.tex
>> texi2dvi --pdf report.tex
>>
>> clean:
>> rm dummy.Rnw dummy.tex
>> rm *.aux *.log *.toc
>>
>> Is it really necessary to add dummy.Rnw? Am I missing something?
>>
>> /Henrik
>>
>>> sessionInfo()
>> R version 2.13.0 alpha (2011-03-27 r55091)
>> Platform: x86_64-pc-mingw32/x64 (64-bit)
>>
>> locale:
>> [1] LC_COLLATE=English_United States.1252
>> [2] LC_CTYPE=English_United States.1252
>> [3] LC_MONETARY=English_United States.1252
>> [4] LC_NUMERIC=C
>> [5] LC_TIME=English_United States.1252
>>
>> attached base packages:
>> [1] stats graphics grDevices utils datasets methods base
>>
>> loaded via a namespace (and not attached):
>> [1] tools_2.13.0
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>


-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M2-B876
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fhcrc.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From baptiste.auguie at googlemail.com  Sat Apr 30 01:58:40 2011
From: baptiste.auguie at googlemail.com (baptiste auguie)
Date: Sat, 30 Apr 2011 11:58:40 +1200
Subject: [Rd] grid stringHeight
In-Reply-To: <BANLkTik0dL-oC8GzAqAJsNanZDF7LpndsA@mail.gmail.com>
References: <BANLkTik0dL-oC8GzAqAJsNanZDF7LpndsA@mail.gmail.com>
Message-ID: <BANLkTi=s04Ft8oVV077x8kLWW+hSuTLC+w@mail.gmail.com>

On 27 April 2011 11:06, baptiste auguie <baptiste.auguie at googlemail.com> wrote:
> Dear all,
>
> I'm puzzled by the behavior of stringHeight in the grid package.
> Consider the following test,
>
> library(grid)
>
> test <- function(lab="dog", ...){
> ?g1 <- textGrob(lab)
> ?g2 <- rectGrob(height=grobHeight(g1), width=grobWidth(g1))
> ?gg <- gTree(children=gList(g1,g2), ...)
>
> ?print(c("height:", convertUnit(stringHeight(lab), "mm", "y")))
> ?grid.draw(gg)
> }
>
> grid.newpage()
> test()
> test(expression(dog), vp=viewport(x=0.6))
> ## notice how the dog's tail is being cut off, where
> ## expression yields a snug cage
>
> grid.newpage()
> test("aoc")
> test(expression(aoc), vp=viewport(x=0.6))
>
> It appears that stringHeight correctly calculates the height for an
> expression, but not for a basic string. I think it used to produce the
> same output for both.
>
> Best regards,
>
> baptiste
>
> sessionInfo()
> R version 2.13.0 alpha (2011-03-27 r55076)
> Platform: i386-apple-darwin9.8.0 (32-bit)
>
> locale:
> [1] C
>
> attached base packages:
> [1] stats ? ? graphics ?grDevices utils ? ? datasets ?grid ? ? ?methods
> [8] base
>

I have now filed a bug report for this issue, though I could only
confirm it on one operating system.

https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=14566

Best regards,

baptiste


From D.Strbenac at garvan.org.au  Sat Apr 30 06:00:12 2011
From: D.Strbenac at garvan.org.au (Dario Strbenac)
Date: Sat, 30 Apr 2011 14:00:12 +1000 (EST)
Subject: [Rd] R CMD check and Suggests Packages
Message-ID: <20110430140012.BLP92138@gimr.garvan.unsw.edu.au>

The intention was more to have another place to make the user aware of a real-sized data package I made, since the package only comes with trivially sized data. The help examples and vignette only use the small sized data, and never the realistic dataset. I suppose it is better just to put a reference to it in the vignette and describe its availability in there.


From ripley at stats.ox.ac.uk  Sat Apr 30 07:36:17 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 30 Apr 2011 06:36:17 +0100 (BST)
Subject: [Rd] R CMD build processes inst/doc/Makefile only if there are
 vignette files?
In-Reply-To: <4DBB4191.80809@fhcrc.org>
References: <BANLkTinYAyuKfHy74QKkqOBFfT3tiF8t5g@mail.gmail.com>
	<alpine.LFD.2.02.1103300946510.20705@gannet.stats.ox.ac.uk>
	<4DBB4191.80809@fhcrc.org>
Message-ID: <alpine.LFD.2.02.1104300630100.15222@gannet.stats.ox.ac.uk>

On Fri, 29 Apr 2011, Herv? Pag?s wrote:

> On 11-03-30 01:55 AM, Prof Brian Ripley wrote:
>> What R CMD build (and check) does is to call tools::buildVignettes.
>> That has been true for a while, and buildVignettes() returns if no
>> vignettes are found. The docs are out-of-date.
>> 
>> My view is that you are misusing inst/doc: it is intended *only* for
>> files which are going to be installed and hence report.tex should not
>> really be there. So you should be doing this in another source directory
>> and copying report.pdf to inst/doc. Use configure to arrange this.
>> 
>> Shortly vignettes to be built will be moved out of inst/doc.
>
> Could you please elaborate on this? I just found this in the NEWS for
> R 2.14.0:
>
>  o The preferred location for vignette sources is now the directory
>    ?vignettes? and not ?inst/doc?: R CMD build will now re-build
>    vignettes in ?vignettes? and copy the ?.Rnw? (etc) files and
>    the corresponding PDFs to ?inst/doc?.
>
> Sounds like an important move. What are the long term plans: keep
> both inst/doc/ and vignettes/ as places for vignettes to be built?
> Or drop inst/doc/ at some point?

Drop inst/doc at some point.  It doesn't make much difference to the 
codebase: all the work is done in pkgVignettes().

>
> Thanks!
> H.
>
>
>> 
>> On Tue, 29 Mar 2011, Henrik Bengtsson wrote:
>> 
>>> Hi,
>>> 
>>> in Section 'Writing package vignettes' of 'Writing R Extensions' it says:
>>> 
>>> "Whenever a Makefile is found, then R CMD build will try to run make
>>> after the Sweave runs, so PDF manuals can be created from arbitrary
>>> source formats (plain LaTeX files, ...). [...] Note that the make step
>>> is executed even if there are no files in Sweave format, [...]".
>>> 
>>> In my package, inst/doc/ file contains two files: Makefile, and
>>> report.tex. However, when running 'Rcmd build' on Windows with R
>>> v2.13.0 alpha (2011-03-27 r55091) I can only get 'make' to run
>>> (process inst/doc/Makefile) if I add a inst/doc/dummy.Rnw file,
>>> otherwise nothing happens. My Makefile contains:
>>> 
>>> all: pdf
>>> 
>>> pdf: report.tex
>>> texi2dvi --pdf report.tex
>>> 
>>> clean:
>>> rm dummy.Rnw dummy.tex
>>> rm *.aux *.log *.toc
>>> 
>>> Is it really necessary to add dummy.Rnw? Am I missing something?
>>> 
>>> /Henrik
>>> 
>>>> sessionInfo()
>>> R version 2.13.0 alpha (2011-03-27 r55091)
>>> Platform: x86_64-pc-mingw32/x64 (64-bit)
>>> 
>>> locale:
>>> [1] LC_COLLATE=English_United States.1252
>>> [2] LC_CTYPE=English_United States.1252
>>> [3] LC_MONETARY=English_United States.1252
>>> [4] LC_NUMERIC=C
>>> [5] LC_TIME=English_United States.1252
>>> 
>>> attached base packages:
>>> [1] stats graphics grDevices utils datasets methods base
>>> 
>>> loaded via a namespace (and not attached):
>>> [1] tools_2.13.0
>>> 
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>> 
>> 
>
>
> -- 
> Herv? Pag?s
>
> Program in Computational Biology
> Division of Public Health Sciences
> Fred Hutchinson Cancer Research Center
> 1100 Fairview Ave. N, M2-B876
> P.O. Box 19024
> Seattle, WA 98109-1024
>
> E-mail: hpages at fhcrc.org
> Phone:  (206) 667-5791
> Fax:    (206) 667-1319
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From timhesterberg at gmail.com  Sat Apr 30 17:19:31 2011
From: timhesterberg at gmail.com (Tim Hesterberg)
Date: Sat, 30 Apr 2011 08:19:31 -0700
Subject: [Rd] median and data frames
In-Reply-To: <4DBB039A.70609@pburns.seanet.com> (message from Patrick Burns on
	Fri, 29 Apr 2011 19:29:46 +0100)
References: <4DBB039A.70609@pburns.seanet.com>
Message-ID: <yajfei4j6a2k.fsf@gmail.com>

I also favor deprecating mean.data.frame.

One possible exception would be for a single-column data frame.
But even here I'd say no, lest people expect the same behavior for
median, var, ...

Pat's suggestion of using stop() would work nicely for mean.
(but omit paste - stop handles that).

Tim Hesterberg

>If Martin's proposal is accepted, does
>that mean that the median method for
>data frames would be something like:
>
>function (x, ...)
>{
>         stop(paste("you probably mean to use the command: sapply(",
>                 deparse(substitute(x)), ", median)", sep=""))
>}
>
>Pat
>
>
>On 29/04/2011 15:25, Martin Maechler wrote:
>>>>>>> Paul Johnson<pauljohn32 at gmail.com>
>>>>>>>      on Thu, 28 Apr 2011 00:20:27 -0500 writes:
>>
>>      >  On Wed, Apr 27, 2011 at 12:44 PM, Patrick Burns
>>      >  <pburns at pburns.seanet.com>  wrote:
>>      >>  Here are some data frames:
>>      >>
>>      >>  df3.2<- data.frame(1:3, 7:9)
>>      >>  df4.2<- data.frame(1:4, 7:10)
>>      >>  df3.3<- data.frame(1:3, 7:9, 10:12)
>>      >>  df4.3<- data.frame(1:4, 7:10, 10:13)
>>      >>  df3.4<- data.frame(1:3, 7:9, 10:12, 15:17)
>>      >>  df4.4<- data.frame(1:4, 7:10, 10:13, 15:18)
>>      >>
>>      >>  Now here are some commands and their answers:
>>
>>      >>>  median(df4.4)
>>      >>  [1]  8.5 11.5
>>      >>>  median(df3.2[c(1,2,3),])
>>      >>  [1] 2 8
>>      >>>  median(df3.2[c(1,3,2),])
>>      >>  [1]  2 NA
>>      >>  Warning message:
>>      >>  In mean.default(X[[2L]], ...) :
>>      >>    argument is not numeric or logical: returning NA
>>      >>
>>      >>
>>      >>
>>      >>  The sessionInfo is below, but it looks
>>      >>  to me like the present behavior started
>>      >>  in 2.10.0.
>>      >>
>>      >>  Sometimes it gets the right answer.  I'd
>>      >>  be grateful to hear how it does that -- I
>>      >>  can't figure it out.
>>      >>
>>
>>      >  Hello, Pat.
>>
>>      >  Nice poetry there!  I think I have an actual answer, as opposed to the
>>      >  usual crap I spew.
>>
>>      >  I would agree if you said median.data.frame ought to be written to
>>      >  work columnwise, similar to mean.data.frame.
>>
>>      >  apply and sapply  always give the correct answer
>>
>>      >>  apply(df3.3, 2, median)
>>      >  X1.3   X7.9 X10.12
>>      >  2      8     11
>>
>>      [...........]
>>
>> exactly
>>
>>      >  mean.data.frame is now implemented as
>>
>>      >  mean.data.frame<- function(x, ...) sapply(x, mean, ...)
>>
>> exactly.
>>
>> My personal oppinion is that  mean.data.frame() should never have
>> been written.
>> People should know, or learn, to use apply functions for such a
>> task.
>>
>> The unfortunate fact that mean.data.frame() exists makes people
>> think that median.data.frame() should too,
>> and then
>>
>>    var.data.frame()
>>     sd.data.frame()
>>    mad.data.frame()
>>    min.data.frame()
>>    max.data.frame()
>>    ...
>>    ...
>>
>> all just in order to *not* to have to know  sapply()
>> ????
>>
>> No, rather not.
>>
>> My vote is for deprecating  mean.data.frame().
>>
>> Martin
>>
>
>--
>Patrick Burns
>pburns at pburns.seanet.com
>twitter: @portfolioprobe
>http://www.portfolioprobe.com/blog
>http://www.burns-stat.com
>(home of 'Some hints for the R beginner'
>and 'The R Inferno')


From SeshanV at mskcc.org  Sat Apr 30 17:20:59 2011
From: SeshanV at mskcc.org (SeshanV at mskcc.org)
Date: Sat, 30 Apr 2011 11:20:59 -0400
Subject: [Rd] Kendall's tau code
Message-ID: <3C5050149D662D4C8E41A0EC71CAE93447EBB30DAE@SMSKPEX7MBX6.MSKCC.ROOT.MSKCC.ORG>

I discovered that  the Kendall's tau calculation in R uses all pairwise comparisons which is O(n^2) and takes a long time for large vectors. I implemented a O(n*log(n)) algorithm based on merge-sort. Is this of interest to be included in core R? The code (fortran and R wrapper) is available in my package clinfun v0.9.7 (not exported in NAMESPACE). 

Thanks,
Venkat

-- 
Venkatraman E. Seshan, Ph.D. | Attending Biostatistician
Director of Biostatistics Computer-Intensive Support Services
Department of Epidemiology and Biostatistics | MSKCC
307 E 63rd St 3rd Floor | New York, NY 10065
Phone: 646-735-8126 | Fax: 646-735-0010

 
     =====================================================================
     
     Please note that this e-mail and any files transmitted with it may be 
     privileged, confidential, and protected from disclosure under 
     applicable law. If the reader of this message is not the intended 
     recipient, or an employee or agent responsible for delivering this 
     message to the intended recipient, you are hereby notified that any 
     reading, dissemination, distribution, copying, or other use of this 
     communication or any of its attachments is strictly prohibited.  If 
     you have received this communication in error, please notify the 
     sender immediately by replying to this message and deleting this 
     message, any attachments, and all copies and backups from your 
     computer.


From chad.goymer at hotmail.co.uk  Sat Apr 30 18:35:24 2011
From: chad.goymer at hotmail.co.uk (Chad Goymer)
Date: Sat, 30 Apr 2011 16:35:24 +0000
Subject: [Rd] Reference Classes: Accessing methods via [[...]], bug?
Message-ID: <SNT131-w42BCCDD218A68509A634CFB99D0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110430/9dd50b16/attachment.pl>

From maechler at stat.math.ethz.ch  Sat Apr 30 23:05:23 2011
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Sat, 30 Apr 2011 23:05:23 +0200
Subject: [Rd] Kendall's tau code
In-Reply-To: <3C5050149D662D4C8E41A0EC71CAE93447EBB30DAE@SMSKPEX7MBX6.MSKCC.ROOT.MSKCC.ORG>
References: <3C5050149D662D4C8E41A0EC71CAE93447EBB30DAE@SMSKPEX7MBX6.MSKCC.ROOT.MSKCC.ORG>
Message-ID: <19900.31123.896985.311637@stat.math.ethz.ch>

>>>>> "S" == SeshanV  <SeshanV at mskcc.org>
>>>>>     on Sat, 30 Apr 2011 11:20:59 -0400 writes:

    > I discovered that the Kendall's tau calculation in R uses
    > all pairwise comparisons which is O(n^2) and takes a long time for
    > large vectors. I implemented a O(n*log(n)) algorithm based on
    > merge-sort. Is this of interest to be included in core R? 

Yes, quite a bit of interest!

I know about the O(n^2) "feature" for quite a while, and it is
indeed a considerable problem in copula modelling which has
become an interest of mine in the recent year.

    > The code (fortran and R wrapper) is available in my package clinfun v0.9.7
    > (not exported in NAMESPACE).  

Thank you! Yes, I see you've put them there quite recently.
I see the Fortran code uses modern allocate / deallocate
constructs (that I don't know).
As I think we'd want to use this in the C code which is also
underlying
	cor(*, method="kendall")
I'll eventually want a C version, not the least because we may
look into dealing with  NA 's in the same -- flexible -- way
that they are handled currently via the  'use = "..."'
argument.

I may contact you privately for more.
Thanks again,

Martin Maechler, 
ETH Zurich (and R Core Team).



    >Thanks, Venkat

    > -- 
    > Venkatraman E. Seshan, Ph.D. | Attending Biostatistician
    > Director of Biostatistics Computer-Intensive Support Services
    > Department of Epidemiology and Biostatistics | MSKCC
    > 307 E 63rd St 3rd Floor | New York, NY 10065
    > Phone: 646-735-8126 | Fax: 646-735-0010

    > ______________________________________________
    > R-devel at r-project.org mailing list
    > https://stat.ethz.ch/mailman/listinfo/r-devel


