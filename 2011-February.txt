From maechler at stat.math.ethz.ch  Tue Feb  1 09:22:03 2011
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 1 Feb 2011 09:22:03 +0100
Subject: [Rd] [.raster bug {was "str() on raster objects fails .."}
In-Reply-To: <AANLkTimycPK-3_mj5OPd0eLauAh41r2-Wkrp7j2jo1sw@mail.gmail.com>
References: <AANLkTimycPK-3_mj5OPd0eLauAh41r2-Wkrp7j2jo1sw@mail.gmail.com>
Message-ID: <19783.49835.494142.88222@stat.math.ethz.ch>

>>>>> Henrik Bengtsson <hb at biostat.ucsf.edu>
>>>>>     on Mon, 31 Jan 2011 11:16:59 -0800 writes:

    > Hi, str() on raster objects fails for certain dimensions.  For
    > example:

    >> str(as.raster(0, nrow=1, ncol=100)) 'raster' chr [1, 1:100]
    > "#000000" "#000000" "#000000" "#000000" ...

    >> str(as.raster(0, nrow=1, ncol=101)) Error in `[.raster`(object,
    > seq_len(max.len)) : subscript out of bounds

    > This seems to do with how str() and "[.raster"() is coded; when
    > subsetting as a vector, which str() relies on, "[.raster"()
    > still returns a matrix-like object, e.g.

    >> img <- as.raster(1:25, max=25, nrow=5, ncol=5);
    >> img[1:2]
    > [,1]      [,2]      [,3]      [,4]      [,5]
    > [1,] "#0A0A0A" "#3D3D3D" "#707070" "#A3A3A3" "#D6D6D6"
    > [2,] "#141414" "#474747" "#7A7A7A" "#ADADAD" "#E0E0E0"

    > compare with:

    >> as.matrix(img)[1:2]
    > [1] "#0A0A0A" "#3D3D3D"


    > The easy but incomplete fix is to do:

    > str.raster <- function(object, ...) {
    > str(as.matrix(object), ...);
    > }

    > Other suggestions?

The informal "raster" class is behaving ``illogical''
in the following sense:

 > r <- as.raster(0, nrow=1, ncol=11)
 > r[seq_along(r)]
 Error in `[.raster`(r, seq_along(r)) : subscript out of bounds

or, here equivalently,
 > r[1:length(r)]
 Error in `[.raster`(r, 1:length(r)) : subscript out of bounds

When classes do behave in such a way, they definitely need their
own str() method.

However, the bug really is in "[.raster":
Currently,  r[i] is equivalent to  r[i,]  which is not at all 
matrix-like and its help clearly says that subsetting should
work as for matrices.
A recent thread on R-help/R-devel has mentioned the fact that
"[" methods for matrix-like methods need to use both nargs() and
missing() and that "[.dataframe" has been the example to follow
"forever", IIRC already in S and S-plus as of 20 years ago.

Thank you, Henrik, for the bug report.
Martin


From jwiley.psych at gmail.com  Tue Feb  1 20:00:07 2011
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Tue, 1 Feb 2011 11:00:07 -0800
Subject: [Rd] dotchart {graphics} 2.11.1 vs. 2.12.1 [followed up from Rhelp]
Message-ID: <AANLkTi=-Ja17h9X2cx1AJB-+a7dK7tQUSK2SBP+fMZMy@mail.gmail.com>

Dear List,

With the R 2.12.0 addition of table methods for points(), dotchart()
struggles with tables.  I found several possible solutions, but it is
beyond my skill to decide what is "best".  Here is a small example:


#############################################
x <- table(infert$education)
y <- 1:3L

dotchart(x) # error about incorrect plot type

## moving closer to the cause, dotchart() essentially does
plot(x = c(0, 150), y = c(0, 5), type = "n")
points(x, y) # error, because arg #2 is the type

## One option would be to explicitly name the arguments in dotchart()
points(x = x, y = y) # "works", but misses the point (no pun intended)

## Another possibility would be to add unclass(). I'm not sure
## if this would have other repercussions.  line 71 could become:
points(unclass(x), y, pch = pch, col = color, bg = bg)

## Other options could be adding a method for dotchart()
## or to update the table method for points()
points.table <- function (x, y, type = "h", lwd = 2, ...)
{
    if (length(dim(x)) == 1L) {
        nx <- dimnames(x)[[1L]]
        is.num <- suppressWarnings(!any(is.na(xx <- as.numeric(nx))))
        x0 <- if (is.num)
            xx
        else seq.int(x)
        if (missing(y)) {
          points(x0, unclass(x), type = type, lwd = lwd, ...)
        } else points(unclass(x), y, type = type, lwd = lwd, ...)
    }
    else stop("only for 1-D table")
}

plot(x = c(0, 150), y = c(0, 5), type = "n")
points(x, y, type = "p")

#############################################



-- 
Joshua Wiley
Ph.D. Student, Health Psychology
University of California, Los Angeles
http://www.joshuawiley.com/


From djsamperi at gmail.com  Wed Feb  2 01:45:26 2011
From: djsamperi at gmail.com (Dominick Samperi)
Date: Tue, 1 Feb 2011 19:45:26 -0500
Subject: [Rd] Warning: you may need to use R-patched with recent R
	distros
In-Reply-To: <alpine.LFD.2.02.1101312015170.18622@gannet.stats.ox.ac.uk>
References: <C96C7042.22581%ken.williams@thomsonreuters.com>
	<alpine.LFD.2.02.1101312015170.18622@gannet.stats.ox.ac.uk>
Message-ID: <AANLkTi=jJ584GSoxR25Tyrvo43iFntTF4M7x1ET+yJ+o@mail.gmail.com>

On Mon, Jan 31, 2011 at 3:18 PM, Prof Brian Ripley
<ripley at stats.ox.ac.uk> wrote:
> On Mon, 31 Jan 2011, Ken.Williams at thomsonreuters.com wrote:
>
>> For the complex-numbers bug, do you know a reliable way (besides looking
>> at version numbers) to determine whether the bug is present or absent in a
>> given build?
>
> I know a way: See tests/complex.R in R-devel.
>
> z <- 0.2853725+0.3927816i
> z2 <- z^(1:20)
> z3 <- z^-(1:20)
> z0 <- cumprod(rep(z, 20))
> stopifnot(all.equal(z2, z0), all.equal(z3, 1/z0))
> ## z^3 had value z^2 ....
>

I tried this under Fedora 14 (GCC 4.5.1) using the released R 2.12.1 and
R-devel (2.13.0 devel) and saw no problems? I compared the numbers with
those generated by Octave, took the cube root of z^3 and got z, ran this
unit test and stopifnot did not terminate, etc.

At build time the optimization level was O2.

Dominick

>>
>> I don't know what version of gcc was used in my build nor the optimization
>> flags, so I did a few test exponentiations z^n and the results look okay,
>> but maybe I'm not tickling the right bits.
>>
>>
>> --
>> Ken Williams
>> Senior Research Scientist
>> Thomson Reuters
>> Phone: 651-848-7712
>> ken.williams at thomsonreuters.com
>> http://labs.thomsonreuters.com
>>
>>
>>
>>
>>
>> On 1/31/11 1:48 PM, "Prof Brian Ripley" <ripley at stats.ox.ac.uk> wrote:
>>
>>> Two things have emerged in testing on x86_64 Fedora 14 which mean that
>>> a recent R-patched is probably needed.
>>>
>>> 1) That OS uses zlib 1.2.5: that claims to be binary-compatible with
>>> zlib 1.2.3 but is not, as we found (painfully) on Windows. ?The remedy
>>> was to remap _all_ the symbols in R's own copy of zlib (not just those
>>> zlib arranged to remap).
>>>
>>> The symptoms were crashes using packages XML and rgoobi (both of which
>>> link to zlib) and incorrect results in RJaCGH (which contains a copy
>>> of zlib). ?There may well be other problems ....
>>>
>>> 2) ?Fedora 14 uses gcc 4.5.1. With CFLAGS containing the default -O2
>>> or higher, HAVE_C99_COMPLEX was detected as false because there is a
>>> (genuine) incompatibility between types Rcomplex and C99's double
>>> complex. ?This means that R's fallback code is used, and regretably
>>> that contains a serious bug in an 'optimization' by a colleague, so
>>> z^n is incorrect for most complex z and integer n (and has been since
>>> 2.10.0). ?The remedy is to use R-patched or R-devel, or only optimize
>>> to -O.
>>>
>>> We've also seen incorrect results from package mvtnorm when C
>>> optimization was -O3.
>>>
>>> The upshot is that there is likely to be a 2.12.2 to fix these issues.
>>>
>>> --
>>> Brian D. Ripley, ? ? ? ? ? ? ? ? ?ripley at stats.ox.ac.uk
>>> Professor of Applied Statistics, ?http://www.stats.ox.ac.uk/~ripley/
>>> University of Oxford, ? ? ? ? ? ? Tel: ?+44 1865 272861 (self)
>>> 1 South Parks Road, ? ? ? ? ? ? ? ? ? ? +44 1865 272866 (PA)
>>> Oxford OX1 3TG, UK ? ? ? ? ? ? ? ?Fax: ?+44 1865 272595
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>
>>
>
> --
> Brian D. Ripley, ? ? ? ? ? ? ? ? ?ripley at stats.ox.ac.uk
> Professor of Applied Statistics, ?http://www.stats.ox.ac.uk/~ripley/
> University of Oxford, ? ? ? ? ? ? Tel: ?+44 1865 272861 (self)
> 1 South Parks Road, ? ? ? ? ? ? ? ? ? ? +44 1865 272866 (PA)
> Oxford OX1 3TG, UK ? ? ? ? ? ? ? ?Fax: ?+44 1865 272595
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From p.murrell at auckland.ac.nz  Wed Feb  2 01:46:35 2011
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Wed, 02 Feb 2011 13:46:35 +1300
Subject: [Rd] [.raster bug {was "str() on raster objects fails .."}
In-Reply-To: <19783.49835.494142.88222@stat.math.ethz.ch>
References: <AANLkTimycPK-3_mj5OPd0eLauAh41r2-Wkrp7j2jo1sw@mail.gmail.com>
	<19783.49835.494142.88222@stat.math.ethz.ch>
Message-ID: <4D48A96B.9020801@auckland.ac.nz>

Hi

On 1/02/2011 9:22 p.m., Martin Maechler wrote:
>>>>>> Henrik Bengtsson<hb at biostat.ucsf.edu>
>>>>>>      on Mon, 31 Jan 2011 11:16:59 -0800 writes:
>
>      >  Hi, str() on raster objects fails for certain dimensions.  For
>      >  example:
>
>      >>  str(as.raster(0, nrow=1, ncol=100)) 'raster' chr [1, 1:100]
>      >  "#000000" "#000000" "#000000" "#000000" ...
>
>      >>  str(as.raster(0, nrow=1, ncol=101)) Error in `[.raster`(object,
>      >  seq_len(max.len)) : subscript out of bounds
>
>      >  This seems to do with how str() and "[.raster"() is coded; when
>      >  subsetting as a vector, which str() relies on, "[.raster"()
>      >  still returns a matrix-like object, e.g.
>
>      >>  img<- as.raster(1:25, max=25, nrow=5, ncol=5);
>      >>  img[1:2]
>      >  [,1]      [,2]      [,3]      [,4]      [,5]
>      >  [1,] "#0A0A0A" "#3D3D3D" "#707070" "#A3A3A3" "#D6D6D6"
>      >  [2,] "#141414" "#474747" "#7A7A7A" "#ADADAD" "#E0E0E0"
>
>      >  compare with:
>
>      >>  as.matrix(img)[1:2]
>      >  [1] "#0A0A0A" "#3D3D3D"
>
>
>      >  The easy but incomplete fix is to do:
>
>      >  str.raster<- function(object, ...) {
>      >  str(as.matrix(object), ...);
>      >  }
>
>      >  Other suggestions?
>
> The informal "raster" class is behaving ``illogical''
> in the following sense:
>
>   >  r<- as.raster(0, nrow=1, ncol=11)
>   >  r[seq_along(r)]
>   Error in `[.raster`(r, seq_along(r)) : subscript out of bounds
>
> or, here equivalently,
>   >  r[1:length(r)]
>   Error in `[.raster`(r, 1:length(r)) : subscript out of bounds
>
> When classes do behave in such a way, they definitely need their
> own str() method.
>
> However, the bug really is in "[.raster":
> Currently,  r[i] is equivalent to  r[i,]  which is not at all
> matrix-like and its help clearly says that subsetting should
> work as for matrices.
> A recent thread on R-help/R-devel has mentioned the fact that
> "[" methods for matrix-like methods need to use both nargs() and
> missing() and that "[.dataframe" has been the example to follow
> "forever", IIRC already in S and S-plus as of 20 years ago.

The main motivation for non-standard behaviour here is to make sure that 
a subset of a raster object NEVER produces a vector (because the 
conversion back to a raster object then produces a single-column raster 
and that may be a "surprise").  Thanks for making the code more standard 
and robust.

The r[i] case is still tricky.  The following behaviour is quite 
convenient ...

r[r == "black"] <- "white"

... but the next behaviour is quite jarring (at least in terms of the 
raster image that results from it) ...

r2 <- r[1:(nrow(r) + 1)]

So I think there is some justification for further non-standardness to 
try to ensure that the subset of a raster image always produces a 
sensible image.  A simple solution would be just to outlaw r[i] for 
raster objects and force the user to write r[i, ] or r[, j], depending 
on what they want.

Paul

> Thank you, Henrik, for the bug report.
> Martin
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/


From hb at biostat.ucsf.edu  Wed Feb  2 02:03:18 2011
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Tue, 1 Feb 2011 17:03:18 -0800
Subject: [Rd] [.raster bug {was "str() on raster objects fails .."}
In-Reply-To: <4D48A96B.9020801@auckland.ac.nz>
References: <AANLkTimycPK-3_mj5OPd0eLauAh41r2-Wkrp7j2jo1sw@mail.gmail.com>
	<19783.49835.494142.88222@stat.math.ethz.ch>
	<4D48A96B.9020801@auckland.ac.nz>
Message-ID: <AANLkTimRBZbzgRfAkE2-VhnFmVRkWz1-cCqeD4VW7O42@mail.gmail.com>

On Tue, Feb 1, 2011 at 4:46 PM, Paul Murrell <p.murrell at auckland.ac.nz> wrote:
> Hi
>
> On 1/02/2011 9:22 p.m., Martin Maechler wrote:
>>>>>>>
>>>>>>> Henrik Bengtsson<hb at biostat.ucsf.edu>
>>>>>>> ? ? on Mon, 31 Jan 2011 11:16:59 -0800 writes:
>>
>> ? ? > ?Hi, str() on raster objects fails for certain dimensions. ?For
>> ? ? > ?example:
>>
>> ? ? >> ?str(as.raster(0, nrow=1, ncol=100)) 'raster' chr [1, 1:100]
>> ? ? > ?"#000000" "#000000" "#000000" "#000000" ...
>>
>> ? ? >> ?str(as.raster(0, nrow=1, ncol=101)) Error in `[.raster`(object,
>> ? ? > ?seq_len(max.len)) : subscript out of bounds
>>
>> ? ? > ?This seems to do with how str() and "[.raster"() is coded; when
>> ? ? > ?subsetting as a vector, which str() relies on, "[.raster"()
>> ? ? > ?still returns a matrix-like object, e.g.
>>
>> ? ? >> ?img<- as.raster(1:25, max=25, nrow=5, ncol=5);
>> ? ? >> ?img[1:2]
>> ? ? > ?[,1] ? ? ?[,2] ? ? ?[,3] ? ? ?[,4] ? ? ?[,5]
>> ? ? > ?[1,] "#0A0A0A" "#3D3D3D" "#707070" "#A3A3A3" "#D6D6D6"
>> ? ? > ?[2,] "#141414" "#474747" "#7A7A7A" "#ADADAD" "#E0E0E0"
>>
>> ? ? > ?compare with:
>>
>> ? ? >> ?as.matrix(img)[1:2]
>> ? ? > ?[1] "#0A0A0A" "#3D3D3D"
>>
>>
>> ? ? > ?The easy but incomplete fix is to do:
>>
>> ? ? > ?str.raster<- function(object, ...) {
>> ? ? > ?str(as.matrix(object), ...);
>> ? ? > ?}
>>
>> ? ? > ?Other suggestions?
>>
>> The informal "raster" class is behaving ``illogical''
>> in the following sense:
>>
>> ?> ?r<- as.raster(0, nrow=1, ncol=11)
>> ?> ?r[seq_along(r)]
>> ?Error in `[.raster`(r, seq_along(r)) : subscript out of bounds
>>
>> or, here equivalently,
>> ?> ?r[1:length(r)]
>> ?Error in `[.raster`(r, 1:length(r)) : subscript out of bounds
>>
>> When classes do behave in such a way, they definitely need their
>> own str() method.
>>
>> However, the bug really is in "[.raster":
>> Currently, ?r[i] is equivalent to ?r[i,] ?which is not at all
>> matrix-like and its help clearly says that subsetting should
>> work as for matrices.
>> A recent thread on R-help/R-devel has mentioned the fact that
>> "[" methods for matrix-like methods need to use both nargs() and
>> missing() and that "[.dataframe" has been the example to follow
>> "forever", IIRC already in S and S-plus as of 20 years ago.
>
> The main motivation for non-standard behaviour here is to make sure that a
> subset of a raster object NEVER produces a vector (because the conversion
> back to a raster object then produces a single-column raster and that may be
> a "surprise"). ?Thanks for making the code more standard and robust.
>
> The r[i] case is still tricky. ?The following behaviour is quite convenient
> ...
>
> r[r == "black"] <- "white"
>
> ... but the next behaviour is quite jarring (at least in terms of the raster
> image that results from it) ...
>
> r2 <- r[1:(nrow(r) + 1)]
>
> So I think there is some justification for further non-standardness to try
> to ensure that the subset of a raster image always produces a sensible
> image. ?A simple solution would be just to outlaw r[i] for raster objects
> and force the user to write r[i, ] or r[, j], depending on what they want.

FYI, I've tried out Martin's updated version at it seems like a
one-column raster matrix is now returned for r[i], e.g.

> r <- as.raster(1:8, max=8, nrow=2, ncol=4);
> r
     [,1]      [,2]      [,3]      [,4]
[1,] "#202020" "#606060" "#9F9F9F" "#DFDFDF"
[2,] "#404040" "#808080" "#BFBFBF" "#FFFFFF"

> r[1:length(r)]
     [,1]
[1,] "#202020"
[2,] "#404040"
[3,] "#606060"
[4,] "#808080"
[5,] "#9F9F9F"
[6,] "#BFBFBF"
[7,] "#DFDFDF"
[8,] "#FFFFFF"

> r[1:5,drop=TRUE]
     [,1]
[1,] "#202020"
[2,] "#404040"
[3,] "#606060"
[4,] "#808080"
[5,] "#9F9F9F"
Warning message:
In `[.raster`(r, 1:5, drop = TRUE) :
  'drop' is always implicitly FALSE in '[.raster'

Also,

> r[1:5] <- "white"
> r
     [,1]    [,2]    [,3]      [,4]
[1,] "white" "white" "white"   "#DFDFDF"
[2,] "white" "white" "#BFBFBF" "#FFFFFF"

/Henrik

>
> Paul
>
>> Thank you, Henrik, for the bug report.
>> Martin
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> --
> Dr Paul Murrell
> Department of Statistics
> The University of Auckland
> Private Bag 92019
> Auckland
> New Zealand
> 64 9 3737599 x85392
> paul at stat.auckland.ac.nz
> http://www.stat.auckland.ac.nz/~paul/
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From p.murrell at auckland.ac.nz  Wed Feb  2 02:16:58 2011
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Wed, 02 Feb 2011 14:16:58 +1300
Subject: [Rd] [.raster bug {was "str() on raster objects fails .."}
In-Reply-To: <AANLkTimRBZbzgRfAkE2-VhnFmVRkWz1-cCqeD4VW7O42@mail.gmail.com>
References: <AANLkTimycPK-3_mj5OPd0eLauAh41r2-Wkrp7j2jo1sw@mail.gmail.com>	<19783.49835.494142.88222@stat.math.ethz.ch>	<4D48A96B.9020801@auckland.ac.nz>
	<AANLkTimRBZbzgRfAkE2-VhnFmVRkWz1-cCqeD4VW7O42@mail.gmail.com>
Message-ID: <4D48B08A.40302@auckland.ac.nz>

Hi

On 2/02/2011 2:03 p.m., Henrik Bengtsson wrote:
> On Tue, Feb 1, 2011 at 4:46 PM, Paul Murrell<p.murrell at auckland.ac.nz>  wrote:
>> Hi
>>
>> On 1/02/2011 9:22 p.m., Martin Maechler wrote:
>>>>>>>>
>>>>>>>> Henrik Bengtsson<hb at biostat.ucsf.edu>
>>>>>>>>      on Mon, 31 Jan 2011 11:16:59 -0800 writes:
>>>
>>>      >    Hi, str() on raster objects fails for certain dimensions.  For
>>>      >    example:
>>>
>>>      >>    str(as.raster(0, nrow=1, ncol=100)) 'raster' chr [1, 1:100]
>>>      >    "#000000" "#000000" "#000000" "#000000" ...
>>>
>>>      >>    str(as.raster(0, nrow=1, ncol=101)) Error in `[.raster`(object,
>>>      >    seq_len(max.len)) : subscript out of bounds
>>>
>>>      >    This seems to do with how str() and "[.raster"() is coded; when
>>>      >    subsetting as a vector, which str() relies on, "[.raster"()
>>>      >    still returns a matrix-like object, e.g.
>>>
>>>      >>    img<- as.raster(1:25, max=25, nrow=5, ncol=5);
>>>      >>    img[1:2]
>>>      >    [,1]      [,2]      [,3]      [,4]      [,5]
>>>      >    [1,] "#0A0A0A" "#3D3D3D" "#707070" "#A3A3A3" "#D6D6D6"
>>>      >    [2,] "#141414" "#474747" "#7A7A7A" "#ADADAD" "#E0E0E0"
>>>
>>>      >    compare with:
>>>
>>>      >>    as.matrix(img)[1:2]
>>>      >    [1] "#0A0A0A" "#3D3D3D"
>>>
>>>
>>>      >    The easy but incomplete fix is to do:
>>>
>>>      >    str.raster<- function(object, ...) {
>>>      >    str(as.matrix(object), ...);
>>>      >    }
>>>
>>>      >    Other suggestions?
>>>
>>> The informal "raster" class is behaving ``illogical''
>>> in the following sense:
>>>
>>>   >    r<- as.raster(0, nrow=1, ncol=11)
>>>   >    r[seq_along(r)]
>>>   Error in `[.raster`(r, seq_along(r)) : subscript out of bounds
>>>
>>> or, here equivalently,
>>>   >    r[1:length(r)]
>>>   Error in `[.raster`(r, 1:length(r)) : subscript out of bounds
>>>
>>> When classes do behave in such a way, they definitely need their
>>> own str() method.
>>>
>>> However, the bug really is in "[.raster":
>>> Currently,  r[i] is equivalent to  r[i,]  which is not at all
>>> matrix-like and its help clearly says that subsetting should
>>> work as for matrices.
>>> A recent thread on R-help/R-devel has mentioned the fact that
>>> "[" methods for matrix-like methods need to use both nargs() and
>>> missing() and that "[.dataframe" has been the example to follow
>>> "forever", IIRC already in S and S-plus as of 20 years ago.
>>
>> The main motivation for non-standard behaviour here is to make sure that a
>> subset of a raster object NEVER produces a vector (because the conversion
>> back to a raster object then produces a single-column raster and that may be
>> a "surprise").  Thanks for making the code more standard and robust.
>>
>> The r[i] case is still tricky.  The following behaviour is quite convenient
>> ...
>>
>> r[r == "black"]<- "white"
>>
>> ... but the next behaviour is quite jarring (at least in terms of the raster
>> image that results from it) ...
>>
>> r2<- r[1:(nrow(r) + 1)]
>>
>> So I think there is some justification for further non-standardness to try
>> to ensure that the subset of a raster image always produces a sensible
>> image.  A simple solution would be just to outlaw r[i] for raster objects
>> and force the user to write r[i, ] or r[, j], depending on what they want.
>
> FYI, I've tried out Martin's updated version at it seems like a
> one-column raster matrix is now returned for r[i], e.g.

Yes, that's what I've been looking at ...

>> r<- as.raster(1:8, max=8, nrow=2, ncol=4);
>> r
>       [,1]      [,2]      [,3]      [,4]
> [1,] "#202020" "#606060" "#9F9F9F" "#DFDFDF"
> [2,] "#404040" "#808080" "#BFBFBF" "#FFFFFF"
>
>> r[1:length(r)]
>       [,1]
> [1,] "#202020"
> [2,] "#404040"
> [3,] "#606060"
> [4,] "#808080"
> [5,] "#9F9F9F"
> [6,] "#BFBFBF"
> [7,] "#DFDFDF"
> [8,] "#FFFFFF"

... and the above is exactly the sort of thing that will fry your mind 
if the image that you are subsetting is, for example, a photo.

Paul

>> r[1:5,drop=TRUE]
>       [,1]
> [1,] "#202020"
> [2,] "#404040"
> [3,] "#606060"
> [4,] "#808080"
> [5,] "#9F9F9F"
> Warning message:
> In `[.raster`(r, 1:5, drop = TRUE) :
>    'drop' is always implicitly FALSE in '[.raster'
>
> Also,
>
>> r[1:5]<- "white"
>> r
>       [,1]    [,2]    [,3]      [,4]
> [1,] "white" "white" "white"   "#DFDFDF"
> [2,] "white" "white" "#BFBFBF" "#FFFFFF"
>
> /Henrik
>
>>
>> Paul
>>
>>> Thank you, Henrik, for the bug report.
>>> Martin
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>> --
>> Dr Paul Murrell
>> Department of Statistics
>> The University of Auckland
>> Private Bag 92019
>> Auckland
>> New Zealand
>> 64 9 3737599 x85392
>> paul at stat.auckland.ac.nz
>> http://www.stat.auckland.ac.nz/~paul/
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/


From D.Strbenac at garvan.org.au  Wed Feb  2 03:00:11 2011
From: D.Strbenac at garvan.org.au (Dario Strbenac)
Date: Wed,  2 Feb 2011 13:00:11 +1100 (EST)
Subject: [Rd] Memory Leak
Message-ID: <20110202130011.BKR98832@gimr.garvan.unsw.edu.au>

Hello,

I'm trying to track down the cause of some extreme memory usage and I've been using Dirk Eddelbuettel's lsos() function he posted on stack overflow. There is a large difference between R's RAM usage :

PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND
6637 darstr    20   0 30.0g  29g 4712 S    0 63.2  10:34.43 R 

and what objects I have loaded in memory :

> lsos()
           Type      Size PrettySize     Rows Columns
A          list 552387720   526.8 Mb        2      NA
B   GRangesList 552376408   526.8 Mb        4      NA
C SimpleRleList 353421896     337 Mb       24      NA
D       GRanges 236410608   225.5 Mb 15272853      NA
E    data.frame   6981952     6.7 Mb    24966      14
F    data.frame   6782136     6.5 Mb    24966      13
G          list   4393704     4.2 Mb    24964      NA
H        matrix   3195760       3 Mb    24964      16
I          list   1798752     1.7 Mb    24964      NA
J       GRanges    312656   305.3 Kb    24964      NA

(The total looks like about 1.5 GB)

I haven't got any calls to external C code in my R script, although the Bioconductor packages I am using do. How can I regain those missing Gigabytes ?

--------------------------------------
Dario Strbenac
Research Assistant
Cancer Epigenetics
Garvan Institute of Medical Research
Darlinghurst NSW 2010
Australia


From simon.urbanek at r-project.org  Wed Feb  2 03:29:38 2011
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Tue, 1 Feb 2011 21:29:38 -0500
Subject: [Rd] Memory Leak
In-Reply-To: <20110202130011.BKR98832@gimr.garvan.unsw.edu.au>
References: <20110202130011.BKR98832@gimr.garvan.unsw.edu.au>
Message-ID: <A2DAF529-A6C3-482C-A36C-D1BDC742592E@r-project.org>


On Feb 1, 2011, at 9:00 PM, Dario Strbenac wrote:

> Hello,
> 
> I'm trying to track down the cause of some extreme memory usage and I've been using Dirk Eddelbuettel's lsos() function he posted on stack overflow. There is a large difference between R's RAM usage :
> 
> PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND
> 6637 darstr    20   0 30.0g  29g 4712 S    0 63.2  10:34.43 R 
> 
> and what objects I have loaded in memory :
> 
>> lsos()
>           Type      Size PrettySize     Rows Columns
> A          list 552387720   526.8 Mb        2      NA
> B   GRangesList 552376408   526.8 Mb        4      NA
> C SimpleRleList 353421896     337 Mb       24      NA
> D       GRanges 236410608   225.5 Mb 15272853      NA
> E    data.frame   6981952     6.7 Mb    24966      14
> F    data.frame   6782136     6.5 Mb    24966      13
> G          list   4393704     4.2 Mb    24964      NA
> H        matrix   3195760       3 Mb    24964      16
> I          list   1798752     1.7 Mb    24964      NA
> J       GRanges    312656   305.3 Kb    24964      NA
> 
> (The total looks like about 1.5 GB)
> 
> I haven't got any calls to external C code in my R script, although the Bioconductor packages I am using do. How can I regain those missing Gigabytes ?
> 

There is no reason why the two numbers should have anything in common. The OS (assuming the above is supposed to be ps output) reports memory that the OS reserved (it is not necessarily what the application is currently using) and lsos (assuming you meant to point to this: http://stackoverflow.com/questions/1358003/tricks-to-manage-the-available-memory-in-an-r-session ) simply shows approximate size estimates of objects in your workspace. So you can expect the former to be larger than the latter (often but not necessarily always) but that's about all you can say.

If you want to know what R objects are allocated, just look at gc() - it has the actual numbers. However, that only includes transient allocations using the R GC, any memory reserved directly from the OS will not be included. Furthermore, many OSes don't release memory from processes for performance reasons so even if you had exact allocation numbers they would not match what you see in ps.

I you want to lean more, you'll have to grab the tools available for your platform to find out who's allocating what. Since you didn't even mention your platform I can't really help you with the specifics, though.

Cheers,
Simon


From D.Strbenac at garvan.org.au  Wed Feb  2 06:00:10 2011
From: D.Strbenac at garvan.org.au (Dario Strbenac)
Date: Wed,  2 Feb 2011 16:00:10 +1100 (EST)
Subject: [Rd] Memory Leak
Message-ID: <20110202160010.BKS06480@gimr.garvan.unsw.edu.au>

Hello again,

Thanks, that explanation helps me understand the issue more. My platform is
Platform: x86_64-unknown-linux-gnu (64-bit) (Ubuntu 10.04 to be more precise).

- Dario.

---- Original message ----
>Date: Tue, 1 Feb 2011 21:29:38 -0500
>From: Simon Urbanek <simon.urbanek at r-project.org>  
>Subject: Re: [Rd] Memory Leak  
>To: D.Strbenac at garvan.org.au
>Cc: r-devel at r-project.org
>
>
>On Feb 1, 2011, at 9:00 PM, Dario Strbenac wrote:
>
>> Hello,
>> 
>> I'm trying to track down the cause of some extreme memory usage and I've been using Dirk Eddelbuettel's lsos() function he posted on stack overflow. There is a large difference between R's RAM usage :
>> 
>> PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND
>> 6637 darstr    20   0 30.0g  29g 4712 S    0 63.2  10:34.43 R 
>> 
>> and what objects I have loaded in memory :
>> 
>>> lsos()
>>           Type      Size PrettySize     Rows Columns
>> A          list 552387720   526.8 Mb        2      NA
>> B   GRangesList 552376408   526.8 Mb        4      NA
>> C SimpleRleList 353421896     337 Mb       24      NA
>> D       GRanges 236410608   225.5 Mb 15272853      NA
>> E    data.frame   6981952     6.7 Mb    24966      14
>> F    data.frame   6782136     6.5 Mb    24966      13
>> G          list   4393704     4.2 Mb    24964      NA
>> H        matrix   3195760       3 Mb    24964      16
>> I          list   1798752     1.7 Mb    24964      NA
>> J       GRanges    312656   305.3 Kb    24964      NA
>> 
>> (The total looks like about 1.5 GB)
>> 
>> I haven't got any calls to external C code in my R script, although the Bioconductor packages I am using do. How can I regain those missing Gigabytes ?
>> 
>
>There is no reason why the two numbers should have anything in common. The OS (assuming the above is supposed to be ps output) reports memory that the OS reserved (it is not necessarily what the application is currently using) and lsos (assuming you meant to point to this: http://stackoverflow.com/questions/1358003/tricks-to-manage-the-available-memory-in-an-r-session ) simply shows approximate size estimates of objects in your workspace. So you can expect the former to be larger than the latter (often but not necessarily always) but that's about all you can say.
>
>If you want to know what R objects are allocated, just look at gc() - it has the actual numbers. However, that only includes transient allocations using the R GC, any memory reserved directly from the OS will not be included. Furthermore, many OSes don't release memory from processes for performance reasons so even if you had exact allocation numbers they would not match what you see in ps.
>
>I you want to lean more, you'll have to grab the tools available for your platform to find out who's allocating what. Since you didn't even mention your platform I can't really help you with the specifics, though.
>
>Cheers,
>Simon


From sgiannerini at gmail.com  Wed Feb  2 11:52:27 2011
From: sgiannerini at gmail.com (Simone Giannerini)
Date: Wed, 2 Feb 2011 11:52:27 +0100
Subject: [Rd] Warning: you may need to use R-patched with recent R
	distros
In-Reply-To: <AANLkTi=jJ584GSoxR25Tyrvo43iFntTF4M7x1ET+yJ+o@mail.gmail.com>
References: <C96C7042.22581%ken.williams@thomsonreuters.com>
	<alpine.LFD.2.02.1101312015170.18622@gannet.stats.ox.ac.uk>
	<AANLkTi=jJ584GSoxR25Tyrvo43iFntTF4M7x1ET+yJ+o@mail.gmail.com>
Message-ID: <AANLkTikwPSahYC5Ovbr=vrKKM_TddoofefA3RD-SKtj3@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110202/c0d81735/attachment.pl>

From ripley at stats.ox.ac.uk  Wed Feb  2 12:03:51 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 2 Feb 2011 11:03:51 +0000 (GMT)
Subject: [Rd] Warning: you may need to use R-patched with recent R
 distros
In-Reply-To: <AANLkTikwPSahYC5Ovbr=vrKKM_TddoofefA3RD-SKtj3@mail.gmail.com>
References: <C96C7042.22581%ken.williams@thomsonreuters.com>
	<alpine.LFD.2.02.1101312015170.18622@gannet.stats.ox.ac.uk>
	<AANLkTi=jJ584GSoxR25Tyrvo43iFntTF4M7x1ET+yJ+o@mail.gmail.com>
	<AANLkTikwPSahYC5Ovbr=vrKKM_TddoofefA3RD-SKtj3@mail.gmail.com>
Message-ID: <alpine.LFD.2.00.1102021101530.690@auk.stats.ox.ac.uk>

On Wed, 2 Feb 2011, Simone Giannerini wrote:

> I see the problem on my OpenSuse 11.3 box
> 
> gcc (SUSE Linux) 4.5.0 20100604 [gcc-4_5-branch revision 160292]
> 
> > sessionInfo()
> R version 2.12.1 Patched (2011-01-10 r53953)

Please update this and let us know if it persists with current 
R-patched.

> Platform: x86_64-unknown-linux-gnu (64-bit)

DS failed to tell us his platform, and maybe it was not x86_64.

> locale:
> ?[1] LC_CTYPE=en_US.UTF-8?????? LC_NUMERIC=C?????????????
> ?[3] LC_TIME=en_US.UTF-8??????? LC_COLLATE=en_US.UTF-8???
> ?[5] LC_MONETARY=C????????????? LC_MESSAGES=en_US.UTF-8??
> ?[7] LC_PAPER=en_US.UTF-8?????? LC_NAME=C????????????????
> ?[9] LC_ADDRESS=C?????????????? LC_TELEPHONE=C???????????
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C??????
> 
> attached base packages:
> [1] stats???? graphics? grDevices utils???? datasets? methods?? base???
> 
> > z <- 0.2853725+0.3927816i
> > z2 <- z^(1:20)
> > z3 <- z^-(1:20)
> > z0 <- cumprod(rep(z, 20))
> > stopifnot(all.equal(z2, z0), all.equal(z3, 1/z0))
> Error: all.equal(z2, z0) is not TRUE
> 
> Simone
> 
> 
> On Wed, Feb 2, 2011 at 1:45 AM, Dominick Samperi <djsamperi at gmail.com>
> wrote:
>       On Mon, Jan 31, 2011 at 3:18 PM, Prof Brian Ripley
>       <ripley at stats.ox.ac.uk> wrote:
> > On Mon, 31 Jan 2011, Ken.Williams at thomsonreuters.com wrote:
> >
> >> For the complex-numbers bug, do you know a reliable way (besides
> looking
> >> at version numbers) to determine whether the bug is present or
> absent in a
> >> given build?
> >
> > I know a way: See tests/complex.R in R-devel.
> >
> > z <- 0.2853725+0.3927816i
> > z2 <- z^(1:20)
> > z3 <- z^-(1:20)
> > z0 <- cumprod(rep(z, 20))
> > stopifnot(all.equal(z2, z0), all.equal(z3, 1/z0))
> > ## z^3 had value z^2 ....
> >
> 
> I tried this under Fedora 14 (GCC 4.5.1) using the released R 2.12.1
> and
> R-devel (2.13.0 devel) and saw no problems? I compared the numbers
> with
> those generated by Octave, took the cube root of z^3 and got z, ran
> this
> unit test and stopifnot did not terminate, etc.
> 
> At build time the optimization level was O2.
> 
> Dominick
> 
> >>
> >> I don't know what version of gcc was used in my build nor the
> optimization
> >> flags, so I did a few test exponentiations z^n and the results look
> okay,
> >> but maybe I'm not tickling the right bits.
> >>
> >>
> >> --
> >> Ken Williams
> >> Senior Research Scientist
> >> Thomson Reuters
> >> Phone: 651-848-7712
> >> ken.williams at thomsonreuters.com
> >> http://labs.thomsonreuters.com
> >>
> >>
> >>
> >>
> >>
> >> On 1/31/11 1:48 PM, "Prof Brian Ripley" <ripley at stats.ox.ac.uk>
> wrote:
> >>
> >>> Two things have emerged in testing on x86_64 Fedora 14 which mean
> that
> >>> a recent R-patched is probably needed.
> >>>
> >>> 1) That OS uses zlib 1.2.5: that claims to be binary-compatible
> with
> >>> zlib 1.2.3 but is not, as we found (painfully) on Windows. ?The
> remedy
> >>> was to remap _all_ the symbols in R's own copy of zlib (not just
> those
> >>> zlib arranged to remap).
> >>>
> >>> The symptoms were crashes using packages XML and rgoobi (both of
> which
> >>> link to zlib) and incorrect results in RJaCGH (which contains a
> copy
> >>> of zlib). ?There may well be other problems ....
> >>>
> >>> 2) ?Fedora 14 uses gcc 4.5.1. With CFLAGS containing the default
> -O2
> >>> or higher, HAVE_C99_COMPLEX was detected as false because there is
> a
> >>> (genuine) incompatibility between types Rcomplex and C99's double
> >>> complex. ?This means that R's fallback code is used, and
> regretably
> >>> that contains a serious bug in an 'optimization' by a colleague,
> so
> >>> z^n is incorrect for most complex z and integer n (and has been
> since
> >>> 2.10.0). ?The remedy is to use R-patched or R-devel, or only
> optimize
> >>> to -O.
> >>>
> >>> We've also seen incorrect results from package mvtnorm when C
> >>> optimization was -O3.
> >>>
> >>> The upshot is that there is likely to be a 2.12.2 to fix these
> issues.
> >>>
> >>> --
> >>> Brian D. Ripley, ? ? ? ? ? ? ? ? ?ripley at stats.ox.ac.uk
> >>> Professor of Applied Statistics,
> ?http://www.stats.ox.ac.uk/~ripley/
> >>> University of Oxford, ? ? ? ? ? ? Tel: ?+44 1865 272861 (self)
> >>> 1 South Parks Road, ? ? ? ? ? ? ? ? ? ? +44 1865 272866 (PA)
> >>> Oxford OX1 3TG, UK ? ? ? ? ? ? ? ?Fax: ?+44 1865 272595
> >>>
> >>> ______________________________________________
> >>> R-devel at r-project.org mailing list
> >>> https://stat.ethz.ch/mailman/listinfo/r-devel
> >>>
> >>
> >>
> >
> > --
> > Brian D. Ripley, ? ? ? ? ? ? ? ? ?ripley at stats.ox.ac.uk
> > Professor of Applied Statistics, ?http://www.stats.ox.ac.uk/~ripley/
> > University of Oxford, ? ? ? ? ? ? Tel: ?+44 1865 272861 (self)
> > 1 South Parks Road, ? ? ? ? ? ? ? ? ? ? +44 1865 272866 (PA)
> > Oxford OX1 3TG, UK ? ? ? ? ? ? ? ?Fax: ?+44 1865 272595
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 
> 
> 
> --
> ______________________________________________________
> 
> Simone Giannerini
> Dipartimento di Scienze Statistiche "Paolo Fortunati"
> Universita' di Bologna
> Via delle belle arti 41 - 40126? Bologna,? ITALY
> Tel: +39 051 2098262? Fax: +39 051 232153
> http://www2.stat.unibo.it/giannerini/
> ______________________________________________________
> 
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From sgiannerini at gmail.com  Wed Feb  2 12:29:42 2011
From: sgiannerini at gmail.com (Simone Giannerini)
Date: Wed, 2 Feb 2011 12:29:42 +0100
Subject: [Rd] Warning: you may need to use R-patched with recent R
	distros
In-Reply-To: <alpine.LFD.2.00.1102021101530.690@auk.stats.ox.ac.uk>
References: <C96C7042.22581%ken.williams@thomsonreuters.com>
	<alpine.LFD.2.02.1101312015170.18622@gannet.stats.ox.ac.uk>
	<AANLkTi=jJ584GSoxR25Tyrvo43iFntTF4M7x1ET+yJ+o@mail.gmail.com>
	<AANLkTikwPSahYC5Ovbr=vrKKM_TddoofefA3RD-SKtj3@mail.gmail.com>
	<alpine.LFD.2.00.1102021101530.690@auk.stats.ox.ac.uk>
Message-ID: <AANLkTik6Rdgz0PB02kRaxEdsXuMYsoBGpGhPYRvTXe_q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110202/c9d658d0/attachment.pl>

From gong-yi.liao at uconn.edu  Wed Feb  2 09:00:46 2011
From: gong-yi.liao at uconn.edu (GONG-YI LIAO)
Date: Wed, 02 Feb 2011 03:00:46 -0500
Subject: [Rd] Using MathJax in R's help system
Message-ID: <1296633646.25319.58.camel@GongTop1>

Hi, 
  
  I am doing a small experiment to test if I can use 

  MathJax ( official site: http://www.mathjax.org )

  in R's html help pages  (i.e. options(help_type='html'))

  and it seems working with some minor modifications.


  The screenshot (rendered by Firefox 4.0 beta and with STIX fonts) of 

  the help page in html format with MathJax enabled is at the following 

  url: 

  http://picasaweb.google.com/gongyi.liao/RDevel#5568989227748103346 
  
  (the corresponding R.css in this srceenshot is obtained from 

   Yihui Xie  
http://yihui.name/en/2011/01/customizing-the-theme-of-your-r-html-help/ )

  I made a simple modification on

  R-2.12.1/src/library/tools/R/Rd2HTML.R

  with diff:

  435c435
<                    of1('$')
---
>                    of1("<i>")
439c439
<                    of1('$')
---
>                    of1("</i>")
444c444
<                    of1('</p>\\[')
---
>                    of1('</p><p align="center"><i>')
447c447
<                    of1('\\]<p>')
---
>                    of1('</i></p><p>')
688,694c688
<         of0('<script type="text/javascript"
src="http://mathjax.connectmv.com/MathJax.js">\n', 
<             'MathJax.Hub.Config({\n', 
<             'extensions: ["tex2jax.js"],\n',
<             'jax: ["input/TeX","output/HTML-CSS"],\n',
<             'tex2jax: {inlineMath: [["$","$"]]}\n',
<             '});\n',
<             '</script>\n')
---
> 

and the modified R-2.12.1/src/library/base/man/svd.Rd:

for demonstration: 


47,51c47,50
<   \deqn{ \mathbf{X} = \mathbf{U D V}^\top,} where \eqn{\mathbf{U}} and
\eqn{\mathbf{V}} are
<   orthogonal, \eqn{\mathbf{V}^\top} means \emph{V transposed}, and
<   \eqn{\mathbf{D}} is a diagonal matrix with the singular
<   values \eqn{D_{ii}}{D[i,i]}.  Equivalently, \eqn{\mathbf{D} =
<   \mathbf{U}^\top \mathbf{X V}},\deqn{1 = \int_{\mathbb R}\phi(z)dz}
---
>   \deqn{ \bold{X = U D V'},} where \eqn{\bold{U}} and \eqn{\bold{V}}
are
>   orthogonal, \eqn{\bold{V'}} means \emph{V transposed}, and
>   \eqn{\bold{D}} is a diagonal matrix with the singular
>   values \eqn{D_{ii}}{D[i,i]}.  Equivalently, \eqn{\bold{D = U' X V}},


  My personal opinion is, html is a better format for showing R help 

  documents, because modern browsers can process some complicated 

  interactive contents, while text editors (emacs, vim, etc.) and PDF 

  readers (Adobe reader, evince, xpdf, etc.) only have limited ability 

  to process complicated contents like interactive animations.

  
  But, at this moment, R's html help pages do not show the 

  mathematical materials (I mean, the formula) in a proper 

  way. R's PDF and PS help pages provide good mathematical 

  material layouts but PDF and PS are better choices for printing 

  rather than screen displaying. 

  
  So, if R provides some mechanism that we can customize the 

  html header in R's html help pages, like include some 

  javascripts, then we could have much more flexible, accessible 

  R help documents in html format and both users and developers 

  can benefit from better reading experience.


  Any comments are greatly appreciated.

  



  
-- 
Gong-Yi Liao

Department of Statistics
University of Connecticut
215 Glenbrook Road  U4120
Storrs, CT 06269-4120

860-486-9478 
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Rd2HTML.diff
Type: text/x-patch
Size: 706 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110202/5fffeeb7/attachment.bin>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: svd-Rd.diff
Type: text/x-patch
Size: 645 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110202/5fffeeb7/attachment-0001.bin>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: mathjax_in_R_help.png
Type: image/png
Size: 124573 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110202/5fffeeb7/attachment.png>

From Ken.Williams at thomsonreuters.com  Wed Feb  2 15:57:47 2011
From: Ken.Williams at thomsonreuters.com (Ken.Williams at thomsonreuters.com)
Date: Wed, 2 Feb 2011 08:57:47 -0600
Subject: [Rd] Using MathJax in R's help system
In-Reply-To: <1296633646.25319.58.camel@GongTop1>
Message-ID: <C96ECCF5.231C0%ken.williams@thomsonreuters.com>

Very nice.  I think this is a great idea too.

--
Ken Williams
Senior Research Scientist
Thomson Reuters
Phone: 651-848-7712
ken.williams at thomsonreuters.com
http://labs.thomsonreuters.com





On 2/2/11 2:00 AM, "GONG-YI LIAO" <gong-yi.liao at uconn.edu> wrote:

>Hi, 
>  
>  I am doing a small experiment to test if I can use
>
>  MathJax ( official site: http://www.mathjax.org )
>
>  in R's html help pages  (i.e. options(help_type='html'))
>
>  and it seems working with some minor modifications.
>


From hadley at rice.edu  Wed Feb  2 16:04:51 2011
From: hadley at rice.edu (Hadley Wickham)
Date: Wed, 2 Feb 2011 09:04:51 -0600
Subject: [Rd] Using MathJax in R's help system
In-Reply-To: <1296633646.25319.58.camel@GongTop1>
References: <1296633646.25319.58.camel@GongTop1>
Message-ID: <AANLkTi=RD0gyB8QnAs7aa2yv7647_x2SBAyZ_AL=LLoz@mail.gmail.com>

Two comments:

 * one problem with mathjax is it's sheer size: 130 meg and >30,000
files.  A hosted solution is in the works and will hopefully resolve
that situations

 * you might also want to look at the helpr package, which is a ground
up rewrite of the R documentation html renderer to provide things like
global comments on functions, examples that run in browser, syntax
highlighting, search across all packages (coming in the next version),
and much much more.

Hadley

On Wed, Feb 2, 2011 at 2:00 AM, GONG-YI LIAO <gong-yi.liao at uconn.edu> wrote:
> Hi,
>
> ?I am doing a small experiment to test if I can use
>
> ?MathJax ( official site: http://www.mathjax.org )
>
> ?in R's html help pages ?(i.e. options(help_type='html'))
>
> ?and it seems working with some minor modifications.
>
>
> ?The screenshot (rendered by Firefox 4.0 beta and with STIX fonts) of
>
> ?the help page in html format with MathJax enabled is at the following
>
> ?url:
>
> ?http://picasaweb.google.com/gongyi.liao/RDevel#5568989227748103346
>
> ?(the corresponding R.css in this srceenshot is obtained from
>
> ? Yihui Xie
> http://yihui.name/en/2011/01/customizing-the-theme-of-your-r-html-help/ )
>
> ?I made a simple modification on
>
> ?R-2.12.1/src/library/tools/R/Rd2HTML.R
>
> ?with diff:
>
> ?435c435
> < ? ? ? ? ? ? ? ? ? ?of1('$')
> ---
>> ? ? ? ? ? ? ? ? ? ?of1("<i>")
> 439c439
> < ? ? ? ? ? ? ? ? ? ?of1('$')
> ---
>> ? ? ? ? ? ? ? ? ? ?of1("</i>")
> 444c444
> < ? ? ? ? ? ? ? ? ? ?of1('</p>\\[')
> ---
>> ? ? ? ? ? ? ? ? ? ?of1('</p><p align="center"><i>')
> 447c447
> < ? ? ? ? ? ? ? ? ? ?of1('\\]<p>')
> ---
>> ? ? ? ? ? ? ? ? ? ?of1('</i></p><p>')
> 688,694c688
> < ? ? ? ? of0('<script type="text/javascript"
> src="http://mathjax.connectmv.com/MathJax.js">\n',
> < ? ? ? ? ? ? 'MathJax.Hub.Config({\n',
> < ? ? ? ? ? ? 'extensions: ["tex2jax.js"],\n',
> < ? ? ? ? ? ? 'jax: ["input/TeX","output/HTML-CSS"],\n',
> < ? ? ? ? ? ? 'tex2jax: {inlineMath: [["$","$"]]}\n',
> < ? ? ? ? ? ? '});\n',
> < ? ? ? ? ? ? '</script>\n')
> ---
>>
>
> and the modified R-2.12.1/src/library/base/man/svd.Rd:
>
> for demonstration:
>
>
> 47,51c47,50
> < ? \deqn{ \mathbf{X} = \mathbf{U D V}^\top,} where \eqn{\mathbf{U}} and
> \eqn{\mathbf{V}} are
> < ? orthogonal, \eqn{\mathbf{V}^\top} means \emph{V transposed}, and
> < ? \eqn{\mathbf{D}} is a diagonal matrix with the singular
> < ? values \eqn{D_{ii}}{D[i,i]}. ?Equivalently, \eqn{\mathbf{D} =
> < ? \mathbf{U}^\top \mathbf{X V}},\deqn{1 = \int_{\mathbb R}\phi(z)dz}
> ---
>> ? \deqn{ \bold{X = U D V'},} where \eqn{\bold{U}} and \eqn{\bold{V}}
> are
>> ? orthogonal, \eqn{\bold{V'}} means \emph{V transposed}, and
>> ? \eqn{\bold{D}} is a diagonal matrix with the singular
>> ? values \eqn{D_{ii}}{D[i,i]}. ?Equivalently, \eqn{\bold{D = U' X V}},
>
>
> ?My personal opinion is, html is a better format for showing R help
>
> ?documents, because modern browsers can process some complicated
>
> ?interactive contents, while text editors (emacs, vim, etc.) and PDF
>
> ?readers (Adobe reader, evince, xpdf, etc.) only have limited ability
>
> ?to process complicated contents like interactive animations.
>
>
> ?But, at this moment, R's html help pages do not show the
>
> ?mathematical materials (I mean, the formula) in a proper
>
> ?way. R's PDF and PS help pages provide good mathematical
>
> ?material layouts but PDF and PS are better choices for printing
>
> ?rather than screen displaying.
>
>
> ?So, if R provides some mechanism that we can customize the
>
> ?html header in R's html help pages, like include some
>
> ?javascripts, then we could have much more flexible, accessible
>
> ?R help documents in html format and both users and developers
>
> ?can benefit from better reading experience.
>
>
> ?Any comments are greatly appreciated.
>
>
>
>
>
>
> --
> Gong-Yi Liao
>
> Department of Statistics
> University of Connecticut
> 215 Glenbrook Road ?U4120
> Storrs, CT 06269-4120
>
> 860-486-9478
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>



-- 
Assistant Professor / Dobelman Family Junior Chair
Department of Statistics / Rice University
http://had.co.nz/


From djsamperi at gmail.com  Wed Feb  2 16:39:37 2011
From: djsamperi at gmail.com (Dominick Samperi)
Date: Wed, 2 Feb 2011 10:39:37 -0500
Subject: [Rd] Warning: you may need to use R-patched with recent R
	distros
In-Reply-To: <alpine.LFD.2.00.1102021101530.690@auk.stats.ox.ac.uk>
References: <C96C7042.22581%ken.williams@thomsonreuters.com>
	<alpine.LFD.2.02.1101312015170.18622@gannet.stats.ox.ac.uk>
	<AANLkTi=jJ584GSoxR25Tyrvo43iFntTF4M7x1ET+yJ+o@mail.gmail.com>
	<AANLkTikwPSahYC5Ovbr=vrKKM_TddoofefA3RD-SKtj3@mail.gmail.com>
	<alpine.LFD.2.00.1102021101530.690@auk.stats.ox.ac.uk>
Message-ID: <AANLkTimTw63Ng_F2NcHUB7=Ah2P=uYvbA-4m2y4MP8pY@mail.gmail.com>

On Wed, Feb 2, 2011 at 6:03 AM, Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
> On Wed, 2 Feb 2011, Simone Giannerini wrote:
>
>> I see the problem on my OpenSuse 11.3 box
>>
>> gcc (SUSE Linux) 4.5.0 20100604 [gcc-4_5-branch revision 160292]
>>
>> > sessionInfo()
>> R version 2.12.1 Patched (2011-01-10 r53953)
>
> Please update this and let us know if it persists with current R-patched.
>
>> Platform: x86_64-unknown-linux-gnu (64-bit)
>
> DS failed to tell us his platform, and maybe it was not x86_64.

It is x86_64, to be precise:
Linux 2.6.35.10-74.fc14.x86_64 #1 SMP Thu Dec 23 16:04:50 UTC 2010

I tested against released R-2.12.1 and R-devel trunk (latest yesterday).

>
>> locale:
>> ?[1] LC_CTYPE=en_US.UTF-8?????? LC_NUMERIC=C
>> ?[3] LC_TIME=en_US.UTF-8??????? LC_COLLATE=en_US.UTF-8
>> ?[5] LC_MONETARY=C????????????? LC_MESSAGES=en_US.UTF-8
>> ?[7] LC_PAPER=en_US.UTF-8?????? LC_NAME=C
>> ?[9] LC_ADDRESS=C?????????????? LC_TELEPHONE=C
>> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>>
>> attached base packages:
>> [1] stats???? graphics? grDevices utils???? datasets? methods?? base
>>
>> > z <- 0.2853725+0.3927816i
>> > z2 <- z^(1:20)
>> > z3 <- z^-(1:20)
>> > z0 <- cumprod(rep(z, 20))
>> > stopifnot(all.equal(z2, z0), all.equal(z3, 1/z0))
>> Error: all.equal(z2, z0) is not TRUE
>>
>> Simone
>>
>>
>> On Wed, Feb 2, 2011 at 1:45 AM, Dominick Samperi <djsamperi at gmail.com>
>> wrote:
>> ? ? ?On Mon, Jan 31, 2011 at 3:18 PM, Prof Brian Ripley
>> ? ? ?<ripley at stats.ox.ac.uk> wrote:
>> > On Mon, 31 Jan 2011, Ken.Williams at thomsonreuters.com wrote:
>> >
>> >> For the complex-numbers bug, do you know a reliable way (besides
>> looking
>> >> at version numbers) to determine whether the bug is present or
>> absent in a
>> >> given build?
>> >
>> > I know a way: See tests/complex.R in R-devel.
>> >
>> > z <- 0.2853725+0.3927816i
>> > z2 <- z^(1:20)
>> > z3 <- z^-(1:20)
>> > z0 <- cumprod(rep(z, 20))
>> > stopifnot(all.equal(z2, z0), all.equal(z3, 1/z0))
>> > ## z^3 had value z^2 ....
>> >
>>
>> I tried this under Fedora 14 (GCC 4.5.1) using the released R 2.12.1
>> and
>> R-devel (2.13.0 devel) and saw no problems? I compared the numbers
>> with
>> those generated by Octave, took the cube root of z^3 and got z, ran
>> this
>> unit test and stopifnot did not terminate, etc.
>>
>> At build time the optimization level was O2.
>>
>> Dominick
>>
>> >>
>> >> I don't know what version of gcc was used in my build nor the
>> optimization
>> >> flags, so I did a few test exponentiations z^n and the results look
>> okay,
>> >> but maybe I'm not tickling the right bits.
>> >>
>> >>
>> >> --
>> >> Ken Williams
>> >> Senior Research Scientist
>> >> Thomson Reuters
>> >> Phone: 651-848-7712
>> >> ken.williams at thomsonreuters.com
>> >> http://labs.thomsonreuters.com
>> >>
>> >>
>> >>
>> >>
>> >>
>> >> On 1/31/11 1:48 PM, "Prof Brian Ripley" <ripley at stats.ox.ac.uk>
>> wrote:
>> >>
>> >>> Two things have emerged in testing on x86_64 Fedora 14 which mean
>> that
>> >>> a recent R-patched is probably needed.
>> >>>
>> >>> 1) That OS uses zlib 1.2.5: that claims to be binary-compatible
>> with
>> >>> zlib 1.2.3 but is not, as we found (painfully) on Windows. ?The
>> remedy
>> >>> was to remap _all_ the symbols in R's own copy of zlib (not just
>> those
>> >>> zlib arranged to remap).
>> >>>
>> >>> The symptoms were crashes using packages XML and rgoobi (both of
>> which
>> >>> link to zlib) and incorrect results in RJaCGH (which contains a
>> copy
>> >>> of zlib). ?There may well be other problems ....
>> >>>
>> >>> 2) ?Fedora 14 uses gcc 4.5.1. With CFLAGS containing the default
>> -O2
>> >>> or higher, HAVE_C99_COMPLEX was detected as false because there is
>> a
>> >>> (genuine) incompatibility between types Rcomplex and C99's double
>> >>> complex. ?This means that R's fallback code is used, and
>> regretably
>> >>> that contains a serious bug in an 'optimization' by a colleague,
>> so
>> >>> z^n is incorrect for most complex z and integer n (and has been
>> since
>> >>> 2.10.0). ?The remedy is to use R-patched or R-devel, or only
>> optimize
>> >>> to -O.
>> >>>
>> >>> We've also seen incorrect results from package mvtnorm when C
>> >>> optimization was -O3.
>> >>>
>> >>> The upshot is that there is likely to be a 2.12.2 to fix these
>> issues.
>> >>>
>> >>> --
>> >>> Brian D. Ripley, ? ? ? ? ? ? ? ? ?ripley at stats.ox.ac.uk
>> >>> Professor of Applied Statistics,
>> ?http://www.stats.ox.ac.uk/~ripley/
>> >>> University of Oxford, ? ? ? ? ? ? Tel: ?+44 1865 272861 (self)
>> >>> 1 South Parks Road, ? ? ? ? ? ? ? ? ? ? +44 1865 272866 (PA)
>> >>> Oxford OX1 3TG, UK ? ? ? ? ? ? ? ?Fax: ?+44 1865 272595
>> >>>
>> >>> ______________________________________________
>> >>> R-devel at r-project.org mailing list
>> >>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> >>>
>> >>
>> >>
>> >
>> > --
>> > Brian D. Ripley, ? ? ? ? ? ? ? ? ?ripley at stats.ox.ac.uk
>> > Professor of Applied Statistics, ?http://www.stats.ox.ac.uk/~ripley/
>> > University of Oxford, ? ? ? ? ? ? Tel: ?+44 1865 272861 (self)
>> > 1 South Parks Road, ? ? ? ? ? ? ? ? ? ? +44 1865 272866 (PA)
>> > Oxford OX1 3TG, UK ? ? ? ? ? ? ? ?Fax: ?+44 1865 272595
>> >
>> > ______________________________________________
>> > R-devel at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-devel
>> >
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>>
>>
>> --
>> ______________________________________________________
>>
>> Simone Giannerini
>> Dipartimento di Scienze Statistiche "Paolo Fortunati"
>> Universita' di Bologna
>> Via delle belle arti 41 - 40126? Bologna,? ITALY
>> Tel: +39 051 2098262? Fax: +39 051 232153
>> http://www2.stat.unibo.it/giannerini/
>> ______________________________________________________
>>
>>
>
> --
> Brian D. Ripley, ? ? ? ? ? ? ? ? ?ripley at stats.ox.ac.uk
> Professor of Applied Statistics, ?http://www.stats.ox.ac.uk/~ripley/
> University of Oxford, ? ? ? ? ? ? Tel: ?+44 1865 272861 (self)
> 1 South Parks Road, ? ? ? ? ? ? ? ? ? ? +44 1865 272866 (PA)
> Oxford OX1 3TG, UK ? ? ? ? ? ? ? ?Fax: ?+44 1865 272595
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From hadley at rice.edu  Wed Feb  2 17:38:59 2011
From: hadley at rice.edu (Hadley Wickham)
Date: Wed, 2 Feb 2011 10:38:59 -0600
Subject: [Rd] Using MathJax in R's help system
In-Reply-To: <1296664429.2269.49.camel@GongTop1>
References: <1296633646.25319.58.camel@GongTop1>
	<AANLkTi=RD0gyB8QnAs7aa2yv7647_x2SBAyZ_AL=LLoz@mail.gmail.com>
	<1296664429.2269.49.camel@GongTop1>
Message-ID: <AANLkTik6YmG6YMvJ5E-_yBcFv4zZ-MGP1NMpB5X8B3-u@mail.gmail.com>

On Wed, Feb 2, 2011 at 10:33 AM, Gong-Yi Liao <gong-yi.liao at uconn.edu> wrote:
> Thank you for comments,
>
> ? 1. ? About MathJax's sheer size:
>
> ? ? ? ?I think we can consider the following two cases:
>
> ? ? ? ?A. ?The user starts nanohttpd on his/her own PC and read the
> ? ? ? ? ? ?help files in html
> ? ? ? ? ? ?(i.e. ? ?> options(help_type="html", browser="xdg_open")
> ? ? ? ? ? ? ? ? ? ? > ?svd ?)
> ? ? ? ? ? ? ?For this case, I think that ?the user can just ?install a
> ? ? ? ? ? ? ?MathJax distribution on his/her own PC (or workstation)
> ? ? ? ? ? ? ?and let the local nanohttpd send the MathJax scripts,
> ? ? ? ? ? ? ?fonts and image files to user's browser. ?Since all the
> ? ? ? ? ? ? ?MathJax files are transmitted locally (i.e. at the same
> ? ? ? ? ? ? ?IP, on the same machine), I think 130 MB ?is not a big
> ? ? ? ? ? ? ?issue in this case.

But the user still needs to get it in some way - an additional
installation step means that it's probably not suitable for inclusion
with base R.  It could possibly be bundled inside a package, using
some tricks to keep all the files in a single zip file, which reduces
the bundle size to a manageable 15 meg.

> ? ? ? ?B. ?The user reads the R help html pages, ?which are hosted by
> ? ? ? ? ? ?a third party httpd server
>
> ? ? ? ? ? ? For this case, I think a CDN (Content Delivery Network)
> ? ? ? ? ? ? hosting server is needed. MathJax's 130 MB size can be a
> ? ? ? ? ? ? critical issue in this case. ?As far as I know, there's
> ? ? ? ? ? ? a site ( mathjax.connectmv.com ) providing such service,
> ? ? ? ? ? ? but I can't imagine if all the R users around the world
> ? ? ? ? ? ? request resources from this site 24-7, the site must
> ? ? ? ? ? ? be DoSed.

Agreed.

> ? ?2. About the helpr package:
>
> ? ? ? ?I install the helpr package from CRAN, and, maybe due to my
> ? ? ? ?problem, ?the manual of this package is quite confusing to me.
> ? ? ? ?I run the command helpr and my browser shows me the following
> ? ? ? ?content:

Could you please provide a reproducible example?

The following steps should get you up and running:

install.packages("helpr")
library(helpr)
helpr()

The solr warnings will be removed in the next version - you can ignore
them for now.

Hadley

-- 
Assistant Professor / Dobelman Family Junior Chair
Department of Statistics / Rice University
http://had.co.nz/


From gong-yi.liao at uconn.edu  Wed Feb  2 17:33:49 2011
From: gong-yi.liao at uconn.edu (Gong-Yi Liao)
Date: Wed, 02 Feb 2011 11:33:49 -0500
Subject: [Rd] Using MathJax in R's help system
In-Reply-To: <AANLkTi=RD0gyB8QnAs7aa2yv7647_x2SBAyZ_AL=LLoz@mail.gmail.com>
References: <1296633646.25319.58.camel@GongTop1>
	<AANLkTi=RD0gyB8QnAs7aa2yv7647_x2SBAyZ_AL=LLoz@mail.gmail.com>
Message-ID: <1296664429.2269.49.camel@GongTop1>

Thank you for comments, 

   1.   About MathJax's sheer size:

        I think we can consider the following two cases: 

        A.  The user starts nanohttpd on his/her own PC and read the 
            help files in html 
            (i.e.    > options(help_type="html", browser="xdg_open")
                     > ?svd  )                   
              For this case, I think that  the user can just  install a 
              MathJax distribution on his/her own PC (or workstation)   
              and let the local nanohttpd send the MathJax scripts, 
              fonts and image files to user's browser.  Since all the 
              MathJax files are transmitted locally (i.e. at the same 
              IP, on the same machine), I think 130 MB  is not a big  
              issue in this case.   


        B.  The user reads the R help html pages,  which are hosted by 
            a third party httpd server 
              
             For this case, I think a CDN (Content Delivery Network) 
             hosting server is needed. MathJax's 130 MB size can be a 
             critical issue in this case.  As far as I know, there's
             a site ( mathjax.connectmv.com ) providing such service, 
             but I can't imagine if all the R users around the world 
             request resources from this site 24-7, the site must 
             be DoSed. 
   

    2. About the helpr package:
             
        I install the helpr package from CRAN, and, maybe due to my 
        problem,  the manual of this package is quite confusing to me. 
        I run the command helpr and my browser shows me the following 
        content:

        ERROR: no history available to save 

        1: do.call(function (...) 
        {
           page_info <- helpr_home()
           page_info$html <- "/index.html"
           render_brew("index", page_info, path = path)
        }, list())
        2: function (...) 
                  {
                          page_info <- helpr_home()
                          page_info$html <- "/index.html"
                          render_brew("index", page_info, path = path)
                  }()
                  3: helpr_home()
                  4: ten_functions()
                  5: get_function_history()
                  6: savehistory(file1)    

        And I can't find any CRAN packages with 'Solr' keyword, any 
        comments?
        
     Thank you!
       

On Wed, 2011-02-02 at 09:04 -0600, Hadley Wickham wrote: 
> Two comments:
> 
>  * one problem with mathjax is it's sheer size: 130 meg and >30,000
> files.  A hosted solution is in the works and will hopefully resolve
> that situations
> 
>  * you might also want to look at the helpr package, which is a ground
> up rewrite of the R documentation html renderer to provide things like
> global comments on functions, examples that run in browser, syntax
> highlighting, search across all packages (coming in the next version),
> and much much more.
> 
> Hadley


-- 
Gong-Yi Liao

Department of Statistics
University of Connecticut
215 Glenbrook Road  U4120
Storrs, CT 06269-4120

860-486-9478


From gong-yi.liao at uconn.edu  Wed Feb  2 18:08:28 2011
From: gong-yi.liao at uconn.edu (Gong-Yi Liao)
Date: Wed, 02 Feb 2011 12:08:28 -0500
Subject: [Rd] Using MathJax in R's help system
In-Reply-To: <AANLkTik6YmG6YMvJ5E-_yBcFv4zZ-MGP1NMpB5X8B3-u@mail.gmail.com>
References: <1296633646.25319.58.camel@GongTop1>
	<AANLkTi=RD0gyB8QnAs7aa2yv7647_x2SBAyZ_AL=LLoz@mail.gmail.com>
	<1296664429.2269.49.camel@GongTop1>
	<AANLkTik6YmG6YMvJ5E-_yBcFv4zZ-MGP1NMpB5X8B3-u@mail.gmail.com>
Message-ID: <1296666508.2269.67.camel@GongTop1>


I think your "another CRAN package for mathjax" approach is better

than modifying the base R's code. I am trying to find the possible 

way to implement it.

On Wed, 2011-02-02 at 10:38 -0600, Hadley Wickham wrote:
> 
> But the user still needs to get it in some way - an additional
> installation step means that it's probably not suitable for inclusion
> with base R.  It could possibly be bundled inside a package, using
> some tricks to keep all the files in a single zip file, which reduces
> the bundle size to a manageable 15 meg.

> Agreed.
> 
> >    2. About the helpr package:
> >
> >        I install the helpr package from CRAN, and, maybe due to my
> >        problem,  the manual of this package is quite confusing to me.
> >        I run the command helpr and my browser shows me the following
> >        content:
> 
> Could you please provide a reproducible example?
> 
> The following steps should get you up and running:
> 
> install.packages("helpr")
> library(helpr)
> helpr()
> 

It seems that I triggered a strange issue (or, a bug is ESS?). I run 
exactly the same commands in EMACS+ESS and then I got the error 
messages shown in my last mail. Now, I try to do the same things
but, at this time, I run the commands in a terminal (gnome-terminal), 
then, everything works properly, as you expected (I can see the  
packages and functions list with nice CSS layout in the browser).

This issue is quite weird, and I think it is caused by Emacs or ESS   
but not the helpr package. I still need to do several test to figure 
out what really causes it.   





> The solr warnings will be removed in the next version - you can ignore
> them for now.
> 
> Hadley
> 

-- 
Gong-Yi Liao

Department of Statistics
University of Connecticut
215 Glenbrook Road  U4120
Storrs, CT 06269-4120

860-486-9478


From simon.urbanek at r-project.org  Wed Feb  2 20:30:47 2011
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Wed, 2 Feb 2011 14:30:47 -0500
Subject: [Rd] Using MathJax in R's help system
In-Reply-To: <1296666508.2269.67.camel@GongTop1>
References: <1296633646.25319.58.camel@GongTop1>
	<AANLkTi=RD0gyB8QnAs7aa2yv7647_x2SBAyZ_AL=LLoz@mail.gmail.com>
	<1296664429.2269.49.camel@GongTop1>
	<AANLkTik6YmG6YMvJ5E-_yBcFv4zZ-MGP1NMpB5X8B3-u@mail.gmail.com>
	<1296666508.2269.67.camel@GongTop1>
Message-ID: <3C7308D8-AC4D-4A77-9BFB-51E18093C6B4@r-project.org>


On Feb 2, 2011, at 12:08 PM, Gong-Yi Liao wrote:

> 
> I think your "another CRAN package for mathjax" approach is better
> 
> than modifying the base R's code. I am trying to find the possible 
> 
> way to implement it.
> 

Note that R has already an extensible http server included (it's used for the help already!), so it is easy for package to extend it - you could trivially host the necessary files from a package.

Cheers,
S



> On Wed, 2011-02-02 at 10:38 -0600, Hadley Wickham wrote:
>> 
>> But the user still needs to get it in some way - an additional
>> installation step means that it's probably not suitable for inclusion
>> with base R.  It could possibly be bundled inside a package, using
>> some tricks to keep all the files in a single zip file, which reduces
>> the bundle size to a manageable 15 meg.
> 
>> Agreed.
>> 
>>>   2. About the helpr package:
>>> 
>>>       I install the helpr package from CRAN, and, maybe due to my
>>>       problem,  the manual of this package is quite confusing to me.
>>>       I run the command helpr and my browser shows me the following
>>>       content:
>> 
>> Could you please provide a reproducible example?
>> 
>> The following steps should get you up and running:
>> 
>> install.packages("helpr")
>> library(helpr)
>> helpr()
>> 
> 
> It seems that I triggered a strange issue (or, a bug is ESS?). I run 
> exactly the same commands in EMACS+ESS and then I got the error 
> messages shown in my last mail. Now, I try to do the same things
> but, at this time, I run the commands in a terminal (gnome-terminal), 
> then, everything works properly, as you expected (I can see the  
> packages and functions list with nice CSS layout in the browser).
> 
> This issue is quite weird, and I think it is caused by Emacs or ESS   
> but not the helpr package. I still need to do several test to figure 
> out what really causes it.   
> 
> 
> 
> 
> 
>> The solr warnings will be removed in the next version - you can ignore
>> them for now.
>> 
>> Hadley
>> 
> 
> -- 
> Gong-Yi Liao
> 
> Department of Statistics
> University of Connecticut
> 215 Glenbrook Road  U4120
> Storrs, CT 06269-4120
> 
> 860-486-9478
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From maechler at stat.math.ethz.ch  Wed Feb  2 21:14:28 2011
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 2 Feb 2011 21:14:28 +0100
Subject: [Rd] [.raster bug {was "str() on raster objects fails .."}
In-Reply-To: <4D48B08A.40302@auckland.ac.nz>
References: <AANLkTimycPK-3_mj5OPd0eLauAh41r2-Wkrp7j2jo1sw@mail.gmail.com>
	<19783.49835.494142.88222@stat.math.ethz.ch>
	<4D48A96B.9020801@auckland.ac.nz>
	<AANLkTimRBZbzgRfAkE2-VhnFmVRkWz1-cCqeD4VW7O42@mail.gmail.com>
	<4D48B08A.40302@auckland.ac.nz>
Message-ID: <AANLkTim+TCddv7YOmtGfE7=95ru+q01rUP=HMnur7Lc0@mail.gmail.com>

On Wed, Feb 2, 2011 at 02:16, Paul Murrell <p.murrell at auckland.ac.nz> wrote:
> Hi
>
> On 2/02/2011 2:03 p.m., Henrik Bengtsson wrote:
>>
>> On Tue, Feb 1, 2011 at 4:46 PM, Paul Murrell<p.murrell at auckland.ac.nz>
>> ?wrote:
>>>
>>> Hi
>>>
>>> On 1/02/2011 9:22 p.m., Martin Maechler wrote:
>>>>>>>>>
>>>>>>>>> Henrik Bengtsson<hb at biostat.ucsf.edu>
>>>>>>>>> ? ? on Mon, 31 Jan 2011 11:16:59 -0800 writes:
>>>>
>>>> ? ? > ? ?Hi, str() on raster objects fails for certain dimensions. ?For
>>>> ? ? > ? ?example:
>>>>
>>>> ? ? >> ? ?str(as.raster(0, nrow=1, ncol=100)) 'raster' chr [1, 1:100]
>>>> ? ? > ? ?"#000000" "#000000" "#000000" "#000000" ...
>>>>
>>>> ? ? >> ? ?str(as.raster(0, nrow=1, ncol=101)) Error in
>>>> `[.raster`(object,
>>>> ? ? > ? ?seq_len(max.len)) : subscript out of bounds
>>>>
>>>> ? ? > ? ?This seems to do with how str() and "[.raster"() is coded; when
>>>> ? ? > ? ?subsetting as a vector, which str() relies on, "[.raster"()
>>>> ? ? > ? ?still returns a matrix-like object, e.g.
>>>>
>>>> ? ? >> ? ?img<- as.raster(1:25, max=25, nrow=5, ncol=5);
>>>> ? ? >> ? ?img[1:2]
>>>> ? ? > ? ?[,1] ? ? ?[,2] ? ? ?[,3] ? ? ?[,4] ? ? ?[,5]
>>>> ? ? > ? ?[1,] "#0A0A0A" "#3D3D3D" "#707070" "#A3A3A3" "#D6D6D6"
>>>> ? ? > ? ?[2,] "#141414" "#474747" "#7A7A7A" "#ADADAD" "#E0E0E0"
>>>>
>>>> ? ? > ? ?compare with:
>>>>
>>>> ? ? >> ? ?as.matrix(img)[1:2]
>>>> ? ? > ? ?[1] "#0A0A0A" "#3D3D3D"
>>>>
>>>>
>>>> ? ? > ? ?The easy but incomplete fix is to do:
>>>>
>>>> ? ? > ? ?str.raster<- function(object, ...) {
>>>> ? ? > ? ?str(as.matrix(object), ...);
>>>> ? ? > ? ?}
>>>>
>>>> ? ? > ? ?Other suggestions?
>>>>
>>>> The informal "raster" class is behaving ``illogical''
>>>> in the following sense:
>>>>
>>>> ?> ? ?r<- as.raster(0, nrow=1, ncol=11)
>>>> ?> ? ?r[seq_along(r)]
>>>> ?Error in `[.raster`(r, seq_along(r)) : subscript out of bounds
>>>>
>>>> or, here equivalently,
>>>> ?> ? ?r[1:length(r)]
>>>> ?Error in `[.raster`(r, 1:length(r)) : subscript out of bounds
>>>>
>>>> When classes do behave in such a way, they definitely need their
>>>> own str() method.
>>>>
>>>> However, the bug really is in "[.raster":
>>>> Currently, ?r[i] is equivalent to ?r[i,] ?which is not at all
>>>> matrix-like and its help clearly says that subsetting should
>>>> work as for matrices.
>>>> A recent thread on R-help/R-devel has mentioned the fact that
>>>> "[" methods for matrix-like methods need to use both nargs() and
>>>> missing() and that "[.dataframe" has been the example to follow
>>>> "forever", IIRC already in S and S-plus as of 20 years ago.
>>>
>>> The main motivation for non-standard behaviour here is to make sure that
>>> a
>>> subset of a raster object NEVER produces a vector (because the conversion
>>> back to a raster object then produces a single-column raster and that may
>>> be
>>> a "surprise"). ?Thanks for making the code more standard and robust.
>>>
>>> The r[i] case is still tricky. ?The following behaviour is quite
>>> convenient
>>> ...
>>>
>>> r[r == "black"]<- "white"
>>>
>>> ... but the next behaviour is quite jarring (at least in terms of the
>>> raster
>>> image that results from it) ...
>>>
>>> r2<- r[1:(nrow(r) + 1)]
>>>
>>> So I think there is some justification for further non-standardness to
>>> try
>>> to ensure that the subset of a raster image always produces a sensible
>>> image. ?A simple solution would be just to outlaw r[i] for raster objects
>>> and force the user to write r[i, ] or r[, j], depending on what they
>>> want.
>>
>> FYI, I've tried out Martin's updated version at it seems like a
>> one-column raster matrix is now returned for r[i], e.g.
>
> Yes, that's what I've been looking at ...
>
>>> r<- as.raster(1:8, max=8, nrow=2, ncol=4);
>>> r
>>
>> ? ? ?[,1] ? ? ?[,2] ? ? ?[,3] ? ? ?[,4]
>> [1,] "#202020" "#606060" "#9F9F9F" "#DFDFDF"
>> [2,] "#404040" "#808080" "#BFBFBF" "#FFFFFF"
>>
>>> r[1:length(r)]
>>
>> ? ? ?[,1]
>> [1,] "#202020"
>> [2,] "#404040"
>> [3,] "#606060"
>> [4,] "#808080"
>> [5,] "#9F9F9F"
>> [6,] "#BFBFBF"
>> [7,] "#DFDFDF"
>> [8,] "#FFFFFF"
>
> ... and the above is exactly the sort of thing that will fry your mind if
> the image that you are subsetting is, for example, a photo.
>
> Paul

I agree.  But the  r[i]  case  (not subassignment, but subsetting) case
has been in the code, and that's why I left it .. but changed it to
behave sensibly in the sense of "compatible" to matrix....
... and with the consequence that   r[1:length(r)] does not give an
error ... and in this sense behaves more regular.
Yet another alternative might be to only raise a warning and perhaps
return a (character) vector as that is very compatible to matrix
behavior.
BTW, you haven't mentioned the  r[xy] indexing where  xy is a
two-column matrix of indices.
There it's even more non-sense to return

>
>>> r[1:5,drop=TRUE]
>>
>> ? ? ?[,1]
>> [1,] "#202020"
>> [2,] "#404040"
>> [3,] "#606060"
>> [4,] "#808080"
>> [5,] "#9F9F9F"
>> Warning message:
>> In `[.raster`(r, 1:5, drop = TRUE) :
>> ? 'drop' is always implicitly FALSE in '[.raster'
>>
>> Also,
>>
>>> r[1:5]<- "white"
>>> r
>>
>> ? ? ?[,1] ? ?[,2] ? ?[,3] ? ? ?[,4]
>> [1,] "white" "white" "white" ? "#DFDFDF"
>> [2,] "white" "white" "#BFBFBF" "#FFFFFF"
>>
>> /Henrik
>>
>>>
>>> Paul
>>>
>>>> Thank you, Henrik, for the bug report.
>>>> Martin
>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>> --
>>> Dr Paul Murrell
>>> Department of Statistics
>>> The University of Auckland
>>> Private Bag 92019
>>> Auckland
>>> New Zealand
>>> 64 9 3737599 x85392
>>> paul at stat.auckland.ac.nz
>>> http://www.stat.auckland.ac.nz/~paul/
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>
> --
> Dr Paul Murrell
> Department of Statistics
> The University of Auckland
> Private Bag 92019
> Auckland
> New Zealand
> 64 9 3737599 x85392
> paul at stat.auckland.ac.nz
> http://www.stat.auckland.ac.nz/~paul/
>
>


From simon.urbanek at r-project.org  Wed Feb  2 23:30:10 2011
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Wed, 2 Feb 2011 17:30:10 -0500
Subject: [Rd] [.raster bug {was "str() on raster objects fails .."}
In-Reply-To: <4D48B08A.40302@auckland.ac.nz>
References: <AANLkTimycPK-3_mj5OPd0eLauAh41r2-Wkrp7j2jo1sw@mail.gmail.com>	<19783.49835.494142.88222@stat.math.ethz.ch>	<4D48A96B.9020801@auckland.ac.nz>
	<AANLkTimRBZbzgRfAkE2-VhnFmVRkWz1-cCqeD4VW7O42@mail.gmail.com>
	<4D48B08A.40302@auckland.ac.nz>
Message-ID: <5251E963-8D1C-46CF-AAB9-39ABFE520229@r-project.org>


On Feb 1, 2011, at 8:16 PM, Paul Murrell wrote:

> Hi
> 
> On 2/02/2011 2:03 p.m., Henrik Bengtsson wrote:
>> On Tue, Feb 1, 2011 at 4:46 PM, Paul Murrell<p.murrell at auckland.ac.nz>  wrote:
>>> Hi
>>> 
>>> On 1/02/2011 9:22 p.m., Martin Maechler wrote:
>>>>>>>>> 
>>>>>>>>> Henrik Bengtsson<hb at biostat.ucsf.edu>
>>>>>>>>>     on Mon, 31 Jan 2011 11:16:59 -0800 writes:
>>>> 
>>>>     >    Hi, str() on raster objects fails for certain dimensions.  For
>>>>     >    example:
>>>> 
>>>>     >>    str(as.raster(0, nrow=1, ncol=100)) 'raster' chr [1, 1:100]
>>>>     >    "#000000" "#000000" "#000000" "#000000" ...
>>>> 
>>>>     >>    str(as.raster(0, nrow=1, ncol=101)) Error in `[.raster`(object,
>>>>     >    seq_len(max.len)) : subscript out of bounds
>>>> 
>>>>     >    This seems to do with how str() and "[.raster"() is coded; when
>>>>     >    subsetting as a vector, which str() relies on, "[.raster"()
>>>>     >    still returns a matrix-like object, e.g.
>>>> 
>>>>     >>    img<- as.raster(1:25, max=25, nrow=5, ncol=5);
>>>>     >>    img[1:2]
>>>>     >    [,1]      [,2]      [,3]      [,4]      [,5]
>>>>     >    [1,] "#0A0A0A" "#3D3D3D" "#707070" "#A3A3A3" "#D6D6D6"
>>>>     >    [2,] "#141414" "#474747" "#7A7A7A" "#ADADAD" "#E0E0E0"
>>>> 
>>>>     >    compare with:
>>>> 
>>>>     >>    as.matrix(img)[1:2]
>>>>     >    [1] "#0A0A0A" "#3D3D3D"
>>>> 
>>>> 
>>>>     >    The easy but incomplete fix is to do:
>>>> 
>>>>     >    str.raster<- function(object, ...) {
>>>>     >    str(as.matrix(object), ...);
>>>>     >    }
>>>> 
>>>>     >    Other suggestions?
>>>> 
>>>> The informal "raster" class is behaving ``illogical''
>>>> in the following sense:
>>>> 
>>>>  >    r<- as.raster(0, nrow=1, ncol=11)
>>>>  >    r[seq_along(r)]
>>>>  Error in `[.raster`(r, seq_along(r)) : subscript out of bounds
>>>> 
>>>> or, here equivalently,
>>>>  >    r[1:length(r)]
>>>>  Error in `[.raster`(r, 1:length(r)) : subscript out of bounds
>>>> 
>>>> When classes do behave in such a way, they definitely need their
>>>> own str() method.
>>>> 
>>>> However, the bug really is in "[.raster":
>>>> Currently,  r[i] is equivalent to  r[i,]  which is not at all
>>>> matrix-like and its help clearly says that subsetting should
>>>> work as for matrices.
>>>> A recent thread on R-help/R-devel has mentioned the fact that
>>>> "[" methods for matrix-like methods need to use both nargs() and
>>>> missing() and that "[.dataframe" has been the example to follow
>>>> "forever", IIRC already in S and S-plus as of 20 years ago.
>>> 
>>> The main motivation for non-standard behaviour here is to make sure that a
>>> subset of a raster object NEVER produces a vector (because the conversion
>>> back to a raster object then produces a single-column raster and that may be
>>> a "surprise").  Thanks for making the code more standard and robust.
>>> 
>>> The r[i] case is still tricky.  The following behaviour is quite convenient
>>> ...
>>> 
>>> r[r == "black"]<- "white"
>>> 
>>> ... but the next behaviour is quite jarring (at least in terms of the raster
>>> image that results from it) ...
>>> 
>>> r2<- r[1:(nrow(r) + 1)]
>>> 
>>> So I think there is some justification for further non-standardness to try
>>> to ensure that the subset of a raster image always produces a sensible
>>> image.  A simple solution would be just to outlaw r[i] for raster objects
>>> and force the user to write r[i, ] or r[, j], depending on what they want.
>> 
>> FYI, I've tried out Martin's updated version at it seems like a
>> one-column raster matrix is now returned for r[i], e.g.
> 
> Yes, that's what I've been looking at ...
> 
>>> r<- as.raster(1:8, max=8, nrow=2, ncol=4);
>>> r
>>      [,1]      [,2]      [,3]      [,4]
>> [1,] "#202020" "#606060" "#9F9F9F" "#DFDFDF"
>> [2,] "#404040" "#808080" "#BFBFBF" "#FFFFFF"
>> 
>>> r[1:length(r)]
>>      [,1]
>> [1,] "#202020"
>> [2,] "#404040"
>> [3,] "#606060"
>> [4,] "#808080"
>> [5,] "#9F9F9F"
>> [6,] "#BFBFBF"
>> [7,] "#DFDFDF"
>> [8,] "#FFFFFF"
> 
> ... and the above is exactly the sort of thing that will fry your mind if the image that you are subsetting is, for example, a photo.
> 

Why doesn't raster behave consistently like any matrix object? I would expect simply

> r[1:length(r)]
[1] "#202020" "#404040" "#606060" "#808080" "#9F9F9F" "#BFBFBF" "#DFDFDF"
[8] "#FFFFFF"

Where it's obvious what happened. I saw the comment about the vector but I'm not sure I get it - why don't you want a vector? The raster is no different than matrices - you still need to define the dimensions when going back anyway, moreover what you get now is not consistent at all since there raster never had that dimension anyway ...

Cheers,
Simon





> Paul
> 
>>> r[1:5,drop=TRUE]
>>      [,1]
>> [1,] "#202020"
>> [2,] "#404040"
>> [3,] "#606060"
>> [4,] "#808080"
>> [5,] "#9F9F9F"
>> Warning message:
>> In `[.raster`(r, 1:5, drop = TRUE) :
>>   'drop' is always implicitly FALSE in '[.raster'
>> 
>> Also,
>> 
>>> r[1:5]<- "white"
>>> r
>>      [,1]    [,2]    [,3]      [,4]
>> [1,] "white" "white" "white"   "#DFDFDF"
>> [2,] "white" "white" "#BFBFBF" "#FFFFFF"
>> 
>> /Henrik
>> 
>>> 
>>> Paul
>>> 
>>>> Thank you, Henrik, for the bug report.
>>>> Martin
>>>> 
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>> 
>>> --
>>> Dr Paul Murrell
>>> Department of Statistics
>>> The University of Auckland
>>> Private Bag 92019
>>> Auckland
>>> New Zealand
>>> 64 9 3737599 x85392
>>> paul at stat.auckland.ac.nz
>>> http://www.stat.auckland.ac.nz/~paul/
>>> 
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>> 
> 
> -- 
> Dr Paul Murrell
> Department of Statistics
> The University of Auckland
> Private Bag 92019
> Auckland
> New Zealand
> 64 9 3737599 x85392
> paul at stat.auckland.ac.nz
> http://www.stat.auckland.ac.nz/~paul/
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From maechler at stat.math.ethz.ch  Thu Feb  3 00:19:01 2011
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 3 Feb 2011 00:19:01 +0100
Subject: [Rd] [.raster bug {was "str() on raster objects fails .."}
In-Reply-To: <5251E963-8D1C-46CF-AAB9-39ABFE520229@r-project.org>
References: <AANLkTimycPK-3_mj5OPd0eLauAh41r2-Wkrp7j2jo1sw@mail.gmail.com>
	<19783.49835.494142.88222@stat.math.ethz.ch>
	<4D48A96B.9020801@auckland.ac.nz>
	<AANLkTimRBZbzgRfAkE2-VhnFmVRkWz1-cCqeD4VW7O42@mail.gmail.com>
	<4D48B08A.40302@auckland.ac.nz>
	<5251E963-8D1C-46CF-AAB9-39ABFE520229@r-project.org>
Message-ID: <AANLkTikgSiucEMzfSa2s9YTypkqzYLCab9gJvkGyr0Pz@mail.gmail.com>

On Wed, Feb 2, 2011 at 23:30, Simon Urbanek <simon.urbanek at r-project.org> wrote:
>
> On Feb 1, 2011, at 8:16 PM, Paul Murrell wrote:
>
>> Hi
>>
>> On 2/02/2011 2:03 p.m., Henrik Bengtsson wrote:
>>> On Tue, Feb 1, 2011 at 4:46 PM, Paul Murrell<p.murrell at auckland.ac.nz> ?wrote:
>>>> Hi
>>>>
>>>> On 1/02/2011 9:22 p.m., Martin Maechler wrote:
>>>>>>>>>>
>>>>>>>>>> Henrik Bengtsson<hb at biostat.ucsf.edu>
>>>>>>>>>> ? ? on Mon, 31 Jan 2011 11:16:59 -0800 writes:
>>>>>
>>>>> ? ? > ? ?Hi, str() on raster objects fails for certain dimensions. ?For
>>>>> ? ? > ? ?example:
>>>>>
>>>>> ? ? >> ? ?str(as.raster(0, nrow=1, ncol=100)) 'raster' chr [1, 1:100]
>>>>> ? ? > ? ?"#000000" "#000000" "#000000" "#000000" ...
>>>>>
>>>>> ? ? >> ? ?str(as.raster(0, nrow=1, ncol=101)) Error in `[.raster`(object,
>>>>> ? ? > ? ?seq_len(max.len)) : subscript out of bounds
>>>>>
>>>>> ? ? > ? ?This seems to do with how str() and "[.raster"() is coded; when
>>>>> ? ? > ? ?subsetting as a vector, which str() relies on, "[.raster"()
>>>>> ? ? > ? ?still returns a matrix-like object, e.g.
>>>>>
>>>>> ? ? >> ? ?img<- as.raster(1:25, max=25, nrow=5, ncol=5);
>>>>> ? ? >> ? ?img[1:2]
>>>>> ? ? > ? ?[,1] ? ? ?[,2] ? ? ?[,3] ? ? ?[,4] ? ? ?[,5]
>>>>> ? ? > ? ?[1,] "#0A0A0A" "#3D3D3D" "#707070" "#A3A3A3" "#D6D6D6"
>>>>> ? ? > ? ?[2,] "#141414" "#474747" "#7A7A7A" "#ADADAD" "#E0E0E0"
>>>>>
>>>>> ? ? > ? ?compare with:
>>>>>
>>>>> ? ? >> ? ?as.matrix(img)[1:2]
>>>>> ? ? > ? ?[1] "#0A0A0A" "#3D3D3D"
>>>>>
>>>>>
>>>>> ? ? > ? ?The easy but incomplete fix is to do:
>>>>>
>>>>> ? ? > ? ?str.raster<- function(object, ...) {
>>>>> ? ? > ? ?str(as.matrix(object), ...);
>>>>> ? ? > ? ?}
>>>>>
>>>>> ? ? > ? ?Other suggestions?
>>>>>
>>>>> The informal "raster" class is behaving ``illogical''
>>>>> in the following sense:
>>>>>
>>>>> ?> ? ?r<- as.raster(0, nrow=1, ncol=11)
>>>>> ?> ? ?r[seq_along(r)]
>>>>> ?Error in `[.raster`(r, seq_along(r)) : subscript out of bounds
>>>>>
>>>>> or, here equivalently,
>>>>> ?> ? ?r[1:length(r)]
>>>>> ?Error in `[.raster`(r, 1:length(r)) : subscript out of bounds
>>>>>
>>>>> When classes do behave in such a way, they definitely need their
>>>>> own str() method.
>>>>>
>>>>> However, the bug really is in "[.raster":
>>>>> Currently, ?r[i] is equivalent to ?r[i,] ?which is not at all
>>>>> matrix-like and its help clearly says that subsetting should
>>>>> work as for matrices.
>>>>> A recent thread on R-help/R-devel has mentioned the fact that
>>>>> "[" methods for matrix-like methods need to use both nargs() and
>>>>> missing() and that "[.dataframe" has been the example to follow
>>>>> "forever", IIRC already in S and S-plus as of 20 years ago.
>>>>
>>>> The main motivation for non-standard behaviour here is to make sure that a
>>>> subset of a raster object NEVER produces a vector (because the conversion
>>>> back to a raster object then produces a single-column raster and that may be
>>>> a "surprise"). ?Thanks for making the code more standard and robust.
>>>>
>>>> The r[i] case is still tricky. ?The following behaviour is quite convenient
>>>> ...
>>>>
>>>> r[r == "black"]<- "white"
>>>>
>>>> ... but the next behaviour is quite jarring (at least in terms of the raster
>>>> image that results from it) ...
>>>>
>>>> r2<- r[1:(nrow(r) + 1)]
>>>>
>>>> So I think there is some justification for further non-standardness to try
>>>> to ensure that the subset of a raster image always produces a sensible
>>>> image. ?A simple solution would be just to outlaw r[i] for raster objects
>>>> and force the user to write r[i, ] or r[, j], depending on what they want.
>>>
>>> FYI, I've tried out Martin's updated version at it seems like a
>>> one-column raster matrix is now returned for r[i], e.g.
>>
>> Yes, that's what I've been looking at ...
>>
>>>> r<- as.raster(1:8, max=8, nrow=2, ncol=4);
>>>> r
>>> ? ? ?[,1] ? ? ?[,2] ? ? ?[,3] ? ? ?[,4]
>>> [1,] "#202020" "#606060" "#9F9F9F" "#DFDFDF"
>>> [2,] "#404040" "#808080" "#BFBFBF" "#FFFFFF"
>>>
>>>> r[1:length(r)]
>>> ? ? ?[,1]
>>> [1,] "#202020"
>>> [2,] "#404040"
>>> [3,] "#606060"
>>> [4,] "#808080"
>>> [5,] "#9F9F9F"
>>> [6,] "#BFBFBF"
>>> [7,] "#DFDFDF"
>>> [8,] "#FFFFFF"
>>
>> ... and the above is exactly the sort of thing that will fry your mind if the image that you are subsetting is, for example, a photo.
>>
>
> Why doesn't raster behave consistently like any matrix object? I would expect simply
>
>> r[1:length(r)]
> [1] "#202020" "#404040" "#606060" "#808080" "#9F9F9F" "#BFBFBF" "#DFDFDF"
> [8] "#FFFFFF"
>
> Where it's obvious what happened. I saw the comment about the vector but I'm not sure I get it - why don't you want a vector? The raster is no different than matrices - you still need to define the dimensions when going back anyway, moreover what you get now is not consistent at all since there raster never had that dimension anyway ...
>
> Cheers,
> Simon

I agree that this would be the most "logical" and notably least
surprising behavior,
which I find the most important argument
(I'm sorry my last message was cut off as it was sent accidentally
before being finished completely).
Martin


>> Paul
>>
>>>> r[1:5,drop=TRUE]
>>> ? ? ?[,1]
>>> [1,] "#202020"
>>> [2,] "#404040"
>>> [3,] "#606060"
>>> [4,] "#808080"
>>> [5,] "#9F9F9F"
>>> Warning message:
>>> In `[.raster`(r, 1:5, drop = TRUE) :
>>> ? 'drop' is always implicitly FALSE in '[.raster'
>>>
>>> Also,
>>>
>>>> r[1:5]<- "white"
>>>> r
>>> ? ? ?[,1] ? ?[,2] ? ?[,3] ? ? ?[,4]
>>> [1,] "white" "white" "white" ? "#DFDFDF"
>>> [2,] "white" "white" "#BFBFBF" "#FFFFFF"
>>>
>>> /Henrik
>>>
>>>>
>>>> Paul
>>>>
>>>>> Thank you, Henrik, for the bug report.
>>>>> Martin
>>>>>
>>>>> ______________________________________________


From paul at stat.auckland.ac.nz  Thu Feb  3 01:00:36 2011
From: paul at stat.auckland.ac.nz (Paul Murrell)
Date: Thu, 03 Feb 2011 13:00:36 +1300
Subject: [Rd] [.raster bug {was "str() on raster objects fails .."}
In-Reply-To: <AANLkTikgSiucEMzfSa2s9YTypkqzYLCab9gJvkGyr0Pz@mail.gmail.com>
References: <AANLkTimycPK-3_mj5OPd0eLauAh41r2-Wkrp7j2jo1sw@mail.gmail.com>	<19783.49835.494142.88222@stat.math.ethz.ch>	<4D48A96B.9020801@auckland.ac.nz>	<AANLkTimRBZbzgRfAkE2-VhnFmVRkWz1-cCqeD4VW7O42@mail.gmail.com>	<4D48B08A.40302@auckland.ac.nz>	<5251E963-8D1C-46CF-AAB9-39ABFE520229@r-project.org>
	<AANLkTikgSiucEMzfSa2s9YTypkqzYLCab9gJvkGyr0Pz@mail.gmail.com>
Message-ID: <4D49F024.6090906@stat.auckland.ac.nz>

Hi

Martin Maechler wrote:
> On Wed, Feb 2, 2011 at 23:30, Simon Urbanek <simon.urbanek at r-project.org> wrote:
>> On Feb 1, 2011, at 8:16 PM, Paul Murrell wrote:
>>
>>> Hi
>>>
>>> On 2/02/2011 2:03 p.m., Henrik Bengtsson wrote:
>>>> On Tue, Feb 1, 2011 at 4:46 PM, Paul Murrell<p.murrell at auckland.ac.nz>  wrote:
>>>>> Hi
>>>>>
>>>>> On 1/02/2011 9:22 p.m., Martin Maechler wrote:
>>>>>>>>>>> Henrik Bengtsson<hb at biostat.ucsf.edu>
>>>>>>>>>>>     on Mon, 31 Jan 2011 11:16:59 -0800 writes:
>>>>>>     >    Hi, str() on raster objects fails for certain dimensions.  For
>>>>>>     >    example:
>>>>>>
>>>>>>     >>    str(as.raster(0, nrow=1, ncol=100)) 'raster' chr [1, 1:100]
>>>>>>     >    "#000000" "#000000" "#000000" "#000000" ...
>>>>>>
>>>>>>     >>    str(as.raster(0, nrow=1, ncol=101)) Error in `[.raster`(object,
>>>>>>     >    seq_len(max.len)) : subscript out of bounds
>>>>>>
>>>>>>     >    This seems to do with how str() and "[.raster"() is coded; when
>>>>>>     >    subsetting as a vector, which str() relies on, "[.raster"()
>>>>>>     >    still returns a matrix-like object, e.g.
>>>>>>
>>>>>>     >>    img<- as.raster(1:25, max=25, nrow=5, ncol=5);
>>>>>>     >>    img[1:2]
>>>>>>     >    [,1]      [,2]      [,3]      [,4]      [,5]
>>>>>>     >    [1,] "#0A0A0A" "#3D3D3D" "#707070" "#A3A3A3" "#D6D6D6"
>>>>>>     >    [2,] "#141414" "#474747" "#7A7A7A" "#ADADAD" "#E0E0E0"
>>>>>>
>>>>>>     >    compare with:
>>>>>>
>>>>>>     >>    as.matrix(img)[1:2]
>>>>>>     >    [1] "#0A0A0A" "#3D3D3D"
>>>>>>
>>>>>>
>>>>>>     >    The easy but incomplete fix is to do:
>>>>>>
>>>>>>     >    str.raster<- function(object, ...) {
>>>>>>     >    str(as.matrix(object), ...);
>>>>>>     >    }
>>>>>>
>>>>>>     >    Other suggestions?
>>>>>>
>>>>>> The informal "raster" class is behaving ``illogical''
>>>>>> in the following sense:
>>>>>>
>>>>>>  >    r<- as.raster(0, nrow=1, ncol=11)
>>>>>>  >    r[seq_along(r)]
>>>>>>  Error in `[.raster`(r, seq_along(r)) : subscript out of bounds
>>>>>>
>>>>>> or, here equivalently,
>>>>>>  >    r[1:length(r)]
>>>>>>  Error in `[.raster`(r, 1:length(r)) : subscript out of bounds
>>>>>>
>>>>>> When classes do behave in such a way, they definitely need their
>>>>>> own str() method.
>>>>>>
>>>>>> However, the bug really is in "[.raster":
>>>>>> Currently,  r[i] is equivalent to  r[i,]  which is not at all
>>>>>> matrix-like and its help clearly says that subsetting should
>>>>>> work as for matrices.
>>>>>> A recent thread on R-help/R-devel has mentioned the fact that
>>>>>> "[" methods for matrix-like methods need to use both nargs() and
>>>>>> missing() and that "[.dataframe" has been the example to follow
>>>>>> "forever", IIRC already in S and S-plus as of 20 years ago.
>>>>> The main motivation for non-standard behaviour here is to make sure that a
>>>>> subset of a raster object NEVER produces a vector (because the conversion
>>>>> back to a raster object then produces a single-column raster and that may be
>>>>> a "surprise").  Thanks for making the code more standard and robust.
>>>>>
>>>>> The r[i] case is still tricky.  The following behaviour is quite convenient
>>>>> ...
>>>>>
>>>>> r[r == "black"]<- "white"
>>>>>
>>>>> ... but the next behaviour is quite jarring (at least in terms of the raster
>>>>> image that results from it) ...
>>>>>
>>>>> r2<- r[1:(nrow(r) + 1)]
>>>>>
>>>>> So I think there is some justification for further non-standardness to try
>>>>> to ensure that the subset of a raster image always produces a sensible
>>>>> image.  A simple solution would be just to outlaw r[i] for raster objects
>>>>> and force the user to write r[i, ] or r[, j], depending on what they want.
>>>> FYI, I've tried out Martin's updated version at it seems like a
>>>> one-column raster matrix is now returned for r[i], e.g.
>>> Yes, that's what I've been looking at ...
>>>
>>>>> r<- as.raster(1:8, max=8, nrow=2, ncol=4);
>>>>> r
>>>>      [,1]      [,2]      [,3]      [,4]
>>>> [1,] "#202020" "#606060" "#9F9F9F" "#DFDFDF"
>>>> [2,] "#404040" "#808080" "#BFBFBF" "#FFFFFF"
>>>>
>>>>> r[1:length(r)]
>>>>      [,1]
>>>> [1,] "#202020"
>>>> [2,] "#404040"
>>>> [3,] "#606060"
>>>> [4,] "#808080"
>>>> [5,] "#9F9F9F"
>>>> [6,] "#BFBFBF"
>>>> [7,] "#DFDFDF"
>>>> [8,] "#FFFFFF"
>>> ... and the above is exactly the sort of thing that will fry your mind if the image that you are subsetting is, for example, a photo.
>>>
>> Why doesn't raster behave consistently like any matrix object? I would expect simply
>>
>>> r[1:length(r)]
>> [1] "#202020" "#404040" "#606060" "#808080" "#9F9F9F" "#BFBFBF" "#DFDFDF"
>> [8] "#FFFFFF"
>>
>> Where it's obvious what happened. I saw the comment about the vector but I'm not sure I get it - why don't you want a vector? The raster is no different than matrices - you still need to define the dimensions when going back anyway, moreover what you get now is not consistent at all since there raster never had that dimension anyway ...
>>
>> Cheers,
>> Simon
> 
> I agree that this would be the most "logical" and notably least
> surprising behavior,
> which I find the most important argument
> (I'm sorry my last message was cut off as it was sent accidentally
> before being finished completely).

I think this behaviour might surprise some ...

download.file("http://cran.r-project.org/Rlogo.jpg",
               "Rlogo.jpg")
library(ReadImages)
logo <- read.jpeg("Rlogo.jpg")

rLogo <- as.raster(logo)
rLogoBit <- rLogo[50:60, 50:60]

library(grid)
# Original image
grid.raster(rLogoBit)
grid.newpage()
# Subset produces a vector
grid.raster(rLogoBit[1:length(rLogoBit)])

Paul

> Martin
> 
> 
>>> Paul
>>>
>>>>> r[1:5,drop=TRUE]
>>>>      [,1]
>>>> [1,] "#202020"
>>>> [2,] "#404040"
>>>> [3,] "#606060"
>>>> [4,] "#808080"
>>>> [5,] "#9F9F9F"
>>>> Warning message:
>>>> In `[.raster`(r, 1:5, drop = TRUE) :
>>>>   'drop' is always implicitly FALSE in '[.raster'
>>>>
>>>> Also,
>>>>
>>>>> r[1:5]<- "white"
>>>>> r
>>>>      [,1]    [,2]    [,3]      [,4]
>>>> [1,] "white" "white" "white"   "#DFDFDF"
>>>> [2,] "white" "white" "#BFBFBF" "#FFFFFF"
>>>>
>>>> /Henrik
>>>>
>>>>> Paul
>>>>>
>>>>>> Thank you, Henrik, for the bug report.
>>>>>> Martin
>>>>>>
>>>>>> ______________________________________________

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/


From simon.urbanek at r-project.org  Thu Feb  3 01:23:28 2011
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Wed, 2 Feb 2011 19:23:28 -0500
Subject: [Rd] [.raster bug {was "str() on raster objects fails .."}
In-Reply-To: <4D49F024.6090906@stat.auckland.ac.nz>
References: <AANLkTimycPK-3_mj5OPd0eLauAh41r2-Wkrp7j2jo1sw@mail.gmail.com>	<19783.49835.494142.88222@stat.math.ethz.ch>	<4D48A96B.9020801@auckland.ac.nz>	<AANLkTimRBZbzgRfAkE2-VhnFmVRkWz1-cCqeD4VW7O42@mail.gmail.com>	<4D48B08A.40302@auckland.ac.nz>	<5251E963-8D1C-46CF-AAB9-39ABFE520229@r-project.org>
	<AANLkTikgSiucEMzfSa2s9YTypkqzYLCab9gJvkGyr0Pz@mail.gmail.com>
	<4D49F024.6090906@stat.auckland.ac.nz>
Message-ID: <74150327-8264-43FF-A4AC-1D3A2C469B4F@r-project.org>


On Feb 2, 2011, at 7:00 PM, Paul Murrell wrote:

> Hi
> 
> Martin Maechler wrote:
>> On Wed, Feb 2, 2011 at 23:30, Simon Urbanek <simon.urbanek at r-project.org> wrote:
>>> On Feb 1, 2011, at 8:16 PM, Paul Murrell wrote:
>>> 
>>>> Hi
>>>> 
>>>> On 2/02/2011 2:03 p.m., Henrik Bengtsson wrote:
>>>>> On Tue, Feb 1, 2011 at 4:46 PM, Paul Murrell<p.murrell at auckland.ac.nz>  wrote:
>>>>>> Hi
>>>>>> 
>>>>>> On 1/02/2011 9:22 p.m., Martin Maechler wrote:
>>>>>>>>>>>> Henrik Bengtsson<hb at biostat.ucsf.edu>
>>>>>>>>>>>>    on Mon, 31 Jan 2011 11:16:59 -0800 writes:
>>>>>>>    >    Hi, str() on raster objects fails for certain dimensions.  For
>>>>>>>    >    example:
>>>>>>> 
>>>>>>>    >>    str(as.raster(0, nrow=1, ncol=100)) 'raster' chr [1, 1:100]
>>>>>>>    >    "#000000" "#000000" "#000000" "#000000" ...
>>>>>>> 
>>>>>>>    >>    str(as.raster(0, nrow=1, ncol=101)) Error in `[.raster`(object,
>>>>>>>    >    seq_len(max.len)) : subscript out of bounds
>>>>>>> 
>>>>>>>    >    This seems to do with how str() and "[.raster"() is coded; when
>>>>>>>    >    subsetting as a vector, which str() relies on, "[.raster"()
>>>>>>>    >    still returns a matrix-like object, e.g.
>>>>>>> 
>>>>>>>    >>    img<- as.raster(1:25, max=25, nrow=5, ncol=5);
>>>>>>>    >>    img[1:2]
>>>>>>>    >    [,1]      [,2]      [,3]      [,4]      [,5]
>>>>>>>    >    [1,] "#0A0A0A" "#3D3D3D" "#707070" "#A3A3A3" "#D6D6D6"
>>>>>>>    >    [2,] "#141414" "#474747" "#7A7A7A" "#ADADAD" "#E0E0E0"
>>>>>>> 
>>>>>>>    >    compare with:
>>>>>>> 
>>>>>>>    >>    as.matrix(img)[1:2]
>>>>>>>    >    [1] "#0A0A0A" "#3D3D3D"
>>>>>>> 
>>>>>>> 
>>>>>>>    >    The easy but incomplete fix is to do:
>>>>>>> 
>>>>>>>    >    str.raster<- function(object, ...) {
>>>>>>>    >    str(as.matrix(object), ...);
>>>>>>>    >    }
>>>>>>> 
>>>>>>>    >    Other suggestions?
>>>>>>> 
>>>>>>> The informal "raster" class is behaving ``illogical''
>>>>>>> in the following sense:
>>>>>>> 
>>>>>>> >    r<- as.raster(0, nrow=1, ncol=11)
>>>>>>> >    r[seq_along(r)]
>>>>>>> Error in `[.raster`(r, seq_along(r)) : subscript out of bounds
>>>>>>> 
>>>>>>> or, here equivalently,
>>>>>>> >    r[1:length(r)]
>>>>>>> Error in `[.raster`(r, 1:length(r)) : subscript out of bounds
>>>>>>> 
>>>>>>> When classes do behave in such a way, they definitely need their
>>>>>>> own str() method.
>>>>>>> 
>>>>>>> However, the bug really is in "[.raster":
>>>>>>> Currently,  r[i] is equivalent to  r[i,]  which is not at all
>>>>>>> matrix-like and its help clearly says that subsetting should
>>>>>>> work as for matrices.
>>>>>>> A recent thread on R-help/R-devel has mentioned the fact that
>>>>>>> "[" methods for matrix-like methods need to use both nargs() and
>>>>>>> missing() and that "[.dataframe" has been the example to follow
>>>>>>> "forever", IIRC already in S and S-plus as of 20 years ago.
>>>>>> The main motivation for non-standard behaviour here is to make sure that a
>>>>>> subset of a raster object NEVER produces a vector (because the conversion
>>>>>> back to a raster object then produces a single-column raster and that may be
>>>>>> a "surprise").  Thanks for making the code more standard and robust.
>>>>>> 
>>>>>> The r[i] case is still tricky.  The following behaviour is quite convenient
>>>>>> ...
>>>>>> 
>>>>>> r[r == "black"]<- "white"
>>>>>> 
>>>>>> ... but the next behaviour is quite jarring (at least in terms of the raster
>>>>>> image that results from it) ...
>>>>>> 
>>>>>> r2<- r[1:(nrow(r) + 1)]
>>>>>> 
>>>>>> So I think there is some justification for further non-standardness to try
>>>>>> to ensure that the subset of a raster image always produces a sensible
>>>>>> image.  A simple solution would be just to outlaw r[i] for raster objects
>>>>>> and force the user to write r[i, ] or r[, j], depending on what they want.
>>>>> FYI, I've tried out Martin's updated version at it seems like a
>>>>> one-column raster matrix is now returned for r[i], e.g.
>>>> Yes, that's what I've been looking at ...
>>>> 
>>>>>> r<- as.raster(1:8, max=8, nrow=2, ncol=4);
>>>>>> r
>>>>>     [,1]      [,2]      [,3]      [,4]
>>>>> [1,] "#202020" "#606060" "#9F9F9F" "#DFDFDF"
>>>>> [2,] "#404040" "#808080" "#BFBFBF" "#FFFFFF"
>>>>> 
>>>>>> r[1:length(r)]
>>>>>     [,1]
>>>>> [1,] "#202020"
>>>>> [2,] "#404040"
>>>>> [3,] "#606060"
>>>>> [4,] "#808080"
>>>>> [5,] "#9F9F9F"
>>>>> [6,] "#BFBFBF"
>>>>> [7,] "#DFDFDF"
>>>>> [8,] "#FFFFFF"
>>>> ... and the above is exactly the sort of thing that will fry your mind if the image that you are subsetting is, for example, a photo.
>>>> 
>>> Why doesn't raster behave consistently like any matrix object? I would expect simply
>>> 
>>>> r[1:length(r)]
>>> [1] "#202020" "#404040" "#606060" "#808080" "#9F9F9F" "#BFBFBF" "#DFDFDF"
>>> [8] "#FFFFFF"
>>> 
>>> Where it's obvious what happened. I saw the comment about the vector but I'm not sure I get it - why don't you want a vector? The raster is no different than matrices - you still need to define the dimensions when going back anyway, moreover what you get now is not consistent at all since there raster never had that dimension anyway ...
>>> 
>>> Cheers,
>>> Simon
>> I agree that this would be the most "logical" and notably least
>> surprising behavior,
>> which I find the most important argument
>> (I'm sorry my last message was cut off as it was sent accidentally
>> before being finished completely).
> 
> I think this behaviour might surprise some ...
> 
> download.file("http://cran.r-project.org/Rlogo.jpg",
>              "Rlogo.jpg")
> library(ReadImages)
> logo <- read.jpeg("Rlogo.jpg")
> 
> rLogo <- as.raster(logo)
> rLogoBit <- rLogo[50:60, 50:60]
> 
> library(grid)
> # Original image
> grid.raster(rLogoBit)
> grid.newpage()
> # Subset produces a vector
> grid.raster(rLogoBit[1:length(rLogoBit)])
> 

But this should fail IMHO since you're supplying a vector but grid.raster (assuming it's the same as rasterImage) requires a matrix - exactly as you would expect in the matrix case - if a function requires a matrix and you pass a vector, it will bark. I think you are explaining why going to vector *is* desirable ;). In the current case it simply generates the wrong dimensions instead of resulting in a vector, right?

Cheers,
Simon





> Paul
> 
>> Martin
>>>> Paul
>>>> 
>>>>>> r[1:5,drop=TRUE]
>>>>>     [,1]
>>>>> [1,] "#202020"
>>>>> [2,] "#404040"
>>>>> [3,] "#606060"
>>>>> [4,] "#808080"
>>>>> [5,] "#9F9F9F"
>>>>> Warning message:
>>>>> In `[.raster`(r, 1:5, drop = TRUE) :
>>>>>  'drop' is always implicitly FALSE in '[.raster'
>>>>> 
>>>>> Also,
>>>>> 
>>>>>> r[1:5]<- "white"
>>>>>> r
>>>>>     [,1]    [,2]    [,3]      [,4]
>>>>> [1,] "white" "white" "white"   "#DFDFDF"
>>>>> [2,] "white" "white" "#BFBFBF" "#FFFFFF"
>>>>> 
>>>>> /Henrik
>>>>> 
>>>>>> Paul
>>>>>> 
>>>>>>> Thank you, Henrik, for the bug report.
>>>>>>> Martin
>>>>>>> 
>>>>>>> ______________________________________________
> 
> -- 
> Dr Paul Murrell
> Department of Statistics
> The University of Auckland
> Private Bag 92019
> Auckland
> New Zealand
> 64 9 3737599 x85392
> paul at stat.auckland.ac.nz
> http://www.stat.auckland.ac.nz/~paul/
> 
> 


From jeffrey.horner at gmail.com  Thu Feb  3 04:25:18 2011
From: jeffrey.horner at gmail.com (Jeffrey Horner)
Date: Wed, 2 Feb 2011 21:25:18 -0600
Subject: [Rd] Creating a reference class object from a class definition in a
 package fails
Message-ID: <AANLkTimXJ+J+HPR_+tPAExFUAJ3_xmYKYzQXvpn5r8du@mail.gmail.com>

Hi,

I'm trying to create a package that contains reference class
definitions from which users can create reference objects, but there
seems to be something awry.

My toy example creates an empty package via
package.skeleton('TestClass') to which I add the following R code:

TestClass <- setRefClass('TestClass',fields=c('name'))

Unfortunately my R console output bears this:

> library(TestClass)
> TestClass$new(name='foo')
Error: attempt to apply non-function
> getRefClass('TestClass')$new(name='foo')
Error: attempt to apply non-function

Creating the same reference class in the global environment works though:

> x <- setRefClass('TestClass',fields='name')
> x$new(name='foo')
An object of class "TestClass"
<environment: 0x82a43cc>

I'm new to S4 and reference classes, so maybe I'm missing something fundamental?

Jeff

> sessionInfo()
R version 2.13.0 Under development (unstable) (2011-02-02 r54197)
Platform: i686-pc-linux-gnu (32-bit)

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
 [5] LC_MONETARY=C              LC_MESSAGES=en_US.UTF-8
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
 [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices datasets  utils     methods   base

other attached packages:
[1] TestClass_1.0

loaded via a namespace (and not attached):
[1] tools_2.13.0


From gong-yi.liao at uconn.edu  Thu Feb  3 05:33:56 2011
From: gong-yi.liao at uconn.edu (Gong-Yi Liao)
Date: Wed, 02 Feb 2011 23:33:56 -0500
Subject: [Rd] Using MathJax in R's help system
In-Reply-To: <AANLkTik6YmG6YMvJ5E-_yBcFv4zZ-MGP1NMpB5X8B3-u@mail.gmail.com>
References: <1296633646.25319.58.camel@GongTop1>
	<AANLkTi=RD0gyB8QnAs7aa2yv7647_x2SBAyZ_AL=LLoz@mail.gmail.com>
	<1296664429.2269.49.camel@GongTop1>
	<AANLkTik6YmG6YMvJ5E-_yBcFv4zZ-MGP1NMpB5X8B3-u@mail.gmail.com>
Message-ID: <1296707636.12271.51.camel@GongTop1>


Thank you for reply, 

  I made some modification, the diff (against helpr 0.1.2.2) 

  is attached. 

  What I did are 

  1. Install helpr by install.packages() 

  2. Download the MathJax distribution and extract it under 

   $R_HOME/library/public/_script 

  3. Create a new html snippet file _mathjax_config.html in 
  
  the $R_HOME/library/view directory and then make index.html, 

  package.html, topic.html, source.html, and whistle.html  

  include the line 

  <%= helpr:::render_snippet("mathjax_config") %>


  4. modify \\deqn part of th parse-rd.R from 
  
    "<code>... </code>" to "\\[ ... \\]"

    and similarly, for \\eqn part from 

    "<code>... </code>" to "$ ... $".


  The screenshot is also attached. 

  The rest question is, how to make R download the MathJax, 

  while install helpr?



  Any comments are appreciated.

  

On Wed, 2011-02-02 at 10:38 -0600, Hadley Wickham wrote: 
> But the user still needs to get it in some way - an additional
> installation step means that it's probably not suitable for inclusion
> with base R.  It could possibly be bundled inside a package, using
> some tricks to keep all the files in a single zip file, which reduces
> the bundle size to a manageable 15 meg.

> Agreed.
> 
> >    2. About the helpr package:
> >
> >        
> 
> Could you please provide a reproducible example?
> 
> The following steps should get you up and running:
> 
> install.packages("helpr")
> library(helpr)
> helpr()
> 
> The solr warnings will be removed in the next version - you can ignore
> them for now.
> 
> Hadley
> 

-- 
Gong-Yi Liao

Department of Statistics
University of Connecticut
215 Glenbrook Road  U4120
Storrs, CT 06269-4120

860-486-9478 
-------------- next part --------------
A non-text attachment was scrubbed...
Name: helpr_mathjax.diff
Type: text/x-patch
Size: 1656 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110202/66413063/attachment.bin>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: helpr_with_mathjax.png
Type: image/png
Size: 104557 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110202/66413063/attachment.png>

From htl10 at users.sourceforge.net  Thu Feb  3 11:26:33 2011
From: htl10 at users.sourceforge.net (Hin-Tak Leung)
Date: Thu, 3 Feb 2011 10:26:33 +0000 (GMT)
Subject: [Rd] bug in codetools/R CMD check?
Message-ID: <257810.82307.qm@web29520.mail.ird.yahoo.com>

Hi Mr Tierney,

I have noticed an error message from R 1.12.x's CMD check for a while (apparently prof Ripley completely rewrote CMD check in R 1.12+)
e.g.:
http://bioconductor.org/checkResults/2.7/bioc-LATEST/snpMatrix/lamb2-checksrc.html

----------------
* checking R code for possible problems ... NOTE
Warning: non-unique value when setting 'row.names': ?new?
Error in `row.names<-.data.frame`(`*tmp*`, value = c("1", "new", "new" : 
  duplicate 'row.names' are not allowed
Calls: <Anonymous> ... rownames<- -> row.names<- -> row.names<-.data.frame
Execution halted
-----------------

yet everything is okey dokey at http://bioconductor.org/checkResults/2.7/bioc-LATEST/#S under the snpMatrix entry.

I believe it might be a bug in codetools::incLocalSrcInfo (used by "R CMD check") and here is what I think the fix(?) - but I am not entirely sure what that routine does and why other package writers haven't noticed similiar problems before:

diff -ur codetools/R/codetools.R codetools-fix/R/codetools.R
--- codetools/R/codetools.R	2011-01-07 15:52:58.000000000 +0000
+++ codetools-fix/R/codetools.R	2011-02-03 10:03:54.000000000 +0000
@@ -823,8 +823,9 @@
     new <- list(srcfile = if (is.null(w$srcfile)) NA_character_ else w$srcfile,
                 frow = if (is.null(w$frow)) NA_integer_ else w$frow,
                 lrow = if (is.null(w$lrow)) NA_integer_ else w$lrow)
+    new <- as.data.frame(new, stringsAsFactors = FALSE)
     if (is.null(value))
-        value <- as.data.frame(new, stringsAsFactors = FALSE)
+        value <- new
     else
         value <- rbind(value, new)
     assign("srcinfo", value, entry)


Apply this "fix" would result in snpMatrix's "R CMD check" churning out:

---------------------
.ld.withmany: local variable ?names.components? assigned but may not be used
.ld.withmany: local variable ?nsnps.for.each? assigned but may not be used
misinherits: local variable ?nc.snps? assigned but may not be used
misinherits: local variable ?nr.snps? assigned but may not be used
qq.chisq: local variable ?lab? assigned but may not be used
read.HapMap.data: local variable ?base? assigned but may not be used
read.HapMap.data: local variable ?build? assigned but may not be used
read.HapMap.data: local variable ?finish? assigned but may not be used
read.HapMap.data: local variable ?strand? assigned but may not be used
tdt.snp: local variable ?nc.snps? assigned but may not be used
tdt.snp: local variable ?nr.snps? assigned but may not be used
---------------------

which is more like expected check warnings.

Care to comment?

Hin-Tak Leung





From rainer.stuetz at gmail.com  Thu Feb  3 15:56:10 2011
From: rainer.stuetz at gmail.com (Rainer Stuetz)
Date: Thu, 3 Feb 2011 15:56:10 +0100
Subject: [Rd] Minor typo in files2.Rd (Manipulaton)
Message-ID: <AANLkTinxfwxXXaMFf4-c1eQi5PBF51G_TCwq2ErEXP+b@mail.gmail.com>

There is a minor typo in the title section of 'files2.Rd':

~/R/r-devel> svn diff
Index: src/library/base/man/files2.Rd
===================================================================
--- src/library/base/man/files2.Rd	(revision 54213)
+++ src/library/base/man/files2.Rd	(working copy)
@@ -9,7 +9,7 @@
 \alias{Sys.umask}
 \concept{directory}
 \concept{mkdir}
-\title{Manipulaton of Directories and file Permissions}
+\title{Manipulation of Directories and file Permissions}
 \usage{
 dir.create(path, showWarnings = TRUE, recursive = FALSE, mode = "0777")
 Sys.chmod(paths, mode = "0777")


Thanks,
Rainer


From pgilbert at bank-banque-canada.ca  Thu Feb  3 18:29:27 2011
From: pgilbert at bank-banque-canada.ca (Paul Gilbert)
Date: Thu, 3 Feb 2011 17:29:27 +0000
Subject: [Rd] S3 method for S4 object
Message-ID: <6441154A9FF1CD4386AF4ABF141A056D2151ABD4@WMEXOSCD2-N2.bocad.bank-banque-canada.ca>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110203/6b6c2acc/attachment.pl>

From mtmorgan at fhcrc.org  Thu Feb  3 19:15:30 2011
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Thu, 03 Feb 2011 10:15:30 -0800
Subject: [Rd] S3 method for S4 object
In-Reply-To: <6441154A9FF1CD4386AF4ABF141A056D2151ABD4@WMEXOSCD2-N2.bocad.bank-banque-canada.ca>
References: <6441154A9FF1CD4386AF4ABF141A056D2151ABD4@WMEXOSCD2-N2.bocad.bank-banque-canada.ca>
Message-ID: <4D4AF0C2.1070104@fhcrc.org>

On 02/03/2011 09:29 AM, Paul Gilbert wrote:
> I am trying to extend an S3 method to work with an S4 object as well
> as the S3 objects it works with, but UseMethod does not seem to
> recognize the S4 class and dispatches to the default method.  Is this
> to be expected or should I be looking for an error in my code?
> 
> If it is not an error in my code, is there an easy way to do this, or
> do I have to convert the generic to S4 and then make  those methods
> deal with the S3 objects?

Hi Paul

See ?Methods and the "Methods for S3 Generic Functions" section.

Martin

> 
> (Using R 2.12.1 on Ubuntu 10.10.)
> 
> Paul Gilbert 
> ====================================================================================
>
>  La version fran??aise suit le texte anglais.
> 
> ------------------------------------------------------------------------------------
>
>  This email may contain privileged and/or confidential information,
> and the Bank of Canada does not waive any related rights. Any
> distribution, use, or copying of this email or the information it
> contains by other than the intended recipient is unauthorized. If you
> received this email in error please delete it immediately from your
> system and notify the sender promptly by email that you have done so.
> 
> 
> ------------------------------------------------------------------------------------
>
>  Le pr??sent courriel peut contenir de l'information privil??gi??e ou
> confidentielle. La Banque du Canada ne renonce pas aux droits qui s'y
> rapportent. Toute diffusion, utilisation ou copie de ce courriel ou
> des renseignements qu'il contient par une personne autre que le ou
> les destinataires d??sign??s est interdite. Si vous recevez ce
> courriel par erreur, veuillez le supprimer imm??diatement et envoyer
> sans d??lai ? l'exp??diteur un message ??lectronique pour l'aviser
> que vous avez ??limin?? de votre ordinateur toute copie du courriel
> re??u.
> 
> [[alternative HTML version deleted]]
> 
> 
> 
> 
> ______________________________________________ R-devel at r-project.org
> mailing list https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
Computational Biology
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N. PO Box 19024 Seattle, WA 98109

Location: M1-B861
Telephone: 206 667-2793


From jeffrey.horner at gmail.com  Thu Feb  3 22:46:19 2011
From: jeffrey.horner at gmail.com (Jeffrey Horner)
Date: Thu, 3 Feb 2011 15:46:19 -0600
Subject: [Rd] Creating a reference class object from a class definition
 in a package fails
In-Reply-To: <AANLkTimXJ+J+HPR_+tPAExFUAJ3_xmYKYzQXvpn5r8du@mail.gmail.com>
References: <AANLkTimXJ+J+HPR_+tPAExFUAJ3_xmYKYzQXvpn5r8du@mail.gmail.com>
Message-ID: <AANLkTim_qkOYXkKU0J-FGCqGmHQX_Cqvd7LNNPhyFUQ4@mail.gmail.com>

Apparently reference classes must be declared in the NAMESPACE file
via an S4 declaration. If I place the following in the NAMESPACE file
all is well:

exportClasses(TestClass)
export(TestClass)


Jeff

On Wed, Feb 2, 2011 at 9:25 PM, Jeffrey Horner <jeffrey.horner at gmail.com> wrote:
> Hi,
>
> I'm trying to create a package that contains reference class
> definitions from which users can create reference objects, but there
> seems to be something awry.
>
> My toy example creates an empty package via
> package.skeleton('TestClass') to which I add the following R code:
>
> TestClass <- setRefClass('TestClass',fields=c('name'))
>
> Unfortunately my R console output bears this:
>
>> library(TestClass)
>> TestClass$new(name='foo')
> Error: attempt to apply non-function
>> getRefClass('TestClass')$new(name='foo')
> Error: attempt to apply non-function
>
> Creating the same reference class in the global environment works though:
>
>> x <- setRefClass('TestClass',fields='name')
>> x$new(name='foo')
> An object of class "TestClass"
> <environment: 0x82a43cc>
>
> I'm new to S4 and reference classes, so maybe I'm missing something fundamental?
>
> Jeff
>
>> sessionInfo()
> R version 2.13.0 Under development (unstable) (2011-02-02 r54197)
> Platform: i686-pc-linux-gnu (32-bit)
>
> locale:
> ?[1] LC_CTYPE=en_US.UTF-8 ? ? ? LC_NUMERIC=C
> ?[3] LC_TIME=en_US.UTF-8 ? ? ? ?LC_COLLATE=en_US.UTF-8
> ?[5] LC_MONETARY=C ? ? ? ? ? ? ?LC_MESSAGES=en_US.UTF-8
> ?[7] LC_PAPER=en_US.UTF-8 ? ? ? LC_NAME=C
> ?[9] LC_ADDRESS=C ? ? ? ? ? ? ? LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats ? ? graphics ?grDevices datasets ?utils ? ? methods ? base
>
> other attached packages:
> [1] TestClass_1.0
>
> loaded via a namespace (and not attached):
> [1] tools_2.13.0
>



-- 
http://biostat.mc.vanderbilt.edu/JeffreyHorner


From john.maindonald at anu.edu.au  Fri Feb  4 01:09:01 2011
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Fri, 4 Feb 2011 13:09:01 +1300
Subject: [Rd] keep.source when semicolons separate statements on the one line
Message-ID: <48B94A4D-DB81-4912-850B-CDB2D7711968@anu.edu.au>

The following is 'semicolon.Rnw'

> \SweaveOpts{engine=R, keep.source=TRUE}
> 
> <<xycig-A, eval=f, echo=f>>=
> library(SMIR); data(bronchit); library(KernSmooth)
> @ %
> 
> Code for panel A is
> <<code-xycig-A, eval=f, echo=t>>=
> <<xycig-A>>
> @ %

Sweave("semicolon") yields the following 'semicolon.tex'

> Code for panel A is
> \begin{Schunk}
> \begin{Sinput}
>> library(SMIR); data(bronchit); library(KernSmooth)
>> library(SMIR); data(bronchit); library(KernSmooth)
>> library(SMIR); data(bronchit); library(KernSmooth)
> \end{Sinput}
> \end{Schunk}

(I have omitted three blank lines at the start)

With keep.source=FALSE, the commands are split onto 
separate lines, and there is no repetition.

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.
http://www.maths.anu.edu.au/~johnm


From john.maindonald at anu.edu.au  Fri Feb  4 01:11:54 2011
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Fri, 4 Feb 2011 13:11:54 +1300
Subject: [Rd] keep.source when semicolons separate statements on the one
	line; PS
Message-ID: <966372B7-299F-4BD5-8C23-0C962C356668@anu.edu.au>

I forgot to add the sessionInfo() information:

> sessionInfo()
R version 2.12.1 Patched (2011-01-22 r54081)
Platform: x86_64-pc-mingw32/x64 (64-bit)
. . .


The following is 'semicolon.Rnw'

> \SweaveOpts{engine=R, keep.source=TRUE}
> 
> <<xycig-A, eval=f, echo=f>>=
> library(SMIR); data(bronchit); library(KernSmooth)
> @ %
> 
> Code for panel A is
> <<code-xycig-A, eval=f, echo=t>>=
> <<xycig-A>>
> @ %

Sweave("semicolon") yields the following 'semicolon.tex'

> Code for panel A is
> \begin{Schunk}
> \begin{Sinput}
>> library(SMIR); data(bronchit); library(KernSmooth)
>> library(SMIR); data(bronchit); library(KernSmooth)
>> library(SMIR); data(bronchit); library(KernSmooth)
> \end{Sinput}
> \end{Schunk}

(I have omitted three blank lines at the start)

With keep.source=FALSE, the commands are split onto 
separate lines, and there is no repetition.

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.
http://www.maths.anu.edu.au/~johnm


From jmc at r-project.org  Fri Feb  4 01:38:31 2011
From: jmc at r-project.org (John Chambers)
Date: Thu, 03 Feb 2011 16:38:31 -0800
Subject: [Rd] Creating a reference class object from a class definition
 in a package fails
In-Reply-To: <AANLkTimXJ+J+HPR_+tPAExFUAJ3_xmYKYzQXvpn5r8du@mail.gmail.com>
References: <AANLkTimXJ+J+HPR_+tPAExFUAJ3_xmYKYzQXvpn5r8du@mail.gmail.com>
Message-ID: <4D4B4A87.4070801@r-project.org>

You don't say, but my guess is you created the package without a namespace.

For reasons that are not too clear at the moment, the namespace seems to 
be needed.  At any rate, replicating your experiment with the argument 
namespace=TRUE to package.skeleton() worked:

 > require(TestClass2)
Loading required package: TestClass2
 > TestClass$new()
An object of class "TestClass"
<environment: 0x100df2e38>

Without that I replicated your result.

Namespaces are a good idea anyway, though other things being equal it 
would be nice not to require them.  For the moment, though, we do.

John


On 2/2/11 7:25 PM, Jeffrey Horner wrote:
> Hi,
>
> I'm trying to create a package that contains reference class
> definitions from which users can create reference objects, but there
> seems to be something awry.
>
> My toy example creates an empty package via
> package.skeleton('TestClass') to which I add the following R code:
>
> TestClass<- setRefClass('TestClass',fields=c('name'))
>
> Unfortunately my R console output bears this:
>
>> library(TestClass)
>> TestClass$new(name='foo')
> Error: attempt to apply non-function
>> getRefClass('TestClass')$new(name='foo')
> Error: attempt to apply non-function
>
> Creating the same reference class in the global environment works though:
>
>> x<- setRefClass('TestClass',fields='name')
>> x$new(name='foo')
> An object of class "TestClass"
> <environment: 0x82a43cc>
>
> I'm new to S4 and reference classes, so maybe I'm missing something fundamental?
>
> Jeff
>
>> sessionInfo()
> R version 2.13.0 Under development (unstable) (2011-02-02 r54197)
> Platform: i686-pc-linux-gnu (32-bit)
>
> locale:
>   [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>   [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>   [5] LC_MONETARY=C              LC_MESSAGES=en_US.UTF-8
>   [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>   [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices datasets  utils     methods   base
>
> other attached packages:
> [1] TestClass_1.0
>
> loaded via a namespace (and not attached):
> [1] tools_2.13.0
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From jmc at r-project.org  Fri Feb  4 01:48:58 2011
From: jmc at r-project.org (John Chambers)
Date: Thu, 03 Feb 2011 16:48:58 -0800
Subject: [Rd] Creating a reference class object from a class definition
 in a package fails
In-Reply-To: <AANLkTim_qkOYXkKU0J-FGCqGmHQX_Cqvd7LNNPhyFUQ4@mail.gmail.com>
References: <AANLkTimXJ+J+HPR_+tPAExFUAJ3_xmYKYzQXvpn5r8du@mail.gmail.com>
	<AANLkTim_qkOYXkKU0J-FGCqGmHQX_Cqvd7LNNPhyFUQ4@mail.gmail.com>
Message-ID: <4D4B4CFA.5060503@r-project.org>

Yes, as noted in my previous mail, which crossed yours.  If you included 
the TestClass  in a code_file= in the package skeleton, the default 
NAMESPACE file from package.skeleton() will do that for you:

exportPattern("^[[:alpha:]]+")
exportClasses(
     "TestClass"

It's certainly true that _if_ you have a namespace file, reference 
classes (and all other classes) and generator objects have to be 
exported to be used outside the package.  Still not quite clear, though, 
why _any_ namespace file is needed.

Thanks for the catch.

John


On 2/3/11 1:46 PM, Jeffrey Horner wrote:
> Apparently reference classes must be declared in the NAMESPACE file
> via an S4 declaration. If I place the following in the NAMESPACE file
> all is well:
>
> exportClasses(TestClass)
> export(TestClass)
>
>
> Jeff
>
> On Wed, Feb 2, 2011 at 9:25 PM, Jeffrey Horner<jeffrey.horner at gmail.com>  wrote:
>> Hi,
>>
>> I'm trying to create a package that contains reference class
>> definitions from which users can create reference objects, but there
>> seems to be something awry.
>>
>> My toy example creates an empty package via
>> package.skeleton('TestClass') to which I add the following R code:
>>
>> TestClass<- setRefClass('TestClass',fields=c('name'))
>>
>> Unfortunately my R console output bears this:
>>
>>> library(TestClass)
>>> TestClass$new(name='foo')
>> Error: attempt to apply non-function
>>> getRefClass('TestClass')$new(name='foo')
>> Error: attempt to apply non-function
>>
>> Creating the same reference class in the global environment works though:
>>
>>> x<- setRefClass('TestClass',fields='name')
>>> x$new(name='foo')
>> An object of class "TestClass"
>> <environment: 0x82a43cc>
>>
>> I'm new to S4 and reference classes, so maybe I'm missing something fundamental?
>>
>> Jeff
>>
>>> sessionInfo()
>> R version 2.13.0 Under development (unstable) (2011-02-02 r54197)
>> Platform: i686-pc-linux-gnu (32-bit)
>>
>> locale:
>>   [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>>   [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>>   [5] LC_MONETARY=C              LC_MESSAGES=en_US.UTF-8
>>   [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>>   [9] LC_ADDRESS=C               LC_TELEPHONE=C
>> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>>
>> attached base packages:
>> [1] stats     graphics  grDevices datasets  utils     methods   base
>>
>> other attached packages:
>> [1] TestClass_1.0
>>
>> loaded via a namespace (and not attached):
>> [1] tools_2.13.0
>>
>
>
>


From jeroenooms at gmail.com  Fri Feb  4 03:31:30 2011
From: jeroenooms at gmail.com (Jeroen Ooms)
Date: Thu, 3 Feb 2011 18:31:30 -0800 (PST)
Subject: [Rd] dependencies on system packages
Message-ID: <1296786690226-3259395.post@n4.nabble.com>


Many R packages depend on some unix libraries that are not part of most
default installations. I often spend a significant amount of time figuring
out where to get the appropriate libraries for compiling these packages,
after they give some vague error of something missing. I was wondering why
there is no formal system of specifying non-R dependencies in the
DESCRIPTION file. If this would be the case, then during the installation of
an R package, the user could be prompted to install required system packages
(if they have appropriate privileges).

So for example:

Package: XML
Version: 3.2-0
Depends: R (>= 1.2.0), methods, utils
Depends-debian: libxml2-dev
Depends-ubuntu: libxml2-dev
Depends-redhat: libxml2-devel
Depends-suse: libxml2-devel
etc. 

This might make life for many people just a little easier. If they are root
and the package is in their system repositories, than it will install
automatically. If not, at least they know for which package to look, or
request their sys admin to install.
-- 
View this message in context: http://r.789695.n4.nabble.com/dependencies-on-system-packages-tp3259395p3259395.html
Sent from the R devel mailing list archive at Nabble.com.


From simon.urbanek at r-project.org  Fri Feb  4 04:48:13 2011
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Thu, 3 Feb 2011 22:48:13 -0500
Subject: [Rd] dependencies on system packages
In-Reply-To: <1296786690226-3259395.post@n4.nabble.com>
References: <1296786690226-3259395.post@n4.nabble.com>
Message-ID: <189F3930-6DA0-4EF5-B419-CB5AAA5EF68B@r-project.org>

Jeroen,

On Feb 3, 2011, at 9:31 PM, Jeroen Ooms wrote:

> 
> Many R packages depend on some unix libraries that are not part of most
> default installations. I often spend a significant amount of time figuring
> out where to get the appropriate libraries for compiling these packages,
> after they give some vague error of something missing. I was wondering why
> there is no formal system of specifying non-R dependencies in the
> DESCRIPTION file. If this would be the case, then during the installation of
> an R package, the user could be prompted to install required system packages
> (if they have appropriate privileges).
> 
> So for example:
> 
> Package: XML
> Version: 3.2-0
> Depends: R (>= 1.2.0), methods, utils
> Depends-debian: libxml2-dev
> Depends-ubuntu: libxml2-dev
> Depends-redhat: libxml2-devel
> Depends-suse: libxml2-devel
> etc. 
> 
> This might make life for many people just a little easier. If they are root
> and the package is in their system repositories, than it will install
> automatically. If not, at least they know for which package to look, or
> request their sys admin to install.

Well, there is already such system in place and it is the corresponding descriptions in the distributions. Obviously as an author of the package I don't care what any particular Linux distribution uses as a name for the needed dependencies as the corresponding chaos is distribution-specific. The only person who can reasonably determine the dependencies is the maintainer of the distribution and that's what they do and as a user of the above mentioned distributions you should be thankful to them. Fortunately, normal users don't have to worry about it as major distributions already come with a large set of R packages resolving all dependencies. Hence I don't see any reason why this should have anything to do with the DESCRIPTION file. The improvements I could think of would be a parseable entry or a canonical pointer to dependency sources, but that's a whole another story.

Cheers,
Simon


From cbeleites at units.it  Fri Feb  4 09:18:00 2011
From: cbeleites at units.it (Claudia Beleites)
Date: Fri, 04 Feb 2011 09:18:00 +0100
Subject: [Rd] dependencies on system packages
In-Reply-To: <189F3930-6DA0-4EF5-B419-CB5AAA5EF68B@r-project.org>
References: <1296786690226-3259395.post@n4.nabble.com>
	<189F3930-6DA0-4EF5-B419-CB5AAA5EF68B@r-project.org>
Message-ID: <4D4BB638.8030409@units.it>

Dear all,

 From the writing extensions manual:
"Other dependencies (external to the R system) should be listed in the 
?SystemRequirements? field, possibly amplified in a separate README file."

I guess one problem is the user may not realize that the -dev version is 
needed, and just sees libxml2 installed but the R package installation 
stopping with the respective error.

Giving the package name for specific distributions is of course polite 
(if the developer knows it). As developer you may also put into the 
README that the package's mailing list/forum/wiki/... contains 
information and ask the user to enter the package name on his distro if 
it is not already there.


my 2 ct

Claudia



Am 04.02.2011 04:48, schrieb Simon Urbanek:
> Jeroen,
>
> On Feb 3, 2011, at 9:31 PM, Jeroen Ooms wrote:
>
>>
>> Many R packages depend on some unix libraries that are not part of most
>> default installations. I often spend a significant amount of time figuring
>> out where to get the appropriate libraries for compiling these packages,
>> after they give some vague error of something missing. I was wondering why
>> there is no formal system of specifying non-R dependencies in the
>> DESCRIPTION file. If this would be the case, then during the installation of
>> an R package, the user could be prompted to install required system packages
>> (if they have appropriate privileges).
>>
>> So for example:
>>
>> Package: XML
>> Version: 3.2-0
>> Depends: R (>= 1.2.0), methods, utils
>> Depends-debian: libxml2-dev
>> Depends-ubuntu: libxml2-dev
>> Depends-redhat: libxml2-devel
>> Depends-suse: libxml2-devel
>> etc.
>>
>> This might make life for many people just a little easier. If they are root
>> and the package is in their system repositories, than it will install
>> automatically. If not, at least they know for which package to look, or
>> request their sys admin to install.
>
> Well, there is already such system in place and it is the corresponding descriptions in the distributions. Obviously as an author of the package I don't care what any particular Linux distribution uses as a name for the needed dependencies as the corresponding chaos is distribution-specific. The only person who can reasonably determine the dependencies is the maintainer of the distribution and that's what they do and as a user of the above mentioned distributions you should be thankful to them. Fortunately, normal users don't have to worry about it as major distributions already come with a large set of R packages resolving all dependencies. Hence I don't see any reason why this should have anything to do with the DESCRIPTION file. The improvements I could think of would be a parseable entry or a canonical pointer to dependency sources, but that's a whole another story.
>
> Cheers,
> Simon
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From cruckert at uni-muenster.de  Fri Feb  4 11:35:33 2011
From: cruckert at uni-muenster.de (Christian Ruckert)
Date: Fri, 04 Feb 2011 11:35:33 +0100
Subject: [Rd] Strange behaviour of read and writeBin
Message-ID: <4D4BD675.9060206@uni-muenster.de>

To me it seems like writeBin() writes one char/byte more than expected.

 > con <- file("testbin", "wb")
 > writeBin("ttccggaa", con)
 > close(con)

 > con <- file("testbin", "rb")
 > readBin(con, what="character")
[1] "ttccggaa"
 > seek(con, what=NA)
[1] 9
 > close(con)

 > con <- file("testbin", "rb")
 > readBin(con, what="raw", n=20)
[1] 74 74 63 63 67 67 61 61 00
 > seek(con, what=NA)
[1] 9
 > close(con)

As the numbering starts with 0 the position should be 8 and not 9 after 
reading. There were two older threads which look very similar to my problem:

http://tolstoy.newcastle.edu.au/R/e2/devel/06/11/1119.html
http://r.789695.n4.nabble.com/Re-Problem-reading-binaries-created-with-fortran-More-infos-td974396.html

Thanks in advance,
Christian



 > sessionInfo()
R version 2.12.0 (2010-10-15)
Platform: x86_64-pc-linux-gnu (64-bit)

locale:
[1] C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] Biostrings_2.18.2 IRanges_1.8.8

loaded via a namespace (and not attached):
[1] Biobase_2.10.0


From jeff.a.ryan at gmail.com  Fri Feb  4 14:12:41 2011
From: jeff.a.ryan at gmail.com (Jeff Ryan)
Date: Fri, 4 Feb 2011 07:12:41 -0600
Subject: [Rd] Strange behaviour of read and writeBin
In-Reply-To: <4D4BD675.9060206@uni-muenster.de>
References: <4D4BD675.9060206@uni-muenster.de>
Message-ID: <AANLkTi=tVkRvexQC+j5jBoTARWGEdCitwXXM0qcQD3w2@mail.gmail.com>

from ?seek

?seek? returns the current position (before any move), as a
     (numeric) byte offset from the origin, if relevant, or ?0? if not.

Your string is nul terminated (9 bytes long).  That would be the
current offset. If you only read one byte, you'd have to be more than
0 bytes offset.

Jeff

On Fri, Feb 4, 2011 at 4:35 AM, Christian Ruckert
<cruckert at uni-muenster.de> wrote:
> To me it seems like writeBin() writes one char/byte more than expected.
>
>> con <- file("testbin", "wb")
>> writeBin("ttccggaa", con)
>> close(con)
>
>> con <- file("testbin", "rb")
>> readBin(con, what="character")
> [1] "ttccggaa"
>> seek(con, what=NA)
> [1] 9
>> close(con)
>
>> con <- file("testbin", "rb")
>> readBin(con, what="raw", n=20)
> [1] 74 74 63 63 67 67 61 61 00
>> seek(con, what=NA)
> [1] 9
>> close(con)
>
> As the numbering starts with 0 the position should be 8 and not 9 after
> reading. There were two older threads which look very similar to my problem:
>
> http://tolstoy.newcastle.edu.au/R/e2/devel/06/11/1119.html
> http://r.789695.n4.nabble.com/Re-Problem-reading-binaries-created-with-fortran-More-infos-td974396.html
>
> Thanks in advance,
> Christian
>
>
>
>> sessionInfo()
> R version 2.12.0 (2010-10-15)
> Platform: x86_64-pc-linux-gnu (64-bit)
>
> locale:
> [1] C
>
> attached base packages:
> [1] stats ? ? graphics ?grDevices utils ? ? datasets ?methods ? base
>
> other attached packages:
> [1] Biostrings_2.18.2 IRanges_1.8.8
>
> loaded via a namespace (and not attached):
> [1] Biobase_2.10.0
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>



-- 
Jeffrey Ryan
jeffrey.ryan at lemnica.com

www.lemnica.com


From murdoch.duncan at gmail.com  Fri Feb  4 14:52:32 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 04 Feb 2011 08:52:32 -0500
Subject: [Rd] Strange behaviour of read and writeBin
In-Reply-To: <4D4BD675.9060206@uni-muenster.de>
References: <4D4BD675.9060206@uni-muenster.de>
Message-ID: <4D4C04A0.5050203@gmail.com>

On 04/02/2011 5:35 AM, Christian Ruckert wrote:
> To me it seems like writeBin() writes one char/byte more than expected.

You want writeChar rather than writeBin to avoid the null termination of 
strings.

Duncan Murdoch

>   >  con<- file("testbin", "wb")
>   >  writeBin("ttccggaa", con)
>   >  close(con)
>
>   >  con<- file("testbin", "rb")
>   >  readBin(con, what="character")
> [1] "ttccggaa"
>   >  seek(con, what=NA)
> [1] 9
>   >  close(con)
>
>   >  con<- file("testbin", "rb")
>   >  readBin(con, what="raw", n=20)
> [1] 74 74 63 63 67 67 61 61 00
>   >  seek(con, what=NA)
> [1] 9
>   >  close(con)
>
> As the numbering starts with 0 the position should be 8 and not 9 after
> reading. There were two older threads which look very similar to my problem:
>
> http://tolstoy.newcastle.edu.au/R/e2/devel/06/11/1119.html
> http://r.789695.n4.nabble.com/Re-Problem-reading-binaries-created-with-fortran-More-infos-td974396.html
>
> Thanks in advance,
> Christian
>
>
>
>   >  sessionInfo()
> R version 2.12.0 (2010-10-15)
> Platform: x86_64-pc-linux-gnu (64-bit)
>
> locale:
> [1] C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] Biostrings_2.18.2 IRanges_1.8.8
>
> loaded via a namespace (and not attached):
> [1] Biobase_2.10.0
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From murdoch.duncan at gmail.com  Fri Feb  4 14:56:31 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 04 Feb 2011 08:56:31 -0500
Subject: [Rd] keep.source when semicolons separate statements on the one
 line
In-Reply-To: <48B94A4D-DB81-4912-850B-CDB2D7711968@anu.edu.au>
References: <48B94A4D-DB81-4912-850B-CDB2D7711968@anu.edu.au>
Message-ID: <4D4C058F.1050304@gmail.com>

Thanks for the report.  I'll take a look.

I'm now past one major time sink, and will have some time to catch up on 
old problems; I'll add this to that list.

Duncan Murdoch

On 03/02/2011 7:09 PM, John Maindonald wrote:
> The following is 'semicolon.Rnw'
>
> >  \SweaveOpts{engine=R, keep.source=TRUE}
> >
> >  <<xycig-A, eval=f, echo=f>>=
> >  library(SMIR); data(bronchit); library(KernSmooth)
> >  @ %
> >
> >  Code for panel A is
> >  <<code-xycig-A, eval=f, echo=t>>=
> >  <<xycig-A>>
> >  @ %
>
> Sweave("semicolon") yields the following 'semicolon.tex'
>
> >  Code for panel A is
> >  \begin{Schunk}
> >  \begin{Sinput}
> >>  library(SMIR); data(bronchit); library(KernSmooth)
> >>  library(SMIR); data(bronchit); library(KernSmooth)
> >>  library(SMIR); data(bronchit); library(KernSmooth)
> >  \end{Sinput}
> >  \end{Schunk}
>
> (I have omitted three blank lines at the start)
>
> With keep.source=FALSE, the commands are split onto
> separate lines, and there is no repetition.
>
> John Maindonald             email: john.maindonald at anu.edu.au
> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
> Centre for Mathematics&  Its Applications, Room 1194,
> John Dedman Mathematical Sciences Building (Building 27)
> Australian National University, Canberra ACT 0200.
> http://www.maths.anu.edu.au/~johnm
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From simon.urbanek at r-project.org  Fri Feb  4 16:01:28 2011
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Fri, 4 Feb 2011 10:01:28 -0500
Subject: [Rd] dependencies on system packages
In-Reply-To: <4D4BB638.8030409@units.it>
References: <1296786690226-3259395.post@n4.nabble.com>
	<189F3930-6DA0-4EF5-B419-CB5AAA5EF68B@r-project.org>
	<4D4BB638.8030409@units.it>
Message-ID: <EDBA419B-0DEF-4B3F-B2AE-29303D89999C@r-project.org>

Claudia,

thanks for you comments .

On Feb 4, 2011, at 3:18 AM, Claudia Beleites wrote:

> Dear all,
> 
> From the writing extensions manual:
> "Other dependencies (external to the R system) should be listed in the ?SystemRequirements? field, possibly amplified in a separate README file."
> 
> I guess one problem is the user may not realize that the -dev version is needed, and just sees libxml2 installed but the R package installation stopping with the respective error.
> 

I'd argue that if a user attempts to install a package from sources instead of using the distribution binaries, he should know what he's doing as there is much more involved (proper tools, usually a different library location etc.). And anyone who knows what he's doing also knows that -dev packages are needed (at the latest when the installation fails you remember ;)). If he doesn't then it should give him a clue that he may want to use something else (and especially Linux users should know better ;)).

Clearly, it doesn't prevent users from doing stupid things and I completely agree with you that the README should have the instructions as far as the developer knows. And as a package developer you'll learn soon enough when people start complaining ;).

Thanks,
Simon



> Giving the package name for specific distributions is of course polite (if the developer knows it). As developer you may also put into the README that the package's mailing list/forum/wiki/... contains information and ask the user to enter the package name on his distro if it is not already there.
> 
> 
> my 2 ct
> 
> Claudia
> 
> 
> 
> Am 04.02.2011 04:48, schrieb Simon Urbanek:
>> Jeroen,
>> 
>> On Feb 3, 2011, at 9:31 PM, Jeroen Ooms wrote:
>> 
>>> 
>>> Many R packages depend on some unix libraries that are not part of most
>>> default installations. I often spend a significant amount of time figuring
>>> out where to get the appropriate libraries for compiling these packages,
>>> after they give some vague error of something missing. I was wondering why
>>> there is no formal system of specifying non-R dependencies in the
>>> DESCRIPTION file. If this would be the case, then during the installation of
>>> an R package, the user could be prompted to install required system packages
>>> (if they have appropriate privileges).
>>> 
>>> So for example:
>>> 
>>> Package: XML
>>> Version: 3.2-0
>>> Depends: R (>= 1.2.0), methods, utils
>>> Depends-debian: libxml2-dev
>>> Depends-ubuntu: libxml2-dev
>>> Depends-redhat: libxml2-devel
>>> Depends-suse: libxml2-devel
>>> etc.
>>> 
>>> This might make life for many people just a little easier. If they are root
>>> and the package is in their system repositories, than it will install
>>> automatically. If not, at least they know for which package to look, or
>>> request their sys admin to install.
>> 
>> Well, there is already such system in place and it is the corresponding descriptions in the distributions. Obviously as an author of the package I don't care what any particular Linux distribution uses as a name for the needed dependencies as the corresponding chaos is distribution-specific. The only person who can reasonably determine the dependencies is the maintainer of the distribution and that's what they do and as a user of the above mentioned distributions you should be thankful to them. Fortunately, normal users don't have to worry about it as major distributions already come with a large set of R packages resolving all dependencies. Hence I don't see any reason why this should have anything to do with the DESCRIPTION file. The improvements I could think of would be a parseable entry or a canonical pointer to dependency sources, but that's a whole another story.
>> 
>> Cheers,
>> Simon
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From jorismeys at gmail.com  Fri Feb  4 16:21:55 2011
From: jorismeys at gmail.com (Joris Meys)
Date: Fri, 4 Feb 2011 16:21:55 +0100
Subject: [Rd] terribly annoying bug with POSIXlt : one o'clock is midnight?
Message-ID: <AANLkTi=sY4fzwZ1SBSnW540FXPMEay3rAciv_u2M5hvm@mail.gmail.com>

Apparently, as.POSIXlt takes one o'clock as the start of the day :

> as.POSIXlt(0,origin="1970-01-01")
[1] "1970-01-01 01:00:00 CET"
> as.POSIXlt(0,origin="1970-01-01 00:00:00")
[1] "1970-01-01 01:00:00 CET"
> as.POSIXlt(0,origin="1970-01-01 23:59:59")
[1] "1970-01-02 00:59:59 CET"

Cheers



-- 
Joris Meys
Statistical consultant

Ghent University
Faculty of Bioscience Engineering
Department of Applied mathematics, biometrics and process control

tel : +32 9 264 59 87
Joris.Meys at Ugent.be
-------------------------------
Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php


From jorismeys at gmail.com  Fri Feb  4 16:24:53 2011
From: jorismeys at gmail.com (Joris Meys)
Date: Fri, 4 Feb 2011 16:24:53 +0100
Subject: [Rd] terribly annoying bug with POSIXlt : one o'clock is
	midnight?
In-Reply-To: <AANLkTi=sY4fzwZ1SBSnW540FXPMEay3rAciv_u2M5hvm@mail.gmail.com>
References: <AANLkTi=sY4fzwZ1SBSnW540FXPMEay3rAciv_u2M5hvm@mail.gmail.com>
Message-ID: <AANLkTikWBmT252xYxSs7XH4mnDSujnsZ0W5kCtx0yZYa@mail.gmail.com>

Been too fast : I am in Central European Time (GMT +1), which explains
the time conversion. Still, I find it highly annoying that as.POSIXlt
assumes that the time is given in GMT and has to be converted to
whatever timezone you're in if you don't specify anything.

Probably this behaviour is not going to be changed, but it's causing
very hard-to-track-down bugs nonetheless.

Cheers
Joris

On Fri, Feb 4, 2011 at 4:21 PM, Joris Meys <jorismeys at gmail.com> wrote:
> Apparently, as.POSIXlt takes one o'clock as the start of the day :
>
>> as.POSIXlt(0,origin="1970-01-01")
> [1] "1970-01-01 01:00:00 CET"
>> as.POSIXlt(0,origin="1970-01-01 00:00:00")
> [1] "1970-01-01 01:00:00 CET"
>> as.POSIXlt(0,origin="1970-01-01 23:59:59")
> [1] "1970-01-02 00:59:59 CET"
>
> Cheers
>
>
>
> --
> Joris Meys
> Statistical consultant
>
> Ghent University
> Faculty of Bioscience Engineering
> Department of Applied mathematics, biometrics and process control
>
> tel : +32 9 264 59 87
> Joris.Meys at Ugent.be
> -------------------------------
> Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php
>



-- 
Joris Meys
Statistical consultant

Ghent University
Faculty of Bioscience Engineering
Department of Applied mathematics, biometrics and process control

tel : +32 9 264 59 87
Joris.Meys at Ugent.be
-------------------------------
Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php


From gavin.simpson at ucl.ac.uk  Fri Feb  4 16:28:42 2011
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Fri, 04 Feb 2011 15:28:42 +0000
Subject: [Rd] terribly annoying bug with POSIXlt : one o'clock is
 midnight?
In-Reply-To: <AANLkTi=sY4fzwZ1SBSnW540FXPMEay3rAciv_u2M5hvm@mail.gmail.com>
References: <AANLkTi=sY4fzwZ1SBSnW540FXPMEay3rAciv_u2M5hvm@mail.gmail.com>
Message-ID: <1296833322.2445.28.camel@desktop.localdomain>

On Fri, 2011-02-04 at 16:21 +0100, Joris Meys wrote:
> Apparently, as.POSIXlt takes one o'clock as the start of the day :
> 
> > as.POSIXlt(0,origin="1970-01-01")
> [1] "1970-01-01 01:00:00 CET"
> > as.POSIXlt(0,origin="1970-01-01 00:00:00")
> [1] "1970-01-01 01:00:00 CET"
> > as.POSIXlt(0,origin="1970-01-01 23:59:59")
> [1] "1970-01-02 00:59:59 CET"
> 
> Cheers

Isn't this just a timezone thing? CET is an hour ahead of UTC (GMT)

> as.POSIXlt(0,origin="1970-01-01")
[1] "1970-01-01 01:00:00 BST"
> as.POSIXlt(0,origin="1970-01-01", tz = "GMT")
[1] "1970-01-01 GMT"
> as.POSIXlt(0,origin="1970-01-01 00:00:00")
[1] "1970-01-01 01:00:00 BST"
> as.POSIXlt(0,origin="1970-01-01 00:00:00", tz = "GMT")
[1] "1970-01-01 GMT"
> as.POSIXlt(0,origin="1970-01-01 23:59:59", tz = "GMT")
[1] "1970-01-01 23:59:59 GMT"

G
-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
 Dr. Gavin Simpson             [t] +44 (0)20 7679 0522
 ECRC, UCL Geography,          [f] +44 (0)20 7679 0565
 Pearson Building,             [e] gavin.simpsonATNOSPAMucl.ac.uk
 Gower Street, London          [w] http://www.ucl.ac.uk/~ucfagls/
 UK. WC1E 6BT.                 [w] http://www.freshwaters.org.uk
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%


From jeff.a.ryan at gmail.com  Fri Feb  4 16:29:35 2011
From: jeff.a.ryan at gmail.com (Jeff Ryan)
Date: Fri, 4 Feb 2011 09:29:35 -0600
Subject: [Rd] terribly annoying bug with POSIXlt : one o'clock is
	midnight?
In-Reply-To: <AANLkTikWBmT252xYxSs7XH4mnDSujnsZ0W5kCtx0yZYa@mail.gmail.com>
References: <AANLkTi=sY4fzwZ1SBSnW540FXPMEay3rAciv_u2M5hvm@mail.gmail.com>
	<AANLkTikWBmT252xYxSs7XH4mnDSujnsZ0W5kCtx0yZYa@mail.gmail.com>
Message-ID: <AANLkTinVA9uYb=BV7MTr=apKfPWUyK2bNxb1eHVGSTAH@mail.gmail.com>

Much of TZ-hell (I almost dare say all) has been sorted through in xts.

  http://cran.r-project.org/web/packages/xts/index.html

Peruse the sources for inspiration or just take some comfort in that
you are not the only one ;-)

Jeff

On Fri, Feb 4, 2011 at 9:24 AM, Joris Meys <jorismeys at gmail.com> wrote:
> Been too fast : I am in Central European Time (GMT +1), which explains
> the time conversion. Still, I find it highly annoying that as.POSIXlt
> assumes that the time is given in GMT and has to be converted to
> whatever timezone you're in if you don't specify anything.
>
> Probably this behaviour is not going to be changed, but it's causing
> very hard-to-track-down bugs nonetheless.
>
> Cheers
> Joris
>
> On Fri, Feb 4, 2011 at 4:21 PM, Joris Meys <jorismeys at gmail.com> wrote:
>> Apparently, as.POSIXlt takes one o'clock as the start of the day :
>>
>>> as.POSIXlt(0,origin="1970-01-01")
>> [1] "1970-01-01 01:00:00 CET"
>>> as.POSIXlt(0,origin="1970-01-01 00:00:00")
>> [1] "1970-01-01 01:00:00 CET"
>>> as.POSIXlt(0,origin="1970-01-01 23:59:59")
>> [1] "1970-01-02 00:59:59 CET"
>>
>> Cheers
>>
>>
>>
>> --
>> Joris Meys
>> Statistical consultant
>>
>> Ghent University
>> Faculty of Bioscience Engineering
>> Department of Applied mathematics, biometrics and process control
>>
>> tel : +32 9 264 59 87
>> Joris.Meys at Ugent.be
>> -------------------------------
>> Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php
>>
>
>
>
> --
> Joris Meys
> Statistical consultant
>
> Ghent University
> Faculty of Bioscience Engineering
> Department of Applied mathematics, biometrics and process control
>
> tel : +32 9 264 59 87
> Joris.Meys at Ugent.be
> -------------------------------
> Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>



-- 
Jeffrey Ryan
jeffrey.ryan at lemnica.com

www.lemnica.com


From bbolker at gmail.com  Fri Feb  4 16:44:12 2011
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 04 Feb 2011 10:44:12 -0500
Subject: [Rd] axTicks.Rd documentation bug
Message-ID: <4D4C1ECC.2090504@mcmaster.ca>


?axTicks says:

    usr: numeric vector of length four, defaulting to ?par("usr")?
          giving horizontal (?x?) and vertical (?y?) user coordinate
          limits.

 but this is not how the function is implemented -- in fact 'usr' should
be a vector of length two corresponding to the appropriate elements of
par("usr") [1:2 if side is 1 or 3, 3:4 if side is 2 or 4].

  A patch for src/library/graphics/man/axTicks.Rd against the latest SVN
is attached (I hope it makes it through).

  I also included an extended example of how to use axTicks without
reference to an existing plot in the logarithmic axis case: it took me
quite a bit of digging in documentation and source code to figure out
how to do this for myself, so I think it would be useful to others ...

   Ben Bolker


-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: axTicks_patch.txt
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110204/067c126d/attachment.txt>

From bbolker at gmail.com  Fri Feb  4 17:16:36 2011
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 4 Feb 2011 11:16:36 -0500
Subject: [Rd] read.csv trap
Message-ID: <4D4C2664.6030403@gmail.com>

  This is not specifically a bug, but an (implicitly/obscurely)
documented behavior of read.csv (or read.table with fill=TRUE) that can
be quite dangerous/confusing for users.  I would love to hear some
discussion from other users and/or R-core about this ...  As always, I
apologize if I have missed some obvious workaround or reason that this
is actually the desired behavior ...

  In a nutshell, when fill=TRUE R guesses the number of columns from the
first 5 rows of the data set.  That's fine, and ?read.table documents this:

   The number of data columns is determined by looking at the first
     five lines of input (or the whole file if it has less than five
     lines), or from the length of ?col.names? if it is specified and
     is longer.  This could conceivably be wrong if ?fill? or
     ?blank.lines.skip? are true, so specify ?col.names? if necessary.

What is dangerous/confusing is that R silently **wraps** longer lines if
fill=TRUE (which is the default for read.csv).  I encountered this when
working with a colleague on a long, messy CSV file that had some phantom
extra fields in some rows, which then turned into empty lines in the
data frame.

  Here is an example and a workaround that runs count.fields on the
whole file to find the maximum column length and set col.names
accordingly.  (It assumes you don't already have a file named "test.csv"
in your working directory ...)

  I haven't dug in to try to write a patch for this -- I wanted to test
the waters and see what people thought first, and I realize that
read.table() is a very complicated piece of code that embodies a lot of
tradeoffs, so there could be lots of different approaches to trying to
mitigate this problem. I appreciate very much how hard it is to write a
robust and general function to read data files, but I also think it's
really important to minimize the number of traps in read.table(), which
will often be the first part of R that new users encounter ...

  A quick fix for this might be to allow the number of lines analyzed
for length to be settable by the user, or to allow a settable 'maxcols'
parameter, although those would only help in the case where the user
already knows there is a problem.

  cheers
    Ben Bolker

===============
writeLines(c("A,B,C,D",
             "1,a,b,c",
             "2,f,g,c",
             "3,a,i,j",
             "4,a,b,c",
             "5,d,e,f",
             "6,g,h,i,j,k,l,m,n"),
           con=file("test.csv"))


read.csv("test.csv")
try(read.csv("test.csv",fill=FALSE))

## assumes header=TRUE, fill=TRUE; should be a little more careful
##  with comment, quote arguments (possibly explicit)
## ... contains information about quote, comment.char, sep
Read.csv <- function(fn,sep=",",...) {
  colnames <- scan(fn,nlines=1,what="character",sep=sep,...)
  ncolnames <- length(colnames)
  maxcols <- max(count.fields(fn,sep=sep,...))
  if (maxcols>ncolnames) {
    colnames <- c(colnames,paste("V",(ncolnames+1):maxcols,sep=""))
  }
  ## assumes you don't have any other columns labeled "V[large number]"
  read.csv(fn,...,col.names=colnames)
}

Read.csv("test.csv")


From edd at debian.org  Fri Feb  4 19:24:16 2011
From: edd at debian.org (Dirk Eddelbuettel)
Date: Fri, 4 Feb 2011 12:24:16 -0600
Subject: [Rd] dependencies on system packages
In-Reply-To: <EDBA419B-0DEF-4B3F-B2AE-29303D89999C@r-project.org>
References: <1296786690226-3259395.post@n4.nabble.com>
	<189F3930-6DA0-4EF5-B419-CB5AAA5EF68B@r-project.org>
	<4D4BB638.8030409@units.it>
	<EDBA419B-0DEF-4B3F-B2AE-29303D89999C@r-project.org>
Message-ID: <19788.17488.126990.458044@max.nulle.part>


Simon,

On 4 February 2011 at 10:01, Simon Urbanek wrote:
| Claudia,
| 
| thanks for you comments .
| 
| On Feb 4, 2011, at 3:18 AM, Claudia Beleites wrote:
| 
| > Dear all,
| > 
| > From the writing extensions manual:
| > "Other dependencies (external to the R system) should be listed in the ?SystemRequirements? field, possibly amplified in a separate README file."
| > 
| > I guess one problem is the user may not realize that the -dev version is needed, and just sees libxml2 installed but the R package installation stopping with the respective error.
| > 
| 
| I'd argue that if a user attempts to install a package from sources instead
| of using the distribution binaries, he should know what he's doing as there
| is much more involved (proper tools, usually a different library location
| etc.). And anyone who knows what he's doing also knows that -dev packages
| are needed (at the latest when the installation fails you remember ;)). If
| he doesn't then it should give him a clue that he may want to use something
| else (and especially Linux users should know better ;)). 
| 
| Clearly, it doesn't prevent users from doing stupid things and I completely
| agree with you that the README should have the instructions as far as the
| developer knows. And as a package developer you'll learn soon enough when
| people start complaining ;).

I respectfully disagree.

Based on a number of years of supporting users on Linux where people install
frequently from source, I can assure you that a rather large number of people
fails.  Not everybody is fluent with compilers, knows about libraries and
their interdependencies, or can even read configure error messages. We all
see the r-help messages (or the traffic on the SIG lists).

People want to use the wealth of software that is CRAN, and we should help
them.  I have also been involved in by now two attempts to overcome this in
an automated fashion via cran2deb.  We had that working somewhat reliably
until parts of the infrastructure misteriously self-destructed (a large
sqlite table) right when I visited Vienna, and are now in a rewrite which may
be never ending (for lack of resources).  There was a lot of interest for it
when it worked, and there is ongoing interest right now (as a few guys from
across Europe just met last weekend to try to use for BioC builds).

There were also folks from other distros who tried something similar. What
Jeroen suggested is along those lines with the needed meta-data. Whether we
make it per-package (as per Jeroen's idea) or 'per-repo-distro-pair' (which
is what cran2deb does) is a detail.  

We need to address this: With 2600+ packages and continued growth, manually
wading through README is not good enough.  We should do better.  Resources
(time, money, servers, ...) would help.  Maybe one day someone with more time
can fold this into a proper sub-project of a larger grant application.  It
would be worth, and I would try to help, time permitting.

Cheers, Dirk

| 
| Thanks,
| Simon
| 
| 
| 
| > Giving the package name for specific distributions is of course polite (if the developer knows it). As developer you may also put into the README that the package's mailing list/forum/wiki/... contains information and ask the user to enter the package name on his distro if it is not already there.
| > 
| > 
| > my 2 ct
| > 
| > Claudia
| > 
| > 
| > 
| > Am 04.02.2011 04:48, schrieb Simon Urbanek:
| >> Jeroen,
| >> 
| >> On Feb 3, 2011, at 9:31 PM, Jeroen Ooms wrote:
| >> 
| >>> 
| >>> Many R packages depend on some unix libraries that are not part of most
| >>> default installations. I often spend a significant amount of time figuring
| >>> out where to get the appropriate libraries for compiling these packages,
| >>> after they give some vague error of something missing. I was wondering why
| >>> there is no formal system of specifying non-R dependencies in the
| >>> DESCRIPTION file. If this would be the case, then during the installation of
| >>> an R package, the user could be prompted to install required system packages
| >>> (if they have appropriate privileges).
| >>> 
| >>> So for example:
| >>> 
| >>> Package: XML
| >>> Version: 3.2-0
| >>> Depends: R (>= 1.2.0), methods, utils
| >>> Depends-debian: libxml2-dev
| >>> Depends-ubuntu: libxml2-dev
| >>> Depends-redhat: libxml2-devel
| >>> Depends-suse: libxml2-devel
| >>> etc.
| >>> 
| >>> This might make life for many people just a little easier. If they are root
| >>> and the package is in their system repositories, than it will install
| >>> automatically. If not, at least they know for which package to look, or
| >>> request their sys admin to install.
| >> 
| >> Well, there is already such system in place and it is the corresponding descriptions in the distributions. Obviously as an author of the package I don't care what any particular Linux distribution uses as a name for the needed dependencies as the corresponding chaos is distribution-specific. The only person who can reasonably determine the dependencies is the maintainer of the distribution and that's what they do and as a user of the above mentioned distributions you should be thankful to them. Fortunately, normal users don't have to worry about it as major distributions already come with a large set of R packages resolving all dependencies. Hence I don't see any reason why this should have anything to do with the DESCRIPTION file. The improvements I could think of would be a parseable entry or a canonical pointer to dependency sources, but that's a whole another story.
| >> 
| >> Cheers,
| >> Simon
| >> 
| >> ______________________________________________
| >> R-devel at r-project.org mailing list
| >> https://stat.ethz.ch/mailman/listinfo/r-devel
| > 
| > ______________________________________________
| > R-devel at r-project.org mailing list
| > https://stat.ethz.ch/mailman/listinfo/r-devel
| > 
| > 
| 
| ______________________________________________
| R-devel at r-project.org mailing list
| https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com


From Ken.Williams at thomsonreuters.com  Fri Feb  4 19:58:17 2011
From: Ken.Williams at thomsonreuters.com (Ken.Williams at thomsonreuters.com)
Date: Fri, 4 Feb 2011 12:58:17 -0600
Subject: [Rd] dependencies on system packages
In-Reply-To: <EDBA419B-0DEF-4B3F-B2AE-29303D89999C@r-project.org>
Message-ID: <C971A7B2.233DC%ken.williams@thomsonreuters.com>






On 2/4/11 9:01 AM, "Simon Urbanek" <simon.urbanek at r-project.org> wrote:

>I'd argue that if a user attempts to install a package from sources
>instead of using the distribution binaries, he should know what he's
>doing as there is much more involved (proper tools, usually a different
>library location etc.).


Most of the time when I build an existing package from source, it's
because I'm doing The Open Source Thing, either trying to fix some bug or
add some new feature.  One should only need to be a competent writer of R
code to do that, but often the mechanics of building the package get in
the way.


--
Ken Williams
Senior Research Scientist
Thomson Reuters
http://labs.thomsonreuters.com


From simon.urbanek at r-project.org  Fri Feb  4 20:29:59 2011
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Fri, 4 Feb 2011 14:29:59 -0500
Subject: [Rd] dependencies on system packages
In-Reply-To: <19788.17488.126990.458044@max.nulle.part>
References: <1296786690226-3259395.post@n4.nabble.com>
	<189F3930-6DA0-4EF5-B419-CB5AAA5EF68B@r-project.org>
	<4D4BB638.8030409@units.it>
	<EDBA419B-0DEF-4B3F-B2AE-29303D89999C@r-project.org>
	<19788.17488.126990.458044@max.nulle.part>
Message-ID: <073563D8-365F-45B8-8DFD-6B521968B8E6@r-project.org>


On Feb 4, 2011, at 1:24 PM, Dirk Eddelbuettel wrote:

> 
> Simon,
> 
> On 4 February 2011 at 10:01, Simon Urbanek wrote:
> | Claudia,
> | 
> | thanks for you comments .
> | 
> | On Feb 4, 2011, at 3:18 AM, Claudia Beleites wrote:
> | 
> | > Dear all,
> | > 
> | > From the writing extensions manual:
> | > "Other dependencies (external to the R system) should be listed in the ?SystemRequirements? field, possibly amplified in a separate README file."
> | > 
> | > I guess one problem is the user may not realize that the -dev version is needed, and just sees libxml2 installed but the R package installation stopping with the respective error.
> | > 
> | 
> | I'd argue that if a user attempts to install a package from sources instead
> | of using the distribution binaries, he should know what he's doing as there
> | is much more involved (proper tools, usually a different library location
> | etc.). And anyone who knows what he's doing also knows that -dev packages
> | are needed (at the latest when the installation fails you remember ;)). If
> | he doesn't then it should give him a clue that he may want to use something
> | else (and especially Linux users should know better ;)). 
> | 
> | Clearly, it doesn't prevent users from doing stupid things and I completely
> | agree with you that the README should have the instructions as far as the
> | developer knows. And as a package developer you'll learn soon enough when
> | people start complaining ;).
> 
> I respectfully disagree.
> 
> Based on a number of years of supporting users on Linux where people install
> frequently from source, I can assure you that a rather large number of people
> fails.  Not everybody is fluent with compilers, knows about libraries and
> their interdependencies, or can even read configure error messages. We all
> see the r-help messages (or the traffic on the SIG lists).
> 
> People want to use the wealth of software that is CRAN, and we should help
> them.  I have also been involved in by now two attempts to overcome this in
> an automated fashion via cran2deb.  We had that working somewhat reliably
> until parts of the infrastructure misteriously self-destructed (a large
> sqlite table) right when I visited Vienna, and are now in a rewrite which may
> be never ending (for lack of resources).  There was a lot of interest for it
> when it worked, and there is ongoing interest right now (as a few guys from
> across Europe just met last weekend to try to use for BioC builds).
> 
> There were also folks from other distros who tried something similar. What
> Jeroen suggested is along those lines with the needed meta-data. Whether we
> make it per-package (as per Jeroen's idea) or 'per-repo-distro-pair' (which
> is what cran2deb does) is a detail.  
> 
> We need to address this: With 2600+ packages and continued growth, manually
> wading through README is not good enough.  We should do better.  Resources
> (time, money, servers, ...) would help.  Maybe one day someone with more time
> can fold this into a proper sub-project of a larger grant application.  It
> would be worth, and I would try to help, time permitting.
> 

Well, as far as I can see you're only agreeing with me :). I said people like you are solving the issues by creating the corresponding distro-specific description and people should be thankful for that. Also I said that the distro-specific way is the only reliable way as package authors cannot know the intricacies of the distros involved. If the distros could share a system that helps to maintain this, it would be perfect - by all mean supported by us if we can, but it's separate from the package authors. And, finally, I also said that it would be nice to have a parseable field that is disto-independent so the distro-maintainer don't need to weed through READMEs to find dependency sources. I'm sorry to hear that cran2deb self-destructed as your Debian handling of packages is immensely helpful, especially for package with intricate dependencies.

On a similar note, I also think that it would be useful to have a common support already at the package level -- very few people know how to write good configure scripts and there are many pitfalls that catch the unwary, so we could have a template for the most common case of requiring a few libraries. This would also allow some auto-maigc handling of the extended requirement, possibly with some site support ... (e.g. you could imagine searching debs for the library files that are required and coming up with a suggestion of packages etc.).

Cheers,
Simon


> | 
> | Thanks,
> | Simon
> | 
> | 
> | 
> | > Giving the package name for specific distributions is of course polite (if the developer knows it). As developer you may also put into the README that the package's mailing list/forum/wiki/... contains information and ask the user to enter the package name on his distro if it is not already there.
> | > 
> | > 
> | > my 2 ct
> | > 
> | > Claudia
> | > 
> | > 
> | > 
> | > Am 04.02.2011 04:48, schrieb Simon Urbanek:
> | >> Jeroen,
> | >> 
> | >> On Feb 3, 2011, at 9:31 PM, Jeroen Ooms wrote:
> | >> 
> | >>> 
> | >>> Many R packages depend on some unix libraries that are not part of most
> | >>> default installations. I often spend a significant amount of time figuring
> | >>> out where to get the appropriate libraries for compiling these packages,
> | >>> after they give some vague error of something missing. I was wondering why
> | >>> there is no formal system of specifying non-R dependencies in the
> | >>> DESCRIPTION file. If this would be the case, then during the installation of
> | >>> an R package, the user could be prompted to install required system packages
> | >>> (if they have appropriate privileges).
> | >>> 
> | >>> So for example:
> | >>> 
> | >>> Package: XML
> | >>> Version: 3.2-0
> | >>> Depends: R (>= 1.2.0), methods, utils
> | >>> Depends-debian: libxml2-dev
> | >>> Depends-ubuntu: libxml2-dev
> | >>> Depends-redhat: libxml2-devel
> | >>> Depends-suse: libxml2-devel
> | >>> etc.
> | >>> 
> | >>> This might make life for many people just a little easier. If they are root
> | >>> and the package is in their system repositories, than it will install
> | >>> automatically. If not, at least they know for which package to look, or
> | >>> request their sys admin to install.
> | >> 
> | >> Well, there is already such system in place and it is the corresponding descriptions in the distributions. Obviously as an author of the package I don't care what any particular Linux distribution uses as a name for the needed dependencies as the corresponding chaos is distribution-specific. The only person who can reasonably determine the dependencies is the maintainer of the distribution and that's what they do and as a user of the above mentioned distributions you should be thankful to them. Fortunately, normal users don't have to worry about it as major distributions already come with a large set of R packages resolving all dependencies. Hence I don't see any reason why this should have anything to do with the DESCRIPTION file. The improvements I could think of would be a parseable entry or a canonical pointer to dependency sources, but that's a whole another story.
> | >> 
> | >> Cheers,
> | >> Simon
> | >> 
> | >> ______________________________________________
> | >> R-devel at r-project.org mailing list
> | >> https://stat.ethz.ch/mailman/listinfo/r-devel
> | > 
> | > ______________________________________________
> | > R-devel at r-project.org mailing list
> | > https://stat.ethz.ch/mailman/listinfo/r-devel
> | > 
> | > 
> | 
> | ______________________________________________
> | R-devel at r-project.org mailing list
> | https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> -- 
> Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com
> 
> 


From r.ted.byers at gmail.com  Fri Feb  4 20:30:48 2011
From: r.ted.byers at gmail.com (Ted Byers)
Date: Fri, 4 Feb 2011 14:30:48 -0500
Subject: [Rd] dependencies on system packages
In-Reply-To: <C971A7B2.233DC%ken.williams@thomsonreuters.com>
References: <EDBA419B-0DEF-4B3F-B2AE-29303D89999C@r-project.org>
	<C971A7B2.233DC%ken.williams@thomsonreuters.com>
Message-ID: <11f101cbc4a2$07b77240$172656c0$@gmail.com>

From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org]
On Behalf Of Ken.Williams at thomsonreuters.com
>Sent: February-04-11 1:58 PM
>To: simon.urbanek at r-project.org; cbeleites at units.it
>Cc: r-devel at r-project.org
>Subject: Re: [Rd] dependencies on system packages
>On 2/4/11 9:01 AM, "Simon Urbanek" <simon.urbanek at r-project.org> wrote:
>
>>I'd argue that if a user attempts to install a package from sources 
>>instead of using the distribution binaries, he should know what he's 
>>doing as there is much more involved (proper tools, usually a different 
>>library location etc.).
>
>Most of the time when I build an existing package from source, it's because
I'm doing The Open Source Thing, either trying to fix some bug or add some
new feature.  One should only need to be a competent writer of R code to do
that, but often the mechanics of >building the package get in the way.

Actually, I develop enough software that I don't really have the time to do
this (debug a package's source, or extend it), though that may change at any
time as I start using it more intensively.

Normally, the only time I have been compiling R packages from source is when
there were no 64 bit Windows binaries.  Using the right RTools, along with
R's ability to install from source allowed me to use PostGreSQL and MySQL in
64 bit R on 64 biw Windows 7.  This is a counter-example related to Simon's
remarks about a user building packages from source.  His remark is valid IF
the user is making repairs or extensions, as Ken says he does.  However, it
is problemtic for those users who are faced with a situation in which there
IS no binary distribution for their specific platform.

I do precisely the same thing with open source software written for some
flavour of Unix, even though I don't have a machine with a real unix.  On my
machine (64 bit Windows 7), I have cygwin installed (and it works fine), and
for that unix software I want to use, the usual  process of "./configure"
followed by make, "make check" or "make test", and "make install" works
great.  All I have to do is read the documentation for the software or
library I want to use, in order to make certain the dependancy requirements
are satisfied.  NB: I use cygwin ONLY to pass my C++ code through gcc, as a
check on the quality of code I have already passed through MSVC++, but that
is another story.  Yes, I have the skills needed to deal with the issues
Simon raises WRT building software n a unix machine, but I know several R
users who do not, and I would not want them to be unable to use one package
or another because of there being no binary distribution for their specific
platform (of course, you know who they ask when they encounter this sort of
issue).

Thus, I agree with Dirk that more robust and user friendly option is
required.  For me, I don't care if it is a script that runs from the shell
(bash, Windows shell, &c.) or from the R menu, but I know some potential
users who would be lost unless it is something simple that can be invoked
from R's menu.

Cheers,

Ted


From ngkbr8es at gmail.com  Fri Feb  4 20:37:37 2011
From: ngkbr8es at gmail.com (Patrick Leyshock)
Date: Fri, 4 Feb 2011 11:37:37 -0800
Subject: [Rd] matching symbols to objects
Message-ID: <AANLkTindUsvryMwCr2=rdfTxyf_J-cAAL+aFrSpEw23_@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110204/d3d9def1/attachment.pl>

From jeff.a.ryan at gmail.com  Fri Feb  4 20:42:22 2011
From: jeff.a.ryan at gmail.com (Jeff Ryan)
Date: Fri, 4 Feb 2011 13:42:22 -0600
Subject: [Rd] matching symbols to objects
In-Reply-To: <AANLkTindUsvryMwCr2=rdfTxyf_J-cAAL+aFrSpEw23_@mail.gmail.com>
References: <AANLkTindUsvryMwCr2=rdfTxyf_J-cAAL+aFrSpEw23_@mail.gmail.com>
Message-ID: <AANLkTi=4NuSJLMFXCTC8W1hD_nQXrTjtNG9fxMvDpQ84@mail.gmail.com>

Patrick,

Take a look at all.vars to start with  That will return the vars as
characters, from there you can use get to test/proceed.

> all.vars(parse.tree)
[1] "x"


Best,
Jeff

On Fri, Feb 4, 2011 at 1:37 PM, Patrick Leyshock <ngkbr8es at gmail.com> wrote:
> Hello,
>
> I'm trying to access an object, given only its name as a symbol. ?I cannot
> figure out how to proceed. ?Suppose I call substitute( ) on the expression
> 'x + 2':
>
>> parse.tree <- substitute(x + 2);
>
> The constituents of parse.tree are of type symbol and numeric:
>
>> str(parse.tree[[1]])
> symbol +
>
>> str(parse.tree[[2]])
> symbol x
>
>> str(parse.tree[[3]])
> num 2
>
> Suppose that x is S4 object, and that I need to access a slot of that
> object. ?How can I do so, using only 'parse.tree' (or parse.tree coerced
> into a list)?
>
> Thanks, Patrick
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>



-- 
Jeffrey Ryan
jeffrey.ryan at lemnica.com

www.lemnica.com


From ngkbr8es at gmail.com  Fri Feb  4 20:53:17 2011
From: ngkbr8es at gmail.com (Patrick Leyshock)
Date: Fri, 4 Feb 2011 11:53:17 -0800
Subject: [Rd] matching symbols to objects
In-Reply-To: <AANLkTiniC_Dm7vkqEcyiRrKC0MOH8cLtPE4s_VxYzOYr@mail.gmail.com>
References: <AANLkTindUsvryMwCr2=rdfTxyf_J-cAAL+aFrSpEw23_@mail.gmail.com>
	<AANLkTi=4NuSJLMFXCTC8W1hD_nQXrTjtNG9fxMvDpQ84@mail.gmail.com>
	<AANLkTiniC_Dm7vkqEcyiRrKC0MOH8cLtPE4s_VxYzOYr@mail.gmail.com>
Message-ID: <AANLkTime9y1p8=PhOSU_SLr2swAYupcgzu5jmLmv=aqi@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110204/39f790be/attachment.pl>

From kevin.r.coombes at gmail.com  Fri Feb  4 21:34:33 2011
From: kevin.r.coombes at gmail.com (Kevin R. Coombes)
Date: Fri, 04 Feb 2011 14:34:33 -0600
Subject: [Rd] keep.source when semicolons separate statements on the one
 line
In-Reply-To: <4D4C058F.1050304@gmail.com>
References: <48B94A4D-DB81-4912-850B-CDB2D7711968@anu.edu.au>
	<4D4C058F.1050304@gmail.com>
Message-ID: <4D4C62D9.6040902@gmail.com>

This is probably the same underlying bug, but it is not caused by 
semicolons.

If you use keep,soure=TRUE with expand=FALSE and interpolate a code 
chunk, the name of the chunkl is sent to the TeX file once for every 
line in the chunk. Specifically, the source file:

%%%%%%%%%%%
\documentclass{article}
\begin{document}
<<example>>=
x <- 1
y <- 2
x+y
@
<<keep.source=TRUE,expand=FALSE>>=
<<example>>
@
\end{document}
%%%%%%%%%%%

produces the output LaTeX file:

%%%%%%%%%%%
\documentclass{article}
\usepackage{Sweave}
\begin{document}
\begin{Schunk}
\begin{Sinput}
 > x <- 1
 > y <- 2
 > x + y
\end{Sinput}
\begin{Soutput}
[1] 3
\end{Soutput}
\end{Schunk}
\begin{Schunk}
\begin{Sinput}
 > <<example>>
 > <<example>>
 > <<example>>
\end{Sinput}
\begin{Soutput}
[1] 3
\end{Soutput}
\end{Schunk}
\end{document}

%%%%%%%%%%%




On 2/4/2011 7:56 AM, Duncan Murdoch wrote:
> Thanks for the report.  I'll take a look.
>
> I'm now past one major time sink, and will have some time to catch up 
> on old problems; I'll add this to that list.
>
> Duncan Murdoch
>
> On 03/02/2011 7:09 PM, John Maindonald wrote:
>> The following is 'semicolon.Rnw'
>>
>> >  \SweaveOpts{engine=R, keep.source=TRUE}
>> >
>> > <<xycig-A, eval=f, echo=f>>=
>> >  library(SMIR); data(bronchit); library(KernSmooth)
>> >  @ %
>> >
>> >  Code for panel A is
>> > <<code-xycig-A, eval=f, echo=t>>=
>> > <<xycig-A>>
>> >  @ %
>>
>> Sweave("semicolon") yields the following 'semicolon.tex'
>>
>> >  Code for panel A is
>> >  \begin{Schunk}
>> >  \begin{Sinput}
>> >>  library(SMIR); data(bronchit); library(KernSmooth)
>> >>  library(SMIR); data(bronchit); library(KernSmooth)
>> >>  library(SMIR); data(bronchit); library(KernSmooth)
>> >  \end{Sinput}
>> >  \end{Schunk}
>>
>> (I have omitted three blank lines at the start)
>>
>> With keep.source=FALSE, the commands are split onto
>> separate lines, and there is no repetition.
>>
>> John Maindonald             email: john.maindonald at anu.edu.au
>> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
>> Centre for Mathematics&  Its Applications, Room 1194,
>> John Dedman Mathematical Sciences Building (Building 27)
>> Australian National University, Canberra ACT 0200.
>> http://www.maths.anu.edu.au/~johnm
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From pleyshock at gmail.com  Fri Feb  4 20:52:19 2011
From: pleyshock at gmail.com (Patrick Leyshock)
Date: Fri, 4 Feb 2011 11:52:19 -0800
Subject: [Rd] matching symbols to objects
In-Reply-To: <AANLkTi=4NuSJLMFXCTC8W1hD_nQXrTjtNG9fxMvDpQ84@mail.gmail.com>
References: <AANLkTindUsvryMwCr2=rdfTxyf_J-cAAL+aFrSpEw23_@mail.gmail.com>
	<AANLkTi=4NuSJLMFXCTC8W1hD_nQXrTjtNG9fxMvDpQ84@mail.gmail.com>
Message-ID: <AANLkTiniC_Dm7vkqEcyiRrKC0MOH8cLtPE4s_VxYzOYr@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110204/204a6f56/attachment.pl>

From spencer.graves at structuremonitoring.com  Sat Feb  5 02:57:31 2011
From: spencer.graves at structuremonitoring.com (Spencer Graves)
Date: Fri, 04 Feb 2011 17:57:31 -0800
Subject: [Rd] Reading a specific file during "R CMD check"?
Message-ID: <4D4CAE8B.9080305@structuremonitoring.com>

Hello, All:


       How can I obtain the location of an example data file in a 
package during "R CMD check"?


       I want to include sample raw data files in a package and have 
them read by a function in the package.  It occurs to me to put such a 
file in "\inst\rawdata" and have examples find the data using something 
like "system.file('rawdata', package='MyPackage')". However, this will 
only work if the desired data are already in a version of 'MyPackage' 
that is already installed.  If I change the data, this will return the 
old data, not the modified.  I've looked at packages RUnit and svUnit, 
but have not spent enough time with either to know if they include a 
solution to this problem.


       Thanks for your help.
       Spencer

-- 
Spencer Graves, PE, PhD
President and Chief Operating Officer
Structure Inspection and Monitoring, Inc.
751 Emerson Ct.
San Jos?, CA 95126
ph:  408-655-4567


From hadley at rice.edu  Sat Feb  5 04:27:42 2011
From: hadley at rice.edu (Hadley Wickham)
Date: Fri, 4 Feb 2011 21:27:42 -0600
Subject: [Rd] Reading a specific file during "R CMD check"?
In-Reply-To: <4D4CAE8B.9080305@structuremonitoring.com>
References: <4D4CAE8B.9080305@structuremonitoring.com>
Message-ID: <AANLkTinHL2Cee93GOUP8c9ZbJ_3YRQxVBWZ79ibt-q4V@mail.gmail.com>

Hi Spencer,

I think one of the early phases of R CMD check is R CMD install - it
installs the package into a special location so that it doesn't
override existing installed packages, but still allows function to
work exactly as if they were in an installed package.

Hadley

On Fri, Feb 4, 2011 at 7:57 PM, Spencer Graves
<spencer.graves at structuremonitoring.com> wrote:
> Hello, All:
>
>
> ? ? ?How can I obtain the location of an example data file in a package
> during "R CMD check"?
>
>
> ? ? ?I want to include sample raw data files in a package and have them read
> by a function in the package. ?It occurs to me to put such a file in
> "\inst\rawdata" and have examples find the data using something like
> "system.file('rawdata', package='MyPackage')". However, this will only work
> if the desired data are already in a version of 'MyPackage' that is already
> installed. ?If I change the data, this will return the old data, not the
> modified. ?I've looked at packages RUnit and svUnit, but have not spent
> enough time with either to know if they include a solution to this problem.
>
>
> ? ? ?Thanks for your help.
> ? ? ?Spencer
>
> --
> Spencer Graves, PE, PhD
> President and Chief Operating Officer
> Structure Inspection and Monitoring, Inc.
> 751 Emerson Ct.
> San Jos?, CA 95126
> ph: ?408-655-4567
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>



-- 
Assistant Professor / Dobelman Family Junior Chair
Department of Statistics / Rice University
http://had.co.nz/


From ripley at stats.ox.ac.uk  Sat Feb  5 09:04:42 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 5 Feb 2011 08:04:42 +0000 (GMT)
Subject: [Rd] Reading a specific file during "R CMD check"?
In-Reply-To: <AANLkTinHL2Cee93GOUP8c9ZbJ_3YRQxVBWZ79ibt-q4V@mail.gmail.com>
References: <4D4CAE8B.9080305@structuremonitoring.com>
	<AANLkTinHL2Cee93GOUP8c9ZbJ_3YRQxVBWZ79ibt-q4V@mail.gmail.com>
Message-ID: <alpine.LFD.2.02.1102050753400.11626@gannet.stats.ox.ac.uk>

On Fri, 4 Feb 2011, Hadley Wickham wrote:

> Hi Spencer,
>
> I think one of the early phases of R CMD check is R CMD install - it
> installs the package into a special location so that it doesn't
> override existing installed packages, but still allows function to
> work exactly as if they were in an installed package.

There first part may or may not be true (it is not for some of the 
ways 'check' is used on the check farm: consider the --install 
argument, which is not described in --help), but in every case it will 
be true that the copy of the package under check is installed in the 
library at .libPaths()[1], and that installed package is used by 
'check' unless the user's code does really odd things (like manipulate 
.libPaths()).

>
> Hadley
>
> On Fri, Feb 4, 2011 at 7:57 PM, Spencer Graves
> <spencer.graves at structuremonitoring.com> wrote:
>> Hello, All:
>>
>>
>> ? ? ?How can I obtain the location of an example data file in a package
>> during "R CMD check"?
>>
>>
>> ? ? ?I want to include sample raw data files in a package and have them read
>> by a function in the package. ?It occurs to me to put such a file in
>> "\inst\rawdata" and have examples find the data using something like
>> "system.file('rawdata', package='MyPackage')". However, this will only work
>> if the desired data are already in a version of 'MyPackage' that is already
>> installed. ?If I change the data, this will return the old data, not the
>> modified. ?I've looked at packages RUnit and svUnit, but have not spent
>> enough time with either to know if they include a solution to this problem.

I doubt that the 'problem' is in 'R CMD check', but without a 
reproducible example, we have no evidence either way.  Certainly 
plenty of packages use system.file() in their examples, and 'check' 
works for them even if they are not previously installed.

>>
>> ? ? ?Thanks for your help.
>> ? ? ?Spencer
>>
>> --
>> Spencer Graves, PE, PhD
>> President and Chief Operating Officer
>> Structure Inspection and Monitoring, Inc.
>> 751 Emerson Ct.
>> San Jos?, CA 95126
>> ph: ?408-655-4567
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
>
>
> -- 
> Assistant Professor / Dobelman Family Junior Chair
> Department of Statistics / Rice University
> http://had.co.nz/
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From spencer.graves at structuremonitoring.com  Sat Feb  5 10:38:32 2011
From: spencer.graves at structuremonitoring.com (Spencer Graves)
Date: Sat, 05 Feb 2011 01:38:32 -0800
Subject: [Rd] Reading a specific file during "R CMD check"?
In-Reply-To: <alpine.LFD.2.02.1102050753400.11626@gannet.stats.ox.ac.uk>
References: <4D4CAE8B.9080305@structuremonitoring.com>
	<AANLkTinHL2Cee93GOUP8c9ZbJ_3YRQxVBWZ79ibt-q4V@mail.gmail.com>
	<alpine.LFD.2.02.1102050753400.11626@gannet.stats.ox.ac.uk>
Message-ID: <4D4D1A98.30807@structuremonitoring.com>

       Thanks very much to Hadley and Prof. Ripley for their replies -- 
and my apologies to the list for failing to check my facts before I posted:


       Prof. Ripley's reply was correct:  system.file('rawdata', 
package='testPackage') in a help page in package 'tstPackage' with 
subdirectory 'inst/rawdata' returned 
"~/Rpkgs/tstPackage.Rcheck/tstPackage/rawdata".


       I was once again misled by something I knew that wasn't so.


       Best Wishes,
       Spencer


On 2/5/2011 12:04 AM, Prof Brian Ripley wrote:
> On Fri, 4 Feb 2011, Hadley Wickham wrote:
>
>> Hi Spencer,
>>
>> I think one of the early phases of R CMD check is R CMD install - it
>> installs the package into a special location so that it doesn't
>> override existing installed packages, but still allows function to
>> work exactly as if they were in an installed package.
>
> There first part may or may not be true (it is not for some of the 
> ways 'check' is used on the check farm: consider the --install 
> argument, which is not described in --help), but in every case it will 
> be true that the copy of the package under check is installed in the 
> library at .libPaths()[1], and that installed package is used by 
> 'check' unless the user's code does really odd things (like manipulate 
> .libPaths()).
>
>>
>> Hadley
>>
>> On Fri, Feb 4, 2011 at 7:57 PM, Spencer Graves
>> <spencer.graves at structuremonitoring.com> wrote:
>>> Hello, All:
>>>
>>>
>>>      How can I obtain the location of an example data file in a package
>>> during "R CMD check"?
>>>
>>>
>>>      I want to include sample raw data files in a package and have 
>>> them read
>>> by a function in the package.  It occurs to me to put such a file in
>>> "\inst\rawdata" and have examples find the data using something like
>>> "system.file('rawdata', package='MyPackage')". However, this will 
>>> only work
>>> if the desired data are already in a version of 'MyPackage' that is 
>>> already
>>> installed.  If I change the data, this will return the old data, not 
>>> the
>>> modified.  I've looked at packages RUnit and svUnit, but have not spent
>>> enough time with either to know if they include a solution to this 
>>> problem.
>
> I doubt that the 'problem' is in 'R CMD check', but without a 
> reproducible example, we have no evidence either way.  Certainly 
> plenty of packages use system.file() in their examples, and 'check' 
> works for them even if they are not previously installed.
>
>>>
>>>      Thanks for your help.
>>>      Spencer
>>>
>>> -- 
>>> Spencer Graves, PE, PhD
>>> President and Chief Operating Officer
>>> Structure Inspection and Monitoring, Inc.
>>> 751 Emerson Ct.
>>> San Jos?, CA 95126
>>> ph:  408-655-4567
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>
>>
>>
>> -- 
>> Assistant Professor / Dobelman Family Junior Chair
>> Department of Statistics / Rice University
>> http://had.co.nz/
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>


From murdoch.duncan at gmail.com  Sat Feb  5 19:18:24 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 05 Feb 2011 13:18:24 -0500
Subject: [Rd] keep.source when semicolons separate statements on the one
 line
In-Reply-To: <4D4C62D9.6040902@gmail.com>
References: <48B94A4D-DB81-4912-850B-CDB2D7711968@anu.edu.au>
	<4D4C058F.1050304@gmail.com> <4D4C62D9.6040902@gmail.com>
Message-ID: <4D4D9470.1020108@gmail.com>

On 04/02/2011 3:34 PM, Kevin R. Coombes wrote:
> This is probably the same underlying bug, but it is not caused by
> semicolons.

Yes, it was the same bug.  I think I have it fixed now, and will commit 
after some more testing.

Duncan Murdoch

>
> If you use keep,soure=TRUE with expand=FALSE and interpolate a code
> chunk, the name of the chunkl is sent to the TeX file once for every
> line in the chunk. Specifically, the source file:
>
> %%%%%%%%%%%
> \documentclass{article}
> \begin{document}
> <<example>>=
> x<- 1
> y<- 2
> x+y
> @
> <<keep.source=TRUE,expand=FALSE>>=
> <<example>>
> @
> \end{document}
> %%%%%%%%%%%
>
> produces the output LaTeX file:
>
> %%%%%%%%%%%
> \documentclass{article}
> \usepackage{Sweave}
> \begin{document}
> \begin{Schunk}
> \begin{Sinput}
>   >  x<- 1
>   >  y<- 2
>   >  x + y
> \end{Sinput}
> \begin{Soutput}
> [1] 3
> \end{Soutput}
> \end{Schunk}
> \begin{Schunk}
> \begin{Sinput}
>   >  <<example>>
>   >  <<example>>
>   >  <<example>>
> \end{Sinput}
> \begin{Soutput}
> [1] 3
> \end{Soutput}
> \end{Schunk}
> \end{document}
>
> %%%%%%%%%%%
>
>
>
>
> On 2/4/2011 7:56 AM, Duncan Murdoch wrote:
>> Thanks for the report.  I'll take a look.
>>
>> I'm now past one major time sink, and will have some time to catch up
>> on old problems; I'll add this to that list.
>>
>> Duncan Murdoch
>>
>> On 03/02/2011 7:09 PM, John Maindonald wrote:
>>> The following is 'semicolon.Rnw'
>>>
>>>>   \SweaveOpts{engine=R, keep.source=TRUE}
>>>>
>>>> <<xycig-A, eval=f, echo=f>>=
>>>>   library(SMIR); data(bronchit); library(KernSmooth)
>>>>   @ %
>>>>
>>>>   Code for panel A is
>>>> <<code-xycig-A, eval=f, echo=t>>=
>>>> <<xycig-A>>
>>>>   @ %
>>>
>>> Sweave("semicolon") yields the following 'semicolon.tex'
>>>
>>>>   Code for panel A is
>>>>   \begin{Schunk}
>>>>   \begin{Sinput}
>>>>>   library(SMIR); data(bronchit); library(KernSmooth)
>>>>>   library(SMIR); data(bronchit); library(KernSmooth)
>>>>>   library(SMIR); data(bronchit); library(KernSmooth)
>>>>   \end{Sinput}
>>>>   \end{Schunk}
>>>
>>> (I have omitted three blank lines at the start)
>>>
>>> With keep.source=FALSE, the commands are split onto
>>> separate lines, and there is no repetition.
>>>
>>> John Maindonald             email: john.maindonald at anu.edu.au
>>> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
>>> Centre for Mathematics&   Its Applications, Room 1194,
>>> John Dedman Mathematical Sciences Building (Building 27)
>>> Australian National University, Canberra ACT 0200.
>>> http://www.maths.anu.edu.au/~johnm
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel


From bbolker at gmail.com  Sat Feb  5 21:58:09 2011
From: bbolker at gmail.com (Ben Bolker)
Date: Sat, 5 Feb 2011 15:58:09 -0500
Subject: [Rd] print(...,digits=2) behavior
Message-ID: <4D4DB9E1.4000306@mcmaster.ca>


  A bug was recently posted to the R bug database (which probably would
better have been posted as a query here) as to why this happens:

> print(7.921,digits=2)
[1] 8
> print(7.92,digits=2)
[1] 7.9

  Two things I *haven't* done to help make sense of this for myself are
(1) writing out the binary representations to see if something obvious
pops out about why this would be a breakpoint and (2) poking in the
source code (I did a little bit of this but gave up).

  I know that confusion over rounding etc. is very common, and my first
reaction to this sort of question is always that there must be some sort
of confusion (either (1) in a FAQ 7.31-ish sort of way that floating
point values have finite precision in the first place, or (2) a
confusion over the difference between the value and the representation
of the number, or (3) more subtly, about the differences among various
choices of rounding conventions).

  However, in this case I am a bit stumped: I don't see that any of the
standard confusions apply.  I grepped the R manuals for "rounding" and
didn't find anything useful ...  I have a very strong prior that such a
core part of R must be correct, and that therefore I (and the original
bug reporter) must be misunderstanding something.

  Thoughts/references?

  cheers
    Ben Bolker


From murdoch.duncan at gmail.com  Sat Feb  5 22:02:54 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 05 Feb 2011 16:02:54 -0500
Subject: [Rd] keep.source when semicolons separate statements on the one
 line
In-Reply-To: <4D4D9470.1020108@gmail.com>
References: <48B94A4D-DB81-4912-850B-CDB2D7711968@anu.edu.au>
	<4D4C058F.1050304@gmail.com> <4D4C62D9.6040902@gmail.com>
	<4D4D9470.1020108@gmail.com>
Message-ID: <4D4DBAFE.7040301@gmail.com>

On 05/02/2011 1:18 PM, Duncan Murdoch wrote:
> On 04/02/2011 3:34 PM, Kevin R. Coombes wrote:
>> This is probably the same underlying bug, but it is not caused by
>> semicolons.
>
> Yes, it was the same bug.  I think I have it fixed now, and will commit
> after some more testing.

Now committed as r54232 in R-devel.  I will wait a couple of days before 
backporting it to R-patched, in case new problems show up.

This should also fix the long-standing problem of dropped comments at 
the start and end of code chunks.  Now, all comments should be echoed,
even in nested named chunks and with \SweaveInput.

Duncan Murdoch

>
> Duncan Murdoch
>
>>
>> If you use keep,soure=TRUE with expand=FALSE and interpolate a code
>> chunk, the name of the chunkl is sent to the TeX file once for every
>> line in the chunk. Specifically, the source file:
>>
>> %%%%%%%%%%%
>> \documentclass{article}
>> \begin{document}
>> <<example>>=
>> x<- 1
>> y<- 2
>> x+y
>> @
>> <<keep.source=TRUE,expand=FALSE>>=
>> <<example>>
>> @
>> \end{document}
>> %%%%%%%%%%%
>>
>> produces the output LaTeX file:
>>
>> %%%%%%%%%%%
>> \documentclass{article}
>> \usepackage{Sweave}
>> \begin{document}
>> \begin{Schunk}
>> \begin{Sinput}
>>    >   x<- 1
>>    >   y<- 2
>>    >   x + y
>> \end{Sinput}
>> \begin{Soutput}
>> [1] 3
>> \end{Soutput}
>> \end{Schunk}
>> \begin{Schunk}
>> \begin{Sinput}
>>    >   <<example>>
>>    >   <<example>>
>>    >   <<example>>
>> \end{Sinput}
>> \begin{Soutput}
>> [1] 3
>> \end{Soutput}
>> \end{Schunk}
>> \end{document}
>>
>> %%%%%%%%%%%
>>
>>
>>
>>
>> On 2/4/2011 7:56 AM, Duncan Murdoch wrote:
>>> Thanks for the report.  I'll take a look.
>>>
>>> I'm now past one major time sink, and will have some time to catch up
>>> on old problems; I'll add this to that list.
>>>
>>> Duncan Murdoch
>>>
>>> On 03/02/2011 7:09 PM, John Maindonald wrote:
>>>> The following is 'semicolon.Rnw'
>>>>
>>>>>    \SweaveOpts{engine=R, keep.source=TRUE}
>>>>>
>>>>> <<xycig-A, eval=f, echo=f>>=
>>>>>    library(SMIR); data(bronchit); library(KernSmooth)
>>>>>    @ %
>>>>>
>>>>>    Code for panel A is
>>>>> <<code-xycig-A, eval=f, echo=t>>=
>>>>> <<xycig-A>>
>>>>>    @ %
>>>>
>>>> Sweave("semicolon") yields the following 'semicolon.tex'
>>>>
>>>>>    Code for panel A is
>>>>>    \begin{Schunk}
>>>>>    \begin{Sinput}
>>>>>>    library(SMIR); data(bronchit); library(KernSmooth)
>>>>>>    library(SMIR); data(bronchit); library(KernSmooth)
>>>>>>    library(SMIR); data(bronchit); library(KernSmooth)
>>>>>    \end{Sinput}
>>>>>    \end{Schunk}
>>>>
>>>> (I have omitted three blank lines at the start)
>>>>
>>>> With keep.source=FALSE, the commands are split onto
>>>> separate lines, and there is no repetition.
>>>>
>>>> John Maindonald             email: john.maindonald at anu.edu.au
>>>> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
>>>> Centre for Mathematics&    Its Applications, Room 1194,
>>>> John Dedman Mathematical Sciences Building (Building 27)
>>>> Australian National University, Canberra ACT 0200.
>>>> http://www.maths.anu.edu.au/~johnm
>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From rhurlin at gwdg.de  Sun Feb  6 15:27:26 2011
From: rhurlin at gwdg.de (Rainer Hurling)
Date: Sun, 06 Feb 2011 15:27:26 +0100
Subject: [Rd] R-devel on FreeBSD: Support for C99 complex type is required
Message-ID: <4D4EAFCE.6020004@gwdg.de>

Today I tried two build R-devel_2011-02-06.tar.gz from sources on 
FreeBSD 9.0-CURRENT (amd64) with gcc-4.5.2 and I got the following 
messages when configuring:


./configure
[..SNIP..]
checking whether C99 double complex is supported...
checking complex.h usability... yes
checking complex.h presence... yes
checking for complex.h... yes
checking for double complex... yes
checking whether cexp exists and is declared... no
checking whether clog exists and is declared... no
checking whether csqrt exists and is declared... yes
checking whether cpow exists and is declared... no
checking whether ccos exists and is declared... no
checking whether csin exists and is declared... no
checking whether ctan exists and is declared... no
checking whether cacos exists and is declared... no
checking whether casin exists and is declared... no
checking whether catan exists and is declared... no
checking whether ccosh exists and is declared... no
checking whether csinh exists and is declared... no
checking whether ctanh exists and is declared... no
checking whether cacosh exists and is declared... no
checking whether casinh exists and is declared... no
checking whether catanh exists and is declared... no
configure: error: Support for C99 complex type is required.
[..script stops here..]

Until 2.12.1 this works for me. In the NEWS file of 2.13.0 I found in 
the INSTALLATION section:

'A C99 compiler is now required, and more C99 language features will be 
used in the R sources.'

What exactly characterizes a C99 compiler? Does gcc-4.5.2 belongs to 
this? Are the special arguments or knobs to consider? Any other ideas?

Please let me know if more infos are needed.

Thanks in advance for any help,
Rainer Hurling


From ripley at stats.ox.ac.uk  Sun Feb  6 16:22:51 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 6 Feb 2011 15:22:51 +0000 (GMT)
Subject: [Rd] R-devel on FreeBSD: Support for C99 complex type is
 required
In-Reply-To: <4D4EAFCE.6020004@gwdg.de>
References: <4D4EAFCE.6020004@gwdg.de>
Message-ID: <alpine.LFD.2.00.1102061507430.15472@auk.stats.ox.ac.uk>

On Sun, 6 Feb 2011, Rainer Hurling wrote:

> Today I tried two build R-devel_2011-02-06.tar.gz from sources on FreeBSD 
> 9.0-CURRENT (amd64) with gcc-4.5.2 and I got the following messages when 
> configuring:
>
>
> ./configure
> [..SNIP..]
> checking whether C99 double complex is supported...
> checking complex.h usability... yes
> checking complex.h presence... yes
> checking for complex.h... yes
> checking for double complex... yes
> checking whether cexp exists and is declared... no
> checking whether clog exists and is declared... no
> checking whether csqrt exists and is declared... yes
> checking whether cpow exists and is declared... no
> checking whether ccos exists and is declared... no
> checking whether csin exists and is declared... no
> checking whether ctan exists and is declared... no
> checking whether cacos exists and is declared... no
> checking whether casin exists and is declared... no
> checking whether catan exists and is declared... no
> checking whether ccosh exists and is declared... no
> checking whether csinh exists and is declared... no
> checking whether ctanh exists and is declared... no
> checking whether cacosh exists and is declared... no
> checking whether casinh exists and is declared... no
> checking whether catanh exists and is declared... no
> configure: error: Support for C99 complex type is required.
> [..script stops here..]
>
> Until 2.12.1 this works for me. In the NEWS file of 2.13.0 I found in the 
> INSTALLATION section:
>
> 'A C99 compiler is now required, and more C99 language features will be used 
> in the R sources.'

But that was against R 2.12.0!

> What exactly characterizes a C99 compiler? Does gcc-4.5.2 belongs to this?

Yes with flag -std=c99, but it also needs a runtime complying with 
C99.  Those missing functions are part of C99.

> Are the special arguments or knobs to consider? Any other ideas?
>
> Please let me know if more infos are needed.

I think this is really a FreeBSD support question. In 2011, an OS 
really should have support for a 1999 standard.  Darwin, a FreeBSD 
derivative, does and its help page says

4th Berkeley Distribution      December 11, 2006     4th Berkeley Distribution

which suggests that is part of BSD.

We are not going to put back the emulation code used: we simply don't 
have the resources to fix up its problems (nor do we have a platform 
which needs it).  The alternative I will look into is allowing R to be 
compiled without support for complex arithmetic.

> Thanks in advance for any help,
> Rainer Hurling

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From rhurlin at gwdg.de  Sun Feb  6 17:50:58 2011
From: rhurlin at gwdg.de (Rainer Hurling)
Date: Sun, 06 Feb 2011 17:50:58 +0100
Subject: [Rd] R-devel on FreeBSD: Support for C99 complex type is
	required
In-Reply-To: <alpine.LFD.2.00.1102061507430.15472@auk.stats.ox.ac.uk>
References: <4D4EAFCE.6020004@gwdg.de>
	<alpine.LFD.2.00.1102061507430.15472@auk.stats.ox.ac.uk>
Message-ID: <4D4ED172.9090402@gwdg.de>

On 06.02.2011 16:22 (UTC+1), Prof Brian Ripley wrote:
> On Sun, 6 Feb 2011, Rainer Hurling wrote:
>
>> Today I tried two build R-devel_2011-02-06.tar.gz from sources on
>> FreeBSD 9.0-CURRENT (amd64) with gcc-4.5.2 and I got the following
>> messages when configuring:
>>
>>
>> ./configure
>> [..SNIP..]
>> checking whether C99 double complex is supported...
>> checking complex.h usability... yes
>> checking complex.h presence... yes
>> checking for complex.h... yes
>> checking for double complex... yes
>> checking whether cexp exists and is declared... no
>> checking whether clog exists and is declared... no
>> checking whether csqrt exists and is declared... yes
>> checking whether cpow exists and is declared... no
>> checking whether ccos exists and is declared... no
>> checking whether csin exists and is declared... no
>> checking whether ctan exists and is declared... no
>> checking whether cacos exists and is declared... no
>> checking whether casin exists and is declared... no
>> checking whether catan exists and is declared... no
>> checking whether ccosh exists and is declared... no
>> checking whether csinh exists and is declared... no
>> checking whether ctanh exists and is declared... no
>> checking whether cacosh exists and is declared... no
>> checking whether casinh exists and is declared... no
>> checking whether catanh exists and is declared... no
>> configure: error: Support for C99 complex type is required.
>> [..script stops here..]
>>
>> Until 2.12.1 this works for me. In the NEWS file of 2.13.0 I found in
>> the INSTALLATION section:
>>
>> 'A C99 compiler is now required, and more C99 language features will
>> be used in the R sources.'
>
> But that was against R 2.12.0!

Yes, but emulation code was not removed until R-2.13.0?

>> What exactly characterizes a C99 compiler? Does gcc-4.5.2 belongs to
>> this?
>
> Yes with flag -std=c99, but it also needs a runtime complying with C99.
> Those missing functions are part of C99.

Probably a stupid question because I am not a programmer: Is this 
'runtime complying with C99' a compilers binary or something else?

>> Are the special arguments or knobs to consider? Any other ideas?
>>
>> Please let me know if more infos are needed.
>
> I think this is really a FreeBSD support question. In 2011, an OS really
> should have support for a 1999 standard. Darwin, a FreeBSD derivative,
> does and its help page says

Hmm, on FreeBSD I really have no other piece of software which complains 
about lack of C99.

> 4th Berkeley Distribution December 11, 2006 4th Berkeley Distribution

In 2006 we had already Darwin 8.x in Mac OS X 10.4.

> which suggests that is part of BSD.
>
> We are not going to put back the emulation code used: we simply don't
> have the resources to fix up its problems (nor do we have a platform
> which needs it). The alternative I will look into is allowing R to be
> compiled without support for complex arithmetic.

Ok, I understand. This seems consistent. I will try to contact FreeBSD 
support about it. Please do not change back the behaviour for FreeBSD 
(towards emulation code) until this is clarified.

>> Thanks in advance for any help,
>> Rainer Hurling

Thanks for answering and clearing this up,
Rainer Hurling


From murray at stokely.org  Sun Feb  6 18:24:27 2011
From: murray at stokely.org (Murray Stokely)
Date: Sun, 6 Feb 2011 09:24:27 -0800
Subject: [Rd] R-devel on FreeBSD: Support for C99 complex type is
	required
In-Reply-To: <4D4ED172.9090402@gwdg.de>
References: <4D4EAFCE.6020004@gwdg.de>
	<alpine.LFD.2.00.1102061507430.15472@auk.stats.ox.ac.uk>
	<4D4ED172.9090402@gwdg.de>
Message-ID: <AANLkTinvJZYiLTRAfhN1Bo7Si1dTHed9+kv3p1Uqw0RB@mail.gmail.com>

On Sun, Feb 6, 2011 at 8:50 AM, Rainer Hurling <rhurlin at gwdg.de> wrote:
>> I think this is really a FreeBSD support question. In 2011, an OS really
>> should have support for a 1999 standard. Darwin, a FreeBSD derivative,
>> does and its help page says
>
> Hmm, on FreeBSD I really have no other piece of software which complains
> about lack of C99.

FreeBSD is planning on switching to a different compiler, llvm/clang,
and so the version of gcc is stale, but still it should be more than
sufficient to support C99.  FreeBSD started a C99 effort a decade ago
and I haven't heard from this initiative in a long time as I thought
it was completed.

    http://www.freebsd.org/projects/c99/index.html

There is I believe experimental support for llvm/clang built into
FreeBSD 9, so you could try compiling with that instead of gcc.

> Ok, I understand. This seems consistent. I will try to contact FreeBSD
> support about it. Please do not change back the behaviour for FreeBSD
> (towards emulation code) until this is clarified.

Yes, please mail freebsd-standards at google.com

I haven't looked at what autoconf is testing exactly but I suspect
simply another argument must be provided in the autoconf script to get
it to pull up the C99 math functions its looking for.

          - Murray


From ripley at stats.ox.ac.uk  Sun Feb  6 18:24:59 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 6 Feb 2011 17:24:59 +0000 (GMT)
Subject: [Rd] R-devel on FreeBSD: Support for C99 complex type is
 required
In-Reply-To: <4D4ED172.9090402@gwdg.de>
References: <4D4EAFCE.6020004@gwdg.de>
	<alpine.LFD.2.00.1102061507430.15472@auk.stats.ox.ac.uk>
	<4D4ED172.9090402@gwdg.de>
Message-ID: <alpine.LFD.2.00.1102061710320.22661@auk.stats.ox.ac.uk>

On Sun, 6 Feb 2011, Rainer Hurling wrote:

> On 06.02.2011 16:22 (UTC+1), Prof Brian Ripley wrote:
>> On Sun, 6 Feb 2011, Rainer Hurling wrote:
>> 
>>> Today I tried two build R-devel_2011-02-06.tar.gz from sources on
>>> FreeBSD 9.0-CURRENT (amd64) with gcc-4.5.2 and I got the following
>>> messages when configuring:
>>> 
>>> 
>>> ./configure
>>> [..SNIP..]
>>> checking whether C99 double complex is supported...
>>> checking complex.h usability... yes
>>> checking complex.h presence... yes
>>> checking for complex.h... yes
>>> checking for double complex... yes
>>> checking whether cexp exists and is declared... no
>>> checking whether clog exists and is declared... no
>>> checking whether csqrt exists and is declared... yes
>>> checking whether cpow exists and is declared... no
>>> checking whether ccos exists and is declared... no
>>> checking whether csin exists and is declared... no
>>> checking whether ctan exists and is declared... no
>>> checking whether cacos exists and is declared... no
>>> checking whether casin exists and is declared... no
>>> checking whether catan exists and is declared... no
>>> checking whether ccosh exists and is declared... no
>>> checking whether csinh exists and is declared... no
>>> checking whether ctanh exists and is declared... no
>>> checking whether cacosh exists and is declared... no
>>> checking whether casinh exists and is declared... no
>>> checking whether catanh exists and is declared... no
>>> configure: error: Support for C99 complex type is required.
>>> [..script stops here..]
>>> 
>>> Until 2.12.1 this works for me. In the NEWS file of 2.13.0 I found in
>>> the INSTALLATION section:
>>> 
>>> 'A C99 compiler is now required, and more C99 language features will
>>> be used in the R sources.'
>> 
>> But that was against R 2.12.0!
>
> Yes, but emulation code was not removed until R-2.13.0?

Not really: there was an alternative not using C99 double complex 
prior to R-devel (there is no 'R-2.13.0').

>>> What exactly characterizes a C99 compiler? Does gcc-4.5.2 belongs to
>>> this?
>> 
>> Yes with flag -std=c99, but it also needs a runtime complying with C99.
>> Those missing functions are part of C99.
>
> Probably a stupid question because I am not a programmer: Is this 'runtime 
> complying with C99' a compilers binary or something else?

The C99 standard requires more than a compiler.  It is usual (but not 
compulsory) to provide the runtime support in libraries such as libc 
and libm: so on Linux these functions are in glibc, on Windows most 
are in MSVCRT.dll and some in libmingwex.a ....

>>> Are the special arguments or knobs to consider? Any other ideas?
>>> 
>>> Please let me know if more infos are needed.
>> 
>> I think this is really a FreeBSD support question. In 2011, an OS really
>> should have support for a 1999 standard. Darwin, a FreeBSD derivative,
>> does and its help page says
>
> Hmm, on FreeBSD I really have no other piece of software which complains 
> about lack of C99.

Maybe you use no other piece of software relying on C99's complex 
functions?

>> 4th Berkeley Distribution December 11, 2006 4th Berkeley Distribution
>
> In 2006 we had already Darwin 8.x in Mac OS X 10.4.
>
>> which suggests that is part of BSD.
>> 
>> We are not going to put back the emulation code used: we simply don't
>> have the resources to fix up its problems (nor do we have a platform
>> which needs it). The alternative I will look into is allowing R to be
>> compiled without support for complex arithmetic.
>
> Ok, I understand. This seems consistent. I will try to contact FreeBSD 
> support about it. Please do not change back the behaviour for FreeBSD 
> (towards emulation code) until this is clarified.

As I said, we are never going to do that.  The usual Open Source way 
to solve problems like this is for substitute functions to be provided 
on the deficient platform.  We do that for several functions that used 
not to be common: see src/main/Makefile.

>>> Thanks in advance for any help,
>>> Rainer Hurling
>
> Thanks for answering and clearing this up,
> Rainer Hurling
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From murray at stokely.org  Sun Feb  6 18:25:18 2011
From: murray at stokely.org (Murray Stokely)
Date: Sun, 6 Feb 2011 09:25:18 -0800
Subject: [Rd] R-devel on FreeBSD: Support for C99 complex type is
	required
In-Reply-To: <AANLkTinvJZYiLTRAfhN1Bo7Si1dTHed9+kv3p1Uqw0RB@mail.gmail.com>
References: <4D4EAFCE.6020004@gwdg.de>
	<alpine.LFD.2.00.1102061507430.15472@auk.stats.ox.ac.uk>
	<4D4ED172.9090402@gwdg.de>
	<AANLkTinvJZYiLTRAfhN1Bo7Si1dTHed9+kv3p1Uqw0RB@mail.gmail.com>
Message-ID: <AANLkTikw5Ggi6rOXM-EM_5==5-UOOHZBnF81dFHoe_Lb@mail.gmail.com>

On Sun, Feb 6, 2011 at 9:24 AM, Murray Stokely <murray at stokely.org> wrote:
> Yes, please mail freebsd-standards at google.com

Ugh, that should be freebsd-standards at freebsd.org of course.  Silly brain-o.

        - Murray


From ripley at stats.ox.ac.uk  Sun Feb  6 18:30:15 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 6 Feb 2011 17:30:15 +0000 (GMT)
Subject: [Rd] R-devel on FreeBSD: Support for C99 complex type is
 required
In-Reply-To: <AANLkTinvJZYiLTRAfhN1Bo7Si1dTHed9+kv3p1Uqw0RB@mail.gmail.com>
References: <4D4EAFCE.6020004@gwdg.de>
	<alpine.LFD.2.00.1102061507430.15472@auk.stats.ox.ac.uk>
	<4D4ED172.9090402@gwdg.de>
	<AANLkTinvJZYiLTRAfhN1Bo7Si1dTHed9+kv3p1Uqw0RB@mail.gmail.com>
Message-ID: <alpine.LFD.2.00.1102061725570.22661@auk.stats.ox.ac.uk>

On Sun, 6 Feb 2011, Murray Stokely wrote:

> On Sun, Feb 6, 2011 at 8:50 AM, Rainer Hurling <rhurlin at gwdg.de> wrote:
>>> I think this is really a FreeBSD support question. In 2011, an OS really
>>> should have support for a 1999 standard. Darwin, a FreeBSD derivative,
>>> does and its help page says
>>
>> Hmm, on FreeBSD I really have no other piece of software which complains
>> about lack of C99.
>
> FreeBSD is planning on switching to a different compiler, llvm/clang,
> and so the version of gcc is stale, but still it should be more than
> sufficient to support C99.  FreeBSD started a C99 effort a decade ago
> and I haven't heard from this initiative in a long time as I thought
> it was completed.
>
>    http://www.freebsd.org/projects/c99/index.html

Hmm, the line

Implement new functions that appear in <complex.h>.

is marked as 1/2 done, 2008.

> There is I believe experimental support for llvm/clang built into
> FreeBSD 9, so you could try compiling with that instead of gcc.
>
>> Ok, I understand. This seems consistent. I will try to contact FreeBSD
>> support about it. Please do not change back the behaviour for FreeBSD
>> (towards emulation code) until this is clarified.
>
> Yes, please mail freebsd-standards at google.com
>
> I haven't looked at what autoconf is testing exactly but I suspect
> simply another argument must be provided in the autoconf script to get
> it to pull up the C99 math functions its looking for.

Maybe, but it is looking in complex.h, where the C99 standard says 
these must be (unconditionally).

>
>          - Murray
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From rhurlin at gwdg.de  Sun Feb  6 18:54:25 2011
From: rhurlin at gwdg.de (Rainer Hurling)
Date: Sun, 06 Feb 2011 18:54:25 +0100
Subject: [Rd] R-devel on FreeBSD: Support for C99 complex type is
	required
In-Reply-To: <AANLkTinvJZYiLTRAfhN1Bo7Si1dTHed9+kv3p1Uqw0RB@mail.gmail.com>
References: <4D4EAFCE.6020004@gwdg.de>	<alpine.LFD.2.00.1102061507430.15472@auk.stats.ox.ac.uk>	<4D4ED172.9090402@gwdg.de>
	<AANLkTinvJZYiLTRAfhN1Bo7Si1dTHed9+kv3p1Uqw0RB@mail.gmail.com>
Message-ID: <4D4EE051.5040101@gwdg.de>

On 06.02.2011 18:24 (UTC+1), Murray Stokely wrote:
> On Sun, Feb 6, 2011 at 8:50 AM, Rainer Hurling<rhurlin at gwdg.de>  wrote:
>>> I think this is really a FreeBSD support question. In 2011, an OS really
>>> should have support for a 1999 standard. Darwin, a FreeBSD derivative,
>>> does and its help page says
>>
>> Hmm, on FreeBSD I really have no other piece of software which complains
>> about lack of C99.
>
> FreeBSD is planning on switching to a different compiler, llvm/clang,
> and so the version of gcc is stale, but still it should be more than
> sufficient to support C99.  FreeBSD started a C99 effort a decade ago
> and I haven't heard from this initiative in a long time as I thought
> it was completed.
>
>      http://www.freebsd.org/projects/c99/index.html

As far as I understand these initiative was/is for the built in gcc 
4.2.1. When building a port newer ones like 4.5.3 can be used. The newer 
gcc versions made a lot of progress, see

http://gcc.gnu.org/gcc-4.2/c99status.html

http://gcc.gnu.org/gcc-4.5/c99status.html

Especially the complex support in complex.h of version 4.2.1 is broken.

> There is I believe experimental support for llvm/clang built into
> FreeBSD 9, so you could try compiling with that instead of gcc.

This is not an option at the moment, because I have to work with my 
system (desktop).

>> Ok, I understand. This seems consistent. I will try to contact FreeBSD
>> support about it. Please do not change back the behaviour for FreeBSD
>> (towards emulation code) until this is clarified.
>
> Yes, please mail freebsd-standards at google.com

I will mail freebsd-standards at freebsd.org as you suggested.

> I haven't looked at what autoconf is testing exactly but I suspect
> simply another argument must be provided in the autoconf script to get
> it to pull up the C99 math functions its looking for.

Perhaps there is a way to use gcc's 4.5.3 C99 functionality instead of 
4.2.1 ones. The c99 wrapper at /usr/bin/c99 enforces the use of the 
built in compiler (hardcoded path).

>            - Murray

Thanks for the answer,
Rainer


From rhurlin at gwdg.de  Sun Feb  6 19:20:34 2011
From: rhurlin at gwdg.de (Rainer Hurling)
Date: Sun, 06 Feb 2011 19:20:34 +0100
Subject: [Rd] R-devel on FreeBSD: Support for C99 complex type is
	required
In-Reply-To: <alpine.LFD.2.00.1102061710320.22661@auk.stats.ox.ac.uk>
References: <4D4EAFCE.6020004@gwdg.de>
	<alpine.LFD.2.00.1102061507430.15472@auk.stats.ox.ac.uk>
	<4D4ED172.9090402@gwdg.de>
	<alpine.LFD.2.00.1102061710320.22661@auk.stats.ox.ac.uk>
Message-ID: <4D4EE672.6080601@gwdg.de>

On 06.02.2011 18:24 (UTC+1), Prof Brian Ripley wrote:
> On Sun, 6 Feb 2011, Rainer Hurling wrote:
>
>> On 06.02.2011 16:22 (UTC+1), Prof Brian Ripley wrote:
>>> On Sun, 6 Feb 2011, Rainer Hurling wrote:
>>>
>>>> Today I tried two build R-devel_2011-02-06.tar.gz from sources on
>>>> FreeBSD 9.0-CURRENT (amd64) with gcc-4.5.2 and I got the following
>>>> messages when configuring:
>>>>
>>>>
>>>> ./configure
>>>> [..SNIP..]
>>>> checking whether C99 double complex is supported...
>>>> checking complex.h usability... yes
>>>> checking complex.h presence... yes
>>>> checking for complex.h... yes
>>>> checking for double complex... yes
>>>> checking whether cexp exists and is declared... no
>>>> checking whether clog exists and is declared... no
>>>> checking whether csqrt exists and is declared... yes
>>>> checking whether cpow exists and is declared... no
>>>> checking whether ccos exists and is declared... no
>>>> checking whether csin exists and is declared... no
>>>> checking whether ctan exists and is declared... no
>>>> checking whether cacos exists and is declared... no
>>>> checking whether casin exists and is declared... no
>>>> checking whether catan exists and is declared... no
>>>> checking whether ccosh exists and is declared... no
>>>> checking whether csinh exists and is declared... no
>>>> checking whether ctanh exists and is declared... no
>>>> checking whether cacosh exists and is declared... no
>>>> checking whether casinh exists and is declared... no
>>>> checking whether catanh exists and is declared... no
>>>> configure: error: Support for C99 complex type is required.
>>>> [..script stops here..]
>>>>
>>>> Until 2.12.1 this works for me. In the NEWS file of 2.13.0 I found in
>>>> the INSTALLATION section:
>>>>
>>>> 'A C99 compiler is now required, and more C99 language features will
>>>> be used in the R sources.'
>>>
>>> But that was against R 2.12.0!
>>
>> Yes, but emulation code was not removed until R-2.13.0?
>
> Not really: there was an alternative not using C99 double complex prior
> to R-devel (there is no 'R-2.13.0').

Sorry for the naming, R-devel of course.

>>>> What exactly characterizes a C99 compiler? Does gcc-4.5.2 belongs to
>>>> this?
>>>
>>> Yes with flag -std=c99, but it also needs a runtime complying with C99.
>>> Those missing functions are part of C99.
>>
>> Probably a stupid question because I am not a programmer: Is this
>> 'runtime complying with C99' a compilers binary or something else?
>
> The C99 standard requires more than a compiler. It is usual (but not
> compulsory) to provide the runtime support in libraries such as libc and
> libm: so on Linux these functions are in glibc, on Windows most are in
> MSVCRT.dll and some in libmingwex.a ....

Ok, so only changing the compiler might be not enough. We have to try out.

>>>> Are the special arguments or knobs to consider? Any other ideas?
>>>>
>>>> Please let me know if more infos are needed.
>>>
>>> I think this is really a FreeBSD support question. In 2011, an OS really
>>> should have support for a 1999 standard. Darwin, a FreeBSD derivative,
>>> does and its help page says
>>
>> Hmm, on FreeBSD I really have no other piece of software which
>> complains about lack of C99.
>
> Maybe you use no other piece of software relying on C99's complex
> functions?

That is possible. But I have more than 1300 ports (FreeBSD packages) 
installed. And some of them are quite sophisticated.

>>> 4th Berkeley Distribution December 11, 2006 4th Berkeley Distribution
>>
>> In 2006 we had already Darwin 8.x in Mac OS X 10.4.
>>
>>> which suggests that is part of BSD.
>>>
>>> We are not going to put back the emulation code used: we simply don't
>>> have the resources to fix up its problems (nor do we have a platform
>>> which needs it). The alternative I will look into is allowing R to be
>>> compiled without support for complex arithmetic.
>>
>> Ok, I understand. This seems consistent. I will try to contact FreeBSD
>> support about it. Please do not change back the behaviour for FreeBSD
>> (towards emulation code) until this is clarified.
>
> As I said, we are never going to do that. The usual Open Source way to
> solve problems like this is for substitute functions to be provided on
> the deficient platform. We do that for several functions that used not
> to be common: see src/main/Makefile.

I had a look at src/main/complex.c. There is a comment which describes 
the failure for gcc 4.2.1 on some systems.

This gives me the idea that perhaps FreeBSD is using the wrong complex.h 
file. The old one is in /usr/include, the newer one (4.5.3) in 
/usr/local/lib/gcc45/include/c++. But obviously the older header is 
used. I have to clear up this.

>>>> Thanks in advance for any help,
>>>> Rainer Hurling
>>
>> Thanks for answering and clearing this up,
>> Rainer Hurling


From p.murrell at auckland.ac.nz  Mon Feb  7 02:10:20 2011
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Mon, 07 Feb 2011 14:10:20 +1300
Subject: [Rd] [.raster bug {was "str() on raster objects fails .."}
In-Reply-To: <74150327-8264-43FF-A4AC-1D3A2C469B4F@r-project.org>
References: <AANLkTimycPK-3_mj5OPd0eLauAh41r2-Wkrp7j2jo1sw@mail.gmail.com>	<19783.49835.494142.88222@stat.math.ethz.ch>	<4D48A96B.9020801@auckland.ac.nz>	<AANLkTimRBZbzgRfAkE2-VhnFmVRkWz1-cCqeD4VW7O42@mail.gmail.com>	<4D48B08A.40302@auckland.ac.nz>	<5251E963-8D1C-46CF-AAB9-39ABFE520229@r-project.org>
	<AANLkTikgSiucEMzfSa2s9YTypkqzYLCab9gJvkGyr0Pz@mail.gmail.com>
	<4D49F024.6090906@stat.auckland.ac.nz>
	<74150327-8264-43FF-A4AC-1D3A2C469B4F@r-project.org>
Message-ID: <4D4F467C.8040201@auckland.ac.nz>

Hi

On 3/02/2011 1:23 p.m., Simon Urbanek wrote:
>
> On Feb 2, 2011, at 7:00 PM, Paul Murrell wrote:
>
>> Hi
>>
>> Martin Maechler wrote:
>>> On Wed, Feb 2, 2011 at 23:30, Simon
>>> Urbanek<simon.urbanek at r-project.org>  wrote:
>>>> On Feb 1, 2011, at 8:16 PM, Paul Murrell wrote:
>>>>
>>>>> Hi
>>>>>
>>>>> On 2/02/2011 2:03 p.m., Henrik Bengtsson wrote:
>>>>>> On Tue, Feb 1, 2011 at 4:46 PM, Paul
>>>>>> Murrell<p.murrell at auckland.ac.nz>   wrote:
>>>>>>> Hi
>>>>>>>
>>>>>>> On 1/02/2011 9:22 p.m., Martin Maechler wrote:
>>>>>>>>>>>>> Henrik Bengtsson<hb at biostat.ucsf.edu> on Mon,
>>>>>>>>>>>>> 31 Jan 2011 11:16:59 -0800 writes:
>>>>>>>>> Hi, str() on raster objects fails for certain
>>>>>>>>> dimensions.  For example:
>>>>>>>>
>>>>>>>>>> str(as.raster(0, nrow=1, ncol=100)) 'raster' chr
>>>>>>>>>> [1, 1:100]
>>>>>>>>> "#000000" "#000000" "#000000" "#000000" ...
>>>>>>>>
>>>>>>>>>> str(as.raster(0, nrow=1, ncol=101)) Error in
>>>>>>>>>> `[.raster`(object,
>>>>>>>>> seq_len(max.len)) : subscript out of bounds
>>>>>>>>
>>>>>>>>> This seems to do with how str() and "[.raster"() is
>>>>>>>>> coded; when subsetting as a vector, which str()
>>>>>>>>> relies on, "[.raster"() still returns a matrix-like
>>>>>>>>> object, e.g.
>>>>>>>>
>>>>>>>>>> img<- as.raster(1:25, max=25, nrow=5, ncol=5);
>>>>>>>>>> img[1:2]
>>>>>>>>> [,1]      [,2]      [,3]      [,4]      [,5] [1,]
>>>>>>>>> "#0A0A0A" "#3D3D3D" "#707070" "#A3A3A3" "#D6D6D6"
>>>>>>>>> [2,] "#141414" "#474747" "#7A7A7A" "#ADADAD"
>>>>>>>>> "#E0E0E0"
>>>>>>>>
>>>>>>>>> compare with:
>>>>>>>>
>>>>>>>>>> as.matrix(img)[1:2]
>>>>>>>>> [1] "#0A0A0A" "#3D3D3D"
>>>>>>>>
>>>>>>>>
>>>>>>>>> The easy but incomplete fix is to do:
>>>>>>>>
>>>>>>>>> str.raster<- function(object, ...) {
>>>>>>>>> str(as.matrix(object), ...); }
>>>>>>>>
>>>>>>>>> Other suggestions?
>>>>>>>>
>>>>>>>> The informal "raster" class is behaving ``illogical''
>>>>>>>> in the following sense:
>>>>>>>>
>>>>>>>>> r<- as.raster(0, nrow=1, ncol=11) r[seq_along(r)]
>>>>>>>> Error in `[.raster`(r, seq_along(r)) : subscript out of
>>>>>>>> bounds
>>>>>>>>
>>>>>>>> or, here equivalently,
>>>>>>>>> r[1:length(r)]
>>>>>>>> Error in `[.raster`(r, 1:length(r)) : subscript out of
>>>>>>>> bounds
>>>>>>>>
>>>>>>>> When classes do behave in such a way, they definitely
>>>>>>>> need their own str() method.
>>>>>>>>
>>>>>>>> However, the bug really is in "[.raster": Currently,
>>>>>>>> r[i] is equivalent to  r[i,]  which is not at all
>>>>>>>> matrix-like and its help clearly says that subsetting
>>>>>>>> should work as for matrices. A recent thread on
>>>>>>>> R-help/R-devel has mentioned the fact that "[" methods
>>>>>>>> for matrix-like methods need to use both nargs() and
>>>>>>>> missing() and that "[.dataframe" has been the example
>>>>>>>> to follow "forever", IIRC already in S and S-plus as of
>>>>>>>> 20 years ago.
>>>>>>> The main motivation for non-standard behaviour here is to
>>>>>>> make sure that a subset of a raster object NEVER produces
>>>>>>> a vector (because the conversion back to a raster object
>>>>>>> then produces a single-column raster and that may be a
>>>>>>> "surprise").  Thanks for making the code more standard
>>>>>>> and robust.
>>>>>>>
>>>>>>> The r[i] case is still tricky.  The following behaviour
>>>>>>> is quite convenient ...
>>>>>>>
>>>>>>> r[r == "black"]<- "white"
>>>>>>>
>>>>>>> ... but the next behaviour is quite jarring (at least in
>>>>>>> terms of the raster image that results from it) ...
>>>>>>>
>>>>>>> r2<- r[1:(nrow(r) + 1)]
>>>>>>>
>>>>>>> So I think there is some justification for further
>>>>>>> non-standardness to try to ensure that the subset of a
>>>>>>> raster image always produces a sensible image.  A simple
>>>>>>> solution would be just to outlaw r[i] for raster objects
>>>>>>> and force the user to write r[i, ] or r[, j], depending
>>>>>>> on what they want.
>>>>>> FYI, I've tried out Martin's updated version at it seems
>>>>>> like a one-column raster matrix is now returned for r[i],
>>>>>> e.g.
>>>>> Yes, that's what I've been looking at ...
>>>>>
>>>>>>> r<- as.raster(1:8, max=8, nrow=2, ncol=4); r
>>>>>> [,1]      [,2]      [,3]      [,4] [1,] "#202020" "#606060"
>>>>>> "#9F9F9F" "#DFDFDF" [2,] "#404040" "#808080" "#BFBFBF"
>>>>>> "#FFFFFF"
>>>>>>
>>>>>>> r[1:length(r)]
>>>>>> [,1] [1,] "#202020" [2,] "#404040" [3,] "#606060" [4,]
>>>>>> "#808080" [5,] "#9F9F9F" [6,] "#BFBFBF" [7,] "#DFDFDF" [8,]
>>>>>> "#FFFFFF"
>>>>> ... and the above is exactly the sort of thing that will fry
>>>>> your mind if the image that you are subsetting is, for
>>>>> example, a photo.
>>>>>
>>>> Why doesn't raster behave consistently like any matrix object?
>>>> I would expect simply
>>>>
>>>>> r[1:length(r)]
>>>> [1] "#202020" "#404040" "#606060" "#808080" "#9F9F9F" "#BFBFBF"
>>>> "#DFDFDF" [8] "#FFFFFF"
>>>>
>>>> Where it's obvious what happened. I saw the comment about the
>>>> vector but I'm not sure I get it - why don't you want a vector?
>>>> The raster is no different than matrices - you still need to
>>>> define the dimensions when going back anyway, moreover what you
>>>> get now is not consistent at all since there raster never had
>>>> that dimension anyway ...
>>>>
>>>> Cheers, Simon
>>> I agree that this would be the most "logical" and notably least
>>> surprising behavior, which I find the most important argument
>>> (I'm sorry my last message was cut off as it was sent
>>> accidentally before being finished completely).
>>
>> I think this behaviour might surprise some ...
>>
>> download.file("http://cran.r-project.org/Rlogo.jpg", "Rlogo.jpg")
>> library(ReadImages) logo<- read.jpeg("Rlogo.jpg")
>>
>> rLogo<- as.raster(logo) rLogoBit<- rLogo[50:60, 50:60]
>>
>> library(grid) # Original image grid.raster(rLogoBit)
>> grid.newpage() # Subset produces a vector
>> grid.raster(rLogoBit[1:length(rLogoBit)])
>>
>
> But this should fail IMHO since you're supplying a vector but
> grid.raster (assuming it's the same as rasterImage) requires a matrix
> - exactly as you would expect in the matrix case - if a function
> requires a matrix and you pass a vector, it will bark. I think you
> are explaining why going to vector *is* desirable ;). In the current
> case it simply generates the wrong dimensions instead of resulting in
> a vector, right?

The raster subsetting always produces a raster, but grid.raster() works 
with vectors anyway because as.raster() has a vector method.

Anyway, I'm happy to go with things as they now are.  I think at worst 
it will encourage people to specify two indices when subsetting a raster 
object, and that's not a bad thing.

Paul


> Cheers, Simon
>
>
>
>
>
>> Paul
>>
>>> Martin
>>>>> Paul
>>>>>
>>>>>>> r[1:5,drop=TRUE]
>>>>>> [,1] [1,] "#202020" [2,] "#404040" [3,] "#606060" [4,]
>>>>>> "#808080" [5,] "#9F9F9F" Warning message: In `[.raster`(r,
>>>>>> 1:5, drop = TRUE) : 'drop' is always implicitly FALSE in
>>>>>> '[.raster'
>>>>>>
>>>>>> Also,
>>>>>>
>>>>>>> r[1:5]<- "white" r
>>>>>> [,1]    [,2]    [,3]      [,4] [1,] "white" "white" "white"
>>>>>> "#DFDFDF" [2,] "white" "white" "#BFBFBF" "#FFFFFF"
>>>>>>
>>>>>> /Henrik
>>>>>>
>>>>>>> Paul
>>>>>>>
>>>>>>>> Thank you, Henrik, for the bug report. Martin
>>>>>>>>
>>>>>>>> ______________________________________________
>>
>> -- Dr Paul Murrell Department of Statistics The University of
>> Auckland Private Bag 92019 Auckland New Zealand 64 9 3737599
>> x85392 paul at stat.auckland.ac.nz
>> http://www.stat.auckland.ac.nz/~paul/
>>
>>
>

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/


From simon.urbanek at r-project.org  Mon Feb  7 02:53:01 2011
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Sun, 6 Feb 2011 20:53:01 -0500
Subject: [Rd] [.raster bug {was "str() on raster objects fails .."}
In-Reply-To: <4D4F467C.8040201@auckland.ac.nz>
References: <AANLkTimycPK-3_mj5OPd0eLauAh41r2-Wkrp7j2jo1sw@mail.gmail.com>	<19783.49835.494142.88222@stat.math.ethz.ch>	<4D48A96B.9020801@auckland.ac.nz>	<AANLkTimRBZbzgRfAkE2-VhnFmVRkWz1-cCqeD4VW7O42@mail.gmail.com>	<4D48B08A.40302@auckland.ac.nz>	<5251E963-8D1C-46CF-AAB9-39ABFE520229@r-project.org>
	<AANLkTikgSiucEMzfSa2s9YTypkqzYLCab9gJvkGyr0Pz@mail.gmail.com>
	<4D49F024.6090906@stat.auckland.ac.nz>
	<74150327-8264-43FF-A4AC-1D3A2C469B4F@r-project.org>
	<4D4F467C.8040201@auckland.ac.nz>
Message-ID: <0C865A58-A3C5-4A46-AA7E-50439BAAC520@r-project.org>


On Feb 6, 2011, at 8:10 PM, Paul Murrell wrote:

> Hi
> 
> On 3/02/2011 1:23 p.m., Simon Urbanek wrote:
>> 
>> On Feb 2, 2011, at 7:00 PM, Paul Murrell wrote:
>> 
>>> Hi
>>> 
>>> Martin Maechler wrote:
>>>> On Wed, Feb 2, 2011 at 23:30, Simon
>>>> Urbanek<simon.urbanek at r-project.org>  wrote:
>>>>> On Feb 1, 2011, at 8:16 PM, Paul Murrell wrote:
>>>>> 
>>>>>> Hi
>>>>>> 
>>>>>> On 2/02/2011 2:03 p.m., Henrik Bengtsson wrote:
>>>>>>> On Tue, Feb 1, 2011 at 4:46 PM, Paul
>>>>>>> Murrell<p.murrell at auckland.ac.nz>   wrote:
>>>>>>>> Hi
>>>>>>>> 
>>>>>>>> On 1/02/2011 9:22 p.m., Martin Maechler wrote:
>>>>>>>>>>>>>> Henrik Bengtsson<hb at biostat.ucsf.edu> on Mon,
>>>>>>>>>>>>>> 31 Jan 2011 11:16:59 -0800 writes:
>>>>>>>>>> Hi, str() on raster objects fails for certain
>>>>>>>>>> dimensions.  For example:
>>>>>>>>> 
>>>>>>>>>>> str(as.raster(0, nrow=1, ncol=100)) 'raster' chr
>>>>>>>>>>> [1, 1:100]
>>>>>>>>>> "#000000" "#000000" "#000000" "#000000" ...
>>>>>>>>> 
>>>>>>>>>>> str(as.raster(0, nrow=1, ncol=101)) Error in
>>>>>>>>>>> `[.raster`(object,
>>>>>>>>>> seq_len(max.len)) : subscript out of bounds
>>>>>>>>> 
>>>>>>>>>> This seems to do with how str() and "[.raster"() is
>>>>>>>>>> coded; when subsetting as a vector, which str()
>>>>>>>>>> relies on, "[.raster"() still returns a matrix-like
>>>>>>>>>> object, e.g.
>>>>>>>>> 
>>>>>>>>>>> img<- as.raster(1:25, max=25, nrow=5, ncol=5);
>>>>>>>>>>> img[1:2]
>>>>>>>>>> [,1]      [,2]      [,3]      [,4]      [,5] [1,]
>>>>>>>>>> "#0A0A0A" "#3D3D3D" "#707070" "#A3A3A3" "#D6D6D6"
>>>>>>>>>> [2,] "#141414" "#474747" "#7A7A7A" "#ADADAD"
>>>>>>>>>> "#E0E0E0"
>>>>>>>>> 
>>>>>>>>>> compare with:
>>>>>>>>> 
>>>>>>>>>>> as.matrix(img)[1:2]
>>>>>>>>>> [1] "#0A0A0A" "#3D3D3D"
>>>>>>>>> 
>>>>>>>>> 
>>>>>>>>>> The easy but incomplete fix is to do:
>>>>>>>>> 
>>>>>>>>>> str.raster<- function(object, ...) {
>>>>>>>>>> str(as.matrix(object), ...); }
>>>>>>>>> 
>>>>>>>>>> Other suggestions?
>>>>>>>>> 
>>>>>>>>> The informal "raster" class is behaving ``illogical''
>>>>>>>>> in the following sense:
>>>>>>>>> 
>>>>>>>>>> r<- as.raster(0, nrow=1, ncol=11) r[seq_along(r)]
>>>>>>>>> Error in `[.raster`(r, seq_along(r)) : subscript out of
>>>>>>>>> bounds
>>>>>>>>> 
>>>>>>>>> or, here equivalently,
>>>>>>>>>> r[1:length(r)]
>>>>>>>>> Error in `[.raster`(r, 1:length(r)) : subscript out of
>>>>>>>>> bounds
>>>>>>>>> 
>>>>>>>>> When classes do behave in such a way, they definitely
>>>>>>>>> need their own str() method.
>>>>>>>>> 
>>>>>>>>> However, the bug really is in "[.raster": Currently,
>>>>>>>>> r[i] is equivalent to  r[i,]  which is not at all
>>>>>>>>> matrix-like and its help clearly says that subsetting
>>>>>>>>> should work as for matrices. A recent thread on
>>>>>>>>> R-help/R-devel has mentioned the fact that "[" methods
>>>>>>>>> for matrix-like methods need to use both nargs() and
>>>>>>>>> missing() and that "[.dataframe" has been the example
>>>>>>>>> to follow "forever", IIRC already in S and S-plus as of
>>>>>>>>> 20 years ago.
>>>>>>>> The main motivation for non-standard behaviour here is to
>>>>>>>> make sure that a subset of a raster object NEVER produces
>>>>>>>> a vector (because the conversion back to a raster object
>>>>>>>> then produces a single-column raster and that may be a
>>>>>>>> "surprise").  Thanks for making the code more standard
>>>>>>>> and robust.
>>>>>>>> 
>>>>>>>> The r[i] case is still tricky.  The following behaviour
>>>>>>>> is quite convenient ...
>>>>>>>> 
>>>>>>>> r[r == "black"]<- "white"
>>>>>>>> 
>>>>>>>> ... but the next behaviour is quite jarring (at least in
>>>>>>>> terms of the raster image that results from it) ...
>>>>>>>> 
>>>>>>>> r2<- r[1:(nrow(r) + 1)]
>>>>>>>> 
>>>>>>>> So I think there is some justification for further
>>>>>>>> non-standardness to try to ensure that the subset of a
>>>>>>>> raster image always produces a sensible image.  A simple
>>>>>>>> solution would be just to outlaw r[i] for raster objects
>>>>>>>> and force the user to write r[i, ] or r[, j], depending
>>>>>>>> on what they want.
>>>>>>> FYI, I've tried out Martin's updated version at it seems
>>>>>>> like a one-column raster matrix is now returned for r[i],
>>>>>>> e.g.
>>>>>> Yes, that's what I've been looking at ...
>>>>>> 
>>>>>>>> r<- as.raster(1:8, max=8, nrow=2, ncol=4); r
>>>>>>> [,1]      [,2]      [,3]      [,4] [1,] "#202020" "#606060"
>>>>>>> "#9F9F9F" "#DFDFDF" [2,] "#404040" "#808080" "#BFBFBF"
>>>>>>> "#FFFFFF"
>>>>>>> 
>>>>>>>> r[1:length(r)]
>>>>>>> [,1] [1,] "#202020" [2,] "#404040" [3,] "#606060" [4,]
>>>>>>> "#808080" [5,] "#9F9F9F" [6,] "#BFBFBF" [7,] "#DFDFDF" [8,]
>>>>>>> "#FFFFFF"
>>>>>> ... and the above is exactly the sort of thing that will fry
>>>>>> your mind if the image that you are subsetting is, for
>>>>>> example, a photo.
>>>>>> 
>>>>> Why doesn't raster behave consistently like any matrix object?
>>>>> I would expect simply
>>>>> 
>>>>>> r[1:length(r)]
>>>>> [1] "#202020" "#404040" "#606060" "#808080" "#9F9F9F" "#BFBFBF"
>>>>> "#DFDFDF" [8] "#FFFFFF"
>>>>> 
>>>>> Where it's obvious what happened. I saw the comment about the
>>>>> vector but I'm not sure I get it - why don't you want a vector?
>>>>> The raster is no different than matrices - you still need to
>>>>> define the dimensions when going back anyway, moreover what you
>>>>> get now is not consistent at all since there raster never had
>>>>> that dimension anyway ...
>>>>> 
>>>>> Cheers, Simon
>>>> I agree that this would be the most "logical" and notably least
>>>> surprising behavior, which I find the most important argument
>>>> (I'm sorry my last message was cut off as it was sent
>>>> accidentally before being finished completely).
>>> 
>>> I think this behaviour might surprise some ...
>>> 
>>> download.file("http://cran.r-project.org/Rlogo.jpg", "Rlogo.jpg")
>>> library(ReadImages) logo<- read.jpeg("Rlogo.jpg")
>>> 
>>> rLogo<- as.raster(logo) rLogoBit<- rLogo[50:60, 50:60]
>>> 
>>> library(grid) # Original image grid.raster(rLogoBit)
>>> grid.newpage() # Subset produces a vector
>>> grid.raster(rLogoBit[1:length(rLogoBit)])
>>> 
>> 
>> But this should fail IMHO since you're supplying a vector but
>> grid.raster (assuming it's the same as rasterImage) requires a matrix
>> - exactly as you would expect in the matrix case - if a function
>> requires a matrix and you pass a vector, it will bark. I think you
>> are explaining why going to vector *is* desirable ;). In the current
>> case it simply generates the wrong dimensions instead of resulting in
>> a vector, right?
> 
> The raster subsetting always produces a raster, but grid.raster() works with vectors anyway because as.raster() has a vector method.
> 

Well, isn't that the actual problem? ;) It could make sense but it should fail if dimensions are not specified for exactly the reason you mentioned - it is fatal if what you have is really an image ...

Cheers,
Simon


> Anyway, I'm happy to go with things as they now are.  I think at worst it will encourage people to specify two indices when subsetting a raster object, and that's not a bad thing.
> 
> Paul
> 
> 
>> Cheers, Simon
>> 
>> 
>> 
>> 
>> 
>>> Paul
>>> 
>>>> Martin
>>>>>> Paul
>>>>>> 
>>>>>>>> r[1:5,drop=TRUE]
>>>>>>> [,1] [1,] "#202020" [2,] "#404040" [3,] "#606060" [4,]
>>>>>>> "#808080" [5,] "#9F9F9F" Warning message: In `[.raster`(r,
>>>>>>> 1:5, drop = TRUE) : 'drop' is always implicitly FALSE in
>>>>>>> '[.raster'
>>>>>>> 
>>>>>>> Also,
>>>>>>> 
>>>>>>>> r[1:5]<- "white" r
>>>>>>> [,1]    [,2]    [,3]      [,4] [1,] "white" "white" "white"
>>>>>>> "#DFDFDF" [2,] "white" "white" "#BFBFBF" "#FFFFFF"
>>>>>>> 
>>>>>>> /Henrik
>>>>>>> 
>>>>>>>> Paul
>>>>>>>> 
>>>>>>>>> Thank you, Henrik, for the bug report. Martin
>>>>>>>>> 
>>>>>>>>> ______________________________________________
>>> 
>>> -- Dr Paul Murrell Department of Statistics The University of
>>> Auckland Private Bag 92019 Auckland New Zealand 64 9 3737599
>>> x85392 paul at stat.auckland.ac.nz
>>> http://www.stat.auckland.ac.nz/~paul/
>>> 
>>> 
>> 
> 
> -- 
> Dr Paul Murrell
> Department of Statistics
> The University of Auckland
> Private Bag 92019
> Auckland
> New Zealand
> 64 9 3737599 x85392
> paul at stat.auckland.ac.nz
> http://www.stat.auckland.ac.nz/~paul/
> 
> 


From maechler at stat.math.ethz.ch  Mon Feb  7 08:36:41 2011
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 7 Feb 2011 08:36:41 +0100
Subject: [Rd] [.raster bug {was "str() on raster objects fails .."}
In-Reply-To: <0C865A58-A3C5-4A46-AA7E-50439BAAC520@r-project.org>
References: <AANLkTimycPK-3_mj5OPd0eLauAh41r2-Wkrp7j2jo1sw@mail.gmail.com>
	<19783.49835.494142.88222@stat.math.ethz.ch>
	<4D48A96B.9020801@auckland.ac.nz>
	<AANLkTimRBZbzgRfAkE2-VhnFmVRkWz1-cCqeD4VW7O42@mail.gmail.com>
	<4D48B08A.40302@auckland.ac.nz>
	<5251E963-8D1C-46CF-AAB9-39ABFE520229@r-project.org>
	<AANLkTikgSiucEMzfSa2s9YTypkqzYLCab9gJvkGyr0Pz@mail.gmail.com>
	<4D49F024.6090906@stat.auckland.ac.nz>
	<74150327-8264-43FF-A4AC-1D3A2C469B4F@r-project.org>
	<4D4F467C.8040201@auckland.ac.nz>
	<0C865A58-A3C5-4A46-AA7E-50439BAAC520@r-project.org>
Message-ID: <19791.41225.32589.640921@stat.math.ethz.ch>

>>>>> Simon Urbanek <simon.urbanek at r-project.org>
>>>>>     on Sun, 6 Feb 2011 20:53:01 -0500 writes:

    > On Feb 6, 2011, at 8:10 PM, Paul Murrell wrote:

    >> Hi
    >> 
    >> On 3/02/2011 1:23 p.m., Simon Urbanek wrote:
    >>> 
    >>> On Feb 2, 2011, at 7:00 PM, Paul Murrell wrote:
    >>> 
    >>>> Hi
    >>>> 
    >>>> Martin Maechler wrote:
    >>>>> On Wed, Feb 2, 2011 at 23:30, Simon
    >>>>> Urbanek<simon.urbanek at r-project.org> wrote:
>>>>> On Feb 1, 2011, at 8:16 PM, Paul Murrell wrote:
>>>>> 
    >>>>>>> Hi
    >>>>>>> 
    >>>>>>> On 2/02/2011 2:03 p.m., Henrik Bengtsson wrote:
    >>>>>>>> On Tue, Feb 1, 2011 at 4:46 PM, Paul
    >>>>>>>> Murrell<p.murrell at auckland.ac.nz> wrote:
    >>>>>>>>> Hi
    >>>>>>>>> 
    >>>>>>>>> On 1/02/2011 9:22 p.m., Martin Maechler wrote:
    >>>>>>>>>>>>>>> Henrik Bengtsson<hb at biostat.ucsf.edu> on
    >>>>>>>>>>>>>>> Mon, 31 Jan 2011 11:16:59 -0800 writes:
    >>>>>>>>>>> Hi, str() on raster objects fails for certain
    >>>>>>>>>>> dimensions.  For example:
    >>>>>>>>>> 
    >>>>>>>>>>>> str(as.raster(0, nrow=1, ncol=100)) 'raster'
    >>>>>>>>>>>> chr [1, 1:100]
    >>>>>>>>>>> "#000000" "#000000" "#000000" "#000000" ...
    >>>>>>>>>> 
    >>>>>>>>>>>> str(as.raster(0, nrow=1, ncol=101)) Error in
    >>>>>>>>>>>> `[.raster`(object,
    >>>>>>>>>>> seq_len(max.len)) : subscript out of bounds
    >>>>>>>>>> 
    >>>>>>>>>>> This seems to do with how str() and "[.raster"()
    >>>>>>>>>>> is coded; when subsetting as a vector, which
    >>>>>>>>>>> str() relies on, "[.raster"() still returns a
    >>>>>>>>>>> matrix-like object, e.g.
    >>>>>>>>>> 
    >>>>>>>>>>>> img<- as.raster(1:25, max=25, nrow=5, ncol=5);
    >>>>>>>>>>>> img[1:2]
    >>>>>>>>>>> [,1] [,2] [,3] [,4] [,5] [1,] "#0A0A0A"
    >>>>>>>>>>> "#3D3D3D" "#707070" "#A3A3A3" "#D6D6D6" [2,]
    >>>>>>>>>>> "#141414" "#474747" "#7A7A7A" "#ADADAD"
    >>>>>>>>>>> "#E0E0E0"
    >>>>>>>>>> 
    >>>>>>>>>>> compare with:
    >>>>>>>>>> 
    >>>>>>>>>>>> as.matrix(img)[1:2]
    >>>>>>>>>>> [1] "#0A0A0A" "#3D3D3D"
    >>>>>>>>>> 
    >>>>>>>>>> 
    >>>>>>>>>>> The easy but incomplete fix is to do:
    >>>>>>>>>> 
    >>>>>>>>>>> str.raster<- function(object, ...) {
    >>>>>>>>>>> str(as.matrix(object), ...); }
    >>>>>>>>>> 
    >>>>>>>>>>> Other suggestions?
    >>>>>>>>>> 
    >>>>>>>>>> The informal "raster" class is behaving
    >>>>>>>>>> ``illogical'' in the following sense:
    >>>>>>>>>> 
    >>>>>>>>>>> r<- as.raster(0, nrow=1, ncol=11)
    >>>>>>>>>>> r[seq_along(r)]
    >>>>>>>>>> Error in `[.raster`(r, seq_along(r)) : subscript
    >>>>>>>>>> out of bounds
    >>>>>>>>>> 
    >>>>>>>>>> or, here equivalently,
    >>>>>>>>>>> r[1:length(r)]
    >>>>>>>>>> Error in `[.raster`(r, 1:length(r)) : subscript
    >>>>>>>>>> out of bounds
    >>>>>>>>>> 
    >>>>>>>>>> When classes do behave in such a way, they
    >>>>>>>>>> definitely need their own str() method.
    >>>>>>>>>> 
    >>>>>>>>>> However, the bug really is in "[.raster":
    >>>>>>>>>> Currently, r[i] is equivalent to r[i,] which is
    >>>>>>>>>> not at all matrix-like and its help clearly says
    >>>>>>>>>> that subsetting should work as for matrices. A
    >>>>>>>>>> recent thread on R-help/R-devel has mentioned the
    >>>>>>>>>> fact that "[" methods for matrix-like methods
    >>>>>>>>>> need to use both nargs() and missing() and that
    >>>>>>>>>> "[.dataframe" has been the example to follow
    >>>>>>>>>> "forever", IIRC already in S and S-plus as of 20
    >>>>>>>>>> years ago.
    >>>>>>>>> The main motivation for non-standard behaviour
    >>>>>>>>> here is to make sure that a subset of a raster
    >>>>>>>>> object NEVER produces a vector (because the
    >>>>>>>>> conversion back to a raster object then produces a
    >>>>>>>>> single-column raster and that may be a
    >>>>>>>>> "surprise").  Thanks for making the code more
    >>>>>>>>> standard and robust.
    >>>>>>>>> 
    >>>>>>>>> The r[i] case is still tricky.  The following
    >>>>>>>>> behaviour is quite convenient ...
    >>>>>>>>> 
    >>>>>>>>> r[r == "black"]<- "white"
    >>>>>>>>> 
    >>>>>>>>> ... but the next behaviour is quite jarring (at
    >>>>>>>>> least in terms of the raster image that results
    >>>>>>>>> from it) ...
    >>>>>>>>> 
    >>>>>>>>> r2<- r[1:(nrow(r) + 1)]
    >>>>>>>>> 
    >>>>>>>>> So I think there is some justification for further
    >>>>>>>>> non-standardness to try to ensure that the subset
    >>>>>>>>> of a raster image always produces a sensible
    >>>>>>>>> image.  A simple solution would be just to outlaw
    >>>>>>>>> r[i] for raster objects and force the user to
    >>>>>>>>> write r[i, ] or r[, j], depending on what they
    >>>>>>>>> want.
    >>>>>>>> FYI, I've tried out Martin's updated version at it
    >>>>>>>> seems like a one-column raster matrix is now
    >>>>>>>> returned for r[i], e.g.
    >>>>>>> Yes, that's what I've been looking at ...
    >>>>>>> 
    >>>>>>>>> r<- as.raster(1:8, max=8, nrow=2, ncol=4); r
    >>>>>>>> [,1] [,2] [,3] [,4] [1,] "#202020" "#606060"
    >>>>>>>> "#9F9F9F" "#DFDFDF" [2,] "#404040" "#808080"
    >>>>>>>> "#BFBFBF" "#FFFFFF"
    >>>>>>>> 
    >>>>>>>>> r[1:length(r)]
    >>>>>>>> [,1] [1,] "#202020" [2,] "#404040" [3,] "#606060"
    >>>>>>>> [4,] "#808080" [5,] "#9F9F9F" [6,] "#BFBFBF" [7,]
    >>>>>>>> "#DFDFDF" [8,] "#FFFFFF"
    >>>>>>> ... and the above is exactly the sort of thing that
    >>>>>>> will fry your mind if the image that you are
    >>>>>>> subsetting is, for example, a photo.
    >>>>>>> 
>>>>> Why doesn't raster behave consistently like any matrix
    >>>>>>> object?
>>>>> I would expect simply
>>>>> 
    >>>>>>> r[1:length(r)]
>>>>> [1] "#202020" "#404040" "#606060" "#808080" "#9F9F9F"
    >>>>>>> "#BFBFBF"
>>>>> "#DFDFDF" [8] "#FFFFFF"
>>>>> 
>>>>> Where it's obvious what happened. I saw the comment about
    >>>>>>> the
>>>>> vector but I'm not sure I get it - why don't you want a
    >>>>>>> vector?
>>>>> The raster is no different than matrices - you still need
    >>>>>>> to
>>>>> define the dimensions when going back anyway, moreover
    >>>>>>> what you
>>>>> get now is not consistent at all since there raster never
    >>>>>>> had
>>>>> that dimension anyway ...
>>>>> 
>>>>> Cheers, Simon
    >>>>> I agree that this would be the most "logical" and
    >>>>> notably least surprising behavior, which I find the
    >>>>> most important argument (I'm sorry my last message was
    >>>>> cut off as it was sent accidentally before being
    >>>>> finished completely).
    >>>> 
    >>>> I think this behaviour might surprise some ...
    >>>> 
    >>>> download.file("http://cran.r-project.org/Rlogo.jpg",
    >>>> "Rlogo.jpg") library(ReadImages) logo<-
    >>>> read.jpeg("Rlogo.jpg")
    >>>> 
    >>>> rLogo<- as.raster(logo) rLogoBit<- rLogo[50:60, 50:60]
    >>>> 
    >>>> library(grid) # Original image grid.raster(rLogoBit)
    >>>> grid.newpage() # Subset produces a vector
    >>>> grid.raster(rLogoBit[1:length(rLogoBit)])
    >>>> 
    >>> 
>> But this should fail IMHO since you're supplying a vector but
    >>> grid.raster (assuming it's the same as rasterImage)
    >>> requires a matrix - exactly as you would expect in the
    >>> matrix case - if a function requires a matrix and you
    >>> pass a vector, it will bark. I think you are explaining
    >>> why going to vector *is* desirable ;). In the current
    >>> case it simply generates the wrong dimensions instead of
    >>> resulting in a vector, right?
    >> 
    >> The raster subsetting always produces a raster, but
    >> grid.raster() works with vectors anyway because
    >> as.raster() has a vector method.
    >> 

   > Well, isn't that the actual problem? ;) It could make sense but it
   > should fail if dimensions are not specified for exactly the reason you
   > mentioned - it is fatal if what you have is really an image ...

    > Cheers, Simon


    >> Anyway, I'm happy to go with things as they now are.  I
    >> think at worst it will encourage people to specify two
    >> indices when subsetting a raster object, and that's not a
    >> bad thing.
    >> 
    >> Paul

I and (maybe others) are getting a bit lost..

AFAIK:

- Simon proposes that     r[i]  should return a simple character vector
  such that raster images behave more naturally like matrices.

- Paul  seems happy with  r[i]  returning  a (k x 1) raster object
  -- where  k  almost completely unrelated to the original
  dim(r) -- with the argument that raster subsetting must always
  return a "raster".

My vote would be for Simon's proposal, hence raster subsetting
should return a raster only when  [i,j] or [i,] or [,j]  syntax
is used.

Martin


From maechler at stat.math.ethz.ch  Mon Feb  7 09:56:18 2011
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 7 Feb 2011 09:56:18 +0100
Subject: [Rd] print(...,digits=2) behavior
In-Reply-To: <4D4DB9E1.4000306@mcmaster.ca>
References: <4D4DB9E1.4000306@mcmaster.ca>
Message-ID: <19791.46002.901049.478712@stat.math.ethz.ch>

>>>>> Ben Bolker <bbolker at gmail.com>
>>>>>     on Sat, 5 Feb 2011 15:58:09 -0500 writes:

    >   A bug was recently posted to the R bug database (which
    > probably would better have been posted as a query here) as
    > to why this happens:

    >> print(7.921,digits=2)
    > [1] 8
    >> print(7.92,digits=2)
    > [1] 7.9

    >   Two things I *haven't* done to help make sense of this
    > for myself are (1) writing out the binary representations
    > to see if something obvious pops out about why this would
    > be a breakpoint and (2) poking in the source code (I did a
    > little bit of this but gave up).

    >   I know that confusion over rounding etc. is very common,
    > and my first reaction to this sort of question is always
    > that there must be some sort of confusion (either (1) in a
    > FAQ 7.31-ish sort of way that floating point values have
    > finite precision in the first place, or (2) a confusion
    > over the difference between the value and the
    > representation of the number, or (3) more subtly, about
    > the differences among various choices of rounding
    > conventions).

    >   However, in this case I am a bit stumped: I don't see
    > that any of the standard confusions apply.  I grepped the
    > R manuals for "rounding" and didn't find anything useful
    > ...  I have a very strong prior that such a core part of R
    > must be correct, and that therefore I (and the original
    > bug reporter) must be misunderstanding something.

    >   Thoughts/references?

I had started to delve into this after you've posted the bug
report. It is clearly a bug(let),
caused by code that has been in  R  from its very
beginning, at least in the first source code I've seen in 1994.

The problem is not related to digits=2,
but using such a low number of digits shows it more
dramatically, e.g., also

 > print(5.9994, digits=4)
 [1] 5.999
 > print(5.9994001, digits=4)
 [1] 6

Interestingly, the problem seems *not* to be present for
digits = 1 (only).

I haven't found time to mathematically "analyze" it for
determining a correct solution though.
Note that fixing this bug(let) will probably (very slightly)
change a huge number of R outputs .. so there is a caveat,
but nonetheless, we must approach it.

The responsible code is the C function  scientific()
in src/main/format.c 

a somewhat direct R interface to its functionality is given by
R's format.info() :

  > format.info(7.92, digits=2)
  [1] 3 1 0
  > format.info(7.921, digits=2)
  [1] 1 0 0

which means that 7.92 will use 3 characters, 1 digit after the decimal
7.921 will use 1 character, 0 digits after decimal.

The crucial "buggy" part of the code is  {line 180 ff} :

	/* compute number of digits */

	*nsig = R_print.digits;
	for (j = 1; j <= *nsig; j++) {
	    if (fabs(alpha - floor(alpha+0.5)) < eps * alpha) {
		*nsig = j;
		break;
	    }
	    alpha *= 10.0;
	}

where notably
	    if (fabs(alpha - floor(alpha+0.5)) < eps * alpha) {
is not quite the correct check.
Note that  eps = 10^-2  in our case and  alpha = 7.92 or 7.921
and that  8 - 7.921 = 0.079 <  7.921/10^2  is just at the border.

Looking for "all the border cases" is solving the above
analytically with '=' and setting  k = ceiling(alpha) :

> p0 <- function(...) paste(..., sep="")
> k <- 6:9; names(k) <- p0("k=",k)
> d <- 1:5; names(d) <- p0("d=",d)
> xc <- outer(k, 1+10^-d, "/")
> print(xc, digits= 11)
             d=1          d=2         d=3        d=4          d=5
k=6 5.4545454545 5.9405940594 5.994005994 5.99940006 5.9999400006
k=7 6.3636363636 6.9306930693 6.993006993 6.99930007 6.9999300007
k=8 7.2727272727 7.9207920792 7.992007992 7.99920008 7.9999200008
k=9 8.1818181818 8.9108910891 8.991008991 8.99910009 8.9999100009

So we see that for our case, 7.920792... is more exactly the
border case.

One change that is *not* correct is making it an absolute
instead of relative comparison, i.e.  replacing the RHS
eps * alpha  by  eps

Namely, one important purpose of the test is to ensure that e.g.

  print(3.597, digits = 3)

is printed as  3.6   and not 3.60

Now I have had -- since 1997 at least -- an R version of
scientific() for more easy experimentation.
Here's an updated version of that:

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: scientific.R
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110207/d05c4b37/attachment.pl>
-------------- next part --------------

and here some of the experimentation code:

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: scientific-ex.R
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110207/d05c4b37/attachment-0001.pl>
-------------- next part --------------

-------

Now, I'm waiting for comments/suggestions ..
Martin

From clement.calenge at oncfs.gouv.fr  Mon Feb  7 13:36:58 2011
From: clement.calenge at oncfs.gouv.fr (=?ISO-8859-1?Q?Cl=E9ment_Calenge?=)
Date: Mon, 07 Feb 2011 13:36:58 +0100
Subject: [Rd] Error with named chunks in Sweave with the development version
 of R
Message-ID: <4D4FE76A.8020501@oncfs.gouv.fr>

Dear all,

There seems to be a problem with named chunks in Sweave with the version 
of R under development (downloaded yesterday). When I sweave the file 
toto.Rnw described at the end of this mail (Ubuntu 10.04 LTS), the 
function Sweave returns an Internal error:

 > utils::Sweave("toto.Rnw")
Writing to file toto.tex
Processing code chunks ...
  1 : echo term verbatim (label=a)
  2 : echo term verbatim (label=c)
  3 : echo term verbatim (label=b)
  4 : echo term verbatim (label=d)

Error:  chunk 4 (label=d)
Error in eval(expr, envir, enclos) : Internal Sweave error

I did not find the cause of this problem, except that it occurs when 
Sweave is called on a file with named chunks. Note that the function 
Sweave works fine with the latest stable version of R (both R-2.12.1 and 
R-patched). And I found nothing about this problem in the NEWS file of 
the development version. I am not sure, but I wonder whether this might 
be a bug... could you confirm?

 > version
                _
platform       i686-pc-linux-gnu
arch           i686
os             linux-gnu
system         i686, linux-gnu
status         Under development (unstable)
major          2
minor          13.0
year           2011
month          02
day            06
svn rev        54234
language       R
version.string R version 2.13.0 Under development (unstable) (2011-02-06 
r54234)

 > sessionInfo()
R version 2.13.0 Under development (unstable) (2011-02-06 r54234)
Platform: i686-pc-linux-gnu (32-bit)

locale:
  [1] LC_CTYPE=en_US.utf8       LC_NUMERIC=C
  [3] LC_TIME=en_US.utf8        LC_COLLATE=en_US.utf8
  [5] LC_MONETARY=C             LC_MESSAGES=en_US.utf8
  [7] LC_PAPER=en_US.utf8       LC_NAME=C
  [9] LC_ADDRESS=C              LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.utf8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] fortunes_1.4-0  lattice_0.19-13

loaded via a namespace (and not attached):
[1] grid_2.13.0


==============================
% file: toto.Rnw

\documentclass{article}
\usepackage{Sweave}
\begin{document}

<<a>>=
a <- 1
@

<<c>>=
b <- 1
@

<<b>>=
u <- 1:10
@

A test:

<<d>>=
<<a>>
<<b>>
<<c>>
@

\end{document}


-- 
Cl?ment CALENGE
Cellule d'appui ? l'analyse de donn?es
Direction des Etudes et de la Recherche
Office national de la chasse et de la faune sauvage
Saint Benoist - 78610 Auffargis
tel. (33) 01.30.46.54.14


From murdoch.duncan at gmail.com  Mon Feb  7 14:10:17 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 07 Feb 2011 08:10:17 -0500
Subject: [Rd] Error with named chunks in Sweave with the development
 version of R
In-Reply-To: <4D4FE76A.8020501@oncfs.gouv.fr>
References: <4D4FE76A.8020501@oncfs.gouv.fr>
Message-ID: <4D4FEF39.3040001@gmail.com>

Thanks, I'll take a look.  The "internal error" message was intended to 
catch this kind of problem.

Duncan Murdoch

On 07/02/2011 7:36 AM, Cl?ment Calenge wrote:
> Dear all,
>
> There seems to be a problem with named chunks in Sweave with the version
> of R under development (downloaded yesterday). When I sweave the file
> toto.Rnw described at the end of this mail (Ubuntu 10.04 LTS), the
> function Sweave returns an Internal error:
>
>   >  utils::Sweave("toto.Rnw")
> Writing to file toto.tex
> Processing code chunks ...
>    1 : echo term verbatim (label=a)
>    2 : echo term verbatim (label=c)
>    3 : echo term verbatim (label=b)
>    4 : echo term verbatim (label=d)
>
> Error:  chunk 4 (label=d)
> Error in eval(expr, envir, enclos) : Internal Sweave error
>
> I did not find the cause of this problem, except that it occurs when
> Sweave is called on a file with named chunks. Note that the function
> Sweave works fine with the latest stable version of R (both R-2.12.1 and
> R-patched). And I found nothing about this problem in the NEWS file of
> the development version. I am not sure, but I wonder whether this might
> be a bug... could you confirm?
>
>   >  version
>                  _
> platform       i686-pc-linux-gnu
> arch           i686
> os             linux-gnu
> system         i686, linux-gnu
> status         Under development (unstable)
> major          2
> minor          13.0
> year           2011
> month          02
> day            06
> svn rev        54234
> language       R
> version.string R version 2.13.0 Under development (unstable) (2011-02-06
> r54234)
>
>   >  sessionInfo()
> R version 2.13.0 Under development (unstable) (2011-02-06 r54234)
> Platform: i686-pc-linux-gnu (32-bit)
>
> locale:
>    [1] LC_CTYPE=en_US.utf8       LC_NUMERIC=C
>    [3] LC_TIME=en_US.utf8        LC_COLLATE=en_US.utf8
>    [5] LC_MONETARY=C             LC_MESSAGES=en_US.utf8
>    [7] LC_PAPER=en_US.utf8       LC_NAME=C
>    [9] LC_ADDRESS=C              LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.utf8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] fortunes_1.4-0  lattice_0.19-13
>
> loaded via a namespace (and not attached):
> [1] grid_2.13.0
>
>
> ==============================
> % file: toto.Rnw
>
> \documentclass{article}
> \usepackage{Sweave}
> \begin{document}
>
> <<a>>=
> a<- 1
> @
>
> <<c>>=
> b<- 1
> @
>
> <<b>>=
> u<- 1:10
> @
>
> A test:
>
> <<d>>=
> <<a>>
> <<b>>
> <<c>>
> @
>
> \end{document}
>
>


From murdoch.duncan at gmail.com  Mon Feb  7 16:11:39 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 07 Feb 2011 10:11:39 -0500
Subject: [Rd] Error with named chunks in Sweave with the development
 version of R
In-Reply-To: <4D4FE76A.8020501@oncfs.gouv.fr>
References: <4D4FE76A.8020501@oncfs.gouv.fr>
Message-ID: <4D500BAB.2060000@gmail.com>

This should be fixed as of r54259.

Duncan Murdoch

On 07/02/2011 7:36 AM, Cl?ment Calenge wrote:
> Dear all,
>
> There seems to be a problem with named chunks in Sweave with the version
> of R under development (downloaded yesterday). When I sweave the file
> toto.Rnw described at the end of this mail (Ubuntu 10.04 LTS), the
> function Sweave returns an Internal error:
>
>   >  utils::Sweave("toto.Rnw")
> Writing to file toto.tex
> Processing code chunks ...
>    1 : echo term verbatim (label=a)
>    2 : echo term verbatim (label=c)
>    3 : echo term verbatim (label=b)
>    4 : echo term verbatim (label=d)
>
> Error:  chunk 4 (label=d)
> Error in eval(expr, envir, enclos) : Internal Sweave error
>
> I did not find the cause of this problem, except that it occurs when
> Sweave is called on a file with named chunks. Note that the function
> Sweave works fine with the latest stable version of R (both R-2.12.1 and
> R-patched). And I found nothing about this problem in the NEWS file of
> the development version. I am not sure, but I wonder whether this might
> be a bug... could you confirm?
>
>   >  version
>                  _
> platform       i686-pc-linux-gnu
> arch           i686
> os             linux-gnu
> system         i686, linux-gnu
> status         Under development (unstable)
> major          2
> minor          13.0
> year           2011
> month          02
> day            06
> svn rev        54234
> language       R
> version.string R version 2.13.0 Under development (unstable) (2011-02-06
> r54234)
>
>   >  sessionInfo()
> R version 2.13.0 Under development (unstable) (2011-02-06 r54234)
> Platform: i686-pc-linux-gnu (32-bit)
>
> locale:
>    [1] LC_CTYPE=en_US.utf8       LC_NUMERIC=C
>    [3] LC_TIME=en_US.utf8        LC_COLLATE=en_US.utf8
>    [5] LC_MONETARY=C             LC_MESSAGES=en_US.utf8
>    [7] LC_PAPER=en_US.utf8       LC_NAME=C
>    [9] LC_ADDRESS=C              LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.utf8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] fortunes_1.4-0  lattice_0.19-13
>
> loaded via a namespace (and not attached):
> [1] grid_2.13.0
>
>
> ==============================
> % file: toto.Rnw
>
> \documentclass{article}
> \usepackage{Sweave}
> \begin{document}
>
> <<a>>=
> a<- 1
> @
>
> <<c>>=
> b<- 1
> @
>
> <<b>>=
> u<- 1:10
> @
>
> A test:
>
> <<d>>=
> <<a>>
> <<b>>
> <<c>>
> @
>
> \end{document}
>
>


From maechler at stat.math.ethz.ch  Mon Feb  7 18:02:39 2011
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 7 Feb 2011 18:02:39 +0100
Subject: [Rd] axTicks.Rd documentation bug
In-Reply-To: <4D4C1ECC.2090504@mcmaster.ca>
References: <4D4C1ECC.2090504@mcmaster.ca>
Message-ID: <19792.9647.619610.855636@stat.math.ethz.ch>


>>>>> Ben Bolker <bbolker at gmail.com>
>>>>>     on Fri, 04 Feb 2011 10:44:12 -0500 writes:

    > ?axTicks says:

    >     usr: numeric vector of length four, defaulting to
    > ?par("usr")? giving horizontal (?x?) and vertical (?y?)
    > user coordinate limits.

    >  but this is not how the function is implemented -- in
    > fact 'usr' should be a vector of length two corresponding
    > to the appropriate elements of par("usr") [1:2 if side is
    > 1 or 3, 3:4 if side is 2 or 4].

    >   A patch for src/library/graphics/man/axTicks.Rd against
    > the latest SVN is attached (I hope it makes it through).

    >   I also included an extended example of how to use
    > axTicks without reference to an existing plot in the
    > logarithmic axis case: it took me quite a bit of digging
    > in documentation and source code to figure out how to do
    > this for myself, so I think it would be useful to others
    > ...

Thanks a lot, Ben!

I've also added the new example .. though slightly modified.
Notably I'm a tiny bit disappointed ;-) that you were not aware of
the existence of the  extendrange() function ...

Martin Maechler


From wdunlap at tibco.com  Mon Feb  7 20:56:14 2011
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 7 Feb 2011 11:56:14 -0800
Subject: [Rd] as.list(subclassed function) -> cannot coerce type 'closure'
	to vector of type 'list'
Message-ID: <77EB52C6DD32BA4D87471DCD70C8D70003DE1FB8@NA-PA-VBE03.na.tibco.com>

I was looking for all the glm-related 'family' functions
in stats using the following predicate that returns TRUE
for any function whose first argument is called "link".
   is.family <- function(object) is.function(object) &&
            identical(names(as.list(object))[1], "link")

It threw an error when applied to SSfol
   > is.family(SSfol)
   Error in as.vector(x, "list") :
     cannot coerce type 'closure' to vector of type 'list'
but works when I unclass SSfol
   > is.family(unclass(SSfol))
   [1] FALSE

It looks like as.list fails on any function that is assigned
a class:
   > as.list(function(x)x+1)
   $x
   
   
   [[2]]
   x + 1

   > as.list(structure(function(x)x+1, class="unrecognized class name"))
   Error in as.vector(x, "list") :
     cannot coerce type 'closure' to vector of type 'list'

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com 


From luke-tierney at uiowa.edu  Mon Feb  7 21:13:48 2011
From: luke-tierney at uiowa.edu (luke-tierney at uiowa.edu)
Date: Mon, 7 Feb 2011 14:13:48 -0600
Subject: [Rd] as.list(subclassed function) -> cannot coerce type
 'closure' to vector of type 'list'
In-Reply-To: <77EB52C6DD32BA4D87471DCD70C8D70003DE1FB8@NA-PA-VBE03.na.tibco.com>
References: <77EB52C6DD32BA4D87471DCD70C8D70003DE1FB8@NA-PA-VBE03.na.tibco.com>
Message-ID: <alpine.DEB.2.00.1102071410230.1906@luke-inspiron>

For this application I would use names(formals(object)) to extract the
formal arguments.

luke

On Mon, 7 Feb 2011, William Dunlap wrote:

> I was looking for all the glm-related 'family' functions
> in stats using the following predicate that returns TRUE
> for any function whose first argument is called "link".
>   is.family <- function(object) is.function(object) &&
>            identical(names(as.list(object))[1], "link")
>
> It threw an error when applied to SSfol
>   > is.family(SSfol)
>   Error in as.vector(x, "list") :
>     cannot coerce type 'closure' to vector of type 'list'
> but works when I unclass SSfol
>   > is.family(unclass(SSfol))
>   [1] FALSE
>
> It looks like as.list fails on any function that is assigned
> a class:
>   > as.list(function(x)x+1)
>   $x
>
>
>   [[2]]
>   x + 1
>
>   > as.list(structure(function(x)x+1, class="unrecognized class name"))
>   Error in as.vector(x, "list") :
>     cannot coerce type 'closure' to vector of type 'list'
>
> Bill Dunlap
> Spotfire, TIBCO Software
> wdunlap tibco.com
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Luke Tierney
Statistics and Actuarial Science
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From ripley at stats.ox.ac.uk  Mon Feb  7 22:08:41 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 7 Feb 2011 21:08:41 +0000 (GMT)
Subject: [Rd] as.list(subclassed function) -> cannot coerce type
 'closure' to vector of type 'list'
In-Reply-To: <77EB52C6DD32BA4D87471DCD70C8D70003DE1FB8@NA-PA-VBE03.na.tibco.com>
References: <77EB52C6DD32BA4D87471DCD70C8D70003DE1FB8@NA-PA-VBE03.na.tibco.com>
Message-ID: <alpine.LFD.2.02.1102072103500.22528@gannet.stats.ox.ac.uk>

This is because there is an as.list.function, but your classed object 
does not inherit from 'function'.

However, I think coercing to a list is S-like, and in R we have 
formals() and body(), and I think you want the former.

Seems this was a late 2008 change: maybe the author can tell us why it 
was done?

On Mon, 7 Feb 2011, William Dunlap wrote:

> I was looking for all the glm-related 'family' functions
> in stats using the following predicate that returns TRUE
> for any function whose first argument is called "link".
>   is.family <- function(object) is.function(object) &&
>            identical(names(as.list(object))[1], "link")
>
> It threw an error when applied to SSfol
>   > is.family(SSfol)
>   Error in as.vector(x, "list") :
>     cannot coerce type 'closure' to vector of type 'list'
> but works when I unclass SSfol
>   > is.family(unclass(SSfol))
>   [1] FALSE
>
> It looks like as.list fails on any function that is assigned
> a class:
>   > as.list(function(x)x+1)
>   $x
>
>
>   [[2]]
>   x + 1
>
>   > as.list(structure(function(x)x+1, class="unrecognized class name"))
>   Error in as.vector(x, "list") :
>     cannot coerce type 'closure' to vector of type 'list'
>
> Bill Dunlap
> Spotfire, TIBCO Software
> wdunlap tibco.com
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From hadley at rice.edu  Mon Feb  7 22:33:13 2011
From: hadley at rice.edu (Hadley Wickham)
Date: Mon, 7 Feb 2011 15:33:13 -0600
Subject: [Rd] Save and serialize
Message-ID: <AANLkTimQe8suNsPmVryHfNZp1YLFk=RYenFfvn9bh24_@mail.gmail.com>

Hi all,

Is there any relationship between save and serialize?  Do they use the
same algorithm?

Hadley

-- 
Assistant Professor / Dobelman Family Junior Chair
Department of Statistics / Rice University
http://had.co.nz/


From ripley at stats.ox.ac.uk  Mon Feb  7 22:51:04 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 7 Feb 2011 21:51:04 +0000 (GMT)
Subject: [Rd] Save and serialize
In-Reply-To: <AANLkTimQe8suNsPmVryHfNZp1YLFk=RYenFfvn9bh24_@mail.gmail.com>
References: <AANLkTimQe8suNsPmVryHfNZp1YLFk=RYenFfvn9bh24_@mail.gmail.com>
Message-ID: <alpine.LFD.2.02.1102072144470.25585@gannet.stats.ox.ac.uk>

On Mon, 7 Feb 2011, Hadley Wickham wrote:

> Hi all,
>
> Is there any relationship between save and serialize?  Do they use the
> same algorithm?

See the R-internals manual: there is more info in the R-devel version, 
not least because saveRDS() is added to the mix.

But basically serialize() and saveRDS() use the same format, and 
save() writes a header and then serializes a pairlist of the objects 
given.

'The same algorithm' is somewhat misleading here: strictly no, as they 
manage to use four entry points to the code base.

>
> Hadley
>
> -- 
> Assistant Professor / Dobelman Family Junior Chair
> Department of Statistics / Rice University
> http://had.co.nz/
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From hb at biostat.ucsf.edu  Mon Feb  7 23:06:54 2011
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Mon, 7 Feb 2011 14:06:54 -0800
Subject: [Rd] Save and serialize
In-Reply-To: <alpine.LFD.2.02.1102072144470.25585@gannet.stats.ox.ac.uk>
References: <AANLkTimQe8suNsPmVryHfNZp1YLFk=RYenFfvn9bh24_@mail.gmail.com>
	<alpine.LFD.2.02.1102072144470.25585@gannet.stats.ox.ac.uk>
Message-ID: <AANLkTik4_6mxWQDEwicx9-k+CnYTDkYMaLs-rN-wdG8F@mail.gmail.com>

Also, if it it adds any value to what you are looking for, the output
of serialize() also has header information, cf. R-devel thread 'Small
inconsistency in serialize() between R versions and	implications on
digest()' started March 7, 2007:

  http://www.mail-archive.com/r-devel at r-project.org/msg07931.html

It caused us some headaches when trying to generate identical output
of the same input using different versions of R.  It was solved in
that thread.  See code for digest::digest() on how to skip/ignore that
header.

/Henrik


On Mon, Feb 7, 2011 at 1:51 PM, Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
> On Mon, 7 Feb 2011, Hadley Wickham wrote:
>
>> Hi all,
>>
>> Is there any relationship between save and serialize? ?Do they use the
>> same algorithm?
>
> See the R-internals manual: there is more info in the R-devel version, not
> least because saveRDS() is added to the mix.
>
> But basically serialize() and saveRDS() use the same format, and save()
> writes a header and then serializes a pairlist of the objects given.
>
> 'The same algorithm' is somewhat misleading here: strictly no, as they
> manage to use four entry points to the code base.
>
>>
>> Hadley
>>
>> --
>> Assistant Professor / Dobelman Family Junior Chair
>> Department of Statistics / Rice University
>> http://had.co.nz/
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
> --
> Brian D. Ripley, ? ? ? ? ? ? ? ? ?ripley at stats.ox.ac.uk
> Professor of Applied Statistics, ?http://www.stats.ox.ac.uk/~ripley/
> University of Oxford, ? ? ? ? ? ? Tel: ?+44 1865 272861 (self)
> 1 South Parks Road, ? ? ? ? ? ? ? ? ? ? +44 1865 272866 (PA)
> Oxford OX1 3TG, UK ? ? ? ? ? ? ? ?Fax: ?+44 1865 272595
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From savicky at cs.cas.cz  Mon Feb  7 23:14:39 2011
From: savicky at cs.cas.cz (Petr Savicky)
Date: Mon, 7 Feb 2011 23:14:39 +0100
Subject: [Rd] print(...,digits=2) behavior
In-Reply-To: <19791.46002.901049.478712@stat.math.ethz.ch>
References: <4D4DB9E1.4000306@mcmaster.ca>
	<19791.46002.901049.478712@stat.math.ethz.ch>
Message-ID: <20110207221439.GA9407@cs.cas.cz>

On Mon, Feb 07, 2011 at 09:56:18AM +0100, Martin Maechler wrote:
> >>>>> Ben Bolker <bbolker at gmail.com>
> >>>>>     on Sat, 5 Feb 2011 15:58:09 -0500 writes:
> 
>     >   A bug was recently posted to the R bug database (which
>     > probably would better have been posted as a query here) as
>     > to why this happens:
> 
>     >> print(7.921,digits=2)
>     > [1] 8
>     >> print(7.92,digits=2)
>     > [1] 7.9
> 
>     >   Two things I *haven't* done to help make sense of this
>     > for myself are (1) writing out the binary representations
>     > to see if something obvious pops out about why this would
>     > be a breakpoint and (2) poking in the source code (I did a
>     > little bit of this but gave up).
> 
>     >   I know that confusion over rounding etc. is very common,
>     > and my first reaction to this sort of question is always
>     > that there must be some sort of confusion (either (1) in a
>     > FAQ 7.31-ish sort of way that floating point values have
>     > finite precision in the first place, or (2) a confusion
>     > over the difference between the value and the
>     > representation of the number, or (3) more subtly, about
>     > the differences among various choices of rounding
>     > conventions).
> 
>     >   However, in this case I am a bit stumped: I don't see
>     > that any of the standard confusions apply.  I grepped the
>     > R manuals for "rounding" and didn't find anything useful
>     > ...  I have a very strong prior that such a core part of R
>     > must be correct, and that therefore I (and the original
>     > bug reporter) must be misunderstanding something.
> 
>     >   Thoughts/references?
> 
> I had started to delve into this after you've posted the bug
> report. It is clearly a bug(let),
> caused by code that has been in  R  from its very
> beginning, at least in the first source code I've seen in 1994.
> 
> The problem is not related to digits=2,
> but using such a low number of digits shows it more
> dramatically, e.g., also
> 
>  > print(5.9994, digits=4)
>  [1] 5.999
>  > print(5.9994001, digits=4)
>  [1] 6

I think that this may be a consequence of the following
analysis, which i did some time ago using the source code
of scientific() function in src/main/format.c. The
conclusion was the following.

Printing to k digits looks for the smallest number of
digits l <= k so that the relative error of the printed
mantissa (significand) is at most 10^-k. If the mantissa
begins with a digit less than 5, then this condition is
stronger than having absolute error at most 5*10^-k. So,
in this case, we cannot get lower accuracy than rounding
to k digits.

If the mantissa begins with 5 or more, then having relative
error at most 10^-k is a weaker condition than having absolute
error at most 5*10^-k. In this case, the chosen l may be
smaller than k even if the printed number has larger error
than the number rounded to k digits.

This may be seen in the following example

  xx <- 8 + (6:10)*10^-7
  for (x in xx) print(x)

  [1] 8
  [1] 8
  [1] 8
  [1] 8.000001
  [1] 8.000001

where all the printed numbers are 8.000001 if rounded
to 7 digits.

The cases 

  print(7.921,digits=2)
  [1] 8

  print(7.92,digits=2)
  [1] 7.9

seem to have the same explanation. The relative errors of the
numbers rounded to a single digit are

  (8 - 7.921)/7.921
  [1] 0.009973488

  (8 - 7.92)/7.92
  [1] 0.01010101

In the first case, this is less than 10^-2 and so, l = 1
is used. In the second case, the relative error for l = 1
is larger than 10^-2 an so, l = 2 is chosen.

In the cases

  print(5.9994, digits=4)
  [1] 5.999
  print(5.9994001, digits=4)
  [1] 6

the relative errors of one digit output are

  (6 - 5.9994)/5.9994
  [1] 0.00010001
  
  (6 - 5.9994001)/5.9994001
  [1] 9.999333e-05

Here, one digit output is chosen if the relative error is
less than 10^-4 and not otherwise.

Petr Savicky.


From ripley at stats.ox.ac.uk  Mon Feb  7 23:45:26 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 7 Feb 2011 22:45:26 +0000 (GMT)
Subject: [Rd] R-devel on FreeBSD: Support for C99 complex type is
 required
In-Reply-To: <4D4EE672.6080601@gwdg.de>
References: <4D4EAFCE.6020004@gwdg.de>
	<alpine.LFD.2.00.1102061507430.15472@auk.stats.ox.ac.uk>
	<4D4ED172.9090402@gwdg.de>
	<alpine.LFD.2.00.1102061710320.22661@auk.stats.ox.ac.uk>
	<4D4EE672.6080601@gwdg.de>
Message-ID: <alpine.LFD.2.02.1102072237210.30160@gannet.stats.ox.ac.uk>

A follow-up on this.

Cygwin has recently[*] added support for C99 complex math, taken from 
NetBSD with code that is very similar to that from Steven Moshier 
available via http://www.moshier.net/c9x_readme.html.

That code isn't entirely right, especially not at the cuts on the 
inverse functions where C99 mandates what cut is used (and neither 
glibc nor Mac OS X have it correct).

I would expect that the current R-devel (I mean an SVN checkout now) 
should build on your platform, substituting the missing functions by 
ones based on earlier code.  There may be a few more tweaks required, 
but I have corrected several errors in the versions FreeBSD would have 
used in R 2.12.1.

[*] AFAICS not yet released in Cygwin, but in newlib 1.19.0.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From hadley at rice.edu  Tue Feb  8 00:15:46 2011
From: hadley at rice.edu (Hadley Wickham)
Date: Mon, 7 Feb 2011 17:15:46 -0600
Subject: [Rd] Save and serialize
In-Reply-To: <AANLkTik4_6mxWQDEwicx9-k+CnYTDkYMaLs-rN-wdG8F@mail.gmail.com>
References: <AANLkTimQe8suNsPmVryHfNZp1YLFk=RYenFfvn9bh24_@mail.gmail.com>
	<alpine.LFD.2.02.1102072144470.25585@gannet.stats.ox.ac.uk>
	<AANLkTik4_6mxWQDEwicx9-k+CnYTDkYMaLs-rN-wdG8F@mail.gmail.com>
Message-ID: <AANLkTimQQPzHnrxtLBS2V3xVMnLmsaJ2tKj0_ZN4pfaP@mail.gmail.com>

Thanks to you both for the information - that's exactly the level of
detail I was looking for.  I ask because I want to play around with a
function to automatically cache expensive operations to disk, in a way
that can be lazy loaded on the next run.

Hadley

On Mon, Feb 7, 2011 at 4:06 PM, Henrik Bengtsson <hb at biostat.ucsf.edu> wrote:
> Also, if it it adds any value to what you are looking for, the output
> of serialize() also has header information, cf. R-devel thread 'Small
> inconsistency in serialize() between R versions and ? ? implications on
> digest()' started March 7, 2007:
>
> ?http://www.mail-archive.com/r-devel at r-project.org/msg07931.html
>
> It caused us some headaches when trying to generate identical output
> of the same input using different versions of R. ?It was solved in
> that thread. ?See code for digest::digest() on how to skip/ignore that
> header.
>
> /Henrik
>
>
> On Mon, Feb 7, 2011 at 1:51 PM, Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
>> On Mon, 7 Feb 2011, Hadley Wickham wrote:
>>
>>> Hi all,
>>>
>>> Is there any relationship between save and serialize? ?Do they use the
>>> same algorithm?
>>
>> See the R-internals manual: there is more info in the R-devel version, not
>> least because saveRDS() is added to the mix.
>>
>> But basically serialize() and saveRDS() use the same format, and save()
>> writes a header and then serializes a pairlist of the objects given.
>>
>> 'The same algorithm' is somewhat misleading here: strictly no, as they
>> manage to use four entry points to the code base.
>>
>>>
>>> Hadley
>>>
>>> --
>>> Assistant Professor / Dobelman Family Junior Chair
>>> Department of Statistics / Rice University
>>> http://had.co.nz/
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>
>> --
>> Brian D. Ripley, ? ? ? ? ? ? ? ? ?ripley at stats.ox.ac.uk
>> Professor of Applied Statistics, ?http://www.stats.ox.ac.uk/~ripley/
>> University of Oxford, ? ? ? ? ? ? Tel: ?+44 1865 272861 (self)
>> 1 South Parks Road, ? ? ? ? ? ? ? ? ? ? +44 1865 272866 (PA)
>> Oxford OX1 3TG, UK ? ? ? ? ? ? ? ?Fax: ?+44 1865 272595
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
>



-- 
Assistant Professor / Dobelman Family Junior Chair
Department of Statistics / Rice University
http://had.co.nz/


From hb at biostat.ucsf.edu  Tue Feb  8 01:21:50 2011
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Mon, 7 Feb 2011 16:21:50 -0800
Subject: [Rd] Save and serialize
In-Reply-To: <AANLkTimQQPzHnrxtLBS2V3xVMnLmsaJ2tKj0_ZN4pfaP@mail.gmail.com>
References: <AANLkTimQe8suNsPmVryHfNZp1YLFk=RYenFfvn9bh24_@mail.gmail.com>
	<alpine.LFD.2.02.1102072144470.25585@gannet.stats.ox.ac.uk>
	<AANLkTik4_6mxWQDEwicx9-k+CnYTDkYMaLs-rN-wdG8F@mail.gmail.com>
	<AANLkTimQQPzHnrxtLBS2V3xVMnLmsaJ2tKj0_ZN4pfaP@mail.gmail.com>
Message-ID: <AANLkTikSttcXZ5xDEEFBUuL0tJU=5TDv4OeCm+hpH0C7@mail.gmail.com>

On Mon, Feb 7, 2011 at 3:15 PM, Hadley Wickham <hadley at rice.edu> wrote:
> Thanks to you both for the information - that's exactly the level of
> detail I was looking for. ?I ask because I want to play around with a
> function to automatically cache expensive operations to disk, in a way
> that can be lazy loaded on the next run.

So starting with digest v0.3.0 (April 2007), the digest() method can
be considered consistent across R version (in addition to across R
sessions).


FYI, recently in R-devel serialize(), which digest() relies on, gained
a 'version' argument reserved for future usage.  From NEWS:

- serialize() and unserialize() are no longer described as
?experimental?. The interface is now regarded as stable, although the
serialization format may well change in future releases. (serialize()
has a new argument version which would allow the current format to be
written if that happens.)

I've tested, and the introduction of this argument was done such that
the serialized object is identical to as before (R <= 2.12.x).  Thus,
digest() will generate the same output also in R v2.13.0.  At some
point, we will add an option to digest() for specifying what 'version'
value should be passed to serialize(), but it doesn't sound like it is
too urgent to add that.  Any updates to digest() will also be backward
compatible, so as long as you use digest() you shouldn't have to worry
about consistency.

/Henrik

>
> Hadley
>
> On Mon, Feb 7, 2011 at 4:06 PM, Henrik Bengtsson <hb at biostat.ucsf.edu> wrote:
>> Also, if it it adds any value to what you are looking for, the output
>> of serialize() also has header information, cf. R-devel thread 'Small
>> inconsistency in serialize() between R versions and ? ? implications on
>> digest()' started March 7, 2007:
>>
>> ?http://www.mail-archive.com/r-devel at r-project.org/msg07931.html
>>
>> It caused us some headaches when trying to generate identical output
>> of the same input using different versions of R. ?It was solved in
>> that thread. ?See code for digest::digest() on how to skip/ignore that
>> header.
>>
>> /Henrik
>>
>>
>> On Mon, Feb 7, 2011 at 1:51 PM, Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
>>> On Mon, 7 Feb 2011, Hadley Wickham wrote:
>>>
>>>> Hi all,
>>>>
>>>> Is there any relationship between save and serialize? ?Do they use the
>>>> same algorithm?
>>>
>>> See the R-internals manual: there is more info in the R-devel version, not
>>> least because saveRDS() is added to the mix.
>>>
>>> But basically serialize() and saveRDS() use the same format, and save()
>>> writes a header and then serializes a pairlist of the objects given.
>>>
>>> 'The same algorithm' is somewhat misleading here: strictly no, as they
>>> manage to use four entry points to the code base.
>>>
>>>>
>>>> Hadley
>>>>
>>>> --
>>>> Assistant Professor / Dobelman Family Junior Chair
>>>> Department of Statistics / Rice University
>>>> http://had.co.nz/
>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>
>>>
>>> --
>>> Brian D. Ripley, ? ? ? ? ? ? ? ? ?ripley at stats.ox.ac.uk
>>> Professor of Applied Statistics, ?http://www.stats.ox.ac.uk/~ripley/
>>> University of Oxford, ? ? ? ? ? ? Tel: ?+44 1865 272861 (self)
>>> 1 South Parks Road, ? ? ? ? ? ? ? ? ? ? +44 1865 272866 (PA)
>>> Oxford OX1 3TG, UK ? ? ? ? ? ? ? ?Fax: ?+44 1865 272595
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>
>>
>
>
>
> --
> Assistant Professor / Dobelman Family Junior Chair
> Department of Statistics / Rice University
> http://had.co.nz/
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From luke-tierney at uiowa.edu  Tue Feb  8 16:34:04 2011
From: luke-tierney at uiowa.edu (luke-tierney at uiowa.edu)
Date: Tue, 8 Feb 2011 09:34:04 -0600
Subject: [Rd] bug in codetools/R CMD check?
In-Reply-To: <257810.82307.qm@web29520.mail.ird.yahoo.com>
References: <257810.82307.qm@web29520.mail.ird.yahoo.com>
Message-ID: <alpine.DEB.2.00.1102080933330.1906@luke-inspiron>

Thanks -- will try to have a look sometime soon.

luke

On Thu, 3 Feb 2011, Hin-Tak Leung wrote:

> Hi Mr Tierney,
>
> I have noticed an error message from R 1.12.x's CMD check for a while (apparently prof Ripley completely rewrote CMD check in R 1.12+)
> e.g.:
> http://bioconductor.org/checkResults/2.7/bioc-LATEST/snpMatrix/lamb2-checksrc.html
>
> ----------------
> * checking R code for possible problems ... NOTE
> Warning: non-unique value when setting 'row.names': ?new?
> Error in `row.names<-.data.frame`(`*tmp*`, value = c("1", "new", "new" :
>  duplicate 'row.names' are not allowed
> Calls: <Anonymous> ... rownames<- -> row.names<- -> row.names<-.data.frame
> Execution halted
> -----------------
>
> yet everything is okey dokey at http://bioconductor.org/checkResults/2.7/bioc-LATEST/#S under the snpMatrix entry.
>
> I believe it might be a bug in codetools::incLocalSrcInfo (used by "R CMD check") and here is what I think the fix(?) - but I am not entirely sure what that routine does and why other package writers haven't noticed similiar problems before:
>
> diff -ur codetools/R/codetools.R codetools-fix/R/codetools.R
> --- codetools/R/codetools.R	2011-01-07 15:52:58.000000000 +0000
> +++ codetools-fix/R/codetools.R	2011-02-03 10:03:54.000000000 +0000
> @@ -823,8 +823,9 @@
>     new <- list(srcfile = if (is.null(w$srcfile)) NA_character_ else w$srcfile,
>                 frow = if (is.null(w$frow)) NA_integer_ else w$frow,
>                 lrow = if (is.null(w$lrow)) NA_integer_ else w$lrow)
> +    new <- as.data.frame(new, stringsAsFactors = FALSE)
>     if (is.null(value))
> -        value <- as.data.frame(new, stringsAsFactors = FALSE)
> +        value <- new
>     else
>         value <- rbind(value, new)
>     assign("srcinfo", value, entry)
>
>
> Apply this "fix" would result in snpMatrix's "R CMD check" churning out:
>
> ---------------------
> .ld.withmany: local variable ?names.components? assigned but may not be used
> .ld.withmany: local variable ?nsnps.for.each? assigned but may not be used
> misinherits: local variable ?nc.snps? assigned but may not be used
> misinherits: local variable ?nr.snps? assigned but may not be used
> qq.chisq: local variable ?lab? assigned but may not be used
> read.HapMap.data: local variable ?base? assigned but may not be used
> read.HapMap.data: local variable ?build? assigned but may not be used
> read.HapMap.data: local variable ?finish? assigned but may not be used
> read.HapMap.data: local variable ?strand? assigned but may not be used
> tdt.snp: local variable ?nc.snps? assigned but may not be used
> tdt.snp: local variable ?nr.snps? assigned but may not be used
> ---------------------
>
> which is more like expected check warnings.
>
> Care to comment?
>
> Hin-Tak Leung
>
>
>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Luke Tierney
Statistics and Actuarial Science
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu

From htl10 at users.sourceforge.net  Tue Feb  8 17:06:10 2011
From: htl10 at users.sourceforge.net (Hin-Tak Leung)
Date: Tue, 8 Feb 2011 16:06:10 +0000 (GMT)
Subject: [Rd] bug in codetools/R CMD check?
In-Reply-To: <alpine.DEB.2.00.1102080933330.1906@luke-inspiron>
Message-ID: <189791.22034.qm@web29519.mail.ird.yahoo.com>

--- On Tue, 8/2/11, luke-tierney at uiowa.edu <luke-tierney at uiowa.edu> wrote:

> From: luke-tierney at uiowa.edu <luke-tierney at uiowa.edu>
> Subject: Re: [Rd] bug in codetools/R CMD check?
> To: "Hin-Tak Leung" <htl10 at users.sourceforge.net>
> Cc: david.clayton at cimr.cam.ac.uk, r-devel at r-project.org
> Date: Tuesday, 8 February, 2011, 15:34
> Thanks -- will try to have a look
> sometime soon.
> 
> luke


Thanks.

Also, regardless of whether that's a bug in codetools or snpMatrix (I am okay if you turn this around to say there is some coding style we shouldn't do in there, for which I'd apologize), there seems to be a small bug or inconsistency, and certainly in R or codetools, in that the codetools message is shown in all 4 platforms - linux, mac, win32, win64 - but the error status, whether it is correct or not, only propagate back up to the "R CMD check" harness in the case of win64 and not for the other 3 platforms. It should pass or fail with a warning consistently on all platforms.

Hin-Tak 

> On Thu, 3 Feb 2011, Hin-Tak Leung wrote:
> 
> > Hi Mr Tierney,
> >
> > I have noticed an error message from R 1.12.x's CMD
> check for a while (apparently prof Ripley completely rewrote
> CMD check in R 1.12+)
> > e.g.:
> > http://bioconductor.org/checkResults/2.7/bioc-LATEST/snpMatrix/lamb2-checksrc.html
> >
> > ----------------
> > * checking R code for possible problems ... NOTE
> > Warning: non-unique value when setting 'row.names':
> ?new?
> > Error in `row.names<-.data.frame`(`*tmp*`, value =
> c("1", "new", "new" :
> >? duplicate 'row.names' are not allowed
> > Calls: <Anonymous> ... rownames<- ->
> row.names<- -> row.names<-.data.frame
> > Execution halted
> > -----------------
> >
> > yet everything is okey dokey at http://bioconductor.org/checkResults/2.7/bioc-LATEST/#S
> under the snpMatrix entry.
> >
> > I believe it might be a bug in
> codetools::incLocalSrcInfo (used by "R CMD check") and here
> is what I think the fix(?) - but I am not entirely sure what
> that routine does and why other package writers haven't
> noticed similiar problems before:
> >
> > diff -ur codetools/R/codetools.R
> codetools-fix/R/codetools.R
> > --- codetools/R/codetools.R???
> 2011-01-07 15:52:58.000000000 +0000
> > +++ codetools-fix/R/codetools.R???
> 2011-02-03 10:03:54.000000000 +0000
> > @@ -823,8 +823,9 @@
> >? ???new <- list(srcfile = if
> (is.null(w$srcfile)) NA_character_ else w$srcfile,
> >? ? ? ? ? ? ?
> ???frow = if (is.null(w$frow)) NA_integer_
> else w$frow,
> >? ? ? ? ? ? ?
> ???lrow = if (is.null(w$lrow)) NA_integer_
> else w$lrow)
> > +? ? new <- as.data.frame(new,
> stringsAsFactors = FALSE)
> >? ???if (is.null(value))
> > -? ? ? ? value <-
> as.data.frame(new, stringsAsFactors = FALSE)
> > +? ? ? ? value <- new
> >? ???else
> >? ? ? ???value <-
> rbind(value, new)
> >? ???assign("srcinfo", value,
> entry)
> >
> >
> > Apply this "fix" would result in snpMatrix's "R CMD
> check" churning out:
> >
> > ---------------------
> > .ld.withmany: local variable ?names.components?
> assigned but may not be used
> > .ld.withmany: local variable ?nsnps.for.each?
> assigned but may not be used
> > misinherits: local variable ?nc.snps? assigned but
> may not be used
> > misinherits: local variable ?nr.snps? assigned but
> may not be used
> > qq.chisq: local variable ?lab? assigned but may
> not be used
> > read.HapMap.data: local variable ?base? assigned
> but may not be used
> > read.HapMap.data: local variable ?build? assigned
> but may not be used
> > read.HapMap.data: local variable ?finish? assigned
> but may not be used
> > read.HapMap.data: local variable ?strand? assigned
> but may not be used
> > tdt.snp: local variable ?nc.snps? assigned but may
> not be used
> > tdt.snp: local variable ?nr.snps? assigned but may
> not be used
> > ---------------------
> >
> > which is more like expected check warnings.
> >
> > Care to comment?
> >
> > Hin-Tak Leung
> >
> >
> >
> >
> > ______________________________________________
> > R-devel at r-project.org
> mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> -- 
> Luke Tierney
> Statistics and Actuarial Science
> Ralph E. Wareham Professor of Mathematical Sciences
> University of Iowa? ? ? ? ? ?
> ? ? ? Phone:? ? ? ?
> ? ???319-335-3386
> Department of Statistics and? ? ? ?
> Fax:? ? ? ? ? ?
> ???319-335-3017
> ? ? Actuarial Science
> 241 Schaeffer Hall? ? ? ? ? ?
> ? ? ? email:? ? ? luke at stat.uiowa.edu
> Iowa City, IA 52242? ? ? ? ?
> ? ? ???WWW:? http://www.stat.uiowa.edu





From ripley at stats.ox.ac.uk  Tue Feb  8 18:36:02 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 8 Feb 2011 17:36:02 +0000 (GMT)
Subject: [Rd] bug in codetools/R CMD check?
In-Reply-To: <189791.22034.qm@web29519.mail.ird.yahoo.com>
References: <189791.22034.qm@web29519.mail.ird.yahoo.com>
Message-ID: <alpine.LFD.2.02.1102081730560.12643@gannet.stats.ox.ac.uk>

On Tue, 8 Feb 2011, Hin-Tak Leung wrote:

> --- On Tue, 8/2/11, luke-tierney at uiowa.edu <luke-tierney at uiowa.edu> wrote:
>
>> From: luke-tierney at uiowa.edu <luke-tierney at uiowa.edu>
>> Subject: Re: [Rd] bug in codetools/R CMD check?
>> To: "Hin-Tak Leung" <htl10 at users.sourceforge.net>
>> Cc: david.clayton at cimr.cam.ac.uk, r-devel at r-project.org
>> Date: Tuesday, 8 February, 2011, 15:34
>> Thanks -- will try to have a look
>> sometime soon.
>>
>> luke
>
>
> Thanks.
>
> Also, regardless of whether that's a bug in codetools or snpMatrix 
> (I am okay if you turn this around to say there is some coding style 
> we shouldn't do in there, for which I'd apologize), there seems to 
> be a small bug or inconsistency, and certainly in R or codetools, in 
> that the codetools message is shown in all 4 platforms - linux, mac, 
> win32, win64 - but the error status, whether it is correct or not, 
> only propagate back up to the "R CMD check" harness in the case of 
> win64 and not for the other 3 platforms. It should pass or fail with 
> a warning consistently on all platforms.

Are you sure this is the same version of R and codetools?  If you mean 
BioC's check farm, that often has version skew.  I see the message 
consistently on all my platforms ....

>
> Hin-Tak
>
>> On Thu, 3 Feb 2011, Hin-Tak Leung wrote:
>>
>>> Hi Mr Tierney,
>>>
>>> I have noticed an error message from R 1.12.x's CMD
>> check for a while (apparently prof Ripley completely rewrote
>> CMD check in R 1.12+)
>>> e.g.:
>>> http://bioconductor.org/checkResults/2.7/bioc-LATEST/snpMatrix/lamb2-checksrc.html
>>>
>>> ----------------
>>> * checking R code for possible problems ... NOTE
>>> Warning: non-unique value when setting 'row.names':
>> ?new?
>>> Error in `row.names<-.data.frame`(`*tmp*`, value =
>> c("1", "new", "new" :
>>> ? duplicate 'row.names' are not allowed
>>> Calls: <Anonymous> ... rownames<- ->
>> row.names<- -> row.names<-.data.frame
>>> Execution halted
>>> -----------------
>>>
>>> yet everything is okey dokey at http://bioconductor.org/checkResults/2.7/bioc-LATEST/#S
>> under the snpMatrix entry.
>>>
>>> I believe it might be a bug in
>> codetools::incLocalSrcInfo (used by "R CMD check") and here
>> is what I think the fix(?) - but I am not entirely sure what
>> that routine does and why other package writers haven't
>> noticed similiar problems before:
>>>
>>> diff -ur codetools/R/codetools.R
>> codetools-fix/R/codetools.R
>>> --- codetools/R/codetools.R???
>> 2011-01-07 15:52:58.000000000 +0000
>>> +++ codetools-fix/R/codetools.R???
>> 2011-02-03 10:03:54.000000000 +0000
>>> @@ -823,8 +823,9 @@
>>> ? ???new <- list(srcfile = if
>> (is.null(w$srcfile)) NA_character_ else w$srcfile,
>>> ? ? ? ? ? ? ?
>> ???frow = if (is.null(w$frow)) NA_integer_
>> else w$frow,
>>> ? ? ? ? ? ? ?
>> ???lrow = if (is.null(w$lrow)) NA_integer_
>> else w$lrow)
>>> +? ? new <- as.data.frame(new,
>> stringsAsFactors = FALSE)
>>> ? ???if (is.null(value))
>>> -? ? ? ? value <-
>> as.data.frame(new, stringsAsFactors = FALSE)
>>> +? ? ? ? value <- new
>>> ? ???else
>>> ? ? ? ???value <-
>> rbind(value, new)
>>> ? ???assign("srcinfo", value,
>> entry)
>>>
>>>
>>> Apply this "fix" would result in snpMatrix's "R CMD
>> check" churning out:
>>>
>>> ---------------------
>>> .ld.withmany: local variable ?names.components?
>> assigned but may not be used
>>> .ld.withmany: local variable ?nsnps.for.each?
>> assigned but may not be used
>>> misinherits: local variable ?nc.snps? assigned but
>> may not be used
>>> misinherits: local variable ?nr.snps? assigned but
>> may not be used
>>> qq.chisq: local variable ?lab? assigned but may
>> not be used
>>> read.HapMap.data: local variable ?base? assigned
>> but may not be used
>>> read.HapMap.data: local variable ?build? assigned
>> but may not be used
>>> read.HapMap.data: local variable ?finish? assigned
>> but may not be used
>>> read.HapMap.data: local variable ?strand? assigned
>> but may not be used
>>> tdt.snp: local variable ?nc.snps? assigned but may
>> not be used
>>> tdt.snp: local variable ?nr.snps? assigned but may
>> not be used
>>> ---------------------
>>>
>>> which is more like expected check warnings.
>>>
>>> Care to comment?
>>>
>>> Hin-Tak Leung
>>>
>>>
>>>
>>>
>>> ______________________________________________
>>> R-devel at r-project.org
>> mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>> --
>> Luke Tierney
>> Statistics and Actuarial Science
>> Ralph E. Wareham Professor of Mathematical Sciences
>> University of Iowa? ? ? ? ? ?
>> ? ? ? Phone:? ? ? ?
>> ? ???319-335-3386
>> Department of Statistics and? ? ? ?
>> Fax:? ? ? ? ? ?
>> ???319-335-3017
>> ? ? Actuarial Science
>> 241 Schaeffer Hall? ? ? ? ? ?
>> ? ? ? email:? ? ? luke at stat.uiowa.edu
>> Iowa City, IA 52242? ? ? ? ?
>> ? ? ???WWW:? http://www.stat.uiowa.edu
>
>
>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From adrian at waddell.ch  Tue Feb  8 19:06:15 2011
From: adrian at waddell.ch (Adrian Waddell)
Date: Tue, 08 Feb 2011 13:06:15 -0500
Subject: [Rd] Compiling a Tcl extension for an R package
Message-ID: <4D518617.10604@waddell.ch>

Dear R developers,

I plan to upload a first version of my R package RnavGraph to the R CRAN
server in a week or two. However I'm still struggling with an image
resizing function written in C as a tcl extension. I did all my
development in Ubuntu, and everything works fine in Ubuntu, however my
attempts to compile this C function under Windows or OSX have all failed.

I provide a minimal self contained example at the end of this post. I
also wrapped this example in a minimal R package (less than 20 lines of
code!) and it can be downloaded at
http://www.waddell.ch/RnavGraph/TclHelloWorld.zip

Can somebody help me to get this package to compile correctly under
Linux, Windows and OSX? (i.e. writing a configure script with the
correct compile commands).

Thanks,

Adrian Waddell



###########################

C Code (save as hello.c):

#include <tcl.h>
static int Hello_Cmd(ClientData cdata, Tcl_Interp *interp, int objc,
Tcl_Obj *const objv[]) {
  Tcl_SetObjResult(interp, Tcl_NewStringObj("Hello, World!", -1));
  return TCL_OK;
}
int DLLEXPORT Hello_Init(Tcl_Interp *interp) {
  Tcl_CreateObjCommand(interp, "hello", Hello_Cmd, NULL, NULL);
  return TCL_OK;
}

which can be compiled (under Ubuntu 10.04) with:
gcc -shared -o hello.so -DUSE_TCL_STUBS -I/usr/include/tcl8.5/ hello.c
-L/usr/lib/ -ltclstub8.5 -fPIC

and used within an R session with

library(tcltk)
.Tcl('load ./hello[info sharedlibextension]')
tcl('hello')


From htl10 at users.sourceforge.net  Tue Feb  8 19:24:35 2011
From: htl10 at users.sourceforge.net (Hin-Tak Leung)
Date: Tue, 8 Feb 2011 18:24:35 +0000 (GMT)
Subject: [Rd] bug in codetools/R CMD check?
In-Reply-To: <alpine.LFD.2.02.1102081730560.12643@gannet.stats.ox.ac.uk>
Message-ID: <133261.3368.qm@web29506.mail.ird.yahoo.com>

--- On Tue, 8/2/11, Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:

> From: Prof Brian Ripley <ripley at stats.ox.ac.uk>
> Subject: Re: [Rd] bug in codetools/R CMD check?
> To: "Hin-Tak Leung" <htl10 at users.sourceforge.net>
> Cc: luke-tierney at uiowa.edu, david.clayton at cimr.cam.ac.uk, r-devel at r-project.org
> Date: Tuesday, 8 February, 2011, 17:36
> On Tue, 8 Feb 2011, Hin-Tak Leung
> wrote:
> 
> > --- On Tue, 8/2/11, luke-tierney at uiowa.edu
> <luke-tierney at uiowa.edu>
> wrote:
> >
> >> From: luke-tierney at uiowa.edu
> <luke-tierney at uiowa.edu>
> >> Subject: Re: [Rd] bug in codetools/R CMD check?
> >> To: "Hin-Tak Leung" <htl10 at users.sourceforge.net>
> >> Cc: david.clayton at cimr.cam.ac.uk,
> r-devel at r-project.org
> >> Date: Tuesday, 8 February, 2011, 15:34
> >> Thanks -- will try to have a look
> >> sometime soon.
> >>
> >> luke
> >
> >
> > Thanks.
> >
> > Also, regardless of whether that's a bug in codetools
> or snpMatrix 
> > (I am okay if you turn this around to say there is
> some coding style 
> > we shouldn't do in there, for which I'd apologize),
> there seems to 
> > be a small bug or inconsistency, and certainly in R or
> codetools, in 
> > that the codetools message is shown in all 4 platforms
> - linux, mac, 
> > win32, win64 - but the error status, whether it is
> correct or not, 
> > only propagate back up to the "R CMD check" harness in
> the case of 
> > win64 and not for the other 3 platforms. It should
> pass or fail with 
> > a warning consistently on all platforms.
> 
> Are you sure this is the same version of R and
> codetools?? If you mean 
> BioC's check farm, that often has version skew.? I see
> the message 
> consistently on all my platforms ....

That's what I mean - the codetools message are seen consistently on all platforms, but the warning status only propagate back up to R CMD check (and resulted in a "1 warning" status) for win64 only; so R CMD check is behaving inconsistently, regardless of whether the message is genuine or not.

http://bioconductor.org/checkResults/2.7/bioc-LATEST/snpMatrix/gewurz-checksrc.html
* using R version 2.12.1 (2010-12-16)
* using platform: x86_64-pc-mingw32 (64-bit)
codetools message, status 1, 1 warning

http://bioconductor.org/checkResults/2.7/bioc-LATEST/snpMatrix/pelham-checksrc.html
* using R version 2.12.1 Patched (2010-12-17 r53867)
* using platform: i386-apple-darwin9.8.0 (32-bit)
codetools message, no error status, no warning

http://bioconductor.org/checkResults/2.7/bioc-LATEST/snpMatrix/liverpool-checksrc.html
* using R version 2.12.1 (2010-12-16)
* using platform: i386-pc-mingw32 (32-bit)
codetools message, status 1, no warning

http://bioconductor.org/checkResults/2.7/bioc-LATEST/snpMatrix/lamb2-checksrc.html
* using R version 2.12.1 (2010-12-16)
* using platform: x86_64-unknown-linux-gnu (64-bit)
codetools message, no error status, no warning


The mac OS X box has a slightly different version of R, but the other seems to be the same, and yet the error status and also whether the warning status is propate back is different. The codetools message is seen in all cases.

Hin-Tak








From rhurlin at gwdg.de  Tue Feb  8 20:36:02 2011
From: rhurlin at gwdg.de (Rainer Hurling)
Date: Tue, 08 Feb 2011 20:36:02 +0100
Subject: [Rd] R-devel on FreeBSD: Support for C99 complex type is
	required
In-Reply-To: <alpine.LFD.2.02.1102072237210.30160@gannet.stats.ox.ac.uk>
References: <4D4EAFCE.6020004@gwdg.de>
	<alpine.LFD.2.00.1102061507430.15472@auk.stats.ox.ac.uk>
	<4D4ED172.9090402@gwdg.de>
	<alpine.LFD.2.00.1102061710320.22661@auk.stats.ox.ac.uk>
	<4D4EE672.6080601@gwdg.de>
	<alpine.LFD.2.02.1102072237210.30160@gannet.stats.ox.ac.uk>
Message-ID: <4D519B22.3040508@gwdg.de>

On 07.02.2011 23:45 (UTC+1), Prof Brian Ripley wrote:
> A follow-up on this.
>
> Cygwin has recently[*] added support for C99 complex math, taken from
> NetBSD with code that is very similar to that from Steven Moshier
> available via http://www.moshier.net/c9x_readme.html.
>
> That code isn't entirely right, especially not at the cuts on the
> inverse functions where C99 mandates what cut is used (and neither glibc
> nor Mac OS X have it correct).
>
> I would expect that the current R-devel (I mean an SVN checkout now)
> should build on your platform, substituting the missing functions by
> ones based on earlier code. There may be a few more tweaks required, but
> I have corrected several errors in the versions FreeBSD would have used
> in R 2.12.1.

On FreeBSD 9.0-CURRENT (amd64) I have done a

   svn co https://svn.r-project.org/R/trunk r-devel/R

and after that

   configure --without-recommended-packages

The configure script does not complain any more about missing C99 
complex support. I was able to build and install R (without recommended 
packages).

Starting R and doing examples on ?complex seems to work correct.

sessionInfo()
R version 2.13.0 Under development (unstable) (2011-02-08 r54279)
Platform: x86_64-unknown-freebsd9.0 (64-bit)
locale:
[1] de_DE.ISO8859-15/de_DE.ISO8859-15/C/C/de_DE.ISO8859-15/de_DE.ISO8859-15
attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base
loaded via a namespace (and not attached):
[1] tools_2.13.0

Thank you very much for this work. Will it exist in some way in the next 
release?

> [*] AFAICS not yet released in Cygwin, but in newlib 1.19.0.
>


From simon.urbanek at r-project.org  Tue Feb  8 21:14:21 2011
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Tue, 8 Feb 2011 15:14:21 -0500
Subject: [Rd] Compiling a Tcl extension for an R package
In-Reply-To: <4D518617.10604@waddell.ch>
References: <4D518617.10604@waddell.ch>
Message-ID: <A365BEA2-A48F-446C-94DB-7D67E9ADAAB6@r-project.org>

Adrian,

On Feb 8, 2011, at 1:06 PM, Adrian Waddell wrote:

> Dear R developers,
> 
> I plan to upload a first version of my R package RnavGraph to the R CRAN
> server in a week or two. However I'm still struggling with an image
> resizing function written in C as a tcl extension. I did all my
> development in Ubuntu, and everything works fine in Ubuntu, however my
> attempts to compile this C function under Windows or OSX have all failed.
> 
> I provide a minimal self contained example at the end of this post. I
> also wrapped this example in a minimal R package (less than 20 lines of
> code!) and it can be downloaded at
> http://www.waddell.ch/RnavGraph/TclHelloWorld.zip
> 
> Can somebody help me to get this package to compile correctly under
> Linux, Windows and OSX? (i.e. writing a configure script with the
> correct compile commands).
> 

You should really read the TEA (Tcl Extension Architecture) documentation for details. Technically, you cannot use R package compilation to build TEAs, because they use entirely separate process (you can use a Makefile/Makevar with a separate target, though). Also note that TEAs are intended to be installed in the Tcl location, so you may want to think twice about it as it is orthogonal to the R package process (usually packages require extensions) -- for example there is no guarantee that the compiler used to build Tcl is on the machine that builds R packages. TEA recommends the use of tcl.m4 and autoconf - but note that you'll need to separate it from the package's flags.

That said, if you are willing to take some risks and cut corners (normally not what I'd suggest), there are a few things you can consider.

On unix (which includes Mac OS X), you may get away with locating tclConfig.sh and using the appropriate flags from there. This is still best done using configure, otherwise you'll need to jump through hoops to get tclConfig.sh sourced before a call to a sub-make, worry about multi-arch etc. 

Another alternative (more corner-cutting) is to use R's own Tcl/Tk configuration and pray that it will work. It did work for me on Mac, but be aware that it assumes that Tcl is compatible with the compiler used for R and that R's config is good enough to compile TEAs:

*** Makevars:

# you can't use $(DYLIB_EXT) even though that's what Tcl uses
# because R multi-arch installs won't copy it! So it must be SHLIB_EXT
TEALIB=helloTEA$(SHLIB_EXT)

all: $(SHLIB) $(TEALIB)

$(TEALIB): helloTEA.o
	$(SHLIB_LINK) -o $(TEALIB) helloTEA.o $(TCLTK_LIBS)

helloTEA.o: hello.c
	$(CC) -DTEA=1 -c hello.c -o $@ $(CPPFLAGS) $(CFLAGS) $(CPICFLAGS) $(TCLTK_CPPFLAGS)


**** hello.c [modified - see comments]

/* we have to make it conditional as R will also compile it for the package */
#if TEA
#include <tcl.h>
static int Hello_Cmd(ClientData cdata, Tcl_Interp *interp, int objc,
Tcl_Obj *const objv[]) {
 Tcl_SetObjResult(interp, Tcl_NewStringObj("Hello, World!", -1));
 return TCL_OK;
}
/* to avoid name clashes the TEA version is called helloTEA so the Init has to be adjusted accordingly */
int DLLEXPORT Hellotea_Init(Tcl_Interp *interp) {
 Tcl_CreateObjCommand(interp, "hello", Hello_Cmd, NULL, NULL);
 return TCL_OK;
}
#else
/* your R package C code goes here if you want */
#endif


*** test run on a Mac (created as package A)

> library(A)
> library(tcltk)
Loading Tcl/Tk interface ... done
> .Tcl(paste('load',system.file("libs",.Platform$r_arch,paste("helloTEA",.Platform$dynlib.ext,sep=''),package="A")))
<Tcl> dlsym(0x93b3e0, Hellotea_SafeInit): symbol not founddlsym(0x93b3e0, Hellotea_Unload): symbol not founddlsym(0x93b3e0, Hellotea_SafeUnload): symbol not found 
> .Tcl('hello')
<Tcl> Hello, World! 



Modulo a small bug in R (x64/Makeconf has wrong TCLTK_LIBS - it should point to bin64 instead of bin) and the fact that Tcl doesn't like paths with spaces (I suppose you can escape it somehow) it actually works on Windows as well.

Cheers,
Simon




> Thanks,
> 
> Adrian Waddell
> 
> 
> 
> ###########################
> 
> C Code (save as hello.c):
> 
> #include <tcl.h>
> static int Hello_Cmd(ClientData cdata, Tcl_Interp *interp, int objc,
> Tcl_Obj *const objv[]) {
>  Tcl_SetObjResult(interp, Tcl_NewStringObj("Hello, World!", -1));
>  return TCL_OK;
> }
> int DLLEXPORT Hello_Init(Tcl_Interp *interp) {
>  Tcl_CreateObjCommand(interp, "hello", Hello_Cmd, NULL, NULL);
>  return TCL_OK;
> }
> 
> which can be compiled (under Ubuntu 10.04) with:
> gcc -shared -o hello.so -DUSE_TCL_STUBS -I/usr/include/tcl8.5/ hello.c
> -L/usr/lib/ -ltclstub8.5 -fPIC
> 
> and used within an R session with
> 
> library(tcltk)
> .Tcl('load ./hello[info sharedlibextension]')
> tcl('hello')
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From this.is.mvw at gmail.com  Tue Feb  8 21:24:30 2011
From: this.is.mvw at gmail.com (Mike Williamson)
Date: Tue, 8 Feb 2011 12:24:30 -0800
Subject: [Rd] manipulating the Date & Time classes
Message-ID: <AANLkTi=RKFKDZgrb072mefmOefjNwwoE_QT8ZWOwFSci@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110208/96c6a449/attachment.pl>

From daniel.cegielka at gmail.com  Tue Feb  8 21:50:54 2011
From: daniel.cegielka at gmail.com (=?ISO-8859-2?Q?Daniel_Cegie=B3ka?=)
Date: Tue, 8 Feb 2011 21:50:54 +0100
Subject: [Rd] manipulating the Date & Time classes
In-Reply-To: <AANLkTi=RKFKDZgrb072mefmOefjNwwoE_QT8ZWOwFSci@mail.gmail.com>
References: <AANLkTi=RKFKDZgrb072mefmOefjNwwoE_QT8ZWOwFSci@mail.gmail.com>
Message-ID: <AANLkTindUNERPVHC=USSuJm5LESWv4ZWXJ-NJ3z0pwOw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110208/d8f1aaca/attachment.pl>

From p.murrell at auckland.ac.nz  Tue Feb  8 21:59:29 2011
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Wed, 09 Feb 2011 09:59:29 +1300
Subject: [Rd] [.raster bug {was "str() on raster objects fails .."}
In-Reply-To: <19791.41225.32589.640921@stat.math.ethz.ch>
References: <AANLkTimycPK-3_mj5OPd0eLauAh41r2-Wkrp7j2jo1sw@mail.gmail.com>	<19783.49835.494142.88222@stat.math.ethz.ch>	<4D48A96B.9020801@auckland.ac.nz>	<AANLkTimRBZbzgRfAkE2-VhnFmVRkWz1-cCqeD4VW7O42@mail.gmail.com>	<4D48B08A.40302@auckland.ac.nz>	<5251E963-8D1C-46CF-AAB9-39ABFE520229@r-project.org>	<AANLkTikgSiucEMzfSa2s9YTypkqzYLCab9gJvkGyr0Pz@mail.gmail.com>	<4D49F024.6090906@stat.auckland.ac.nz>	<74150327-8264-43FF-A4AC-1D3A2C469B4F@r-project.org>	<4D4F467C.8040201@auckland.ac.nz>	<0C865A58-A3C5-4A46-AA7E-50439BAAC520@r-project.org>
	<19791.41225.32589.640921@stat.math.ethz.ch>
Message-ID: <4D51AEB1.6060409@auckland.ac.nz>

Hi

On 7/02/2011 8:36 p.m., Martin Maechler wrote:
>>>>>> Simon Urbanek<simon.urbanek at r-project.org>
>>>>>>      on Sun, 6 Feb 2011 20:53:01 -0500 writes:
>
>      >  On Feb 6, 2011, at 8:10 PM, Paul Murrell wrote:
>
>      >>  Hi
>      >>
>      >>  On 3/02/2011 1:23 p.m., Simon Urbanek wrote:
>      >>>
>      >>>  On Feb 2, 2011, at 7:00 PM, Paul Murrell wrote:
>      >>>
>      >>>>  Hi
>      >>>>
>      >>>>  Martin Maechler wrote:
>      >>>>>  On Wed, Feb 2, 2011 at 23:30, Simon
>      >>>>>  Urbanek<simon.urbanek at r-project.org>  wrote:
>>>>>> On Feb 1, 2011, at 8:16 PM, Paul Murrell wrote:
>>>>>>
>      >>>>>>>  Hi
>      >>>>>>>
>      >>>>>>>  On 2/02/2011 2:03 p.m., Henrik Bengtsson wrote:
>      >>>>>>>>  On Tue, Feb 1, 2011 at 4:46 PM, Paul
>      >>>>>>>>  Murrell<p.murrell at auckland.ac.nz>  wrote:
>      >>>>>>>>>  Hi
>      >>>>>>>>>
>      >>>>>>>>>  On 1/02/2011 9:22 p.m., Martin Maechler wrote:
>      >>>>>>>>>>>>>>>  Henrik Bengtsson<hb at biostat.ucsf.edu>  on
>      >>>>>>>>>>>>>>>  Mon, 31 Jan 2011 11:16:59 -0800 writes:
>      >>>>>>>>>>>  Hi, str() on raster objects fails for certain
>      >>>>>>>>>>>  dimensions.  For example:
>      >>>>>>>>>>
>      >>>>>>>>>>>>  str(as.raster(0, nrow=1, ncol=100)) 'raster'
>      >>>>>>>>>>>>  chr [1, 1:100]
>      >>>>>>>>>>>  "#000000" "#000000" "#000000" "#000000" ...
>      >>>>>>>>>>
>      >>>>>>>>>>>>  str(as.raster(0, nrow=1, ncol=101)) Error in
>      >>>>>>>>>>>>  `[.raster`(object,
>      >>>>>>>>>>>  seq_len(max.len)) : subscript out of bounds
>      >>>>>>>>>>
>      >>>>>>>>>>>  This seems to do with how str() and "[.raster"()
>      >>>>>>>>>>>  is coded; when subsetting as a vector, which
>      >>>>>>>>>>>  str() relies on, "[.raster"() still returns a
>      >>>>>>>>>>>  matrix-like object, e.g.
>      >>>>>>>>>>
>      >>>>>>>>>>>>  img<- as.raster(1:25, max=25, nrow=5, ncol=5);
>      >>>>>>>>>>>>  img[1:2]
>      >>>>>>>>>>>  [,1] [,2] [,3] [,4] [,5] [1,] "#0A0A0A"
>      >>>>>>>>>>>  "#3D3D3D" "#707070" "#A3A3A3" "#D6D6D6" [2,]
>      >>>>>>>>>>>  "#141414" "#474747" "#7A7A7A" "#ADADAD"
>      >>>>>>>>>>>  "#E0E0E0"
>      >>>>>>>>>>
>      >>>>>>>>>>>  compare with:
>      >>>>>>>>>>
>      >>>>>>>>>>>>  as.matrix(img)[1:2]
>      >>>>>>>>>>>  [1] "#0A0A0A" "#3D3D3D"
>      >>>>>>>>>>
>      >>>>>>>>>>
>      >>>>>>>>>>>  The easy but incomplete fix is to do:
>      >>>>>>>>>>
>      >>>>>>>>>>>  str.raster<- function(object, ...) {
>      >>>>>>>>>>>  str(as.matrix(object), ...); }
>      >>>>>>>>>>
>      >>>>>>>>>>>  Other suggestions?
>      >>>>>>>>>>
>      >>>>>>>>>>  The informal "raster" class is behaving
>      >>>>>>>>>>  ``illogical'' in the following sense:
>      >>>>>>>>>>
>      >>>>>>>>>>>  r<- as.raster(0, nrow=1, ncol=11)
>      >>>>>>>>>>>  r[seq_along(r)]
>      >>>>>>>>>>  Error in `[.raster`(r, seq_along(r)) : subscript
>      >>>>>>>>>>  out of bounds
>      >>>>>>>>>>
>      >>>>>>>>>>  or, here equivalently,
>      >>>>>>>>>>>  r[1:length(r)]
>      >>>>>>>>>>  Error in `[.raster`(r, 1:length(r)) : subscript
>      >>>>>>>>>>  out of bounds
>      >>>>>>>>>>
>      >>>>>>>>>>  When classes do behave in such a way, they
>      >>>>>>>>>>  definitely need their own str() method.
>      >>>>>>>>>>
>      >>>>>>>>>>  However, the bug really is in "[.raster":
>      >>>>>>>>>>  Currently, r[i] is equivalent to r[i,] which is
>      >>>>>>>>>>  not at all matrix-like and its help clearly says
>      >>>>>>>>>>  that subsetting should work as for matrices. A
>      >>>>>>>>>>  recent thread on R-help/R-devel has mentioned the
>      >>>>>>>>>>  fact that "[" methods for matrix-like methods
>      >>>>>>>>>>  need to use both nargs() and missing() and that
>      >>>>>>>>>>  "[.dataframe" has been the example to follow
>      >>>>>>>>>>  "forever", IIRC already in S and S-plus as of 20
>      >>>>>>>>>>  years ago.
>      >>>>>>>>>  The main motivation for non-standard behaviour
>      >>>>>>>>>  here is to make sure that a subset of a raster
>      >>>>>>>>>  object NEVER produces a vector (because the
>      >>>>>>>>>  conversion back to a raster object then produces a
>      >>>>>>>>>  single-column raster and that may be a
>      >>>>>>>>>  "surprise").  Thanks for making the code more
>      >>>>>>>>>  standard and robust.
>      >>>>>>>>>
>      >>>>>>>>>  The r[i] case is still tricky.  The following
>      >>>>>>>>>  behaviour is quite convenient ...
>      >>>>>>>>>
>      >>>>>>>>>  r[r == "black"]<- "white"
>      >>>>>>>>>
>      >>>>>>>>>  ... but the next behaviour is quite jarring (at
>      >>>>>>>>>  least in terms of the raster image that results
>      >>>>>>>>>  from it) ...
>      >>>>>>>>>
>      >>>>>>>>>  r2<- r[1:(nrow(r) + 1)]
>      >>>>>>>>>
>      >>>>>>>>>  So I think there is some justification for further
>      >>>>>>>>>  non-standardness to try to ensure that the subset
>      >>>>>>>>>  of a raster image always produces a sensible
>      >>>>>>>>>  image.  A simple solution would be just to outlaw
>      >>>>>>>>>  r[i] for raster objects and force the user to
>      >>>>>>>>>  write r[i, ] or r[, j], depending on what they
>      >>>>>>>>>  want.
>      >>>>>>>>  FYI, I've tried out Martin's updated version at it
>      >>>>>>>>  seems like a one-column raster matrix is now
>      >>>>>>>>  returned for r[i], e.g.
>      >>>>>>>  Yes, that's what I've been looking at ...
>      >>>>>>>
>      >>>>>>>>>  r<- as.raster(1:8, max=8, nrow=2, ncol=4); r
>      >>>>>>>>  [,1] [,2] [,3] [,4] [1,] "#202020" "#606060"
>      >>>>>>>>  "#9F9F9F" "#DFDFDF" [2,] "#404040" "#808080"
>      >>>>>>>>  "#BFBFBF" "#FFFFFF"
>      >>>>>>>>
>      >>>>>>>>>  r[1:length(r)]
>      >>>>>>>>  [,1] [1,] "#202020" [2,] "#404040" [3,] "#606060"
>      >>>>>>>>  [4,] "#808080" [5,] "#9F9F9F" [6,] "#BFBFBF" [7,]
>      >>>>>>>>  "#DFDFDF" [8,] "#FFFFFF"
>      >>>>>>>  ... and the above is exactly the sort of thing that
>      >>>>>>>  will fry your mind if the image that you are
>      >>>>>>>  subsetting is, for example, a photo.
>      >>>>>>>
>>>>>> Why doesn't raster behave consistently like any matrix
>      >>>>>>>  object?
>>>>>> I would expect simply
>>>>>>
>      >>>>>>>  r[1:length(r)]
>>>>>> [1] "#202020" "#404040" "#606060" "#808080" "#9F9F9F"
>      >>>>>>>  "#BFBFBF"
>>>>>> "#DFDFDF" [8] "#FFFFFF"
>>>>>>
>>>>>> Where it's obvious what happened. I saw the comment about
>      >>>>>>>  the
>>>>>> vector but I'm not sure I get it - why don't you want a
>      >>>>>>>  vector?
>>>>>> The raster is no different than matrices - you still need
>      >>>>>>>  to
>>>>>> define the dimensions when going back anyway, moreover
>      >>>>>>>  what you
>>>>>> get now is not consistent at all since there raster never
>      >>>>>>>  had
>>>>>> that dimension anyway ...
>>>>>>
>>>>>> Cheers, Simon
>      >>>>>  I agree that this would be the most "logical" and
>      >>>>>  notably least surprising behavior, which I find the
>      >>>>>  most important argument (I'm sorry my last message was
>      >>>>>  cut off as it was sent accidentally before being
>      >>>>>  finished completely).
>      >>>>
>      >>>>  I think this behaviour might surprise some ...
>      >>>>
>      >>>>  download.file("http://cran.r-project.org/Rlogo.jpg",
>      >>>>  "Rlogo.jpg") library(ReadImages) logo<-
>      >>>>  read.jpeg("Rlogo.jpg")
>      >>>>
>      >>>>  rLogo<- as.raster(logo) rLogoBit<- rLogo[50:60, 50:60]
>      >>>>
>      >>>>  library(grid) # Original image grid.raster(rLogoBit)
>      >>>>  grid.newpage() # Subset produces a vector
>      >>>>  grid.raster(rLogoBit[1:length(rLogoBit)])
>      >>>>
>      >>>
>>> But this should fail IMHO since you're supplying a vector but
>      >>>  grid.raster (assuming it's the same as rasterImage)
>      >>>  requires a matrix - exactly as you would expect in the
>      >>>  matrix case - if a function requires a matrix and you
>      >>>  pass a vector, it will bark. I think you are explaining
>      >>>  why going to vector *is* desirable ;). In the current
>      >>>  case it simply generates the wrong dimensions instead of
>      >>>  resulting in a vector, right?
>      >>
>      >>  The raster subsetting always produces a raster, but
>      >>  grid.raster() works with vectors anyway because
>      >>  as.raster() has a vector method.
>      >>
>
>     >  Well, isn't that the actual problem? ;) It could make sense but it
>     >  should fail if dimensions are not specified for exactly the reason you
>     >  mentioned - it is fatal if what you have is really an image ...
>
>      >  Cheers, Simon
>
>
>      >>  Anyway, I'm happy to go with things as they now are.  I
>      >>  think at worst it will encourage people to specify two
>      >>  indices when subsetting a raster object, and that's not a
>      >>  bad thing.
>      >>
>      >>  Paul
>
> I and (maybe others) are getting a bit lost..
>
> AFAIK:
>
> - Simon proposes that     r[i]  should return a simple character vector
>    such that raster images behave more naturally like matrices.
>
> - Paul  seems happy with  r[i]  returning  a (k x 1) raster object
>    -- where  k  almost completely unrelated to the original
>    dim(r) -- with the argument that raster subsetting must always
>    return a "raster".

Actually, I'd prefer it to return something more sensible, or just fail 
(I don't see why raster images should behave in all ways like matrices) ...

> My vote would be for Simon's proposal, hence raster subsetting
> should return a raster only when  [i,j] or [i,] or [,j]  syntax
> is used.

... but I can also live with (Martin's interpretation of) Simon's proposal.

Paul

> Martin

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/


From jeffrey.ryan at lemnica.com  Tue Feb  8 22:02:07 2011
From: jeffrey.ryan at lemnica.com (Jeffrey Ryan)
Date: Tue, 8 Feb 2011 15:02:07 -0600
Subject: [Rd] manipulating the Date & Time classes
In-Reply-To: <AANLkTi=RKFKDZgrb072mefmOefjNwwoE_QT8ZWOwFSci@mail.gmail.com>
References: <AANLkTi=RKFKDZgrb072mefmOefjNwwoE_QT8ZWOwFSci@mail.gmail.com>
Message-ID: <AANLkTikuUkhoErhW2kG2H=MWjD28C-WJf0VxdEW+SHu5@mail.gmail.com>

Firstly, don't double post.

On Tue, Feb 8, 2011 at 2:24 PM, Mike Williamson <this.is.mvw at gmail.com> wrote:
> Hello,
>
> ? ?This is mostly to developers, but in case I missed something in my
> literature search, I am sending this to the broader audience.
>
>
> ? - Are there any plans in the works to make "time" classes a bit more
> ? friendly to the rest of the "R" world? ?I am not suggesting to allow for
> ? fancy functions to manipulate times, per se, or to figure out how to
> ? properly "add" times or anything complicated. ?Just some fixes to make it
> ? easier to work with the "time" classes. ?Here is a sampling of some strange
> ? bugs with the time classes that, to my knowledge, don't exist with any other
> ? core classes:
> ? ? ?1. you cannot "unlist" a time without losing the class. ?E.g., if you
> ? ? ?unlist "2010-12-14 20:25:40" (POSIXct), you get "1292387141", at
> least on my
> ? ? ?OS & with my time zone. ?Regardless of the exact number, unlisting a time
> ? ? ?class converts it to a numeric.

You didn't say what your OS is, but two things spring to mind.  Why
are you calling 'unlist' on an object that isn't a list and ... "it
works for me":

> unlist(Sys.time())
[1] "2011-02-08 14:46:24.262146 CST"

> ? ? ? ? - upon converting to a numeric, it seems there is an underlying,
> ? ? ? ? assumed origin of "1970-01-01 00:00:00". ?However, this same
> assumption does
> ? ? ? ? not underlie the conversion *back* to a POSIX time, e.g., through
> ? ? ? ? as.POSIXct() function. ?Therefore, whenever a time is "accidentally"
> ? ? ? ? converted to a numeric, I have to force it back to a time through
> ? ? ? ? as.POSIXct(), *providing my own details* as to the origin. ?There
> ? ? ? ? is no easy way to find the underlying origin. ?This makes me
> nervous for any
> ? ? ? ? persistent functions I create. ?If the underlying origin ever
> changes, then
> ? ? ? ? all this code will be inaccurate. ?Maybe the origin will
> never change, but
> ? ? ? ? regardless it makes more sense to allow for the same underlying origin
> ? ? ? ? default for "as.POSIXct" that is used when unlisting, or
> similar activities
> ? ? ? ? that force the time into a numeric.

If it is just numeric, it shouldn't have any attribute and since the
origin isn't global, you're sort of stuck. You can keep track of it
yourself, or just leave it as the standard unix epoch.

> ? ? ? ? 2. you cannot perform functions that otherwise seem trivial, such
> ? ? ?as a "max" or "min". ?I understand why, for instance, adding is
> hard. ?But
> ? ? ?what about max or min? ?Greater than or less than are possible, as is
> ? ? ?order(). ?I have my own simple scripts using these 2 functions
> in order to
> ? ? ?create a "max" & "min" for times, but it would be nice to have something
> ? ? ?vetted & official.
>

> min(Sys.time()+1:10)
[1] "2011-02-08 14:59:26.40236 CST"
> max(Sys.time()+1:10)
[1] "2011-02-08 14:59:36.762224 CST"

Again, works for me.

R.version
               _
platform       x86_64-apple-darwin10.2.0
arch           x86_64
os             darwin10.2.0
system         x86_64, darwin10.2.0
status
major          2
minor          12.0
year           2010
month          10
day            15
svn rev        53317
language       R
version.string R version 2.12.0 (2010-10-15)
>


> ? ?If others could chime in with any strange behaviors they've seen in
> working with times, maybe we could get a critical mass of issues that are
> worthy of an overhaul.
>
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?Thanks & Regards,
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?Mike
>
>
> "Telescopes and bathyscaphes and sonar probes of Scottish lakes,
> Tacoma Narrows bridge collapse explained with abstract phase-space maps,
> Some x-ray slides, a music score, Minard's Napoleanic war:
> The most exciting frontier is charting what's already here."
> ?-- xkcd
>
> --
> Help protect Wikipedia. Donate now:
> http://wikimediafoundation.org/wiki/Support_Wikipedia/en
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>



-- 
Jeffrey Ryan
jeffrey.ryan at lemnica.com

www.lemnica.com


From ripley at stats.ox.ac.uk  Tue Feb  8 22:10:59 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 8 Feb 2011 21:10:59 +0000 (GMT)
Subject: [Rd] R-devel on FreeBSD: Support for C99 complex type is
 required
In-Reply-To: <4D519B22.3040508@gwdg.de>
References: <4D4EAFCE.6020004@gwdg.de>
	<alpine.LFD.2.00.1102061507430.15472@auk.stats.ox.ac.uk>
	<4D4ED172.9090402@gwdg.de>
	<alpine.LFD.2.00.1102061710320.22661@auk.stats.ox.ac.uk>
	<4D4EE672.6080601@gwdg.de>
	<alpine.LFD.2.02.1102072237210.30160@gannet.stats.ox.ac.uk>
	<4D519B22.3040508@gwdg.de>
Message-ID: <alpine.LFD.2.02.1102082103020.19688@gannet.stats.ox.ac.uk>

On Tue, 8 Feb 2011, Rainer Hurling wrote:

> On 07.02.2011 23:45 (UTC+1), Prof Brian Ripley wrote:
>> A follow-up on this.
>> 
>> Cygwin has recently[*] added support for C99 complex math, taken from
>> NetBSD with code that is very similar to that from Steven Moshier
>> available via http://www.moshier.net/c9x_readme.html.
>> 
>> That code isn't entirely right, especially not at the cuts on the
>> inverse functions where C99 mandates what cut is used (and neither glibc
>> nor Mac OS X have it correct).
>> 
>> I would expect that the current R-devel (I mean an SVN checkout now)
>> should build on your platform, substituting the missing functions by
>> ones based on earlier code. There may be a few more tweaks required, but
>> I have corrected several errors in the versions FreeBSD would have used
>> in R 2.12.1.
>
> On FreeBSD 9.0-CURRENT (amd64) I have done a
>
>  svn co https://svn.r-project.org/R/trunk r-devel/R
>
> and after that
>
>  configure --without-recommended-packages
>
> The configure script does not complain any more about missing C99 complex 
> support. I was able to build and install R (without recommended packages).
>
> Starting R and doing examples on ?complex seems to work correct.
>
> sessionInfo()
> R version 2.13.0 Under development (unstable) (2011-02-08 r54279)
> Platform: x86_64-unknown-freebsd9.0 (64-bit)
> locale:
> [1] de_DE.ISO8859-15/de_DE.ISO8859-15/C/C/de_DE.ISO8859-15/de_DE.ISO8859-15
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> loaded via a namespace (and not attached):
> [1] tools_2.13.0
>
> Thank you very much for this work. Will it exist in some way in the next 
> release?

Just to be clear, the next release will almost certainly be 2.12.2 
(currently R-patched).  That will use pre-C99 complex as 2.12.1 did, 
but with several bugs fixed.  Then we would expect a 2.13.0 in April, 
and that will require C99 complex in the compiler plus some version of 
the current substitutes for csin etc.

My sysadmins have updated a FreeBSD virtual machine for me (to 
8.2-rc3): hopefully I will be able to test R-devel on it in future.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From rhurlin at gwdg.de  Tue Feb  8 22:31:45 2011
From: rhurlin at gwdg.de (Rainer Hurling)
Date: Tue, 08 Feb 2011 22:31:45 +0100
Subject: [Rd] R-devel on FreeBSD: Support for C99 complex type is
	required
In-Reply-To: <alpine.LFD.2.02.1102082103020.19688@gannet.stats.ox.ac.uk>
References: <4D4EAFCE.6020004@gwdg.de>
	<alpine.LFD.2.00.1102061507430.15472@auk.stats.ox.ac.uk>
	<4D4ED172.9090402@gwdg.de>
	<alpine.LFD.2.00.1102061710320.22661@auk.stats.ox.ac.uk>
	<4D4EE672.6080601@gwdg.de>
	<alpine.LFD.2.02.1102072237210.30160@gannet.stats.ox.ac.uk>
	<4D519B22.3040508@gwdg.de>
	<alpine.LFD.2.02.1102082103020.19688@gannet.stats.ox.ac.uk>
Message-ID: <4D51B641.4080902@gwdg.de>

On 08.02.2011 22:10 (UTC+1), Prof Brian Ripley wrote:
> On Tue, 8 Feb 2011, Rainer Hurling wrote:
>> On 07.02.2011 23:45 (UTC+1), Prof Brian Ripley wrote:
>>> A follow-up on this.
>>>
>>> Cygwin has recently[*] added support for C99 complex math, taken from
>>> NetBSD with code that is very similar to that from Steven Moshier
>>> available via http://www.moshier.net/c9x_readme.html.
>>>
>>> That code isn't entirely right, especially not at the cuts on the
>>> inverse functions where C99 mandates what cut is used (and neither glibc
>>> nor Mac OS X have it correct).
>>>
>>> I would expect that the current R-devel (I mean an SVN checkout now)
>>> should build on your platform, substituting the missing functions by
>>> ones based on earlier code. There may be a few more tweaks required, but
>>> I have corrected several errors in the versions FreeBSD would have used
>>> in R 2.12.1.
>>
>> On FreeBSD 9.0-CURRENT (amd64) I have done a
>>
>> svn co https://svn.r-project.org/R/trunk r-devel/R
>>
>> and after that
>>
>> configure --without-recommended-packages
>>
>> The configure script does not complain any more about missing C99
>> complex support. I was able to build and install R (without
>> recommended packages).
>>
>> Starting R and doing examples on ?complex seems to work correct.
>>
>> sessionInfo()
>> R version 2.13.0 Under development (unstable) (2011-02-08 r54279)
>> Platform: x86_64-unknown-freebsd9.0 (64-bit)
>> locale:
>> [1]
>> de_DE.ISO8859-15/de_DE.ISO8859-15/C/C/de_DE.ISO8859-15/de_DE.ISO8859-15
>> attached base packages:
>> [1] stats graphics grDevices utils datasets methods base
>> loaded via a namespace (and not attached):
>> [1] tools_2.13.0
>>
>> Thank you very much for this work. Will it exist in some way in the
>> next release?
>
> Just to be clear, the next release will almost certainly be 2.12.2
> (currently R-patched). That will use pre-C99 complex as 2.12.1 did, but
> with several bugs fixed. Then we would expect a 2.13.0 in April, and
> that will require C99 complex in the compiler plus some version of the
> current substitutes for csin etc.

Sorry, my last question was imprecise. Of course I meant 2.13.x.

> My sysadmins have updated a FreeBSD virtual machine for me (to 8.2-rc3):
> hopefully I will be able to test R-devel on it in future.

Wow, that's interesting. Please let me know if I could test something on 
FreeBSD 9.0-CURRENT (the amd64 development version).


From ripley at stats.ox.ac.uk  Tue Feb  8 22:58:43 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 8 Feb 2011 21:58:43 +0000 (GMT)
Subject: [Rd] Compiling a Tcl extension for an R package
In-Reply-To: <A365BEA2-A48F-446C-94DB-7D67E9ADAAB6@r-project.org>
References: <4D518617.10604@waddell.ch>
	<A365BEA2-A48F-446C-94DB-7D67E9ADAAB6@r-project.org>
Message-ID: <alpine.LFD.2.02.1102082145220.21168@gannet.stats.ox.ac.uk>

On Tue, 8 Feb 2011, Simon Urbanek wrote:

> Adrian,
>
> On Feb 8, 2011, at 1:06 PM, Adrian Waddell wrote:
>
>> Dear R developers,
>>
>> I plan to upload a first version of my R package RnavGraph to the R CRAN
>> server in a week or two. However I'm still struggling with an image
>> resizing function written in C as a tcl extension. I did all my
>> development in Ubuntu, and everything works fine in Ubuntu, however my
>> attempts to compile this C function under Windows or OSX have all failed.
>>
>> I provide a minimal self contained example at the end of this post. I
>> also wrapped this example in a minimal R package (less than 20 lines of
>> code!) and it can be downloaded at
>> http://www.waddell.ch/RnavGraph/TclHelloWorld.zip
>>
>> Can somebody help me to get this package to compile correctly under
>> Linux, Windows and OSX? (i.e. writing a configure script with the
>> correct compile commands).
>>
>
> You should really read the TEA (Tcl Extension Architecture) 
> documentation for details. Technically, you cannot use R package 
> compilation to build TEAs, because they use entirely separate 
> process (you can use a Makefile/Makevar with a separate target, 
> though). Also note that TEAs are intended to be installed in the Tcl 
> location, so you may want to think twice about it as it is 
> orthogonal to the R package process (usually packages require 
> extensions) -- for example there is no guarantee that the compiler 
> used to build Tcl is on the machine that builds R packages. TEA

And that is serious.  Solaris and Windows are two platforms on which 
Tcl/Tk and R are often built with different compilers.

A few of us were looking into this last month to see if there was an 
easy portable way to provide Tcl extensions such as Bwidget, Tktable 
and Img (the common ones used in CRAN packages).  We concluded it 
probably was possible (as Tktable uses the tclConfig.sh route) but not 
very portable.

> recommends the use of tcl.m4 and autoconf - but note that you'll 
> need to separate it from the package's flags.
>
> That said, if you are willing to take some risks and cut corners 
> (normally not what I'd suggest), there are a few things you can 
> consider.
>
> On unix (which includes Mac OS X), you may get away with locating 
> tclConfig.sh and using the appropriate flags from there. This is 
> still best done using configure, otherwise you'll need to jump 
> through hoops to get tclConfig.sh sourced before a call to a 
> sub-make, worry about multi-arch etc.
>
> Another alternative (more corner-cutting) is to use R's own Tcl/Tk 
> configuration and pray that it will work. It did work for me on Mac, 
> but be aware that it assumes that Tcl is compatible with the 
> compiler used for R and that R's config is good enough to compile 
> TEAs:
>
> *** Makevars:
>
> # you can't use $(DYLIB_EXT) even though that's what Tcl uses
> # because R multi-arch installs won't copy it! So it must be SHLIB_EXT
> TEALIB=helloTEA$(SHLIB_EXT)
>
> all: $(SHLIB) $(TEALIB)
>
> $(TEALIB): helloTEA.o
> 	$(SHLIB_LINK) -o $(TEALIB) helloTEA.o $(TCLTK_LIBS)
>
> helloTEA.o: hello.c
> 	$(CC) -DTEA=1 -c hello.c -o $@ $(CPPFLAGS) $(CFLAGS) $(CPICFLAGS) $(TCLTK_CPPFLAGS)
>
>
> **** hello.c [modified - see comments]
>
> /* we have to make it conditional as R will also compile it for the package */
> #if TEA
> #include <tcl.h>
> static int Hello_Cmd(ClientData cdata, Tcl_Interp *interp, int objc,
> Tcl_Obj *const objv[]) {
> Tcl_SetObjResult(interp, Tcl_NewStringObj("Hello, World!", -1));
> return TCL_OK;
> }
> /* to avoid name clashes the TEA version is called helloTEA so the Init has to be adjusted accordingly */
> int DLLEXPORT Hellotea_Init(Tcl_Interp *interp) {
> Tcl_CreateObjCommand(interp, "hello", Hello_Cmd, NULL, NULL);
> return TCL_OK;
> }
> #else
> /* your R package C code goes here if you want */
> #endif
>
>
> *** test run on a Mac (created as package A)
>
>> library(A)
>> library(tcltk)
> Loading Tcl/Tk interface ... done
>> .Tcl(paste('load',system.file("libs",.Platform$r_arch,paste("helloTEA",.Platform$dynlib.ext,sep=''),package="A")))
> <Tcl> dlsym(0x93b3e0, Hellotea_SafeInit): symbol not founddlsym(0x93b3e0, Hellotea_Unload): symbol not founddlsym(0x93b3e0, Hellotea_SafeUnload): symbol not found
>> .Tcl('hello')
> <Tcl> Hello, World!
>
>
>
> Modulo a small bug in R (x64/Makeconf has wrong TCLTK_LIBS - it should point to bin64 instead of bin) and the fact that Tcl doesn't like paths with spaces (I suppose you can escape it somehow) it actually works on Windows as well.
>
> Cheers,
> Simon
>
>
>
>
>> Thanks,
>>
>> Adrian Waddell
>>
>>
>>
>> ###########################
>>
>> C Code (save as hello.c):
>>
>> #include <tcl.h>
>> static int Hello_Cmd(ClientData cdata, Tcl_Interp *interp, int objc,
>> Tcl_Obj *const objv[]) {
>>  Tcl_SetObjResult(interp, Tcl_NewStringObj("Hello, World!", -1));
>>  return TCL_OK;
>> }
>> int DLLEXPORT Hello_Init(Tcl_Interp *interp) {
>>  Tcl_CreateObjCommand(interp, "hello", Hello_Cmd, NULL, NULL);
>>  return TCL_OK;
>> }
>>
>> which can be compiled (under Ubuntu 10.04) with:
>> gcc -shared -o hello.so -DUSE_TCL_STUBS -I/usr/include/tcl8.5/ hello.c
>> -L/usr/lib/ -ltclstub8.5 -fPIC
>>
>> and used within an R session with
>>
>> library(tcltk)
>> .Tcl('load ./hello[info sharedlibextension]')
>> tcl('hello')
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From simon.urbanek at r-project.org  Tue Feb  8 23:31:15 2011
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Tue, 8 Feb 2011 17:31:15 -0500
Subject: [Rd] manipulating the Date & Time classes
In-Reply-To: <AANLkTi=RKFKDZgrb072mefmOefjNwwoE_QT8ZWOwFSci@mail.gmail.com>
References: <AANLkTi=RKFKDZgrb072mefmOefjNwwoE_QT8ZWOwFSci@mail.gmail.com>
Message-ID: <273A1D8C-68B9-446C-BFD3-956CCEF0322D@r-project.org>

Mike,

On Feb 8, 2011, at 3:24 PM, Mike Williamson wrote:

> Hello,
> 
>    This is mostly to developers, but in case I missed something in my
> literature search, I am sending this to the broader audience.
> 
> 
>   - Are there any plans in the works to make "time" classes a bit more
>   friendly to the rest of the "R" world?  I am not suggesting to allow for
>   fancy functions to manipulate times, per se, or to figure out how to
>   properly "add" times or anything complicated.  Just some fixes to make it
>   easier to work with the "time" classes.  Here is a sampling of some strange
>   bugs with the time classes that, to my knowledge, don't exist with any other
>   core classes:
>      1. you cannot "unlist" a time without losing the class.  E.g., if you
>      unlist "2010-12-14 20:25:40" (POSIXct), you get "1292387141", at
> least on my
>      OS & with my time zone.  Regardless of the exact number, unlisting a time
>      class converts it to a numeric.

Same answer as Jeff said - it works for me. When posting claims like this it's good to provide some evidence like a reproducible example with details such as the version of R you used, OS etc.


>         - upon converting to a numeric, it seems there is an underlying,
>         assumed origin of "1970-01-01 00:00:00".  

You may want to read up on times a bit - POSIX time (aka unix time) *is* defined as number of seconds elapsed since midnight UTC 1970/1/1. That is also the internal representation of POSIXct (see ?POSIXct) that you get when unclassing it (not unlisting).  


> However, this same
> assumption does
>         not underlie the conversion *back* to a POSIX time, e.g., through
>         as.POSIXct() function.  

And it would be fatal if it did. When you have a number there is no way of knowing what the origin is, that's why it has to be specified. There are many different numeric times with various origins (e.g. Apple used to have its own one before OS X, Excel uses 1900 etc. - see Epoch).
 

> Therefore, whenever a time is "accidentally"
>         converted to a numeric, I have to force it back to a time through
>         as.POSIXct(), *providing my own details* as to the origin.  There
>         is no easy way to find the underlying origin.  

In general, there is no way. *If* your numbers come from unclassing POSIXct then you can simply set the class back - which avoid other hassles such as the fact that you have no idea about the target time zone of the original number otherwise.


> This makes me
> nervous for any
>         persistent functions I create.  If the underlying origin ever
> changes, then
>         all this code will be inaccurate.  

POSIX time is POSIX time (aka unix time) - that's where the name comes from! If that definition changes, we'll see more issues than your code ;).


> Maybe the origin will
> never change, but
>         regardless it makes more sense to allow for the same underlying origin
>         default for "as.POSIXct" that is used when unlisting, or
> similar activities
>         that force the time into a numeric.
>         2. you cannot perform functions that otherwise seem trivial, such
>      as a "max" or "min".

Again, I don't believe you:

> x = Sys.time() + 1:10
> min(x)
[1] "2011-02-08 17:17:47 EST"
> max(x)
[1] "2011-02-08 17:17:56 EST"
> max(x) - min(x)
Time difference of 9 secs


>  I understand why, for instance, adding is
> hard.  But
>      what about max or min?  Greater than or less than are possible, as is
>      order().  I have my own simple scripts using these 2 functions
> in order to
>      create a "max" & "min" for times, but it would be nice to have something
>      vetted & official.
> 
>    If others could chime in with any strange behaviors they've seen in
> working with times, maybe we could get a critical mass of issues that are
> worthy of an overhaul.
> 

Please do provide some real evidence, like reproducible examples. So far none of your claims was verifiable.

Cheers,
Simon




>                                          Thanks & Regards,
>                                                    Mike
> 
> 
> "Telescopes and bathyscaphes and sonar probes of Scottish lakes,
> Tacoma Narrows bridge collapse explained with abstract phase-space maps,
> Some x-ray slides, a music score, Minard's Napoleanic war:
> The most exciting frontier is charting what's already here."
>  -- xkcd
> 
> --
> Help protect Wikipedia. Donate now:
> http://wikimediafoundation.org/wiki/Support_Wikipedia/en
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From bbolker at gmail.com  Wed Feb  9 02:49:27 2011
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 8 Feb 2011 20:49:27 -0500
Subject: [Rd] using rasterImage within image
Message-ID: <4D51F2A7.8010505@mcmaster.ca>


  Has anyone yet tried incorporating rasterImage into the base image()
function?  It seems to make a *huge* difference, with
a very small number of added/changed lines of code.  (Of course I have
barely tested it at all.)
  Is there any reason this *shouldn't* go into the next release?

> source("image.R")
> z <- matrix(runif(1e6),nrow=1000)
> image(z)
> image(z,useRaster=TRUE)

  (Patch against SVN 54284 attached; people can contact me if it doesn't
go through and they want it.)

  Ben Bolker

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: image_diff.txt
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110208/723aa201/attachment.txt>

From mdsumner at gmail.com  Wed Feb  9 03:51:57 2011
From: mdsumner at gmail.com (Michael Sumner)
Date: Wed, 9 Feb 2011 13:51:57 +1100
Subject: [Rd] using rasterImage within image
In-Reply-To: <4D51F2A7.8010505@mcmaster.ca>
References: <4D51F2A7.8010505@mcmaster.ca>
Message-ID: <AANLkTikZ2ktQ+AnyYeaYwuiRFiXB_xwHzEYc48X5m5eT@mail.gmail.com>

Hello,

There's a problem for rasterImage when used in SDI mode in Windows,
which may be worth considering.

https://stat.ethz.ch/pipermail/r-sig-geo/2010-July/008820.html

I had off-list emails with Duncan Murdoch and Paul Murrell about this
and they determined that it was in SDI only, and there's still no
resolution for it as far as I know.  I checked in the latest dev build
of 2.13.0 2011-02-04 r54221 just in case.

This has been in use in the derived function
image.SpatialGridDataFrame in the sp package since rasterImage was
released, the sp function incorporates a warning for users in SDI
mode.

Cheers, Mike.

On Wed, Feb 9, 2011 at 12:49 PM, Ben Bolker <bbolker at gmail.com> wrote:
>
> ?Has anyone yet tried incorporating rasterImage into the base image()
> function? ?It seems to make a *huge* difference, with
> a very small number of added/changed lines of code. ?(Of course I have
> barely tested it at all.)
> ?Is there any reason this *shouldn't* go into the next release?
>
>> source("image.R")
>> z <- matrix(runif(1e6),nrow=1000)
>> image(z)
>> image(z,useRaster=TRUE)
>
> ?(Patch against SVN 54284 attached; people can contact me if it doesn't
> go through and they want it.)
>
> ?Ben Bolker
>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>



-- 
Michael Sumner
Institute for Marine and Antarctic Studies, University of Tasmania
Hobart, Australia
e-mail: mdsumner at gmail.com


From simon.urbanek at r-project.org  Wed Feb  9 04:03:28 2011
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Tue, 8 Feb 2011 22:03:28 -0500
Subject: [Rd] using rasterImage within image
In-Reply-To: <4D51F2A7.8010505@mcmaster.ca>
References: <4D51F2A7.8010505@mcmaster.ca>
Message-ID: <D8F5413E-025A-4511-BCE1-7ED06CBE99A0@r-project.org>

Ben,

did you actually look at the result of your function with useRaster=TRUE ? ;) [Hint: don't use an image that is symmetric]

Apart from that nice bug there are more issues as well, try
image(matrix(1:4,2),col=1:3)
The underlying issue is that as.raster() is not quite what you would hope. Unfortunately I'm not aware of an easy fix (that doesn't involve going back to RGB decomposition).

In general, I think it's a nice option, but I don't think you'll get away with only a few lines...

Cheers,
Simon



On Feb 8, 2011, at 8:49 PM, Ben Bolker wrote:

> 
>  Has anyone yet tried incorporating rasterImage into the base image()
> function?  It seems to make a *huge* difference, with
> a very small number of added/changed lines of code.  (Of course I have
> barely tested it at all.)
>  Is there any reason this *shouldn't* go into the next release?
> 
>> source("image.R")
>> z <- matrix(runif(1e6),nrow=1000)
>> image(z)
>> image(z,useRaster=TRUE)
> 
>  (Patch against SVN 54284 attached; people can contact me if it doesn't
> go through and they want it.)
> 
>  Ben Bolker
> 
> <image_diff.txt>______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From p.murrell at auckland.ac.nz  Wed Feb  9 04:04:18 2011
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Wed, 9 Feb 2011 16:04:18 +1300
Subject: [Rd] using rasterImage within image
In-Reply-To: <AANLkTikZ2ktQ+AnyYeaYwuiRFiXB_xwHzEYc48X5m5eT@mail.gmail.com>
References: <4D51F2A7.8010505@mcmaster.ca>
	<AANLkTikZ2ktQ+AnyYeaYwuiRFiXB_xwHzEYc48X5m5eT@mail.gmail.com>
Message-ID: <4D520432.9050405@auckland.ac.nz>

Hi

On 9/02/2011 3:51 p.m., Michael Sumner wrote:
> Hello,
>
> There's a problem for rasterImage when used in SDI mode in Windows,
> which may be worth considering.
>
> https://stat.ethz.ch/pipermail/r-sig-geo/2010-July/008820.html
>
> I had off-list emails with Duncan Murdoch and Paul Murrell about this
> and they determined that it was in SDI only, and there's still no
> resolution for it as far as I know.  I checked in the latest dev build
> of 2.13.0 2011-02-04 r54221 just in case.

I committed a bug fix this morning (r54280), which improves Windows 
raster drawing for some simple test cases.  I'd love to know if that has 
had any effect on the problem that you reported.

Paul

> This has been in use in the derived function
> image.SpatialGridDataFrame in the sp package since rasterImage was
> released, the sp function incorporates a warning for users in SDI
> mode.
>
> Cheers, Mike.
>
> On Wed, Feb 9, 2011 at 12:49 PM, Ben Bolker<bbolker at gmail.com>  wrote:
>>
>>   Has anyone yet tried incorporating rasterImage into the base image()
>> function?  It seems to make a *huge* difference, with
>> a very small number of added/changed lines of code.  (Of course I have
>> barely tested it at all.)
>>   Is there any reason this *shouldn't* go into the next release?
>>
>>> source("image.R")
>>> z<- matrix(runif(1e6),nrow=1000)
>>> image(z)
>>> image(z,useRaster=TRUE)
>>
>>   (Patch against SVN 54284 attached; people can contact me if it doesn't
>> go through and they want it.)
>>
>>   Ben Bolker
>>
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>
>
>

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/


From savicky at cs.cas.cz  Wed Feb  9 13:55:59 2011
From: savicky at cs.cas.cz (Petr Savicky)
Date: Wed, 9 Feb 2011 13:55:59 +0100
Subject: [Rd] print(...,digits=2) behavior
In-Reply-To: <19791.46002.901049.478712@stat.math.ethz.ch>
References: <4D4DB9E1.4000306@mcmaster.ca>
	<19791.46002.901049.478712@stat.math.ethz.ch>
Message-ID: <20110209125559.GA23941@cs.cas.cz>

On Mon, Feb 07, 2011 at 09:56:18AM +0100, Martin Maechler wrote:
> >>>>> Ben Bolker <bbolker at gmail.com>
> >>>>>     on Sat, 5 Feb 2011 15:58:09 -0500 writes:
> 
>     >   A bug was recently posted to the R bug database (which
>     > probably would better have been posted as a query here) as
>     > to why this happens:
> 
>     >> print(7.921,digits=2)
>     > [1] 8
>     >> print(7.92,digits=2)
>     > [1] 7.9
> 
[...]

> I had started to delve into this after you've posted the bug
> report. It is clearly a bug(let),
> caused by code that has been in  R  from its very
> beginning, at least in the first source code I've seen in 1994.
> 
> The problem is not related to digits=2,
> but using such a low number of digits shows it more
> dramatically, e.g., also
> 
>  > print(5.9994, digits=4)
>  [1] 5.999
>  > print(5.9994001, digits=4)
>  [1] 6
> 
> Interestingly, the problem seems *not* to be present for
> digits = 1 (only).
> 
> I haven't found time to mathematically "analyze" it for
> determining a correct solution though.
> Note that fixing this bug(let) will probably (very slightly)
> change a huge number of R outputs .. so there is a caveat,
> but nonetheless, we must approach it.
> 
> The responsible code is the C function  scientific()
> in src/main/format.c 

I inspected the source of scientific() and formatReal() (2.13.0, revision
2011-02-08 r54284). Let me point out an example of the difference between
the output of print() and rounding to "digits" significant digits, which
is slightly different from the previous ones, since also the exponent
changes. Namely,

  print(9.991, digits=3)
  [1] 10

while rounding to 3 digits yields 9.99. The reason is in scientific(),
where the situation that rounding increases the exponent is tested using

    /* make sure that alpha is in [1,10) AFTER rounding */

    if (10.0 - alpha < eps*alpha) {
        alpha /= 10.0;
        kp += 1;
    }

Here, eps is determined in formatReal() as

    double eps = pow(10.0, -(double)R_print.digits);

so we have eps = 10^-digits. The above condition on alpha is equivalent to

  alpha > 10.0/(1 + 10^-digits)

For digits=3, this is

  alpha > 9.99000999000999

This bound may be verified as follows

  print(9.9900099900, digits=3)
  [1] 9.99

  print(9.9900099901, digits=3)
  [1] 10

The existing algorithm for choosing the number of digits is designed to
predict the format suitable for all numbers in a vector before the actual
call of sprintf() or snprintf(). For speed, this algorithm should use
the standard double precision, so it is necessarily inaccurate for precision
15 and more and there may be some rare such cases also for smaller
precisions. For smaller precisions, say below 7, the algorithm can be made
more precise. This would change the output in rare cases and mainly for
printing single numbers. If a vector is printed, then the format is typically
not determined by the problematic numbers.

Changing the default behavior may be undesirable for backward compatibility
reasons. If this is the case, then a possible solution is to make the
documentation more precise on this and include pointers to possible
solutions. The functions sprintf(), formatC() and signif() may be used. In
particular, if signif() is used to round the numbers before printing, then we
get the correct output

  print(signif(7.921, digits=2))  
  [1] 7.9

  print(signif(9.9900099901, digits=3))
  [1] 9.99

The current ?print.default contains

  digits: a non-null value for ?digits? specifies the minimum number of
          significant digits to be printed in values.

The word "minimum" here means that all numbers in the vector will have
at least the chosen number of digits, but some may have more. I suggest
to add "See 'options' for more detail.".

The current ?options contains

    ?digits?: controls the number of digits to print when printing
          numeric values.  It is a suggestion only.

I suggest to extend this to

   It is a suggestion only and the actual number of printed digits
   may be smaller, if the relative error of the output number is
   less than 10^-digits. Use 'signif(, digits)' before printing to get
   the exact number of the printed significant digits.

I appreciate to know the opinion of R developers on this.

Petr Savicky.


From lawrence.michael at gene.com  Wed Feb  9 14:54:38 2011
From: lawrence.michael at gene.com (Michael Lawrence)
Date: Wed, 9 Feb 2011 05:54:38 -0800
Subject: [Rd] subassignment does not always duplicate object from active
	binding
Message-ID: <AANLkTimThFS0CV1XRgh0wAg7ZfmJY77_UJNe3js9W6kE@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110209/b39d621b/attachment.pl>

From bbolker at gmail.com  Wed Feb  9 16:06:35 2011
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 9 Feb 2011 10:06:35 -0500
Subject: [Rd] using rasterImage within image
In-Reply-To: <D8F5413E-025A-4511-BCE1-7ED06CBE99A0@r-project.org>
References: <4D51F2A7.8010505@mcmaster.ca>
	<D8F5413E-025A-4511-BCE1-7ED06CBE99A0@r-project.org>
Message-ID: <4D52AD7B.6070402@gmail.com>

On 11-02-08 10:03 PM, Simon Urbanek wrote:
> Ben,
> 
> did you actually look at the result of your function with useRaster=TRUE ? ;) [Hint: don't use an image that is symmetric]
> 
> Apart from that nice bug there are more issues as well, try
> image(matrix(1:4,2),col=1:3)
> The underlying issue is that as.raster() is not quite what you would hope. 
> Unfortunately I'm not aware of an easy fix (that doesn't involve going
back to RGB decomposition).
> 
> In general, I think it's a nice option, but I don't think you'll get away with only a few lines...
> 
> Cheers,
> Simon
> 
> 
> 
> On Feb 8, 2011, at 8:49 PM, Ben Bolker wrote:
> 
>>
>>  Has anyone yet tried incorporating rasterImage into the base image()
>> function?  It seems to make a *huge* difference, with
>> a very small number of added/changed lines of code.  (Of course I have
>> barely tested it at all.)
>>  Is there any reason this *shouldn't* go into the next release?
>>
>>> source("image.R")
>>> z <- matrix(runif(1e6),nrow=1000)
>>> image(z)
>>> image(z,useRaster=TRUE)
>>
>>  (Patch against SVN 54284 attached; people can contact me if it doesn't
>> go through and they want it.)
>>
>>  Ben Bolker
>>
>> <image_diff.txt>______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel

  Trying again. Rotated counterclockwise within R (although this *could*
be coded in C if speed were important?)
  Some brute-force testing suggests it is *slightly* slower for small
images (7 vs 8 seconds for 1000 reps) and still much faster (and
produces much smaller images, which don't suffer from antialiasing junk
in my PDF viewer) for large images.
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: image_diff.txt
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110209/9db1839e/attachment.txt>
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: imagetest.R
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110209/9db1839e/attachment.pl>
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: image.R
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110209/9db1839e/attachment-0001.pl>

From asr at ufl.edu  Wed Feb  9 20:05:36 2011
From: asr at ufl.edu (Allen S. Rout)
Date: Wed, 9 Feb 2011 14:05:36 -0500
Subject: [Rd] dependencies on system packages
References: <1296786690226-3259395.post@n4.nabble.com>
	<189F3930-6DA0-4EF5-B419-CB5AAA5EF68B@r-project.org>
	<4D4BB638.8030409@units.it>
	<EDBA419B-0DEF-4B3F-B2AE-29303D89999C@r-project.org>
	<19788.17488.126990.458044@max.nulle.part>
	<073563D8-365F-45B8-8DFD-6B521968B8E6@r-project.org>
Message-ID: <87vd0t2flr.fsf@ufl.edu>

Simon Urbanek <simon.urbanek at r-project.org> writes:
> On Feb 4, 2011, at 1:24 PM, Dirk Eddelbuettel wrote:

[...]

>> We need to address this: With 2600+ packages and continued growth,
>> manually wading through README is not good enough.  We should do
>> better.  Resources (time, money, servers, ...) would help.  Maybe one
>> day someone with more time can fold this into a proper sub-project of
>> a larger grant application.  It would be worth, and I would try to
>> help, time permitting.


I'm one of the people who made stabs at this in the past.  I had a
fairly complete Gentoo process in place, but then the sickness passed.

More recently, I've been peripherally involved with an effort to
translate CRAN to redhat-land.

When we talked about this most intensely last (waaay back in 2006), I
had a detailed submission for an "Extended depends string", a strictly
formatted field to accompany or supplant the existing system depends.

I also supplied suggested code to translate a string in this format to a
simple depstring, which would neatly plug into the existing depstring
infrastructure already in place.  


http://article.gmane.org/gmane.comp.lang.r.devel/9179


So, for an example extended depstring

src <- "libgd (>= 1.9.0) (gentoo gd >= 2.0) (debian >= 1.9.2)"

extdepstring2depstring(src)

yields "libgd (>= 1.9.0)"

and

extdepstring2depstring(src,systype="debian")

yields "libgd (>= 1.9.2)"

and 

extdepstring2depstring(src,systype="unknown")

yields the default. 



I think this would be preferable to a growing taxonomy of 

Depends-[system]: 




- Allen S. Rout


From simon.urbanek at r-project.org  Wed Feb  9 20:25:04 2011
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Wed, 9 Feb 2011 14:25:04 -0500
Subject: [Rd] using rasterImage within image
In-Reply-To: <4D52AD7B.6070402@gmail.com>
References: <4D51F2A7.8010505@mcmaster.ca>
	<D8F5413E-025A-4511-BCE1-7ED06CBE99A0@r-project.org>
	<4D52AD7B.6070402@gmail.com>
Message-ID: <E86B0A90-F63F-4537-A7FB-1AA84D685154@r-project.org>

Ben,

I have committed something analogous to R-devel (your rotation code was not unlike mine, I replicated the color handling from R internals to be consistent, I fixed the drawing limits and added a check for x/y conformance). Note that useRaster can only be used when x, y form a regular grid. Although I tried a lot of corner cases (requiring quite a few fixes), I'm sure I did not test all of them, so volunteers please give it a go and compare it with non-raster output.

The only thing I'm not quite happy about is the argument name: useRaster. Personally, I hate camel case in R (it has crept in more recently making it horribly inconsistent) so please feel free to suggest a better name ;).

Thanks,
Simon


On Feb 9, 2011, at 10:06 AM, Ben Bolker wrote:

> On 11-02-08 10:03 PM, Simon Urbanek wrote:
>> Ben,
>> 
>> did you actually look at the result of your function with useRaster=TRUE ? ;) [Hint: don't use an image that is symmetric]
>> 
>> Apart from that nice bug there are more issues as well, try
>> image(matrix(1:4,2),col=1:3)
>> The underlying issue is that as.raster() is not quite what you would hope. 
>> Unfortunately I'm not aware of an easy fix (that doesn't involve going
> back to RGB decomposition).
>> 
>> In general, I think it's a nice option, but I don't think you'll get away with only a few lines...
>> 
>> Cheers,
>> Simon
>> 
>> 
>> 
>> On Feb 8, 2011, at 8:49 PM, Ben Bolker wrote:
>> 
>>> 
>>> Has anyone yet tried incorporating rasterImage into the base image()
>>> function?  It seems to make a *huge* difference, with
>>> a very small number of added/changed lines of code.  (Of course I have
>>> barely tested it at all.)
>>> Is there any reason this *shouldn't* go into the next release?
>>> 
>>>> source("image.R")
>>>> z <- matrix(runif(1e6),nrow=1000)
>>>> image(z)
>>>> image(z,useRaster=TRUE)
>>> 
>>> (Patch against SVN 54284 attached; people can contact me if it doesn't
>>> go through and they want it.)
>>> 
>>> Ben Bolker
>>> 
>>> <image_diff.txt>______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
>  Trying again. Rotated counterclockwise within R (although this *could*
> be coded in C if speed were important?)
>  Some brute-force testing suggests it is *slightly* slower for small
> images (7 vs 8 seconds for 1000 reps) and still much faster (and
> produces much smaller images, which don't suffer from antialiasing junk
> in my PDF viewer) for large images.
> <image_diff.txt><imagetest.R><image.R>


From hb at biostat.ucsf.edu  Wed Feb  9 20:36:58 2011
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Wed, 9 Feb 2011 11:36:58 -0800
Subject: [Rd] using rasterImage within image
In-Reply-To: <E86B0A90-F63F-4537-A7FB-1AA84D685154@r-project.org>
References: <4D51F2A7.8010505@mcmaster.ca>
	<D8F5413E-025A-4511-BCE1-7ED06CBE99A0@r-project.org>
	<4D52AD7B.6070402@gmail.com>
	<E86B0A90-F63F-4537-A7FB-1AA84D685154@r-project.org>
Message-ID: <AANLkTi=yRP56wACtOs+Ouc70EV57rw9RKYmfLAh2hQ8a@mail.gmail.com>

On Wed, Feb 9, 2011 at 11:25 AM, Simon Urbanek
<simon.urbanek at r-project.org> wrote:
> Ben,
>
> I have committed something analogous to R-devel (your rotation code was not unlike mine, I replicated the color handling from R internals to be consistent, I fixed the drawing limits and added a check for x/y conformance). Note that useRaster can only be used when x, y form a regular grid. Although I tried a lot of corner cases (requiring quite a few fixes), I'm sure I did not test all of them, so volunteers please give it a go and compare it with non-raster output.
>
> The only thing I'm not quite happy about is the argument name: useRaster. Personally, I hate camel case in R (it has crept in more recently making it horribly inconsistent) so please feel free to suggest a better name ;).

It.is.spelled.camelCase.

What about style=c("image", "raster")?  This allows for future extensions too.

/H

>
> Thanks,
> Simon
>
>
> On Feb 9, 2011, at 10:06 AM, Ben Bolker wrote:
>
>> On 11-02-08 10:03 PM, Simon Urbanek wrote:
>>> Ben,
>>>
>>> did you actually look at the result of your function with useRaster=TRUE ? ;) [Hint: don't use an image that is symmetric]
>>>
>>> Apart from that nice bug there are more issues as well, try
>>> image(matrix(1:4,2),col=1:3)
>>> The underlying issue is that as.raster() is not quite what you would hope.
>>> Unfortunately I'm not aware of an easy fix (that doesn't involve going
>> back to RGB decomposition).
>>>
>>> In general, I think it's a nice option, but I don't think you'll get away with only a few lines...
>>>
>>> Cheers,
>>> Simon
>>>
>>>
>>>
>>> On Feb 8, 2011, at 8:49 PM, Ben Bolker wrote:
>>>
>>>>
>>>> Has anyone yet tried incorporating rasterImage into the base image()
>>>> function? ?It seems to make a *huge* difference, with
>>>> a very small number of added/changed lines of code. ?(Of course I have
>>>> barely tested it at all.)
>>>> Is there any reason this *shouldn't* go into the next release?
>>>>
>>>>> source("image.R")
>>>>> z <- matrix(runif(1e6),nrow=1000)
>>>>> image(z)
>>>>> image(z,useRaster=TRUE)
>>>>
>>>> (Patch against SVN 54284 attached; people can contact me if it doesn't
>>>> go through and they want it.)
>>>>
>>>> Ben Bolker
>>>>
>>>> <image_diff.txt>______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>> ?Trying again. Rotated counterclockwise within R (although this *could*
>> be coded in C if speed were important?)
>> ?Some brute-force testing suggests it is *slightly* slower for small
>> images (7 vs 8 seconds for 1000 reps) and still much faster (and
>> produces much smaller images, which don't suffer from antialiasing junk
>> in my PDF viewer) for large images.
>> <image_diff.txt><imagetest.R><image.R>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From simon.urbanek at r-project.org  Wed Feb  9 20:53:59 2011
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Wed, 9 Feb 2011 14:53:59 -0500
Subject: [Rd] using rasterImage within image
In-Reply-To: <AANLkTi=yRP56wACtOs+Ouc70EV57rw9RKYmfLAh2hQ8a@mail.gmail.com>
References: <4D51F2A7.8010505@mcmaster.ca>
	<D8F5413E-025A-4511-BCE1-7ED06CBE99A0@r-project.org>
	<4D52AD7B.6070402@gmail.com>
	<E86B0A90-F63F-4537-A7FB-1AA84D685154@r-project.org>
	<AANLkTi=yRP56wACtOs+Ouc70EV57rw9RKYmfLAh2hQ8a@mail.gmail.com>
Message-ID: <825F0B1E-EF80-48F5-AFF1-5832092450AB@r-project.org>


On Feb 9, 2011, at 2:36 PM, Henrik Bengtsson wrote:

> On Wed, Feb 9, 2011 at 11:25 AM, Simon Urbanek
> <simon.urbanek at r-project.org> wrote:
>> Ben,
>> 
>> I have committed something analogous to R-devel (your rotation code was not unlike mine, I replicated the color handling from R internals to be consistent, I fixed the drawing limits and added a check for x/y conformance). Note that useRaster can only be used when x, y form a regular grid. Although I tried a lot of corner cases (requiring quite a few fixes), I'm sure I did not test all of them, so volunteers please give it a go and compare it with non-raster output.
>> 
>> The only thing I'm not quite happy about is the argument name: useRaster. Personally, I hate camel case in R (it has crept in more recently making it horribly inconsistent) so please feel free to suggest a better name ;).
> 
> It.is.spelled.camelCase.
> 

Fortunately not in English ;)


> What about style=c("image", "raster")?  This allows for future extensions too.
> 

Hmm.. it's not really a "style" - the output doesn't change (ideally) - it's more of a back-end specification .. also we already have oldstyle argument in image() adding to the confusion ...

Thanks,
Simon


>> 
>> Thanks,
>> Simon
>> 
>> 
>> On Feb 9, 2011, at 10:06 AM, Ben Bolker wrote:
>> 
>>> On 11-02-08 10:03 PM, Simon Urbanek wrote:
>>>> Ben,
>>>> 
>>>> did you actually look at the result of your function with useRaster=TRUE ? ;) [Hint: don't use an image that is symmetric]
>>>> 
>>>> Apart from that nice bug there are more issues as well, try
>>>> image(matrix(1:4,2),col=1:3)
>>>> The underlying issue is that as.raster() is not quite what you would hope.
>>>> Unfortunately I'm not aware of an easy fix (that doesn't involve going
>>> back to RGB decomposition).
>>>> 
>>>> In general, I think it's a nice option, but I don't think you'll get away with only a few lines...
>>>> 
>>>> Cheers,
>>>> Simon
>>>> 
>>>> 
>>>> 
>>>> On Feb 8, 2011, at 8:49 PM, Ben Bolker wrote:
>>>> 
>>>>> 
>>>>> Has anyone yet tried incorporating rasterImage into the base image()
>>>>> function?  It seems to make a *huge* difference, with
>>>>> a very small number of added/changed lines of code.  (Of course I have
>>>>> barely tested it at all.)
>>>>> Is there any reason this *shouldn't* go into the next release?
>>>>> 
>>>>>> source("image.R")
>>>>>> z <- matrix(runif(1e6),nrow=1000)
>>>>>> image(z)
>>>>>> image(z,useRaster=TRUE)
>>>>> 
>>>>> (Patch against SVN 54284 attached; people can contact me if it doesn't
>>>>> go through and they want it.)
>>>>> 
>>>>> Ben Bolker
>>>>> 
>>>>> <image_diff.txt>______________________________________________
>>>>> R-devel at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>> 
>>>  Trying again. Rotated counterclockwise within R (although this *could*
>>> be coded in C if speed were important?)
>>>  Some brute-force testing suggests it is *slightly* slower for small
>>> images (7 vs 8 seconds for 1000 reps) and still much faster (and
>>> produces much smaller images, which don't suffer from antialiasing junk
>>> in my PDF viewer) for large images.
>>> <image_diff.txt><imagetest.R><image.R>
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> 
> 
> 


From hb at biostat.ucsf.edu  Wed Feb  9 21:09:33 2011
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Wed, 9 Feb 2011 12:09:33 -0800
Subject: [Rd] using rasterImage within image
In-Reply-To: <825F0B1E-EF80-48F5-AFF1-5832092450AB@r-project.org>
References: <4D51F2A7.8010505@mcmaster.ca>
	<D8F5413E-025A-4511-BCE1-7ED06CBE99A0@r-project.org>
	<4D52AD7B.6070402@gmail.com>
	<E86B0A90-F63F-4537-A7FB-1AA84D685154@r-project.org>
	<AANLkTi=yRP56wACtOs+Ouc70EV57rw9RKYmfLAh2hQ8a@mail.gmail.com>
	<825F0B1E-EF80-48F5-AFF1-5832092450AB@r-project.org>
Message-ID: <AANLkTi=0K6hCP0tptSf6h4S6au+-SmahDm983zRdZEgb@mail.gmail.com>

On Wed, Feb 9, 2011 at 11:53 AM, Simon Urbanek
<simon.urbanek at r-project.org> wrote:
>
> On Feb 9, 2011, at 2:36 PM, Henrik Bengtsson wrote:
>
>> On Wed, Feb 9, 2011 at 11:25 AM, Simon Urbanek
>> <simon.urbanek at r-project.org> wrote:
>>> Ben,
>>>
>>> I have committed something analogous to R-devel (your rotation code was not unlike mine, I replicated the color handling from R internals to be consistent, I fixed the drawing limits and added a check for x/y conformance). Note that useRaster can only be used when x, y form a regular grid. Although I tried a lot of corner cases (requiring quite a few fixes), I'm sure I did not test all of them, so volunteers please give it a go and compare it with non-raster output.
>>>
>>> The only thing I'm not quite happy about is the argument name: useRaster. Personally, I hate camel case in R (it has crept in more recently making it horribly inconsistent) so please feel free to suggest a better name ;).
>>
>> It.is.spelled.camelCase.
>>
>
> Fortunately not in English ;)
>
>
>> What about style=c("image", "raster")? ?This allows for future extensions too.
>>
>
> Hmm.. it's not really a "style" - the output doesn't change (ideally) - it's more of a back-end specification .. also we already have oldstyle argument in image() adding to the confusion ...

flavor=c("image", "raster")
renderer=c("image", "raster")
backend=c("image", "raster")
...

?

/H

>
> Thanks,
> Simon
>
>
>>>
>>> Thanks,
>>> Simon
>>>
>>>
>>> On Feb 9, 2011, at 10:06 AM, Ben Bolker wrote:
>>>
>>>> On 11-02-08 10:03 PM, Simon Urbanek wrote:
>>>>> Ben,
>>>>>
>>>>> did you actually look at the result of your function with useRaster=TRUE ? ;) [Hint: don't use an image that is symmetric]
>>>>>
>>>>> Apart from that nice bug there are more issues as well, try
>>>>> image(matrix(1:4,2),col=1:3)
>>>>> The underlying issue is that as.raster() is not quite what you would hope.
>>>>> Unfortunately I'm not aware of an easy fix (that doesn't involve going
>>>> back to RGB decomposition).
>>>>>
>>>>> In general, I think it's a nice option, but I don't think you'll get away with only a few lines...
>>>>>
>>>>> Cheers,
>>>>> Simon
>>>>>
>>>>>
>>>>>
>>>>> On Feb 8, 2011, at 8:49 PM, Ben Bolker wrote:
>>>>>
>>>>>>
>>>>>> Has anyone yet tried incorporating rasterImage into the base image()
>>>>>> function? ?It seems to make a *huge* difference, with
>>>>>> a very small number of added/changed lines of code. ?(Of course I have
>>>>>> barely tested it at all.)
>>>>>> Is there any reason this *shouldn't* go into the next release?
>>>>>>
>>>>>>> source("image.R")
>>>>>>> z <- matrix(runif(1e6),nrow=1000)
>>>>>>> image(z)
>>>>>>> image(z,useRaster=TRUE)
>>>>>>
>>>>>> (Patch against SVN 54284 attached; people can contact me if it doesn't
>>>>>> go through and they want it.)
>>>>>>
>>>>>> Ben Bolker
>>>>>>
>>>>>> <image_diff.txt>______________________________________________
>>>>>> R-devel at r-project.org mailing list
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>
>>>> ?Trying again. Rotated counterclockwise within R (although this *could*
>>>> be coded in C if speed were important?)
>>>> ?Some brute-force testing suggests it is *slightly* slower for small
>>>> images (7 vs 8 seconds for 1000 reps) and still much faster (and
>>>> produces much smaller images, which don't suffer from antialiasing junk
>>>> in my PDF viewer) for large images.
>>>> <image_diff.txt><imagetest.R><image.R>
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>
>>
>
>


From bbolker at gmail.com  Wed Feb  9 23:29:44 2011
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 9 Feb 2011 17:29:44 -0500
Subject: [Rd] using rasterImage within image
In-Reply-To: <AANLkTi=0K6hCP0tptSf6h4S6au+-SmahDm983zRdZEgb@mail.gmail.com>
References: <4D51F2A7.8010505@mcmaster.ca>	<D8F5413E-025A-4511-BCE1-7ED06CBE99A0@r-project.org>	<4D52AD7B.6070402@gmail.com>	<E86B0A90-F63F-4537-A7FB-1AA84D685154@r-project.org>	<AANLkTi=yRP56wACtOs+Ouc70EV57rw9RKYmfLAh2hQ8a@mail.gmail.com>	<825F0B1E-EF80-48F5-AFF1-5832092450AB@r-project.org>
	<AANLkTi=0K6hCP0tptSf6h4S6au+-SmahDm983zRdZEgb@mail.gmail.com>
Message-ID: <4D531558.7010709@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 11-02-09 03:09 PM, Henrik Bengtsson wrote:
> On Wed, Feb 9, 2011 at 11:53 AM, Simon Urbanek 
> <simon.urbanek at r-project.org> wrote:
>> 
>> On Feb 9, 2011, at 2:36 PM, Henrik Bengtsson wrote:
>> 
>>> On Wed, Feb 9, 2011 at 11:25 AM, Simon Urbanek 
>>> <simon.urbanek at r-project.org> wrote:
>>>> Ben,
>>>> 
>>>> I have committed something analogous to R-devel (your rotation
>>>> code was not unlike mine, I replicated the color handling from
>>>> R internals to be consistent, I fixed the drawing limits and
>>>> added a check for x/y conformance). Note that useRaster can
>>>> only be used when x, y form a regular grid. Although I tried a
>>>> lot of corner cases (requiring quite a few fixes), I'm sure I
>>>> did not test all of them, so volunteers please give it a go and
>>>> compare it with non-raster output.
>>>> 
>>>> The only thing I'm not quite happy about is the argument name:
>>>> useRaster. Personally, I hate camel case in R (it has crept in
>>>> more recently making it horribly inconsistent) so please feel
>>>> free to suggest a better name ;).
>>> 
>>> It.is.spelled.camelCase.
>>> 
>> 
>> Fortunately not in English ;)
>> 
>> 
>>> What about style=c("image", "raster")?  This allows for future
>>> extensions too.
>>> 
>> 
>> Hmm.. it's not really a "style" - the output doesn't change
>> (ideally) - it's more of a back-end specification .. also we
>> already have oldstyle argument in image() adding to the confusion
>> ...
> 
> flavor=c("image", "raster") renderer=c("image", "raster") 
> backend=c("image", "raster") ...

  Thanks Simon! (Any reports on the SDI Windows raster rendering issue,
or do we need a warning/workaround there?)

  I like "backend", or possibly "method"

  One minor consideration: if "raster" eventually becomes the default
(as I hope it will), there would need to be some internal logic that
drops back to "image" if the user specifies uneven spacing and doesn't
explicitly specify the 'backend/method' parameter ...
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.10 (GNU/Linux)
Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org/

iEYEARECAAYFAk1TFVcACgkQc5UpGjwzenOa6ACfVnJq67cG0czATeyti7AxgUbw
ZWwAniA7JuYCv4clq8e6jwWQuMvw/r+m
=/da6
-----END PGP SIGNATURE-----


From mdsumner at gmail.com  Wed Feb  9 23:41:10 2011
From: mdsumner at gmail.com (Michael Sumner)
Date: Thu, 10 Feb 2011 09:41:10 +1100
Subject: [Rd] using rasterImage within image
In-Reply-To: <4D531558.7010709@gmail.com>
References: <4D51F2A7.8010505@mcmaster.ca>
	<D8F5413E-025A-4511-BCE1-7ED06CBE99A0@r-project.org>
	<4D52AD7B.6070402@gmail.com>
	<E86B0A90-F63F-4537-A7FB-1AA84D685154@r-project.org>
	<AANLkTi=yRP56wACtOs+Ouc70EV57rw9RKYmfLAh2hQ8a@mail.gmail.com>
	<825F0B1E-EF80-48F5-AFF1-5832092450AB@r-project.org>
	<AANLkTi=0K6hCP0tptSf6h4S6au+-SmahDm983zRdZEgb@mail.gmail.com>
	<4D531558.7010709@gmail.com>
Message-ID: <AANLkTi=KCruG2vDST6K1uBsG5NwQ6d-pELfhYh4N1bvC@mail.gmail.com>

Regarding the SDI problem, I'll check that as soon as the next
snapshot build of 2.13.0 is available from CRAN (probably a few days
from now, unless I can manage to compile it myself).

Cheers, Mike.

On Thu, Feb 10, 2011 at 9:29 AM, Ben Bolker <bbolker at gmail.com> wrote:
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
>
> On 11-02-09 03:09 PM, Henrik Bengtsson wrote:
>> On Wed, Feb 9, 2011 at 11:53 AM, Simon Urbanek
>> <simon.urbanek at r-project.org> wrote:
>>>
>>> On Feb 9, 2011, at 2:36 PM, Henrik Bengtsson wrote:
>>>
>>>> On Wed, Feb 9, 2011 at 11:25 AM, Simon Urbanek
>>>> <simon.urbanek at r-project.org> wrote:
>>>>> Ben,
>>>>>
>>>>> I have committed something analogous to R-devel (your rotation
>>>>> code was not unlike mine, I replicated the color handling from
>>>>> R internals to be consistent, I fixed the drawing limits and
>>>>> added a check for x/y conformance). Note that useRaster can
>>>>> only be used when x, y form a regular grid. Although I tried a
>>>>> lot of corner cases (requiring quite a few fixes), I'm sure I
>>>>> did not test all of them, so volunteers please give it a go and
>>>>> compare it with non-raster output.
>>>>>
>>>>> The only thing I'm not quite happy about is the argument name:
>>>>> useRaster. Personally, I hate camel case in R (it has crept in
>>>>> more recently making it horribly inconsistent) so please feel
>>>>> free to suggest a better name ;).
>>>>
>>>> It.is.spelled.camelCase.
>>>>
>>>
>>> Fortunately not in English ;)
>>>
>>>
>>>> What about style=c("image", "raster")? ?This allows for future
>>>> extensions too.
>>>>
>>>
>>> Hmm.. it's not really a "style" - the output doesn't change
>>> (ideally) - it's more of a back-end specification .. also we
>>> already have oldstyle argument in image() adding to the confusion
>>> ...
>>
>> flavor=c("image", "raster") renderer=c("image", "raster")
>> backend=c("image", "raster") ...
>
> ?Thanks Simon! (Any reports on the SDI Windows raster rendering issue,
> or do we need a warning/workaround there?)
>
> ?I like "backend", or possibly "method"
>
> ?One minor consideration: if "raster" eventually becomes the default
> (as I hope it will), there would need to be some internal logic that
> drops back to "image" if the user specifies uneven spacing and doesn't
> explicitly specify the 'backend/method' parameter ...
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v1.4.10 (GNU/Linux)
> Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org/
>
> iEYEARECAAYFAk1TFVcACgkQc5UpGjwzenOa6ACfVnJq67cG0czATeyti7AxgUbw
> ZWwAniA7JuYCv4clq8e6jwWQuMvw/r+m
> =/da6
> -----END PGP SIGNATURE-----
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>



-- 
Michael Sumner
Institute for Marine and Antarctic Studies, University of Tasmania
Hobart, Australia
e-mail: mdsumner at gmail.com


From JHZhang at mdanderson.org  Thu Feb 10 00:01:05 2011
From: JHZhang at mdanderson.org (Zhang,Jun)
Date: Wed, 9 Feb 2011 17:01:05 -0600
Subject: [Rd] Problem installing MCMCpack on SPARC Solaris 10
Message-ID: <5685E4FBA752A441B1975A77A77CD648252B6B1573@DCPWVMBXC1VS2.mdanderson.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110209/e950be7e/attachment.pl>

From nakama at ki.rim.or.jp  Thu Feb 10 04:20:21 2011
From: nakama at ki.rim.or.jp (Ei-ji Nakama)
Date: Thu, 10 Feb 2011 12:20:21 +0900
Subject: [Rd] SurviveGotoBLAS2 for Win64 (RC release)
Message-ID: <AANLkTinYxjmGQvf-G8X1jBa3W7oF5N36d833jB6P7txz@mail.gmail.com>

Hi,

I put below Rblas.dll(GotoBLAS2 for Win64).
http://prs.ism.ac.jp/~nakama/SurviveGotoBLAS2/binary/windows/x64/
please choose the core-name of your CPU.
The recognition of the CPU of DYNAMIC_ARCH is low.

zdot[cu], zgemv came to calculate definitely.

-- 
EI-JI Nakama? <nakama (a) ki.rim.or.jp>
"\u4e2d\u9593\u6804\u6cbb"? <nakama (a) ki.rim.or.jp>


From nugulus at yahoo.com  Wed Feb  9 23:57:24 2011
From: nugulus at yahoo.com (Jun Zhang)
Date: Wed, 9 Feb 2011 14:57:24 -0800 (PST)
Subject: [Rd] Problem installing MCMCpack on SPARC Solaris 10
Message-ID: <299270.46458.qm@web57610.mail.re1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110209/ef7e84e8/attachment.pl>

From baptiste.auguie at googlemail.com  Thu Feb 10 07:31:04 2011
From: baptiste.auguie at googlemail.com (baptiste auguie)
Date: Thu, 10 Feb 2011 07:31:04 +0100
Subject: [Rd] using rasterImage within image
In-Reply-To: <4D531558.7010709@gmail.com>
References: <4D51F2A7.8010505@mcmaster.ca>
	<D8F5413E-025A-4511-BCE1-7ED06CBE99A0@r-project.org>
	<4D52AD7B.6070402@gmail.com>
	<E86B0A90-F63F-4537-A7FB-1AA84D685154@r-project.org>
	<AANLkTi=yRP56wACtOs+Ouc70EV57rw9RKYmfLAh2hQ8a@mail.gmail.com>
	<825F0B1E-EF80-48F5-AFF1-5832092450AB@r-project.org>
	<AANLkTi=0K6hCP0tptSf6h4S6au+-SmahDm983zRdZEgb@mail.gmail.com>
	<4D531558.7010709@gmail.com>
Message-ID: <AANLkTi=nwF-3UjtoFAaLdTwphmezvuk57HaaJd57=am2@mail.gmail.com>

Dear all,

Back when grid.raster() was introduced, it was suggested that perhaps
grid.rect() could use grid.raster() in case of even spacing. The
response at the time was that it would be best to keep the two
functions separate at a lower level, that is grid.rect() and
grid.raster(), but perhaps a new function grid.image() could be
proposed at a higher level with the two possible backends. If this is
done in grid graphics, perhaps the same convention could be used for
base graphics: image() would be high level with the backend option,
and a new function ("tiles()", perhaps?) would implement the current
behavior of image().

In any case, it would be nice to have a unified scheme to switch
between "tiles" and raster; currently lattice (panl.levelplot.raster)
and a few other packages all do it separately.

Best wishes,

baptiste



On 9 February 2011 23:29, Ben Bolker <bbolker at gmail.com> wrote:
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
>
> On 11-02-09 03:09 PM, Henrik Bengtsson wrote:
>> On Wed, Feb 9, 2011 at 11:53 AM, Simon Urbanek
>> <simon.urbanek at r-project.org> wrote:
>>>
>>> On Feb 9, 2011, at 2:36 PM, Henrik Bengtsson wrote:
>>>
>>>> On Wed, Feb 9, 2011 at 11:25 AM, Simon Urbanek
>>>> <simon.urbanek at r-project.org> wrote:
>>>>> Ben,
>>>>>
>>>>> I have committed something analogous to R-devel (your rotation
>>>>> code was not unlike mine, I replicated the color handling from
>>>>> R internals to be consistent, I fixed the drawing limits and
>>>>> added a check for x/y conformance). Note that useRaster can
>>>>> only be used when x, y form a regular grid. Although I tried a
>>>>> lot of corner cases (requiring quite a few fixes), I'm sure I
>>>>> did not test all of them, so volunteers please give it a go and
>>>>> compare it with non-raster output.
>>>>>
>>>>> The only thing I'm not quite happy about is the argument name:
>>>>> useRaster. Personally, I hate camel case in R (it has crept in
>>>>> more recently making it horribly inconsistent) so please feel
>>>>> free to suggest a better name ;).
>>>>
>>>> It.is.spelled.camelCase.
>>>>
>>>
>>> Fortunately not in English ;)
>>>
>>>
>>>> What about style=c("image", "raster")? ?This allows for future
>>>> extensions too.
>>>>
>>>
>>> Hmm.. it's not really a "style" - the output doesn't change
>>> (ideally) - it's more of a back-end specification .. also we
>>> already have oldstyle argument in image() adding to the confusion
>>> ...
>>
>> flavor=c("image", "raster") renderer=c("image", "raster")
>> backend=c("image", "raster") ...
>
> ?Thanks Simon! (Any reports on the SDI Windows raster rendering issue,
> or do we need a warning/workaround there?)
>
> ?I like "backend", or possibly "method"
>
> ?One minor consideration: if "raster" eventually becomes the default
> (as I hope it will), there would need to be some internal logic that
> drops back to "image" if the user specifies uneven spacing and doesn't
> explicitly specify the 'backend/method' parameter ...
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v1.4.10 (GNU/Linux)
> Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org/
>
> iEYEARECAAYFAk1TFVcACgkQc5UpGjwzenOa6ACfVnJq67cG0czATeyti7AxgUbw
> ZWwAniA7JuYCv4clq8e6jwWQuMvw/r+m
> =/da6
> -----END PGP SIGNATURE-----
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From mdsumner at gmail.com  Thu Feb 10 07:54:06 2011
From: mdsumner at gmail.com (Michael Sumner)
Date: Thu, 10 Feb 2011 17:54:06 +1100
Subject: [Rd] using rasterImage within image
In-Reply-To: <AANLkTi=nwF-3UjtoFAaLdTwphmezvuk57HaaJd57=am2@mail.gmail.com>
References: <4D51F2A7.8010505@mcmaster.ca>
	<D8F5413E-025A-4511-BCE1-7ED06CBE99A0@r-project.org>
	<4D52AD7B.6070402@gmail.com>
	<E86B0A90-F63F-4537-A7FB-1AA84D685154@r-project.org>
	<AANLkTi=yRP56wACtOs+Ouc70EV57rw9RKYmfLAh2hQ8a@mail.gmail.com>
	<825F0B1E-EF80-48F5-AFF1-5832092450AB@r-project.org>
	<AANLkTi=0K6hCP0tptSf6h4S6au+-SmahDm983zRdZEgb@mail.gmail.com>
	<4D531558.7010709@gmail.com>
	<AANLkTi=nwF-3UjtoFAaLdTwphmezvuk57HaaJd57=am2@mail.gmail.com>
Message-ID: <AANLkTimHAmzq4CEJF-auHRSA8745x2yb8r_GK9+vTrKJ@mail.gmail.com>

Hello, I'm afraid the SDI graphics issue is still a problem in 2.13.0
2011-02-09 r54308.

To reproduce, in a fresh R session (Windows in SDI mode):

## create a dummy dataset
m<- matrix(c(0.2, 0.4, 0.6, 0.8), 2, 2)

## simple helper function to open the windows() device and plot the matrix
draw.f<- function(x) {
   plot(0, xlim = c(0, 1), ylim = c(0, 1))
   rasterImage(x, 0, 0, 1, 1, interpolate = FALSE)
}

draw.f(m)

## repeat the following 2 lines five times:

dev.off()
draw.f(m)

On the fifth attempt, only the background plot appears - but the
raster is visible on resize of the windows() device.

Cheers, Mike.

sessionInfo()
R version 2.13.0 Under development (unstable) (2011-02-09 r54308)
Platform: x86_64-pc-mingw32/x64 (64-bit)

locale:
[1] LC_COLLATE=English_Australia.1252  LC_CTYPE=English_Australia.1252
[3] LC_MONETARY=English_Australia.1252 LC_NUMERIC=C
[5] LC_TIME=English_Australia.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base



On Thu, Feb 10, 2011 at 5:31 PM, baptiste auguie
<baptiste.auguie at googlemail.com> wrote:
> Dear all,
>
> Back when grid.raster() was introduced, it was suggested that perhaps
> grid.rect() could use grid.raster() in case of even spacing. The
> response at the time was that it would be best to keep the two
> functions separate at a lower level, that is grid.rect() and
> grid.raster(), but perhaps a new function grid.image() could be
> proposed at a higher level with the two possible backends. If this is
> done in grid graphics, perhaps the same convention could be used for
> base graphics: image() would be high level with the backend option,
> and a new function ("tiles()", perhaps?) would implement the current
> behavior of image().
>
> In any case, it would be nice to have a unified scheme to switch
> between "tiles" and raster; currently lattice (panl.levelplot.raster)
> and a few other packages all do it separately.
>
> Best wishes,
>
> baptiste
>
>
>
> On 9 February 2011 23:29, Ben Bolker <bbolker at gmail.com> wrote:
>> -----BEGIN PGP SIGNED MESSAGE-----
>> Hash: SHA1
>>
>> On 11-02-09 03:09 PM, Henrik Bengtsson wrote:
>>> On Wed, Feb 9, 2011 at 11:53 AM, Simon Urbanek
>>> <simon.urbanek at r-project.org> wrote:
>>>>
>>>> On Feb 9, 2011, at 2:36 PM, Henrik Bengtsson wrote:
>>>>
>>>>> On Wed, Feb 9, 2011 at 11:25 AM, Simon Urbanek
>>>>> <simon.urbanek at r-project.org> wrote:
>>>>>> Ben,
>>>>>>
>>>>>> I have committed something analogous to R-devel (your rotation
>>>>>> code was not unlike mine, I replicated the color handling from
>>>>>> R internals to be consistent, I fixed the drawing limits and
>>>>>> added a check for x/y conformance). Note that useRaster can
>>>>>> only be used when x, y form a regular grid. Although I tried a
>>>>>> lot of corner cases (requiring quite a few fixes), I'm sure I
>>>>>> did not test all of them, so volunteers please give it a go and
>>>>>> compare it with non-raster output.
>>>>>>
>>>>>> The only thing I'm not quite happy about is the argument name:
>>>>>> useRaster. Personally, I hate camel case in R (it has crept in
>>>>>> more recently making it horribly inconsistent) so please feel
>>>>>> free to suggest a better name ;).
>>>>>
>>>>> It.is.spelled.camelCase.
>>>>>
>>>>
>>>> Fortunately not in English ;)
>>>>
>>>>
>>>>> What about style=c("image", "raster")? ?This allows for future
>>>>> extensions too.
>>>>>
>>>>
>>>> Hmm.. it's not really a "style" - the output doesn't change
>>>> (ideally) - it's more of a back-end specification .. also we
>>>> already have oldstyle argument in image() adding to the confusion
>>>> ...
>>>
>>> flavor=c("image", "raster") renderer=c("image", "raster")
>>> backend=c("image", "raster") ...
>>
>> ?Thanks Simon! (Any reports on the SDI Windows raster rendering issue,
>> or do we need a warning/workaround there?)
>>
>> ?I like "backend", or possibly "method"
>>
>> ?One minor consideration: if "raster" eventually becomes the default
>> (as I hope it will), there would need to be some internal logic that
>> drops back to "image" if the user specifies uneven spacing and doesn't
>> explicitly specify the 'backend/method' parameter ...
>> -----BEGIN PGP SIGNATURE-----
>> Version: GnuPG v1.4.10 (GNU/Linux)
>> Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org/
>>
>> iEYEARECAAYFAk1TFVcACgkQc5UpGjwzenOa6ACfVnJq67cG0czATeyti7AxgUbw
>> ZWwAniA7JuYCv4clq8e6jwWQuMvw/r+m
>> =/da6
>> -----END PGP SIGNATURE-----
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>



-- 
Michael Sumner
Institute for Marine and Antarctic Studies, University of Tasmania
Hobart, Australia
e-mail: mdsumner at gmail.com


From ripley at stats.ox.ac.uk  Thu Feb 10 08:08:10 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 10 Feb 2011 07:08:10 +0000 (GMT)
Subject: [Rd] Problem installing MCMCpack on SPARC Solaris 10
In-Reply-To: <5685E4FBA752A441B1975A77A77CD648252B6B1573@DCPWVMBXC1VS2.mdanderson.edu>
References: <5685E4FBA752A441B1975A77A77CD648252B6B1573@DCPWVMBXC1VS2.mdanderson.edu>
Message-ID: <alpine.LFD.2.02.1102100705010.3094@gannet.stats.ox.ac.uk>

There are lots of problems with MCMCpack's C++: the only way (short of 
a major rewrite) that you will get it to compile on Solaris is to use 
g++ (and even that needs corrections).

The maintainers seem deaf to reports of the issues.

And please note what the posting guide says about where to send 
questions about non-R programming issues.

On Wed, 9 Feb 2011, Zhang,Jun wrote:

> Hi list,
>    I tried to install MCMCpack to R-2.12.0, got the following error,
> R CMD INSTALL MCMCpack_1.0-9.tar.gz
> ..........
> CC -m64 -library=stlport4 -I/apps/sparcv9/R-2.12.0/lib/R/include -DSCYTHE_COMPILE_DIRECT -DSCYTHE_DEBUG=0 -DHAVE_TRUNC -DHAVE_IEEEFP_H   -I/opt/csw/include    -KPIC  -g -c MCMCSVDreg.cc<http://MCMCSVDreg.cc> -o MCMCSVDreg.o
> "error.h", line 598: Error: The function "abort" must have a prototype.
> "distributions.h", line 550: Error: The function "trunc" must have a prototype.
> "distributions.h", line 550: Error: log1p is not a member of file level.
> "distributions.h", line 566: Error: The function "trunc" must have a prototype.
> "distributions.h", line 566: Error: log1p is not a member of file level.
> "distributions.h", line 2177: Error: sqrt is not a member of file level.
> 6 Error(s) detected.
> make: *** [MCMCSVDreg.o] Error 2
> ERROR: compilation failed for package 'MCMCpack'
> * removing '/apps/sparcv9/R-2.12.0/lib/R/library/MCMCpack'
>
> root at dqssun4 local# which cc
> /opt/solstudio12.2/bin/cc
> root at dqssun4 local# which R
> /apps/sparcv9/R-2.12.0/bin/R
>
> The configure script for the successful R installation is the following,
> CC="cc -xc99 -m64 -xarch=sparcvis2"
> CPPFLAGS="-I/opt/csw/include"
> CFLAGS="-xcode=abs64 -xlibmieee -xtarget=ultra3 -xarch=sparcvis2"
> F77=f95
> CXX="CC -m64 -library=stlport4"
> FC=$F77
> FFLAGS="-m64 -xarch=sparcvis2"
> FCFLAGS=$FFLAGS
> LDFLAGS="-L/opt/csw/lib/sparcv9 -L/opt/solstudio12.2/prod/lib/v9"
> export CC CPPFLAGS CFLAGS F77 FFLAGS CXX CXXFLAGS FC FCFLAGS LDFLAGS
> ./configure --prefix=/apps/sparcv9/R-2.12.0 --with-tcl-config=/opt/csw/lib/tclCo
> nfig.sh<http://nfig.sh> --with-tk-config=/opt/csw/lib/tkConfig.sh --disable-nls
>
> Jun Zhang
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Thu Feb 10 11:01:55 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 10 Feb 2011 10:01:55 +0000 (GMT)
Subject: [Rd] Problem installing MCMCpack on SPARC Solaris 10
In-Reply-To: <alpine.LFD.2.02.1102100705010.3094@gannet.stats.ox.ac.uk>
References: <5685E4FBA752A441B1975A77A77CD648252B6B1573@DCPWVMBXC1VS2.mdanderson.edu>
	<alpine.LFD.2.02.1102100705010.3094@gannet.stats.ox.ac.uk>
Message-ID: <alpine.LFD.2.02.1102101000110.23914@gannet.stats.ox.ac.uk>

On Thu, 10 Feb 2011, Prof Brian Ripley wrote:

> There are lots of problems with MCMCpack's C++: the only way (short of a 
> major rewrite) that you will get it to compile on Solaris is to use g++ (and 
> even that needs corrections).
>
> The maintainers seem deaf to reports of the issues.
>
> And please note what the posting guide says about where to send questions 
> about non-R programming issues.

Sorry, I omitted 'in contributed packages'.  And PLEASE don't post 
twice.

The patch I needed on x86 Solaris was

diff -ru tests32/MCMCpack/src/algorithm.h MCMCpack/src/algorithm.h
--- tests32/MCMCpack/src/algorithm.h    Mon Jan 31 17:28:11 2011
+++ MCMCpack/src/algorithm.h    Sun May 16 19:15:39 2010
@@ -45,6 +45,11 @@
  #include "scythestat/matrix_random_access_iterator.h"
  #endif

+#undef DO
+#undef DS
+#undef SO
+#undef SS
+


>
> On Wed, 9 Feb 2011, Zhang,Jun wrote:
>
>> Hi list,
>>    I tried to install MCMCpack to R-2.12.0, got the following error,
>> R CMD INSTALL MCMCpack_1.0-9.tar.gz
>> ..........
>> CC -m64 -library=stlport4 -I/apps/sparcv9/R-2.12.0/lib/R/include 
>> -DSCYTHE_COMPILE_DIRECT -DSCYTHE_DEBUG=0 -DHAVE_TRUNC -DHAVE_IEEEFP_H 
>> -I/opt/csw/include    -KPIC  -g -c MCMCSVDreg.cc<http://MCMCSVDreg.cc> -o 
>> MCMCSVDreg.o
>> "error.h", line 598: Error: The function "abort" must have a prototype.
>> "distributions.h", line 550: Error: The function "trunc" must have a 
>> prototype.
>> "distributions.h", line 550: Error: log1p is not a member of file level.
>> "distributions.h", line 566: Error: The function "trunc" must have a 
>> prototype.
>> "distributions.h", line 566: Error: log1p is not a member of file level.
>> "distributions.h", line 2177: Error: sqrt is not a member of file level.
>> 6 Error(s) detected.
>> make: *** [MCMCSVDreg.o] Error 2
>> ERROR: compilation failed for package 'MCMCpack'
>> * removing '/apps/sparcv9/R-2.12.0/lib/R/library/MCMCpack'
>> 
>> root at dqssun4 local# which cc
>> /opt/solstudio12.2/bin/cc
>> root at dqssun4 local# which R
>> /apps/sparcv9/R-2.12.0/bin/R
>> 
>> The configure script for the successful R installation is the following,
>> CC="cc -xc99 -m64 -xarch=sparcvis2"
>> CPPFLAGS="-I/opt/csw/include"
>> CFLAGS="-xcode=abs64 -xlibmieee -xtarget=ultra3 -xarch=sparcvis2"
>> F77=f95
>> CXX="CC -m64 -library=stlport4"
>> FC=$F77
>> FFLAGS="-m64 -xarch=sparcvis2"
>> FCFLAGS=$FFLAGS
>> LDFLAGS="-L/opt/csw/lib/sparcv9 -L/opt/solstudio12.2/prod/lib/v9"
>> export CC CPPFLAGS CFLAGS F77 FFLAGS CXX CXXFLAGS FC FCFLAGS LDFLAGS
>> ./configure --prefix=/apps/sparcv9/R-2.12.0 
>> --with-tcl-config=/opt/csw/lib/tclCo
>> nfig.sh<http://nfig.sh> --with-tk-config=/opt/csw/lib/tkConfig.sh 
>> --disable-nls
>> 
>> Jun Zhang
>>
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> 
>
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From possokhoff at gmail.com  Thu Feb 10 11:42:00 2011
From: possokhoff at gmail.com (=?KOI8-R?B?4NLJyiDwz9PPyM/X?=)
Date: Thu, 10 Feb 2011 15:42:00 +0500
Subject: [Rd] BLAS optimization by CUBLAS
Message-ID: <AANLkTikjEh-EPAfaQ=BYgq3N+R6a16Nn0am1an8tt_+=@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110210/882c9ce3/attachment.pl>

From Graham.Williams at anu.edu.au  Thu Feb 10 12:37:09 2011
From: Graham.Williams at anu.edu.au (Graham Williams)
Date: Thu, 10 Feb 2011 22:37:09 +1100
Subject: [Rd] R 2.12.1 Windows 32bit and 64bit - are numerical differences
	expected?
Message-ID: <AANLkTinnBKjuw3KCQ_oT1n8YcGRFCNw3k1EuRPkL2HWD@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110210/5d969ce3/attachment.pl>

From murdoch.duncan at gmail.com  Thu Feb 10 13:39:30 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 10 Feb 2011 07:39:30 -0500
Subject: [Rd] R 2.12.1 Windows 32bit and 64bit - are numerical
 differences expected?
In-Reply-To: <AANLkTinnBKjuw3KCQ_oT1n8YcGRFCNw3k1EuRPkL2HWD@mail.gmail.com>
References: <AANLkTinnBKjuw3KCQ_oT1n8YcGRFCNw3k1EuRPkL2HWD@mail.gmail.com>
Message-ID: <4D53DC82.6080108@gmail.com>

On 11-02-10 6:37 AM, Graham Williams wrote:
> Should one expect minor numerical differences between 64bit and 32bit R on
> Windows? Hunting around the lists I've not been able to find a definitive
> answer yet. Seems plausible using different precision arithmetic, but waned
> to confirm from those who might know for sure.

I think our goal is that those results should be as close as possible. 
R uses the same precision in both 32 bit and 64 bit; the differences are 
all in pointers, not floating point values.

However, the two versions use different run-time libraries, and it is 
possible that there are precision differences coming from there.  I 
think we'd be interested in knowing what they are even if they are 
beyond our control, so I would appreciate it if you could track down 
where the difference arises.

Duncan Murdoch

>
> BACKGROUND
>
> A colleague was trying to replicate some modelling results (from a soon to
> be published book) using rpart, ada, and randomForest, for example. My 64bit
> Linux and 64bit Windows 7 always agree (so far), but not their 32bit
> Windows. I've distilled it to a few simple lines of code to replicate the
> differences (but had to stay with the weather dataset from rattle since
> could not replicate on standard datasets yet).
>
> library(rpart)
> library(rattle)
> set.seed(41)
> model<- rpart(RainTomorrow ~ ., data=weather[-c(1, 2,
> 23)], control=rpart.control(minbucket=0))
> print(model$cptable)
>
> Final row on 32bit: 9 0.01000000     23 0.1515152 1.1060606 0.1158273
> Final row on 64bit: 9 0.01000000     23 0.1515152 1.0909091 0.1152273
>
> Pretty minor, but different. I've not found any seed other than 41 (only
> tried a few) that results in a difference.
>
> library(ada) # using rpart underneath
> set.seed(41)
> model<- ada(RainTomorrow ~ ., data=weather[-c(1, 2, 23)])
> print(model)
>
> On 32bit: Train Error: 0.057
> On 64bit: Train Error: 0.055
>
> Changing the seed to 42, for example, brings them into sync.
>
> library(randomForest)
> set.seed(41)
> model<- randomForest(RainTomorrow ~ ., data=weather[-c(1, 2, 23)],
>                        importance=TRUE, na.action=na.roughfix)
> print(model)
>
> On 32bit:  OOB estimate of  error rate: 12.84%
> On 64bit:  OOB estimate of  error rate: 11.75%
>
>
>> sessionInfo()
> R version 2.12.1 (2010-12-16)
> Platform: i386-pc-mingw32/i386 (32-bit)
>
> locale:
> [1] LC_COLLATE=English_Australia.1252  LC_CTYPE=English_Australia.1252
> [3] LC_MONETARY=English_Australia.1252 LC_NUMERIC=C
> [5] LC_TIME=English_Australia.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] randomForest_4.5-36 pmml_1.2.27         XML_3.2-0.2
> [4] colorspace_1.0-1    RGtk2_2.20.3        ada_2.0-2
> [7] rattle_2.6.2        rpart_3.1-47
>
> loaded via a namespace (and not attached):
> [1] tools_2.12.1
>
>> sessionInfo()
> R version 2.12.1 (2010-12-16)
> Platform: x86_64-pc-mingw32/x64 (64-bit)
> ...
>
>
> Thanks,
> Graham
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From savicky at cs.cas.cz  Thu Feb 10 14:33:40 2011
From: savicky at cs.cas.cz (Petr Savicky)
Date: Thu, 10 Feb 2011 14:33:40 +0100
Subject: [Rd] R 2.12.1 Windows 32bit and 64bit - are numerical
	differences expected?
In-Reply-To: <AANLkTinnBKjuw3KCQ_oT1n8YcGRFCNw3k1EuRPkL2HWD@mail.gmail.com>
References: <AANLkTinnBKjuw3KCQ_oT1n8YcGRFCNw3k1EuRPkL2HWD@mail.gmail.com>
Message-ID: <20110210133340.GA27904@cs.cas.cz>

On Thu, Feb 10, 2011 at 10:37:09PM +1100, Graham Williams wrote:
> Should one expect minor numerical differences between 64bit and 32bit R on
> Windows? Hunting around the lists I've not been able to find a definitive
> answer yet. Seems plausible using different precision arithmetic, but waned
> to confirm from those who might know for sure.

One of the sources for the difference between platforms are different
settings of the compiler. On Intel processors, the options may influence,
whether the registers use 80 bit or 64 bit representation of floating
point numbers. In memory, it is always 64 bit. Testing, whether there is
a difference between registers and memory may be done for example using
the code

  #include <stdio.h>
  #define n 3
  int main(int agc, char *argv[])
  {
      double x[n];
      int i;
      for (i=0; i<n; i++) {
          x[i] = 1.0/(i + 5);
      }
      for (i=0; i<n; i++) {
          if (x[i] != 1.0/(i + 5)) {
              printf("difference for %d\n", i);
          }
      }
      return 0;
  }

If the compiler uses SSE arithmetic (-mfpmath=sse), then the output is empty.
If Intel's extended arithmetic is used, then we get

  difference for 0
  difference for 1
  difference for 2

On 32 bit Linuxes, the default was Intel's extended arithmetic, while on
64 bit Linuxes, the default is sometimes SSE. I do not know the situation
on Windows.

Another source of difference is different optimization of expressions.

It is sometimes possible to obtain identical results on different platforms,
however, it cannot be generally guaranteed. For tree construction, even
minor differences in rounding may influence comparisons and this may
result in a different form of the tree.

Petr Savicky.


From ripley at stats.ox.ac.uk  Thu Feb 10 15:44:35 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 10 Feb 2011 14:44:35 +0000 (GMT)
Subject: [Rd] BLAS optimization by CUBLAS
In-Reply-To: <AANLkTikjEh-EPAfaQ=BYgq3N+R6a16Nn0am1an8tt_+=@mail.gmail.com>
References: <AANLkTikjEh-EPAfaQ=BYgq3N+R6a16Nn0am1an8tt_+=@mail.gmail.com>
Message-ID: <alpine.LFD.2.02.1102101442220.21762@toucan.stats.ox.ac.uk>

On Thu, 10 Feb 2011, ???? ??????? wrote:

> Dear colleagues!
>
> In early 2009 there was a discussion about fast BLAS library initiated by
> Sachin. He reported a faster BLAS library made by Nvidia CUBLAS library. Uwe
> Ligges showed an interest for placing the optimized rblas.dll into
> windows/contrib section managed by him. Unfortunately there is no any CUBLAS
> version of rblas.dll in this section at present. So, is anybody interested
> in CUBLAS optimization of rblas now?

We are, but we are primarily interested in maintainable Open Source 
solutions.  No one made available such a version of Rblas.dll (sic).

>  In my opinion current directions (packages) of high-performance and
> parallel computing with R suffer from grave shortcomings: all GPU
> optimization is made by introducing more and more optimized functions
> coexisting with original ones. This hard way has been chosen for Matlab too.
> It complicates R as a language. So, the idea of optimizing BLAS (especially
> by CUBLAS) seems to overcome the mentioned shortcomings. It might be
> remarkable to make some efforts to this way of high-performance computing.
>
> Yuri Possokhov
>
> 	[[alternative HTML version deleted]]

Please do follow the posting guide and not send HTML.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From ripley at stats.ox.ac.uk  Thu Feb 10 16:12:40 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 10 Feb 2011 15:12:40 +0000 (GMT)
Subject: [Rd] R 2.12.1 Windows 32bit and 64bit - are numerical
 differences expected?
In-Reply-To: <20110210133340.GA27904@cs.cas.cz>
References: <AANLkTinnBKjuw3KCQ_oT1n8YcGRFCNw3k1EuRPkL2HWD@mail.gmail.com>
	<20110210133340.GA27904@cs.cas.cz>
Message-ID: <alpine.LFD.2.02.1102101445160.21762@toucan.stats.ox.ac.uk>

A more important difference is the number of registers available on 
the CPU, which differs between i386 and x86_64.  Hence computations 
get done in different orders by optimizing compilers.

And yes, all x86_64 CPUs have SSE, so the optimizer uses them at the 
compiler settings we use.

As Duncan mentioned, the runtime (libc/m, on Windows mainly 
MSVCRT.dll) differs between OSes.

We know rather a lot about differences between platforms, as recent 
versions of R contain reference results for almost all the examples, 
and we from time to time compare output from CRAN check runs across 
platforms (this was part of the test suite run before releasing the 
64-bit Windows port).

Almost all the 64-bit platforms are very close (and agree exactly on 
the R examples), and 32-bit Solaris and Mac OS X are pretty close, 
32-bit Linux has quite a lot of differences, and 32-bit Windows 
somewhat more.

On Thu, 10 Feb 2011, Petr Savicky wrote:

> On Thu, Feb 10, 2011 at 10:37:09PM +1100, Graham Williams wrote:
>> Should one expect minor numerical differences between 64bit and 32bit R on
>> Windows? Hunting around the lists I've not been able to find a definitive
>> answer yet. Seems plausible using different precision arithmetic, but waned
>> to confirm from those who might know for sure.
>
> One of the sources for the difference between platforms are different
> settings of the compiler. On Intel processors, the options may influence,
> whether the registers use 80 bit or 64 bit representation of floating
> point numbers. In memory, it is always 64 bit. Testing, whether there is
> a difference between registers and memory may be done for example using
> the code
>
>  #include <stdio.h>
>  #define n 3
>  int main(int agc, char *argv[])
>  {
>      double x[n];
>      int i;
>      for (i=0; i<n; i++) {
>          x[i] = 1.0/(i + 5);
>      }
>      for (i=0; i<n; i++) {
>          if (x[i] != 1.0/(i + 5)) {
>              printf("difference for %d\n", i);
>          }
>      }
>      return 0;
>  }
>
> If the compiler uses SSE arithmetic (-mfpmath=sse), then the output is empty.
> If Intel's extended arithmetic is used, then we get
>
>  difference for 0
>  difference for 1
>  difference for 2
>
> On 32 bit Linuxes, the default was Intel's extended arithmetic, while on
> 64 bit Linuxes, the default is sometimes SSE. I do not know the situation
> on Windows.
>
> Another source of difference is different optimization of expressions.
>
> It is sometimes possible to obtain identical results on different platforms,
> however, it cannot be generally guaranteed. For tree construction, even
> minor differences in rounding may influence comparisons and this may
> result in a different form of the tree.
>
> Petr Savicky.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From chuck at sharpsteen.net  Thu Feb 10 22:39:51 2011
From: chuck at sharpsteen.net (Sharpie)
Date: Thu, 10 Feb 2011 13:39:51 -0800 (PST)
Subject: [Rd] embed Sweave driver in .Rnw file
In-Reply-To: <19719.24931.968293.80971@angua.stat.uni-muenchen.de>
References: <4D075794.3010201@r-enthusiasts.com>
	<19719.24931.968293.80971@angua.stat.uni-muenchen.de>
Message-ID: <1297373991040-3300339.post@n4.nabble.com>



Friedrich Leisch wrote:
> 
>>>>>> On Tue, 14 Dec 2010 12:40:04 +0100,
>>>>>> Romain Francois (RF) wrote:
> 
>   > Hello,
>   > Sweave lets you use alternative drivers through the driver argument,
> and 
>   > several packages take advantage of that and define custom Sweave
> driver 
>   > for various purposes. Most of them are listed on the Reproducible 
>   > Research CTV: 
>   > (http://cran.r-project.org/web/views/ReproducibleResearch.html)
> 
>   > The next natural step is for package developpers to take advantage of 
>   > this in their vignettes. In Rcpp we work around the way package
> building 
>   > works and we do:
>   > - let R build a dummy vignette
>   > - then use the inst/doc/Makefile to replace it with a vignette that is 
>   > processed by the driver from the highlight package (giving syntax 
>   > highlighting).
> 
>   > I played with Sweave so that it would be able to create the driver
> from 
>   > some text included in the text of the .Rnw file:
> 
>   > $ svn diff
>   > Index: src/library/utils/R/Sweave.R
>   > ===================================================================
>   > --- src/library/utils/R/Sweave.R	(revision 53846)
>   > +++ src/library/utils/R/Sweave.R	(working copy)
>   > @@ -20,6 +20,16 @@
>   >   # We don't need srclines for code, but we do need it for text, and 
>   > it's easiest
>   >   # to just keep it for everything.
> 
>   > +SweaveGetDriver <- function(file){
>   > +    txt <- readLines(file)
>   > +    line <- grep( "\\SweaveDriver", txt, value = TRUE )
>   > +    if( length(line) ){
>   > +        txt <- sub( "^.*\\SweaveDriver[{](.*)[}]", "\\1", line[1L] )
>   > +        driver <- try( eval( parse( text = txt ) ), silent = TRUE )
>   > +        if( !inherits( driver, "try-error") ) driver
>   > +    }
>   > +}
>   > +
>   >   Sweave <- function(file, driver=RweaveLatex(),
>   >                      syntax=getOption("SweaveSyntax"), ...)
>   >   {
>   > @@ -28,7 +38,9 @@
>   >       else if(is.function(driver))
>   >           driver <- driver()
> 
>   > -
>   > +    drv <- SweaveGetDriver(file)
>   > +    if( !is.null(drv) ) driver <- drv
>   > +
>   >       if(is.null(syntax))
>   >           syntax <- SweaveGetSyntax(file)
>   >       if(is.character(syntax))
> 
> 
> 
>   > This allows one to write something like this in their file:
> 
>   > %\SweaveDriver{ { require(highlight); HighlightWeaveLatex() } }
> 
>   > So that when calling :
> 
>   >> Sweave( "somefile.Rnw" )
> 
>   > the highlight driver is used instead of the default driver.
> 
>   > Could something like that be added to Sweave ?
> 
> Yes, sure!
> 
> Will have a look at the patch later this week and apply it if it
> passes the tests. The patch is against a current r-devel?
> 
> Best,
> Fritz
> 


Is there an update on the status of this patch?  I use a particularly ugly
hack to splice a custom driver into one of my package Vignettes and it would
be great to retire it in favor of an officially supported method.

-Charlie  

-----
Charlie Sharpsteen
Undergraduate-- Environmental Resources Engineering
Humboldt State University
-- 
View this message in context: http://r.789695.n4.nabble.com/embed-Sweave-driver-in-Rnw-file-tp3086897p3300339.html
Sent from the R devel mailing list archive at Nabble.com.


From p.murrell at auckland.ac.nz  Fri Feb 11 00:01:43 2011
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Fri, 11 Feb 2011 12:01:43 +1300
Subject: [Rd] using rasterImage within image
In-Reply-To: <AANLkTimHAmzq4CEJF-auHRSA8745x2yb8r_GK9+vTrKJ@mail.gmail.com>
References: <4D51F2A7.8010505@mcmaster.ca>	<D8F5413E-025A-4511-BCE1-7ED06CBE99A0@r-project.org>	<4D52AD7B.6070402@gmail.com>	<E86B0A90-F63F-4537-A7FB-1AA84D685154@r-project.org>	<AANLkTi=yRP56wACtOs+Ouc70EV57rw9RKYmfLAh2hQ8a@mail.gmail.com>	<825F0B1E-EF80-48F5-AFF1-5832092450AB@r-project.org>	<AANLkTi=0K6hCP0tptSf6h4S6au+-SmahDm983zRdZEgb@mail.gmail.com>	<4D531558.7010709@gmail.com>	<AANLkTi=nwF-3UjtoFAaLdTwphmezvuk57HaaJd57=am2@mail.gmail.com>
	<AANLkTimHAmzq4CEJF-auHRSA8745x2yb8r_GK9+vTrKJ@mail.gmail.com>
Message-ID: <4D546E57.7020304@auckland.ac.nz>

Hi

On 10/02/2011 7:54 p.m., Michael Sumner wrote:
> Hello, I'm afraid the SDI graphics issue is still a problem in 2.13.0
> 2011-02-09 r54308.

Bother.  Thanks very much for testing.  I'll keep looking.

Paul

> To reproduce, in a fresh R session (Windows in SDI mode):
>
> ## create a dummy dataset
> m<- matrix(c(0.2, 0.4, 0.6, 0.8), 2, 2)
>
> ## simple helper function to open the windows() device and plot the matrix
> draw.f<- function(x) {
>     plot(0, xlim = c(0, 1), ylim = c(0, 1))
>     rasterImage(x, 0, 0, 1, 1, interpolate = FALSE)
> }
>
> draw.f(m)
>
> ## repeat the following 2 lines five times:
>
> dev.off()
> draw.f(m)
>
> On the fifth attempt, only the background plot appears - but the
> raster is visible on resize of the windows() device.
>
> Cheers, Mike.
>
> sessionInfo()
> R version 2.13.0 Under development (unstable) (2011-02-09 r54308)
> Platform: x86_64-pc-mingw32/x64 (64-bit)
>
> locale:
> [1] LC_COLLATE=English_Australia.1252  LC_CTYPE=English_Australia.1252
> [3] LC_MONETARY=English_Australia.1252 LC_NUMERIC=C
> [5] LC_TIME=English_Australia.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
>
>
> On Thu, Feb 10, 2011 at 5:31 PM, baptiste auguie
> <baptiste.auguie at googlemail.com>  wrote:
>> Dear all,
>>
>> Back when grid.raster() was introduced, it was suggested that perhaps
>> grid.rect() could use grid.raster() in case of even spacing. The
>> response at the time was that it would be best to keep the two
>> functions separate at a lower level, that is grid.rect() and
>> grid.raster(), but perhaps a new function grid.image() could be
>> proposed at a higher level with the two possible backends. If this is
>> done in grid graphics, perhaps the same convention could be used for
>> base graphics: image() would be high level with the backend option,
>> and a new function ("tiles()", perhaps?) would implement the current
>> behavior of image().
>>
>> In any case, it would be nice to have a unified scheme to switch
>> between "tiles" and raster; currently lattice (panl.levelplot.raster)
>> and a few other packages all do it separately.
>>
>> Best wishes,
>>
>> baptiste
>>
>>
>>
>> On 9 February 2011 23:29, Ben Bolker<bbolker at gmail.com>  wrote:
>>> -----BEGIN PGP SIGNED MESSAGE-----
>>> Hash: SHA1
>>>
>>> On 11-02-09 03:09 PM, Henrik Bengtsson wrote:
>>>> On Wed, Feb 9, 2011 at 11:53 AM, Simon Urbanek
>>>> <simon.urbanek at r-project.org>  wrote:
>>>>>
>>>>> On Feb 9, 2011, at 2:36 PM, Henrik Bengtsson wrote:
>>>>>
>>>>>> On Wed, Feb 9, 2011 at 11:25 AM, Simon Urbanek
>>>>>> <simon.urbanek at r-project.org>  wrote:
>>>>>>> Ben,
>>>>>>>
>>>>>>> I have committed something analogous to R-devel (your rotation
>>>>>>> code was not unlike mine, I replicated the color handling from
>>>>>>> R internals to be consistent, I fixed the drawing limits and
>>>>>>> added a check for x/y conformance). Note that useRaster can
>>>>>>> only be used when x, y form a regular grid. Although I tried a
>>>>>>> lot of corner cases (requiring quite a few fixes), I'm sure I
>>>>>>> did not test all of them, so volunteers please give it a go and
>>>>>>> compare it with non-raster output.
>>>>>>>
>>>>>>> The only thing I'm not quite happy about is the argument name:
>>>>>>> useRaster. Personally, I hate camel case in R (it has crept in
>>>>>>> more recently making it horribly inconsistent) so please feel
>>>>>>> free to suggest a better name ;).
>>>>>>
>>>>>> It.is.spelled.camelCase.
>>>>>>
>>>>>
>>>>> Fortunately not in English ;)
>>>>>
>>>>>
>>>>>> What about style=c("image", "raster")?  This allows for future
>>>>>> extensions too.
>>>>>>
>>>>>
>>>>> Hmm.. it's not really a "style" - the output doesn't change
>>>>> (ideally) - it's more of a back-end specification .. also we
>>>>> already have oldstyle argument in image() adding to the confusion
>>>>> ...
>>>>
>>>> flavor=c("image", "raster") renderer=c("image", "raster")
>>>> backend=c("image", "raster") ...
>>>
>>>   Thanks Simon! (Any reports on the SDI Windows raster rendering issue,
>>> or do we need a warning/workaround there?)
>>>
>>>   I like "backend", or possibly "method"
>>>
>>>   One minor consideration: if "raster" eventually becomes the default
>>> (as I hope it will), there would need to be some internal logic that
>>> drops back to "image" if the user specifies uneven spacing and doesn't
>>> explicitly specify the 'backend/method' parameter ...
>>> -----BEGIN PGP SIGNATURE-----
>>> Version: GnuPG v1.4.10 (GNU/Linux)
>>> Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org/
>>>
>>> iEYEARECAAYFAk1TFVcACgkQc5UpGjwzenOa6ACfVnJq67cG0czATeyti7AxgUbw
>>> ZWwAniA7JuYCv4clq8e6jwWQuMvw/r+m
>>> =/da6
>>> -----END PGP SIGNATURE-----
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
>
>

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/


From p.murrell at auckland.ac.nz  Fri Feb 11 02:41:17 2011
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Fri, 11 Feb 2011 14:41:17 +1300
Subject: [Rd] using rasterImage within image
In-Reply-To: <AANLkTimHAmzq4CEJF-auHRSA8745x2yb8r_GK9+vTrKJ@mail.gmail.com>
References: <4D51F2A7.8010505@mcmaster.ca>	<D8F5413E-025A-4511-BCE1-7ED06CBE99A0@r-project.org>	<4D52AD7B.6070402@gmail.com>	<E86B0A90-F63F-4537-A7FB-1AA84D685154@r-project.org>	<AANLkTi=yRP56wACtOs+Ouc70EV57rw9RKYmfLAh2hQ8a@mail.gmail.com>	<825F0B1E-EF80-48F5-AFF1-5832092450AB@r-project.org>	<AANLkTi=0K6hCP0tptSf6h4S6au+-SmahDm983zRdZEgb@mail.gmail.com>	<4D531558.7010709@gmail.com>	<AANLkTi=nwF-3UjtoFAaLdTwphmezvuk57HaaJd57=am2@mail.gmail.com>
	<AANLkTimHAmzq4CEJF-auHRSA8745x2yb8r_GK9+vTrKJ@mail.gmail.com>
Message-ID: <4D5493BD.4050801@auckland.ac.nz>

Hi

Just committed another fix that solves this problem for me at least.  If 
you want to test for yourself, the magic revision number that you are 
looking for is r54330.

Thanks again for your help.

Paul

On 10/02/2011 7:54 p.m., Michael Sumner wrote:
> Hello, I'm afraid the SDI graphics issue is still a problem in 2.13.0
> 2011-02-09 r54308.
>
> To reproduce, in a fresh R session (Windows in SDI mode):
>
> ## create a dummy dataset
> m<- matrix(c(0.2, 0.4, 0.6, 0.8), 2, 2)
>
> ## simple helper function to open the windows() device and plot the matrix
> draw.f<- function(x) {
>     plot(0, xlim = c(0, 1), ylim = c(0, 1))
>     rasterImage(x, 0, 0, 1, 1, interpolate = FALSE)
> }
>
> draw.f(m)
>
> ## repeat the following 2 lines five times:
>
> dev.off()
> draw.f(m)
>
> On the fifth attempt, only the background plot appears - but the
> raster is visible on resize of the windows() device.
>
> Cheers, Mike.
>
> sessionInfo()
> R version 2.13.0 Under development (unstable) (2011-02-09 r54308)
> Platform: x86_64-pc-mingw32/x64 (64-bit)
>
> locale:
> [1] LC_COLLATE=English_Australia.1252  LC_CTYPE=English_Australia.1252
> [3] LC_MONETARY=English_Australia.1252 LC_NUMERIC=C
> [5] LC_TIME=English_Australia.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
>
>
> On Thu, Feb 10, 2011 at 5:31 PM, baptiste auguie
> <baptiste.auguie at googlemail.com>  wrote:
>> Dear all,
>>
>> Back when grid.raster() was introduced, it was suggested that perhaps
>> grid.rect() could use grid.raster() in case of even spacing. The
>> response at the time was that it would be best to keep the two
>> functions separate at a lower level, that is grid.rect() and
>> grid.raster(), but perhaps a new function grid.image() could be
>> proposed at a higher level with the two possible backends. If this is
>> done in grid graphics, perhaps the same convention could be used for
>> base graphics: image() would be high level with the backend option,
>> and a new function ("tiles()", perhaps?) would implement the current
>> behavior of image().
>>
>> In any case, it would be nice to have a unified scheme to switch
>> between "tiles" and raster; currently lattice (panl.levelplot.raster)
>> and a few other packages all do it separately.
>>
>> Best wishes,
>>
>> baptiste
>>
>>
>>
>> On 9 February 2011 23:29, Ben Bolker<bbolker at gmail.com>  wrote:
>>> -----BEGIN PGP SIGNED MESSAGE-----
>>> Hash: SHA1
>>>
>>> On 11-02-09 03:09 PM, Henrik Bengtsson wrote:
>>>> On Wed, Feb 9, 2011 at 11:53 AM, Simon Urbanek
>>>> <simon.urbanek at r-project.org>  wrote:
>>>>>
>>>>> On Feb 9, 2011, at 2:36 PM, Henrik Bengtsson wrote:
>>>>>
>>>>>> On Wed, Feb 9, 2011 at 11:25 AM, Simon Urbanek
>>>>>> <simon.urbanek at r-project.org>  wrote:
>>>>>>> Ben,
>>>>>>>
>>>>>>> I have committed something analogous to R-devel (your rotation
>>>>>>> code was not unlike mine, I replicated the color handling from
>>>>>>> R internals to be consistent, I fixed the drawing limits and
>>>>>>> added a check for x/y conformance). Note that useRaster can
>>>>>>> only be used when x, y form a regular grid. Although I tried a
>>>>>>> lot of corner cases (requiring quite a few fixes), I'm sure I
>>>>>>> did not test all of them, so volunteers please give it a go and
>>>>>>> compare it with non-raster output.
>>>>>>>
>>>>>>> The only thing I'm not quite happy about is the argument name:
>>>>>>> useRaster. Personally, I hate camel case in R (it has crept in
>>>>>>> more recently making it horribly inconsistent) so please feel
>>>>>>> free to suggest a better name ;).
>>>>>>
>>>>>> It.is.spelled.camelCase.
>>>>>>
>>>>>
>>>>> Fortunately not in English ;)
>>>>>
>>>>>
>>>>>> What about style=c("image", "raster")?  This allows for future
>>>>>> extensions too.
>>>>>>
>>>>>
>>>>> Hmm.. it's not really a "style" - the output doesn't change
>>>>> (ideally) - it's more of a back-end specification .. also we
>>>>> already have oldstyle argument in image() adding to the confusion
>>>>> ...
>>>>
>>>> flavor=c("image", "raster") renderer=c("image", "raster")
>>>> backend=c("image", "raster") ...
>>>
>>>   Thanks Simon! (Any reports on the SDI Windows raster rendering issue,
>>> or do we need a warning/workaround there?)
>>>
>>>   I like "backend", or possibly "method"
>>>
>>>   One minor consideration: if "raster" eventually becomes the default
>>> (as I hope it will), there would need to be some internal logic that
>>> drops back to "image" if the user specifies uneven spacing and doesn't
>>> explicitly specify the 'backend/method' parameter ...
>>> -----BEGIN PGP SIGNATURE-----
>>> Version: GnuPG v1.4.10 (GNU/Linux)
>>> Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org/
>>>
>>> iEYEARECAAYFAk1TFVcACgkQc5UpGjwzenOa6ACfVnJq67cG0czATeyti7AxgUbw
>>> ZWwAniA7JuYCv4clq8e6jwWQuMvw/r+m
>>> =/da6
>>> -----END PGP SIGNATURE-----
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
>
>

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/


From jjgoss at sbcglobal.net  Fri Feb 11 01:32:10 2011
From: jjgoss at sbcglobal.net (James Goss)
Date: Thu, 10 Feb 2011 16:32:10 -0800
Subject: [Rd] R project testers - how to help out
Message-ID: <5ABB1665-1934-41E5-993A-1D3557EF14A5@sbcglobal.net>


I just want to find out how I could help out with testing on the R  
project.  I have
many years of software development as well as QA and test of  
everything from
chips to supercomputers and really enjoy testing.  Increasingly, I am  
working in
data mining and large-scale statistical kinds of things and "R" is my  
tool of choice.

Any help is much appreciated.

James Goss
Los Angeles, CA


From ripley at stats.ox.ac.uk  Fri Feb 11 09:52:51 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 11 Feb 2011 08:52:51 +0000 (GMT)
Subject: [Rd] R project testers - how to help out
In-Reply-To: <5ABB1665-1934-41E5-993A-1D3557EF14A5@sbcglobal.net>
References: <5ABB1665-1934-41E5-993A-1D3557EF14A5@sbcglobal.net>
Message-ID: <alpine.LFD.2.02.1102110839060.21679@gannet.stats.ox.ac.uk>

We have a 4-week alpha/beta/RC period every 6 months for testing 
before a 2.x.0 release.  This is announced here, and we get very 
little response.  I expect the testing window for R 2.13.0 to be 
Mar-Apr.

That said, we do quite extensive testing on the main platforms (ix86 
and x86_64 Linux, i386 and x64 Windows) and slightly less on ix86 Mac 
OS X, x86 Solaris and Sparc Solaris.  This includes very frequent 
automated runs over all available R packages.  And we do also make 
daily snapshots available for testing.

R itself comes with a quite extensive test suite, and tools for 
testing packages.  Some people have chosen to use particular 
unit-testing frameworks (such as package RUnits), but these are 
notorious for obfuscating problems to the extent that the public 
output from the check farms contains almost no clue as to the specific 
test failure.

I hope that is enough background for you to explore the status quo and 
come with specific proposals.  Thank you for your offer of help.

On Thu, 10 Feb 2011, James Goss wrote:

>
> I just want to find out how I could help out with testing on the R 
> project. I have many years of software development as well as QA and 
> test of everything from chips to supercomputers and really enjoy 
> testing.  Increasingly, I am working in data mining and large-scale 
> statistical kinds of things and "R" is my tool of choice.
>
> Any help is much appreciated.
>
> James Goss
> Los Angeles, CA
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From kino at northwestern.edu  Fri Feb 11 19:25:52 2011
From: kino at northwestern.edu (Kino Aguilar)
Date: Fri, 11 Feb 2011 12:25:52 -0600
Subject: [Rd] Problem with confint function
Message-ID: <AANLkTinUeFk0Mr+Vd0bCMD0NB35pc_ryiGJF-Aa=CCzo@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110211/7b64d22c/attachment.pl>

From jfox at mcmaster.ca  Fri Feb 11 19:53:32 2011
From: jfox at mcmaster.ca (John Fox)
Date: Fri, 11 Feb 2011 13:53:32 -0500
Subject: [Rd] Problem with confint function
In-Reply-To: <AANLkTinUeFk0Mr+Vd0bCMD0NB35pc_ryiGJF-Aa=CCzo@mail.gmail.com>
References: <AANLkTinUeFk0Mr+Vd0bCMD0NB35pc_ryiGJF-Aa=CCzo@mail.gmail.com>
Message-ID: <006401cbca1c$fbcaad50$f36007f0$@mcmaster.ca>

Dear Kino,

The confidence intervals that you've computed yourself are based on the Wald
statistic, while confint() computes confidence intervals based on the
likelihood-ratio statistic, by profiling the likelihood (see ?confint and
click on the link for confint.glm). Basing confidence intervals on the
likelihood is more computationally intensive but should be more accurate.

I hope this helps,
 John

--------------------------------
John Fox
Senator William McMaster
  Professor of Social Statistics
Department of Sociology
McMaster University
Hamilton, Ontario, Canada
http://socserv.mcmaster.ca/jfox




> -----Original Message-----
> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-
> project.org] On Behalf Of Kino Aguilar
> Sent: February-11-11 1:26 PM
> To: R-devel at r-project.org
> Subject: [Rd] Problem with confint function
> 
> Hi,
> 
> I am currently doing logistic regression analyses and I am trying to get
> confidence intervals for my partial logistic regression coefficients.
> Supposing I am right in assuming that the formula to estimate a 95% CI
> for a log odds coefficient is the following:
> 
> log odds - 1.96*SE to log odds + 1.96*SE
> 
> then I am not getting the right CI.
> 
> For instance, this is a summary of my model:
>             Estimate Std. Error z value Pr(>|z|)
> (Intercept) -0.06106    0.29808  -0.205   0.8377
> pSusSD       0.21184    0.36886   0.574   0.5658
> pBenSD       1.20255    0.52271   2.301   0.0214 *
> pBarSD      -0.08654    0.48749  -0.178   0.8591
> pSevSD       0.99759    0.44795   2.227   0.0259 *
> 
> And this is are the corresponding CI when I call the confint function:
>                  2.5 %    97.5 %
> (Intercept) -0.6548023 0.5264357
> pSusSD      -0.4980888 0.9733975
> pBenSD       0.2665235 2.3495259
> pBarSD      -1.0695945 0.8740359
> pSevSD       0.1877044 1.9747499
> 
> Utilizing the formula I mentioned above, the correct CI for pSusSD would
> actually be:
> > .21184-1.96*.36886
> [1] -0.5111256
> > .21184+1.96*.36886
> [1] 0.9348056
> 
> That is:
>                  2.5 %    97.5 %
> pSusSD      -0.5111256 0.9348056
> 
> I am wondering if there is a bug in the code or if there is another way
> to calculate a 95% CI for a logistic regression coefficient that I am
> not aware of?
> 
> Thanks!
> 
> --
> All the best!,
> ~Joaquin A. Aguilar A. - aka Kino
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From pdalgd at gmail.com  Fri Feb 11 20:04:08 2011
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 11 Feb 2011 20:04:08 +0100
Subject: [Rd] Problem with confint function
In-Reply-To: <AANLkTinUeFk0Mr+Vd0bCMD0NB35pc_ryiGJF-Aa=CCzo@mail.gmail.com>
References: <AANLkTinUeFk0Mr+Vd0bCMD0NB35pc_ryiGJF-Aa=CCzo@mail.gmail.com>
Message-ID: <63E2D44F-9CE9-468C-B6F9-D63369263202@gmail.com>


On Feb 11, 2011, at 19:25 , Kino Aguilar wrote:

> Hi,
> 
> I am currently doing logistic regression analyses and I am trying to get
> confidence intervals for my partial logistic regression coefficients.
> Supposing I am right in assuming that the formula to estimate a 95% CI for a
> log odds coefficient is the following:
> 
> log odds - 1.96*SE to log odds + 1.96*SE
> 
> then I am not getting the right CI.
> 
> For instance, this is a summary of my model:
>            Estimate Std. Error z value Pr(>|z|)
> (Intercept) -0.06106    0.29808  -0.205   0.8377
> pSusSD       0.21184    0.36886   0.574   0.5658
> pBenSD       1.20255    0.52271   2.301   0.0214 *
> pBarSD      -0.08654    0.48749  -0.178   0.8591
> pSevSD       0.99759    0.44795   2.227   0.0259 *
> 
> And this is are the corresponding CI when I call the confint function:
>                 2.5 %    97.5 %
> (Intercept) -0.6548023 0.5264357
> pSusSD      -0.4980888 0.9733975
> pBenSD       0.2665235 2.3495259
> pBarSD      -1.0695945 0.8740359
> pSevSD       0.1877044 1.9747499
> 
> Utilizing the formula I mentioned above, the correct CI for pSusSD would
> actually be:
>> .21184-1.96*.36886
> [1] -0.5111256
>> .21184+1.96*.36886
> [1] 0.9348056
> 
> That is:
>                 2.5 %    97.5 %
> pSusSD      -0.5111256 0.9348056
> 
> I am wondering if there is a bug in the code or if there is another way to
> calculate a 95% CI for a logistic regression coefficient that I am not aware
> of?
> 

confint.glm computes using likelihood profiling (i.e., it inverts the likelihood ratio test criterion for a parameter). This is considered somewhat more accurate than the Wald approximation implied by +/- 1.96*SE. If you insist on the latter, try confint.default. (This *is* all on the help page for confint()!). 

> Thanks!
> 
> -- 
> All the best!,
> ~Joaquin A. Aguilar A. - aka Kino
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Peter Dalgaard
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From bbolker at gmail.com  Fri Feb 11 20:39:12 2011
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 11 Feb 2011 14:39:12 -0500
Subject: [Rd] read.csv trap
Message-ID: <4D559060.7050502@gmail.com>


  Bump.

  It's been a week since I posted this to r-devel.  Any
thoughts/discussion?  Would R-core be irritated if I submitted a bug report?

  cheers
    Ben


-------- Original Message --------
Subject: read.csv trap
Date: Fri, 04 Feb 2011 11:16:36 -0500
From: Ben Bolker <bbolker at gmail.com>
To: r-devel at stat.math.ethz.ch <r-devel at stat.math.ethz.ch>,  David Earn
<earn at math.mcmaster.ca>

  This is not specifically a bug, but an (implicitly/obscurely)
documented behavior of read.csv (or read.table with fill=TRUE) that can
be quite dangerous/confusing for users.  I would love to hear some
discussion from other users and/or R-core about this ...  As always, I
apologize if I have missed some obvious workaround or reason that this
is actually the desired behavior ...

  In a nutshell, when fill=TRUE R guesses the number of columns from the
first 5 rows of the data set.  That's fine, and ?read.table documents this:

   The number of data columns is determined by looking at the first
     five lines of input (or the whole file if it has less than five
     lines), or from the length of ?col.names? if it is specified and
     is longer.  This could conceivably be wrong if ?fill? or
     ?blank.lines.skip? are true, so specify ?col.names? if necessary.

What is dangerous/confusing is that R silently **wraps** longer lines if
fill=TRUE (which is the default for read.csv).  I encountered this when
working with a colleague on a long, messy CSV file that had some phantom
extra fields in some rows, which then turned into empty lines in the
data frame.

  Here is an example and a workaround that runs count.fields on the
whole file to find the maximum column length and set col.names
accordingly.  (It assumes you don't already have a file named "test.csv"
in your working directory ...)

  I haven't dug in to try to write a patch for this -- I wanted to test
the waters and see what people thought first, and I realize that
read.table() is a very complicated piece of code that embodies a lot of
tradeoffs, so there could be lots of different approaches to trying to
mitigate this problem. I appreciate very much how hard it is to write a
robust and general function to read data files, but I also think it's
really important to minimize the number of traps in read.table(), which
will often be the first part of R that new users encounter ...

  A quick fix for this might be to allow the number of lines analyzed
for length to be settable by the user, or to allow a settable 'maxcols'
parameter, although those would only help in the case where the user
already knows there is a problem.

  cheers
    Ben Bolker

===============
writeLines(c("A,B,C,D",
             "1,a,b,c",
             "2,f,g,c",
             "3,a,i,j",
             "4,a,b,c",
             "5,d,e,f",
             "6,g,h,i,j,k,l,m,n"),
           con=file("test.csv"))


read.csv("test.csv")
try(read.csv("test.csv",fill=FALSE))

## assumes header=TRUE, fill=TRUE; should be a little more careful
##  with comment, quote arguments (possibly explicit)
## ... contains information about quote, comment.char, sep
Read.csv <- function(fn,sep=",",...) {
  colnames <- scan(fn,nlines=1,what="character",sep=sep,...)
  ncolnames <- length(colnames)
  maxcols <- max(count.fields(fn,sep=sep,...))
  if (maxcols>ncolnames) {
    colnames <- c(colnames,paste("V",(ncolnames+1):maxcols,sep=""))
  }
  ## assumes you don't have any other columns labeled "V[large number]"
  read.csv(fn,...,col.names=colnames)
}

Read.csv("test.csv")


From Ken.Williams at thomsonreuters.com  Fri Feb 11 20:56:52 2011
From: Ken.Williams at thomsonreuters.com (Ken.Williams at thomsonreuters.com)
Date: Fri, 11 Feb 2011 13:56:52 -0600
Subject: [Rd] read.csv trap
In-Reply-To: <4D559060.7050502@gmail.com>
Message-ID: <C97AF018.238D8%ken.williams@thomsonreuters.com>



On 2/11/11 1:39 PM, "Ben Bolker" <bbolker at gmail.com> wrote:

>[snip]
>-------- Original Message --------
>Subject: read.csv trap
>Date: Fri, 04 Feb 2011 11:16:36 -0500
>From: Ben Bolker <bbolker at gmail.com>
>To: r-devel at stat.math.ethz.ch <r-devel at stat.math.ethz.ch>,  David Earn
><earn at math.mcmaster.ca>
>
>[snip]
>What is dangerous/confusing is that R silently **wraps** longer lines if
>fill=TRUE (which is the default for read.csv).
>[snip]


Based on your description, I would be very irritated if I encountered the
behavior you describe.  I would consider it a bug, though my opinion
doesn't necessarily count for much.

--
Ken Williams
Senior Research Scientist
Thomson Reuters
Phone: 651-848-7712
ken.williams at thomsonreuters.com
http://labs.thomsonreuters.com


From laurent.gatto at gmail.com  Fri Feb 11 21:37:46 2011
From: laurent.gatto at gmail.com (Laurent Gatto)
Date: Fri, 11 Feb 2011 20:37:46 +0000
Subject: [Rd] read.csv trap
In-Reply-To: <4D559060.7050502@gmail.com>
References: <4D559060.7050502@gmail.com>
Message-ID: <AANLkTi=hT7h7yQyL-xuNZE4a9YtQeH99d=nuJ2MvzZf0@mail.gmail.com>

On 11 February 2011 19:39, Ben Bolker <bbolker at gmail.com> wrote:
>
[snip]
>
> What is dangerous/confusing is that R silently **wraps** longer lines if
> fill=TRUE (which is the default for read.csv). ?I encountered this when
> working with a colleague on a long, messy CSV file that had some phantom
> extra fields in some rows, which then turned into empty lines in the
> data frame.
>

As a matter of fact, this is exactly what happened to a colleague of
mine yesterday and caused her quite a bit of trouble. On the other
hand, it could also be considered as a 'bug' in the csv file. Although
no formal specification exist for the csv format, RFC 4180 [1]
indicates that 'each line should contain the same number of fields
throughout the file'.

[1] http://tools.ietf.org/html/rfc4180

Best wishes,

Laurent

> ?Here is an example and a workaround that runs count.fields on the
> whole file to find the maximum column length and set col.names
> accordingly. ?(It assumes you don't already have a file named "test.csv"
> in your working directory ...)
>
> ?I haven't dug in to try to write a patch for this -- I wanted to test
> the waters and see what people thought first, and I realize that
> read.table() is a very complicated piece of code that embodies a lot of
> tradeoffs, so there could be lots of different approaches to trying to
> mitigate this problem. I appreciate very much how hard it is to write a
> robust and general function to read data files, but I also think it's
> really important to minimize the number of traps in read.table(), which
> will often be the first part of R that new users encounter ...
>
> ?A quick fix for this might be to allow the number of lines analyzed
> for length to be settable by the user, or to allow a settable 'maxcols'
> parameter, although those would only help in the case where the user
> already knows there is a problem.
>
> ?cheers
> ? ?Ben Bolker
>
> ===============
> writeLines(c("A,B,C,D",
> ? ? ? ? ? ? "1,a,b,c",
> ? ? ? ? ? ? "2,f,g,c",
> ? ? ? ? ? ? "3,a,i,j",
> ? ? ? ? ? ? "4,a,b,c",
> ? ? ? ? ? ? "5,d,e,f",
> ? ? ? ? ? ? "6,g,h,i,j,k,l,m,n"),
> ? ? ? ? ? con=file("test.csv"))
>
>
> read.csv("test.csv")
> try(read.csv("test.csv",fill=FALSE))
>
> ## assumes header=TRUE, fill=TRUE; should be a little more careful
> ## ?with comment, quote arguments (possibly explicit)
> ## ... contains information about quote, comment.char, sep
> Read.csv <- function(fn,sep=",",...) {
> ?colnames <- scan(fn,nlines=1,what="character",sep=sep,...)
> ?ncolnames <- length(colnames)
> ?maxcols <- max(count.fields(fn,sep=sep,...))
> ?if (maxcols>ncolnames) {
> ? ?colnames <- c(colnames,paste("V",(ncolnames+1):maxcols,sep=""))
> ?}
> ?## assumes you don't have any other columns labeled "V[large number]"
> ?read.csv(fn,...,col.names=colnames)
> }
>
> Read.csv("test.csv")
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>



-- 
[ Laurent Gatto | slashhome.be ]


From c.ryan.king at gmail.com  Fri Feb 11 22:29:24 2011
From: c.ryan.king at gmail.com (Ryan King)
Date: Fri, 11 Feb 2011 15:29:24 -0600
Subject: [Rd] Writting my own package - 64 bit problem with R_GetCCallable
Message-ID: <AANLkTi=h3G=orR7oQRkRw7RxJSGafPnKg+BD0nZ0qM6i@mail.gmail.com>

Hello list,
I've been working on a package of my own.  It works fine on the 32bit
linux machines that I've tested it on.  Someone using 64bit ubuntu
wanted to try it, and surprising segfaults happened.  My test code
results in no segfault, errors, or leaks from my calls when run under
valgrind (I recompiled R with the level 2 valgrind instruments).  R
and packages are compiled from source, so this is hopefully not a
debian/ubuntu issue.  I'm totally stumped and hoping that this is a
silly / common 32 to 64 bit transition issue.

The problem seems to come when I attempt to access a function
registered by the Matrix package.  During compilation (on 64 bit only)
I get the ominous:

--------------
slim_stolen_from_matrix.c: In function ?R_as_cholmod_sparse?:
slim_stolen_from_matrix.c:36: warning: implicit declaration of
function ?R_GetCCallable?
slim_stolen_from_matrix.c:36: warning: cast to pointer from integer of
different size
--------------

The function in question is an identical copy of Matrix's
M_as_cholmod_sparse, reproduced below

--------------
CHM_SP
R_as_cholmod_sparse(CHM_SP ans, SEXP x, Rboolean check_Udiag, Rboolean
sort_in_place)
{
    static CHM_SP(*fun)(CHM_SP,SEXP,Rboolean,Rboolean)= NULL;
    if(fun == NULL)
	fun = (CHM_SP(*)(CHM_SP,SEXP,Rboolean,Rboolean))
	    R_GetCCallable("Matrix", "as_cholmod_sparse");
    return fun(ans, x, check_Udiag, sort_in_place);
}
--------------

I made this duplicate function since using Matrix's #include stubs
conflicts with my copy of the CHOLMOD library (I need some functions
Matrix doesn't make public).

When run, the code gives the following segfault when it reaches te
first call to that function:

--------------
Program received signal SIGSEGV, Segmentation fault.
0xfffffffff54314e2 in ?? ()
 *** caught segfault ***
address 0xfffffffff54314e2, cause 'memory not mapped'
--------------

As mentioned above, under valgrind the segault doesn't happen, but in
GDB, the function pointer can be seen to have some problem.  In 64 bit
--------------
35              fun = (CHM_SP(*)(CHM_SP,SEXP,Rboolean,Rboolean))
(gdb) p fun
$1 = (CHM_SP (*)(CHM_SP, SEXP, Rboolean, Rboolean)) 0
(gdb) n
37          return fun(ans, x, check_Udiag, sort_in_place);
(gdb) p fun
$2 = (CHM_SP (*)(CHM_SP, SEXP, Rboolean, Rboolean)) 0xfffffffff54314e2
--------------

vs 32bit
--------------
(gdb) p fun
$1 = (CHM_SP (*)(CHM_SP, SEXP, Rboolean, Rboolean)) 0xb72a3ec0
<as_cholmod_sparse>
--------------

I've never done 64 bit development, so I don't know what I've probably
done wrong.  I don't see an intermediate cast to an int to mess it up.
 Checking the pointer sizeof's seems like R_GetCCallable's return
should be the same size as the function pointer.

--------------
(gdb) p sizeof(void*)
$5 = 8
(gdb) p sizeof(CHM_SP*)
$6 = 8
(gdb) p sizeof(CHM_SP)
$7 = 8
(gdb) p sizeof(SEXP)
$8 = 8
(gdb) p sizeof(CHM_SP(*))
$9 = 8
(gdb) p sizeof(DL_FUNC)
$10 = 8
(gdb) p sizeof(DL_FUNC*)
$11 = 8
--------------

The function is invoked by
----------
fitholder->Zt = R_as_cholmod_sparse
((CHM_SP)malloc(sizeof(cholmod_sparse)), Zt, TRUE, FALSE);
-----------

where Zt is a SEXP pointing to a Matrix-class sparse matrix passed by
.Call from R.  CHM_SP is a typedef'd pointer to a cholmod_sparse



> sessionInfo()
R version 2.12.1 (2010-12-16)
Platform: x86_64-unknown-linux-gnu (64-bit)

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
 [5] LC_MONETARY=C              LC_MESSAGES=en_US.UTF-8
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
 [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] emmpat_0.001       Matrix_0.999375-46 lattice_0.19-13

loaded via a namespace (and not attached):
[1] grid_2.12.1


Ryan King
University of Chicago
Dept. Health Studies


From simon.urbanek at r-project.org  Fri Feb 11 22:53:26 2011
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Fri, 11 Feb 2011 16:53:26 -0500
Subject: [Rd] Writting my own package - 64 bit problem with
	R_GetCCallable
In-Reply-To: <AANLkTi=h3G=orR7oQRkRw7RxJSGafPnKg+BD0nZ0qM6i@mail.gmail.com>
References: <AANLkTi=h3G=orR7oQRkRw7RxJSGafPnKg+BD0nZ0qM6i@mail.gmail.com>
Message-ID: <8BEAD894-6D29-436B-A48D-3670F8D17E73@r-project.org>

Ryan,

On Feb 11, 2011, at 4:29 PM, Ryan King wrote:

> Hello list,
> I've been working on a package of my own.  It works fine on the 32bit
> linux machines that I've tested it on.  Someone using 64bit ubuntu
> wanted to try it, and surprising segfaults happened.  My test code
> results in no segfault, errors, or leaks from my calls when run under
> valgrind (I recompiled R with the level 2 valgrind instruments).  R
> and packages are compiled from source, so this is hopefully not a
> debian/ubuntu issue.  I'm totally stumped and hoping that this is a
> silly / common 32 to 64 bit transition issue.
> 
> The problem seems to come when I attempt to access a function
> registered by the Matrix package.  During compilation (on 64 bit only)
> I get the ominous:
> 
> --------------
> slim_stolen_from_matrix.c: In function ?R_as_cholmod_sparse?:
> slim_stolen_from_matrix.c:36: warning: implicit declaration of
> function ?R_GetCCallable?
> slim_stolen_from_matrix.c:36: warning: cast to pointer from integer of
> different size


This is the key issue - you're missing the declaration of R_GetCCallable() as the compiler tells you, so the compiler assumes "int" as the return value. However, int is only 32-bit so it won't hold a 64-bit pointer and hence you're in trouble.

All you really need is

#include <R_ext/Rdynload.h>

before you use R_GetCCallable and hopefully your issues should go away.

Note that your bug is there even in 32-bit -- you will see " implicit declaration of function" in any case -- it just is not fatal, incidentally. It is a good idea to listen to the compiler ... ;).

Cheers,
Simon


> --------------
> 
> The function in question is an identical copy of Matrix's
> M_as_cholmod_sparse, reproduced below
> 
> --------------
> CHM_SP
> R_as_cholmod_sparse(CHM_SP ans, SEXP x, Rboolean check_Udiag, Rboolean
> sort_in_place)
> {
>    static CHM_SP(*fun)(CHM_SP,SEXP,Rboolean,Rboolean)= NULL;
>    if(fun == NULL)
> 	fun = (CHM_SP(*)(CHM_SP,SEXP,Rboolean,Rboolean))
> 	    R_GetCCallable("Matrix", "as_cholmod_sparse");
>    return fun(ans, x, check_Udiag, sort_in_place);
> }
> --------------
> 
> I made this duplicate function since using Matrix's #include stubs
> conflicts with my copy of the CHOLMOD library (I need some functions
> Matrix doesn't make public).
> 
> When run, the code gives the following segfault when it reaches te
> first call to that function:
> 
> --------------
> Program received signal SIGSEGV, Segmentation fault.
> 0xfffffffff54314e2 in ?? ()
> *** caught segfault ***
> address 0xfffffffff54314e2, cause 'memory not mapped'
> --------------
> 
> As mentioned above, under valgrind the segault doesn't happen, but in
> GDB, the function pointer can be seen to have some problem.  In 64 bit
> --------------
> 35              fun = (CHM_SP(*)(CHM_SP,SEXP,Rboolean,Rboolean))
> (gdb) p fun
> $1 = (CHM_SP (*)(CHM_SP, SEXP, Rboolean, Rboolean)) 0
> (gdb) n
> 37          return fun(ans, x, check_Udiag, sort_in_place);
> (gdb) p fun
> $2 = (CHM_SP (*)(CHM_SP, SEXP, Rboolean, Rboolean)) 0xfffffffff54314e2
> --------------
> 
> vs 32bit
> --------------
> (gdb) p fun
> $1 = (CHM_SP (*)(CHM_SP, SEXP, Rboolean, Rboolean)) 0xb72a3ec0
> <as_cholmod_sparse>
> --------------
> 
> I've never done 64 bit development, so I don't know what I've probably
> done wrong.  I don't see an intermediate cast to an int to mess it up.
> Checking the pointer sizeof's seems like R_GetCCallable's return
> should be the same size as the function pointer.
> 
> --------------
> (gdb) p sizeof(void*)
> $5 = 8
> (gdb) p sizeof(CHM_SP*)
> $6 = 8
> (gdb) p sizeof(CHM_SP)
> $7 = 8
> (gdb) p sizeof(SEXP)
> $8 = 8
> (gdb) p sizeof(CHM_SP(*))
> $9 = 8
> (gdb) p sizeof(DL_FUNC)
> $10 = 8
> (gdb) p sizeof(DL_FUNC*)
> $11 = 8
> --------------
> 
> The function is invoked by
> ----------
> fitholder->Zt = R_as_cholmod_sparse
> ((CHM_SP)malloc(sizeof(cholmod_sparse)), Zt, TRUE, FALSE);
> -----------
> 
> where Zt is a SEXP pointing to a Matrix-class sparse matrix passed by
> .Call from R.  CHM_SP is a typedef'd pointer to a cholmod_sparse
> 
> 
> 
>> sessionInfo()
> R version 2.12.1 (2010-12-16)
> Platform: x86_64-unknown-linux-gnu (64-bit)
> 
> locale:
> [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
> [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
> [5] LC_MONETARY=C              LC_MESSAGES=en_US.UTF-8
> [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
> [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> other attached packages:
> [1] emmpat_0.001       Matrix_0.999375-46 lattice_0.19-13
> 
> loaded via a namespace (and not attached):
> [1] grid_2.12.1
> 
> 
> Ryan King
> University of Chicago
> Dept. Health Studies
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From bbolker at gmail.com  Fri Feb 11 23:00:30 2011
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 11 Feb 2011 17:00:30 -0500
Subject: [Rd] read.csv trap
In-Reply-To: <AANLkTi=hT7h7yQyL-xuNZE4a9YtQeH99d=nuJ2MvzZf0@mail.gmail.com>
References: <4D559060.7050502@gmail.com>
	<AANLkTi=hT7h7yQyL-xuNZE4a9YtQeH99d=nuJ2MvzZf0@mail.gmail.com>
Message-ID: <4D55B17E.4040509@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 02/11/2011 03:37 PM, Laurent Gatto wrote:
> On 11 February 2011 19:39, Ben Bolker <bbolker at gmail.com> wrote:
>>
> [snip]
>>
>> What is dangerous/confusing is that R silently **wraps** longer lines if
>> fill=TRUE (which is the default for read.csv).  I encountered this when
>> working with a colleague on a long, messy CSV file that had some phantom
>> extra fields in some rows, which then turned into empty lines in the
>> data frame.
>>
> 
> As a matter of fact, this is exactly what happened to a colleague of
> mine yesterday and caused her quite a bit of trouble. On the other
> hand, it could also be considered as a 'bug' in the csv file. Although
> no formal specification exist for the csv format, RFC 4180 [1]
> indicates that 'each line should contain the same number of fields
> throughout the file'.
> 
> [1] http://tools.ietf.org/html/rfc4180
> 
> Best wishes,
> 
> Laurent

  Asserting that the bug is in the CSV file is logically consistent, but
if this is true then the "fill=TRUE" argument (which is only needed when
the lines contain different numbers of fields) should not be allowed.

 I had never seen RFC4180 before -- interesting!  I note especially
points 5-7 which define the handling of double quotation marks (but says
nothing about single quotes or using backslashes as escape characters).

  Dealing with read.[table|csv] seems a bit of an Augean task
<http://en.wikipedia.org/wiki/Augeas> (hmmm, maybe I should write a
parallel document to Burns's _Inferno_ ...)

  cheers
    Ben

> 
>>  Here is an example and a workaround that runs count.fields on the
>> whole file to find the maximum column length and set col.names
>> accordingly.  (It assumes you don't already have a file named "test.csv"
>> in your working directory ...)
>>
>>  I haven't dug in to try to write a patch for this -- I wanted to test
>> the waters and see what people thought first, and I realize that
>> read.table() is a very complicated piece of code that embodies a lot of
>> tradeoffs, so there could be lots of different approaches to trying to
>> mitigate this problem. I appreciate very much how hard it is to write a
>> robust and general function to read data files, but I also think it's
>> really important to minimize the number of traps in read.table(), which
>> will often be the first part of R that new users encounter ...
>>
>>  A quick fix for this might be to allow the number of lines analyzed
>> for length to be settable by the user, or to allow a settable 'maxcols'
>> parameter, although those would only help in the case where the user
>> already knows there is a problem.
>>
>>  cheers
>>    Ben Bolker
>>
>> ===============
>> writeLines(c("A,B,C,D",
>>             "1,a,b,c",
>>             "2,f,g,c",
>>             "3,a,i,j",
>>             "4,a,b,c",
>>             "5,d,e,f",
>>             "6,g,h,i,j,k,l,m,n"),
>>           con=file("test.csv"))
>>
>>
>> read.csv("test.csv")
>> try(read.csv("test.csv",fill=FALSE))
>>
>> ## assumes header=TRUE, fill=TRUE; should be a little more careful
>> ##  with comment, quote arguments (possibly explicit)
>> ## ... contains information about quote, comment.char, sep
>> Read.csv <- function(fn,sep=",",...) {
>>  colnames <- scan(fn,nlines=1,what="character",sep=sep,...)
>>  ncolnames <- length(colnames)
>>  maxcols <- max(count.fields(fn,sep=sep,...))
>>  if (maxcols>ncolnames) {
>>    colnames <- c(colnames,paste("V",(ncolnames+1):maxcols,sep=""))
>>  }
>>  ## assumes you don't have any other columns labeled "V[large number]"
>>  read.csv(fn,...,col.names=colnames)
>> }
>>
>> Read.csv("test.csv")
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
> 
> 
> 

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.10 (GNU/Linux)
Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org/

iEYEARECAAYFAk1VsX4ACgkQc5UpGjwzenPwsgCfTtGo0kJSXhUTPcY+p7cgaiuq
zHAAnikRORUhqLP9O+6M5SwyZcFEW9uT
=Rb2R
-----END PGP SIGNATURE-----


From c.ryan.king at gmail.com  Fri Feb 11 23:03:17 2011
From: c.ryan.king at gmail.com (Ryan King)
Date: Fri, 11 Feb 2011 16:03:17 -0600
Subject: [Rd] Writting my own package - 64 bit problem with
	R_GetCCallable
In-Reply-To: <8BEAD894-6D29-436B-A48D-3670F8D17E73@r-project.org>
References: <AANLkTi=h3G=orR7oQRkRw7RxJSGafPnKg+BD0nZ0qM6i@mail.gmail.com>
	<8BEAD894-6D29-436B-A48D-3670F8D17E73@r-project.org>
Message-ID: <AANLkTinySy20gZnEwTN4_1ffpe0dUK+CBT55cYHc8XNE@mail.gmail.com>

Ah thanks, that did fix it.

Ryan King

On Fri, Feb 11, 2011 at 3:53 PM, Simon Urbanek
<simon.urbanek at r-project.org> wrote:
> Ryan,
>
> On Feb 11, 2011, at 4:29 PM, Ryan King wrote:
>
>> Hello list,
>> I've been working on a package of my own. ?It works fine on the 32bit
>> linux machines that I've tested it on. ?Someone using 64bit ubuntu
>> wanted to try it, and surprising segfaults happened. ?My test code
>> results in no segfault, errors, or leaks from my calls when run under
>> valgrind (I recompiled R with the level 2 valgrind instruments). ?R
>> and packages are compiled from source, so this is hopefully not a
>> debian/ubuntu issue. ?I'm totally stumped and hoping that this is a
>> silly / common 32 to 64 bit transition issue.
>>
>> The problem seems to come when I attempt to access a function
>> registered by the Matrix package. ?During compilation (on 64 bit only)
>> I get the ominous:
>>
>> --------------
>> slim_stolen_from_matrix.c: In function ?R_as_cholmod_sparse?:
>> slim_stolen_from_matrix.c:36: warning: implicit declaration of
>> function ?R_GetCCallable?
>> slim_stolen_from_matrix.c:36: warning: cast to pointer from integer of
>> different size
>
>
> This is the key issue - you're missing the declaration of R_GetCCallable() as the compiler tells you, so the compiler assumes "int" as the return value. However, int is only 32-bit so it won't hold a 64-bit pointer and hence you're in trouble.
>
> All you really need is
>
> #include <R_ext/Rdynload.h>
>
> before you use R_GetCCallable and hopefully your issues should go away.
>
> Note that your bug is there even in 32-bit -- you will see " implicit declaration of function" in any case -- it just is not fatal, incidentally. It is a good idea to listen to the compiler ... ;).
>
> Cheers,
> Simon
>
>
>> --------------
>>
>> The function in question is an identical copy of Matrix's
>> M_as_cholmod_sparse, reproduced below
>>
>> --------------
>> CHM_SP
>> R_as_cholmod_sparse(CHM_SP ans, SEXP x, Rboolean check_Udiag, Rboolean
>> sort_in_place)
>> {
>> ? ?static CHM_SP(*fun)(CHM_SP,SEXP,Rboolean,Rboolean)= NULL;
>> ? ?if(fun == NULL)
>> ? ? ? fun = (CHM_SP(*)(CHM_SP,SEXP,Rboolean,Rboolean))
>> ? ? ? ? ? R_GetCCallable("Matrix", "as_cholmod_sparse");
>> ? ?return fun(ans, x, check_Udiag, sort_in_place);
>> }
>> --------------
>>
>> I made this duplicate function since using Matrix's #include stubs
>> conflicts with my copy of the CHOLMOD library (I need some functions
>> Matrix doesn't make public).
>>
>> When run, the code gives the following segfault when it reaches te
>> first call to that function:
>>
>> --------------
>> Program received signal SIGSEGV, Segmentation fault.
>> 0xfffffffff54314e2 in ?? ()
>> *** caught segfault ***
>> address 0xfffffffff54314e2, cause 'memory not mapped'
>> --------------
>>
>> As mentioned above, under valgrind the segault doesn't happen, but in
>> GDB, the function pointer can be seen to have some problem. ?In 64 bit
>> --------------
>> 35 ? ? ? ? ? ? ?fun = (CHM_SP(*)(CHM_SP,SEXP,Rboolean,Rboolean))
>> (gdb) p fun
>> $1 = (CHM_SP (*)(CHM_SP, SEXP, Rboolean, Rboolean)) 0
>> (gdb) n
>> 37 ? ? ? ? ?return fun(ans, x, check_Udiag, sort_in_place);
>> (gdb) p fun
>> $2 = (CHM_SP (*)(CHM_SP, SEXP, Rboolean, Rboolean)) 0xfffffffff54314e2
>> --------------
>>
>> vs 32bit
>> --------------
>> (gdb) p fun
>> $1 = (CHM_SP (*)(CHM_SP, SEXP, Rboolean, Rboolean)) 0xb72a3ec0
>> <as_cholmod_sparse>
>> --------------
>>
>> I've never done 64 bit development, so I don't know what I've probably
>> done wrong. ?I don't see an intermediate cast to an int to mess it up.
>> Checking the pointer sizeof's seems like R_GetCCallable's return
>> should be the same size as the function pointer.
>>
>> --------------
>> (gdb) p sizeof(void*)
>> $5 = 8
>> (gdb) p sizeof(CHM_SP*)
>> $6 = 8
>> (gdb) p sizeof(CHM_SP)
>> $7 = 8
>> (gdb) p sizeof(SEXP)
>> $8 = 8
>> (gdb) p sizeof(CHM_SP(*))
>> $9 = 8
>> (gdb) p sizeof(DL_FUNC)
>> $10 = 8
>> (gdb) p sizeof(DL_FUNC*)
>> $11 = 8
>> --------------
>>
>> The function is invoked by
>> ----------
>> fitholder->Zt = R_as_cholmod_sparse
>> ((CHM_SP)malloc(sizeof(cholmod_sparse)), Zt, TRUE, FALSE);
>> -----------
>>
>> where Zt is a SEXP pointing to a Matrix-class sparse matrix passed by
>> .Call from R. ?CHM_SP is a typedef'd pointer to a cholmod_sparse
>>
>>
>>
>>> sessionInfo()
>> R version 2.12.1 (2010-12-16)
>> Platform: x86_64-unknown-linux-gnu (64-bit)
>>
>> locale:
>> [1] LC_CTYPE=en_US.UTF-8 ? ? ? LC_NUMERIC=C
>> [3] LC_TIME=en_US.UTF-8 ? ? ? ?LC_COLLATE=en_US.UTF-8
>> [5] LC_MONETARY=C ? ? ? ? ? ? ?LC_MESSAGES=en_US.UTF-8
>> [7] LC_PAPER=en_US.UTF-8 ? ? ? LC_NAME=C
>> [9] LC_ADDRESS=C ? ? ? ? ? ? ? LC_TELEPHONE=C
>> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>>
>> attached base packages:
>> [1] stats ? ? graphics ?grDevices utils ? ? datasets ?methods ? base
>>
>> other attached packages:
>> [1] emmpat_0.001 ? ? ? Matrix_0.999375-46 lattice_0.19-13
>>
>> loaded via a namespace (and not attached):
>> [1] grid_2.12.1
>>
>>
>> Ryan King
>> University of Chicago
>> Dept. Health Studies
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>
>


From djsamperi at gmail.com  Sat Feb 12 01:09:15 2011
From: djsamperi at gmail.com (Dominick Samperi)
Date: Fri, 11 Feb 2011 19:09:15 -0500
Subject: [Rd] R limits documented?
Message-ID: <AANLkTinoie27eMBdq7=QBBcrhBLorhFoiBX6sW+6vBzm@mail.gmail.com>

Is there documentation on R limits?
That is, max matrix size, etc.?

Diagnostics when limits are exceeded are not always
meaningful. For example:
> x <- rep(0,50000*50000)
Error in rep(0, 50000 * 50000) : invalid 'times' argument
In addition: Warning message:
In as.vector(data) : NAs introduced by coercion

Here's another example:
> library(orthopolynom)
> hermite <- hermite.h.polynomials(1001)
> hermite[[1001]] # should display 1000-th degree polynomial
Error in if (signs[1] == "- ") "-" else "" :
  missing value where TRUE/FALSE needed

Thanks,
Dominick


From dwinsemius at comcast.net  Sat Feb 12 01:55:17 2011
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 11 Feb 2011 19:55:17 -0500
Subject: [Rd] R limits documented?
In-Reply-To: <AANLkTinoie27eMBdq7=QBBcrhBLorhFoiBX6sW+6vBzm@mail.gmail.com>
References: <AANLkTinoie27eMBdq7=QBBcrhBLorhFoiBX6sW+6vBzm@mail.gmail.com>
Message-ID: <7C9BDD66-4BF5-4A49-A3E1-B96274457DA4@comcast.net>


On Feb 11, 2011, at 7:09 PM, Dominick Samperi wrote:

> Is there documentation on R limits?
> That is, max matrix size, etc.?
>
> Diagnostics when limits are exceeded are not always
> meaningful. For example:
>> x <- rep(0,50000*50000)
> Error in rep(0, 50000 * 50000) : invalid 'times' argument
> In addition: Warning message:
> In as.vector(data) : NAs introduced by coercion

 > x <- rep(0,40000*50000)
 > gc()
              used    (Mb) gc trigger    (Mb)   max used    (Mb)
Ncells    4673306   249.6    6945861   371.0    5315868   283.9
Vcells 2165579376 16522.1 4374103452 33371.8 4165580443 31780.9
 > object.size(x)
16000000040 bytes

So that is about 2/3 of my installed memory. This seems to be a  
limitation due to the maximum positive integer being ~ 2*10^9
 > 2*10^9 < 50000*50000
[1] TRUE
 > 2*10^9 < 40000*50000
[1] FALSE

>
> Here's another example:
>> library(orthopolynom)
>> hermite <- hermite.h.polynomials(1001)
>> hermite[[1001]] # should display 1000-th degree polynomial
> Error in if (signs[1] == "- ") "-" else "" :
>  missing value where TRUE/FALSE needed

Sounds as though the maximum length of an element of type character  
has been exceeded.
>
> Thanks,
> Dominick
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

David Winsemius, MD
West Hartford, CT


From simon.urbanek at r-project.org  Sat Feb 12 02:45:06 2011
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Fri, 11 Feb 2011 20:45:06 -0500
Subject: [Rd] R limits documented?
In-Reply-To: <7C9BDD66-4BF5-4A49-A3E1-B96274457DA4@comcast.net>
References: <AANLkTinoie27eMBdq7=QBBcrhBLorhFoiBX6sW+6vBzm@mail.gmail.com>
	<7C9BDD66-4BF5-4A49-A3E1-B96274457DA4@comcast.net>
Message-ID: <433F8810-FE8D-4AD0-A012-45C056A505FA@r-project.org>


On Feb 11, 2011, at 7:55 PM, David Winsemius wrote:

> 
> On Feb 11, 2011, at 7:09 PM, Dominick Samperi wrote:
> 
>> Is there documentation on R limits?
>> That is, max matrix size, etc.?
>> 
>> Diagnostics when limits are exceeded are not always
>> meaningful. For example:
>>> x <- rep(0,50000*50000)
>> Error in rep(0, 50000 * 50000) : invalid 'times' argument
>> In addition: Warning message:
>> In as.vector(data) : NAs introduced by coercion
> 
> > x <- rep(0,40000*50000)
> > gc()
>             used    (Mb) gc trigger    (Mb)   max used    (Mb)
> Ncells    4673306   249.6    6945861   371.0    5315868   283.9
> Vcells 2165579376 16522.1 4374103452 33371.8 4165580443 31780.9
> > object.size(x)
> 16000000040 bytes
> 
> So that is about 2/3 of my installed memory. This seems to be a limitation due to the maximum positive integer being ~ 2*10^9
> > 2*10^9 < 50000*50000
> [1] TRUE
> > 2*10^9 < 40000*50000
> [1] FALSE
> 

The actual limit is for obvious reasons 2^31-1

> as.integer(2^31-1)
[1] 2147483647
> as.integer(2^31)
[1] NA
Warning message:
NAs introduced by coercion 

(ok, for those that this is not obvious: the integer type ("int" in C) is 32-bit wide and it is a signed type so the range is -2^31-1 .. 2^31-1 -- the minus one on each side is the representation of NA and 0 respectively).

Cheers,
Simon


>> 
>> Here's another example:
>>> library(orthopolynom)
>>> hermite <- hermite.h.polynomials(1001)
>>> hermite[[1001]] # should display 1000-th degree polynomial
>> Error in if (signs[1] == "- ") "-" else "" :
>> missing value where TRUE/FALSE needed
> 
> Sounds as though the maximum length of an element of type character has been exceeded.
>> 
>> Thanks,
>> Dominick
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> David Winsemius, MD
> West Hartford, CT
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From simon.urbanek at r-project.org  Sat Feb 12 02:46:29 2011
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Fri, 11 Feb 2011 20:46:29 -0500
Subject: [Rd] R limits documented?
In-Reply-To: <433F8810-FE8D-4AD0-A012-45C056A505FA@r-project.org>
References: <AANLkTinoie27eMBdq7=QBBcrhBLorhFoiBX6sW+6vBzm@mail.gmail.com>
	<7C9BDD66-4BF5-4A49-A3E1-B96274457DA4@comcast.net>
	<433F8810-FE8D-4AD0-A012-45C056A505FA@r-project.org>
Message-ID: <6EAEBC2E-42FD-4D2B-BDAE-94CEC63E9FE9@r-project.org>


On Feb 11, 2011, at 8:45 PM, Simon Urbanek wrote:

> 
> On Feb 11, 2011, at 7:55 PM, David Winsemius wrote:
> 
>> 
>> On Feb 11, 2011, at 7:09 PM, Dominick Samperi wrote:
>> 
>>> Is there documentation on R limits?
>>> That is, max matrix size, etc.?
>>> 
>>> Diagnostics when limits are exceeded are not always
>>> meaningful. For example:
>>>> x <- rep(0,50000*50000)
>>> Error in rep(0, 50000 * 50000) : invalid 'times' argument
>>> In addition: Warning message:
>>> In as.vector(data) : NAs introduced by coercion
>> 
>>> x <- rep(0,40000*50000)
>>> gc()
>>            used    (Mb) gc trigger    (Mb)   max used    (Mb)
>> Ncells    4673306   249.6    6945861   371.0    5315868   283.9
>> Vcells 2165579376 16522.1 4374103452 33371.8 4165580443 31780.9
>>> object.size(x)
>> 16000000040 bytes
>> 
>> So that is about 2/3 of my installed memory. This seems to be a limitation due to the maximum positive integer being ~ 2*10^9
>>> 2*10^9 < 50000*50000
>> [1] TRUE
>>> 2*10^9 < 40000*50000
>> [1] FALSE
>> 
> 
> The actual limit is for obvious reasons 2^31-1
> 
>> as.integer(2^31-1)
> [1] 2147483647
>> as.integer(2^31)
> [1] NA
> Warning message:
> NAs introduced by coercion 
> 
> (ok, for those that this is not obvious: the integer type ("int" in C) is 32-bit wide and it is a signed type so the range is -2^31-1 .. 2^31-1 -- the minus one on each side is the representation of NA and 0 respectively).
> 

correction: the range should have read -(2^31-1) .. 2^31


> Cheers,
> Simon
> 
> 
>>> 
>>> Here's another example:
>>>> library(orthopolynom)
>>>> hermite <- hermite.h.polynomials(1001)
>>>> hermite[[1001]] # should display 1000-th degree polynomial
>>> Error in if (signs[1] == "- ") "-" else "" :
>>> missing value where TRUE/FALSE needed
>> 
>> Sounds as though the maximum length of an element of type character has been exceeded.
>>> 
>>> Thanks,
>>> Dominick
>>> 
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> 
>> David Winsemius, MD
>> West Hartford, CT
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> 
>> 
> 


From dwinsemius at comcast.net  Sat Feb 12 03:24:43 2011
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 11 Feb 2011 21:24:43 -0500
Subject: [Rd] R limits documented?
In-Reply-To: <6EAEBC2E-42FD-4D2B-BDAE-94CEC63E9FE9@r-project.org>
References: <AANLkTinoie27eMBdq7=QBBcrhBLorhFoiBX6sW+6vBzm@mail.gmail.com>
	<7C9BDD66-4BF5-4A49-A3E1-B96274457DA4@comcast.net>
	<433F8810-FE8D-4AD0-A012-45C056A505FA@r-project.org>
	<6EAEBC2E-42FD-4D2B-BDAE-94CEC63E9FE9@r-project.org>
Message-ID: <E85328A3-DCDD-4BF5-B1E8-749B68FB5F3A@comcast.net>


On Feb 11, 2011, at 8:46 PM, Simon Urbanek wrote:

>
> On Feb 11, 2011, at 8:45 PM, Simon Urbanek wrote:
>
>>
>> On Feb 11, 2011, at 7:55 PM, David Winsemius wrote:
>>
>>>
>>> On Feb 11, 2011, at 7:09 PM, Dominick Samperi wrote:
>>>
>>>> Is there documentation on R limits?
>>>> That is, max matrix size, etc.?
>>>>
>>>> Diagnostics when limits are exceeded are not always
>>>> meaningful. For example:
>>>>> x <- rep(0,50000*50000)
>>>> Error in rep(0, 50000 * 50000) : invalid 'times' argument
>>>> In addition: Warning message:
>>>> In as.vector(data) : NAs introduced by coercion
>>>
>>>> x <- rep(0,40000*50000)
>>>> gc()
>>>           used    (Mb) gc trigger    (Mb)   max used    (Mb)
>>> Ncells    4673306   249.6    6945861   371.0    5315868   283.9
>>> Vcells 2165579376 16522.1 4374103452 33371.8 4165580443 31780.9
>>>> object.size(x)
>>> 16000000040 bytes
>>>
>>> So that is about 2/3 of my installed memory. This seems to be a  
>>> limitation due to the maximum positive integer being ~ 2*10^9
>>>> 2*10^9 < 50000*50000
>>> [1] TRUE
>>>> 2*10^9 < 40000*50000
>>> [1] FALSE
>>>
>>
>> The actual limit is for obvious reasons 2^31-1
>>
>>> as.integer(2^31-1)
>> [1] 2147483647
>>> as.integer(2^31)
>> [1] NA
>> Warning message:
>> NAs introduced by coercion
>>
>> (ok, for those that this is not obvious: the integer type ("int" in  
>> C) is 32-bit wide and it is a signed type so the range is  
>> -2^31-1 .. 2^31-1 -- the minus one on each side is the  
>> representation of NA and 0 respectively).
>>
>
> correction: the range should have read -(2^31-1) .. 2^31

I was using the number given in the help page documentation for  
"integer". (Part of the question was whether it was "documented".) I  
did understand that it was d/t the 4 byte range.

Regarding the second part of the OP's question.... this is from the  
"character" help page:
"as.character truncates components of language objects to 500  
characters (was about 70 before 1.3.1)."

And there was a posting from Prof Ripley regarding some other  
limitations that had been recently modified:
https://stat.ethz.ch/pipermail/r-devel/2010-November/058989.html

-- 
David.

>
>> Cheers,
>> Simon
>>
>>>>
>>>> Here's another example:
>>>>> library(orthopolynom)
>>>>> hermite <- hermite.h.polynomials(1001)
>>>>> hermite[[1001]] # should display 1000-th degree polynomial
>>>> Error in if (signs[1] == "- ") "-" else "" :
>>>> missing value where TRUE/FALSE needed
>>>
>>> Sounds as though the maximum length of an element of type  
>>> character has been exceeded.
>>>>
>>>> Thanks,
>>>> Dominick
>

David Winsemius, MD
West Hartford, CT


From mdsumner at gmail.com  Sat Feb 12 07:22:59 2011
From: mdsumner at gmail.com (Michael Sumner)
Date: Sat, 12 Feb 2011 17:22:59 +1100
Subject: [Rd] using rasterImage within image
In-Reply-To: <4D5493BD.4050801@auckland.ac.nz>
References: <4D51F2A7.8010505@mcmaster.ca>
	<D8F5413E-025A-4511-BCE1-7ED06CBE99A0@r-project.org>
	<4D52AD7B.6070402@gmail.com>
	<E86B0A90-F63F-4537-A7FB-1AA84D685154@r-project.org>
	<AANLkTi=yRP56wACtOs+Ouc70EV57rw9RKYmfLAh2hQ8a@mail.gmail.com>
	<825F0B1E-EF80-48F5-AFF1-5832092450AB@r-project.org>
	<AANLkTi=0K6hCP0tptSf6h4S6au+-SmahDm983zRdZEgb@mail.gmail.com>
	<4D531558.7010709@gmail.com>
	<AANLkTi=nwF-3UjtoFAaLdTwphmezvuk57HaaJd57=am2@mail.gmail.com>
	<AANLkTimHAmzq4CEJF-auHRSA8745x2yb8r_GK9+vTrKJ@mail.gmail.com>
	<4D5493BD.4050801@auckland.ac.nz>
Message-ID: <AANLkTikiFnaCPzBxDdDGV0+jhvo-bwo067Fnx1tSzW3=@mail.gmail.com>

Hello, that appears to have fixed it. Thank you very much.

I can now repeat the reported workflow and the image appears on the
fifth (and subsequent) calls.

Cheers, Mike.

 sessionInfo()
R version 2.13.0 Under development (unstable) (2011-02-11 r54330)
Platform: x86_64-pc-mingw32/x64 (64-bit)

locale:
[1] LC_COLLATE=English_Australia.1252  LC_CTYPE=English_Australia.1252
[3] LC_MONETARY=English_Australia.1252 LC_NUMERIC=C
[5] LC_TIME=English_Australia.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

On Fri, Feb 11, 2011 at 12:41 PM, Paul Murrell <p.murrell at auckland.ac.nz> wrote:
> Hi
>
> Just committed another fix that solves this problem for me at least. ?If you
> want to test for yourself, the magic revision number that you are looking
> for is r54330.
>
> Thanks again for your help.
>
> Paul
>
> On 10/02/2011 7:54 p.m., Michael Sumner wrote:
>>
>> Hello, I'm afraid the SDI graphics issue is still a problem in 2.13.0
>> 2011-02-09 r54308.
>>
>> To reproduce, in a fresh R session (Windows in SDI mode):
>>
>> ## create a dummy dataset
>> m<- matrix(c(0.2, 0.4, 0.6, 0.8), 2, 2)
>>
>> ## simple helper function to open the windows() device and plot the matrix
>> draw.f<- function(x) {
>> ? ?plot(0, xlim = c(0, 1), ylim = c(0, 1))
>> ? ?rasterImage(x, 0, 0, 1, 1, interpolate = FALSE)
>> }
>>
>> draw.f(m)
>>
>> ## repeat the following 2 lines five times:
>>
>> dev.off()
>> draw.f(m)
>>
>> On the fifth attempt, only the background plot appears - but the
>> raster is visible on resize of the windows() device.
>>
>> Cheers, Mike.
>>
>> sessionInfo()
>> R version 2.13.0 Under development (unstable) (2011-02-09 r54308)
>> Platform: x86_64-pc-mingw32/x64 (64-bit)
>>
>> locale:
>> [1] LC_COLLATE=English_Australia.1252 ?LC_CTYPE=English_Australia.1252
>> [3] LC_MONETARY=English_Australia.1252 LC_NUMERIC=C
>> [5] LC_TIME=English_Australia.1252
>>
>> attached base packages:
>> [1] stats ? ? graphics ?grDevices utils ? ? datasets ?methods ? base
>>
>>
>>
>> On Thu, Feb 10, 2011 at 5:31 PM, baptiste auguie
>> <baptiste.auguie at googlemail.com> ?wrote:
>>>
>>> Dear all,
>>>
>>> Back when grid.raster() was introduced, it was suggested that perhaps
>>> grid.rect() could use grid.raster() in case of even spacing. The
>>> response at the time was that it would be best to keep the two
>>> functions separate at a lower level, that is grid.rect() and
>>> grid.raster(), but perhaps a new function grid.image() could be
>>> proposed at a higher level with the two possible backends. If this is
>>> done in grid graphics, perhaps the same convention could be used for
>>> base graphics: image() would be high level with the backend option,
>>> and a new function ("tiles()", perhaps?) would implement the current
>>> behavior of image().
>>>
>>> In any case, it would be nice to have a unified scheme to switch
>>> between "tiles" and raster; currently lattice (panl.levelplot.raster)
>>> and a few other packages all do it separately.
>>>
>>> Best wishes,
>>>
>>> baptiste
>>>
>>>
>>>
>>> On 9 February 2011 23:29, Ben Bolker<bbolker at gmail.com> ?wrote:
>>>>
>>>> -----BEGIN PGP SIGNED MESSAGE-----
>>>> Hash: SHA1
>>>>
>>>> On 11-02-09 03:09 PM, Henrik Bengtsson wrote:
>>>>>
>>>>> On Wed, Feb 9, 2011 at 11:53 AM, Simon Urbanek
>>>>> <simon.urbanek at r-project.org> ?wrote:
>>>>>>
>>>>>> On Feb 9, 2011, at 2:36 PM, Henrik Bengtsson wrote:
>>>>>>
>>>>>>> On Wed, Feb 9, 2011 at 11:25 AM, Simon Urbanek
>>>>>>> <simon.urbanek at r-project.org> ?wrote:
>>>>>>>>
>>>>>>>> Ben,
>>>>>>>>
>>>>>>>> I have committed something analogous to R-devel (your rotation
>>>>>>>> code was not unlike mine, I replicated the color handling from
>>>>>>>> R internals to be consistent, I fixed the drawing limits and
>>>>>>>> added a check for x/y conformance). Note that useRaster can
>>>>>>>> only be used when x, y form a regular grid. Although I tried a
>>>>>>>> lot of corner cases (requiring quite a few fixes), I'm sure I
>>>>>>>> did not test all of them, so volunteers please give it a go and
>>>>>>>> compare it with non-raster output.
>>>>>>>>
>>>>>>>> The only thing I'm not quite happy about is the argument name:
>>>>>>>> useRaster. Personally, I hate camel case in R (it has crept in
>>>>>>>> more recently making it horribly inconsistent) so please feel
>>>>>>>> free to suggest a better name ;).
>>>>>>>
>>>>>>> It.is.spelled.camelCase.
>>>>>>>
>>>>>>
>>>>>> Fortunately not in English ;)
>>>>>>
>>>>>>
>>>>>>> What about style=c("image", "raster")? ?This allows for future
>>>>>>> extensions too.
>>>>>>>
>>>>>>
>>>>>> Hmm.. it's not really a "style" - the output doesn't change
>>>>>> (ideally) - it's more of a back-end specification .. also we
>>>>>> already have oldstyle argument in image() adding to the confusion
>>>>>> ...
>>>>>
>>>>> flavor=c("image", "raster") renderer=c("image", "raster")
>>>>> backend=c("image", "raster") ...
>>>>
>>>> ?Thanks Simon! (Any reports on the SDI Windows raster rendering issue,
>>>> or do we need a warning/workaround there?)
>>>>
>>>> ?I like "backend", or possibly "method"
>>>>
>>>> ?One minor consideration: if "raster" eventually becomes the default
>>>> (as I hope it will), there would need to be some internal logic that
>>>> drops back to "image" if the user specifies uneven spacing and doesn't
>>>> explicitly specify the 'backend/method' parameter ...
>>>> -----BEGIN PGP SIGNATURE-----
>>>> Version: GnuPG v1.4.10 (GNU/Linux)
>>>> Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org/
>>>>
>>>> iEYEARECAAYFAk1TFVcACgkQc5UpGjwzenOa6ACfVnJq67cG0czATeyti7AxgUbw
>>>> ZWwAniA7JuYCv4clq8e6jwWQuMvw/r+m
>>>> =/da6
>>>> -----END PGP SIGNATURE-----
>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>
>>
>>
>
> --
> Dr Paul Murrell
> Department of Statistics
> The University of Auckland
> Private Bag 92019
> Auckland
> New Zealand
> 64 9 3737599 x85392
> paul at stat.auckland.ac.nz
> http://www.stat.auckland.ac.nz/~paul/
>



-- 
Michael Sumner
Institute for Marine and Antarctic Studies, University of Tasmania
Hobart, Australia
e-mail: mdsumner at gmail.com


From ligges at statistik.tu-dortmund.de  Sat Feb 12 15:34:33 2011
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sat, 12 Feb 2011 15:34:33 +0100
Subject: [Rd] R limits documented?
In-Reply-To: <E85328A3-DCDD-4BF5-B1E8-749B68FB5F3A@comcast.net>
References: <AANLkTinoie27eMBdq7=QBBcrhBLorhFoiBX6sW+6vBzm@mail.gmail.com>	<7C9BDD66-4BF5-4A49-A3E1-B96274457DA4@comcast.net>	<433F8810-FE8D-4AD0-A012-45C056A505FA@r-project.org>	<6EAEBC2E-42FD-4D2B-BDAE-94CEC63E9FE9@r-project.org>
	<E85328A3-DCDD-4BF5-B1E8-749B68FB5F3A@comcast.net>
Message-ID: <4D569A79.6030202@statistik.tu-dortmund.de>

I think it is easiest to point people to the manual "R Internals" for 
questions on the size of integers, pointers etc.

Best,
Uwe Ligges



On 12.02.2011 03:24, David Winsemius wrote:
>
> On Feb 11, 2011, at 8:46 PM, Simon Urbanek wrote:
>
>>
>> On Feb 11, 2011, at 8:45 PM, Simon Urbanek wrote:
>>
>>>
>>> On Feb 11, 2011, at 7:55 PM, David Winsemius wrote:
>>>
>>>>
>>>> On Feb 11, 2011, at 7:09 PM, Dominick Samperi wrote:
>>>>
>>>>> Is there documentation on R limits?
>>>>> That is, max matrix size, etc.?
>>>>>
>>>>> Diagnostics when limits are exceeded are not always
>>>>> meaningful. For example:
>>>>>> x <- rep(0,50000*50000)
>>>>> Error in rep(0, 50000 * 50000) : invalid 'times' argument
>>>>> In addition: Warning message:
>>>>> In as.vector(data) : NAs introduced by coercion
>>>>
>>>>> x <- rep(0,40000*50000)
>>>>> gc()
>>>> used (Mb) gc trigger (Mb) max used (Mb)
>>>> Ncells 4673306 249.6 6945861 371.0 5315868 283.9
>>>> Vcells 2165579376 16522.1 4374103452 33371.8 4165580443 31780.9
>>>>> object.size(x)
>>>> 16000000040 bytes
>>>>
>>>> So that is about 2/3 of my installed memory. This seems to be a
>>>> limitation due to the maximum positive integer being ~ 2*10^9
>>>>> 2*10^9 < 50000*50000
>>>> [1] TRUE
>>>>> 2*10^9 < 40000*50000
>>>> [1] FALSE
>>>>
>>>
>>> The actual limit is for obvious reasons 2^31-1
>>>
>>>> as.integer(2^31-1)
>>> [1] 2147483647
>>>> as.integer(2^31)
>>> [1] NA
>>> Warning message:
>>> NAs introduced by coercion
>>>
>>> (ok, for those that this is not obvious: the integer type ("int" in
>>> C) is 32-bit wide and it is a signed type so the range is -2^31-1 ..
>>> 2^31-1 -- the minus one on each side is the representation of NA and
>>> 0 respectively).
>>>
>>
>> correction: the range should have read -(2^31-1) .. 2^31
>
> I was using the number given in the help page documentation for
> "integer". (Part of the question was whether it was "documented".) I did
> understand that it was d/t the 4 byte range.
>
> Regarding the second part of the OP's question.... this is from the
> "character" help page:
> "as.character truncates components of language objects to 500 characters
> (was about 70 before 1.3.1)."
>
> And there was a posting from Prof Ripley regarding some other
> limitations that had been recently modified:
> https://stat.ethz.ch/pipermail/r-devel/2010-November/058989.html
>


From ripley at stats.ox.ac.uk  Sat Feb 12 18:12:47 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 12 Feb 2011 17:12:47 +0000 (GMT)
Subject: [Rd] R limits documented?
In-Reply-To: <4D569A79.6030202@statistik.tu-dortmund.de>
References: <AANLkTinoie27eMBdq7=QBBcrhBLorhFoiBX6sW+6vBzm@mail.gmail.com>
	<7C9BDD66-4BF5-4A49-A3E1-B96274457DA4@comcast.net>
	<433F8810-FE8D-4AD0-A012-45C056A505FA@r-project.org>
	<6EAEBC2E-42FD-4D2B-BDAE-94CEC63E9FE9@r-project.org>
	<E85328A3-DCDD-4BF5-B1E8-749B68FB5F3A@comcast.net>
	<4D569A79.6030202@statistik.tu-dortmund.de>
Message-ID: <alpine.LFD.2.02.1102121701040.32157@gannet.stats.ox.ac.uk>

On Sat, 12 Feb 2011, Uwe Ligges wrote:

> I think it is easiest to point people to the manual "R Internals" for 
> questions on the size of integers, pointers etc.

But ?"Memory-limits" is a good start.

The messages below (which were not from a current version of R with 
that call!) come from

> as.integer(50000 * 50000)
[1] NA
Warning message:
NAs introduced by coercion

and times = NA is of course invalid.

>
> Best,
> Uwe Ligges
>
>
>
> On 12.02.2011 03:24, David Winsemius wrote:
>> 
>> On Feb 11, 2011, at 8:46 PM, Simon Urbanek wrote:
>> 
>>> 
>>> On Feb 11, 2011, at 8:45 PM, Simon Urbanek wrote:
>>> 
>>>> 
>>>> On Feb 11, 2011, at 7:55 PM, David Winsemius wrote:
>>>> 
>>>>> 
>>>>> On Feb 11, 2011, at 7:09 PM, Dominick Samperi wrote:
>>>>> 
>>>>>> Is there documentation on R limits?
>>>>>> That is, max matrix size, etc.?
>>>>>> 
>>>>>> Diagnostics when limits are exceeded are not always
>>>>>> meaningful. For example:
>>>>>>> x <- rep(0,50000*50000)
>>>>>> Error in rep(0, 50000 * 50000) : invalid 'times' argument
>>>>>> In addition: Warning message:
>>>>>> In as.vector(data) : NAs introduced by coercion
>>>>> 
>>>>>> x <- rep(0,40000*50000)
>>>>>> gc()
>>>>> used (Mb) gc trigger (Mb) max used (Mb)
>>>>> Ncells 4673306 249.6 6945861 371.0 5315868 283.9
>>>>> Vcells 2165579376 16522.1 4374103452 33371.8 4165580443 31780.9
>>>>>> object.size(x)
>>>>> 16000000040 bytes
>>>>> 
>>>>> So that is about 2/3 of my installed memory. This seems to be a
>>>>> limitation due to the maximum positive integer being ~ 2*10^9
>>>>>> 2*10^9 < 50000*50000
>>>>> [1] TRUE
>>>>>> 2*10^9 < 40000*50000
>>>>> [1] FALSE
>>>>> 
>>>> 
>>>> The actual limit is for obvious reasons 2^31-1
>>>> 
>>>>> as.integer(2^31-1)
>>>> [1] 2147483647
>>>>> as.integer(2^31)
>>>> [1] NA
>>>> Warning message:
>>>> NAs introduced by coercion
>>>> 
>>>> (ok, for those that this is not obvious: the integer type ("int" in
>>>> C) is 32-bit wide and it is a signed type so the range is -2^31-1 ..
>>>> 2^31-1 -- the minus one on each side is the representation of NA and
>>>> 0 respectively).
>>>> 
>>> 
>>> correction: the range should have read -(2^31-1) .. 2^31
>> 
>> I was using the number given in the help page documentation for
>> "integer". (Part of the question was whether it was "documented".) I did
>> understand that it was d/t the 4 byte range.
>> 
>> Regarding the second part of the OP's question.... this is from the
>> "character" help page:
>> "as.character truncates components of language objects to 500 characters
>> (was about 70 before 1.3.1)."
>> 
>> And there was a posting from Prof Ripley regarding some other
>> limitations that had been recently modified:
>> https://stat.ethz.ch/pipermail/r-devel/2010-November/058989.html
>> 
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From hb at biostat.ucsf.edu  Sat Feb 12 22:57:41 2011
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Sat, 12 Feb 2011 13:57:41 -0800
Subject: [Rd] R 2.13.0 on Windows: R CMD check and '"du"' not found
Message-ID: <AANLkTinypB_0XrtxrxyK26URcCeUWuMFFFsXKzqa7G1X@mail.gmail.com>

FYI, I'm sure the following is a temporary issue, but in case it slips
through, I want to raise it here.  On Windows 7 64-bit, running Rcmd
check on R devel gives:

 * using R version 2.13.0 Under development (unstable) (2011-02-11 r54330)
* using platform: x86_64-pc-mingw32 (64-bit)
* using session charset: ISO8859-1
* checking for file 'aroma.core/DESCRIPTION' ... OK
* this is package 'aroma.core' version '1.9.4'
* checking package dependencies ... OK
* checking if this is a source package ... OK
* checking for executable files ... OK
* checking whether package 'aroma.core' can be installed ... OK
* checking installed package size ...Error in system2("du", , TRUE,
TRUE) : '"du"' not found
Execution halted

That is, the 'du' (disk usage) executable is missing.

I've verified that installing the latest Rtools
[http://www.murdoch-sutherland.com/Rtools/Rtools212.exe] does not
solve it (=it does not contain 'du').  BTW, is there a way to know
when Rtools have been updated relative to the version you already have
installed?

/Henrik

PS. Placing the 'du.exe' executable of UnxTools
(http://sourceforge.net/projects/unxutils/) in the bin/ directory of
Rtools (e.g. C:/Rtools/bin/) provides a workaround.


> sessionInfo()
R version 2.13.0 Under development (unstable) (2011-02-11 r54330)
Platform: x86_64-pc-mingw32/x64 (64-bit)

locale:
[1] LC_COLLATE=English_United States.1252
[2] LC_CTYPE=English_United States.1252
[3] LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C
[5] LC_TIME=English_United States.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base


From hankin.robin at gmail.com  Sat Feb 12 22:54:37 2011
From: hankin.robin at gmail.com (robin hankin)
Date: Sun, 13 Feb 2011 10:54:37 +1300
Subject: [Rd] large vignette problem
Message-ID: <AANLkTikVr=_Pi2ft494GjTAe71WkCtcjb8p96icDvjPp@mail.gmail.com>

Hello

I am trying to get one of my packages to be less than 5Mb in size, and
it is currently
72Mb installed.  It is big because the single vignette includes half a
dozen very large PDF
images.  The PDF files are created as part of the Sweave process.

Using jpg images instead of PDFs is acceptable  in terms of picture
quality (although
not perfect), and results in a very much smaller vignette.

OK, so here?s my first plan and I?m not sure if it?s optimal::

1.  Produce the .jpg files by hand from my own PDF files.
2.  Change the .Rnw file so that it doesn?t produce the PDF files and
the vignette uses the .jpg files instead.
3. ship the package with the .jpg files and the modified .Rnw file.

This is not ideal because it?s not reproducible: only *I* can create
the jpg files from the original .Rnw file, as the new .Rnw file does
not produce the PDF files.

Or can I somehow coerce Sweave into producing jpg files instead of PDF?

Can anyone advise?

thanks

Robin


-- 
Robin Hankin
Uncertainty Analyst
hankin.robin at gmail.com


From hb at biostat.ucsf.edu  Sun Feb 13 01:26:02 2011
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Sat, 12 Feb 2011 16:26:02 -0800
Subject: [Rd] large vignette problem
In-Reply-To: <AANLkTikVr=_Pi2ft494GjTAe71WkCtcjb8p96icDvjPp@mail.gmail.com>
References: <AANLkTikVr=_Pi2ft494GjTAe71WkCtcjb8p96icDvjPp@mail.gmail.com>
Message-ID: <AANLkTi=-N_Jkcn_AhsVqKpF51zVSq4BuBoCGUKXQL0Y-@mail.gmail.com>

Never ever use JPEG for bitmap data plots. Use PNG instead.  See
attach image (origin unknown; it is *not* an xkcd comics).

That should solve your issues.

/H

On Sat, Feb 12, 2011 at 1:54 PM, robin hankin <hankin.robin at gmail.com> wrote:
> Hello
>
> I am trying to get one of my packages to be less than 5Mb in size, and
> it is currently
> 72Mb installed. ?It is big because the single vignette includes half a
> dozen very large PDF
> images. ?The PDF files are created as part of the Sweave process.
>
> Using jpg images instead of PDFs is acceptable ?in terms of picture
> quality (although
> not perfect), and results in a very much smaller vignette.
>
> OK, so here?s my first plan and I?m not sure if it?s optimal::
>
> 1. ?Produce the .jpg files by hand from my own PDF files.
> 2. ?Change the .Rnw file so that it doesn?t produce the PDF files and
> the vignette uses the .jpg files instead.
> 3. ship the package with the .jpg files and the modified .Rnw file.
>
> This is not ideal because it?s not reproducible: only *I* can create
> the jpg files from the original .Rnw file, as the new .Rnw file does
> not produce the PDF files.
>
> Or can I somehow coerce Sweave into producing jpg files instead of PDF?
>
> Can anyone advise?
>
> thanks
>
> Robin
>
>
> --
> Robin Hankin
> Uncertainty Analyst
> hankin.robin at gmail.com
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: PNG_vs_JPEG.png
Type: image/png
Size: 48018 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110212/28b1d551/attachment.png>

From hb at biostat.ucsf.edu  Sun Feb 13 01:43:50 2011
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Sat, 12 Feb 2011 16:43:50 -0800
Subject: [Rd] large vignette problem
In-Reply-To: <AANLkTi=-N_Jkcn_AhsVqKpF51zVSq4BuBoCGUKXQL0Y-@mail.gmail.com>
References: <AANLkTikVr=_Pi2ft494GjTAe71WkCtcjb8p96icDvjPp@mail.gmail.com>
	<AANLkTi=-N_Jkcn_AhsVqKpF51zVSq4BuBoCGUKXQL0Y-@mail.gmail.com>
Message-ID: <AANLkTi=1f2-7ZM7Vo7Vf1f7hrcwORHGRRaah+5CnrB8A@mail.gmail.com>

On Sat, Feb 12, 2011 at 4:26 PM, Henrik Bengtsson <hb at biostat.ucsf.edu> wrote:
> Never ever use JPEG for bitmap data plots. Use PNG instead. ?See
> attach image (origin unknown; it is *not* an xkcd comics).

Oops - missed to include the following:

To generate PNGs, you can do it manually in the Sweave document, e.g.

<<myFigure>>=
png("myFigure.png");
plot(1:10);
dev.off();
@

\begin{figure}
 \resizebox{0.9\textwidth}{!}{\includegraphics{myFigure}}
 \caption{A caption.}
 \label{fig:aLabel}
\end{figure}

>
> That should solve your issues.

/H

>
> /H
>
> On Sat, Feb 12, 2011 at 1:54 PM, robin hankin <hankin.robin at gmail.com> wrote:
>> Hello
>>
>> I am trying to get one of my packages to be less than 5Mb in size, and
>> it is currently
>> 72Mb installed. ?It is big because the single vignette includes half a
>> dozen very large PDF
>> images. ?The PDF files are created as part of the Sweave process.
>>
>> Using jpg images instead of PDFs is acceptable ?in terms of picture
>> quality (although
>> not perfect), and results in a very much smaller vignette.
>>
>> OK, so here?s my first plan and I?m not sure if it?s optimal::
>>
>> 1. ?Produce the .jpg files by hand from my own PDF files.
>> 2. ?Change the .Rnw file so that it doesn?t produce the PDF files and
>> the vignette uses the .jpg files instead.
>> 3. ship the package with the .jpg files and the modified .Rnw file.
>>
>> This is not ideal because it?s not reproducible: only *I* can create
>> the jpg files from the original .Rnw file, as the new .Rnw file does
>> not produce the PDF files.
>>
>> Or can I somehow coerce Sweave into producing jpg files instead of PDF?
>>
>> Can anyone advise?
>>
>> thanks
>>
>> Robin
>>
>>
>> --
>> Robin Hankin
>> Uncertainty Analyst
>> hankin.robin at gmail.com
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>


From D.Strbenac at garvan.org.au  Sun Feb 13 02:00:11 2011
From: D.Strbenac at garvan.org.au (Dario Strbenac)
Date: Sun, 13 Feb 2011 12:00:11 +1100 (EST)
Subject: [Rd] large vignette problem
Message-ID: <20110213120011.BKV88388@gimr.garvan.unsw.edu.au>

I usually do :

<<label=xyFile, echo=FALSE>>=
png("xyPlot.png", width = 800, height = 800)
@

<<label=xyPlot>>=
...      ...       ... # Code goes here.
@

<<label=xyClose, echo=FALSE>>=
null <- dev.off()
@

\begin{figure}
    \begin{center}
        \includegraphics{xyPlot.png}
    \end{center}
\end{figure}

---- Original message ----
>Date: Sun, 13 Feb 2011 10:54:37 +1300
>From: r-devel-bounces at r-project.org (on behalf of robin hankin <hankin.robin at gmail.com>)
>Subject: [Rd] large vignette problem  
>To: r-devel at r-project.org
>
>Hello
>
>I am trying to get one of my packages to be less than 5Mb in size, and
>it is currently
>72Mb installed.  It is big because the single vignette includes half a
>dozen very large PDF
>images.  The PDF files are created as part of the Sweave process.
>
>Using jpg images instead of PDFs is acceptable  in terms of picture
>quality (although
>not perfect), and results in a very much smaller vignette.
>
>OK, so here?s my first plan and I?m not sure if it?s optimal::
>
>1.  Produce the .jpg files by hand from my own PDF files.
>2.  Change the .Rnw file so that it doesn?t produce the PDF files and
>the vignette uses the .jpg files instead.
>3. ship the package with the .jpg files and the modified .Rnw file.
>
>This is not ideal because it?s not reproducible: only *I* can create
>the jpg files from the original .Rnw file, as the new .Rnw file does
>not produce the PDF files.
>
>Or can I somehow coerce Sweave into producing jpg files instead of PDF?
>
>Can anyone advise?
>
>thanks
>
>Robin
>
>
>-- 
>Robin Hankin
>Uncertainty Analyst
>hankin.robin at gmail.com
>
>______________________________________________
>R-devel at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-devel


--------------------------------------
Dario Strbenac
Research Assistant
Cancer Epigenetics
Garvan Institute of Medical Research
Darlinghurst NSW 2010
Australia

From hankin.robin at gmail.com  Sun Feb 13 04:12:43 2011
From: hankin.robin at gmail.com (robin hankin)
Date: Sun, 13 Feb 2011 16:12:43 +1300
Subject: [Rd] large vignette problem
In-Reply-To: <20110213120011.BKV88388@gimr.garvan.unsw.edu.au>
References: <20110213120011.BKV88388@gimr.garvan.unsw.edu.au>
Message-ID: <AANLkTim063ZP-OYZTbN5+8EsieNXAbnffiO6u3oBhzW8@mail.gmail.com>

Thanks guys.

It works perfectly

best wishes

rksh

On Sun, Feb 13, 2011 at 2:00 PM, Dario Strbenac
<D.Strbenac at garvan.org.au> wrote:
> I usually do :
>
> <<label=xyFile, echo=FALSE>>=
> png("xyPlot.png", width = 800, height = 800)
> @
>
> <<label=xyPlot>>=
> ... ? ? ?... ? ? ? ... # Code goes here.
> @
>
> <<label=xyClose, echo=FALSE>>=
> null <- dev.off()
> @
>
> \begin{figure}
> ? ?\begin{center}
> ? ? ? ?\includegraphics{xyPlot.png}
> ? ?\end{center}
> \end{figure}
>
> ---- Original message ----
>>Date: Sun, 13 Feb 2011 10:54:37 +1300
>>From: r-devel-bounces at r-project.org (on behalf of robin hankin <hankin.robin at gmail.com>)
>>Subject: [Rd] large vignette problem
>>To: r-devel at r-project.org
>>
>>Hello
>>
>>I am trying to get one of my packages to be less than 5Mb in size, and
>>it is currently
>>72Mb installed. ?It is big because the single vignette includes half a
>>dozen very large PDF
>>images. ?The PDF files are created as part of the Sweave process.
>>
>>Using jpg images instead of PDFs is acceptable ?in terms of picture
>>quality (although
>>not perfect), and results in a very much smaller vignette.
>>
>>OK, so here?s my first plan and I?m not sure if it?s optimal::
>>
>>1. ?Produce the .jpg files by hand from my own PDF files.
>>2. ?Change the .Rnw file so that it doesn?t produce the PDF files and
>>the vignette uses the .jpg files instead.
>>3. ship the package with the .jpg files and the modified .Rnw file.
>>
>>This is not ideal because it?s not reproducible: only *I* can create
>>the jpg files from the original .Rnw file, as the new .Rnw file does
>>not produce the PDF files.
>>
>>Or can I somehow coerce Sweave into producing jpg files instead of PDF?
>>
>>Can anyone advise?
>>
>>thanks
>>
>>Robin
>>
>>
>>--
>>Robin Hankin
>>Uncertainty Analyst
>>hankin.robin at gmail.com
>>
>>______________________________________________
>>R-devel at r-project.org mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-devel
>
>
> --------------------------------------
> Dario Strbenac
> Research Assistant
> Cancer Epigenetics
> Garvan Institute of Medical Research
> Darlinghurst NSW 2010
> Australia
>



-- 
Robin Hankin
Uncertainty Analyst
hankin.robin at gmail.com


From savicky at cs.cas.cz  Sun Feb 13 13:16:05 2011
From: savicky at cs.cas.cz (Petr Savicky)
Date: Sun, 13 Feb 2011 13:16:05 +0100
Subject: [Rd] print(...,digits=2) behavior
In-Reply-To: <19791.46002.901049.478712@stat.math.ethz.ch>
References: <4D4DB9E1.4000306@mcmaster.ca>
	<19791.46002.901049.478712@stat.math.ethz.ch>
Message-ID: <20110213121605.GA17004@cs.cas.cz>

On Mon, Feb 07, 2011 at 09:56:18AM +0100, Martin Maechler wrote:
[...]
> Namely, one important purpose of the test is to ensure that e.g.
> 
>   print(3.597, digits = 3)
> 
> is printed as  3.6   and not 3.60
> 
> Now I have had -- since 1997 at least -- an R version of
> scientific() for more easy experimentation.
> Here's an updated version of that:

[...]
> 
> Now, I'm waiting for comments/suggestions ..

In a previous email, i discussed the case print(9.991, digits=3).
This case is already handled in your R level experimental function
scientific(). I noticed this only after sending the previous email.

I would like to suggest a modification of the algorithm. The purpose
is to determine the minimum number of digits, such that the printed number
has the same value as the number rounded to exactly getOption("digits")
digits, but shorter representation.

Algorithm. First, the mantissa of the number rounded to "digits" digits
is computed as an integer by the formula

  a <- floor(alpha*10^(digits - 1) + 0.5)

The obtained integer number a satisfies

  10^(digits-1) <= a <= 10^digits

The case a = 10^digits corresponds to the situation that we have to
increase the exponent. This may be tested either before the remaining
part of the code or as the last step as below.

For example, if alpha = 3.597 and digits = 3, we get a = 360. The
question, whether (digits - 1) digits are sufficient for printing the
number, is equivalent to the condition that "a" is divisible by 10.
Similarly, (digits - 2) digits are sufficient if and only if "a" is
divisible by 100. This may be tested using the following code

    nsig <- digits
    for (j in 1:nsig) {
        a <- a / 10
        if (a == floor(a)) {
            nsig <- nsig - 1
        } else {
            break
        }
    }
    ## nsig == 0 if and only if we started with a == 10^digits
    if (nsig == 0) {
        nsig <- 1
        kpower <- kpower + 1
    }

This code uses double precision for a, since values up to 10^digits
may occur and digits may be 15 or more. The algorithm is not exact
for digits = 15, but works reasonably. I suggest to use a different,
slower and more accurate algorithm, if getOption("digits") >= 16.

Please, find in an attachment two versions of the above algorithm. One
is a modification of your R level function from scientific.R and the
other is a patch against src/main/format.c, which i tested.

I suggest to consider the following test cases. The presented output
is obtained using the patch.

  example1 <- c(
  7.94999999999999,
  7.95000000000001,
  8.04999999999999,
  8.05000000000001)
  for (x in example1) print(x, digits=2)
  
  [1] 7.9
  [1] 8
  [1] 8
  [1] 8.1
  
  example2 <- c(
  3.59949999999999,
  3.59950000000001,
  3.60049999999999,
  3.60050000000001)
  for (x in example2) print(x, digits=4)
  
  [1] 3.599
  [1] 3.6
  [1] 3.6
  [1] 3.601
  
  example3 <- c(
  1.00000049999999,
  1.00000050000001)
  for (x in example3) print(x, digits=7)
  
  [1] 1
  [1] 1.000001
  
  example4 <- c(
  9.99999949999999,
  9.99999950000001)
  for (x in example4) print(x, digits=7)
  
  [1] 9.999999
  [1] 10

I appreciate comments.

Petr Savicky.

-------------- next part --------------
###--- R function that does the same as 'scientific' in

###--- /usr/local/R-0.50/src/main/format.c
###--- ~~~~~~~~~~~||||||~~~~~~~~~~~~~~~~~~

scientific1 <- function(x, digits = getOption('digits')) ## eps = 10^-(digits)
{
  ##-   /* for 1 number  x , return
  ##-    *      sgn    = 1_{x < 0}  {0/1}
  ##-    *      kpower = Exponent of 10;
  ##-    *      nsig   = min(digits, #{significant digits of alpha})
  ##-    *
  ##-    * where  |x| = alpha * 10^kpower   and  1 <= alpha < 10
  ##-    */

  eps <- 10 ^(-digits)

  if (x == 0) {
    kpower <- 0
    nsig <- 1
    sgn <- 0
  } else {
    if(x < 0) {
      sgn <- 1; r <- -x
    } else {
      sgn <- 0; r <- x
    }
    kpower <- floor(log10(r));##-->      r = |x| ;  10^k <= r

    if (kpower <= -308) ## close to denormalization -- added for R 2.x.y
        alpha <- (r * 1e+30) / 10^(kpower+30)
    else
        alpha <- r / 10^kpower

    ## "a" integer, 10^(digits-1) <= a <= 10^digits

    a <- floor(alpha*10^(digits - 1) + 0.5)
    nsig <- digits
    for (j in 1:nsig) {
        a <- a / 10
        if (a == floor(a)) {
            nsig <- nsig - 1
        } else {
            break
        }
    }
    if (nsig == 0) {
        nsig <- 1
        kpower <- kpower + 1
    }
  }
  left <- kpower + 1
  c(sgn = sgn, kpower = kpower, nsig = nsig,
    left = left, right = nsig - left,
    sleft = sgn + max(1,left))
}

-------------- next part --------------
diff --minimal -U 5 -r R-devel/src/main/format.c R-devel-print/src/main/format.c
--- R-devel/src/main/format.c	2010-04-27 17:52:24.000000000 +0200
+++ R-devel-print/src/main/format.c	2011-02-12 11:07:37.000000000 +0100
@@ -167,28 +167,26 @@
 	    alpha = (r * 1e+30)/pow(10.0, (double)(kp+30));
 	}
 	else
 	    alpha = r / pow(10.0, (double)kp);
 
-	/* make sure that alpha is in [1,10) AFTER rounding */
-
-	if (10.0 - alpha < eps*alpha) {
-	    alpha /= 10.0;
-	    kp += 1;
-	}
-	*kpower = kp;
-
-	/* compute number of digits */
-
-	*nsig = R_print.digits;
-	for (j = 1; j <= *nsig; j++) {
-	    if (fabs(alpha - floor(alpha+0.5)) < eps * alpha) {
-		*nsig = j;
-		break;
-	    }
-	    alpha *= 10.0;
-	}
+        /* alpha integer, 10^(digits-1) <= alpha <= 10^digits */
+        alpha = floor(alpha*pow(10.0, R_print.digits - 1.0) + 0.5);
+        *nsig = R_print.digits;
+        for (j = 1; j <= R_print.digits; j++) {
+            alpha /= 10.0;
+            if (alpha == floor(alpha)) {
+                (*nsig)--;
+            } else {
+                break;
+            }
+        }
+        if (*nsig == 0) {
+            *nsig = 1;
+            kp += 1;
+        }
+        *kpower = kp;
     }
 }
 
 /*
    The return values are

From ripley at stats.ox.ac.uk  Sun Feb 13 13:30:24 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 13 Feb 2011 12:30:24 +0000 (GMT)
Subject: [Rd] CRAN package sizes
Message-ID: <alpine.OSX.1.00.1102131203050.44163@tystie.local>

Robin Hankin's post reminded me to post about the following recent 
addition to 'Writing R Extensions', in the section on 'Submitting a 
package to CRAN'

   Ensure that the package sources are not unnecessarily large. ...
   As a general rule, doc directories should not exceed 5Mb, and
   where data directories need to be 10Mb or more, consideration should
   be given to a separate package containing just the data. (Similarly
   for external data directories, large jar files and other libraries
   that need to be installed.)

With 2800 packages on CRAN, overall size is becoming a concern and 
currently to install all of CRAN takes 4Gb.  As the attached (I hope) 
graph shows, the 20 packages over 20Mb take a quarter, and those over 
5Mb take half.  (And this is after we have removed 100Mb from the 
largest installed package by re-compression, and archived the second 
largest, so Robin's package is currently the largest.)  Some of the 
largest packages are data/jar packages, but there are 55 packages with 
'doc' directories over 5Mb.  To put that in perspective, PDFs of whole 
books with lots of figures (MASS, Paul's R Graphics) are well under 
5Mb.

R CMD check in R-devel reports on large packages, and expect in future 
that submitted package sizes will be questioned more often.

There are lots of different reasons why doc directories are large, but 
the major ones are

- installing files that are unneeded, such as Rplots.pdf and .eps
   figures.
- using PDF figures of images where PNG would be more appropriate.
- including less than relevant material (such as how to install R,
   with screenshots!)

There are several ways to reduce the sizes of PDFs with no loss in 
quality, e.g. Adobe Acrobat Standard/Pro.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595
-------------- next part --------------
A non-text attachment was scrubbed...
Name: sizes.png
Type: image/png
Size: 23640 bytes
Desc: 
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110213/4a016436/attachment.png>

From murdoch.duncan at gmail.com  Sun Feb 13 14:30:59 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 13 Feb 2011 08:30:59 -0500
Subject: [Rd] R 2.13.0 on Windows: R CMD check and '"du"' not found
In-Reply-To: <AANLkTinypB_0XrtxrxyK26URcCeUWuMFFFsXKzqa7G1X@mail.gmail.com>
References: <AANLkTinypB_0XrtxrxyK26URcCeUWuMFFFsXKzqa7G1X@mail.gmail.com>
Message-ID: <4D57DD13.9060804@gmail.com>

On 11-02-12 4:57 PM, Henrik Bengtsson wrote:
> FYI, I'm sure the following is a temporary issue, but in case it slips
> through, I want to raise it here.  On Windows 7 64-bit, running Rcmd
> check on R devel gives:

I think you need version r54335 or newer to avoid this error.


>
>   * using R version 2.13.0 Under development (unstable) (2011-02-11 r54330)
> * using platform: x86_64-pc-mingw32 (64-bit)
> * using session charset: ISO8859-1
> * checking for file 'aroma.core/DESCRIPTION' ... OK
> * this is package 'aroma.core' version '1.9.4'
> * checking package dependencies ... OK
> * checking if this is a source package ... OK
> * checking for executable files ... OK
> * checking whether package 'aroma.core' can be installed ... OK
> * checking installed package size ...Error in system2("du", , TRUE,
> TRUE) : '"du"' not found
> Execution halted
>
> That is, the 'du' (disk usage) executable is missing.
>
> I've verified that installing the latest Rtools
> [http://www.murdoch-sutherland.com/Rtools/Rtools212.exe] does not
> solve it (=it does not contain 'du').  BTW, is there a way to know
> when Rtools have been updated relative to the version you already have
> installed?

I usually put news on the page when I update them, but I don't send out 
notices.  Aren't there services to monitor a page and notify you of changes?


>
> /Henrik
>
> PS. Placing the 'du.exe' executable of UnxTools
> (http://sourceforge.net/projects/unxutils/) in the bin/ directory of
> Rtools (e.g. C:/Rtools/bin/) provides a workaround.

I'll see about adding it with the next update.

Duncan Murdoch
>
>
>> sessionInfo()
> R version 2.13.0 Under development (unstable) (2011-02-11 r54330)
> Platform: x86_64-pc-mingw32/x64 (64-bit)
>
> locale:
> [1] LC_COLLATE=English_United States.1252
> [2] LC_CTYPE=English_United States.1252
> [3] LC_MONETARY=English_United States.1252
> [4] LC_NUMERIC=C
> [5] LC_TIME=English_United States.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From p.murrell at auckland.ac.nz  Sun Feb 13 21:53:47 2011
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Mon, 14 Feb 2011 09:53:47 +1300
Subject: [Rd] using rasterImage within image
In-Reply-To: <AANLkTikiFnaCPzBxDdDGV0+jhvo-bwo067Fnx1tSzW3=@mail.gmail.com>
References: <4D51F2A7.8010505@mcmaster.ca>	<D8F5413E-025A-4511-BCE1-7ED06CBE99A0@r-project.org>	<4D52AD7B.6070402@gmail.com>	<E86B0A90-F63F-4537-A7FB-1AA84D685154@r-project.org>	<AANLkTi=yRP56wACtOs+Ouc70EV57rw9RKYmfLAh2hQ8a@mail.gmail.com>	<825F0B1E-EF80-48F5-AFF1-5832092450AB@r-project.org>	<AANLkTi=0K6hCP0tptSf6h4S6au+-SmahDm983zRdZEgb@mail.gmail.com>	<4D531558.7010709@gmail.com>	<AANLkTi=nwF-3UjtoFAaLdTwphmezvuk57HaaJd57=am2@mail.gmail.com>	<AANLkTimHAmzq4CEJF-auHRSA8745x2yb8r_GK9+vTrKJ@mail.gmail.com>	<4D5493BD.4050801@auckland.ac.nz>
	<AANLkTikiFnaCPzBxDdDGV0+jhvo-bwo067Fnx1tSzW3=@mail.gmail.com>
Message-ID: <4D5844DB.4040801@auckland.ac.nz>

Hi

On 12/02/2011 7:22 p.m., Michael Sumner wrote:
> Hello, that appears to have fixed it. Thank you very much.
>
> I can now repeat the reported workflow and the image appears on the
> fifth (and subsequent) calls.

Great. Thanks for checking.

Paul

> Cheers, Mike.
>
>   sessionInfo()
> R version 2.13.0 Under development (unstable) (2011-02-11 r54330)
> Platform: x86_64-pc-mingw32/x64 (64-bit)
>
> locale:
> [1] LC_COLLATE=English_Australia.1252  LC_CTYPE=English_Australia.1252
> [3] LC_MONETARY=English_Australia.1252 LC_NUMERIC=C
> [5] LC_TIME=English_Australia.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> On Fri, Feb 11, 2011 at 12:41 PM, Paul Murrell<p.murrell at auckland.ac.nz>  wrote:
>> Hi
>>
>> Just committed another fix that solves this problem for me at least.  If you
>> want to test for yourself, the magic revision number that you are looking
>> for is r54330.
>>
>> Thanks again for your help.
>>
>> Paul
>>
>> On 10/02/2011 7:54 p.m., Michael Sumner wrote:
>>>
>>> Hello, I'm afraid the SDI graphics issue is still a problem in 2.13.0
>>> 2011-02-09 r54308.
>>>
>>> To reproduce, in a fresh R session (Windows in SDI mode):
>>>
>>> ## create a dummy dataset
>>> m<- matrix(c(0.2, 0.4, 0.6, 0.8), 2, 2)
>>>
>>> ## simple helper function to open the windows() device and plot the matrix
>>> draw.f<- function(x) {
>>>     plot(0, xlim = c(0, 1), ylim = c(0, 1))
>>>     rasterImage(x, 0, 0, 1, 1, interpolate = FALSE)
>>> }
>>>
>>> draw.f(m)
>>>
>>> ## repeat the following 2 lines five times:
>>>
>>> dev.off()
>>> draw.f(m)
>>>
>>> On the fifth attempt, only the background plot appears - but the
>>> raster is visible on resize of the windows() device.
>>>
>>> Cheers, Mike.
>>>
>>> sessionInfo()
>>> R version 2.13.0 Under development (unstable) (2011-02-09 r54308)
>>> Platform: x86_64-pc-mingw32/x64 (64-bit)
>>>
>>> locale:
>>> [1] LC_COLLATE=English_Australia.1252  LC_CTYPE=English_Australia.1252
>>> [3] LC_MONETARY=English_Australia.1252 LC_NUMERIC=C
>>> [5] LC_TIME=English_Australia.1252
>>>
>>> attached base packages:
>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>
>>>
>>>
>>> On Thu, Feb 10, 2011 at 5:31 PM, baptiste auguie
>>> <baptiste.auguie at googlemail.com>    wrote:
>>>>
>>>> Dear all,
>>>>
>>>> Back when grid.raster() was introduced, it was suggested that perhaps
>>>> grid.rect() could use grid.raster() in case of even spacing. The
>>>> response at the time was that it would be best to keep the two
>>>> functions separate at a lower level, that is grid.rect() and
>>>> grid.raster(), but perhaps a new function grid.image() could be
>>>> proposed at a higher level with the two possible backends. If this is
>>>> done in grid graphics, perhaps the same convention could be used for
>>>> base graphics: image() would be high level with the backend option,
>>>> and a new function ("tiles()", perhaps?) would implement the current
>>>> behavior of image().
>>>>
>>>> In any case, it would be nice to have a unified scheme to switch
>>>> between "tiles" and raster; currently lattice (panl.levelplot.raster)
>>>> and a few other packages all do it separately.
>>>>
>>>> Best wishes,
>>>>
>>>> baptiste
>>>>
>>>>
>>>>
>>>> On 9 February 2011 23:29, Ben Bolker<bbolker at gmail.com>    wrote:
>>>>>
>>>>> -----BEGIN PGP SIGNED MESSAGE-----
>>>>> Hash: SHA1
>>>>>
>>>>> On 11-02-09 03:09 PM, Henrik Bengtsson wrote:
>>>>>>
>>>>>> On Wed, Feb 9, 2011 at 11:53 AM, Simon Urbanek
>>>>>> <simon.urbanek at r-project.org>    wrote:
>>>>>>>
>>>>>>> On Feb 9, 2011, at 2:36 PM, Henrik Bengtsson wrote:
>>>>>>>
>>>>>>>> On Wed, Feb 9, 2011 at 11:25 AM, Simon Urbanek
>>>>>>>> <simon.urbanek at r-project.org>    wrote:
>>>>>>>>>
>>>>>>>>> Ben,
>>>>>>>>>
>>>>>>>>> I have committed something analogous to R-devel (your rotation
>>>>>>>>> code was not unlike mine, I replicated the color handling from
>>>>>>>>> R internals to be consistent, I fixed the drawing limits and
>>>>>>>>> added a check for x/y conformance). Note that useRaster can
>>>>>>>>> only be used when x, y form a regular grid. Although I tried a
>>>>>>>>> lot of corner cases (requiring quite a few fixes), I'm sure I
>>>>>>>>> did not test all of them, so volunteers please give it a go and
>>>>>>>>> compare it with non-raster output.
>>>>>>>>>
>>>>>>>>> The only thing I'm not quite happy about is the argument name:
>>>>>>>>> useRaster. Personally, I hate camel case in R (it has crept in
>>>>>>>>> more recently making it horribly inconsistent) so please feel
>>>>>>>>> free to suggest a better name ;).
>>>>>>>>
>>>>>>>> It.is.spelled.camelCase.
>>>>>>>>
>>>>>>>
>>>>>>> Fortunately not in English ;)
>>>>>>>
>>>>>>>
>>>>>>>> What about style=c("image", "raster")?  This allows for future
>>>>>>>> extensions too.
>>>>>>>>
>>>>>>>
>>>>>>> Hmm.. it's not really a "style" - the output doesn't change
>>>>>>> (ideally) - it's more of a back-end specification .. also we
>>>>>>> already have oldstyle argument in image() adding to the confusion
>>>>>>> ...
>>>>>>
>>>>>> flavor=c("image", "raster") renderer=c("image", "raster")
>>>>>> backend=c("image", "raster") ...
>>>>>
>>>>>   Thanks Simon! (Any reports on the SDI Windows raster rendering issue,
>>>>> or do we need a warning/workaround there?)
>>>>>
>>>>>   I like "backend", or possibly "method"
>>>>>
>>>>>   One minor consideration: if "raster" eventually becomes the default
>>>>> (as I hope it will), there would need to be some internal logic that
>>>>> drops back to "image" if the user specifies uneven spacing and doesn't
>>>>> explicitly specify the 'backend/method' parameter ...
>>>>> -----BEGIN PGP SIGNATURE-----
>>>>> Version: GnuPG v1.4.10 (GNU/Linux)
>>>>> Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org/
>>>>>
>>>>> iEYEARECAAYFAk1TFVcACgkQc5UpGjwzenOa6ACfVnJq67cG0czATeyti7AxgUbw
>>>>> ZWwAniA7JuYCv4clq8e6jwWQuMvw/r+m
>>>>> =/da6
>>>>> -----END PGP SIGNATURE-----
>>>>>
>>>>> ______________________________________________
>>>>> R-devel at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>>
>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>
>>>
>>>
>>>
>>
>> --
>> Dr Paul Murrell
>> Department of Statistics
>> The University of Auckland
>> Private Bag 92019
>> Auckland
>> New Zealand
>> 64 9 3737599 x85392
>> paul at stat.auckland.ac.nz
>> http://www.stat.auckland.ac.nz/~paul/
>>
>
>
>

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/


From xie at yihui.name  Sun Feb 13 22:02:32 2011
From: xie at yihui.name (Yihui Xie)
Date: Sun, 13 Feb 2011 15:02:32 -0600
Subject: [Rd] CRAN package sizes
In-Reply-To: <alpine.OSX.1.00.1102131203050.44163@tystie.local>
References: <alpine.OSX.1.00.1102131203050.44163@tystie.local>
Message-ID: <AANLkTin5vM8C+7w-PDzVWdRA67WNbXxH3MqMjbxd1HSs@mail.gmail.com>

Regarding the reasons that make the doc directory large, I wonder if
we can make some changes in R:

1. Use a null graphics device as the default device rather than pdf()
when running Sweave -- this can avoid the useless Rplots.pdf:

options(device = function(...) {
    .Call("R_GD_nullDevice", PACKAGE = "grDevices")
})

This can save some time in building the vignette(s) as well. (see
http://yihui.name/en/?p=673)

However, this undocumented null device may not work for certain
graphics. Here is an example that it fails for ggplot2:
http://stackoverflow.com/questions/4692974/ggplot2-code-that-works-interactively-rkward-crashes-under-lyx-pgfsweave-hint/4707745#4707745

Is it possible for someone to look into the null device (Dr Murrell?)
to make it stable enough?

2. Compress the PDF graphics and vignettes using third-party tools,
among which I recommend qpdf (it's free).

qpdf --stream-data=compress input.pdf output.pdf

This can reduce the size of PDF files a lot without quality loss. I'm
using this tool in the animation package to reduce the size of PDF
animations.

3. Sorry I bring up this issue again, but I don't understand why
Sweave could not implement the png() device along with pdf() and
postscript(). I'm willing to provide a patch if needed.

Thanks!

Regards,
Yihui
--
Yihui Xie <xieyihui at gmail.com>
Phone: 515-294-2465 Web: http://yihui.name
Department of Statistics, Iowa State University
2215 Snedecor Hall, Ames, IA



On Sun, Feb 13, 2011 at 6:30 AM, Prof Brian Ripley
<ripley at stats.ox.ac.uk> wrote:
> Robin Hankin's post reminded me to post about the following recent addition
> to 'Writing R Extensions', in the section on 'Submitting a package to CRAN'
>
> ?Ensure that the package sources are not unnecessarily large. ...
> ?As a general rule, doc directories should not exceed 5Mb, and
> ?where data directories need to be 10Mb or more, consideration should
> ?be given to a separate package containing just the data. (Similarly
> ?for external data directories, large jar files and other libraries
> ?that need to be installed.)
>
> With 2800 packages on CRAN, overall size is becoming a concern and currently
> to install all of CRAN takes 4Gb. ?As the attached (I hope) graph shows, the
> 20 packages over 20Mb take a quarter, and those over 5Mb take half. ?(And
> this is after we have removed 100Mb from the largest installed package by
> re-compression, and archived the second largest, so Robin's package is
> currently the largest.) ?Some of the largest packages are data/jar packages,
> but there are 55 packages with 'doc' directories over 5Mb. ?To put that in
> perspective, PDFs of whole books with lots of figures (MASS, Paul's R
> Graphics) are well under 5Mb.
>
> R CMD check in R-devel reports on large packages, and expect in future that
> submitted package sizes will be questioned more often.
>
> There are lots of different reasons why doc directories are large, but the
> major ones are
>
> - installing files that are unneeded, such as Rplots.pdf and .eps
> ?figures.
> - using PDF figures of images where PNG would be more appropriate.
> - including less than relevant material (such as how to install R,
> ?with screenshots!)
>
> There are several ways to reduce the sizes of PDFs with no loss in quality,
> e.g. Adobe Acrobat Standard/Pro.
>
> --
> Brian D. Ripley, ? ? ? ? ? ? ? ? ?ripley at stats.ox.ac.uk
> Professor of Applied Statistics, ?http://www.stats.ox.ac.uk/~ripley/
> University of Oxford, ? ? ? ? ? ? Tel: ?+44 1865 272861 (self)
> 1 South Parks Road, ? ? ? ? ? ? ? ? ? ? +44 1865 272866 (PA)
> Oxford OX1 3TG, UK ? ? ? ? ? ? ? ?Fax: ?+44 1865 272595
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From takeo.katsuki at gmail.com  Sun Feb 13 19:18:31 2011
From: takeo.katsuki at gmail.com (TakeoKatsuki)
Date: Sun, 13 Feb 2011 10:18:31 -0800 (PST)
Subject: [Rd] Suggestion: Adding quick rowMin and rowMax functions to
 base package
In-Reply-To: <59d7961d1003300133g1fdff6fdg7322b26d8ee896f4@mail.gmail.com>
References: <4BB100E0.3010201@uni-bonn.de>
	<59d7961d1003300133g1fdff6fdg7322b26d8ee896f4@mail.gmail.com>
Message-ID: <1297621111442-3303893.post@n4.nabble.com>


Hi Henrik,

It would be nice if functions of the matrixStats package can handle array
data.
For example, rowSums() of the base package sums along the third axis of an
array by rowSums(x, dim=2).
Thanks.

Takeo


Henrik Bengtsson wrote:
> 
> See rowMins(), rowMaxs() and rowRanges() in matrixStats (on CRAN).
> 
> The matrixStats package was created for the purpose of providing such
> row*/col*() methods.  First the functionality is provided, then the
> methods are optimized for speed and memory, e.g. vectorizing,
> implementing in native code, and utilizing other fast existing
> functions.  Some methods have already been optimized this way.  When
> mature, these may be suggested to be part of the default R
> distribution.
> 
> Benchmarking reports, and contributions of code and redundancy are
> welcome.  Testing the code under many different conditions is
> critical, e.g. missing values or not, infinite values or not, zero,
> one or many columns/rows, ...
> 
> /Henrik
> 
> PS. The rowMaxs() etc does not utilize pmax(); didn't know of it.
> 
> 
> On Mon, Mar 29, 2010 at 9:34 PM, Sebastian Kranz <skranz at uni-bonn.de>
> wrote:
>> Hi,
>>
>> I wonder whether similarly to the very quick rowSums and colSums
>> functions
>> in the base package, one could add quick functions that calculate the min
>> or
>> max over rows / cols in a matrix. While apply(x,1,min) works, I found out
>> by
>> profiling a program of mine that it is rather slow for matrices with a
>> very
>> large number of rows. A quick functionality seems to be already there in
>> the
>> functions pmax and pmin, but it is rather cumbersume to apply them to all
>> columns of a matrix (if one does not know how many columns the matrix
>> has).
>> ?Below, I have some code that shows a very unelegant implementation that
>> illustrates possible speed gains if apply could be avoided:
>>
>> rowMin = function(x) {
>> ? # Construct a call pmin(x[,1],x[,2],...x[,NCOL(x)])
>> ? ?code = paste("x[,",1:(NCOL(x)),"]",sep="",collapse=",")
>> ? ?code = paste("pmin(",code,")")
>> ? ?return(eval(parse(text=code)))
>> }
>>
>> # Speed comparison: Taking rowMin of a 1,000,000 x 10 matrix
>> x = matrix(rnorm(1e7),1e6,10)
>>
>> # The traditional apply method
>> y=apply(x,1,min) # Runtime ca. 12 seconds
>>
>> # My unelegant rowMin function
>> z=rowMin(x) # Runtime ca 0.5 seconds
>>
>> Of course, the way the function rowMin is constructed is highly
>> ineffective
>> if the matrix x has many columns, but maybe there is a simple way to
>> adapt
>> the code from pmin and pmax to create quick rowMin, rowMax,... functions.
>> I
>> don't know whether it is worth the effort, but I guess taking minima and
>> maxima over rows is a common task.
>>
>> Best wishes,
>> Sebastian
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 

-- 
View this message in context: http://r.789695.n4.nabble.com/Suggestion-Adding-quick-rowMin-and-rowMax-functions-to-base-package-tp1744761p3303893.html
Sent from the R devel mailing list archive at Nabble.com.


From hb at biostat.ucsf.edu  Mon Feb 14 02:19:48 2011
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Sun, 13 Feb 2011 17:19:48 -0800
Subject: [Rd] Wish: Iterate over any data type/object 'xs' in for (x in xs)
	{ ... }
Message-ID: <AANLkTi=yKaEA4vv-vymcoWHQmgL8+JiCVZUp2h5C7B81@mail.gmail.com>

Hi,

this is about iterating over any data type/object 'xs' in the for-loop
constructor:

  for (x in xs) { ... }

>From help("for"), on can read that 'xs' has to be "An expression
evaluating to a vector (including a list and an expression) or to a
pairlist or NULL. A factor value will be coerced to a character
vector".

If you have a data type/class that contains items that you wish to
iterate over, you could write a as.sequence() method that returns a
vector to iterate over, e.g.

for (x in as.sequence(xs)) {
  print(x);
}

For cases where 'xs' in for (x in xs) { ... } is not a vector (or a
pairlist or NULL), would it be possible to extend R such that it
automatically do the above?

Here is an example based on an S3 class illustrating this:

Letter <- function(i) {
  structure(i, class="Letter");
}

as.character.Letter <- function(x, ...) {
  base::letters[x];
}

print.Letter <- function(x, ...) {
  print(sprintf("Letter: %s", as.character(x)), ...);
}

Letters <- function(n) {
  res <- structure(NA, class="Letters");
  attr(res, "items") <- lapply(1:n, FUN=Letter);
  res;
}

as.sequence.Letters <- function(x, ...) { attr(x, "items"); }
as.sequence <- function(x, ...) UseMethod("as.sequence");


xs <- Letters(5);
for (x in as.sequence(xs)) {
  print(x);
}

[1] "Letter: a"
[1] "Letter: b"
[1] "Letter: c"
[1] "Letter: d"
[1] "Letter: e"


What would be really nice is if one could just do:

for (x in xs) {
  print(x);
}

[1] NA


I'm sure this is way more complicated than I anticipate (e.g. for() is
language construct), but I'd though it's worth throwing it out there.


/Henrik


From spinuvit.list at gmail.com  Mon Feb 14 14:40:39 2011
From: spinuvit.list at gmail.com (Vitalie S.)
Date: Mon, 14 Feb 2011 14:40:39 +0100
Subject: [Rd] getGenerics returns names what are not generics
Message-ID: <cpnpqquhgyw.fsf@gmail.com>


Hi there,

I encounter the following problem with getGenerics
when Rgraphviz is installed:

which(!sapply(getGenerics(), isGeneric))
#graph Rgraphviz     graph Rgraphviz 
#  105       106       107       108

so, getGenerics returns twice graph and Rgrapviz as being generics, when they
are not:

isGeneric("graph")
#FALSE


Best,
Vitalie.

R version 2.13.0 Under development (unstable) (2011-02-11 r54330)
Platform: i386-pc-mingw32/i386 (32-bit)

locale:
[1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United States.1252    LC_MONETARY=English_United States.1252 LC_NUMERIC=C                          
[5] LC_TIME=English_United States.1252    

attached base packages:
[1] grid      stats     datasets  grDevices utils     graphics  methods   base     

other attached packages:
[1] Rgraphviz_1.29.0 graph_1.28.0    

loaded via a namespace (and not attached):
[1] tools_2.13.0


From ivo.welch at gmail.com  Mon Feb 14 14:54:43 2011
From: ivo.welch at gmail.com (ivo welch)
Date: Mon, 14 Feb 2011 08:54:43 -0500
Subject: [Rd] small suggestion---add sd to summary() for vectors, matrices,
 and data frames
Message-ID: <AANLkTinkwvnfm1OUM50-6EqjdLLNpCF2PEnEfvPFb1C+@mail.gmail.com>

Dear R developers---of course, I have my own function that does this,
but I think this would be useful for others, too.  summary() already
returns the first moment, and I would hope most of us think of the
standard deviation as a pretty common summary statistic.

not to clutter this mailing list, but it would also be useful to have
an optional parameter that creates a different type of output,
stacking the univariate outputs, along the lines of
    for (i in 1:ncol(d))  cat(names(d)[i], summary(d[i]), "\n")
of course, both of these suggestions may be useful but are not necessary.

my biggest suggestion is still to issue an "ambiguity warning" when
"<-[0-9]" is encountered, suggesting to users either to use '<-[
][0-9]' or '<[ ]-[0-9]' spacing for disambiguation.  this would help a
lot of my students who are newcomers.

regards,

/iaw
----
Ivo Welch (ivo.welch at brown.edu, ivo.welch at gmail.com)


From kevin.r.coombes at gmail.com  Mon Feb 14 15:52:26 2011
From: kevin.r.coombes at gmail.com (Kevin R. Coombes)
Date: Mon, 14 Feb 2011 08:52:26 -0600
Subject: [Rd] CRAN package sizes
In-Reply-To: <AANLkTin5vM8C+7w-PDzVWdRA67WNbXxH3MqMjbxd1HSs@mail.gmail.com>
References: <alpine.OSX.1.00.1102131203050.44163@tystie.local>
	<AANLkTin5vM8C+7w-PDzVWdRA67WNbXxH3MqMjbxd1HSs@mail.gmail.com>
Message-ID: <4D5941AA.8020504@gmail.com>

I think it would be even more useful if we could get Sweave to easily 
produce PNG figures instead of just PDF/EPS.  In the current state of 
things, making PNG versions is more cumbersome than making PDF versions, 
so I'm not surprised that most people don't go to that trouble most of 
the time.

I also know (from searching the archives when I wanted to try this 
myself) that a couple of people have, in the past, modified Sweave so it 
can generate PNG automatically.  However, the changes have never 
migrated into the released version.  Perhaps the space constraints at 
CRAN can convince Freidrich Leisch that the change would be a good idea....

     Kevin

On 2/13/2011 3:02 PM, Yihui Xie wrote:
> Regarding the reasons that make the doc directory large, I wonder if
> we can make some changes in R:
>
> 1. Use a null graphics device as the default device rather than pdf()
> when running Sweave -- this can avoid the useless Rplots.pdf:
>
> options(device = function(...) {
>      .Call("R_GD_nullDevice", PACKAGE = "grDevices")
> })
>
> This can save some time in building the vignette(s) as well. (see
> http://yihui.name/en/?p=673)
>
> However, this undocumented null device may not work for certain
> graphics. Here is an example that it fails for ggplot2:
> http://stackoverflow.com/questions/4692974/ggplot2-code-that-works-interactively-rkward-crashes-under-lyx-pgfsweave-hint/4707745#4707745
>
> Is it possible for someone to look into the null device (Dr Murrell?)
> to make it stable enough?
>
> 2. Compress the PDF graphics and vignettes using third-party tools,
> among which I recommend qpdf (it's free).
>
> qpdf --stream-data=compress input.pdf output.pdf
>
> This can reduce the size of PDF files a lot without quality loss. I'm
> using this tool in the animation package to reduce the size of PDF
> animations.
>
> 3. Sorry I bring up this issue again, but I don't understand why
> Sweave could not implement the png() device along with pdf() and
> postscript(). I'm willing to provide a patch if needed.
>
> Thanks!
>
> Regards,
> Yihui
> --
> Yihui Xie<xieyihui at gmail.com>
> Phone: 515-294-2465 Web: http://yihui.name
> Department of Statistics, Iowa State University
> 2215 Snedecor Hall, Ames, IA
>
>
>
> On Sun, Feb 13, 2011 at 6:30 AM, Prof Brian Ripley
> <ripley at stats.ox.ac.uk>  wrote:
>> Robin Hankin's post reminded me to post about the following recent addition
>> to 'Writing R Extensions', in the section on 'Submitting a package to CRAN'
>>
>>   Ensure that the package sources are not unnecessarily large. ...
>>   As a general rule, doc directories should not exceed 5Mb, and
>>   where data directories need to be 10Mb or more, consideration should
>>   be given to a separate package containing just the data. (Similarly
>>   for external data directories, large jar files and other libraries
>>   that need to be installed.)
>>
>> With 2800 packages on CRAN, overall size is becoming a concern and currently
>> to install all of CRAN takes 4Gb.  As the attached (I hope) graph shows, the
>> 20 packages over 20Mb take a quarter, and those over 5Mb take half.  (And
>> this is after we have removed 100Mb from the largest installed package by
>> re-compression, and archived the second largest, so Robin's package is
>> currently the largest.)  Some of the largest packages are data/jar packages,
>> but there are 55 packages with 'doc' directories over 5Mb.  To put that in
>> perspective, PDFs of whole books with lots of figures (MASS, Paul's R
>> Graphics) are well under 5Mb.
>>
>> R CMD check in R-devel reports on large packages, and expect in future that
>> submitted package sizes will be questioned more often.
>>
>> There are lots of different reasons why doc directories are large, but the
>> major ones are
>>
>> - installing files that are unneeded, such as Rplots.pdf and .eps
>>   figures.
>> - using PDF figures of images where PNG would be more appropriate.
>> - including less than relevant material (such as how to install R,
>>   with screenshots!)
>>
>> There are several ways to reduce the sizes of PDFs with no loss in quality,
>> e.g. Adobe Acrobat Standard/Pro.
>>
>> --
>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>> University of Oxford,             Tel:  +44 1865 272861 (self)
>> 1 South Parks Road,                     +44 1865 272866 (PA)
>> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From jorismeys at gmail.com  Mon Feb 14 16:05:40 2011
From: jorismeys at gmail.com (Joris Meys)
Date: Mon, 14 Feb 2011 16:05:40 +0100
Subject: [Rd] readPNG gives warnings and doesn't execute sample code from
	help files
Message-ID: <AANLkTinVuFBRCoHHjQ_fAF5BXFFQ+sQPm7-Yq79MtqOL@mail.gmail.com>

Dear all,

I noticed in the latest R version (R.2.12.1) that the readPNG gives
following warning when running the example code in the help file (or
when using any other png for that matter) :

50: In rasterImage(img, 1.2, 1.27, 1.8, 1.73) :
  Per-pixel alpha not supported on this device

No picture is shown, and code I used to be able to run, doesn't run any more.

> sessionInfo()
R version 2.12.1 (2010-12-16)
Platform: i386-pc-mingw32/i386 (32-bit)

locale:
[1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United
States.1252    LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C                           LC_TIME=English_United
States.1252

attached base packages:
[1] grDevices datasets  splines   graphics  stats     tcltk     utils
   methods   base

other attached packages:
[1] png_0.1-2       svSocket_0.9-51 TinnR_1.0.3     R2HTML_2.2
Hmisc_3.8-3     survival_2.36-2

loaded via a namespace (and not attached):
[1] cluster_1.13.2  grid_2.12.1     lattice_0.19-13 svMisc_0.9-61
tools_2.12.1


-- 
Joris Meys
Statistical consultant

Ghent University
Faculty of Bioscience Engineering
Department of Applied mathematics, biometrics and process control

tel : +32 9 264 59 87
Joris.Meys at Ugent.be
-------------------------------
Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php


From Simon.Urbanek at r-project.org  Mon Feb 14 17:30:57 2011
From: Simon.Urbanek at r-project.org (Simon Urbanek)
Date: Mon, 14 Feb 2011 11:30:57 -0500
Subject: [Rd] readPNG gives warnings and doesn't execute sample code
	from help files
In-Reply-To: <AANLkTinVuFBRCoHHjQ_fAF5BXFFQ+sQPm7-Yq79MtqOL@mail.gmail.com>
References: <AANLkTinVuFBRCoHHjQ_fAF5BXFFQ+sQPm7-Yq79MtqOL@mail.gmail.com>
Message-ID: <C425001D-55D4-4411-BAE2-8308E76E310B@r-project.org>

Joris,

On Feb 14, 2011, at 10:05 AM, Joris Meys wrote:

> Dear all,
> 
> I noticed in the latest R version (R.2.12.1) that the readPNG gives
> following warning when running the example code in the help file (or
> when using any other png for that matter) :
> 
> 50: In rasterImage(img, 1.2, 1.27, 1.8, 1.73) :
>  Per-pixel alpha not supported on this device
> 
> No picture is shown, and code I used to be able to run, doesn't run any more.
> 

You may want to use a device that supports alpha. The R logo in the example uses alpha so are probably the images you are using. If you don't want to (or can't) use a device that supports alpha, you'll have to flatten the alpha, - i.e. plot just img[,,1:3]
However, most images don't have color where alpha is zero, so you'll have to replace it with the background color, e.g.:
r = as.raster(img[,,1:3])
r[img[,,4] == 0] = "white"

Cheers,
Simon



>> sessionInfo()
> R version 2.12.1 (2010-12-16)
> Platform: i386-pc-mingw32/i386 (32-bit)
> 
> locale:
> [1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United
> States.1252    LC_MONETARY=English_United States.1252
> [4] LC_NUMERIC=C                           LC_TIME=English_United
> States.1252
> 
> attached base packages:
> [1] grDevices datasets  splines   graphics  stats     tcltk     utils
>   methods   base
> 
> other attached packages:
> [1] png_0.1-2       svSocket_0.9-51 TinnR_1.0.3     R2HTML_2.2
> Hmisc_3.8-3     survival_2.36-2
> 
> loaded via a namespace (and not attached):
> [1] cluster_1.13.2  grid_2.12.1     lattice_0.19-13 svMisc_0.9-61
> tools_2.12.1
> 
> 
> -- 
> Joris Meys
> Statistical consultant
> 
> Ghent University
> Faculty of Bioscience Engineering
> Department of Applied mathematics, biometrics and process control
> 
> tel : +32 9 264 59 87
> Joris.Meys at Ugent.be
> -------------------------------
> Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php
> 
> 


From bbolker at gmail.com  Mon Feb 14 18:26:20 2011
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 14 Feb 2011 17:26:20 +0000
Subject: [Rd] using rasterImage within image
References: <4D51F2A7.8010505@mcmaster.ca>	<D8F5413E-025A-4511-BCE1-7ED06CBE99A0@r-project.org>	<4D52AD7B.6070402@gmail.com>	<E86B0A90-F63F-4537-A7FB-1AA84D685154@r-project.org>	<AANLkTi=yRP56wACtOs+Ouc70EV57rw9RKYmfLAh2hQ8a@mail.gmail.com>	<825F0B1E-EF80-48F5-AFF1-5832092450AB@r-project.org>	<AANLkTi=0K6hCP0tptSf6h4S6au+-SmahDm983zRdZEgb@mail.gmail.com>	<4D531558.7010709@gmail.com>	<AANLkTi=nwF-3UjtoFAaLdTwphmezvuk57HaaJd57=am2@mail.gmail.com>	<AANLkTimHAmzq4CEJF-auHRSA8745x2yb8r_GK9+vTrKJ@mail.gmail.com>	<4D5493BD.4050801@auckland.ac.nz>
	<AANLkTikiFnaCPzBxDdDGV0+jhvo-bwo067Fnx1tSzW3=@mail.gmail.com>
	<4D5844DB.4040801@auckland.ac.nz>
Message-ID: <loom.20110214T182423-339@post.gmane.org>

Paul Murrell <p.murrell <at> auckland.ac.nz> writes:

> 
> Hi
> 
> On 12/02/2011 7:22 p.m., Michael Sumner wrote:
> > Hello, that appears to have fixed it. Thank you very much.
> >
> > I can now repeat the reported workflow and the image appears on the
> > fifth (and subsequent) calls.
> 
> Great. Thanks for checking.
> 
> Paul
> 


  That's great.

  Just a little bump: I would encourage Simon (in his copious spare
time), or other interested members of R-core, to decide on a good
name for the argument (as a reminder, I prefer 'method=c("raster","image")').
Furthermore, I would strongly encourage that "raster" be made the default
behavior for the development release of R ...

  cheers
    Ben Bolker


From hangphan at gmail.com  Mon Feb 14 18:40:29 2011
From: hangphan at gmail.com (Hang PHAN)
Date: Mon, 14 Feb 2011 17:40:29 +0000
Subject: [Rd] R command line and pipe using in Linux?
Message-ID: <AANLkTimNYYpwWJDiNxhxq+Ay-i8DmqQU=H5dLE9gxRVR@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110214/23ec0ee4/attachment.pl>

From baptiste.auguie at googlemail.com  Mon Feb 14 18:44:10 2011
From: baptiste.auguie at googlemail.com (baptiste auguie)
Date: Mon, 14 Feb 2011 18:44:10 +0100
Subject: [Rd] using rasterImage within image
In-Reply-To: <loom.20110214T182423-339@post.gmane.org>
References: <4D51F2A7.8010505@mcmaster.ca>
	<D8F5413E-025A-4511-BCE1-7ED06CBE99A0@r-project.org>
	<4D52AD7B.6070402@gmail.com>
	<E86B0A90-F63F-4537-A7FB-1AA84D685154@r-project.org>
	<AANLkTi=yRP56wACtOs+Ouc70EV57rw9RKYmfLAh2hQ8a@mail.gmail.com>
	<825F0B1E-EF80-48F5-AFF1-5832092450AB@r-project.org>
	<AANLkTi=0K6hCP0tptSf6h4S6au+-SmahDm983zRdZEgb@mail.gmail.com>
	<4D531558.7010709@gmail.com>
	<AANLkTi=nwF-3UjtoFAaLdTwphmezvuk57HaaJd57=am2@mail.gmail.com>
	<AANLkTimHAmzq4CEJF-auHRSA8745x2yb8r_GK9+vTrKJ@mail.gmail.com>
	<4D5493BD.4050801@auckland.ac.nz>
	<AANLkTikiFnaCPzBxDdDGV0+jhvo-bwo067Fnx1tSzW3=@mail.gmail.com>
	<4D5844DB.4040801@auckland.ac.nz>
	<loom.20110214T182423-339@post.gmane.org>
Message-ID: <AANLkTi=Fjo8F=rcwiGEuO5GNSeS+KWhqmiWtdCUX9QFM@mail.gmail.com>

On 14 February 2011 18:26, Ben Bolker <bbolker at gmail.com> wrote:
> Paul Murrell <p.murrell <at> auckland.ac.nz> writes:
>
>>
>> Hi
>>
>> On 12/02/2011 7:22 p.m., Michael Sumner wrote:
>> > Hello, that appears to have fixed it. Thank you very much.
>> >
>> > I can now repeat the reported workflow and the image appears on the
>> > fifth (and subsequent) calls.
>>
>> Great. Thanks for checking.
>>
>> Paul
>>
>
>
> ?That's great.
>
> ?Just a little bump: I would encourage Simon (in his copious spare
> time), or other interested members of R-core, to decide on a good
> name for the argument (as a reminder, I prefer 'method=c("raster","image")').
> Furthermore, I would strongly encourage that "raster" be made the default
> behavior for the development release of R ...

Seconded.

Also, I haven't had any comment on my suggestion, so I was wondering
if Grid graphics are meant to be left out of this question. Having
each package that uses Grid graphics implement its own version of
imageGrob() (e.g. lattice, ggplot2, RGraphics, gridExtra) with
optional use of raster format is probably not a very desirable
situation.

Best regards,

baptiste


>
> ?cheers
> ? ?Ben Bolker
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From seanpor at acm.org  Mon Feb 14 18:51:02 2011
From: seanpor at acm.org (Sean O'Riordain)
Date: Mon, 14 Feb 2011 17:51:02 +0000
Subject: [Rd] R command line and pipe using in Linux?
In-Reply-To: <AANLkTimNYYpwWJDiNxhxq+Ay-i8DmqQU=H5dLE9gxRVR@mail.gmail.com>
References: <AANLkTimNYYpwWJDiNxhxq+Ay-i8DmqQU=H5dLE9gxRVR@mail.gmail.com>
Message-ID: <AANLkTimKTD=C2Z_WwYp86ig8gE47eLSonLoXnm3QdKX2@mail.gmail.com>

Good afternoon Hang,

This is an example of what I've done with a csv file with a header
which is too big to read into memory.

# this is a file with about 50 columns and 28 million records
ap.fnam <- 'p2_all28m_records.csv'
# lets just explore the columns in Addresspoint...
# by reading in the header and the first row
p1 <- read.csv(ap.fnam, nrows=1)

# now which columns do we actually want?
# ok... in this case we only want the NCAT column...
cols.reqd <- grep('NCAT', names(p1))
# so we create a list containing this/these column(s) as a 'character'
# type and all other columns as 'NULL'...
col.classes <- ifelse(seq(ncol(p1)) %in% cols.reqd, 'character', 'NULL')

# this will likely take a little over a minute!
p9 <- read.csv(ap.fnam, colClasses=col.classes )

Hope this helps

Kind regards,
Sean

On 14 February 2011 17:40, Hang PHAN <hangphan at gmail.com> wrote:
> Hi,
> I have a very large data file(GB) from which I only want to extract one
> column to draw histogram. This would be done several times, so I would like
> to ask if there is anyway to plot this using R from the linux command line,
> something look like this
>
> cut -f1 xxx.txt |RplotHist ....
>
> Thanks and hope to hear from you.
> Best regards,
> Hang
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From edd at debian.org  Mon Feb 14 19:30:48 2011
From: edd at debian.org (Dirk Eddelbuettel)
Date: Mon, 14 Feb 2011 12:30:48 -0600
Subject: [Rd] R command line and pipe using in Linux?
In-Reply-To: <AANLkTimNYYpwWJDiNxhxq+Ay-i8DmqQU=H5dLE9gxRVR@mail.gmail.com>
References: <AANLkTimNYYpwWJDiNxhxq+Ay-i8DmqQU=H5dLE9gxRVR@mail.gmail.com>
Message-ID: <19801.29912.853582.36706@max.nulle.part>


On 14 February 2011 at 17:40, Hang PHAN wrote:
| Hi,
| I have a very large data file(GB) from which I only want to extract one
| column to draw histogram. This would be done several times, so I would like
| to ask if there is anyway to plot this using R from the linux command line,
| something look like this
| 
| cut -f1 xxx.txt |RplotHist ....

Have a look at littler which was written with these uses in mind:

   http://dirk.eddelbuettel.com/code/littler.html

It includes a few examples which should get you going. Also, in
non-interactive mode, your plot device will have to a file.

Hope this helps, Dirk

-- 
Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com


From savicky at cs.cas.cz  Mon Feb 14 19:36:44 2011
From: savicky at cs.cas.cz (Petr Savicky)
Date: Mon, 14 Feb 2011 19:36:44 +0100
Subject: [Rd] R command line and pipe using in Linux?
In-Reply-To: <AANLkTimNYYpwWJDiNxhxq+Ay-i8DmqQU=H5dLE9gxRVR@mail.gmail.com>
References: <AANLkTimNYYpwWJDiNxhxq+Ay-i8DmqQU=H5dLE9gxRVR@mail.gmail.com>
Message-ID: <20110214183644.GB25057@cs.cas.cz>

On Mon, Feb 14, 2011 at 05:40:29PM +0000, Hang PHAN wrote:
> Hi,
> I have a very large data file(GB) from which I only want to extract one
> column to draw histogram. This would be done several times, so I would like
> to ask if there is anyway to plot this using R from the linux command line,
> something look like this
> 
> cut -f1 xxx.txt |RplotHist ....

Hi Hang:

Can you use something like the following?

  x <- as.numeric(system("cut -f1 xxx.txt", intern=TRUE))

According to ?system, long lines will be split, however, no limit
on the number of lines of the output is formulated there.

Petr Savicky.


From simon.urbanek at r-project.org  Mon Feb 14 20:11:21 2011
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Mon, 14 Feb 2011 14:11:21 -0500
Subject: [Rd] using rasterImage within image
In-Reply-To: <loom.20110214T182423-339@post.gmane.org>
References: <4D51F2A7.8010505@mcmaster.ca>	<D8F5413E-025A-4511-BCE1-7ED06CBE99A0@r-project.org>	<4D52AD7B.6070402@gmail.com>	<E86B0A90-F63F-4537-A7FB-1AA84D685154@r-project.org>	<AANLkTi=yRP56wACtOs+Ouc70EV57rw9RKYmfLAh2hQ8a@mail.gmail.com>	<825F0B1E-EF80-48F5-AFF1-5832092450AB@r-project.org>	<AANLkTi=0K6hCP0tptSf6h4S6au+-SmahDm983zRdZEgb@mail.gmail.com>	<4D531558.7010709@gmail.com>	<AANLkTi=nwF-3UjtoFAaLdTwphmezvuk57HaaJd57=am2@mail.gmail.com>	<AANLkTimHAmzq4CEJF-auHRSA8745x2yb8r_GK9+vTrKJ@mail.gmail.com>	<4D5493BD.4050801@auckland.ac.nz>
	<AANLkTikiFnaCPzBxDdDGV0+jhvo-bwo067Fnx1tSzW3=@mail.gmail.com>
	<4D5844DB.4040801@auckland.ac.nz>
	<loom.20110214T182423-339@post.gmane.org>
Message-ID: <058A2CD6-E303-4ABD-AD16-23E82F8513A0@r-project.org>


On Feb 14, 2011, at 12:26 PM, Ben Bolker wrote:

> Paul Murrell <p.murrell <at> auckland.ac.nz> writes:
> 
>> 
>> Hi
>> 
>> On 12/02/2011 7:22 p.m., Michael Sumner wrote:
>>> Hello, that appears to have fixed it. Thank you very much.
>>> 
>>> I can now repeat the reported workflow and the image appears on the
>>> fifth (and subsequent) calls.
>> 
>> Great. Thanks for checking.
>> 
>> Paul
>> 
> 
> 
>  That's great.
> 
>  Just a little bump: I would encourage Simon (in his copious spare
> time), or other interested members of R-core, to decide on a good
> name for the argument (as a reminder, I prefer 'method=c("raster","image")').
> Furthermore, I would strongly encourage that "raster" be made the default
> behavior for the development release of R ...
> 


Unfortunately I just encountered a speed bump today - I had no idea that the Windows device doesn't even support transparent pixels. That needs to be fixed before we can make it the default...

Cheers,
Simon


From p.murrell at auckland.ac.nz  Mon Feb 14 20:28:35 2011
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Tue, 15 Feb 2011 08:28:35 +1300
Subject: [Rd] using rasterImage within image
In-Reply-To: <058A2CD6-E303-4ABD-AD16-23E82F8513A0@r-project.org>
References: <4D51F2A7.8010505@mcmaster.ca>	<D8F5413E-025A-4511-BCE1-7ED06CBE99A0@r-project.org>	<4D52AD7B.6070402@gmail.com>	<E86B0A90-F63F-4537-A7FB-1AA84D685154@r-project.org>	<AANLkTi=yRP56wACtOs+Ouc70EV57rw9RKYmfLAh2hQ8a@mail.gmail.com>	<825F0B1E-EF80-48F5-AFF1-5832092450AB@r-project.org>	<AANLkTi=0K6hCP0tptSf6h4S6au+-SmahDm983zRdZEgb@mail.gmail.com>	<4D531558.7010709@gmail.com>	<AANLkTi=nwF-3UjtoFAaLdTwphmezvuk57HaaJd57=am2@mail.gmail.com>	<AANLkTimHAmzq4CEJF-auHRSA8745x2yb8r_GK9+vTrKJ@mail.gmail.com>	<4D5493BD.4050801@auckland.ac.nz>	<AANLkTikiFnaCPzBxDdDGV0+jhvo-bwo067Fnx1tSzW3=@mail.gmail.com>	<4D5844DB.4040801@auckland.ac.nz>	<loom.20110214T182423-339@post.gmane.org>
	<058A2CD6-E303-4ABD-AD16-23E82F8513A0@r-project.org>
Message-ID: <4D598263.9020700@auckland.ac.nz>

Hi

On 15/02/2011 8:11 a.m., Simon Urbanek wrote:
>
> On Feb 14, 2011, at 12:26 PM, Ben Bolker wrote:
>
>> Paul Murrell<p.murrell<at>  auckland.ac.nz>  writes:
>>
>>>
>>> Hi
>>>
>>> On 12/02/2011 7:22 p.m., Michael Sumner wrote:
>>>> Hello, that appears to have fixed it. Thank you very much.
>>>>
>>>> I can now repeat the reported workflow and the image appears on
>>>> the fifth (and subsequent) calls.
>>>
>>> Great. Thanks for checking.
>>>
>>> Paul
>>>
>>
>>
>> That's great.
>>
>> Just a little bump: I would encourage Simon (in his copious spare
>> time), or other interested members of R-core, to decide on a good
>> name for the argument (as a reminder, I prefer
>> 'method=c("raster","image")'). Furthermore, I would strongly
>> encourage that "raster" be made the default behavior for the
>> development release of R ...
>>
>
>
> Unfortunately I just encountered a speed bump today - I had no idea
> that the Windows device doesn't even support transparent pixels. That
> needs to be fixed before we can make it the default...

See the table at the bottom of 
http://developer.r-project.org/Raster/raster-RFC.html for the full list 
of limitations.

Paul

> Cheers, Simon
>
> ______________________________________________ R-devel at r-project.org
> mailing list https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/


From simon.urbanek at r-project.org  Mon Feb 14 20:59:01 2011
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Mon, 14 Feb 2011 14:59:01 -0500
Subject: [Rd] using rasterImage within image
In-Reply-To: <4D598263.9020700@auckland.ac.nz>
References: <4D51F2A7.8010505@mcmaster.ca>	<D8F5413E-025A-4511-BCE1-7ED06CBE99A0@r-project.org>	<4D52AD7B.6070402@gmail.com>	<E86B0A90-F63F-4537-A7FB-1AA84D685154@r-project.org>	<AANLkTi=yRP56wACtOs+Ouc70EV57rw9RKYmfLAh2hQ8a@mail.gmail.com>	<825F0B1E-EF80-48F5-AFF1-5832092450AB@r-project.org>	<AANLkTi=0K6hCP0tptSf6h4S6au+-SmahDm983zRdZEgb@mail.gmail.com>	<4D531558.7010709@gmail.com>	<AANLkTi=nwF-3UjtoFAaLdTwphmezvuk57HaaJd57=am2@mail.gmail.com>	<AANLkTimHAmzq4CEJF-auHRSA8745x2yb8r_GK9+vTrKJ@mail.gmail.com>	<4D5493BD.4050801@auckland.ac.nz>	<AANLkTikiFnaCPzBxDdDGV0+jhvo-bwo067Fnx1tSzW3=@mail.gmail.com>	<4D5844DB.4040801@auckland.ac.nz>	<loom.20110214T182423-339@post.gmane.org>
	<058A2CD6-E303-4ABD-AD16-23E82F8513A0@r-project.org>
	<4D598263.9020700@auckland.ac.nz>
Message-ID: <0478466E-4EDF-4594-B571-7CF36CB95A6C@r-project.org>


On Feb 14, 2011, at 2:28 PM, Paul Murrell wrote:

> Hi
> 
> On 15/02/2011 8:11 a.m., Simon Urbanek wrote:
>> 
>> On Feb 14, 2011, at 12:26 PM, Ben Bolker wrote:
>> 
>>> Paul Murrell<p.murrell<at>  auckland.ac.nz>  writes:
>>> 
>>>> 
>>>> Hi
>>>> 
>>>> On 12/02/2011 7:22 p.m., Michael Sumner wrote:
>>>>> Hello, that appears to have fixed it. Thank you very much.
>>>>> 
>>>>> I can now repeat the reported workflow and the image appears on
>>>>> the fifth (and subsequent) calls.
>>>> 
>>>> Great. Thanks for checking.
>>>> 
>>>> Paul
>>>> 
>>> 
>>> 
>>> That's great.
>>> 
>>> Just a little bump: I would encourage Simon (in his copious spare
>>> time), or other interested members of R-core, to decide on a good
>>> name for the argument (as a reminder, I prefer
>>> 'method=c("raster","image")'). Furthermore, I would strongly
>>> encourage that "raster" be made the default behavior for the
>>> development release of R ...
>>> 
>> 
>> 
>> Unfortunately I just encountered a speed bump today - I had no idea
>> that the Windows device doesn't even support transparent pixels. That
>> needs to be fixed before we can make it the default...
> 
> See the table at the bottom of http://developer.r-project.org/Raster/raster-RFC.html for the full list of limitations.
> 

Mea culpa - I had forgotten that the default for interpolate=TRUE (unfortunately) so all those dozens of warnings came from the fact that R was trying to interpolate on a device that doesn't support it. I stand corrected, transparent pixels are supported if interpolate=FALSE so image() should be safe.

Thanks,
Simon


From hangphan at gmail.com  Mon Feb 14 21:14:12 2011
From: hangphan at gmail.com (Hang PHAN)
Date: Mon, 14 Feb 2011 20:14:12 +0000
Subject: [Rd] R command line and pipe using in Linux?
In-Reply-To: <19801.29912.853582.36706@max.nulle.part>
References: <AANLkTimNYYpwWJDiNxhxq+Ay-i8DmqQU=H5dLE9gxRVR@mail.gmail.com>
	<19801.29912.853582.36706@max.nulle.part>
Message-ID: <AANLkTinzjFo+kfcWjzr8=A1g3r69f45FmBsxBTSEhfwe@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110214/d737e393/attachment.pl>

From cbeleites at units.it  Mon Feb 14 22:03:24 2011
From: cbeleites at units.it (Claudia Beleites)
Date: Mon, 14 Feb 2011 22:03:24 +0100
Subject: [Rd] drop argument for apply, rowSums, etc.
Message-ID: <4D59989C.7000703@units.it>

Dear list, dear Henrik,

I find myself often reconstructing matrices from the result of rowSum (matrix) 
etc. I therefore propose a new argument, drop, for these functions:

drop = TRUE (default) is the current behaviour. With
drop = FALSE length (dim (x)) and dimnames are preserved and the affected 
dimensions are set to 1 (or whatever teh result length of the applied function is)

I modified the base functions in colSums.R accordingly, and provide the 
respective methods (I did not yet have the time to look into apply.R).

I'm wondering whether these changes are of sufficient interest to the R public 
that these methods should have a more obvious "home" than a spectroscopy 
package. As I learned this morning of package matrixStats: Henrik, would you 
like to include these modified functions?

Anyways, the code is in the attached file, so if someone needs the funcionality, 
he can find it here.

Claudia












-- 
Claudia Beleites
Dipartimento dei Materiali e delle Risorse Naturali
Universit? degli Studi di Trieste
Via Alfonso Valerio 6/a
I-34127 Trieste

phone: +39 0 40 5 58-37 68
email: cbeleites at units.it
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: colSums.R
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110214/d4641f70/attachment.pl>

From bbolker at gmail.com  Mon Feb 14 22:17:14 2011
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 14 Feb 2011 16:17:14 -0500
Subject: [Rd] using rasterImage within image
In-Reply-To: <0478466E-4EDF-4594-B571-7CF36CB95A6C@r-project.org>
References: <4D51F2A7.8010505@mcmaster.ca>	<D8F5413E-025A-4511-BCE1-7ED06CBE99A0@r-project.org>	<4D52AD7B.6070402@gmail.com>	<E86B0A90-F63F-4537-A7FB-1AA84D685154@r-project.org>	<AANLkTi=yRP56wACtOs+Ouc70EV57rw9RKYmfLAh2hQ8a@mail.gmail.com>	<825F0B1E-EF80-48F5-AFF1-5832092450AB@r-project.org>	<AANLkTi=0K6hCP0tptSf6h4S6au+-SmahDm983zRdZEgb@mail.gmail.com>	<4D531558.7010709@gmail.com>	<AANLkTi=nwF-3UjtoFAaLdTwphmezvuk57HaaJd57=am2@mail.gmail.com>	<AANLkTimHAmzq4CEJF-auHRSA8745x2yb8r_GK9+vTrKJ@mail.gmail.com>	<4D5493BD.4050801@auckland.ac.nz>	<AANLkTikiFnaCPzBxDdDGV0+jhvo-bwo067Fnx1tSzW3=@mail.gmail.com>	<4D5844DB.4040801@auckland.ac.nz>	<loom.20110214T182423-339@post.gmane.org>
	<058A2CD6-E303-4ABD-AD16-23E82F8513A0@r-project.org>
	<4D598263.9020700@auckland.ac.nz>
	<0478466E-4EDF-4594-B571-7CF36CB95A6C@r-project.org>
Message-ID: <4D599BDA.5030708@gmail.com>

On 02/14/2011 02:59 PM, Simon Urbanek wrote:
> 
> On Feb 14, 2011, at 2:28 PM, Paul Murrell wrote:
> 
>> Hi
>> 
>> On 15/02/2011 8:11 a.m., Simon Urbanek wrote:
>>> 
>>> On Feb 14, 2011, at 12:26 PM, Ben Bolker wrote:
>>> 
>>>> Paul Murrell<p.murrell<at>  auckland.ac.nz>  writes:
>>>> 
>>>>> 
>>>>> Hi
>>>>> 
>>>>> On 12/02/2011 7:22 p.m., Michael Sumner wrote:
>>>>>> Hello, that appears to have fixed it. Thank you very much.
>>>>>> 
>>>>>> I can now repeat the reported workflow and the image
>>>>>> appears on the fifth (and subsequent) calls.
>>>>> 
>>>>> Great. Thanks for checking.
>>>>> 
>>>>> Paul
>>>>> 
>>>> 
>>>> 
>>>> That's great.
>>>> 
>>>> Just a little bump: I would encourage Simon (in his copious
>>>> spare time), or other interested members of R-core, to decide
>>>> on a good name for the argument (as a reminder, I prefer 
>>>> 'method=c("raster","image")'). Furthermore, I would strongly 
>>>> encourage that "raster" be made the default behavior for the 
>>>> development release of R ...
>>>> 
>>> 
>>> 
>>> Unfortunately I just encountered a speed bump today - I had no
>>> idea that the Windows device doesn't even support transparent
>>> pixels. That needs to be fixed before we can make it the
>>> default...
>> 
>> See the table at the bottom of
>> http://developer.r-project.org/Raster/raster-RFC.html for the full
>> list of limitations.
>> 
> 
> Mea culpa - I had forgotten that the default for interpolate=TRUE
> (unfortunately) so all those dozens of warnings came from the fact
> that R was trying to interpolate on a device that doesn't support it.
> I stand corrected, transparent pixels are supported if
> interpolate=FALSE so image() should be safe.
> 
> Thanks, Simon
> 

  Yes, but: according to the table of limitations, this

image(matrix(1:9,3),
      col=rgb(rep(1,9),rep(0,9),rep(0,9),alpha=seq(0,1,length=9)))

 shouldn't work with raster under Windows.

"** The Windows device can do semitransparent raster images, but ONLY if
there is a constant alpha across the entire image, i.e., it CANNOT do
per-pixel alpha (the Windows API AlphaBlend can, but GraphApp's bitmap
structures do not support "shades of alpha" - it's either transparent or
opaque). The Windows device DOES support fully transparent pixels in an
image (possibly in addition to a single level of semitransparency). In
other words, the image can have up to three different levels of alpha,
as long as fully transparent and fully opaque are two of the three. "

  I *think* the following function should provide a test of when we have
to fall back to method="image" if the current device is "windows" ...

diff_alpha <- function(cstr) {
  alphastr <- substr(cstr[nchar(cstr)==9],8,9)
  length(unique(alphastr[!alphastr %in% c("00","FF")]))>1
}

tst2 <- c(rgb(1,0,0,1),rgb(1,0,0),rgb(1,0,0,0.5),rgb(1,1,0,0.5),
          rgb(1,0,0,0.7))

diff_alpha(tst2)
diff_alpha(tst2[1:4])


  (I would argue that this situation is sufficiently rare that we should
still make "raster" the default, with a fallback to "image" if
diff_alpha() && windows is TRUE [perhaps a warning if missing(method)
and an error otherwise?])

  Ben Bolker



>


From baptiste.auguie at googlemail.com  Tue Feb 15 09:42:26 2011
From: baptiste.auguie at googlemail.com (baptiste auguie)
Date: Tue, 15 Feb 2011 09:42:26 +0100
Subject: [Rd] gList and gTree methods of grid::grobX
Message-ID: <AANLkTikH-c7EECcu8fpgxrMGShXnX5hR3tPmy1izPafx@mail.gmail.com>

Dear all,

In an attempt to draw fill patterns in grid graphics, I have
encountered a behavior of grobX that I cannot understand from the
documentation. Consider this,

library(grid)

## gTree
g1 <- gTree(children=gList(
             rectGrob(0.5,0.5, width=unit(0.8,"npc"),
                      height=unit(2,"cm")),
             circleGrob(r=0.3)), vp=viewport(0.5,0.5))

## gList
g1 <- gList(rectGrob(0.5,0.5, width=unit(0.8,"npc"),
                     height=unit(2,"cm")),
            circleGrob(r=0.3))

## loop over angles to map the boundary
gtheta <- function(g, theta){

  sapply(theta, function(.t){
         gx <- convertX(grobX(g, .t), "npc")
         gy <- convertY(grobY(g, .t), "npc")

         c(gx,gy)
       })

}

angles <- seq(0,360,by=30)
p1 <- gtheta(g1, angles)

grid.newpage()
grid.draw(g1)
grid.points(p1[1,],p1[2,], gp=gpar(cex=0.2),
            default.units="npc")


If I'm not mistaken, neither gList nor gTree seem to produce the
documented behavior,

"If the grob describes multiple shapes, the boundary value will either
correspond to the edge of a bounding box around all of the shapes
described by the grob (for multiple rectangles, circles, xsplines, or
text), or to a convex hull around all vertices of all shapes described
by the grob (for multiple polygons, points, lines, polylines, and
segments)."

with gList, I observe that the boundary is only considered for the
first shape, whilst gTree ignores all children altogether.

It works fine for single shapes (e.g. g1 = circleGrob(r=0.3)).

The same behavior is observed with quartz(), pdf() and png().


Sincerely,

baptiste

sessionInfo()
R version 2.12.1 Patched (2010-12-30 r53895)
Platform: i386-apple-darwin9.8.0 (32-bit)

locale:
[1] en_GB.UTF-8/en_GB.UTF-8/C/C/en_GB.UTF-8/en_GB.UTF-8

attached base packages:
[1] grid      stats     graphics  grDevices utils     datasets
methods   base

loaded via a namespace (and not attached):
[1] tools_2.12.1


From jorismeys at gmail.com  Tue Feb 15 10:21:19 2011
From: jorismeys at gmail.com (Joris Meys)
Date: Tue, 15 Feb 2011 10:21:19 +0100
Subject: [Rd] readPNG gives warnings and doesn't execute sample code
	from help files
In-Reply-To: <C425001D-55D4-4411-BAE2-8308E76E310B@r-project.org>
References: <AANLkTinVuFBRCoHHjQ_fAF5BXFFQ+sQPm7-Yq79MtqOL@mail.gmail.com>
	<C425001D-55D4-4411-BAE2-8308E76E310B@r-project.org>
Message-ID: <AANLkTi=dW4Ch7CgRhsXx-Fz4LrkbuDHdm9sgLaKY672-@mail.gmail.com>

I believed the standard plotting device on R in 2.12.1 would support
per-pixel alpha. It does support alpha, as

 plot(1:2,type="l")
 polygon(c(1,1,2,2),c(1,2,2,1),col=rgb(60,100,60,60,maxColorValue=255))

plots correctly. Which device should I use then?

Cheers
Joris

On Mon, Feb 14, 2011 at 5:30 PM, Simon Urbanek
<Simon.Urbanek at r-project.org> wrote:
> Joris,
>
> On Feb 14, 2011, at 10:05 AM, Joris Meys wrote:
>
>> Dear all,
>>
>> I noticed in the latest R version (R.2.12.1) that the readPNG gives
>> following warning when running the example code in the help file (or
>> when using any other png for that matter) :
>>
>> 50: In rasterImage(img, 1.2, 1.27, 1.8, 1.73) :
>> ?Per-pixel alpha not supported on this device
>>
>> No picture is shown, and code I used to be able to run, doesn't run any more.
>>
>
> You may want to use a device that supports alpha. The R logo in the example uses alpha so are probably the images you are using. If you don't want to (or can't) use a device that supports alpha, you'll have to flatten the alpha, - i.e. plot just img[,,1:3]
> However, most images don't have color where alpha is zero, so you'll have to replace it with the background color, e.g.:
> r = as.raster(img[,,1:3])
> r[img[,,4] == 0] = "white"
>
> Cheers,
> Simon
>
>
>
>>> sessionInfo()
>> R version 2.12.1 (2010-12-16)
>> Platform: i386-pc-mingw32/i386 (32-bit)
>>
>> locale:
>> [1] LC_COLLATE=English_United States.1252 ?LC_CTYPE=English_United
>> States.1252 ? ?LC_MONETARY=English_United States.1252
>> [4] LC_NUMERIC=C ? ? ? ? ? ? ? ? ? ? ? ? ? LC_TIME=English_United
>> States.1252
>>
>> attached base packages:
>> [1] grDevices datasets ?splines ? graphics ?stats ? ? tcltk ? ? utils
>> ? methods ? base
>>
>> other attached packages:
>> [1] png_0.1-2 ? ? ? svSocket_0.9-51 TinnR_1.0.3 ? ? R2HTML_2.2
>> Hmisc_3.8-3 ? ? survival_2.36-2
>>
>> loaded via a namespace (and not attached):
>> [1] cluster_1.13.2 ?grid_2.12.1 ? ? lattice_0.19-13 svMisc_0.9-61
>> tools_2.12.1
>>
>>
>> --
>> Joris Meys
>> Statistical consultant
>>
>> Ghent University
>> Faculty of Bioscience Engineering
>> Department of Applied mathematics, biometrics and process control
>>
>> tel : +32 9 264 59 87
>> Joris.Meys at Ugent.be
>> -------------------------------
>> Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php
>>
>>
>
>



-- 
Joris Meys
Statistical consultant

Ghent University
Faculty of Bioscience Engineering
Department of Applied mathematics, biometrics and process control

tel : +32 9 264 59 87
Joris.Meys at Ugent.be
-------------------------------
Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php


From ripley at stats.ox.ac.uk  Tue Feb 15 10:40:39 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 15 Feb 2011 09:40:39 +0000 (GMT)
Subject: [Rd] CRAN package sizes
In-Reply-To: <AANLkTin5vM8C+7w-PDzVWdRA67WNbXxH3MqMjbxd1HSs@mail.gmail.com>
References: <alpine.OSX.1.00.1102131203050.44163@tystie.local>
	<AANLkTin5vM8C+7w-PDzVWdRA67WNbXxH3MqMjbxd1HSs@mail.gmail.com>
Message-ID: <alpine.LFD.2.02.1102141112140.5766@gannet.stats.ox.ac.uk>

On Sun, 13 Feb 2011, Yihui Xie wrote:

> Regarding the reasons that make the doc directory large, I wonder if
> we can make some changes in R:

'we' cannot: only core developers can.  However, end users can 
contribute in many other ways: see below.

> 1. Use a null graphics device as the default device rather than pdf()
> when running Sweave -- this can avoid the useless Rplots.pdf:
>
> options(device = function(...) {
>    .Call("R_GD_nullDevice", PACKAGE = "grDevices")
> })
>
> This can save some time in building the vignette(s) as well. (see
> http://yihui.name/en/?p=673)
>
> However, this undocumented null device may not work for certain
> graphics. Here is an example that it fails for ggplot2:
> http://stackoverflow.com/questions/4692974/ggplot2-code-that-works-interactively-rkward-crashes-under-lyx-pgfsweave-hint/4707745#4707745
>
> Is it possible for someone to look into the null device (Dr Murrell?)
> to make it stable enough?

I don't see a bug report on that, and a patch would help expedite 
this.

> 2. Compress the PDF graphics and vignettes using third-party tools,
> among which I recommend qpdf (it's free).
>
> qpdf --stream-data=compress input.pdf output.pdf
>
> This can reduce the size of PDF files a lot without quality loss. I'm
> using this tool in the animation package to reduce the size of PDF
> animations.

*Can*, but I did say

   'There are several ways to reduce the sizes of PDFs with no loss in
    quality, e.g. Adobe Acrobat Standard/Pro.'

and qpdf is often ineffective (or worse), e.g. on package mokken.  The 
problem is that many of the large packages need images re-saved in 
some other format (or preferably re-generated in some other format).

I've added a --compact-vignettes option to R CMD build (in R-devel). 
At present it uses qpdf, but I will look out for better/additional 
options.  (I use Acrobat 9 Pro on my Mac and that has always beaten 
qpdf, often by a large margin.  But qpdf is perhaps the most readily 
available of these tools.)

> 3. Sorry I bring up this issue again, but I don't understand why
> Sweave could not implement the png() device along with pdf() and
> postscript(). I'm willing to provide a patch if needed.

Does it need changes to R?  I believe that it just needs a 
different driver, something which could be provided in a package.

This has been raised several times (including recently) with the 
Sweave maintainer, so maybe it will happpen eventually.  But a package 
would retrofit it to eariier versions of R.


>
> Thanks!
>
> Regards,
> Yihui
> --
> Yihui Xie <xieyihui at gmail.com>
> Phone: 515-294-2465 Web: http://yihui.name
> Department of Statistics, Iowa State University
> 2215 Snedecor Hall, Ames, IA
>
>
>
> On Sun, Feb 13, 2011 at 6:30 AM, Prof Brian Ripley
> <ripley at stats.ox.ac.uk> wrote:
>> Robin Hankin's post reminded me to post about the following recent addition
>> to 'Writing R Extensions', in the section on 'Submitting a package to CRAN'
>>
>> ?Ensure that the package sources are not unnecessarily large. ...
>> ?As a general rule, doc directories should not exceed 5Mb, and
>> ?where data directories need to be 10Mb or more, consideration should
>> ?be given to a separate package containing just the data. (Similarly
>> ?for external data directories, large jar files and other libraries
>> ?that need to be installed.)
>>
>> With 2800 packages on CRAN, overall size is becoming a concern and currently
>> to install all of CRAN takes 4Gb. ?As the attached (I hope) graph shows, the
>> 20 packages over 20Mb take a quarter, and those over 5Mb take half. ?(And
>> this is after we have removed 100Mb from the largest installed package by
>> re-compression, and archived the second largest, so Robin's package is
>> currently the largest.) ?Some of the largest packages are data/jar packages,
>> but there are 55 packages with 'doc' directories over 5Mb. ?To put that in
>> perspective, PDFs of whole books with lots of figures (MASS, Paul's R
>> Graphics) are well under 5Mb.
>>
>> R CMD check in R-devel reports on large packages, and expect in future that
>> submitted package sizes will be questioned more often.
>>
>> There are lots of different reasons why doc directories are large, but the
>> major ones are
>>
>> - installing files that are unneeded, such as Rplots.pdf and .eps
>> ?figures.
>> - using PDF figures of images where PNG would be more appropriate.
>> - including less than relevant material (such as how to install R,
>> ?with screenshots!)
>>
>> There are several ways to reduce the sizes of PDFs with no loss in quality,
>> e.g. Adobe Acrobat Standard/Pro.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From nashjc at uottawa.ca  Tue Feb 15 13:16:29 2011
From: nashjc at uottawa.ca (Prof. John C Nash)
Date: Tue, 15 Feb 2011 07:16:29 -0500
Subject: [Rd] Google Summer of Code 2011
Message-ID: <4D5A6E9D.70209@uottawa.ca>

The 2011 Google Summer of Code will soon be open for organizations to submit potential
projects for which students may apply (with detailed plans) for funding. We have some
proposals in process at

http://rwiki.sciviews.org/doku.php?id=developers:projects:gsoc2011

Note that projects do need to have mentors. Google has so far had a 1 mentor per project
policy, but informally there have been support teams.

Claudia Beleites and I are also administering the gsoc-r discussion on google groups
mentioned at the bottom of the page linked above. Thanks to Dirk E. who has run this up to
now and passed the torch to us.

John Nash


From hankin.robin at gmail.com  Tue Feb 15 08:54:55 2011
From: hankin.robin at gmail.com (robin hankin)
Date: Tue, 15 Feb 2011 20:54:55 +1300
Subject: [Rd] S4 problems
Message-ID: <AANLkTikf6TGWStjHPeF8uF94JsW=dP_Q3c7yk1N_hPMr@mail.gmail.com>

Hello everybody

[R-2.12.1]

I am having difficulty dealing with Oarray objects.
I have a generic function, call it foo(), and I wish
to define  a method for Oarray objects.

I do not have or want a method for regular arrays [actually,
I want to coerce to an Oarray, and give a warning].

But setMethod() does not behave as desired, giving
an error message when I try to define a method for
Oarray objects.

Also, if I define a method for array objects, this does not
give an error message, but neither does it behave as desired,
as the method is not found when  passing an Oarray object
to foo().


LE110:~/packages% R --vanilla --quiet
> library(Oarray)
> setGeneric("foo",function(x){standardGeneric("foo")})
[1] "foo"
>  setMethod("foo","Oarray",function(x){x})
in method for ?foo? with signature ?"Oarray"?: no definition for class "Oarray"
[1] "foo"
> setMethod("foo","array",function(x){x})
[1] "foo"
> a <- Oarray(0,2:3)
> is.array(a)
[1] TRUE
> foo(a)
Error in function (classes, fdef, mtable)  :
  unable to find an inherited method for function "foo", for signature "Oarray"

Three questions:

Why does the first call to setMethod() give an error message?
Why does (a) not find the method defined for arrays, even though 'a'
is an array?
How can I make "foo(a)" behave as desired when 'a' is an object of
class 'Oarray'?






-- 
Robin Hankin
Uncertainty Analyst
hankin.robin at gmail.com


From bbolker at gmail.com  Tue Feb 15 14:20:59 2011
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 15 Feb 2011 13:20:59 +0000
Subject: [Rd]
	=?utf-8?q?readPNG_gives_warnings_and_doesn=27t_execute_sampl?=
	=?utf-8?q?e_code=09from_help_files?=
References: <AANLkTinVuFBRCoHHjQ_fAF5BXFFQ+sQPm7-Yq79MtqOL@mail.gmail.com>
	<C425001D-55D4-4411-BAE2-8308E76E310B@r-project.org>
	<AANLkTi=dW4Ch7CgRhsXx-Fz4LrkbuDHdm9sgLaKY672-@mail.gmail.com>
Message-ID: <loom.20110215T141928-342@post.gmane.org>

Joris Meys <jorismeys <at> gmail.com> writes:

> 
> I believed the standard plotting device on R in 2.12.1 would support
> per-pixel alpha. It does support alpha, as
> 
>  plot(1:2,type="l")
>  polygon(c(1,1,2,2),c(1,2,2,1),col=rgb(60,100,60,60,maxColorValue=255))
> 
> plots correctly. Which device should I use then?

See 

http://developer.r-project.org/Raster/raster-RFC.html

(near the bottom of the page, where it explains that the
Windows device supports alpha but not per-pixel alpha ...)

 cheers
    Ben Bolker


From jorismeys at gmail.com  Tue Feb 15 14:40:26 2011
From: jorismeys at gmail.com (Joris Meys)
Date: Tue, 15 Feb 2011 14:40:26 +0100
Subject: [Rd] readPNG gives warnings and doesn't execute sample code
 from help files
In-Reply-To: <loom.20110215T141928-342@post.gmane.org>
References: <AANLkTinVuFBRCoHHjQ_fAF5BXFFQ+sQPm7-Yq79MtqOL@mail.gmail.com>
	<C425001D-55D4-4411-BAE2-8308E76E310B@r-project.org>
	<AANLkTi=dW4Ch7CgRhsXx-Fz4LrkbuDHdm9sgLaKY672-@mail.gmail.com>
	<loom.20110215T141928-342@post.gmane.org>
Message-ID: <AANLkTi=vq+JZd3Nvtr5VDMrLveei60VUxXei_bvqH4hw@mail.gmail.com>

Thx again for your answer. I've tried X11() - which is supposed to
support alpha per pixel as well, but on Windows that's still no avail.
So basically, on Windows I can forget about alpha?

Cheers
Jors

On Tue, Feb 15, 2011 at 2:20 PM, Ben Bolker <bbolker at gmail.com> wrote:
> Joris Meys <jorismeys <at> gmail.com> writes:
>
>>
>> I believed the standard plotting device on R in 2.12.1 would support
>> per-pixel alpha. It does support alpha, as
>>
>> ?plot(1:2,type="l")
>> ?polygon(c(1,1,2,2),c(1,2,2,1),col=rgb(60,100,60,60,maxColorValue=255))
>>
>> plots correctly. Which device should I use then?
>
> See
>
> http://developer.r-project.org/Raster/raster-RFC.html
>
> (near the bottom of the page, where it explains that the
> Windows device supports alpha but not per-pixel alpha ...)
>
> ?cheers
> ? ?Ben Bolker
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>



-- 
Joris Meys
Statistical consultant

Ghent University
Faculty of Bioscience Engineering
Department of Applied mathematics, biometrics and process control

tel : +32 9 264 59 87
Joris.Meys at Ugent.be
-------------------------------
Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php


From jorismeys at gmail.com  Tue Feb 15 14:44:03 2011
From: jorismeys at gmail.com (Joris Meys)
Date: Tue, 15 Feb 2011 14:44:03 +0100
Subject: [Rd] readPNG gives warnings and doesn't execute sample code
 from help files
In-Reply-To: <AANLkTi=vq+JZd3Nvtr5VDMrLveei60VUxXei_bvqH4hw@mail.gmail.com>
References: <AANLkTinVuFBRCoHHjQ_fAF5BXFFQ+sQPm7-Yq79MtqOL@mail.gmail.com>
	<C425001D-55D4-4411-BAE2-8308E76E310B@r-project.org>
	<AANLkTi=dW4Ch7CgRhsXx-Fz4LrkbuDHdm9sgLaKY672-@mail.gmail.com>
	<loom.20110215T141928-342@post.gmane.org>
	<AANLkTi=vq+JZd3Nvtr5VDMrLveei60VUxXei_bvqH4hw@mail.gmail.com>
Message-ID: <AANLkTik=z=u-jyCtSd8Ko0jJDERp=+apGzjnh00Txzv2@mail.gmail.com>

Sorry, correction. X11() is not supposed to do that. So on Windows,
per-pixel alpha is no option apparently. Any chance this will be
implemented in the future?

Cheers
Joris

PS : also thx to Simon for his helpful answer earlier.

On Tue, Feb 15, 2011 at 2:40 PM, Joris Meys <jorismeys at gmail.com> wrote:
> Thx again for your answer. I've tried X11() - which is supposed to
> support alpha per pixel as well, but on Windows that's still no avail.
> So basically, on Windows I can forget about alpha?
>
> Cheers
> Jors
>
> On Tue, Feb 15, 2011 at 2:20 PM, Ben Bolker <bbolker at gmail.com> wrote:
>> Joris Meys <jorismeys <at> gmail.com> writes:
>>
>>>
>>> I believed the standard plotting device on R in 2.12.1 would support
>>> per-pixel alpha. It does support alpha, as
>>>
>>> ?plot(1:2,type="l")
>>> ?polygon(c(1,1,2,2),c(1,2,2,1),col=rgb(60,100,60,60,maxColorValue=255))
>>>
>>> plots correctly. Which device should I use then?
>>
>> See
>>
>> http://developer.r-project.org/Raster/raster-RFC.html
>>
>> (near the bottom of the page, where it explains that the
>> Windows device supports alpha but not per-pixel alpha ...)
>>
>> ?cheers
>> ? ?Ben Bolker
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
>
>
> --
> Joris Meys
> Statistical consultant
>
> Ghent University
> Faculty of Bioscience Engineering
> Department of Applied mathematics, biometrics and process control
>
> tel : +32 9 264 59 87
> Joris.Meys at Ugent.be
> -------------------------------
> Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php
>



-- 
Joris Meys
Statistical consultant

Ghent University
Faculty of Bioscience Engineering
Department of Applied mathematics, biometrics and process control

tel : +32 9 264 59 87
Joris.Meys at Ugent.be
-------------------------------
Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php


From ggrothendieck at gmail.com  Tue Feb 15 14:45:38 2011
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 15 Feb 2011 08:45:38 -0500
Subject: [Rd] ave reports warning when nothing is wrong
Message-ID: <AANLkTi=nv4noOM4buvf2LQo6XVyv4wPW5EEgtuf54XXM@mail.gmail.com>

ave reports a warning here:

> DF <- data.frame(A = c(1, 2, 2), B = c(1, 1, 2), C = c(1, 2, 3))
> with(DF, ave(C, A, B, FUN = min))
[1] 1 2 3
Warning message:
In FUN(X[[4L]], ...) : no non-missing arguments to min; returning Inf

In this case it can be avoided by using drop = TRUE which could only
be discovered by looking at the source code and at any rate should not
be necessary:

> with(DF, ave(C, A, B, drop = TRUE, FUN = min))
[1] 1 2 3

The problem is that internally ave uses interaction(...) -- in the
example above that would correspond to interaction(A, B).  This can
result in a factor with unused levels.  Replacing   interaction(...)
in the source code with
   interaction(..., drop = TRUE)
would avoid the warning message.

> ave
function (x, ..., FUN = mean)
{
    n <- length(list(...))
    if (n) {
        g <- interaction(...)
        split(x, g) <- lapply(split(x, g), FUN)
    }
    else x[] <- FUN(x)
    x
}
<environment: namespace:stats>

> R.version.string
[1] "R version 2.12.1 Patched (2010-12-16 r53864)"

I got the same results with:
> R.version.string
[1] "R version 2.13.0 Under development (unstable) (2011-02-11 r54330)"
>


-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From bbolker at gmail.com  Tue Feb 15 15:21:30 2011
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 15 Feb 2011 09:21:30 -0500
Subject: [Rd] readPNG gives warnings and doesn't execute sample code
 from help files
In-Reply-To: <AANLkTik=z=u-jyCtSd8Ko0jJDERp=+apGzjnh00Txzv2@mail.gmail.com>
References: <AANLkTinVuFBRCoHHjQ_fAF5BXFFQ+sQPm7-Yq79MtqOL@mail.gmail.com>	<C425001D-55D4-4411-BAE2-8308E76E310B@r-project.org>	<AANLkTi=dW4Ch7CgRhsXx-Fz4LrkbuDHdm9sgLaKY672-@mail.gmail.com>	<loom.20110215T141928-342@post.gmane.org>	<AANLkTi=vq+JZd3Nvtr5VDMrLveei60VUxXei_bvqH4hw@mail.gmail.com>
	<AANLkTik=z=u-jyCtSd8Ko0jJDERp=+apGzjnh00Txzv2@mail.gmail.com>
Message-ID: <4D5A8BEA.3030908@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 02/15/2011 08:44 AM, Joris Meys wrote:
> Sorry, correction. X11() is not supposed to do that. So on Windows,
> per-pixel alpha is no option apparently. Any chance this will be
> implemented in the future?
> 
> Cheers
> Joris
> 
> PS : also thx to Simon for his helpful answer earlier.

  Hmmm.

  I think your best bet would be
http://cran.r-project.org/web/packages/Cairo/index.html ... ?


> 
> On Tue, Feb 15, 2011 at 2:40 PM, Joris Meys <jorismeys at gmail.com> wrote:
>> Thx again for your answer. I've tried X11() - which is supposed to
>> support alpha per pixel as well, but on Windows that's still no avail.
>> So basically, on Windows I can forget about alpha?
>>
>> Cheers
>> Jors
>>
>> On Tue, Feb 15, 2011 at 2:20 PM, Ben Bolker <bbolker at gmail.com> wrote:
>>> Joris Meys <jorismeys <at> gmail.com> writes:
>>>
>>>>
>>>> I believed the standard plotting device on R in 2.12.1 would support
>>>> per-pixel alpha. It does support alpha, as
>>>>
>>>>  plot(1:2,type="l")
>>>>  polygon(c(1,1,2,2),c(1,2,2,1),col=rgb(60,100,60,60,maxColorValue=255))
>>>>
>>>> plots correctly. Which device should I use then?
>>>
>>> See
>>>
>>> http://developer.r-project.org/Raster/raster-RFC.html
>>>
>>> (near the bottom of the page, where it explains that the
>>> Windows device supports alpha but not per-pixel alpha ...)
>>>
>>>  cheers
>>>    Ben Bolker
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>
>>
>>
>> --
>> Joris Meys
>> Statistical consultant
>>
>> Ghent University
>> Faculty of Bioscience Engineering
>> Department of Applied mathematics, biometrics and process control
>>
>> tel : +32 9 264 59 87
>> Joris.Meys at Ugent.be
>> -------------------------------
>> Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php
>>
> 
> 
> 

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.10 (GNU/Linux)
Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org/

iEYEARECAAYFAk1ai+oACgkQc5UpGjwzenPNWQCgiMQwXc9t/8DnziWOZJbk1Aqw
X+IAnA9G+VwcknZPisZ5pqVICxEQ+L++
=iPcR
-----END PGP SIGNATURE-----


From mtmorgan at fhcrc.org  Tue Feb 15 15:24:20 2011
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Tue, 15 Feb 2011 06:24:20 -0800
Subject: [Rd] S4 problems
In-Reply-To: <AANLkTikf6TGWStjHPeF8uF94JsW=dP_Q3c7yk1N_hPMr@mail.gmail.com>
References: <AANLkTikf6TGWStjHPeF8uF94JsW=dP_Q3c7yk1N_hPMr@mail.gmail.com>
Message-ID: <4D5A8C94.3020101@fhcrc.org>

On 02/14/2011 11:54 PM, robin hankin wrote:
> Hello everybody
> 
> [R-2.12.1]
> 
> I am having difficulty dealing with Oarray objects.
> I have a generic function, call it foo(), and I wish
> to define  a method for Oarray objects.
> 
> I do not have or want a method for regular arrays [actually,
> I want to coerce to an Oarray, and give a warning].
> 
> But setMethod() does not behave as desired, giving
> an error message when I try to define a method for
> Oarray objects.
> 
> Also, if I define a method for array objects, this does not
> give an error message, but neither does it behave as desired,
> as the method is not found when  passing an Oarray object
> to foo().
> 
> 
> LE110:~/packages% R --vanilla --quiet
>> library(Oarray)
>> setGeneric("foo",function(x){standardGeneric("foo")})
> [1] "foo"
>>  setMethod("foo","Oarray",function(x){x})
> in method for ?foo? with signature ?"Oarray"?: no definition for class "Oarray"
> [1] "foo"
>> setMethod("foo","array",function(x){x})
> [1] "foo"
>> a <- Oarray(0,2:3)
>> is.array(a)
> [1] TRUE
>> foo(a)
> Error in function (classes, fdef, mtable)  :
>   unable to find an inherited method for function "foo", for signature "Oarray"
> 
> Three questions:
> 
> Why does the first call to setMethod() give an error message?

Oarray is an S3 class, so

setOldClass("Oarray")

before defining methods on the class.

Hope that helps,

Martin

> Why does (a) not find the method defined for arrays, even though 'a'
> is an array?
> How can I make "foo(a)" behave as desired when 'a' is an object of
> class 'Oarray'?
> 
> 
> 
> 
> 
> 


-- 
Computational Biology
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N. PO Box 19024 Seattle, WA 98109

Location: M1-B861
Telephone: 206 667-2793


From cbeleites at units.it  Tue Feb 15 15:44:21 2011
From: cbeleites at units.it (Claudia Beleites)
Date: Tue, 15 Feb 2011 15:44:21 +0100
Subject: [Rd] vignette question was: CRAN package sizes
In-Reply-To: <alpine.LFD.2.02.1102141112140.5766@gannet.stats.ox.ac.uk>
References: <alpine.OSX.1.00.1102131203050.44163@tystie.local>	<AANLkTin5vM8C+7w-PDzVWdRA67WNbXxH3MqMjbxd1HSs@mail.gmail.com>
	<alpine.LFD.2.02.1102141112140.5766@gannet.stats.ox.ac.uk>
Message-ID: <4D5A9145.9050301@units.it>

Also I started doing my homework with regards to package size, and that is 
mainly cleaning leftovers from vignette generation and compressing the pdfs.

For most of my vignettes, ghostscript (lossy) compression works very well:
I use the /screen settings and -dDownsampleColorImages=false
gs -sDEVICE=pdfwrite -dCompatibilityLevel=1.4 -dPDFSETTINGS=/screen -dNOPAUSE 
-dQUIET -dBATCH -dDownsampleColorImages=false -dAutoRotatePages=/None
(DownsampleColorImages=false is important as I found otherwise that some .png 
become completely useless. However, the pngs are saved with carefully determined 
size and are pngs because the pdfs were too large: so I know that the bitmap 
images are already "size-optimized")
I wrote a inst/doc/makefile to do this and also clean up a few more "leftovers 
from the vignette".

BTW: while compressing the final .pdf achieves better total compression, it 
already helps a lot to compress the .pdf figures which can be done at the end of 
the .Rnw.

qpdf didn't help for my vignettes.


One question remains, though. I have two vignettes, where I cannot put the 
original data into the package (the very first thing in the vignette is the link 
to a zip file on r-forge that contains everything needed to reproduce the 
vignette, though. I think this is accessible enough for FOSS).
I'd like to have these documents accessible via the usual vignette () mechanism 
(this question has come up before, but I found only that the 00Index.dcf does 
not work any longer).
My second thought was to set up the Makefile so that instead of building the pdf 
a message is printed and the available pdf is used.
This does not work, however: buildVignettes (which I guess does the work*) first 
Sweaves the .Rnw file and then replaces the texi2dvi () call by make.
Is this intended behaviour? If so, how do I make my vignette accessible 
[obviously the "dummy .Rnw that includes the pdf"-technique doesn't look quite 
appropriate as it leads to unnecessarily large package size]?

*I did not realise this from the Makefile discussion in the extensions manual 
(nor does the help page of buildVignettes mention anything about this). Also, 
I'd appreciate very much if the extension manual would mention buildVignettes - 
it took me quite a while to find out what code is used and why my Makefile 
didn't lead to the desired results.

Thanks a lot for any ideas,

Claudia

-- 
Claudia Beleites
Dipartimento dei Materiali e delle Risorse Naturali
Universit? degli Studi di Trieste
Via Alfonso Valerio 6/a
I-34127 Trieste

phone: +39 0 40 5 58-37 68
email: cbeleites at units.it


From jorismeys at gmail.com  Tue Feb 15 15:48:06 2011
From: jorismeys at gmail.com (Joris Meys)
Date: Tue, 15 Feb 2011 15:48:06 +0100
Subject: [Rd] Using rasterImage on a CairoWin device prevents adding further
 elements to device?
Message-ID: <AANLkTikng2NZ0doG0W-ZXLjr-JEmV6sQ=bv28eR2REyw@mail.gmail.com>

I was pointed to the Cairo package for plotting PNG images on a
device. I've been playing around with it, but found that after I use
the rasterImage function, I can't add anything any more to the device,
eg :

img <- readPNG(system.file("img", "Rlogo.png", package="png"))
r = as.raster(img[,,1:3])
r[img[,,4] == 0] = "white"

CairoWin()
plot(1:2,1:2,type="l")
rasterImage(r,1,1,2,2)
points(seq(1,2,by=0.1),seq(2,1,by=-0.1),col="black")

The points are not plotted anymore.

If I use the normal plotting device, I see the points plotted on top
of the image.

Cheers
Joris


-- 
Joris Meys
Statistical consultant

Ghent University
Faculty of Bioscience Engineering
Department of Applied mathematics, biometrics and process control

tel : +32 9 264 59 87
Joris.Meys at Ugent.be
-------------------------------
Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php


From nashjc at uottawa.ca  Tue Feb 15 16:31:44 2011
From: nashjc at uottawa.ca (Prof. John C Nash)
Date: Tue, 15 Feb 2011 10:31:44 -0500
Subject: [Rd] Google Summer of Code 2011 - credit where it is due
Message-ID: <4D5A9C60.4090500@uottawa.ca>

In my reminder that GSoC project proposals are requested (to R wiki developers' projects
page for GSoC 2011), I mentioned that Dirk Eddelbuettel had acted as leader for the R
Foundation activity on GSoC prior to handing the torch to Claudia Beleites and I for this
year. I should have mentioned that for 2009 Manuel Eugster wore the hat, and in 2008
Friedrich Leisch. GSoC has been running since 2005, but we were not involved for the first
three years.

JN


From cbeleites at units.it  Tue Feb 15 17:27:19 2011
From: cbeleites at units.it (Claudia Beleites)
Date: Tue, 15 Feb 2011 17:27:19 +0100
Subject: [Rd] vignette question was: CRAN package sizes
In-Reply-To: <4D5A9145.9050301@units.it>
References: <alpine.OSX.1.00.1102131203050.44163@tystie.local>	<AANLkTin5vM8C+7w-PDzVWdRA67WNbXxH3MqMjbxd1HSs@mail.gmail.com>	<alpine.LFD.2.02.1102141112140.5766@gannet.stats.ox.ac.uk>
	<4D5A9145.9050301@units.it>
Message-ID: <4D5AA967.1010000@units.it>

Please excuse the noise about dummy .Rnw.

On 02/15/2011 03:44 PM, Claudia Beleites wrote:
> Also I started doing my homework with regards to package size, and that is
> mainly cleaning leftovers from vignette generation and compressing the pdfs.
>
> For most of my vignettes, ghostscript (lossy) compression works very well:
> I use the /screen settings and -dDownsampleColorImages=false
> gs -sDEVICE=pdfwrite -dCompatibilityLevel=1.4 -dPDFSETTINGS=/screen -dNOPAUSE
> -dQUIET -dBATCH -dDownsampleColorImages=false -dAutoRotatePages=/None
> (DownsampleColorImages=false is important as I found otherwise that some .png
> become completely useless. However, the pngs are saved with carefully determined
> size and are pngs because the pdfs were too large: so I know that the bitmap
> images are already "size-optimized")
> I wrote a inst/doc/makefile to do this and also clean up a few more "leftovers
> from the vignette".
>
> BTW: while compressing the final .pdf achieves better total compression, it
> already helps a lot to compress the .pdf figures which can be done at the end of
> the .Rnw.
>
> qpdf didn't help for my vignettes.


> One question remains, though. I have two vignettes, where I cannot put the
> original data into the package (the very first thing in the vignette is the link
> to a zip file on r-forge that contains everything needed to reproduce the
> vignette, though. I think this is accessible enough for FOSS).
> I'd like to have these documents accessible via the usual vignette () mechanism
> (this question has come up before, but I found only that the 00Index.dcf does
> not work any longer).
> My second thought was to set up the Makefile so that instead of building the pdf
> a message is printed and the available pdf is used.
> This does not work, however: buildVignettes (which I guess does the work*) first
> Sweaves the .Rnw file and then replaces the texi2dvi () call by make.
> Is this intended behaviour? If so, how do I make my vignette accessible
> [obviously the "dummy .Rnw that includes the pdf"-technique doesn't look quite
> appropriate as it leads to unnecessarily large package size]?
coffe break was helpful: of course I just need a dummy .Rnw that is processed to 
a .tex but (via Makefile) _not_ to pdf...

> *I did not realise this from the Makefile discussion in the extensions manual
> (nor does the help page of buildVignettes mention anything about this). Also,
> I'd appreciate very much if the extension manual would mention buildVignettes -
> it took me quite a while to find out what code is used and why my Makefile
> didn't lead to the desired results.

Sorry, Claudia



-- 
Claudia Beleites
Dipartimento dei Materiali e delle Risorse Naturali
Universit? degli Studi di Trieste
Via Alfonso Valerio 6/a
I-34127 Trieste

phone: +39 0 40 5 58-37 68
email: cbeleites at units.it


From hb at biostat.ucsf.edu  Tue Feb 15 18:43:01 2011
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Tue, 15 Feb 2011 09:43:01 -0800
Subject: [Rd] R 2.13.0 on Windows: R CMD check and '"du"' not found
In-Reply-To: <4D57DD13.9060804@gmail.com>
References: <AANLkTinypB_0XrtxrxyK26URcCeUWuMFFFsXKzqa7G1X@mail.gmail.com>
	<4D57DD13.9060804@gmail.com>
Message-ID: <AANLkTi=F4kx8+FuR7p_h7hVHKi=4qtDjw+RJEH7u+_X_@mail.gmail.com>

On Sun, Feb 13, 2011 at 5:30 AM, Duncan Murdoch
<murdoch.duncan at gmail.com> wrote:
> On 11-02-12 4:57 PM, Henrik Bengtsson wrote:
>>
>> FYI, I'm sure the following is a temporary issue, but in case it slips
>> through, I want to raise it here. ?On Windows 7 64-bit, running Rcmd
>> check on R devel gives:
>
> I think you need version r54335 or newer to avoid this error.

Confirm (tried with r54412).  Thxs.

>
>
>>
>> ?* using R version 2.13.0 Under development (unstable) (2011-02-11 r54330)
>> * using platform: x86_64-pc-mingw32 (64-bit)
>> * using session charset: ISO8859-1
>> * checking for file 'aroma.core/DESCRIPTION' ... OK
>> * this is package 'aroma.core' version '1.9.4'
>> * checking package dependencies ... OK
>> * checking if this is a source package ... OK
>> * checking for executable files ... OK
>> * checking whether package 'aroma.core' can be installed ... OK
>> * checking installed package size ...Error in system2("du", , TRUE,
>> TRUE) : '"du"' not found
>> Execution halted
>>
>> That is, the 'du' (disk usage) executable is missing.
>>
>> I've verified that installing the latest Rtools
>> [http://www.murdoch-sutherland.com/Rtools/Rtools212.exe] does not
>> solve it (=it does not contain 'du'). ?BTW, is there a way to know
>> when Rtools have been updated relative to the version you already have
>> installed?
>
> I usually put news on the page when I update them, but I don't send out
> notices. ?Aren't there services to monitor a page and notify you of changes?

Thanks.  I don't need notices, but wanted to be sure that it is
possible to figure out when it is updated.

I guess I failed to see the following on
http://www.murdoch-sutherland.com/Rtools/ because my illiteracy and "R
2.11.1" caused me to skip the complete paragraph:

Changes since R 2.11.1:
Prior to October 18, 2010, builds of Rtools212.exe did not correctly
install the "extras" required to build R. Version 2.12.0.1892 or later
should fix this. We have now updated all of the tools to current
Cygwin versions, and have updated the compilers, and included the 64
bit compilers into Rtools. See Prof. Ripley's page for the details.
Perl is rarely needed in R since R 2.12.0, so it is by default not
installed. Rtools 2.11 has been frozen.

I see that you now add dates.  That should be enough to know if it is
needed to install the new version.  You are displaying a version
number (e.g. "2.12.0.1892").  Is it possible to check that version
number on an Rtools installation?  Not that important, but could be
useful.

Thanks

/Henrik

>
>
>>
>> /Henrik
>>
>> PS. Placing the 'du.exe' executable of UnxTools
>> (http://sourceforge.net/projects/unxutils/) in the bin/ directory of
>> Rtools (e.g. C:/Rtools/bin/) provides a workaround.
>
> I'll see about adding it with the next update.
>
> Duncan Murdoch
>>
>>
>>> sessionInfo()
>>
>> R version 2.13.0 Under development (unstable) (2011-02-11 r54330)
>> Platform: x86_64-pc-mingw32/x64 (64-bit)
>>
>> locale:
>> [1] LC_COLLATE=English_United States.1252
>> [2] LC_CTYPE=English_United States.1252
>> [3] LC_MONETARY=English_United States.1252
>> [4] LC_NUMERIC=C
>> [5] LC_TIME=English_United States.1252
>>
>> attached base packages:
>> [1] stats ? ? graphics ?grDevices utils ? ? datasets ?methods ? base
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From jon.clayden at gmail.com  Tue Feb 15 18:45:10 2011
From: jon.clayden at gmail.com (Jon Clayden)
Date: Tue, 15 Feb 2011 17:45:10 +0000
Subject: [Rd] Reference classes and ".requireCachedGenerics"
Message-ID: <AANLkTin+UGGVnk7XRWa5i2Y+3w_hC7rfTRpTh1SG+18j@mail.gmail.com>

Dear all,

If I load a package which creates reference classes whilst another
such package is also loaded, I get a warning about masking of the
".requireCachedGenerics" variable. (FWIW, both packages are
lazy-loaded.) Googling this variable name turned up only one previous
discussion, which didn't immediately help, except to suggest that it
may be related to my defining an S3 method for one or more of the
classes. It also pointed me at bits of the R source, but it wasn't
obvious to me from that, what this variable is for.

Aside from being a nuisance, I wonder if this is indicative of a
problem on R's side or on mine, so I'd be glad for any clarification.

This is R 2.12.1 on Mac OS X.6.6, though it still happens with the new
2.12.2 beta. Any feedback welcome.

Thanks,
Jon


From pauljohn32 at gmail.com  Tue Feb 15 19:04:42 2011
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Tue, 15 Feb 2011 12:04:42 -0600
Subject: [Rd] Request: Suggestions for "good teaching" packages,
	esp. with C code
Message-ID: <AANLkTikODppzk5=x7=TzVepH+aHuvaZUErf_0xQZ5ioX@mail.gmail.com>

Hello,

I am looking for CRAN packages that don't teach bad habits.  Can I
have suggestions?

I don't mean the recommended packages that come with R, I mean the
contributed ones.  I've been sampling a lot of examples and am
surprised that many ignore seemingly agreed-upon principles of R
coding. In r-devel, almost everyone seems to support the "functional
programming" theme in Chambers's book on Software For Data Analysis,
but when I go look at randomly selected packages, programmers don't
follow that advice.

In particular:

1. Functions must avoid "mystery variables from nowhere."

Consider a function's code, it should not be necessary to say "what's
variable X?" and go hunting in the commands that lead up to the
function call.  If X is used in the function, it should be in a named
argument, or extracted from one of the named arguments.  People who
rely on variables floating around in the user's environment are
creating hard-to-find bugs.

2. We don't want functions with indirect effects (no <<- ), almost always.

3. Code should be vectorized where possible, C style for loops over
vector members should be avoided.

4. We don't want gratuitous use of "return" at the end of functions.
Why do people still do that?

5. Neatness counts.  Code should look nice!  Check out how beautiful
the functions in MASS look! I want code with spaces and " <- " rather
than  everything jammed together with "=".

I don't mean to criticize any particular person's code in raising this
point.  For teaching exemples, where to focus?

Here's one candidate I've found:

MNP.  as far as I can tell, it meets the first 4 requirements.  And it
has some very clear C code with it as well. I'm only hesitant there
because I'm not entirely sure that a package's C code should introduce
its own functions for handling vectors and matrices, when some general
purpose library might be more desirable.  But that's a small point,
and clarity and completeness counts a great deal in my opinion.





-- 
Paul E. Johnson
Professor, Political Science
1541 Lilac Lane, Room 504
University of Kansas


From hb at biostat.ucsf.edu  Tue Feb 15 19:11:46 2011
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Tue, 15 Feb 2011 10:11:46 -0800
Subject: [Rd] matrixStats: Extend to arrays too (Was: Re: Suggestion: Adding
 quick rowMin and rowMax functions to base package)
Message-ID: <AANLkTi=W09bhrxHW=UfAsD5Ep71RkHit_HjC1xPs1RrR@mail.gmail.com>

Hi.

On Sun, Feb 13, 2011 at 10:18 AM, TakeoKatsuki <takeo.katsuki at gmail.com> wrote:
>
> Hi Henrik,
>
> It would be nice if functions of the matrixStats package can handle array
> data.
> For example, rowSums() of the base package sums along the third axis of an
> array by rowSums(x, dim=2).

That is a good idea.  This was indeed the initial objective before
starting matrixStats.  After debating (mostly with myself) on what a
consistent and solid API for arrays would look like I decided to
postpone that and just focus on matrices (the more immediate need).

A well-designed API generalized to work with arrays should probably
borrow ideas from how argument 'MARGIN' of apply() works, how argument
'dim' in rowSums() for (though I must say the letter seem a bit ad hoc
at first sight given the name of the function).  There may also be
something to learn from the 'reshape' package and so.

Having said this, code contributions toward an array-based API are
appreciated.  As a start it may be better to make the extension
independent of the existing matrix-based API, at least before a solid
array-based API has been settled.

/Henrik

> Thanks.
>
> Takeo

[snip]


From hadley at rice.edu  Tue Feb 15 19:39:54 2011
From: hadley at rice.edu (Hadley Wickham)
Date: Tue, 15 Feb 2011 18:39:54 +0000
Subject: [Rd] Request: Suggestions for "good teaching" packages,
 esp. with C code
In-Reply-To: <AANLkTikODppzk5=x7=TzVepH+aHuvaZUErf_0xQZ5ioX@mail.gmail.com>
References: <AANLkTikODppzk5=x7=TzVepH+aHuvaZUErf_0xQZ5ioX@mail.gmail.com>
Message-ID: <AANLkTim=foR6=xr2MuwRxuOkgFaUbCw-EnZFh0xvjM4t@mail.gmail.com>

I think my recent packages are pretty good. In particular, I'd
recommend string, plyr and testthat as being well written, well
documented and (somewhat) well tested.  I've also been trying to write
up the process of writing good packages.  See
https://github.com/hadley/devtools/wiki for my thoughts so far.

Hadley

On Tue, Feb 15, 2011 at 6:04 PM, Paul Johnson <pauljohn32 at gmail.com> wrote:
> Hello,
>
> I am looking for CRAN packages that don't teach bad habits. ?Can I
> have suggestions?
>
> I don't mean the recommended packages that come with R, I mean the
> contributed ones. ?I've been sampling a lot of examples and am
> surprised that many ignore seemingly agreed-upon principles of R
> coding. In r-devel, almost everyone seems to support the "functional
> programming" theme in Chambers's book on Software For Data Analysis,
> but when I go look at randomly selected packages, programmers don't
> follow that advice.
>
> In particular:
>
> 1. Functions must avoid "mystery variables from nowhere."
>
> Consider a function's code, it should not be necessary to say "what's
> variable X?" and go hunting in the commands that lead up to the
> function call. ?If X is used in the function, it should be in a named
> argument, or extracted from one of the named arguments. ?People who
> rely on variables floating around in the user's environment are
> creating hard-to-find bugs.
>
> 2. We don't want functions with indirect effects (no <<- ), almost always.
>
> 3. Code should be vectorized where possible, C style for loops over
> vector members should be avoided.
>
> 4. We don't want gratuitous use of "return" at the end of functions.
> Why do people still do that?
>
> 5. Neatness counts. ?Code should look nice! ?Check out how beautiful
> the functions in MASS look! I want code with spaces and " <- " rather
> than ?everything jammed together with "=".
>
> I don't mean to criticize any particular person's code in raising this
> point. ?For teaching exemples, where to focus?
>
> Here's one candidate I've found:
>
> MNP. ?as far as I can tell, it meets the first 4 requirements. ?And it
> has some very clear C code with it as well. I'm only hesitant there
> because I'm not entirely sure that a package's C code should introduce
> its own functions for handling vectors and matrices, when some general
> purpose library might be more desirable. ?But that's a small point,
> and clarity and completeness counts a great deal in my opinion.
>
>
>
>
>
> --
> Paul E. Johnson
> Professor, Political Science
> 1541 Lilac Lane, Room 504
> University of Kansas
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>



-- 
Assistant Professor / Dobelman Family Junior Chair
Department of Statistics / Rice University
http://had.co.nz/


From paul at stat.auckland.ac.nz  Tue Feb 15 19:51:16 2011
From: paul at stat.auckland.ac.nz (Paul Murrell)
Date: Wed, 16 Feb 2011 07:51:16 +1300
Subject: [Rd] gList and gTree methods of grid::grobX
In-Reply-To: <AANLkTikH-c7EECcu8fpgxrMGShXnX5hR3tPmy1izPafx@mail.gmail.com>
References: <AANLkTikH-c7EECcu8fpgxrMGShXnX5hR3tPmy1izPafx@mail.gmail.com>
Message-ID: <4D5ACB24.1000909@stat.auckland.ac.nz>

Hi

baptiste auguie wrote:
> Dear all,
> 
> In an attempt to draw fill patterns in grid graphics, I have
> encountered a behavior of grobX that I cannot understand from the
> documentation. Consider this,
> 
> library(grid)
> 
> ## gTree
> g1 <- gTree(children=gList(
>              rectGrob(0.5,0.5, width=unit(0.8,"npc"),
>                       height=unit(2,"cm")),
>              circleGrob(r=0.3)), vp=viewport(0.5,0.5))
> 
> ## gList
> g1 <- gList(rectGrob(0.5,0.5, width=unit(0.8,"npc"),
>                      height=unit(2,"cm")),
>             circleGrob(r=0.3))
> 
> ## loop over angles to map the boundary
> gtheta <- function(g, theta){
> 
>   sapply(theta, function(.t){
>          gx <- convertX(grobX(g, .t), "npc")
>          gy <- convertY(grobY(g, .t), "npc")
> 
>          c(gx,gy)
>        })
> 
> }
> 
> angles <- seq(0,360,by=30)
> p1 <- gtheta(g1, angles)
> 
> grid.newpage()
> grid.draw(g1)
> grid.points(p1[1,],p1[2,], gp=gpar(cex=0.2),
>             default.units="npc")
> 
> 
> If I'm not mistaken, neither gList nor gTree seem to produce the
> documented behavior,
> 
> "If the grob describes multiple shapes, the boundary value will either
> correspond to the edge of a bounding box around all of the shapes
> described by the grob (for multiple rectangles, circles, xsplines, or
> text), or to a convex hull around all vertices of all shapes described
> by the grob (for multiple polygons, points, lines, polylines, and
> segments)."

That description is referring to a single *grob* object that draws 
multiple shapes, something like ...

g1 <- circleGrob(x=1:3/4, y=1:3/4, r=.1)

... in your example.

The behaviour of gTrees is pretty much undefined, but the user is free 
to slap a class on the gTree and write their own xDetails() and 
yDetails() methods to achieve the outcome that they want.  I have 
wondered about supplying a default that makes some sort of union of the 
boundaries of the children of a gTree, but have not yet implemented that.

The gList case has been explicitly coded to produce the result from the 
last object in the gList, but I cannot recall why I ever thought that 
might be a good default.  Again, making the gList the children of a 
gTree with a specific class provides the opportunity to control what 
grobX() and grobY() return for yourself.

Paul

> with gList, I observe that the boundary is only considered for the
> first shape, whilst gTree ignores all children altogether.
> 
> It works fine for single shapes (e.g. g1 = circleGrob(r=0.3)).
> 
> The same behavior is observed with quartz(), pdf() and png().
> 
> 
> Sincerely,
> 
> baptiste
> 
> sessionInfo()
> R version 2.12.1 Patched (2010-12-30 r53895)
> Platform: i386-apple-darwin9.8.0 (32-bit)
> 
> locale:
> [1] en_GB.UTF-8/en_GB.UTF-8/C/C/en_GB.UTF-8/en_GB.UTF-8
> 
> attached base packages:
> [1] grid      stats     graphics  grDevices utils     datasets
> methods   base
> 
> loaded via a namespace (and not attached):
> [1] tools_2.12.1
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/


From hadley at rice.edu  Tue Feb 15 19:52:13 2011
From: hadley at rice.edu (Hadley Wickham)
Date: Tue, 15 Feb 2011 18:52:13 +0000
Subject: [Rd] matrixStats: Extend to arrays too (Was: Re: Suggestion:
 Adding quick rowMin and rowMax functions to base package)
In-Reply-To: <AANLkTi=W09bhrxHW=UfAsD5Ep71RkHit_HjC1xPs1RrR@mail.gmail.com>
References: <AANLkTi=W09bhrxHW=UfAsD5Ep71RkHit_HjC1xPs1RrR@mail.gmail.com>
Message-ID: <AANLkTikh_y74ny=Lt0Vm-tM8tj2EKNgyB3Vaup-e2De2@mail.gmail.com>

> A well-designed API generalized to work with arrays should probably
> borrow ideas from how argument 'MARGIN' of apply() works, how argument
> 'dim' in rowSums() for (though I must say the letter seem a bit ad hoc
> at first sight given the name of the function). ?There may also be
> something to learn from the 'reshape' package and so.

I'd also recommend looking at plyr::aaply, which fixes a few things
that have always annoyed me about apply - namely that it is not
idempotent/identical to aperm when the summary function is the
identity.

Hadley

-- 
Assistant Professor / Dobelman Family Junior Chair
Department of Statistics / Rice University
http://had.co.nz/


From jeffrey.ryan at lemnica.com  Tue Feb 15 20:19:45 2011
From: jeffrey.ryan at lemnica.com (Jeffrey Ryan)
Date: Tue, 15 Feb 2011 13:19:45 -0600
Subject: [Rd] Request: Suggestions for "good teaching" packages,
 esp. with C code
In-Reply-To: <AANLkTikODppzk5=x7=TzVepH+aHuvaZUErf_0xQZ5ioX@mail.gmail.com>
References: <AANLkTikODppzk5=x7=TzVepH+aHuvaZUErf_0xQZ5ioX@mail.gmail.com>
Message-ID: <AANLkTi=GkyHj5HerhJth-OioaBofhfied7XkrvkjrtZ2@mail.gmail.com>

I think for teaching, you need to use R itself.

Everything else is going to be a derivative from that, and if you are
looking for 'correctness' or 'consistency' with the spirit of R, you
can only be disappointed - as everyone will take liberties or bring
personal style into the equation.

In addition, your points are debatable in terms of priority/value.
e.g. what is wrong with 'return'?  Certainly provides clarity and
consistency if you have if-else constructs.

We've all learned from reading R sources, and it seems to have worked
out well for many of us.

Jeff


On Tue, Feb 15, 2011 at 12:04 PM, Paul Johnson <pauljohn32 at gmail.com> wrote:
> Hello,
>
> I am looking for CRAN packages that don't teach bad habits. ?Can I
> have suggestions?
>
> I don't mean the recommended packages that come with R, I mean the
> contributed ones. ?I've been sampling a lot of examples and am
> surprised that many ignore seemingly agreed-upon principles of R
> coding. In r-devel, almost everyone seems to support the "functional
> programming" theme in Chambers's book on Software For Data Analysis,
> but when I go look at randomly selected packages, programmers don't
> follow that advice.
>
> In particular:
>
> 1. Functions must avoid "mystery variables from nowhere."
>
> Consider a function's code, it should not be necessary to say "what's
> variable X?" and go hunting in the commands that lead up to the
> function call. ?If X is used in the function, it should be in a named
> argument, or extracted from one of the named arguments. ?People who
> rely on variables floating around in the user's environment are
> creating hard-to-find bugs.
>
> 2. We don't want functions with indirect effects (no <<- ), almost always.
>
> 3. Code should be vectorized where possible, C style for loops over
> vector members should be avoided.
>
> 4. We don't want gratuitous use of "return" at the end of functions.
> Why do people still do that?
>
> 5. Neatness counts. ?Code should look nice! ?Check out how beautiful
> the functions in MASS look! I want code with spaces and " <- " rather
> than ?everything jammed together with "=".
>
> I don't mean to criticize any particular person's code in raising this
> point. ?For teaching exemples, where to focus?
>
> Here's one candidate I've found:
>
> MNP. ?as far as I can tell, it meets the first 4 requirements. ?And it
> has some very clear C code with it as well. I'm only hesitant there
> because I'm not entirely sure that a package's C code should introduce
> its own functions for handling vectors and matrices, when some general
> purpose library might be more desirable. ?But that's a small point,
> and clarity and completeness counts a great deal in my opinion.
>
>
>
>
>
> --
> Paul E. Johnson
> Professor, Political Science
> 1541 Lilac Lane, Room 504
> University of Kansas
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>



-- 
Jeffrey Ryan
jeffrey.ryan at lemnica.com

www.lemnica.com


From ggrothendieck at gmail.com  Tue Feb 15 20:38:11 2011
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 15 Feb 2011 14:38:11 -0500
Subject: [Rd] Request: Suggestions for "good teaching" packages,
 esp. with C code
In-Reply-To: <AANLkTikODppzk5=x7=TzVepH+aHuvaZUErf_0xQZ5ioX@mail.gmail.com>
References: <AANLkTikODppzk5=x7=TzVepH+aHuvaZUErf_0xQZ5ioX@mail.gmail.com>
Message-ID: <AANLkTi=vfpWDJ4T=CehL9iL0MHDJM4iFgNAyG91DtLEF@mail.gmail.com>

On Tue, Feb 15, 2011 at 1:04 PM, Paul Johnson <pauljohn32 at gmail.com> wrote:
> Hello,
>
> I am looking for CRAN packages that don't teach bad habits. ?Can I
> have suggestions?
>
> I don't mean the recommended packages that come with R, I mean the
> contributed ones. ?I've been sampling a lot of examples and am
> surprised that many ignore seemingly agreed-upon principles of R
> coding. In r-devel, almost everyone seems to support the "functional
> programming" theme in Chambers's book on Software For Data Analysis,
> but when I go look at randomly selected packages, programmers don't
> follow that advice.
>
> In particular:
>
> 1. Functions must avoid "mystery variables from nowhere."
>
> Consider a function's code, it should not be necessary to say "what's
> variable X?" and go hunting in the commands that lead up to the
> function call. ?If X is used in the function, it should be in a named
> argument, or extracted from one of the named arguments. ?People who
> rely on variables floating around in the user's environment are
> creating hard-to-find bugs.
>
> 2. We don't want functions with indirect effects (no <<- ), almost always.
>
> 3. Code should be vectorized where possible, C style for loops over
> vector members should be avoided.
>
> 4. We don't want gratuitous use of "return" at the end of functions.
> Why do people still do that?
>
> 5. Neatness counts. ?Code should look nice! ?Check out how beautiful
> the functions in MASS look! I want code with spaces and " <- " rather
> than ?everything jammed together with "=".
>
> I don't mean to criticize any particular person's code in raising this
> point. ?For teaching exemples, where to focus?
>
> Here's one candidate I've found:
>
> MNP. ?as far as I can tell, it meets the first 4 requirements. ?And it
> has some very clear C code with it as well. I'm only hesitant there
> because I'm not entirely sure that a package's C code should introduce
> its own functions for handling vectors and matrices, when some general
> purpose library might be more desirable. ?But that's a small point,
> and clarity and completeness counts a great deal in my opinion.
>

There was some discussion of this on stats stackexchange

http://stats.stackexchange.com/questions/5418/first-r-packages-source-code-to-study-in-preparation-for-writing-own-package

-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From baptiste.auguie at googlemail.com  Tue Feb 15 20:53:43 2011
From: baptiste.auguie at googlemail.com (baptiste auguie)
Date: Tue, 15 Feb 2011 20:53:43 +0100
Subject: [Rd] gList and gTree methods of grid::grobX
In-Reply-To: <4D5ACB24.1000909@stat.auckland.ac.nz>
References: <AANLkTikH-c7EECcu8fpgxrMGShXnX5hR3tPmy1izPafx@mail.gmail.com>
	<4D5ACB24.1000909@stat.auckland.ac.nz>
Message-ID: <AANLkTi=ULcY+uKOSiZKNOOwzk3JUMBAB7PXyQOAew5Qd@mail.gmail.com>

Hi,

Thanks for the clarification. Perhaps something along those lines
could be added to the help page.

Regards,

baptiste

On 15 February 2011 19:51, Paul Murrell <paul at stat.auckland.ac.nz> wrote:
> Hi
>
> baptiste auguie wrote:
>>
>> Dear all,
>>
>> In an attempt to draw fill patterns in grid graphics, I have
>> encountered a behavior of grobX that I cannot understand from the
>> documentation. Consider this,
>>
>> library(grid)
>>
>> ## gTree
>> g1 <- gTree(children=gList(
>> ? ? ? ? ? ? rectGrob(0.5,0.5, width=unit(0.8,"npc"),
>> ? ? ? ? ? ? ? ? ? ? ?height=unit(2,"cm")),
>> ? ? ? ? ? ? circleGrob(r=0.3)), vp=viewport(0.5,0.5))
>>
>> ## gList
>> g1 <- gList(rectGrob(0.5,0.5, width=unit(0.8,"npc"),
>> ? ? ? ? ? ? ? ? ? ? height=unit(2,"cm")),
>> ? ? ? ? ? ?circleGrob(r=0.3))
>>
>> ## loop over angles to map the boundary
>> gtheta <- function(g, theta){
>>
>> ?sapply(theta, function(.t){
>> ? ? ? ? gx <- convertX(grobX(g, .t), "npc")
>> ? ? ? ? gy <- convertY(grobY(g, .t), "npc")
>>
>> ? ? ? ? c(gx,gy)
>> ? ? ? })
>>
>> }
>>
>> angles <- seq(0,360,by=30)
>> p1 <- gtheta(g1, angles)
>>
>> grid.newpage()
>> grid.draw(g1)
>> grid.points(p1[1,],p1[2,], gp=gpar(cex=0.2),
>> ? ? ? ? ? ?default.units="npc")
>>
>>
>> If I'm not mistaken, neither gList nor gTree seem to produce the
>> documented behavior,
>>
>> "If the grob describes multiple shapes, the boundary value will either
>> correspond to the edge of a bounding box around all of the shapes
>> described by the grob (for multiple rectangles, circles, xsplines, or
>> text), or to a convex hull around all vertices of all shapes described
>> by the grob (for multiple polygons, points, lines, polylines, and
>> segments)."
>
> That description is referring to a single *grob* object that draws multiple
> shapes, something like ...
>
> g1 <- circleGrob(x=1:3/4, y=1:3/4, r=.1)
>
> ... in your example.
>
> The behaviour of gTrees is pretty much undefined, but the user is free to
> slap a class on the gTree and write their own xDetails() and yDetails()
> methods to achieve the outcome that they want. ?I have wondered about
> supplying a default that makes some sort of union of the boundaries of the
> children of a gTree, but have not yet implemented that.
>
> The gList case has been explicitly coded to produce the result from the last
> object in the gList, but I cannot recall why I ever thought that might be a
> good default. ?Again, making the gList the children of a gTree with a
> specific class provides the opportunity to control what grobX() and grobY()
> return for yourself.
>
> Paul
>
>> with gList, I observe that the boundary is only considered for the
>> first shape, whilst gTree ignores all children altogether.
>>
>> It works fine for single shapes (e.g. g1 = circleGrob(r=0.3)).
>>
>> The same behavior is observed with quartz(), pdf() and png().
>>
>>
>> Sincerely,
>>
>> baptiste
>>
>> sessionInfo()
>> R version 2.12.1 Patched (2010-12-30 r53895)
>> Platform: i386-apple-darwin9.8.0 (32-bit)
>>
>> locale:
>> [1] en_GB.UTF-8/en_GB.UTF-8/C/C/en_GB.UTF-8/en_GB.UTF-8
>>
>> attached base packages:
>> [1] grid ? ? ?stats ? ? graphics ?grDevices utils ? ? datasets
>> methods ? base
>>
>> loaded via a namespace (and not attached):
>> [1] tools_2.12.1
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> --
> Dr Paul Murrell
> Department of Statistics
> The University of Auckland
> Private Bag 92019
> Auckland
> New Zealand
> 64 9 3737599 x85392
> paul at stat.auckland.ac.nz
> http://www.stat.auckland.ac.nz/~paul/
>


From spluque at gmail.com  Tue Feb 15 21:26:22 2011
From: spluque at gmail.com (Sebastian P. Luque)
Date: Tue, 15 Feb 2011 14:26:22 -0600
Subject: [Rd] Request: Suggestions for "good teaching" packages,
	esp. with C code
In-Reply-To: <AANLkTikODppzk5=x7=TzVepH+aHuvaZUErf_0xQZ5ioX@mail.gmail.com>
	(Paul Johnson's message of "Tue, 15 Feb 2011 12:04:42 -0600")
References: <AANLkTikODppzk5=x7=TzVepH+aHuvaZUErf_0xQZ5ioX@mail.gmail.com>
Message-ID: <87fwrpkpsh.fsf@kolob.sebmags.homelinux.org>

Hi Paul,

You might want to post this to the teaching list (R-sig-teaching).  I'd
look at packages written by old-timers and R Core.  I've also found that
most Bioconductor packages follow the guidelines you mention and many
other excellent habits very well.  I agree with you that these are very
important things to teach.

Seb



On Tue, 15 Feb 2011 12:04:42 -0600,
Paul Johnson <pauljohn32 at gmail.com> wrote:

> Hello, I am looking for CRAN packages that don't teach bad habits.
> Can I have suggestions?

> I don't mean the recommended packages that come with R, I mean the
> contributed ones.  I've been sampling a lot of examples and am
> surprised that many ignore seemingly agreed-upon principles of R
> coding. In r-devel, almost everyone seems to support the "functional
> programming" theme in Chambers's book on Software For Data Analysis,
> but when I go look at randomly selected packages, programmers don't
> follow that advice.

> In particular:

> 1. Functions must avoid "mystery variables from nowhere."

> Consider a function's code, it should not be necessary to say "what's
> variable X?" and go hunting in the commands that lead up to the
> function call.  If X is used in the function, it should be in a named
> argument, or extracted from one of the named arguments.  People who
> rely on variables floating around in the user's environment are
> creating hard-to-find bugs.

> 2. We don't want functions with indirect effects (no <<- ), almost
> always.

> 3. Code should be vectorized where possible, C style for loops over
> vector members should be avoided.

> 4. We don't want gratuitous use of "return" at the end of functions.
> Why do people still do that?

> 5. Neatness counts.  Code should look nice!  Check out how beautiful
> the functions in MASS look! I want code with spaces and " <- " rather
> than everything jammed together with "=".

> I don't mean to criticize any particular person's code in raising this
> point.  For teaching exemples, where to focus?

> Here's one candidate I've found:

> MNP.  as far as I can tell, it meets the first 4 requirements.  And it
> has some very clear C code with it as well. I'm only hesitant there
> because I'm not entirely sure that a package's C code should introduce
> its own functions for handling vectors and matrices, when some general
> purpose library might be more desirable.  But that's a small point,
> and clarity and completeness counts a great deal in my opinion.


-- 
Seb


From jmc at r-project.org  Tue Feb 15 21:52:00 2011
From: jmc at r-project.org (John Chambers)
Date: Tue, 15 Feb 2011 12:52:00 -0800
Subject: [Rd] Reference classes and ".requireCachedGenerics"
In-Reply-To: <AANLkTin+UGGVnk7XRWa5i2Y+3w_hC7rfTRpTh1SG+18j@mail.gmail.com>
References: <AANLkTin+UGGVnk7XRWa5i2Y+3w_hC7rfTRpTh1SG+18j@mail.gmail.com>
Message-ID: <4D5AE770.3090201@r-project.org>

No worries, and we will get rid of the warning message.

Certain of the S4 classes require methods for particular primitive 
functions.  If a subclass of one of those classes is loaded from a 
package, then we need to turn on method dispatch for the corresponding 
primitive(s).  For efficiency, this information is precomputed and 
stored in the variable you mentioned.  It's quite reasonable for several 
instances to be encountered.  Nothing specific to reference classes 
except that they need, e.g., methods for `$`.

The variable name can be added to a "dont.mind" list to suppress the 
warning.

Thanks for the catch.

John


On 2/15/11 9:45 AM, Jon Clayden wrote:
> Dear all,
>
> If I load a package which creates reference classes whilst another
> such package is also loaded, I get a warning about masking of the
> ".requireCachedGenerics" variable. (FWIW, both packages are
> lazy-loaded.) Googling this variable name turned up only one previous
> discussion, which didn't immediately help, except to suggest that it
> may be related to my defining an S3 method for one or more of the
> classes. It also pointed me at bits of the R source, but it wasn't
> obvious to me from that, what this variable is for.
>
> Aside from being a nuisance, I wonder if this is indicative of a
> problem on R's side or on mine, so I'd be glad for any clarification.
>
> This is R 2.12.1 on Mac OS X.6.6, though it still happens with the new
> 2.12.2 beta. Any feedback welcome.
>
> Thanks,
> Jon
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From d.scott at auckland.ac.nz  Tue Feb 15 22:48:24 2011
From: d.scott at auckland.ac.nz (David Scott)
Date: Wed, 16 Feb 2011 10:48:24 +1300
Subject: [Rd] Request: Suggestions for "good teaching" packages,
 esp. with C code
In-Reply-To: <AANLkTikODppzk5=x7=TzVepH+aHuvaZUErf_0xQZ5ioX@mail.gmail.com>
References: <AANLkTikODppzk5=x7=TzVepH+aHuvaZUErf_0xQZ5ioX@mail.gmail.com>
Message-ID: <4D5AF4A8.50001@auckland.ac.nz>

On 16/02/2011 7:04 a.m., Paul Johnson wrote:
> Hello,
>
> I am looking for CRAN packages that don't teach bad habits.  Can I
> have suggestions?
>
> I don't mean the recommended packages that come with R, I mean the
> contributed ones.  I've been sampling a lot of examples and am
> surprised that many ignore seemingly agreed-upon principles of R
> coding. In r-devel, almost everyone seems to support the "functional
> programming" theme in Chambers's book on Software For Data Analysis,
> but when I go look at randomly selected packages, programmers don't
> follow that advice.
>
> In particular:
>
> 1. Functions must avoid "mystery variables from nowhere."
>
> Consider a function's code, it should not be necessary to say "what's
> variable X?" and go hunting in the commands that lead up to the
> function call.  If X is used in the function, it should be in a named
> argument, or extracted from one of the named arguments.  People who
> rely on variables floating around in the user's environment are
> creating hard-to-find bugs.
>
> 2. We don't want functions with indirect effects (no<<- ), almost always.
>
> 3. Code should be vectorized where possible, C style for loops over
> vector members should be avoided.
>
> 4. We don't want gratuitous use of "return" at the end of functions.
> Why do people still do that?

Well I for one (and Jeff as well it seems) think it is good programming 
practice. It makes explicit what is being returned eliminating the 
possibility of mistakes and provides clarity for anyone reading the code.

David Scott

>
> 5. Neatness counts.  Code should look nice!  Check out how beautiful
> the functions in MASS look! I want code with spaces and "<- " rather
> than  everything jammed together with "=".
>
> I don't mean to criticize any particular person's code in raising this
> point.  For teaching exemples, where to focus?
>
> Here's one candidate I've found:
>
> MNP.  as far as I can tell, it meets the first 4 requirements.  And it
> has some very clear C code with it as well. I'm only hesitant there
> because I'm not entirely sure that a package's C code should introduce
> its own functions for handling vectors and matrices, when some general
> purpose library might be more desirable.  But that's a small point,
> and clarity and completeness counts a great deal in my opinion.
>
>
>
>
>


-- 
_________________________________________________________________
David Scott	Department of Statistics
		The University of Auckland, PB 92019
		Auckland 1142,    NEW ZEALAND
Phone: +64 9 923 5055, or +64 9 373 7599 ext 85055
Email:	d.scott at auckland.ac.nz,  Fax: +64 9 373 7018

Director of Consulting, Department of Statistics


From geoffjentry at hexdump.org  Tue Feb 15 22:55:30 2011
From: geoffjentry at hexdump.org (Geoff Jentry)
Date: Tue, 15 Feb 2011 13:55:30 -0800 (PST)
Subject: [Rd] Request: Suggestions for "good teaching" packages,
 esp. with C code
In-Reply-To: <4D5AF4A8.50001@auckland.ac.nz>
References: <AANLkTikODppzk5=x7=TzVepH+aHuvaZUErf_0xQZ5ioX@mail.gmail.com>
	<4D5AF4A8.50001@auckland.ac.nz>
Message-ID: <Pine.LNX.4.64.1102151353000.13921@cardinals.dreamhost.com>

On Wed, 16 Feb 2011, David Scott wrote:
>> 4. We don't want gratuitous use of "return" at the end of functions.
>> Why do people still do that?
> Well I for one (and Jeff as well it seems) think it is good programming 
> practice. It makes explicit what is being returned eliminating the 
> possibility of mistakes and provides clarity for anyone reading the code.

You're unnecessarily adding the overhead of a function call by explicitly 
calling return().

Sure it seems odd for someone coming from the C/C++/Java/etc world, but 
anyone familiar with R should find code that doesn't have an explicit 
return() call to be fully readable & clear.

-J


From simon.urbanek at r-project.org  Tue Feb 15 23:05:54 2011
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Tue, 15 Feb 2011 17:05:54 -0500
Subject: [Rd] Using rasterImage on a CairoWin device prevents adding
	further elements to device?
In-Reply-To: <AANLkTikng2NZ0doG0W-ZXLjr-JEmV6sQ=bv28eR2REyw@mail.gmail.com>
References: <AANLkTikng2NZ0doG0W-ZXLjr-JEmV6sQ=bv28eR2REyw@mail.gmail.com>
Message-ID: <E4359DF4-52EF-426E-95A5-9A21747830A6@r-project.org>

Joris,

I have added raster support only recently (last week ;)) and there was a bug causing what you see. I have fixed it now so Cairo 1.4-7 will have the fix.

Thanks,
Simon


On Feb 15, 2011, at 9:48 AM, Joris Meys wrote:

> I was pointed to the Cairo package for plotting PNG images on a
> device. I've been playing around with it, but found that after I use
> the rasterImage function, I can't add anything any more to the device,
> eg :
> 
> img <- readPNG(system.file("img", "Rlogo.png", package="png"))
> r = as.raster(img[,,1:3])
> r[img[,,4] == 0] = "white"
> 
> CairoWin()
> plot(1:2,1:2,type="l")
> rasterImage(r,1,1,2,2)
> points(seq(1,2,by=0.1),seq(2,1,by=-0.1),col="black")
> 
> The points are not plotted anymore.
> 
> If I use the normal plotting device, I see the points plotted on top
> of the image.
> 
> Cheers
> Joris
> 
> 
> -- 
> Joris Meys
> Statistical consultant
> 
> Ghent University
> Faculty of Bioscience Engineering
> Department of Applied mathematics, biometrics and process control
> 
> tel : +32 9 264 59 87
> Joris.Meys at Ugent.be
> -------------------------------
> Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php
> 
> 


From kw.stat at gmail.com  Tue Feb 15 23:22:58 2011
From: kw.stat at gmail.com (Kevin Wright)
Date: Tue, 15 Feb 2011 16:22:58 -0600
Subject: [Rd] Request: Suggestions for "good teaching" packages,
 esp. with C code
In-Reply-To: <Pine.LNX.4.64.1102151353000.13921@cardinals.dreamhost.com>
References: <AANLkTikODppzk5=x7=TzVepH+aHuvaZUErf_0xQZ5ioX@mail.gmail.com>
	<4D5AF4A8.50001@auckland.ac.nz>
	<Pine.LNX.4.64.1102151353000.13921@cardinals.dreamhost.com>
Message-ID: <AANLkTikn+t2V22x4bv1hg+1B7_WE7y3aPfS+MFMFwwRy@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110215/41d6eadc/attachment.pl>

From geoffjentry at hexdump.org  Tue Feb 15 23:25:32 2011
From: geoffjentry at hexdump.org (Geoff Jentry)
Date: Tue, 15 Feb 2011 14:25:32 -0800 (PST)
Subject: [Rd] Request: Suggestions for "good teaching" packages,
 esp. with C code
In-Reply-To: <AANLkTikn+t2V22x4bv1hg+1B7_WE7y3aPfS+MFMFwwRy@mail.gmail.com>
References: <AANLkTikODppzk5=x7=TzVepH+aHuvaZUErf_0xQZ5ioX@mail.gmail.com>
	<4D5AF4A8.50001@auckland.ac.nz>
	<Pine.LNX.4.64.1102151353000.13921@cardinals.dreamhost.com>
	<AANLkTikn+t2V22x4bv1hg+1B7_WE7y3aPfS+MFMFwwRy@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.1102151424300.13921@cardinals.dreamhost.com>

> f1 <- function(){
>  a=5
> }

The primary difference is that function 1 uses an incorrect assignment 
operator in an attempt to cause confusion ;)


From jmc at r-project.org  Tue Feb 15 23:26:31 2011
From: jmc at r-project.org (John Chambers)
Date: Tue, 15 Feb 2011 14:26:31 -0800
Subject: [Rd] Reference classes and ".requireCachedGenerics"
In-Reply-To: <4D5AE770.3090201@r-project.org>
References: <AANLkTin+UGGVnk7XRWa5i2Y+3w_hC7rfTRpTh1SG+18j@mail.gmail.com>
	<4D5AE770.3090201@r-project.org>
Message-ID: <4D5AFD97.1020106@r-project.org>

PS: this is another glitch that arises when you don't use NAMESPACE 
files.  If the .requireCachedGenerics is in a NAMESPACE and not 
exported, the conflict does not arise.

On 2/15/11 12:52 PM, John Chambers wrote:
> No worries, and we will get rid of the warning message.
>
> Certain of the S4 classes require methods for particular primitive
> functions. If a subclass of one of those classes is loaded from a
> package, then we need to turn on method dispatch for the corresponding
> primitive(s). For efficiency, this information is precomputed and stored
> in the variable you mentioned. It's quite reasonable for several
> instances to be encountered. Nothing specific to reference classes
> except that they need, e.g., methods for `$`.
>
> The variable name can be added to a "dont.mind" list to suppress the
> warning.
>
> Thanks for the catch.
>
> John
>
>
> On 2/15/11 9:45 AM, Jon Clayden wrote:
>> Dear all,
>>
>> If I load a package which creates reference classes whilst another
>> such package is also loaded, I get a warning about masking of the
>> ".requireCachedGenerics" variable. (FWIW, both packages are
>> lazy-loaded.) Googling this variable name turned up only one previous
>> discussion, which didn't immediately help, except to suggest that it
>> may be related to my defining an S3 method for one or more of the
>> classes. It also pointed me at bits of the R source, but it wasn't
>> obvious to me from that, what this variable is for.
>>
>> Aside from being a nuisance, I wonder if this is indicative of a
>> problem on R's side or on mine, so I'd be glad for any clarification.
>>
>> This is R 2.12.1 on Mac OS X.6.6, though it still happens with the new
>> 2.12.2 beta. Any feedback welcome.
>>
>> Thanks,
>> Jon
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From jeffrey.ryan at lemnica.com  Tue Feb 15 23:29:52 2011
From: jeffrey.ryan at lemnica.com (Jeffrey Ryan)
Date: Tue, 15 Feb 2011 16:29:52 -0600
Subject: [Rd] Request: Suggestions for "good teaching" packages,
 esp. with C code
In-Reply-To: <AANLkTikn+t2V22x4bv1hg+1B7_WE7y3aPfS+MFMFwwRy@mail.gmail.com>
References: <AANLkTikODppzk5=x7=TzVepH+aHuvaZUErf_0xQZ5ioX@mail.gmail.com>
	<4D5AF4A8.50001@auckland.ac.nz>
	<Pine.LNX.4.64.1102151353000.13921@cardinals.dreamhost.com>
	<AANLkTikn+t2V22x4bv1hg+1B7_WE7y3aPfS+MFMFwwRy@mail.gmail.com>
Message-ID: <AANLkTi=TUMLoimg179_i4vNNMesqeVLSLcSEPVjfCxSW@mail.gmail.com>

f3 <- function() {
  ( a <- 5 )
}

f4 <- function() {
  a <- 5
  a
}

On my machine f1,f2, and f4 all perform approx. the same.  The () in
f3 adds about 20% overhead.

Jeff

On Tue, Feb 15, 2011 at 4:22 PM, Kevin Wright <kw.stat at gmail.com> wrote:
> For those of you "familiar with R", here's a little quiz. ?What what's the
> difference between:
>
>
> f1 <- function(){
> ?a=5
> }
> f1()
>
> f2 <- function(){
> ?return(a=5)
> }
> f2()
>
>
> Kevin Wright
>
>
>
>
> On Tue, Feb 15, 2011 at 3:55 PM, Geoff Jentry <geoffjentry at hexdump.org>wrote:
>
>> On Wed, 16 Feb 2011, David Scott wrote:
>>
>>> 4. We don't want gratuitous use of "return" at the end of functions.
>>>> Why do people still do that?
>>>>
>>> Well I for one (and Jeff as well it seems) think it is good programming
>>> practice. It makes explicit what is being returned eliminating the
>>> possibility of mistakes and provides clarity for anyone reading the code.
>>>
>>
>> You're unnecessarily adding the overhead of a function call by explicitly
>> calling return().
>>
>> Sure it seems odd for someone coming from the C/C++/Java/etc world, but
>> anyone familiar with R should find code that doesn't have an explicit
>> return() call to be fully readable & clear.
>>
>> -J
>>
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>



-- 
Jeffrey Ryan
jeffrey.ryan at lemnica.com

www.lemnica.com


From ggrothendieck at gmail.com  Tue Feb 15 23:35:01 2011
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 15 Feb 2011 17:35:01 -0500
Subject: [Rd] Request: Suggestions for "good teaching" packages,
 esp. with C code
In-Reply-To: <4D5AF4A8.50001@auckland.ac.nz>
References: <AANLkTikODppzk5=x7=TzVepH+aHuvaZUErf_0xQZ5ioX@mail.gmail.com>
	<4D5AF4A8.50001@auckland.ac.nz>
Message-ID: <AANLkTikOVVyMF0Xjn2Re9JLekvKoi2euZdZodEJnN9WM@mail.gmail.com>

On Tue, Feb 15, 2011 at 4:48 PM, David Scott <d.scott at auckland.ac.nz> wrote:
> On 16/02/2011 7:04 a.m., Paul Johnson wrote:
>>
>> Hello,
>>
>> I am looking for CRAN packages that don't teach bad habits. ?Can I
>> have suggestions?
>>
>> I don't mean the recommended packages that come with R, I mean the
>> contributed ones. ?I've been sampling a lot of examples and am
>> surprised that many ignore seemingly agreed-upon principles of R
>> coding. In r-devel, almost everyone seems to support the "functional
>> programming" theme in Chambers's book on Software For Data Analysis,
>> but when I go look at randomly selected packages, programmers don't
>> follow that advice.
>>
>> In particular:
>>
>> 1. Functions must avoid "mystery variables from nowhere."
>>
>> Consider a function's code, it should not be necessary to say "what's
>> variable X?" and go hunting in the commands that lead up to the
>> function call. ?If X is used in the function, it should be in a named
>> argument, or extracted from one of the named arguments. ?People who
>> rely on variables floating around in the user's environment are
>> creating hard-to-find bugs.
>>
>> 2. We don't want functions with indirect effects (no<<- ), almost always.
>>
>> 3. Code should be vectorized where possible, C style for loops over
>> vector members should be avoided.
>>
>> 4. We don't want gratuitous use of "return" at the end of functions.
>> Why do people still do that?
>
> Well I for one (and Jeff as well it seems) think it is good programming
> practice. It makes explicit what is being returned eliminating the
> possibility of mistakes and provides clarity for anyone reading the code.
>

I think the real good programming practice is to have a single point
of exit at the bottom.   If that is how you program all your functions
then you don't need to explicitly put a return in since it always
returns from the bottom anyways and the return would just clutter your
code.

Sometimes the single point of exit at the bottom is a soft rule in
which the rule is encouraged but if there is significant code
expansion on that account then the rule is broken.

-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From Ken.Williams at thomsonreuters.com  Tue Feb 15 23:43:16 2011
From: Ken.Williams at thomsonreuters.com (Ken.Williams at thomsonreuters.com)
Date: Tue, 15 Feb 2011 16:43:16 -0600
Subject: [Rd] Request: Suggestions for "good teaching" packages,
 esp. with C code
In-Reply-To: <AANLkTikOVVyMF0Xjn2Re9JLekvKoi2euZdZodEJnN9WM@mail.gmail.com>
Message-ID: <C9805C71.23A27%ken.williams@thomsonreuters.com>


On 2/15/11 4:35 PM, "Gabor Grothendieck" <ggrothendieck at gmail.com> wrote:

>I think the real good programming practice is to have a single point
>of exit at the bottom.

I disagree, it can be extremely useful to exit early from a function.  It
can also make the code much more clear by not having 95% of the body in a
huge else{} block.


>If that is how you program all your functions
>then you don't need to explicitly put a return in since it always
>returns from the bottom anyways and the return would just clutter your
>code.

For someone else reading your code, they wouldn't know that you always do
this unless they're very familiar with your coding style.  Even then, it
needs to be manually checked by inspection because nobody sticks with the
"rule" 100% of the time, so it renders the benefit moot.

--
Ken Williams
Senior Research Scientist
Thomson Reuters
Phone: 651-848-7712
ken.williams at thomsonreuters.com
http://labs.thomsonreuters.com


From d.scott at auckland.ac.nz  Tue Feb 15 23:59:35 2011
From: d.scott at auckland.ac.nz (David Scott)
Date: Wed, 16 Feb 2011 11:59:35 +1300
Subject: [Rd] Request: Suggestions for "good teaching" packages,
 esp. with C code
In-Reply-To: <C9805C71.23A27%ken.williams@thomsonreuters.com>
References: <C9805C71.23A27%ken.williams@thomsonreuters.com>
Message-ID: <4D5B0557.9020108@auckland.ac.nz>

On 16/02/2011 11:43 a.m., Ken.Williams at thomsonreuters.com wrote:
>
> On 2/15/11 4:35 PM, "Gabor Grothendieck"<ggrothendieck at gmail.com>  wrote:
>
>> I think the real good programming practice is to have a single point
>> of exit at the bottom.
>
> I disagree, it can be extremely useful to exit early from a function.  It
> can also make the code much more clear by not having 95% of the body in a
> huge else{} block.
>
>
>> If that is how you program all your functions
>> then you don't need to explicitly put a return in since it always
>> returns from the bottom anyways and the return would just clutter your
>> code.
>
> For someone else reading your code, they wouldn't know that you always do
> this unless they're very familiar with your coding style.  Even then, it
> needs to be manually checked by inspection because nobody sticks with the
> "rule" 100% of the time, so it renders the benefit moot.
>
> --
> Ken Williams
> Senior Research Scientist
> Thomson Reuters
> Phone: 651-848-7712
> ken.williams at thomsonreuters.com
> http://labs.thomsonreuters.com
>
>
Some interesting discussion on this point. Enlightening for me at least.

A quick test showed me that an explicit return does produce about a 20% 
time hit in a one-line function (obviously a lesser % in a non-trivial 
function) but enough to convince me not to use an explicit return in 
functions where what is being returned is obvious.

Gabor's point is a good one, there *should* be a single exit point at 
the bottom, but I have certainly had situations where an early exit 
seems preferable as Ken suggests. Then an explicit return may make the 
code sufficiently clear for a violation of Gabor's principle to be 
acceptable.

David Scott






-- 
_________________________________________________________________
David Scott	Department of Statistics
		The University of Auckland, PB 92019
		Auckland 1142,    NEW ZEALAND
Phone: +64 9 923 5055, or +64 9 373 7599 ext 85055
Email:	d.scott at auckland.ac.nz,  Fax: +64 9 373 7018

Director of Consulting, Department of Statistics


From ggrothendieck at gmail.com  Wed Feb 16 00:09:52 2011
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 15 Feb 2011 18:09:52 -0500
Subject: [Rd] Request: Suggestions for "good teaching" packages,
 esp. with C code
In-Reply-To: <C9805C71.23A27%ken.williams@thomsonreuters.com>
References: <AANLkTikOVVyMF0Xjn2Re9JLekvKoi2euZdZodEJnN9WM@mail.gmail.com>
	<C9805C71.23A27%ken.williams@thomsonreuters.com>
Message-ID: <AANLkTi=z8JwjNtnKO7c_ouPktPsk0nE0E9-mGAdt10Vs@mail.gmail.com>

On Tue, Feb 15, 2011 at 5:43 PM,  <Ken.Williams at thomsonreuters.com> wrote:
>
> On 2/15/11 4:35 PM, "Gabor Grothendieck" <ggrothendieck at gmail.com> wrote:
>
>>I think the real good programming practice is to have a single point
>>of exit at the bottom.
>
> I disagree, it can be extremely useful to exit early from a function. ?It
> can also make the code much more clear by not having 95% of the body in a
> huge else{} block.
>

If that is the case then the routines may be too large.  One of the
purposes of this widely practiced principle is to encourage
modularity.

Also achieving code coverage can be simplified when using single point
of return rather than multiple points of return.

-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From murdoch.duncan at gmail.com  Wed Feb 16 00:10:24 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 15 Feb 2011 18:10:24 -0500
Subject: [Rd] Request: Suggestions for "good teaching" packages,
 esp. with C code
In-Reply-To: <AANLkTikn+t2V22x4bv1hg+1B7_WE7y3aPfS+MFMFwwRy@mail.gmail.com>
References: <AANLkTikODppzk5=x7=TzVepH+aHuvaZUErf_0xQZ5ioX@mail.gmail.com>	<4D5AF4A8.50001@auckland.ac.nz>	<Pine.LNX.4.64.1102151353000.13921@cardinals.dreamhost.com>
	<AANLkTikn+t2V22x4bv1hg+1B7_WE7y3aPfS+MFMFwwRy@mail.gmail.com>
Message-ID: <4D5B07E0.4020508@gmail.com>

On 15/02/2011 5:22 PM, Kevin Wright wrote:
> For those of you "familiar with R", here's a little quiz.  What what's the
> difference between:
>
>
> f1<- function(){
>    a=5
> }

This returns 5, invisibly.  It's also bad style, according to those of 
us who prefer <- to = for assignment.

> f2<- function(){
>    return(a=5)
> }

This is a mistake:  return() doesn't take named arguments.  It is 
lenient and lets you get away with this error (treating it the same as
return(5)), and returns the 5, visibly.

Duncan Murdoch

> f2()
>
>
> Kevin Wright
>
>
>
>
> On Tue, Feb 15, 2011 at 3:55 PM, Geoff Jentry<geoffjentry at hexdump.org>wrote:
>
>> On Wed, 16 Feb 2011, David Scott wrote:
>>
>>> 4. We don't want gratuitous use of "return" at the end of functions.
>>>> Why do people still do that?
>>>>
>>> Well I for one (and Jeff as well it seems) think it is good programming
>>> practice. It makes explicit what is being returned eliminating the
>>> possibility of mistakes and provides clarity for anyone reading the code.
>>>
>>
>> You're unnecessarily adding the overhead of a function call by explicitly
>> calling return().
>>
>> Sure it seems odd for someone coming from the C/C++/Java/etc world, but
>> anyone familiar with R should find code that doesn't have an explicit
>> return() call to be fully readable&  clear.
>>
>> -J
>>
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From smckinney at bccrc.ca  Wed Feb 16 00:47:02 2011
From: smckinney at bccrc.ca (Steven McKinney)
Date: Tue, 15 Feb 2011 15:47:02 -0800
Subject: [Rd] Request: Suggestions for "good teaching" packages,
 esp. with C code
In-Reply-To: <20386_1297811446_1297811446_4D5B07E0.4020508@gmail.com>
References: <AANLkTikODppzk5=x7=TzVepH+aHuvaZUErf_0xQZ5ioX@mail.gmail.com>
	<4D5AF4A8.50001@auckland.ac.nz>
	<Pine.LNX.4.64.1102151353000.13921@cardinals.dreamhost.com>
	<AANLkTikn+t2V22x4bv1hg+1B7_WE7y3aPfS+MFMFwwRy@mail.gmail.com>
	<20386_1297811446_1297811446_4D5B07E0.4020508@gmail.com>
Message-ID: <DCE81E14EB74504B971DAD4D2DB0356B0864727E6A@crcmail4.BCCRC.CA>


> -----Original Message-----
> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org] On Behalf Of Duncan Murdoch
> Sent: February-15-11 3:10 PM
> To: Kevin Wright
> Cc: R Devel List
> Subject: Re: [Rd] Request: Suggestions for "good teaching" packages, esp. with C code
> 
> On 15/02/2011 5:22 PM, Kevin Wright wrote:
> > For those of you "familiar with R", here's a little quiz.  What what's the
> > difference between:
> >
> >
> > f1<- function(){
> >    a=5
> > }
> 
> This returns 5, invisibly.  It's also bad style, according to those of
> us who prefer <- to = for assignment.

For maximum clarity

f0 <- function() {
    b <- 5
    return( list( a = b ) )
}

> f0()
$a
[1] 5


Steven McKinney

> 
> > f2<- function(){
> >    return(a=5)
> > }
> 
> This is a mistake:  return() doesn't take named arguments.  It is
> lenient and lets you get away with this error (treating it the same as
> return(5)), and returns the 5, visibly.
> 
> Duncan Murdoch
> 
> > f2()
> >
> >
> > Kevin Wright
> >
> >
> >
> >
> > On Tue, Feb 15, 2011 at 3:55 PM, Geoff Jentry<geoffjentry at hexdump.org>wrote:
> >
> >> On Wed, 16 Feb 2011, David Scott wrote:
> >>
> >>> 4. We don't want gratuitous use of "return" at the end of functions.
> >>>> Why do people still do that?
> >>>>
> >>> Well I for one (and Jeff as well it seems) think it is good programming
> >>> practice. It makes explicit what is being returned eliminating the
> >>> possibility of mistakes and provides clarity for anyone reading the code.
> >>>
> >>
> >> You're unnecessarily adding the overhead of a function call by explicitly
> >> calling return().
> >>
> >> Sure it seems odd for someone coming from the C/C++/Java/etc world, but
> >> anyone familiar with R should find code that doesn't have an explicit
> >> return() call to be fully readable&  clear.
> >>
> >> -J
> >>
> >>
> >> ______________________________________________
> >> R-devel at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-devel
> >>
> >
> > 	[[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From r.ted.byers at gmail.com  Wed Feb 16 02:44:53 2011
From: r.ted.byers at gmail.com (Ted Byers)
Date: Tue, 15 Feb 2011 20:44:53 -0500
Subject: [Rd] Request: Suggestions for "good teaching" packages,
	esp. with C code
In-Reply-To: <AANLkTi=z8JwjNtnKO7c_ouPktPsk0nE0E9-mGAdt10Vs@mail.gmail.com>
References: <AANLkTikOVVyMF0Xjn2Re9JLekvKoi2euZdZodEJnN9WM@mail.gmail.com>
	<C9805C71.23A27%ken.williams@thomsonreuters.com>
	<AANLkTi=z8JwjNtnKO7c_ouPktPsk0nE0E9-mGAdt10Vs@mail.gmail.com>
Message-ID: <04c101cbcd7b$1cfdaed0$56f90c70$@gmail.com>

>From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org]
On Behalf Of Gabor Grothendieck
>Sent: February-15-11 6:10 PM
>On Tue, Feb 15, 2011 at 5:43 PM,  <Ken.Williams at thomsonreuters.com> wrote:
>>
>> On 2/15/11 4:35 PM, "Gabor Grothendieck" <ggrothendieck at gmail.com> wrote:
>>
>>>I think the real good programming practice is to have a single point 
>>>of exit at the bottom.

NB: I am drawing on my experience with C++ and Java, as I have 10x as much
experience  with them as I do with R)

It  is often not practicable to use a single point of exit.  I routinely
have checked all the requirements/assumptions of my code at the beginning,
to ensure error conditions do not arise once the code that does the real
work gets started.  That means that there is as least one exit point between
the beginning of my checks and the beginning of my code that is doing the
real work; often more.  These exits generally include construction of an
error condition object with the details of what the error is and why it
happened. (but that is my high performance C++ code, and Gui code written in
Java).

>> I disagree, it can be extremely useful to exit early from a function. ?
>> It can also make the code much more clear by not having 95% of the 
>> body in a huge else{} block.
>>
>
>If that is the case then the routines may be too large.  One of the
purposes of this widely practiced principle is to encourage modularity.

This I'd agree with, to an extent.  I routinely try to keep my functions
short enough to be able to see the whole thing without scrolling.  This
means I break large tasks into a number of small ones, implemented in
functions that can be inlined.    And of course, such small functions make
writing complex conditional blocks much easier and it makes them much more
readable.  Thus, if you looked at my C++ code, you'd find a large number of
smaller functions with a single exit, and a small, but significant, portion
of my functions are a bit longer with multiple exits.

>Also achieving code coverage can be simplified when using single point of
return rather than multiple points of return.

This is an issue only if your code is badly designed spaghetti code.    if
your function is that long, it will be a nightmare to write decent unit test
that test all possible paths through the code, let alone those tests
required to verify that the result it produces is correct.  But if you have
ensured that all your functions can be viewed on your screen without
scrolling, it is easy to see all exit points, and write unit tests for each.
The functions that test for conditions that can produce errors often form
the basis of the unit tests needed for testing every possible exit point
(basically killing two birds with one stone).  This is relatively simple if
handled right, with a good eye for detail.

One of the things I would point out is that such generalities can be useful
in introducing young people to programming, but it is wise not to be too
dogmatic or generalize too widely.

Cheers

Ted


From janko.thyson.rstuff at googlemail.com  Wed Feb 16 10:29:16 2011
From: janko.thyson.rstuff at googlemail.com (Janko Thyson)
Date: Wed, 16 Feb 2011 10:29:16 +0100
Subject: [Rd] Avoiding name clashes: opinion on best practice naming
	conventions
Message-ID: <4d5b98ec.4c02cc0a.13fe.476c@mx.google.com>

Dear List,

I'm trying to figure out some best practice way with respect to the naming
conventions when building own packages.

I'd like to minimize the risk of choosing function names that might
interfere with those of other packages (both available ones and those yet to
come).

I came up with following alternatives
1. Prefixing the actual names (e.g. myPkgfoo() instead of foo()): pretty
verbose
2. Emulating a package namespace while developing and explicitly using
myPkg::foo() in all scripts: IMHO the best way, but apparently not possible
as I learned. 
3. Carefully choosing which functions to export. Yet, I'm not sure I
completely understand the implications of exported functions. Does this
imply that not exported functions cannot interfere with functions in other
namespaces?

I'd be great to hear some recommendations on this one!

Thanks a lot,
Janko


From murdoch.duncan at gmail.com  Wed Feb 16 13:26:47 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 16 Feb 2011 07:26:47 -0500
Subject: [Rd] Avoiding name clashes: opinion on best practice naming
	conventions
In-Reply-To: <4d5b98ec.4c02cc0a.13fe.476c@mx.google.com>
References: <4d5b98ec.4c02cc0a.13fe.476c@mx.google.com>
Message-ID: <4D5BC287.8070404@gmail.com>

On 11-02-16 4:29 AM, Janko Thyson wrote:
> Dear List,
>
> I'm trying to figure out some best practice way with respect to the naming
> conventions when building own packages.
>
> I'd like to minimize the risk of choosing function names that might
> interfere with those of other packages (both available ones and those yet to
> come).
>
> I came up with following alternatives
> 1. Prefixing the actual names (e.g. myPkgfoo() instead of foo()): pretty
> verbose

Another verbose solution is to use descriptive names for your functions. 
  Then you'll only clash with functions that are trying to do the same 
thing.

> 2. Emulating a package namespace while developing and explicitly using
> myPkg::foo() in all scripts: IMHO the best way, but apparently not possible
> as I learned.

Is it really a problem when developing?  Surely you can control which 
other packages are loaded, and just choose names that don't clash with 
those?  The real problem with name clashes comes when your package is 
out in the wild, and a user wants to use your package and an unrelated 
one at the same time.  If you both have a foo() function that user's 
scripts could change depending on the search order.

> 3. Carefully choosing which functions to export. Yet, I'm not sure I
> completely understand the implications of exported functions. Does this
> imply that not exported functions cannot interfere with functions in other
> namespaces?

You should definitely do this.  Functions which are not exported will 
not be visible to other packages without a prefix, so they won't clash. 
  Your package will be guaranteed to see its own functions first.  A 
user can still have a clash between your exported functions and some 
other package's exports, but with fewer functions exported, that will 
not be as much of a problem.

Duncan Murdoch
>
> I'd be great to hear some recommendations on this one!
>
> Thanks a lot,
> Janko
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From martin.becker at mx.uni-saarland.de  Wed Feb 16 13:31:20 2011
From: martin.becker at mx.uni-saarland.de (Martin Becker)
Date: Wed, 16 Feb 2011 13:31:20 +0100
Subject: [Rd] Request: Suggestions for "good teaching" packages,
 esp. with C code
In-Reply-To: <4D5AF4A8.50001@auckland.ac.nz>
References: <AANLkTikODppzk5=x7=TzVepH+aHuvaZUErf_0xQZ5ioX@mail.gmail.com>
	<4D5AF4A8.50001@auckland.ac.nz>
Message-ID: <4D5BC398.3050209@mx.uni-saarland.de>

On 15.02.2011 22:48, David Scott wrote:
> On 16/02/2011 7:04 a.m., Paul Johnson wrote:
>> ...
>>
>> 4. We don't want gratuitous use of "return" at the end of functions.
>> Why do people still do that?
>
> Well I for one (and Jeff as well it seems) think it is good 
> programming practice. It makes explicit what is being returned 
> eliminating the possibility of mistakes and provides clarity for 
> anyone reading the code.
>
> David Scott
>
>

AFAIR (but I am not sure, maybe some expert can comment on this), there 
is a difference between using return and not using return when R code is 
called from C-code via eval(). If my memory is correct, a return() 
statement (in the R code) would abort the C function (which is trying to 
evaluate the R code, e.g., the body of a function) as well, which is 
probably not intended. So, the use of return() in R code may be quite 
disadvantageous in certain situations.

Martin

-- 
Dr. Martin Becker
Statistics and Econometrics
Saarland University
Campus C3 1, Room 217
66123 Saarbruecken
Germany


From murdoch.duncan at gmail.com  Wed Feb 16 13:39:46 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 16 Feb 2011 07:39:46 -0500
Subject: [Rd] Request: Suggestions for "good teaching" packages,
 esp. with C code
In-Reply-To: <4D5BC398.3050209@mx.uni-saarland.de>
References: <AANLkTikODppzk5=x7=TzVepH+aHuvaZUErf_0xQZ5ioX@mail.gmail.com>	<4D5AF4A8.50001@auckland.ac.nz>
	<4D5BC398.3050209@mx.uni-saarland.de>
Message-ID: <4D5BC592.6020900@gmail.com>

On 11-02-16 7:31 AM, Martin Becker wrote:
> On 15.02.2011 22:48, David Scott wrote:
>> On 16/02/2011 7:04 a.m., Paul Johnson wrote:
>>> ...
>>>
>>> 4. We don't want gratuitous use of "return" at the end of functions.
>>> Why do people still do that?
>>
>> Well I for one (and Jeff as well it seems) think it is good
>> programming practice. It makes explicit what is being returned
>> eliminating the possibility of mistakes and provides clarity for
>> anyone reading the code.
>>
>> David Scott
>>
>>
>
> AFAIR (but I am not sure, maybe some expert can comment on this), there
> is a difference between using return and not using return when R code is
> called from C-code via eval(). If my memory is correct, a return()
> statement (in the R code) would abort the C function (which is trying to
> evaluate the R code, e.g., the body of a function) as well, which is
> probably not intended. So, the use of return() in R code may be quite
> disadvantageous in certain situations.

As far as I know there is no such effect.  I suspect what you saw just 
triggered a bug in the C code that had stayed hidden before.

Duncan Murdoch


From edd at debian.org  Wed Feb 16 15:00:34 2011
From: edd at debian.org (Dirk Eddelbuettel)
Date: Wed, 16 Feb 2011 08:00:34 -0600
Subject: [Rd] R-Forge is dark
Message-ID: <19803.55426.708404.315797@max.nulle.part>


Hoping that it is nothing to permanent, could someone with the power to do so
please give the r-forge machine (or something in the network controlling
access to it) a good shake or reboot ?  

Thanks, Dirk

-- 
Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com


From edd at debian.org  Wed Feb 16 15:32:20 2011
From: edd at debian.org (Dirk Eddelbuettel)
Date: Wed, 16 Feb 2011 08:32:20 -0600
Subject: [Rd] R-Forge is dark
In-Reply-To: <19803.55426.708404.315797@max.nulle.part>
References: <19803.55426.708404.315797@max.nulle.part>
Message-ID: <19803.57332.58254.280101@max.nulle.part>


On 16 February 2011 at 08:00, Dirk Eddelbuettel wrote:
| Hoping that it is nothing to permanent, could someone with the power to do so
| please give the r-forge machine (or something in the network controlling
| access to it) a good shake or reboot ?  

That appears to have been temporary. http and svn+ssh connect again. Thanks
to whoever took care of it.

Dirk

-- 
Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com


From timhesterberg at gmail.com  Wed Feb 16 15:48:39 2011
From: timhesterberg at gmail.com (Tim Hesterberg)
Date: Wed, 16 Feb 2011 06:48:39 -0800
Subject: [Rd] matrixStats: Extend to arrays too (Was: Re:	Suggestion:
	Adding quick rowMin and rowMax functions to base package)
In-Reply-To: <AANLkTikh_y74ny=Lt0Vm-tM8tj2EKNgyB3Vaup-e2De2@mail.gmail.com>
	(message from Hadley Wickham on Tue, 15 Feb 2011 18:52:13 +0000)
References: <AANLkTikh_y74ny=Lt0Vm-tM8tj2EKNgyB3Vaup-e2De2@mail.gmail.com>
Message-ID: <yajfk4h0rq60.fsf@gmail.com>

For consistency with rowSums colSums rowMeans etc., the names should be
	colMins colMaxs
	rowMins rowMaxs
This is also consistent with S+.

FYI, the rowSums naming convention was chosen to avoid conflict
with rowsum (which computes column sums!).

Tim Hesterberg

>> A well-designed API generalized to work with arrays should probably
>> borrow ideas from how argument 'MARGIN' of apply() works, how argument
>> 'dim' in rowSums() for (though I must say the letter seem a bit ad hoc
>> at first sight given the name of the function). ?There may also be
>> something to learn from the 'reshape' package and so.
>
>I'd also recommend looking at plyr::aaply, which fixes a few things
>that have always annoyed me about apply - namely that it is not
>idempotent/identical to aperm when the summary function is the
>identity.
>
>Hadley
>
>--
>Assistant Professor / Dobelman Family Junior Chair
>Department of Statistics / Rice University
>http://had.co.nz/


From hadley at rice.edu  Wed Feb 16 16:31:43 2011
From: hadley at rice.edu (Hadley Wickham)
Date: Wed, 16 Feb 2011 15:31:43 +0000
Subject: [Rd] matrixStats: Extend to arrays too (Was: Re: Suggestion:
 Adding quick rowMin and rowMax functions to base package)
In-Reply-To: <yajfk4h0rq60.fsf@gmail.com>
References: <AANLkTikh_y74ny=Lt0Vm-tM8tj2EKNgyB3Vaup-e2De2@mail.gmail.com>
	<yajfk4h0rq60.fsf@gmail.com>
Message-ID: <AANLkTina14Jjri3E0KOd91E1CT1_ivxCUaXZPBg4wWZA@mail.gmail.com>

On Wed, Feb 16, 2011 at 2:48 PM, Tim Hesterberg <timhesterberg at gmail.com> wrote:
> For consistency with rowSums colSums rowMeans etc., the names should be
> ? ? ? ?colMins colMaxs
> ? ? ? ?rowMins rowMaxs
> This is also consistent with S+.

You mean rowMaxes, right?  Or is the rule to add an s, not to pluralise?

I think if you were writing a new package, you'd be better off a whole
new naming convention that extended better to higher dimensions.

Hadley

-- 
Assistant Professor / Dobelman Family Junior Chair
Department of Statistics / Rice University
http://had.co.nz/


From luke-tierney at uiowa.edu  Wed Feb 16 17:11:00 2011
From: luke-tierney at uiowa.edu (luke-tierney at uiowa.edu)
Date: Wed, 16 Feb 2011 10:11:00 -0600
Subject: [Rd] Request: Suggestions for "good teaching" packages,
 esp. with C code
In-Reply-To: <4D5BC592.6020900@gmail.com>
References: <AANLkTikODppzk5=x7=TzVepH+aHuvaZUErf_0xQZ5ioX@mail.gmail.com>
	<4D5AF4A8.50001@auckland.ac.nz>
	<4D5BC398.3050209@mx.uni-saarland.de> <4D5BC592.6020900@gmail.com>
Message-ID: <alpine.LFD.2.00.1102161007180.13402@itasca.stat.uiowa.edu>

If you evaluate return(x) in an evironment env then then that will
execute a return from the function call associated with env or signal
an error if there is none.  That is the way return() is intended to
work.

Best,

luke

On Wed, 16 Feb 2011, Duncan Murdoch wrote:

> On 11-02-16 7:31 AM, Martin Becker wrote:
>> On 15.02.2011 22:48, David Scott wrote:
>>> On 16/02/2011 7:04 a.m., Paul Johnson wrote:
>>>> ...
>>>> 
>>>> 4. We don't want gratuitous use of "return" at the end of functions.
>>>> Why do people still do that?
>>> 
>>> Well I for one (and Jeff as well it seems) think it is good
>>> programming practice. It makes explicit what is being returned
>>> eliminating the possibility of mistakes and provides clarity for
>>> anyone reading the code.
>>> 
>>> David Scott
>>> 
>>> 
>> 
>> AFAIR (but I am not sure, maybe some expert can comment on this), there
>> is a difference between using return and not using return when R code is
>> called from C-code via eval(). If my memory is correct, a return()
>> statement (in the R code) would abort the C function (which is trying to
>> evaluate the R code, e.g., the body of a function) as well, which is
>> probably not intended. So, the use of return() in R code may be quite
>> disadvantageous in certain situations.
>
> As far as I know there is no such effect.  I suspect what you saw just 
> triggered a bug in the C code that had stayed hidden before.
>
> Duncan Murdoch
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Luke Tierney
Statistics and Actuarial Science
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From jon.clayden at gmail.com  Wed Feb 16 17:25:49 2011
From: jon.clayden at gmail.com (Jon Clayden)
Date: Wed, 16 Feb 2011 16:25:49 +0000
Subject: [Rd] Ignoring .Rprofile when installing a package
Message-ID: <AANLkTin_a=tANUqwH3_=zFadbFuc-M8KhHTovyuahDpD@mail.gmail.com>

Dear all,

Is there a way to force R CMD INSTALL to ignore ~/.Rprofile and
similar? I presume it sources these startup files for a reason, but
I've found that it can cause confusion or problems. In particular, my
~/.Rprofile loads a few packages which I very frequently use, but this
stops me from installing new versions of their dependencies; viz.

$ R CMD INSTALL tractor.base
* installing to library ?/Library/Frameworks/R.framework/Resources/library?
* installing *source* package ?tractor.base? ...
** R
** data
** preparing package for lazy loading
Error: package ?tractor.base? is required by ?tractor.opt? so will not
be detached
* removing ?/Library/Frameworks/R.framework/Resources/library/tractor.base?
* restoring previous
?/Library/Frameworks/R.framework/Resources/library/tractor.base?

I've tried R --vanilla CMD INSTALL, but that seems to have no effect.
This is R 2.12.1 on Mac OS X.6.6. Any pointers appreciated.

All the best,
Jon


From martin.becker at mx.uni-saarland.de  Wed Feb 16 17:35:14 2011
From: martin.becker at mx.uni-saarland.de (Martin Becker)
Date: Wed, 16 Feb 2011 17:35:14 +0100
Subject: [Rd] Request: Suggestions for "good teaching" packages,
 esp. with C code
In-Reply-To: <alpine.LFD.2.00.1102161007180.13402@itasca.stat.uiowa.edu>
References: <AANLkTikODppzk5=x7=TzVepH+aHuvaZUErf_0xQZ5ioX@mail.gmail.com>
	<4D5AF4A8.50001@auckland.ac.nz>
	<4D5BC398.3050209@mx.uni-saarland.de> <4D5BC592.6020900@gmail.com>
	<alpine.LFD.2.00.1102161007180.13402@itasca.stat.uiowa.edu>
Message-ID: <4D5BFCC2.1020805@mx.uni-saarland.de>

Luke,

thanks for your explanation.
I now remember that I was indeed getting an error (instead of a silent 
abort) because I did something comparable to a .Call() to "lapply" in 
section 5.11 of WRE (Writing R extensions) where expr was the body of a 
function f (literally) which contained a return()-statement. Although 
removing the return()-statement solved my problem a few years ago, I now 
know that I had better followed the next example of WRE ("lapply2") 
which is especially designed for evaluating function calls (instead of 
expressions).
So, sorry for the noise (and for blaming return()) and thanks again for 
the clarification.

Best,

   Martin

On 16.02.2011 17:11, luke-tierney at uiowa.edu wrote:
> If you evaluate return(x) in an evironment env then then that will
> execute a return from the function call associated with env or signal
> an error if there is none.  That is the way return() is intended to
> work.
>
> Best,
>
> luke
>
> On Wed, 16 Feb 2011, Duncan Murdoch wrote:
>
>> On 11-02-16 7:31 AM, Martin Becker wrote:
>>> On 15.02.2011 22:48, David Scott wrote:
>>>> On 16/02/2011 7:04 a.m., Paul Johnson wrote:
>>>>> ...
>>>>>
>>>>> 4. We don't want gratuitous use of "return" at the end of functions.
>>>>> Why do people still do that?
>>>>
>>>> Well I for one (and Jeff as well it seems) think it is good
>>>> programming practice. It makes explicit what is being returned
>>>> eliminating the possibility of mistakes and provides clarity for
>>>> anyone reading the code.
>>>>
>>>> David Scott
>>>>
>>>>
>>>
>>> AFAIR (but I am not sure, maybe some expert can comment on this), there
>>> is a difference between using return and not using return when R 
>>> code is
>>> called from C-code via eval(). If my memory is correct, a return()
>>> statement (in the R code) would abort the C function (which is 
>>> trying to
>>> evaluate the R code, e.g., the body of a function) as well, which is
>>> probably not intended. So, the use of return() in R code may be quite
>>> disadvantageous in certain situations.
>>
>> As far as I know there is no such effect.  I suspect what you saw 
>> just triggered a bug in the C code that had stayed hidden before.
>>
>> Duncan Murdoch
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>


-- 
Dr. Martin Becker
Statistics and Econometrics
Saarland University
Campus C3 1, Room 217
66123 Saarbruecken
Germany


From ripley at stats.ox.ac.uk  Wed Feb 16 17:57:54 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 16 Feb 2011 16:57:54 +0000 (GMT)
Subject: [Rd] Ignoring .Rprofile when installing a package
In-Reply-To: <AANLkTin_a=tANUqwH3_=zFadbFuc-M8KhHTovyuahDpD@mail.gmail.com>
References: <AANLkTin_a=tANUqwH3_=zFadbFuc-M8KhHTovyuahDpD@mail.gmail.com>
Message-ID: <alpine.LFD.2.02.1102161650260.11129@gannet.stats.ox.ac.uk>

The most obvious answer is not to do that.  You have not used the 
standard mechanism to to do that (which should work here as R CMD 
INSTALL overrides that one).  It's all in ?Startup (look for 
R_DEFAULT_PACKAGES).

The simplest way to ignore ~/.Rprofile is to set R_PROFILE_USER to 
something else.

On Wed, 16 Feb 2011, Jon Clayden wrote:

> Dear all,
>
> Is there a way to force R CMD INSTALL to ignore ~/.Rprofile and
> similar? I presume it sources these startup files for a reason, but
> I've found that it can cause confusion or problems. In particular, my
> ~/.Rprofile loads a few packages which I very frequently use, but this
> stops me from installing new versions of their dependencies; viz.
>
> $ R CMD INSTALL tractor.base
> * installing to library ?/Library/Frameworks/R.framework/Resources/library?
> * installing *source* package ?tractor.base? ...
> ** R
> ** data
> ** preparing package for lazy loading
> Error: package ?tractor.base? is required by ?tractor.opt? so will not
> be detached
> * removing ?/Library/Frameworks/R.framework/Resources/library/tractor.base?
> * restoring previous
> ?/Library/Frameworks/R.framework/Resources/library/tractor.base?
>
> I've tried R --vanilla CMD INSTALL, but that seems to have no effect.

As documented.

> This is R 2.12.1 on Mac OS X.6.6. Any pointers appreciated.
>
> All the best,
> Jon
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From wdunlap at tibco.com  Wed Feb 16 18:05:59 2011
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 16 Feb 2011 09:05:59 -0800
Subject: [Rd] matrixStats: Extend to arrays too (Was: Re: Suggestion:
	Adding quick rowMin and rowMax functions to base package)
In-Reply-To: <AANLkTina14Jjri3E0KOd91E1CT1_ivxCUaXZPBg4wWZA@mail.gmail.com>
References: <AANLkTikh_y74ny=Lt0Vm-tM8tj2EKNgyB3Vaup-e2De2@mail.gmail.com><yajfk4h0rq60.fsf@gmail.com>
	<AANLkTina14Jjri3E0KOd91E1CT1_ivxCUaXZPBg4wWZA@mail.gmail.com>
Message-ID: <77EB52C6DD32BA4D87471DCD70C8D70003E62D73@NA-PA-VBE03.na.tibco.com>

> -----Original Message-----
> From: r-devel-bounces at r-project.org 
> [mailto:r-devel-bounces at r-project.org] On Behalf Of Hadley Wickham
> Sent: Wednesday, February 16, 2011 7:32 AM
> To: Tim Hesterberg
> Cc: Henrik Bengtsson; r-devel at r-project.org
> Subject: Re: [Rd] matrixStats: Extend to arrays too (Was: Re: 
> Suggestion: Adding quick rowMin and rowMax functions to base package)
> 
> On Wed, Feb 16, 2011 at 2:48 PM, Tim Hesterberg 
> <timhesterberg at gmail.com> wrote:
> > For consistency with rowSums colSums rowMeans etc., the 
> names should be
> > ? ? ? ?colMins colMaxs
> > ? ? ? ?rowMins rowMaxs
> > This is also consistent with S+.
> 
> You mean rowMaxes, right?  Or is the rule to add an s, not to 
> pluralise?

In S+ we chose to just append the 's' instead of making
everyone worry about the vagarities of English spelling
and pluralization rules.  We also have 'groupAnys' and
'igroupAnys' (and should have {row,col}Anys, but we don't).

The 'igroup<Summarys>' family of functions in S+ is to the
'group<Summarys>' family as 'tabulate' is to 'table':  it
requires that the grouping variable be an integer in the
range 1:numGroups and in return gives fast results.

Having a similar family of functions for general arrays
would be nice also, but I think that specialized row* and col*
functions are good to have: data.frames only have rows and
columns and I can never remember the MARGIN number conventions
of apply and sweep.

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com 

> 
> I think if you were writing a new package, you'd be better off a whole
> new naming convention that extended better to higher dimensions.
> 
> Hadley
> 
> -- 
> Assistant Professor / Dobelman Family Junior Chair
> Department of Statistics / Rice University
> http://had.co.nz/
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 


From hadley at rice.edu  Wed Feb 16 18:21:18 2011
From: hadley at rice.edu (Hadley Wickham)
Date: Wed, 16 Feb 2011 11:21:18 -0600
Subject: [Rd] matrixStats: Extend to arrays too (Was: Re: Suggestion:
 Adding quick rowMin and rowMax functions to base package)
In-Reply-To: <77EB52C6DD32BA4D87471DCD70C8D70003E62D73@NA-PA-VBE03.na.tibco.com>
References: <AANLkTikh_y74ny=Lt0Vm-tM8tj2EKNgyB3Vaup-e2De2@mail.gmail.com>
	<yajfk4h0rq60.fsf@gmail.com>
	<AANLkTina14Jjri3E0KOd91E1CT1_ivxCUaXZPBg4wWZA@mail.gmail.com>
	<77EB52C6DD32BA4D87471DCD70C8D70003E62D73@NA-PA-VBE03.na.tibco.com>
Message-ID: <AANLkTik25g6RsvGmXJqFtocoGKmUVgrhQd-CTQrCv7ce@mail.gmail.com>

>> You mean rowMaxes, right? ?Or is the rule to add an s, not to
>> pluralise?
>
> In S+ we chose to just append the 's' instead of making
> everyone worry about the vagarities of English spelling
> and pluralization rules. ?We also have 'groupAnys' and
> 'igroupAnys' (and should have {row,col}Anys, but we don't).

I think that's the strongest argument for sticking with singular nouns
for function names - English pluralisations are complex and arbitrary,
but just adding an s is going to look horrible for any native speaker.

Hadley


-- 
Assistant Professor / Dobelman Family Junior Chair
Department of Statistics / Rice University
http://had.co.nz/


From brian at braverock.com  Wed Feb 16 18:25:07 2011
From: brian at braverock.com (Brian G. Peterson)
Date: Wed, 16 Feb 2011 11:25:07 -0600
Subject: [Rd] Ignoring .Rprofile when installing a package
In-Reply-To: <alpine.LFD.2.02.1102161650260.11129@gannet.stats.ox.ac.uk>
References: <AANLkTin_a=tANUqwH3_=zFadbFuc-M8KhHTovyuahDpD@mail.gmail.com>
	<alpine.LFD.2.02.1102161650260.11129@gannet.stats.ox.ac.uk>
Message-ID: <4D5C0873.2010404@braverock.com>

On 02/16/2011 10:57 AM, Prof Brian Ripley wrote:
> The most obvious answer is not to do that. You have not used the
> standard mechanism to to do that (which should work here as R CMD
> INSTALL overrides that one). It's all in ?Startup (look for
> R_DEFAULT_PACKAGES).

Note that R CMD INSTALL is not mentioned at all here.

> The simplest way to ignore ~/.Rprofile is to set R_PROFILE_USER to
> something else.

>> I've tried R --vanilla CMD INSTALL, but that seems to have no effect.
>
> As documented.

Then let's try this from another angle...

Is there a rationale why --vanilla or --no-environ or --no-site-file or 
--no-init-file are *NOT* supported by R CMD INSTALL ?  I don't see any 
reasoning for the inconsistency in the docs anywhere.

If not, would R-core entertain a patch that would handle these options?

This functionality is troublesome in a production installations where we 
*want* our users to have specific packages and environment options set 
all the time, and I need to edit the Rprofile.site file every time I 
upgrade one of these 'production' packages.

Regards,

    - Brian


From wdunlap at tibco.com  Wed Feb 16 18:37:57 2011
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 16 Feb 2011 09:37:57 -0800
Subject: [Rd] matrixStats: Extend to arrays too (Was: Re: Suggestion:
	Adding quick rowMin and rowMax functions to base package)
In-Reply-To: <AANLkTik25g6RsvGmXJqFtocoGKmUVgrhQd-CTQrCv7ce@mail.gmail.com>
References: <AANLkTikh_y74ny=Lt0Vm-tM8tj2EKNgyB3Vaup-e2De2@mail.gmail.com>
	<yajfk4h0rq60.fsf@gmail.com>
	<AANLkTina14Jjri3E0KOd91E1CT1_ivxCUaXZPBg4wWZA@mail.gmail.com>
	<77EB52C6DD32BA4D87471DCD70C8D70003E62D73@NA-PA-VBE03.na.tibco.com>
	<AANLkTik25g6RsvGmXJqFtocoGKmUVgrhQd-CTQrCv7ce@mail.gmail.com>
Message-ID: <77EB52C6DD32BA4D87471DCD70C8D70003E62D8F@NA-PA-VBE03.na.tibco.com>


> -----Original Message-----
> From: h.wickham at gmail.com [mailto:h.wickham at gmail.com] On 
> Behalf Of Hadley Wickham
> Sent: Wednesday, February 16, 2011 9:21 AM
> To: William Dunlap
> Cc: Tim Hesterberg; Henrik Bengtsson; r-devel at r-project.org
> Subject: Re: [Rd] matrixStats: Extend to arrays too (Was: Re: 
> Suggestion: Adding quick rowMin and rowMax functions to base package)
> 
> >> You mean rowMaxes, right? ?Or is the rule to add an s, not to
> >> pluralise?
> >
> > In S+ we chose to just append the 's' instead of making
> > everyone worry about the vagarities of English spelling
> > and pluralization rules. ?We also have 'groupAnys' and
> > 'igroupAnys' (and should have {row,col}Anys, but we don't).
> 
> I think that's the strongest argument for sticking with singular nouns
> for function names - English pluralisations are complex and arbitrary,
> but just adding an s is going to look horrible for any native speaker.
> 
> Hadley

That is a good argument, but the horse has been out
of the barn for quite a while: rowSums has been in R
since at least 2007 (2.6.1 is the oldest version of R
I have installed) and in S+ since at least 1998 (S+ 5.0,
the oldest I have installed).

There are lots of R and S+ functions with plurals in
the name (computeRestarts, objects, sys.calls, ...)
and I think they generally make sense to be plural.
(However, why is dim() singular and dimnames() plural?
Their results generally have the same length for a
given object.)

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com 


> 
> 
> -- 
> Assistant Professor / Dobelman Family Junior Chair
> Department of Statistics / Rice University
> http://had.co.nz/
> 


From djsamperi at gmail.com  Wed Feb 16 18:43:47 2011
From: djsamperi at gmail.com (Dominick Samperi)
Date: Wed, 16 Feb 2011 12:43:47 -0500
Subject: [Rd] Avoiding name clashes: opinion on best practice naming
	conventions
In-Reply-To: <4d5b98ec.4c02cc0a.13fe.476c@mx.google.com>
References: <4d5b98ec.4c02cc0a.13fe.476c@mx.google.com>
Message-ID: <AANLkTimdA=ExqfGGVuzk703PAs2eMcU_87rj1fydccx-@mail.gmail.com>

On Wed, Feb 16, 2011 at 4:29 AM, Janko Thyson
<janko.thyson.rstuff at googlemail.com> wrote:
> Dear List,
>
> I'm trying to figure out some best practice way with respect to the naming
> conventions when building own packages.
>
> I'd like to minimize the risk of choosing function names that might
> interfere with those of other packages (both available ones and those yet to
> come).
>
> I came up with following alternatives
> 1. Prefixing the actual names (e.g. myPkgfoo() instead of foo()): pretty
> verbose
> 2. Emulating a package namespace while developing and explicitly using
> myPkg::foo() in all scripts: IMHO the best way, but apparently not possible
> as I learned.

Since the resolution of myPkg::foo() occurs at runtime (via a function
call) instead
of at compile time (as it would in C++), this practice can introduce a
significant
performance hit. This can be avoided by doing something like:
mylocalfunc <- myPkg::foo
[tight loop that uses mylocalfunc repeatedly]

Here mylocalfunc would not be exported, of course.

Dominick

> 3. Carefully choosing which functions to export. Yet, I'm not sure I
> completely understand the implications of exported functions. Does this
> imply that not exported functions cannot interfere with functions in other
> namespaces?
>
> I'd be great to hear some recommendations on this one!
>
> Thanks a lot,
> Janko
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From pgilbert at bank-banque-canada.ca  Wed Feb 16 19:13:36 2011
From: pgilbert at bank-banque-canada.ca (Paul Gilbert)
Date: Wed, 16 Feb 2011 18:13:36 +0000
Subject: [Rd] function call overhead
In-Reply-To: <AANLkTimdA=ExqfGGVuzk703PAs2eMcU_87rj1fydccx-@mail.gmail.com>
References: <4d5b98ec.4c02cc0a.13fe.476c@mx.google.com>
	<AANLkTimdA=ExqfGGVuzk703PAs2eMcU_87rj1fydccx-@mail.gmail.com>
Message-ID: <6441154A9FF1CD4386AF4ABF141A056D21525F40@WMEXOSCD2-N1.bocad.bank-banque-canada.ca>

(subject changed from: RE: [Rd] Avoiding name clashes: opinion on best practice naming	conventions)

Dominick

Is this really true? Is there a speed advantage to defining a local function this way, say, within another function, and then calling it within a loop rather than the original? Do you have data on this?

Paul

> -----Original Message-----
> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-
> project.org] On Behalf Of Dominick Samperi
> Sent: February 16, 2011 12:44 PM
... 
> Since the resolution of myPkg::foo() occurs at runtime (via a function
> call) instead
> of at compile time (as it would in C++), this practice can introduce a
> significant
> performance hit. This can be avoided by doing something like:
> mylocalfunc <- myPkg::foo
> [tight loop that uses mylocalfunc repeatedly]
> 
> Here mylocalfunc would not be exported, of course.
> 
> Dominick
...
====================================================================================

La version fran?aise suit le texte anglais.

------------------------------------------------------------------------------------

This email may contain privileged and/or confidential information, and the Bank of
Canada does not waive any related rights. Any distribution, use, or copying of this
email or the information it contains by other than the intended recipient is
unauthorized. If you received this email in error please delete it immediately from
your system and notify the sender promptly by email that you have done so. 

------------------------------------------------------------------------------------

Le pr?sent courriel peut contenir de l'information privil?gi?e ou confidentielle.
La Banque du Canada ne renonce pas aux droits qui s'y rapportent. Toute diffusion,
utilisation ou copie de ce courriel ou des renseignements qu'il contient par une
personne autre que le ou les destinataires d?sign?s est interdite. Si vous recevez
ce courriel par erreur, veuillez le supprimer imm?diatement et envoyer sans d?lai ?
l'exp?diteur un message ?lectronique pour l'aviser que vous avez ?limin? de votre
ordinateur toute copie du courriel re?u.

From nashjc at uottawa.ca  Wed Feb 16 19:21:56 2011
From: nashjc at uottawa.ca (Prof. John C Nash)
Date: Wed, 16 Feb 2011 13:21:56 -0500
Subject: [Rd] return(); was  Suggestions for "good teaching" packages
In-Reply-To: <mailman.19.1297854009.22220.r-devel@r-project.org>
References: <mailman.19.1297854009.22220.r-devel@r-project.org>
Message-ID: <4D5C15C4.9070806@uottawa.ca>


I tend to code with return(), at least in development, because I've once stepped in the
cowpad of

    ans<- list(    )

then attr(ans ....)

and forgot to do another

    ans

so got only part of what I wanted. Perhaps its just my thinking style, but I agree with
some others who suggest that it's not such a bad idea to be explicit about what one is
doing. I prefer pedestrian code that I can understand easily and quickly fix/modify rather
than highly optimized and uncommented brilliance that I cannot reuse.

Given the overhead of return(), I'll likely switch to
    ans # return(ans)
to make my programs clear, especially to non-R folk migrating in.


I have also been writing optimization functions. Modularizing might be a nice student
exercise, as well as avoiding early return()s, but Canada isn't wide enough for all the
indents of the else clauses when methods crash at different stages and we want to return a
very simple structure with partial data etc.

Reminds me of the great "GOTO" debate some 30+ years ago.

JN


From jeffrey.ryan at lemnica.com  Wed Feb 16 19:20:39 2011
From: jeffrey.ryan at lemnica.com (Jeffrey Ryan)
Date: Wed, 16 Feb 2011 12:20:39 -0600
Subject: [Rd] function call overhead
In-Reply-To: <6441154A9FF1CD4386AF4ABF141A056D21525F40@WMEXOSCD2-N1.bocad.bank-banque-canada.ca>
References: <4d5b98ec.4c02cc0a.13fe.476c@mx.google.com>
	<AANLkTimdA=ExqfGGVuzk703PAs2eMcU_87rj1fydccx-@mail.gmail.com>
	<6441154A9FF1CD4386AF4ABF141A056D21525F40@WMEXOSCD2-N1.bocad.bank-banque-canada.ca>
Message-ID: <AANLkTimSvTAYpTSNoQJ1cV2MmHwBmS4V2ktC9_fXzjc2@mail.gmail.com>

Hi Paul,

> `:::`
function (pkg, name)
{
    pkg <- as.character(substitute(pkg))
    name <- as.character(substitute(name))
    get(name, envir = asNamespace(pkg), inherits = FALSE)
}
<environment: namespace:base>

and

> `::`
function (pkg, name)
{
    pkg <- as.character(substitute(pkg))
    name <- as.character(substitute(name))
    ns <- tryCatch(asNamespace(pkg), hasNoNamespaceError = function(e) NULL)
    if (is.null(ns)) {
        pos <- match(paste("package", pkg, sep = ":"), search(),
            0L)
        if (pos == 0)
            stop(gettextf("package %s has no name space and is not on
the search path"),
                sQuote(pkg), domain = NA)
        get(name, pos = pos, inherits = FALSE)
    }
    else getExportedValue(pkg, name)
}
<environment: namespace:base>


are the reasons I think.

Jeff

On Wed, Feb 16, 2011 at 12:13 PM, Paul Gilbert
<pgilbert at bank-banque-canada.ca> wrote:
> (subject changed from: RE: [Rd] Avoiding name clashes: opinion on best practice naming ?conventions)
>
> Dominick
>
> Is this really true? Is there a speed advantage to defining a local function this way, say, within another function, and then calling it within a loop rather than the original? Do you have data on this?
>
> Paul
>
>> -----Original Message-----
>> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-
>> project.org] On Behalf Of Dominick Samperi
>> Sent: February 16, 2011 12:44 PM
> ...
>> Since the resolution of myPkg::foo() occurs at runtime (via a function
>> call) instead
>> of at compile time (as it would in C++), this practice can introduce a
>> significant
>> performance hit. This can be avoided by doing something like:
>> mylocalfunc <- myPkg::foo
>> [tight loop that uses mylocalfunc repeatedly]
>>
>> Here mylocalfunc would not be exported, of course.
>>
>> Dominick
> ...
> ====================================================================================
>
> La version fran?aise suit le texte anglais.
>
> ------------------------------------------------------------------------------------
>
> This email may contain privileged and/or confidential information, and the Bank of
> Canada does not waive any related rights. Any distribution, use, or copying of this
> email or the information it contains by other than the intended recipient is
> unauthorized. If you received this email in error please delete it immediately from
> your system and notify the sender promptly by email that you have done so.
>
> ------------------------------------------------------------------------------------
>
> Le pr?sent courriel peut contenir de l'information privil?gi?e ou confidentielle.
> La Banque du Canada ne renonce pas aux droits qui s'y rapportent. Toute diffusion,
> utilisation ou copie de ce courriel ou des renseignements qu'il contient par une
> personne autre que le ou les destinataires d?sign?s est interdite. Si vous recevez
> ce courriel par erreur, veuillez le supprimer imm?diatement et envoyer sans d?lai ?
> l'exp?diteur un message ?lectronique pour l'aviser que vous avez ?limin? de votre
> ordinateur toute copie du courriel re?u.
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>



-- 
Jeffrey Ryan
jeffrey.ryan at lemnica.com

www.lemnica.com


From mdowle at mdowle.plus.com  Wed Feb 16 19:36:38 2011
From: mdowle at mdowle.plus.com (Matthew Dowle)
Date: Wed, 16 Feb 2011 18:36:38 +0000
Subject: [Rd] method="radix" in sort.list() isn't actually a radix sort
Message-ID: <ijh5fm$837$1@dough.gmane.org>

Dear list,

Were you aware that, strictly speaking, do_radixsort in sort.c actually
implements a counting sort, not a radix sort ?

http://en.wikipedia.org/wiki/Counting_sort

It it was a radix sort it wouldn't need the 100,000 range restriction.

Clearly the method argument can't be changed (now) from "radix" to
"counting", but perhaps a note could be added to the .Rd ?

According to Wikipedia, Harold H. Seward created both counting and
radix sorting in 1954, and they are distinctly different.

I did a grep through all R source for the keyword "radix" in case this
was already documented. A google search and rseek.org search didn't
return results for "counting sort" in the R context.

There appears to be scope to add (true) radix sorting to R then, that
doesn't have the 100,000 range restriction.  Is there any interest in that?

Matthew


From hadley at rice.edu  Wed Feb 16 21:53:54 2011
From: hadley at rice.edu (Hadley Wickham)
Date: Wed, 16 Feb 2011 14:53:54 -0600
Subject: [Rd] function call overhead
In-Reply-To: <6441154A9FF1CD4386AF4ABF141A056D21525F40@WMEXOSCD2-N1.bocad.bank-banque-canada.ca>
References: <4d5b98ec.4c02cc0a.13fe.476c@mx.google.com>
	<AANLkTimdA=ExqfGGVuzk703PAs2eMcU_87rj1fydccx-@mail.gmail.com>
	<6441154A9FF1CD4386AF4ABF141A056D21525F40@WMEXOSCD2-N1.bocad.bank-banque-canada.ca>
Message-ID: <AANLkTi=f0j5TXZ=pu6rsFUXLmrAYHWjdTDOy24MDUZ2w@mail.gmail.com>

On Wed, Feb 16, 2011 at 12:13 PM, Paul Gilbert
<pgilbert at bank-banque-canada.ca> wrote:
> (subject changed from: RE: [Rd] Avoiding name clashes: opinion on best practice naming ?conventions)
>
> Dominick
>
> Is this really true? Is there a speed advantage to defining a local function this way, say, within another function, and then calling it within a loop rather than the original? Do you have data on this?

I wondered about this statement too but:

> system.time(replicate(1e4, base::print))
   user  system elapsed
  0.539   0.001   0.541
> system.time(replicate(1e4, print))
   user  system elapsed
  0.013   0.000   0.012

So it is (relatively) significant, although it's not going to make an
impact unless you're doing thousands of function calls.

Hadley


-- 
Assistant Professor / Dobelman Family Junior Chair
Department of Statistics / Rice University
http://had.co.nz/


From djsamperi at gmail.com  Wed Feb 16 22:27:43 2011
From: djsamperi at gmail.com (Dominick Samperi)
Date: Wed, 16 Feb 2011 16:27:43 -0500
Subject: [Rd] function call overhead
In-Reply-To: <6441154A9FF1CD4386AF4ABF141A056D21525F40@WMEXOSCD2-N1.bocad.bank-banque-canada.ca>
References: <4d5b98ec.4c02cc0a.13fe.476c@mx.google.com>
	<AANLkTimdA=ExqfGGVuzk703PAs2eMcU_87rj1fydccx-@mail.gmail.com>
	<6441154A9FF1CD4386AF4ABF141A056D21525F40@WMEXOSCD2-N1.bocad.bank-banque-canada.ca>
Message-ID: <AANLkTikTn30jLoohfgmBNm4xoj9aywKVb4T1M9=uMrDM@mail.gmail.com>

On Wed, Feb 16, 2011 at 1:13 PM, Paul Gilbert
<pgilbert at bank-banque-canada.ca> wrote:
> (subject changed from: RE: [Rd] Avoiding name clashes: opinion on best practice naming ?conventions)
>
> Dominick,
>
> Is this really true? Is there a speed advantage to defining a local function this way, say, within another function, and then calling it within a loop rather than the original? Do you have data on this?
>
> Paul

I worked on an application where a complex characteristic function was
computed over
and over again to compute a Fourier transform, and there was a very
significant performance
penalty to be paid by using myPgk::foo() compared with foo(). It was
recommended on this
list that I try the local assignment trick and it worked great.

Unfortunately this discourages the use of programming styles that are
more explicit and
easier to follow for the human reader. It also complicates the problem
of explicitly specifying
what version of "foo()" you really mean to use.

Dominick

>> -----Original Message-----
>> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-
>> project.org] On Behalf Of Dominick Samperi
>> Sent: February 16, 2011 12:44 PM
> ...
>> Since the resolution of myPkg::foo() occurs at runtime (via a function
>> call) instead
>> of at compile time (as it would in C++), this practice can introduce a
>> significant
>> performance hit. This can be avoided by doing something like:
>> mylocalfunc <- myPkg::foo
>> [tight loop that uses mylocalfunc repeatedly]
>>
>> Here mylocalfunc would not be exported, of course.
>>
>> Dominick
> ...
> ====================================================================================
>
> La version fran?aise suit le texte anglais.
>
> ------------------------------------------------------------------------------------
>
> This email may contain privileged and/or confidential information, and the Bank of
> Canada does not waive any related rights. Any distribution, use, or copying of this
> email or the information it contains by other than the intended recipient is
> unauthorized. If you received this email in error please delete it immediately from
> your system and notify the sender promptly by email that you have done so.
>
> ------------------------------------------------------------------------------------
>
> Le pr?sent courriel peut contenir de l'information privil?gi?e ou confidentielle.
> La Banque du Canada ne renonce pas aux droits qui s'y rapportent. Toute diffusion,
> utilisation ou copie de ce courriel ou des renseignements qu'il contient par une
> personne autre que le ou les destinataires d?sign?s est interdite. Si vous recevez
> ce courriel par erreur, veuillez le supprimer imm?diatement et envoyer sans d?lai ?
> l'exp?diteur un message ?lectronique pour l'aviser que vous avez ?limin? de votre
> ordinateur toute copie du courriel re?u.
>


From olafm at statistik.tu-dortmund.de  Wed Feb 16 23:28:51 2011
From: olafm at statistik.tu-dortmund.de (Olaf Mersmann)
Date: Wed, 16 Feb 2011 23:28:51 +0100
Subject: [Rd] function call overhead
In-Reply-To: <AANLkTi=f0j5TXZ=pu6rsFUXLmrAYHWjdTDOy24MDUZ2w@mail.gmail.com>
References: <4d5b98ec.4c02cc0a.13fe.476c@mx.google.com>
	<AANLkTimdA=ExqfGGVuzk703PAs2eMcU_87rj1fydccx-@mail.gmail.com>
	<6441154A9FF1CD4386AF4ABF141A056D21525F40@WMEXOSCD2-N1.bocad.bank-banque-canada.ca>
	<AANLkTi=f0j5TXZ=pu6rsFUXLmrAYHWjdTDOy24MDUZ2w@mail.gmail.com>
Message-ID: <AANLkTikfe2Vq7u_rWbZ3idMrmO7tXEYrF7CDuvPC1G6F@mail.gmail.com>

Dear Hadly, dear list,

On Wed, Feb 16, 2011 at 9:53 PM, Hadley Wickham <hadley at rice.edu> wrote:
> I wondered about this statement too but:
>
>> system.time(replicate(1e4, base::print))
> ? user ?system elapsed
> ?0.539 ? 0.001 ? 0.541
>> system.time(replicate(1e4, print))
> ? user ?system elapsed
> ?0.013 ? 0.000 ? 0.012

These timings are skewed. Because I too have wondered about this in
the past, I recently published the microbenchmark package which tries
hard to accurately time it takes to evaluate some expression(s). Using
this package I get:

> library("microbenchmark")
> res <- microbenchmark(print, base::print, times=10000)
> res
Unit: nanoeconds  ## I've fixed the typo, but not pushed to CRAN
              min    lq  median    uq     max
print          57    65    68.0    69   48389
base::print 41763 43357 44278.5 48403 4749851

A better way to look at this is by converting to evaluations per second:

> print(res, unit="eps")
Unit: evaluations per second
                    min          lq      median          uq        max
print       17543859.65 15384615.38 14705882.35 14492753.62 20665.8538
base::print    23944.64    23064.33    22584.32    20659.88   210.5329

Resolving 23000 names per second or ~15M ist quite a dramatic
difference in my world. The timings obtained by

>  system.time(replicate(1e4, base::print))
       User      System verstrichen
      0.475       0.006       0.483
>  system.time(replicate(1e4, print))
       User      System verstrichen
      0.011       0.001       0.014

are skewed by the overhead of replicate() in this case because the
execution time of the expression under test is so short.

Cheers,
Olaf Mersmann


From hankin.robin at gmail.com  Thu Feb 17 06:41:58 2011
From: hankin.robin at gmail.com (robin hankin)
Date: Thu, 17 Feb 2011 18:41:58 +1300
Subject: [Rd] Dependencies problem
Message-ID: <AANLkTinaTp_RKVJDP5b=+Ch_k+-9XzyzSvjLkvHHGL+J@mail.gmail.com>

Dear List

I am developing a package which needs another package purely
for one of the datasets it uses.

What is Best Practice for doing this?  Simply including it in
the Dependencies: list in the DESCRIPTION file is giving
me curious errors from R CMD check or R CMD INSTALL:

Error in code2LazyLoadDB(package, lib.loc = lib.loc, keep.source =
keep.source,  :
  name space must not be loaded.
ERROR: lazy loading failed for package ?MM?

This error seems to be system-dependent.  All of the depencies are
packages which
are on CRAN and AFAICS  pass R CMD check.

Can anyone advise?


-- 
Robin Hankin
Uncertainty Analyst
hankin.robin at gmail.com


From therneau at mayo.edu  Thu Feb 17 18:07:03 2011
From: therneau at mayo.edu (Terry Therneau)
Date: Thu, 17 Feb 2011 11:07:03 -0600
Subject: [Rd] Rd2pdf error in R12.0
Message-ID: <1297962423.14309.26.camel@punchbuggy>

 On the local machine the command R11 CMD Rd2pdf survfit.Rd works fine. 
   R12 CMD Rd2pdf survfit.Rd fails with the message below.

Converting Rd files to LaTeX ...
  survfit.Rd
Creating pdf output from LaTeX ...
Error in texi2dvi("Rd2.tex", pdf = (out_ext == "pdf"), quiet =
FALSE,  : 
  Running 'texi2dvi' on 'Rd2.tex' failed.
Messages:
sh: texi2dvi: command not found
Output:

Error in running tools::texi2dvi

---------------
Here is the header when invoking the newer version:

R version 2.12.0 (2010-10-15)
Copyright (C) 2010 The R Foundation for Statistical Computing
ISBN 3-900051-07-0
Platform: x86_64-unknown-linux-gnu (64-bit)

The R11 call is 2.11.0, same machine, same login session.


 I've looked in the manuals and didn't see anything specific about
version 12.  Our system administrator will want some hints about what to
do to fix this, ere I complain.  I discovered it running CMD check on a
package update.

Any pointers?

Terry Therneau


From gong-yi.liao at uconn.edu  Thu Feb 17 18:26:49 2011
From: gong-yi.liao at uconn.edu (Gong-Yi Liao)
Date: Thu, 17 Feb 2011 12:26:49 -0500
Subject: [Rd] Rd2pdf error in R12.0
In-Reply-To: <1297962423.14309.26.camel@punchbuggy>
References: <1297962423.14309.26.camel@punchbuggy>
Message-ID: <AANLkTikh4f4QoMC-S7CtNk1BjyPAj_utCzkbeYhmqgOs@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110217/9b14278f/attachment.pl>

From ripley at stats.ox.ac.uk  Thu Feb 17 19:04:42 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 17 Feb 2011 18:04:42 +0000 (GMT)
Subject: [Rd] Rd2pdf error in R12.0
In-Reply-To: <1297962423.14309.26.camel@punchbuggy>
References: <1297962423.14309.26.camel@punchbuggy>
Message-ID: <alpine.LFD.2.02.1102171752350.17745@gannet.stats.ox.ac.uk>

I think you are decades in the future.  We are on R 2.12.x in 2011.

It seems that you don't have texi2dvi installed.  Either install it 
(it may part of the TeX or texinfo distributions)  or set 
options(texi2dvi='') (see ?tools::texi2dvi and ?EnvVar).  'Tis also 
discussed in the R-admin manual.

The problem here (and what changed from 2.11.x) is that people build R 
on one machine and run on another with different software installed, 
so the defaults were changed to look on the path.  R 2.12.0 is not 
current, and 2.12.2 beta has an even more robust search mechanism.

On Thu, 17 Feb 2011, Terry Therneau wrote:

> On the local machine the command R11 CMD Rd2pdf survfit.Rd works fine.
>   R12 CMD Rd2pdf survfit.Rd fails with the message below.
>
> Converting Rd files to LaTeX ...
>  survfit.Rd
> Creating pdf output from LaTeX ...
> Error in texi2dvi("Rd2.tex", pdf = (out_ext == "pdf"), quiet =
> FALSE,  :
>  Running 'texi2dvi' on 'Rd2.tex' failed.
> Messages:
> sh: texi2dvi: command not found
> Output:
>
> Error in running tools::texi2dvi
>
> ---------------
> Here is the header when invoking the newer version:
>
> R version 2.12.0 (2010-10-15)
> Copyright (C) 2010 The R Foundation for Statistical Computing
> ISBN 3-900051-07-0
> Platform: x86_64-unknown-linux-gnu (64-bit)
>
> The R11 call is 2.11.0, same machine, same login session.
>
>
> I've looked in the manuals and didn't see anything specific about
> version 12.  Our system administrator will want some hints about what to
> do to fix this, ere I complain.  I discovered it running CMD check on a
> package update.
>
> Any pointers?
>
> Terry Therneau
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From azege at yahoo.com  Thu Feb 17 19:29:50 2011
From: azege at yahoo.com (Andre Zege)
Date: Thu, 17 Feb 2011 10:29:50 -0800 (PST)
Subject: [Rd] Newbie Rccp module question. "Failed to initialize module
	pointer"???
Message-ID: <798847.76881.qm@web39321.mail.mud.yahoo.com>

Hi all. I started looking at Rcpp, which looks pretty great, actually. At the 
moment just trying to compile a module to get a feel how it all works without 
fully understanding how all the pieces fit together. 


Basically, i took the first example from Rcpp modules vignette: 

fun.cpp 
======================== 
#include <Rcpp.h> 
#include <math.h> 

using namespace Rcpp; 

double norm(double x, double y){ 
  return sqrt(x*x+y*y); 
} 

RCPP_MODULE(mod){ 
  function("norm", &norm); 
} 
========================== 

I then run Rcpp.package.skeleton("mypackage"), put fun.cpp in mypackage/src and 
did 

R CMD INSTALL mypackage, which seemed to compile mypackage.so OK. However, when 
i am trying  to use module, i get error message.  Namely, after i run R and do 

>library("Rcpp") 
>library("mypackage") 
> mod<-Module("mod") 
>mod$norm(3,4) 

i get the following 

Error in Module(module, mustStart = TRUE) : 
  Failed to initialize module pointer: Error in 
FUN("_rcpp_module_boot_mod"[[1L]], ...): no such symbol _rcpp_module_boot_mod in 
package .GlobalEnv 



I am pretty sure my error is a pretty obvious one, could someone give me a 
pointer on what to do differently or where to look for reference. Literal search 
for the error message doesn't bring anything useful.


From pgilbert at bank-banque-canada.ca  Thu Feb 17 20:06:41 2011
From: pgilbert at bank-banque-canada.ca (Paul Gilbert)
Date: Thu, 17 Feb 2011 19:06:41 +0000
Subject: [Rd] S3/S4/NAMESPACE
Message-ID: <6441154A9FF1CD4386AF4ABF141A056D21526661@WMEXOSCD2-N1.bocad.bank-banque-canada.ca>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110217/82e22c88/attachment.pl>

From edd at debian.org  Thu Feb 17 20:14:29 2011
From: edd at debian.org (Dirk Eddelbuettel)
Date: Thu, 17 Feb 2011 13:14:29 -0600
Subject: [Rd] Newbie Rccp module question. "Failed to initialize
	module	pointer"???
In-Reply-To: <798847.76881.qm@web39321.mail.mud.yahoo.com>
References: <798847.76881.qm@web39321.mail.mud.yahoo.com>
Message-ID: <19805.29589.842345.489802@max.nulle.part>


Hi Andre,

Please consider posting on rcpp-devel for Rcpp-related questions.

On 17 February 2011 at 10:29, Andre Zege wrote:
| Hi all. I started looking at Rcpp, which looks pretty great, actually. At the 
| moment just trying to compile a module to get a feel how it all works without 
| fully understanding how all the pieces fit together. 
| 
| 
| Basically, i took the first example from Rcpp modules vignette: 
| 
| fun.cpp 
| ======================== 
| #include <Rcpp.h> 
| #include <math.h> 
| 
| using namespace Rcpp; 
| 
| double norm(double x, double y){ 
|   return sqrt(x*x+y*y); 
| } 
| 
| RCPP_MODULE(mod){ 
|   function("norm", &norm); 
| } 
| ========================== 
| 
| I then run Rcpp.package.skeleton("mypackage"), put fun.cpp in mypackage/src and 
| did 
| 
| R CMD INSTALL mypackage, which seemed to compile mypackage.so OK. However, when 
| i am trying  to use module, i get error message.  Namely, after i run R and do 
| 
| >library("Rcpp") 
| >library("mypackage") 
| > mod<-Module("mod") 

You may want to try

    mod <- new( mod )
    bdtMod <- Module( "bdt" )			# get the module code
    bdt <- new( bdtMod$date )                  	# date class default constructor for reference instance

| >mod$norm(3,4) 
| 
| i get the following 
| 
| Error in Module(module, mustStart = TRUE) : 
|   Failed to initialize module pointer: Error in 
| FUN("_rcpp_module_boot_mod"[[1L]], ...): no such symbol _rcpp_module_boot_mod in 
| package .GlobalEnv 

Hm. Not sure what is going there. I can run it via inline as a quick test:

R> inc <- '
+ double norm(double x, double y){
+   return sqrt(x*x+y*y);
+ }
+ 
+ RCPP_MODULE(mod){
+   function("norm", &norm);
+ }
+ '
R> fx <- cxxfunction( signature(), "" , include = inc, plugin = "Rcpp" )
R> mod <- Module( "mod", getDynLib(fx) )
R> mod$norm(3,4)
[1] 5
R> mod
Rcpp module 'mod' 
	1 functions: 
           norm : 2 arguments

	0 classes : 
R>  
| I am pretty sure my error is a pretty obvious one, could someone give me a 
| pointer on what to do differently or where to look for reference. Literal search 
| for the error message doesn't bring anything useful.

What is your version?  What is your OS?

We just released Rcpp 0.9.1 a few days ago so I have been running a lot of
tests some of which include building and loading modules.  This "should have
worked" for you.

Again, follow-ups on rcpp-devel which I'll CC will be appreciated. You'd have
to sign up there to post.

Thanks, Dirk

-- 
Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com


From croosen at mango-solutions.com  Fri Feb 18 11:24:43 2011
From: croosen at mango-solutions.com (Charles Roosen)
Date: Fri, 18 Feb 2011 10:24:43 -0000
Subject: [Rd] debugger() fails if "..." in function arguments
Message-ID: <3CBFCFB1FEFFA841BA83ADF2F2A9C6FA011A3578@mango-data1.Mango.local>

Dear all,

I'm having a problem with debugger() in both R 2.8.0 and R 2.12.0.
Probably also versions in-between.  

I don't see it logged in the bug database, but it's hard for me to
imagine that no-one else has encountered it.  So my question is whether
it's a known problem with a workaround, or do I log it as a new problem?

The situation is that if I use "options(error=dump.frames)" and then use
"debugger()", it fails if there's "..." in the function arguments.
Repro and version info below.

Thanks,
Charlie Roosen

> myFunc <- function(a,b,...) {d <- a+b; stop("")}
> options(error=dump.frames)
> myFunc(1,2)
Error in myFunc(1, 2) : 

> debugger()
Message:  Error in myFunc(1, 2) : 
Available environments had calls:
1: myFunc(1, 2)
2: stop("")

Enter an environment number, or 0 to exit  Selection: 1
Error in get(.obj, envir = dump[[.selection]]) : 
  argument "..." is missing, with no default


> version
               _                            
platform       i386-pc-mingw32              
arch           i386                         
os             mingw32                      
system         i386, mingw32                
status                                      
major          2                            
minor          12.0                         
year           2010                         
month          10                           
day            15                           
svn rev        53317                        
language       R                            
version.string R version 2.12.0 (2010-10-15)


Charles Roosen, PhD
Technical Director
 
T: +41 (0)61 206 92 91 
M: +41 (0)79 248 70 71
F: +41 (0) 61 206 92 99

www.mango-solutions.com
 
Mango Solutions AG
Aeschenvorstadt 36
4051 Basel
Switzerland
 
 image002
 
LEGAL NOTICE
This message is intended for the use o...{{dropped:10}}


From jon.clayden at gmail.com  Fri Feb 18 13:12:38 2011
From: jon.clayden at gmail.com (Jon Clayden)
Date: Fri, 18 Feb 2011 12:12:38 +0000
Subject: [Rd] Ignoring .Rprofile when installing a package
In-Reply-To: <4D5C0873.2010404@braverock.com>
References: <AANLkTin_a=tANUqwH3_=zFadbFuc-M8KhHTovyuahDpD@mail.gmail.com>
	<alpine.LFD.2.02.1102161650260.11129@gannet.stats.ox.ac.uk>
	<4D5C0873.2010404@braverock.com>
Message-ID: <AANLkTintzjfx2pY4R6usohzEj7D3_cJXHi20E9vAMXBu@mail.gmail.com>

I would also be interested in knowing what the rationale is for this.

Moreover, it seems that the "standard" (and documented) approach to
this of calling "options(defaultPackages=c(...))" in ~/.Rprofile does
not get ignored when installing. The environment variable approach may
work, but it seems to me that this requires some (educated) guesswork.
Could R CMD INSTALL not ignore the default packages option?

Regards,
Jon


On 16 February 2011 17:25, Brian G. Peterson <brian at braverock.com> wrote:
> On 02/16/2011 10:57 AM, Prof Brian Ripley wrote:
>>
>> The most obvious answer is not to do that. You have not used the
>> standard mechanism to to do that (which should work here as R CMD
>> INSTALL overrides that one). It's all in ?Startup (look for
>> R_DEFAULT_PACKAGES).
>
> Note that R CMD INSTALL is not mentioned at all here.
>
>> The simplest way to ignore ~/.Rprofile is to set R_PROFILE_USER to
>> something else.
>
>>> I've tried R --vanilla CMD INSTALL, but that seems to have no effect.
>>
>> As documented.
>
> Then let's try this from another angle...
>
> Is there a rationale why --vanilla or --no-environ or --no-site-file or
> --no-init-file are *NOT* supported by R CMD INSTALL ? ?I don't see any
> reasoning for the inconsistency in the docs anywhere.
>
> If not, would R-core entertain a patch that would handle these options?
>
> This functionality is troublesome in a production installations where we
> *want* our users to have specific packages and environment options set all
> the time, and I need to edit the Rprofile.site file every time I upgrade one
> of these 'production' packages.
>
> Regards,
>
> ? - Brian
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From ripley at stats.ox.ac.uk  Fri Feb 18 14:06:23 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 18 Feb 2011 13:06:23 +0000 (GMT)
Subject: [Rd] debugger() fails if "..." in function arguments
In-Reply-To: <3CBFCFB1FEFFA841BA83ADF2F2A9C6FA011A3578@mango-data1.Mango.local>
References: <3CBFCFB1FEFFA841BA83ADF2F2A9C6FA011A3578@mango-data1.Mango.local>
Message-ID: <alpine.LFD.2.02.1102181244360.5129@toucan.stats.ox.ac.uk>

On Fri, 18 Feb 2011, Charles Roosen wrote:

> Dear all,
>
> I'm having a problem with debugger() in both R 2.8.0 and R 2.12.0.
> Probably also versions in-between.

But you are asked to report only on current R.

> I don't see it logged in the bug database, but it's hard for me to
> imagine that no-one else has encountered it.  So my question is whether
> it's a known problem with a workaround, or do I log it as a new problem?

I doubt if almost anyone uses dump.frames() in R.  I think this is 
known, and the workaround is 'don't do that': use error=recover.

> The situation is that if I use "options(error=dump.frames)" and then use
> "debugger()", it fails if there's "..." in the function arguments.
> Repro and version info below.
>
> Thanks,
> Charlie Roosen
>
>> myFunc <- function(a,b,...) {d <- a+b; stop("")}
>> options(error=dump.frames)
>> myFunc(1,2)
> Error in myFunc(1, 2) :
>
>> debugger()
> Message:  Error in myFunc(1, 2) :
> Available environments had calls:
> 1: myFunc(1, 2)
> 2: stop("")
>
> Enter an environment number, or 0 to exit  Selection: 1
> Error in get(.obj, envir = dump[[.selection]]) :
>  argument "..." is missing, with no default

That's easy to fix with a tryCatch() wrapper.  But the real problem is 
with last.dump(), and recover() has it to some extent:

options(error=recover)
myFunc(1,2,e=pi)
Error in myFunc(1, 2, e = pi) :

Enter a frame number, or 0 to exit

1: myFunc(1, 2, e = pi)

Selection: 1
Called from: top level
Browse[1]> e
Error during wrapup: object 'e' not found

If you know how, you can get to 'e' though ....

I am really not sure this is worth changing.

>
>> version
>               _
> platform       i386-pc-mingw32
> arch           i386
> os             mingw32
> system         i386, mingw32
> status
> major          2
> minor          12.0
> year           2010
> month          10
> day            15
> svn rev        53317
> language       R
> version.string R version 2.12.0 (2010-10-15)
>
>
> Charles Roosen, PhD
> Technical Director
>
> T: +41 (0)61 206 92 91
> M: +41 (0)79 248 70 71
> F: +41 (0) 61 206 92 99
>
> www.mango-solutions.com
>
> Mango Solutions AG
> Aeschenvorstadt 36
> 4051 Basel
> Switzerland
>
> image002
>
> LEGAL NOTICE
> This message is intended for the use o...{{dropped:10}}
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Fri Feb 18 14:44:20 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 18 Feb 2011 13:44:20 +0000 (GMT)
Subject: [Rd] dotchart {graphics} 2.11.1 vs. 2.12.1 [followed up from
 Rhelp]
In-Reply-To: <AANLkTi=-Ja17h9X2cx1AJB-+a7dK7tQUSK2SBP+fMZMy@mail.gmail.com>
References: <AANLkTi=-Ja17h9X2cx1AJB-+a7dK7tQUSK2SBP+fMZMy@mail.gmail.com>
Message-ID: <alpine.LFD.2.02.1102180948500.32212@toucan.stats.ox.ac.uk>

On Tue, 1 Feb 2011, Joshua Wiley wrote:

> Dear List,
>
> With the R 2.12.0 addition of table methods for points(), dotchart()
> struggles with tables.

Which of course it is not documented to accept, not even the base type 
of such tables, a 1-D array.  So this is detecting a previously 
undetected user error.

Because the table methods of lines/points have different defaults, 
your suggestions are not going to work (did you actually try them 
with the dotchart example?).  The best we can do is to throw an error 
if 'y' is specified in a table method.

> I found several possible solutions, but it is beyond my skill to 
> decide what is "best".  Here is a small example:

dotchart(as.vector(x)) works, but is probably not what you want.
dotchart(unclass(x)) works, but it is not guaranteed to keep working.

Unclassing is definitely dangerous, since the test is.numeric(x) 
invokes a generic function.  If methods have been written following 
the help page (and not all have), as.numeric(x) should do the trick, 
but needs to be done after names are extracted.

OTOH, learning the discipline of consulting the help pages if things 
do not work as you expect is a good one, since there is no way R is 
going to check all inputs to all functions.


> #############################################
> x <- table(infert$education)
> y <- 1:3L
>
> dotchart(x) # error about incorrect plot type
>
> ## moving closer to the cause, dotchart() essentially does
> plot(x = c(0, 150), y = c(0, 5), type = "n")
> points(x, y) # error, because arg #2 is the type
>
> ## One option would be to explicitly name the arguments in dotchart()
> points(x = x, y = y) # "works", but misses the point (no pun intended)
>
> ## Another possibility would be to add unclass(). I'm not sure
> ## if this would have other repercussions.  line 71 could become:
> points(unclass(x), y, pch = pch, col = color, bg = bg)
>
> ## Other options could be adding a method for dotchart()
> ## or to update the table method for points()
> points.table <- function (x, y, type = "h", lwd = 2, ...)
> {
>    if (length(dim(x)) == 1L) {
>        nx <- dimnames(x)[[1L]]
>        is.num <- suppressWarnings(!any(is.na(xx <- as.numeric(nx))))
>        x0 <- if (is.num)
>            xx
>        else seq.int(x)
>        if (missing(y)) {
>          points(x0, unclass(x), type = type, lwd = lwd, ...)
>        } else points(unclass(x), y, type = type, lwd = lwd, ...)
>    }
>    else stop("only for 1-D table")
> }
>
> plot(x = c(0, 150), y = c(0, 5), type = "n")
> points(x, y, type = "p")
>
> #############################################
>
>
>
> -- 
> Joshua Wiley
> Ph.D. Student, Health Psychology
> University of California, Los Angeles
> http://www.joshuawiley.com/

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From pauljohn32 at gmail.com  Sat Feb 19 05:00:28 2011
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Fri, 18 Feb 2011 22:00:28 -0600
Subject: [Rd] Set up new CRAN mirror; but have questions before finalizing.
Message-ID: <AANLkTi=yVCSGzFde-obL347__HOTBH6E+TcbXmhc-5c9@mail.gmail.com>

Hi, everybody

I have an account on Dreamhost.com and when I renewed it recently,
their message said my usage of storage and bandwidth had been
reasonably low. In an idle moment about 3 weeks ago, I followed your
instructions to set up a CRAN mirror on their server.  Here it is:

http://www.freefaculty.org/cran

It is not hosted at my University, but it is a working, high
availability server.  Is there any reason it could not be listed as a
CRAN mirror. (Although I really have no idea where these machines
exist. I'm pretty sure it is in the USA. I'll try to find out).

Maybe you might try it and see?  It has updated several times, no
trouble I can see in that.

I have a couple of small details to ask about.  Maybe this first one
is a potential  "bug report" for the CRAN mirror instructions.

1. Permissions on "src" and "web" folders are 700,  and so running
"update.packages" or an apt-get update against the debian stuff
results in permission denied errors.  I re-set the permissions
manually, but wonder if I'm actually supposed to mess around with your
archive.  After doing that, it works.  But I worry a little bit about
what else might not be readable "down there" in the hierarchy. And I
wonder why any body else's mirror works without doing that.

Notice before

> update.packages( repos=c("http://www.freefaculty.org/cran"))
Warning: unable to access index for repository
http://www.freefaculty.org/cran/src/contrib

and after giving others rx permission on "src".

> update.packages( repos=c("http://www.freefaculty.org/cran"))
RandomFields :
 Version 1.3.47 installed in /usr/local/lib/R/site-library
 Version 2.0.40 available at http://www.freefaculty.org/cran
Update (y/N/c)?

So at least that part works.  right?

2. When I run "apt-get update" against my mirror, i get a lot of
harassment about the lack of a security key for my repository.  Should
I be publishing an R Core team key to fix that, or my own key to do
what?  I've never administered an apt repository before. I have
administered yum repositories and the security there is in the key on
the individual RPMS, I don't quite understand what the Debian thing is
asking me to do.

If just a couple of you would test this out, I would feel more brave
in asking to have this listed on the CRAN mirror system.

Regards,

pj

-- 
Paul E. Johnson
Professor, Political Science
1541 Lilac Lane, Room 504
University of Kansas


From friedrich.leisch at stat.uni-muenchen.de  Sat Feb 19 07:43:22 2011
From: friedrich.leisch at stat.uni-muenchen.de (Friedrich Leisch)
Date: Sat, 19 Feb 2011 07:43:22 +0100
Subject: [Rd] Set up new CRAN mirror;
	but have questions before finalizing.
In-Reply-To: <AANLkTi=yVCSGzFde-obL347__HOTBH6E+TcbXmhc-5c9@mail.gmail.com>
References: <AANLkTi=yVCSGzFde-obL347__HOTBH6E+TcbXmhc-5c9@mail.gmail.com>
Message-ID: <19807.26250.233742.464297@ridcully.stat.uni-muenchen.de>

>>>>> On Fri, 18 Feb 2011 22:00:28 -0600,
>>>>> Paul Johnson (PJ) wrote:

  > Hi, everybody
  > I have an account on Dreamhost.com and when I renewed it recently,
  > their message said my usage of storage and bandwidth had been
  > reasonably low. In an idle moment about 3 weeks ago, I followed your
  > instructions to set up a CRAN mirror on their server.  Here it is:

  > http://www.freefaculty.org/cran

  > It is not hosted at my University, but it is a working, high
  > availability server.  Is there any reason it could not be listed as a
  > CRAN mirror. (Although I really have no idea where these machines
  > exist. I'm pretty sure it is in the USA. I'll try to find out).

We would need to know where it is because we lsit mirrors in the US
sorted by state ...
  

  > Maybe you might try it and see?  It has updated several times, no
  > trouble I can see in that.

  > I have a couple of small details to ask about.  Maybe this first one
  > is a potential  "bug report" for the CRAN mirror instructions.

  > 1. Permissions on "src" and "web" folders are 700,

Then you must have made a mistake in setting up the mirror, because on
the master we have 775 for both directories and all directories within
these two. We also had never complaints about this before.

  > and so running "update.packages" or an apt-get update against the
  > debian stuff results in permission denied errors.  I re-set the
  > permissions manually, but wonder if I'm actually supposed to mess
  > around with your archive.  After doing that, it works.  But I
  > worry a little bit about what else might not be readable "down
  > there" in the hierarchy. And I wonder why any body else's mirror
  > works without doing that.

Well, they simply mirrored our permissions ...  


  > 2. When I run "apt-get update" against my mirror, i get a lot of
  > harassment about the lack of a security key for my repository.  Should
  > I be publishing an R Core team key to fix that, or my own key to do
  > what?  I've never administered an apt repository before. I have
  > administered yum repositories and the security there is in the key on
  > the individual RPMS, I don't quite understand what the Debian thing is
  > asking me to do.

It is quite common then non-official Debian mirrors have no security
key, I would not worry too much about that.

Best regards,
Fritz Leisch


From paul_roebuck at comcast.net  Sat Feb 19 04:12:24 2011
From: paul_roebuck at comcast.net (Paul Roebuck)
Date: Fri, 18 Feb 2011 21:12:24 -0600
Subject: [Rd] Accessing Package NEWS (NEWS.Rd)
Message-ID: <0806D6AB-89F2-476A-BBBA-7A82F5A90983@comcast.net>

Okay. So, after having spent quite some time never really tracking down
why my package NEWS files were unacceptable to readNEWS(), I
noticed that there was recent (to me anyway) development that allowed
the NEWS to be done as an Rd file. Sweet! A more standard format...

I converted a NEWS file in one of my unreleased packages to Rd format.
checkNEWS() gave it a thumbs up.

But then it went south. Tried the following after installation:

> checkNEWS("myapp/trunk/MyApp/inst/NEWS.Rd")
[1] TRUE
> news(package="MyApp")

Nothing.

Debugging news() itself left me wondering. The first thing checked
for was 'inst/NEWS.Rd' - once I install the package, that would never
exist though, right? Should tools:::.build_news_db() instead use:

    nfile <- file.path(dir, c("NEWS.Rd", file.path("inst", "NEWS.Rd")))

On the slim chance it should, I modified the path to my
source folder's copy and continued debugging into 
tools:::.build_news_db_from_package_NEWS_Rd().


debug: ind <- grepl(re_v, nms, ignore.case = TRUE)
Browse[2]> 
debug: if (!all(ind)) warning("Cannot extract version info from the following section titles:\n", 
Browse[2]> ind
[1] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE
Browse[2]> 
debug: NULL
Browse[2]> 
debug: .make_news_db(cbind(ifelse(ind, sub(re_v, "\\1", nms), NA_character_), 
    ifelse(grepl(re_d, nms), sub(re_d, "\\1", nms), NA_character_), 
    db[, 2L], sub("\n*$", "", db[, 3L])), logical(nrow(db)), 
    "news_db_from_Rd")
Browse[2]> 
debugging in: .make_news_db(cbind(ifelse(ind, sub(re_v, "\\1", nms), NA_character_), 
    ifelse(grepl(re_d, nms), sub(re_d, "\\1", nms), NA_character_), 
    db[, 2L], sub("\n*$", "", db[, 3L])), logical(nrow(db)), 
    "news_db_from_Rd")
debug: {
    out <- data.frame(x, row.names = NULL, stringsAsFactors = FALSE)
    colnames(out) <- c("Version", "Date", "Category", "Text")
    if (!is.null(bad)) 
        attr(out, "bad") <- bad
    class(out) <- unique(c(classes, "news_db", "data.frame"))
    out
}
Browse[3]> 
debug: out <- data.frame(x, row.names = NULL, stringsAsFactors = FALSE)
Browse[3]> 
debug: colnames(out) <- c("Version", "Date", "Category", "Text")
Browse[3]> 
debug: if (!is.null(bad)) attr(out, "bad") <- bad
Browse[3]> 
debug: attr(out, "bad") <- bad
Browse[3]> 
debug: class(out) <- unique(c(classes, "news_db", "data.frame"))
Browse[3]> 
debug: out
Browse[3]> 
exiting from: .make_news_db(cbind(ifelse(ind, sub(re_v, "\\1", nms), NA_character_), 
    ifelse(grepl(re_d, nms), sub(re_d, "\\1", nms), NA_character_), 
    db[, 2L], sub("\n*$", "", db[, 3L])), logical(nrow(db)), 
    "news_db_from_Rd")
exiting from: tools:::.build_news_db_from_package_NEWS_Rd(newsfile)
Error: invalid version specification CHANGES IN VERSION 1.0.0CHANGES IN VERSION 1.0.1CHANGES IN VERSION 2.0.0


Well, so it didn't like my version numbers. But is the regexp check correct?

Browse[2]> .standard_regexps()$valid_package_version
[1] "([[:digit:]]+[.-]){1,}[[:digit:]]+"

Would appear as though packages with only major.minor comparisons would
pass. Or did I miss something...


----
P.S. Another thing I didn't see specified was whether this was an acceptable format
in current Rd format:

\section{CHANGES IN VERSION 2.0.0}{

Trying to get original TEXT files to be read by readNEWS(), the sections had to
read "CHANGES IN R VERSION nnn". Using Rd format, checkNEWS() seemed
to allow optionally using a package name instead (of 'R'). As it also allowed using
nothing, i went with that. What's the intended canonical format?


From hb at biostat.ucsf.edu  Sat Feb 19 19:00:29 2011
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Sat, 19 Feb 2011 10:00:29 -0800
Subject: [Rd] Set up new CRAN mirror;
	but have questions before finalizing.
In-Reply-To: <19807.26250.233742.464297@ridcully.stat.uni-muenchen.de>
References: <AANLkTi=yVCSGzFde-obL347__HOTBH6E+TcbXmhc-5c9@mail.gmail.com>
	<19807.26250.233742.464297@ridcully.stat.uni-muenchen.de>
Message-ID: <AANLkTinpeeDG_rGCYi4RyjrpDs9QuKKey7AaMSwiaYYG@mail.gmail.com>

On Fri, Feb 18, 2011 at 10:43 PM, Friedrich Leisch
<friedrich.leisch at stat.uni-muenchen.de> wrote:
>>>>>> On Fri, 18 Feb 2011 22:00:28 -0600,
>>>>>> Paul Johnson (PJ) wrote:
>
> ?> Hi, everybody
> ?> I have an account on Dreamhost.com and when I renewed it recently,
> ?> their message said my usage of storage and bandwidth had been
> ?> reasonably low. In an idle moment about 3 weeks ago, I followed your
> ?> instructions to set up a CRAN mirror on their server. ?Here it is:
>
> ?> http://www.freefaculty.org/cran
>
> ?> It is not hosted at my University, but it is a working, high
> ?> availability server. ?Is there any reason it could not be listed as a
> ?> CRAN mirror. (Although I really have no idea where these machines
> ?> exist. I'm pretty sure it is in the USA. I'll try to find out).
>
> We would need to know where it is because we lsit mirrors in the US
> sorted by state ...

http://ipinfodb.com/ip_locator.php?ip=www.freefaculty.org

?

/Henrik

>
>
> ?> Maybe you might try it and see? ?It has updated several times, no
> ?> trouble I can see in that.
>
> ?> I have a couple of small details to ask about. ?Maybe this first one
> ?> is a potential ?"bug report" for the CRAN mirror instructions.
>
> ?> 1. Permissions on "src" and "web" folders are 700,
>
> Then you must have made a mistake in setting up the mirror, because on
> the master we have 775 for both directories and all directories within
> these two. We also had never complaints about this before.
>
> ?> and so running "update.packages" or an apt-get update against the
> ?> debian stuff results in permission denied errors. ?I re-set the
> ?> permissions manually, but wonder if I'm actually supposed to mess
> ?> around with your archive. ?After doing that, it works. ?But I
> ?> worry a little bit about what else might not be readable "down
> ?> there" in the hierarchy. And I wonder why any body else's mirror
> ?> works without doing that.
>
> Well, they simply mirrored our permissions ...
>
>
> ?> 2. When I run "apt-get update" against my mirror, i get a lot of
> ?> harassment about the lack of a security key for my repository. ?Should
> ?> I be publishing an R Core team key to fix that, or my own key to do
> ?> what? ?I've never administered an apt repository before. I have
> ?> administered yum repositories and the security there is in the key on
> ?> the individual RPMS, I don't quite understand what the Debian thing is
> ?> asking me to do.
>
> It is quite common then non-official Debian mirrors have no security
> key, I would not worry too much about that.
>
> Best regards,
> Fritz Leisch
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From pauljohn32 at gmail.com  Sat Feb 19 19:41:50 2011
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Sat, 19 Feb 2011 12:41:50 -0600
Subject: [Rd] Set up new CRAN mirror;
	but have questions before finalizing.
In-Reply-To: <19807.26250.233742.464297@ridcully.stat.uni-muenchen.de>
References: <AANLkTi=yVCSGzFde-obL347__HOTBH6E+TcbXmhc-5c9@mail.gmail.com>
	<19807.26250.233742.464297@ridcully.stat.uni-muenchen.de>
Message-ID: <AANLkTin0CZ5a0xL8QVxX7a2PijDU+A0EQHnvOZotcQx2@mail.gmail.com>

On Sat, Feb 19, 2011 at 12:43 AM, Friedrich Leisch
<friedrich.leisch at stat.uni-muenchen.de> wrote:
>>>>>> On Fri, 18 Feb 2011 22:00:28 -0600,
>>>>>> Paul Johnson (PJ) wrote:
>
> ?> Hi, everybody

> ?> Maybe you might try it and see? ?It has updated several times, no
> ?> trouble I can see in that.
>
> ?> I have a couple of small details to ask about. ?Maybe this first one
> ?> is a potential ?"bug report" for the CRAN mirror instructions.
>
> ?> 1. Permissions on "src" and "web" folders are 700,
>
> Then you must have made a mistake in setting up the mirror, because on
> the master we have 775 for both directories and all directories within
> these two. We also had never complaints about this before.
>
Greetings, Fritz

I'm surprised too.  All I did was follow the very clear and simple
instructions in the HOWTO. I run this script in the folder where the
web server lives.
$ cat downloadCran.sh
rsync -rtlzv --delete cran.r-project.org::CRAN
/home/freefaculty/freefaculty.org/cran

I promise (sincerely) I changed nothing that forced src or web to 700.

I manually put all the directories to permission 755 and then will run
an update and see if they stay that way.  If all stays well, I'll
notify the address listed in the mirror HOWTO that this thing is in
California.

pj

>
> Best regards,
> Fritz Leisch
>



-- 
Paul E. Johnson
Professor, Political Science
1541 Lilac Lane, Room 504
University of Kansas


From gb at stat.umu.se  Sat Feb 19 23:44:04 2011
From: gb at stat.umu.se (=?iso-8859-1?Q?G=F6ran_Brostr=F6m?=)
Date: Sat, 19 Feb 2011 23:44:04 +0100
Subject: [Rd] pre-release?
Message-ID: <B60E27B4-B08F-433D-B89C-1B8F10B5DEFD@stat.umu.se>

When I install eha I get a warning:

1: package 'eha' was built under R version 2.12.2 

'eha' was installed thru 'install.packages("eha"), and as far as I can see, version 2.12.2 is not released yet. This is on a Mac, with 2.12.1.

G?ran

From simon.urbanek at r-project.org  Sun Feb 20 00:20:38 2011
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Sat, 19 Feb 2011 18:20:38 -0500
Subject: [Rd] pre-release?
In-Reply-To: <B60E27B4-B08F-433D-B89C-1B8F10B5DEFD@stat.umu.se>
References: <B60E27B4-B08F-433D-B89C-1B8F10B5DEFD@stat.umu.se>
Message-ID: <A0847647-B2A2-4616-B789-6284C239B3C8@r-project.org>

On Feb 19, 2011, at 5:44 PM, G?ran Brostr?m wrote:

> When I install eha I get a warning:
> 
> 1: package 'eha' was built under R version 2.12.2 
> 
> 'eha' was installed thru 'install.packages("eha"), and as far as I can see, version 2.12.2 is not released yet. This is on a Mac, with 2.12.1.
> 

This comes from the fact that the R-2.12-patched branch has moved from 2.12.1 at the time of the beta to 2.12.2 -- (now RC BTW).

Cheers,
Simon


From rpbarry at alaska.edu  Sun Feb 20 03:57:56 2011
From: rpbarry at alaska.edu (Ronald Barry)
Date: Sat, 19 Feb 2011 17:57:56 -0900
Subject: [Rd] Demo and 00Index problems
Message-ID: <AANLkTim=07VJmcSmbDny9afS1+nZVUP9-8hV9i8vz8Ad@mail.gmail.com>

Greetings,
  I am sure I'm missing the obvious, but my 00Index file in the demo
subdirectory is not recognized by R CMD check (the demo runs fine, but
I get a WARNING from R CMD check about a lack of demo/00Index file.
When I invoke demo()  in R I see the name but not description of the
demo).  Is there documentation (other than 'Writing R extensions') on
putting together the demo subdirectory?  Thanks.

Ron Barry


From ggrothendieck at gmail.com  Sun Feb 20 04:04:57 2011
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 19 Feb 2011 22:04:57 -0500
Subject: [Rd] Demo and 00Index problems
In-Reply-To: <AANLkTim=07VJmcSmbDny9afS1+nZVUP9-8hV9i8vz8Ad@mail.gmail.com>
References: <AANLkTim=07VJmcSmbDny9afS1+nZVUP9-8hV9i8vz8Ad@mail.gmail.com>
Message-ID: <AANLkTim_8GabgON_QT7DN+LxLL7BfxYoQthrbNA0+EVT@mail.gmail.com>

On Sat, Feb 19, 2011 at 9:57 PM, Ronald Barry <rpbarry at alaska.edu> wrote:
> Greetings,
> ?I am sure I'm missing the obvious, but my 00Index file in the demo
> subdirectory is not recognized by R CMD check (the demo runs fine, but
> I get a WARNING from R CMD check about a lack of demo/00Index file.
> When I invoke demo() ?in R I see the name but not description of the
> demo). ?Is there documentation (other than 'Writing R extensions') on
> putting together the demo subdirectory? ?Thanks.
>

Download the source of any existing package that has a demo/00Index file, e.g.
http://cran.r-project.org/web/packages/gsubfn/index.html


-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From jwiley.psych at gmail.com  Sun Feb 20 08:34:29 2011
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Sat, 19 Feb 2011 23:34:29 -0800
Subject: [Rd] dotchart {graphics} 2.11.1 vs. 2.12.1 [followed up from
	Rhelp]
In-Reply-To: <alpine.LFD.2.02.1102180948500.32212@toucan.stats.ox.ac.uk>
References: <AANLkTi=-Ja17h9X2cx1AJB-+a7dK7tQUSK2SBP+fMZMy@mail.gmail.com>
	<alpine.LFD.2.02.1102180948500.32212@toucan.stats.ox.ac.uk>
Message-ID: <AANLkTinWTuZLBtV6XE8F=mARxokqjmK55+ZCZude803p@mail.gmail.com>

On Fri, Feb 18, 2011 at 5:44 AM, Prof Brian Ripley
<ripley at stats.ox.ac.uk> wrote:
> On Tue, 1 Feb 2011, Joshua Wiley wrote:
>
>> Dear List,
>>
>> With the R 2.12.0 addition of table methods for points(), dotchart()
>> struggles with tables.
>
> Which of course it is not documented to accept, not even the base type of
> such tables, a 1-D array. ?So this is detecting a previously undetected user
> error.

Of course, I hope my wording did not imply there was any problem or
error.  I was interested in "what is the best way to make this work?"

>
> Because the table methods of lines/points have different defaults, your
> suggestions are not going to work (did you actually try them with the
> dotchart example?).

I thought I had, but evidently not.

>The best we can do is to throw an error if 'y' is
> specified in a table method.
>
>> I found several possible solutions, but it is beyond my skill to decide
>> what is "best". ?Here is a small example:
>
> dotchart(as.vector(x)) works, but is probably not what you want.
> dotchart(unclass(x)) works, but it is not guaranteed to keep working.
>
> Unclassing is definitely dangerous, since the test is.numeric(x) invokes a
> generic function. ?If methods have been written following the help page (and
> not all have), as.numeric(x) should do the trick, but needs to be done after
> names are extracted.

I take it creating a named vector using name extraction and
as.numeric(x) is the best approach.

Thanks for the information,

Josh

>
> OTOH, learning the discipline of consulting the help pages if things do not
> work as you expect is a good one, since there is no way R is going to check
> all inputs to all functions.
>
>
>> #############################################
>> x <- table(infert$education)
>> y <- 1:3L
>>
>> dotchart(x) # error about incorrect plot type
>>
>> ## moving closer to the cause, dotchart() essentially does
>> plot(x = c(0, 150), y = c(0, 5), type = "n")
>> points(x, y) # error, because arg #2 is the type
>>
>> ## One option would be to explicitly name the arguments in dotchart()
>> points(x = x, y = y) # "works", but misses the point (no pun intended)
>>
>> ## Another possibility would be to add unclass(). I'm not sure
>> ## if this would have other repercussions. ?line 71 could become:
>> points(unclass(x), y, pch = pch, col = color, bg = bg)
>>
>> ## Other options could be adding a method for dotchart()
>> ## or to update the table method for points()
>> points.table <- function (x, y, type = "h", lwd = 2, ...)
>> {
>> ? if (length(dim(x)) == 1L) {
>> ? ? ? nx <- dimnames(x)[[1L]]
>> ? ? ? is.num <- suppressWarnings(!any(is.na(xx <- as.numeric(nx))))
>> ? ? ? x0 <- if (is.num)
>> ? ? ? ? ? xx
>> ? ? ? else seq.int(x)
>> ? ? ? if (missing(y)) {
>> ? ? ? ? points(x0, unclass(x), type = type, lwd = lwd, ...)
>> ? ? ? } else points(unclass(x), y, type = type, lwd = lwd, ...)
>> ? }
>> ? else stop("only for 1-D table")
>> }
>>
>> plot(x = c(0, 150), y = c(0, 5), type = "n")
>> points(x, y, type = "p")
>>
>> #############################################
>>
>>
>>
>> --
>> Joshua Wiley
>> Ph.D. Student, Health Psychology
>> University of California, Los Angeles
>> http://www.joshuawiley.com/
>
> --
> Brian D. Ripley, ? ? ? ? ? ? ? ? ?ripley at stats.ox.ac.uk
> Professor of Applied Statistics, ?http://www.stats.ox.ac.uk/~ripley/
> University of Oxford, ? ? ? ? ? ? Tel: ?+44 1865 272861 (self)
> 1 South Parks Road, ? ? ? ? ? ? ? ? ? ? +44 1865 272866 (PA)
> Oxford OX1 3TG, UK ? ? ? ? ? ? ? ?Fax: ?+44 1865 272595


From jcrudy at gmail.com  Sun Feb 20 01:50:58 2011
From: jcrudy at gmail.com (Jason Rudy)
Date: Sat, 19 Feb 2011 16:50:58 -0800
Subject: [Rd] Problem using F77_CALL(dgemm) in a package
Message-ID: <AANLkTimAHcu_=_rMR9bFVYK86bmWhs8Pimgv3L-LiHsV@mail.gmail.com>

Dear R-devel,

I've written a numerical solver for SOCPs (second order cone programs)
in R, and now I want to move most of the solver code into C for speed.
 I've written combined R/C packages before, but in this case I need to
do matrix operations in my C code.  As I have never done that before,
I'm trying to write some simple examples to make sure I understand the
basics.  I am stuck on the first one.  I'm trying to write a function
to multiply two matrices using the blas routine dgemm.  The name of my
example package is CMATRIX.  My code is as follows.

I have a file matrix.c in my src directory:

#include <R.h>
#include <R_ext/Utils.h>
#include <R_ext/Lapack.h>
#include <R_ext/BLAS.h>

//Computes C = A*B
void R_matrix_multiply(double * A, double * B, int * m, int *n, int *
p, double * C){
	double one = 1.0;
	double zero = 0.0;

        //Just printing the input arguments
	Rprintf("m = %d, n = %d, p = %d\n",*m,*n,*p);
	int i;
	for(i=0;i<(*m**n);i++){
		Rprintf("%f ",A[i]);
	}
	Rprintf("\n");
	for(i=0;i<(*n**p);i++){
		Rprintf("%f ",B[i]);
	}
	Rprintf("\n");
	for(i=0;i<(*m**p);i++){
		Rprintf("%f ",C[i]);
	}
	Rprintf("\n");	


        //Here is the actual multiplication	
	F77_CALL(dgemm)("N","N",m,n,p,&one,A,m,B,n,&zero,C,m);
}

And the file C_matrix_multiply.R in my R directory:

C_matrix_multiply = function(A,B){
	C <- matrix(0,nrow(A),ncol(B))
	cout <- .C("R_matrix_multiply",as.double(A),as.double(B),nrow(A),ncol(A),ncol(B),as.double(C))
	return(matrix(cout$C,nrowA,ncol(B)))
	
}

My namespace file is:

export("C_matrix_multiply")
useDynLib(CMATRIX.so,R_matrix_multiply)

I'm not sure if it's necessary, but I've also included a Makevars.in
file in my src directory:

PKG_CPPFLAGS=@PKG_CPPFLAGS@
PKG_CFLAGS=@PKG_CFLAGS@
PKG_LIBS=@PKG_LIBS@  ${LAPACK_LIBS} ${BLAS_LIBS} ${FLIBS}

which I simply copied from the diversitree package, which seems to use
a lot of fortran.  I have the same problem (which I am getting to)
with or without this Makevars.in file.

I install my package using:

R CMD INSTALL CMATRIX

Then I start up R and attempt to run the following code:

#Make some random matrices
A = matrix(rnorm(8),4,2)
B = matrix(rnorm(6),2,3)

#Load my package
library(CMATRIX)

#Print the matrices
A
B

#Try to multiply them
product = C_matrix_multiply(A,B)

What I want, and what according to my understanding should happen, is
for product to contain the same matrix as would result from A %*% B.
Instead, I get the following:

> A = matrix(rnorm(8),4,2)
> B = matrix(rnorm(6),2,3)
> library(CMATRIX)
> A
           [,1]         [,2]
[1,] -0.4981664 -0.7243532
[2,]  0.1428766 -1.5501623
[3,] -2.0624701  1.5104507
[4,] -0.5871962  0.3049442
> B
            [,1]            [,2]            [,3]
[1,]  0.02477964 0.5827084 1.8434375
[2,] -0.20200104 1.7294264 0.9071397
> C_matrix_multiply(A,B)
m = 4, n = 2, p = 3
-0.498166 0.142877 -2.062470 -0.587196 -0.724353 -1.550162 1.510451 0.304944
0.024780 -0.202001 0.582708 1.729426 1.843437 0.907140
0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000
0.000000 0.000000 0.000000 0.000000 0.000000
Parameter 10 to routine DGEMM  was incorrect
Mac OS BLAS parameter error in DGEMM , parameter #0, (unavailable), is 0

and R immediately dies.  I know the arguments are being passed into
the C code and everything up to my F77_CALL is functioning based on
the printed output.  The problem is definitely something to do with my
F77_CALL(dgemm) line.  My understanding is that parameter 10 should be
the leading dimension of the matrix B, which in this case should be
equal to 2, the number of rows in that matrix, which is what I am
doing.  I have also considered that parameter numbering starts at 0,
in which case the incorrect parameter is &zero, but again that seems
correct to me.  All of my reading and research suggests I am doing
everything correctly, so I am somewhat stumped.  Perhaps I am missing
something simple or obvious, as I have never done this before and am
proceeding with only google and the R docs as my guide.  I am
wondering if anybody can see what I'm doing wrong here, or perhaps
something I could do to try to fix it.  Any assistance would be
greatly appreciated.

Best Regards,

Jason Rudy
Graduate Student
Bioinformatics and Medical Informatics Program
San Diego State University


From ripley at stats.ox.ac.uk  Sun Feb 20 16:42:44 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 20 Feb 2011 15:42:44 +0000 (GMT)
Subject: [Rd] Problem using F77_CALL(dgemm) in a package
In-Reply-To: <AANLkTimAHcu_=_rMR9bFVYK86bmWhs8Pimgv3L-LiHsV@mail.gmail.com>
References: <AANLkTimAHcu_=_rMR9bFVYK86bmWhs8Pimgv3L-LiHsV@mail.gmail.com>
Message-ID: <alpine.LFD.2.02.1102201540060.16292@gannet.stats.ox.ac.uk>

Look a close look at matprod in src/main/array in the R sources.
Hint: it is the other dimensions you have wrong.

And as BLAS is Fortran, counts do start at 1.

On Sat, 19 Feb 2011, Jason Rudy wrote:

> Dear R-devel,
>
> I've written a numerical solver for SOCPs (second order cone programs)
> in R, and now I want to move most of the solver code into C for speed.
> I've written combined R/C packages before, but in this case I need to
> do matrix operations in my C code.  As I have never done that before,
> I'm trying to write some simple examples to make sure I understand the
> basics.  I am stuck on the first one.  I'm trying to write a function
> to multiply two matrices using the blas routine dgemm.  The name of my
> example package is CMATRIX.  My code is as follows.
>
> I have a file matrix.c in my src directory:
>
> #include <R.h>
> #include <R_ext/Utils.h>
> #include <R_ext/Lapack.h>
> #include <R_ext/BLAS.h>
>
> //Computes C = A*B
> void R_matrix_multiply(double * A, double * B, int * m, int *n, int *
> p, double * C){
> 	double one = 1.0;
> 	double zero = 0.0;
>
>        //Just printing the input arguments
> 	Rprintf("m = %d, n = %d, p = %d\n",*m,*n,*p);
> 	int i;
> 	for(i=0;i<(*m**n);i++){
> 		Rprintf("%f ",A[i]);
> 	}
> 	Rprintf("\n");
> 	for(i=0;i<(*n**p);i++){
> 		Rprintf("%f ",B[i]);
> 	}
> 	Rprintf("\n");
> 	for(i=0;i<(*m**p);i++){
> 		Rprintf("%f ",C[i]);
> 	}
> 	Rprintf("\n");
>
>
>        //Here is the actual multiplication
> 	F77_CALL(dgemm)("N","N",m,n,p,&one,A,m,B,n,&zero,C,m);
> }
>
> And the file C_matrix_multiply.R in my R directory:
>
> C_matrix_multiply = function(A,B){
> 	C <- matrix(0,nrow(A),ncol(B))
> 	cout <- .C("R_matrix_multiply",as.double(A),as.double(B),nrow(A),ncol(A),ncol(B),as.double(C))
> 	return(matrix(cout$C,nrowA,ncol(B)))
>
> }
>
> My namespace file is:
>
> export("C_matrix_multiply")
> useDynLib(CMATRIX.so,R_matrix_multiply)
>
> I'm not sure if it's necessary, but I've also included a Makevars.in
> file in my src directory:
>
> PKG_CPPFLAGS=@PKG_CPPFLAGS@
> PKG_CFLAGS=@PKG_CFLAGS@
> PKG_LIBS=@PKG_LIBS@  ${LAPACK_LIBS} ${BLAS_LIBS} ${FLIBS}
>
> which I simply copied from the diversitree package, which seems to use
> a lot of fortran.  I have the same problem (which I am getting to)
> with or without this Makevars.in file.
>
> I install my package using:
>
> R CMD INSTALL CMATRIX
>
> Then I start up R and attempt to run the following code:
>
> #Make some random matrices
> A = matrix(rnorm(8),4,2)
> B = matrix(rnorm(6),2,3)
>
> #Load my package
> library(CMATRIX)
>
> #Print the matrices
> A
> B
>
> #Try to multiply them
> product = C_matrix_multiply(A,B)
>
> What I want, and what according to my understanding should happen, is
> for product to contain the same matrix as would result from A %*% B.
> Instead, I get the following:
>
>> A = matrix(rnorm(8),4,2)
>> B = matrix(rnorm(6),2,3)
>> library(CMATRIX)
>> A
>           [,1]         [,2]
> [1,] -0.4981664 -0.7243532
> [2,]  0.1428766 -1.5501623
> [3,] -2.0624701  1.5104507
> [4,] -0.5871962  0.3049442
>> B
>            [,1]            [,2]            [,3]
> [1,]  0.02477964 0.5827084 1.8434375
> [2,] -0.20200104 1.7294264 0.9071397
>> C_matrix_multiply(A,B)
> m = 4, n = 2, p = 3
> -0.498166 0.142877 -2.062470 -0.587196 -0.724353 -1.550162 1.510451 0.304944
> 0.024780 -0.202001 0.582708 1.729426 1.843437 0.907140
> 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000
> 0.000000 0.000000 0.000000 0.000000 0.000000
> Parameter 10 to routine DGEMM  was incorrect
> Mac OS BLAS parameter error in DGEMM , parameter #0, (unavailable), is 0
>
> and R immediately dies.  I know the arguments are being passed into
> the C code and everything up to my F77_CALL is functioning based on
> the printed output.  The problem is definitely something to do with my
> F77_CALL(dgemm) line.  My understanding is that parameter 10 should be
> the leading dimension of the matrix B, which in this case should be
> equal to 2, the number of rows in that matrix, which is what I am
> doing.  I have also considered that parameter numbering starts at 0,
> in which case the incorrect parameter is &zero, but again that seems
> correct to me.  All of my reading and research suggests I am doing
> everything correctly, so I am somewhat stumped.  Perhaps I am missing
> something simple or obvious, as I have never done this before and am
> proceeding with only google and the R docs as my guide.  I am
> wondering if anybody can see what I'm doing wrong here, or perhaps
> something I could do to try to fix it.  Any assistance would be
> greatly appreciated.
>
> Best Regards,
>
> Jason Rudy
> Graduate Student
> Bioinformatics and Medical Informatics Program
> San Diego State University
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From edd at debian.org  Sun Feb 20 16:50:43 2011
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sun, 20 Feb 2011 09:50:43 -0600
Subject: [Rd] Problem using F77_CALL(dgemm) in a package
In-Reply-To: <AANLkTimAHcu_=_rMR9bFVYK86bmWhs8Pimgv3L-LiHsV@mail.gmail.com>
References: <AANLkTimAHcu_=_rMR9bFVYK86bmWhs8Pimgv3L-LiHsV@mail.gmail.com>
Message-ID: <19809.14419.760969.854831@max.nulle.part>


On 19 February 2011 at 16:50, Jason Rudy wrote:
| Dear R-devel,
| 
| I've written a numerical solver for SOCPs (second order cone programs)
| in R, and now I want to move most of the solver code into C for speed.
|  I've written combined R/C packages before, but in this case I need to
| do matrix operations in my C code.  As I have never done that before,
| I'm trying to write some simple examples to make sure I understand the
| basics.  I am stuck on the first one.  I'm trying to write a function
| to multiply two matrices using the blas routine dgemm.  The name of my
| example package is CMATRIX.  My code is as follows.

There is of course merit in working through the barebones API but in case you
would consider a higher-level alternative, consider these few lines based on
RcppArmadillo (which end up calling dgemm() for you via R's linkage to the BLAS)

  suppressMessages(library(inline))
  
  txt <- '
     Rcpp::NumericMatrix Ar(A);	// creates Rcpp matrix from SEXP
     Rcpp::NumericMatrix Br(B);	// creates Rcpp matrix from SEXP
  
     arma::mat Am(Ar.begin(), Ar.nrow(), Ar.ncol(), false); // Arma mat, no copy
     arma::mat Bm(Br.begin(), Br.nrow(), Br.ncol(), false); // Arma mat, no copy
  
     arma::mat Cm = Am * Bm;
  
     return Rcpp::wrap(Cm);
     '
  
  mmult <- cxxfunction(signature(A="numeric", B="numeric"),
                       body=txt,
                       plugin="RcppArmadillo")
  
  A <- matrix(1:9, 3, 3)
  B <- matrix(9:1, 3, 3)
  C <- mmult(A, B)
  print(C)

which when passed into R yield

  R> txt <- '
  +    Rcpp::NumericMatrix Ar(A); // creates Rcpp matrix from SEXP
  +    Rcpp::NumericMatrix Br(B); // creates Rcpp matrix from SEXP
  +    arma::mat Am(Ar.begin(), Ar.nrow(), Ar.ncol(), false); // Arma mat, no copy
  +    arma::mat Bm(Br.begin(), Br.nrow(), Br.ncol(), false); // Arma mat, no copy
  +    arma::mat Cm = Am * Bm;
  +    return Rcpp::wrap(Cm);
  +    '
  R> mmult <- cxxfunction(signature(A="numeric", B="numeric"),
  +                      body=txt,
  +                      plugin="RcppArmadillo")
  R> A <- matrix(1:9, 3, 3)
  R> B <- matrix(9:1, 3, 3)
  R> C <- mmult(A, B)
  R> C
       [,1] [,2] [,3]
  [1,]   90   54   18
  [2,]  114   69   24
  [3,]  138   84   30
  R> 

You can then use this helper function to have a package created for you:

  RcppArmadillo.package.skeleton("mmult", mmult, path="/tmp")

The rcpp-devel list is open for help and further questions should you have any.

Cheers, Dirk

-- 
Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com


From edd at debian.org  Sun Feb 20 17:11:21 2011
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sun, 20 Feb 2011 10:11:21 -0600
Subject: [Rd] Problem using F77_CALL(dgemm) in a package
In-Reply-To: <19809.14419.760969.854831@max.nulle.part>
References: <AANLkTimAHcu_=_rMR9bFVYK86bmWhs8Pimgv3L-LiHsV@mail.gmail.com>
	<19809.14419.760969.854831@max.nulle.part>
Message-ID: <19809.15657.103744.21821@max.nulle.part>


On 20 February 2011 at 09:50, Dirk Eddelbuettel wrote:
| There is of course merit in working through the barebones API but in case you
| would consider a higher-level alternative, consider these few lines based on
| RcppArmadillo (which end up calling dgemm() for you via R's linkage to the BLAS)

PS I always forget that we have direct support in Rcpp::as<> for Armadillo
matrices. The examples reduces to three lines in C++, and you never need to
worry about row or column dimension, or memory allocation or deallocation:

  R> suppressMessages(library(inline))
  R> txt <- '
  +    arma::mat Am = Rcpp::as< arma::mat >(A);
  +    arma::mat Bm = Rcpp::as< arma::mat >(B);
  +    return Rcpp::wrap( Am * Bm );
  +    '
  R> mmult <- cxxfunction(signature(A="numeric", B="numeric"),
  +                      body=txt,
  +                      plugin="RcppArmadillo")
  R> A <- matrix(1:9, 3, 3)
  R> B <- matrix(9:1, 3, 3)
  R> C <- mmult(A, B)
  R> print(C)
       [,1] [,2] [,3]
  [1,]   90   54   18
  [2,]  114   69   24
  [3,]  138   84   30
  R> 

Matrices A and B from directly initialise Armadillo matrices, and the result
can be returned directly.

Hth, Dirk

-- 
Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com


From jcrudy at gmail.com  Sun Feb 20 23:23:26 2011
From: jcrudy at gmail.com (Jason Rudy)
Date: Sun, 20 Feb 2011 14:23:26 -0800
Subject: [Rd] Problem using F77_CALL(dgemm) in a package
In-Reply-To: <alpine.LFD.2.02.1102201540060.16292@gannet.stats.ox.ac.uk>
References: <AANLkTimAHcu_=_rMR9bFVYK86bmWhs8Pimgv3L-LiHsV@mail.gmail.com>
	<alpine.LFD.2.02.1102201540060.16292@gannet.stats.ox.ac.uk>
Message-ID: <AANLkTi=CQhxm5RBhymbCBLz8JAYs1cbEy=xC9LR_n8js@mail.gmail.com>

It was indeed a simple problem!  I took a look at that array.c as you
suggested and that cleared it right up.  So, the correct C code is:

#include <R.h>
#include <R_ext/Utils.h>
#include <R_ext/Lapack.h>
#include <R_ext/BLAS.h>

void R_matrix_multiply(double * A, double * B, int * m, int *n, int *
p, double * C){

	double one = 1.0;
	double zero = 0.0;

        //Just printing the input arguments
	Rprintf("m = %d, n = %d, p = %d\n",*m,*n,*p);
	int i;
	for(i=0;i<(*m**n);i++){
		Rprintf("%f ",A[i]);
	}
	Rprintf("\n");
	for(i=0;i<(*n**p);i++){
		Rprintf("%f ",B[i]);
	}
	Rprintf("\n");
	for(i=0;i<(*m**p);i++){
		Rprintf("%f ",C[i]);
	}
	Rprintf("\n");	
	
        //Here is the actual multiplication
	F77_CALL(dgemm)("N","N",m,p,n,&one,A,m,B,n,&zero,C,m);
}

The only difference being that I had the 4th and 5th arguments (n and
p) mixed up.  There was also a problem in my R code after the
multiplication took place.  For the record, the correct R code is:

C_matrix_multiply = function(A,B){
	C <- matrix(0,nrow(A),ncol(B))
	cout <- .C("R_matrix_multiply",as.double(A),as.double(B),nrow(A),ncol(A),ncol(B),as.double(C))
	return(matrix(cout[[6]],nrow(A),ncol(B)))
}

Thanks for the help.  Now that I have a functioning example I am well
on my way to completing this project.

-Jason

On Sun, Feb 20, 2011 at 7:42 AM, Prof Brian Ripley
<ripley at stats.ox.ac.uk> wrote:
> Look a close look at matprod in src/main/array in the R sources.
> Hint: it is the other dimensions you have wrong.
>
> And as BLAS is Fortran, counts do start at 1.
>
> On Sat, 19 Feb 2011, Jason Rudy wrote:
>
>> Dear R-devel,
>>
>> I've written a numerical solver for SOCPs (second order cone programs)
>> in R, and now I want to move most of the solver code into C for speed.
>> I've written combined R/C packages before, but in this case I need to
>> do matrix operations in my C code. ?As I have never done that before,
>> I'm trying to write some simple examples to make sure I understand the
>> basics. ?I am stuck on the first one. ?I'm trying to write a function
>> to multiply two matrices using the blas routine dgemm. ?The name of my
>> example package is CMATRIX. ?My code is as follows.
>>
>> I have a file matrix.c in my src directory:
>>
>> #include <R.h>
>> #include <R_ext/Utils.h>
>> #include <R_ext/Lapack.h>
>> #include <R_ext/BLAS.h>
>>
>> //Computes C = A*B
>> void R_matrix_multiply(double * A, double * B, int * m, int *n, int *
>> p, double * C){
>> ? ? ? ?double one = 1.0;
>> ? ? ? ?double zero = 0.0;
>>
>> ? ? ? //Just printing the input arguments
>> ? ? ? ?Rprintf("m = %d, n = %d, p = %d\n",*m,*n,*p);
>> ? ? ? ?int i;
>> ? ? ? ?for(i=0;i<(*m**n);i++){
>> ? ? ? ? ? ? ? ?Rprintf("%f ",A[i]);
>> ? ? ? ?}
>> ? ? ? ?Rprintf("\n");
>> ? ? ? ?for(i=0;i<(*n**p);i++){
>> ? ? ? ? ? ? ? ?Rprintf("%f ",B[i]);
>> ? ? ? ?}
>> ? ? ? ?Rprintf("\n");
>> ? ? ? ?for(i=0;i<(*m**p);i++){
>> ? ? ? ? ? ? ? ?Rprintf("%f ",C[i]);
>> ? ? ? ?}
>> ? ? ? ?Rprintf("\n");
>>
>>
>> ? ? ? //Here is the actual multiplication
>> ? ? ? ?F77_CALL(dgemm)("N","N",m,n,p,&one,A,m,B,n,&zero,C,m);
>> }
>>
>> And the file C_matrix_multiply.R in my R directory:
>>
>> C_matrix_multiply = function(A,B){
>> ? ? ? ?C <- matrix(0,nrow(A),ncol(B))
>> ? ? ? ?cout <-
>> .C("R_matrix_multiply",as.double(A),as.double(B),nrow(A),ncol(A),ncol(B),as.double(C))
>> ? ? ? ?return(matrix(cout$C,nrowA,ncol(B)))
>>
>> }
>>
>> My namespace file is:
>>
>> export("C_matrix_multiply")
>> useDynLib(CMATRIX.so,R_matrix_multiply)
>>
>> I'm not sure if it's necessary, but I've also included a Makevars.in
>> file in my src directory:
>>
>> PKG_CPPFLAGS=@PKG_CPPFLAGS@
>> PKG_CFLAGS=@PKG_CFLAGS@
>> PKG_LIBS=@PKG_LIBS@ ?${LAPACK_LIBS} ${BLAS_LIBS} ${FLIBS}
>>
>> which I simply copied from the diversitree package, which seems to use
>> a lot of fortran. ?I have the same problem (which I am getting to)
>> with or without this Makevars.in file.
>>
>> I install my package using:
>>
>> R CMD INSTALL CMATRIX
>>
>> Then I start up R and attempt to run the following code:
>>
>> #Make some random matrices
>> A = matrix(rnorm(8),4,2)
>> B = matrix(rnorm(6),2,3)
>>
>> #Load my package
>> library(CMATRIX)
>>
>> #Print the matrices
>> A
>> B
>>
>> #Try to multiply them
>> product = C_matrix_multiply(A,B)
>>
>> What I want, and what according to my understanding should happen, is
>> for product to contain the same matrix as would result from A %*% B.
>> Instead, I get the following:
>>
>>> A = matrix(rnorm(8),4,2)
>>> B = matrix(rnorm(6),2,3)
>>> library(CMATRIX)
>>> A
>>
>> ? ? ? ? ?[,1] ? ? ? ? [,2]
>> [1,] -0.4981664 -0.7243532
>> [2,] ?0.1428766 -1.5501623
>> [3,] -2.0624701 ?1.5104507
>> [4,] -0.5871962 ?0.3049442
>>>
>>> B
>>
>> ? ? ? ? ? [,1] ? ? ? ? ? ?[,2] ? ? ? ? ? ?[,3]
>> [1,] ?0.02477964 0.5827084 1.8434375
>> [2,] -0.20200104 1.7294264 0.9071397
>>>
>>> C_matrix_multiply(A,B)
>>
>> m = 4, n = 2, p = 3
>> -0.498166 0.142877 -2.062470 -0.587196 -0.724353 -1.550162 1.510451
>> 0.304944
>> 0.024780 -0.202001 0.582708 1.729426 1.843437 0.907140
>> 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000
>> 0.000000 0.000000 0.000000 0.000000 0.000000
>> Parameter 10 to routine DGEMM ?was incorrect
>> Mac OS BLAS parameter error in DGEMM , parameter #0, (unavailable), is 0
>>
>> and R immediately dies. ?I know the arguments are being passed into
>> the C code and everything up to my F77_CALL is functioning based on
>> the printed output. ?The problem is definitely something to do with my
>> F77_CALL(dgemm) line. ?My understanding is that parameter 10 should be
>> the leading dimension of the matrix B, which in this case should be
>> equal to 2, the number of rows in that matrix, which is what I am
>> doing. ?I have also considered that parameter numbering starts at 0,
>> in which case the incorrect parameter is &zero, but again that seems
>> correct to me. ?All of my reading and research suggests I am doing
>> everything correctly, so I am somewhat stumped. ?Perhaps I am missing
>> something simple or obvious, as I have never done this before and am
>> proceeding with only google and the R docs as my guide. ?I am
>> wondering if anybody can see what I'm doing wrong here, or perhaps
>> something I could do to try to fix it. ?Any assistance would be
>> greatly appreciated.
>>
>> Best Regards,
>>
>> Jason Rudy
>> Graduate Student
>> Bioinformatics and Medical Informatics Program
>> San Diego State University
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
> --
> Brian D. Ripley, ? ? ? ? ? ? ? ? ?ripley at stats.ox.ac.uk
> Professor of Applied Statistics, ?http://www.stats.ox.ac.uk/~ripley/
> University of Oxford, ? ? ? ? ? ? Tel: ?+44 1865 272861 (self)
> 1 South Parks Road, ? ? ? ? ? ? ? ? ? ? +44 1865 272866 (PA)
> Oxford OX1 3TG, UK ? ? ? ? ? ? ? ?Fax: ?+44 1865 272595
>


From jcrudy at gmail.com  Sun Feb 20 23:39:00 2011
From: jcrudy at gmail.com (Jason Rudy)
Date: Sun, 20 Feb 2011 14:39:00 -0800
Subject: [Rd] Problem using F77_CALL(dgemm) in a package
In-Reply-To: <19809.15657.103744.21821@max.nulle.part>
References: <AANLkTimAHcu_=_rMR9bFVYK86bmWhs8Pimgv3L-LiHsV@mail.gmail.com>
	<19809.14419.760969.854831@max.nulle.part>
	<19809.15657.103744.21821@max.nulle.part>
Message-ID: <AANLkTikP74hDvS9RAyzR68pKU6fHXuMWMtZ9o3tzZkAx@mail.gmail.com>

I've never used C++ before, so for this project I think I will stick
with just using the BLAS and LAPACK routines directly.  Another issue
is that I will need to do some sparse matrix computations, for which I
am planning to use CSPARSE, at least to begin with.  I am interested
by RcppArmadillo, and would consider it for future projects.  If you
don't mind, what in your opinion are the major pros and cons of an
RcppArmadillo solution compared to simply using the BLAS or LAPACK
routines through the .C interface?

-Jason

On Sun, Feb 20, 2011 at 8:11 AM, Dirk Eddelbuettel <edd at debian.org> wrote:
>
> On 20 February 2011 at 09:50, Dirk Eddelbuettel wrote:
> | There is of course merit in working through the barebones API but in case you
> | would consider a higher-level alternative, consider these few lines based on
> | RcppArmadillo (which end up calling dgemm() for you via R's linkage to the BLAS)
>
> PS I always forget that we have direct support in Rcpp::as<> for Armadillo
> matrices. The examples reduces to three lines in C++, and you never need to
> worry about row or column dimension, or memory allocation or deallocation:
>
> ?R> suppressMessages(library(inline))
> ?R> txt <- '
> ?+ ? ?arma::mat Am = Rcpp::as< arma::mat >(A);
> ?+ ? ?arma::mat Bm = Rcpp::as< arma::mat >(B);
> ?+ ? ?return Rcpp::wrap( Am * Bm );
> ?+ ? ?'
> ?R> mmult <- cxxfunction(signature(A="numeric", B="numeric"),
> ?+ ? ? ? ? ? ? ? ? ? ? ?body=txt,
> ?+ ? ? ? ? ? ? ? ? ? ? ?plugin="RcppArmadillo")
> ?R> A <- matrix(1:9, 3, 3)
> ?R> B <- matrix(9:1, 3, 3)
> ?R> C <- mmult(A, B)
> ?R> print(C)
> ? ? ? [,1] [,2] [,3]
> ?[1,] ? 90 ? 54 ? 18
> ?[2,] ?114 ? 69 ? 24
> ?[3,] ?138 ? 84 ? 30
> ?R>
>
> Matrices A and B from directly initialise Armadillo matrices, and the result
> can be returned directly.
>
> Hth, Dirk
>
> --
> Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com
>


From janko.thyson.rstuff at googlemail.com  Mon Feb 21 00:57:32 2011
From: janko.thyson.rstuff at googlemail.com (Janko Thyson)
Date: Mon, 21 Feb 2011 00:57:32 +0100
Subject: [Rd] Reference classes: error with missing arguments in method calls
Message-ID: <4d61aa9d.017b0e0a.190f.1021@mx.google.com>

Dear list,

 

I'm having problems in understanding an error that pops up in the context of
missing arguments with methods of reference class objects.

 

Because of the following statement taken from '?referenceClass', my ref
class methods call explicit S4 methods:

"Reference methods should be kept simple; if they need to do some
specialized R computation, that computation should use a separate R function
that is called from the reference method"

 

So a ref class would look like this:

setRefClass(Class="Xmple", methods=list(foo=function(var.1, ...)
fooMthd(.self=.self, var.1=var.1, ...))) 

 

I'd like to keep the generics defs as simple as possible, thus their only
arg should be '.self'. The S4 methods are specified in a way that if 'var.1'
is missing, it will be assigned some default value (I know I could
explicitly set the default value, yet I would like to rely on 'missing()'
for that). Now, my problem is that this works fine if the generic contains
an argument 'var.1', but results in an error if it doesn't. And I don't
quite understand why since it seems to be related to whether the S4 method
is invoked from a call to a ref class method or not. Here's an example which
demonstrates when it works as planed and when the error occurs. I tried to
keep as short as possible:

 

# 1) "Stand-alone" context

setGeneric(name="fooMthd", def=function(.self, ...)
standardGeneric("fooMthd"), signature=c(".self"))    

 

setMethod(f="fooMthd", signature=signature(.self="character"), 

    definition=function(.self, var.1, ...){

    cat("I'm having one additional argument compared to my generic:",
sep="\n")

    if(missing(var.1)) var.1 <- "some default value"

    cat(paste("* var.1: ", var.1, sep=""), sep="\n")    

})

 

fooMthd(.self="blabla", var.1="hello world!")

fooMthd(.self="blabla") # Works.

 

#+++++

 

# 2) Reference class context

setMethod(f="fooMthd", signature=signature(.self="Xmple"), 

    definition=function(.self, var.1, ...){

    cat("I'm having one additional argument compared to my generic:",
sep="\n")

    if(missing(var.1)) var.1 <- "some default value"

    cat(paste("* var.1: ", var.1, sep=""), sep="\n")    

})

 

setRefClass(Class="Xmple", methods=list(foo=function(var.1, ...)
fooMthd(.self=.self, var.1=var.1, ...)))

 

xmple <- getRefClass(Class="Xmple")$new()

xmple$foo(var.1="hallo") 

xmple$foo() # Does not work.

 

#+++++

 

# 3) "Fixed generic" context

setGeneric(name="fooMthd", def=function(.self, var.1, ...)
standardGeneric("fooMthd"), signature=c(".self"))     

 

setMethod(f="fooMthd", signature=signature(.self="Xmple"), 

    definition=function(.self, var.1, ...){

    cat("I'm having one additional argument compared to my generic:",
sep="\n")

    if(missing(var.1)) var.1 <- "some default value"

    cat(paste("* var.1: ", var.1, sep=""), sep="\n")    

})

 

xmple$foo(var.1=" blabla") 

xmple$foo() # Works.

 

I do understand that in the ref class 'foo()' has trouble passing an arg to
'fooMthd()' that hasn't been specified. But why and how does simply
including 'var.1' in the generic def fix this?

 

Thanks for any comments,

Janko

 

R version 2.12.1 (2010-12-16)

Platform: i386-pc-mingw32/i386 (32-bit)

 

locale:

[1] LC_COLLATE=German_Germany.1252  LC_CTYPE=German_Germany.1252   

[3] LC_MONETARY=German_Germany.1252 LC_NUMERIC=C                   

[5] LC_TIME=German_Germany.1252    

 

attached base packages:

[1] stats     graphics  grDevices utils     datasets  methods   base     

 

loaded via a namespace (and not attached):

[1] codetools_0.2-6 tools_2.12.1  

 


From keith at wehi.EDU.AU  Mon Feb 21 01:25:44 2011
From: keith at wehi.EDU.AU (Keith)
Date: Mon, 21 Feb 2011 11:25:44 +1100
Subject: [Rd] Ignoring .Rprofile when installing a package
In-Reply-To: <AANLkTintzjfx2pY4R6usohzEj7D3_cJXHi20E9vAMXBu@mail.gmail.com>
References: <AANLkTin_a=tANUqwH3_=zFadbFuc-M8KhHTovyuahDpD@mail.gmail.com>	<alpine.LFD.2.02.1102161650260.11129@gannet.stats.ox.ac.uk>	<4D5C0873.2010404@braverock.com>
	<AANLkTintzjfx2pY4R6usohzEj7D3_cJXHi20E9vAMXBu@mail.gmail.com>
Message-ID: <4D61B108.1040609@wehi.edu.au>

Jon,

I have had a similar problem when installing librarys. I have written a 
script which uses biocLite to install librarys.
I have included the following code which hides .Rprofile by renaming it 
and then renaming it back again after it has finished.

#Hide .Rprofile whilst this script is running.
file.rename(paste(Sys.getenv("HOME"),".Rprofile",sep=.Platform$file.sep),paste(Sys.getenv("HOME"),".Rprofile_hiding",sep=.Platform$file.sep))
# ...
# ... install libraries code
# ...
#Put .Rprofile back
file.rename(paste(Sys.getenv("HOME"),".Rprofile_hiding",sep=.Platform$file.sep),paste(Sys.getenv("HOME"),".Rprofile",sep=.Platform$file.sep))

I think this should be platform independent, but have mainly tried it on 
Windows and Unix.

cheers,

Keith Satterley,


On 18/02/2011 11:12 PM, Jon Clayden wrote:
> I would also be interested in knowing what the rationale is for this.
>
> Moreover, it seems that the "standard" (and documented) approach to
> this of calling "options(defaultPackages=c(...))" in ~/.Rprofile does
> not get ignored when installing. The environment variable approach may
> work, but it seems to me that this requires some (educated) guesswork.
> Could R CMD INSTALL not ignore the default packages option?
>
> Regards,
> Jon
>
>
> On 16 February 2011 17:25, Brian G. Peterson<brian at braverock.com>  wrote:
>> On 02/16/2011 10:57 AM, Prof Brian Ripley wrote:
>>> The most obvious answer is not to do that. You have not used the
>>> standard mechanism to to do that (which should work here as R CMD
>>> INSTALL overrides that one). It's all in ?Startup (look for
>>> R_DEFAULT_PACKAGES).
>> Note that R CMD INSTALL is not mentioned at all here.
>>
>>> The simplest way to ignore ~/.Rprofile is to set R_PROFILE_USER to
>>> something else.
>>>> I've tried R --vanilla CMD INSTALL, but that seems to have no effect.
>>> As documented.
>> Then let's try this from another angle...
>>
>> Is there a rationale why --vanilla or --no-environ or --no-site-file or
>> --no-init-file are *NOT* supported by R CMD INSTALL ?  I don't see any
>> reasoning for the inconsistency in the docs anywhere.
>>
>> If not, would R-core entertain a patch that would handle these options?
>>
>> This functionality is troublesome in a production installations where we
>> *want* our users to have specific packages and environment options set all
>> the time, and I need to edit the Rprofile.site file every time I upgrade one
>> of these 'production' packages.
>>
>> Regards,
>>
>>    - Brian
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

______________________________________________________________________
The information in this email is confidential and intend...{{dropped:4}}


From simon.urbanek at r-project.org  Mon Feb 21 01:27:26 2011
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Sun, 20 Feb 2011 19:27:26 -0500
Subject: [Rd] Problem using F77_CALL(dgemm) in a package
In-Reply-To: <AANLkTi=CQhxm5RBhymbCBLz8JAYs1cbEy=xC9LR_n8js@mail.gmail.com>
References: <AANLkTimAHcu_=_rMR9bFVYK86bmWhs8Pimgv3L-LiHsV@mail.gmail.com>
	<alpine.LFD.2.02.1102201540060.16292@gannet.stats.ox.ac.uk>
	<AANLkTi=CQhxm5RBhymbCBLz8JAYs1cbEy=xC9LR_n8js@mail.gmail.com>
Message-ID: <D11E54DC-6FED-4AE3-A5DB-7EDBDBA28DD4@r-project.org>

Jason,

FWIW the direct interface (.Call) is more efficient and makes passing things from R simpler:

C_matrix_multiply = function(A,B) .Call("R_matrix_multiply", A, B)

The drawback is a bit more legwork on the C side, but it also gives you more flexibility:

SEXP R_matrix_multiply(SEXP A, SEXP B) {
 	double one = 1.0;
	double zero = 0.0;
	int *dimA = INTEGER(getAttrib(A, R_DimSymbol));
	int *dimB = INTEGER(getAttrib(B, R_DimSymbol));
	SEXP sDimC = PROTECT(allocVector(INTSXP, 2));
	int *dimC = INTEGER(sDimC);
	SEXP C = PROTECT(allocVector(REALSXP, dimA[0] * dimB[1]));
	if (dimA[1] != dimB[0]) error("incompatible matrices!");
	dimC[0] = dimA[0];
	dimC[1] = dimB[1];
	setAttrib(C, R_DimSymbol, sDimC);
	A = PROTECT(coerceVector(A, REALSXP));
	B = PROTECT(coerceVector(B, REALSXP));
	F77_CALL(dgemm)("N","N",dimA,dimB+1,dimA+1,&one,REAL(A),dimA,REAL(B),dimA+1,&zero,REAL(C),dimA);
	UNPROTECT(4);
	return C;
}

For comparison:
> A=matrix(rnorm(1e5),500)
> B=matrix(rnorm(1e5),,500)

.Call:

> system.time(for (i in 1:10) C_matrix_multiply(A,B))
   user  system elapsed 
  0.656   0.008   0.686 

.C:

> system.time(for (i in 1:10) CC_matrix_multiply(A,B))
   user  system elapsed 
  0.886   0.044   0.943 


in fact .Call is even a tiny bit faster than %*%:

> system.time(for (i in 1:10) A %*% B)
   user  system elapsed 
  0.658   0.004   0.665 

(it's not just a measurement error - it's consistent for more replications etc. - but it's really negligible - possibly just due to dispatch of %*%)

Cheers,
Simon


On Feb 20, 2011, at 5:23 PM, Jason Rudy wrote:

> It was indeed a simple problem!  I took a look at that array.c as you
> suggested and that cleared it right up.  So, the correct C code is:
> 
> #include <R.h>
> #include <R_ext/Utils.h>
> #include <R_ext/Lapack.h>
> #include <R_ext/BLAS.h>
> 
> void R_matrix_multiply(double * A, double * B, int * m, int *n, int *
> p, double * C){
> 
> 	double one = 1.0;
> 	double zero = 0.0;
> 
>        //Just printing the input arguments
> 	Rprintf("m = %d, n = %d, p = %d\n",*m,*n,*p);
> 	int i;
> 	for(i=0;i<(*m**n);i++){
> 		Rprintf("%f ",A[i]);
> 	}
> 	Rprintf("\n");
> 	for(i=0;i<(*n**p);i++){
> 		Rprintf("%f ",B[i]);
> 	}
> 	Rprintf("\n");
> 	for(i=0;i<(*m**p);i++){
> 		Rprintf("%f ",C[i]);
> 	}
> 	Rprintf("\n");	
> 	
>        //Here is the actual multiplication
> 	F77_CALL(dgemm)("N","N",m,p,n,&one,A,m,B,n,&zero,C,m);
> }
> 
> The only difference being that I had the 4th and 5th arguments (n and
> p) mixed up.  There was also a problem in my R code after the
> multiplication took place.  For the record, the correct R code is:
> 
> C_matrix_multiply = function(A,B){
> 	C <- matrix(0,nrow(A),ncol(B))
> 	cout <- .C("R_matrix_multiply",as.double(A),as.double(B),nrow(A),ncol(A),ncol(B),as.double(C))
> 	return(matrix(cout[[6]],nrow(A),ncol(B)))
> }
> 
> Thanks for the help.  Now that I have a functioning example I am well
> on my way to completing this project.
> 
> -Jason
> 
> On Sun, Feb 20, 2011 at 7:42 AM, Prof Brian Ripley
> <ripley at stats.ox.ac.uk> wrote:
>> Look a close look at matprod in src/main/array in the R sources.
>> Hint: it is the other dimensions you have wrong.
>> 
>> And as BLAS is Fortran, counts do start at 1.
>> 
>> On Sat, 19 Feb 2011, Jason Rudy wrote:
>> 
>>> Dear R-devel,
>>> 
>>> I've written a numerical solver for SOCPs (second order cone programs)
>>> in R, and now I want to move most of the solver code into C for speed.
>>> I've written combined R/C packages before, but in this case I need to
>>> do matrix operations in my C code.  As I have never done that before,
>>> I'm trying to write some simple examples to make sure I understand the
>>> basics.  I am stuck on the first one.  I'm trying to write a function
>>> to multiply two matrices using the blas routine dgemm.  The name of my
>>> example package is CMATRIX.  My code is as follows.
>>> 
>>> I have a file matrix.c in my src directory:
>>> 
>>> #include <R.h>
>>> #include <R_ext/Utils.h>
>>> #include <R_ext/Lapack.h>
>>> #include <R_ext/BLAS.h>
>>> 
>>> //Computes C = A*B
>>> void R_matrix_multiply(double * A, double * B, int * m, int *n, int *
>>> p, double * C){
>>>        double one = 1.0;
>>>        double zero = 0.0;
>>> 
>>>       //Just printing the input arguments
>>>        Rprintf("m = %d, n = %d, p = %d\n",*m,*n,*p);
>>>        int i;
>>>        for(i=0;i<(*m**n);i++){
>>>                Rprintf("%f ",A[i]);
>>>        }
>>>        Rprintf("\n");
>>>        for(i=0;i<(*n**p);i++){
>>>                Rprintf("%f ",B[i]);
>>>        }
>>>        Rprintf("\n");
>>>        for(i=0;i<(*m**p);i++){
>>>                Rprintf("%f ",C[i]);
>>>        }
>>>        Rprintf("\n");
>>> 
>>> 
>>>       //Here is the actual multiplication
>>>        F77_CALL(dgemm)("N","N",m,n,p,&one,A,m,B,n,&zero,C,m);
>>> }
>>> 
>>> And the file C_matrix_multiply.R in my R directory:
>>> 
>>> C_matrix_multiply = function(A,B){
>>>        C <- matrix(0,nrow(A),ncol(B))
>>>        cout <-
>>> .C("R_matrix_multiply",as.double(A),as.double(B),nrow(A),ncol(A),ncol(B),as.double(C))
>>>        return(matrix(cout$C,nrowA,ncol(B)))
>>> 
>>> }
>>> 
>>> My namespace file is:
>>> 
>>> export("C_matrix_multiply")
>>> useDynLib(CMATRIX.so,R_matrix_multiply)
>>> 
>>> I'm not sure if it's necessary, but I've also included a Makevars.in
>>> file in my src directory:
>>> 
>>> PKG_CPPFLAGS=@PKG_CPPFLAGS@
>>> PKG_CFLAGS=@PKG_CFLAGS@
>>> PKG_LIBS=@PKG_LIBS@  ${LAPACK_LIBS} ${BLAS_LIBS} ${FLIBS}
>>> 
>>> which I simply copied from the diversitree package, which seems to use
>>> a lot of fortran.  I have the same problem (which I am getting to)
>>> with or without this Makevars.in file.
>>> 
>>> I install my package using:
>>> 
>>> R CMD INSTALL CMATRIX
>>> 
>>> Then I start up R and attempt to run the following code:
>>> 
>>> #Make some random matrices
>>> A = matrix(rnorm(8),4,2)
>>> B = matrix(rnorm(6),2,3)
>>> 
>>> #Load my package
>>> library(CMATRIX)
>>> 
>>> #Print the matrices
>>> A
>>> B
>>> 
>>> #Try to multiply them
>>> product = C_matrix_multiply(A,B)
>>> 
>>> What I want, and what according to my understanding should happen, is
>>> for product to contain the same matrix as would result from A %*% B.
>>> Instead, I get the following:
>>> 
>>>> A = matrix(rnorm(8),4,2)
>>>> B = matrix(rnorm(6),2,3)
>>>> library(CMATRIX)
>>>> A
>>> 
>>>          [,1]         [,2]
>>> [1,] -0.4981664 -0.7243532
>>> [2,]  0.1428766 -1.5501623
>>> [3,] -2.0624701  1.5104507
>>> [4,] -0.5871962  0.3049442
>>>> 
>>>> B
>>> 
>>>           [,1]            [,2]            [,3]
>>> [1,]  0.02477964 0.5827084 1.8434375
>>> [2,] -0.20200104 1.7294264 0.9071397
>>>> 
>>>> C_matrix_multiply(A,B)
>>> 
>>> m = 4, n = 2, p = 3
>>> -0.498166 0.142877 -2.062470 -0.587196 -0.724353 -1.550162 1.510451
>>> 0.304944
>>> 0.024780 -0.202001 0.582708 1.729426 1.843437 0.907140
>>> 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000
>>> 0.000000 0.000000 0.000000 0.000000 0.000000
>>> Parameter 10 to routine DGEMM  was incorrect
>>> Mac OS BLAS parameter error in DGEMM , parameter #0, (unavailable), is 0
>>> 
>>> and R immediately dies.  I know the arguments are being passed into
>>> the C code and everything up to my F77_CALL is functioning based on
>>> the printed output.  The problem is definitely something to do with my
>>> F77_CALL(dgemm) line.  My understanding is that parameter 10 should be
>>> the leading dimension of the matrix B, which in this case should be
>>> equal to 2, the number of rows in that matrix, which is what I am
>>> doing.  I have also considered that parameter numbering starts at 0,
>>> in which case the incorrect parameter is &zero, but again that seems
>>> correct to me.  All of my reading and research suggests I am doing
>>> everything correctly, so I am somewhat stumped.  Perhaps I am missing
>>> something simple or obvious, as I have never done this before and am
>>> proceeding with only google and the R docs as my guide.  I am
>>> wondering if anybody can see what I'm doing wrong here, or perhaps
>>> something I could do to try to fix it.  Any assistance would be
>>> greatly appreciated.
>>> 
>>> Best Regards,
>>> 
>>> Jason Rudy
>>> Graduate Student
>>> Bioinformatics and Medical Informatics Program
>>> San Diego State University
>>> 
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>> 
>> 
>> --
>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>> University of Oxford,             Tel:  +44 1865 272861 (self)
>> 1 South Parks Road,                     +44 1865 272866 (PA)
>> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>> 
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From ripley at stats.ox.ac.uk  Mon Feb 21 08:42:00 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 21 Feb 2011 07:42:00 +0000 (GMT)
Subject: [Rd] Problem using F77_CALL(dgemm) in a package
In-Reply-To: <D11E54DC-6FED-4AE3-A5DB-7EDBDBA28DD4@r-project.org>
References: <AANLkTimAHcu_=_rMR9bFVYK86bmWhs8Pimgv3L-LiHsV@mail.gmail.com>
	<alpine.LFD.2.02.1102201540060.16292@gannet.stats.ox.ac.uk>
	<AANLkTi=CQhxm5RBhymbCBLz8JAYs1cbEy=xC9LR_n8js@mail.gmail.com>
	<D11E54DC-6FED-4AE3-A5DB-7EDBDBA28DD4@r-project.org>
Message-ID: <alpine.LFD.2.02.1102210738150.31556@gannet.stats.ox.ac.uk>

Simon,

FWIW, %*% does a bit more, in particular does not call dgemm with NAs 
present, as BLAS are often 'optimized' to give the wrong answer in 
that case (e.g. by assuming 0*x is always 0, even though x can be 
Inf, or my not distinguishing NaNs, whereas R uses one for NA).

Brian

On Sun, 20 Feb 2011, Simon Urbanek wrote:

> Jason,
>
> FWIW the direct interface (.Call) is more efficient and makes passing things from R simpler:
>
> C_matrix_multiply = function(A,B) .Call("R_matrix_multiply", A, B)
>
> The drawback is a bit more legwork on the C side, but it also gives you more flexibility:
>
> SEXP R_matrix_multiply(SEXP A, SEXP B) {
> 	double one = 1.0;
> 	double zero = 0.0;
> 	int *dimA = INTEGER(getAttrib(A, R_DimSymbol));
> 	int *dimB = INTEGER(getAttrib(B, R_DimSymbol));
> 	SEXP sDimC = PROTECT(allocVector(INTSXP, 2));
> 	int *dimC = INTEGER(sDimC);
> 	SEXP C = PROTECT(allocVector(REALSXP, dimA[0] * dimB[1]));
> 	if (dimA[1] != dimB[0]) error("incompatible matrices!");
> 	dimC[0] = dimA[0];
> 	dimC[1] = dimB[1];
> 	setAttrib(C, R_DimSymbol, sDimC);
> 	A = PROTECT(coerceVector(A, REALSXP));
> 	B = PROTECT(coerceVector(B, REALSXP));
> 	F77_CALL(dgemm)("N","N",dimA,dimB+1,dimA+1,&one,REAL(A),dimA,REAL(B),dimA+1,&zero,REAL(C),dimA);
> 	UNPROTECT(4);
> 	return C;
> }
>
> For comparison:
>> A=matrix(rnorm(1e5),500)
>> B=matrix(rnorm(1e5),,500)
>
> .Call:
>
>> system.time(for (i in 1:10) C_matrix_multiply(A,B))
>   user  system elapsed
>  0.656   0.008   0.686
>
> .C:
>
>> system.time(for (i in 1:10) CC_matrix_multiply(A,B))
>   user  system elapsed
>  0.886   0.044   0.943
>
>
> in fact .Call is even a tiny bit faster than %*%:
>
>> system.time(for (i in 1:10) A %*% B)
>   user  system elapsed
>  0.658   0.004   0.665
>
> (it's not just a measurement error - it's consistent for more replications etc. - but it's really negligible - possibly just due to dispatch of %*%)
>
> Cheers,
> Simon
>
>
> On Feb 20, 2011, at 5:23 PM, Jason Rudy wrote:
>
>> It was indeed a simple problem!  I took a look at that array.c as you
>> suggested and that cleared it right up.  So, the correct C code is:
>>
>> #include <R.h>
>> #include <R_ext/Utils.h>
>> #include <R_ext/Lapack.h>
>> #include <R_ext/BLAS.h>
>>
>> void R_matrix_multiply(double * A, double * B, int * m, int *n, int *
>> p, double * C){
>>
>> 	double one = 1.0;
>> 	double zero = 0.0;
>>
>>        //Just printing the input arguments
>> 	Rprintf("m = %d, n = %d, p = %d\n",*m,*n,*p);
>> 	int i;
>> 	for(i=0;i<(*m**n);i++){
>> 		Rprintf("%f ",A[i]);
>> 	}
>> 	Rprintf("\n");
>> 	for(i=0;i<(*n**p);i++){
>> 		Rprintf("%f ",B[i]);
>> 	}
>> 	Rprintf("\n");
>> 	for(i=0;i<(*m**p);i++){
>> 		Rprintf("%f ",C[i]);
>> 	}
>> 	Rprintf("\n");
>>
>>        //Here is the actual multiplication
>> 	F77_CALL(dgemm)("N","N",m,p,n,&one,A,m,B,n,&zero,C,m);
>> }
>>
>> The only difference being that I had the 4th and 5th arguments (n and
>> p) mixed up.  There was also a problem in my R code after the
>> multiplication took place.  For the record, the correct R code is:
>>
>> C_matrix_multiply = function(A,B){
>> 	C <- matrix(0,nrow(A),ncol(B))
>> 	cout <- .C("R_matrix_multiply",as.double(A),as.double(B),nrow(A),ncol(A),ncol(B),as.double(C))
>> 	return(matrix(cout[[6]],nrow(A),ncol(B)))
>> }
>>
>> Thanks for the help.  Now that I have a functioning example I am well
>> on my way to completing this project.
>>
>> -Jason
>>
>> On Sun, Feb 20, 2011 at 7:42 AM, Prof Brian Ripley
>> <ripley at stats.ox.ac.uk> wrote:
>>> Look a close look at matprod in src/main/array in the R sources.
>>> Hint: it is the other dimensions you have wrong.
>>>
>>> And as BLAS is Fortran, counts do start at 1.
>>>
>>> On Sat, 19 Feb 2011, Jason Rudy wrote:
>>>
>>>> Dear R-devel,
>>>>
>>>> I've written a numerical solver for SOCPs (second order cone programs)
>>>> in R, and now I want to move most of the solver code into C for speed.
>>>> I've written combined R/C packages before, but in this case I need to
>>>> do matrix operations in my C code.  As I have never done that before,
>>>> I'm trying to write some simple examples to make sure I understand the
>>>> basics.  I am stuck on the first one.  I'm trying to write a function
>>>> to multiply two matrices using the blas routine dgemm.  The name of my
>>>> example package is CMATRIX.  My code is as follows.
>>>>
>>>> I have a file matrix.c in my src directory:
>>>>
>>>> #include <R.h>
>>>> #include <R_ext/Utils.h>
>>>> #include <R_ext/Lapack.h>
>>>> #include <R_ext/BLAS.h>
>>>>
>>>> //Computes C = A*B
>>>> void R_matrix_multiply(double * A, double * B, int * m, int *n, int *
>>>> p, double * C){
>>>>        double one = 1.0;
>>>>        double zero = 0.0;
>>>>
>>>>       //Just printing the input arguments
>>>>        Rprintf("m = %d, n = %d, p = %d\n",*m,*n,*p);
>>>>        int i;
>>>>        for(i=0;i<(*m**n);i++){
>>>>                Rprintf("%f ",A[i]);
>>>>        }
>>>>        Rprintf("\n");
>>>>        for(i=0;i<(*n**p);i++){
>>>>                Rprintf("%f ",B[i]);
>>>>        }
>>>>        Rprintf("\n");
>>>>        for(i=0;i<(*m**p);i++){
>>>>                Rprintf("%f ",C[i]);
>>>>        }
>>>>        Rprintf("\n");
>>>>
>>>>
>>>>       //Here is the actual multiplication
>>>>        F77_CALL(dgemm)("N","N",m,n,p,&one,A,m,B,n,&zero,C,m);
>>>> }
>>>>
>>>> And the file C_matrix_multiply.R in my R directory:
>>>>
>>>> C_matrix_multiply = function(A,B){
>>>>        C <- matrix(0,nrow(A),ncol(B))
>>>>        cout <-
>>>> .C("R_matrix_multiply",as.double(A),as.double(B),nrow(A),ncol(A),ncol(B),as.double(C))
>>>>        return(matrix(cout$C,nrowA,ncol(B)))
>>>>
>>>> }
>>>>
>>>> My namespace file is:
>>>>
>>>> export("C_matrix_multiply")
>>>> useDynLib(CMATRIX.so,R_matrix_multiply)
>>>>
>>>> I'm not sure if it's necessary, but I've also included a Makevars.in
>>>> file in my src directory:
>>>>
>>>> PKG_CPPFLAGS=@PKG_CPPFLAGS@
>>>> PKG_CFLAGS=@PKG_CFLAGS@
>>>> PKG_LIBS=@PKG_LIBS@  ${LAPACK_LIBS} ${BLAS_LIBS} ${FLIBS}
>>>>
>>>> which I simply copied from the diversitree package, which seems to use
>>>> a lot of fortran.  I have the same problem (which I am getting to)
>>>> with or without this Makevars.in file.
>>>>
>>>> I install my package using:
>>>>
>>>> R CMD INSTALL CMATRIX
>>>>
>>>> Then I start up R and attempt to run the following code:
>>>>
>>>> #Make some random matrices
>>>> A = matrix(rnorm(8),4,2)
>>>> B = matrix(rnorm(6),2,3)
>>>>
>>>> #Load my package
>>>> library(CMATRIX)
>>>>
>>>> #Print the matrices
>>>> A
>>>> B
>>>>
>>>> #Try to multiply them
>>>> product = C_matrix_multiply(A,B)
>>>>
>>>> What I want, and what according to my understanding should happen, is
>>>> for product to contain the same matrix as would result from A %*% B.
>>>> Instead, I get the following:
>>>>
>>>>> A = matrix(rnorm(8),4,2)
>>>>> B = matrix(rnorm(6),2,3)
>>>>> library(CMATRIX)
>>>>> A
>>>>
>>>>          [,1]         [,2]
>>>> [1,] -0.4981664 -0.7243532
>>>> [2,]  0.1428766 -1.5501623
>>>> [3,] -2.0624701  1.5104507
>>>> [4,] -0.5871962  0.3049442
>>>>>
>>>>> B
>>>>
>>>>           [,1]            [,2]            [,3]
>>>> [1,]  0.02477964 0.5827084 1.8434375
>>>> [2,] -0.20200104 1.7294264 0.9071397
>>>>>
>>>>> C_matrix_multiply(A,B)
>>>>
>>>> m = 4, n = 2, p = 3
>>>> -0.498166 0.142877 -2.062470 -0.587196 -0.724353 -1.550162 1.510451
>>>> 0.304944
>>>> 0.024780 -0.202001 0.582708 1.729426 1.843437 0.907140
>>>> 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000
>>>> 0.000000 0.000000 0.000000 0.000000 0.000000
>>>> Parameter 10 to routine DGEMM  was incorrect
>>>> Mac OS BLAS parameter error in DGEMM , parameter #0, (unavailable), is 0
>>>>
>>>> and R immediately dies.  I know the arguments are being passed into
>>>> the C code and everything up to my F77_CALL is functioning based on
>>>> the printed output.  The problem is definitely something to do with my
>>>> F77_CALL(dgemm) line.  My understanding is that parameter 10 should be
>>>> the leading dimension of the matrix B, which in this case should be
>>>> equal to 2, the number of rows in that matrix, which is what I am
>>>> doing.  I have also considered that parameter numbering starts at 0,
>>>> in which case the incorrect parameter is &zero, but again that seems
>>>> correct to me.  All of my reading and research suggests I am doing
>>>> everything correctly, so I am somewhat stumped.  Perhaps I am missing
>>>> something simple or obvious, as I have never done this before and am
>>>> proceeding with only google and the R docs as my guide.  I am
>>>> wondering if anybody can see what I'm doing wrong here, or perhaps
>>>> something I could do to try to fix it.  Any assistance would be
>>>> greatly appreciated.
>>>>
>>>> Best Regards,
>>>>
>>>> Jason Rudy
>>>> Graduate Student
>>>> Bioinformatics and Medical Informatics Program
>>>> San Diego State University
>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>
>>>
>>> --
>>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>>> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>>> University of Oxford,             Tel:  +44 1865 272861 (self)
>>> 1 South Parks Road,                     +44 1865 272866 (PA)
>>> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>>>
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From hb at biostat.ucsf.edu  Mon Feb 21 09:14:20 2011
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Mon, 21 Feb 2011 00:14:20 -0800
Subject: [Rd] Using src/ to create executable - how to not build shared
	objects?
Message-ID: <AANLkTi=d=7VOY+Aj9e9h1rranRQ0HO8XyJKgYnw5ZYmi@mail.gmail.com>

Hi.

I can use the src/ directory to create executable, cf. Section
'Package subdirectories' in 'Writing R Extensions":

"A few packages use the src directory for purposes other than making a
shared object (e.g. to create executables). Such packages should have
files src/Makefile and src/Makefile.win (unless intended for only
Unix-alikes or only Windows)."

When doing this, how can I turn off the building of the shared objects
that are created under libs/<arch>/?  Currently they end up in the
built package binaries, e.g. *.zip and *.tgz.

Thanks,

Henrik


From andreas.borg at unimedizin-mainz.de  Mon Feb 21 11:17:36 2011
From: andreas.borg at unimedizin-mainz.de (Andreas Borg)
Date: Mon, 21 Feb 2011 11:17:36 +0100
Subject: [Rd] Problem with documentation of user-defined operator (S4 method)
Message-ID: <4D623BC0.7090302@unimedizin-mainz.de>

Dear list members,

I have defined a binary operator %append% with methods for some S4 
classes. In my documentation file, I want to list the methods explicitly 
by using e.g.:

    \S4method{\%append\%}{RecLinkData,RecLinkData}(x, y)

In the HTML documentation this comes out right as
   
    ## S4 method for signature 'RecLinkResult,RecLinkResult'
    x %append% y

, but R CMD check raises the following warning:

    Bad \usage lines found in documentation object '%append%-methods':
      <unescaped bksl>S4method{%append%}{RecLinkData,RecLinkData}(x, y)

Any idea what is wrong?

I have seen this behaviour with R 2.12.0 and 2.12.1.

Best regards and thanks for any suggestion,

Andreas

-- 
Andreas Borg
Medizinische Informatik

UNIVERSIT?TSMEDIZIN
der Johannes Gutenberg-Universit?t
Institut f?r Medizinische Biometrie, Epidemiologie und Informatik
Obere Zahlbacher Stra?e 69, 55131 Mainz
www.imbei.uni-mainz.de

Telefon +49 (0) 6131 175062
E-Mail: borg at imbei.uni-mainz.de

Diese E-Mail enth?lt vertrauliche und/oder rechtlich gesch?tzte Informationen. Wenn Sie nicht der
richtige Adressat sind oder diese E-Mail irrt?mlich erhalten haben, informieren Sie bitte sofort den
Absender und l?schen Sie diese Mail. Das unerlaubte Kopieren sowie die unbefugte Weitergabe
dieser Mail und der darin enthaltenen Informationen ist nicht gestattet.


From andreas.borg at unimedizin-mainz.de  Mon Feb 21 11:32:39 2011
From: andreas.borg at unimedizin-mainz.de (Andreas Borg)
Date: Mon, 21 Feb 2011 11:32:39 +0100
Subject: [Rd] Problem with documentation of user-defined operator (S4
 method)
In-Reply-To: <4D623BC0.7090302@unimedizin-mainz.de>
References: <4D623BC0.7090302@unimedizin-mainz.de>
Message-ID: <4D623F47.204@unimedizin-mainz.de>

Just to add this, the operator is defined as follows:

standardGeneric for "%append%" defined from package "RecordLinkage"

function (x, y)
standardGeneric("%append%")
<environment: 01b19a3c>
Methods may be defined for arguments: x, y
Use  showMethods("%append%")  for currently available ones.

So this is not a problem of misspelled arguments. The involved class is 
an S3 class made usable to S4 methods by "oldClass".

Andreas Borg schrieb:
> Dear list members,
>
> I have defined a binary operator %append% with methods for some S4 
> classes. In my documentation file, I want to list the methods 
> explicitly by using e.g.:
>
>    \S4method{\%append\%}{RecLinkData,RecLinkData}(x, y)
>
> In the HTML documentation this comes out right as
>      ## S4 method for signature 'RecLinkResult,RecLinkResult'
>    x %append% y
>
> , but R CMD check raises the following warning:
>
>    Bad \usage lines found in documentation object '%append%-methods':
>      <unescaped bksl>S4method{%append%}{RecLinkData,RecLinkData}(x, y)
>
> Any idea what is wrong?
>
> I have seen this behaviour with R 2.12.0 and 2.12.1.
>
> Best regards and thanks for any suggestion,
>
> Andreas
>


-- 
Andreas Borg
Medizinische Informatik

UNIVERSIT?TSMEDIZIN
der Johannes Gutenberg-Universit?t
Institut f?r Medizinische Biometrie, Epidemiologie und Informatik
Obere Zahlbacher Stra?e 69, 55131 Mainz
www.imbei.uni-mainz.de

Telefon +49 (0) 6131 175062
E-Mail: borg at imbei.uni-mainz.de

Diese E-Mail enth?lt vertrauliche und/oder rechtlich gesch?tzte Informationen. Wenn Sie nicht der
richtige Adressat sind oder diese E-Mail irrt?mlich erhalten haben, informieren Sie bitte sofort den
Absender und l?schen Sie diese Mail. Das unerlaubte Kopieren sowie die unbefugte Weitergabe
dieser Mail und der darin enthaltenen Informationen ist nicht gestattet.


From Kurt.Hornik at wu.ac.at  Mon Feb 21 15:26:23 2011
From: Kurt.Hornik at wu.ac.at (Kurt Hornik)
Date: Mon, 21 Feb 2011 15:26:23 +0100
Subject: [Rd] Accessing Package NEWS (NEWS.Rd)
In-Reply-To: <0806D6AB-89F2-476A-BBBA-7A82F5A90983@comcast.net>
References: <0806D6AB-89F2-476A-BBBA-7A82F5A90983@comcast.net>
Message-ID: <19810.30223.616666.563347@fangorn.hornik.net>

>>>>> Paul Roebuck writes:

> Okay. So, after having spent quite some time never really tracking down
> why my package NEWS files were unacceptable to readNEWS(), I
> noticed that there was recent (to me anyway) development that allowed
> the NEWS to be done as an Rd file. Sweet! A more standard format...

> I converted a NEWS file in one of my unreleased packages to Rd format.
> checkNEWS() gave it a thumbs up.

> But then it went south. Tried the following after installation:

All of this works much better for r-devel: in particular, this makes
clear that checkNEWS is for old-style (pre 2.12.0) R NEWS files ...

Best
-k

>> checkNEWS("myapp/trunk/MyApp/inst/NEWS.Rd")
> [1] TRUE
>> news(package="MyApp")

> Nothing.

> Debugging news() itself left me wondering. The first thing checked
> for was 'inst/NEWS.Rd' - once I install the package, that would never
> exist though, right? Should tools:::.build_news_db() instead use:

>     nfile <- file.path(dir, c("NEWS.Rd", file.path("inst", "NEWS.Rd")))

> On the slim chance it should, I modified the path to my
> source folder's copy and continued debugging into 
> tools:::.build_news_db_from_package_NEWS_Rd().


> debug: ind <- grepl(re_v, nms, ignore.case = TRUE)
> Browse[2]> 
> debug: if (!all(ind)) warning("Cannot extract version info from the following section titles:\n", 
> Browse[2]> ind
> [1] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE
> Browse[2]> 
> debug: NULL
> Browse[2]> 
> debug: .make_news_db(cbind(ifelse(ind, sub(re_v, "\\1", nms), NA_character_), 
>     ifelse(grepl(re_d, nms), sub(re_d, "\\1", nms), NA_character_), 
>     db[, 2L], sub("\n*$", "", db[, 3L])), logical(nrow(db)), 
>     "news_db_from_Rd")
> Browse[2]> 
> debugging in: .make_news_db(cbind(ifelse(ind, sub(re_v, "\\1", nms), NA_character_), 
>     ifelse(grepl(re_d, nms), sub(re_d, "\\1", nms), NA_character_), 
>     db[, 2L], sub("\n*$", "", db[, 3L])), logical(nrow(db)), 
>     "news_db_from_Rd")
> debug: {
>     out <- data.frame(x, row.names = NULL, stringsAsFactors = FALSE)
>     colnames(out) <- c("Version", "Date", "Category", "Text")
>     if (!is.null(bad)) 
>         attr(out, "bad") <- bad
>     class(out) <- unique(c(classes, "news_db", "data.frame"))
>     out
> }
> Browse[3]> 
> debug: out <- data.frame(x, row.names = NULL, stringsAsFactors = FALSE)
> Browse[3]> 
> debug: colnames(out) <- c("Version", "Date", "Category", "Text")
> Browse[3]> 
> debug: if (!is.null(bad)) attr(out, "bad") <- bad
> Browse[3]> 
> debug: attr(out, "bad") <- bad
> Browse[3]> 
> debug: class(out) <- unique(c(classes, "news_db", "data.frame"))
> Browse[3]> 
> debug: out
> Browse[3]> 
> exiting from: .make_news_db(cbind(ifelse(ind, sub(re_v, "\\1", nms), NA_character_), 
>     ifelse(grepl(re_d, nms), sub(re_d, "\\1", nms), NA_character_), 
>     db[, 2L], sub("\n*$", "", db[, 3L])), logical(nrow(db)), 
>     "news_db_from_Rd")
> exiting from: tools:::.build_news_db_from_package_NEWS_Rd(newsfile)
> Error: invalid version specification CHANGES IN VERSION 1.0.0CHANGES IN VERSION 1.0.1CHANGES IN VERSION 2.0.0


> Well, so it didn't like my version numbers. But is the regexp check correct?

> Browse[2]> .standard_regexps()$valid_package_version
> [1] "([[:digit:]]+[.-]){1,}[[:digit:]]+"

> Would appear as though packages with only major.minor comparisons would
> pass. Or did I miss something...


> ----
> P.S. Another thing I didn't see specified was whether this was an acceptable format
> in current Rd format:

> \section{CHANGES IN VERSION 2.0.0}{

> Trying to get original TEXT files to be read by readNEWS(), the sections had to
> read "CHANGES IN R VERSION nnn". Using Rd format, checkNEWS() seemed
> to allow optionally using a package name instead (of 'R'). As it also allowed using
> nothing, i went with that. What's the intended canonical format?

> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From simon.urbanek at r-project.org  Mon Feb 21 16:18:03 2011
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Mon, 21 Feb 2011 10:18:03 -0500
Subject: [Rd] Using src/ to create executable - how to not build shared
	objects?
In-Reply-To: <AANLkTi=d=7VOY+Aj9e9h1rranRQ0HO8XyJKgYnw5ZYmi@mail.gmail.com>
References: <AANLkTi=d=7VOY+Aj9e9h1rranRQ0HO8XyJKgYnw5ZYmi@mail.gmail.com>
Message-ID: <0D87837E-C493-4214-B9FA-0D6AF0E45634@r-project.org>


On Feb 21, 2011, at 3:14 AM, Henrik Bengtsson wrote:

> Hi.
> 
> I can use the src/ directory to create executable, cf. Section
> 'Package subdirectories' in 'Writing R Extensions":
> 
> "A few packages use the src directory for purposes other than making a
> shared object (e.g. to create executables). Such packages should have
> files src/Makefile and src/Makefile.win (unless intended for only
> Unix-alikes or only Windows)."
> 
> When doing this, how can I turn off the building of the shared objects
> that are created under libs/<arch>/?  Currently they end up in the
> built package binaries, e.g. *.zip and *.tgz.
> 

If you build an executable then it won't be copied anyway. If you are building something that looks like a shared object then I'm a bit puzzled why you would not want to install it as that is the only way you can install it in multi-arch build (since you can't use inst in that case). That said, you can simply build your "executable" in a subdirectory which is I'd recommend for anything other than contents that you want R to deal with -- but, again, beware of multi-arch settings as it's get really tricky.

Cheers,
Simon


From chiefmurphy at gmail.com  Mon Feb 21 17:14:38 2011
From: chiefmurphy at gmail.com (Dan Murphy)
Date: Mon, 21 Feb 2011 08:14:38 -0800
Subject: [Rd] [R] S4 classes: referencing slots with other slots
Message-ID: <AANLkTikuYDGxW0ZXjaPn=_qGre3p4BmM9mU6VipRPBMD@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110221/a56e076c/attachment.pl>

From thomas.k.roth at googlemail.com  Mon Feb 21 19:30:17 2011
From: thomas.k.roth at googlemail.com (Thomas Roth)
Date: Mon, 21 Feb 2011 19:30:17 +0100
Subject: [Rd] Error in tools::build Vignettes (dir = ".")
Message-ID: <AANLkTimrrTwwFqhCMmASKV4tBBvN5McK2fP=_V0xHCoQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110221/2a558597/attachment.pl>

From ripley at stats.ox.ac.uk  Mon Feb 21 19:42:34 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 21 Feb 2011 18:42:34 +0000 (GMT)
Subject: [Rd] Error in tools::build Vignettes (dir = ".")
In-Reply-To: <AANLkTimrrTwwFqhCMmASKV4tBBvN5McK2fP=_V0xHCoQ@mail.gmail.com>
References: <AANLkTimrrTwwFqhCMmASKV4tBBvN5McK2fP=_V0xHCoQ@mail.gmail.com>
Message-ID: <alpine.LFD.2.02.1102211835500.26234@gannet.stats.ox.ac.uk>

On Mon, 21 Feb 2011, Thomas Roth wrote:

> Dear List,
>
> Recently i changed my environment switching from 32bit XP to 64bit W7. I'm
> trying to rebuild my package with R 2.12.1 (2010-12-16)
>
> R CMD check --> everything ok, no warning, error nothing
>
> BUT
>
> R CMD build --> Error in tools::build Vignettes (dir = ".") : Execution of
> make failed  (translated output)

I presume you mean tools::buildVignettes, no space.

> However, if i take the commands from the makefile, they all work out fine.
> Any hints?

Well, normally the system gives you some output before that message. 
All you need to do is to cd to your package's inst/doc directory, run 
'make' and see what is reported.  This doesn't look like an R issue, 
more to do with your Makefile or your environment.

>
> Best Whishes,
>
> Thomas
>
> 	[[alternative HTML version deleted]]

Please do review the posting guide and not send HTML when explicitly 
asked not to.

> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From therneau at mayo.edu  Mon Feb 21 20:31:54 2011
From: therneau at mayo.edu (Terry Therneau)
Date: Mon, 21 Feb 2011 13:31:54 -0600
Subject: [Rd] Anomaly in [.terms
Message-ID: <1298316714.27061.25.camel@punchbuggy>

 This arose when working on an addition to coxph, which has the features
that the X matrix never has an intercept column, and we remove strata()
terms before computing an X matrix.  The surprise: when a terms object
is subset the intercept attribute is turned back on.
  My lines 2 and 3 below were being executed just before a call to
model.frame.  The simple solution was of course to do them in the
opposite order so I am not waiting on a "fix". 
  Not to mention that I am not sure a fix is required, though I was
surprised. 
    Terry T.


tmt1131% R

R version 2.12.0 (2010-10-15)
Copyright (C) 2010 The R Foundation for Statistical Computing
ISBN 3-900051-07-0
Platform: x86_64-unknown-linux-gnu (64-bit)

> test <- terms(Surv(time, status) ~ age + strata(ph.ecog),
+    specials='strata')

> attr(test, 'intercept') <- 0  #turn off intercept
> test <- test[-2]   #remove strata

> test
Surv(time, status) ~ age
attr(,"variables")
list(Surv(time, status), age)
attr(,"factors")
                   age
Surv(time, status)   0
age                  1
attr(,"term.labels")
[1] "age"
attr(,"specials")
attr(,"specials")$strata
NULL

attr(,"order")
[1] 1
attr(,"intercept")
[1] 1
attr(,"response")
[1] 1


From ripley at stats.ox.ac.uk  Mon Feb 21 20:59:27 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 21 Feb 2011 19:59:27 +0000 (GMT)
Subject: [Rd] Anomaly in [.terms
In-Reply-To: <1298316714.27061.25.camel@punchbuggy>
References: <1298316714.27061.25.camel@punchbuggy>
Message-ID: <alpine.LFD.2.02.1102211956370.17303@gannet.stats.ox.ac.uk>

>From the NEWS for 2.13.0-to-be

       \item \code{drop.terms} and the \code{[} method for class
       \code{"terms"} no longer add back an intercept.  (Reported by
       Niels Hansen.)

so it has been fixed, just not rolled out yet.

On Mon, 21 Feb 2011, Terry Therneau wrote:

> This arose when working on an addition to coxph, which has the features
> that the X matrix never has an intercept column, and we remove strata()
> terms before computing an X matrix.  The surprise: when a terms object
> is subset the intercept attribute is turned back on.
>  My lines 2 and 3 below were being executed just before a call to
> model.frame.  The simple solution was of course to do them in the
> opposite order so I am not waiting on a "fix".
>  Not to mention that I am not sure a fix is required, though I was
> surprised.
>    Terry T.
>
>
> tmt1131% R
>
> R version 2.12.0 (2010-10-15)
> Copyright (C) 2010 The R Foundation for Statistical Computing
> ISBN 3-900051-07-0
> Platform: x86_64-unknown-linux-gnu (64-bit)
>
>> test <- terms(Surv(time, status) ~ age + strata(ph.ecog),
> +    specials='strata')
>
>> attr(test, 'intercept') <- 0  #turn off intercept
>> test <- test[-2]   #remove strata
>
>> test
> Surv(time, status) ~ age
> attr(,"variables")
> list(Surv(time, status), age)
> attr(,"factors")
>                   age
> Surv(time, status)   0
> age                  1
> attr(,"term.labels")
> [1] "age"
> attr(,"specials")
> attr(,"specials")$strata
> NULL
>
> attr(,"order")
> [1] 1
> attr(,"intercept")
> [1] 1
> attr(,"response")
> [1] 1
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From cbeleites at units.it  Tue Feb 22 09:56:22 2011
From: cbeleites at units.it (Claudia Beleites)
Date: Tue, 22 Feb 2011 09:56:22 +0100
Subject: [Rd] X error on r-forge
Message-ID: <4D637A36.7090707@units.it>

Dear all,

since a few days, my package hyperSpec does not build on r-forge. I have no idea 
whether this is due to my code or whether something is wrong with r-forge.
It fails with an X server error:

X Error of failed request:  BadMatch (invalid parameter attributes)
   Major opcode of failed request:  73 (X_GetImage)
   Serial number of failed request:  806
   Current serial number in output stream:  806

My guesstimate from the other output 
(http://r-forge.r-project.org/R/?group_id=366&log=build_src&pkg=hyperSpec&flavor=patched) 
is that it happens in the "plotting" vignette where I demonstrate plotting with 
rgl and try to save the image as png.
It used to work, and the package builds and checks on my computer with both
R version 2.12.1 (2010-12-16) Platform: x86_64-pc-linux-gnu (64-bit) and the 
current r-devel as well as on winbuilder.

Any ideas?

Thanks a lot,

Claudia


-- 
Claudia Beleites
Dipartimento dei Materiali e delle Risorse Naturali
Universit? degli Studi di Trieste
Via Alfonso Valerio 6/a
I-34127 Trieste

phone: +39 0 40 5 58-37 68
email: cbeleites at units.it


From savicky at cs.cas.cz  Tue Feb 22 11:42:32 2011
From: savicky at cs.cas.cz (Petr Savicky)
Date: Tue, 22 Feb 2011 11:42:32 +0100
Subject: [Rd] error in memCompress() in make check
Message-ID: <20110222104232.GA20876@cs.cas.cz>

Dear R developers:

When i run "make check" in R-patched_2011-02-12 and R-devel_2011-02-22
on a specific machine, the test fails and the file

  tests/Examples/base-Ex.Rout.fail

ends with

  > txt.xz <- memCompress(txt, "x")
  Error in memCompress(txt, "x") : internal error 5 in memCompress
  Execution halted

The error may be reproduced using commands

  txt <- readLines(file.path(R.home("doc"), "COPYING"))
  txt.xz <- memCompress(txt, "x")

in both the above installed versions. The machine is CentOS
release 5.4 (Final) under VMware.

I did not observe this error on other machines, some of which are
also CentOS.

For the development version, sessionInfo() is

  R version 2.13.0 Under development (unstable) (2011-02-22 r54523)
  Platform: i686-pc-linux-gnu (32-bit)
  
  locale:
   [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              
   [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    
   [5] LC_MONETARY=C              LC_MESSAGES=en_US.UTF-8   
   [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                 
   [9] LC_ADDRESS=C               LC_TELEPHONE=C            
  [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       
  
  attached base packages:
  [1] stats     graphics  grDevices utils     datasets  methods   base     

gcc --version

  gcc (GCC) 4.1.2 20080704 (Red Hat 4.1.2-46)

Petr Savicky.


From ripley at stats.ox.ac.uk  Tue Feb 22 12:25:50 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 22 Feb 2011 11:25:50 +0000 (GMT)
Subject: [Rd] error in memCompress() in make check
In-Reply-To: <20110222104232.GA20876@cs.cas.cz>
References: <20110222104232.GA20876@cs.cas.cz>
Message-ID: <alpine.LFD.2.02.1102221115330.11838@gannet.stats.ox.ac.uk>

So it seems that there is something wrong with the liblzma library 
used on that machine.  Did it use the version supplied with R or an 
external library (which is the default if one is found)?  My first 
step would be to force the internal version via --with-system-xz=no.

That error appears to be LZMA_MEM_ERROR: see xz/api/lzma/base.h .

On Tue, 22 Feb 2011, Petr Savicky wrote:

> Dear R developers:
>
> When i run "make check" in R-patched_2011-02-12 and R-devel_2011-02-22
> on a specific machine, the test fails and the file
>
>  tests/Examples/base-Ex.Rout.fail
>
> ends with
>
>  > txt.xz <- memCompress(txt, "x")
>  Error in memCompress(txt, "x") : internal error 5 in memCompress
>  Execution halted
>
> The error may be reproduced using commands
>
>  txt <- readLines(file.path(R.home("doc"), "COPYING"))
>  txt.xz <- memCompress(txt, "x")
>
> in both the above installed versions. The machine is CentOS
> release 5.4 (Final) under VMware.
>
> I did not observe this error on other machines, some of which are
> also CentOS.
>
> For the development version, sessionInfo() is
>
>  R version 2.13.0 Under development (unstable) (2011-02-22 r54523)
>  Platform: i686-pc-linux-gnu (32-bit)
>
>  locale:
>   [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>   [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>   [5] LC_MONETARY=C              LC_MESSAGES=en_US.UTF-8
>   [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>   [9] LC_ADDRESS=C               LC_TELEPHONE=C
>  [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>
>  attached base packages:
>  [1] stats     graphics  grDevices utils     datasets  methods   base
>
> gcc --version
>
>  gcc (GCC) 4.1.2 20080704 (Red Hat 4.1.2-46)
>
> Petr Savicky.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From jcrudy at gmail.com  Tue Feb 22 07:55:14 2011
From: jcrudy at gmail.com (Jason Rudy)
Date: Mon, 21 Feb 2011 22:55:14 -0800
Subject: [Rd] Problem using F77_CALL(dgemm) in a package
In-Reply-To: <D11E54DC-6FED-4AE3-A5DB-7EDBDBA28DD4@r-project.org>
References: <AANLkTimAHcu_=_rMR9bFVYK86bmWhs8Pimgv3L-LiHsV@mail.gmail.com>
	<alpine.LFD.2.02.1102201540060.16292@gannet.stats.ox.ac.uk>
	<AANLkTi=CQhxm5RBhymbCBLz8JAYs1cbEy=xC9LR_n8js@mail.gmail.com>
	<D11E54DC-6FED-4AE3-A5DB-7EDBDBA28DD4@r-project.org>
Message-ID: <AANLkTi=2P19dKd2W1aNnksSPGpmKqYqpkSE+AnPdt4Rz@mail.gmail.com>

I just tried that myself and the .Call version is substantially
faster.  It seems like there is a lot more going on in the .Call C
code than the .C.  Why is .Call faster?  Does it have to do with the
way arguments are passed into the C function?  I tried with DUP=FALSE
and NAOK=TRUE, but .Call was still the winner.

On Sun, Feb 20, 2011 at 4:27 PM, Simon Urbanek
<simon.urbanek at r-project.org> wrote:
> Jason,
>
> FWIW the direct interface (.Call) is more efficient and makes passing things from R simpler:
>
> C_matrix_multiply = function(A,B) .Call("R_matrix_multiply", A, B)
>
> The drawback is a bit more legwork on the C side, but it also gives you more flexibility:
>
> SEXP R_matrix_multiply(SEXP A, SEXP B) {
> ? ? ? ?double one = 1.0;
> ? ? ? ?double zero = 0.0;
> ? ? ? ?int *dimA = INTEGER(getAttrib(A, R_DimSymbol));
> ? ? ? ?int *dimB = INTEGER(getAttrib(B, R_DimSymbol));
> ? ? ? ?SEXP sDimC = PROTECT(allocVector(INTSXP, 2));
> ? ? ? ?int *dimC = INTEGER(sDimC);
> ? ? ? ?SEXP C = PROTECT(allocVector(REALSXP, dimA[0] * dimB[1]));
> ? ? ? ?if (dimA[1] != dimB[0]) error("incompatible matrices!");
> ? ? ? ?dimC[0] = dimA[0];
> ? ? ? ?dimC[1] = dimB[1];
> ? ? ? ?setAttrib(C, R_DimSymbol, sDimC);
> ? ? ? ?A = PROTECT(coerceVector(A, REALSXP));
> ? ? ? ?B = PROTECT(coerceVector(B, REALSXP));
> ? ? ? ?F77_CALL(dgemm)("N","N",dimA,dimB+1,dimA+1,&one,REAL(A),dimA,REAL(B),dimA+1,&zero,REAL(C),dimA);
> ? ? ? ?UNPROTECT(4);
> ? ? ? ?return C;
> }
>
> For comparison:
>> A=matrix(rnorm(1e5),500)
>> B=matrix(rnorm(1e5),,500)
>
> .Call:
>
>> system.time(for (i in 1:10) C_matrix_multiply(A,B))
> ? user ?system elapsed
> ?0.656 ? 0.008 ? 0.686
>
> .C:
>
>> system.time(for (i in 1:10) CC_matrix_multiply(A,B))
> ? user ?system elapsed
> ?0.886 ? 0.044 ? 0.943
>
>
> in fact .Call is even a tiny bit faster than %*%:
>
>> system.time(for (i in 1:10) A %*% B)
> ? user ?system elapsed
> ?0.658 ? 0.004 ? 0.665
>
> (it's not just a measurement error - it's consistent for more replications etc. - but it's really negligible - possibly just due to dispatch of %*%)
>
> Cheers,
> Simon
>
>
> On Feb 20, 2011, at 5:23 PM, Jason Rudy wrote:
>
>> It was indeed a simple problem! ?I took a look at that array.c as you
>> suggested and that cleared it right up. ?So, the correct C code is:
>>
>> #include <R.h>
>> #include <R_ext/Utils.h>
>> #include <R_ext/Lapack.h>
>> #include <R_ext/BLAS.h>
>>
>> void R_matrix_multiply(double * A, double * B, int * m, int *n, int *
>> p, double * C){
>>
>> ? ? ? double one = 1.0;
>> ? ? ? double zero = 0.0;
>>
>> ? ? ? ?//Just printing the input arguments
>> ? ? ? Rprintf("m = %d, n = %d, p = %d\n",*m,*n,*p);
>> ? ? ? int i;
>> ? ? ? for(i=0;i<(*m**n);i++){
>> ? ? ? ? ? ? ? Rprintf("%f ",A[i]);
>> ? ? ? }
>> ? ? ? Rprintf("\n");
>> ? ? ? for(i=0;i<(*n**p);i++){
>> ? ? ? ? ? ? ? Rprintf("%f ",B[i]);
>> ? ? ? }
>> ? ? ? Rprintf("\n");
>> ? ? ? for(i=0;i<(*m**p);i++){
>> ? ? ? ? ? ? ? Rprintf("%f ",C[i]);
>> ? ? ? }
>> ? ? ? Rprintf("\n");
>>
>> ? ? ? ?//Here is the actual multiplication
>> ? ? ? F77_CALL(dgemm)("N","N",m,p,n,&one,A,m,B,n,&zero,C,m);
>> }
>>
>> The only difference being that I had the 4th and 5th arguments (n and
>> p) mixed up. ?There was also a problem in my R code after the
>> multiplication took place. ?For the record, the correct R code is:
>>
>> C_matrix_multiply = function(A,B){
>> ? ? ? C <- matrix(0,nrow(A),ncol(B))
>> ? ? ? cout <- .C("R_matrix_multiply",as.double(A),as.double(B),nrow(A),ncol(A),ncol(B),as.double(C))
>> ? ? ? return(matrix(cout[[6]],nrow(A),ncol(B)))
>> }
>>
>> Thanks for the help. ?Now that I have a functioning example I am well
>> on my way to completing this project.
>>
>> -Jason
>>
>> On Sun, Feb 20, 2011 at 7:42 AM, Prof Brian Ripley
>> <ripley at stats.ox.ac.uk> wrote:
>>> Look a close look at matprod in src/main/array in the R sources.
>>> Hint: it is the other dimensions you have wrong.
>>>
>>> And as BLAS is Fortran, counts do start at 1.
>>>
>>> On Sat, 19 Feb 2011, Jason Rudy wrote:
>>>
>>>> Dear R-devel,
>>>>
>>>> I've written a numerical solver for SOCPs (second order cone programs)
>>>> in R, and now I want to move most of the solver code into C for speed.
>>>> I've written combined R/C packages before, but in this case I need to
>>>> do matrix operations in my C code. ?As I have never done that before,
>>>> I'm trying to write some simple examples to make sure I understand the
>>>> basics. ?I am stuck on the first one. ?I'm trying to write a function
>>>> to multiply two matrices using the blas routine dgemm. ?The name of my
>>>> example package is CMATRIX. ?My code is as follows.
>>>>
>>>> I have a file matrix.c in my src directory:
>>>>
>>>> #include <R.h>
>>>> #include <R_ext/Utils.h>
>>>> #include <R_ext/Lapack.h>
>>>> #include <R_ext/BLAS.h>
>>>>
>>>> //Computes C = A*B
>>>> void R_matrix_multiply(double * A, double * B, int * m, int *n, int *
>>>> p, double * C){
>>>> ? ? ? ?double one = 1.0;
>>>> ? ? ? ?double zero = 0.0;
>>>>
>>>> ? ? ? //Just printing the input arguments
>>>> ? ? ? ?Rprintf("m = %d, n = %d, p = %d\n",*m,*n,*p);
>>>> ? ? ? ?int i;
>>>> ? ? ? ?for(i=0;i<(*m**n);i++){
>>>> ? ? ? ? ? ? ? ?Rprintf("%f ",A[i]);
>>>> ? ? ? ?}
>>>> ? ? ? ?Rprintf("\n");
>>>> ? ? ? ?for(i=0;i<(*n**p);i++){
>>>> ? ? ? ? ? ? ? ?Rprintf("%f ",B[i]);
>>>> ? ? ? ?}
>>>> ? ? ? ?Rprintf("\n");
>>>> ? ? ? ?for(i=0;i<(*m**p);i++){
>>>> ? ? ? ? ? ? ? ?Rprintf("%f ",C[i]);
>>>> ? ? ? ?}
>>>> ? ? ? ?Rprintf("\n");
>>>>
>>>>
>>>> ? ? ? //Here is the actual multiplication
>>>> ? ? ? ?F77_CALL(dgemm)("N","N",m,n,p,&one,A,m,B,n,&zero,C,m);
>>>> }
>>>>
>>>> And the file C_matrix_multiply.R in my R directory:
>>>>
>>>> C_matrix_multiply = function(A,B){
>>>> ? ? ? ?C <- matrix(0,nrow(A),ncol(B))
>>>> ? ? ? ?cout <-
>>>> .C("R_matrix_multiply",as.double(A),as.double(B),nrow(A),ncol(A),ncol(B),as.double(C))
>>>> ? ? ? ?return(matrix(cout$C,nrowA,ncol(B)))
>>>>
>>>> }
>>>>
>>>> My namespace file is:
>>>>
>>>> export("C_matrix_multiply")
>>>> useDynLib(CMATRIX.so,R_matrix_multiply)
>>>>
>>>> I'm not sure if it's necessary, but I've also included a Makevars.in
>>>> file in my src directory:
>>>>
>>>> PKG_CPPFLAGS=@PKG_CPPFLAGS@
>>>> PKG_CFLAGS=@PKG_CFLAGS@
>>>> PKG_LIBS=@PKG_LIBS@ ?${LAPACK_LIBS} ${BLAS_LIBS} ${FLIBS}
>>>>
>>>> which I simply copied from the diversitree package, which seems to use
>>>> a lot of fortran. ?I have the same problem (which I am getting to)
>>>> with or without this Makevars.in file.
>>>>
>>>> I install my package using:
>>>>
>>>> R CMD INSTALL CMATRIX
>>>>
>>>> Then I start up R and attempt to run the following code:
>>>>
>>>> #Make some random matrices
>>>> A = matrix(rnorm(8),4,2)
>>>> B = matrix(rnorm(6),2,3)
>>>>
>>>> #Load my package
>>>> library(CMATRIX)
>>>>
>>>> #Print the matrices
>>>> A
>>>> B
>>>>
>>>> #Try to multiply them
>>>> product = C_matrix_multiply(A,B)
>>>>
>>>> What I want, and what according to my understanding should happen, is
>>>> for product to contain the same matrix as would result from A %*% B.
>>>> Instead, I get the following:
>>>>
>>>>> A = matrix(rnorm(8),4,2)
>>>>> B = matrix(rnorm(6),2,3)
>>>>> library(CMATRIX)
>>>>> A
>>>>
>>>> ? ? ? ? ?[,1] ? ? ? ? [,2]
>>>> [1,] -0.4981664 -0.7243532
>>>> [2,] ?0.1428766 -1.5501623
>>>> [3,] -2.0624701 ?1.5104507
>>>> [4,] -0.5871962 ?0.3049442
>>>>>
>>>>> B
>>>>
>>>> ? ? ? ? ? [,1] ? ? ? ? ? ?[,2] ? ? ? ? ? ?[,3]
>>>> [1,] ?0.02477964 0.5827084 1.8434375
>>>> [2,] -0.20200104 1.7294264 0.9071397
>>>>>
>>>>> C_matrix_multiply(A,B)
>>>>
>>>> m = 4, n = 2, p = 3
>>>> -0.498166 0.142877 -2.062470 -0.587196 -0.724353 -1.550162 1.510451
>>>> 0.304944
>>>> 0.024780 -0.202001 0.582708 1.729426 1.843437 0.907140
>>>> 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000
>>>> 0.000000 0.000000 0.000000 0.000000 0.000000
>>>> Parameter 10 to routine DGEMM ?was incorrect
>>>> Mac OS BLAS parameter error in DGEMM , parameter #0, (unavailable), is 0
>>>>
>>>> and R immediately dies. ?I know the arguments are being passed into
>>>> the C code and everything up to my F77_CALL is functioning based on
>>>> the printed output. ?The problem is definitely something to do with my
>>>> F77_CALL(dgemm) line. ?My understanding is that parameter 10 should be
>>>> the leading dimension of the matrix B, which in this case should be
>>>> equal to 2, the number of rows in that matrix, which is what I am
>>>> doing. ?I have also considered that parameter numbering starts at 0,
>>>> in which case the incorrect parameter is &zero, but again that seems
>>>> correct to me. ?All of my reading and research suggests I am doing
>>>> everything correctly, so I am somewhat stumped. ?Perhaps I am missing
>>>> something simple or obvious, as I have never done this before and am
>>>> proceeding with only google and the R docs as my guide. ?I am
>>>> wondering if anybody can see what I'm doing wrong here, or perhaps
>>>> something I could do to try to fix it. ?Any assistance would be
>>>> greatly appreciated.
>>>>
>>>> Best Regards,
>>>>
>>>> Jason Rudy
>>>> Graduate Student
>>>> Bioinformatics and Medical Informatics Program
>>>> San Diego State University
>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>
>>>
>>> --
>>> Brian D. Ripley, ? ? ? ? ? ? ? ? ?ripley at stats.ox.ac.uk
>>> Professor of Applied Statistics, ?http://www.stats.ox.ac.uk/~ripley/
>>> University of Oxford, ? ? ? ? ? ? Tel: ?+44 1865 272861 (self)
>>> 1 South Parks Road, ? ? ? ? ? ? ? ? ? ? +44 1865 272866 (PA)
>>> Oxford OX1 3TG, UK ? ? ? ? ? ? ? ?Fax: ?+44 1865 272595
>>>
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>
>


From savicky at cs.cas.cz  Tue Feb 22 13:38:07 2011
From: savicky at cs.cas.cz (Petr Savicky)
Date: Tue, 22 Feb 2011 13:38:07 +0100
Subject: [Rd] error in memCompress() in make check
In-Reply-To: <alpine.LFD.2.02.1102221115330.11838@gannet.stats.ox.ac.uk>
References: <20110222104232.GA20876@cs.cas.cz>
	<alpine.LFD.2.02.1102221115330.11838@gannet.stats.ox.ac.uk>
Message-ID: <20110222123807.GA13609@cs.cas.cz>

On Tue, Feb 22, 2011 at 11:25:50AM +0000, Prof Brian Ripley wrote:
> So it seems that there is something wrong with the liblzma library 
> used on that machine.  Did it use the version supplied with R or an 
> external library (which is the default if one is found)?  My first 
> step would be to force the internal version via --with-system-xz=no.

Thank you for your reply.

I tried 

  ./configure --with-x=no --with-system-xz=no

in a clean R-devel_2011-02-22 and the result of make check is the same.

The commands

  txt <- readLines(file.path(R.home("doc"), "COPYING"))
  txt.xz <- memCompress(txt, "x")

do not produce an error, if the compiled R runs in the same shell,
where "make check" was run. However, they produce the error, if R is
started in a new shell.

The command

  find /usr -name "liblzma*"

has empty output.

Petr Savicky.


From simon.urbanek at r-project.org  Tue Feb 22 16:27:08 2011
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Tue, 22 Feb 2011 10:27:08 -0500
Subject: [Rd] Problem using F77_CALL(dgemm) in a package
In-Reply-To: <AANLkTi=2P19dKd2W1aNnksSPGpmKqYqpkSE+AnPdt4Rz@mail.gmail.com>
References: <AANLkTimAHcu_=_rMR9bFVYK86bmWhs8Pimgv3L-LiHsV@mail.gmail.com>
	<alpine.LFD.2.02.1102201540060.16292@gannet.stats.ox.ac.uk>
	<AANLkTi=CQhxm5RBhymbCBLz8JAYs1cbEy=xC9LR_n8js@mail.gmail.com>
	<D11E54DC-6FED-4AE3-A5DB-7EDBDBA28DD4@r-project.org>
	<AANLkTi=2P19dKd2W1aNnksSPGpmKqYqpkSE+AnPdt4Rz@mail.gmail.com>
Message-ID: <BF3431FB-43FF-47AB-BC9A-D71163B53515@r-project.org>

On Feb 22, 2011, at 1:55 AM, Jason Rudy wrote:

> I just tried that myself and the .Call version is substantially
> faster.  It seems like there is a lot more going on in the .Call C
> code than the .C.  Why is .Call faster?  Does it have to do with the
> way arguments are passed into the C function?  I tried with DUP=FALSE
> and NAOK=TRUE, but .Call was still the winner.
> 

.Call is the "native" interface so it passes all objects directly as references - essentially the same way that R uses internally (.C with DUP=FALSE and NAOK=TRUE comes close to that, though; the fastest is .External in this respect). Also you're allocating objects as you need them so there will be less copying afterwards. However, I suspect that major part of the difference is also in the code preceding the C code involved in this -- for example as.double() will implicitly create a copy since it needs to strip attributes whereas coerceVector is a no-op if the type matches.

.C is there for historical compatibility - it is essentially equivalent to .Fortran which was the original (and only) interface way back when. .Call is in comparison a more recent addition, that's why you still find a lot of .C code. Personally I don't use .C at all because compared to .Call it is so cumbersome and error-prone (you can't even tell the length of the passed vectors in C!), but others have different preferences.

Cheers,
Simon


> On Sun, Feb 20, 2011 at 4:27 PM, Simon Urbanek
> <simon.urbanek at r-project.org> wrote:
>> Jason,
>> 
>> FWIW the direct interface (.Call) is more efficient and makes passing things from R simpler:
>> 
>> C_matrix_multiply = function(A,B) .Call("R_matrix_multiply", A, B)
>> 
>> The drawback is a bit more legwork on the C side, but it also gives you more flexibility:
>> 
>> SEXP R_matrix_multiply(SEXP A, SEXP B) {
>>        double one = 1.0;
>>        double zero = 0.0;
>>        int *dimA = INTEGER(getAttrib(A, R_DimSymbol));
>>        int *dimB = INTEGER(getAttrib(B, R_DimSymbol));
>>        SEXP sDimC = PROTECT(allocVector(INTSXP, 2));
>>        int *dimC = INTEGER(sDimC);
>>        SEXP C = PROTECT(allocVector(REALSXP, dimA[0] * dimB[1]));
>>        if (dimA[1] != dimB[0]) error("incompatible matrices!");
>>        dimC[0] = dimA[0];
>>        dimC[1] = dimB[1];
>>        setAttrib(C, R_DimSymbol, sDimC);
>>        A = PROTECT(coerceVector(A, REALSXP));
>>        B = PROTECT(coerceVector(B, REALSXP));
>>        F77_CALL(dgemm)("N","N",dimA,dimB+1,dimA+1,&one,REAL(A),dimA,REAL(B),dimA+1,&zero,REAL(C),dimA);
>>        UNPROTECT(4);
>>        return C;
>> }
>> 
>> For comparison:
>>> A=matrix(rnorm(1e5),500)
>>> B=matrix(rnorm(1e5),,500)
>> 
>> .Call:
>> 
>>> system.time(for (i in 1:10) C_matrix_multiply(A,B))
>>   user  system elapsed
>>  0.656   0.008   0.686
>> 
>> .C:
>> 
>>> system.time(for (i in 1:10) CC_matrix_multiply(A,B))
>>   user  system elapsed
>>  0.886   0.044   0.943
>> 
>> 
>> in fact .Call is even a tiny bit faster than %*%:
>> 
>>> system.time(for (i in 1:10) A %*% B)
>>   user  system elapsed
>>  0.658   0.004   0.665
>> 
>> (it's not just a measurement error - it's consistent for more replications etc. - but it's really negligible - possibly just due to dispatch of %*%)
>> 
>> Cheers,
>> Simon
>> 
>> 
>> On Feb 20, 2011, at 5:23 PM, Jason Rudy wrote:
>> 
>>> It was indeed a simple problem!  I took a look at that array.c as you
>>> suggested and that cleared it right up.  So, the correct C code is:
>>> 
>>> #include <R.h>
>>> #include <R_ext/Utils.h>
>>> #include <R_ext/Lapack.h>
>>> #include <R_ext/BLAS.h>
>>> 
>>> void R_matrix_multiply(double * A, double * B, int * m, int *n, int *
>>> p, double * C){
>>> 
>>>       double one = 1.0;
>>>       double zero = 0.0;
>>> 
>>>        //Just printing the input arguments
>>>       Rprintf("m = %d, n = %d, p = %d\n",*m,*n,*p);
>>>       int i;
>>>       for(i=0;i<(*m**n);i++){
>>>               Rprintf("%f ",A[i]);
>>>       }
>>>       Rprintf("\n");
>>>       for(i=0;i<(*n**p);i++){
>>>               Rprintf("%f ",B[i]);
>>>       }
>>>       Rprintf("\n");
>>>       for(i=0;i<(*m**p);i++){
>>>               Rprintf("%f ",C[i]);
>>>       }
>>>       Rprintf("\n");
>>> 
>>>        //Here is the actual multiplication
>>>       F77_CALL(dgemm)("N","N",m,p,n,&one,A,m,B,n,&zero,C,m);
>>> }
>>> 
>>> The only difference being that I had the 4th and 5th arguments (n and
>>> p) mixed up.  There was also a problem in my R code after the
>>> multiplication took place.  For the record, the correct R code is:
>>> 
>>> C_matrix_multiply = function(A,B){
>>>       C <- matrix(0,nrow(A),ncol(B))
>>>       cout <- .C("R_matrix_multiply",as.double(A),as.double(B),nrow(A),ncol(A),ncol(B),as.double(C))
>>>       return(matrix(cout[[6]],nrow(A),ncol(B)))
>>> }
>>> 
>>> Thanks for the help.  Now that I have a functioning example I am well
>>> on my way to completing this project.
>>> 
>>> -Jason
>>> 
>>> On Sun, Feb 20, 2011 at 7:42 AM, Prof Brian Ripley
>>> <ripley at stats.ox.ac.uk> wrote:
>>>> Look a close look at matprod in src/main/array in the R sources.
>>>> Hint: it is the other dimensions you have wrong.
>>>> 
>>>> And as BLAS is Fortran, counts do start at 1.
>>>> 
>>>> On Sat, 19 Feb 2011, Jason Rudy wrote:
>>>> 
>>>>> Dear R-devel,
>>>>> 
>>>>> I've written a numerical solver for SOCPs (second order cone programs)
>>>>> in R, and now I want to move most of the solver code into C for speed.
>>>>> I've written combined R/C packages before, but in this case I need to
>>>>> do matrix operations in my C code.  As I have never done that before,
>>>>> I'm trying to write some simple examples to make sure I understand the
>>>>> basics.  I am stuck on the first one.  I'm trying to write a function
>>>>> to multiply two matrices using the blas routine dgemm.  The name of my
>>>>> example package is CMATRIX.  My code is as follows.
>>>>> 
>>>>> I have a file matrix.c in my src directory:
>>>>> 
>>>>> #include <R.h>
>>>>> #include <R_ext/Utils.h>
>>>>> #include <R_ext/Lapack.h>
>>>>> #include <R_ext/BLAS.h>
>>>>> 
>>>>> //Computes C = A*B
>>>>> void R_matrix_multiply(double * A, double * B, int * m, int *n, int *
>>>>> p, double * C){
>>>>>        double one = 1.0;
>>>>>        double zero = 0.0;
>>>>> 
>>>>>       //Just printing the input arguments
>>>>>        Rprintf("m = %d, n = %d, p = %d\n",*m,*n,*p);
>>>>>        int i;
>>>>>        for(i=0;i<(*m**n);i++){
>>>>>                Rprintf("%f ",A[i]);
>>>>>        }
>>>>>        Rprintf("\n");
>>>>>        for(i=0;i<(*n**p);i++){
>>>>>                Rprintf("%f ",B[i]);
>>>>>        }
>>>>>        Rprintf("\n");
>>>>>        for(i=0;i<(*m**p);i++){
>>>>>                Rprintf("%f ",C[i]);
>>>>>        }
>>>>>        Rprintf("\n");
>>>>> 
>>>>> 
>>>>>       //Here is the actual multiplication
>>>>>        F77_CALL(dgemm)("N","N",m,n,p,&one,A,m,B,n,&zero,C,m);
>>>>> }
>>>>> 
>>>>> And the file C_matrix_multiply.R in my R directory:
>>>>> 
>>>>> C_matrix_multiply = function(A,B){
>>>>>        C <- matrix(0,nrow(A),ncol(B))
>>>>>        cout <-
>>>>> .C("R_matrix_multiply",as.double(A),as.double(B),nrow(A),ncol(A),ncol(B),as.double(C))
>>>>>        return(matrix(cout$C,nrowA,ncol(B)))
>>>>> 
>>>>> }
>>>>> 
>>>>> My namespace file is:
>>>>> 
>>>>> export("C_matrix_multiply")
>>>>> useDynLib(CMATRIX.so,R_matrix_multiply)
>>>>> 
>>>>> I'm not sure if it's necessary, but I've also included a Makevars.in
>>>>> file in my src directory:
>>>>> 
>>>>> PKG_CPPFLAGS=@PKG_CPPFLAGS@
>>>>> PKG_CFLAGS=@PKG_CFLAGS@
>>>>> PKG_LIBS=@PKG_LIBS@  ${LAPACK_LIBS} ${BLAS_LIBS} ${FLIBS}
>>>>> 
>>>>> which I simply copied from the diversitree package, which seems to use
>>>>> a lot of fortran.  I have the same problem (which I am getting to)
>>>>> with or without this Makevars.in file.
>>>>> 
>>>>> I install my package using:
>>>>> 
>>>>> R CMD INSTALL CMATRIX
>>>>> 
>>>>> Then I start up R and attempt to run the following code:
>>>>> 
>>>>> #Make some random matrices
>>>>> A = matrix(rnorm(8),4,2)
>>>>> B = matrix(rnorm(6),2,3)
>>>>> 
>>>>> #Load my package
>>>>> library(CMATRIX)
>>>>> 
>>>>> #Print the matrices
>>>>> A
>>>>> B
>>>>> 
>>>>> #Try to multiply them
>>>>> product = C_matrix_multiply(A,B)
>>>>> 
>>>>> What I want, and what according to my understanding should happen, is
>>>>> for product to contain the same matrix as would result from A %*% B.
>>>>> Instead, I get the following:
>>>>> 
>>>>>> A = matrix(rnorm(8),4,2)
>>>>>> B = matrix(rnorm(6),2,3)
>>>>>> library(CMATRIX)
>>>>>> A
>>>>> 
>>>>>          [,1]         [,2]
>>>>> [1,] -0.4981664 -0.7243532
>>>>> [2,]  0.1428766 -1.5501623
>>>>> [3,] -2.0624701  1.5104507
>>>>> [4,] -0.5871962  0.3049442
>>>>>> 
>>>>>> B
>>>>> 
>>>>>           [,1]            [,2]            [,3]
>>>>> [1,]  0.02477964 0.5827084 1.8434375
>>>>> [2,] -0.20200104 1.7294264 0.9071397
>>>>>> 
>>>>>> C_matrix_multiply(A,B)
>>>>> 
>>>>> m = 4, n = 2, p = 3
>>>>> -0.498166 0.142877 -2.062470 -0.587196 -0.724353 -1.550162 1.510451
>>>>> 0.304944
>>>>> 0.024780 -0.202001 0.582708 1.729426 1.843437 0.907140
>>>>> 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000
>>>>> 0.000000 0.000000 0.000000 0.000000 0.000000
>>>>> Parameter 10 to routine DGEMM  was incorrect
>>>>> Mac OS BLAS parameter error in DGEMM , parameter #0, (unavailable), is 0
>>>>> 
>>>>> and R immediately dies.  I know the arguments are being passed into
>>>>> the C code and everything up to my F77_CALL is functioning based on
>>>>> the printed output.  The problem is definitely something to do with my
>>>>> F77_CALL(dgemm) line.  My understanding is that parameter 10 should be
>>>>> the leading dimension of the matrix B, which in this case should be
>>>>> equal to 2, the number of rows in that matrix, which is what I am
>>>>> doing.  I have also considered that parameter numbering starts at 0,
>>>>> in which case the incorrect parameter is &zero, but again that seems
>>>>> correct to me.  All of my reading and research suggests I am doing
>>>>> everything correctly, so I am somewhat stumped.  Perhaps I am missing
>>>>> something simple or obvious, as I have never done this before and am
>>>>> proceeding with only google and the R docs as my guide.  I am
>>>>> wondering if anybody can see what I'm doing wrong here, or perhaps
>>>>> something I could do to try to fix it.  Any assistance would be
>>>>> greatly appreciated.
>>>>> 
>>>>> Best Regards,
>>>>> 
>>>>> Jason Rudy
>>>>> Graduate Student
>>>>> Bioinformatics and Medical Informatics Program
>>>>> San Diego State University
>>>>> 
>>>>> ______________________________________________
>>>>> R-devel at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>> 
>>>> 
>>>> --
>>>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>>>> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>>>> University of Oxford,             Tel:  +44 1865 272861 (self)
>>>> 1 South Parks Road,                     +44 1865 272866 (PA)
>>>> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>>>> 
>>> 
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>> 
>>> 
>> 
>> 
> 
> 


From bates at stat.wisc.edu  Tue Feb 22 16:37:55 2011
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 22 Feb 2011 09:37:55 -0600
Subject: [Rd] Problem using F77_CALL(dgemm) in a package
In-Reply-To: <AANLkTikP74hDvS9RAyzR68pKU6fHXuMWMtZ9o3tzZkAx@mail.gmail.com>
References: <AANLkTimAHcu_=_rMR9bFVYK86bmWhs8Pimgv3L-LiHsV@mail.gmail.com>
	<19809.14419.760969.854831@max.nulle.part>
	<19809.15657.103744.21821@max.nulle.part>
	<AANLkTikP74hDvS9RAyzR68pKU6fHXuMWMtZ9o3tzZkAx@mail.gmail.com>
Message-ID: <AANLkTi=L2PcKxAcNz=V9OZdWzXC3WFowLXKi8pS3Bj8L@mail.gmail.com>

On Sun, Feb 20, 2011 at 4:39 PM, Jason Rudy <jcrudy at gmail.com> wrote:
> I've never used C++ before, so for this project I think I will stick
> with just using the BLAS and LAPACK routines directly. ?Another issue
> is that I will need to do some sparse matrix computations, for which I
> am planning to use CSPARSE, at least to begin with. ?I am interested
> by RcppArmadillo, and would consider it for future projects. ?If you
> don't mind, what in your opinion are the major pros and cons of an
> RcppArmadillo solution compared to simply using the BLAS or LAPACK
> routines through the .C interface?

You may want to consider the API exported by the Matrix package that
allows access to CHOLMOD functions in that package's library.  The
entire CSPARSE library is also included in the Matrix package but most
of it is not exported because the CHOLMOD functions are generally more
effective.  (Both CHOLMOD and CSPARSE are written by Tim Davis.
CSPARSE is good code but it was written more for instructional purpose
than as an "industrial strength" package.)

> On Sun, Feb 20, 2011 at 8:11 AM, Dirk Eddelbuettel <edd at debian.org> wrote:
>>
>> On 20 February 2011 at 09:50, Dirk Eddelbuettel wrote:
>> | There is of course merit in working through the barebones API but in case you
>> | would consider a higher-level alternative, consider these few lines based on
>> | RcppArmadillo (which end up calling dgemm() for you via R's linkage to the BLAS)
>>
>> PS I always forget that we have direct support in Rcpp::as<> for Armadillo
>> matrices. The examples reduces to three lines in C++, and you never need to
>> worry about row or column dimension, or memory allocation or deallocation:
>>
>> ?R> suppressMessages(library(inline))
>> ?R> txt <- '
>> ?+ ? ?arma::mat Am = Rcpp::as< arma::mat >(A);
>> ?+ ? ?arma::mat Bm = Rcpp::as< arma::mat >(B);
>> ?+ ? ?return Rcpp::wrap( Am * Bm );
>> ?+ ? ?'
>> ?R> mmult <- cxxfunction(signature(A="numeric", B="numeric"),
>> ?+ ? ? ? ? ? ? ? ? ? ? ?body=txt,
>> ?+ ? ? ? ? ? ? ? ? ? ? ?plugin="RcppArmadillo")
>> ?R> A <- matrix(1:9, 3, 3)
>> ?R> B <- matrix(9:1, 3, 3)
>> ?R> C <- mmult(A, B)
>> ?R> print(C)
>> ? ? ? [,1] [,2] [,3]
>> ?[1,] ? 90 ? 54 ? 18
>> ?[2,] ?114 ? 69 ? 24
>> ?[3,] ?138 ? 84 ? 30
>> ?R>
>>
>> Matrices A and B from directly initialise Armadillo matrices, and the result
>> can be returned directly.
>>
>> Hth, Dirk
>>
>> --
>> Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From paul_roebuck at comcast.net  Tue Feb 22 16:53:36 2011
From: paul_roebuck at comcast.net (Paul Roebuck)
Date: Tue, 22 Feb 2011 09:53:36 -0600
Subject: [Rd] Tcl/Tk Binding % Substitutions
Message-ID: <441A11B6-6806-4C0E-81FF-0410E47B1068@comcast.net>

How should we translate something like the following?

Tcl> bind Frame <Enter> {%W config -bg red}

such that the widget id (and other % substitutions) can be accessed
in R callback?

one <- tkframe(width=30, height=30)
tkbind("Frame",
            "<Enter>",
            function(TBD} {
                ## Do whatever...
            })


From savicky at cs.cas.cz  Tue Feb 22 17:40:11 2011
From: savicky at cs.cas.cz (Petr Savicky)
Date: Tue, 22 Feb 2011 17:40:11 +0100
Subject: [Rd] error in memCompress() in make check
In-Reply-To: <20110222123807.GA13609@cs.cas.cz>
References: <20110222104232.GA20876@cs.cas.cz>
	<alpine.LFD.2.02.1102221115330.11838@gannet.stats.ox.ac.uk>
	<20110222123807.GA13609@cs.cas.cz>
Message-ID: <20110222164011.GA26081@cs.cas.cz>

On Tue, Feb 22, 2011 at 01:38:07PM +0100, Petr Savicky wrote:
...
> The commands
> 
>   txt <- readLines(file.path(R.home("doc"), "COPYING"))
>   txt.xz <- memCompress(txt, "x")
> 
> do not produce an error, if the compiled R runs in the same shell,
> where "make check" was run. However, they produce the error, if R is
> started in a new shell.

Athough i did see the above two lines with no error on my screen, the
change of the behavior is not reproducible. I am sorry, i probably
mixed up windows or something.

According to a repeated test, the above two lines produce the error

  Error in memCompress(txt, "x") : internal error 5 in memCompress

on the machine described in the first email, even if --with-system-xz=no
was used for configuration.

Petr Savicky.


From amosfolarin at gmail.com  Tue Feb 22 18:05:26 2011
From: amosfolarin at gmail.com (zoolium)
Date: Tue, 22 Feb 2011 09:05:26 -0800 (PST)
Subject: [Rd] trouble compiling RMySQL (and others) for 64 bit windows.
In-Reply-To: <4CDEDD26.6050201@statistik.tu-dortmund.de>
References: <AANLkTinDSqVgdtt2qJ634_2QTOADQbbxiiXC-qoFrFj_@mail.gmail.com>
	<4CDEDD26.6050201@statistik.tu-dortmund.de>
Message-ID: <1298394326417-3319623.post@n4.nabble.com>


I recently found a solution to the RMySQL compiling problem. 

You however there is one additional requirement at present (with the MySQL
server version 5.5 & R2.12.1) follow the
http://biostat.mc.vanderbilt.edu/wiki/Main/RMySQL instructions at present as
the locations of the libmySQL.dll differs to what is expected in the
package.

i.e. for the 64bit compiling. 
it expects the libmySQL.dll to be in "${MYSQL_HOME}"/bin/libmySQL.dll
so simply copy the dll over to the /bin dir and it will now compile.




for the 32bit compilling.
the libmySQL.lib is expected in "${MYSQL_HOME}"/lib/opt/libmysql.lib
again moving this should solve the problem.



Alternatively, if you don't want to or can't move these files. Then you can
edit the source code files:
Makevars.win
Makevars.win32
Makevars.win64
 appropriately pointing to /lib/libmysql.dll /lib/libmysql.lib











-- 
View this message in context: http://r.789695.n4.nabble.com/trouble-compiling-RMySQL-and-others-for-64-bit-windows-tp2549336p3319623.html
Sent from the R devel mailing list archive at Nabble.com.


From wdunlap at tibco.com  Tue Feb 22 18:25:00 2011
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 22 Feb 2011 09:25:00 -0800
Subject: [Rd] Anomaly in [.terms
In-Reply-To: <1298316714.27061.25.camel@punchbuggy>
References: <1298316714.27061.25.camel@punchbuggy>
Message-ID: <77EB52C6DD32BA4D87471DCD70C8D70003EF3D3E@NA-PA-VBE03.na.tibco.com>


> -----Original Message-----
> From: r-devel-bounces at r-project.org 
> [mailto:r-devel-bounces at r-project.org] On Behalf Of Terry Therneau
> Sent: Monday, February 21, 2011 11:32 AM
> To: r-devel at r-project.org
> Subject: [Rd] Anomaly in [.terms
> 
> 
>  This arose when working on an addition to coxph, which has 
> the features
> that the X matrix never has an intercept column, and we 
> remove strata()
> terms before computing an X matrix.  The surprise: when a terms object
> is subset the intercept attribute is turned back on.

I've wondered about how to deal with terms objects
whose formula and attributes disagreed with each
other.  In your case the intercept attribute was 0
but there was no -1 in the formula and you (and others)
complained that [.terms respected the formula and not
the attributes.  In another case you can set the response
attribute to 0 but leave the response term in the formula.
Then [.terms alters the formula to drop the response term.
  > t <- terms(y ~ x1 + x2)
  > attr(t, "response")
  [1] 1
  > attr(t, "response") <- 0
  > t[1]
  ~x1
  attr(,"variables")
  list(x1)
  attr(,"factors")
     x1
  x1  1
  attr(,"term.labels")
  [1] "x1"
  attr(,"order")
  [1] 1
  attr(,"intercept")
  [1] 1
  attr(,"response")
  [1] 0
  attr(,".Environment")
  <environment: R_GlobalEnv>
  > version$version.string
  [1] "R version 2.12.1 (2010-12-16)"
Is altering the formula to match the attributes desirable?

I suspect you would be displeased if [.terms added
a -1 to the formula if the intercept term were 0.

If you have a terms object without a response in
the formula and you set the response attribute to
1 then [.terms just gets mixed up.  Altering most
other attributes of a terms object risks confusing
lots of functions.

Should R have a function to set the intercept term
to a legal value so we could say that directly altering
the attributes of a terms object should never be done?

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com 

>   My lines 2 and 3 below were being executed just before a call to
> model.frame.  The simple solution was of course to do them in the
> opposite order so I am not waiting on a "fix". 
>   Not to mention that I am not sure a fix is required, though I was
> surprised. 
>     Terry T.
> 
> 
> tmt1131% R
> 
> R version 2.12.0 (2010-10-15)
> Copyright (C) 2010 The R Foundation for Statistical Computing
> ISBN 3-900051-07-0
> Platform: x86_64-unknown-linux-gnu (64-bit)
> 
> > test <- terms(Surv(time, status) ~ age + strata(ph.ecog),
> +    specials='strata')
> 
> > attr(test, 'intercept') <- 0  #turn off intercept
> > test <- test[-2]   #remove strata
> 
> > test
> Surv(time, status) ~ age
> attr(,"variables")
> list(Surv(time, status), age)
> attr(,"factors")
>                    age
> Surv(time, status)   0
> age                  1
> attr(,"term.labels")
> [1] "age"
> attr(,"specials")
> attr(,"specials")$strata
> NULL
> 
> attr(,"order")
> [1] 1
> attr(,"intercept")
> [1] 1
> attr(,"response")
> [1] 1
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 


From kjetilbrinchmannhalvorsen at gmail.com  Tue Feb 22 20:36:19 2011
From: kjetilbrinchmannhalvorsen at gmail.com (Kjetil Halvorsen)
Date: Tue, 22 Feb 2011 16:36:19 -0300
Subject: [Rd] How to make a package with help pages in multiple languages?
Message-ID: <AANLkTikaefGR7iN6aVNBaDYN9_zF6nctG3AfAzLDk1oF@mail.gmail.com>

This question was adsked on R-help-es, and got no responses there.
the OP asked for help pages in english and spanish. Any ideas how this
should be done? I guess there really should be a solution for any number of
languages.

Kjetil


From ripley at stats.ox.ac.uk  Tue Feb 22 21:34:23 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 22 Feb 2011 20:34:23 +0000
Subject: [Rd] How to make a package with help pages in multiple
 languages?
In-Reply-To: <AANLkTikaefGR7iN6aVNBaDYN9_zF6nctG3AfAzLDk1oF@mail.gmail.com>
References: <AANLkTikaefGR7iN6aVNBaDYN9_zF6nctG3AfAzLDk1oF@mail.gmail.com>
Message-ID: <alpine.LFD.2.02.1102222022300.14679@gannet.stats.ox.ac.uk>

On Tue, 22 Feb 2011, Kjetil Halvorsen wrote:

> This question was adsked on R-help-es, and got no responses there.
> the OP asked for help pages in english and spanish. Any ideas how this
> should be done? I guess there really should be a solution for any number of
> languages.

Rcmdr had English and Spanish help overviews, as I recall, and now has
PDFs in English, Spanish, Japanese and Russian.

The short answer is that we don't have a way to do it, and we have a 
default encoding for a package which makes this awkward.  I think I 
would simply prepare separate packages foo.en and foo.es which 
differed only in the man directory (and there are packages 
openNLPmodels.{en.es}).  And although they do differ in detail, the 
two largest installed packages on CRAN are nutshell and nutshellDE.

If there were enough demand and someone was prepared to put the work 
in, we could have man-es in the sources and help-es, html-es in the 
installed packages.  But the amount of work would be non-trivial, as 
for example 'R CMD check' would have to check all the installed 
languages.  But I suspect the demand is far too low to consider doing 
this.

>
> Kjetil
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From murdoch.duncan at gmail.com  Tue Feb 22 21:42:38 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 22 Feb 2011 15:42:38 -0500
Subject: [Rd] How to make a package with help pages in multiple
	languages?
In-Reply-To: <AANLkTikaefGR7iN6aVNBaDYN9_zF6nctG3AfAzLDk1oF@mail.gmail.com>
References: <AANLkTikaefGR7iN6aVNBaDYN9_zF6nctG3AfAzLDk1oF@mail.gmail.com>
Message-ID: <4D641FBE.8050103@gmail.com>

On 22/02/2011 2:36 PM, Kjetil Halvorsen wrote:
> This question was adsked on R-help-es, and got no responses there.
> the OP asked for help pages in english and spanish. Any ideas how this
> should be done? I guess there really should be a solution for any number of
> languages.

I don't think there is any easy way to do this currently, but it would 
be a good idea.

I think we would need a fair bit of work to add the support for it, so 
it's not likely to arrive soon unless someone is eager to do the work.

Here are some thoughts:

  - Allow a type of package that contains language-specific 
documentation for another package or multiple packages.  When such a 
package is attached, pages in it are shown in preference to the regular 
ones, with an automatic link to the regular one generated (in case the 
translation is out of date or incorrect).
- Perhaps such a package is automatically attached when the original is 
attached, if the locale says to use that language?

Duncan Murdoch


From jcrudy at gmail.com  Tue Feb 22 23:44:12 2011
From: jcrudy at gmail.com (Jason Rudy)
Date: Tue, 22 Feb 2011 14:44:12 -0800
Subject: [Rd] Problem using F77_CALL(dgemm) in a package
In-Reply-To: <BF3431FB-43FF-47AB-BC9A-D71163B53515@r-project.org>
References: <AANLkTimAHcu_=_rMR9bFVYK86bmWhs8Pimgv3L-LiHsV@mail.gmail.com>
	<alpine.LFD.2.02.1102201540060.16292@gannet.stats.ox.ac.uk>
	<AANLkTi=CQhxm5RBhymbCBLz8JAYs1cbEy=xC9LR_n8js@mail.gmail.com>
	<D11E54DC-6FED-4AE3-A5DB-7EDBDBA28DD4@r-project.org>
	<AANLkTi=2P19dKd2W1aNnksSPGpmKqYqpkSE+AnPdt4Rz@mail.gmail.com>
	<BF3431FB-43FF-47AB-BC9A-D71163B53515@r-project.org>
Message-ID: <AANLkTi=Ds_LOPh8H92sZEVReNbdHrf3t8FQBi3kcLNne@mail.gmail.com>

You're right about the code preceding .C.  I stripped down the .C and
.Call codes to be as similar as possible, and the timings were much
closer.

R code:
Call_matrix_multiply = function(A,B){
	C <- matrix(0,nrow(A),ncol(B))
	.Call("R_CALL_matrix_multiply", A, B, C)
	return(C)
}

C_matrix_multiply = function(A,B){
	C <- matrix(0,nrow(A),ncol(B))
	.C("R_matrix_multiply",A,B,nrow(A),ncol(A),ncol(B),C,DUP=FALSE,NAOK=TRUE)
	return(C)
}


C code:


void R_CALL_matrix_multiply(SEXP A, SEXP B, SEXP C) {
	double one = 1.0;
	double zero = 0.0;
	int *dimA = INTEGER(getAttrib(A, R_DimSymbol));
	int *dimB = INTEGER(getAttrib(B, R_DimSymbol));
	F77_CALL(dgemm)("N","N",dimA,dimB+1,dimA+1,&one,REAL(A),dimA,REAL(B),dimA+1,&zero,REAL(C),dimA);
}

void R_matrix_multiply(double * A, double * B, int * m, int *n, int *
					   p, double * C){
	
	double one = 1.0;
	double zero = 0.0;
	
	//Here is the actual multiplication
	F77_CALL(dgemm)("N","N",m,p,n,&one,A,m,B,n,&zero,C,m);
}


Timings:

> m = 2000
> n = 2000
> p = 2000
> A = matrix(rnorm(m*n),m,n)
> B = matrix(rnorm(n*p),n,p)
> library(CMATRIX)
> system.time(C_matrix_multiply(A,B))
   user  system elapsed
  2.782   0.035   1.611
> system.time(Call_matrix_multiply(A,B))
   user  system elapsed
  2.789   0.032   1.629
>
> m = 2000
> n = 2000
> p = 2000
> A = matrix(rnorm(m*n),m,n)
> B = matrix(rnorm(n*p),n,p)
> library(CMATRIX)
> system.time(C_matrix_multiply(A,B))
   user  system elapsed
  2.793   0.029   1.609
> system.time(Call_matrix_multiply(A,B))
   user  system elapsed
  2.787   0.029   1.586

Even so, it seems the .Call interface has a lot of advantages.  I
think I will use it for this project and see how I like it.

Jason

On Tue, Feb 22, 2011 at 7:27 AM, Simon Urbanek
<simon.urbanek at r-project.org> wrote:
> On Feb 22, 2011, at 1:55 AM, Jason Rudy wrote:
>
>> I just tried that myself and the .Call version is substantially
>> faster. ?It seems like there is a lot more going on in the .Call C
>> code than the .C. ?Why is .Call faster? ?Does it have to do with the
>> way arguments are passed into the C function? ?I tried with DUP=FALSE
>> and NAOK=TRUE, but .Call was still the winner.
>>
>
> .Call is the "native" interface so it passes all objects directly as references - essentially the same way that R uses internally (.C with DUP=FALSE and NAOK=TRUE comes close to that, though; the fastest is .External in this respect). Also you're allocating objects as you need them so there will be less copying afterwards. However, I suspect that major part of the difference is also in the code preceding the C code involved in this -- for example as.double() will implicitly create a copy since it needs to strip attributes whereas coerceVector is a no-op if the type matches.
>
> .C is there for historical compatibility - it is essentially equivalent to .Fortran which was the original (and only) interface way back when. .Call is in comparison a more recent addition, that's why you still find a lot of .C code. Personally I don't use .C at all because compared to .Call it is so cumbersome and error-prone (you can't even tell the length of the passed vectors in C!), but others have different preferences.
>
> Cheers,
> Simon
>
>
>> On Sun, Feb 20, 2011 at 4:27 PM, Simon Urbanek
>> <simon.urbanek at r-project.org> wrote:
>>> Jason,
>>>
>>> FWIW the direct interface (.Call) is more efficient and makes passing things from R simpler:
>>>
>>> C_matrix_multiply = function(A,B) .Call("R_matrix_multiply", A, B)
>>>
>>> The drawback is a bit more legwork on the C side, but it also gives you more flexibility:
>>>
>>> SEXP R_matrix_multiply(SEXP A, SEXP B) {
>>> ? ? ? ?double one = 1.0;
>>> ? ? ? ?double zero = 0.0;
>>> ? ? ? ?int *dimA = INTEGER(getAttrib(A, R_DimSymbol));
>>> ? ? ? ?int *dimB = INTEGER(getAttrib(B, R_DimSymbol));
>>> ? ? ? ?SEXP sDimC = PROTECT(allocVector(INTSXP, 2));
>>> ? ? ? ?int *dimC = INTEGER(sDimC);
>>> ? ? ? ?SEXP C = PROTECT(allocVector(REALSXP, dimA[0] * dimB[1]));
>>> ? ? ? ?if (dimA[1] != dimB[0]) error("incompatible matrices!");
>>> ? ? ? ?dimC[0] = dimA[0];
>>> ? ? ? ?dimC[1] = dimB[1];
>>> ? ? ? ?setAttrib(C, R_DimSymbol, sDimC);
>>> ? ? ? ?A = PROTECT(coerceVector(A, REALSXP));
>>> ? ? ? ?B = PROTECT(coerceVector(B, REALSXP));
>>> ? ? ? ?F77_CALL(dgemm)("N","N",dimA,dimB+1,dimA+1,&one,REAL(A),dimA,REAL(B),dimA+1,&zero,REAL(C),dimA);
>>> ? ? ? ?UNPROTECT(4);
>>> ? ? ? ?return C;
>>> }
>>>
>>> For comparison:
>>>> A=matrix(rnorm(1e5),500)
>>>> B=matrix(rnorm(1e5),,500)
>>>
>>> .Call:
>>>
>>>> system.time(for (i in 1:10) C_matrix_multiply(A,B))
>>> ? user ?system elapsed
>>> ?0.656 ? 0.008 ? 0.686
>>>
>>> .C:
>>>
>>>> system.time(for (i in 1:10) CC_matrix_multiply(A,B))
>>> ? user ?system elapsed
>>> ?0.886 ? 0.044 ? 0.943
>>>
>>>
>>> in fact .Call is even a tiny bit faster than %*%:
>>>
>>>> system.time(for (i in 1:10) A %*% B)
>>> ? user ?system elapsed
>>> ?0.658 ? 0.004 ? 0.665
>>>
>>> (it's not just a measurement error - it's consistent for more replications etc. - but it's really negligible - possibly just due to dispatch of %*%)
>>>
>>> Cheers,
>>> Simon
>>>
>>>
>>> On Feb 20, 2011, at 5:23 PM, Jason Rudy wrote:
>>>
>>>> It was indeed a simple problem! ?I took a look at that array.c as you
>>>> suggested and that cleared it right up. ?So, the correct C code is:
>>>>
>>>> #include <R.h>
>>>> #include <R_ext/Utils.h>
>>>> #include <R_ext/Lapack.h>
>>>> #include <R_ext/BLAS.h>
>>>>
>>>> void R_matrix_multiply(double * A, double * B, int * m, int *n, int *
>>>> p, double * C){
>>>>
>>>> ? ? ? double one = 1.0;
>>>> ? ? ? double zero = 0.0;
>>>>
>>>> ? ? ? ?//Just printing the input arguments
>>>> ? ? ? Rprintf("m = %d, n = %d, p = %d\n",*m,*n,*p);
>>>> ? ? ? int i;
>>>> ? ? ? for(i=0;i<(*m**n);i++){
>>>> ? ? ? ? ? ? ? Rprintf("%f ",A[i]);
>>>> ? ? ? }
>>>> ? ? ? Rprintf("\n");
>>>> ? ? ? for(i=0;i<(*n**p);i++){
>>>> ? ? ? ? ? ? ? Rprintf("%f ",B[i]);
>>>> ? ? ? }
>>>> ? ? ? Rprintf("\n");
>>>> ? ? ? for(i=0;i<(*m**p);i++){
>>>> ? ? ? ? ? ? ? Rprintf("%f ",C[i]);
>>>> ? ? ? }
>>>> ? ? ? Rprintf("\n");
>>>>
>>>> ? ? ? ?//Here is the actual multiplication
>>>> ? ? ? F77_CALL(dgemm)("N","N",m,p,n,&one,A,m,B,n,&zero,C,m);
>>>> }
>>>>
>>>> The only difference being that I had the 4th and 5th arguments (n and
>>>> p) mixed up. ?There was also a problem in my R code after the
>>>> multiplication took place. ?For the record, the correct R code is:
>>>>
>>>> C_matrix_multiply = function(A,B){
>>>> ? ? ? C <- matrix(0,nrow(A),ncol(B))
>>>> ? ? ? cout <- .C("R_matrix_multiply",as.double(A),as.double(B),nrow(A),ncol(A),ncol(B),as.double(C))
>>>> ? ? ? return(matrix(cout[[6]],nrow(A),ncol(B)))
>>>> }
>>>>
>>>> Thanks for the help. ?Now that I have a functioning example I am well
>>>> on my way to completing this project.
>>>>
>>>> -Jason
>>>>
>>>> On Sun, Feb 20, 2011 at 7:42 AM, Prof Brian Ripley
>>>> <ripley at stats.ox.ac.uk> wrote:
>>>>> Look a close look at matprod in src/main/array in the R sources.
>>>>> Hint: it is the other dimensions you have wrong.
>>>>>
>>>>> And as BLAS is Fortran, counts do start at 1.
>>>>>
>>>>> On Sat, 19 Feb 2011, Jason Rudy wrote:
>>>>>
>>>>>> Dear R-devel,
>>>>>>
>>>>>> I've written a numerical solver for SOCPs (second order cone programs)
>>>>>> in R, and now I want to move most of the solver code into C for speed.
>>>>>> I've written combined R/C packages before, but in this case I need to
>>>>>> do matrix operations in my C code. ?As I have never done that before,
>>>>>> I'm trying to write some simple examples to make sure I understand the
>>>>>> basics. ?I am stuck on the first one. ?I'm trying to write a function
>>>>>> to multiply two matrices using the blas routine dgemm. ?The name of my
>>>>>> example package is CMATRIX. ?My code is as follows.
>>>>>>
>>>>>> I have a file matrix.c in my src directory:
>>>>>>
>>>>>> #include <R.h>
>>>>>> #include <R_ext/Utils.h>
>>>>>> #include <R_ext/Lapack.h>
>>>>>> #include <R_ext/BLAS.h>
>>>>>>
>>>>>> //Computes C = A*B
>>>>>> void R_matrix_multiply(double * A, double * B, int * m, int *n, int *
>>>>>> p, double * C){
>>>>>> ? ? ? ?double one = 1.0;
>>>>>> ? ? ? ?double zero = 0.0;
>>>>>>
>>>>>> ? ? ? //Just printing the input arguments
>>>>>> ? ? ? ?Rprintf("m = %d, n = %d, p = %d\n",*m,*n,*p);
>>>>>> ? ? ? ?int i;
>>>>>> ? ? ? ?for(i=0;i<(*m**n);i++){
>>>>>> ? ? ? ? ? ? ? ?Rprintf("%f ",A[i]);
>>>>>> ? ? ? ?}
>>>>>> ? ? ? ?Rprintf("\n");
>>>>>> ? ? ? ?for(i=0;i<(*n**p);i++){
>>>>>> ? ? ? ? ? ? ? ?Rprintf("%f ",B[i]);
>>>>>> ? ? ? ?}
>>>>>> ? ? ? ?Rprintf("\n");
>>>>>> ? ? ? ?for(i=0;i<(*m**p);i++){
>>>>>> ? ? ? ? ? ? ? ?Rprintf("%f ",C[i]);
>>>>>> ? ? ? ?}
>>>>>> ? ? ? ?Rprintf("\n");
>>>>>>
>>>>>>
>>>>>> ? ? ? //Here is the actual multiplication
>>>>>> ? ? ? ?F77_CALL(dgemm)("N","N",m,n,p,&one,A,m,B,n,&zero,C,m);
>>>>>> }
>>>>>>
>>>>>> And the file C_matrix_multiply.R in my R directory:
>>>>>>
>>>>>> C_matrix_multiply = function(A,B){
>>>>>> ? ? ? ?C <- matrix(0,nrow(A),ncol(B))
>>>>>> ? ? ? ?cout <-
>>>>>> .C("R_matrix_multiply",as.double(A),as.double(B),nrow(A),ncol(A),ncol(B),as.double(C))
>>>>>> ? ? ? ?return(matrix(cout$C,nrowA,ncol(B)))
>>>>>>
>>>>>> }
>>>>>>
>>>>>> My namespace file is:
>>>>>>
>>>>>> export("C_matrix_multiply")
>>>>>> useDynLib(CMATRIX.so,R_matrix_multiply)
>>>>>>
>>>>>> I'm not sure if it's necessary, but I've also included a Makevars.in
>>>>>> file in my src directory:
>>>>>>
>>>>>> PKG_CPPFLAGS=@PKG_CPPFLAGS@
>>>>>> PKG_CFLAGS=@PKG_CFLAGS@
>>>>>> PKG_LIBS=@PKG_LIBS@ ?${LAPACK_LIBS} ${BLAS_LIBS} ${FLIBS}
>>>>>>
>>>>>> which I simply copied from the diversitree package, which seems to use
>>>>>> a lot of fortran. ?I have the same problem (which I am getting to)
>>>>>> with or without this Makevars.in file.
>>>>>>
>>>>>> I install my package using:
>>>>>>
>>>>>> R CMD INSTALL CMATRIX
>>>>>>
>>>>>> Then I start up R and attempt to run the following code:
>>>>>>
>>>>>> #Make some random matrices
>>>>>> A = matrix(rnorm(8),4,2)
>>>>>> B = matrix(rnorm(6),2,3)
>>>>>>
>>>>>> #Load my package
>>>>>> library(CMATRIX)
>>>>>>
>>>>>> #Print the matrices
>>>>>> A
>>>>>> B
>>>>>>
>>>>>> #Try to multiply them
>>>>>> product = C_matrix_multiply(A,B)
>>>>>>
>>>>>> What I want, and what according to my understanding should happen, is
>>>>>> for product to contain the same matrix as would result from A %*% B.
>>>>>> Instead, I get the following:
>>>>>>
>>>>>>> A = matrix(rnorm(8),4,2)
>>>>>>> B = matrix(rnorm(6),2,3)
>>>>>>> library(CMATRIX)
>>>>>>> A
>>>>>>
>>>>>> ? ? ? ? ?[,1] ? ? ? ? [,2]
>>>>>> [1,] -0.4981664 -0.7243532
>>>>>> [2,] ?0.1428766 -1.5501623
>>>>>> [3,] -2.0624701 ?1.5104507
>>>>>> [4,] -0.5871962 ?0.3049442
>>>>>>>
>>>>>>> B
>>>>>>
>>>>>> ? ? ? ? ? [,1] ? ? ? ? ? ?[,2] ? ? ? ? ? ?[,3]
>>>>>> [1,] ?0.02477964 0.5827084 1.8434375
>>>>>> [2,] -0.20200104 1.7294264 0.9071397
>>>>>>>
>>>>>>> C_matrix_multiply(A,B)
>>>>>>
>>>>>> m = 4, n = 2, p = 3
>>>>>> -0.498166 0.142877 -2.062470 -0.587196 -0.724353 -1.550162 1.510451
>>>>>> 0.304944
>>>>>> 0.024780 -0.202001 0.582708 1.729426 1.843437 0.907140
>>>>>> 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000
>>>>>> 0.000000 0.000000 0.000000 0.000000 0.000000
>>>>>> Parameter 10 to routine DGEMM ?was incorrect
>>>>>> Mac OS BLAS parameter error in DGEMM , parameter #0, (unavailable), is 0
>>>>>>
>>>>>> and R immediately dies. ?I know the arguments are being passed into
>>>>>> the C code and everything up to my F77_CALL is functioning based on
>>>>>> the printed output. ?The problem is definitely something to do with my
>>>>>> F77_CALL(dgemm) line. ?My understanding is that parameter 10 should be
>>>>>> the leading dimension of the matrix B, which in this case should be
>>>>>> equal to 2, the number of rows in that matrix, which is what I am
>>>>>> doing. ?I have also considered that parameter numbering starts at 0,
>>>>>> in which case the incorrect parameter is &zero, but again that seems
>>>>>> correct to me. ?All of my reading and research suggests I am doing
>>>>>> everything correctly, so I am somewhat stumped. ?Perhaps I am missing
>>>>>> something simple or obvious, as I have never done this before and am
>>>>>> proceeding with only google and the R docs as my guide. ?I am
>>>>>> wondering if anybody can see what I'm doing wrong here, or perhaps
>>>>>> something I could do to try to fix it. ?Any assistance would be
>>>>>> greatly appreciated.
>>>>>>
>>>>>> Best Regards,
>>>>>>
>>>>>> Jason Rudy
>>>>>> Graduate Student
>>>>>> Bioinformatics and Medical Informatics Program
>>>>>> San Diego State University
>>>>>>
>>>>>> ______________________________________________
>>>>>> R-devel at r-project.org mailing list
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>>>
>>>>>
>>>>> --
>>>>> Brian D. Ripley, ? ? ? ? ? ? ? ? ?ripley at stats.ox.ac.uk
>>>>> Professor of Applied Statistics, ?http://www.stats.ox.ac.uk/~ripley/
>>>>> University of Oxford, ? ? ? ? ? ? Tel: ?+44 1865 272861 (self)
>>>>> 1 South Parks Road, ? ? ? ? ? ? ? ? ? ? +44 1865 272866 (PA)
>>>>> Oxford OX1 3TG, UK ? ? ? ? ? ? ? ?Fax: ?+44 1865 272595
>>>>>
>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>
>>>>
>>>
>>>
>>
>>
>
>


From jcrudy at gmail.com  Tue Feb 22 23:45:42 2011
From: jcrudy at gmail.com (Jason Rudy)
Date: Tue, 22 Feb 2011 14:45:42 -0800
Subject: [Rd] Problem using F77_CALL(dgemm) in a package
In-Reply-To: <AANLkTi=L2PcKxAcNz=V9OZdWzXC3WFowLXKi8pS3Bj8L@mail.gmail.com>
References: <AANLkTimAHcu_=_rMR9bFVYK86bmWhs8Pimgv3L-LiHsV@mail.gmail.com>
	<19809.14419.760969.854831@max.nulle.part>
	<19809.15657.103744.21821@max.nulle.part>
	<AANLkTikP74hDvS9RAyzR68pKU6fHXuMWMtZ9o3tzZkAx@mail.gmail.com>
	<AANLkTi=L2PcKxAcNz=V9OZdWzXC3WFowLXKi8pS3Bj8L@mail.gmail.com>
Message-ID: <AANLkTimr+YH-NgfsXoJeRWQx53nsp1du7YvejxfUKOUB@mail.gmail.com>

Thanks for the tip.  That API could make my work considerably easier.

Jason

On Tue, Feb 22, 2011 at 7:37 AM, Douglas Bates <bates at stat.wisc.edu> wrote:
> On Sun, Feb 20, 2011 at 4:39 PM, Jason Rudy <jcrudy at gmail.com> wrote:
>> I've never used C++ before, so for this project I think I will stick
>> with just using the BLAS and LAPACK routines directly. ?Another issue
>> is that I will need to do some sparse matrix computations, for which I
>> am planning to use CSPARSE, at least to begin with. ?I am interested
>> by RcppArmadillo, and would consider it for future projects. ?If you
>> don't mind, what in your opinion are the major pros and cons of an
>> RcppArmadillo solution compared to simply using the BLAS or LAPACK
>> routines through the .C interface?
>
> You may want to consider the API exported by the Matrix package that
> allows access to CHOLMOD functions in that package's library. ?The
> entire CSPARSE library is also included in the Matrix package but most
> of it is not exported because the CHOLMOD functions are generally more
> effective. ?(Both CHOLMOD and CSPARSE are written by Tim Davis.
> CSPARSE is good code but it was written more for instructional purpose
> than as an "industrial strength" package.)
>
>> On Sun, Feb 20, 2011 at 8:11 AM, Dirk Eddelbuettel <edd at debian.org> wrote:
>>>
>>> On 20 February 2011 at 09:50, Dirk Eddelbuettel wrote:
>>> | There is of course merit in working through the barebones API but in case you
>>> | would consider a higher-level alternative, consider these few lines based on
>>> | RcppArmadillo (which end up calling dgemm() for you via R's linkage to the BLAS)
>>>
>>> PS I always forget that we have direct support in Rcpp::as<> for Armadillo
>>> matrices. The examples reduces to three lines in C++, and you never need to
>>> worry about row or column dimension, or memory allocation or deallocation:
>>>
>>> ?R> suppressMessages(library(inline))
>>> ?R> txt <- '
>>> ?+ ? ?arma::mat Am = Rcpp::as< arma::mat >(A);
>>> ?+ ? ?arma::mat Bm = Rcpp::as< arma::mat >(B);
>>> ?+ ? ?return Rcpp::wrap( Am * Bm );
>>> ?+ ? ?'
>>> ?R> mmult <- cxxfunction(signature(A="numeric", B="numeric"),
>>> ?+ ? ? ? ? ? ? ? ? ? ? ?body=txt,
>>> ?+ ? ? ? ? ? ? ? ? ? ? ?plugin="RcppArmadillo")
>>> ?R> A <- matrix(1:9, 3, 3)
>>> ?R> B <- matrix(9:1, 3, 3)
>>> ?R> C <- mmult(A, B)
>>> ?R> print(C)
>>> ? ? ? [,1] [,2] [,3]
>>> ?[1,] ? 90 ? 54 ? 18
>>> ?[2,] ?114 ? 69 ? 24
>>> ?[3,] ?138 ? 84 ? 30
>>> ?R>
>>>
>>> Matrices A and B from directly initialise Armadillo matrices, and the result
>>> can be returned directly.
>>>
>>> Hth, Dirk
>>>
>>> --
>>> Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com
>>>
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>


From bbolker at gmail.com  Wed Feb 23 15:14:37 2011
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 23 Feb 2011 09:14:37 -0500
Subject: [Rd] request for patch in  "drop1" (add.R)
Message-ID: <4D65164D.7080707@mcmaster.ca>


  By changing three lines in drop1 from access based on $ to access
based on standard accessor methods (terms() and residuals()), it becomes
*much* easier to extend drop1 to work with other model types.
The use of $ rather than accessors in this context seems to be an
oversight rather than a design decision, but maybe someone knows better ...

  In particular, if one makes these changes (which I am pretty certain
will not break anything, as the original code basically mimicked the
default methods anyway), it becomes possible to make drop1() work with
mer objects (Doug Bates's new mixed model code) merely by defining:

terms.mer <- function(x, ...) {
  attr(x at frame,"terms")
}

extractAIC.default <- function(fit, scale=0, k=2, ...) {
  L <- logLik(fit)
  edf <- attr(L,"df")
  c(edf,-2*L+2*edf)
}

 Adding this definition of extractAIC.default also makes drop1() work
with lme fits ...

  Comments?  Should I submit to the bug database as "enhancement
request"?  Are there any hidden downsides to this?

  Ben Bolker
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: add_diff.txt
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110223/0cb0c994/attachment.txt>

From hpages at fhcrc.org  Wed Feb 23 20:55:16 2011
From: hpages at fhcrc.org (=?ISO-8859-1?Q?Herv=E9_Pag=E8s?=)
Date: Wed, 23 Feb 2011 11:55:16 -0800
Subject: [Rd] factor() on a double vector
Message-ID: <4D656624.60200@fhcrc.org>

Hi,

When 'x' is a vector of doubles, it's not clear how 'factor(x)'
compares its values in order to determine the levels. For example,
here all the values in 'x' are "conceptually" the same:

   x <- c(11/3,
          2/3 + 4/3 + 5/3,
          50 + 11/3 - 50,
          7.00001 - 1000003/300000)

However, due to machine rounding errors, they are not strictly equal:

   > duplicated(x)
   [1] FALSE FALSE FALSE FALSE
   > unique(x)
   [1] 3.666667 3.666667 3.666667 3.666667

but they are nearly equal:

   > all.equal(x, rep(11/3, 4))
   [1] TRUE

Now factor(), and therefore table() (which seems to be using factor()
internally), have a different opinion:

   > factor(x)
   [1] 3.66666666666667 3.66666666666667 3.66666666666666 3.66666666666667
   Levels: 3.66666666666666 3.66666666666667

   > table(x)
   x
   3.66666666666666 3.66666666666667
                  1                3

So factor() doesn't seem to be using "strict equality" or "near
equality" to determine the levels. What does it use? Sorry if I
missed it but I couldn't find any information about this in its
man page.

Wouldn't it be better if factor() was consistent with either
duplicated() or all.equal() instead of introducing its own way
of comparing doubles that lies somewhere in between?

Cheers,
H.

 > sessionInfo()
R version 2.12.0 (2010-10-15)
Platform: x86_64-unknown-linux-gnu (64-bit)

locale:
  [1] LC_CTYPE=en_US.utf8       LC_NUMERIC=C
  [3] LC_TIME=en_US.utf8        LC_COLLATE=en_US.utf8
  [5] LC_MONETARY=C             LC_MESSAGES=en_US.utf8
  [7] LC_PAPER=en_US.utf8       LC_NAME=C
  [9] LC_ADDRESS=C              LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.utf8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] tools_2.12.0

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M2-B876
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fhcrc.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From simon.urbanek at r-project.org  Wed Feb 23 21:09:22 2011
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Wed, 23 Feb 2011 15:09:22 -0500
Subject: [Rd] factor() on a double vector
In-Reply-To: <4D656624.60200@fhcrc.org>
References: <4D656624.60200@fhcrc.org>
Message-ID: <649808EB-B087-47BB-893C-0D44EAA57F12@r-project.org>

Herve,

the answer is simple - it's as.character() - it has nothing to do with factor or table.

> as.character(x)
[1] "3.66666666666667" "3.66666666666667" "3.66666666666666" "3.66666666666667"

That's what you are passing to factor, so you get the corresponding results.

Cheers,
Simon



On Feb 23, 2011, at 2:55 PM, Herv? Pag?s wrote:

> Hi,
> 
> When 'x' is a vector of doubles, it's not clear how 'factor(x)'
> compares its values in order to determine the levels. For example,
> here all the values in 'x' are "conceptually" the same:
> 
>  x <- c(11/3,
>         2/3 + 4/3 + 5/3,
>         50 + 11/3 - 50,
>         7.00001 - 1000003/300000)
> 
> However, due to machine rounding errors, they are not strictly equal:
> 
>  > duplicated(x)
>  [1] FALSE FALSE FALSE FALSE
>  > unique(x)
>  [1] 3.666667 3.666667 3.666667 3.666667
> 
> but they are nearly equal:
> 
>  > all.equal(x, rep(11/3, 4))
>  [1] TRUE
> 
> Now factor(), and therefore table() (which seems to be using factor()
> internally), have a different opinion:
> 
>  > factor(x)
>  [1] 3.66666666666667 3.66666666666667 3.66666666666666 3.66666666666667
>  Levels: 3.66666666666666 3.66666666666667
> 
>  > table(x)
>  x
>  3.66666666666666 3.66666666666667
>                 1                3
> 
> So factor() doesn't seem to be using "strict equality" or "near
> equality" to determine the levels. What does it use? Sorry if I
> missed it but I couldn't find any information about this in its
> man page.
> 
> Wouldn't it be better if factor() was consistent with either
> duplicated() or all.equal() instead of introducing its own way
> of comparing doubles that lies somewhere in between?
> 
> Cheers,
> H.
> 
> > sessionInfo()
> R version 2.12.0 (2010-10-15)
> Platform: x86_64-unknown-linux-gnu (64-bit)
> 
> locale:
> [1] LC_CTYPE=en_US.utf8       LC_NUMERIC=C
> [3] LC_TIME=en_US.utf8        LC_COLLATE=en_US.utf8
> [5] LC_MONETARY=C             LC_MESSAGES=en_US.utf8
> [7] LC_PAPER=en_US.utf8       LC_NAME=C
> [9] LC_ADDRESS=C              LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.utf8 LC_IDENTIFICATION=C
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> loaded via a namespace (and not attached):
> [1] tools_2.12.0
> 
> -- 
> Herv? Pag?s
> 
> Program in Computational Biology
> Division of Public Health Sciences
> Fred Hutchinson Cancer Research Center
> 1100 Fairview Ave. N, M2-B876
> P.O. Box 19024
> Seattle, WA 98109-1024
> 
> E-mail: hpages at fhcrc.org
> Phone:  (206) 667-5791
> Fax:    (206) 667-1319
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From hpages at fhcrc.org  Wed Feb 23 21:17:25 2011
From: hpages at fhcrc.org (=?windows-1252?Q?Herv=E9_Pag=E8s?=)
Date: Wed, 23 Feb 2011 12:17:25 -0800
Subject: [Rd] factor() on a double vector
In-Reply-To: <649808EB-B087-47BB-893C-0D44EAA57F12@r-project.org>
References: <4D656624.60200@fhcrc.org>
	<649808EB-B087-47BB-893C-0D44EAA57F12@r-project.org>
Message-ID: <4D656B55.1000700@fhcrc.org>

On 02/23/2011 12:09 PM, Simon Urbanek wrote:
> Herve,
>
> the answer is simple - it's as.character() - it has nothing to do with factor or table.
>
>> as.character(x)
> [1] "3.66666666666667" "3.66666666666667" "3.66666666666666" "3.66666666666667"
>
> That's what you are passing to factor, so you get the corresponding results.

I see. Thanks Simon.

I missed this:

   levels: an optional vector of the values that ?x? might have taken.
           The default is the unique set of values taken by
           ?as.character(x)?, ...

Cheers,
H.

>
> Cheers,
> Simon
>
>
>
> On Feb 23, 2011, at 2:55 PM, Herv? Pag?s wrote:
>
>> Hi,
>>
>> When 'x' is a vector of doubles, it's not clear how 'factor(x)'
>> compares its values in order to determine the levels. For example,
>> here all the values in 'x' are "conceptually" the same:
>>
>>   x<- c(11/3,
>>          2/3 + 4/3 + 5/3,
>>          50 + 11/3 - 50,
>>          7.00001 - 1000003/300000)
>>
>> However, due to machine rounding errors, they are not strictly equal:
>>
>>   >  duplicated(x)
>>   [1] FALSE FALSE FALSE FALSE
>>   >  unique(x)
>>   [1] 3.666667 3.666667 3.666667 3.666667
>>
>> but they are nearly equal:
>>
>>   >  all.equal(x, rep(11/3, 4))
>>   [1] TRUE
>>
>> Now factor(), and therefore table() (which seems to be using factor()
>> internally), have a different opinion:
>>
>>   >  factor(x)
>>   [1] 3.66666666666667 3.66666666666667 3.66666666666666 3.66666666666667
>>   Levels: 3.66666666666666 3.66666666666667
>>
>>   >  table(x)
>>   x
>>   3.66666666666666 3.66666666666667
>>                  1                3
>>
>> So factor() doesn't seem to be using "strict equality" or "near
>> equality" to determine the levels. What does it use? Sorry if I
>> missed it but I couldn't find any information about this in its
>> man page.
>>
>> Wouldn't it be better if factor() was consistent with either
>> duplicated() or all.equal() instead of introducing its own way
>> of comparing doubles that lies somewhere in between?
>>
>> Cheers,
>> H.
>>
>>> sessionInfo()
>> R version 2.12.0 (2010-10-15)
>> Platform: x86_64-unknown-linux-gnu (64-bit)
>>
>> locale:
>> [1] LC_CTYPE=en_US.utf8       LC_NUMERIC=C
>> [3] LC_TIME=en_US.utf8        LC_COLLATE=en_US.utf8
>> [5] LC_MONETARY=C             LC_MESSAGES=en_US.utf8
>> [7] LC_PAPER=en_US.utf8       LC_NAME=C
>> [9] LC_ADDRESS=C              LC_TELEPHONE=C
>> [11] LC_MEASUREMENT=en_US.utf8 LC_IDENTIFICATION=C
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> loaded via a namespace (and not attached):
>> [1] tools_2.12.0
>>
>> --
>> Herv? Pag?s
>>
>> Program in Computational Biology
>> Division of Public Health Sciences
>> Fred Hutchinson Cancer Research Center
>> 1100 Fairview Ave. N, M2-B876
>> P.O. Box 19024
>> Seattle, WA 98109-1024
>>
>> E-mail: hpages at fhcrc.org
>> Phone:  (206) 667-5791
>> Fax:    (206) 667-1319
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>


-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M2-B876
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fhcrc.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From maechler at stat.math.ethz.ch  Wed Feb 23 21:20:44 2011
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 23 Feb 2011 21:20:44 +0100
Subject: [Rd] request for patch in  "drop1" (add.R)
In-Reply-To: <4D65164D.7080707@mcmaster.ca>
References: <4D65164D.7080707@mcmaster.ca>
Message-ID: <19813.27676.462859.988544@stat.math.ethz.ch>

>>>>> Ben Bolker <bbolker at gmail.com>
>>>>>     on Wed, 23 Feb 2011 09:14:37 -0500 writes:

    >   By changing three lines in drop1 from access based on $
    > to access based on standard accessor methods (terms() and
    > residuals()), it becomes *much* easier to extend drop1 to
    > work with other model types.  The use of $ rather than
    > accessors in this context seems to be an oversight rather
    > than a design decision, but maybe someone knows better ...

    >   In particular, if one makes these changes (which I am
    > pretty certain will not break anything, as the original
    > code basically mimicked the default methods anyway), it
    > becomes possible to make drop1() work with mer objects
    > (Doug Bates's new mixed model code) merely by defining:

    > terms.mer <- function(x, ...) {
    > attr(x at frame,"terms")
    > }

    > extractAIC.default <- function(fit, scale=0, k=2, ...) {
    > L <- logLik(fit)
    > edf <- attr(L,"df")
    > c(edf,-2*L+2*edf)
    > }

    > Adding this definition of extractAIC.default also makes drop1() work
    > with lme fits ...

    > Comments?  Should I submit to the bug database as "enhancement
    > request"?  Are there any hidden downsides to this?

drawback: a possible very small performance cut for the cases
where the "$" access is ok.  But that should not count.

I like the idea.... {it's a pity that only S3 methods work that way,
because residuals(), terms(), etc... are unfortunately not
general (implicit) S4 generics but just S3 ones..

I'm currently testing your change, plus some more in step().
However, for step() to work automagically there is more needed.
It currently relies in more places on 'object' being a list to
which you can append new components, basically by
   fit <- object
   fit$new1 <- ...
   fit$new2 <- ...

That would have to be changed to something like
   fit <- list(obj = object)
   fit$new1 <- ...
   fit$new2 <- ...
and more changes where 'fit' has to be replaced by 'fit$obj'.
Would that not be of interest as well?

Martin


    > Ben Bolker

    > ----------------------------------------------------------------------
    > Index: add.R
    > ===================================================================
    > --- add.R	(revision 54562)
    > +++ add.R	(working copy)
    > @@ -330,7 +330,7 @@
    > drop1.default <- function(object, scope, scale = 0, test=c("none", "Chisq"),
    > k = 2, trace = FALSE, ...)
    > {
    > -    tl <- attr(object$terms, "term.labels")
    > +    tl <- attr(terms(object), "term.labels")
    > if(missing(scope)) scope <- drop.scope(object)
    > else {
    > if(!is.character(scope))
    > @@ -344,7 +344,7 @@
    > ans <- matrix(nrow = ns + 1L, ncol = 2L,
    > dimnames =  list(c("<none>", scope), c("df", "AIC")))
    > ans[1, ] <- extractAIC(object, scale, k = k, ...)
    > -    n0 <- length(object$residuals)
    > +    n0 <- length(residuals(object))
    > env <- environment(formula(object))
    > for(i in seq(ns)) {
    > tt <- scope[i]
    > @@ -356,7 +356,7 @@
    > evaluate = FALSE)
    > nfit <- eval(nfit, envir=env) # was  eval.parent(nfit)
    > ans[i+1, ] <- extractAIC(nfit, scale, k = k, ...)
    > -        if(length(nfit$residuals) != n0)
    > +        if(length(residuals(nfit)) != n0)
    > stop("number of rows in use has changed: remove missing values?")
    > }
    > dfs <- ans[1L , 1L] - ans[, 1L]

    > ----------------------------------------------------------------------
    > ______________________________________________
    > R-devel at r-project.org mailing list
    > https://stat.ethz.ch/mailman/listinfo/r-devel


From bbolker at gmail.com  Wed Feb 23 21:38:52 2011
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 23 Feb 2011 15:38:52 -0500
Subject: [Rd] request for patch in  "drop1" (add.R)
In-Reply-To: <19813.27676.462859.988544@stat.math.ethz.ch>
References: <4D65164D.7080707@mcmaster.ca>
	<19813.27676.462859.988544@stat.math.ethz.ch>
Message-ID: <4D65705C.90408@gmail.com>

On 11-02-23 03:20 PM, Martin Maechler wrote:
>>>>>> Ben Bolker <bbolker at gmail.com>
>>>>>>     on Wed, 23 Feb 2011 09:14:37 -0500 writes:
> 
>     >   By changing three lines in drop1 from access based on $
>     > to access based on standard accessor methods (terms() and
>     > residuals()), it becomes *much* easier to extend drop1 to
>     > work with other model types.  The use of $ rather than
>     > accessors in this context seems to be an oversight rather
>     > than a design decision, but maybe someone knows better ...
> 
>     >   In particular, if one makes these changes (which I am
>     > pretty certain will not break anything, as the original
>     > code basically mimicked the default methods anyway), it
>     > becomes possible to make drop1() work with mer objects
>     > (Doug Bates's new mixed model code) merely by defining:
> 
>     > terms.mer <- function(x, ...) {
>     > attr(x at frame,"terms")
>     > }
> 
>     > extractAIC.default <- function(fit, scale=0, k=2, ...) {
>     > L <- logLik(fit)
>     > edf <- attr(L,"df")
>     > c(edf,-2*L+2*edf)
>     > }
> 
>     > Adding this definition of extractAIC.default also makes drop1() work
>     > with lme fits ...
> 
>     > Comments?  Should I submit to the bug database as "enhancement
>     > request"?  Are there any hidden downsides to this?
> 
> drawback: a possible very small performance cut for the cases
> where the "$" access is ok.  But that should not count.
> 
> I like the idea.... {it's a pity that only S3 methods work that way,
> because residuals(), terms(), etc... are unfortunately not
> general (implicit) S4 generics but just S3 ones..
> 
> I'm currently testing your change, plus some more in step().
> However, for step() to work automagically there is more needed.
> It currently relies in more places on 'object' being a list to
> which you can append new components, basically by
>    fit <- object
>    fit$new1 <- ...
>    fit$new2 <- ...
> 
> That would have to be changed to something like
>    fit <- list(obj = object)
>    fit$new1 <- ...
>    fit$new2 <- ...
> and more changes where 'fit' has to be replaced by 'fit$obj'.
> Would that not be of interest as well?
> 
> Martin

  Potentially, but I am personally much more interested in enabling
drop1(), which seems to be a much more legitimate tool for testing terms
in models than step(), which is so easy to abuse ...

    Ben Bolker


From pdalgd at gmail.com  Wed Feb 23 22:54:59 2011
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 23 Feb 2011 22:54:59 +0100
Subject: [Rd] request for patch in  "drop1" (add.R)
In-Reply-To: <4D65705C.90408@gmail.com>
References: <4D65164D.7080707@mcmaster.ca>
	<19813.27676.462859.988544@stat.math.ethz.ch>
	<4D65705C.90408@gmail.com>
Message-ID: <0A73F01A-9C56-4AD3-8AD3-99DE70D0C645@gmail.com>


On Feb 23, 2011, at 21:38 , Ben Bolker wrote:

> 
>  Potentially, but I am personally much more interested in enabling
> drop1(), which seems to be a much more legitimate tool for testing terms
> in models than step(), which is so easy to abuse ...

Yes, although repeated use of drop1() easily leads to backwards elimination.... 

However, I have a different point: To make drop1() a better generic, I suspect that something needs to be done about the test = c("none", "Chisq") bit. It would be nice if the list of possible tests could vary according to model type, e.g. by doing all tests via anova(model1,model2,...). I'm not quite up to figuring out how complicated that would be.

-- 
Peter Dalgaard
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From b.rowlingson at lancaster.ac.uk  Wed Feb 23 23:23:58 2011
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Wed, 23 Feb 2011 22:23:58 +0000
Subject: [Rd] Easily switchable factor levels
Message-ID: <AANLkTik1qHoFRKXk2ns9qVD0mcUeLqoW1f9uGpACbDTj@mail.gmail.com>

I've recently been working with some California county-level data. The
counties can be referred to as either FIPS codes, eg F060102, friendly
names such as "Del Norte County", names without 'County' on the end,
names with 'CA' on the end ("Del Norte County, CA"). Different data
sets use slightly different forms and putting them all together is a
pain.

 So I was wondering about ways to attach multiple sets of level codes
to a factor. It would work something like this:

 > foo=multifactor(sample(letters,5),levels=letters,levelname="lower")
 > foo
 [1] m u i z b
 Levels: a b c d ... y z
 > levels(foo,"upper") = LETTERS
 > uselevels(foo,"upper")
 > foo
 [1] M U I Z B
  Levels: A B C D E F....Z
 > uselevels(foo,"lower")
 > foo
 [1] m u i z b
  Levels: a b c d ....z

In this way you could easily switch your levels from M and F to Male
and Female, or Hommes et Dames, without having to do levels(foo) =
something and hope to get the ordering right every time. Just do it
once, keep the multiple sets of level lables in the object.

I'd even throw in a function to print out all the level codes:

 > levels(foo,all=TRUE)
   upper  lower
[1] A  a
[2] B  b

etc

I can see assorted problems coding this up to cope with dropping
levels when making subsets... and possibly problems when code does
character matching of levels and expects them to be unchanged...

Has anyone bothered to write anything like this yet? Or is the
application a bit too rare to be worth it?

Barry


From ripley at stats.ox.ac.uk  Thu Feb 24 00:12:09 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 23 Feb 2011 23:12:09 +0000
Subject: [Rd] request for patch in  "drop1" (add.R)
In-Reply-To: <19813.27676.462859.988544@stat.math.ethz.ch>
References: <4D65164D.7080707@mcmaster.ca>
	<19813.27676.462859.988544@stat.math.ethz.ch>
Message-ID: <alpine.OSX.1.00.1102232201590.12718@tystie.local>

residuals() and $residuals are often very different:  residuals() is 
generic, but even the default method is *not* simple extraction. Their 
values can be of different lengths: think about an lm fit with 
na.action = na.exclude.  That is precisely the sort of thing the tests 
in add.R were designed to detect, hence the use of $residuals.

None of this is used in drop1()!  One of the places $residuals was 
used in that file was the default method for drop1(), others being 
step() and the default method for add1().  As default methods these 
have to continue to work for any class of object that has previously 
been thrown at them over the last 10+ years, and even all CRAN 
packages will not be a good enough test suite.

In any case, the current code in R-devel makes use of the new generic 
nobs(), which is intended to help sort out the many versions of 
functions called 'BIC" in packages, but is also useful here.  (It is 
still under development.)

terms() is also generic so there is also some danger that its 
substitution could give an inappropriate result.  But as it used in 
several other places in add.R the breakage will probably occur 
elsewhere already.

On Wed, 23 Feb 2011, Martin Maechler wrote:

>>>>>> Ben Bolker <bbolker at gmail.com>
>>>>>>     on Wed, 23 Feb 2011 09:14:37 -0500 writes:
>
>    >   By changing three lines in drop1 from access based on $
>    > to access based on standard accessor methods (terms() and
>    > residuals()), it becomes *much* easier to extend drop1 to
>    > work with other model types.  The use of $ rather than
>    > accessors in this context seems to be an oversight rather
>    > than a design decision, but maybe someone knows better ...
>
>    >   In particular, if one makes these changes (which I am
>    > pretty certain will not break anything, as the original
>    > code basically mimicked the default methods anyway), it
>    > becomes possible to make drop1() work with mer objects
>    > (Doug Bates's new mixed model code) merely by defining:
>
>    > terms.mer <- function(x, ...) {
>    > attr(x at frame,"terms")
>    > }
>
>    > extractAIC.default <- function(fit, scale=0, k=2, ...) {
>    > L <- logLik(fit)
>    > edf <- attr(L,"df")
>    > c(edf,-2*L+2*edf)
>    > }
>
>    > Adding this definition of extractAIC.default also makes drop1() work
>    > with lme fits ...
>
>    > Comments?  Should I submit to the bug database as "enhancement
>    > request"?  Are there any hidden downsides to this?
>
> drawback: a possible very small performance cut for the cases
> where the "$" access is ok.  But that should not count.
>
> I like the idea.... {it's a pity that only S3 methods work that way,
> because residuals(), terms(), etc... are unfortunately not
> general (implicit) S4 generics but just S3 ones..
>
> I'm currently testing your change, plus some more in step().
> However, for step() to work automagically there is more needed.
> It currently relies in more places on 'object' being a list to
> which you can append new components, basically by
>   fit <- object
>   fit$new1 <- ...
>   fit$new2 <- ...
>
> That would have to be changed to something like
>   fit <- list(obj = object)
>   fit$new1 <- ...
>   fit$new2 <- ...
> and more changes where 'fit' has to be replaced by 'fit$obj'.
> Would that not be of interest as well?
>
> Martin
>
>
>    > Ben Bolker
>
>    > ----------------------------------------------------------------------
>    > Index: add.R
>    > ===================================================================
>    > --- add.R	(revision 54562)
>    > +++ add.R	(working copy)
>    > @@ -330,7 +330,7 @@
>    > drop1.default <- function(object, scope, scale = 0, test=c("none", "Chisq"),
>    > k = 2, trace = FALSE, ...)
>    > {
>    > -    tl <- attr(object$terms, "term.labels")
>    > +    tl <- attr(terms(object), "term.labels")
>    > if(missing(scope)) scope <- drop.scope(object)
>    > else {
>    > if(!is.character(scope))
>    > @@ -344,7 +344,7 @@
>    > ans <- matrix(nrow = ns + 1L, ncol = 2L,
>    > dimnames =  list(c("<none>", scope), c("df", "AIC")))
>    > ans[1, ] <- extractAIC(object, scale, k = k, ...)
>    > -    n0 <- length(object$residuals)
>    > +    n0 <- length(residuals(object))
>    > env <- environment(formula(object))
>    > for(i in seq(ns)) {
>    > tt <- scope[i]
>    > @@ -356,7 +356,7 @@
>    > evaluate = FALSE)
>    > nfit <- eval(nfit, envir=env) # was  eval.parent(nfit)
>    > ans[i+1, ] <- extractAIC(nfit, scale, k = k, ...)
>    > -        if(length(nfit$residuals) != n0)
>    > +        if(length(residuals(nfit)) != n0)
>    > stop("number of rows in use has changed: remove missing values?")
>    > }
>    > dfs <- ans[1L , 1L] - ans[, 1L]
>
>    > ----------------------------------------------------------------------
>    > ______________________________________________
>    > R-devel at r-project.org mailing list
>    > https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From osoong+r at gmail.com  Thu Feb 24 00:21:45 2011
From: osoong+r at gmail.com (Oliver Soong)
Date: Wed, 23 Feb 2011 15:21:45 -0800
Subject: [Rd] system(wait = FALSE)
Message-ID: <AANLkTin7u18yiwLo9yiO0v97n=FJHOsFXUuOrzKH0Hqj@mail.gmail.com>

I'm having a very odd problem with system(wait = FALSE).  I'm not
entirely sure whether it's a bug in R or a problem on our end.  It's
related to a post a month or so ago in R-help which got no responses,
but I have a little more to add.

This command works as expected (I use c:\tmp since c:\ isn't normally
writable under later versions of Windows).  The file is created at
c:\tmp\tmp.txt.
system("cmd /c dir > c:\\tmp\\tmp.txt", wait = TRUE)
This command does not work as expected.  There is no file created at
c:\tmp\tmp.txt.
system("cmd /c dir > c:\\tmp\\tmp.txt", wait = FALSE)

The computer is a 64-bit Windows Server 2008R2 machine.  This affects
R 2.12.1, both the 32-bit and 64-bit RGui executables but not the
RTerm executables.  This does not affect 32-bit Windows XP, 32-bit
Windows Server 2003, or 64-bit Windows Server 2008.  This does not
affect R 2.12.0, and if I'm reading the svn logs correctly, there were
some changes made to the system function from 2.12.0 to 2.12.1.
Things seem to work normally when R is started from the start menu
recent programs list, but things do not work properly when R is
started from a shortcut, from the start menu all programs menu, or
through explorer.

I'm stumped.  Any ideas I can try?

Oliver


From tuechler at gmx.at  Thu Feb 24 01:18:43 2011
From: tuechler at gmx.at (Heinz Tuechler)
Date: Thu, 24 Feb 2011 01:18:43 +0100
Subject: [Rd] Easily switchable factor levels
In-Reply-To: <AANLkTik1qHoFRKXk2ns9qVD0mcUeLqoW1f9uGpACbDTj@mail.gmail.c
 om>
References: <AANLkTik1qHoFRKXk2ns9qVD0mcUeLqoW1f9uGpACbDTj@mail.gmail.com>
Message-ID: <201102240017.p1O0HcKF017007@hypatia.math.ethz.ch>

To me this is a common situation, especially to switch between two 
languages. I solve it by separating the coding of values and their 
labels. Values are coded numerically or as character, and their 
labels are attached by a value.label attribute. When needed a 
modified factor function transforms these variable into a factor 
using the value.labels as labels for the factor.
It's, however, no nice code and a drawback is that the value.label 
attribute has to be copied on subsetting.

best regards,

Heinz

At 23.02.2011 22:23 +0000, Barry Rowlingson wrote:
>I've recently been working with some California county-level data. The
>counties can be referred to as either FIPS codes, eg F060102, friendly
>names such as "Del Norte County", names without 'County' on the end,
>names with 'CA' on the end ("Del Norte County, CA"). Different data
>sets use slightly different forms and putting them all together is a
>pain.
>
>  So I was wondering about ways to attach multiple sets of level codes
>to a factor. It would work something like this:
>
>  > foo=multifactor(sample(letters,5),levels=letters,levelname="lower")
>  > foo
>  [1] m u i z b
>  Levels: a b c d ... y z
>  > levels(foo,"upper") = LETTERS
>  > uselevels(foo,"upper")
>  > foo
>  [1] M U I Z B
>   Levels: A B C D E F....Z
>  > uselevels(foo,"lower")
>  > foo
>  [1] m u i z b
>   Levels: a b c d ....z
>
>In this way you could easily switch your levels from M and F to Male
>and Female, or Hommes et Dames, without having to do levels(foo) =
>something and hope to get the ordering right every time. Just do it
>once, keep the multiple sets of level lables in the object.
>
>I'd even throw in a function to print out all the level codes:
>
>  > levels(foo,all=TRUE)
>    upper  lower
>[1] A  a
>[2] B  b
>
>etc
>
>I can see assorted problems coding this up to cope with dropping
>levels when making subsets... and possibly problems when code does
>character matching of levels and expects them to be unchanged...
>
>Has anyone bothered to write anything like this yet? Or is the
>application a bit too rare to be worth it?
>
>Barry
>
>______________________________________________
>R-devel at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-devel


From bbolker at gmail.com  Thu Feb 24 01:36:43 2011
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 23 Feb 2011 19:36:43 -0500
Subject: [Rd] request for patch in  "drop1" (add.R)
In-Reply-To: <alpine.OSX.1.00.1102232201590.12718@tystie.local>
References: <4D65164D.7080707@mcmaster.ca>
	<19813.27676.462859.988544@stat.math.ethz.ch>
	<alpine.OSX.1.00.1102232201590.12718@tystie.local>
Message-ID: <4D65A81B.3080606@gmail.com>

On 11-02-23 06:12 PM, Prof Brian Ripley wrote:
> residuals() and $residuals are often very different:  residuals() is
> generic, but even the default method is *not* simple extraction. Their
> values can be of different lengths: think about an lm fit with na.action
> = na.exclude.  That is precisely the sort of thing the tests in add.R
> were designed to detect, hence the use of $residuals.
> 
> None of this is used in drop1()!  One of the places $residuals was used
> in that file was the default method for drop1(), others being step() and
> the default method for add1().  As default methods these have to
> continue to work for any class of object that has previously been thrown
> at them over the last 10+ years, and even all CRAN packages will not be
> a good enough test suite.
> 
> In any case, the current code in R-devel makes use of the new generic
> nobs(), which is intended to help sort out the many versions of
> functions called 'BIC" in packages, but is also useful here.  (It is
> still under development.)
> 
> terms() is also generic so there is also some danger that its
> substitution could give an inappropriate result.  But as it used in
> several other places in add.R the breakage will probably occur elsewhere
> already.

  Thanks Prof. Ripley.
  (I will say that, while I understand why residuals(x) and x$residuals
could be different, I am happy that a more transparent form of coding is
being introduced ...)
> 
> On Wed, 23 Feb 2011, Martin Maechler wrote:
> 
>>>>>>> Ben Bolker <bbolker at gmail.com>
>>>>>>>     on Wed, 23 Feb 2011 09:14:37 -0500 writes:
>>
>>    >   By changing three lines in drop1 from access based on $
>>    > to access based on standard accessor methods (terms() and
>>    > residuals()), it becomes *much* easier to extend drop1 to
>>    > work with other model types.  The use of $ rather than
>>    > accessors in this context seems to be an oversight rather
>>    > than a design decision, but maybe someone knows better ...
>>
>>    >   In particular, if one makes these changes (which I am
>>    > pretty certain will not break anything, as the original
>>    > code basically mimicked the default methods anyway), it
>>    > becomes possible to make drop1() work with mer objects
>>    > (Doug Bates's new mixed model code) merely by defining:
>>
>>    > terms.mer <- function(x, ...) {
>>    > attr(x at frame,"terms")
>>    > }
>>
>>    > extractAIC.default <- function(fit, scale=0, k=2, ...) {
>>    > L <- logLik(fit)
>>    > edf <- attr(L,"df")
>>    > c(edf,-2*L+2*edf)
>>    > }
>>
>>    > Adding this definition of extractAIC.default also makes drop1() work
>>    > with lme fits ...
>>
>>    > Comments?  Should I submit to the bug database as "enhancement
>>    > request"?  Are there any hidden downsides to this?
>>
>> drawback: a possible very small performance cut for the cases
>> where the "$" access is ok.  But that should not count.
>>
>> I like the idea.... {it's a pity that only S3 methods work that way,
>> because residuals(), terms(), etc... are unfortunately not
>> general (implicit) S4 generics but just S3 ones..
>>
>> I'm currently testing your change, plus some more in step().
>> However, for step() to work automagically there is more needed.
>> It currently relies in more places on 'object' being a list to
>> which you can append new components, basically by
>>   fit <- object
>>   fit$new1 <- ...
>>   fit$new2 <- ...
>>
>> That would have to be changed to something like
>>   fit <- list(obj = object)
>>   fit$new1 <- ...
>>   fit$new2 <- ...
>> and more changes where 'fit' has to be replaced by 'fit$obj'.
>> Would that not be of interest as well?
>>
>> Martin
>>
>>
>>    > Ben Bolker
>>
>>    >
>> ----------------------------------------------------------------------
>>    > Index: add.R
>>    > ===================================================================
>>    > --- add.R    (revision 54562)
>>    > +++ add.R    (working copy)
>>    > @@ -330,7 +330,7 @@
>>    > drop1.default <- function(object, scope, scale = 0,
>> test=c("none", "Chisq"),
>>    > k = 2, trace = FALSE, ...)
>>    > {
>>    > -    tl <- attr(object$terms, "term.labels")
>>    > +    tl <- attr(terms(object), "term.labels")
>>    > if(missing(scope)) scope <- drop.scope(object)
>>    > else {
>>    > if(!is.character(scope))
>>    > @@ -344,7 +344,7 @@
>>    > ans <- matrix(nrow = ns + 1L, ncol = 2L,
>>    > dimnames =  list(c("<none>", scope), c("df", "AIC")))
>>    > ans[1, ] <- extractAIC(object, scale, k = k, ...)
>>    > -    n0 <- length(object$residuals)
>>    > +    n0 <- length(residuals(object))
>>    > env <- environment(formula(object))
>>    > for(i in seq(ns)) {
>>    > tt <- scope[i]
>>    > @@ -356,7 +356,7 @@
>>    > evaluate = FALSE)
>>    > nfit <- eval(nfit, envir=env) # was  eval.parent(nfit)
>>    > ans[i+1, ] <- extractAIC(nfit, scale, k = k, ...)
>>    > -        if(length(nfit$residuals) != n0)
>>    > +        if(length(residuals(nfit)) != n0)
>>    > stop("number of rows in use has changed: remove missing values?")
>>    > }
>>    > dfs <- ans[1L , 1L] - ans[, 1L]
>>
>>    >
>> ----------------------------------------------------------------------
>>    > ______________________________________________
>>    > R-devel at r-project.org mailing list
>>    > https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>


From hpages at fhcrc.org  Thu Feb 24 02:01:19 2011
From: hpages at fhcrc.org (=?windows-1252?Q?Herv=E9_Pag=E8s?=)
Date: Wed, 23 Feb 2011 17:01:19 -0800
Subject: [Rd] min/max of a vector with NAs and NaNs
Message-ID: <4D65ADDF.20700@fhcrc.org>

I get this (with R-2.12 and R-2.13, didn't try with earlier versions):

 > max(c(NaN, NA))
[1] NA
 > max(c(NA, NaN))
[1] NaN

I get the same thing with min().

The fact that the result of 'max(x)' or 'min(x)' depends on the order
of the elements in 'x' is surprising. It also seems to contradict the
man page:

      By definition the min/max of a numeric vector containing an ?NaN?
      is ?NaN?, except that the min/max of any vector containing an ?NA?
      is ?NA? even if it also contains an ?NaN?.

Cheers,
H.

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M2-B876
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fhcrc.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From ripley at stats.ox.ac.uk  Thu Feb 24 08:07:40 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 24 Feb 2011 07:07:40 +0000 (GMT)
Subject: [Rd] system(wait = FALSE)
In-Reply-To: <AANLkTin7u18yiwLo9yiO0v97n=FJHOsFXUuOrzKH0Hqj@mail.gmail.com>
References: <AANLkTin7u18yiwLo9yiO0v97n=FJHOsFXUuOrzKH0Hqj@mail.gmail.com>
Message-ID: <alpine.LFD.2.02.1102240658290.27094@gannet.stats.ox.ac.uk>

On Wed, 23 Feb 2011, Oliver Soong wrote:

> I'm having a very odd problem with system(wait = FALSE).  I'm not
> entirely sure whether it's a bug in R or a problem on our end.  It's
> related to a post a month or so ago in R-help which got no responses,
> but I have a little more to add.

Well, the place you are asked to report issues on the Windows port is 
R-windows at r-project.org.   But no one was able to reproduce this, and 
it does sound as if the problem is on your specific machine.  If so, 
only you can debug it and find out if it is really in R.

> This command works as expected (I use c:\tmp since c:\ isn't normally
> writable under later versions of Windows).

That's a bold claim (and untrue of my Windows 7 systems), but if c:\ 
is not writeable, you cannot create c:\tmp!

>  The file is created at
> c:\tmp\tmp.txt.
> system("cmd /c dir > c:\\tmp\\tmp.txt", wait = TRUE)
> This command does not work as expected.  There is no file created at
> c:\tmp\tmp.txt.
> system("cmd /c dir > c:\\tmp\\tmp.txt", wait = FALSE)

Windows' own programs are peculiar things, and often do not obey 
Windows' own rules for everyone else.  So I give little weight to such 
an example.  And in any case, we recommend shell() for such usages.

> The computer is a 64-bit Windows Server 2008R2 machine.  This affects
> R 2.12.1, both the 32-bit and 64-bit RGui executables but not the
> RTerm executables.  This does not affect 32-bit Windows XP, 32-bit
> Windows Server 2003, or 64-bit Windows Server 2008.  This does not
> affect R 2.12.0, and if I'm reading the svn logs correctly, there were
> some changes made to the system function from 2.12.0 to 2.12.1.
> Things seem to work normally when R is started from the start menu
> recent programs list, but things do not work properly when R is
> started from a shortcut, from the start menu all programs menu, or
> through explorer.
>
> I'm stumped.  Any ideas I can try?
>
> Oliver
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From maechler at stat.math.ethz.ch  Thu Feb 24 09:36:22 2011
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 24 Feb 2011 09:36:22 +0100
Subject: [Rd] request for patch in  "drop1" (add.R)
In-Reply-To: <4D65A81B.3080606@gmail.com>
References: <4D65164D.7080707@mcmaster.ca>
	<19813.27676.462859.988544@stat.math.ethz.ch>
	<alpine.OSX.1.00.1102232201590.12718@tystie.local>
	<4D65A81B.3080606@gmail.com>
Message-ID: <19814.6278.447626.365595@stat.math.ethz.ch>

>>>>> Ben Bolker <bbolker at gmail.com>
>>>>>     on Wed, 23 Feb 2011 19:36:43 -0500 writes:

    > On 11-02-23 06:12 PM, Prof Brian Ripley wrote:
    >> residuals() and $residuals are often very different:
    >> residuals() is generic, but even the default method is *not*
    >> simple extraction. Their values can be of different lengths:
    >> think about an lm fit with na.action = na.exclude.  That is
    >> precisely the sort of thing the tests in add.R were designed to
    >> detect, hence the use of $residuals.
    >> 
    >> None of this is used in drop1()!  One of the places $residuals
    >> was used in that file was the default method for drop1(),
    >> others being step() and the default method for add1().  As
    >> default methods these have to continue to work for any class of
    >> object that has previously been thrown at them over the last
    >> 10+ years, and even all CRAN packages will not be a good enough
    >> test suite.
    >> 
    >> In any case, the current code in R-devel makes use of the new
    >> generic nobs(), which is intended to help sort out the many
    >> versions of functions called 'BIC" in packages, but is also
    >> useful here.  (It is still under development.)
    >> 
    >> terms() is also generic so there is also some danger that its
    >> substitution could give an inappropriate result.  But as it
    >> used in several other places in add.R the breakage will
    >> probably occur elsewhere already.

:-) yes.  I think it is very good change to have drop1.default() and
other R functions that do "generic" model analysis work
via calls to simpler generic functions such as residuals(), or
the new  nobs() .  Thanks for introducing that, a really good
idea I think (and along which I think I was also musing when I
last looked at the BIC() implementations..).
I'm glad you've started to clean this up nicely.

    > Thanks Prof. Ripley.  (I will say that, while I understand why
    > residuals(x) and x$residuals could be different, I am happy that
    > a more transparent form of coding is being introduced ...)

(indeed, see above).
Advertising the use of nobs(), i.e. asking package authors to
write nobs() methods for their models will be probably worth
doing, as soon as 2.13.0 hits the roads..

Martin


    >> On Wed, 23 Feb 2011, Martin Maechler wrote:
    >> 
    >>>>>>>> Ben Bolker <bbolker at gmail.com>
    >>>>>>>> on Wed, 23 Feb 2011 09:14:37 -0500 writes:
    >>> 
    >>> >   By changing three lines in drop1 from access based on $
    >>> > to access based on standard accessor methods (terms() and
    >>> > residuals()), it becomes *much* easier to extend drop1 to
    >>> > work with other model types.  The use of $ rather than
    >>> > accessors in this context seems to be an oversight rather
    >>> > than a design decision, but maybe someone knows better ...
    >>> 
    >>> >   In particular, if one makes these changes (which I am
    >>> > pretty certain will not break anything, as the original
    >>> > code basically mimicked the default methods anyway), it
    >>> > becomes possible to make drop1() work with mer objects
    >>> > (Doug Bates's new mixed model code) merely by defining:
    >>> 
    >>> > terms.mer <- function(x, ...) {
    >>> > attr(x at frame,"terms")
    >>> > }
    >>> 
    >>> > extractAIC.default <- function(fit, scale=0, k=2, ...) {
    >>> > L <- logLik(fit)
    >>> > edf <- attr(L,"df")
    >>> > c(edf,-2*L+2*edf)
    >>> > }
    >>> 
    >>> > Adding this definition of extractAIC.default also makes
    >>> > drop1() work with lme fits ...
    >>> 
    >>> > Comments?  Should I submit to the bug database as
    >>> > "enhancement request"?  Are there any hidden downsides to
    >>> > this?
    >>> 
    >>> drawback: a possible very small performance cut for the cases
    >>> where the "$" access is ok.  But that should not count.
    >>> 
    >>> I like the idea.... {it's a pity that only S3 methods work
    >>> that way, because residuals(), terms(), etc... are
    >>> unfortunately not general (implicit) S4 generics but just S3
    >>> ones..
    >>> 
    >>> I'm currently testing your change, plus some more in step().
    >>> However, for step() to work automagically there is more
    >>> needed.  It currently relies in more places on 'object' being
    >>> a list to which you can append new components, basically by
    >>> fit <- object fit$new1 <- ...  fit$new2 <- ...
    >>> 
    >>> That would have to be changed to something like fit <-
    >>> list(obj = object) fit$new1 <- ...  fit$new2 <- ...  and more
    >>> changes where 'fit' has to be replaced by 'fit$obj'.  Would
    >>> that not be of interest as well?
    >>> 
    >>> Martin
    >>> 
    >>> 
    >>> > Ben Bolker
    >>> 
    >>> >
    >>> ----------------------------------------------------------------------
    >>> > Index: add.R
    >>> > ===================================================================
    >>> > --- add.R (revision 54562) +++ add.R (working copy) @@
    >>> > -330,7 +330,7 @@ drop1.default <- function(object, scope,
    >>> > scale = 0,
    >>> test=c("none", "Chisq"),
    >>> > k = 2, trace = FALSE, ...)  { - tl <- attr(object$terms,
    >>> > "term.labels") + tl <- attr(terms(object), "term.labels")
    >>> > if(missing(scope)) scope <- drop.scope(object) else {
    >>> > if(!is.character(scope)) @@ -344,7 +344,7 @@ ans <-
    >>> > matrix(nrow = ns + 1L, ncol = 2L, dimnames =
    >>> > list(c("<none>", scope), c("df", "AIC"))) ans[1, ] <-
    >>> > extractAIC(object, scale, k = k, ...)  - n0 <-
    >>> > length(object$residuals) + n0 <- length(residuals(object))
    >>> > env <- environment(formula(object)) for(i in seq(ns)) { tt
    >>> > <- scope[i] @@ -356,7 +356,7 @@ evaluate = FALSE) nfit <-
    >>> > eval(nfit, envir=env) # was eval.parent(nfit) ans[i+1, ] <-
    >>> > extractAIC(nfit, scale, k = k, ...)  -
    >>> > if(length(nfit$residuals) != n0) +
    >>> > if(length(residuals(nfit)) != n0) stop("number of rows in
    >>> > use has changed: remove missing values?")  } dfs <- ans[1L ,
    >>> > 1L] - ans[, 1L]
    >>> 
    >>> >
    >>> ----------------------------------------------------------------------
    >>> > ______________________________________________
    >>> > R-devel at r-project.org mailing list
    >>> > https://stat.ethz.ch/mailman/listinfo/r-devel
    >>> 
    >>> ______________________________________________
    >>> R-devel at r-project.org mailing list
    >>> https://stat.ethz.ch/mailman/listinfo/r-devel
    >>> 
    >> 

    > ______________________________________________
    > R-devel at r-project.org mailing list
    > https://stat.ethz.ch/mailman/listinfo/r-devel


From thomas at themel.com  Thu Feb 24 10:15:21 2011
From: thomas at themel.com (Thomas Themel)
Date: Thu, 24 Feb 2011 10:15:21 +0100
Subject: [Rd] Rd, S4 classes and PDFs
Message-ID: <1298531726-sup-6499@eristoteles.iwoars.net>

Hi,

I'm documenting a package that makes heavy use of S4 methods at the moment, and
I'm having a hard time from keeping the PDF output of Rd from looking really
terrible.

First of all, what is the preferred way to actually document S4 methods? When I
use promptClass/promptMethod, I get a style that doesn't use the \S4method
macro and puts the entire function signature into a \item.

The generated PDFs look terrible because there is no way to get line breaks
into these \item titles (?) and so a lot of lines just overflow the page.

Manually writing the docs and using \S4method is a noticeable improvement since it

a) separates the types of the arguments into an extra line and 
b) allows line breaks in the argument list

Typographic issues aside, I like that R CMD check will actually make sure that
all the parameters are documented etc.

However, there are still some overflows for methods with many parameters, my
worst offender currently being

\S4method{readWorksheet}{workbook,numeric,numeric,numeric,numeric,numeric,logical}(object,sheet,startRow,startCol,endRow,endCol,header)

where just the type signature alone is too long. I tried various ways of
introducing line breaks in the type signature, but they all seem to fail (\cr,
\, raw line breaks, double raw line breaks), is there anything that can be done
about it?

Another PDF ugliness issue is the index - the S4 class documentation
conventions require a ton of alias that are not directly intended to be
human-readable, my index is cluttered with many overflowing entries of the form

readWorksheet,workbook,character,numeric,missing,missing,missing,missing-method

Is there a way to get rid of these in the PDF?

In another somewhat unpleasant interaction with these conventions, all the
sections in my PDF are titled foo-methods instead of just foo. 

I'd appreciate guidance on the issues above and maybe some pointers to some
well-documented S4 packages.

thanks,
-- 
[*Thomas  Themel*]      Oh, well.  Size isn't everything, I hear; uptime may also
[extended contact]      be important.
[info provided in]              - Arvid Gr?tting in the monastery
[*message header*]


From osoong+r at gmail.com  Thu Feb 24 20:46:34 2011
From: osoong+r at gmail.com (Oliver Soong)
Date: Thu, 24 Feb 2011 11:46:34 -0800
Subject: [Rd] system(wait = FALSE)
In-Reply-To: <alpine.LFD.2.02.1102240658290.27094@gannet.stats.ox.ac.uk>
References: <AANLkTin7u18yiwLo9yiO0v97n=FJHOsFXUuOrzKH0Hqj@mail.gmail.com>
	<alpine.LFD.2.02.1102240658290.27094@gannet.stats.ox.ac.uk>
Message-ID: <AANLkTimp+0uNi+urFztjWz0XGOVC69LZM4+G0cUF8uV1@mail.gmail.com>

Sorry, I didn't know about r-windows at r-project.org.  Is that a public
mailing list like r-help?  It's not listed under
http://www.r-project.org/mail.html.

I was able to reproduce the issue under two other 32-bit Windows 7
machines, so it's not specific to the one computer.  It could be
something common to my Windows user account configurations, although
those accounts are not all configured similarly.  The part that's the
strangest to me is that things do work when R is started through the
start menu recent programs and when called from a command shell, but
not through shortcuts or the start menu all programs list.  Sys.getenv
does not indicate any particular difference.  Are there any other
things I might check in R?

The actual command I want to run has quoting concerns (inherent to
Windows and cmd) that force me to use system.  If you don't like cmd
/c dir, this command also serves the purpose and also shows the weird
behavior.  It presumes that Rscript is on the path:
system("Rscript -e \"writeLines(letters,
\\\"C:\\\\\\\\tmp\\\\\\\\tmp.txt\\\")\"", wait = FALSE)

I've been told (and can see) that shell just calls system, and since
the equivalent command in shell shows the same behavior due to this
weirdness I'm finding with system, I decided to focus on what appeared
to be the underlying problem (although perhaps not the actual problem
if it is just something with me).

Oliver


On Wed, Feb 23, 2011 at 11:07 PM, Prof Brian Ripley
<ripley at stats.ox.ac.uk> wrote:
> On Wed, 23 Feb 2011, Oliver Soong wrote:
>
>> I'm having a very odd problem with system(wait = FALSE). ?I'm not
>> entirely sure whether it's a bug in R or a problem on our end. ?It's
>> related to a post a month or so ago in R-help which got no responses,
>> but I have a little more to add.
>
> Well, the place you are asked to report issues on the Windows port is
> R-windows at r-project.org. ? But no one was able to reproduce this, and it
> does sound as if the problem is on your specific machine. ?If so, only you
> can debug it and find out if it is really in R.
>
>> This command works as expected (I use c:\tmp since c:\ isn't normally
>> writable under later versions of Windows).
>
> That's a bold claim (and untrue of my Windows 7 systems), but if c:\ is not
> writeable, you cannot create c:\tmp!
>
>> ?The file is created at
>> c:\tmp\tmp.txt.
>> system("cmd /c dir > c:\\tmp\\tmp.txt", wait = TRUE)
>> This command does not work as expected. ?There is no file created at
>> c:\tmp\tmp.txt.
>> system("cmd /c dir > c:\\tmp\\tmp.txt", wait = FALSE)
>
> Windows' own programs are peculiar things, and often do not obey Windows'
> own rules for everyone else. ?So I give little weight to such an example.
> ?And in any case, we recommend shell() for such usages.
>
>> The computer is a 64-bit Windows Server 2008R2 machine. ?This affects
>> R 2.12.1, both the 32-bit and 64-bit RGui executables but not the
>> RTerm executables. ?This does not affect 32-bit Windows XP, 32-bit
>> Windows Server 2003, or 64-bit Windows Server 2008. ?This does not
>> affect R 2.12.0, and if I'm reading the svn logs correctly, there were
>> some changes made to the system function from 2.12.0 to 2.12.1.
>> Things seem to work normally when R is started from the start menu
>> recent programs list, but things do not work properly when R is
>> started from a shortcut, from the start menu all programs menu, or
>> through explorer.
>>
>> I'm stumped. ?Any ideas I can try?
>>
>> Oliver
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
> --
> Brian D. Ripley, ? ? ? ? ? ? ? ? ?ripley at stats.ox.ac.uk
> Professor of Applied Statistics, ?http://www.stats.ox.ac.uk/~ripley/
> University of Oxford, ? ? ? ? ? ? Tel: ?+44 1865 272861 (self)
> 1 South Parks Road, ? ? ? ? ? ? ? ? ? ? +44 1865 272866 (PA)
> Oxford OX1 3TG, UK ? ? ? ? ? ? ? ?Fax: ?+44 1865 272595
>



-- 
Oliver Soong
Donald Bren School of Environmental Science & Management
University of California, Santa Barbara
Santa Barbara, CA 93106-5131
805-893-7044 (office)
610-291-9706 (cell)


From ggrothendieck at gmail.com  Fri Feb 25 00:54:48 2011
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 24 Feb 2011 18:54:48 -0500
Subject: [Rd] system(wait = FALSE)
In-Reply-To: <AANLkTimp+0uNi+urFztjWz0XGOVC69LZM4+G0cUF8uV1@mail.gmail.com>
References: <AANLkTin7u18yiwLo9yiO0v97n=FJHOsFXUuOrzKH0Hqj@mail.gmail.com>
	<alpine.LFD.2.02.1102240658290.27094@gannet.stats.ox.ac.uk>
	<AANLkTimp+0uNi+urFztjWz0XGOVC69LZM4+G0cUF8uV1@mail.gmail.com>
Message-ID: <AANLkTikmfm0Si1en3nA=DpQh_y7jzEZxy9jcyQKbp=fj@mail.gmail.com>

On Thu, Feb 24, 2011 at 2:46 PM, Oliver Soong <osoong+r at gmail.com> wrote:
> Sorry, I didn't know about r-windows at r-project.org. ?Is that a public
> mailing list like r-help? ?It's not listed under
> http://www.r-project.org/mail.html.
>
> I was able to reproduce the issue under two other 32-bit Windows 7
> machines, so it's not specific to the one computer. ?It could be
> something common to my Windows user account configurations, although
> those accounts are not all configured similarly. ?The part that's the
> strangest to me is that things do work when R is started through the
> start menu recent programs and when called from a command shell, but
> not through shortcuts or the start menu all programs list. ?Sys.getenv
> does not indicate any particular difference. ?Are there any other
> things I might check in R?

Right click the particular start menu recent program entry that starts
it and choose properties; also right click the shortcut and choose
properties and right click the start menu programs list entry and
choose properties.  See what the differences are in the targets.





>
> The actual command I want to run has quoting concerns (inherent to
> Windows and cmd) that force me to use system. ?If you don't like cmd
> /c dir, this command also serves the purpose and also shows the weird
> behavior. ?It presumes that Rscript is on the path:
> system("Rscript -e \"writeLines(letters,
> \\\"C:\\\\\\\\tmp\\\\\\\\tmp.txt\\\")\"", wait = FALSE)
>
> I've been told (and can see) that shell just calls system, and since
> the equivalent command in shell shows the same behavior due to this
> weirdness I'm finding with system, I decided to focus on what appeared
> to be the underlying problem (although perhaps not the actual problem
> if it is just something with me).
>
> Oliver
>
>
> On Wed, Feb 23, 2011 at 11:07 PM, Prof Brian Ripley
> <ripley at stats.ox.ac.uk> wrote:
>> On Wed, 23 Feb 2011, Oliver Soong wrote:
>>
>>> I'm having a very odd problem with system(wait = FALSE). ?I'm not
>>> entirely sure whether it's a bug in R or a problem on our end. ?It's
>>> related to a post a month or so ago in R-help which got no responses,
>>> but I have a little more to add.
>>
>> Well, the place you are asked to report issues on the Windows port is
>> R-windows at r-project.org. ? But no one was able to reproduce this, and it
>> does sound as if the problem is on your specific machine. ?If so, only you
>> can debug it and find out if it is really in R.
>>
>>> This command works as expected (I use c:\tmp since c:\ isn't normally
>>> writable under later versions of Windows).
>>
>> That's a bold claim (and untrue of my Windows 7 systems), but if c:\ is not
>> writeable, you cannot create c:\tmp!
>>
>>> ?The file is created at
>>> c:\tmp\tmp.txt.
>>> system("cmd /c dir > c:\\tmp\\tmp.txt", wait = TRUE)
>>> This command does not work as expected. ?There is no file created at
>>> c:\tmp\tmp.txt.
>>> system("cmd /c dir > c:\\tmp\\tmp.txt", wait = FALSE)
>>
>> Windows' own programs are peculiar things, and often do not obey Windows'
>> own rules for everyone else. ?So I give little weight to such an example.
>> ?And in any case, we recommend shell() for such usages.
>>
>>> The computer is a 64-bit Windows Server 2008R2 machine. ?This affects
>>> R 2.12.1, both the 32-bit and 64-bit RGui executables but not the
>>> RTerm executables. ?This does not affect 32-bit Windows XP, 32-bit
>>> Windows Server 2003, or 64-bit Windows Server 2008. ?This does not
>>> affect R 2.12.0, and if I'm reading the svn logs correctly, there were
>>> some changes made to the system function from 2.12.0 to 2.12.1.
>>> Things seem to work normally when R is started from the start menu
>>> recent programs list, but things do not work properly when R is
>>> started from a shortcut, from the start menu all programs menu, or
>>> through explorer.
>>>
>>> I'm stumped. ?Any ideas I can try?
>>>
>>> Oliver
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>
>> --
>> Brian D. Ripley, ? ? ? ? ? ? ? ? ?ripley at stats.ox.ac.uk
>> Professor of Applied Statistics, ?http://www.stats.ox.ac.uk/~ripley/
>> University of Oxford, ? ? ? ? ? ? Tel: ?+44 1865 272861 (self)
>> 1 South Parks Road, ? ? ? ? ? ? ? ? ? ? +44 1865 272866 (PA)
>> Oxford OX1 3TG, UK ? ? ? ? ? ? ? ?Fax: ?+44 1865 272595
>>
>
>
>
> --
> Oliver Soong
> Donald Bren School of Environmental Science & Management
> University of California, Santa Barbara
> Santa Barbara, CA 93106-5131
> 805-893-7044 (office)
> 610-291-9706 (cell)
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>



-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From osoong+r at gmail.com  Fri Feb 25 01:30:38 2011
From: osoong+r at gmail.com (Oliver Soong)
Date: Thu, 24 Feb 2011 16:30:38 -0800
Subject: [Rd] system(wait = FALSE)
In-Reply-To: <AANLkTikmfm0Si1en3nA=DpQh_y7jzEZxy9jcyQKbp=fj@mail.gmail.com>
References: <AANLkTin7u18yiwLo9yiO0v97n=FJHOsFXUuOrzKH0Hqj@mail.gmail.com>
	<alpine.LFD.2.02.1102240658290.27094@gannet.stats.ox.ac.uk>
	<AANLkTimp+0uNi+urFztjWz0XGOVC69LZM4+G0cUF8uV1@mail.gmail.com>
	<AANLkTikmfm0Si1en3nA=DpQh_y7jzEZxy9jcyQKbp=fj@mail.gmail.com>
Message-ID: <AANLkTinCesOEW-b+AD6e5ZoHNE2+mrgW0api5mCDDa+0@mail.gmail.com>

The targets are identical.  In fact, I located the exact shortcut
listed as the start menu recent programs entry, and it's the same one
used in the all programs entry (there's some Windows magic going on
here that I don't necessarily understand).  Running that through
explorer or the all programs menu gives the weird behavior, and
running it through the recent programs list gives me the expected
behavior.

Oliver


On Thu, Feb 24, 2011 at 3:54 PM, Gabor Grothendieck
<ggrothendieck at gmail.com> wrote:
> On Thu, Feb 24, 2011 at 2:46 PM, Oliver Soong <osoong+r at gmail.com> wrote:
>> Sorry, I didn't know about r-windows at r-project.org. ?Is that a public
>> mailing list like r-help? ?It's not listed under
>> http://www.r-project.org/mail.html.
>>
>> I was able to reproduce the issue under two other 32-bit Windows 7
>> machines, so it's not specific to the one computer. ?It could be
>> something common to my Windows user account configurations, although
>> those accounts are not all configured similarly. ?The part that's the
>> strangest to me is that things do work when R is started through the
>> start menu recent programs and when called from a command shell, but
>> not through shortcuts or the start menu all programs list. ?Sys.getenv
>> does not indicate any particular difference. ?Are there any other
>> things I might check in R?
>
> Right click the particular start menu recent program entry that starts
> it and choose properties; also right click the shortcut and choose
> properties and right click the start menu programs list entry and
> choose properties. ?See what the differences are in the targets.
>
>
>
>
>
>>
>> The actual command I want to run has quoting concerns (inherent to
>> Windows and cmd) that force me to use system. ?If you don't like cmd
>> /c dir, this command also serves the purpose and also shows the weird
>> behavior. ?It presumes that Rscript is on the path:
>> system("Rscript -e \"writeLines(letters,
>> \\\"C:\\\\\\\\tmp\\\\\\\\tmp.txt\\\")\"", wait = FALSE)
>>
>> I've been told (and can see) that shell just calls system, and since
>> the equivalent command in shell shows the same behavior due to this
>> weirdness I'm finding with system, I decided to focus on what appeared
>> to be the underlying problem (although perhaps not the actual problem
>> if it is just something with me).
>>
>> Oliver
>>
>>
>> On Wed, Feb 23, 2011 at 11:07 PM, Prof Brian Ripley
>> <ripley at stats.ox.ac.uk> wrote:
>>> On Wed, 23 Feb 2011, Oliver Soong wrote:
>>>
>>>> I'm having a very odd problem with system(wait = FALSE). ?I'm not
>>>> entirely sure whether it's a bug in R or a problem on our end. ?It's
>>>> related to a post a month or so ago in R-help which got no responses,
>>>> but I have a little more to add.
>>>
>>> Well, the place you are asked to report issues on the Windows port is
>>> R-windows at r-project.org. ? But no one was able to reproduce this, and it
>>> does sound as if the problem is on your specific machine. ?If so, only you
>>> can debug it and find out if it is really in R.
>>>
>>>> This command works as expected (I use c:\tmp since c:\ isn't normally
>>>> writable under later versions of Windows).
>>>
>>> That's a bold claim (and untrue of my Windows 7 systems), but if c:\ is not
>>> writeable, you cannot create c:\tmp!
>>>
>>>> ?The file is created at
>>>> c:\tmp\tmp.txt.
>>>> system("cmd /c dir > c:\\tmp\\tmp.txt", wait = TRUE)
>>>> This command does not work as expected. ?There is no file created at
>>>> c:\tmp\tmp.txt.
>>>> system("cmd /c dir > c:\\tmp\\tmp.txt", wait = FALSE)
>>>
>>> Windows' own programs are peculiar things, and often do not obey Windows'
>>> own rules for everyone else. ?So I give little weight to such an example.
>>> ?And in any case, we recommend shell() for such usages.
>>>
>>>> The computer is a 64-bit Windows Server 2008R2 machine. ?This affects
>>>> R 2.12.1, both the 32-bit and 64-bit RGui executables but not the
>>>> RTerm executables. ?This does not affect 32-bit Windows XP, 32-bit
>>>> Windows Server 2003, or 64-bit Windows Server 2008. ?This does not
>>>> affect R 2.12.0, and if I'm reading the svn logs correctly, there were
>>>> some changes made to the system function from 2.12.0 to 2.12.1.
>>>> Things seem to work normally when R is started from the start menu
>>>> recent programs list, but things do not work properly when R is
>>>> started from a shortcut, from the start menu all programs menu, or
>>>> through explorer.
>>>>
>>>> I'm stumped. ?Any ideas I can try?
>>>>
>>>> Oliver
>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>
>>>
>>> --
>>> Brian D. Ripley, ? ? ? ? ? ? ? ? ?ripley at stats.ox.ac.uk
>>> Professor of Applied Statistics, ?http://www.stats.ox.ac.uk/~ripley/
>>> University of Oxford, ? ? ? ? ? ? Tel: ?+44 1865 272861 (self)
>>> 1 South Parks Road, ? ? ? ? ? ? ? ? ? ? +44 1865 272866 (PA)
>>> Oxford OX1 3TG, UK ? ? ? ? ? ? ? ?Fax: ?+44 1865 272595
>>>
>>
>>
>>
>> --
>> Oliver Soong
>> Donald Bren School of Environmental Science & Management
>> University of California, Santa Barbara
>> Santa Barbara, CA 93106-5131
>> 805-893-7044 (office)
>> 610-291-9706 (cell)
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
>
>
> --
> Statistics & Software Consulting
> GKX Group, GKX Associates Inc.
> tel: 1-877-GKX-GROUP
> email: ggrothendieck at gmail.com
>



-- 
Oliver Soong
Donald Bren School of Environmental Science & Management
University of California, Santa Barbara
Santa Barbara, CA 93106-5131
805-893-7044 (office)
610-291-9706 (cell)


From ggrothendieck at gmail.com  Fri Feb 25 02:08:26 2011
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 24 Feb 2011 20:08:26 -0500
Subject: [Rd] system(wait = FALSE)
In-Reply-To: <AANLkTinCesOEW-b+AD6e5ZoHNE2+mrgW0api5mCDDa+0@mail.gmail.com>
References: <AANLkTin7u18yiwLo9yiO0v97n=FJHOsFXUuOrzKH0Hqj@mail.gmail.com>
	<alpine.LFD.2.02.1102240658290.27094@gannet.stats.ox.ac.uk>
	<AANLkTimp+0uNi+urFztjWz0XGOVC69LZM4+G0cUF8uV1@mail.gmail.com>
	<AANLkTikmfm0Si1en3nA=DpQh_y7jzEZxy9jcyQKbp=fj@mail.gmail.com>
	<AANLkTinCesOEW-b+AD6e5ZoHNE2+mrgW0api5mCDDa+0@mail.gmail.com>
Message-ID: <AANLkTinVm2e3+W4-xxoebaEiPbRaTb2JWkoGQxvwKYJi@mail.gmail.com>

On Thu, Feb 24, 2011 at 7:30 PM, Oliver Soong <osoong+r at gmail.com> wrote:
> The targets are identical. ?In fact, I located the exact shortcut
> listed as the start menu recent programs entry, and it's the same one
> used in the all programs entry (there's some Windows magic going on
> here that I don't necessarily understand). ?Running that through
> explorer or the all programs menu gives the weird behavior, and
> running it through the recent programs list gives me the expected
> behavior.

Check all other components of the property as well.

-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From hankin.robin at gmail.com  Fri Feb 25 06:16:38 2011
From: hankin.robin at gmail.com (robin hankin)
Date: Fri, 25 Feb 2011 18:16:38 +1300
Subject: [Rd] Sexpr problem
Message-ID: <AANLkTim6YeiHZ3=AqidHDGVhRfTKhVtwa1ey_x4vtUSq@mail.gmail.com>

Hi.

I am having difficulty  making \Sexpr work as desired.
 Specifically, the pdf and the text  versions of the help system
differ, and I can't reproduce the example on page 63 of
the R Journal article by  Murdoch and Urbanek (Vol 1/2,
December 2009).

Is there an example package that I could examine for Best Practice?

thanks



-- 
Robin Hankin
Uncertainty Analyst
hankin.robin at gmail.com


From murdoch.duncan at gmail.com  Fri Feb 25 14:51:34 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 25 Feb 2011 08:51:34 -0500
Subject: [Rd] Sexpr problem
In-Reply-To: <AANLkTim6YeiHZ3=AqidHDGVhRfTKhVtwa1ey_x4vtUSq@mail.gmail.com>
References: <AANLkTim6YeiHZ3=AqidHDGVhRfTKhVtwa1ey_x4vtUSq@mail.gmail.com>
Message-ID: <4D67B3E6.7040302@gmail.com>

On 25/02/2011 12:16 AM, robin hankin wrote:
> Hi.
>
> I am having difficulty  making \Sexpr work as desired.
>   Specifically, the pdf and the text  versions of the help system
> differ, and I can't reproduce the example on page 63 of
> the R Journal article by  Murdoch and Urbanek (Vol 1/2,
> December 2009).
>
> Is there an example package that I could examine for Best Practice?


We use \Sexpr in only a couple of places currently:  in the NEWS.Rd 
files (which are treated differently than other .Rd files), and in the 
tools package where it is illustrated (see ?tools::Rd2HTML; the last few 
lines of the note are generated using \Sexpr).

If you put together a simple .Rd file that shows the difference you're 
seeing, I'll take a look.

Duncan Murdoch


From Koert.Kuipers at diamondnotch.com  Fri Feb 25 15:36:12 2011
From: Koert.Kuipers at diamondnotch.com (Koert Kuipers)
Date: Fri, 25 Feb 2011 09:36:12 -0500
Subject: [Rd] R CMD build error (RProtoBuf on windows)
Message-ID: <6143522CDE27514BB78C92BCD7190003033B87D350@DNLEXCH01>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110225/6a41d493/attachment.pl>

From ripley at stats.ox.ac.uk  Fri Feb 25 18:17:35 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 25 Feb 2011 17:17:35 +0000 (GMT)
Subject: [Rd] R CMD build error (RProtoBuf on windows)
In-Reply-To: <6143522CDE27514BB78C92BCD7190003033B87D350@DNLEXCH01>
References: <6143522CDE27514BB78C92BCD7190003033B87D350@DNLEXCH01>
Message-ID: <alpine.LFD.2.02.1102251712590.20251@toucan.stats.ox.ac.uk>

On Fri, 25 Feb 2011, Koert Kuipers wrote:

> Hello all,
> I am trying to port the package RProtoBuf to windows. The developers of RProtoBuf have given me some helpful pointers so far, but now I am stuck.
>
> After having made what I think are the necessary changes to the 
> package to compile on windows, "R CMD build RProtoBuf" outputs a 
> somewhat cryptic error ("This application has requested the Runtime 
> to terminate it in an unusual way") after which it deletes the

Well, that's a standard Windows error message: it is normally 
accompanied by a popup window with more information.

> temporary directory in which it was working. How do I 
> debug/investigate this? The relevant lines of the build output are 
> pasted below.

Why are you trying to rebuild the package vignettes?  Use Rcmd build 
--no-vignettes to get a tarball, Rcmd INSTALL to get an installed 
package: then you can run the installed package under a debugger (see 
the rw-FAQ) in the usual way to track down bugs in compiled code.

> Thanks! Koert
>
>
> g++ -shared -s -static-libgcc -o RProtoBuf.dll tmp.def ConnectionCopyingInputStr
> eam.o ConnectionCopyingOutputStream.o ConnectionInputStream.o ConnectionOutputSt
> ream.o DescriptorPoolLookup.o RSourceTree.o RWarningErrorCollector.o Rconnection
> CopyingInputStream.o ZeroCopyInputStreamWrapper.o ZeroCopyOutputStreamWrapper.o
> exceptions.o extractors.o lookup.o mutators.o rprotobuf.o streams.o wrapper_Arra
> yInputStream.o wrapper_ArrayOutputStream.o wrapper_Descriptor.o wrapper_EnumDesc
> riptor.o wrapper_EnumValueDescriptor.o wrapper_FieldDescriptor.o wrapper_FileDes
> criptor.o wrapper_Message.o wrapper_MethodDescriptor.o wrapper_ServiceDescriptor
> .o wrapper_ZeroCopyInputStream.o C:/Devel/R-2.12/library/Rcpp/lib/i386/libRcpp.a
> -Lc:/Devel/mingw/msys/1.0/local/lib -lprotobuf -LC:/Devel/R-2.12/bin/i386 -lR
> Info: resolving google::protobuf::FieldDescriptor::kTypeToCppTypeMap      by lin
> king to __imp___ZN6google8protobuf15FieldDescriptor17kTypeToCppTypeMapE (auto-im
> portc:/devel/rtools/mingw/bin/../lib/gcc/mingw32/4.5.0/../../../../mingw32/bin/l
> d.exe: warning: auto-importing has been activated without --enable-auto-import s
> pecified on the command line.
> This should work unless it involves constant data structures referencing symbols
> from auto-imported DLLs.)
>
> installing to C:/DOCUME~1/kkuipers/LOCALS~1/Temp/RtmpRbU0Q2/Rinst25a17ae0/RProto
> Buf/libs/i386
> ** R
> ** demo
> ** inst
> ** preparing package for lazy loading
> Loading required package: bitops
> Warning: package 'Rcpp' was built under R version 2.12.1
> ** help
> *** installing help indices
> ** building package indices ...
> ** testing if installed package can be loaded
>
> * DONE (RProtoBuf)
>
> This application has requested the Runtime to terminate it in an unusual way.
> Please contact the application's support team for more information.
>
> This application has requested the Runtime to terminate it in an unusual way.
> Please contact the application's support team for more information.
>      -----------------------------------
> ERROR: Installation failed
> Removing installation dir
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From therneau at mayo.edu  Fri Feb 25 19:24:15 2011
From: therneau at mayo.edu (Terry Therneau)
Date: Fri, 25 Feb 2011 12:24:15 -0600
Subject: [Rd] Small enhancement for CMD check
Message-ID: <1298658255.4670.64.camel@punchbuggy>

 It would be nice if the 00check.log file also included this part of the
output:
  Running ?bladder.R?
  Comparing ?bladder.Rout? to ?bladder.Rout.save? ... OK
  Running ?book1.R?
  Comparing ?book1.Rout? to ?book1.Rout.save? ... OK
  Running ?book2.R?
  Comparing ?book2.Rout? to ?book2.Rout.save? ... OK

etc.

  The survival package has enough test scripts that it exceeds my
terminal's scroll bar; I have to either watch closely or run
 R CMD check survival >& mylog

Terry Therneau


From Toby.Hocking at inria.fr  Fri Feb 25 22:12:01 2011
From: Toby.Hocking at inria.fr (Toby Dylan Hocking)
Date: Fri, 25 Feb 2011 22:12:01 +0100 (CET)
Subject: [Rd] Named capture in regexp
Message-ID: <20110225.221201.769599707548117493.Toby.Hocking@inria.fr>

Dear R core developers,

One feature from Python that I have been wanting in R is the ability
to capture groups in regular expressions using names. Consider the
following example in R.

> notables <- c("  Ben Franklin and Jefferson Davis","\tMillard Fillmore")
> name.rex <- "(?<first>[A-Z][a-z]+) (?<last>[A-Z][a-z]+)"
> (parsed <- regexpr(name.rex,notables,perl=TRUE))
[1] 3 2
attr(,"match.length")
[1] 12 16
attr(,"capture.start")
     [,1] [,2]
[1,]    3    7
[2,]    2   10
attr(,"capture.length")
     [,1] [,2]
[1,]    3    8
[2,]    7    8
attr(,"capture.names")
[1] "first" "last" 
> parse.one(notables,parsed)
     first     last      
[1,] "Ben"     "Franklin"
[2,] "Millard" "Fillmore"
> parse.one(notables,parsed)[,"last"]
[1] "Franklin" "Fillmore"

The advantage to this approach is that you can tag groups by name, and
then use the names later in the code to extract the matched substrings.

I realized this is possible by using the PCRE library which ships with
R, so in the last couple days I hacked a bit in src/main/grep.c in the
R source code. I managed to get named capture to work with the
standard gregexpr and regexpr functions. For backwards-compatibility,
my strategy was to just add more attributes to the results of these
functions, as shown above.

Attached is the patch and some R code for testing the new features. It
works fine for me with no memory problems. However, I noticed that
there is some UTF8 handling code, which I did not touch (use_UTF8 is
false on my machine). I presume we will need to make some small
modifications to get it to work with unicode, but I'm not sure how to
do them.

Would you consider integrating this patch into the R source code for
future releases, so the larger R community can take advantage of this
feature? If there's anything else I can do to help please let me know.

Sincerely,
Toby Dylan Hocking
http://cbio.ensmp.fr/~thocking/

-------------- next part --------------
A non-text attachment was scrubbed...
Name: grep-named-capture.patch
Type: text/x-patch
Size: 9016 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110225/819df4b2/attachment.bin>
-------------- next part --------------
### Toby Dylan Hocking, 25 feb 2011. Some R code to test my
### implementation of new named capture group features in gregexpr
gctorture(FALSE)##for debugging

### Parse result of gregexpr(,string)
result2list <- function(string,result){
  extract.substrings <- function(string,starts,lengths,names){
    subs <- substring(string,starts,starts+lengths-1)
    m <- matrix(subs,ncol=length(names))
    colnames(m) <- names
    m
  }
  N <- attr(result,"capture.names")
  lapply(seq_along(result),function(i){
    extract.substrings(string[i],
                       attr(result[[i]],"capture.start"),
                       attr(result[[i]],"capture.length"),
                       N)
  })
}

### Parse result of regexpr(,string)
parse.one <- function(string,result){
  m <- do.call(rbind,lapply(seq_along(string),function(i){
    st <- attr(result,"capture.start")[i,]
    substring(string[i],st,st+attr(result,"capture.length")[i,]-1)
  }))
  colnames(m) <- attr(result,"capture.names")
  m
}
string <- c("another foobar bazing string",
            "fbar baz foooobar baz",
            "no matches here",
            "my foobar baz st another fooooobar baz dude fobar baz")
notables <- c("  Ben Franklin and Jefferson Davis","\tMillard Fillmore")
name.rex <- "(?<first>[A-Z][a-z]+) (?<last>[A-Z][a-z]+)"
for(i in 1:100)
parsed <- gregexpr(name.rex,notables,perl=TRUE)
parsed[[1]]
result2list(notables,parsed)
(parsed <- regexpr(name.rex,notables,perl=TRUE))
parse.one(notables,parsed)
parse.one(notables,parsed)[,"last"]
result <- gregexpr("f(?<os_in_foo>o*)b(?<as_in_bar>a*)r (baz)",string,perl=TRUE)
print(result)
s2 <- paste(rep("foobar",1030),collapse=" ")
result <- gregexpr("f(?<os_in_foo>o*)b(?<as_in_bar>a*)r",s2,perl=TRUE)

## negative controls
regexpr(name.rex,notables)##perl not TRUE, bad regexp
regexpr("([A-Z][a-z]+) ([A-Z][a-z]+)",notables)##still works like usual

From ripley at stats.ox.ac.uk  Sun Feb 27 10:07:42 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 27 Feb 2011 09:07:42 +0000 (GMT)
Subject: [Rd] min/max of a vector with NAs and NaNs
In-Reply-To: <4D65ADDF.20700@fhcrc.org>
References: <4D65ADDF.20700@fhcrc.org>
Message-ID: <alpine.LFD.2.02.1102270905070.4051@gannet.stats.ox.ac.uk>

On Wed, 23 Feb 2011, Herv? Pag?s wrote:

> I get this (with R-2.12 and R-2.13, didn't try with earlier versions):
>
>> max(c(NaN, NA))
> [1] NA
>> max(c(NA, NaN))
> [1] NaN
>
> I get the same thing with min().
>
> The fact that the result of 'max(x)' or 'min(x)' depends on the order
> of the elements in 'x' is surprising. It also seems to contradict the
> man page:
>
>     By definition the min/max of a numeric vector containing an ?NaN?
>     is ?NaN?, except that the min/max of any vector containing an ?NA?
>     is ?NA? even if it also contains an ?NaN?.

This seemed to depend on the compiler, and in your case the compiler 
has optimized away the code to achieve this.   I've changed the code 
in R-devel to something that seems to be more robust.  Note that the 
comment did not apply to max(NA, NaN), but that should also now be 
consistent.

>
> Cheers,
> H.
>
> -- 
> Herv? Pag?s
>
> Program in Computational Biology
> Division of Public Health Sciences
> Fred Hutchinson Cancer Research Center
> 1100 Fairview Ave. N, M2-B876
> P.O. Box 19024
> Seattle, WA 98109-1024
>
> E-mail: hpages at fhcrc.org
> Phone:  (206) 667-5791
> Fax:    (206) 667-1319
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From D.Strbenac at garvan.org.au  Mon Feb 28 01:00:07 2011
From: D.Strbenac at garvan.org.au (Dario Strbenac)
Date: Mon, 28 Feb 2011 11:00:07 +1100 (EST)
Subject: [Rd] sys.calls Behaviour
Message-ID: <20110228110007.BLB14251@gimr.garvan.unsw.edu.au>

Hello,

I noticed a difference between S4 methods and ordinary methods for sys.calls(), where it seems to report everything twice for S4 methods. This seems strange. Am I overlooking something ?

> f <- function(x)
+ {
+ g(x)
+ }
> 
> g <- function(y)
+ {
+ cat(y, '\n')
+ sys.calls()
+ }
> 
> f(5)
5 
[[1]]
f(5)

[[2]]
g(x)

> 
> 
> setGeneric("conv", signature = c("x"), function(x){standardGeneric("conv")})
[1] "conv"
> 
> setMethod("conv", "character", function(x)
+ {
+ conv(as.numeric(x))
+ })
[1] "conv"
> 
> setMethod("conv", "numeric", function(x)
+ {
+ cat(x, '\n')
+ sys.calls()
+ })
[1] "conv"
> 
> conv("5")
5 
[[1]]
conv("5")

[[2]]
conv("5")

[[3]]
conv(as.numeric(x))

[[4]]
conv(as.numeric(x))

> 
> sessionInfo()
R version 2.12.2 (2011-02-25)
Platform: i386-pc-mingw32/i386 (32-bit)

locale:
[1] LC_COLLATE=English_Australia.1252  LC_CTYPE=English_Australia.1252    LC_MONETARY=English_Australia.1252 LC_NUMERIC=C                       LC_TIME=English_Australia.1252    

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

--------------------------------------
Dario Strbenac
Research Assistant
Cancer Epigenetics
Garvan Institute of Medical Research
Darlinghurst NSW 2010
Australia


From ripley at stats.ox.ac.uk  Mon Feb 28 17:57:51 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 28 Feb 2011 16:57:51 +0000 (GMT)
Subject: [Rd] Small enhancement for CMD check
In-Reply-To: <1298658255.4670.64.camel@punchbuggy>
References: <1298658255.4670.64.camel@punchbuggy>
Message-ID: <alpine.LFD.2.02.1102281641400.19979@gannet.stats.ox.ac.uk>

Unfortunately it would need a major rewrite, and either piping output 
through a pager (surely the standard Unix way to handle this) or 
redirecting to a file is the simplest way to do this.

R CMD check calls a process to run .runPackageTestsR, which calls 
further processes to run each test and diff the results.  We could 
simply capture stdout/stderr of .runPackageTestsR, but then one would 
have to wait until all the tests had run before seeing any output, 
which may mean waiting hours -- that was decided to be too 
undesirable.

On Fri, 25 Feb 2011, Terry Therneau wrote:

> It would be nice if the 00check.log file also included this part of the
> output:
>  Running ?bladder.R?
>  Comparing ?bladder.Rout? to ?bladder.Rout.save? ... OK
>  Running ?book1.R?
>  Comparing ?book1.Rout? to ?book1.Rout.save? ... OK
>  Running ?book2.R?
>  Comparing ?book2.Rout? to ?book2.Rout.save? ... OK
>
> etc.
>
>  The survival package has enough test scripts that it exceeds my
> terminal's scroll bar; I have to either watch closely or run
> R CMD check survival >& mylog

The most prolix are
  survival portfolio    matlab  kappalab  spatstat
        68        36        32        30        28
        BB    HSAUR2    fields     pcalg     aster
        26        22        22        22        21

The remedy seems to be to group the tests into larger units.

> Terry Therneau

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From therneau at mayo.edu  Mon Feb 28 19:29:23 2011
From: therneau at mayo.edu (Terry Therneau)
Date: Mon, 28 Feb 2011 12:29:23 -0600
Subject: [Rd] Small enhancement for CMD check
In-Reply-To: <alpine.LFD.2.02.1102281641400.19979@gannet.stats.ox.ac.uk>
References: <1298658255.4670.64.camel@punchbuggy>
	<alpine.LFD.2.02.1102281641400.19979@gannet.stats.ox.ac.uk>
Message-ID: <1298917763.15393.27.camel@punchbuggy>

On Mon, 2011-02-28 at 16:57 +0000, Prof Brian Ripley wrote:
> Unfortunately it would need a major rewrite, and either piping output 
> through a pager (surely the standard Unix way to handle this) or 
> redirecting to a file is the simplest way to do this.
> 
> R CMD check calls a process to run .runPackageTestsR, which calls 
> further processes to run each test and diff the results.  We could 
> simply capture stdout/stderr of .runPackageTestsR, but then one would 
> have to wait until all the tests had run before seeing any output, 
> which may mean waiting hours -- that was decided to be too 
> undesirable.

Fair enough.  My request was of the "if it's easy to do...." class.
Thanks for looking.  (On Unix you could avoid the wait by using tee,
BTW)


> The most prolix are
>   survival portfolio    matlab  kappalab  spatstat
>         68        36        32        30        28
>         BB    HSAUR2    fields     pcalg     aster
>         26        22        22        22        21
> 
> The remedy seems to be to group the tests into larger units.

It appears that I'm an outlier.  I certainly didn't start thinking that
there would be so many tests.  But whenever I track down a new bug in
response to a user I'll have created some code to isolate and define the
error first, and then more lines to verify the fix; I usually find the
extra 15-20 minutes to 'formalize' this and add it to the test suite to
be a good investment.  Hopefully the 68 is taken as a measure of
longivity of the package and not of bad programming skills!

Terry T


From mxkuhn at gmail.com  Mon Feb 28 21:22:30 2011
From: mxkuhn at gmail.com (Max Kuhn)
Date: Mon, 28 Feb 2011 15:22:30 -0500
Subject: [Rd] broken link on CRAN
Message-ID: <AANLkTinr2UguUBOmtdF9Z6Po1RUKJ_MLQeAbgROp81n_@mail.gmail.com>

The link to

   http://cran.r-project.org/bin/macosx/R-2.12.1.pkg

on the CRAN page

   http://cran.r-project.org/bin/macosx/

is broken. Also, the email address for the webmaster is null (which is
why I'm emailing here).

Thanks,

Max


From pdalgd at gmail.com  Mon Feb 28 21:47:02 2011
From: pdalgd at gmail.com (peter dalgaard)
Date: Mon, 28 Feb 2011 21:47:02 +0100
Subject: [Rd] broken link on CRAN
In-Reply-To: <AANLkTinr2UguUBOmtdF9Z6Po1RUKJ_MLQeAbgROp81n_@mail.gmail.com>
References: <AANLkTinr2UguUBOmtdF9Z6Po1RUKJ_MLQeAbgROp81n_@mail.gmail.com>
Message-ID: <91C0F53A-00A0-467D-BE50-5C9E3F3C1B7A@gmail.com>


On Feb 28, 2011, at 21:22 , Max Kuhn wrote:

> The link to
> 
>   http://cran.r-project.org/bin/macosx/R-2.12.1.pkg
> 
> on the CRAN page
> 
>   http://cran.r-project.org/bin/macosx/
> 
> is broken. Also, the email address for the webmaster is null (which is
> why I'm emailing here).

There's no such link and 2.12.2 is current. I suspect you have a page cache issue, or managed to hit the link at exactly the wrong time during update.

If you really need the older version, look in old/.

> 
> Thanks,
> 
> Max
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Peter Dalgaard
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From simon.urbanek at r-project.org  Mon Feb 28 21:48:25 2011
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Mon, 28 Feb 2011 15:48:25 -0500
Subject: [Rd] broken link on CRAN
In-Reply-To: <AANLkTinr2UguUBOmtdF9Z6Po1RUKJ_MLQeAbgROp81n_@mail.gmail.com>
References: <AANLkTinr2UguUBOmtdF9Z6Po1RUKJ_MLQeAbgROp81n_@mail.gmail.com>
Message-ID: <1885A1FE-F3AF-4751-B3D2-54CB5F58C1F5@r-project.org>


On Feb 28, 2011, at 3:22 PM, Max Kuhn wrote:

> The link to
> 
>   http://cran.r-project.org/bin/macosx/R-2.12.1.pkg
> 
> on the CRAN page
> 
>   http://cran.r-project.org/bin/macosx/
> 
> is broken.

There is no such link on the page - it's R-2.12.2.pkg now - I suspect you have a cached page in your browser - try reloading it.

Cheers,
Simon


> Also, the email address for the webmaster is null (which is
> why I'm emailing here).
> 
> Thanks,
> 
> Max
> 
> 


