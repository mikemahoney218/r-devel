From jeff at kanecap.com  Tue Nov  1 01:04:21 2005
From: jeff at kanecap.com (Jeff Enos)
Date: Mon, 31 Oct 2005 19:04:21 -0500
Subject: [Rd] S4 classes in existing packages
Message-ID: <17254.45317.101767.527318@gargle.gargle.HOWL>

R-devel,

I'm interested in looking at some examples of existing R packages that
rely heavily on S4 classes to get a feel for varying styles and
package organization techniques.  Could you recommend any packages
that might serve as a good starting point?

Thanks in advance,

Jeff


From sfalcon at fhcrc.org  Tue Nov  1 02:25:44 2005
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Mon, 31 Oct 2005 17:25:44 -0800
Subject: [Rd] S4 classes in existing packages
In-Reply-To: <17254.45317.101767.527318@gargle.gargle.HOWL> (Jeff Enos's
	message of "Mon, 31 Oct 2005 19:04:21 -0500")
References: <17254.45317.101767.527318@gargle.gargle.HOWL>
Message-ID: <m28xw9p3af.fsf@fhcrc.org>

On 31 Oct 2005, jeff at kanecap.com wrote:
> I'm interested in looking at some examples of existing R packages
> that rely heavily on S4 classes to get a feel for varying styles and
> package organization techniques.  Could you recommend any packages
> that might serve as a good starting point?

I would look at the Matrix package.

+ seth


From Matthias.Kohl at stamats.de  Tue Nov  1 09:01:49 2005
From: Matthias.Kohl at stamats.de (Matthias Kohl)
Date: Tue, 01 Nov 2005 09:01:49 +0100
Subject: [Rd] S4 classes in existing packages
In-Reply-To: <17254.45317.101767.527318@gargle.gargle.HOWL>
References: <17254.45317.101767.527318@gargle.gargle.HOWL>
Message-ID: <436720ED.6060807@stamats.de>

Jeff Enos schrieb:

>R-devel,
>
>I'm interested in looking at some examples of existing R packages that
>rely heavily on S4 classes to get a feel for varying styles and
>package organization techniques.  Could you recommend any packages
>that might serve as a good starting point?
>
>Thanks in advance,
>
>Jeff
>  
>
our packages distr, distrEx, distrSim, distrTEst and RandVar are based 
on S4 classes and methods.

hth
Matthias

>______________________________________________
>R-devel at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-devel
>  
>


-- 
StaMatS - Statistik + Mathematik Service
Dipl.Math.(Univ.) Matthias Kohl
www.stamats.de


From ripley at stats.ox.ac.uk  Tue Nov  1 09:18:23 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 1 Nov 2005 08:18:23 +0000 (GMT)
Subject: [Rd] S4 classes in existing packages
In-Reply-To: <436720ED.6060807@stamats.de>
References: <17254.45317.101767.527318@gargle.gargle.HOWL>
	<436720ED.6060807@stamats.de>
Message-ID: <Pine.LNX.4.61.0511010807170.13190@gannet.stats>

On Tue, 1 Nov 2005, Matthias Kohl wrote:

> Jeff Enos schrieb:
>
>> R-devel,
>>
>> I'm interested in looking at some examples of existing R packages that
>> rely heavily on S4 classes to get a feel for varying styles and
>> package organization techniques.  Could you recommend any packages
>> that might serve as a good starting point?
>>
>> Thanks in advance,
>>
>> Jeff
>>
>>
> our packages distr, distrEx, distrSim, distrTEst and RandVar are based
> on S4 classes and methods.

As do many others, providing the variety of styles that the questioner 
asked for.  Those that are documented to do so include

CoCo DBI IDPmisc Matrix RMySQL ROracle RSQLite RUnit SparseM aod arules 
boolean coin colorspace copula deal dynamicGraph fBasics(etc) flexclust 
flexmix giRaph gpclib its kappalab kernalb limma lme4 matlab monoProc 
orientlib partsm pixmap tuneR

on CRAM, stats4 in the R sources and most (all?) of BioC.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From Bernhard_Pfaff at fra.invesco.com  Tue Nov  1 09:33:10 2005
From: Bernhard_Pfaff at fra.invesco.com (Pfaff, Bernhard Dr.)
Date: Tue, 1 Nov 2005 08:33:10 -0000 
Subject: [Rd] S4 classes in existing packages
Message-ID: <25D1C2585277D311B9A20000F6CCC71B0735BB07@DEFRAEX02>

> Jeff Enos schrieb:
>
>> R-devel,
>>
>> I'm interested in looking at some examples of existing R packages that
>> rely heavily on S4 classes to get a feel for varying styles and
>> package organization techniques.  Could you recommend any packages
>> that might serve as a good starting point?
>>
>> Thanks in advance,
>>
>> Jeff
>>
>>
> our packages distr, distrEx, distrSim, distrTEst and RandVar are based
> on S4 classes and methods.

As do many others, providing the variety of styles that the questioner 
asked for.  Those that are documented to do so include

CoCo DBI IDPmisc Matrix RMySQL ROracle RSQLite RUnit SparseM aod arules 
boolean coin colorspace copula deal dynamicGraph fBasics(etc) flexclust 
flexmix giRaph gpclib its kappalab kernalb limma lme4 matlab monoProc 
orientlib partsm pixmap tuneR

on CRAM, stats4 in the R sources and most (all?) of BioC.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


Hello Jeff,

to amend the list: in the package "urca" S4-classes are implemented too.

Best,
Bernhard 


______________________________________________
R-devel at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-devel
-------------- next part --------------
*****************************************************************
Confidentiality Note: The information contained in this message,
and any attachments, may contain confidential and/or privileged
material. It is intended solely for the person(s) or entity to
which it is addressed. Any review, retransmission, dissemination,
or taking of any action in reliance upon this information by
persons or entities other than the intended recipient(s) is
prohibited. If you received this in error, please contact the
sender and delete the material from any computer.
*****************************************************************

From ripley at stats.ox.ac.uk  Tue Nov  1 11:58:20 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 1 Nov 2005 10:58:20 +0000 (GMT)
Subject: [Rd] Yates' correction for continuity in chisq.test (PR#8265)
In-Reply-To: <Pine.LNX.4.61.0510311255330.19359@gannet.stats>
References: <20051030140726.95628205FA@slim.kubism.ku.dk>
	<4364DD5C.7090508@math.ucalgary.ca>
	<Pine.LNX.4.61.0510311255330.19359@gannet.stats>
Message-ID: <Pine.LNX.4.61.0511011037350.24802@gannet.stats>

On Mon, 31 Oct 2005, Prof Brian Ripley wrote:

> On Sun, 30 Oct 2005, P Ehlers wrote:
>
>> dih69530 at syd.odn.ne.jp wrote:
>>> Full_Name: foo ba baz
>>> Version: R2.2.0
>>> OS: Mac OS X (10.4)
>>> Submission from: (NULL) (219.66.32.183)
>>> 
>>> 
>>> chisq.test(matrix(c(9,10,9,11),2,2))
>>> 
>>> Chi-square value must be 0, and, P value must be 0
>>> R does over correction
>>> 
>>> when | a d - b c | < n / 2 &#65292;chi-sq must be 0
>> 
>> (Presumably, you mean P-value = 1.)
>> If you don't want the correction, set correct=FALSE. (The
>> results won't differ much.)
>> 
>> A better example is
>> 
>>  chisq.test(matrix(c(9,10,9,10),2,2))
>> 
>> for which R probably should return X-squared = 0.
>
> R is using the correction that almost all the sources I looked at suggest. 
> You can't go around adjusting X^2 for just some values of the data: the claim 
> is that the adjusted statistic has a more accurate chisq distribution under 
> the null.
>
> I think at this remove it does not matter what Yates' suggested (although if 
> I were writing a textbook I would find out), especially as the R 
> documentation does not mention Yates.

I have now checked Yates (1934), Fisher's 'Statistical Methods for 
Research Workers' and the Encyclopedia of Statistical Sciences.  The first 
two are vague (and could perhaps be read as not correcting O-E = 0), but 
the latter agrees with R in giving a formula which always subtracts 1/2. 
Also, it mentions that Pearson stated that the formula for the continuity 
correction long preceded Yates' publication, so it is perhaps reasonable 
not to mention Yates.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From murdoch at stats.uwo.ca  Tue Nov  1 15:16:53 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue, 01 Nov 2005 09:16:53 -0500
Subject: [Rd] [R] unvectorized option for outer()
In-Reply-To: <4366833E.8000508@acm.org>
References: <8B08A3A1EA7AAC41BE24C750338754E69FDF14@HERMES.demogr.mpg.de>	<43629490.9060204@acm.org>	<971536df0510281643u50929fa6rf097c40948700804@mail.gmail.com>	<4364A4FC.2030400@durham.ac.uk>	<Pine.LNX.4.63a.0510301300260.28148@homer23.u.washington.edu>	<x2y84amyv4.fsf@turmalin.kubism.ku.dk>	<43666D4D.7070602@acm.org>
	<4366738C.1080508@stats.uwo.ca> <4366833E.8000508@acm.org>
Message-ID: <436778D5.2010800@stats.uwo.ca>

The version I posted yesterday did indeed mess up when some arguments 
were unspecified.  Here's a revision that seems to work in all the tests 
I can think of.  I also added the SIMPLIFY and USE.NAMES args from 
mapply to it, and a sanity check to the args.

I did notice and work around one buglet in mapply:  if you choose not to 
vectorize any arguments, you don't get a call to the original function, 
mapply returns "list()".

For example,

 > mapply(function(x) x^2, MoreArgs = list(x=2))
list()

whereas I would think 4 is a more logical answer.


Vectorize <- function(FUN, vectorize.args = arg.names, SIMPLIFY = TRUE, 
USE.NAMES = TRUE) {

     arg.names <- as.list(formals(FUN))
     arg.names[["..."]] <- NULL
     arg.names <- names(arg.names)

     vectorize.args <- as.character(vectorize.args)

     if (!length(vectorize.args)) return(FUN)

     if (!all(vectorize.args %in% arg.names))
	stop("must specify formal argument names to vectorize")

     FUNV <- function() { # will set the formals below
         args <- lapply(as.list(match.call())[-1], eval, parent.frame())
         dovec <- match(vectorize.args, names(args), nomatch = 0)
      	do.call("mapply", c(FUN = FUN,
      			    args[dovec],
      			    MoreArgs = list(args[-dovec]),
      			    SIMPLIFY = SIMPLIFY,
      			    USE.NAMES = USE.NAMES))
     }
     formals(FUNV) <- formals(FUN)
     FUNV
}
      	
Duncan Murdoch

On 10/31/2005 3:49 PM, Tony Plate wrote:
> Duncan Murdoch wrote:
>> On 10/31/2005 2:15 PM, Tony Plate wrote:
>> 
>>> [snipped comments irrelevant to this post]
>>>
>>> So, here's a first pass at a general Vectorize() function:
>>>
>>> Vectorize <- function(FUN, vectorize.args) {
>>>      if (!all(is.element(vectorize.args, names(formals(FUN)))))
>>>          stop("some args to vectorize are not args of FUN")
>>>      FUNV <- eval(substitute(function(x, ...) mapply(FUN, x, 
>>> MoreArgs=list(...)), list(FUN=FUN)))
>>>      formals(FUNV) <- formals(FUNV)[c(rep(1, length(vectorize.args)), 2)]
>>>      names(formals(FUNV))[seq(along=vectorize.args)] <- vectorize.args
>>>      body(FUNV) <- body(FUNV)[c(1, 2, rep(3, length(vectorize.args)), 4)]
>>>      body(FUNV)[seq(3,len=length(vectorize.args))] <- 
>>> lapply(vectorize.args, as.name)
>>>      FUNV
>>> }
>> 
>> 
>> I'd think the formals of the result should be identical to the formals 
>> of the input.
>> 
>> Regarding the environment of the result:  it is used to determine the 
>> meaning of symbols that aren't defined within the function, e.g. things 
>> like "eval", "substitute", etc.  So I'd say that you don't want anything 
>> special there, as long as you make sure that FUN is always evaluated in 
>> its original environment.
>> 
>> Generally I don't like the look of that manipulation of the body of your 
>> result; it looks pretty fragile to me.  But I haven't worked out exactly 
>> what you're doing, or whether it's possible to avoid it.
>> 
>> Duncan Murdoch
>> 
> 
> Thanks for explanation about the environment.
> 
> I should have said, that manipulation of the body creates the call
>    mapply(FUN, A, alpha, MoreArgs=list(...))
> from the original (x is a dummy argument)
>    mapply(FUN, x, MoreArgs=list(...))
> 
> Are there better ways to create that call?  The difficulty is that the 
> argument names in the call are derived from the actual arguments to 
> Vectorize(), and there is an arbitrary number of them.
> 
> As for the formals of the result being identical to the formals of the 
> input, I couldn't see any easy way to do that and still support optional 
> arguments, e.g., if the input function formals were (a, b, t=1), then 
> the result function would look something like:
> 
> function(a, b, t=1) mapply(FUN, a, b, t=t)
> 
> and missing(t) would not work correctly within FUN (with even more 
> serious problems for optional arguments with no defaults).
> 
> -- Tony Plate
> 
> 
>> 
>>> ssd <- function(A,alpha,Y,t) sum((Y - A*exp(-alpha*t))2)
>>> # SSD is a vectorized version of ssd
>>> SSD <- function(Avec, alphavec, ...) mapply(ssd, Avec, alphavec, 
>>> MoreArgs=list(...))
>>> # Vectorize(ssd, c("A", "alpha")) should produce
>>> # function(A, alpha, ...) mapply(ssd, A, alpha, MoreArgs=list(...))
>>> Y <- 1:5; t <- 3
>>> outer(1:3, 1:2, SSD, Y, t)
>>> outer(1:3, 1:2, Vectorize(ssd, c("A", "alpha")), Y, t)
>>>
>>>  > # transcript of running the above commands
>>>  > Vectorize(ssd, c("A", "alpha"))
>>> function (A, alpha, ...)
>>> mapply(function (A, alpha, Y, t)
>>> sum((Y - A * exp(-alpha * t))^2), A, alpha, MoreArgs = list(...))
>>> <environment: 0x1361f40>
>>>  > Y <- 1:5; t <- 3
>>>  > outer(1:3, 1:2, SSD, Y, t)
>>>           [,1]     [,2]
>>> [1,] 53.51878 54.92567
>>> [2,] 52.06235 54.85140
>>> [3,] 50.63071 54.77719
>>>  > outer(1:3, 1:2, Vectorize(ssd, c("A", "alpha")), Y, t)
>>>           [,1]     [,2]
>>> [1,] 53.51878 54.92567
>>> [2,] 52.06235 54.85140
>>> [3,] 50.63071 54.77719
>>>  >
>>>
>>> [There are a couple of minor design issues around syntax -- what is 
>>> the best way of specifying the arguments to vectorize? (e.g., what 
>>> about an interface that allowed Vectorize(ssd ~ A * alpha)?), and 
>>> should the function name rather than the definition appear in the 
>>> result of Vectorize()?  But those are issues of secondary importance.]
>>>
>>> I have to confess I don't really understand how environments work with 
>>> functions, so I don't know if this Vectorize() function will work in 
>>> general.  What is the appropriate environment for returned value of 
>>> Vectorize()?  Is this approach to creating a Vectorize() function on 
>>> the right tack at all?  Any other improvements or fixes?
>>>
>>> -- Tony Plate
>>>
>>>
>>> Peter Dalgaard wrote:
>>>
>>>> Thomas Lumley <tlumley at u.washington.edu> writes:
>>>>
>>>>
>>>>> On Sun, 30 Oct 2005, Jonathan Rougier wrote:
>>>>>
>>>>>
>>>>>> I'm not sure about this.  Perhaps I am a dinosaur, but my feeling is
>>>>>> that if people are writing functions in R that might be subject to
>>>>>> simple operations like outer products, then they ought to be writing
>>>>>> vectorised functions!
>>>>>
>>>>>
>>>>> I would agree.  How about an oapply() function that does multiway 
>>>>> (rather than just two-way) outer products.  Basing the name on 
>>>>> "apply" would emphasize the similarity to other flexible, not 
>>>>> particularly optimized second-order functions.
>>>>
>>>>
>>>>
>>>> In fairness, it should probably be said that not all problems
>>>> vectorize naturally. One example is
>>>>
>>>>   ssd <- function(A,alpha) sum((Y - A*exp(-alpha*t))^2)
>>>>
>>>> However, it should be worth noting that with the mapply() function at
>>>> hand, it is pretty easy to turn a non-vectorized function into a
>>>> vectorized one.
>>>>   SSD <- function(A,alpha) mapply(ssd, A, alpha)
>>>>
>>>> (Anybody want to try their hand on writing a general Vectorize()
>>>> function? I.e. one that allowed
>>>>
>>>>    outer(Avec, alphavec, Vectorize(ssd))
>>>>
>>>> to work.)
>>>
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> 
>>
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From tlumley at u.washington.edu  Tue Nov  1 16:16:20 2005
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 1 Nov 2005 07:16:20 -0800 (PST)
Subject: [Rd] [R] unvectorized option for outer()
In-Reply-To: <436778D5.2010800@stats.uwo.ca>
References: <8B08A3A1EA7AAC41BE24C750338754E69FDF14@HERMES.demogr.mpg.de>
	<43629490.9060204@acm.org>
	<971536df0510281643u50929fa6rf097c40948700804@mail.gmail.com>
	<4364A4FC.2030400@durham.ac.uk>
	<Pine.LNX.4.63a.0510301300260.28148@homer23.u.washington.edu>
	<x2y84amyv4.fsf@turmalin.kubism.ku.dk> <43666D4D.7070602@acm.org>
	<4366738C.1080508@stats.uwo.ca> <4366833E.8000508@acm.org>
	<436778D5.2010800@stats.uwo.ca>
Message-ID: <Pine.LNX.4.63a.0511010713550.30147@homer21.u.washington.edu>

On Tue, 1 Nov 2005, Duncan Murdoch wrote:

> The version I posted yesterday did indeed mess up when some arguments were 
> unspecified.  Here's a revision that seems to work in all the tests I can 
> think of.  I also added the SIMPLIFY and USE.NAMES args from mapply to it, 
> and a sanity check to the args.
>
> I did notice and work around one buglet in mapply:  if you choose not to 
> vectorize any arguments, you don't get a call to the original function, 
> mapply returns "list()".
>
> For example,
>
>> mapply(function(x) x^2, MoreArgs = list(x=2))
> list()
>
> whereas I would think 4 is a more logical answer.
>

I don't agree at all.  The answer should be the length of the longest 
vectorised argument, and it is.

 	-thomas


From kin.chan at yale.edu  Tue Nov  1 16:18:53 2005
From: kin.chan at yale.edu (kin.chan@yale.edu)
Date: Tue,  1 Nov 2005 16:18:53 +0100 (CET)
Subject: [Rd] spyware detected (PR#8270)
Message-ID: <20051101151853.CE5C823D20@slim.kubism.ku.dk>

Gentlemen:

I ran a spyware sweep on my computer after installing:

10/07/2005  03:25 PM        27,230,914 R-2.2.0-win32.exe

>From the cran website.

Spy Sweeper 4.0.3 with the latest definition files found

Directory of C:\Program Files\R\R-2.2.0

11/01/2005  09:27 AM           668,938 unins000.exe

To have the golden eye signature.  This is serious if indeed the uninstall
program contains the golden eye monitor program.

Please look into this and update me with developments.

Thank you,

Kin Chan


From jeff at kanecap.com  Tue Nov  1 16:51:33 2005
From: jeff at kanecap.com (Jeff Enos)
Date: Tue, 1 Nov 2005 10:51:33 -0500
Subject: [Rd] S4 classes in existing packages
In-Reply-To: <Pine.LNX.4.61.0511010807170.13190@gannet.stats>
References: <17254.45317.101767.527318@gargle.gargle.HOWL>
	<436720ED.6060807@stamats.de>
	<Pine.LNX.4.61.0511010807170.13190@gannet.stats>
Message-ID: <17255.36613.327599.322881@gargle.gargle.HOWL>

Thanks to Dirk Eddelbuettel, Matthias Kohl, Professor Ripley, and
Bernhard Pfaff for their helpful reponses.

Here is a list of the packages they recommended:

CRAN: distr distrEx distrSim distrTEst RandVar CoCo DBI IDPmisc Matrix
RMySQL ROracle RSQLite RUnit SparseM aod arules boolean coin
colorspace copula deal dynamicGraph fBasics(etc) flexclust flexmix
giRaph gpclib its kappalab kernalb limma lme4 matlab monoProc
orientlib partsm pixmap tuneR urca

R sources: stats4

BoiC: most/all

Which of these are thought (by the community as a whole) to use S4
classes in a method/style that less experienced programmers like me
should try to learn from and emulate?

Thanks,

Jeff

Prof Brian Ripley writes:
 > On Tue, 1 Nov 2005, Matthias Kohl wrote:
 > 
 > > Jeff Enos schrieb:
 > >
 > >> R-devel,
 > >>
 > >> I'm interested in looking at some examples of existing R packages that
 > >> rely heavily on S4 classes to get a feel for varying styles and
 > >> package organization techniques.  Could you recommend any packages
 > >> that might serve as a good starting point?
 > >>
 > >> Thanks in advance,
 > >>
 > >> Jeff
 > >>
 > >>
 > > our packages distr, distrEx, distrSim, distrTEst and RandVar are based
 > > on S4 classes and methods.
 > 
 > As do many others, providing the variety of styles that the questioner 
 > asked for.  Those that are documented to do so include
 > 
 > CoCo DBI IDPmisc Matrix RMySQL ROracle RSQLite RUnit SparseM aod arules 
 > boolean coin colorspace copula deal dynamicGraph fBasics(etc) flexclust 
 > flexmix giRaph gpclib its kappalab kernalb limma lme4 matlab monoProc 
 > orientlib partsm pixmap tuneR
 > 
 > on CRAM, stats4 in the R sources and most (all?) of BioC.
 > 
 > -- 
 > Brian D. Ripley,                  ripley at stats.ox.ac.uk
 > Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
 > University of Oxford,             Tel:  +44 1865 272861 (self)
 > 1 South Parks Road,                     +44 1865 272866 (PA)
 > Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-- 
Jeff Enos
Kane Capital Management
jeff at kanecap.com


From andy_liaw at merck.com  Tue Nov  1 16:55:44 2005
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue, 1 Nov 2005 10:55:44 -0500
Subject: [Rd] S4 classes in existing packages
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED54C@usctmx1106.merck.com>

Fritz gave a talk on S4 using pixmap as example at useR! 2004.  You might
want to start with that.  The slides should be on the useR! 2004 web site.

Andy

> From: Jeff Enos
> 
> Thanks to Dirk Eddelbuettel, Matthias Kohl, Professor Ripley, and
> Bernhard Pfaff for their helpful reponses.
> 
> Here is a list of the packages they recommended:
> 
> CRAN: distr distrEx distrSim distrTEst RandVar CoCo DBI IDPmisc Matrix
> RMySQL ROracle RSQLite RUnit SparseM aod arules boolean coin
> colorspace copula deal dynamicGraph fBasics(etc) flexclust flexmix
> giRaph gpclib its kappalab kernalb limma lme4 matlab monoProc
> orientlib partsm pixmap tuneR urca
> 
> R sources: stats4
> 
> BoiC: most/all
> 
> Which of these are thought (by the community as a whole) to use S4
> classes in a method/style that less experienced programmers like me
> should try to learn from and emulate?
> 
> Thanks,
> 
> Jeff
> 
> Prof Brian Ripley writes:
>  > On Tue, 1 Nov 2005, Matthias Kohl wrote:
>  > 
>  > > Jeff Enos schrieb:
>  > >
>  > >> R-devel,
>  > >>
>  > >> I'm interested in looking at some examples of existing 
> R packages that
>  > >> rely heavily on S4 classes to get a feel for varying styles and
>  > >> package organization techniques.  Could you recommend 
> any packages
>  > >> that might serve as a good starting point?
>  > >>
>  > >> Thanks in advance,
>  > >>
>  > >> Jeff
>  > >>
>  > >>
>  > > our packages distr, distrEx, distrSim, distrTEst and 
> RandVar are based
>  > > on S4 classes and methods.
>  > 
>  > As do many others, providing the variety of styles that 
> the questioner 
>  > asked for.  Those that are documented to do so include
>  > 
>  > CoCo DBI IDPmisc Matrix RMySQL ROracle RSQLite RUnit 
> SparseM aod arules 
>  > boolean coin colorspace copula deal dynamicGraph 
> fBasics(etc) flexclust 
>  > flexmix giRaph gpclib its kappalab kernalb limma lme4 
> matlab monoProc 
>  > orientlib partsm pixmap tuneR
>  > 
>  > on CRAM, stats4 in the R sources and most (all?) of BioC.
>  > 
>  > -- 
>  > Brian D. Ripley,                  ripley at stats.ox.ac.uk
>  > Professor of Applied Statistics,  
> http://www.stats.ox.ac.uk/~ripley/
>  > University of Oxford,   
>           Tel:  +44 1865 272861 (self)
>  > 1 South Parks Road,                     +44 1865 272866 (PA)
>  > Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 
> -- 
> Jeff Enos
> Kane Capital Management
> jeff at kanecap.com
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
>


From murdoch at stats.uwo.ca  Tue Nov  1 16:56:54 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue, 01 Nov 2005 10:56:54 -0500
Subject: [Rd] [R] unvectorized option for outer()
In-Reply-To: <Pine.LNX.4.63a.0511010713550.30147@homer21.u.washington.edu>
References: <8B08A3A1EA7AAC41BE24C750338754E69FDF14@HERMES.demogr.mpg.de>	<43629490.9060204@acm.org>	<971536df0510281643u50929fa6rf097c40948700804@mail.gmail.com>	<4364A4FC.2030400@durham.ac.uk>	<Pine.LNX.4.63a.0510301300260.28148@homer23.u.washington.edu>	<x2y84amyv4.fsf@turmalin.kubism.ku.dk>
	<43666D4D.7070602@acm.org>	<4366738C.1080508@stats.uwo.ca>
	<4366833E.8000508@acm.org>	<436778D5.2010800@stats.uwo.ca>
	<Pine.LNX.4.63a.0511010713550.30147@homer21.u.washington.edu>
Message-ID: <43679046.10209@stats.uwo.ca>

On 11/1/2005 10:16 AM, Thomas Lumley wrote:
> On Tue, 1 Nov 2005, Duncan Murdoch wrote:
> 
>> The version I posted yesterday did indeed mess up when some arguments were 
>> unspecified.  Here's a revision that seems to work in all the tests I can 
>> think of.  I also added the SIMPLIFY and USE.NAMES args from mapply to it, 
>> and a sanity check to the args.
>>
>> I did notice and work around one buglet in mapply:  if you choose not to 
>> vectorize any arguments, you don't get a call to the original function, 
>> mapply returns "list()".
>>
>> For example,
>>
>>> mapply(function(x) x^2, MoreArgs = list(x=2))
>> list()
>>
>> whereas I would think 4 is a more logical answer.
>>
> 
> I don't agree at all.  The answer should be the length of the longest 
> vectorised argument, and it is.

I do agree that if I'd specified something like

mapply(function(x) x^2, x=numeric(0))

then the answer (which is again list()) would be correct.  But
what is the length of the longest item in an empty set?  I'd say it's 
undefined.

Duncan Murdoch


From murdoch at stats.uwo.ca  Tue Nov  1 17:06:43 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue, 01 Nov 2005 11:06:43 -0500
Subject: [Rd] spyware detected (PR#8270)
In-Reply-To: <20051101151853.CE5C823D20@slim.kubism.ku.dk>
References: <20051101151853.CE5C823D20@slim.kubism.ku.dk>
Message-ID: <43679293.5020208@stats.uwo.ca>

On 11/1/2005 10:18 AM, kin.chan at yale.edu wrote:
> Gentlemen:
> 
> I ran a spyware sweep on my computer after installing:
> 
> 10/07/2005  03:25 PM        27,230,914 R-2.2.0-win32.exe
> 
>>From the cran website.
> 
> Spy Sweeper 4.0.3 with the latest definition files found
> 
> Directory of C:\Program Files\R\R-2.2.0
> 
> 11/01/2005  09:27 AM           668,938 unins000.exe
> 
> To have the golden eye signature.  This is serious if indeed the uninstall
> program contains the golden eye monitor program.
> 
> Please look into this and update me with developments.

unins000.exe is the uninstaller for R.  If your "Spy Sweeper" thinks 
there's something wrong with it, you'll have to tell us what.

According to Symantec's web site

http://securityresponse.symantec.com/avcenter/venc/data/spyware.goldeneye.html

the spyware "adds the value:

"AGSeyApp"="<installation path>\AGSeyApp.exe"

to the following registry key:

HKEY_LOCAL_MACHINE\Software\Microsoft\Windows\CurrentVersion\Run

so that the spyware runs when you start Windows."

I don't see that registry key in the machine that built the installer, 
so this looks like a false alarm.  If I were you I'd contact the writers 
of "Spy Sweeper" with a bug report.

Duncan Murdoch


From beissbarth at wehi.edu.au  Tue Nov  1 18:36:04 2005
From: beissbarth at wehi.edu.au (beissbarth@wehi.edu.au)
Date: Tue,  1 Nov 2005 18:36:04 +0100 (CET)
Subject: [Rd] strsplit ignores empty fields (PR#8271)
Message-ID: <20051101173604.5D89D23D14@slim.kubism.ku.dk>

Full_Name: Tim Beissbarth
Version: 2.2.0
OS: Windows
Submission from: (NULL) (193.174.58.254)


strsplit ignores empty strings at the end. 

> strsplit(paste(c("", "a", ""), collapse="#"), split="#", fixed=TRUE)
[[1]]
[1] ""  "a"

This should really give:
[1] ""  "a"  ""

Some might say this is a feature, but strsplit should be the reverse of paste, I
think.


From ggrothendieck at gmail.com  Tue Nov  1 19:05:31 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 1 Nov 2005 13:05:31 -0500
Subject: [Rd] strsplit ignores empty fields (PR#8271)
In-Reply-To: <20051101173604.5D89D23D14@slim.kubism.ku.dk>
References: <20051101173604.5D89D23D14@slim.kubism.ku.dk>
Message-ID: <971536df0511011005j54e968a1x735cc61f3e4893f6@mail.gmail.com>

A workaround would be to append # onto the end of the string:

> s <- c("abc#def", "abc#", "#def")
> ss <- paste(s, "#", sep = "")
> strsplit(ss, "#")
[[1]]
[1] "abc" "def"

[[2]]
[1] "abc" ""

[[3]]
[1] ""    "def"


On 11/1/05, beissbarth at wehi.edu.au <beissbarth at wehi.edu.au> wrote:
> Full_Name: Tim Beissbarth
> Version: 2.2.0
> OS: Windows
> Submission from: (NULL) (193.174.58.254)
>
>
> strsplit ignores empty strings at the end.
>
> > strsplit(paste(c("", "a", ""), collapse="#"), split="#", fixed=TRUE)
> [[1]]
> [1] ""  "a"
>
> This should really give:
> [1] ""  "a"  ""
>
> Some might say this is a feature, but strsplit should be the reverse of paste, I
> think.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From davison at uchicago.edu  Tue Nov  1 22:12:30 2005
From: davison at uchicago.edu (davison@uchicago.edu)
Date: Tue,  1 Nov 2005 22:12:30 +0100 (CET)
Subject: [Rd] Im() of negative non-complex numbers is pi (PR#8272)
Message-ID: <20051101211230.F39D323D22@slim.kubism.ku.dk>

Hi,

I think the following indicates a bug in Im().

> Im(-1)
[1] 3.141592653589793115998
> pi
[1] 3.141592653589793115998
> Im(0i-1)
[1] 0
> Im(-0.9876)
[1] 3.141592653589793115998
> Im(-987654321)
[1] 3.141592653589793115998
> Im(1)
[1] 0
> is.complex(-1)
[1] FALSE

This is R 2.2.0; Im(-1) == 0 with R 2.2.1.

Thanks,

Dan

> version
          _
platform i386-pc-linux-gnu
arch     i386
os       linux-gnu
system   i386, linux-gnu
status
major    2
minor    2.0
year     2005
month    10
day      06
svn rev  35749
language R

Debian (stable) linux


From davison at uchicago.edu  Tue Nov  1 22:47:39 2005
From: davison at uchicago.edu (davison@uchicago.edu)
Date: Tue,  1 Nov 2005 22:47:39 +0100 (CET)
Subject: [Rd] Im() of negative non-complex numbers is pi (PR#8272)
Message-ID: <20051101214739.C8E3623D24@slim.kubism.ku.dk>


Sorry, I meant to write 2.1.1 instead of 2.2.1 below.


On Tue, 1 Nov 2005 davison at uchicago.edu wrote:

> Hi,
>
> I think the following indicates a bug in Im().
>
>> Im(-1)
> [1] 3.141592653589793115998
>> pi
> [1] 3.141592653589793115998
>> Im(0i-1)
> [1] 0
>> Im(-0.9876)
> [1] 3.141592653589793115998
>> Im(-987654321)
> [1] 3.141592653589793115998
>> Im(1)
> [1] 0
>> is.complex(-1)
> [1] FALSE
>
> This is R 2.2.0; Im(-1) == 0 with R 2.2.1.
>
> Thanks,
>
> Dan
>
>> version
>          _
> platform i386-pc-linux-gnu
> arch     i386
> os       linux-gnu
> system   i386, linux-gnu
> status
> major    2
> minor    2.0
> year     2005
> month    10
> day      06
> svn rev  35749
> language R
>
> Debian (stable) linux
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From ripley at stats.ox.ac.uk  Tue Nov  1 23:08:16 2005
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Tue,  1 Nov 2005 23:08:16 +0100 (CET)
Subject: [Rd] Im() of negative non-complex numbers is pi (PR#8272)
Message-ID: <20051101220816.A814423D24@slim.kubism.ku.dk>

On Tue, 1 Nov 2005 davison at uchicago.edu wrote:

> Sorry, I meant to write 2.1.1 instead of 2.2.1 below.

OK, but it was changed in 2.1.1 patched so one needs to be precise.

We used to have Arg=Im for such numbers and Arg was wrong, then Im was 
wrong (and now both are correct in 2.2.0 patched).

> On Tue, 1 Nov 2005 davison at uchicago.edu wrote:
>
>> Hi,
>>
>> I think the following indicates a bug in Im().
>>
>>> Im(-1)
>> [1] 3.141592653589793115998
>>> pi
>> [1] 3.141592653589793115998
>>> Im(0i-1)
>> [1] 0
>>> Im(-0.9876)
>> [1] 3.141592653589793115998
>>> Im(-987654321)
>> [1] 3.141592653589793115998
>>> Im(1)
>> [1] 0
>>> is.complex(-1)
>> [1] FALSE
>>
>> This is R 2.2.0; Im(-1) == 0 with R 2.2.1.
>>
>> Thanks,
>>
>> Dan
>>
>>> version
>>          _
>> platform i386-pc-linux-gnu
>> arch     i386
>> os       linux-gnu
>> system   i386, linux-gnu
>> status
>> major    2
>> minor    2.0
>> year     2005
>> month    10
>> day      06
>> svn rev  35749
>> language R
>>
>> Debian (stable) linux
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ch-r at bobobeach.com  Wed Nov  2 01:57:09 2005
From: ch-r at bobobeach.com (ch-r@bobobeach.com)
Date: Wed,  2 Nov 2005 01:57:09 +0100 (CET)
Subject: [Rd] Documentation error in online help for print.data.frame
	(PR#8273)
Message-ID: <20051102005709.39C5223D18@slim.kubism.ku.dk>

Full_Name: Cyrus Harmon
Version: 2.3.0 devel
OS: Mac OS X 10.4.3
Submission from: (NULL) (169.229.10.51)


The Usage in the print.data.frame help page says:

print(x, ..., digits=NULL, quote=FALSE, right=TRUE)

meanwhile, down in the Arguments section it says:

  right: logical, indicating whether or not strings should be
           right-aligned. The default is left-alignment.

This seems to be at odds with the right=TRUE in the Usage, and with what I see
when I print a data.frame.


From murdoch at stats.uwo.ca  Wed Nov  2 02:14:51 2005
From: murdoch at stats.uwo.ca (murdoch@stats.uwo.ca)
Date: Wed,  2 Nov 2005 02:14:51 +0100 (CET)
Subject: [Rd] Documentation error in online help for print.data.frame
	(PR#8274)
Message-ID: <20051102011451.9C66823D15@slim.kubism.ku.dk>

ch-r at bobobeach.com wrote:
> Full_Name: Cyrus Harmon
> Version: 2.3.0 devel
> OS: Mac OS X 10.4.3
> Submission from: (NULL) (169.229.10.51)
> 
> 
> The Usage in the print.data.frame help page says:
> 
> print(x, ..., digits=NULL, quote=FALSE, right=TRUE)
> 
> meanwhile, down in the Arguments section it says:
> 
>   right: logical, indicating whether or not strings should be
>            right-aligned. The default is left-alignment.
> 
> This seems to be at odds with the right=TRUE in the Usage, and with what I see
> when I print a data.frame.

Fixed in R-devel.

Duncan Murdoch


From murdoch at stats.uwo.ca  Wed Nov  2 02:14:44 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue, 01 Nov 2005 20:14:44 -0500
Subject: [Rd] Documentation error in online help for print.data.frame
 (PR#8273)
In-Reply-To: <20051102005709.39C5223D18@slim.kubism.ku.dk>
References: <20051102005709.39C5223D18@slim.kubism.ku.dk>
Message-ID: <43681304.8040903@stats.uwo.ca>

ch-r at bobobeach.com wrote:
> Full_Name: Cyrus Harmon
> Version: 2.3.0 devel
> OS: Mac OS X 10.4.3
> Submission from: (NULL) (169.229.10.51)
> 
> 
> The Usage in the print.data.frame help page says:
> 
> print(x, ..., digits=NULL, quote=FALSE, right=TRUE)
> 
> meanwhile, down in the Arguments section it says:
> 
>   right: logical, indicating whether or not strings should be
>            right-aligned. The default is left-alignment.
> 
> This seems to be at odds with the right=TRUE in the Usage, and with what I see
> when I print a data.frame.

Fixed in R-devel.

Duncan Murdoch


From john.maindonald at anu.edu.au  Wed Nov  2 07:44:03 2005
From: john.maindonald at anu.edu.au (john.maindonald@anu.edu.au)
Date: Wed,  2 Nov 2005 07:44:03 +0100 (CET)
Subject: [Rd] Bugs/issues with model.tables() (PR#8275)
Message-ID: <20051102064403.D57D822152@slim.kubism.ku.dk>

Based on what follows, the most favourable construction is that
the documentation, by failing to say that the function should be
used only for completely balanced designs, is deficient.  Even
for such designs, there is a bug that needs correction. The
discussion is lengthy because I think it important to document,
at least wrt effects and means, exactly what model.tables()
does.

My preference is to pension model.tables() off, and to replace
it with the function that I describe (but do not, at this point,
reproduce) below.  Basically, for getting the means or effects,
my function replaces the call to proj() with a call to
predict.lm(.., type="terms"). The SEs for effects can also be
obtained using predict.lm().  For getting SEs of differences of
treatment means, the SEs that appear from summary.lm() can be
used.  Such a function will apply quite generally to models that
include only main effects.  This is surely a matter for
discussion and comment, especially as model.tables() has been
around since nearly the beginning of R time.

Summary
~~~~~~~
Under "Description:" there is the claim:
      Computes summary tables for model fits, especially complex 'aov'
      fits.

The warning that appears some way further down is perhaps intended
to weaken the force of this:

      The implementation is incomplete, and only the simpler cases have
      been tested thoroughly.

The implementation is useful only for balanced complete designs.
The documentation should say this.

In (I), I summarize issues with model.tables()
In (II), I give examples, which can be extended to verify points
that the output below does not specifically illustrate.

I (a) Even for balanced designs, the SEs for the effects are wrong.
I give an example below.

I (b) model.tables() works from a sequential breakdown of the
predicted values. In a model with factors A and B, with A fitted
first, model.tables() calculates effects for A, unadjusted for B,
then effects for B after adjusting for A.  If every combination
of A and B occurs equally often (a completely balanced design),
the order makes no difference.  If the design is not completely
balanced, then the order does matter, and the "effects" will not
be unbiased estimates of the treatment effects.  Nor will their
differences be unbiased estimates of the treatment differences.
This is true even for balanced incomplete block designs.

Means are obtained by adding "effects", calculated as just described,
to the overall mean.

The only hint on the help page that so-called "effects" and
"means" relate to such a sequential breakdown of predicted values
is the reference, under "See also", to proj. Under help(proj), it
is written:

      Projection matrices from the default
      method have orthogonal columns representing the projection of the
      response onto the column space of the Q matrix from the QR
      decomposition.

For those who know about QR, this immediatly flags a sequential
breakdown of the fitted values.

I (c) Standard errors for effects seeem to have in mind a formula
that (with a correction that will be noted below) applies only in
the completely balanced case.

I (d) Standard errors for differences of means (SEDs) seem to be
correct for completely balanced designs.  For BIB designs they
are independent of the order of terms, even though the "effects"
and "means" are not. They are in general wrong, even for the
"means" as given.

A correct order independent breakdown of the fitted values can be
obtained by replacing, in model.tables(), the call to proj() with
a call to predict.lm(.., type="terms").  [This requires a bit
more than a simple replacement.]  The means and effects are,
quite generally, the means and expects that most users will want.
Once I have worked over the code with some care, and sorted out
the caculation of SEs, I will offer this function for inclusion
in R's stats package.  Or I am happy to provide the current
draft of my function to anyone who wants to look at it.

II: Further Details, and Examples:

(a) For calculations of SEs for effects, model.tables.aov() calls
se.aov(), which uses the formula:
   s/sqrt(n)  [the mean is over n subunits]

The formula required, in the completely balanced case, is
   sqrt((m-1)/m)*s/sqrt(n) formula
[an effect is a mean over n subunits, minus the grand mean;
the grand mean is a mean over mn units.]

Often, m is large enough that the difference is of no consequence.
Also, the SEs of effects are commonly of little more than academic
interest.  But, if given at all, they should be correct.

Example
"bal1" <-
   structure(list(y = c(3.1, 2.4, 2.2, 2.3, 1.9, 0.9, 1.8, 1.1),
                  trt = structure(as.integer(c(1, 1, 2, 2, 3, 3, 4, 4)),
                    .Label = c("a", "b", "c", "d"), class = "factor")),
             .Names = c("y", "trt"),
             row.names = c("1", "2", "3", "4", "5", "6", "7", "8"),
             class = "data.frame")
 > model.tables(bal1.aov, type="effects", se=TRUE)$se
       trt
0.3526684
 > summary.lm(u)$sigma/sqrt(2)*sqrt(3/4)  # m=4
[1] 0.3054198
"
 > unique(predict.lm(bal1.aov, type="terms", se=TRUE)$se)
         trt
1 0.3054198

II (d) In the interests of brevity (sic!), I will limit attention
to means:

"bdes" <-
   structure(list(trt = structure(as.integer(c(1, 2, 1, 3, 1, 4,
                    2, 3, 2, 4, 3, 4)), .Label = c("a", "b", "c", "d"),
                    class = "factor"),
                  blk = structure(as.integer(c(1, 1, 2, 2, 3, 3, 4,  
4, 5, 5,
                    6, 6)), .Label = c("A", "B", "C", "D", "E", "F"),
                    class = "factor"),
                  y = c(0.8, -1.1, 4.5, 3.3, 4.3, 4.9, 0.6, 3.9, 4.6,  
9.4,
                    3.7, 5.7)), .Names = c("trt", "blk", "y"),
             row.names = c("1","2", "3", "4", "5", "6", "7", "8",  
"9", "10",
               "11", "12"), class = "data.frame")
 > # Crude block means; these are meaningless
 > tapply(bdes$y, bdes$blk, mean)
     A     B     C     D     E     F
-0.15  3.90  4.60  2.25  7.00  4.70
 > # Crude treatment means
 > tapply(bdes$y, bdes$trt, mean)
        a        b        c        d
3.200000 1.366667 3.633333 6.666667
 > ## aov fits
 > bdes.aov <- aov(y~blk+trt, data=bdes)  # Blocks first
 > bdes_trtFirst.aov <- aov(y~trt+blk, data=bdes) # trt first
 > model.tables(bdes.aov, type="means")[["table"]][["blk"]]
blk
     A     B     C     D     E     F
-0.15  3.90  4.60  2.25  7.00  4.70
 >   # Observe that these agree with the above crude block means
 > model.tables(bdes_trtFirst.aov, type="means")[["table"]][["trt"]]
trt
        a        b        c        d
3.200000 1.366667 3.633333 6.666667
 >
 > ## Treatment means, when blocks are taken first
 > model.tables(bdes.aov, type="means")[["table"]][["trt"]]
trt
        a        b        c        d
4.133333 2.050000 3.733333 4.950000
 > ## Also, note their differences
 > diff(model.tables(bdes.aov, type="means")[["table"]][["trt"]])
trt
         b         c         d
-2.083333  1.683333  1.216667

 > ## Treatment means, from the "usual" least squares analysis
 > dummy.coef(bdes.aov)[["(Intercept)"]]
(Intercept)
      1.4125
 > dummy.coef(bdes.aov)[["(Intercept)"]]+mean(dummy.coef(bdes.aov)$blk)+
+ dummy.coef(bdes.aov)$trt
        a        b        c        d
4.341667 1.216667 3.741667 5.566667
 > diff(dummy.coef(bdes.aov)$trt)
      b      c      d
-3.125  2.525  1.825
 > diff(model.tables(bdes.aov, type="means")[["table"]][["trt"]])/
+ diff(dummy.coef(bdes.aov)$trt)
trt
         b         c         d
0.6666667 0.6666667 0.6666667
 >  # This factor is some simple function of the BIB design parameters,
 >  # which I am too lazy or too busy to work out.


--please do not edit the information below--

Version:
platform = powerpc-apple-darwin7.9.0
arch = powerpc
os = darwin7.9.0
system = powerpc, darwin7.9.0
status =
major = 2
minor = 2.0
year = 2005
month = 10
day = 06
svn rev = 35749
language = R

Locale:
C

Search Path:
.GlobalEnv, cuckoohosts, file:~/r/ch2/.RData, file:../.RData,  
package:methods, package:stats, package:graphics, package:grDevices,  
package:utils, package:datasets, Autoloads, package:base



John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Bioinformation Science, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.


From rob at aetiologic.ca  Wed Nov  2 17:19:20 2005
From: rob at aetiologic.ca (rob@aetiologic.ca)
Date: Wed,  2 Nov 2005 17:19:20 +0100 (CET)
Subject: [Rd] configure error under  FC 4 64 bit (PR#8276)
Message-ID: <20051102161920.617E523D25@slim.kubism.ku.dk>

Full_Name: Rob James
Version: 2.2.0
OS: Fedora Core 4 64 Bit
Submission from: (NULL) (24.79.225.106)


Attempting to run the configure script yields the following inscrutable error:


configure: error: --with-readline=yes (default) and headers/libs are not
available


This occurs at the following point in the processing of the configure script:

checking for readline/history.h... no
checking readline/readline.h usability... no
checking readline/readline.h presence... no
checking for readline/readline.h... no
checking for rl_callback_read_char in -lreadline... no
checking for main in -lncurses... yes
checking for rl_callback_read_char in -lreadline... no
checking for history_truncate_file... no


Any suggestions?

Thanks,


From p.dalgaard at biostat.ku.dk  Wed Nov  2 17:28:22 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 02 Nov 2005 17:28:22 +0100
Subject: [Rd] configure error under  FC 4 64 bit (PR#8276)
In-Reply-To: <20051102161920.617E523D25@slim.kubism.ku.dk>
References: <20051102161920.617E523D25@slim.kubism.ku.dk>
Message-ID: <x21x1zggk9.fsf@viggo.kubism.ku.dk>

rob at aetiologic.ca writes:

> Full_Name: Rob James
> Version: 2.2.0
> OS: Fedora Core 4 64 Bit
> Submission from: (NULL) (24.79.225.106)
> 
> 
> Attempting to run the configure script yields the following inscrutable error:
> 
> 
> configure: error: --with-readline=yes (default) and headers/libs are not
> available
> 
> 
> This occurs at the following point in the processing of the configure script:
> 
> checking for readline/history.h... no
> checking readline/readline.h usability... no
> checking readline/readline.h presence... no
> checking for readline/readline.h... no
> checking for rl_callback_read_char in -lreadline... no
> checking for main in -lncurses... yes
> checking for rl_callback_read_char in -lreadline... no
> checking for history_truncate_file... no
> 
> 
> Any suggestions?

Yes.

(a) read http://cran.r-project.org/doc/manuals/R-admin.html,
especially the section C1, platform notes for Linux

(b) also read the section on what is a bug and what is not a bug in
http://www.ci.tuwien.ac.at/~hornik/R/R-FAQ.html#R%20Bugs 

(c) If you are that new to compiling R on FC4, why not use the RPMs
from Fedora Extra?

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From murdoch at stats.uwo.ca  Wed Nov  2 19:55:22 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Wed, 02 Nov 2005 13:55:22 -0500
Subject: [Rd] unvectorized option for outer()
In-Reply-To: <43629490.9060204@acm.org>
References: <8B08A3A1EA7AAC41BE24C750338754E69FDF14@HERMES.demogr.mpg.de>
	<43629490.9060204@acm.org>
Message-ID: <43690B9A.4040102@stats.uwo.ca>

I've now added a version of Vectorize to R-devel.

Duncan


From mpiktas at gmail.com  Thu Nov  3 09:37:21 2005
From: mpiktas at gmail.com (mpiktas@gmail.com)
Date: Thu,  3 Nov 2005 09:37:21 +0100 (CET)
Subject: [Rd] shared-mime-info (PR#8278)
Message-ID: <20051103083721.1A3D72361F@slim.kubism.ku.dk>

Full_Name: Vaidotas Zemlys
Version: 2.1.1
OS: Ubuntu 05.10
Submission from: (NULL) (213.197.173.50)


Hi,

This is really a feature request, not a bug. I wrote the mail to R-devel, 
but nobody answered it. 

I use Gnome on my computer and sometimes I use its default text editor
gedit. It uses gtksourceview library for syntax highlighting. I
decided that it would be nice if gedit supported R syntax. So I
created apropriate .lang file:
http://bugzilla.gnome.org/show_bug.cgi?id=157370

Gedit picks apropriate lang file according to file mimetype, so I
created apropriate mime type for files with extension .R. I filed a bug
report at freedesktop.org:
https://freedesktop.org/bugzilla/show_bug.cgi?id=1782

There Christophe Fergeau suggested that maybe R could take care of
installing this mime type by itself. Is it possible? As I understand it would
only concern Linux installations and R should cooperate with shared-mime-info
package which is responsible for all mime type definitions.

Vaidotas Zemlys


From ripley at stats.ox.ac.uk  Thu Nov  3 10:21:28 2005
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Thu,  3 Nov 2005 10:21:28 +0100 (CET)
Subject: [Rd] shared-mime-info (PR#8278)
Message-ID: <20051103092128.288C823892@slim.kubism.ku.dk>

We do not usually put features in R which are specific to just some 
distributions of some OSes, and in this case to one editor on those.
We do not for example include the ESS mode for the much-more-widely-used 
Emacs family of editors.

This looks as if it might be appropriate to the Linux binary packages for 
R, so I suggest you contact their maintainers.  But my understanding is 
that this is an issue for gedit and not for R.  Indeed .R is just a 
convention (one of many choices, including .r and .q) for R itself.

I do wonder why you concentrated on .R files and not .Rd files, where I 
find syntax highlighting more useful.

On Thu, 3 Nov 2005 mpiktas at gmail.com wrote:

> Full_Name: Vaidotas Zemlys
> Version: 2.1.1
> OS: Ubuntu 05.10
> Submission from: (NULL) (213.197.173.50)
>
>
> Hi,
>
> This is really a feature request, not a bug. I wrote the mail to R-devel,
> but nobody answered it.

That's generally a sign of lack of interest, and also in your case that 
you fail to sign your emails, a basic courtesy especially for people using 
an anonymous email address.

> I use Gnome on my computer and sometimes I use its default text editor
> gedit. It uses gtksourceview library for syntax highlighting. I
> decided that it would be nice if gedit supported R syntax. So I
> created apropriate .lang file:
> http://bugzilla.gnome.org/show_bug.cgi?id=157370
>
> Gedit picks apropriate lang file according to file mimetype, so I
> created apropriate mime type for files with extension .R. I filed a bug
> report at freedesktop.org:
> https://freedesktop.org/bugzilla/show_bug.cgi?id=1782
>
> There Christophe Fergeau suggested that maybe R could take care of
> installing this mime type by itself. Is it possible? As I understand it would
> only concern Linux installations and R should cooperate with shared-mime-info
> package which is responsible for all mime type definitions.
>
> Vaidotas Zemlys

NB: signature missing

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From p.dalgaard at biostat.ku.dk  Thu Nov  3 12:41:53 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 03 Nov 2005 12:41:53 +0100
Subject: [Rd] shared-mime-info (PR#8278)
In-Reply-To: <20051103092128.288C823892@slim.kubism.ku.dk>
References: <20051103092128.288C823892@slim.kubism.ku.dk>
Message-ID: <x2u0euufem.fsf@viggo.kubism.ku.dk>

ripley at stats.ox.ac.uk writes:

> We do not usually put features in R which are specific to just some 
> distributions of some OSes, and in this case to one editor on those.
> We do not for example include the ESS mode for the much-more-widely-used 
> Emacs family of editors.
> 
> This looks as if it might be appropriate to the Linux binary packages for 
> R, so I suggest you contact their maintainers.  But my understanding is 
> that this is an issue for gedit and not for R.  Indeed .R is just a 
> convention (one of many choices, including .r and .q) for R itself.
> 
> I do wonder why you concentrated on .R files and not .Rd files, where I 
> find syntax highlighting more useful.

Mime-types shouldn't be distribution-specific or even editor-specific,
should they? The whole point is that they can be used for things like
email attachments that pass from one OS to the other.

It might be useful to have the mime-type definitions for R (and Rd)
files centralized in R core, with the appropriate OS conventions
systematized. But I think we need to know more. Who keeps track of
mime-types? Can we just grab text/x-R (and text/x-Rd and
application/x-Rdata)? To which extent the XML format a standard; is it
only used by particular applications?



> On Thu, 3 Nov 2005 mpiktas at gmail.com wrote:
> 
> > Full_Name: Vaidotas Zemlys
> > Version: 2.1.1
> > OS: Ubuntu 05.10
> > Submission from: (NULL) (213.197.173.50)
.....

> >
> > Vaidotas Zemlys
> 
> NB: signature missing

Er, it came in via the rbugs web interface. We don't usually get
.sig's added to those. We had dozens of messages from VZ on the
regular mail lists, all without a formal .sig, so this would seem to
be the least appropriate time to complain.

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From ripley at stats.ox.ac.uk  Thu Nov  3 13:14:22 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 3 Nov 2005 12:14:22 +0000 (GMT)
Subject: [Rd] shared-mime-info (PR#8278)
In-Reply-To: <x2u0euufem.fsf@viggo.kubism.ku.dk>
References: <20051103092128.288C823892@slim.kubism.ku.dk>
	<x2u0euufem.fsf@viggo.kubism.ku.dk>
Message-ID: <Pine.LNX.4.61.0511031212360.447@gannet.stats>

On Thu, 3 Nov 2005, Peter Dalgaard wrote:

> ripley at stats.ox.ac.uk writes:
>
>> We do not usually put features in R which are specific to just some
>> distributions of some OSes, and in this case to one editor on those.
>> We do not for example include the ESS mode for the much-more-widely-used
>> Emacs family of editors.
>>
>> This looks as if it might be appropriate to the Linux binary packages for
>> R, so I suggest you contact their maintainers.  But my understanding is
>> that this is an issue for gedit and not for R.  Indeed .R is just a
>> convention (one of many choices, including .r and .q) for R itself.
>>
>> I do wonder why you concentrated on .R files and not .Rd files, where I
>> find syntax highlighting more useful.
>
> Mime-types shouldn't be distribution-specific or even editor-specific,
> should they? The whole point is that they can be used for things like
> email attachments that pass from one OS to the other.

AFAIK, the way to register them is distribution-specific.

> It might be useful to have the mime-type definitions for R (and Rd)
> files centralized in R core, with the appropriate OS conventions
> systematized. But I think we need to know more. Who keeps track of
> mime-types? Can we just grab text/x-R (and text/x-Rd and
> application/x-Rdata)? To which extent the XML format a standard; is it
> only used by particular applications?
>
>
>
>> On Thu, 3 Nov 2005 mpiktas at gmail.com wrote:
>>
>>> Full_Name: Vaidotas Zemlys
>>> Version: 2.1.1
>>> OS: Ubuntu 05.10
>>> Submission from: (NULL) (213.197.173.50)
> .....
>
>>>
>>> Vaidotas Zemlys
>>
>> NB: signature missing
>
> Er, it came in via the rbugs web interface. We don't usually get
> .sig's added to those. We had dozens of messages from VZ on the
> regular mail lists, all without a formal .sig, so this would seem to
> be the least appropriate time to complain.
>
> -- 
>   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
>  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
> (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From mpiktas at gmail.com  Thu Nov  3 13:56:15 2005
From: mpiktas at gmail.com (Vaidotas Zemlys)
Date: Thu, 3 Nov 2005 14:56:15 +0200
Subject: [Rd] shared-mime-info (PR#8278)
In-Reply-To: <x2u0euufem.fsf@viggo.kubism.ku.dk>
References: <20051103092128.288C823892@slim.kubism.ku.dk>
	<x2u0euufem.fsf@viggo.kubism.ku.dk>
Message-ID: <e47808320511030456md740f13xddfc65322f9b1d6d@mail.gmail.com>

Hi,

On 03 Nov 2005 12:41:53 +0100, Peter Dalgaard <p.dalgaard at biostat.ku.dk> wrote:
> ripley at stats.ox.ac.uk writes:
>
> > We do not usually put features in R which are specific to just some
> > distributions of some OSes, and in this case to one editor on those.
> > We do not for example include the ESS mode for the much-more-widely-used
> > Emacs family of editors.
> >
> > This looks as if it might be appropriate to the Linux binary packages for
> > R, so I suggest you contact their maintainers.  But my understanding is
> > that this is an issue for gedit and not for R.  Indeed .R is just a
> > convention (one of many choices, including .r and .q) for R itself.
> >
> > I do wonder why you concentrated on .R files and not .Rd files, where I
> > find syntax highlighting more useful.
>
> Mime-types shouldn't be distribution-specific or even editor-specific,
> should they? The whole point is that they can be used for things like
> email attachments that pass from one OS to the other.
>
> It might be useful to have the mime-type definitions for R (and Rd)
> files centralized in R core, with the appropriate OS conventions
> systematized. But I think we need to know more. Who keeps track of
> mime-types? Can we just grab text/x-R (and text/x-Rd and
> application/x-Rdata)? To which extent the XML format a standard; is it
> only used by particular applications?
>
>
As far as I know, at least in Debian, the mimetypes are tracked by
shared-mime-info package. The upstream is freedesktop.org. I do not
know about oficial standarts, but Gnome and KDE tries to adher to some
of the freedesktop.org standarts. I can confirm that mimetypes
provided by shared-mime-info are widely used in Gnome, for some time
now.

Vaidotas Zemlys
--
Doctorate student, http://www.mif.vu.lt/katedros/eka/katedra/zemlys.php
Vilnius University


From mpiktas at gmail.com  Thu Nov  3 13:56:34 2005
From: mpiktas at gmail.com (mpiktas@gmail.com)
Date: Thu,  3 Nov 2005 13:56:34 +0100 (CET)
Subject: [Rd] shared-mime-info (PR#8278)
Message-ID: <20051103125634.1B15F24722@slim.kubism.ku.dk>

Hi,

On 03 Nov 2005 12:41:53 +0100, Peter Dalgaard <p.dalgaard at biostat.ku.dk> wr=
ote:
> ripley at stats.ox.ac.uk writes:
>
> > We do not usually put features in R which are specific to just some
> > distributions of some OSes, and in this case to one editor on those.
> > We do not for example include the ESS mode for the much-more-widely-use=
d
> > Emacs family of editors.
> >
> > This looks as if it might be appropriate to the Linux binary packages f=
or
> > R, so I suggest you contact their maintainers.  But my understanding is
> > that this is an issue for gedit and not for R.  Indeed .R is just a
> > convention (one of many choices, including .r and .q) for R itself.
> >
> > I do wonder why you concentrated on .R files and not .Rd files, where I
> > find syntax highlighting more useful.
>
> Mime-types shouldn't be distribution-specific or even editor-specific,
> should they? The whole point is that they can be used for things like
> email attachments that pass from one OS to the other.
>
> It might be useful to have the mime-type definitions for R (and Rd)
> files centralized in R core, with the appropriate OS conventions
> systematized. But I think we need to know more. Who keeps track of
> mime-types? Can we just grab text/x-R (and text/x-Rd and
> application/x-Rdata)? To which extent the XML format a standard; is it
> only used by particular applications?
>
>
As far as I know, at least in Debian, the mimetypes are tracked by
shared-mime-info package. The upstream is freedesktop.org. I do not
know about oficial standarts, but Gnome and KDE tries to adher to some
of the freedesktop.org standarts. I can confirm that mimetypes
provided by shared-mime-info are widely used in Gnome, for some time
now.

Vaidotas Zemlys
--
Doctorate student, http://www.mif.vu.lt/katedros/eka/katedra/zemlys.php
Vilnius University


From gs at statlab.uni-heidelberg.de  Thu Nov  3 16:24:56 2005
From: gs at statlab.uni-heidelberg.de (G. Sawitzki)
Date: Thu, 3 Nov 2005 16:24:56 +0100
Subject: [Rd] typo in browse.pkgs
Message-ID: <p06210200bf8fdc0381f9@[129.206.113.130]>


See below.

  gs.

Error in browse.pkgs("CRAN", "binary") : couldn't find function 
"avaliable.packages"

Your version of R is up to date
>  browse.pkgs
function (repos = getOption("repos"), contriburl = contrib.url(repos,
     type), type = getOption("pkgType"))
{
     if (.Platform$GUI != "AQUA")
         stop("this function is intended to work with the Aqua GUI")
     x <- installed.packages()
     i.pkgs <- as.character(x[, 1])
     i.vers <- as.character(x[, 3])
     label <- paste("(", type, ") @", contriburl)
     y <- avaliable.packages(contriburl = contriburl)
     c.pkgs <- as.character(y[, 1])
     c.vers <- as.character(y[, 2])
     idx <- match(i.pkgs, c.pkgs)
     vers2 <- character(length(c.pkgs))
     xx <- idx[which(!is.na(idx))]
     vers2[xx] <- i.vers[which(!is.na(idx))]
     i.vers <- vers2
     want.update <- rep(FALSE, length(i.vers))
     .Internal(pkgbrowser(c.pkgs, c.vers, i.vers, label, want.update))
}
<environment: namespace:utils>
>


From ripley at stats.ox.ac.uk  Thu Nov  3 16:44:54 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 3 Nov 2005 15:44:54 +0000 (GMT)
Subject: [Rd] typo in browse.pkgs
In-Reply-To: <p06210200bf8fdc0381f9@[129.206.113.130]>
References: <p06210200bf8fdc0381f9@[129.206.113.130]>
Message-ID: <Pine.LNX.4.61.0511031541320.17006@gannet.stats>

I believe you will find this is already fixed in R-patched and R-devel as 
the logs say  (2005-10-07)

r35790 Fixed a typo in aqua R code

and it seems to be that line.

On Thu, 3 Nov 2005, G. Sawitzki wrote:

>
> See below.
>
>  gs.
>
> Error in browse.pkgs("CRAN", "binary") : couldn't find function
> "avaliable.packages"
>
> Your version of R is up to date
>>  browse.pkgs
> function (repos = getOption("repos"), contriburl = contrib.url(repos,
>     type), type = getOption("pkgType"))
> {
>     if (.Platform$GUI != "AQUA")
>         stop("this function is intended to work with the Aqua GUI")
>     x <- installed.packages()
>     i.pkgs <- as.character(x[, 1])
>     i.vers <- as.character(x[, 3])
>     label <- paste("(", type, ") @", contriburl)
>     y <- avaliable.packages(contriburl = contriburl)
>     c.pkgs <- as.character(y[, 1])
>     c.vers <- as.character(y[, 2])
>     idx <- match(i.pkgs, c.pkgs)
>     vers2 <- character(length(c.pkgs))
>     xx <- idx[which(!is.na(idx))]
>     vers2[xx] <- i.vers[which(!is.na(idx))]
>     i.vers <- vers2
>     want.update <- rep(FALSE, length(i.vers))
>     .Internal(pkgbrowser(c.pkgs, c.vers, i.vers, label, want.update))
> }
> <environment: namespace:utils>
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From gs at statlab.uni-heidelberg.de  Thu Nov  3 17:03:17 2005
From: gs at statlab.uni-heidelberg.de (G. Sawitzki)
Date: Thu, 3 Nov 2005 17:03:17 +0100
Subject: [Rd] typo in browse.pkgs
In-Reply-To: <Pine.LNX.4.61.0511031541320.17006@gannet.stats>
References: <p06210200bf8fdc0381f9@[129.206.113.130]>
	<Pine.LNX.4.61.0511031541320.17006@gannet.stats>
Message-ID: <p06210204bf8fe4b58b9c@[129.206.113.130]>

At 15:44 +0000 03.11.2005, Prof Brian Ripley wrote:
>I believe you will find this is already fixed in R-patched and 
>R-devel as the logs say  (2005-10-07)
>
>r35790 Fixed a typo in aqua R code
>
>and it seems to be that line.

... but possibly it did not find its way into the version "R for Mac 
OS X 2.2.0 released on 2005/10/18" ....

  g.


From ripley at stats.ox.ac.uk  Thu Nov  3 17:39:41 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 3 Nov 2005 16:39:41 +0000 (GMT)
Subject: [Rd] typo in browse.pkgs
In-Reply-To: <p06210204bf8fe4b58b9c@[129.206.113.130]>
References: <p06210200bf8fdc0381f9@[129.206.113.130]>
	<Pine.LNX.4.61.0511031541320.17006@gannet.stats>
	<p06210204bf8fe4b58b9c@[129.206.113.130]>
Message-ID: <Pine.LNX.4.61.0511031637580.23179@gannet.stats>

On Thu, 3 Nov 2005, G. Sawitzki wrote:

> At 15:44 +0000 03.11.2005, Prof Brian Ripley wrote:
>> I believe you will find this is already fixed in R-patched and R-devel as 
>> the logs say  (2005-10-07)
>> 
>> r35790 Fixed a typo in aqua R code
>> 
>> and it seems to be that line.
>
> ... but possibly it did not find its way into the version "R for Mac OS X 
> 2.2.0 released on 2005/10/18" ....

R 2.2.0 was released on 2005-10-06, so it postdates that.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From pgilbert at bank-banque-canada.ca  Thu Nov  3 18:09:13 2005
From: pgilbert at bank-banque-canada.ca (Paul Gilbert)
Date: Thu, 03 Nov 2005 12:09:13 -0500
Subject: [Rd] proposal to make loadings() generic in R-devel
Message-ID: <436A4439.201@bank-banque-canada.ca>

I propose that loadings() be made generic in R-devel with definition

    loadings <- function(x, ...) UseMethod("loadings")

    loadings.default <- function(x, ...) x$loadings

The default is the current definition of loadings with the ... argument 
added.

The current definition is not specific about the returned value, though 
$loadings may usually be a matrix. I'm not sure what would be broken if 
a more strict definition of the return value is enforced. For my 
purposes a matrix is fine, but I am not sure that there is a benefit 
from imposing that the returned value must be a matrix, so I suggest 
sticking with the current non-specific structure for the return value. 
(For piecewise linear or other non-linear analysis there may be good 
reasons to allow more general structures for the loadings.)

Paul Gilbert


From simon.urbanek at r-project.org  Thu Nov  3 18:16:25 2005
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Thu, 3 Nov 2005 12:16:25 -0500
Subject: [Rd] typo in browse.pkgs
In-Reply-To: <p06210200bf8fdc0381f9@[129.206.113.130]>
References: <p06210200bf8fdc0381f9@[129.206.113.130]>
Message-ID: <A2AC7F8A-16B6-4E81-813D-3889DEBB28EF@r-project.org>

G?nther,

On Nov 3, 2005, at 10:24 AM, G. Sawitzki wrote:

> See below.
>
>   gs.
>
> Error in browse.pkgs("CRAN", "binary") : couldn't find function
> "avaliable.packages"

You seem to have an old version of the R.app, because the R 2.2.0  
release R GUI has a work-around for that problem. Please update your  
R.app either from the R release or the nightly builds page:
http://research.att.com/~urbanek/R/

As Brian was saying, the error was fixed in R immediately after the  
release - strangely enough no one reported the error during the alpha  
and beta cycle although both the GUI and R binaries were available  
for download :(.

Cheers,
Simon


From izmirlig at mail.nih.gov  Fri Nov  4 01:10:14 2005
From: izmirlig at mail.nih.gov (izmirlig@mail.nih.gov)
Date: Fri,  4 Nov 2005 01:10:14 +0100 (CET)
Subject: [Rd] small bug in gl1ce, package lasso2 (PR#8279)
Message-ID: <20051104001014.C8E71238E5@slim.kubism.ku.dk>

Full_Name: Grant Izmirlian
Version: 2.2.0
OS: SuSe Linux version 9.2
Submission from: (NULL) (156.40.34.177)


The option exists to include all parameters, including the intercept, in the L-1
constraint, by specifying the argument, sweep.out=NULL, explicitly in the
call. However, upon doing this, the function stops with an error report 
"Matrix build from transformed variables has a constant column"

I was able to fix it as follows. In the following line, taken from the same
block of code producing the stop error, modify the existing line from

      X.to.C.stds <- sqrt(apply(X.to.C.w, 2, var))

to 


      X.to.C.stds <- ifelse(con.int, 
                            c(1,sqrt(apply(X.to.C.w[,-is.null(sweep.out)], 2,
var))), 
                                sqrt(apply(X.to.C.w,2,var)))

That should work.


From izmirlig at mail.nih.gov  Fri Nov  4 01:32:37 2005
From: izmirlig at mail.nih.gov (izmirlig@mail.nih.gov)
Date: Fri,  4 Nov 2005 01:32:37 +0100 (CET)
Subject: [Rd] small bug in gl1ce, package lasso2 (PR#8280)
Message-ID: <20051104003237.A00B8238E5@slim.kubism.ku.dk>

Full_Name: Grant Izmirlian
Version: 2.2.0
OS: SuSe Linux version 9.2
Submission from: (NULL) (156.40.34.177)


Sorry about the last submission, my bug-fix had an error in it because ifelse 
doesn't vectorize.  I'll repost with the correct bug-fix.
-------------------------------------------------------------------------------
The option exists to include all parameters, including the intercept, in the L-1
constraint, by specifying the argument, sweep.out=NULL, explicitly in the
call. However, upon doing this, the function stops with an error report 
"Matrix build from transformed variables has a constant column"

I was able to fix it as follows. In the following line, taken from the same
block of code producing the stop error, modify the existing line from

      X.to.C.stds <- sqrt(apply(X.to.C.w, 2, var))

to 


      X.to.C.stds <- (!is.null(sweep.out)) *
                     c(1,sqrt(apply(X.to.C.w[,-is.null(sweep.out)], 2, var))) +

                     (is.null(sweep.out)) * sqrt(apply(X.to.C.w,2,var)))

That should work.


From murdoch at stats.uwo.ca  Fri Nov  4 01:55:42 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 03 Nov 2005 19:55:42 -0500
Subject: [Rd] Changes to environments in R-devel
Message-ID: <436AB18E.6080305@stats.uwo.ca>

I've just committed some changes to R-devel which affect environments. 
Specifically:

  - using NULL as an environment is now deprecated:  use baseenv() 
instead.  (baseenv() is already available in R 2.2.0, where it returns 
NULL.  For most purposes it retains the same meaning in R-devel.) If you 
do use NULL, it will be converted to baseenv(), and a warning printed. 
For example:

 > f <- function(x) 1
 > environment(f) <- NULL
Warning message:
use of NULL environment is deprecated
 > environment(f)
<environment: base>

There may be some places where I've missed putting the conversion in 
place, and use of NULL will cause an error; please let me know if you 
find any of those.  The intention is that NULL will be usable with 
warnings through to the end of the 2.3.x releases.

  - baseenv() is no longer its own parent.  Its parent is an empty 
environment, available as emptyenv().

  - You can now create your own environment with emptyenv() as its 
parent.  Searches for variables in such an environment will not 
automatically proceed to baseenv(), as searches do in current R releases.

Duncan Murdoch


From ripley at stats.ox.ac.uk  Fri Nov  4 06:52:12 2005
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Fri,  4 Nov 2005 06:52:12 +0100 (CET)
Subject: [Rd] small bug in gl1ce, package lasso2 (PR#8280)
Message-ID: <20051104055212.50C0922141@slim.kubism.ku.dk>

Please do read the FAQ:

   Finally, check carefully whether the bug is with R, or a contributed
   package.  Bug reports on contributed packages should be sent first to
   the package maintainer, and only submitted to the R-bugs repository
   by package maintainers, mentioning the package in the subject line.

You are not the maintainer, so this is the wrong place.


On Fri, 4 Nov 2005 izmirlig at mail.nih.gov wrote:

> Full_Name: Grant Izmirlian
> Version: 2.2.0
> OS: SuSe Linux version 9.2
> Submission from: (NULL) (156.40.34.177)
>
>
> Sorry about the last submission, my bug-fix had an error in it because ifelse
> doesn't vectorize.  I'll repost with the correct bug-fix.
> -------------------------------------------------------------------------------
> The option exists to include all parameters, including the intercept, in the L-1
> constraint, by specifying the argument, sweep.out=NULL, explicitly in the
> call. However, upon doing this, the function stops with an error report
> "Matrix build from transformed variables has a constant column"
>
> I was able to fix it as follows. In the following line, taken from the same
> block of code producing the stop error, modify the existing line from
>
>      X.to.C.stds <- sqrt(apply(X.to.C.w, 2, var))
>
> to
>
>
>      X.to.C.stds <- (!is.null(sweep.out)) *
>                     c(1,sqrt(apply(X.to.C.w[,-is.null(sweep.out)], 2, var))) +
>
>                     (is.null(sweep.out)) * sqrt(apply(X.to.C.w,2,var)))
>
> That should work.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From berwin at maths.uwa.edu.au  Fri Nov  4 08:45:53 2005
From: berwin at maths.uwa.edu.au (Berwin A Turlach)
Date: Fri, 4 Nov 2005 15:45:53 +0800
Subject: [Rd] small bug in gl1ce, package lasso2 (PR#8280)
In-Reply-To: <20051104055212.50C0922141@slim.kubism.ku.dk>
References: <20051104055212.50C0922141@slim.kubism.ku.dk>
Message-ID: <17259.4529.335046.34815@bossiaea.maths.uwa.edu.au>

>>>>> "BDR" == ripley  <ripley at stats.ox.ac.uk> writes:

    BDR> Please do read the FAQ:

    BDR> Finally, check carefully whether the bug is with R, or a
    BDR> contributed package.  Bug reports on contributed packages
    BDR> should be sent first to the package maintainer, and only
    BDR> submitted to the R-bugs repository by package maintainers,
    BDR> mentioning the package in the subject line.

And Brian forgot to point out that you should probably not file a bug
report on your bug report since somebody has to clean up after you. :)
Now there is PR#8279 and PR#8280 to deal with, the second one should
have been a follow up for the first.

    BDR> You are not the maintainer, so this is the wrong place.
Well, I am not the maintainer either, but just a short note:

You should read the documentation of the argument 'standardize', whose
default is TRUE:

standardize: logical flag: if 'TRUE', then the columns of the model
          matrix that correspond to parameters that are constrained
          are standardized to have empirical variance one.  The
          standardization is done after taking possible weights into
          account and after sweeping out variables whose parameters
          are not constrained.

If you have a constant term in your model, then you can not
standardize it.  So if you set 'sweep.out' to NULL and have a constant
term in your model, then you should set standardize to FALSE.  If you
still want to standardize your non constant regressor variables, then
you have to do it yourself and pass the variables as you want them to
gl1ce.

IMO, there is no bug here, the functions were designed to work in this
way.

Cheers,

        Berwin

========================== Full address ============================
Berwin A Turlach                      Tel.: +61 (8) 6488 3338 (secr)   
School of Mathematics and Statistics        +61 (8) 6488 3383 (self)      
The University of Western Australia   FAX : +61 (8) 6488 1028
35 Stirling Highway                   
Crawley WA 6009                e-mail: berwin at maths.uwa.edu.au
Australia                        http://www.maths.uwa.edu.au/~berwin


From maechler at stat.math.ethz.ch  Fri Nov  4 09:58:47 2005
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 4 Nov 2005 09:58:47 +0100
Subject: [Rd] Alpha and Beta testing of R versions
In-Reply-To: <A2AC7F8A-16B6-4E81-813D-3889DEBB28EF@r-project.org>
References: <p06210200bf8fdc0381f9@[129.206.113.130]>
	<A2AC7F8A-16B6-4E81-813D-3889DEBB28EF@r-project.org>
Message-ID: <17259.8903.764080.973751@stat.math.ethz.ch>

[Mainly for R-foundation members; but kept in public for general
 brainstorming...]

>>>>> "Simon" == Simon Urbanek <simon.urbanek at r-project.org>
>>>>>     on Thu, 3 Nov 2005 12:16:25 -0500 writes:

	  <............>

    Simon> As Brian was saying, the error was fixed in R
    Simon> immediately after the release - strangely enough no
    Simon> one reported the error during the alpha and beta
    Simon> cycle although both the GUI and R binaries were
    Simon> available for download :(.

Unfortunately, the phrase "strangely enough" could be replaced with
``as almost always''.

Maybe we (the R-foundation) should give serious thoughts to
offer prizes for valid bug reports during alpha and beta
testing.  These could include
- Reduced fee for 'useR' and 'DSC' conferences
- being listed as helpful person in R's 'THANKS' file
  {but that may not entice those who are already listed},
  or even in the NEWS of the new relase 
  or on the "Hall of fame of R beta testers"

In order to discourage an increased number of non-bug reports we
may have to also open a "hall of shame" though...

Martin


From david.meyer at wu-wien.ac.at  Fri Nov  4 21:48:40 2005
From: david.meyer at wu-wien.ac.at (David Meyer)
Date: Fri, 4 Nov 2005 21:48:40 +0100
Subject: [Rd]  Alpha and Beta testing of R versions
Message-ID: <20051104214840.28fda9e8.david.meyer@wu-wien.ac.at>


[...]

> Maybe we (the R-foundation) should give serious thoughts to
> offer prizes for valid bug reports during alpha and beta
> testing.  These could include
> - Reduced fee for 'useR' and 'DSC' conferences
> - being listed as helpful person in R's 'THANKS' file
>  {but that may not entice those who are already listed},
>  or even in the NEWS of the new relase 
>  or on the "Hall of fame of R beta testers"

... formalized as a bug finding contest, for example?

-d


From ripley at stats.ox.ac.uk  Fri Nov  4 12:58:11 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 4 Nov 2005 11:58:11 +0000 (GMT)
Subject: [Rd] Alpha and Beta testing of R versions
In-Reply-To: <17259.8903.764080.973751@stat.math.ethz.ch>
References: <p06210200bf8fdc0381f9@[129.206.113.130]>
	<A2AC7F8A-16B6-4E81-813D-3889DEBB28EF@r-project.org>
	<17259.8903.764080.973751@stat.math.ethz.ch>
Message-ID: <Pine.LNX.4.61.0511041145190.24713@gannet.stats>

Martin's point is generally very valid, but in the case of the 2.2.0 
release remarkably few of the bugs found since release were new in 2.2.0.
One thing we have learnt is that none of the testers seem to look at HTML 
help (which accounts for 2 of the 4 2.2.0-only bugs I counted).

What we need most is persistent help in testing each release, especially 
on unusual platforms.  How do we `incentivize' that?

On Fri, 4 Nov 2005, Martin Maechler wrote:

> [Mainly for R-foundation members; but kept in public for general
> brainstorming...]
>
>>>>>> "Simon" == Simon Urbanek <simon.urbanek at r-project.org>
>>>>>>     on Thu, 3 Nov 2005 12:16:25 -0500 writes:
>
> 	  <............>
>
>    Simon> As Brian was saying, the error was fixed in R
>    Simon> immediately after the release - strangely enough no
>    Simon> one reported the error during the alpha and beta
>    Simon> cycle although both the GUI and R binaries were
>    Simon> available for download :(.
>
> Unfortunately, the phrase "strangely enough" could be replaced with
> ``as almost always''.
>
> Maybe we (the R-foundation) should give serious thoughts to
> offer prizes for valid bug reports during alpha and beta
> testing.  These could include
> - Reduced fee for 'useR' and 'DSC' conferences
> - being listed as helpful person in R's 'THANKS' file
>  {but that may not entice those who are already listed},
>  or even in the NEWS of the new relase
>  or on the "Hall of fame of R beta testers"
>
> In order to discourage an increased number of non-bug reports we
> may have to also open a "hall of shame" though...
>
> Martin
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From p.dalgaard at biostat.ku.dk  Fri Nov  4 13:51:56 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 04 Nov 2005 13:51:56 +0100
Subject: [Rd] shared-mime-info (PR#8278)
In-Reply-To: <20051103125634.1B15F24722@slim.kubism.ku.dk>
References: <20051103125634.1B15F24722@slim.kubism.ku.dk>
Message-ID: <x2slucy3rn.fsf@viggo.kubism.ku.dk>

mpiktas at gmail.com writes:

> Hi,
> 
> On 03 Nov 2005 12:41:53 +0100, Peter Dalgaard <p.dalgaard at biostat.ku.dk> wr=
> ote:
> > ripley at stats.ox.ac.uk writes:
> >
> > > We do not usually put features in R which are specific to just some
> > > distributions of some OSes, and in this case to one editor on those.
> > > We do not for example include the ESS mode for the much-more-widely-use=
> d
> > > Emacs family of editors.
> > >
> > > This looks as if it might be appropriate to the Linux binary packages f=
> or
> > > R, so I suggest you contact their maintainers.  But my understanding is
> > > that this is an issue for gedit and not for R.  Indeed .R is just a
> > > convention (one of many choices, including .r and .q) for R itself.
> > >
> > > I do wonder why you concentrated on .R files and not .Rd files, where I
> > > find syntax highlighting more useful.
> >
> > Mime-types shouldn't be distribution-specific or even editor-specific,
> > should they? The whole point is that they can be used for things like
> > email attachments that pass from one OS to the other.
> >
> > It might be useful to have the mime-type definitions for R (and Rd)
> > files centralized in R core, with the appropriate OS conventions
> > systematized. But I think we need to know more. Who keeps track of
> > mime-types? Can we just grab text/x-R (and text/x-Rd and
> > application/x-Rdata)? To which extent the XML format a standard; is it
> > only used by particular applications?
> >
> >
> As far as I know, at least in Debian, the mimetypes are tracked by
> shared-mime-info package. The upstream is freedesktop.org. I do not
> know about oficial standarts, but Gnome and KDE tries to adher to some
> of the freedesktop.org standarts. I can confirm that mimetypes
> provided by shared-mime-info are widely used in Gnome, for some time
> now.

One further thought about this:

On SUSE, 

rpm -qif /usr/share/mime/

points at 

http://www.freedesktop.org/wiki/Software_2fshared_2dmime_2dinfo

So I guess that the proper tree to bark at is the upstreams
maintainers of

http://freedesktop.org/~jrb/shared-mime-info-*.tar.gz

Instructions there say to submit new XML files to

https://bugs.freedesktop.org/buglist.cgi?product=shared-mime-info&bug_status=NEW&bug_status=ASSIGNED&bug_status=REOPENED

It would likely be a good idea to send them first to R-devel for review.

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From mpiktas at gmail.com  Fri Nov  4 14:24:19 2005
From: mpiktas at gmail.com (Vaidotas Zemlys)
Date: Fri, 4 Nov 2005 15:24:19 +0200
Subject: [Rd] shared-mime-info (PR#8278)
In-Reply-To: <x2slucy3rn.fsf@viggo.kubism.ku.dk>
References: <20051103125634.1B15F24722@slim.kubism.ku.dk>
	<x2slucy3rn.fsf@viggo.kubism.ku.dk>
Message-ID: <e47808320511040524g19097bb4k3929f8a6aaab5ea7@mail.gmail.com>

Hi,

On 04 Nov 2005 13:51:56 +0100, Peter Dalgaard <p.dalgaard at biostat.ku.dk> wrote:

> One further thought about this:
>
> On SUSE,
>
> rpm -qif /usr/share/mime/
>
> points at
>
> http://www.freedesktop.org/wiki/Software_2fshared_2dmime_2dinfo
>
> So I guess that the proper tree to bark at is the upstreams
> maintainers of
>
> http://freedesktop.org/~jrb/shared-mime-info-*.tar.gz
>
> Instructions there say to submit new XML files to
>
> https://bugs.freedesktop.org/buglist.cgi?product=shared-mime-info&bug_status=NEW&bug_status=ASSIGNED&bug_status=REOPENED
>
> It would likely be a good idea to send them first to R-devel for review.
>

I already barked at upstream. The upstream barked back. The result is here:

https://bugs.freedesktop.org/show_bug.cgi?id=1782

There you can find xml file for R scripts. I've made it from some
example. It is really only a proof of a concept. But it would not be
very difficult to produce xml files for mimetypes of all R related
files. We must only decide which R related files would benefit from
having mimetypes.

My proposal is
1. R source code, R scripts. Files with extensions .R, .r and others
(.q?, .s?, .S?). Mimetypes text/x-R, text/x-Rsrc
2. R documentation files. File extension .Rd. Mimetype text/x-Rd
3. RData files. File extension .RData, files which at beginning have
RDX2. Mimetype application/x-RData.
4. Rhistory files. File extension .Rhistory. Mimetype text/x-Rhistory
5. R transcript files from ESS/Emacs. File extension .Rt. Mimetype
text/x-Rtranscript

The relevant xml code could be pushed upstream to end up in
freedesktop.org.xml, or it could be distributed with R linux package,
and installed into relevant subdirectory of /usr/share/mime. With a
bit more work the result could be, that people using for example
Nautilus (graphical Gnome browser) could see R related files displayed
with R logo, and clicking them could result in various appropriate
actions. For example for .RData R process could be iinvoked and
relevant .RData file could be loaded.

I could write and test the xml code. But first we have to agree on
which files benefit from having mimetypes and how the mimetypes should
be named. Feel free to suggest.

Vaidotas Zemlys
--
Doctorate student, http://www.mif.vu.lt/katedros/eka/katedra/zemlys.php
Vilnius University


From simon.urbanek at r-project.org  Fri Nov  4 14:51:18 2005
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Fri, 4 Nov 2005 08:51:18 -0500
Subject: [Rd] Alpha and Beta testing of R versions
In-Reply-To: <Pine.LNX.4.61.0511041145190.24713@gannet.stats>
References: <p06210200bf8fdc0381f9@[129.206.113.130]>
	<A2AC7F8A-16B6-4E81-813D-3889DEBB28EF@r-project.org>
	<17259.8903.764080.973751@stat.math.ethz.ch>
	<Pine.LNX.4.61.0511041145190.24713@gannet.stats>
Message-ID: <4C965F86-0A19-4581-99AB-76F2AC881BA5@r-project.org>

On Nov 4, 2005, at 6:58 AM, Prof Brian Ripley wrote:

> Martin's point is generally very valid, but in the case of the  
> 2.2.0 release remarkably few of the bugs found since release were  
> new in 2.2.0.
> One thing we have learnt is that none of the testers seem to look  
> at HTML help (which accounts for 2 of the 4 2.2.0-only bugs I  
> counted).
>
> What we need most is persistent help in testing each release,  
> especially on unusual platforms.  How do we `incentivize' that?

I suspect that in the particular case of OS X the problem was  
probably visibility - it was the first time ever that nightly OS X  
binaries were available during alpha/beta phase (afaict), but I'm not  
sure how many people knew about it. I think posted about it on R-SIG- 
Mac during some discussion, but maybe I should have announced it more  
specifically somewhere. I'm, not even sure whether there was a link  
from the main page on CRAN. I would think that OS X users are more  
likely to rely on binaries, so the above is more relevant than on  
other platforms.

>> - being listed as helpful person in R's 'THANKS' file
>>  {but that may not entice those who are already listed},
>>  or even in the NEWS of the new relase
>>  or on the "Hall of fame of R beta testers"

The latter sounds good to me, although I'm not sure how many of our  
users are striving for fame ;).

Cheers,
Simon


From p.dalgaard at biostat.ku.dk  Fri Nov  4 15:59:26 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 04 Nov 2005 15:59:26 +0100
Subject: [Rd] shared-mime-info (PR#8278)
In-Reply-To: <e47808320511040524g19097bb4k3929f8a6aaab5ea7@mail.gmail.com>
References: <20051103125634.1B15F24722@slim.kubism.ku.dk>
	<x2slucy3rn.fsf@viggo.kubism.ku.dk>
	<e47808320511040524g19097bb4k3929f8a6aaab5ea7@mail.gmail.com>
Message-ID: <x2oe50xxv5.fsf@viggo.kubism.ku.dk>

Vaidotas Zemlys <mpiktas at gmail.com> writes:

> Hi,
> 
> On 04 Nov 2005 13:51:56 +0100, Peter Dalgaard <p.dalgaard at biostat.ku.dk> wrote:
> 
> > One further thought about this:
> >
> > On SUSE,
> >
> > rpm -qif /usr/share/mime/
> >
> > points at
> >
> > http://www.freedesktop.org/wiki/Software_2fshared_2dmime_2dinfo
> >
> > So I guess that the proper tree to bark at is the upstreams
> > maintainers of
> >
> > http://freedesktop.org/~jrb/shared-mime-info-*.tar.gz
> >
> > Instructions there say to submit new XML files to
> >
> > https://bugs.freedesktop.org/buglist.cgi?product=shared-mime-info&bug_status=NEW&bug_status=ASSIGNED&bug_status=REOPENED
> >
> > It would likely be a good idea to send them first to R-devel for review.
> >
> 
> I already barked at upstream. The upstream barked back. The result is here:
> 
> https://bugs.freedesktop.org/show_bug.cgi?id=1782

Aha... This is pretty weird, in light of the prescription on the website:

<<
Shared MIME database package

The core database and the update-mime-database program for extending
it are available from the [WWW]software pages.

If you have added types that should go in the common freedesktop.org
base list of types, you should create an enhancement request on
[WWW]the MIME bugtracker with your new XML file.
>>

If the procedure is different, perhaps we should ask them what it is?
I don't think we have a real problem with maintaining a "freedesktop"
subdir somewhere in the sources since it appears to cover quite a wide
range of systems, but we don't seem to know what to do with it.

The procedure appears to be different between Linuxen: On SUSE, I get

viggo:~/>rpm -qf /usr/share/mime/text/x-texinfo.xml
shared-mime-info-0.15.cvs20050321-3

whereas FC4 has

[pd at janus ~]$ rpm -qf /usr/share/mime/text/x-texinfo.xml
file /usr/share/mime/text/x-texinfo.xml is not owned by any package

(and likewise 60-odd other .xml files). So it seems that SUSE collects
all this stuff in a single RPM and FC4 lets it be handled by the
post-install mechanism (on each package or by "exploding"
freedesktop.org.xml ??)
 
> There you can find xml file for R scripts. I've made it from some
> example. It is really only a proof of a concept. But it would not be
> very difficult to produce xml files for mimetypes of all R related
> files. We must only decide which R related files would benefit from
> having mimetypes.
> 
> My proposal is
> 1. R source code, R scripts. Files with extensions .R, .r and others
> (.q?, .s?, .S?). Mimetypes text/x-R, text/x-Rsrc

My inclination would be to stick with .R, possibly adding .r to guard
against Windows case-folding issues, but .r used to be Ratfor files.
.q/.s/.S are used by some people supporting both R and S-PLUS, but I
don't think they care how such files are displayed by Nautilus and
Konqueror... 

> 2. R documentation files. File extension .Rd. Mimetype text/x-Rd

OK, modulo case-fold

> 3. RData files. File extension .RData, files which at beginning have
> RDX2. Mimetype application/x-RData.

Why the RDX2 bit?? We do have .RDA from windows, too. 


> 4. Rhistory files. File extension .Rhistory. Mimetype text/x-Rhistory

OK.

> 5. R transcript files from ESS/Emacs. File extension .Rt. Mimetype
> text/x-Rtranscript

.Rout, please. Also .Rout.save and .Rout.fail. (And it's not just
ESS that creates them).

Also

6. Rprofile files .Rprofile or Rprofile.

> The relevant xml code could be pushed upstream to end up in
> freedesktop.org.xml, or it could be distributed with R linux package,
> and installed into relevant subdirectory of /usr/share/mime. With a
> bit more work the result could be, that people using for example
> Nautilus (graphical Gnome browser) could see R related files displayed
> with R logo, and clicking them could result in various appropriate
> actions. For example for .RData R process could be iinvoked and
> relevant .RData file could be loaded.

Some fun potential with gedit/Kate plugins too (ESS for the 21st
century anyone?)

> I could write and test the xml code. But first we have to agree on
> which files benefit from having mimetypes and how the mimetypes should
> be named. Feel free to suggest.


-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From p.dalgaard at biostat.ku.dk  Fri Nov  4 15:59:43 2005
From: p.dalgaard at biostat.ku.dk (p.dalgaard@biostat.ku.dk)
Date: Fri,  4 Nov 2005 15:59:43 +0100 (CET)
Subject: [Rd] shared-mime-info (PR#8278)
Message-ID: <20051104145943.50FE720606@slim.kubism.ku.dk>

Vaidotas Zemlys <mpiktas at gmail.com> writes:

> Hi,
> 
> On 04 Nov 2005 13:51:56 +0100, Peter Dalgaard <p.dalgaard at biostat.ku.dk> wrote:
> 
> > One further thought about this:
> >
> > On SUSE,
> >
> > rpm -qif /usr/share/mime/
> >
> > points at
> >
> > http://www.freedesktop.org/wiki/Software_2fshared_2dmime_2dinfo
> >
> > So I guess that the proper tree to bark at is the upstreams
> > maintainers of
> >
> > http://freedesktop.org/~jrb/shared-mime-info-*.tar.gz
> >
> > Instructions there say to submit new XML files to
> >
> > https://bugs.freedesktop.org/buglist.cgi?product=shared-mime-info&bug_status=NEW&bug_status=ASSIGNED&bug_status=REOPENED
> >
> > It would likely be a good idea to send them first to R-devel for review.
> >
> 
> I already barked at upstream. The upstream barked back. The result is here:
> 
> https://bugs.freedesktop.org/show_bug.cgi?id=1782

Aha... This is pretty weird, in light of the prescription on the website:

<<
Shared MIME database package

The core database and the update-mime-database program for extending
it are available from the [WWW]software pages.

If you have added types that should go in the common freedesktop.org
base list of types, you should create an enhancement request on
[WWW]the MIME bugtracker with your new XML file.
>>

If the procedure is different, perhaps we should ask them what it is?
I don't think we have a real problem with maintaining a "freedesktop"
subdir somewhere in the sources since it appears to cover quite a wide
range of systems, but we don't seem to know what to do with it.

The procedure appears to be different between Linuxen: On SUSE, I get

viggo:~/>rpm -qf /usr/share/mime/text/x-texinfo.xml
shared-mime-info-0.15.cvs20050321-3

whereas FC4 has

[pd at janus ~]$ rpm -qf /usr/share/mime/text/x-texinfo.xml
file /usr/share/mime/text/x-texinfo.xml is not owned by any package

(and likewise 60-odd other .xml files). So it seems that SUSE collects
all this stuff in a single RPM and FC4 lets it be handled by the
post-install mechanism (on each package or by "exploding"
freedesktop.org.xml ??)
 
> There you can find xml file for R scripts. I've made it from some
> example. It is really only a proof of a concept. But it would not be
> very difficult to produce xml files for mimetypes of all R related
> files. We must only decide which R related files would benefit from
> having mimetypes.
> 
> My proposal is
> 1. R source code, R scripts. Files with extensions .R, .r and others
> (.q?, .s?, .S?). Mimetypes text/x-R, text/x-Rsrc

My inclination would be to stick with .R, possibly adding .r to guard
against Windows case-folding issues, but .r used to be Ratfor files.
.q/.s/.S are used by some people supporting both R and S-PLUS, but I
don't think they care how such files are displayed by Nautilus and
Konqueror... 

> 2. R documentation files. File extension .Rd. Mimetype text/x-Rd

OK, modulo case-fold

> 3. RData files. File extension .RData, files which at beginning have
> RDX2. Mimetype application/x-RData.

Why the RDX2 bit?? We do have .RDA from windows, too. 


> 4. Rhistory files. File extension .Rhistory. Mimetype text/x-Rhistory

OK.

> 5. R transcript files from ESS/Emacs. File extension .Rt. Mimetype
> text/x-Rtranscript

.Rout, please. Also .Rout.save and .Rout.fail. (And it's not just
ESS that creates them).

Also

6. Rprofile files .Rprofile or Rprofile.

> The relevant xml code could be pushed upstream to end up in
> freedesktop.org.xml, or it could be distributed with R linux package,
> and installed into relevant subdirectory of /usr/share/mime. With a
> bit more work the result could be, that people using for example
> Nautilus (graphical Gnome browser) could see R related files displayed
> with R logo, and clicking them could result in various appropriate
> actions. For example for .RData R process could be iinvoked and
> relevant .RData file could be loaded.

Some fun potential with gedit/Kate plugins too (ESS for the 21st
century anyone?)

> I could write and test the xml code. But first we have to agree on
> which files benefit from having mimetypes and how the mimetypes should
> be named. Feel free to suggest.


-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From bolker at zoo.ufl.edu  Fri Nov  4 16:05:19 2005
From: bolker at zoo.ufl.edu (Ben Bolker)
Date: Fri, 04 Nov 2005 10:05:19 -0500
Subject: [Rd] dgamma error condition?
Message-ID: <436B78AF.9010602@zoo.ufl.edu>


   There's an apparent inconsistency between the
behavior of d(pqr)gamma and other distribution
functions for "bad" parameter values.  Specifically,
most distributions give NaN and a warning for bad
parameters (e.g. probabilities <0 or >1).  In contrast,
d(pqr)gamma actually gives an error and stops when shape<0.
I don't see why it has to be this way -- the internal
C code is set up to detect shape<0 (or scale<0) and
return NaN and a warning, and none of the other
distribution functions in that bit of the code have
similar behavior.

   It would seem more consistent (and would be more
convenient for me -- the error-instead-of-warning
is making me have to jump through additional hoops)
if dgamma just returned NaN and a warning.

    Any thoughts?

   cheers
     Ben Bolker


From ripley at stats.ox.ac.uk  Fri Nov  4 16:08:55 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 4 Nov 2005 15:08:55 +0000 (GMT)
Subject: [Rd] Changes to environments in R-devel
In-Reply-To: <436AB18E.6080305@stats.uwo.ca>
References: <436AB18E.6080305@stats.uwo.ca>
Message-ID: <Pine.LNX.4.61.0511041443420.30492@gannet.stats>

As a followup, these changes have some impacts on already installed 
packages, most likely including all those using lazy-loading or saved 
images.

If you are building from a checked-out version of R you will need to 
trigger re-installation of the recommended packages.  Unix users can do 
that by

    rm src/library/Recommended/*.ts
    make

but Windows users will best do 'make distclean; make all recommended' as a 
clean is needed.

One way to re-install all other packages is

> have <- installed.packages(priority="NA")[,1]
> install.packages(have)

at least if you have them all in the main library tree or all in one 
additional tree.  Doing it from within R ensures that the dependency order 
is maintained.  If like me you have almost all CRAN packages installed 
that will take quite a while.

Note that re-installing binary packages under Windows and MacOS X will not 
be effective until the repositories have been rebuilt.

On Thu, 3 Nov 2005, Duncan Murdoch wrote:

> I've just committed some changes to R-devel which affect environments.
> Specifically:
>
>  - using NULL as an environment is now deprecated:  use baseenv()
> instead.  (baseenv() is already available in R 2.2.0, where it returns
> NULL.  For most purposes it retains the same meaning in R-devel.) If you
> do use NULL, it will be converted to baseenv(), and a warning printed.
> For example:
>
> > f <- function(x) 1
> > environment(f) <- NULL
> Warning message:
> use of NULL environment is deprecated
> > environment(f)
> <environment: base>
>
> There may be some places where I've missed putting the conversion in
> place, and use of NULL will cause an error; please let me know if you
> find any of those.  The intention is that NULL will be usable with
> warnings through to the end of the 2.3.x releases.
>
>  - baseenv() is no longer its own parent.  Its parent is an empty
> environment, available as emptyenv().
>
>  - You can now create your own environment with emptyenv() as its
> parent.  Searches for variables in such an environment will not
> automatically proceed to baseenv(), as searches do in current R releases.
>
> Duncan Murdoch
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From izmirlig at mail.nih.gov  Fri Nov  4 16:43:55 2005
From: izmirlig at mail.nih.gov (Izmirlian, Grant (NIH/NCI))
Date: Fri, 4 Nov 2005 10:43:55 -0500
Subject: [Rd] Classification Trees and basic Random Forest pkg using tree
	structures in C
Message-ID: <CE0E73903DB53F43B4B0938747F34F8A01242CB8@nihexchange7.nih.gov>

Hello R-devel:

I have written a package, called "woods", that does classification trees
(R function CT), and currently, only the most basic functionality of
Random Forest, e.g. bagged trees with choices about sample size, with/without
replacement, size of (random) subset of covariates drawn when nodes are 
split.  My reason for writing this is twofold.  First, I wanted to base
this development entirely in C (as others have done), but using data structures such as a node, pointer to node (for trees), and pointer to pointer of node (for forests) implemented in C. The algorithm which
does bagging isn't any faster (its 30% slower) than one by Leo Breiman/Adele Cutler/Andy Liaw/ Matt Weiner. The CT function runs about equally as fast
as Professor Brian Ripley's.

The only interesting feature is that the tree structure has been implemented in C. Its a neater way to carry stuff around and I am 
guessing would make future implementation easier. 

Because of its inherent redundancy from the users standpoint, it isn't
something to send to CRAN. However, I was wondering whether anyone is
interested in a copy?

Grant Izmirlian
NCI


From p.dalgaard at biostat.ku.dk  Fri Nov  4 17:32:02 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 04 Nov 2005 17:32:02 +0100
Subject: [Rd] shared-mime-info (PR#8278)
In-Reply-To: <Pine.OSF.4.58.0511041021160.346445@wotan.mdacc.tmc.edu>
References: <20051103125634.1B15F24722@slim.kubism.ku.dk>
	<x2slucy3rn.fsf@viggo.kubism.ku.dk>
	<e47808320511040524g19097bb4k3929f8a6aaab5ea7@mail.gmail.com>
	<x2oe50xxv5.fsf@viggo.kubism.ku.dk>
	<Pine.OSF.4.58.0511041021160.346445@wotan.mdacc.tmc.edu>
Message-ID: <x27jboxtkt.fsf@viggo.kubism.ku.dk>

Paul Roebuck <roebuck at mdanderson.org> writes:

> On Fri, 4 Nov 2005, Peter Dalgaard wrote:
> 
> > Vaidotas Zemlys <mpiktas at gmail.com> writes:
> >
> > > [SNIP]
> > >
> >
> > Also
> >
> > 6. Rprofile files .Rprofile or Rprofile.
> >
> 
> .Renviron?

Yes, but you seem to have forgotten to keep r-devel in the circuit...

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From rsamurti at touchtelindia.net  Fri Nov  4 18:19:00 2005
From: rsamurti at touchtelindia.net (R S Ananda Murthy)
Date: Fri, 04 Nov 2005 22:49:00 +0530
Subject: [Rd] R-2.2.0 Compile problem on Slackware 10.2
Message-ID: <436B9804.4000703@touchtelindia.net>

Hello,

I am trying to compile R-2.2.0 on Slackware 10.2.

I did ./configure --prefix=/usr --build=i486-slackware-linux. It went 
off without any problem and gave this configure status:

R is now configured for i486-slackware-linux-gnu

  Source directory:          .
  Installation directory:    /usr

  C compiler:                gcc  -g -O2
  C++ compiler:              g++  -g -O2
  Fortran compiler:          g77  -g -O2

  Interfaces supported:      X11, tcltk
  External libraries:        readline
  Additional capabilities:   PNG, JPEG, iconv, MBCS, NLS
  Options enabled:           R profiling

  Recommended packages:      yes

When I gave make command, I got the following error message:

gcc -I.  -DUSE_MMAP -I. -I../../../src/include -I../../../src/include 
-I/usr/local/include -DHAVE_CONFIG_H   -g -O2 -c crc32.c -o crc32.o
In file included from /usr/include/linux/errno.h:4,
                 from /usr/include/bits/errno.h:25,
                 from /usr/include/errno.h:36,
                 from zutil.h:38,
                 from crc32.c:29:
/usr/include/asm/errno.h:4:31: asm-generic/errno.h: No such file or 
directory
make[4]: *** [crc32.o] Error 1
make[4]: Leaving directory `/home/anand/R-2.2.0/src/extra/zlib'
make[3]: *** [R] Error 2
make[3]: Leaving directory `/home/anand/R-2.2.0/src/extra/zlib'
make[2]: *** [R] Error 1
make[2]: Leaving directory `/home/anand/R-2.2.0/src/extra'
make[1]: *** [R] Error 1
make[1]: Leaving directory `/home/anand/R-2.2.0/src'
make: *** [R] Error 1

What should I do to correct this?

Thanks for your help.

Anand


From ripley at stats.ox.ac.uk  Fri Nov  4 18:36:43 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 4 Nov 2005 17:36:43 +0000 (GMT)
Subject: [Rd] R-2.2.0 Compile problem on Slackware 10.2
In-Reply-To: <436B9804.4000703@touchtelindia.net>
References: <436B9804.4000703@touchtelindia.net>
Message-ID: <Pine.LNX.4.61.0511041732420.2857@gannet.stats>

This an error in a standard system header file /usr/include/errno.h, not 
something we can help with.

However, is --build=i486-slackware-linux actually correct?  Our manuals do 
not suggest you specify --build, and if incorrect it might just explain 
this.

On Fri, 4 Nov 2005, R S Ananda Murthy wrote:

> Hello,
>
> I am trying to compile R-2.2.0 on Slackware 10.2.
>
> I did ./configure --prefix=/usr --build=i486-slackware-linux. It went
> off without any problem and gave this configure status:
>
> R is now configured for i486-slackware-linux-gnu
>
>  Source directory:          .
>  Installation directory:    /usr
>
>  C compiler:                gcc  -g -O2
>  C++ compiler:              g++  -g -O2
>  Fortran compiler:          g77  -g -O2
>
>  Interfaces supported:      X11, tcltk
>  External libraries:        readline
>  Additional capabilities:   PNG, JPEG, iconv, MBCS, NLS
>  Options enabled:           R profiling
>
>  Recommended packages:      yes
>
> When I gave make command, I got the following error message:
>
> gcc -I.  -DUSE_MMAP -I. -I../../../src/include -I../../../src/include
> -I/usr/local/include -DHAVE_CONFIG_H   -g -O2 -c crc32.c -o crc32.o
> In file included from /usr/include/linux/errno.h:4,
>                 from /usr/include/bits/errno.h:25,
>                 from /usr/include/errno.h:36,
>                 from zutil.h:38,
>                 from crc32.c:29:
> /usr/include/asm/errno.h:4:31: asm-generic/errno.h: No such file or
> directory
> make[4]: *** [crc32.o] Error 1
> make[4]: Leaving directory `/home/anand/R-2.2.0/src/extra/zlib'
> make[3]: *** [R] Error 2
> make[3]: Leaving directory `/home/anand/R-2.2.0/src/extra/zlib'
> make[2]: *** [R] Error 1
> make[2]: Leaving directory `/home/anand/R-2.2.0/src/extra'
> make[1]: *** [R] Error 1
> make[1]: Leaving directory `/home/anand/R-2.2.0/src'
> make: *** [R] Error 1
>
> What should I do to correct this?
>
> Thanks for your help.
>
> Anand
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From hin-tak.leung at cimr.cam.ac.uk  Fri Nov  4 18:43:10 2005
From: hin-tak.leung at cimr.cam.ac.uk (Hin-Tak Leung)
Date: Fri, 04 Nov 2005 17:43:10 +0000
Subject: [Rd] Classification Trees and basic Random Forest pkg using
 tree structures in C
In-Reply-To: <CE0E73903DB53F43B4B0938747F34F8A01242CB8@nihexchange7.nih.gov>
References: <CE0E73903DB53F43B4B0938747F34F8A01242CB8@nihexchange7.nih.gov>
Message-ID: <436B9DAE.6070503@cimr.cam.ac.uk>

Izmirlian, Grant (NIH/NCI) wrote:
<snipped>
> The only interesting feature is that the tree structure has been
> implemented in C. Its a neater way to carry stuff around and I am 
> guessing would make future implementation easier.
> 
> Because of its inherent redundancy from the users standpoint, it
> isn't something to send to CRAN. However, I was wondering whether
> anyone is interested in a copy?

Hi,

Hmm, why didn't you just post a URL? Incidentally I am actually very
interested in seeing your code. I am working on a project where
the data set is extremely large, but the permuntation of the states of
the data is extremely small. Each piece of data consists of only 4 
states, so stuffing it as an R object (which takes up 32-byte? on
32-bit machines) or even an char vector is quite wasteful; so I
have written a "strange" data.frame where internally it uses only
2-bit for storage. (it is still work-in-process but I have got to
the point of being able to get and set each 2-bit cell now).

Hin-Tak Leung


From hin-tak.leung at cimr.cam.ac.uk  Fri Nov  4 19:12:42 2005
From: hin-tak.leung at cimr.cam.ac.uk (Hin-Tak Leung)
Date: Fri, 04 Nov 2005 18:12:42 +0000
Subject: [Rd] R-2.2.0 Compile problem on Slackware 10.2
In-Reply-To: <436B9804.4000703@touchtelindia.net>
References: <436B9804.4000703@touchtelindia.net>
Message-ID: <436BA49A.2060207@cimr.cam.ac.uk>

Your system is badly screwed up. On my Slackware 10.2,
/usr/include/asm/errno.h is just a plain file and doesn't
include anything else, unlike yours, which seems to look
for "asm-generic/errno.h".

The package you need to re-install is "kernel-headers-2.4.31-i386-1".
It is part of the d series, on your slackware CD or wherever you got
it installed from. On your box, the file is not missing but screwed
up, so you should get somebody more experienced to take a look at
your box and get it fixed before trying to uninstall/reinstall.

Good luck.
HTL

P.S. for ix86, very old slackware [kernel 2.2 or before?] "asm/errno.h"
is linked to "/usr/src/linux/include/asm-i386/errno.h" [because 
"/usr/include/asm" is linked to "/usr/src/linux/include/asm", which
in turn is linked to "asm-i386" (I have an "asm-generic", which
is just a link from asm-i386); for more modern boxes, "asm/errno.h"
is just a plain file in a plain directory.

R S Ananda Murthy wrote:
> Hello,
> 
> I am trying to compile R-2.2.0 on Slackware 10.2.
> 
> I did ./configure --prefix=/usr --build=i486-slackware-linux. It went 
> off without any problem and gave this configure status:
> 
> R is now configured for i486-slackware-linux-gnu
> 
>   Source directory:          .
>   Installation directory:    /usr
> 
>   C compiler:                gcc  -g -O2
>   C++ compiler:              g++  -g -O2
>   Fortran compiler:          g77  -g -O2
> 
>   Interfaces supported:      X11, tcltk
>   External libraries:        readline
>   Additional capabilities:   PNG, JPEG, iconv, MBCS, NLS
>   Options enabled:           R profiling
> 
>   Recommended packages:      yes
> 
> When I gave make command, I got the following error message:
> 
> gcc -I.  -DUSE_MMAP -I. -I../../../src/include -I../../../src/include 
> -I/usr/local/include -DHAVE_CONFIG_H   -g -O2 -c crc32.c -o crc32.o
> In file included from /usr/include/linux/errno.h:4,
>                  from /usr/include/bits/errno.h:25,
>                  from /usr/include/errno.h:36,
>                  from zutil.h:38,
>                  from crc32.c:29:
> /usr/include/asm/errno.h:4:31: asm-generic/errno.h: No such file or 
> directory
> make[4]: *** [crc32.o] Error 1
> make[4]: Leaving directory `/home/anand/R-2.2.0/src/extra/zlib'
> make[3]: *** [R] Error 2
> make[3]: Leaving directory `/home/anand/R-2.2.0/src/extra/zlib'
> make[2]: *** [R] Error 1
> make[2]: Leaving directory `/home/anand/R-2.2.0/src/extra'
> make[1]: *** [R] Error 1
> make[1]: Leaving directory `/home/anand/R-2.2.0/src'
> make: *** [R] Error 1
> 
> What should I do to correct this?
> 
> Thanks for your help.
> 
> Anand
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From rgentlem at fhcrc.org  Fri Nov  4 19:56:36 2005
From: rgentlem at fhcrc.org (Robert Gentleman)
Date: Fri, 04 Nov 2005 10:56:36 -0800
Subject: [Rd] clarification of library/require semantics
Message-ID: <436BAEE4.2030604@fhcrc.org>

Recently I have added a lib.loc argument to require, so that
it is more consistent with library. However, there are some oddities 
that folks have pointed out, and we do not have a documented description 
of the semantics for what should happen when the lib.loc parameter is 
provided.

   Proposal: the most common use case seems to be one where any other 
dependencies, or calls to library/require should also see the library 
specified in the lib.loc parameter for the duration of the initial call 
to library. Hence, we should modify the library search path for the 
duration of the call (via .libPaths).

  The alternative, is to not do that. Which is what happens now.

  Both have costs, automatically setting the library search path, of 
course, means that users that do not want that behavior have to manually 
remove things from their library. But if almost no one does that, and 
most folks I have asked have said they want the lib.loc parameter to be 
used for other loading.

   Comments?

  Robert

-- 
Robert Gentleman, PhD
Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M2-B876
PO Box 19024
Seattle, Washington 98109-1024
206-667-7700
rgentlem at fhcrc.org


From izmirlig at mail.nih.gov  Fri Nov  4 19:57:28 2005
From: izmirlig at mail.nih.gov (Izmirlian, Grant (NIH/NCI))
Date: Fri, 4 Nov 2005 13:57:28 -0500
Subject: [Rd] Classification Trees and basic Random Forest pkg using
	tree structures in C
Message-ID: <CE0E73903DB53F43B4B0938747F34F8A01242CB9@nihexchange7.nih.gov>

Hello Hin-Tak:

Thanks for your interest. This is just a short not to tell you and others that
the URL idea is a good one. This will take a few days at our organization.
When its available I will post again to this thread. In the meantime, I will
will send copies directly to those interested. So far, you and one other person.

Regards,

Grant


From andy_liaw at merck.com  Fri Nov  4 20:00:03 2005
From: andy_liaw at merck.com (Liaw, Andy)
Date: Fri, 4 Nov 2005 14:00:03 -0500
Subject: [Rd] Classification Trees and basic Random Forest pkg using t
 ree structures in C
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED569@usctmx1106.merck.com>

> From: Hin-Tak Leung
> 
> Izmirlian, Grant (NIH/NCI) wrote:
> <snipped>
> > The only interesting feature is that the tree structure has been
> > implemented in C. Its a neater way to carry stuff around and I am 
> > guessing would make future implementation easier.
> > 
> > Because of its inherent redundancy from the users standpoint, it
> > isn't something to send to CRAN. However, I was wondering whether
> > anyone is interested in a copy?
> 
> Hi,
> 
> Hmm, why didn't you just post a URL?

Isn't it a bit too much to assume that everyone has a personal web space
somewhere?

> Incidentally I am actually very
> interested in seeing your code. I am working on a project where
> the data set is extremely large, but the permuntation of the states of
> the data is extremely small. Each piece of data consists of only 4 
> states, so stuffing it as an R object (which takes up 32-byte? on
> 32-bit machines) or even an char vector is quite wasteful; so I
> have written a "strange" data.frame where internally it uses only
> 2-bit for storage. (it is still work-in-process but I have got to
> the point of being able to get and set each 2-bit cell now).

For some of the data we encounter, all X variables are binary, so each data
point can be encoded into a bitstring.  There are algorithms that take
advantage of that.  The problem is interfacing such code with R.  I know of
no good solutions.  As I told Grant, I thought about what he did, too, but
the difficulty is how to pass such data structures to R.  Actually, some
time down the road I might try to use the dendrogram class that's in R, and
manipulate them in C.  Not sure about efficiency though. 

Andy

 
> Hin-Tak Leung
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
>


From ripley at stats.ox.ac.uk  Fri Nov  4 20:06:57 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 4 Nov 2005 19:06:57 +0000 (GMT)
Subject: [Rd] clarification of library/require semantics
In-Reply-To: <436BAEE4.2030604@fhcrc.org>
References: <436BAEE4.2030604@fhcrc.org>
Message-ID: <Pine.LNX.4.61.0511041902140.5439@gannet.stats>

On Fri, 4 Nov 2005, Robert Gentleman wrote:

> Recently I have added a lib.loc argument to require, so that
> it is more consistent with library. However, there are some oddities
> that folks have pointed out, and we do not have a documented description
> of the semantics for what should happen when the lib.loc parameter is
> provided.
>
>   Proposal: the most common use case seems to be one where any other
> dependencies, or calls to library/require should also see the library
> specified in the lib.loc parameter for the duration of the initial call
> to library. Hence, we should modify the library search path for the
> duration of the call (via .libPaths).
>
>  The alternative, is to not do that. Which is what happens now.
>
>  Both have costs, automatically setting the library search path, of
> course, means that users that do not want that behavior have to manually
> remove things from their library. But if almost no one does that, and
> most folks I have asked have said they want the lib.loc parameter to be
> used for other loading.
>
>   Comments?

There is a parallel set of issues with loadNamespace and the dependent 
namespaces it loads.  I think I would want the same semantics (whatever 
they are) for loadNamespace and library.

I set my standard libraries in R_LIBS, so when I use lib.loc it is for 
experimental things.  So I would neither want the .libPaths changed nor 
be affected if they were.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From rsamurti at touchtelindia.net  Sat Nov  5 08:28:15 2005
From: rsamurti at touchtelindia.net (R S Ananda Murthy)
Date: Sat, 05 Nov 2005 12:58:15 +0530
Subject: [Rd] R-2.2.0 Compile problem on Slackware 10.2
In-Reply-To: <436BA49A.2060207@cimr.cam.ac.uk>
References: <436B9804.4000703@touchtelindia.net> 
	<436BA49A.2060207@cimr.cam.ac.uk>
Message-ID: <436C5F0F.1040109@touchtelindia.net>

Dear HTL,

Thanks for your help. I reinstalled kernel-headers-2.4.31 as mentioned 
by you. Now it compiled without any errors. Thanks again.

Regards,

Anand

Hin-Tak Leung wrote:

> Your system is badly screwed up. On my Slackware 10.2,
> /usr/include/asm/errno.h is just a plain file and doesn't
> include anything else, unlike yours, which seems to look
> for "asm-generic/errno.h".
>
> The package you need to re-install is "kernel-headers-2.4.31-i386-1".
> It is part of the d series, on your slackware CD or wherever you got
> it installed from. On your box, the file is not missing but screwed
> up, so you should get somebody more experienced to take a look at
> your box and get it fixed before trying to uninstall/reinstall.
>
> Good luck.
> HTL
>
> P.S. for ix86, very old slackware [kernel 2.2 or before?] "asm/errno.h"
> is linked to "/usr/src/linux/include/asm-i386/errno.h" [because 
> "/usr/include/asm" is linked to "/usr/src/linux/include/asm", which
> in turn is linked to "asm-i386" (I have an "asm-generic", which
> is just a link from asm-i386); for more modern boxes, "asm/errno.h"
> is just a plain file in a plain directory.
>
> R S Ananda Murthy wrote:
>
>> Hello,
>>
>> I am trying to compile R-2.2.0 on Slackware 10.2.
>>
>> I did ./configure --prefix=/usr --build=i486-slackware-linux. It went 
>> off without any problem and gave this configure status:
>>
>> R is now configured for i486-slackware-linux-gnu
>>
>>   Source directory:          .
>>   Installation directory:    /usr
>>
>>   C compiler:                gcc  -g -O2
>>   C++ compiler:              g++  -g -O2
>>   Fortran compiler:          g77  -g -O2
>>
>>   Interfaces supported:      X11, tcltk
>>   External libraries:        readline
>>   Additional capabilities:   PNG, JPEG, iconv, MBCS, NLS
>>   Options enabled:           R profiling
>>
>>   Recommended packages:      yes
>>
>> When I gave make command, I got the following error message:
>>
>> gcc -I.  -DUSE_MMAP -I. -I../../../src/include -I../../../src/include 
>> -I/usr/local/include -DHAVE_CONFIG_H   -g -O2 -c crc32.c -o crc32.o
>> In file included from /usr/include/linux/errno.h:4,
>>                  from /usr/include/bits/errno.h:25,
>>                  from /usr/include/errno.h:36,
>>                  from zutil.h:38,
>>                  from crc32.c:29:
>> /usr/include/asm/errno.h:4:31: asm-generic/errno.h: No such file or 
>> directory
>> make[4]: *** [crc32.o] Error 1
>> make[4]: Leaving directory `/home/anand/R-2.2.0/src/extra/zlib'
>> make[3]: *** [R] Error 2
>> make[3]: Leaving directory `/home/anand/R-2.2.0/src/extra/zlib'
>> make[2]: *** [R] Error 1
>> make[2]: Leaving directory `/home/anand/R-2.2.0/src/extra'
>> make[1]: *** [R] Error 1
>> make[1]: Leaving directory `/home/anand/R-2.2.0/src'
>> make: *** [R] Error 1
>>
>> What should I do to correct this?
>>
>> Thanks for your help.
>>
>> Anand
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>
>
>


From rolf at math.unb.ca  Sat Nov  5 16:56:47 2005
From: rolf at math.unb.ca (rolf@math.unb.ca)
Date: Sat,  5 Nov 2005 16:56:47 +0100 (CET)
Subject: [Rd] read.fwf; bug reports 8226 & 8236 (PR#8284)
Message-ID: <20051105155647.9CCD123D1C@slim.kubism.ku.dk>

It seems to me that the bug dealt with in bug reports 8226 and 8236
is still not fixed.

I obtained the revised version of read.fwf from the latest
R-patched and tried

	try.it <- read.fwf("junk",w,header=TRUE,as.is=TRUE)

This gave the error

Error in read.table(file = FILE, header = header, sep = sep, as.is = as.is,  : 
        more columns than column names

Inspection of file ``FILE'' revealed that (of course) the
first line of ``FILE'' was not tab separated and was hence
being treated as a single field.

I then tried the last of Emmanuel Paradis' proposed fixes; this
didn't quite work --- an extra ``sep'' (tab) gets tacked on at the
end of the line being catted and makes read.table think that there is
one more field than there actually are.

So I modified the fix to:

	if (header) {
        	headerline <- readLines(file, n = 1)
        	head.last  <- cumsum(widths)
        	head.first <- head.last - widths + 1
        	headerline <- substring(headerline,head.first,head.last)[!drop]
        	headerline <- paste(headerline,collapse=sep)
        	cat(file = FILE, headerline, "\n")
    	}

This works for me.

Brian Ripley says that this will crash with multiline records.  Well,
at least it works with single line records, as the current version
seems not to.
				cheers,

					Rolf Turner
					rolf at math.unb.ca


From rsamurti at touchtelindia.net  Sat Nov  5 18:22:38 2005
From: rsamurti at touchtelindia.net (R S Ananda Murthy)
Date: Sat, 05 Nov 2005 22:52:38 +0530
Subject: [Rd] How to make install DESTDIR=
Message-ID: <436CEA5E.30703@touchtelindia.net>

Hello,

I tried to do make install DESTDIR=$PKGDIR. But this does not work. What 
is the alternative? I need to do this to create Slackware package.

Thanks for your help,

Anand


From edd at debian.org  Sat Nov  5 18:52:35 2005
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sat, 5 Nov 2005 11:52:35 -0600
Subject: [Rd] How to make install DESTDIR=
In-Reply-To: <436CEA5E.30703@touchtelindia.net>
References: <436CEA5E.30703@touchtelindia.net>
Message-ID: <17260.61795.6844.2221@basebud.nulle.part>


On 5 November 2005 at 22:52, R S Ananda Murthy wrote:
| I tried to do make install DESTDIR=$PKGDIR. But this does not work. What 
| is the alternative? I need to do this to create Slackware package.

I think you want

	make prefix=$PKGDIR install

as the documentation in R-admin states rather clearly in several places.

Hth, Dirk

-- 
Statistics: The (futile) attempt to offer certainty about uncertainty.
         -- Roger Koenker, 'Dictionary of Received Ideas of Statistics'


From sfalcon at fhcrc.org  Sat Nov  5 20:21:05 2005
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Sat, 05 Nov 2005 11:21:05 -0800
Subject: [Rd] clarification of library/require semantics
In-Reply-To: <Pine.LNX.4.61.0511041902140.5439@gannet.stats> (Brian Ripley's
	message of "Fri, 4 Nov 2005 19:06:57 +0000 (GMT)")
References: <436BAEE4.2030604@fhcrc.org>
	<Pine.LNX.4.61.0511041902140.5439@gannet.stats>
Message-ID: <m2sluarjdq.fsf@macaroni.local>

On  4 Nov 2005, ripley at stats.ox.ac.uk wrote:
> I set my standard libraries in R_LIBS, so when I use lib.loc it is
> for experimental things.  So I would neither want the .libPaths
> changed nor be affected if they were.

With the current semantics, if one is testing a _collection_ of
experimental packages that depend on each other, the only way to test
the collection is to modify .libPaths.

Setting lib.loc only allows one to test a single experimental package
against dependencies picked up from R_LIBS.

Robert's proposal, as I understand it, would change the meaning of
lib.loc so that dependencies would be resolved there --- allowing a
collection of experimental packages to be tested against each other.

The current behavior could be replicated in this case by putting a
given experimental package in a library by itself.

Clearly, each choice has a tradeoff.  I understand that if one most
often tests a single independent experimental package, then the
current behavior is most convenient.

My preference is for lib.loc grabbing dependencies because I more
often deal with packages that have dependencies that I want to test
together.


+ seth


From A.Robinson at ms.unimelb.edu.au  Sun Nov  6 01:01:30 2005
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Sun, 6 Nov 2005 11:01:30 +1100
Subject: [Rd] Brainstorm: Alpha and Beta testing of R versions
In-Reply-To: <17259.8903.764080.973751@stat.math.ethz.ch>
References: <p06210200bf8fdc0381f9@[129.206.113.130]>
	<A2AC7F8A-16B6-4E81-813D-3889DEBB28EF@r-project.org>
	<17259.8903.764080.973751@stat.math.ethz.ch>
Message-ID: <20051106000130.GB1601@ms.unimelb.edu.au>

Hi Martin,

On Fri, Nov 04, 2005 at 09:58:47AM +0100, Martin Maechler wrote:
> [Mainly for R-foundation members; but kept in public for general
>  brainstorming...]

I'll take up the invitation to brainstorm.

As a user of R for a number of years, I'd really like to perform some
useful service.  I use a relatively obscure platform (FreeBSD) and I
can compile code.  I'd like to think that I'm in the target market for
beta testing :).  But, I'm timid.  I do not feel, in general, that R
core welcomes bug reports.

I think that there are several things that could be tried to encourage
more, and more useful, bug reports.

1) Put the following text on the *front page* of the tracking system, so
   that it is seen before the reader clicks on "New Bug Report":

"Before submitting a bug report, please read Chapter `R Bugs' of `The
R FAQ'. It describes what a bug is and how to report a bug.

If you are not sure whether you have observed a bug or not, it is a
good idea to ask on the mailing list R-Help by sending an e-mail to
r-help at stat.math.ethz.ch rather than submitting a bug report."

(BTW is this true also for alpha/beta testing?)

2) Try to use the structure of the reporting page to prompt good
   reporting.  On the report page, summarize the key points of
   identifying and reporting a bug in a checklist format.  Maybe even
   insist that the boxes be checked before allowing submission.
   Include seperate text boxes for description and sample code, to
   suggest that sample code is valued.

3) On either or both pages (and in FAQ), explain that thoughtful bug
   reports are valued and appreciated.  Further, explain that bug
   reports that do not follow the protocol are less valuable, and take
   more time.

4) Add checkboxes to the report page for alpha/beta.  (I suggest this
   for the purposes of marketing, not organization.)

5) On the report page, include hyperlinks to archived bug reports that
   were good.  Do likewise with some artificial bug reports that are
   bad.

6) Add an intermediate, draft step for bug submission, to allow
   checking.  If possible, include as part of this step an automated
   pattern matching call that identifies similarly texted bug reports,
   provides links to the reports, and invites a last-minute cross-check.

7) Keep a list of people who report useful bugs in alpha/beta phase on
   the website.  Many academics could point to it as evidence of
   community service.

> In order to discourage an increased number of non-bug reports we
> may have to also open a "hall of shame" though...

8) I'm sure that you're being ironic!  But I will take the point
   seriously, for what it's worth.  I think that humiliating
   submitters who haven't followed the protocol is deleterious.  It
   seems like almost every month we see someone get slapped on the
   wrist for not doing something the right way.  Of course, it's
   frustrating that people aren't following the posting guide.  But,
   why is that?  Where is the breakdown?  It might be interesting to
   try some follow-up (an exit interview!). If someone has failed to
   follow the protocol, perhaps we should try to find out why it was
   confusing, or if they just ignored it.

   The R-core is surrounded by, and serves, a community that comprises
   people who are not sufficiently good at what R-core does to be
   invited in to R-core. But, we're clearly interested in what R-core
   produces.  Please don't assume that bug submissions that do not
   follow the R protocol are the consequence of deliberate
   malfeasance.  

   To paraphrase Ian Fleming: Once is happenstance.  Twice is
   incompetence.  The third time, Mr. Bond, is enemy action. So, ...

9) Publicly thank bug reporters whether their reports are useful or
   not.  I just googled 'R-devel thank' and you figure prominently,
   Martin :).

Cheers

Andrew
-- 
Andrew Robinson
Senior Lecturer in Statistics                       Tel: +61-3-8344-9763
Department of Mathematics and Statistics            Fax: +61-3-8344-4599
University of Melbourne, VIC 3010 Australia
Email: a.robinson at ms.unimelb.edu.au    Website: http://www.ms.unimelb.edu.au


From hb at maths.lth.se  Sun Nov  6 01:43:04 2005
From: hb at maths.lth.se (Henrik Bengtsson)
Date: Sun, 06 Nov 2005 11:43:04 +1100
Subject: [Rd] Brainstorm: Alpha and Beta testing of R versions
In-Reply-To: <20051106000130.GB1601@ms.unimelb.edu.au>
References: <p06210200bf8fdc0381f9@[129.206.113.130]>	<A2AC7F8A-16B6-4E81-813D-3889DEBB28EF@r-project.org>	<17259.8903.764080.973751@stat.math.ethz.ch>
	<20051106000130.GB1601@ms.unimelb.edu.au>
Message-ID: <436D5198.3050408@maths.lth.se>

Andrew Robinson wrote:

>Hi Martin,
>
>On Fri, Nov 04, 2005 at 09:58:47AM +0100, Martin Maechler wrote:
>  
>
>>[Mainly for R-foundation members; but kept in public for general
>> brainstorming...]
>>    
>>
>
>I'll take up the invitation to brainstorm.
>
>As a user of R for a number of years, I'd really like to perform some
>useful service.  I use a relatively obscure platform (FreeBSD) and I
>can compile code.  I'd like to think that I'm in the target market for
>beta testing :).  But, I'm timid.  I do not feel, in general, that R
>core welcomes bug reports.
>
>I think that there are several things that could be tried to encourage
>more, and more useful, bug reports.
>
>1) Put the following text on the *front page* of the tracking system, so
>   that it is seen before the reader clicks on "New Bug Report":
>
>"Before submitting a bug report, please read Chapter `R Bugs' of `The
>R FAQ'. It describes what a bug is and how to report a bug.
>
>If you are not sure whether you have observed a bug or not, it is a
>good idea to ask on the mailing list R-Help by sending an e-mail to
>r-help at stat.math.ethz.ch rather than submitting a bug report."
>
>(BTW is this true also for alpha/beta testing?)
>
>2) Try to use the structure of the reporting page to prompt good
>   reporting.  On the report page, summarize the key points of
>   identifying and reporting a bug in a checklist format.  Maybe even
>   insist that the boxes be checked before allowing submission.
>   Include seperate text boxes for description and sample code, to
>   suggest that sample code is valued.
>  
>
...and a optional field to select one or several packages related to the 
bug.  This is a good place to clarify that problems related to 
third-party packages should not be reporter "here".  Example HTML code:

Package(s) related to the bug, if applicable:<br>
(Bugs related to packages not listed below should <em>not</em> be 
reported here. Instead, contact the package manager.)
<select name="packages" multiple>
 <option value="">- - Select one or more packages related to the bug - 
-</option>
 <option value="base">base (Base R functions)</option>
 <option value="datasets">datasets (Base R datasets)</option>
 <option value="grDevices">grDevices (Graphics devices for base and grid 
graphics)</option>
 <option value="graphics">graphics (R functions for base graphics)</option>
 <option value="grid">grid (A rewrite of the graphics layout 
capabilities, plus some support for interaction)</option>
 <option value="methods">methods (Formally defined methods and classes 
for R objects, plus other programming tools, as described in the Green 
Book)</option>
 <option value="splines">splines (Regression spline functions and 
classes)</option>
 <option value="stats">stats (R statistical functions)</option>
 <option value="stats4">stats4 (Statistical functions using S4 
classes)</option>
 <option value="tcltk">tcltk (Interface and language bindings to Tcl/Tk 
GUI elements)</option>
 <option value="tools">tools (Tools for package development and 
administration)</option>
 <option value="utils">utils (R utility functions)</option>
</select>

/Henrik

>3) On either or both pages (and in FAQ), explain that thoughtful bug
>   reports are valued and appreciated.  Further, explain that bug
>   reports that do not follow the protocol are less valuable, and take
>   more time.
>
>4) Add checkboxes to the report page for alpha/beta.  (I suggest this
>   for the purposes of marketing, not organization.)
>
>5) On the report page, include hyperlinks to archived bug reports that
>   were good.  Do likewise with some artificial bug reports that are
>   bad.
>
>6) Add an intermediate, draft step for bug submission, to allow
>   checking.  If possible, include as part of this step an automated
>   pattern matching call that identifies similarly texted bug reports,
>   provides links to the reports, and invites a last-minute cross-check.
>
>7) Keep a list of people who report useful bugs in alpha/beta phase on
>   the website.  Many academics could point to it as evidence of
>   community service.
>
>  
>
>>In order to discourage an increased number of non-bug reports we
>>may have to also open a "hall of shame" though...
>>    
>>
>
>8) I'm sure that you're being ironic!  But I will take the point
>   seriously, for what it's worth.  I think that humiliating
>   submitters who haven't followed the protocol is deleterious.  It
>   seems like almost every month we see someone get slapped on the
>   wrist for not doing something the right way.  Of course, it's
>   frustrating that people aren't following the posting guide.  But,
>   why is that?  Where is the breakdown?  It might be interesting to
>   try some follow-up (an exit interview!). If someone has failed to
>   follow the protocol, perhaps we should try to find out why it was
>   confusing, or if they just ignored it.
>
>   The R-core is surrounded by, and serves, a community that comprises
>   people who are not sufficiently good at what R-core does to be
>   invited in to R-core. But, we're clearly interested in what R-core
>   produces.  Please don't assume that bug submissions that do not
>   follow the R protocol are the consequence of deliberate
>   malfeasance.  
>
>   To paraphrase Ian Fleming: Once is happenstance.  Twice is
>   incompetence.  The third time, Mr. Bond, is enemy action. So, ...
>
>9) Publicly thank bug reporters whether their reports are useful or
>   not.  I just googled 'R-devel thank' and you figure prominently,
>   Martin :).
>
>Cheers
>
>Andrew
>  
>


From Torsten.Hothorn at rzmail.uni-erlangen.de  Mon Nov  7 09:20:32 2005
From: Torsten.Hothorn at rzmail.uni-erlangen.de (Torsten Hothorn)
Date: Mon, 7 Nov 2005 09:20:32 +0100 (CET)
Subject: [Rd] Classification Trees and basic Random Forest pkg using
	tree structures in C
In-Reply-To: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED569@usctmx1106.merck.com>
References: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED569@usctmx1106.merck.com>
Message-ID: <Pine.LNX.4.51.0511070917020.11505@artemis.imbe.med.uni-erlangen.de>


On Fri, 4 Nov 2005, Liaw, Andy wrote:
>
> For some of the data we encounter, all X variables are binary, so each data
> point can be encoded into a bitstring.  There are algorithms that take
> advantage of that.  The problem is interfacing such code with R.  I know of
> no good solutions.  As I told Grant, I thought about what he did, too, but
> the difficulty is how to pass such data structures to R.  Actually, some
> time down the road I might try to use the dendrogram class that's in R, and
> manipulate them in C.

I faced similar problems some time ago and ended up representing a
(binary) tree as recursive lists which can be manipulated from both the C
and R side. The `party' package has the code (and an internal random
forest function, however, without R interface yet) and the vignette
explains some details.

Best,

Torsten

> Not sure about efficiency though.
>
> Andy
>
>
> > Hin-Tak Leung
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
> >
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From roebuck at mdanderson.org  Mon Nov  7 09:48:31 2005
From: roebuck at mdanderson.org (Paul Roebuck)
Date: Mon, 7 Nov 2005 02:48:31 -0600 (CST)
Subject: [Rd] Brainstorm: Alpha and Beta testing of R versions
In-Reply-To: <436D5198.3050408@maths.lth.se>
References: <p06210200bf8fdc0381f9@[129.206.113.130]>
	<A2AC7F8A-16B6-4E81-813D-3889DEBB28EF@r-project.org>
	<17259.8903.764080.973751@stat.math.ethz.ch>
	<20051106000130.GB1601@ms.unimelb.edu.au>
	<436D5198.3050408@maths.lth.se>
Message-ID: <Pine.OSF.4.58.0511070221580.522664@wotan.mdacc.tmc.edu>

On Sun, 6 Nov 2005, Henrik Bengtsson wrote:

> Andrew Robinson wrote:
>
> >On Fri, Nov 04, 2005 at 09:58:47AM +0100, Martin Maechler wrote:
> >
> >>[Mainly for R-foundation members; but kept in public for general
> >> brainstorming...]
> >>
> >
> >[SNIP]
> >
> >2) Try to use the structure of the reporting page to prompt good
> >   reporting.  On the report page, summarize the key points of
> >   identifying and reporting a bug in a checklist format.  Maybe even
> >   insist that the boxes be checked before allowing submission.
> >   Include seperate text boxes for description and sample code, to
> >   suggest that sample code is valued.
> >
> >
> ...and a optional field to select one or several packages related to the
> bug.  This is a good place to clarify that problems related to
> third-party packages should not be reporter "here".  Example HTML code:
>
> Package(s) related to the bug, if applicable:<br>
> (Bugs related to packages not listed below should <em>not</em> be
> reported here. Instead, contact the package manager.)

Perhaps there should be no attempt to swim upstream here.
Why not just have the bug-reporter forward the report to
the maintainer? From user perspective, they would have a
single point to report bugs.

I'm not advocating increasing manual processing of bug
reports by R Core, rather that an alternative to the
problem [of package bug reports] may exist.

----------------------------------------------------------
SIGSIG -- signature too long (core dumped)


From hin-tak.leung at cimr.cam.ac.uk  Mon Nov  7 11:39:01 2005
From: hin-tak.leung at cimr.cam.ac.uk (Hin-Tak Leung)
Date: Mon, 07 Nov 2005 10:39:01 +0000
Subject: [Rd] Classification Trees and basic Random Forest pkg using t
 ree structures in C
In-Reply-To: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED569@usctmx1106.merck.com>
References: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED569@usctmx1106.merck.com>
Message-ID: <436F2EC5.5030508@cimr.cam.ac.uk>

Liaw, Andy wrote:
>>From: Hin-Tak Leung
<snipped>
>>Hmm, why didn't you just post a URL?
> 
> Isn't it a bit too much to assume that everyone has a personal web space
> somewhere?

Just for the sake of argument... I did assume that nih.gov is a sizeable
government organization and have official channnels for such things.
That's what government agencies do, and I suppose this software work is
in-the-line-of-duty for public consumption and therefore quite 
appropriate to put on a *.gov web site. (the same applies to *.ac.uk and 
  *.edu postings).

> For some of the data we encounter, all X variables are binary, so each data
> point can be encoded into a bitstring.  There are algorithms that take
> advantage of that.  The problem is interfacing such code with R.  I know of
> no good solutions.  As I told Grant, I thought about what he did, too, but
> the difficulty is how to pass such data structures to R.  Actually, some
> time down the road I might try to use the dendrogram class that's in R, and
> manipulate them in C.  Not sure about efficiency though. 

The best examples I have seen of manipulating foreign object is among 
the omegahat projects, like RSPerl and PSPython. Quite insteresting reading.

Hin-Tak Leung


From john.emerson at yale.edu  Mon Nov  7 15:56:20 2005
From: john.emerson at yale.edu (John W Emerson)
Date: Mon, 7 Nov 2005 09:56:20 -0500 (EST)
Subject: [Rd] mosaicplot() update
Message-ID: <Pine.LNX.4.44.0511070952450.24907-100000@argos.its.yale.edu>


Hi --

I've found a need for an additional option to mosaicplot(), to suppress
the labels.  It's not difficult, obviously, a minor thing.

Would you like me to submit my revised code (I'll use your code rather
than my original source code which was adapted for S-Plus and R)?  Or
it might be a 5-minute change for the appropriate person.  No problem
either way, just let me know.

Cheers,

Jay

John Emerson
Assistant Professor of Statistics
Yale University


From ripley at stats.ox.ac.uk  Mon Nov  7 17:43:08 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 7 Nov 2005 16:43:08 +0000 (GMT)
Subject: [Rd] mosaicplot() update
In-Reply-To: <Pine.LNX.4.44.0511070952450.24907-100000@argos.its.yale.edu>
References: <Pine.LNX.4.44.0511070952450.24907-100000@argos.its.yale.edu>
Message-ID: <Pine.LNX.4.61.0511071640020.4573@gannet.stats>

Jay,

Having your code change to know exactly what you are suggesting would be 
helpful.

There is an enhanced version of mosaicplot called mosaic in package vcd, 
and you might like to talk to its maintainers (if the facility is not 
already there, as at a quick glance it seemed not to be).

Brian

On Mon, 7 Nov 2005, John W Emerson wrote:

>
> Hi --
>
> I've found a need for an additional option to mosaicplot(), to suppress
> the labels.  It's not difficult, obviously, a minor thing.
>
> Would you like me to submit my revised code (I'll use your code rather
> than my original source code which was adapted for S-Plus and R)?  Or
> it might be a 5-minute change for the appropriate person.  No problem
> either way, just let me know.
>
> Cheers,
>
> Jay
>
> John Emerson
> Assistant Professor of Statistics
> Yale University
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From bolker at zoo.ufl.edu  Mon Nov  7 18:34:08 2005
From: bolker at zoo.ufl.edu (Ben Bolker)
Date: Mon, 07 Nov 2005 12:34:08 -0500
Subject: [Rd] Brainstorm: Alpha and Beta testing of R versions
Message-ID: <436F9010.3010606@zoo.ufl.edu>


   My most common problem with the bug reporting system
is distinguishing between bugs and my own stupidity
or confusion.  So I post to the r-devel list to ask;
even when there is a response, I may then
fail to get around to submitting the bug report itself ...
I know R-core doesn't want the bug list cluttered up with
non-bugs, but this two-step process often gets in the way of
my filing potential bugs.
   (I realize this is straying fairly far from the "alpha/beta
testing" topic to a more general discussion of bug reporting
etc. etc.)
   The main reason I fail to do alpha/beta checking is
that I like to keep using the same version of R as my classes
are currently using, and I haven't yet gone to the trouble of 
maintaining different versions on my system.

   [did anyone have any thoughts on my  4 Nov query about
errors vs warnings in dgamma?]


   cheers
     Ben Bolker

-- 
620B Bartram Hall                            bolker at zoo.ufl.edu
Zoology Department, University of Florida    http://www.zoo.ufl.edu/bolker
Box 118525                                   (ph)  352-392-5697
Gainesville, FL 32611-8525                   (fax) 352-392-3704


From john.emerson at yale.edu  Mon Nov  7 19:06:05 2005
From: john.emerson at yale.edu (John W Emerson)
Date: Mon, 7 Nov 2005 13:06:05 -0500 (EST)
Subject: [Rd] mosaicplot() update
In-Reply-To: <Pine.LNX.4.61.0511071640020.4573@gannet.stats>
Message-ID: <Pine.LNX.4.44.0511071303160.22062-100000@ares.its.yale.edu>


Brian,

Thanks, I'll send the code with the few changes marked
with something obvious like,

################################# JWE changed previous line,

etc...

I wasn't aware of the {vcd} implementation.  It looks like it
is built on my original S-Plus code, too.  Always nice to get
the citation!

Jay


On Mon, 7 Nov 2005, Prof Brian Ripley wrote:

> Jay,
> 
> Having your code change to know exactly what you are suggesting would be 
> helpful.
> 
> There is an enhanced version of mosaicplot called mosaic in package vcd, 
> and you might like to talk to its maintainers (if the facility is not 
> already there, as at a quick glance it seemed not to be).
> 
> Brian
> 
> On Mon, 7 Nov 2005, John W Emerson wrote:
> 
> >
> > Hi --
> >
> > I've found a need for an additional option to mosaicplot(), to suppress
> > the labels.  It's not difficult, obviously, a minor thing.
> >
> > Would you like me to submit my revised code (I'll use your code rather
> > than my original source code which was adapted for S-Plus and R)?  Or
> > it might be a 5-minute change for the appropriate person.  No problem
> > either way, just let me know.
> >
> > Cheers,
> >
> > Jay
> >
> > John Emerson
> > Assistant Professor of Statistics
> > Yale University
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
> >
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>


From Achim.Zeileis at wu-wien.ac.at  Mon Nov  7 19:50:30 2005
From: Achim.Zeileis at wu-wien.ac.at (Achim Zeileis)
Date: Mon, 7 Nov 2005 19:50:30 +0100
Subject: [Rd] mosaicplot() update
In-Reply-To: <Pine.LNX.4.61.0511071640020.4573@gannet.stats>
References: <Pine.LNX.4.44.0511070952450.24907-100000@argos.its.yale.edu>
	<Pine.LNX.4.61.0511071640020.4573@gannet.stats>
Message-ID: <20051107195030.5207c4ab.Achim.Zeileis@wu-wien.ac.at>

On Mon, 7 Nov 2005 16:43:08 +0000 (GMT) Prof Brian Ripley wrote:

> Jay,
> 
> Having your code change to know exactly what you are suggesting would
> be helpful.

Depending on what exactly you want, you could do e.g.
  mosaic(HairEyeColor, labeling = NULL)
which prints no labels at all. If you only want to suppress
names(dimnames(HairEyeColor)) you could do
  mosaic(HairEyeColor, labeling_args = list(varnames = FALSE))
etc.
 
> There is an enhanced version of mosaicplot called mosaic in package
> vcd, and you might like to talk to its maintainers (if the facility is
> not already there, as at a quick glance it seemed not to be).

The user can change everything (well, almost)! Unfortunately, this
flexibility means that most options will not be obvious `at a quick
glance'. David (as the main author) knows most options, even I (as a
co-author) had to look up how the above works.
But now there are at least some vignettes which explain the many knobs
and switches in mosaic().
Z

> Brian
> 
> On Mon, 7 Nov 2005, John W Emerson wrote:
> 
> >
> > Hi --
> >
> > I've found a need for an additional option to mosaicplot(), to
> > suppress the labels.  It's not difficult, obviously, a minor thing.
> >
> > Would you like me to submit my revised code (I'll use your code
> > rather than my original source code which was adapted for S-Plus and
> > R)?  Or it might be a 5-minute change for the appropriate person. 
> > No problem either way, just let me know.
> >
> > Cheers,
> >
> > Jay
> >
> > John Emerson
> > Assistant Professor of Statistics
> > Yale University
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
> >
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From Olaf.Schenk at unibas.ch  Mon Nov  7 19:57:28 2005
From: Olaf.Schenk at unibas.ch (Olaf.Schenk@unibas.ch)
Date: Mon,  7 Nov 2005 19:57:28 +0100
Subject: [Rd] R thread safe
Message-ID: <1131389848.436fa39855a52@webmail.unibas.ch>

Dear R-dev,

I would like to accelerate my R computation by using parallel OpenMP compilers
(e.g from Pathscale) on a 2-processor AMD server and I would like to know
whether R is a tread safe library. The main kernel of the OpenMP
parallelization is a C SEXP function that performs the computational routine in
parallel with:

*******************
SEXP example(SEXP list, SEXP expr, SEXP rho)
     {
       R_len_t i, n = length(list);
       SEXP ans, alocal;

       omp_lock_t lck;
       PROTECT(ans = allocVector(VECSXP, n));
       ans = allocVector(VECSXP, n);
       omp_init_lock(&lck);
#pragma omp parallel for default(none) private(i, alocal) shared(list,
lck,rho, ans, n, expr)
       for(i = 0; i < n; i++) {

          omp_set_lock(&lck);
             PROTECT(alocal = allocVector(VECSXP, 1));
             alocal = allocVector(VECSXP, 1);
             defineVar(install("x"), VECTOR_ELT(list, i), rho);
          omp_unset_lock(&lck);

          /* do computational kernel in parallel */
          alocal = eval(expr, rho);

          omp_set_lock(&lck);
             SET_VECTOR_ELT(ans, i, alocal);
             UNPROTECT(1);
          omp_unset_lock(&lck);

       }
       setAttrib(ans, R_NamesSymbol, getAttrib(list, R_NamesSymbol));
       UNPROTECT(1);
       return(ans);
}

***********

The code works fine using one thread and breaks currently down with 2 threads. 
I am using a recent R distribution and  the complete R code is compile with
"-openmp" and the Pathscale compiler suite.

Thanks in advance,
Olaf


From Achim.Zeileis at wu-wien.ac.at  Mon Nov  7 20:24:19 2005
From: Achim.Zeileis at wu-wien.ac.at (Achim Zeileis)
Date: Mon, 7 Nov 2005 20:24:19 +0100
Subject: [Rd] mosaicplot() update
In-Reply-To: <Pine.LNX.4.44.0511071303160.22062-100000@ares.its.yale.edu>
References: <Pine.LNX.4.61.0511071640020.4573@gannet.stats>
	<Pine.LNX.4.44.0511071303160.22062-100000@ares.its.yale.edu>
Message-ID: <20051107202419.26180a47.Achim.Zeileis@wu-wien.ac.at>

Jay:

> Thanks, I'll send the code with the few changes marked
> with something obvious like,
> 
> ################################# JWE changed previous line,
> 
> etc...
> 
> I wasn't aware of the {vcd} implementation.  It looks like it
> is built on my original S-Plus code, too. 

Nope, everything written from scratch using Paul's wonderful grid
graphics. The internals look completely different and David's
implementation provides not only mosaic plots but also association and
sieve plots within the same framework.

> Always nice to get the citation!

...give credit where credit is due...:-)
Best,
Z

> Jay
> 
> 
> On Mon, 7 Nov 2005, Prof Brian Ripley wrote:
> 
> > Jay,
> > 
> > Having your code change to know exactly what you are suggesting
> > would be helpful.
> > 
> > There is an enhanced version of mosaicplot called mosaic in package
> > vcd, and you might like to talk to its maintainers (if the facility
> > is not already there, as at a quick glance it seemed not to be).
> > 
> > Brian
> > 
> > On Mon, 7 Nov 2005, John W Emerson wrote:
> > 
> > >
> > > Hi --
> > >
> > > I've found a need for an additional option to mosaicplot(), to
> > > suppress the labels.  It's not difficult, obviously, a minor
> > > thing.
> > >
> > > Would you like me to submit my revised code (I'll use your code
> > > rather than my original source code which was adapted for S-Plus
> > > and R)?  Or it might be a 5-minute change for the appropriate
> > > person.  No problem either way, just let me know.
> > >
> > > Cheers,
> > >
> > > Jay
> > >
> > > John Emerson
> > > Assistant Professor of Statistics
> > > Yale University
> > >
> > > ______________________________________________
> > > R-devel at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-devel
> > >
> > >
> > 
> > -- 
> > Brian D. Ripley,                  ripley at stats.ox.ac.uk
> > Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> > University of Oxford,             Tel:  +44 1865 272861 (self)
> > 1 South Parks Road,                     +44 1865 272866 (PA)
> > Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> >
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From john.emerson at yale.edu  Mon Nov  7 22:09:07 2005
From: john.emerson at yale.edu (John W Emerson)
Date: Mon, 7 Nov 2005 16:09:07 -0500 (EST)
Subject: [Rd] mosaicplot() update
In-Reply-To: <20051107202419.26180a47.Achim.Zeileis@wu-wien.ac.at>
Message-ID: <Pine.LNX.4.44.0511071608060.14655-100000@ares.its.yale.edu>


Thanks, obviously my mistake.  The google search 
turned up my code with {vcd} after it, so there is
at least one page out there where my version (mosaicplot)
is listed incorrectly as being in {vcd}.

Cheers!

Jay

On Mon, 7 Nov 2005, Achim Zeileis wrote:

> Jay:
> 
> > Thanks, I'll send the code with the few changes marked
> > with something obvious like,
> > 
> > ################################# JWE changed previous line,
> > 
> > etc...
> > 
> > I wasn't aware of the {vcd} implementation.  It looks like it
> > is built on my original S-Plus code, too. 
> 
> Nope, everything written from scratch using Paul's wonderful grid
> graphics. The internals look completely different and David's
> implementation provides not only mosaic plots but also association and
> sieve plots within the same framework.
> 
> > Always nice to get the citation!
> 
> ...give credit where credit is due...:-)
> Best,
> Z
> 
> > Jay
> > 
> > 
> > On Mon, 7 Nov 2005, Prof Brian Ripley wrote:
> > 
> > > Jay,
> > > 
> > > Having your code change to know exactly what you are suggesting
> > > would be helpful.
> > > 
> > > There is an enhanced version of mosaicplot called mosaic in package
> > > vcd, and you might like to talk to its maintainers (if the facility
> > > is not already there, as at a quick glance it seemed not to be).
> > > 
> > > Brian
> > > 
> > > On Mon, 7 Nov 2005, John W Emerson wrote:
> > > 
> > > >
> > > > Hi --
> > > >
> > > > I've found a need for an additional option to mosaicplot(), to
> > > > suppress the labels.  It's not difficult, obviously, a minor
> > > > thing.
> > > >
> > > > Would you like me to submit my revised code (I'll use your code
> > > > rather than my original source code which was adapted for S-Plus
> > > > and R)?  Or it might be a 5-minute change for the appropriate
> > > > person.  No problem either way, just let me know.
> > > >
> > > > Cheers,
> > > >
> > > > Jay
> > > >
> > > > John Emerson
> > > > Assistant Professor of Statistics
> > > > Yale University
> > > >
> > > > ______________________________________________
> > > > R-devel at r-project.org mailing list
> > > > https://stat.ethz.ch/mailman/listinfo/r-devel
> > > >
> > > >
> > > 
> > > -- 
> > > Brian D. Ripley,                  ripley at stats.ox.ac.uk
> > > Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> > > University of Oxford,             Tel:  +44 1865 272861 (self)
> > > 1 South Parks Road,                     +44 1865 272866 (PA)
> > > Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> > >
> > 
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> > 
>


From maechler at stat.math.ethz.ch  Mon Nov  7 22:09:46 2005
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 7 Nov 2005 22:09:46 +0100
Subject: [Rd] Brainstorm: Alpha and Beta testing of R versions
In-Reply-To: <20051106000130.GB1601@ms.unimelb.edu.au>
References: <p06210200bf8fdc0381f9@[129.206.113.130]>
	<A2AC7F8A-16B6-4E81-813D-3889DEBB28EF@r-project.org>
	<17259.8903.764080.973751@stat.math.ethz.ch>
	<20051106000130.GB1601@ms.unimelb.edu.au>
Message-ID: <17263.49818.469371.738460@stat.math.ethz.ch>

Thanks a lot, 
Andrew, for your input!

A general point about your suggestions:  You seem to assume that
bug reports are typically entered via the R-bugs web interface
(which is down at the moment and for a few more dozen hours probably},
rather than via  R's builtin  bug.report() function or the
simple e-mail to R-bugs at r-project.org  [[which will also not
properly work for the moment, as long as the bug repository is
suffering from a fiber cable cut in Kopenhagen]].

For some dinosaurs like me, having to fill a web page rather
than sending e-mail would be quite a loss of comfort, but
actually, it might not be a bad idea to require a unique
bug-entry interface -- actually we have been thinking of moving
to bugzilla -- if only Peter Dalgaard could find a smart enough
person (even to be paid) who'd port all the old bug reports into the
new format.. 


>>>>> "Andrew" == Andrew Robinson <A.Robinson at ms.unimelb.edu.au>
>>>>>     on Sun, 6 Nov 2005 11:01:30 +1100 writes:

    Andrew> Hi Martin, On Fri, Nov 04, 2005 at 09:58:47AM +0100,
    Andrew> Martin Maechler wrote:
    >> [Mainly for R-foundation members; but kept in public for
    >> general brainstorming...]

    Andrew> I'll take up the invitation to brainstorm.

good, thank 

    Andrew> As a user of R for a number of years, I'd really
    Andrew> like to perform some useful service.  I use a
    Andrew> relatively obscure platform (FreeBSD) and I can
    Andrew> compile code.  I'd like to think that I'm in the
    Andrew> target market for beta testing :).  

indeed!

    Andrew> But, I'm timid. I do not feel, in general, that R core welcomes bug
    Andrew> reports.

I think that's a partly wrong feeling; understandibly nourished
by some of our reactions about some "bug reports" that stemmed
from user misconceptions.  As you've remarked below, I've
expressed gratitude more than once for helpful bug reports.

    Andrew> I think that there are several things that could be
    Andrew> tried to encourage more, and more useful, bug
    Andrew> reports.

    Andrew> 1) Put the following text on the *front page* of the
    Andrew> tracking system, so that it is seen before the
    Andrew> reader clicks on "New Bug Report":

    Andrew> "Before submitting a bug report, please read Chapter
    Andrew> `R Bugs' of `The R FAQ'. It describes what a bug is
    Andrew> and how to report a bug.

    Andrew> If you are not sure whether you have observed a bug
    Andrew> or not, it is a good idea to ask on the mailing list
    Andrew> R-Help by sending an e-mail to
    Andrew> r-help at stat.math.ethz.ch rather than submitting a
    Andrew> bug report."

    Andrew> (BTW is this true also for alpha/beta testing?)

Yes, in principile.  The only thing to be changed would be 
   sub("-help", "-devel",  <the above text>)

    Andrew> 2) Try to use the structure of the reporting page to
    Andrew> prompt good reporting.  On the report page,
    Andrew> summarize the key points of identifying and
    Andrew> reporting a bug in a checklist format.  Maybe even
    Andrew> insist that the boxes be checked before allowing
    Andrew> submission.  Include seperate text boxes for
    Andrew> description and sample code, to suggest that sample
    Andrew> code is valued.

    Andrew> 3) On either or both pages (and in FAQ), explain
    Andrew> that thoughtful bug reports are valued and
    Andrew> appreciated.  Further, explain that bug reports that
    Andrew> do not follow the protocol are less valuable, and
    Andrew> take more time.

    Andrew> 4) Add checkboxes to the report page for alpha/beta.
    Andrew> (I suggest this for the purposes of marketing, not
    Andrew> organization.)

    Andrew> 5) On the report page, include hyperlinks to
    Andrew> archived bug reports that were good.  Do likewise
    Andrew> with some artificial bug reports that are bad.

    Andrew> 6) Add an intermediate, draft step for bug
    Andrew> submission, to allow checking.  If possible, include
    Andrew> as part of this step an automated pattern matching
    Andrew> call that identifies similarly texted bug reports,
    Andrew> provides links to the reports, and invites a
    Andrew> last-minute cross-check.


    Andrew> 7) Keep a list of people who report useful bugs in
    Andrew> alpha/beta phase on the website.  Many academics
    Andrew> could point to it as evidence of community service.

    >> In order to discourage an increased number of non-bug
    >> reports we may have to also open a "hall of shame"
    >> though...

    Andrew> 8) I'm sure that you're being ironic!  

indeed I was, partly.  The point was just that if the bug
reporting will be something like a challenge with prizes, we had
to discourage too many entries {which would be made just to try
to win (a|the) prize}.

    Andrew> 8) I'm sure that you're being ironic!  But I will
    Andrew> take the point seriously, for what it's worth.  I
    Andrew> think that humiliating submitters who haven't
    Andrew> followed the protocol is deleterious.  It seems like
    Andrew> almost every month we see someone get slapped on the
    Andrew> wrist for not doing something the right way.  Of
    Andrew> course, it's frustrating that people aren't
    Andrew> following the posting guide.  But, why is that?
    Andrew> Where is the breakdown?  It might be interesting to
    Andrew> try some follow-up (an exit interview!). If someone
    Andrew> has failed to follow the protocol, perhaps we should
    Andrew> try to find out why it was confusing, or if they
    Andrew> just ignored it.

    Andrew>    The R-core is surrounded by, and serves, a
    Andrew> community that comprises people who are not
    Andrew> sufficiently good at what R-core does to be invited
    Andrew> in to R-core. But, we're clearly interested in what
    Andrew> R-core produces.  Please don't assume that bug
    Andrew> submissions that do not follow the R protocol are
    Andrew> the consequence of deliberate malfeasance.

    Andrew>    To paraphrase Ian Fleming: Once is happenstance.
    Andrew> Twice is incompetence.  The third time, Mr. Bond, is
    Andrew> enemy action. So, ...

    Andrew> 9) Publicly thank bug reporters whether their
    Andrew> reports are useful or not.  I just googled 'R-devel
    Andrew> thank' and you figure prominently, Martin :).

Thanks again, Andrew,
for your useful input!

Martin


From duncan at wald.ucdavis.edu  Mon Nov  7 22:35:22 2005
From: duncan at wald.ucdavis.edu (Duncan Temple Lang)
Date: Mon, 07 Nov 2005 13:35:22 -0800
Subject: [Rd] R thread safe
In-Reply-To: <1131389848.436fa39855a52@webmail.unibas.ch>
References: <1131389848.436fa39855a52@webmail.unibas.ch>
Message-ID: <436FC89A.1060000@wald.ucdavis.edu>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1



R is not yet thread safe.
We are working on it, and I hope to make some progress before
the end of the year.  (This one even!)

 D.


Olaf.Schenk at unibas.ch wrote:
> Dear R-dev,
> 
> I would like to accelerate my R computation by using parallel OpenMP compilers
> (e.g from Pathscale) on a 2-processor AMD server and I would like to know
> whether R is a tread safe library. The main kernel of the OpenMP
> parallelization is a C SEXP function that performs the computational routine in
> parallel with:
> 
> *******************
> SEXP example(SEXP list, SEXP expr, SEXP rho)
>      {
>        R_len_t i, n = length(list);
>        SEXP ans, alocal;
> 
>        omp_lock_t lck;
>        PROTECT(ans = allocVector(VECSXP, n));
>        ans = allocVector(VECSXP, n);
>        omp_init_lock(&lck);
> #pragma omp parallel for default(none) private(i, alocal) shared(list,
> lck,rho, ans, n, expr)
>        for(i = 0; i < n; i++) {
> 
>           omp_set_lock(&lck);
>              PROTECT(alocal = allocVector(VECSXP, 1));
>              alocal = allocVector(VECSXP, 1);
>              defineVar(install("x"), VECTOR_ELT(list, i), rho);
>           omp_unset_lock(&lck);
> 
>           /* do computational kernel in parallel */
>           alocal = eval(expr, rho);
> 
>           omp_set_lock(&lck);
>              SET_VECTOR_ELT(ans, i, alocal);
>              UNPROTECT(1);
>           omp_unset_lock(&lck);
> 
>        }
>        setAttrib(ans, R_NamesSymbol, getAttrib(list, R_NamesSymbol));
>        UNPROTECT(1);
>        return(ans);
> }
> 
> ***********
> 
> The code works fine using one thread and breaks currently down with 2 threads. 
> I am using a recent R distribution and  the complete R code is compile with
> "-openmp" and the Pathscale compiler suite.
> 
> Thanks in advance,
> Olaf
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

- --
Duncan Temple Lang                duncan at wald.ucdavis.edu
Department of Statistics          work:  (530) 752-4782
371 Kerr Hall                     fax:   (530) 752-7099
One Shields Ave.
University of California at Davis
Davis, CA 95616, USA
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.2 (Darwin)
Comment: Using GnuPG with Thunderbird - http://enigmail.mozdev.org

iD8DBQFDb8ia9p/Jzwa2QP4RAjHoAJ9/VVL5DIRwE4tYjwM+0oQPKjmQ4QCeNzFa
lX6CVF5yVQZPNSE3bZPr7q4=
=hsjc
-----END PGP SIGNATURE-----


From A.Robinson at ms.unimelb.edu.au  Mon Nov  7 23:56:35 2005
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Tue, 8 Nov 2005 09:56:35 +1100
Subject: [Rd] Brainstorm: Alpha and Beta testing of R versions
In-Reply-To: <17263.49818.469371.738460@stat.math.ethz.ch>
References: <p06210200bf8fdc0381f9@[129.206.113.130]>
	<A2AC7F8A-16B6-4E81-813D-3889DEBB28EF@r-project.org>
	<17259.8903.764080.973751@stat.math.ethz.ch>
	<20051106000130.GB1601@ms.unimelb.edu.au>
	<17263.49818.469371.738460@stat.math.ethz.ch>
Message-ID: <20051107225635.GS34329@ms.unimelb.edu.au>

Martin, you're very welcome.  

> A general point about your suggestions:  You seem to assume that
> bug reports are typically entered via the R-bugs web interface

Yes, that was the premiss of my suggestions.  Perhaps to supplement
these ideas, bug.report() could be rewritten to prompt useful
information, much as prompt() does. And simple e-mail to
R-bugs at r-project.org could be filtered to only allow entries from R
core, and/or a list of registered beta testers.

> actually we have been thinking of moving to bugzilla -- if only
> Peter Dalgaard could find a smart enough person (even to be paid)
> who'd port all the old bug reports into the new format..

I see that this would be useful.  What are the challenges? If funding
is available, then I wonder if any of the linked organizations might
be suitable?

http://www.bugzilla.org/support/consulting.html

> As you've remarked below, I've expressed gratitude more than once
> for helpful bug reports.

Absolutely, and the effect is appreciated.  Sadly, the average user
struggles to distinguish between a helpful and an unhelpful bug report
before sending it.

> indeed I was, partly.  The point was just that if the bug
> reporting will be something like a challenge with prizes, we had
> to discourage too many entries {which would be made just to try
> to win (a|the) prize}.

Yes, I see that.  I really don't think that we need prizes; I really
do think that we need to create an environment that actively mitigates
against the kinds of error that you/we find so frustrating. A sort of
TQM strategy.

Cheers

Andrew
-- 
Andrew Robinson
Senior Lecturer in Statistics                       Tel: +61-3-8344-9763
Department of Mathematics and Statistics            Fax: +61-3-8344-4599
University of Melbourne, VIC 3010 Australia
Email: a.robinson at ms.unimelb.edu.au    Website: http://www.ms.unimelb.edu.au


From h.wickham at gmail.com  Tue Nov  8 00:10:40 2005
From: h.wickham at gmail.com (hadley wickham)
Date: Mon, 7 Nov 2005 17:10:40 -0600
Subject: [Rd] Brainstorm: Alpha and Beta testing of R versions
In-Reply-To: <17263.49818.469371.738460@stat.math.ethz.ch>
References: <p06210200bf8fdc0381f9@129.206.113.130>
	<A2AC7F8A-16B6-4E81-813D-3889DEBB28EF@r-project.org>
	<17259.8903.764080.973751@stat.math.ethz.ch>
	<20051106000130.GB1601@ms.unimelb.edu.au>
	<17263.49818.469371.738460@stat.math.ethz.ch>
Message-ID: <f8e6ff050511071510r371415d7o42593afbe4f23739@mail.gmail.com>

> actually, it might not be a bad idea to require a unique
> bug-entry interface -- actually we have been thinking of moving
> to bugzilla -- if only Peter Dalgaard could find a smart enough
> person (even to be paid) who'd port all the old bug reports into the
> new format..

If you haven't already it might worthwhile looking in to fogbugz and trac.

Fogbugz (http://www.fogcreek.com/FogBugz/) is a commercial bug
tracking software package.  It is very professional and has been
designed to make tracking and submitting bugs as easy as possible
(sometimes you do get what you pay for).

Trac (http://www.edgewall.com/trac/) is more of an integrated software
development environment (open source) offering svn repository
browsing, a wiki and bug tracking.  It makes it very easy to link
between bug reports and the commits that fix them (although I know
fogbugz does this too, and I'm sure bugzilla does as well).

Hadley


From john.emerson at yale.edu  Tue Nov  8 00:04:43 2005
From: john.emerson at yale.edu (John W Emerson)
Date: Mon, 7 Nov 2005 18:04:43 -0500 (EST)
Subject: [Rd] mosaicplot() update and clarification
In-Reply-To: <20051107202419.26180a47.Achim.Zeileis@wu-wien.ac.at>
Message-ID: <Pine.LNX.4.44.0511071750030.10318-100000@ajax.its.yale.edu>


All,

Again, my apologies for seeming to claim credit for
your other mosaic implementation.  However, there are two
sources of this confusion, and I hope the following helps.

1. "my" implementation (e.g. the one originally written for
and included in S-Plus, then modified and improved for R
by "KH") appears to have been included in a package
called "vcd" at some point in time.  This was one of the
first hits when I used googled "vcd".  See, for example:

http://www.maths.lth.se/help/R/.R/library/vcd/html/mosaicplot.html

2. Once I load library(vcd) and do ?mosaicplot, the top of the
help page does, in fact, say "package:vcd" although it credits me
as the author?!  This was downloaded today from CRAN.  This most
certainly is not my fault, nor do I want to take credit for
something that isn't mine.  If {vcd} uses R:base's mosaicplot(),
then, of course, everything is fine, but I gather from your email
that this is not the case. So perhaps the {vcd} package needs to
update its documentation.  If I am misunderstanding something,
again, I apologize.

Anyway, the more interested people we have improving
our graphics tools, the better!  !_)

Cheers,

Jay


On Mon, 7 Nov 2005, Achim Zeileis wrote:

> Jay:
> 
> > Thanks, I'll send the code with the few changes marked
> > with something obvious like,
> > 
> > ################################# JWE changed previous line,
> > 
> > etc...
> > 
> > I wasn't aware of the {vcd} implementation.  It looks like it
> > is built on my original S-Plus code, too. 
> 
> Nope, everything written from scratch using Paul's wonderful grid
> graphics. The internals look completely different and David's
> implementation provides not only mosaic plots but also association and
> sieve plots within the same framework.
> 
> > Always nice to get the citation!
> 
> ...give credit where credit is due...:-)
> Best,
> Z
> 
> > Jay
> > 
> > 
> > On Mon, 7 Nov 2005, Prof Brian Ripley wrote:
> > 
> > > Jay,
> > > 
> > > Having your code change to know exactly what you are suggesting
> > > would be helpful.
> > > 
> > > There is an enhanced version of mosaicplot called mosaic in package
> > > vcd, and you might like to talk to its maintainers (if the facility
> > > is not already there, as at a quick glance it seemed not to be).
> > > 
> > > Brian
> > > 
> > > On Mon, 7 Nov 2005, John W Emerson wrote:
> > > 
> > > >
> > > > Hi --
> > > >
> > > > I've found a need for an additional option to mosaicplot(), to
> > > > suppress the labels.  It's not difficult, obviously, a minor
> > > > thing.
> > > >
> > > > Would you like me to submit my revised code (I'll use your code
> > > > rather than my original source code which was adapted for S-Plus
> > > > and R)?  Or it might be a 5-minute change for the appropriate
> > > > person.  No problem either way, just let me know.
> > > >
> > > > Cheers,
> > > >
> > > > Jay
> > > >
> > > > John Emerson
> > > > Assistant Professor of Statistics
> > > > Yale University
> > > >
> > > > ______________________________________________
> > > > R-devel at r-project.org mailing list
> > > > https://stat.ethz.ch/mailman/listinfo/r-devel
> > > >
> > > >
> > > 
> > > -- 
> > > Brian D. Ripley,                  ripley at stats.ox.ac.uk
> > > Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> > > University of Oxford,             Tel:  +44 1865 272861 (self)
> > > 1 South Parks Road,                     +44 1865 272866 (PA)
> > > Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> > >
> > 
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> > 
>


From ripley at stats.ox.ac.uk  Tue Nov  8 08:44:41 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 8 Nov 2005 07:44:41 +0000 (GMT)
Subject: [Rd] dgamma error condition?
In-Reply-To: <436B78AF.9010602@zoo.ufl.edu>
References: <436B78AF.9010602@zoo.ufl.edu>
Message-ID: <Pine.LNX.4.61.0511080736390.14096@gannet.stats>

On Fri, 4 Nov 2005, Ben Bolker wrote:

>
>   There's an apparent inconsistency between the
> behavior of d(pqr)gamma and other distribution
> functions for "bad" parameter values.  Specifically,
> most distributions give NaN and a warning for bad
> parameters (e.g. probabilities <0 or >1).  In contrast,
> d(pqr)gamma actually gives an error and stops when shape<0.
> I don't see why it has to be this way -- the internal
> C code is set up to detect shape<0 (or scale<0) and
> return NaN and a warning, and none of the other
> distribution functions in that bit of the code have
> similar behavior.
>
>   It would seem more consistent (and would be more
> convenient for me -- the error-instead-of-warning
> is making me have to jump through additional hoops)
> if dgamma just returned NaN and a warning.
>
>    Any thoughts?

No one has come up with any, so let us remove the errors in R-devel.

Note that rgamma is not protected at C level: try rgamma(10, -2), or 
(worse) rgamma(10, -20)  after removing the stop() call.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From Torsten.Hothorn at rzmail.uni-erlangen.de  Tue Nov  8 09:22:03 2005
From: Torsten.Hothorn at rzmail.uni-erlangen.de (Torsten Hothorn)
Date: Tue, 8 Nov 2005 09:22:03 +0100 (CET)
Subject: [Rd] mosaicplot() update and clarification
In-Reply-To: <Pine.LNX.4.44.0511071750030.10318-100000@ajax.its.yale.edu>
References: <Pine.LNX.4.44.0511071750030.10318-100000@ajax.its.yale.edu>
Message-ID: <Pine.LNX.4.51.0511080917010.18360@artemis.imbe.med.uni-erlangen.de>


>
> All,
>
> Again, my apologies for seeming to claim credit for
> your other mosaic implementation.  However, there are two
> sources of this confusion, and I hope the following helps.
>
> 1. "my" implementation (e.g. the one originally written for
> and included in S-Plus, then modified and improved for R
> by "KH") appears to have been included in a package
> called "vcd" at some point in time.  This was one of the
> first hits when I used googled "vcd".  See, for example:
>
> http://www.maths.lth.se/help/R/.R/library/vcd/html/mosaicplot.html
>
> 2. Once I load library(vcd) and do ?mosaicplot, the top of the
> help page does, in fact, say "package:vcd" although it credits me
> as the author?!  This was downloaded today from CRAN.  This most
> certainly is not my fault, nor do I want to take credit for
> something that isn't mine.  If {vcd} uses R:base's mosaicplot(),
> then, of course, everything is fine, but I gather from your email
> that this is not the case. So perhaps the {vcd} package needs to
> update its documentation.  If I am misunderstanding something,
> again, I apologize.

`mosaicplot' is a function in package `graphics' (and lists you as the
author) and `mosaic' is a function in package `vcd'. There _was_ a
function `vcd::mosaicplot' in older versions of the `vcd' package masking
`graphics::mosaicplot: `update.packages("vcd")' will update the package
and documentation on your system :-)

Best,

Torsten

>
> Anyway, the more interested people we have improving
> our graphics tools, the better!  !_)
>
> Cheers,
>
> Jay
>
>
> On Mon, 7 Nov 2005, Achim Zeileis wrote:
>
> > Jay:
> >
> > > Thanks, I'll send the code with the few changes marked
> > > with something obvious like,
> > >
> > > ################################# JWE changed previous line,
> > >
> > > etc...
> > >
> > > I wasn't aware of the {vcd} implementation.  It looks like it
> > > is built on my original S-Plus code, too.
> >
> > Nope, everything written from scratch using Paul's wonderful grid
> > graphics. The internals look completely different and David's
> > implementation provides not only mosaic plots but also association and
> > sieve plots within the same framework.
> >
> > > Always nice to get the citation!
> >
> > ...give credit where credit is due...:-)
> > Best,
> > Z
> >
> > > Jay
> > >
> > >
> > > On Mon, 7 Nov 2005, Prof Brian Ripley wrote:
> > >
> > > > Jay,
> > > >
> > > > Having your code change to know exactly what you are suggesting
> > > > would be helpful.
> > > >
> > > > There is an enhanced version of mosaicplot called mosaic in package
> > > > vcd, and you might like to talk to its maintainers (if the facility
> > > > is not already there, as at a quick glance it seemed not to be).
> > > >
> > > > Brian
> > > >
> > > > On Mon, 7 Nov 2005, John W Emerson wrote:
> > > >
> > > > >
> > > > > Hi --
> > > > >
> > > > > I've found a need for an additional option to mosaicplot(), to
> > > > > suppress the labels.  It's not difficult, obviously, a minor
> > > > > thing.
> > > > >
> > > > > Would you like me to submit my revised code (I'll use your code
> > > > > rather than my original source code which was adapted for S-Plus
> > > > > and R)?  Or it might be a 5-minute change for the appropriate
> > > > > person.  No problem either way, just let me know.
> > > > >
> > > > > Cheers,
> > > > >
> > > > > Jay
> > > > >
> > > > > John Emerson
> > > > > Assistant Professor of Statistics
> > > > > Yale University
> > > > >
> > > > > ______________________________________________
> > > > > R-devel at r-project.org mailing list
> > > > > https://stat.ethz.ch/mailman/listinfo/r-devel
> > > > >
> > > > >
> > > >
> > > > --
> > > > Brian D. Ripley,                  ripley at stats.ox.ac.uk
> > > > Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> > > > University of Oxford,             Tel:  +44 1865 272861 (self)
> > > > 1 South Parks Road,                     +44 1865 272866 (PA)
> > > > Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> > > >
> > >
> > > ______________________________________________
> > > R-devel at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-devel
> > >
> >
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From Achim.Zeileis at wu-wien.ac.at  Tue Nov  8 11:24:42 2005
From: Achim.Zeileis at wu-wien.ac.at (Achim Zeileis)
Date: Tue, 8 Nov 2005 11:24:42 +0100
Subject: [Rd] mosaicplot() update and clarification
In-Reply-To: <Pine.LNX.4.51.0511080917010.18360@artemis.imbe.med.uni-erlangen.de>
References: <Pine.LNX.4.44.0511071750030.10318-100000@ajax.its.yale.edu>
	<Pine.LNX.4.51.0511080917010.18360@artemis.imbe.med.uni-erlangen.de>
Message-ID: <20051108112442.28359ffe.Achim.Zeileis@wu-wien.ac.at>

Torsten, thanks for pointing this out. 

Jay, just to expand a little on this explanation:

> `mosaicplot' is a function in package `graphics' (and lists you as the
> author) and `mosaic' is a function in package `vcd'. There _was_ a
> function `vcd::mosaicplot' in older versions of the `vcd' package
> masking`graphics::mosaicplot: `update.packages("vcd")' will update the
> package and documentation on your system :-)

The reason for these changes in vcd is the following: When we started
the project we just extended the mosaicplot() function from graphics
(which is based on your code) in a few directions but keeping it
upwardly compatible. Therefore, we decided that it's ok to overload the
graphics function.
Rather soon we wanted something based on grid and something which can be
more easily modified and extended and we've written about three (I
think) new implementations in grid. As the interface needed to be quite
different from the original one, we decided that it wouldn't be
appropriate to overload the graphics function and hence chose a new
function name mosaic(). The corresponding man page still has Emerson
(1998) in the references but does not mention you as the author (as it
is enitrely new code).

Best,
Z


From bolker at zoo.ufl.edu  Tue Nov  8 15:17:33 2005
From: bolker at zoo.ufl.edu (Ben Bolker)
Date: Tue, 08 Nov 2005 09:17:33 -0500
Subject: [Rd] dgamma error condition?
In-Reply-To: <Pine.LNX.4.61.0511080736390.14096@gannet.stats>
References: <436B78AF.9010602@zoo.ufl.edu>
	<Pine.LNX.4.61.0511080736390.14096@gannet.stats>
Message-ID: <4370B37D.9000807@zoo.ufl.edu>


   thanks.  would you like a patch?
(seems easy enough but I thought I'd offer)
looks like library/stats/R/distn.R and
nmath/rgamma.c need fixing; looks like
qgamma may not check for scale<0 in C
code either ...

   Ben Bolker

Prof Brian Ripley wrote:
> On Fri, 4 Nov 2005, Ben Bolker wrote:
> 
>>
>>   There's an apparent inconsistency between the
>> behavior of d(pqr)gamma and other distribution
>> functions for "bad" parameter values.  Specifically,
>> most distributions give NaN and a warning for bad
>> parameters (e.g. probabilities <0 or >1).  In contrast,
>> d(pqr)gamma actually gives an error and stops when shape<0.
>> I don't see why it has to be this way -- the internal
>> C code is set up to detect shape<0 (or scale<0) and
>> return NaN and a warning, and none of the other
>> distribution functions in that bit of the code have
>> similar behavior.
>>
>>   It would seem more consistent (and would be more
>> convenient for me -- the error-instead-of-warning
>> is making me have to jump through additional hoops)
>> if dgamma just returned NaN and a warning.
>>
>>    Any thoughts?
> 
> 
> No one has come up with any, so let us remove the errors in R-devel.
> 
> Note that rgamma is not protected at C level: try rgamma(10, -2), or 
> (worse) rgamma(10, -20)  after removing the stop() call.
>


From gml4410 at ggr.co.uk  Tue Nov  8 15:50:35 2005
From: gml4410 at ggr.co.uk (gml4410@ggr.co.uk)
Date: Tue,  8 Nov 2005 15:50:35 +0100 (CET)
Subject: [Rd] R-2.2.0: malloc probelm in regex code (PR#8287)
Message-ID: <20051108145035.8779521ED7@slim.kubism.ku.dk>

Full_Name: Gordon Lack
Version: 2.2.0
OS: OSF1/Tur64
Submission from: (NULL) (193.128.25.20)


R-2.2.0 fails to build on OSF1 systems.

.....
make[4]: Leaving directory `..../R-2.2.0/src/library/tools/src
Error in list.files(path, pattern, all.files, full.names, recursive) :
        invalid 'pattern' regular expression
Execution halted
make[3]: *** [all] Error 1
.....



I've tracked down the problem to change (somewhere) in 2.2.0 vs. 2.1.1 which has
resulted in re_node_set_alloc() (in src/main/regex.c) being called with a size
of 0.  Whereas some system (Solaris, Linux, ...) return a valid pointer to a
zero-size allocation, OSF1 returns a NULL pointer on a 0 allocation request
(documented as such, and the Open Group Base Specifications Issue 6 documents
that either may happen).  The calling code treats a NULL return as a ESPACE
error.

In R-2.1.1 this code was not asked to allocate 0 sizes, so I suspect that it
shouldn't be happening here either.

A workaround is to add:

   if (size==0) size=1;     /* OSF1 (at least) returns NULL on 0 alloc */

before the re_malloc (int, size) line in re_node_set_alloc(), which just means
you allocate a small space (which shodul be free()d soon anyway).

The actual regex whcih triggers this during the build is:

 ^tools($|_)


From gilles.guillot at inapg.inra.fr  Tue Nov  8 16:33:49 2005
From: gilles.guillot at inapg.inra.fr (Gilles GUILLOT)
Date: Tue, 8 Nov 2005 16:33:49 +0100
Subject: [Rd] R build under mandriva 10.2
Message-ID: <200511081633.49575.gilles.guillot@inapg.inra.fr>

After upgrading from mandrake 10.1 to mandriva 10.2
I can't build shared archive with R 2.2.0

[guillot at laplace src]$ R CMD SHLIB main.f sub.f wrapper.c 
gcc -shared  -L/usr/local/lib -o main.so main.o sub.o wrapper.o  -lg2c -lm 
-lgcc_s
/usr//bin/ld: cannot find -lg2c
collect2: ld returned 1 exit status
make: *** [main.so] Erreur 1

I guess the information in
http://finzi.psych.upenn.edu/R/Rhelp01/archive/5146.html 
are not relevant any longer.

What is missing ?

Gilles


From ripley at stats.ox.ac.uk  Tue Nov  8 17:11:49 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 8 Nov 2005 16:11:49 +0000 (GMT)
Subject: [Rd] R-2.2.0: malloc probelm in regex code (PR#8287)
In-Reply-To: <20051108145035.8779521ED7@slim.kubism.ku.dk>
References: <20051108145035.8779521ED7@slim.kubism.ku.dk>
Message-ID: <Pine.LNX.4.61.0511081603060.13035@gannet.stats>

Please try R-patched, as this has already been reported for AIX and 
addressed in R-patched and R-devel.

On Tue, 8 Nov 2005 gml4410 at ggr.co.uk wrote:

> Full_Name: Gordon Lack
> Version: 2.2.0
> OS: OSF1/Tur64
> Submission from: (NULL) (193.128.25.20)
>
>
> R-2.2.0 fails to build on OSF1 systems.
>
> .....
> make[4]: Leaving directory `..../R-2.2.0/src/library/tools/src
> Error in list.files(path, pattern, all.files, full.names, recursive) :
>        invalid 'pattern' regular expression
> Execution halted
> make[3]: *** [all] Error 1
> .....
>
>
>
> I've tracked down the problem to change (somewhere) in 2.2.0 vs. 2.1.1 which has
> resulted in re_node_set_alloc() (in src/main/regex.c) being called with a size
> of 0.  Whereas some system (Solaris, Linux, ...) return a valid pointer to a
> zero-size allocation, OSF1 returns a NULL pointer on a 0 allocation request
> (documented as such, and the Open Group Base Specifications Issue 6 documents
> that either may happen).  The calling code treats a NULL return as a ESPACE
> error.
>
> In R-2.1.1 this code was not asked to allocate 0 sizes, so I suspect that it
> shouldn't be happening here either.
>
> A workaround is to add:
>
>   if (size==0) size=1;     /* OSF1 (at least) returns NULL on 0 alloc */
>
> before the re_malloc (int, size) line in re_node_set_alloc(), which just means
> you allocate a small space (which shodul be free()d soon anyway).
>
> The actual regex whcih triggers this during the build is:
>
> ^tools($|_)
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From roberto.ugoccioni at sanpaoloimi.com  Tue Nov  8 17:51:51 2005
From: roberto.ugoccioni at sanpaoloimi.com (roberto.ugoccioni@sanpaoloimi.com)
Date: Tue,  8 Nov 2005 17:51:51 +0100 (CET)
Subject: [Rd] bug in windows GUI/script editor (PR#8288)
Message-ID: <20051108165151.40AA924E60@slim.kubism.ku.dk>

Full_Name: Roberto Ugoccioni
Version: 2.2.0
OS: Windows 2000
Submission from: (NULL) (193.203.232.5)


Running Windows 2000 Professional, all patches up to nov 8, 2005.

> version
         _              
platform i386-pc-mingw32
arch     i386           
os       mingw32        
system   i386, mingw32  
status                  
major    2              
minor    2.0            
year     2005           
month    10             
day      06             
svn rev  35749          
language R  

How to reproduce the bug:

1. launch Rgui.exe
2. menu File->open script
3. close editor clicking on X
4. clicking menu File now generates the fatal error (omitting memory
addresses):

 An instruction referred to a memory location which could not be "read"

Clicking on OK in the error message window causes R to consume 100% CPU and not
to respond - must be terminated from task manager.


From murdoch at stats.uwo.ca  Tue Nov  8 19:00:40 2005
From: murdoch at stats.uwo.ca (murdoch@stats.uwo.ca)
Date: Tue,  8 Nov 2005 19:00:40 +0100 (CET)
Subject: [Rd] bug in windows GUI/script editor (PR#8288)
Message-ID: <20051108180040.8998D24620@slim.kubism.ku.dk>

On 11/8/2005 11:51 AM, roberto.ugoccioni at sanpaoloimi.com wrote:
> Full_Name: Roberto Ugoccioni
> Version: 2.2.0
> OS: Windows 2000
> Submission from: (NULL) (193.203.232.5)
> 
> 
> Running Windows 2000 Professional, all patches up to nov 8, 2005.
> 
> 
>>version
> 
>          _              
> platform i386-pc-mingw32
> arch     i386           
> os       mingw32        
> system   i386, mingw32  
> status                  
> major    2              
> minor    2.0            
> year     2005           
> month    10             
> day      06             
> svn rev  35749          
> language R  
> 
> How to reproduce the bug:
> 
> 1. launch Rgui.exe
> 2. menu File->open script
> 3. close editor clicking on X
> 4. clicking menu File now generates the fatal error (omitting memory
> addresses):
> 
>  An instruction referred to a memory location which could not be "read"
> 
> Clicking on OK in the error message window causes R to consume 100% CPU and not
> to respond - must be terminated from task manager.

I don't see this, but it sounds like something that was fixed before the 
release of 2.2.0, so maybe there's another way to generate the same problem.

Could you give more detail:

  - are you running in the default MDI mode (one big window containing 
the console, editor, etc.) or SDI mode (separate windows)?

  - does it matter what was in the file you opened?

Duncan Murdoch


From maillist at roomity.com  Tue Nov  8 19:35:07 2005
From: maillist at roomity.com (shenanigans)
Date: Tue,  8 Nov 2005 10:35:07 -0800 (PST)
Subject: [Rd] [OTAnn] Feedback
Message-ID: <4321300.2631131474907257.JavaMail.tomcat5@slave1.roomity.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20051108/5d281a68/attachment.pl

From atp at piskorski.com  Tue Nov  8 22:59:19 2005
From: atp at piskorski.com (Andrew Piskorski)
Date: Tue, 8 Nov 2005 16:59:19 -0500
Subject: [Rd] R thread safe
In-Reply-To: <1131389848.436fa39855a52@webmail.unibas.ch>
References: <1131389848.436fa39855a52@webmail.unibas.ch>
Message-ID: <20051108215919.GA65494@tehun.pair.com>

On Mon, Nov 07, 2005 at 07:57:28PM +0100, Olaf.Schenk at unibas.ch wrote:

> I would like to accelerate my R computation by using parallel OpenMP
> compilers (e.g from Pathscale) on a 2-processor AMD server and I
> would like to know whether R is a tread safe library. The main

R is not thread safe, but others will have to tell you just how and
why not and what needs to be done to fix that (I don't know).

Does OpenMP require thread support, or can it alternately use multiple
processes plus System V shared memory?  Perhaps the latter would still
be an option even in R's currently non-thread-safe state.

Your approach is interesting.  Why do you want to do shared memory
parallel programming with OpenMP, rather than say message passing via
MPI or PVM?  Do you have a particularly fine-grained problem for which
message passing would be unsuitable?  Or are you just hoping to
automatically take advantage of both CPUs of your dual CPU workstation
without having to write any extra message passing code?

I haven't heard of anyone else doing shared memory programming with R.
But if instead you are interested in message passing, there are lots
of different tools and projects in R for that:

  http://cran.us.r-project.org/src/contrib/Descriptions/Rmpi.html
  http://cran.us.r-project.org/src/contrib/Descriptions/rpvm.html
  http://cran.us.r-project.org/src/contrib/Descriptions/papply.html
  http://cran.us.r-project.org/src/contrib/Descriptions/snow.html
  http://www.aspect-sdm.org/Parallel-R/
  http://cran.us.r-project.org/src/contrib/Descriptions/RScaLAPACK.html
  http://cran.us.r-project.org/src/contrib/Descriptions/taskPR.html
  http://cran.us.r-project.org/src/contrib/Descriptions/biopara.html
  http://www.omegahat.org/download/R/packages/CORBA.tar.gz

-- 
Andrew Piskorski <atp at piskorski.com>
http://www.piskorski.com/


From timh at insightful.com  Wed Nov  9 03:09:08 2005
From: timh at insightful.com (timh@insightful.com)
Date: Wed,  9 Nov 2005 03:09:08 +0100 (CET)
Subject: [Rd] R CMD Sd2Rd a.sgml > a.Rd does not recognize <code> tag
	(PR#8289)
Message-ID: <20051109020908.360F824E8E@slim.kubism.ku.dk>

I'm trying:

	R CMD Sd2Rd file.sgml > file.Rd

If file.sgml contains
	<code>x</code>
this should be translated to
	\code{x}
in the .Rd file, but is not.  
It should be treated the same as the old
	<s-expression>x</s-expression>



I'm using:
Cygwin (uname gives: CYGWIN_NT-5.1) (installed 10 Oct 05)
Perl 5.8.7 build 813	(installed 7 Nov 05)

--please do not edit the information below--

Version:
 platform = i386-pc-mingw32
 arch = i386
 os = mingw32
 system = i386, mingw32
 status = 
 major = 2
 minor = 2.0
 year = 2005
 month = 10
 day = 06
 svn rev = 35749
 language = R

Windows XP Professional (build 2600) Service Pack 2.0

Locale:
LC_COLLATE=English_United States.1252;LC_CTYPE=English_United States.1252;LC_MONETARY=English_United States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252

Search Path:
 .GlobalEnv, package:methods, package:stats, package:graphics, package:grDevices, package:utils, package:datasets, Autoloads, package:base


From timh at insightful.com  Wed Nov  9 03:15:51 2005
From: timh at insightful.com (timh@insightful.com)
Date: Wed,  9 Nov 2005 03:15:51 +0100 (CET)
Subject: [Rd] R CMD Rdconv file.Rd --type=Ssgm \code{x} should use <code>
	(PR#8290)
Message-ID: <20051109021551.59EA724E8E@slim.kubism.ku.dk>

I'm trying:

	R CMD Rdconv file.Rd --type=Ssgm

If file.Rd contains
	\code{x}
then this is currently translated as
	<s-expression>x</s-expression>
I suggest instead translating to
	<code>x</code>

(provided that R CMD Sd2Rd is changed to support the <code>
tag; I just submitted that bug separately).


Note that this is an enhancement, not a bug.
This change would give functionally-equivalent but prettier sgml files.


I'm using:
Cygwin (uname gives: CYGWIN_NT-5.1) (installed 10 Oct 05)
Perl 5.8.7 build 813	(installed 7 Nov 05)

--please do not edit the information below--

Version:
 platform = i386-pc-mingw32
 arch = i386
 os = mingw32
 system = i386, mingw32
 status = 
 major = 2
 minor = 2.0
 year = 2005
 month = 10
 day = 06
 svn rev = 35749
 language = R

Windows XP Professional (build 2600) Service Pack 2.0

Locale:
LC_COLLATE=English_United States.1252;LC_CTYPE=English_United States.1252;LC_MONETARY=English_United States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252

Search Path:
 .GlobalEnv, package:methods, package:stats, package:graphics, package:grDevices, package:utils, package:datasets, Autoloads, package:base

========================================================
| Tim Hesterberg       Research Scientist              |
| timh at insightful.com  Insightful Corp.                |
| (206)802-2319        1700 Westlake Ave. N, Suite 500 |
| (206)283-8691 (fax)  Seattle, WA 98109-3012, U.S.A.  |
|                      www.insightful.com/Hesterberg   |
========================================================
Download the S+Resample library from www.insightful.com/downloads/libraries

Two Research Scientist positions:
	data mining
	frailty/mixed effects
    http://www.insightful.com/company/jobs.asp

Speak out about biased science in Washington D.C.
    http://home.comcast.net/~timhesterberg/ScientificIntegrity.html


From Torsten.Hothorn at rzmail.uni-erlangen.de  Wed Nov  9 09:02:15 2005
From: Torsten.Hothorn at rzmail.uni-erlangen.de (Torsten Hothorn)
Date: Wed, 9 Nov 2005 09:02:15 +0100 (CET)
Subject: [Rd] useR! 2006: submission & registration started!
Message-ID: <Pine.LNX.4.51.0511090856450.17628@artemis.imbe.med.uni-erlangen.de>


We are happy to inform you that the online abstract submission and
registration for `useR! 2006' is now available online from
  http://www.R-project.org/useR-2006/

This second world meeting of the R user community will take place at
the Wirtschaftsuniversitaet Wien, Vienna, Austria, June 15 to 17 2006.
The conference schedule comprises keynote lectures and user-contributed
sessions as well as half-day tutorials presented by R experts on June 14,
2006, prior to the conference.

Keynote lectures addressing hot topics including data mining, graphics,
marketing or teaching with R will be presented by prominent speakers
including John Chambers, Jan de Leeuw, Brian Everitt, Travor Hastie, John
Fox, Stefano Iacus, Uwe Ligges, Paul Murrell, Peter Rossi, Simon Urbanek
and Sanford Weisberg.

The spectrum of user-contributed sessions will depend on your submissions.
Hence, we invite you to submit abstracts on topics presenting innovations
or exciting applications of R. The call for papers along with the link to
the online abstract submission is available at
  http://www.R-project.org/useR-2006/#Call

Before the start of the official program, half-day tutorials will be
offered on Wednesday, June 14th, a list of topics and speakers can be
found at
  http://www.R-project.org/useR-2006/Tutorials/

A special highlight of the conference will be a panel discussion on
`Getting recognition for excellence in computational statistics'. Editors
of well established journals in both computational and applied statistics
will discuss the impact of recent developments in computational statistics
on peer-reviewed journal publications. Currently, the panelists include
Jan de Leeuw (JSS), Brian Everitt (SMMR), Wolfgang Haerdle (CS), Nicholas
Jewell (SMGMB), Erricos Konthogiorges (CSDA), and Luke Tierney (JCGS).

Early birds fly until January 31st 2006, so now is the perfect time to
write and submit an abstract, register as a participant and plan your trip
to Vienna. The conference web page
  http://www.R-project.org/useR-2006/
has a link to a local hotel booking service and much more news.

See you in Vienna!
Torsten, Achim, David, Bettina, Kurt and Fritz


From ligges at statistik.uni-dortmund.de  Wed Nov  9 10:26:06 2005
From: ligges at statistik.uni-dortmund.de (ligges@statistik.uni-dortmund.de)
Date: Wed,  9 Nov 2005 10:26:06 +0100 (CET)
Subject: [Rd] bug in windows GUI/script editor (PR#8288)
Message-ID: <20051109092606.171A427670@slim.kubism.ku.dk>

murdoch at stats.uwo.ca wrote:

> On 11/8/2005 11:51 AM, roberto.ugoccioni at sanpaoloimi.com wrote:
> 
>>Full_Name: Roberto Ugoccioni
>>Version: 2.2.0
>>OS: Windows 2000
>>Submission from: (NULL) (193.203.232.5)
>>
>>
>>Running Windows 2000 Professional, all patches up to nov 8, 2005.
>>
>>
>>
>>>version
>>
>>         _              
>>platform i386-pc-mingw32
>>arch     i386           
>>os       mingw32        
>>system   i386, mingw32  
>>status                  
>>major    2              
>>minor    2.0            
>>year     2005           
>>month    10             
>>day      06             
>>svn rev  35749          
>>language R  
>>
>>How to reproduce the bug:
>>
>>1. launch Rgui.exe
>>2. menu File->open script
>>3. close editor clicking on X
>>4. clicking menu File now generates the fatal error (omitting memory
>>addresses):
>>
>> An instruction referred to a memory location which could not be "read"
>>
>>Clicking on OK in the error message window causes R to consume 100% CPU and not
>>to respond - must be terminated from task manager.
> 
> 
> I don't see this, but it sounds like something that was fixed before the 
> release of 2.2.0, so maybe there's another way to generate the same problem.

I see the crash for R-2.2.0 on WinNT4.0 but it does not happen for 
R-devel from yesterday...

Uwe


> Could you give more detail:
> 
>   - are you running in the default MDI mode (one big window containing 
> the console, editor, etc.) or SDI mode (separate windows)?
> 
>   - does it matter what was in the file you opened?
> 
> Duncan Murdoch
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From hin-tak.leung at cimr.cam.ac.uk  Wed Nov  9 10:38:53 2005
From: hin-tak.leung at cimr.cam.ac.uk (Hin-Tak Leung)
Date: Wed, 09 Nov 2005 09:38:53 +0000
Subject: [Rd] R build under mandriva 10.2
In-Reply-To: <200511081633.49575.gilles.guillot@inapg.inra.fr>
References: <200511081633.49575.gilles.guillot@inapg.inra.fr>
Message-ID: <4371C3AD.4060707@cimr.cam.ac.uk>

Gilles GUILLOT wrote:
> After upgrading from mandrake 10.1 to mandriva 10.2
> I can't build shared archive with R 2.2.0

libg2c is part of the g77 fortran runtime package in gcc 3.x. You probably
have gcc 4.x (which has a new/different fortran frontend
called gfortran) when you upgrade to mandriva 10.2 .

You probably need to rebuild R with gcc 4.x, or downgrade your
compiler suites back to gcc 3.x.

> [guillot at laplace src]$ R CMD SHLIB main.f sub.f wrapper.c 
> gcc -shared  -L/usr/local/lib -o main.so main.o sub.o wrapper.o  -lg2c -lm 
> -lgcc_s
> /usr//bin/ld: cannot find -lg2c
> collect2: ld returned 1 exit status
> make: *** [main.so] Erreur 1
> 
> I guess the information in
> http://finzi.psych.upenn.edu/R/Rhelp01/archive/5146.html 
> are not relevant any longer.
> 
> What is missing ?
> 
> Gilles
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From gavin.simpson at ucl.ac.uk  Wed Nov  9 17:50:27 2005
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Wed, 09 Nov 2005 16:50:27 +0000
Subject: [Rd] Packages that require other packages - How?
Message-ID: <1131555027.32250.37.camel@gsimpson.geog.ucl.ac.uk>

Dear list,

The help page for library/require contains the following paragraph in
the section "Packages that require other packages":

     The source code for a package that requires one or more other
     packages should have a call to 'require', preferably near the
     beginning of the source, and of course before any code that uses
     functions, classes or methods from the other package. 

Now, I'm being very dense today, but I don't know where to put such a
call to require.

My package has added methods for a generic function supplied by another
package. I have listed this package in the Depends field in my
DESCRIPTION.

What do I need to do to have the package that my package depends on be
attached when I call library or require to attach my package?

Apologies for being dense...

Thanks,

G
-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
Gavin Simpson                     [T] +44 (0)20 7679 5522
ENSIS Research Fellow             [F] +44 (0)20 7679 7565
ENSIS Ltd. & ECRC                 [E] gavin.simpsonATNOSPAMucl.ac.uk
UCL Department of Geography       [W] http://www.ucl.ac.uk/~ucfagls/cv/
26 Bedford Way                    [W] http://www.ucl.ac.uk/~ucfagls/
London.  WC1H 0AP.
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%


From murdoch at stats.uwo.ca  Wed Nov  9 18:22:58 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Wed, 09 Nov 2005 12:22:58 -0500
Subject: [Rd] Packages that require other packages - How?
In-Reply-To: <1131555027.32250.37.camel@gsimpson.geog.ucl.ac.uk>
References: <1131555027.32250.37.camel@gsimpson.geog.ucl.ac.uk>
Message-ID: <43723072.6040307@stats.uwo.ca>

On 11/9/2005 11:50 AM, Gavin Simpson wrote:
> Dear list,
> 
> The help page for library/require contains the following paragraph in
> the section "Packages that require other packages":
> 
>      The source code for a package that requires one or more other
>      packages should have a call to 'require', preferably near the
>      beginning of the source, and of course before any code that uses
>      functions, classes or methods from the other package. 
> 
> Now, I'm being very dense today, but I don't know where to put such a
> call to require.
> 
> My package has added methods for a generic function supplied by another
> package. I have listed this package in the Depends field in my
> DESCRIPTION.
> 
> What do I need to do to have the package that my package depends on be
> attached when I call library or require to attach my package?
> 
> Apologies for being dense...

You can either put a call to require() in the function that needs it 
(which would be the best solution if that function is relatively rarely 
used), or in the startup code (in .First.lib, .onLoad, or .onAttach: 
see the manual for the differences) if you make extensive use of the 
other package.

Duncan Murdoch


From rpeng at jhsph.edu  Wed Nov  9 19:04:19 2005
From: rpeng at jhsph.edu (Roger Peng)
Date: Wed, 09 Nov 2005 13:04:19 -0500
Subject: [Rd] Packages that require other packages - How?
In-Reply-To: <1131555027.32250.37.camel@gsimpson.geog.ucl.ac.uk>
References: <1131555027.32250.37.camel@gsimpson.geog.ucl.ac.uk>
Message-ID: <43723A23.3090607@jhsph.edu>

If I'm not mistaken, when you put the other package in the "Depends:" 
field of DESCRIPTION, the other package will be loaded first, before 
your package is loaded.  So you shouldn't have to put require/library 
anywhere else.

-roger

Gavin Simpson wrote:
> Dear list,
> 
> The help page for library/require contains the following paragraph in
> the section "Packages that require other packages":
> 
>      The source code for a package that requires one or more other
>      packages should have a call to 'require', preferably near the
>      beginning of the source, and of course before any code that uses
>      functions, classes or methods from the other package. 
> 
> Now, I'm being very dense today, but I don't know where to put such a
> call to require.
> 
> My package has added methods for a generic function supplied by another
> package. I have listed this package in the Depends field in my
> DESCRIPTION.
> 
> What do I need to do to have the package that my package depends on be
> attached when I call library or require to attach my package?
> 
> Apologies for being dense...
> 
> Thanks,
> 
> G


From khansen at stat.Berkeley.EDU  Wed Nov  9 19:31:00 2005
From: khansen at stat.Berkeley.EDU (Kasper Daniel Hansen)
Date: Wed, 9 Nov 2005 10:31:00 -0800
Subject: [Rd] Packages that require other packages - How?
In-Reply-To: <43723072.6040307@stats.uwo.ca>
References: <1131555027.32250.37.camel@gsimpson.geog.ucl.ac.uk>
	<43723072.6040307@stats.uwo.ca>
Message-ID: <CAA6F9CF-F9EB-460D-9560-E1805FE0EFBF@stat.berkeley.edu>


On Nov 9, 2005, at 9:22 AM, Duncan Murdoch wrote:

> On 11/9/2005 11:50 AM, Gavin Simpson wrote:
>> Dear list,
>>
>> The help page for library/require contains the following paragraph in
>> the section "Packages that require other packages":
>>
>>      The source code for a package that requires one or more other
>>      packages should have a call to 'require', preferably near the
>>      beginning of the source, and of course before any code that uses
>>      functions, classes or methods from the other package.
>>
>> Now, I'm being very dense today, but I don't know where to put such a
>> call to require.
>>
>> My package has added methods for a generic function supplied by  
>> another
>> package. I have listed this package in the Depends field in my
>> DESCRIPTION.
>>
>> What do I need to do to have the package that my package depends  
>> on be
>> attached when I call library or require to attach my package?
>>
>> Apologies for being dense...
>
> You can either put a call to require() in the function that needs it
> (which would be the best solution if that function is relatively  
> rarely
> used), or in the startup code (in .First.lib, .onLoad, or .onAttach:
> see the manual for the differences) if you make extensive use of the
> other package.

But isn't it true that the introduction of the DEPENDS field in the  
description file, largely makes calls to require obsolete? My  
impression is that require calls are mostly used to make examples  
execute if the depend on a suggested package. I may be wrong of course.

Kasper


From voilesnews.newsletter at wanadoo.fr  Wed Nov  9 19:38:48 2005
From: voilesnews.newsletter at wanadoo.fr (voilesnews.newsletter@wanadoo.fr)
Date: Wed,  9 Nov 2005 19:38:48 +0100 (CET)
Subject: [Rd] News Letter - Voiles News magazine - n?43 - 8 novembre 2005
	(PR#8294)
Message-ID: <20051109183848.201BD265BB@slim.kubism.ku.dk>

This is a multi-part message in MIME format.

------=_SAKbound_19_3848_20051109_3FC750EE.0417D0AB
Content-Type: text/plain;
	charset="iso-8859-1"
Content-Transfer-Encoding: 8Bit


------=_SAKbound_19_3848_20051109_3FC750EE.0417D0AB
Content-Type: text/html;
	charset="iso-8859-1"
Content-Transfer-Encoding: 8Bit

<HTML><HEAD></HEAD>
<BODY>
<P style="MARGIN-TOP: 0px; MARGIN-BOTTOM: 0px" align=center><FONT size=2>Vous n'arrivez pas ? lire notre <B>News Letter - </B>au format HTML, vous pouvez la retrouver sur nos sites ? la page <B><A title="Derni?re news letter" href="http://www.voilesnews.fr/news_letter_dernier_envoi.htm">derni?re news letter</A></B></FONT></P>
<P style="MARGIN-TOP: 0px; MARGIN-BOTTOM: 0px" align=center>&nbsp;</P>
<TABLE id=table1 cellSpacing=10 cellPadding=0 width="100%" bgColor=#143ca8 border=0>
<TBODY>
<TR>
<TD width=201 bgColor=#143ca8>
<P style="MARGIN-TOP: 0px; MARGIN-BOTTOM: 0px" align=justify><FONT face="Times New Roman" color=#ffffff size=1><A href="http://www.voilesnews.fr"><IMG height=62 src="http://voilesnews.fr/photos_news_letter/logo_voiles_news_news_letter.jpg" width=200 border=0></A></FONT></P>
<P style="MARGIN-TOP: 0px; MARGIN-BOTTOM: 0px" align=center><FONT face="Times New Roman" size=1><A href="http://www.google.es/language_tools?hl=es" target=_blank><FONT color=#ffffff><IMG height=19 src="http://www.voilesnews.fr/dossier_animation_divers%20gif/spainw.gif" width=27 border=0></FONT></A><A href="http://www.google.es/language_tools?hl=it" target=_blank><FONT color=#ffffff><IMG height=20 src="http://www.voilesnews.fr/dossier_animation_divers%20gif/italyw.gif" width=27 border=0></FONT></A><A href="http://www.google.es/language_tools?hl=de" target=_blank><FONT color=#ffffff><IMG height=20 src="http://www.voilesnews.fr/dossier_animation_divers%20gif/germanyw.gif" width=27 border=0></FONT></A><A href="http://www.google.es/language_tools?hl=us" target=_blank><FONT color=#ffffff><IMG height=20 src="http://www.voilesnews.fr/dossier_animation_divers%20gif/greatbrw.gif" width=27 border=0></FONT></A></FONT></P></TD>
<TD bgColor=#143ca8>
<P style="MARGIN-TOP: 0px; MARGIN-BOTTOM: 0px" align=center>&nbsp;</P></TD></TR></TBODY></TABLE>
<TABLE id=table1 cellSpacing=10 cellPadding=0 width="100%" bgColor=#143ca8 border=0>
<TBODY>
<TR>
<TD style="TEXT-ALIGN: center" width="22%" bgColor=#000000 height="100%">
<P style="MARGIN-TOP: 0px; MARGIN-BOTTOM: 0px" align=center><B><FONT face="Times New Roman" color=#ffffff>News Lettre n?43</FONT></B> 
<P style="MARGIN-TOP: 0px; MARGIN-BOTTOM: 0px" align=center><FONT color=#ffffff>---------</FONT> 
<P style="MARGIN-TOP: 0px; MARGIN-BOTTOM: 0px" align=center><B><FONT face="Times New Roman" color=#ffffff>8 novembre 2005</FONT></B></P></TD>
<TD style="TEXT-ALIGN: center" width="75%" bgColor=#000000 height="100%">
<P style="MARGIN-TOP: 0px; MARGIN-BOTTOM: 0px"><B><FONT color=#ffffff>Bonjour </FONT><FONT color=#ff0000> , </FONT></B></P>
<P style="MARGIN-TOP: 0px; MARGIN-BOTTOM: 0px" align=center><FONT face="Times New Roman"><FONT color=#ffffff size=2><A href="http://www.voilesnews.fr/news_letter_inscription.htm"><IMG height=25 src="http://www.voilesnews.fr/dossier_animation_divers%20gif/fleche_vers_la_droite.gif" width=33 border=0></A> </FONT><B><U><FONT color=#ffffff size=2>Je souhaite m'abonner / me d?sabonner ? la News Letter de Voiles News, merci de rappeler l'adresse suivante :</FONT></U><FONT color=#ff0000 size=2>&nbsp;r-bugs at biostat.ku.dk</FONT></B></FONT></P>&nbsp;</TD></TR>
<TR>
<TD align=middle width="97%" bgColor=#143ca8 colSpan=2>
<TABLE dir=ltr cellSpacing=0 cellPadding=0 width="100%" border=0>
<TBODY>
<TR>
<TD vAlign=top>
<TABLE dir=ltr cellSpacing=0 cellPadding=0 width="100%" border=0>
<TBODY>
<TR>
<TD vAlign=top>
<TABLE id=table26 cellSpacing=10 cellPadding=0 width="100%" border=0>
<TBODY>
<TR>
<TD style="TEXT-ALIGN: justify" vAlign=top width=881 bgColor=#ffffff>
<P style="MARGIN-TOP: 0px; MARGIN-BOTTOM: 0px"><FONT size=2><IMG height=16 src="http://www.voilesnews.fr/photos_generique_site/favicon.gif" width=16 border=0> L'actualit? nautique est riche en cette saison avec la Transat Jacques Vabre qui vient de quitter la France et bient?t la salon nautique 2005 de Paris. L'int?r?t d'Internet, c'est sa r?activit?, ainsi nous vous proposons de suivre en direct les aventures de nos champions sur cette Transat et de prendre connaissance en avant premi?re des nouveaut?s de ce prochain salon.</FONT></P>
<P style="MARGIN-TOP: 0px; MARGIN-BOTTOM: 0px"><FONT size=2><IMG height=16 src="http://www.voilesnews.fr/photos_generique_site/favicon.gif" width=16 border=0> Voiles News Magazine va changer, nous travaillons actuellement sur une refonte totale de notre webzine, n'h?sitez pas ? nous faire conna?tre vos id?es, souhaits, nous sommes preneur de toutes les bonnes id?es !</FONT></P>
<P style="MARGIN-TOP: 0px; MARGIN-BOTTOM: 0px">&nbsp;</P>
<P style="MARGIN-TOP: 0px; MARGIN-BOTTOM: 0px; TEXT-ALIGN: right"><FONT size=2>La R?daction</FONT></P>
<P style="MARGIN-TOP: 0px; MARGIN-BOTTOM: 0px">&nbsp;</P>
<P style="MARGIN-TOP: 0px; MARGIN-BOTTOM: 0px; TEXT-ALIGN: center"><A href="http://www.voilesnews.fr"><IMG height=185 src="http://www.voilesnews.fr/dossier_pub/pub_salon_nautique_2005.bmp" width=512 border=0></A> </P>
<P style="MARGIN-TOP: 0px; MARGIN-BOTTOM: 0px; TEXT-ALIGN: center">&nbsp;</P>
<P style="MARGIN-TOP: 0px; MARGIN-BOTTOM: 0px; TEXT-ALIGN: center"><A href="http://www.voilesnews.fr/" target=_blank><FONT color=#ff0000 size=5><B>D?couvrez en avant premi?re les nouveaut?s du Salon Nautique 2005 de Paris</B></FONT></A></P>
<P style="MARGIN-TOP: 0px; MARGIN-BOTTOM: 0px; TEXT-ALIGN: center">&nbsp;</P></TD></TR></TBODY></TABLE></TD></TR></TBODY></TABLE></TD></TR></TBODY></TABLE></TD></TR>
<TR>
<TD vAlign=top align=justify width="97%" bgColor=#143ca8 colSpan=2>
<P style="MARGIN-TOP: 0px; MARGIN-BOTTOM: 0px" align=center><FONT face="Times New Roman" color=#ffffff><B><U>Notre prochaine News Letter vers le :</U> </B></FONT><B><FONT face="Times New Roman" color=#ff0000>20 novembre 2005</FONT></B></P>
<P style="MARGIN-TOP: 0px; MARGIN-BOTTOM: 0px" align=center>&nbsp;</P>
<DIV align=center>
<P style="MARGIN-TOP: 0px; MARGIN-BOTTOM: 0px"><FONT face="Times New Roman" size=2><FONT color=#ffffff><B>Pour nous ?crire :</B> </FONT><A href="mailto:voilesnews at wanadoo.fr"><FONT color=#ff0000>voilesnews at wanadoo.fr</FONT></A></FONT></P></DIV>
<DIV align=center>
<P style="MARGIN-TOP: 0px; MARGIN-BOTTOM: 0px"><FONT face="Times New Roman" size=2><FONT color=#ffffff><B>Pour ?crire ? la r?daction :</B> </FONT><A href="mailto:voilesnews at wanadoo.fr"><FONT color=#ff0000>voilesnews.redaction at wanadoo.fr</FONT></A></FONT></P></DIV></TD></TR></TBODY></TABLE><img src="http://www.power-emailer.com/tracking/tkop.php?var=I-YFTHcYRLHGZG.PF.WP-__-56384" width="0" height="0"></BODY></HTML>


------=_SAKbound_19_3848_20051109_3FC750EE.0417D0AB--


From murdoch at stats.uwo.ca  Wed Nov  9 21:03:26 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Wed, 09 Nov 2005 15:03:26 -0500
Subject: [Rd] Packages that require other packages - How?
In-Reply-To: <CAA6F9CF-F9EB-460D-9560-E1805FE0EFBF@stat.berkeley.edu>
References: <1131555027.32250.37.camel@gsimpson.geog.ucl.ac.uk>
	<43723072.6040307@stats.uwo.ca>
	<CAA6F9CF-F9EB-460D-9560-E1805FE0EFBF@stat.berkeley.edu>
Message-ID: <4372560E.2050604@stats.uwo.ca>

On 11/9/2005 1:31 PM, Kasper Daniel Hansen wrote:
> On Nov 9, 2005, at 9:22 AM, Duncan Murdoch wrote:
> 
>> On 11/9/2005 11:50 AM, Gavin Simpson wrote:
>>> Dear list,
>>>
>>> The help page for library/require contains the following paragraph in
>>> the section "Packages that require other packages":
>>>
>>>      The source code for a package that requires one or more other
>>>      packages should have a call to 'require', preferably near the
>>>      beginning of the source, and of course before any code that uses
>>>      functions, classes or methods from the other package.
>>>
>>> Now, I'm being very dense today, but I don't know where to put such a
>>> call to require.
>>>
>>> My package has added methods for a generic function supplied by  
>>> another
>>> package. I have listed this package in the Depends field in my
>>> DESCRIPTION.
>>>
>>> What do I need to do to have the package that my package depends  
>>> on be
>>> attached when I call library or require to attach my package?
>>>
>>> Apologies for being dense...
>>
>> You can either put a call to require() in the function that needs it
>> (which would be the best solution if that function is relatively  
>> rarely
>> used), or in the startup code (in .First.lib, .onLoad, or .onAttach:
>> see the manual for the differences) if you make extensive use of the
>> other package.
> 
> But isn't it true that the introduction of the DEPENDS field in the  
> description file, largely makes calls to require obsolete? My  
> impression is that require calls are mostly used to make examples  
> execute if the depend on a suggested package. I may be wrong of course.

No, you're right, I was wrong.

Duncan Murdoch


From Duncan.Mackay at flinders.edu.au  Thu Nov 10 00:16:14 2005
From: Duncan.Mackay at flinders.edu.au (Duncan Mackay)
Date: Thu, 10 Nov 2005 09:46:14 +1030
Subject: [Rd]  bug in windows GUI/script editor (PR#8288)
Message-ID: <000401c5e583$af873f40$f4e66081@duncanlt>

Here's how I can reproduce this bug, running under MDI under WinXP

1) start Rgui
2) open a script window using File>New script
3) click back in the console window and open a help window (e.g. by typing
"?merge") in the console window
4) click in the close box of the help window
5) click in the close box of the script window (which was visible even
though the script window was largely behind the console window)
6) click on the File menu ..........CRASH!!! "R for Windows GUI front-end
has encountered a problem and needs to close.  We are sorry for the
inconvenience."


Cheers,
Duncan



> version
         _              
platform i386-pc-mingw32
arch     i386           
os       mingw32        
system   i386, mingw32  
status                  
major    2              
minor    2.0            
year     2005           
month    10             
day      06             
svn rev  35749          
language R  


*****************************************
Dr. Duncan Mackay
School of Biological Sciences
Flinders University
GPO Box 2100
Adelaide
S.A.    5001
AUSTRALIA

Ph (08) 8201 2627    FAX (08) 8201 3015

http://www.scieng.flinders.edu.au/biology/people/mackay_d/index.html


From hb at maths.lth.se  Thu Nov 10 00:32:52 2005
From: hb at maths.lth.se (Henrik Bengtsson)
Date: Thu, 10 Nov 2005 10:32:52 +1100
Subject: [Rd] Request: read.table() - argument 'flush' to be passed to scan()
Message-ID: <43728724.80206@maths.lth.se>

Hi,

would it be possible to add an argument 'flush' to read.table(), which 
is passed as internal scan(..., 'flush=flush') calls?

BACKGROUND:
The microarray image analysis software QuantArray, sometimes generates 
tab-delimited files that contain data rows with trailing and obsolete 
TAB's (for unknown reasons).  Then number of TABs are unknown on before 
hand, and may vary.  These files do have a header, which defines the 
number of "target/wanted" columns.

SOLUTION:
If one add 'flush=FALSE' to the list of arguments and passes 
'flush=flush' to the "data <- scan(..., flush=flush)" call, that is, the 
scan call that reads the data table, files like the above can be read 
correctly.

 From ?scan, we have:

   flush: logical: if 'TRUE', 'scan' will flush to the end of the line
          after reading the last of the fields requested. This allows
          putting comments after the last field, but precludes putting
          more that one record on a line.

Removing the last sentence, this would be in line with the above 
suggestion. 

Is this a wanted update to read.table()?  Comments?

Cheers

Henrik


From Duncan.Mackay at flinders.edu.au  Thu Nov 10 01:48:29 2005
From: Duncan.Mackay at flinders.edu.au (Duncan Mackay)
Date: Thu, 10 Nov 2005 11:18:29 +1030
Subject: [Rd]  bug in windows GUI/script editor (PR#8288)
Message-ID: <000801c5e590$778392d0$f4e66081@duncanlt>

P.S.  I should have added that this crash occurred when the MDI toolbar was
OFF.

Here's how I can reproduce this bug, running under MDI under WinXP

1) start Rgui
2) open a script window using File>New script
3) click back in the console window and open a help window (e.g. by typing
"?merge") in the console window
4) click in the close box of the help window
5) click in the close box of the script window (which was visible even
though the script window was largely behind the console window)
6) click on the File menu ..........CRASH!!! "R for Windows GUI front-end
has encountered a problem and needs to close.  We are sorry for the
inconvenience."


Cheers,
Duncan



> version
         _              
platform i386-pc-mingw32
arch     i386           
os       mingw32        
system   i386, mingw32  
status                  
major    2              
minor    2.0            
year     2005           
month    10             
day      06             
svn rev  35749          
language R  


*****************************************
Dr. Duncan Mackay
School of Biological Sciences
Flinders University
GPO Box 2100
Adelaide
S.A.    5001
AUSTRALIA

Ph (08) 8201 2627    FAX (08) 8201 3015

http://www.scieng.flinders.edu.au/biology/people/mackay_d/index.html


From murdoch at stats.uwo.ca  Thu Nov 10 03:33:16 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Wed, 09 Nov 2005 21:33:16 -0500
Subject: [Rd] bug in windows GUI/script editor (PR#8288)
In-Reply-To: <000401c5e583$af873f40$f4e66081@duncanlt>
References: <000401c5e583$af873f40$f4e66081@duncanlt>
Message-ID: <4372B16C.8030106@stats.uwo.ca>

On 11/9/2005 6:16 PM, Duncan Mackay wrote:
> Here's how I can reproduce this bug, running under MDI under WinXP
> 
> 1) start Rgui
> 2) open a script window using File>New script
> 3) click back in the console window and open a help window (e.g. by typing
> "?merge") in the console window
> 4) click in the close box of the help window
> 5) click in the close box of the script window (which was visible even
> though the script window was largely behind the console window)
> 6) click on the File menu ..........CRASH!!! "R for Windows GUI front-end
> has encountered a problem and needs to close.  We are sorry for the
> inconvenience."

Thanks, I can reproduce this.  I'll track it down.

Duncan Murdoch
> 
> 
> Cheers,
> Duncan
> 
> 
> 
> 
>>version
> 
>          _              
> platform i386-pc-mingw32
> arch     i386           
> os       mingw32        
> system   i386, mingw32  
> status                  
> major    2              
> minor    2.0            
> year     2005           
> month    10             
> day      06             
> svn rev  35749          
> language R  
> 
> 
> *****************************************
> Dr. Duncan Mackay
> School of Biological Sciences
> Flinders University
> GPO Box 2100
> Adelaide
> S.A.    5001
> AUSTRALIA
> 
> Ph (08) 8201 2627    FAX (08) 8201 3015
> 
> http://www.scieng.flinders.edu.au/biology/people/mackay_d/index.html
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From scanrikpr at sbcglobal.net  Thu Nov 10 06:12:11 2005
From: scanrikpr at sbcglobal.net (scanrikpr@sbcglobal.net)
Date: Thu, 10 Nov 2005 06:12:11 +0100 (CET)
Subject: [Rd] # symbol in input data (PR#8296)
Message-ID: <20051110051211.64B8D265B9@slim.kubism.ku.dk>

Full_Name: Richard L Lozes
Version: 2.1.1
OS: Win XP
Submission from: (NULL) (69.107.18.35)


"#" appearing in a quoted string in input causes further input of that line to
be ignored.
Can be cured by escaping (i.e., "\#"), but in big data sets it is onerous to
find.

# should not be "special" inside a quoted string.

Here is a small input file. Read it with read.csv().

Title1, Title2, cHdr1, cHdr2, cHdr3
"xyz","abc",1.0,2.0,3.0
"xyy","ab#c",4.0,5.0,6.0
"zyx","abc",7.0,8.0,9.0


From roberto.ugoccioni at sanpaoloimi.com  Thu Nov 10 09:02:58 2005
From: roberto.ugoccioni at sanpaoloimi.com (roberto.ugoccioni@sanpaoloimi.com)
Date: Thu, 10 Nov 2005 09:02:58 +0100 (CET)
Subject: [Rd] R:  bug in windows GUI/script editor (PR#8288)
Message-ID: <20051110080258.05B3C26664@slim.kubism.ku.dk>
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From p.dalgaard at biostat.ku.dk  Thu Nov 10 09:33:37 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 10 Nov 2005 09:33:37 +0100
Subject: [Rd] # symbol in input data (PR#8296)
In-Reply-To: <20051110051211.64B8D265B9@slim.kubism.ku.dk>
References: <20051110051211.64B8D265B9@slim.kubism.ku.dk>
Message-ID: <x2irv09a1q.fsf@turmalin.kubism.ku.dk>

scanrikpr at sbcglobal.net writes:

> Full_Name: Richard L Lozes
> Version: 2.1.1
> OS: Win XP
> Submission from: (NULL) (69.107.18.35)
> 
> 
> "#" appearing in a quoted string in input causes further input of that line to
> be ignored.
> Can be cured by escaping (i.e., "\#"), but in big data sets it is onerous to
> find.
> 
> # should not be "special" inside a quoted string.
> 
> Here is a small input file. Read it with read.csv().
> 
> Title1, Title2, cHdr1, cHdr2, cHdr3
> "xyz","abc",1.0,2.0,3.0
> "xyy","ab#c",4.0,5.0,6.0
> "zyx","abc",7.0,8.0,9.0

...and what do you think the comment.char argument is for?

This is no bug.
 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From murdoch at stats.uwo.ca  Thu Nov 10 14:58:11 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 10 Nov 2005 08:58:11 -0500
Subject: [Rd] R:  bug in windows GUI/script editor (PR#8288)
In-Reply-To: <20051110080258.05B3C26664@slim.kubism.ku.dk>
References: <20051110080258.05B3C26664@slim.kubism.ku.dk>
Message-ID: <437351F3.4040207@stats.uwo.ca>

On 11/10/2005 3:02 AM, roberto.ugoccioni at sanpaoloimi.com wrote:
> SGkgRHVuY2FuLA0KSSBhbSBydW5uaW5nIFIgaW4gTURJIG1vZGUgKHdpdGggbG9jYWxpc2F0

Roberto:

Something went wrong with your posting -- it came out completely in 
binary.

I think I have found what was wrong with the editor windows.  There were 
two problems:

  - a variable was sometimes uninitialized.  I've fixed this in R-devel 
(though it won't be downloadable for a while).  I had hoped this was 
enough, but it wasn't.

  - the script editor window duplicates some menu items from the main 
window, but unfortunately in doing so it overwrites some pointers to 
those items.  When the script editor is closed, the pointers become 
invalid, and you may crash.

The second fix will require more extensive work, but I should get it 
done today.

Duncan Murdoch


From murdoch at stats.uwo.ca  Thu Nov 10 17:39:01 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 10 Nov 2005 11:39:01 -0500
Subject: [Rd] R:  bug in windows GUI/script editor (PR#8288)
In-Reply-To: <437351F3.4040207@stats.uwo.ca>
References: <20051110080258.05B3C26664@slim.kubism.ku.dk>
	<437351F3.4040207@stats.uwo.ca>
Message-ID: <437377A5.5060202@stats.uwo.ca>

On 11/10/2005 8:58 AM, Duncan Murdoch wrote:
> On 11/10/2005 3:02 AM, roberto.ugoccioni at sanpaoloimi.com wrote:
> 
>>SGkgRHVuY2FuLA0KSSBhbSBydW5uaW5nIFIgaW4gTURJIG1vZGUgKHdpdGggbG9jYWxpc2F0
> 
> 
> Roberto:
> 
> Something went wrong with your posting -- it came out completely in 
> binary.
> 
> I think I have found what was wrong with the editor windows.  There were 
> two problems:
> 
>   - a variable was sometimes uninitialized.  I've fixed this in R-devel 
> (though it won't be downloadable for a while).  I had hoped this was 
> enough, but it wasn't.
> 
>   - the script editor window duplicates some menu items from the main 
> window, but unfortunately in doing so it overwrites some pointers to 
> those items.  When the script editor is closed, the pointers become 
> invalid, and you may crash.
> 
> The second fix will require more extensive work, but I should get it 
> done today.

Now committed to both R-patched and R-devel.  Will show up in the 
binaries on CRAN in due time.

Duncan Murdoch


From murdoch at stats.uwo.ca  Thu Nov 10 17:39:41 2005
From: murdoch at stats.uwo.ca (murdoch@stats.uwo.ca)
Date: Thu, 10 Nov 2005 17:39:41 +0100 (CET)
Subject: [Rd] R:  bug in windows GUI/script editor (PR#8288)
Message-ID: <20051110163941.607A726558@slim.kubism.ku.dk>

On 11/10/2005 8:58 AM, Duncan Murdoch wrote:
> On 11/10/2005 3:02 AM, roberto.ugoccioni at sanpaoloimi.com wrote:
> 
>>SGkgRHVuY2FuLA0KSSBhbSBydW5uaW5nIFIgaW4gTURJIG1vZGUgKHdpdGggbG9jYWxpc2F0
> 
> 
> Roberto:
> 
> Something went wrong with your posting -- it came out completely in 
> binary.
> 
> I think I have found what was wrong with the editor windows.  There were 
> two problems:
> 
>   - a variable was sometimes uninitialized.  I've fixed this in R-devel 
> (though it won't be downloadable for a while).  I had hoped this was 
> enough, but it wasn't.
> 
>   - the script editor window duplicates some menu items from the main 
> window, but unfortunately in doing so it overwrites some pointers to 
> those items.  When the script editor is closed, the pointers become 
> invalid, and you may crash.
> 
> The second fix will require more extensive work, but I should get it 
> done today.

Now committed to both R-patched and R-devel.  Will show up in the 
binaries on CRAN in due time.

Duncan Murdoch


From W.E.Wolski at newcastle.ac.uk  Thu Nov 10 18:53:31 2005
From: W.E.Wolski at newcastle.ac.uk (nwew)
Date: Thu, 10 Nov 2005 17:53:31 +0000
Subject: [Rd] Problem with C code under R2.2 only.
Message-ID: <43603E10@webmail.ncl.ac.uk>

Dear R developers,

Running a R CMD check under R2.2 gives me the error messages (appended to this 
e-mail) while the with R2.1 the check on the same package directory runs fine. 
To my knowledge the configuration of R2.2 and R2.1 on my machine are 
identical.


* checking S3 generic/method consistency ... WARNING
Error: .First.lib failed for 'SBMLodeSolveR'
Call sequence:
2: stop(gettextf(".First.lib failed for '%s'", libraryPkgName(package)),
       domain = NA)
1: library(package, lib.loc = lib.loc, character.only = TRUE, verbose = FALSE)
Execution halted
See section 'Generic functions and methods' of the 'Writing R Extensions'
manual.
* checking replacement functions ... WARNING
Error: .First.lib failed for 'SBMLodeSolveR'
Call sequence:
2: stop(gettextf(".First.lib failed for '%s'", libraryPkgName(package)),
       domain = NA)
1: library(package, lib.loc = lib.loc, character.only = TRUE, verbose = FALSE)
Execution halted
In R, the argument of a replacement function which corresponds to the right
hand side must be named 'value'.
* checking foreign function calls ... WARNING
Error: .First.lib failed for 'SBMLodeSolveR'
Call sequence:
2: stop(gettextf(".First.lib failed for '%s'", libraryPkgName(package)),
       domain = NA)
1: library(package, lib.loc = lib.loc, character.only = TRUE, verbose = FALSE)
Execution halted
See section 'System and foreign language interfaces' of the 'Writing R
Extensions' manual.
* checking Rd files ... OK
* checking for missing documentation entries ... ERROR
Error: .First.lib failed for 'SBMLodeSolveR'



Help is highly appreciated.

Eryk

Witold Eryk Wolski

University of Newcastle upon Tyne
School of Mathematics and Statistics
Merz Court
http://www.mas.ncl.ac.uk/~nwew
http://www.northeasttango.org.uk


From ldimitro at wfubmc.edu  Thu Nov 10 20:13:38 2005
From: ldimitro at wfubmc.edu (Latchezar Dimitrov)
Date: Thu, 10 Nov 2005 14:13:38 -0500
Subject: [Rd] FW: Re: (Case 843) Recon-X msg: "Failed to get the list of
	instances: Server's ssh public key does not match our private
	ssh key"
Message-ID: <F160BE32A2E5E04497668BBDFE83FEDF11CF7BC3@EXCHVS1.medctr.ad.wfubmc.edu>

Bob,

Would you please install the six dependency packages as per the
suggestion bellow? This is for Recon-X server you installed some time
ago.
I case you need to please feel free to contact Bruno fro StarNet at
(604) 630-8700.

Thanks,
Lucho

PS. I will answer the rest of the questions from bellow by myself.

-----Original Message-----
From: StarNet Customer Service [mailto:helpdesk-support at starnet.com] 
Sent: Thursday, November 10, 2005 11:48 AM
To: Latchezar Dimitrov
Cc: Harold L Hunt
Subject: Re: (Case 843) Recon-X msg: "Failed to get the list of
instances: Server's ssh public key does not match our private ssh key"

Hi Latchezar,

Please see my comments inline (below).

>As you correctly assumed I am not the sysadmin on the machine (how else

>to explain the way you describe what you want ;-) and it will be very 
>much problematic to play with re-installations of the Recon-X server.
>Fortunately, since I was wise to ask for it, I have almost complete 
>copy of the installation session. Please find it attached.

>From what I can see, Latchezar, seems like some of the required
dependency packages were not installed during setup. The setup complains
about them during the install. These are:

CSWtextutils
CSWexpect
CSWnetcat
CSWshutils
CSWfindutils
CSWggrep

You do not need to go through the entire installation again but you do
need these packages installed before Recon-X would work. You can find
these packages under the deps directory. Please have your system
administrator install these six deps and have him run the command:

# /opt/csw/ReconX/bin/nxsetup

Please see if this fixes the problem. 

PS - Just in case you need these steps in detail, I'll be more than
happy to send you a follow up email today with detailed steps you (or
the system administrator) needs to take in order to get Recon-X working.

>The server is Sun SPARC with Solaris 9.

Could you provide me with the output of the command ssh -V? Is the
server using Sun's supplied SSH server? 

>I have also reported a second "feature" of the client. After its 
>unsuccessful attempt to connect to the server it interferes with say 
>SSH FTP Client from SSH Communication Security preventing it from 
>getting connected. This should _not_ depend on any software on any 
>other machine being installed properly or not or whatever. This should 
>be fixed first since it blocks my normal work.

Absolutely. Now, just to understand you correctly..you have an SSH
server running on the server and you connect via sftp to this server
using SSH Communication's SSH/SFTP client, correct? And for some reason,
after the installation of ReconX client on windows, the ssh sftp windows
stops working?

ReconX should not interefere with the SSH server in any way that impedes
your work. Perhaps you can installs the deps and clarify the second
problem, I can suggest and fix what might be going wrong. 

With warm regards,

-Bruno


From Piotr.Zuraniewski at agh.edu.pl  Thu Nov 10 21:37:13 2005
From: Piotr.Zuraniewski at agh.edu.pl (Zuraniewski)
Date: Thu, 10 Nov 2005 21:37:13 +0100
Subject: [Rd] fSeries armaFit problem
Message-ID: <002a01c5e636$88606b90$c1de1251@comp>

Dear all,
I encountered the following problem with fSeries library ver.220.10063
using R 2.1.1 on WinXPSP1 Athlon 1800+ machine

> x = armaSim(model = list(d=0.3), n = 1000)
> fit = armaFit(x ~ fracdiff(0, 0))
Error in n + M : non-numeric argument to binary operator

I believe it is due to the following fragment of code of armaFit

    fun = match.fun(paste(".", tsmodel, "Fit", sep = ""))
    filter = 100
    fit = fun(x = ts, order = order, include.mean = include.mean,
        method = method[1], fixed = fixed, M = M, h = h, ...)

Parameter filter is not known inside the body of fun
where we can find

debugging in: fun(x = ts, order = order, include.mean = include.mean, method
= method[1],
    fixed = fixed, M = M, h = h, ...)
debug: {
    M = filter

here 'filter' is treated as a name of the existing function, not an intended
integer numeber and results in crash while calling .fracdiff function

Best regards

Piotrek Z


From vincent.goulet at act.ulaval.ca  Thu Nov 10 21:36:57 2005
From: vincent.goulet at act.ulaval.ca (Vincent Goulet)
Date: Thu, 10 Nov 2005 15:36:57 -0500
Subject: [Rd] Writing new probability functions
Message-ID: <200511101536.57059.vincent.goulet@act.ulaval.ca>

Dear developeRs,

I am maintaining a package of Actuarial Science functions (soon to be uploaded 
to CRAN) in which we would like to include the usual d*, p*, q* and r* 
functions for some probability laws not currently found in base R.

Taking into account that most of the distributions are functions or 
transformations of the distributions found in base R, should we look into 
writing our functions in C or in R, both in terms of: (1) speed, and (2) 
accuracy?

If we opt for C, is there a canonical reference detailing the precautions one 
has to take to ensure accuracy of the density/distribution/quantile functions 
over the complete domain of the probability laws?

Comments appreciated.

-- 
  Vincent Goulet, Associate Professor
  ?cole d'actuariat
  Universit? Laval, Qu?bec 
  Vincent.Goulet at act.ulaval.ca   http://vgoulet.act.ulaval.ca


From p.dalgaard at biostat.ku.dk  Fri Nov 11 16:10:39 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 11 Nov 2005 16:10:39 +0100
Subject: [Rd] Recursive dependencies(Rcmdr)
Message-ID: <x264qzi5jk.fsf@viggo.kubism.ku.dk>

Something might have slipped by me, but I got into the following situation
installing Rcmdr:

< install.packages("Rcmdr",depend=TRUE) >

Oodles of Output, until:

* Installing *source* package 'multcomp' ...
** R
** data
** inst
** preparing package for lazy loading
Error in dyn.load(x, as.logical(local), as.logical(now)) :
        unable to load shared library '/home/bs/pd/Rlibrary/mvtnorm/libs/mvtnorm.so':
  /home/bs/pd/Rlibrary/mvtnorm/libs/mvtnorm.so: cannot open shared object file: No such file or directory
Execution halted

.... Several oodles more for remaining packages ....

** building package indices ...
* DONE (strucchange)

The downloaded packages are in
        /tmp/RtmpF23254/downloaded_packages
Warning messages:
1: installation of package 'multcomp' had non-zero exit status in: install.packages("Rcmdr", depend = TRUE)
2: cannot create HTML package index in: tools:::unix.packages.html(.Library)


OK, so we start Rcmdr

> library(Rcmdr)
Loading required package: tcltk
Loading required package: car

it then detects that multcomp is missing and asks for permission to
install it, giving the same result. 

The thing appears to be that multcomp depends on mvtnorm, but the
extra dependency goes undetected. Manual installation of the two
works.

A workaround is that John adds mvtnorm to the Suggested list for
Rcmdr, but I wonder if we couldn't do something smarter.

> version
         _
platform x86_64-unknown-linux-gnu
arch     x86_64
os       linux-gnu
system   x86_64, linux-gnu
status
major    2
minor    2.0
year     2005
month    10
day      06
svn rev  35749
language R
> .libPaths()
[1] "/home/bs/pd/Rlibrary" "/usr/lib64/R/library"

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From ripley at stats.ox.ac.uk  Fri Nov 11 16:45:05 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 11 Nov 2005 15:45:05 +0000 (GMT)
Subject: [Rd] Recursive dependencies(Rcmdr)
In-Reply-To: <x264qzi5jk.fsf@viggo.kubism.ku.dk>
References: <x264qzi5jk.fsf@viggo.kubism.ku.dk>
Message-ID: <Pine.LNX.4.61.0511111529420.10550@gannet.stats>

On Fri, 11 Nov 2005, Peter Dalgaard wrote:

> Something might have slipped by me, but I got into the following situation
> installing Rcmdr:

install.packages() does indeed have code to check for dependencies of 
dependencies.  I got the message

also installing the dependencies 'acepack', 'scatterplot3d', 'quadprog', 
'fBasics', 'Hmisc', 'mlbench', 'randomForest', 'SparseM', 'xtable', 'oz', 
'leaps', 'dynlm', 'e1071', 'tseries', 'chron', 'fCalendar', 'its', 'DAAG', 
'abind', 'car', 'effects', 'lmtest', 'multcomp', 'mvtnorm', 'relimp', 
'sandwich', 'strucchange', 'zoo'

The problem is the ordering.  Rcmdr does have mvtnorm in the 'Suggests' 
list, and has it after 'multcomp', and install.packages does not check 
that the Suggests list does not have inter-dependencies.

So we do `do something smarter', but not smart enough.

>
> < install.packages("Rcmdr",depend=TRUE) >
>
> Oodles of Output, until:
>
> * Installing *source* package 'multcomp' ...
> ** R
> ** data
> ** inst
> ** preparing package for lazy loading
> Error in dyn.load(x, as.logical(local), as.logical(now)) :
>        unable to load shared library '/home/bs/pd/Rlibrary/mvtnorm/libs/mvtnorm.so':
>  /home/bs/pd/Rlibrary/mvtnorm/libs/mvtnorm.so: cannot open shared object file: No such file or directory
> Execution halted
>
> .... Several oodles more for remaining packages ....
>
> ** building package indices ...
> * DONE (strucchange)
>
> The downloaded packages are in
>        /tmp/RtmpF23254/downloaded_packages
> Warning messages:
> 1: installation of package 'multcomp' had non-zero exit status in: install.packages("Rcmdr", depend = TRUE)
> 2: cannot create HTML package index in: tools:::unix.packages.html(.Library)
>
>
> OK, so we start Rcmdr
>
>> library(Rcmdr)
> Loading required package: tcltk
> Loading required package: car
>
> it then detects that multcomp is missing and asks for permission to
> install it, giving the same result.
>
> The thing appears to be that multcomp depends on mvtnorm, but the
> extra dependency goes undetected. Manual installation of the two
> works.
>
> A workaround is that John adds mvtnorm to the Suggested list for
> Rcmdr, but I wonder if we couldn't do something smarter.
>
>> version
>         _
> platform x86_64-unknown-linux-gnu
> arch     x86_64
> os       linux-gnu
> system   x86_64, linux-gnu
> status
> major    2
> minor    2.0
> year     2005
> month    10
> day      06
> svn rev  35749
> language R
>> .libPaths()
> [1] "/home/bs/pd/Rlibrary" "/usr/lib64/R/library"
>
> -- 
>   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
>  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
> (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From jfox at mcmaster.ca  Fri Nov 11 17:47:45 2005
From: jfox at mcmaster.ca (John Fox)
Date: Fri, 11 Nov 2005 11:47:45 -0500
Subject: [Rd] Recursive dependencies(Rcmdr)
In-Reply-To: <Pine.LNX.4.61.0511111529420.10550@gannet.stats>
Message-ID: <20051111164745.JPYD2981.tomts43-srv.bellnexxia.net@JohnDesktop8300>

Dear Brian and Peter,

I guess that this problem didn't surface before because most use of the
Rcmdr package is on Windows using the package binaries.

I think that I can simply remove mvtnorm (and probably some others as well)
from the Rcmdr dependencies. I'll check more carefully when I have some
time, but I believe that mtvnorm is there just for multcomp, and its
inclusion probably dates to a period before dependencies were resolved by
install.packages().

Thanks for bringing this to my attention.

John

--------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario
Canada L8S 4M4
905-525-9140x23604
http://socserv.mcmaster.ca/jfox 
-------------------------------- 

> -----Original Message-----
> From: r-devel-bounces at r-project.org 
> [mailto:r-devel-bounces at r-project.org] On Behalf Of Prof Brian Ripley
> Sent: Friday, November 11, 2005 10:45 AM
> To: Peter Dalgaard
> Cc: r-devel at stat.math.ethz.ch
> Subject: Re: [Rd] Recursive dependencies(Rcmdr)
> 
> On Fri, 11 Nov 2005, Peter Dalgaard wrote:
> 
> > Something might have slipped by me, but I got into the following 
> > situation installing Rcmdr:
> 
> install.packages() does indeed have code to check for 
> dependencies of dependencies.  I got the message
> 
> also installing the dependencies 'acepack', 'scatterplot3d', 
> 'quadprog', 'fBasics', 'Hmisc', 'mlbench', 'randomForest', 
> 'SparseM', 'xtable', 'oz', 'leaps', 'dynlm', 'e1071', 
> 'tseries', 'chron', 'fCalendar', 'its', 'DAAG', 'abind', 
> 'car', 'effects', 'lmtest', 'multcomp', 'mvtnorm', 'relimp', 
> 'sandwich', 'strucchange', 'zoo'
> 
> The problem is the ordering.  Rcmdr does have mvtnorm in the 
> 'Suggests' 
> list, and has it after 'multcomp', and install.packages does 
> not check that the Suggests list does not have inter-dependencies.
> 
> So we do `do something smarter', but not smart enough.
> 
> >
> > < install.packages("Rcmdr",depend=TRUE) >
> >
> > Oodles of Output, until:
> >
> > * Installing *source* package 'multcomp' ...
> > ** R
> > ** data
> > ** inst
> > ** preparing package for lazy loading
> > Error in dyn.load(x, as.logical(local), as.logical(now)) :
> >        unable to load shared library 
> '/home/bs/pd/Rlibrary/mvtnorm/libs/mvtnorm.so':
> >  /home/bs/pd/Rlibrary/mvtnorm/libs/mvtnorm.so: cannot open shared 
> > object file: No such file or directory Execution halted
> >
> > .... Several oodles more for remaining packages ....
> >
> > ** building package indices ...
> > * DONE (strucchange)
> >
> > The downloaded packages are in
> >        /tmp/RtmpF23254/downloaded_packages
> > Warning messages:
> > 1: installation of package 'multcomp' had non-zero exit status in: 
> > install.packages("Rcmdr", depend = TRUE)
> > 2: cannot create HTML package index in: 
> > tools:::unix.packages.html(.Library)
> >
> >
> > OK, so we start Rcmdr
> >
> >> library(Rcmdr)
> > Loading required package: tcltk
> > Loading required package: car
> >
> > it then detects that multcomp is missing and asks for permission to 
> > install it, giving the same result.
> >
> > The thing appears to be that multcomp depends on mvtnorm, but the 
> > extra dependency goes undetected. Manual installation of the two 
> > works.
> >
> > A workaround is that John adds mvtnorm to the Suggested list for 
> > Rcmdr, but I wonder if we couldn't do something smarter.
> >
> >> version
> >         _
> > platform x86_64-unknown-linux-gnu
> > arch     x86_64
> > os       linux-gnu
> > system   x86_64, linux-gnu
> > status
> > major    2
> > minor    2.0
> > year     2005
> > month    10
> > day      06
> > svn rev  35749
> > language R
> >> .libPaths()
> > [1] "/home/bs/pd/Rlibrary" "/usr/lib64/R/library"
> >
> > -- 
> >   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
> >  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
> > (*) \(*) -- University of Copenhagen   Denmark          Ph: 
>  (+45) 35327918
> > ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  
> FAX: (+45) 35327907
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
> >
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From toby.m at mail.utexas.edu  Fri Nov 11 18:33:04 2005
From: toby.m at mail.utexas.edu (toby.m@mail.utexas.edu)
Date: Fri, 11 Nov 2005 18:33:04 +0100 (CET)
Subject: [Rd] configure on solaris 2.9 with non GNU compilers (PR#8300)
Message-ID: <20051111173304.83D9C1DFE9@slim.kubism.ku.dk>

Full_Name: Toby Muhlhofer
Version: 2.2.0, 2.1.1
OS: Solaris 2.9
Submission from: (NULL) (128.83.62.46)


I'm trying to compile R on a Solaris machine. The default C compiler is cc
(although gcc is available) and the default Fortran compiler is f95 (although
g77 is available).

Without defining the F77 environment variable, configure defaults to f95 as a
Fortran compiler and eventually fails with the following output:

---------------------------------
checking whether mixed C/Fortran code can be run... configure: WARNING: cannot
run mixed C/Fortan code
configure: error: Maybe check LDFLAGS for paths to Fortran libraries?
---------------------------------

Setting LDFLAGS to the path where the Fortran libraries sit makes the C compiler
complain.

If I give the value g77 (or the full path to g77) to F77, there are two
interesting issues:

1)
-------------------------
defining F77 to be g77
checking whether we are using the GNU Fortran 77 compiler... no
checking whether g77 accepts -g... yes
-------------------------

Why does configure think we are not using the GNU Fortran 77 compiler?

But more importantly

2)
-------------------------------------
checking how to get verbose linking output from g77... configure: WARNING:
compilation failed

checking for Fortran libraries of g77...
checking how to get verbose linking output from cc... -###
checking for C libraries of cc...  -L/usr/local/lib -lthread
checking for dummy main to link with Fortran libraries... none
checking for Fortran name-mangling scheme... configure: error: cannot compile a
simple Fortran program
-------------------------------------

I tried to compile a simple "Hello World" program with either Fortran compiler
and both work without a problem.


From berwin at maths.uwa.edu.au  Sat Nov 12 11:55:06 2005
From: berwin at maths.uwa.edu.au (Berwin A Turlach)
Date: Sat, 12 Nov 2005 18:55:06 +0800
Subject: [Rd] Suggested changes to R-lang.texi and R-exts.texi
Message-ID: <17269.51722.209207.470465@bossiaea.maths.uwa.edu.au>

Dear all,

I would like to suggest the following changes to the R documentation:

1) R-exts.texi:
   Having had my first experience with uploading a package to
   ftp://cran.R-project.org/incoming/, I think it would be nice if the
   documentation pointed out that one should use ftp and not sftp (at
   least on my machine sftp failed to make a connection) and that one
   should log in as user 'anonymous' and not 'guest'.  As it is, I had
   to figure this out by trial and error.  It would also be nice, if
   in the phrase "sent a message to cran at r-project.org about it" the
   e-mail address would be a mailto: URL.

   The patch file attached below would modify R-exts.texi to
   incorporate all these chanes.

2) R-lang.texi:
   There was recently a short discussion on one of the R mailing list
   by someone who got bitten by partial matching.  Looking at
   R-lang.texi and the section that explains how function arguments
   are matched, I notice that the second step is explained thus:
        "Each named supplied argument is compared to the remaining formal
         arguments using partial matching."
   It might be just me, but when reading a sentence like this I start
   to wonder why the qualifier "remaining" is used for formal
   arguments but not for named supplied arguments and I am left
   momentarily confused.  I would like to suggest that the start of
   the sentence is changed to "Each remaining named supplied
   argument...".

   The patch file attached below would modify R-exts.texi to
   incorporate all these chanes.

The patch file attached below was produced by running "svn diff" on my
machine in the directory that contains the trunk of the R-devel
version of R.  So the patch file also includes the patch corresponding
to my bugreport #8218

Cheers,

        Berwin

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: R-patch
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20051112/7ebf9bb0/R-patch.pl

From hans.kestler at gmail.com  Sun Nov 13 21:47:17 2005
From: hans.kestler at gmail.com (hans.kestler@gmail.com)
Date: Sun, 13 Nov 2005 21:47:17 +0100 (CET)
Subject: [Rd] Memory allocation (PR#8304)
Message-ID: <20051113204717.85CD2223D7@slim.kubism.ku.dk>

Full_Name: Hans Kestler
Version: 2.2.0
OS: 10.4.3
Submission from: (NULL) (84.156.184.101)


> sam1.out<-sam(raw1[,2:23],raw1.cl,B=0,rand=124)

We're doing 319770 complete permutations

Error: cannot allocate vector of size 575586 Kb
R(572,0xa000ed68) malloc: *** vm_allocate(size=589402112) failed (error code=3)
R(572,0xa000ed68) malloc: *** error: can't allocate region
R(572,0xa000ed68) malloc: *** set a breakpoint in szone_error to debug
R(572,0xa000ed68) malloc: *** vm_allocate(size=589402112) failed (error code=3)
R(572,0xa000ed68) malloc: *** error: can't allocate region
R(572,0xa000ed68) malloc: *** set a breakpoint in szone_error to debug


From simon.urbanek at r-project.org  Sun Nov 13 23:15:18 2005
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Sun, 13 Nov 2005 17:15:18 -0500
Subject: [Rd] Memory allocation (PR#8304)
In-Reply-To: <20051113204717.85CD2223D7@slim.kubism.ku.dk>
References: <20051113204717.85CD2223D7@slim.kubism.ku.dk>
Message-ID: <51C972C6-5870-4ED1-B2C5-07C0B7A0E893@r-project.org>

Hans,

this is not a bug! You're simply running out of memory as the message  
tells you (allocating ca. 570MB? That's lot...) . You should consider  
re-phrasing the problem (preferably) or getting more memory and/or  
using 64-bit version of R where applicable.

Cheers,
Simon

On Nov 13, 2005, at 3:47 PM, hans.kestler at gmail.com wrote:

> Full_Name: Hans Kestler
> Version: 2.2.0
> OS: 10.4.3
> Submission from: (NULL) (84.156.184.101)
>
>
>> sam1.out<-sam(raw1[,2:23],raw1.cl,B=0,rand=124)
>
> We're doing 319770 complete permutations
>
> Error: cannot allocate vector of size 575586 Kb
> R(572,0xa000ed68) malloc: *** vm_allocate(size=589402112) failed  
> (error code=3)
> R(572,0xa000ed68) malloc: *** error: can't allocate region
> R(572,0xa000ed68) malloc: *** set a breakpoint in szone_error to debug
> R(572,0xa000ed68) malloc: *** vm_allocate(size=589402112) failed  
> (error code=3)
> R(572,0xa000ed68) malloc: *** error: can't allocate region
> R(572,0xa000ed68) malloc: *** set a breakpoint in szone_error to debug
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From Greg.Evans at datamine.com  Mon Nov 14 01:03:32 2005
From: Greg.Evans at datamine.com (Greg Evans)
Date: Mon, 14 Nov 2005 13:03:32 +1300
Subject: [Rd] Help finding some code in the R source code
Message-ID: <3D39BB5C5071174C8F25FC1EDC3B7D6E1CD186@postie.datamine.co.nz>

Hi,
 
I'm trying to write some Python code to check if a string text contains
a complete R statement.  I'm hoping someone will be able to point me to
the right place in the R source code, so I can use it as a starting
point.
 
For example, In the R console.
 
> x <- 1
> plot(
+ x
+ 
+ )
> 
 
If I type "plot(", the console adds a "+" until the ")" is entered.  I'm
looking for the place in the source code that adds the "+" symbol.
 
Thanks in advance,
Greg


From simon.urbanek at r-project.org  Mon Nov 14 01:39:05 2005
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Sun, 13 Nov 2005 19:39:05 -0500
Subject: [Rd] Help finding some code in the R source code
In-Reply-To: <3D39BB5C5071174C8F25FC1EDC3B7D6E1CD186@postie.datamine.co.nz>
References: <3D39BB5C5071174C8F25FC1EDC3B7D6E1CD186@postie.datamine.co.nz>
Message-ID: <D08AEFB8-1804-43DC-8697-56A219895940@r-project.org>

Greg,

On Nov 13, 2005, at 7:03 PM, Greg Evans wrote:

> I'm trying to write some Python code to check if a string text  
> contains a complete R statement.  I'm hoping someone will be able  
> to point me to the right place in the R source code, so I can use  
> it as a starting point.

What happens internally is that R runs the expression through the  
parser. When the parser returns PARSE_INCOMPLETE then you know that  
the expression is not complete and thus more input is needed. If you  
are directly interfacing R from Python then you can easily do exactly  
the same thing.
However, if you want a solution in pure Python, it may be more  
difficult as it would be equal to re-writing the R parser in  
Python... (or some 'light' version of it..).

Cheers,
Simon


From mcallaha at mitre.org  Fri Nov 11 15:33:06 2005
From: mcallaha at mitre.org (mcallaha@mitre.org)
Date: Fri, 11 Nov 2005 15:33:06 +0100 (CET)
Subject: [Rd] Typo in R-Intro, v. 2.2.0, sec. 8.1 (PR#8299)
Message-ID: <20051111143306.CAE4E1DF8F@slim.kubism.ku.dk>

The table in section 8.1 of Introduction to R, v. 2.2.0, lists the
"additional arguments" for the F distribution as "df1, df1, ncp." I
think it should be "df1, df2, ncp."

Thank you for the great R software and documentation, and continuing
improvement!

--Michael Callaham


From roebuck at mdanderson.org  Mon Nov 14 09:00:58 2005
From: roebuck at mdanderson.org (Paul Roebuck)
Date: Mon, 14 Nov 2005 02:00:58 -0600 (CST)
Subject: [Rd] Package manpage DCF hooks
Message-ID: <Pine.OSF.4.58.0511140146400.518678@wotan.mdacc.tmc.edu>

Was looking at what was output for <pkgname>-package.Rd
and wondered if any there was any means (via macro, etc)
to merge some of the same information with a template
for my package manpage? As much (all?) of the generated
information was already provided in the DESCRIPTION, I'd
prefer not to have to update the information in multiple
places. I'm thinking here that I could provide a template
file "<pkgname>-package.Rd.in" and during build, the
DCF information could be substituted appropriately and
"<pkgname>-package.Rd" would be output.

see also:
    promptPackage method

----------------------------------------------------------
SIGSIG -- signature too long (core dumped)


From ggrothendieck at gmail.com  Mon Nov 14 09:12:31 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 14 Nov 2005 03:12:31 -0500
Subject: [Rd] Package manpage DCF hooks
In-Reply-To: <Pine.OSF.4.58.0511140146400.518678@wotan.mdacc.tmc.edu>
References: <Pine.OSF.4.58.0511140146400.518678@wotan.mdacc.tmc.edu>
Message-ID: <971536df0511140012t5b9a2ee0vfd72dbb66c574a11@mail.gmail.com>

What I do is make my whatever-package.Rd page be
the central page where one can get a list of all
the other places one can look for info (rather than
placing the info itself there).  See, for example,

library(dyn)
package?dyn


On 11/14/05, Paul Roebuck <roebuck at mdanderson.org> wrote:
> Was looking at what was output for <pkgname>-package.Rd
> and wondered if any there was any means (via macro, etc)
> to merge some of the same information with a template
> for my package manpage? As much (all?) of the generated
> information was already provided in the DESCRIPTION, I'd
> prefer not to have to update the information in multiple
> places. I'm thinking here that I could provide a template
> file "<pkgname>-package.Rd.in" and during build, the
> DCF information could be substituted appropriately and
> "<pkgname>-package.Rd" would be output.
>
> see also:
>    promptPackage method
>
> ----------------------------------------------------------
> SIGSIG -- signature too long (core dumped)
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From ripley at stats.ox.ac.uk  Mon Nov 14 09:16:03 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 14 Nov 2005 08:16:03 +0000 (GMT)
Subject: [Rd] optimized BLAS
Message-ID: <Pine.LNX.4.61.0511140805450.31220@gannet.stats>

As a few of you will know, Dr Goto's BLAS is now available again 
(http://www.tacc.utexas.edu/resources/software/software.php), but only for 
academic use and only for Linux (at least in binary form, and source-code 
licenses are not yet available).

http://www.netlib.org/lapack pointed me to AMD's ACML 
(http://www.amd.com/acml).  This has a less restrictive licence, and seems 
at least as fast as the Goto BLAS - it is also a full optimized LAPACK.

What does seem a bit confused is all the references to AMD64, when they 
also supply 32-bit non-SSE2 and even non-SSE versions (and there are no 
such versions of AMD64 to my knowledge).  It runs on my Athlon XP systems, 
and even under Windows.

I've added comments in R-admin.texi and Windows support, in both R-patched 
and R-devel.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From Weigand.Stephen at mayo.edu  Mon Nov 14 21:23:54 2005
From: Weigand.Stephen at mayo.edu (Weigand.Stephen@mayo.edu)
Date: Mon, 14 Nov 2005 21:23:54 +0100 (CET)
Subject: [Rd] typo in as.POSIXlt.Rd (PR#8309)
Message-ID: <20051114202354.222E820BF8@slim.kubism.ku.dk>

While reading ?as.POSIXlt a possible typo caught my eye.

The "diff -u" output based on R-devel downloaded today 
vs. a suggested change is below. 

Thank you,

Stephen


--- as.POSIXlt.Rd       Mon Oct 17 10:50:06 2005
+++ /tmp/as.POSIXlt.Rd  Mon Nov 14 09:48:48 2005
@@ -30,7 +30,7 @@
 \details{
   The \code{as.POSIX*} functions convert an object to one of the two
   classes used to represent date/times (calendar dates plus time to the
-  nearest second).  They can take convert a wide variety of objects,
+  nearest second).  They can convert a wide variety of objects,
   including objects of the other class and of classes \code{"Date"},
   \code{"date"} (from package \pkg{\link[date:as.date]{date}} or
   \pkg{\link[survival:as.date]{survival}}), \code{"chron"} and

::::::::::::::::::::::::::::::::::
Stephen Weigand
Division of Biostatistics
Mayo Clinic Rochester, Minn., USA
Phone (507) 266-1650, fax 284-9542


From frohne at gci.net  Mon Nov 14 21:55:32 2005
From: frohne at gci.net (Ivan Frohne)
Date: Mon, 14 Nov 2005 11:55:32 -0900
Subject: [Rd] Dead link in documentation for dbinom
Message-ID: <003901c5e95d$c7883530$0bb93a42@Dell8400>

Greetings:

In the documentation for dbinom:
_______________________________________________________
References:

     Catherine Loader (2000). _Fast and Accurate Computation of
     Binomial Probabilities_; manuscript available from <URL:
     http://cm.bell-labs.com/cm/ms/departments/sia/catherine/dbinom>
_______________________________________________________

the URL is dead.  Here's one that works:
_______________________________________________________
References:

    Catherine Loader(2000).  _Fast and Accurate Computation of Binomial 
Probabilities_; manuscript and C listing available from <URL: 
http://www.herine.net/stat/software/dbinom.html>
_______________________________________________________

Her web site is <URL: http://stat.cwru.edu/~catherine/ >; email address: 
<catherine at case.edu>.

--Ivan Frohne


From roebuck at mdanderson.org  Mon Nov 14 22:57:04 2005
From: roebuck at mdanderson.org (Paul Roebuck)
Date: Mon, 14 Nov 2005 15:57:04 -0600 (CST)
Subject: [Rd] Package manpage DCF hooks
In-Reply-To: <971536df0511140012t5b9a2ee0vfd72dbb66c574a11@mail.gmail.com>
References: <Pine.OSF.4.58.0511140146400.518678@wotan.mdacc.tmc.edu>
	<971536df0511140012t5b9a2ee0vfd72dbb66c574a11@mail.gmail.com>
Message-ID: <Pine.OSF.4.58.0511141539060.32647@wotan.mdacc.tmc.edu>

On Mon, 14 Nov 2005, Gabor Grothendieck wrote:

> On 11/14/05, Paul Roebuck <roebuck at mdanderson.org> wrote:
>
> > Was looking at what was output for <pkgname>-package.Rd
> > and wondered if any there was any means (via macro, etc)
> > to merge some of the same information with a template
> > for my package manpage? As much (all?) of the generated
> > information was already provided in the DESCRIPTION, I'd
> > prefer not to have to update the information in multiple
> > places. I'm thinking here that I could provide a template
> > file "<pkgname>-package.Rd.in" and during build, the
> > DCF information could be substituted appropriately and
> > "<pkgname>-package.Rd" would be output.
> >
> > see also:
> >    promptPackage method
>
> What I do is make my whatever-package.Rd page be
> the central page where one can get a list of all
> the other places one can look for info (rather than
> placing the info itself there).  See, for example,
>
> library(dyn)
> package?dyn
>

Thanks for your reply. That gives me some additional
ideas but still think being able to display DCF
information and public function listing would be a nice
thing to have. For example, 'dyn-package.Rd' repeats its
DCF description.

----------------------------------------------------------
SIGSIG -- signature too long (core dumped)


From Weigand.Stephen at mayo.edu  Mon Nov 14 23:28:49 2005
From: Weigand.Stephen at mayo.edu (Weigand.Stephen@mayo.edu)
Date: Mon, 14 Nov 2005 23:28:49 +0100 (CET)
Subject: [Rd] Typo in isR.Rd (PR#8310)
Message-ID: <20051114222849.635602214D@slim.kubism.ku.dk>

In reading ?is.R, I noticed what appears to be a typo.

The "diff -u" output based on R-devel downloaded today
vs. a possible change is below.

Thank you,

Stephen

--- ./src/library/base/man/isR.Rd       Tue Jul 20 11:46:24 2004
+++ /tmp/isR.Rd Mon Nov 14 16:13:27 2005
@@ -12,7 +12,7 @@
   The function has been written such as to correctly run in all versions
   of \R, S and S-PLUS.
   In order for code to be runnable in both \R and S dialects, either
-  your the code must define \code{is.R} or use it as
+  the code must define \code{is.R} or use it as
 
   \code{if (exists("is.R") && is.function(is.R) && is.R()) \{}\cr
   \code{    }\emph{\#\# R-specific code}\cr


::::::::::::::::::::::::::::::::::
Stephen Weigand
Division of Biostatistics
Mayo Clinic Rochester, Minn., USA
Phone (507) 266-1650, fax 284-9542


From maechler at stat.math.ethz.ch  Tue Nov 15 10:09:03 2005
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 15 Nov 2005 10:09:03 +0100
Subject: [Rd] Dead link in documentation for dbinom
In-Reply-To: <003901c5e95d$c7883530$0bb93a42@Dell8400>
References: <003901c5e95d$c7883530$0bb93a42@Dell8400>
Message-ID: <17273.42415.848795.224023@stat.math.ethz.ch>

Thank you, Ivan, for the documentation update;
Yes, such small "fixes"/patches are welcome as well.

Martin


From maechler at stat.math.ethz.ch  Tue Nov 15 10:50:05 2005
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 15 Nov 2005 10:50:05 +0100
Subject: [Rd] Package manpage DCF hooks
In-Reply-To: <Pine.OSF.4.58.0511141539060.32647@wotan.mdacc.tmc.edu>
References: <Pine.OSF.4.58.0511140146400.518678@wotan.mdacc.tmc.edu>
	<971536df0511140012t5b9a2ee0vfd72dbb66c574a11@mail.gmail.com>
	<Pine.OSF.4.58.0511141539060.32647@wotan.mdacc.tmc.edu>
Message-ID: <17273.44877.537229.807094@stat.math.ethz.ch>

>>>>> "Paul" == Paul Roebuck <roebuck at mdanderson.org>
>>>>>     on Mon, 14 Nov 2005 15:57:04 -0600 (CST) writes:

    Paul> On Mon, 14 Nov 2005, Gabor Grothendieck wrote:
    >> On 11/14/05, Paul Roebuck <roebuck at mdanderson.org> wrote:
    >> 
    >> > Was looking at what was output for <pkgname>-package.Rd
    >> > and wondered if any there was any means (via macro, etc)
    >> > to merge some of the same information with a template
    >> > for my package manpage? As much (all?) of the generated
    >> > information was already provided in the DESCRIPTION, I'd
    >> > prefer not to have to update the information in multiple
    >> > places. I'm thinking here that I could provide a template
    >> > file "<pkgname>-package.Rd.in" and during build, the
    >> > DCF information could be substituted appropriately and
    >> > "<pkgname>-package.Rd" would be output.
    >> >
    >> > see also:
    >> >    promptPackage method
    >> 
    >> What I do is make my whatever-package.Rd page be
    >> the central page where one can get a list of all
    >> the other places one can look for info (rather than
    >> placing the info itself there).  See, for example,
    >> 
    >> library(dyn)
    >> package?dyn

    Paul> Thanks for your reply. That gives me some additional
    Paul> ideas but still think being able to display DCF
    Paul> information and public function listing would be a nice
    Paul> thing to have. For example, 'dyn-package.Rd' repeats its
    Paul> DCF description.

which I agree is not ideal.  I agree that such information
should in principle reside in one place and be
``auto-distributed'' to other places during package installation
and maybe also package load time.

Note that  packageDescription("dyn")
returns an object that contains (and may print if you want) the
DCF information.

One possibility I see would be the convention that the 
'generated' (text, html, tex) help files for  'package-<name>' 
would combine both the packageDescription() and
the contents of  <name>-package.Rd.  

Martin


From wolfgang.lederer at stat.uni-muenchen.de  Tue Nov 15 17:33:31 2005
From: wolfgang.lederer at stat.uni-muenchen.de (wolfgang.lederer@stat.uni-muenchen.de)
Date: Tue, 15 Nov 2005 17:33:31 +0100 (CET)
Subject: [Rd] Bug in the example of function optim() (PR#8312)
Message-ID: <20051115163331.0FF662243B@slim.kubism.ku.dk>

Dear R-Team,

there seems to be a minor bug in the example for optim(). In the 
travelling salseman part of the example section the lines

text(x, y, names(eurodist), cex=0.8)  (7th line from bottom)

text(x, y, names(eurodist), cex=0.8)  (last line)

do not produce any oputput, because names(eurodist) has value "NULL". To 
get the intended output one has just to substitute names() by labels(). 
So the correct line will be:

text(x, y, labels(eurodist), cex=0.8)  .

Thanks for all your effort and the software you created.

Greetings

Wolfgang Lederer

--please do not edit the information below--

Version:
 platform = i386-pc-mingw32
 arch = i386
 os = mingw32
 system = i386, mingw32
 status =
 major = 2
 minor = 2.0
 year = 2005
 month = 10
 day = 06
 svn rev = 35749
 language = R

Windows XP Professional (build 2600) Service Pack 2.0

Locale:
LC_COLLATE=German_Germany.1252;LC_CTYPE=German_Germany.1252;LC_MONETARY=German_Germany.1252;LC_NUMERIC=C;LC_TIME=German_Germany.1252

Search Path:
 .GlobalEnv, package:methods, package:stats, package:graphics, 
package:grDevices, package:utils, package:datasets, Autoloads, package:base

-- 
**************************************************
Wolfgang Lederer
Institut f?r Statistik
Ludwig-Maximilians-Universit?t M?nchen
Martius Str. 4
D-80539 M?nchen
Tel: +49 89 2180 4847
Fax: +49 89 2180 5308


From ripley at stats.ox.ac.uk  Tue Nov 15 17:47:25 2005
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Tue, 15 Nov 2005 17:47:25 +0100 (CET)
Subject: [Rd] Bug in the example of function optim() (PR#8312)
Message-ID: <20051115164725.BEDC71DFF7@slim.kubism.ku.dk>

  This message is in MIME format.  The first part should be readable text,
  while the remaining parts are likely unreadable without MIME-aware tools.

--27464147-1959301360-1132073234=:9778
Content-Type: TEXT/PLAIN; charset=iso-8859-1; format=flowed
Content-Transfer-Encoding: QUOTED-PRINTABLE

This is aleady fixed in the current versions of R, R-patched, and R-devel.
See the posting guide or FAQ for how you can check such versions
(and save your time and ours).

On Tue, 15 Nov 2005 wolfgang.lederer at stat.uni-muenchen.de wrote:

> Dear R-Team,
>
> there seems to be a minor bug in the example for optim(). In the
> travelling salseman part of the example section the lines
>
> text(x, y, names(eurodist), cex=3D0.8)  (7th line from bottom)
>
> text(x, y, names(eurodist), cex=3D0.8)  (last line)
>
> do not produce any oputput, because names(eurodist) has value "NULL". To
> get the intended output one has just to substitute names() by labels().
> So the correct line will be:
>
> text(x, y, labels(eurodist), cex=3D0.8)  .
>
> Thanks for all your effort and the software you created.
>
> Greetings
>
> Wolfgang Lederer
>
> --please do not edit the information below--
>
> Version:
> platform =3D i386-pc-mingw32
> arch =3D i386
> os =3D mingw32
> system =3D i386, mingw32
> status =3D
> major =3D 2
> minor =3D 2.0
> year =3D 2005
> month =3D 10
> day =3D 06
> svn rev =3D 35749
> language =3D R
>
> Windows XP Professional (build 2600) Service Pack 2.0
>
> Locale:
> LC_COLLATE=3DGerman_Germany.1252;LC_CTYPE=3DGerman_Germany.1252;LC_MONETA=
RY=3DGerman_Germany.1252;LC_NUMERIC=3DC;LC_TIME=3DGerman_Germany.1252
>
> Search Path:
> .GlobalEnv, package:methods, package:stats, package:graphics,
> package:grDevices, package:utils, package:datasets, Autoloads, package:ba=
se
>
> --=20
> **************************************************
> Wolfgang Lederer
> Institut f=FCr Statistik
> Ludwig-Maximilians-Universit=E4t M=FCnchen
> Martius Str. 4
> D-80539 M=FCnchen
> Tel: +49 89 2180 4847
> Fax: +49 89 2180 5308
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

--=20
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595
--27464147-1959301360-1132073234=:9778--


From roebuck at mdanderson.org  Tue Nov 15 20:07:47 2005
From: roebuck at mdanderson.org (Paul Roebuck)
Date: Tue, 15 Nov 2005 13:07:47 -0600 (CST)
Subject: [Rd] Package manpage DCF hooks
In-Reply-To: <17273.44877.537229.807094@stat.math.ethz.ch>
References: <Pine.OSF.4.58.0511140146400.518678@wotan.mdacc.tmc.edu>
	<971536df0511140012t5b9a2ee0vfd72dbb66c574a11@mail.gmail.com>
	<Pine.OSF.4.58.0511141539060.32647@wotan.mdacc.tmc.edu>
	<17273.44877.537229.807094@stat.math.ethz.ch>
Message-ID: <Pine.OSF.4.58.0511151235350.98026@wotan.mdacc.tmc.edu>

On Tue, 15 Nov 2005, Martin Maechler wrote:

> >>>>> "Paul" == Paul Roebuck <roebuck at mdanderson.org>
> >>>>>     on Mon, 14 Nov 2005 15:57:04 -0600 (CST) writes:
>
>     Paul> On Mon, 14 Nov 2005, Gabor Grothendieck wrote:
>     >> On 11/14/05, Paul Roebuck <roebuck at mdanderson.org> wrote:
>     >>
>     >> > Was looking at what was output for <pkgname>-package.Rd
>     >> > and wondered if any there was any means (via macro, etc)
>     >> > to merge some of the same information with a template
>     >> > for my package manpage? As much (all?) of the generated
>     >> > information was already provided in the DESCRIPTION, I'd
>     >> > prefer not to have to update the information in multiple
>     >> > places. I'm thinking here that I could provide a template
>     >> > file "<pkgname>-package.Rd.in" and during build, the
>     >> > DCF information could be substituted appropriately and
>     >> > "<pkgname>-package.Rd" would be output.
>     >> >
>     >> > see also:
>     >> >    promptPackage method
>     >>
>     >> What I do is make my whatever-package.Rd page be
>     >> the central page where one can get a list of all
>     >> the other places one can look for info (rather than
>     >> placing the info itself there).  See, for example,
>     >>
>     >> library(dyn)
>     >> package?dyn
>
>     Paul> Thanks for your reply. That gives me some additional
>     Paul> ideas but still think being able to display DCF
>     Paul> information and public function listing would be a nice
>     Paul> thing to have. For example, 'dyn-package.Rd' repeats its
>     Paul> DCF description.
>
> which I agree is not ideal.  I agree that such information
> should in principle reside in one place and be
> ``auto-distributed'' to other places during package installation
> and maybe also package load time.
>
> Note that packageDescription("dyn") returns an object that
> contains (and may print if you want) the DCF information.

I'm aware of this, having used it in various places. What
I don't know is how to access/use it during package
installation (if even possible). Using read.dcf and a sed
script, I could probably manage to perform the template
merge. But I don't know how to invoke such without adding
a configure script (overkill for R-only packages), as
'install.R' is meant for something else.

> One possibility I see would be the convention that the
> 'generated' (text, html, tex) help files for 'package-<name>'
> would combine both the packageDescription() and
> the contents of <name>-package.Rd.

Well, a system-level approach would be preferable to doing
this per-package. R-2.3 then?

----------------------------------------------------------
SIGSIG -- signature too long (core dumped)


From berwin at maths.uwa.edu.au  Wed Nov 16 02:48:30 2005
From: berwin at maths.uwa.edu.au (Berwin A Turlach)
Date: Wed, 16 Nov 2005 09:48:30 +0800
Subject: [Rd] Bug or a feature that I completely missed?
Message-ID: <17274.36846.361077.416981@bossiaea.maths.uwa.edu.au>

Dear all,

while looking at some R-code submitted by students in a unit that I
teach, I came across constructs that I thought would lead to an error.
Much to my surprise, the code is actually executed.

A boiled down version of the code is the following:

> tt <- function(x, i){
+   mean(x[i,2])/mean(x[i,1])
+ }
> dat <- matrix(rnorm(200), ncol=2)
> mean(dat[,2])/mean(dat[,1])
[1] -1.163893
> dat1 <- data.frame(dat)
> tt(dat1)                 ###  Why does this work?
[1] -1.163893
> tt(dat)
Error in mean(x[i, 2]) : argument "i" is missing, with no default

Since the data for the assignment was in a data frame, the students got
an answer and not an error message when they called the equivalent of
tt(dat1) in their work.

I tested this code on R 1.8.1, 1.9.1, 2.0.0, 2.0.1, 2.1.0, 2.1.1,
2.2.0 and R-devel (2005-11-14 r36330), all with the same result, no
error message when executing tt(dat1).

I would have expected that tt(dat1) behaves in the same way as tt(dat)
and would produce an error.  Thus, I think it is a bug, but the fact
that so many R versions accept this code makes me wonder whether it is
a misunderstanding on my side.  Can somebody enlighten me why this
code is working?

Cheers,

        Berwin


From ggrothendieck at gmail.com  Wed Nov 16 03:39:22 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 15 Nov 2005 21:39:22 -0500
Subject: [Rd] Bug or a feature that I completely missed?
In-Reply-To: <17274.36846.361077.416981@bossiaea.maths.uwa.edu.au>
References: <17274.36846.361077.416981@bossiaea.maths.uwa.edu.au>
Message-ID: <971536df0511151839q3ddca14s41cdb09c95dff5ba@mail.gmail.com>

On 11/15/05, Berwin A Turlach <berwin at maths.uwa.edu.au> wrote:
> Dear all,
>
> while looking at some R-code submitted by students in a unit that I
> teach, I came across constructs that I thought would lead to an error.
> Much to my surprise, the code is actually executed.
>
> A boiled down version of the code is the following:
>
> > tt <- function(x, i){
> +   mean(x[i,2])/mean(x[i,1])
> + }
> > dat <- matrix(rnorm(200), ncol=2)
> > mean(dat[,2])/mean(dat[,1])
> [1] -1.163893
> > dat1 <- data.frame(dat)
> > tt(dat1)                 ###  Why does this work?
> [1] -1.163893
> > tt(dat)
> Error in mean(x[i, 2]) : argument "i" is missing, with no default
>
> Since the data for the assignment was in a data frame, the students got
> an answer and not an error message when they called the equivalent of
> tt(dat1) in their work.
>
> I tested this code on R 1.8.1, 1.9.1, 2.0.0, 2.0.1, 2.1.0, 2.1.1,
> 2.2.0 and R-devel (2005-11-14 r36330), all with the same result, no
> error message when executing tt(dat1).
>
> I would have expected that tt(dat1) behaves in the same way as tt(dat)
> and would produce an error.  Thus, I think it is a bug, but the fact
> that so many R versions accept this code makes me wonder whether it is
> a misunderstanding on my side.  Can somebody enlighten me why this
> code is working?
>

I don't have a complete explanation but consider:

f <- function(x) missing(x)
g <- function(x) f(x)
g()  # TRUE

That is, in R one can pass missing values from one
function to another and that is evidently what
is happening with tt which passes the missing
i to [.data.frame.  The weird part, to me, is that
[ does not also allow this even though it does allow
empty arguments though likely its due to
[ being written in C and [.data.frame being
written in R.

Try

getAnywhere("[.data.frame")
getAnywhere("[")


From ripley at stats.ox.ac.uk  Wed Nov 16 09:21:06 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 16 Nov 2005 08:21:06 +0000 (GMT)
Subject: [Rd] Bug or a feature that I completely missed?
In-Reply-To: <17274.36846.361077.416981@bossiaea.maths.uwa.edu.au>
References: <17274.36846.361077.416981@bossiaea.maths.uwa.edu.au>
Message-ID: <Pine.LNX.4.61.0511160740250.28536@gannet.stats>

On Wed, 16 Nov 2005, Berwin A Turlach wrote:

> Dear all,
>
> while looking at some R-code submitted by students in a unit that I
> teach, I came across constructs that I thought would lead to an error.
> Much to my surprise, the code is actually executed.
>
> A boiled down version of the code is the following:
>
>> tt <- function(x, i){
> +   mean(x[i,2])/mean(x[i,1])
> + }
>> dat <- matrix(rnorm(200), ncol=2)
>> mean(dat[,2])/mean(dat[,1])
> [1] -1.163893
>> dat1 <- data.frame(dat)
>> tt(dat1)                 ###  Why does this work?
> [1] -1.163893
>> tt(dat)
> Error in mean(x[i, 2]) : argument "i" is missing, with no default
>
> Since the data for the assignment was in a data frame, the students got
> an answer and not an error message when they called the equivalent of
> tt(dat1) in their work.
>
> I tested this code on R 1.8.1, 1.9.1, 2.0.0, 2.0.1, 2.1.0, 2.1.1,
> 2.2.0 and R-devel (2005-11-14 r36330), all with the same result, no
> error message when executing tt(dat1).
>
> I would have expected that tt(dat1) behaves in the same way as tt(dat)
> and would produce an error.  Thus, I think it is a bug, but the fact
> that so many R versions accept this code makes me wonder whether it is
> a misunderstanding on my side.  Can somebody enlighten me why this
> code is working?

[.data.frame is interpreted, [ is internal for a matrix.  The issue is 
what happens to x[i,2] where i is missing.  In [.data.frame you find

     if(missing(i)) { # df[, j] or df[ , ]
         ## handle the column only subsetting ...
         if(!missing(j)) x <- x[j]
 	cols <- names(x)
 	if(any(is.na(cols))) stop("undefined columns selected")
     } ...

so it was deliberate, it seems.  I believe S used to do the same 
thing in its S3 days, but it appears this is now an error.  However, 
missingness is an area of S/R differences (mainly undocumented, I think).
Currently in S there is

> args("[.data.frame")
function(x, ..., drop = T)

whereas in R

> args("[.data.frame")
function (x, i, j, drop = ....

Since [ is primitive you cannot use args() on it, but its argument list is 
more like S's (which is f(x, ..., drop = T) for the generic and all 
methods).

I don't believe this would be easy to change if we wanted to.  Similar 
things happen for the replacement method.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From maechler at stat.math.ethz.ch  Wed Nov 16 09:42:35 2005
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 16 Nov 2005 09:42:35 +0100
Subject: [Rd] Package manpage DCF hooks
In-Reply-To: <Pine.OSF.4.58.0511151235350.98026@wotan.mdacc.tmc.edu>
References: <Pine.OSF.4.58.0511140146400.518678@wotan.mdacc.tmc.edu>
	<971536df0511140012t5b9a2ee0vfd72dbb66c574a11@mail.gmail.com>
	<Pine.OSF.4.58.0511141539060.32647@wotan.mdacc.tmc.edu>
	<17273.44877.537229.807094@stat.math.ethz.ch>
	<Pine.OSF.4.58.0511151235350.98026@wotan.mdacc.tmc.edu>
Message-ID: <17274.61691.755261.379446@stat.math.ethz.ch>

>>>>> "Paul" == Paul Roebuck <roebuck at mdanderson.org>
>>>>>     on Tue, 15 Nov 2005 13:07:47 -0600 (CST) writes:

    Paul> On Tue, 15 Nov 2005, Martin Maechler wrote:
    >> >>>>> "Paul" == Paul Roebuck <roebuck at mdanderson.org>
    >> >>>>>     on Mon, 14 Nov 2005 15:57:04 -0600 (CST) writes:
    >> 
    Paul> On Mon, 14 Nov 2005, Gabor Grothendieck wrote:
    >> >> On 11/14/05, Paul Roebuck <roebuck at mdanderson.org> wrote:
    >> >>
    >> >> > Was looking at what was output for <pkgname>-package.Rd
    >> >> > and wondered if any there was any means (via macro, etc)
    >> >> > to merge some of the same information with a template
    >> >> > for my package manpage? As much (all?) of the generated
    >> >> > information was already provided in the DESCRIPTION, I'd
    >> >> > prefer not to have to update the information in multiple
    >> >> > places. I'm thinking here that I could provide a template
    >> >> > file "<pkgname>-package.Rd.in" and during build, the
    >> >> > DCF information could be substituted appropriately and
    >> >> > "<pkgname>-package.Rd" would be output.
    >> >> >
    >> >> > see also:
    >> >> >    promptPackage method
    >> >>
    >> >> What I do is make my whatever-package.Rd page be
    >> >> the central page where one can get a list of all
    >> >> the other places one can look for info (rather than
    >> >> placing the info itself there).  See, for example,
    >> >>
    >> >> library(dyn)
    >> >> package?dyn
    >> 
    Paul> Thanks for your reply. That gives me some additional
    Paul> ideas but still think being able to display DCF
    Paul> information and public function listing would be a nice
    Paul> thing to have. For example, 'dyn-package.Rd' repeats its
    Paul> DCF description.
    >> 
    >> which I agree is not ideal.  I agree that such information
    >> should in principle reside in one place and be
    >> ``auto-distributed'' to other places during package installation
    >> and maybe also package load time.
    >> 
    >> Note that packageDescription("dyn") returns an object that
    >> contains (and may print if you want) the DCF information.

    Paul> I'm aware of this, having used it in various places. What
    Paul> I don't know is how to access/use it during package
    Paul> installation (if even possible). Using read.dcf and a sed
    Paul> script, I could probably manage to perform the template
    Paul> merge. But I don't know how to invoke such without adding
    Paul> a configure script (overkill for R-only packages), as
    Paul> 'install.R' is meant for something else.

    >> One possibility I see would be the convention that the
    >> 'generated' (text, html, tex) help files for 'package-<name>'
    >> would combine both the packageDescription() and
    >> the contents of <name>-package.Rd.

    Paul> Well, a system-level approach would be preferable to doing
    Paul> this per-package.

Definitely, and actually I was only thinking of the former.

    Paul>  R-2.3 then?

with help of contributions from smart R-devel
readers/contributors that should be fairly plausible, 
otherwise I'm much less confident.

Martin


From petrakl at zce.cz  Wed Nov 16 10:10:46 2005
From: petrakl at zce.cz (petrakl@zce.cz)
Date: Wed, 16 Nov 2005 10:10:46 +0100 (CET)
Subject: [Rd] Malformed package name (PR#8314)
Message-ID: <20051116091046.B6EF722361@slim.kubism.ku.dk>

Full_Name: L. Petr?k
Version: 2.2
OS: w2k
Submission from: (NULL) (193.109.177.11)


# rcmd build Translation-it
* checking for file 'Translation-it/DESCRIPTION' ... OK
* preparing 'Translation-it':
* checking DESCRIPTION meta-information ... ERROR
Malformed package name

See the information on DESCRIPTION files in section 'Creating R
packages' of the 'Writing R Extensions' manual.

=====
char "-" is not alowed in package name (bug in 'build' script or 'utils.R' or
'manuals/R-ext')


From p.dalgaard at biostat.ku.dk  Wed Nov 16 11:40:24 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 16 Nov 2005 11:40:24 +0100
Subject: [Rd] Malformed package name (PR#8314)
In-Reply-To: <20051116091046.B6EF722361@slim.kubism.ku.dk>
References: <20051116091046.B6EF722361@slim.kubism.ku.dk>
Message-ID: <x2sltwx4dj.fsf@viggo.kubism.ku.dk>

petrakl at zce.cz writes:

> Full_Name: L. Petr?k
> Version: 2.2
> OS: w2k
> Submission from: (NULL) (193.109.177.11)
> 
> 
> # rcmd build Translation-it
> * checking for file 'Translation-it/DESCRIPTION' ... OK
> * preparing 'Translation-it':
> * checking DESCRIPTION meta-information ... ERROR
> Malformed package name
> 
> See the information on DESCRIPTION files in section 'Creating R
> packages' of the 'Writing R Extensions' manual.
> 
> =====
> char "-" is not alowed in package name (bug in 'build' script or 'utils.R' or
> 'manuals/R-ext')

Why is that a bug? The documentation clearly says what is allowed and
this isn't:

The Package and Version fields give the name and the version of the
package, respectively. The name should consist of letters, numbers,
and the dot character and start with a letter. The version is a
sequence of at least two (and usually three) non-negative integers
separated by single . or - characters. The canonical form is as shown
in the example, and a version such as 0.01 or 0.01.0 will be handled
as if it were 0.1-0.

If we allowed "-" in names, the first thing that would happen is that
we get bug reports that library(Translation-it) causes weird error
messages. 


-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From maechler at stat.math.ethz.ch  Wed Nov 16 12:05:50 2005
From: maechler at stat.math.ethz.ch (maechler@stat.math.ethz.ch)
Date: Wed, 16 Nov 2005 12:05:50 +0100 (CET)
Subject: [Rd] Malformed package name (PR#8314)
Message-ID: <20051116110550.4572B2241E@slim.kubism.ku.dk>

>>>>> "petrakl" == petrakl  <petrakl at zce.cz>
>>>>>     on Wed, 16 Nov 2005 10:10:46 +0100 (CET) writes:

    petrakl> Full_Name: L. Petr?k
    petrakl> Version: 2.2
    petrakl> OS: w2k
    petrakl> Submission from: (NULL) (193.109.177.11)


    petrakl> # rcmd build Translation-it
    petrakl> * checking for file 'Translation-it/DESCRIPTION' ... OK
    petrakl> * preparing 'Translation-it':
    petrakl> * checking DESCRIPTION meta-information ... ERROR
    petrakl> Malformed package name

    petrakl> See the information on DESCRIPTION files in section 'Creating R
    petrakl> packages' of the 'Writing R Extensions' manual.

if you do what this error message tells you, 
you should quickly find

>>    The `Package' and `Version' fields give the name and the version of
>> the package, respectively.  The name should consist of letters,
>> numbers, and the dot character and start with a letter. ...............

Hence it's clear that the character "-" is not allowed in a
package name.

So why do you think this is a bug ?

    petrakl> =====
    petrakl> char "-" is not alowed in package name (bug in
    petrakl> 'build' script or 'utils.R' or 'manuals/R-ext')

Regards,
Martin Maechler, ETH Zurich


From ripley at stats.ox.ac.uk  Wed Nov 16 13:05:17 2005
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Wed, 16 Nov 2005 13:05:17 +0100 (CET)
Subject: [Rd] Malformed package name (PR#8314)
Message-ID: <20051116120517.881D71E366@slim.kubism.ku.dk>

  This message is in MIME format.  The first part should be readable text,
  while the remaining parts are likely unreadable without MIME-aware tools.

--27464147-1563048805-1132142703=:11543
Content-Type: TEXT/PLAIN; charset=iso-8859-1; format=flowed
Content-Transfer-Encoding: QUOTED-PRINTABLE

On Wed, 16 Nov 2005 maechler at stat.math.ethz.ch wrote:

>>>>>> "petrakl" =3D=3D petrakl  <petrakl at zce.cz>
>>>>>>     on Wed, 16 Nov 2005 10:10:46 +0100 (CET) writes:
>
>    petrakl> Full_Name: L. Petr=E1k
>    petrakl> Version: 2.2
>    petrakl> OS: w2k
>    petrakl> Submission from: (NULL) (193.109.177.11)
>
>
>    petrakl> # rcmd build Translation-it
>    petrakl> * checking for file 'Translation-it/DESCRIPTION' ... OK
>    petrakl> * preparing 'Translation-it':
>    petrakl> * checking DESCRIPTION meta-information ... ERROR
>    petrakl> Malformed package name
>
>    petrakl> See the information on DESCRIPTION files in section 'Creating=
 R
>    petrakl> packages' of the 'Writing R Extensions' manual.
>
> if you do what this error message tells you,
> you should quickly find
>
>>>    The `Package' and `Version' fields give the name and the version of
>>> the package, respectively.  The name should consist of letters,
>>> numbers, and the dot character and start with a letter. ...............
>
> Hence it's clear that the character "-" is not allowed in a
> package name.
>
> So why do you think this is a bug ?

Because that form 'Translation-ll' is recommended in the R-exts manual
for translation packages.  We do say R CMD build will build such=20
packages, and at the time it was written it did.  So we need to make an=20
exception in 'build' for translation packages.

--=20
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595
--27464147-1563048805-1132142703=:11543--


From martin.o'gorman at nonlinear.com  Wed Nov 16 14:37:44 2005
From: martin.o'gorman at nonlinear.com (martin.o'gorman@nonlinear.com)
Date: Wed, 16 Nov 2005 14:37:44 +0100 (CET)
Subject: [Rd] PPC package-ppc.read.raw.nobatch (PR#8316)
Message-ID: <20051116133744.4054C1DE51@slim.kubism.ku.dk>

Full_Name: Martin O'Gorman
Version: 
OS: 
Submission from: (NULL) (84.176.63.149)


I have been looking at the PPC package and have a question. As the input data is
comma separated, shouldn?t the command to read in the raw (no batch) mass spec
data indicate that sep=?,?  (marked below) ? Otherwise, the data read in is the
pair of values (m/z,intensity). It is not obvious why that should be. While
playing around with the data, I noticed that xtr (the intensity matrix) is a
full matrix of value NA as a result of omitting the ?,?. I apologize in advance
if I have missed something obvious. However, the batch read function does use
the sep=?,?. This possible bug doesn't doesn't crash the script and so is
difficult to spot.

 

Many thanks 

Martin

 

 

 

 

 

 

ppc.read.raw.nobatch <- function(directory, mz = NULL) {

  datafiles.list <- ppc.xl.get.names.of.files(directory)

  

  ##

  ## First determine the dimensions of the data matrix

  ##

 

  if (is.null(mz)) {

    pat1 <- read.table(datafiles.list[1])   ?-----  here

    mz <- pat1[,1]

  }

  

  xtr <- matrix(NA, nrow=length(mz), ncol=length(datafiles.list))

 

  ##

  ## Now read in all the data

  ##

  for (j in 1:length(datafiles.list)) {

    if (ppc.options$debug) print(paste("Reading file", datafiles.list[j]))

    

    temp <-  read.table(datafiles.list[j], sep = ",")

    

    xtr[, j] <- approx(temp[, 1], temp[, 2], xout = mz)$y

  }

  

  return(list(xtr = xtr,

              mz = mz,

              filenames=datafiles.list))

}


From jonathan.s.callahan at gmail.com  Wed Nov 16 16:15:00 2005
From: jonathan.s.callahan at gmail.com (Jonathan Callahan)
Date: Wed, 16 Nov 2005 07:15:00 -0800
Subject: [Rd] two-way communication using Unix pipes
Message-ID: <f68da330511160715m6ad1ab40s6744c67aed1998ff@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20051116/728c61ec/attachment.pl

From W.E.Wolski at ncl.ac.uk  Wed Nov 16 16:41:12 2005
From: W.E.Wolski at ncl.ac.uk (Witold Eryk Wolski)
Date: Wed, 16 Nov 2005 16:41:12 +0100
Subject: [Rd] Problem with R.2.2 "No rule to make target
	`d:/prog/r/rw2011/include/R.h"
Message-ID: <437B5318.9000409@ncl.ac.uk>

Dear R-devlopers,

I removed yesterday the R.2.1. installation from windows NT laptop and I 
am getting the following error when building a pacage with R.2.2

---------- Making package msbase ------------
   adding build stamp to DESCRIPTION
   making DLL ...
make[3]: *** No rule to make target `d:/prog/r/rw2011/include/R.h', 
needed by `llogic.o'.  Stop.
....


I have no idea from where R.2.2 takes this path information?

Yours Eryk


-- 
Witold Eryk Wolski
__("<  School of Mathematics and Statistics     _
\__/   University of Newcastle                 'v'
  ||    Newcastle upon Tyne, NE1 7RU, ENGLAND  /   \
  ^^    mail: witek96 at users.sourceforge.net     m m
        http://www.mas.ncl.ac.uk/~nwew
        http://www.northeasttango.org.uk


From B.Rowlingson at lancaster.ac.uk  Wed Nov 16 16:58:26 2005
From: B.Rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Wed, 16 Nov 2005 15:58:26 +0000
Subject: [Rd] two-way communication using Unix pipes
In-Reply-To: <f68da330511160715m6ad1ab40s6744c67aed1998ff@mail.gmail.com>
References: <f68da330511160715m6ad1ab40s6744c67aed1998ff@mail.gmail.com>
Message-ID: <437B5722.9050302@lancaster.ac.uk>

Jonathan Callahan wrote:

> Can someone please explain to me exactly what R is doing with the the
> standard IO handles and whether or not there is any simple way to convince
> it to behave as if it were talking to a user at the other end of a keyboard
> and terminal? I've already tried '--no-readline' but that doesn't solve my
> problem.
> 

This little noddy example works for me:

#!/usr/bin/perl

use FileHandle;
use IPC::Open2;

$pid=open2(*Reader, *Writer, "R --no-save");
print Writer "x=runif(10);print(mean(x))\n";
while($got=<Reader>){
     print "Got ".$got;
}

Of course, without the \n in the command string it doesnt work at all, 
but I dont see any problems with R reading from stdin and writing to 
stdout....

This is on a Linux box, I dont think you mentioned an OS or platform...

Baz


From ripley at stats.ox.ac.uk  Wed Nov 16 17:20:29 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 16 Nov 2005 16:20:29 +0000 (GMT)
Subject: [Rd] Problem with R.2.2 "No rule to make target
 `d:/prog/r/rw2011/include/R.h"
In-Reply-To: <437B5318.9000409@ncl.ac.uk>
References: <437B5318.9000409@ncl.ac.uk>
Message-ID: <Pine.LNX.4.61.0511161605180.14174@gannet.stats>

On Wed, 16 Nov 2005, Witold Eryk Wolski wrote:

> Dear R-devlopers,
>
> I removed yesterday the R.2.1. installation from windows NT laptop and I
> am getting the following error when building a pacage with R.2.2
>
> ---------- Making package msbase ------------
>   adding build stamp to DESCRIPTION
>   making DLL ...
> make[3]: *** No rule to make target `d:/prog/r/rw2011/include/R.h',
> needed by `llogic.o'.  Stop.
> ....
>
>
> I have no idea from where R.2.2 takes this path information?

Dependency information in your package directory.  Please remove any *.d 
and Makedeps files.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ligges at statistik.uni-dortmund.de  Wed Nov 16 17:29:07 2005
From: ligges at statistik.uni-dortmund.de (ligges@statistik.uni-dortmund.de)
Date: Wed, 16 Nov 2005 17:29:07 +0100 (CET)
Subject: [Rd] PPC package-ppc.read.raw.nobatch (PR#8316)
Message-ID: <20051116162907.0F595223EC@slim.kubism.ku.dk>

martin.o'gorman at nonlinear.com wrote:

> Full_Name: Martin O'Gorman
> Version: 
> OS: 
> Submission from: (NULL) (84.176.63.149)
> 
> 
> I have been looking at the PPC package and have a question. As the input data is
> comma separated, shouldn?t the command to read in the raw (no batch) mass spec
> data indicate that sep=?,?  (marked below) ? Otherwise, the data read in is the
> pair of values (m/z,intensity). It is not obvious why that should be. While
> playing around with the data, I noticed that xtr (the intensity matrix) is a
> full matrix of value NA as a result of omitting the ?,?. I apologize in advance
> if I have missed something obvious. However, the batch read function does use
> the sep=?,?. This possible bug doesn't doesn't crash the script and so is
> difficult to spot.
> 
>  
> 
> Many thanks 
> 
> Martin

Please report bugs in contributed R packages to the package maintainer 
rather than to R-bugs. The R Core members cannot do anything in such a 
case but have to clean up teh bug repository after you...
Please note that the package you are talking about is probably named 
"ppc" rather than "PPC".

Uwe Ligges


From W.E.Wolski at ncl.ac.uk  Wed Nov 16 17:41:12 2005
From: W.E.Wolski at ncl.ac.uk (Witold Eryk Wolski)
Date: Wed, 16 Nov 2005 17:41:12 +0100
Subject: [Rd] Problem with R.2.2 "No rule to make target
	`d:/prog/r/rw2011/include/R.h"
In-Reply-To: <Pine.LNX.4.61.0511161605180.14174@gannet.stats>
References: <437B5318.9000409@ncl.ac.uk>
	<Pine.LNX.4.61.0511161605180.14174@gannet.stats>
Message-ID: <437B6128.80905@ncl.ac.uk>

Thats it.
Thanks a lot,

Eryk

Prof Brian Ripley wrote:
> On Wed, 16 Nov 2005, Witold Eryk Wolski wrote:
> 
>> Dear R-devlopers,
>>
>> I removed yesterday the R.2.1. installation from windows NT laptop and I
>> am getting the following error when building a pacage with R.2.2
>>
>> ---------- Making package msbase ------------
>>   adding build stamp to DESCRIPTION
>>   making DLL ...
>> make[3]: *** No rule to make target `d:/prog/r/rw2011/include/R.h',
>> needed by `llogic.o'.  Stop.
>> ....
>>
>>
>> I have no idea from where R.2.2 takes this path information?
> 
> 
> Dependency information in your package directory.  Please remove any *.d 
> and Makedeps files.
> 

-- 
Witold Eryk Wolski
__("<  School of Mathematics and Statistics     _
\__/   University of Newcastle                 'v'
  ||    Newcastle upon Tyne, NE1 7RU, ENGLAND  /   \
  ^^    mail: witek96 at users.sourceforge.net     m m
        http://www.mas.ncl.ac.uk/~nwew
        http://www.northeasttango.org.uk


From ripley at stats.ox.ac.uk  Wed Nov 16 18:06:49 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 16 Nov 2005 17:06:49 +0000 (GMT)
Subject: [Rd] two-way communication using Unix pipes
In-Reply-To: <437B5722.9050302@lancaster.ac.uk>
References: <f68da330511160715m6ad1ab40s6744c67aed1998ff@mail.gmail.com>
	<437B5722.9050302@lancaster.ac.uk>
Message-ID: <Pine.LNX.4.61.0511161653290.14633@gannet.stats>

On Wed, 16 Nov 2005, Barry Rowlingson wrote:

> Jonathan Callahan wrote:
>
>> Can someone please explain to me exactly what R is doing with the the
>> standard IO handles and whether or not there is any simple way to convince
>> it to behave as if it were talking to a user at the other end of a keyboard
>> and terminal? I've already tried '--no-readline' but that doesn't solve my
>> problem.
>>
>
> This little noddy example works for me:
>
> #!/usr/bin/perl
>
> use FileHandle;
> use IPC::Open2;
>
> $pid=open2(*Reader, *Writer, "R --no-save");
> print Writer "x=runif(10);print(mean(x))\n";
> while($got=<Reader>){
>     print "Got ".$got;
> }
>
> Of course, without the \n in the command string it doesnt work at all,
> but I dont see any problems with R reading from stdin and writing to
> stdout....
>
> This is on a Linux box, I dont think you mentioned an OS or platform...

Well `Unix' is in the subject line so I was assuming not Windows and 
probably not MacOS.

To answer the (somewhat unrelated) question, R for Unix-alikes does

system.c:    R_Interactive = isatty(0);

and so it will not `behave as if it were talking to a user at the other 
end of a keyboard' unless stdin is `connected to a terminal'.  (I am 
pretty sure that pty's count, as that is what ESS uses, but this could be 
OS-dependent.)  Otherwise R does nothing with stdin, so standard rules 
about e.g. line-buffering apply.

And --no-readline is only relevant if R is `connected to a terminal', 
since R_ReadConsole talks directly to stdin (via fgets) if !R_Interactive.

R is Open Source and you can get definitive answers by reading the code.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From contatti at vacanzeviaggi.net  Wed Nov 16 18:21:41 2005
From: contatti at vacanzeviaggi.net (Evolution Travel)
Date: Wed, 16 Nov 2005 17:21:41 UT
Subject: [Rd] Newsletter Evolution Travel
Message-ID: <20051116172141.866A375F20@tefnut.vacanzeviaggi.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20051116/14b3a563/attachment.pl

From roebuck at mdanderson.org  Wed Nov 16 20:52:00 2005
From: roebuck at mdanderson.org (Paul Roebuck)
Date: Wed, 16 Nov 2005 13:52:00 -0600 (CST)
Subject: [Rd] two-way communication using Unix pipes
In-Reply-To: <f68da330511160715m6ad1ab40s6744c67aed1998ff@mail.gmail.com>
References: <f68da330511160715m6ad1ab40s6744c67aed1998ff@mail.gmail.com>
Message-ID: <Pine.OSF.4.58.0511161341030.174462@wotan.mdacc.tmc.edu>

On Wed, 16 Nov 2005, Jonathan Callahan wrote:

> I am trying to communicate with R from a perl program. Because this code
> must be deployed on systems that are outside of my control I do not wish to
> pursue the RSperl.pm approach which requires that R be compiled to use
> shared libraries.
>
> I have a custom, light weight module I have used with other command line
> driven programs like Ferret and Grads. This module follows the standard perl
> procedures for forking a process, opening pipes and then redirecting STDOUT,
> STDIN and STDERR. Commands are sent out to the external program and my perl
> module then uses perl's select(2) function to listen for output from the
> program.
>
> Unfortunately, it doesn't ever seem to get a response from R on the
> redirected STDOUT or STDERR.
>
> Looking at the perl IPC::Run module I see that some programs are aware of
> whether they are talking to a tty or not and revert to 'batch behavior' if
> they don't detect a tty.
>
> Can someone please explain to me exactly what R is doing with the the
> standard IO handles and whether or not there is any simple way to convince
> it to behave as if it were talking to a user at the other end of a keyboard
> and terminal? I've already tried '--no-readline' but that doesn't solve my
> problem.

You can always run a pseudoterminal (pty) between them
which will solve your problem. You can get a copy of the
source for a simple one from Steven's APUE. May have to
modify the getopt() processing a bit on Linux.

----------------------------------------------------------
SIGSIG -- signature too long (core dumped)


From sarkar at mail.utexas.edu  Thu Nov 17 02:22:20 2005
From: sarkar at mail.utexas.edu (sarkar@mail.utexas.edu)
Date: Thu, 17 Nov 2005 02:22:20 +0100 (CET)
Subject: [Rd] Principal Components Analysis (PR#8320)
Message-ID: <20051117012220.307D01E370@slim.kubism.ku.dk>

Full_Name: Sahotra Sarkar
Version: 2.2.0
OS: Windows XP Professional
Submission from: (NULL) (146.6.130.180)


The following two commands should give the same results for the eigenvectors but
do not (there is a sign reversal for the first one):

> summary(princomp(bumpus),loading = TRUE)
Importance of components:
                          Comp.1    Comp.2     Comp.3      Comp.4     Comp.5
Standard deviation     6.2801653 2.4285636 1.13995042 0.560733747 0.03458915
Proportion of Variance 0.8399662 0.1256084 0.02767525 0.006696272 0.00002548
Cumulative Proportion  0.8399662 0.9655746 0.99324988 0.999946156 0.99997164
                             Comp.6       Comp.7       Comp.8       Comp.9
Standard deviation     3.025628e-02 1.405339e-02 1.147326e-02 9.339938e-03
Proportion of Variance 1.949623e-05 4.206121e-06 2.803451e-06 1.857837e-06
Cumulative Proportion  9.999911e-01 9.999953e-01 9.999981e-01 1.000000e+00

Loadings:
   Comp.1 Comp.2 Comp.3 Comp.4 Comp.5 Comp.6 Comp.7 Comp.8 Comp.9
V1  0.497  0.851  0.171                                          
V2  0.853 -0.515                                                 
V3  0.149  0.103 -0.965  0.189                                   
V4               -0.180 -0.981                                   
V5                             -0.288         0.568  0.327  0.693
V6                             -0.399         0.565  0.154 -0.705
V7                             -0.867        -0.475 -0.107       
V8                                            0.352 -0.926  0.118
V9                                     0.994                     
> eigen(cov(bumpus))
$values
[1] 3.973263e+01 5.941610e+00 1.309113e+00 3.167514e-01 1.205271e-03
9.222233e-04
[7] 1.989606e-04 1.326107e-04 8.788062e-05

$vectors
              [,1]          [,2]         [,3]         [,4]          [,5]
 [1,] -0.496897319  0.8505093640  0.171388489  0.018744742 -0.0002708851
 [2,] -0.852790441 -0.5152155401  0.081515933  0.025301353  0.0031275939
 [3,] -0.149011771  0.1032588064 -0.965116017  0.188813583  0.0029039523
 [4,] -0.059981091  0.0228574697 -0.180065518 -0.981007482  0.0301789269
 [5,] -0.002474454 -0.0009781164 -0.003402721 -0.011404980 -0.2884751568
 [6,] -0.002255070 -0.0003234929 -0.002776659 -0.014386855 -0.3990284747
 [7,] -0.003505091 -0.0005603692 -0.006526439 -0.022328724 -0.8671382015
 [8,] -0.001124313  0.0005858447 -0.003031985 -0.006957916 -0.0674635788
 [9,] -0.003810707  0.0004531193 -0.006127501 -0.009908937 -0.0122192249
              [,6]          [,7]          [,8]          [,9]
 [1,] -0.001028476  1.638253e-06  0.0004887328 -0.0003561342
 [2,] -0.002350593 -8.313864e-04 -0.0003929312  0.0005026715
 [3,] -0.004636198  8.031165e-05  0.0015963693  0.0010649875
 [4,] -0.011239114 -5.568762e-03  0.0035062479  0.0003785351
 [5,]  0.083901242  5.675807e-01  0.3265320650 -0.6934139460
 [6,]  0.032231827  5.646388e-01  0.1541661011  0.7049350072
 [7,] -0.058318858 -4.748060e-01 -0.1070487286 -0.0849487969
 [8,]  0.014813290  3.516922e-01 -0.9260185177 -0.1182046449
 [9,]  0.994055719 -9.937481e-02 -0.0249932592  0.0324567705


From ripley at stats.ox.ac.uk  Thu Nov 17 08:15:34 2005
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Thu, 17 Nov 2005 08:15:34 +0100 (CET)
Subject: [Rd] Principal Components Analysis (PR#8320)
Message-ID: <20051117071534.CF567223ED@slim.kubism.ku.dk>

Please do RTFM:  ?princomp says

Note:

      The signs of the columns of the loadings and scores are arbitrary,
      and so may differ between different programs for PCA, and even
      between different builds of R.

and ?prcomp has a similar comment.  Equally, the signs of eigenvectors are 
arbitrary, and ?eigen says

           Recall that the eigenvectors are only defined up to a
           constant: even when the length is specified they are still
           only defined up to a scalar of modulus one (the sign for real
           matrices).

If you don't know why these are true, please ask your advisors for help.


On Thu, 17 Nov 2005 sarkar at mail.utexas.edu wrote:

> Full_Name: Sahotra Sarkar
> Version: 2.2.0
> OS: Windows XP Professional
> Submission from: (NULL) (146.6.130.180)
>
>
> The following two commands should give the same results for the eigenvectors but
> do not (there is a sign reversal for the first one):
>
>> summary(princomp(bumpus),loading = TRUE)
> Importance of components:
>                          Comp.1    Comp.2     Comp.3      Comp.4     Comp.5
> Standard deviation     6.2801653 2.4285636 1.13995042 0.560733747 0.03458915
> Proportion of Variance 0.8399662 0.1256084 0.02767525 0.006696272 0.00002548
> Cumulative Proportion  0.8399662 0.9655746 0.99324988 0.999946156 0.99997164
>                             Comp.6       Comp.7       Comp.8       Comp.9
> Standard deviation     3.025628e-02 1.405339e-02 1.147326e-02 9.339938e-03
> Proportion of Variance 1.949623e-05 4.206121e-06 2.803451e-06 1.857837e-06
> Cumulative Proportion  9.999911e-01 9.999953e-01 9.999981e-01 1.000000e+00
>
> Loadings:
>   Comp.1 Comp.2 Comp.3 Comp.4 Comp.5 Comp.6 Comp.7 Comp.8 Comp.9
> V1  0.497  0.851  0.171
> V2  0.853 -0.515
> V3  0.149  0.103 -0.965  0.189
> V4               -0.180 -0.981
> V5                             -0.288         0.568  0.327  0.693
> V6                             -0.399         0.565  0.154 -0.705
> V7                             -0.867        -0.475 -0.107
> V8                                            0.352 -0.926  0.118
> V9                                     0.994
>> eigen(cov(bumpus))
> $values
> [1] 3.973263e+01 5.941610e+00 1.309113e+00 3.167514e-01 1.205271e-03
> 9.222233e-04
> [7] 1.989606e-04 1.326107e-04 8.788062e-05
>
> $vectors
>              [,1]          [,2]         [,3]         [,4]          [,5]
> [1,] -0.496897319  0.8505093640  0.171388489  0.018744742 -0.0002708851
> [2,] -0.852790441 -0.5152155401  0.081515933  0.025301353  0.0031275939
> [3,] -0.149011771  0.1032588064 -0.965116017  0.188813583  0.0029039523
> [4,] -0.059981091  0.0228574697 -0.180065518 -0.981007482  0.0301789269
> [5,] -0.002474454 -0.0009781164 -0.003402721 -0.011404980 -0.2884751568
> [6,] -0.002255070 -0.0003234929 -0.002776659 -0.014386855 -0.3990284747
> [7,] -0.003505091 -0.0005603692 -0.006526439 -0.022328724 -0.8671382015
> [8,] -0.001124313  0.0005858447 -0.003031985 -0.006957916 -0.0674635788
> [9,] -0.003810707  0.0004531193 -0.006127501 -0.009908937 -0.0122192249
>              [,6]          [,7]          [,8]          [,9]
> [1,] -0.001028476  1.638253e-06  0.0004887328 -0.0003561342
> [2,] -0.002350593 -8.313864e-04 -0.0003929312  0.0005026715
> [3,] -0.004636198  8.031165e-05  0.0015963693  0.0010649875
> [4,] -0.011239114 -5.568762e-03  0.0035062479  0.0003785351
> [5,]  0.083901242  5.675807e-01  0.3265320650 -0.6934139460
> [6,]  0.032231827  5.646388e-01  0.1541661011  0.7049350072
> [7,] -0.058318858 -4.748060e-01 -0.1070487286 -0.0849487969
> [8,]  0.014813290  3.516922e-01 -0.9260185177 -0.1182046449
> [9,]  0.994055719 -9.937481e-02 -0.0249932592  0.0324567705
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From Gregor.Gorjanc at bfro.uni-lj.si  Thu Nov 17 11:52:45 2005
From: Gregor.Gorjanc at bfro.uni-lj.si (Gorjanc Gregor)
Date: Thu, 17 Nov 2005 11:52:45 +0100
Subject: [Rd] Problem with fitdistr for gamma in R 2.2.0
Message-ID: <7FFEE688B57D7346BC6241C55900E730F31ABB@pollux.bfro.uni-lj.si>

Dear R developers,

I have encountered strange behaviour of fitdistr for gamma in recent R
build i.e. 2.2.0. I have attached the code for data at the end of this mail
so you can reproduce the problem. In short, I am able to run fitdistr under
2.1.0 without problems, while I get the following error under 2.2.0
(Version 2.2.0 Patched (2005-11-15 r36348))

> fitdistr(otm, "gamma")
Error in densfun(x, parm[1], parm[2], ...) : 
        'shape' must be strictly positive

The results on 2.1.1 (Version 2.1.1 (2005-06-20)) are

> fitdistr(otm, "gamma")
    shape       rate  
  1.030667   0.189177 
 (0.090537) (0.021166)

Platform: Windows XP

Thank you in advance for your effort on this remarkable tool!

Here is the data for above problem/results:

"otm" <-
c(0.059610966029577, 0.0591496321922168, 0.14, 0.18, 0.24, 0.25, 
0.270071982912719, 0.270758049933706, 0.269911804412492, 0.280138451903593, 
0.279787947586738, 0.279429937571753, 0.3, 0.320746235495899, 
0.319553311037365, 0.51, 0.54, 0.56, 0.6, 0.609812622915953, 
0.609198293855879, 0.64, 0.69, 0.74, 0.76, 0.770972826186568, 
0.769288654833566, 0.78, 0.789181584270671, 0.78991363293305, 
0.8, 0.89, 0.900691718998831, 0.8991656800583, 0.92, 0.93, 0.94, 
1.01, 1.02, 1.13, 1.18, 1.26, 1.29, 1.33, 1.42, 1.43, 1.47, 1.47940529614314, 
1.47920716832764, 1.6, 1.61, 1.63, 1.68938231960637, 1.6894849291523, 
1.82, 1.88088044053270, 1.8792804789003, 1.89, 1.92, 2, 2.04, 
2.07, 2.12, 2.17, 2.18, 2.22, 2.23, 2.27, 2.28, 2.3, 2.32092240267433, 
2.31912300181622, 2.38, 2.39, 2.43, 2.46, 2.51, 2.52, 2.55, 2.56, 
2.61, 2.66091404781397, 2.6595832825806, 2.67, 2.7, 2.77, 2.8, 
2.81, 2.86, 2.87, 2.93, 3.01, 3.05, 3.14, 3.15, 3.17, 3.18, 3.24, 
3.26, 3.33, 3.44, 3.45, 3.52, 3.55, 3.63, 3.73, 3.9, 4, 4.01, 
4.04, 4.13, 4.15934497380769, 4.16094719917513, 4.3, 4.33, 4.34, 
4.66, 4.76, 4.82, 4.83, 4.89, 4.92, 5.06, 5.14, 5.16, 5.26, 5.31, 
5.36, 5.48, 5.66, 5.79, 5.8, 5.85, 5.87, 5.92952534468565, 5.92962284128508, 
6.04, 6.11, 6.13, 6.16, 6.19, 6.42, 6.66, 6.69, 7.11, 7.16, 7.29, 
7.3, 7.31, 7.33, 7.72, 7.82, 7.87, 7.91, 8.01, 8.17, 8.45, 8.49, 
8.73, 8.86, 8.95, 9, 9.05, 9.13, 9.22, 9.52, 9.82, 9.88, 9.91, 
9.99, 10.03, 10.4, 10.59, 10.83, 11.06, 11.64, 11.85, 12.02, 
12.4, 12.64, 12.96, 13.44, 14.06, 14.07, 14.37, 15.4, 15.6, 15.92, 
16.23, 16.6, 16.97, 17.06, 17.8, 18.69, 18.73, 19.2, 19.51, 19.54, 
20.57, 21.05, 22.23, 27.02)

Lep pozdrav / With regards,
    Gregor Gorjanc

----------------------------------------------------------------------
University of Ljubljana
Biotechnical Faculty        URI: http://www.bfro.uni-lj.si/MR/ggorjan
Zootechnical Department     mail: gregor.gorjanc <at> bfro.uni-lj.si
Groblje 3                   tel: +386 (0)1 72 17 861
SI-1230 Domzale             fax: +386 (0)1 72 17 888
Slovenia, Europe
----------------------------------------------------------------------
"One must learn by doing the thing; for though you think you know it,
 you have no certainty until you try." Sophocles ~ 450 B.C.


From ehlers at math.ucalgary.ca  Thu Nov 17 15:38:34 2005
From: ehlers at math.ucalgary.ca (P Ehlers)
Date: Thu, 17 Nov 2005 07:38:34 -0700
Subject: [Rd] Problem with fitdistr for gamma in R 2.2.0
In-Reply-To: <7FFEE688B57D7346BC6241C55900E730F31ABB@pollux.bfro.uni-lj.si>
References: <7FFEE688B57D7346BC6241C55900E730F31ABB@pollux.bfro.uni-lj.si>
Message-ID: <437C95EA.9050502@math.ucalgary.ca>

Gregor,

  fitdistr(otm, "gamma", method="L-BFGS-B")

works for me (on WinXP). Or you could specify "lower = 0".

I no longer have 2.1.0 running, so I don't know why this
wasn't needed in 2.1.0.

"R version 2.2.0, 2005-10-24"
MASS version: 7.2-20

-peter

Gorjanc Gregor wrote:
> Dear R developers,
> 
> I have encountered strange behaviour of fitdistr for gamma in recent R
> build i.e. 2.2.0. I have attached the code for data at the end of this mail
> so you can reproduce the problem. In short, I am able to run fitdistr under
> 2.1.0 without problems, while I get the following error under 2.2.0
> (Version 2.2.0 Patched (2005-11-15 r36348))
> 
> 
>>fitdistr(otm, "gamma")
> 
> Error in densfun(x, parm[1], parm[2], ...) : 
>         'shape' must be strictly positive
> 
> The results on 2.1.1 (Version 2.1.1 (2005-06-20)) are
> 
> 
>>fitdistr(otm, "gamma")
> 
>     shape       rate  
>   1.030667   0.189177 
>  (0.090537) (0.021166)
> 
> Platform: Windows XP
> 
> Thank you in advance for your effort on this remarkable tool!
> 
> Here is the data for above problem/results:
> 
> "otm" <-
> c(0.059610966029577, 0.0591496321922168, 0.14, 0.18, 0.24, 0.25, 
> 0.270071982912719, 0.270758049933706, 0.269911804412492, 0.280138451903593, 
> 0.279787947586738, 0.279429937571753, 0.3, 0.320746235495899, 
> 0.319553311037365, 0.51, 0.54, 0.56, 0.6, 0.609812622915953, 
> 0.609198293855879, 0.64, 0.69, 0.74, 0.76, 0.770972826186568, 
> 0.769288654833566, 0.78, 0.789181584270671, 0.78991363293305, 
> 0.8, 0.89, 0.900691718998831, 0.8991656800583, 0.92, 0.93, 0.94, 
> 1.01, 1.02, 1.13, 1.18, 1.26, 1.29, 1.33, 1.42, 1.43, 1.47, 1.47940529614314, 
> 1.47920716832764, 1.6, 1.61, 1.63, 1.68938231960637, 1.6894849291523, 
> 1.82, 1.88088044053270, 1.8792804789003, 1.89, 1.92, 2, 2.04, 
> 2.07, 2.12, 2.17, 2.18, 2.22, 2.23, 2.27, 2.28, 2.3, 2.32092240267433, 
> 2.31912300181622, 2.38, 2.39, 2.43, 2.46, 2.51, 2.52, 2.55, 2.56, 
> 2.61, 2.66091404781397, 2.6595832825806, 2.67, 2.7, 2.77, 2.8, 
> 2.81, 2.86, 2.87, 2.93, 3.01, 3.05, 3.14, 3.15, 3.17, 3.18, 3.24, 
> 3.26, 3.33, 3.44, 3.45, 3.52, 3.55, 3.63, 3.73, 3.9, 4, 4.01, 
> 4.04, 4.13, 4.15934497380769, 4.16094719917513, 4.3, 4.33, 4.34, 
> 4.66, 4.76, 4.82, 4.83, 4.89, 4.92, 5.06, 5.14, 5.16, 5.26, 5.31, 
> 5.36, 5.48, 5.66, 5.79, 5.8, 5.85, 5.87, 5.92952534468565, 5.92962284128508, 
> 6.04, 6.11, 6.13, 6.16, 6.19, 6.42, 6.66, 6.69, 7.11, 7.16, 7.29, 
> 7.3, 7.31, 7.33, 7.72, 7.82, 7.87, 7.91, 8.01, 8.17, 8.45, 8.49, 
> 8.73, 8.86, 8.95, 9, 9.05, 9.13, 9.22, 9.52, 9.82, 9.88, 9.91, 
> 9.99, 10.03, 10.4, 10.59, 10.83, 11.06, 11.64, 11.85, 12.02, 
> 12.4, 12.64, 12.96, 13.44, 14.06, 14.07, 14.37, 15.4, 15.6, 15.92, 
> 16.23, 16.6, 16.97, 17.06, 17.8, 18.69, 18.73, 19.2, 19.51, 19.54, 
> 20.57, 21.05, 22.23, 27.02)
> 
> Lep pozdrav / With regards,
>     Gregor Gorjanc
> 
> ----------------------------------------------------------------------
> University of Ljubljana
> Biotechnical Faculty        URI: http://www.bfro.uni-lj.si/MR/ggorjan
> Zootechnical Department     mail: gregor.gorjanc <at> bfro.uni-lj.si
> Groblje 3                   tel: +386 (0)1 72 17 861
> SI-1230 Domzale             fax: +386 (0)1 72 17 888
> Slovenia, Europe
> ----------------------------------------------------------------------
> "One must learn by doing the thing; for though you think you know it,
>  you have no certainty until you try." Sophocles ~ 450 B.C.
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

Peter Ehlers
University of Calgary


From vasu.akkineni at gmail.com  Thu Nov 17 16:35:27 2005
From: vasu.akkineni at gmail.com (Vasundhara Akkineni)
Date: Thu, 17 Nov 2005 10:35:27 -0500
Subject: [Rd] Scan data from a .txt file
Message-ID: <3b67376c0511170735m1c9120cfjee0b4d4fe59d2740@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20051117/7b98bb5e/attachment.pl

From p.dalgaard at biostat.ku.dk  Thu Nov 17 16:37:35 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 17 Nov 2005 16:37:35 +0100
Subject: [Rd] Problem with fitdistr for gamma in R 2.2.0
In-Reply-To: <437C95EA.9050502@math.ucalgary.ca>
References: <7FFEE688B57D7346BC6241C55900E730F31ABB@pollux.bfro.uni-lj.si>
	<437C95EA.9050502@math.ucalgary.ca>
Message-ID: <x2br0jffpc.fsf@viggo.kubism.ku.dk>

P Ehlers <ehlers at math.ucalgary.ca> writes:

> Gregor,
> 
>   fitdistr(otm, "gamma", method="L-BFGS-B")
> 
> works for me (on WinXP). Or you could specify "lower = 0".

The really odd thing is that it even works with

>  fitdistr(otm, "gamma",lower=-Inf)
     shape         rate
  1.03081094   0.18924370
 (0.09055117) (0.02117350)

or even

>  fitdistr(otm, "gamma",upper=Inf)
     shape         rate
  1.03081094   0.18924370
 (0.09055117) (0.02117350)


Also

>  fitdistr(otm, "gamma",control=list(parscale=c(.1,.1)))
     shape         rate
  1.03079500   0.18923897
 (0.09055106) (0.02117363)

and quite amusingly:


>  fitdistr(otm, "gamma",method="BFGS",lower=0)
     shape         rate
  1.03081096   0.18924371
 (0.09055118) (0.02117350)
Warning message:
bounds can only be used with method L-BFGS-B in: optim(x = c(0.059610966029577, 0.0591496321922168, 0.14, 0.18,
>  fitdistr(otm, "gamma",method="CG",lower=0)
     shape         rate
  1.03081096   0.18924371
 (0.09055118) (0.02117350)
Warning message:
bounds can only be used with method L-BFGS-B in: optim(x = c(0.059610966029577, 0.0591496321922168, 0.14, 0.18,

whereas the same calls without the dysfunctional lower= gives the
warning about `shape` needing to be positive.

This probably all indicates that something inside optim() is broken.


 
> I no longer have 2.1.0 running, so I don't know why this
> wasn't needed in 2.1.0.
> 
> "R version 2.2.0, 2005-10-24"
> MASS version: 7.2-20
> 
> -peter
> 
> Gorjanc Gregor wrote:
> > Dear R developers,
> > 
> > I have encountered strange behaviour of fitdistr for gamma in recent R
> > build i.e. 2.2.0. I have attached the code for data at the end of this mail
> > so you can reproduce the problem. In short, I am able to run fitdistr under
> > 2.1.0 without problems, while I get the following error under 2.2.0
> > (Version 2.2.0 Patched (2005-11-15 r36348))
> > 
> > 
> >>fitdistr(otm, "gamma")
> > 
> > Error in densfun(x, parm[1], parm[2], ...) : 
> >         'shape' must be strictly positive
> > 
> > The results on 2.1.1 (Version 2.1.1 (2005-06-20)) are
> > 
> > 
> >>fitdistr(otm, "gamma")
> > 
> >     shape       rate  
> >   1.030667   0.189177 
> >  (0.090537) (0.021166)
> > 
> > Platform: Windows XP
> > 
> > Thank you in advance for your effort on this remarkable tool!
> > 
> > Here is the data for above problem/results:
> > 
> > "otm" <-
> > c(0.059610966029577, 0.0591496321922168, 0.14, 0.18, 0.24, 0.25, 
> > 0.270071982912719, 0.270758049933706, 0.269911804412492, 0.280138451903593, 
> > 0.279787947586738, 0.279429937571753, 0.3, 0.320746235495899, 
> > 0.319553311037365, 0.51, 0.54, 0.56, 0.6, 0.609812622915953, 
> > 0.609198293855879, 0.64, 0.69, 0.74, 0.76, 0.770972826186568, 
> > 0.769288654833566, 0.78, 0.789181584270671, 0.78991363293305, 
> > 0.8, 0.89, 0.900691718998831, 0.8991656800583, 0.92, 0.93, 0.94, 
> > 1.01, 1.02, 1.13, 1.18, 1.26, 1.29, 1.33, 1.42, 1.43, 1.47, 1.47940529614314, 
> > 1.47920716832764, 1.6, 1.61, 1.63, 1.68938231960637, 1.6894849291523, 
> > 1.82, 1.88088044053270, 1.8792804789003, 1.89, 1.92, 2, 2.04, 
> > 2.07, 2.12, 2.17, 2.18, 2.22, 2.23, 2.27, 2.28, 2.3, 2.32092240267433, 
> > 2.31912300181622, 2.38, 2.39, 2.43, 2.46, 2.51, 2.52, 2.55, 2.56, 
> > 2.61, 2.66091404781397, 2.6595832825806, 2.67, 2.7, 2.77, 2.8, 
> > 2.81, 2.86, 2.87, 2.93, 3.01, 3.05, 3.14, 3.15, 3.17, 3.18, 3.24, 
> > 3.26, 3.33, 3.44, 3.45, 3.52, 3.55, 3.63, 3.73, 3.9, 4, 4.01, 
> > 4.04, 4.13, 4.15934497380769, 4.16094719917513, 4.3, 4.33, 4.34, 
> > 4.66, 4.76, 4.82, 4.83, 4.89, 4.92, 5.06, 5.14, 5.16, 5.26, 5.31, 
> > 5.36, 5.48, 5.66, 5.79, 5.8, 5.85, 5.87, 5.92952534468565, 5.92962284128508, 
> > 6.04, 6.11, 6.13, 6.16, 6.19, 6.42, 6.66, 6.69, 7.11, 7.16, 7.29, 
> > 7.3, 7.31, 7.33, 7.72, 7.82, 7.87, 7.91, 8.01, 8.17, 8.45, 8.49, 
> > 8.73, 8.86, 8.95, 9, 9.05, 9.13, 9.22, 9.52, 9.82, 9.88, 9.91, 
> > 9.99, 10.03, 10.4, 10.59, 10.83, 11.06, 11.64, 11.85, 12.02, 
> > 12.4, 12.64, 12.96, 13.44, 14.06, 14.07, 14.37, 15.4, 15.6, 15.92, 
> > 16.23, 16.6, 16.97, 17.06, 17.8, 18.69, 18.73, 19.2, 19.51, 19.54, 
> > 20.57, 21.05, 22.23, 27.02)
> > 
> > Lep pozdrav / With regards,
> >     Gregor Gorjanc
> > 
> > ----------------------------------------------------------------------
> > University of Ljubljana
> > Biotechnical Faculty        URI: http://www.bfro.uni-lj.si/MR/ggorjan
> > Zootechnical Department     mail: gregor.gorjanc <at> bfro.uni-lj.si
> > Groblje 3                   tel: +386 (0)1 72 17 861
> > SI-1230 Domzale             fax: +386 (0)1 72 17 888
> > Slovenia, Europe
> > ----------------------------------------------------------------------
> > "One must learn by doing the thing; for though you think you know it,
> >  you have no certainty until you try." Sophocles ~ 450 B.C.
> > 
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> Peter Ehlers
> University of Calgary
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From murdoch at stats.uwo.ca  Thu Nov 17 17:13:36 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 17 Nov 2005 11:13:36 -0500
Subject: [Rd] Scan data from a .txt file
In-Reply-To: <3b67376c0511170735m1c9120cfjee0b4d4fe59d2740@mail.gmail.com>
References: <3b67376c0511170735m1c9120cfjee0b4d4fe59d2740@mail.gmail.com>
Message-ID: <437CAC30.80709@stats.uwo.ca>

On 11/17/2005 10:35 AM, Vasundhara Akkineni wrote:
> Hi all,
> Am trying to read data from a .txt file in such a way that i can access the
> column names too. For example, the data in the table.txt file is as below:
>  Name Weight Height Gender
> Anne 150 65 F
> Rob 160 68 M
> George 180 65 M
> Greg 205 69 M
>  i used the following commands:
>  data<-scan("table.txt",list("",0,0,0),sep="")
> a<-data[[1]]
> b<-data[[2]]
> c<-data[[3]]
> d<-data[[4]]
>  But this doesn't work because of type mismatch. I want to pull the col
> names also into the respective lists. For example i want 'b' to have
> (weight,150,160,180,205) so that i can access the col name and also the
> induvidual weights. I tried using the read.table method too, but couldn't
> get this working. Can someone suggest a way to do this.

You probably want to use read.table("table.txt", head=TRUE).  Chances 
are it will automatically recognize the column types; if not, there's 
the colClasses argument.

Duncan Murdoch


From Cougar at psu.edu  Thu Nov 17 20:41:50 2005
From: Cougar at psu.edu (Cougar@psu.edu)
Date: Thu, 17 Nov 2005 20:41:50 +0100 (CET)
Subject: [Rd] Matrix (PR#8321)
Message-ID: <20051117194150.C7E871E091@slim.kubism.ku.dk>

It appears to me that the new version of the package Matrix will not load to
R-2.2.0.

Respectfully,

Frank Lawrence


From ehlers at math.ucalgary.ca  Thu Nov 17 22:14:38 2005
From: ehlers at math.ucalgary.ca (P Ehlers)
Date: Thu, 17 Nov 2005 14:14:38 -0700
Subject: [Rd] Problem with fitdistr for gamma in R 2.2.0
In-Reply-To: <x2br0jffpc.fsf@viggo.kubism.ku.dk>
References: <7FFEE688B57D7346BC6241C55900E730F31ABB@pollux.bfro.uni-lj.si>	<437C95EA.9050502@math.ucalgary.ca>
	<x2br0jffpc.fsf@viggo.kubism.ku.dk>
Message-ID: <437CF2BE.7000602@math.ucalgary.ca>

I think the problem may lie with fitdistr().
Specifically, replacing the code in fitdistr.R (VR_7.2-20)
(line 137 to end) with the code in VR_7.2-8 (line 92 to end)
seems to handle

   fitdistr(otm, "gamma")

just fine. But I haven't done much testing.

Peter Ehlers

Peter Dalgaard wrote:
> P Ehlers <ehlers at math.ucalgary.ca> writes:
> 
> 
>>Gregor,
>>
>>  fitdistr(otm, "gamma", method="L-BFGS-B")
>>
>>works for me (on WinXP). Or you could specify "lower = 0".
> 
> 
> The really odd thing is that it even works with
> 
> 
>> fitdistr(otm, "gamma",lower=-Inf)
> 
>      shape         rate
>   1.03081094   0.18924370
>  (0.09055117) (0.02117350)
> 
> or even
> 
> 
>> fitdistr(otm, "gamma",upper=Inf)
> 
>      shape         rate
>   1.03081094   0.18924370
>  (0.09055117) (0.02117350)
> 
> 
> Also
> 
> 
>> fitdistr(otm, "gamma",control=list(parscale=c(.1,.1)))
> 
>      shape         rate
>   1.03079500   0.18923897
>  (0.09055106) (0.02117363)
> 
> and quite amusingly:
> 
> 
> 
>> fitdistr(otm, "gamma",method="BFGS",lower=0)
> 
>      shape         rate
>   1.03081096   0.18924371
>  (0.09055118) (0.02117350)
> Warning message:
> bounds can only be used with method L-BFGS-B in: optim(x = c(0.059610966029577, 0.0591496321922168, 0.14, 0.18,
> 
>> fitdistr(otm, "gamma",method="CG",lower=0)
> 
>      shape         rate
>   1.03081096   0.18924371
>  (0.09055118) (0.02117350)
> Warning message:
> bounds can only be used with method L-BFGS-B in: optim(x = c(0.059610966029577, 0.0591496321922168, 0.14, 0.18,
> 
> whereas the same calls without the dysfunctional lower= gives the
> warning about `shape` needing to be positive.
> 
> This probably all indicates that something inside optim() is broken.
> 
> 
>  
> 
>>I no longer have 2.1.0 running, so I don't know why this
>>wasn't needed in 2.1.0.
>>
>>"R version 2.2.0, 2005-10-24"
>>MASS version: 7.2-20
>>
>>-peter
>>
>>Gorjanc Gregor wrote:
>>
>>>Dear R developers,
>>>
>>>I have encountered strange behaviour of fitdistr for gamma in recent R
>>>build i.e. 2.2.0. I have attached the code for data at the end of this mail
>>>so you can reproduce the problem. In short, I am able to run fitdistr under
>>>2.1.0 without problems, while I get the following error under 2.2.0
>>>(Version 2.2.0 Patched (2005-11-15 r36348))
>>>
>>>
>>>
>>>>fitdistr(otm, "gamma")
>>>
>>>Error in densfun(x, parm[1], parm[2], ...) : 
>>>        'shape' must be strictly positive
>>>
>>>The results on 2.1.1 (Version 2.1.1 (2005-06-20)) are
>>>
>>>
>>>
>>>>fitdistr(otm, "gamma")
>>>
>>>    shape       rate  
>>>  1.030667   0.189177 
>>> (0.090537) (0.021166)
>>>
>>>Platform: Windows XP
>>>
>>>Thank you in advance for your effort on this remarkable tool!
>>>
>>>Here is the data for above problem/results:
>>>
>>>"otm" <-
>>>c(0.059610966029577, 0.0591496321922168, 0.14, 0.18, 0.24, 0.25, 
>>>0.270071982912719, 0.270758049933706, 0.269911804412492, 0.280138451903593, 
>>>0.279787947586738, 0.279429937571753, 0.3, 0.320746235495899, 
>>>0.319553311037365, 0.51, 0.54, 0.56, 0.6, 0.609812622915953, 
>>>0.609198293855879, 0.64, 0.69, 0.74, 0.76, 0.770972826186568, 
>>>0.769288654833566, 0.78, 0.789181584270671, 0.78991363293305, 
>>>0.8, 0.89, 0.900691718998831, 0.8991656800583, 0.92, 0.93, 0.94, 
>>>1.01, 1.02, 1.13, 1.18, 1.26, 1.29, 1.33, 1.42, 1.43, 1.47, 1.47940529614314, 
>>>1.47920716832764, 1.6, 1.61, 1.63, 1.68938231960637, 1.6894849291523, 
>>>1.82, 1.88088044053270, 1.8792804789003, 1.89, 1.92, 2, 2.04, 
>>>2.07, 2.12, 2.17, 2.18, 2.22, 2.23, 2.27, 2.28, 2.3, 2.32092240267433, 
>>>2.31912300181622, 2.38, 2.39, 2.43, 2.46, 2.51, 2.52, 2.55, 2.56, 
>>>2.61, 2.66091404781397, 2.6595832825806, 2.67, 2.7, 2.77, 2.8, 
>>>2.81, 2.86, 2.87, 2.93, 3.01, 3.05, 3.14, 3.15, 3.17, 3.18, 3.24, 
>>>3.26, 3.33, 3.44, 3.45, 3.52, 3.55, 3.63, 3.73, 3.9, 4, 4.01, 
>>>4.04, 4.13, 4.15934497380769, 4.16094719917513, 4.3, 4.33, 4.34, 
>>>4.66, 4.76, 4.82, 4.83, 4.89, 4.92, 5.06, 5.14, 5.16, 5.26, 5.31, 
>>>5.36, 5.48, 5.66, 5.79, 5.8, 5.85, 5.87, 5.92952534468565, 5.92962284128508, 
>>>6.04, 6.11, 6.13, 6.16, 6.19, 6.42, 6.66, 6.69, 7.11, 7.16, 7.29, 
>>>7.3, 7.31, 7.33, 7.72, 7.82, 7.87, 7.91, 8.01, 8.17, 8.45, 8.49, 
>>>8.73, 8.86, 8.95, 9, 9.05, 9.13, 9.22, 9.52, 9.82, 9.88, 9.91, 
>>>9.99, 10.03, 10.4, 10.59, 10.83, 11.06, 11.64, 11.85, 12.02, 
>>>12.4, 12.64, 12.96, 13.44, 14.06, 14.07, 14.37, 15.4, 15.6, 15.92, 
>>>16.23, 16.6, 16.97, 17.06, 17.8, 18.69, 18.73, 19.2, 19.51, 19.54, 
>>>20.57, 21.05, 22.23, 27.02)
>>>
>>>Lep pozdrav / With regards,
>>>    Gregor Gorjanc
>>>
>>>----------------------------------------------------------------------
>>>University of Ljubljana
>>>Biotechnical Faculty        URI: http://www.bfro.uni-lj.si/MR/ggorjan
>>>Zootechnical Department     mail: gregor.gorjanc <at> bfro.uni-lj.si
>>>Groblje 3                   tel: +386 (0)1 72 17 861
>>>SI-1230 Domzale             fax: +386 (0)1 72 17 888
>>>Slovenia, Europe
>>>----------------------------------------------------------------------
>>>"One must learn by doing the thing; for though you think you know it,
>>> you have no certainty until you try." Sophocles ~ 450 B.C.
>>>
>>>______________________________________________
>>>R-devel at r-project.org mailing list
>>>https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>Peter Ehlers
>>University of Calgary
>>
>>______________________________________________
>>R-devel at r-project.org mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-devel
>>
> 
> 

-- 
Peter Ehlers
Department of Mathematics and Statistics
University of Calgary, 2500 University Dr. NW


From ehlers at math.ucalgary.ca  Thu Nov 17 22:53:06 2005
From: ehlers at math.ucalgary.ca (P Ehlers)
Date: Thu, 17 Nov 2005 14:53:06 -0700
Subject: [Rd] Matrix (PR#8321)
In-Reply-To: <20051117194150.C7E871E091@slim.kubism.ku.dk>
References: <20051117194150.C7E871E091@slim.kubism.ku.dk>
Message-ID: <437CFBC2.3010901@math.ucalgary.ca>

Assuming you're on Windows (you didn't say), it looks
like the PACKAGES file in /.../contrib/2.2/ has two
entries for Matrix. Perhaps that's the problem.

Peter


Cougar at psu.edu wrote:

> It appears to me that the new version of the package Matrix will not load to
> R-2.2.0.
> 
> Respectfully,
> 
> Frank Lawrence
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Peter Ehlers
Department of Mathematics and Statistics
University of Calgary, 2500 University Dr. NW
Calgary, Alberta  T2N 1N4, CANADA


From ross at biostat.ucsf.edu  Thu Nov 17 22:55:58 2005
From: ross at biostat.ucsf.edu (ross@biostat.ucsf.edu)
Date: Thu, 17 Nov 2005 22:55:58 +0100 (CET)
Subject: [Rd] problem with \eqn (PR#8322)
Message-ID: <20051117215558.33EB422485@slim.kubism.ku.dk>

Full_Name: Ross Boylan
Version: 2.2.0
OS: Linux
Submission from: (NULL) (65.175.48.58)


  \eqn{{\bf\beta}_j}{b(j)} in my .Rd file produces this error
--------------------------------------------
! Missing $ inserted.
<inserted text> 
                $
l.7 \eqn{{\bf\beta}_j}{\bf\beta}_
                                 jnormal-bracket5bracket-normal{b(j)}
--
! Missing $ inserted.
<inserted text> 
                $
l.16 
     
--
! Missing } inserted.
<inserted text> 
                }
l.16 
     
--
! Extra }, or forgotten \endgroup.
\par ...m \@noitemerr {\@@par }\fi \else {\@@par }
                                                  \fi 
l.16 
-------------------------------
I think this is a bug.  A query to r-help has produced no response.

Note that \bf\beta seems to have been doubled.

Currently on R 2.2.0.final-4 on Debian.  I think I've seen this with
many prior versions too.


From Cougar_711 at msn.com  Fri Nov 18 00:10:48 2005
From: Cougar_711 at msn.com (Cougar Lawrence)
Date: Thu, 17 Nov 2005 18:10:48 -0500
Subject: [Rd] Matrix (PR#8321)
In-Reply-To: <437CFBC2.3010901@math.ucalgary.ca>
Message-ID: <004601c5ebcc$29409040$641a7680@hhdev.psu.edu>

Thanks for the reply.  I am using windows.  I tried both packages.  The
directions under Matrix indicate that package 99.2 is current.  It is the
one that will not load.

Respectfully,
 
Frank Lawrence


-----Original Message-----
From: P Ehlers [mailto:ehlers at math.ucalgary.ca] 
Sent: Thursday, November 17, 2005 16:53
To: Cougar at psu.edu
Cc: r-devel at stat.math.ethz.ch; R-bugs at biostat.ku.dk
Subject: Re: [Rd] Matrix (PR#8321)


Assuming you're on Windows (you didn't say), it looks
like the PACKAGES file in /.../contrib/2.2/ has two
entries for Matrix. Perhaps that's the problem.

Peter


Cougar at psu.edu wrote:

> It appears to me that the new version of the package Matrix will not 
> load to R-2.2.0.
> 
> Respectfully,
> 
> Frank Lawrence
> 
> ______________________________________________
> R-devel at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Peter Ehlers
Department of Mathematics and Statistics
University of Calgary, 2500 University Dr. NW
Calgary, Alberta  T2N 1N4, CANADA


From ehlers at math.ucalgary.ca  Fri Nov 18 02:38:45 2005
From: ehlers at math.ucalgary.ca (P Ehlers)
Date: Thu, 17 Nov 2005 18:38:45 -0700
Subject: [Rd] Matrix (PR#8321)
In-Reply-To: <004601c5ebcc$29409040$641a7680@hhdev.psu.edu>
References: <004601c5ebcc$29409040$641a7680@hhdev.psu.edu>
Message-ID: <437D30A5.2000101@math.ucalgary.ca>

Actually, my guess about PACKAGES was wrong. I just removed Matrix
and re-installed Matrix_0.99-2 (Rgui: Packages menu) from CRAN and
had no problems.

You'll have to be more explicit about "will not load".

Peter


Cougar Lawrence wrote:

> Thanks for the reply.  I am using windows.  I tried both packages.  The
> directions under Matrix indicate that package 99.2 is current.  It is the
> one that will not load.
> 
> Respectfully,
>  
> Frank Lawrence
> 
> 
> -----Original Message-----
> From: P Ehlers [mailto:ehlers at math.ucalgary.ca] 
> Sent: Thursday, November 17, 2005 16:53
> To: Cougar at psu.edu
> Cc: r-devel at stat.math.ethz.ch; R-bugs at biostat.ku.dk
> Subject: Re: [Rd] Matrix (PR#8321)
> 
> 
> Assuming you're on Windows (you didn't say), it looks
> like the PACKAGES file in /.../contrib/2.2/ has two
> entries for Matrix. Perhaps that's the problem.
> 
> Peter
> 
> 
> Cougar at psu.edu wrote:
> 
> 
>>It appears to me that the new version of the package Matrix will not 
>>load to R-2.2.0.
>>
>>Respectfully,
>>
>>Frank Lawrence
>>
>>______________________________________________
>>R-devel at r-project.org mailing list 
>>https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 

-- 
Peter Ehlers
Department of Mathematics and Statistics
University of Calgary, 2500 University Dr. NW


From pdbailey at uchicago.edu  Fri Nov 18 04:23:15 2005
From: pdbailey at uchicago.edu (pdbailey@uchicago.edu)
Date: Fri, 18 Nov 2005 04:23:15 +0100 (CET)
Subject: [Rd] PR#8282
Message-ID: <20051118032315.B22F58599@slim.kubism.ku.dk>

When an attempt was made to reproduce this on other platforms,
how high was the index? For one of my Apples, I need to take
it very high, maybe 1000000? Sorry, I guess I edited that part
out.

--
zi <- vector()
for(i in 1:1000000) {
  zi[i] <- c(1,2)
}
zi[,1]
--


From berwin at maths.uwa.edu.au  Fri Nov 18 04:29:09 2005
From: berwin at maths.uwa.edu.au (Berwin A Turlach)
Date: Fri, 18 Nov 2005 11:29:09 +0800
Subject: [Rd] R-exts.texi in SVN version 36380
Message-ID: <17277.19077.463979.101648@bossiaea.maths.uwa.edu.au>

G'day all,

after issuing `svn up' on my machine this morning, I noticed that
`make info' choked on R-exts.texi.  Below is a patch that seems to
solve the problem.  BTW, while `make info' runs now, I still get the
following warning:

/usr/bin/makeinfo --enable-encoding -D UseExternalXrefs -I/opt/src/R-devel-src/doc/manual /opt/src/R-devel-src/doc/manual/R-exts.texi
/opt/src/R-devel-src/doc/manual/R-exts.texi:1219: warning: @strong{Note...} produces a spurious cross-reference in Info; reword to avoid that.

No idea how to fix that, my texinfo knowledge is not good enough. :)

Actually, I am not clear on the following two questions:
1) Should such patches be sent to r-devel, r-bugs or both?
2) Should such patches be sent at all, or should users just wait till
   R-core fixes it itself?

Cheers,

        Berwin


-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: R-patch
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20051118/07f5858d/R-patch.pl

From gregor.gorjanc at bfro.uni-lj.si  Fri Nov 18 08:18:58 2005
From: gregor.gorjanc at bfro.uni-lj.si (Gregor Gorjanc)
Date: Fri, 18 Nov 2005 08:18:58 +0100
Subject: [Rd] Problem with fitdistr for gamma in R 2.2.0
In-Reply-To: <437CF2BE.7000602@math.ucalgary.ca>
References: <7FFEE688B57D7346BC6241C55900E730F31ABB@pollux.bfro.uni-lj.si>	<437C95EA.9050502@math.ucalgary.ca>
	<x2br0jffpc.fsf@viggo.kubism.ku.dk>
	<437CF2BE.7000602@math.ucalgary.ca>
Message-ID: <437D8062.2040801@bfro.uni-lj.si>

Thanks to both Peters for involvment. I will add argument for method to
be used in optim.

-- 
Lep pozdrav / With regards,
    Gregor Gorjanc

----------------------------------------------------------------------
University of Ljubljana     PhD student
Biotechnical Faculty
Zootechnical Department     URI: http://www.bfro.uni-lj.si/MR/ggorjan
Groblje 3                   mail: gregor.gorjanc <at> bfro.uni-lj.si

SI-1230 Domzale             tel: +386 (0)1 72 17 861
Slovenia, Europe            fax: +386 (0)1 72 17 888

----------------------------------------------------------------------
"One must learn by doing the thing; for though you think you know it,
 you have no certainty until you try." Sophocles ~ 450 B.C.


From ripley at stats.ox.ac.uk  Fri Nov 18 08:46:14 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 18 Nov 2005 07:46:14 +0000 (GMT)
Subject: [Rd] R-exts.texi in SVN version 36380
In-Reply-To: <17277.19077.463979.101648@bossiaea.maths.uwa.edu.au>
References: <17277.19077.463979.101648@bossiaea.maths.uwa.edu.au>
Message-ID: <Pine.LNX.4.61.0511180731490.9545@gannet.stats>

On Fri, 18 Nov 2005, Berwin A Turlach wrote:

> G'day all,
>
> after issuing `svn up' on my machine this morning, I noticed that
> `make info' choked on R-exts.texi.

Actually 'make' chokes.

> Below is a patch that seems to
> solve the problem.  BTW, while `make info' runs now, I still get the
> following warning:
>
> /usr/bin/makeinfo --enable-encoding -D UseExternalXrefs -I/opt/src/R-devel-src/doc/manual /opt/src/R-devel-src/doc/manual/R-exts.texi
> /opt/src/R-devel-src/doc/manual/R-exts.texi:1219: warning: @strong{Note...} produces a spurious cross-reference in Info; reword to avoid that.

Thank you for the report.  The last warning is long-standing and has been 
not thought worth fixing as very few (if any) Windows users use info.
The fix is simple though

@quotation Note to Windows users
@code{R CMD check} and @code{R CMD build} work well under Windows
....


> No idea how to fix that, my texinfo knowledge is not good enough. :)
>
> Actually, I am not clear on the following two questions:
> 1) Should such patches be sent to r-devel, r-bugs or both?
> 2) Should such patches be sent at all, or should users just wait till
>   R-core fixes it itself?

If they are this obvious you can just do nothing if you prefer.  We do 
expect people to run 'make all check' before committing and deal with any 
new warnings/errors, and when (as here) people omit to do so it gets 
spotted and fixed within hours.

There were other markup problems, e.g. we use @R{} for R.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Fri Nov 18 08:56:23 2005
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Fri, 18 Nov 2005 08:56:23 +0100 (CET)
Subject: [Rd] PR#8282
Message-ID: <20051118075623.560A21E024@slim.kubism.ku.dk>

The attempt made was to reproduce exactly the example you reported (of 
course).

Notice that this is incorrect usage, as you are trying to replace one 
element by 2.  We have since found another example of this, and fixed it, 
but it is nothing new in 2.2.0.  Please try a current version of R 
(R-patched or R-devel).  The relevant NEWS item is

     o	Subassignment of a vector which increased the length of the
 	vector _and_ had the wrong length of replacement could
 	occasionally segfault.  (This has been there since at least
 	mid 1997.)

It is poor practice to increase the size of a vector in this way rather
than pre-allocate.  Perhaps it has persisted so long because it is a user 
error in poor practice that can need 1000000 repeats to reproduce.


On Fri, 18 Nov 2005 pdbailey at uchicago.edu wrote:

> When an attempt was made to reproduce this on other platforms,
> how high was the index? For one of my Apples, I need to take
> it very high, maybe 1000000? Sorry, I guess I edited that part
> out.
>
> --
> zi <- vector()
> for(i in 1:1000000) {
>  zi[i] <- c(1,2)
> }
> zi[,1]
> --
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ligges at statistik.uni-dortmund.de  Fri Nov 18 10:10:04 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 18 Nov 2005 10:10:04 +0100
Subject: [Rd] Matrix (PR#8321)
In-Reply-To: <437D30A5.2000101@math.ucalgary.ca>
References: <004601c5ebcc$29409040$641a7680@hhdev.psu.edu>
	<437D30A5.2000101@math.ucalgary.ca>
Message-ID: <437D9A6C.5050201@statistik.uni-dortmund.de>

P Ehlers wrote:

> Actually, my guess about PACKAGES was wrong. I just removed Matrix
> and re-installed Matrix_0.99-2 (Rgui: Packages menu) from CRAN and
> had no problems.


The outdated Matrix version will disappear from CRAN master within 24 
hours. Two versions in the repository do not cause any problems.

I think Cougar Lawrence has to tell us what "do not load" means, i.e. 
his setup of packages and libraries, his call to load Matrix as well as 
the error message.

Uwe Ligges




> You'll have to be more explicit about "will not load".
> 
> Peter
> 
> 
> Cougar Lawrence wrote:
> 
> 
>>Thanks for the reply.  I am using windows.  I tried both packages.  The
>>directions under Matrix indicate that package 99.2 is current.  It is the
>>one that will not load.
>>
>>Respectfully,
>> 
>>Frank Lawrence
>>
>>
>>-----Original Message-----
>>From: P Ehlers [mailto:ehlers at math.ucalgary.ca] 
>>Sent: Thursday, November 17, 2005 16:53
>>To: Cougar at psu.edu
>>Cc: r-devel at stat.math.ethz.ch; R-bugs at biostat.ku.dk
>>Subject: Re: [Rd] Matrix (PR#8321)
>>
>>
>>Assuming you're on Windows (you didn't say), it looks
>>like the PACKAGES file in /.../contrib/2.2/ has two
>>entries for Matrix. Perhaps that's the problem.
>>
>>Peter
>>
>>
>>Cougar at psu.edu wrote:
>>
>>
>>
>>>It appears to me that the new version of the package Matrix will not 
>>>load to R-2.2.0.
>>>
>>>Respectfully,
>>>
>>>Frank Lawrence
>>>
>>>______________________________________________
>>>R-devel at r-project.org mailing list 
>>>https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>


From bhx5 at mevik.net  Fri Nov 18 13:04:39 2005
From: bhx5 at mevik.net (bhx5@mevik.net)
Date: Fri, 18 Nov 2005 13:04:39 +0100 (CET)
Subject: [Rd] pr[in]comp: predict single observation when data has colnames
	(PR#8324)
Message-ID: <20051118120439.D8D8F22424@slim.kubism.ku.dk>

To my knowledge, this has not been reported previously, and doesn't
seem to have been changed in R-devel or R-patched.

If M is a matrix with coloumn names, and

mod <- prcomp(M)  # or princomp

then predicting a single observation (row) with predict() gives the
error

Error in scale.default(newdata, object$center, object$scale) : 
	length of 'center' must equal the number of columns of 'x'

This doesn't happen if M doesn't have coloumn names.

For instance:

> M <- matrix(rnorm(30), ncol = 3)
> mod <- prcomp(M[-1,])
> predict(mod, newdata = M[1,, drop = FALSE])
           PC1       PC2       PC3
[1,] -1.666191 -2.333012 -1.424587

> colnames(M) <- 1:3
> mod <- prcomp(M[-1,])
> predict(mod, newdata = M[1,, drop = FALSE])
Error in scale.default(newdata, object$center, object$scale) : 
	length of 'center' must equal the number of columns of 'x'


I believe the problem is the line

        newdata <- newdata[, nm]

in predict.prcomp (line 106 of prcomp.R) and predict.princomp (line 11
of princomp-add.R), which should probably be

        newdata <- newdata[, nm, drop = FALSE]



Version:
 platform = x86_64-unknown-linux-gnu
 arch = x86_64
 os = linux-gnu
 system = x86_64, linux-gnu
 status = 
 major = 2
 minor = 2.0
 year = 2005
 month = 10
 day = 06
 svn rev = 35749
 language = R

Locale:
LC_CTYPE=no_NO.UTF-8;LC_NUMERIC=C;LC_TIME=no_NO.UTF-8;LC_COLLATE=no_NO.UTF-8;LC_MONETARY=no_NO.UTF-8;LC_MESSAGES=no_NO.UTF-8;LC_PAPER=C;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=C;LC_IDENTIFICATION=C

Search Path:
 .GlobalEnv, package:methods, package:stats, package:graphics, package:grDevices, package:utils, package:datasets, Autoloads, package:base

-- 
Bj?rn-Helge Mevik


From murdoch at stats.uwo.ca  Fri Nov 18 15:02:10 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri, 18 Nov 2005 09:02:10 -0500
Subject: [Rd] pr[in]comp: predict single observation when data has
 colnames (PR#8324)
In-Reply-To: <20051118120439.D8D8F22424@slim.kubism.ku.dk>
References: <20051118120439.D8D8F22424@slim.kubism.ku.dk>
Message-ID: <437DDEE2.2010900@stats.uwo.ca>

On 11/18/2005 7:04 AM, bhx5 at mevik.net wrote:
> To my knowledge, this has not been reported previously, and doesn't
> seem to have been changed in R-devel or R-patched.
> 
> If M is a matrix with coloumn names, and
> 
> mod <- prcomp(M)  # or princomp
> 
> then predicting a single observation (row) with predict() gives the
> error
> 
> Error in scale.default(newdata, object$center, object$scale) : 
> 	length of 'center' must equal the number of columns of 'x'
> 
> This doesn't happen if M doesn't have coloumn names.
> 
> For instance:
> 
> 
>>M <- matrix(rnorm(30), ncol = 3)
>>mod <- prcomp(M[-1,])
>>predict(mod, newdata = M[1,, drop = FALSE])
> 
>            PC1       PC2       PC3
> [1,] -1.666191 -2.333012 -1.424587
> 
> 
>>colnames(M) <- 1:3
>>mod <- prcomp(M[-1,])
>>predict(mod, newdata = M[1,, drop = FALSE])
> 
> Error in scale.default(newdata, object$center, object$scale) : 
> 	length of 'center' must equal the number of columns of 'x'
> 
> 
> I believe the problem is the line
> 
>         newdata <- newdata[, nm]
> 
> in predict.prcomp (line 106 of prcomp.R) and predict.princomp (line 11
> of princomp-add.R), which should probably be
> 
>         newdata <- newdata[, nm, drop = FALSE]
> 

Yes, I see the problem, and I agree with your correction.  I'll commit a 
patch.  Thanks!

Duncan Murdoch


From murdoch at stats.uwo.ca  Fri Nov 18 15:02:28 2005
From: murdoch at stats.uwo.ca (murdoch@stats.uwo.ca)
Date: Fri, 18 Nov 2005 15:02:28 +0100 (CET)
Subject: [Rd] pr[in]comp: predict single observation when data has
	colnames (PR#8325)
Message-ID: <20051118140228.0353E1DFD0@slim.kubism.ku.dk>

On 11/18/2005 7:04 AM, bhx5 at mevik.net wrote:
> To my knowledge, this has not been reported previously, and doesn't
> seem to have been changed in R-devel or R-patched.
> 
> If M is a matrix with coloumn names, and
> 
> mod <- prcomp(M)  # or princomp
> 
> then predicting a single observation (row) with predict() gives the
> error
> 
> Error in scale.default(newdata, object$center, object$scale) : 
> 	length of 'center' must equal the number of columns of 'x'
> 
> This doesn't happen if M doesn't have coloumn names.
> 
> For instance:
> 
> 
>>M <- matrix(rnorm(30), ncol = 3)
>>mod <- prcomp(M[-1,])
>>predict(mod, newdata = M[1,, drop = FALSE])
> 
>            PC1       PC2       PC3
> [1,] -1.666191 -2.333012 -1.424587
> 
> 
>>colnames(M) <- 1:3
>>mod <- prcomp(M[-1,])
>>predict(mod, newdata = M[1,, drop = FALSE])
> 
> Error in scale.default(newdata, object$center, object$scale) : 
> 	length of 'center' must equal the number of columns of 'x'
> 
> 
> I believe the problem is the line
> 
>         newdata <- newdata[, nm]
> 
> in predict.prcomp (line 106 of prcomp.R) and predict.princomp (line 11
> of princomp-add.R), which should probably be
> 
>         newdata <- newdata[, nm, drop = FALSE]
> 

Yes, I see the problem, and I agree with your correction.  I'll commit a 
patch.  Thanks!

Duncan Murdoch


From vasu.akkineni at gmail.com  Fri Nov 18 16:22:32 2005
From: vasu.akkineni at gmail.com (Vasundhara Akkineni)
Date: Fri, 18 Nov 2005 10:22:32 -0500
Subject: [Rd] Image display in R
In-Reply-To: <3b67376c0511180646y7ea4985bo9292b74d40e242c1@mail.gmail.com>
References: <3b67376c0511180646y7ea4985bo9292b74d40e242c1@mail.gmail.com>
Message-ID: <3b67376c0511180722s527aa6ao94079aa978af9013@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20051118/c4837299/attachment.pl

From murdoch at stats.uwo.ca  Fri Nov 18 16:35:31 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri, 18 Nov 2005 10:35:31 -0500
Subject: [Rd] Image display in R
In-Reply-To: <3b67376c0511180722s527aa6ao94079aa978af9013@mail.gmail.com>
References: <3b67376c0511180646y7ea4985bo9292b74d40e242c1@mail.gmail.com>
	<3b67376c0511180722s527aa6ao94079aa978af9013@mail.gmail.com>
Message-ID: <437DF4C3.70705@stats.uwo.ca>

On 11/18/2005 10:22 AM, Vasundhara Akkineni wrote:
> Hi all,
>  I am trying to display a matrix of plots(images), for example a 3*3 matrix
> of 9 image plots, such that when a user clicks on a image i can show the
> enlarged plot. I tried the multiple graphic device(using mfcol=c(3,3) and
> mfg), but it creates multiple plots in a single image file. So, i won't be
> able to highlight a particular plot when the user clicks on it.
>  To be more clear, can i display images in the form of a matrix in R. Are
> there any grids available? Please let me know.

I don't see why you think par(mfcol=c(3,3)) isn't working.  If you want 
your plots all in one device, that's one way to do it.  (There are 
others, but I don't know what you dislike about this one, so I don't 
know which ones would be any better.)

About a month ago I posted code to use locator() to determine which cell 
someone clicked on.  You can see that code here: 
<http://tolstoy.newcastle.edu.au/~rking/R/help/05/10/14322.html>.

Duncan Murdoch


From hin-tak.leung at cimr.cam.ac.uk  Fri Nov 18 17:38:28 2005
From: hin-tak.leung at cimr.cam.ac.uk (Hin-Tak Leung)
Date: Fri, 18 Nov 2005 16:38:28 +0000
Subject: [Rd] problem with \eqn (PR#8322)
In-Reply-To: <20051117215558.33EB422485@slim.kubism.ku.dk>
References: <20051117215558.33EB422485@slim.kubism.ku.dk>
Message-ID: <437E0384.604@cimr.cam.ac.uk>

Your own fault. See below. It is basic LaTeX and any LaTeX person
can tell you the answer...(most probably haven't bothered...)

ross at biostat.ucsf.edu wrote:
> Full_Name: Ross Boylan
> Version: 2.2.0
> OS: Linux
> Submission from: (NULL) (65.175.48.58)
> 
> 
>   \eqn{{\bf\beta}_j}{b(j)} in my .Rd file produces this error


> --------------------------------------------
> ! Missing $ inserted.
> <inserted text> 
>                 $
> l.7 \eqn{{\bf\beta}_j}{\bf\beta}_
>                                  jnormal-bracket5bracket-normal{b(j)}

\eqn{{\bf\beta}_j} is already syntactically complete, so latex
complains the next "_" is not in maths mode, and automatically
switch into maths mode for you (the $ inserted message) You have
to match all the braces - you need 3 right-braces after \eqn,
like this, at least:

\eqn{  {  {\bf\beta
           }_j
        }
        {\bf\beta
        }_ ....
        {b(j)
        }
     }


From buser at stat.math.ethz.ch  Fri Nov 18 17:38:22 2005
From: buser at stat.math.ethz.ch (Christoph Buser)
Date: Fri, 18 Nov 2005 17:38:22 +0100
Subject: [Rd] using a factor as col argument in plot:
Message-ID: <17278.894.547650.661337@stat.math.ethz.ch>

Dear R core team

Using the following code produces an empty plot (similar 
to col = NA): 

> plot(1:9, col = factor(rep(1:3,3), labels = c("red", "blue", "black")))


My question: Shouldn't one get at least a warning (or an error)
	     if one tries to use a factor as col argument?

Thanks for an answer.

Regards,

Christoph Buser

--------------------------------------------------------------
Christoph Buser <buser at stat.math.ethz.ch>
Seminar fuer Statistik, LEO C13
ETH (Federal Inst. Technology)	8092 Zurich	 SWITZERLAND
phone: x-41-44-632-4673		fax: 632-1228
http://stat.ethz.ch/~buser/


From ripley at stats.ox.ac.uk  Fri Nov 18 18:08:35 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 18 Nov 2005 17:08:35 +0000 (GMT)
Subject: [Rd] using a factor as col argument in plot:
In-Reply-To: <17278.894.547650.661337@stat.math.ethz.ch>
References: <17278.894.547650.661337@stat.math.ethz.ch>
Message-ID: <Pine.LNX.4.61.0511181703030.7151@gannet.stats>

On Fri, 18 Nov 2005, Christoph Buser wrote:

> Dear R core team

and R-devel-listers.

> Using the following code produces an empty plot (similar
> to col = NA):
>
>> plot(1:9, col = factor(rep(1:3,3), labels = c("red", "blue", "black")))
>
>
> My question: Shouldn't one get at least a warning (or an error)
> 	     if one tries to use a factor as col argument?
>
> Thanks for an answer.

I can read that two ways

1) No, it should not give a warning, as it is programmed to take all
invalid values as 0.

2) Is the way it is programmed sensible (yes) or desirable (no)?

The actual code is

/* Convert a sexp element to an R  color desc */
/* We Assume that Checks Have Been Done */

unsigned int RGBpar(SEXP x, int i)
{
     int indx;
     if(isString(x)) {
 	return str2col(CHAR(STRING_ELT(x, i)));
     }
     else if(isInteger(x) || isLogical(x)) {
 	if(INTEGER(x)[i] == NA_INTEGER)
 	    /*
 	     * Paul 01/07/04
 	     * Used to be set to NA_INTEGER (see comment in name2col).
 	     */
 	    return R_TRANWHITE;
 	indx = INTEGER(x)[i] - 1;
 	if(indx < 0) return Rf_dpptr(CurrentDevice())->bg;
 	else return R_ColorTable[indx % R_ColorTableSize];
     }
     else if(isReal(x)) {
 	if(!R_FINITE(REAL(x)[i]))
 	    /*
 	     * Paul 01/07/04
 	     * Used to be set to NA_INTEGER (see comment in name2col).
 	     */
 	    return R_TRANWHITE;
 	indx = REAL(x)[i] - 1;
 	if(indx < 0) return Rf_dpptr(CurrentDevice())->bg;
 	else return R_ColorTable[indx % R_ColorTableSize];
     }
     return 0;		/* should not occur */
}

but I could see no checks of type in any of the calling functions. Adding 
a warning would be a good idea.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From maechler at stat.math.ethz.ch  Fri Nov 18 18:22:25 2005
From: maechler at stat.math.ethz.ch (maechler@stat.math.ethz.ch)
Date: Fri, 18 Nov 2005 18:22:25 +0100 (CET)
Subject: [Rd] problem with \eqn (PR#8322)
Message-ID: <20051118172225.0A9F01DFD0@slim.kubism.ku.dk>

>>>>> "Hin-Tak" == Hin-Tak Leung <hin-tak.leung at cimr.cam.ac.uk>
>>>>>     on Fri, 18 Nov 2005 16:38:28 +0000 writes:

    Hin-Tak> Your own fault. See below. It is basic LaTeX and any LaTeX person
    Hin-Tak> can tell you the answer...(most probably haven't bothered...)

No.  Whereas I partly agree that it's Ross ``fault'' trying to
use too smart LaTex (and using outdated \bf instead of \mathbf), 
;-)

The bug is really there, since we are talking about the Rd "language",
not LaTeX, an in Rd,  \eqn and \deqn are defined to have either
one or two arguments -- where Ross used the 2-argument version
correctly (in principle at least) --> See the manual "Writing R
Extensions".


    >> Full_Name: Ross Boylan
    >> Version: 2.2.0
    >> OS: Linux
    >> Submission from: (NULL) (65.175.48.58)
    >> 
    >> 
    >> \eqn{{\bf\beta}_j}{b(j)} in my .Rd file produces this error

    >> --------------------------------------------
    >> ! Missing $ inserted.
    >> <inserted text> 
    >> $
    >> l.7 \eqn{{\bf\beta}_j}{\bf\beta}_jnormal-bracket5bracket-normal{b(j)}

    Hin-Tak> \eqn{{\bf\beta}_j} is already syntactically complete, so latex
    Hin-Tak> complains the next "_" is not in maths mode, and automatically
    Hin-Tak> switch into maths mode for you (the $ inserted message) You have
    Hin-Tak> to match all the braces - you need 3 right-braces after \eqn,
    Hin-Tak> like this, at least:

    Hin-Tak> \eqn{  {  {\bf\beta
    Hin-Tak> }_j
    Hin-Tak> }
    Hin-Tak> {\bf\beta
    Hin-Tak> }_ ....
    Hin-Tak> {b(j)
    Hin-Tak> }
    Hin-Tak> }


From ross at biostat.ucsf.edu  Fri Nov 18 18:32:54 2005
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Fri, 18 Nov 2005 09:32:54 -0800
Subject: [Rd] problem with \eqn (PR#8322)
In-Reply-To: <437E0384.604@cimr.cam.ac.uk>
References: <20051117215558.33EB422485@slim.kubism.ku.dk>
	<437E0384.604@cimr.cam.ac.uk>
Message-ID: <20051118173254.GU17336@wheat.betterworld.us>

I put a response into the bug tracker, but I don't think it took.  So
I'm sending this; apologies if it's a duplicate.

On Fri, Nov 18, 2005 at 04:38:28PM +0000, Hin-Tak Leung wrote:
> Your own fault. 

Not on the evidence you presented.  line 1.7 below is in error, but
that's not my input.  My input was 
\eqn{{\bf\beta}_j}{b(j)}

The process of reading the .Rd file and generating the file for LaTeX
to process somehow doubles the initial LaTeX part, which is
{{\bf\beta}_j}  (and the ascii part is {b(j)}).

I suspect that the nested {} is causing trouble.

>See below. It is basic LaTeX and any LaTeX person
> can tell you the answer...(most probably haven't bothered...)
> 
> ross at biostat.ucsf.edu wrote:
> >Full_Name: Ross Boylan
> >Version: 2.2.0
> >OS: Linux
> >Submission from: (NULL) (65.175.48.58)
> >
> >
> >  \eqn{{\bf\beta}_j}{b(j)} in my .Rd file produces this error
> 
> 
> >--------------------------------------------
> >! Missing $ inserted.
> ><inserted text> 
> >                $
> >l.7 \eqn{{\bf\beta}_j}{\bf\beta}_
> >                                 jnormal-bracket5bracket-normal{b(j)}
> 
> \eqn{{\bf\beta}_j} is already syntactically complete, so latex
> complains the next "_" is not in maths mode, and automatically
> switch into maths mode for you (the $ inserted message) You have
> to match all the braces - you need 3 right-braces after \eqn,
> like this, at least:
> 
> \eqn{  {  {\bf\beta
>           }_j
>        }
>        {\bf\beta
>        }_ ....
>        {b(j)
>        }
>     }
> 
The nesting of braces above seems to have only the LaTeX part, i.e, at
top level it is \eqn{} not \eqn{}{}.  My intent was the latter.


From hin-tak.leung at cimr.cam.ac.uk  Fri Nov 18 18:40:07 2005
From: hin-tak.leung at cimr.cam.ac.uk (Hin-Tak Leung)
Date: Fri, 18 Nov 2005 17:40:07 +0000
Subject: [Rd] problem with \eqn (PR#8322)
In-Reply-To: <17278.3526.762256.703178@stat.math.ethz.ch>
References: <20051117215558.33EB422485@slim.kubism.ku.dk>	<437E0384.604@cimr.cam.ac.uk>
	<17278.3526.762256.703178@stat.math.ethz.ch>
Message-ID: <437E11F7.6010604@cimr.cam.ac.uk>

Martin Maechler wrote:
>>>>>>"Hin-Tak" == Hin-Tak Leung <hin-tak.leung at cimr.cam.ac.uk>
>>>>>>    on Fri, 18 Nov 2005 16:38:28 +0000 writes:
> 
> 
>     Hin-Tak> Your own fault. See below. It is basic LaTeX and any LaTeX person
>     Hin-Tak> can tell you the answer...(most probably haven't bothered...)
> 
> No.  Whereas I partly agree that it's Ross ``fault'' trying to
> use too smart LaTex (and using outdated \bf instead of \mathbf), 
> ;-)
> 
> The bug is really there, since we are talking about the Rd "language",
> not LaTeX, an in Rd,  \eqn and \deqn are defined to have either
> one or two arguments -- where Ross used the 2-argument version
> correctly (in principle at least) --> See the manual "Writing R
> Extensions".

Forgive me for not reading R-ext carefully, but Ross's Rd code is
still "obviously" wrong in the lights of the two-argument \eqn:
(really doesn't differ from the 1-arg interpretaion of \eqn)

\eqn{{\bf\beta}_j}{\bf\beta}_jnormal-bracket5bracket-normal{b(j)}

In other words,
\eqn{...}{...}_...

and the "_" is still outside of any maths environment, which is most
probably not Ross's intention.

> 
> 
>     >> Full_Name: Ross Boylan
>     >> Version: 2.2.0
>     >> OS: Linux
>     >> Submission from: (NULL) (65.175.48.58)
>     >> 
>     >> 
>     >> \eqn{{\bf\beta}_j}{b(j)} in my .Rd file produces this error
> 
>     >> --------------------------------------------
>     >> ! Missing $ inserted.
>     >> <inserted text> 
>     >> $
>     >> l.7 \eqn{{\bf\beta}_j}{\bf\beta}_jnormal-bracket5bracket-normal{b(j)}
> 
>     Hin-Tak> \eqn{{\bf\beta}_j} is already syntactically complete, so latex
>     Hin-Tak> complains the next "_" is not in maths mode, and automatically
>     Hin-Tak> switch into maths mode for you (the $ inserted message) You have
>     Hin-Tak> to match all the braces - you need 3 right-braces after \eqn,
>     Hin-Tak> like this, at least:
> 
>     Hin-Tak> \eqn{  {  {\bf\beta
>     Hin-Tak> }_j
>     Hin-Tak> }
>     Hin-Tak> {\bf\beta
>     Hin-Tak> }_ ....
>     Hin-Tak> {b(j)
>     Hin-Tak> }
>     Hin-Tak> }


From hin-tak.leung at cimr.cam.ac.uk  Fri Nov 18 18:40:19 2005
From: hin-tak.leung at cimr.cam.ac.uk (hin-tak.leung@cimr.cam.ac.uk)
Date: Fri, 18 Nov 2005 18:40:19 +0100 (CET)
Subject: [Rd] problem with \eqn (PR#8322)
Message-ID: <20051118174019.785C07E7A@slim.kubism.ku.dk>

Martin Maechler wrote:
>>>>>>"Hin-Tak" == Hin-Tak Leung <hin-tak.leung at cimr.cam.ac.uk>
>>>>>>    on Fri, 18 Nov 2005 16:38:28 +0000 writes:
> 
> 
>     Hin-Tak> Your own fault. See below. It is basic LaTeX and any LaTeX person
>     Hin-Tak> can tell you the answer...(most probably haven't bothered...)
> 
> No.  Whereas I partly agree that it's Ross ``fault'' trying to
> use too smart LaTex (and using outdated \bf instead of \mathbf), 
> ;-)
> 
> The bug is really there, since we are talking about the Rd "language",
> not LaTeX, an in Rd,  \eqn and \deqn are defined to have either
> one or two arguments -- where Ross used the 2-argument version
> correctly (in principle at least) --> See the manual "Writing R
> Extensions".

Forgive me for not reading R-ext carefully, but Ross's Rd code is
still "obviously" wrong in the lights of the two-argument \eqn:
(really doesn't differ from the 1-arg interpretaion of \eqn)

\eqn{{\bf\beta}_j}{\bf\beta}_jnormal-bracket5bracket-normal{b(j)}

In other words,
\eqn{...}{...}_...

and the "_" is still outside of any maths environment, which is most
probably not Ross's intention.

> 
> 
>     >> Full_Name: Ross Boylan
>     >> Version: 2.2.0
>     >> OS: Linux
>     >> Submission from: (NULL) (65.175.48.58)
>     >> 
>     >> 
>     >> \eqn{{\bf\beta}_j}{b(j)} in my .Rd file produces this error
> 
>     >> --------------------------------------------
>     >> ! Missing $ inserted.
>     >> <inserted text> 
>     >> $
>     >> l.7 \eqn{{\bf\beta}_j}{\bf\beta}_jnormal-bracket5bracket-normal{b(j)}
> 
>     Hin-Tak> \eqn{{\bf\beta}_j} is already syntactically complete, so latex
>     Hin-Tak> complains the next "_" is not in maths mode, and automatically
>     Hin-Tak> switch into maths mode for you (the $ inserted message) You have
>     Hin-Tak> to match all the braces - you need 3 right-braces after \eqn,
>     Hin-Tak> like this, at least:
> 
>     Hin-Tak> \eqn{  {  {\bf\beta
>     Hin-Tak> }_j
>     Hin-Tak> }
>     Hin-Tak> {\bf\beta
>     Hin-Tak> }_ ....
>     Hin-Tak> {b(j)
>     Hin-Tak> }
>     Hin-Tak> }


From murdoch at stats.uwo.ca  Fri Nov 18 19:12:35 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri, 18 Nov 2005 13:12:35 -0500
Subject: [Rd] problem with \eqn (PR#8322)
In-Reply-To: <437E11F7.6010604@cimr.cam.ac.uk>
References: <20051117215558.33EB422485@slim.kubism.ku.dk>	<437E0384.604@cimr.cam.ac.uk>	<17278.3526.762256.703178@stat.math.ethz.ch>
	<437E11F7.6010604@cimr.cam.ac.uk>
Message-ID: <437E1993.5020804@stats.uwo.ca>

On 11/18/2005 12:40 PM, Hin-Tak Leung wrote:
> Martin Maechler wrote:
> 
>>>>>>>"Hin-Tak" == Hin-Tak Leung <hin-tak.leung at cimr.cam.ac.uk>
>>>>>>>   on Fri, 18 Nov 2005 16:38:28 +0000 writes:
>>
>>
>>    Hin-Tak> Your own fault. See below. It is basic LaTeX and any LaTeX person
>>    Hin-Tak> can tell you the answer...(most probably haven't bothered...)
>>
>>No.  Whereas I partly agree that it's Ross ``fault'' trying to
>>use too smart LaTex (and using outdated \bf instead of \mathbf), 
>>;-)
>>
>>The bug is really there, since we are talking about the Rd "language",
>>not LaTeX, an in Rd,  \eqn and \deqn are defined to have either
>>one or two arguments -- where Ross used the 2-argument version
>>correctly (in principle at least) --> See the manual "Writing R
>>Extensions".
> 
> 
> Forgive me for not reading R-ext carefully, but Ross's Rd code is
> still "obviously" wrong in the lights of the two-argument \eqn:
> (really doesn't differ from the 1-arg interpretaion of \eqn)
> 
> \eqn{{\bf\beta}_j}{\bf\beta}_jnormal-bracket5bracket-normal{b(j)}
> 
> In other words,
> \eqn{...}{...}_...
> 
> and the "_" is still outside of any maths environment, which is most
> probably not Ross's intention.

But that is Latex code produced by R, not Rd code produced by Ross.  The 
bug is in the Latex production (which I think is done by 
share/perl/R/Rdconv.pm, but I don't know Perl well enough to attempt to 
fix it).

Duncan Murdoch


From bolker at zoo.ufl.edu  Fri Nov 18 19:13:02 2005
From: bolker at zoo.ufl.edu (Ben Bolker)
Date: Fri, 18 Nov 2005 13:13:02 -0500
Subject: [Rd] minor suggestion for optim documentation
Message-ID: <437E19AE.5070101@zoo.ufl.edu>


   consider adding the following clause to the optim documentation
describing SANN?  I had to go look this up in the
optim.c code for a student who is not proficient
in C, and it may be simple enough to include it
in the documentation.  (This replaces the existing
sentence that ends where the semicolon is.)

Temperatures are decreased according to the
   logarithmic cooling schedule as given in Belisle (1992, p. 890);
   specifically, the temperature is set to
\code{temp/(log((t-1) %/%tmax)*tmax+exp(1))},
   where \code{t} is the current iteration step.

   sincerely
     Ben Bolker

-- 
620B Bartram Hall                            bolker at zoo.ufl.edu
Zoology Department, University of Florida    http://www.zoo.ufl.edu/bolker
Box 118525                                   (ph)  352-392-5697
Gainesville, FL 32611-8525                   (fax) 352-392-3704


From ligges at statistik.uni-dortmund.de  Fri Nov 18 19:14:41 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 18 Nov 2005 19:14:41 +0100
Subject: [Rd] problem with \eqn (PR#8322)
In-Reply-To: <437E11F7.6010604@cimr.cam.ac.uk>
References: <20051117215558.33EB422485@slim.kubism.ku.dk>	<437E0384.604@cimr.cam.ac.uk>	<17278.3526.762256.703178@stat.math.ethz.ch>
	<437E11F7.6010604@cimr.cam.ac.uk>
Message-ID: <437E1A11.3040308@statistik.uni-dortmund.de>

Hin-Tak Leung wrote:

> Martin Maechler wrote:
> 
>>>>>>>"Hin-Tak" == Hin-Tak Leung <hin-tak.leung at cimr.cam.ac.uk>
>>>>>>>   on Fri, 18 Nov 2005 16:38:28 +0000 writes:
>>
>>
>>    Hin-Tak> Your own fault. See below. It is basic LaTeX and any LaTeX person
>>    Hin-Tak> can tell you the answer...(most probably haven't bothered...)
>>
>>No.  Whereas I partly agree that it's Ross ``fault'' trying to
>>use too smart LaTex (and using outdated \bf instead of \mathbf), 
>>;-)
>>
>>The bug is really there, since we are talking about the Rd "language",
>>not LaTeX, an in Rd,  \eqn and \deqn are defined to have either
>>one or two arguments -- where Ross used the 2-argument version
>>correctly (in principle at least) --> See the manual "Writing R
>>Extensions".
> 
> 
> Forgive me for not reading R-ext carefully, but Ross's Rd code is
> still "obviously" wrong in the lights of the two-argument \eqn:
> (really doesn't differ from the 1-arg interpretaion of \eqn)
> 
> \eqn{{\bf\beta}_j}{\bf\beta}_jnormal-bracket5bracket-normal{b(j)}


No, that is the output after conversion, please read the original 
poster's mail more carefully.

Uwe Ligges


> In other words,
> \eqn{...}{...}_...
> 
> and the "_" is still outside of any maths environment, which is most
> probably not Ross's intention.
> 
> 
>>
>>    >> Full_Name: Ross Boylan
>>    >> Version: 2.2.0
>>    >> OS: Linux
>>    >> Submission from: (NULL) (65.175.48.58)
>>    >> 
>>    >> 
>>    >> \eqn{{\bf\beta}_j}{b(j)} in my .Rd file produces this error
>>
>>    >> --------------------------------------------
>>    >> ! Missing $ inserted.
>>    >> <inserted text> 
>>    >> $
>>    >> l.7 \eqn{{\bf\beta}_j}{\bf\beta}_jnormal-bracket5bracket-normal{b(j)}
>>
>>    Hin-Tak> \eqn{{\bf\beta}_j} is already syntactically complete, so latex
>>    Hin-Tak> complains the next "_" is not in maths mode, and automatically
>>    Hin-Tak> switch into maths mode for you (the $ inserted message) You have
>>    Hin-Tak> to match all the braces - you need 3 right-braces after \eqn,
>>    Hin-Tak> like this, at least:
>>
>>    Hin-Tak> \eqn{  {  {\bf\beta
>>    Hin-Tak> }_j
>>    Hin-Tak> }
>>    Hin-Tak> {\bf\beta
>>    Hin-Tak> }_ ....
>>    Hin-Tak> {b(j)
>>    Hin-Tak> }
>>    Hin-Tak> }
> 
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From maechler at stat.math.ethz.ch  Fri Nov 18 21:32:58 2005
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 18 Nov 2005 21:32:58 +0100
Subject: [Rd] challenge: using 'subset = <computed>' inside function ..
Message-ID: <17278.14970.987870.440521@stat.math.ethz.ch>

I've been asked by someone else whom I originally taught 
`` to just work with substitute() and then all will be fine'' ...

But it looks to me that I've been caught here.

Is it possible to make this work along the way we thought it should?

1)  Inside a function, say tst() with the 'formula' and a 'data' argument, 
2)  call another modeling function using 'subset = <EXPR>' with the *original*
    data,
3)  but <EXPR> is really computed from 'formula' itself ..

It would probably be pretty easy to use a modified 'data' (data
frame), inside tst(), instead of trying to the original data;
but let's assume for the moment that this is not at all wanted.


Here is example code {that fails}
showing several other possibilities that fail as well


tst <- function(formula, data, na.action = na.omit) {

    stopifnot(inherits(formula,"formula"), length(formula) == 3)
    ## I want to fit a model to those observations that have 'Y > 0'
    ## where 'Y' is the left-hand-side (LHS)
    ## The really natural problem is using 'subset'; since I want to keep 'data' intact
    ## It's really  lm(), glm(), gam(), ... but the problem is with model.frame:

    cat("subsetting expression: ")
    print(substitute(Y > 0, list(Y = formula[[2]])))# is perfect
    YY <- formula[[2]]
    cat("  or   "); print(bquote(.(YY) > 0))

    mf <- model.frame(formula, data=data,
                      subset = bquote(.(YY) > 0),
                      ##or subset = substitute(Y > 0, list(Y = formula[[2]])),
                      ##or subset = eval(substitute(Y > 0, list(Y = formula[[2]]))),
                      ##or subset = as.expression(bquote(.(formula[[2]]) > 0)),
                      ##or subset = bquote(.(formula[[2]]) > 0),
                      na.action = na.action)
    mf
}


## never works
tst(ncases ~ agegp + alcgp, data = esoph)

traceback() #--> shows that inside model.frame.default
	    #    eval(substitute(subset, ...))  is called as well

----

Happy quizzing..

Martin Maechler, ETH Zurich


From ellis at stat.harvard.edu  Fri Nov 18 23:46:34 2005
From: ellis at stat.harvard.edu (Byron Ellis)
Date: Fri, 18 Nov 2005 14:46:34 -0800
Subject: [Rd] A problem with glm() and possibly model-using functions in
	general?
Message-ID: <1FB5B939-D81E-4CC6-9806-C4D1912581F7@stat.harvard.edu>

So, consider the following:

 > example(glm)
 > g = function(model) { w = runif(9);glm(model,weights=w); }
 > g(counts ~ outcome + treatment)
Error in eval(expr, envir, enclos) : object "w" not found

Huh?! I suspect that somebody is lazily evaluating arguments in the  
wrong environment (probably GlobalEnv in this case). I'm willing to  
accept the fact that there's some mysterious reason you'd actually  
want this behavior, but this looks like it should be filed as a bug  
to me.

---
Byron Ellis (ellis at stat.harvard.edu)
"Oook" -- The Librarian


From Kurt.Hornik at wu-wien.ac.at  Fri Nov 18 20:38:01 2005
From: Kurt.Hornik at wu-wien.ac.at (Kurt Hornik)
Date: Fri, 18 Nov 2005 20:38:01 +0100
Subject: [Rd] problem with \eqn (PR#8322)
In-Reply-To: <437E1993.5020804@stats.uwo.ca>
References: <20051117215558.33EB422485@slim.kubism.ku.dk>
	<437E0384.604@cimr.cam.ac.uk>
	<17278.3526.762256.703178@stat.math.ethz.ch>
	<437E11F7.6010604@cimr.cam.ac.uk> <437E1993.5020804@stats.uwo.ca>
Message-ID: <17278.11673.761366.759409@mithrandir.hornik.net>

>>>>> Duncan Murdoch writes:

> On 11/18/2005 12:40 PM, Hin-Tak Leung wrote:
>> Martin Maechler wrote:
>> 
>>>>>>>> "Hin-Tak" == Hin-Tak Leung <hin-tak.leung at cimr.cam.ac.uk>
>>>>>>>> on Fri, 18 Nov 2005 16:38:28 +0000 writes:
>>> 
>>> 
Hin-Tak> Your own fault. See below. It is basic LaTeX and any LaTeX person
Hin-Tak> can tell you the answer...(most probably haven't bothered...)
>>> 
>>> No.  Whereas I partly agree that it's Ross ``fault'' trying to
>>> use too smart LaTex (and using outdated \bf instead of \mathbf), 
>>> ;-)
>>> 
>>> The bug is really there, since we are talking about the Rd "language",
>>> not LaTeX, an in Rd,  \eqn and \deqn are defined to have either
>>> one or two arguments -- where Ross used the 2-argument version
>>> correctly (in principle at least) --> See the manual "Writing R
>>> Extensions".
>> 
>> 
>> Forgive me for not reading R-ext carefully, but Ross's Rd code is
>> still "obviously" wrong in the lights of the two-argument \eqn:
>> (really doesn't differ from the 1-arg interpretaion of \eqn)
>> 
>> \eqn{{\bf\beta}_j}{\bf\beta}_jnormal-bracket5bracket-normal{b(j)}
>> 
>> In other words,
>> \eqn{...}{...}_...
>> 
>> and the "_" is still outside of any maths environment, which is most
>> probably not Ross's intention.

> But that is Latex code produced by R, not Rd code produced by Ross.
> The bug is in the Latex production (which I think is done by
> share/perl/R/Rdconv.pm, but I don't know Perl well enough to attempt
> to fix it).

Definitely a problem in Rdconv.

E.g.,

$ cat foo.Rd 
\description{
  \eqn{{A}}{B}
}
hornik at mithrandir:~/tmp$ R-d CMD Rdconv -t latex foo.Rd | grep eqn
\eqn{{A}}{A}{{B}

shows what is going on.

My reading of R-exts would suggest that it is not necessary to escape
braces inside \eqn (and in fact these are not unescaped by Rdconv).

Btw, the conversions of the above example are wrong for at least HTML
and text as well, giving

  <i>A</i>{{B}

and

  A{{B}

respectively.

-k


From tlumley at u.washington.edu  Sat Nov 19 01:35:45 2005
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Fri, 18 Nov 2005 16:35:45 -0800 (PST)
Subject: [Rd] A problem with glm() and possibly model-using functions in
 general?
In-Reply-To: <1FB5B939-D81E-4CC6-9806-C4D1912581F7@stat.harvard.edu>
References: <1FB5B939-D81E-4CC6-9806-C4D1912581F7@stat.harvard.edu>
Message-ID: <Pine.LNX.4.63a.0511181631510.14137@homer22.u.washington.edu>

On Fri, 18 Nov 2005, Byron Ellis wrote:

> So, consider the following:
>
> > example(glm)
> > g = function(model) { w = runif(9);glm(model,weights=w); }
> > g(counts ~ outcome + treatment)
> Error in eval(expr, envir, enclos) : object "w" not found
>
> Huh?! I suspect that somebody is lazily evaluating arguments in the
> wrong environment (probably GlobalEnv in this case). I'm willing to
> accept the fact that there's some mysterious reason you'd actually
> want this behavior, but this looks like it should be filed as a bug
> to me.

Yes, there is a reason you'd actually want this behaviour, and 
it is documented. In help(model.frame) it says

      All the variables in 'formula', 'subset' and in '...' are looked
      for first in 'data' and then in the environment of 'formula' (see
      the help for 'formula()' for further details) and collected into a
      data frame.

In your example the environment of 'formula' is the global environment, 
since that's where it was created.

There isn't a set of scoping rules for formulas that will make everyone 
happy, but this lexical scope is what R has done for quite some time.

 	-thomas


From ellis at stat.harvard.edu  Sat Nov 19 02:30:20 2005
From: ellis at stat.harvard.edu (Byron Ellis)
Date: Fri, 18 Nov 2005 17:30:20 -0800
Subject: [Rd] A problem with glm() and possibly model-using functions in
	general?
In-Reply-To: <Pine.LNX.4.63a.0511181631510.14137@homer22.u.washington.edu>
References: <1FB5B939-D81E-4CC6-9806-C4D1912581F7@stat.harvard.edu>
	<Pine.LNX.4.63a.0511181631510.14137@homer22.u.washington.edu>
Message-ID: <4F11519C-0EDC-4F8E-B8DE-A9CD675C7F46@stat.harvard.edu>


On Nov 18, 2005, at 4:35 PM, Thomas Lumley wrote:

> On Fri, 18 Nov 2005, Byron Ellis wrote:
>
>> So, consider the following:
>>
>>> example(glm)
>>> g = function(model) { w = runif(9);glm(model,weights=w); }
>>> g(counts ~ outcome + treatment)
>> Error in eval(expr, envir, enclos) : object "w" not found
>>
>> Huh?! I suspect that somebody is lazily evaluating arguments in the
>> wrong environment (probably GlobalEnv in this case). I'm willing to
>> accept the fact that there's some mysterious reason you'd actually
>> want this behavior, but this looks like it should be filed as a bug
>> to me.
>
> Yes, there is a reason you'd actually want this behaviour, and
> it is documented. In help(model.frame) it says
>
>       All the variables in 'formula', 'subset' and in '...' are looked
>       for first in 'data' and then in the environment of  
> 'formula' (see
>       the help for 'formula()' for further details) and collected  
> into a
>       data frame.
>
> In your example the environment of 'formula' is the global  
> environment,
> since that's where it was created.
>
> There isn't a set of scoping rules for formulas that will make  
> everyone
> happy, but this lexical scope is what R has done for quite some time.
>
>  	-thomas
>

Hrmm, well at least I know why it does what it does. I can't claim to  
like it, but I suspect thats a religious debate that won't be  
particularly useful.

> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

---
Byron Ellis (ellis at stat.harvard.edu)
"Oook" -- The Librarian


From bhs2 at mevik.net  Sat Nov 19 11:03:47 2005
From: bhs2 at mevik.net (=?iso-8859-1?q?Bj=F8rn-Helge_Mevik?=)
Date: Sat, 19 Nov 2005 11:03:47 +0100
Subject: [Rd] challenge: using 'subset = <computed>' inside function ..
In-Reply-To: <17278.14970.987870.440521@stat.math.ethz.ch> (Martin
	Maechler's message of "Fri, 18 Nov 2005 21:32:58 +0100")
References: <17278.14970.987870.440521@stat.math.ethz.ch>
Message-ID: <m0zmo1lzss.fsf@bar.nemo-project.org>

Hmm.. Maybe I'm overlooking something, but why not use do.call()?
For instance

tst <- function(formula, data, na.action = na.omit) {

    stopifnot(inherits(formula,"formula"), length(formula) == 3)
    ## I want to fit a model to those observations that have 'Y > 0'
    ## where 'Y' is the left-hand-side (LHS)
    ## The really natural problem is using 'subset'; since I want to keep 'data' intact
    ## It's really  lm(), glm(), gam(), ... but the problem is with model.frame:

    cat("subsetting expression: ")
    print(substitute(Y > 0, list(Y = formula[[2]])))# is perfect
    YY <- formula[[2]]
    cat("  or   "); print(bquote(.(YY) > 0))

    mf <- do.call("model.frame", list(formula = formula, data = data,
                                      subset = bquote(.(YY) > 0),
                                      na.action = na.action))
    mf
}

It seems to work for me:

> mydata <- data.frame(y = rep(c(-1, 1), each = 5), x = rnorm(10))
> tst(y ~ x, data = mydata)
subsetting expression: y > 0
  or   y > 0
   y          x
6  1  0.9568283
7  1  0.1166081
8  1 -0.9592458
9  1 -0.0974119
10 1  0.2217222


-- 
Bj?rn-Helge Mevik


From pinard at iro.umontreal.ca  Sun Nov 20 22:01:42 2005
From: pinard at iro.umontreal.ca (pinard@iro.umontreal.ca)
Date: Sun, 20 Nov 2005 22:01:42 +0100 (CET)
Subject: [Rd] mapply() gives seg fault (PR#8332)
Message-ID: <20051120210142.E3A62223A5@slim.kubism.ku.dk>


--KsGdsel6WgEHnImy
Content-Type: text/plain; charset=iso-8859-1; format=flowed
Content-Disposition: inline
Content-Transfer-Encoding: 8bit

Hi, people.  Wandering in R archives, and seeing the message attached 
below, I noticed that:

   mapply(rep,times=1:4, MoreArgs=42)

still segfaults on R 2.2.0, and thought I should be a good citizen and 
report it, even if I do not have an actual problem with this. :-)

> version
         _                
platform i686-pc-linux-gnu
arch     i686             
os       linux-gnu        
system   i686, linux-gnu  
status                    
major    2                
minor    2.0              
year     2005             
month    10               
day      06               
svn rev  35749            
language R                

(By the way, in the output of "R.version", should all the spurious 
whitespace be kept at end of lines?)

-- 
Fran?ois Pinard   http://pinard.progiciels-bpi.ca

--KsGdsel6WgEHnImy
Content-Type: message/rfc822
Content-Disposition: inline

From: rpeng at jhsph.edu (Roger D. Peng)
Date: Tue Oct 14 18:10:52 2003
Subject: [R] mapply() gives seg fault
In-Reply-To: <a06002007bbb1c91c2d44@[139.166.242.29]>
References: <a06002007bbb1c91c2d44@[139.166.242.29]>
Message-ID: <3F8C1E93.7030903 at jhsph.edu>

I get this too on the released version.  I guess the problem is that the 
value passed to MoreArgs is not a list.  Maybe,

mapply(rep, times = 1:4, MoreArgs = list(42))

produces what you want?  At any rate, R shouldn't segfault so it looks 
like bug somewhere.

-roger

Robin Hankin wrote:

> Hello everybody.
>
> I've been experimenting with mapply().  Does anyone else have problems 
> with:
>
> R> mapply(rep,times=1:4, MoreArgs=42)
>
> (I get a seg fault).
>
> robin
>
>
>
> R> R.version
>          _
> platform powerpc-apple-darwin6.6
> arch     powerpc
> os       darwin6.6
> system   powerpc, darwin6.6
> status   beta
> major    1
> minor    8.0
> year     2003
> month    10
> day      02
> language R
>
>>
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>

--KsGdsel6WgEHnImy--


From p.dalgaard at biostat.ku.dk  Sun Nov 20 23:02:35 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 20 Nov 2005 23:02:35 +0100
Subject: [Rd] mapply() gives seg fault (PR#8332)
In-Reply-To: <20051120210142.E3A62223A5@slim.kubism.ku.dk>
References: <20051120210142.E3A62223A5@slim.kubism.ku.dk>
Message-ID: <x2ek5bou4k.fsf@turmalin.kubism.ku.dk>

pinard at iro.umontreal.ca writes:

> --KsGdsel6WgEHnImy
> Content-Type: text/plain; charset=iso-8859-1; format=flowed
> Content-Disposition: inline
> Content-Transfer-Encoding: 8bit
> 
> Hi, people.  Wandering in R archives, and seeing the message attached 
> below, I noticed that:
> 
>    mapply(rep,times=1:4, MoreArgs=42)
> 
> still segfaults on R 2.2.0, and thought I should be a good citizen and 
> report it, even if I do not have an actual problem with this. :-)

Looks like Brian already fixed it in r-patched. Seems like this was
after your message, so I'd better skip the snide remark about how to
be an even better citizen.... ;-)

 
> > version
>          _                
> platform i686-pc-linux-gnu
> arch     i686             
> os       linux-gnu        
> system   i686, linux-gnu  
> status                    
> major    2                
> minor    2.0              
> year     2005             
> month    10               
> day      06               
> svn rev  35749            
> language R                
> 
> (By the way, in the output of "R.version", should all the spurious 
> whitespace be kept at end of lines?)
> 
> -- 
> Fran?ois Pinard   http://pinard.progiciels-bpi.ca
> 
> --KsGdsel6WgEHnImy
> Content-Type: message/rfc822
> Content-Disposition: inline
> 
> From: rpeng at jhsph.edu (Roger D. Peng)
> Date: Tue Oct 14 18:10:52 2003
> Subject: [R] mapply() gives seg fault
> In-Reply-To: <a06002007bbb1c91c2d44@[139.166.242.29]>
> References: <a06002007bbb1c91c2d44@[139.166.242.29]>
> Message-ID: <3F8C1E93.7030903 at jhsph.edu>
> 
> I get this too on the released version.  I guess the problem is that the 
> value passed to MoreArgs is not a list.  Maybe,
> 
> mapply(rep, times = 1:4, MoreArgs = list(42))
> 
> produces what you want?  At any rate, R shouldn't segfault so it looks 
> like bug somewhere.
> 
> -roger
> 
> Robin Hankin wrote:
> 
> > Hello everybody.
> >
> > I've been experimenting with mapply().  Does anyone else have problems 
> > with:
> >
> > R> mapply(rep,times=1:4, MoreArgs=42)
> >
> > (I get a seg fault).
> >
> > robin
> >
> >
> >
> > R> R.version
> >          _
> > platform powerpc-apple-darwin6.6
> > arch     powerpc
> > os       darwin6.6
> > system   powerpc, darwin6.6
> > status   beta
> > major    1
> > minor    8.0
> > year     2003
> > month    10
> > day      02
> > language R
> >
> >>
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >
> 
> --KsGdsel6WgEHnImy--
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From pinard at iro.umontreal.ca  Mon Nov 21 03:45:47 2005
From: pinard at iro.umontreal.ca (=?iso-8859-1?Q?Fran=E7ois?= Pinard)
Date: Sun, 20 Nov 2005 21:45:47 -0500
Subject: [Rd] mapply() gives seg fault (PR#8332)
In-Reply-To: <x2ek5bou4k.fsf@turmalin.kubism.ku.dk>
References: <20051120210142.E3A62223A5@slim.kubism.ku.dk>
	<x2ek5bou4k.fsf@turmalin.kubism.ku.dk>
Message-ID: <20051121024547.GA22829@phenix.sram.qc.ca>

[Peter Dalgaard]

> Looks like Brian already fixed it in r-patched.  Seems like this was 
> after your message, so I'd better skip the snide remark about how to 
> be an even better citizen.... ;-)

:-).  Yet, there are limits to perfection!  I maintained some software 
for many, many years, and witnessed a change in mentalities over time, 
not always to my pleasure.  There was a time when user reports,
would they be about programming bugs, documentation weaknesses, or mere 
suggestions, were received as worth contributions, deserving a friendly 
replies.  Nowadays, some maintainers went ferocious, putting no end to 
the flurry of bug trackers, wikis, chat rooms, reviewing committees, Web 
forms, they want us to learn and go by, each maintainer his own set.

While I understand and appreciate that maintainers' time is precious, 
mine is not totally insignificant.  Some equilibrium, common sense and 
civility is needed!  I would dare a spurious report, if I guess it would 
take no more than a few dozen seconds to cross-check at the other end, 
if this spares me hours of learning or preparation.  The alternative is 
either being shy to the point of not contributing, or else, embracing 
only very few software packages as if they were jealous religions.

The R developers group seems reasonable so far that I could see, for the 
year or so I've been reading the exchanges.  A few gurus regularly do 
remind others about posting guidelines, and the need of prior research.  
Despite some are a bit stiff at times, they always acted with civility.

-- 
Fran?ois Pinard   http://pinard.progiciels-bpi.ca


From hin-tak.leung at cimr.cam.ac.uk  Mon Nov 21 11:18:25 2005
From: hin-tak.leung at cimr.cam.ac.uk (Hin-Tak Leung)
Date: Mon, 21 Nov 2005 10:18:25 +0000
Subject: [Rd] problem with \eqn (PR#8322)
In-Reply-To: <17278.11673.761366.759409@mithrandir.hornik.net>
References: <20051117215558.33EB422485@slim.kubism.ku.dk>	<437E0384.604@cimr.cam.ac.uk>	<17278.3526.762256.703178@stat.math.ethz.ch>	<437E11F7.6010604@cimr.cam.ac.uk>	<437E1993.5020804@stats.uwo.ca>
	<17278.11673.761366.759409@mithrandir.hornik.net>
Message-ID: <43819EF1.7000908@cimr.cam.ac.uk>

Kurt Hornik wrote:
>>>>>>Duncan Murdoch writes:
> 
> 
>>On 11/18/2005 12:40 PM, Hin-Tak Leung wrote:
>>
>>>Martin Maechler wrote:
>>>
>>>
>>>>>>>>>"Hin-Tak" == Hin-Tak Leung <hin-tak.leung at cimr.cam.ac.uk>
>>>>>>>>>on Fri, 18 Nov 2005 16:38:28 +0000 writes:
>>>>
>>>>
> Hin-Tak> Your own fault. See below. It is basic LaTeX and any LaTeX person
> Hin-Tak> can tell you the answer...(most probably haven't bothered...)
> 
>>>>No.  Whereas I partly agree that it's Ross ``fault'' trying to
>>>>use too smart LaTex (and using outdated \bf instead of \mathbf), 
>>>>;-)
>>>>
>>>>The bug is really there, since we are talking about the Rd "language",
>>>>not LaTeX, an in Rd,  \eqn and \deqn are defined to have either
>>>>one or two arguments -- where Ross used the 2-argument version
>>>>correctly (in principle at least) --> See the manual "Writing R
>>>>Extensions".
>>>
>>>
>>>Forgive me for not reading R-ext carefully, but Ross's Rd code is
>>>still "obviously" wrong in the lights of the two-argument \eqn:
>>>(really doesn't differ from the 1-arg interpretaion of \eqn)
>>>
>>>\eqn{{\bf\beta}_j}{\bf\beta}_jnormal-bracket5bracket-normal{b(j)}
>>>
>>>In other words,
>>>\eqn{...}{...}_...
>>>
>>>and the "_" is still outside of any maths environment, which is most
>>>probably not Ross's intention.
> 
> 
>>But that is Latex code produced by R, not Rd code produced by Ross.
>>The bug is in the Latex production (which I think is done by
>>share/perl/R/Rdconv.pm, but I don't know Perl well enough to attempt
>>to fix it).
> 
> 
> Definitely a problem in Rdconv.
> 
> E.g.,
> 
> $ cat foo.Rd 
> \description{
>   \eqn{{A}}{B}
> }
> hornik at mithrandir:~/tmp$ R-d CMD Rdconv -t latex foo.Rd | grep eqn
> \eqn{{A}}{A}{{B}
> 
> shows what is going on.
> 
> My reading of R-exts would suggest that it is not necessary to escape
> braces inside \eqn (and in fact these are not unescaped by Rdconv).
> 
> Btw, the conversions of the above example are wrong for at least HTML
> and text as well, giving
> 
>   <i>A</i>{{B}
> 
> and
> 
>   A{{B}
> 
> respectively.

Apologies - the problem is with this section of "share/perl/R/Rdconv.pm"
around line 400 - it basically doesn't try very hard dealing with nested 
brackets.

=======================
## Get the arguments of a command.
sub get_arguments {
     my ($command, $text, $nargs) = @_;
     ## Arguments of get_arguments:
     ##  1, command: next occurence of 'command' is searched
     ##  2, text:    'text' is the text containing the command
     ##  3, nargs:   the optional number of arguments to be extracted;
     ##              default 1
     my @retval;
     ## Returns a list with the id of the last closing bracket and the
     ## arguments.

     if($text =~ /\\($command)(\[[^\]]+\])?($ID)/){
         $id = $3;
         $text =~ /$id(.*)$id/s;
         $retval[1] = $1;
         my $k=2;
         while(($k<=$nargs) && ($text =~ /$id($ID)/)){
             $id = $1;
             $text =~ /$id\s*(.*)$id/s;
             $retval[$k++] = $1;
         }
     }
     $retval[0] = $id;
     @retval;
}
==================

HT


From hin-tak.leung at cimr.cam.ac.uk  Mon Nov 21 11:27:17 2005
From: hin-tak.leung at cimr.cam.ac.uk (Hin-Tak Leung)
Date: Mon, 21 Nov 2005 10:27:17 +0000
Subject: [Rd] problem with \eqn (PR#8322)
In-Reply-To: <17278.11673.761366.759409@mithrandir.hornik.net>
References: <20051117215558.33EB422485@slim.kubism.ku.dk>	<437E0384.604@cimr.cam.ac.uk>	<17278.3526.762256.703178@stat.math.ethz.ch>	<437E11F7.6010604@cimr.cam.ac.uk>	<437E1993.5020804@stats.uwo.ca>
	<17278.11673.761366.759409@mithrandir.hornik.net>
Message-ID: <4381A105.4000404@cimr.cam.ac.uk>

Kurt Hornik wrote:
<snipped>
> Definitely a problem in Rdconv.
> 
> E.g.,
> 
> $ cat foo.Rd 
> \description{
>   \eqn{{A}}{B}
> }
> hornik at mithrandir:~/tmp$ R-d CMD Rdconv -t latex foo.Rd | grep eqn
> \eqn{{A}}{A}{{B}
> 
> shows what is going on.

There is a "work-around" - putting extra spaces between the two braces:

$ cat foo.Rd
\description{
   \eqn{ {A} }{B}
}

$R CMD Rdconv -t latex foo.Rd
\HeaderA{}{}{}
\begin{Description}\relax
\eqn{ {A} }{B}
\end{Description}


HT


From kwright68 at gmail.com  Mon Nov 21 18:13:36 2005
From: kwright68 at gmail.com (kwright68@gmail.com)
Date: Mon, 21 Nov 2005 18:13:36 +0100 (CET)
Subject: [Rd] formatC adds leading space to exponential format (PR#8337)
Message-ID: <20051121171336.1A1698565@slim.kubism.ku.dk>

Full_Name: Kevin Wright
Version: 2.2.0
OS: Windows 2000
Submission from: (NULL) (170.54.58.4)



Apologies if my expectations (or reading of the man page) are incorrect.  

I seem unable to left-justify exponential format numbers.  There appears to
always be an extra space inserted to the left.

Using the example from the formatC help page:

R> xx  <- pi * 10^(-5:4)

R> cbind(formatC(xx, wid = 9, flag = "-"))
      [,1]        
 [1,] " 3.142e-05"
 [2,] "0.0003142" 
 [3,] "0.003142 " 
 [4,] "0.03142  " 
 [5,] "0.3142   " 
 [6,] "3.142    " 
 [7,] "31.42    " 
 [8,] "314.2    " 
 [9,] "3142     " 
[10,] " 3.142e+04"


# What does R want to do by default?
# Exponential numbers have a leading space

R> formatC(xx)
 [1] " 3.142e-05" "0.0003142"  "0.003142"   "0.03142"    "0.3142"    
 [6] "3.142"      "31.42"      "314.2"      "3142"       " 3.142e+04"


# Maybe space is reserved for a +/- sign?  Let's try formatting negative
numbers
# Still an extra space before exponential numbers

R> cbind(formatC(-xx, wid = 9, flag = "-"))
      [,1]         
 [1,] " -3.142e-05"
 [2,] "-0.0003142" 
 [3,] "-0.003142"  
 [4,] "-0.03142 "  
 [5,] "-0.3142  "  
 [6,] "-3.142   "  
 [7,] "-31.42   "  
 [8,] "-314.2   "  
 [9,] "-3142    "  
[10,] " -3.142e+04"

# Try to force left-justification using 'width=-1',
# still no luck.

R> cbind(formatC(xx, wid = -1))
      [,1]        
 [1,] " 3.142e-05"
 [2,] "0.0003142" 
 [3,] "0.003142"  
 [4,] "0.03142"   
 [5,] "0.3142"    
 [6,] "3.142"     
 [7,] "31.42"     
 [8,] "314.2"     
 [9,] "3142"      
[10,] " 3.142e+04"


From roebuck at mdanderson.org  Mon Nov 21 18:34:12 2005
From: roebuck at mdanderson.org (Paul Roebuck)
Date: Mon, 21 Nov 2005 11:34:12 -0600 (CST)
Subject: [Rd] shared-mime-info (PR#8278)
In-Reply-To: <x2oe50xxv5.fsf@viggo.kubism.ku.dk>
References: <20051103125634.1B15F24722@slim.kubism.ku.dk>
	<x2slucy3rn.fsf@viggo.kubism.ku.dk>
	<e47808320511040524g19097bb4k3929f8a6aaab5ea7@mail.gmail.com>
	<x2oe50xxv5.fsf@viggo.kubism.ku.dk>
Message-ID: <Pine.OSF.4.58.0511211006220.507459@wotan.mdacc.tmc.edu>

On Fri, 4 Nov 2005, Peter Dalgaard wrote:

> Vaidotas Zemlys writes:
>
> > On 04 Nov 2005 13:51:56 +0100, Peter Dalgaard wrote:
> >
> > > [SNIP RPM discussion]
>
> > There you can find xml file for R scripts. I've made it from some
> > example. It is really only a proof of a concept. But it would not be
> > very difficult to produce xml files for mimetypes of all R related
> > files. We must only decide which R related files would benefit from
> > having mimetypes.
> >
> > My proposal is
> > 1. R source code, R scripts. Files with extensions .R, .r and others
> > (.q?, .s?, .S?). Mimetypes text/x-R, text/x-Rsrc
>
> My inclination would be to stick with .R, possibly adding .r to guard
> against Windows case-folding issues, but .r used to be Ratfor files.
> .q/.s/.S are used by some people supporting both R and S-PLUS, but I
> don't think they care how such files are displayed by Nautilus and
> Konqueror...
>
> > 2. R documentation files. File extension .Rd. Mimetype text/x-Rd
>
> OK, modulo case-fold
>
> > 3. RData files. File extension .RData, files which at beginning have
> > RDX2. Mimetype application/x-RData.
>
> Why the RDX2 bit?? We do have .RDA from windows, too.
>
>
> > 4. Rhistory files. File extension .Rhistory. Mimetype text/x-Rhistory
>
> OK.
>
> > 5. R transcript files from ESS/Emacs. File extension .Rt. Mimetype
> > text/x-Rtranscript
>
> .Rout, please. Also .Rout.save and .Rout.fail. (And it's not just
> ESS that creates them).
>
> Also
>
> 6. Rprofile files .Rprofile or Rprofile.
>
> > I could write and test the xml code. But first we have to agree on
> > which files benefit from having mimetypes and how the mimetypes should
> > be named. Feel free to suggest.
>

What is the status of this problem report? Was a standard
set of MIME types ever established for the various R file
types? If so, where can I find them? The following seem
reasonable comparing against various sources, blended
with the above.


File types			MIME types
------------------------------	------------------------
.R				text/x-r,
                                text/x-r-source,
                                text/plain

.Rd				text/x-r-doc,
                                text/plain

.RData				application/x-r-data

.Rhistory			text/x-r-history,
                                text/plain

.Rout, .Rout.save, .Rout.fail	text/x-r-transcript,
                                text/plain

.Rprofile, Rprofile.site	text/x-r-profile,
				text/plain

.Renviron, Renviron		text/x-r-environ,
                                text/plain

I read long ago about suggestion for using dot-q for S
source but don't recall ever having seen it in the wild.
Peter mentioned dot-r as having been previously used for
Ratfor. It was also used by Rez on Mac OS. Also note that
dot-s is for assembly source.

Not sure if all of these even deserve MIME types. The first
three seem useful though the latter four could be dropped.

----------------------------------------------------------
SIGSIG -- signature too long (core dumped)


From sfalcon at fhcrc.org  Mon Nov 21 22:16:37 2005
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Mon, 21 Nov 2005 13:16:37 -0800
Subject: [Rd] NAMESPACE, S4, and .onLoad
Message-ID: <m2veylzop6.fsf@fhcrc.org>

The Writing R Extensions manual instructs developers who use S4
classes and methods in a package with a name space to:

    There needs to be an .onLoad action to ensure that the methods package
    is loaded and attached:
    
         .onLoad <- function(lib, pkg) require(methods)

I'm wondering if listing methods in the Depends field of the package's
DESCRIPTION file is sufficient.  My understanding is that doing so
will result in the methods package being loaded and attached.

Best,

+ seth


Link to section in extension manual:
http://cran.r-project.org/doc/manuals/R-exts.html#Name-spaces-with-formal-classes-and-methods


From roebuck at mdanderson.org  Mon Nov 21 23:10:35 2005
From: roebuck at mdanderson.org (Paul Roebuck)
Date: Mon, 21 Nov 2005 16:10:35 -0600 (CST)
Subject: [Rd] NAMESPACE, S4, and .onLoad
In-Reply-To: <m2veylzop6.fsf@fhcrc.org>
References: <m2veylzop6.fsf@fhcrc.org>
Message-ID: <Pine.OSF.4.58.0511211604050.13497@wotan.mdacc.tmc.edu>

On Mon, 21 Nov 2005, Seth Falcon wrote:

> The Writing R Extensions manual instructs developers who use S4
> classes and methods in a package with a name space to:
>
>     There needs to be an .onLoad action to ensure that the methods package
>     is loaded and attached:
>
>          .onLoad <- function(lib, pkg) require(methods)
>
> I'm wondering if listing methods in the Depends field of the package's
> DESCRIPTION file is sufficient.  My understanding is that doing so
> will result in the methods package being loaded and attached.

Using DCF Depends provides same service and better documents
the external dependency. The manual should reflect this.

----------------------------------------------------------
SIGSIG -- signature too long (core dumped)


From Allyson.Williams at dpi.qld.gov.au  Tue Nov 22 02:50:46 2005
From: Allyson.Williams at dpi.qld.gov.au (Allyson.Williams@dpi.qld.gov.au)
Date: Tue, 22 Nov 2005 02:50:46 +0100 (CET)
Subject: [Rd] windrose (circular package) error in table (PR#8341)
Message-ID: <20051122015046.3E345103B8@slim.kubism.ku.dk>

Full_Name: Allyson Williams
Version: 2.1.1
OS: Windows XP
Submission from: (NULL) (203.25.1.208)


I'm using the 'Circular' package to plot windroses. I think the output table
(see out2$table below) is incorrect when using different rotations. More
precisely, when a rotation is used for the plot, the output table stuffs up.

This example is from the code in the help notes, although the input data (dir,
mag) are changed):

> dir <- c(1:50,1:50)
> mag <-  c(1:100)
> 
> sample <- data.frame(dir=circular(dir,units="degrees"), mag=mag)
> 
> par(mfrow=c(2,2))
> res <- windrose(sample)
> 
> ## we join two pedals and keep the same shrink (scale of the plot)
> breaks <- seq(0, 2 * pi, by = pi/6)
> breaks <- breaks[-2]
> out1<-windrose(sample, breaks=breaks, increment=50,main="The same but with two
pedals joined", shrink=res$shrink)
> #
> # change the rotation
> sample <- data.frame(dir=circular(dir, units="degrees", rotation="clock"),
mag=mag)
> out2<-windrose(sample, breaks=breaks,increment=50, main="Change the rotation",
shrink=res$shrink)
> 
> ## use geographics template
> sample <- data.frame(dir=circular(dir, units="degrees",
template="geographics"), mag=mag)
> out3<-windrose(sample, breaks=breaks, increment=50,main="Use the template
'geographics'", shrink=res$shrink)
> 

THESE are the output tables that seem to be incorrect (I'm sorry they're not
clearer):
> out1$table
               [0, 60) [60, 90) [90, 120) [120, 150) [150, 180) [180, 210) [210,
240) [240, 270) [270, 300) [300, 330) [330, 360)
>From 0 to 50       0.5        0         0          0          0          0      
   0          0          0          0          0
>From 50 to 100     0.5        0         0          0          0          0      
   0          0          0          0          0
> out2$table
               [0, 60) [60, 90) [90, 120) [120, 150) [150, 180) [180, 210) [210,
240) [240, 270) [270, 300) [300, 330) [330, 360)
>From 0 to 50         0        0         0          0          0          0      
   0          0          0          0        0.5
>From 50 to 100       0        0         0          0          0          0      
   0          0          0          0        0.5
> out3$table
               [0, 60) [60, 90) [90, 120) [120, 150) [150, 180) [180, 210) [210,
240) [240, 270) [270, 300) [300, 330) [330, 360)
>From 0 to 50         0      0.5         0          0          0          0      
   0          0          0          0          0
>From 50 to 100       0      0.5         0          0          0          0      
   0          0          0          0          0
> 


out1$table is correct. The data is all between 0-60degrees.
out2$table (changed rotation) is incorrect. The data are listed as being between
330-360degrees. 
Out3$table (geographic rotation) is incorrect. The data are listed as being
between 60-90degrees. 
Regardless of the rotation, the data should always be between 0-60degrees!

The problem only seems to occur when 'rotating' the plot.


From murdoch at stats.uwo.ca  Tue Nov 22 03:19:31 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Mon, 21 Nov 2005 21:19:31 -0500
Subject: [Rd] windrose (circular package) error in table (PR#8341)
In-Reply-To: <20051122015046.3E345103B8@slim.kubism.ku.dk>
References: <20051122015046.3E345103B8@slim.kubism.ku.dk>
Message-ID: <43828033.3070502@stats.uwo.ca>

On 11/21/2005 8:50 PM, Allyson.Williams at dpi.qld.gov.au wrote:
> Full_Name: Allyson Williams
> Version: 2.1.1
> OS: Windows XP
> Submission from: (NULL) (203.25.1.208)
> 
> 
> I'm using the 'Circular' package to plot windroses. I think the output table
> (see out2$table below) is incorrect when using different rotations. More
> precisely, when a rotation is used for the plot, the output table stuffs up.

Please send bug reports about contributed packages to the maintainer, 
Claudio Agostinelli <claudio at unive.it>.

Duncan Murdoch

> 
> This example is from the code in the help notes, although the input data (dir,
> mag) are changed):
> 
> 
>>dir <- c(1:50,1:50)
>>mag <-  c(1:100)
>>
>>sample <- data.frame(dir=circular(dir,units="degrees"), mag=mag)
>>
>>par(mfrow=c(2,2))
>>res <- windrose(sample)
>>
>>## we join two pedals and keep the same shrink (scale of the plot)
>>breaks <- seq(0, 2 * pi, by = pi/6)
>>breaks <- breaks[-2]
>>out1<-windrose(sample, breaks=breaks, increment=50,main="The same but with two
> 
> pedals joined", shrink=res$shrink)
> 
>>#
>># change the rotation
>>sample <- data.frame(dir=circular(dir, units="degrees", rotation="clock"),
> 
> mag=mag)
> 
>>out2<-windrose(sample, breaks=breaks,increment=50, main="Change the rotation",
> 
> shrink=res$shrink)
> 
>>## use geographics template
>>sample <- data.frame(dir=circular(dir, units="degrees",
> 
> template="geographics"), mag=mag)
> 
>>out3<-windrose(sample, breaks=breaks, increment=50,main="Use the template
> 
> 'geographics'", shrink=res$shrink)
> 
> 
> THESE are the output tables that seem to be incorrect (I'm sorry they're not
> clearer):
> 
>>out1$table
> 
>                [0, 60) [60, 90) [90, 120) [120, 150) [150, 180) [180, 210) [210,
> 240) [240, 270) [270, 300) [300, 330) [330, 360)
>>From 0 to 50       0.5        0         0          0          0          0      
>    0          0          0          0          0
>>From 50 to 100     0.5        0         0          0          0          0      
>    0          0          0          0          0
> 
>>out2$table
> 
>                [0, 60) [60, 90) [90, 120) [120, 150) [150, 180) [180, 210) [210,
> 240) [240, 270) [270, 300) [300, 330) [330, 360)
>>From 0 to 50         0        0         0          0          0          0      
>    0          0          0          0        0.5
>>From 50 to 100       0        0         0          0          0          0      
>    0          0          0          0        0.5
> 
>>out3$table
> 
>                [0, 60) [60, 90) [90, 120) [120, 150) [150, 180) [180, 210) [210,
> 240) [240, 270) [270, 300) [300, 330) [330, 360)
>>From 0 to 50         0      0.5         0          0          0          0      
>    0          0          0          0          0
>>From 50 to 100       0      0.5         0          0          0          0      
>    0          0          0          0          0
> 
> 
> 
> out1$table is correct. The data is all between 0-60degrees.
> out2$table (changed rotation) is incorrect. The data are listed as being between
> 330-360degrees. 
> Out3$table (geographic rotation) is incorrect. The data are listed as being
> between 60-90degrees. 
> Regardless of the rotation, the data should always be between 0-60degrees!
> 
> The problem only seems to occur when 'rotating' the plot.
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From buser at stat.math.ethz.ch  Tue Nov 22 08:50:57 2005
From: buser at stat.math.ethz.ch (Christoph Buser)
Date: Tue, 22 Nov 2005 08:50:57 +0100
Subject: [Rd] using a factor as col argument in plot:
In-Reply-To: <Pine.LNX.4.61.0511181703030.7151@gannet.stats>
References: <17278.894.547650.661337@stat.math.ethz.ch>
	<Pine.LNX.4.61.0511181703030.7151@gannet.stats>
Message-ID: <17282.52705.59318.72870@stat.math.ethz.ch>

Dear Prof. Ripley

Thank you for your reply and for changing the function in
R-devel. 
I've intended to ask my question in way 2) but I probably have
chosen a ambiguous formulation. :-)

Regards

Christoph Buser

--------------------------------------------------------------
Christoph Buser <buser at stat.math.ethz.ch>
Seminar fuer Statistik, LEO C13
ETH (Federal Inst. Technology)	8092 Zurich	 SWITZERLAND
phone: x-41-44-632-4673		fax: 632-1228
http://stat.ethz.ch/~buser/
--------------------------------------------------------------



Prof Brian Ripley writes:
 > On Fri, 18 Nov 2005, Christoph Buser wrote:
 > 
 > > Dear R core team
 > 
 > and R-devel-listers.
 > 
 > > Using the following code produces an empty plot (similar
 > > to col = NA):
 > >
 > >> plot(1:9, col = factor(rep(1:3,3), labels = c("red", "blue", "black")))
 > >
 > >
 > > My question: Shouldn't one get at least a warning (or an error)
 > > 	     if one tries to use a factor as col argument?
 > >
 > > Thanks for an answer.
 > 
 > I can read that two ways
 > 
 > 1) No, it should not give a warning, as it is programmed to take all
 > invalid values as 0.
 > 
 > 2) Is the way it is programmed sensible (yes) or desirable (no)?
 > 
 > The actual code is
 > 
 > /* Convert a sexp element to an R  color desc */
 > /* We Assume that Checks Have Been Done */
 > 
 > unsigned int RGBpar(SEXP x, int i)
 > {
 >      int indx;
 >      if(isString(x)) {
 >  	return str2col(CHAR(STRING_ELT(x, i)));
 >      }
 >      else if(isInteger(x) || isLogical(x)) {
 >  	if(INTEGER(x)[i] == NA_INTEGER)
 >  	    /*
 >  	     * Paul 01/07/04
 >  	     * Used to be set to NA_INTEGER (see comment in name2col).
 >  	     */
 >  	    return R_TRANWHITE;
 >  	indx = INTEGER(x)[i] - 1;
 >  	if(indx < 0) return Rf_dpptr(CurrentDevice())->bg;
 >  	else return R_ColorTable[indx % R_ColorTableSize];
 >      }
 >      else if(isReal(x)) {
 >  	if(!R_FINITE(REAL(x)[i]))
 >  	    /*
 >  	     * Paul 01/07/04
 >  	     * Used to be set to NA_INTEGER (see comment in name2col).
 >  	     */
 >  	    return R_TRANWHITE;
 >  	indx = REAL(x)[i] - 1;
 >  	if(indx < 0) return Rf_dpptr(CurrentDevice())->bg;
 >  	else return R_ColorTable[indx % R_ColorTableSize];
 >      }
 >      return 0;		/* should not occur */
 > }
 > 
 > but I could see no checks of type in any of the calling functions. Adding 
 > a warning would be a good idea.
 > 
 > 
 > -- 
 > Brian D. Ripley,                  ripley at stats.ox.ac.uk
 > Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
 > University of Oxford,             Tel:  +44 1865 272861 (self)
 > 1 South Parks Road,                     +44 1865 272866 (PA)
 > Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From maechler at stat.math.ethz.ch  Tue Nov 22 08:54:12 2005
From: maechler at stat.math.ethz.ch (maechler@stat.math.ethz.ch)
Date: Tue, 22 Nov 2005 08:54:12 +0100 (CET)
Subject: [Rd] (PR#8337)  formatC adds leading space -- on some Windoze
Message-ID: <20051122075412.87EA222367@slim.kubism.ku.dk>

>>>>> "KevinW" == Kevin Wright <kwright68 at gmail.com>
>>>>>     on Mon, 21 Nov 2005 18:13:36 +0100 (CET) writes:

    KevinW> Full_Name: Kevin Wright
    KevinW> Version: 2.2.0
    KevinW> OS: Windows 2000
	        ^^^^^^^
this must be part of the problem


    KevinW> Submission from: (NULL) (170.54.58.4)



    KevinW> Apologies if my expectations (or reading of the man page) are incorrect.  

    KevinW> I seem unable to left-justify exponential format
    KevinW> numbers.  There appears to always be an extra space
    KevinW> inserted to the left.

    KevinW> Using the example from the formatC help page:

    R> xx  <- pi * 10^(-5:4)

    R> cbind(formatC(xx, wid = 9, flag = "-"))
    KevinW>      [,1]        
    KevinW> [1,] " 3.142e-05"
    KevinW> [2,] "0.0003142" 
    KevinW> [3,] "0.003142 " 
    KevinW> [4,] "0.03142  " 
    KevinW> [5,] "0.3142   " 
    KevinW> [6,] "3.142    " 
    KevinW> [7,] "31.42    " 
    KevinW> [8,] "314.2    " 
    KevinW> [9,] "3142     " 
    KevinW> [10,] " 3.142e+04"

which is also not obeying the 'wid' argument.

I get something much more reasonable:

      [,1]       
 [1,] "3.142e-05"
 [2,] "0.0003142"
 [3,] "0.003142 "
 [4,] "0.03142  "
 [5,] "0.3142   "
 [6,] "3.142    "
 [7,] "31.42    "
 [8,] "314.2    "
 [9,] "3142     "
[10,] "3.142e+04"

formatC uses your system's C library printf {that's where the
"C" comes from in 'formatC'} which seems to be
broken or at least not performing as we think it should.

On a "Windows 2003 Server" I have access to, I see the same
wrong behavior as above.

Martin Maechler, ETH Zurich


From ripley at stats.ox.ac.uk  Tue Nov 22 09:35:19 2005
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Tue, 22 Nov 2005 09:35:19 +0100 (CET)
Subject: [Rd] (PR#8337)  formatC adds leading space -- on some Windoze
Message-ID: <20051122083519.035741E092@slim.kubism.ku.dk>

On Tue, 22 Nov 2005 maechler at stat.math.ethz.ch wrote:

>>>>>> "KevinW" == Kevin Wright <kwright68 at gmail.com>
>>>>>>     on Mon, 21 Nov 2005 18:13:36 +0100 (CET) writes:
>
>    KevinW> Full_Name: Kevin Wright
>    KevinW> Version: 2.2.0
>    KevinW> OS: Windows 2000
> 	        ^^^^^^^
> this must be part of the problem

It is, and it is a known inconsistency with Linux (but I do not consider 
it to be a bug or `wrong behavior' or not `reasonable').

Windows always uses three digits for the exponent, e.g. E+001. This 
results from adjusting the returned result to be more consistent with 
other platforms.  (BTW, since width (sic) is a lower bound, it _is_ 
respected.)  Even if the layout is not ideal, the results are at least 
diff-able against those from other platforms.

If Kevin (or anyone else) wants it done even more consistently, he could 
contribute a patch.  Now, we _have_ done that for print(), but it did not 
seem worth it for formatC (especially as sprintf() is now widely used and 
would also need to be made consistent). (It also did not seem worth it 
given how little credit is given for such work.)


>    KevinW> Submission from: (NULL) (170.54.58.4)
>
>
>
>    KevinW> Apologies if my expectations (or reading of the man page) are incorrect.
>
>    KevinW> I seem unable to left-justify exponential format
>    KevinW> numbers.  There appears to always be an extra space
>    KevinW> inserted to the left.
>
>    KevinW> Using the example from the formatC help page:
>
>    R> xx  <- pi * 10^(-5:4)
>
>    R> cbind(formatC(xx, wid = 9, flag = "-"))
>    KevinW>      [,1]
>    KevinW> [1,] " 3.142e-05"
>    KevinW> [2,] "0.0003142"
>    KevinW> [3,] "0.003142 "
>    KevinW> [4,] "0.03142  "
>    KevinW> [5,] "0.3142   "
>    KevinW> [6,] "3.142    "
>    KevinW> [7,] "31.42    "
>    KevinW> [8,] "314.2    "
>    KevinW> [9,] "3142     "
>    KevinW> [10,] " 3.142e+04"
>
> which is also not obeying the 'wid' argument.
>
> I get something much more reasonable:
>
>      [,1]
> [1,] "3.142e-05"
> [2,] "0.0003142"
> [3,] "0.003142 "
> [4,] "0.03142  "
> [5,] "0.3142   "
> [6,] "3.142    "
> [7,] "31.42    "
> [8,] "314.2    "
> [9,] "3142     "
> [10,] "3.142e+04"
>
> formatC uses your system's C library printf {that's where the
> "C" comes from in 'formatC'} which seems to be
> broken or at least not performing as we think it should.
>
> On a "Windows 2003 Server" I have access to, I see the same
> wrong behavior as above.
>
> Martin Maechler, ETH Zurich
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Tue Nov 22 10:10:45 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 22 Nov 2005 09:10:45 +0000 (GMT)
Subject: [Rd] NAMESPACE, S4, and .onLoad
In-Reply-To: <m2veylzop6.fsf@fhcrc.org>
References: <m2veylzop6.fsf@fhcrc.org>
Message-ID: <Pine.LNX.4.61.0511212141090.13616@gannet.stats>

On Mon, 21 Nov 2005, Seth Falcon wrote:

> The Writing R Extensions manual instructs developers who use S4
> classes and methods in a package with a name space to:
>
>    There needs to be an .onLoad action to ensure that the methods package
>    is loaded and attached:
>
>         .onLoad <- function(lib, pkg) require(methods)
>
> I'm wondering if listing methods in the Depends field of the package's
> DESCRIPTION file is sufficient.  My understanding is that doing so
> will result in the methods package being loaded and attached.

It will do so when the _package_ is loaded, but not when its _namespace_ 
is loaded.  So the advice is correct, as it is always possible that other 
packages will load your package's namespace (via imports) and not 
themselves depend on the 'methods' package and be used in a session with 
a non-default set of packages including 'methods'.  (This is unlikely, of 
course, which is why this may elude detection.)

At one time (and it may still be so) loading the 'methods' namespace and 
not the 'methods' package left R in an internally inconsistent state. 
When I discussed this with John Chambers, his preference was that the 
'methods' package be loaded and attached whenever S4 methods are in use. 
The advice does reflect that (rather than, say, advising that the 
'methods' namespace be imported.)

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ahenningsen at email.uni-kiel.de  Tue Nov 22 10:25:14 2005
From: ahenningsen at email.uni-kiel.de (ahenningsen@email.uni-kiel.de)
Date: Tue, 22 Nov 2005 10:25:14 +0100 (CET)
Subject: [Rd] make check fails for R 2.3.0 (PR#8343)
Message-ID: <20051122092514.07D291E025@slim.kubism.ku.dk>

Full_Name: Arne Henningsen
Version: 2.3.0, 2005-11-21, i686-pc-linux-gnu
OS: SuSE Linux 9.0, Kernel 2.4.21
Submission from: (NULL) (134.245.140.242)


I did not find any problems in "./configure" and "make", but "make check"
fails:

make[4]: Entering directory `/home/suapm095/Download/R-devel/tests/Examples'
collecting examples for package 'base' ...
make[5]: Entering directory `/home/suapm095/Download/R-devel/src/library'
 >>> Building/Updating help pages for package 'base'
     Formats: text html latex example
make[5]: Leaving directory `/home/suapm095/Download/R-devel/src/library'
running code in 'base-Ex.R' ...make[4]: *** [base-Ex.Rout] Fehler 1
make[4]: Leaving directory `/home/suapm095/Download/R-devel/tests/Examples'
make[3]: *** [test-Examples-Base] Fehler 2
make[3]: Leaving directory `/home/suapm095/Download/R-devel/tests/Examples'
make[2]: *** [test-Examples] Fehler 2
make[2]: Leaving directory `/home/suapm095/Download/R-devel/tests'
make[1]: *** [test-all-basics] Fehler 1
make[1]: Leaving directory `/home/suapm095/Download/R-devel/tests'
make: *** [check] Fehler 2


At the end of the file "tests/Examples/base-Ex.Rout.fail" I found:

> i39 <- sapply(3:9, seq) # list of vectors
> sapply(i39, fivenum)
     [,1] [,2] [,3] [,4] [,5] [,6] [,7]
[1,]  1.0  1.0    1  1.0  1.0  1.0    1
[2,]  1.5  1.5    2  2.0  2.5  2.5    3
[3,]  2.0  2.5    3  3.5  4.0  4.5    5
[4,]  2.5  3.5    4  5.0  5.5  6.5    7
[5,]  3.0  4.0    5  6.0  7.0  8.0    9
> 
> hist(replicate(100, mean(rexp(10))))
Fehler in hist.default(replicate(100, mean(rexp(10)))) : 
	invalid number of 'breaks'
Ausf?hrung angehalten


From ripley at stats.ox.ac.uk  Tue Nov 22 12:55:49 2005
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Tue, 22 Nov 2005 12:55:49 +0100 (CET)
Subject: [Rd] make check fails for R 2.3.0 (PR#8343)
Message-ID: <20051122115549.D1ECA23202@slim.kubism.ku.dk>

  This message is in MIME format.  The first part should be readable text,
  while the remaining parts are likely unreadable without MIME-aware tools.

--27464147-1978628741-1132653680=:25449
Content-Type: TEXT/PLAIN; CHARSET=ISO-8859-1; format=flowed
Content-Transfer-Encoding: QUOTED-PRINTABLE
Content-ID: <Pine.LNX.4.61.0511221102121.26494 at gannet.stats>

On Tue, 22 Nov 2005 ahenningsen at email.uni-kiel.de wrote:

> Full_Name: Arne Henningsen
> Version: 2.3.0, 2005-11-21, i686-pc-linux-gnu

Please use the svn revision for unreleased versions of R.  There is no 'R=
=20
2.3.0' and the version changes several times a day.  But we do expect=20
'make check' to have been run successfully on each of those versions.

> OS: SuSE Linux 9.0, Kernel 2.4.21
> Submission from: (NULL) (134.245.140.242)

You are reporting as a bug in R a problem on your own system in an=20
unreleased ('unstable') version of R.  Since it is unstable and=20
unreleased, such things are by definition not bugs in R.

Others are not seeing this, so we cannot do anything about the problems=20
seen on your system.  This is not at all a new test, and although random=20
it is run with set.seed(1). I can reproduce the result in the output file=
=20
(on my systems) exactly by

> set.seed(1)
> hist(replicate(100, mean(rexp(10))))

Please see if you can debug it on your own system.  (My guess would be=20
that it only occurs as part of the test file.)

> I did not find any problems in "./configure" and "make", but "make check"
> fails:
>
> make[4]: Entering directory `/home/suapm095/Download/R-devel/tests/Exampl=
es'
> collecting examples for package 'base' ...
> make[5]: Entering directory `/home/suapm095/Download/R-devel/src/library'
> >>> Building/Updating help pages for package 'base'
>     Formats: text html latex example
> make[5]: Leaving directory `/home/suapm095/Download/R-devel/src/library'
> running code in 'base-Ex.R' ...make[4]: *** [base-Ex.Rout] Fehler 1
> make[4]: Leaving directory `/home/suapm095/Download/R-devel/tests/Example=
s'
> make[3]: *** [test-Examples-Base] Fehler 2
> make[3]: Leaving directory `/home/suapm095/Download/R-devel/tests/Example=
s'
> make[2]: *** [test-Examples] Fehler 2
> make[2]: Leaving directory `/home/suapm095/Download/R-devel/tests'
> make[1]: *** [test-all-basics] Fehler 1
> make[1]: Leaving directory `/home/suapm095/Download/R-devel/tests'
> make: *** [check] Fehler 2
>
>
> At the end of the file "tests/Examples/base-Ex.Rout.fail" I found:
>
>> i39 <- sapply(3:9, seq) # list of vectors
>> sapply(i39, fivenum)
>     [,1] [,2] [,3] [,4] [,5] [,6] [,7]
> [1,]  1.0  1.0    1  1.0  1.0  1.0    1
> [2,]  1.5  1.5    2  2.0  2.5  2.5    3
> [3,]  2.0  2.5    3  3.5  4.0  4.5    5
> [4,]  2.5  3.5    4  5.0  5.5  6.5    7
> [5,]  3.0  4.0    5  6.0  7.0  8.0    9
>>
>> hist(replicate(100, mean(rexp(10))))
> Fehler in hist.default(replicate(100, mean(rexp(10)))) :
> =09invalid number of 'breaks'
> Ausf=FChrung angehalten

--=20
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595
--27464147-1978628741-1132653680=:25449--


From kugelfang at gentoo.org  Tue Nov 22 15:50:25 2005
From: kugelfang at gentoo.org (kugelfang@gentoo.org)
Date: Tue, 22 Nov 2005 15:50:25 +0100 (CET)
Subject: [Rd] [PATCH] Add fpicflags for Intel(R) Fortran Compiler (PR#8344)
Message-ID: <20051122145025.4837FCA08@slim.kubism.ku.dk>

Full_Name: Danny van Dyk
Version: R-2.2.0
OS: Gentoo/AMD64
Submission from: (NULL) (83.129.50.65)


I have successfully compiled R-2.2.0 using ifc-9.0.026 on my x86_64 box.
The only (minor) change that hade to be made was adding fpicflags="-fPIC" to
configure.ac in case F77 matches either "ifc" (old name) or "ifort" (new name).

Please apply following patch:

dvandyk at phi trunk $ svn diff
        Index: configure.ac
===================================================================
--- configure.ac        (revision 36420)
+++ configure.ac        (working copy)
@@ -942,7 +942,7 @@
   rm -f Imakefile Makefile
 fi

-## Step 2.  GNU compilers.
+## Step 2.  GNU and Intel compilers.
 if test "${GCC}" = yes; then
   cpicflags="-fPIC"
   shlib_ldflags="-shared"
@@ -954,6 +954,11 @@
   cxxpicflags="-fPIC"
   shlib_cxxldflags="-shared"
 fi
+case "${F77}" in
+  ifc|ifort)
+    fpicflags="-fPIC"
+    ;;
+esac

 ## Step 3.  Individual platform overrides.
 case "${host_os}" in
===================================================================

Danny


From ahenningsen at email.uni-kiel.de  Tue Nov 22 16:19:19 2005
From: ahenningsen at email.uni-kiel.de (Arne Henningsen)
Date: Tue, 22 Nov 2005 16:19:19 +0100
Subject: [Rd] make check fails for R 2.3.0 (PR#8343)
In-Reply-To: <20051122115549.D1ECA23202@slim.kubism.ku.dk>
References: <20051122115549.D1ECA23202@slim.kubism.ku.dk>
Message-ID: <200511221619.20016.ahenningsen@email.uni-kiel.de>

On Tuesday 22 November 2005 12:55, ripley at stats.ox.ac.uk wrote:
>   This message is in MIME format.  The first part should be readable text,
>   while the remaining parts are likely unreadable without MIME-aware tools.
>
> --27464147-1978628741-1132653680=:25449
> Content-Type: TEXT/PLAIN; CHARSET=ISO-8859-1; format=flowed
> Content-Transfer-Encoding: QUOTED-PRINTABLE
> Content-ID: <Pine.LNX.4.61.0511221102121.26494 at gannet.stats>
>
> On Tue, 22 Nov 2005 ahenningsen at email.uni-kiel.de wrote:
> > Full_Name: Arne Henningsen
> > Version: 2.3.0, 2005-11-21, i686-pc-linux-gnu
>
> Please use the svn revision for unreleased versions of R.  

OK. I have done this, but the same error still occurs.

> There is no 'R= =20
> 2.3.0' and the version changes several times a day.  But we do expect=20
> 'make check' to have been run successfully on each of those versions.
>
> > OS: SuSE Linux 9.0, Kernel 2.4.21
> > Submission from: (NULL) (134.245.140.242)
>
> You are reporting as a bug in R a problem on your own system in an=20
> unreleased ('unstable') version of R.  

I used this version to check my R packages because the packages on CRAN are 
checked by R-devel, too.

> Since it is unstable and=20 
> unreleased, such things are by definition not bugs in R.

Sorry, I did not know this. I thought that my report could help you. 
The next time when I will find an error in R-devel I won't report it.

> Others are not seeing this, so we cannot do anything about the problems=20
> seen on your system.  This is not at all a new test, and although random=20
> it is run with set.seed(1). I can reproduce the result in the output file=
> =20
> (on my systems) exactly by
>
> > set.seed(1)
> > hist(replicate(100, mean(rexp(10))))
>
> Please see if you can debug it on your own system.  (My guess would be=20
> that it only occurs as part of the test file.)

Yes, that's exactly the case. If you want any further information please don't 
hesitate to contact me. Otherwise I won't bother you anymore with this issue.

Best,
Arne

> > I did not find any problems in "./configure" and "make", but "make check"
> > fails:
> >
> > make[4]: Entering directory
> > `/home/suapm095/Download/R-devel/tests/Exampl=
>
> es'
>
> > collecting examples for package 'base' ...
> > make[5]: Entering directory `/home/suapm095/Download/R-devel/src/library'
> >
> > >>> Building/Updating help pages for package 'base'
> >
> >     Formats: text html latex example
> > make[5]: Leaving directory `/home/suapm095/Download/R-devel/src/library'
> > running code in 'base-Ex.R' ...make[4]: *** [base-Ex.Rout] Fehler 1
> > make[4]: Leaving directory
> > `/home/suapm095/Download/R-devel/tests/Example=
>
> s'
>
> > make[3]: *** [test-Examples-Base] Fehler 2
> > make[3]: Leaving directory
> > `/home/suapm095/Download/R-devel/tests/Example=
>
> s'
>
> > make[2]: *** [test-Examples] Fehler 2
> > make[2]: Leaving directory `/home/suapm095/Download/R-devel/tests'
> > make[1]: *** [test-all-basics] Fehler 1
> > make[1]: Leaving directory `/home/suapm095/Download/R-devel/tests'
> > make: *** [check] Fehler 2
> >
> > At the end of the file "tests/Examples/base-Ex.Rout.fail" I found:
> >> i39 <- sapply(3:9, seq) # list of vectors
> >> sapply(i39, fivenum)
> >
> >     [,1] [,2] [,3] [,4] [,5] [,6] [,7]
> > [1,]  1.0  1.0    1  1.0  1.0  1.0    1
> > [2,]  1.5  1.5    2  2.0  2.5  2.5    3
> > [3,]  2.0  2.5    3  3.5  4.0  4.5    5
> > [4,]  2.5  3.5    4  5.0  5.5  6.5    7
> > [5,]  3.0  4.0    5  6.0  7.0  8.0    9
> >
> >> hist(replicate(100, mean(rexp(10))))
> >
> > Fehler in hist.default(replicate(100, mean(rexp(10)))) :
> > =09invalid number of 'breaks'
> > Ausf=FChrung angehalten
>
> --=20
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> --27464147-1978628741-1132653680=:25449--
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Arne Henningsen
Department of Agricultural Economics
University of Kiel
Olshausenstr. 40
D-24098 Kiel (Germany)
Tel: +49-431-880 4445
Fax: +49-431-880 1397
ahenningsen at agric-econ.uni-kiel.de
http://www.uni-kiel.de/agrarpol/ahenningsen/


From ahenningsen at email.uni-kiel.de  Tue Nov 22 16:19:43 2005
From: ahenningsen at email.uni-kiel.de (ahenningsen@email.uni-kiel.de)
Date: Tue, 22 Nov 2005 16:19:43 +0100 (CET)
Subject: [Rd] make check fails for R 2.3.0 (PR#8343)
Message-ID: <20051122151943.16F9285D3@slim.kubism.ku.dk>

On Tuesday 22 November 2005 12:55, ripley at stats.ox.ac.uk wrote:
>   This message is in MIME format.  The first part should be readable text,
>   while the remaining parts are likely unreadable without MIME-aware tools.
>
> --27464147-1978628741-1132653680=:25449
> Content-Type: TEXT/PLAIN; CHARSET=ISO-8859-1; format=flowed
> Content-Transfer-Encoding: QUOTED-PRINTABLE
> Content-ID: <Pine.LNX.4.61.0511221102121.26494 at gannet.stats>
>
> On Tue, 22 Nov 2005 ahenningsen at email.uni-kiel.de wrote:
> > Full_Name: Arne Henningsen
> > Version: 2.3.0, 2005-11-21, i686-pc-linux-gnu
>
> Please use the svn revision for unreleased versions of R.  

OK. I have done this, but the same error still occurs.

> There is no 'R= =20
> 2.3.0' and the version changes several times a day.  But we do expect=20
> 'make check' to have been run successfully on each of those versions.
>
> > OS: SuSE Linux 9.0, Kernel 2.4.21
> > Submission from: (NULL) (134.245.140.242)
>
> You are reporting as a bug in R a problem on your own system in an=20
> unreleased ('unstable') version of R.  

I used this version to check my R packages because the packages on CRAN are 
checked by R-devel, too.

> Since it is unstable and=20 
> unreleased, such things are by definition not bugs in R.

Sorry, I did not know this. I thought that my report could help you. 
The next time when I will find an error in R-devel I won't report it.

> Others are not seeing this, so we cannot do anything about the problems=20
> seen on your system.  This is not at all a new test, and although random=20
> it is run with set.seed(1). I can reproduce the result in the output file=
> =20
> (on my systems) exactly by
>
> > set.seed(1)
> > hist(replicate(100, mean(rexp(10))))
>
> Please see if you can debug it on your own system.  (My guess would be=20
> that it only occurs as part of the test file.)

Yes, that's exactly the case. If you want any further information please don't 
hesitate to contact me. Otherwise I won't bother you anymore with this issue.

Best,
Arne

> > I did not find any problems in "./configure" and "make", but "make check"
> > fails:
> >
> > make[4]: Entering directory
> > `/home/suapm095/Download/R-devel/tests/Exampl=
>
> es'
>
> > collecting examples for package 'base' ...
> > make[5]: Entering directory `/home/suapm095/Download/R-devel/src/library'
> >
> > >>> Building/Updating help pages for package 'base'
> >
> >     Formats: text html latex example
> > make[5]: Leaving directory `/home/suapm095/Download/R-devel/src/library'
> > running code in 'base-Ex.R' ...make[4]: *** [base-Ex.Rout] Fehler 1
> > make[4]: Leaving directory
> > `/home/suapm095/Download/R-devel/tests/Example=
>
> s'
>
> > make[3]: *** [test-Examples-Base] Fehler 2
> > make[3]: Leaving directory
> > `/home/suapm095/Download/R-devel/tests/Example=
>
> s'
>
> > make[2]: *** [test-Examples] Fehler 2
> > make[2]: Leaving directory `/home/suapm095/Download/R-devel/tests'
> > make[1]: *** [test-all-basics] Fehler 1
> > make[1]: Leaving directory `/home/suapm095/Download/R-devel/tests'
> > make: *** [check] Fehler 2
> >
> > At the end of the file "tests/Examples/base-Ex.Rout.fail" I found:
> >> i39 <- sapply(3:9, seq) # list of vectors
> >> sapply(i39, fivenum)
> >
> >     [,1] [,2] [,3] [,4] [,5] [,6] [,7]
> > [1,]  1.0  1.0    1  1.0  1.0  1.0    1
> > [2,]  1.5  1.5    2  2.0  2.5  2.5    3
> > [3,]  2.0  2.5    3  3.5  4.0  4.5    5
> > [4,]  2.5  3.5    4  5.0  5.5  6.5    7
> > [5,]  3.0  4.0    5  6.0  7.0  8.0    9
> >
> >> hist(replicate(100, mean(rexp(10))))
> >
> > Fehler in hist.default(replicate(100, mean(rexp(10)))) :
> > =09invalid number of 'breaks'
> > Ausf=FChrung angehalten
>
> --=20
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> --27464147-1978628741-1132653680=:25449--
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Arne Henningsen
Department of Agricultural Economics
University of Kiel
Olshausenstr. 40
D-24098 Kiel (Germany)
Tel: +49-431-880 4445
Fax: +49-431-880 1397
ahenningsen at agric-econ.uni-kiel.de
http://www.uni-kiel.de/agrarpol/ahenningsen/


From andy_liaw at merck.com  Tue Nov 22 16:26:06 2005
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue, 22 Nov 2005 10:26:06 -0500
Subject: [Rd] make check fails for R 2.3.0 (PR#8343)
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED5DC@usctmx1106.merck.com>

From: ahenningsen at email.uni-kiel.de
> 
> On Tuesday 22 November 2005 12:55, ripley at stats.ox.ac.uk wrote:
[snip]
> > Since it is unstable and=20 
> > unreleased, such things are by definition not bugs in R.
> 
> Sorry, I did not know this. I thought that my report could help you. 
> The next time when I will find an error in R-devel I won't report it.

I do not believe that's the intention.  Problem with building R-devel should
be reported, but as post to R-devel (the list), rather than filed as bug
report.

Andy


From imosqueira at suk.azti.es  Tue Nov 22 17:19:57 2005
From: imosqueira at suk.azti.es (Iago Mosqueira)
Date: Tue, 22 Nov 2005 17:19:57 +0100
Subject: [Rd] install.packages in R 2.2.0
Message-ID: <1132676397.7936.159.camel@patudo.azti.local>

Dear all,

I am having trouble with install.packages() when specifying a non-CRAN
repository. The command below works in R 2.1.0 and R 2.1.1 compiled from
source in Linux, bringing up the Tcl/Tk interface for selection, but in
2.2.0 I get

> install.packages(repos='http://flr-project.org/R')
Error in install.packages(repos = "http://flr-project.org/R") : 
        argument "pkgs" is missing, with no default
In addition: Warning message:
number of rows of result
        is not a multiple of vector length (arg 2) in: cbind(1, res0,
Repository = repos) 

Has there been any change to this function, or the way repositories
should be organised, that I have missed in the NEWS file?

For example, a package file called FLCore_1.0.7.tar.gz is located in
http://flr-project/R/src/contrib/ and the relevant entry in the PCAKGEs
file looks like this:

Package: FLCore
Version: 1.0.7
Depends: R (>=2.2.0), methods, graphics, stats, lattice

but install.packages from R 2.2.0 is not getting to it.

In contrast, The FLCore_1.0.3.3.tar.gz file, with entry

Package: FLCore
Version: 1.0.3.3
Depends: R (>=2.1.0), methods, graphics, stats, lattice

gets picked up when install.packages is called from R 2.1.1. There are
other packages in this repository that do not have versions dependent on
R version, but still the same problem appears.

Any ideas? Thanks very much,


Iago Mosqueira


From ripley at stats.ox.ac.uk  Tue Nov 22 17:31:44 2005
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Tue, 22 Nov 2005 17:31:44 +0100 (CET)
Subject: [Rd] [PATCH] Add fpicflags for Intel(R) Fortran Compiler
	(PR#8344)
Message-ID: <20051122163144.5D71E1E33A@slim.kubism.ku.dk>

1) The documented way to specify this is to set FPICFLAGS in config.site: 
see the example in R-admin for the PG compilers.  When you tried that, 
what went wrong?

2) It seems strange to specify this for the Fortran compiler and not the C 
or C++ compiler.

3) You have suggested the change to a section for all OSes.  Do you know 
for sure that all compilers called 'ifort' on all OSes need the -fPIC 
flag?  Or is it really just for Linux (and AFAICS, just x86_64 Linux, as 
i386 Linux seems to work with icc/ifort without it).

On Tue, 22 Nov 2005 kugelfang at gentoo.org wrote:

> Full_Name: Danny van Dyk
> Version: R-2.2.0
> OS: Gentoo/AMD64
> Submission from: (NULL) (83.129.50.65)
>
>
> I have successfully compiled R-2.2.0 using ifc-9.0.026 on my x86_64 box.
> The only (minor) change that hade to be made was adding fpicflags="-fPIC" to
> configure.ac in case F77 matches either "ifc" (old name) or "ifort" (new name).
>
> Please apply following patch:
>
> dvandyk at phi trunk $ svn diff
>        Index: configure.ac
> ===================================================================
> --- configure.ac        (revision 36420)
> +++ configure.ac        (working copy)
> @@ -942,7 +942,7 @@
>   rm -f Imakefile Makefile
> fi
>
> -## Step 2.  GNU compilers.
> +## Step 2.  GNU and Intel compilers.
> if test "${GCC}" = yes; then
>   cpicflags="-fPIC"
>   shlib_ldflags="-shared"
> @@ -954,6 +954,11 @@
>   cxxpicflags="-fPIC"
>   shlib_cxxldflags="-shared"
> fi
> +case "${F77}" in
> +  ifc|ifort)
> +    fpicflags="-fPIC"
> +    ;;
> +esac
>
> ## Step 3.  Individual platform overrides.
> case "${host_os}" in
> ===================================================================
>
> Danny
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From maechler at stat.math.ethz.ch  Tue Nov 22 17:34:34 2005
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 22 Nov 2005 17:34:34 +0100
Subject: [Rd] make check fails for R 2.3.0 (PR#8343)
In-Reply-To: <200511221619.20016.ahenningsen@email.uni-kiel.de>
References: <20051122115549.D1ECA23202@slim.kubism.ku.dk>
	<200511221619.20016.ahenningsen@email.uni-kiel.de>
Message-ID: <17283.18586.384788.982523@stat.math.ethz.ch>

>>>>> "Arne" == Arne Henningsen <ahenningsen at email.uni-kiel.de>
>>>>>     on Tue, 22 Nov 2005 16:19:19 +0100 writes:

    .....

    >> You are reporting as a bug in R a problem on your own system in an=20
    >> unreleased ('unstable') version of R.  

    Arne> I used this version to check my R packages because the
    Arne> packages on CRAN are checked by R-devel, too.

    >> Since it is unstable and
    >> unreleased, such things are by definition not bugs in R.

    Arne> Sorry, I did not know this. I thought that my report could help you. 
    Arne> The next time when I will find an error in R-devel I won't report it.

No; please do "report" the problem, which may be useful for
development, but please do *NOT* use the bug repository, and
probably don't assume it's a bug in R, unless you have quite a
bit experience about R bugs and non-bugs.

Instead, just send e-mail to R-devel and explain,
and you may actually helping R development, particularly if you
are willing to investigate some details that we ma ask you
about.


    >> Others are not seeing this, so we cannot do anything
    >> about the problems=20 seen on your system.  This is not
    >> at all a new test, and although random=20 it is run with
    >> set.seed(1). I can reproduce the result in the output
    >> file= =20 (on my systems) exactly by
    >> 
    >> > set.seed(1)
    >> > hist(replicate(100, mean(rexp(10))))
    >> 
    >> Please see if you can debug it on your own system.  (My guess would be=20
    >> that it only occurs as part of the test file.)

    Arne> Yes, that's exactly the case. If you want any further
    Arne> information please don't hesitate to contact
    Arne> me. Otherwise I won't bother you anymore with this
    Arne> issue.

Too bad.
It might have been interesting to see what

 set.seed(1)
 replicate(100, mean(rexp(10)))

or also

 set.seed(1)
 hist(replicate(100, mean(rexp(10))))
 traceback()
 ##^^^^^^^^^

gives on your R-devel installation.
That's why Brian Ripley helped you by mentioning 'set.seed(1)'.

Regards,
Martin Maechler, ETH Zurich


From ahenningsen at email.uni-kiel.de  Tue Nov 22 18:37:09 2005
From: ahenningsen at email.uni-kiel.de (Arne Henningsen)
Date: Tue, 22 Nov 2005 18:37:09 +0100
Subject: [Rd] make check fails for R 2.3.0 (PR#8343)
In-Reply-To: <17283.18586.384788.982523@stat.math.ethz.ch>
References: <20051122115549.D1ECA23202@slim.kubism.ku.dk>
	<200511221619.20016.ahenningsen@email.uni-kiel.de>
	<17283.18586.384788.982523@stat.math.ethz.ch>
Message-ID: <200511221837.09387.ahenningsen@email.uni-kiel.de>

On Tuesday 22 November 2005 17:34, Martin Maechler wrote:
> >>>>> "Arne" == Arne Henningsen <ahenningsen at email.uni-kiel.de>
> >>>>>     on Tue, 22 Nov 2005 16:19:19 +0100 writes:
>
>     .....
>
>     >> You are reporting as a bug in R a problem on your own system in
>     >> an=20 unreleased ('unstable') version of R.
>
>     Arne> I used this version to check my R packages because the
>     Arne> packages on CRAN are checked by R-devel, too.
>
>     >> Since it is unstable and
>     >> unreleased, such things are by definition not bugs in R.
>
>     Arne> Sorry, I did not know this. I thought that my report could help
> you. Arne> The next time when I will find an error in R-devel I won't
> report it.
>
> No; please do "report" the problem, which may be useful for
> development, but please do *NOT* use the bug repository, and
> probably don't assume it's a bug in R, unless you have quite a
> bit experience about R bugs and non-bugs.
>
> Instead, just send e-mail to R-devel and explain,
> and you may actually helping R development, particularly if you
> are willing to investigate some details that we ma ask you
> about.
>
>     >> Others are not seeing this, so we cannot do anything
>     >> about the problems=20 seen on your system.  This is not
>     >> at all a new test, and although random=20 it is run with
>     >> set.seed(1). I can reproduce the result in the output
>     >> file= =20 (on my systems) exactly by
>     >>
>     >> > set.seed(1)
>     >> > hist(replicate(100, mean(rexp(10))))
>     >>
>     >> Please see if you can debug it on your own system.  (My guess would
>     >> be=20 that it only occurs as part of the test file.)
>
>     Arne> Yes, that's exactly the case. If you want any further
>     Arne> information please don't hesitate to contact
>     Arne> me. Otherwise I won't bother you anymore with this
>     Arne> issue.
>
> Too bad.
> It might have been interesting to see what
>
>  set.seed(1)
>  replicate(100, mean(rexp(10)))
>
> or also
>
>  set.seed(1)
>  hist(replicate(100, mean(rexp(10))))
>  traceback()
>  ##^^^^^^^^^
>
> gives on your R-devel installation.
> That's why Brian Ripley helped you by mentioning 'set.seed(1)'.

It is exactly as Brian Ripley said: If I just start R and execute
   set.seed(1)
   hist(replicate(100, mean(rexp(10))))
everything works well. However, if I run "make check" the error occurs.
Now I have tried something inbetween: I started R and source()d the file that 
caused the error. The error occured again:
R> sink("base-Ex.Rout")
R> source("tests/Examples/base-Ex.R",echo=TRUE)
Warnung in gamma(x) :NaNs wurden erzeugt
Warnung in gamma(x) :NaNs wurden erzeugt
Warnung in gamma(x) :NaNs wurden erzeugt
Fehler in assign("y", 2, env = e) : kann keine Bindungen zu einer 
abgeschlossenen Umgebung hinzuf?gen
Fehler in assign("x", 2, env = e) : kann den Wert einer festgestellten Bindung 
nicht ?ndern
Warnung in cbind(1, 1:7, diag(3)) :number of rows of result
        is not a multiple of vector length (arg 1)
Warnung in cbind(1, 0, matrix(1, nrow = 0, ncol = 4)) :
         number of rows of result
        is not a multiple of vector length (arg 1)
Warnung in withCallingHandlers({ :A
Warnung in data.matrix(DF) :Klasseninformation f?r eine oder mehrere Spalten 
verloren
Garbage collection 25 = 17+1+7 (level 2) ...
221048 cons cells free (47%)
10.2 Mbytes of heap free (90%)
Warnung in sqrt(x) :NaNs wurden erzeugt
Warnung in sqrt(x) :NaNs wurden erzeugt
Warnung in sin(Inf) :NaNs wurden erzeugt
Warnung in cos(Inf) :NaNs wurden erzeugt
Warnung in tan(Inf) :NaNs wurden erzeugt
Fehler in hist.default(replicate(100, mean(rexp(10)))) :
        invalid number of 'breaks'


Then I typed
R> traceback()
6: stop("invalid number of 'breaks'")
5: hist.default(replicate(100, mean(rexp(10))))
4: hist(replicate(100, mean(rexp(10))))
3: eval.with.vis(expr, envir, enclos)
2: eval.with.vis(ei, envir)
1: source("tests/Examples/base-Ex.R")

After sourcing this file it is impossible to use hist() because always the 
same error message occurs:
R> hist(rnorm(55))
Fehler in hist.default(rnorm(55)) : invalid number of 'breaks'
R> traceback()
3: stop("invalid number of 'breaks'")
2: hist.default(rnorm(55))
1: hist(rnorm(55))
R> hist(c(1,2,2))
Fehler in hist.default(c(1, 2, 2)) : invalid number of 'breaks'
R> traceback()
3: stop("invalid number of 'breaks'")
2: hist.default(c(1, 2, 2))
1: hist(c(1, 2, 2))

This seems to be independent from argument x (the values).

Cheers,
Arne

> Regards,
> Martin Maechler, ETH Zurich
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Arne Henningsen
Department of Agricultural Economics
University of Kiel
Olshausenstr. 40
D-24098 Kiel (Germany)
Tel: +49-431-880 4445
Fax: +49-431-880 1397
ahenningsen at agric-econ.uni-kiel.de
http://www.uni-kiel.de/agrarpol/ahenningsen/


From kugelfang at gentoo.org  Tue Nov 22 18:58:52 2005
From: kugelfang at gentoo.org (kugelfang@gentoo.org)
Date: Tue, 22 Nov 2005 18:58:52 +0100 (CET)
Subject: [Rd] [PATCH] Add fpicflags for Intel(R) Fortran Compiler
	(PR#8344)
Message-ID: <20051122175852.5FA6185D3@slim.kubism.ku.dk>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

Dear Prof. Ripley,

Prof Brian Ripley schrieb:
| 1) The documented way to specify this is to set FPICFLAGS in
| config.site: see the example in R-admin for the PG compilers.  When you
| tried that, what went wrong?
Nothing went wrong. However, I was of the opinion that support of
ifc/ifort 'out-of-the-box' is worthwhile. This is why I asked to include
it into the source-tree. As a matter of fact, I stumbled upon this when
testing Gentoo's R-2.2.0 buildscripts and added a similar patch to our
repository.

| 2) It seems strange to specify this for the Fortran compiler and not the
| C or C++ compiler.
I used the combination of 'gcc/g++/ifort' to build and test R. Testing
the combination of 'icc/ifort' on Gentoo is scheduled already.

| 3) You have suggested the change to a section for all OSes.  Do you know
| for sure that all compilers called 'ifort' on all OSes need the -fPIC
| flag?  Or is it really just for Linux (and AFAICS, just x86_64 Linux, as
| i386 Linux seems to work with icc/ifort without it).
a) For building shared ELF-libraries on x86_64 and ia64, you need to
instruct the compiler to build PIC. As a matter of fact, this isn't
necessary for x86, but it is strongly recommended as it should improve
performance due to the lack of text relocations the dynamic linker would
have to perform otherwise. This affects all OSes that can handle ELF
binaries (Linux, FreeBSD, Solaris, tbc.).

b) I surely can't guarantee that there never will be a different fortran
compiler with same name on any OS. However, I think that it is a safe
assumption to say that there currently is no such compiler on OSes
supported by autotools.


The number of target OSes and and supported ISAs makes it - in my eyes -
worthwhile to add the check to the 'general' section of the configure.ac
script. If - in a rare case - a conflict with other compiler emerged, it
would still be possible to work around a problem in the following
section of the script: '## Step 3.  Individual platform overrides.'.
(Emphasis here on 'individual' and 'override')

Danny
- --
Danny van Dyk <kugelfang at gentoo.org>
Gentoo/AMD64 Project, Gentoo Scientific Project
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.1 (GNU/Linux)

iD8DBQFDg120aVNL8NrtU6IRAqVFAJ9Nv3FnfUjzGU2q4FEf+3TRek2HTQCfQG4R
DD5dVT076/1HBJw5B4N+mck=
=eBBz
-----END PGP SIGNATURE-----


From spluque at gmail.com  Tue Nov 22 20:12:10 2005
From: spluque at gmail.com (Sebastian Luque)
Date: Tue, 22 Nov 2005 13:12:10 -0600
Subject: [Rd] failure in `setClass' examples
Message-ID: <87psosfqet.fsf@gmail.com>

Hello,

Below is what I got running the examples from `setClass'.  Could somebody
please help explain why the last `setIs' call is returning the warning and
whether this is expected?


R>      setClass("track",
+               representation(x="numeric", y="numeric"))
[1] "track"
R>      setClass("trackCurve",
+               representation("track", smooth = "numeric"))
[1] "trackCurve"
R>      setClass("trackMultiCurve",
+               representation(x="numeric", y="matrix", smooth="matrix"),
+               prototype = list(x=numeric(), y=matrix(0,0,0),
+                                smooth= matrix(0,0,0)))
[1] "trackMultiCurve"
R>      try(setIs("trackMultiCurve", "trackCurve",
+          test = function(obj) {ncol(slot(obj, "y")) == 1}))
Warning message:
there is no automatic definition for as(object, "trackCurve") <- value when object has class "trackMultiCurve" and no 'replace' argument was supplied; replacement will be an error in: makeExtends(class1, class2, coerce, test, replace, by, classDef1 = classDef,  
R>      setIs("trackMultiCurve", "trackCurve",
+        test = function(obj) {ncol(slot(obj, "y")) == 1},
+        coerce = function(obj) {
+           new("trackCurve",
+               x = slot(obj, "x"),
+               y = as.numeric(slot(obj,"y")),
+               smooth = as.numeric(slot(obj, "smooth")))
+        })
Warning message:
there is no automatic definition for as(object, "trackCurve") <- value when object has class "trackMultiCurve" and no 'replace' argument was supplied; replacement will be an error in: makeExtends(class1, class2, coerce, test, replace, by, classDef1 = classDef,  
R> version
         _                
platform i486-pc-linux-gnu
arch     i486             
os       linux-gnu        
system   i486, linux-gnu  
status                    
major    2                
minor    2.0              
year     2005             
month    10               
day      06               
svn rev  35749            
language R                


Thanks in advance,

-- 
Sebastian P. Luque


From jmc at R-project.org  Tue Nov 22 21:08:54 2005
From: jmc at R-project.org (John Chambers)
Date: Tue, 22 Nov 2005 15:08:54 -0500
Subject: [Rd] failure in `setClass' examples
In-Reply-To: <87psosfqet.fsf@gmail.com>
References: <87psosfqet.fsf@gmail.com>
Message-ID: <43837AD6.4020300@R-project.org>

There's nothing bad happening, and we should remove the setIs() example 
from the setClass() documentation.

If you run example(setIs), you will see a slightly different version of 
the same call to setIs(), but one that does not generate the warning 
(because it includes the argument replace= to setIs()). Comparing the 
two calls and looking at the documentation for setIs should explain 
where the warning comes from.  But in any case, nothing to worry about.

John Chambers.

Sebastian Luque wrote:
> Hello,
> 
> Below is what I got running the examples from `setClass'.  Could somebody
> please help explain why the last `setIs' call is returning the warning and
> whether this is expected?
> 
> 
> R>      setClass("track",
> +               representation(x="numeric", y="numeric"))
> [1] "track"
> R>      setClass("trackCurve",
> +               representation("track", smooth = "numeric"))
> [1] "trackCurve"
> R>      setClass("trackMultiCurve",
> +               representation(x="numeric", y="matrix", smooth="matrix"),
> +               prototype = list(x=numeric(), y=matrix(0,0,0),
> +                                smooth= matrix(0,0,0)))
> [1] "trackMultiCurve"
> R>      try(setIs("trackMultiCurve", "trackCurve",
> +          test = function(obj) {ncol(slot(obj, "y")) == 1}))
> Warning message:
> there is no automatic definition for as(object, "trackCurve") <- value when object has class "trackMultiCurve" and no 'replace' argument was supplied; replacement will be an error in: makeExtends(class1, class2, coerce, test, replace, by, classDef1 = classDef,  
> R>      setIs("trackMultiCurve", "trackCurve",
> +        test = function(obj) {ncol(slot(obj, "y")) == 1},
> +        coerce = function(obj) {
> +           new("trackCurve",
> +               x = slot(obj, "x"),
> +               y = as.numeric(slot(obj,"y")),
> +               smooth = as.numeric(slot(obj, "smooth")))
> +        })
> Warning message:
> there is no automatic definition for as(object, "trackCurve") <- value when object has class "trackMultiCurve" and no 'replace' argument was supplied; replacement will be an error in: makeExtends(class1, class2, coerce, test, replace, by, classDef1 = classDef,  
> R> version
>          _                
> platform i486-pc-linux-gnu
> arch     i486             
> os       linux-gnu        
> system   i486, linux-gnu  
> status                    
> major    2                
> minor    2.0              
> year     2005             
> month    10               
> day      06               
> svn rev  35749            
> language R                
> 
> 
> Thanks in advance,
>


From spluque at gmail.com  Tue Nov 22 22:03:48 2005
From: spluque at gmail.com (Sebastian Luque)
Date: Tue, 22 Nov 2005 15:03:48 -0600
Subject: [Rd] failure in `setClass' examples
References: <87psosfqet.fsf@gmail.com> <43837AD6.4020300@R-project.org>
Message-ID: <873bloo0nf.fsf@gmail.com>

John Chambers <jmc at r-project.org> wrote:
> There's nothing bad happening, and we should remove the setIs() example
> from the setClass() documentation.

> If you run example(setIs), you will see a slightly different version of
> the same call to setIs(), but one that does not generate the warning 
> (because it includes the argument replace= to setIs()). Comparing the 
> two calls and looking at the documentation for setIs should explain 
> where the warning comes from.  But in any case, nothing to worry about.

Thank you, things are much clearer after reading the setIs()
documentation.


Cheers,

-- 
Sebastian P. Luque


From sims at Princeton.EDU  Wed Nov 23 01:04:05 2005
From: sims at Princeton.EDU (sims@Princeton.EDU)
Date: Wed, 23 Nov 2005 01:04:05 +0100 (CET)
Subject: [Rd] Inaccurate documentation for qr.R and qr.Q (PR#8347)
Message-ID: <20051123000405.AE8C32214D@slim.kubism.ku.dk>

This is a multi-part message in MIME format.
--------------060805080907030400090708
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 7bit

The documentation in QR.Auxiliaries {base} states

|qr.Q| returns part or all of *Q*, the order-nrow(X) orthogonal 
(unitary) transformation represented by |qr|. If |complete| is |TRUE|, 
*Q* has |nrow(X)| columns. If |complete| is |FALSE|, *Q* has |ncol(X)| 
columns. When |Dvec| is specified, each column of *Q* is multiplied by 
the corresponding value in |Dvec|.
|qr.R| returns *R*, the upper triangular matrix such that |X == Q %*% R|.

This last statement is true if there has been no pivoting, but if the 
LAPACK=TRUE option is turned on or the x matrix is complex, there is 
likely to be pivoting, and in that case Q %*% R is X with columns 
reordered by the pivot.  qr.X does return the original x matrix in 
either case, but a naive user who uses R alone (e.g. thinking that 
solve(R,crossprod(Q ,y)) will give ols estimates) could be misled.

Example:

 > x <- matrix(c(1,2,3,3,6,8),ncol=2)
 > qrlin <- qr(x)
 > qrla <- qr(x,LAPACK=TRUE)
 > qr.Q(qrlin) %*% qr.R(qrlin)
     [,1] [,2]
[1,]    1    3
[2,]    2    6
[3,]    3    8
 > qr.Q(qrla) %*% qr.R(qrla)
     [,1] [,2]
[1,]    3    1
[2,]    6    2
[3,]    8    3
 > qr.Q(qrla) %*% qr.R(qrla)[,qrla$pivot]
     [,1] [,2]
[1,]    1    3
[2,]    2    6
[3,]    3    8

--------------060805080907030400090708
Content-Type: text/x-vcard; charset=utf-8;
 name="sims.vcf"
Content-Transfer-Encoding: 7bit
Content-Disposition: attachment;
 filename="sims.vcf"

begin:vcard
fn:Chris Sims
n:Sims;Chris
org:Princeton University;Department of Economics
adr:;;Fisher Hall;Princeton;NJ;08544-1021;USA
email;internet:sims at princeton.edu
tel;work:609 258 4033
tel;fax:609 258 6419
x-mozilla-html:FALSE
url:http://www.princeton.edu/~sims
version:2.1
end:vcard


--------------060805080907030400090708--


From mtmorgan at fhcrc.org  Wed Nov 23 01:34:42 2005
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Tue, 22 Nov 2005 16:34:42 -0800
Subject: [Rd] winMenuAdd
Message-ID: <6phlkzg2od9.fsf@gopher3.fhcrc.org>

The following

winMenuAdd("X")
for (i in 1:20) winMenuAdd(paste("X",i, sep="/"))

generates an (incorrect) error after adding 12 menu items:

Error in winMenuAdd(menuname, NULL, NULL) : 
        unable to add menu (base menu does not exist)

More elaborate examples (e.g., adding menu items to each menu) create
other errors (e.g., "Only 16 menus are allowed"), and the original
example (at
https://stat.ethz.ch/pipermail/bioconductor/2005-November/011010.html)
crashes with SIGSEGV in rui.c:1389. I think the basic problem is that
there is a hard-coded limit of 16 menus. The limit is reached in
Bioconductor, as packages add vignettes.

R version 2.2.0, 2005-11-21, i386-pc-mingw32 

attached base packages:
[1] "methods"   "stats"     "graphics"  "grDevices" "utils"     "datasets" 
[7] "base"     


-- 
Martin Morgan


From sfalcon at fhcrc.org  Wed Nov 23 03:10:17 2005
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Tue, 22 Nov 2005 18:10:17 -0800
Subject: [Rd] ANN: R for Bioinformatics (advanced R programming) Course
Message-ID: <m2zmnwt8qe.fsf@fhcrc.org>

Robert and I will be teaching an advanced R programming course January
18-20, 2006 in Seattle.

Learn more here: http://bioconductor.org/rforbioc

The topics we plan to cover include:
  * Lexical Scope
  * Vectorization
  * Object Oriented Programming (S3 and S4)
  * Writing R packages
  * Database interfaces (DBI, ODBC)
  * Interfacing to C (.C/.Call)

Best,

+ seth


From ripley at stats.ox.ac.uk  Wed Nov 23 09:54:45 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 23 Nov 2005 08:54:45 +0000 (GMT)
Subject: [Rd] make check fails for R 2.3.0 (PR#8343)
In-Reply-To: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED5DC@usctmx1106.merck.com>
References: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED5DC@usctmx1106.merck.com>
Message-ID: <Pine.LNX.4.61.0511230824400.8049@gannet.stats>

On Tue, 22 Nov 2005, Liaw, Andy wrote:

> From: ahenningsen at email.uni-kiel.de
>>
>> On Tuesday 22 November 2005 12:55, ripley at stats.ox.ac.uk wrote:
> [snip]
>>> Since it is unstable and=20
>>> unreleased, such things are by definition not bugs in R.
>>
>> Sorry, I did not know this. I thought that my report could help you.
>> The next time when I will find an error in R-devel I won't report it.
>
> I do not believe that's the intention.  Problem with building R-devel should
> be reported, but as post to R-devel (the list), rather than filed as bug
> report.

Andy is right about the intention, as Martin Maechler has said.  It might 
be a good idea to wait a few days and try the current R-devel before 
reporting, as for example files sometimes get missed out of the tarball 
for a day or two (but no longer).

The main point is to remember that the R-devel sources are not thoroughly 
tested and are not intended to be in working order on all platforms. 
(Automated testing lags a day or two behind, and fixing can lag further.) 
So if you are able to report something that is not obvious with an 
identified cause it is very helpful.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ligges at statistik.uni-dortmund.de  Wed Nov 23 10:47:08 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 23 Nov 2005 10:47:08 +0100
Subject: [Rd] winMenuAdd
In-Reply-To: <6phlkzg2od9.fsf@gopher3.fhcrc.org>
References: <6phlkzg2od9.fsf@gopher3.fhcrc.org>
Message-ID: <43843A9C.2090705@statistik.uni-dortmund.de>

Martin Morgan wrote:

> The following
> 
> winMenuAdd("X")
> for (i in 1:20) winMenuAdd(paste("X",i, sep="/"))
> 
> generates an (incorrect) error after adding 12 menu items:
> 
> Error in winMenuAdd(menuname, NULL, NULL) : 
>         unable to add menu (base menu does not exist)
> 
> More elaborate examples (e.g., adding menu items to each menu) create
> other errors (e.g., "Only 16 menus are allowed"), and the original
> example (at
> https://stat.ethz.ch/pipermail/bioconductor/2005-November/011010.html)
> crashes with SIGSEGV in rui.c:1389. I think the basic problem is that
> there is a hard-coded limit of 16 menus. The limit is reached in
> Bioconductor, as packages add vignettes.
> 
> R version 2.2.0, 2005-11-21, i386-pc-mingw32 
> 
> attached base packages:
> [1] "methods"   "stats"     "graphics"  "grDevices" "utils"     "datasets" 
> [7] "base"     

This seems to be a bug introduced in R-patched (and R-devel).

R-2.2.0 release correctly reports:

Error in winMenuAdd(menuname, NULL, NULL) :
         unable to add menu (Only 16 menus are allowed)


Uwe Ligges


From hin-tak.leung at cimr.cam.ac.uk  Wed Nov 23 11:11:25 2005
From: hin-tak.leung at cimr.cam.ac.uk (Hin-Tak Leung)
Date: Wed, 23 Nov 2005 10:11:25 +0000
Subject: [Rd] problem with \eqn (PR#8322)
In-Reply-To: <1132686495.2949.87.camel@iron.psg.net>
References: <20051117215558.33EB422485@slim.kubism.ku.dk>	
	<437E0384.604@cimr.cam.ac.uk>	<17278.3526.762256.703178@stat.math.ethz.ch>	
	<437E11F7.6010604@cimr.cam.ac.uk>	<437E1993.5020804@stats.uwo.ca>	
	<17278.11673.761366.759409@mithrandir.hornik.net>	
	<4381A105.4000404@cimr.cam.ac.uk>
	<1132686495.2949.87.camel@iron.psg.net>
Message-ID: <4384404D.2010301@cimr.cam.ac.uk>

Ross Boylan wrote:
> On Mon, 2005-11-21 at 10:27 +0000, Hin-Tak Leung wrote:
> 
>>Kurt Hornik wrote:
>><snipped>
>>
>>>Definitely a problem in Rdconv.
>>>
>>>E.g.,
>>>
>>>$ cat foo.Rd 
>>>\description{
>>>  \eqn{{A}}{B}
>>>}
>>>hornik at mithrandir:~/tmp$ R-d CMD Rdconv -t latex foo.Rd | grep eqn
>>>\eqn{{A}}{A}{{B}
>>>
>>>shows what is going on.
>>
>>There is a "work-around" - putting extra spaces between the two braces:
>>
>>$ cat foo.Rd
>>\description{
>>   \eqn{ {A} }{B}
>>}
>>
>>$R CMD Rdconv -t latex foo.Rd
>>\HeaderA{}{}{}
>>\begin{Description}\relax
>>\eqn{ {A} }{B}
>>\end{Description}
>>
>>
>>HT
> 
> Terrific!  I can confirm that works for me and, in a way, a work-around
> is better than a fix.  With the work-around, I can distribute the
> package without needing to require that people get some not-yet-release
> version of R that fixes the problem.  I do hope the problem gets fixed
> though :)
> 
> By the way, I  couldn't see how the perl code excerpted earlier paid any
> attention to {}.  But perl is not my native tongue.
> 
> Ross
> 

Glad to hear - the extra space in the latex-eqn-processed part of
\eqn (versus the ascii part) possibly get skipped so there shouldn't
be visual difference if it works.

Regarding the perl code - "share/perl/R/Rdconv.pm" around line 400 - 
reproduced again here - the way I understand it, "\eqn{{a}}{b}" is first
transformed into something like
"\eqnbraces1brace2abrace2brace1brace1bbrace1", then called as
"get_arguments {'eqn', ..., 2}", which then tries to extract "a" and 
"b". $ID is defined elsewhere to be "brace1", etc. That's the idea.
The 4 regular expressions - the 1st, 2nd and the 4th probably should be
non-greedy (i.e. "??" instead of "?", and ".*?" instead of ".*"). But 
then, this is just my idea and I haven't tried very hard to figure out
what it is supposed and not supposed to do...

For those who wants to get to the bottom of it, I think inserting
something like this (this just append $text into a tmp file) would be 
useful, against the small snipplet that Kurt provided:
     open(JUNK, ">> /tmp/junk");
	print JUNK "outer/inner loop:", $text, "\n";
     close(JUNK);

HT

=======================
## Get the arguments of a command.
sub get_arguments {
     my ($command, $text, $nargs) = @_;
     ## Arguments of get_arguments:
     ##  1, command: next occurence of 'command' is searched
     ##  2, text:    'text' is the text containing the command
     ##  3, nargs:   the optional number of arguments to be extracted;
     ##              default 1
     my @retval;
     ## Returns a list with the id of the last closing bracket and the
     ## arguments.

     if($text =~ /\\($command)(\[[^\]]+\])?($ID)/){
         $id = $3;
         $text =~ /$id(.*)$id/s;
         $retval[1] = $1;
         my $k=2;
         while(($k<=$nargs) && ($text =~ /$id($ID)/)){
             $id = $1;
             $text =~ /$id\s*(.*)$id/s;
             $retval[$k++] = $1;
         }
     }
     $retval[0] = $id;
     @retval;
}
==================

HT


From ross at biostat.ucsf.edu  Tue Nov 22 20:08:15 2005
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Tue, 22 Nov 2005 11:08:15 -0800
Subject: [Rd] problem with \eqn (PR#8322)
In-Reply-To: <4381A105.4000404@cimr.cam.ac.uk>
References: <20051117215558.33EB422485@slim.kubism.ku.dk>
	<437E0384.604@cimr.cam.ac.uk>	<17278.3526.762256.703178@stat.math.ethz.ch>
	<437E11F7.6010604@cimr.cam.ac.uk>	<437E1993.5020804@stats.uwo.ca>
	<17278.11673.761366.759409@mithrandir.hornik.net>
	<4381A105.4000404@cimr.cam.ac.uk>
Message-ID: <1132686495.2949.87.camel@iron.psg.net>

On Mon, 2005-11-21 at 10:27 +0000, Hin-Tak Leung wrote:
> Kurt Hornik wrote:
> <snipped>
> > Definitely a problem in Rdconv.
> > 
> > E.g.,
> > 
> > $ cat foo.Rd 
> > \description{
> >   \eqn{{A}}{B}
> > }
> > hornik at mithrandir:~/tmp$ R-d CMD Rdconv -t latex foo.Rd | grep eqn
> > \eqn{{A}}{A}{{B}
> > 
> > shows what is going on.
> 
> There is a "work-around" - putting extra spaces between the two braces:
> 
> $ cat foo.Rd
> \description{
>    \eqn{ {A} }{B}
> }
> 
> $R CMD Rdconv -t latex foo.Rd
> \HeaderA{}{}{}
> \begin{Description}\relax
> \eqn{ {A} }{B}
> \end{Description}
> 
> 
> HT
Terrific!  I can confirm that works for me and, in a way, a work-around
is better than a fix.  With the work-around, I can distribute the
package without needing to require that people get some not-yet-release
version of R that fixes the problem.  I do hope the problem gets fixed
though :)

By the way, I  couldn't see how the perl code excerpted earlier paid any
attention to {}.  But perl is not my native tongue.

Ross


From hb at maths.lth.se  Wed Nov 23 11:50:51 2005
From: hb at maths.lth.se (Henrik Bengtsson)
Date: Wed, 23 Nov 2005 21:50:51 +1100
Subject: [Rd] x[1,], x[1,,], x[1,,,], ...
Message-ID: <4384498B.1080401@maths.lth.se>

Hi,

is there a function in R already doing what I try to do below:

# Let 'x' be an array with *any* number of dimensions (>=1).
x <- array(1:24, dim=c(2,2,3,2))
...
x <- array(1:24, dim=c(4,3,2))

i <- 2:3

ndim <- length(dim(x))
if (ndim == 1)
   y <- x[i]
else if (ndim == 2)
   y <- x[i,]
else if (ndim == 3)
   y <- x[i,,]
else ...

and so on.  My current solution is

ndim <- length(dim(x))
args <- rep(",", ndim)
args[1] <- "i"
args <- paste(args, collapse="")
code <- paste("x[", args, "]", sep="")
expr <- parse(text=code)
y <- eval(expr)

ndim <- length(dim(x))
args <- rep(",", ndim)
args[1] <- "i"
args <- paste(args, collapse="")
code <- paste("x[", args, "]", sep="")
expr <- parse(text=code)
y <- eval(expr)

Is there another way I can do this in R that I have overlooked?

/Henrik


From j.van_den_Hoff at fz-rossendorf.de  Wed Nov 23 12:28:33 2005
From: j.van_den_Hoff at fz-rossendorf.de (Joerg van den Hoff)
Date: Wed, 23 Nov 2005 12:28:33 +0100
Subject: [Rd] nls and weigthing the fit
Message-ID: <43845261.6030305@fz-rossendorf.de>

hi everybody,

which each release I hope that the section

"weights: an optional numeric vector of (fixed) weights.  When present,
           the objective function is weighted least squares. _not yet
           implemented_"

in the help page of 'nls' is missing the last sentence.

are their any plans to allow/include weighting in the upcoming releases?

modifying the cost function to include the weights is probably not the 
problem, I presume. what is the reason for not including the weighting? 
are they related to the 'statistical' output (estimation of parameter 
uncertainties and significances?).

I know of the "y ~ M"   vs. "~ sqrt(W)*(y-M)" work around suggestion in 
MASS to include weighting. (I understand that resulting error estimates 
und confidence intervals from 'nls' are wrong in this case. right?) 
would'nt it be sensible to inlcude weighting in 'nls' at least on this 
level, i.e. weighted parameters provided now, correct error estimates 
and the like coming later?


regards,
joerg


From pburns at pburns.seanet.com  Wed Nov 23 13:06:24 2005
From: pburns at pburns.seanet.com (Patrick Burns)
Date: Wed, 23 Nov 2005 12:06:24 +0000
Subject: [Rd] x[1,], x[1,,], x[1,,,], ...
In-Reply-To: <4384498B.1080401@maths.lth.se>
References: <4384498B.1080401@maths.lth.se>
Message-ID: <43845B40.9020000@pburns.seanet.com>

You can look at the definition of 'corner' in the public
domain area of the Burns Statistics website.  It uses
'do.call' on '[' to achieve (sort of) what you want.

Patrick Burns
patrick at burns-stat.com
+44 (0)20 8525 0696
http://www.burns-stat.com
(home of S Poetry and "A Guide for the Unwilling S User")

Henrik Bengtsson wrote:

>Hi,
>
>is there a function in R already doing what I try to do below:
>
># Let 'x' be an array with *any* number of dimensions (>=1).
>x <- array(1:24, dim=c(2,2,3,2))
>...
>x <- array(1:24, dim=c(4,3,2))
>
>i <- 2:3
>
>ndim <- length(dim(x))
>if (ndim == 1)
>   y <- x[i]
>else if (ndim == 2)
>   y <- x[i,]
>else if (ndim == 3)
>   y <- x[i,,]
>else ...
>
>and so on.  My current solution is
>
>ndim <- length(dim(x))
>args <- rep(",", ndim)
>args[1] <- "i"
>args <- paste(args, collapse="")
>code <- paste("x[", args, "]", sep="")
>expr <- parse(text=code)
>y <- eval(expr)
>
>ndim <- length(dim(x))
>args <- rep(",", ndim)
>args[1] <- "i"
>args <- paste(args, collapse="")
>code <- paste("x[", args, "]", sep="")
>expr <- parse(text=code)
>y <- eval(expr)
>
>Is there another way I can do this in R that I have overlooked?
>
>/Henrik
>
>______________________________________________
>R-devel at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-devel
>
>
>
>  
>


From ripley at stats.ox.ac.uk  Wed Nov 23 13:50:22 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 23 Nov 2005 12:50:22 +0000 (GMT)
Subject: [Rd] winMenuAdd
In-Reply-To: <43843A9C.2090705@statistik.uni-dortmund.de>
References: <6phlkzg2od9.fsf@gopher3.fhcrc.org>
	<43843A9C.2090705@statistik.uni-dortmund.de>
Message-ID: <Pine.LNX.4.61.0511231239480.1246@gannet.stats>

I can see no change in the relevant code since 2.2.0 and the release 
version of 2.2.0 does this for me.

It seems to be a long-standard error in rui.c that only 10 menus are 
allocated but 16 are tested for.

On Wed, 23 Nov 2005, Uwe Ligges wrote:

> Martin Morgan wrote:
>
>> The following
>>
>> winMenuAdd("X")
>> for (i in 1:20) winMenuAdd(paste("X",i, sep="/"))
>>
>> generates an (incorrect) error after adding 12 menu items:
>>
>> Error in winMenuAdd(menuname, NULL, NULL) :
>>         unable to add menu (base menu does not exist)
>>
>> More elaborate examples (e.g., adding menu items to each menu) create
>> other errors (e.g., "Only 16 menus are allowed"), and the original
>> example (at
>> https://stat.ethz.ch/pipermail/bioconductor/2005-November/011010.html)
>> crashes with SIGSEGV in rui.c:1389. I think the basic problem is that
>> there is a hard-coded limit of 16 menus. The limit is reached in
>> Bioconductor, as packages add vignettes.
>>
>> R version 2.2.0, 2005-11-21, i386-pc-mingw32

Please don't use such a misleading description!  You appear to mean
something like

 	Version 2.2.0 Patched (2005-11-21 r36418)


>> attached base packages:
>> [1] "methods"   "stats"     "graphics"  "grDevices" "utils"     "datasets"
>> [7] "base"
>
> This seems to be a bug introduced in R-patched (and R-devel).
>
> R-2.2.0 release correctly reports:
>
> Error in winMenuAdd(menuname, NULL, NULL) :
>         unable to add menu (Only 16 menus are allowed)
>
>
> Uwe Ligges
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From p.dalgaard at biostat.ku.dk  Wed Nov 23 13:57:14 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 23 Nov 2005 13:57:14 +0100
Subject: [Rd] x[1,], x[1,,], x[1,,,], ...
In-Reply-To: <4384498B.1080401@maths.lth.se>
References: <4384498B.1080401@maths.lth.se>
Message-ID: <x2oe4br07p.fsf@viggo.kubism.ku.dk>

Henrik Bengtsson <hb at maths.lth.se> writes:

> Hi,
> 
> is there a function in R already doing what I try to do below:
> 
> # Let 'x' be an array with *any* number of dimensions (>=1).
> x <- array(1:24, dim=c(2,2,3,2))
> ...
> x <- array(1:24, dim=c(4,3,2))
> 
> i <- 2:3
> 
> ndim <- length(dim(x))
> if (ndim == 1)
>    y <- x[i]
> else if (ndim == 2)
>    y <- x[i,]
> else if (ndim == 3)
>    y <- x[i,,]
> else ...
> 
> and so on.  My current solution is
> 
> ndim <- length(dim(x))
> args <- rep(",", ndim)
> args[1] <- "i"
> args <- paste(args, collapse="")
> code <- paste("x[", args, "]", sep="")
> expr <- parse(text=code)
> y <- eval(expr)
> 
> ndim <- length(dim(x))
> args <- rep(",", ndim)
> args[1] <- "i"
> args <- paste(args, collapse="")
> code <- paste("x[", args, "]", sep="")
> expr <- parse(text=code)
> y <- eval(expr)
> 
> Is there another way I can do this in R that I have overlooked?

I think this should work:

x <- array(1:24, dim=c(3,2,2,2)) # not c(2,2,3,2)....
i <- 2:3
ndim <- length(dim(x))
ix <- as.list(rep(TRUE, ndim))
ix[[1]] <- i
do.call("[", c(list(x), ix))


-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From andy_liaw at merck.com  Wed Nov 23 14:02:29 2005
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 23 Nov 2005 08:02:29 -0500
Subject: [Rd] x[1,], x[1,,], x[1,,,], ...
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED5EB@usctmx1106.merck.com>

I suppose one can make use of slice.index():

> array(x[slice.index(x, 1) == 1], dim(x)[-1])
     [,1] [,2]
[1,]    1   13
[2,]    5   17
[3,]    9   21

Andy


> From: Henrik Bengtsson
> 
> Hi,
> 
> is there a function in R already doing what I try to do below:
> 
> # Let 'x' be an array with *any* number of dimensions (>=1).
> x <- array(1:24, dim=c(2,2,3,2))
> ...
> x <- array(1:24, dim=c(4,3,2))
> 
> i <- 2:3
> 
> ndim <- length(dim(x))
> if (ndim == 1)
>    y <- x[i]
> else if (ndim == 2)
>    y <- x[i,]
> else if (ndim == 3)
>    y <- x[i,,]
> else ...
> 
> and so on.  My current solution is
> 
> ndim <- length(dim(x))
> args <- rep(",", ndim)
> args[1] <- "i"
> args <- paste(args, collapse="")
> code <- paste("x[", args, "]", sep="")
> expr <- parse(text=code)
> y <- eval(expr)
> 
> ndim <- length(dim(x))
> args <- rep(",", ndim)
> args[1] <- "i"
> args <- paste(args, collapse="")
> code <- paste("x[", args, "]", sep="")
> expr <- parse(text=code)
> y <- eval(expr)
> 
> Is there another way I can do this in R that I have overlooked?
> 
> /Henrik
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
>


From ripley at stats.ox.ac.uk  Wed Nov 23 15:30:50 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 23 Nov 2005 14:30:50 +0000 (GMT)
Subject: [Rd] [PATCH] Add fpicflags for Intel(R) Fortran Compiler
	(PR#8344)
In-Reply-To: <43835DB4.5080204@gentoo.org>
References: <20051122145025.4837FCA08@slim.kubism.ku.dk>
	<Pine.LNX.4.61.0511221611180.28852@gannet.stats>
	<43835DB4.5080204@gentoo.org>
Message-ID: <Pine.LNX.4.61.0511231228060.1246@gannet.stats>

I've some playing with the Intel compilers, currently only on ia32.  As 
far as I can see Intel provides compilers for only two OSes and on 50% of 
those -fPIC is wrong so I do think this is really Linux-specific.
I have put in a Linux-specific change to set FPICFLAGS, but that is the 
least of the problems I have found.

The reason there is not a problem with the C compiler is that configure 
reports

 	checking whether we are using the GNU C compiler... yes

and so configure takes the builtin defaults for gcc.  This seems to come 
from the test of

int
main ()
{
#ifndef __GNUC__
        choke me
#endif

   ;
   return 0;
}

and so it seems that the masquerading by icc is intentional.  This has 
some consequences: for example package foreign assumes that GCC accepts 
-Wno-long-long, but icc does not act on it.  More seriously, it means that 
the default CFLAGS get set to "-g -O2", which is not what is documented. 
And with those flags, the build fails, incorrectly reporting that a regexp 
is invalid.

There are also problems with optimizing src/modules/dlamc.f under ifort.


On Tue, 22 Nov 2005, Danny van Dyk wrote:

> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
>
> Dear Prof. Ripley,
>
> Prof Brian Ripley schrieb:
> | 1) The documented way to specify this is to set FPICFLAGS in
> | config.site: see the example in R-admin for the PG compilers.  When you
> | tried that, what went wrong?
> Nothing went wrong. However, I was of the opinion that support of
> ifc/ifort 'out-of-the-box' is worthwhile. This is why I asked to include
> it into the source-tree. As a matter of fact, I stumbled upon this when
> testing Gentoo's R-2.2.0 buildscripts and added a similar patch to our
> repository.
>
> | 2) It seems strange to specify this for the Fortran compiler and not the
> | C or C++ compiler.
> I used the combination of 'gcc/g++/ifort' to build and test R. Testing
> the combination of 'icc/ifort' on Gentoo is scheduled already.
>
> | 3) You have suggested the change to a section for all OSes.  Do you know
> | for sure that all compilers called 'ifort' on all OSes need the -fPIC
> | flag?  Or is it really just for Linux (and AFAICS, just x86_64 Linux, as
> | i386 Linux seems to work with icc/ifort without it).
> a) For building shared ELF-libraries on x86_64 and ia64, you need to
> instruct the compiler to build PIC. As a matter of fact, this isn't
> necessary for x86, but it is strongly recommended as it should improve
> performance due to the lack of text relocations the dynamic linker would
> have to perform otherwise. This affects all OSes that can handle ELF
> binaries (Linux, FreeBSD, Solaris, tbc.).
>
> b) I surely can't guarantee that there never will be a different fortran
> compiler with same name on any OS. However, I think that it is a safe
> assumption to say that there currently is no such compiler on OSes
> supported by autotools.
>
>
> The number of target OSes and and supported ISAs makes it - in my eyes -
> worthwhile to add the check to the 'general' section of the configure.ac
> script. If - in a rare case - a conflict with other compiler emerged, it
> would still be possible to work around a problem in the following
> section of the script: '## Step 3.  Individual platform overrides.'.
> (Emphasis here on 'individual' and 'override')
>
> Danny
> - --
> Danny van Dyk <kugelfang at gentoo.org>
> Gentoo/AMD64 Project, Gentoo Scientific Project
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v1.4.1 (GNU/Linux)
>
> iD8DBQFDg120aVNL8NrtU6IRAqVFAJ9Nv3FnfUjzGU2q4FEf+3TRek2HTQCfQG4R
> DD5dVT076/1HBJw5B4N+mck=
> =eBBz
> -----END PGP SIGNATURE-----
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From sfalcon at fhcrc.org  Wed Nov 23 15:54:40 2005
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Wed, 23 Nov 2005 06:54:40 -0800
Subject: [Rd] winMenuAdd
In-Reply-To: <Pine.LNX.4.61.0511231239480.1246@gannet.stats> (Brian Ripley's
	message of "Wed, 23 Nov 2005 12:50:22 +0000 (GMT)")
References: <6phlkzg2od9.fsf@gopher3.fhcrc.org>
	<43843A9C.2090705@statistik.uni-dortmund.de>
	<Pine.LNX.4.61.0511231239480.1246@gannet.stats>
Message-ID: <m23blntnwv.fsf@fhcrc.org>

On 23 Nov 2005, ripley at stats.ox.ac.uk wrote:

> I can see no change in the relevant code since 2.2.0 and the release
> version of 2.2.0 does this for me.
>
> It seems to be a long-standard error in rui.c that only 10 menus are
> allocated but 16 are tested for.

Would it be possible for the allocation to be dynamic?


From ripley at stats.ox.ac.uk  Wed Nov 23 19:54:12 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 23 Nov 2005 18:54:12 +0000 (GMT)
Subject: [Rd] [PATCH] Add fpicflags for Intel(R) Fortran Compiler
	(PR#8344)
In-Reply-To: <Pine.LNX.4.61.0511231228060.1246@gannet.stats>
References: <20051122145025.4837FCA08@slim.kubism.ku.dk>
	<Pine.LNX.4.61.0511221611180.28852@gannet.stats>
	<43835DB4.5080204@gentoo.org>
	<Pine.LNX.4.61.0511231228060.1246@gannet.stats>
Message-ID: <Pine.LNX.4.61.0511231712140.13601@gannet.stats>

I was somewhat more successful testing the Intel EM64T compilers (on an 
Opteron).  The masquerading as gcc means the default for CFLAGS is "-g 
-O2" which again is problematic: I had to include -mp in all the compiler 
flags to ensure that IEC60059 arithmetic was used.

After all that, the Intel compiler setup was a percent or two slower than 
gcc-3.4.4 at -O2.

We now have a reasonable attempt at icc/ifort support "out of the box", 
but there was a _lot_ more to it, and we still need to deal with the
dlamc.f issues.  (My sysadmin misunderstood and uninstalled ia32 
icc/ifort, so this will need to wait until it is put back on a P4 box.)

On Wed, 23 Nov 2005, Prof Brian Ripley wrote:

> I've some playing with the Intel compilers, currently only on ia32.  As far 
> as I can see Intel provides compilers for only two OSes and on 50% of those 
> -fPIC is wrong so I do think this is really Linux-specific.
> I have put in a Linux-specific change to set FPICFLAGS, but that is the least 
> of the problems I have found.
>
> The reason there is not a problem with the C compiler is that configure 
> reports
>
> 	checking whether we are using the GNU C compiler... yes
>
> and so configure takes the builtin defaults for gcc.  This seems to come from 
> the test of
>
> int
> main ()
> {
> #ifndef __GNUC__
>       choke me
> #endif
>
>  ;
>  return 0;
> }
>
> and so it seems that the masquerading by icc is intentional.  This has some 
> consequences: for example package foreign assumes that GCC accepts 
> -Wno-long-long, but icc does not act on it.  More seriously, it means that 
> the default CFLAGS get set to "-g -O2", which is not what is documented. And 
> with those flags, the build fails, incorrectly reporting that a regexp is 
> invalid.
>
> There are also problems with optimizing src/modules/dlamc.f under ifort.
>
>
> On Tue, 22 Nov 2005, Danny van Dyk wrote:
>
>> -----BEGIN PGP SIGNED MESSAGE-----
>> Hash: SHA1
>> 
>> Dear Prof. Ripley,
>> 
>> Prof Brian Ripley schrieb:
>> | 1) The documented way to specify this is to set FPICFLAGS in
>> | config.site: see the example in R-admin for the PG compilers.  When you
>> | tried that, what went wrong?
>> Nothing went wrong. However, I was of the opinion that support of
>> ifc/ifort 'out-of-the-box' is worthwhile. This is why I asked to include
>> it into the source-tree. As a matter of fact, I stumbled upon this when
>> testing Gentoo's R-2.2.0 buildscripts and added a similar patch to our
>> repository.
>> 
>> | 2) It seems strange to specify this for the Fortran compiler and not the
>> | C or C++ compiler.
>> I used the combination of 'gcc/g++/ifort' to build and test R. Testing
>> the combination of 'icc/ifort' on Gentoo is scheduled already.
>> 
>> | 3) You have suggested the change to a section for all OSes.  Do you know
>> | for sure that all compilers called 'ifort' on all OSes need the -fPIC
>> | flag?  Or is it really just for Linux (and AFAICS, just x86_64 Linux, as
>> | i386 Linux seems to work with icc/ifort without it).
>> a) For building shared ELF-libraries on x86_64 and ia64, you need to
>> instruct the compiler to build PIC. As a matter of fact, this isn't
>> necessary for x86, but it is strongly recommended as it should improve
>> performance due to the lack of text relocations the dynamic linker would
>> have to perform otherwise. This affects all OSes that can handle ELF
>> binaries (Linux, FreeBSD, Solaris, tbc.).
>> 
>> b) I surely can't guarantee that there never will be a different fortran
>> compiler with same name on any OS. However, I think that it is a safe
>> assumption to say that there currently is no such compiler on OSes
>> supported by autotools.
>> 
>> 
>> The number of target OSes and and supported ISAs makes it - in my eyes -
>> worthwhile to add the check to the 'general' section of the configure.ac
>> script. If - in a rare case - a conflict with other compiler emerged, it
>> would still be possible to work around a problem in the following
>> section of the script: '## Step 3.  Individual platform overrides.'.
>> (Emphasis here on 'individual' and 'override')
>> 
>> Danny
>> - --
>> Danny van Dyk <kugelfang at gentoo.org>
>> Gentoo/AMD64 Project, Gentoo Scientific Project
>> -----BEGIN PGP SIGNATURE-----
>> Version: GnuPG v1.4.1 (GNU/Linux)
>> 
>> iD8DBQFDg120aVNL8NrtU6IRAqVFAJ9Nv3FnfUjzGU2q4FEf+3TRek2HTQCfQG4R
>> DD5dVT076/1HBJw5B4N+mck=
>> =eBBz
>> -----END PGP SIGNATURE-----
>> 
>> 
>
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From Kurt.Hornik at wu-wien.ac.at  Wed Nov 23 21:28:05 2005
From: Kurt.Hornik at wu-wien.ac.at (Kurt Hornik)
Date: Wed, 23 Nov 2005 21:28:05 +0100
Subject: [Rd] [PATCH] Add fpicflags for Intel(R) Fortran
	Compiler	(PR#8344)
In-Reply-To: <Pine.LNX.4.61.0511231228060.1246@gannet.stats>
References: <20051122145025.4837FCA08@slim.kubism.ku.dk>
	<Pine.LNX.4.61.0511221611180.28852@gannet.stats>
	<43835DB4.5080204@gentoo.org>
	<Pine.LNX.4.61.0511231228060.1246@gannet.stats>
Message-ID: <17284.53461.987042.519447@mithrandir.hornik.net>

>>>>> Prof Brian Ripley writes:

> I've some playing with the Intel compilers, currently only on ia32.  As 
> far as I can see Intel provides compilers for only two OSes and on 50% of 
> those -fPIC is wrong so I do think this is really Linux-specific.
> I have put in a Linux-specific change to set FPICFLAGS, but that is the 
> least of the problems I have found.

> The reason there is not a problem with the C compiler is that configure 
> reports

>  	checking whether we are using the GNU C compiler... yes

> and so configure takes the builtin defaults for gcc.  This seems to come 
> from the test of

> int
> main ()
> {
> #ifndef __GNUC__
>         choke me
> #endif

>    ;
>    return 0;
> }

> and so it seems that the masquerading by icc is intentional.  This has 
> some consequences: for example package foreign assumes that GCC accepts 
> -Wno-long-long, but icc does not act on it.

Not sure about the "assumption": there is a configure test for the
configured CC to accept command line argument '-Wno-long-long'.

But I see that foreign/src/swap_bytes.h.in has

#if defined __GNUC__ && __GNUC__ >= 2

#define swap_bytes_double(from, to)             \
do {                                            \
    union {                                     \
        unsigned long long int u64;             \
        double d;                               \
    } __from, __to;                             \

etc so this may be another instance of icc masquerading itself as gcc.

-k


From rich.fitzjohn at gmail.com  Wed Nov 23 22:53:19 2005
From: rich.fitzjohn at gmail.com (Rich FitzJohn)
Date: Thu, 24 Nov 2005 10:53:19 +1300
Subject: [Rd] Infinite recursion in S3 methods crashes R on windows (related
	to PR#8203?)
Message-ID: <5934ae570511231353s2e01cb2fh6996b0b977de21b4@mail.gmail.com>

Hi,

Infinite recursion in S3 methods seem to crash R on Windows 2000 (R
terminating with the ("Rgui.exe has generated errors...") message,
rather than throwing an error.  This happens with both Rgui and Rterm.

The following toy example triggers this:
myf <- function(x, ...)
  UseMethod("myf")

myf.default <- function(x, ...)
  myf(x)

myf(1)
...R crashes...

Which I would expect to terminate with the usual "evaluation nested
too deeply: infinite recursion" or protect stack overflow message.

This may be related to the reported bug 8203 - apologies if this has
been fixed.  I couldn't find specific mention of this in the NEWS
file.

This does not happen on R 2.1.0 on Windows 2000 (same machine), or on
R 2.2.0 on Linux.  R/Machine version below.

Cheers,
Rich

Version:
platform = i386-pc-mingw32
arch = i386
os = mingw32
system = i386, mingw32
status =
major = 2
minor = 2.0
year = 2005
month = 10
day = 06
svn rev = 35749
language = R

Windows 2000 Professional (build 2195) Service Pack 4.0

Locale:
LC_COLLATE=English_New Zealand.1252;LC_CTYPE=English_New
Zealand.1252;LC_MONETARY=English_New
Zealand.1252;LC_NUMERIC=C;LC_TIME=English_New Zealand.1252

Search Path:
.GlobalEnv, package:methods, package:stats, package:graphics,
package:grDevices, package:utils, package:datasets, Autoloads,
package:base


--
Rich FitzJohn
rich.fitzjohn <at> gmail.com   |    http://homepages.paradise.net.nz/richa183
                      You are in a maze of twisty little functions, all alike


From spencer.graves at pdf.com  Wed Nov 23 23:01:29 2005
From: spencer.graves at pdf.com (Spencer Graves)
Date: Wed, 23 Nov 2005 14:01:29 -0800
Subject: [Rd] qbinom returns NaN
Message-ID: <4384E6B9.8000207@pdf.com>

Hi, All:

	  For most but not all cases, qbinom is the inverse of pbinom. 
Consider the following example, which generates an exception:

 > (pb01 <- pbinom(0:1, 1, .5, log=T, lower.tail=FALSE))
[1] -0.6931472       -Inf

	  Since "lower.tail=FALSE", Pr{X>1} = 0 in this context, and log(0) = 
-Inf, consistent with the documentation.

	  However, the inverse of this does NOT recover 0:1:

 > qbinom(pb01,1, .5, log=T, lower.tail=F)
[1]   0 NaN

	  Shouldn't the NaN here be 1?  If yes, this is relatively easy to fix. 
  Consider for example the following:

qbinom. <-
function (p, size, prob, lower.tail = TRUE, log.p = FALSE){
   q. <- .Internal(qbinom(p, size, prob, lower.tail, log.p))
   q.[p==(-Inf)] <- 1
   q.
}
 > qbinom.(pb01,1, .5, log=T, lower.tail=F)
[1] 0 1
Warning message:
NaNs produced in: qbinom(p, size, prob, lower.tail, log.p)

	  It's also easy to eliminate the Warning.  Consider for example the 
following:

qbinom. <-
function (p, size, prob, lower.tail = TRUE, log.p = FALSE){
   if(any(p.inf <- p==(-Inf))&&(!lower.tail)&&log.p){
     n <- max(length(p), length(size), length(prob))
     p <- rep(p, length=n)
     size <- rep(size, length=n)
     prob <- rep(prob, length=n)
     q. <- size
     q.[p>(-Inf)] <- .Internal(qbinom(p[!p.inf],
             size[!p.inf], prob[!p.inf], lower.tail, log.p))
     return(q.)
   }
   .Internal(qbinom(p, size, prob, lower.tail, log.p))
}

	  I suspect that for the right person, it would likely be easy to fix 
this in the .Internal qbinom code.  However, that's beyond my current R 
skill level.

	  Thanks for all your efforts to make R what it is today.
	  Best Wishes,
	  spencer graves

-- 
Spencer Graves, PhD
Senior Development Engineer
PDF Solutions, Inc.
333 West San Carlos Street Suite 700
San Jose, CA 95110, USA

spencer.graves at pdf.com
www.pdf.com <http://www.pdf.com>
Tel:  408-938-4420
Fax: 408-280-7915


From ross at biostat.ucsf.edu  Thu Nov 24 00:26:31 2005
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Wed, 23 Nov 2005 15:26:31 -0800
Subject: [Rd] Makefiles and other customization
Message-ID: <1132788391.2949.199.camel@iron.psg.net>

Writing R Extensions mentions that a package developer can provide a
Makefile, but gives very little information about what should be in it.
It says there must be a clean target, and later on there's mention of 
     $(SHLIB): $(OBJECTS)
             $(SHLIB_LINK) -o $@ $(OBJECTS) $(ALL_LIBS)
(in the F95 discussion).

What should a Makefile provide, and what can it assume?  In other words,
what variables and environment setup should have been done?  My guess is
that all the R boilerplate for Makefiles will have been read before the
Makefile I provide.  It appears from the F95 example that the Makefile
has to get the names of the files it needs itself.

I suspect this is not documented more fully because of the extreme
difficulty of writing a portable Makefile.  However, I already have a
"Makefile.full", so called to avoid having R use it.  Makefile.full does
lots of stuff, so portability is already compromised.  I'm thinking it
might be more direct to provide "Makefile," since I'm now trying to
alter what R CMD build does.

I posted a related question on r-help, before I realized this kind of
issue is more appropriate for this list.  The question I asked there was
whether it would be reasonable to do my own tar of the files I wanted to
distribute in place of using R CMD build.  I'm also interested in
knowing about that.
https://stat.ethz.ch/pipermail/r-help/2005-November/081758.html (though
the thread has so far been on a tangential issue).

Here is that first post, if you want more background:
---------------------------------------------------------------
I've made a package for which R CMD build isn't producing very
satisfactory results.  I'll get to the details in a moment.

I wonder if it would make sense to have my own makefiles (which already
exist and are doing quite a lot) produce the .tar.gz file ordinarily
produced by R CMD build.  As far as I can tell, R CMD build basically
tars up of the project directory after running some checks.  I could run
R CMD check separately.

There are two main problems with the results of R CMD build.  First, it
has lots of files that I don't want included (the input files used to
generate configure, miscellaneous garbage, other stuff not suitable for
distribution).  Second, I have data files as both "data.gz" and "data".
R puts "data" into the .tar.gz file and sensibly ignores the .gz file.
Unfortunately, my makefiles assume the existence of the "data.gz" files,
and so may have trouble after the .tar.gz is unpacked and there are no
"data.gz" files.

My bias would ordinarily be to piggy back on the R build system as much
as possible.  In principle, this could get me extra features (binary
builds, MS Windows builds) and it would track the things R build does
beyond tarring files.  But in this case using the R build system seems
quite ugly.  I could in principle use .Rbuildignore, probably generated
dynamically, to exclude files.  That doesn't solve the 2nd problem
(data.gz becomes data).

So does the alternative of doing the tar'ing myself make sense?

Is there another option that could hook into the R CMD build process
more deeply than the use of .Rbuildignore?

I suppose another option would be to do a clean checkout of the sources
for my package, run a special makefile target that would create the
necessary files and delete all unwanted files, and then do a regular R
CMD build.  This might still have trouble with "data.gz".
--------------------------------------------------------------

-- 
Ross Boylan                                      wk:  (415) 514-8146
185 Berry St #5700                               ross at biostat.ucsf.edu
Dept of Epidemiology and Biostatistics           fax: (415) 514-8150
University of California, San Francisco
San Francisco, CA 94107-1739                     hm:  (415) 550-1062


From khansen at stat.Berkeley.EDU  Thu Nov 24 00:47:00 2005
From: khansen at stat.Berkeley.EDU (Kasper Daniel Hansen)
Date: Wed, 23 Nov 2005 15:47:00 -0800
Subject: [Rd] Makefiles and other customization
In-Reply-To: <1132788391.2949.199.camel@iron.psg.net>
References: <1132788391.2949.199.camel@iron.psg.net>
Message-ID: <8C07F197-381B-4B60-81FE-CF66716C42CC@stat.berkeley.edu>

Well you can have a look at etc/Makeconf. I have had some troubles  
understanding the make process myself (which probably reveals I am  
not a make guru), but it really depends on what you want to  
accomplish - and from a certain perspective it is all documented in  
the sources.

I think you need to describe what exactly you want to do, perhaps  
even post a copy of your Makefie.

In case you include code which needs to be compiled and distributed  
to various platforms you definitely want R to do the compilation.

Kasper

On Nov 23, 2005, at 3:26 PM, Ross Boylan wrote:

> Writing R Extensions mentions that a package developer can provide a
> Makefile, but gives very little information about what should be in  
> it.
> It says there must be a clean target, and later on there's mention of
>      $(SHLIB): $(OBJECTS)
>              $(SHLIB_LINK) -o $@ $(OBJECTS) $(ALL_LIBS)
> (in the F95 discussion).
>
> What should a Makefile provide, and what can it assume?  In other  
> words,
> what variables and environment setup should have been done?  My  
> guess is
> that all the R boilerplate for Makefiles will have been read before  
> the
> Makefile I provide.  It appears from the F95 example that the Makefile
> has to get the names of the files it needs itself.
>
> I suspect this is not documented more fully because of the extreme
> difficulty of writing a portable Makefile.  However, I already have a
> "Makefile.full", so called to avoid having R use it.  Makefile.full  
> does
> lots of stuff, so portability is already compromised.  I'm thinking it
> might be more direct to provide "Makefile," since I'm now trying to
> alter what R CMD build does.
>
> I posted a related question on r-help, before I realized this kind of
> issue is more appropriate for this list.  The question I asked  
> there was
> whether it would be reasonable to do my own tar of the files I  
> wanted to
> distribute in place of using R CMD build.  I'm also interested in
> knowing about that.
> https://stat.ethz.ch/pipermail/r-help/2005-November/081758.html  
> (though
> the thread has so far been on a tangential issue).
>
> Here is that first post, if you want more background:
> ---------------------------------------------------------------
> I've made a package for which R CMD build isn't producing very
> satisfactory results.  I'll get to the details in a moment.
>
> I wonder if it would make sense to have my own makefiles (which  
> already
> exist and are doing quite a lot) produce the .tar.gz file ordinarily
> produced by R CMD build.  As far as I can tell, R CMD build basically
> tars up of the project directory after running some checks.  I  
> could run
> R CMD check separately.
>
> There are two main problems with the results of R CMD build.   
> First, it
> has lots of files that I don't want included (the input files used to
> generate configure, miscellaneous garbage, other stuff not suitable  
> for
> distribution).  Second, I have data files as both "data.gz" and  
> "data".
> R puts "data" into the .tar.gz file and sensibly ignores the .gz file.
> Unfortunately, my makefiles assume the existence of the "data.gz"  
> files,
> and so may have trouble after the .tar.gz is unpacked and there are no
> "data.gz" files.
>
> My bias would ordinarily be to piggy back on the R build system as  
> much
> as possible.  In principle, this could get me extra features (binary
> builds, MS Windows builds) and it would track the things R build does
> beyond tarring files.  But in this case using the R build system seems
> quite ugly.  I could in principle use .Rbuildignore, probably  
> generated
> dynamically, to exclude files.  That doesn't solve the 2nd problem
> (data.gz becomes data).
>
> So does the alternative of doing the tar'ing myself make sense?
>
> Is there another option that could hook into the R CMD build process
> more deeply than the use of .Rbuildignore?
>
> I suppose another option would be to do a clean checkout of the  
> sources
> for my package, run a special makefile target that would create the
> necessary files and delete all unwanted files, and then do a regular R
> CMD build.  This might still have trouble with "data.gz".
> --------------------------------------------------------------
>
> -- 
> Ross Boylan                                      wk:  (415) 514-8146
> 185 Berry St #5700                               ross at biostat.ucsf.edu
> Dept of Epidemiology and Biostatistics           fax: (415) 514-8150
> University of California, San Francisco
> San Francisco, CA 94107-1739                     hm:  (415) 550-1062
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From ross at biostat.ucsf.edu  Thu Nov 24 01:05:10 2005
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Wed, 23 Nov 2005 16:05:10 -0800
Subject: [Rd] Makefiles and other customization
In-Reply-To: <8C07F197-381B-4B60-81FE-CF66716C42CC@stat.berkeley.edu>
References: <1132788391.2949.199.camel@iron.psg.net>
	<8C07F197-381B-4B60-81FE-CF66716C42CC@stat.berkeley.edu>
Message-ID: <1132790711.2951.212.camel@iron.psg.net>

On Wed, 2005-11-23 at 15:47 -0800, Kasper Daniel Hansen wrote:
> Well you can have a look at etc/Makeconf. I have had some troubles  
> understanding the make process myself (which probably reveals I am  
> not a make guru), but it really depends on what you want to  
> accomplish - and from a certain perspective it is all documented in  
> the sources.

Makeconf sets environment variables and general rules for building
different types of files, but it doesn't have any regular targets.
While the answer is in the source, the full answer doesn't seem to be in
that particular piece.

> 
> I think you need to describe what exactly you want to do, perhaps  
> even post a copy of your Makefie.
My build system is a bit baroque; my first question is what a Makefile
should look like that simply duplicates the existing functionality.  In
other words, without a Makefile R can compile my code, check the
package, and build something for distribution.  If I want to add a
Makefile that preserves all this behavior, what needs to be in it?

I need something extra for two main reasons.  First, I'm using the fweb
literate programming system, so I maintain a .web file which must be
processed to get program sources and documentation.  Second, I have a
lot of unit tests of my code, and I want to exercise them apart from
simply building and testing the package as a whole.  All of this
requires assistance from the GNU autotools.

> 
> In case you include code which needs to be compiled and distributed  
> to various platforms you definitely want R to do the compilation.
> 
Since R does a lot, it would be better to try to build on that.  But if
it's too much of a fight, I might want to roll my own.  Creating a
source distribution, for example, looked like something I might be able
to do in my own makefile.

Ross


From hb at maths.lth.se  Thu Nov 24 01:09:48 2005
From: hb at maths.lth.se (Henrik Bengtsson)
Date: Thu, 24 Nov 2005 11:09:48 +1100
Subject: [Rd] Infinite recursion in S3 methods crashes R on windows
 (related to PR#8203?)
In-Reply-To: <5934ae570511231353s2e01cb2fh6996b0b977de21b4@mail.gmail.com>
References: <5934ae570511231353s2e01cb2fh6996b0b977de21b4@mail.gmail.com>
Message-ID: <438504CC.3020707@maths.lth.se>

Hi, trying the same on WinXP I get

:R 2.1.1 Patched (2005-09-19)
 > myf(1)
Error: protect(): protection stack overflow

R 2.2.0 Patched (2005-11-21 r36410):
 > myf(1)
Error: evaluation nested too deeply: infinite recursion / 
options(expressions=)?
 > options(expressions=50000)
 > myf(1)
Error: protect(): protection stack overflow

So either it has been fixed or there is a bug there that only shows up 
under certain conditions.

Cheers

Henrik


Rich FitzJohn wrote:
> Hi,
> 
> Infinite recursion in S3 methods seem to crash R on Windows 2000 (R
> terminating with the ("Rgui.exe has generated errors...") message,
> rather than throwing an error.  This happens with both Rgui and Rterm.
> 
> The following toy example triggers this:
> myf <- function(x, ...)
>   UseMethod("myf")
> 
> myf.default <- function(x, ...)
>   myf(x)
> 
> myf(1)
> ...R crashes...
> 
> Which I would expect to terminate with the usual "evaluation nested
> too deeply: infinite recursion" or protect stack overflow message.
> 
> This may be related to the reported bug 8203 - apologies if this has
> been fixed.  I couldn't find specific mention of this in the NEWS
> file.
> 
> This does not happen on R 2.1.0 on Windows 2000 (same machine), or on
> R 2.2.0 on Linux.  R/Machine version below.
> 
> Cheers,
> Rich
> 
> Version:
> platform = i386-pc-mingw32
> arch = i386
> os = mingw32
> system = i386, mingw32
> status =
> major = 2
> minor = 2.0
> year = 2005
> month = 10
> day = 06
> svn rev = 35749
> language = R
> 
> Windows 2000 Professional (build 2195) Service Pack 4.0
> 
> Locale:
> LC_COLLATE=English_New Zealand.1252;LC_CTYPE=English_New
> Zealand.1252;LC_MONETARY=English_New
> Zealand.1252;LC_NUMERIC=C;LC_TIME=English_New Zealand.1252
> 
> Search Path:
> .GlobalEnv, package:methods, package:stats, package:graphics,
> package:grDevices, package:utils, package:datasets, Autoloads,
> package:base
> 
> 
> --
> Rich FitzJohn
> rich.fitzjohn <at> gmail.com   |    http://homepages.paradise.net.nz/richa183
>                       You are in a maze of twisty little functions, all alike
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
>


From hb at maths.lth.se  Thu Nov 24 01:33:35 2005
From: hb at maths.lth.se (Henrik Bengtsson)
Date: Thu, 24 Nov 2005 11:33:35 +1100
Subject: [Rd] x[1,], x[1,,], x[1,,,], ...
In-Reply-To: <x2oe4br07p.fsf@viggo.kubism.ku.dk>
References: <4384498B.1080401@maths.lth.se> <x2oe4br07p.fsf@viggo.kubism.ku.dk>
Message-ID: <43850A5F.5090508@maths.lth.se>

Hi, thanks everyone.

Some comments below:

Peter Dalgaard wrote:
> Henrik Bengtsson <hb at maths.lth.se> writes:
> 
> 
>>Hi,
>>
>>is there a function in R already doing what I try to do below:
>>
>># Let 'x' be an array with *any* number of dimensions (>=1).
>>x <- array(1:24, dim=c(2,2,3,2))
>>...
>>x <- array(1:24, dim=c(4,3,2))
>>
>>i <- 2:3
>>
>>ndim <- length(dim(x))
>>if (ndim == 1)
>>   y <- x[i]
>>else if (ndim == 2)
>>   y <- x[i,]
>>else if (ndim == 3)
>>   y <- x[i,,]
>>else ...
>>
>>and so on.  My current solution is
>>
>>ndim <- length(dim(x))
>>args <- rep(",", ndim)
>>args[1] <- "i"
>>args <- paste(args, collapse="")
>>code <- paste("x[", args, "]", sep="")
>>expr <- parse(text=code)
>>y <- eval(expr)
>>
>>Is there another way I can do this in R that I have overlooked?
> 
> 
> I think this should work:
> 
> x <- array(1:24, dim=c(3,2,2,2)) # not c(2,2,3,2)....
> i <- 2:3
> ndim <- length(dim(x))
> ix <- as.list(rep(TRUE, ndim))
> ix[[1]] <- i
> do.call("[", c(list(x), ix))

In my case, 'x' is huge, an I have to be careful with allocating memory. 
Doesn't the 'list(x)' statement enforce an extra copy of 'x'?  Or will 
lazy evaluation be able to pull out 'x' from the list again without 
evaluating 'list(x)'?  I don't think so, but I'm not sure.  There is 
also some overhead in 'ix[[1]] <- i', but 'i' is typically much smaller 
than 'x' so this should be of minor importance.

What about Andy's suggestion

   array(x[slice.index(x, 1) == 1], dim(x)[-1])?

There 'slice.index(x, 1)' will create an array of same size as 'x'.

I do not think the 'eval(parse(...))' has such overhead (correct me if 
I'm wrong), but on the other hand, it is a more "ugly" solution. I 
prefer not to use parse(), substitute() and friends in my code, if I 
don't have to.

I just want to bring up this flavor of the problem too, because I often 
find myself having to choose from similar options in other situations. 
If you have further comments, I would appreciate those.

Thanks

Henrik


From tplate at acm.org  Thu Nov 24 03:33:46 2005
From: tplate at acm.org (Tony Plate)
Date: Wed, 23 Nov 2005 19:33:46 -0700
Subject: [Rd] x[1,], x[1,,], x[1,,,], ...
In-Reply-To: <43850A5F.5090508@maths.lth.se>
References: <4384498B.1080401@maths.lth.se> <x2oe4br07p.fsf@viggo.kubism.ku.dk>
	<43850A5F.5090508@maths.lth.se>
Message-ID: <4385268A.7080308@acm.org>

Henrik Bengtsson wrote:
> Hi, thanks everyone.
> 
> Some comments below:
> 
> Peter Dalgaard wrote:
> 
>>Henrik Bengtsson <hb at maths.lth.se> writes:
>>
>>
>>
>>>Hi,
>>>
>>>is there a function in R already doing what I try to do below:
>>>
>>># Let 'x' be an array with *any* number of dimensions (>=1).
>>>x <- array(1:24, dim=c(2,2,3,2))
>>>...
>>>x <- array(1:24, dim=c(4,3,2))
>>>
>>>i <- 2:3
>>>
>>>ndim <- length(dim(x))
>>>if (ndim == 1)
>>>  y <- x[i]
>>>else if (ndim == 2)
>>>  y <- x[i,]
>>>else if (ndim == 3)
>>>  y <- x[i,,]
>>>else ...
>>>
>>>and so on.  My current solution is
>>>
>>>ndim <- length(dim(x))
>>>args <- rep(",", ndim)
>>>args[1] <- "i"
>>>args <- paste(args, collapse="")
>>>code <- paste("x[", args, "]", sep="")
>>>expr <- parse(text=code)
>>>y <- eval(expr)
>>>
>>>Is there another way I can do this in R that I have overlooked?
>>
>>
>>I think this should work:
>>
>>x <- array(1:24, dim=c(3,2,2,2)) # not c(2,2,3,2)....
>>i <- 2:3
>>ndim <- length(dim(x))
>>ix <- as.list(rep(TRUE, ndim))
>>ix[[1]] <- i
>>do.call("[", c(list(x), ix))
> 
> 
> In my case, 'x' is huge, an I have to be careful with allocating memory. 
> Doesn't the 'list(x)' statement enforce an extra copy of 'x'?  Or will 
> lazy evaluation be able to pull out 'x' from the list again without 
> evaluating 'list(x)'?  I don't think so, but I'm not sure.  There is 
> also some overhead in 'ix[[1]] <- i', but 'i' is typically much smaller 
> than 'x' so this should be of minor importance.
> 
> What about Andy's suggestion
> 
>    array(x[slice.index(x, 1) == 1], dim(x)[-1])?
> 
> There 'slice.index(x, 1)' will create an array of same size as 'x'.
> 
> I do not think the 'eval(parse(...))' has such overhead (correct me if 
> I'm wrong), but on the other hand, it is a more "ugly" solution. I 
> prefer not to use parse(), substitute() and friends in my code, if I 
> don't have to.
> 
> I just want to bring up this flavor of the problem too, because I often 
> find myself having to choose from similar options in other situations. 
> If you have further comments, I would appreciate those.
> 

Here's the type of manipulation I often do to approach these problems:

 > x <- array(1:24, dim=c(4,3,2))
 > i <- 2:3
 > x[i,,]
, , 1

      [,1] [,2] [,3]
[1,]    2    6   10
[2,]    3    7   11

, , 2

      [,1] [,2] [,3]
[1,]   14   18   22
[2,]   15   19   23

 > xic <- Quote(x[i,])
 > xic
x[i, ]
 > length(xic)
[1] 4
 > # now duplicate the empty index argument the appropriate number of times
 > xic <- xic[c(1:3,4,4)]
 > xic
x[i, , ]
 > eval(xic)
, , 1

      [,1] [,2] [,3]
[1,]    2    6   10
[2,]    3    7   11

, , 2

      [,1] [,2] [,3]
[1,]   14   18   22
[2,]   15   19   23

 >

I do this type of manipulation for precisely the reasons you bring up. 
I do know that in S-PLUS, using do.call() in the most obvious manner can 
result in unnecessary multiple duplications of data objects (as you 
suspect).  I don't think R is quite as bad, but I haven't done careful 
the experiments with R.

Do be careful though: this type of manipulation can expose a bug in R, 
which I don't think has been fixed (PR#7924).

-- Tony Plate

> Thanks
> 
> Henrik
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From ripley at stats.ox.ac.uk  Thu Nov 24 08:00:37 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 24 Nov 2005 07:00:37 +0000 (GMT)
Subject: [Rd] Infinite recursion in S3 methods crashes R on windows
 (related to PR#8203?)
In-Reply-To: <5934ae570511231353s2e01cb2fh6996b0b977de21b4@mail.gmail.com>
References: <5934ae570511231353s2e01cb2fh6996b0b977de21b4@mail.gmail.com>
Message-ID: <Pine.LNX.4.61.0511240650400.31387@gannet.stats>

On Thu, 24 Nov 2005, Rich FitzJohn wrote:

> Hi,
>
> Infinite recursion in S3 methods seem to crash R on Windows 2000 (R
> terminating with the ("Rgui.exe has generated errors...") message,
> rather than throwing an error.  This happens with both Rgui and Rterm.
>
> The following toy example triggers this:
> myf <- function(x, ...)
>  UseMethod("myf")
>
> myf.default <- function(x, ...)
>  myf(x)
>
> myf(1)
> ...R crashes...
>
> Which I would expect to terminate with the usual "evaluation nested
> too deeply: infinite recursion" or protect stack overflow message.
>
> This may be related to the reported bug 8203 - apologies if this has
> been fixed.  I couldn't find specific mention of this in the NEWS
> file.

PR#8203 is attributed to C-stack overflow, and there is a prominent 
message (quoted below) in NEWS.

> This does not happen on R 2.1.0 on Windows 2000 (same machine), or on
> R 2.2.0 on Linux.  R/Machine version below.

What is happening is that the Windows C stack is being overflowed before 
the evaluation limit is reached, and what happens thereafter is random.
So it would probably also crash in 2.1.0 eventually.

This has already been fixed, and the R-patched NEWS file says

USER-VISIBLE CHANGES

     o   options("expressions") has been reduced to 1000: the limit
         of 5000 introduced in 2.1.0 was liable to give crashes from C
         stack overflow.

and the Windows CHANGES file says

The maximum C stack size for RGui.exe and Rterm.exe has been increased
to 10Mb (from 2Mb); this is comparable with the default on Linux systems
and may allow some larger programs to run without crashes.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Thu Nov 24 08:55:33 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 24 Nov 2005 07:55:33 +0000 (GMT)
Subject: [Rd] qbinom returns NaN
In-Reply-To: <4384E6B9.8000207@pdf.com>
References: <4384E6B9.8000207@pdf.com>
Message-ID: <Pine.LNX.4.61.0511240754250.32478@gannet.stats>

This is a very simple change at C level: the !R_FINITE(p) test is 
incorrect for log_p != 0.

Changed now.


On Wed, 23 Nov 2005, Spencer Graves wrote:

> Hi, All:
>
> 	  For most but not all cases, qbinom is the inverse of pbinom.
> Consider the following example, which generates an exception:
>
> > (pb01 <- pbinom(0:1, 1, .5, log=T, lower.tail=FALSE))
> [1] -0.6931472       -Inf
>
> 	  Since "lower.tail=FALSE", Pr{X>1} = 0 in this context, and log(0) =
> -Inf, consistent with the documentation.
>
> 	  However, the inverse of this does NOT recover 0:1:
>
> > qbinom(pb01,1, .5, log=T, lower.tail=F)
> [1]   0 NaN
>
> 	  Shouldn't the NaN here be 1?  If yes, this is relatively easy to fix.
>  Consider for example the following:
>
> qbinom. <-
> function (p, size, prob, lower.tail = TRUE, log.p = FALSE){
>   q. <- .Internal(qbinom(p, size, prob, lower.tail, log.p))
>   q.[p==(-Inf)] <- 1
>   q.
> }
> > qbinom.(pb01,1, .5, log=T, lower.tail=F)
> [1] 0 1
> Warning message:
> NaNs produced in: qbinom(p, size, prob, lower.tail, log.p)
>
> 	  It's also easy to eliminate the Warning.  Consider for example the
> following:
>
> qbinom. <-
> function (p, size, prob, lower.tail = TRUE, log.p = FALSE){
>   if(any(p.inf <- p==(-Inf))&&(!lower.tail)&&log.p){
>     n <- max(length(p), length(size), length(prob))
>     p <- rep(p, length=n)
>     size <- rep(size, length=n)
>     prob <- rep(prob, length=n)
>     q. <- size
>     q.[p>(-Inf)] <- .Internal(qbinom(p[!p.inf],
>             size[!p.inf], prob[!p.inf], lower.tail, log.p))
>     return(q.)
>   }
>   .Internal(qbinom(p, size, prob, lower.tail, log.p))
> }
>
> 	  I suspect that for the right person, it would likely be easy to fix
> this in the .Internal qbinom code.  However, that's beyond my current R
> skill level.
>
> 	  Thanks for all your efforts to make R what it is today.
> 	  Best Wishes,
> 	  spencer graves
>
> -- 
> Spencer Graves, PhD
> Senior Development Engineer
> PDF Solutions, Inc.
> 333 West San Carlos Street Suite 700
> San Jose, CA 95110, USA
>
> spencer.graves at pdf.com
> www.pdf.com <http://www.pdf.com>
> Tel:  408-938-4420
> Fax: 408-280-7915
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From Kurt.Hornik at wu-wien.ac.at  Wed Nov 23 22:07:57 2005
From: Kurt.Hornik at wu-wien.ac.at (Kurt Hornik)
Date: Wed, 23 Nov 2005 22:07:57 +0100
Subject: [Rd] problem with \eqn (PR#8322)
In-Reply-To: <4384404D.2010301@cimr.cam.ac.uk>
References: <20051117215558.33EB422485@slim.kubism.ku.dk>
	<437E0384.604@cimr.cam.ac.uk>
	<17278.3526.762256.703178@stat.math.ethz.ch>
	<437E11F7.6010604@cimr.cam.ac.uk> <437E1993.5020804@stats.uwo.ca>
	<17278.11673.761366.759409@mithrandir.hornik.net>
	<4381A105.4000404@cimr.cam.ac.uk>
	<1132686495.2949.87.camel@iron.psg.net>
	<4384404D.2010301@cimr.cam.ac.uk>
Message-ID: <17284.55853.820080.724465@mithrandir.hornik.net>

>>>>> Hin-Tak Leung writes:

> Ross Boylan wrote:
>> On Mon, 2005-11-21 at 10:27 +0000, Hin-Tak Leung wrote:
>> 
>>> Kurt Hornik wrote:
>>> <snipped>
>>> 
>>>> Definitely a problem in Rdconv.
>>>> 
>>>> E.g.,
>>>> 
>>>> $ cat foo.Rd 
>>>> \description{
>>>> \eqn{{A}}{B}
>>>> }
>>>> hornik at mithrandir:~/tmp$ R-d CMD Rdconv -t latex foo.Rd | grep eqn
>>>> \eqn{{A}}{A}{{B}
>>>> 
>>>> shows what is going on.
>>> 
>>> There is a "work-around" - putting extra spaces between the two braces:
>>> 
>>> $ cat foo.Rd
>>> \description{
>>> \eqn{ {A} }{B}
>>> }
>>> 
>>> $R CMD Rdconv -t latex foo.Rd
>>> \HeaderA{}{}{}
>>> \begin{Description}\relax
>>> \eqn{ {A} }{B}
>>> \end{Description}
>>> 
>>> 
>>> HT
>> 
>> Terrific!  I can confirm that works for me and, in a way, a work-around
>> is better than a fix.  With the work-around, I can distribute the
>> package without needing to require that people get some not-yet-release
>> version of R that fixes the problem.  I do hope the problem gets fixed
>> though :)
>> 
>> By the way, I  couldn't see how the perl code excerpted earlier paid any
>> attention to {}.  But perl is not my native tongue.
>> 
>> Ross
>> 

> Glad to hear - the extra space in the latex-eqn-processed part of
> \eqn (versus the ascii part) possibly get skipped so there shouldn't
> be visual difference if it works.

> Regarding the perl code - "share/perl/R/Rdconv.pm" around line 400 - 
> reproduced again here - the way I understand it, "\eqn{{a}}{b}" is first
> transformed into something like
> "\eqnbraces1brace2abrace2brace1brace1bbrace1", then called as
> "get_arguments {'eqn', ..., 2}", which then tries to extract "a" and 
> "b". $ID is defined elsewhere to be "brace1", etc. That's the idea.
> The 4 regular expressions - the 1st, 2nd and the 4th probably should be
> non-greedy (i.e. "??" instead of "?", and ".*?" instead of ".*"). But 
> then, this is just my idea and I haven't tried very hard to figure out
> what it is supposed and not supposed to do...

> For those who wants to get to the bottom of it, I think inserting
> something like this (this just append $text into a tmp file) would be 
> useful, against the small snipplet that Kurt provided:
>      open(JUNK, ">> /tmp/junk");
> 	print JUNK "outer/inner loop:", $text, "\n";
>      close(JUNK);

> HT

> =======================
> ## Get the arguments of a command.
> sub get_arguments {
>      my ($command, $text, $nargs) = @_;
>      ## Arguments of get_arguments:
>      ##  1, command: next occurence of 'command' is searched
>      ##  2, text:    'text' is the text containing the command
>      ##  3, nargs:   the optional number of arguments to be extracted;
>      ##              default 1
>      my @retval;
>      ## Returns a list with the id of the last closing bracket and the
>      ## arguments.

>      if($text =~ /\\($command)(\[[^\]]+\])?($ID)/){
>          $id = $3;
>          $text =~ /$id(.*)$id/s;
>          $retval[1] = $1;
>          my $k=2;
>          while(($k<=$nargs) && ($text =~ /$id($ID)/)){
>              $id = $1;
>              $text =~ /$id\s*(.*)$id/s;
>              $retval[$k++] = $1;
>          }
>      }
>      $retval[0] = $id;
>      @retval;
> }
> ==================

> HT

I think I have a fix for this.  Will shortly commit to r-devel.

-k


From Kurt.Hornik at wu-wien.ac.at  Thu Nov 24 10:09:32 2005
From: Kurt.Hornik at wu-wien.ac.at (Kurt Hornik)
Date: Thu, 24 Nov 2005 10:09:32 +0100
Subject: [Rd] Makefiles and other customization
In-Reply-To: <1132788391.2949.199.camel@iron.psg.net>
References: <1132788391.2949.199.camel@iron.psg.net>
Message-ID: <17285.33612.539171.70340@mithrandir.hornik.net>

>>>>> Ross Boylan writes:

> Writing R Extensions mentions that a package developer can provide a
> Makefile, but gives very little information about what should be in it.
> It says there must be a clean target, and later on there's mention of 
>      $(SHLIB): $(OBJECTS)
>              $(SHLIB_LINK) -o $@ $(OBJECTS) $(ALL_LIBS)
> (in the F95 discussion).

> What should a Makefile provide, and what can it assume?  In other
> words, what variables and environment setup should have been done?  My
> guess is that all the R boilerplate for Makefiles will have been read
> before the Makefile I provide.  It appears from the F95 example that
> the Makefile has to get the names of the files it needs itself.

> I suspect this is not documented more fully because of the extreme
> difficulty of writing a portable Makefile.  However, I already have a
> "Makefile.full", so called to avoid having R use it.  Makefile.full
> does lots of stuff, so portability is already compromised.  I'm
> thinking it might be more direct to provide "Makefile," since I'm now
> trying to alter what R CMD build does.

> I posted a related question on r-help, before I realized this kind of
> issue is more appropriate for this list.  The question I asked there
> was whether it would be reasonable to do my own tar of the files I
> wanted to distribute in place of using R CMD build.  I'm also
> interested in knowing about that.
> https://stat.ethz.ch/pipermail/r-help/2005-November/081758.html
> (though the thread has so far been on a tangential issue).

> Here is that first post, if you want more background:
> ---------------------------------------------------------------
> I've made a package for which R CMD build isn't producing very
> satisfactory results.  I'll get to the details in a moment.

> I wonder if it would make sense to have my own makefiles (which
> already exist and are doing quite a lot) produce the .tar.gz file
> ordinarily produced by R CMD build.  As far as I can tell, R CMD build
> basically tars up of the project directory after running some checks.
> I could run R CMD check separately.

> There are two main problems with the results of R CMD build.  First,
> it has lots of files that I don't want included (the input files used
> to generate configure, miscellaneous garbage, other stuff not suitable
> for distribution).  Second, I have data files as both "data.gz" and
> "data".  R puts "data" into the .tar.gz file and sensibly ignores the
> .gz file.  Unfortunately, my makefiles assume the existence of the
> "data.gz" files, and so may have trouble after the .tar.gz is unpacked
> and there are no "data.gz" files.

> My bias would ordinarily be to piggy back on the R build system as
> much as possible.  In principle, this could get me extra features
> (binary builds, MS Windows builds) and it would track the things R
> build does beyond tarring files.  But in this case using the R build
> system seems quite ugly.  I could in principle use .Rbuildignore,
> probably generated dynamically, to exclude files.  That doesn't solve
> the 2nd problem (data.gz becomes data).

> So does the alternative of doing the tar'ing myself make sense?

> Is there another option that could hook into the R CMD build process
> more deeply than the use of .Rbuildignore?

> I suppose another option would be to do a clean checkout of the sources
> for my package, run a special makefile target that would create the
> necessary files and delete all unwanted files, and then do a regular R
> CMD build.  This might still have trouble with "data.gz".
> --------------------------------------------------------------

I would typically advocate against bypassing the standard tool-chain.  R
CMD build will continue being enhanced, e.g. by adding more metadata
which certify the authenticity of the toolchain and/or the builder.  Of
course, all this is open source, and one can piggyback on the sources,
but one of the great successes of R and related projects is the fact
that there is a highly standardized way of managing extensions to the
base system.

Re hooks, in addition to .Rbuildignore there is a "cleanup" (before
packaging) mechanism, see sub cleanup_pkg in the build sources.  This is
what runs make clean in the src subdir, and under Unix also a cleanup
shell script in the top level package source directory (and we could in
principle add a cleanup.win mechanism).

I am not sure about the data.gz issue: perhaps you can send me a sample
package to that I can investigate.

-k


From p.dalgaard at biostat.ku.dk  Thu Nov 24 10:31:32 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 24 Nov 2005 10:31:32 +0100
Subject: [Rd] Infinite recursion in S3 methods crashes R on windows
	(related to PR#8203?)
In-Reply-To: <5934ae570511231353s2e01cb2fh6996b0b977de21b4@mail.gmail.com>
References: <5934ae570511231353s2e01cb2fh6996b0b977de21b4@mail.gmail.com>
Message-ID: <x2acfuo0i3.fsf@turmalin.kubism.ku.dk>

Rich FitzJohn <rich.fitzjohn at gmail.com> writes:

> Hi,
> 
> Infinite recursion in S3 methods seem to crash R on Windows 2000 (R
> terminating with the ("Rgui.exe has generated errors...") message,
> rather than throwing an error.  This happens with both Rgui and Rterm.
> 
> The following toy example triggers this:
> myf <- function(x, ...)
>   UseMethod("myf")
> 
> myf.default <- function(x, ...)
>   myf(x)
> 
> myf(1)
> ...R crashes...
> 
> Which I would expect to terminate with the usual "evaluation nested
> too deeply: infinite recursion" or protect stack overflow message.
> 
> This may be related to the reported bug 8203 - apologies if this has
> been fixed.  I couldn't find specific mention of this in the NEWS
> file.
> 
> This does not happen on R 2.1.0 on Windows 2000 (same machine), or on
> R 2.2.0 on Linux.  R/Machine version below.

This is presumably an issue of C stack size. We increased
options("expressions") in 2.2.0 from 500 to 5000, thinking that
"machines are bigger than that these days", but apparently not.

So for 2.2.0 patched we have

    o   options("expressions") has been reduced to 1000: the limit
        of 5000 introduced in 2.1.0 was liable to give crashes from C
        stack overflow.

and in R-devel

    o   options(expressions) reverts to the default of 5000 now
        stack checking is in place.



 
> Cheers,
> Rich
> 
> Version:
> platform = i386-pc-mingw32
> arch = i386
> os = mingw32
> system = i386, mingw32
> status =
> major = 2
> minor = 2.0
> year = 2005
> month = 10
> day = 06
> svn rev = 35749
> language = R
> 
> Windows 2000 Professional (build 2195) Service Pack 4.0
> 
> Locale:
> LC_COLLATE=English_New Zealand.1252;LC_CTYPE=English_New
> Zealand.1252;LC_MONETARY=English_New
> Zealand.1252;LC_NUMERIC=C;LC_TIME=English_New Zealand.1252
> 
> Search Path:
> .GlobalEnv, package:methods, package:stats, package:graphics,
> package:grDevices, package:utils, package:datasets, Autoloads,
> package:base
> 
> 
> --
> Rich FitzJohn
> rich.fitzjohn <at> gmail.com   |    http://homepages.paradise.net.nz/richa183
>                       You are in a maze of twisty little functions, all alike
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From ripley at stats.ox.ac.uk  Thu Nov 24 11:02:51 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 24 Nov 2005 10:02:51 +0000 (GMT)
Subject: [Rd] winMenuAdd
In-Reply-To: <m23blntnwv.fsf@fhcrc.org>
References: <6phlkzg2od9.fsf@gopher3.fhcrc.org>
	<43843A9C.2090705@statistik.uni-dortmund.de>
	<Pine.LNX.4.61.0511231239480.1246@gannet.stats>
	<m23blntnwv.fsf@fhcrc.org>
Message-ID: <Pine.LNX.4.61.0511240954170.11570@gannet.stats>

On Wed, 23 Nov 2005, Seth Falcon wrote:

> On 23 Nov 2005, ripley at stats.ox.ac.uk wrote:
>
>> I can see no change in the relevant code since 2.2.0 and the release
>> version of 2.2.0 does this for me.
>>
>> It seems to be a long-standard error in rui.c that only 10 menus are
>> allocated but 16 are tested for.
>
> Would it be possible for the allocation to be dynamic?

It actually already is in R-devel, but it was not announced because it 
needed some manual updating of the translations which I did this morning.
(We try to leave the RGui translations alone as much as possible because 
testing them is so tedious.)

[Not copied to the poster as he does not do so.]

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From len at mcs.st-and.ac.uk  Thu Nov 24 11:37:14 2005
From: len at mcs.st-and.ac.uk (Len Thomas)
Date: Thu, 24 Nov 2005 10:37:14 +0000
Subject: [Rd] Changes to Windows registry in R-2.2.0
Message-ID: <200511241032.jAOAWDv09528@mcs.st-and.ac.uk>

R-Devel,

I note from the CHANGES log accompanying the Windows version of R-2.2.0 that 
the behaviour with respect to the Windows registry has changed.  It says:

"If the user chooses to register R during installation, a registry entry
HKEY_LOCAL_MACHINE\Software\R-core\R\{version}\InstallPath will be added.
Users require administrative privileges to create this key.  For others,
the same key will be put under the HKEY_CURRENT_USER root."

The old behaviour was to add or modify the registry entry at
HKEY_LOCAL_MACHINE\Software\R-core\R\InstallPath
(ie the same entry, but without the extra {version} key).   Having installed 
R-2.2.0, I notice that the entry at this location, which used to say
C:\Program Files\R\R-2.1.1
now says
C:\Program Files\R\R-2.2.0
I also tried deleting the \R-core\R key, and re-installing R, and it added 
both the 
HKEY_LOCAL_MACHINE\Software\R-core\R\R-2.2.0\InstallPath
and
HKEY_LOCAL_MACHINE\Software\R-core\R\InstallPath
entries

In other words, the new behaviour seems to be to *both* modify/add an entry 
under
HKEY_LOCAL_MACHINE\Software\R-core\R\InstallPath
*and* 
HKEY_LOCAL_MACHINE\Software\R-core\R\{version}\InstallPath

I note also that it adds another entry 
HKEY_LOCAL_MACHINE\Software\R-core\R\Current Version

My questions are:

(1) Am I correct that this is the new behaviour?

(2) Can the appropriate developer confirm that this behaviour will be 
continued in future versions (at least for a while)?  I ask, because I 
distribute software that uses R, and it uses the 
HKEY_LOCAL_MACHINE\Software\R-core\R\InstallPath
to find R.  (It will also now look under HKEY_CURRENT_USER, as documented in 
CHANGES.)  If future versions will not update this entry, then I'll switch 
the behaviour of my software.

(3) Might it be worth documenting this behaviour somewhere?  I've searched 
all the files in the R-2.2.0 distribution and didn't find it, as well as 
looking in the recent r-devel and r-help archives.

There is one out-of-date entry: in R-2.2.0\doc\manual\R-exts.html it says:
[...]
Find and set the R home directory and the user's home directory.  The
former may be available from the Windows Registry: it will normally be
in <code>HKEY_LOCAL_MACHINE\Software\R-core\R\InstallPath</code> and can be
set there by running the program <span class="file">R_HOME\bin\RSetReg.exe
</span>

Perhaps I missed it elsewhere?

Thanks for any help,

 - Len Thomas


--
Len Thomas   len at mcs.st-and.ac.uk    http://www.creem.st-and.ac.uk/len/
Centre for Research into Ecological and Environmental Modelling
The Observatory, University of St Andrews, Scotland KY16 9LZ
Tel. (0)1334-461801  Fax. (0)1334-461800  Secretary (0)1334-461842


From murdoch at stats.uwo.ca  Thu Nov 24 13:11:13 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 24 Nov 2005 07:11:13 -0500
Subject: [Rd] Changes to Windows registry in R-2.2.0
In-Reply-To: <200511241032.jAOAWDv09528@mcs.st-and.ac.uk>
References: <200511241032.jAOAWDv09528@mcs.st-and.ac.uk>
Message-ID: <4385ADE1.9020906@stats.uwo.ca>

On 11/24/2005 5:37 AM, Len Thomas wrote:
> R-Devel,
> 
> I note from the CHANGES log accompanying the Windows version of R-2.2.0 that 
> the behaviour with respect to the Windows registry has changed.  It says:
> 
> "If the user chooses to register R during installation, a registry entry
> HKEY_LOCAL_MACHINE\Software\R-core\R\{version}\InstallPath will be added.
> Users require administrative privileges to create this key.  For others,
> the same key will be put under the HKEY_CURRENT_USER root."
> 
> The old behaviour was to add or modify the registry entry at
> HKEY_LOCAL_MACHINE\Software\R-core\R\InstallPath
> (ie the same entry, but without the extra {version} key).   Having installed 
> R-2.2.0, I notice that the entry at this location, which used to say
> C:\Program Files\R\R-2.1.1
> now says
> C:\Program Files\R\R-2.2.0
> I also tried deleting the \R-core\R key, and re-installing R, and it added 
> both the 
> HKEY_LOCAL_MACHINE\Software\R-core\R\R-2.2.0\InstallPath
> and
> HKEY_LOCAL_MACHINE\Software\R-core\R\InstallPath
> entries
> 
> In other words, the new behaviour seems to be to *both* modify/add an entry 
> under
> HKEY_LOCAL_MACHINE\Software\R-core\R\InstallPath
> *and* 
> HKEY_LOCAL_MACHINE\Software\R-core\R\{version}\InstallPath
> 
> I note also that it adds another entry 
> HKEY_LOCAL_MACHINE\Software\R-core\R\Current Version
> 
> My questions are:
> 
> (1) Am I correct that this is the new behaviour?

Yes.  The value in Current Version can be used to select the subkey from 
\R to find the InstallPath.
> 
> (2) Can the appropriate developer confirm that this behaviour will be 
> continued in future versions (at least for a while)?  I ask, because I 
> distribute software that uses R, and it uses the 
> HKEY_LOCAL_MACHINE\Software\R-core\R\InstallPath
> to find R.  (It will also now look under HKEY_CURRENT_USER, as documented in 
> CHANGES.)  If future versions will not update this entry, then I'll switch 
> the behaviour of my software.

The undocumented behaviour (putting InstallPath directly below \R) will 
eventually go away.  It's there for now for backwards compatibility. 
The problem as you've seen is that it gets overwritten every time you 
install a new version.  Some people will have multiple versions 
installed, and there was a request for a mechanism to allow tools to 
find them.

You can probably find that if you look back through the archives in this 
list (check the revision log on developer.r-project.org for the dates of 
the changes if you are having trouble).  The code to do this is in 
src/gnuwin32/installer/JRins.pl, a Perl script that writes out an Inno 
Setup installer script.

> (3) Might it be worth documenting this behaviour somewhere?  I've searched 
> all the files in the R-2.2.0 distribution and didn't find it, as well as 
> looking in the recent r-devel and r-help archives.

The folks who need this are pretty rare, but if you want to work out an 
appropriate place for the documentation (I'd guess the R-Admin or 
R-Extensions manual) and write it up I'll consider it for addition 
there.  The source for those manuals is in Texinfo format (.texi); don't 
edit the HTML versions.

> There is one out-of-date entry: in R-2.2.0\doc\manual\R-exts.html it says:
> [...]
> Find and set the R home directory and the user's home directory.  The
> former may be available from the Windows Registry: it will normally be
> in <code>HKEY_LOCAL_MACHINE\Software\R-core\R\InstallPath</code> and can be
> set there by running the program <span class="file">R_HOME\bin\RSetReg.exe
> </span>

Thanks, I'll fix that.

Duncan Murdoch
> 
> Perhaps I missed it elsewhere?
> 
> Thanks for any help,
> 
>  - Len Thomas
> 
> 
> --
> Len Thomas   len at mcs.st-and.ac.uk    http://www.creem.st-and.ac.uk/len/
> Centre for Research into Ecological and Environmental Modelling
> The Observatory, University of St Andrews, Scotland KY16 9LZ
> Tel. (0)1334-461801  Fax. (0)1334-461800  Secretary (0)1334-461842
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From sven at schaltenbrand.de  Thu Nov 24 17:00:41 2005
From: sven at schaltenbrand.de (Sven Schaltenbrand)
Date: Thu, 24 Nov 2005 17:00:41 +0100
Subject: [Rd] write.csv
Message-ID: <!~!UENERkVCMDkAAQACAAAAAAAAAAAAAAAAABgAAAAAAAAAhSZy0zcp30KH/pKqSCi9sMKAAAAQAAAAcIeg/3SLt0iaHwGiAYoTZgEAAAAA@schaltenbrand.de>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20051124/f2aa994e/attachment.pl

From gavin.simpson at ucl.ac.uk  Thu Nov 24 17:14:56 2005
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Thu, 24 Nov 2005 16:14:56 +0000
Subject: [Rd] write.csv
In-Reply-To: <!~!UENERkVCMDkAAQACAAAAAAAAAAAAAAAAABgAAAAAAAAAhSZy0zcp30KH/pKqSCi9sMKAAAAQAAAAcIeg/3SLt0iaHwGiAYoTZgEAAAAA@schaltenbrand.de>
References: <!~!UENERkVCMDkAAQACAAAAAAAAAAAAAAAAABgAAAAAAAAAhSZy0zcp30KH/pKqSCi9sMKAAAAQAAAAcIeg/3SLt0iaHwGiAYoTZgEAAAAA@schaltenbrand.de>
Message-ID: <1132848896.26884.5.camel@gsimpson.geog.ucl.ac.uk>

On Thu, 2005-11-24 at 17:00 +0100, Sven Schaltenbrand wrote:
> hallo,
>  
> i have a problem by writing a csv file
> the first colum is filled with index numbers from 1 to n.
> i have to unique two csv files once a week while one file is always the
> same.
> can anybody tell me, how to write the dataset into a csv file without the
> first row of the indexnumbers.
> x[,-1] does not wok as it eliminates the first "interesting" colum.
> col.names is not accepted by r (do i habe to start a package first? which
> one?)
>  
> thx
>  
> sven
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

This isn't a R-Devel related question, it would have been better sent to
R-Help:

https://stat.ethz.ch/mailman/listinfo/r-help

Also, you are asked to read the docs for the functions you are having
problems with. The answer is in ?write.csv and the argument row.names.
Setting this to FALSE gives you your desired behaviour, e.g.:

> ?write.csv
> data(iris) #example data
> write.csv(iris, row.names = FALSE)
> write.csv(iris, row.names = TRUE)

As I didn't specify a filename as the file argument, the results are
displayed at the console.

HTH

G
-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
Gavin Simpson                     [T] +44 (0)20 7679 5522
ENSIS Research Fellow             [F] +44 (0)20 7679 7565
ENSIS Ltd. & ECRC                 [E] gavin.simpsonATNOSPAMucl.ac.uk
UCL Department of Geography       [W] http://www.ucl.ac.uk/~ucfagls/cv/
26 Bedford Way                    [W] http://www.ucl.ac.uk/~ucfagls/
London.  WC1H 0AP.
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%


From rpeng at jhsph.edu  Thu Nov 24 17:18:48 2005
From: rpeng at jhsph.edu (Roger Peng)
Date: Thu, 24 Nov 2005 11:18:48 -0500
Subject: [Rd] write.csv
In-Reply-To: <!~!UENERkVCMDkAAQACAAAAAAAAAAAAAAAAABgAAAAAAAAAhSZy0zcp30KH/pKqSCi9sMKAAAAQAAAAcIeg/3SLt0iaHwGiAYoTZgEAAAAA@schaltenbrand.de>
References: <!~!UENERkVCMDkAAQACAAAAAAAAAAAAAAAAABgAAAAAAAAAhSZy0zcp30KH/pKqSCi9sMKAAAAQAAAAcIeg/3SLt0iaHwGiAYoTZgEAAAAA@schaltenbrand.de>
Message-ID: <4385E7E8.8030406@jhsph.edu>

If you don't want the row names, as 'write.csv()' writes out by default, 
try

write.table(<object>, file = "myfile.csv", sep = ",", row.names = FALSE)

-roger

Sven Schaltenbrand wrote:
> hallo,
>  
> i have a problem by writing a csv file
> the first colum is filled with index numbers from 1 to n.
> i have to unique two csv files once a week while one file is always the
> same.
> can anybody tell me, how to write the dataset into a csv file without the
> first row of the indexnumbers.
> x[,-1] does not wok as it eliminates the first "interesting" colum.
> col.names is not accepted by r (do i habe to start a package first? which
> one?)
>  
> thx
>  
> sven
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From fcombes at gmail.com  Thu Nov 24 17:17:34 2005
From: fcombes at gmail.com (Florence Combes)
Date: Thu, 24 Nov 2005 17:17:34 +0100
Subject: [Rd] write.csv
In-Reply-To: <!~!UENERkVCMDkAAQACAAAAAAAAAAAAAAAAABgAAAAAAAAAhSZy0zcp30KH/pKqSCi9sMKAAAAQAAAAcIeg/3SLt0iaHwGiAYoTZgEAAAAA@schaltenbrand.de>
References: <!~!UENERkVCMDkAAQACAAAAAAAAAAAAAAAAABgAAAAAAAAAhSZy0zcp30KH/pKqSCi9sMKAAAAQAAAAcIeg/3SLt0iaHwGiAYoTZgEAAAAA@schaltenbrand.de>
Message-ID: <73dae3060511240817p44c8732axf718e232edba1d33@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20051124/e61231f5/attachment.pl

From ripley at stats.ox.ac.uk  Thu Nov 24 17:27:04 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 24 Nov 2005 16:27:04 +0000 (GMT)
Subject: [Rd] write.csv
In-Reply-To: <4385E7E8.8030406@jhsph.edu>
References: <!~!UENERkVCMDkAAQACAAAAAAAAAAAAAAAAABgAAAAAAAAAhSZy0zcp30KH/pKqSCi9sMKAAAAQAAAAcIeg/3SLt0iaHwGiAYoTZgEAAAAA@schaltenbrand.de>
	<4385E7E8.8030406@jhsph.edu>
Message-ID: <Pine.LNX.4.61.0511241624180.24426@gannet.stats>

On Thu, 24 Nov 2005, Roger Peng wrote:

> If you don't want the row names, as 'write.csv()' writes out by default,
> try
>
> write.table(<object>, file = "myfile.csv", sep = ",", row.names = FALSE)

Or, better (since it sets other args to the appropriate values),

write.csv(<object>, file = "myfile.csv", row.names = FALSE)

That write.csv supports row.names = FALSE is explicitly mentioned on the 
help page.

>
> -roger
>
> Sven Schaltenbrand wrote:
>> hallo,
>>
>> i have a problem by writing a csv file
>> the first colum is filled with index numbers from 1 to n.
>> i have to unique two csv files once a week while one file is always the
>> same.
>> can anybody tell me, how to write the dataset into a csv file without the
>> first row of the indexnumbers.
>> x[,-1] does not wok as it eliminates the first "interesting" colum.
>> col.names is not accepted by r (do i habe to start a package first? which
>> one?)
>>
>> thx
>>
>> sven
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From rpeng at jhsph.edu  Thu Nov 24 17:30:50 2005
From: rpeng at jhsph.edu (Roger Peng)
Date: Thu, 24 Nov 2005 11:30:50 -0500
Subject: [Rd] write.csv ignores 'row.names'
In-Reply-To: <!~!UENERkVCMDkAAQACAAAAAAAAAAAAAAAAABgAAAAAAAAAhSZy0zcp30KH/pKqSCi9sMKAAAAQAAAAcIeg/3SLt0iaHwGiAYoTZgEAAAAA@schaltenbrand.de>
References: <!~!UENERkVCMDkAAQACAAAAAAAAAAAAAAAAABgAAAAAAAAAhSZy0zcp30KH/pKqSCi9sMKAAAAQAAAAcIeg/3SLt0iaHwGiAYoTZgEAAAAA@schaltenbrand.de>
Message-ID: <4385EABA.7070704@jhsph.edu>

Upon replying to this email, I took a look at 'write.csv()' and noticed 
something interesting.  I remember there being a discussion sometime in 
the past about letting 'write.csv()' accept the 'row.names' argument. 
However, I get the following error:

 > write.csv(airquality, file = "myfile.csv", row.names = F)
Error in write.table(airquality, file = "myfile.csv", row.names = F, 
col.names = NA,  :
         col.names = NA makes no sense when row.names = FALSE
 >

In 'write.csv()' there is

     rn <- Call$row.names
     Call$col.names <- if (is.logical(rn) && !rn)
         TRUE

but is.logical(rn) is always FALSE because even if 'row.names' is 
specified (non-NULL), it is of class "name".  Perhaps something like

rn <- eval(Call$row.names)

would suffice?  I can't tell if that would break anything.

-roger

Sven Schaltenbrand wrote:
> hallo,
>  
> i have a problem by writing a csv file
> the first colum is filled with index numbers from 1 to n.
> i have to unique two csv files once a week while one file is always the
> same.
> can anybody tell me, how to write the dataset into a csv file without the
> first row of the indexnumbers.
> x[,-1] does not wok as it eliminates the first "interesting" colum.
> col.names is not accepted by r (do i habe to start a package first? which
> one?)
>  
> thx
>  
> sven
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From rpeng at jhsph.edu  Thu Nov 24 17:36:48 2005
From: rpeng at jhsph.edu (Roger Peng)
Date: Thu, 24 Nov 2005 11:36:48 -0500
Subject: [Rd] write.csv ignores 'row.names'
In-Reply-To: <4385EABA.7070704@jhsph.edu>
References: <!~!UENERkVCMDkAAQACAAAAAAAAAAAAAAAAABgAAAAAAAAAhSZy0zcp30KH/pKqSCi9sMKAAAAQAAAAcIeg/3SLt0iaHwGiAYoTZgEAAAAA@schaltenbrand.de>
	<4385EABA.7070704@jhsph.edu>
Message-ID: <4385EC20.6020000@jhsph.edu>

Okay, upon further examination, it appears that it works fine if you set 
'row.names = FALSE' as opposed to 'row.names = F'.

-roger

Roger Peng wrote:
> Upon replying to this email, I took a look at 'write.csv()' and noticed 
> something interesting.  I remember there being a discussion sometime in 
> the past about letting 'write.csv()' accept the 'row.names' argument. 
> However, I get the following error:
> 
>  > write.csv(airquality, file = "myfile.csv", row.names = F)
> Error in write.table(airquality, file = "myfile.csv", row.names = F, 
> col.names = NA,  :
>         col.names = NA makes no sense when row.names = FALSE
>  >
> 
> In 'write.csv()' there is
> 
>     rn <- Call$row.names
>     Call$col.names <- if (is.logical(rn) && !rn)
>         TRUE
> 
> but is.logical(rn) is always FALSE because even if 'row.names' is 
> specified (non-NULL), it is of class "name".  Perhaps something like
> 
> rn <- eval(Call$row.names)
> 
> would suffice?  I can't tell if that would break anything.
> 
> -roger
> 
> Sven Schaltenbrand wrote:
> 
>> hallo,
>>  
>> i have a problem by writing a csv file
>> the first colum is filled with index numbers from 1 to n.
>> i have to unique two csv files once a week while one file is always the
>> same.
>> can anybody tell me, how to write the dataset into a csv file without the
>> first row of the indexnumbers.
>> x[,-1] does not wok as it eliminates the first "interesting" colum.
>> col.names is not accepted by r (do i habe to start a package first? which
>> one?)
>>  
>> thx
>>  
>> sven
>>
>>     [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>


From p.dalgaard at biostat.ku.dk  Thu Nov 24 18:02:13 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 24 Nov 2005 18:02:13 +0100
Subject: [Rd] write.csv ignores 'row.names'
In-Reply-To: <4385EC20.6020000@jhsph.edu>
References: <!~!UENERkVCMDkAAQACAAAAAAAAAAAAAAAAABgAAAAAAAAAhSZy0zcp30KH/pKqSCi9sMKAAAAQAAAAcIeg/3SLt0iaHwGiAYoTZgEAAAAA@schaltenbrand.de>
	<4385EABA.7070704@jhsph.edu> <4385EC20.6020000@jhsph.edu>
Message-ID: <x264qif08a.fsf@viggo.kubism.ku.dk>

Roger Peng <rpeng at jhsph.edu> writes:

> Okay, upon further examination, it appears that it works fine if you set 
> 'row.names = FALSE' as opposed to 'row.names = F'.

Nope. It's still a bug and you're quite right that eval() is needed.
We can't have that an argument only works when supplied as an explicit
constant. 

 
> -roger
> 
> Roger Peng wrote:
> > Upon replying to this email, I took a look at 'write.csv()' and noticed 
> > something interesting.  I remember there being a discussion sometime in 
> > the past about letting 'write.csv()' accept the 'row.names' argument. 
> > However, I get the following error:
> > 
> >  > write.csv(airquality, file = "myfile.csv", row.names = F)
> > Error in write.table(airquality, file = "myfile.csv", row.names = F, 
> > col.names = NA,  :
> >         col.names = NA makes no sense when row.names = FALSE
> >  >
> > 
> > In 'write.csv()' there is
> > 
> >     rn <- Call$row.names
> >     Call$col.names <- if (is.logical(rn) && !rn)
> >         TRUE
> > 
> > but is.logical(rn) is always FALSE because even if 'row.names' is 
> > specified (non-NULL), it is of class "name".  Perhaps something like
> > 
> > rn <- eval(Call$row.names)
> > 
> > would suffice?  I can't tell if that would break anything.
> > 
> > -roger
> > 
> > Sven Schaltenbrand wrote:
> > 
> >> hallo,
> >>  
> >> i have a problem by writing a csv file
> >> the first colum is filled with index numbers from 1 to n.
> >> i have to unique two csv files once a week while one file is always the
> >> same.
> >> can anybody tell me, how to write the dataset into a csv file without the
> >> first row of the indexnumbers.
> >> x[,-1] does not wok as it eliminates the first "interesting" colum.
> >> col.names is not accepted by r (do i habe to start a package first? which
> >> one?)
> >>  
> >> thx
> >>  
> >> sven
> >>
> >>     [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-devel at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-devel
> >>
> >
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From ripley at stats.ox.ac.uk  Thu Nov 24 18:32:11 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 24 Nov 2005 17:32:11 +0000 (GMT)
Subject: [Rd] write.csv ignores 'row.names'
In-Reply-To: <4385EC20.6020000@jhsph.edu>
References: <!~!UENERkVCMDkAAQACAAAAAAAAAAAAAAAAABgAAAAAAAAAhSZy0zcp30KH/pKqSCi9sMKAAAAQAAAAcIeg/3SLt0iaHwGiAYoTZgEAAAAA@schaltenbrand.de>
	<4385EABA.7070704@jhsph.edu> <4385EC20.6020000@jhsph.edu>
Message-ID: <Pine.LNX.4.61.0511241729310.30853@gannet.stats>

On Thu, 24 Nov 2005, Roger Peng wrote:

> Okay, upon further examination, it appears that it works fine if you set
> 'row.names = FALSE' as opposed to 'row.names = F'.

Yes.  Adding eval.parent() (not eval()) would be better, though, as it 
would allow a variable (like F) to be used.  I rather like the poetic 
justice of 'F' not working since no developer would have tested that, 
though.

>
> -roger
>
> Roger Peng wrote:
>> Upon replying to this email, I took a look at 'write.csv()' and noticed
>> something interesting.  I remember there being a discussion sometime in
>> the past about letting 'write.csv()' accept the 'row.names' argument.
>> However, I get the following error:
>>
>> > write.csv(airquality, file = "myfile.csv", row.names = F)
>> Error in write.table(airquality, file = "myfile.csv", row.names = F,
>> col.names = NA,  :
>>         col.names = NA makes no sense when row.names = FALSE
>> >
>>
>> In 'write.csv()' there is
>>
>>     rn <- Call$row.names
>>     Call$col.names <- if (is.logical(rn) && !rn)
>>         TRUE
>>
>> but is.logical(rn) is always FALSE because even if 'row.names' is
>> specified (non-NULL), it is of class "name".  Perhaps something like
>>
>> rn <- eval(Call$row.names)
>>
>> would suffice?  I can't tell if that would break anything.
>>
>> -roger
>>
>> Sven Schaltenbrand wrote:
>>
>>> hallo,
>>>
>>> i have a problem by writing a csv file
>>> the first colum is filled with index numbers from 1 to n.
>>> i have to unique two csv files once a week while one file is always the
>>> same.
>>> can anybody tell me, how to write the dataset into a csv file without the
>>> first row of the indexnumbers.
>>> x[,-1] does not wok as it eliminates the first "interesting" colum.
>>> col.names is not accepted by r (do i habe to start a package first? which
>>> one?)
>>>
>>> thx
>>>
>>> sven
>>>
>>>     [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From mtmorgan at fhcrc.org  Thu Nov 24 19:28:58 2005
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Thu, 24 Nov 2005 10:28:58 -0800
Subject: [Rd] Windows R CMD build <pkg> leftovers
Message-ID: <6phacftq4r9.fsf@gopher3.fhcrc.org>

A command

R CMD build  <pkg>

that fails, e.g., because of C code compilation errors, leaves a
directory %TMPDIR%/Rinst.xxx containing the file R.css. Although R
CMD INSTALL --build cleans up after itself, build does not. A fix is
below. Also, build.in references Rcmd.exe, which I thought was no
longer necessary?

Index: build.in
===================================================================
--- build.in	(revision 36450)
+++ build.in	(working copy)
@@ -434,6 +434,8 @@
 	    if($doit && R_system($cmd)) {
 		$log->error();
 		$log->print("Installation failed.\n");
+		$log->print("Removing '$libdir'\n");
+		rmtree($libdir);
 		exit(1);
 	    }
 	    my $R_LIBS = $ENV{'R_LIBS'};


From aleszib at gmail.com  Fri Nov 25 09:57:02 2005
From: aleszib at gmail.com (Ales Ziberna)
Date: Fri, 25 Nov 2005 09:57:02 +0100
Subject: [Rd] Buliding a package (on Windows) does not produce libs directory
Message-ID: <07e801c5f19e$3f21e580$0100a8c0@ALES>

Dear expeRts!



I have produced a package and I would like to compile it on windows to build 
a binary package. The package also includes Fortran code. This is where I 
have problems.



The package compiles fine, however the Fortran code seams to be ignored. I 
have the Fortran code in src subdirectory. I have all the compilers 
installed. Actually, if I compile the Fortran subroutines manually and then 
place them in the libs subdirectory (which I have to create) in the zip 
file, the package loads nicely and the Fortran subroutines can be used.



At the bottom of the mail is the output I get when calling R CMD build (if I 
call install the result is similar).



I apologize if this has been answered previously, since I have not found it.


C:\Ales\Statistika>R CMD build --binary --docs="none" blockmodeling
* checking for file 'blockmodeling/DESCRIPTION' ... OK
* preparing 'blockmodeling':
* checking DESCRIPTION meta-information ... OK
* cleaning src
* removing junk files
* checking for LF line-endings in source files
* checking for empty directories
* building binary distribution
 WARNING
* some HTML links may not be found
installing R.css in C:/TEMP/Rinst.1696



Using auto-selected zip options ' blockmodeling-HELP=ziponly'



---------- Making package blockmodeling ------------
  adding build stamp to DESCRIPTION
  installing R files
  installing man source files
  installing indices
  preparing package blockmodeling for lazy loading
  adding MD5 sums



packaged installation of package 'blockmodeling' as blockmodeling_0.1.0.zip
* DONE (blockmodeling)


From ripley at stats.ox.ac.uk  Fri Nov 25 10:20:10 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 25 Nov 2005 09:20:10 +0000 (GMT)
Subject: [Rd] Buliding a package (on Windows) does not produce libs
 directory
In-Reply-To: <07e801c5f19e$3f21e580$0100a8c0@ALES>
References: <07e801c5f19e$3f21e580$0100a8c0@ALES>
Message-ID: <Pine.LNX.4.61.0511250917540.17824@gannet.stats>

There is no DLL being built. We have absolutely nothing to go on here, but 
there are dozens of examples on CRAN which do work.  A simple one 
containing Fortran is 'ash' - perhaps you should study how yours differs 
from that.

And please get R CMD INSTALL working before complicating the issue with 
the (not recommended) R CMD build --binary.


On Fri, 25 Nov 2005, Ales Ziberna wrote:

> Dear expeRts!
>
>
>
> I have produced a package and I would like to compile it on windows to build
> a binary package. The package also includes Fortran code. This is where I
> have problems.
>
>
>
> The package compiles fine, however the Fortran code seams to be ignored. I
> have the Fortran code in src subdirectory. I have all the compilers
> installed. Actually, if I compile the Fortran subroutines manually and then
> place them in the libs subdirectory (which I have to create) in the zip
> file, the package loads nicely and the Fortran subroutines can be used.
>
>
>
> At the bottom of the mail is the output I get when calling R CMD build (if I
> call install the result is similar).
>
>
>
> I apologize if this has been answered previously, since I have not found it.
>
>
> C:\Ales\Statistika>R CMD build --binary --docs="none" blockmodeling
> * checking for file 'blockmodeling/DESCRIPTION' ... OK
> * preparing 'blockmodeling':
> * checking DESCRIPTION meta-information ... OK
> * cleaning src
> * removing junk files
> * checking for LF line-endings in source files
> * checking for empty directories
> * building binary distribution
> WARNING
> * some HTML links may not be found
> installing R.css in C:/TEMP/Rinst.1696
>
>
>
> Using auto-selected zip options ' blockmodeling-HELP=ziponly'
>
>
>
> ---------- Making package blockmodeling ------------
>  adding build stamp to DESCRIPTION
>  installing R files
>  installing man source files
>  installing indices
>  preparing package blockmodeling for lazy loading
>  adding MD5 sums
>
>
>
> packaged installation of package 'blockmodeling' as blockmodeling_0.1.0.zip
> * DONE (blockmodeling)
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From vasu.akkineni at gmail.com  Fri Nov 25 19:31:40 2005
From: vasu.akkineni at gmail.com (Vasundhara Akkineni)
Date: Fri, 25 Nov 2005 13:31:40 -0500
Subject: [Rd] read.table without sep
Message-ID: <3b67376c0511251031j7a1c2515r47468b1ed7019e31@mail.gmail.com>

Hello all,

I have a data file table.txt  which i have attached. I am trying to pass the
columns as arguments to a function "totnorm" where i am displaying a total
normalization plot. The function is given below:

totnorm<-function(x,y){scale<-sum(x)/sum(y);xlab<-colnames(x);ylab<-colnames(y);x1<-x[[1]];y1<-scale*y[[1]];plot(x1,y1,xlab=xlab,ylab=ylab,col=6,
col.lab=4);}

i tried doing this:

data<-read.table("alldata.txt",header=TRUE,sep="\t")
a<-data[1]
b<-data[2]
totnorm(a,b)

The problem i am facing is- xlab and ylab contain the column names of
data[1] and data[2], but data[1][[1]] which is assigned to x1 has different
data which does not correspond to the colname(data[1]). Stating more
clearly, the colnames and the coldata don't match. I tried usind
read.tablewithout sep attribute, as given below:

data1<-read.table("alldata.txt",header=TRUE)

But this statement is not getting executed using Rserve when i make a
connection to R and try to execute it from a java servlet. I don't know why
it was doing so, so thought it would be better to fix this on R side, i.e,
try to use the "sep" attribue in read.table and still make the colnames and
coldata point to the same col#.

Please suggest a solution.
Thanks,
Vasu.
-------------- next part --------------
14A_U133A_StatPairs	14A_U133A_Detection	14B_U133A_Signal	88A_U133A_Signal	88B_U133A_Signal	183A_U133A_Signal	183B_U133A_Signal
AFFX-BioB-5_at	403.0	409.3	611.5	569.2	536.6	580.2	
AFFX-BioB-M_at	757.3	574.4	826.7	595.3	755.2	956.0	
AFFX-BioB-3_at	284.4	327.3	421.6	336.6	391.3	412.6	
AFFX-BioC-5_at	2314.2	1685.3	2264.7	2204.1	2233.1	2458.4	
AFFX-BioC-3_at	1574.5	1273.0	1484.6	1321.2	1474.7	1774.1	
AFFX-BioDn-5_at	2333.7	1796.8	2464.5	2372.5	2095.9	2735.7	
AFFX-BioDn-3_at	13673.9	11463.9	13624.7	14513.9	12934.1	16293.1	
AFFX-CreX-5_at	17778.8	15248.8	19977.2	19613.4	18609.1	18988.2	
AFFX-CreX-3_at	31056.6	24869.9	30773.4	32918.6	34412.1	33954.6	
AFFX-DapX-5_at	36.3	69.8	92.0	52.0	57.3	64.9	
AFFX-DapX-M_at	133.4	75.1	76.2	108.9	74.0	100.2	
AFFX-DapX-3_at	10.0	11.1	84.0	9.6	9.3	9.6	
AFFX-LysX-5_at	40.4	31.1	8.3	6.6	8.6	50.0	
AFFX-LysX-M_at	12.8	16.5	65.2	67.8	13.7	39.1	
AFFX-LysX-3_at	66.1	8.6	83.5	9.4	43.9	28.7	
AFFX-PheX-5_at	14.8	17.6	9.7	14.7	15.2	19.3	
AFFX-PheX-M_at	70.6	12.4	22.8	88.0	8.0	18.5	
AFFX-PheX-3_at	33.2	97.4	31.6	31.7	129.5	11.1	
AFFX-ThrX-5_at	26.4	31.3	14.5	23.4	28.1	24.2	
AFFX-ThrX-M_at	87.4	43.9	89.4	33.0	52.4	52.8	
AFFX-ThrX-3_at	19.9	18.9	13.9	26.1	24.0	17.0	
AFFX-TrpnX-5_at	32.6	13.5	26.5	11.4	60.3	18.4	
AFFX-TrpnX-M_at	14.9	7.5	12.1	10.1	11.3	12.8	
AFFX-TrpnX-3_at	17.3	4.3	7.0	26.0	2.3	8.6	










From deepayan.sarkar at gmail.com  Fri Nov 25 21:25:50 2005
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Fri, 25 Nov 2005 14:25:50 -0600
Subject: [Rd] 'partial' in sort() inefficient?
Message-ID: <eb555e660511251225k37d2e305v4bf54e2d5489b4de@mail.gmail.com>

I often need to work with large vectors whose distribution I want to
summarize by Q-Q plots.  Since the vectors are large, I use a subset
of quantiles, e.g.

quantile(x, probs = ppoints(1000))

Unfortunately, this seemed to be taking too long for large x (much
longer than 'sort').  I initially thought maybe quantile was doing
something sophisticated (which I don't really need with a large data
set), so I would write something simple myself.  I did, but then I
noticed that 'quantile' was doing essentially the same thing, with the
exception that it was calling 'sort' with a non-null 'partial'
argument.


?sort says:

     If 'partial' is not 'NULL', it is taken to contain indices of
     elements of 'x' which are to be placed in their correct positions
     by partial sorting.  After the sort, the values specified in
     'partial' are in their correct position in the sorted array.  Any
     values smaller than these values are guaranteed to have a smaller
     index in the sorted array and any values which are greater are
     guaranteed to have a bigger index in the sorted array.  This is
     included for efficiency, and many of the options are not available
     for partial sorting.

However, rather than being efficient, this seems to considerably slow
things down (I haven't checked memory efficiency).  Consider the
following code (imitating what 'quantile' does by default):


probs <- ppoints(1000)

for (i in seq(5000, 50000, 5000))
{
     x <- rnorm(i)
     n <- length(x)
     index <- 1 + (n - 1) * probs
     lo <- floor(index)
     hi <- ceiling(index)
     keep <- as.integer(unique(c(lo, hi)))
     cat(system.time(y1 <- sort(x, partial = keep))[1])
     cat("\t")
     cat(system.time(y2 <- sort(x))[1])
     cat("\t")
     cat(round(max(abs( y1 - y2 )), digits = 3))
     cat("\t")
     cat(max(abs( y1[keep] - y2[keep] )))
     cat("\n")
}


The first two columns in the output are timings for 'sort' with and
without 'partial', the last two columns are just a rough check that
partial sorting is doing what it claims.  With R-2.2:


0.78    0       0.031   0
1.64    0.01    0.565   0
2.59    0.01    0.646   0
3.44    0.01    0.487   0
4.4     0.01    0.569   0
5.26    0.01    0.642   0
6.29    0.01    1.071   0
7.18    0.02    0.566   0
8.18    0.02    1.094   0
9.01    0.03    0.89    0
> version
         _
platform i686-pc-linux-gnu
arch     i686
os       linux-gnu
system   i686, linux-gnu
status   Patched
major    2
minor    2.0
year     2005
month    10
day      16
svn rev  35911
language R


This also holds on (a faster machine running) r-devel


0.39    0       0.176   0
0.85    0.01    0.62    0
1.32    0       0.193   0
1.8     0       0.949   0
2.29    0       0.73    0
2.77    0       1.185   0
3.25    0.01    0.813   0
3.75    0.01    1.171   0
4.21    0.01    0.827   0
4.74    0.01    0.372   0
> version
         _
platform x86_64-unknown-linux-gnu
arch     x86_64
os       linux-gnu
system   x86_64, linux-gnu
status   Under development (unstable)
major    2
minor    3.0
year     2005
month    11
day      25
svn rev  36468
language R


Speed improves when the number of 'partial' indices is small, but even
for 10 indices plain 'sort' is faster.

Am I missing something?  I haven't checked if NA's make a difference
or if there might be memory usage issues, but even so, could
'quantile' at least have an option to disable partial sorting?

Deepayan


From joelpf at u.washington.edu  Fri Nov 25 22:38:47 2005
From: joelpf at u.washington.edu (joelpf@u.washington.edu)
Date: Fri, 25 Nov 2005 22:38:47 +0100 (CET)
Subject: [Rd] "integrate" error using a constant function (PR#8348)
Message-ID: <20051125213847.8BA0F103B2@slim.kubism.ku.dk>

Full_Name: Joel Franklin
Version: 2.2.0
OS: WinXP-Prof
Submission from: (NULL) (63.226.223.22)


The "integrate" function, when evaluating an integrand function that is constant
(therefore not a function of the integral) cannot be valuated, and instead
throws an error. Instead, the interate function should evaluate the constant
function as a rectangular area with length (upper-lower).

For example:

integrand<-function(x){5}
integrate(f=integrand,lower=1,upper=5)

"Error in integrate(f = integrand, lower = 1, upper = 5) : 
        evaluation of function gave a result of wrong length"


From ehlers at math.ucalgary.ca  Sat Nov 26 00:26:26 2005
From: ehlers at math.ucalgary.ca (P Ehlers)
Date: Fri, 25 Nov 2005 16:26:26 -0700
Subject: [Rd] "integrate" error using a constant function (PR#8348)
In-Reply-To: <20051125213847.8BA0F103B2@slim.kubism.ku.dk>
References: <20051125213847.8BA0F103B2@slim.kubism.ku.dk>
Message-ID: <43879DA2.2090701@math.ucalgary.ca>

Did you check the examples on the help page for integrate?

integrand <- function(x) rep(5, length(x))

should do it. Definitely not a bug.

Peter

joelpf at u.washington.edu wrote:

> Full_Name: Joel Franklin
> Version: 2.2.0
> OS: WinXP-Prof
> Submission from: (NULL) (63.226.223.22)
> 
> 
> The "integrate" function, when evaluating an integrand function that is constant
> (therefore not a function of the integral) cannot be valuated, and instead
> throws an error. Instead, the interate function should evaluate the constant
> function as a rectangular area with length (upper-lower).
> 
> For example:
> 
> integrand<-function(x){5}
> integrate(f=integrand,lower=1,upper=5)
> 
> "Error in integrate(f = integrand, lower = 1, upper = 5) : 
>         evaluation of function gave a result of wrong length"
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Peter Ehlers
Department of Mathematics and Statistics
University of Calgary, 2500 University Dr. NW       ph: 403-220-3936
Calgary, Alberta  T2N 1N4, CANADA                  fax: 403-282-5150


From bill at insightful.com  Sat Nov 26 01:46:58 2005
From: bill at insightful.com (bill@insightful.com)
Date: Fri, 25 Nov 2005 16:46:58 -0800 (PST)
Subject: [Rd] list.files(recursive=T) does not return directory names
Message-ID: <Pine.GSO.4.56.0511251633420.4828@durian.statsci.com>

list.files() (and dir()) don't appear to return names of
directories when one uses the recursive=T argument.  E.g.,
  > dir(file.path(R.home(),"library"), pattern="^R$", recursive=T)
  [1] "Malmig/help/R"
but the unix find commmand finds lots of R directories
  > z <- system(paste("find", file.path(R.home(),"library"), "-name R"), intern=T)
  > length(z)
  [1] 665
  > file.info(z[1:3])[,1:3]
                                            size isdir mode
  /dept/devel/sw/R/R.linux/R/library/aCGH/R 4096  TRUE 2755
  /dept/devel/sw/R/R.linux/R/library/RBGL/R 4096  TRUE 2755
  /dept/devel/sw/R/R.linux/R/library/XML/R  4096  TRUE 2755

The help file is silent on this behavior.  I am writing
an emulation of these for functions for Splus and was
wondering about 3 things.

a) Is this behavior intended?

b) Is there an easy way to get the names of all directories
under a given one?

b) I would like to add an argument to list.files() to specify
that I'd like the names of only non-directories, only directories,
or both.  I've tentatively called this argument "type" (following
the unix find command) and the acceptable values are "files",
"directories", and "all" (or any abbreviation).  Symbolic links,
fifos, etc. might be nice, but I don't want to fill the code
with unixisms or tempt folks to use them.  Would adding
	type = "files","directories","all"
to list.files and dir conflict with any plans for R's list.files
or dir?

----------------------------------------------------------------------------
Bill Dunlap
Insightful Corporation
bill at insightful dot com
360-428-8146
 "Formerly known as MathSoft, Insightful Corporation provides analytical
 solutions leveraging S-PLUS, StatServer and consulting services."

 "All statements in this message represent the opinions of the author and do
 not necessarily reflect Insightful Corporation policy or position."


From hb at maths.lth.se  Sat Nov 26 07:14:22 2005
From: hb at maths.lth.se (Henrik Bengtsson)
Date: Sat, 26 Nov 2005 17:14:22 +1100
Subject: [Rd] list.files(recursive=T) does not return directory names
In-Reply-To: <Pine.GSO.4.56.0511251633420.4828@durian.statsci.com>
References: <Pine.GSO.4.56.0511251633420.4828@durian.statsci.com>
Message-ID: <4387FD3E.5000601@maths.lth.se>

Hi,

the R.utils package has a function listDirectory() that returns the 
directory names too.  (I've made some changes to the function recently, 
which is not in the CRAN version, so get it from http://www.braju.com/R/ 
instead.)

The package also has isFile() and isDirectory() to test if a pathname 
refers to an existing file and directory, respectively.  These are not 
"vectorized" (yet), so you have to call them with sapply() if you have 
many pathnames, e.g.

 > path <- file.path(R.home(), "share")
 > ld <- listDirectory(path, recursive=TRUE, fullNames=TRUE)
 > ld[sapply(ld, isDirectory)]
  [1] "C:\\PROGRA~1\\R\\rw2011pat/share/licenses"
  [2] "C:\\PROGRA~1\\R\\rw2011pat/share/locale"
  [3] "C:\\PROGRA~1\\R\\rw2011pat/share/make"
...
[27] "C:\\PROGRA~1\\R\\rw2011pat/share/perl/R"
[28] "C:\\PROGRA~1\\R\\rw2011pat/share/perl/Text"
 > ld[sapply(ld, isFile)]
  [1] "C:\\PROGRA~1\\R\\rw2011pat/share/licenses/Artistic"
  [2] "C:\\PROGRA~1\\R\\rw2011pat/share/licenses/BSD"
  [3] "C:\\PROGRA~1\\R\\rw2011pat/share/licenses/GPL-2"
...
[50] "C:\\PROGRA~1\\R\\rw2011pat/share/texmf/ts1aett.fd"
[51] "C:\\PROGRA~1\\R\\rw2011pat/share/texmf/upquote.sty"

Hope this helps.

BTW, this package also have functions to read Windows Shortcuts files 
(*.lnk) and the function filePath("data", "raw", expandLinks="any") will 
recognize if any part is a shortcut to another directory, e.g. data.lnk 
links to another directory containing subdirectory "raw" (and directory 
data/ does not exist).  (filePath() also not vectorized). 
listDirectory() does not follow Windows Shortcuts.

Henrik


bill at insightful.com wrote:
> list.files() (and dir()) don't appear to return names of
> directories when one uses the recursive=T argument.  E.g.,
>   > dir(file.path(R.home(),"library"), pattern="^R$", recursive=T)
>   [1] "Malmig/help/R"
> but the unix find commmand finds lots of R directories
>   > z <- system(paste("find", file.path(R.home(),"library"), "-name R"), intern=T)
>   > length(z)
>   [1] 665
>   > file.info(z[1:3])[,1:3]
>                                             size isdir mode
>   /dept/devel/sw/R/R.linux/R/library/aCGH/R 4096  TRUE 2755
>   /dept/devel/sw/R/R.linux/R/library/RBGL/R 4096  TRUE 2755
>   /dept/devel/sw/R/R.linux/R/library/XML/R  4096  TRUE 2755
> 
> The help file is silent on this behavior.  I am writing
> an emulation of these for functions for Splus and was
> wondering about 3 things.
> 
> a) Is this behavior intended?
> 
> b) Is there an easy way to get the names of all directories
> under a given one?
> 
> b) I would like to add an argument to list.files() to specify
> that I'd like the names of only non-directories, only directories,
> or both.  I've tentatively called this argument "type" (following
> the unix find command) and the acceptable values are "files",
> "directories", and "all" (or any abbreviation).  Symbolic links,
> fifos, etc. might be nice, but I don't want to fill the code
> with unixisms or tempt folks to use them.  Would adding
> 	type = "files","directories","all"
> to list.files and dir conflict with any plans for R's list.files
> or dir?
> 
> ----------------------------------------------------------------------------
> Bill Dunlap
> Insightful Corporation
> bill at insightful dot com
> 360-428-8146
>  "Formerly known as MathSoft, Insightful Corporation provides analytical
>  solutions leveraging S-PLUS, StatServer and consulting services."
> 
>  "All statements in this message represent the opinions of the author and do
>  not necessarily reflect Insightful Corporation policy or position."
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
>


From glsmah001 at mail.uct.ac.za  Sat Nov 26 13:54:03 2005
From: glsmah001 at mail.uct.ac.za (glsmah001@mail.uct.ac.za)
Date: Sat, 26 Nov 2005 13:54:03 +0100 (CET)
Subject: [Rd] Rcmdr for Tiger Mac OS not running (PR#8350)
Message-ID: <20051126125403.E32E0CC6A@slim.kubism.ku.dk>

Full_Name: Maha  Golestaneh
Version: Mac OS
OS: Tiger 10.4.3
Submission from: (NULL) (155.232.250.19)


Cannot load and run Rcmdr on R for Tiger MacOS X.4.3.


From jfox at mcmaster.ca  Sat Nov 26 15:26:22 2005
From: jfox at mcmaster.ca (John Fox)
Date: Sat, 26 Nov 2005 09:26:22 -0500
Subject: [Rd] When, where,
	and how to report bugs [was Rcmdr for Tiger Mac OS not running
	(PR#8350)]
In-Reply-To: <20051126125403.E32E0CC6A@slim.kubism.ku.dk>
Message-ID: <20051126142622.JQEL1799.tomts40-srv.bellnexxia.net@JohnDesktop8300>

Dear Maha,

Before posting a bug report please read the R Mailing Lists Posting Guide
<http://www.r-project.org/posting-guide.html> and the information in the R
FAQ about posting bugs
<http://cran.r-project.org/doc/FAQ/R-FAQ.html#R-Bugs>.

Among other things, a problem with the Rcmdr package is not a bug in R. (It
may or may not be a bug in the Rcmdr package.) Moreover, you've already
posted this problem to the r-help mailing list, and Rob Goedman has offered
to help you. Finally, this bug report has no information in it.

Regards,
 John

--------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario
Canada L8S 4M4
905-525-9140x23604
http://socserv.mcmaster.ca/jfox 
-------------------------------- 

> -----Original Message-----
> From: r-devel-bounces at r-project.org 
> [mailto:r-devel-bounces at r-project.org] On Behalf Of 
> glsmah001 at mail.uct.ac.za
> Sent: Saturday, November 26, 2005 7:54 AM
> To: r-devel at stat.math.ethz.ch
> Cc: R-bugs at biostat.ku.dk
> Subject: [Rd] Rcmdr for Tiger Mac OS not running (PR#8350)
> 
> Full_Name: Maha  Golestaneh
> Version: Mac OS
> OS: Tiger 10.4.3
> Submission from: (NULL) (155.232.250.19)
> 
> 
> Cannot load and run Rcmdr on R for Tiger MacOS X.4.3.
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From berwin at maths.uwa.edu.au  Sat Nov 26 17:51:51 2005
From: berwin at maths.uwa.edu.au (Berwin A Turlach)
Date: Sun, 27 Nov 2005 00:51:51 +0800
Subject: [Rd] Help page of "par"
Message-ID: <17288.37543.501344.534298@bossiaea.maths.uwa.edu.au>

Dear all,

the second paragraph on the value returned by par() on the help page
of par says:

     When just one parameter is queried, the value is a character
     string. When two or more parameters are queried, the result is a
     list of character strings, with the list names giving the
     parameters.

But this does not seem to be correct:

> par("lty", "ask", "lwd", "oma")
$lty
[1] "solid"

$ask
[1] FALSE

$lwd
[1] 1

$oma
[1] 0 0 0 0

Only the first one is a character string, the other ones are a
logical, a number and a vector of numbers, respectively.  Should it
rather be something like (also in view of the next sentence):

     When just one parameter is queried, the value of that parameter
     is returned as a vector.  When two or more parameters are
     queried, their values are returned in a list, with the list names
     giving the parameters.

Cheers,

        Berwin


From maechler at stat.math.ethz.ch  Sat Nov 26 18:36:12 2005
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Sat, 26 Nov 2005 18:36:12 +0100
Subject: [Rd] Help page of "par"
In-Reply-To: <17288.37543.501344.534298@bossiaea.maths.uwa.edu.au>
References: <17288.37543.501344.534298@bossiaea.maths.uwa.edu.au>
Message-ID: <17288.40204.421391.330744@stat.math.ethz.ch>

Thank you, Berwin.

You are definitely right,
and I have committed a fix to R-patched and R-devel.

Maybe  help(par)  has been just too long a document to be really read .. ;-)

Martin

>>>>> "BeT" == Berwin A Turlach <berwin at maths.uwa.edu.au>
>>>>>     on Sun, 27 Nov 2005 00:51:51 +0800 writes:

    BeT> Dear all,
    BeT> the second paragraph on the value returned by par() on the help page
    BeT> of par says:

    BeT> When just one parameter is queried, the value is a character
    BeT> string. When two or more parameters are queried, the result is a
    BeT> list of character strings, with the list names giving the
    BeT> parameters.

    BeT> But this does not seem to be correct:

    >> par("lty", "ask", "lwd", "oma")
    BeT> $lty
    BeT> [1] "solid"

    BeT> $ask
    BeT> [1] FALSE

    BeT> $lwd
    BeT> [1] 1

    BeT> $oma
    BeT> [1] 0 0 0 0

    BeT> Only the first one is a character string, the other ones are a
    BeT> logical, a number and a vector of numbers, respectively.  Should it
    BeT> rather be something like (also in view of the next sentence):

    BeT> When just one parameter is queried, the value of that parameter
    BeT> is returned as a vector.  When two or more parameters are
    BeT> queried, their values are returned in a list, with the list names
    BeT> giving the parameters.

    BeT> Cheers,

    BeT> Berwin

    BeT> ______________________________________________
    BeT> R-devel at r-project.org mailing list
    BeT> https://stat.ethz.ch/mailman/listinfo/r-devel


From sfalcon at fhcrc.org  Sun Nov 27 05:02:21 2005
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Sat, 26 Nov 2005 20:02:21 -0800
Subject: [Rd] segfault on write.dcf with gzfile connection
Message-ID: <m2wtiuviuq.fsf@ziti.local>

I'm seeing a segfault on x86_64 Linux with the following code:

    desc = read.dcf("BAD")
    con = gzfile("test.gz", "wt")
    write.dcf(desc, file=con)
    close(con)    

where BAD has a long field (see below for example).  The crash happens
inside dummy_vfprintf.  I think the issue is that the va_list ap is
modified by the first vsnprintf call (connections.c:190) and the
subsequent vsprintf call (connections.c:194) gets an invalid va_list
arg.

The following patch improves things for me, but I've not tested on
other platforms.


Index: connections.c
===================================================================
--- connections.c       (revision 36434)
+++ connections.c       (working copy)
@@ -186,8 +186,11 @@
 {   
     char buf[BUFSIZE], *b = buf, *vmax = vmaxget();
     int res, usedRalloc = FALSE;
+    va_list aq;

-    res = vsnprintf(buf, BUFSIZE, format, ap);
+    va_copy(aq, ap);
+    res = vsnprintf(buf, BUFSIZE, format, aq);
+    va_end(aq);
     if(res >= BUFSIZE) { /* res is the desired output length */
        usedRalloc = TRUE;
        b = R_alloc(res + 1, sizeof(char));        


And here is an example BAD file, but I'm pretty sure any DCF field
with a very long value would trigger it:


Description: The package provides and API in R to query BioMart
        system which produces and maintains automatic annotation on
        system which produces and maintains automatic annotation on
        system which produces and maintains automatic annotation on
        system which produces and maintains automatic annotation on
        system which produces and maintains automatic annotation on
        system which produces and maintains automatic annotation on
        system which produces and maintains automatic annotation on
        system which produces and maintains automatic annotation on
        system which produces and maintains automatic annotation on
        system which produces and maintains automatic annotation on
        system which produces and maintains automatic annotation on
        system which produces and maintains automatic annotation on
        system which produces and maintains automatic annotation on
        system which produces and maintains automatic annotation on
        system which produces and maintains automatic annotation on
        system which produces and maintains automatic annotation on
        system which produces and maintains automatic annotation on
        system which produces and maintains automatic annotation on
        system which produces and maintains automatic annotation on
        system which produces and maintains automatic annotation on
        system which produces and maintains automatic annotation on
        system which produces and maintains automatic annotation on
        system which produces and maintains automatic annotation on
        system which produces and maintains automatic annotation on
        system which produces and maintains automatic annotation on
        system which produces and maintains automatic annotation on


From ripley at stats.ox.ac.uk  Sun Nov 27 10:40:02 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 27 Nov 2005 09:40:02 +0000 (GMT)
Subject: [Rd] segfault on write.dcf with gzfile connection
In-Reply-To: <m2wtiuviuq.fsf@ziti.local>
References: <m2wtiuviuq.fsf@ziti.local>
Message-ID: <Pine.LNX.4.61.0511270936460.1182@gannet.stats>

Unfortunately va_copy is an ISO C99 function, so not always available.

Please do heed the posting guide and give us real details of your OS and 
compiler, as they do matter here (stdarg.h is often compiler-specific).

On Sat, 26 Nov 2005, Seth Falcon wrote:

> I'm seeing a segfault on x86_64 Linux with the following code:
>
>    desc = read.dcf("BAD")
>    con = gzfile("test.gz", "wt")
>    write.dcf(desc, file=con)
>    close(con)
>
> where BAD has a long field (see below for example).  The crash happens
> inside dummy_vfprintf.  I think the issue is that the va_list ap is
> modified by the first vsnprintf call (connections.c:190) and the
> subsequent vsprintf call (connections.c:194) gets an invalid va_list
> arg.
>
> The following patch improves things for me, but I've not tested on
> other platforms.
>
>
> Index: connections.c
> ===================================================================
> --- connections.c       (revision 36434)
> +++ connections.c       (working copy)
> @@ -186,8 +186,11 @@
> {
>     char buf[BUFSIZE], *b = buf, *vmax = vmaxget();
>     int res, usedRalloc = FALSE;
> +    va_list aq;
>
> -    res = vsnprintf(buf, BUFSIZE, format, ap);
> +    va_copy(aq, ap);
> +    res = vsnprintf(buf, BUFSIZE, format, aq);
> +    va_end(aq);
>     if(res >= BUFSIZE) { /* res is the desired output length */
>        usedRalloc = TRUE;
>        b = R_alloc(res + 1, sizeof(char));
>
>
> And here is an example BAD file, but I'm pretty sure any DCF field
> with a very long value would trigger it:
>
>
> Description: The package provides and API in R to query BioMart
>        system which produces and maintains automatic annotation on
>        system which produces and maintains automatic annotation on
>        system which produces and maintains automatic annotation on
>        system which produces and maintains automatic annotation on
>        system which produces and maintains automatic annotation on
>        system which produces and maintains automatic annotation on
>        system which produces and maintains automatic annotation on
>        system which produces and maintains automatic annotation on
>        system which produces and maintains automatic annotation on
>        system which produces and maintains automatic annotation on
>        system which produces and maintains automatic annotation on
>        system which produces and maintains automatic annotation on
>        system which produces and maintains automatic annotation on
>        system which produces and maintains automatic annotation on
>        system which produces and maintains automatic annotation on
>        system which produces and maintains automatic annotation on
>        system which produces and maintains automatic annotation on
>        system which produces and maintains automatic annotation on
>        system which produces and maintains automatic annotation on
>        system which produces and maintains automatic annotation on
>        system which produces and maintains automatic annotation on
>        system which produces and maintains automatic annotation on
>        system which produces and maintains automatic annotation on
>        system which produces and maintains automatic annotation on
>        system which produces and maintains automatic annotation on
>        system which produces and maintains automatic annotation on
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From sfalcon at fhcrc.org  Sun Nov 27 18:14:28 2005
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Sun, 27 Nov 2005 09:14:28 -0800
Subject: [Rd] segfault on write.dcf with gzfile connection
In-Reply-To: <Pine.LNX.4.61.0511270936460.1182@gannet.stats> (Brian Ripley's
	message of "Sun, 27 Nov 2005 09:40:02 +0000 (GMT)")
References: <m2wtiuviuq.fsf@ziti.local>
	<Pine.LNX.4.61.0511270936460.1182@gannet.stats>
Message-ID: <m2mzjqui6j.fsf@ziti.local>

On 27 Nov 2005, ripley at stats.ox.ac.uk wrote:

> Unfortunately va_copy is an ISO C99 function, so not always
> available.
>
> Please do heed the posting guide and give us real details of your OS
> and compiler, as they do matter here (stdarg.h is often
> compiler-specific).

    > R.version
             _                           
    platform x86_64-unknown-linux-gnu    
    arch     x86_64                      
    os       linux-gnu                   
    system   x86_64, linux-gnu           
    status   Under development (unstable)
    major    2                           
    minor    3.0                         
    year     2005                        
    month    11                          
    day      23                          
    svn rev  36434                       
    language R             

    gcc --version
    gcc (GCC) 3.3.4 (pre 3.3.5 20040809)      

This page appears to have useful documentation:
http://www.unixpapa.com/incnote/variadic.html

Thinking out loud: Does writecon need to be variadic?  It is only
called once with a fixed format string "%s%s".


From ripley at stats.ox.ac.uk  Sun Nov 27 23:10:07 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 27 Nov 2005 22:10:07 +0000 (GMT)
Subject: [Rd] segfault on write.dcf with gzfile connection
In-Reply-To: <m2mzjqui6j.fsf@ziti.local>
References: <m2wtiuviuq.fsf@ziti.local>
	<Pine.LNX.4.61.0511270936460.1182@gannet.stats>
	<m2mzjqui6j.fsf@ziti.local>
Message-ID: <Pine.LNX.4.61.0511271741470.18706@gannet.stats>

On Sun, 27 Nov 2005, Seth Falcon wrote:

> On 27 Nov 2005, ripley at stats.ox.ac.uk wrote:
>
>> Unfortunately va_copy is an ISO C99 function, so not always
>> available.
>>
>> Please do heed the posting guide and give us real details of your OS
>> and compiler, as they do matter here (stdarg.h is often
>> compiler-specific).
>
>    > R.version
>             _
>    platform x86_64-unknown-linux-gnu
>    arch     x86_64
>    os       linux-gnu
>    system   x86_64, linux-gnu
>    status   Under development (unstable)
>    major    2
>    minor    3.0
>    year     2005
>    month    11
>    day      23
>    svn rev  36434
>    language R
>
>    gcc --version
>    gcc (GCC) 3.3.4 (pre 3.3.5 20040809)

Thanks.  The only one of my systems that seems to have any problem is FC3 
x86_64 with gcc 3.4.3.  The fixes I have put in (different on R-patched 
and R-devel) fix this example and the one now in reg-tests-1-R on that 
machine at least.

> This page appears to have useful documentation:
> http://www.unixpapa.com/incnote/variadic.html

It's somewhat dated: (almost-)C99 compilers are much more common these 
days.

> Thinking out loud: Does writecon need to be variadic?  It is only
> called once with a fixed format string "%s%s".

It does not, but the print method for gzfile connections does.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From maechler at stat.math.ethz.ch  Mon Nov 28 11:49:40 2005
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 28 Nov 2005 11:49:40 +0100
Subject: [Rd] as.data.frame() : needs "..." ?!
In-Reply-To: <971536df0511271116g29b2b469i2d87abc53addc173@mail.gmail.com>
References: <20051127174920.48183.qmail@web51914.mail.yahoo.com>
	<XFMail.051127182712.Ted.Harding@nessie.mcc.ac.uk>
	<971536df0511271116g29b2b469i2d87abc53addc173@mail.gmail.com>
Message-ID: <17290.57540.60564.949167@stat.math.ethz.ch>

       [diverted from R-help to R-devel]

>>>>> "Gabor" == Gabor Grothendieck <ggrothendieck at gmail.com>
>>>>>     on Sun, 27 Nov 2005 14:16:34 -0500 writes:

	  <................>

    Gabor> making use of as.data.frame.table we can shorten that
    Gabor> slightly to just:

    Gabor> as.data.frame.table(table(Species = iris$Species),
    Gabor>                     responseName = "Count")

    Gabor> Incidently, I just noticed that there is an
    Gabor> inconsistency between as.data.frame and
    Gabor> as.data.frame.table making it impossible to shorten
    Gabor> as.data.frame.table to as.data.frame in the above due
    Gabor> to the responseName= argument which is not referenced
    Gabor> in the generic.

    >> args(as.data.frame)
    Gabor> function (x, row.names = NULL, optional = FALSE)
    Gabor> NULL
    >> args(as.data.frame.table)
    Gabor> function (x, row.names = NULL, optional = FALSE, Gabor> responseName = "Freq")
    Gabor> NULL

  {If you used  str() instead of args()  ,  you wouldn't get the
   superfluous extra 'NULL' line }

I think this is an example where we (R-core) haven't followed
our own recommendations, namely, that  generic functions (and
methods) need to have a (trailing) "..." argument
just so that new methods can have further arguments.

I'm wondering a bit... 
or could there be a good reason in the present case,
why this hasn't been done?

Martin


From Matthias.Kohl at stamats.de  Mon Nov 28 12:16:33 2005
From: Matthias.Kohl at stamats.de (Matthias Kohl)
Date: Mon, 28 Nov 2005 12:16:33 +0100
Subject: [Rd] import of Namespaces
Message-ID: <438AE711.4000708@stamats.de>

Dear R devels,

let's say I have three packages "pkg1", "pkg2" and "pkg3" which all 
contain new S4 classes and methods. Where "pkg3" depends on "pkg2" and 
"pkg2" depends on "pkg1". Moreover, all three packages have namespaces.

1) I use ".onLoad <- function(lib, pkg) require(methods)". Do I also 
have to import the namespace of "methods" package?

2) If I use import("pkg1") in the namespace of "pkg2", does this also 
(correctly) import the S4 classes and methods of "pkg1"? Or do I 
explicitly have to use importClassesFrom resp. importMethodsFrom?

3) If I import the Namespace of "pkg2" in "pkg3", where the namespace of 
"pkg2" has import("pkg1") (or maybe importClassesFrom, 
importMethodsFrom) and I also want to use S4 classes and methods of 
"pkg1" in "pkg3". Is it sufficient to have import("pkg2") in the 
Namespace of "pkg3" or do I need import("pkg1") and import("pkg2")?

Many thanks for your help and advice
Matthias

-- 
StaMatS - Statistik + Mathematik Service
Dipl.Math.(Univ.) Matthias Kohl
www.stamats.de


From s.wood at bath.ac.uk  Mon Nov 28 14:09:42 2005
From: s.wood at bath.ac.uk (s.wood@bath.ac.uk)
Date: Mon, 28 Nov 2005 14:09:42 +0100 (CET)
Subject: [Rd] terms.object documentation bug? (PR#8353)
Message-ID: <20051128130942.2769823221@slim.kubism.ku.dk>

Full_Name: simon wood
Version: 2.2.0 (and lower)
OS: linux/windows
Submission from: (NULL) (86.135.153.59)


I think that the documentation for the `specials' attribute of a `terms.object'
is not quite right:

specials: If the 'specials' argument was given to 'terms.formula' there
          is a 'specials' attribute, a list of vectors indicating the
          terms that contain these special functions.

should read something like:

specials: If the 'specials' argument was given to 'terms.formula' there
          is a 'specials' attribute, a list of vectors indicating the
          variables that contain these special functions.

Here is some example code illustrating the problem:

tf <- terms.formula(y~x+x:z+s(x),specials="s") ## make a `terms' object
attr(tf,"specials") ## documented to index `s' in list of terms
## but in lists of terms, `s' is in position 2, not 4 ....
attr(tf,"term.labels")
colnames(attr(tf,"factors"))

## in lists of variables `s' *is* in position 4...
attr(tf,"variables")
rownames(attr(tf,"factors"))

best,
Simon


From jpiitula at ling.helsinki.fi  Mon Nov 28 15:41:27 2005
From: jpiitula at ling.helsinki.fi (Jussi Piitulainen)
Date: 28 Nov 2005 16:41:27 +0200
Subject: [Rd] No Rmath.h when making just standalone library
Message-ID: <qot3blgu960.fsf@venus.ling.helsinki.fi>

When making only the standalone math library, include/Rmath.h
is not there, so compilation fails. A solution is to go to
src/include/ and just say `make Rmath.h' there first.

This is with R-2.2.0 on GNU/Linux on i686. The failing steps
are:

tar xzf ../R-2.2.0.tar.gz
./configure
cd src/nmath/standalone
make

Would be nice if this worked, or if the issue were just
mentioned in src/nmath/standalone/README.


From ripley at stats.ox.ac.uk  Mon Nov 28 16:28:18 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 28 Nov 2005 15:28:18 +0000 (GMT)
Subject: [Rd] No Rmath.h when making just standalone library
In-Reply-To: <qot3blgu960.fsf@venus.ling.helsinki.fi>
References: <qot3blgu960.fsf@venus.ling.helsinki.fi>
Message-ID: <Pine.LNX.4.61.0511281520150.15571@gannet.stats>

On Mon, 28 Nov 2005, Jussi Piitulainen wrote:

> When making only the standalone math library, include/Rmath.h
> is not there, so compilation fails. A solution is to go to
> src/include/ and just say `make Rmath.h' there first.
>
> This is with R-2.2.0 on GNU/Linux on i686. The failing steps
> are:
>
> tar xzf ../R-2.2.0.tar.gz
> ./configure
> cd src/nmath/standalone
> make
>
> Would be nice if this worked, or if the issue were just
> mentioned in src/nmath/standalone/README.

It used to work as documented, and now does again.  Thank you for the 
report.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Mon Nov 28 19:55:05 2005
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Mon, 28 Nov 2005 19:55:05 +0100 (CET)
Subject: [Rd] terms.object documentation bug? (PR#8353)
Message-ID: <20051128185505.E4D1A15AB7@slim.kubism.ku.dk>

On Mon, 28 Nov 2005 s.wood at bath.ac.uk wrote:

> Full_Name: simon wood
> Version: 2.2.0 (and lower)
> OS: linux/windows
> Submission from: (NULL) (86.135.153.59)
>
>
> I think that the documentation for the `specials' attribute of a `terms.object'
> is not quite right:
>
> specials: If the 'specials' argument was given to 'terms.formula' there
>          is a 'specials' attribute, a list of vectors indicating the
>          terms that contain these special functions.

This is wrong, but it does not say `in the list of terms'.

> should read something like:
>
> specials: If the 'specials' argument was given to 'terms.formula' there
>          is a 'specials' attribute, a list of vectors indicating the
>          variables that contain these special functions.

You are right it refers to the variables, but we need to make 
clear that the vectors are numeric indices, and into what (not the 
variables attribute).

> Here is some example code illustrating the problem:
>
> tf <- terms.formula(y~x+x:z+s(x),specials="s") ## make a `terms' object
> attr(tf,"specials") ## documented to index `s' in list of terms
> ## but in lists of terms, `s' is in position 2, not 4 ....
> attr(tf,"term.labels")
> colnames(attr(tf,"factors"))
>
> ## in lists of variables `s' *is* in position 4...
> attr(tf,"variables")
> rownames(attr(tf,"factors"))

Thanks, I have adapted that for the help page.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From mschwartz at mn.rr.com  Mon Nov 28 22:54:13 2005
From: mschwartz at mn.rr.com (Marc Schwartz (via MN))
Date: Mon, 28 Nov 2005 15:54:13 -0600
Subject: [Rd] Proposed Patch for table.Rd
Message-ID: <1133214853.2495.33.camel@localhost.localdomain>

Hi all,

Attached is both a patch file for and a patched version of table.Rd.

The change is to add the following:

 \concept{counts}
 \concept{frequencies}
 \concept{occurrences}
 \concept{contingency table}

to enable help.search() to locate table() using the aforementioned
search terms.

This came up again this weekend and going back to the archives, these
seem to cover a significant proportion of the common search terms that
have been mentioned in relevant posts where it was suggested by the
responder to see ?table.

HTH,

Marc Schwartz

-------------- next part --------------
--- table.Rd	2005-10-06 07:50:32.000000000 -0500
+++ table-patched.Rd	2005-11-28 14:47:53.000000000 -0600
@@ -7,6 +7,10 @@
 \alias{as.table}
 \alias{as.table.default}
 \alias{is.table}
+\concept{counts}
+\concept{frequencies}
+\concept{occurrences}
+\concept{contingency table}
 \description{
   \code{table} uses the cross-classifying factors to build a contingency
   table of the counts at each combination of factor levels.
-------------- next part --------------
\name{table}
\title{Cross Tabulation and Table Creation}
\alias{table}
\alias{summary.table}
\alias{print.summary.table}
\alias{as.data.frame.table}
\alias{as.table}
\alias{as.table.default}
\alias{is.table}
\concept{counts}
\concept{frequencies}
\concept{occurrences}
\concept{contingency table}
\description{
  \code{table} uses the cross-classifying factors to build a contingency
  table of the counts at each combination of factor levels.
}
\usage{
table(\dots, exclude = c(NA, NaN), dnn = list.names(...),
      deparse.level = 1)
as.table(x, \dots)
is.table(x)

as.data.frame.table(x, row.names = NULL, optional = FALSE,
                    responseName = "Freq")
}
\arguments{
  \item{\dots}{objects which can be interpreted as factors (including
    character strings), or a list (or data frame) whose components can
    be so interpreted.  (For \code{as.table}, arguments passed to
    specific methods.)}
  \item{exclude}{values to use in the exclude argument of \code{\link{factor}}
    when interpreting non-factor objects; if specified, levels to remove
    from all factors in \code{\dots}.}
  \item{dnn}{the names to be given to the dimensions in the result (the
    \emph{dimnames names}).}
  \item{deparse.level}{controls how the default \code{dnn} is
    constructed.  See details.}
  \item{x}{an arbitrary \R object, or an object inheriting from class
    \code{"table"} for the \code{as.data.frame} method.}
  \item{row.names}{a character vector giving the row names for the data
    frame.}
  \item{optional}{a logical controlling whether row names are set.
    Currently not used.}
  \item{responseName}{The name to be used for the column of
    table entries, usually counts.}
}
\value{
  \code{table()} returns a \emph{contingency table}, an object of
  \code{\link[base]{class}} \code{"table"}, an array of integer values.

  There is a \code{summary} method for objects created by \code{table}
  or \code{\link{xtabs}}, which gives basic information and performs a
  chi-squared test for independence of factors (note that the function
  \code{\link{chisq.test}} currently only handles 2-d tables).

  \code{as.table} and \code{is.table} coerce to and test for contingency
  table, respectively.

  The \code{as.data.frame} method for objects inheriting from class
  \code{"table"} can be used to convert the array-based representation
  of a contingency table to a data frame containing the classifying
  factors and the corresponding entries (the latter as component
  named by \code{responseName}).  This is the inverse of \code{\link{xtabs}}.
}
\details{
  If the argument \code{dnn} is not supplied, the internal function
  \code{list.names} is called to compute the \sQuote{dimname names}.  If the
  arguments in \code{\dots} are named, those names are used.  For the
  remaining arguments, \code{deparse.level = 0} gives an empty name,
  \code{deparse.level = 1} uses the supplied argument if it is a symbol,
  and \code{deparse.level = 2} will deparse the argument.

  Only when \code{exclude} is specified (i.e., not by default), will
  \code{table} drop levels of factor arguments potentially.

  Note that \code{as.data.frame.table} is also the \code{"table"} method
  for \code{\link{as.data.frame}}, but the \code{responseName} argument
  can only be given if it is called explicitly.
}
\seealso{Use \code{\link{ftable}} for printing (and more) of
  multidimensional tables.
}
\references{
  Becker, R. A., Chambers, J. M. and Wilks, A. R. (1988)
  \emph{The New S Language}.
  Wadsworth \& Brooks/Cole.
}
\examples{
require(stats) # for rpois and xtabs
## Simple frequency distribution
table(rpois(100,5))
attach(warpbreaks)
## Check the design:
table(wool, tension)
detach()
table(state.division, state.region)

# simple two-way contingency table
with(airquality, table(cut(Temp, quantile(Temp)), Month))

a <- letters[1:3]
table(a, sample(a))                    # dnn is c("a", "")
table(a, sample(a), deparse.level = 0) # dnn is c("", "")
table(a, sample(a), deparse.level = 2) # dnn is c("a", "sample(a)")

## xtabs() <-> as.data.frame.table() :
UCBAdmissions ## already a contingency table
DF <- as.data.frame(UCBAdmissions)
class(tab <- xtabs(Freq ~ ., DF)) # xtabs & table
## tab *is* "the same" as the original table:
all(tab == UCBAdmissions)
all.equal(dimnames(tab), dimnames(UCBAdmissions))

a <- rep(c(NA, 1/0:3), 10)
table(a)
table(a, exclude=NULL)
b <- factor(rep(c("A","B","C"), 10))
table(b)
table(b, exclude="B")
d <- factor(rep(c("A","B","C"), 10), levels=c("A","B","C","D","E"))
table(d, exclude="B")

## NA counting:
is.na(d) <- 3:4
d <- factor(d, exclude=NULL)
d[1:7]
table(d, exclude = NULL)
}
\keyword{category}

From kjetilbrinchmannhalvorsen at gmail.com  Tue Nov 29 02:09:15 2005
From: kjetilbrinchmannhalvorsen at gmail.com (Kjetil Brinchmann Halvorsen)
Date: Mon, 28 Nov 2005 21:09:15 -0400
Subject: [Rd] buglet in ?StructTS
Message-ID: <438BAA3B.9050603@gmail.com>

?StructTS   has

The basic structural model, type = "BSM", is a local trend model with an 
additional seasonal component. Thus the measurement equation is

x[t] = m[t] + s[t] + eps[t], exp[t] ~ N(0, sigma^2_eps)

I guess in the last line exp[t] ~   should be
                          eps[t] ~ ...


Kjetil


From ripley at stats.ox.ac.uk  Tue Nov 29 08:54:34 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 29 Nov 2005 07:54:34 +0000 (GMT)
Subject: [Rd] Proposed Patch for table.Rd
In-Reply-To: <1133214853.2495.33.camel@localhost.localdomain>
References: <1133214853.2495.33.camel@localhost.localdomain>
Message-ID: <Pine.LNX.4.61.0511290754010.24766@gannet.stats>

Thanks, incorporated now.

On Mon, 28 Nov 2005, Marc Schwartz (via MN) wrote:

> Hi all,
>
> Attached is both a patch file for and a patched version of table.Rd.
>
> The change is to add the following:
>
> \concept{counts}
> \concept{frequencies}
> \concept{occurrences}
> \concept{contingency table}
>
> to enable help.search() to locate table() using the aforementioned
> search terms.
>
> This came up again this weekend and going back to the archives, these
> seem to cover a significant proportion of the common search terms that
> have been mentioned in relevant posts where it was suggested by the
> responder to see ?table.
>
> HTH,
>
> Marc Schwartz
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From maechler at stat.math.ethz.ch  Tue Nov 29 10:58:42 2005
From: maechler at stat.math.ethz.ch (maechler@stat.math.ethz.ch)
Date: Tue, 29 Nov 2005 10:58:42 +0100 (CET)
Subject: [Rd] (PR#8337)  formatC adds leading space -- on some Windoze
Message-ID: <20051129095842.E12FB15AD5@slim.kubism.ku.dk>

>>>>> "BDR" == Brian Ripley <ripley at stats.ox.ac.uk>
>>>>>     on Tue, 22 Nov 2005 09:35:19 +0100 (CET) writes:

    BDR> On Tue, 22 Nov 2005 maechler at stat.math.ethz.ch wrote:
    >>>>>>> "KevinW" == Kevin Wright <kwright68 at gmail.com>
    >>>>>>> on Mon, 21 Nov 2005 18:13:36 +0100 (CET) writes:
    >> 
    KevinW> Full_Name: Kevin Wright
    KevinW> Version: 2.2.0
    KevinW> OS: Windows 2000
    >>          ^^^^^^^
    >> this must be part of the problem

    BDR> It is, and it is a known inconsistency with Linux (but I do not consider 
    BDR> it to be a bug or `wrong behavior' or not `reasonable').

    BDR> Windows always uses three digits for the exponent, e.g. E+001. 

    BDR> This results from adjusting the returned result to be more consistent with 
    BDR> other platforms.  (BTW, since width (sic) is a lower bound, it _is_ 
    BDR> respected.)  Even if the layout is not ideal, the results are at least 
    BDR> diff-able against those from other platforms.

yes, and that's good ("diff-able").

Now, after looking in the source (src/appl/strsignif.c),
I understand what you mean above: Because Windows libc's sprintf()
produces 3-digits exponents *and* because you amended the code
to change these back to 2 digits, the extraneous blank is a
consequence that one had to live with.. 

OTOH, the oldest R on Windows I have, "2.0.1 patched
(2004-11-27)" does *not* prepend the extra " " and gives the
same as on non-windows in some cases, i.e.,

> formatC(pi * 10^(-5:4))
 [1] "3.142e-05" "0.0003142" "0.003142"  "0.03142"   "0.3142"    "3.142"    
 [7] "31.42"     "314.2"     "3142"      "3.142e+04"

Insofar, the  svn r35148 (2005-08-04 18:17:00) change
did produce a backward incompatibility.  
Which is why I confirmed Kevin that this was wrong behavior.

    BDR> If Kevin (or anyone else) wants it done even more
    BDR> consistently, he could contribute a patch.  

yes, that would be useful.
Particularly, since for some cases formatC() *was* more
consistent (see above).

    BDR> Now, we _have_ done that for print(), but it did not seem worth
    BDR> it for formatC (especially as sprintf() is now widely
    BDR> used and would also need to be made consistent).

I agree that sprintf should also be consistent, and I also agree
that for "real" programmers sprintf() is probably more useful
than formatC() which OTOH is easier to use for simple useRs.

    BDR> (It also did not seem worth it 
    BDR>  given how little credit is given for such work.)

    KevinW> Submission from: (NULL) (170.54.58.4)
    >> 

    KevinW> Apologies if my expectations (or reading of the man page) are incorrect.
    >> 
    KevinW> I seem unable to left-justify exponential format
    KevinW> numbers.  There appears to always be an extra space
    KevinW> inserted to the left.
    >> 
    KevinW> Using the example from the formatC help page:
    >> 
    R> xx  <- pi * 10^(-5:4)
    >> 
    R> cbind(formatC(xx, wid = 9, flag = "-"))
    KevinW> [,1]
    KevinW> [1,] " 3.142e-05"
    KevinW> [2,] "0.0003142"
    KevinW> [3,] "0.003142 "
    KevinW> [4,] "0.03142  "
    KevinW> [5,] "0.3142   "
    KevinW> [6,] "3.142    "
    KevinW> [7,] "31.42    "
    KevinW> [8,] "314.2    "
    KevinW> [9,] "3142     "
    KevinW> [10,] " 3.142e+04"
    >> 
    >> which is also not obeying the 'wid' argument.
    >> 
    >> I get something much more reasonable:
    >> 
    >> [,1]
    >> [1,] "3.142e-05"
    >> [2,] "0.0003142"
    >> [3,] "0.003142 "
    >> [4,] "0.03142  "
    >> [5,] "0.3142   "
    >> [6,] "3.142    "
    >> [7,] "31.42    "
    >> [8,] "314.2    "
    >> [9,] "3142     "
    >> [10,] "3.142e+04"
    >> 
    >> formatC uses your system's C library printf {that's where the
    >> "C" comes from in 'formatC'} which seems to be
    >> broken or at least not performing as we think it should.
    >> 
    >> On a "Windows 2003 Server" I have access to, I see the same
    >> wrong behavior as above.
    >> 
    >> Martin Maechler, ETH Zurich
    >> 
    >> ______________________________________________
    >> R-devel at r-project.org mailing list
    >> https://stat.ethz.ch/mailman/listinfo/r-devel
    >> 
    >> 

    BDR> -- 
    BDR> Brian D. Ripley,                  ripley at stats.ox.ac.uk
    BDR> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
    BDR> University of Oxford,             Tel:  +44 1865 272861 (self)
    BDR> 1 South Parks Road,                     +44 1865 272866 (PA)
    BDR> Oxford OX1 3TG, UK                Fax:  +44 1865 272595

    BDR> ______________________________________________
    BDR> R-devel at r-project.org mailing list
    BDR> https://stat.ethz.ch/mailman/listinfo/r-devel


From r.hankin at noc.soton.ac.uk  Tue Nov 29 11:41:33 2005
From: r.hankin at noc.soton.ac.uk (Robin Hankin)
Date: Tue, 29 Nov 2005 10:41:33 +0000
Subject: [Rd] x[1,], x[1,,], x[1,,,], ...
In-Reply-To: <4384498B.1080401@maths.lth.se>
References: <4384498B.1080401@maths.lth.se>
Message-ID: <EFF39129-E649-4485-BB79-00EAE5805B46@soc.soton.ac.uk>

Hi everyone


apltake(x,1)

[where apltake() is part of library(magic)]

does this.

best wishes

Robin




On 23 Nov 2005, at 10:50, Henrik Bengtsson wrote:

> Hi,
>
> is there a function in R already doing what I try to do below:
>
> # Let 'x' be an array with *any* number of dimensions (>=1).
> x <- array(1:24, dim=c(2,2,3,2))
> ...
> x <- array(1:24, dim=c(4,3,2))
>
> i <- 2:3
>
> ndim <- length(dim(x))
> if (ndim == 1)
>    y <- x[i]
> else if (ndim == 2)
>    y <- x[i,]
> else if (ndim == 3)
>    y <- x[i,,]
> else ...
>
> and so on.  My current solution is
>
> ndim <- length(dim(x))
> args <- rep(",", ndim)
> args[1] <- "i"
> args <- paste(args, collapse="")
> code <- paste("x[", args, "]", sep="")
> expr <- parse(text=code)
> y <- eval(expr)
>
> ndim <- length(dim(x))
> args <- rep(",", ndim)
> args[1] <- "i"
> args <- paste(args, collapse="")
> code <- paste("x[", args, "]", sep="")
> expr <- parse(text=code)
> y <- eval(expr)
>
> Is there another way I can do this in R that I have overlooked?
>
> /Henrik
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

--
Robin Hankin
Uncertainty Analyst
National Oceanography Centre, Southampton
European Way, Southampton SO14 3ZH, UK
  tel  023-8059-7743


From ggrothendieck at gmail.com  Tue Nov 29 16:17:47 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 29 Nov 2005 10:17:47 -0500
Subject: [Rd] x[1,], x[1,,], x[1,,,], ...
In-Reply-To: <EFF39129-E649-4485-BB79-00EAE5805B46@soc.soton.ac.uk>
References: <4384498B.1080401@maths.lth.se>
	<EFF39129-E649-4485-BB79-00EAE5805B46@soc.soton.ac.uk>
Message-ID: <971536df0511290717k17440617qc98d4413325728ed@mail.gmail.com>

I couldn't find it:

> library(magic)
> apltake
Error: object "apltake" not found

On 11/29/05, Robin Hankin <r.hankin at noc.soton.ac.uk> wrote:
> Hi everyone
>
>
> apltake(x,1)
>
> [where apltake() is part of library(magic)]
>
> does this.
>
> best wishes
>
> Robin
>
>
>
>
> On 23 Nov 2005, at 10:50, Henrik Bengtsson wrote:
>
> > Hi,
> >
> > is there a function in R already doing what I try to do below:
> >
> > # Let 'x' be an array with *any* number of dimensions (>=1).
> > x <- array(1:24, dim=c(2,2,3,2))
> > ...
> > x <- array(1:24, dim=c(4,3,2))
> >
> > i <- 2:3
> >
> > ndim <- length(dim(x))
> > if (ndim == 1)
> >    y <- x[i]
> > else if (ndim == 2)
> >    y <- x[i,]
> > else if (ndim == 3)
> >    y <- x[i,,]
> > else ...
> >
> > and so on.  My current solution is
> >
> > ndim <- length(dim(x))
> > args <- rep(",", ndim)
> > args[1] <- "i"
> > args <- paste(args, collapse="")
> > code <- paste("x[", args, "]", sep="")
> > expr <- parse(text=code)
> > y <- eval(expr)
> >
> > ndim <- length(dim(x))
> > args <- rep(",", ndim)
> > args[1] <- "i"
> > args <- paste(args, collapse="")
> > code <- paste("x[", args, "]", sep="")
> > expr <- parse(text=code)
> > y <- eval(expr)
> >
> > Is there another way I can do this in R that I have overlooked?
> >
> > /Henrik
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
>
> --
> Robin Hankin
> Uncertainty Analyst
> National Oceanography Centre, Southampton
> European Way, Southampton SO14 3ZH, UK
>  tel  023-8059-7743
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From r.hankin at noc.soton.ac.uk  Tue Nov 29 16:36:51 2005
From: r.hankin at noc.soton.ac.uk (Robin Hankin)
Date: Tue, 29 Nov 2005 15:36:51 +0000
Subject: [Rd] x[1,], x[1,,], x[1,,,], ...
In-Reply-To: <971536df0511290717k17440617qc98d4413325728ed@mail.gmail.com>
References: <4384498B.1080401@maths.lth.se>
	<EFF39129-E649-4485-BB79-00EAE5805B46@soc.soton.ac.uk>
	<971536df0511290717k17440617qc98d4413325728ed@mail.gmail.com>
Message-ID: <4AC6BD2E-651A-41F6-873B-092E54B164D9@soc.soton.ac.uk>

Hi everyone

apltake() is part of magic_1.3-20, which I only uploaded to CRAN
this morning.  Perhaps I should have mentioned this!

[
this version of the magic package also includes a whole slew
of functions that operate on arbitrary dimensioned arrays including
adiag(), apad(), arow(), arot(), arev()


enjoy!
]



On 29 Nov 2005, at 15:17, Gabor Grothendieck wrote:

> I couldn't find it:
>
>> library(magic)
>> apltake
> Error: object "apltake" not found
>
> On 11/29/05, Robin Hankin <r.hankin at noc.soton.ac.uk> wrote:
>> Hi everyone
>>
>>
>> apltake(x,1)
>>
>> [where apltake() is part of library(magic)]
>>
>> does this.
>>
>> best wishes
>>
>> Robin
>>
>>
>>
>>
>> On 23 Nov 2005, at 10:50, Henrik Bengtsson wrote:
>>
>>> Hi,
>>>
>>> is there a function in R already doing what I try to do below:
>>>
>>> # Let 'x' be an array with *any* number of dimensions (>=1).
>>> x <- array(1:24, dim=c(2,2,3,2))
>>> ...
>>> x <- array(1:24, dim=c(4,3,2))
>>>
>>> i <- 2:3
>>>
>>> ndim <- length(dim(x))
>>> if (ndim == 1)
>>>    y <- x[i]
>>> else if (ndim == 2)
>>>    y <- x[i,]
>>> else if (ndim == 3)
>>>    y <- x[i,,]
>>> else ...
>>>
>>> and so on.  My current solution is
>>>
>>> ndim <- length(dim(x))
>>> args <- rep(",", ndim)
>>> args[1] <- "i"
>>> args <- paste(args, collapse="")
>>> code <- paste("x[", args, "]", sep="")
>>> expr <- parse(text=code)
>>> y <- eval(expr)
>>>
>>> ndim <- length(dim(x))
>>> args <- rep(",", ndim)
>>> args[1] <- "i"
>>> args <- paste(args, collapse="")
>>> code <- paste("x[", args, "]", sep="")
>>> expr <- parse(text=code)
>>> y <- eval(expr)
>>>
>>> Is there another way I can do this in R that I have overlooked?
>>>
>>> /Henrik
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>> --
>> Robin Hankin
>> Uncertainty Analyst
>> National Oceanography Centre, Southampton
>> European Way, Southampton SO14 3ZH, UK
>>  tel  023-8059-7743
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>

--
Robin Hankin
Uncertainty Analyst
National Oceanography Centre, Southampton
European Way, Southampton SO14 3ZH, UK
  tel  023-8059-7743


From gilles.guillot at inapg.inra.fr  Wed Nov 30 10:51:22 2005
From: gilles.guillot at inapg.inra.fr (Gilles GUILLOT)
Date: Wed, 30 Nov 2005 10:51:22 +0100
Subject: [Rd] R binomial RNG stuck at 1 via Fortran call
Message-ID: <200511301051.22383.gilles.guillot@inapg.inra.fr>

Hi, 

I have some trouble with the result of a fortran function calling the R
binomial RNG:

The C function rbinom is wrapped as in the file attached.

My main fortran program starts as
call rndstart()

and ends as
call rndend()  

I happen to call the binomial RNG within a loop as 

b = ggrbinom(1.d0,0.5d0)
write(*,*) 'b=',b 

In certain cases, after a few iterations in the loop,
b get stuck at 1

Any hint to explain that would help.

Gilles 


-- 
???????????????????????????????????????????????????????????????????
Gilles Guillot 
INRA - MIA Paris 

Currently working from G?teborg Stochastic Centre
Eklandagatan 86 - Rum1439 
Chalmers University of Technology
SE 412-96 G?teborg Sweden 
Phone +46 31 772 3514 / Fax +46 31772 3508

www.inapg.inra.fr/ens_rech/mathinfo/personnel/guillot/welcome.html
???????????????????????????????????????????????????????????????????


From gilles.guillot at inapg.inra.fr  Wed Nov 30 10:58:04 2005
From: gilles.guillot at inapg.inra.fr (Gilles GUILLOT)
Date: Wed, 30 Nov 2005 10:58:04 +0100
Subject: [Rd] R binomial RNG stuck at 1 via Fortran call
Message-ID: <200511301058.04228.gilles.guillot@inapg.inra.fr>

wrapper now attached



-- 
???????????????????????????????????????????????????????????????????
Gilles Guillot 
INRA - MIA Paris 

Currently working from G?teborg Stochastic Centre
Eklandagatan 86 - Rum1439 
Chalmers University of Technology
SE 412-96 G?teborg Sweden 
Phone +46 31 772 3514 / Fax +46 31772 3508

www.inapg.inra.fr/ens_rech/mathinfo/personnel/guillot/welcome.html
???????????????????????????????????????????????????????????????????


From gilles.guillot at inapg.inra.fr  Wed Nov 30 11:00:47 2005
From: gilles.guillot at inapg.inra.fr (Gilles GUILLOT)
Date: Wed, 30 Nov 2005 11:00:47 +0100
Subject: [Rd] R binomial RNG stuck at 1 via Fortran call
Message-ID: <200511301100.47545.gilles.guillot@inapg.inra.fr>

wrapper now as part as the message, 
sorry about previous mail

#include <R.h>
#include <Rmath.h>


void F77_SUB(rndstart)(void) 
{ GetRNGstate(); }

void F77_SUB(rndend)(void) 
{ PutRNGstate(); }

double F77_SUB(ggrnorm)(double *mu, double *sigma) 
{ return rnorm(*mu, *sigma); }

double F77_SUB(ggrexp)(double *scale)
{return rexp(*scale);}

double F77_SUB(ggrgam)(double *a, double *scale)
{return rgamma(*a, *scale);}

double F77_SUB(ggrunif)(double *a, double *b)
{return runif(*a, *b);}

double F77_SUB(ggrbinom)(double *n, double *p)
{return rbinom(*n, *p);}

double F77_SUB(ggrpois)(double *lambda)
{return rpois(*lambda);}


From rob.foxall at bbsrc.ac.uk  Wed Nov 30 12:00:46 2005
From: rob.foxall at bbsrc.ac.uk (rob.foxall@bbsrc.ac.uk)
Date: Wed, 30 Nov 2005 12:00:46 +0100 (CET)
Subject: [Rd] multinom crashes (when I do something stupid) (PR#8358)
Message-ID: <20051130110046.E256215AB4@slim.kubism.ku.dk>

Full_Name: Rob Foxall
Version: 2.2.0
OS: Windows XP
Submission from: (NULL) (149.155.96.5)


I was using multinom from nnet package, when I did something stupid -- I entered
in an incorrect factor variable as response. This factor had only one level.
Instead of R telling me not to be so dumb, it crashed, clicking on debug coming
up with the message "An exception 'Unhandled Win32 Exception' has occurred in
Rgui.exe." This has happened on both my laptop and desktop (it took me a while
to see my mistake!). It can be easily reproduced with made-up data, e.g.

library(nnet)
set.seed(1) # not really needed, but definitely crashes for this!
temp_g <- as.factor(rep("level1",10))
temp_x <- rnorm(10)
multinom(temp_g ~ temp_x)

Cheers,
Rob.


From p.dalgaard at biostat.ku.dk  Wed Nov 30 14:40:01 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 30 Nov 2005 14:40:01 +0100
Subject: [Rd] multinom crashes (when I do something stupid) (PR#8358)
In-Reply-To: <20051130110046.E256215AB4@slim.kubism.ku.dk>
References: <20051130110046.E256215AB4@slim.kubism.ku.dk>
Message-ID: <x2psoixnim.fsf@viggo.kubism.ku.dk>

rob.foxall at bbsrc.ac.uk writes:

> Full_Name: Rob Foxall
> Version: 2.2.0
> OS: Windows XP
> Submission from: (NULL) (149.155.96.5)
> 
> 
> I was using multinom from nnet package, when I did something stupid -- I entered
> in an incorrect factor variable as response. This factor had only one level.
> Instead of R telling me not to be so dumb, it crashed, clicking on debug coming
> up with the message "An exception 'Unhandled Win32 Exception' has occurred in
> Rgui.exe." This has happened on both my laptop and desktop (it took me a while
> to see my mistake!). It can be easily reproduced with made-up data, e.g.
> 
> library(nnet)
> set.seed(1) # not really needed, but definitely crashes for this!
> temp_g <- as.factor(rep("level1",10))
> temp_x <- rnorm(10)
> multinom(temp_g ~ temp_x)

Thanks for the reproducible example, but the general directive is to
send reports on packages directly to the package maintainer. (He'll
see it here, so don't worry about resending.)

The fault comes here:

 # weights:  3 (0 variable)
initial  value 0.000000
final  value 0.000000
converged
*** glibc detected *** free(): invalid next size (fast): 0x000000000172ce20 ***

Program received signal SIGABRT, Aborted.
0x00002aaaab059e79 in raise () from /lib64/tls/libc.so.6
(gdb) bt
#0  0x00002aaaab059e79 in raise () from /lib64/tls/libc.so.6
#1  0x00002aaaab05b48f in abort () from /lib64/tls/libc.so.6
#2  0x00002aaaab08e5d3 in __libc_message () from /lib64/tls/libc.so.6
#3  0x00002aaaab093153 in malloc_printerr () from /lib64/tls/libc.so.6
#4  0x00002aaaab0948a7 in free () from /lib64/tls/libc.so.6
#5  0x00002aaaaacb43ec in R_chk_free () from /usr/lib64/R/lib//libR.so
#6  0x00002aaaabfa3c0d in VR_unset_net ()
   from /usr/lib64/R/library/nnet/libs/nnet.so
#7  0x00002aaaaac5c3ac in do_dotCode () from /usr/lib64/R/lib//libR.so
#8  0x00002aaaaac7e712 in Rf_eval () from /usr/lib64/R/lib//libR.so
....

I.e. it is within internal C code from the nnet package, so the error
most likely belongs to the package, not R at large.

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From gavin.simpson at ucl.ac.uk  Wed Nov 30 15:33:27 2005
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Wed, 30 Nov 2005 14:33:27 +0000
Subject: [Rd] Building a windows binary of a package on Linux
Message-ID: <1133361207.9803.36.camel@gsimpson.geog.ucl.ac.uk>

Dear List,

Can I build a binary package (.zip) for Windows on my Linux machine from
my package sources? There is no C, C++, Fortran code involved, just
plain ol' R. I read through the article by Jun and Rossini, but (on
first reading) this seems more targeted at building a Windows version of
R and Windows package binaries that contain C, C++, Fortran code that
needs to be compiled.

Thanks,

Gav
-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
Gavin Simpson                     [T] +44 (0)20 7679 5522
ENSIS Research Fellow             [F] +44 (0)20 7679 7565
ENSIS Ltd. & ECRC                 [E] gavin.simpsonATNOSPAMucl.ac.uk
UCL Department of Geography       [W] http://www.ucl.ac.uk/~ucfagls/cv/
26 Bedford Way                    [W] http://www.ucl.ac.uk/~ucfagls/
London.  WC1H 0AP.
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%


From gilles.guillot at inapg.inra.fr  Wed Nov 30 16:06:33 2005
From: gilles.guillot at inapg.inra.fr (Gilles GUILLOT)
Date: Wed, 30 Nov 2005 16:06:33 +0100
Subject: [Rd] RNG stuck via Fortran call
Message-ID: <200511301606.34120.gilles.guillot@inapg.inra.fr>

Having not much success with my previous question I try to reformulate it:

I'm simulating a Markow chain in Fortran interfaced with R.
Each loop of my Fortran calls various functions of the R RNG through 
the wrapper given below.

In a run of 100 iterations of the Markov kernel, 
 after 20 iterations, the RNG seems like frozen.

For example, the first call to the RNG in my loop is:

 rpostlamb = ggrgam(dble(m),1.d0)
 write(*,*) 'rpostlamb=',rpostlamb


after the 20th iteration,  it will return the same value 
rpostlamb=  1.24634557

for all the following interations.

Is there any suggestion of explanation for this strange fact ?


Thanks in advance

Gilles 

R Version 2.2.0 compiled under Mandrake 10.1


#include <R.h>
#include <Rmath.h>

/******************/
/* random numbers */
/******************/

void F77_SUB(rndstart)(void) 
{ GetRNGstate(); }

void F77_SUB(rndend)(void) 
{ PutRNGstate(); }

double F77_SUB(ggrnorm)(double *mu, double *sigma) 
{ return rnorm(*mu, *sigma); }

double F77_SUB(ggrexp)(double *scale)
{return rexp(*scale);}

double F77_SUB(ggrgam)(double *a, double *scale)
{return rgamma(*a, *scale);}

double F77_SUB(ggrunif)(double *a, double *b)
{return runif(*a, *b);}

double F77_SUB(ggrbinom)(double *n, double *p)
{return rbinom(*n, *p);}

double F77_SUB(ggrpois)(double *lambda)
{return rpois(*lambda);}


From murdoch at stats.uwo.ca  Wed Nov 30 16:46:57 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Wed, 30 Nov 2005 10:46:57 -0500
Subject: [Rd] Building a windows binary of a package on Linux
In-Reply-To: <1133361207.9803.36.camel@gsimpson.geog.ucl.ac.uk>
References: <1133361207.9803.36.camel@gsimpson.geog.ucl.ac.uk>
Message-ID: <438DC971.1020804@stats.uwo.ca>

On 11/30/2005 9:33 AM, Gavin Simpson wrote:
> Dear List,
> 
> Can I build a binary package (.zip) for Windows on my Linux machine from
> my package sources? There is no C, C++, Fortran code involved, just
> plain ol' R. I read through the article by Jun and Rossini, but (on
> first reading) this seems more targeted at building a Windows version of
> R and Windows package binaries that contain C, C++, Fortran code that
> needs to be compiled.

You should be able to.  Instructions are in the README.packages file in 
R_HOME/src/gnuwin32.  I don't know if you've got that file if you 
installed a pre-built R, but it's in the source tarball (and in 
https://svn.r-project.org/R.  Choose a tag subdirectory for a release 
version, or the trunk for the latest and greatest.  You'll probably get 
the same instructions on all recent ones, they don't change much.

Duncan Murdoch


From murdoch at stats.uwo.ca  Wed Nov 30 16:50:53 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Wed, 30 Nov 2005 10:50:53 -0500
Subject: [Rd] RNG stuck via Fortran call
In-Reply-To: <200511301606.34120.gilles.guillot@inapg.inra.fr>
References: <200511301606.34120.gilles.guillot@inapg.inra.fr>
Message-ID: <438DCA5D.8000500@stats.uwo.ca>

On 11/30/2005 10:06 AM, Gilles GUILLOT wrote:
> Having not much success with my previous question I try to reformulate it:
> 
> I'm simulating a Markow chain in Fortran interfaced with R.
> Each loop of my Fortran calls various functions of the R RNG through 
> the wrapper given below.
> 
> In a run of 100 iterations of the Markov kernel, 
>  after 20 iterations, the RNG seems like frozen.
> 
> For example, the first call to the RNG in my loop is:
> 
>  rpostlamb = ggrgam(dble(m),1.d0)
>  write(*,*) 'rpostlamb=',rpostlamb
> 
> 
> after the 20th iteration,  it will return the same value 
> rpostlamb=  1.24634557
> 
> for all the following interations.
> 
> Is there any suggestion of explanation for this strange fact ?

You need to put together code that someone else could compile and run, 
or show us your real code if it's short enough.  It sounds as though 
you're not handling the RNG state properly.

Please don't send this code to me, post it to the list.  (Actually, in 
putting together a short reproducible example, you're very likely to 
discover the bug yourself, and won't need to post anything.)

Duncan Murdoch
> 
> 
> Thanks in advance
> 
> Gilles 
> 
> R Version 2.2.0 compiled under Mandrake 10.1
> 
> 
> #include <R.h>
> #include <Rmath.h>
> 
> /******************/
> /* random numbers */
> /******************/
> 
> void F77_SUB(rndstart)(void) 
> { GetRNGstate(); }
> 
> void F77_SUB(rndend)(void) 
> { PutRNGstate(); }
> 
> double F77_SUB(ggrnorm)(double *mu, double *sigma) 
> { return rnorm(*mu, *sigma); }
> 
> double F77_SUB(ggrexp)(double *scale)
> {return rexp(*scale);}
> 
> double F77_SUB(ggrgam)(double *a, double *scale)
> {return rgamma(*a, *scale);}
> 
> double F77_SUB(ggrunif)(double *a, double *b)
> {return runif(*a, *b);}
> 
> double F77_SUB(ggrbinom)(double *n, double *p)
> {return rbinom(*n, *p);}
> 
> double F77_SUB(ggrpois)(double *lambda)
> {return rpois(*lambda);}
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From gavin.simpson at ucl.ac.uk  Wed Nov 30 17:02:48 2005
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Wed, 30 Nov 2005 16:02:48 +0000
Subject: [Rd] Building a windows binary of a package on Linux
In-Reply-To: <438DC971.1020804@stats.uwo.ca>
References: <1133361207.9803.36.camel@gsimpson.geog.ucl.ac.uk>
	<438DC971.1020804@stats.uwo.ca>
Message-ID: <1133366568.9803.48.camel@gsimpson.geog.ucl.ac.uk>

On Wed, 2005-11-30 at 10:46 -0500, Duncan Murdoch wrote:
> On 11/30/2005 9:33 AM, Gavin Simpson wrote:
> > Dear List,
> > 
> > Can I build a binary package (.zip) for Windows on my Linux machine from
> > my package sources? There is no C, C++, Fortran code involved, just
> > plain ol' R. I read through the article by Jun and Rossini, but (on
> > first reading) this seems more targeted at building a Windows version of
> > R and Windows package binaries that contain C, C++, Fortran code that
> > needs to be compiled.
> 
> You should be able to.  Instructions are in the README.packages file in 
> R_HOME/src/gnuwin32.  I don't know if you've got that file if you 
> installed a pre-built R, but it's in the source tarball (and in 
> https://svn.r-project.org/R.  Choose a tag subdirectory for a release 
> version, or the trunk for the latest and greatest.  You'll probably get 
> the same instructions on all recent ones, they don't change much.
> 
> Duncan Murdoch

My reading of README.packages would indicate that I need to download the
cross-compile tools as outlined in that README and in the Jun and
Rossini article in R News. I was wondering if it could be done without
all this extra stuff - but it appears not.

Thanks, Duncan for the prompt reply, I'll set aside some time to set
this up as described in the docs.

All the best,

Gav

-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
Gavin Simpson                     [T] +44 (0)20 7679 5522
ENSIS Research Fellow             [F] +44 (0)20 7679 7565
ENSIS Ltd. & ECRC                 [E] gavin.simpsonATNOSPAMucl.ac.uk
UCL Department of Geography       [W] http://www.ucl.ac.uk/~ucfagls/cv/
26 Bedford Way                    [W] http://www.ucl.ac.uk/~ucfagls/
London.  WC1H 0AP.
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%


From murdoch at stats.uwo.ca  Wed Nov 30 17:08:41 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Wed, 30 Nov 2005 11:08:41 -0500
Subject: [Rd] Building a windows binary of a package on Linux
In-Reply-To: <1133366568.9803.48.camel@gsimpson.geog.ucl.ac.uk>
References: <1133361207.9803.36.camel@gsimpson.geog.ucl.ac.uk>	
	<438DC971.1020804@stats.uwo.ca>
	<1133366568.9803.48.camel@gsimpson.geog.ucl.ac.uk>
Message-ID: <438DCE89.3030502@stats.uwo.ca>

On 11/30/2005 11:02 AM, Gavin Simpson wrote:
> On Wed, 2005-11-30 at 10:46 -0500, Duncan Murdoch wrote:
>> On 11/30/2005 9:33 AM, Gavin Simpson wrote:
>> > Dear List,
>> > 
>> > Can I build a binary package (.zip) for Windows on my Linux machine from
>> > my package sources? There is no C, C++, Fortran code involved, just
>> > plain ol' R. I read through the article by Jun and Rossini, but (on
>> > first reading) this seems more targeted at building a Windows version of
>> > R and Windows package binaries that contain C, C++, Fortran code that
>> > needs to be compiled.
>> 
>> You should be able to.  Instructions are in the README.packages file in 
>> R_HOME/src/gnuwin32.  I don't know if you've got that file if you 
>> installed a pre-built R, but it's in the source tarball (and in 
>> https://svn.r-project.org/R.  Choose a tag subdirectory for a release 
>> version, or the trunk for the latest and greatest.  You'll probably get 
>> the same instructions on all recent ones, they don't change much.
>> 
>> Duncan Murdoch
> 
> My reading of README.packages would indicate that I need to download the
> cross-compile tools as outlined in that README and in the Jun and
> Rossini article in R News. I was wondering if it could be done without
> all this extra stuff - but it appears not.
> 
> Thanks, Duncan for the prompt reply, I'll set aside some time to set
> this up as described in the docs.

Why not just try it?  If you don't compile anything, you shouldn't need 
the compilers set up, for example.  You'll definitely need GNU Make and 
zip/unzip and Perl, but you probably already have those.

Duncan Murdoch


From ripley at stats.ox.ac.uk  Wed Nov 30 17:09:11 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 30 Nov 2005 16:09:11 +0000 (GMT)
Subject: [Rd] Building a windows binary of a package on Linux
In-Reply-To: <1133361207.9803.36.camel@gsimpson.geog.ucl.ac.uk>
References: <1133361207.9803.36.camel@gsimpson.geog.ucl.ac.uk>
Message-ID: <Pine.LNX.4.61.0511301600030.7544@gannet.stats>

On Wed, 30 Nov 2005, Gavin Simpson wrote:

> Can I build a binary package (.zip) for Windows on my Linux machine from
> my package sources? There is no C, C++, Fortran code involved, just
> plain ol' R.

A high proportion of the time you can just zip up the installed package on 
Linux.  We don't understand why some people have reported failures, but as 
this is not supported (and so is not tested regularly) we removed it from 
the documentation a while back.  But both Marc Schwartz and I succeeded 
a month or two ago.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From mschwartz at mn.rr.com  Wed Nov 30 17:10:06 2005
From: mschwartz at mn.rr.com (Marc Schwartz (via MN))
Date: Wed, 30 Nov 2005 10:10:06 -0600
Subject: [Rd] Building a windows binary of a package on Linux
In-Reply-To: <1133361207.9803.36.camel@gsimpson.geog.ucl.ac.uk>
References: <1133361207.9803.36.camel@gsimpson.geog.ucl.ac.uk>
Message-ID: <1133367007.11280.4.camel@localhost.localdomain>

On Wed, 2005-11-30 at 14:33 +0000, Gavin Simpson wrote:
> Dear List,
> 
> Can I build a binary package (.zip) for Windows on my Linux machine from
> my package sources? There is no C, C++, Fortran code involved, just
> plain ol' R. I read through the article by Jun and Rossini, but (on
> first reading) this seems more targeted at building a Windows version of
> R and Windows package binaries that contain C, C++, Fortran code that
> needs to be compiled.
> 
> Thanks,
> 
> Gav

Gavin,

If you have the source tarball, there is a file called README.packages
in .../src/gnuwin32 which describes the process. The details begin on
line 124 in that file. That too covers more than just R code based
packages.

If you just have R code only, you could use the following:

  cd R_HOME/library 
  zip -r9X mypkg mypkg

where 'mypkg' is the folder name of the _installed_ Linux version of the
package.

This creates 'mypkg.zip', which can then be installed on the Windows
side.

HTH,

Marc Schwartz


From gavin.simpson at ucl.ac.uk  Wed Nov 30 17:32:25 2005
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Wed, 30 Nov 2005 16:32:25 +0000
Subject: [Rd] Building a windows binary of a package on Linux
In-Reply-To: <438DCE89.3030502@stats.uwo.ca>
References: <1133361207.9803.36.camel@gsimpson.geog.ucl.ac.uk>
	<438DC971.1020804@stats.uwo.ca>
	<1133366568.9803.48.camel@gsimpson.geog.ucl.ac.uk>
	<438DCE89.3030502@stats.uwo.ca>
Message-ID: <1133368345.9803.56.camel@gsimpson.geog.ucl.ac.uk>

On Wed, 2005-11-30 at 11:08 -0500, Duncan Murdoch wrote:
> On 11/30/2005 11:02 AM, Gavin Simpson wrote:
> > On Wed, 2005-11-30 at 10:46 -0500, Duncan Murdoch wrote:
> >> On 11/30/2005 9:33 AM, Gavin Simpson wrote:
> >> > Dear List,
> >> > 
> >> > Can I build a binary package (.zip) for Windows on my Linux machine from
> >> > my package sources? There is no C, C++, Fortran code involved, just
> >> > plain ol' R. I read through the article by Jun and Rossini, but (on
> >> > first reading) this seems more targeted at building a Windows version of
> >> > R and Windows package binaries that contain C, C++, Fortran code that
> >> > needs to be compiled.
> >> 
> >> You should be able to.  Instructions are in the README.packages file in 
> >> R_HOME/src/gnuwin32.  I don't know if you've got that file if you 
> >> installed a pre-built R, but it's in the source tarball (and in 
> >> https://svn.r-project.org/R.  Choose a tag subdirectory for a release 
> >> version, or the trunk for the latest and greatest.  You'll probably get 
> >> the same instructions on all recent ones, they don't change much.
> >> 
> >> Duncan Murdoch
> > 
> > My reading of README.packages would indicate that I need to download the
> > cross-compile tools as outlined in that README and in the Jun and
> > Rossini article in R News. I was wondering if it could be done without
> > all this extra stuff - but it appears not.
> > 
> > Thanks, Duncan for the prompt reply, I'll set aside some time to set
> > this up as described in the docs.
> 
> Why not just try it?  If you don't compile anything, you shouldn't need 
> the compilers set up, for example.  You'll definitely need GNU Make and 
> zip/unzip and Perl, but you probably already have those.
> 
> Duncan Murdoch

Ah, looks like I spoke too soon, as replies from Prof. Ripley and Marc
Schwartz indicate that I can just zip up the installed version of my
package on Linux if I just have R code. The specific reference to
zipping the installed package is the key. I was originally thinking
whether R CMD build etc. on my Linux system could be used to create a
windows binary. Zipping the installed package up is easy and will
suffice until I get time to set-up the other tools.

Thank you Duncan, Prof. Ripley and Marc for your ideas and suggestions.

All the best,

G

-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
Gavin Simpson                     [T] +44 (0)20 7679 5522
ENSIS Research Fellow             [F] +44 (0)20 7679 7565
ENSIS Ltd. & ECRC                 [E] gavin.simpsonATNOSPAMucl.ac.uk
UCL Department of Geography       [W] http://www.ucl.ac.uk/~ucfagls/cv/
26 Bedford Way                    [W] http://www.ucl.ac.uk/~ucfagls/
London.  WC1H 0AP.
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%


From gavin.simpson at ucl.ac.uk  Wed Nov 30 17:41:17 2005
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Wed, 30 Nov 2005 16:41:17 +0000
Subject: [Rd] \dQuote{} in \code{} not processed
Message-ID: <1133368877.9803.63.camel@gsimpson.geog.ucl.ac.uk>

Just wondering if this is the expected behaviour.

I was wanting to produce quoted text within \code{}, without manually
entering the '"'. \dQuote{} seems advisable after reading the Writing R
Extensions manual, so I tried \code{\dQuote{mytext}} expecting it to
produce "mytext" in monospace font (with ' ' round it in the R help
files) but it appears that \dQuote{mytext} is not processed within \code
{} as \dQuote{mytext} is printed literally in the produced
documentation.

Is this intended? I didn't see any statements suggesting \code{} could
not include other markup, and \code{\link{}} works...

You can see an example in the pdf manual for my package on CRAN:

http://www.stats.bris.ac.uk/R/doc/packages/cocorresp.pdf 

in particular the entry for coca().

This is on Fedora Core 3 with:
Version 2.2.0 Patched (2005-11-09 r36252) and
Version 2.3.0 Under development (unstable) (2005-11-30 r36557)

Cheers,

G
-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
Gavin Simpson                     [T] +44 (0)20 7679 5522
ENSIS Research Fellow             [F] +44 (0)20 7679 7565
ENSIS Ltd. & ECRC                 [E] gavin.simpsonATNOSPAMucl.ac.uk
UCL Department of Geography       [W] http://www.ucl.ac.uk/~ucfagls/cv/
26 Bedford Way                    [W] http://www.ucl.ac.uk/~ucfagls/
London.  WC1H 0AP.
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%


From deepayan at stat.wisc.edu  Wed Nov 30 20:19:19 2005
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Wed, 30 Nov 2005 13:19:19 -0600
Subject: [Rd] [ANN] bash completion for R
Message-ID: <200511301319.19282.deepayan@stat.wisc.edu>


[This is of potential interest primarily to bash users and  R package 
developers (hence the posting to r-devel only). Others, feel free to ignore.]

I have been using bash's command completion features [1] for a while now, to 
the point where I expect everything to just work when I hit TAB. Since there 
was no bash completion for R (that I knew of), I took a stab at it myself 
last summer. This was my first major effort in bash programming, so it's far 
from perfect, but it mostly works. In case anyone's interested, the script is 
available at 

http://www.stat.wisc.edu/~deepayan/R/R.bash_completion

which has more details on installation and use.

Any feedback/improvements appreciated.

-Deepayan

[1] http://www.caliban.org/bash/#completion


