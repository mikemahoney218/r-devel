From henrik.bengtsson at gmail.com  Sat Oct  1 22:11:38 2016
From: henrik.bengtsson at gmail.com (Henrik Bengtsson)
Date: Sat, 1 Oct 2016 13:11:38 -0700
Subject: [Rd] socketSelect(..., timeout): non-integer timeouts in (0,
 2) (?) equal infinite timeout on Linux - weird
Message-ID: <CAFDcVCSfd_nx8vKLLn5oNz+JXgyn9TMEFVMxjCd2X=x2UcO+VA@mail.gmail.com>

There's something weird going on for certain non-integer values of
argument 'timeout' to base::socketSelect().  For such values, there is
no timeout and you effectively end up with an infinite timeout.   I
can reproduce this on R 3.3.1 on Ubuntu 16.04 and RedHat 6.6, but not
on Windows (via Linux Wine).

# 1. In R master session
> con <- socketConnection('localhost', port = 11001, server = TRUE, blocking = TRUE, open = 'a+b')

# 2. In R servant session (connect to the above master socket)
> con <- socketConnection('localhost', port = 11001, server = FALSE, blocking = TRUE, open = 'a+b')

# 3. In R master session (check if there's something available on connection)
# Wait at most 0 seconds
> t <- system.time(r <- socketSelect(list(con), write = FALSE, timeout = 0)); print(t); print(r)
   user  system elapsed
      0       0       0
[1] FALSE

# Wait at most 1 seconds
> t <- system.time(r <- socketSelect(list(con), write = FALSE, timeout = 1)); print(t); print(r)
   user  system elapsed
  0.000   0.000   1.002
[1] FALSE

# Wait at most 2 seconds
> t <- system.time(r <- socketSelect(list(con), write = FALSE, timeout = 2)); print(t); print(r)
   user  system elapsed
  0.000   0.000   2.002
[1] FALSE

# Wait at most 2.5 seconds
> t <- system.time(r <- socketSelect(list(con), write = FALSE, timeout = 2.5)); print(t); print(r)
   user  system elapsed
  0.000   0.000   2.502
[1] FALSE

# Wait at most 2.1 seconds
> t <- system.time(r <- socketSelect(list(con), write = FALSE, timeout = 2.1)); print(t); print(r)
   user  system elapsed
  0.000   0.000   2.101
[1] FALSE

However, here are some weird cases where the value of the 'timeout'
argument is ignored:

# Wait at most 1.9 seconds
> t <- system.time(r <- socketSelect(list(con), write = FALSE, timeout = 1.9)); print(t); print(r)
^C   user  system elapsed
  3.780  14.888  20.594

> t <- system.time(r <- socketSelect(list(con), write = FALSE, timeout = 0.1)); print(t); print(r)
^C   user  system elapsed
  2.596  11.208  13.907
[1] FALSE

Note how I had to signal a user interrupt (Ctrl-C) to exit
socketSelect().  Also, not that it still works with the timeout values
chosen above, e.g.

> t <- system.time(r <- socketSelect(list(con), write = FALSE, timeout = 0)); print(t); print(r)
   user  system elapsed
      0       0       0
[1] FALSE
> t <- system.time(r <- socketSelect(list(con), write = FALSE, timeout = 1)); print(t); print(r)
   user  system elapsed
  0.000   0.000   1.001
[1] FALSE

> t <- system.time(r <- socketSelect(list(con), write = FALSE, timeout = 2.1)); print(t); print(r)
   user  system elapsed
  0.000   0.000   2.103
[1] FALSE

It's almost as if there is something special with non-integer values
in (0,2).  Not saying these are the only cases, but that's what I've
observed by trial and error.  Weird.  The fact that it works on
Windows, may suggest it is a Unix specific.  Anyway with macOS that
wanna confirm?

/Henrik

Session information details:

# Ubuntu 16.04
> sessionInfo()
R version 3.3.1 (2016-06-21)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 16.04.1 LTS

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
 [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] tools_3.3.1

# RedHat 6.6:
> sessionInfo()
R version 3.3.1 (2016-06-21)
Platform: x86_64-pc-linux-gnu (64-bit)

locale:
[1] C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] tools_3.3.1

# Windows via Wine on Linux
> sessionInfo()
R version 3.3.1 (2016-06-21)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows XP x64 (build 2600) Service Pack 3

locale:
[1] LC_COLLATE=English_United States.1252 LC_CTYPE=English_United States.1252
[3] LC_MONETARY=C                         LC_NUMERIC=C
[5] LC_TIME=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] tools_3.3.1


From ripley at stats.ox.ac.uk  Sun Oct  2 10:59:11 2016
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 2 Oct 2016 09:59:11 +0100
Subject: [Rd] library() asks user to accept license of some built-in
 packages
In-Reply-To: <1733ce04-9659-157d-fb2b-85fb71cf38f4@helsinki.fi>
References: <1733ce04-9659-157d-fb2b-85fb71cf38f4@helsinki.fi>
Message-ID: <fd997493-5d07-498a-b864-ca1f1bc929e0@stats.ox.ac.uk>

On 27/09/2016 10:49, Mikko Korpela wrote:
> When 'getOption("checkPackageLicense")' is 'TRUE' and the user calls
> 'library(grid)' for the first time, R asks the user to either accept or
> decline the package license. This should not be necessary as the package
> license is "Part of R ..." with "..." denoting the R version number, and
> R is free and open source.
>
> The unnecessary license question is asked for the built-in packages
> "compiler", "grid" and "parallel".
>
> The source file where the checks happen is
> "src/library/base/R/library.R". I think one solution could be to add
> something like
>
> if(identical(pkgInfo$DESCRIPTION[["Priority"]], "base")) return()
>
> to the beginning of checkLicense(), or add more packages to the
> hard-coded exemption list checked before calling checkLicense().

Rather, the analysis code has been told about the current licence for 
standard packages.

> Also, in find.package(), the shortcut list of standard packages is
> missing "compiler".

Which was intentional when the code was written (it is just a shortcut) 
but as 'compiler' is getting used more, it has been added.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford


From kynnjo at gmail.com  Sun Oct  2 19:29:52 2016
From: kynnjo at gmail.com (Kynn Jones)
Date: Sun, 2 Oct 2016 13:29:52 -0400
Subject: [Rd] On implementing zero-overhead code reuse
Message-ID: <CAFvQaj4Bcd-FW_z2Sc019d9JUa_Xy3Xz0HO=Ze16ZLnGJx4JiQ@mail.gmail.com>

I'm looking for a way to approximate the "zero-overhead" model of code
reuse available in languages like Python, Perl, etc.

I've described this idea in more detail, and the motivation for this
question in an earlier post to R-help
(https://stat.ethz.ch/pipermail/r-help/2016-September/442174.html).

(One of the responses I got advised that I post my question here instead.)

The best I have so far is to configure my PROJ_R_LIB environment
variable to point to the directory with my shared code, and put a
function like the following in my .Rprofile file:

    import <- function(name){
        ## usage:
        ## import("foo")
        ## foo$bar()
        path <- file.path(Sys.getenv("PROJ_R_LIB"),paste0(name,".R"))
        if(!file.exists(path)) stop('file "',path,'" does not exist')
        mod <- new.env()
        source(path,local=mod)
        list2env(setNames(list(mod),list(name)),envir=parent.frame())
        invisible()
    }

(NB: the idea above is an elaboration of the one I showed in my first post.)

But this is very much of an R noob's solution.  I figure there may
already be more solid ways to achieve "zero-overhead" code reuse.

I would appreciate any suggestions/critiques/pointers/comments.

TIA!

kj


From juanpide at gmail.com  Sun Oct  2 18:54:04 2016
From: juanpide at gmail.com (Pi)
Date: Sun, 2 Oct 2016 18:54:04 +0200
Subject: [Rd] grep
Message-ID: <CAEQWovS-Ymxz6RJ92_7eRBkxqdJ3CxQdL1DNJEpjQkRpTmcXsA@mail.gmail.com>

Hello.

It would be great if the grep function in R had the option to use the -m
parameter as the linux command does.
That would allow to stop a grep search as soon as something is found.
It would make many operations much faster.

	[[alternative HTML version deleted]]


From frederik at ofb.net  Mon Oct  3 01:09:56 2016
From: frederik at ofb.net (frederik at ofb.net)
Date: Sun, 2 Oct 2016 16:09:56 -0700
Subject: [Rd] On implementing zero-overhead code reuse
In-Reply-To: <CAFvQaj4Bcd-FW_z2Sc019d9JUa_Xy3Xz0HO=Ze16ZLnGJx4JiQ@mail.gmail.com>
References: <CAFvQaj4Bcd-FW_z2Sc019d9JUa_Xy3Xz0HO=Ze16ZLnGJx4JiQ@mail.gmail.com>
Message-ID: <20161002230956.GT9995@ofb.net>

Hi Kynn,

Do you mind defining the term "zero-overhead model of code reuse"?

I think I understand what you're getting at, but not sure.

Thank you,

Frederick

On Sun, Oct 02, 2016 at 01:29:52PM -0400, Kynn Jones wrote:
> I'm looking for a way to approximate the "zero-overhead" model of code
> reuse available in languages like Python, Perl, etc.
> 
> I've described this idea in more detail, and the motivation for this
> question in an earlier post to R-help
> (https://stat.ethz.ch/pipermail/r-help/2016-September/442174.html).
> 
> (One of the responses I got advised that I post my question here instead.)
> 
> The best I have so far is to configure my PROJ_R_LIB environment
> variable to point to the directory with my shared code, and put a
> function like the following in my .Rprofile file:
> 
>     import <- function(name){
>         ## usage:
>         ## import("foo")
>         ## foo$bar()
>         path <- file.path(Sys.getenv("PROJ_R_LIB"),paste0(name,".R"))
>         if(!file.exists(path)) stop('file "',path,'" does not exist')
>         mod <- new.env()
>         source(path,local=mod)
>         list2env(setNames(list(mod),list(name)),envir=parent.frame())
>         invisible()
>     }
> 
> (NB: the idea above is an elaboration of the one I showed in my first post.)
> 
> But this is very much of an R noob's solution.  I figure there may
> already be more solid ways to achieve "zero-overhead" code reuse.
> 
> I would appreciate any suggestions/critiques/pointers/comments.
> 
> TIA!
> 
> kj
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From kynnjo at gmail.com  Mon Oct  3 02:01:58 2016
From: kynnjo at gmail.com (Kynn Jones)
Date: Sun, 2 Oct 2016 20:01:58 -0400
Subject: [Rd] On implementing zero-overhead code reuse
In-Reply-To: <20161002230956.GT9995@ofb.net>
References: <CAFvQaj4Bcd-FW_z2Sc019d9JUa_Xy3Xz0HO=Ze16ZLnGJx4JiQ@mail.gmail.com>
	<20161002230956.GT9995@ofb.net>
Message-ID: <CAFvQaj4SLxim=Jqi_yeOrKTRvuhWB7X-C6xXjpCw_pbmfz_=3Q@mail.gmail.com>

Hi Frederick,

I described what I meant in the post I sent to R-help
(https://stat.ethz.ch/pipermail/r-help/2016-September/442174.html),
but in brief, by "zero overhead" I mean that the only thing needed for
library code to be accessible to client code is for it to be located
in designed directory.  No additional meta-files, packaging/compiling,
etc. are required.

Best,

G.

On Sun, Oct 2, 2016 at 7:09 PM,  <frederik at ofb.net> wrote:
> Hi Kynn,
>
> Do you mind defining the term "zero-overhead model of code reuse"?
>
> I think I understand what you're getting at, but not sure.
>
> Thank you,
>
> Frederick
>
> On Sun, Oct 02, 2016 at 01:29:52PM -0400, Kynn Jones wrote:
>> I'm looking for a way to approximate the "zero-overhead" model of code
>> reuse available in languages like Python, Perl, etc.
>>
>> I've described this idea in more detail, and the motivation for this
>> question in an earlier post to R-help
>> (https://stat.ethz.ch/pipermail/r-help/2016-September/442174.html).
>>
>> (One of the responses I got advised that I post my question here instead.)
>>
>> The best I have so far is to configure my PROJ_R_LIB environment
>> variable to point to the directory with my shared code, and put a
>> function like the following in my .Rprofile file:
>>
>>     import <- function(name){
>>         ## usage:
>>         ## import("foo")
>>         ## foo$bar()
>>         path <- file.path(Sys.getenv("PROJ_R_LIB"),paste0(name,".R"))
>>         if(!file.exists(path)) stop('file "',path,'" does not exist')
>>         mod <- new.env()
>>         source(path,local=mod)
>>         list2env(setNames(list(mod),list(name)),envir=parent.frame())
>>         invisible()
>>     }
>>
>> (NB: the idea above is an elaboration of the one I showed in my first post.)
>>
>> But this is very much of an R noob's solution.  I figure there may
>> already be more solid ways to achieve "zero-overhead" code reuse.
>>
>> I would appreciate any suggestions/critiques/pointers/comments.
>>
>> TIA!
>>
>> kj
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>


From kynnjo at gmail.com  Mon Oct  3 02:05:53 2016
From: kynnjo at gmail.com (Kynn Jones)
Date: Sun, 2 Oct 2016 20:05:53 -0400
Subject: [Rd] On implementing zero-overhead code reuse
In-Reply-To: <CAFvQaj4SLxim=Jqi_yeOrKTRvuhWB7X-C6xXjpCw_pbmfz_=3Q@mail.gmail.com>
References: <CAFvQaj4Bcd-FW_z2Sc019d9JUa_Xy3Xz0HO=Ze16ZLnGJx4JiQ@mail.gmail.com>
	<20161002230956.GT9995@ofb.net>
	<CAFvQaj4SLxim=Jqi_yeOrKTRvuhWB7X-C6xXjpCw_pbmfz_=3Q@mail.gmail.com>
Message-ID: <CAFvQaj6=UUWafXD5asf-mtho7O1qKs9TLpWmLRdmEhGYh1exVw@mail.gmail.com>

On Sun, Oct 2, 2016 at 8:01 PM, Kynn Jones <kynnjo at gmail.com> wrote:
> Hi Frederick,
>
> I described what I meant in the post I sent to R-help
> (https://stat.ethz.ch/pipermail/r-help/2016-September/442174.html),
> but in brief, by "zero overhead" I mean that the only thing needed for
> library code to be accessible to client code is for it to be located
> in designed directory.  No additional meta-files, packaging/compiling,
     ^^^^^^^^

Sorry, I meant to write "designated".

> etc. are required.


From edd at debian.org  Mon Oct  3 02:18:41 2016
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sun, 2 Oct 2016 19:18:41 -0500
Subject: [Rd] On implementing zero-overhead code reuse
In-Reply-To: <CAFvQaj6=UUWafXD5asf-mtho7O1qKs9TLpWmLRdmEhGYh1exVw@mail.gmail.com>
References: <CAFvQaj4Bcd-FW_z2Sc019d9JUa_Xy3Xz0HO=Ze16ZLnGJx4JiQ@mail.gmail.com>
	<20161002230956.GT9995@ofb.net>
	<CAFvQaj4SLxim=Jqi_yeOrKTRvuhWB7X-C6xXjpCw_pbmfz_=3Q@mail.gmail.com>
	<CAFvQaj6=UUWafXD5asf-mtho7O1qKs9TLpWmLRdmEhGYh1exVw@mail.gmail.com>
Message-ID: <22513.41953.204280.605359@max.nulle.part>


Kynn,

How much homework have you done researching any other "alternatives" to the
package system?  I know of at least one...

In short, just about everybody here believes in packages. And repositories.
And package management.  And version control (at the package level). And
maybe byte compilation.  And associated documentation.  And unit tests.  And
continuous integration.

You don't have to -- that's cool.  Different strokes for different folks.

But if think you need something different you may just have to build that
yourself.

Cheers, Dirk

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From mikko.korpela at helsinki.fi  Mon Oct  3 08:39:29 2016
From: mikko.korpela at helsinki.fi (Mikko Korpela)
Date: Mon, 3 Oct 2016 09:39:29 +0300
Subject: [Rd] library() asks user to accept license of some built-in
	packages
In-Reply-To: <fd997493-5d07-498a-b864-ca1f1bc929e0@stats.ox.ac.uk>
References: <1733ce04-9659-157d-fb2b-85fb71cf38f4@helsinki.fi>
	<fd997493-5d07-498a-b864-ca1f1bc929e0@stats.ox.ac.uk>
Message-ID: <26213992-17b2-f75c-09e0-aa5dbba2ce9b@helsinki.fi>

On 02/10/16 11:59, Prof Brian Ripley wrote:
> On 27/09/2016 10:49, Mikko Korpela wrote:
>> When 'getOption("checkPackageLicense")' is 'TRUE' and the user calls
>> 'library(grid)' for the first time, R asks the user to either accept or
>> decline the package license. This should not be necessary as the package
>> license is "Part of R ..." with "..." denoting the R version number, and
>> R is free and open source.
>>
>> The unnecessary license question is asked for the built-in packages
>> "compiler", "grid" and "parallel".
>>
>> The source file where the checks happen is
>> "src/library/base/R/library.R". I think one solution could be to add
>> something like
>>
>> if(identical(pkgInfo$DESCRIPTION[["Priority"]], "base")) return()
>>
>> to the beginning of checkLicense(), or add more packages to the
>> hard-coded exemption list checked before calling checkLicense().
>
> Rather, the analysis code has been told about the current licence for
> standard packages.

Great, thank you.

>> Also, in find.package(), the shortcut list of standard packages is
>> missing "compiler".
>
> Which was intentional when the code was written (it is just a shortcut)
> but as 'compiler' is getting used more, it has been added.

Makes perfect sense.

-- 
Mikko Korpela
Department of Geosciences and Geography
University of Helsinki


From frederik at ofb.net  Mon Oct  3 16:18:59 2016
From: frederik at ofb.net (frederik at ofb.net)
Date: Mon, 3 Oct 2016 07:18:59 -0700
Subject: [Rd] On implementing zero-overhead code reuse
In-Reply-To: <22513.41953.204280.605359@max.nulle.part>
	<CAFvQaj6=UUWafXD5asf-mtho7O1qKs9TLpWmLRdmEhGYh1exVw@mail.gmail.com>
	<CAFvQaj4SLxim=Jqi_yeOrKTRvuhWB7X-C6xXjpCw_pbmfz_=3Q@mail.gmail.com>
Message-ID: <20161003141859.GV9995@ofb.net>

Hi Kynn,

Thanks for expanding.

I wrote a function like yours when I first started using R. It's
basically the same up to your "new.env()" line, I don't do anything
with environmentns. I just called my function "mysource" and it's
essentially a "source with path". That allows me to find code I reuse
in standard locations.

I don't know why R does not have built-in support for such a thing.
You can get it in C compilers with CPATH, and as you say in Perl with
PERL5LIB, in Python, etc. Obviously when I use my "mysource" I have to
remember that my code is now not portable without copying over some
files from other locations in my home directory. However, as a
beginner I find this tool to be indispensable, as R lacks several
functions which I use regularly, and I'm not necessarily ready to
confront the challenges associated with creating a package.

However, I guess since we can get your functionality pretty easily
using some lines in .Rprofile, that makes it seem less important to
have it built-in. In fact, if everyone has to implement their own
version of your "import", this almost guarantees that the function
won't appear by accident in any public code. My choice of name
"mysource" was meant to serve as a more visible lexical reminder that
the function is not meant to be seen by the public.

By the way, why do you do the stuff with environments in your "import"
function?

Dirk's take is interesting. I don't use version control for my
personal projects, just backing-up. Obviously not all R users are
interested in becoming package maintainers, in fact I think it would
clutter things a bit if this were the case. Or maybe it would be good
to have everyone publish their personal utility functions, who knows?
Anyway I appreciate Dirk's arguments, but I'm also a bit surprised
that Kynn and I seem to be the only ones who have written personal
functions to do what Kynn calls "zero-overhead code reuse". FWIW.

Cheers,

Frederick

On Sun, Oct 02, 2016 at 08:01:58PM -0400, Kynn Jones wrote:
> Hi Frederick,
> 
> I described what I meant in the post I sent to R-help
> (https://stat.ethz.ch/pipermail/r-help/2016-September/442174.html),
> but in brief, by "zero overhead" I mean that the only thing needed for
> library code to be accessible to client code is for it to be located
> in a designated directory.  No additional meta-files, packaging/compiling,
> etc. are required.
> 
> Best,
> 
> G.
> 
> On Sun, Oct 2, 2016 at 7:09 PM,  <frederik at ofb.net> wrote:
> > Hi Kynn,
> >
> > Do you mind defining the term "zero-overhead model of code reuse"?
> >
> > I think I understand what you're getting at, but not sure.
> >
> > Thank you,
> >
> > Frederick
> >
> > On Sun, Oct 02, 2016 at 01:29:52PM -0400, Kynn Jones wrote:
> >> I'm looking for a way to approximate the "zero-overhead" model of code
> >> reuse available in languages like Python, Perl, etc.
> >>
> >> I've described this idea in more detail, and the motivation for this
> >> question in an earlier post to R-help
> >> (https://stat.ethz.ch/pipermail/r-help/2016-September/442174.html).
> >>
> >> (One of the responses I got advised that I post my question here instead.)
> >>
> >> The best I have so far is to configure my PROJ_R_LIB environment
> >> variable to point to the directory with my shared code, and put a
> >> function like the following in my .Rprofile file:
> >>
> >>     import <- function(name){
> >>         ## usage:
> >>         ## import("foo")
> >>         ## foo$bar()
> >>         path <- file.path(Sys.getenv("PROJ_R_LIB"),paste0(name,".R"))
> >>         if(!file.exists(path)) stop('file "',path,'" does not exist')
> >>         mod <- new.env()
> >>         source(path,local=mod)
> >>         list2env(setNames(list(mod),list(name)),envir=parent.frame())
> >>         invisible()
> >>     }
> >>
> >> (NB: the idea above is an elaboration of the one I showed in my first post.)
> >>
> >> But this is very much of an R noob's solution.  I figure there may
> >> already be more solid ways to achieve "zero-overhead" code reuse.
> >>
> >> I would appreciate any suggestions/critiques/pointers/comments.
> >>
> >> TIA!
> >>
> >> kj
> >>
> >> ______________________________________________
> >> R-devel at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-devel
> >>
> 

On Sun, Oct 02, 2016 at 08:05:53PM -0400, Kynn Jones wrote:
> On Sun, Oct 2, 2016 at 8:01 PM, Kynn Jones <kynnjo at gmail.com> wrote:
> > Hi Frederick,
> >
> > I described what I meant in the post I sent to R-help
> > (https://stat.ethz.ch/pipermail/r-help/2016-September/442174.html),
> > but in brief, by "zero overhead" I mean that the only thing needed for
> > library code to be accessible to client code is for it to be located
> > in designed directory.  No additional meta-files, packaging/compiling,
>      ^^^^^^^^
> 
> Sorry, I meant to write "designated".
> 
> > etc. are required.
> 

On Sun, Oct 02, 2016 at 07:18:41PM -0500, Dirk Eddelbuettel wrote:
> 
> Kynn,
> 
> How much homework have you done researching any other "alternatives" to the
> package system?  I know of at least one...
> 
> In short, just about everybody here believes in packages. And repositories.
> And package management.  And version control (at the package level). And
> maybe byte compilation.  And associated documentation.  And unit tests.  And
> continuous integration.
> 
> You don't have to -- that's cool.  Different strokes for different folks.
> 
> But if think you need something different you may just have to build that
> yourself.
> 
> Cheers, Dirk
> 
> -- 
> http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org
>


From ggrothendieck at gmail.com  Mon Oct  3 17:56:37 2016
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 3 Oct 2016 11:56:37 -0400
Subject: [Rd] On implementing zero-overhead code reuse
In-Reply-To: <CAFvQaj4Bcd-FW_z2Sc019d9JUa_Xy3Xz0HO=Ze16ZLnGJx4JiQ@mail.gmail.com>
References: <CAFvQaj4Bcd-FW_z2Sc019d9JUa_Xy3Xz0HO=Ze16ZLnGJx4JiQ@mail.gmail.com>
Message-ID: <CAP01uRnTUvLxEAXaCk-2-WofF=+bS=1Udw2+Gh_ph3ckB40EhA@mail.gmail.com>

Have a look at the CRAN modules package and the import package.

On Sun, Oct 2, 2016 at 1:29 PM, Kynn Jones <kynnjo at gmail.com> wrote:
> I'm looking for a way to approximate the "zero-overhead" model of code
> reuse available in languages like Python, Perl, etc.
>
> I've described this idea in more detail, and the motivation for this
> question in an earlier post to R-help
> (https://stat.ethz.ch/pipermail/r-help/2016-September/442174.html).
>
> (One of the responses I got advised that I post my question here instead.)
>
> The best I have so far is to configure my PROJ_R_LIB environment
> variable to point to the directory with my shared code, and put a
> function like the following in my .Rprofile file:
>
>     import <- function(name){
>         ## usage:
>         ## import("foo")
>         ## foo$bar()
>         path <- file.path(Sys.getenv("PROJ_R_LIB"),paste0(name,".R"))
>         if(!file.exists(path)) stop('file "',path,'" does not exist')
>         mod <- new.env()
>         source(path,local=mod)
>         list2env(setNames(list(mod),list(name)),envir=parent.frame())
>         invisible()
>     }
>
> (NB: the idea above is an elaboration of the one I showed in my first post.)
>
> But this is very much of an R noob's solution.  I figure there may
> already be more solid ways to achieve "zero-overhead" code reuse.
>
> I would appreciate any suggestions/critiques/pointers/comments.
>
> TIA!
>
> kj
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel



-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From kasperdanielhansen at gmail.com  Mon Oct  3 18:06:04 2016
From: kasperdanielhansen at gmail.com (Kasper Daniel Hansen)
Date: Mon, 3 Oct 2016 12:06:04 -0400
Subject: [Rd] On implementing zero-overhead code reuse
In-Reply-To: <20161003141859.GV9995@ofb.net>
References: <22513.41953.204280.605359@max.nulle.part>
	<CAFvQaj6=UUWafXD5asf-mtho7O1qKs9TLpWmLRdmEhGYh1exVw@mail.gmail.com>
	<CAFvQaj4SLxim=Jqi_yeOrKTRvuhWB7X-C6xXjpCw_pbmfz_=3Q@mail.gmail.com>
	<20161003141859.GV9995@ofb.net>
Message-ID: <CAC2h7usFJCN1R+Fw_8oaBb37dJdQO5FRLiSgh8tZ_V30nGBmNg@mail.gmail.com>

On Mon, Oct 3, 2016 at 10:18 AM, <frederik at ofb.net> wrote:

> Hi Kynn,
>
> Thanks for expanding.
>
> I wrote a function like yours when I first started using R. It's
> basically the same up to your "new.env()" line, I don't do anything
> with environmentns. I just called my function "mysource" and it's
> essentially a "source with path". That allows me to find code I reuse
> in standard locations.
>
> I don't know why R does not have built-in support for such a thing.
> You can get it in C compilers with CPATH, and as you say in Perl with
> PERL5LIB, in Python, etc. Obviously when I use my "mysource" I have to
> remember that my code is now not portable without copying over some
> files from other locations in my home directory. However, as a
> beginner I find this tool to be indispensable, as R lacks several
> functions which I use regularly, and I'm not necessarily ready to
> confront the challenges associated with creating a package.
>

I can pretty much guarantee that when you finally confront the "challenge"
of making your own package you'll realize (1) it is pretty easy if the
intention is only to use it yourself (and perhaps a couple of
collaborators) - by easy I mean I can make a package in 5m max. (2) you'll
ask yourself "why didn't I do this earlier?".  I still get that feeling
now, when I have done it many times for internal use.  Almost every time I
think I should have made an internal package earlier in the process.

Of course, all of this is hard to see when you're standing in the middle of
your work.

Best,
Kasper






> However, I guess since we can get your functionality pretty easily
> using some lines in .Rprofile, that makes it seem less important to
> have it built-in. In fact, if everyone has to implement their own
> version of your "import", this almost guarantees that the function
> won't appear by accident in any public code. My choice of name
> "mysource" was meant to serve as a more visible lexical reminder that
> the function is not meant to be seen by the public.
>
> By the way, why do you do the stuff with environments in your "import"
> function?
>
> Dirk's take is interesting. I don't use version control for my
> personal projects, just backing-up. Obviously not all R users are
> interested in becoming package maintainers, in fact I think it would
> clutter things a bit if this were the case. Or maybe it would be good
> to have everyone publish their personal utility functions, who knows?
> Anyway I appreciate Dirk's arguments, but I'm also a bit surprised
> that Kynn and I seem to be the only ones who have written personal
> functions to do what Kynn calls "zero-overhead code reuse". FWIW.
>
> Cheers,
>
> Frederick
>
> On Sun, Oct 02, 2016 at 08:01:58PM -0400, Kynn Jones wrote:
> > Hi Frederick,
> >
> > I described what I meant in the post I sent to R-help
> > (https://stat.ethz.ch/pipermail/r-help/2016-September/442174.html),
> > but in brief, by "zero overhead" I mean that the only thing needed for
> > library code to be accessible to client code is for it to be located
> > in a designated directory.  No additional meta-files,
> packaging/compiling,
> > etc. are required.
> >
> > Best,
> >
> > G.
> >
> > On Sun, Oct 2, 2016 at 7:09 PM,  <frederik at ofb.net> wrote:
> > > Hi Kynn,
> > >
> > > Do you mind defining the term "zero-overhead model of code reuse"?
> > >
> > > I think I understand what you're getting at, but not sure.
> > >
> > > Thank you,
> > >
> > > Frederick
> > >
> > > On Sun, Oct 02, 2016 at 01:29:52PM -0400, Kynn Jones wrote:
> > >> I'm looking for a way to approximate the "zero-overhead" model of code
> > >> reuse available in languages like Python, Perl, etc.
> > >>
> > >> I've described this idea in more detail, and the motivation for this
> > >> question in an earlier post to R-help
> > >> (https://stat.ethz.ch/pipermail/r-help/2016-September/442174.html).
> > >>
> > >> (One of the responses I got advised that I post my question here
> instead.)
> > >>
> > >> The best I have so far is to configure my PROJ_R_LIB environment
> > >> variable to point to the directory with my shared code, and put a
> > >> function like the following in my .Rprofile file:
> > >>
> > >>     import <- function(name){
> > >>         ## usage:
> > >>         ## import("foo")
> > >>         ## foo$bar()
> > >>         path <- file.path(Sys.getenv("PROJ_R_LIB"),paste0(name,".R"))
> > >>         if(!file.exists(path)) stop('file "',path,'" does not exist')
> > >>         mod <- new.env()
> > >>         source(path,local=mod)
> > >>         list2env(setNames(list(mod),list(name)),envir=parent.frame())
> > >>         invisible()
> > >>     }
> > >>
> > >> (NB: the idea above is an elaboration of the one I showed in my first
> post.)
> > >>
> > >> But this is very much of an R noob's solution.  I figure there may
> > >> already be more solid ways to achieve "zero-overhead" code reuse.
> > >>
> > >> I would appreciate any suggestions/critiques/pointers/comments.
> > >>
> > >> TIA!
> > >>
> > >> kj
> > >>
> > >> ______________________________________________
> > >> R-devel at r-project.org mailing list
> > >> https://stat.ethz.ch/mailman/listinfo/r-devel
> > >>
> >
>
> On Sun, Oct 02, 2016 at 08:05:53PM -0400, Kynn Jones wrote:
> > On Sun, Oct 2, 2016 at 8:01 PM, Kynn Jones <kynnjo at gmail.com> wrote:
> > > Hi Frederick,
> > >
> > > I described what I meant in the post I sent to R-help
> > > (https://stat.ethz.ch/pipermail/r-help/2016-September/442174.html),
> > > but in brief, by "zero overhead" I mean that the only thing needed for
> > > library code to be accessible to client code is for it to be located
> > > in designed directory.  No additional meta-files, packaging/compiling,
> >      ^^^^^^^^
> >
> > Sorry, I meant to write "designated".
> >
> > > etc. are required.
> >
>
> On Sun, Oct 02, 2016 at 07:18:41PM -0500, Dirk Eddelbuettel wrote:
> >
> > Kynn,
> >
> > How much homework have you done researching any other "alternatives" to
> the
> > package system?  I know of at least one...
> >
> > In short, just about everybody here believes in packages. And
> repositories.
> > And package management.  And version control (at the package level). And
> > maybe byte compilation.  And associated documentation.  And unit tests.
> And
> > continuous integration.
> >
> > You don't have to -- that's cool.  Different strokes for different folks.
> >
> > But if think you need something different you may just have to build that
> > yourself.
> >
> > Cheers, Dirk
> >
> > --
> > http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org
> >
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From ripley at stats.ox.ac.uk  Mon Oct  3 18:17:48 2016
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 3 Oct 2016 17:17:48 +0100
Subject: [Rd] grep
In-Reply-To: <CAEQWovS-Ymxz6RJ92_7eRBkxqdJ3CxQdL1DNJEpjQkRpTmcXsA@mail.gmail.com>
References: <CAEQWovS-Ymxz6RJ92_7eRBkxqdJ3CxQdL1DNJEpjQkRpTmcXsA@mail.gmail.com>
Message-ID: <00e4fcd9-b720-de32-0978-5ed2b8f142dd@stats.ox.ac.uk>

On 02/10/2016 17:54, Pi wrote:
> Hello.
>
> It would be great if the grep function in R had the option to use the -m
> parameter as the linux command does.

I guess you mean the non-standard flag of the GNU version of grep 
(probably but not necessarily as used by Linux).

That the POSIX standard for grep does not have this (nor any other 
commonly used implementation I am aware of) indicates that your 
enthusiasm for this is not shared by grep experts.

> That would allow to stop a grep search as soon as something is found.
> It would make many operations much faster.

Those who would have to do the work to implement this will not be taking 
your word for that, but would expect convincing examples of real 
problems where it was so and grep was the bottleneck.

Your 'case' seems to be for a shortcut for any(grepl()) along the lines 
of anyDuplicated().

> 	[[alternative HTML version deleted]]

This is a non-HTML list, as the posting guide told you.  And using a 
real name adds credibility.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford


From kynnjo at gmail.com  Mon Oct  3 19:51:32 2016
From: kynnjo at gmail.com (Kynn Jones)
Date: Mon, 3 Oct 2016 13:51:32 -0400
Subject: [Rd] On implementing zero-overhead code reuse
In-Reply-To: <CAC2h7usFJCN1R+Fw_8oaBb37dJdQO5FRLiSgh8tZ_V30nGBmNg@mail.gmail.com>
References: <22513.41953.204280.605359@max.nulle.part>
	<CAFvQaj6=UUWafXD5asf-mtho7O1qKs9TLpWmLRdmEhGYh1exVw@mail.gmail.com>
	<CAFvQaj4SLxim=Jqi_yeOrKTRvuhWB7X-C6xXjpCw_pbmfz_=3Q@mail.gmail.com>
	<20161003141859.GV9995@ofb.net>
	<CAC2h7usFJCN1R+Fw_8oaBb37dJdQO5FRLiSgh8tZ_V30nGBmNg@mail.gmail.com>
Message-ID: <CAFvQaj69J8SuA3uirTa_jpY6JjUZb0DsPiFe5eru=ZbZTS_uLg@mail.gmail.com>

Thank you all for your comments and suggestions.

@Frederik, my reason for mucking with environments is that I want to
minimize the number of names that import adds to my current
environment.  For instance, if module foo defines a function bar, I
want my client code to look like this:

  import("foo")
  foo$bar(1,2,3)

rather than

  import("foo")
  bar(1,2,3)

(Just a personal preference.)

@Dirk, @Kasper, as I see it, the benefit of scripting languages like
Python, Perl, etc., is that they allow very quick development, with
minimal up-front cost.  Their main strength is precisely that one can,
without much difficulty, *immediately* start *programming
productively*, without having to worry at all about (to quote Dirk)
"repositories.  And package management.  And version control (at the
package level).  And ... byte compilation.  And associated
documentation.  And unit tests.  And continuous integration."

Of course, *eventually*, and for a fraction of one's total code base
(in my case, a *very small* fraction), one will want to worry about
all those things, but I see no point in burdening *all* my code with
all those concerns from the start.  Again, please keep in mind that
those concerns come into play for at most 5% of the code I write.

Also, I'd like to point out that the Python, Perl, etc. communities
are no less committed to all the concerns that Dirk listed (version
control, package management, documentation, testing, etc.) than the R
community is.  And yet, Python, Perl, etc. support the "zero-overhead"
model of code reuse.  There's no contradiction here.  Support for
"zero-overhead" code reuse does not preclude forms of code reuse with
more overhead.

One benefit the zero-overhead model is that the concerns of
documentation, testing, etc. can be addressed with varying degrees of
thoroughness, depending on the situation's demands.  (For example,
documentation that would be perfectly adequate for me as the author of
a function would not be adequate for the general user.)

This means that the transition from writing private code to writing
code that can be shared with the world can be made much more
gradually, according to the programmer's needs and means.

Currently, in the R world, the choice for programmers is much starker:
either stay writing little scripts that one sources from an
interactive session, or learn to implement packages.  There's too
little in-between.

Of course, from the point of view of someone who has already written
several packages, the barrier to writing a package may seem too small
to fret over, but adopting the expert's perspective is likely to
result in excluding the non-experts.

Best, kj


On Mon, Oct 3, 2016 at 12:06 PM, Kasper Daniel Hansen
<kasperdanielhansen at gmail.com> wrote:
>
>
> On Mon, Oct 3, 2016 at 10:18 AM, <frederik at ofb.net> wrote:
>>
>> Hi Kynn,
>>
>> Thanks for expanding.
>>
>> I wrote a function like yours when I first started using R. It's
>> basically the same up to your "new.env()" line, I don't do anything
>> with environmentns. I just called my function "mysource" and it's
>> essentially a "source with path". That allows me to find code I reuse
>> in standard locations.
>>
>> I don't know why R does not have built-in support for such a thing.
>> You can get it in C compilers with CPATH, and as you say in Perl with
>> PERL5LIB, in Python, etc. Obviously when I use my "mysource" I have to
>> remember that my code is now not portable without copying over some
>> files from other locations in my home directory. However, as a
>> beginner I find this tool to be indispensable, as R lacks several
>> functions which I use regularly, and I'm not necessarily ready to
>> confront the challenges associated with creating a package.
>
>
> I can pretty much guarantee that when you finally confront the "challenge"
> of making your own package you'll realize (1) it is pretty easy if the
> intention is only to use it yourself (and perhaps a couple of collaborators)
> - by easy I mean I can make a package in 5m max. (2) you'll ask yourself
> "why didn't I do this earlier?".  I still get that feeling now, when I have
> done it many times for internal use.  Almost every time I think I should
> have made an internal package earlier in the process.
>
> Of course, all of this is hard to see when you're standing in the middle of
> your work.
>
> Best,
> Kasper
>
>
>
>
>
>>
>> However, I guess since we can get your functionality pretty easily
>> using some lines in .Rprofile, that makes it seem less important to
>> have it built-in. In fact, if everyone has to implement their own
>> version of your "import", this almost guarantees that the function
>> won't appear by accident in any public code. My choice of name
>> "mysource" was meant to serve as a more visible lexical reminder that
>> the function is not meant to be seen by the public.
>>
>> By the way, why do you do the stuff with environments in your "import"
>> function?
>>
>> Dirk's take is interesting. I don't use version control for my
>> personal projects, just backing-up. Obviously not all R users are
>> interested in becoming package maintainers, in fact I think it would
>> clutter things a bit if this were the case. Or maybe it would be good
>> to have everyone publish their personal utility functions, who knows?
>> Anyway I appreciate Dirk's arguments, but I'm also a bit surprised
>> that Kynn and I seem to be the only ones who have written personal
>> functions to do what Kynn calls "zero-overhead code reuse". FWIW.
>>
>> Cheers,
>>
>> Frederick
>>
>> On Sun, Oct 02, 2016 at 08:01:58PM -0400, Kynn Jones wrote:
>> > Hi Frederick,
>> >
>> > I described what I meant in the post I sent to R-help
>> > (https://stat.ethz.ch/pipermail/r-help/2016-September/442174.html),
>> > but in brief, by "zero overhead" I mean that the only thing needed for
>> > library code to be accessible to client code is for it to be located
>> > in a designated directory.  No additional meta-files,
>> > packaging/compiling,
>> > etc. are required.
>> >
>> > Best,
>> >
>> > G.
>> >
>> > On Sun, Oct 2, 2016 at 7:09 PM,  <frederik at ofb.net> wrote:
>> > > Hi Kynn,
>> > >
>> > > Do you mind defining the term "zero-overhead model of code reuse"?
>> > >
>> > > I think I understand what you're getting at, but not sure.
>> > >
>> > > Thank you,
>> > >
>> > > Frederick
>> > >
>> > > On Sun, Oct 02, 2016 at 01:29:52PM -0400, Kynn Jones wrote:
>> > >> I'm looking for a way to approximate the "zero-overhead" model of
>> > >> code
>> > >> reuse available in languages like Python, Perl, etc.
>> > >>
>> > >> I've described this idea in more detail, and the motivation for this
>> > >> question in an earlier post to R-help
>> > >> (https://stat.ethz.ch/pipermail/r-help/2016-September/442174.html).
>> > >>
>> > >> (One of the responses I got advised that I post my question here
>> > >> instead.)
>> > >>
>> > >> The best I have so far is to configure my PROJ_R_LIB environment
>> > >> variable to point to the directory with my shared code, and put a
>> > >> function like the following in my .Rprofile file:
>> > >>
>> > >>     import <- function(name){
>> > >>         ## usage:
>> > >>         ## import("foo")
>> > >>         ## foo$bar()
>> > >>         path <- file.path(Sys.getenv("PROJ_R_LIB"),paste0(name,".R"))
>> > >>         if(!file.exists(path)) stop('file "',path,'" does not exist')
>> > >>         mod <- new.env()
>> > >>         source(path,local=mod)
>> > >>         list2env(setNames(list(mod),list(name)),envir=parent.frame())
>> > >>         invisible()
>> > >>     }
>> > >>
>> > >> (NB: the idea above is an elaboration of the one I showed in my first
>> > >> post.)
>> > >>
>> > >> But this is very much of an R noob's solution.  I figure there may
>> > >> already be more solid ways to achieve "zero-overhead" code reuse.
>> > >>
>> > >> I would appreciate any suggestions/critiques/pointers/comments.
>> > >>
>> > >> TIA!
>> > >>
>> > >> kj
>> > >>
>> > >> ______________________________________________
>> > >> R-devel at r-project.org mailing list
>> > >> https://stat.ethz.ch/mailman/listinfo/r-devel
>> > >>
>> >
>>
>> On Sun, Oct 02, 2016 at 08:05:53PM -0400, Kynn Jones wrote:
>> > On Sun, Oct 2, 2016 at 8:01 PM, Kynn Jones <kynnjo at gmail.com> wrote:
>> > > Hi Frederick,
>> > >
>> > > I described what I meant in the post I sent to R-help
>> > > (https://stat.ethz.ch/pipermail/r-help/2016-September/442174.html),
>> > > but in brief, by "zero overhead" I mean that the only thing needed for
>> > > library code to be accessible to client code is for it to be located
>> > > in designed directory.  No additional meta-files, packaging/compiling,
>> >      ^^^^^^^^
>> >
>> > Sorry, I meant to write "designated".
>> >
>> > > etc. are required.
>> >
>>
>> On Sun, Oct 02, 2016 at 07:18:41PM -0500, Dirk Eddelbuettel wrote:
>> >
>> > Kynn,
>> >
>> > How much homework have you done researching any other "alternatives" to
>> > the
>> > package system?  I know of at least one...
>> >
>> > In short, just about everybody here believes in packages. And
>> > repositories.
>> > And package management.  And version control (at the package level). And
>> > maybe byte compilation.  And associated documentation.  And unit tests.
>> > And
>> > continuous integration.
>> >
>> > You don't have to -- that's cool.  Different strokes for different
>> > folks.
>> >
>> > But if think you need something different you may just have to build
>> > that
>> > yourself.
>> >
>> > Cheers, Dirk
>> >
>> > --
>> > http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org
>> >
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From edd at debian.org  Mon Oct  3 23:55:56 2016
From: edd at debian.org (Dirk Eddelbuettel)
Date: Mon, 3 Oct 2016 16:55:56 -0500
Subject: [Rd] On implementing zero-overhead code reuse
In-Reply-To: <CAFvQaj69J8SuA3uirTa_jpY6JjUZb0DsPiFe5eru=ZbZTS_uLg@mail.gmail.com>
References: <22513.41953.204280.605359@max.nulle.part>
	<CAFvQaj6=UUWafXD5asf-mtho7O1qKs9TLpWmLRdmEhGYh1exVw@mail.gmail.com>
	<CAFvQaj4SLxim=Jqi_yeOrKTRvuhWB7X-C6xXjpCw_pbmfz_=3Q@mail.gmail.com>
	<20161003141859.GV9995@ofb.net>
	<CAC2h7usFJCN1R+Fw_8oaBb37dJdQO5FRLiSgh8tZ_V30nGBmNg@mail.gmail.com>
	<CAFvQaj69J8SuA3uirTa_jpY6JjUZb0DsPiFe5eru=ZbZTS_uLg@mail.gmail.com>
Message-ID: <22514.54252.986532.619094@max.nulle.part>


Kynn,

You appear confused by the meaning of the word "optional".

All the things I listed for packages are additional features you _may_ use,
not onces that are imposed on you so that they _must_ be used.

Lastly, I forgot to mention NAMESPACE support.  Which gives pretty much
exactly what you outlined at the beginning of your post as a desiderata.

But it seems you know full well what you need, so by all means do charge full
speed ahead.  But before I close allow me to reiterate that you are somewhat
ill-informed.

Packages do not impose anything. Asking to be included in a high-quality
repository such as CRAN does.

For local and personal packages you can be precisely as ad-hoc as you are in
sourced files.  Yet you still have access to the very framework that gives
you _options_ for more structure.

Dirk

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From martin.morgan at roswellpark.org  Tue Oct  4 00:17:12 2016
From: martin.morgan at roswellpark.org (Martin Morgan)
Date: Mon, 3 Oct 2016 18:17:12 -0400
Subject: [Rd] On implementing zero-overhead code reuse
In-Reply-To: <CAFvQaj69J8SuA3uirTa_jpY6JjUZb0DsPiFe5eru=ZbZTS_uLg@mail.gmail.com>
References: <22513.41953.204280.605359@max.nulle.part>
	<CAFvQaj6=UUWafXD5asf-mtho7O1qKs9TLpWmLRdmEhGYh1exVw@mail.gmail.com>
	<CAFvQaj4SLxim=Jqi_yeOrKTRvuhWB7X-C6xXjpCw_pbmfz_=3Q@mail.gmail.com>
	<20161003141859.GV9995@ofb.net>
	<CAC2h7usFJCN1R+Fw_8oaBb37dJdQO5FRLiSgh8tZ_V30nGBmNg@mail.gmail.com>
	<CAFvQaj69J8SuA3uirTa_jpY6JjUZb0DsPiFe5eru=ZbZTS_uLg@mail.gmail.com>
Message-ID: <789dc6b3-f557-9f5a-d373-09003a699f25@roswellpark.org>

On 10/03/2016 01:51 PM, Kynn Jones wrote:
> Thank you all for your comments and suggestions.
>
> @Frederik, my reason for mucking with environments is that I want to
> minimize the number of names that import adds to my current
> environment.  For instance, if module foo defines a function bar, I
> want my client code to look like this:
>
>   import("foo")
>   foo$bar(1,2,3)
>
> rather than
>
>   import("foo")
>   bar(1,2,3)
>
> (Just a personal preference.)
>
> @Dirk, @Kasper, as I see it, the benefit of scripting languages like
> Python, Perl, etc., is that they allow very quick development, with
> minimal up-front cost.  Their main strength is precisely that one can,
> without much difficulty, *immediately* start *programming
> productively*, without having to worry at all about (to quote Dirk)
> "repositories.  And package management.  And version control (at the
> package level).  And ... byte compilation.  And associated
> documentation.  And unit tests.  And continuous integration."
>
> Of course, *eventually*, and for a fraction of one's total code base
> (in my case, a *very small* fraction), one will want to worry about
> all those things, but I see no point in burdening *all* my code with
> all those concerns from the start.  Again, please keep in mind that
> those concerns come into play for at most 5% of the code I write.
>
> Also, I'd like to point out that the Python, Perl, etc. communities
> are no less committed to all the concerns that Dirk listed (version
> control, package management, documentation, testing, etc.) than the R
> community is.  And yet, Python, Perl, etc. support the "zero-overhead"
> model of code reuse.  There's no contradiction here.  Support for
> "zero-overhead" code reuse does not preclude forms of code reuse with
> more overhead.
>
> One benefit the zero-overhead model is that the concerns of
> documentation, testing, etc. can be addressed with varying degrees of
> thoroughness, depending on the situation's demands.  (For example,
> documentation that would be perfectly adequate for me as the author of
> a function would not be adequate for the general user.)
>
> This means that the transition from writing private code to writing
> code that can be shared with the world can be made much more
> gradually, according to the programmer's needs and means.
>
> Currently, in the R world, the choice for programmers is much starker:
> either stay writing little scripts that one sources from an
> interactive session, or learn to implement packages.  There's too
> little in-between.

I know it's flogging the same horse, but for the non-expert I create and 
attach a complete package

   devtools::create("myutils")
   library(myutils)

Of course it doesn't do anything, so I write my code by editing a plain 
text file myutils/R/foo.R to contain

   foo = function() "hello wirld"

then return to my still-running R session and install the updated 
package and use my new function

   devtools::install("myutils")
   foo()
   myutils::foo()  # same, but belt-and-suspenders

I notice my typo, update the file, and use the updated package

   devtools::install("myutils")
   foo()

The transition from here to a robust package can be gradual, updating 
the DESCRIPTION file, adding roxygen2 documentation, unit tests, using 
version control, etc... in a completely incremental way. At the end of 
it all, I'll still install and use my package with

   devtools::install("myutils")
   foo()

maybe graduating to

   devtools::install_github("mtmorgan/myutils")
   library(myutils)
   foo()

when it's time to share my work with the wirld.

Martin

>
> Of course, from the point of view of someone who has already written
> several packages, the barrier to writing a package may seem too small
> to fret over, but adopting the expert's perspective is likely to
> result in excluding the non-experts.
>
> Best, kj
>
>
> On Mon, Oct 3, 2016 at 12:06 PM, Kasper Daniel Hansen
> <kasperdanielhansen at gmail.com> wrote:
>>
>>
>> On Mon, Oct 3, 2016 at 10:18 AM, <frederik at ofb.net> wrote:
>>>
>>> Hi Kynn,
>>>
>>> Thanks for expanding.
>>>
>>> I wrote a function like yours when I first started using R. It's
>>> basically the same up to your "new.env()" line, I don't do anything
>>> with environmentns. I just called my function "mysource" and it's
>>> essentially a "source with path". That allows me to find code I reuse
>>> in standard locations.
>>>
>>> I don't know why R does not have built-in support for such a thing.
>>> You can get it in C compilers with CPATH, and as you say in Perl with
>>> PERL5LIB, in Python, etc. Obviously when I use my "mysource" I have to
>>> remember that my code is now not portable without copying over some
>>> files from other locations in my home directory. However, as a
>>> beginner I find this tool to be indispensable, as R lacks several
>>> functions which I use regularly, and I'm not necessarily ready to
>>> confront the challenges associated with creating a package.
>>
>>
>> I can pretty much guarantee that when you finally confront the "challenge"
>> of making your own package you'll realize (1) it is pretty easy if the
>> intention is only to use it yourself (and perhaps a couple of collaborators)
>> - by easy I mean I can make a package in 5m max. (2) you'll ask yourself
>> "why didn't I do this earlier?".  I still get that feeling now, when I have
>> done it many times for internal use.  Almost every time I think I should
>> have made an internal package earlier in the process.
>>
>> Of course, all of this is hard to see when you're standing in the middle of
>> your work.
>>
>> Best,
>> Kasper
>>
>>
>>
>>
>>
>>>
>>> However, I guess since we can get your functionality pretty easily
>>> using some lines in .Rprofile, that makes it seem less important to
>>> have it built-in. In fact, if everyone has to implement their own
>>> version of your "import", this almost guarantees that the function
>>> won't appear by accident in any public code. My choice of name
>>> "mysource" was meant to serve as a more visible lexical reminder that
>>> the function is not meant to be seen by the public.
>>>
>>> By the way, why do you do the stuff with environments in your "import"
>>> function?
>>>
>>> Dirk's take is interesting. I don't use version control for my
>>> personal projects, just backing-up. Obviously not all R users are
>>> interested in becoming package maintainers, in fact I think it would
>>> clutter things a bit if this were the case. Or maybe it would be good
>>> to have everyone publish their personal utility functions, who knows?
>>> Anyway I appreciate Dirk's arguments, but I'm also a bit surprised
>>> that Kynn and I seem to be the only ones who have written personal
>>> functions to do what Kynn calls "zero-overhead code reuse". FWIW.
>>>
>>> Cheers,
>>>
>>> Frederick
>>>
>>> On Sun, Oct 02, 2016 at 08:01:58PM -0400, Kynn Jones wrote:
>>>> Hi Frederick,
>>>>
>>>> I described what I meant in the post I sent to R-help
>>>> (https://stat.ethz.ch/pipermail/r-help/2016-September/442174.html),
>>>> but in brief, by "zero overhead" I mean that the only thing needed for
>>>> library code to be accessible to client code is for it to be located
>>>> in a designated directory.  No additional meta-files,
>>>> packaging/compiling,
>>>> etc. are required.
>>>>
>>>> Best,
>>>>
>>>> G.
>>>>
>>>> On Sun, Oct 2, 2016 at 7:09 PM,  <frederik at ofb.net> wrote:
>>>>> Hi Kynn,
>>>>>
>>>>> Do you mind defining the term "zero-overhead model of code reuse"?
>>>>>
>>>>> I think I understand what you're getting at, but not sure.
>>>>>
>>>>> Thank you,
>>>>>
>>>>> Frederick
>>>>>
>>>>> On Sun, Oct 02, 2016 at 01:29:52PM -0400, Kynn Jones wrote:
>>>>>> I'm looking for a way to approximate the "zero-overhead" model of
>>>>>> code
>>>>>> reuse available in languages like Python, Perl, etc.
>>>>>>
>>>>>> I've described this idea in more detail, and the motivation for this
>>>>>> question in an earlier post to R-help
>>>>>> (https://stat.ethz.ch/pipermail/r-help/2016-September/442174.html).
>>>>>>
>>>>>> (One of the responses I got advised that I post my question here
>>>>>> instead.)
>>>>>>
>>>>>> The best I have so far is to configure my PROJ_R_LIB environment
>>>>>> variable to point to the directory with my shared code, and put a
>>>>>> function like the following in my .Rprofile file:
>>>>>>
>>>>>>     import <- function(name){
>>>>>>         ## usage:
>>>>>>         ## import("foo")
>>>>>>         ## foo$bar()
>>>>>>         path <- file.path(Sys.getenv("PROJ_R_LIB"),paste0(name,".R"))
>>>>>>         if(!file.exists(path)) stop('file "',path,'" does not exist')
>>>>>>         mod <- new.env()
>>>>>>         source(path,local=mod)
>>>>>>         list2env(setNames(list(mod),list(name)),envir=parent.frame())
>>>>>>         invisible()
>>>>>>     }
>>>>>>
>>>>>> (NB: the idea above is an elaboration of the one I showed in my first
>>>>>> post.)
>>>>>>
>>>>>> But this is very much of an R noob's solution.  I figure there may
>>>>>> already be more solid ways to achieve "zero-overhead" code reuse.
>>>>>>
>>>>>> I would appreciate any suggestions/critiques/pointers/comments.
>>>>>>
>>>>>> TIA!
>>>>>>
>>>>>> kj
>>>>>>
>>>>>> ______________________________________________
>>>>>> R-devel at r-project.org mailing list
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>>>
>>>>
>>>
>>> On Sun, Oct 02, 2016 at 08:05:53PM -0400, Kynn Jones wrote:
>>>> On Sun, Oct 2, 2016 at 8:01 PM, Kynn Jones <kynnjo at gmail.com> wrote:
>>>>> Hi Frederick,
>>>>>
>>>>> I described what I meant in the post I sent to R-help
>>>>> (https://stat.ethz.ch/pipermail/r-help/2016-September/442174.html),
>>>>> but in brief, by "zero overhead" I mean that the only thing needed for
>>>>> library code to be accessible to client code is for it to be located
>>>>> in designed directory.  No additional meta-files, packaging/compiling,
>>>>      ^^^^^^^^
>>>>
>>>> Sorry, I meant to write "designated".
>>>>
>>>>> etc. are required.
>>>>
>>>
>>> On Sun, Oct 02, 2016 at 07:18:41PM -0500, Dirk Eddelbuettel wrote:
>>>>
>>>> Kynn,
>>>>
>>>> How much homework have you done researching any other "alternatives" to
>>>> the
>>>> package system?  I know of at least one...
>>>>
>>>> In short, just about everybody here believes in packages. And
>>>> repositories.
>>>> And package management.  And version control (at the package level). And
>>>> maybe byte compilation.  And associated documentation.  And unit tests.
>>>> And
>>>> continuous integration.
>>>>
>>>> You don't have to -- that's cool.  Different strokes for different
>>>> folks.
>>>>
>>>> But if think you need something different you may just have to build
>>>> that
>>>> yourself.
>>>>
>>>> Cheers, Dirk
>>>>
>>>> --
>>>> http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org
>>>>
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


This email message may contain legally privileged and/or...{{dropped:2}}


From kynnjo at gmail.com  Tue Oct  4 01:24:52 2016
From: kynnjo at gmail.com (Kynn Jones)
Date: Mon, 3 Oct 2016 19:24:52 -0400
Subject: [Rd] On implementing zero-overhead code reuse
In-Reply-To: <789dc6b3-f557-9f5a-d373-09003a699f25@roswellpark.org>
References: <22513.41953.204280.605359@max.nulle.part>
	<CAFvQaj6=UUWafXD5asf-mtho7O1qKs9TLpWmLRdmEhGYh1exVw@mail.gmail.com>
	<CAFvQaj4SLxim=Jqi_yeOrKTRvuhWB7X-C6xXjpCw_pbmfz_=3Q@mail.gmail.com>
	<20161003141859.GV9995@ofb.net>
	<CAC2h7usFJCN1R+Fw_8oaBb37dJdQO5FRLiSgh8tZ_V30nGBmNg@mail.gmail.com>
	<CAFvQaj69J8SuA3uirTa_jpY6JjUZb0DsPiFe5eru=ZbZTS_uLg@mail.gmail.com>
	<789dc6b3-f557-9f5a-d373-09003a699f25@roswellpark.org>
Message-ID: <CAFvQaj6Kr8nbKkt4N+Y3ahiVr2qJEPvQ-XXaBuc-Fqac-uWMiw@mail.gmail.com>

Martin, thanks for that example.  It's definitely eye-opening, and
very good to know.

The installation business, however, is still a killer for me.  Of
course, it's a trivial step in a simple example like the one you
showed.  But consider this scenario:  suppose I perform an analysis
that I may publish in the future, so I commit the project's state at
the time of the analysis, and tag the commit with the KEEPER tag.
Several months later, I want to repeat that exact analysis for some
whatever reason.  If the code for the analysis was in Python (say),
all I need to do is this (at the Unix command line):

    % git checkout KEEPER
    % python src/python/go_to_town.py

...knowing that the `git checkout KEEPER` command, *all by itself*,
has put the working directory in the state I want it to be before I
re-do the analysis.

AFAICT, if the code for the analysis was in R, then `git checkout`, by
itself, would *not* put the working directory in the desired state.  I
still need to re-install all the R libraries in the repo.  And I
better not forget to do this re-installation, otherwise I will end up
running code different from the one I thought I was running.  (I find
this prospect horrifying, for some reason.)

A similar need to re-install stuff would arise whenever I update the repo.

Please correct me if I'm wrong.


From spencer.graves at prodsyse.com  Tue Oct  4 01:59:07 2016
From: spencer.graves at prodsyse.com (Spencer Graves)
Date: Mon, 3 Oct 2016 18:59:07 -0500
Subject: [Rd] suggested addition to model.matrix
Message-ID: <37d127c5-2137-e077-61af-6cbe1b6cad47@prodsyse.com>

Hello, All:


       What's the simplest way to convert a data.frame into a model.matrix?


       One way is given by the following example, modified from the 
examples in help(model.matrix):


dd <- data.frame(a = gl(3,4), b = gl(4,1,12))
ab <- model.matrix(~ a + b, dd)
ab0 <- model.matrix(~., dd)
all.equal(ab, ab0)


       What do you think about replacing "model.matrix(~ a + b, dd)" in 
the current help(model.matrix) with this 3-line expansion?


       I suggest this, because I spent a few hours today trying to 
convert a data.frame into a model.matrix before finding this.


       Also, what do you think about adding something like the following 
to the stats package:


model.matrix.data.frame <- function(object, ...){
     model.matrix(~., object, ...)
}


       And then extend the above example as follows:

ab. <- model.matrix(dd)
all.equal(ab, ab.)


       Thanks,
       Spencer Graves


From jfox at mcmaster.ca  Tue Oct  4 06:46:02 2016
From: jfox at mcmaster.ca (Fox, John)
Date: Tue, 4 Oct 2016 04:46:02 +0000
Subject: [Rd] suggested addition to model.matrix
In-Reply-To: <37d127c5-2137-e077-61af-6cbe1b6cad47@prodsyse.com>
References: <37d127c5-2137-e077-61af-6cbe1b6cad47@prodsyse.com>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC836581F47@FHSDB2D11-2.csu.mcmaster.ca>

Dear Spencer,

I don't think that the problem of "converting a data frame into a model matrix" is well-defined, because there isn't a unique mapping from one to the other. 

In your example, you build  the model matrix for the additive formula ~ a + b from the data frame matrix containing a and b, using "treatment" contrasts, but there are other possible formulas (e.g., ~ a*b) and contrasts [e.g., model.matrix(~ a + b, dd, contrasts=list(a=contr.sum, b=contr.helmert)].

So I think that the current approach is sensible -- to require both a data frame and a formula.

Best,
 John

> -----Original Message-----
> From: R-devel [mailto:r-devel-bounces at r-project.org] On Behalf Of Spencer
> Graves
> Sent: October 3, 2016 7:59 PM
> To: r-devel at r-project.org
> Subject: [Rd] suggested addition to model.matrix
> 
> Hello, All:
> 
> 
>        What's the simplest way to convert a data.frame into a model.matrix?
> 
> 
>        One way is given by the following example, modified from the examples in
> help(model.matrix):
> 
> 
> dd <- data.frame(a = gl(3,4), b = gl(4,1,12))
> ab <- model.matrix(~ a + b, dd)
> ab0 <- model.matrix(~., dd)
> all.equal(ab, ab0)
> 
> 
>        What do you think about replacing "model.matrix(~ a + b, dd)" in
> the current help(model.matrix) with this 3-line expansion?
> 
> 
>        I suggest this, because I spent a few hours today trying to
> convert a data.frame into a model.matrix before finding this.
> 
> 
>        Also, what do you think about adding something like the following
> to the stats package:
> 
> 
> model.matrix.data.frame <- function(object, ...){
>      model.matrix(~., object, ...)
> }
> 
> 
>        And then extend the above example as follows:
> 
> ab. <- model.matrix(dd)
> all.equal(ab, ab.)
> 
> 
>        Thanks,
>        Spencer Graves
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From konrad.rudolph+r-devel at gmail.com  Tue Oct  4 13:07:31 2016
From: konrad.rudolph+r-devel at gmail.com (Konrad Rudolph)
Date: Tue, 04 Oct 2016 11:07:31 +0000
Subject: [Rd] On implementing zero-overhead code reuse
In-Reply-To: <CAFvQaj4Bcd-FW_z2Sc019d9JUa_Xy3Xz0HO=Ze16ZLnGJx4JiQ@mail.gmail.com>
References: <CAFvQaj4Bcd-FW_z2Sc019d9JUa_Xy3Xz0HO=Ze16ZLnGJx4JiQ@mail.gmail.com>
Message-ID: <CAM2gKPbGxrFy+hNBVixPTgRNRinTJY9k5O0sfOJMdNVF=7L5iA@mail.gmail.com>

Check out ?klmr/modules? on Github (distinct from CRAN?s ?modules?!). It
looks pretty much exactly like what you want:

https://github.com/klmr/modules

It has an extensive README and vignette explaining the usage.

Cheers,
Konrad

-- 
Konrad Rudolph
On Sun, 2 Oct 2016 at 18:31 Kynn Jones <kynnjo at gmail.com> wrote:

> I'm looking for a way to approximate the "zero-overhead" model of code
> reuse available in languages like Python, Perl, etc.
>
> I've described this idea in more detail, and the motivation for this
> question in an earlier post to R-help
> (https://stat.ethz.ch/pipermail/r-help/2016-September/442174.html).
>
> (One of the responses I got advised that I post my question here instead.)
>
> The best I have so far is to configure my PROJ_R_LIB environment
> variable to point to the directory with my shared code, and put a
> function like the following in my .Rprofile file:
>
>     import <- function(name){
>         ## usage:
>         ## import("foo")
>         ## foo$bar()
>         path <- file.path(Sys.getenv("PROJ_R_LIB"),paste0(name,".R"))
>         if(!file.exists(path)) stop('file "',path,'" does not exist')
>         mod <- new.env()
>         source(path,local=mod)
>         list2env(setNames(list(mod),list(name)),envir=parent.frame())
>         invisible()
>     }
>
> (NB: the idea above is an elaboration of the one I showed in my first
> post.)
>
> But this is very much of an R noob's solution.  I figure there may
> already be more solid ways to achieve "zero-overhead" code reuse.
>
> I would appreciate any suggestions/critiques/pointers/comments.
>
> TIA!
>
> kj
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From elw at stderr.org  Tue Oct  4 18:10:35 2016
From: elw at stderr.org (elijah wright)
Date: Tue, 4 Oct 2016 11:10:35 -0500
Subject: [Rd] On implementing zero-overhead code reuse
In-Reply-To: <CAFvQaj6Kr8nbKkt4N+Y3ahiVr2qJEPvQ-XXaBuc-Fqac-uWMiw@mail.gmail.com>
References: <22513.41953.204280.605359@max.nulle.part>
	<CAFvQaj6=UUWafXD5asf-mtho7O1qKs9TLpWmLRdmEhGYh1exVw@mail.gmail.com>
	<CAFvQaj4SLxim=Jqi_yeOrKTRvuhWB7X-C6xXjpCw_pbmfz_=3Q@mail.gmail.com>
	<20161003141859.GV9995@ofb.net>
	<CAC2h7usFJCN1R+Fw_8oaBb37dJdQO5FRLiSgh8tZ_V30nGBmNg@mail.gmail.com>
	<CAFvQaj69J8SuA3uirTa_jpY6JjUZb0DsPiFe5eru=ZbZTS_uLg@mail.gmail.com>
	<789dc6b3-f557-9f5a-d373-09003a699f25@roswellpark.org>
	<CAFvQaj6Kr8nbKkt4N+Y3ahiVr2qJEPvQ-XXaBuc-Fqac-uWMiw@mail.gmail.com>
Message-ID: <CANQ3A2MXOEjq+tiT+fv2fSc=fMGR-Xoo0dSdfJxLAK6y_icoZA@mail.gmail.com>

Shower thoughts:

Are you digging for something like what you'd use with a CI/CD pipeline?
 e.g. - building a workflow that pulls a tag from a couple of code
repositories, checks them out into a workspace, installs prereqs, and then
runs your code/tasks in a repeatable fashion?

I'm not aware of a thing that is like a Gemfile or a Berksfile or a
package.json for R - but you can surely approximate that with a job step
that runs install.packages from a snippet of R code.

[I did have a quick glance at the install.packages docs to refresh my
memory -- it looks like it's biased toward installing the latest *unless*
you point it at something like an archive that has your package selections
frozen in time.  You can either store the deps yourself, or find an archive
that has historical snapshots by-date?  I would expect, really, that the
CRAN packages are unlikely to suddenly stop being version controlled or for
their history to vanish into the ether....   Maybe someone stores zfs
snapshots or similar of CRAN, on a date-by-date basis?  It should be cheap
(disk wise) to do...]

In my ideal world 'newer packages should mean more accurate results' --
running code with older package versions should mean that you're
duplicating the errors which to me seems not-useful in most cases....

best,

--e


On Mon, Oct 3, 2016 at 6:24 PM, Kynn Jones <kynnjo at gmail.com> wrote:

> Martin, thanks for that example.  It's definitely eye-opening, and
> very good to know.
>
> The installation business, however, is still a killer for me.  Of
> course, it's a trivial step in a simple example like the one you
> showed.  But consider this scenario:  suppose I perform an analysis
> that I may publish in the future, so I commit the project's state at
> the time of the analysis, and tag the commit with the KEEPER tag.
> Several months later, I want to repeat that exact analysis for some
> whatever reason.  If the code for the analysis was in Python (say),
> all I need to do is this (at the Unix command line):
>
>     % git checkout KEEPER
>     % python src/python/go_to_town.py
>
> ...knowing that the `git checkout KEEPER` command, *all by itself*,
> has put the working directory in the state I want it to be before I
> re-do the analysis.
>
> AFAICT, if the code for the analysis was in R, then `git checkout`, by
> itself, would *not* put the working directory in the desired state.  I
> still need to re-install all the R libraries in the repo.  And I
> better not forget to do this re-installation, otherwise I will end up
> running code different from the one I thought I was running.  (I find
> this prospect horrifying, for some reason.)
>
> A similar need to re-install stuff would arise whenever I update the repo.
>
> Please correct me if I'm wrong.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Tue Oct  4 18:27:19 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 4 Oct 2016 09:27:19 -0700
Subject: [Rd] suggested addition to model.matrix
In-Reply-To: <ACD1644AA6C67E4FBD0C350625508EC836581F47@FHSDB2D11-2.csu.mcmaster.ca>
References: <37d127c5-2137-e077-61af-6cbe1b6cad47@prodsyse.com>
	<ACD1644AA6C67E4FBD0C350625508EC836581F47@FHSDB2D11-2.csu.mcmaster.ca>
Message-ID: <CAF8bMcbf669xUr949YBv8=X6u3534V8vPqbpXEePcNCq+4GS4Q@mail.gmail.com>

In addition, there is a formula method for data.frame that
assumes the first column is the dependent variable.
 > z <- data.frame(X1=1:6,X2=letters[1:3],Y=log(1:6))
 > formula(z)
 X1 ~ X2 + Y
 > colnames(model.matrix(formula(z), z))
 [1] "(Intercept)" "X2b"         "X2c"         "Y"

Spencer's request is that the default formula given to model.matrix have
no dependent variable.
 > colnames(model.matrix(~., z))
 [1] "(Intercept)" "X1"          "X2b"         "X2c"         "Y"

In my opinion, formula.data.frame is a mistake, but we don't need two
incompatible mistakes.


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Mon, Oct 3, 2016 at 9:46 PM, Fox, John <jfox at mcmaster.ca> wrote:

> Dear Spencer,
>
> I don't think that the problem of "converting a data frame into a model
> matrix" is well-defined, because there isn't a unique mapping from one to
> the other.
>
> In your example, you build  the model matrix for the additive formula ~ a
> + b from the data frame matrix containing a and b, using "treatment"
> contrasts, but there are other possible formulas (e.g., ~ a*b) and
> contrasts [e.g., model.matrix(~ a + b, dd, contrasts=list(a=contr.sum,
> b=contr.helmert)].
>
> So I think that the current approach is sensible -- to require both a data
> frame and a formula.
>
> Best,
>  John
>
> > -----Original Message-----
> > From: R-devel [mailto:r-devel-bounces at r-project.org] On Behalf Of
> Spencer
> > Graves
> > Sent: October 3, 2016 7:59 PM
> > To: r-devel at r-project.org
> > Subject: [Rd] suggested addition to model.matrix
> >
> > Hello, All:
> >
> >
> >        What's the simplest way to convert a data.frame into a
> model.matrix?
> >
> >
> >        One way is given by the following example, modified from the
> examples in
> > help(model.matrix):
> >
> >
> > dd <- data.frame(a = gl(3,4), b = gl(4,1,12))
> > ab <- model.matrix(~ a + b, dd)
> > ab0 <- model.matrix(~., dd)
> > all.equal(ab, ab0)
> >
> >
> >        What do you think about replacing "model.matrix(~ a + b, dd)" in
> > the current help(model.matrix) with this 3-line expansion?
> >
> >
> >        I suggest this, because I spent a few hours today trying to
> > convert a data.frame into a model.matrix before finding this.
> >
> >
> >        Also, what do you think about adding something like the following
> > to the stats package:
> >
> >
> > model.matrix.data.frame <- function(object, ...){
> >      model.matrix(~., object, ...)
> > }
> >
> >
> >        And then extend the above example as follows:
> >
> > ab. <- model.matrix(dd)
> > all.equal(ab, ab.)
> >
> >
> >        Thanks,
> >        Spencer Graves
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Tue Oct  4 22:40:43 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 4 Oct 2016 13:40:43 -0700
Subject: [Rd] error handling in strcapture
In-Reply-To: <CAOQ5Nyd3MfPh-Bvmi9yNyxsrMWzJAbBs_zRrKni8pdFB-fkw7w@mail.gmail.com>
References: <CAF8bMcZrTbM7FFPVoQv1=BpzpVY2-tvLGB+68UaQzLROF2-JDw@mail.gmail.com>
	<CAOQ5NydFbWHyAYasxUvhNjAu3hiWAwtvMKv35sd2TsNbihLqqw@mail.gmail.com>
	<CAF8bMca95a+ByPbD9YKgnZm26ZFQO8ju1irj9KVkkXqaP5B74Q@mail.gmail.com>
	<CAOQ5Nyd3MfPh-Bvmi9yNyxsrMWzJAbBs_zRrKni8pdFB-fkw7w@mail.gmail.com>
Message-ID: <CAF8bMcap0wCSn2Ti6nTXV+HFh6fE=p2YfZxnZcDueU+GoG9MFQ@mail.gmail.com>

I noticed a problem in the strcapture from R-devel (2016-09-27 r71386),
when the text contains a missing value and perl=TRUE.

{
      # NA in text input should map to row of NA's in output, without
warning
      r9p <- strcapture(perl = TRUE, "(.).* ([[:digit:]]+)", c("One 1", NA,
"Fifty 50"), data.frame(Initial=factor(), Number=numeric()))
      e9p <- structure(list(Initial = structure(c(2L, NA, 1L), .Label =
c("F", "O"), class = "factor"),
                           Number = c(1, NA, 50)),
                      row.names = c(NA, -3L),
                      class = "data.frame")
      all.equal(e9p, r9p)
  }
#Error in if (any(ind)) { : missing value where TRUE/FALSE needed


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Wed, Sep 21, 2016 at 2:32 PM, Michael Lawrence <lawrence.michael at gene.com
> wrote:

> The new behavior is that it yields NAs when the pattern does not match
> (like strptime) and for empty captures in a matching pattern it yields
> the empty string, which is consistent with regmatches().
>
> Michael
>
> On Wed, Sep 21, 2016 at 2:21 PM, William Dunlap <wdunlap at tibco.com> wrote:
> > If there are any matches then strcapture can see if the pattern has the
> same
> > number of capture expressions as the prototype has columns and give an
> > error if not.  That seems appropriate.
> >
> > If there are no matches, then there is no easy way to see if the
> prototype
> > is compatible with the pattern, so should strcapture just assume the best
> > and fill in the prototype with NA's?
> >
> > Should there be warnings?  This is kind of like strptime(), which
> silently
> > gives NA's when the format does not match the text input.
> >
> >
> > Bill Dunlap
> > TIBCO Software
> > wdunlap tibco.com
> >
> > On Wed, Sep 21, 2016 at 2:10 PM, Michael Lawrence
> > <lawrence.michael at gene.com> wrote:
> >>
> >> Hi Bill,
> >>
> >> Thanks, another good suggestion. strcapture() now returns NAs for
> >> non-matches. It's nice to have someone kicking the tires on that
> >> function.
> >>
> >> Michael
> >>
> >> On Wed, Sep 21, 2016 at 12:11 PM, William Dunlap via R-devel
> >> <r-devel at r-project.org> wrote:
> >> > Michael, thanks for looking at my first issue with utils::strcapture.
> >> >
> >> > Another issue is how it deals with lines that don't match the pattern.
> >> > Currently it gives an error
> >> >
> >> >> strcapture("(.+) (.+)", c("One 1", "noSpaceInLine", "Three 3"),
> >> > proto=list(Name="", Number=0))
> >> > Error in strcapture("(.+) (.+)", c("One 1", "noSpaceInLine", "Three
> 3"),
> >> > :
> >> >   number of matches does not always match ncol(proto)
> >> >
> >> > First, isn't the 'number of matches' the number of parenthesized
> >> > subpatterns in the regular expression?  I thought that if the entire
> >> > pattern matches then the subpatterns without matches would be
> >> > shown as matches at position 0 with length 0.  Hence either the
> >> > pattern is compatible with the prototype or it isn't, it does not
> depend
> >> > on the text input.  E.g.,
> >> >
> >> >> regexec("^(([[:alpha:]]+)|([[:digit:]]+))$", c("Twelve", "12",
> "Z280"))
> >> > [[1]]
> >> > [1] 1 1 1 0
> >> > attr(,"match.length")
> >> > [1] 6 6 6 0
> >> > attr(,"useBytes")
> >> > [1] TRUE
> >> >
> >> > [[2]]
> >> > [1] 1 1 0 1
> >> > attr(,"match.length")
> >> > [1] 2 2 0 2
> >> > attr(,"useBytes")
> >> > [1] TRUE
> >> >
> >> > [[3]]
> >> > [1] -1
> >> > attr(,"match.length")
> >> > [1] -1
> >> > attr(,"useBytes")
> >> > [1] TRUE
> >> >
> >> > Second, an error message like 'some lines were bad' is not very
> helpful.
> >> > Should it put NA's in all the columns of the current output row if the
> >> > input line didn't match the pattern and perhaps warn the user that
> there
> >> > were problems?  The user could then look for rows of NA's to see where
> >> > the
> >> > problems were.
> >> >
> >> > Bill Dunlap
> >> > TIBCO Software
> >> > wdunlap tibco.com
> >> >
> >> >         [[alternative HTML version deleted]]
> >> >
> >> > ______________________________________________
> >> > R-devel at r-project.org mailing list
> >> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
> >
>

	[[alternative HTML version deleted]]


From lawrence.michael at gene.com  Tue Oct  4 23:21:50 2016
From: lawrence.michael at gene.com (Michael Lawrence)
Date: Tue, 4 Oct 2016 14:21:50 -0700
Subject: [Rd] error handling in strcapture
In-Reply-To: <CAF8bMcap0wCSn2Ti6nTXV+HFh6fE=p2YfZxnZcDueU+GoG9MFQ@mail.gmail.com>
References: <CAF8bMcZrTbM7FFPVoQv1=BpzpVY2-tvLGB+68UaQzLROF2-JDw@mail.gmail.com>
	<CAOQ5NydFbWHyAYasxUvhNjAu3hiWAwtvMKv35sd2TsNbihLqqw@mail.gmail.com>
	<CAF8bMca95a+ByPbD9YKgnZm26ZFQO8ju1irj9KVkkXqaP5B74Q@mail.gmail.com>
	<CAOQ5Nyd3MfPh-Bvmi9yNyxsrMWzJAbBs_zRrKni8pdFB-fkw7w@mail.gmail.com>
	<CAF8bMcap0wCSn2Ti6nTXV+HFh6fE=p2YfZxnZcDueU+GoG9MFQ@mail.gmail.com>
Message-ID: <CAOQ5NycDCgWuh3CP0_iuZnekYht45U+RSaWXW4-JBjsriro+Rw@mail.gmail.com>

Hi Bill,

This is a bug in regexec() and I will commit a fix.

Thanks for the report,
Michael

On Tue, Oct 4, 2016 at 1:40 PM, William Dunlap <wdunlap at tibco.com> wrote:
> I noticed a problem in the strcapture from R-devel (2016-09-27 r71386), when
> the text contains a missing value and perl=TRUE.
>
> {
>       # NA in text input should map to row of NA's in output, without
> warning
>       r9p <- strcapture(perl = TRUE, "(.).* ([[:digit:]]+)", c("One 1", NA,
> "Fifty 50"), data.frame(Initial=factor(), Number=numeric()))
>       e9p <- structure(list(Initial = structure(c(2L, NA, 1L), .Label =
> c("F", "O"), class = "factor"),
>                            Number = c(1, NA, 50)),
>                       row.names = c(NA, -3L),
>                       class = "data.frame")
>       all.equal(e9p, r9p)
>   }
> #Error in if (any(ind)) { : missing value where TRUE/FALSE needed
>
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
> On Wed, Sep 21, 2016 at 2:32 PM, Michael Lawrence
> <lawrence.michael at gene.com> wrote:
>>
>> The new behavior is that it yields NAs when the pattern does not match
>> (like strptime) and for empty captures in a matching pattern it yields
>> the empty string, which is consistent with regmatches().
>>
>> Michael
>>
>> On Wed, Sep 21, 2016 at 2:21 PM, William Dunlap <wdunlap at tibco.com> wrote:
>> > If there are any matches then strcapture can see if the pattern has the
>> > same
>> > number of capture expressions as the prototype has columns and give an
>> > error if not.  That seems appropriate.
>> >
>> > If there are no matches, then there is no easy way to see if the
>> > prototype
>> > is compatible with the pattern, so should strcapture just assume the
>> > best
>> > and fill in the prototype with NA's?
>> >
>> > Should there be warnings?  This is kind of like strptime(), which
>> > silently
>> > gives NA's when the format does not match the text input.
>> >
>> >
>> > Bill Dunlap
>> > TIBCO Software
>> > wdunlap tibco.com
>> >
>> > On Wed, Sep 21, 2016 at 2:10 PM, Michael Lawrence
>> > <lawrence.michael at gene.com> wrote:
>> >>
>> >> Hi Bill,
>> >>
>> >> Thanks, another good suggestion. strcapture() now returns NAs for
>> >> non-matches. It's nice to have someone kicking the tires on that
>> >> function.
>> >>
>> >> Michael
>> >>
>> >> On Wed, Sep 21, 2016 at 12:11 PM, William Dunlap via R-devel
>> >> <r-devel at r-project.org> wrote:
>> >> > Michael, thanks for looking at my first issue with utils::strcapture.
>> >> >
>> >> > Another issue is how it deals with lines that don't match the
>> >> > pattern.
>> >> > Currently it gives an error
>> >> >
>> >> >> strcapture("(.+) (.+)", c("One 1", "noSpaceInLine", "Three 3"),
>> >> > proto=list(Name="", Number=0))
>> >> > Error in strcapture("(.+) (.+)", c("One 1", "noSpaceInLine", "Three
>> >> > 3"),
>> >> > :
>> >> >   number of matches does not always match ncol(proto)
>> >> >
>> >> > First, isn't the 'number of matches' the number of parenthesized
>> >> > subpatterns in the regular expression?  I thought that if the entire
>> >> > pattern matches then the subpatterns without matches would be
>> >> > shown as matches at position 0 with length 0.  Hence either the
>> >> > pattern is compatible with the prototype or it isn't, it does not
>> >> > depend
>> >> > on the text input.  E.g.,
>> >> >
>> >> >> regexec("^(([[:alpha:]]+)|([[:digit:]]+))$", c("Twelve", "12",
>> >> >> "Z280"))
>> >> > [[1]]
>> >> > [1] 1 1 1 0
>> >> > attr(,"match.length")
>> >> > [1] 6 6 6 0
>> >> > attr(,"useBytes")
>> >> > [1] TRUE
>> >> >
>> >> > [[2]]
>> >> > [1] 1 1 0 1
>> >> > attr(,"match.length")
>> >> > [1] 2 2 0 2
>> >> > attr(,"useBytes")
>> >> > [1] TRUE
>> >> >
>> >> > [[3]]
>> >> > [1] -1
>> >> > attr(,"match.length")
>> >> > [1] -1
>> >> > attr(,"useBytes")
>> >> > [1] TRUE
>> >> >
>> >> > Second, an error message like 'some lines were bad' is not very
>> >> > helpful.
>> >> > Should it put NA's in all the columns of the current output row if
>> >> > the
>> >> > input line didn't match the pattern and perhaps warn the user that
>> >> > there
>> >> > were problems?  The user could then look for rows of NA's to see
>> >> > where
>> >> > the
>> >> > problems were.
>> >> >
>> >> > Bill Dunlap
>> >> > TIBCO Software
>> >> > wdunlap tibco.com
>> >> >
>> >> >         [[alternative HTML version deleted]]
>> >> >
>> >> > ______________________________________________
>> >> > R-devel at r-project.org mailing list
>> >> > https://stat.ethz.ch/mailman/listinfo/r-devel
>> >
>> >
>
>


From wdunlap at tibco.com  Tue Oct  4 23:37:00 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 4 Oct 2016 14:37:00 -0700
Subject: [Rd] error handling in strcapture
In-Reply-To: <CAOQ5NycDCgWuh3CP0_iuZnekYht45U+RSaWXW4-JBjsriro+Rw@mail.gmail.com>
References: <CAF8bMcZrTbM7FFPVoQv1=BpzpVY2-tvLGB+68UaQzLROF2-JDw@mail.gmail.com>
	<CAOQ5NydFbWHyAYasxUvhNjAu3hiWAwtvMKv35sd2TsNbihLqqw@mail.gmail.com>
	<CAF8bMca95a+ByPbD9YKgnZm26ZFQO8ju1irj9KVkkXqaP5B74Q@mail.gmail.com>
	<CAOQ5Nyd3MfPh-Bvmi9yNyxsrMWzJAbBs_zRrKni8pdFB-fkw7w@mail.gmail.com>
	<CAF8bMcap0wCSn2Ti6nTXV+HFh6fE=p2YfZxnZcDueU+GoG9MFQ@mail.gmail.com>
	<CAOQ5NycDCgWuh3CP0_iuZnekYht45U+RSaWXW4-JBjsriro+Rw@mail.gmail.com>
Message-ID: <CAF8bMcYoinMz0GfKYJr8WLkhTNLw3cc4-mS9SUgNBE9m=8GKQw@mail.gmail.com>

It is also not catching the cases where the number of capture expressions
does not match the number of entries in proto.  I think all of the
following should give an error about the mismatch.

> strcapture("(.)(.)", c("ab", "cde", "fgh", "ij", "lm"),
proto=list(A="",B="",C=""))
   A  B  C
1  a  b cd
2  d fg  f
3 ij  i  j
4  l  m ab
Warning message:
In matrix(as.character(unlist(str)), ncol = ntokens, byrow = TRUE) :
  data length [15] is not a sub-multiple or multiple of the number of rows
[4]
> strcapture("(.)(.)(.)", c("abc", "def", "ghi", "jkl", "mno"),
proto=list(A="",B=""))
    A   B
1   a   b
2 def   d
3   f ghi
4   h   i
5   j   k
6 mno   m
7   o abc
Warning message:
In matrix(as.character(unlist(str)), ncol = ntokens, byrow = TRUE) :
  data length [20] is not a sub-multiple or multiple of the number of rows
[7]
> strcapture("(.)(.)(.)", c("abc", "def"), proto=list(A=""))
  A
1 a
2 c
3 d
4 f


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Tue, Oct 4, 2016 at 2:21 PM, Michael Lawrence <lawrence.michael at gene.com>
wrote:

> Hi Bill,
>
> This is a bug in regexec() and I will commit a fix.
>
> Thanks for the report,
> Michael
>
> On Tue, Oct 4, 2016 at 1:40 PM, William Dunlap <wdunlap at tibco.com> wrote:
> > I noticed a problem in the strcapture from R-devel (2016-09-27 r71386),
> when
> > the text contains a missing value and perl=TRUE.
> >
> > {
> >       # NA in text input should map to row of NA's in output, without
> > warning
> >       r9p <- strcapture(perl = TRUE, "(.).* ([[:digit:]]+)", c("One 1",
> NA,
> > "Fifty 50"), data.frame(Initial=factor(), Number=numeric()))
> >       e9p <- structure(list(Initial = structure(c(2L, NA, 1L), .Label =
> > c("F", "O"), class = "factor"),
> >                            Number = c(1, NA, 50)),
> >                       row.names = c(NA, -3L),
> >                       class = "data.frame")
> >       all.equal(e9p, r9p)
> >   }
> > #Error in if (any(ind)) { : missing value where TRUE/FALSE needed
> >
> >
> > Bill Dunlap
> > TIBCO Software
> > wdunlap tibco.com
> >
> > On Wed, Sep 21, 2016 at 2:32 PM, Michael Lawrence
> > <lawrence.michael at gene.com> wrote:
> >>
> >> The new behavior is that it yields NAs when the pattern does not match
> >> (like strptime) and for empty captures in a matching pattern it yields
> >> the empty string, which is consistent with regmatches().
> >>
> >> Michael
> >>
> >> On Wed, Sep 21, 2016 at 2:21 PM, William Dunlap <wdunlap at tibco.com>
> wrote:
> >> > If there are any matches then strcapture can see if the pattern has
> the
> >> > same
> >> > number of capture expressions as the prototype has columns and give an
> >> > error if not.  That seems appropriate.
> >> >
> >> > If there are no matches, then there is no easy way to see if the
> >> > prototype
> >> > is compatible with the pattern, so should strcapture just assume the
> >> > best
> >> > and fill in the prototype with NA's?
> >> >
> >> > Should there be warnings?  This is kind of like strptime(), which
> >> > silently
> >> > gives NA's when the format does not match the text input.
> >> >
> >> >
> >> > Bill Dunlap
> >> > TIBCO Software
> >> > wdunlap tibco.com
> >> >
> >> > On Wed, Sep 21, 2016 at 2:10 PM, Michael Lawrence
> >> > <lawrence.michael at gene.com> wrote:
> >> >>
> >> >> Hi Bill,
> >> >>
> >> >> Thanks, another good suggestion. strcapture() now returns NAs for
> >> >> non-matches. It's nice to have someone kicking the tires on that
> >> >> function.
> >> >>
> >> >> Michael
> >> >>
> >> >> On Wed, Sep 21, 2016 at 12:11 PM, William Dunlap via R-devel
> >> >> <r-devel at r-project.org> wrote:
> >> >> > Michael, thanks for looking at my first issue with
> utils::strcapture.
> >> >> >
> >> >> > Another issue is how it deals with lines that don't match the
> >> >> > pattern.
> >> >> > Currently it gives an error
> >> >> >
> >> >> >> strcapture("(.+) (.+)", c("One 1", "noSpaceInLine", "Three 3"),
> >> >> > proto=list(Name="", Number=0))
> >> >> > Error in strcapture("(.+) (.+)", c("One 1", "noSpaceInLine", "Three
> >> >> > 3"),
> >> >> > :
> >> >> >   number of matches does not always match ncol(proto)
> >> >> >
> >> >> > First, isn't the 'number of matches' the number of parenthesized
> >> >> > subpatterns in the regular expression?  I thought that if the
> entire
> >> >> > pattern matches then the subpatterns without matches would be
> >> >> > shown as matches at position 0 with length 0.  Hence either the
> >> >> > pattern is compatible with the prototype or it isn't, it does not
> >> >> > depend
> >> >> > on the text input.  E.g.,
> >> >> >
> >> >> >> regexec("^(([[:alpha:]]+)|([[:digit:]]+))$", c("Twelve", "12",
> >> >> >> "Z280"))
> >> >> > [[1]]
> >> >> > [1] 1 1 1 0
> >> >> > attr(,"match.length")
> >> >> > [1] 6 6 6 0
> >> >> > attr(,"useBytes")
> >> >> > [1] TRUE
> >> >> >
> >> >> > [[2]]
> >> >> > [1] 1 1 0 1
> >> >> > attr(,"match.length")
> >> >> > [1] 2 2 0 2
> >> >> > attr(,"useBytes")
> >> >> > [1] TRUE
> >> >> >
> >> >> > [[3]]
> >> >> > [1] -1
> >> >> > attr(,"match.length")
> >> >> > [1] -1
> >> >> > attr(,"useBytes")
> >> >> > [1] TRUE
> >> >> >
> >> >> > Second, an error message like 'some lines were bad' is not very
> >> >> > helpful.
> >> >> > Should it put NA's in all the columns of the current output row if
> >> >> > the
> >> >> > input line didn't match the pattern and perhaps warn the user that
> >> >> > there
> >> >> > were problems?  The user could then look for rows of NA's to see
> >> >> > where
> >> >> > the
> >> >> > problems were.
> >> >> >
> >> >> > Bill Dunlap
> >> >> > TIBCO Software
> >> >> > wdunlap tibco.com
> >> >> >
> >> >> >         [[alternative HTML version deleted]]
> >> >> >
> >> >> > ______________________________________________
> >> >> > R-devel at r-project.org mailing list
> >> >> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >> >
> >> >
> >
> >
>

	[[alternative HTML version deleted]]


From kynnjo at gmail.com  Tue Oct  4 23:50:29 2016
From: kynnjo at gmail.com (Kynn Jones)
Date: Tue, 4 Oct 2016 17:50:29 -0400
Subject: [Rd] On implementing zero-overhead code reuse
In-Reply-To: <CAM2gKPbGxrFy+hNBVixPTgRNRinTJY9k5O0sfOJMdNVF=7L5iA@mail.gmail.com>
References: <CAFvQaj4Bcd-FW_z2Sc019d9JUa_Xy3Xz0HO=Ze16ZLnGJx4JiQ@mail.gmail.com>
	<CAM2gKPbGxrFy+hNBVixPTgRNRinTJY9k5O0sfOJMdNVF=7L5iA@mail.gmail.com>
Message-ID: <CAFvQaj7vipO8O9kYkJGT5tTOYo9z5KS3hVu4tn8Zp9p7=ANL8g@mail.gmail.com>

@Konrad, you're right, that's exactly what I'm looking for.  That's
great stuff.  Thanks!  (And thanks also to Gabor Grothendieck, who
suggested modules to me way back.)


On Tue, Oct 4, 2016 at 7:07 AM, Konrad Rudolph
<konrad.rudolph+r-devel at gmail.com> wrote:
> Check out ?klmr/modules? on Github (distinct from CRAN?s ?modules?!). It
> looks pretty much exactly like what you want:
>
> https://github.com/klmr/modules
>
> It has an extensive README and vignette explaining the usage.
>
> Cheers,
> Konrad
>
> --
> Konrad Rudolph
> On Sun, 2 Oct 2016 at 18:31 Kynn Jones <kynnjo at gmail.com> wrote:
>>
>> I'm looking for a way to approximate the "zero-overhead" model of code
>> reuse available in languages like Python, Perl, etc.
>>
>> I've described this idea in more detail, and the motivation for this
>> question in an earlier post to R-help
>> (https://stat.ethz.ch/pipermail/r-help/2016-September/442174.html).
>>
>> (One of the responses I got advised that I post my question here instead.)
>>
>> The best I have so far is to configure my PROJ_R_LIB environment
>> variable to point to the directory with my shared code, and put a
>> function like the following in my .Rprofile file:
>>
>>     import <- function(name){
>>         ## usage:
>>         ## import("foo")
>>         ## foo$bar()
>>         path <- file.path(Sys.getenv("PROJ_R_LIB"),paste0(name,".R"))
>>         if(!file.exists(path)) stop('file "',path,'" does not exist')
>>         mod <- new.env()
>>         source(path,local=mod)
>>         list2env(setNames(list(mod),list(name)),envir=parent.frame())
>>         invisible()
>>     }
>>
>> (NB: the idea above is an elaboration of the one I showed in my first
>> post.)
>>
>> But this is very much of an R noob's solution.  I figure there may
>> already be more solid ways to achieve "zero-overhead" code reuse.
>>
>> I would appreciate any suggestions/critiques/pointers/comments.
>>
>> TIA!
>>
>> kj
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel


From lawrence.michael at gene.com  Tue Oct  4 23:59:33 2016
From: lawrence.michael at gene.com (Michael Lawrence)
Date: Tue, 4 Oct 2016 14:59:33 -0700
Subject: [Rd] error handling in strcapture
In-Reply-To: <CAF8bMcYoinMz0GfKYJr8WLkhTNLw3cc4-mS9SUgNBE9m=8GKQw@mail.gmail.com>
References: <CAF8bMcZrTbM7FFPVoQv1=BpzpVY2-tvLGB+68UaQzLROF2-JDw@mail.gmail.com>
	<CAOQ5NydFbWHyAYasxUvhNjAu3hiWAwtvMKv35sd2TsNbihLqqw@mail.gmail.com>
	<CAF8bMca95a+ByPbD9YKgnZm26ZFQO8ju1irj9KVkkXqaP5B74Q@mail.gmail.com>
	<CAOQ5Nyd3MfPh-Bvmi9yNyxsrMWzJAbBs_zRrKni8pdFB-fkw7w@mail.gmail.com>
	<CAF8bMcap0wCSn2Ti6nTXV+HFh6fE=p2YfZxnZcDueU+GoG9MFQ@mail.gmail.com>
	<CAOQ5NycDCgWuh3CP0_iuZnekYht45U+RSaWXW4-JBjsriro+Rw@mail.gmail.com>
	<CAF8bMcYoinMz0GfKYJr8WLkhTNLw3cc4-mS9SUgNBE9m=8GKQw@mail.gmail.com>
Message-ID: <CAOQ5NydbySt5nFLDbqc2fhw6LzweOa9LFce0wNKmOFHj+CZWcw@mail.gmail.com>

Once again, nice catch. I've committed a check for this.

Michael

On Tue, Oct 4, 2016 at 2:37 PM, William Dunlap <wdunlap at tibco.com> wrote:
> It is also not catching the cases where the number of capture expressions
> does not match the number of entries in proto.  I think all of the following
> should give an error about the mismatch.
>
>> strcapture("(.)(.)", c("ab", "cde", "fgh", "ij", "lm"),
>> proto=list(A="",B="",C=""))
>    A  B  C
> 1  a  b cd
> 2  d fg  f
> 3 ij  i  j
> 4  l  m ab
> Warning message:
> In matrix(as.character(unlist(str)), ncol = ntokens, byrow = TRUE) :
>   data length [15] is not a sub-multiple or multiple of the number of rows
> [4]
>> strcapture("(.)(.)(.)", c("abc", "def", "ghi", "jkl", "mno"),
>> proto=list(A="",B=""))
>     A   B
> 1   a   b
> 2 def   d
> 3   f ghi
> 4   h   i
> 5   j   k
> 6 mno   m
> 7   o abc
> Warning message:
> In matrix(as.character(unlist(str)), ncol = ntokens, byrow = TRUE) :
>   data length [20] is not a sub-multiple or multiple of the number of rows
> [7]
>> strcapture("(.)(.)(.)", c("abc", "def"), proto=list(A=""))
>   A
> 1 a
> 2 c
> 3 d
> 4 f
>
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
> On Tue, Oct 4, 2016 at 2:21 PM, Michael Lawrence <lawrence.michael at gene.com>
> wrote:
>>
>> Hi Bill,
>>
>> This is a bug in regexec() and I will commit a fix.
>>
>> Thanks for the report,
>> Michael
>>
>> On Tue, Oct 4, 2016 at 1:40 PM, William Dunlap <wdunlap at tibco.com> wrote:
>> > I noticed a problem in the strcapture from R-devel (2016-09-27 r71386),
>> > when
>> > the text contains a missing value and perl=TRUE.
>> >
>> > {
>> >       # NA in text input should map to row of NA's in output, without
>> > warning
>> >       r9p <- strcapture(perl = TRUE, "(.).* ([[:digit:]]+)", c("One 1",
>> > NA,
>> > "Fifty 50"), data.frame(Initial=factor(), Number=numeric()))
>> >       e9p <- structure(list(Initial = structure(c(2L, NA, 1L), .Label =
>> > c("F", "O"), class = "factor"),
>> >                            Number = c(1, NA, 50)),
>> >                       row.names = c(NA, -3L),
>> >                       class = "data.frame")
>> >       all.equal(e9p, r9p)
>> >   }
>> > #Error in if (any(ind)) { : missing value where TRUE/FALSE needed
>> >
>> >
>> > Bill Dunlap
>> > TIBCO Software
>> > wdunlap tibco.com
>> >
>> > On Wed, Sep 21, 2016 at 2:32 PM, Michael Lawrence
>> > <lawrence.michael at gene.com> wrote:
>> >>
>> >> The new behavior is that it yields NAs when the pattern does not match
>> >> (like strptime) and for empty captures in a matching pattern it yields
>> >> the empty string, which is consistent with regmatches().
>> >>
>> >> Michael
>> >>
>> >> On Wed, Sep 21, 2016 at 2:21 PM, William Dunlap <wdunlap at tibco.com>
>> >> wrote:
>> >> > If there are any matches then strcapture can see if the pattern has
>> >> > the
>> >> > same
>> >> > number of capture expressions as the prototype has columns and give
>> >> > an
>> >> > error if not.  That seems appropriate.
>> >> >
>> >> > If there are no matches, then there is no easy way to see if the
>> >> > prototype
>> >> > is compatible with the pattern, so should strcapture just assume the
>> >> > best
>> >> > and fill in the prototype with NA's?
>> >> >
>> >> > Should there be warnings?  This is kind of like strptime(), which
>> >> > silently
>> >> > gives NA's when the format does not match the text input.
>> >> >
>> >> >
>> >> > Bill Dunlap
>> >> > TIBCO Software
>> >> > wdunlap tibco.com
>> >> >
>> >> > On Wed, Sep 21, 2016 at 2:10 PM, Michael Lawrence
>> >> > <lawrence.michael at gene.com> wrote:
>> >> >>
>> >> >> Hi Bill,
>> >> >>
>> >> >> Thanks, another good suggestion. strcapture() now returns NAs for
>> >> >> non-matches. It's nice to have someone kicking the tires on that
>> >> >> function.
>> >> >>
>> >> >> Michael
>> >> >>
>> >> >> On Wed, Sep 21, 2016 at 12:11 PM, William Dunlap via R-devel
>> >> >> <r-devel at r-project.org> wrote:
>> >> >> > Michael, thanks for looking at my first issue with
>> >> >> > utils::strcapture.
>> >> >> >
>> >> >> > Another issue is how it deals with lines that don't match the
>> >> >> > pattern.
>> >> >> > Currently it gives an error
>> >> >> >
>> >> >> >> strcapture("(.+) (.+)", c("One 1", "noSpaceInLine", "Three 3"),
>> >> >> > proto=list(Name="", Number=0))
>> >> >> > Error in strcapture("(.+) (.+)", c("One 1", "noSpaceInLine",
>> >> >> > "Three
>> >> >> > 3"),
>> >> >> > :
>> >> >> >   number of matches does not always match ncol(proto)
>> >> >> >
>> >> >> > First, isn't the 'number of matches' the number of parenthesized
>> >> >> > subpatterns in the regular expression?  I thought that if the
>> >> >> > entire
>> >> >> > pattern matches then the subpatterns without matches would be
>> >> >> > shown as matches at position 0 with length 0.  Hence either the
>> >> >> > pattern is compatible with the prototype or it isn't, it does not
>> >> >> > depend
>> >> >> > on the text input.  E.g.,
>> >> >> >
>> >> >> >> regexec("^(([[:alpha:]]+)|([[:digit:]]+))$", c("Twelve", "12",
>> >> >> >> "Z280"))
>> >> >> > [[1]]
>> >> >> > [1] 1 1 1 0
>> >> >> > attr(,"match.length")
>> >> >> > [1] 6 6 6 0
>> >> >> > attr(,"useBytes")
>> >> >> > [1] TRUE
>> >> >> >
>> >> >> > [[2]]
>> >> >> > [1] 1 1 0 1
>> >> >> > attr(,"match.length")
>> >> >> > [1] 2 2 0 2
>> >> >> > attr(,"useBytes")
>> >> >> > [1] TRUE
>> >> >> >
>> >> >> > [[3]]
>> >> >> > [1] -1
>> >> >> > attr(,"match.length")
>> >> >> > [1] -1
>> >> >> > attr(,"useBytes")
>> >> >> > [1] TRUE
>> >> >> >
>> >> >> > Second, an error message like 'some lines were bad' is not very
>> >> >> > helpful.
>> >> >> > Should it put NA's in all the columns of the current output row if
>> >> >> > the
>> >> >> > input line didn't match the pattern and perhaps warn the user that
>> >> >> > there
>> >> >> > were problems?  The user could then look for rows of NA's to see
>> >> >> > where
>> >> >> > the
>> >> >> > problems were.
>> >> >> >
>> >> >> > Bill Dunlap
>> >> >> > TIBCO Software
>> >> >> > wdunlap tibco.com
>> >> >> >
>> >> >> >         [[alternative HTML version deleted]]
>> >> >> >
>> >> >> > ______________________________________________
>> >> >> > R-devel at r-project.org mailing list
>> >> >> > https://stat.ethz.ch/mailman/listinfo/r-devel
>> >> >
>> >> >
>> >
>> >
>
>


From henrik.bengtsson at gmail.com  Wed Oct  5 20:28:11 2016
From: henrik.bengtsson at gmail.com (Henrik Bengtsson)
Date: Wed, 5 Oct 2016 11:28:11 -0700
Subject: [Rd] parallel: Memory improvement to PSOCK clusters (PATCH)
Message-ID: <CAFDcVCQqC7n4cftHiP=2ij7Cp9omiKn87Q=UU=LHPui4-Cnzjw@mail.gmail.com>

I would like to bump the attention of a very simple patch to
parallel:::slaveLoop(), which I've already submitted as
https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=17115.  The patch
lowers the memory overhead for anyone using parallel::makeCluster().

The patch makes sure that the workers remove their results / values as
soon as they've been transferred back to the master process.  They
also remove any incoming objects / values as soon as possible.   For
instance, if a PSOCK worker produces 1 GiB objects in each iteration,
it is currently holding on to the old result while working on the new
one resulting in an unnecessary 1 GiB memory overhead.  This patch
avoids this.

Index: src/library/parallel/R/worker.R
===================================================================
--- src/library/parallel/R/worker.R (revision 70874)
+++ src/library/parallel/R/worker.R (working copy)
@@ -44,7 +44,9 @@
                 t2 <- proc.time()
                 value <- list(type = "VALUE", value = value, success = success,
                               time = t2 - t1, tag = msg$data$tag)
+                rm(list = "msg")
                 sendData(master, value)
+                rm(list = "value")
             }
         }, interrupt = function(e) NULL)
 }

Thanks,

Henrik


From wewolski at gmail.com  Fri Oct  7 12:18:24 2016
From: wewolski at gmail.com (Witold E Wolski)
Date: Fri, 7 Oct 2016 12:18:24 +0200
Subject: [Rd] unzip does not like a / at the end of path.
Message-ID: <CAAjnpdgDHuPDKZPW6-i+WhsN+g=96LRKVnm3ZB3MpZ5rtDV29Q@mail.gmail.com>

dir("inst/extdata/")
dir("./inst/extdata/")
dir("inst/extdata")

works all fine, listing the directory content.

but:

unzip(tmp[1],exdir = "inst/extdata/")
Error in unzip(tmp[1], exdir = "inst/extdata/") : 'exdir' does not exist
unzip(tmp[1],exdir = "./inst/extdata/")
Error in unzip(tmp[1], exdir = "inst/extdata/") : 'exdir' does not exist

only
unzip(tmp[1],exdir = "inst/extdata")
does work.

Somehow inconsistent isn't it?


-- 
Witold Eryk Wolski


From murdoch.duncan at gmail.com  Fri Oct  7 12:34:56 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 7 Oct 2016 06:34:56 -0400
Subject: [Rd] unzip does not like a / at the end of path.
In-Reply-To: <CAAjnpdgDHuPDKZPW6-i+WhsN+g=96LRKVnm3ZB3MpZ5rtDV29Q@mail.gmail.com>
References: <CAAjnpdgDHuPDKZPW6-i+WhsN+g=96LRKVnm3ZB3MpZ5rtDV29Q@mail.gmail.com>
Message-ID: <de636419-2658-377d-b05f-7db4a00bf487@gmail.com>

On 07/10/2016 6:18 AM, Witold E Wolski wrote:
> dir("inst/extdata/")
> dir("./inst/extdata/")
> dir("inst/extdata")
>
> works all fine, listing the directory content.
>
> but:
>
> unzip(tmp[1],exdir = "inst/extdata/")
> Error in unzip(tmp[1], exdir = "inst/extdata/") : 'exdir' does not exist
> unzip(tmp[1],exdir = "./inst/extdata/")
> Error in unzip(tmp[1], exdir = "inst/extdata/") : 'exdir' does not exist
>
> only
> unzip(tmp[1],exdir = "inst/extdata")
> does work.
>
> Somehow inconsistent isn't it?
>
>

You don't say what platform you're working on, but I'd guess Windows, 
because on Windows "inst/extdata/" (or "inst\extdata\") is not a valid 
path.  The dir() function works around this issue by removing trailing 
slashes as appropriate, but unzip() passes the work to an external 
utility, and it is stricter about enforcing the rules of the platform.

Duncan Murdoch


From suharto_anggono at yahoo.com  Sat Oct  8 16:42:46 2016
From: suharto_anggono at yahoo.com (Suharto Anggono Suharto Anggono)
Date: Sat, 8 Oct 2016 14:42:46 +0000 (UTC)
Subject: [Rd] 'max' on mixed numeric and character arguments
References: <1873513454.533658.1475937766535.ref@mail.yahoo.com>
Message-ID: <1873513454.533658.1475937766535@mail.yahoo.com>

Bug 17160 (https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=17160) leads me to ask this. In R, should max(...) equals max(c(...)) ? If 'max' have both numeric and character arguments, should lexicographic sorting be used for all?

> max("", 3, 10)
[1] "3"
> max("", c(3, 10))
[1] "10"
> range("", c(3, 10))[2]
[1] "3"

Should all above have the same result?

> sessionInfo()
R version 3.3.1 (2016-06-21)
Platform: i386-w64-mingw32/i386 (32-bit)
Running under: Windows XP (build 2600) Service Pack 2

locale:
[1] LC_COLLATE=English_United States.1252
[2] LC_CTYPE=English_United States.1252
[3] LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C
[5] LC_TIME=English_United States.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base


From spencer.graves at prodsyse.com  Sat Oct  8 20:50:35 2016
From: spencer.graves at prodsyse.com (Spencer Graves)
Date: Sat, 8 Oct 2016 13:50:35 -0500
Subject: [Rd] =?utf-8?b?b3B0aW0o4oCmLCBtZXRob2Q94oCYTC1CRkdTLULigJkpIHN0?=
 =?utf-8?q?ops_with_an_error_message_while_violating_the_lower_bound?=
Message-ID: <a4515835-87f7-302d-5420-4cbf10b44fa1@prodsyse.com>

Hello:


       The development version of Ecdat on R-Forge contains a vignette 
in which optim(?, method=?L-BFGS-B?) stops with an error message while 
violating the lower bound.


       To see all the details, try the following:


install.packages("Ecdat", repos="http://R-Forge.R-project.org")


       Then do "help(pac=Ecdat)" -> "User guides, package vignettes and 
other documentation" -> "Ecdat::AverageIncomeModels".


       I've found other optimizers that will get around the problem in 
this case but none that performs as well as optim with many other problems.


       Thanks,
       Spencer Graves


p.s.  I've also tested bobyqa{minqa} or nloptr{nloptr}, recommended in a 
vignette in the lme4 package.  These did better than optim in this 
example but worse in others I tried.


From ravi.varadhan at jhu.edu  Sat Oct  8 21:29:54 2016
From: ravi.varadhan at jhu.edu (Ravi Varadhan)
Date: Sat, 8 Oct 2016 19:29:54 +0000
Subject: [Rd]
 =?windows-1252?q?optim=28=85=2C_method=3D=91L-BFGS-B=92=29_s?=
 =?windows-1252?q?tops_with_an_error_message_while_violating_the_lower_bou?=
 =?windows-1252?q?nd?=
In-Reply-To: <a4515835-87f7-302d-5420-4cbf10b44fa1@prodsyse.com>
References: <a4515835-87f7-302d-5420-4cbf10b44fa1@prodsyse.com>
Message-ID: <1475954974266.10173@jhu.edu>

Have you tried "optimx" package that John Nash and I wrote?  The main purpose is to be able to readily compare multiple optimizers on a particular class of problems and see which one seems to do the best.  It doesn't include nloptr, but most other optimizers are there.

Ravi
________________________________________
From: R-devel <r-devel-bounces at r-project.org> on behalf of Spencer Graves <spencer.graves at prodsyse.com>
Sent: Saturday, October 8, 2016 2:50 PM
To: R-devel
Subject: [Rd] optim(?, method=?L-BFGS-B?) stops with an error message while violating the lower bound

Hello:


       The development version of Ecdat on R-Forge contains a vignette
in which optim(?, method=?L-BFGS-B?) stops with an error message while
violating the lower bound.


       To see all the details, try the following:


install.packages("Ecdat", repos="http://R-Forge.R-project.org")


       Then do "help(pac=Ecdat)" -> "User guides, package vignettes and
other documentation" -> "Ecdat::AverageIncomeModels".


       I've found other optimizers that will get around the problem in
this case but none that performs as well as optim with many other problems.


       Thanks,
       Spencer Graves


p.s.  I've also tested bobyqa{minqa} or nloptr{nloptr}, recommended in a
vignette in the lme4 package.  These did better than optim in this
example but worse in others I tried.

______________________________________________
R-devel at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-devel


From spencer.graves at prodsyse.com  Sat Oct  8 23:43:37 2016
From: spencer.graves at prodsyse.com (Spencer Graves)
Date: Sat, 8 Oct 2016 16:43:37 -0500
Subject: [Rd]
 =?utf-8?b?b3B0aW0o4oCmLCBtZXRob2Q94oCYTC1CRkdTLULigJkpIHN0?=
 =?utf-8?q?ops_with_an_error_message_while_violating_the_lower_bound?=
In-Reply-To: <1475954974266.10173@jhu.edu>
References: <a4515835-87f7-302d-5420-4cbf10b44fa1@prodsyse.com>
	<1475954974266.10173@jhu.edu>
Message-ID: <95dadd40-e6f6-1c60-a874-4bb426da1d9e@prodsyse.com>

Hi, Ravi:


       Thanks.  I got the following:


 > optimx.out[order(optimx.out$value),
+    c('Q.lvl', 'Q.slope', 'H', 'value', 'kkt1', 'kkt2')]
                Q.lvl       Q.slope            H
nlminb   0.001806087  0.000000e+00 0.000000e+00
nmkb     0.001806177  6.924995e-13 1.563012e-12
L-BFGS-B 0.001939930 -1.084202e-19 0.000000e+00
spg      0.001422563  2.308140e-01 0.000000e+00
bobyqa   0.001423449  9.622976e-01 0.000000e+00
hjkb     1.000000000  1.000000e+00 1.000000e+00
Rcgmin            NA            NA           NA
Rvmmin            NA            NA           NA
                   value  kkt1  kkt2
nlminb    -3.869081e+02 FALSE  TRUE
nmkb      -3.869081e+02 FALSE FALSE
L-BFGS-B  -3.866286e+02 FALSE  TRUE
spg       -3.010668e+02 FALSE FALSE
bobyqa    -2.726830e+02 FALSE FALSE
hjkb       3.515507e+02    NA    NA
Rcgmin    8.988466e+307    NA    NA
Rvmmin    8.988466e+307    NA    NA


        'L-BFGS-B' returned the same violation of the constraint that 
lower = 0 as before.  'nlminb' and 'nmkb' got essentially the same 
answer, but neither seemed confident they had the minimum.  'nmkb' 
reported the same 'value' as 'nlminb', but the parameter values were at 
the boundary for nlminb and not for nmkb.  When I started optimx with 
nlminb, the first 5 decided that was the best and the last 3 failed, as 
before.


       I've added this to my vignette on this.


       Thanks,
       Spencer Graves


On 10/8/2016 2:29 PM, Ravi Varadhan wrote:
> Have you tried "optimx" package that John Nash and I wrote?  The main  > purpose is to be able to readily compare multiple optimizers on a > 
particular class of problems and see which one seems to do the best. > 
It doesn't include nloptr, but most other optimizers are there. > > Ravi 
________________________________________ From: R-devel > 
<r-devel-bounces at r-project.org> on behalf of Spencer Graves > 
<spencer.graves at prodsyse.com> Sent: Saturday, October 8, 2016 2:50 > PM 
To: R-devel Subject: [Rd] optim(?, method=?L-BFGS-B?) stops with > an 
error message while violating the lower bound > > Hello: > > > The 
development version of Ecdat on R-Forge contains a vignette in > which 
optim(?, method=?L-BFGS-B?) stops with an error message while > 
violating the lower bound. > > > To see all the details, try the 
following: > > > install.packages("Ecdat", 
repos="http://R-Forge.R-project.org") > > > Then do "help(pac=Ecdat)" -> 
"User guides, package vignettes and > other documentation" -> 
"Ecdat::AverageIncomeModels". > > > I've found other optimizers that 
will get around the problem in this > case but none that performs as 
well as optim with many other > problems. > > > Thanks, Spencer Graves > 
 > > p.s.  I've also tested bobyqa{minqa} or nloptr{nloptr}, recommended 
 > in a vignette in the lme4 package.  These did better than optim in > 
this example but worse in others I tried. > > 
______________________________________________ R-devel at r-project.org > 
mailing list https://stat.ethz.ch/mailman/listinfo/r-devel >



	[[alternative HTML version deleted]]


From markleeds2 at gmail.com  Sun Oct  9 00:00:24 2016
From: markleeds2 at gmail.com (Mark Leeds)
Date: Sat, 8 Oct 2016 18:00:24 -0400
Subject: [Rd]
	=?utf-8?b?b3B0aW0o4oCmLCBtZXRob2Q94oCYTC1CRkdTLULigJkpIHN0?=
	=?utf-8?q?ops_with_an_error_message_while_violating_the_lower_boun?=
	=?utf-8?q?d?=
In-Reply-To: <a4515835-87f7-302d-5420-4cbf10b44fa1@prodsyse.com>
References: <a4515835-87f7-302d-5420-4cbf10b44fa1@prodsyse.com>
Message-ID: <CAHz+bWZExjt5YGu0SaAx4bK7hvFo0QsT0NE=d-4Wuc+aFRwPMg@mail.gmail.com>

Hi Spencer: See the link below about L-BFGS-B below because  I had problems
with it a good while back (and I think the link description is the cause
but I can't prove it )  so  eventually I moved to the  Rvmmin(b) package.
It's a package but really an algorithm. Rvmmin(b) uses a variable-metric
algorithm similar to that of L-BFGS-B but without the problem below. It's
not surprisingly a creation of John Nash and quite impressive based on my
experience. Just like L-BFGS, it can implement box constraints by adding
the b.

http://users.eecs.northwestern.edu/~morales/PSfiles/acm-remark.pdf







On Sat, Oct 8, 2016 at 2:50 PM, Spencer Graves <spencer.graves at prodsyse.com>
wrote:

> Hello:
>
>
>       The development version of Ecdat on R-Forge contains a vignette in
> which optim(?, method=?L-BFGS-B?) stops with an error message while
> violating the lower bound.
>
>
>       To see all the details, try the following:
>
>
> install.packages("Ecdat", repos="http://R-Forge.R-project.org")
>
>
>       Then do "help(pac=Ecdat)" -> "User guides, package vignettes and
> other documentation" -> "Ecdat::AverageIncomeModels".
>
>
>       I've found other optimizers that will get around the problem in this
> case but none that performs as well as optim with many other problems.
>
>
>       Thanks,
>       Spencer Graves
>
>
> p.s.  I've also tested bobyqa{minqa} or nloptr{nloptr}, recommended in a
> vignette in the lme4 package.  These did better than optim in this example
> but worse in others I tried.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

	[[alternative HTML version deleted]]


From spencer.graves at prodsyse.com  Sun Oct  9 01:03:43 2016
From: spencer.graves at prodsyse.com (Spencer Graves)
Date: Sat, 8 Oct 2016 18:03:43 -0500
Subject: [Rd]
 =?utf-8?b?b3B0aW0o4oCmLCBtZXRob2Q94oCYTC1CRkdTLULigJkpIHN0?=
 =?utf-8?q?ops_with_an_error_message_while_violating_the_lower_bound?=
In-Reply-To: <CAHz+bWZExjt5YGu0SaAx4bK7hvFo0QsT0NE=d-4Wuc+aFRwPMg@mail.gmail.com>
References: <a4515835-87f7-302d-5420-4cbf10b44fa1@prodsyse.com>
	<CAHz+bWZExjt5YGu0SaAx4bK7hvFo0QsT0NE=d-4Wuc+aFRwPMg@mail.gmail.com>
Message-ID: <f29714b9-98d6-3a55-d798-40decfa13461@prodsyse.com>

Hi, Mark et al.:


       Thanks, Mark.


       Three comments:


             1.  Rvmmin was one of the methods I tried after Ravi 
directed me to optimx.  It returned NAs for essentially everything. See 
my email of this subject stamped 4:43 PM Central time = 21:43 UTC.


             2.  It would be interesting to know if the current 
algorithm behind optim and optimx with method='L-BFGS-B' incorporates 
Morales and Nocedal (2011) 'Remark on ?Algorithm 778: L-BFGS-B: Fortran 
Subroutines for Large-Scale Bound Constrained Optimization?'.  I created 
this vignette and started this threat hoping that someone on the R Core 
team might decide it's worth checking things like that.


             3.  The vignette mentioned below was extracted from a 
larger vignette fitting several models that seem to encounter 
convergence problems.  I should probably switch to optimx using all the 
methods that offers for constrained optimization, including nminb.


       Best Wishes,
       Spencer Graves


On 10/8/2016 5:00 PM, Mark Leeds wrote:
> Hi Spencer: See the link below about L-BFGS-B below because  I had 
> problems
> with it a good while back (and I think the link description is the 
> cause but I can't prove it )  so  eventually I moved to the  Rvmmin(b) 
> package. It's a package but really an algorithm. Rvmmin(b) uses a 
> variable-metric algorithm similar to that of L-BFGS-B but without the 
> problem below. It's not surprisingly a creation of John Nash and quite 
> impressive based on my experience. Just like L-BFGS, it can implement 
> box constraints by adding the b.
>
> http://users.eecs.northwestern.edu/~morales/PSfiles/acm-remark.pdf 
> <http://users.eecs.northwestern.edu/%7Emorales/PSfiles/acm-remark.pdf>
>
>
>
>
>
>
>
> On Sat, Oct 8, 2016 at 2:50 PM, Spencer Graves 
> <spencer.graves at prodsyse.com <mailto:spencer.graves at prodsyse.com>> wrote:
>
>     Hello:
>
>
>           The development version of Ecdat on R-Forge contains a
>     vignette in which optim(?, method=?L-BFGS-B?) stops with an error
>     message while violating the lower bound.
>
>
>           To see all the details, try the following:
>
>
>     install.packages("Ecdat", repos="http://R-Forge.R-project.org
>     <http://R-Forge.R-project.org>")
>
>
>           Then do "help(pac=Ecdat)" -> "User guides, package vignettes
>     and other documentation" -> "Ecdat::AverageIncomeModels".
>
>
>           I've found other optimizers that will get around the problem
>     in this case but none that performs as well as optim with many
>     other problems.
>
>
>           Thanks,
>           Spencer Graves
>
>
>     p.s.  I've also tested bobyqa{minqa} or nloptr{nloptr},
>     recommended in a vignette in the lme4 package.  These did better
>     than optim in this example but worse in others I tried.
>
>     ______________________________________________
>     R-devel at r-project.org <mailto:R-devel at r-project.org> mailing list
>     https://stat.ethz.ch/mailman/listinfo/r-devel
>     <https://stat.ethz.ch/mailman/listinfo/r-devel>
>
>


	[[alternative HTML version deleted]]


From markleeds2 at gmail.com  Sun Oct  9 02:41:44 2016
From: markleeds2 at gmail.com (Mark Leeds)
Date: Sat, 8 Oct 2016 20:41:44 -0400
Subject: [Rd]
	=?utf-8?b?b3B0aW0o4oCmLCBtZXRob2Q94oCYTC1CRkdTLULigJkpIHN0?=
	=?utf-8?q?ops_with_an_error_message_while_violating_the_lower_boun?=
	=?utf-8?q?d?=
In-Reply-To: <f29714b9-98d6-3a55-d798-40decfa13461@prodsyse.com>
References: <a4515835-87f7-302d-5420-4cbf10b44fa1@prodsyse.com>
	<CAHz+bWZExjt5YGu0SaAx4bK7hvFo0QsT0NE=d-4Wuc+aFRwPMg@mail.gmail.com>
	<f29714b9-98d6-3a55-d798-40decfa13461@prodsyse.com>
Message-ID: <CAHz+bWb3Zt1qjNzRKJNQKUbC+37dm7udVavkRERZfkPxCr=rkw@mail.gmail.com>

Hi Spencer:

1)  I can't help much as far as your results but one thing you could do is
check what
the convergence flag of Rvmmin is. There are difference ones depending
on what happened during the optimization and they're pretty helpful IIRC.
But that may require running Rvmmin directly rather than in optimx.
I did a lot of optimizations ( hundreds ) at one point and I never saw it
return NA ??

2) I wasn't sure about 2) either so I figured it was safer to get away from
L-BFGS-B.








On Sat, Oct 8, 2016 at 7:03 PM, Spencer Graves <spencer.graves at prodsyse.com>
wrote:

> Hi, Mark et al.:
>
>
>       Thanks, Mark.
>
>
>       Three comments:
>
>
>             1.  Rvmmin was one of the methods I tried after Ravi directed
> me to optimx.  It returned NAs for essentially everything.  See my email of
> this subject stamped 4:43 PM Central time = 21:43 UTC.
>
>
>             2.  It would be interesting to know if the current algorithm
> behind optim and optimx with method='L-BFGS-B' incorporates Morales and
> Nocedal (2011) 'Remark on ?Algorithm 778: L-BFGS-B: Fortran Subroutines for
> Large-Scale Bound Constrained Optimization?'.  I created this vignette and
> started this threat hoping that someone on the R Core team might decide
> it's worth checking things like that.
>
>
>             3.  The vignette mentioned below was extracted from a larger
> vignette fitting several models that seem to encounter convergence
> problems.  I should probably switch to optimx using all the methods that
> offers for constrained optimization, including nminb.
>
>
>       Best Wishes,
>       Spencer Graves
>
>
>
> On 10/8/2016 5:00 PM, Mark Leeds wrote:
>
> Hi Spencer: See the link below about L-BFGS-B below because  I had problems
> with it a good while back (and I think the link description is the cause
> but I can't prove it )  so  eventually I moved to the  Rvmmin(b) package.
> It's a package but really an algorithm. Rvmmin(b) uses a variable-metric
> algorithm similar to that of L-BFGS-B but without the problem below. It's
> not surprisingly a creation of John Nash and quite impressive based on my
> experience. Just like L-BFGS, it can implement box constraints by adding
> the b.
>
> http://users.eecs.northwestern.edu/~morales/PSfiles/acm-remark.pdf
>
>
>
>
>
>
>
> On Sat, Oct 8, 2016 at 2:50 PM, Spencer Graves <
> spencer.graves at prodsyse.com> wrote:
>
>> Hello:
>>
>>
>>       The development version of Ecdat on R-Forge contains a vignette in
>> which optim(?, method=?L-BFGS-B?) stops with an error message while
>> violating the lower bound.
>>
>>
>>       To see all the details, try the following:
>>
>>
>> install.packages("Ecdat", repos="http://R-Forge.R-project.org")
>>
>>
>>       Then do "help(pac=Ecdat)" -> "User guides, package vignettes and
>> other documentation" -> "Ecdat::AverageIncomeModels".
>>
>>
>>       I've found other optimizers that will get around the problem in
>> this case but none that performs as well as optim with many other problems.
>>
>>
>>       Thanks,
>>       Spencer Graves
>>
>>
>> p.s.  I've also tested bobyqa{minqa} or nloptr{nloptr}, recommended in a
>> vignette in the lme4 package.  These did better than optim in this example
>> but worse in others I tried.
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>
>
>

	[[alternative HTML version deleted]]


From profjcnash at gmail.com  Sun Oct  9 16:00:39 2016
From: profjcnash at gmail.com (ProfJCNash)
Date: Sun, 9 Oct 2016 10:00:39 -0400
Subject: [Rd] optim(?, method=?L-BFGS-B?) stops with an error
Message-ID: <6a609ef9-79ea-d78a-83ec-ee69891447bb@gmail.com>

I'll not copy all the previous material on this thread to avoid overload.

The summary is that all the methods Spencer has tried have some issues.

The bad news: This is not uncommon with optimization methods, in part because the problems are "hard",
in part because getting them implemented and linked to an interfacing approach like R is very tedious
and prone to omissions and errors.

The good news: I've been working on a revision to optimx, having noted the implementation issues just
mentioned. There is now a package optimr on CRAN, but that's just to reserve the name. The real package
is optimrx on R-forge (dependencies can fail, then the poor maintainer gets "your package doesn't work",
with no hope of fixing it). Moreover, Harry Joe recently pointed out to me a bug and in the last few
weeks I think I've resolved issues where Rvmmin and other packages got NA results when numerical gradient
approximations were used in certain ways.

optimrx came about because I realized that optimx() has just enough difference in syntax from optim()
to be a nuisance and was heavy to maintain. Also I wanted parameter scaling to work for all methods,
as in optim(). However, Ravi's efforts easily convinced me that trying multiple methods was a
good idea, so there is an opm() function. We also had an option for polyalgorithms and at one point
for multiple starts. I've put them in polyopt() and multistart() -- the combination in optimx was
driving me nuts when doing any work on the code. Ravi, I hope this doesn't offend. The optimx
ideas are still there, but the restructuring will, I hope, lead to easier maintenance and development.
As the package is very new, I fully expect there are some deficiencies, and ask that users send
executable examples so I can address same.

optimrx doesn't (yet) have nloptr. It's on the todo list, but I've not been able despite many tries to
get any response from its maintainer (Jelmer Ypma), who seems to have largely dropped out of R work, though
there was a fairly recent minor adjustment on Github. However, no communication is a
worry, as nloptr and also ipoptr are important tools that could use support. I've offered, but I don't
have C++ expertise. If anyone is willing to work with me, this can be moved forward soon.

Spencer: Can you prepare your problem in a way that the optimization bit is replaceable and send to
me? I'll see if I can figure out what is the actual source of the error as well as figure out what
methods "work" and how well.

Note that the Rtnmin package (a translation I made of my brother's Matlab code) also will handle
bounds, but optimrx probably makes the call easier. If you send the example, I'll make sure it gets
tried also.

Best, JN


From spencer.graves at prodsyse.com  Sun Oct  9 16:55:21 2016
From: spencer.graves at prodsyse.com (Spencer Graves)
Date: Sun, 9 Oct 2016 09:55:21 -0500
Subject: [Rd] optim(?, method=?L-BFGS-B?) stops with an error
In-Reply-To: <6a609ef9-79ea-d78a-83ec-ee69891447bb@gmail.com>
References: <6a609ef9-79ea-d78a-83ec-ee69891447bb@gmail.com>
Message-ID: <d749fbe1-44ef-1ac4-379e-5ff2f14e535a@prodsyse.com>



On 10/9/2016 9:00 AM, ProfJCNash wrote:
> I'll not copy all the previous material on this thread to avoid overload.
>
> The summary is that all the methods Spencer has tried have some issues.
>
> The bad news: This is not uncommon with optimization methods, in part because the problems are "hard",
> in part because getting them implemented and linked to an interfacing approach like R is very tedious
> and prone to omissions and errors.
>
> The good news: I've been working on a revision to optimx, having noted the implementation issues just
> mentioned. There is now a package optimr on CRAN, but that's just to reserve the name. The real package
> is optimrx on R-forge (dependencies can fail, then the poor maintainer gets "your package doesn't work",
> with no hope of fixing it). Moreover, Harry Joe recently pointed out to me a bug and in the last few
> weeks I think I've resolved issues where Rvmmin and other packages got NA results when numerical gradient
> approximations were used in certain ways.
>
> optimrx came about because I realized that optimx() has just enough difference in syntax from optim()
> to be a nuisance and was heavy to maintain. Also I wanted parameter scaling to work for all methods,
> as in optim(). However, Ravi's efforts easily convinced me that trying multiple methods was a
> good idea, so there is an opm() function. We also had an option for polyalgorithms and at one point
> for multiple starts. I've put them in polyopt() and multistart() -- the combination in optimx was
> driving me nuts when doing any work on the code. Ravi, I hope this doesn't offend. The optimx
> ideas are still there, but the restructuring will, I hope, lead to easier maintenance and development.
> As the package is very new, I fully expect there are some deficiencies, and ask that users send
> executable examples so I can address same.
>
> optimrx doesn't (yet) have nloptr. It's on the todo list, but I've not been able despite many tries to
> get any response from its maintainer (Jelmer Ypma), who seems to have largely dropped out of R work, though
> there was a fairly recent minor adjustment on Github. However, no communication is a
> worry, as nloptr and also ipoptr are important tools that could use support. I've offered, but I don't
> have C++ expertise. If anyone is willing to work with me, this can be moved forward soon.
>
> Spencer: Can you prepare your problem in a way that the optimization bit is replaceable and send to
> me? I'll see if I can figure out what is the actual source of the error as well as figure out what
> methods "work" and how well.


       Have you tried the following:


install.packages("Ecdat", repos="http://R-Forge.R-project.org")


       Then do "help(pac=Ecdat)" -> "User guides, package vignettes and 
other documentation" -> "Ecdat::AverageIncomeModels".


       This is a vignette that ends with one call to optim and two to 
optimx.  If you'd like to go to 
"https://r-forge.r-project.org/projects/ecdat/" and "Request to join", I 
will approve it as soon as I get the request.  Then you can edit that 
vignette directly.


       Thanks,
       Spencer
>
> Note that the Rtnmin package (a translation I made of my brother's Matlab code) also will handle
> bounds, but optimrx probably makes the call easier. If you send the example, I'll make sure it gets
> tried also.
>
> Best, JN


From ravi.varadhan at jhu.edu  Sun Oct  9 17:54:10 2016
From: ravi.varadhan at jhu.edu (Ravi Varadhan)
Date: Sun, 9 Oct 2016 15:54:10 +0000
Subject: [Rd]
 =?windows-1252?q?optim=28=85=2C_method=3D=91L-BFGS-B=92=29_s?=
 =?windows-1252?q?tops_with_an_error_message_while_violating_the_lower_bou?=
 =?windows-1252?q?nd?=
In-Reply-To: <f29714b9-98d6-3a55-d798-40decfa13461@prodsyse.com>
References: <a4515835-87f7-302d-5420-4cbf10b44fa1@prodsyse.com>
	<CAHz+bWZExjt5YGu0SaAx4bK7hvFo0QsT0NE=d-4Wuc+aFRwPMg@mail.gmail.com>,
	<f29714b9-98d6-3a55-d798-40decfa13461@prodsyse.com>
Message-ID: <1476028430471.84657@jhu.edu>

Spencer,
Another option is to try the "lbfgs" package.  Hans Werner Borchers has told me that this is a good implementation of L-BFGS.
Best,
Ravi
________________________________________
From: R-devel <r-devel-bounces at r-project.org> on behalf of Spencer Graves <spencer.graves at prodsyse.com>
Sent: Saturday, October 8, 2016 7:03 PM
To: Mark Leeds
Cc: R-devel
Subject: Re: [Rd] optim(?, method=?L-BFGS-B?) stops with an error message while violating the lower bound

Hi, Mark et al.:


       Thanks, Mark.


       Three comments:


             1.  Rvmmin was one of the methods I tried after Ravi
directed me to optimx.  It returned NAs for essentially everything. See
my email of this subject stamped 4:43 PM Central time = 21:43 UTC.


             2.  It would be interesting to know if the current
algorithm behind optim and optimx with method='L-BFGS-B' incorporates
Morales and Nocedal (2011) 'Remark on ?Algorithm 778: L-BFGS-B: Fortran
Subroutines for Large-Scale Bound Constrained Optimization?'.  I created
this vignette and started this threat hoping that someone on the R Core
team might decide it's worth checking things like that.


             3.  The vignette mentioned below was extracted from a
larger vignette fitting several models that seem to encounter
convergence problems.  I should probably switch to optimx using all the
methods that offers for constrained optimization, including nminb.


       Best Wishes,
       Spencer Graves


On 10/8/2016 5:00 PM, Mark Leeds wrote:
> Hi Spencer: See the link below about L-BFGS-B below because  I had
> problems
> with it a good while back (and I think the link description is the
> cause but I can't prove it )  so  eventually I moved to the  Rvmmin(b)
> package. It's a package but really an algorithm. Rvmmin(b) uses a
> variable-metric algorithm similar to that of L-BFGS-B but without the
> problem below. It's not surprisingly a creation of John Nash and quite
> impressive based on my experience. Just like L-BFGS, it can implement
> box constraints by adding the b.
>
> http://users.eecs.northwestern.edu/~morales/PSfiles/acm-remark.pdf
> <http://users.eecs.northwestern.edu/%7Emorales/PSfiles/acm-remark.pdf>
>
>
>
>
>
>
>
> On Sat, Oct 8, 2016 at 2:50 PM, Spencer Graves
> <spencer.graves at prodsyse.com <mailto:spencer.graves at prodsyse.com>> wrote:
>
>     Hello:
>
>
>           The development version of Ecdat on R-Forge contains a
>     vignette in which optim(?, method=?L-BFGS-B?) stops with an error
>     message while violating the lower bound.
>
>
>           To see all the details, try the following:
>
>
>     install.packages("Ecdat", repos="http://R-Forge.R-project.org
>     <http://R-Forge.R-project.org>")
>
>
>           Then do "help(pac=Ecdat)" -> "User guides, package vignettes
>     and other documentation" -> "Ecdat::AverageIncomeModels".
>
>
>           I've found other optimizers that will get around the problem
>     in this case but none that performs as well as optim with many
>     other problems.
>
>
>           Thanks,
>           Spencer Graves
>
>
>     p.s.  I've also tested bobyqa{minqa} or nloptr{nloptr},
>     recommended in a vignette in the lme4 package.  These did better
>     than optim in this example but worse in others I tried.
>
>     ______________________________________________
>     R-devel at r-project.org <mailto:R-devel at r-project.org> mailing list
>     https://stat.ethz.ch/mailman/listinfo/r-devel
>     <https://stat.ethz.ch/mailman/listinfo/r-devel>
>
>


        [[alternative HTML version deleted]]

______________________________________________
R-devel at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-devel


From maechler at stat.math.ethz.ch  Mon Oct 10 11:54:54 2016
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 10 Oct 2016 11:54:54 +0200
Subject: [Rd]
 =?utf-8?b?b3B0aW0o4oCmPz0sID0/dXRmLTg/UT9tZXRob2Q94oCYTC1C?=
 =?utf-8?q?FGS-B=E2=80=99=29_stops_with_an_error_message_while_violating_t?=
 =?utf-8?q?he_lower_bound?=
In-Reply-To: <f29714b9-98d6-3a55-d798-40decfa13461@prodsyse.com>
References: <a4515835-87f7-302d-5420-4cbf10b44fa1@prodsyse.com>
	<CAHz+bWZExjt5YGu0SaAx4bK7hvFo0QsT0NE=d-4Wuc+aFRwPMg@mail.gmail.com>
	<f29714b9-98d6-3a55-d798-40decfa13461@prodsyse.com>
Message-ID: <22523.25966.567603.28049@stat.math.ethz.ch>

>>>>> Spencer Graves <spencer.graves at prodsyse.com>
>>>>>     on Sat, 8 Oct 2016 18:03:43 -0500 writes:

[.............]

    >              2.  It would be interesting to know if the
    > current algorithm behind optim and optimx with
    > method='L-BFGS-B' incorporates Morales and Nocedal (2011)
    > 'Remark on ?Algorithm 778: L-BFGS-B: Fortran Subroutines
    > for Large-Scale Bound Constrained Optimization?'.  I
    > created this vignette and started this threat hoping that
    > someone on the R Core team might decide it's worth
    > checking things like that.

well I hope you mean "thread" rather "threat"  ;-)

I've now looked at the reference above, which is indeed quite
interesting.
	doi 10.1145/2049662.2049669
	--> http://dl.acm.org/citation.cfm?doid=2049662.2049669
A "free" (pre-publication I assume) version of the manuscript is
  http://www.eecs.northwestern.edu/~morales/PSfiles/acm-remark.pdf

The authors, Morales and Nocedal, the 2nd one being one of the
original L-BFGS-B(1997) paper, make two remarks, the 2nd one
about the "machine epsilon" used, and I can assure you that R's
optim() version never suffered from that; we've always been
using a C translation of the fortran code, and then used DBL_EPSILON.
R's (main) source file for that is in .../src/appl/lbfgsb.c, e.g., here
https://svn.r-project.org/R/trunk/src/appl/lbfgsb.c

OTOH, their remark 1 is very relevant and promising faster /
more reliable convergence. 
I'd be "happy" if optim() could gain a new option, say, "L-BFGS-B-2011"
which would incorporate what they call "modified L-BFGS-B".

However, I did not find published code to go together with their
remark.
Ideally, some of you interested in this, would provide a patch
against the above  lbfgsb.c  file

Martin Maechler,
ETH Zurich


From behamilton at google.com  Mon Oct 10 16:46:14 2016
From: behamilton at google.com (Russ Hamilton)
Date: Mon, 10 Oct 2016 10:46:14 -0400
Subject: [Rd] Bug/Inconsistency in merge() with all.x when first nonmatching
 column in y is matrix
Message-ID: <CAAG-DU0yBXa7D8mizBcHhdFW=6p7DB79DfHkh+mGnPhENS=+Qw@mail.gmail.com>

I've noticed inconsistent behavior with merge() when using all.x=TRUE.
After some digging I found the following test cases:
1) The snippet below doesn't work as expected, as the non-matching
columns of rows in a but not b take the value from the first matching
row instead of being NA:
--- Snip >>>
NUM<-25;
a <- data.frame(id=factor(letters[1:NUM]), qq=rep(NA, NUM), rr=rep(1.0,NUM))
b <- data.frame(id=c("e","a","f","y","x"))

b$mm <- as.vector(c(1,2,3.1,4.0,NA))%o%3.14
b$nn <- rep("from b", 5)

merge(a,b,by="id",all.x=TRUE)
<<< Snip ---
2) The modified snippet below works as expected:
--- Snip >>>
NUM<-25;
a <- data.frame(id=factor(letters[1:NUM]), qq=rep(NA, NUM), rr=rep(1.0,NUM))
b <- data.frame(id=c("e","a","f","y","x"))

b$nn <- rep("from b", 5)
b$mm <- as.vector(c(1,2,3.1,4.0,NA))%o%3.14

merge(a,b,by="id",all.x=TRUE)
<<< Snip ---

In src/library/base/R/merge.R:154, I see the following:
--- Snip >>>
for(i in seq_along(y)) {
## do it this way to invoke methods for e.g. factor
if(is.matrix(y[[1]])) y[[1]][zap, ] <- NA
else is.na(y[[i]]) <- zap
}
<<< Snip ---
Changing the '1's in the if statement to 'i's fixes this issue for me, i.e.:
--- Snip >>>
for(i in seq_along(y)) {
## do it this way to invoke methods for e.g. factor
if(is.matrix(y[[i]])) y[[i]][zap, ] <- NA
else is.na(y[[i]]) <- zap
}
<<< Snip ---
I'm actually not sure if the "if statement" is even needed (the "else"
case seems to handle matrices just fine).

--Russ Hamilton


From avraham.adler at gmail.com  Mon Oct 10 23:48:27 2016
From: avraham.adler at gmail.com (Avraham Adler)
Date: Mon, 10 Oct 2016 17:48:27 -0400
Subject: [Rd]
	=?utf-8?b?b3B0aW0o4oCmPz0sID0/dXRmLTg/UT9tZXRob2Q94oCYTC1C?=
	=?utf-8?q?FGS-B=E2=80=99=29_stops_with_an_error_message_while_viol?=
	=?utf-8?q?ating_the_lower_bound?=
In-Reply-To: <22523.25966.567603.28049@stat.math.ethz.ch>
References: <a4515835-87f7-302d-5420-4cbf10b44fa1@prodsyse.com>
	<CAHz+bWZExjt5YGu0SaAx4bK7hvFo0QsT0NE=d-4Wuc+aFRwPMg@mail.gmail.com>
	<f29714b9-98d6-3a55-d798-40decfa13461@prodsyse.com>
	<22523.25966.567603.28049@stat.math.ethz.ch>
Message-ID: <CAL6gwnJc909HmZOqtYr7KyVZf_=jW5g9PAH7avehoe9hYRc_Nw@mail.gmail.com>

I believe the code can be found here:
http://users.iems.northwestern.edu/~nocedal/lbfgsb.html. Specifically,
lbfgsb.f in version 3.0 starts:

This is a modified version of L-BFGS-B. Minor changes in the updated
c     code appear preceded by a line comment as follows
c
c     c-jlm-jn
c
c     Major changes are described in the accompanying paper:
c
c         Jorge Nocedal and Jose Luis Morales, Remark on "Algorithm 778:
c         L-BFGS-B: Fortran Subroutines for Large-Scale Bound Constrained
c         Optimization"  (2011). To appear in  ACM Transactions on
c         Mathematical Software,
c
c     The paper describes an improvement and a correction to Algorithm 778.
c     It is shown that the performance of the algorithm can be improved
c     significantly by making a relatively simple modication to the subspace
c     minimization phase. The correction concerns an error caused by the use
c     of routine dpmeps to estimate machine precision.


It is released under the New 3-clause BSD license, so porting it to C
for inclusion into R should be OK as long as the i's are dotted and
t's crossed.


Avi

On Mon, Oct 10, 2016 at 5:54 AM, Martin Maechler
<maechler at stat.math.ethz.ch> wrote:
>>>>>> Spencer Graves <spencer.graves at prodsyse.com>
>>>>>>     on Sat, 8 Oct 2016 18:03:43 -0500 writes:
>
> [.............]
>
>     >              2.  It would be interesting to know if the
>     > current algorithm behind optim and optimx with
>     > method='L-BFGS-B' incorporates Morales and Nocedal (2011)
>     > 'Remark on ?Algorithm 778: L-BFGS-B: Fortran Subroutines
>     > for Large-Scale Bound Constrained Optimization?'.  I
>     > created this vignette and started this threat hoping that
>     > someone on the R Core team might decide it's worth
>     > checking things like that.
>
> well I hope you mean "thread" rather "threat"  ;-)
>
> I've now looked at the reference above, which is indeed quite
> interesting.
>         doi 10.1145/2049662.2049669
>         --> http://dl.acm.org/citation.cfm?doid=2049662.2049669
> A "free" (pre-publication I assume) version of the manuscript is
>   http://www.eecs.northwestern.edu/~morales/PSfiles/acm-remark.pdf
>
> The authors, Morales and Nocedal, the 2nd one being one of the
> original L-BFGS-B(1997) paper, make two remarks, the 2nd one
> about the "machine epsilon" used, and I can assure you that R's
> optim() version never suffered from that; we've always been
> using a C translation of the fortran code, and then used DBL_EPSILON.
> R's (main) source file for that is in .../src/appl/lbfgsb.c, e.g., here
> https://svn.r-project.org/R/trunk/src/appl/lbfgsb.c
>
> OTOH, their remark 1 is very relevant and promising faster /
> more reliable convergence.
> I'd be "happy" if optim() could gain a new option, say, "L-BFGS-B-2011"
> which would incorporate what they call "modified L-BFGS-B".
>
> However, I did not find published code to go together with their
> remark.
> Ideally, some of you interested in this, would provide a patch
> against the above  lbfgsb.c  file
>
> Martin Maechler,
> ETH Zurich
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From bodenhofer at bioinf.jku.at  Tue Oct 11 08:39:33 2016
From: bodenhofer at bioinf.jku.at (Ulrich Bodenhofer)
Date: Tue, 11 Oct 2016 08:39:33 +0200
Subject: [Rd] PKG_LIBS in make child processes
Message-ID: <ca643a41-3710-5dba-de9a-a1875d22c2ad@bioinf.jku.at>

[cross-posted from bioc-devel list]

Hi all,

I have a subtle question related to how R CMD SHLIB handles variables in 
make child processes. In more detail: I am the maintainer of the 'msa' 
package which has been in Bioconductor since April 2015. This package 
integrates three open-source libraries for multiple sequence alignment. 
This is organized in the following way: in src/, there are three 
sub-directories, one for each of the libraries (plus another one for a 
garbage collector library, but that is not relevant at this point). 
src/Makevars is made such that the libraries are compiled individually 
to static libraries in their respective sub-directory, then these static 
libraries are copied to src/, and finally the static libraries are 
integrated into msa.so. The Makevars file looks as follows:

     PKG_LIBS=`${R_HOME}/bin${R_ARCH_BIN}/Rscript -e "if
     (Sys.info()['sysname'] == 'Darwin') cat('-Wl,-all_load ./libgc.a
     ./libClustalW.a ./libClustalOmega.a ./libMuscle.a') else
     cat('-Wl,--whole-archive ./libgc.a ./libClustalW.a
     ./libClustalOmega.a ./libMuscle.a  -Wl,--no-whole-archive')"`
     PKG_CXXFLAGS=-I"./gc-7.2/include" -I"./Muscle/" -I"./ClustalW/src"
     -I"./ClustalOmega/src"

     .PHONY: all mylibs

     all: $(SHLIB)
     $(SHLIB): mylibs

     mylibs: build_gc build_muscle build_clustalw build_clustalomega

     build_gc:
          make --file=msaMakefile --directory=gc-7.2
          @echo "----------------------------------------"
          @echo "------------------ GC  -----------------"
          @echo "----------------------------------------"
          @echo "--------- Compilation finished ---------"
          @echo "----------------------------------------"

     build_muscle:
          make --file=msaMakefile --directory=Muscle
          @echo "----------------------------------------"
          @echo "---------------- MUSCLE ----------------"
          @echo "----------------------------------------"
          @echo "--------- Compilation finished ---------"
          @echo "----------------------------------------"

     build_clustalw:
          make --file=msaMakefile --directory=ClustalW
          @echo "----------------------------------------"
          @echo "--------------- ClustalW ---------------"
          @echo "----------------------------------------"
          @echo "--------- Compilation finished ---------"
          @echo "----------------------------------------"

     build_clustalomega:
          make --file=msaMakefile --directory=ClustalOmega
          @echo "----------------------------------------"
          @echo "------------- ClustalOmega -------------"
          @echo "----------------------------------------"
          @echo "--------- Compilation finished ---------"
          @echo "----------------------------------------"

This has always worked on Linux and Mac OS so far. Now I have received 
an error report from a user who cannot install the package on a 64-bit 
openSUSE 13.1 system using R 3.3.1. It turned out that R CMD SHLIB as 
called in the make child processes (make target 'build_muscle' above) 
uses the value of PKG_LIBS defined in the first line of the top-level 
Makevars file shown above (which of course does not work and makes no 
sense), while this does not happen on any other Unix-like system I have 
tried so far (Ubuntu, CentOS, Mac OS). Maybe somebody can shed some 
light on how variables defined inside the Makevars file propagate to 
child processes. Thanks so much in advance!

Best regards,
Ulrich


From lukas.stadler at oracle.com  Wed Oct 12 10:37:18 2016
From: lukas.stadler at oracle.com (Lukas Stadler)
Date: Wed, 12 Oct 2016 10:37:18 +0200
Subject: [Rd] integerOneIndex/get1index/... in vector access error messages
Message-ID: <86CA0E2F-87F5-47AB-8633-2F06649D2DC8@oracle.com>

Hi!

We noticed that these error messages were changed to include the name of the function that causes them:
> { x<-c(1,2); x[[c("a", "b")]] }
old: ?Error in x[[c("a", "b")]] : attempt to select more than one element?
new: ?Error in x[[c("a", "b")]] : attempt to select more than one element in vectorIndex?

This is the relevant change:
https://github.com/wch/r-source/commit/5d6c765bf8b97bf872f760d06622850f43696d8b

I don?t think that a user of R is supposed to know the difference between, e.g., integerOneIndex and get1index, so this will confuse, rather than help, a user while diagnosing problems.
To be honest, this looks to me like leftover debug code...

In FastR, we try to adhere as closely as possible to GNUR in which errors are returned when.
Do you think that providing these ?in Xyz? suffixes is important?

- Lukas

From henrik.bengtsson at gmail.com  Wed Oct 12 18:20:53 2016
From: henrik.bengtsson at gmail.com (Henrik Bengtsson)
Date: Wed, 12 Oct 2016 09:20:53 -0700
Subject: [Rd] How to assign NULL value to pairlist element while keeping it
	a pairlist?
Message-ID: <CAFDcVCQEA8Q7Zec6m3mF4PY4mL=VJOihGtXRbKiPq98hKMfY2A@mail.gmail.com>

Hi, I seem to not be able to assign NULL to an element of a pairlist
without causing it to be coerced to a plain list.  For example:

> x <- pairlist(1, 2)
> class(x)
[1] "pairlist"

> x[1] <- list(NULL)
> class(x)
[1] "list"

This actually true for all [()<- assignments regardless of list value, e.g.

> x <- pairlist(1, 2)
> x[1] <- list(0)
[1] "list"

I also tried assigning a pairlist(), but still the same problem:

> x <- pairlist(1, 2)
> x[1] <- pairlist(0)
[1] "list"

The only workaround I'm aware of is to:

x <- as.pairlist(x)

at the end.  Any other suggestions?

Thanks,

Henrik


From lawrence.michael at gene.com  Wed Oct 12 18:40:53 2016
From: lawrence.michael at gene.com (Michael Lawrence)
Date: Wed, 12 Oct 2016 09:40:53 -0700
Subject: [Rd] How to assign NULL value to pairlist element while keeping
 it a pairlist?
In-Reply-To: <CAFDcVCQEA8Q7Zec6m3mF4PY4mL=VJOihGtXRbKiPq98hKMfY2A@mail.gmail.com>
References: <CAFDcVCQEA8Q7Zec6m3mF4PY4mL=VJOihGtXRbKiPq98hKMfY2A@mail.gmail.com>
Message-ID: <CAOQ5NyeBDy-jAC2-u4TB_CbFtjS4z11dzVuV5_ZmhU11BCwETg@mail.gmail.com>

The coercion is probably the most viable workaround for now, as it's
consistent with what happens internally for calls. All pairlists/calls
are converted to list for subassignment, but only calls are converted
back. My guess is that the intent was for users to move from using a
pairlist to the "new" (almost 20 years ago) list. In my opinion,
consistency trumps "convenience" in this case. If others agree, I'll
change it to also coerce back to pairlist.

Michael

On Wed, Oct 12, 2016 at 9:20 AM, Henrik Bengtsson
<henrik.bengtsson at gmail.com> wrote:
> Hi, I seem to not be able to assign NULL to an element of a pairlist
> without causing it to be coerced to a plain list.  For example:
>
>> x <- pairlist(1, 2)
>> class(x)
> [1] "pairlist"
>
>> x[1] <- list(NULL)
>> class(x)
> [1] "list"
>
> This actually true for all [()<- assignments regardless of list value, e.g.
>
>> x <- pairlist(1, 2)
>> x[1] <- list(0)
> [1] "list"
>
> I also tried assigning a pairlist(), but still the same problem:
>
>> x <- pairlist(1, 2)
>> x[1] <- pairlist(0)
> [1] "list"
>
> The only workaround I'm aware of is to:
>
> x <- as.pairlist(x)
>
> at the end.  Any other suggestions?
>
> Thanks,
>
> Henrik
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From lawrence.michael at gene.com  Wed Oct 12 19:53:45 2016
From: lawrence.michael at gene.com (Michael Lawrence)
Date: Wed, 12 Oct 2016 10:53:45 -0700
Subject: [Rd] How to assign NULL value to pairlist element while keeping
 it a pairlist?
In-Reply-To: <CAOQ5NyeBDy-jAC2-u4TB_CbFtjS4z11dzVuV5_ZmhU11BCwETg@mail.gmail.com>
References: <CAFDcVCQEA8Q7Zec6m3mF4PY4mL=VJOihGtXRbKiPq98hKMfY2A@mail.gmail.com>
	<CAOQ5NyeBDy-jAC2-u4TB_CbFtjS4z11dzVuV5_ZmhU11BCwETg@mail.gmail.com>
Message-ID: <CAOQ5NyfOshFmNp1nQ9Kc7VME2WgqEmJa42Y7m6GRjwsE9=nhTg@mail.gmail.com>

Hi Henrik,

It would help to understand your use case for pairlists.

Thanks,
Michael

On Wed, Oct 12, 2016 at 9:40 AM, Michael Lawrence <michafla at gene.com> wrote:
> The coercion is probably the most viable workaround for now, as it's
> consistent with what happens internally for calls. All pairlists/calls
> are converted to list for subassignment, but only calls are converted
> back. My guess is that the intent was for users to move from using a
> pairlist to the "new" (almost 20 years ago) list. In my opinion,
> consistency trumps "convenience" in this case. If others agree, I'll
> change it to also coerce back to pairlist.
>
> Michael
>
> On Wed, Oct 12, 2016 at 9:20 AM, Henrik Bengtsson
> <henrik.bengtsson at gmail.com> wrote:
>> Hi, I seem to not be able to assign NULL to an element of a pairlist
>> without causing it to be coerced to a plain list.  For example:
>>
>>> x <- pairlist(1, 2)
>>> class(x)
>> [1] "pairlist"
>>
>>> x[1] <- list(NULL)
>>> class(x)
>> [1] "list"
>>
>> This actually true for all [()<- assignments regardless of list value, e.g.
>>
>>> x <- pairlist(1, 2)
>>> x[1] <- list(0)
>> [1] "list"
>>
>> I also tried assigning a pairlist(), but still the same problem:
>>
>>> x <- pairlist(1, 2)
>>> x[1] <- pairlist(0)
>> [1] "list"
>>
>> The only workaround I'm aware of is to:
>>
>> x <- as.pairlist(x)
>>
>> at the end.  Any other suggestions?
>>
>> Thanks,
>>
>> Henrik
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel


From henrik.bengtsson at gmail.com  Wed Oct 12 21:31:25 2016
From: henrik.bengtsson at gmail.com (Henrik Bengtsson)
Date: Wed, 12 Oct 2016 12:31:25 -0700
Subject: [Rd] How to assign NULL value to pairlist element while keeping
 it a pairlist?
In-Reply-To: <CAOQ5NyfOshFmNp1nQ9Kc7VME2WgqEmJa42Y7m6GRjwsE9=nhTg@mail.gmail.com>
References: <CAFDcVCQEA8Q7Zec6m3mF4PY4mL=VJOihGtXRbKiPq98hKMfY2A@mail.gmail.com>
	<CAOQ5NyeBDy-jAC2-u4TB_CbFtjS4z11dzVuV5_ZmhU11BCwETg@mail.gmail.com>
	<CAOQ5NyfOshFmNp1nQ9Kc7VME2WgqEmJa42Y7m6GRjwsE9=nhTg@mail.gmail.com>
Message-ID: <CAFDcVCQ3bKCE9DqH9XVQYZOWpKxmaOO7u-NnmDjC3FU_b7pFdg@mail.gmail.com>

Michael, thanks for this info.

I've stumbled upon this in a case where I walk an R expression (the
AST) and (optionally) modifies it (part of the globals package).  In R
expressions, a function definition uses a pairlist to represent the
arguments.  For example,

> expr <- quote(function(x = 1) x)
> str(as.list(expr))
List of 4
 $ : symbol function
 $ :Dotted pair list of 1
  ..$ x: num 1
 $ : symbol x
 $ :Class 'srcref'  atomic [1:8] 1 15 1 29 15 29 1 1
.. ..- attr(*, "srcfile")=Classes 'srcfilecopy', 'srcfile'
<environment: 0x13918b8>

Here the 2nd element is a pairlist:

> str(expr[[2]])
Dotted pair list of 1
 $ x: num 1
> typeof(expr[[2]])
[1] "pairlist"

Now say that I want to update the default value of argument 'x', which
is currently 1, to NULL.  Then I do:

> expr[[2]][1] <- list(x = NULL)

At this step, I end up with an expression 'expr' where the arguments
are no longer represented by a pairlist:

> str(expr[[2]])
List of 1
 $ x: NULL
> typeof(expr[[2]])
[1] "list"

More importantly, at this point 'expr' no longer holds a valid R expression:

> expr
Error: badly formed function expression

The solution is to make sure we have a pairlist:

> expr[[2]] <- as.pairlist(expr[[2]])
> expr
function(x = NULL) x


I agree it would be nice to fix this for consistency, but if you bump
into major issues, at least I can live with having to use an explicit
as.pairlist().

Thanks

Henrik

On Wed, Oct 12, 2016 at 10:53 AM, Michael Lawrence
<lawrence.michael at gene.com> wrote:
> Hi Henrik,
>
> It would help to understand your use case for pairlists.
>
> Thanks,
> Michael
>
> On Wed, Oct 12, 2016 at 9:40 AM, Michael Lawrence <michafla at gene.com> wrote:
>> The coercion is probably the most viable workaround for now, as it's
>> consistent with what happens internally for calls. All pairlists/calls
>> are converted to list for subassignment, but only calls are converted
>> back. My guess is that the intent was for users to move from using a
>> pairlist to the "new" (almost 20 years ago) list. In my opinion,
>> consistency trumps "convenience" in this case. If others agree, I'll
>> change it to also coerce back to pairlist.
>>
>> Michael
>>
>> On Wed, Oct 12, 2016 at 9:20 AM, Henrik Bengtsson
>> <henrik.bengtsson at gmail.com> wrote:
>>> Hi, I seem to not be able to assign NULL to an element of a pairlist
>>> without causing it to be coerced to a plain list.  For example:
>>>
>>>> x <- pairlist(1, 2)
>>>> class(x)
>>> [1] "pairlist"
>>>
>>>> x[1] <- list(NULL)
>>>> class(x)
>>> [1] "list"
>>>
>>> This actually true for all [()<- assignments regardless of list value, e.g.
>>>
>>>> x <- pairlist(1, 2)
>>>> x[1] <- list(0)
>>> [1] "list"
>>>
>>> I also tried assigning a pairlist(), but still the same problem:
>>>
>>>> x <- pairlist(1, 2)
>>>> x[1] <- pairlist(0)
>>> [1] "list"
>>>
>>> The only workaround I'm aware of is to:
>>>
>>> x <- as.pairlist(x)
>>>
>>> at the end.  Any other suggestions?
>>>
>>> Thanks,
>>>
>>> Henrik
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel


From lawrence.michael at gene.com  Thu Oct 13 00:21:13 2016
From: lawrence.michael at gene.com (Michael Lawrence)
Date: Wed, 12 Oct 2016 15:21:13 -0700
Subject: [Rd] How to assign NULL value to pairlist element while keeping
 it a pairlist?
In-Reply-To: <CAFDcVCQ3bKCE9DqH9XVQYZOWpKxmaOO7u-NnmDjC3FU_b7pFdg@mail.gmail.com>
References: <CAFDcVCQEA8Q7Zec6m3mF4PY4mL=VJOihGtXRbKiPq98hKMfY2A@mail.gmail.com>
	<CAOQ5NyeBDy-jAC2-u4TB_CbFtjS4z11dzVuV5_ZmhU11BCwETg@mail.gmail.com>
	<CAOQ5NyfOshFmNp1nQ9Kc7VME2WgqEmJa42Y7m6GRjwsE9=nhTg@mail.gmail.com>
	<CAFDcVCQ3bKCE9DqH9XVQYZOWpKxmaOO7u-NnmDjC3FU_b7pFdg@mail.gmail.com>
Message-ID: <CAOQ5NydLhK2mJ_rQfg103qkoG0V=GGiGm461UfSZEBqjrB=fZw@mail.gmail.com>

Thanks, this was what I expected. There is a desire to eliminate the
usage of pairlist from user code, which suggests the alternative of
allowing for function arguments to be stored in lists. That's a much
deeper change though.

On Wed, Oct 12, 2016 at 12:31 PM, Henrik Bengtsson
<henrik.bengtsson at gmail.com> wrote:
> Michael, thanks for this info.
>
> I've stumbled upon this in a case where I walk an R expression (the
> AST) and (optionally) modifies it (part of the globals package).  In R
> expressions, a function definition uses a pairlist to represent the
> arguments.  For example,
>
>> expr <- quote(function(x = 1) x)
>> str(as.list(expr))
> List of 4
>  $ : symbol function
>  $ :Dotted pair list of 1
>   ..$ x: num 1
>  $ : symbol x
>  $ :Class 'srcref'  atomic [1:8] 1 15 1 29 15 29 1 1
> .. ..- attr(*, "srcfile")=Classes 'srcfilecopy', 'srcfile'
> <environment: 0x13918b8>
>
> Here the 2nd element is a pairlist:
>
>> str(expr[[2]])
> Dotted pair list of 1
>  $ x: num 1
>> typeof(expr[[2]])
> [1] "pairlist"
>
> Now say that I want to update the default value of argument 'x', which
> is currently 1, to NULL.  Then I do:
>
>> expr[[2]][1] <- list(x = NULL)
>
> At this step, I end up with an expression 'expr' where the arguments
> are no longer represented by a pairlist:
>
>> str(expr[[2]])
> List of 1
>  $ x: NULL
>> typeof(expr[[2]])
> [1] "list"
>
> More importantly, at this point 'expr' no longer holds a valid R expression:
>
>> expr
> Error: badly formed function expression
>
> The solution is to make sure we have a pairlist:
>
>> expr[[2]] <- as.pairlist(expr[[2]])
>> expr
> function(x = NULL) x
>
>
> I agree it would be nice to fix this for consistency, but if you bump
> into major issues, at least I can live with having to use an explicit
> as.pairlist().
>
> Thanks
>
> Henrik
>
> On Wed, Oct 12, 2016 at 10:53 AM, Michael Lawrence
> <lawrence.michael at gene.com> wrote:
>> Hi Henrik,
>>
>> It would help to understand your use case for pairlists.
>>
>> Thanks,
>> Michael
>>
>> On Wed, Oct 12, 2016 at 9:40 AM, Michael Lawrence <michafla at gene.com> wrote:
>>> The coercion is probably the most viable workaround for now, as it's
>>> consistent with what happens internally for calls. All pairlists/calls
>>> are converted to list for subassignment, but only calls are converted
>>> back. My guess is that the intent was for users to move from using a
>>> pairlist to the "new" (almost 20 years ago) list. In my opinion,
>>> consistency trumps "convenience" in this case. If others agree, I'll
>>> change it to also coerce back to pairlist.
>>>
>>> Michael
>>>
>>> On Wed, Oct 12, 2016 at 9:20 AM, Henrik Bengtsson
>>> <henrik.bengtsson at gmail.com> wrote:
>>>> Hi, I seem to not be able to assign NULL to an element of a pairlist
>>>> without causing it to be coerced to a plain list.  For example:
>>>>
>>>>> x <- pairlist(1, 2)
>>>>> class(x)
>>>> [1] "pairlist"
>>>>
>>>>> x[1] <- list(NULL)
>>>>> class(x)
>>>> [1] "list"
>>>>
>>>> This actually true for all [()<- assignments regardless of list value, e.g.
>>>>
>>>>> x <- pairlist(1, 2)
>>>>> x[1] <- list(0)
>>>> [1] "list"
>>>>
>>>> I also tried assigning a pairlist(), but still the same problem:
>>>>
>>>>> x <- pairlist(1, 2)
>>>>> x[1] <- pairlist(0)
>>>> [1] "list"
>>>>
>>>> The only workaround I'm aware of is to:
>>>>
>>>> x <- as.pairlist(x)
>>>>
>>>> at the end.  Any other suggestions?
>>>>
>>>> Thanks,
>>>>
>>>> Henrik
>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel


From maechler at stat.math.ethz.ch  Sat Oct 15 11:00:00 2016
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Sat, 15 Oct 2016 11:00:00 +0200
Subject: [Rd] How to assign NULL value to pairlist element while keeping
 it a pairlist?
In-Reply-To: <CAOQ5NydLhK2mJ_rQfg103qkoG0V=GGiGm461UfSZEBqjrB=fZw@mail.gmail.com>
References: <CAFDcVCQEA8Q7Zec6m3mF4PY4mL=VJOihGtXRbKiPq98hKMfY2A@mail.gmail.com>
	<CAOQ5NyeBDy-jAC2-u4TB_CbFtjS4z11dzVuV5_ZmhU11BCwETg@mail.gmail.com>
	<CAOQ5NyfOshFmNp1nQ9Kc7VME2WgqEmJa42Y7m6GRjwsE9=nhTg@mail.gmail.com>
	<CAFDcVCQ3bKCE9DqH9XVQYZOWpKxmaOO7u-NnmDjC3FU_b7pFdg@mail.gmail.com>
	<CAOQ5NydLhK2mJ_rQfg103qkoG0V=GGiGm461UfSZEBqjrB=fZw@mail.gmail.com>
Message-ID: <22529.61456.824573.56016@stat.math.ethz.ch>

>>>>> Michael Lawrence <lawrence.michael at gene.com>
>>>>>     on Wed, 12 Oct 2016 15:21:13 -0700 writes:

    > Thanks, this was what I expected. There is a desire to
    > eliminate the usage of pairlist from user code, which
    > suggests the alternative of allowing for function
    > arguments to be stored in lists. That's a much deeper
    > change though.

and I hope we would not go there just for the purpose of
eliminating pairlists from user code, would we ?

As nobody else has mentioned it, I'd really  like to mention the
two (actually 3) functions important for dealing with function
argument lists much more transparently than the
as.list(<function>) things below:

  formals(<f>)
  formals(<f>) <- <arglist>      #  and
  alist()

for creating / modifying function argument lists (which are
pairlists, but the user does not need to know really).
Or did you imply, Henrik, that would you want is not achievable
with these?

Martin

    > On Wed, Oct 12, 2016 at 12:31 PM, Henrik Bengtsson
    > <henrik.bengtsson at gmail.com> wrote:
    >> Michael, thanks for this info.
    >> 
    >> I've stumbled upon this in a case where I walk an R expression (the
    >> AST) and (optionally) modifies it (part of the globals package).  In R
    >> expressions, a function definition uses a pairlist to represent the
    >> arguments.  For example,
    >> 
    >>> expr <- quote(function(x = 1) x)
    >>> str(as.list(expr))
    >> List of 4
    >> $ : symbol function
    >> $ :Dotted pair list of 1
    >> ..$ x: num 1
    >> $ : symbol x
    >> $ :Class 'srcref'  atomic [1:8] 1 15 1 29 15 29 1 1
    >> .. ..- attr(*, "srcfile")=Classes 'srcfilecopy', 'srcfile'
    >> <environment: 0x13918b8>
    >> 
    >> Here the 2nd element is a pairlist:
    >> 
    >>> str(expr[[2]])
    >> Dotted pair list of 1
    >> $ x: num 1
    >>> typeof(expr[[2]])
    >> [1] "pairlist"
    >> 
    >> Now say that I want to update the default value of argument 'x', which
    >> is currently 1, to NULL.  Then I do:
    >> 
    >>> expr[[2]][1] <- list(x = NULL)
    >> 
    >> At this step, I end up with an expression 'expr' where the arguments
    >> are no longer represented by a pairlist:
    >> 
    >>> str(expr[[2]])
    >> List of 1
    >> $ x: NULL
    >>> typeof(expr[[2]])
    >> [1] "list"
    >> 
    >> More importantly, at this point 'expr' no longer holds a valid R expression:
    >> 
    >>> expr
    >> Error: badly formed function expression
    >> 
    >> The solution is to make sure we have a pairlist:
    >> 
    >>> expr[[2]] <- as.pairlist(expr[[2]])
    >>> expr
    >> function(x = NULL) x
    >> 
    >> 
    >> I agree it would be nice to fix this for consistency, but if you bump
    >> into major issues, at least I can live with having to use an explicit
    >> as.pairlist().
    >> 
    >> Thanks
    >> 
    >> Henrik
    >> 
    >> On Wed, Oct 12, 2016 at 10:53 AM, Michael Lawrence
    >> <lawrence.michael at gene.com> wrote:
    >>> Hi Henrik,
    >>> 
    >>> It would help to understand your use case for pairlists.
    >>> 
    >>> Thanks,
    >>> Michael
    >>> 
    >>> On Wed, Oct 12, 2016 at 9:40 AM, Michael Lawrence <michafla at gene.com> wrote:
    >>>> The coercion is probably the most viable workaround for now, as it's
    >>>> consistent with what happens internally for calls. All pairlists/calls
    >>>> are converted to list for subassignment, but only calls are converted
    >>>> back. My guess is that the intent was for users to move from using a
    >>>> pairlist to the "new" (almost 20 years ago) list. In my opinion,
    >>>> consistency trumps "convenience" in this case. If others agree, I'll
    >>>> change it to also coerce back to pairlist.
    >>>> 
    >>>> Michael
    >>>> 
    >>>> On Wed, Oct 12, 2016 at 9:20 AM, Henrik Bengtsson
    >>>> <henrik.bengtsson at gmail.com> wrote:
    >>>>> Hi, I seem to not be able to assign NULL to an element of a pairlist
    >>>>> without causing it to be coerced to a plain list.  For example:
    >>>>> 
>>>>> x <- pairlist(1, 2)
>>>>> class(x)
    >>>>> [1] "pairlist"
    >>>>> 
>>>>> x[1] <- list(NULL)
>>>>> class(x)
    >>>>> [1] "list"
    >>>>> 
    >>>>> This actually true for all [()<- assignments regardless of list value, e.g.
    >>>>> 
>>>>> x <- pairlist(1, 2)
>>>>> x[1] <- list(0)
    >>>>> [1] "list"
    >>>>> 
    >>>>> I also tried assigning a pairlist(), but still the same problem:
    >>>>> 
>>>>> x <- pairlist(1, 2)
>>>>> x[1] <- pairlist(0)
    >>>>> [1] "list"
    >>>>> 
    >>>>> The only workaround I'm aware of is to:
    >>>>> 
    >>>>> x <- as.pairlist(x)
    >>>>> 
    >>>>> at the end.  Any other suggestions?
    >>>>> 
    >>>>> Thanks,
    >>>>> 
    >>>>> Henrik
    >>>>> 
    >>>>> ______________________________________________
    >>>>> R-devel at r-project.org mailing list
    >>>>> https://stat.ethz.ch/mailman/listinfo/r-devel

    > ______________________________________________
    > R-devel at r-project.org mailing list
    > https://stat.ethz.ch/mailman/listinfo/r-devel


From kindlychung at gmail.com  Sat Oct 15 11:48:31 2016
From: kindlychung at gmail.com (Kaiyin Zhong)
Date: Sat, 15 Oct 2016 11:48:31 +0200
Subject: [Rd] Inconsistent behavior of summary
Message-ID: <CAOHtMfWg2ayM0XFma3kxuiJ_Uz1WjW4XfSQ_y=P4jtqo0WcbBQ@mail.gmail.com>

Here is the code:

summary(c(1:5, NA))
summary(c("a", NA))

It seems in the firs case the number of NAs is reported, but not in the
second.

Tested with R 3.3.1 on a mac.


Best regards,

Kaiyin ZHONG

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Sat Oct 15 12:41:08 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 15 Oct 2016 06:41:08 -0400
Subject: [Rd] Inconsistent behavior of summary
In-Reply-To: <CAOHtMfWg2ayM0XFma3kxuiJ_Uz1WjW4XfSQ_y=P4jtqo0WcbBQ@mail.gmail.com>
References: <CAOHtMfWg2ayM0XFma3kxuiJ_Uz1WjW4XfSQ_y=P4jtqo0WcbBQ@mail.gmail.com>
Message-ID: <c7d13f14-74ca-c841-0b82-743a9dc3a609@gmail.com>

On 15/10/2016 5:48 AM, Kaiyin Zhong wrote:
> Here is the code:
>
> summary(c(1:5, NA))
> summary(c("a", NA))
>
> It seems in the firs case the number of NAs is reported, but not in the
> second.
>
> Tested with R 3.3.1 on a mac.

summary() is a generic function, so the output depends on the class of 
the input.  There's no special method for character vectors, so you get 
the default output.  Numeric vectors show more detail.

If you want a particular behaviour for character objects, just write a 
summary.character method.

Here's the default:

 > summary(c("a", NA))
    Length     Class      Mode
         2 character character

Here's a method and example using it:

 > summary.character <- function (x, ...) { cat("this character vector 
has", sum(is.na(x)), " NA value(s)\n")}

 > summary(c("a", NA))
this character vector has 1  NA value(s)

Duncan Murdoch


From zhengda1936 at gmail.com  Sun Oct 16 15:46:49 2016
From: zhengda1936 at gmail.com (Da Zheng)
Date: Sun, 16 Oct 2016 09:46:49 -0400
Subject: [Rd] compile c++ code in an R package without -g
Message-ID: <CAFLer81sYXPQ8rkKj3+uXd8gXTfGHkmBUqP=3feCGE2rzvFXcQ@mail.gmail.com>

Hello,

I'm writing an R package that is mainly written in C++. By default, R
CMD INSTALL creates C/C++ flags as follows:
-g -O2 -fstack-protector --param=ssp-buffer-size=4 -Wformat
-Werror=format-security -D_FORTIFY_SOURCE=2 -g

However, my package is fairly large. With debug info compiled into the
library, the generated .so file is over 200MB. Without debug info,
it's about 30MB. I hope by default debug info is disabled. However, I
don't see any option in R CMD INSTALL that can disable "-g". Could
anyone tell me how to disable it?

Many thanks,
Da


From edd at debian.org  Sun Oct 16 16:09:20 2016
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sun, 16 Oct 2016 09:09:20 -0500
Subject: [Rd] compile c++ code in an R package without -g
In-Reply-To: <CAFLer81sYXPQ8rkKj3+uXd8gXTfGHkmBUqP=3feCGE2rzvFXcQ@mail.gmail.com>
References: <CAFLer81sYXPQ8rkKj3+uXd8gXTfGHkmBUqP=3feCGE2rzvFXcQ@mail.gmail.com>
Message-ID: <22531.35344.355506.984934@max.nulle.part>


On 16 October 2016 at 09:46, Da Zheng wrote:
| I'm writing an R package that is mainly written in C++. By default, R
| CMD INSTALL creates C/C++ flags as follows:
| -g -O2 -fstack-protector --param=ssp-buffer-size=4 -Wformat
| -Werror=format-security -D_FORTIFY_SOURCE=2 -g

That looks like you are running R on a Debian or Ubuntu system as these are
the compilation defaults we set everywhere, and which my r-base-core package
has via the same defaults.

That is also where the `-g` comes from.  By default we compile everything
with debugging, and (these days) strip debug symbols away in a -dbg package.

I.e. if you wanted to use gdb to analyse R you could without recompilation by
just installing the r-base-core-dbg package.  That is a nice feature.

| However, my package is fairly large. With debug info compiled into the
| library, the generated .so file is over 200MB. Without debug info,
| it's about 30MB. I hope by default debug info is disabled.

You cannot, currently.

The values in Makeconf (for us in /etc/R/Makeconf) cannot be edited before `R
CMD INSTALL` et al use them.  That is a pity, but such is life.  We had prior
discussions about this here; and at least Simon chimed in once and confirmed.

| However, I don't see any option in R CMD INSTALL that can disable
| "-g". Could  anyone tell me how to disable it?

You cannot, currently.

There are a few ways out:

  i)  Quick local fix: Edit /etc/R/Makeconf. Obviously not portable.

 ii)  Rebuild R without -g in the configure flags. Ditto.

iii)  Do something in src/Makevars to strip after the build.  May be
      flagged as non-portable by CRAN but at least it tries.

 iv)  (Lot of work, potentially) Patch the R build system to allow, say,
      sed filtering of some of the values in Makeconf. Get the patch
      included. 

Hope this helps,  Dirk

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From zhengda1936 at gmail.com  Sun Oct 16 16:52:40 2016
From: zhengda1936 at gmail.com (Da Zheng)
Date: Sun, 16 Oct 2016 10:52:40 -0400
Subject: [Rd] compile c++ code in an R package without -g
In-Reply-To: <22531.35344.355506.984934@max.nulle.part>
References: <CAFLer81sYXPQ8rkKj3+uXd8gXTfGHkmBUqP=3feCGE2rzvFXcQ@mail.gmail.com>
	<22531.35344.355506.984934@max.nulle.part>
Message-ID: <CAFLer81kpd6_E4Lu=kYTvrYgzMpaHTQP3kg-vDot8B09o_4b1g@mail.gmail.com>

Hello Dirk,

Thank you very much for your reply.

The main reason I want to remove the debug info is that when I use R
CMD check on my package, it gives the following info
* checking installed package size ... NOTE
  installed size is 223.6Mb
  sub-directories of 1Mb or more:
  libs 223.1Mb

CRAN requires an R package to pass all checks and fix all complaints
including NOTEs.
It seems R's default compilation options significantly increase the
library size.
Do you have any suggestions on fixing this NOTE?

Thanks,
Da

On Sun, Oct 16, 2016 at 10:09 AM, Dirk Eddelbuettel <edd at debian.org> wrote:
>
> On 16 October 2016 at 09:46, Da Zheng wrote:
> | I'm writing an R package that is mainly written in C++. By default, R
> | CMD INSTALL creates C/C++ flags as follows:
> | -g -O2 -fstack-protector --param=ssp-buffer-size=4 -Wformat
> | -Werror=format-security -D_FORTIFY_SOURCE=2 -g
>
> That looks like you are running R on a Debian or Ubuntu system as these are
> the compilation defaults we set everywhere, and which my r-base-core package
> has via the same defaults.
>
> That is also where the `-g` comes from.  By default we compile everything
> with debugging, and (these days) strip debug symbols away in a -dbg package.
>
> I.e. if you wanted to use gdb to analyse R you could without recompilation by
> just installing the r-base-core-dbg package.  That is a nice feature.
>
> | However, my package is fairly large. With debug info compiled into the
> | library, the generated .so file is over 200MB. Without debug info,
> | it's about 30MB. I hope by default debug info is disabled.
>
> You cannot, currently.
>
> The values in Makeconf (for us in /etc/R/Makeconf) cannot be edited before `R
> CMD INSTALL` et al use them.  That is a pity, but such is life.  We had prior
> discussions about this here; and at least Simon chimed in once and confirmed.
>
> | However, I don't see any option in R CMD INSTALL that can disable
> | "-g". Could  anyone tell me how to disable it?
>
> You cannot, currently.
>
> There are a few ways out:
>
>   i)  Quick local fix: Edit /etc/R/Makeconf. Obviously not portable.
>
>  ii)  Rebuild R without -g in the configure flags. Ditto.
>
> iii)  Do something in src/Makevars to strip after the build.  May be
>       flagged as non-portable by CRAN but at least it tries.
>
>  iv)  (Lot of work, potentially) Patch the R build system to allow, say,
>       sed filtering of some of the values in Makeconf. Get the patch
>       included.
>
> Hope this helps,  Dirk
>
> --
> http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From edd at debian.org  Sun Oct 16 17:42:55 2016
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sun, 16 Oct 2016 10:42:55 -0500
Subject: [Rd] compile c++ code in an R package without -g
In-Reply-To: <CAFLer81kpd6_E4Lu=kYTvrYgzMpaHTQP3kg-vDot8B09o_4b1g@mail.gmail.com>
References: <CAFLer81sYXPQ8rkKj3+uXd8gXTfGHkmBUqP=3feCGE2rzvFXcQ@mail.gmail.com>
	<22531.35344.355506.984934@max.nulle.part>
	<CAFLer81kpd6_E4Lu=kYTvrYgzMpaHTQP3kg-vDot8B09o_4b1g@mail.gmail.com>
Message-ID: <22531.40959.267272.690340@max.nulle.part>


On 16 October 2016 at 10:52, Da Zheng wrote:
| The main reason I want to remove the debug info is that when I use R
| CMD check on my package, it gives the following info
| * checking installed package size ... NOTE
|   installed size is 223.6Mb
|   sub-directories of 1Mb or more:
|   libs 223.1Mb
| 
| CRAN requires an R package to pass all checks and fix all complaints
| including NOTEs.
| It seems R's default compilation options significantly increase the
| library size.
| Do you have any suggestions on fixing this NOTE?

As I tried to say to in my first reply, 'we know'.

I am somewhat involved with a number of packages using C++ (and sometimes
lots of it) and almost all of which trigger this NOTE.

There are several additional points here:

  i)   'R CMD check' really needs a white-listing facility. By permanently
       listing 'known and tolerated' features it downgrades the value in
       the 'reports' files off CRAN -- as I know beforehand Rcpp et all will
       tickle this.

       Then again, someone would need to step up, work with CRAN and implement
       a white-listing facility.

 ii)   You can hack a 'strip' facility into the package.  A friend and (now
       former) colleague did so in a package but I don't have the reference
       handy.  In essence, src/Makevars figures out if the host in 'amenable
       to this' (ie is not Solaris) and then strips

iii)   In the narrowest sense, just relax and mention the NOTE when you
       upload the packages. NOTES are tolerated, WARNINGS and ERRORS are more
       serious.

Dirk

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From simonyansenzhao at gmail.com  Mon Oct 17 04:14:44 2016
From: simonyansenzhao at gmail.com (Simon)
Date: Mon, 17 Oct 2016 10:14:44 +0800
Subject: [Rd] compile c++ code in an R package without -g
In-Reply-To: <CAFLer81sYXPQ8rkKj3+uXd8gXTfGHkmBUqP=3feCGE2rzvFXcQ@mail.gmail.com>
References: <CAFLer81sYXPQ8rkKj3+uXd8gXTfGHkmBUqP=3feCGE2rzvFXcQ@mail.gmail.com>
Message-ID: <8298ab1f-eff9-fcdb-b868-5d5263060b8f@gmail.com>

Hi,

As I know, a solution is customizing Makefile target by yourself in 
src/Makevars of your package, and removing the -g option.

As an example, you can see 
https://github.com/SimonYansenZhao/wsrf/blob/09b197ed79b1c55a95d52b14aa5db3437f75f930/src/Makevars

I paste that here.  See "$(CXX1XFLAGS:-g=)" below.


     CXX_STD = "CXX11"
     PKG_LIBS = `"$(R_HOME)/bin/Rscript" -e "Rcpp:::LdFlags()"` -pthread
     wsrf_FLAGS = $(R_XTRA_CPPFLAGS) $(PKG_CPPFLAGS) $(CPPFLAGS) 
$(CLINK_CPPFLAGS) $(R_XTRA_CXXFLAGS) $(PKG_CXXFLAGS) $(CXX1XPICFLAGS) 
$(SHLIB_CXXFLAGS) $(CXX1XFLAGS:-g=) $(CXX1XSTD)

     all: $(SHLIB)

     %.o: %.cpp
         $(SHLIB_CXX1XLD) $(wsrf_FLAGS) -c $< -o $@

However, I am not sure if it is allowed on CRAN, and I think it must 
have a reason for that, though I don't know.

So I didn't do that in my package.


Best regards,
Simon(??)

On 2016?10?16? 21:46, Da Zheng wrote:
> Hello,
>
> I'm writing an R package that is mainly written in C++. By default, R
> CMD INSTALL creates C/C++ flags as follows:
> -g -O2 -fstack-protector --param=ssp-buffer-size=4 -Wformat
> -Werror=format-security -D_FORTIFY_SOURCE=2 -g
>
> However, my package is fairly large. With debug info compiled into the
> library, the generated .so file is over 200MB. Without debug info,
> it's about 30MB. I hope by default debug info is disabled. However, I
> don't see any option in R CMD INSTALL that can disable "-g". Could
> anyone tell me how to disable it?
>
> Many thanks,
> Da
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From pauljohn32 at gmail.com  Tue Oct 18 01:44:13 2016
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Mon, 17 Oct 2016 18:44:13 -0500
Subject: [Rd] Cluster: Various GCC, how important is consistency?
Message-ID: <CAErODj-6d83ObMb3u0CMXd_-J0A6nbom2HOVTuaV=R1DqZw5+A@mail.gmail.com>

On a cluster that is based on RedHat 6.2, we are updating to R-3.3.1.
I have, from time to time, run into problems with various R packages
and some older versions of GCC. I wish we had newer Linux in the
cluster, but with 1000s of nodes running 1000s of jobs, well, they
don't want a restart.

Administrator suggested I try to build with the GCC that is provided
with the nodes, which is gcc-4.4.7.  To my surprise, R-3.3.1 compiled
with that.  After that, I got quite far, many 100s of packages
compiled, but then I hit a snag that RccArmadillo explicitly refuses
to build with anything older than gcc-4.6.  The OpenMx package and
emplik packages also refuse to compile with old gcc

The cluster uses a module system, it is easy enough to swap in various
gcc versions to see what compiles.

I did succeed compiling RcppArmadillo with gcc 4.9.2. But Rcpp is not
picky, it compiled with gcc-4.4.7.

I worry...

1)  will reliance on various GCC make the packages incompatible with
R, or each other?

I logged out, logged back in, with R 3.3.1 I can run

library(RcppArmadillo)
library(Rcpp)

with no errors so far. But I'm not stress testing it much.

I should rebuild everything?

I expect that if I were to use gcc-6 on one package, it would not be
compatible with binaries built with 4.4.7.  But is there a zone of
tolerance allowing 4.4.7 and 4.9 packages to coexist?

2) If I build with non-default GCC, are all of the R users going to
hit trouble if they don't have the same GCC I use?  Unless I make some
extraordinary effort, they are getting GCC 4.4.7. If they try to
install a package, they are getting that GCC, not the one I use to
build RcppArmadillo or the other trouble cases (or everything, if you
say I need to go back and rebuild).

>From an administrative point of view, should I tie R-3.3.1 to a
particular version of GCC? I think I could learn how to do that.

On the cluster, they use the module framework. There are about 50
versions of GCC.  It is easy enough ask for a newer one:

$ module load gcc/4.9.2

It puts the gcc 4.9.2 binaries and shared libraries at the front of the PATHs.

pj


-- 
Paul E. Johnson   http://pj.freefaculty.org
Director, Center for Research Methods and Data Analysis http://crmda.ku.edu

To write me directly, address me at pauljohn at ku.edu.


From simon.urbanek at r-project.org  Tue Oct 18 03:05:40 2016
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Mon, 17 Oct 2016 21:05:40 -0400
Subject: [Rd] Cluster: Various GCC, how important is consistency?
In-Reply-To: <CAErODj-6d83ObMb3u0CMXd_-J0A6nbom2HOVTuaV=R1DqZw5+A@mail.gmail.com>
References: <CAErODj-6d83ObMb3u0CMXd_-J0A6nbom2HOVTuaV=R1DqZw5+A@mail.gmail.com>
Message-ID: <83BA9ABA-9EAB-4378-9CBC-18C4887ADA2C@r-project.org>

There are many issues with different gcc versions, but they can at least be minimized by using static linking, i.e. you should at the very least use -static-libstdc++ -static-libgcc to make sure you don't mix runtime versions. We run into the same problem since C++11 compilers are rare on production machines, but as long as you can isolate the packages away from the dynamically loaded code it often works since R only works at symbol level as long as you have a self-contained binary. The only other thing to worry about are ABI changes, but unless you use Fortran they tend to be compatible enough.

Cheers,
Simon


> On Oct 17, 2016, at 7:44 PM, Paul Johnson <pauljohn32 at gmail.com> wrote:
> 
> On a cluster that is based on RedHat 6.2, we are updating to R-3.3.1.
> I have, from time to time, run into problems with various R packages
> and some older versions of GCC. I wish we had newer Linux in the
> cluster, but with 1000s of nodes running 1000s of jobs, well, they
> don't want a restart.
> 
> Administrator suggested I try to build with the GCC that is provided
> with the nodes, which is gcc-4.4.7.  To my surprise, R-3.3.1 compiled
> with that.  After that, I got quite far, many 100s of packages
> compiled, but then I hit a snag that RccArmadillo explicitly refuses
> to build with anything older than gcc-4.6.  The OpenMx package and
> emplik packages also refuse to compile with old gcc
> 
> The cluster uses a module system, it is easy enough to swap in various
> gcc versions to see what compiles.
> 
> I did succeed compiling RcppArmadillo with gcc 4.9.2. But Rcpp is not
> picky, it compiled with gcc-4.4.7.
> 
> I worry...
> 
> 1)  will reliance on various GCC make the packages incompatible with
> R, or each other?
> 
> I logged out, logged back in, with R 3.3.1 I can run
> 
> library(RcppArmadillo)
> library(Rcpp)
> 
> with no errors so far. But I'm not stress testing it much.
> 
> I should rebuild everything?
> 
> I expect that if I were to use gcc-6 on one package, it would not be
> compatible with binaries built with 4.4.7.  But is there a zone of
> tolerance allowing 4.4.7 and 4.9 packages to coexist?
> 
> 2) If I build with non-default GCC, are all of the R users going to
> hit trouble if they don't have the same GCC I use?  Unless I make some
> extraordinary effort, they are getting GCC 4.4.7. If they try to
> install a package, they are getting that GCC, not the one I use to
> build RcppArmadillo or the other trouble cases (or everything, if you
> say I need to go back and rebuild).
> 
>> From an administrative point of view, should I tie R-3.3.1 to a
> particular version of GCC? I think I could learn how to do that.
> 
> On the cluster, they use the module framework. There are about 50
> versions of GCC.  It is easy enough ask for a newer one:
> 
> $ module load gcc/4.9.2
> 
> It puts the gcc 4.9.2 binaries and shared libraries at the front of the PATHs.
> 
> pj
> 
> 
> -- 
> Paul E. Johnson   http://pj.freefaculty.org
> Director, Center for Research Methods and Data Analysis http://crmda.ku.edu
> 
> To write me directly, address me at pauljohn at ku.edu.
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 


From gmbecker at ucdavis.edu  Tue Oct 18 06:27:13 2016
From: gmbecker at ucdavis.edu (Gabriel Becker)
Date: Mon, 17 Oct 2016 21:27:13 -0700
Subject: [Rd] Cluster: Various GCC, how important is consistency?
In-Reply-To: <83BA9ABA-9EAB-4378-9CBC-18C4887ADA2C@r-project.org>
References: <CAErODj-6d83ObMb3u0CMXd_-J0A6nbom2HOVTuaV=R1DqZw5+A@mail.gmail.com>
	<83BA9ABA-9EAB-4378-9CBC-18C4887ADA2C@r-project.org>
Message-ID: <CADwqtCNi5N+DxkXvCW5z_MAJuR2sE057xDe=a0O4J5H7z_pBgA@mail.gmail.com>

This absolutely causes it's own problems (and they may be bad enough that
you shouldnt do it) but you can also install an older version of
rcpparmadillo. My switchr package makes this more convenient from within r
but grabbing tarballs from the crank Web archive also works  (in fact
that's what switchr will do in this case).

This, of course will never be more than a stop gap. Eventually, sadly,
you'll likely need a newer operating system. We have the same problems on
our cluster.

Best of luck,
~G

On Oct 17, 2016 6:16 PM, "Simon Urbanek" <simon.urbanek at r-project.org>
wrote:

> There are many issues with different gcc versions, but they can at least
> be minimized by using static linking, i.e. you should at the very least use
> -static-libstdc++ -static-libgcc to make sure you don't mix runtime
> versions. We run into the same problem since C++11 compilers are rare on
> production machines, but as long as you can isolate the packages away from
> the dynamically loaded code it often works since R only works at symbol
> level as long as you have a self-contained binary. The only other thing to
> worry about are ABI changes, but unless you use Fortran they tend to be
> compatible enough.
>
> Cheers,
> Simon
>
>
> > On Oct 17, 2016, at 7:44 PM, Paul Johnson <pauljohn32 at gmail.com> wrote:
> >
> > On a cluster that is based on RedHat 6.2, we are updating to R-3.3.1.
> > I have, from time to time, run into problems with various R packages
> > and some older versions of GCC. I wish we had newer Linux in the
> > cluster, but with 1000s of nodes running 1000s of jobs, well, they
> > don't want a restart.
> >
> > Administrator suggested I try to build with the GCC that is provided
> > with the nodes, which is gcc-4.4.7.  To my surprise, R-3.3.1 compiled
> > with that.  After that, I got quite far, many 100s of packages
> > compiled, but then I hit a snag that RccArmadillo explicitly refuses
> > to build with anything older than gcc-4.6.  The OpenMx package and
> > emplik packages also refuse to compile with old gcc
> >
> > The cluster uses a module system, it is easy enough to swap in various
> > gcc versions to see what compiles.
> >
> > I did succeed compiling RcppArmadillo with gcc 4.9.2. But Rcpp is not
> > picky, it compiled with gcc-4.4.7.
> >
> > I worry...
> >
> > 1)  will reliance on various GCC make the packages incompatible with
> > R, or each other?
> >
> > I logged out, logged back in, with R 3.3.1 I can run
> >
> > library(RcppArmadillo)
> > library(Rcpp)
> >
> > with no errors so far. But I'm not stress testing it much.
> >
> > I should rebuild everything?
> >
> > I expect that if I were to use gcc-6 on one package, it would not be
> > compatible with binaries built with 4.4.7.  But is there a zone of
> > tolerance allowing 4.4.7 and 4.9 packages to coexist?
> >
> > 2) If I build with non-default GCC, are all of the R users going to
> > hit trouble if they don't have the same GCC I use?  Unless I make some
> > extraordinary effort, they are getting GCC 4.4.7. If they try to
> > install a package, they are getting that GCC, not the one I use to
> > build RcppArmadillo or the other trouble cases (or everything, if you
> > say I need to go back and rebuild).
> >
> >> From an administrative point of view, should I tie R-3.3.1 to a
> > particular version of GCC? I think I could learn how to do that.
> >
> > On the cluster, they use the module framework. There are about 50
> > versions of GCC.  It is easy enough ask for a newer one:
> >
> > $ module load gcc/4.9.2
> >
> > It puts the gcc 4.9.2 binaries and shared libraries at the front of the
> PATHs.
> >
> > pj
> >
> >
> > --
> > Paul E. Johnson   http://pj.freefaculty.org
> > Director, Center for Research Methods and Data Analysis
> http://crmda.ku.edu
> >
> > To write me directly, address me at pauljohn at ku.edu.
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From jeroen.ooms at stat.ucla.edu  Tue Oct 18 12:55:38 2016
From: jeroen.ooms at stat.ucla.edu (Jeroen Ooms)
Date: Tue, 18 Oct 2016 12:55:38 +0200
Subject: [Rd] Cluster: Various GCC, how important is consistency?
In-Reply-To: <CAErODj-6d83ObMb3u0CMXd_-J0A6nbom2HOVTuaV=R1DqZw5+A@mail.gmail.com>
References: <CAErODj-6d83ObMb3u0CMXd_-J0A6nbom2HOVTuaV=R1DqZw5+A@mail.gmail.com>
Message-ID: <CABFfbXsuMCizgN6enRr590fN9+XimeJYLEB8uY=5qYWcNXE+GQ@mail.gmail.com>

On Tue, Oct 18, 2016 at 1:44 AM, Paul Johnson <pauljohn32 at gmail.com> wrote:
>
> Administrator suggested I try to build with the GCC that is provided
> with the nodes, which is gcc-4.4.7.

Redhat provides an alternative compiler (gcc 5.3 based) in one of it's
opt-in repositories called "redhat developer toolkit" (RDT). In CentOS
you install it as follows:

  yum install -y centos-release-scl
  yum install -y devtoolset-4-gcc-c++

This compiler is specifically designed to be used alongside the EL6
stock gcc 4.4.7. It includes a simple 'enable' script which will put
RDT gcc and g++ in front of your PATH and LD_LIBRARY_PATH and so on.

So what I do on CentOS is install R from EPEL (built with stock gcc
4.4.7) and whenever I need to install an R package that uses e.g.
CXX11, simply start an R shell using the RDT compilers:

   source /opt/rh/devtoolset-4/enable
   R

>From what I have been able to test, this works pretty well (though I
am not a regular EL user). But I was able to build R packages that use
C++11 (such as feather) and once installed, these packages can be used
even in a regular R session (without RDT enabled).


From karl.forner at gmail.com  Tue Oct 18 15:08:11 2016
From: karl.forner at gmail.com (Karl Forner)
Date: Tue, 18 Oct 2016 15:08:11 +0200
Subject: [Rd] weird dir() behavior with broken symlinks
Message-ID: <CAMd4_AewVAk4FEG0LfkdgjZuPRjYESxLWmkfviNS2RtJRKVE5g@mail.gmail.com>

I encountered very weird behavior of the dir() function, that I just can
not understand.

Reproducible example:

docker run -ti rocker/r-base
R version 3.3.1 (2016-06-21) -- "Bug in Your Hair"
Copyright (C) 2016 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)
> # setup
> tmp <- tempfile()
> dir.create(tmp)
> setwd(tmp)
> file.symlink('from', 'to')

# First weirdness, the behavior of the recursive argument
> dir()
[1] "to"
> dir(recursive=TRUE)
character(0)

# include.dirs make it work again. The doc states: Should subdirectory
names be included in
#         recursive listings?  (They always are in non-recursive ones).
>dir(recursive=TRUE, include.dirs=TRUE)
[1] "to"

Best,
Karl

	[[alternative HTML version deleted]]


From karl.forner at gmail.com  Tue Oct 18 16:47:27 2016
From: karl.forner at gmail.com (Karl Forner)
Date: Tue, 18 Oct 2016 16:47:27 +0200
Subject: [Rd] weird dir() behavior with broken symlinks
In-Reply-To: <CAMd4_AewVAk4FEG0LfkdgjZuPRjYESxLWmkfviNS2RtJRKVE5g@mail.gmail.com>
References: <CAMd4_AewVAk4FEG0LfkdgjZuPRjYESxLWmkfviNS2RtJRKVE5g@mail.gmail.com>
Message-ID: <CAMd4_AdG-mW=GYTSwHVqUQ-nyrPosUX=2kTx-L=F9F4ZLi0rBQ@mail.gmail.com>

another strange behavior of list.dirs(), that seems related:
docker run -ti rocker/r-base

> setwd(tempdir())
> file.symlink('from', 'to')
[1] TRUE
> list.dirs(recursive=FALSE)
[1] "./to"

> file.symlink('C/non_existing.doc', 'broken.txt')
[1] TRUE
> list.dirs(recursive=FALSE)
[1] "./broken.txt"


On Tue, Oct 18, 2016 at 3:08 PM, Karl Forner <karl.forner at gmail.com> wrote:

> I encountered very weird behavior of the dir() function, that I just can
> not understand.
>
> Reproducible example:
>
> docker run -ti rocker/r-base
> R version 3.3.1 (2016-06-21) -- "Bug in Your Hair"
> Copyright (C) 2016 The R Foundation for Statistical Computing
> Platform: x86_64-pc-linux-gnu (64-bit)
> > # setup
> > tmp <- tempfile()
> > dir.create(tmp)
> > setwd(tmp)
> > file.symlink('from', 'to')
>
> # First weirdness, the behavior of the recursive argument
> > dir()
> [1] "to"
> > dir(recursive=TRUE)
> character(0)
>
> # include.dirs make it work again. The doc states: Should subdirectory
> names be included in
> #         recursive listings?  (They always are in non-recursive ones).
> >dir(recursive=TRUE, include.dirs=TRUE)
> [1] "to"
>
> Best,
> Karl
>
>
>

	[[alternative HTML version deleted]]


From pauljohn32 at gmail.com  Tue Oct 18 17:04:39 2016
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Tue, 18 Oct 2016 10:04:39 -0500
Subject: [Rd] Cluster: Various GCC, how important is consistency?
In-Reply-To: <CABFfbXsuMCizgN6enRr590fN9+XimeJYLEB8uY=5qYWcNXE+GQ@mail.gmail.com>
References: <CAErODj-6d83ObMb3u0CMXd_-J0A6nbom2HOVTuaV=R1DqZw5+A@mail.gmail.com>
	<CABFfbXsuMCizgN6enRr590fN9+XimeJYLEB8uY=5qYWcNXE+GQ@mail.gmail.com>
Message-ID: <CAErODj_0iTU=TDoEo=QQaJ3YcOFf6WRf6y3iJnxm2HJW9E=dfA@mail.gmail.com>

Dear Jeroen

Did you  rebuild R-3.3.1 and all of the packages with GCC-5.3 in order
to make this work?

The part that worries me is that the shared libraries won't be
consistent, with various versions of GCC in play.

On Tue, Oct 18, 2016 at 5:55 AM, Jeroen Ooms <jeroen.ooms at stat.ucla.edu> wrote:
> On Tue, Oct 18, 2016 at 1:44 AM, Paul Johnson <pauljohn32 at gmail.com> wrote:
>>
>> Administrator suggested I try to build with the GCC that is provided
>> with the nodes, which is gcc-4.4.7.
>
> Redhat provides an alternative compiler (gcc 5.3 based) in one of it's
> opt-in repositories called "redhat developer toolkit" (RDT). In CentOS
> you install it as follows:
>
>   yum install -y centos-release-scl
>   yum install -y devtoolset-4-gcc-c++
>
> This compiler is specifically designed to be used alongside the EL6
> stock gcc 4.4.7. It includes a simple 'enable' script which will put
> RDT gcc and g++ in front of your PATH and LD_LIBRARY_PATH and so on.
>
> So what I do on CentOS is install R from EPEL (built with stock gcc
> 4.4.7) and whenever I need to install an R package that uses e.g.
> CXX11, simply start an R shell using the RDT compilers:
>
>    source /opt/rh/devtoolset-4/enable
>    R
>
> From what I have been able to test, this works pretty well (though I
> am not a regular EL user). But I was able to build R packages that use
> C++11 (such as feather) and once installed, these packages can be used
> even in a regular R session (without RDT enabled).



-- 
Paul E. Johnson   http://pj.freefaculty.org
Director, Center for Research Methods and Data Analysis http://crmda.ku.edu

I only use this account for email list memberships. To write directly,
address me at pauljohn at ku.edu.


From henrik.bengtsson at gmail.com  Wed Oct 19 19:25:25 2016
From: henrik.bengtsson at gmail.com (Henrik Bengtsson)
Date: Wed, 19 Oct 2016 10:25:25 -0700
Subject: [Rd] How to assign NULL value to pairlist element while keeping
 it a pairlist?
In-Reply-To: <22529.61456.824573.56016@stat.math.ethz.ch>
References: <CAFDcVCQEA8Q7Zec6m3mF4PY4mL=VJOihGtXRbKiPq98hKMfY2A@mail.gmail.com>
	<CAOQ5NyeBDy-jAC2-u4TB_CbFtjS4z11dzVuV5_ZmhU11BCwETg@mail.gmail.com>
	<CAOQ5NyfOshFmNp1nQ9Kc7VME2WgqEmJa42Y7m6GRjwsE9=nhTg@mail.gmail.com>
	<CAFDcVCQ3bKCE9DqH9XVQYZOWpKxmaOO7u-NnmDjC3FU_b7pFdg@mail.gmail.com>
	<CAOQ5NydLhK2mJ_rQfg103qkoG0V=GGiGm461UfSZEBqjrB=fZw@mail.gmail.com>
	<22529.61456.824573.56016@stat.math.ethz.ch>
Message-ID: <CAFDcVCQt_Ss98excv8=TbAEuxBryLj-qNxBHoGuX5t+23vdBKw@mail.gmail.com>

On Sat, Oct 15, 2016 at 2:00 AM, Martin Maechler
<maechler at stat.math.ethz.ch> wrote:
>>>>>> Michael Lawrence <lawrence.michael at gene.com>
>>>>>>     on Wed, 12 Oct 2016 15:21:13 -0700 writes:
>
>     > Thanks, this was what I expected. There is a desire to
>     > eliminate the usage of pairlist from user code, which
>     > suggests the alternative of allowing for function
>     > arguments to be stored in lists. That's a much deeper
>     > change though.
>
> and I hope we would not go there just for the purpose of
> eliminating pairlists from user code, would we ?
>
> As nobody else has mentioned it, I'd really  like to mention the
> two (actually 3) functions important for dealing with function
> argument lists much more transparently than the
> as.list(<function>) things below:
>
>   formals(<f>)
>   formals(<f>) <- <arglist>      #  and
>   alist()
>
> for creating / modifying function argument lists (which are
> pairlists, but the user does not need to know really).
> Or did you imply, Henrik, that would you want is not achievable
> with these?

Martin, thanks for bringing these options up.  Just to make sure no
one misreads these comments - I'm not operating on as.list(expr) - it
was just used to show the content of the expression.    In my case,
I'm operating / modifying expressions and not functions per se, e.g.

  expr <- quote(function(x = 1) x)

It's not clear to me how I would go about to modify this to be the
equivalent of:

  expr <- quote(function(x = NULL) x)

without having to:

  f <- eval(expr)
  formals(f) <- list(x=NULL)
  expr <- bquote(.(f))

/Henrik

>
> Martin
>
>     > On Wed, Oct 12, 2016 at 12:31 PM, Henrik Bengtsson
>     > <henrik.bengtsson at gmail.com> wrote:
>     >> Michael, thanks for this info.
>     >>
>     >> I've stumbled upon this in a case where I walk an R expression (the
>     >> AST) and (optionally) modifies it (part of the globals package).  In R
>     >> expressions, a function definition uses a pairlist to represent the
>     >> arguments.  For example,
>     >>
>     >>> expr <- quote(function(x = 1) x)
>     >>> str(as.list(expr))
>     >> List of 4
>     >> $ : symbol function
>     >> $ :Dotted pair list of 1
>     >> ..$ x: num 1
>     >> $ : symbol x
>     >> $ :Class 'srcref'  atomic [1:8] 1 15 1 29 15 29 1 1
>     >> .. ..- attr(*, "srcfile")=Classes 'srcfilecopy', 'srcfile'
>     >> <environment: 0x13918b8>
>     >>
>     >> Here the 2nd element is a pairlist:
>     >>
>     >>> str(expr[[2]])
>     >> Dotted pair list of 1
>     >> $ x: num 1
>     >>> typeof(expr[[2]])
>     >> [1] "pairlist"
>     >>
>     >> Now say that I want to update the default value of argument 'x', which
>     >> is currently 1, to NULL.  Then I do:
>     >>
>     >>> expr[[2]][1] <- list(x = NULL)
>     >>
>     >> At this step, I end up with an expression 'expr' where the arguments
>     >> are no longer represented by a pairlist:
>     >>
>     >>> str(expr[[2]])
>     >> List of 1
>     >> $ x: NULL
>     >>> typeof(expr[[2]])
>     >> [1] "list"
>     >>
>     >> More importantly, at this point 'expr' no longer holds a valid R expression:
>     >>
>     >>> expr
>     >> Error: badly formed function expression
>     >>
>     >> The solution is to make sure we have a pairlist:
>     >>
>     >>> expr[[2]] <- as.pairlist(expr[[2]])
>     >>> expr
>     >> function(x = NULL) x
>     >>
>     >>
>     >> I agree it would be nice to fix this for consistency, but if you bump
>     >> into major issues, at least I can live with having to use an explicit
>     >> as.pairlist().
>     >>
>     >> Thanks
>     >>
>     >> Henrik
>     >>
>     >> On Wed, Oct 12, 2016 at 10:53 AM, Michael Lawrence
>     >> <lawrence.michael at gene.com> wrote:
>     >>> Hi Henrik,
>     >>>
>     >>> It would help to understand your use case for pairlists.
>     >>>
>     >>> Thanks,
>     >>> Michael
>     >>>
>     >>> On Wed, Oct 12, 2016 at 9:40 AM, Michael Lawrence <michafla at gene.com> wrote:
>     >>>> The coercion is probably the most viable workaround for now, as it's
>     >>>> consistent with what happens internally for calls. All pairlists/calls
>     >>>> are converted to list for subassignment, but only calls are converted
>     >>>> back. My guess is that the intent was for users to move from using a
>     >>>> pairlist to the "new" (almost 20 years ago) list. In my opinion,
>     >>>> consistency trumps "convenience" in this case. If others agree, I'll
>     >>>> change it to also coerce back to pairlist.
>     >>>>
>     >>>> Michael
>     >>>>
>     >>>> On Wed, Oct 12, 2016 at 9:20 AM, Henrik Bengtsson
>     >>>> <henrik.bengtsson at gmail.com> wrote:
>     >>>>> Hi, I seem to not be able to assign NULL to an element of a pairlist
>     >>>>> without causing it to be coerced to a plain list.  For example:
>     >>>>>
>>>>>> x <- pairlist(1, 2)
>>>>>> class(x)
>     >>>>> [1] "pairlist"
>     >>>>>
>>>>>> x[1] <- list(NULL)
>>>>>> class(x)
>     >>>>> [1] "list"
>     >>>>>
>     >>>>> This actually true for all [()<- assignments regardless of list value, e.g.
>     >>>>>
>>>>>> x <- pairlist(1, 2)
>>>>>> x[1] <- list(0)
>     >>>>> [1] "list"
>     >>>>>
>     >>>>> I also tried assigning a pairlist(), but still the same problem:
>     >>>>>
>>>>>> x <- pairlist(1, 2)
>>>>>> x[1] <- pairlist(0)
>     >>>>> [1] "list"
>     >>>>>
>     >>>>> The only workaround I'm aware of is to:
>     >>>>>
>     >>>>> x <- as.pairlist(x)
>     >>>>>
>     >>>>> at the end.  Any other suggestions?
>     >>>>>
>     >>>>> Thanks,
>     >>>>>
>     >>>>> Henrik
>     >>>>>
>     >>>>> ______________________________________________
>     >>>>> R-devel at r-project.org mailing list
>     >>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>     > ______________________________________________
>     > R-devel at r-project.org mailing list
>     > https://stat.ethz.ch/mailman/listinfo/r-devel


From luke-tierney at uiowa.edu  Wed Oct 19 20:47:45 2016
From: luke-tierney at uiowa.edu (luke-tierney at uiowa.edu)
Date: Wed, 19 Oct 2016 13:47:45 -0500
Subject: [Rd] How to assign NULL value to pairlist element while keeping
 it a pairlist?
In-Reply-To: <CAFDcVCQt_Ss98excv8=TbAEuxBryLj-qNxBHoGuX5t+23vdBKw@mail.gmail.com>
References: <CAFDcVCQEA8Q7Zec6m3mF4PY4mL=VJOihGtXRbKiPq98hKMfY2A@mail.gmail.com>
	<CAOQ5NyeBDy-jAC2-u4TB_CbFtjS4z11dzVuV5_ZmhU11BCwETg@mail.gmail.com>
	<CAOQ5NyfOshFmNp1nQ9Kc7VME2WgqEmJa42Y7m6GRjwsE9=nhTg@mail.gmail.com>
	<CAFDcVCQ3bKCE9DqH9XVQYZOWpKxmaOO7u-NnmDjC3FU_b7pFdg@mail.gmail.com>
	<CAOQ5NydLhK2mJ_rQfg103qkoG0V=GGiGm461UfSZEBqjrB=fZw@mail.gmail.com>
	<22529.61456.824573.56016@stat.math.ethz.ch>
	<CAFDcVCQt_Ss98excv8=TbAEuxBryLj-qNxBHoGuX5t+23vdBKw@mail.gmail.com>
Message-ID: <alpine.DEB.2.20.1610191346290.2688@luke-Latitude>

On Wed, 19 Oct 2016, Henrik Bengtsson wrote:

> On Sat, Oct 15, 2016 at 2:00 AM, Martin Maechler
> <maechler at stat.math.ethz.ch> wrote:
>>>>>>> Michael Lawrence <lawrence.michael at gene.com>
>>>>>>>     on Wed, 12 Oct 2016 15:21:13 -0700 writes:
>>
>>    > Thanks, this was what I expected. There is a desire to
>>    > eliminate the usage of pairlist from user code, which
>>    > suggests the alternative of allowing for function
>>    > arguments to be stored in lists. That's a much deeper
>>    > change though.
>>
>> and I hope we would not go there just for the purpose of
>> eliminating pairlists from user code, would we ?
>>
>> As nobody else has mentioned it, I'd really  like to mention the
>> two (actually 3) functions important for dealing with function
>> argument lists much more transparently than the
>> as.list(<function>) things below:
>>
>>   formals(<f>)
>>   formals(<f>) <- <arglist>      #  and
>>   alist()
>>
>> for creating / modifying function argument lists (which are
>> pairlists, but the user does not need to know really).
>> Or did you imply, Henrik, that would you want is not achievable
>> with these?
>
> Martin, thanks for bringing these options up.  Just to make sure no
> one misreads these comments - I'm not operating on as.list(expr) - it
> was just used to show the content of the expression.    In my case,
> I'm operating / modifying expressions and not functions per se, e.g.
>
>  expr <- quote(function(x = 1) x)
>
> It's not clear to me how I would go about to modify this to be the
> equivalent of:
>
>  expr <- quote(function(x = NULL) x)
>
> without having to:
>
>  f <- eval(expr)
>  formals(f) <- list(x=NULL)
>  expr <- bquote(.(f))

You don't need to go through the eval\bquote if you use

expr <- quote(function(x = 1) x)
alist <- expr[[2]]
alist[1] <- list(NULL)
expr[[2]] <- as.pairlist(alist)

Best,

luke

>
> /Henrik
>
>>
>> Martin
>>
>>    > On Wed, Oct 12, 2016 at 12:31 PM, Henrik Bengtsson
>>    > <henrik.bengtsson at gmail.com> wrote:
>>    >> Michael, thanks for this info.
>>    >>
>>    >> I've stumbled upon this in a case where I walk an R expression (the
>>    >> AST) and (optionally) modifies it (part of the globals package).  In R
>>    >> expressions, a function definition uses a pairlist to represent the
>>    >> arguments.  For example,
>>    >>
>>    >>> expr <- quote(function(x = 1) x)
>>    >>> str(as.list(expr))
>>    >> List of 4
>>    >> $ : symbol function
>>    >> $ :Dotted pair list of 1
>>    >> ..$ x: num 1
>>    >> $ : symbol x
>>    >> $ :Class 'srcref'  atomic [1:8] 1 15 1 29 15 29 1 1
>>    >> .. ..- attr(*, "srcfile")=Classes 'srcfilecopy', 'srcfile'
>>    >> <environment: 0x13918b8>
>>    >>
>>    >> Here the 2nd element is a pairlist:
>>    >>
>>    >>> str(expr[[2]])
>>    >> Dotted pair list of 1
>>    >> $ x: num 1
>>    >>> typeof(expr[[2]])
>>    >> [1] "pairlist"
>>    >>
>>    >> Now say that I want to update the default value of argument 'x', which
>>    >> is currently 1, to NULL.  Then I do:
>>    >>
>>    >>> expr[[2]][1] <- list(x = NULL)
>>    >>
>>    >> At this step, I end up with an expression 'expr' where the arguments
>>    >> are no longer represented by a pairlist:
>>    >>
>>    >>> str(expr[[2]])
>>    >> List of 1
>>    >> $ x: NULL
>>    >>> typeof(expr[[2]])
>>    >> [1] "list"
>>    >>
>>    >> More importantly, at this point 'expr' no longer holds a valid R expression:
>>    >>
>>    >>> expr
>>    >> Error: badly formed function expression
>>    >>
>>    >> The solution is to make sure we have a pairlist:
>>    >>
>>    >>> expr[[2]] <- as.pairlist(expr[[2]])
>>    >>> expr
>>    >> function(x = NULL) x
>>    >>
>>    >>
>>    >> I agree it would be nice to fix this for consistency, but if you bump
>>    >> into major issues, at least I can live with having to use an explicit
>>    >> as.pairlist().
>>    >>
>>    >> Thanks
>>    >>
>>    >> Henrik
>>    >>
>>    >> On Wed, Oct 12, 2016 at 10:53 AM, Michael Lawrence
>>    >> <lawrence.michael at gene.com> wrote:
>>    >>> Hi Henrik,
>>    >>>
>>    >>> It would help to understand your use case for pairlists.
>>    >>>
>>    >>> Thanks,
>>    >>> Michael
>>    >>>
>>    >>> On Wed, Oct 12, 2016 at 9:40 AM, Michael Lawrence <michafla at gene.com> wrote:
>>    >>>> The coercion is probably the most viable workaround for now, as it's
>>    >>>> consistent with what happens internally for calls. All pairlists/calls
>>    >>>> are converted to list for subassignment, but only calls are converted
>>    >>>> back. My guess is that the intent was for users to move from using a
>>    >>>> pairlist to the "new" (almost 20 years ago) list. In my opinion,
>>    >>>> consistency trumps "convenience" in this case. If others agree, I'll
>>    >>>> change it to also coerce back to pairlist.
>>    >>>>
>>    >>>> Michael
>>    >>>>
>>    >>>> On Wed, Oct 12, 2016 at 9:20 AM, Henrik Bengtsson
>>    >>>> <henrik.bengtsson at gmail.com> wrote:
>>    >>>>> Hi, I seem to not be able to assign NULL to an element of a pairlist
>>    >>>>> without causing it to be coerced to a plain list.  For example:
>>    >>>>>
>>>>>>> x <- pairlist(1, 2)
>>>>>>> class(x)
>>    >>>>> [1] "pairlist"
>>    >>>>>
>>>>>>> x[1] <- list(NULL)
>>>>>>> class(x)
>>    >>>>> [1] "list"
>>    >>>>>
>>    >>>>> This actually true for all [()<- assignments regardless of list value, e.g.
>>    >>>>>
>>>>>>> x <- pairlist(1, 2)
>>>>>>> x[1] <- list(0)
>>    >>>>> [1] "list"
>>    >>>>>
>>    >>>>> I also tried assigning a pairlist(), but still the same problem:
>>    >>>>>
>>>>>>> x <- pairlist(1, 2)
>>>>>>> x[1] <- pairlist(0)
>>    >>>>> [1] "list"
>>    >>>>>
>>    >>>>> The only workaround I'm aware of is to:
>>    >>>>>
>>    >>>>> x <- as.pairlist(x)
>>    >>>>>
>>    >>>>> at the end.  Any other suggestions?
>>    >>>>>
>>    >>>>> Thanks,
>>    >>>>>
>>    >>>>> Henrik
>>    >>>>>
>>    >>>>> ______________________________________________
>>    >>>>> R-devel at r-project.org mailing list
>>    >>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>    > ______________________________________________
>>    > R-devel at r-project.org mailing list
>>    > https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Luke Tierney
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From henrik.bengtsson at gmail.com  Wed Oct 19 22:25:59 2016
From: henrik.bengtsson at gmail.com (Henrik Bengtsson)
Date: Wed, 19 Oct 2016 13:25:59 -0700
Subject: [Rd] How to assign NULL value to pairlist element while keeping
 it a pairlist?
In-Reply-To: <alpine.DEB.2.20.1610191346290.2688@luke-Latitude>
References: <CAFDcVCQEA8Q7Zec6m3mF4PY4mL=VJOihGtXRbKiPq98hKMfY2A@mail.gmail.com>
	<CAOQ5NyeBDy-jAC2-u4TB_CbFtjS4z11dzVuV5_ZmhU11BCwETg@mail.gmail.com>
	<CAOQ5NyfOshFmNp1nQ9Kc7VME2WgqEmJa42Y7m6GRjwsE9=nhTg@mail.gmail.com>
	<CAFDcVCQ3bKCE9DqH9XVQYZOWpKxmaOO7u-NnmDjC3FU_b7pFdg@mail.gmail.com>
	<CAOQ5NydLhK2mJ_rQfg103qkoG0V=GGiGm461UfSZEBqjrB=fZw@mail.gmail.com>
	<22529.61456.824573.56016@stat.math.ethz.ch>
	<CAFDcVCQt_Ss98excv8=TbAEuxBryLj-qNxBHoGuX5t+23vdBKw@mail.gmail.com>
	<alpine.DEB.2.20.1610191346290.2688@luke-Latitude>
Message-ID: <CAFDcVCR159jhEKrO1K0xqw9bJeELjbLww1qHw-ewb_JMG-b6iA@mail.gmail.com>

Thanks Luke.  Yes, this is what I wrote as a workaround in my original
post (and my first follow up):

expr[[2]][1] <- list(x = NULL)
expr[[2]] <- as.pairlist(expr[[2]])

but your

alist <- expr[[2]]
alist[1] <- list(NULL)
expr[[2]] <- as.pairlist(alist)

makes it a bit more clear what the issue is; a pairlist 'x' (here
expr[[2]] and expr) gets coerced to a plain list if one try to do a
`[<-()` assignment.  It would be nice / useful / less surprising /
more consistent(?) if it would remain a pairlist also in those cases.

/Henrik


On Wed, Oct 19, 2016 at 11:47 AM,  <luke-tierney at uiowa.edu> wrote:
> On Wed, 19 Oct 2016, Henrik Bengtsson wrote:
>
>> On Sat, Oct 15, 2016 at 2:00 AM, Martin Maechler
>> <maechler at stat.math.ethz.ch> wrote:
>>>>>>>>
>>>>>>>> Michael Lawrence <lawrence.michael at gene.com>
>>>>>>>>     on Wed, 12 Oct 2016 15:21:13 -0700 writes:
>>>
>>>
>>>    > Thanks, this was what I expected. There is a desire to
>>>    > eliminate the usage of pairlist from user code, which
>>>    > suggests the alternative of allowing for function
>>>    > arguments to be stored in lists. That's a much deeper
>>>    > change though.
>>>
>>> and I hope we would not go there just for the purpose of
>>> eliminating pairlists from user code, would we ?
>>>
>>> As nobody else has mentioned it, I'd really  like to mention the
>>> two (actually 3) functions important for dealing with function
>>> argument lists much more transparently than the
>>> as.list(<function>) things below:
>>>
>>>   formals(<f>)
>>>   formals(<f>) <- <arglist>      #  and
>>>   alist()
>>>
>>> for creating / modifying function argument lists (which are
>>> pairlists, but the user does not need to know really).
>>> Or did you imply, Henrik, that would you want is not achievable
>>> with these?
>>
>>
>> Martin, thanks for bringing these options up.  Just to make sure no
>> one misreads these comments - I'm not operating on as.list(expr) - it
>> was just used to show the content of the expression.    In my case,
>> I'm operating / modifying expressions and not functions per se, e.g.
>>
>>  expr <- quote(function(x = 1) x)
>>
>> It's not clear to me how I would go about to modify this to be the
>> equivalent of:
>>
>>  expr <- quote(function(x = NULL) x)
>>
>> without having to:
>>
>>  f <- eval(expr)
>>  formals(f) <- list(x=NULL)
>>  expr <- bquote(.(f))
>
>
> You don't need to go through the eval\bquote if you use
>
> expr <- quote(function(x = 1) x)
> alist <- expr[[2]]
> alist[1] <- list(NULL)
> expr[[2]] <- as.pairlist(alist)
>
> Best,
>
> luke
>
>
>>
>> /Henrik
>>
>>>
>>> Martin
>>>
>>>    > On Wed, Oct 12, 2016 at 12:31 PM, Henrik Bengtsson
>>>    > <henrik.bengtsson at gmail.com> wrote:
>>>    >> Michael, thanks for this info.
>>>    >>
>>>    >> I've stumbled upon this in a case where I walk an R expression (the
>>>    >> AST) and (optionally) modifies it (part of the globals package).
>>> In R
>>>    >> expressions, a function definition uses a pairlist to represent the
>>>    >> arguments.  For example,
>>>    >>
>>>    >>> expr <- quote(function(x = 1) x)
>>>    >>> str(as.list(expr))
>>>    >> List of 4
>>>    >> $ : symbol function
>>>    >> $ :Dotted pair list of 1
>>>    >> ..$ x: num 1
>>>    >> $ : symbol x
>>>    >> $ :Class 'srcref'  atomic [1:8] 1 15 1 29 15 29 1 1
>>>    >> .. ..- attr(*, "srcfile")=Classes 'srcfilecopy', 'srcfile'
>>>    >> <environment: 0x13918b8>
>>>    >>
>>>    >> Here the 2nd element is a pairlist:
>>>    >>
>>>    >>> str(expr[[2]])
>>>    >> Dotted pair list of 1
>>>    >> $ x: num 1
>>>    >>> typeof(expr[[2]])
>>>    >> [1] "pairlist"
>>>    >>
>>>    >> Now say that I want to update the default value of argument 'x',
>>> which
>>>    >> is currently 1, to NULL.  Then I do:
>>>    >>
>>>    >>> expr[[2]][1] <- list(x = NULL)
>>>    >>
>>>    >> At this step, I end up with an expression 'expr' where the
>>> arguments
>>>    >> are no longer represented by a pairlist:
>>>    >>
>>>    >>> str(expr[[2]])
>>>    >> List of 1
>>>    >> $ x: NULL
>>>    >>> typeof(expr[[2]])
>>>    >> [1] "list"
>>>    >>
>>>    >> More importantly, at this point 'expr' no longer holds a valid R
>>> expression:
>>>    >>
>>>    >>> expr
>>>    >> Error: badly formed function expression
>>>    >>
>>>    >> The solution is to make sure we have a pairlist:
>>>    >>
>>>    >>> expr[[2]] <- as.pairlist(expr[[2]])
>>>    >>> expr
>>>    >> function(x = NULL) x
>>>    >>
>>>    >>
>>>    >> I agree it would be nice to fix this for consistency, but if you
>>> bump
>>>    >> into major issues, at least I can live with having to use an
>>> explicit
>>>    >> as.pairlist().
>>>    >>
>>>    >> Thanks
>>>    >>
>>>    >> Henrik
>>>    >>
>>>    >> On Wed, Oct 12, 2016 at 10:53 AM, Michael Lawrence
>>>    >> <lawrence.michael at gene.com> wrote:
>>>    >>> Hi Henrik,
>>>    >>>
>>>    >>> It would help to understand your use case for pairlists.
>>>    >>>
>>>    >>> Thanks,
>>>    >>> Michael
>>>    >>>
>>>    >>> On Wed, Oct 12, 2016 at 9:40 AM, Michael Lawrence
>>> <michafla at gene.com> wrote:
>>>    >>>> The coercion is probably the most viable workaround for now, as
>>> it's
>>>    >>>> consistent with what happens internally for calls. All
>>> pairlists/calls
>>>    >>>> are converted to list for subassignment, but only calls are
>>> converted
>>>    >>>> back. My guess is that the intent was for users to move from
>>> using a
>>>    >>>> pairlist to the "new" (almost 20 years ago) list. In my opinion,
>>>    >>>> consistency trumps "convenience" in this case. If others agree,
>>> I'll
>>>    >>>> change it to also coerce back to pairlist.
>>>    >>>>
>>>    >>>> Michael
>>>    >>>>
>>>    >>>> On Wed, Oct 12, 2016 at 9:20 AM, Henrik Bengtsson
>>>    >>>> <henrik.bengtsson at gmail.com> wrote:
>>>    >>>>> Hi, I seem to not be able to assign NULL to an element of a
>>> pairlist
>>>    >>>>> without causing it to be coerced to a plain list.  For example:
>>>    >>>>>
>>>>>>>>
>>>>>>>> x <- pairlist(1, 2)
>>>>>>>> class(x)
>>>
>>>    >>>>> [1] "pairlist"
>>>    >>>>>
>>>>>>>>
>>>>>>>> x[1] <- list(NULL)
>>>>>>>> class(x)
>>>
>>>    >>>>> [1] "list"
>>>    >>>>>
>>>    >>>>> This actually true for all [()<- assignments regardless of list
>>> value, e.g.
>>>    >>>>>
>>>>>>>>
>>>>>>>> x <- pairlist(1, 2)
>>>>>>>> x[1] <- list(0)
>>>
>>>    >>>>> [1] "list"
>>>    >>>>>
>>>    >>>>> I also tried assigning a pairlist(), but still the same problem:
>>>    >>>>>
>>>>>>>>
>>>>>>>> x <- pairlist(1, 2)
>>>>>>>> x[1] <- pairlist(0)
>>>
>>>    >>>>> [1] "list"
>>>    >>>>>
>>>    >>>>> The only workaround I'm aware of is to:
>>>    >>>>>
>>>    >>>>> x <- as.pairlist(x)
>>>    >>>>>
>>>    >>>>> at the end.  Any other suggestions?
>>>    >>>>>
>>>    >>>>> Thanks,
>>>    >>>>>
>>>    >>>>> Henrik
>>>    >>>>>
>>>    >>>>> ______________________________________________
>>>    >>>>> R-devel at r-project.org mailing list
>>>    >>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>>    > ______________________________________________
>>>    > R-devel at r-project.org mailing list
>>>    > https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
> --
> Luke Tierney
> Ralph E. Wareham Professor of Mathematical Sciences
> University of Iowa                  Phone:             319-335-3386
> Department of Statistics and        Fax:               319-335-3017
>    Actuarial Science
> 241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
> Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From nilsson.henric at gmail.com  Fri Oct 21 12:01:49 2016
From: nilsson.henric at gmail.com (Henric Winell)
Date: Fri, 21 Oct 2016 12:01:49 +0200
Subject: [Rd] Package install problem in R-devel under Windows
Message-ID: <30d98a37-50de-05c4-546e-15f3e286cd6f@gmail.com>

Hi,

Using the latest R-devel under Windows, I've encountered the following 
problem when trying to install packages at the prompt:

 >R CMD INSTALL d:\inum_0.1-0.tar.gz
* installing to library 'C:\Users\henwin\R\win-library\3.4'
* installing *source* package 'inum' ...
** R
** preparing package for lazy loading
** help
*** installing help indices
** building package indices
** testing if installed package can be loaded
*** arch - i386
Error: '\U' used without hex digits in character string starting "'C:\U"
Execution halted
*** arch - x64
Error: '\U' used without hex digits in character string starting "'C:\U"
Execution halted
ERROR: loading failed for 'i386', 'x64'
* removing 'C:\Users\henwin\R\win-library\3.4/inum'

So, it seems that it doesn't correctly escape the '\' anymore...? 
However, installing from within Rgui works without a hitch.  Also, in 
latest R-3.3.1patched it works as expected:

C:\Program Files\R\R-3.3.1patched\bin>R CMD INSTALL d:\inum_0.1-0.tar.gz
* installing to library 'C:/Users/hennil/R/win-library/3.3'
* installing *source* package 'inum' ...
** R
** preparing package for lazy loading
** help
*** installing help indices
** building package indices
** testing if installed package can be loaded
*** arch - i386
*** arch - x64
* DONE (inum)


Is this a known issue?  Or is it just me...?

Henric Winell


From wilm.schumacher at gmail.com  Fri Oct 21 15:10:08 2016
From: wilm.schumacher at gmail.com (Wilm Schumacher)
Date: Fri, 21 Oct 2016 15:10:08 +0200
Subject: [Rd] anonymous function parsing bug?
Message-ID: <97dcb35c-9173-5fc6-a499-680a4be15a94@gmail.com>

Hi,

I hope this is the correct list for my question. I found a wired 
behaviour of my R installation on the evaluation of anonymous functions.

minimal working example

###
f<-function(x) {
     print( 2*x )
}(2)

class(f)

f(3)

f<-function(x) {
     print( 2*x )
}(4)(5)

f(6)
###

leads to

###
 > f<-function(x) {
+ print( 2*x )
+ }(2)
 >
 > class(f)
[1] "function"
 >
 > f(3)
[1] 6
Error in f(3) : attempt to apply non-function
 >
 > f<-function(x) {
+ print( 2*x )
+ }(4)(5)
 >
 > f(6)
[1] 12
Error in f(6) : attempt to apply non-function

###

is this a bug or desired behavior? Using parenthesis of coures solves 
the problem. However, I think the operator precedence could be the 
problem here. I looked at the "./src/main/gram.y" and I think that the 
line 385
     |    FUNCTION '(' formlist ')' cr expr_or_assign %prec LOW
should be of way higher precedence. But I cannot forsee the side effects 
of that (which could be horrible in that case).

If this is the desired behaviour and not a bug, I'm very interested in 
the rational behind that.

Best wishes,

Wilm

ps:

$ R --version
R version 3.3.1 (2016-06-21) -- "Bug in Your Hair"


From wilm.schumacher at gmail.com  Fri Oct 21 15:22:52 2016
From: wilm.schumacher at gmail.com (Wilm Schumacher)
Date: Fri, 21 Oct 2016 15:22:52 +0200
Subject: [Rd] anonymous function parsing bug?
In-Reply-To: <97dcb35c-9173-5fc6-a499-680a4be15a94@gmail.com>
References: <97dcb35c-9173-5fc6-a499-680a4be15a94@gmail.com>
Message-ID: <68134961-8933-ddff-e6b4-21929b6768f4@gmail.com>

Hi,

sry for the double posting. I forgot to mention that this example

###
f<-function(x) {
     return( 2*x )
}(2)

class(f)

f(3)

f<-function(x) {
     return( 2*x )
}(4)(5)

f(6)
###

leads to

##
 > f<-function(x) {
+     return( 2*x )
+ }(2)
 >
 > class(f)
[1] "function"
 >
 > f(3)
[1] 6
 >
 > f<-function(x) {
+     return( 2*x )
+ }(4)(5)
 >
 > f(6)
[1] 12
##

which is even stranger (at least for me) and contradicts the first 
listing imho in behaviour.

Best wishes,

Wilm

Am 21.10.2016 um 15:10 schrieb Wilm Schumacher:
> Hi,
>
> I hope this is the correct list for my question. I found a wired 
> behaviour of my R installation on the evaluation of anonymous functions.
>
> minimal working example
>
> ###
> f<-function(x) {
>     print( 2*x )
> }(2)
>
> class(f)
>
> f(3)
>
> f<-function(x) {
>     print( 2*x )
> }(4)(5)
>
> f(6)
> ###
>
> leads to
>
> ###
> > f<-function(x) {
> + print( 2*x )
> + }(2)
> >
> > class(f)
> [1] "function"
> >
> > f(3)
> [1] 6
> Error in f(3) : attempt to apply non-function
> >
> > f<-function(x) {
> + print( 2*x )
> + }(4)(5)
> >
> > f(6)
> [1] 12
> Error in f(6) : attempt to apply non-function
>
> ###
>
> is this a bug or desired behavior? Using parenthesis of coures solves 
> the problem. However, I think the operator precedence could be the 
> problem here. I looked at the "./src/main/gram.y" and I think that the 
> line 385
>     |    FUNCTION '(' formlist ')' cr expr_or_assign %prec LOW
> should be of way higher precedence. But I cannot forsee the side 
> effects of that (which could be horrible in that case).
>
> If this is the desired behaviour and not a bug, I'm very interested in 
> the rational behind that.
>
> Best wishes,
>
> Wilm
>
> ps:
>
> $ R --version
> R version 3.3.1 (2016-06-21) -- "Bug in Your Hair"
>


From wdunlap at tibco.com  Fri Oct 21 17:00:28 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 21 Oct 2016 08:00:28 -0700
Subject: [Rd] anonymous function parsing bug?
In-Reply-To: <97dcb35c-9173-5fc6-a499-680a4be15a94@gmail.com>
References: <97dcb35c-9173-5fc6-a499-680a4be15a94@gmail.com>
Message-ID: <CAF8bMcakY4mDNiFqi2Tj8JeuLXQ74utkrC4J4ArWQLx0LX=E8w@mail.gmail.com>

Here is a simplified version of your problem
  > { sqrt }(c(2,4,8))
  [1] 1.414214 2.000000 2.828427
Do you want that to act differently?


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Fri, Oct 21, 2016 at 6:10 AM, Wilm Schumacher <wilm.schumacher at gmail.com>
wrote:

> Hi,
>
> I hope this is the correct list for my question. I found a wired behaviour
> of my R installation on the evaluation of anonymous functions.
>
> minimal working example
>
> ###
> f<-function(x) {
>     print( 2*x )
> }(2)
>
> class(f)
>
> f(3)
>
> f<-function(x) {
>     print( 2*x )
> }(4)(5)
>
> f(6)
> ###
>
> leads to
>
> ###
> > f<-function(x) {
> + print( 2*x )
> + }(2)
> >
> > class(f)
> [1] "function"
> >
> > f(3)
> [1] 6
> Error in f(3) : attempt to apply non-function
> >
> > f<-function(x) {
> + print( 2*x )
> + }(4)(5)
> >
> > f(6)
> [1] 12
> Error in f(6) : attempt to apply non-function
>
> ###
>
> is this a bug or desired behavior? Using parenthesis of coures solves the
> problem. However, I think the operator precedence could be the problem
> here. I looked at the "./src/main/gram.y" and I think that the line 385
>     |    FUNCTION '(' formlist ')' cr expr_or_assign %prec LOW
> should be of way higher precedence. But I cannot forsee the side effects
> of that (which could be horrible in that case).
>
> If this is the desired behaviour and not a bug, I'm very interested in the
> rational behind that.
>
> Best wishes,
>
> Wilm
>
> ps:
>
> $ R --version
> R version 3.3.1 (2016-06-21) -- "Bug in Your Hair"
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From wilm.schumacher at gmail.com  Fri Oct 21 17:43:44 2016
From: wilm.schumacher at gmail.com (Wilm Schumacher)
Date: Fri, 21 Oct 2016 17:43:44 +0200
Subject: [Rd] anonymous function parsing bug?
In-Reply-To: <CAF8bMcakY4mDNiFqi2Tj8JeuLXQ74utkrC4J4ArWQLx0LX=E8w@mail.gmail.com>
References: <97dcb35c-9173-5fc6-a499-680a4be15a94@gmail.com>
	<CAF8bMcakY4mDNiFqi2Tj8JeuLXQ74utkrC4J4ArWQLx0LX=E8w@mail.gmail.com>
Message-ID: <1852931e-89bd-3e9f-934c-2a42361ed414@gmail.com>

Hi,

thx for the reply. Unfortunately that is not a simplified version of the 
problem. You have a function, call it and get the result (numeric in, 
numeric out in that case). For simplicity lets use the "return" case:

##
foobar<-function(x) { return(sqrt(x)) }(2)
##
which is a function (numeric in, numeric out) which is defined, then 
gets called and the return value is a function (with an appendix of 
"(2)" which gets ignored), not the numeric.

In my opinion the result of the expression above should be a numeric 
(1.41... in this case) or an parser error because of ambiguities.

e.g. in comparison with node.js

##
function(x){
     return(2*x)
}(2);
##

leads to

##
SyntaxError: Unexpected token (
##

Or Haskell (and basically every complete functional languange)
##
(\x -> 2*x) 2
##
which leads to 4 (... okay, that is not comparable because here the 
parenthesis make a closure which also works in R or node.js).

However, I think it's weird that

 > ( function(x) { return(2*x) } ( 2 ) ) (3)

is a legal statement which results to 6 and that the "(2)" is basically 
ignored by the parser.

Furthermore it is very strange, that

##
f1<-function(x) { print(2*x) }(2)
f1(3)
##
does the command and gives an error ("attempt to apply non-function") and
##
f2<-function(x) { return(2*x) }(2)
f2(3)
##
is perfectly fine. Thus the return statement changes the interpretation 
as a function? Or do I miss something?

Best wishes

Wilm

Am 21.10.2016 um 17:00 schrieb William Dunlap:
> Here is a simplified version of your problem
>   > { sqrt }(c(2,4,8))
>   [1] 1.414214 2.000000 2.828427
> Do you want that to act differently?
>
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com <http://tibco.com>
>
> On Fri, Oct 21, 2016 at 6:10 AM, Wilm Schumacher 
> <wilm.schumacher at gmail.com <mailto:wilm.schumacher at gmail.com>> wrote:
>
>     Hi,
>
>     I hope this is the correct list for my question. I found a wired
>     behaviour of my R installation on the evaluation of anonymous
>     functions.
>
>     minimal working example
>
>     ###
>     f<-function(x) {
>         print( 2*x )
>     }(2)
>
>     class(f)
>
>     f(3)
>
>     f<-function(x) {
>         print( 2*x )
>     }(4)(5)
>
>     f(6)
>     ###
>
>     leads to
>
>     ###
>     > f<-function(x) {
>     + print( 2*x )
>     + }(2)
>     >
>     > class(f)
>     [1] "function"
>     >
>     > f(3)
>     [1] 6
>     Error in f(3) : attempt to apply non-function
>     >
>     > f<-function(x) {
>     + print( 2*x )
>     + }(4)(5)
>     >
>     > f(6)
>     [1] 12
>     Error in f(6) : attempt to apply non-function
>
>     ###
>
>     is this a bug or desired behavior? Using parenthesis of coures
>     solves the problem. However, I think the operator precedence could
>     be the problem here. I looked at the "./src/main/gram.y" and I
>     think that the line 385
>         |    FUNCTION '(' formlist ')' cr expr_or_assign %prec LOW
>     should be of way higher precedence. But I cannot forsee the side
>     effects of that (which could be horrible in that case).
>
>     If this is the desired behaviour and not a bug, I'm very
>     interested in the rational behind that.
>
>     Best wishes,
>
>     Wilm
>
>     ps:
>
>     $ R --version
>     R version 3.3.1 (2016-06-21) -- "Bug in Your Hair"
>
>     ______________________________________________
>     R-devel at r-project.org <mailto:R-devel at r-project.org> mailing list
>     https://stat.ethz.ch/mailman/listinfo/r-devel
>     <https://stat.ethz.ch/mailman/listinfo/r-devel>
>
>


	[[alternative HTML version deleted]]


From luke-tierney at uiowa.edu  Fri Oct 21 17:57:40 2016
From: luke-tierney at uiowa.edu (luke-tierney at uiowa.edu)
Date: Fri, 21 Oct 2016 10:57:40 -0500
Subject: [Rd] anonymous function parsing bug?
In-Reply-To: <1852931e-89bd-3e9f-934c-2a42361ed414@gmail.com>
References: <97dcb35c-9173-5fc6-a499-680a4be15a94@gmail.com>
	<CAF8bMcakY4mDNiFqi2Tj8JeuLXQ74utkrC4J4ArWQLx0LX=E8w@mail.gmail.com>
	<1852931e-89bd-3e9f-934c-2a42361ed414@gmail.com>
Message-ID: <alpine.DEB.2.20.1610211056570.2688@luke-Latitude>

You might find it useful to look at what body() shows you for your
example and to think about what return does.

Best,

luke

On Fri, 21 Oct 2016, Wilm Schumacher wrote:

> Hi,
>
> thx for the reply. Unfortunately that is not a simplified version of the
> problem. You have a function, call it and get the result (numeric in,
> numeric out in that case). For simplicity lets use the "return" case:
>
> ##
> foobar<-function(x) { return(sqrt(x)) }(2)
> ##
> which is a function (numeric in, numeric out) which is defined, then
> gets called and the return value is a function (with an appendix of
> "(2)" which gets ignored), not the numeric.
>
> In my opinion the result of the expression above should be a numeric
> (1.41... in this case) or an parser error because of ambiguities.
>
> e.g. in comparison with node.js
>
> ##
> function(x){
>     return(2*x)
> }(2);
> ##
>
> leads to
>
> ##
> SyntaxError: Unexpected token (
> ##
>
> Or Haskell (and basically every complete functional languange)
> ##
> (\x -> 2*x) 2
> ##
> which leads to 4 (... okay, that is not comparable because here the
> parenthesis make a closure which also works in R or node.js).
>
> However, I think it's weird that
>
> > ( function(x) { return(2*x) } ( 2 ) ) (3)
>
> is a legal statement which results to 6 and that the "(2)" is basically
> ignored by the parser.
>
> Furthermore it is very strange, that
>
> ##
> f1<-function(x) { print(2*x) }(2)
> f1(3)
> ##
> does the command and gives an error ("attempt to apply non-function") and
> ##
> f2<-function(x) { return(2*x) }(2)
> f2(3)
> ##
> is perfectly fine. Thus the return statement changes the interpretation
> as a function? Or do I miss something?
>
> Best wishes
>
> Wilm
>
> Am 21.10.2016 um 17:00 schrieb William Dunlap:
>> Here is a simplified version of your problem
>>  > { sqrt }(c(2,4,8))
>>   [1] 1.414214 2.000000 2.828427
>> Do you want that to act differently?
>>
>>
>> Bill Dunlap
>> TIBCO Software
>> wdunlap tibco.com <http://tibco.com>
>>
>> On Fri, Oct 21, 2016 at 6:10 AM, Wilm Schumacher
>> <wilm.schumacher at gmail.com <mailto:wilm.schumacher at gmail.com>> wrote:
>>
>>     Hi,
>>
>>     I hope this is the correct list for my question. I found a wired
>>     behaviour of my R installation on the evaluation of anonymous
>>     functions.
>>
>>     minimal working example
>>
>>     ###
>>     f<-function(x) {
>>         print( 2*x )
>>     }(2)
>>
>>     class(f)
>>
>>     f(3)
>>
>>     f<-function(x) {
>>         print( 2*x )
>>     }(4)(5)
>>
>>     f(6)
>>     ###
>>
>>     leads to
>>
>>     ###
>>    > f<-function(x) {
>>     + print( 2*x )
>>     + }(2)
>>    >
>>    > class(f)
>>     [1] "function"
>>    >
>>    > f(3)
>>     [1] 6
>>     Error in f(3) : attempt to apply non-function
>>    >
>>    > f<-function(x) {
>>     + print( 2*x )
>>     + }(4)(5)
>>    >
>>    > f(6)
>>     [1] 12
>>     Error in f(6) : attempt to apply non-function
>>
>>     ###
>>
>>     is this a bug or desired behavior? Using parenthesis of coures
>>     solves the problem. However, I think the operator precedence could
>>     be the problem here. I looked at the "./src/main/gram.y" and I
>>     think that the line 385
>>         |    FUNCTION '(' formlist ')' cr expr_or_assign %prec LOW
>>     should be of way higher precedence. But I cannot forsee the side
>>     effects of that (which could be horrible in that case).
>>
>>     If this is the desired behaviour and not a bug, I'm very
>>     interested in the rational behind that.
>>
>>     Best wishes,
>>
>>     Wilm
>>
>>     ps:
>>
>>     $ R --version
>>     R version 3.3.1 (2016-06-21) -- "Bug in Your Hair"
>>
>>     ______________________________________________
>>     R-devel at r-project.org <mailto:R-devel at r-project.org> mailing list
>>     https://stat.ethz.ch/mailman/listinfo/r-devel
>>     <https://stat.ethz.ch/mailman/listinfo/r-devel>
>>
>>
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Luke Tierney
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From wdunlap at tibco.com  Fri Oct 21 18:10:21 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 21 Oct 2016 09:10:21 -0700
Subject: [Rd] anonymous function parsing bug?
In-Reply-To: <1852931e-89bd-3e9f-934c-2a42361ed414@gmail.com>
References: <97dcb35c-9173-5fc6-a499-680a4be15a94@gmail.com>
	<CAF8bMcakY4mDNiFqi2Tj8JeuLXQ74utkrC4J4ArWQLx0LX=E8w@mail.gmail.com>
	<1852931e-89bd-3e9f-934c-2a42361ed414@gmail.com>
Message-ID: <CAF8bMcaxjGukTYgcOEbQc6XfF51q65CwqWYPzkxaymGBKS-1Ng@mail.gmail.com>

Are you saying that
    f1 <- function(x) log(x)
    f2 <- function(x) { log } (x)
should act differently?

Using 'return' complicates the matter, because it affects evaluation, not
parsing.

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Fri, Oct 21, 2016 at 8:43 AM, Wilm Schumacher <wilm.schumacher at gmail.com>
wrote:

> Hi,
>
> thx for the reply. Unfortunately that is not a simplified version of the
> problem. You have a function, call it and get the result (numeric in,
> numeric out in that case). For simplicity lets use the "return" case:
> ##
> foobar<-function(x) { return(sqrt(x)) }(2)
> ##
> which is a function (numeric in, numeric out) which is defined, then gets
> called and the return value is a function (with an appendix of "(2)" which
> gets ignored), not the numeric.
>
> In my opinion the result of the expression above should be a numeric
> (1.41... in this case) or an parser error because of ambiguities.
>
> e.g. in comparison with node.js
> ##
> function(x){
>     return(2*x)
> }(2);
> ##
>
> leads to
> ##
> SyntaxError: Unexpected token (
> ##
>
> Or Haskell (and basically every complete functional languange)
> ##
> (\x -> 2*x) 2
> ##
> which leads to 4 (... okay, that is not comparable because here the
> parenthesis make a closure which also works in R or node.js).
>
> However, I think it's weird that
>
> > ( function(x) { return(2*x) } ( 2 ) ) (3)
>
> is a legal statement which results to 6 and that the "(2)" is basically
> ignored by the parser.
>
> Furthermore it is very strange, that
> ##
> f1<-function(x) { print(2*x) }(2)
> f1(3)
> ##
> does the command and gives an error ("attempt to apply non-function") and
> ##
> f2<-function(x) { return(2*x) }(2)
> f2(3)
> ##
> is perfectly fine. Thus the return statement changes the interpretation as
> a function? Or do I miss something?
>
> Best wishes
> Wilm
>
>
> Am 21.10.2016 um 17:00 schrieb William Dunlap:
>
> Here is a simplified version of your problem
>   > { sqrt }(c(2,4,8))
>   [1] 1.414214 2.000000 2.828427
> Do you want that to act differently?
>
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
> On Fri, Oct 21, 2016 at 6:10 AM, Wilm Schumacher <
> wilm.schumacher at gmail.com> wrote:
>
>> Hi,
>>
>> I hope this is the correct list for my question. I found a wired
>> behaviour of my R installation on the evaluation of anonymous functions.
>>
>> minimal working example
>>
>> ###
>> f<-function(x) {
>>     print( 2*x )
>> }(2)
>>
>> class(f)
>>
>> f(3)
>>
>> f<-function(x) {
>>     print( 2*x )
>> }(4)(5)
>>
>> f(6)
>> ###
>>
>> leads to
>>
>> ###
>> > f<-function(x) {
>> + print( 2*x )
>> + }(2)
>> >
>> > class(f)
>> [1] "function"
>> >
>> > f(3)
>> [1] 6
>> Error in f(3) : attempt to apply non-function
>> >
>> > f<-function(x) {
>> + print( 2*x )
>> + }(4)(5)
>> >
>> > f(6)
>> [1] 12
>> Error in f(6) : attempt to apply non-function
>>
>> ###
>>
>> is this a bug or desired behavior? Using parenthesis of coures solves the
>> problem. However, I think the operator precedence could be the problem
>> here. I looked at the "./src/main/gram.y" and I think that the line 385
>>     |    FUNCTION '(' formlist ')' cr expr_or_assign %prec LOW
>> should be of way higher precedence. But I cannot forsee the side effects
>> of that (which could be horrible in that case).
>>
>> If this is the desired behaviour and not a bug, I'm very interested in
>> the rational behind that.
>>
>> Best wishes,
>>
>> Wilm
>>
>> ps:
>>
>> $ R --version
>> R version 3.3.1 (2016-06-21) -- "Bug in Your Hair"
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
>
>

	[[alternative HTML version deleted]]


From wilm.schumacher at gmail.com  Fri Oct 21 19:17:33 2016
From: wilm.schumacher at gmail.com (Wilm Schumacher)
Date: Fri, 21 Oct 2016 19:17:33 +0200
Subject: [Rd] anonymous function parsing bug?
In-Reply-To: <CAF8bMcaxjGukTYgcOEbQc6XfF51q65CwqWYPzkxaymGBKS-1Ng@mail.gmail.com>
References: <97dcb35c-9173-5fc6-a499-680a4be15a94@gmail.com>
	<CAF8bMcakY4mDNiFqi2Tj8JeuLXQ74utkrC4J4ArWQLx0LX=E8w@mail.gmail.com>
	<1852931e-89bd-3e9f-934c-2a42361ed414@gmail.com>
	<CAF8bMcaxjGukTYgcOEbQc6XfF51q65CwqWYPzkxaymGBKS-1Ng@mail.gmail.com>
Message-ID: <1ffe617d-5699-95ee-6846-7741ca75e351@gmail.com>

Hi,


Am 21.10.2016 um 18:10 schrieb William Dunlap:
> Are you saying that
>     f1 <- function(x) log(x)
>     f2 <- function(x) { log } (x)
> should act differently?
yes. Or more precisely: I would expect that. "Should" implies, that I 
want to change something. I just want to understand the behavior (or 
file a bug, if this would have been one).

As I wrote, in e.g. node.js the pendents to the lines that you wrote are 
treated differently (the first is a function, the latter is a parsing 
error).

Let's use this example instead:
x <- 20
f1 <- function(x) { x<-x+1; log(x) }
f2 <- function(x) { x<-x+1; log } (x)
which act equally.

But as the latter is a legal statement, I would read it as
f2 <- (function(x) { x<-x+1; log }) (x)

thus, I would expect the first to be a function, the latter to be a 
numeric ( log(20) in this case ).


> Using 'return' complicates the matter, because it affects evaluation, 
> not parsing.

But perhaps it illustrates my problem a little better:
x <- 20
f1 <- function(x) return(log(x))
f2 <- function(x) { return(log) } (x)

f1(10) is a numeric, f2(10) is the log function. Again: as the latter is 
a legal statement, I would expect:
f2 <- (function(x) { x<-x+1; log }) (x)

However, regarding the answers I will try to construct the AST regarding 
the grammar defined in gramm.y of that statement
f2 <- function(x) { x<-x+1; log } (x)
to understand what the R interpreter really does.

Best wishes,

Wilm


From wdunlap at tibco.com  Fri Oct 21 19:54:29 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 21 Oct 2016 10:54:29 -0700
Subject: [Rd] anonymous function parsing bug?
In-Reply-To: <1ffe617d-5699-95ee-6846-7741ca75e351@gmail.com>
References: <97dcb35c-9173-5fc6-a499-680a4be15a94@gmail.com>
	<CAF8bMcakY4mDNiFqi2Tj8JeuLXQ74utkrC4J4ArWQLx0LX=E8w@mail.gmail.com>
	<1852931e-89bd-3e9f-934c-2a42361ed414@gmail.com>
	<CAF8bMcaxjGukTYgcOEbQc6XfF51q65CwqWYPzkxaymGBKS-1Ng@mail.gmail.com>
	<1ffe617d-5699-95ee-6846-7741ca75e351@gmail.com>
Message-ID: <CAF8bMcb8PjSv1-aTBP_JXrJBuaEKsSQHuZUifPcNfn9ho9x9UQ@mail.gmail.com>

Am 21.10.2016 um 18:10 schrieb William Dunlap:
>
> Are you saying that

    f1 <- function(x) log(x)

    f2 <- function(x) { log } (x)

should act differently?

yes.


But that would mean that {log} would act differently than log.
I suppose it is a matter of taste, but I say yuck.

As for 'return', don't use it if you want readable code.  It is
like a goto but worse.  It is never necessary.


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Fri, Oct 21, 2016 at 10:17 AM, Wilm Schumacher <wilm.schumacher at gmail.com
> wrote:

> Hi,
>
>
> Am 21.10.2016 um 18:10 schrieb William Dunlap:
>
>> Are you saying that
>>     f1 <- function(x) log(x)
>>     f2 <- function(x) { log } (x)
>> should act differently?
>>
> yes. Or more precisely: I would expect that. "Should" implies, that I want
> to change something. I just want to understand the behavior (or file a bug,
> if this would have been one).
>
> As I wrote, in e.g. node.js the pendents to the lines that you wrote are
> treated differently (the first is a function, the latter is a parsing
> error).
>
> Let's use this example instead:
> x <- 20
> f1 <- function(x) { x<-x+1; log(x) }
> f2 <- function(x) { x<-x+1; log } (x)
> which act equally.
>
> But as the latter is a legal statement, I would read it as
> f2 <- (function(x) { x<-x+1; log }) (x)
>
> thus, I would expect the first to be a function, the latter to be a
> numeric ( log(20) in this case ).
>
>
> Using 'return' complicates the matter, because it affects evaluation, not
>> parsing.
>>
>
> But perhaps it illustrates my problem a little better:
> x <- 20
> f1 <- function(x) return(log(x))
> f2 <- function(x) { return(log) } (x)
>
> f1(10) is a numeric, f2(10) is the log function. Again: as the latter is a
> legal statement, I would expect:
> f2 <- (function(x) { x<-x+1; log }) (x)
>
> However, regarding the answers I will try to construct the AST regarding
> the grammar defined in gramm.y of that statement
> f2 <- function(x) { x<-x+1; log } (x)
> to understand what the R interpreter really does.
>
> Best wishes,
>
> Wilm
>
>
>
>
>

	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Fri Oct 21 20:13:48 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 21 Oct 2016 20:13:48 +0200
Subject: [Rd] anonymous function parsing bug?
In-Reply-To: <1ffe617d-5699-95ee-6846-7741ca75e351@gmail.com>
References: <97dcb35c-9173-5fc6-a499-680a4be15a94@gmail.com>
	<CAF8bMcakY4mDNiFqi2Tj8JeuLXQ74utkrC4J4ArWQLx0LX=E8w@mail.gmail.com>
	<1852931e-89bd-3e9f-934c-2a42361ed414@gmail.com>
	<CAF8bMcaxjGukTYgcOEbQc6XfF51q65CwqWYPzkxaymGBKS-1Ng@mail.gmail.com>
	<1ffe617d-5699-95ee-6846-7741ca75e351@gmail.com>
Message-ID: <4B5350C2-2E8B-42E6-8BFD-D52D25ED2D96@gmail.com>


> On 21 Oct 2016, at 19:17 , Wilm Schumacher <wilm.schumacher at gmail.com> wrote:
> 
> Am 21.10.2016 um 18:10 schrieb William Dunlap:
>> Are you saying that
>>    f1 <- function(x) log(x)
>>    f2 <- function(x) { log } (x)
>> should act differently?
> yes. Or more precisely: I would expect that. "Should" implies, that I want to change something. I just want to understand the behavior (or file a bug, if this would have been one).

I think Bill and Luke are failing in trying to make you work out the logic for yourself...

The point is that 
{
  some_computation
}(x)

is an expression that evaluates some_computation and applies it as a function to the argument x (or fails if not a function). 

When you define functions, the body can be a single expression, so

f <- function(a)
{
  some_computation
}(x)

is effectively the same as

f <- function(a) {
 {
   some_computation
 }(x)
}

where you seem to be expecting

{f <- function(a) {
 {
   some_computation
 }
}(x)

Got it?
  
-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From luke-tierney at uiowa.edu  Fri Oct 21 23:59:58 2016
From: luke-tierney at uiowa.edu (luke-tierney at uiowa.edu)
Date: Fri, 21 Oct 2016 16:59:58 -0500
Subject: [Rd] anonymous function parsing bug?
In-Reply-To: <CAF8bMcb8PjSv1-aTBP_JXrJBuaEKsSQHuZUifPcNfn9ho9x9UQ@mail.gmail.com>
References: <97dcb35c-9173-5fc6-a499-680a4be15a94@gmail.com>
	<CAF8bMcakY4mDNiFqi2Tj8JeuLXQ74utkrC4J4ArWQLx0LX=E8w@mail.gmail.com>
	<1852931e-89bd-3e9f-934c-2a42361ed414@gmail.com>
	<CAF8bMcaxjGukTYgcOEbQc6XfF51q65CwqWYPzkxaymGBKS-1Ng@mail.gmail.com>
	<1ffe617d-5699-95ee-6846-7741ca75e351@gmail.com>
	<CAF8bMcb8PjSv1-aTBP_JXrJBuaEKsSQHuZUifPcNfn9ho9x9UQ@mail.gmail.com>
Message-ID: <alpine.DEB.2.20.1610211655180.2688@luke-Latitude>

On Fri, 21 Oct 2016, William Dunlap via R-devel wrote:

> Am 21.10.2016 um 18:10 schrieb William Dunlap:
>>
>> Are you saying that
>
>    f1 <- function(x) log(x)
>
>    f2 <- function(x) { log } (x)
>
> should act differently?
>
> yes.
>
>
> But that would mean that {log} would act differently than log.
> I suppose it is a matter of taste, but I say yuck.
>
> As for 'return', don't use it if you want readable code.  It is
> like a goto but worse.  It is never necessary.

As a rule I agree, but one case where return is clearer than the alternative is

repeat {
    ....
    if (...)
       return(...)
}

Complicated nested if expressions are also sometimes clearer using
return as an early breakout.

Best,

luke

>
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
> On Fri, Oct 21, 2016 at 10:17 AM, Wilm Schumacher <wilm.schumacher at gmail.com
>> wrote:
>
>> Hi,
>>
>>
>> Am 21.10.2016 um 18:10 schrieb William Dunlap:
>>
>>> Are you saying that
>>>     f1 <- function(x) log(x)
>>>     f2 <- function(x) { log } (x)
>>> should act differently?
>>>
>> yes. Or more precisely: I would expect that. "Should" implies, that I want
>> to change something. I just want to understand the behavior (or file a bug,
>> if this would have been one).
>>
>> As I wrote, in e.g. node.js the pendents to the lines that you wrote are
>> treated differently (the first is a function, the latter is a parsing
>> error).
>>
>> Let's use this example instead:
>> x <- 20
>> f1 <- function(x) { x<-x+1; log(x) }
>> f2 <- function(x) { x<-x+1; log } (x)
>> which act equally.
>>
>> But as the latter is a legal statement, I would read it as
>> f2 <- (function(x) { x<-x+1; log }) (x)
>>
>> thus, I would expect the first to be a function, the latter to be a
>> numeric ( log(20) in this case ).
>>
>>
>> Using 'return' complicates the matter, because it affects evaluation, not
>>> parsing.
>>>
>>
>> But perhaps it illustrates my problem a little better:
>> x <- 20
>> f1 <- function(x) return(log(x))
>> f2 <- function(x) { return(log) } (x)
>>
>> f1(10) is a numeric, f2(10) is the log function. Again: as the latter is a
>> legal statement, I would expect:
>> f2 <- (function(x) { x<-x+1; log }) (x)
>>
>> However, regarding the answers I will try to construct the AST regarding
>> the grammar defined in gramm.y of that statement
>> f2 <- function(x) { x<-x+1; log } (x)
>> to understand what the R interpreter really does.
>>
>> Best wishes,
>>
>> Wilm
>>
>>
>>
>>
>>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Luke Tierney
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From jeroen.ooms at stat.ucla.edu  Sun Oct 23 18:37:01 2016
From: jeroen.ooms at stat.ucla.edu (Jeroen Ooms)
Date: Sun, 23 Oct 2016 18:37:01 +0200
Subject: [Rd] Support for signing R packages with GPG
Message-ID: <CABFfbXv=ERj+1atPDP_6ZjYE9xi6r+CVEk4sEqHjSMEZz21Qbw@mail.gmail.com>

I would like to propose adding experimental support for including a
PGP signature in R source packages. This would make it possible to
verify the identity of the package author and integrity of the package
sources.

There are two ways to implement this. Assuming GnuPG is on the PATH,
the CMD build script could call:

  gpg --clearsign MD5 -o MD5.gpg

Alternatively the 'gpg' R package provides a more portable method via
the gpgme C library. This method works on Windows / macOS as well.

  writeLines(gpg::gpg_sign("MD5"), "MD5.gpg")

Attached is an example implementation of the latter (also available at
https://git.io/vPb9G) which has been tested with several versions of
GnuPG. It exposes an optional flag for CMD build, i.e:

  R CMD build somepkg --sign
  R CMD build somepkg --sign=jeroen.ooms at stat.ucla.edu

The --sign flag creates a signature for the MD5 file [1] in the source
package and saves it as MD5.gpg (similar to a Debian 'Release.gpg'
file [2]). Obviously the package author or build server needs to have
a suitable private key in the local keyring.


## Signature verification

Once R supports signed packages, we can develop a system to take
advantage of such signatures. The verification itself can easily be
implemented via 'gpg --verify' or via gpg::gpg_verify() and could be
performed without changes in R itself. The difficult part in GPG comes
from defining which peers should be trusted.

But even without a 'web of trust' there are several ways one can
immediately take advantage of signatures. For example, when a
installing a package update or dev-version of a package, we can verify
that the signature of the update matches that of the currently
installed package. This would prevent the type of attacks where an
intermediate party pushes a fake malicious update for a popular R
package via e.g. a hacked CRAN mirror.

Eventually, CRAN could consider allowing signatures as a secure
alternative to confirmation emails, and signing packages on the build
servers with a CRAN GPG key, similar to Debian repositories. For now,
at least establishing a format for (optionally) signing packages would
be a great first step.


[1] Eventually we should add SHA256 and SHA256.sig in addition to MD5
[2] https://cran.r-project.org/web/packages/gpg/vignettes/intro.html#debian_example

From bob at rud.is  Sun Oct 23 19:16:14 2016
From: bob at rud.is (Bob Rudis)
Date: Sun, 23 Oct 2016 13:16:14 -0400
Subject: [Rd] Support for signing R packages with GPG
In-Reply-To: <CABFfbXv=ERj+1atPDP_6ZjYE9xi6r+CVEk4sEqHjSMEZz21Qbw@mail.gmail.com>
References: <CABFfbXv=ERj+1atPDP_6ZjYE9xi6r+CVEk4sEqHjSMEZz21Qbw@mail.gmail.com>
Message-ID: <CAA-FpKXU=u4iWO=QNb2Wob7miz-A56FsJxvmRqi_21nXACwXBQ@mail.gmail.com>

I suspected/hoped this was one reason for the new pkg ;-)

I'm *100% in support of this* and will help as much as I can. I can
see if my org (Rapid7) would be willing to be a trusted peer (given my
position it's prbly more like "we will be doing this" vs an ask).
Sonatype may also be willing to be one (I have contacts there). I
might be able to convince Veracode, too. Given Microsoft's reliance on
R, they might be willing to be one and I suspect TIBCO, Mango and
other Consortium companies would gain some solid PR benefit &
community good will from being trusted peers.

With a similar purpose of integrity validation (not necessarily
gpg-related), I've been contemplating a rationale write-up and PR for
`base::source()` & `base::sys.source()` to support some type of
signature verification parameter option (with a default warning issued
when `source()` is used w/o the signature and a corresponding option
string to mute the warnings.

`devtools::source_gist()` ?well, really `devtools::source_url()`
(which ultimately calls `base::source()`) would benefit from the check
being in `base::source()` but I've been contemplating PR'ing a warning
into them vs the easily ignorable message that is printed when no hash
is provided.

Neither may be accepted (and, yes, the `devtools` functions do have
Description text which try to emphasize the need for integrity
validation) but an explicit warning would (IMO) be a good way to
really get folks to think start to think about security issues.

Finally, it would also be nice to see RStudio team take advantage of
this new gpg pkg to enable generation of PGP keys and signing of git
commits. I'm personally at fault for not manually committing RStudio
projects with `-S` since the GUI makes it way too easy to avoid going
to the command-line. The Labs team at work is in the process of making
signing mandatory for private prod repos, so there's some shameless
personal benefit to this request ;-)



On Sun, Oct 23, 2016 at 12:37 PM, Jeroen Ooms <jeroen.ooms at stat.ucla.edu> wrote:
> I would like to propose adding experimental support for including a
> PGP signature in R source packages. This would make it possible to
> verify the identity of the package author and integrity of the package
> sources.
>
> There are two ways to implement this. Assuming GnuPG is on the PATH,
> the CMD build script could call:
>
>   gpg --clearsign MD5 -o MD5.gpg
>
> Alternatively the 'gpg' R package provides a more portable method via
> the gpgme C library. This method works on Windows / macOS as well.
>
>   writeLines(gpg::gpg_sign("MD5"), "MD5.gpg")
>
> Attached is an example implementation of the latter (also available at
> https://git.io/vPb9G) which has been tested with several versions of
> GnuPG. It exposes an optional flag for CMD build, i.e:
>
>   R CMD build somepkg --sign
>   R CMD build somepkg --sign=jeroen.ooms at stat.ucla.edu
>
> The --sign flag creates a signature for the MD5 file [1] in the source
> package and saves it as MD5.gpg (similar to a Debian 'Release.gpg'
> file [2]). Obviously the package author or build server needs to have
> a suitable private key in the local keyring.
>
>
> ## Signature verification
>
> Once R supports signed packages, we can develop a system to take
> advantage of such signatures. The verification itself can easily be
> implemented via 'gpg --verify' or via gpg::gpg_verify() and could be
> performed without changes in R itself. The difficult part in GPG comes
> from defining which peers should be trusted.
>
> But even without a 'web of trust' there are several ways one can
> immediately take advantage of signatures. For example, when a
> installing a package update or dev-version of a package, we can verify
> that the signature of the update matches that of the currently
> installed package. This would prevent the type of attacks where an
> intermediate party pushes a fake malicious update for a popular R
> package via e.g. a hacked CRAN mirror.
>
> Eventually, CRAN could consider allowing signatures as a secure
> alternative to confirmation emails, and signing packages on the build
> servers with a CRAN GPG key, similar to Debian repositories. For now,
> at least establishing a format for (optionally) signing packages would
> be a great first step.
>
>
> [1] Eventually we should add SHA256 and SHA256.sig in addition to MD5
> [2] https://cran.r-project.org/web/packages/gpg/vignettes/intro.html#debian_example
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From kevinushey at gmail.com  Mon Oct 24 19:51:05 2016
From: kevinushey at gmail.com (Kevin Ushey)
Date: Mon, 24 Oct 2016 10:51:05 -0700
Subject: [Rd] improve 'package not installed' load errors?
Message-ID: <CAJXgQP1AAs2oXZX1wbsCcPCsUYOjG-VXTPZ_zeyq9co2C5B0rQ@mail.gmail.com>

Hi R-devel,

One of the more common issues that new R users see, and become stumped
by, is error messages during package load of the form:

> library(ggplot2)
Error in loadNamespace(j <- i[[1L]], c(lib.loc, .libPaths()),
versionCheck = vI[[j]]) :
  there is no package called 'Rcpp'
Error: package or namespace load failed for 'ggplot2'

Typically, error messages of this form are caused simply by one or
more dependent packages (in this case, 'Rcpp') not being installed or
available on the current library paths. (A side question, which I do
not know the answer to, is how users get themselves into this state.)

I believe it would be helpful for new users if the error message
reported here was a bit more direct, e.g.

> library(ggplot2)
Error: 'ggplot2' depends on package 'Rcpp', but 'Rcpp' is not installed
consider installing 'Rcpp' with install.packages("Rcpp")

In other words, it might be helpful to avoid printing the
'loadNamespace()' call on error (since it's mostly just scary /
uninformative), and check up-front that the package is installed
before attempting to call 'loadNamespace()'. I'm sure a number of
novice users will still just throw their hands up in the air and say
"I don't know what to do", but I think this would help steer a number
of users in the right direction.

(The prescription to suggest installing a package from CRAN if
available might be a step too far, but I think making it more clear
that the error is due to a missing dependent package would help.)

Any thoughts?
Kevin


From jfox at mcmaster.ca  Mon Oct 24 20:19:49 2016
From: jfox at mcmaster.ca (Fox, John)
Date: Mon, 24 Oct 2016 18:19:49 +0000
Subject: [Rd] improve 'package not installed' load errors?
In-Reply-To: <CAJXgQP1AAs2oXZX1wbsCcPCsUYOjG-VXTPZ_zeyq9co2C5B0rQ@mail.gmail.com>
References: <CAJXgQP1AAs2oXZX1wbsCcPCsUYOjG-VXTPZ_zeyq9co2C5B0rQ@mail.gmail.com>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC83659894F@FHSDB2D11-2.csu.mcmaster.ca>

Dear Kevin,

As others have mentioned, it's my sense that this kind of error has become more frequent -- at least I see students who encounter these errors more frequently. I agree that a less cryptic error message might help.

Best,
 John
--------------------------------------
John Fox, Professor
McMaster University
Hamilton, Ontario, Canada
Web: socserv.mcmaster.ca/jfox



> -----Original Message-----
> From: R-devel [mailto:r-devel-bounces at r-project.org] On Behalf Of Kevin
> Ushey
> Sent: Monday, October 24, 2016 1:51 PM
> To: R-devel <r-devel at r-project.org>
> Subject: [Rd] improve 'package not installed' load errors?
> 
> Hi R-devel,
> 
> One of the more common issues that new R users see, and become stumped
> by, is error messages during package load of the form:
> 
> > library(ggplot2)
> Error in loadNamespace(j <- i[[1L]], c(lib.loc, .libPaths()),
> versionCheck = vI[[j]]) :
>   there is no package called 'Rcpp'
> Error: package or namespace load failed for 'ggplot2'
> 
> Typically, error messages of this form are caused simply by one or more
> dependent packages (in this case, 'Rcpp') not being installed or
> available on the current library paths. (A side question, which I do not
> know the answer to, is how users get themselves into this state.)
> 
> I believe it would be helpful for new users if the error message
> reported here was a bit more direct, e.g.
> 
> > library(ggplot2)
> Error: 'ggplot2' depends on package 'Rcpp', but 'Rcpp' is not installed
> consider installing 'Rcpp' with install.packages("Rcpp")
> 
> In other words, it might be helpful to avoid printing the
> 'loadNamespace()' call on error (since it's mostly just scary /
> uninformative), and check up-front that the package is installed before
> attempting to call 'loadNamespace()'. I'm sure a number of novice users
> will still just throw their hands up in the air and say "I don't know
> what to do", but I think this would help steer a number of users in the
> right direction.
> 
> (The prescription to suggest installing a package from CRAN if available
> might be a step too far, but I think making it more clear that the error
> is due to a missing dependent package would help.)
> 
> Any thoughts?
> Kevin
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From murdoch.duncan at gmail.com  Mon Oct 24 20:54:16 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 24 Oct 2016 14:54:16 -0400
Subject: [Rd] improve 'package not installed' load errors?
In-Reply-To: <CAJXgQP1AAs2oXZX1wbsCcPCsUYOjG-VXTPZ_zeyq9co2C5B0rQ@mail.gmail.com>
References: <CAJXgQP1AAs2oXZX1wbsCcPCsUYOjG-VXTPZ_zeyq9co2C5B0rQ@mail.gmail.com>
Message-ID: <923577ec-5b0e-d71c-6244-b39952fb00e7@gmail.com>

On 24/10/2016 1:51 PM, Kevin Ushey wrote:
> Hi R-devel,
>
> One of the more common issues that new R users see, and become stumped
> by, is error messages during package load of the form:
>
> > library(ggplot2)
> Error in loadNamespace(j <- i[[1L]], c(lib.loc, .libPaths()),
> versionCheck = vI[[j]]) :
>    there is no package called 'Rcpp'
> Error: package or namespace load failed for 'ggplot2'
>
> Typically, error messages of this form are caused simply by one or
> more dependent packages (in this case, 'Rcpp') not being installed or
> available on the current library paths. (A side question, which I do
> not know the answer to, is how users get themselves into this state.)

I think one way to get here is to be running with several libraries.  
You install ggplot2 while Rcpp is available, but in a different part of 
the .libPaths list, then in a later session try to use it with a 
different .libPaths setting.
>
> I believe it would be helpful for new users if the error message
> reported here was a bit more direct, e.g.
>
> > library(ggplot2)
> Error: 'ggplot2' depends on package 'Rcpp', but 'Rcpp' is not installed
> consider installing 'Rcpp' with install.packages("Rcpp")

The risk with this message is that Rcpp may really be installed, but 
it's just not currently on .libPaths.  Detecting that situation and 
reporting on it looks like it would be relatively hard:  it would mean 
the ggplot2 installation needs to record where it found all 
dependencies, and if at some later time it doesn't find one, see if that 
location still exists and would still work (in which case the message 
should suggest modifying .libPaths).  I think that's too much work.

Even a simple change like

Error: 'ggplot2' depends on package 'Rcpp', but 'Rcpp' was not found


might not be easy (which function knows both names?)  However, if you 
want to suggest a patch to implement this, I would take a look.

Duncan Murdoch

>
> In other words, it might be helpful to avoid printing the
> 'loadNamespace()' call on error (since it's mostly just scary /
> uninformative), and check up-front that the package is installed
> before attempting to call 'loadNamespace()'. I'm sure a number of
> novice users will still just throw their hands up in the air and say
> "I don't know what to do", but I think this would help steer a number
> of users in the right direction.
>
> (The prescription to suggest installing a package from CRAN if
> available might be a step too far, but I think making it more clear
> that the error is due to a missing dependent package would help.)
>
> Any thoughts?
> Kevin
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From wojciech.musial at gmail.com  Tue Oct 25 00:07:55 2016
From: wojciech.musial at gmail.com (Wojciech Musial (Voitek))
Date: Mon, 24 Oct 2016 15:07:55 -0700
Subject: [Rd] typo or stale info in qr man
Message-ID: <CACPpiHS11GEDAULwOT9T8TY7Kf87BEdP5WqnrqhSCUbyPd2u-Q@mail.gmail.com>

man for `qr` says that the function uses LINPACK's DQRDC, while it in
fact uses DQRDC2.

```
The QR decomposition of the matrix as computed by LINPACK or LAPACK.
The components in the returned value correspond directly to the values
returned by DQRDC/DGEQP3/ZGEQP3
```


From bbolker at gmail.com  Tue Oct 25 01:26:35 2016
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 24 Oct 2016 19:26:35 -0400
Subject: [Rd] ACM license link broken
Message-ID: <aeec383a-c734-3bad-495b-fb58bcff013a@gmail.com>

The URL listed under
https://svn.r-project.org/R/trunk/share/licenses/license.db for the ACM
license,

http://www.acm.org/publications/policies/softwarecrnotice ,

gives a 404 error.  I think this should be replaced by

https://www.acm.org/publications/policies/software-copyright-notice

?  For what it's worth, the original page did exist as recently as 5
April 2016:

https://web.archive.org/web/20160405100845/http://www.acm.org/publications/policies/softwarecrnotice/

  Suggestions for where/to whom to report this?  R-bugzilla?
cran at r-project.org?  Here?

  cheers
    Ben Bolker


From maechler at stat.math.ethz.ch  Tue Oct 25 10:08:46 2016
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 25 Oct 2016 10:08:46 +0200
Subject: [Rd] typo or stale info in qr man
In-Reply-To: <CACPpiHS11GEDAULwOT9T8TY7Kf87BEdP5WqnrqhSCUbyPd2u-Q@mail.gmail.com>
References: <CACPpiHS11GEDAULwOT9T8TY7Kf87BEdP5WqnrqhSCUbyPd2u-Q@mail.gmail.com>
Message-ID: <22543.4878.559316.78350@stat.math.ethz.ch>

>>>>> Wojciech Musial (Voitek) <wojciech.musial at gmail.com>
>>>>>     on Mon, 24 Oct 2016 15:07:55 -0700 writes:

    > man for `qr` says that the function uses LINPACK's DQRDC, while it in
    > fact uses DQRDC2.

which is a modification of LINPACK's DQRDC.

But you are right, and I have added to the help file (and a tiny
bit to the comments in the Fortran source).

When this change was done > 20 years ago, it was still hoped 
that the numerical linear algebra community or more specifically
those behind LAPACK would eventually provide this functionality
with LAPACK (and we would then use that),
but that has never happened according to my knowledge.

Thank you for the 'heads up'.

Martin Maechler
ETH Zurich


From maechler at stat.math.ethz.ch  Tue Oct 25 10:16:52 2016
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 25 Oct 2016 10:16:52 +0200
Subject: [Rd] ACM license link broken
In-Reply-To: <aeec383a-c734-3bad-495b-fb58bcff013a@gmail.com>
References: <aeec383a-c734-3bad-495b-fb58bcff013a@gmail.com>
Message-ID: <22543.5364.976670.114369@stat.math.ethz.ch>

>>>>> Ben Bolker <bbolker at gmail.com>
>>>>>     on Mon, 24 Oct 2016 19:26:35 -0400 writes:

    > The URL listed under
    > https://svn.r-project.org/R/trunk/share/licenses/license.db for the ACM
    > license,

    > http://www.acm.org/publications/policies/softwarecrnotice ,

    > gives a 404 error.  I think this should be replaced by

    > https://www.acm.org/publications/policies/software-copyright-notice

    > ?  For what it's worth, the original page did exist as recently as 5
    > April 2016:

    > https://web.archive.org/web/20160405100845/http://www.acm.org/publications/policies/softwarecrnotice/

    > Suggestions for where/to whom to report this?  R-bugzilla?
    > cran at r-project.org?  Here?

Thank you, Ben!

"Here" is perfect for such a small change.
  I have fixed the sources, including those for 'R 3.2.2 RC' (RC
  := Release candidate; release in ca 5 days)
 
(R-bugzilla would have been fine, too.  It's slightly more work
 for you and R core, but in general things there should less
 easily fall between the cracks)

Martin


From jari.oksanen at oulu.fi  Tue Oct 25 11:08:57 2016
From: jari.oksanen at oulu.fi (Jari Oksanen)
Date: Tue, 25 Oct 2016 09:08:57 +0000
Subject: [Rd] typo or stale info in qr man
In-Reply-To: <22543.4878.559316.78350@stat.math.ethz.ch>
References: <CACPpiHS11GEDAULwOT9T8TY7Kf87BEdP5WqnrqhSCUbyPd2u-Q@mail.gmail.com>,
	<22543.4878.559316.78350@stat.math.ethz.ch>
Message-ID: <1477386537183.68937@oulu.fi>

And that missing functionality is that Linpack/Lapack routines do not return rank and have a different style of pivoting? For other aspects, the user-interface is very similar in dqrdc2 in R and in dqrdc in Linpack. Another difference seems to be that the final pivoting reported to the user is different: R keeps the original order except for aliased variables, but Linpack makes either wild shuffling or no pivoting at all. I haven't looked at dqpq3 in Lapack, but it appears to return no rank either (don't know about shuffling the columns). It seems that using Linpack dqrdc directly is not always compatible with dqrdc2 of R although it returns similar objects. That is, when packing up the Linpack function to produce an object with same items as qr.default (qr, rank, qraux, pivot, class "qr"), the result object may not yield similar results in base::qr.fitted, base::qr.resid etc as base::qr.default result (but I haven't had time for thorough testing).

This is how I tried to do the packing (apologies for clumsy coding):

SEXP do_QR(SEXP x, SEXP dopivot)
{
    /* set up */
    int i;
    int nr = nrows(x), nx = ncols(x);
    int pivoting = asInteger(dopivot);
    SEXP qraux = PROTECT(allocVector(REALSXP, nx));
    SEXP pivot = PROTECT(allocVector(INTSXP, nx));
    /* do pivoting or keep the order of columns? */
    if (pivoting)
        memset(INTEGER(pivot), 0, nx * sizeof(int));
    else
        for(i = 0; i < nx; i++)
            INTEGER(pivot)[i] = i+1;
    double *work = (double *) R_alloc(nx, sizeof(double));
    int job = 1;
    x = PROTECT(duplicate(x));

    /* QR decomposition with Linpack */
    F77_CALL(dqrdc)(REAL(x), &nr, &nr, &nx, REAL(qraux),
                    INTEGER(pivot), work, &job);

    /* pack up */
    SEXP qr = PROTECT(allocVector(VECSXP, 4));
    SEXP labs = PROTECT(allocVector(STRSXP, 4));
    SET_STRING_ELT(labs, 0, mkChar("qr"));
    SET_STRING_ELT(labs, 1, mkChar("rank"));
    SET_STRING_ELT(labs, 2, mkChar("qraux"));
    SET_STRING_ELT(labs, 3, mkChar("pivot"));
    setAttrib(qr, R_NamesSymbol, labs);
    SEXP cl = PROTECT(allocVector(STRSXP, 1));
    SET_STRING_ELT(cl, 0, mkChar("qr"));
    classgets(qr, cl);
    UNPROTECT(2); /* cl, labs */
    SET_VECTOR_ELT(qr, 0, x);
    SET_VECTOR_ELT(qr, 1, ScalarInteger(nx)); /* not really the rank,
                                                 but no. of columns */
    SET_VECTOR_ELT(qr, 2, qraux);
    SET_VECTOR_ELT(qr, 3, pivot);
    UNPROTECT(4); /* qr, x, pivot, qraux */
    return qr;
}


cheers, Jari Oksanen
________________________________________
From: R-devel <r-devel-bounces at r-project.org> on behalf of Martin Maechler <maechler at stat.math.ethz.ch>
Sent: 25 October 2016 11:08
To: Wojciech Musial (Voitek)
Cc: R-devel at r-project.org
Subject: Re: [Rd] typo or stale info in qr man

>>>>> Wojciech Musial (Voitek) <wojciech.musial at gmail.com>
>>>>>     on Mon, 24 Oct 2016 15:07:55 -0700 writes:

    > man for `qr` says that the function uses LINPACK's DQRDC, while it in
    > fact uses DQRDC2.

which is a modification of LINPACK's DQRDC.

But you are right, and I have added to the help file (and a tiny
bit to the comments in the Fortran source).

When this change was done > 20 years ago, it was still hoped
that the numerical linear algebra community or more specifically
those behind LAPACK would eventually provide this functionality
with LAPACK (and we would then use that),
but that has never happened according to my knowledge.

Thank you for the 'heads up'.

Martin Maechler
ETH Zurich

______________________________________________
R-devel at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-devel


From pdalgd at gmail.com  Tue Oct 25 13:00:37 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Tue, 25 Oct 2016 13:00:37 +0200
Subject: [Rd] typo or stale info in qr man
In-Reply-To: <22543.4878.559316.78350@stat.math.ethz.ch>
References: <CACPpiHS11GEDAULwOT9T8TY7Kf87BEdP5WqnrqhSCUbyPd2u-Q@mail.gmail.com>
	<22543.4878.559316.78350@stat.math.ethz.ch>
Message-ID: <906E4147-A37B-405D-B64D-D1A2C6B5DD25@gmail.com>


On 25 Oct 2016, at 10:08 , Martin Maechler <maechler at stat.math.ethz.ch> wrote:

>>>>>> Wojciech Musial (Voitek) <wojciech.musial at gmail.com>
>>>>>>    on Mon, 24 Oct 2016 15:07:55 -0700 writes:
> 
>> man for `qr` says that the function uses LINPACK's DQRDC, while it in
>> fact uses DQRDC2.
> 
> which is a modification of LINPACK's DQRDC.
> 
> But you are right, and I have added to the help file (and a tiny
> bit to the comments in the Fortran source).
> 
> When this change was done > 20 years ago, it was still hoped 
> that the numerical linear algebra community or more specifically
> those behind LAPACK would eventually provide this functionality
> with LAPACK (and we would then use that),
> but that has never happened according to my knowledge.
> 

I had some thoughts on this recently and resolved that the base issue is that R wants successive (Gram/Schmidt-type) orthogonalization of the design matrix, not really QR as such. 

The LINPACK QR routine happens to work by orthogonalization, but it is far from the only way of doing QR, and most likely not the "best" one (speedwise/precisionwise) if a QR decompositiion as such is the target. (Pivoting is only part of the story)

lm() and associates (notably anova()) relies so much on successive terms being orthogonalized that method="qr" really is a misnomer. For much the same reason, it really is too much to expect that numerical analysts would enforce orthogonality features on a general QR-decomposer. 

I suppose that if we want to be free of LINPACK, we may need to step back and write our own orthogonalization routines based on other routines in LAPACK or on the BLAS directly.

-pd

> Thank you for the 'heads up'.
> 
> Martin Maechler
> ETH Zurich
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From plummerm at iarc.fr  Tue Oct 25 19:22:59 2016
From: plummerm at iarc.fr (Martyn Plummer)
Date: Tue, 25 Oct 2016 17:22:59 +0000
Subject: [Rd] Support for signing R packages with GPG
In-Reply-To: <CABFfbXv=ERj+1atPDP_6ZjYE9xi6r+CVEk4sEqHjSMEZz21Qbw@mail.gmail.com>
References: <CABFfbXv=ERj+1atPDP_6ZjYE9xi6r+CVEk4sEqHjSMEZz21Qbw@mail.gmail.com>
Message-ID: <1477416100.16944.377.camel@iarc.fr>

Thanks Jeroen. The R Foundation has recently formed a working group to
look into package authentication. There are basically two models. One
is the GPG based model you describe; the other is to use X.509 as
implemented in the PKI package. It's not yet clear which way to go but
we are thinking about it.

Martyn


On Sun, 2016-10-23 at 18:37 +0200, Jeroen Ooms wrote:
> I would like to propose adding experimental support for including a
> PGP signature in R source packages. This would make it possible to
> verify the identity of the package author and integrity of the
> package
> sources.
> 
> There are two ways to implement this. Assuming GnuPG is on the PATH,
> the CMD build script could call:
> 
> ? gpg --clearsign MD5 -o MD5.gpg
> 
> Alternatively the 'gpg' R package provides a more portable method via
> the gpgme C library. This method works on Windows / macOS as well.
> 
> ? writeLines(gpg::gpg_sign("MD5"), "MD5.gpg")
> 
> Attached is an example implementation of the latter (also available
> at
> https://git.io/vPb9G) which has been tested with several versions of
> GnuPG. It exposes an optional flag for CMD build, i.e:
> 
> ? R CMD build somepkg --sign
> ? R CMD build somepkg --sign=jeroen.ooms at stat.ucla.edu
> 
> The --sign flag creates a signature for the MD5 file [1] in the
> source
> package and saves it as MD5.gpg (similar to a Debian 'Release.gpg'
> file [2]). Obviously the package author or build server needs to have
> a suitable private key in the local keyring.
> 
> 
> ## Signature verification
> 
> Once R supports signed packages, we can develop a system to take
> advantage of such signatures. The verification itself can easily be
> implemented via 'gpg --verify' or via gpg::gpg_verify() and could be
> performed without changes in R itself. The difficult part in GPG
> comes
> from defining which peers should be trusted.
> 
> But even without a 'web of trust' there are several ways one can
> immediately take advantage of signatures. For example, when a
> installing a package update or dev-version of a package, we can
> verify
> that the signature of the update matches that of the currently
> installed package. This would prevent the type of attacks where an
> intermediate party pushes a fake malicious update for a popular R
> package via e.g. a hacked CRAN mirror.
> 
> Eventually, CRAN could consider allowing signatures as a secure
> alternative to confirmation emails, and signing packages on the build
> servers with a CRAN GPG key, similar to Debian repositories. For now,
> at least establishing a format for (optionally) signing packages
> would
> be a great first step.
> 
> 
> [1] Eventually we should add SHA256 and SHA256.sig in addition to MD5
> [2] https://cran.r-project.org/web/packages/gpg/vignettes/intro.html#
> debian_example
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel-----------------------------------------------------------------------
This message and its attachments are strictly confidenti...{{dropped:8}}


From henrik.bengtsson at gmail.com  Wed Oct 26 04:44:22 2016
From: henrik.bengtsson at gmail.com (Henrik Bengtsson)
Date: Tue, 25 Oct 2016 19:44:22 -0700
Subject: [Rd] BUG?: On Linux setTimeLimit() fails to propagate timeout error
 when it occurs (works on Windows)
Message-ID: <CAFDcVCStodbQMS4TffimW69qvVutCX8FheDNxf1o_Ejpmu9NQg@mail.gmail.com>

setTimeLimit(elapsed=1) causes a timeout error whenever a call takes
more than one second.  For instance, this is how it works on Windows
(R 3.3.1):

> setTimeLimit(elapsed=1)
> Sys.sleep(10); message("done")
Error in Sys.sleep(10) : reached elapsed time limit

Also, the error propagates immediately and causes an interrupt after ~1 second;

> system.time({ Sys.sleep(10); message("done") })
Error in Sys.sleep(10) : reached elapsed time limit
Timing stopped at: 0.01 0 1.02

This works as expected.  However, on Linux (R 3.3.1 but also e.g.
2.11.0, 2.15.3) I get:

> setTimeLimit(elapsed=1)
> system.time({ Sys.sleep(10); message("done") })
Error in Sys.sleep(10) : reached elapsed time limit
Timing stopped at: 0 0 10.01

Note how the timeout error is signaled, but for some reason, it does
not interrupt the Sys.sleep(10) call until after it finishes after 10
seconds.  If you change to Sys.sleep(60) it will take 1 minute. Note
that the following print("done") is not called, so the timeout error
does propagate immediately after Sys.sleep() but not before / during.

This looks like a bug to me.  Can anyone on macOS confirm whether this
is also a problem there or not?

/Henrik

> sessionInfo()
R version 3.3.1 (2016-06-21)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows XP x64 (build 2600) Service Pack 3

> sessionInfo()
R version 3.3.1 (2016-06-21)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 16.04.1 LTS

> sessionInfo()
R version 2.11.0 (2010-04-22)
x86_64-unknown-linux-gnu

sessionInfo()
R version 2.15.3 (2013-03-01)
Platform: x86_64-unknown-linux-gnu (64-bit)


From spencer.graves at prodsyse.com  Wed Oct 26 05:02:29 2016
From: spencer.graves at prodsyse.com (Spencer Graves)
Date: Tue, 25 Oct 2016 22:02:29 -0500
Subject: [Rd] BUG?: On Linux setTimeLimit() fails to propagate timeout
 error when it occurs (works on Windows)
In-Reply-To: <CAFDcVCStodbQMS4TffimW69qvVutCX8FheDNxf1o_Ejpmu9NQg@mail.gmail.com>
References: <CAFDcVCStodbQMS4TffimW69qvVutCX8FheDNxf1o_Ejpmu9NQg@mail.gmail.com>
Message-ID: <21e7967d-866d-11f9-4be6-6261bb120ee5@prodsyse.com>



On 10/25/2016 9:44 PM, Henrik Bengtsson wrote:
> setTimeLimit(elapsed=1) causes a timeout error whenever a call takes
> more than one second.  For instance, this is how it works on Windows
> (R 3.3.1):
>
>> setTimeLimit(elapsed=1)
>> Sys.sleep(10); message("done")
> Error in Sys.sleep(10) : reached elapsed time limit
>
> Also, the error propagates immediately and causes an interrupt after ~1 second;
>
>> system.time({ Sys.sleep(10); message("done") })
> Error in Sys.sleep(10) : reached elapsed time limit
> Timing stopped at: 0.01 0 1.02
>
> This works as expected.  However, on Linux (R 3.3.1 but also e.g.
> 2.11.0, 2.15.3) I get:
>
>> setTimeLimit(elapsed=1)
>> system.time({ Sys.sleep(10); message("done") })
> Error in Sys.sleep(10) : reached elapsed time limit
> Timing stopped at: 0 0 10.01
>
> Note how the timeout error is signaled, but for some reason, it does
> not interrupt the Sys.sleep(10) call until after it finishes after 10
> seconds.  If you change to Sys.sleep(60) it will take 1 minute. Note
> that the following print("done") is not called, so the timeout error
> does propagate immediately after Sys.sleep() but not before / during.
>
> This looks like a bug to me.  Can anyone on macOS confirm whether this
> is also a problem there or not?


 > setTimeLimit(elapsed=1)
 > system.time({ Sys.sleep(10); message("done") })
Error in Sys.sleep(10) : reached elapsed time limit
Timing stopped at: 0.003 0.004 0.978
 >
 > sessionInfo()
R version 3.3.1 (2016-06-21)
Platform: x86_64-apple-darwin13.4.0 (64-bit)
Running under: OS X 10.11.6 (El Capitan)

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils
[5] datasets  methods   base

loaded via a namespace (and not attached):
[1] rsconnect_0.5 tools_3.3.1
Error: reached elapsed time limit

> /Henrik
>
>> sessionInfo()
> R version 3.3.1 (2016-06-21)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Running under: Windows XP x64 (build 2600) Service Pack 3
>
>> sessionInfo()
> R version 3.3.1 (2016-06-21)
> Platform: x86_64-pc-linux-gnu (64-bit)
> Running under: Ubuntu 16.04.1 LTS
>
>> sessionInfo()
> R version 2.11.0 (2010-04-22)
> x86_64-unknown-linux-gnu
>
> sessionInfo()
> R version 2.15.3 (2013-03-01)
> Platform: x86_64-unknown-linux-gnu (64-bit)
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From maechler at stat.math.ethz.ch  Wed Oct 26 09:21:35 2016
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 26 Oct 2016 09:21:35 +0200
Subject: [Rd] BUG?: On Linux setTimeLimit() fails to propagate timeout
 error when it occurs (works on Windows)
In-Reply-To: <21e7967d-866d-11f9-4be6-6261bb120ee5@prodsyse.com>
References: <CAFDcVCStodbQMS4TffimW69qvVutCX8FheDNxf1o_Ejpmu9NQg@mail.gmail.com>
	<21e7967d-866d-11f9-4be6-6261bb120ee5@prodsyse.com>
Message-ID: <22544.22911.2726.453164@stat.math.ethz.ch>

>>>>> Spencer Graves <spencer.graves at prodsyse.com>
>>>>>     on Tue, 25 Oct 2016 22:02:29 -0500 writes:

    > On 10/25/2016 9:44 PM, Henrik Bengtsson wrote:
    >> setTimeLimit(elapsed=1) causes a timeout error whenever a call takes
    >> more than one second.  For instance, this is how it works on Windows
    >> (R 3.3.1):
    >> 
    >>> setTimeLimit(elapsed=1)
    >>> Sys.sleep(10); message("done")
    >> Error in Sys.sleep(10) : reached elapsed time limit
    >> 
    >> Also, the error propagates immediately and causes an interrupt after ~1 second;
    >> 
    >>> system.time({ Sys.sleep(10); message("done") })
    >> Error in Sys.sleep(10) : reached elapsed time limit
    >> Timing stopped at: 0.01 0 1.02
    >> 
    >> This works as expected.  However, on Linux (R 3.3.1 but also e.g.
    >> 2.11.0, 2.15.3) I get:
    >> 
    >>> setTimeLimit(elapsed=1)
    >>> system.time({ Sys.sleep(10); message("done") })
    >> Error in Sys.sleep(10) : reached elapsed time limit
    >> Timing stopped at: 0 0 10.01
    >> 
    >> Note how the timeout error is signaled, but for some reason, it does
    >> not interrupt the Sys.sleep(10) call until after it finishes after 10
    >> seconds.  If you change to Sys.sleep(60) it will take 1 minute. Note
    >> that the following print("done") is not called, so the timeout error
    >> does propagate immediately after Sys.sleep() but not before / during.
    >> 
    >> This looks like a bug to me.  Can anyone on macOS confirm whether this
    >> is also a problem there or not?


    >> setTimeLimit(elapsed=1)
    >> system.time({ Sys.sleep(10); message("done") })
    > Error in Sys.sleep(10) : reached elapsed time limit
    > Timing stopped at: 0.003 0.004 0.978
    >> 
    >> sessionInfo()
    > R version 3.3.1 (2016-06-21)
    > Platform: x86_64-apple-darwin13.4.0 (64-bit)
    > Running under: OS X 10.11.6 (El Capitan)

Thank you, Spencer.

Indeed, confirmed here (Linux Fedora 24) for the most current
'R-devel' and "R 3.3.2 RC".

Also, this "not quite terminating" on Linux is not limited to
Sys.sleep() in case someone was wondering:

> setTimeLimit(elapsed=0.5) ; system.time(P <- sfsmisc::primes(1e7))
   user  system elapsed 
  0.227   0.055   0.281 
> str(P)
 int [1:664579] 2 3 5 7 11 13 17 19 23 29 ...
> setTimeLimit(elapsed=0.5) ; system.time(P <- sfsmisc::primes(3e7))
Error in sfsmisc::primes(3e+07) : reached elapsed time limit
Timing stopped at: 0.538 0.132 0.671


This *is* embarrassing a bit;  ..  probably too late to be fixed
for 3.3.2 .. (and something I'd rather leave to others to fix).

It may be that this has never worked on Linux, or then worked in
Linuxen where some interrupt behavior was different.
At least on my current Linux it does not work, all the way back
to R 2.11.1 .. and setTimeLimit() has not existed for much longer...

Martin


    > locale:
    > [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

    > attached base packages:
    > [1] stats     graphics  grDevices utils
    > [5] datasets  methods   base

    > loaded via a namespace (and not attached):
    > [1] rsconnect_0.5 tools_3.3.1
    > Error: reached elapsed time limit

    >> /Henrik
    >> 
    >>> sessionInfo()
    >> R version 3.3.1 (2016-06-21)
    >> Platform: x86_64-w64-mingw32/x64 (64-bit)
    >> Running under: Windows XP x64 (build 2600) Service Pack 3
    >> 
    >>> sessionInfo()
    >> R version 3.3.1 (2016-06-21)
    >> Platform: x86_64-pc-linux-gnu (64-bit)
    >> Running under: Ubuntu 16.04.1 LTS
    >> 
    >>> sessionInfo()
    >> R version 2.11.0 (2010-04-22)
    >> x86_64-unknown-linux-gnu
    >> 
    >> sessionInfo()
    >> R version 2.15.3 (2013-03-01)
    >> Platform: x86_64-unknown-linux-gnu (64-bit)
    >>


From pdalgd at gmail.com  Wed Oct 26 11:07:32 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 26 Oct 2016 11:07:32 +0200
Subject: [Rd] BUG?: On Linux setTimeLimit() fails to propagate timeout
	error when it occurs (works on Windows)
In-Reply-To: <CAFDcVCStodbQMS4TffimW69qvVutCX8FheDNxf1o_Ejpmu9NQg@mail.gmail.com>
References: <CAFDcVCStodbQMS4TffimW69qvVutCX8FheDNxf1o_Ejpmu9NQg@mail.gmail.com>
Message-ID: <7A6244C9-6F28-4D26-A0CD-9926C1457CAA@gmail.com>


On 26 Oct 2016, at 04:44 , Henrik Bengtsson <henrik.bengtsson at gmail.com> wrote:

> This looks like a bug to me.  Can anyone on macOS confirm whether this
> is also a problem there or not?

I don't know whether it is a problem ( ;-) ), but it does the same thing (checked Mavericks, Yosemite and Sierra)

-pd

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From bhh at xs4all.nl  Wed Oct 26 11:22:37 2016
From: bhh at xs4all.nl (Berend Hasselman)
Date: Wed, 26 Oct 2016 11:22:37 +0200
Subject: [Rd] BUG?: On Linux setTimeLimit() fails to propagate timeout
	error when it occurs (works on Windows)
In-Reply-To: <CAFDcVCStodbQMS4TffimW69qvVutCX8FheDNxf1o_Ejpmu9NQg@mail.gmail.com>
References: <CAFDcVCStodbQMS4TffimW69qvVutCX8FheDNxf1o_Ejpmu9NQg@mail.gmail.com>
Message-ID: <8995051E-628D-4536-A64C-517A9188F416@xs4all.nl>


> On 26 Oct 2016, at 04:44, Henrik Bengtsson <henrik.bengtsson at gmail.com> wrote:
> .......
> This looks like a bug to me.  Can anyone on macOS confirm whether this
> is also a problem there or not?
> 


Tried it on macOS El Capitan and got this (running in R.app with R version 3.3.2 RC (2016-10-23 r71574):

> setTimeLimit(elapsed=1)
> system.time({ Sys.sleep(10); message("done") })
Error in Sys.sleep(10) : reached elapsed time limit
Timing stopped at: 0.113 0.042 10.038 

Berend


From maechler at stat.math.ethz.ch  Wed Oct 26 11:52:55 2016
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 26 Oct 2016 11:52:55 +0200
Subject: [Rd] improve 'package not installed' load errors?
In-Reply-To: <923577ec-5b0e-d71c-6244-b39952fb00e7@gmail.com>
References: <CAJXgQP1AAs2oXZX1wbsCcPCsUYOjG-VXTPZ_zeyq9co2C5B0rQ@mail.gmail.com>
	<923577ec-5b0e-d71c-6244-b39952fb00e7@gmail.com>
Message-ID: <22544.31991.783940.23504@stat.math.ethz.ch>

>>>>> Duncan Murdoch <murdoch.duncan at gmail.com>
>>>>>     on Mon, 24 Oct 2016 14:54:16 -0400 writes:

    > On 24/10/2016 1:51 PM, Kevin Ushey wrote:
    >> Hi R-devel,
    >> 
    >> One of the more common issues that new R users see, and become stumped
    >> by, is error messages during package load of the form:
    >> 
    >> > library(ggplot2)
    >> Error in loadNamespace(j <- i[[1L]], c(lib.loc, .libPaths()),
    >> versionCheck = vI[[j]]) :
    >> there is no package called 'Rcpp'
    >> Error: package or namespace load failed for 'ggplot2'
    >> 
    >> Typically, error messages of this form are caused simply by one or
    >> more dependent packages (in this case, 'Rcpp') not being installed or
    >> available on the current library paths. (A side question, which I do
    >> not know the answer to, is how users get themselves into this state.)

    > I think one way to get here is to be running with several libraries.  
    > You install ggplot2 while Rcpp is available, but in a different part of 
    > the .libPaths list, then in a later session try to use it with a 
    > different .libPaths setting.
    >> 
    >> I believe it would be helpful for new users if the error message
    >> reported here was a bit more direct, e.g.
    >> 
    >> > library(ggplot2)
    >> Error: 'ggplot2' depends on package 'Rcpp', but 'Rcpp' is not installed
    >> consider installing 'Rcpp' with install.packages("Rcpp")

    > The risk with this message is that Rcpp may really be installed, but 
    > it's just not currently on .libPaths.  Detecting that situation and 
    > reporting on it looks like it would be relatively hard:  it would mean 
    > the ggplot2 installation needs to record where it found all 
    > dependencies, and if at some later time it doesn't find one, see if that 
    > location still exists and would still work (in which case the message 
    > should suggest modifying .libPaths).  I think that's too much work.

    > Even a simple change like

    > Error: 'ggplot2' depends on package 'Rcpp', but 'Rcpp' was not found


    > might not be easy (which function knows both names?)  

    > However, if you want to suggest a patch to implement this,
    > I would take a look. 

I woul want to take a look, even before that. Our current error
handling here should be revised, I think : 

For library() the user sees *two* error messages: In my "setup"
((where I did fiddle with .libPaths() to provoke the error,
  exactly as Duncan mentioned)), I have

>> > library(ggplot2)

1. >> Error in loadNamespace(i, c(lib.loc, .libPaths()), versionCheck = vI[[i]]) : 
>>   there is no package called ?gtable?

2. >> Error: package or namespace load failed for ?ggplot2?

and together they at least give a good clue to the user (yes,
not easy enough for the beginner, I agree).

However, because the above is already a kludge (only one of the
two error messages is part of the error that is signalled !!!),
the situation is even worse if the user (or her code) uses require():

>> > require(ggplot2)
>> Loading required package: ggplot2
>> Error in loadNamespace(i, c(lib.loc, .libPaths()), versionCheck = vI[[i]]) : 
>>   there is no package called ?gtable?
>> > 

Only the 2nd of  library()'s "Error" messages is transfered to require()
[or any other caller of library() !]
and that is in itself very unsatisfactory.


    >> In other words, it might be helpful to avoid printing the
    >> 'loadNamespace()' call on error (since it's mostly just scary /
    >> uninformative), and check up-front that the package is installed
    >> before attempting to call 'loadNamespace()'.

well, yes, one should not use try() there, but tryCatch() anyway :
try() is a wrapper around tryCatch() and I agree the error
message should not be printed which try() *does* by default, but
should be *combined* with the "2nd one" to one error.. which
then also is automatically "transfered" to require() or another caller.

There is a small problem for producing a really nice error
message : It is *wrong* to assume we can easily use  sub() or
similar to get the dependecy package name ('gtable' or 'Rcpp' in
the above examples) from the error message :

The error message may be and often is translated {{apart from the
 "Error in " of the first error message which is  never
 translated, it seems, but that is different issue(buglet) }} :

a) French:

> Sys.setenv("LANGUAGE"="fr"); Sys.setlocale("LC_MESSAGES", "fr_FR.UTF-8")
> library(ggplot2)
Error in loadNamespace(i, c(lib.loc, .libPaths()), versionCheck = vI[[i]]) : 
  aucun package nomm? ?gtable? n'est trouv?
Erreur : le chargement du package ou de l'espace de noms a ?chou? pour ?ggplot2?

b) German:

> Sys.setenv("LANGUAGE"="de"); Sys.setlocale("LC_MESSAGES", "de_CH.UTF-8")
[1] "de_CH.UTF-8"
> library(ggplot2)
Error in loadNamespace(i, c(lib.loc, .libPaths()), versionCheck = vI[[i]]) : 
  es gibt kein Paket namens ?gtable?
Fehler: Laden von Paket oder Namensraum f?r ?ggplot2? fehlgeschlagen
> 

c) Japanase :

> Sys.setenv("LANGUAGE"="ja"); Sys.setlocale("LC_MESSAGES", "ja_JP.UTF-8")
[1] "ja_JP.UTF-8"
> library(ggplot2)
Error in loadNamespace(i, c(lib.loc, .libPaths()), versionCheck = vI[[i]]) : 
   ?gtable? ????????????????? 
 ???:  ?ggplot2? ???????????????????????????? 
> 

We could try to look for the sQuote(.)'d package name
independently of the translation of the error message and use
that in the "merged" error message.


Martin


    >>  I'm sure a number of
    >> novice users will still just throw their hands up in the air and say
    >> "I don't know what to do", but I think this would help steer a number
    >> of users in the right direction.
    >> 
    >> (The prescription to suggest installing a package from CRAN if
    >> available might be a step too far, but I think making it more clear
    >> that the error is due to a missing dependent package would help.)
    >> 
    >> Any thoughts?
    >> Kevin


From murdoch.duncan at gmail.com  Wed Oct 26 13:13:21 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 26 Oct 2016 07:13:21 -0400
Subject: [Rd] improve 'package not installed' load errors?
In-Reply-To: <22544.31991.783940.23504@stat.math.ethz.ch>
References: <CAJXgQP1AAs2oXZX1wbsCcPCsUYOjG-VXTPZ_zeyq9co2C5B0rQ@mail.gmail.com>
	<923577ec-5b0e-d71c-6244-b39952fb00e7@gmail.com>
	<22544.31991.783940.23504@stat.math.ethz.ch>
Message-ID: <ef0fa638-2416-0195-8ad1-ee8dcca7eecf@gmail.com>

On 26/10/2016 5:52 AM, Martin Maechler wrote:
>>>>>> Duncan Murdoch <murdoch.duncan at gmail.com>
>>>>>>     on Mon, 24 Oct 2016 14:54:16 -0400 writes:
>
>     > On 24/10/2016 1:51 PM, Kevin Ushey wrote:
>     >> Hi R-devel,
>     >>
>     >> One of the more common issues that new R users see, and become stumped
>     >> by, is error messages during package load of the form:
>     >>
>     >> > library(ggplot2)
>     >> Error in loadNamespace(j <- i[[1L]], c(lib.loc, .libPaths()),
>     >> versionCheck = vI[[j]]) :
>     >> there is no package called 'Rcpp'
>     >> Error: package or namespace load failed for 'ggplot2'
>     >>
>     >> Typically, error messages of this form are caused simply by one or
>     >> more dependent packages (in this case, 'Rcpp') not being installed or
>     >> available on the current library paths. (A side question, which I do
>     >> not know the answer to, is how users get themselves into this state.)
>
>     > I think one way to get here is to be running with several libraries.
>     > You install ggplot2 while Rcpp is available, but in a different part of
>     > the .libPaths list, then in a later session try to use it with a
>     > different .libPaths setting.
>     >>
>     >> I believe it would be helpful for new users if the error message
>     >> reported here was a bit more direct, e.g.
>     >>
>     >> > library(ggplot2)
>     >> Error: 'ggplot2' depends on package 'Rcpp', but 'Rcpp' is not installed
>     >> consider installing 'Rcpp' with install.packages("Rcpp")
>
>     > The risk with this message is that Rcpp may really be installed, but
>     > it's just not currently on .libPaths.  Detecting that situation and
>     > reporting on it looks like it would be relatively hard:  it would mean
>     > the ggplot2 installation needs to record where it found all
>     > dependencies, and if at some later time it doesn't find one, see if that
>     > location still exists and would still work (in which case the message
>     > should suggest modifying .libPaths).  I think that's too much work.
>
>     > Even a simple change like
>
>     > Error: 'ggplot2' depends on package 'Rcpp', but 'Rcpp' was not found
>
>
>     > might not be easy (which function knows both names?)
>
>     > However, if you want to suggest a patch to implement this,
>     > I would take a look.
>
> I woul want to take a look, even before that. Our current error
> handling here should be revised, I think :

If you've got the time to do that, please do so.  My message really 
meant "I have too much on my plate right now to develop a patch, but 
this is important enough that I would evaluate one that you produced."

I think my "full plate" status is going to last until the end of the 
year; after that I may have some more free time.

Duncan Murdoch


>
> For library() the user sees *two* error messages: In my "setup"
> ((where I did fiddle with .libPaths() to provoke the error,
>   exactly as Duncan mentioned)), I have
>
>>>> library(ggplot2)
>
> 1. >> Error in loadNamespace(i, c(lib.loc, .libPaths()), versionCheck = vI[[i]]) :
>>>   there is no package called ?gtable?
>
> 2. >> Error: package or namespace load failed for ?ggplot2?
>
> and together they at least give a good clue to the user (yes,
> not easy enough for the beginner, I agree).
>
> However, because the above is already a kludge (only one of the
> two error messages is part of the error that is signalled !!!),
> the situation is even worse if the user (or her code) uses require():
>
>>>> require(ggplot2)
>>> Loading required package: ggplot2
>>> Error in loadNamespace(i, c(lib.loc, .libPaths()), versionCheck = vI[[i]]) :
>>>   there is no package called ?gtable?
>>>>
>
> Only the 2nd of  library()'s "Error" messages is transfered to require()
> [or any other caller of library() !]
> and that is in itself very unsatisfactory.
>
>
>     >> In other words, it might be helpful to avoid printing the
>     >> 'loadNamespace()' call on error (since it's mostly just scary /
>     >> uninformative), and check up-front that the package is installed
>     >> before attempting to call 'loadNamespace()'.
>
> well, yes, one should not use try() there, but tryCatch() anyway :
> try() is a wrapper around tryCatch() and I agree the error
> message should not be printed which try() *does* by default, but
> should be *combined* with the "2nd one" to one error.. which
> then also is automatically "transfered" to require() or another caller.
>
> There is a small problem for producing a really nice error
> message : It is *wrong* to assume we can easily use  sub() or
> similar to get the dependecy package name ('gtable' or 'Rcpp' in
> the above examples) from the error message :
>
> The error message may be and often is translated {{apart from the
>  "Error in " of the first error message which is  never
>  translated, it seems, but that is different issue(buglet) }} :
>
> a) French:
>
>> Sys.setenv("LANGUAGE"="fr"); Sys.setlocale("LC_MESSAGES", "fr_FR.UTF-8")
>> library(ggplot2)
> Error in loadNamespace(i, c(lib.loc, .libPaths()), versionCheck = vI[[i]]) :
>   aucun package nomm? ?gtable? n'est trouv?
> Erreur : le chargement du package ou de l'espace de noms a ?chou? pour ?ggplot2?
>
> b) German:
>
>> Sys.setenv("LANGUAGE"="de"); Sys.setlocale("LC_MESSAGES", "de_CH.UTF-8")
> [1] "de_CH.UTF-8"
>> library(ggplot2)
> Error in loadNamespace(i, c(lib.loc, .libPaths()), versionCheck = vI[[i]]) :
>   es gibt kein Paket namens ?gtable?
> Fehler: Laden von Paket oder Namensraum f?r ?ggplot2? fehlgeschlagen
>>
>
> c) Japanase :
>
>> Sys.setenv("LANGUAGE"="ja"); Sys.setlocale("LC_MESSAGES", "ja_JP.UTF-8")
> [1] "ja_JP.UTF-8"
>> library(ggplot2)
> Error in loadNamespace(i, c(lib.loc, .libPaths()), versionCheck = vI[[i]]) :
>    ?gtable? ?????????????????
>  ???:  ?ggplot2? ????????????????????????????
>>
>
> We could try to look for the sQuote(.)'d package name
> independently of the translation of the error message and use
> that in the "merged" error message.
>
>
> Martin
>
>
>     >>  I'm sure a number of
>     >> novice users will still just throw their hands up in the air and say
>     >> "I don't know what to do", but I think this would help steer a number
>     >> of users in the right direction.
>     >>
>     >> (The prescription to suggest installing a package from CRAN if
>     >> available might be a step too far, but I think making it more clear
>     >> that the error is due to a missing dependent package would help.)
>     >>
>     >> Any thoughts?
>     >> Kevin
>


From mikko.korpela at helsinki.fi  Wed Oct 26 14:25:22 2016
From: mikko.korpela at helsinki.fi (Mikko Korpela)
Date: Wed, 26 Oct 2016 15:25:22 +0300
Subject: [Rd] A few typos in config.site
Message-ID: <e63fec01-5a1f-321d-d04a-e7762b014352@helsinki.fi>

I noticed the following typos in the file "config.site":

The word "compilier" should be "compiler", occurs twice (in the R-devel 
version). Also, "It not" should be "If not" and "overriden" should be 
"overridden".

-- 
Mikko Korpela
Department of Geosciences and Geography
University of Helsinki


From luke-tierney at uiowa.edu  Wed Oct 26 18:22:01 2016
From: luke-tierney at uiowa.edu (luke-tierney at uiowa.edu)
Date: Wed, 26 Oct 2016 11:22:01 -0500
Subject: [Rd] improve 'package not installed' load errors?
In-Reply-To: <22544.31991.783940.23504@stat.math.ethz.ch>
References: <CAJXgQP1AAs2oXZX1wbsCcPCsUYOjG-VXTPZ_zeyq9co2C5B0rQ@mail.gmail.com>
	<923577ec-5b0e-d71c-6244-b39952fb00e7@gmail.com>
	<22544.31991.783940.23504@stat.math.ethz.ch>
Message-ID: <alpine.DEB.2.20.1610261119010.2355@luke-Latitude>

This might be a good opportunity for developing some error classes for
signaling these errors that can be used to programmatically do
something more useful at the library/require. I can try to help with
that.

Best,

luke

On Wed, 26 Oct 2016, Martin Maechler wrote:

>>>>>> Duncan Murdoch <murdoch.duncan at gmail.com>
>>>>>>     on Mon, 24 Oct 2016 14:54:16 -0400 writes:
>
>    > On 24/10/2016 1:51 PM, Kevin Ushey wrote:
>    >> Hi R-devel,
>    >>
>    >> One of the more common issues that new R users see, and become stumped
>    >> by, is error messages during package load of the form:
>    >>
>    >> > library(ggplot2)
>    >> Error in loadNamespace(j <- i[[1L]], c(lib.loc, .libPaths()),
>    >> versionCheck = vI[[j]]) :
>    >> there is no package called 'Rcpp'
>    >> Error: package or namespace load failed for 'ggplot2'
>    >>
>    >> Typically, error messages of this form are caused simply by one or
>    >> more dependent packages (in this case, 'Rcpp') not being installed or
>    >> available on the current library paths. (A side question, which I do
>    >> not know the answer to, is how users get themselves into this state.)
>
>    > I think one way to get here is to be running with several libraries.
>    > You install ggplot2 while Rcpp is available, but in a different part of
>    > the .libPaths list, then in a later session try to use it with a
>    > different .libPaths setting.
>    >>
>    >> I believe it would be helpful for new users if the error message
>    >> reported here was a bit more direct, e.g.
>    >>
>    >> > library(ggplot2)
>    >> Error: 'ggplot2' depends on package 'Rcpp', but 'Rcpp' is not installed
>    >> consider installing 'Rcpp' with install.packages("Rcpp")
>
>    > The risk with this message is that Rcpp may really be installed, but
>    > it's just not currently on .libPaths.  Detecting that situation and
>    > reporting on it looks like it would be relatively hard:  it would mean
>    > the ggplot2 installation needs to record where it found all
>    > dependencies, and if at some later time it doesn't find one, see if that
>    > location still exists and would still work (in which case the message
>    > should suggest modifying .libPaths).  I think that's too much work.
>
>    > Even a simple change like
>
>    > Error: 'ggplot2' depends on package 'Rcpp', but 'Rcpp' was not found
>
>
>    > might not be easy (which function knows both names?) 
>
>    > However, if you want to suggest a patch to implement this,
>    > I would take a look. 
>
> I woul want to take a look, even before that. Our current error
> handling here should be revised, I think : 
>
> For library() the user sees *two* error messages: In my "setup"
> ((where I did fiddle with .libPaths() to provoke the error,
>  exactly as Duncan mentioned)), I have
>
>>> > library(ggplot2)
>
> 1. >> Error in loadNamespace(i, c(lib.loc, .libPaths()), versionCheck = vI[[i]]) :
>>>   there is no package called ?gtable?
>
> 2. >> Error: package or namespace load failed for ?ggplot2?
>
> and together they at least give a good clue to the user (yes,
> not easy enough for the beginner, I agree).
>
> However, because the above is already a kludge (only one of the
> two error messages is part of the error that is signalled !!!),
> the situation is even worse if the user (or her code) uses require():
>
>>> > require(ggplot2)
>>> Loading required package: ggplot2
>>> Error in loadNamespace(i, c(lib.loc, .libPaths()), versionCheck = vI[[i]]) :
>>>   there is no package called ?gtable?
>>> > 
>
> Only the 2nd of  library()'s "Error" messages is transfered to require()
> [or any other caller of library() !]
> and that is in itself very unsatisfactory.
>
>
>    >> In other words, it might be helpful to avoid printing the
>    >> 'loadNamespace()' call on error (since it's mostly just scary /
>    >> uninformative), and check up-front that the package is installed
>    >> before attempting to call 'loadNamespace()'.
>
> well, yes, one should not use try() there, but tryCatch() anyway :
> try() is a wrapper around tryCatch() and I agree the error
> message should not be printed which try() *does* by default, but
> should be *combined* with the "2nd one" to one error.. which
> then also is automatically "transfered" to require() or another caller.
>
> There is a small problem for producing a really nice error
> message : It is *wrong* to assume we can easily use  sub() or
> similar to get the dependecy package name ('gtable' or 'Rcpp' in
> the above examples) from the error message :
>
> The error message may be and often is translated {{apart from the
> "Error in " of the first error message which is  never
> translated, it seems, but that is different issue(buglet) }} :
>
> a) French:
>
>> Sys.setenv("LANGUAGE"="fr"); Sys.setlocale("LC_MESSAGES", "fr_FR.UTF-8")
>> library(ggplot2)
> Error in loadNamespace(i, c(lib.loc, .libPaths()), versionCheck = vI[[i]]) :
>  aucun package nomm? ?gtable? n'est trouv?
> Erreur : le chargement du package ou de l'espace de noms a ?chou? pour ?ggplot2?
>
> b) German:
>
>> Sys.setenv("LANGUAGE"="de"); Sys.setlocale("LC_MESSAGES", "de_CH.UTF-8")
> [1] "de_CH.UTF-8"
>> library(ggplot2)
> Error in loadNamespace(i, c(lib.loc, .libPaths()), versionCheck = vI[[i]]) :
>  es gibt kein Paket namens ?gtable?
> Fehler: Laden von Paket oder Namensraum f?r ?ggplot2? fehlgeschlagen
>> 
>
> c) Japanase :
>
>> Sys.setenv("LANGUAGE"="ja"); Sys.setlocale("LC_MESSAGES", "ja_JP.UTF-8")
> [1] "ja_JP.UTF-8"
>> library(ggplot2)
> Error in loadNamespace(i, c(lib.loc, .libPaths()), versionCheck = vI[[i]]) :
>   ?gtable? ????????????????? 
> ???:  ?ggplot2? ???????????????????????????? 
>> 
>
> We could try to look for the sQuote(.)'d package name
> independently of the translation of the error message and use
> that in the "merged" error message.
>
>
> Martin
>
>
>    >>  I'm sure a number of
>    >> novice users will still just throw their hands up in the air and say
>    >> "I don't know what to do", but I think this would help steer a number
>    >> of users in the right direction.
>    >>
>    >> (The prescription to suggest installing a package from CRAN if
>    >> available might be a step too far, but I think making it more clear
>    >> that the error is due to a missing dependent package would help.)
>    >>
>    >> Any thoughts?
>    >> Kevin
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Luke Tierney
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu

From henrik.bengtsson at gmail.com  Wed Oct 26 21:54:52 2016
From: henrik.bengtsson at gmail.com (Henrik Bengtsson)
Date: Wed, 26 Oct 2016 12:54:52 -0700
Subject: [Rd] BUG?: On Linux setTimeLimit() fails to propagate timeout
 error when it occurs (works on Windows)
In-Reply-To: <8995051E-628D-4536-A64C-517A9188F416@xs4all.nl>
References: <CAFDcVCStodbQMS4TffimW69qvVutCX8FheDNxf1o_Ejpmu9NQg@mail.gmail.com>
	<8995051E-628D-4536-A64C-517A9188F416@xs4all.nl>
Message-ID: <CAFDcVCQmAAq_GYB5WUE2O25RkzCCpeMudJwQ3pCucp5MATAkXw@mail.gmail.com>

Thank you for the feedback and confirmations.  Interesting to see that
it's also reproducible on macOS expect for Spencer; that might
indicate a difference in builds.

BTW, my original post suggested that timeout error was for sure
detected while running Sys.sleep(10).  However, it could of course
also be that it is only detected after it finishes.


For troubleshooting, the help("setTimeLimit", package = "base") says that:

* "Time limits are checked whenever a user interrupt could occur. This
will happen frequently in R code and during Sys.sleep, but only at
points in compiled C and Fortran code identified by the code author."

The example here uses Sys.sleep(), which supports and detects user interrupts.


The timeout error message is thrown by the R_ProcessEvents(void)
function as defined in:

* src/unix/sys-unix.c
(https://github.com/wch/r-source/blob/trunk/src/unix/sys-unix.c#L421-L453)
* src/gnuwin32/system.c
(https://github.com/wch/r-source/blob/trunk/src/gnuwin32/system.c#L110-L140)

So, they're clearly different implementations on Windows and Unix.
Also, for the Unix implementation, the code differ based on
preprocessing directive HAVE_AQUA, which could explain why Spencer
observes a different behavior than Peter and Berend (all on macOS).


Whenever the R_CheckUserInterrupt() function is called it in turn
always calls R_ProcessEvents().  At the end, there is a code snippet -
if (R_interrupts_pending) onintr(); - which is Windows specific and
could be another important difference between Windows and Unix.  This
function is defined in:

* src/main/errors.c
(https://github.com/wch/r-source/blob/trunk/src/main/errors.c#L114-L134)


The do_setTimeLimit() function controls global variables cpuLimitValue
and elapsedLimitValue, which are checked in R_ProcessEvents(), but
other than setting the timeout limits I don't think it's involved in
the runtime checks. The do_setTimeLimit() is defined in:

* src/main/sysutils.c
(https://github.com/wch/r-source/blob/trunk/src/main/sysutils.c#L1692-L1736)


Unfortunately, right now, I've got little extra time to troubleshoot
this further.

/Henrik

On Wed, Oct 26, 2016 at 2:22 AM, Berend Hasselman <bhh at xs4all.nl> wrote:
>
>> On 26 Oct 2016, at 04:44, Henrik Bengtsson <henrik.bengtsson at gmail.com> wrote:
>> .......
>> This looks like a bug to me.  Can anyone on macOS confirm whether this
>> is also a problem there or not?
>>
>
>
> Tried it on macOS El Capitan and got this (running in R.app with R version 3.3.2 RC (2016-10-23 r71574):
>
>> setTimeLimit(elapsed=1)
>> system.time({ Sys.sleep(10); message("done") })
> Error in Sys.sleep(10) : reached elapsed time limit
> Timing stopped at: 0.113 0.042 10.038
>
> Berend
>


From pdalgd at gmail.com  Wed Oct 26 22:34:21 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 26 Oct 2016 22:34:21 +0200
Subject: [Rd] BUG?: On Linux setTimeLimit() fails to propagate timeout
	error when it occurs (works on Windows)
In-Reply-To: <CAFDcVCQmAAq_GYB5WUE2O25RkzCCpeMudJwQ3pCucp5MATAkXw@mail.gmail.com>
References: <CAFDcVCStodbQMS4TffimW69qvVutCX8FheDNxf1o_Ejpmu9NQg@mail.gmail.com>
	<8995051E-628D-4536-A64C-517A9188F416@xs4all.nl>
	<CAFDcVCQmAAq_GYB5WUE2O25RkzCCpeMudJwQ3pCucp5MATAkXw@mail.gmail.com>
Message-ID: <57E7E96A-D3F9-42F4-877D-56109CD38CC8@gmail.com>

Spencer also had tools and rsconnect loaded (via a namespace) but it doesn't seem to make a difference for me if I load them. It also doesn't seem to matter for me whether it is CRAN R, locally built R, Terminal, R.app. However, RStudio differs 

> setTimeLimit(elapsed=1)
Error: reached elapsed time limit
> setTimeLimit(elapsed=1)
Error: reached elapsed time limit
> setTimeLimit(elapsed=1); system.time({Sys.sleep(10);message("done")})
Error in Sys.sleep(10) : reached elapsed time limit
Timing stopped at: 0.003 0.003 0.733 

-pd


> On 26 Oct 2016, at 21:54 , Henrik Bengtsson <henrik.bengtsson at gmail.com> wrote:
> 
> Thank you for the feedback and confirmations.  Interesting to see that
> it's also reproducible on macOS expect for Spencer; that might
> indicate a difference in builds.
> 
> BTW, my original post suggested that timeout error was for sure
> detected while running Sys.sleep(10).  However, it could of course
> also be that it is only detected after it finishes.
> 
> 
> For troubleshooting, the help("setTimeLimit", package = "base") says that:
> 
> * "Time limits are checked whenever a user interrupt could occur. This
> will happen frequently in R code and during Sys.sleep, but only at
> points in compiled C and Fortran code identified by the code author."
> 
> The example here uses Sys.sleep(), which supports and detects user interrupts.
> 
> 
> The timeout error message is thrown by the R_ProcessEvents(void)
> function as defined in:
> 
> * src/unix/sys-unix.c
> (https://github.com/wch/r-source/blob/trunk/src/unix/sys-unix.c#L421-L453)
> * src/gnuwin32/system.c
> (https://github.com/wch/r-source/blob/trunk/src/gnuwin32/system.c#L110-L140)
> 
> So, they're clearly different implementations on Windows and Unix.
> Also, for the Unix implementation, the code differ based on
> preprocessing directive HAVE_AQUA, which could explain why Spencer
> observes a different behavior than Peter and Berend (all on macOS).
> 
> 
> Whenever the R_CheckUserInterrupt() function is called it in turn
> always calls R_ProcessEvents().  At the end, there is a code snippet -
> if (R_interrupts_pending) onintr(); - which is Windows specific and
> could be another important difference between Windows and Unix.  This
> function is defined in:
> 
> * src/main/errors.c
> (https://github.com/wch/r-source/blob/trunk/src/main/errors.c#L114-L134)
> 
> 
> The do_setTimeLimit() function controls global variables cpuLimitValue
> and elapsedLimitValue, which are checked in R_ProcessEvents(), but
> other than setting the timeout limits I don't think it's involved in
> the runtime checks. The do_setTimeLimit() is defined in:
> 
> * src/main/sysutils.c
> (https://github.com/wch/r-source/blob/trunk/src/main/sysutils.c#L1692-L1736)
> 
> 
> Unfortunately, right now, I've got little extra time to troubleshoot
> this further.
> 
> /Henrik
> 
> On Wed, Oct 26, 2016 at 2:22 AM, Berend Hasselman <bhh at xs4all.nl> wrote:
>> 
>>> On 26 Oct 2016, at 04:44, Henrik Bengtsson <henrik.bengtsson at gmail.com> wrote:
>>> .......
>>> This looks like a bug to me.  Can anyone on macOS confirm whether this
>>> is also a problem there or not?
>>> 
>> 
>> 
>> Tried it on macOS El Capitan and got this (running in R.app with R version 3.3.2 RC (2016-10-23 r71574):
>> 
>>> setTimeLimit(elapsed=1)
>>> system.time({ Sys.sleep(10); message("done") })
>> Error in Sys.sleep(10) : reached elapsed time limit
>> Timing stopped at: 0.113 0.042 10.038
>> 
>> Berend
>> 
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From spencer.graves at prodsyse.com  Wed Oct 26 23:04:29 2016
From: spencer.graves at prodsyse.com (Spencer Graves)
Date: Wed, 26 Oct 2016 16:04:29 -0500
Subject: [Rd] BUG?: On Linux setTimeLimit() fails to propagate timeout
 error when it occurs (works on Windows)
In-Reply-To: <57E7E96A-D3F9-42F4-877D-56109CD38CC8@gmail.com>
References: <CAFDcVCStodbQMS4TffimW69qvVutCX8FheDNxf1o_Ejpmu9NQg@mail.gmail.com>
	<8995051E-628D-4536-A64C-517A9188F416@xs4all.nl>
	<CAFDcVCQmAAq_GYB5WUE2O25RkzCCpeMudJwQ3pCucp5MATAkXw@mail.gmail.com>
	<57E7E96A-D3F9-42F4-877D-56109CD38CC8@gmail.com>
Message-ID: <51e9b70c-10db-7945-e82a-7ccbdb7fc510@prodsyse.com>

I was using RStudio 0.99.902.  Spencer


On 10/26/2016 3:34 PM, peter dalgaard wrote:
> Spencer also had tools and rsconnect loaded (via a namespace) but it doesn't seem to make a difference for me if I load them. It also doesn't seem to matter for me whether it is CRAN R, locally built R, Terminal, R.app. However, RStudio differs
>
>> setTimeLimit(elapsed=1)
> Error: reached elapsed time limit
>> setTimeLimit(elapsed=1)
> Error: reached elapsed time limit
>> setTimeLimit(elapsed=1); system.time({Sys.sleep(10);message("done")})
> Error in Sys.sleep(10) : reached elapsed time limit
> Timing stopped at: 0.003 0.003 0.733
>
> -pd
>
>
>> On 26 Oct 2016, at 21:54 , Henrik Bengtsson <henrik.bengtsson at gmail.com> wrote:
>>
>> Thank you for the feedback and confirmations.  Interesting to see that
>> it's also reproducible on macOS expect for Spencer; that might
>> indicate a difference in builds.
>>
>> BTW, my original post suggested that timeout error was for sure
>> detected while running Sys.sleep(10).  However, it could of course
>> also be that it is only detected after it finishes.
>>
>>
>> For troubleshooting, the help("setTimeLimit", package = "base") says that:
>>
>> * "Time limits are checked whenever a user interrupt could occur. This
>> will happen frequently in R code and during Sys.sleep, but only at
>> points in compiled C and Fortran code identified by the code author."
>>
>> The example here uses Sys.sleep(), which supports and detects user interrupts.
>>
>>
>> The timeout error message is thrown by the R_ProcessEvents(void)
>> function as defined in:
>>
>> * src/unix/sys-unix.c
>> (https://github.com/wch/r-source/blob/trunk/src/unix/sys-unix.c#L421-L453)
>> * src/gnuwin32/system.c
>> (https://github.com/wch/r-source/blob/trunk/src/gnuwin32/system.c#L110-L140)
>>
>> So, they're clearly different implementations on Windows and Unix.
>> Also, for the Unix implementation, the code differ based on
>> preprocessing directive HAVE_AQUA, which could explain why Spencer
>> observes a different behavior than Peter and Berend (all on macOS).
>>
>>
>> Whenever the R_CheckUserInterrupt() function is called it in turn
>> always calls R_ProcessEvents().  At the end, there is a code snippet -
>> if (R_interrupts_pending) onintr(); - which is Windows specific and
>> could be another important difference between Windows and Unix.  This
>> function is defined in:
>>
>> * src/main/errors.c
>> (https://github.com/wch/r-source/blob/trunk/src/main/errors.c#L114-L134)
>>
>>
>> The do_setTimeLimit() function controls global variables cpuLimitValue
>> and elapsedLimitValue, which are checked in R_ProcessEvents(), but
>> other than setting the timeout limits I don't think it's involved in
>> the runtime checks. The do_setTimeLimit() is defined in:
>>
>> * src/main/sysutils.c
>> (https://github.com/wch/r-source/blob/trunk/src/main/sysutils.c#L1692-L1736)
>>
>>
>> Unfortunately, right now, I've got little extra time to troubleshoot
>> this further.
>>
>> /Henrik
>>
>> On Wed, Oct 26, 2016 at 2:22 AM, Berend Hasselman <bhh at xs4all.nl> wrote:
>>>> On 26 Oct 2016, at 04:44, Henrik Bengtsson <henrik.bengtsson at gmail.com> wrote:
>>>> .......
>>>> This looks like a bug to me.  Can anyone on macOS confirm whether this
>>>> is also a problem there or not?
>>>>
>>>
>>> Tried it on macOS El Capitan and got this (running in R.app with R version 3.3.2 RC (2016-10-23 r71574):
>>>
>>>> setTimeLimit(elapsed=1)
>>>> system.time({ Sys.sleep(10); message("done") })
>>> Error in Sys.sleep(10) : reached elapsed time limit
>>> Timing stopped at: 0.113 0.042 10.038
>>>
>>> Berend
>>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel


From richierocks at gmail.com  Thu Oct 27 09:51:58 2016
From: richierocks at gmail.com (Richard Cotton)
Date: Thu, 27 Oct 2016 10:51:58 +0300
Subject: [Rd] using with inside loop breaks next
Message-ID: <CAPp_+=dh_8cUxK6GxT6oNnK4HvZ1wBqZ+QWggicKiDmuzaGbxQ@mail.gmail.com>

If I want to use with inside a loop, it seems that next gets confused.
To reproduce:

for(lst in list(list(a = 1), list(a = 2), list(a = 3)))
{
  with(lst, if(a == 2) next else print(a))
}

I expect 1 and 3 to be printed, but I see

[1] 1
 Error in eval(expr, envir, enclos) :
  no loop for break/next, jumping to top level

Is this
a) by design, or
b) a bug, or
c) a thing that is rare enough that I should just rewrite my code?

-- 
Regards,
Richie

Learning R
4dpiecharts.com


From richierocks at gmail.com  Thu Oct 27 10:03:20 2016
From: richierocks at gmail.com (Richard Cotton)
Date: Thu, 27 Oct 2016 11:03:20 +0300
Subject: [Rd] improve 'package not installed' load errors?
In-Reply-To: <CAJXgQP1AAs2oXZX1wbsCcPCsUYOjG-VXTPZ_zeyq9co2C5B0rQ@mail.gmail.com>
References: <CAJXgQP1AAs2oXZX1wbsCcPCsUYOjG-VXTPZ_zeyq9co2C5B0rQ@mail.gmail.com>
Message-ID: <CAPp_+=cNo9wS71Kf0mmYzweGJ-C9gUHV=fdjLwKkzgpmeMgc8g@mail.gmail.com>

> A side question, which I do not know the answer to, is how users get themselves into this state.

I've fallen over this a few times.  It happens when you have multiple
R sessions running, and R tries to update Rcpp while it is loaded in
the other session.

For example, I'm working on one project, then I open another copy of R
to work on a different project.  Because I have update.packages in my
Rprofile, R occasionally tries to update Rcpp.  If that is loaded in
the first session, then a clean uninstall doesn't happen (the
directory and the dll are left).  Since the directory is still there,
update.packages thinks that the package exists, and I'm left with a
mangled copy of Rcpp that I need to manually remove.

On 24 October 2016 at 20:51, Kevin Ushey <kevinushey at gmail.com> wrote:
> Hi R-devel,
>
> One of the more common issues that new R users see, and become stumped
> by, is error messages during package load of the form:
>
>> library(ggplot2)
> Error in loadNamespace(j <- i[[1L]], c(lib.loc, .libPaths()),
> versionCheck = vI[[j]]) :
>   there is no package called 'Rcpp'
> Error: package or namespace load failed for 'ggplot2'
>
> Typically, error messages of this form are caused simply by one or
> more dependent packages (in this case, 'Rcpp') not being installed or
> available on the current library paths. (A side question, which I do
> not know the answer to, is how users get themselves into this state.)
>
> I believe it would be helpful for new users if the error message
> reported here was a bit more direct, e.g.
>
>> library(ggplot2)
> Error: 'ggplot2' depends on package 'Rcpp', but 'Rcpp' is not installed
> consider installing 'Rcpp' with install.packages("Rcpp")
>
> In other words, it might be helpful to avoid printing the
> 'loadNamespace()' call on error (since it's mostly just scary /
> uninformative), and check up-front that the package is installed
> before attempting to call 'loadNamespace()'. I'm sure a number of
> novice users will still just throw their hands up in the air and say
> "I don't know what to do", but I think this would help steer a number
> of users in the right direction.
>
> (The prescription to suggest installing a package from CRAN if
> available might be a step too far, but I think making it more clear
> that the error is due to a missing dependent package would help.)
>
> Any thoughts?
> Kevin
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel



-- 
Regards,
Richie

Learning R
4dpiecharts.com


From pdalgd at gmail.com  Thu Oct 27 10:10:10 2016
From: pdalgd at gmail.com (Peter Dalgaard)
Date: Thu, 27 Oct 2016 10:10:10 +0200
Subject: [Rd] using with inside loop breaks next
In-Reply-To: <CAPp_+=dh_8cUxK6GxT6oNnK4HvZ1wBqZ+QWggicKiDmuzaGbxQ@mail.gmail.com>
References: <CAPp_+=dh_8cUxK6GxT6oNnK4HvZ1wBqZ+QWggicKiDmuzaGbxQ@mail.gmail.com>
Message-ID: <39AD6E38-BA48-4545-BC31-E366D40B306E@gmail.com>

(a)/(c) mostly, I think. The crux is that "next" is unhappy about being evaluated in a different environment than the containing loop. Witness this:


> for (i in 1:10) {if (i == 5) evalq(next); print(i)}
[1] 1
[1] 2
[1] 3
[1] 4
[1] 6
[1] 7
[1] 8
[1] 9
[1] 10
> for (i in 1:10) {if (i == 5) evalq(next, new.env()); print(i)}
[1] 1
[1] 2
[1] 3
[1] 4
Error in eval(substitute(expr), envir, enclos) : 
  no loop for break/next, jumping to top level
> for (i in 1:10) {if (i == 5) evalq(next, parent.env(new.env())); print(i)}
[1] 1
[1] 2
[1] 3
[1] 4
[1] 6
[1] 7
[1] 8
[1] 9
[1] 10

-pd



> On 27 Oct 2016, at 09:51 , Richard Cotton <richierocks at gmail.com> wrote:
> 
> If I want to use with inside a loop, it seems that next gets confused.
> To reproduce:
> 
> for(lst in list(list(a = 1), list(a = 2), list(a = 3)))
> {
>  with(lst, if(a == 2) next else print(a))
> }
> 
> I expect 1 and 3 to be printed, but I see
> 
> [1] 1
> Error in eval(expr, envir, enclos) :
>  no loop for break/next, jumping to top level
> 
> Is this
> a) by design, or
> b) a bug, or
> c) a thing that is rare enough that I should just rewrite my code?
> 
> -- 
> Regards,
> Richie
> 
> Learning R
> 4dpiecharts.com
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From steffen.wagner at inwt-statistics.de  Thu Oct 27 11:26:42 2016
From: steffen.wagner at inwt-statistics.de (Steffen Wagner)
Date: Thu, 27 Oct 2016 11:26:42 +0200
Subject: [Rd] enhancement to R CMD check: do imported objects from multiple
 packages mask each other?
Message-ID: <CAKjXbS7UtyBZFukq8fC8w5hJWxf+Ve3OwWt66Neu8_O4ZQWhhA@mail.gmail.com>

Dear R-Developement Team,

I want to suggest an additiol check to the R CMD check functionality.

Consider the situation where the objects of more than one package are
imported to the NAMESPACE of a third package, e.g. via

    import(foo, bar)

in the NAMESPACE file.

There might be situations where exported objects in the packages `foo`
and `bar` have the same name, let?s say there is an object `f`
exported from both packages.

Then a warning created by R CMD check comparable to the same situation
when attaching multiple packages to the search path, like

> library(foo)
> library(bar)
The following objects are masked from ?package:foo?:

    f


would be very helpful.

I am aware that it is not best practice to import many packages with
many exported objects to the NAMESPACE of another package.
Nevertheless it would be nice feature to be warned about the resulting
name conflict.

Thanks in advance.

Steffen

-- 
INWT Statistics GmbH
Obentrautstra?e 72
10963 Berlin

Fon +49 30 609857995
Fax +49 30 609857998
E-Mail steffen.wagner at inwt-statistics.de
www.inwt-statistics.de

Sitz der Gesellschaft: Berlin-Kreuzberg
AG Berlin-Charlottenburg, HRB 133141 B
Gesch?ftsf?hrer: Dr. Amit Ghosh


From murdoch.duncan at gmail.com  Thu Oct 27 14:17:29 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 27 Oct 2016 08:17:29 -0400
Subject: [Rd] enhancement to R CMD check: do imported objects from
 multiple packages mask each other?
In-Reply-To: <CAKjXbS7UtyBZFukq8fC8w5hJWxf+Ve3OwWt66Neu8_O4ZQWhhA@mail.gmail.com>
References: <CAKjXbS7UtyBZFukq8fC8w5hJWxf+Ve3OwWt66Neu8_O4ZQWhhA@mail.gmail.com>
Message-ID: <8843cbef-2a88-bf79-7136-bd3833ef25aa@gmail.com>

On 27/10/2016 5:26 AM, Steffen Wagner wrote:
> Dear R-Developement Team,
>
> I want to suggest an additiol check to the R CMD check functionality.
>
> Consider the situation where the objects of more than one package are
> imported to the NAMESPACE of a third package, e.g. via
>
>      import(foo, bar)
>
> in the NAMESPACE file.
>
> There might be situations where exported objects in the packages `foo`
> and `bar` have the same name, let?s say there is an object `f`
> exported from both packages.
>
> Then a warning created by R CMD check comparable to the same situation
> when attaching multiple packages to the search path, like
>
> > library(foo)
> > library(bar)
> The following objects are masked from ?package:foo?:
>
>      f
>
>
> would be very helpful.
>
> I am aware that it is not best practice to import many packages with
> many exported objects to the NAMESPACE of another package.
> Nevertheless it would be nice feature to be warned about the resulting
> name conflict.

That sounds like a reasonable suggestion.  However, unless someone 
volunteers to do it very quickly, it will likely get lost in the 
archives of this list and forgotten.

Could you please post it to the bug list as an enhancement request? 
Those should be persistent.

If you have never posted to the bug list you will need to be manually 
added to the list of people allowed to post.  In that case, write to me 
and I'll do it.

Duncan Murdoch


From hpages at fredhutch.org  Thu Oct 27 17:58:49 2016
From: hpages at fredhutch.org (=?UTF-8?B?SGVydsOpIFBhZ8Oocw==?=)
Date: Thu, 27 Oct 2016 08:58:49 -0700
Subject: [Rd] enhancement to R CMD check: do imported objects from
 multiple packages mask each other?
In-Reply-To: <8843cbef-2a88-bf79-7136-bd3833ef25aa@gmail.com>
References: <CAKjXbS7UtyBZFukq8fC8w5hJWxf+Ve3OwWt66Neu8_O4ZQWhhA@mail.gmail.com>
	<8843cbef-2a88-bf79-7136-bd3833ef25aa@gmail.com>
Message-ID: <b61e52c9-56b9-0815-64b7-5e9039287fea@fredhutch.org>

Hi Duncan,

On 10/27/2016 05:17 AM, Duncan Murdoch wrote:
[...]
> Could you please post it to the bug list as an enhancement request?
> Those should be persistent.
>
> If you have never posted to the bug list you will need to be manually
> added to the list of people allowed to post.  In that case, write to me
> and I'll do it.

Sorry to ask such a naive question but is there a bug list or do you
mean the Bugzilla bug tracker?

Thanks,
H.

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fredhutch.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From luke-tierney at uiowa.edu  Thu Oct 27 18:26:22 2016
From: luke-tierney at uiowa.edu (luke-tierney at uiowa.edu)
Date: Thu, 27 Oct 2016 11:26:22 -0500
Subject: [Rd] BUG?: On Linux setTimeLimit() fails to propagate timeout
 error when it occurs (works on Windows)
In-Reply-To: <57E7E96A-D3F9-42F4-877D-56109CD38CC8@gmail.com>
References: <CAFDcVCStodbQMS4TffimW69qvVutCX8FheDNxf1o_Ejpmu9NQg@mail.gmail.com>
	<8995051E-628D-4536-A64C-517A9188F416@xs4all.nl>
	<CAFDcVCQmAAq_GYB5WUE2O25RkzCCpeMudJwQ3pCucp5MATAkXw@mail.gmail.com>
	<57E7E96A-D3F9-42F4-877D-56109CD38CC8@gmail.com>
Message-ID: <alpine.DEB.2.20.1610271113550.2355@luke-Latitude>

On unix, unless event polling is enabled Sys.sleep just waits in a
select() call (with a SIGINT handler in place) so the elapsed time
isn't checked until after the select call is complete. Rstudio uses
event polling, and in particular sets R_wait_usec to 10000, which
means event and interrupt checks happen during a Sys.seep call.  The R
GUI on macOS doesn't seem to do this (but my lldb skills aren't up to
checking). Now that we have this elapsed time limit mechanism it might
be a good idea to set the default for R_wait_usec to something
reasonable on unix in general. 100000 might be a good value.

A more worrying thing I noticed while looking at this is that blocking
reads on fifos and pipes and probably sockets are not interruptable --
that should probably be looked into.

Best,

luke

On Wed, 26 Oct 2016, peter dalgaard wrote:

> Spencer also had tools and rsconnect loaded (via a namespace) but it doesn't seem to make a difference for me if I load them. It also doesn't seem to matter for me whether it is CRAN R, locally built R, Terminal, R.app. However, RStudio differs
>
>> setTimeLimit(elapsed=1)
> Error: reached elapsed time limit
>> setTimeLimit(elapsed=1)
> Error: reached elapsed time limit
>> setTimeLimit(elapsed=1); system.time({Sys.sleep(10);message("done")})
> Error in Sys.sleep(10) : reached elapsed time limit
> Timing stopped at: 0.003 0.003 0.733
>
> -pd
>
>
>> On 26 Oct 2016, at 21:54 , Henrik Bengtsson <henrik.bengtsson at gmail.com> wrote:
>>
>> Thank you for the feedback and confirmations.  Interesting to see that
>> it's also reproducible on macOS expect for Spencer; that might
>> indicate a difference in builds.
>>
>> BTW, my original post suggested that timeout error was for sure
>> detected while running Sys.sleep(10).  However, it could of course
>> also be that it is only detected after it finishes.
>>
>>
>> For troubleshooting, the help("setTimeLimit", package = "base") says that:
>>
>> * "Time limits are checked whenever a user interrupt could occur. This
>> will happen frequently in R code and during Sys.sleep, but only at
>> points in compiled C and Fortran code identified by the code author."
>>
>> The example here uses Sys.sleep(), which supports and detects user interrupts.
>>
>>
>> The timeout error message is thrown by the R_ProcessEvents(void)
>> function as defined in:
>>
>> * src/unix/sys-unix.c
>> (https://github.com/wch/r-source/blob/trunk/src/unix/sys-unix.c#L421-L453)
>> * src/gnuwin32/system.c
>> (https://github.com/wch/r-source/blob/trunk/src/gnuwin32/system.c#L110-L140)
>>
>> So, they're clearly different implementations on Windows and Unix.
>> Also, for the Unix implementation, the code differ based on
>> preprocessing directive HAVE_AQUA, which could explain why Spencer
>> observes a different behavior than Peter and Berend (all on macOS).
>>
>>
>> Whenever the R_CheckUserInterrupt() function is called it in turn
>> always calls R_ProcessEvents().  At the end, there is a code snippet -
>> if (R_interrupts_pending) onintr(); - which is Windows specific and
>> could be another important difference between Windows and Unix.  This
>> function is defined in:
>>
>> * src/main/errors.c
>> (https://github.com/wch/r-source/blob/trunk/src/main/errors.c#L114-L134)
>>
>>
>> The do_setTimeLimit() function controls global variables cpuLimitValue
>> and elapsedLimitValue, which are checked in R_ProcessEvents(), but
>> other than setting the timeout limits I don't think it's involved in
>> the runtime checks. The do_setTimeLimit() is defined in:
>>
>> * src/main/sysutils.c
>> (https://github.com/wch/r-source/blob/trunk/src/main/sysutils.c#L1692-L1736)
>>
>>
>> Unfortunately, right now, I've got little extra time to troubleshoot
>> this further.
>>
>> /Henrik
>>
>> On Wed, Oct 26, 2016 at 2:22 AM, Berend Hasselman <bhh at xs4all.nl> wrote:
>>>
>>>> On 26 Oct 2016, at 04:44, Henrik Bengtsson <henrik.bengtsson at gmail.com> wrote:
>>>> .......
>>>> This looks like a bug to me.  Can anyone on macOS confirm whether this
>>>> is also a problem there or not?
>>>>
>>>
>>>
>>> Tried it on macOS El Capitan and got this (running in R.app with R version 3.3.2 RC (2016-10-23 r71574):
>>>
>>>> setTimeLimit(elapsed=1)
>>>> system.time({ Sys.sleep(10); message("done") })
>>> Error in Sys.sleep(10) : reached elapsed time limit
>>> Timing stopped at: 0.113 0.042 10.038
>>>
>>> Berend
>>>
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Luke Tierney
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From murdoch.duncan at gmail.com  Thu Oct 27 20:35:45 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 27 Oct 2016 14:35:45 -0400
Subject: [Rd] enhancement to R CMD check: do imported objects from
 multiple packages mask each other?
In-Reply-To: <b61e52c9-56b9-0815-64b7-5e9039287fea@fredhutch.org>
References: <CAKjXbS7UtyBZFukq8fC8w5hJWxf+Ve3OwWt66Neu8_O4ZQWhhA@mail.gmail.com>
	<8843cbef-2a88-bf79-7136-bd3833ef25aa@gmail.com>
	<b61e52c9-56b9-0815-64b7-5e9039287fea@fredhutch.org>
Message-ID: <74b8f8ba-bb3c-6400-27c0-e7b7cffde75e@gmail.com>

On 27/10/2016 11:58 AM, Herv? Pag?s wrote:
> Hi Duncan,
>
> On 10/27/2016 05:17 AM, Duncan Murdoch wrote:
> [...]
> > Could you please post it to the bug list as an enhancement request?
> > Those should be persistent.
> >
> > If you have never posted to the bug list you will need to be manually
> > added to the list of people allowed to post.  In that case, write to me
> > and I'll do it.
>
> Sorry to ask such a naive question but is there a bug list or do you
> mean the Bugzilla bug tracker?

I meant bugzilla.

Duncan Murdoch


From suharto_anggono at yahoo.com  Sat Oct 29 17:32:00 2016
From: suharto_anggono at yahoo.com (Suharto Anggono Suharto Anggono)
Date: Sat, 29 Oct 2016 15:32:00 +0000 (UTC)
Subject: [Rd] lapply on long vector fails
References: <1007285085.282204.1477755120056.ref@mail.yahoo.com>
Message-ID: <1007285085.282204.1477755120056@mail.yahoo.com>

I report here that, in RStudio in Data Scientist Workbench,
lapply(raw(2^31), function(x) NULL)
failed after not so long time.

> res <- lapply(raw(2^31), function(x) NULL)
Error in FUN(X[[i]], ...) : long vectors not supported yet: memory.c:1652
> sessionInfo()
R version 3.3.1 (2016-06-21)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Debian GNU/Linux stretch/sid

locale:
 [1] LC_CTYPE=en_US.UTF-8      
 [2] LC_NUMERIC=C              
 [3] LC_TIME=en_US.UTF-8       
 [4] LC_COLLATE=en_US.UTF-8    
 [5] LC_MONETARY=en_US.UTF-8   
 [6] LC_MESSAGES=en_US.UTF-8   
 [7] LC_PAPER=en_US.UTF-8      
 [8] LC_NAME=C                 
 [9] LC_ADDRESS=C              
[10] LC_TELEPHONE=C            
[11] LC_MEASUREMENT=en_US.UTF-8
[12] LC_IDENTIFICATION=C       

attached base packages:
[1] stats     graphics  grDevices utils     datasets 
[6] methods   base     

other attached packages:
[1] SparkR_1.6.1

loaded via a namespace (and not attached):
[1] tools_3.3.1


However, the code that implements 'lapply', function 'do_lapply' in apply.c, seems to support long vectors.

The error message points to memory.c:1652. I don't understand the code there.


A different case:
gc()
after
system.time(vector("list", 2^31))
gave an error with message pointing to memory.c at different line. Subsequent
gc()
didn't give error.

> system.time(vector("list", 2^31))
   user  system elapsed 
  3.104  15.608  18.711 
> gc()
Error in gc() : long vectors not supported yet: memory.c:1121
> gc()
         used (Mb) gc trigger    (Mb)   max used    (Mb)
Ncells 445496 23.8     750400    40.1     592000    31.7
Vcells 667725  5.1 2062440028 15735.2 2148153146 16389.2


From luke-tierney at uiowa.edu  Sun Oct 30 12:50:20 2016
From: luke-tierney at uiowa.edu (luke-tierney at uiowa.edu)
Date: Sun, 30 Oct 2016 06:50:20 -0500
Subject: [Rd] lapply on long vector fails
In-Reply-To: <1007285085.282204.1477755120056@mail.yahoo.com>
References: <1007285085.282204.1477755120056.ref@mail.yahoo.com>
	<1007285085.282204.1477755120056@mail.yahoo.com>
Message-ID: <alpine.OSX.2.20.1610300649340.4633@lukes-macbook-air.local>

Thanks.  Fixed in R-devel in r71606.

Best,

luke

On Sat, 29 Oct 2016, Suharto Anggono Suharto Anggono via R-devel wrote:

> I report here that, in RStudio in Data Scientist Workbench,
> lapply(raw(2^31), function(x) NULL)
> failed after not so long time.
>
>> res <- lapply(raw(2^31), function(x) NULL)
> Error in FUN(X[[i]], ...) : long vectors not supported yet: memory.c:1652
>> sessionInfo()
> R version 3.3.1 (2016-06-21)
> Platform: x86_64-pc-linux-gnu (64-bit)
> Running under: Debian GNU/Linux stretch/sid
>
> locale:
> [1] LC_CTYPE=en_US.UTF-8
> [2] LC_NUMERIC=C
> [3] LC_TIME=en_US.UTF-8
> [4] LC_COLLATE=en_US.UTF-8
> [5] LC_MONETARY=en_US.UTF-8
> [6] LC_MESSAGES=en_US.UTF-8
> [7] LC_PAPER=en_US.UTF-8
> [8] LC_NAME=C
> [9] LC_ADDRESS=C
> [10] LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.UTF-8
> [12] LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets
> [6] methods   base
>
> other attached packages:
> [1] SparkR_1.6.1
>
> loaded via a namespace (and not attached):
> [1] tools_3.3.1
>
>
> However, the code that implements 'lapply', function 'do_lapply' in apply.c, seems to support long vectors.
>
> The error message points to memory.c:1652. I don't understand the code there.
>
>
> A different case:
> gc()
> after
> system.time(vector("list", 2^31))
> gave an error with message pointing to memory.c at different line. Subsequent
> gc()
> didn't give error.
>
>> system.time(vector("list", 2^31))
>   user  system elapsed
>  3.104  15.608  18.711
>> gc()
> Error in gc() : long vectors not supported yet: memory.c:1121
>> gc()
>         used (Mb) gc trigger    (Mb)   max used    (Mb)
> Ncells 445496 23.8     750400    40.1     592000    31.7
> Vcells 667725  5.1 2062440028 15735.2 2148153146 16389.2
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Luke Tierney
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From henrik.bengtsson at gmail.com  Sun Oct 30 19:38:07 2016
From: henrik.bengtsson at gmail.com (Henrik Bengtsson)
Date: Sun, 30 Oct 2016 11:38:07 -0700
Subject: [Rd] closeAllConnections() can really mess things up
Message-ID: <CAFDcVCTOvn4mc9Xva8FMP-hMiR-p2thQvKVs7ynFFCspDy6Adg@mail.gmail.com>

This is what I get on R 3.3.1 on Linux:

> con1 <- textConnection("foo1", open = "w")
> print(con1)
     description            class             mode             text
          "foo1" "textConnection"              "w"           "text"
          opened         can read        can write
        "opened"             "no"            "yes"

> closeAllConnections()
> con2 <- textConnection("foo2", open = "w")

## Hmm... at this point, con1 point to con2.

> print(con1)
     description            class             mode             text
          "foo2" "textConnection"              "w"           "text"
          opened         can read        can write
        "opened"             "no"            "yes"

> all.equal(con2, con1)
[1] TRUE

Hmm... that looks it could potentially mess up things badly if some
code / user calls closeAllConnections(), then other connections are
opened after that, and then there's code (e.g. via promises or
finalizers) that tries to write to the original connections (resulting
in writing to the new ones).

I'm not sure how one can protect oneself against this.  One approach
that could lower the risk for mistakes is to record a checksum for the
connection (think digest::digest(summary(con1))) when the connection
is first opened and then each time one tried to read or write to the
connect, one validate against this again.

I can see how this could happen if each connection is referenced via
an integer index internally.

I discovered this in a case where the R session terminates (for
unknown reasons) and then calls sys.save.image().  sys.save.image()
calls closeAllConnections() and then save.image().   The latter
triggered promises / delayed assignments to be resolved.  Then each of
those tries to access their previously assigned connections.  At this
point, those are now all closed, but the promises doesn't know and
instead tries to read their connections.  At least the first one will
try to access the now only open connection, which is the one
save.image() opened.  In my case, they tried to read so they failed.

/Henrik


From henrik.bengtsson at gmail.com  Mon Oct 31 01:35:48 2016
From: henrik.bengtsson at gmail.com (Henrik Bengtsson)
Date: Sun, 30 Oct 2016 17:35:48 -0700
Subject: [Rd] BUG?: On Linux setTimeLimit() fails to propagate timeout
 error when it occurs (works on Windows)
In-Reply-To: <alpine.DEB.2.20.1610271113550.2355@luke-Latitude>
References: <CAFDcVCStodbQMS4TffimW69qvVutCX8FheDNxf1o_Ejpmu9NQg@mail.gmail.com>
	<8995051E-628D-4536-A64C-517A9188F416@xs4all.nl>
	<CAFDcVCQmAAq_GYB5WUE2O25RkzCCpeMudJwQ3pCucp5MATAkXw@mail.gmail.com>
	<57E7E96A-D3F9-42F4-877D-56109CD38CC8@gmail.com>
	<alpine.DEB.2.20.1610271113550.2355@luke-Latitude>
Message-ID: <CAFDcVCQ7QyNs2ZJ8YxEyHZHmX3iOcDEV0SbydptchSBJFt5sHA@mail.gmail.com>

Thank you for looking into this Luke.

On Thu, Oct 27, 2016 at 9:26 AM,  <luke-tierney at uiowa.edu> wrote:
> On unix, unless event polling is enabled Sys.sleep just waits in a
> select() call (with a SIGINT handler in place) so the elapsed time
> isn't checked until after the select call is complete. Rstudio uses
> event polling, and in particular sets R_wait_usec to 10000, which
> means event and interrupt checks happen during a Sys.seep call.  The R
> GUI on macOS doesn't seem to do this (but my lldb skills aren't up to
> checking). Now that we have this elapsed time limit mechanism it might
> be a good idea to set the default for R_wait_usec to something
> reasonable on unix in general. 100000 might be a good value.
>

> A more worrying thing I noticed while looking at this is that blocking
> reads on fifos and pipes and probably sockets are not interruptable --
> that should probably be looked into.

This is actually related to the use case where I want to use
setTimeLimit().  When using parallel:::newPSOCKnode(), there's a
30-day timeout associated with the socket connection.  Now, this long
timeout is needed in order for long-running tasks to not to timeout
the master-worker connection.   However, when it comes to the actual
setup of the connection, then it would be able to detect connection
issues earlier than that.  For example, if the socket connection
cannot be established within 60 seconds, then it is very likely that
the worker machine couldn't be reached, especially for connecting to
remote machines over SSH.

The current code of parallel:::newPSOCKnode() basically does:

system("ssh remote.server.org Rscript -e <launch worker and connect
back>", wait = FALSE)
con <- socketConnection("localhost", port = 11000, server = TRUE,
blocking = TRUE, open = "a+b", timeout = 30*24*60*60)

If the remote SSH system call fails to reach or set up the worker, the
following call to socketConnection() will sit there and wait for 30
days.  Ideally one could solve this as:

system("ssh remote.server.org Rscript -e <launch worker and connect
back>", wait = FALSE)
setTimeLimit(elapsed=60)
con <- socketConnection("localhost", port = 11000, server = TRUE,
blocking = TRUE, open = "a+b", timeout = 30*24*60*60)

Thanks,

Henrik

>
> Best,
>
> luke
>
>
> On Wed, 26 Oct 2016, peter dalgaard wrote:
>
>> Spencer also had tools and rsconnect loaded (via a namespace) but it
>> doesn't seem to make a difference for me if I load them. It also doesn't
>> seem to matter for me whether it is CRAN R, locally built R, Terminal,
>> R.app. However, RStudio differs
>>
>>> setTimeLimit(elapsed=1)
>>
>> Error: reached elapsed time limit
>>>
>>> setTimeLimit(elapsed=1)
>>
>> Error: reached elapsed time limit
>>>
>>> setTimeLimit(elapsed=1); system.time({Sys.sleep(10);message("done")})
>>
>> Error in Sys.sleep(10) : reached elapsed time limit
>> Timing stopped at: 0.003 0.003 0.733
>>
>> -pd
>>
>>
>>> On 26 Oct 2016, at 21:54 , Henrik Bengtsson <henrik.bengtsson at gmail.com>
>>> wrote:
>>>
>>> Thank you for the feedback and confirmations.  Interesting to see that
>>> it's also reproducible on macOS expect for Spencer; that might
>>> indicate a difference in builds.
>>>
>>> BTW, my original post suggested that timeout error was for sure
>>> detected while running Sys.sleep(10).  However, it could of course
>>> also be that it is only detected after it finishes.
>>>
>>>
>>> For troubleshooting, the help("setTimeLimit", package = "base") says
>>> that:
>>>
>>> * "Time limits are checked whenever a user interrupt could occur. This
>>> will happen frequently in R code and during Sys.sleep, but only at
>>> points in compiled C and Fortran code identified by the code author."
>>>
>>> The example here uses Sys.sleep(), which supports and detects user
>>> interrupts.
>>>
>>>
>>> The timeout error message is thrown by the R_ProcessEvents(void)
>>> function as defined in:
>>>
>>> * src/unix/sys-unix.c
>>>
>>> (https://github.com/wch/r-source/blob/trunk/src/unix/sys-unix.c#L421-L453)
>>> * src/gnuwin32/system.c
>>>
>>> (https://github.com/wch/r-source/blob/trunk/src/gnuwin32/system.c#L110-L140)
>>>
>>> So, they're clearly different implementations on Windows and Unix.
>>> Also, for the Unix implementation, the code differ based on
>>> preprocessing directive HAVE_AQUA, which could explain why Spencer
>>> observes a different behavior than Peter and Berend (all on macOS).
>>>
>>>
>>> Whenever the R_CheckUserInterrupt() function is called it in turn
>>> always calls R_ProcessEvents().  At the end, there is a code snippet -
>>> if (R_interrupts_pending) onintr(); - which is Windows specific and
>>> could be another important difference between Windows and Unix.  This
>>> function is defined in:
>>>
>>> * src/main/errors.c
>>> (https://github.com/wch/r-source/blob/trunk/src/main/errors.c#L114-L134)
>>>
>>>
>>> The do_setTimeLimit() function controls global variables cpuLimitValue
>>> and elapsedLimitValue, which are checked in R_ProcessEvents(), but
>>> other than setting the timeout limits I don't think it's involved in
>>> the runtime checks. The do_setTimeLimit() is defined in:
>>>
>>> * src/main/sysutils.c
>>>
>>> (https://github.com/wch/r-source/blob/trunk/src/main/sysutils.c#L1692-L1736)
>>>
>>>
>>> Unfortunately, right now, I've got little extra time to troubleshoot
>>> this further.
>>>
>>> /Henrik
>>>
>>> On Wed, Oct 26, 2016 at 2:22 AM, Berend Hasselman <bhh at xs4all.nl> wrote:
>>>>
>>>>
>>>>> On 26 Oct 2016, at 04:44, Henrik Bengtsson <henrik.bengtsson at gmail.com>
>>>>> wrote:
>>>>> .......
>>>>> This looks like a bug to me.  Can anyone on macOS confirm whether this
>>>>> is also a problem there or not?
>>>>>
>>>>
>>>>
>>>> Tried it on macOS El Capitan and got this (running in R.app with R
>>>> version 3.3.2 RC (2016-10-23 r71574):
>>>>
>>>>> setTimeLimit(elapsed=1)
>>>>> system.time({ Sys.sleep(10); message("done") })
>>>>
>>>> Error in Sys.sleep(10) : reached elapsed time limit
>>>> Timing stopped at: 0.113 0.042 10.038
>>>>
>>>> Berend
>>>>
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>>
>
> --
> Luke Tierney
> Ralph E. Wareham Professor of Mathematical Sciences
> University of Iowa                  Phone:             319-335-3386
> Department of Statistics and        Fax:               319-335-3017
>    Actuarial Science
> 241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
> Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From richierocks at gmail.com  Mon Oct 31 10:38:39 2016
From: richierocks at gmail.com (Richard Cotton)
Date: Mon, 31 Oct 2016 12:38:39 +0300
Subject: [Rd] S3 dispatch for primitive generics
Message-ID: <CAPp_+=eTZ-J9N_eTqb1HYPN87Abkw2iB4r0Q2xzGpfBgJ7Z_7A@mail.gmail.com>

I seem to recall reading that for primitive generics, S3 will dispatch
on class first, then on mode.  Unfortunately, I can't find the place
that I read this, and I don't trust my memory.

1) Is this correct?  Or is it dispatch on class, then on typeof? Or
something else?

2) Where is this documented?

-- 
Regards,
Richie

Learning R
4dpiecharts.com


From luke-tierney at uiowa.edu  Mon Oct 31 17:36:40 2016
From: luke-tierney at uiowa.edu (luke-tierney at uiowa.edu)
Date: Mon, 31 Oct 2016 11:36:40 -0500
Subject: [Rd] BUG?: On Linux setTimeLimit() fails to propagate timeout
 error when it occurs (works on Windows)
In-Reply-To: <CAFDcVCQ7QyNs2ZJ8YxEyHZHmX3iOcDEV0SbydptchSBJFt5sHA@mail.gmail.com>
References: <CAFDcVCStodbQMS4TffimW69qvVutCX8FheDNxf1o_Ejpmu9NQg@mail.gmail.com>
	<8995051E-628D-4536-A64C-517A9188F416@xs4all.nl>
	<CAFDcVCQmAAq_GYB5WUE2O25RkzCCpeMudJwQ3pCucp5MATAkXw@mail.gmail.com>
	<57E7E96A-D3F9-42F4-877D-56109CD38CC8@gmail.com>
	<alpine.DEB.2.20.1610271113550.2355@luke-Latitude>
	<CAFDcVCQ7QyNs2ZJ8YxEyHZHmX3iOcDEV0SbydptchSBJFt5sHA@mail.gmail.com>
Message-ID: <alpine.OSX.2.20.1610311132070.4633@lukes-macbook-air.local>

On Mon, 31 Oct 2016, Henrik Bengtsson wrote:

> Thank you for looking into this Luke.
>
> On Thu, Oct 27, 2016 at 9:26 AM,  <luke-tierney at uiowa.edu> wrote:
>> On unix, unless event polling is enabled Sys.sleep just waits in a
>> select() call (with a SIGINT handler in place) so the elapsed time
>> isn't checked until after the select call is complete. Rstudio uses
>> event polling, and in particular sets R_wait_usec to 10000, which
>> means event and interrupt checks happen during a Sys.seep call.  The R
>> GUI on macOS doesn't seem to do this (but my lldb skills aren't up to
>> checking). Now that we have this elapsed time limit mechanism it might
>> be a good idea to set the default for R_wait_usec to something
>> reasonable on unix in general. 100000 might be a good value.
>>
>
>> A more worrying thing I noticed while looking at this is that blocking
>> reads on fifos and pipes and probably sockets are not interruptable --
>> that should probably be looked into.

I'll address the sleep issue sometime soon but I won't be able to look
into the blocking read issue for many months. SOmeone else might have
a chance to look earlier.

But for the situation you describe below using setTimeLimit doesn't
seem like the right approach. The parallel code is not written for
situations that need this kind of fault tolerance; it is not robust to
user interrupts and would not be to timer interrupts either. If you
are concerned that some potential workers might not be available then
you would be better checking that with a ping or simple ssh commend
first before starting a cluster on the available nodes.

Best,

luke

>
> This is actually related to the use case where I want to use
> setTimeLimit().  When using parallel:::newPSOCKnode(), there's a
> 30-day timeout associated with the socket connection.  Now, this long
> timeout is needed in order for long-running tasks to not to timeout
> the master-worker connection.   However, when it comes to the actual
> setup of the connection, then it would be able to detect connection
> issues earlier than that.  For example, if the socket connection
> cannot be established within 60 seconds, then it is very likely that
> the worker machine couldn't be reached, especially for connecting to
> remote machines over SSH.
>
> The current code of parallel:::newPSOCKnode() basically does:
>
> system("ssh remote.server.org Rscript -e <launch worker and connect
> back>", wait = FALSE)
> con <- socketConnection("localhost", port = 11000, server = TRUE,
> blocking = TRUE, open = "a+b", timeout = 30*24*60*60)
>
> If the remote SSH system call fails to reach or set up the worker, the
> following call to socketConnection() will sit there and wait for 30
> days.  Ideally one could solve this as:
>
> system("ssh remote.server.org Rscript -e <launch worker and connect
> back>", wait = FALSE)
> setTimeLimit(elapsed=60)
> con <- socketConnection("localhost", port = 11000, server = TRUE,
> blocking = TRUE, open = "a+b", timeout = 30*24*60*60)
>
> Thanks,
>
> Henrik
>
>>
>> Best,
>>
>> luke
>>
>>
>> On Wed, 26 Oct 2016, peter dalgaard wrote:
>>
>>> Spencer also had tools and rsconnect loaded (via a namespace) but it
>>> doesn't seem to make a difference for me if I load them. It also doesn't
>>> seem to matter for me whether it is CRAN R, locally built R, Terminal,
>>> R.app. However, RStudio differs
>>>
>>>> setTimeLimit(elapsed=1)
>>>
>>> Error: reached elapsed time limit
>>>>
>>>> setTimeLimit(elapsed=1)
>>>
>>> Error: reached elapsed time limit
>>>>
>>>> setTimeLimit(elapsed=1); system.time({Sys.sleep(10);message("done")})
>>>
>>> Error in Sys.sleep(10) : reached elapsed time limit
>>> Timing stopped at: 0.003 0.003 0.733
>>>
>>> -pd
>>>
>>>
>>>> On 26 Oct 2016, at 21:54 , Henrik Bengtsson <henrik.bengtsson at gmail.com>
>>>> wrote:
>>>>
>>>> Thank you for the feedback and confirmations.  Interesting to see that
>>>> it's also reproducible on macOS expect for Spencer; that might
>>>> indicate a difference in builds.
>>>>
>>>> BTW, my original post suggested that timeout error was for sure
>>>> detected while running Sys.sleep(10).  However, it could of course
>>>> also be that it is only detected after it finishes.
>>>>
>>>>
>>>> For troubleshooting, the help("setTimeLimit", package = "base") says
>>>> that:
>>>>
>>>> * "Time limits are checked whenever a user interrupt could occur. This
>>>> will happen frequently in R code and during Sys.sleep, but only at
>>>> points in compiled C and Fortran code identified by the code author."
>>>>
>>>> The example here uses Sys.sleep(), which supports and detects user
>>>> interrupts.
>>>>
>>>>
>>>> The timeout error message is thrown by the R_ProcessEvents(void)
>>>> function as defined in:
>>>>
>>>> * src/unix/sys-unix.c
>>>>
>>>> (https://github.com/wch/r-source/blob/trunk/src/unix/sys-unix.c#L421-L453)
>>>> * src/gnuwin32/system.c
>>>>
>>>> (https://github.com/wch/r-source/blob/trunk/src/gnuwin32/system.c#L110-L140)
>>>>
>>>> So, they're clearly different implementations on Windows and Unix.
>>>> Also, for the Unix implementation, the code differ based on
>>>> preprocessing directive HAVE_AQUA, which could explain why Spencer
>>>> observes a different behavior than Peter and Berend (all on macOS).
>>>>
>>>>
>>>> Whenever the R_CheckUserInterrupt() function is called it in turn
>>>> always calls R_ProcessEvents().  At the end, there is a code snippet -
>>>> if (R_interrupts_pending) onintr(); - which is Windows specific and
>>>> could be another important difference between Windows and Unix.  This
>>>> function is defined in:
>>>>
>>>> * src/main/errors.c
>>>> (https://github.com/wch/r-source/blob/trunk/src/main/errors.c#L114-L134)
>>>>
>>>>
>>>> The do_setTimeLimit() function controls global variables cpuLimitValue
>>>> and elapsedLimitValue, which are checked in R_ProcessEvents(), but
>>>> other than setting the timeout limits I don't think it's involved in
>>>> the runtime checks. The do_setTimeLimit() is defined in:
>>>>
>>>> * src/main/sysutils.c
>>>>
>>>> (https://github.com/wch/r-source/blob/trunk/src/main/sysutils.c#L1692-L1736)
>>>>
>>>>
>>>> Unfortunately, right now, I've got little extra time to troubleshoot
>>>> this further.
>>>>
>>>> /Henrik
>>>>
>>>> On Wed, Oct 26, 2016 at 2:22 AM, Berend Hasselman <bhh at xs4all.nl> wrote:
>>>>>
>>>>>
>>>>>> On 26 Oct 2016, at 04:44, Henrik Bengtsson <henrik.bengtsson at gmail.com>
>>>>>> wrote:
>>>>>> .......
>>>>>> This looks like a bug to me.  Can anyone on macOS confirm whether this
>>>>>> is also a problem there or not?
>>>>>>
>>>>>
>>>>>
>>>>> Tried it on macOS El Capitan and got this (running in R.app with R
>>>>> version 3.3.2 RC (2016-10-23 r71574):
>>>>>
>>>>>> setTimeLimit(elapsed=1)
>>>>>> system.time({ Sys.sleep(10); message("done") })
>>>>>
>>>>> Error in Sys.sleep(10) : reached elapsed time limit
>>>>> Timing stopped at: 0.113 0.042 10.038
>>>>>
>>>>> Berend
>>>>>
>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>>
>>>
>>
>> --
>> Luke Tierney
>> Ralph E. Wareham Professor of Mathematical Sciences
>> University of Iowa                  Phone:             319-335-3386
>> Department of Statistics and        Fax:               319-335-3017
>>    Actuarial Science
>> 241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
>> Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu
>

-- 
Luke Tierney
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


